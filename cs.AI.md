# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Class Attendance System in Education with Deep Learning Method.](http://arxiv.org/abs/2309.13317) | 该论文介绍了利用深度学习方法实现的课堂考勤系统。深度学习方法可以通过图像处理进行面部识别，从而在教育中提供安全性和自动化的贡献。 |
| [^2] | [USL-Net: Uncertainty Self-Learning Network for Unsupervised Skin Lesion Segmentation.](http://arxiv.org/abs/2309.13289) | 使用对比学习和类激活图技术，USL-Net提供了一种无需手动标注指导的方法，能够有效地分割各种皮肤病变区域。 |
| [^3] | [Collision Avoidance and Navigation for a Quadrotor Swarm Using End-to-end Deep Reinforcement Learning.](http://arxiv.org/abs/2309.13285) | 这项研究提出了一种基于端到端深度强化学习的方法，用于在带有障碍物的环境中控制无人机群体，并通过课程学习和回放缓冲区提高性能。此外，还实施了注意力机制以关注邻近机器人和障碍物之间的相互作用。 |
| [^4] | [Being Aware of Localization Accuracy By Generating Predicted-IoU-Guided Quality Scores.](http://arxiv.org/abs/2309.13269) | 本文提出了一种通过生成预测IoU引导的质量得分来意识到本地化准确性的方法，通过联合考虑分类得分和本地化准确性，提高了检测性能。实验结果表明，该方法在一阶检测中取得了最佳性能。 |
| [^5] | [Robust Navigation with Cross-Modal Fusion and Knowledge Transfer.](http://arxiv.org/abs/2309.13266) | 本文提出了一种跨模态融合方法和知识迁移框架，通过师生蒸馏架构实现。在实验中表现出了优于基准线的鲁棒导航性能。 |
| [^6] | [WikiMT++ Dataset Card.](http://arxiv.org/abs/2309.13259) | WikiMT++是一个扩展和精细版本的WikiMusicText数据集，包含了1010个经过策划的ABC记谱法的主题曲。它添加了客观属性和主观情感属性，增强了数据集的应用场景和可用性，并通过CLaMP来纠正属性，提高准确性和完整性。 |
| [^7] | [Defending Pre-trained Language Models as Few-shot Learners against Backdoor Attacks.](http://arxiv.org/abs/2309.13256) | 本研究针对预训练语言模型作为少样本学习者的安全风险进行了初步研究，发现其极易受到反向攻击。为了应对这个问题，我们提出了一种名为MDP的轻量级、可插拔且有效的防御方法，通过利用被污染样本和清洁样本之间的掩码敏感性差距来识别污染样本。实证评估结果表明，MDP在攻击效果和检测逃避性之间形成了进退两难。 |
| [^8] | [Can I Trust the Explanations? Investigating Explainable Machine Learning Methods for Monotonic Models.](http://arxiv.org/abs/2309.13246) | 本研究研究了可解释机器学习方法在单调模型中的应用，发现了解释的可靠性和模型的单调性之间的关系。 |
| [^9] | [UniHead: Unifying Multi-Perception for Detection Heads.](http://arxiv.org/abs/2309.13242) | UniHead是一种创新的检测头，它通过引入变形感知、双轴聚合变换器和跨任务交互变换器，实现了全感知能力的统一。 |
| [^10] | [Heterogeneous Feature Representation for Digital Twin-Oriented Complex Networked Systems.](http://arxiv.org/abs/2309.13229) | 本研究致力于提高数字孪生导向的复杂网络系统中节点特征的表达能力，通过使用异质特征表示原则，并通过实证分析建立了数字孪生导向的复杂网络系统来重现现实物理接触网络，进一步探究其对灾害韧性的影响。 |
| [^11] | [Pick Planning Strategies for Large-Scale Package Manipulation.](http://arxiv.org/abs/2309.13224) | 本文介绍了亚马逊机器人公司的Robot Induction（Robin）舰队中的大规模包裹操纵，通过使用拣选成功预测器以及训练的拣选质量估计方法，在真实生产系统中进行自动化仓储操作。 |
| [^12] | [Hindi to English: Transformer-Based Neural Machine Translation.](http://arxiv.org/abs/2309.13222) | 本文使用Transformer模型开发了一种基于神经网络的印度语Hindi到英文的机器翻译系统，并通过回译和不同的分词方法提升了翻译质量。 |
| [^13] | [Poster: Self-Supervised Quantization-Aware Knowledge Distillation.](http://arxiv.org/abs/2309.13220) | 本文提出了一种名为SQAKD的自监督的量化感知知识蒸馏框架，它可以在不需要标签监督和准确性损失的情况下，显著提高各种最先进的QAT方法的性能。通过统一各种量化函数的动力学，并以自监督的方式进行优化，SQAKD为最先进的QAT研究提供了更强的基线，同时不需要大量标记的训练数据，使其更易于操作。 |
| [^14] | [AI-Copilot for Business Optimisation: A Framework and A Case Study in Production Scheduling.](http://arxiv.org/abs/2309.13218) | 这篇论文提出了一个AI-企业优化的协同辅助系统，通过采用大型语言模型和微调预训练模型的方法，实现了减少人类专业知识需求的目标。 |
| [^15] | [MISFIT-V: Misaligned Image Synthesis and Fusion using Information from Thermal and Visual.](http://arxiv.org/abs/2309.13216) | MISFIT-V 是一个使用来自热视觉和可见光信息的不匹配图像合成和融合的新方法，利用无监督深度学习和交叉注意力机制，提供了对不匹配和恶劣环境条件更强的鲁棒性。 |
| [^16] | [Assessing the Impact of Personality on Affective States from Video Game Communication.](http://arxiv.org/abs/2309.13214) | 本研究探讨了个性对团队合作的虚拟现实游戏玩家的情感表达方式的影响。通过分析两周内11名玩家的聊天记录，我们发现了个性变量与情感表达之间的合理相关性，例如较低的自我能力与增加的困惑之间的关系，以及个人烦恼与内在和外在形象问题的增多之间的关系。 |
| [^17] | [Intent-Aware Autonomous Driving: A Case Study on Highway Merging Scenarios.](http://arxiv.org/abs/2309.13206) | 本文研究了使用意图沟通作为促进自动驾驶车辆合作的方法，并在高速合并情景中研究了意图共享如何帮助接收车辆调整其行为策略。 |
| [^18] | [A Practical Survey on Zero-shot Prompt Design for In-context Learning.](http://arxiv.org/abs/2309.13205) | 本文综述了针对上下文学习的零样本提示设计技术，并探讨了不同类型提示对大型语言模型性能的影响。研究重点讨论了人工设计、优化算法和评价方法等多种提示设计方法，以优化模型在不同任务上的性能。同时，本文强调了考虑多种指标和缺乏单一最佳提示等评估挑战。该研究揭示了提示设计在充分发挥大型语言模型潜力方面的关键作用。 |
| [^19] | [Large Language Models and Control Mechanisms Improve Text Readability of Biomedical Abstracts.](http://arxiv.org/abs/2309.13202) | 本研究使用大型语言模型和控制机制改善了生物医学摘要的文本可读性，具体包括领域微调和基于提示的学习方法，以及应用于编码器-解码器模型和GPT模型的控制令牌机制。 |
| [^20] | [Towards Green AI in Fine-tuning Large Language Models via Adaptive Backpropagation.](http://arxiv.org/abs/2309.13192) | 本文提出了GreenTrainer，一种新的LLM细调技术，通过自适应评估不同张量的反向传播成本和对细调模型准确性的贡献，以实现绿色AI。 |
| [^21] | [Masked Discriminators for Content-Consistent Unpaired Image-to-Image Translation.](http://arxiv.org/abs/2309.13188) | 本论文提出了一种基于遮盖的判别器方法，用于减少无配对图像转换中的内容不一致性。通过在两个域的全局判别器上使用基于内容的遮罩，可以显著降低不一致性。同时，引入了局部判别器和相似性采样策略，以减少由于遮盖过程引起的伪影。 |
| [^22] | [Diagnosing and exploiting the computational demands of videos games for deep reinforcement learning.](http://arxiv.org/abs/2309.13181) | 本研究通过引入学习挑战诊断器(LCD)来分析视频游戏对深度强化学习的计算需求，并在Procgen基准测试中发现新的挑战分类。结果表明，LCD的预测可靠且能指导算法的发展。 |
| [^23] | [AI Risk Profiles: A Standards Proposal for Pre-Deployment AI Risk Disclosures.](http://arxiv.org/abs/2309.13176) | 本文提出了一个AI风险概述的标准，旨在帮助消费者理解与披露相关的AI系统的风险，为下游决策和监管框架提供指导。 |
| [^24] | [Investigating Efficient Deep Learning Architectures For Side-Channel Attacks on AES.](http://arxiv.org/abs/2309.13170) | 本论文研究了在AES侧信道攻击中使用高效深度学习架构的应用，重点在于减少计算资源和数据量的成本，并提出了基于ANSI侧信道攻击数据库的深度学习框架，并研究了Transformer模型的有效性。 |
| [^25] | [Large Language Models Are Also Good Prototypical Commonsense Reasoners.](http://arxiv.org/abs/2309.13165) | 本论文提出了一种解决大型语言模型常识推理任务的方法，通过设计更好的提示，实现了在ProtoQA数据集上的最新最佳结果，最大答案正确率提高了8％，最大错误率降低了4％。 |
| [^26] | [GAMIX-VAE: A VAE with Gaussian Mixture Based Posterior.](http://arxiv.org/abs/2309.13160) | 本文提出了一种基于高斯混合后验的VAE方法，重新定义了ELBO，引入正则化项和PatchGAN鉴别器，能够生成逼真的人脸。 |
| [^27] | [Contextual Emotion Estimation from Image Captions.](http://arxiv.org/abs/2309.13136) | 本文探索使用大型语言模型（LLMs）支持上下文情感估计任务的方法，通过首先对图像进行字幕生成，然后使用LLM进行推理。研究着重于理解LLMs对人类情感的感知能力以及哪些信息能帮助其确定情感。研究还提出了一组自然语言描述符，用于生成字幕和情感注释，以实现情感估计和理解场景中元素对情感的影响。 |
| [^28] | [Insights from an OTTR-centric Ontology Engineering Methodology.](http://arxiv.org/abs/2309.13130) | 本论文介绍了一种以OTTR为核心的本体工程方法，在材料科学领域的实践中取得了重要发现。OTTR语言通过实例化模板来构建本体或知识库，通过隐藏本体表示语言的特定性，使领域专家能够分离决定建模信息和如何建模信息的过程，从而提高了工作效率。 |
| [^29] | [OpportunityFinder: A Framework for Automated Causal Inference.](http://arxiv.org/abs/2309.13103) | OpportunityFinder是一个无需编码的因果推断框架，可以帮助非专业用户进行各种面板数据的因果推断研究，节省科学家和经济学家的带宽，并提供统计和严格的敏感性和稳健性分析。 |
| [^30] | [Lamarck's Revenge: Inheritance of Learned Traits Can Make Robot Evolution Better.](http://arxiv.org/abs/2309.13099) | 本研究使用进化机器人模拟实验探索了18世纪生物学家Lamarck的遗传理论，发现个体通过学习获得的特征可以通过遗传传递给后代，这对进化动力学和遗传学有重要的新见解。 |
| [^31] | [Computational Natural Philosophy: A Thread from Presocratics through Turing to ChatGPT.](http://arxiv.org/abs/2309.13094) | 现代计算自然哲学将宇宙概念化为信息和计算，推动了智能研究的发展，如基于深度神经网络的ChatGPT。这种计算视角结合了多领域知识，并利用强化学习与人类反馈。当前的研究旨在将神经网络与符号计算相结合，引入了新一代的混合计算模型。 |
| [^32] | [MiChao-HuaFen 1.0: A Specialized Pre-trained Corpus Dataset for Domain-specific Large Models.](http://arxiv.org/abs/2309.13079) | MiChao-HuaFen 1.0是一个专为新闻和政府部门定制的面向领域特定大模型的预训练语料数据集，它不仅能够满足特定领域的高质量需求，还有助于推动相关领域的深度学习研究和应用。 |
| [^33] | [LPML: LLM-Prompting Markup Language for Mathematical Reasoning.](http://arxiv.org/abs/2309.13078) | 本论文提出了LPML，一种用于数学推理的LLM提示标记语言。通过将Chain-of-Thought方法和Python REPL与该标记语言结合，我们能够控制LLM生成文本中的错误，并增强其推理能力。我们的方法能够实现利用Python计算纠正错误和解决挑战性数学问题，而只需要零样本提示。 |
| [^34] | [A Differentiable Framework for End-to-End Learning of Hybrid Structured Compression.](http://arxiv.org/abs/2309.13077) | 提出了一个可微分的端到端混合结构压缩学习框架，该框架能够在单一的分析公式中融合滤波器选择、秩选择和预算约束，并通过梯度优化实现端到端学习。实验证明了该框架的有效性，超过了现有的结构化压缩方法。 |
| [^35] | [SCREWS: A Modular Framework for Reasoning with Revisions.](http://arxiv.org/abs/2309.13075) | SCREWS是一个模块化框架，用于推理修订。它能够统一先前的方法并提供新的策略来识别改进的推理链。在多样的推理任务上，使用最先进的LLMs（ChatGPT和GPT-4）评估SCREWS的性能，并发现了有用的新的推理策略。 |
| [^36] | [Weakly Supervised Reasoning by Neuro-Symbolic Approaches.](http://arxiv.org/abs/2309.13072) | 本文介绍了一种基于神经符号方法的弱监督推理框架，该框架将符号主义和连接主义结合起来，成功应用于各种自然语言处理任务，并通过设计具有符号潜在结构的神经系统，并应用强化学习或松弛方法来进行推理。 |
| [^37] | [Tree-Based Reconstructive Partitioning: A Novel Low-Data Level Generation Approach.](http://arxiv.org/abs/2309.13071) | 基于树的重建分区（TRP）是一种新颖的PCGML方法，能够在游戏开发的早期阶段引入，无需人类专业知识或大量训练数据。 |
| [^38] | [InvestLM: A Large Language Model for Investment using Financial Domain Instruction Tuning.](http://arxiv.org/abs/2309.13064) | InvestLM是一个通过对金融领域指导数据集进行调优的大型语言模型，具有强大的理解金融文本的能力，并在投资相关问题上提供有帮助的回答。金融专家评价其与最先进的商业模型可媲美，并在金融NLP基准问题上展现了强大的泛化能力。 |
| [^39] | [Using Large Language Models to Generate, Validate, and Apply User Intent Taxonomies.](http://arxiv.org/abs/2309.13063) | 通过使用大型语言模型生成用户意图分类，我们提出了一种新方法来分析和验证日志数据中的用户意图，从而解决了手动或基于机器学习的标注方法在大型和不断变化的数据集上的问题。 |
| [^40] | [Implementing Learning Principles with a Personal AI Tutor: A Case Study.](http://arxiv.org/abs/2309.13060) | 本研究通过将AI导师与学习计划相结合，实施了个性化、检索练习和间隔重复等学习原理，研究结果显示，积极使用AI导师参与学习的学生获得了显著更高的成绩。 |
| [^41] | [Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education.](http://arxiv.org/abs/2309.13059) | 大型语言模型和聊天机器人在研究生工程教育中有着巨大的潜力，研究发现它们能够准确回答复杂问题，并在课堂上带来潜在的优势。 |
| [^42] | [Originality and the Future of Copyright in an Age of Generative AI.](http://arxiv.org/abs/2309.13055) | 生成式人工智能工具创作的作品引发了关于人类创作权的问题。 |
| [^43] | [Data Commons.](http://arxiv.org/abs/2309.13054) | 数据共享平台旨在帮助用户轻松访问和利用公共数据，并解决数据整理的耗时和繁琐问题，使不同数据源的数据可以方便地合并和交互使用。 |
| [^44] | [Using Curriculum Theory to Inform Approaches to Generative AI in Schools.](http://arxiv.org/abs/2309.13053) | 本文通过使用课程理论，探讨了中学教育中生成式人工智能所需的紧迫课程改革，并分析了将新兴技术融入课程结构所面临的挑战和困境。最后，研究人员提供了一些关于时间表、教材编写和教学方法的建议。 |
| [^45] | [A Contextual Topic Modeling and Content Analysis of Iranian laws and Regulations.](http://arxiv.org/abs/2309.13051) | 本研究通过主题建模方法分析了伊朗法律，从中识别出了包括经济、海关、住房与城市发展、农业、保险、法律和司法、文化、信息技术、政治和政府在内的10个主题，并发现经济是规定中最重要的主题。 |
| [^46] | [AI-Driven Personalised Offloading Device Prescriptions: A Cutting-Edge Approach to Preventing Diabetes-Related Plantar Forefoot Ulcers and Complications.](http://arxiv.org/abs/2309.13049) | 基于人工智能的个性化减重装置处方是一个先进解决方案，通过识别高风险区域和推荐精确的减重策略，有效预防糖尿病相关前足溃疡和并发症。 |
| [^47] | [What is the Title of this Paper? Solving logic puzzles using algorithms.](http://arxiv.org/abs/2309.13044) | 本文研究使用Python算法自动解决了骑士与诡计逻辑谜题，提供了一种高效和易于使用的计算方法，通过解析陈述并进行逻辑推理来推断角色的真实身份。 |
| [^48] | [Creativity Support in the Age of Large Language Models: An Empirical Study Involving Emerging Writers.](http://arxiv.org/abs/2309.12570) | 本文通过实证研究探讨了大型语言模型（LLM）在协助专业作家方面的效用，并发现作家们更倾向于在翻译和审查阶段中寻求LLM的帮助。 |
| [^49] | [ForceSight: Text-Guided Mobile Manipulation with Visual-Force Goals.](http://arxiv.org/abs/2309.12312) | ForceSight是一个使用文本引导的移动操作系统，通过深度神经网络预测视觉力导向目标。在实验中，该系统展示了在未见环境中进行精确抓取、抽屉打开和物体交接等任务的能力，并取得了较高的成功率。 |
| [^50] | [Learning to Drive Anywhere.](http://arxiv.org/abs/2309.12295) | 本文提出了一种能够学习适应不同地理位置和驾驶行为的模型，该模型通过引入基于地理位置的通道注意机制，在数据驱动的方式下高效地学习并灵活地建模不同地区之间的相似性和差异性。 |
| [^51] | [The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A".](http://arxiv.org/abs/2309.12288) | LLMs模型在训练中只能学习到"A是B"的结构，无法自动推广到"B是A"。这表明模型在逻辑推断上存在基本失败和训练集中模式的推广问题。 |
| [^52] | [OSNet & MNetO: Two Types of General Reconstruction Architectures for Linear Computed Tomography in Multi-Scenarios.](http://arxiv.org/abs/2309.11858) | 本论文提出了两种通用的线性计算机断层扫描的重建架构（OSNet和MNetO），旨在解决在LCT中实现稳定内部重建和避免希尔伯特滤波旋转操作的问题。 |
| [^53] | [Chain-of-Verification Reduces Hallucination in Large Language Models.](http://arxiv.org/abs/2309.11495) | 该论文提出了一种链式验证方法（CoVe），通过在回答之前进行备查问题来减少大型语言模型中的幻觉。实验证明CoVe方法在各种任务中都能有效降低幻觉的发生。 |
| [^54] | [Using deep learning to construct stochastic local search SAT solvers with performance bounds.](http://arxiv.org/abs/2309.11452) | 本论文利用深度学习方法构建了一种随机局部搜索SAT求解器，并且使用图神经网络训练了求解SAT问题的“神谕”。实验结果表明，访问基于GNN的神谕显著提高了求解器的性能。 |
| [^55] | [Gold-YOLO: Efficient Object Detector via Gather-and-Distribute Mechanism.](http://arxiv.org/abs/2309.11331) | 本研究提出了Gold-YOLO模型，通过先进的收集和分发机制（GD）机制以及MAE风格的预训练，解决了YOLO系列模型中的信息融合问题，实现了高效的目标检测和多尺度特征融合。 |
| [^56] | [AI-Driven Patient Monitoring with Multi-Agent Deep Reinforcement Learning.](http://arxiv.org/abs/2309.10980) | 本研究提出了一种基于多智能体深度强化学习的AI驱动患者监测框架，通过部署多个学习智能体，针对不同的生理特征进行监测，并根据紧急程度预警医疗紧急团队。 |
| [^57] | [Geometric structure of Deep Learning networks and construction of global ${\mathcal L}^2$ minimizers.](http://arxiv.org/abs/2309.10639) | 本文提供了深度学习网络结构的几何解释，并且构建了全局最小化器族，该族能够全局最小化成本函数。此外，还确定了各种退化局部最小值。 |
| [^58] | [FRAMU: Attention-based Machine Unlearning using Federated Reinforcement Learning.](http://arxiv.org/abs/2309.10283) | FRAMU是一种基于注意力和联邦强化学习的机器遗忘框架，通过自适应学习机制、隐私保护技术和优化策略，处理各种数据源并保持准确性和隐私，适应波动的数据环境，支持持续模型演进。 |
| [^59] | [Multi-level feature fusion network combining attention mechanisms for polyp segmentation.](http://arxiv.org/abs/2309.10219) | 提出了一种名为 MLFF-Net 的多层次特征融合网络，结合注意力机制实现了对息肉分割的改进。对编码器提取的特征进行了滤波和利用，并解决了特征融合引起的语义冲突和信息冗余问题。 |
| [^60] | [Applying Deep Learning to Calibrate Stochastic Volatility Models.](http://arxiv.org/abs/2309.07843) | 本研究将深度学习技术应用于校准随机波动性模型，通过训练神经网络对基于Heston模型的标的资产进行定价，并且在校准方面取得了快速和准确的结果。 |
| [^61] | [Learning Environment-Aware Affordance for 3D Articulated Object Manipulation under Occlusions.](http://arxiv.org/abs/2309.07510) | 本论文提出了一个环境感知的可供性框架，考虑了物体级的可行性先验和环境约束，以解决多个遮挡的复杂情况下的三维关节物体操作问题。 |
| [^62] | [JSMNet Improving Indoor Point Cloud Semantic and Instance Segmentation through Self-Attention and Multiscale.](http://arxiv.org/abs/2309.07425) | JSMNet通过自注意力机制和多尺度改进室内点云语义和实例分割。在室内3D点云数据中，JSMNet通过全局特征自注意力模块和多分辨率特征自适应融合模块，实现了更好的室内目标特征表达和语义、实例分割结果，具有较高的质量和准确性。 |
| [^63] | [LEyes: A Lightweight Framework for Deep Learning-Based Eye Tracking using Synthetic Eye Images.](http://arxiv.org/abs/2309.06129) | 本研究提出了一种名为LEyes的轻量级深度学习眼动跟踪框架，利用合成眼部图像进行训练，解决了由于训练数据集不足和眼部图像变异导致的模型泛化问题。实验结果表明，LEyes训练的模型在瞳孔和CR定位方面优于其他算法。 |
| [^64] | [SayNav: Grounding Large Language Models for Dynamic Planning to Navigation in New Environments.](http://arxiv.org/abs/2309.04077) | SayNav是一种使用大型语言模型进行动态规划导航的方法，通过使用人类知识和场景图实现对复杂导航任务的高效泛化，动态生成指令并根据新信息不断完善未来步骤。 |
| [^65] | [Algebraic Models for Qualified Aggregation in General Rough Sets, and Reasoning Bias Discovery.](http://arxiv.org/abs/2309.03217) | 本研究提出了一种泛粗糙集中合格聚合的代数模型，用于模拟人类推理中的悲观和乐观的合并，以及研究推理中的歧视/有害行为和机器学习算法。 |
| [^66] | [Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models.](http://arxiv.org/abs/2309.01219) | 本文调查了大型语言模型中幻觉的检测、解释和缓解的最新研究，提出了幻觉现象和评估基准的分类，并讨论了未来研究的潜在方向。 |
| [^67] | [CPSP: Learning Speech Concepts From Phoneme Supervision.](http://arxiv.org/abs/2309.00424) | 论文提出了一种名为CPSP的方法，通过对比学习来从语音中提取细粒度的中间表示，使得提取的信息既包含语言内容又去除了发言人身份和声学细节，适用于TTS、VC和ASR等任务。 |
| [^68] | [Algebraic, Topological, and Mereological Foundations of Existential Granules.](http://arxiv.org/abs/2308.16157) | 本研究从代数、拓扑和细部学的角度创造了新的存在性颗粒概念，并刻画了其特征。这些颗粒首先确定自己，然后与环境互动，并且适用于多种颗粒计算理论框架。研究结果对算法开发、分类问题应用和方法推广的数学基础具有重要意义。 |
| [^69] | [Multi-plane denoising diffusion-based dimensionality expansion for 2D-to-3D reconstruction of microstructures with harmonized sampling.](http://arxiv.org/abs/2308.14035) | 本论文提出一种名为Micro3Diff的框架，通过扩散生成模型实现了二维到三维微结构的重建，其中采用了多平面去噪扩散的概念。 |
| [^70] | [Functional Graph Contrastive Learning of Hyperscanning EEG Reveals Emotional Contagion Evoked by Stereotype-Based Stressors.](http://arxiv.org/abs/2308.13546) | 本研究通过利用超扫描技术，引入功能性图对比学习方法探究基于刻板印象的压力引发的情绪传染。研究结果揭示了情绪传染与认知功能之间的复杂相互作用。 |
| [^71] | [How Much Temporal Long-Term Context is Needed for Action Segmentation?.](http://arxiv.org/abs/2308.11358) | 本文提出了一种基于transformer的模型，利用稀疏注意力捕捉视频的完整上下文，以回答时间行动分割需要多少长期时间上下文。通过与当前最先进的方法进行比较，在三个时间行动分割数据集上取得了良好的性能。 |
| [^72] | [Digital Twin-Oriented Complex Networked Systems based on Heterogeneous node features and interaction rules.](http://arxiv.org/abs/2308.11034) | 本研究提出了一种面向数字孪生的复杂网络系统的可扩展建模框架，重点关注节点特征和交互规则。通过实验研究了网络增长和疫情传播的不同级别的复杂性对系统的影响，结果表明需要在DT-CNS中平衡这些复杂性水平。 |
| [^73] | [GNNPipe: Scaling Deep GNN Training with Pipelined Model Parallelism.](http://arxiv.org/abs/2308.10087) | GNNPipe是一种扩展分布式全图深度GNN训练的方法，使用层级模型并行性将GNN层划分在不同的GPU上，通过减少通信量和处理特定挑战，实现了更好的计算资源利用和模型收敛性的保证。 |
| [^74] | [AI Hilbert: A New Paradigm for Scientific Discovery by Unifying Data and Background Knowledge.](http://arxiv.org/abs/2308.09474) | AI Hilbert提出了一种整合数据与背景知识的科学发现新范式，通过将回归和推理相结合，解决了在搜索与背景理论一致的公式空间中找到最符合数据的公式的问题。 |
| [^75] | [Case Study: Using AI-Assisted Code Generation In Mobile Teams.](http://arxiv.org/abs/2308.04736) | 本研究通过案例研究评估了在专注于移动开发的团队中使用AI辅助代码生成的性能。通过对参与者进行技术入职和技术堆栈切换阶段的问题求解，评估了使用和不使用AI-Code生成器的影响。研究结合了时间、正确性和技术集成等度量指标，并分析了参与者的反馈，以确定使用AI辅助编程工具是否对开发人员产生影响。 |
| [^76] | [Establishing Trust in ChatGPT BioMedical Generated Text: An Ontology-Based Knowledge Graph to Validate Disease-Symptom Links.](http://arxiv.org/abs/2308.03929) | 本研究通过构建基于本体的知识图谱，利用疾病本体和症状本体构建数学模型，利用事实核查算法和网络中心度指标分析ChatGPT生成的文本与真实医学文献之间的准确性，以验证疾病-症状关系。 |
| [^77] | [Exploiting Generalization in Offline Reinforcement Learning via Unseen State Augmentations.](http://arxiv.org/abs/2308.03882) | 本文提出了一种利用未见状态增强的策略，在离线强化学习中通过基于价值的扰动和过滤，实现了对离线数据之外的状态的利用和泛化。 |
| [^78] | [Exploring ChatGPT's Empathic Abilities.](http://arxiv.org/abs/2308.03527) | 这项研究探索了基于GPT-3.5的ChatGPT在展现共情回应和情感表达方面的能力。研究结果表明，在91.7%的情况下，ChatGPT能够准确识别情感并产生适当的回答。 |
| [^79] | [Relation-Oriented: Toward Knowledge-Aligned Causal AI.](http://arxiv.org/abs/2307.16387) | 本研究从创新的关系导向视角出发，探讨了当前的建模范式中的观察模型与实际理解的不对齐问题，并提出了关系定义的表示学习方法作为实现关系导向建模的实践方法。 |
| [^80] | [Enhancing Human-like Multi-Modal Reasoning: A New Challenging Dataset and Comprehensive Framework.](http://arxiv.org/abs/2307.12626) | 提出了COCO-MMR数据集，该数据集是一个包含了大量开放性问题、理由和答案的新颖数据集，通过全面的评估和详细的分析，提供了一些向多模态推理领域贡献的创新和理论基础。 |
| [^81] | [Anticipating Driving Behavior through Deep Learning-Based Policy Prediction.](http://arxiv.org/abs/2307.11058) | 通过处理视频帧和深度细节，我们开发了一个综合系统来预测驾驶行为，实现了显著的准确性，比单独使用视频帧更好。 |
| [^82] | [AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity using Contrastive Learning and Structured Knowledge.](http://arxiv.org/abs/2307.07851) | AspectCSE是一种使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入方法，它在信息检索任务中相比之前的最好结果平均提高了3.97%，通过同时考虑多个特定方面的嵌入模型优于单方面嵌入。 |
| [^83] | [Named entity recognition using GPT for identifying comparable companies.](http://arxiv.org/abs/2307.07420) | 本文使用GPT以识别可比公司。传统的可比公司方法通常使用定性方法来识别相似的同行公司，而我们使用大型语言模型通过提取公司描述/摘要从而进行相似性分析，实现更量化的方法。 |
| [^84] | [Efficient Domain Adaptation of Sentence Embeddings using Adapters.](http://arxiv.org/abs/2307.03104) | 本论文提出了一种通过训练轻量级适配器来高效域自适应句子嵌入的方法，避免了微调整个句子嵌入模型的资源消耗。通过训练特定领域的适配器，可以在不同领域中使用同一模型获得良好的性能。 |
| [^85] | [Learning to Communicate using Contrastive Learning.](http://arxiv.org/abs/2307.01403) | 本研究提出了一种使用对比学习进行通信的方法，在分散的环境中通过最大化反映发送和接收消息关系的互信息来学习通信。在通信关键的环境中，我们的方法在性能和学习速度方面优于先前的工作，并且能够捕获全局状态信息，实现了更对称的通信。 |
| [^86] | [Modularizing while Training: a New Paradigm for Modularizing DNN Models.](http://arxiv.org/abs/2306.09376) | 本文提出了一种新方法，将模块化纳入模型训练过程中，即在训练时模块化(MwT)，通过两个损失函数实现模型结构上的模块化，进而实现模块的重用，能够在较短的训练时间内达到可比较的模型精度，并且相对于最先进的训练后模块化方法需要更少的参数。 |
| [^87] | [Human Preference Score v2: A Solid Benchmark for Evaluating Human Preferences of Text-to-Image Synthesis.](http://arxiv.org/abs/2306.09341) | 该论文提出了一个可以准确评估文本到图像合成中生成图像质量的可靠基准——人类偏好分数v2。通过引入人类偏好数据集v2（HPD v2）和微调CLIP，研究者们成功获得了更能预测人类偏好的评分模型HPS v2，其在各种图像分布中具有更好的泛化能力，并对文本到图像生成模型的算法改进具有响应性。 |
| [^88] | [How to estimate carbon footprint when training deep learning models? A guide and review.](http://arxiv.org/abs/2306.08323) | 这篇论文提出了一份详尽的指南和综述，介绍了如何估计训练深度学习模型的碳足迹，并比较了多种在线和软件工具的能源消耗估计结果。研究为AI从业人员在选择合适的工具和基础设施方面提供了建议。 |
| [^89] | [Efficient Quantization-aware Training with Adaptive Coreset Selection.](http://arxiv.org/abs/2306.07215) | 本研究提出了一种用于改善量化感知训练的训练效率的方法，通过核心集选择和两个重要性指标来选择训练数据的子集。 |
| [^90] | [Adversarial Attacks and Defenses in Explainable Artificial Intelligence: A Survey.](http://arxiv.org/abs/2306.06123) | 本文总结了对抗性攻击和防御在可解释人工智能中的研究。列出了现有的不安全因素，并表明了本领域的新兴研究方向。 |
| [^91] | [FedMLSecurity: A Benchmark for Attacks and Defenses in Federated Learning and LLMs.](http://arxiv.org/abs/2306.04959) | 本文介绍了一个名为FedMLSecurity的基准测试，它可以模拟在联邦学习中可能出现的对抗攻击并提供相应的防御策略。该测试对各种机器学习模型和联合优化器都可以适用，并且能够轻松应用于大规模语言模型中。 |
| [^92] | [PDT: Pretrained Dual Transformers for Time-aware Bipartite Graphs.](http://arxiv.org/abs/2306.01913) | 该论文提出了一种预训练模型，用于学习二分图中用户和内容之间的上下文知识，并采用对比学习任务以提高性能。 |
| [^93] | [Dilated Convolution with Learnable Spacings: beyond bilinear interpolation.](http://arxiv.org/abs/2306.00817) | 可学习空间可伸展卷积（DCLS）通过使用可学习的间距和插值技巧，超越了双线性插值，在不增加参数的情况下提高了最先进卷积结构在ImageNet1k分类上的性能。 |
| [^94] | [GenQ: Automated Question Generation to Support Caregivers While Reading Stories with Children.](http://arxiv.org/abs/2305.16809) | 本研究设计了一个智能辅导系统（GenQ），可以根据照顾者和孩子之间的对话促进孩子的阅读理解能力，并通过考虑文化背景和语境变化以提高系统效果。 |
| [^95] | [KeyPosS: Plug-and-Play Facial Landmark Detection through GPS-Inspired True-Range Multilateration.](http://arxiv.org/abs/2305.16437) | KeyPosS是一种面部标记检测框架，采用真实距离多边定位算法实现快速而准确的检测，避免了传统方法中的计算负担和量化误差问题。 |
| [^96] | [The Benefits of Being Distributional: Small-Loss Bounds for Reinforcement Learning.](http://arxiv.org/abs/2305.15703) | 通过小损失边界的视角，我们提供了分布式RL好处的一个解释，该边界与实例相关的最优成本成比例。如果最优成本很小，分布式方法优于非分布式方法。 |
| [^97] | [Model evaluation for extreme risks.](http://arxiv.org/abs/2305.15324) | 当前建立通用人工智能系统的方法可能会产生既有益处又有害处的系统，而进一步发展人工智能可能导致极端风险，需要通过模型评估来解决这个问题。 |
| [^98] | [Learning to Rank the Importance of Nodes in Road Networks Based on Multi-Graph Fusion.](http://arxiv.org/abs/2305.14375) | 本文提出了一种新的基于图学习的节点排序方法（MGL2Rank），充分利用了道路网络的丰富特征，并且在实验中表现出比现有方法更高的精度和效率。 |
| [^99] | [Training Transitive and Commutative Multimodal Transformers with LoReTTa.](http://arxiv.org/abs/2305.14243) | LoReTTa是一个自监督框架，可以在具有不同模态的数据集中转换。通过合成数据集的方法，显著提高了下游任务的性能。 |
| [^100] | [On the Statistical Efficiency of Mean Field Reinforcement Learning with General Function Approximation.](http://arxiv.org/abs/2305.11283) | 本文研究了一般函数逼近下的均场控制(MFC)和均场博弈(MFG)中的强化学习的统计效率，提出了基于乐观最大似然估计的算法，并仅对转移动力学具有Lipschitz连续性的假设，最后建立了一个指数级的下界支持MFC设置。 |
| [^101] | [A Generalist Dynamics Model for Control.](http://arxiv.org/abs/2305.10912) | 本文研究使用Transformer序列模型作为控制的动力学模型(TDMs)，证明TDMs表现良好且具有强大的泛化能力，相比于直接作为策略通用最优行为，泛化系统动力学可以更好地工作。 |
| [^102] | [MM-Fi: Multi-Modal Non-Intrusive 4D Human Dataset for Versatile Wireless Sensing.](http://arxiv.org/abs/2305.10345) | 提出了第一个多模态非侵入式的4D人体数据集MM-Fi，用于多种无线传感任务的支持。该数据集包含40名受试者的超过320K同步帧的五种模态，支持人体姿态估计和动作识别等任务的开展。 |
| [^103] | [Exploring the Landscape of Machine Unlearning: A Survey and Taxonomy.](http://arxiv.org/abs/2305.06360) | 本文综述了机器遗忘的现状和技术应用，包括数据删除、扰动和模型更新，讨论了MU在隐私、安全和公正性等领域的潜在益处，以及它在自然语言处理、计算机视觉和推荐系统中的未来发展方向。 |
| [^104] | [Seeing is not always believing: A Quantitative Study on Human Perception of AI-Generated Images.](http://arxiv.org/abs/2304.13023) | 本研究揭示了人类无法辨别AI生成的假照片和真实照片，这一点受个人背景的影响并不显著。 |
| [^105] | [Benchmarking Low-Shot Robustness to Natural Distribution Shifts.](http://arxiv.org/abs/2304.11263) | 本文通过对不同少样本数据集、架构、预训练初始化和稳健性干预的自然分布漂移的稳健性进行了首次深入研究，发现没有单一的选择模型比其他模型更稳健，现有的干预措施也可能无法提高某些数据集的稳健性。 |
| [^106] | [Sampling-based Reactive Synthesis for Nondeterministic Hybrid Systems.](http://arxiv.org/abs/2304.06876) | 本文提出了一种基于采样的策略综合算法，用于具有复杂连续动力学和时间和可达性约束的非确定性混合系统。算法基于在混合空间中生长（搜索）游戏树，以合成一种反应（鲁棒）策略，以满足目标并在可扩展性和效率方面优于最新技术水平。 |
| [^107] | [Controllable Textual Inversion for Personalized Text-to-Image Generation.](http://arxiv.org/abs/2304.05265) | 本文提出了一种名为COTI的技术，通过引入理论指导的损失目标和全面的加权评分机制，并结合主动学习范式来解决文本反转时的困难，提供了一个强大，数据效率高，易于使用的框架。 |
| [^108] | [Deep Reinforcement Learning-Based Mapless Crowd Navigation with Perceived Risk of the Moving Crowd for Mobile Robots.](http://arxiv.org/abs/2304.03593) | 本论文提出了一种基于碰撞概率的无图Crowd Navigation方法，使用深度强化学习(DRL)来感知人群的危险程度，确保机器人在通过拥挤环境时的安全，同时提高模型的可扩展性。 |
| [^109] | [Language-Guided Audio-Visual Source Separation via Trimodal Consistency.](http://arxiv.org/abs/2303.16342) | 该论文提出了一种自监督学习的方法，通过使用自然语言查询来进行音频源分离，实现了语言、视觉和音频的一致性对齐，并在多个数据集上表现出比现有方法更好的效果。 |
| [^110] | [Understanding and Exploring the Whole Set of Good Sparse Generalized Additive Models.](http://arxiv.org/abs/2303.16047) | 提出一种有效而准确地近似稀疏广义可加模型（GAMs）的Rashomon集的技术，并使用这些近似模型来解决实际应用的挑战。 |
| [^111] | [Large AI Models in Health Informatics: Applications, Challenges, and the Future.](http://arxiv.org/abs/2303.11568) | 大型AI模型在健康信息学领域具有突破性应用，但其规模和数据量的挑战需要克服，未来仍需深入探索。 |
| [^112] | [Unsupervised Interpretable Basis Extraction for Concept-Based Visual Explanations.](http://arxiv.org/abs/2303.10523) | 本文提出了一种无监督的方法，通过对CNN进行转换，从而更好地解释中间层的表示，提取了一个可解释性欠完备基础，并证明该方法在各种网络结构和训练数据集上都很有效。 |
| [^113] | [Merging Decision Transformers: Weight Averaging for Forming Multi-Task Policies.](http://arxiv.org/abs/2303.07551) | 本文提出通过在权重空间中合并训练于不同 MuJoCo 运动问题上的 Decision Transformer 的子集，形成多任务模型。通过共享一些辅助任务的训练以及共同使用预训练初始化，能够获得更好的结果。这个方向的研究有助于使代理的过程民主化和分发。 |
| [^114] | [GOATS: Goal Sampling Adaptation for Scooping with Curriculum Reinforcement Learning.](http://arxiv.org/abs/2303.05193) | 本文提出了一种名为GOATS的方法，使用目标采样自适应课程强化学习技术，通过插值位置目标和数量目标的分布创建学习过程中的课程来解决机器人舀取任务中的位置目标和水量目标问题，取得了比基线更好的表现。 |
| [^115] | [Travel Demand Forecasting: A Fair AI Approach.](http://arxiv.org/abs/2303.01692) | 本研究提出了一种新的方法来开发具有公平意识的、高度准确的旅行需求预测模型，该方法可以同时提高AI模型对于多个受保护属性的公平性。 |
| [^116] | [Targeted demand response for flexible energy communities using clustering techniques.](http://arxiv.org/abs/2303.00186) | 本研究探讨了使用机器学习算法中的聚类技术设计并执行需求响应（DR）计划的可行性，目的是改变分布式能源社区内供应者的消费行为，以最小化反向功率流和削减系统范围内的功峰需求。 |
| [^117] | [Permutation Equivariant Neural Functionals.](http://arxiv.org/abs/2302.14040) | 本文介绍了置换等变神经功能网络的设计，通过对权重进行置换对称性编码，实现对其他网络权重或梯度进行处理，为学习优化、处理隐式神经表示等应用提供了架构原则。 |
| [^118] | [A comparative assessment of deep learning models for day-ahead load forecasting: Investigating key accuracy drivers.](http://arxiv.org/abs/2302.12168) | 本文通过比较评估深度学习模型在提前一天负荷预测中的准确性，重点研究了葡萄牙国家净聚合STLF，并分析了多层感知机（MLP）、长短期记忆网络（LSTM）、神经基础扩展系数分析（N-BEATS）、时间卷积网络（TCN）和时间融合变压器（TFT）等多个模型的影响因素。 |
| [^119] | [One Fits All:Power General Time Series Analysis by Pretrained LM.](http://arxiv.org/abs/2302.11939) | 本论文提出了一种称为 Frozen Pretrained Transformer (FPT) 的预训练模型，利用从数十亿标记训练出来的语言或 CV 模型进行时间序列分析的所有主要类型任务的微调，进而使其在所有任务中都具备着最先进的性能和泛化能力。 |
| [^120] | [SAT Requires Exhaustive Search.](http://arxiv.org/abs/2302.09512) | 本文证明了对于一些具有大域和长子句的极难例子，要求进行彻底搜索才能解决，这意味着P $\neq$ NP。 |
| [^121] | [Off-the-Grid MARL: Datasets with Baselines for Offline Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2302.00521) | 这项工作填补了离线多智能体增强学习（MARL）领域的一个空白，提供了Off-the-Grid MARL（OG-MARL）数据集和基准，帮助社区衡量进展。 |
| [^122] | [Salesforce CausalAI Library: A Fast and Scalable Framework for Causal Analysis of Time Series and Tabular Data.](http://arxiv.org/abs/2301.10859) | Salesforce CausalAI库是一个快速可扩展的框架，用于进行时间序列和表格数据的因果分析。它支持离散、连续和异质类型的数据，提供了处理线性和非线性因果关系的算法，并包括一个用于生成具有指定结构方程模型的合成数据的数据生成器。用户可以通过用户界面进行因果分析，无需编程。 |
| [^123] | [A Unified Architecture for Dynamic Role Allocation and Collaborative Task Planning in Mixed Human-Robot Teams.](http://arxiv.org/abs/2301.08038) | 本文提出了一种用于混合人机团队中动态角色分配和协同任务规划的统一体系结构，通过基于行为树的反应式规划方法和混合整数线性规划解决不同方面的协作问题。 |
| [^124] | [Leveraging Large Language Models to Power Chatbots for Collecting User Self-Reported Data.](http://arxiv.org/abs/2301.05843) | 本研究通过探索设计提示的因素，研究了如何利用大型语言模型构建聊天机器人来进行自然对话和可靠地收集用户自我报告数据。结果显示，提示的设计和对话主题明显影响了对话流程和数据收集性能。 |
| [^125] | [A Robust Multilabel Method Integrating Rule-based Transparent Model, Soft Label Correlation Learning and Label Noise Resistance.](http://arxiv.org/abs/2301.03283) | 本论文提出了一种融合基于规则的透明模型、软标签相关性学习和标签噪声抗性的鲁棒多标记方法（R-MLTSK-FS）。实验证明了该方法在多标记学习中的优越性能。 |
| [^126] | [StitchNet: Composing Neural Networks from Pre-Trained Fragments.](http://arxiv.org/abs/2301.01947) | StitchNet提出了一种新的神经网络创建方式，它通过组合预训练神经网络的片段来创建高性能的网络，无需传统训练的大量计算资源和数据要求。通过居中核对齐（CKA），可以有效指导片段的选择，以满足特定准确性需求和计算资源限制。此外，StitchNet还可以实现即时个性化模型创建和推断。 |
| [^127] | [Goal-Guided Transformer-Enabled Reinforcement Learning for Efficient Autonomous Navigation.](http://arxiv.org/abs/2301.00362) | 该论文提出了一种利用目标引导变压器增强学习的方法，通过将目标信息与场景表示耦合，实现高效自主导航。通过使用专家先验进行预训练，提高了数据效率。 |
| [^128] | [Robust and Explainable Identification of Logical Fallacies in Natural Language Arguments.](http://arxiv.org/abs/2212.07425) | 本论文提出了一个鲁棒且可解释的方法来识别自然语言论证中的逻辑谬误。通过三阶段的评估框架和不同的推理方法，结合语言模型和背景知识，有效处理了大量数据和数据稀疏性的问题。 |
| [^129] | [3DHumanGAN: 3D-Aware Human Image Generation with 3D Pose Mapping.](http://arxiv.org/abs/2212.07378) | 3DHumanGAN 是一个能够生成具有一致外观的全身人体照片的生成对抗网络，通过引入3D姿势映射网络，它能够合成具有不同视角和姿势的图像，并结合3D人体先验实现姿态条件化。 |
| [^130] | [PASTA: Proportional Amplitude Spectrum Training Augmentation for Syn-to-Real Domain Generalization.](http://arxiv.org/abs/2212.00979) | 本文提出了一种基于比例幅度谱训练增强的方法 PASTA，可有效提高合成数据到真实数据的泛化性能，在多个 Syn-to-Real 任务上均具有优越性能。 |
| [^131] | [Where Am I Now? Dynamically Finding Optimal Sensor States to Minimize Localization Uncertainty for a Perception-Denied Rover.](http://arxiv.org/abs/2211.16721) | DyFOS是一种动态感知方法，通过优化搜索来寻找最佳传感器状态，以最小化感知受限漫游器的定位不确定性，同时避免障碍和遮挡。 |
| [^132] | [SnCQA: A hardware-efficient equivariant quantum convolutional circuit architecture.](http://arxiv.org/abs/2211.12711) | SnCQA是一种硬件高效的等变量子卷积电路架构，通过利用排列对称性和空间晶格对称性，适用于解决存在排列对称性的机器学习问题，具有更高的可扩展性、准确性和噪声韧性。 |
| [^133] | [REPAIR: REnormalizing Permuted Activations for Interpolation Repair.](http://arxiv.org/abs/2211.08403) | 作者发现仅使用神经元对齐方法不能有效解决线性插值中激活方差坍缩的问题，因此提出了REPAIR方法来修复插值的归一化置换激活。实验证明，在各种架构中将REPAIR与神经元对齐方法结合使用可以大幅降低障碍。 |
| [^134] | [Overlapping Community Detection using Dynamic Dilated Aggregation in Deep Residual GCN.](http://arxiv.org/abs/2210.11174) | 本论文提出了一种使用动态扩张聚合的深度残差GCN方法进行重叠社区检测。通过设计深度动态残差图卷积网络和统一的编码器-解码器框架，实现了在不规则图上进行社区检测。实验结果表明，该方法在不同数据集上取得了较好的效果。 |
| [^135] | [A Generalist Framework for Panoptic Segmentation of Images and Videos.](http://arxiv.org/abs/2210.06366) | 这个论文提出了一个通用框架，用于图像和视频的全景分割。他们将全景分割问题定义为离散数据生成问题，并提出了一个简单的扩散模型来建模全景掩码。他们的方法能够在流式设置中建模视频，并自动学习跟踪对象实例，并在实验中展现出与最先进的专家方法竞争的能力。 |
| [^136] | [DenseShift: Towards Accurate and Efficient Low-Bit Power-of-Two Quantization.](http://arxiv.org/abs/2208.09708) | DenseShift网络是一种准确和高效的低位幂乘法量化方法，通过改进Shift网络的精度和引入非量化浮点激活来提高性能。 |
| [^137] | [Reduced Implication-bias Logic Loss for Neuro-Symbolic Learning.](http://arxiv.org/abs/2208.06838) | 本文提出了一种减少蕴含偏差逻辑损失（RILL）的方法，用于解决在神经符号学习中由于从模糊逻辑算子中派生的损失函数带来的偏差问题。实证研究表明，RILL相比有偏差的逻辑损失函数在知识库不完整和标记数据不足时具有显著的改进和更强的稳健性。 |
| [^138] | [From Understanding Genetic Drift to a Smart-Restart Mechanism for Estimation-of-Distribution Algorithms.](http://arxiv.org/abs/2206.09090) | 这篇论文介绍了一种基于智能重启机制的分布估计算法，该算法可以在基因漂变风险高的情况下停止运行，并寻找良好的参数范围以运行EDA，从而提高性能。 |
| [^139] | [Leveraging Queue Length and Attention Mechanisms for Enhanced Traffic Signal Control Optimization.](http://arxiv.org/abs/2201.00006) | 这篇论文提出了一种利用队列长度和注意力机制的交通信号控制优化方法。作者提出了Max Queue-Length (M-QL)和AttentionLight两种新方法，实验结果表明M-QL方法优于现有的强化学习方法，并且AttentionLight方法适用于各种交通场景并具有更好的性能表现。 |
| [^140] | [Optimising Rolling Stock Planning including Maintenance with Constraint Programming and Quantum Annealing.](http://arxiv.org/abs/2109.07212) | 本文比较了约束编程和量子退火方法在优化机车编组分配与维护任务中的应用，并发现两种方法在当前发展阶段的量子退火机器上产生相当的结果。 |
| [^141] | [Decision-making for Autonomous Vehicles on Highway: Deep Reinforcement Learning with Continuous Action Horizon.](http://arxiv.org/abs/2008.11852) | 本文提出了一种基于深度强化学习的决策策略，用于自主车辆在高速公路上的连续视角决策问题。该方法通过引入近端策略优化的算法，实现了高学习效率和优秀的控制性能。该策略从多个角度进行评估，并展示了在类似驾驶场景中的在线应用潜力。 |

# 详细

[^1]: 教育中的深度学习方法实现的课堂考勤系统

    Class Attendance System in Education with Deep Learning Method. (arXiv:2309.13317v1 [cs.CV])

    [http://arxiv.org/abs/2309.13317](http://arxiv.org/abs/2309.13317)

    该论文介绍了利用深度学习方法实现的课堂考勤系统。深度学习方法可以通过图像处理进行面部识别，从而在教育中提供安全性和自动化的贡献。

    

    随着技术的进步，计算机的硬件增益和处理器的处理能力的提升，使得即时和实时图像的处理变得更加容易。面部识别过程也是图像处理领域的研究。面部识别过程经常在安全应用和商业应用中使用。特别是在过去的20年里，人工智能（AI）研究的高性能对这些研究在许多不同领域的扩散做出了贡献。教育便是其中之一。使用AI在教育中的潜力和优势可以分为三个方面：学生、教师和机构。机构研究之一可能是教育环境的安全性以及自动化对教育和培训过程的贡献。从这个角度来看，本研究采用了深度学习方法，这是AI的一个子分支。对于从图像中进行对象检测，本研究进行了开创性的工作。

    With the advancing technology, the hardware gain of computers and the increase in the processing capacity of processors have facilitated the processing of instantaneous and real-time images. Face recognition processes are also studies in the field of image processing. Facial recognition processes are frequently used in security applications and commercial applications. Especially in the last 20 years, the high performances of artificial intelligence (AI) studies have contributed to the spread of these studies in many different fields. Education is one of them. The potential and advantages of using AI in education; can be grouped under three headings: student, teacher, and institution. One of the institutional studies may be the security of educational environments and the contribution of automation to education and training processes. From this point of view, deep learning methods, one of the sub-branches of AI, were used in this study. For object detection from images, a pioneering st
    
[^2]: USL-Net：用于无监督皮肤病变分割的不确定性自学习网络

    USL-Net: Uncertainty Self-Learning Network for Unsupervised Skin Lesion Segmentation. (arXiv:2309.13289v1 [cs.CV])

    [http://arxiv.org/abs/2309.13289](http://arxiv.org/abs/2309.13289)

    使用对比学习和类激活图技术，USL-Net提供了一种无需手动标注指导的方法，能够有效地分割各种皮肤病变区域。

    

    无监督皮肤病变分割具有多种好处，包括节约专家人力资源、减少主观人工标注引起的差异以及适应新环境。然而，在没有手动标注指导的情况下分割皮肤镜图像存在显著挑战，如毛发噪声、水疱噪声和细微边缘差异等皮肤镜图像伪影。为了应对这些挑战，我们引入了一种创新的不确定性自学习网络（USL-Net）用于皮肤病变分割。USL-Net能够有效地分割各种病变，无需手动标注指导。首先，使用对比学习提取特征，然后使用这些特征生成类激活图（CAMs）作为显著图。不同的CAM位置对应于基于显著性的病变区域的重要性。地图中的高显著区域用作病变区域的伪标签，而低显著区域用作非病变区域的伪标签。

    Unsupervised skin lesion segmentation offers several benefits, including conserving expert human resources, reducing discrepancies due to subjective human labeling, and adapting to novel environments. However, segmenting dermoscopic images without manual labeling guidance presents significant challenges due to dermoscopic image artifacts such as hair noise, blister noise, and subtle edge differences. To address these challenges, we introduce an innovative Uncertainty Self-Learning Network (USL-Net) designed for skin lesion segmentation. The USL-Net can effectively segment a range of lesions, eliminating the need for manual labeling guidance. Initially, features are extracted using contrastive learning, followed by the generation of Class Activation Maps (CAMs) as saliency maps using these features. The different CAM locations correspond to the importance of the lesion region based on their saliency. High-saliency regions in the map serve as pseudo-labels for lesion regions while low-sa
    
[^3]: 无人机群体的碰撞回避和导航方法：基于端到端深度强化学习

    Collision Avoidance and Navigation for a Quadrotor Swarm Using End-to-end Deep Reinforcement Learning. (arXiv:2309.13285v1 [cs.RO])

    [http://arxiv.org/abs/2309.13285](http://arxiv.org/abs/2309.13285)

    这项研究提出了一种基于端到端深度强化学习的方法，用于在带有障碍物的环境中控制无人机群体，并通过课程学习和回放缓冲区提高性能。此外，还实施了注意力机制以关注邻近机器人和障碍物之间的相互作用。

    

    端到端深度强化学习(DRL)的无人机控制方法具有易于部署、任务泛化和实时执行能力等优点。然而，以往的端到端DRL方法主要用于在简单、无障碍环境中训练单个无人机或无人机团队的控制器，并没有考虑障碍物对训练RL策略的困难性增加造成的挑战。本文提出了一种在带有障碍物环境中控制无人机群体的端到端DRL方法。我们为智能体提供了一个课程（curriculum）和一个回放缓冲区（replay buffer），用于改善在充满障碍物的环境中的性能。此外，我们还实施了一个注意力机制，以关注邻近机器人和障碍物之间的相互作用 - 这是首次成功地在严重计算受限的硬件上部署的群体行为策略中应用此机制。

    End-to-end deep reinforcement learning (DRL) for quadrotor control promises many benefits -- easy deployment, task generalization and real-time execution capability. Prior end-to-end DRL-based methods have showcased the ability to deploy learned controllers onto single quadrotors or quadrotor teams maneuvering in simple, obstacle-free environments. However, the addition of obstacles increases the number of possible interactions exponentially, thereby increasing the difficulty of training RL policies. In this work, we propose an end-to-end DRL approach to control quadrotor swarms in environments with obstacles. We provide our agents a curriculum and a replay buffer of the clipped collision episodes to improve performance in obstacle-rich environments. We implement an attention mechanism to attend to the neighbor robots and obstacle interactions - the first successful demonstration of this mechanism on policies for swarm behavior deployed on severely compute-constrained hardware. Our wor
    
[^4]: 通过生成预测IoU引导的质量得分，意识到本地化准确性

    Being Aware of Localization Accuracy By Generating Predicted-IoU-Guided Quality Scores. (arXiv:2309.13269v1 [cs.CV])

    [http://arxiv.org/abs/2309.13269](http://arxiv.org/abs/2309.13269)

    本文提出了一种通过生成预测IoU引导的质量得分来意识到本地化准确性的方法，通过联合考虑分类得分和本地化准确性，提高了检测性能。实验结果表明，该方法在一阶检测中取得了最佳性能。

    

    本文介绍了一种本地化质量估计（LQE）方法，通过联合考虑分类得分和本地化准确性，在后处理中有助于提高检测性能。为了进一步利用本地化准确性和IoU（交并比）之间的紧密关系，并抑制那些不一致的预测结果，我们设计了一个优雅的LQE分支，以获取由预测的IoU引导的本地化质量得分。此外，为了在培训和推理过程中减轻分类得分和本地化质量之间的不一致性，前者可能会损害性能，我们将LQE分支嵌入分类分支中，产生一个联合的分类-本地化质量表示。然后，我们提出了一种名为CLQ的新型一阶检测器。大量实验证实了CLQ的性能是目前最好的。

    Localization Quality Estimation (LQE) helps to improve detection performance as it benefits post processing through jointly considering classification score and localization accuracy. In this perspective, for further leveraging the close relationship between localization accuracy and IoU (Intersection-Over-Union), and for depressing those inconsistent predictions, we designed an elegant LQE branch to acquire localization quality score guided by predicted IoU. Distinctly, for alleviating the inconsistency of classification score and localization quality during training and inference, under which some predictions with low classification scores but high LQE scores will impair the performance, instead of separately and independently setting, we embedded LQE branch into classification branch, producing a joint classification-localization-quality representation. Then a novel one stage detector termed CLQ is proposed. Extensive experiments show that CLQ achieves state-of-the-arts' performance
    
[^5]: 基于跨模态融合和知识迁移的鲁棒导航

    Robust Navigation with Cross-Modal Fusion and Knowledge Transfer. (arXiv:2309.13266v1 [cs.RO])

    [http://arxiv.org/abs/2309.13266](http://arxiv.org/abs/2309.13266)

    本文提出了一种跨模态融合方法和知识迁移框架，通过师生蒸馏架构实现。在实验中表现出了优于基准线的鲁棒导航性能。

    

    最近，基于学习的方法在导航任务中显示出了很好的结果。然而，差强人意的泛化能力和模拟-现实差距限制了广泛的应用。我们考虑提高移动机器人的泛化能力并实现导航技能的模拟到实际转移的问题。为此，我们提出了一种跨模态融合方法和一个知识迁移框架来提高泛化能力。这通过一个师生蒸馏架构实现。老师在一个理想的环境中学习一个有区分性的表示和近乎完美的策略。通过模仿老师的行为和表示，学生能够对来自嘈杂的多模态输入对齐特征，并减少变化对导航策略的影响。我们在模拟和现实环境中评估了我们的方法。实验表明，我们的方法相比基准线表现出了很大的优势，并实现了鲁棒的导航性能。

    Recently, learning-based approaches show promising results in navigation tasks. However, the poor generalization capability and the simulation-reality gap prevent a wide range of applications. We consider the problem of improving the generalization of mobile robots and achieving sim-to-real transfer for navigation skills. To that end, we propose a cross-modal fusion method and a knowledge transfer framework for better generalization. This is realized by a teacher-student distillation architecture. The teacher learns a discriminative representation and the near-perfect policy in an ideal environment. By imitating the behavior and representation of the teacher, the student is able to align the features from noisy multi-modal input and reduce the influence of variations on navigation policy. We evaluate our method in simulated and real-world environments. Experiments show that our method outperforms the baselines by a large margin and achieves robust navigation performance with varying wo
    
[^6]: WikiMT++数据集卡片

    WikiMT++ Dataset Card. (arXiv:2309.13259v1 [cs.IR])

    [http://arxiv.org/abs/2309.13259](http://arxiv.org/abs/2309.13259)

    WikiMT++是一个扩展和精细版本的WikiMusicText数据集，包含了1010个经过策划的ABC记谱法的主题曲。它添加了客观属性和主观情感属性，增强了数据集的应用场景和可用性，并通过CLaMP来纠正属性，提高准确性和完整性。

    

    WikiMT++是WikiMusicText（WikiMT）的扩展和精细版本，包含了1010个经过策划的ABC记谱法的主题曲。为了扩展WikiMT的应用场景，我们添加了客观属性（专辑、歌词、视频）和主观情感属性（12个情感形容词）和情感4Q（Russell 4Q），增强了其在音乐信息检索、条件音乐生成、自动作曲和情感分类等方面的可用性。此外，我们还实现了CLaMP来纠正从WikiMT继承的属性，以减少原始数据收集过程中引入的错误，增强了数据集的准确性和完整性。

    WikiMT++ is an expanded and refined version of WikiMusicText (WikiMT), featuring 1010 curated lead sheets in ABC notation. To expand application scenarios of WikiMT, we add both objective (album, lyrics, video) and subjective emotion (12 emotion adjectives) and emo\_4q (Russell 4Q) attributes, enhancing its usability for music information retrieval, conditional music generation, automatic composition, and emotion classification, etc. Additionally, CLaMP is implemented to correct the attributes inherited from WikiMT to reduce errors introduced during original data collection and enhance the accuracy and completeness of our dataset.
    
[^7]: 针对预训练语言模型的少样本学习者的反向攻击防御

    Defending Pre-trained Language Models as Few-shot Learners against Backdoor Attacks. (arXiv:2309.13256v1 [cs.LG])

    [http://arxiv.org/abs/2309.13256](http://arxiv.org/abs/2309.13256)

    本研究针对预训练语言模型作为少样本学习者的安全风险进行了初步研究，发现其极易受到反向攻击。为了应对这个问题，我们提出了一种名为MDP的轻量级、可插拔且有效的防御方法，通过利用被污染样本和清洁样本之间的掩码敏感性差距来识别污染样本。实证评估结果表明，MDP在攻击效果和检测逃避性之间形成了进退两难。

    

    预训练语言模型（PLM）作为少样本学习者展示出了卓越的性能。然而，在这种设置下，它们的安全风险尚未得到广泛探究。在这项工作中，我们进行了一项初步研究，表明少样本学习者的PLMs极易受到反向攻击，而现有的防御措施由于少样本情境的独特挑战而不足。为了应对这些挑战，我们提出了MDP，一种新颖、轻量级、可插拔且有效的预训练语言模型少样本学习者的防御方法。具体而言，MDP利用了被污染样本和清洁样本之间的掩码敏感性差距：参考有限的少样本数据作为分布锚点，它比较不同掩码下给定样本的表示，并识别出具有显著变化的被污染样本。我们通过分析表明，MDP对于攻击者在攻击效果和检测逃避性之间产生了有趣的进退两难。实证评估使用be

    Pre-trained language models (PLMs) have demonstrated remarkable performance as few-shot learners. However, their security risks under such settings are largely unexplored. In this work, we conduct a pilot study showing that PLMs as few-shot learners are highly vulnerable to backdoor attacks while existing defenses are inadequate due to the unique challenges of few-shot scenarios. To address such challenges, we advocate MDP, a novel lightweight, pluggable, and effective defense for PLMs as few-shot learners. Specifically, MDP leverages the gap between the masking-sensitivity of poisoned and clean samples: with reference to the limited few-shot data as distributional anchors, it compares the representations of given samples under varying masking and identifies poisoned samples as ones with significant variations. We show analytically that MDP creates an interesting dilemma for the attacker to choose between attack effectiveness and detection evasiveness. The empirical evaluation using be
    
[^8]: 我可以相信解释吗？研究可解释机器学习方法在单调模型中的应用

    Can I Trust the Explanations? Investigating Explainable Machine Learning Methods for Monotonic Models. (arXiv:2309.13246v1 [cs.LG])

    [http://arxiv.org/abs/2309.13246](http://arxiv.org/abs/2309.13246)

    本研究研究了可解释机器学习方法在单调模型中的应用，发现了解释的可靠性和模型的单调性之间的关系。

    

    近年来，可解释机器学习方法取得了很大成功。尽管成功，但大多数可解释机器学习方法都是应用于黑盒模型而没有任何领域知识。通过结合领域知识，以科学为基础的机器学习模型展现出更好的泛化和解释性。但是，如果我们将可解释的机器学习方法应用于基于科学知识的机器学习模型，我们能获得一致的科学解释吗？这个问题在展示三种不同类型的单调模型的背景下得到了回答。为了展示单调性，我们提出了三个公理。相应地，这项研究表明，当仅涉及个体单调性时，基准Shapley值提供了良好的解释；然而，当涉及强大的成对单调性时，集成梯度方法在平均上提供了合理的解释。

    In recent years, explainable machine learning methods have been very successful. Despite their success, most explainable machine learning methods are applied to black-box models without any domain knowledge. By incorporating domain knowledge, science-informed machine learning models have demonstrated better generalization and interpretation. But do we obtain consistent scientific explanations if we apply explainable machine learning methods to science-informed machine learning models? This question is addressed in the context of monotonic models that exhibit three different types of monotonicity. To demonstrate monotonicity, we propose three axioms. Accordingly, this study shows that when only individual monotonicity is involved, the baseline Shapley value provides good explanations; however, when strong pairwise monotonicity is involved, the Integrated gradients method provides reasonable explanations on average.
    
[^9]: UniHead: 融合多感知的检测头

    UniHead: Unifying Multi-Perception for Detection Heads. (arXiv:2309.13242v1 [cs.CV])

    [http://arxiv.org/abs/2309.13242](http://arxiv.org/abs/2309.13242)

    UniHead是一种创新的检测头，它通过引入变形感知、双轴聚合变换器和跨任务交互变换器，实现了全感知能力的统一。

    

    检测头是目标检测器中一个关键组件，负责执行分类和定位功能。然而，常用的并行检测头常常缺乏全感知能力，如变形感知、全局感知和跨任务感知。尽管有很多方法试图从单个方面提高这些能力，但实现全面统一的解决方案仍然是一个重大挑战。针对这个挑战，我们开发了一种创新的检测头，称为UniHead，同时统一了三种感知能力。具体而言，我们的方法：（1）引入了变形感知，使模型能够自适应采样对象特征；（2）提出了双轴聚合变换器（DAT）来灵活地建模长距离依赖关系，从而实现全局感知；（3）设计了一种跨任务交互变换器（CIT），促进分类和定位之间的交互作用。

    The detection head constitutes a pivotal component within object detectors, tasked with executing both classification and localization functions. Regrettably, the commonly used parallel head often lacks omni perceptual capabilities, such as deformation perception, global perception and cross-task perception. Despite numerous methods attempt to enhance these abilities from a single aspect, achieving a comprehensive and unified solution remains a significant challenge. In response to this challenge, we have developed an innovative detection head, termed UniHead, to unify three perceptual abilities simultaneously. More precisely, our approach (1) introduces deformation perception, enabling the model to adaptively sample object features; (2) proposes a Dual-axial Aggregation Transformer (DAT) to adeptly model long-range dependencies, thereby achieving global perception; and (3) devises a Cross-task Interaction Transformer (CIT) that facilitates interaction between the classification and lo
    
[^10]: 面向数字孪生的复杂网络系统的异质特征表示

    Heterogeneous Feature Representation for Digital Twin-Oriented Complex Networked Systems. (arXiv:2309.13229v1 [cs.AI])

    [http://arxiv.org/abs/2309.13229](http://arxiv.org/abs/2309.13229)

    本研究致力于提高数字孪生导向的复杂网络系统中节点特征的表达能力，通过使用异质特征表示原则，并通过实证分析建立了数字孪生导向的复杂网络系统来重现现实物理接触网络，进一步探究其对灾害韧性的影响。

    

    构建能够准确表示现实的复杂网络系统(CNS)模型是一个重要的研究领域。为了能够反映现实世界的系统，建模需要考虑不仅仅是实体之间的相互作用强度，还要考虑系统中所有元素的特征。本研究旨在通过采用异质特征表示原则来提高数字孪生导向的复杂网络系统(DT-CNSs)中节点特征的表达能力。这涉及到使用清晰的特征值和模糊集合来表示特征，每个特征描述了节点特征和特征差异的客观和主观归纳。我们的实证分析基于各种表示原则和优化的特征偏好，建立DT-CNSs来重现不同国家的现实物理接触网络。我们还调查了它们对从流行病爆发开始的灾害韧性的影响。

    Building models of Complex Networked Systems (CNS) that can accurately represent reality forms an important research area. To be able to reflect real world systems, the modelling needs to consider not only the intensity of interactions between the entities but also features of all the elements of the system. This study aims to improve the expressive power of node features in Digital Twin-Oriented Complex Networked Systems (DT-CNSs) with heterogeneous feature representation principles. This involves representing features with crisp feature values and fuzzy sets, each describing the objective and the subjective inductions of the nodes' features and feature differences. Our empirical analysis builds DT-CNSs to recreate realistic physical contact networks in different countries from real node feature distributions based on various representation principles and an optimised feature preference. We also investigate their respective disaster resilience to an epidemic outbreak starting from the
    
[^11]: 大规模包裹操纵的拣选计划策略

    Pick Planning Strategies for Large-Scale Package Manipulation. (arXiv:2309.13224v1 [cs.RO])

    [http://arxiv.org/abs/2309.13224](http://arxiv.org/abs/2309.13224)

    本文介绍了亚马逊机器人公司的Robot Induction（Robin）舰队中的大规模包裹操纵，通过使用拣选成功预测器以及训练的拣选质量估计方法，在真实生产系统中进行自动化仓储操作。

    

    自动化仓储操作可以降低物流成本，最终降低消费者的价格，加快交货速度，并增强对市场波动的适应力。本文展示了亚马逊机器人公司的机器人引导（Robin）舰队中的大规模包裹操纵，用于每天拣选和单独处理600万个包裹，并且目前已经处理了20亿个包裹。它描述了随着时间推移开发的各种启发式方法及其后继方法，后继方法利用了在真实生产数据上训练的拣选成功预测器。据作者所知，这项工作是在真实生产系统中首次大规模部署学习的拣选质量估计方法。

    Automating warehouse operations can reduce logistics overhead costs, ultimately driving down the final price for consumers, increasing the speed of delivery, and enhancing the resiliency to market fluctuations.  This extended abstract showcases a large-scale package manipulation from unstructured piles in Amazon Robotics' Robot Induction (Robin) fleet, which is used for picking and singulating up to 6 million packages per day and so far has manipulated over 2 billion packages. It describes the various heuristic methods developed over time and their successor, which utilizes a pick success predictor trained on real production data.  To the best of the authors' knowledge, this work is the first large-scale deployment of learned pick quality estimation methods in a real production system.
    
[^12]: Hindi to English: 基于Transformer的神经机器翻译

    Hindi to English: Transformer-Based Neural Machine Translation. (arXiv:2309.13222v1 [cs.CL])

    [http://arxiv.org/abs/2309.13222](http://arxiv.org/abs/2309.13222)

    本文使用Transformer模型开发了一种基于神经网络的印度语Hindi到英文的机器翻译系统，并通过回译和不同的分词方法提升了翻译质量。

    

    机器翻译（MT）是自然语言处理（NLP）中最重要的任务之一，它涉及将文本从一种自然语言自动转换为另一种语言，同时保持其含义和流畅性。尽管机器翻译的研究已经持续了数十年，但将深度学习技术与自然语言处理结合的新方法从根本上改善了翻译质量。在本文中，我们通过训练Transformer模型开发了一种神经机器翻译（NMT）系统，用于将印度语Hindi文本翻译成英文。Hindi作为一种资源稀缺的语言，使得神经网络难以理解该语言，从而导致神经机器翻译器的发展缓慢。因此，为了弥补这一差距，我们实施了回译来增加训练数据，并通过实验使用了词级和子词级的分词方法创建了词汇表。

    Machine Translation (MT) is one of the most prominent tasks in Natural Language Processing (NLP) which involves the automatic conversion of texts from one natural language to another while preserving its meaning and fluency. Although the research in machine translation has been going on since multiple decades, the newer approach of integrating deep learning techniques in natural language processing has led to significant improvements in the translation quality. In this paper, we have developed a Neural Machine Translation (NMT) system by training the Transformer model to translate texts from Indian Language Hindi to English. Hindi being a low resource language has made it difficult for neural networks to understand the language thereby leading to a slow growth in the development of neural machine translators. Thus, to address this gap, we implemented back-translation to augment the training data and for creating the vocabulary, we experimented with both word and subword level tokenizat
    
[^13]: 海报：自监督的量化感知知识蒸馏

    Poster: Self-Supervised Quantization-Aware Knowledge Distillation. (arXiv:2309.13220v1 [cs.CV])

    [http://arxiv.org/abs/2309.13220](http://arxiv.org/abs/2309.13220)

    本文提出了一种名为SQAKD的自监督的量化感知知识蒸馏框架，它可以在不需要标签监督和准确性损失的情况下，显著提高各种最先进的QAT方法的性能。通过统一各种量化函数的动力学，并以自监督的方式进行优化，SQAKD为最先进的QAT研究提供了更强的基线，同时不需要大量标记的训练数据，使其更易于操作。

    

    量化感知训练(QAT)从预训练的全精度模型开始，在重新训练过程中执行量化。然而，现有的QAT方法需要依赖标签的监督，并且由于降低了精度而导致准确性损失。为了解决这些限制，本文提出了一种新颖的自监督的量化感知知识蒸馏框架(SQAKD)。SQAKD首先统一了各种量化函数的前向和反向动力学，然后以自监督的方式将QAT重新构建为一个共同优化的问题，同时最小化KL损失和离散化误差。评估结果表明，SQAKD显著改善了各种最先进的QAT方法的性能。SQAKD建立了更强的基线，并且不需要大量的标记训练数据，潜在地使得最先进的QAT研究更易于操作。

    Quantization-aware training (QAT) starts with a pre-trained full-precision model and performs quantization during retraining. However, existing QAT works require supervision from the labels and they suffer from accuracy loss due to reduced precision. To address these limitations, this paper proposes a novel Self-Supervised Quantization-Aware Knowledge Distillation framework (SQAKD). SQAKD first unifies the forward and backward dynamics of various quantization functions and then reframes QAT as a co-optimization problem that simultaneously minimizes the KL-Loss and the discretization error, in a self-supervised manner. The evaluation shows that SQAKD significantly improves the performance of various state-of-the-art QAT works. SQAKD establishes stronger baselines and does not require extensive labeled training data, potentially making state-of-the-art QAT research more accessible.
    
[^14]: AI-企业优化的协同辅助：一个框架和在生产调度中的案例研究。

    AI-Copilot for Business Optimisation: A Framework and A Case Study in Production Scheduling. (arXiv:2309.13218v1 [cs.AI])

    [http://arxiv.org/abs/2309.13218](http://arxiv.org/abs/2309.13218)

    这篇论文提出了一个AI-企业优化的协同辅助系统，通过采用大型语言模型和微调预训练模型的方法，实现了减少人类专业知识需求的目标。

    

    企业优化是寻找和实施高效和具有成本效益的运营方式，以为企业带来竞争优势的过程。综合问题表述是企业优化的一个重要组成部分，它围绕着人类专业知识展开，因此很有可能成为瓶颈。随着大型语言模型（LLMs）的最新进展，通过人工智能（AI）可以潜在地减少问题表述中所需的人类专业知识。然而，开发用于问题表述的LLM具有挑战性，由于训练数据要求、令牌限制以及LLM中缺乏适当的性能度量。为了减少大量训练数据的需求，最近人们开始关注对预训练的LLM进行微调以适应下游任务，而不是从头开始训练一个特定任务的LLM。在本文中，我们采用了这种方法，提出了一个AI-企业优化的协同辅助系统。

    Business optimisation is the process of finding and implementing efficient and cost-effective means of operation to bring a competitive advantage for businesses. Synthesizing problem formulations is an integral part of business optimisation which is centred around human expertise, thus with a high potential of becoming a bottleneck. With the recent advancements in Large Language Models (LLMs), human expertise needed in problem formulation can potentially be minimized using Artificial Intelligence (AI). However, developing a LLM for problem formulation is challenging, due to training data requirements, token limitations, and the lack of appropriate performance metrics in LLMs. To minimize the requirement of large training data, considerable attention has recently been directed towards fine-tuning pre-trained LLMs for downstream tasks, rather than training a LLM from scratch for a specific task. In this paper, we adopt this approach and propose an AI-Copilot for business optimisation by 
    
[^15]: MISFIT-V: 利用来自热视觉和可见光的信息进行不匹配图像合成和融合

    MISFIT-V: Misaligned Image Synthesis and Fusion using Information from Thermal and Visual. (arXiv:2309.13216v1 [cs.CV])

    [http://arxiv.org/abs/2309.13216](http://arxiv.org/abs/2309.13216)

    MISFIT-V 是一个使用来自热视觉和可见光信息的不匹配图像合成和融合的新方法，利用无监督深度学习和交叉注意力机制，提供了对不匹配和恶劣环境条件更强的鲁棒性。

    

    对于野外搜救(WiSAR)团队来说，从空中可见光和热视觉图像中检测人体是一个基本挑战，他们必须在巨大压力下准确执行这个功能。融合这两种传感器模式的能力可能会减少人类操作员的认知负荷和/或提高计算机视觉目标检测模型的有效性。然而，在WiSAR环境中，由于硬件限制和极端的环境因素，融合任务尤其具有挑战性。该研究提出了Misaligned Image Synthesis and Fusion using Information from Thermal and Visual (MISFIT-V)，这是一种新颖的双通道无监督深度学习方法，利用生成对抗网络(GAN)和交叉注意力机制从每个模态中捕捉最相关的特征。实验结果显示，与现有方法相比，MISFIT-V在对不匹配和光照/热环境条件差的情况下具有更强的鲁棒性。

    Detecting humans from airborne visual and thermal imagery is a fundamental challenge for Wilderness Search-and-Rescue (WiSAR) teams, who must perform this function accurately in the face of immense pressure. The ability to fuse these two sensor modalities can potentially reduce the cognitive load on human operators and/or improve the effectiveness of computer vision object detection models. However, the fusion task is particularly challenging in the context of WiSAR due to hardware limitations and extreme environmental factors. This work presents Misaligned Image Synthesis and Fusion using Information from Thermal and Visual (MISFIT-V), a novel two-pronged unsupervised deep learning approach that utilizes a Generative Adversarial Network (GAN) and a cross-attention mechanism to capture the most relevant features from each modality. Experimental results show MISFIT-V offers enhanced robustness against misalignment and poor lighting/thermal environmental conditions compared to existing v
    
[^16]: 评估个性对于视频游戏交流中情感状态的影响

    Assessing the Impact of Personality on Affective States from Video Game Communication. (arXiv:2309.13214v1 [cs.AI])

    [http://arxiv.org/abs/2309.13214](http://arxiv.org/abs/2309.13214)

    本研究探讨了个性对团队合作的虚拟现实游戏玩家的情感表达方式的影响。通过分析两周内11名玩家的聊天记录，我们发现了个性变量与情感表达之间的合理相关性，例如较低的自我能力与增加的困惑之间的关系，以及个人烦恼与内在和外在形象问题的增多之间的关系。

    

    个性的个体差异决定了我们的喜好、特征和价值观，这同样适用于我们表达自己的方式。在当前技术和社会的进步和转变中，基于文本的沟通变得普遍，并且通常甚至超过了自然的语音交流，带来了不同的挑战和机遇。在这项探索性工作中，我们研究了个性对基于团队合作的虚拟现实游戏玩家情感表达方式的影响。我们在两周内收集了十一个玩家的聊天记录，根据他们的情感状态进行标记，并评估了它们与五个人格领域和方面之间的关联。在应用多元线性回归之后，我们发现了一系列合理的相关性，即（组合）个性变量与表达的情感之间的关系--例如，较低的自我能力（C1）可以预测增加的困惑，个人烦恼可以预测通过内在和外在形象问题的增多。

    Individual differences in personality determine our preferences, traits and values, which should similarly hold for the way we express ourselves. With current advancements and transformations of technology and society, text-based communication has become ordinary and often even surpasses natural voice conversations -- with distinct challenges and opportunities. In this exploratory work, we investigate the impact of personality on the tendency how players of a team-based collaborative alternate reality game express themselves affectively. We collected chat logs from eleven players over two weeks, labeled them according to their affective state, and assessed the connection between them and the five-factor personality domains and facets. After applying multi-linear regression, we found a series of reasonable correlations between (combinations of) personality variables and expressed affect -- as increased confusion could be predicted by lower self-competence (C1), personal annoyance by vul
    
[^17]: 意图感知自动驾驶：高速合并情景案例研究

    Intent-Aware Autonomous Driving: A Case Study on Highway Merging Scenarios. (arXiv:2309.13206v1 [cs.RO])

    [http://arxiv.org/abs/2309.13206](http://arxiv.org/abs/2309.13206)

    本文研究了使用意图沟通作为促进自动驾驶车辆合作的方法，并在高速合并情景中研究了意图共享如何帮助接收车辆调整其行为策略。

    

    在这项研究中，我们使用意图的沟通作为促进自动驾驶车辆之间合作的手段。通常情况下，意图可以是车辆与另一辆车沟通的关于其未来行为的可靠信息。我们在highway-env模拟器的合并环境中实现了一个意图共享任务，该模拟器提供了一系列用于学习自动驾驶车辆决策策略的环境。在两个代理之间的简单设置下，我们仔细研究了意图共享如何帮助接收车辆调整其在高速合并情景中的行为。

    In this work, we use the communication of intent as a means to facilitate cooperation between autonomous vehicle agents. Generally speaking, intents can be any reliable information about its future behavior that a vehicle communicates with another vehicle. We implement this as an intent-sharing task atop the merging environment in the simulator of highway-env, which provides a collection of environments for learning decision-making strategies for autonomous vehicles. Under a simple setting between two agents, we carefully investigate how intent-sharing can aid the receiving vehicle in adjusting its behavior in highway merging scenarios.
    
[^18]: 针对上下文学习的零样本提示设计的实际调查

    A Practical Survey on Zero-shot Prompt Design for In-context Learning. (arXiv:2309.13205v1 [cs.CL])

    [http://arxiv.org/abs/2309.13205](http://arxiv.org/abs/2309.13205)

    本文综述了针对上下文学习的零样本提示设计技术，并探讨了不同类型提示对大型语言模型性能的影响。研究重点讨论了人工设计、优化算法和评价方法等多种提示设计方法，以优化模型在不同任务上的性能。同时，本文强调了考虑多种指标和缺乏单一最佳提示等评估挑战。该研究揭示了提示设计在充分发挥大型语言模型潜力方面的关键作用。

    

    大型语言模型（LLM）的显著进展在自然语言处理（NLP）任务中带来了显著的改进。本文对上下文学习技术进行了综合回顾，重点关注不同类型的提示，包括离散、连续、少样本和零样本，并探讨它们对LLM性能的影响。我们探索了各种提示设计方法，如人工设计、优化算法和评价方法，以优化LLM在各种任务中的性能。我们的回顾涵盖了提示工程领域的关键研究，讨论了其方法论和对该领域的贡献。我们还深入探讨了在评估提示性能方面面临的挑战，包括缺乏单一的"最佳"提示和考虑多个指标的重要性。总之，本文强调了提示设计在发挥LLM的全部潜力中的关键作用，并提供了关于人工设计、优化算法和评价方法结合的见解。

    The remarkable advancements in large language models (LLMs) have brought about significant improvements in Natural Language Processing(NLP) tasks. This paper presents a comprehensive review of in-context learning techniques, focusing on different types of prompts, including discrete, continuous, few-shot, and zero-shot, and their impact on LLM performance. We explore various approaches to prompt design, such as manual design, optimization algorithms, and evaluation methods, to optimize LLM performance across diverse tasks. Our review covers key research studies in prompt engineering, discussing their methodologies and contributions to the field. We also delve into the challenges faced in evaluating prompt performance, given the absence of a single "best" prompt and the importance of considering multiple metrics. In conclusion, the paper highlights the critical role of prompt design in harnessing the full potential of LLMs and provides insights into the combination of manual design, opt
    
[^19]: 大型语言模型和控制机制提高了生物医学摘要的文本可读性

    Large Language Models and Control Mechanisms Improve Text Readability of Biomedical Abstracts. (arXiv:2309.13202v1 [cs.CL])

    [http://arxiv.org/abs/2309.13202](http://arxiv.org/abs/2309.13202)

    本研究使用大型语言模型和控制机制改善了生物医学摘要的文本可读性，具体包括领域微调和基于提示的学习方法，以及应用于编码器-解码器模型和GPT模型的控制令牌机制。

    

    生物医学文献通常使用复杂的语言和难以理解的专业术语。因此，简化在提高公共健康素养方面起着重要作用。将自然语言处理（NLP）模型应用于自动化此类任务可以使非专业读者快速直接地获取信息。在本研究中，我们使用公开可用的用于生物医学摘要简化的数据集（PLABA）来调查最先进大型语言模型（LLMs）在生物医学摘要简化任务上的能力。应用的方法包括领域微调和基于提示的学习（PBL）在：1）编码器-解码器模型（T5、SciFive和BART）上，2）仅解码器的GPT模型（GPT-3.5和GPT-4）来自OpenAI和BioGPT，以及3）基于控制令牌机制的基于BART的模型。我们使用了一系列自动评估指标，包括BLEU、ROUGE、SARI和BERTscore，并进行了人工评估。

    Biomedical literature often uses complex language and inaccessible professional terminologies. That is why simplification plays an important role in improving public health literacy. Applying Natural Language Processing (NLP) models to automate such tasks allows for quick and direct accessibility for lay readers. In this work, we investigate the ability of state-of-the-art large language models (LLMs) on the task of biomedical abstract simplification, using the publicly available dataset for plain language adaptation of biomedical abstracts (\textbf{PLABA}). The methods applied include domain fine-tuning and prompt-based learning (PBL) on: 1) Encoder-decoder models (T5, SciFive, and BART), 2) Decoder-only GPT models (GPT-3.5 and GPT-4) from OpenAI and BioGPT, and 3) Control-token mechanisms on BART-based models. We used a range of automatic evaluation metrics, including BLEU, ROUGE, SARI, and BERTscore, and also conducted human evaluations. BART-Large with Control Token (BART-L-w-CT) m
    
[^20]: 通过自适应反向传播实现大型语言模型的绿色AI细调

    Towards Green AI in Fine-tuning Large Language Models via Adaptive Backpropagation. (arXiv:2309.13192v1 [cs.LG])

    [http://arxiv.org/abs/2309.13192](http://arxiv.org/abs/2309.13192)

    本文提出了GreenTrainer，一种新的LLM细调技术，通过自适应评估不同张量的反向传播成本和对细调模型准确性的贡献，以实现绿色AI。

    

    细调是将预训练的大型语言模型（LLMs）适应到下游应用中最有效的方法。随着LLM驱动的AI应用的快速增长以及开源LLM的民主化，非专业人员也可以进行细调，但是全球范围内对LLM的大规模细调可能导致能源消耗和碳足迹显著增加，从而对环境产生重大影响。实现绿色AI以减少细调的FLOPs直接相关，但是现有的高效LLM细调技术只能实现有限的FLOPs降低，因为它们忽视了细调中的反向传播成本。为了解决这个限制，本文提出了GreenTrainer，一种新的LLM细调技术，通过自适应评估不同张量的反向传播成本和对细调模型准确性的贡献，通过选择最有效的张量来最小化细调成本。

    Fine-tuning is the most effective way of adapting pre-trained large language models (LLMs) to downstream applications. With the fast growth of LLM-enabled AI applications and democratization of open-souced LLMs, fine-tuning has become possible for non-expert individuals, but intensively performed LLM fine-tuning worldwide could result in significantly high energy consumption and carbon footprint, which may bring large environmental impact. Mitigating such environmental impact towards Green AI directly correlates to reducing the FLOPs of fine-tuning, but existing techniques on efficient LLM fine-tuning can only achieve limited reduction of such FLOPs, due to their ignorance of the backpropagation cost in fine-tuning. To address this limitation, in this paper we present GreenTrainer, a new LLM fine-tuning technique that adaptively evaluates different tensors' backpropagation costs and contributions to the fine-tuned model accuracy, to minimize the fine-tuning cost by selecting the most a
    
[^21]: 基于遮盖的判别器用于内容一致性不配对的图像转换

    Masked Discriminators for Content-Consistent Unpaired Image-to-Image Translation. (arXiv:2309.13188v1 [cs.CV])

    [http://arxiv.org/abs/2309.13188](http://arxiv.org/abs/2309.13188)

    本论文提出了一种基于遮盖的判别器方法，用于减少无配对图像转换中的内容不一致性。通过在两个域的全局判别器上使用基于内容的遮罩，可以显著降低不一致性。同时，引入了局部判别器和相似性采样策略，以减少由于遮盖过程引起的伪影。

    

    无配对的图像转换的一个共同目标是在模仿目标域的风格的同时保持源图像和转换后图像之间的内容一致性。由于两个域的数据集之间存在偏差，许多方法在转换过程中会产生不一致性。大多数方法用于缓解这些不一致性的方法没有对判别器进行限制，导致训练设置更加无法确定。此外，这些方法都不适用于更大的裁剪尺寸。在这项工作中，我们展示了通过使用基于内容的遮罩对两个域的全局判别器的输入进行遮盖可以显著减少内容不一致性。然而，这种策略会导致可以追溯到遮罩过程的伪影。为了减少这些伪影，我们引入了一种在使用相似性采样策略选择的小裁剪对上操作的局部判别器。此外，我们还将这种采样策略应用于全局采样。

    A common goal of unpaired image-to-image translation is to preserve content consistency between source images and translated images while mimicking the style of the target domain. Due to biases between the datasets of both domains, many methods suffer from inconsistencies caused by the translation process. Most approaches introduced to mitigate these inconsistencies do not constrain the discriminator, leading to an even more ill-posed training setup. Moreover, none of these approaches is designed for larger crop sizes. In this work, we show that masking the inputs of a global discriminator for both domains with a content-based mask is sufficient to reduce content inconsistencies significantly. However, this strategy leads to artifacts that can be traced back to the masking process. To reduce these artifacts, we introduce a local discriminator that operates on pairs of small crops selected with a similarity sampling strategy. Furthermore, we apply this sampling strategy to sample global
    
[^22]: 分析和利用视频游戏对深度强化学习的计算需求

    Diagnosing and exploiting the computational demands of videos games for deep reinforcement learning. (arXiv:2309.13181v1 [cs.LG])

    [http://arxiv.org/abs/2309.13181](http://arxiv.org/abs/2309.13181)

    本研究通过引入学习挑战诊断器(LCD)来分析视频游戏对深度强化学习的计算需求，并在Procgen基准测试中发现新的挑战分类。结果表明，LCD的预测可靠且能指导算法的发展。

    

    人类通过与环境互动并感知行动结果来学习。深度强化学习算法在视频游戏中能够实现与人类相媲美甚至更好的表现，这在人工智能领域是一个里程碑。然而，目前还不清楚深度强化学习模型成功的原因是视觉表示学习的进步，还是强化学习算法发现更好策略的有效性，或者两者兼具。为了解决这个问题，我们引入了学习挑战诊断器（LCD），这是一种能够单独测量任务中感知和强化学习需求的工具。我们使用LCD在Procgen基准测试中发现了一种新的挑战分类，并证明这些预测既高度可靠，又能指导算法的发展。更广泛地讲，LCD揭示了在像P这样的整个视频游戏基准测试中优化深度强化学习算法时可能出现的多种失败情况。

    Humans learn by interacting with their environments and perceiving the outcomes of their actions. A landmark in artificial intelligence has been the development of deep reinforcement learning (dRL) algorithms capable of doing the same in video games, on par with or better than humans. However, it remains unclear whether the successes of dRL models reflect advances in visual representation learning, the effectiveness of reinforcement learning algorithms at discovering better policies, or both. To address this question, we introduce the Learning Challenge Diagnosticator (LCD), a tool that separately measures the perceptual and reinforcement learning demands of a task. We use LCD to discover a novel taxonomy of challenges in the Procgen benchmark, and demonstrate that these predictions are both highly reliable and can instruct algorithmic development. More broadly, the LCD reveals multiple failure cases that can occur when optimizing dRL algorithms over entire video game benchmarks like P
    
[^23]: AI风险概况：AI风险披露的标准提案

    AI Risk Profiles: A Standards Proposal for Pre-Deployment AI Risk Disclosures. (arXiv:2309.13176v1 [cs.AI])

    [http://arxiv.org/abs/2309.13176](http://arxiv.org/abs/2309.13176)

    本文提出了一个AI风险概述的标准，旨在帮助消费者理解与披露相关的AI系统的风险，为下游决策和监管框架提供指导。

    

    随着AI系统的复杂性和普及程度的增加，对其风险的认识也相应增长。因此，对于AI行业更加强调披露和透明度的呼声越来越高，提议从标准化技术披露（如模型卡片）到尚未具体说明的许可制度。由于AI价值链具有复杂性，包括代表不同专业知识、观点和价值观的参与者，消费者能够理解与披露相关的AI系统的风险至关重要。在本文中，我们提出了一个风险概述标准，可以指导下游决策，包括风险评估的分流、采购和部署的信息和指导监管框架。这个标准是建立在我们提出的AI风险分类系统基础上的，反映了广泛的高级分类。

    As AI systems' sophistication and proliferation have increased, awareness of the risks has grown proportionally (Sorkin et al. 2023). In response, calls have grown for stronger emphasis on disclosure and transparency in the AI industry (NTIA 2023; OpenAI 2023b), with proposals ranging from standardizing use of technical disclosures, like model cards (Mitchell et al. 2019), to yet-unspecified licensing regimes (Sindhu 2023). Since the AI value chain is complicated, with actors representing various expertise, perspectives, and values, it is crucial that consumers of a transparency disclosure be able to understand the risks of the AI system the disclosure concerns. In this paper we propose a risk profiling standard which can guide downstream decision-making, including triaging further risk assessment, informing procurement and deployment, and directing regulatory frameworks. The standard is built on our proposed taxonomy of AI risks, which reflects a high-level categorization of the wide 
    
[^24]: 研究高效深度学习架构在AES侧信道攻击中的应用

    Investigating Efficient Deep Learning Architectures For Side-Channel Attacks on AES. (arXiv:2309.13170v1 [cs.CR])

    [http://arxiv.org/abs/2309.13170](http://arxiv.org/abs/2309.13170)

    本论文研究了在AES侧信道攻击中使用高效深度学习架构的应用，重点在于减少计算资源和数据量的成本，并提出了基于ANSI侧信道攻击数据库的深度学习框架，并研究了Transformer模型的有效性。

    

    在过去几年中，深度学习在利用嵌入式密码应用中的侧信道漏洞方面越来越受欢迎，因为它在有效密钥恢复所需的攻击轨迹数量方面具有优势。已经发布了一些使用神经网络的有效攻击方法，但在计算资源和数据量方面减少其成本是一个永恒的目标，我们在这项工作中追求这个目标。我们专注于ANSI侧信道攻击数据库（ASCAD），并使用基于JAX的深度学习SCA框架，重现了一系列先前的结果并在此基础上改进性能。我们还研究了各种基于Transformer的模型的有效性。

    Over the past few years, deep learning has been getting progressively more popular for the exploitation of side-channel vulnerabilities in embedded cryptographic applications, as it offers advantages in terms of the amount of attack traces required for effective key recovery. A number of effective attacks using neural networks have already been published, but reducing their cost in terms of the amount of computing resources and data required is an ever-present goal, which we pursue in this work. We focus on the ANSSI Side-Channel Attack Database (ASCAD), and produce a JAX-based framework for deep-learning-based SCA, with which we reproduce a selection of previous results and build upon them in an attempt to improve their performance. We also investigate the effectiveness of various Transformer-based models.
    
[^25]: 大型语言模型也是良好的典型常识推理器

    Large Language Models Are Also Good Prototypical Commonsense Reasoners. (arXiv:2309.13165v1 [cs.CL])

    [http://arxiv.org/abs/2309.13165](http://arxiv.org/abs/2309.13165)

    本论文提出了一种解决大型语言模型常识推理任务的方法，通过设计更好的提示，实现了在ProtoQA数据集上的最新最佳结果，最大答案正确率提高了8％，最大错误率降低了4％。

    

    常识推理是大型语言模型的关键技能，但在涉及此能力的特定任务中仍存在持续挑战。传统的微调方法可能耗费大量资源，并可能损害模型的泛化能力。此外，像GPT-3.5和Claude这样的最先进语言模型主要通过API调用进行访问，这使得微调模型具有挑战性。为了解决这些问题，我们从大型模型的输出中汲取灵感，针对特定任务半自动地开发了一组新颖的提示，包括任务相关性、支持性证据生成（例如思路链和知识）、多样路径解码等，以帮助模型。在ProtoQA数据集上的实验结果表明，通过更好设计的提示，我们可以在ProtoQA排行榜上取得新的最佳成绩，将最大答案正确率提高了8％，最大错误率降低了4％（突破50％）

    Commonsense reasoning is a pivotal skill for large language models, yet it presents persistent challenges in specific tasks requiring this competence. Traditional fine-tuning approaches can be resource-intensive and potentially compromise a model's generalization capacity. Furthermore, state-of-the-art language models like GPT-3.5 and Claude are primarily accessible through API calls, which makes fine-tuning models challenging. To address these challenges, we draw inspiration from the outputs of large models for tailored tasks and semi-automatically developed a set of novel prompts from several perspectives, including task-relevance, supportive evidence generation (e.g. chain-of-thought and knowledge), diverse path decoding to aid the model. Experimental results on ProtoQA dataset demonstrate that with better designed prompts we can achieve the new state-of-art(SOTA) on the ProtoQA leaderboard, improving the Max Answer@1 score by 8%, Max Incorrect@1 score by 4% (breakthrough 50% for th
    
[^26]: GAMIX-VAE: 一种基于高斯混合后验的VAE

    GAMIX-VAE: A VAE with Gaussian Mixture Based Posterior. (arXiv:2309.13160v1 [cs.LG])

    [http://arxiv.org/abs/2309.13160](http://arxiv.org/abs/2309.13160)

    本文提出了一种基于高斯混合后验的VAE方法，重新定义了ELBO，引入正则化项和PatchGAN鉴别器，能够生成逼真的人脸。

    

    变分自动编码器（VAEs）已成为机器学习中生成建模和表示学习的基石。本文探讨了VAEs的一个细微方面，重点是解释KL Divergence，这是Evidence Lower Bound（ELBO）中的关键组成部分，它控制了重构准确性和正则化之间的权衡。虽然KL Divergence让潜变量分布与先验分布对齐，给整个潜空间加上结构约束，但却不限制各个变量分布。所提出的方法重新定义了带有高斯混合的后验概率的ELBO，引入了正则化项以防止方差崩溃，并使用PatchGAN鉴别器来增强纹理逼真度。实现细节涉及Encoder和Decoder的ResNetV2架构。实验证明了生成逼真的人脸的能力，为提供了一个有希望的解决方案。

    Variational Autoencoders (VAEs) have become a cornerstone in generative modeling and representation learning within machine learning. This paper explores a nuanced aspect of VAEs, focusing on interpreting the Kullback Leibler (KL) Divergence, a critical component within the Evidence Lower Bound (ELBO) that governs the trade-off between reconstruction accuracy and regularization. While the KL Divergence enforces alignment between latent variable distributions and a prior imposing a structure on the overall latent space but leaves individual variable distributions unconstrained. The proposed method redefines the ELBO with a mixture of Gaussians for the posterior probability, introduces a regularization term to prevent variance collapse, and employs a PatchGAN discriminator to enhance texture realism. Implementation details involve ResNetV2 architectures for both the Encoder and Decoder. The experiments demonstrate the ability to generate realistic faces, offering a promising solution for
    
[^27]: 图像标题中的上下文情感估计

    Contextual Emotion Estimation from Image Captions. (arXiv:2309.13136v1 [cs.CV])

    [http://arxiv.org/abs/2309.13136](http://arxiv.org/abs/2309.13136)

    本文探索使用大型语言模型（LLMs）支持上下文情感估计任务的方法，通过首先对图像进行字幕生成，然后使用LLM进行推理。研究着重于理解LLMs对人类情感的感知能力以及哪些信息能帮助其确定情感。研究还提出了一组自然语言描述符，用于生成字幕和情感注释，以实现情感估计和理解场景中元素对情感的影响。

    

    图像中的情感估计是一项具有挑战性的任务，通常使用计算机视觉方法通过面部、身体姿势和上下文线索直接估计人们的情感。本文探讨了是否可以通过使用大型语言模型（LLMs）来支持上下文情感估计任务，方法是首先对图像进行字幕生成，然后使用LLM进行推理。首先，我们必须了解：LLMs对人类情感的感知能力如何？以及哪些信息部分使它们能够确定情感？首先的一个挑战是构建一个能够描述场景中的人物并包含与情感感知相关信息的标题。为了实现这个目标，我们提出了一组用于面部、身体、互动和环境的自然语言描述符。我们使用它们为EMOTIC数据集中的331个图像手动生成字幕和情感注释。这些字幕为情感估计提供了一种可解释的表示，以便理解场景中的元素如何影响情感。

    Emotion estimation in images is a challenging task, typically using computer vision methods to directly estimate people's emotions using face, body pose and contextual cues. In this paper, we explore whether Large Language Models (LLMs) can support the contextual emotion estimation task, by first captioning images, then using an LLM for inference. First, we must understand: how well do LLMs perceive human emotions? And which parts of the information enable them to determine emotions? One initial challenge is to construct a caption that describes a person within a scene with information relevant for emotion perception. Towards this goal, we propose a set of natural language descriptors for faces, bodies, interactions, and environments. We use them to manually generate captions and emotion annotations for a subset of 331 images from the EMOTIC dataset. These captions offer an interpretable representation for emotion estimation, towards understanding how elements of a scene affect emotion
    
[^28]: 从一个以OTTR为核心的本体工程方法中获得的见解

    Insights from an OTTR-centric Ontology Engineering Methodology. (arXiv:2309.13130v1 [cs.DB])

    [http://arxiv.org/abs/2309.13130](http://arxiv.org/abs/2309.13130)

    本论文介绍了一种以OTTR为核心的本体工程方法，在材料科学领域的实践中取得了重要发现。OTTR语言通过实例化模板来构建本体或知识库，通过隐藏本体表示语言的特定性，使领域专家能够分离决定建模信息和如何建模信息的过程，从而提高了工作效率。

    

    OTTR是一种用于表示本体建模模式的语言，它通过实例化模板来构建本体或知识库。通过这种方式，本体表示语言的特定性被隐藏在领域专家之外，使得本体工程师在决定建模信息以及如何建模信息（例如使用哪些设计模式）时能够在一定程度上分离这两个过程。因此，某些决策可以推迟，以便更加专注于其中一个过程。到目前为止，在应用本体模板的本体工程方面的文献中只有少数几篇作品被描述。在本文中，我们概述了我们的方法论，并报告了我们在材料科学领域的本体工程活动中的发现。在这些活动中，OTTR模板起着关键作用。我们的本体工程过程是自下而上的，我们从现有数据开始建模活动，然后通过模板将数据输入到一个k

    OTTR is a language for representing ontology modeling patterns, which enables to build ontologies or knowledge bases by instantiating templates. Thereby, particularities of the ontological representation language are hidden from the domain experts, and it enables ontology engineers to, to some extent, separate the processes of deciding about what information to model from deciding about how to model the information, e.g., which design patterns to use. Certain decisions can thus be postponed for the benefit of focusing on one of these processes. To date, only few works on ontology engineering where ontology templates are applied are described in the literature.  In this paper, we outline our methodology and report findings from our ontology engineering activities in the domain of Material Science. In these activities, OTTR templates play a key role. Our ontology engineering process is bottom-up, as we begin modeling activities from existing data that is then, via templates, fed into a k
    
[^29]: OpportunityFinder：一个自动因果推断的框架

    OpportunityFinder: A Framework for Automated Causal Inference. (arXiv:2309.13103v1 [cs.LG])

    [http://arxiv.org/abs/2309.13103](http://arxiv.org/abs/2309.13103)

    OpportunityFinder是一个无需编码的因果推断框架，可以帮助非专业用户进行各种面板数据的因果推断研究，节省科学家和经济学家的带宽，并提供统计和严格的敏感性和稳健性分析。

    

    我们介绍了OpportunityFinder，一个无需编码的框架，用于为非专业用户进行各种面板数据的因果推断研究。在当前状态下，OpportunityFinder只需要用户提供原始观察数据和配置文件。然后触发一个流水线来检查/处理数据，选择适合的算法来执行因果研究。它返回处理的结果，包括治疗对预期结果的因果影响，以及敏感性和稳健性的结果。因果推断被广泛研究和用于估计个人与产品和特征相互作用的下游影响。通常这些因果研究是由科学家和/或经济学家定期进行的。业务利益相关者通常受限于科学家或经济学家进行因果研究的带宽。我们提供OpportunityFinder作为常见的因果研究的解决方案，具有四个关键特点：（1）易于使用，适用于业务分析师和决策者。(2)由于无编程需求，有效节省了科学家和经济学家的带宽。(3)它是一个端到端的系统，它可以负责数据处理、推断配置、推断评估等所有事情。(4)它提供了关于推断质量的统计和严格的敏感性和稳健性分析。

    We introduce OpportunityFinder, a code-less framework for performing a variety of causal inference studies with panel data for non-expert users. In its current state, OpportunityFinder only requires users to provide raw observational data and a configuration file. A pipeline is then triggered that inspects/processes data, chooses the suitable algorithm(s) to execute the causal study. It returns the causal impact of the treatment on the configured outcome, together with sensitivity and robustness results. Causal inference is widely studied and used to estimate the downstream impact of individual's interactions with products and features. It is common that these causal studies are performed by scientists and/or economists periodically. Business stakeholders are often bottle-necked on scientist or economist bandwidth to conduct causal studies. We offer OpportunityFinder as a solution for commonly performed causal studies with four key features: (1) easy to use for both Business Analysts a
    
[^30]: Lamarck的复仇：学习特征的遗传可以使机器人进化更好

    Lamarck's Revenge: Inheritance of Learned Traits Can Make Robot Evolution Better. (arXiv:2309.13099v1 [cs.RO])

    [http://arxiv.org/abs/2309.13099](http://arxiv.org/abs/2309.13099)

    本研究使用进化机器人模拟实验探索了18世纪生物学家Lamarck的遗传理论，发现个体通过学习获得的特征可以通过遗传传递给后代，这对进化动力学和遗传学有重要的新见解。

    

    进化机器人系统提供了两个主要的优势：通过进化优化来发展机器人的先进方法和用于进行关于进化问题的假设实验的特殊研究平台。我们的研究处于这两者的交叉点上。我们通过进化机器人框架的模拟研究一个问题：“如果18世纪生物学家Lamarck并非完全错误，个体在一生中学习到的特征是否可以通过遗传传递给后代？”我们比较了一个Lamarckian系统（学习到的大脑部分可以遗传）和一个Darwinian系统（学习到的大脑部分不能遗传），并通过分析基于这些系统的模拟实验，获得了关于Lamarckian进化动力学以及遗传和学习之间相互作用的新见解。

    Evolutionary robot systems offer two principal advantages: an advanced way of developing robots through evolutionary optimization and a special research platform to conduct what-if experiments regarding questions about evolution. Our study sits at the intersection of these. We investigate the question ``What if the 18th-century biologist Lamarck was not completely wrong and individual traits learned during a lifetime could be passed on to offspring through inheritance?'' We research this issue through simulations with an evolutionary robot framework where morphologies (bodies) and controllers (brains) of robots are evolvable and robots also can improve their controllers through learning during their lifetime. Within this framework, we compare a Lamarckian system, where learned bits of the brain are inheritable, with a Darwinian system, where they are not. Analyzing simulations based on these systems, we obtain new insights about Lamarckian evolution dynamics and the interaction between
    
[^31]: 计算自然哲学: 从前苏格拉底到图灵到ChatGPT的线索

    Computational Natural Philosophy: A Thread from Presocratics through Turing to ChatGPT. (arXiv:2309.13094v1 [cs.GL])

    [http://arxiv.org/abs/2309.13094](http://arxiv.org/abs/2309.13094)

    现代计算自然哲学将宇宙概念化为信息和计算，推动了智能研究的发展，如基于深度神经网络的ChatGPT。这种计算视角结合了多领域知识，并利用强化学习与人类反馈。当前的研究旨在将神经网络与符号计算相结合，引入了新一代的混合计算模型。

    

    现代计算自然哲学以信息和计算的概念化物质宇宙，并建立了认知和智能研究的框架。尽管存在一些批评，但这种计算视角对我们对自然界的理解产生了重要影响，推动了基于深度神经网络的ChatGPT等人工智能系统的发展。该领域的进展得益于跨学科研究，将多个领域的知识整合起来模拟复杂系统。大型语言模型（LLMs），如ChatGPT，代表了这种方法的能力，利用强化学习与人类反馈（RLHF）。目前的研究倡导将神经网络与符号计算相结合，引入新一代的混合计算模型。

    Modern computational natural philosophy conceptualizes the universe in terms of information and computation, establishing a framework for the study of cognition and intelligence. Despite some critiques, this computational perspective has significantly influenced our understanding of the natural world, leading to the development of AI systems like ChatGPT based on deep neural networks. Advancements in this domain have been facilitated by interdisciplinary research, integrating knowledge from multiple fields to simulate complex systems. Large Language Models (LLMs), such as ChatGPT, represent this approach's capabilities, utilizing reinforcement learning with human feedback (RLHF). Current research initiatives aim to integrate neural networks with symbolic computing, introducing a new generation of hybrid computational models.
    
[^32]: MiChao-HuaFen 1.0：面向领域特定大模型的专用预训练语料数据集

    MiChao-HuaFen 1.0: A Specialized Pre-trained Corpus Dataset for Domain-specific Large Models. (arXiv:2309.13079v1 [cs.CL])

    [http://arxiv.org/abs/2309.13079](http://arxiv.org/abs/2309.13079)

    MiChao-HuaFen 1.0是一个专为新闻和政府部门定制的面向领域特定大模型的预训练语料数据集，它不仅能够满足特定领域的高质量需求，还有助于推动相关领域的深度学习研究和应用。

    

    随着深度学习技术的进步，如GPT-4等通用大模型已经在各个领域展现出卓越的能力。然而，在诸如医疗、法律和金融等领域仍然存在对高质量的领域特定输出的需求。本文首先评估了现有的面向特定领域的大模型，并讨论了它们的局限性。为了满足特定领域的特殊需求，我们引入了“MiChao-HuaFen 1.0”预训练语料数据集，该数据集特别针对新闻和政府部门。该数据集来源于2022年公开可用的互联网数据，经过多轮清洁和处理以确保高质量和可靠性，并具备持续和稳定的更新机制。该数据集不仅支持针对中文垂直领域的大模型的预训练，还助力于推动相关领域的深度学习研究和应用。

    With the advancement of deep learning technologies, general-purpose large models such as GPT-4 have demonstrated exceptional capabilities across various domains. Nevertheless, there remains a demand for high-quality, domain-specific outputs in areas like healthcare, law, and finance. This paper first evaluates the existing large models for specialized domains and discusses their limitations. To cater to the specific needs of certain domains, we introduce the ``MiChao-HuaFen 1.0'' pre-trained corpus dataset, tailored for the news and governmental sectors. The dataset, sourced from publicly available internet data from 2022, underwent multiple rounds of cleansing and processing to ensure high quality and reliable origins, with provisions for consistent and stable updates. This dataset not only supports the pre-training of large models for Chinese vertical domains but also aids in propelling deep learning research and applications in related fields.
    
[^33]: LPML: 数学推理的LLM提示标记语言

    LPML: LLM-Prompting Markup Language for Mathematical Reasoning. (arXiv:2309.13078v1 [cs.AI])

    [http://arxiv.org/abs/2309.13078](http://arxiv.org/abs/2309.13078)

    本论文提出了LPML，一种用于数学推理的LLM提示标记语言。通过将Chain-of-Thought方法和Python REPL与该标记语言结合，我们能够控制LLM生成文本中的错误，并增强其推理能力。我们的方法能够实现利用Python计算纠正错误和解决挑战性数学问题，而只需要零样本提示。

    

    在利用大型语言模型（LLMs）进行数学推理时，解决LLMs生成文本中的推理和计算错误是一个关键挑战。在本文中，我们提出了一种新的框架，将Chain-of-Thought（CoT）方法与外部工具（Python REPL）相结合。我们发现，通过提示LLMs生成类似XML标记语言的结构化文本，我们可以无缝地集成CoT和外部工具，并控制LLMs的不良行为。通过我们的方法，LLMs可以利用Python计算来纠正CoT中的错误。我们将我们的方法应用于ChatGPT（GPT-3.5）来解决具有挑战性的数学问题，并证明通过标记语言将CoT和Python REPL结合起来可以增强LLMs的推理能力。我们的方法使LLMs能够使用零样本提示编写标记语言，并进行高级数学推理。

    In utilizing large language models (LLMs) for mathematical reasoning, addressing the errors in the reasoning and calculation present in the generated text by LLMs is a crucial challenge. In this paper, we propose a novel framework that integrates the Chain-of-Thought (CoT) method with an external tool (Python REPL). We discovered that by prompting LLMs to generate structured text in XML-like markup language, we could seamlessly integrate CoT and the external tool and control the undesired behaviors of LLMs. With our approach, LLMs can utilize Python computation to rectify errors within CoT. We applied our method to ChatGPT (GPT-3.5) to solve challenging mathematical problems and demonstrated that combining CoT and Python REPL through the markup language enhances the reasoning capability of LLMs. Our approach enables LLMs to write the markup language and perform advanced mathematical reasoning using only zero-shot prompting.
    
[^34]: 一种可微分的端到端混合结构压缩学习框架

    A Differentiable Framework for End-to-End Learning of Hybrid Structured Compression. (arXiv:2309.13077v1 [cs.LG])

    [http://arxiv.org/abs/2309.13077](http://arxiv.org/abs/2309.13077)

    提出了一个可微分的端到端混合结构压缩学习框架，该框架能够在单一的分析公式中融合滤波器选择、秩选择和预算约束，并通过梯度优化实现端到端学习。实验证明了该框架的有效性，超过了现有的结构化压缩方法。

    

    滤波器剪枝和低秩分解是结构化压缩的两个基本技术。虽然最近的研究尝试了整合这两种技术优势的混合方法，但性能提升一直很有限。本研究提出了一个称为Differentiable Framework (DF)的框架，它能够将滤波器选择、秩选择和预算约束融合成一个单一的分析公式。在该框架下，我们引入了用于滤波器选择的DML-S，将调度集成到现有的掩码学习技术中。此外，我们还提出了用于秩选择的DTL-S，利用奇异值阈值运算符。DF框架结合DML-S和DTL-S提供了一种混合结构压缩方法，在梯度优化的过程中实现了端到端学习。实验证明了DF的有效性，超过了现有的结构化压缩方法。我们的工作为建立一个强大而通用的研究方向奠定了基础。

    Filter pruning and low-rank decomposition are two of the foundational techniques for structured compression. Although recent efforts have explored hybrid approaches aiming to integrate the advantages of both techniques, their performance gains have been modest at best. In this study, we develop a \textit{Differentiable Framework~(DF)} that can express filter selection, rank selection, and budget constraint into a single analytical formulation. Within the framework, we introduce DML-S for filter selection, integrating scheduling into existing mask learning techniques. Additionally, we present DTL-S for rank selection, utilizing a singular value thresholding operator. The framework with DML-S and DTL-S offers a hybrid structured compression methodology that facilitates end-to-end learning through gradient-base optimization. Experimental results demonstrate the efficacy of DF, surpassing state-of-the-art structured compression methods. Our work establishes a robust and versatile avenue fo
    
[^35]: SCREWS: 一种用于推理修订的模块化框架

    SCREWS: A Modular Framework for Reasoning with Revisions. (arXiv:2309.13075v1 [cs.AI])

    [http://arxiv.org/abs/2309.13075](http://arxiv.org/abs/2309.13075)

    SCREWS是一个模块化框架，用于推理修订。它能够统一先前的方法并提供新的策略来识别改进的推理链。在多样的推理任务上，使用最先进的LLMs（ChatGPT和GPT-4）评估SCREWS的性能，并发现了有用的新的推理策略。

    

    大型语言模型 (LLMs) 可以通过根据反馈不断改进和修订其输出来提高在各种任务上的准确性。我们观察到这些修订可能会引入错误，如果是这样的话，最好回滚到先前的结果。此外，修订通常是同质的：它们使用与产生初始答案的相同推理方法，这可能无法纠正错误。为了在这个领域中进行探索，我们提出了 SCREWS，一种用于推理修订的模块化框架。它由三个主要模块组成: 采样、条件重新采样和选择，每个模块都包含可以根据任务手动选择的子模块。我们展示了 SCREWS 不仅将几个先前的方法统一到一个共同的框架中，还揭示了几种用于识别改进的推理链的新策略。我们使用最先进的LLMs （ChatGPT 和 GPT-4）在多样的推理任务上评估我们的框架，并揭示了有用的新的推理策略。

    Large language models (LLMs) can improve their accuracy on various tasks through iteratively refining and revising their output based on feedback. We observe that these revisions can introduce errors, in which case it is better to roll back to a previous result. Further, revisions are typically homogeneous: they use the same reasoning method that produced the initial answer, which may not correct errors. To enable exploration in this space, we present SCREWS, a modular framework for reasoning with revisions. It is comprised of three main modules: Sampling, Conditional Resampling, and Selection, each consisting of sub-modules that can be hand-selected per task. We show that SCREWS not only unifies several previous approaches under a common framework, but also reveals several novel strategies for identifying improved reasoning chains. We evaluate our framework with state-of-the-art LLMs (ChatGPT and GPT-4) on a diverse set of reasoning tasks and uncover useful new reasoning strategies fo
    
[^36]: 基于神经符号方法的弱监督推理

    Weakly Supervised Reasoning by Neuro-Symbolic Approaches. (arXiv:2309.13072v1 [cs.CL])

    [http://arxiv.org/abs/2309.13072](http://arxiv.org/abs/2309.13072)

    本文介绍了一种基于神经符号方法的弱监督推理框架，该框架将符号主义和连接主义结合起来，成功应用于各种自然语言处理任务，并通过设计具有符号潜在结构的神经系统，并应用强化学习或松弛方法来进行推理。

    

    深度学习极大地提高了各种自然语言处理（NLP）任务的性能。然而，大多数深度学习模型是黑盒机器，缺乏明确的解释。在本章中，我们将介绍我们在NLP方面的神经符号方法的最新进展，该方法结合了不同的人工智能学派，即符号主义和连接主义。一般而言，我们会设计一个带有符号潜在结构的神经系统，用于NLP任务，并应用强化学习或其松弛方法来进行下游任务中的弱监督推理。我们的框架已成功应用于各种任务，包括表格查询推理、句法结构推理、信息抽取推理和规则推理。对于每个应用，我们将介绍背景、我们的方法和实验结果。

    Deep learning has largely improved the performance of various natural language processing (NLP) tasks. However, most deep learning models are black-box machinery, and lack explicit interpretation. In this chapter, we will introduce our recent progress on neuro-symbolic approaches to NLP, which combines different schools of AI, namely, symbolism and connectionism. Generally, we will design a neural system with symbolic latent structures for an NLP task, and apply reinforcement learning or its relaxation to perform weakly supervised reasoning in the downstream task. Our framework has been successfully applied to various tasks, including table query reasoning, syntactic structure reasoning, information extraction reasoning, and rule reasoning. For each application, we will introduce the background, our approach, and experimental results.
    
[^37]: 基于树的重建分区：一种新颖的低数据级生成方法

    Tree-Based Reconstructive Partitioning: A Novel Low-Data Level Generation Approach. (arXiv:2309.13071v1 [cs.AI])

    [http://arxiv.org/abs/2309.13071](http://arxiv.org/abs/2309.13071)

    基于树的重建分区（TRP）是一种新颖的PCGML方法，能够在游戏开发的早期阶段引入，无需人类专业知识或大量训练数据。

    

    程序化内容生成（PCG）是一种算法生成内容的方法，通常应用于游戏。已经有一些基于机器学习的PCG方法出现在已发表的游戏中。然而，在游戏开发的早期阶段应用这些方法可能会很困难。PCG需要在规则或函数中表示设计师对质量的概念的专业知识，而基于机器学习的PCG通常需要大量的训练数据，这在开发初期可能无法获取。本文介绍了一种名为基于树的重建分区（TRP）的新颖PCGML方法，旨在解决这个问题。我们在两个领域的实验结果表明，TRP生成的关卡更具可玩性和连贯性，并且这种方法在使用较少训练数据的情况下更具泛化能力。我们认为TRP是一种有前途的新方法，可以使PCGML在游戏开发的早期阶段引入，而不需要人类专业知识或大量训练数据。

    Procedural Content Generation (PCG) is the algorithmic generation of content, often applied to games. PCG and PCG via Machine Learning (PCGML) have appeared in published games. However, it can prove difficult to apply these approaches in the early stages of an in-development game. PCG requires expertise in representing designer notions of quality in rules or functions, and PCGML typically requires significant training data, which may not be available early in development. In this paper, we introduce Tree-based Reconstructive Partitioning (TRP), a novel PCGML approach aimed to address this problem. Our results, across two domains, demonstrate that TRP produces levels that are more playable and coherent, and that the approach is more generalizable with less training data. We consider TRP to be a promising new approach that can afford the introduction of PCGML into the early stages of game development without requiring human expertise or significant training data.
    
[^38]: InvestLM：使用金融领域指导调优的大型语言模型

    InvestLM: A Large Language Model for Investment using Financial Domain Instruction Tuning. (arXiv:2309.13064v1 [q-fin.GN])

    [http://arxiv.org/abs/2309.13064](http://arxiv.org/abs/2309.13064)

    InvestLM是一个通过对金融领域指导数据集进行调优的大型语言模型，具有强大的理解金融文本的能力，并在投资相关问题上提供有帮助的回答。金融专家评价其与最先进的商业模型可媲美，并在金融NLP基准问题上展现了强大的泛化能力。

    

    我们介绍了一种新的金融领域大型语言模型InvestLM，该模型通过精心策划的与金融投资相关的指导数据集对LLaMA-65B进行调优。受到“少即是多”的启发，我们手动策划了一个既小又多样的指导数据集，涵盖了从特许金融分析师（CFA）考试问题到SEC文件和Stackexchange量化金融讨论的广泛金融相关主题。InvestLM表现出良好的理解金融文本的能力，并对投资相关问题提供有帮助的回答。包括对冲基金经理和研究分析师在内的金融专家将InvestLM的回答评价为与最先进的商业模型（GPT-3.5、GPT-4和Claude-2）可媲美。对一组金融NLP基准问题进行零样本评估表明了其强大的泛化能力。从研究角度来看，本研究表明可以使用高质量的领域特定LLM进行调优。

    We present a new financial domain large language model, InvestLM, tuned on LLaMA-65B (Touvron et al., 2023), using a carefully curated instruction dataset related to financial investment. Inspired by less-is-more-for-alignment (Zhou et al., 2023), we manually curate a small yet diverse instruction dataset, covering a wide range of financial related topics, from Chartered Financial Analyst (CFA) exam questions to SEC filings to Stackexchange quantitative finance discussions. InvestLM shows strong capabilities in understanding financial text and provides helpful responses to investment related questions. Financial experts, including hedge fund managers and research analysts, rate InvestLM's response as comparable to those of state-of-the-art commercial models (GPT-3.5, GPT-4 and Claude-2). Zero-shot evaluation on a set of financial NLP benchmarks demonstrates strong generalizability. From a research perspective, this work suggests that a high-quality domain specific LLM can be tuned usin
    
[^39]: 使用大型语言模型生成、验证和应用用户意图分类方法

    Using Large Language Models to Generate, Validate, and Apply User Intent Taxonomies. (arXiv:2309.13063v1 [cs.IR])

    [http://arxiv.org/abs/2309.13063](http://arxiv.org/abs/2309.13063)

    通过使用大型语言模型生成用户意图分类，我们提出了一种新方法来分析和验证日志数据中的用户意图，从而解决了手动或基于机器学习的标注方法在大型和不断变化的数据集上的问题。

    

    日志数据可以揭示用户与网络搜索服务的交互方式、用户的需求以及满意程度等宝贵信息。然而，分析日志数据中的用户意图并不容易，尤其是对于新的网络搜索形式，如人工智能驱动的聊天。为了理解日志数据中的用户意图，我们需要一种能够用有意义的分类方式标记它们的方法，以捕捉其多样性和动态性。现有的方法依赖于手动或基于机器学习的标注，这些方法对于大型且不断变化的数据集而言，要么代价高昂要么不够灵活。我们提出了一种使用大型语言模型(LLM)的新方法，这种模型能够生成丰富且相关的概念、描述和示例来表示用户意图。然而，使用LLM生成用户意图分类并将其应用于日志分析可能存在两个主要问题：这样的分类得不到外部验证，并且可能存在不良的反馈回路。为了克服这些问题，我们提出了一种新的方法，通过人工专家和评估者来验证。

    Log data can reveal valuable information about how users interact with web search services, what they want, and how satisfied they are. However, analyzing user intents in log data is not easy, especially for new forms of web search such as AI-driven chat. To understand user intents from log data, we need a way to label them with meaningful categories that capture their diversity and dynamics. Existing methods rely on manual or ML-based labeling, which are either expensive or inflexible for large and changing datasets. We propose a novel solution using large language models (LLMs), which can generate rich and relevant concepts, descriptions, and examples for user intents. However, using LLMs to generate a user intent taxonomy and apply it to do log analysis can be problematic for two main reasons: such a taxonomy is not externally validated, and there may be an undesirable feedback loop. To overcome these issues, we propose a new methodology with human experts and assessors to verify th
    
[^40]: 用个人AI导师实施学习原理：一个案例研究

    Implementing Learning Principles with a Personal AI Tutor: A Case Study. (arXiv:2309.13060v1 [cs.CY])

    [http://arxiv.org/abs/2309.13060](http://arxiv.org/abs/2309.13060)

    本研究通过将AI导师与学习计划相结合，实施了个性化、检索练习和间隔重复等学习原理，研究结果显示，积极使用AI导师参与学习的学生获得了显著更高的成绩。

    

    基于个性化、检索练习和间隔重复等原则的有效学习策略往往难以在实践中实施。在这里，我们探索了将AI导师与学习计划相结合，根据学习科学进行补充。在UniDistance Suisse进行了一个学期长的研究，将一个AI导师应用提供给修读神经科学课程的心理学学生（N=51）。通过使用GPT-3从现有课程材料自动生成微学习问题，AI导师开发了每个学生对关键概念的理解的动态神经网络模型。这使得可以根据每个学生个体水平和能力个性化实施分布式检索练习。结果表明，积极使用AI导师参与学习的学生获得了显著更高的成绩。此外，积极参与导致平均提高了最多15个百分点，相比于平行课程。

    Effective learning strategies based on principles like personalization, retrieval practice, and spaced repetition are often challenging to implement due to practical constraints. Here we explore the integration of AI tutors to complement learning programs in accordance with learning sciences. A semester-long study was conducted at UniDistance Suisse, where an AI tutor app was provided to psychology students taking a neuroscience course (N=51). After automatically generating microlearning questions from existing course materials using GPT-3, the AI tutor developed a dynamic neural-network model of each student's grasp of key concepts. This enabled the implementation of distributed retrieval practice, personalized to each student's individual level and abilities. The results indicate that students who actively engaged with the AI tutor achieved significantly higher grades. Moreover, active engagement led to an average improvement of up to 15 percentile points compared to a parallel cours
    
[^41]: 超越传统教学：大型语言模型和聊天机器人在研究生工程教育中的潜力

    Beyond Traditional Teaching: The Potential of Large Language Models and Chatbots in Graduate Engineering Education. (arXiv:2309.13059v1 [cs.CY])

    [http://arxiv.org/abs/2309.13059](http://arxiv.org/abs/2309.13059)

    大型语言模型和聊天机器人在研究生工程教育中有着巨大的潜力，研究发现它们能够准确回答复杂问题，并在课堂上带来潜在的优势。

    

    在教育领域快速发展的环境中，数字技术一再打破传统教学方法。本文探讨了最新的这些颠覆：大型语言模型（LLMs）和聊天机器人在研究生工程教育中的潜力融合。我们首先追溯历史和技术的颠覆，以提供背景，然后介绍关键术语，如机器学习和深度学习，以及最近进展的基本机制，即注意力/变压器模型和图形处理单元。我们研究的核心是将基于LLM的聊天机器人应用于研究生流体力学课程。我们从课程材料中构建了一个问题库，并评估了聊天机器人提供准确、有见地的回答的能力。结果令人鼓舞，不仅展示了机器人回答复杂问题的能力，还展示了课堂上使用聊天机器人的潜在优势，例如…

    In the rapidly evolving landscape of education, digital technologies have repeatedly disrupted traditional pedagogical methods. This paper explores the latest of these disruptions: the potential integration of large language models (LLMs) and chatbots into graduate engineering education. We begin by tracing historical and technological disruptions to provide context and then introduce key terms such as machine learning and deep learning and the underlying mechanisms of recent advancements, namely attention/transformer models and graphics processing units. The heart of our investigation lies in the application of an LLM-based chatbot in a graduate fluid mechanics course. We developed a question bank from the course material and assessed the chatbot's ability to provide accurate, insightful responses. The results are encouraging, demonstrating not only the bot's ability to effectively answer complex questions but also the potential advantages of chatbot usage in the classroom, such as th
    
[^42]: 原创性与生成式人工智能时代版权的未来

    Originality and the Future of Copyright in an Age of Generative AI. (arXiv:2309.13055v1 [cs.CY])

    [http://arxiv.org/abs/2309.13055](http://arxiv.org/abs/2309.13055)

    生成式人工智能工具创作的作品引发了关于人类创作权的问题。

    

    本文探讨了当作品通过生成式人工智能工具创建时，人类创作权的问题。

    This papers explores the question of human authorship when works are created with generative AI tools.
    
[^43]: 数据共享平台

    Data Commons. (arXiv:2309.13054v1 [cs.CY])

    [http://arxiv.org/abs/2309.13054](http://arxiv.org/abs/2309.13054)

    数据共享平台旨在帮助用户轻松访问和利用公共数据，并解决数据整理的耗时和繁琐问题，使不同数据源的数据可以方便地合并和交互使用。

    

    来自公开数据源（例如美国人口普查局（人口普查）、世界卫生组织（WHO）、政府间气候变化专门委员会（IPCC））的公共可用数据是政策制定者、学生和跨学科研究人员的重要资源。将来自不同源头的数据组合起来需要用户解决模式、格式、假设等方面的差异。这种数据整理耗时、繁琐，每个使用数据的用户都需要重复进行。我们希望通过数据共享平台（DC）帮助将公共数据变得可访问且有用，以解决社会挑战和机遇。我们进行数据处理，并通过标准模式和云API广泛提供已处理的数据。数据共享平台是一个分布式网络，通过数据共享平台API进行互操作，并使用公共模式发布数据的网站。不同数据共享平台的数据可以轻松合并。所有数据共享平台的总和可以帮助人们充分利用公共数据，解决社会挑战和机遇。

    Publicly available data from open sources (e.g., United States Census Bureau (Census), World Health Organization (WHO), Intergovernmental Panel on Climate Change (IPCC)) are vital resources for policy makers, students and researchers across different disciplines. Combining data from different sources requires the user to reconcile the differences in schemas, formats, assumptions, and more. This data wrangling is time consuming, tedious and needs to be repeated by every user of the data. Our goal with Data Commons (DC) is to help make public data accessible and useful to those who want to understand this data and use it to solve societal challenges and opportunities. We do the data processing and make the processed data widely available via standard schemas and Cloud APIs. Data Commons is a distributed network of sites that publish data in a common schema and interoperate using the Data Commons APIs. Data from different Data Commons can be joined easily. The aggregate of these Data Comm
    
[^44]: 使用课程理论指导学校中生成式人工智能的方法

    Using Curriculum Theory to Inform Approaches to Generative AI in Schools. (arXiv:2309.13053v1 [cs.CY])

    [http://arxiv.org/abs/2309.13053](http://arxiv.org/abs/2309.13053)

    本文通过使用课程理论，探讨了中学教育中生成式人工智能所需的紧迫课程改革，并分析了将新兴技术融入课程结构所面临的挑战和困境。最后，研究人员提供了一些关于时间表、教材编写和教学方法的建议。

    

    在迅速增长的大型语言模型的教育背景下，本文探讨了中学教育所需的紧迫课程改革。以Madeline Grumet的课程研究三元框架为基础，研究界定了生成式人工智能与Elliot Eisner的显性、隐性和无实际目标课程概念之间的多维关系。研究审视了教育工作者在将这一新兴技术融入历史悠久的课程结构时所面临的物流和道德挑战，例如 AI 检测器的可靠性。通过接触Ted Aoki的“中间区域”理论，本文阐明了教育工作者在协调规定性课程目标与教室生活的变动真实性之间的困境，所有这些都发生在由于生成式人工智能持续变化的教育环境中。论文最后通过研究人员的反思分析，确定了时间表、教材的编写和教学方法的自主选择等主要问题，为将生成式人工智能引入学校提供了一些建议。

    In an educational landscape dramatically altered by the swift proliferation of Large Language Models, this essay interrogates the urgent this essay interrogates the urgent pedagogical modifications required in secondary schooling. Anchored in Madeline Grumet's triadic framework of curriculum inquiry, the study delineates the multifaceted relationship between Generative AI and Elliot Eisner's explicit, implicit, and null curriculum concepts. It scrutinizes the logistical and ethical challenges, such as the reliability of AI detectors, that educators confront when attempting to assimilate this nascent technology into long-standing curricular structures. Engaging with Ted Aoki's theory of the "zone of between", the essay illuminates educators' dilemmas in reconciling prescriptive curricular aims with the fluid realities of classroom life, all within an educational milieu in constant flux due to Generative AI. The paper culminates in a reflective analysis by the researcher, identifying ave
    
[^45]: 伊朗法律和规定的语境主题建模和内容分析

    A Contextual Topic Modeling and Content Analysis of Iranian laws and Regulations. (arXiv:2309.13051v1 [cs.CY])

    [http://arxiv.org/abs/2309.13051](http://arxiv.org/abs/2309.13051)

    本研究通过主题建模方法分析了伊朗法律，从中识别出了包括经济、海关、住房与城市发展、农业、保险、法律和司法、文化、信息技术、政治和政府在内的10个主题，并发现经济是规定中最重要的主题。

    

    宪法是一个国家最高的法律文件，它作为其他法律建立的指南。宪法定义了一个国家政府的政治原则、结构、等级、职位和权力的限制。它确定并保障公民的权利。本研究旨在对伊朗法律进行主题建模。作为研究的一部分，从Dotic网站收集了11760条法律。然后，使用LDA对法规的标题和内容进行主题建模。通过主题建模的数据分析，确定了10个主题，包括经济、海关、住房与城市发展、农业、保险、法律和司法、文化、信息技术、政治和政府。最大的主题是经济，占规定的29%，而最小的主题是政治和政府，占2%。本研究利用主题建模方法来探索法律文本并识别趋势。

    A constitution is the highest legal document of a country and serves as a guide for the establishment of other laws. The constitution defines the political principles, structure, hierarchy, position, and limits of the political power of a country's government. It determines and guarantees the rights of citizens. This study aimed at topic modeling of Iranian laws. As part of this research, 11760 laws were collected from the Dotic website. Then, topic modeling was conducted on the title and content of the regularizations using LDA. Data analysis with topic modeling led to the identification of 10 topics including Economic, Customs, Housing and Urban Development, Agriculture, Insurance, Legal and judicial, Cultural, Information Technology, Political, and Government. The largest topic, Economic, accounts for 29% of regulations, while the smallest are Political and Government, accounting for 2%. This research utilizes a topic modeling method in exploring law texts and identifying trends in 
    
[^46]: 基于人工智能的个性化减重装置处方：预防糖尿病相关前足溃疡和并发症的尖端方法

    AI-Driven Personalised Offloading Device Prescriptions: A Cutting-Edge Approach to Preventing Diabetes-Related Plantar Forefoot Ulcers and Complications. (arXiv:2309.13049v1 [cs.CY])

    [http://arxiv.org/abs/2309.13049](http://arxiv.org/abs/2309.13049)

    基于人工智能的个性化减重装置处方是一个先进解决方案，通过识别高风险区域和推荐精确的减重策略，有效预防糖尿病相关前足溃疡和并发症。

    

    糖尿病相关足溃疡和并发症对糖尿病患者来说是一个重要的问题，会导致严重的健康问题，如下肢截肢和生活质量降低。本章讨论了应用基于人工智能的个性化减重装置处方作为预防这些状况的先进解决方案。通过利用人工智能的能力，这一尖端方法能够根据每个患者的特定需求来开具减重装置处方。包括患者对减重装置（如鞋类和足部矫形器）的偏好以及适合患者使用意图和生活方式的适应性。通过一系列研究、实际数据分析和机器学习算法，可以识别高风险区域，从而推荐精确的减重策略，包括定制矫形鞋垫、鞋类改造或专门的鞋类。通过包括患者特定需求的个性化减重装置处方，可以有效预防糖尿病相关前足溃疡和并发症。

    Diabetes-related foot ulcers and complications are a significant concern for individuals with diabetes, leading to severe health implications such as lower-limb amputation and reduced quality of life. This chapter discusses applying AI-driven personalised offloading device prescriptions as an advanced solution for preventing such conditions. By harnessing the capabilities of artificial intelligence, this cutting-edge approach enables the prescription of offloading devices tailored to each patient's specific requirements. This includes the patient's preferences on offloading devices such as footwear and foot orthotics and their adaptations that suit the patient's intention of use and lifestyle. Through a series of studies, real-world data analysis and machine learning algorithms, high-risk areas can be identified, facilitating the recommendation of precise offloading strategies, including custom orthotic insoles, shoe adaptations, or specialised footwear. By including patient-specific f
    
[^47]: 这篇论文的标题是什么？使用算法解决逻辑谜题。

    What is the Title of this Paper? Solving logic puzzles using algorithms. (arXiv:2309.13044v1 [cs.LO])

    [http://arxiv.org/abs/2309.13044](http://arxiv.org/abs/2309.13044)

    本文研究使用Python算法自动解决了骑士与诡计逻辑谜题，提供了一种高效和易于使用的计算方法，通过解析陈述并进行逻辑推理来推断角色的真实身份。

    

    该研究深入探讨了逻辑谜题领域，并专注于雷蒙德·斯穆利安在他的《这本书的名字是什么？》系列中推广的骑士与诡计问题。这些谜题围绕着被称为骑士（讲真话者）和诡计（说谎者）的角色展开，挑战解题者根据他们的陈述来确定每个人的真实身份。本论文探索了利用Python算法自动化解决这些谜题的过程，提供了一种增强效率和可访问性的计算方法。在本研究中，我们旨在开发一个能够解析和分析骑士与诡计谜题中所提供陈述的Python算法。该算法集成了逻辑推理框架，根据陈述推断角色的身份。算法处理输入的陈述，创建知识库，并按照骑士与诡计逻辑的规则进行推理。已经对该算法进行了彻底的

    This work delves into the realm of logic puzzles by focusing on the Knight and Knave problems popularized by Raymond Smullyan in his book series "What is the Name of This Book?". The puzzles revolve around characters known as Knights (truth-tellers) and Knaves (liars), challenging solvers to determine the true identity of each person based on their statements. This paper explores the utilization of Python algorithms to automate the process of solving these puzzles, offering a computational approach that enhances efficiency and accessibility. In this work, we aim to develop a Python algorithm capable of parsing and analyzing the statements provided in the Knight and Knave puzzles. A logical reasoning framework is integrated within the algorithm to deduce the identities of the characters based on their statements. The algorithm processes the input statements, create a knowledge base, and make deductions following the rules of Knight and Knave logic. The developed algorithm is thoroughly 
    
[^48]: 大型语言模型下的创造力支持: 一项涉及新兴作家的实证研究

    Creativity Support in the Age of Large Language Models: An Empirical Study Involving Emerging Writers. (arXiv:2309.12570v1 [cs.HC])

    [http://arxiv.org/abs/2309.12570](http://arxiv.org/abs/2309.12570)

    本文通过实证研究探讨了大型语言模型（LLM）在协助专业作家方面的效用，并发现作家们更倾向于在翻译和审查阶段中寻求LLM的帮助。

    

    大型语言模型（LLM）的发展使得其能够遵循指令并参与对话互动，引发了在各种支持工具中利用它们的兴趣增加。我们通过一项实证用户研究（n=30）探讨了现代LLM在协助专业作家方面的效用。我们的合作写作界面设计基于将写作视为一个目标导向的思维过程的认知过程模型，涵盖了非线性的认知活动：规划、翻译和审查。参与者被要求提交一份后完成调查，以提供关于LLM作为写作合作者潜力和问题的反馈。通过分析作家-LLM互动,我们发现作家在三种类型的认知活动中都寻求LLM的帮助，但他们发现LLM在翻译和审查方面更有帮助。通过分析互动和调查结果，我们的发现强调了未来研究的方向。

    The development of large language models (LLMs) capable of following instructions and engaging in conversational interactions sparked increased interest in their utilization across various support tools. We investigate the utility of modern LLMs in assisting professional writers via an empirical user study (n=30). The design of our collaborative writing interface is grounded in the cognitive process model of writing that views writing as a goal-oriented thinking process encompassing non-linear cognitive activities: planning, translating, and reviewing. Participants are asked to submit a post-completion survey to provide feedback on the potential and pitfalls of LLMs as writing collaborators. Upon analyzing the writer-LLM interactions, we find that while writers seek LLM's help across all three types of cognitive activities, they find LLMs more helpful in translation and reviewing. Our findings from analyzing both the interactions and the survey responses highlight future research direc
    
[^49]: ForceSight: 使用文本引导的视觉力导向移动操作

    ForceSight: Text-Guided Mobile Manipulation with Visual-Force Goals. (arXiv:2309.12312v1 [cs.RO])

    [http://arxiv.org/abs/2309.12312](http://arxiv.org/abs/2309.12312)

    ForceSight是一个使用文本引导的移动操作系统，通过深度神经网络预测视觉力导向目标。在实验中，该系统展示了在未见环境中进行精确抓取、抽屉打开和物体交接等任务的能力，并取得了较高的成功率。

    

    我们提出了一个名为ForceSight的系统，它使用深度神经网络通过文本引导来预测视觉力导向的目标。给定一张RGBD图片和一个文本提示，ForceSight可以确定相机坐标系下的目标末端执行器位姿（运动目标）和相关的力量（力量目标）。这两个组成部分共同形成了一个视觉力导向目标。之前的研究已经表明，输出人可解释的运动目标的深度模型可以实现真实机器人的巧妙操作。力量在操作中至关重要，但在这些系统中通常被限制在较低层次的执行中。当应用于带有手臂和眼睛的移动操作装置的ForceSight时，在与训练数据差异显著的未见环境中，能够以81%的成功率完成诸如精确抓取、抽屉打开和物体交接等任务。在另一项独立实验中，ForceSight仅使用视觉伺服，不考虑力量信息，但依然显示出较高的操作成功率。

    We present ForceSight, a system for text-guided mobile manipulation that predicts visual-force goals using a deep neural network. Given a single RGBD image combined with a text prompt, ForceSight determines a target end-effector pose in the camera frame (kinematic goal) and the associated forces (force goal). Together, these two components form a visual-force goal. Prior work has demonstrated that deep models outputting human-interpretable kinematic goals can enable dexterous manipulation by real robots. Forces are critical to manipulation, yet have typically been relegated to lower-level execution in these systems. When deployed on a mobile manipulator equipped with an eye-in-hand RGBD camera, ForceSight performed tasks such as precision grasps, drawer opening, and object handovers with an 81% success rate in unseen environments with object instances that differed significantly from the training data. In a separate experiment, relying exclusively on visual servoing and ignoring force 
    
[^50]: 学习驾驶到任何地方

    Learning to Drive Anywhere. (arXiv:2309.12295v1 [cs.CV])

    [http://arxiv.org/abs/2309.12295](http://arxiv.org/abs/2309.12295)

    本文提出了一种能够学习适应不同地理位置和驾驶行为的模型，该模型通过引入基于地理位置的通道注意机制，在数据驱动的方式下高效地学习并灵活地建模不同地区之间的相似性和差异性。

    

    人类驾驶员可以无缝地适应不同地理位置的驾驶决策，包括不同的道路条件和交通规则，例如左驾驶和右驾驶。然而，现有的自动驾驶模型只能在限定的操作领域内部署，不能考虑不同地理位置之间的驾驶行为差异和模型的可扩展性。本文提出了AnyD，一种单一的具有地理感知的条件性模仿学习（CIL）模型，能够高效地从具有动态环境、交通和社会特征的异构和全球分布的数据中进行学习。我们的关键见解是引入一个高容量的基于地理位置的通道注意机制，可以在数据驱动的方式下有效地适应本地细微差异并灵活地建模不同地区之间的相似性。通过优化对比性模仿目标，我们提出的方法可以高效地适应固有的不平衡数据分布和地理位置差异。

    Human drivers can seamlessly adapt their driving decisions across geographical locations with diverse conditions and rules of the road, e.g., left vs. right-hand traffic. In contrast, existing models for autonomous driving have been thus far only deployed within restricted operational domains, i.e., without accounting for varying driving behaviors across locations or model scalability. In this work, we propose AnyD, a single geographically-aware conditional imitation learning (CIL) model that can efficiently learn from heterogeneous and globally distributed data with dynamic environmental, traffic, and social characteristics. Our key insight is to introduce a high-capacity geo-location-based channel attention mechanism that effectively adapts to local nuances while also flexibly modeling similarities among regions in a data-driven manner. By optimizing a contrastive imitation objective, our proposed approach can efficiently scale across inherently imbalanced data distributions and loca
    
[^51]: 翻转诅咒: 在大型语言模型中训练的"A是B"无法学习"B是A"

    The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A". (arXiv:2309.12288v1 [cs.CL])

    [http://arxiv.org/abs/2309.12288](http://arxiv.org/abs/2309.12288)

    LLMs模型在训练中只能学习到"A是B"的结构，无法自动推广到"B是A"。这表明模型在逻辑推断上存在基本失败和训练集中模式的推广问题。

    

    我们揭示了自回归大型语言模型（LLM）在泛化上的令人惊讶的失败。如果一个模型是基于"A是B"形式的句子进行训练，它不会自动推广到相反的方向"B是A"。这就是翻转诅咒。例如，如果一个模型是基于"Olaf Scholz是德国第九任总理"进行训练的，它不会自动能够回答问题"谁是德国第九任总理？"。此外，正确答案（"Olaf Scholz"）的可能性不会比随机名字更高。因此，模型在逻辑推断上存在基本失败，并且不会推广到它们训练集中的普遍模式（即如果出现"A是B"，则"B是A"更可能出现）。我们通过在虚构的陈述（如"Uriah Hawthorne是'Abyssal Melodies'的作曲家"）上对GPT-3和Llama-1进行微调，并展示它们无法正确回答"谁创作了'Abyssal Melodies'?"来提供翻转诅咒的证据。

    We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model is trained on a sentence of the form "A is B", it will not automatically generalize to the reverse direction "B is A". This is the Reversal Curse. For instance, if a model is trained on "Olaf Scholz was the ninth Chancellor of Germany", it will not automatically be able to answer the question, "Who was the ninth Chancellor of Germany?". Moreover, the likelihood of the correct answer ("Olaf Scholz") will not be higher than for a random name. Thus, models exhibit a basic failure of logical deduction and do not generalize a prevalent pattern in their training set (i.e. if "A is B'' occurs, "B is A" is more likely to occur). We provide evidence for the Reversal Curse by finetuning GPT-3 and Llama-1 on fictitious statements such as "Uriah Hawthorne is the composer of 'Abyssal Melodies'" and showing that they fail to correctly answer "Who composed 'Abyssal Melodies?'". The Reversal Cu
    
[^52]: OSNet和MNetO：适用于多种场景的线性计算机断层扫描的两种通用重建架构

    OSNet & MNetO: Two Types of General Reconstruction Architectures for Linear Computed Tomography in Multi-Scenarios. (arXiv:2309.11858v1 [cs.CV])

    [http://arxiv.org/abs/2309.11858](http://arxiv.org/abs/2309.11858)

    本论文提出了两种通用的线性计算机断层扫描的重建架构（OSNet和MNetO），旨在解决在LCT中实现稳定内部重建和避免希尔伯特滤波旋转操作的问题。

    

    最近，线性计算机断层扫描（LCT）系统引起了人们的广泛关注。为了减弱LCT中的投影截断并对感兴趣区域（ROI）进行成像，反投影滤波（BPF）算法是一个有效的解决方案。然而，在LCT的BPF中，很难实现稳定的内部重建，并且对于LCT的不同反投影（DBP）图像，多个旋转有限反演的希尔伯特变换（希尔伯特滤波）-反转操作将使图像模糊。为了满足LCT的多种重建场景，包括内部ROI、完整对象和超出视野范围的外部区域，并避免希尔伯特滤波的旋转操作，我们提出了两种重建架构。第一种是叠加多个DBP图像以获得完整的DBP图像，然后使用网络学习叠加的希尔伯特滤波函数，称为叠加单一网络（OSNet）。第二种是使用多个网络训练不同的反投影重构器网络（MNetO）。

    Recently, linear computed tomography (LCT) systems have actively attracted attention. To weaken projection truncation and image the region of interest (ROI) for LCT, the backprojection filtration (BPF) algorithm is an effective solution. However, in BPF for LCT, it is difficult to achieve stable interior reconstruction, and for differentiated backprojection (DBP) images of LCT, multiple rotation-finite inversion of Hilbert transform (Hilbert filtering)-inverse rotation operations will blur the image. To satisfy multiple reconstruction scenarios for LCT, including interior ROI, complete object, and exterior region beyond field-of-view (FOV), and avoid the rotation operations of Hilbert filtering, we propose two types of reconstruction architectures. The first overlays multiple DBP images to obtain a complete DBP image, then uses a network to learn the overlying Hilbert filtering function, referred to as the Overlay-Single Network (OSNet). The second uses multiple networks to train diffe
    
[^53]: 链式验证减少大型语言模型中的幻觉

    Chain-of-Verification Reduces Hallucination in Large Language Models. (arXiv:2309.11495v1 [cs.CL])

    [http://arxiv.org/abs/2309.11495](http://arxiv.org/abs/2309.11495)

    该论文提出了一种链式验证方法（CoVe），通过在回答之前进行备查问题来减少大型语言模型中的幻觉。实验证明CoVe方法在各种任务中都能有效降低幻觉的发生。

    

    大型语言模型中存在生成合理但不正确的事实信息（即幻觉）的问题，我们研究了语言模型在给出回复时进行思考以纠正错误的能力。我们开发了一种链式验证（CoVe）方法，模型首先（i）起草初始回复；然后（ii）计划验证问题来事实检查草稿；（iii）独立回答这些问题，以避免答案受其他回复的影响；最后（iv）生成最终的经过验证的回答。在实验中，我们展示了CoVe在各种任务中降低了幻觉的情况，包括来自维基数据的列表问题、封闭书籍MultiSpanQA和长文本生成。

    Generation of plausible yet incorrect factual information, termed hallucination, is an unsolved issue in large language models. We study the ability of language models to deliberate on the responses they give in order to correct their mistakes. We develop the Chain-of-Verification (CoVe) method whereby the model first (i) drafts an initial response; then (ii) plans verification questions to fact-check its draft; (iii) answers those questions independently so the answers are not biased by other responses; and (iv) generates its final verified response. In experiments, we show CoVe decreases hallucinations across a variety of tasks, from list-based questions from Wikidata, closed book MultiSpanQA and longform text generation.
    
[^54]: 使用深度学习构建具有性能边界的随机局部搜索SAT求解器

    Using deep learning to construct stochastic local search SAT solvers with performance bounds. (arXiv:2309.11452v1 [cs.AI])

    [http://arxiv.org/abs/2309.11452](http://arxiv.org/abs/2309.11452)

    本论文利用深度学习方法构建了一种随机局部搜索SAT求解器，并且使用图神经网络训练了求解SAT问题的“神谕”。实验结果表明，访问基于GNN的神谕显著提高了求解器的性能。

    

    布尔可满足性问题（SAT）是最典型的NP完全问题，具有极大的实际重要性。这个问题的一种重要求解器类别是随机局部搜索（SLS）算法，通过迭代和随机更新候选解来求解。最近，在理论计算机科学领域取得了重大突破，建立了足够的条件，以确保SLS求解器能够有效地求解SAT实例，只要它们可以访问合适的“神谕”，从实例特定的分布中提供样本，利用实例的局部结构。受这些结果以及神经网络在学习大型数据集中常见结构的良好能力的启发，本研究利用图神经网络训练了神谕，并在两个SLS求解器上对具有不同难度的随机SAT实例进行了评估。我们发现，访问基于GNN的神谕显著提高了两个求解器的性能，使它们平均能够解决17个实例。

    The Boolean Satisfiability problem (SAT) is the most prototypical NP-complete problem and of great practical relevance. One important class of solvers for this problem are stochastic local search (SLS) algorithms that iteratively and randomly update a candidate assignment. Recent breakthrough results in theoretical computer science have established sufficient conditions under which SLS solvers are guaranteed to efficiently solve a SAT instance, provided they have access to suitable "oracles" that provide samples from an instance-specific distribution, exploiting an instance's local structure. Motivated by these results and the well established ability of neural networks to learn common structure in large datasets, in this work, we train oracles using Graph Neural Networks and evaluate them on two SLS solvers on random SAT instances of varying difficulty. We find that access to GNN-based oracles significantly boosts the performance of both solvers, allowing them, on average, to solve 17
    
[^55]: Gold-YOLO: 通过收集和分发机制实现高效目标检测器

    Gold-YOLO: Efficient Object Detector via Gather-and-Distribute Mechanism. (arXiv:2309.11331v1 [cs.CV])

    [http://arxiv.org/abs/2309.11331](http://arxiv.org/abs/2309.11331)

    本研究提出了Gold-YOLO模型，通过先进的收集和分发机制（GD）机制以及MAE风格的预训练，解决了YOLO系列模型中的信息融合问题，实现了高效的目标检测和多尺度特征融合。

    

    过去几年中，YOLO系列模型已成为实时目标检测领域的领先方法。许多研究通过修改架构、增加数据和设计新的损失函数将基线提升到了更高水平。然而，我们发现之前的模型仍然存在信息融合问题，虽然特征金字塔网络（FPN）和路径聚合网络（PANet）已经缓解了这个问题。因此，本研究提出了一种先进的收集和分发机制（GD）机制，通过卷积和自注意力操作实现。这个新设计的模型名为Gold-YOLO，提升了多尺度特征融合能力，并在所有模型尺度上实现了延迟和准确性的理想平衡。此外，我们首次在YOLO系列中实现了MAE风格的预训练，使得YOLO系列模型可以从无监督预训练中受益。Gold-YOLO-N在COCO val2017数据集上达到了出色的39.9%平均精度（AP）。

    In the past years, YOLO-series models have emerged as the leading approaches in the area of real-time object detection. Many studies pushed up the baseline to a higher level by modifying the architecture, augmenting data and designing new losses. However, we find previous models still suffer from information fusion problem, although Feature Pyramid Network (FPN) and Path Aggregation Network (PANet) have alleviated this. Therefore, this study provides an advanced Gatherand-Distribute mechanism (GD) mechanism, which is realized with convolution and self-attention operations. This new designed model named as Gold-YOLO, which boosts the multi-scale feature fusion capabilities and achieves an ideal balance between latency and accuracy across all model scales. Additionally, we implement MAE-style pretraining in the YOLO-series for the first time, allowing YOLOseries models could be to benefit from unsupervised pretraining. Gold-YOLO-N attains an outstanding 39.9% AP on the COCO val2017 datas
    
[^56]: 基于多智能体深度强化学习的AI驱动患者监测

    AI-Driven Patient Monitoring with Multi-Agent Deep Reinforcement Learning. (arXiv:2309.10980v1 [cs.LG])

    [http://arxiv.org/abs/2309.10980](http://arxiv.org/abs/2309.10980)

    本研究提出了一种基于多智能体深度强化学习的AI驱动患者监测框架，通过部署多个学习智能体，针对不同的生理特征进行监测，并根据紧急程度预警医疗紧急团队。

    

    有效的患者监测对及时干预和改善医疗结果至关重要。传统的监测系统往往难以处理复杂、动态的环境和波动的生命体征，导致延迟发现危急情况。为了应对这一挑战，我们提出了一种新颖的基于多智能体深度强化学习（DRL）的AI驱动患者监测框架。我们的方法部署了多个学习智能体，每个智能体专门负责监测特定的生理特征，如心率、呼吸和体温。这些智能体与通用的医疗监测环境进行交互，学习患者的行为模式，并根据估计的紧急程度做出通知相应医疗紧急团队（MET）的决策。在本研究中，我们使用来自两个数据集（PPG-DaLiA和WESAD）的真实生理和运动数据评估了提出的多智能体DRL框架的性能。

    Effective patient monitoring is vital for timely interventions and improved healthcare outcomes. Traditional monitoring systems often struggle to handle complex, dynamic environments with fluctuating vital signs, leading to delays in identifying critical conditions. To address this challenge, we propose a novel AI-driven patient monitoring framework using multi-agent deep reinforcement learning (DRL). Our approach deploys multiple learning agents, each dedicated to monitoring a specific physiological feature, such as heart rate, respiration, and temperature. These agents interact with a generic healthcare monitoring environment, learn the patients' behavior patterns, and make informed decisions to alert the corresponding Medical Emergency Teams (METs) based on the level of emergency estimated. In this study, we evaluate the performance of the proposed multi-agent DRL framework using real-world physiological and motion data from two datasets: PPG-DaLiA and WESAD. We compare the results 
    
[^57]: 深度学习网络的几何结构和全局${\mathcal L}^2$最小化器的构建

    Geometric structure of Deep Learning networks and construction of global ${\mathcal L}^2$ minimizers. (arXiv:2309.10639v1 [cs.LG])

    [http://arxiv.org/abs/2309.10639](http://arxiv.org/abs/2309.10639)

    本文提供了深度学习网络结构的几何解释，并且构建了全局最小化器族，该族能够全局最小化成本函数。此外，还确定了各种退化局部最小值。

    

    本文提供了对深度学习（DL）网络结构的几何解释，该网络具有$L$个隐藏层，斜坡激活函数，${\mathcal L}^2$ Schatten类（或Hilbert-Schmidt）成本函数，以及相等维度$Q\geq1$的输入和输出空间${\mathbb R}^Q$。隐藏层也定义在${\mathbb R}^{Q}$的空间上。我们利用我们最新的关于浅层神经网络的结果，在$L\geq Q$的情况下构造了一个明确的最小化器族，该族能够全局最小化成本函数，并且我们证明这个族是退化的。在这里提到的上下文中，DL网络的隐藏层通过对训练输入的递归截断映射的应用来“整理”训练输入，以最小化噪声与信号的比率。此外，我们确定了$2^Q-1$个不同的退化局部最小值。

    In this paper, we provide a geometric interpretation of the structure of Deep Learning (DL) networks, characterized by $L$ hidden layers, a ramp activation function, an ${\mathcal L}^2$ Schatten class (or Hilbert-Schmidt) cost function, and input and output spaces ${\mathbb R}^Q$ with equal dimension $Q\geq1$. The hidden layers are defined on spaces ${\mathbb R}^{Q}$, as well. We apply our recent results on shallow neural networks to construct an explicit family of minimizers for the global minimum of the cost function in the case $L\geq Q$, which we show to be degenerate. In the context presented here, the hidden layers of the DL network "curate" the training inputs by recursive application of a truncation map that minimizes the noise to signal ratio of the training inputs. Moreover, we determine a set of $2^Q-1$ distinct degenerate local minima of the cost function.
    
[^58]: FRAMU: 基于注意力的联邦强化学习机器遗忘

    FRAMU: Attention-based Machine Unlearning using Federated Reinforcement Learning. (arXiv:2309.10283v1 [cs.LG])

    [http://arxiv.org/abs/2309.10283](http://arxiv.org/abs/2309.10283)

    FRAMU是一种基于注意力和联邦强化学习的机器遗忘框架，通过自适应学习机制、隐私保护技术和优化策略，处理各种数据源并保持准确性和隐私，适应波动的数据环境，支持持续模型演进。

    

    机器遗忘是一个新兴领域，通过允许从机器学习过程中删除私有或无关数据，解决数据隐私问题。使用过时的、私有的和无关的数据会引发与隐私和模型效率相关的挑战。这些问题不仅影响模型在机器学习和遗忘中的准确性和计算效率，还会对数据隐私造成威胁。为了解决这些挑战，我们引入了一种新颖的框架，即基于注意力的联邦强化学习机器遗忘（FRAMU）。该框架融合了自适应学习机制、隐私保护技术和优化策略，是处理各种数据源（单模态或多模态）同时保持准确性和隐私性的综合解决方案。FRAMU的优势在于其适应波动的数据环境、遗忘过时、私有或无关数据的能力，以及支持模型持续演进的支持。

    Machine Unlearning is an emerging field that addresses data privacy issues by enabling the removal of private or irrelevant data from the Machine Learning process. Challenges related to privacy and model efficiency arise from the use of outdated, private, and irrelevant data. These issues compromise both the accuracy and the computational efficiency of models in both Machine Learning and Unlearning. To mitigate these challenges, we introduce a novel framework, Attention-based Machine Unlearning using Federated Reinforcement Learning (FRAMU). This framework incorporates adaptive learning mechanisms, privacy preservation techniques, and optimization strategies, making it a well-rounded solution for handling various data sources, either single-modality or multi-modality, while maintaining accuracy and privacy. FRAMU's strength lies in its adaptability to fluctuating data landscapes, its ability to unlearn outdated, private, or irrelevant data, and its support for continual model evolution
    
[^59]: 多层次特征融合网络结合注意力机制的息肉分割

    Multi-level feature fusion network combining attention mechanisms for polyp segmentation. (arXiv:2309.10219v1 [cs.CV])

    [http://arxiv.org/abs/2309.10219](http://arxiv.org/abs/2309.10219)

    提出了一种名为 MLFF-Net 的多层次特征融合网络，结合注意力机制实现了对息肉分割的改进。对编码器提取的特征进行了滤波和利用，并解决了特征融合引起的语义冲突和信息冗余问题。

    

    临床上，自动化的息肉分割技术有潜力显著提高医学诊断的效率和准确性，从而降低患者患结直肠癌的风险。然而，现有方法存在两个显著弱点可能影响分割的准确性。首先，编码器提取的特征未经充分滤波和利用。其次，由特征融合引起的语义冲突和信息冗余没有得到关注。为了克服这些局限性，我们提出了一种新的息肉分割方法，名为 MLFF-Net，它利用多层次特征融合和注意力机制。具体而言，MLFF-Net 包括三个模块：多尺度注意力模块（MAM）、高层特征增强模块（HFEM）和全局注意力模块（GAM）。其中，MAM 用于从编码器的浅层输出中提取多尺度信息和息肉细节。在 HFEM 中，编码器的深层特征可以被进一步增强。

    Clinically, automated polyp segmentation techniques have the potential to significantly improve the efficiency and accuracy of medical diagnosis, thereby reducing the risk of colorectal cancer in patients. Unfortunately, existing methods suffer from two significant weaknesses that can impact the accuracy of segmentation. Firstly, features extracted by encoders are not adequately filtered and utilized. Secondly, semantic conflicts and information redundancy caused by feature fusion are not attended to. To overcome these limitations, we propose a novel approach for polyp segmentation, named MLFF-Net, which leverages multi-level feature fusion and attention mechanisms. Specifically, MLFF-Net comprises three modules: Multi-scale Attention Module (MAM), High-level Feature Enhancement Module (HFEM), and Global Attention Module (GAM). Among these, MAM is used to extract multi-scale information and polyp details from the shallow output of the encoder. In HFEM, the deep features of the encoders
    
[^60]: 将深度学习应用于校准随机波动性模型

    Applying Deep Learning to Calibrate Stochastic Volatility Models. (arXiv:2309.07843v1 [q-fin.CP])

    [http://arxiv.org/abs/2309.07843](http://arxiv.org/abs/2309.07843)

    本研究将深度学习技术应用于校准随机波动性模型，通过训练神经网络对基于Heston模型的标的资产进行定价，并且在校准方面取得了快速和准确的结果。

    

    随机波动性模型是一种波动率是随机过程的模型，可以捕捉到隐含波动率曲面的大部分基本特征，并提供更真实的波动率笑曲线或偏斜动态。然而，它们存在一个重要问题，即校准时间过长。最近，基于深度学习（DL）技术的替代校准方法已被用于构建快速且准确的校准解决方案。Huge和Savine开发了一种差分深度学习（DDL）方法，该方法在样本中训练了机器学习模型，其中样本不仅包括特征和标签，还包括标签对特征的微分。本研究旨在将DDL技术应用于定价基本欧洲期权（即校准工具），具体而言，是在基于Heston模型的标的资产上定价看涨期权，并使用训练好的网络对模型进行校准。DDL可以实现快速训练和准确定价。训练好的神经网络戏剧性地

    Stochastic volatility models, where the volatility is a stochastic process, can capture most of the essential stylized facts of implied volatility surfaces and give more realistic dynamics of the volatility smile or skew. However, they come with the significant issue that they take too long to calibrate.  Alternative calibration methods based on Deep Learning (DL) techniques have been recently used to build fast and accurate solutions to the calibration problem. Huge and Savine developed a Differential Deep Learning (DDL) approach, where Machine Learning models are trained on samples of not only features and labels but also differentials of labels to features. The present work aims to apply the DDL technique to price vanilla European options (i.e. the calibration instruments), more specifically, puts when the underlying asset follows a Heston model and then calibrate the model on the trained network. DDL allows for fast training and accurate pricing. The trained neural network dramatic
    
[^61]: 学习环境感知的遮挡下三维关节物体操作的可供性

    Learning Environment-Aware Affordance for 3D Articulated Object Manipulation under Occlusions. (arXiv:2309.07510v1 [cs.RO])

    [http://arxiv.org/abs/2309.07510](http://arxiv.org/abs/2309.07510)

    本论文提出了一个环境感知的可供性框架，考虑了物体级的可行性先验和环境约束，以解决多个遮挡的复杂情况下的三维关节物体操作问题。

    

    在多样的环境中感知和操作三维关节物体对于家庭助理机器人至关重要。最近的研究表明，点级可供性为下游操作任务提供了可行性先验。然而，现有工作主要集中在单个物体场景中的均质代理，忽视了环境和代理形态所施加的现实约束，如遮挡和物理限制。在本文中，我们提出了一个环境感知的可供性框架，结合了物体级可行性先验和环境约束。与以物体为中心的可供性方法不同，学习环境感知的可供性面临着由各种遮挡的复杂性引起的组合爆炸挑战，这些遮挡以其数量、几何形状、位置和姿势来刻画。为了解决这个问题并提高数据效率，我们引入了一种新颖的对比式可供性学习框架，能够在含有遮挡的场景中进行训练。

    Perceiving and manipulating 3D articulated objects in diverse environments is essential for home-assistant robots. Recent studies have shown that point-level affordance provides actionable priors for downstream manipulation tasks. However, existing works primarily focus on single-object scenarios with homogeneous agents, overlooking the realistic constraints imposed by the environment and the agent's morphology, e.g., occlusions and physical limitations. In this paper, we propose an environment-aware affordance framework that incorporates both object-level actionable priors and environment constraints. Unlike object-centric affordance approaches, learning environment-aware affordance faces the challenge of combinatorial explosion due to the complexity of various occlusions, characterized by their quantities, geometries, positions and poses. To address this and enhance data efficiency, we introduce a novel contrastive affordance learning framework capable of training on scenes containin
    
[^62]: JSMNet通过自注意力机制和多尺度改进室内点云语义和实例分割

    JSMNet Improving Indoor Point Cloud Semantic and Instance Segmentation through Self-Attention and Multiscale. (arXiv:2309.07425v1 [cs.CV])

    [http://arxiv.org/abs/2309.07425](http://arxiv.org/abs/2309.07425)

    JSMNet通过自注意力机制和多尺度改进室内点云语义和实例分割。在室内3D点云数据中，JSMNet通过全局特征自注意力模块和多分辨率特征自适应融合模块，实现了更好的室内目标特征表达和语义、实例分割结果，具有较高的质量和准确性。

    

    室内3D点云数据的语义理解对于一系列后续应用非常重要，包括室内服务机器人、导航系统和数字孪生工程。全局特征对于实现高质量的室内点云语义和实例分割至关重要，因为它们提供了重要的长程上下文信息。为此，我们提出了JSMNet，它结合了多层网络和全局特征自注意力模块，共同分割三维点云的语义和实例。为了更好地表达室内目标的特征，我们设计了一个多分辨率特征自适应融合模块，考虑了由于扫描仪距离目标的变化而导致的点云密度差异。此外，我们提出了一个结合语义和实例特征的联合语义和实例分割框架，以达到优越的结果。我们在S3DIS上进行了实验，该数据集是一个大型的室内地物点云数据集。

    The semantic understanding of indoor 3D point cloud data is crucial for a range of subsequent applications, including indoor service robots, navigation systems, and digital twin engineering. Global features are crucial for achieving high-quality semantic and instance segmentation of indoor point clouds, as they provide essential long-range context information. To this end, we propose JSMNet, which combines a multi-layer network with a global feature self-attention module to jointly segment three-dimensional point cloud semantics and instances. To better express the characteristics of indoor targets, we have designed a multi-resolution feature adaptive fusion module that takes into account the differences in point cloud density caused by varying scanner distances from the target. Additionally, we propose a framework for joint semantic and instance segmentation by integrating semantic and instance features to achieve superior results. We conduct experiments on S3DIS, which is a large thr
    
[^63]: LEyes：一种轻量级深度学习眼动跟踪框架，使用合成眼部图像

    LEyes: A Lightweight Framework for Deep Learning-Based Eye Tracking using Synthetic Eye Images. (arXiv:2309.06129v1 [cs.CV])

    [http://arxiv.org/abs/2309.06129](http://arxiv.org/abs/2309.06129)

    本研究提出了一种名为LEyes的轻量级深度学习眼动跟踪框架，利用合成眼部图像进行训练，解决了由于训练数据集不足和眼部图像变异导致的模型泛化问题。实验结果表明，LEyes训练的模型在瞳孔和CR定位方面优于其他算法。

    

    深度学习已经加强了凝视估计技术，但实际部署受到不足的训练数据集的限制。眼部图像的硬件引起的变异以及记录的参与者之间固有的生物差异会导致特征和像素级别的差异，阻碍了在特定数据集上训练的模型的泛化能力。虚拟数据集可以是一个解决方案，但创建虚拟数据集既需要时间又需要资源。为了解决这个问题，我们提出了一个名为Light Eyes or "LEyes"的框架，与传统的逼真方法不同，LEyes仅模拟视频眼动跟踪所需的关键图像特征。LEyes便于在多样化的凝视估计任务上训练神经网络。我们证明，使用LEyes训练的模型在眼睛瞳孔和CR定位方面优于其他最先进的算法。

    Deep learning has bolstered gaze estimation techniques, but real-world deployment has been impeded by inadequate training datasets. This problem is exacerbated by both hardware-induced variations in eye images and inherent biological differences across the recorded participants, leading to both feature and pixel-level variance that hinders the generalizability of models trained on specific datasets. While synthetic datasets can be a solution, their creation is both time and resource-intensive. To address this problem, we present a framework called Light Eyes or "LEyes" which, unlike conventional photorealistic methods, only models key image features required for video-based eye tracking using simple light distributions. LEyes facilitates easy configuration for training neural networks across diverse gaze-estimation tasks. We demonstrate that models trained using LEyes outperform other state-of-the-art algorithms in terms of pupil and CR localization across well-known datasets. In addit
    
[^64]: SayNav：将大型语言模型用于新环境中的动态规划导航

    SayNav: Grounding Large Language Models for Dynamic Planning to Navigation in New Environments. (arXiv:2309.04077v1 [cs.RO])

    [http://arxiv.org/abs/2309.04077](http://arxiv.org/abs/2309.04077)

    SayNav是一种使用大型语言模型进行动态规划导航的方法，通过使用人类知识和场景图实现对复杂导航任务的高效泛化，动态生成指令并根据新信息不断完善未来步骤。

    

    语义推理和动态规划能力对于一个自主代理在未知环境中执行复杂导航任务至关重要。为了在这些任务中取得成功，需要大量的常识知识，这是人类所具备的。我们提出了SayNav，一种新的方法，利用来自大型语言模型（LLMs）的人类知识，以便高效地对未知大规模环境中的复杂导航任务进行泛化。SayNav使用一种新颖的接地机制，逐步构建一个探索环境的3D场景图，并将其作为LLMs的输入，用于生成可行且上下文适当的高层导航计划。然后，由预先训练的低层规划器执行LLM生成的计划，将每个计划的步骤视为短距离点目标导航子任务。SayNav在导航过程中动态生成一步一步的指令，并根据新获取的信息不断完善未来步骤。我们在一个新的多任务机验证环境上评估了SayNav。

    Semantic reasoning and dynamic planning capabilities are crucial for an autonomous agent to perform complex navigation tasks in unknown environments. It requires a large amount of common-sense knowledge, that humans possess, to succeed in these tasks. We present SayNav, a new approach that leverages human knowledge from Large Language Models (LLMs) for efficient generalization to complex navigation tasks in unknown large-scale environments. SayNav uses a novel grounding mechanism, that incrementally builds a 3D scene graph of the explored environment as inputs to LLMs, for generating feasible and contextually appropriate high-level plans for navigation. The LLM-generated plan is then executed by a pre-trained low-level planner, that treats each planned step as a short-distance point-goal navigation sub-task. SayNav dynamically generates step-by-step instructions during navigation and continuously refines future steps based on newly perceived information. We evaluate SayNav on a new mul
    
[^65]: 泛粗糙集中的合格聚合的代数模型及推理偏差发现

    Algebraic Models for Qualified Aggregation in General Rough Sets, and Reasoning Bias Discovery. (arXiv:2309.03217v1 [cs.AI])

    [http://arxiv.org/abs/2309.03217](http://arxiv.org/abs/2309.03217)

    本研究提出了一种泛粗糙集中合格聚合的代数模型，用于模拟人类推理中的悲观和乐观的合并，以及研究推理中的歧视/有害行为和机器学习算法。

    

    在泛粗糙集的背景下，将两个事物组合成另一个并非直接。对于涉及不确定性和模糊性的其他理论也是如此。这种行为可以赋予额外的意义，超越了结构上的合取和析取，就像$L$模糊集上的$*$-范数理论和相关推导一样。在本研究中，我们发明了在具有近似算子（称为粗糙便利格）的格上将事物组合的代数模型。研究受到要建模怀疑论或悲观论和乐观论合并于人类推理，以及操作选择被观点所约束的动机的强烈推动。证明了最小模型提供的弱否定和推导的基本结果。此外，该模型适用于研究人类推理中的歧视/有害行为和机器学习算法。

    In the context of general rough sets, the act of combining two things to form another is not straightforward. The situation is similar for other theories that concern uncertainty and vagueness. Such acts can be endowed with additional meaning that go beyond structural conjunction and disjunction as in the theory of $*$-norms and associated implications over $L$-fuzzy sets. In the present research, algebraic models of acts of combining things in generalized rough sets over lattices with approximation operators (called rough convenience lattices) is invented. The investigation is strongly motivated by the desire to model skeptical or pessimistic, and optimistic or possibilistic aggregation in human reasoning, and the choice of operations is constrained by the perspective. Fundamental results on the weak negations and implications afforded by the minimal models are proved. In addition, the model is suitable for the study of discriminatory/toxic behavior in human reasoning, and of ML algor
    
[^66]: AI海洋中的妖怪之歌：大型语言模型中的幻觉调查

    Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models. (arXiv:2309.01219v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.01219](http://arxiv.org/abs/2309.01219)

    本文调查了大型语言模型中幻觉的检测、解释和缓解的最新研究，提出了幻觉现象和评估基准的分类，并讨论了未来研究的潜在方向。

    

    尽管大型语言模型（LLMs）在各种下游任务中展示出了卓越的能力，但人们对其产生幻觉的倾向表示担忧：LLMs有时会生成与用户输入不符、与先前生成的内容相矛盾或与已建立的世界知识不符的内容。这种现象对LLMs在现实场景中的可靠性构成了重大挑战。本文对关于幻觉检测、解释和缓解的最新研究进行了调查，重点探讨了LLMs所面临的独特挑战。我们提出了LLM幻觉现象和评估基准的分类，分析了现有的旨在缓解LLM幻觉的方法，并讨论了未来研究的潜在方向。

    While large language models (LLMs) have demonstrated remarkable capabilities across a range of downstream tasks, a significant concern revolves around their propensity to exhibit hallucinations: LLMs occasionally generate content that diverges from the user input, contradicts previously generated context, or misaligns with established world knowledge. This phenomenon poses a substantial challenge to the reliability of LLMs in real-world scenarios. In this paper, we survey recent efforts on the detection, explanation, and mitigation of hallucination, with an emphasis on the unique challenges posed by LLMs. We present taxonomies of the LLM hallucination phenomena and evaluation benchmarks, analyze existing approaches aiming at mitigating LLM hallucination, and discuss potential directions for future research.
    
[^67]: CPSP: 从音素监督中学习语音概念

    CPSP: Learning Speech Concepts From Phoneme Supervision. (arXiv:2309.00424v1 [eess.AS])

    [http://arxiv.org/abs/2309.00424](http://arxiv.org/abs/2309.00424)

    论文提出了一种名为CPSP的方法，通过对比学习来从语音中提取细粒度的中间表示，使得提取的信息既包含语言内容又去除了发言人身份和声学细节，适用于TTS、VC和ASR等任务。

    

    对于诸如最小监督的文本转语音（TTS）、语音转换（VC）和自动语音识别（ASR）等细粒度生成和识别任务，从语音中提取的中间表示应包含介于文本编码和声学编码之间的信息。语言内容突出，而发言人身份和声学细节等语音信息应该被去除。然而，现有的从语音中提取细粒度中间表示的方法存在冗余性过高和维度爆炸的问题。此外，音频领域中现有的对比学习方法主要关注提取用于下游音频分类任务的全局描述信息，不适合TTS、VC和ASR任务。为了解决这些问题，我们提出了一种名为对比音素-语音预训练（CPSP）的方法，该方法使用三个编码器、一个解码器和对比学习来将音素和语音信息相结合。

    For fine-grained generation and recognition tasks such as minimally-supervised text-to-speech (TTS), voice conversion (VC), and automatic speech recognition (ASR), the intermediate representation extracted from speech should contain information that is between text coding and acoustic coding. The linguistic content is salient, while the paralinguistic information such as speaker identity and acoustic details should be removed. However, existing methods for extracting fine-grained intermediate representations from speech suffer from issues of excessive redundancy and dimension explosion. Additionally, existing contrastive learning methods in the audio field focus on extracting global descriptive information for downstream audio classification tasks, making them unsuitable for TTS, VC, and ASR tasks. To address these issues, we propose a method named Contrastive Phoneme-Speech Pretraining (CPSP), which uses three encoders, one decoder, and contrastive learning to bring phoneme and speech
    
[^68]: 存在性颗粒的代数、拓扑和细部学基础

    Algebraic, Topological, and Mereological Foundations of Existential Granules. (arXiv:2308.16157v1 [cs.LO])

    [http://arxiv.org/abs/2308.16157](http://arxiv.org/abs/2308.16157)

    本研究从代数、拓扑和细部学的角度创造了新的存在性颗粒概念，并刻画了其特征。这些颗粒首先确定自己，然后与环境互动，并且适用于多种颗粒计算理论框架。研究结果对算法开发、分类问题应用和方法推广的数学基础具有重要意义。

    

    在这项研究中，发明了确定自己的存在性颗粒的新概念，并从代数、拓扑和细部学的角度对其进行了刻画。存在性颗粒是那些最初确定自己，并随后与其环境进行交互的颗粒。这个概念的示例，比如颗粒球，在之前其他人的作品中虽然定义不完备、算法建立不充分、理论化不足，但已经在粗糙集和软计算的应用中使用。研究表明它们适合于颗粒计算的多个理论框架（公理化、适应性等）。这种刻画旨在用于算法开发、分类问题的应用以及可能的方法推广的数学基础。此外，还提出了许多开放问题并提供了方向。

    In this research, new concepts of existential granules that determine themselves are invented, and are characterized from algebraic, topological, and mereological perspectives. Existential granules are those that determine themselves initially, and interact with their environment subsequently. Examples of the concept, such as those of granular balls, though inadequately defined, algorithmically established, and insufficiently theorized in earlier works by others, are already used in applications of rough sets and soft computing. It is shown that they fit into multiple theoretical frameworks (axiomatic, adaptive, and others) of granular computing. The characterization is intended for algorithm development, application to classification problems and possible mathematical foundations of generalizations of the approach. Additionally, many open problems are posed and directions provided.
    
[^69]: 多平面去噪扩展维度的基于扩散的微结构二维到三维重建方法与采样协调

    Multi-plane denoising diffusion-based dimensionality expansion for 2D-to-3D reconstruction of microstructures with harmonized sampling. (arXiv:2308.14035v2 [cond-mat.mtrl-sci] UPDATED)

    [http://arxiv.org/abs/2308.14035](http://arxiv.org/abs/2308.14035)

    本论文提出一种名为Micro3Diff的框架，通过扩散生成模型实现了二维到三维微结构的重建，其中采用了多平面去噪扩散的概念。

    

    获得可靠的微结构数据集对于使用集成计算材料工程（ICME）方法进行材料系统设计是一个关键步骤。

    Acquiring reliable microstructure datasets is a pivotal step toward the systematic design of materials with the aid of integrated computational materials engineering (ICME) approaches. However, obtaining three-dimensional (3D) microstructure datasets is often challenging due to high experimental costs or technical limitations, while acquiring two-dimensional (2D) micrographs is comparatively easier. To deal with this issue, this study proposes a novel framework for 2D-to-3D reconstruction of microstructures called Micro3Diff using diffusion-based generative models (DGMs). Specifically, this approach solely requires pre-trained DGMs for the generation of 2D samples, and dimensionality expansion (2D-to-3D) takes place only during the generation process (i.e., reverse diffusion process). The proposed framework incorporates a new concept referred to as multi-plane denoising diffusion, which transforms noisy samples (i.e., latent variables) from different planes into the data structure whil
    
[^70]: Hyperscanning EEG的功能性图对比学习揭示了基于刻板印象的压力引发的情绪传染

    Functional Graph Contrastive Learning of Hyperscanning EEG Reveals Emotional Contagion Evoked by Stereotype-Based Stressors. (arXiv:2308.13546v1 [eess.SP])

    [http://arxiv.org/abs/2308.13546](http://arxiv.org/abs/2308.13546)

    本研究通过利用超扫描技术，引入功能性图对比学习方法探究基于刻板印象的压力引发的情绪传染。研究结果揭示了情绪传染与认知功能之间的复杂相互作用。

    

    本研究深入探讨情绪传染的细微差异及其对双人互动中表现的影响。具体而言，研究聚焦于女性对的合作解决问题任务中基于刻板印象的压力背景。通过对情绪传染的研究，旨在揭示其潜在机制和影响。利用基于EEG的超扫描技术，本研究引入了一种名为功能性图对比学习（fGCL）的创新方法，提取主体不变的神经活动模式表示。这些表示进一步应用动态图分类（DGC）模型进行分析，旨在剖析情绪传染的过程。通过对脑部同步和连接性的研究，揭示了情绪传染与认知功能之间的复杂相互作用。结果强调情绪传染在塑造轨迹中的重要作用。

    This study delves into the intricacies of emotional contagion and its impact on performance within dyadic interactions. Specifically, it focuses on the context of stereotype-based stress (SBS) during collaborative problem-solving tasks among female pairs. Through an exploration of emotional contagion, the research seeks to unveil its underlying mechanisms and effects. Leveraging EEG-based hyperscanning technology, the study introduces an innovative approach known as functional Graph Contrastive Learning (fGCL), which extracts subject-invariant representations of neural activity patterns. These representations are further subjected to analysis using the Dynamic Graph Classification (DGC) model, aimed at dissecting the process of emotional contagion. By scrutinizing brain synchronization and connectivity, the study reveals the intricate interplay between emotional contagion and cognitive functioning. The results underscore the substantial role of emotional contagion in shaping the trajec
    
[^71]: 行动分割需要多少长期时间上下文？

    How Much Temporal Long-Term Context is Needed for Action Segmentation?. (arXiv:2308.11358v1 [cs.CV])

    [http://arxiv.org/abs/2308.11358](http://arxiv.org/abs/2308.11358)

    本文提出了一种基于transformer的模型，利用稀疏注意力捕捉视频的完整上下文，以回答时间行动分割需要多少长期时间上下文。通过与当前最先进的方法进行比较，在三个时间行动分割数据集上取得了良好的性能。

    

    在视频中建模长期上下文对于许多细粒度任务包括时间行动分割至关重要。一个有趣的问题是，为了达到最佳性能，需要多少长期时间上下文仍然是一个未解之谜。虽然transformers可以对视频的长期上下文进行建模，但对于长视频，这在计算上是不可行的。因此，最近关于时间行动分割的研究结合了使用局部时间窗口计算出的自注意力的时间卷积网络。虽然这些方法显示出良好的结果，但它们的性能受到无法捕捉视频的完整上下文的限制。在这项工作中，我们通过引入基于transformer的模型并利用稀疏注意力来捕捉视频的完整上下文，试图回答需要多少长期时间上下文才能进行时间行动分割。我们将我们的模型与目前的三个数据集上的时间行动分割的最新技术水平进行比较，这三个数据集包括50Salads，Brea...

    Modeling long-term context in videos is crucial for many fine-grained tasks including temporal action segmentation. An interesting question that is still open is how much long-term temporal context is needed for optimal performance. While transformers can model the long-term context of a video, this becomes computationally prohibitive for long videos. Recent works on temporal action segmentation thus combine temporal convolutional networks with self-attentions that are computed only for a local temporal window. While these approaches show good results, their performance is limited by their inability to capture the full context of a video. In this work, we try to answer how much long-term temporal context is required for temporal action segmentation by introducing a transformer-based model that leverages sparse attention to capture the full context of a video. We compare our model with the current state of the art on three datasets for temporal action segmentation, namely 50Salads, Brea
    
[^72]: 基于异构节点特征和交互规则的面向数字孪生的复杂网络系统

    Digital Twin-Oriented Complex Networked Systems based on Heterogeneous node features and interaction rules. (arXiv:2308.11034v1 [cs.SI])

    [http://arxiv.org/abs/2308.11034](http://arxiv.org/abs/2308.11034)

    本研究提出了一种面向数字孪生的复杂网络系统的可扩展建模框架，重点关注节点特征和交互规则。通过实验研究了网络增长和疫情传播的不同级别的复杂性对系统的影响，结果表明需要在DT-CNS中平衡这些复杂性水平。

    

    本研究提出了一种可扩展的建模框架，用于数字孪生导向的复杂网络系统（DT-CNS），旨在生成能够真实表示实际系统的网络。建模过程关注节点的特征和基于个体节点偏好创建连接的交互规则。我们对基于模拟的DT-CNS进行了实验，其中包括各种特征和规则，以及与传染病在这些网络中的传播相关的不同传染能力。我们通过调查特定时间和社交距离内的感染情况，对社交网络的灾害韧性进行了案例研究。实验结果显示了结构复杂性和动态复杂性的不同级别对网络增长和疫情传播的影响，分别涉及特征多样性和交互规则的灵活性。分析表明，要实现最大的灾害韧性，需要在DT-CNS中平衡这些复杂性水平。

    This study proposes an extendable modelling framework for Digital Twin-Oriented Complex Networked Systems (DT-CNSs) with a goal of generating networks that faithfully represent real systems. Modelling process focuses on (i) features of nodes and (ii) interaction rules for creating connections that are built based on individual node's preferences. We conduct experiments on simulation-based DT-CNSs that incorporate various features and rules about network growth and different transmissibilities related to an epidemic spread on these networks. We present a case study on disaster resilience of social networks given an epidemic outbreak by investigating the infection occurrence within specific time and social distance. The experimental results show how different levels of the structural and dynamics complexities, concerned with feature diversity and flexibility of interaction rules respectively, influence network growth and epidemic spread. The analysis revealed that, to achieve maximum dis
    
[^73]: GNNPipe：使用流水线模型并行实现深度GNN训练的扩展

    GNNPipe: Scaling Deep GNN Training with Pipelined Model Parallelism. (arXiv:2308.10087v2 [cs.DC] UPDATED)

    [http://arxiv.org/abs/2308.10087](http://arxiv.org/abs/2308.10087)

    GNNPipe是一种扩展分布式全图深度GNN训练的方法，使用层级模型并行性将GNN层划分在不同的GPU上，通过减少通信量和处理特定挑战，实现了更好的计算资源利用和模型收敛性的保证。

    

    通信是分布式图神经网络（GNN）训练的关键瓶颈。本文提出了GNNPipe，一种新的方法，用于扩展分布式的全图深度GNN训练。作为首次使用层级模型并行性进行GNN训练的方法，GNNPipe将GNN层划分在不同的GPU上，每个设备在整个图上为一组连续的GNN层执行计算。与每个GPU处理一个图划分的图并行性相比，GNNPipe将通信量减少了GNN层数的倍数。GNNPipe克服了整个图上流水线层级模型并行的独特挑战，通过将图划分为相互依赖的块，允许使用历史顶点嵌入，并应用特定的训练技术以确保收敛性。我们还提出了一种混合策略，将GNNPipe与图并行结合以处理大型图，实现更好的计算资源利用和模型收敛性的保证。

    Communication is a key bottleneck for distributed graph neural network (GNN) training. This paper proposes GNNPipe, a new approach that scales the distributed full-graph deep GNN training. Being the first to use layer-level model parallelism for GNN training, GNNPipe partitions GNN layers among GPUs, each device performs the computation for a disjoint subset of consecutive GNN layers on the whole graph. Compared to graph parallelism with each GPU handling a graph partition, GNNPipe reduces the communication volume by a factor of the number of GNN layers. GNNPipe overcomes the unique challenges for pipelined layer-level model parallelism on the whole graph by partitioning it into dependent chunks, allowing the use of historical vertex embeddings, and applying specific training techniques to ensure convergence. We also propose a hybrid approach by combining GNNPipe with graph parallelism to handle large graphs, achieve better computer resource utilization and ensure model convergence. We
    
[^74]: AI Hilbert: 整合数据与背景知识的科学发现新范式

    AI Hilbert: A New Paradigm for Scientific Discovery by Unifying Data and Background Knowledge. (arXiv:2308.09474v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.09474](http://arxiv.org/abs/2308.09474)

    AI Hilbert提出了一种整合数据与背景知识的科学发现新范式，通过将回归和推理相结合，解决了在搜索与背景理论一致的公式空间中找到最符合数据的公式的问题。

    

    在科学中，发现能简单解释自然现象并与现有背景理论一致的科学公式是一个关键目标。过去，科学家通过操作基于现有知识的方程式、形成新方程式并进行实验验证来推导自然规律。近年来，数据驱动的科学发现已成为在具有大量实验数据的情境中的一种可行竞争方式。然而，当数据嘈杂或稀缺时，数据驱动的方法通常无法发现有效的规律。因此，最近的研究将回归和推理结合起来以剔除与背景理论不一致的公式。然而，在与背景理论一致的方程空间中搜索出最符合数据的公式仍存在问题。我们提出了一种解决方案，当所有公理和科学定律都可以通过多项式等式和不等式来表达时，我们的方法被认为是广泛适用的。

    The discovery of scientific formulae that parsimoniously explain natural phenomena and align with existing background theory is a key goal in science. Historically, scientists have derived natural laws by manipulating equations based on existing knowledge, forming new equations, and verifying them experimentally. In recent years, data-driven scientific discovery has emerged as a viable competitor in settings with large amounts of experimental data. Unfortunately, data-driven methods often fail to discover valid laws when data is noisy or scarce. Accordingly, recent works combine regression and reasoning to eliminate formulae inconsistent with background theory. However, the problem of searching over the space of formulae consistent with background theory to find one that fits the data best is not well-solved. We propose a solution to this problem when all axioms and scientific laws are expressible via polynomial equalities and inequalities and argue that our approach is widely applicab
    
[^75]: 案例研究：在移动团队中使用AI辅助代码生成

    Case Study: Using AI-Assisted Code Generation In Mobile Teams. (arXiv:2308.04736v1 [cs.SE])

    [http://arxiv.org/abs/2308.04736](http://arxiv.org/abs/2308.04736)

    本研究通过案例研究评估了在专注于移动开发的团队中使用AI辅助代码生成的性能。通过对参与者进行技术入职和技术堆栈切换阶段的问题求解，评估了使用和不使用AI-Code生成器的影响。研究结合了时间、正确性和技术集成等度量指标，并分析了参与者的反馈，以确定使用AI辅助编程工具是否对开发人员产生影响。

    

    本研究旨在评估在专注于Kotlin和Swift等原生移动语言的实际移动开发团队中使用AI辅助编程的性能。这个广泛的案例研究涉及16名参与者和2名技术评审人员，来自一个软件开发部门，旨在了解在团队的特定阶段中使用针对代码生成进行训练的LLMs的影响，更具体地说是技术入职和技术堆栈切换。研究使用针对每个阶段的技术问题，并要求参与者使用和不使用AI-Code生成器提供解决方案。它通过ReviewerScore这一特定于本论文的度量标准，以及从实际行业标准（合并请求的代码评审人员）中提取的度量时间、正确性和技术集成。输出与参与者的反馈一起转换和分析，以确定使用AI辅助编程工具是否对获得开发人员有影响。

    The aim of this study is to evaluate the performance of AI-assisted programming in actual mobile development teams that are focused on native mobile languages like Kotlin and Swift. The extensive case study involves 16 participants and 2 technical reviewers, from a software development department designed to understand the impact of using LLMs trained for code generation in specific phases of the team, more specifically, technical onboarding and technical stack switch. The study uses technical problems dedicated to each phase and requests solutions from the participants with and without using AI-Code generators. It measures time, correctness, and technical integration using ReviewerScore, a metric specific to the paper and extracted from actual industry standards, the code reviewers of merge requests. The output is converted and analyzed together with feedback from the participants in an attempt to determine if using AI-assisted programming tools will have an impact on getting develope
    
[^76]: ChatGPT生物医学生成文本中建立信任的方法：基于本体的知识图谱用于验证疾病-症状关系

    Establishing Trust in ChatGPT BioMedical Generated Text: An Ontology-Based Knowledge Graph to Validate Disease-Symptom Links. (arXiv:2308.03929v1 [cs.AI])

    [http://arxiv.org/abs/2308.03929](http://arxiv.org/abs/2308.03929)

    本研究通过构建基于本体的知识图谱，利用疾病本体和症状本体构建数学模型，利用事实核查算法和网络中心度指标分析ChatGPT生成的文本与真实医学文献之间的准确性，以验证疾病-症状关系。

    

    方法：通过创新的方法，我们从真实的医学文献和人工智能生成的内容构建了基于本体的知识图谱。我们的目标是区分事实信息和未经验证的数据。我们收集了两个数据集：一个是使用“人类疾病和症状”查询从生物医学文献中编译的，另一个是由ChatGPT生成的模拟文章。利用这些数据集（PubMed和ChatGPT），我们随机选择了10组每组250个摘要，并使用特定的种子。我们的方法主要是利用疾病本体（DOID）和症状本体（SYMP）构建知识图谱，这是一种强大的数学模型，可以进行无偏差的比较。通过使用我们的事实核查算法和网络中心度指标，我们进行了GPT疾病-症状链接分析，以量化在噪声、假设和重要发现中的事实知识的准确性。结果：通过比较不同ChatGPT知识图谱及其PubMed计数获得的结果，我们发现...

    Methods: Through an innovative approach, we construct ontology-based knowledge graphs from authentic medical literature and AI-generated content. Our goal is to distinguish factual information from unverified data. We compiled two datasets: one from biomedical literature using a "human disease and symptoms" query, and another generated by ChatGPT, simulating articles. With these datasets (PubMed and ChatGPT), we curated 10 sets of 250 abstracts each, selected randomly with a specific seed. Our method focuses on utilizing disease ontology (DOID) and symptom ontology (SYMP) to build knowledge graphs, robust mathematical models that facilitate unbiased comparisons. By employing our fact-checking algorithms and network centrality metrics, we conducted GPT disease-symptoms link analysis to quantify the accuracy of factual knowledge amid noise, hypotheses, and significant findings.  Results: The findings obtained from the comparison of diverse ChatGPT knowledge graphs with their PubMed count
    
[^77]: 通过未见过的状态增强利用广义化在离线强化学习中

    Exploiting Generalization in Offline Reinforcement Learning via Unseen State Augmentations. (arXiv:2308.03882v1 [cs.LG])

    [http://arxiv.org/abs/2308.03882](http://arxiv.org/abs/2308.03882)

    本文提出了一种利用未见状态增强的策略，在离线强化学习中通过基于价值的扰动和过滤，实现了对离线数据之外的状态的利用和泛化。

    

    离线强化学习方法通过对未见过的状态和动作进行保守价值评估来平衡探索和利用。无模型方法会对所有未见过的动作进行惩罚，而有模型方法可以进一步通过模型展开对未见过的状态进行利用。然而，由于两个因素，这些方法在找到离线数据之外的未见过的状态时存在困难：(a)由于级联模型误差，模型的展开范围非常短，(b)模型展开仅以离线数据中观察到的状态为起点。我们放宽了第二个假设，并提出了一种新颖的未见过状态增强策略，以允许学得的模型和价值估计在未见状态中泛化。我们的策略通过对观察到的状态进行基于价值的扰动来找到未见过的状态，然后通过过滤具有过高的启发性不确定性估计（高误差）或过低的（过于相似）

    Offline reinforcement learning (RL) methods strike a balance between exploration and exploitation by conservative value estimation -- penalizing values of unseen states and actions. Model-free methods penalize values at all unseen actions, while model-based methods are able to further exploit unseen states via model rollouts. However, such methods are handicapped in their ability to find unseen states far away from the available offline data due to two factors -- (a) very short rollout horizons in models due to cascading model errors, and (b) model rollouts originating solely from states observed in offline data. We relax the second assumption and present a novel unseen state augmentation strategy to allow exploitation of unseen states where the learned model and value estimates generalize. Our strategy finds unseen states by value-informed perturbations of seen states followed by filtering out states with epistemic uncertainty estimates too high (high error) or too low (too similar to
    
[^78]: 探索ChatGPT的共情能力

    Exploring ChatGPT's Empathic Abilities. (arXiv:2308.03527v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.03527](http://arxiv.org/abs/2308.03527)

    这项研究探索了基于GPT-3.5的ChatGPT在展现共情回应和情感表达方面的能力。研究结果表明，在91.7%的情况下，ChatGPT能够准确识别情感并产生适当的回答。

    

    共情通常被理解为分享和理解他人的心态或情绪的能力。随着聊天机器人在各个领域的增加应用，例如儿童寻求作业帮助、个人寻求医疗建议以及人们将聊天机器人作为日常伴侣，共情在人机交互中的重要性变得更加明显。因此，我们的研究调查了基于GPT-3.5的ChatGPT在展现共情回应和情感表达方面的能力。我们分析了以下三个方面：(1)理解和表达情感、(2)并行情感回应以及(3)共情个性。因此，我们不仅在各个共情方面评估了ChatGPT并将其与人类行为进行比较，还展示了一种分析聊天机器人共情能力的可能方式。我们的研究结果显示，在91.7%的情况下，ChatGPT能够准确识别情感并产生适当的回答。

    Empathy is often understood as the ability to share and understand another individual's state of mind or emotion. With the increasing use of chatbots in various domains, e.g., children seeking help with homework, individuals looking for medical advice, and people using the chatbot as a daily source of everyday companionship, the importance of empathy in human-computer interaction has become more apparent. Therefore, our study investigates the extent to which ChatGPT based on GPT-3.5 can exhibit empathetic responses and emotional expressions. We analyzed the following three aspects: (1) understanding and expressing emotions, (2) parallel emotional response, and (3) empathic personality. Thus, we not only evaluate ChatGPT on various empathy aspects and compare it with human behavior but also show a possible way to analyze the empathy of chatbots in general. Our results show, that in 91.7% of the cases, ChatGPT was able to correctly identify emotions and produces appropriate answers. In c
    
[^79]: Relation-Oriented: 迈向与知识对准的因果人工智能

    Relation-Oriented: Toward Knowledge-Aligned Causal AI. (arXiv:2307.16387v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2307.16387](http://arxiv.org/abs/2307.16387)

    本研究从创新的关系导向视角出发，探讨了当前的建模范式中的观察模型与实际理解的不对齐问题，并提出了关系定义的表示学习方法作为实现关系导向建模的实践方法。

    

    在机器学习中，我们自然地应用一个观察导向的原则，其中观察变量先存在并为构建关系奠定基础。虽然对于传统模型来说足够了，但是人工智能与大数据的整合暴露了观察模型与我们的实际理解之间的不对齐。相反，人类塑造了由关系定义的认知实体，使我们能够跨越时间和超维度空间制定知识，而不是被限制在观察构建中。从一种创新的关系导向的视角出发，本研究通过来自计算机视觉和健康信息学的直观例子，分析了在我们当前的建模范式中这种不对齐的根源。我们还介绍了关系定义的表示学习方法作为关系导向建模的一种实际实施，支持广泛的实验验证。

    In machine learning, we naturally apply an Observation-Oriented principle, in which observational variables preexist and set the stage for constructing relationships. While sufficient for traditional models, the integration of AI with big data exposes the misalignment between the observational models and our actual comprehension. Contrarily, humans shape cognitive entities defined by relationships, enabling us to formulate knowledge across temporal and hyper-dimensional spaces, rather than being confined to observational constructs. From an innovative Relation-Oriented perspective, this study examines the roots of this misalignment within our current modeling paradigm, illuminated by intuitive examples from computer vision and health informatics. We also introduce the relation-defined representation learning methodology as a practical implementation of Relation-Oriented modeling, supported by extensive experimental validation.
    
[^80]: 提升人类化多模态推理：一个新的具有挑战性的数据集和综合框架

    Enhancing Human-like Multi-Modal Reasoning: A New Challenging Dataset and Comprehensive Framework. (arXiv:2307.12626v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2307.12626](http://arxiv.org/abs/2307.12626)

    提出了COCO-MMR数据集，该数据集是一个包含了大量开放性问题、理由和答案的新颖数据集，通过全面的评估和详细的分析，提供了一些向多模态推理领域贡献的创新和理论基础。

    

    多模态推理是追求展示人类智能的人工智能系统中的关键组成部分，特别是在处理复杂任务时。虽然连续思维（Chain-of-Thought，CoT）技术已经引起了相当大的关注，但现有的ScienceQA数据集专注于多模态科学问题和基于小学和高中教科书的解释，缺乏对不同方法的全面评价。为了弥补这一空白，我们提出了COCO Multi-Modal Reasoning（COCO-MMR）数据集，这是一个包含了大量开放性问题、理由和答案的新颖数据集，这些问题、理由和答案是从大型对象数据集COCO中衍生出来的。与先前依赖多项选择问题的数据集不同，我们的数据集在多模态连续思维的背景下首次引入了开放性问题，引入了一个更具挑战性的问题，能够有效评估CoT模型的推理能力。通过全面的评估和详细的分析，我们提供了一些向该领域贡献的创新和理论基础。

    Multimodal reasoning is a critical component in the pursuit of artificial intelligence systems that exhibit human-like intelligence, especially when tackling complex tasks. While the chain-of-thought (CoT) technique has gained considerable attention, the existing ScienceQA dataset, which focuses on multimodal scientific questions and explanations from elementary and high school textbooks, lacks a comprehensive evaluation of diverse approaches. To address this gap, we present COCO Multi-Modal Reasoning(COCO-MMR) dataset, a novel dataset that encompasses an extensive collection of open-ended questions, rationales, and answers derived from the large object dataset COCO. Unlike previous datasets that rely on multiple-choice questions, our dataset pioneers the use of open-ended questions in the context of multimodal CoT, introducing a more challenging problem that effectively assesses the reasoning capability of CoT models. Through comprehensive evaluations and detailed analyses, we provide
    
[^81]: 通过基于深度学习的策略预测来预测驾驶行为

    Anticipating Driving Behavior through Deep Learning-Based Policy Prediction. (arXiv:2307.11058v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2307.11058](http://arxiv.org/abs/2307.11058)

    通过处理视频帧和深度细节，我们开发了一个综合系统来预测驾驶行为，实现了显著的准确性，比单独使用视频帧更好。

    

    在这个研究中，我们开发了一个综合系统，通过处理由普通摄像头拍摄的视频帧衍生出的综合视觉特征以及从点云扫描仪获得的深度细节。该系统旨在预测驾驶行为，包括车辆速度和转向角度。为了确保其可靠性，我们进行了评估，将预测结果与熟练的真实驾驶员遵循的既定规范进行了对比。我们的评估结果表明，预测在至少一半的测试场景中实现了显著的准确性水平（根据具体模型，在50-80%之间）。值得注意的是，使用综合特征相比于只使用视频帧在大多数情况下表现更好。

    In this endeavor, we developed a comprehensive system that processes integrated visual features derived from video frames captured by a regular camera, along with depth details obtained from a point cloud scanner. This system is designed to anticipate driving actions, encompassing both vehicle speed and steering angle. To ensure its reliability, we conducted assessments where we juxtaposed the projected outcomes with the established norms adhered to by skilled real-world drivers. Our evaluation outcomes indicate that the forecasts achieve a noteworthy level of accuracy in a minimum of half the test scenarios (ranging around 50-80%, contingent on the specific model). Notably, the utilization of amalgamated features yielded superior performance in comparison to using video frames in isolation, as demonstrated by most of the cases.
    
[^82]: AspectCSE: 使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入

    AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity using Contrastive Learning and Structured Knowledge. (arXiv:2307.07851v1 [cs.CL])

    [http://arxiv.org/abs/2307.07851](http://arxiv.org/abs/2307.07851)

    AspectCSE是一种使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入方法，它在信息检索任务中相比之前的最好结果平均提高了3.97%，通过同时考虑多个特定方面的嵌入模型优于单方面嵌入。

    

    通用的句子嵌入提供了对语义文本相似性的粗略近似，但忽略了使文本相似的特定方面。相反，基于方面的句子嵌入提供了基于预定义方面的文本相似性。因此，文本的相似性预测更加针对特定要求，并且更容易解释。在本文中，我们提出了AspectCSE，一种用于基于方面的对比学习句子嵌入的方法。结果表明，与之前最好的结果相比，AspectCSE在多个方面的信息检索任务中实现了平均改善3.97%。我们还提出使用Wikidata知识图属性来训练多方面句子嵌入模型，其中在相似性预测过程中同时考虑多个特定方面。我们证明了多方面嵌入在特定方面信息检索任务上优于单方面嵌入。最后，我们展示了嵌入模型的可解释性，并提出通过对比学习来改进嵌入质量。

    Generic sentence embeddings provide a coarse-grained approximation of semantic textual similarity but ignore specific aspects that make texts similar. Conversely, aspect-based sentence embeddings provide similarities between texts based on certain predefined aspects. Thus, similarity predictions of texts are more targeted to specific requirements and more easily explainable. In this paper, we present AspectCSE, an approach for aspect-based contrastive learning of sentence embeddings. Results indicate that AspectCSE achieves an average improvement of 3.97% on information retrieval tasks across multiple aspects compared to the previous best results. We also propose using Wikidata knowledge graph properties to train models of multi-aspect sentence embeddings in which multiple specific aspects are simultaneously considered during similarity predictions. We demonstrate that multi-aspect embeddings outperform single-aspect embeddings on aspect-specific information retrieval tasks. Finally, w
    
[^83]: 使用GPT进行命名实体识别以识别可比公司

    Named entity recognition using GPT for identifying comparable companies. (arXiv:2307.07420v1 [cs.CL])

    [http://arxiv.org/abs/2307.07420](http://arxiv.org/abs/2307.07420)

    本文使用GPT以识别可比公司。传统的可比公司方法通常使用定性方法来识别相似的同行公司，而我们使用大型语言模型通过提取公司描述/摘要从而进行相似性分析，实现更量化的方法。

    

    对于公共和私人公司，可比公司分析被广泛用作公司估值的方法。特别是对于私募股权公司的估值，该方法非常有价值。可比公司方法的几种方法通常依赖于定性方法来识别相似的同行公司，这往往使用已建立的行业分类方案和/或分析师的直觉和知识。然而，文献和私募股权行业开始使用更多的量化方法，特别是机器学习聚类和自然语言处理（NLP）。对于NLP方法，该过程包括从公司的网站或来自某些金融数据库系统的公司描述中提取产品实体，然后进行相似性分析。在这里，我们使用公开可用的公司维基百科网站的公司描述/摘要，展示了使用大型语言模型（LLM），例如GPT

    For both public and private firms, comparable companies analysis is widely used as a method for company valuation. In particular, the method is of great value for valuation of private equity companies. The several approaches to the comparable companies method usually rely on a qualitative approach to identifying similar peer companies, which tends to use established industry classification schemes and/or analyst intuition and knowledge. However, more quantitative methods have started being used in the literature and in the private equity industry, in particular, machine learning clustering, and natural language processing (NLP). For NLP methods, the process consists of extracting product entities from e.g., the company's website or company descriptions from some financial database system and then to perform similarity analysis. Here, using companies descriptions/summaries from publicly available companies' Wikipedia websites, we show that using large language models (LLMs), such as GPT
    
[^84]: 使用适配器高效域自适应句子嵌入

    Efficient Domain Adaptation of Sentence Embeddings using Adapters. (arXiv:2307.03104v1 [cs.CL])

    [http://arxiv.org/abs/2307.03104](http://arxiv.org/abs/2307.03104)

    本论文提出了一种通过训练轻量级适配器来高效域自适应句子嵌入的方法，避免了微调整个句子嵌入模型的资源消耗。通过训练特定领域的适配器，可以在不同领域中使用同一模型获得良好的性能。

    

    句子嵌入使我们能够捕捉短文本的语义相似性。大多数句子嵌入模型是针对一般语义文本相似性（STS）任务进行训练的。因此，要在特定领域中使用句子嵌入，必须将模型适应于该领域以获得良好的结果。通常，这是通过对感兴趣的域对整个句子嵌入模型进行微调来实现的。虽然这种方法能够产生最先进的结果，但在微调过程中更新了所有模型的权重，使该方法在资源上要求较高。因此，我们提出了训练轻量级适配器的方法，而不是单独为每个目标领域微调整个句子嵌入模型。这些特定领域的适配器不需要微调所有底层句子嵌入模型的参数。相反，我们只训练少量的额外参数，同时保持底层句子嵌入模型的权重不变。训练特定领域的适配器可以始终使用同一模型并在不同领域中获得良好的性能。

    Sentence embeddings enable us to capture the semantic similarity of short texts. Most sentence embedding models are trained for general semantic textual similarity (STS) tasks. Therefore, to use sentence embeddings in a particular domain, the model must be adapted to it in order to achieve good results. Usually, this is done by fine-tuning the entire sentence embedding model for the domain of interest. While this approach yields state-of-the-art results, all of the model's weights are updated during fine-tuning, making this method resource-intensive. Therefore, instead of fine-tuning entire sentence embedding models for each target domain individually, we propose to train lightweight adapters. These domain-specific adapters do not require fine-tuning all underlying sentence embedding model parameters. Instead, we only train a small number of additional parameters while keeping the weights of the underlying sentence embedding model fixed. Training domain-specific adapters allows always 
    
[^85]: 学习使用对比学习进行通信

    Learning to Communicate using Contrastive Learning. (arXiv:2307.01403v1 [cs.AI])

    [http://arxiv.org/abs/2307.01403](http://arxiv.org/abs/2307.01403)

    本研究提出了一种使用对比学习进行通信的方法，在分散的环境中通过最大化反映发送和接收消息关系的互信息来学习通信。在通信关键的环境中，我们的方法在性能和学习速度方面优于先前的工作，并且能够捕获全局状态信息，实现了更对称的通信。

    

    通信是多智能体强化学习中协调的有力工具。但在分散的环境中诱导一个有效的共同语言是一个困难的挑战。在这项工作中，我们引入了一个替代视角，即将智能体之间发送的通信消息视为环境状态的不完整视图。通过检查发送和接收的消息之间的关系，我们提出使用对比学习来最大化给定轨迹的消息之间的互信息来学习通信。在通信关键的环境中，我们的方法在性能和学习速度方面优于先前的工作。使用定性指标和表示探测，我们展示了我们的方法诱导了更对称的通信并从环境中捕获了全局状态信息。总体而言，我们展示了对比学习的力量以及利用消息作为编码实现有效通信的重要性。

    Communication is a powerful tool for coordination in multi-agent RL. But inducing an effective, common language is a difficult challenge, particularly in the decentralized setting. In this work, we introduce an alternative perspective where communicative messages sent between agents are considered as different incomplete views of the environment state. By examining the relationship between messages sent and received, we propose to learn to communicate using contrastive learning to maximize the mutual information between messages of a given trajectory. In communication-essential environments, our method outperforms previous work in both performance and learning speed. Using qualitative metrics and representation probing, we show that our method induces more symmetric communication and captures global state information from the environment. Overall, we show the power of contrastive learning and the importance of leveraging messages as encodings for effective communication.
    
[^86]: 模型训练中的模块化：一种新的模块化深度神经网络的范式

    Modularizing while Training: a New Paradigm for Modularizing DNN Models. (arXiv:2306.09376v1 [cs.LG])

    [http://arxiv.org/abs/2306.09376](http://arxiv.org/abs/2306.09376)

    本文提出了一种新方法，将模块化纳入模型训练过程中，即在训练时模块化(MwT)，通过两个损失函数实现模型结构上的模块化，进而实现模块的重用，能够在较短的训练时间内达到可比较的模型精度，并且相对于最先进的训练后模块化方法需要更少的参数。

    

    深度神经网络(DNN)模型已成为智能软件系统中越来越关键的组成部分。然而，训练DNN模型通常在时间和成本方面都很昂贵。为了解决这个问题，研究人员最近开始关注重用现有的DNN模型-借鉴软件工程中的代码重用思想。但是，重用整个模型可能会造成额外的开销或从不需要的功能中继承弱点。因此，现有的工作提出将已经训练好的模型分解成模块，即训练后的模块化，并实现模块的重用。但是，由于已经训练好的模型并不是为了模块化而构建的，所以训练后的模块化会导致巨大的开销和模型精度损失。本文提出了一种新方法，将模块化纳入模型训练过程中，即在训练时模块化（MwT）。我们通过两个损失函数在模型训练过程中使模型具有结构上的模块化能力，这两个损失函数同时优化模块内的内聚性和模块之间的独立性，从而得到一个真正的模块化模型。我们展示了我们的方法可以在较短的训练时间内达到可比较的模型精度，并且相对于最先进的训练后模块化方法需要更少的参数。

    Deep neural network (DNN) models have become increasingly crucial components in intelligent software systems. However, training a DNN model is typically expensive in terms of both time and money. To address this issue, researchers have recently focused on reusing existing DNN models - borrowing the idea of code reuse in software engineering. However, reusing an entire model could cause extra overhead or inherits the weakness from the undesired functionalities. Hence, existing work proposes to decompose an already trained model into modules, i.e., modularizing-after-training, and enable module reuse. Since trained models are not built for modularization, modularizing-after-training incurs huge overhead and model accuracy loss. In this paper, we propose a novel approach that incorporates modularization into the model training process, i.e., modularizing-while-training (MwT). We train a model to be structurally modular through two loss functions that optimize intra-module cohesion and int
    
[^87]: 人类偏好分数v2：用于评估文本到图像合成的人类偏好的可靠基准

    Human Preference Score v2: A Solid Benchmark for Evaluating Human Preferences of Text-to-Image Synthesis. (arXiv:2306.09341v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.09341](http://arxiv.org/abs/2306.09341)

    该论文提出了一个可以准确评估文本到图像合成中生成图像质量的可靠基准——人类偏好分数v2。通过引入人类偏好数据集v2（HPD v2）和微调CLIP，研究者们成功获得了更能预测人类偏好的评分模型HPS v2，其在各种图像分布中具有更好的泛化能力，并对文本到图像生成模型的算法改进具有响应性。

    

    最近的文本到图像生成模型可以从文本输入中生成高保真度的图像，但是这些生成图像的质量无法通过现有的评估指标准确评估。为解决这个问题，我们引入了人类偏好数据集v2（HPD v2），这是一个大规模数据集，捕捉了来自各种来源的图像的人类偏好。HPD v2包括798,090个人类偏好选择，涉及433,760对图像，是同类数据集中最大的数据集。文本提示和图像是经过精心收集的，以消除潜在的偏见，这是先前数据集中经常出现的问题。通过在HPD v2上微调CLIP，我们获得了人类偏好分数v2（HPS v2），这是一个可以更准确预测生成图像人类偏好的评分模型。我们的实验表明，HPS v2在各种图像分布中具有更好的泛化能力，对于文本到图像生成模型的算法改进具有响应性，使其成为更可取的选择。

    Recent text-to-image generative models can generate high-fidelity images from text inputs, but the quality of these generated images cannot be accurately evaluated by existing evaluation metrics. To address this issue, we introduce Human Preference Dataset v2 (HPD v2), a large-scale dataset that captures human preferences on images from a wide range of sources. HPD v2 comprises 798,090 human preference choices on 433,760 pairs of images, making it the largest dataset of its kind. The text prompts and images are deliberately collected to eliminate potential bias, which is a common issue in previous datasets. By fine-tuning CLIP on HPD v2, we obtain Human Preference Score v2 (HPS v2), a scoring model that can more accurately predict human preferences on generated images. Our experiments demonstrate that HPS v2 generalizes better than previous metrics across various image distributions and is responsive to algorithmic improvements of text-to-image generative models, making it a preferable
    
[^88]: 如何估计训练深度学习模型的碳足迹？一份指南和综述。

    How to estimate carbon footprint when training deep learning models? A guide and review. (arXiv:2306.08323v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.08323](http://arxiv.org/abs/2306.08323)

    这篇论文提出了一份详尽的指南和综述，介绍了如何估计训练深度学习模型的碳足迹，并比较了多种在线和软件工具的能源消耗估计结果。研究为AI从业人员在选择合适的工具和基础设施方面提供了建议。

    

    机器学习和深度学习模型在社会各个领域的快速发展中变得至关重要。人们普遍认识到这些模型的发展存在环境成本，已经有很多研究对此进行了分析。已经开发了几种在线和软件工具来跟踪机器学习模型训练过程中的能源消耗。在本文中，我们提出了对这些工具进行全面介绍和比较，并针对希望开始估计其工作环境影响的AI从业人员进行了讨论。我们对每个工具的特定词汇和技术要求进行了评估，并比较了这些工具对两个用于图像处理的深度神经网络和不同类型服务器的能源消耗估计结果。根据这些实验，我们提供了一些建议，以更好地选择合适的工具和基础设施。

    Machine learning and deep learning models have become essential in the recent fast development of artificial intelligence in many sectors of the society. It is now widely acknowledge that the development of these models has an environmental cost that has been analyzed in many studies. Several online and software tools have been developed to track energy consumption while training machine learning models. In this paper, we propose a comprehensive introduction and comparison of these tools for AI practitioners wishing to start estimating the environmental impact of their work. We review the specific vocabulary, the technical requirements for each tool. We compare the energy consumption estimated by each tool on two deep neural networks for image processing and on different types of servers. From these experiments, we provide some advice for better choosing the right tool and infrastructure.
    
[^89]: 高效的量化感知训练与自适应核心集选择

    Efficient Quantization-aware Training with Adaptive Coreset Selection. (arXiv:2306.07215v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.07215](http://arxiv.org/abs/2306.07215)

    本研究提出了一种用于改善量化感知训练的训练效率的方法，通过核心集选择和两个重要性指标来选择训练数据的子集。

    

    深度神经网络（DNN）的模型大小和计算量的增加，增加了对有效模型部署方法的需求。量化感知训练（QAT）是一种代表性的模型压缩方法，可以利用权重和激活中的冗余信息。然而，大多数现有的QAT方法需要在整个数据集上进行端到端训练，这会导致长时间的训练和高能耗。核心集选择是利用训练数据的冗余性提高数据效率的方法，在高效训练中被广泛应用。在这项工作中，我们提出了一种新的角度，通过核心集选择来提高量化感知训练的训练效率。基于QAT的特性，我们提出了两个指标：误差向量分数和不一致分数，用于量化训练过程中每个样本的重要性。基于这两个重要性指标，我们提出了一种量化感知的自适应核心集选择（ACS）方法，用于选择训练数据的子集。

    The expanding model size and computation of deep neural networks (DNNs) have increased the demand for efficient model deployment methods. Quantization-aware training (QAT) is a representative model compression method to leverage redundancy in weights and activations. However, most existing QAT methods require end-to-end training on the entire dataset, which suffers from long training time and high energy costs. Coreset selection, aiming to improve data efficiency utilizing the redundancy of training data, has also been widely used for efficient training. In this work, we propose a new angle through the coreset selection to improve the training efficiency of quantization-aware training. Based on the characteristics of QAT, we propose two metrics: error vector score and disagreement score, to quantify the importance of each sample during training. Guided by these two metrics of importance, we proposed a quantization-aware adaptive coreset selection (ACS) method to select the data for the
    
[^90]: 《可解释人工智能中的对抗性攻击和防御：调查报告》

    Adversarial Attacks and Defenses in Explainable Artificial Intelligence: A Survey. (arXiv:2306.06123v1 [cs.CR])

    [http://arxiv.org/abs/2306.06123](http://arxiv.org/abs/2306.06123)

    本文总结了对抗性攻击和防御在可解释人工智能中的研究。列出了现有的不安全因素，并表明了本领域的新兴研究方向。

    

    可解释人工智能（XAI）方法被描绘为调试和信任统计和深度学习模型的治疗方式，以及解释它们的预测。然而，对抗机器学习的最新进展突出了最新解释的局限性和漏洞，这些进展令人对其安全性和可信度产生质疑。操纵、欺骗或洗白模型推理证据的可能性在高风险决策和知识发现中产生不利后果。本文总结了50多篇论文的研究，概述了针对机器学习模型解释的对抗攻击以及公平度量的研究。我们讨论了如何防御攻击并设计鲁棒的解释方法。我们列出XAI中现有的不安全因素，并概述了对抗性XAI（AdvXAI）的新兴研究方向。

    Explainable artificial intelligence (XAI) methods are portrayed as a remedy for debugging and trusting statistical and deep learning models, as well as interpreting their predictions. However, recent advances in adversarial machine learning highlight the limitations and vulnerabilities of state-of-the-art explanations, putting their security and trustworthiness into question. The possibility of manipulating, fooling or fairwashing evidence of the model's reasoning has detrimental consequences when applied in high-stakes decision-making and knowledge discovery. This concise survey of over 50 papers summarizes research concerning adversarial attacks on explanations of machine learning models, as well as fairness metrics. We discuss how to defend against attacks and design robust interpretation methods. We contribute a list of existing insecurities in XAI and outline the emerging research directions in adversarial XAI (AdvXAI).
    
[^91]: FedMLSecurity：联邦学习与LLMs中攻击与防御的基准测试

    FedMLSecurity: A Benchmark for Attacks and Defenses in Federated Learning and LLMs. (arXiv:2306.04959v1 [cs.CR])

    [http://arxiv.org/abs/2306.04959](http://arxiv.org/abs/2306.04959)

    本文介绍了一个名为FedMLSecurity的基准测试，它可以模拟在联邦学习中可能出现的对抗攻击并提供相应的防御策略。该测试对各种机器学习模型和联合优化器都可以适用，并且能够轻松应用于大规模语言模型中。

    

    本文介绍了FedMLSecurity，这是一个在联邦学习（FL）中模拟对抗攻击和相应防御机制的基准测试。作为开源库FedML的一个重要模块，FedMLSecurity增强了FedML的安全评估能力。FedMLSecurity包含两个主要组件：FedMLAttacker模拟在FL训练中注入的攻击，而FedMLDefender则模拟旨在减轻攻击影响的防御策略。FedMLSecurity是开源的，可适用于各种机器学习模型（例如逻辑回归，ResNet，GAN等）和联合优化器（例如FedAVG，FedOPT，FedNOVA等）。本文的实验评估还展示了将FedMLSecurity轻松应用于LLMs的便利性，进一步强化了其各种场景下的通用性和实用性。

    This paper introduces FedMLSecurity, a benchmark that simulates adversarial attacks and corresponding defense mechanisms in Federated Learning (FL). As an integral module of the open-sourced library FedML that facilitates FL algorithm development and performance comparison, FedMLSecurity enhances the security assessment capacity of FedML. FedMLSecurity comprises two principal components: FedMLAttacker, which simulates attacks injected into FL training, and FedMLDefender, which emulates defensive strategies designed to mitigate the impacts of the attacks. FedMLSecurity is open-sourced 1 and is customizable to a wide range of machine learning models (e.g., Logistic Regression, ResNet, GAN, etc.) and federated optimizers (e.g., FedAVG, FedOPT, FedNOVA, etc.). Experimental evaluations in this paper also demonstrate the ease of application of FedMLSecurity to Large Language Models (LLMs), further reinforcing its versatility and practical utility in various scenarios.
    
[^92]: PDT: 面向时间感知的双向预训练变压器模型用于二分图

    PDT: Pretrained Dual Transformers for Time-aware Bipartite Graphs. (arXiv:2306.01913v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.01913](http://arxiv.org/abs/2306.01913)

    该论文提出了一种预训练模型，用于学习二分图中用户和内容之间的上下文知识，并采用对比学习任务以提高性能。

    

    在许多机器学习应用中，预先训练大型模型正在普及并涌现，随着不断增长的用户生成内容。已经认识到，从描绘用户内容交互的数据集中学习上下文知识对下游任务至关重要。尽管有几项研究尝试通过预训练方法学习上下文知识，但为这种任务找到最佳的训练目标和策略仍然是一个具有挑战性的问题。在这项工作中，我们认为在表示用户-内容交互的数据集中，有两个不同的上下文知识方面，即用户方面和内容方面。为了学习上下文知识，我们提出了一种预训练方法，该方法学习用户方面和内容方面之间的双向映射，我们将训练目标制定为对比学习任务，并提出了双重Transformer架构来编码上下文知识。

    Pre-training on large models is prevalent and emerging with the ever-growing user-generated content in many machine learning application categories. It has been recognized that learning contextual knowledge from the datasets depicting user-content interaction plays a vital role in downstream tasks. Despite several studies attempting to learn contextual knowledge via pre-training methods, finding an optimal training objective and strategy for this type of task remains a challenging problem. In this work, we contend that there are two distinct aspects of contextual knowledge, namely the user-side and the content-side, for datasets where user-content interaction can be represented as a bipartite graph. To learn contextual knowledge, we propose a pre-training method that learns a bi-directional mapping between the spaces of the user-side and the content-side. We formulate the training goal as a contrastive learning task and propose a dual-Transformer architecture to encode the contextual k
    
[^93]: 可学习空间可伸展卷积：超越双线性插值

    Dilated Convolution with Learnable Spacings: beyond bilinear interpolation. (arXiv:2306.00817v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.00817](http://arxiv.org/abs/2306.00817)

    可学习空间可伸展卷积（DCLS）通过使用可学习的间距和插值技巧，超越了双线性插值，在不增加参数的情况下提高了最先进卷积结构在ImageNet1k分类上的性能。

    

    可学习空间可伸展卷积（Dilated Convolution with Learnable Spacings，DCLS）是一种最近提出的改进型膨胀卷积，其中卷积核中非零元素的间距或者等效地说，它们的位置是可学习的。非整数位置通过插值处理，这种技巧使得位置具有明确的梯度。原始的DCLS使用双线性插值，只考虑了最近的四个像素。然而，我们在这里展示了更长程的插值，尤其是高斯插值，可以在不增加参数的情况下提高ConvNeXt和Conv-Former两个最先进的卷积结构在ImageNet1k分类上的性能。该方法的代码基于PyTorch，可以在https://github.com/K-H-Ismail/Dilated-Convolution-with-Learnable-Spacings-PyTorch上获得。

    Dilated Convolution with Learnable Spacings (DCLS) is a recently proposed variation of the dilated convolution in which the spacings between the non-zero elements in the kernel, or equivalently their positions, are learnable. Non-integer positions are handled via interpolation. Thanks to this trick, positions have well-defined gradients. The original DCLS used bilinear interpolation, and thus only considered the four nearest pixels. Yet here we show that longer range interpolations, and in particular a Gaussian interpolation, allow improving performance on ImageNet1k classification on two state-of-the-art convolutional architectures (ConvNeXt and Conv\-Former), without increasing the number of parameters. The method code is based on PyTorch and is available at https://github.com/K-H-Ismail/Dilated-Convolution-with-Learnable-Spacings-PyTorch
    
[^94]: GenQ：自动化问答生成器以帮助照顾者与孩子共读故事

    GenQ: Automated Question Generation to Support Caregivers While Reading Stories with Children. (arXiv:2305.16809v1 [cs.CL])

    [http://arxiv.org/abs/2305.16809](http://arxiv.org/abs/2305.16809)

    本研究设计了一个智能辅导系统（GenQ），可以根据照顾者和孩子之间的对话促进孩子的阅读理解能力，并通过考虑文化背景和语境变化以提高系统效果。

    

    当照顾者询问开放式问题以激发与孩子的对话时，可以促进孩子的阅读理解能力。虽然有利用技术工具来支持这个过程，即所谓的“智能辅导系统”的空间，但目前仍不清楚现有的生成类人语言问题的智能系统是否有益。此外，用于开发这些自动生成问题系统的培训数据通常没有考虑到人口统计学，但具有不同文化背景的人可能会提出不同的问题。作为为拉丁裔儿童设计智能阅读支持应用程序的广泛项目的一部分，我们从来自不同人口统计学的拉丁裔护理人员和非护理人员以及其他人口统计学背景的护理人员和非护理人员中群集大量问题。我们研究了这个数据集中个体、文化和环境因素中介的问题提问的变化。然后我们设计了一个系统来自动产生问题。

    When caregivers ask open--ended questions to motivate dialogue with children, it facilitates the child's reading comprehension skills.Although there is scope for use of technological tools, referred here as "intelligent tutoring systems", to scaffold this process, it is currently unclear whether existing intelligent systems that generate human--language like questions is beneficial. Additionally, training data used in the development of these automated question generation systems is typically sourced without attention to demographics, but people with different cultural backgrounds may ask different questions. As a part of a broader project to design an intelligent reading support app for Latinx children, we crowdsourced questions from Latinx caregivers and noncaregivers as well as caregivers and noncaregivers from other demographics. We examine variations in question--asking within this dataset mediated by individual, cultural, and contextual factors. We then design a system that autom
    
[^95]: KeyPosS: 基于 GPS 灵感的真实距离多边定位的即插即用面部标记检测

    KeyPosS: Plug-and-Play Facial Landmark Detection through GPS-Inspired True-Range Multilateration. (arXiv:2305.16437v1 [cs.CV])

    [http://arxiv.org/abs/2305.16437](http://arxiv.org/abs/2305.16437)

    KeyPosS是一种面部标记检测框架，采用真实距离多边定位算法实现快速而准确的检测，避免了传统方法中的计算负担和量化误差问题。

    

    在面部分析领域，准确的标记检测对于各种应用至关重要，包括人脸识别和表情分析等。然而，传统的热力图或坐标回归技术经常面临计算负担和量化误差等挑战。为解决这些问题，我们提出了 KeyPoint Positioning System（KeyPosS），这是一种突破性的面部标记检测框架，与现有方法不同。KeyPosS首次采用真实距离多边定位算法，一种最初用于GPS系统的技术，通过不依赖于计算密集型回归方法实现快速而准确的面部标记检测。该框架利用完全卷积网络预测距离图，计算感兴趣点（POI）与多个锚点之间的距离。通过巧妙地利用这些锚点来三角测量POI的位置，实现面部标记的检测。

    In the realm of facial analysis, accurate landmark detection is crucial for various applications, ranging from face recognition and expression analysis to animation. Conventional heatmap or coordinate regression-based techniques, however, often face challenges in terms of computational burden and quantization errors. To address these issues, we present the KeyPoint Positioning System (KeyPosS), a groundbreaking facial landmark detection framework that stands out from existing methods. For the first time, KeyPosS employs the True-range Multilateration algorithm, a technique originally used in GPS systems, to achieve rapid and precise facial landmark detection without relying on computationally intensive regression approaches. The framework utilizes a fully convolutional network to predict a distance map, which computes the distance between a Point of Interest (POI) and multiple anchor points. These anchor points are ingeniously harnessed to triangulate the POI's position through the Tru
    
[^96]: 分布式强化学习的好处：小损失边界

    The Benefits of Being Distributional: Small-Loss Bounds for Reinforcement Learning. (arXiv:2305.15703v1 [cs.LG])

    [http://arxiv.org/abs/2305.15703](http://arxiv.org/abs/2305.15703)

    通过小损失边界的视角，我们提供了分布式RL好处的一个解释，该边界与实例相关的最优成本成比例。如果最优成本很小，分布式方法优于非分布式方法。

    

    虽然分布式强化学习已经取得了实证成果，但其何时何地有益的问题尚未得到回答。在这项工作中，通过小损失边界的视角，我们提供了分布式RL好处的一个解释，该边界与实例相关的最优成本成比例。如果最优成本很小，我们的边界会比非分布式方法更强。作为热身，我们展示了学习成本分布会在情境展开（CB）中导致小损失后悔边界，我们发现分布式CB在三个具有挑战性的任务上比最先进的技术在实证上表现更好。对于在线RL，我们提出了一个分布式版本空间算法，该算法使用最大似然估计构建置信区间，并证明了它在表格MDP中实现了小损失后悔，同时在潜变量模型中享有小损失PAC边界。以类似的见解为基础，我们提出了一个分布式离线RL算法

    While distributional reinforcement learning (RL) has demonstrated empirical success, the question of when and why it is beneficial has remained unanswered. In this work, we provide one explanation for the benefits of distributional RL through the lens of small-loss bounds, which scale with the instance-dependent optimal cost. If the optimal cost is small, our bounds are stronger than those from non-distributional approaches. As warmup, we show that learning the cost distribution leads to small-loss regret bounds in contextual bandits (CB), and we find that distributional CB empirically outperforms the state-of-the-art on three challenging tasks. For online RL, we propose a distributional version-space algorithm that constructs confidence sets using maximum likelihood estimation, and we prove that it achieves small-loss regret in the tabular MDPs and enjoys small-loss PAC bounds in latent variable models. Building on similar insights, we propose a distributional offline RL algorithm bas
    
[^97]: 极端风险的模型评估

    Model evaluation for extreme risks. (arXiv:2305.15324v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.15324](http://arxiv.org/abs/2305.15324)

    当前建立通用人工智能系统的方法可能会产生既有益处又有害处的系统，而进一步发展人工智能可能导致极端风险，需要通过模型评估来解决这个问题。

    

    目前建立通用人工智能系统的方法往往会产生既有益处又有害处的系统。人工智能的进一步发展可能会导致具有极端风险的能力，例如攻击性的网络能力或强大的操纵技能。我们解释了为什么模型评估对于解决极端风险至关重要。开发者必须能够识别危险的能力（通过“危险能力评估”）以及模型应用能力对造成危害的倾向（通过“对齐评估”）。这些评估将对保持决策者和其他利益相关者的信息，并对模型训练、部署和安全性的负责任决策至关重要。

    Current approaches to building general-purpose AI systems tend to produce systems with both beneficial and harmful capabilities. Further progress in AI development could lead to capabilities that pose extreme risks, such as offensive cyber capabilities or strong manipulation skills. We explain why model evaluation is critical for addressing extreme risks. Developers must be able to identify dangerous capabilities (through "dangerous capability evaluations") and the propensity of models to apply their capabilities for harm (through "alignment evaluations"). These evaluations will become critical for keeping policymakers and other stakeholders informed, and for making responsible decisions about model training, deployment, and security.
    
[^98]: 基于多图融合的道路网络节点重要性排序方法的学习。

    Learning to Rank the Importance of Nodes in Road Networks Based on Multi-Graph Fusion. (arXiv:2305.14375v1 [cs.LG])

    [http://arxiv.org/abs/2305.14375](http://arxiv.org/abs/2305.14375)

    本文提出了一种新的基于图学习的节点排序方法（MGL2Rank），充分利用了道路网络的丰富特征，并且在实验中表现出比现有方法更高的精度和效率。

    

    在城市规划领域中，识别具有强传播能力的重要节点是一个重要的课题。然而，现有的评估节点重要性的方法仅考虑拓扑信息和交通流量，忽略了道路网络的多样性特征，如车道数量和道路段的平均速度，限制了它们的性能。为了解决这个问题，本文提出了一种基于图学习的节点排序方法（MGL2Rank），它集成了道路网络的丰富特征。在这种方法中，我们首先开发了一个采样算法（MGWalk），利用多图融合来建立基于属性的道路段之间的关联。然后，提出了一个嵌入模块，用于学习每个道路段的潜在表示。最后，得到的节点表示用于学习道路段的重要性排序。我们在中国沈阳市区域道路网络上进行了仿真实验，评估了MGL2Rank的有效性。实验结果表明，MGL2Rank在精度和效率方面优于现有的节点排序方法。

    Identifying important nodes with strong propagation capabilities in road networks is a significant topic in the field of urban planning. However, existing methods for evaluating nodes importance consider only topological information and traffic volumes, ignoring the diversity of characteristics in road networks, such as the number of lanes and average speed of road segments, limiting their performance. To address this issue, this paper proposes a graph learning-based node ranking method (MGL2Rank) that integrates the rich characteristics of the road network. In this method, we first develop a sampling algorithm (MGWalk) that utilizes multi-graph fusion to establish association between road segments based on their attributes. Then, an embedding module is proposed to learn latent representation for each road segment. Finally, the obtained node representation is used to learn importance ranking of road segments. We conduct simulation experiments on the regional road network of Shenyang ci
    
[^99]: 内容丰富的多模态转换器训练与 LoReTTa

    Training Transitive and Commutative Multimodal Transformers with LoReTTa. (arXiv:2305.14243v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.14243](http://arxiv.org/abs/2305.14243)

    LoReTTa是一个自监督框架，可以在具有不同模态的数据集中转换。通过合成数据集的方法，显著提高了下游任务的性能。

    

    实践中，收集两个匹配的形态A和B或B和C的多模态数据集很困难，获得包含三个对齐形态A、B和C的数据集更加具有挑战性。我们引入了LoReTTa以应对这个未被充分研究的问题。我们的自监督框架结合了因果掩码建模和交换律和传递性的规则，可以在不同的模态中转换。我们的实验表明，这种合成显着提高了下游任务的性能。

    Collecting a multimodal dataset with two paired modalities A and B or B and C is difficult in practice. Obtaining a dataset with three aligned modalities A, B, and C is even more challenging. For example, some public medical datasets have only genetic sequences and microscopic images for one patient, and only genetic sequences and radiological images for another - but no dataset includes both microscopic and radiological images for the same patient. This makes it difficult to integrate and combine all modalities into a large pre-trained neural network. We introduce LoReTTa (Linking mOdalities with a tRansitive and commutativE pre-Training sTrAtegy) to address this understudied problem. Our self-supervised framework combines causal masked modeling with the rules of commutativity and transitivity to transition within and between different modalities. Thus, it can model the relation A -> C with A -> B -> C. Given a dataset containing only the disjoint combinations (A, B) and (B, C), we sh
    
[^100]: 关于一般函数逼近下的均场强化学习的统计效率

    On the Statistical Efficiency of Mean Field Reinforcement Learning with General Function Approximation. (arXiv:2305.11283v1 [cs.LG])

    [http://arxiv.org/abs/2305.11283](http://arxiv.org/abs/2305.11283)

    本文研究了一般函数逼近下的均场控制(MFC)和均场博弈(MFG)中的强化学习的统计效率，提出了基于乐观最大似然估计的算法，并仅对转移动力学具有Lipschitz连续性的假设，最后建立了一个指数级的下界支持MFC设置。

    

    本文研究了一般函数逼近下的均场控制（MFC）和均场博弈（MFG）中强化学习的统计效率。引入了一种称为Mean-Field Model-Based Eluder Dimension (MBED)的新概念，包含了一系列丰富的均场强化学习问题。此外，我们提出了基于乐观最大似然估计的算法，可以返回一个$\epsilon$优的策略，适用于MFC或$\epsilon$纳什均衡策略适用于MFG，样本复杂度多项式与相关参数无关，与状态、动作和代理数量无关。值得注意的是，我们的结果仅对转移动力学具有Lipschitz连续性的假设，避免了以前的强结构假设。最后，在tabular设置下，假设有一个生成模型，我们建立了一个指数级的下界支持MFC设置，同时提供了一种新颖的样本高效的模型消除算法以逼近最优策略。

    In this paper, we study the statistical efficiency of Reinforcement Learning in Mean-Field Control (MFC) and Mean-Field Game (MFG) with general function approximation. We introduce a new concept called Mean-Field Model-Based Eluder Dimension (MBED), which subsumes a rich family of Mean-Field RL problems. Additionally, we propose algorithms based on Optimistic Maximal Likelihood Estimation, which can return an $\epsilon$-optimal policy for MFC or an $\epsilon$-Nash Equilibrium policy for MFG, with sample complexity polynomial w.r.t. relevant parameters and independent of the number of states, actions and the number of agents. Notably, our results only require a mild assumption of Lipschitz continuity on transition dynamics and avoid strong structural assumptions in previous work. Finally, in the tabular setting, given the access to a generative model, we establish an exponential lower bound for MFC setting, while providing a novel sample-efficient model elimination algorithm to approxim
    
[^101]: 一种通用动力学模型用于控制

    A Generalist Dynamics Model for Control. (arXiv:2305.10912v1 [cs.AI])

    [http://arxiv.org/abs/2305.10912](http://arxiv.org/abs/2305.10912)

    本文研究使用Transformer序列模型作为控制的动力学模型(TDMs)，证明TDMs表现良好且具有强大的泛化能力，相比于直接作为策略通用最优行为，泛化系统动力学可以更好地工作。

    

    本文研究使用Transformer序列模型作为控制的动力学模型(TDMs)。我们在DeepMind控制套件中进行了一系列实验，发现首先，在单环境学习设置中，与基准模型相比，TDMs表现良好。其次，TDMs表现出强大的泛化能力，可以很好地应用于未见过的环境，包括few-shot学习和zero-shot学习。我们进一步证明，相比于直接作为策略通用最优行为，泛化系统动力学可以更好地工作。这使得TDMs成为控制的基础模型中具有很大的潜力的一个重要组成部分。

    We investigate the use of transformer sequence models as dynamics models (TDMs) for control. In a number of experiments in the DeepMind control suite, we find that first, TDMs perform well in a single-environment learning setting when compared to baseline models. Second, TDMs exhibit strong generalization capabilities to unseen environments, both in a few-shot setting, where a generalist model is fine-tuned with small amounts of data from the target environment, and in a zero-shot setting, where a generalist model is applied to an unseen environment without any further training. We further demonstrate that generalizing system dynamics can work much better than generalizing optimal behavior directly as a policy. This makes TDMs a promising ingredient for a foundation model of control.
    
[^102]: MM-Fi：用于多种无线传感的多模态非侵入式4D人体数据集

    MM-Fi: Multi-Modal Non-Intrusive 4D Human Dataset for Versatile Wireless Sensing. (arXiv:2305.10345v1 [eess.SP])

    [http://arxiv.org/abs/2305.10345](http://arxiv.org/abs/2305.10345)

    提出了第一个多模态非侵入式的4D人体数据集MM-Fi，用于多种无线传感任务的支持。该数据集包含40名受试者的超过320K同步帧的五种模态，支持人体姿态估计和动作识别等任务的开展。

    

    在家庭自动化和元宇宙人物模拟等众多应用中，4D人体感知起着至关重要的作用。然而，现有的解决方案主要依赖于摄像头和可穿戴设备，要么侵犯隐私，要么使用不便。为了解决这些问题，无线传感成为潜在的选择，利用激光雷达、毫米波雷达和WiFi信号进行非设备式人体感知。本文提出了MM-Fi，第一个包含27种日常或康复动作类别的多模态非侵入式4D人体数据集，以弥合无线传感和高级人体感知任务之间的差距。MM-Fi由40名人体主体的超过320K同步帧的五个模态组成。提供了各种注释以支持潜在的感知任务，例如人体姿态估计和动作识别。通过对多个任务的模态的感知能力进行比较，进行了大量实验。我们预计这些数据和所提出的评估协议将有助于开发新的无线传感算法，用于多种人体感知任务。

    4D human perception plays an essential role in a myriad of applications, such as home automation and metaverse avatar simulation. However, existing solutions which mainly rely on cameras and wearable devices are either privacy intrusive or inconvenient to use. To address these issues, wireless sensing has emerged as a promising alternative, leveraging LiDAR, mmWave radar, and WiFi signals for device-free human sensing. In this paper, we propose MM-Fi, the first multi-modal non-intrusive 4D human dataset with 27 daily or rehabilitation action categories, to bridge the gap between wireless sensing and high-level human perception tasks. MM-Fi consists of over 320k synchronized frames of five modalities from 40 human subjects. Various annotations are provided to support potential sensing tasks, e.g., human pose estimation and action recognition. Extensive experiments have been conducted to compare the sensing capacity of each or several modalities in terms of multiple tasks. We envision th
    
[^103]: 探索机器遗忘的领域：一篇综述与分类

    Exploring the Landscape of Machine Unlearning: A Survey and Taxonomy. (arXiv:2305.06360v1 [cs.LG])

    [http://arxiv.org/abs/2305.06360](http://arxiv.org/abs/2305.06360)

    本文综述了机器遗忘的现状和技术应用，包括数据删除、扰动和模型更新，讨论了MU在隐私、安全和公正性等领域的潜在益处，以及它在自然语言处理、计算机视觉和推荐系统中的未来发展方向。

    

    机器遗忘是一个越来越受关注的领域，因为需要删除或修改机器学习模型所做出的预测。虽然训练模型变得更加有效和准确，但在某些领域（如隐私、安全和公正性），遗忘先前学到的信息的重要性变得越来越显著。本文介绍了机器遗忘的综述，涵盖了当前最先进的技术和方法，包括数据删除、扰动和模型更新。此外，文中还介绍了常用的度量标准和数据集。文章还强调了需要解决的挑战，包括攻击复杂性、标准化、可转移性、可解释性、训练数据和资源限制。本文的贡献包括讨论MU的潜在益处以及它在自然语言处理、计算机视觉和推荐系统中的未来方向。

    Machine unlearning (MU) is a field that is gaining increasing attention due to the need to remove or modify predictions made by machine learning (ML) models. While training models have become more efficient and accurate, the importance of unlearning previously learned information has become increasingly significant in fields such as privacy, security, and fairness. This paper presents a comprehensive survey of MU, covering current state-of-the-art techniques and approaches, including data deletion, perturbation, and model updates. In addition, commonly used metrics and datasets are also presented. The paper also highlights the challenges that need to be addressed, including attack sophistication, standardization, transferability, interpretability, training data, and resource constraints. The contributions of this paper include discussions about the potential benefits of MU and its future directions in Natural Language Processing, Computer vision, and Recommender Systems. Additionally, 
    
[^104]: 眼见不一定为实：人类感知AI生成图像的定量研究

    Seeing is not always believing: A Quantitative Study on Human Perception of AI-Generated Images. (arXiv:2304.13023v1 [cs.AI])

    [http://arxiv.org/abs/2304.13023](http://arxiv.org/abs/2304.13023)

    本研究揭示了人类无法辨别AI生成的假照片和真实照片，这一点受个人背景的影响并不显著。

    

    照片是人们记录日常生活经历的一种方式，通常被认为是可信的信息来源。然而，越来越多的人担心人工智能（AI）技术的进步可能产生伪造的照片，从而产生困惑并降低对照片的信任。本研究旨在回答一个问题，即当前最先进的基于AI的视觉内容生成模型能否持续地欺骗人类的眼睛，并传达错误信息。通过对50名参与者进行高质量的定量研究，我们首次揭示，人类无法显著区分真实照片和AI创建的伪造照片，达到38.7%。我们的研究还发现，个人的背景，如性别，年龄和经验，对区分AI生成的图像和真实照片的能力没有显著影响。但是，我们观察到

    Photos serve as a way for humans to record what they experience in their daily lives, and they are often regarded as trustworthy sources of information. However, there is a growing concern that the advancement of artificial intelligence (AI) technology may produce fake photos, which can create confusion and diminish trust in photographs. This study aims to answer the question of whether the current state-of-the-art AI-based visual content generation models can consistently deceive human eyes and convey false information. By conducting a high-quality quantitative study with fifty participants, we reveal, for the first time, that humans cannot distinguish between real photos and AI-created fake photos to a significant degree 38.7%. Our study also finds that an individual's background, such as their gender, age, and experience with AI-generated content (AIGC), does not significantly affect their ability to distinguish AI-generated images from real photographs. However, we do observe that 
    
[^105]: 自然分布漂移下低样本稳健性的基准测试

    Benchmarking Low-Shot Robustness to Natural Distribution Shifts. (arXiv:2304.11263v1 [cs.CV])

    [http://arxiv.org/abs/2304.11263](http://arxiv.org/abs/2304.11263)

    本文通过对不同少样本数据集、架构、预训练初始化和稳健性干预的自然分布漂移的稳健性进行了首次深入研究，发现没有单一的选择模型比其他模型更稳健，现有的干预措施也可能无法提高某些数据集的稳健性。

    

    近年来，结合更好的微调方法的预训练策略已经取得了针对自然分布漂移的鲁棒性的显著进展。然而，这样的微调假设可以访问大量标记数据，而当训练数据量不高时观察到的情况尚不清楚。我们通过对不同少样本数据集、架构、预训练初始化和最先进的稳健性干预的自然分布漂移的稳健性进行了首次深入研究，填补了这一空白。最重要的是，我们发现没有单一的选择模型比其他模型更稳健，即使在完整样本下，现有的干预措施也可能无法提高某些数据集的稳健性。我们希望我们的工作能够激励社区关注这个实际重要性的问题。

    Robustness to natural distribution shifts has seen remarkable progress thanks to recent pre-training strategies combined with better fine-tuning methods. However, such fine-tuning assumes access to large amounts of labelled data, and the extent to which the observations hold when the amount of training data is not as high remains unknown. We address this gap by performing the first in-depth study of robustness to various natural distribution shifts in different low-shot regimes: spanning datasets, architectures, pre-trained initializations, and state-of-the-art robustness interventions. Most importantly, we find that there is no single model of choice that is often more robust than others, and existing interventions can fail to improve robustness on some datasets even if they do so in the full-shot regime. We hope that our work will motivate the community to focus on this problem of practical importance.
    
[^106]: 基于采样的反应综合算法应用于非确定性混合系统

    Sampling-based Reactive Synthesis for Nondeterministic Hybrid Systems. (arXiv:2304.06876v1 [eess.SY])

    [http://arxiv.org/abs/2304.06876](http://arxiv.org/abs/2304.06876)

    本文提出了一种基于采样的策略综合算法，用于具有复杂连续动力学和时间和可达性约束的非确定性混合系统。算法基于在混合空间中生长（搜索）游戏树，以合成一种反应（鲁棒）策略，以满足目标并在可扩展性和效率方面优于最新技术水平。

    

    本文提出了一种基于采样的策略综合算法，用于具有复杂连续动力学和时间和可达性约束的非确定性混合系统。我们将混合系统的演化视为一个双人游戏，其中非确定性是一个对手玩家，其目标是阻止实现时间和可达性目标。旨在合成一种获胜策略——一种反应（鲁棒）策略，它保证在对手玩家的所有可能移动下满足目标。该方法基于在混合空间中生长（搜索）游戏树，通过将基于采样的规划方法与一种用于选择和改进部分策略的新型乘客舱机技术相结合。我们提供的条件下，算法是概率上完备的，即，如果存在获胜策略，该算法几乎肯定会找到它。案例研究和基准结果表明，该算法具有广泛的适用性，并在可扩展性和效率方面始终优于最新技术水平。

    This paper introduces a sampling-based strategy synthesis algorithm for nondeterministic hybrid systems with complex continuous dynamics under temporal and reachability constraints. We view the evolution of the hybrid system as a two-player game, where the nondeterminism is an adversarial player whose objective is to prevent achieving temporal and reachability goals. The aim is to synthesize a winning strategy -- a reactive (robust) strategy that guarantees the satisfaction of the goals under all possible moves of the adversarial player. The approach is based on growing a (search) game-tree in the hybrid space by combining a sampling-based planning method with a novel bandit-based technique to select and improve on partial strategies. We provide conditions under which the algorithm is probabilistically complete, i.e., if a winning strategy exists, the algorithm will almost surely find it. The case studies and benchmark results show that the algorithm is general and consistently outperf
    
[^107]: 个性化文本到图像生成的可控文本反转

    Controllable Textual Inversion for Personalized Text-to-Image Generation. (arXiv:2304.05265v1 [cs.CV])

    [http://arxiv.org/abs/2304.05265](http://arxiv.org/abs/2304.05265)

    本文提出了一种名为COTI的技术，通过引入理论指导的损失目标和全面的加权评分机制，并结合主动学习范式来解决文本反转时的困难，提供了一个强大，数据效率高，易于使用的框架。

    

    最近，大规模生成模型在以文本为引导的高保真图像的生成方面取得了前所未有的性能。当引导信息包含用户定义的、未见过的或长尾概念标记时，文本反转成为一种有效的个性化生成技术。尽管如此，我们发现并展示了文本反转的部署仍充满了“黑魔法”，例如额外数据集的严苛要求，在循环中需要艰苦的人力成本和缺乏鲁棒性等。在这项工作中，我们提出了一种名为可控文本反转的大大增强版反转，解决了所有上述问题，并反过来提供了一个强大，数据效率高，易于使用的框架。COTI的核心是基于理论的损失目标，具有全面和新颖的加权评分机制，并由主动学习范式所提取。广泛的结果表明，COTI的性能比之前技术有了显著的提升，尤其是在数据少的情况下。

    The recent large-scale generative modeling has attained unprecedented performance especially in producing high-fidelity images driven by text prompts. Text inversion (TI), alongside the text-to-image model backbones, is proposed as an effective technique in personalizing the generation when the prompts contain user-defined, unseen or long-tail concept tokens. Despite that, we find and show that the deployment of TI remains full of "dark-magics" -- to name a few, the harsh requirement of additional datasets, arduous human efforts in the loop and lack of robustness. In this work, we propose a much-enhanced version of TI, dubbed Controllable Textual Inversion (COTI), in resolving all the aforementioned problems and in turn delivering a robust, data-efficient and easy-to-use framework. The core to COTI is a theoretically-guided loss objective instantiated with a comprehensive and novel weighted scoring mechanism, encapsulated by an active-learning paradigm. The extensive results show that 
    
[^108]: 基于深度强化学习的无图Crowd Navigation与感知风险控制的移动机器人

    Deep Reinforcement Learning-Based Mapless Crowd Navigation with Perceived Risk of the Moving Crowd for Mobile Robots. (arXiv:2304.03593v1 [cs.RO])

    [http://arxiv.org/abs/2304.03593](http://arxiv.org/abs/2304.03593)

    本论文提出了一种基于碰撞概率的无图Crowd Navigation方法，使用深度强化学习(DRL)来感知人群的危险程度，确保机器人在通过拥挤环境时的安全，同时提高模型的可扩展性。

    

    传统的基于地图的机器人导航方法在拥挤环境中往往会遇到“冻结机器人问题”。深度强化学习方法解决了此问题，但是存在泛化和可扩展性的问题。为了克服这些挑战，我们提出一种使用“碰撞概率”来帮助机器人安全通过人群的方法。将“碰撞概率”包括在观察空间中，给机器人提供了一个感知移动人群的危险程度的能力。机器人会在看似安全的情况下穿过人群，但在人群移动过于激烈时会绕路。通过关注最危险的障碍物，机器人不会在人群密度较高时混淆，确保模型的可扩展性。我们的方法使用深度强化学习(DRL)开发，并在Gazebo模拟器中进行了非合作人群环境中的训练，其中的障碍物以随机速度移动。

    Classical map-based navigation methods are commonly used for robot navigation, but they often struggle in crowded environments due to the Frozen Robot Problem (FRP). Deep reinforcement learning-based methods address the FRP problem, however, suffer from the issues of generalization and scalability. To overcome these challenges, we propose a method that uses Collision Probability (CP) to help the robot navigate safely through crowds. The inclusion of CP in the observation space gives the robot a sense of the level of danger of the moving crowd. The robot will navigate through the crowd when it appears safe but will take a detour when the crowd is moving aggressively. By focusing on the most dangerous obstacle, the robot will not be confused when the crowd density is high, ensuring scalability of the model. Our approach was developed using deep reinforcement learning (DRL) and trained using the Gazebo simulator in a non cooperative crowd environment with obstacles moving at randomized sp
    
[^109]: 利用语言指导的三模态一致性进行音频-视频源分离

    Language-Guided Audio-Visual Source Separation via Trimodal Consistency. (arXiv:2303.16342v1 [cs.CV])

    [http://arxiv.org/abs/2303.16342](http://arxiv.org/abs/2303.16342)

    该论文提出了一种自监督学习的方法，通过使用自然语言查询来进行音频源分离，实现了语言、视觉和音频的一致性对齐，并在多个数据集上表现出比现有方法更好的效果。

    

    我们提出了一种自监督学习的方法，基于自然语言查询在视频中学习执行音频源分离，仅使用未标记的视频和音频对作为训练数据。这项任务的一个关键挑战是学习将发声物体的语言描述与其视觉特征和相应的音频波形组件联系起来，而在训练期间没有访问注释。为了克服这个挑战，我们改进了现成的视觉语言基础模型，通过两种新的损失函数提供伪目标监督，并促进音频、视觉和自然语言模态之间更强的对齐。在推理过程中，我们的方法可以在给定文本、视频和音频输入或仅给定文本和音频输入时分离声音。我们在三个音频-视频分离数据集（包括MUSIC、SOLOS和AudioSet）上展示了我们自监督方法的有效性，其中我们的模型胜过了现有强监督方法的最新成果。

    We propose a self-supervised approach for learning to perform audio source separation in videos based on natural language queries, using only unlabeled video and audio pairs as training data. A key challenge in this task is learning to associate the linguistic description of a sound-emitting object to its visual features and the corresponding components of the audio waveform, all without access to annotations during training. To overcome this challenge, we adapt off-the-shelf vision-language foundation models to provide pseudo-target supervision via two novel loss functions and encourage a stronger alignment between the audio, visual and natural language modalities. During inference, our approach can separate sounds given text, video and audio input, or given text and audio input alone. We demonstrate the effectiveness of our self-supervised approach on three audio-visual separation datasets, including MUSIC, SOLOS and AudioSet, where we outperform state-of-the-art strongly supervised 
    
[^110]: 理解和探索稀疏广义可加模型的整个优秀集合

    Understanding and Exploring the Whole Set of Good Sparse Generalized Additive Models. (arXiv:2303.16047v1 [cs.LG])

    [http://arxiv.org/abs/2303.16047](http://arxiv.org/abs/2303.16047)

    提出一种有效而准确地近似稀疏广义可加模型（GAMs）的Rashomon集的技术，并使用这些近似模型来解决实际应用的挑战。

    

    在实际应用中，机器学习模型与领域专家之间的交互至关重要；然而，通常只生成单个模型的经典机器学习范式不利于此类交互。近似和探索Rashomon集，即所有近乎最优模型的集合，通过提供用户可搜索的空间包含多样性模型的方法，解决了这一实际挑战，领域专家可以从中选择。我们提出了一种有效而准确地近似稀疏广义可加模型（GAMs）的Rashomon集的技术。我们提供了用于近似具有固定支持集的GAMs的Rashomon集的椭球形算法，并使用这些椭球形近似了许多不同支持集的Rashomon集。近似的Rashomon集为解决实际挑战，例如（1）研究模型类的变量重要性；（2）在用户指定约束条件下查找模型，提供了重要的基础。

    In real applications, interaction between machine learning model and domain experts is critical; however, the classical machine learning paradigm that usually produces only a single model does not facilitate such interaction. Approximating and exploring the Rashomon set, i.e., the set of all near-optimal models, addresses this practical challenge by providing the user with a searchable space containing a diverse set of models from which domain experts can choose. We present a technique to efficiently and accurately approximate the Rashomon set of sparse, generalized additive models (GAMs). We present algorithms to approximate the Rashomon set of GAMs with ellipsoids for fixed support sets and use these ellipsoids to approximate Rashomon sets for many different support sets. The approximated Rashomon set serves as a cornerstone to solve practical challenges such as (1) studying the variable importance for the model class; (2) finding models under user-specified constraints (monotonicity
    
[^111]: 健康信息学中的大型AI模型：应用、挑战和未来展望

    Large AI Models in Health Informatics: Applications, Challenges, and the Future. (arXiv:2303.11568v1 [cs.AI])

    [http://arxiv.org/abs/2303.11568](http://arxiv.org/abs/2303.11568)

    大型AI模型在健康信息学领域具有突破性应用，但其规模和数据量的挑战需要克服，未来仍需深入探索。

    

    大型AI模型是最近出现的模型，具有庞大的参数和数据规模，其规模往往超过数十亿。一旦预训练，大型AI模型在各种下游任务中展现出令人印象深刻的性能。在健康信息学领域，大型AI模型的出现为方法学设计带来了新的范例，并为健康相关领域的突破提供了推动力量。本文对大型AI模型进行了全面综述，包括背景、应用和挑战等方面。

    Large AI models, or foundation models, are models recently emerging with massive scales both parameter-wise and data-wise, the magnitudes of which often reach beyond billions. Once pretrained, large AI models demonstrate impressive performance in various downstream tasks. A concrete example is the recent debut of ChatGPT, whose capability has compelled people's imagination about the far-reaching influence that large AI models can have and their potential to transform different domains of our life. In health informatics, the advent of large AI models has brought new paradigms for the design of methodologies. The scale of multimodality data in the biomedical and health domain has been ever-expanding especially since the community embraced the era of deep learning, which provides the ground to develop, validate, and advance large AI models for breakthroughs in health-related areas. This article presents an up-to-date comprehensive review of large AI models, from background to their applic
    
[^112]: 无监督解释性基础抽取用于基于概念的视觉解释

    Unsupervised Interpretable Basis Extraction for Concept-Based Visual Explanations. (arXiv:2303.10523v1 [cs.CV])

    [http://arxiv.org/abs/2303.10523](http://arxiv.org/abs/2303.10523)

    本文提出了一种无监督的方法，通过对CNN进行转换，从而更好地解释中间层的表示，提取了一个可解释性欠完备基础，并证明该方法在各种网络结构和训练数据集上都很有效。

    

    研究人员尝试用人类可以理解的概念来解释CNN图像分类器预测和中间层表示。本文提出了一种无监督后处理方法，通过查找解释像素激活的稀疏二值化转换表示的特征空间旋转来提取解释性欠完备基础。我们对现有的流行CNN进行了实验，并证明了我们方法在网络架构和训练数据集上提取解释性基础的有效性。最后，我们扩展了文献中的基础可解释性度量，并表明，当中间层表示被转换为我们方法提取的基础时，它们变得更易解释。

    An important line of research attempts to explain CNN image classifier predictions and intermediate layer representations in terms of human understandable concepts. In this work, we expand on previous works in the literature that use annotated concept datasets to extract interpretable feature space directions and propose an unsupervised post-hoc method to extract a disentangling interpretable basis by looking for the rotation of the feature space that explains sparse one-hot thresholded transformed representations of pixel activations. We do experimentation with existing popular CNNs and demonstrate the effectiveness of our method in extracting an interpretable basis across network architectures and training datasets. We make extensions to the existing basis interpretability metrics found in the literature and show that, intermediate layer representations become more interpretable when transformed to the bases extracted with our method. Finally, using the basis interpretability metrics
    
[^113]: 合并决策Transformer：多任务策略形成的权重平均化

    Merging Decision Transformers: Weight Averaging for Forming Multi-Task Policies. (arXiv:2303.07551v1 [cs.LG])

    [http://arxiv.org/abs/2303.07551](http://arxiv.org/abs/2303.07551)

    本文提出通过在权重空间中合并训练于不同 MuJoCo 运动问题上的 Decision Transformer 的子集，形成多任务模型。通过共享一些辅助任务的训练以及共同使用预训练初始化，能够获得更好的结果。这个方向的研究有助于使代理的过程民主化和分发。

    

    最近的研究展示了基于Transformer的通用语言、视觉和连续决策制定问题的策略的前景。为了创建这样的模型，我们通常需要集中的训练目标、数据和计算。如果我们能够更灵活地创建通用策略，通过合并多个任务特定的、单独训练的策略，则这样做就比较有意义。在本文中，我们通过在权重空间中合并或平均不同MuJoCo运动问题上训练的Decision Transformer的子集来迈出这个方向的初步步骤，形成没有集中训练的多任务模型。我们还建议在合并策略时可以获得更好的结果，如果所有策略都从共同的预训练初始化开始，并在问题特定的微调期间共同训练共享的辅助任务。一般来说，我们相信这个方向的研究可以帮助民主化和分发具有一般能力的代理的过程。

    Recent work has shown the promise of creating generalist, transformer-based, policies for language, vision, and sequential decision-making problems. To create such models, we generally require centralized training objectives, data, and compute. It is of interest if we can more flexibly create generalist policies, by merging together multiple, task-specific, individually trained policies. In this work, we take a preliminary step in this direction through merging, or averaging, subsets of Decision Transformers in weight space trained on different MuJoCo locomotion problems, forming multi-task models without centralized training. We also propose that when merging policies, we can obtain better results if all policies start from common, pre-trained initializations, while also co-training on shared auxiliary tasks during problem-specific finetuning. In general, we believe research in this direction can help democratize and distribute the process of which forms generally capable agents.
    
[^114]: GOATS：目标采样自适应课程强化学习用于舀取任务

    GOATS: Goal Sampling Adaptation for Scooping with Curriculum Reinforcement Learning. (arXiv:2303.05193v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.05193](http://arxiv.org/abs/2303.05193)

    本文提出了一种名为GOATS的方法，使用目标采样自适应课程强化学习技术，通过插值位置目标和数量目标的分布创建学习过程中的课程来解决机器人舀取任务中的位置目标和水量目标问题，取得了比基线更好的表现。

    

    本文首先使用目标条件强化学习对机器人舀取水的问题进行了阐述。由于流体的复杂动力学和实现多模式目标的需求，该任务具有特别的挑战性。政策需要成功地达到位置目标和水量目标，这导致一个庞大而复杂的目标状态空间。为了克服这些挑战，我们引入了GOATS，一种课程强化学习方法，通过插值位置目标分布和数量目标分布来创建学习过程中的课程，使用目标分解奖励公式，学习一个高效且具有通用性的机器人舀取策略。结果，我们的方法可以在仿真中表现出比基线更好的性能，分别在碗舀和桶舀任务中实现了5.46％和8.71％的误差，涵盖了1000种初始水状态的变化。

    In this work, we first formulate the problem of robotic water scooping using goal-conditioned reinforcement learning. This task is particularly challenging due to the complex dynamics of fluid and the need to achieve multi-modal goals. The policy is required to successfully reach both position goals and water amount goals, which leads to a large convoluted goal state space. To overcome these challenges, we introduce Goal Sampling Adaptation for Scooping (GOATS), a curriculum reinforcement learning method that can learn an effective and generalizable policy for robot scooping tasks. Specifically, we use a goal-factorized reward formulation and interpolate position goal distributions and amount goal distributions to create curriculum throughout the learning process. As a result, our proposed method can outperform the baselines in simulation and achieves 5.46% and 8.71% amount errors on bowl scooping and bucket scooping tasks, respectively, under 1000 variations of initial water states in
    
[^115]: 旅行需求预测：公正的人工智能方法

    Travel Demand Forecasting: A Fair AI Approach. (arXiv:2303.01692v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.01692](http://arxiv.org/abs/2303.01692)

    本研究提出了一种新的方法来开发具有公平意识的、高度准确的旅行需求预测模型，该方法可以同时提高AI模型对于多个受保护属性的公平性。

    

    人工智能（AI）和机器学习越来越多地被用于旅行需求预测。尽管基于AI的旅行需求预测模型能产生准确的预测，但可能会产生预测偏差并引发公平性问题。使用这些有偏见模型进行决策可能会导致加剧社会不平等的交通政策。然而，目前对于解决这些模型的公平性问题的研究有限。因此，在本研究中，我们提出了一种新的方法来开发具有公平意识的、高度准确的旅行需求预测模型。特别地，我们提出的方法可以同时提高AI模型对于多个受保护属性（如种族和收入）的公平性。具体来说，我们引入了一个新的公平性正则化项，该项明确地设计用于衡量预测准确性与多个受保护属性之间的相关性，并将其加入到旅行需求预测模型的损失函数中。

    Artificial Intelligence (AI) and machine learning have been increasingly adopted for travel demand forecasting. The AI-based travel demand forecasting models, though generate accurate predictions, may produce prediction biases and raise fairness issues. Using such biased models for decision-making may lead to transportation policies that exacerbate social inequalities. However, limited studies have been focused on addressing the fairness issues of these models. Therefore, in this study, we propose a novel methodology to develop fairness-aware, highly-accurate travel demand forecasting models. Particularly, the proposed methodology can enhance the fairness of AI models for multiple protected attributes (such as race and income) simultaneously. Specifically, we introduce a new fairness regularization term, which is explicitly designed to measure the correlation between prediction accuracy and multiple protected attributes, into the loss function of the travel demand forecasting model. We
    
[^116]: 基于聚类技术的灵活能源社区目标需求响应

    Targeted demand response for flexible energy communities using clustering techniques. (arXiv:2303.00186v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00186](http://arxiv.org/abs/2303.00186)

    本研究探讨了使用机器学习算法中的聚类技术设计并执行需求响应（DR）计划的可行性，目的是改变分布式能源社区内供应者的消费行为，以最小化反向功率流和削减系统范围内的功峰需求。

    

    本研究探讨了使用聚类技术为商业和住宅社区的能量供应者设计和执行需求响应（DR）计划的可能性。该计划的目的是改变意大利分布式能源社区内的供应者的消费行为。这种聚合旨在：a）最小化在主要变电站处产生的反向功率流，该功率流在当地电网中的太阳能电池的发电量超过消耗时会发生; b）削减系统范围内的功峰需求，该需求通常发生在傍晚时分。在聚类阶段，我们采用了三种热门的电负荷聚类机器学习算法-即k-means，k-medoids和一种聚合层次聚类-alongside两种不同的距离度量-即欧几里得距离和受限动态时间扭曲（DTW）。我们使用多个验证度量来评估这些方法，包括一项新颖的指标-即峰值性能评分（PPS）

    The present study explores the use of clustering techniques for the design and implementation of a demand response (DR) program for commercial and residential prosumers. The goal of the program is to alter the consumption behavior of the prosumers pertaining to a distributed energy community in Italy. This aggregation aims to: a) minimize the reverse power flow at the primary substation, that occurs when generation from solar panels in the local grid exceeds consumption, and b) shave the system wide peak demand, that typically occurs during the hours of late afternoon. Regarding the clustering stage, three popular machine learning algorithms for electrical load clustering are employed -namely k-means, k-medoids and an agglomerative hierarchical clustering- alongside two different distance measures -namely euclidean and constrained dynamic time warping (DTW). We evaluate the methods using multiple validation metrics including a novel metric -namely peak performance score (PPS)- that we 
    
[^117]: 置换等变神经功能网络

    Permutation Equivariant Neural Functionals. (arXiv:2302.14040v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.14040](http://arxiv.org/abs/2302.14040)

    本文介绍了置换等变神经功能网络的设计，通过对权重进行置换对称性编码，实现对其他网络权重或梯度进行处理，为学习优化、处理隐式神经表示等应用提供了架构原则。

    

    本文研究了能够处理其他神经网络的权重或梯度的神经网络的设计，我们将其称为神经功能网络（NFN）。尽管具有广泛的潜在应用，包括学习优化、处理隐式神经表示、网络编辑和策略评估，但设计处理其他网络权重的有效架构的统一原则很少。我们通过对称性的视角来设计神经功能，特别是通过关注深度前馈网络权重中出现的置换对称性，因为隐藏层神经元没有固有顺序。我们介绍了一种构建置换等变神经功能的框架，该框架将这些对称性编码为归纳偏差。该框架的关键组成部分是我们通过适当的参数来约束为置换等变的NF-Layers（神经功能层）。

    This work studies the design of neural networks that can process the weights or gradients of other neural networks, which we refer to as neural functional networks (NFNs). Despite a wide range of potential applications, including learned optimization, processing implicit neural representations, network editing, and policy evaluation, there are few unifying principles for designing effective architectures that process the weights of other networks. We approach the design of neural functionals through the lens of symmetry, in particular by focusing on the permutation symmetries that arise in the weights of deep feedforward networks because hidden layer neurons have no inherent order. We introduce a framework for building permutation equivariant neural functionals, whose architectures encode these symmetries as an inductive bias. The key building blocks of this framework are NF-Layers (neural functional layers) that we constrain to be permutation equivariant through an appropriate paramet
    
[^118]: 深度学习模型在提前一天负荷预测中的比较评估：研究关键的准确性影响因素。

    A comparative assessment of deep learning models for day-ahead load forecasting: Investigating key accuracy drivers. (arXiv:2302.12168v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.12168](http://arxiv.org/abs/2302.12168)

    本文通过比较评估深度学习模型在提前一天负荷预测中的准确性，重点研究了葡萄牙国家净聚合STLF，并分析了多层感知机（MLP）、长短期记忆网络（LSTM）、神经基础扩展系数分析（N-BEATS）、时间卷积网络（TCN）和时间融合变压器（TFT）等多个模型的影响因素。

    

    短期负荷预测（STLF）对电网和能源市场的有效和经济运行至关重要。然而，电力需求的非线性和非平稳性以及其对各种外部因素的依赖性使得STLF成为一项具有挑战性的任务。为了评估这些模型在提前一天的预测环境下的准确性，在本文中我们专注于葡萄牙的国家净聚合STLF，并进行了一项比较研究，考虑了一组有指示性的、被广泛接受的深度自回归模型，包括多层感知机（MLP）、长短期记忆网络（LSTM）、神经基础扩展系数分析（N-BEATS）、时间卷积网络（TCN）和时间融合变压器（TFT）。此外，我们还确定了显著影响需求的因素，并研究了它们对每个模型准确性的影响。

    Short-term load forecasting (STLF) is vital for the effective and economic operation of power grids and energy markets. However, the non-linearity and non-stationarity of electricity demand as well as its dependency on various external factors renders STLF a challenging task. To that end, several deep learning models have been proposed in the literature for STLF, reporting promising results. In order to evaluate the accuracy of said models in day-ahead forecasting settings, in this paper we focus on the national net aggregated STLF of Portugal and conduct a comparative study considering a set of indicative, well-established deep autoregressive models, namely multi-layer perceptrons (MLP), long short-term memory networks (LSTM), neural basis expansion coefficient analysis (N-BEATS), temporal convolutional networks (TCN), and temporal fusion transformers (TFT). Moreover, we identify factors that significantly affect the demand and investigate their impact on the accuracy of each model. O
    
[^119]: 一站式解决方案：利用预训练 LM 进行强大的时间序列分析

    One Fits All:Power General Time Series Analysis by Pretrained LM. (arXiv:2302.11939v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.11939](http://arxiv.org/abs/2302.11939)

    本论文提出了一种称为 Frozen Pretrained Transformer (FPT) 的预训练模型，利用从数十亿标记训练出来的语言或 CV 模型进行时间序列分析的所有主要类型任务的微调，进而使其在所有任务中都具备着最先进的性能和泛化能力。

    

    尽管预训练模型在自然语言处理 (NLP) 和计算机视觉 (CV) 领域取得了巨大成功，但在通用时间序列分析领域取得的进展有限。与 NLP 和 CV 不同的是，这些领域采用统一模型即可执行不同的任务，而在每个时间序列分析任务中，专门设计的方法仍然占据主导地位，如分类、异常检测、预测和少样本学习。阻碍预训练模型发展的主要挑战是缺乏大量用于训练的数据。在本文中，我们通过利用从数十亿标记训练出来的语言或 CV 模型，来解决这一挑战，用于时间序列分析。具体而言，我们避免改变预训练语言或图像模型中残差块中的自注意力和前向传递层。这种模型被称为冻结的预训练变压器 (FPT)，通过对涉及时间序列分析的所有主要类型的任务进行微调进行评估，包括分类、异常检测、预测和少样本学习等。实验结果证明，FPT 在所有任务中都具有最先进的性能和泛化能力。

    Although we have witnessed great success of pre-trained models in natural language processing (NLP) and computer vision (CV), limited progress has been made for general time series analysis. Unlike NLP and CV where a unified model can be used to perform different tasks, specially designed approach still dominates in each time series analysis task such as classification, anomaly detection, forecasting, and few-shot learning. The main challenge that blocks the development of pre-trained model for time series analysis is the lack of a large amount of data for training. In this work, we address this challenge by leveraging language or CV models, pre-trained from billions of tokens, for time series analysis. Specifically, we refrain from altering the self-attention and feedforward layers of the residual blocks in the pre-trained language or image model. This model, known as the Frozen Pretrained Transformer (FPT), is evaluated through fine-tuning on all major types of tasks involving time s
    
[^120]: SAT需要彻底搜索

    SAT Requires Exhaustive Search. (arXiv:2302.09512v4 [cs.CC] CROSS LISTED)

    [http://arxiv.org/abs/2302.09512](http://arxiv.org/abs/2302.09512)

    本文证明了对于一些具有大域和长子句的极难例子，要求进行彻底搜索才能解决，这意味着P $\neq$ NP。

    

    本文通过构造具有大域和长子句的CSP和SAT的极难例子，证明这些例子无法在不进行彻底搜索的情况下解决，这意味着一个较弱的结论P $\neq$ NP。本文采用的是一种证明不可能性结果的建设性方法，与目前计算复杂性理论中使用的方法非常不同，但与Kurt G\"{o}del在证明他著名的逻辑不可能性结果时使用的方法相似。正如G\"{o}del的结果表明，在数学中证明形式上的不可证明性是可行的一样，本文的结果表明，在数学中证明计算上的难度不是很难的。具体来说，对许多问题，如3-SAT，证明下界可能具有挑战性，因为这些问题有各种有效的策略可用于避免进行彻底搜索。然而，在极难的例子中，彻底搜索可能是唯一可行的选择，证明其必要性变得更加重要。

    In this paper, by constructing extremely hard examples of CSP (with large domains) and SAT (with long clauses), we prove that such examples cannot be solved without exhaustive search, which implies a weaker conclusion P $\neq$ NP. This constructive approach for proving impossibility results is very different (and missing) from those currently used in computational complexity theory, but is similar to that used by Kurt G\"{o}del in proving his famous logical impossibility results. Just as shown by G\"{o}del's results that proving formal unprovability is feasible in mathematics, the results of this paper show that proving computational hardness is not hard in mathematics. Specifically, proving lower bounds for many problems, such as 3-SAT, can be challenging because these problems have various effective strategies available for avoiding exhaustive search. However, in cases of extremely hard examples, exhaustive search may be the only viable option, and proving its necessity becomes more 
    
[^121]: Off-the-Grid MARL: 带有基准的离线多智能体增强学习数据集

    Off-the-Grid MARL: Datasets with Baselines for Offline Multi-Agent Reinforcement Learning. (arXiv:2302.00521v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00521](http://arxiv.org/abs/2302.00521)

    这项工作填补了离线多智能体增强学习（MARL）领域的一个空白，提供了Off-the-Grid MARL（OG-MARL）数据集和基准，帮助社区衡量进展。

    

    能够利用大型数据集开发合作多智能体控制器，为实际应用开启了巨大的价值。许多重要的工业系统是多智能体的，并且很难使用定制的模拟器进行建模。然而，在工业中，分布式进程经常可以在运行期间记录，并存储大量的演示数据。离线多智能体增强学习（MARL）为利用这些数据建立有效的分散式控制器提供了有希望的范例。然而，离线MARL仍处于起步阶段，因此缺乏在强化学习更成熟的子领域中通常会找到的标准化基准数据集和基线。这些不足使得社区无法合理地衡量进展。在这项工作中，我们旨在通过发布Off-the-Grid MARL（OG-MARL）来填补这个空白：一个不断增长的高质量数据集存储库，其中包含协作离线MARL的基准。

    Being able to harness the power of large datasets for developing cooperative multi-agent controllers promises to unlock enormous value for real-world applications. Many important industrial systems are multi-agent in nature and are difficult to model using bespoke simulators. However, in industry, distributed processes can often be recorded during operation, and large quantities of demonstrative data stored. Offline multi-agent reinforcement learning (MARL) provides a promising paradigm for building effective decentralised controllers from such datasets. However, offline MARL is still in its infancy and therefore lacks standardised benchmark datasets and baselines typically found in more mature subfields of reinforcement learning (RL). These deficiencies make it difficult for the community to sensibly measure progress. In this work, we aim to fill this gap by releasing off-the-grid MARL (OG-MARL): a growing repository of high-quality datasets with baselines for cooperative offline MARL
    
[^122]: Salesforce CausalAI库: 用于时间序列和表格数据因果分析的快速可扩展框架

    Salesforce CausalAI Library: A Fast and Scalable Framework for Causal Analysis of Time Series and Tabular Data. (arXiv:2301.10859v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.10859](http://arxiv.org/abs/2301.10859)

    Salesforce CausalAI库是一个快速可扩展的框架，用于进行时间序列和表格数据的因果分析。它支持离散、连续和异质类型的数据，提供了处理线性和非线性因果关系的算法，并包括一个用于生成具有指定结构方程模型的合成数据的数据生成器。用户可以通过用户界面进行因果分析，无需编程。

    

    我们介绍了Salesforce CausalAI库，这是一个用于使用观测数据进行因果分析的开源库。它支持离散、连续和异质类型的表格和时间序列数据的因果发现和因果推断。该库包括处理变量之间线性和非线性因果关系的算法，并使用多处理进行加速。我们还提供了一个数据生成器，可以生成具有指定结构方程模型的合成数据，以帮助用户在研究各种算法的同时控制基础因果过程。最后，我们提供了一个用户界面（UI），使用户可以在无需编程的情况下对数据进行因果分析。该库旨在提供一种快速灵活的解决方案，用于解决因果性领域中的各种问题。本技术报告描述了Salesforce CausalAI API及其功能以及s的实现。

    We introduce the Salesforce CausalAI Library, an open-source library for causal analysis using observational data. It supports causal discovery and causal inference for tabular and time series data, of discrete, continuous and heterogeneous types. This library includes algorithms that handle linear and non-linear causal relationships between variables, and uses multi-processing for speed-up. We also include a data generator capable of generating synthetic data with specified structural equation model for the aforementioned data formats and types, that helps users control the ground-truth causal process while investigating various algorithms. Finally, we provide a user interface (UI) that allows users to perform causal analysis on data without coding. The goal of this library is to provide a fast and flexible solution for a variety of problems in the domain of causality. This technical report describes the Salesforce CausalAI API along with its capabilities, the implementations of the s
    
[^123]: 一种用于混合人机团队中动态角色分配和协同任务规划的统一体系结构

    A Unified Architecture for Dynamic Role Allocation and Collaborative Task Planning in Mixed Human-Robot Teams. (arXiv:2301.08038v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2301.08038](http://arxiv.org/abs/2301.08038)

    本文提出了一种用于混合人机团队中动态角色分配和协同任务规划的统一体系结构，通过基于行为树的反应式规划方法和混合整数线性规划解决不同方面的协作问题。

    

    在工业应用中，例如处理、焊接和装配，人机协同过程的不断部署推动了管理大型异构团队和同时监控复杂任务执行能力的追求。本文提出了一种新颖的混合人机团队动态角色分配和协同任务规划体系结构，该体系结构利用基于行为树的集中式反应式和模块化任务无关规划方法进行动作调度，同时利用混合整数线性规划来制定动态分配个体角色或协作的问题。采用不同的混整数线性规划成本度量指标使得该体系结构可以更好地关注协作的不同方面（例如完成时间、人体工程学、人类偏好）。人类偏好是通过谈判阶段来确定的，

    The growing deployment of human-robot collaborative processes in several industrial applications, such as handling, welding, and assembly, unfolds the pursuit of systems which are able to manage large heterogeneous teams and, at the same time, monitor the execution of complex tasks. In this paper, we present a novel architecture for dynamic role allocation and collaborative task planning in a mixed human-robot team of arbitrary size. The architecture capitalizes on a centralized reactive and modular task-agnostic planning method based on Behavior Trees (BTs), in charge of actions scheduling, while the allocation problem is formulated through a Mixed-Integer Linear Program (MILP), that assigns dynamically individual roles or collaborations to the agents of the team. Different metrics used as MILP cost allow the architecture to favor various aspects of the collaboration (e.g. makespan, ergonomics, human preferences). Human preference are identified through a negotiation phase, in which, 
    
[^124]: 利用大型语言模型提升用于收集用户自我报告数据的聊天机器人的能力

    Leveraging Large Language Models to Power Chatbots for Collecting User Self-Reported Data. (arXiv:2301.05843v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2301.05843](http://arxiv.org/abs/2301.05843)

    本研究通过探索设计提示的因素，研究了如何利用大型语言模型构建聊天机器人来进行自然对话和可靠地收集用户自我报告数据。结果显示，提示的设计和对话主题明显影响了对话流程和数据收集性能。

    

    大型语言模型（LLMs）提供了一种通过接受自然语言提示来构建聊天机器人的新方法。然而，如何设计提示来使聊天机器人在追求给定目标（如从用户收集自我报告数据）的同时进行自然对话尚不清楚。我们探讨了哪些提示的设计因素可以帮助引导聊天机器人进行自然对话并可靠地收集数据。为此，我们设计了四种具有不同结构和人设的提示形式。通过一项在线研究（N = 48），参与者与由不同设计提示驱动的聊天机器人进行对话，我们评估了设计提示和对话主题如何影响对话流程和用户对聊天机器人的感知。在对话过程中，我们的聊天机器人覆盖了79%的所需信息槽，并且提示和主题的设计显著影响了对话流程和数据收集性能。我们讨论了利用LLMs构建聊天机器人的机遇和挑战。

    Large language models (LLMs) provide a new way to build chatbots by accepting natural language prompts. Yet, it is unclear how to design prompts to power chatbots to carry on naturalistic conversations while pursuing a given goal, such as collecting self-report data from users. We explore what design factors of prompts can help steer chatbots to talk naturally and collect data reliably. To this aim, we formulated four prompt designs with different structures and personas. Through an online study (N = 48) where participants conversed with chatbots driven by different designs of prompts, we assessed how prompt designs and conversation topics affected the conversation flows and users' perceptions of chatbots. Our chatbots covered 79% of the desired information slots during conversations, and the designs of prompts and topics significantly influenced the conversation flows and the data collection performance. We discuss the opportunities and challenges of building chatbots with LLMs.
    
[^125]: 一个融合基于规则的透明模型、软标签相关性学习和标签噪声抗性的鲁棒多标记方法

    A Robust Multilabel Method Integrating Rule-based Transparent Model, Soft Label Correlation Learning and Label Noise Resistance. (arXiv:2301.03283v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.03283](http://arxiv.org/abs/2301.03283)

    本论文提出了一种融合基于规则的透明模型、软标签相关性学习和标签噪声抗性的鲁棒多标记方法（R-MLTSK-FS）。实验证明了该方法在多标记学习中的优越性能。

    

    在多标记学习中，模型透明性、标签相关性学习和对标签噪声的鲁棒性非常重要。然而，目前很少有方法同时研究这三个特点。为了解决这个挑战，我们提出了一种鲁棒的多标记Takagi-Sugeno-Kang模糊系统（R-MLTSK-FS），其中包括三种机制。首先，我们设计了一个软标签学习机制，通过明确测量标签之间的交互作用来减少标签噪声的影响，这也是其他两种机制的基础。其次，我们使用基于规则的TSK FS作为基模型，以比许多现有的多标记模型更透明的方式有效地建模特征和软标签之间的推理关系。第三，为了进一步提高多标记学习的性能，我们基于软标签空间和模糊特征空间构建了一个相关增强学习机制。我们进行了大量实验证明了所提方法的优越性。

    Model transparency, label correlation learning and the robust-ness to label noise are crucial for multilabel learning. However, few existing methods study these three characteristics simultaneously. To address this challenge, we propose the robust multilabel Takagi-Sugeno-Kang fuzzy system (R-MLTSK-FS) with three mechanisms. First, we design a soft label learning mechanism to reduce the effect of label noise by explicitly measuring the interactions between labels, which is also the basis of the other two mechanisms. Second, the rule-based TSK FS is used as the base model to efficiently model the inference relationship be-tween features and soft labels in a more transparent way than many existing multilabel models. Third, to further improve the performance of multilabel learning, we build a correlation enhancement learning mechanism based on the soft label space and the fuzzy feature space. Extensive experiments are conducted to demonstrate the superiority of the proposed method.
    
[^126]: StitchNet: 从预训练片段组合神经网络

    StitchNet: Composing Neural Networks from Pre-Trained Fragments. (arXiv:2301.01947v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.01947](http://arxiv.org/abs/2301.01947)

    StitchNet提出了一种新的神经网络创建方式，它通过组合预训练神经网络的片段来创建高性能的网络，无需传统训练的大量计算资源和数据要求。通过居中核对齐（CKA），可以有效指导片段的选择，以满足特定准确性需求和计算资源限制。此外，StitchNet还可以实现即时个性化模型创建和推断。

    

    我们提出了一种新颖的神经网络创建范式StitchNet，它将来自多个预训练神经网络的片段（一个或多个连续的网络层）拼接在一起。StitchNet允许创建高性能的神经网络，而无需传统的基于反向传播训练的大量计算和数据要求。我们利用居中核对齐（CKA）作为一种兼容性度量，以有效地指导选择这些片段，以组合适合特定准确性需求和计算资源限制的任务网络。然后，我们展示了这些片段可以被拼接在一起，以在计算资源和数据要求的一小部分下创建与传统训练网络相媲美准确度的神经网络。最后，我们探索了这种新范式所能实现的一种新颖的即时个性化模型创建和推断应用。

    We propose StitchNet, a novel neural network creation paradigm that stitches together fragments (one or more consecutive network layers) from multiple pre-trained neural networks. StitchNet allows the creation of high-performing neural networks without the large compute and data requirements needed under traditional model creation processes via backpropagation training. We leverage Centered Kernel Alignment (CKA) as a compatibility measure to efficiently guide the selection of these fragments in composing a network for a given task tailored to specific accuracy needs and computing resource constraints. We then show that these fragments can be stitched together to create neural networks with comparable accuracy to traditionally trained networks at a fraction of computing resource and data requirements. Finally, we explore a novel on-the-fly personalized model creation and inference application enabled by this new paradigm.
    
[^127]: 面向高效自主导航的目标引导变压器增强学习

    Goal-Guided Transformer-Enabled Reinforcement Learning for Efficient Autonomous Navigation. (arXiv:2301.00362v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2301.00362](http://arxiv.org/abs/2301.00362)

    该论文提出了一种利用目标引导变压器增强学习的方法，通过将目标信息与场景表示耦合，实现高效自主导航。通过使用专家先验进行预训练，提高了数据效率。

    

    尽管目标驱动导航有些成功应用，但现有的基于深度强化学习(DRL)的方法在数据效率方面存在明显问题。其中一个原因是目标信息与感知模块解耦，并直接作为决策的条件引入，导致场景表示中与目标无关的特征在学习过程中起到对抗作用。鉴于此，我们提出了一种新颖的目标引导变压器增强学习(GTRL)方法，通过将物理目标状态作为场景编码器的输入来指导场景表示与目标信息的耦合，并实现高效的自主导航。具体而言，我们提出了一种新的视觉变压器变体作为感知系统的骨干，即目标引导变压器(GoT)，并使用专家先验进行预训练，以提高数据效率。随后，我们设计了一个增强学习算法进行导航决策。

    Despite some successful applications of goal-driven navigation, existing deep reinforcement learning (DRL)-based approaches notoriously suffers from poor data efficiency issue. One of the reasons is that the goal information is decoupled from the perception module and directly introduced as a condition of decision-making, resulting in the goal-irrelevant features of the scene representation playing an adversary role during the learning process. In light of this, we present a novel Goal-guided Transformer-enabled reinforcement learning (GTRL) approach by considering the physical goal states as an input of the scene encoder for guiding the scene representation to couple with the goal information and realizing efficient autonomous navigation. More specifically, we propose a novel variant of the Vision Transformer as the backbone of the perception system, namely Goal-guided Transformer (GoT), and pre-train it with expert priors to boost the data efficiency. Subsequently, a reinforcement le
    
[^128]: 在自然语言论证中鲁棒且可解释的识别逻辑谬误

    Robust and Explainable Identification of Logical Fallacies in Natural Language Arguments. (arXiv:2212.07425v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.07425](http://arxiv.org/abs/2212.07425)

    本论文提出了一个鲁棒且可解释的方法来识别自然语言论证中的逻辑谬误。通过三阶段的评估框架和不同的推理方法，结合语言模型和背景知识，有效处理了大量数据和数据稀疏性的问题。

    

    在互联网时代，虚假信息、宣传和错误论证的传播现象得到了放大。给定数据量的庞大和识别论证规范违规的微妙性，使用可靠的方法来识别逻辑谬误来支持信息分析任务（如内容审核）是至关重要的。本文将以前关于逻辑谬误的理论工作制定为检测、粗粒度和细粒度分类的综合三阶段评估框架。我们针对评估的每个阶段对现有的评估数据集进行了适应。我们采用了基于原型推理、基于实例推理和知识注入的三个鲁棒且可解释的方法族。这些方法结合了语言模型、背景知识和可解释的机制。此外，我们通过数据增强和课程学习的策略解决了数据稀疏性的问题。我们的三阶段框架自然地巩固了以前的数据集和方法。

    The spread of misinformation, propaganda, and flawed argumentation has been amplified in the Internet era. Given the volume of data and the subtlety of identifying violations of argumentation norms, supporting information analytics tasks, like content moderation, with trustworthy methods that can identify logical fallacies is essential. In this paper, we formalize prior theoretical work on logical fallacies into a comprehensive three-stage evaluation framework of detection, coarse-grained, and fine-grained classification. We adapt existing evaluation datasets for each stage of the evaluation. We employ three families of robust and explainable methods based on prototype reasoning, instance-based reasoning, and knowledge injection. The methods combine language models with background knowledge and explainable mechanisms. Moreover, we address data sparsity with strategies for data augmentation and curriculum learning. Our three-stage framework natively consolidates prior datasets and metho
    
[^129]: 3DHumanGAN: 具有3D姿势映射的3D感知人体图像生成

    3DHumanGAN: 3D-Aware Human Image Generation with 3D Pose Mapping. (arXiv:2212.07378v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.07378](http://arxiv.org/abs/2212.07378)

    3DHumanGAN 是一个能够生成具有一致外观的全身人体照片的生成对抗网络，通过引入3D姿势映射网络，它能够合成具有不同视角和姿势的图像，并结合3D人体先验实现姿态条件化。

    

    我们提出了3DHumanGAN，这是一个具有3D感知的生成对抗网络，能够合成具有一致外观的全身人体照片，且能适应不同视角和身体姿势。为了解决合成人体结构时的表达和计算挑战，我们提出了一种新颖的生成器架构，其中2D卷积骨干由一个3D姿态映射网络调制。3D姿态映射网络以有姿态的3D人体网格为条件，形成一个可呈现的隐式函数。这一设计具有以下几个优点：i）它利用了2D GAN的优势来产生高质量的图像；ii）在不同的视角和姿势下生成一致的图像；iii）模型可以结合3D人体先验并实现姿态条件化。

    We present 3DHumanGAN, a 3D-aware generative adversarial network that synthesizes photorealistic images of full-body humans with consistent appearances under different view-angles and body-poses. To tackle the representational and computational challenges in synthesizing the articulated structure of human bodies, we propose a novel generator architecture in which a 2D convolutional backbone is modulated by a 3D pose mapping network. The 3D pose mapping network is formulated as a renderable implicit function conditioned on a posed 3D human mesh. This design has several merits: i) it leverages the strength of 2D GANs to produce high-quality images; ii) it generates consistent images under varying view-angles and poses; iii) the model can incorporate the 3D human prior and enable pose conditioning. Project page: https://3dhumangan.github.io/.
    
[^130]: PASTA：比例幅度谱训练增强用于 Syn-to-Real 领域泛化

    PASTA: Proportional Amplitude Spectrum Training Augmentation for Syn-to-Real Domain Generalization. (arXiv:2212.00979v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.00979](http://arxiv.org/abs/2212.00979)

    本文提出了一种基于比例幅度谱训练增强的方法 PASTA，可有效提高合成数据到真实数据的泛化性能，在多个 Syn-to-Real 任务上均具有优越性能。

    

    合成数据可以提供廉价且丰富的训练数据，适用于真实世界数据稀缺的情况。然而，在真实世界数据上评估的模型在合成数据上训练时表现显著不佳。在本文中，我们提出了 Proportional Amplitude Spectrum Training Augmentation (PASTA)，一种简单而有效的增强策略，可提高合成到真实（Syn-to-Real）泛化性能。 PASTA 在 Fourier 领域中扰动合成图像的幅度谱以生成增强视图。具体而言，使用 PASTA，我们提出了一种结构化扰动策略，其中高频分量相对于低频分量更容易受到扰动。对于语义分割（GTAV-to-Real），目标检测（Sim10K-to-Real）和对象识别（VisDA-C Syn-to-Real）任务，在总共5个 Syn-to-Real 转移中，我们发现 PASTA 的性能优于更复杂的最先进的泛化方法，同时具有互补性。

    Synthetic data offers the promise of cheap and bountiful training data for settings where labeled real-world data is scarce. However, models trained on synthetic data significantly underperform when evaluated on real-world data. In this paper, we propose Proportional Amplitude Spectrum Training Augmentation (PASTA), a simple and effective augmentation strategy to improve out-of-the-box synthetic-to-real (syn-to-real) generalization performance. PASTA perturbs the amplitude spectra of synthetic images in the Fourier domain to generate augmented views. Specifically, with PASTA we propose a structured perturbation strategy where high-frequency components are perturbed relatively more than the low-frequency ones. For the tasks of semantic segmentation (GTAV-to-Real), object detection (Sim10K-to-Real), and object recognition (VisDA-C Syn-to-Real), across a total of 5 syn-to-real shifts, we find that PASTA outperforms more complex state-of-the-art generalization methods while being complemen
    
[^131]: 我现在在哪里？动态寻找最佳传感器状态以最小化感知受限漫游器的定位不确定性

    Where Am I Now? Dynamically Finding Optimal Sensor States to Minimize Localization Uncertainty for a Perception-Denied Rover. (arXiv:2211.16721v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2211.16721](http://arxiv.org/abs/2211.16721)

    DyFOS是一种动态感知方法，通过优化搜索来寻找最佳传感器状态，以最小化感知受限漫游器的定位不确定性，同时避免障碍和遮挡。

    

    我们提出了DyFOS，一种动态寻找最佳状态以最小化定位不确定性的主动感知方法，同时避免障碍和遮挡。我们考虑了一个感知受限的漫游器依靠来自观察者机器人的位置和不确定性测量来定位自己沿着充满障碍物的路径的情景。观察者的传感器的位置不确定性是传感器本身、漫游器和周围环境状态的函数。为了找到最小化漫游器定位不确定性的最佳传感器状态，DyFOS使用定位不确定性预测流水线进行优化搜索。给定上述状态的大量样本，流水线借助训练有素的复杂状态相关传感器测量模型（概率神经网络）预测漫游器的定位不确定性。我们的流水线还预测遮挡和障碍碰撞，以去除不可取的观察者状态并减少不必要计算。

    We present DyFOS, an active perception method that dynamically finds optimal states to minimize localization uncertainty while avoiding obstacles and occlusions. We consider the scenario where a perception-denied rover relies on position and uncertainty measurements from a viewer robot to localize itself along an obstacle-filled path. The position uncertainty from the viewer's sensor is a function of the states of the sensor itself, the rover, and the surrounding environment. To find an optimal sensor state that minimizes the rover's localization uncertainty, DyFOS uses a localization uncertainty prediction pipeline in an optimization search. Given numerous samples of the states mentioned above, the pipeline predicts the rover's localization uncertainty with the help of a trained, complex state-dependent sensor measurement model (a probabilistic neural network). Our pipeline also predicts occlusion and obstacle collision to remove undesirable viewer states and reduce unnecessary comput
    
[^132]: SnCQA：一种硬件高效的等变量子卷积电路架构

    SnCQA: A hardware-efficient equivariant quantum convolutional circuit architecture. (arXiv:2211.12711v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2211.12711](http://arxiv.org/abs/2211.12711)

    SnCQA是一种硬件高效的等变量子卷积电路架构，通过利用排列对称性和空间晶格对称性，适用于解决存在排列对称性的机器学习问题，具有更高的可扩展性、准确性和噪声韧性。

    

    我们提出了SnCQA，这是一组针对排列对称性和空间晶格对称性的硬件高效等变量子卷积电路的变分电路。通过利用系统的排列对称性，例如许多量子多体和量子化学问题中常见的晶格哈密顿量，我们的量子神经网络适用于解决存在排列对称性的机器学习问题，这可能会显著节省计算成本。除了理论的创新性外，在实际的量子计算化学中，我们发现我们的模拟在学习基态方面表现良好，可以通过少数参数实现与传统方法相当的性能。与其他传统的变分量子电路（如纯硬件高效的基态假设）相比，我们展示了SnCQA具有更高的可扩展性、准确性和噪声韧性（具有20倍更好的）。

    We propose SnCQA, a set of hardware-efficient variational circuits of equivariant quantum convolutional circuits respective to permutation symmetries and spatial lattice symmetries with the number of qubits $n$. By exploiting permutation symmetries of the system, such as lattice Hamiltonians common to many quantum many-body and quantum chemistry problems, Our quantum neural networks are suitable for solving machine learning problems where permutation symmetries are present, which could lead to significant savings of computational costs. Aside from its theoretical novelty, we find our simulations perform well in practical instances of learning ground states in quantum computational chemistry, where we could achieve comparable performances to traditional methods with few tens of parameters. Compared to other traditional variational quantum circuits, such as the pure hardware-efficient ansatz (pHEA), we show that SnCQA is more scalable, accurate, and noise resilient (with $20\times$ bette
    
[^133]: REPAIR: 修复插值的归一化置换激活

    REPAIR: REnormalizing Permuted Activations for Interpolation Repair. (arXiv:2211.08403v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.08403](http://arxiv.org/abs/2211.08403)

    作者发现仅使用神经元对齐方法不能有效解决线性插值中激活方差坍缩的问题，因此提出了REPAIR方法来修复插值的归一化置换激活。实验证明，在各种架构中将REPAIR与神经元对齐方法结合使用可以大幅降低障碍。

    

    本文探讨了Entezari等人（2021）的猜想，即如果考虑神经网络的置换不变性，那么线性插值之间可能没有损失障碍。首先，我们观察到仅使用神经元对齐方法无法建立低障碍线性连接的原因是一种我们称之为方差坍缩的现象：插值深层网络的激活方差崩溃，导致性能较差。其次，我们提出了REPAIR（修复插值的归一化置换激活）方法，通过重新缩放这些插值网络的预激活来缓解方差崩溃。我们探讨了我们方法与归一化层、网络宽度和深度选择之间的相互作用，并演示了在各种架构族中使用REPAIR作为神经元对齐方法的扩展，可以将障碍降低60%至100%。

    In this paper we look into the conjecture of Entezari et al. (2021) which states that if the permutation invariance of neural networks is taken into account, then there is likely no loss barrier to the linear interpolation between SGD solutions. First, we observe that neuron alignment methods alone are insufficient to establish low-barrier linear connectivity between SGD solutions due to a phenomenon we call variance collapse: interpolated deep networks suffer a collapse in the variance of their activations, causing poor performance. Next, we propose REPAIR (REnormalizing Permuted Activations for Interpolation Repair) which mitigates variance collapse by rescaling the preactivations of such interpolated networks. We explore the interaction between our method and the choice of normalization layer, network width, and depth, and demonstrate that using REPAIR on top of neuron alignment methods leads to 60%-100% relative barrier reduction across a wide variety of architecture families and t
    
[^134]: 使用动态扩张聚合在深度残差GCN中进行重叠社区检测

    Overlapping Community Detection using Dynamic Dilated Aggregation in Deep Residual GCN. (arXiv:2210.11174v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2210.11174](http://arxiv.org/abs/2210.11174)

    本论文提出了一种使用动态扩张聚合的深度残差GCN方法进行重叠社区检测。通过设计深度动态残差图卷积网络和统一的编码器-解码器框架，实现了在不规则图上进行社区检测。实验结果表明，该方法在不同数据集上取得了较好的效果。

    

    重叠社区检测是图挖掘中的一个关键问题。一些研究考虑将图卷积网络（GCN）应用于解决该问题。然而，在一般不规则图的情况下，如何将深度图卷积网络结合起来仍然具有挑战性。在本研究中，我们基于我们的新颖动态扩张聚合机制和统一的端到端编码器-解码器框架，设计了一个深度动态残差图卷积网络（DynaResGCN），用于检测网络中的重叠社区。深度的DynaResGCN模型被用作编码器，而我们将伯努利-泊松（BP）模型作为解码器。因此，我们将我们的重叠社区检测框架应用在一个没有基准值的研究主题数据集，一个拥有可靠（手工标记）基准值的Facebook网络集合，以及一组具有经验性（非手工标记）基准值的非常大的合著网络。

    Overlapping community detection is a key problem in graph mining. Some research has considered applying graph convolutional networks (GCN) to tackle the problem. However, it is still challenging to incorporate deep graph convolutional networks in the case of general irregular graphs. In this study, we design a deep dynamic residual graph convolutional network (DynaResGCN) based on our novel dynamic dilated aggregation mechanisms and a unified end-to-end encoder-decoder-based framework to detect overlapping communities in networks. The deep DynaResGCN model is used as the encoder, whereas we incorporate the Bernoulli-Poisson (BP) model as the decoder. Consequently, we apply our overlapping community detection framework in a research topics dataset without having ground truth, a set of networks from Facebook having a reliable (hand-labeled) ground truth, and in a set of very large co-authorship networks having empirical (not hand-labeled) ground truth. Our experimentation on these datase
    
[^135]: 图像和视频的全景分割的通用框架

    A Generalist Framework for Panoptic Segmentation of Images and Videos. (arXiv:2210.06366v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.06366](http://arxiv.org/abs/2210.06366)

    这个论文提出了一个通用框架，用于图像和视频的全景分割。他们将全景分割问题定义为离散数据生成问题，并提出了一个简单的扩散模型来建模全景掩码。他们的方法能够在流式设置中建模视频，并自动学习跟踪对象实例，并在实验中展现出与最先进的专家方法竞争的能力。

    

    全景分割为图像的每个像素分配语义和实例ID标签。由于实例ID的排列也是有效的解决方案，该任务需要学习高维度的一对多映射。因此，最先进的方法使用定制的架构和任务特定的损失函数。我们将全景分割问题定义为离散数据生成问题，不依赖任务的归纳偏差。我们提出了一个扩散模型来建模全景掩码，具有简单的架构和通用的损失函数。通过将过去的预测作为条件信号添加，我们的方法能够在流式设置中建模视频，并自动学习跟踪对象实例。通过大量实验证明，我们的简单方法在类似的设置下能够与最先进的专家方法竞争。

    Panoptic segmentation assigns semantic and instance ID labels to every pixel of an image. As permutations of instance IDs are also valid solutions, the task requires learning of high-dimensional one-to-many mapping. As a result, state-of-the-art approaches use customized architectures and task-specific loss functions. We formulate panoptic segmentation as a discrete data generation problem, without relying on inductive bias of the task. A diffusion model is proposed to model panoptic masks, with a simple architecture and generic loss function. By simply adding past predictions as a conditioning signal, our method is capable of modeling video (in a streaming setting) and thereby learns to track object instances automatically. With extensive experiments, we demonstrate that our simple approach can perform competitively to state-of-the-art specialist methods in similar settings.
    
[^136]: DenseShift: 实现准确和高效的低位幂乘法的量化

    DenseShift: Towards Accurate and Efficient Low-Bit Power-of-Two Quantization. (arXiv:2208.09708v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2208.09708](http://arxiv.org/abs/2208.09708)

    DenseShift网络是一种准确和高效的低位幂乘法量化方法，通过改进Shift网络的精度和引入非量化浮点激活来提高性能。

    

    在低资源边缘设备上高效部署深度神经网络是具有挑战性的，因为其不断增加的资源需求。为了解决这个问题，研究人员提出了无乘法神经网络，如幂乘法的量化，也被称为Shift网络，旨在减少内存使用和简化计算。然而，现有的低位Shift网络不如全精度网络准确，通常受到有限权重范围编码方案和量化损失的影响。在本文中，我们提出了DenseShift网络，显著提高了Shift网络的准确性，为视觉和语音应用实现了与全精度网络相媲美的性能。此外，我们引入了一种使用非量化浮点激活的高效DenseShift网络部署方法，同时获得了现有方法的1.6倍加速。为了实现这一点，我们证明了低位Shift网络中零权重值的作用。

    Efficiently deploying deep neural networks on low-resource edge devices is challenging due to their ever-increasing resource requirements. To address this issue, researchers have proposed multiplication-free neural networks, such as Power-of-Two quantization, or also known as Shift networks, which aim to reduce memory usage and simplify computation. However, existing low-bit Shift networks are not as accurate as their full-precision counterparts, typically suffering from limited weight range encoding schemes and quantization loss. In this paper, we propose the DenseShift network, which significantly improves the accuracy of Shift networks, achieving competitive performance to full-precision networks for vision and speech applications. In addition, we introduce a method to deploy an efficient DenseShift network using non-quantized floating-point activations, while obtaining 1.6X speed-up over existing methods. To achieve this, we demonstrate that zero-weight values in low-bit Shift netw
    
[^137]: 减少蕴含偏差逻辑损失用于神经符号学习

    Reduced Implication-bias Logic Loss for Neuro-Symbolic Learning. (arXiv:2208.06838v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2208.06838](http://arxiv.org/abs/2208.06838)

    本文提出了一种减少蕴含偏差逻辑损失（RILL）的方法，用于解决在神经符号学习中由于从模糊逻辑算子中派生的损失函数带来的偏差问题。实证研究表明，RILL相比有偏差的逻辑损失函数在知识库不完整和标记数据不足时具有显著的改进和更强的稳健性。

    

    通过使用可微分算子来近似逻辑推理，将逻辑推理与机器学习相结合是神经符号系统中广泛使用的技术。然而，某些可微分算子在反向传播过程中可能带来显著的偏差，并降低神经符号学习的性能。本文揭示了这种偏差，称之为“蕴含偏差”，常见于从模糊逻辑算子中派生的损失函数。此外，我们提出了一种简单而有效的方法，将有偏差的损失函数转化为“减少蕴含偏差逻辑损失（RILL）”，以解决上述问题。实证研究表明，与有偏差的逻辑损失函数相比，RILL在知识库不完整时可以取得显著改进，并在标记数据不足时保持更为稳健。

    Integrating logical reasoning and machine learning by approximating logical inference with differentiable operators is a widely used technique in Neuro-Symbolic systems.  However, some differentiable operators could bring a significant bias during backpropagation and degrade the performance of Neuro-Symbolic learning.  In this paper, we reveal that this bias, named \textit{Implication Bias} is common in loss functions derived from fuzzy logic operators.  Furthermore, we propose a simple yet effective method to transform the biased loss functions into \textit{Reduced Implication-bias Logic Loss (RILL)} to address the above problem.  Empirical study shows that RILL can achieve significant improvements compared with the biased logic loss functions, especially when the knowledge base is incomplete, and keeps more robust than the compared methods when labelled data is insufficient.
    
[^138]: 从理解基因漂变到基于智能重启机制的分布估计算法

    From Understanding Genetic Drift to a Smart-Restart Mechanism for Estimation-of-Distribution Algorithms. (arXiv:2206.09090v3 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2206.09090](http://arxiv.org/abs/2206.09090)

    这篇论文介绍了一种基于智能重启机制的分布估计算法，该算法可以在基因漂变风险高的情况下停止运行，并寻找良好的参数范围以运行EDA，从而提高性能。

    

    估计分布算法（EDAs）是一种优化算法，它从搜索空间中学习一个分布，从中可以轻松地采样出好的解决方案。大多数EDAs的关键参数是样本大小（种群大小）。如果种群大小太小，概率模型更新仅基于少量样本，导致不希望出现的基因漂变效应。种群大小过大会避免遗传漂变，但会减缓进程。基于最近量化分析的种群大小如何导致基因漂变，我们设计了EDAs的智能重启机制。当基因漂变风险很高时停止运行，它会自动在良好的参数范围内运行EDA。通过数学运行时间分析，我们为这种智能重启方案证明了一个通用的性能保证。特别地，这表明在许多情况下，如果已知最佳的（问题特定的）参数值，重启方案会自动发现这些值，从而导致更好的性能。

    Estimation-of-distribution algorithms (EDAs) are optimization algorithms that learn a distribution on the search space from which good solutions can be sampled easily. A key parameter of most EDAs is the sample size (population size). If the population size is too small, the update of the probabilistic model builds on few samples, leading to the undesired effect of genetic drift. Too large population sizes avoid genetic drift, but slow down the process.  Building on a recent quantitative analysis of how the population size leads to genetic drift, we design a smart-restart mechanism for EDAs. By stopping runs when the risk for genetic drift is high, it automatically runs the EDA in good parameter regimes.  Via a mathematical runtime analysis, we prove a general performance guarantee for this smart-restart scheme. This in particular shows that in many situations where the optimal (problem-specific) parameter values are known, the restart scheme automatically finds these, leading to the a
    
[^139]: 利用队列长度和注意力机制增强交通信号控制优化

    Leveraging Queue Length and Attention Mechanisms for Enhanced Traffic Signal Control Optimization. (arXiv:2201.00006v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.00006](http://arxiv.org/abs/2201.00006)

    这篇论文提出了一种利用队列长度和注意力机制的交通信号控制优化方法。作者提出了Max Queue-Length (M-QL)和AttentionLight两种新方法，实验结果表明M-QL方法优于现有的强化学习方法，并且AttentionLight方法适用于各种交通场景并具有更好的性能表现。

    

    近年来，强化学习技术在交通信号控制中获得了越来越多的关注。然而，大多数现有的基于强化学习的交通信号控制方法往往主要关注强化学习模型结构，而忽视了适当的交通状态表示的重要性。此外，一些基于强化学习的方法在很大程度上依赖于专家设计的交通信号相位竞争。在本文中，我们提出了一种利用队列长度作为高效状态表示的TSC新方法。我们提出了两种新方法：(1) 基于队列长度属性设计的优化传统方法Max Queue-Length (M-QL)；(2) AttentionLight，一种利用自注意力机制捕捉信号相位相关性的强化学习模型，而无需人工知识的相位关系。对多个实际数据集进行的综合实验表明了我们方法的有效性：(1) M-QL方法优于最新的基于强化学习的方法；(2) 适用于各种交通场景，且相对于专家设计的方法具有更好的性能表现。

    Reinforcement learning (RL) techniques for traffic signal control (TSC) have gained increasing popularity in recent years. However, most existing RL-based TSC methods tend to focus primarily on the RL model structure while neglecting the significance of proper traffic state representation. Furthermore, some RL-based methods heavily rely on expert-designed traffic signal phase competition. In this paper, we present a novel approach to TSC that utilizes queue length as an efficient state representation. We propose two new methods: (1) Max Queue-Length (M-QL), an optimization-based traditional method designed based on the property of queue length; and (2) AttentionLight, an RL model that employs the self-attention mechanism to capture the signal phase correlation without requiring human knowledge of phase relationships. Comprehensive experiments on multiple real-world datasets demonstrate the effectiveness of our approach: (1) the M-QL method outperforms the latest RL-based methods; (2) A
    
[^140]: 优化包括维护在内的机车编组计划的约束编程与量子退火方法

    Optimising Rolling Stock Planning including Maintenance with Constraint Programming and Quantum Annealing. (arXiv:2109.07212v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2109.07212](http://arxiv.org/abs/2109.07212)

    本文比较了约束编程和量子退火方法在优化机车编组分配与维护任务中的应用，并发现两种方法在当前发展阶段的量子退火机器上产生相当的结果。

    

    我们提出并比较了使用约束编程(CP)和量子退火(QA)方法来优化考虑必要维护任务的机车编组分配。在CP方法中，我们使用AllDifferent约束、Element约束的扩展以及逻辑蕴含等来建模问题。对于QA方法，我们开发了一个二次无约束二进制优化(QUBO)模型。为了评估，我们使用基于德国铁路真实数据的数据集，并在D-Wave的真实量子计算机上运行QA方法。经典计算机用于评估CP方法以及QUBO模型中的禁忌搜索。在当前物理量子退火机器的开发阶段，我们发现两种方法往往产生相当的结果。

    We propose and compare Constraint Programming (CP) and Quantum Annealing (QA) approaches for rolling stock assignment optimisation considering necessary maintenance tasks. In the CP approach, we model the problem with an Alldifferent constraint, extensions of the Element constraint, and logical implications, among others. For the QA approach, we develop a quadratic unconstrained binary optimisation (QUBO) model. For evaluation, we use data sets based on real data from Deutsche Bahn and run the QA approach on real quantum computers from D-Wave. Classical computers are used to evaluate the CP approach as well as tabu search for the QUBO model. At the current development stage of the physical quantum annealers, we find that both approaches tend to produce comparable results.
    
[^141]: 自主车辆高速公路决策：连续动作视角下的深度强化学习

    Decision-making for Autonomous Vehicles on Highway: Deep Reinforcement Learning with Continuous Action Horizon. (arXiv:2008.11852v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2008.11852](http://arxiv.org/abs/2008.11852)

    本文提出了一种基于深度强化学习的决策策略，用于自主车辆在高速公路上的连续视角决策问题。该方法通过引入近端策略优化的算法，实现了高学习效率和优秀的控制性能。该策略从多个角度进行评估，并展示了在类似驾驶场景中的在线应用潜力。

    

    自主车辆的决策策略描述了一系列的行驶动作来实现特定的导航任务。本文利用深度强化学习方法解决了高速公路上连续视角决策问题。首先介绍了车辆运动学和高速公路驾驶场景。自动车辆的运行目标是以高效且平稳的策略执行而不发生碰撞。然后介绍了名为近端策略优化（PPO）增强的深度强化学习算法。为了克服训练效率低和样本效率低的挑战，这个应用算法能够实现高学习效率和优秀的控制性能。最后，从最优性、学习效率和适应性等多个角度对基于PPO-DRL的决策策略进行评估。通过将其应用于类似的驾驶场景，讨论了其在线应用的潜力。

    Decision-making strategy for autonomous vehicles de-scribes a sequence of driving maneuvers to achieve a certain navigational mission. This paper utilizes the deep reinforcement learning (DRL) method to address the continuous-horizon decision-making problem on the highway. First, the vehicle kinematics and driving scenario on the freeway are introduced. The running objective of the ego automated vehicle is to execute an efficient and smooth policy without collision. Then, the particular algorithm named proximal policy optimization (PPO)-enhanced DRL is illustrated. To overcome the challenges in tardy training efficiency and sample inefficiency, this applied algorithm could realize high learning efficiency and excellent control performance. Finally, the PPO-DRL-based decision-making strategy is estimated from multiple perspectives, including the optimality, learning efficiency, and adaptability. Its potential for online application is discussed by applying it to similar driving scenario
    

