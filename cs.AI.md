# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models](https://arxiv.org/abs/2402.05935) | 本论文介绍了SPHINX-X，一种扩展的多模态大型语言模型系列。通过改进架构和训练效率，我们成功构建了一系列参数大小和多语言能力不同的MLLMs，与数据和参数规模有强相关性。 |
| [^2] | [Time Series Diffusion in the Frequency Domain](https://arxiv.org/abs/2402.05933) | 本论文通过分析时间序列在频域中的表示，探讨了基于评分的扩散模型中的归纳偏差，提出了频域扩散模型，并将其与经典的时间扩散模型进行了比较。 |
| [^3] | [Driving Everywhere with Large Language Model Policy Adaptation](https://arxiv.org/abs/2402.05932) | 本文介绍了LLaDA，一种使用大型语言模型的工具，使得驾驶员和自动驾驶车辆能够在各地驾驶，通过将任务和运动计划调整到新位置的交通规则。通过广泛的用户研究，证明了LLaDA指导在解决意外情况和适应AV运动计划策略方面的有效性。 |
| [^4] | [An Interactive Agent Foundation Model](https://arxiv.org/abs/2402.05929) | 我们提出了一个交互式智能体基础模型，采用新颖的训练范式，能够跨领域、数据集和任务进行训练，展现出通用性和适应性，且在机器人、游戏 AI 和医疗保健领域表现出色。 |
| [^5] | [Risk-Sensitive Multi-Agent Reinforcement Learning in Network Aggregative Markov Games](https://arxiv.org/abs/2402.05906) | 本论文研究了网络聚合马尔可夫博弈中的风险敏感多智能体强化学习，使用了累积前景理论作为风险度量，并提出了一种分布式嵌套CPT-AC算法。这项工作对于理解人类的损失规避和对概率的高估/低估倾向具有重要意义。 |
| [^6] | [ClickSAM: Fine-tuning Segment Anything Model using click prompts for ultrasound image segmentation](https://arxiv.org/abs/2402.05902) | 本研究提出了ClickSAM，该方法使用点击提示对超声图像进行Segment Anything Model的精细调整，解决了超声图像分割中噪声干扰的问题。 |
| [^7] | [Large Language Model Meets Graph Neural Network in Knowledge Distillation](https://arxiv.org/abs/2402.05894) | 本论文提出了一种新颖的图知识蒸馏框架，使用大规模语言模型作为教师模型、图神经网络作为学生模型，解决了在理解文本-属性图中的节点分类问题中的限制。 |
| [^8] | [CREMA: Multimodal Compositional Video Reasoning via Efficient Modular Adaptation and Fusion](https://arxiv.org/abs/2402.05889) | 该论文提出了一种名为CREMA的高效且模块化的模态融合框架，用于将任意新的模态注入视频推理。通过利用预训练模型增强多种信息模态，并引入查询转换器和融合模块，实现了灵活且有效的多模态组合推理。 |
| [^9] | [Generative Echo Chamber? Effects of LLM-Powered Search Systems on Diverse Information Seeking](https://arxiv.org/abs/2402.05880) | LLM驱动的对话式搜索系统增加了选择性曝光，且支持用户观点的有偏见LLM加剧了这种偏差。 |
| [^10] | [PromptCrypt: Prompt Encryption for Secure Communication with Large Language Models](https://arxiv.org/abs/2402.05868) | PromptCrypt是一种使用表情符号对用户输入进行加密的机制，保护了大型语言模型（LLM）中用户的隐私，防止数据泄露和解密。 |
| [^11] | [How Well Can LLMs Negotiate? NegotiationArena Platform and Analysis](https://arxiv.org/abs/2402.05863) | 本文研究了LLM代理之间的谈判能力，开发了NegotiationArena框架用于评估和探索LLM代理的谈判能力。实验结果表明，LLM代理可以通过运用特定的行为策略显著提高谈判结果。 |
| [^12] | [Let Your Graph Do the Talking: Encoding Structured Data for LLMs](https://arxiv.org/abs/2402.05862) | 本论文介绍了一种参数高效的编码方法，可以使大型语言模型（LLMs）能够显式地表示结构化数据，并在图推理任务中取得了显著改进。 |
| [^13] | [Sparse-VQ Transformer: An FFN-Free Framework with Vector Quantization for Enhanced Time Series Forecasting](https://arxiv.org/abs/2402.05830) | Sparse-VQ是一种无前馈网络的框架，利用稀疏向量量化技术和反实例归一化来减少噪声影响并捕获足够的统计信息，从而提高时间序列预测的性能。 |
| [^14] | [Limitations of Agents Simulated by Predictive Models](https://arxiv.org/abs/2402.05829) | 预测模型模拟的代理存在两个结构上的局限性，分别是自动建议妄想症和预测-策略不一致性。前者是由于隐藏观测作为混淆变量，模型将生成的动作视为不存在观测的证据；后者是由于模型的隐含预测导致选择过于保守。这些故障可以通过纳入修复。 |
| [^15] | [Discovering Temporally-Aware Reinforcement Learning Algorithms](https://arxiv.org/abs/2402.05828) | 这篇论文研究了发现具有时间意识的强化学习算法，用于改进手动设计的算法，使其能够表达出学习的新原则，并适用于各种不同的设置。 |
| [^16] | [FusionSF: Fuse Heterogeneous Modalities in a Vector Quantized Framework for Robust Solar Power Forecasting](https://arxiv.org/abs/2402.05823) | 本文提出了一个多模态融合框架，将历史功率数据、数值天气预报和卫星图像整合在一起，显著提高了太阳能发电预测的性能。研究展示了强大的零样本预测能力，对于新安装的电站尤其有用。 |
| [^17] | [Selective Forgetting: Advancing Machine Unlearning Techniques and Evaluation in Language Models](https://arxiv.org/abs/2402.05813) | 本研究提出了一种新方法，在语言模型中实现了精确和选择性的遗忘，以解决神经模型意外保留个人或敏感数据的问题。此外，还提出了两个创新的评估指标，旨在衡量敏感信息消除的效果。为了强化遗忘框架，还提出了一种有效的标注敏感范围的方法。 |
| [^18] | [You Only Need One Color Space: An Efficient Network for Low-light Image Enhancement](https://arxiv.org/abs/2402.05809) | 本文提出了一种用于低光图像增强的高效网络，通过引入可训练的水平/垂直强度（HVI）颜色空间来解耦亮度和颜色，并设计了颜色和强度解耦网络（CIDNet）以改善增强过程中的稳定性。结果显示，该方法可以减少增强图像中的颜色和亮度伪影。 |
| [^19] | [Training Large Language Models for Reasoning through Reverse Curriculum Reinforcement Learning](https://arxiv.org/abs/2402.05808) | 本文提出了一种通过反向课程强化学习训练大型语言模型进行推理的新方法，通过学习正确演示并建立逐步的课程，实现了结果监督和过程监督的优化。 |
| [^20] | [InkSight: Offline-to-Online Handwriting Conversion by Learning to Read and Write](https://arxiv.org/abs/2402.05804) | InkSight是一个可以将离线手写转换为在线手写的系统，通过结合阅读和书写先验知识，在多样化的照片中有效地Derendering手写文本。 |
| [^21] | [Phonetically rich corpus construction for a low-resourced language](https://arxiv.org/abs/2402.05794) | 本文提出了一种用于资源有限语言巴西葡萄牙语的音标丰富语料库构建方法，包括收集文本数据集、基于三音分布的句子选择算法和根据声学-发音语音特征进行新的音素分类。 |
| [^22] | [Prompting Fairness: Artificial Intelligence as Game Players](https://arxiv.org/abs/2402.05786) | 人工智能作为游戏玩家能够展现出强烈的公平意识，取决于其对游戏伙伴的信任程度、游戏框架对于给予接受者的影响以及其可能存在厌恶不平等的情感。 |
| [^23] | [Limits of Transformer Language Models on Algorithmic Learning](https://arxiv.org/abs/2402.05785) | Transformer语言模型在学习离散算法方面的组合能力非常有限，比重新学习所有子任务对于新的算法组合的效果更差，而且梯度下降在记忆前馈模型上的效率非常低。 |
| [^24] | [Analysing the Sample Complexity of Opponent Shaping](https://arxiv.org/abs/2402.05782) | 本文研究了对手塑造的样本复杂性，并提出了一种适合理论分析的表格化版本R-FOS。 |
| [^25] | [Stable Autonomous Flow Matching](https://arxiv.org/abs/2402.05774) | 本文通过应用随机稳定性工具于时间独立系统的流匹配模型，研究了物理稳定数据点的深度生成模型，并与控制理论原理进行了联系。 |
| [^26] | [Generalized Preference Optimization: A Unified Approach to Offline Alignment](https://arxiv.org/abs/2402.05749) | 广义偏好优化（GPO）是一种离线损失函数，通过参数化一类凸函数来实现统一的偏好优化视角，并提供了新的算法工具和实证洞见。 |
| [^27] | [Jacquard V2: Refining Datasets using the Human In the Loop Data Correction Method](https://arxiv.org/abs/2402.05747) | 本论文提出了一种使用人机交互数据纠错方法来改进数据集质量的方案，以提升视觉识别准确性和优化视觉机器人抓取的性能。 |
| [^28] | [Real-World Robot Applications of Foundation Models: A Review](https://arxiv.org/abs/2402.05741) | 本文综述了基础模型在真实世界机器人中的应用，重点是替换现有机器人系统中的特定组件。这些基础模型在输入输出关系、感知、运动规划和控制等方面扮演了重要角色。未来的挑战和对实际机器人应用的影响也被讨论到。 |
| [^29] | [Model-Based RL for Mean-Field Games is not Statistically Harder than Single-Agent RL](https://arxiv.org/abs/2402.05724) | 本研究研究了在平均场博弈中基于模型的强化学习的样本复杂度，提出了部分基于模型的Eluder维度（P-MBED）概念来衡量模型类复杂度，并且证明在基本假设下，学习平均场博弈的纳什均衡并不比解决对数个单个智能体强化学习问题更具统计挑战性。 |
| [^30] | [Hidden in Plain Sight: Undetectable Adversarial Bias Attacks on Vulnerable Patient Populations](https://arxiv.org/abs/2402.05713) | 该研究发现在医学影像中，可以通过针对特定人群的标签污染攻击来破坏深度学习模型的性能，并引入对抗性的诊断不足偏见。研究结果还表明，人群在训练数据中的表示对于不可检测的对抗性偏见攻击的脆弱性直接相关。 |
| [^31] | [DiffSpeaker: Speech-Driven 3D Facial Animation with Diffusion Transformer](https://arxiv.org/abs/2402.05712) | DiffSpeaker是一种使用扩散变换器和自注意力模块的语音驱动3D面部动画网络，通过解决配对音频-4D数据的缺乏问题，实现了准确的唇部同步和非语言面部表达。 |
| [^32] | [Offline Risk-sensitive RL with Partial Observability to Enhance Performance in Human-Robot Teaming](https://arxiv.org/abs/2402.05703) | 本研究针对人-机组合中的性能提出了离线风险敏感强化学习算法，通过部分可观察性的建模，解决了多样化人类参与者的挑战。 |
| [^33] | [Self-Alignment of Large Language Models via Monopolylogue-based Social Scene Simulation](https://arxiv.org/abs/2402.05699) | 本文提出了一个通过社交场景模拟来自对齐大型语言模型的方法，以减轻其被滥用造成的潜在不良影响。通过一个名为MATRIX的虚拟排练空间，LLM可以在回答查询前考虑社交后果，并通过MATRIX-simulated数据的微调，保持对人类价值的遵从和推理速度的平衡。实验证明，在温和假设下，带有MATRIX的LLM胜过了宪法AI。 |
| [^34] | [Interpretable classifiers for tabular data via discretization and feature selection](https://arxiv.org/abs/2402.05680) | 通过离散化和特征选择的方法，我们提出了一种从表格数据中计算出准确又易解释的分类器的方法。在实验证明该方法在准确度上与随机森林和XGBoost等现有方法相当，并且在多种情况下实际上超过了参考结果。 |
| [^35] | [Comprehensive Assessment of Jailbreak Attacks Against LLMs](https://arxiv.org/abs/2402.05668) | 对大型语言模型（LLMs）的越狱攻击进行了全面的评估，揭示了一种绕过安全措施的不稳定漏洞。本研究是首次对多种越狱攻击方法进行大规模测量，实验证明优化的越狱提示能够持续达到最高的攻击成功率。 |
| [^36] | [Mesoscale Traffic Forecasting for Real-Time Bottleneck and Shockwave Prediction](https://arxiv.org/abs/2402.05663) | 该论文介绍了一种在实时中尺度交通预测中具有最先进效果的深度预测方法SA-LSTM，通过将自注意力与长短期记忆结合，实现了对多步预测的改进，并在短期和长期预测之间取得了平衡。 |
| [^37] | [Rethinking Propagation for Unsupervised Graph Domain Adaptation](https://arxiv.org/abs/2402.05660) | 通过重新评估GNN在图领域适应中的作用，本论文揭示了传播过程对于适应不同图领域至关重要，并通过理论分析提供了多层GNN的泛化界限的证明。 |
| [^38] | [Rocks Coding, Not Development--A Human-Centric, Experimental Evaluation of LLM-Supported SE Tasks](https://arxiv.org/abs/2402.05650) | 这项研究提出了一种自监督学习框架，用于训练神经网络从未标记的多感官数据中学习丰富而有意义的3D场景表示。通过利用不同感觉模态之间的时间一致性和几何对齐，我们的框架能够学习到强大而准确的表示。我们将我们的方法应用于各种3D感知任务，并与监督基线进行了比较，展示了竞争性的性能。此外，我们还展示了我们学到的表示在不同的传感器设置下具有很好的泛化能力，进一步突显了我们的自监督学习方法的有效性和多功能性。 |
| [^39] | [Improving Token-Based World Models with Parallel Observation Prediction](https://arxiv.org/abs/2402.05643) | 该论文提出了一种改进基于令牌的世界模型的方法，通过引入并行观测预测机制（POP）来解决想象过程中出现的瓶颈问题。通过在一个新型TBWM代理中应用POP，想象速度提高了15.4倍，在不到12小时的训练时间内在Atari 100K基准测试中取得了超人类的表现。 |
| [^40] | [The Impact of AI Tool on Engineering at ANZ Bank An Emperical Study on GitHub Copilot within Coporate Environment](https://arxiv.org/abs/2402.05636) | 本研究探讨了在澳新银行这样一个大型组织中，将AI工具GitHub Copilot整合到软件工程实践中的实证研究。通过在受控环境中进行的实验，评估了该工具在实际工程任务中的有效性，并发现在大规模采用后对生产力的改善是显著的。 |
| [^41] | [Binding Dynamics in Rotating Features](https://arxiv.org/abs/2402.05627) | 本论文研究了旋转特征中的绑定动力学问题，并提出了一种新的“余弦绑定”机制，以替代传统的“$\chi$-binding”机制。通过显式计算特征之间的对齐和相应的权重调整，这一新机制能够达到与传统机制相同的性能，与自注意力和生物神经学有关。 |
| [^42] | [Efficient Models for the Detection of Hate, Abuse and Profanity](https://arxiv.org/abs/2402.05624) | 这篇论文提出了针对仇恨、辱骂和亵渎检测的高效模型，因为大型语言模型在训练过程中可能学习到这些负面内容并生成不合适的文本。 |
| [^43] | [Pretrained Generative Language Models as General Learning Frameworks for Sequence-Based Tasks](https://arxiv.org/abs/2402.05616) | 预训练的小型生成式语言模型可以作为序列型任务的通用学习框架，通过指令微调可以在化学信息学任务中实现接近最先进结果。 |
| [^44] | [Extending 6D Object Pose Estimators for Stereo Vision](https://arxiv.org/abs/2402.05610) | 这篇论文扩展了用于立体视觉的6D物体姿态估计器，通过使用立体视觉提供的额外视角和直接推测物体的距离，该方法在6D姿态估计方面优于最先进的算法，且可适用于其他基于密集特征的算法。 |
| [^45] | [Optimizing Delegation in Collaborative Human-AI Hybrid Teams](https://arxiv.org/abs/2402.05605) | 本论文提出了一种优化协作的人工智能-人类混合团队授权的框架，通过引入AI经理（通过强化学习）作为团队的外部观察者，学习团队代理人的行为模型并选择最佳的控制代理人。 |
| [^46] | [AttnLRP: Attention-Aware Layer-wise Relevance Propagation for Transformers](https://arxiv.org/abs/2402.05602) | AttnLRP是首个能够忠实且全面地归因Transformer模型的输入和潜在表示，并具有与单一反向传播相似的计算效率的方法。它通过扩展逐层相关传递归因方法以处理注意力层来解决了黑盒Transformer模型的归因问题，具有超越现有方法的准确性和理解潜在表示的能力。 |
| [^47] | [A Concept for Reconstructing Stucco Statues from historic Sketches using synthetic Data only](https://arxiv.org/abs/2402.05593) | 本研究提出了一种使用合成数据仅通过历史素描重建灰泥雕像的全自动方法，可以实时在现场进行重建，并为专家提供一个有用的起点以手动重建雕像。 |
| [^48] | [SoftEDA: Rethinking Rule-Based Data Augmentation with Soft Labels](https://arxiv.org/abs/2402.05591) | 本文提出了SoftEDA方法，通过使用软标签在增强数据上，从而解决了基于规则的文本数据增强方法可能破坏文本原始含义的问题，实验证明了该方法的有效性。 |
| [^49] | [AutoAugment Is What You Need: Enhancing Rule-based Augmentation Methods in Low-resource Regimes](https://arxiv.org/abs/2402.05584) | 本文提出了将AutoAugment方法应用于解决文本数据增强中的语义损害问题，实验证明该方法可以加强现有的增强方法并提升预训练语言模型的性能。 |
| [^50] | [Simultaneously Achieving Group Exposure Fairness and Within-Group Meritocracy in Stochastic Bandits](https://arxiv.org/abs/2402.05575) | 该论文介绍了一种在随机赌博机中同时实现群体曝光公平性和群内精英主义的方法，通过提供随时的群体曝光公平性保证和在每个群体中实现个体层面的精英主义公平性。 |
| [^51] | [Hypergraph Node Classification With Graph Neural Networks](https://arxiv.org/abs/2402.05569) | 本研究提出了一种简单高效的框架，利用加权子图扩展的图神经网络(WCE-GNN)实现了超图节点分类。实验证明，WCE-GNN具有优秀的预测效果和较低的计算复杂度。 |
| [^52] | [Neural Multigrid Architectures](https://arxiv.org/abs/2402.05563) | 我们提出了一种简单且高效的神经网络多重网格方法，通过参数共享和层序列化实现了高效的训练，并在具有成千上万个未知数的线性问题以及具有数百万个未知数的问题上保持其效率。同时，在数值线性代数中，该网络的训练方法可以寻找最佳的光滑器，以提高几何多重网格方法的效果。我们在几个二阶椭圆方程上的实验结果表明，与基准相比，我们的方法能够显著降低误差传播矩阵的谱半径。 |
| [^53] | [Flashback: Understanding and Mitigating Forgetting in Federated Learning](https://arxiv.org/abs/2402.05558) | 本研究深入探讨了联邦学习中的遗忘问题，强调了遗忘在异质数据环境中的关键性质，提出了"闪回"算法来解决遗忘问题并取得优异的学习结果。 |
| [^54] | [Benchmarking Large Language Models on Communicative Medical Coaching: a Novel System and Dataset](https://arxiv.org/abs/2402.05547) | 本研究介绍了“ChatCoach”，一个集成人工智能与人类医生合作的框架，在交流医疗辅导中利用大型语言模型，提供模拟环境和实时反馈，以帮助医学学员提高沟通技巧。 |
| [^55] | [Offline Actor-Critic Reinforcement Learning Scales to Large Models](https://arxiv.org/abs/2402.05546) | 本文证明了离线演员-评论者强化学习方法可以扩展到大型模型，并且比基线方法在多任务训练中表现更好。通过引入Perceiver-based演员-评论者模型，我们揭示了离线强化学习与自注意机制和跨注意力模块配合的关键模型特征。这项研究的发现表明：离线演员-评论者算法是逐渐摆脱行为克隆范式的一种自然选择，并且通过离线强化学习可以从次优示范或自动生成的数据中学习掌握多个领域的多任务策略。 |
| [^56] | [Reinforcement Learning as a Catalyst for Robust and Fair Federated Learning: Deciphering the Dynamics of Client Contributions](https://arxiv.org/abs/2402.05541) | 本研究提出了一个新的框架——强化联邦学习（RFL），通过利用深度强化学习自适应地优化客户贡献的聚合过程，以增强模型鲁棒性和在非相同分布环境下参与者之间的公平性。 |
| [^57] | [Differentially Private Model-Based Offline Reinforcement Learning](https://arxiv.org/abs/2402.05525) | 本研究提出了一种差分隐私的基于模型的离线强化学习方法，通过学习离线数据中的隐私模型以及基于模型的策略优化，实现了从离线数据中训练具有隐私保护的强化学习代理。同时，研究还总结了在这种设置下隐私的代价。 |
| [^58] | [Linearizing Models for Efficient yet Robust Private Inference](https://arxiv.org/abs/2402.05521) | 本文提出了一种名为RLNet的鲁棒线性化网络，通过减少延迟并改善模型在各种情况下的表现，实现了高效而鲁棒的隐私推理。 |
| [^59] | [Can ChatGPT evaluate research quality?](https://arxiv.org/abs/2402.05519) | 本研究评估了ChatGPT 4.0评估研究质量的准确性，发现其能够产生符合标准的文档摘要和质量评估理由。然而，与作者自我评价得分相比，ChatGPT-4的评分相关性较弱，但多轮评分的平均得分具有显著正相关性。 |
| [^60] | [NoisyICL: A Little Noise in Model Parameters Calibrates In-context Learning](https://arxiv.org/abs/2402.05515) | NoisyICL通过在模型参数中引入噪音，提高了上下文学习的性能和校准性，实验结果显示NoisyICL可以产生更准确、更公平的预测。 |
| [^61] | [GPTs Are Multilingual Annotators for Sequence Generation Tasks](https://arxiv.org/abs/2402.05512) | 本研究提出了一种利用大型语言模型进行自动注释的方法，具有费用效益高和适用于低资源语言注释的优点，同时构建了一个图像字幕数据集并开放了源代码。 |
| [^62] | [Investigating White-Box Attacks for On-Device Models](https://arxiv.org/abs/2402.05493) | 本研究探究了针对设备上模型的白盒攻击，提出了一种逆向工程框架(REOM)以将编译后的设备上TFLite模型转换为可调试模型。 |
| [^63] | [Leveraging AI for Enhanced Software Effort Estimation: A Comprehensive Study and Framework Proposal](https://arxiv.org/abs/2402.05484) | 本文通过全面的研究，提出了基于人工智能的软件工作量估计框架，该框架通过克服传统方法的局限性，提高了准确性和可靠性，对于项目规划和资源分配具有重要意义。 |
| [^64] | [Rapid Optimization for Jailbreaking LLMs via Subconscious Exploitation and Echopraxia](https://arxiv.org/abs/2402.05467) | 本文介绍了一种名为RIPPLE的快速优化方法，该方法通过潜意识利用和模仿动作的思想，解决了通过越狱提示绕过安全措施的问题。 |
| [^65] | [It's Never Too Late: Fusing Acoustic Information into Large Language Models for Automatic Speech Recognition](https://arxiv.org/abs/2402.05457) | 本论文通过将声学信息融入大型语言模型（LLM）中，提出了一种名为不确定性感知动态融合（UADF）的后期融合解决方案，以克服生成性错误纠正（GER）中存在的数据不确定性问题，并应用于自动语音识别（ASR）任务。通过在自回归解码过程中实施UADF方法，在LLM决策的标记级分析和校准的基础上，动态地融合声学信息，从而提高了ASR的准确性。 |
| [^66] | [Minecraft-ify: Minecraft Style Image Generation with Text-guided Image Editing for In-Game Application](https://arxiv.org/abs/2402.05448) | 本文提出了一种用于Minecraft游戏应用的图像生成和编辑系统"Minecraft-ify"，能够生成针对3D虚拟角色的面部聚焦图像，并支持使用文本进行图像编辑，提供了更自由和优化的用户体验。 |
| [^67] | [GPT-4 Generated Narratives of Life Events using a Structured Narrative Prompt: A Validation Study](https://arxiv.org/abs/2402.05435) | 本研究通过使用结构化叙事提示，验证了GPT-4生成的叙述在传达生活事件方面的有效性。研究结果表明，大多数叙述能够足够传达提示的意图。同时，通过机器学习模型的训练和验证，可以自动识别有效和无效的叙述。 |
| [^68] | [Mixture Density Networks for Classification with an Application to Product Bundling](https://arxiv.org/abs/2402.05428) | 本论文提出了两个基于混合密度网络的分类模型，这两个模型通过拟合高斯混合分布并使用学习到的分布进行分类，效果略优于或与五个基准分类模型相当。在实际的产品捆绑应用中，我们的模型在学习产品支付意愿分布方面展现出真实的实用效果。 |
| [^69] | [DiffTOP: Differentiable Trajectory Optimization for Deep Reinforcement and Imitation Learning](https://arxiv.org/abs/2402.05421) | DiffTOP使用可微分轨迹优化作为策略表示来生成动作，解决了模型基于强化学习算法中的“目标不匹配”问题，并在模仿学习任务上进行了性能基准测试。 |
| [^70] | [In-Context Principle Learning from Mistakes](https://arxiv.org/abs/2402.05403) | 本文提出了一种新的学习方法LEAP，通过让模型从少量输入-输出示例中犯错误，然后反思并学习准则，从而提升模型在各种任务上的表现。 |
| [^71] | [CURE: Simulation-Augmented Auto-Tuning in Robotics](https://arxiv.org/abs/2402.05399) | 本论文提出了一种模拟辅助的自动调节技术，用于解决机器人系统中的高度可配置参数的优化问题。该技术通过解决软硬件之间配置选项的交互问题，实现了在不同环境和机器人平台之间的性能迁移。 |
| [^72] | [TASER: Temporal Adaptive Sampling for Fast and Accurate Dynamic Graph Representation Learning](https://arxiv.org/abs/2402.05396) | 该论文提出了TASER方法，它是针对动态图表示学习的时间自适应采样技术，在准确性、效率和可扩展性方面进行了优化，解决了现实世界动态图中存在的噪声问题。 |
| [^73] | [Knowledge Graphs Meet Multi-Modal Learning: A Comprehensive Survey](https://arxiv.org/abs/2402.05391) | 知识图谱与多模态学习的综述介绍了KG4MM和MM4KG两个主要方面，包括任务定义、构建进展、评估基准以及关键研究轨迹。 |
| [^74] | [Graph Neural Networks for Physical-Layer Security in Multi-User Flexible-Duplex Networks](https://arxiv.org/abs/2402.05378) | 本文研究了多用户灵活双工网络中的物理层安全问题，提出了基于图神经网络的无监督学习策略，并通过大量数值模拟验证了其在性能和时间复杂度方面的优势。 |
| [^75] | [CIC: A framework for Culturally-aware Image Captioning](https://arxiv.org/abs/2402.05374) | CIC是一种面向文化感知图像字幕的框架，通过结合视觉问答和大型语言模型，它能够生成能描述图像中文化元素的详细字幕。 |
| [^76] | [Attention as Robust Representation for Time Series Forecasting](https://arxiv.org/abs/2402.05370) | 在时间序列预测中，我们提出的方法将注意力权重提升为主要表示，使用全局标志和局部窗口构建的注意力图作为稳健核表示来克服噪声和分布变化，并取得了比现有模型更好的性能 improvement. |
| [^77] | [Guiding Large Language Models with Divide-and-Conquer Program for Discerning Problem Solving](https://arxiv.org/abs/2402.05359) | 该论文提出了一种以分治程序引导大型语言模型（LLM）的方法，以解决涉及重复子任务和/或具有欺骗性内容的问题。实验证明，该方法可以提高LLM的表达能力。 |
| [^78] | [A Survey on Safe Multi-Modal Learning System](https://arxiv.org/abs/2402.05355) | 这项研究提出了第一个多模态学习系统安全的分类法，对当前发展状态下的关键限制进行了审查，并提出了未来研究的潜在方向。 |
| [^79] | [KIX: A Metacognitive Generalization Framework](https://arxiv.org/abs/2402.05346) | 人工智能代理缺乏通用行为，需要利用结构化知识表示。该论文提出了一种元认知泛化框架KIX，通过与对象的交互学习可迁移的交互概念和泛化能力，促进了知识与强化学习的融合，为实现人工智能系统的自主和通用行为提供了潜力。 |
| [^80] | [Learning on Multimodal Graphs: A Survey](https://arxiv.org/abs/2402.05322) | 这篇综述论文对多模态图学习的已有工作进行了对比分析，阐明了多模态学习的方式和主流技术特点，并揭示了其重要应用和未来方向。 |
| [^81] | [Three Pathways to Neurosymbolic Reinforcement Learning with Interpretable Model and Policy Networks](https://arxiv.org/abs/2402.05307) | 本文探讨了实现具有可解释性的模型和策略的神经符号强化学习的三个路径，并揭示了学习的连续性和可微性的益处，以及将逻辑与数值仿真结合的难点。 |
| [^82] | [Sym-Q: Adaptive Symbolic Regression via Sequential Decision-Making](https://arxiv.org/abs/2402.05306) | Sym-Q是一个基于强化学习的模型，通过将符号回归重新定义为顺序决策任务来解决现有模型在泛化性和适应性方面的挑战。通过利用监督演示和奖励信号，Sym-Q能够根据拟合精度的质量改进表达式。 |
| [^83] | [BIKED++: A Multimodal Dataset of 1.4 Million Bicycle Image and Parametric CAD Designs](https://arxiv.org/abs/2402.05301) | 本文介绍了BIKED++数据集，其中包含了140万个自行车设计的图像和参数化CAD文件。该数据集可以用于训练跨模态预测模型，例如使用参数化表示来准确估计图像的特征嵌入。该数据集也已公开，可供研究者使用。 |
| [^84] | [Classifying spam emails using agglomerative hierarchical clustering and a topic-based approach](https://arxiv.org/abs/2402.05296) | 该论文提出了使用凝聚层次聚类和基于主题的方法对垃圾邮件进行分类的新思路。作者提出了两个新的数据集SPEMC-15K-E和SPEMC-15K-S，并使用凝聚层次聚类将其划分为11个类别。实验结果表明，TF-IDF和LR在英文数据集中达到最佳性能。 |
| [^85] | [An information theoretic approach to quantify the stability of feature selection and ranking algorithms](https://arxiv.org/abs/2402.05295) | 本论文提出了一种基于信息论的方法来量化特征选择和排序算法的稳定性。该方法能够评估不同算法结果中的特征排序的稳定性，包括完整的排名列表、特征子集和部分排名列表。 |
| [^86] | [Examining Modality Incongruity in Multimodal Federated Learning for Medical Vision and Language-based Disease Detection](https://arxiv.org/abs/2402.05294) | 本文首次分析了多模态联邦学习中的模态不一致性的影响，并揭示了其与参与客户端之间的数据异质性的联系。通过使用不考虑不一致性的信息融合机制和模态插值网络，在解决模态不一致性问题方面取得了一定的成果。 |
| [^87] | [A comparative study on feature selection for a risk prediction model for colorectal cancer](https://arxiv.org/abs/2402.05293) | 这项研究比较了不同特征选择算法在结直肠癌风险预测模型中的性能，并提出了视觉方法评估特征排序技术的稳定性。 |
| [^88] | [Do Transformer World Models Give Better Policy Gradients?](https://arxiv.org/abs/2402.05290) | 在强化学习中，通过使用变形器世界模型来预测未来奖励并进行策略梯度学习通常变得不可行。研究人员发现常用的变形器世界模型会产生迂回的梯度路径，对于长距离的策略梯度是有害的。为了解决这个问题，他们提出了一种名为Actions World Models (AWMs)的世界模型，可以提供更直接的梯度传播路径。 |
| [^89] | [Gradient descent induces alignment between weights and the empirical NTK for deep non-linear networks](https://arxiv.org/abs/2402.05271) | 了解神经网络从输入-标签对中提取统计信息的机制是监督学习中最重要的未解决问题之一。前人的研究表明，在训练过程中，权重的格拉姆矩阵与模型的平均梯度外积成正比，这被称为神经特征分析（NFA）。本研究解释了这种相关性的出现，并发现NFA等价于权重矩阵的左奇异结构与与这些权重相关的经验神经切线核的显著成分之间的对齐。在早期训练阶段，可以通过解析的方式预测NFA的发展速度。 |
| [^90] | [Learning Fair Ranking Policies via Differentiable Optimization of Ordered Weighted Averages](https://arxiv.org/abs/2402.05252) | 本文介绍了一种通过优化有序加权平均值函数，在LTR模型的训练过程中集成高效的公平排名模型，实现公平性、用户效用和运行时效率之间的有利平衡。 |
| [^91] | [Universal Neural Functionals](https://arxiv.org/abs/2402.05232) | 本文提出了通用神经功能（UNFs），一种能够自动构建适用于任何权重空间的置换等变模型的算法。实验结果显示，在优化小型图像分类器和语言模型时，UNFs能够取得有希望的改进，为学习优化器设计提供了新的思路。 |
| [^92] | [VerAs: Verify then Assess STEM Lab Reports](https://arxiv.org/abs/2402.05224) | VerAs是一个端到端的神经架构，用于验证和评估STEM实验报告。它通过利用多个维度的分析评估标准，以及针对学生提供详细反馈，帮助他们提高科学写作技巧。 |
| [^93] | [The Effect of Sampling Temperature on Problem Solving in Large Language Models](https://arxiv.org/abs/2402.05201) | 这项研究实证研究了采样温度对大型语言模型在解题中的影响，结果显示在0.0至1.0的温度范围内，LLM性能对解题任务没有显著影响。 |
| [^94] | [Are LLMs Ready for Real-World Materials Discovery?](https://arxiv.org/abs/2402.05200) | LLMs在材料科学中的应用受限，无法实现实际应用。我们提出了基于材料科学知识和假设测试的MatSci-LLMs框架，并描述了关键的材料科学信息提取挑战。 |
| [^95] | [InCoRo: In-Context Learning for Robotics Control with Feedback Loops](https://arxiv.org/abs/2402.05188) | 本文提出了InCoRo系统，使用经典的机器人反馈循环，通过LLM控制器、场景理解单元和机器人的协同工作，实现对动态环境中机器人控制的上下文学习。该系统能够持续分析环境状态并提供适应性执行命令，使机器人能够适应环境变化并纠正控制器错误。 |
| [^96] | [A Resource Model For Neural Scaling Law](https://arxiv.org/abs/2402.05164) | 该论文介绍了神经缩放律的资源模型，通过观察实证发现，子任务的损失与分配的神经元成反比，复合任务中子任务获得的资源随模型变大而增长，保持资源比例不变。该模型可以用于预测复合任务的神经缩放律，并成功复制了Chinchilla模型的神经缩放律。该资源模型是表征和诊断神经网络的有用工具。 |
| [^97] | [Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications](https://arxiv.org/abs/2402.05162) | 本研究通过修剪和低秩修改，发现大型语言模型（LLMs）的安全机制固有易碎性，去除安全关键区域会损害安全性，但对效用影响不大，需要更强健的安全策略。 |
| [^98] | [What's documented in AI? Systematic Analysis of 32K AI Model Cards](https://arxiv.org/abs/2402.05160) | 本研究对Hugging Face平台上的32,111份AI模型文档进行了全面分析，发现大多数模型提供了模型卡，但信息量不一致。有关环境影响、限制和评估的部分填写率最低，训练部分则填写率最高。 |
| [^99] | [Enhancement of Bengali OCR by Specialized Models and Advanced Techniques for Diverse Document Types](https://arxiv.org/abs/2402.05158) | 本文介绍了一个孟加拉OCR系统，具有重构文档布局、精确提取、多样化文档类型支持和优化字符与单词识别的特点。 |
| [^100] | [What About the Data? A Mapping Study on Data Engineering for AI Systems](https://arxiv.org/abs/2402.05156) | 本文通过进行一项关于AI系统数据工程的映射研究，提出了关于AI数据工程活动的生命周期阶段，技术解决方案和架构以及经验教训。 |
| [^101] | [Adaptive Hypergraph Network for Trust Prediction](https://arxiv.org/abs/2402.05154) | 本文提出了一种自适应超图网络（AHNTP）方法，通过利用高阶相关性来改善信任预测的准确性。AHNTP利用基于模式的PageRank来捕捉高阶社交影响信息，并通过构建超群从节点级和结构级属性融入复杂的相关信息。 |
| [^102] | [CrashFormer: A Multimodal Architecture to Predict the Risk of Crash](https://arxiv.org/abs/2402.05151) | CrashFormer是一种多模态架构，利用全面的输入数据（如事故历史、天气信息、地图图像和人口信息），可以每6小时预测5.161平方公里地理范围内的未来事故风险。 |
| [^103] | [FlowPG: Action-constrained Policy Gradient with Normalizing Flows](https://arxiv.org/abs/2402.05149) | 本文提出了使用正则化流的动作约束策略梯度（FlowPG）方法，以解决动作约束强化学习中的挑战。该方法通过学习一个可逆映射和开发多种动作采样方法，有效地解决了在每个强化学习步骤中确保代理采取合理动作的问题。 |
| [^104] | [Cost Optimized Scheduling in Modular Electrolysis Plants](https://arxiv.org/abs/2402.05148) | 本文提出了一种基于交替方向乘子方法的分散式调度模型，以优化模块化电解植物的运营。该模型旨在平衡氢气产量和波动需求，以最小化边际化氢气成本，并确保适应运营干扰。 |
| [^105] | [Compressing Deep Reinforcement Learning Networks with a Dynamic Structured Pruning Method for Autonomous Driving](https://arxiv.org/abs/2402.05146) | 本文提出了一种动态结构化剪枝方法，用于压缩深度强化学习网络，以便在资源受限的自动驾驶设备中实现高效部署。通过逐渐删除不重要的神经元，我们的方法显著减小了内存消耗和计算量。 |
| [^106] | [A Bandit Approach with Evolutionary Operators for Model Selection](https://arxiv.org/abs/2402.05144) | 本文提出了一种使用进化算子的强盗方法来进行模型选择，通过将模型选择问题建模为无穷臂赌博机问题，利用部分训练和准确性作为奖励，最终的算法Mutant-UCB在测试中表现出色，优于固定预算下的最先进技术。 |
| [^107] | [The Foundations of Computational Management: A Systematic Approach to Task Automation for the Integration of Artificial Intelligence into Existing Workflows](https://arxiv.org/abs/2402.05142) | 本文介绍了计算管理，一种系统方法，用于将人工智能整合到现有工作流程中。它提供了三个简单的步骤来开始实施人工智能，包括任务（重新）组织，评估自动化潜力和完成人工智能选择和适应的任务规范模板。 |
| [^108] | [Tag-LLM: Repurposing General-Purpose LLMs for Specialized Domains](https://arxiv.org/abs/2402.05140) | 本文介绍了一种将通用的LLMs应用于专业领域的方法，通过学习自定义的输入标签来对LLMs进行条件约束。通过明确将任务领域与任务功能分离，这种方法能够改善在专业领域中的任务求解能力。 |
| [^109] | [SceMQA: A Scientific College Entrance Level Multimodal Question Answering Benchmark](https://arxiv.org/abs/2402.05138) | SceMQA是一种科学类大学入学级多模态问题回答的基准，填补了现有基准中被忽视的教育阶段的空白。它包含核心科学科目，融合了多项选择和自由回答的格式，并提供详细的问题解析和答案解释。该基准还通过相同背景但问题不同的方式，促进了对推理能力更全面和准确的评估。 |
| [^110] | [CADReN: Contextual Anchor-Driven Relational Network for Controllable Cross-Graphs Node Importance Estimation](https://arxiv.org/abs/2402.05135) | CADReN是一个上下文锚点驱动的关系网络，用于可控的跨图节点重要性估计。它通过引入上下文锚点机制，考虑知识图谱中的结构和语义特征，实现了更好的性能，包括零-shot预测能力，并开源了两个新的数据集RIC200和WK1K。 |
| [^111] | [Personalized Language Modeling from Personalized Human Feedback](https://arxiv.org/abs/2402.05133) | 该论文提出了一个个性化语言模型的方法，通过在于用户的反馈数据中引入个性化特征来解决强化学习框架在多样化用户偏好下存在的问题。 |
| [^112] | [LB-KBQA: Large-language-model and BERT based Knowledge-Based Question and Answering System](https://arxiv.org/abs/2402.05130) | LB-KBQA是一种基于大语言模型和BERT的基于知识的问答系统，通过生成式人工智能的帮助，能够提高意图识别的性能和解决语言多样性的问题。 |
| [^113] | [Enhancing Textbook Question Answering Task with Large Language Models and Retrieval Augmented Generation](https://arxiv.org/abs/2402.05128) | 本论文通过引入检索增强生成（RAG）技术和利用迁移学习来处理长文本和提升推理能力，为教科书问答任务带来了显著的改进。 |
| [^114] | [Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering](https://arxiv.org/abs/2402.05127) | 本研究提出了一种新的抑郁症检测和治疗范式，使用先进的大型语言模型，经过特定提示微调以诊断、解释和建议治疗干预。同时还介绍了一个丰富的数据库，以提供个性化的治疗建议。此方法与患者进行共情对话管理，有效支持抑郁症患者。 |
| [^115] | [Zero-Shot Clinical Trial Patient Matching with LLMs](https://arxiv.org/abs/2402.05125) | 本研究基于LLMs开发了一个零样本临床试验患者匹配系统，可以高效评估患者是否符合入选标准，并通过优化提示策略和检索流程提高了数据和成本效率。 |
| [^116] | [Large Language Model for Table Processing: A Survey](https://arxiv.org/abs/2402.05121) | 该调查综述了大型语言模型在表格处理中的应用，包括传统的表格问题回答和事实验证，以及新兴的表格操作和高级表格数据分析。还讨论了LLMs的最新范例，特别关注了指导调整、提示和基于代理的方法。 |
| [^117] | [More Agents Is All You Need](https://arxiv.org/abs/2402.05120) | 大型语言模型的性能与代理数量成比例，通过简单的采样和投票方法可以进一步增强性能，这种方法与现有的复杂方法正交。 |
| [^118] | [A Closer Look at the Limitations of Instruction Tuning](https://arxiv.org/abs/2402.05119) | 本文通过实验和分析揭示了指令调整的多个局限性，包括无法增强LLM的知识和技能、从具有知识来源的数据集复制回应模式导致质量下降、全参数微调增加了错误生成的情况。 |
| [^119] | [Unsupervised Motion Retargeting for Human-Robot Imitation](https://arxiv.org/abs/2402.05115) | 该论文研究了无监督运动重定位用于人机仿真的问题，提出了一个编码器-解码器神经网络模型进行领域到领域的转换。这种方法可以在无对应数据的情况下进行人机仿真。 |
| [^120] | [SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models](https://arxiv.org/abs/2402.05044) | SALAD-Bench是一个针对大语言模型的全面安全基准，通过其大规模、丰富的分类和多功能性，以及对攻击和防御方法的评估，实现了对LLMs的有效管理和保护。 |
| [^121] | [Multi-Sender Persuasion -- A Computational Perspective](https://arxiv.org/abs/2402.04971) | 这项研究考虑了多个具有信息优势的发信者向单个自私行为者传递信号以影响其行为的问题，并提出了一种新颖的可微神经网络方法来近似解决这一问题。通过额外梯度算法，我们发现了超越已有方法的局部均衡解。 |
| [^122] | [S-Agents: self-organizing agents in open-ended environment](https://arxiv.org/abs/2402.04578) | S-Agents是一个自组织代理系统，通过引入代理树结构、沙漏代理架构和非阻塞协作方法，实现了在无限环境中高效协调代理的能力，提供了优化协作效率和灵活性的解决方案。 |
| [^123] | [Read to Play (R2-Play): Decision Transformer with Multimodal Game Instruction](https://arxiv.org/abs/2402.04154) | 本论文探索了为智能体提供增强形式的任务指导，使其能够理解游戏指导并实现"读玩游戏"的能力。通过将多模态指导调优的成功应用于视觉任务中的强化学习任务，构建了一组... (内容太长，无法继续显示) |
| [^124] | [Logical Specifications-guided Dynamic Task Sampling for Reinforcement Learning Agents](https://arxiv.org/abs/2402.03678) | 本文提出了一种逻辑规范引导下的动态任务采样（LSTS）方法，通过学习一组强化学习策略，根据高级任务规范指导智能体在最小化环境交互次数的同时实现从初始状态到目标状态的引导。在网格世界实验中，LSTS实现了改进的时间到阈值。 |
| [^125] | [IGUANe: a 3D generalizable CycleGAN for multicenter harmonization of brain MR images](https://arxiv.org/abs/2402.03227) | IGUANe是一种三维通用CycleGAN模型，通过集成多个域的训练实现了脑MR图像的多中心协调，使其成为通用生成器。 |
| [^126] | [BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation](https://arxiv.org/abs/2402.03216) | BGE M3-嵌入是一种新的多语言、多功能和多粒度的文本嵌入模型，支持超过100种工作语言，并在多语言和跨语言检索任务上取得了最先进的性能。它能够同时执行密集检索、多向量检索和稀疏检索，并能处理不同粒度的输入。其有效训练包括了一种自知识蒸馏方法和优化的批处理策略。 |
| [^127] | [Conversation Reconstruction Attack Against GPT Models](https://arxiv.org/abs/2402.02987) | 本文介绍了一种针对 GPT 模型的对话重构攻击，该攻击具有劫持会话和重构对话的两个步骤。通过对该攻击对 GPT 模型的隐私风险进行评估，发现 GPT-4 对该攻击具有一定的鲁棒性。 |
| [^128] | [Analysis of Internet of Things implementation barriers in the cold supply chain: an integrated ISM-MICMAC and DEMATEL approach](https://arxiv.org/abs/2402.01804) | 本研究通过综述和调查研究物联网在冷链中的实施障碍，发现了13个关键障碍。其中，合规性和冷链网络是物联网采用策略的关键驱动因素。MICMAC和DEMATEL方法的应用有助于评估障碍之间的互动关系和因果关系。 |
| [^129] | [A Multi-Perspective Machine Learning Approach to Evaluate Police-Driver Interaction in Los Angeles](https://arxiv.org/abs/2402.01703) | 该研究提出了一种多角度的机器学习方法，用于分析洛杉矶警察与司机的互动。该方法利用多模态的数据包括音频、视频和文字信息，旨在提供对复杂和有争议的警民互动的分析工具。 |
| [^130] | [ReAGent: Towards A Model-agnostic Feature Attribution Method for Generative Language Models](https://arxiv.org/abs/2402.00794) | 本论文介绍了一种面向生成语言模型的模型无关特征归因方法，称为ReAGent。该方法解决了现有方法在文本生成中的适用性问题，并提供了计算上效率更高的选择。 |
| [^131] | [Resolving Ethics Trade-offs in Implementing Responsible AI](https://arxiv.org/abs/2401.08103) | 该论文提出了通过权衡处理人工智能伦理中的紧张关系的五种方法，并提出了一个框架来实施全面的人工智能/机器学习系统。 |
| [^132] | [Robust Knowledge Extraction from Large Language Models using Social Choice Theory](https://arxiv.org/abs/2312.14877) | 本研究提出使用排名查询和社会选择理论的方法来提高大型语言模型（LLMs）查询的鲁棒性，特别是在高风险领域如医学中。我们通过实证评估验证了我们方法的鲁棒性和其他有趣属性。 |
| [^133] | [Autoencoder Based Face Verification System](https://arxiv.org/abs/2312.14301) | 这篇论文提出了一种基于自编码器的人脸验证系统，通过使用预训练的自编码器初始化深度神经网络，实现对标记数据依赖性的减少，在人脸图像识别任务中取得了较好的效果。 |
| [^134] | [In-Context Reinforcement Learning for Variable Action Spaces](https://arxiv.org/abs/2312.13327) | 本文提出了一种Headless-AD模型，通过只训练一次，能够在变化的行动空间中实现强化学习任务的泛化。实验证明该模型能够在从未遇到过的行动空间上表现出显著的泛化能力，甚至胜过针对特定行动集训练的模型。 |
| [^135] | [Curated LLM: Synergy of LLMs and Data Curation for tabular augmentation in ultra low-data regimes](https://arxiv.org/abs/2312.12112) | 本论文提出了CLLM方法，利用LLMs和数据筛选在低数据环境中进行表格增强。通过利用大型语言模型的先验知识以及基于学习动态、置信度和不确定度指标的筛选机制，CLLM取得了优越的性能。 |
| [^136] | [How Far Can Fairness Constraints Help Recover From Biased Data?](https://arxiv.org/abs/2312.10396) | 公平性约束在极度有偏差的数据上能够恢复到原始数据分布上准确和公平的分类器。 |
| [^137] | [CIDR: A Cooperative Integrated Dynamic Refining Method for Minimal Feature Removal Problem](https://arxiv.org/abs/2312.08157) | CIDR是一种解决最小特征删除问题的合作式集成动态修正方法，通过使用合作式集成梯度来检测特征交互作用，并将问题转化为一个背包问题，从众多候选集中确定最小特征集。 |
| [^138] | [DroneOptiNet: A Framework for Optimal Drone-based Load Redistribution Mechanism for 5G and Beyond Solar Small Cell Networks](https://arxiv.org/abs/2311.12944) | 本研究提出了一种用于5G及其后太阳能小型蜂窝网络的最佳无人机负载重分配机制，通过使用无人机上的空中基站进行可靠安全的电力再分配，提高了网络的可靠性和稳健性。 |
| [^139] | [Modeling Choice via Self-Attention](https://arxiv.org/abs/2311.07607) | 本论文提出了一种选择模型，利用自注意力成功地进行了建模，这是在深度学习和选择建模领域中的一个重要的研究空白。 |
| [^140] | [Lie Neurons: Adjoint-Equivariant Neural Networks for Semisimple Lie Algebras](https://arxiv.org/abs/2310.04521) | 本文提出了一种Lie神经元网络，能够以任何半单Lie代数数据为输入，通过伴随操作使其具有等变性。通过推广向量神经元网络和引入新的层，该网络在各个领域具有广泛的适用性和竞争性能。 |
| [^141] | [OHQ: On-chip Hardware-aware Quantization](https://arxiv.org/abs/2309.01945) | 本文提出了一种在芯片上进行硬件感知混合精度量化的框架（OHQ），通过构建量化感知流水线和引入掩码引导的量化估计技术，实现了在资源受限的硬件上进行高效量化，填补了现有混合精度量化的搜索空间过大和实际部署差距大的问题。 |
| [^142] | [Lookbehind-SAM: k steps back, 1 step forward](https://arxiv.org/abs/2307.16704) | 本研究提出了一种名为Lookbehind-SAM的方法，通过多次上升步骤和线性插值来增强最大化和最小化过程，以实现更好的损失锐度折衷。实验证明，该方法在各种任务中都有多种优点，包括提高的泛化性能、更高的鲁棒性和改进的学习过程。 |
| [^143] | [Revolutionizing Cyber Threat Detection with Large Language Models: A privacy-preserving BERT-based Lightweight Model for IoT/IIoT Devices](https://arxiv.org/abs/2306.14263) | 本文介绍了一种名为SecurityBERT的新型模型，采用预训练的BERT模型和隐私保护编码技术，用于在物联网网络中检测网络威胁。该模型能够高精度识别网络攻击，并具有最小的计算要求。 |
| [^144] | [HardSATGEN: Understanding the Difficulty of Hard SAT Formula Generation and A Strong Structure-Hardness-Aware Baseline](https://arxiv.org/abs/2302.02104) | HardSATGEN方法提出了一种精细的控制机制，以更好地恢复工业基准的结构和计算特性，此方法在工业SAT公式生成任务中表现出优越性。 |
| [^145] | [Boolean Observation Games](https://arxiv.org/abs/2202.03637) | 布尔观察博弈是一种有限的多人策略博弈，具有不完全信息和定性目标。它是布尔博弈的一种泛化，可以捕捉到不完美和不完全信息的特点。 |
| [^146] | [Self-Rewarding Language Models.](http://arxiv.org/abs/2401.10020) | 该论文提出了自奖励语言模型的概念，通过LLM作为评判者，使用语言模型自己提供训练过程中的奖励。研究表明，该方法不仅可以提高指令遵循能力，还可以为自己提供高质量的奖励。通过对Llama 2 70B模型的三次迭代微调，结果在AlpacaEval 2.0排行榜上超过了其他现有系统。这项工作为实现能够不断自我改进的模型开辟了新的可能性。 |
| [^147] | [Rethinking Spectral Graph Neural Networks with Spatially Adaptive Filtering.](http://arxiv.org/abs/2401.09071) | 本文重新思考了谱图神经网络，并揭示了谱滤波和空间聚合之间的联系。该研究发现，谱滤波在隐含地将原始图转换成适应性新图，并明确计算用于空间聚合的新图。适应性新图展现出非局部性，并能够反映节点之间的标签一致性。 |
| [^148] | [Multimodal Learning for detecting urban functional zones using remote sensing image and multi-semantic information.](http://arxiv.org/abs/2401.06550) | 本研究提出了一种利用遥感图像和多语义信息进行城市功能区检测的多模态学习算法，能够满足移动互联网在线到离线业务的精确要求。 |
| [^149] | [RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation.](http://arxiv.org/abs/2401.04679) | RoSA是一种新的PEFT方法，通过在预训练权重上训练低秩和高度稀疏的组件，以高效近似完全微调的性能，来实现准确的参数高效微调。在多个生成任务中，RoSA表现出优于其他方法的性能。 |
| [^150] | [Contextual Fixed-Budget Best Arm Identification: Adaptive Experimental Design with Policy Learning.](http://arxiv.org/abs/2401.03756) | 该论文研究了个性化治疗推荐的问题，提出了一个上下文固定预算的最佳臂识别模型，通过自适应实验设计和策略学习来推荐最佳治疗方案，并通过最坏情况下的期望简单遗憾来衡量推荐的有效性。 |
| [^151] | [Fairness-Aware Job Scheduling for Multi-Job Federated Learning.](http://arxiv.org/abs/2401.02740) | 本文提出了一种公平感知联邦作业调度（FairFedJS）方法，以确保将高需求的FL客户端数据集公平分配给需要它们的FL作业，并在实验证明其优势。 |
| [^152] | [Quadratic Time-Frequency Analysis of Vibration Signals for Diagnosing Bearing Faults.](http://arxiv.org/abs/2401.01172) | 本文提出了一种融合时间频率分析和深度学习技术的方法，用于在实际条件下诊断带有时间变化速度和不同噪声水平的轴承故障。这种方法有效地解析与不同轴承故障相关的独特动态模式。 |
| [^153] | [Can Large Language Models Capture Public Opinion about Global Warming? An Empirical Assessment of Algorithmic Fidelity and Bias.](http://arxiv.org/abs/2311.00217) | 本研究评估了大型语言模型（LLMs）的算法逼真性和偏见，并发现LLMs可以有效捕捉总统投票行为，但在准确表示全球变暖观点方面存在挑战。同时，LLMs对某些群体的观点估计存在偏差，特别是对非洲裔美国人对全球变暖的担忧低估。这些结果突出了LLMs在社会科学研究中的潜力，并强调了准确性的重要性。 |
| [^154] | [VFedMH: Vertical Federated Learning for Training Multi-party Heterogeneous Models.](http://arxiv.org/abs/2310.13367) | VFedMH是一种垂直联合学习方法，通过在前向传播过程中聚合参与者的嵌入来处理参与者之间的异构模型，解决了现有VFL方法面临的挑战。 |
| [^155] | [Lag-Llama: Towards Foundation Models for Time Series Forecasting.](http://arxiv.org/abs/2310.08278) | Lag-Llama是一个基于大量时间序列数据训练的通用预测模型，在未见过的数据集上展现出强大的零样本预测能力，并使用光滑断裂幂律模型来拟合和预测扩展行为。 |
| [^156] | [A Language-Agent Approach to Formal Theorem-Proving.](http://arxiv.org/abs/2310.04353) | COPRA是一种面向形式定理证明的语言代理方法，利用大型语言模型进行上下文学习，通过选择策略和检索定义和引理进行证明，在MiniF2F基准和Coq任务上表现出优异的性能。 |
| [^157] | [Teaching Text-to-Image Models to Communicate.](http://arxiv.org/abs/2309.15516) | 本文提出了一种针对对话生成图像的高效方法，通过微调预训练的文本到图像模型，实现在给定对话背景下生成一致逼真的图像。 |
| [^158] | [GAMIX-VAE: A VAE with Gaussian Mixture Based Posterior.](http://arxiv.org/abs/2309.13160) | 本文提出了一种基于高斯混合后验的VAE方法，重新定义了ELBO，引入正则化项和PatchGAN鉴别器，能够生成逼真的人脸。 |
| [^159] | [Answering Layer 3 queries with DiscoSCMs.](http://arxiv.org/abs/2309.09323) | 本文介绍了DiscoSCMs，一种用于解决因果查询的模型。它通过扩展结构因果模型和潜在结果框架来解决一致性规则引发的退化问题，并在分析个性化激励场景中的潜在结果时展示了其有效性。通过引入独立潜在噪声条件，可以提高解决Layer 3查询的准确性和可解释性。 |
| [^160] | [How (Not) to Use Sociodemographic Information for Subjective NLP Tasks.](http://arxiv.org/abs/2309.07034) | 该论文研究了如何使用社会人口统计信息在主观NLP任务中，发现社会人口提示技术在某些任务上有效，但也存在一些限制和挑战。 |
| [^161] | [Empowering Clinicians and Democratizing Data Science: Large Language Models Automate Machine Learning for Clinical Studies.](http://arxiv.org/abs/2308.14120) | chatGPT ADA是一种能够自主开发临床研究所需的最先进的机器学习模型的大型语言模型，可将高级分析工具民主化，使非数据科学家的临床医生能够轻松应用于医学领域。 |
| [^162] | [Learning to Team-Based Navigation: A Review of Deep Reinforcement Learning Techniques for Multi-Agent Pathfinding.](http://arxiv.org/abs/2308.05893) | 本文综述了在多智能体路径规划中深度强化学习技术的应用。与其他研究不同，我们重点介绍了DRL方法在MAPF中的整合，并解决了MAPF解决方案评估指标缺乏统一性的问题。我们讨论了基于模型的DRL作为未来发展方向，并提供了解决MAPF当前挑战所需的基础理解。 |
| [^163] | [Who Answers It Better? An In-Depth Analysis of ChatGPT and Stack Overflow Answers to Software Engineering Questions.](http://arxiv.org/abs/2308.02312) | 本研究深入分析了ChatGPT和Stack Overflow回答软件工程问题的特点和可用性。结果显示，ChatGPT回答中有52%错误，77%冗长，但由于其综合性和清晰的语言表达，仍然在39.34%的情况下被使用者偏好选择。 |
| [^164] | [Reinforcement Learning for Generative AI: State of the Art, Opportunities and Open Research Challenges.](http://arxiv.org/abs/2308.00031) | 这篇论文调查了在生成人工智能中应用强化学习的现状、机会和开放研究问题。作者主要讨论了三种应用类型：无特定目标的生成方式、同时最大化目标函数的输出生成方式以及将无法通过目标函数捕捉的期望特征嵌入生成过程的方式。这个新兴领域中存在着丰富的机会和挑战。 |
| [^165] | [Safe Reinforcement Learning as Wasserstein Variational Inference: Formal Methods for Interpretability.](http://arxiv.org/abs/2307.07084) | 本研究提出了一种新的自适应Wasserstein变分优化（AWaVO）方法，利用形式方法解决了顺序决策中的解释和透明性问题，并提供了奖励设计和策略收敛的概率解释。 |
| [^166] | [S2vNTM: Semi-supervised vMF Neural Topic Modeling.](http://arxiv.org/abs/2307.04804) | S2vNTM是一种半监督的vMF神经主题建模方法，通过利用关键词的模式来识别潜在的主题，并优化主题关键词集的质量，提高了分类准确度，并且速度至少比基线模型快两倍。 |
| [^167] | [NeuralMatrix: Moving Entire Neural Networks to General Matrix Multiplication for Efficient Inference.](http://arxiv.org/abs/2305.14405) | NeuralMatrix是一种框架，能够在单个通用矩阵乘法加速器上计算深度神经网络(DNNs)，并可在保持推理准确度的情况下实现高达113倍至19.44倍的性能提升。 |
| [^168] | [Attention-Enhanced Deep Learning for Device-Free Through-the-Wall Presence Detection Using Indoor WiFi System.](http://arxiv.org/abs/2304.13105) | 本文提出了一种利用WiFi信号进行人员存在检测的新系统，采用了关注机制和双向LSTM网络来提高准确性，并证明了其在现实场景中的稳健性。 |
| [^169] | [An Introduction to Transformers.](http://arxiv.org/abs/2304.10557) | Transformer是一种神经网络组件，可以学习序列或数据集表示，在自然语言处理、计算机视觉和时空建模方面取得了重大进展。本论文提供了一个数学精确、直观、简洁的Transformer架构描述。 |
| [^170] | [Principled Reinforcement Learning with Human Feedback from Pairwise or $K$-wise Comparisons.](http://arxiv.org/abs/2301.11270) | 该论文提供了带有人类反馈强化学习问题的理论框架，证明了最大似然估计在Bradley-Terry-Luce和Plackett-Luce模型下收敛。此外，提出了在一定的覆盖假设下，基于悲观估计的MLE提供了性能更好的策略。在证明了真实MLE和以成对比较形式替代的备选MLE都可以在PL模型下收敛的同时，也表明了真实MLE的高效性。这些结果为RLHF算法提供了新的见解，并统一了RLHF问题和IRL问题。 |
| [^171] | [Anticipatory Fleet Repositioning for Shared-use Autonomous Mobility Services: An Optimization and Learning-Based Approach.](http://arxiv.org/abs/2210.08659) | 本文提出一种基于优化和学习的方法，通过预测未来需求和合作优化基于分配策略的重新平衡策略，从而改善SAMS车队的服务质量和效率，并在真实数据集上进行的数值实验表明该方法较传统启发式方法具有更好的性能和可靠性。 |

# 详细

[^1]: SPHINX-X: 扩展数据和参数用于一系列多模态大型语言模型

    SPHINX-X: Scaling Data and Parameters for a Family of Multi-modal Large Language Models

    [https://arxiv.org/abs/2402.05935](https://arxiv.org/abs/2402.05935)

    本论文介绍了SPHINX-X，一种扩展的多模态大型语言模型系列。通过改进架构和训练效率，我们成功构建了一系列参数大小和多语言能力不同的MLLMs，与数据和参数规模有强相关性。

    

    我们提出SPHINX-X，一种基于SPHINX开发的广泛多模态大型语言模型（MLLM）系列。为了改善架构和训练效率，我们通过移除冗余的视觉编码器、绕过完全填充的子图像，并将多阶段训练简化成为一阶段的全集合模式，修改了SPHINX框架。为了充分发挥MLLM的潜力，我们组装了一个综合的跨语言、跨视觉和视觉-语言任务的多领域、多模态的数据集，涵盖了公开可用的资源。我们进一步使用我们的OCR密集和Mark数据集丰富这个收集，扩展了多样性和普适性。通过对不同基础LLM进行训练，包括TinyLlama1.1B、InternLM2-7B、LLaMA2-13B和Mixtral8x7B，我们获得了一系列参数大小和多语言能力变化的MLLMs。全面的基准测试揭示了多模态性能与数据和参数规模之间的强相关性。

    We propose SPHINX-X, an extensive Multimodality Large Language Model (MLLM) series developed upon SPHINX. To improve the architecture and training efficiency, we modify the SPHINX framework by removing redundant visual encoders, bypassing fully-padded sub-images with skip tokens, and simplifying multi-stage training into a one-stage all-in-one paradigm. To fully unleash the potential of MLLMs, we assemble a comprehensive multi-domain and multimodal dataset covering publicly available resources in language, vision, and vision-language tasks. We further enrich this collection with our curated OCR intensive and Set-of-Mark datasets, extending the diversity and generality. By training over different base LLMs including TinyLlama1.1B, InternLM2-7B, LLaMA2-13B, and Mixtral8x7B, we obtain a spectrum of MLLMs that vary in parameter size and multilingual capabilities. Comprehensive benchmarking reveals a strong correlation between the multi-modal performance with the data and parameter scales. 
    
[^2]: 频域中的时间序列扩散

    Time Series Diffusion in the Frequency Domain

    [https://arxiv.org/abs/2402.05933](https://arxiv.org/abs/2402.05933)

    本论文通过分析时间序列在频域中的表示，探讨了基于评分的扩散模型中的归纳偏差，提出了频域扩散模型，并将其与经典的时间扩散模型进行了比较。

    

    傅里叶分析在信号处理的发展中起到了重要的作用。这使我们想知道这个框架是否能够同样有益于生成模型。在本文中，我们通过时间序列扩散模型的范围来探讨这个问题。具体来说，我们分析了在频域中表示时间序列是否对基于评分的扩散模型具有有用的归纳偏差。通过从时间域中扩散的经典SDE公式出发，我们展示了在频域中发生了一种双重扩散过程，并具有一个重要的细微差别：布朗运动被我们称之为镜像布朗运动所取代，其特征是其组分之间的镜像对称性。在此基础上，我们展示了如何通过适应去噪评分匹配方法来实现频域中的扩散模型。这导致了频域扩散模型，我们将其与经典的时间扩散模型进行了比较。我们在实际工作上进行了实证评估。

    Fourier analysis has been an instrumental tool in the development of signal processing. This leads us to wonder whether this framework could similarly benefit generative modelling. In this paper, we explore this question through the scope of time series diffusion models. More specifically, we analyze whether representing time series in the frequency domain is a useful inductive bias for score-based diffusion models. By starting from the canonical SDE formulation of diffusion in the time domain, we show that a dual diffusion process occurs in the frequency domain with an important nuance: Brownian motions are replaced by what we call mirrored Brownian motions, characterized by mirror symmetries among their components. Building on this insight, we show how to adapt the denoising score matching approach to implement diffusion models in the frequency domain. This results in frequency diffusion models, which we compare to canonical time diffusion models. Our empirical evaluation on real-wor
    
[^3]: 通过大型语言模型政策适应在各处驾驶

    Driving Everywhere with Large Language Model Policy Adaptation

    [https://arxiv.org/abs/2402.05932](https://arxiv.org/abs/2402.05932)

    本文介绍了LLaDA，一种使用大型语言模型的工具，使得驾驶员和自动驾驶车辆能够在各地驾驶，通过将任务和运动计划调整到新位置的交通规则。通过广泛的用户研究，证明了LLaDA指导在解决意外情况和适应AV运动计划策略方面的有效性。

    

    自动驾驶中，将驾驶行为适应新环境、习俗和法律是一个长期存在的问题，这限制了自动驾驶车辆(AVs)的广泛部署。本文介绍了LLaDA，一种简单而强大的工具，可以使人类驾驶员和自动驾驶车辆都能在各处行驶，通过将任务和运动计划调整到新位置的交通规则。LLaDA利用大型语言模型(LLMs)在解释本地驾驶手册中的交通规则时具有令人印象深刻的零-shot泛化能力。通过广泛的用户研究，我们展示了LLaDA的指导在解决现实世界中的意外情况时的有用性。我们还展示了LLaDA在真实世界数据集中调整AV运动计划策略的能力；LLaDA在所有指标上优于基线规划方法。请访问我们的网站了解更多详细信息：https://boyiliee.github.io/llada.

    Adapting driving behavior to new environments, customs, and laws is a long-standing problem in autonomous driving, precluding the widespread deployment of autonomous vehicles (AVs). In this paper, we present LLaDA, a simple yet powerful tool that enables human drivers and autonomous vehicles alike to drive everywhere by adapting their tasks and motion plans to traffic rules in new locations. LLaDA achieves this by leveraging the impressive zero-shot generalizability of large language models (LLMs) in interpreting the traffic rules in the local driver handbook. Through an extensive user study, we show that LLaDA's instructions are useful in disambiguating in-the-wild unexpected situations. We also demonstrate LLaDA's ability to adapt AV motion planning policies in real-world datasets; LLaDA outperforms baseline planning approaches on all our metrics. Please check our website for more details: https://boyiliee.github.io/llada.
    
[^4]: 一个交互式智能体基础模型

    An Interactive Agent Foundation Model

    [https://arxiv.org/abs/2402.05929](https://arxiv.org/abs/2402.05929)

    我们提出了一个交互式智能体基础模型，采用新颖的训练范式，能够跨领域、数据集和任务进行训练，展现出通用性和适应性，且在机器人、游戏 AI 和医疗保健领域表现出色。

    

    人工智能系统的发展正在从创建静态、任务特定的模型转变为能够在各种应用中表现出色的动态智能体系统。我们提出了一个交互式智能体基础模型，采用了一种新颖的多任务智能体训练范式，用于训练跨领域、数据集和任务的 AI 智能体。我们的训练范式统一了各种预训练策略，包括视觉遮挡自编码器、语言建模和下一步行动预测，实现了一个通用而适应性强的 AI 框架。我们在三个独立领域 - 机器人、游戏 AI 和医疗保健中展示了我们框架的性能。我们的模型在每个领域都展示了生成有意义和上下文相关输出的能力。我们方法的优势在于其广泛性，利用了各种数据源，如机器人序列、游戏数据、大规模视频数据集和文本信息，以实现高效的效果。

    The development of artificial intelligence systems is transitioning from creating static, task-specific models to dynamic, agent-based systems capable of performing well in a wide range of applications. We propose an Interactive Agent Foundation Model that uses a novel multi-task agent training paradigm for training AI agents across a wide range of domains, datasets, and tasks. Our training paradigm unifies diverse pre-training strategies, including visual masked auto-encoders, language modeling, and next-action prediction, enabling a versatile and adaptable AI framework. We demonstrate the performance of our framework across three separate domains -- Robotics, Gaming AI, and Healthcare. Our model demonstrates its ability to generate meaningful and contextually relevant outputs in each area. The strength of our approach lies in its generality, leveraging a variety of data sources such as robotics sequences, gameplay data, large-scale video datasets, and textual information for effectiv
    
[^5]: 网络聚合马尔可夫博弈中的风险敏感多智能体强化学习

    Risk-Sensitive Multi-Agent Reinforcement Learning in Network Aggregative Markov Games

    [https://arxiv.org/abs/2402.05906](https://arxiv.org/abs/2402.05906)

    本论文研究了网络聚合马尔可夫博弈中的风险敏感多智能体强化学习，使用了累积前景理论作为风险度量，并提出了一种分布式嵌套CPT-AC算法。这项工作对于理解人类的损失规避和对概率的高估/低估倾向具有重要意义。

    

    传统的多智能体强化学习（MARL）假设智能体对风险中性并具有完全客观性。然而，在智能体需要考虑或建模人类经济或社会偏好的情景中，必须将风险概念纳入强化学习优化问题中。在其他人类或非人类智能体参与，可能具有其自己的风险敏感策略的MARL中，这将更加重要。在这项工作中，我们考虑了具有累积前景理论（CPT）的风险敏感和非合作MARL，CPT是一种非凸风险度量，并且是风险协同度量的扩展。CPT能够解释人类的损失规避和他们对小概率/大概率的高估/低估倾向。我们提出了一种使用CPT风险的分布式基于采样的演员-评论家（AC）算法，用于网络聚合马尔可夫博弈（NAMGs），我们称之为分布式嵌套CPT-AC。在一系列假设下，我们证明了算法收敛到一种主观概念。

    Classical multi-agent reinforcement learning (MARL) assumes risk neutrality and complete objectivity for agents. However, in settings where agents need to consider or model human economic or social preferences, a notion of risk must be incorporated into the RL optimization problem. This will be of greater importance in MARL where other human or non-human agents are involved, possibly with their own risk-sensitive policies. In this work, we consider risk-sensitive and non-cooperative MARL with cumulative prospect theory (CPT), a non-convex risk measure and a generalization of coherent measures of risk. CPT is capable of explaining loss aversion in humans and their tendency to overestimate/underestimate small/large probabilities. We propose a distributed sampling-based actor-critic (AC) algorithm with CPT risk for network aggregative Markov games (NAMGs), which we call Distributed Nested CPT-AC. Under a set of assumptions, we prove the convergence of the algorithm to a subjective notion 
    
[^6]: 使用点击提示对超声图像分割进行精调的Segment Anything Model（SAM）

    ClickSAM: Fine-tuning Segment Anything Model using click prompts for ultrasound image segmentation

    [https://arxiv.org/abs/2402.05902](https://arxiv.org/abs/2402.05902)

    本研究提出了ClickSAM，该方法使用点击提示对超声图像进行Segment Anything Model的精细调整，解决了超声图像分割中噪声干扰的问题。

    

    由于其卓越的分割准确性、多样的输入提示、训练能力和高效的模型设计，新发布的Segment Anything Model（SAM）成为图像处理中流行的工具。然而，SAM当前的模型是在一个多样的数据集上训练的，而这些数据集并没有针对医学图像，尤其是超声图像。超声图像往往有很多噪声，这使得分割重要结构变得困难。在这个项目中，我们开发了ClickSAM，它使用点击提示对超声图像进行Segment Anything Model的精细调整。ClickSAM有两个训练阶段：第一阶段使用位于真实轮廓中心的单击提示进行训练，第二阶段通过额外的正负点击提示来改善模型性能。通过将第一阶段的预测与真实掩膜进行比较，计算出真正正、假正和假负段。正点击使用真实掩膜中的真实

    The newly released Segment Anything Model (SAM) is a popular tool used in image processing due to its superior segmentation accuracy, variety of input prompts, training capabilities, and efficient model design. However, its current model is trained on a diverse dataset not tailored to medical images, particularly ultrasound images. Ultrasound images tend to have a lot of noise, making it difficult to segment out important structures. In this project, we developed ClickSAM, which fine-tunes the Segment Anything Model using click prompts for ultrasound images. ClickSAM has two stages of training: the first stage is trained on single-click prompts centered in the ground-truth contours, and the second stage focuses on improving the model performance through additional positive and negative click prompts. By comparing the first stage predictions to the ground-truth masks, true positive, false positive, and false negative segments are calculated. Positive clicks are generated using the true 
    
[^7]: 大规模语言模型在知识蒸馏中遇见图神经网络

    Large Language Model Meets Graph Neural Network in Knowledge Distillation

    [https://arxiv.org/abs/2402.05894](https://arxiv.org/abs/2402.05894)

    本论文提出了一种新颖的图知识蒸馏框架，使用大规模语言模型作为教师模型、图神经网络作为学生模型，解决了在理解文本-属性图中的节点分类问题中的限制。

    

    尽管近期学术界对于大规模语言模型（LLMs）在理解文本-属性图（TAG）方面的进展和潜力有所披露，但LLMs在实际应用中的部署受到了计算和存储需求高，推理过程中延迟长的限制。同时，传统的图神经网络（GNNs）虽然轻量且擅长学习图的结构特征，但对于真实应用中TAG复杂语义的把握有所限制。为了解决这些限制，我们聚焦于TAG中节点分类的下游任务，提出了一种新颖的图知识蒸馏框架，称为语言图知识蒸馏（LinguGKD），使用LLMs作为教师模型，GNNs作为学生模型进行知识蒸馏。其中包括对LLM进行TAG定向指导调整以应对设计的节点分类提示，然后对层次化学习的节点特征进行对齐。

    Despite recent community revelations about the advancements and potential of Large Language Models (LLMs) in understanding Text-Attributed Graphs (TAG), the deployment of LLMs for production is hindered by their high computational and storage requirements, as well as long latencies during inference. Simultaneously, although traditional Graph Neural Networks (GNNs) are light weight and adept at learning structural features of graphs, their ability to grasp the complex semantics in TAGs is somewhat constrained for real applications. To address these limitations, we concentrate on the downstream task of node classification in TAG and propose a novel graph knowledge distillation framework, termed Linguistic Graph Knowledge Distillation (LinguGKD), using LLMs as teacher models and GNNs as student models for knowledge distillation. It involves TAG-oriented instruction tuning of LLM on designed node classification prompts, followed by aligning the hierarchically learned node features of the t
    
[^8]: CREMA: 通过有效的模块化适应和融合进行多模态组合视频推理

    CREMA: Multimodal Compositional Video Reasoning via Efficient Modular Adaptation and Fusion

    [https://arxiv.org/abs/2402.05889](https://arxiv.org/abs/2402.05889)

    该论文提出了一种名为CREMA的高效且模块化的模态融合框架，用于将任意新的模态注入视频推理。通过利用预训练模型增强多种信息模态，并引入查询转换器和融合模块，实现了灵活且有效的多模态组合推理。

    

    尽管在多模态组合推理方法方面取得了令人瞩目的进展，但由于处理固定模态输入并更新许多模型参数，仍然存在灵活性和效率方面的限制。本文解决了这些关键挑战，提出了CREMA，一种用于将任何新的模态注入视频推理的高效且模块化的模态融合框架。我们首先利用现有的预训练模型从给定的视频中增强多种信息模态（如光流、3D点云、音频），而无需额外的人工注释。接下来，我们引入了一个查询转换器，该转换器与每个可以访问的模态相关联，并具有多个参数高效的模块。它将多种模态特征投影到LLM令牌嵌入空间，使模型能够整合不同的数据类型以进行响应生成。此外，我们提出了一个融合模块，用于压缩多模态查询，在LLM中保持计算效率的同时进行融合组合。

    Despite impressive advancements in multimodal compositional reasoning approaches, they are still limited in their flexibility and efficiency by processing fixed modality inputs while updating a lot of model parameters. This paper tackles these critical challenges and proposes CREMA, an efficient and modular modality-fusion framework for injecting any new modality into video reasoning. We first augment multiple informative modalities (such as optical flow, 3D point cloud, audio) from given videos without extra human annotation by leveraging existing pre-trained models. Next, we introduce a query transformer with multiple parameter-efficient modules associated with each accessible modality. It projects diverse modality features to the LLM token embedding space, allowing the model to integrate different data types for response generation. Furthermore, we propose a fusion module designed to compress multimodal queries, maintaining computational efficiency in the LLM while combining additio
    
[^9]: 生成性回音室？LLM驱动的搜索系统对多样化信息搜索的影响

    Generative Echo Chamber? Effects of LLM-Powered Search Systems on Diverse Information Seeking

    [https://arxiv.org/abs/2402.05880](https://arxiv.org/abs/2402.05880)

    LLM驱动的对话式搜索系统增加了选择性曝光，且支持用户观点的有偏见LLM加剧了这种偏差。

    

    数亿人已经使用过大型语言模型（LLM）驱动的对话式搜索系统，并且相信这些系统相比传统搜索带来了许多好处。然而，虽然几十年的研究和公共讨论都调查了搜索系统在增加选择性曝光和产生回音室方面的风险，即限制接触多样化意见并导致意见偏执，但对于LLM驱动的对话式搜索的这种风险知之甚少。我们进行了两个实验来研究：1）LLM驱动的对话式搜索相较于传统搜索是否以及如何增加选择性曝光；2）具有支持或挑战用户观点的意见偏见的LLM如何改变这种影响。总体而言，我们发现参与者在LLM驱动的对话式搜索中更倾向于进行偏见的信息查询，并且支持他们观点的有偏见的LLM加剧了这种偏差。这些结果呈现了重要的意义。

    Large language models (LLMs) powered conversational search systems have already been used by hundreds of millions of people, and are believed to bring many benefits over conventional search. However, while decades of research and public discourse interrogated the risk of search systems in increasing selective exposure and creating echo chambers -- limiting exposure to diverse opinions and leading to opinion polarization, little is known about such a risk of LLM-powered conversational search. We conduct two experiments to investigate: 1) whether and how LLM-powered conversational search increases selective exposure compared to conventional search; 2) whether and how LLMs with opinion biases that either reinforce or challenge the user's view change the effect. Overall, we found that participants engaged in more biased information querying with LLM-powered conversational search, and an opinionated LLM reinforcing their views exacerbated this bias. These results present critical implicatio
    
[^10]: PromptCrypt: 使用表情符号对大型语言模型进行安全通信的提示加密

    PromptCrypt: Prompt Encryption for Secure Communication with Large Language Models

    [https://arxiv.org/abs/2402.05868](https://arxiv.org/abs/2402.05868)

    PromptCrypt是一种使用表情符号对用户输入进行加密的机制，保护了大型语言模型（LLM）中用户的隐私，防止数据泄露和解密。

    

    基于云的大型语言模型（LLM）如ChatGPT在日常操作中变得越来越重要，成为各种应用程序中的重要工具。虽然这些模型在可访问性和功能性方面带来了重大好处，但它们也引入了重要的隐私问题：在云基础架构中传输和存储用户数据会产生重大的数据泄露和未经授权访问敏感信息的风险；即使数据的传输和存储被加密，LLM服务提供商仍然知道数据的真实内容，从而阻止个人或实体放心使用此类LLM服务。为了解决这些问题，本文提出了一种简单但有效的机制PromptCrypt来保护用户隐私。它使用表情符号对用户输入进行加密，然后将其发送到LLM，有效地使其对人类或LLM的检查无法理解，同时保留原始提示的意图，从而确保用户隐私。

    Cloud-based large language models (LLMs) such as ChatGPT have increasingly become integral to daily operations, serving as vital tools across various applications. While these models offer substantial benefits in terms of accessibility and functionality, they also introduce significant privacy concerns: the transmission and storage of user data in cloud infrastructures pose substantial risks of data breaches and unauthorized access to sensitive information; even if the transmission and storage of data is encrypted, the LLM service provider itself still knows the real contents of the data, preventing individuals or entities from confidently using such LLM services. To address these concerns, this paper proposes a simple yet effective mechanism PromptCrypt to protect user privacy. It uses Emoji to encrypt the user inputs before sending them to LLM, effectively rendering them indecipherable to human or LLM's examination while retaining the original intent of the prompt, thus ensuring the 
    
[^11]: LLMs能够进行良好的谈判吗？NegotiationArena平台与分析

    How Well Can LLMs Negotiate? NegotiationArena Platform and Analysis

    [https://arxiv.org/abs/2402.05863](https://arxiv.org/abs/2402.05863)

    本文研究了LLM代理之间的谈判能力，开发了NegotiationArena框架用于评估和探索LLM代理的谈判能力。实验结果表明，LLM代理可以通过运用特定的行为策略显著提高谈判结果。

    

    谈判是社会交往的基础；人们谈判从汽车价格到如何共享共同资源的一切。随着对使用大型语言模型（LLMs）代表人类用户行动的兴趣不断增长，这些LLM代理也需要具备谈判能力。在本文中，我们研究了LLMs之间的谈判能力。我们开发了NegotiationArena：一个灵活的评估和探索LLM代理谈判能力的框架。我们在NegotiationArena中实施了三种类型的场景，以评估LLMs在分配共享资源（终极博弈）、聚合资源（交易博弈）和买卖商品（价格谈判）方面的行为。每个场景都允许LLM代理之间进行多轮灵活对话，以进行更复杂的谈判。有趣的是，通过采用某些行为策略，LLM代理可以显著提高谈判结果。例如，通过假装处境困顿和绝望，LLM代理可以增加谈判成果。

    Negotiation is the basis of social interactions; humans negotiate everything from the price of cars to how to share common resources. With rapidly growing interest in using large language models (LLMs) to act as agents on behalf of human users, such LLM agents would also need to be able to negotiate. In this paper, we study how well LLMs can negotiate with each other. We develop NegotiationArena: a flexible framework for evaluating and probing the negotiation abilities of LLM agents. We implemented three types of scenarios in NegotiationArena to assess LLM's behaviors in allocating shared resources (ultimatum games), aggregate resources (trading games) and buy/sell goods (price negotiations). Each scenario allows for multiple turns of flexible dialogues between LLM agents to allow for more complex negotiations. Interestingly, LLM agents can significantly boost their negotiation outcomes by employing certain behavioral tactics. For example, by pretending to be desolate and desperate, LL
    
[^12]: 让你的图来说话：为LLMs编码结构化数据

    Let Your Graph Do the Talking: Encoding Structured Data for LLMs

    [https://arxiv.org/abs/2402.05862](https://arxiv.org/abs/2402.05862)

    本论文介绍了一种参数高效的编码方法，可以使大型语言模型（LLMs）能够显式地表示结构化数据，并在图推理任务中取得了显著改进。

    

    我们如何最有效地将结构化数据编码成序列形式，以供大型语言模型（LLMs）使用？在这项工作中，我们介绍了一种参数高效的方法，可以明确表示LLMs的结构化数据。我们的方法，GraphToken，学习了一种编码函数，以显式结构化信息扩展提示语。与其他专注于有限领域（例如知识图表示）的工作不同，我们的工作是首次针对一般结构化数据编码进行研究，用于各种推理任务。我们展示了明确表示图结构可以显著改进图推理任务。具体来说，我们在GraphQA基准测试中看到了整体的改进 - 在节点、边和图级任务上高达73%的改进。

    How can we best encode structured data into sequential form for use in large language models (LLMs)? In this work, we introduce a parameter-efficient method to explicitly represent structured data for LLMs. Our method, GraphToken, learns an encoding function to extend prompts with explicit structured information. Unlike other work which focuses on limited domains (e.g. knowledge graph representation), our work is the first effort focused on the general encoding of structured data to be used for various reasoning tasks. We show that explicitly representing the graph structure allows significant improvements to graph reasoning tasks. Specifically, we see across the board improvements - up to 73% points - on node, edge and, graph-level tasks from the GraphQA benchmark.
    
[^13]: 稀疏向量量化变压器：一种无前馈网络的框架，用于增强时间序列预测

    Sparse-VQ Transformer: An FFN-Free Framework with Vector Quantization for Enhanced Time Series Forecasting

    [https://arxiv.org/abs/2402.05830](https://arxiv.org/abs/2402.05830)

    Sparse-VQ是一种无前馈网络的框架，利用稀疏向量量化技术和反实例归一化来减少噪声影响并捕获足够的统计信息，从而提高时间序列预测的性能。

    

    时间序列分析对于许多应用非常重要，而变压器在这个领域中变得越来越突出。领先的方法从自然语言处理和计算机视觉中定制了变压器架构，利用修补技术将连续信号转换为片段。然而，由于分布变化和内在噪声水平的显著变化，时间序列数据具有独特的挑战。为了解决这两个挑战，我们引入了稀疏向量量化的FFN-Free变压器（Sparse-VQ）。我们的方法利用稀疏向量量化技术和反实例归一化（RevIN）来减少噪声影响，并捕获足够的统计信息用于预测，作为变压器架构中前馈层（FFN）的替代方法。我们的无FFN方法削减了参数数量，提高了计算效率，并减少了过拟合。通过对十个基准数据集进行评估，包括新引入的CAISO数据集，Sparse-VQ取得了

    Time series analysis is vital for numerous applications, and transformers have become increasingly prominent in this domain. Leading methods customize the transformer architecture from NLP and CV, utilizing a patching technique to convert continuous signals into segments. Yet, time series data are uniquely challenging due to significant distribution shifts and intrinsic noise levels. To address these two challenges,we introduce the Sparse Vector Quantized FFN-Free Transformer (Sparse-VQ). Our methodology capitalizes on a sparse vector quantization technique coupled with Reverse Instance Normalization (RevIN) to reduce noise impact and capture sufficient statistics for forecasting, serving as an alternative to the Feed-Forward layer (FFN) in the transformer architecture. Our FFN-free approach trims the parameter count, enhancing computational efficiency and reducing overfitting. Through evaluations across ten benchmark datasets, including the newly introduced CAISO dataset, Sparse-VQ su
    
[^14]: 预测模型模拟的代理的局限性

    Limitations of Agents Simulated by Predictive Models

    [https://arxiv.org/abs/2402.05829](https://arxiv.org/abs/2402.05829)

    预测模型模拟的代理存在两个结构上的局限性，分别是自动建议妄想症和预测-策略不一致性。前者是由于隐藏观测作为混淆变量，模型将生成的动作视为不存在观测的证据；后者是由于模型的隐含预测导致选择过于保守。这些故障可以通过纳入修复。

    

    越来越多的关注点是将预测模型应用于类似于代理的系统，特别是基于语言模型的AI助手。我们概述了这些模型在转变成代理时可能失败的两个结构上的原因。首先，我们讨论了自动建议妄想症。先前的研究从理论上表明，如果代理依赖于隐藏观测数据，模型无法模仿生成训练数据的代理:隐藏观测作为混淆变量，模型将其生成的动作视为不存在观测的证据。其次，我们引入并正式研究了一个相关的新限制:预测-策略不一致性。当一个模型生成一系列动作时，模型对生成这些动作的策略的隐含预测可以作为混淆变量。结果是，模型选择动作时，好像它们预期未来的动作是次优的，导致它们过于保守。我们证明了包含这两种故障的修复。

    There is increasing focus on adapting predictive models into agent-like systems, most notably AI assistants based on language models. We outline two structural reasons for why these models can fail when turned into agents. First, we discuss auto-suggestive delusions. Prior work has shown theoretically that models fail to imitate agents that generated the training data if the agents relied on hidden observations: the hidden observations act as confounding variables, and the models treat actions they generate as evidence for nonexistent observations. Second, we introduce and formally study a related, novel limitation: predictor-policy incoherence. When a model generates a sequence of actions, the model's implicit prediction of the policy that generated those actions can serve as a confounding variable. The result is that models choose actions as if they expect future actions to be suboptimal, causing them to be overly conservative. We show that both of those failures are fixed by includi
    
[^15]: 发现具有时间意识的强化学习算法

    Discovering Temporally-Aware Reinforcement Learning Algorithms

    [https://arxiv.org/abs/2402.05828](https://arxiv.org/abs/2402.05828)

    这篇论文研究了发现具有时间意识的强化学习算法，用于改进手动设计的算法，使其能够表达出学习的新原则，并适用于各种不同的设置。

    

    最近的元学习进展使得根据代理目标函数自动发现参数化的新型强化学习算法成为可能。为了改进手动设计的算法，必须对这个学习到的目标函数的参数化进行改进，使其能够表达出学习的新原则（而不仅仅是恢复已经建立的原则），同时仍然适用于其元训练分布之外的各种设置。然而，现有方法集中于发现类似于强化学习中广泛使用的目标函数，这些目标函数不考虑训练所允许的总步数或“训练视野”。相反，人类在获取新能力的过程中会使用各种不同的学习目标。例如，学生可能会根据考试截止日期和自我评估的能力来改变他们的学习技巧。本文认为...

    Recent advancements in meta-learning have enabled the automatic discovery of novel reinforcement learning algorithms parameterized by surrogate objective functions. To improve upon manually designed algorithms, the parameterization of this learned objective function must be expressive enough to represent novel principles of learning (instead of merely recovering already established ones) while still generalizing to a wide range of settings outside of its meta-training distribution. However, existing methods focus on discovering objective functions that, like many widely used objective functions in reinforcement learning, do not take into account the total number of steps allowed for training, or "training horizon". In contrast, humans use a plethora of different learning objectives across the course of acquiring a new ability. For instance, students may alter their studying techniques based on the proximity to exam deadlines and their self-assessed capabilities. This paper contends tha
    
[^16]: FusionSF：在矢量量化框架中融合异质模态以实现可靠的太阳能发电预测

    FusionSF: Fuse Heterogeneous Modalities in a Vector Quantized Framework for Robust Solar Power Forecasting

    [https://arxiv.org/abs/2402.05823](https://arxiv.org/abs/2402.05823)

    本文提出了一个多模态融合框架，将历史功率数据、数值天气预报和卫星图像整合在一起，显著提高了太阳能发电预测的性能。研究展示了强大的零样本预测能力，对于新安装的电站尤其有用。

    

    准确的太阳能发电预测对于将光伏电站整合到电网中，调度和确保电网安全至关重要。对于缺乏足够数据的新安装的太阳能电站来说，这个问题变得更加紧迫。当前的研究主要依赖于历史太阳能发电数据或数值天气预报，以单一模态的形式，忽略了不同模态提供的互补信息。在本文中，我们提出了一个多模态融合框架，将历史功率数据、数值天气预报和卫星图像进行整合，显著提高了预测性能。我们引入了一个矢量量化框架，使具有不同信息密度的模态对齐，平衡了整合足够信息和避免模型过拟合之间的关系。我们的框架展现了强大的零样本预测能力，对于新安装的电站尤其有用。此外，我们还收集并发布了训练和测试数据集。

    Accurate solar power forecasting is crucial to integrate photovoltaic plants into the electric grid, schedule and secure the power grid safety. This problem becomes more demanding for those newly installed solar plants which lack sufficient data. Current research predominantly relies on historical solar power data or numerical weather prediction in a single-modality format, ignoring the complementary information provided in different modalities. In this paper, we propose a multi-modality fusion framework to integrate historical power data, numerical weather prediction, and satellite images, significantly improving forecast performance. We introduce a vector quantized framework that aligns modalities with varying information densities, striking a balance between integrating sufficient information and averting model overfitting. Our framework demonstrates strong zero-shot forecasting capability, which is especially useful for those newly installed plants. Moreover, we collect and release
    
[^17]: 选择性遗忘：推进语言模型中的机器遗忘技术和评估

    Selective Forgetting: Advancing Machine Unlearning Techniques and Evaluation in Language Models

    [https://arxiv.org/abs/2402.05813](https://arxiv.org/abs/2402.05813)

    本研究提出了一种新方法，在语言模型中实现了精确和选择性的遗忘，以解决神经模型意外保留个人或敏感数据的问题。此外，还提出了两个创新的评估指标，旨在衡量敏感信息消除的效果。为了强化遗忘框架，还提出了一种有效的标注敏感范围的方法。

    

    本研究旨在研究机器遗忘（MU），这是一个致力于解决神经模型意外保留个人或敏感数据的问题的新兴领域。在这里，引入了一种新方法，实现精确和选择性遗忘语言模型中的信息。与以往完全相反的训练目标的方法不同，这种方法旨在减轻对语言模型性能的负面影响，特别是在生成任务中。此外，提出了两个创新的评估指标：敏感信息提取可能性（S-EL）和敏感信息存储准确性（S-MA），旨在衡量敏感信息消除的有效性。为了加强遗忘框架，提出了一种有效的标注敏感范围的方法，涵盖了在线和离线策略。在线选择机制利用语言概率得分确保计算效率，而离线策略则利用基于距离的过滤器。

    The aim of this study is to investigate Machine Unlearning (MU), a burgeoning field focused on addressing concerns related to neural models inadvertently retaining personal or sensitive data. Here, a novel approach is introduced to achieve precise and selective forgetting within language models. Unlike previous methodologies that adopt completely opposing training objectives, this approach aims to mitigate adverse effects on language model performance, particularly in generation tasks. Furthermore, two innovative evaluation metrics are proposed: Sensitive Information Extraction Likelihood (S-EL) and Sensitive Information Memory Accuracy (S-MA), designed to gauge the effectiveness of sensitive information elimination. To reinforce the forgetting framework, an effective method for annotating sensitive scopes is presented, involving both online and offline strategies. The online selection mechanism leverages language probability scores to ensure computational efficiency, while the offline
    
[^18]: 只需一个颜色空间：一种用于低光图像增强的高效网络

    You Only Need One Color Space: An Efficient Network for Low-light Image Enhancement

    [https://arxiv.org/abs/2402.05809](https://arxiv.org/abs/2402.05809)

    本文提出了一种用于低光图像增强的高效网络，通过引入可训练的水平/垂直强度（HVI）颜色空间来解耦亮度和颜色，并设计了颜色和强度解耦网络（CIDNet）以改善增强过程中的稳定性。结果显示，该方法可以减少增强图像中的颜色和亮度伪影。

    

    低光图像增强（Low-Light Image Enhancement，LLIE）任务旨在从受损的低光图像中恢复细节和视觉信息。大多数现有方法通过深度神经网络（DNNs）在sRGB和HSV颜色空间上学习低/正常光图像之间的映射函数。然而，增强涉及放大图像信号，并且将这些颜色空间应用于信噪比低的低光图像可能会引入灵敏度和不稳定性，从而导致增强图像中存在颜色伪影和亮度伪影。为了缓解这个问题，我们提出了一种新的可训练颜色空间，称为水平/垂直强度（HVI）。它不仅将亮度和颜色从RGB通道分离出来以减轻增强过程中的不稳定性，而且由于可训练参数，它还适应不同光照范围的低光图像。此外，我们设计了一种新颖的颜色和强度解耦网络（CIDNet），含有两个部分。

    Low-Light Image Enhancement (LLIE) task tends to restore the details and visual information from corrupted low-light images. Most existing methods learn the mapping function between low/normal-light images by Deep Neural Networks (DNNs) on sRGB and HSV color space. Nevertheless, enhancement involves amplifying image signals, and applying these color spaces to low-light images with a low signal-to-noise ratio can introduce sensitivity and instability into the enhancement process. Consequently, this results in the presence of color artifacts and brightness artifacts in the enhanced images. To alleviate this problem, we propose a novel trainable color space, named Horizontal/Vertical-Intensity (HVI). It not only decouples brightness and color from RGB channels to mitigate the instability during enhancement but also adapts to low-light images in different illumination ranges due to the trainable parameters. Further, we design a novel Color and Intensity Decoupling Network (CIDNet) with two
    
[^19]: 通过反向课程强化学习训练大型语言模型进行推理

    Training Large Language Models for Reasoning through Reverse Curriculum Reinforcement Learning

    [https://arxiv.org/abs/2402.05808](https://arxiv.org/abs/2402.05808)

    本文提出了一种通过反向课程强化学习训练大型语言模型进行推理的新方法，通过学习正确演示并建立逐步的课程，实现了结果监督和过程监督的优化。

    

    在本文中，我们提出了R$^3$：通过反向课程强化学习（RL）进行推理的学习方法，该方法只使用结果监督来实现大型语言模型的过程监督的好处。将RL应用于复杂推理的核心挑战是确定一系列行动，以获得正向奖励并提供适当的优化监督。结果监督为最终结果提供了稀疏奖励，而不识别错误位置，而过程监督提供了逐步奖励，但需要大量手动注释。R$^3$通过学习正确演示来克服这些限制。具体而言，R$^3$将推理的起始状态从演示的结束滑动到开始，从而在所有阶段都促进了更容易的模型探索。因此，R$^3$建立了一个逐步的课程，使结果监督能够提供阶段级信号并精确定位错误。

    In this paper, we propose R$^3$: Learning Reasoning through Reverse Curriculum Reinforcement Learning (RL), a novel method that employs only outcome supervision to achieve the benefits of process supervision for large language models. The core challenge in applying RL to complex reasoning is to identify a sequence of actions that result in positive rewards and provide appropriate supervision for optimization. Outcome supervision provides sparse rewards for final results without identifying error locations, whereas process supervision offers step-wise rewards but requires extensive manual annotation. R$^3$ overcomes these limitations by learning from correct demonstrations. Specifically, R$^3$ progressively slides the start state of reasoning from a demonstration's end to its beginning, facilitating easier model exploration at all stages. Thus, R$^3$ establishes a step-wise curriculum, allowing outcome supervision to offer step-level signals and precisely pinpoint errors. Using Llama2-7
    
[^20]: InkSight：通过学习阅读和书写实现离线到在线手写转换

    InkSight: Offline-to-Online Handwriting Conversion by Learning to Read and Write

    [https://arxiv.org/abs/2402.05804](https://arxiv.org/abs/2402.05804)

    InkSight是一个可以将离线手写转换为在线手写的系统，通过结合阅读和书写先验知识，在多样化的照片中有效地Derendering手写文本。

    

    数字笔记正在变得越来越受欢迎，提供了一种耐用、可编辑和易于索引的存储笔记的方式，即矢量化形式的数字墨水。然而，这种笔记方式与传统的纸笔记方式之间仍存在显著差距，而传统纸笔记方式仍受到绝大多数人的青睐。我们的工作InkSight旨在弥合这种差距，使实体笔记者能够轻松地将他们的作品（离线手写）转换为数字墨水（在线手写），这个过程我们称之为Derendering。之前关于此主题的研究集中在图像的几何属性上，导致了在训练领域之外的有限泛化能力。我们的方法结合了阅读和书写的先验知识，允许在缺乏大量配对样本的情况下训练模型，而这些配对样本很难获取。据我们所知，这是第一个有效地对具有多样化视觉特征和背景的任意照片中的手写文本进行Derendering的工作。

    Digital note-taking is gaining popularity, offering a durable, editable, and easily indexable way of storing notes in the vectorized form, known as digital ink. However, a substantial gap remains between this way of note-taking and traditional pen-and-paper note-taking, a practice still favored by a vast majority. Our work, InkSight, aims to bridge the gap by empowering physical note-takers to effortlessly convert their work (offline handwriting) to digital ink (online handwriting), a process we refer to as Derendering. Prior research on the topic has focused on the geometric properties of images, resulting in limited generalization beyond their training domains. Our approach combines reading and writing priors, allowing training a model in the absence of large amounts of paired samples, which are difficult to obtain. To our knowledge, this is the first work that effectively derenders handwritten text in arbitrary photos with diverse visual characteristics and backgrounds. Furthermore,
    
[^21]: 用于资源有限语言的音标丰富语料库构建

    Phonetically rich corpus construction for a low-resourced language

    [https://arxiv.org/abs/2402.05794](https://arxiv.org/abs/2402.05794)

    本文提出了一种用于资源有限语言巴西葡萄牙语的音标丰富语料库构建方法，包括收集文本数据集、基于三音分布的句子选择算法和根据声学-发音语音特征进行新的音素分类。

    

    语音技术依赖于捕捉说话人的声音变异性和获取全面的语言信息。文本提示和句子选择方法已经在文献中被提出，以组成适度的音标数据，被称为音标丰富的语料库。然而，对于资源有限的语言而言，它们仍然对声学建模不足。因此，本文提出了一种新的方法，并概述了为资源有限的巴西葡萄牙语创建具有广泛音标覆盖的语料库所需的方法论方面。我们的方法包括从文本数据集收集到基于三音分布的句子选择算法。此外，我们提出了一种新的音素分类方法，根据声学-发音语音特征，因为不同的三音的绝对数量或低概率三音并不能保证对每种可能的组合进行适当的表示。

    Speech technologies rely on capturing a speaker's voice variability while obtaining comprehensive language information. Textual prompts and sentence selection methods have been proposed in the literature to comprise such adequate phonetic data, referred to as a phonetically rich \textit{corpus}. However, they are still insufficient for acoustic modeling, especially critical for languages with limited resources. Hence, this paper proposes a novel approach and outlines the methodological aspects required to create a \textit{corpus} with broad phonetic coverage for a low-resourced language, Brazilian Portuguese. Our methodology includes text dataset collection up to a sentence selection algorithm based on triphone distribution. Furthermore, we propose a new phonemic classification according to acoustic-articulatory speech features since the absolute number of distinct triphones, or low-probability triphones, does not guarantee an adequate representation of every possible combination. Usin
    
[^22]: 人工智能作为游戏玩家：促进公平性

    Prompting Fairness: Artificial Intelligence as Game Players

    [https://arxiv.org/abs/2402.05786](https://arxiv.org/abs/2402.05786)

    人工智能作为游戏玩家能够展现出强烈的公平意识，取决于其对游戏伙伴的信任程度、游戏框架对于给予接受者的影响以及其可能存在厌恶不平等的情感。

    

    几十年来，社会科学家们一直在研究测量公平性的功利主义游戏，比如独裁者游戏。这些游戏不仅让我们了解了人类对公平性的看法，还揭示了公平性、利他主义和贪婪在何种条件下增加或减少。尽管这些游戏传统上关注人类，但人工智能的崛起使我们能够研究这些模型如何玩这些游戏。人工智能正在成为人际互动中的常态，研究这些模型在游戏中显示的公平性可以让我们对人工智能的决策过程有所了解。通过101轮的独裁者游戏，我得出结论：人工智能具有强烈的公平意识，这与其认为它的游戏伙伴是否值得信任有关；设置对游戏的框架在人工智能给予接受者的数量上有很大影响，而且有可能存在证据表明人工智能也像人类一样具有厌恶不平等的情感。

    Utilitarian games such as dictator games to measure fairness have been studied in the social sciences for decades. These games have given us insight into not only how humans view fairness but also in what conditions the frequency of fairness, altruism and greed increase or decrease. While these games have traditionally been focused on humans, the rise of AI gives us the ability to study how these models play these games. AI is becoming a constant in human interaction and examining how these models portray fairness in game play can give us some insight into how AI makes decisions. Over 101 rounds of the dictator game, I conclude that AI has a strong sense of fairness that is dependant of it it deems the person it is playing with as trustworthy, framing has a strong effect on how much AI gives a recipient when designated the trustee, and there may be evidence that AI experiences inequality aversion just as humans.
    
[^23]: Transformer语言模型在算法学习上的限制

    Limits of Transformer Language Models on Algorithmic Learning

    [https://arxiv.org/abs/2402.05785](https://arxiv.org/abs/2402.05785)

    Transformer语言模型在学习离散算法方面的组合能力非常有限，比重新学习所有子任务对于新的算法组合的效果更差，而且梯度下降在记忆前馈模型上的效率非常低。

    

    我们分析了Transformer语言模型在学习离散算法方面的能力。为此，我们引入了两个要求组合多个离散子任务的新任务。我们通过从头开始训练LLaMA模型和在GPT-4和Gemini上提示来衡量学习学习原语的组合。我们观察到，目前最先进的Transformer语言模型的组合能力非常有限，并且在样本规模方面比为新的算法组合重新学习所有子任务效果更差。我们还提出了一个复杂性理论的定理，证明了记忆前馈模型上的梯度下降可以指数级地浪费数据。

    We analyze the capabilities of Transformer language models on learning discrete algorithms. To this end, we introduce two new tasks demanding the composition of several discrete sub-tasks. On both training LLaMA models from scratch and prompting on GPT-4 and Gemini we measure learning compositions of learned primitives. We observe that the compositional capabilities of state-of-the-art Transformer language models are very limited and sample-wise scale worse than relearning all sub-tasks for a new algorithmic composition. We also present a theorem in complexity theory, showing that gradient descent on memorizing feedforward models can be exponentially data inefficient.
    
[^24]: 分析对手塑造的样本复杂性

    Analysing the Sample Complexity of Opponent Shaping

    [https://arxiv.org/abs/2402.05782](https://arxiv.org/abs/2402.05782)

    本文研究了对手塑造的样本复杂性，并提出了一种适合理论分析的表格化版本R-FOS。

    

    在一般和博弈中，学习通常会导致集体性的次优结果。对此进行改进，对手塑造（OS）方法积极引导其他智能体的学习过程，经验性地提高了个体和群体在许多情景下的表现。早期的OS方法使用高阶导数来塑造合作玩家的学习，这使得它们不适用于塑造多个学习步骤。后续的工作，即无模型对手塑造（M-FOS），通过将OS问题重新定义为元博弈来解决这些问题。与早期的OS方法相比，对于M-FOS框架的理论理解还很少。为M-FOS提供理论保证是困难的，因为A）元强化学习的理论样本复杂性界限的文献很少 B）M-FOS在连续状态和动作空间中运作，所以理论分析具有挑战性。在这项工作中，我们提出了R-FOS，这是M-FOS的表格化版本，更适合进行理论分析。R-FOS离散化了

    Learning in general-sum games often yields collectively sub-optimal results. Addressing this, opponent shaping (OS) methods actively guide the learning processes of other agents, empirically leading to improved individual and group performances in many settings. Early OS methods use higher-order derivatives to shape the learning of co-players, making them unsuitable for shaping multiple learning steps. Follow-up work, Model-free Opponent Shaping (M-FOS), addresses these by reframing the OS problem as a meta-game. In contrast to early OS methods, there is little theoretical understanding of the M-FOS framework. Providing theoretical guarantees for M-FOS is hard because A) there is little literature on theoretical sample complexity bounds for meta-reinforcement learning B) M-FOS operates in continuous state and action spaces, so theoretical analysis is challenging. In this work, we present R-FOS, a tabular version of M-FOS that is more suitable for theoretical analysis. R-FOS discretises
    
[^25]: 稳定的自主流匹配

    Stable Autonomous Flow Matching

    [https://arxiv.org/abs/2402.05774](https://arxiv.org/abs/2402.05774)

    本文通过应用随机稳定性工具于时间独立系统的流匹配模型，研究了物理稳定数据点的深度生成模型，并与控制理论原理进行了联系。

    

    在表示物理稳定状态的数据样本中，通常假设数据点代表能量景观的局部极小值。在控制论中，众所周知，能量可以作为有效的李亚普诺夫函数。尽管如此，控制论与生成模型之间的联系在文献中很少，尽管有几个具有物理稳定数据点的机器学习应用。在本文中，我们关注这样的数据和一种最近的深度生成模型类别，称为流匹配。我们应用随机稳定性工具于时间独立系统的流匹配模型。通过这样做，我们表征了适应这种处理的流匹配模型的空间，以及与其他控制理论原理的联系。我们在两个示例上展示了我们的理论结果。

    In contexts where data samples represent a physically stable state, it is often assumed that the data points represent the local minima of an energy landscape. In control theory, it is well-known that energy can serve as an effective Lyapunov function. Despite this, connections between control theory and generative models in the literature are sparse, even though there are several machine learning applications with physically stable data points. In this paper, we focus on such data and a recent class of deep generative models called flow matching. We apply tools of stochastic stability for time-independent systems to flow matching models. In doing so, we characterize the space of flow matching models that are amenable to this treatment, as well as draw connections to other control theory principles. We demonstrate our theoretical results on two examples.
    
[^26]: 广义偏好优化：离线对齐的统一方法

    Generalized Preference Optimization: A Unified Approach to Offline Alignment

    [https://arxiv.org/abs/2402.05749](https://arxiv.org/abs/2402.05749)

    广义偏好优化（GPO）是一种离线损失函数，通过参数化一类凸函数来实现统一的偏好优化视角，并提供了新的算法工具和实证洞见。

    

    离线偏好优化允许直接从离线数据中对大型模型进行微调，并在最近的对齐实践中证明了其有效性。我们提出了广义偏好优化（GPO），这是一类通过一般的凸函数参数化的离线损失函数。GPO提供了对偏好优化的统一视角，涵盖了现有算法（DPO、IPO和SLiC）作为特殊情况，同时自然引入了新的变体。GPO框架还揭示了离线算法如何通过定义损失的凸函数来实施正则化。我们的分析和实验揭示了离线正则化和规范的RLHF公式所意图的KL散度正则化之间的联系和微妙差异。总的来说，我们的结果为对齐实践者提供了新的算法工具和实证洞见。

    Offline preference optimization allows fine-tuning large models directly from offline data, and has proved effective in recent alignment practices. We propose generalized preference optimization (GPO), a family of offline losses parameterized by a general class of convex functions. GPO enables a unified view over preference optimization, encompassing existing algorithms such as DPO, IPO and SLiC as special cases, while naturally introducing new variants. The GPO framework also sheds light on how offline algorithms enforce regularization, through the design of the convex function that defines the loss. Our analysis and experiments reveal the connections and subtle differences between the offline regularization and the KL divergence regularization intended by the canonical RLHF formulation. In all, our results present new algorithmic toolkits and empirical insights to alignment practitioners.
    
[^27]: Jacquard V2: 使用人机交互数据纠错方法改进数据集

    Jacquard V2: Refining Datasets using the Human In the Loop Data Correction Method

    [https://arxiv.org/abs/2402.05747](https://arxiv.org/abs/2402.05747)

    本论文提出了一种使用人机交互数据纠错方法来改进数据集质量的方案，以提升视觉识别准确性和优化视觉机器人抓取的性能。

    

    在工业自动化快速发展的背景下，基于视觉的机器人抓取在其中扮演着越来越关键的角色。为了提升视觉识别准确性，利用大规模数据集对模型进行训练以获取与处理各种物体相关的隐式知识至关重要。从头开始创建数据集是一项耗时且劳动密集的过程。此外，现有数据集常常由于为了快速标注而产生错误，因此改善这些数据集是一个重要的研究挑战。因此，在流行的Jacquard Grasp中，已经确定了一些在抓取边界框注释中的问题。我们提出利用一种人机交互的方法来提高数据集质量。这种方法依赖于骨干深度学习网络来预测机器人抓取的物体位置和方向。与Intersection over Union（IOU）值低于0.2的预测经过人工操作员评估。

    In the context of rapid advancements in industrial automation, vision-based robotic grasping plays an increasingly crucial role. In order to enhance visual recognition accuracy, the utilization of large-scale datasets is imperative for training models to acquire implicit knowledge related to the handling of various objects. Creating datasets from scratch is a time and labor-intensive process. Moreover, existing datasets often contain errors due to automated annotations aimed at expediency, making the improvement of these datasets a substantial research challenge. Consequently, several issues have been identified in the annotation of grasp bounding boxes within the popular Jacquard Grasp. We propose utilizing a Human-In-The-Loop(HIL) method to enhance dataset quality. This approach relies on backbone deep learning networks to predict object positions and orientations for robotic grasping. Predictions with Intersection over Union (IOU) values below 0.2 undergo an assessment by human oper
    
[^28]: 基于基础模型的真实世界机器人应用：一项综述

    Real-World Robot Applications of Foundation Models: A Review

    [https://arxiv.org/abs/2402.05741](https://arxiv.org/abs/2402.05741)

    本文综述了基础模型在真实世界机器人中的应用，重点是替换现有机器人系统中的特定组件。这些基础模型在输入输出关系、感知、运动规划和控制等方面扮演了重要角色。未来的挑战和对实际机器人应用的影响也被讨论到。

    

    最近，基于大规模语言模型（LLMs）和视觉语言模型（VLMs）等基础模型的发展，通过对大量数据的训练，为不同任务和模态的灵活应用提供了便利。它们的影响涵盖了包括医疗、教育和机器人等各个领域。本文概述了基础模型在真实世界机器人中的实际应用情况，重点是替换现有机器人系统中的特定组件。总结涵盖了基础模型中的输入输出关系以及它们在机器人领域中的感知、运动规划和控制等方面的作用。本文还讨论了未来挑战和对实际机器人应用的影响。

    Recent developments in foundation models, like Large Language Models (LLMs) and Vision-Language Models (VLMs), trained on extensive data, facilitate flexible application across different tasks and modalities. Their impact spans various fields, including healthcare, education, and robotics. This paper provides an overview of the practical application of foundation models in real-world robotics, with a primary emphasis on the replacement of specific components within existing robot systems. The summary encompasses the perspective of input-output relationships in foundation models, as well as their role in perception, motion planning, and control within the field of robotics. This paper concludes with a discussion of future challenges and implications for practical robot applications.
    
[^29]: 基于模型的强化学习在平均场博弈中并不比单个智能体强化学习更加困难

    Model-Based RL for Mean-Field Games is not Statistically Harder than Single-Agent RL

    [https://arxiv.org/abs/2402.05724](https://arxiv.org/abs/2402.05724)

    本研究研究了在平均场博弈中基于模型的强化学习的样本复杂度，提出了部分基于模型的Eluder维度（P-MBED）概念来衡量模型类复杂度，并且证明在基本假设下，学习平均场博弈的纳什均衡并不比解决对数个单个智能体强化学习问题更具统计挑战性。

    

    我们研究了在平均场博弈中基于模型的函数逼近下强化学习样本复杂度，该方法需要策略性探索以找到纳什均衡策略。我们引入了部分基于模型的Eluder维度（P-MBED），这是一种更有效的概念来描述模型类复杂度。值得注意的是，P-MBED可以衡量从给定的平均场模型类转换而来的单个智能体模型类的复杂度，并且潜在上可能比\citet{huang2023statistical}提出的MBED指数级低。我们提出了一种模型消除算法，具有新颖的探索策略，并建立了与P-MBED相关的样本复杂度结果，这些结果表明，在基本可实现性和Lipschitz连续性假设下，学习平均场博弈的纳什均衡并不比解决对数个单个智能体强化学习问题更具统计挑战性。我们进一步将我们的结果推广到多类型平均场博弈。

    We study the sample complexity of reinforcement learning (RL) in Mean-Field Games (MFGs) with model-based function approximation that requires strategic exploration to find a Nash Equilibrium policy. We introduce the Partial Model-Based Eluder Dimension (P-MBED), a more effective notion to characterize the model class complexity. Notably, P-MBED measures the complexity of the single-agent model class converted from the given mean-field model class, and potentially, can be exponentially lower than the MBED proposed by \citet{huang2023statistical}. We contribute a model elimination algorithm featuring a novel exploration strategy and establish sample complexity results polynomial w.r.t.~P-MBED. Crucially, our results reveal that, under the basic realizability and Lipschitz continuity assumptions, \emph{learning Nash Equilibrium in MFGs is no more statistically challenging than solving a logarithmic number of single-agent RL problems}. We further extend our results to Multi-Type MFGs, gen
    
[^30]: 明明就在眼前：对弱势患者群体进行不可检测的对抗性偏见攻击

    Hidden in Plain Sight: Undetectable Adversarial Bias Attacks on Vulnerable Patient Populations

    [https://arxiv.org/abs/2402.05713](https://arxiv.org/abs/2402.05713)

    该研究发现在医学影像中，可以通过针对特定人群的标签污染攻击来破坏深度学习模型的性能，并引入对抗性的诊断不足偏见。研究结果还表明，人群在训练数据中的表示对于不可检测的对抗性偏见攻击的脆弱性直接相关。

    

    人工智能在放射学中的广泛应用揭示了深度学习模型加剧对弱势患者群体的临床偏见的风险。虽然先前的文献主要关注训练的深度学习模型所展示的偏见的量化，但针对特定人口群体的对抗性偏见攻击以及其在临床环境中的影响仍然是一个未被充分研究的医学影像领域。在这项工作中，我们证明了针对人口统计学标签的毒化攻击可以向深度学习模型引入对抗性的诊断不足偏见，并在不影响整体模型性能的情况下降低对被低估群体的性能。此外，我们的结果在多个性能指标和人口群体（如性别、年龄以及其交叉子群）上表明，群体对于不可检测的对抗性偏见攻击的脆弱性与其在模型的训练数据中的表征直接相关。

    The proliferation of artificial intelligence (AI) in radiology has shed light on the risk of deep learning (DL) models exacerbating clinical biases towards vulnerable patient populations. While prior literature has focused on quantifying biases exhibited by trained DL models, demographically targeted adversarial bias attacks on DL models and its implication in the clinical environment remains an underexplored field of research in medical imaging. In this work, we demonstrate that demographically targeted label poisoning attacks can introduce adversarial underdiagnosis bias in DL models and degrade performance on underrepresented groups without impacting overall model performance. Moreover, our results across multiple performance metrics and demographic groups like sex, age, and their intersectional subgroups indicate that a group's vulnerability to undetectable adversarial bias attacks is directly correlated with its representation in the model's training data.
    
[^31]: DiffSpeaker: 使用扩散变换器进行语音驱动的三维面部动画

    DiffSpeaker: Speech-Driven 3D Facial Animation with Diffusion Transformer

    [https://arxiv.org/abs/2402.05712](https://arxiv.org/abs/2402.05712)

    DiffSpeaker是一种使用扩散变换器和自注意力模块的语音驱动3D面部动画网络，通过解决配对音频-4D数据的缺乏问题，实现了准确的唇部同步和非语言面部表达。

    

    语音驱动的三维面部动画对于许多多媒体应用非常重要。最近的研究表明，使用扩散模型或变换器架构都在这个任务中表现出了潜力。然而，它们的简单聚合并没有带来改进的性能。我们怀疑这是由于缺乏配对的音频-4D数据，这对于变换器在扩散框架内有效地作为去噪器进行工作非常关键。为了解决这个问题，我们提出了DiffSpeaker，这是一种基于变换器的网络，配备了新颖的有偏条件注意模块。这些模块作为传统变换器中自注意力/交叉注意力的替代品，融入了经过深思熟虑的偏见，以使注意机制集中在既与任务相关又与扩散相关的条件上。我们还在扩散范式中探讨了精确的唇部同步和非语言面部表情之间的权衡。实验证明我们的模型不仅实现了准确的唇部同步，而且实现了有效的非语言面部表达。

    Speech-driven 3D facial animation is important for many multimedia applications. Recent work has shown promise in using either Diffusion models or Transformer architectures for this task. However, their mere aggregation does not lead to improved performance. We suspect this is due to a shortage of paired audio-4D data, which is crucial for the Transformer to effectively perform as a denoiser within the Diffusion framework. To tackle this issue, we present DiffSpeaker, a Transformer-based network equipped with novel biased conditional attention modules. These modules serve as substitutes for the traditional self/cross-attention in standard Transformers, incorporating thoughtfully designed biases that steer the attention mechanisms to concentrate on both the relevant task-specific and diffusion-related conditions. We also explore the trade-off between accurate lip synchronization and non-verbal facial expressions within the Diffusion paradigm. Experiments show our model not only achieves
    
[^32]: 离线风险敏感强化学习结合部分可观察性，以提高人-机组合的表现

    Offline Risk-sensitive RL with Partial Observability to Enhance Performance in Human-Robot Teaming

    [https://arxiv.org/abs/2402.05703](https://arxiv.org/abs/2402.05703)

    本研究针对人-机组合中的性能提出了离线风险敏感强化学习算法，通过部分可观察性的建模，解决了多样化人类参与者的挑战。

    

    将生理计算整合到混合倡议的人机交互系统中，通过将实时特征作为人类状态观测融入决策系统，可以在自主任务分配中提供有价值的优势。这种方法可以通过智能地分配任务来减轻人类操作员的认知负荷。然而，适应具有不同生理和行为测量结果的多样化人类参与者构成了一个重大挑战。为了解决这个问题，必须利用概率框架，考虑到人类状态的固有不确定性和部分可观察性。最近的研究建议使用离线强化学习（ORL）方法从先前收集的经验数据集中学习一个部分可观测马尔可夫决策过程（POMDP）模型。在本研究中，我们不仅强调部分可观察性表示的潜力，

    The integration of physiological computing into mixed-initiative human-robot interaction systems offers valuable advantages in autonomous task allocation by incorporating real-time features as human state observations into the decision-making system. This approach may alleviate the cognitive load on human operators by intelligently allocating mission tasks between agents. Nevertheless, accommodating a diverse pool of human participants with varying physiological and behavioral measurements presents a substantial challenge. To address this, resorting to a probabilistic framework becomes necessary, given the inherent uncertainty and partial observability on the human's state. Recent research suggests to learn a Partially Observable Markov Decision Process (POMDP) model from a data set of previously collected experiences that can be solved using Offline Reinforcement Learning (ORL) methods. In the present work, we not only highlight the potential of partially observable representations an
    
[^33]: 通过基于垄断对话的社交场景模拟实现大型语言模型的自对齐

    Self-Alignment of Large Language Models via Monopolylogue-based Social Scene Simulation

    [https://arxiv.org/abs/2402.05699](https://arxiv.org/abs/2402.05699)

    本文提出了一个通过社交场景模拟来自对齐大型语言模型的方法，以减轻其被滥用造成的潜在不良影响。通过一个名为MATRIX的虚拟排练空间，LLM可以在回答查询前考虑社交后果，并通过MATRIX-simulated数据的微调，保持对人类价值的遵从和推理速度的平衡。实验证明，在温和假设下，带有MATRIX的LLM胜过了宪法AI。

    

    将大型语言模型(LLMs)与人类价值对齐，以减轻其被滥用造成的潜在不良影响，具有重要意义。本文借鉴社会学的见解，即认识到所有各方的关切是塑造人类价值观的关键因素，提出了一种自对齐LLMs的新方向：社交场景模拟。为此，我们提出了一个名为MATRIX的创新社交场景模拟器，它可以模拟用户输入查询周围的现实场景，使LLM在回答前能够考虑社交后果。MATRIX类似于一个“垄断对话”下的虚拟排练空间，LLM在其中扮演与查询相关的多个角色并进行自我实践。为了引入这种对齐能力，我们使用MATRIX模拟数据对LLM进行微调，确保其在不影响推理速度的情况下符合人类价值观。理论上，我们证明了在温和假设下，带有MATRIX的LLM胜过了宪法AI。最后，大量实验证实了我们的方法在多个任务上都取得了最佳性能。

    Aligning large language models (LLMs) with human values is imperative to mitigate potential adverse effects resulting from their misuse. Drawing from the sociological insight that acknowledging all parties' concerns is a key factor in shaping human values, this paper proposes a novel direction to align LLMs by themselves: social scene simulation. To achieve this, we present MATRIX, a novel social scene simulator that emulates realistic scenes around a user's input query, enabling the LLM to take social consequences into account before responding. MATRIX serves as a virtual rehearsal space, akin to a Monopolylogue, where the LLM performs diverse roles related to the query and practice by itself. To inject this alignment, we fine-tune the LLM with MATRIX-simulated data, ensuring adherence to human values without compromising inference speed. We theoretically show that the LLM with MATRIX outperforms Constitutional AI under mild assumptions. Finally, extensive experiments validate that ou
    
[^34]: 通过离散化和特征选择的可解释性表格数据分类器

    Interpretable classifiers for tabular data via discretization and feature selection

    [https://arxiv.org/abs/2402.05680](https://arxiv.org/abs/2402.05680)

    通过离散化和特征选择的方法，我们提出了一种从表格数据中计算出准确又易解释的分类器的方法。在实验证明该方法在准确度上与随机森林和XGBoost等现有方法相当，并且在多种情况下实际上超过了参考结果。

    

    我们引入了一种从表格数据中计算出具有解释性且准确的分类器的方法。所得到的分类器是简短的DNF公式，通过将原始数据离散化为布尔形式，然后使用特征选择结合非常快速的算法来产生最佳的布尔分类器。我们通过14个实验来演示该方法，得到的结果的准确度主要与随机森林、XGBoost以及文献中相同数据集的现有结果相似。在多种情况下，我们的方法实际上在准确度方面优于参考结果，尽管我们研究的主要目标是我们的分类器的即时可解释性。我们还证明了一个关于从现实数据中获得的分类器与来自数据背景分布的最佳分类器相对应的概率的新结果。

    We introduce a method for computing immediately human interpretable yet accurate classifiers from tabular data. The classifiers obtained are short DNF-formulas, computed via first discretizing the original data to Boolean form and then using feature selection coupled with a very fast algorithm for producing the best possible Boolean classifier for the setting. We demonstrate the approach via 14 experiments, obtaining results with accuracies mainly similar to ones obtained via random forests, XGBoost, and existing results for the same datasets in the literature. In several cases, our approach in fact outperforms the reference results in relation to accuracy, even though the main objective of our study is the immediate interpretability of our classifiers. We also prove a new result on the probability that the classifier we obtain from real-life data corresponds to the ideally best classifier with respect to the background distribution the data comes from.
    
[^35]: 对LLMs的越狱攻击的综合评估

    Comprehensive Assessment of Jailbreak Attacks Against LLMs

    [https://arxiv.org/abs/2402.05668](https://arxiv.org/abs/2402.05668)

    对大型语言模型（LLMs）的越狱攻击进行了全面的评估，揭示了一种绕过安全措施的不稳定漏洞。本研究是首次对多种越狱攻击方法进行大规模测量，实验证明优化的越狱提示能够持续达到最高的攻击成功率。

    

    对大型语言模型（LLMs）的滥用引起了广泛关注。为了解决这个问题，已经采取了安全措施以确保LLMs符合社会伦理。然而，最近的研究发现了一种绕过LLMs安全措施的不稳定漏洞，被称为越狱攻击。通过应用技术，如角色扮演场景、对抗性样本或对安全目标的微妙破坏作为提示，LLMs可以产生不适当甚至有害的回应。虽然研究人员已经研究了几种越狱攻击的类别，但他们都是孤立地进行的。为了填补这个空白，我们提出了对各种越狱攻击方法的首次大规模测量。我们集中在来自四个类别的13种尖端越狱方法、16种违规类别的160个问题以及六种流行的LLMs上。我们广泛的实验结果表明，优化的越狱提示始终能够达到最高的攻击成功率，并表现出...

    Misuse of the Large Language Models (LLMs) has raised widespread concern. To address this issue, safeguards have been taken to ensure that LLMs align with social ethics. However, recent findings have revealed an unsettling vulnerability bypassing the safeguards of LLMs, known as jailbreak attacks. By applying techniques, such as employing role-playing scenarios, adversarial examples, or subtle subversion of safety objectives as a prompt, LLMs can produce an inappropriate or even harmful response. While researchers have studied several categories of jailbreak attacks, they have done so in isolation. To fill this gap, we present the first large-scale measurement of various jailbreak attack methods. We concentrate on 13 cutting-edge jailbreak methods from four categories, 160 questions from 16 violation categories, and six popular LLMs. Our extensive experimental results demonstrate that the optimized jailbreak prompts consistently achieve the highest attack success rates, as well as exhi
    
[^36]: 实时瓶颈和激波预测的中尺度交通预测

    Mesoscale Traffic Forecasting for Real-Time Bottleneck and Shockwave Prediction

    [https://arxiv.org/abs/2402.05663](https://arxiv.org/abs/2402.05663)

    该论文介绍了一种在实时中尺度交通预测中具有最先进效果的深度预测方法SA-LSTM，通过将自注意力与长短期记忆结合，实现了对多步预测的改进，并在短期和长期预测之间取得了平衡。

    

    准确的实时交通状态预测在交通控制研究中起着关键作用。特别是CIRCLES联合项目需要预测技术来减轻数据源延迟的影响。在MegaVanderTest实验取得成功之后，本文旨在克服当前系统限制，开发更适合的方法来改善下一轮实验的实时交通状态估计。在本文中，我们介绍了SA-LSTM，这是一种深度预测方法，将自注意力（SA）与长短期记忆（LSTM）在空间维度上结合，可以在实时中尺度交通预测中获得最先进的结果。我们将这种方法扩展到多步预测，使用n-step SA-LSTM，在短期和长期预测之间的平衡中优于传统的多步预测方法，同时实时运行。

    Accurate real-time traffic state forecasting plays a pivotal role in traffic control research. In particular, the CIRCLES consortium project necessitates predictive techniques to mitigate the impact of data source delays. After the success of the MegaVanderTest experiment, this paper aims at overcoming the current system limitations and develop a more suited approach to improve the real-time traffic state estimation for the next iterations of the experiment. In this paper, we introduce the SA-LSTM, a deep forecasting method integrating Self-Attention (SA) on the spatial dimension with Long Short-Term Memory (LSTM) yielding state-of-the-art results in real-time mesoscale traffic forecasting. We extend this approach to multi-step forecasting with the n-step SA-LSTM, which outperforms traditional multi-step forecasting methods in the trade-off between short-term and long-term predictions, all while operating in real-time.
    
[^37]: 重新思考无监督图领域适应中的传播问题

    Rethinking Propagation for Unsupervised Graph Domain Adaptation

    [https://arxiv.org/abs/2402.05660](https://arxiv.org/abs/2402.05660)

    通过重新评估GNN在图领域适应中的作用，本论文揭示了传播过程对于适应不同图领域至关重要，并通过理论分析提供了多层GNN的泛化界限的证明。

    

    无监督图领域适应（UGDA）旨在将标记源图的知识传输到未标记的目标图中，以解决图领域之间的分布偏移问题。以往的研究主要集中在通过图神经网络（GNN）学习的表示空间中对源图和目标图的数据进行对齐。然而，GNN的内在泛化能力很大程度上被忽视了。在经验分析的基础上，我们重新评估了GNN在图领域适应中的作用，揭示了传播过程在GNN中适应不同图领域中的关键作用。我们对UGDA进行了全面的理论分析，并推导出多层GNN的泛化界限。通过将GNN Lipschitz应用于k层GNNs，我们证明通过在源图中删除传播层并在目标图中堆叠多个传播层，可以使目标风险界限更紧密。基于实证和理论分析结果

    Unsupervised Graph Domain Adaptation (UGDA) aims to transfer knowledge from a labelled source graph to an unlabelled target graph in order to address the distribution shifts between graph domains. Previous works have primarily focused on aligning data from the source and target graph in the representation space learned by graph neural networks (GNNs). However, the inherent generalization capability of GNNs has been largely overlooked. Motivated by our empirical analysis, we reevaluate the role of GNNs in graph domain adaptation and uncover the pivotal role of the propagation process in GNNs for adapting to different graph domains. We provide a comprehensive theoretical analysis of UGDA and derive a generalization bound for multi-layer GNNs. By formulating GNN Lipschitz for k-layer GNNs, we show that the target risk bound can be tighter by removing propagation layers in source graph and stacking multiple propagation layers in target graph. Based on the empirical and theoretical analysis
    
[^38]: 《岩石编码，不是开发-一个以人为中心的LLM在软件工程任务中的实验评估》

    Rocks Coding, Not Development--A Human-Centric, Experimental Evaluation of LLM-Supported SE Tasks

    [https://arxiv.org/abs/2402.05650](https://arxiv.org/abs/2402.05650)

    这项研究提出了一种自监督学习框架，用于训练神经网络从未标记的多感官数据中学习丰富而有意义的3D场景表示。通过利用不同感觉模态之间的时间一致性和几何对齐，我们的框架能够学习到强大而准确的表示。我们将我们的方法应用于各种3D感知任务，并与监督基线进行了比较，展示了竞争性的性能。此外，我们还展示了我们学到的表示在不同的传感器设置下具有很好的泛化能力，进一步突显了我们的自监督学习方法的有效性和多功能性。

    

    最近，基于大型语言模型（LLM）的生成型AI因其在多个领域中令人印象深刻的高质量表现而备受关注，特别是在ChatGPT发布之后。许多人认为它们有潜力在软件开发中执行通用问题解决，并取代人类软件开发人员。然而，目前没有对这些LLM技术在完成软件开发任务方面的能力进行深入调查。在一项有109名参与者的受控 2x2 受试者间实验中，我们研究了与ChatGPT合作在编码任务和典型软件开发任务中的效用程度以及人们如何使用ChatGPT。我们发现，尽管ChatGPT在解决简单的编码问题方面表现出色，但它在支持典型的软件开发任务方面的表现并不理想。我们还观察了参与者与ChatGPT之间的互动，并找到了相互关系。

    Recently, large language models (LLM) based generative AI has been gaining momentum for their impressive high-quality performances in multiple domains, particularly after the release of the ChatGPT. Many believe that they have the potential to perform general-purpose problem-solving in software development and replace human software developers. Nevertheless, there are in a lack of serious investigation into the capability of these LLM techniques in fulfilling software development tasks. In a controlled 2 $\times$ 2 between-subject experiment with 109 participants, we examined whether and to what degree working with ChatGPT was helpful in the coding task and typical software development task and how people work with ChatGPT. We found that while ChatGPT performed well in solving simple coding problems, its performance in supporting typical software development tasks was not that good. We also observed the interactions between participants and ChatGPT and found the relations between the i
    
[^39]: 通过并行观测预测改进基于令牌的世界模型

    Improving Token-Based World Models with Parallel Observation Prediction

    [https://arxiv.org/abs/2402.05643](https://arxiv.org/abs/2402.05643)

    该论文提出了一种改进基于令牌的世界模型的方法，通过引入并行观测预测机制（POP）来解决想象过程中出现的瓶颈问题。通过在一个新型TBWM代理中应用POP，想象速度提高了15.4倍，在不到12小时的训练时间内在Atari 100K基准测试中取得了超人类的表现。

    

    受到将Transformer应用于离散符号序列的成功启发，最近提出了基于令牌的世界模型（TBWMs）作为高效样本方法。在TBWMs中，世界模型将代理经验作为一种类似语言的令牌序列进行消耗，其中每个观测构成一个子序列。然而，在想象过程中，通过令牌逐个生成下一个观测的串行方式导致了严重的瓶颈问题，导致训练时间长、GPU利用率低和表示能力有限。为了解决这个瓶颈问题，我们设计了一种新颖的并行观测预测（POP）机制。POP通过一种针对我们的强化学习环境设计的新型前向模式来扩充了保持网络（RetNet）。我们将POP集成到一种名为REM（保持环境模型）的新型TBWM代理中，展示了比以前的TBWMs快15.4倍的想象能力。REM在Atari 100K基准测试的26个游戏中的12个游戏中达到超越人类水平的性能，并且在不到12小时的训练时间内完成训练。

    Motivated by the success of Transformers when applied to sequences of discrete symbols, token-based world models (TBWMs) were recently proposed as sample-efficient methods. In TBWMs, the world model consumes agent experience as a language-like sequence of tokens, where each observation constitutes a sub-sequence. However, during imagination, the sequential token-by-token generation of next observations results in a severe bottleneck, leading to long training times, poor GPU utilization, and limited representations. To resolve this bottleneck, we devise a novel Parallel Observation Prediction (POP) mechanism. POP augments a Retentive Network (RetNet) with a novel forward mode tailored to our reinforcement learning setting. We incorporate POP in a novel TBWM agent named REM (Retentive Environment Model), showcasing a 15.4x faster imagination compared to prior TBWMs. REM attains superhuman performance on 12 out of 26 games of the Atari 100K benchmark, while training in less than 12 hours.
    
[^40]: AI工具对澳新银行工程的影响——关于GitHub Copilot在企业环境中的实证研究

    The Impact of AI Tool on Engineering at ANZ Bank An Emperical Study on GitHub Copilot within Coporate Environment

    [https://arxiv.org/abs/2402.05636](https://arxiv.org/abs/2402.05636)

    本研究探讨了在澳新银行这样一个大型组织中，将AI工具GitHub Copilot整合到软件工程实践中的实证研究。通过在受控环境中进行的实验，评估了该工具在实际工程任务中的有效性，并发现在大规模采用后对生产力的改善是显著的。

    

    人工智能，特别是大型语言模型（LLMs），的日益流行已经对包括软件工程在内的各个领域产生了重大影响。本研究探讨了在大型组织中将AI工具整合到软件工程实践中的情况。我们的焦点是澳新银行，该银行拥有超过5000名工程师，涵盖软件开发生命周期的各个方面。本文详细介绍了在受控环境中使用一款著名的AI工具GitHub Copilot进行实验，以评估其在实际工程任务中的有效性。此外，本文分享了在大规模采用GitHub Copilot后观察到的生产力改善的初步发现，约有1000名工程师在使用该工具。澳新银行对GitHub Copilot进行了为期六周的实验，其中包括两周的准备和四周的主动测试。该研究评估了参与者的情绪以及该工具对生产力、代码质量和安全性的影响。最初，参与者使用GitHub Copilot进行迭代和改进，同时记录其反馈和体验。

    The increasing popularity of AI, particularly Large Language Models (LLMs), has significantly impacted various domains, including Software Engineering. This study explores the integration of AI tools in software engineering practices within a large organization. We focus on ANZ Bank, which employs over 5000 engineers covering all aspects of the software development life cycle. This paper details an experiment conducted using GitHub Copilot, a notable AI tool, within a controlled environment to evaluate its effectiveness in real-world engineering tasks. Additionally, this paper shares initial findings on the productivity improvements observed after GitHub Copilot was adopted on a large scale, with about 1000 engineers using it. ANZ Bank's six-week experiment with GitHub Copilot included two weeks of preparation and four weeks of active testing. The study evaluated participant sentiment and the tool's impact on productivity, code quality, and security. Initially, participants used GitHub
    
[^41]: 旋转特征中的绑定动力学

    Binding Dynamics in Rotating Features

    [https://arxiv.org/abs/2402.05627](https://arxiv.org/abs/2402.05627)

    本论文研究了旋转特征中的绑定动力学问题，并提出了一种新的“余弦绑定”机制，以替代传统的“$\chi$-binding”机制。通过显式计算特征之间的对齐和相应的权重调整，这一新机制能够达到与传统机制相同的性能，与自注意力和生物神经学有关。

    

    在人类认知中，绑定问题描述了大脑如何灵活地将各种信息整合成具有连贯性的对象表示的未解之谜。类似地，在机器学习中，人们追求通过无监督学习以学习以对象为中心的表示来实现强大的泛化和推理能力的模型。借鉴神经科学理论，旋转特征通过引入矢量特征来学习这种表示，矢量特征的大小包含对象特征，方向包含对象关联。在架构的每个层中都嵌入了“$\chi$-binding”机制，已被证明至关重要，但了解有限。在本文中，我们提出一种替代的“余弦绑定”机制，该机制显式计算特征之间的对齐并相应地调整权重，并且我们证明它可以达到相同的性能。这使我们能够与自注意力和生物神经学产生直接联系。

    In human cognition, the binding problem describes the open question of how the brain flexibly integrates diverse information into cohesive object representations. Analogously, in machine learning, there is a pursuit for models capable of strong generalization and reasoning by learning object-centric representations in an unsupervised manner. Drawing from neuroscientific theories, Rotating Features learn such representations by introducing vector-valued features that encapsulate object characteristics in their magnitudes and object affiliation in their orientations. The "$\chi$-binding" mechanism, embedded in every layer of the architecture, has been shown to be crucial, but remains poorly understood. In this paper, we propose an alternative "cosine binding" mechanism, which explicitly computes the alignment between features and adjusts weights accordingly, and we show that it achieves equivalent performance. This allows us to draw direct connections to self-attention and biological neu
    
[^42]: 针对仇恨、辱骂和亵渎检测的高效模型

    Efficient Models for the Detection of Hate, Abuse and Profanity

    [https://arxiv.org/abs/2402.05624](https://arxiv.org/abs/2402.05624)

    这篇论文提出了针对仇恨、辱骂和亵渎检测的高效模型，因为大型语言模型在训练过程中可能学习到这些负面内容并生成不合适的文本。

    

    大型语言模型(LLM)是许多自然语言处理(NLP)任务的基石，如情感分析、文档分类、命名实体识别、问答、摘要等。LLM通常在来自网络的数据上进行训练。这些数据容易包含仇恨、辱骂和亵渎(HAP)内容。由于LLM在训练过程中接触到HAP内容，模型会学习到并生成带有仇恨或亵渎内容。例如，当使用HuggingFace(Transformers库的开源RoBERTa模型(具体来说，是RoBERTa基础模型))来替换句子`I do not know that Persian people are that MASK`中的掩码标记时，它返回得分最高的词为`stupid`。这在文明对话中是不可接受的。文本中的仇恨、辱骂和亵渎的检测是创建文明和没有偏见的LLM的重要组成部分。

    Large Language Models (LLMs) are the cornerstone for many Natural Language Processing (NLP) tasks like sentiment analysis, document classification, named entity recognition, question answering, summarization, etc. LLMs are often trained on data which originates from the web. This data is prone to having content with Hate, Abuse and Profanity (HAP). For a detailed definition of HAP, please refer to the Appendix. Due to the LLMs being exposed to HAP content during training, the models learn it and may then generate hateful or profane content. For example, when the open-source RoBERTa model (specifically, the RoBERTA base model) from the HuggingFace (HF) Transformers library is prompted to replace the mask token in `I do not know that Persian people are that MASK` it returns the word `stupid` with the highest score. This is unacceptable in civil discourse.The detection of Hate, Abuse and Profanity in text is a vital component of creating civil and unbiased LLMs, which is needed not only f
    
[^43]: 预训练的生成式语言模型作为序列型任务的通用学习框架

    Pretrained Generative Language Models as General Learning Frameworks for Sequence-Based Tasks

    [https://arxiv.org/abs/2402.05616](https://arxiv.org/abs/2402.05616)

    预训练的小型生成式语言模型可以作为序列型任务的通用学习框架，通过指令微调可以在化学信息学任务中实现接近最先进结果。

    

    我们提出了一个观点，即具有数百万参数的小型预训练基础生成式语言模型可以用作序列型任务的通用学习框架。我们的提议解决了从头开始训练神经网络和语言模型所面临的计算资源、技能需求和时间限制等挑战。此外，我们的方法专注于创建小型且高度专业化的模型，能够准确执行基于任务模型无法完成的挑战性任务。我们证明了使用125M、350M和1.3B参数的预训练基础语言模型进行指令微调，使用10,000到1,000,000个指令示例可以在具有挑战性的化学信息学任务上实现接近最先进结果。我们还展示了连续的语言模型微调时期对改进结果的作用，以及数据格式和预训练基础语言模型选择对指令微调成功的重要性。

    We propose that small pretrained foundational generative language models with millions of parameters can be utilized as a general learning framework for sequence-based tasks. Our proposal overcomes the computational resource, skill set, and timeline challenges associated with training neural networks and language models from scratch. Further, our approach focuses on creating small and highly specialized models that can accurately execute a challenging task of which the base model is incapable of performing. We demonstrate that 125M, 350M, and 1.3B parameter pretrained foundational language models can be instruction fine-tuned with 10,000-to-1,000,000 instruction examples to achieve near state-of-the-art results on challenging cheminformatics tasks. We also demonstrate the role of successive language model fine-tuning epochs on improved outcomes, as well as the importance of both data formatting and pretrained foundational language model selection for instruction fine-tuning success.
    
[^44]: 扩展用于立体视觉的6D物体姿态估计器

    Extending 6D Object Pose Estimators for Stereo Vision

    [https://arxiv.org/abs/2402.05610](https://arxiv.org/abs/2402.05610)

    这篇论文扩展了用于立体视觉的6D物体姿态估计器，通过使用立体视觉提供的额外视角和直接推测物体的距离，该方法在6D姿态估计方面优于最先进的算法，且可适用于其他基于密集特征的算法。

    

    准确、快速、稳健地估计物体的6D姿态仍然是一项困难的任务。然而，最近的直接从RGB图像中使用密集特征回归姿态的方法已经取得了最先进的结果。立体视觉提供了对物体的额外视角，可以帮助减少姿态歧义和遮挡。此外，立体图像可以直接推测物体的距离，而单目视觉则需要内置对象尺寸的知识。为了将最先进的6D物体姿态估计方法扩展到立体视觉，我们创建了一个与BOP兼容的YCB-V数据集的立体版本。我们的方法通过利用立体视觉优于最先进的6D姿态估计算法，并且可以轻松应用于其他基于密集特征的算法。

    Estimating the 6D pose of objects accurately, quickly, and robustly remains a difficult task. However, recent methods for directly regressing poses from RGB images using dense features have achieved state-of-the-art results. Stereo vision, which provides an additional perspective on the object, can help reduce pose ambiguity and occlusion. Moreover, stereo can directly infer the distance of an object, while mono-vision requires internalized knowledge of the object's size. To extend the state-of-the-art in 6D object pose estimation to stereo, we created a BOP compatible stereo version of the YCB-V dataset. Our method outperforms state-of-the-art 6D pose estimation algorithms by utilizing stereo vision and can easily be adopted for other dense feature-based algorithms.
    
[^45]: 优化协作的人工智能-人类混合团队中的授权

    Optimizing Delegation in Collaborative Human-AI Hybrid Teams

    [https://arxiv.org/abs/2402.05605](https://arxiv.org/abs/2402.05605)

    本论文提出了一种优化协作的人工智能-人类混合团队授权的框架，通过引入AI经理（通过强化学习）作为团队的外部观察者，学习团队代理人的行为模型并选择最佳的控制代理人。

    

    当人类和自主系统作为混合团队共同运作时，我们希望确保团队的成功和效率。我们将团队成员称为代理人。在我们提出的框架中，我们解决了混合团队的情况，即在任何时候，只有一个团队成员（控制代理人）被授权为团队的控制者。为了确定最佳的控制代理人选择，我们提出了引入AI经理（通过强化学习）的想法，该经理作为团队的外部观察者学习。经理通过观察代理人的表现和团队所处的环境/世界来学习行为模型，并基于这些观察结果选择出最理想的控制代理人。为了限定经理的任务，我们引入了一组约束条件。经理的约束条件指示团队的可接受运作方式，因此如果团队进入不可接受并需要经理介入的状态，就会违反约束条件。

    When humans and autonomous systems operate together as what we refer to as a hybrid team, we of course wish to ensure the team operates successfully and effectively. We refer to team members as agents. In our proposed framework, we address the case of hybrid teams in which, at any time, only one team member (the control agent) is authorized to act as control for the team. To determine the best selection of a control agent, we propose the addition of an AI manager (via Reinforcement Learning) which learns as an outside observer of the team. The manager learns a model of behavior linking observations of agent performance and the environment/world the team is operating in, and from these observations makes the most desirable selection of a control agent. We restrict the manager task by introducing a set of constraints. The manager constraints indicate acceptable team operation, so a violation occurs if the team enters a condition which is unacceptable and requires manager intervention. To
    
[^46]: AttnLRP: 注意力感知的逐层相关传递用于Transformer

    AttnLRP: Attention-Aware Layer-wise Relevance Propagation for Transformers

    [https://arxiv.org/abs/2402.05602](https://arxiv.org/abs/2402.05602)

    AttnLRP是首个能够忠实且全面地归因Transformer模型的输入和潜在表示，并具有与单一反向传播相似的计算效率的方法。它通过扩展逐层相关传递归因方法以处理注意力层来解决了黑盒Transformer模型的归因问题，具有超越现有方法的准确性和理解潜在表示的能力。

    

    大型语言模型容易产生偏见的预测和幻象，这突显了理解其模型内部推理过程的重要性。然而，实现对整个黑盒Transformer模型的准确归因并保持计算效率是一个尚未解决的挑战。通过扩展逐层相关传递归因方法以处理注意力层，我们有效地解决了这些挑战。虽然存在部分解决方案，但我们的方法是首个能够忠实且全面地归因Transformer模型的输入和潜在表示，同时计算效率与单一反向传播相似。通过对Llama 2、Flan-T5和Vision Transformer架构上与现有方法的广泛评估，我们证明了我们提出的方法在准确性方面超过了其他方法，并能够理解潜在表示，为概念打开了大门。

    Large Language Models are prone to biased predictions and hallucinations, underlining the paramount importance of understanding their model-internal reasoning process. However, achieving faithful attributions for the entirety of a black-box transformer model and maintaining computational efficiency is an unsolved challenge. By extending the Layer-wise Relevance Propagation attribution method to handle attention layers, we address these challenges effectively. While partial solutions exist, our method is the first to faithfully and holistically attribute not only input but also latent representations of transformer models with the computational efficiency similar to a singular backward pass. Through extensive evaluations against existing methods on Llama 2, Flan-T5 and the Vision Transformer architecture, we demonstrate that our proposed approach surpasses alternative methods in terms of faithfulness and enables the understanding of latent representations, opening up the door for concep
    
[^47]: 使用合成数据仅从历史素描中重建灰泥雕像的概念

    A Concept for Reconstructing Stucco Statues from historic Sketches using synthetic Data only

    [https://arxiv.org/abs/2402.05593](https://arxiv.org/abs/2402.05593)

    本研究提出了一种使用合成数据仅通过历史素描重建灰泥雕像的全自动方法，可以实时在现场进行重建，并为专家提供一个有用的起点以手动重建雕像。

    

    在中世纪，灰泥工人使用一种称为辛诺比亚的红色颜料在墙上先制作雕像的素描。如今，许多这些雕像已经被摧毁，但是利用原始的辛诺比亚素描，我们可以重建最终雕像的样子。我们提出了一种全自动的方法来重建点云，并通过生成彩色图像、深度图和表面法线来展示初步结果，只需要一张简单的素描，而不需要其他类似样本的集合。我们提出的解决方案可以实时在现场进行重建，例如在展览中，或者为专家提供一个有用的起点，试图手动重建雕像，同时只使用合成数据进行训练。

    In medieval times, stuccoworkers used a red color, called sinopia, to first create a sketch of the to-be-made statue on the wall. Today, many of these statues are destroyed, but using the original drawings, deriving from the red color also called sinopia, we can reconstruct how the final statue might have looked.We propose a fully-automated approach to reconstruct a point cloud and show preliminary results by generating a color-image, a depth-map, as well as surface normals requiring only a single sketch, and without requiring a collection of other, similar samples. Our proposed solution allows real-time reconstruction on-site, for instance, within an exhibition, or to generate a useful starting point for an expert, trying to manually reconstruct the statue, all while using only synthetic data for training.
    
[^48]: SoftEDA: 用软标签重新思考基于规则的数据增强

    SoftEDA: Rethinking Rule-Based Data Augmentation with Soft Labels

    [https://arxiv.org/abs/2402.05591](https://arxiv.org/abs/2402.05591)

    本文提出了SoftEDA方法，通过使用软标签在增强数据上，从而解决了基于规则的文本数据增强方法可能破坏文本原始含义的问题，实验证明了该方法的有效性。

    

    基于规则的文本数据增强因其简单性而被广泛应用于自然语言处理任务。然而，这种方法可能会破坏文本的原始含义，最终影响模型的性能。为了克服这个限制，我们提出了一种将软标签应用于增强数据的简单技术。我们进行了七个不同的分类任务的实验，并经验性地证明了我们提出的方法的有效性。我们已经公开了我们的源代码以便复现。

    Rule-based text data augmentation is widely used for NLP tasks due to its simplicity. However, this method can potentially damage the original meaning of the text, ultimately hurting the performance of the model. To overcome this limitation, we propose a straightforward technique for applying soft labels to augmented data. We conducted experiments across seven different classification tasks and empirically demonstrated the effectiveness of our proposed approach. We have publicly opened our source code for reproducibility.
    
[^49]: AutoAugment是你需要的：在低资源环境下增强基于规则的数据增强方法

    AutoAugment Is What You Need: Enhancing Rule-based Augmentation Methods in Low-resource Regimes

    [https://arxiv.org/abs/2402.05584](https://arxiv.org/abs/2402.05584)

    本文提出了将AutoAugment方法应用于解决文本数据增强中的语义损害问题，实验证明该方法可以加强现有的增强方法并提升预训练语言模型的性能。

    

    文本数据增强是一个复杂的问题，因为句子的离散性质。尽管基于规则的增强方法因其简单性而在实际应用中被广泛采用，但它们可能导致潜在的语义损害。以往的研究者提出了使用软标签（softEDA）进行简单数据增强，并采用标签平滑来减轻这个问题。然而，针对每个模型和数据集找到最佳因子是具有挑战性的，因此在实际应用中使用softEDA仍然困难。在本文中，我们提出了将AutoAugment应用于解决这个问题的方法。实验结果表明，所提出的方法可以提升现有的增强方法，并且基于规则的方法可以增强先进的预训练语言模型。我们提供源代码。

    Text data augmentation is a complex problem due to the discrete nature of sentences. Although rule-based augmentation methods are widely adopted in real-world applications because of their simplicity, they suffer from potential semantic damage. Previous researchers have suggested easy data augmentation with soft labels (softEDA), employing label smoothing to mitigate this problem. However, finding the best factor for each model and dataset is challenging; therefore, using softEDA in real-world applications is still difficult. In this paper, we propose adapting AutoAugment to solve this problem. The experimental results suggest that the proposed method can boost existing augmentation methods and that rule-based methods can enhance cutting-edge pre-trained language models. We offer the source code.
    
[^50]: 在随机赌博机中同时实现群体曝光公平性和群内精英主义

    Simultaneously Achieving Group Exposure Fairness and Within-Group Meritocracy in Stochastic Bandits

    [https://arxiv.org/abs/2402.05575](https://arxiv.org/abs/2402.05575)

    该论文介绍了一种在随机赌博机中同时实现群体曝光公平性和群内精英主义的方法，通过提供随时的群体曝光公平性保证和在每个群体中实现个体层面的精英主义公平性。

    

    现有的随机多臂赌博机（MAB）中的公平性方法主要关注对各个臂的曝光保证。当臂根据某些属性自然分组时，我们提出了双层公平性，它考虑了两个层面的公平性。在第一层面，双层公平性保证每个群体有一定的最低曝光。为了解决群内个体臂的分配不均衡问题，我们在第二层面考虑了精英主义公平性，确保每个臂根据其在群体中的优势被选择。我们的工作表明，通过提供(i) 随时的群体曝光公平性保证和(ii) 在每个群体中实现个体层面的精英主义公平性，我们可以调整基于UCB的算法来实现双层公平性。

    Existing approaches to fairness in stochastic multi-armed bandits (MAB) primarily focus on exposure guarantee to individual arms. When arms are naturally grouped by certain attribute(s), we propose Bi-Level Fairness, which considers two levels of fairness. At the first level, Bi-Level Fairness guarantees a certain minimum exposure to each group. To address the unbalanced allocation of pulls to individual arms within a group, we consider meritocratic fairness at the second level, which ensures that each arm is pulled according to its merit within the group. Our work shows that we can adapt a UCB-based algorithm to achieve a Bi-Level Fairness by providing (i) anytime Group Exposure Fairness guarantees and (ii) ensuring individual-level Meritocratic Fairness within each group. We first show that one can decompose regret bounds into two components: (a) regret due to anytime group exposure fairness and (b) regret due to meritocratic fairness within each group. Our proposed algorithm BF-UCB 
    
[^51]: 使用图神经网络进行超图节点分类

    Hypergraph Node Classification With Graph Neural Networks

    [https://arxiv.org/abs/2402.05569](https://arxiv.org/abs/2402.05569)

    本研究提出了一种简单高效的框架，利用加权子图扩展的图神经网络(WCE-GNN)实现了超图节点分类。实验证明，WCE-GNN具有优秀的预测效果和较低的计算复杂度。

    

    超图是用来模拟现实世界数据中的高阶相互作用的关键。图神经网络（GNNs）的成功揭示了神经网络处理具有成对交互的数据的能力。这激发了使用神经网络处理具有高阶相互作用的数据的想法，从而导致了超图神经网络（HyperGNNs）的发展。GNNs和HyperGNNs通常被认为是不同的，因为它们被设计用于处理不同几何拓扑的数据。然而，在本文中，我们在理论上证明，在节点分类的上下文中，大多数HyperGNNs可以使用带有超图的加权子图扩展的GNN来近似。这导致了WCE-GNN，一种简单高效的框架，包括一个GNN和一个加权子图扩展（WCE），用于超图节点分类。对于九个真实世界的超图节点分类数据集的实验表明，WCE-GNN不仅具有优秀的预测效果，而且具有较低的计算复杂度。

    Hypergraphs, with hyperedges connecting more than two nodes, are key for modelling higher-order interactions in real-world data. The success of graph neural networks (GNNs) reveals the capability of neural networks to process data with pairwise interactions. This inspires the usage of neural networks for data with higher-order interactions, thereby leading to the development of hypergraph neural networks (HyperGNNs). GNNs and HyperGNNs are typically considered distinct since they are designed for data on different geometric topologies. However, in this paper, we theoretically demonstrate that, in the context of node classification, most HyperGNNs can be approximated using a GNN with a weighted clique expansion of the hypergraph. This leads to WCE-GNN, a simple and efficient framework comprising a GNN and a weighted clique expansion (WCE), for hypergraph node classification. Experiments on nine real-world hypergraph node classification benchmarks showcase that WCE-GNN demonstrates not o
    
[^52]: 神经多重网格结构

    Neural Multigrid Architectures

    [https://arxiv.org/abs/2402.05563](https://arxiv.org/abs/2402.05563)

    我们提出了一种简单且高效的神经网络多重网格方法，通过参数共享和层序列化实现了高效的训练，并在具有成千上万个未知数的线性问题以及具有数百万个未知数的问题上保持其效率。同时，在数值线性代数中，该网络的训练方法可以寻找最佳的光滑器，以提高几何多重网格方法的效果。我们在几个二阶椭圆方程上的实验结果表明，与基准相比，我们的方法能够显著降低误差传播矩阵的谱半径。

    

    我们提出了一种方便的无矩阵神经网络多重网格方法。该架构足够简单，可以在不到五十行代码的情况下实施，并且包含大量不同的多重网格求解器。我们认为，没有密集层的固定神经网络无法实现高效的迭代方法。因此，标准的训练协议不能产生具有竞争力的求解器。为了克服这个困难，我们使用参数共享和层的序列化。所得到的网络可以在拥有数千个未知数的线性问题上进行训练，并在具有数百万个未知数的问题上保持其效率。从数值线性代数的角度来看，网络的训练对应于为几何多重网格方法寻找最佳光滑器。我们在几个二阶椭圆方程上演示了我们的方法。对于测试的线性系统，与基准相比，我们得到了两到五倍较小的误差传播矩阵的谱半径。

    We propose a convenient matrix-free neural architecture for the multigrid method. The architecture is simple enough to be implemented in less than fifty lines of code, yet it encompasses a large number of distinct multigrid solvers. We argue that a fixed neural network without dense layers can not realize an efficient iterative method. Because of that, standard training protocols do not lead to competitive solvers. To overcome this difficulty, we use parameter sharing and serialization of layers. The resulting network can be trained on linear problems with thousands of unknowns and retains its efficiency on problems with millions of unknowns. From the point of view of numerical linear algebra network's training corresponds to finding optimal smoothers for the geometric multigrid method. We demonstrate our approach on a few second-order elliptic equations. For tested linear systems, we obtain from two to five times smaller spectral radius of the error propagation matrix compare to a bas
    
[^53]: 闪回：理解和减轻联邦学习中的遗忘问题

    Flashback: Understanding and Mitigating Forgetting in Federated Learning

    [https://arxiv.org/abs/2402.05558](https://arxiv.org/abs/2402.05558)

    本研究深入探讨了联邦学习中的遗忘问题，强调了遗忘在异质数据环境中的关键性质，提出了"闪回"算法来解决遗忘问题并取得优异的学习结果。

    

    在联邦学习中，遗忘或者说在不同轮次中的知识丢失阻碍了算法的收敛，尤其在客户端之间存在严重的数据异质性的情况下更为明显。本研究探究了这个问题的复杂性，强调了遗忘在异质数据环境中对联邦学习的低效学习起到的关键作用。知识丢失既发生在客户端局部更新中，也发生在服务器端的聚合步骤中；只解决其中一个而忽略另一个无法有效减轻遗忘问题。我们引入了一个度量遗忘的指标，以确保在新知识获取中明确识别遗忘。借助这些洞察，我们提出了一种名为"闪回"的联邦学习算法，该算法使用动态蒸馏方法来规范化局部模型，并有效地聚合它们的知识。在不同的基准测试中，"闪回"优于其他方法，减轻了遗忘问题，并在6到16个轮次内达到更快的目标准确度。

    In Federated Learning (FL), forgetting, or the loss of knowledge across rounds, hampers algorithm convergence, particularly in the presence of severe data heterogeneity among clients. This study explores the nuances of this issue, emphasizing the critical role of forgetting in FL's inefficient learning within heterogeneous data contexts. Knowledge loss occurs in both client-local updates and server-side aggregation steps; addressing one without the other fails to mitigate forgetting. We introduce a metric to measure forgetting granularly, ensuring distinct recognition amid new knowledge acquisition. Leveraging these insights, we propose Flashback, an FL algorithm with a dynamic distillation approach that is used to regularize the local models, and effectively aggregate their knowledge. Across different benchmarks, Flashback outperforms other methods, mitigates forgetting, and achieves faster round-to-target-accuracy, by converging in 6 to 16 rounds.
    
[^54]: 在交流医疗辅导上对大型语言模型进行基准测试：一种新的系统和数据集

    Benchmarking Large Language Models on Communicative Medical Coaching: a Novel System and Dataset

    [https://arxiv.org/abs/2402.05547](https://arxiv.org/abs/2402.05547)

    本研究介绍了“ChatCoach”，一个集成人工智能与人类医生合作的框架，在交流医疗辅导中利用大型语言模型，提供模拟环境和实时反馈，以帮助医学学员提高沟通技巧。

    

    在医疗保健领域，自然语言处理（NLP）的传统应用主要集中在以患者为中心的服务上，增强患者互动和护理交付，例如医学对话系统。然而，NLP在帮助经验不丰富的医生，特别是在交流医疗辅导等领域的潜力仍然很少被探索。我们引入了“ChatCoach”，一个集成的人工智能合作框架。在这个框架内，一个患者代理和一个辅导代理共同支持医学学员在会诊过程中练习医学沟通技巧。与传统的对话系统不同，ChatCoach提供了一个模拟环境，医生可以在其中与患者代理进行医学对话。同时，辅导代理会提供实时反馈给医生。为了构建ChatCoach系统，我们开发了一个数据集，并集成了ChatGPT和Llama2等大型语言模型，旨在评估它们在交流医疗辅导方面的效果。

    Traditional applications of natural language processing (NLP) in healthcare have predominantly focused on patient-centered services, enhancing patient interactions and care delivery, such as through medical dialogue systems. However, the potential of NLP to benefit inexperienced doctors, particularly in areas such as communicative medical coaching, remains largely unexplored. We introduce ``ChatCoach,'' an integrated human-AI cooperative framework. Within this framework, both a patient agent and a coaching agent collaboratively support medical learners in practicing their medical communication skills during consultations. Unlike traditional dialogue systems, ChatCoach provides a simulated environment where a human doctor can engage in medical dialogue with a patient agent. Simultaneously, a coaching agent provides real-time feedback to the doctor. To construct the ChatCoach system, we developed a dataset and integrated Large Language Models such as ChatGPT and Llama2, aiming to assess 
    
[^55]: 离线演员-评论者强化学习扩展到大型模型

    Offline Actor-Critic Reinforcement Learning Scales to Large Models

    [https://arxiv.org/abs/2402.05546](https://arxiv.org/abs/2402.05546)

    本文证明了离线演员-评论者强化学习方法可以扩展到大型模型，并且比基线方法在多任务训练中表现更好。通过引入Perceiver-based演员-评论者模型，我们揭示了离线强化学习与自注意机制和跨注意力模块配合的关键模型特征。这项研究的发现表明：离线演员-评论者算法是逐渐摆脱行为克隆范式的一种自然选择，并且通过离线强化学习可以从次优示范或自动生成的数据中学习掌握多个领域的多任务策略。

    

    我们证明了离线演员-评论者强化学习可以扩展到大型模型，如transformer，并且遵循与监督学习类似的扩展规律。我们发现，离线演员-评论者算法在包含132个连续控制任务的大型数据集上的多任务训练中，可以胜过强大的监督式行为克隆基线，该数据集包含了次优和专家行为。我们引入了一种基于Perceiver的演员-评论者模型，并阐明了使离线强化学习与自注意机制和跨注意力模块配合工作所需的关键模型特征。总的来说，我们发现：i）简单的离线演员评论者算法是逐渐远离当前主流行为克隆范式的自然选择，ii）通过离线强化学习，可以从次优示范或自动生成的数据中学习掌握许多领域的多任务策略，包括真实机器人任务。

    We show that offline actor-critic reinforcement learning can scale to large models - such as transformers - and follows similar scaling laws as supervised learning. We find that offline actor-critic algorithms can outperform strong, supervised, behavioral cloning baselines for multi-task training on a large dataset containing both sub-optimal and expert behavior on 132 continuous control tasks. We introduce a Perceiver-based actor-critic model and elucidate the key model features needed to make offline RL work with self- and cross-attention modules. Overall, we find that: i) simple offline actor critic algorithms are a natural choice for gradually moving away from the currently predominant paradigm of behavioral cloning, and ii) via offline RL it is possible to learn multi-task policies that master many domains simultaneously, including real robotics tasks, from sub-optimal demonstrations or self-generated data.
    
[^56]: 强化学习作为鲁棒和公平联邦学习的催化剂：解密客户贡献动力学

    Reinforcement Learning as a Catalyst for Robust and Fair Federated Learning: Deciphering the Dynamics of Client Contributions

    [https://arxiv.org/abs/2402.05541](https://arxiv.org/abs/2402.05541)

    本研究提出了一个新的框架——强化联邦学习（RFL），通过利用深度强化学习自适应地优化客户贡献的聚合过程，以增强模型鲁棒性和在非相同分布环境下参与者之间的公平性。

    

    最近在联邦学习（FL）方面的进展产生了模型，通过在多个分散的设备或系统上训练来保护用户隐私并保留本地数据样本。然而，这些策略经常忽视统计异质性和对敌对攻击的脆弱性所带来的困难，这些因素会降低模型的鲁棒性和公平性。个性化的FL策略可以通过调整模型来适应个别客户的特点，但往往忽视了服务器端聚合的脆弱性。为了解决这些问题，我们提出了强化联邦学习（RFL），这是一个利用深度强化学习来自适应优化聚合过程中客户贡献的新框架，从而增强恶意客户下的模型鲁棒性和参与者之间的公平性在非相同分布环境下。为了实现这一目标，我们提出了一种细致的方法，其中包括基于深度确定性策略梯度算法的协同训练，以优化客户贡献的过程。

    Recent advancements in federated learning (FL) have produced models that retain user privacy by training across multiple decentralized devices or systems holding local data samples. However, these strategies often neglect the inherent challenges of statistical heterogeneity and vulnerability to adversarial attacks, which can degrade model robustness and fairness. Personalized FL strategies offer some respite by adjusting models to fit individual client profiles, yet they tend to neglect server-side aggregation vulnerabilities. To address these issues, we propose Reinforcement Federated Learning (RFL), a novel framework that leverages deep reinforcement learning to adaptively optimize client contribution during aggregation, thereby enhancing both model robustness against malicious clients and fairness across participants under non-identically distributed settings. To achieve this goal, we propose a meticulous approach involving a Deep Deterministic Policy Gradient-based algorithm for co
    
[^57]: 差分隐私的基于模型的离线强化学习

    Differentially Private Model-Based Offline Reinforcement Learning

    [https://arxiv.org/abs/2402.05525](https://arxiv.org/abs/2402.05525)

    本研究提出了一种差分隐私的基于模型的离线强化学习方法，通过学习离线数据中的隐私模型以及基于模型的策略优化，实现了从离线数据中训练具有隐私保护的强化学习代理。同时，研究还总结了在这种设置下隐私的代价。

    

    我们解决了具有隐私保证的离线强化学习问题，目标是训练一个相对于数据集中每个轨迹具有差分隐私的策略。为了实现这一目标，我们引入了DP-MORL，一种带有差分隐私保证的MBRL算法。首先，使用DP-FedAvg从离线数据中学习环境的隐私模型，DP-FedAvg是一种为神经网络提供轨迹级差分隐私保证的训练方法。然后，我们使用基于模型的策略优化从（受罚的）隐私模型中推导出策略，无需进一步与系统交互或访问输入数据。我们经验证明，DP-MORL能够从离线数据中训练出具有隐私保护的RL代理，并进一步概述了在这种情况下隐私的代价。

    We address offline reinforcement learning with privacy guarantees, where the goal is to train a policy that is differentially private with respect to individual trajectories in the dataset. To achieve this, we introduce DP-MORL, an MBRL algorithm coming with differential privacy guarantees. A private model of the environment is first learned from offline data using DP-FedAvg, a training method for neural networks that provides differential privacy guarantees at the trajectory level. Then, we use model-based policy optimization to derive a policy from the (penalized) private model, without any further interaction with the system or access to the input data. We empirically show that DP-MORL enables the training of private RL agents from offline data and we furthermore outline the price of privacy in this setting.
    
[^58]: 线性化模型以实现高效而鲁棒的隐私推理

    Linearizing Models for Efficient yet Robust Private Inference

    [https://arxiv.org/abs/2402.05521](https://arxiv.org/abs/2402.05521)

    本文提出了一种名为RLNet的鲁棒线性化网络，通过减少延迟并改善模型在各种情况下的表现，实现了高效而鲁棒的隐私推理。

    

    对数据隐私的日益关注导致了客户端-服务器应用中私有推理（PI）框架的发展，该框架既保护数据隐私又保护模型知识产权。然而，所需的密码原语导致了显著的延迟开销，限制了其广泛应用。同时，不断变化的环境要求PI服务对各种自然发生的和基于梯度的扰动具有鲁棒性。尽管已有一些工作专注于开发适用于PI的延迟-高效模型，但这些模型对鲁棒性的影响尚未被探索。为实现这个目标，本文提出了RLNet，一种鲁棒的线性化网络，通过减少高延迟的ReLU操作提供延迟改进，同时提高模型在清晰图像和损坏图像上的性能。特别地，RLNet模型提供了在清晰图像、自然扰动图像和基于梯度的扰动图像上的分类准确性改善的“三连赢”解决方案。

    The growing concern about data privacy has led to the development of private inference (PI) frameworks in client-server applications which protects both data privacy and model IP. However, the cryptographic primitives required yield significant latency overhead which limits its wide-spread application. At the same time, changing environments demand the PI service to be robust against various naturally occurring and gradient-based perturbations. Despite several works focused on the development of latency-efficient models suitable for PI, the impact of these models on robustness has remained unexplored. Towards this goal, this paper presents RLNet, a class of robust linearized networks that can yield latency improvement via reduction of high-latency ReLU operations while improving the model performance on both clean and corrupted images. In particular, RLNet models provide a "triple win ticket" of improved classification accuracy on clean, naturally perturbed, and gradient-based perturbe
    
[^59]: ChatGPT能评估研究质量吗？

    Can ChatGPT evaluate research quality?

    [https://arxiv.org/abs/2402.05519](https://arxiv.org/abs/2402.05519)

    本研究评估了ChatGPT 4.0评估研究质量的准确性，发现其能够产生符合标准的文档摘要和质量评估理由。然而，与作者自我评价得分相比，ChatGPT-4的评分相关性较弱，但多轮评分的平均得分具有显著正相关性。

    

    目的: 评估ChatGPT 4.0是否足够准确，能够自动评估期刊论文的研究质量，以节省时间。设计/方法: 通过使用2021年英国研究卓越框架（REF）的发布评分指南创建一个研究评估ChatGPT，并将其应用于我自己的51篇文章中，并与我自己的质量判断进行比较，测试ChatGPT-4评估期刊论文质量的能力。结果: ChatGPT-4可以生成符合REF标准的合理的文档摘要和质量评估理由。它的总体评分与我对相同文章的自我评价得分之间存在较弱的相关性（平均为r=0.281，在15次迭代中平均有8次与0显著不同）。相比之下，15次迭代的平均得分呈现出了0.509的显著正相关。因此，对多轮ChatGPT-4评分求平均似乎更有效。

    Purpose: Assess whether ChatGPT 4.0 is accurate enough to perform research evaluations on journal articles to automate this time-consuming task. Design/methodology/approach: Test the extent to which ChatGPT-4 can assess the quality of journal articles using a case study of the published scoring guidelines of the UK Research Excellence Framework (REF) 2021 to create a research evaluation ChatGPT. This was applied to 51 of my own articles and compared against my own quality judgements. Findings: ChatGPT-4 can produce plausible document summaries and quality evaluation rationales that match the REF criteria. Its overall scores have weak correlations with my self-evaluation scores of the same documents (averaging r=0.281 over 15 iterations, with 8 being statistically significantly different from 0). In contrast, the average scores from the 15 iterations produced a statistically significant positive correlation of 0.509. Thus, averaging scores from multiple ChatGPT-4 rounds seems more effec
    
[^60]: NoisyICL: 一点噪音在模型参数中提高了上下文学习的性能、

    NoisyICL: A Little Noise in Model Parameters Calibrates In-context Learning

    [https://arxiv.org/abs/2402.05515](https://arxiv.org/abs/2402.05515)

    NoisyICL通过在模型参数中引入噪音，提高了上下文学习的性能和校准性，实验结果显示NoisyICL可以产生更准确、更公平的预测。

    

    上下文学习 (ICL) 在高先验偏差和不可信任的置信度的影响下，表现不佳且校准不足。以往的一些工作通过使用庞大的数据集和计算成本对语言模型进行微调以改善 ICL 的性能。在本文中，我们提出了 NoisyICL，通过随机噪音扰动模型参数来努力提高性能和校准性。我们在2个模型和12个下游数据集上的实验表明，NoisyICL可以帮助ICL产生更准确的预测。进一步的分析表明，NoisyICL使得模型能够提供更公平的预测，同时置信度更可信。因此，我们认为NoisyICL是ICL的一种有效校准方法。我们的实验代码已上传至Github。

    In-Context Learning (ICL) is suffering from unsatisfactory performance and under-calibration due to high prior bias and unfaithful confidence. Some previous works fine-tuned language models for better ICL performance with enormous datasets and computing costs. In this paper, we propose NoisyICL, simply perturbing the model parameters by random noises to strive for better performance and calibration. Our experiments on 2 models and 12 downstream datasets show that NoisyICL can help ICL produce more accurate predictions. Our further analysis indicates that NoisyICL enables the model to provide more fair predictions, and also with less unfaithful confidence. Therefore, we believe that NoisyICL is an effective calibration of ICL. Our experimental code is uploaded to Github.
    
[^61]: GPT对于序列生成任务具有多语言注释功能

    GPTs Are Multilingual Annotators for Sequence Generation Tasks

    [https://arxiv.org/abs/2402.05512](https://arxiv.org/abs/2402.05512)

    本研究提出了一种利用大型语言模型进行自动注释的方法，具有费用效益高和适用于低资源语言注释的优点，同时构建了一个图像字幕数据集并开放了源代码。

    

    数据注释是构建新数据集的关键步骤。然而，传统的通过众包进行数据注释的方法既耗时又昂贵。此外，当处理低资源语言时，由于众包工作者的语言池差异，这个过程的复杂性增加。为了解决这些问题，本研究提出了一种利用大型语言模型进行自动注释的方法，最近的研究表明这些模型具有出色的性能。通过我们的实验，我们证明了所提出的方法不仅费用效益高，而且适用于低资源语言注释。此外，我们使用我们的方法构建了一个图像字幕数据集，并致力于将此数据集开放给未来的研究。我们已经开放了我们的源代码，以便进一步研究和可复现性。

    Data annotation is an essential step for constructing new datasets. However, the conventional approach of data annotation through crowdsourcing is both time-consuming and expensive. In addition, the complexity of this process increases when dealing with low-resource languages owing to the difference in the language pool of crowdworkers. To address these issues, this study proposes an autonomous annotation method by utilizing large language models, which have been recently demonstrated to exhibit remarkable performance. Through our experiments, we demonstrate that the proposed method is not just cost-efficient but also applicable for low-resource language annotation. Additionally, we constructed an image captioning dataset using our approach and are committed to open this dataset for future study. We have opened our source code for further study and reproducibility.
    
[^62]: 探索针对设备上模型的白盒攻击

    Investigating White-Box Attacks for On-Device Models

    [https://arxiv.org/abs/2402.05493](https://arxiv.org/abs/2402.05493)

    本研究探究了针对设备上模型的白盒攻击，提出了一种逆向工程框架(REOM)以将编译后的设备上TFLite模型转换为可调试模型。

    

    许多移动应用程序利用了深度学习的能力。然而，设备上的模型容易受到攻击，因为它们可以从相应的移动应用程序中轻易提取出来。现有的设备上攻击方法只能生成黑盒攻击，这种方法远不如白盒策略有效和高效。这是因为移动深度学习框架如TFLite不支持梯度计算，而梯度计算对于白盒攻击算法是必要的。因此，我们认为现有的发现可能低估了设备上攻击的危害性。为了回答这个研究问题，我们进行了一项研究：设备上的模型是否可以通过白盒策略直接受到攻击？我们首先系统地分析了将设备上模型转换为可调试版本的困难，并提出了一种针对设备上模型的逆向工程框架(REOM)，该框架可以自动将编译后的设备上TFLite模型逆向为可调试模型。具体来说，REOM

    Numerous mobile apps have leveraged deep learning capabilities. However, on-device models are vulnerable to attacks as they can be easily extracted from their corresponding mobile apps. Existing on-device attacking approaches only generate black-box attacks, which are far less effective and efficient than white-box strategies. This is because mobile deep learning frameworks like TFLite do not support gradient computing, which is necessary for white-box attacking algorithms. Thus, we argue that existing findings may underestimate the harmfulness of on-device attacks. To this end, we conduct a study to answer this research question: Can on-device models be directly attacked via white-box strategies? We first systematically analyze the difficulties of transforming the on-device model to its debuggable version, and propose a Reverse Engineering framework for On-device Models (REOM), which automatically reverses the compiled on-device TFLite model to the debuggable model. Specifically, REOM
    
[^63]: 利用人工智能提升软件工作量估计：一项全面的研究和框架提议

    Leveraging AI for Enhanced Software Effort Estimation: A Comprehensive Study and Framework Proposal

    [https://arxiv.org/abs/2402.05484](https://arxiv.org/abs/2402.05484)

    本文通过全面的研究，提出了基于人工智能的软件工作量估计框架，该框架通过克服传统方法的局限性，提高了准确性和可靠性，对于项目规划和资源分配具有重要意义。

    

    本文介绍了过去五年（2017年至2023年）中利用人工智能技术进行软件工作量估计的广泛研究。通过克服传统方法的局限性，该研究旨在提高准确性和可靠性。通过性能评估和与各种机器学习模型（包括人工神经网络，支持向量机，线性回归，随机森林等技术）的比较，找到了最有效的方法。提出的基于人工智能的框架有潜力提升项目规划和资源分配，为软件项目工作量估计的研究领域做出贡献。

    This paper presents an extensive study on the application of AI techniques for software effort estimation in the past five years from 2017 to 2023. By overcoming the limitations of traditional methods, the study aims to improve accuracy and reliability. Through performance evaluation and comparison with diverse Machine Learning models, including Artificial Neural Network (ANN), Support Vector Machine (SVM), Linear Regression, Random Forest and other techniques, the most effective method is identified. The proposed AI-based framework holds the potential to enhance project planning and resource allocation, contributing to the research area of software project effort estimation.
    
[^64]: 快速优化LLM越狱方法：通过潜意识利用和模仿动作

    Rapid Optimization for Jailbreaking LLMs via Subconscious Exploitation and Echopraxia

    [https://arxiv.org/abs/2402.05467](https://arxiv.org/abs/2402.05467)

    本文介绍了一种名为RIPPLE的快速优化方法，该方法通过潜意识利用和模仿动作的思想，解决了通过越狱提示绕过安全措施的问题。

    

    大型语言模型(LLMs)在各个领域得到了广泛应用，通过其非凡的推理和理解能力改变了人类生活。随着它们在敏感任务中的增加使用，安全问题引起了广泛关注。人们已经做出了大量努力，以确保LLMs与人类道德原则相一致，以确保其安全部署。尽管有潜力，但最近的研究表明，对齐的LLMs容易受到专门的越狱提示的影响，这些提示绕过安全措施，引发暴力和有害内容。当代LLMs的离散本质和庞大规模使得自动生成多样化、高效和强效的越狱提示面临重大挑战，这是一个持续的障碍。在本文中，我们介绍了一种名为RIPPLE（基于潜意识利用和模仿动作的快速优化）的新型基于优化的方法，该方法受到了两个心理学概念的启发：潜意识和模仿动作。

    Large Language Models (LLMs) have become prevalent across diverse sectors, transforming human life with their extraordinary reasoning and comprehension abilities. As they find increased use in sensitive tasks, safety concerns have gained widespread attention. Extensive efforts have been dedicated to aligning LLMs with human moral principles to ensure their safe deployment. Despite their potential, recent research indicates aligned LLMs are prone to specialized jailbreaking prompts that bypass safety measures to elicit violent and harmful content. The intrinsic discrete nature and substantial scale of contemporary LLMs pose significant challenges in automatically generating diverse, efficient, and potent jailbreaking prompts, representing a continuous obstacle. In this paper, we introduce RIPPLE (Rapid Optimization via Subconscious Exploitation and Echopraxia), a novel optimization-based method inspired by two psychological concepts: subconsciousness and echopraxia, which describe the p
    
[^65]: 永远不嫌晚：将声学信息融入大型语言模型以进行自动语音识别

    It's Never Too Late: Fusing Acoustic Information into Large Language Models for Automatic Speech Recognition

    [https://arxiv.org/abs/2402.05457](https://arxiv.org/abs/2402.05457)

    本论文通过将声学信息融入大型语言模型（LLM）中，提出了一种名为不确定性感知动态融合（UADF）的后期融合解决方案，以克服生成性错误纠正（GER）中存在的数据不确定性问题，并应用于自动语音识别（ASR）任务。通过在自回归解码过程中实施UADF方法，在LLM决策的标记级分析和校准的基础上，动态地融合声学信息，从而提高了ASR的准确性。

    

    最近的研究成功地表明，大型语言模型（LLM）可以成功用于在自动语音识别（ASR）输出之上进行生成性错误纠正（GER）。具体而言，LLM被用于对由ASR系统生成的N最佳假设列表进行直接映射，生成预测的输出转录。然而，尽管其有效性，GER引入了额外的数据不确定性，因为LLM在训练时没有考虑到语音信号中可用的声学信息。在这项工作中，我们旨在通过一种名为不确定性感知动态融合（UADF）的新型后期融合解决方案，通过注入声学信息以生成预测转录来克服这种限制。UADF是一种多模态融合方法，实现在自回归解码过程中，并分为两个阶段：（i）它首先分析和校准标记级LLM决策，然后（ii）它动态地吸收声学信息。

    Recent studies have successfully shown that large language models (LLMs) can be successfully used for generative error correction (GER) on top of the automatic speech recognition (ASR) output. Specifically, an LLM is utilized to carry out a direct mapping from the N-best hypotheses list generated by an ASR system to the predicted output transcription. However, despite its effectiveness, GER introduces extra data uncertainty since the LLM is trained without taking into account acoustic information available in the speech signal. In this work, we aim to overcome such a limitation by infusing acoustic information before generating the predicted transcription through a novel late fusion solution termed Uncertainty-Aware Dynamic Fusion (UADF). UADF is a multimodal fusion approach implemented into an auto-regressive decoding process and works in two stages: (i) It first analyzes and calibrates the token-level LLM decision, and (ii) it then dynamically assimilates the information from the aco
    
[^66]: Minecraft-ify：用于游戏应用的Minecraft风格图像生成与文本引导的图像编辑

    Minecraft-ify: Minecraft Style Image Generation with Text-guided Image Editing for In-Game Application

    [https://arxiv.org/abs/2402.05448](https://arxiv.org/abs/2402.05448)

    本文提出了一种用于Minecraft游戏应用的图像生成和编辑系统"Minecraft-ify"，能够生成针对3D虚拟角色的面部聚焦图像，并支持使用文本进行图像编辑，提供了更自由和优化的用户体验。

    

    本文首先介绍了面向Minecraft视频游戏的角色纹理生成系统"Minecraft-ify"，该系统可以生成针对具有立方体流形的3D虚拟角色的面部聚焦图像以进行纹理映射。与现有项目或作品只生成纹理不同，提出的系统可以反转用户提供的真实图像，或从学习到的分布生成平均/随机外观。此外，它可以使用StyleGAN和StyleCLIP进行文本引导的操作。这些功能提供了更广泛的用户体验和更多的自由，是一种用户友好的AI工具。

    In this paper, we first present the character texture generation system \textit{Minecraft-ify}, specified to Minecraft video game toward in-game application. Ours can generate face-focused image for texture mapping tailored to 3D virtual character having cube manifold. While existing projects or works only generate texture, proposed system can inverse the user-provided real image, or generate average/random appearance from learned distribution. Moreover, it can be manipulated with text-guidance using StyleGAN and StyleCLIP. These features provide a more extended user experience with enlarged freedom as a user-friendly AI-tool. Project page can be found at https://gh-bumsookim.github.io/Minecraft-ify/
    
[^67]: GPT-4使用结构化叙事提示生成生活事件的叙述：一项验证研究

    GPT-4 Generated Narratives of Life Events using a Structured Narrative Prompt: A Validation Study

    [https://arxiv.org/abs/2402.05435](https://arxiv.org/abs/2402.05435)

    本研究通过使用结构化叙事提示，验证了GPT-4生成的叙述在传达生活事件方面的有效性。研究结果表明，大多数叙述能够足够传达提示的意图。同时，通过机器学习模型的训练和验证，可以自动识别有效和无效的叙述。

    

    大型语言模型在生成各种叙述方面发挥重要作用，促进了对其在叙述形式中传达生活事件效果的系统探索。本研究利用零-shot结构化叙事提示，使用OpenAI的GPT-4生成了24,000个叙述。从这个数据集中，我们手动分类了2,880个叙述，并评估它们在传达出生、死亡、招聘和解雇事件方面的有效性。令人惊讶的是，87.43%的叙述足够传达结构化提示的意图。为了自动识别有效和无效的叙述，我们对分类数据集训练和验证了九个机器学习模型。利用这些模型，我们扩展了对剩余21,120个叙述的分类预测分析。所有的机器学习模型在将有效的叙述分类为有效方面表现出色，但在同时将无效的叙述分类为无效方面存在挑战。我们的研究结果不仅推进了这一领域的发展，还提供了自动识别有效叙述的有益信息。

    Large Language Models (LLMs) play a pivotal role in generating vast arrays of narratives, facilitating a systematic exploration of their effectiveness for communicating life events in narrative form. In this study, we employ a zero-shot structured narrative prompt to generate 24,000 narratives using OpenAI's GPT-4. From this dataset, we manually classify 2,880 narratives and evaluate their validity in conveying birth, death, hiring, and firing events. Remarkably, 87.43% of the narratives sufficiently convey the intention of the structured prompt. To automate the identification of valid and invalid narratives, we train and validate nine Machine Learning models on the classified datasets. Leveraging these models, we extend our analysis to predict the classifications of the remaining 21,120 narratives. All the ML models excelled at classifying valid narratives as valid, but experienced challenges at simultaneously classifying invalid narratives as invalid. Our findings not only advance th
    
[^68]: 混合密度网络用于分类及其在产品捆绑中的应用

    Mixture Density Networks for Classification with an Application to Product Bundling

    [https://arxiv.org/abs/2402.05428](https://arxiv.org/abs/2402.05428)

    本论文提出了两个基于混合密度网络的分类模型，这两个模型通过拟合高斯混合分布并使用学习到的分布进行分类，效果略优于或与五个基准分类模型相当。在实际的产品捆绑应用中，我们的模型在学习产品支付意愿分布方面展现出真实的实用效果。

    

    虽然混合密度网络(MDNs)在回归任务中被广泛使用，但在分类任务中却很少使用。其中一个原因是MDNs在分类任务中的可用性不明确和直接。本文中，我们提出了两个基于MDN的分类模型。这两个模型对数据进行高斯混合拟合，并使用拟合的分布通过评估给定输入特征的学习累积分布函数来对给定样本进行分类。在三个公开可用的数据集上，所提出的基于MDN的模型的性能略优于或与五个基准分类模型相当。然而，我们的模型的真实效用通过一个实际的产品捆绑应用中得以展现。具体而言，我们使用我们的基于MDN的模型从合成销售数据中学习两个产品的支付意愿分布。

    While mixture density networks (MDNs) have been extensively used for regression tasks, they have not been used much for classification tasks. One reason for this is that the usability of MDNs for classification is not clear and straightforward. In this paper, we propose two MDN-based models for classification tasks. Both models fit mixtures of Gaussians to the the data and use the fitted distributions to classify a given sample by evaluating the learnt cumulative distribution function for the given input features. While the proposed MDN-based models perform slightly better than, or on par with, five baseline classification models on three publicly available datasets, the real utility of our models comes out through a real-world product bundling application. Specifically, we use our MDN-based models to learn the willingness-to-pay (WTP) distributions for two products from synthetic sales data of the individual products. The Gaussian mixture representation of the learnt WTP distributions
    
[^69]: DiffTOP: 可微分轨迹优化在强化学习和模仿学习中的应用

    DiffTOP: Differentiable Trajectory Optimization for Deep Reinforcement and Imitation Learning

    [https://arxiv.org/abs/2402.05421](https://arxiv.org/abs/2402.05421)

    DiffTOP使用可微分轨迹优化作为策略表示来生成动作，解决了模型基于强化学习算法中的“目标不匹配”问题，并在模仿学习任务上进行了性能基准测试。

    

    本文介绍了DiffTOP，它利用可微分轨迹优化作为策略表示，为深度强化学习和模仿学习生成动作。轨迹优化是一种在控制领域中广泛使用的算法，由成本和动力学函数参数化。我们的方法的关键是利用了最近在可微分轨迹优化方面的进展，使得可以计算损失对于轨迹优化的参数的梯度。因此，轨迹优化的成本和动力学函数可以端到端地学习。DiffTOP解决了之前模型基于强化学习算法中的“目标不匹配”问题，因为DiffTOP中的动力学模型通过轨迹优化过程中的策略梯度损失直接最大化任务性能。我们还对DiffTOP在标准机器人操纵任务套件中进行了模仿学习性能基准测试。

    This paper introduces DiffTOP, which utilizes Differentiable Trajectory OPtimization as the policy representation to generate actions for deep reinforcement and imitation learning. Trajectory optimization is a powerful and widely used algorithm in control, parameterized by a cost and a dynamics function. The key to our approach is to leverage the recent progress in differentiable trajectory optimization, which enables computing the gradients of the loss with respect to the parameters of trajectory optimization. As a result, the cost and dynamics functions of trajectory optimization can be learned end-to-end. DiffTOP addresses the ``objective mismatch'' issue of prior model-based RL algorithms, as the dynamics model in DiffTOP is learned to directly maximize task performance by differentiating the policy gradient loss through the trajectory optimization process. We further benchmark DiffTOP for imitation learning on standard robotic manipulation task suites with high-dimensional sensory
    
[^70]: 从错误中学习的上下文准则学习

    In-Context Principle Learning from Mistakes

    [https://arxiv.org/abs/2402.05403](https://arxiv.org/abs/2402.05403)

    本文提出了一种新的学习方法LEAP，通过让模型从少量输入-输出示例中犯错误，然后反思并学习准则，从而提升模型在各种任务上的表现。

    

    上下文学习（ICL，也称为少样本提示）已成为将LLMs适应下游任务的标准方法，通过从少量的输入-输出示例中学习。然而，所有基于ICL的方法只从正确的输入-输出对中学习。在本文中，我们重新审视这一范例，通过从少给定的输入-输出示例中学习更多内容。我们引入了学习准则（LEAP）：首先，我们有意诱使模型在这些少量示例中犯错误；然后，我们反思这些错误，并从中学习显式的任务特定“准则”，这些准则有助于解决类似的问题并避免常见的错误；最后，我们使用原始的少样本示例和这些学到的通用准则来提示模型回答未见过的测试问题。我们在包括多跳问题回答（Hotpot QA）、文本问题回答（DROP）、Big-Bench困难推理和数学问题（GSM8K和MATH）在内的多个基准测试上评估了LEAP；在所有这些基准测试中，LEAP都有所改进。

    In-context learning (ICL, also known as few-shot prompting) has been the standard method of adapting LLMs to downstream tasks, by learning from a few input-output examples. Nonetheless, all ICL-based approaches only learn from correct input-output pairs. In this paper, we revisit this paradigm, by learning more from the few given input-output examples. We introduce Learning Principles (LEAP): First, we intentionally induce the model to make mistakes on these few examples; then we reflect on these mistakes, and learn explicit task-specific "principles" from them, which help solve similar problems and avoid common mistakes; finally, we prompt the model to answer unseen test questions using the original few-shot examples and these learned general principles. We evaluate LEAP on a wide range of benchmarks, including multi-hop question answering (Hotpot QA), textual QA (DROP), Big-Bench Hard reasoning, and math problems (GSM8K and MATH); in all these benchmarks, LEAP improves the strongest 
    
[^71]: CURE: 机器人领域的模拟辅助自动调节技术

    CURE: Simulation-Augmented Auto-Tuning in Robotics

    [https://arxiv.org/abs/2402.05399](https://arxiv.org/abs/2402.05399)

    本论文提出了一种模拟辅助的自动调节技术，用于解决机器人系统中的高度可配置参数的优化问题。该技术通过解决软硬件之间配置选项的交互问题，实现了在不同环境和机器人平台之间的性能迁移。

    

    机器人系统通常由多个子系统组成，例如定位和导航，每个子系统又包含许多可配置的组件（例如选择不同的规划算法）。一旦选择了某个算法，就需要设置相关的配置选项以达到适当的值。系统堆栈中的配置选项会产生复杂的交互关系。在高度可配置的机器人中找到最佳配置来实现期望的性能是一个重大挑战，因为软件和硬件之间的配置选项交互导致了庞大且复杂的配置空间。性能迁移在不同的环境和机器人平台之间也是一个难题。数据高效优化算法（例如贝叶斯优化）已越来越多地用于自动化调整网络物理系统中的可配置参数。然而，这样的优化算法在机器人领域应用仍有局限性。

    Robotic systems are typically composed of various subsystems, such as localization and navigation, each encompassing numerous configurable components (e.g., selecting different planning algorithms). Once an algorithm has been selected for a component, its associated configuration options must be set to the appropriate values. Configuration options across the system stack interact non-trivially. Finding optimal configurations for highly configurable robots to achieve desired performance poses a significant challenge due to the interactions between configuration options across software and hardware that result in an exponentially large and complex configuration space. These challenges are further compounded by the need for transferability between different environments and robotic platforms. Data efficient optimization algorithms (e.g., Bayesian optimization) have been increasingly employed to automate the tuning of configurable parameters in cyber-physical systems. However, such optimiz
    
[^72]: TASER: 时间自适应采样的快速准确动态图表示学习

    TASER: Temporal Adaptive Sampling for Fast and Accurate Dynamic Graph Representation Learning

    [https://arxiv.org/abs/2402.05396](https://arxiv.org/abs/2402.05396)

    该论文提出了TASER方法，它是针对动态图表示学习的时间自适应采样技术，在准确性、效率和可扩展性方面进行了优化，解决了现实世界动态图中存在的噪声问题。

    

    最近，时间图神经网络（TGNN）在包括欺诈检测和内容推荐在内的各种重要应用中展示出了最先进的性能。尽管TGNN取得了成功，但它们容易受到现实世界动态图中普遍存在的噪声的影响，例如时间过时的链接和偏斜的交互分布。这些噪声导致两个关键问题，严重损害了TGNN的准确性：（1）模型受到较差交互的监督，（2）噪声输入导致聚合消息的高方差。然而，目前的TGNN去噪技术并未考虑每个节点的多样化和动态的噪声模式。此外，它们还面临着遍历更多邻居导致产生过多小批量的开销。我们相信快速准确的TGNN的解决方法在于时间自适应采样。在这项工作中，我们提出了TASER，这是第一个针对准确性、效率和可扩展性进行优化的TGNN自适应采样方法。

    Recently, Temporal Graph Neural Networks (TGNNs) have demonstrated state-of-the-art performance in various high-impact applications, including fraud detection and content recommendation. Despite the success of TGNNs, they are prone to the prevalent noise found in real-world dynamic graphs like time-deprecated links and skewed interaction distribution. The noise causes two critical issues that significantly compromise the accuracy of TGNNs: (1) models are supervised by inferior interactions, and (2) noisy input induces high variance in the aggregated messages. However, current TGNN denoising techniques do not consider the diverse and dynamic noise pattern of each node. In addition, they also suffer from the excessive mini-batch generation overheads caused by traversing more neighbors. We believe the remedy for fast and accurate TGNNs lies in temporal adaptive sampling. In this work, we propose TASER, the first adaptive sampling method for TGNNs optimized for accuracy, efficiency, and sc
    
[^73]: 知识图谱与多模态学习：综述

    Knowledge Graphs Meet Multi-Modal Learning: A Comprehensive Survey

    [https://arxiv.org/abs/2402.05391](https://arxiv.org/abs/2402.05391)

    知识图谱与多模态学习的综述介绍了KG4MM和MM4KG两个主要方面，包括任务定义、构建进展、评估基准以及关键研究轨迹。

    

    知识图谱在推动各种人工智能应用方面起着关键作用，语义网络社区对多模态维度的探索为创新打开了新的途径。在本综述中，我们仔细审查了300多篇文章，重点关注了两个主要方面的知识图谱感知研究：以知识图谱支持多模态任务的KG驱动多模态（KG4MM）学习，将知识图谱研究扩展到多模态知识图谱（MM4KG）领域。我们从定义知识图谱和多模态知识图谱开始，然后探索它们的构建进展。我们的综述包括两个主要任务类别：KG感知的多模态学习任务，如图像分类和视觉问答，以及内在的多模态知识图谱任务，如多模态知识图谱补全和实体对齐，突出了具体的研究轨迹。对于这些任务中的大部分，我们提供了定义、评估基准，并进一步指出进行相关研究的重要见解。最后，我们讨论了cu

    Knowledge Graphs (KGs) play a pivotal role in advancing various AI applications, with the semantic web community's exploration into multi-modal dimensions unlocking new avenues for innovation. In this survey, we carefully review over 300 articles, focusing on KG-aware research in two principal aspects: KG-driven Multi-Modal (KG4MM) learning, where KGs support multi-modal tasks, and Multi-Modal Knowledge Graph (MM4KG), which extends KG studies into the MMKG realm. We begin by defining KGs and MMKGs, then explore their construction progress. Our review includes two primary task categories: KG-aware multi-modal learning tasks, such as Image Classification and Visual Question Answering, and intrinsic MMKG tasks like Multi-modal Knowledge Graph Completion and Entity Alignment, highlighting specific research trajectories. For most of these tasks, we provide definitions, evaluation benchmarks, and additionally outline essential insights for conducting relevant research. Finally, we discuss cu
    
[^74]: 物理层安全在多用户灵活双工网络中的图神经网络研究

    Graph Neural Networks for Physical-Layer Security in Multi-User Flexible-Duplex Networks

    [https://arxiv.org/abs/2402.05378](https://arxiv.org/abs/2402.05378)

    本文研究了多用户灵活双工网络中的物理层安全问题，提出了基于图神经网络的无监督学习策略，并通过大量数值模拟验证了其在性能和时间复杂度方面的优势。

    

    本文研究了在灵活双工网络中的物理层安全（PLS），考虑到窃听者的情景。我们的研究围绕着求解总保密速率最大化问题的复杂性展开，特别是面对采用最小均方误差（MMSE）接收器的协调和分布式窃听者时。我们的贡献包括基于迭代经典优化解和基于图神经网络（GNN）的无监督学习策略。据我们所知，这项工作标志着GNN在PLS应用上的初步探索。此外，我们将GNN方法扩展到解决窃听者的信道信息缺失问题。广泛的数值模拟结果显示，在性能和时间复杂度方面，灵活双工通信优于半双工（HD）通信，GNN方法优于传统方法。

    This paper explores Physical-Layer Security (PLS) in Flexible Duplex (FlexD) networks, considering scenarios involving eavesdroppers. Our investigation revolves around the intricacies of the sum secrecy rate maximization problem, particularly when faced with coordinated and distributed eavesdroppers employing a Minimum Mean Square Error (MMSE) receiver. Our contributions include an iterative classical optimization solution and an unsupervised learning strategy based on Graph Neural Networks (GNNs). To the best of our knowledge, this work marks the initial exploration of GNNs for PLS applications. Additionally, we extend the GNN approach to address the absence of eavesdroppers' channel knowledge. Extensive numerical simulations highlight FlexD's superiority over Half-Duplex (HD) communications and the GNN approach's superiority over the classical method in both performance and time complexity.
    
[^75]: CIC：一种面向文化感知图像字幕的框架

    CIC: A framework for Culturally-aware Image Captioning

    [https://arxiv.org/abs/2402.05374](https://arxiv.org/abs/2402.05374)

    CIC是一种面向文化感知图像字幕的框架，通过结合视觉问答和大型语言模型，它能够生成能描述图像中文化元素的详细字幕。

    

    图像字幕通过使用视觉-语言预训练模型（VLPs）如BLIP从图像生成描述性句子，这种方法已经取得了很大的改进。然而，当前的方法缺乏对图像中所描绘的文化元素（例如亚洲文化群体的传统服装）生成详细描述性字幕的能力。在本文中，我们提出了一种新的框架，\textbf{面向文化感知图像字幕（CIC）}，该框架能够从代表不同文化的图像中生成字幕并描述文化元素。受到将视觉模态和大型语言模型（LLMs）通过适当的提示进行组合的方法的启发，我们的框架（1）根据图像中的文化类别生成问题，（2）利用生成的问题从视觉问答（VQA）中提取文化视觉元素，（3）使用带有提示的LLMs生成文化感知字幕。我们在4个不同大学的45名参与者上进行了人工评估。

    Image Captioning generates descriptive sentences from images using Vision-Language Pre-trained models (VLPs) such as BLIP, which has improved greatly. However, current methods lack the generation of detailed descriptive captions for the cultural elements depicted in the images, such as the traditional clothing worn by people from Asian cultural groups. In this paper, we propose a new framework, \textbf{Culturally-aware Image Captioning (CIC)}, that generates captions and describes cultural elements extracted from cultural visual elements in images representing cultures. Inspired by methods combining visual modality and Large Language Models (LLMs) through appropriate prompts, our framework (1) generates questions based on cultural categories from images, (2) extracts cultural visual elements from Visual Question Answering (VQA) using generated questions, and (3) generates culturally-aware captions using LLMs with the prompts. Our human evaluation conducted on 45 participants from 4 dif
    
[^76]: 作为时间序列预测的稳健表示的注意力

    Attention as Robust Representation for Time Series Forecasting

    [https://arxiv.org/abs/2402.05370](https://arxiv.org/abs/2402.05370)

    在时间序列预测中，我们提出的方法将注意力权重提升为主要表示，使用全局标志和局部窗口构建的注意力图作为稳健核表示来克服噪声和分布变化，并取得了比现有模型更好的性能 improvement.

    

    时间序列预测在许多实际应用中至关重要，由于Transformer模型在自然语言处理和计算机视觉方面的优秀性能，其在时间序列预测中的应用逐渐增多。Transformers的关键特性，注意力机制，动态地融合嵌入以增强数据表示，通常将注意力权重作为副产品。然而，时间序列数据具有噪声和非平稳性，给预测带来了重大挑战。我们的方法将注意力权重提升为时间序列的主要表示，利用数据点之间的时间关系来改善预测准确性。我们的研究表明，使用全局标志和局部窗口构建的注意力图充当数据点的稳健核表示，能够抵抗噪声和分布移动。我们的方法在多变量时间序列预测中，将均方误差(MSE)显著降低了3.6%，超过了现有模型的表现，而不改变核心

    Time series forecasting is essential for many practical applications, with the adoption of transformer-based models on the rise due to their impressive performance in NLP and CV. Transformers' key feature, the attention mechanism, dynamically fusing embeddings to enhance data representation, often relegating attention weights to a byproduct role. Yet, time series data, characterized by noise and non-stationarity, poses significant forecasting challenges. Our approach elevates attention weights as the primary representation for time series, capitalizing on the temporal relationships among data points to improve forecasting accuracy. Our study shows that an attention map, structured using global landmarks and local windows, acts as a robust kernel representation for data points, withstanding noise and shifts in distribution. Our method outperforms state-of-the-art models, reducing mean squared error (MSE) in multivariate time series forecasting by a notable 3.6% without altering the core
    
[^77]: 利用分治程序指导大型语言模型对问题求解进行引导

    Guiding Large Language Models with Divide-and-Conquer Program for Discerning Problem Solving

    [https://arxiv.org/abs/2402.05359](https://arxiv.org/abs/2402.05359)

    该论文提出了一种以分治程序引导大型语言模型（LLM）的方法，以解决涉及重复子任务和/或具有欺骗性内容的问题。实验证明，该方法可以提高LLM的表达能力。

    

    基础模型，如大型语言模型（LLMs），因其广泛的应用而引起了广泛的关注。现有的研究表明，适当的提示设计，如思维链，可以释放LLM在不同领域的强大能力。然而，对于处理涉及重复子任务和/或具有欺骗性内容的任务（如算术计算和文章级虚假新闻检测），现有的提示策略要么表现出表达能力不足，要么由幻觉引发中间错误。为了使LLM对这些中间错误更具辨别力，我们提出了一种以分治程序引导LLM的方法，同时确保优越的表达能力和任务分解、子任务解决和解决组装过程的分离。理论分析表明，我们的策略可以引导LLM扩展固定深度Transformer的表达能力。实验表明，我们提出的方法可以实现

    Foundation models, such as Large language Models (LLMs), have attracted significant amount of interest due to their large number of applications. Existing works show that appropriate prompt design, such as Chain-of-Thoughts, can unlock LLM's powerful capacity in diverse areas. However, when handling tasks involving repetitive sub-tasks and/or deceptive contents, such as arithmetic calculation and article-level fake news detection, existing prompting strategies either suffers from insufficient expressive power or intermediate errors triggered by hallucination. To make LLM more discerning to such intermediate errors, we propose to guide LLM with a Divide-and-Conquer program that simultaneously ensures superior expressive power and disentangles task decomposition, sub-task resolution, and resolution assembly process. Theoretic analysis reveals that our strategy can guide LLM to extend the expressive power of fixed-depth Transformer. Experiments indicate that our proposed method can achiev
    
[^78]: 安全多模态学习系统调研

    A Survey on Safe Multi-Modal Learning System

    [https://arxiv.org/abs/2402.05355](https://arxiv.org/abs/2402.05355)

    这项研究提出了第一个多模态学习系统安全的分类法，对当前发展状态下的关键限制进行了审查，并提出了未来研究的潜在方向。

    

    随着多模态学习系统在现实场景中的广泛应用，安全问题变得越来越突出。对于这一领域的安全问题缺乏系统性研究已成为一个重要的障碍。为了解决这个问题，我们提出了第一个多模态学习系统安全的分类法，确定了这些问题的四个关键支柱。借助这一分类法，我们对每个支柱进行了深入审查，突出了当前发展状态的关键限制。最后，我们指出了多模态学习系统安全面临的独特挑战，并提供了未来研究的潜在方向。

    With the wide deployment of multimodal learning systems (MMLS) in real-world scenarios, safety concerns have become increasingly prominent. The absence of systematic research into their safety is a significant barrier to progress in this field. To bridge the gap, we present the first taxonomy for MMLS safety, identifying four essential pillars of these concerns. Leveraging this taxonomy, we conduct in-depth reviews for each pillar, highlighting key limitations based on the current state of development. Finally, we pinpoint unique challenges in MMLS safety and provide potential directions for future research.
    
[^79]: KIX: 一种元认知泛化框架

    KIX: A Metacognitive Generalization Framework

    [https://arxiv.org/abs/2402.05346](https://arxiv.org/abs/2402.05346)

    人工智能代理缺乏通用行为，需要利用结构化知识表示。该论文提出了一种元认知泛化框架KIX，通过与对象的交互学习可迁移的交互概念和泛化能力，促进了知识与强化学习的融合，为实现人工智能系统的自主和通用行为提供了潜力。

    

    人类和其他动物能够灵活解决各种任务，并且能够通过重复使用和应用长期积累的高级知识来适应新颖情境，这表现了一种泛化智能行为。但是人工智能代理更多地是专家，缺乏这种通用行为。人工智能代理需要理解和利用关键的结构化知识表示。我们提出了一种元认知泛化框架，称为Knowledge-Interaction-eXecution (KIX)，并且认为通过与对象的交互来利用类型空间可以促进学习可迁移的交互概念和泛化能力。这是将知识融入到强化学习中的一种自然方式，并有望成为人工智能系统中实现自主和通用行为的推广者。

    Humans and other animals aptly exhibit general intelligence behaviors in solving a variety of tasks with flexibility and ability to adapt to novel situations by reusing and applying high level knowledge acquired over time. But artificial agents are more of a specialist, lacking such generalist behaviors. Artificial agents will require understanding and exploiting critical structured knowledge representations. We present a metacognitive generalization framework, Knowledge-Interaction-eXecution (KIX), and argue that interactions with objects leveraging type space facilitate the learning of transferable interaction concepts and generalization. It is a natural way of integrating knowledge into reinforcement learning and promising to act as an enabler for autonomous and generalist behaviors in artificial intelligence systems.
    
[^80]: 在多模态图上学习：一项综述

    Learning on Multimodal Graphs: A Survey

    [https://arxiv.org/abs/2402.05322](https://arxiv.org/abs/2402.05322)

    这篇综述论文对多模态图学习的已有工作进行了对比分析，阐明了多模态学习的方式和主流技术特点，并揭示了其重要应用和未来方向。

    

    多模态数据广泛存在于各个领域，包括医疗保健、社交媒体和交通运输等，其中多模态图发挥着关键作用。机器学习在多模态图上的应用，被称为多模态图学习 (MGL)，对于成功的人工智能 (AI) 应用至关重要。这篇综述文章对多模态图学习中已有的工作进行了对比分析，阐明了在不同图类型上实现多模态学习的方式，并探索了主流学习技术的特点。此外，我们还揭示了多模态图学习的重要应用，并对该领域的未来方向提供了深入见解。因此，本文为希望了解现有 MGL 技术及其在不同场景中适用性的研究人员提供了基础资源。

    Multimodal data pervades various domains, including healthcare, social media, and transportation, where multimodal graphs play a pivotal role. Machine learning on multimodal graphs, referred to as multimodal graph learning (MGL), is essential for successful artificial intelligence (AI) applications. The burgeoning research in this field encompasses diverse graph data types and modalities, learning techniques, and application scenarios. This survey paper conducts a comparative analysis of existing works in multimodal graph learning, elucidating how multimodal learning is achieved across different graph types and exploring the characteristics of prevalent learning techniques. Additionally, we delineate significant applications of multimodal graph learning and offer insights into future directions in this domain. Consequently, this paper serves as a foundational resource for researchers seeking to comprehend existing MGL techniques and their applicability across diverse scenarios.
    
[^81]: 具有可解释模型和策略网络的神经符号强化学习的三个路径

    Three Pathways to Neurosymbolic Reinforcement Learning with Interpretable Model and Policy Networks

    [https://arxiv.org/abs/2402.05307](https://arxiv.org/abs/2402.05307)

    本文探讨了实现具有可解释性的模型和策略的神经符号强化学习的三个路径，并揭示了学习的连续性和可微性的益处，以及将逻辑与数值仿真结合的难点。

    

    神经符号人工智能将经典符号方法的可解释性、简约性和显式推理与数据驱动的神经方法的统计学习相结合。同时可微和可解释的模型和策略可能是这种结合的关键。本文在真实世界的强化学习环境中展示了实现这些模型和策略的三种路径。具体而言，我们研究了一类广泛的神经网络，这些网络在其架构中直接构建可解释的语义。我们揭示和强调了将逻辑、仿真和学习结合起来的潜力和基本困难。一个教训是学习受益于连续性和可微性，但经典逻辑是离散且不可微的。将逻辑松弛为实值的可微表示存在一个权衡；越可学习，越不可解释。另一个教训是在数值仿真环境中使用逻辑

    Neurosymbolic AI combines the interpretability, parsimony, and explicit reasoning of classical symbolic approaches with the statistical learning of data-driven neural approaches. Models and policies that are simultaneously differentiable and interpretable may be key enablers of this marriage. This paper demonstrates three pathways to implementing such models and policies in a real-world reinforcement learning setting. Specifically, we study a broad class of neural networks that build interpretable semantics directly into their architecture. We reveal and highlight both the potential and the essential difficulties of combining logic, simulation, and learning. One lesson is that learning benefits from continuity and differentiability, but classical logic is discrete and non-differentiable. The relaxation to real-valued, differentiable representations presents a trade-off; the more learnable, the less interpretable. Another lesson is that using logic in the context of a numerical simulati
    
[^82]: Sym-Q：通过顺序决策进行自适应符号回归

    Sym-Q: Adaptive Symbolic Regression via Sequential Decision-Making

    [https://arxiv.org/abs/2402.05306](https://arxiv.org/abs/2402.05306)

    Sym-Q是一个基于强化学习的模型，通过将符号回归重新定义为顺序决策任务来解决现有模型在泛化性和适应性方面的挑战。通过利用监督演示和奖励信号，Sym-Q能够根据拟合精度的质量改进表达式。

    

    符号回归具有从实证数据中揭示潜在数学和物理关系的巨大潜力。虽然现有的基于Transformer的模型在这个领域取得了显著成功，但它们在泛化性和适应性方面面临挑战。通常，当输出表达式不足以适应实验数据时，这些模型缺乏有效的机制来适应或修改表达式。这种缺乏灵活性限制了它们在实际场景中的应用，特别是在发现未知的物理或生物关系方面。受到人类专家如何改进和调整表达式的启发，我们引入了一种新颖的基于强化学习的模型Symbolic Q-network（Sym-Q），将符号回归重新定义为顺序决策任务。Sym-Q利用监督演示并根据奖励信号来改进表达式，奖励信号指示拟合精度的质量。它独特的能力可以处理复杂性。

    Symbolic regression holds great potential for uncovering underlying mathematical and physical relationships from empirical data. While existing transformer-based models have recently achieved significant success in this domain, they face challenges in terms of generalizability and adaptability. Typically, in cases where the output expressions do not adequately fit experimental data, the models lack efficient mechanisms to adapt or modify the expression. This inflexibility hinders their application in real-world scenarios, particularly in discovering unknown physical or biological relationships. Inspired by how human experts refine and adapt expressions, we introduce Symbolic Q-network (Sym-Q), a novel reinforcement learning-based model that redefines symbolic regression as a sequential decision-making task. Sym-Q leverages supervised demonstrations and refines expressions based on reward signals indicating the quality of fitting precision. Its distinctive ability to manage the complexi
    
[^83]: BIKED++：一个包含140万个自行车图像和参数化CAD设计的多模态数据集

    BIKED++: A Multimodal Dataset of 1.4 Million Bicycle Image and Parametric CAD Designs

    [https://arxiv.org/abs/2402.05301](https://arxiv.org/abs/2402.05301)

    本文介绍了BIKED++数据集，其中包含了140万个自行车设计的图像和参数化CAD文件。该数据集可以用于训练跨模态预测模型，例如使用参数化表示来准确估计图像的特征嵌入。该数据集也已公开，可供研究者使用。

    

    本文介绍了一个公开数据集，包含了140万个通过参数化表示和JSON文件以及栅格化图像生成的自行车设计。该数据集是通过渲染引擎和BikeCAD软件生成参数化设计的矢量图形而创建的。本文还公开了该渲染引擎。该数据集具有多种应用，其中一个主要目标是训练参数化和基于图像的设计表示之间的跨模态预测模型。例如，我们证明可以通过训练预测模型直接从参数化表示准确估计对比语言-图像预训练（CLIP）嵌入。这样可以建立参数化自行车设计与文本字符串或参考图像之间的相似关系。经过训练的预测模型也已公开。该数据集加入了BIKED数据集系列。

    This paper introduces a public dataset of 1.4 million procedurally-generated bicycle designs represented parametrically, as JSON files, and as rasterized images. The dataset is created through the use of a rendering engine which harnesses the BikeCAD software to generate vector graphics from parametric designs. This rendering engine is discussed in the paper and also released publicly alongside the dataset. Though this dataset has numerous applications, a principal motivation is the need to train cross-modal predictive models between parametric and image-based design representations. For example, we demonstrate that a predictive model can be trained to accurately estimate Contrastive Language-Image Pretraining (CLIP) embeddings from a parametric representation directly. This allows similarity relations to be established between parametric bicycle designs and text strings or reference images. Trained predictive models are also made public. The dataset joins the BIKED dataset family whic
    
[^84]: 使用凝聚层次聚类和基于主题的方法对垃圾邮件进行分类

    Classifying spam emails using agglomerative hierarchical clustering and a topic-based approach

    [https://arxiv.org/abs/2402.05296](https://arxiv.org/abs/2402.05296)

    该论文提出了使用凝聚层次聚类和基于主题的方法对垃圾邮件进行分类的新思路。作者提出了两个新的数据集SPEMC-15K-E和SPEMC-15K-S，并使用凝聚层次聚类将其划分为11个类别。实验结果表明，TF-IDF和LR在英文数据集中达到最佳性能。

    

    垃圾邮件是未经请求的恼人且有时有害的消息，可能含有恶意软件、钓鱼或恶作剧。与大多数研究解决高效反垃圾邮件过滤器设计的问题不同，我们从不同和新颖的角度来解决垃圾邮件问题。重点关注网络安全单位的需求，我们采用基于主题的方法来对垃圾邮件进行多类别分类。我们提出了两个新颖的数据集SPEMC-15K-E和SPEMC-15K-S，分别包含大约15K封英文和西班牙文邮件，并使用凝聚层次聚类将其划分为11个类别。我们评估了16种流水线，结合了四种文本表示技术-词频-逆文档频率（TF-IDF）、词袋模型、Word2Vec和BERT-以及四种分类器：支持向量机、朴素贝叶斯、随机森林和逻辑回归。实验结果表明，在英文数据集中，TF-IDF和LR的性能最好，

    Spam emails are unsolicited, annoying and sometimes harmful messages which may contain malware, phishing or hoaxes. Unlike most studies that address the design of efficient anti-spam filters, we approach the spam email problem from a different and novel perspective. Focusing on the needs of cybersecurity units, we follow a topic-based approach for addressing the classification of spam email into multiple categories. We propose SPEMC-15K-E and SPEMC-15K-S, two novel datasets with approximately 15K emails each in English and Spanish, respectively, and we label them using agglomerative hierarchical clustering into 11 classes. We evaluate 16 pipelines, combining four text representation techniques -Term Frequency-Inverse Document Frequency (TF-IDF), Bag of Words, Word2Vec and BERT- and four classifiers: Support Vector Machine, N\"aive Bayes, Random Forest and Logistic Regression. Experimental results show that the highest performance is achieved with TF-IDF and LR for the English dataset, 
    
[^85]: 一种量化特征选择和排序算法稳定性的信息论方法

    An information theoretic approach to quantify the stability of feature selection and ranking algorithms

    [https://arxiv.org/abs/2402.05295](https://arxiv.org/abs/2402.05295)

    本论文提出了一种基于信息论的方法来量化特征选择和排序算法的稳定性。该方法能够评估不同算法结果中的特征排序的稳定性，包括完整的排名列表、特征子集和部分排名列表。

    

    特征选择是处理高维数据时的关键步骤。特别是这些技术通过从嘈杂、冗余和无关的特征中选择最相关的特征，简化了从数据中发现知识的过程。在许多实际应用中出现的一个问题是特征选择算法的结果是不稳定的。因此，数据的微小变化可能导致非常不同的特征排序。在上述情况中，评估这些方法的稳定性成为一个重要问题。我们提出了一种基于Jensen Shannon距离的信息论方法来量化这种鲁棒性。与其他稳定性度量不同，这个度量指标适用于不同的算法结果：完整的排名列表、特征子集以及较少研究的部分排名列表。这个广义度量以概率方法量化了相同大小的整个列表集的差异，并提供了反映其中的排序稳定性的结果。

    Feature selection is a key step when dealing with high dimensional data. In particular, these techniques simplify the process of knowledge discovery from the data by selecting the most relevant features out of the noisy, redundant and irrelevant features. A problem that arises in many of these practical applications is that the outcome of the feature selection algorithm is not stable. Thus, small variations in the data may yield very different feature rankings. Assessing the stability of these methods becomes an important issue in the previously mentioned situations. We propose an information theoretic approach based on the Jensen Shannon divergence to quantify this robustness. Unlike other stability measures, this metric is suitable for different algorithm outcomes: full ranked lists, feature subsets as well as the lesser studied partial ranked lists. This generalized metric quantifies the difference among a whole set of lists with the same size, following a probabilistic approach and
    
[^86]: 检验医疗视觉和基于语言的疾病检测的多模态联邦学习中的模态不一致性

    Examining Modality Incongruity in Multimodal Federated Learning for Medical Vision and Language-based Disease Detection

    [https://arxiv.org/abs/2402.05294](https://arxiv.org/abs/2402.05294)

    本文首次分析了多模态联邦学习中的模态不一致性的影响，并揭示了其与参与客户端之间的数据异质性的联系。通过使用不考虑不一致性的信息融合机制和模态插值网络，在解决模态不一致性问题方面取得了一定的成果。

    

    多模态联邦学习（MMFL）利用每个客户端中的多个模态构建比其单模态对应物更强大的联邦学习（FL）模型。然而，不同客户端缺失模态的影响，也称为模态不一致性，一直被大大忽视。本文首次分析了模态不一致性的影响，并揭示了其与参与客户端之间的数据异质性的联系。我们特别检查了不一致的MMFL与单模态和多模态客户端相比是否更有益于单模态FL。此外，我们还研究了解决这个问题的三个潜在途径。首先，我们研究了各种自注意机制对于不考虑不一致性的信息融合在MMFL中的有效性。其次，我们在多模态客户端中引入了一个预先训练的模态插值网络（MIN）来解决单模态客户端中的模态翻译问题，并研究其减轻缺失模态问题的潜力。第三，我们...

    Multimodal Federated Learning (MMFL) utilizes multiple modalities in each client to build a more powerful Federated Learning (FL) model than its unimodal counterpart. However, the impact of missing modality in different clients, also called modality incongruity, has been greatly overlooked. This paper, for the first time, analyses the impact of modality incongruity and reveals its connection with data heterogeneity across participating clients. We particularly inspect whether incongruent MMFL with unimodal and multimodal clients is more beneficial than unimodal FL. Furthermore, we examine three potential routes of addressing this issue. Firstly, we study the effectiveness of various self-attention mechanisms towards incongruity-agnostic information fusion in MMFL. Secondly, we introduce a modality imputation network (MIN) pre-trained in a multimodal client for modality translation in unimodal clients and investigate its potential towards mitigating the missing modality problem. Thirdly
    
[^87]: 一项关于结直肠癌风险预测模型特征选择的比较研究

    A comparative study on feature selection for a risk prediction model for colorectal cancer

    [https://arxiv.org/abs/2402.05293](https://arxiv.org/abs/2402.05293)

    这项研究比较了不同特征选择算法在结直肠癌风险预测模型中的性能，并提出了视觉方法评估特征排序技术的稳定性。

    

    背景和目标  风险预测模型旨在识别患上某种疾病风险更高的人群。特征选择对于改善预测模型的性能、避免过拟合以及识别导致癌症风险（和保护）的因素尤为重要。对特征选择/排序算法的稳定性评估成为分析具有更多预测能力特征的重要问题。方法 本研究集中在结直肠癌上，评估了几种特征排序算法在一组风险预测模型（神经网络、支持向量机（SVM）、逻辑回归、k-最近邻和提升树）方面的性能。此外，使用标量稳定度指标和本文提出的视觉方法评估了其稳定性，既可以研究特征排序技术之间的相似性，也可以研究它们的单独稳定性。

    Background and objective   Risk prediction models aim at identifying people at higher risk of developing a target disease. Feature selection is particularly important to improve the prediction model performance avoiding overfitting and to identify the leading cancer risk (and protective) factors. Assessing the stability of feature selection/ranking algorithms becomes an important issue when the aim is to analyze the features with more prediction power. Methods   This work is focused on colorectal cancer, assessing several feature ranking algorithms in terms of performance for a set of risk prediction models (Neural Networks, Support Vector Machines (SVM), Logistic Regression, k-Nearest Neighbors and Boosted Trees). Additionally, their robustness is evaluated following a conventional approach with scalar stability metrics and a visual approach proposed in this work to study both similarity among feature ranking techniques as well as their individual stability. A comparative analysis is 
    
[^88]: 变形器世界模型是否可以给出更好的策略梯度？

    Do Transformer World Models Give Better Policy Gradients?

    [https://arxiv.org/abs/2402.05290](https://arxiv.org/abs/2402.05290)

    在强化学习中，通过使用变形器世界模型来预测未来奖励并进行策略梯度学习通常变得不可行。研究人员发现常用的变形器世界模型会产生迂回的梯度路径，对于长距离的策略梯度是有害的。为了解决这个问题，他们提出了一种名为Actions World Models (AWMs)的世界模型，可以提供更直接的梯度传播路径。

    

    对于强化学习来说，一种自然的方法是通过展开神经网络世界模型来预测未来的奖励，并通过计算图进行反向传播以学习策略。然而，由于典型的世界模型产生了难以优化的损失地形，这种方法在长时间跨度上通常变得不可行。变形器已知可以高效地传播长时间跨度的梯度：它们是否可以解决这个问题呢？令人惊讶的是，我们发现常用的变形器世界模型会产生迂回的梯度路径，这对于长距离的策略梯度是有害的。为了应对这个挑战，我们提出了一类称为Actions World Models (AWMs)的世界模型，旨在提供更直接的梯度传播路径。我们将这种AWMs集成到一个策略梯度的框架中，强调了网络架构与策略梯度更新之间的关系。我们证明了AWMs可以产生可优化的梯度路径。

    A natural approach for reinforcement learning is to predict future rewards by unrolling a neural network world model, and to backpropagate through the resulting computational graph to learn a policy. However, this method often becomes impractical for long horizons since typical world models induce hard-to-optimize loss landscapes. Transformers are known to efficiently propagate gradients overlong horizons: could they be the solution to this problem? Surprisingly, we show that commonly-used transformer world models produce circuitous gradient paths, which can be detrimental to long-range policy gradients. To tackle this challenge, we propose a class of world models called Actions World Models (AWMs), designed to provide more direct routes for gradient propagation. We integrate such AWMs into a policy gradient framework that underscores the relationship between network architectures and the policy gradient updates they inherently represent. We demonstrate that AWMs can generate optimizat
    
[^89]: 梯度下降引发了深度非线性网络权重与经验NTK之间的对齐

    Gradient descent induces alignment between weights and the empirical NTK for deep non-linear networks

    [https://arxiv.org/abs/2402.05271](https://arxiv.org/abs/2402.05271)

    了解神经网络从输入-标签对中提取统计信息的机制是监督学习中最重要的未解决问题之一。前人的研究表明，在训练过程中，权重的格拉姆矩阵与模型的平均梯度外积成正比，这被称为神经特征分析（NFA）。本研究解释了这种相关性的出现，并发现NFA等价于权重矩阵的左奇异结构与与这些权重相关的经验神经切线核的显著成分之间的对齐。在早期训练阶段，可以通过解析的方式预测NFA的发展速度。

    

    理解神经网络从输入-标签对中提取统计信息的机制是监督学习中最重要的未解决问题之一。先前的研究已经确定，在一般结构的训练神经网络中，权重的格拉姆矩阵与模型的平均梯度外积成正比，这个说法被称为神经特征分析（NFA）。然而，这些数量在训练过程中如何相关尚不清楚。在这项工作中，我们解释了这种相关性的出现。我们发现NFA等价于权重矩阵的左奇异结构与与这些权重相关的经验神经切线核的显著成分之间的对齐。我们证明了先前研究中引入的NFA是由隔离这种对齐的中心化NFA驱动的。我们还展示了在早期训练阶段，可以通过解析的方式预测NFA的发展速度。

    Understanding the mechanisms through which neural networks extract statistics from input-label pairs is one of the most important unsolved problems in supervised learning. Prior works have identified that the gram matrices of the weights in trained neural networks of general architectures are proportional to the average gradient outer product of the model, in a statement known as the Neural Feature Ansatz (NFA). However, the reason these quantities become correlated during training is poorly understood. In this work, we explain the emergence of this correlation. We identify that the NFA is equivalent to alignment between the left singular structure of the weight matrices and a significant component of the empirical neural tangent kernels associated with those weights. We establish that the NFA introduced in prior works is driven by a centered NFA that isolates this alignment. We show that the speed of NFA development can be predicted analytically at early training times in terms of sim
    
[^90]: 通过可微分优化有序加权平均值学习公平排名策略

    Learning Fair Ranking Policies via Differentiable Optimization of Ordered Weighted Averages

    [https://arxiv.org/abs/2402.05252](https://arxiv.org/abs/2402.05252)

    本文介绍了一种通过优化有序加权平均值函数，在LTR模型的训练过程中集成高效的公平排名模型，实现公平性、用户效用和运行时效率之间的有利平衡。

    

    学习排序（LTR）是最广泛使用的机器学习应用之一。它是具有深远社会影响的平台的关键组成部分，包括求职搜索、医疗信息检索和社交媒体内容推送。传统的LTR模型已经显示出产生偏见结果，引发了如何解决仅优先考虑用户相关性的排名系统引入的差异的讨论。然而，虽然已经提出了几种公平学习排序模型，但它们在准确性或效率方面存在缺陷，从而限制了它们在实际排名平台中的适用性。本文展示了如何将基于有序加权平均（OWA）函数的高效可解的公平排名模型集成到LTR模型的训练循环中，以实现公平性、用户效用和运行时效率之间的有利平衡。特别是，本文首次展示了如何通过约束优化反向传播。

    Learning to Rank (LTR) is one of the most widely used machine learning applications. It is a key component in platforms with profound societal impacts, including job search, healthcare information retrieval, and social media content feeds. Conventional LTR models have been shown to produce biases results, stimulating a discourse on how to address the disparities introduced by ranking systems that solely prioritize user relevance. However, while several models of fair learning to rank have been proposed, they suffer from deficiencies either in accuracy or efficiency, thus limiting their applicability to real-world ranking platforms. This paper shows how efficiently-solvable fair ranking models, based on the optimization of Ordered Weighted Average (OWA) functions, can be integrated into the training loop of an LTR model to achieve favorable balances between fairness, user utility, and runtime efficiency. In particular, this paper is the first to show how to backpropagate through constra
    
[^91]: 通用神经功能

    Universal Neural Functionals

    [https://arxiv.org/abs/2402.05232](https://arxiv.org/abs/2402.05232)

    本文提出了通用神经功能（UNFs），一种能够自动构建适用于任何权重空间的置换等变模型的算法。实验结果显示，在优化小型图像分类器和语言模型时，UNFs能够取得有希望的改进，为学习优化器设计提供了新的思路。

    

    在现代许多机器学习任务中，一个具有挑战性的问题是处理权重空间特征，即从神经网络的权重和梯度中转换或提取信息。最近的研究已经开发出了一些有希望的权重空间模型，这些模型对简单的前馈网络的置换对称性是等变的。然而，它们对于普通架构并不适用，因为权重空间的置换对称性可能会因循环或残差连接而变得复杂。本文提出了一种算法，自动构建置换等变模型，我们称之为通用神经功能（UNFs），适用于任何权重空间。在其他应用中，我们展示了如何将UNFs替代现有的学习优化器设计，并在优化小型图像分类器和语言模型时发现有希望的改进。我们的结果表明，学习优化器可以从考虑（对称）结构的角度受益。

    A challenging problem in many modern machine learning tasks is to process weight-space features, i.e., to transform or extract information from the weights and gradients of a neural network. Recent works have developed promising weight-space models that are equivariant to the permutation symmetries of simple feedforward networks. However, they are not applicable to general architectures, since the permutation symmetries of a weight space can be complicated by recurrence or residual connections. This work proposes an algorithm that automatically constructs permutation equivariant models, which we refer to as universal neural functionals (UNFs), for any weight space. Among other applications, we demonstrate how UNFs can be substituted into existing learned optimizer designs, and find promising improvements over prior methods when optimizing small image classifiers and language models. Our results suggest that learned optimizers can benefit from considering the (symmetry) structure of the
    
[^92]: VerAs: 验证然后评估STEM实验报告

    VerAs: Verify then Assess STEM Lab Reports

    [https://arxiv.org/abs/2402.05224](https://arxiv.org/abs/2402.05224)

    VerAs是一个端到端的神经架构，用于验证和评估STEM实验报告。它通过利用多个维度的分析评估标准，以及针对学生提供详细反馈，帮助他们提高科学写作技巧。

    

    随着STEM教育对批判性思维能力的日益关注，科学写作在注重探究技能的课程中发挥着越来越重要的作用。最近发布的一份数据集是基于一套探究型物理课程的两组大学水平的实验报告，依赖于利用多个维度的分析评估标准，指定学科知识和优秀解释的一般组成部分。每个分析维度都以6分制进行评估，以提供详细反馈，帮助学生提高科学写作技巧。手动评估可能较慢，并且在大班中对所有学生进行一致性校准可能很困难。尽管在STEM学科的开放性问题的自动评估上已经有很多工作，但在实验报告等长篇写作中的工作要少得多。我们提出了一个端到端的神经架构，其中包括独立的验证器和评估模块，灵感来源于开放领域问题回答的方法。

    With an increasing focus in STEM education on critical thinking skills, science writing plays an ever more important role in curricula that stress inquiry skills. A recently published dataset of two sets of college level lab reports from an inquiry-based physics curriculum relies on analytic assessment rubrics that utilize multiple dimensions, specifying subject matter knowledge and general components of good explanations. Each analytic dimension is assessed on a 6-point scale, to provide detailed feedback to students that can help them improve their science writing skills. Manual assessment can be slow, and difficult to calibrate for consistency across all students in large classes. While much work exists on automated assessment of open-ended questions in STEM subjects, there has been far less work on long-form writing such as lab reports. We present an end-to-end neural architecture that has separate verifier and assessment modules, inspired by approaches to Open Domain Question Answ
    
[^93]: 采样温度对大型语言模型在解题中的影响

    The Effect of Sampling Temperature on Problem Solving in Large Language Models

    [https://arxiv.org/abs/2402.05201](https://arxiv.org/abs/2402.05201)

    这项研究实证研究了采样温度对大型语言模型在解题中的影响，结果显示在0.0至1.0的温度范围内，LLM性能对解题任务没有显著影响。

    

    在这项研究中，我们通过实证研究调查了采样温度对大型语言模型（LLMs）在各种解题任务中的性能影响。我们通过从标准LLM基准中随机抽取问题，创建了一个多项选择问题（MCQA）考试。然后，我们使用了四种常见的LLM以及五种提示引擎技术来解决MCQA问题，同时将采样温度从0.0增加到1.0。尽管有关的报道与之相反，我们的实证结果表明，在0.0至1.0的温度范围内，LLM性能在解题任务中的变化没有统计学上显著的影响。此外，这些结果似乎不受LLM、提示引擎技术或问题领域的影响。所有代码、数据和补充资料都可以在GitHub上找到：https://github.com/matthewrenze/jhu-llm-temperature。

    In this research study, we empirically investigate the effect of sampling temperature on the performance of Large Language Models (LLMs) on various problem-solving tasks. We created a multiple-choice question-and-answer (MCQA) exam by randomly sampling problems from standard LLM benchmarks. Then, we used four popular LLMs with five prompt-engineering techniques to solve the MCQA problems while increasing the sampling temperature from 0.0 to 1.0. Despite anecdotal reports to the contrary, our empirical results indicate that changes in temperature in the range 0.0 to 1.0 do not have a statistically significant impact on LLM performance for problem-solving tasks. In addition, these results appear to hold regardless of the LLM, the prompt-engineering technique, or the problem domain. All code, data, and supplemental materials are available on GitHub at: https://github.com/matthewrenze/jhu-llm-temperature.
    
[^94]: LLMs是否准备好应用于真实世界的材料发现？

    Are LLMs Ready for Real-World Materials Discovery?

    [https://arxiv.org/abs/2402.05200](https://arxiv.org/abs/2402.05200)

    LLMs在材料科学中的应用受限，无法实现实际应用。我们提出了基于材料科学知识和假设测试的MatSci-LLMs框架，并描述了关键的材料科学信息提取挑战。

    

    大型语言模型（LLMs）为材料科学中的强大语言处理工具提供了令人兴奋的可能性，加快了材料研究的进展。然而，LLMs在实际应用中仍存在不足，无法成为实用的材料科学工具。本文通过展示LLMs在材料科学中的相关失败案例，揭示了LLMs在理解和推理复杂、相互关联的材料科学知识方面的现有限制。鉴于这些缺点，我们提出了一种开发基于材料科学知识和假设生成与测试的材料科学LLMs（MatSci-LLMs）的框架。实现高性能的MatSci-LLMs的路径在很大程度上取决于建立高质量的多模态数据集，这些数据集来自科学文献，其中存在各种信息提取挑战。因此，我们描述了关键的材料科学信息提取挑战。

    Large Language Models (LLMs) create exciting possibilities for powerful language processing tools to accelerate research in materials science. While LLMs have great potential to accelerate materials understanding and discovery, they currently fall short in being practical materials science tools. In this position paper, we show relevant failure cases of LLMs in materials science that reveal current limitations of LLMs related to comprehending and reasoning over complex, interconnected materials science knowledge. Given those shortcomings, we outline a framework for developing Materials Science LLMs (MatSci-LLMs) that are grounded in materials science knowledge and hypothesis generation followed by hypothesis testing. The path to attaining performant MatSci-LLMs rests in large part on building high-quality, multi-modal datasets sourced from scientific literature where various information extraction challenges persist. As such, we describe key materials science information extraction cha
    
[^95]: InCoRo：带有反馈循环的上下文学习用于机器人控制

    InCoRo: In-Context Learning for Robotics Control with Feedback Loops

    [https://arxiv.org/abs/2402.05188](https://arxiv.org/abs/2402.05188)

    本文提出了InCoRo系统，使用经典的机器人反馈循环，通过LLM控制器、场景理解单元和机器人的协同工作，实现对动态环境中机器人控制的上下文学习。该系统能够持续分析环境状态并提供适应性执行命令，使机器人能够适应环境变化并纠正控制器错误。

    

    机器人技术的一个挑战是使机器人具备足够强大的推理能力，能够在动态环境中执行复杂任务。最近的LLM进展将它们定位为简单推理任务的首选工具，激发了Liang等人的开创性工作[35]，该工作使用LLM将自然语言命令转化为机器人单位的低级静态执行计划。在机器人系统中使用LLM将其泛化能力提升到一个新的水平，实现了对新任务的零样本泛化。本文将这项先前工作扩展到了动态环境。我们提出了InCoRo，一个使用经典的机器人反馈循环的系统，由LLM控制器、场景理解单元和机器人组成。我们的系统持续分析环境状态并提供适应性执行命令，使机器人能够适应不断变化的环境条件并纠正控制器错误。我们的系统不需要任何迭代设计。

    One of the challenges in robotics is to enable robotic units with the reasoning capability that would be robust enough to execute complex tasks in dynamic environments. Recent advances in LLMs have positioned them as go-to tools for simple reasoning tasks, motivating the pioneering work of Liang et al. [35] that uses an LLM to translate natural language commands into low-level static execution plans for robotic units. Using LLMs inside robotics systems brings their generalization to a new level, enabling zero-shot generalization to new tasks. This paper extends this prior work to dynamic environments. We propose InCoRo, a system that uses a classical robotic feedback loop composed of an LLM controller, a scene understanding unit, and a robot. Our system continuously analyzes the state of the environment and provides adapted execution commands, enabling the robot to adjust to changing environmental conditions and correcting for controller errors. Our system does not require any iterativ
    
[^96]: 神经缩放律的资源模型

    A Resource Model For Neural Scaling Law

    [https://arxiv.org/abs/2402.05164](https://arxiv.org/abs/2402.05164)

    该论文介绍了神经缩放律的资源模型，通过观察实证发现，子任务的损失与分配的神经元成反比，复合任务中子任务获得的资源随模型变大而增长，保持资源比例不变。该模型可以用于预测复合任务的神经缩放律，并成功复制了Chinchilla模型的神经缩放律。该资源模型是表征和诊断神经网络的有用工具。

    

    神经缩放律描述了随着模型规模的增大，模型性能如何提高。受实证观察启发，我们引入了神经缩放的资源模型。一个任务通常是复合任务，可以分解为许多子任务，这些子任务竞争资源（以分配给子任务的神经元数量来衡量）。在玩具问题上，我们经验证实：（1）子任务的损失与其分配的神经元成反比。（2）当复合任务中存在多个子任务时，随着模型变大，每个子任务获得的资源均匀增长，保持获得资源的比例不变。我们假设这些发现在一般情况下是有效的，并建立了一个模型来预测一般复合任务的神经缩放律，并成功复制了arXiv:2203.15556中报告的Chinchilla模型的神经缩放律。我们相信本文中使用的资源概念将是表征和诊断神经网络的有用工具。

    Neural scaling laws characterize how model performance improves as the model size scales up. Inspired by empirical observations, we introduce a resource model of neural scaling. A task is usually composite hence can be decomposed into many subtasks, which compete for resources (measured by the number of neurons allocated to subtasks). On toy problems, we empirically find that: (1) The loss of a subtask is inversely proportional to its allocated neurons. (2) When multiple subtasks are present in a composite task, the resources acquired by each subtask uniformly grow as models get larger, keeping the ratios of acquired resources constants. We hypothesize these findings to be generally true and build a model to predict neural scaling laws for general composite tasks, which successfully replicates the neural scaling law of Chinchilla models reported in arXiv:2203.15556. We believe that the notion of resource used in this paper will be a useful tool for characterizing and diagnosing neural 
    
[^97]: 通过修剪和低秩修改评估安全对齐的易碎性

    Assessing the Brittleness of Safety Alignment via Pruning and Low-Rank Modifications

    [https://arxiv.org/abs/2402.05162](https://arxiv.org/abs/2402.05162)

    本研究通过修剪和低秩修改，发现大型语言模型（LLMs）的安全机制固有易碎性，去除安全关键区域会损害安全性，但对效用影响不大，需要更强健的安全策略。

    

    大型语言模型（LLMs）在其安全机制方面表现出固有的易碎性，这可从它们易受越狱和即使是非恶意微调也易受影响来说明。本研究通过利用修剪和低秩修改探讨了安全对齐的易碎性。我们开发了方法，能够识别对于安全防护至关重要，且在神经元和秩级别上与效用相关的区域。令人惊讶的是，我们发现的孤立区域是稀疏的，约占参数级别的$3\%$和排名级别的$2.5\%$。去除这些区域会损害安全性，而对效用的影响不大，从而证实了该模型安全机制的固有易碎性。此外，我们还表明，即使限制对安全关键区域进行修改，LLMs仍然容易受到低成本的微调攻击。这些发现强调了在LLMs中更强大的安全策略的紧迫性需求。

    Large language models (LLMs) show inherent brittleness in their safety mechanisms, as evidenced by their susceptibility to jailbreaking and even non-malicious fine-tuning. This study explores this brittleness of safety alignment by leveraging pruning and low-rank modifications. We develop methods to identify critical regions that are vital for safety guardrails, and that are disentangled from utility-relevant regions at both the neuron and rank levels. Surprisingly, the isolated regions we find are sparse, comprising about $3\%$ at the parameter level and $2.5\%$ at the rank level. Removing these regions compromises safety without significantly impacting utility, corroborating the inherent brittleness of the model's safety mechanisms. Moreover, we show that LLMs remain vulnerable to low-cost fine-tuning attacks even when modifications to the safety-critical regions are restricted. These findings underscore the urgent need for more robust safety strategies in LLMs.
    
[^98]: AI的文档化情况如何？对32,000份AI模型卡进行系统分析

    What's documented in AI? Systematic Analysis of 32K AI Model Cards

    [https://arxiv.org/abs/2402.05160](https://arxiv.org/abs/2402.05160)

    本研究对Hugging Face平台上的32,111份AI模型文档进行了全面分析，发现大多数模型提供了模型卡，但信息量不一致。有关环境影响、限制和评估的部分填写率最低，训练部分则填写率最高。

    

    AI模型的迅速增加突显了充分的文档化的重要性，因为这样可以使用户了解、信任并有效地利用这些模型在各种应用中。虽然开发者鼓励制作模型卡，但目前还不清楚这些卡包含多少信息或者包含哪些信息。在这项研究中，我们对Hugging Face平台上的32,111份AI模型文档进行了全面分析，该平台是分发和部署AI模型的领先平台。我们的调查揭示了普遍的模型卡文档化实践。大多数下载量较大的AI模型提供了模型卡，但这些卡的信息量不一致。我们发现，有关环境影响、限制和评估的部分填写率最低，而训练部分则是填写得最全面的部分。我们对每个部分的内容进行分析，以了解从业者的重点关注内容。有趣的是，有相当多的模型卡在相关部分存在较大的空白。

    The rapid proliferation of AI models has underscored the importance of thorough documentation, as it enables users to understand, trust, and effectively utilize these models in various applications. Although developers are encouraged to produce model cards, it's not clear how much information or what information these cards contain. In this study, we conduct a comprehensive analysis of 32,111 AI model documentations on Hugging Face, a leading platform for distributing and deploying AI models. Our investigation sheds light on the prevailing model card documentation practices. Most of the AI models with substantial downloads provide model cards, though the cards have uneven informativeness. We find that sections addressing environmental impact, limitations, and evaluation exhibit the lowest filled-out rates, while the training section is the most consistently filled-out. We analyze the content of each section to characterize practitioners' priorities. Interestingly, there are substantial
    
[^99]: 提高孟加拉OCR的专用模型和先进技术在不同类型文档中的应用

    Enhancement of Bengali OCR by Specialized Models and Advanced Techniques for Diverse Document Types

    [https://arxiv.org/abs/2402.05158](https://arxiv.org/abs/2402.05158)

    本文介绍了一个孟加拉OCR系统，具有重构文档布局、精确提取、多样化文档类型支持和优化字符与单词识别的特点。

    

    本研究论文介绍了一个独特的孟加拉OCR系统，该系统具有一些能力。该系统在保留结构、对齐和图像的同时，优秀地重构文档布局。它结合了先进的图像和签名检测技术，以进行精确的提取。针对包括计算机排版、凸版印刷、打字机和手写文档在内的不同类型文档，该系统还包括了专门的单词分割模型。该系统能够处理静态和动态手写输入，并识别各种书写风格。此外，它还能够识别孟加拉复合字符。通过广泛的数据收集工作，提供了多样化的语料库，而先进的技术组件则优化了字符和单词识别。其他贡献包括图像、标志、签名和表格识别、透视校正、布局重建以及用于高效可扩展处理的排队模块。该系统在高效准确的文本提取方面表现出色。

    This research paper presents a unique Bengali OCR system with some capabilities. The system excels in reconstructing document layouts while preserving structure, alignment, and images. It incorporates advanced image and signature detection for accurate extraction. Specialized models for word segmentation cater to diverse document types, including computer-composed, letterpress, typewriter, and handwritten documents. The system handles static and dynamic handwritten inputs, recognizing various writing styles. Furthermore, it has the ability to recognize compound characters in Bengali. Extensive data collection efforts provide a diverse corpus, while advanced technical components optimize character and word recognition. Additional contributions include image, logo, signature and table recognition, perspective correction, layout reconstruction, and a queuing module for efficient and scalable processing. The system demonstrates outstanding performance in efficient and accurate text extract
    
[^100]: 数据如何？关于AI系统数据工程的映射研究

    What About the Data? A Mapping Study on Data Engineering for AI Systems

    [https://arxiv.org/abs/2402.05156](https://arxiv.org/abs/2402.05156)

    本文通过进行一项关于AI系统数据工程的映射研究，提出了关于AI数据工程活动的生命周期阶段，技术解决方案和架构以及经验教训。

    

    AI系统离不开数据。现在，随着AI模型（数据科学和AI）的成熟，并可以实际应用，大部分组织在数据基础设施方面遇到了困难。需要了解如何为AI系统准备数据的数据工程师或可以为分析项目设置企业级数据架构的工程师越来越多。然而，在过去，AI工程的数据工程部分没有得到太多关注，而更多讨论建模部分。本文旨在通过进行一项关于AI系统数据工程的映射研究（即AI数据工程）来改变这种情况。我们在2019年1月至2023年6月之间找到了25篇相关论文，解释了AI数据工程活动。我们确定了涵盖的生命周期阶段，提出的技术解决方案或架构以及所呈现的经验教训。最后，我们对论文进行了整体讨论，并对从业者和研究人员提出了一些启示。

    AI systems cannot exist without data. Now that AI models (data science and AI) have matured and are readily available to apply in practice, most organizations struggle with the data infrastructure to do so. There is a growing need for data engineers that know how to prepare data for AI systems or that can setup enterprise-wide data architectures for analytical projects. But until now, the data engineering part of AI engineering has not been getting much attention, in favor of discussing the modeling part. In this paper we aim to change this by perform a mapping study on data engineering for AI systems, i.e., AI data engineering. We found 25 relevant papers between January 2019 and June 2023, explaining AI data engineering activities. We identify which life cycle phases are covered, which technical solutions or architectures are proposed and which lessons learned are presented. We end by an overall discussion of the papers with implications for practitioners and researchers. This paper 
    
[^101]: 自适应超图网络用于信任预测

    Adaptive Hypergraph Network for Trust Prediction

    [https://arxiv.org/abs/2402.05154](https://arxiv.org/abs/2402.05154)

    本文提出了一种自适应超图网络（AHNTP）方法，通过利用高阶相关性来改善信任预测的准确性。AHNTP利用基于模式的PageRank来捕捉高阶社交影响信息，并通过构建超群从节点级和结构级属性融入复杂的相关信息。

    

    信任在个体的决策过程中起着至关重要的作用。传统的信任预测模型依赖于配对相关性来推断用户之间的潜在关系。然而，在现实世界中，用户之间的互动通常是复杂的，不仅仅是配对关系。超图提供了一种灵活的方法来建模这些复杂的高阶关联关系，因为超图可以利用超边来连接两个以上的节点。然而，大多数基于超图的方法是通用的，不能很好地应用到信任预测任务中。在本文中，我们提出了一种用于信任预测的自适应超图网络（AHNTP）的新方法，通过使用高阶相关性来提高信任预测的准确性。AHNTP利用基于模式的PageRank来捕捉高阶社交影响信息。另外，它还从节点级和结构级属性构建超群，以融入复杂的相关信息。

    Trust plays an essential role in an individual's decision-making. Traditional trust prediction models rely on pairwise correlations to infer potential relationships between users. However, in the real world, interactions between users are usually complicated rather than pairwise only. Hypergraphs offer a flexible approach to modeling these complex high-order correlations (not just pairwise connections), since hypergraphs can leverage hyperedeges to link more than two nodes. However, most hypergraph-based methods are generic and cannot be well applied to the trust prediction task. In this paper, we propose an Adaptive Hypergraph Network for Trust Prediction (AHNTP), a novel approach that improves trust prediction accuracy by using higher-order correlations. AHNTP utilizes Motif-based PageRank to capture high-order social influence information. In addition, it constructs hypergroups from both node-level and structure-level attributes to incorporate complex correlation information. Furthe
    
[^102]: CrashFormer: 一种多模态架构用于预测事故风险

    CrashFormer: A Multimodal Architecture to Predict the Risk of Crash

    [https://arxiv.org/abs/2402.05151](https://arxiv.org/abs/2402.05151)

    CrashFormer是一种多模态架构，利用全面的输入数据（如事故历史、天气信息、地图图像和人口信息），可以每6小时预测5.161平方公里地理范围内的未来事故风险。

    

    减少交通事故是一个至关重要的全球公共安全问题。事故预测对于提高交通安全至关重要，可以在事故发生之前采取积极的措施，并提供安全政策、法规和有针对性的干预措施的信息。尽管过去几十年进行了许多关于事故预测的研究，但由于输入数据或问题形式的限制，许多研究在可推广性、可重现性或实际应用上存在局限性。为了解决现有的缺点，我们提出了CrashFormer，这是一种多模态架构，利用全面（但相对容易获取）的输入数据，如事故历史、天气信息、地图图像和人口信息。该模型可以以相对可接受的频率（即每6小时）预测5.161平方公里地理范围内的未来事故风险。CrashFormer由五个组成部分组成：序列编码器用于利用历史事故和天气数据。

    Reducing traffic accidents is a crucial global public safety concern. Accident prediction is key to improving traffic safety, enabling proactive measures to be taken before a crash occurs, and informing safety policies, regulations, and targeted interventions. Despite numerous studies on accident prediction over the past decades, many have limitations in terms of generalizability, reproducibility, or feasibility for practical use due to input data or problem formulation. To address existing shortcomings, we propose CrashFormer, a multi-modal architecture that utilizes comprehensive (but relatively easy to obtain) inputs such as the history of accidents, weather information, map images, and demographic information. The model predicts the future risk of accidents on a reasonably acceptable cadence (i.e., every six hours) for a geographical location of 5.161 square kilometers. CrashFormer is composed of five components: a sequential encoder to utilize historical accidents and weather data
    
[^103]: FlowPG: 使用正则化流的动作约束策略梯度

    FlowPG: Action-constrained Policy Gradient with Normalizing Flows

    [https://arxiv.org/abs/2402.05149](https://arxiv.org/abs/2402.05149)

    本文提出了使用正则化流的动作约束策略梯度（FlowPG）方法，以解决动作约束强化学习中的挑战。该方法通过学习一个可逆映射和开发多种动作采样方法，有效地解决了在每个强化学习步骤中确保代理采取合理动作的问题。

    

    动作约束强化学习（ACRL）是解决安全关键和资源分配相关决策问题的常用方法。ACRL的一个主要挑战是确保代理在每个强化学习步骤中采取满足约束条件的有效动作。通常使用在策略网络之上的投影层的方法需要解决一个优化问题，这可能导致训练时间较长、收敛速度慢和零梯度问题。为了解决这个问题，我们首先使用正则化流模型学习一个可逆的、可微分的映射，将可行动作空间映射到一个潜变量上的简单分布的支撑集合，例如高斯分布。其次，学习流模型需要从可行动作空间中进行采样，这也是一个具有挑战性的问题。我们开发了多种方法，基于哈密顿蒙特卡洛和概率表决图，用于凸约束和非凸约束下的动作采样。接下来，我们将学习的流模型与强化学习的策略网络相整合。

    Action-constrained reinforcement learning (ACRL) is a popular approach for solving safety-critical and resource-allocation related decision making problems. A major challenge in ACRL is to ensure agent taking a valid action satisfying constraints in each RL step. Commonly used approach of using a projection layer on top of the policy network requires solving an optimization program which can result in longer training time, slow convergence, and zero gradient problem. To address this, first we use a normalizing flow model to learn an invertible, differentiable mapping between the feasible action space and the support of a simple distribution on a latent variable, such as Gaussian. Second, learning the flow model requires sampling from the feasible action space, which is also challenging. We develop multiple methods, based on Hamiltonian Monte-Carlo and probabilistic sentential decision diagrams for such action sampling for convex and non-convex constraints. Third, we integrate the learn
    
[^104]: 模块化电解植物的成本优化调度

    Cost Optimized Scheduling in Modular Electrolysis Plants

    [https://arxiv.org/abs/2402.05148](https://arxiv.org/abs/2402.05148)

    本文提出了一种基于交替方向乘子方法的分散式调度模型，以优化模块化电解植物的运营。该模型旨在平衡氢气产量和波动需求，以最小化边际化氢气成本，并确保适应运营干扰。

    

    针对全球转向可再生能源的趋势，通过电解产生绿色氢气正在成为一种有前途的解决方案。设计具有灵活性和可扩展性的模块化电解植物，在适应可再生能源波动的同时，为氢气日益增长的需求提供动态响应。然而，优化它们的运营是具有挑战性的，特别是当需要协调大量可能具有不同特性的电解模块时。为了解决这些挑战，本文提出了一种基于交替方向乘子方法的分散式调度模型，以优化模块化电解植物的运营。该模型旨在平衡氢气产量和波动需求，以最小化边际化氢气成本，并确保适应运营干扰。一个案例研究验证了该模型在计算边际化氢气成本方面的准确性。

    In response to the global shift towards renewable energy resources, the production of green hydrogen through electrolysis is emerging as a promising solution. Modular electrolysis plants, designed for flexibility and scalability, offer a dynamic response to the increasing demand for hydrogen while accommodating the fluctuations inherent in renewable energy sources. However, optimizing their operation is challenging, especially when a large number of electrolysis modules needs to be coordinated, each with potentially different characteristics.   To address these challenges, this paper presents a decentralized scheduling model to optimize the operation of modular electrolysis plants using the Alternating Direction Method of Multipliers. The model aims to balance hydrogen production with fluctuating demand, to minimize the marginal Levelized Cost of Hydrogen (mLCOH), and to ensure adaptability to operational disturbances. A case study validates the accuracy of the model in calculating mLC
    
[^105]: 用动态结构化剪枝方法压缩深度强化学习网络，用于自动驾驶

    Compressing Deep Reinforcement Learning Networks with a Dynamic Structured Pruning Method for Autonomous Driving

    [https://arxiv.org/abs/2402.05146](https://arxiv.org/abs/2402.05146)

    本文提出了一种动态结构化剪枝方法，用于压缩深度强化学习网络，以便在资源受限的自动驾驶设备中实现高效部署。通过逐渐删除不重要的神经元，我们的方法显著减小了内存消耗和计算量。

    

    深度强化学习在复杂的自动驾驶场景中取得了显著的成功。然而，深度强化学习模型不可避免地带来了高内存消耗和计算量，这阻碍了它们在资源受限的自动驾驶设备中的广泛应用。结构化剪枝被认为是一种有用的方法来压缩和加速深度强化学习模型，但是估计一个参数（即神经元）对深度强化学习模型的贡献仍然具有挑战性。在本文中，我们引入了一种新颖的动态结构化剪枝方法，在训练阶段逐渐删除深度强化学习模型中不重要的神经元。我们的方法包括两个步骤，即使用组稀疏正则化器训练深度强化学习模型，以及使用动态剪枝阈值去除不重要的神经元。为了使用少量重要的神经元有效地训练深度强化学习模型，我们采用了一个神经元重要性组稀疏正则化器。与传统的正则化器不同，这个正则化器对冗余参数施加了惩罚。

    Deep reinforcement learning (DRL) has shown remarkable success in complex autonomous driving scenarios. However, DRL models inevitably bring high memory consumption and computation, which hinders their wide deployment in resource-limited autonomous driving devices. Structured Pruning has been recognized as a useful method to compress and accelerate DRL models, but it is still challenging to estimate the contribution of a parameter (i.e., neuron) to DRL models. In this paper, we introduce a novel dynamic structured pruning approach that gradually removes a DRL model's unimportant neurons during the training stage. Our method consists of two steps, i.e. training DRL models with a group sparse regularizer and removing unimportant neurons with a dynamic pruning threshold. To efficiently train the DRL model with a small number of important neurons, we employ a neuron-importance group sparse regularizer. In contrast to conventional regularizers, this regularizer imposes a penalty on redundan
    
[^106]: 一种使用进化算子的强盗方法进行模型选择

    A Bandit Approach with Evolutionary Operators for Model Selection

    [https://arxiv.org/abs/2402.05144](https://arxiv.org/abs/2402.05144)

    本文提出了一种使用进化算子的强盗方法来进行模型选择，通过将模型选择问题建模为无穷臂赌博机问题，利用部分训练和准确性作为奖励，最终的算法Mutant-UCB在测试中表现出色，优于固定预算下的最先进技术。

    

    本文将模型选择问题建模为无穷臂赌博机问题。模型是臂，选择一个臂对应部分训练模型（资源分配）。奖励是选择模型在部分训练后的准确性。在这个最佳臂识别问题中，遗憾是最优模型的预期准确性与最终选择模型的准确性之间的差距。我们首先考虑了UCB-E在随机无穷臂赌博机问题上的直接推广，并且证明了在基本假设下，期望遗憾的顺序是$T^{-\alpha}$，其中$\alpha \in (0,1/5)$，$T$是要分配的资源数量。从这个基本算法出发，我们介绍了一种算法Mutant-UCB，它结合了进化算法的操作符。在三个开源图片分类数据集上进行的测试表明了这种新颖的组合方法的相关性，该方法优于固定预算下的国际领先技术。

    This paper formulates model selection as an infinite-armed bandit problem. The models are arms, and picking an arm corresponds to a partial training of the model (resource allocation). The reward is the accuracy of the selected model after its partial training. In this best arm identification problem, regret is the gap between the expected accuracy of the optimal model and that of the model finally chosen. We first consider a straightforward generalization of UCB-E to the stochastic infinite-armed bandit problem and show that, under basic assumptions, the expected regret order is $T^{-\alpha}$ for some $\alpha \in (0,1/5)$ and $T$ the number of resources to allocate. From this vanilla algorithm, we introduce the algorithm Mutant-UCB that incorporates operators from evolutionary algorithms. Tests carried out on three open source image classification data sets attest to the relevance of this novel combining approach, which outperforms the state-of-the-art for a fixed budget.
    
[^107]: 计算管理的基础：系统方法用于将人工智能整合到现有工作流程中的任务自动化

    The Foundations of Computational Management: A Systematic Approach to Task Automation for the Integration of Artificial Intelligence into Existing Workflows

    [https://arxiv.org/abs/2402.05142](https://arxiv.org/abs/2402.05142)

    本文介绍了计算管理，一种系统方法，用于将人工智能整合到现有工作流程中。它提供了三个简单的步骤来开始实施人工智能，包括任务（重新）组织，评估自动化潜力和完成人工智能选择和适应的任务规范模板。

    

    在人工智能的快速崛起推动下，组织面临着一个关键问题：如何成功地将人工智能整合到现有运营中？为了帮助解答这个问题，管理预期并减轻沮丧，本文介绍了计算管理，一种系统方法，用于增强组织在现有工作流程中利用人工智能潜力的能力。计算管理作为管理科学的战略洞察和计算思维的分析严谨性之间的桥梁。本文提供了三个简单的逐步程序，以开始在工作流程中实施人工智能的过程。这些程序侧重于任务的（重新）组织，评估任务的自动化潜力，完成用于人工智能选择和适应的任务规范模板。本文包含了手动和自动化的方法，并提供了关于发表建议的提示。

    Driven by the rapid ascent of artificial intelligence (AI), organizations are at the epicenter of a seismic shift, facing a crucial question: How can AI be successfully integrated into existing operations? To help answer it, manage expectations and mitigate frustration, this article introduces Computational Management, a systematic approach to task automation for enhancing the ability of organizations to harness AI's potential within existing workflows. Computational Management acts as a bridge between the strategic insights of management science with the analytical rigor of computational thinking. The article offers three easy step-by-step procedures to begin the process of implementing AI within a workflow. Such procedures focus on task (re)formulation, on the assessment of the automation potential of tasks, on the completion of task specification templates for AI selection and adaptation. Included in the article there are manual and automated methods, with prompt suggestions for pub
    
[^108]: Tag-LLM: 将通用的LLM应用于专业领域的再利用

    Tag-LLM: Repurposing General-Purpose LLMs for Specialized Domains

    [https://arxiv.org/abs/2402.05140](https://arxiv.org/abs/2402.05140)

    本文介绍了一种将通用的LLMs应用于专业领域的方法，通过学习自定义的输入标签来对LLMs进行条件约束。通过明确将任务领域与任务功能分离，这种方法能够改善在专业领域中的任务求解能力。

    

    大型语言模型（LLMs）在理解和生成自然语言方面表现出了非凡的能力。然而，在专门领域中，如物理学和生物医学科学这样的预训练语料库中未充分涵盖的领域，它们的能力下降。本文探讨了如何将通用LLMs重新用于专业领域的有效任务解决方案。我们介绍了一种新颖的、与模型无关的框架，用于学习自定义的输入标签，这些标签被参数化为连续向量并附加到LLMs的嵌入层，以对LLMs进行条件约束。我们设计了两种类型的输入标签：领域标签用于限定专业表示（例如化学式）并提供领域相关的上下文；功能标签用于表示特定的功能（例如预测分子性质）并压缩功能解决指令。我们使用辅助数据和领域知识开发了一个包括三个阶段的学习这些标签的协议。通过明确将任务领域与任务功能分离，我们的方法能够改善在专业领域中的任务求解能力。

    Large Language Models (LLMs) have demonstrated remarkable proficiency in understanding and generating natural language. However, their capabilities wane in highly specialized domains underrepresented in the pretraining corpus, such as physical and biomedical sciences. This work explores how to repurpose general LLMs into effective task solvers for specialized domains. We introduce a novel, model-agnostic framework for learning custom input tags, which are parameterized as continuous vectors appended to the LLM's embedding layer, to condition the LLM. We design two types of input tags: domain tags are used to delimit specialized representations (e.g., chemical formulas) and provide domain-relevant context; function tags are used to represent specific functions (e.g., predicting molecular properties) and compress function-solving instructions. We develop a three-stage protocol to learn these tags using auxiliary data and domain knowledge. By explicitly disentangling task domains from tas
    
[^109]: SceMQA：一种科学类大学入学级多模态问题回答基准

    SceMQA: A Scientific College Entrance Level Multimodal Question Answering Benchmark

    [https://arxiv.org/abs/2402.05138](https://arxiv.org/abs/2402.05138)

    SceMQA是一种科学类大学入学级多模态问题回答的基准，填补了现有基准中被忽视的教育阶段的空白。它包含核心科学科目，融合了多项选择和自由回答的格式，并提供详细的问题解析和答案解释。该基准还通过相同背景但问题不同的方式，促进了对推理能力更全面和准确的评估。

    

    本文介绍了SceMQA，这是一种面向大学入学级科学类多模态问题回答的新型基准。它填补了现有基准中常常被忽视的关键教育阶段，涵盖了高中到大学预科的水平。SceMQA专注于核心科学科目，包括数学、物理学、化学和生物学。它融合了多项选择和自由回答的格式，确保对AI模型的能力进行全面评估。此外，我们的基准为每个问题提供了具体的知识点和详细的答案解释。SceMQA还独特地提供了相同背景但问题不同的问题，以促进对推理能力进行更全面和准确的评估。在实验中，我们对开源和闭源的最新多模态大语言模型（MLLMs）进行了评估，同时考虑了不同的实验设置。结果表明，在开发科学类大学入学级多模态问题回答方面，需要进一步的研究和发展。

    The paper introduces SceMQA, a novel benchmark for scientific multimodal question answering at the college entrance level. It addresses a critical educational phase often overlooked in existing benchmarks, spanning high school to pre-college levels. SceMQA focuses on core science subjects including Mathematics, Physics, Chemistry, and Biology. It features a blend of multiple-choice and free-response formats, ensuring a comprehensive evaluation of AI models' abilities. Additionally, our benchmark provides specific knowledge points for each problem and detailed explanations for each answer. SceMQA also uniquely presents problems with identical contexts but varied questions to facilitate a more thorough and accurate assessment of reasoning capabilities. In the experiment, we evaluate both open-source and close-source state-of-the-art Multimodal Large Language Models (MLLMs), across various experimental settings. The results show that further research and development are needed in developi
    
[^110]: CADReN: 上下文锚点驱动的关系网络用于可控跨图节点重要性估计

    CADReN: Contextual Anchor-Driven Relational Network for Controllable Cross-Graphs Node Importance Estimation

    [https://arxiv.org/abs/2402.05135](https://arxiv.org/abs/2402.05135)

    CADReN是一个上下文锚点驱动的关系网络，用于可控的跨图节点重要性估计。它通过引入上下文锚点机制，考虑知识图谱中的结构和语义特征，实现了更好的性能，包括零-shot预测能力，并开源了两个新的数据集RIC200和WK1K。

    

    节点重要性估计(NIE)对于通过检索增强生成将外部信息整合到大型语言模型中至关重要。传统方法侧重于静态的单一图特征，在新图和用户特定要求方面缺乏适应性。我们提出的CADReN通过引入上下文锚点(CA)机制来解决这些限制。该方法使网络能够相对于CA评估节点的重要性，考虑知识图谱(KGs)中的结构和语义特征。广泛的实验表明，CADReN在跨图NIE任务中取得了更好的性能，并具有零-shot预测能力。CADReN还被证明在单一图NIE任务上与以前的模型性能相匹配。此外，我们还引入并开源了两个新数据集RIC200和WK1K，专门用于跨图NIE研究，为这个领域的未来发展提供了宝贵的资源。

    Node Importance Estimation (NIE) is crucial for integrating external information into Large Language Models through Retriever-Augmented Generation. Traditional methods, focusing on static, single-graph characteristics, lack adaptability to new graphs and user-specific requirements. CADReN, our proposed method, addresses these limitations by introducing a Contextual Anchor (CA) mechanism. This approach enables the network to assess node importance relative to the CA, considering both structural and semantic features within Knowledge Graphs (KGs). Extensive experiments show that CADReN achieves better performance in cross-graph NIE task, with zero-shot prediction ability. CADReN is also proven to match the performance of previous models on single-graph NIE task. Additionally, we introduce and opensource two new datasets, RIC200 and WK1K, specifically designed for cross-graph NIE research, providing a valuable resource for future developments in this domain.
    
[^111]: 个性化语言模型基于个性化人类反馈

    Personalized Language Modeling from Personalized Human Feedback

    [https://arxiv.org/abs/2402.05133](https://arxiv.org/abs/2402.05133)

    该论文提出了一个个性化语言模型的方法，通过在于用户的反馈数据中引入个性化特征来解决强化学习框架在多样化用户偏好下存在的问题。

    

    从个性化人类反馈中进行强化学习（RLHF）是目前主流的框架，用于调整大型语言模型以更好地符合人类偏好。然而，在这个框架下开发的算法的基本前提在用户偏好多样化的情况下可能会出现问题。在本文中，我们旨在通过开发个性化语言模型的方法来解决这个问题。我们首先正式介绍了从个性化人类反馈中学习的任务，并解释了为什么在这种情况下普通的RLHF可能会存在问题。然后，我们提出了一个通用的个性化-RLHF（P-RLHF）框架，需要同时学习用户模型和语言（或奖励）模型。用户模型接收用户信息并输出用户表示。其结构编码了我们对反馈数据中用户偏好的假设。我们为个性化奖励建模和个性化直接偏好优化开发了新的学习目标。

    Reinforcement Learning from Human Feedback (RLHF) is the current dominating framework to fine-tune large language models to better align with human preferences. However, the underlying premise of algorithms developed under this framework can be problematic when user preferences encoded in human feedback are diverse. In this work, we aim to address this problem by developing methods for building personalized language models. We first formally introduce the task of learning from personalized human feedback and explain why vanilla RLHF can be problematic in this context. We then propose a general Personalized-RLHF (P-RLHF) framework, which requires one to jointly learn a user model and a language (or reward) model. The user model takes in user information and outputs user representations. Its structure encodes our assumptions about user preferences underlying the feedback data. We develop new learning objectives for personalized reward modeling and personalized Direct Preference Optimizat
    
[^112]: LB-KBQA: 基于大语言模型和BERT的基于知识的问答系统

    LB-KBQA: Large-language-model and BERT based Knowledge-Based Question and Answering System

    [https://arxiv.org/abs/2402.05130](https://arxiv.org/abs/2402.05130)

    LB-KBQA是一种基于大语言模型和BERT的基于知识的问答系统，通过生成式人工智能的帮助，能够提高意图识别的性能和解决语言多样性的问题。

    

    生成式人工智能（AI）因其新兴的能力而赋予了各个领域的力量，其中一个典型的应用领域是大语言模型（LLMs）。与传统的基于AI的方法相比，生成式AI的典型应用领域之一是大语言模型（LLMs），并且在自然语言理解能力方面，LLM的能力得到了显著提高。自然语言理解能力一直以来都是基于知识的问答系统意图识别性能的障碍，这源自语言多样性和新出现的意图。传统的基于AI的意图识别方法可以分为基于语义解析的方法和基于模型的方法。然而，这两种方法都在意图识别方面受到有限的资源限制。为了解决这个问题，我们提出了一种基于大语言模型（LLM）和BERT的新型KBQA系统（LB-KBQA）。在生成式AI的帮助下，我们提出的方法可以检测到……（略）

    Generative Artificial Intelligence (AI), because of its emergent abilities, has empowered various fields, one typical of which is large language models (LLMs). One of the typical application fields of Generative AI is large language models (LLMs), and the natural language understanding capability of LLM is dramatically improved when compared with conventional AI-based methods. The natural language understanding capability has always been a barrier to the intent recognition performance of the Knowledge-Based-Question-and-Answer (KBQA) system, which arises from linguistic diversity and the newly appeared intent. Conventional AI-based methods for intent recognition can be divided into semantic parsing-based and model-based approaches. However, both of the methods suffer from limited resources in intent recognition. To address this issue, we propose a novel KBQA system based on a Large Language Model(LLM) and BERT (LB-KBQA). With the help of generative AI, our proposed method could detect 
    
[^113]: 用大型语言模型和检索增强生成提升教科书问答任务

    Enhancing Textbook Question Answering Task with Large Language Models and Retrieval Augmented Generation

    [https://arxiv.org/abs/2402.05128](https://arxiv.org/abs/2402.05128)

    本论文通过引入检索增强生成（RAG）技术和利用迁移学习来处理长文本和提升推理能力，为教科书问答任务带来了显著的改进。

    

    教科书问答（TQA）是人工智能中的一项具有挑战性的任务，由于上下文和多模式数据的复杂性。尽管以前的研究在任务上取得了显著的进展，但仍存在一些限制，包括模型推理能力不足和无法捕捉长文本中的上下文信息。大型语言模型（LLMs）的引入革命了人工智能领域，然而，直接应用LLMs经常会导致不准确的答案。本文提出了一种方法来处理TQA中领域外情景，即概念分布在不同课程中，该方法结合了检索增强生成（RAG）技术和迁移学习来处理长文本并提升推理能力。通过对LLM模型Llama-2进行监督微调并加入RAG，我们的架构优于基线，在验证集上的准确度提高了4.12%，在测试集上提高了9.84%。

    Textbook question answering (TQA) is a challenging task in artificial intelligence due to the complex nature of context and multimodal data. Although previous research has significantly improved the task, there are still some limitations including the models' weak reasoning and inability to capture contextual information in the lengthy context. The introduction of large language models (LLMs) has revolutionized the field of AI, however, directly applying LLMs often leads to inaccurate answers. This paper proposes a methodology that handle the out-of-domain scenario in TQA where concepts are spread across different lessons by incorporating the retrieval augmented generation (RAG) technique and utilize transfer learning to handle the long context and enhance reasoning abilities. Through supervised fine-tuning of the LLM model Llama-2 and the incorporation of RAG, our architecture outperforms the baseline, achieving a 4.12% accuracy improvement on validation set and 9.84% on test set for 
    
[^114]: Illuminate：一种使用可解释分析和积极治疗的新方法进行抑郁症检测

    Illuminate: A novel approach for depression detection with explainable analysis and proactive therapy using prompt engineering

    [https://arxiv.org/abs/2402.05127](https://arxiv.org/abs/2402.05127)

    本研究提出了一种新的抑郁症检测和治疗范式，使用先进的大型语言模型，经过特定提示微调以诊断、解释和建议治疗干预。同时还介绍了一个丰富的数据库，以提供个性化的治疗建议。此方法与患者进行共情对话管理，有效支持抑郁症患者。

    

    本文介绍了一种使用先进的大型语言模型（LLMs）：Generative Pre-trained Transformer 4（GPT-4）、Llama 2 chat和Gemini的抑郁症检测和治疗新范式。这些LLMs通过特定的提示进行微调，以诊断、解释和建议抑郁症的治疗干预。一种独特的少样本提示方法增强了模型根据DSM-5标准分析和解释抑郁症状的能力。在交互阶段，模型采用共情对话管理，利用PsychDB和认知行为疗法（CBT）指南等资源，与患有重度抑郁症的个体进行支持性互动。此外，研究还介绍了Illuminate数据库，其中包含各种CBT模块，可帮助个性化的治疗建议。该研究使用F1分数、精确度、召回率、余弦相似度和召回率导向的差错进行LLM性能评估。

    This paper introduces a novel paradigm for depression detection and treatment using advanced Large Language Models (LLMs): Generative Pre-trained Transformer 4 (GPT-4), Llama 2 chat, and Gemini. These LLMs are fine-tuned with specialized prompts to diagnose, explain, and suggest therapeutic interventions for depression. A unique few-shot prompting method enhances the models' ability to analyze and explain depressive symptoms based on the DSM-5 criteria. In the interaction phase, the models engage in empathetic dialogue management, drawing from resources like PsychDB and a Cognitive Behavioral Therapy (CBT) Guide, fostering supportive interactions with individuals experiencing major depressive disorders. Additionally, the research introduces the Illuminate Database, enriched with various CBT modules, aiding in personalized therapy recommendations. The study evaluates LLM performance using metrics such as F1 scores, Precision, Recall, Cosine similarity, and Recall-Oriented Understudy for
    
[^115]: 零样本临床试验患者匹配与LLMs

    Zero-Shot Clinical Trial Patient Matching with LLMs

    [https://arxiv.org/abs/2402.05125](https://arxiv.org/abs/2402.05125)

    本研究基于LLMs开发了一个零样本临床试验患者匹配系统，可以高效评估患者是否符合入选标准，并通过优化提示策略和检索流程提高了数据和成本效率。

    

    将患者与临床试验匹配是推出新药的关键难题。目前，识别符合试验入选标准的患者是高度手动的，每位患者需花费长达1小时。然而，自动筛选具有挑战性，因为它需要理解非结构化的临床文本。大型语言模型（LLMs）提供了一个有望的解决方案。在这项工作中，我们探索了它们在试验匹配中的应用。首先，我们设计了一个基于LLM的系统，可以在给定一个患者的病史作为非结构化的临床文本时，评估该患者是否符合一组包含标准（也以自由文本形式指定）。我们的零样本系统在n2c2 2018队列选择基准测试中取得了最先进的得分。其次，我们通过识别一种提示策略，改善了我们方法的数据和成本效率，该策略与现状相比可以将患者匹配时间和成本降低一个数量级，并且开发了一个两阶段的检索流程，减少了匹配消除的次数。

    Matching patients to clinical trials is a key unsolved challenge in bringing new drugs to market. Today, identifying patients who meet a trial's eligibility criteria is highly manual, taking up to 1 hour per patient. Automated screening is challenging, however, as it requires understanding unstructured clinical text. Large language models (LLMs) offer a promising solution. In this work, we explore their application to trial matching. First, we design an LLM-based system which, given a patient's medical history as unstructured clinical text, evaluates whether that patient meets a set of inclusion criteria (also specified as free text). Our zero-shot system achieves state-of-the-art scores on the n2c2 2018 cohort selection benchmark. Second, we improve the data and cost efficiency of our method by identifying a prompting strategy which matches patients an order of magnitude faster and more cheaply than the status quo, and develop a two-stage retrieval pipeline that reduces the number of 
    
[^116]: 大型语言模型在表格处理中的应用：一项调查

    Large Language Model for Table Processing: A Survey

    [https://arxiv.org/abs/2402.05121](https://arxiv.org/abs/2402.05121)

    该调查综述了大型语言模型在表格处理中的应用，包括传统的表格问题回答和事实验证，以及新兴的表格操作和高级表格数据分析。还讨论了LLMs的最新范例，特别关注了指导调整、提示和基于代理的方法。

    

    表格通常是二维结构化的，用于存储大量数据，在数据库查询、电子表格计算和从网络表格生成报告等日常活动中起着重要作用。利用大型语言模型（LLMs）自动化这些以表格为中心的任务可以带来重大的公众利益，引起了学术界和工业界的兴趣。该调查对表格任务进行了广泛的概述，不仅涵盖传统领域如表格问题回答（Table QA）和事实验证，还包括最近强调的方面，如表格操作和高级表格数据分析。此外，它还超越了早期的预训练和微调小型语言模型的策略，包括LLM使用中的最新范例。重点是LLMs领域内的指导调整、提示和基于代理的方法。最后，我们重点介绍了几个挑战，涵盖私有部署、高效推断和 LLMS 发展等方面。

    Tables, typically two-dimensional and structured to store large amounts of data, are essential in daily activities like database queries, spreadsheet calculations, and generating reports from web tables. Automating these table-centric tasks with Large Language Models (LLMs) offers significant public benefits, garnering interest from academia and industry. This survey provides an extensive overview of table tasks, encompassing not only the traditional areas like table question answering (Table QA) and fact verification, but also newly emphasized aspects such as table manipulation and advanced table data analysis. Additionally, it goes beyond the early strategies of pre-training and fine-tuning small language models, to include recent paradigms in LLM usage. The focus here is particularly on instruction-tuning, prompting, and agent-based approaches within the realm of LLMs. Finally, we highlight several challenges, ranging from private deployment and efficient inference to the developmen
    
[^117]: 更多的代理就是你所需要的

    More Agents Is All You Need

    [https://arxiv.org/abs/2402.05120](https://arxiv.org/abs/2402.05120)

    大型语言模型的性能与代理数量成比例，通过简单的采样和投票方法可以进一步增强性能，这种方法与现有的复杂方法正交。

    

    我们发现，仅通过一种采样和投票的方法，大型语言模型(Large Language Models, LLMs)的性能与实例化的代理数量成比例。此外，这种方法对已有的复杂方法进一步增强LLMs是正交的，而增强的程度与任务的困难程度相关。我们进行了广泛的实验，验证了我们的发现，并研究了能够促进其发生的属性。我们的代码公开在以下网址: \url{https://anonymous.4open.science/r/more_agent_is_all_you_need}

    We find that, simply via a sampling-and-voting method, the performance of large language models (LLMs) scales with the number of agents instantiated. Also, this method is orthogonal to existing complicated methods to further enhance LLMs, while the degree of enhancement is correlated to the task difficulty. We conduct comprehensive experiments on a wide range of LLM benchmarks to verify the presence of our finding, and to study the properties that can facilitate its occurrence. Our code is publicly available at: \url{https://anonymous.4open.science/r/more_agent_is_all_you_need}.
    
[^118]: 研究指令调整的局限性

    A Closer Look at the Limitations of Instruction Tuning

    [https://arxiv.org/abs/2402.05119](https://arxiv.org/abs/2402.05119)

    本文通过实验和分析揭示了指令调整的多个局限性，包括无法增强LLM的知识和技能、从具有知识来源的数据集复制回应模式导致质量下降、全参数微调增加了错误生成的情况。

    

    指令调整（IT）是使用指令-回应对来训练大型语言模型（LLM）的过程，已成为将基础预训练LLM转化为开放领域对话代理的主要方法。虽然IT取得了显著的成功并广泛应用，但其局限性和不足仍未得到充分探讨。本文通过严格的实验和对LLM通过IT发生的变化的深入分析，揭示了IT的多种局限性。特别是，我们发现：（1）IT无法增强LLM的知识或技能。LoRA微调仅限于学习回应的启动和样式令牌，而全参数微调会导致知识退化。（2）从具有知识来源的IT数据集复制回应模式会导致回应质量下降。（3）全参数微调通过不准确地从IT数据集中获取概念上相似实例的标记，增加了错误生成的情况。

    Instruction Tuning (IT), the process of training large language models (LLMs) using instruction-response pairs, has emerged as the predominant method for transforming base pre-trained LLMs into open-domain conversational agents. While IT has achieved notable success and widespread adoption, its limitations and shortcomings remain underexplored. In this paper, through rigorous experiments and an in-depth analysis of the changes LLMs undergo through IT, we reveal various limitations of IT. In particular, we show that (1) IT fails to enhance knowledge or skills in LLMs. LoRA fine-tuning is limited to learning response initiation and style tokens, and full-parameter fine-tuning leads to knowledge degradation. (2) Copying response patterns from IT datasets derived from knowledgeable sources leads to a decline in response quality. (3) Full-parameter fine-tuning increases hallucination by inaccurately borrowing tokens from conceptually similar instances in the IT dataset for generating respon
    
[^119]: 无监督运动重定位用于人机仿真

    Unsupervised Motion Retargeting for Human-Robot Imitation

    [https://arxiv.org/abs/2402.05115](https://arxiv.org/abs/2402.05115)

    该论文研究了无监督运动重定位用于人机仿真的问题，提出了一个编码器-解码器神经网络模型进行领域到领域的转换。这种方法可以在无对应数据的情况下进行人机仿真。

    

    这项早期研究旨在通过将人类动作领域的关节位置序列转化为特定机器人可实现的动作领域，从而改进在线人机仿真。借助深度学习方法的泛化能力，我们通过提出一个编码器-解码器神经网络模型进行领域到领域的转换来解决这个问题。为了训练这样的模型，可以使用对应的机器人和人类动作对。然而，在实践中这样的配对数据非常稀缺且收集起来繁琐。因此，我们转向适应于无配对领域到领域转换的深度学习方法，以进行人机仿真。

    This early-stage research work aims to improve online human-robot imitation by translating sequences of joint positions from the domain of human motions to a domain of motions achievable by a given robot, thus constrained by its embodiment. Leveraging the generalization capabilities of deep learning methods, we address this problem by proposing an encoder-decoder neural network model performing domain-to-domain translation. In order to train such a model, one could use pairs of associated robot and human motions. Though, such paired data is extremely rare in practice, and tedious to collect. Therefore, we turn towards deep learning methods for unpaired domain-to-domain translation, that we adapt in order to perform human-robot imitation.
    
[^120]: SALAD-Bench: 一个针对大语言模型的层次化和全面性安全基准

    SALAD-Bench: A Hierarchical and Comprehensive Safety Benchmark for Large Language Models

    [https://arxiv.org/abs/2402.05044](https://arxiv.org/abs/2402.05044)

    SALAD-Bench是一个针对大语言模型的全面安全基准，通过其大规模、丰富的分类和多功能性，以及对攻击和防御方法的评估，实现了对LLMs的有效管理和保护。

    

    在快速发展的大语言模型（LLM）领域中，确保强大的安全措施至关重要。为了满足这一关键需求，我们提出了一种特别设计用于评估LLMs、攻击和防御方法的安全基准，称为SALAD-Bench。SALAD-Bench通过其大规模、丰富多样的特性，以及跨三个层次的细致分类和多功能性，超越了传统基准。SALAD-Bench通过对标准查询和复杂查询（包括攻击、防御修改和多项选择）的精心设计，有效管理其固有的复杂性。为了确保无缝可靠的评估，我们引入了一种创新的评估器：基于LLM的MD-Judge，专注于攻击增强查询的问答对评估。以上组件将SALAD-Bench从标准的LLM安全评估扩展到了LLM攻击和防御方法评估，确保了联合目标的实用性。

    In the rapidly evolving landscape of Large Language Models (LLMs), ensuring robust safety measures is paramount. To meet this crucial need, we propose \emph{SALAD-Bench}, a safety benchmark specifically designed for evaluating LLMs, attack, and defense methods. Distinguished by its breadth, SALAD-Bench transcends conventional benchmarks through its large scale, rich diversity, intricate taxonomy spanning three levels, and versatile functionalities.SALAD-Bench is crafted with a meticulous array of questions, from standard queries to complex ones enriched with attack, defense modifications and multiple-choice. To effectively manage the inherent complexity, we introduce an innovative evaluators: the LLM-based MD-Judge for QA pairs with a particular focus on attack-enhanced queries, ensuring a seamless, and reliable evaluation. Above components extend SALAD-Bench from standard LLM safety evaluation to both LLM attack and defense methods evaluation, ensuring the joint-purpose utility. Our e
    
[^121]: 多发信者说服 - 从计算的角度来看

    Multi-Sender Persuasion -- A Computational Perspective

    [https://arxiv.org/abs/2402.04971](https://arxiv.org/abs/2402.04971)

    这项研究考虑了多个具有信息优势的发信者向单个自私行为者传递信号以影响其行为的问题，并提出了一种新颖的可微神经网络方法来近似解决这一问题。通过额外梯度算法，我们发现了超越已有方法的局部均衡解。

    

    我们考虑到具有信息优势的多个发信者向单个自私行为者传递信号以使其采取某些行动。这些设置是计算经济学，多智能体学习和具有多个目标的机器学习中普遍存在的。核心解决方案概念是发信者信号策略的纳什均衡。理论上，我们证明一般情况下找到一个均衡是PPAD-Hard的;实际上，计算一个发信者的最佳响应甚至是NP-Hard的。鉴于这些固有的困难，我们转而寻找局部纳什均衡。我们提出了一种新颖的可微神经网络来近似该游戏的非线性和不连续效用。结合额外梯度算法，我们发现了超越完全展示均衡和现有神经网络发现的局部均衡。广义上，我们的理论和实证贡献对广泛的类别感兴趣。

    We consider multiple senders with informational advantage signaling to convince a single self-interested actor towards certain actions. Generalizing the seminal Bayesian Persuasion framework, such settings are ubiquitous in computational economics, multi-agent learning, and machine learning with multiple objectives. The core solution concept here is the Nash equilibrium of senders' signaling policies. Theoretically, we prove that finding an equilibrium in general is PPAD-Hard; in fact, even computing a sender's best response is NP-Hard. Given these intrinsic difficulties, we turn to finding local Nash equilibria. We propose a novel differentiable neural network to approximate this game's non-linear and discontinuous utilities. Complementing this with the extra-gradient algorithm, we discover local equilibria that Pareto dominates full-revelation equilibria and those found by existing neural networks. Broadly, our theoretical and empirical contributions are of interest to a large class 
    
[^122]: S-Agents: 自组织代理在无限环境中的应用

    S-Agents: self-organizing agents in open-ended environment

    [https://arxiv.org/abs/2402.04578](https://arxiv.org/abs/2402.04578)

    S-Agents是一个自组织代理系统，通过引入代理树结构、沙漏代理架构和非阻塞协作方法，实现了在无限环境中高效协调代理的能力，提供了优化协作效率和灵活性的解决方案。

    

    利用大型语言模型（LLMs），自主代理能够显著提升，具备处理各种任务的能力。在无限环境中，为了提高效率和效果，优化协作需要灵活的调整。然而，当前的研究主要强调固定的、任务导向的工作流程，忽视了以代理为中心的组织结构。受人类组织行为的启发，我们引入了一种自组织代理系统（S-Agents），其中包括动态工作流程的“代理树”结构、平衡信息优先级的“沙漏代理架构”以及允许代理之间异步执行任务的“非阻塞协作”方法。这种结构可以自主协调一组代理，有效地解决无限且动态的环境挑战，无需人工干预。我们的实验表明，S-Agents能够熟练地执行协作建筑任务和资源收集。

    Leveraging large language models (LLMs), autonomous agents have significantly improved, gaining the ability to handle a variety of tasks. In open-ended settings, optimizing collaboration for efficiency and effectiveness demands flexible adjustments. Despite this, current research mainly emphasizes fixed, task-oriented workflows and overlooks agent-centric organizational structures. Drawing inspiration from human organizational behavior, we introduce a self-organizing agent system (S-Agents) with a "tree of agents" structure for dynamic workflow, an "hourglass agent architecture" for balancing information priorities, and a "non-obstructive collaboration" method to allow asynchronous task execution among agents. This structure can autonomously coordinate a group of agents, efficiently addressing the challenges of an open and dynamic environment without human intervention. Our experiments demonstrate that S-Agents proficiently execute collaborative building tasks and resource collection i
    
[^123]: 《读玩游戏（R2-Play）: 多模态游戏指导下的决策 Transformer》

    Read to Play (R2-Play): Decision Transformer with Multimodal Game Instruction

    [https://arxiv.org/abs/2402.04154](https://arxiv.org/abs/2402.04154)

    本论文探索了为智能体提供增强形式的任务指导，使其能够理解游戏指导并实现"读玩游戏"的能力。通过将多模态指导调优的成功应用于视觉任务中的强化学习任务，构建了一组... (内容太长，无法继续显示)

    

    在人工智能领域，开发一款通用智能体一直是一个长期的目标。先前的研究利用来自各种任务的大量离线数据集，在强化学习的多任务场景中表现出了出色的性能。然而，这些工作在扩展到新任务方面面临挑战。最近的方法将文本指导或视觉轨迹整合到决策网络中，提供任务特定的上下文提示，代表了一个有前途的方向。然而，观察到仅依赖于文本指导或视觉轨迹对于准确传达任务的上下文信息是不足够的。本文探索了增强智能体任务指导的形式，使其能够理解游戏指导，从而实现"读玩游戏"的能力。受到多模态指导调优在视觉任务中的成功启发，我们将基于视觉的强化学习任务视为一个长期视觉任务，并构建了一组... (内容太长，无法继续显示)

    Developing a generalist agent is a longstanding objective in artificial intelligence. Previous efforts utilizing extensive offline datasets from various tasks demonstrate remarkable performance in multitasking scenarios within Reinforcement Learning.However, these works encounter challenges in extending their capabilities to new tasks.Recent approaches integrate textual guidance or visual trajectory into decision networks to provide task-specific contextual cues, representing a promising direction.However, it is observed that relying solely on textual guidance or visual trajectory is insufficient for accurately conveying the contextual information of tasks.This paper explores enhanced forms of task guidance for agents, enabling them to comprehend gameplay instructions, thereby facilitating a "read-to-play" capability.Drawing inspiration from the success of multimodal instruction tuning in visual tasks, we treat the visual-based RL task as a long-horizon vision task and construct a set 
    
[^124]: 逻辑规范引导下的强化学习智能体动态任务采样

    Logical Specifications-guided Dynamic Task Sampling for Reinforcement Learning Agents

    [https://arxiv.org/abs/2402.03678](https://arxiv.org/abs/2402.03678)

    本文提出了一种逻辑规范引导下的动态任务采样（LSTS）方法，通过学习一组强化学习策略，根据高级任务规范指导智能体在最小化环境交互次数的同时实现从初始状态到目标状态的引导。在网格世界实验中，LSTS实现了改进的时间到阈值。

    

    强化学习（RL）在使人工智能智能体学习多样化行为方面取得了重要进展。然而，学习有效的策略通常需要大量的环境交互。为了减少样本复杂性问题，最近的方法使用高级任务规范，如线性时态逻辑（LTL$_f$）公式或奖励机器（RM），来指导智能体的学习过程。在这项工作中，我们提出了一种新颖的方法，称为逻辑规范引导下的动态任务采样（LSTS），它通过学习一组强化学习策略，根据高级任务规范指导智能体从初始状态到目标状态，同时最小化环境交互次数。与以前的工作不同，LSTS不假设环境动力学或奖励机器的信息，并动态采样导致成功目标策略的有希望的任务。我们在一个网格世界上评估了LSTS，并展示了它实现了改进的时间到阈值。

    Reinforcement Learning (RL) has made significant strides in enabling artificial agents to learn diverse behaviors. However, learning an effective policy often requires a large number of environment interactions. To mitigate sample complexity issues, recent approaches have used high-level task specifications, such as Linear Temporal Logic (LTL$_f$) formulas or Reward Machines (RM), to guide the learning progress of the agent. In this work, we propose a novel approach, called Logical Specifications-guided Dynamic Task Sampling (LSTS), that learns a set of RL policies to guide an agent from an initial state to a goal state based on a high-level task specification, while minimizing the number of environmental interactions. Unlike previous work, LSTS does not assume information about the environment dynamics or the Reward Machine, and dynamically samples promising tasks that lead to successful goal policies. We evaluate LSTS on a gridworld and show that it achieves improved time-to-threshol
    
[^125]: IGUANe: 一种适用于脑MR图像多中心协调的三维通用CycleGAN模型

    IGUANe: a 3D generalizable CycleGAN for multicenter harmonization of brain MR images

    [https://arxiv.org/abs/2402.03227](https://arxiv.org/abs/2402.03227)

    IGUANe是一种三维通用CycleGAN模型，通过集成多个域的训练实现了脑MR图像的多中心协调，使其成为通用生成器。

    

    在MRI研究中，来自多个采集点的图像数据的聚合可以增加样本大小，但可能引入阻碍后续分析一致性的与采集点相关的变异。图像翻译的深度学习方法已经成为协调MR图像跨站点的解决方案。在本研究中，我们引入了IGUANe（具有统一对抗网络的图像生成），这是一种原始的三维模型，它结合了域转换的优势和直接应用样式转移方法来实现多中心脑MR图像协调。IGUANe通过多对一策略，集成了任意数量的域进行训练，扩展了CycleGAN架构。在推断过程中，该模型可以应用于任何图像，甚至来自未知采集点，使其成为协调的通用生成器。在由11台不同扫描仪的T1加权图像组成的数据集上进行训练，IGUANe在未见站点的数据上进行了评估。

    In MRI studies, the aggregation of imaging data from multiple acquisition sites enhances sample size but may introduce site-related variabilities that hinder consistency in subsequent analyses. Deep learning methods for image translation have emerged as a solution for harmonizing MR images across sites. In this study, we introduce IGUANe (Image Generation with Unified Adversarial Networks), an original 3D model that leverages the strengths of domain translation and straightforward application of style transfer methods for multicenter brain MR image harmonization. IGUANe extends CycleGAN architecture by integrating an arbitrary number of domains for training through a many-to-one strategy. During inference, the model can be applied to any image, even from an unknown acquisition site, making it a universal generator for harmonization. Trained on a dataset comprising T1-weighted images from 11 different scanners, IGUANe was evaluated on data from unseen sites. The assessments included the
    
[^126]: BGE M3-嵌入：通过自知识蒸馏实现多语言、多功能和多粒度的文本嵌入

    BGE M3-Embedding: Multi-Lingual, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation

    [https://arxiv.org/abs/2402.03216](https://arxiv.org/abs/2402.03216)

    BGE M3-嵌入是一种新的多语言、多功能和多粒度的文本嵌入模型，支持超过100种工作语言，并在多语言和跨语言检索任务上取得了最先进的性能。它能够同时执行密集检索、多向量检索和稀疏检索，并能处理不同粒度的输入。其有效训练包括了一种自知识蒸馏方法和优化的批处理策略。

    

    在本文中，我们提出了一种新的嵌入模型，称为M3-嵌入，以其在多语言、多功能和多粒度方面的多样性而著称。它可以支持超过100种工作语言，在多语言和跨语言检索任务上取得了新的最先进性能。它可以同时执行嵌入模型的三种常见检索功能：密集检索、多向量检索和稀疏检索，为现实世界的IR应用提供了统一的模型基础。它能够处理不同粒度的输入，从短句到长达8192个标记的文档。M3-嵌入的有效训练包括以下技术贡献。我们提出了一种新颖的自知识蒸馏方法，可以将来自不同检索功能的相关性分数整合为教师信号，以提高训练质量。我们还优化了批处理策略。

    In this paper, we present a new embedding model, called M3-Embedding, which is distinguished for its versatility in Multi-Linguality, Multi-Functionality, and Multi-Granularity. It can support more than 100 working languages, leading to new state-of-the-art performances on multi-lingual and cross-lingual retrieval tasks. It can simultaneously perform the three common retrieval functionalities of embedding model: dense retrieval, multi-vector retrieval, and sparse retrieval, which provides a unified model foundation for real-world IR applications. It is able to process inputs of different granularities, spanning from short sentences to long documents of up to 8192 tokens. The effective training of M3-Embedding involves the following technical contributions. We propose a novel self-knowledge distillation approach, where the relevance scores from different retrieval functionalities can be integrated as the teacher signal to enhance the training quality. We also optimize the batching strat
    
[^127]: GPT 模型的对话重构攻击

    Conversation Reconstruction Attack Against GPT Models

    [https://arxiv.org/abs/2402.02987](https://arxiv.org/abs/2402.02987)

    本文介绍了一种针对 GPT 模型的对话重构攻击，该攻击具有劫持会话和重构对话的两个步骤。通过对该攻击对 GPT 模型的隐私风险进行评估，发现 GPT-4 对该攻击具有一定的鲁棒性。

    

    最近，在大型语言模型（LLM）领域取得了重要进展，其中 GPT 系列模型代表着最具代表性的成果。为了优化任务执行，用户经常与托管在云环境中的 GPT 模型进行多轮对话。这些多轮对话往往包含私人信息，需要在云中进行传输和存储。然而，这种操作模式引入了额外的攻击面。本文首先介绍了一种针对 GPT 模型的特定对话重构攻击。我们提出的对话重构攻击由两个步骤组成：劫持会话和重构对话。随后，我们对当 GPT 模型遭受该攻击时对话中固有的隐私风险进行了详尽评估。然而，GPT-4 对于该攻击具有一定的鲁棒性。接着，我们引入了两种高级攻击，旨在更好地重构以前的对话。

    In recent times, significant advancements have been made in the field of large language models (LLMs), represented by GPT series models. To optimize task execution, users often engage in multi-round conversations with GPT models hosted in cloud environments. These multi-round conversations, potentially replete with private information, require transmission and storage within the cloud. However, this operational paradigm introduces additional attack surfaces. In this paper, we first introduce a specific Conversation Reconstruction Attack targeting GPT models. Our introduced Conversation Reconstruction Attack is composed of two steps: hijacking a session and reconstructing the conversations. Subsequently, we offer an exhaustive evaluation of the privacy risks inherent in conversations when GPT models are subjected to the proposed attack. However, GPT-4 demonstrates certain robustness to the proposed attacks. We then introduce two advanced attacks aimed at better reconstructing previous c
    
[^128]: 冷链中物联网实施障碍的分析：一种集成的ISM-MICMAC和DEMATEL方法

    Analysis of Internet of Things implementation barriers in the cold supply chain: an integrated ISM-MICMAC and DEMATEL approach

    [https://arxiv.org/abs/2402.01804](https://arxiv.org/abs/2402.01804)

    本研究通过综述和调查研究物联网在冷链中的实施障碍，发现了13个关键障碍。其中，合规性和冷链网络是物联网采用策略的关键驱动因素。MICMAC和DEMATEL方法的应用有助于评估障碍之间的互动关系和因果关系。

    

    将物联网技术整合到冷链中可以提高透明度、效率和质量，优化运营流程并提高生产力。在复杂的环境下，物联网在冷链中的集成受到特定的障碍的阻碍，需要进行全面的研究。通过对物联网实施的相关文献进行综述，共发现了13个障碍。调查数据经过交叉验证以确保质量，并采用Cronbach's alpha测试来确保有效性。本研究在第一阶段应用解释性结构建模技术以识别主要障碍。在这些障碍中，“合规性”和“冷链网络”是物联网采用策略的关键驱动因素。MICMAC的驱动和依赖力量元素分类有助于评估障碍之间的互动。在本研究的第二阶段中，通过DEMATEL方法确定了所识别障碍之间的因果关系。

    Integrating Internet of Things (IoT) technology inside the cold supply chain can enhance transparency, efficiency, and quality, optimizing operating procedures and increasing productivity. The integration of IoT in this complicated setting is hindered by specific barriers that need a thorough examination. Prominent barriers to IoT implementation in the cold supply chain are identified using a two-stage model. After reviewing the available literature on the topic of IoT implementation, a total of 13 barriers were found. The survey data was cross-validated for quality, and Cronbach's alpha test was employed to ensure validity. This research applies the interpretative structural modeling technique in the first phase to identify the main barriers. Among those barriers, "regularity compliance" and "cold chain networks" are key drivers for IoT adoption strategies. MICMAC's driving and dependence power element categorization helps evaluate the barrier interactions. In the second phase of this
    
[^129]: 一种多角度的机器学习方法用于评估洛杉矶警察与司机的互动

    A Multi-Perspective Machine Learning Approach to Evaluate Police-Driver Interaction in Los Angeles

    [https://arxiv.org/abs/2402.01703](https://arxiv.org/abs/2402.01703)

    该研究提出了一种多角度的机器学习方法，用于分析洛杉矶警察与司机的互动。该方法利用多模态的数据包括音频、视频和文字信息，旨在提供对复杂和有争议的警民互动的分析工具。

    

    政府官员与市民之间的互动影响公共福祉和民主社会的正当性。警察是国家最显而易见、最接触市民的代理人，在交通站停期间，他们每年与公众互动超过2000万次。如今，这些互动经常被戴在身上的摄像机记录下来，这被视为提高警察问责制和改善警民互动的手段。然而，由于缺乏可靠的自动化工具来分析这些复杂而有争议的警民互动，这些记录的及时分析受到了阻碍。本文提出了一种新的多角度、多模态机器学习（ML）工具的方法，用于分析来自这些身上摄像机记录的音频、视频和文字信息。我们的方法首先确定与不同利益相关者最相关的沟通方面，包括共同感知互动的标志标记以及具有这些标记的符号。

    Interactions between the government officials and civilians affect public wellbeing and the state legitimacy that is necessary for the functioning of democratic society. Police officers, the most visible and contacted agents of the state, interact with the public more than 20 million times a year during traffic stops. Today, these interactions are regularly recorded by body-worn cameras (BWCs), which are lauded as a means to enhance police accountability and improve police-public interactions. However, the timely analysis of these recordings is hampered by a lack of reliable automated tools that can enable the analysis of these complex and contested police-public interactions. This article proposes an approach to developing new multi-perspective, multimodal machine learning (ML) tools to analyze the audio, video, and transcript information from this BWC footage. Our approach begins by identifying the aspects of communication most salient to different stakeholders, including both commun
    
[^130]: ReAGent: 一个面向生成语言模型的模型无关特征归因方法

    ReAGent: Towards A Model-agnostic Feature Attribution Method for Generative Language Models

    [https://arxiv.org/abs/2402.00794](https://arxiv.org/abs/2402.00794)

    本论文介绍了一种面向生成语言模型的模型无关特征归因方法，称为ReAGent。该方法解决了现有方法在文本生成中的适用性问题，并提供了计算上效率更高的选择。

    

    特征归因方法（FAs），如梯度和注意力机制，被广泛应用于确定所有输入特征对模型预测的重要性。现有自然语言处理领域的研究主要集中在为仅有编码器的语言模型（LMs）开发和测试FAs，用于分类任务。然而，尚不清楚在文本生成上是否可以使用这些FAs来处理仅有解码器的模型，因为模型架构和任务设置之间存在固有差异。此外，先前的研究已经证明，没有一个通用的FA适用于所有模型和任务。这使得针对大型LMs选择FA计算上非常昂贵，因为输入重要性的推导通常需要多个前向和反向传递，包括可能是限制性的梯度计算。为了解决这些问题，我们提出了一种面向生成LMs的模型无关FA，称为递归归因生成器（ReAGent）。

    Feature attribution methods (FAs), such as gradients and attention, are widely employed approaches to derive the importance of all input features to the model predictions. Existing work in natural language processing has mostly focused on developing and testing FAs for encoder-only language models (LMs) in classification tasks. However, it is unknown if it is faithful to use these FAs for decoder-only models on text generation, due to the inherent differences between model architectures and task settings respectively. Moreover, previous work has demonstrated that there is no `one-wins-all' FA across models and tasks. This makes the selection of a FA computationally expensive for large LMs since input importance derivation often requires multiple forward and backward passes including gradient computations that might be prohibitive even with access to large compute. To address these issues, we present a model-agnostic FA for generative LMs called Recursive Attribution Generator (ReAGent)
    
[^131]: 解决在实施负责任人工智能中的伦理权衡

    Resolving Ethics Trade-offs in Implementing Responsible AI

    [https://arxiv.org/abs/2401.08103](https://arxiv.org/abs/2401.08103)

    该论文提出了通过权衡处理人工智能伦理中的紧张关系的五种方法，并提出了一个框架来实施全面的人工智能/机器学习系统。

    

    虽然把高级人工智能伦理原则应用到实际的人工智能/机器学习系统中已经取得了进展，但在处理底层人工智能伦理方面的紧张关系方面仍存在理论与实践之间的差距。我们提出了五种处理这些关系的方法，从简单到复杂不等。这些方法在考虑的上下文类型、范围、衡量上下文的方法和证明程度上有所不同。这些方法中没有一种适用于所有组织、系统或应用。为了解决这个问题，我们提出了一个框架，包括：（i）积极识别紧张关系，（ii）优先处理和权衡伦理方面，（iii）证明和记录权衡决策。该提议的框架旨在促进实施符合潜在监管要求的全面人工智能/机器学习系统。

    While the operationalisation of high-level AI ethics principles into practical AI/ML systems has made progress, there is still a theory-practice gap in managing tensions between the underlying AI ethics aspects. We cover five approaches for addressing the tensions via trade-offs, ranging from rudimentary to complex. The approaches differ in the types of considered context, scope, methods for measuring contexts, and degree of justification. None of the approaches is likely to be appropriate for all organisations, systems, or applications. To address this, we propose a framework which consists of: (i) proactive identification of tensions, (ii) prioritisation and weighting of ethics aspects, (iii) justification and documentation of trade-off decisions. The proposed framework aims to facilitate the implementation of well-rounded AI/ML systems that are appropriate for potential regulatory requirements.
    
[^132]: 使用社会选择理论从大型语言模型中提取稳健知识

    Robust Knowledge Extraction from Large Language Models using Social Choice Theory

    [https://arxiv.org/abs/2312.14877](https://arxiv.org/abs/2312.14877)

    本研究提出使用排名查询和社会选择理论的方法来提高大型语言模型（LLMs）查询的鲁棒性，特别是在高风险领域如医学中。我们通过实证评估验证了我们方法的鲁棒性和其他有趣属性。

    

    大型语言模型(LLMs)可以支持很多应用，如对话代理、创意写作或一般查询回答。然而，在高风险领域（如医学）中，它们不适用于查询回答，因为当多次提示相同查询时，它们通常不具有鲁棒性 - 结果可能不同。为了提高LLM查询的鲁棒性，我们提出使用排名查询，并使用社会选择理论的方法来汇总查询结果。我们研究了诊断场景中的排名查询，如医学和故障诊断，并讨论了如何应用文献中的Partial Borda Choice函数来合并多个查询结果。我们还讨论了我们设置中的一些其他有趣属性，并通过实证评估了我们方法的鲁棒性。

    Large-language models (LLMs) can support a wide range of applications like conversational agents, creative writing or general query answering. However, they are ill-suited for query answering in high-stake domains like medicine because they are typically not robust - even the same query can result in different answers when prompted multiple times. In order to improve the robustness of LLM queries, we propose using ranking queries repeatedly and to aggregate the queries using methods from social choice theory. We study ranking queries in diagnostic settings like medical and fault diagnosis and discuss how the Partial Borda Choice function from the literature can be applied to merge multiple query results. We discuss some additional interesting properties in our setting and evaluate the robustness of our approach empirically.
    
[^133]: 基于自编码器的人脸验证系统

    Autoencoder Based Face Verification System

    [https://arxiv.org/abs/2312.14301](https://arxiv.org/abs/2312.14301)

    这篇论文提出了一种基于自编码器的人脸验证系统，通过使用预训练的自编码器初始化深度神经网络，实现对标记数据依赖性的减少，在人脸图像识别任务中取得了较好的效果。

    

    本研究的主要目标是提出一种减少对标记数据依赖性的替代方法。我们提出的方法涉及在人脸图像识别任务中利用自编码器的预训练，采用两个步骤的过程。首先，使用大量无标签训练数据以无监督方式训练自编码器。随后，使用来自预训练自编码器的初始化参数来训练深度学习模型。这个深度学习训练过程以有监督方式进行，使用相对有限的标记训练数据。在评估阶段，生成人脸图像嵌入作为深度神经网络层的输出。我们在CelebA数据集上进行了训练，而评估则使用了诸如Labeled Faces in the Wild (LFW)和YouTube Faces (YTF)等基准人脸识别数据集。实验结果表明，通过使用预训练的自编码器来初始化深度神经网络，可以达到较好的效果。

    The primary objective of this work is to present an alternative approach aimed at reducing the dependency on labeled data. Our proposed method involves utilizing autoencoder pre-training within a face image recognition task with two step processes. Initially, an autoencoder is trained in an unsupervised manner using a substantial amount of unlabeled training dataset. Subsequently, a deep learning model is trained with initialized parameters from the pre-trained autoencoder. This deep learning training process is conducted in a supervised manner, employing relatively limited labeled training dataset. During evaluation phase, face image embeddings is generated as the output of deep neural network layer. Our training is executed on the CelebA dataset, while evaluation is performed using benchmark face recognition datasets such as Labeled Faces in the Wild (LFW) and YouTube Faces (YTF). Experimental results demonstrate that by initializing the deep neural network with pre-trained autoencod
    
[^134]: 变化的行动空间中的情境式强化学习

    In-Context Reinforcement Learning for Variable Action Spaces

    [https://arxiv.org/abs/2312.13327](https://arxiv.org/abs/2312.13327)

    本文提出了一种Headless-AD模型，通过只训练一次，能够在变化的行动空间中实现强化学习任务的泛化。实验证明该模型能够在从未遇到过的行动空间上表现出显著的泛化能力，甚至胜过针对特定行动集训练的模型。

    

    最近的研究表明，预先在多样数据集上进行上下文多情节训练的变形金刚网络可以在情境中泛化到新的强化学习任务。先前提出的模型的一个关键限制是它们依赖于预定义的行动空间大小和结构。引入新的行动空间通常需要数据重新收集和模型重新训练，这对于一些应用来说可能是昂贵的。我们的工作表明，通过提出一种只训练一次的Headless-AD模型，可以缓解这个问题，该模型能够泛化到具有可变大小、语义内容和顺序的离散动作空间。通过在伯努利和上下文赌博机以及一个网格世界环境中进行实验，我们展示了Headless-AD在从未遇到的行动空间上表现出显著的泛化能力，甚至在几个环境配置上胜过专门针对特定行动集训练的模型。

    Recently, it has been shown that transformers pre-trained on diverse datasets with multi-episode contexts can generalize to new reinforcement learning tasks in-context. A key limitation of previously proposed models is their reliance on a predefined action space size and structure. The introduction of a new action space often requires data re-collection and model re-training, which can be costly for some applications. In our work, we show that it is possible to mitigate this issue by proposing the Headless-AD model that, despite being trained only once, is capable of generalizing to discrete action spaces of variable size, semantic content and order. By experimenting with Bernoulli and contextual bandits, as well as a gridworld environment, we show that Headless-AD exhibits significant capability to generalize to action spaces it has never encountered, even outperforming specialized models trained for a specific set of actions on several environment configurations.
    
[^135]: LLM精选：在超低数据环境中利用LLMs和数据筛选进行表格增强

    Curated LLM: Synergy of LLMs and Data Curation for tabular augmentation in ultra low-data regimes

    [https://arxiv.org/abs/2312.12112](https://arxiv.org/abs/2312.12112)

    本论文提出了CLLM方法，利用LLMs和数据筛选在低数据环境中进行表格增强。通过利用大型语言模型的先验知识以及基于学习动态、置信度和不确定度指标的筛选机制，CLLM取得了优越的性能。

    

    低数据情况下的机器学习（ML）仍然是一个被低估但至关重要的问题。因此，增加ML所需的数据样本大小的数据增强方法对于释放ML在数据匮乏的地区和领域的变革潜力至关重要。不幸的是，有限的训练集限制了传统的表格合成数据生成器在生成ML任务所需的大规模且多样化的增强数据集方面的能力。为了解决这个挑战，我们引入了CLLM，它利用大型语言模型（LLMs）在低数据环境中进行数据增强的先验知识。然而，像任何生成模型一样，并非LLMs生成的所有数据都能提高下游的效用。因此，我们引入了一种基于学习动态、置信度和不确定度指标的原则性筛选机制，以获取高质量的数据集。通过多个真实世界数据集的实证，我们展示了CLLM在低数据环境中的优越性能。

    Machine Learning (ML) in low-data settings remains an underappreciated yet crucial problem. Hence, data augmentation methods to increase the sample size of datasets needed for ML are key to unlocking the transformative potential of ML in data-deprived regions and domains. Unfortunately, the limited training set constrains traditional tabular synthetic data generators in their ability to generate a large and diverse augmented dataset needed for ML tasks. To address this challenge, we introduce CLLM, which leverages the prior knowledge of Large Language Models (LLMs) for data augmentation in the low-data regime. However, not all the data generated by LLMs will improve downstream utility, as for any generative model. Consequently, we introduce a principled curation mechanism, leveraging learning dynamics, coupled with confidence and uncertainty metrics, to obtain a high-quality dataset. Empirically, on multiple real-world datasets, we demonstrate the superior performance of CLLM in the lo
    
[^136]: 公平性约束能够在多大程度上帮助从有偏差的数据中恢复？

    How Far Can Fairness Constraints Help Recover From Biased Data?

    [https://arxiv.org/abs/2312.10396](https://arxiv.org/abs/2312.10396)

    公平性约束在极度有偏差的数据上能够恢复到原始数据分布上准确和公平的分类器。

    

    一般认为，在公平分类中，公平性约束会导致准确性的减少，而有偏差的数据可能会加剧这种情况。然而，Blum＆Stangl（2019）的研究表明，在极度有偏差的数据上，即使采用平等机会约束，也可以恢复到原始数据分布上准确和公平的分类器。他们的研究结果很有趣，因为它证明了公平性约束可以隐式修正数据偏差，同时克服了公平性与准确性之间的平衡问题。他们的数据偏差模型模拟了受压迫人群的表征和标签偏见，并在具有独立标签噪声的简单条件下，针对一个理想化的数据分布展示了上述结果。我们提出了一种通用方法，以扩展Blum＆Stangl（2019）的结果，适用于不同的公平性约束、数据偏差模型、数据分布和假设类别。

    A general belief in fair classification is that fairness constraints incur a trade-off with accuracy, which biased data may worsen. Contrary to this belief, Blum & Stangl (2019) show that fair classification with equal opportunity constraints even on extremely biased data can recover optimally accurate and fair classifiers on the original data distribution. Their result is interesting because it demonstrates that fairness constraints can implicitly rectify data bias and simultaneously overcome a perceived fairness-accuracy trade-off. Their data bias model simulates under-representation and label bias in underprivileged population, and they show the above result on a stylized data distribution with i.i.d. label noise, under simple conditions on the data distribution and bias parameters. We propose a general approach to extend the result of Blum & Stangl (2019) to different fairness constraints, data bias models, data distributions, and hypothesis classes. We strengthen their result, and
    
[^137]: CIDR: 一种用于最小特征删除问题的合作式集成动态修正方法

    CIDR: A Cooperative Integrated Dynamic Refining Method for Minimal Feature Removal Problem

    [https://arxiv.org/abs/2312.08157](https://arxiv.org/abs/2312.08157)

    CIDR是一种解决最小特征删除问题的合作式集成动态修正方法，通过使用合作式集成梯度来检测特征交互作用，并将问题转化为一个背包问题，从众多候选集中确定最小特征集。

    

    后续解释领域中的最小特征删除问题旨在识别最小特征集（MFS）。先前的研究使用贪婪算法计算最小特征集时缺乏对特征交互作用的探索，而在一般情况下无法满足单调性假设。为了解决上述限制，我们提出了一种合作式集成动态修正方法（CIDR）来高效地发现最小特征集。具体而言，我们设计了合作式集成梯度（CIG）来检测特征之间的交互作用。通过将CIG与最小特征集的特征特性相结合，将最小特征删除问题转化为一个背包问题。此外，我们还设计了辅助最小特征修正算法来从众多候选集中确定最小特征集。据我们所知，我们的工作是在自然语言处理领域中首次提出了最小特征删除问题。

    The minimal feature removal problem in the post-hoc explanation area aims to identify the minimal feature set (MFS). Prior studies using the greedy algorithm to calculate the minimal feature set lack the exploration of feature interactions under a monotonic assumption which cannot be satisfied in general scenarios. In order to address the above limitations, we propose a Cooperative Integrated Dynamic Refining method (CIDR) to efficiently discover minimal feature sets. Specifically, we design Cooperative Integrated Gradients (CIG) to detect interactions between features. By incorporating CIG and characteristics of the minimal feature set, we transform the minimal feature removal problem into a knapsack problem. Additionally, we devise an auxiliary Minimal Feature Refinement algorithm to determine the minimal feature set from numerous candidate sets. To the best of our knowledge, our work is the first to address the minimal feature removal problem in the field of natural language process
    
[^138]: DroneOptiNet: 一种用于5G及其后太阳能小型蜂窝网络的最佳无人机负载重分配机制的框架

    DroneOptiNet: A Framework for Optimal Drone-based Load Redistribution Mechanism for 5G and Beyond Solar Small Cell Networks

    [https://arxiv.org/abs/2311.12944](https://arxiv.org/abs/2311.12944)

    本研究提出了一种用于5G及其后太阳能小型蜂窝网络的最佳无人机负载重分配机制，通过使用无人机上的空中基站进行可靠安全的电力再分配，提高了网络的可靠性和稳健性。

    

    第五代及其后的蜂窝网络对功率需求提出了重要的限制，需要能够高效利用能源的解决方案。在本研究中，我们提出了一种新颖的使用无人机上的空中基站（BS）进行可靠安全的电力再分配的用户负载转移方法，以跨越由绿色小型蜂窝BS组成的微网网络。根据用户密度和空中基站的可用性，通过将空中基站从高能耗小区迁移到低能耗小区，来满足能量不足的小区的能量需求。所提出的混合无人机框架将长短期记忆与独特的成本函数结合，使用进化神经网络来有效地管理无人机和基站的能量和负载重分配。所提出的算法减少了基站停电，并保持了一致的吞吐量稳定性，从而展示了其提升无线网络可靠性和稳健性的能力。

    The power requirements posed by the fifth-generation and beyond cellular networks are an important constraint in network deployment and require energy-efficient solutions. In this work, we propose a novel user load transfer approach using airborne base stations (BS) mounted on drones for reliable and secure power redistribution across the micro-grid network comprising green small cell BSs. Depending on the user density and the availability of an aerial BS, the energy requirement of a cell with an energy deficit is accommodated by migrating the aerial BS from a high-energy to a low-energy cell. The proposed hybrid drone-based framework integrates long short-term memory with unique cost functions using an evolutionary neural network for drones and BSs and efficiently manages energy and load redistribution. The proposed algorithm reduces power outages at BSs and maintains consistent throughput stability, thereby demonstrating its capability to boost the reliability and robustness of wirel
    
[^139]: 通过自注意力建模选择

    Modeling Choice via Self-Attention

    [https://arxiv.org/abs/2311.07607](https://arxiv.org/abs/2311.07607)

    本论文提出了一种选择模型，利用自注意力成功地进行了建模，这是在深度学习和选择建模领域中的一个重要的研究空白。

    

    选择模型是运营管理领域中许多经典优化问题的基础输入，包括组合、库存和定价优化。准确地从数据中估计这些模型是在实践中应用这些优化问题的关键步骤。与此同时，深度学习的最新进展引起了将这些技术整合到选择建模中的兴趣。然而，在深度学习和选择建模的交叉点上存在明显的研究空白，尤其是在理论和经验基础上。因此，我们首先提出了一种选择模型，这是第一个成功（从理论和实践两个方面）利用现代神经网络架构概念（自注意力）的模型。在理论上，我们证明了我们基于注意力的选择模型是Halo多项式逻辑（Halo-MNL）模型的低秩推广。我们证明了Halo-MNL模型需要$\Omega(m^2)$的计算量，而我们的模型只需要$\Omega(m)$的计算量。

    Models of choice are a fundamental input to many now-canonical optimization problems in the field of Operations Management, including assortment, inventory, and price optimization. Naturally, accurate estimation of these models from data is a critical step in the application of these optimization problems in practice. Concurrently, recent advancements in deep learning have sparked interest in integrating these techniques into choice modeling. However, there is a noticeable research gap at the intersection of deep learning and choice modeling, particularly with both theoretical and empirical foundations. Thus motivated, we first propose a choice model that is the first to successfully (both theoretically and practically) leverage a modern neural network architectural concept (self-attention). Theoretically, we show that our attention-based choice model is a low-rank generalization of the Halo Multinomial Logit (Halo-MNL) model. We prove that whereas the Halo-MNL requires $\Omega(m^2)$ d
    
[^140]: Lie神经元：半单Lie代数的伴随等变神经网络

    Lie Neurons: Adjoint-Equivariant Neural Networks for Semisimple Lie Algebras

    [https://arxiv.org/abs/2310.04521](https://arxiv.org/abs/2310.04521)

    本文提出了一种Lie神经元网络，能够以任何半单Lie代数数据为输入，通过伴随操作使其具有等变性。通过推广向量神经元网络和引入新的层，该网络在各个领域具有广泛的适用性和竞争性能。

    

    本文提出了一种等变神经网络，将数据作为输入，该数据存在于任何半单Lie代数中。对应的群通过伴随操作作用于Lie代数上，使得我们提出的网络具有伴随等变性。我们的框架将简单的$\mathrm{SO}(3)$-等变网络——向量神经元从3维欧几里得空间推广到Lie代数空间，利用Killing形式的不变性质。此外，我们还提出了新颖的Lie括号层和几何通道混合层来扩展建模能力。实验在多个任务上对$\mathfrak{so}(3)$和$\mathfrak{sl}(3)$ Lie代数进行了验证，包括拟合等变和不变函数、学习系统动力学、点云配准和基于单应性的形状分类。我们提出的等变网络在各个领域都表现出广泛的适用性和竞争性能。

    This paper proposes an equivariant neural network that takes data in any semi-simple Lie algebra as input. The corresponding group acts on the Lie algebra as adjoint operations, making our proposed network adjoint-equivariant. Our framework generalizes the Vector Neurons, a simple $\mathrm{SO}(3)$-equivariant network, from 3-D Euclidean space to Lie algebra spaces, building upon the invariance property of the Killing form. Furthermore, we propose novel Lie bracket layers and geometric channel mixing layers that extend the modeling capacity. Experiments are conducted for the $\mathfrak{so}(3)$ and $\mathfrak{sl}(3)$ Lie algebras on various tasks, including fitting equivariant and invariant functions, learning system dynamics, point cloud registration, and homography-based shape classification. Our proposed equivariant network shows wide applicability and competitive performance in various domains.
    
[^141]: OHQ: 芯片上的硬件感知量化

    OHQ: On-chip Hardware-aware Quantization

    [https://arxiv.org/abs/2309.01945](https://arxiv.org/abs/2309.01945)

    本文提出了一种在芯片上进行硬件感知混合精度量化的框架（OHQ），通过构建量化感知流水线和引入掩码引导的量化估计技术，实现了在资源受限的硬件上进行高效量化，填补了现有混合精度量化的搜索空间过大和实际部署差距大的问题。

    

    量化成为在资源受限的硬件上部署先进深度模型的最有前途的方法之一。混合精度量化利用多位宽架构来释放量化模型的准确性和效率潜力。然而，现有的混合精度量化存在搜索空间过大的问题，导致巨大的计算开销。因此，量化过程依赖于独立的高性能设备，而不是本地进行，这也导致了考虑的硬件指标与实际部署之间的显著差距。本文提出了一种在芯片上进行硬件感知混合精度量化的框架（OHQ），而无需访问在线设备。首先，我们构建了芯片上的量化感知（OQA）流水线，能够感知量化算子在硬件上的实际效率指标。其次，我们提出了基于掩码引导的量化估计（MQE）技术。

    Quantization emerges as one of the most promising approaches for deploying advanced deep models on resource-constrained hardware. Mixed-precision quantization leverages multiple bit-width architectures to unleash the accuracy and efficiency potential of quantized models. However, existing mixed-precision quantization suffers exhaustive search space that causes immense computational overhead. The quantization process thus relies on separate high-performance devices rather than locally, which also leads to a significant gap between the considered hardware metrics and the real deployment.In this paper, we propose an On-chip Hardware-aware Quantization (OHQ) framework that performs hardware-aware mixed-precision quantization without accessing online devices. First, we construct the On-chip Quantization Awareness (OQA) pipeline, enabling perceive the actual efficiency metrics of the quantization operator on the hardware.Second, we propose Mask-guided Quantization Estimation (MQE) technique 
    
[^142]: Lookbehind-SAM: k步回望，1步前进

    Lookbehind-SAM: k steps back, 1 step forward

    [https://arxiv.org/abs/2307.16704](https://arxiv.org/abs/2307.16704)

    本研究提出了一种名为Lookbehind-SAM的方法，通过多次上升步骤和线性插值来增强最大化和最小化过程，以实现更好的损失锐度折衷。实验证明，该方法在各种任务中都有多种优点，包括提高的泛化性能、更高的鲁棒性和改进的学习过程。

    

    锐度感知优化（SAM）方法通过将最小化损失值和损失锐度问题表述为极小极大型目标，得到了越来越多的关注。在本研究中，我们增加了SAM目标中最大化和最小化部分的效率，以实现更好的损失锐度折衷。受Lookahead优化器的启发，该优化器使用多个向前的下降步骤，我们提出了Lookbehind，它在后面执行多个上升步骤，增强了SAM的最大化步骤，并找到了一个具有更高损失的最坏情况扰动。然后，为了减小由于收集到的多个上升步骤的梯度所引起的下降步骤的方差，我们采用线性插值来改进最小化过程。Lookbehind在各种任务中带来了许多好处。特别是，我们展示了提高的泛化性能，对噪声权重的更高鲁棒性，以及在学习过程中改进的效果和较少的灾难性遗忘。

    Sharpness-aware minimization (SAM) methods have gained increasing popularity by formulating the problem of minimizing both loss value and loss sharpness as a minimax objective. In this work, we increase the efficiency of the maximization and minimization parts of SAM's objective to achieve a better loss-sharpness trade-off. By taking inspiration from the Lookahead optimizer, which uses multiple descent steps ahead, we propose Lookbehind, which performs multiple ascent steps behind to enhance the maximization step of SAM and find a worst-case perturbation with higher loss. Then, to mitigate the variance in the descent step arising from the gathered gradients across the multiple ascent steps, we employ linear interpolation to refine the minimization step. Lookbehind leads to a myriad of benefits across a variety of tasks. Particularly, we show increased generalization performance, greater robustness against noisy weights, as well as improved learning and less catastrophic forgetting in l
    
[^143]: 通过大规模语言模型革新网络威胁检测：一种面向物联网/工业物联网设备的隐私保护BERT轻量级模型

    Revolutionizing Cyber Threat Detection with Large Language Models: A privacy-preserving BERT-based Lightweight Model for IoT/IIoT Devices

    [https://arxiv.org/abs/2306.14263](https://arxiv.org/abs/2306.14263)

    本文介绍了一种名为SecurityBERT的新型模型，采用预训练的BERT模型和隐私保护编码技术，用于在物联网网络中检测网络威胁。该模型能够高精度识别网络攻击，并具有最小的计算要求。

    

    自然语言处理领域（NLP）目前正在经历一场由基于革命性Transformer架构的预训练大型语言模型（LLM）驱动的革命性转变。随着网络安全攻击的频率和多样性持续增加，事件检测的重要性显著提高。物联网设备正在迅速扩展，因此需要高精度和最小计算要求的自主识别物联网中的基于网络的攻击的有效技术。本文提出了SecurityBERT，一种新颖的架构，利用双向编码器表示来自Transformer（BERT）模型，用于物联网网络中的网络威胁检测。在SecurityBERT的训练过程中，我们采用了一种名为隐私保护固定长度编码（PPFLE）的新型隐私保护编码技术。通过将网络流量数据以结构化格式进行有效表示，我们成功地将其与基于Transformer的语言模型相结合。

    The field of Natural Language Processing (NLP) is currently undergoing a revolutionary transformation driven by the power of pre-trained Large Language Models (LLMs) based on groundbreaking Transformer architectures. As the frequency and diversity of cybersecurity attacks continue to rise, the importance of incident detection has significantly increased. IoT devices are expanding rapidly, resulting in a growing need for efficient techniques to autonomously identify network-based attacks in IoT networks with both high precision and minimal computational requirements. This paper presents SecurityBERT, a novel architecture that leverages the Bidirectional Encoder Representations from Transformers (BERT) model for cyber threat detection in IoT networks. During the training of SecurityBERT, we incorporated a novel privacy-preserving encoding technique called Privacy-Preserving Fixed-Length Encoding (PPFLE). We effectively represented network traffic data in a structured format by combining 
    
[^144]: HardSATGEN：理解难SAT公式生成的困难和强的结构困难感知基线

    HardSATGEN: Understanding the Difficulty of Hard SAT Formula Generation and A Strong Structure-Hardness-Aware Baseline

    [https://arxiv.org/abs/2302.02104](https://arxiv.org/abs/2302.02104)

    HardSATGEN方法提出了一种精细的控制机制，以更好地恢复工业基准的结构和计算特性，此方法在工业SAT公式生成任务中表现出优越性。

    

    工业SAT公式生成是一项关键但具有挑战性的任务。现有的SAT生成方法很难同时捕捉全局结构特性并保持合理的计算困难度。我们首先对之前学习方法在重现原始实例的计算困难度方面的限制进行了深入分析，这可能源自其采用的分裂合并过程的内在同质性。基于工业公式呈现明确社区结构和过度分割子结构导致逻辑结构语义形成困难的观察，我们提出了HardSATGEN，在SAT公式生成的神经分裂合并范例中引入了精细的控制机制，以更好地恢复工业基准的结构和计算特性。包括私人和实际企业测试基准评估在内的实验表明HardSATGEN的优越性，成为唯一一种能够

    Industrial SAT formula generation is a critical yet challenging task. Existing SAT generation approaches can hardly simultaneously capture the global structural properties and maintain plausible computational hardness. We first present an in-depth analysis for the limitation of previous learning methods in reproducing the computational hardness of original instances, which may stem from the inherent homogeneity in their adopted split-merge procedure. On top of the observations that industrial formulae exhibit clear community structure and oversplit substructures lead to the difficulty in semantic formation of logical structures, we propose HardSATGEN, which introduces a fine-grained control mechanism to the neural split-merge paradigm for SAT formula generation to better recover the structural and computational properties of the industrial benchmarks. Experiments including evaluations on private and practical corporate testbed show the superiority of HardSATGEN being the only method to
    
[^145]: 布尔观察博弈

    Boolean Observation Games

    [https://arxiv.org/abs/2202.03637](https://arxiv.org/abs/2202.03637)

    布尔观察博弈是一种有限的多人策略博弈，具有不完全信息和定性目标。它是布尔博弈的一种泛化，可以捕捉到不完美和不完全信息的特点。

    

    我们介绍了布尔观察博弈，这是一种有限的多人策略博弈，具有不完全信息和定性目标。在布尔观察博弈中，每个玩家与一组命题变量相关联，只有它能够观察到变量的值，并且它控制着是否以及向谁透露该值。它不能控制给定的固定变量值。布尔观察博弈是布尔博弈的一种泛化，布尔博弈是一种经过充分研究的策略博弈子类，但具有完全信息，每个玩家控制其变量的值。在布尔观察博弈中，玩家的目标描述了多智能体对变量的知识。与经典的策略博弈类似，玩家同时选择他们的策略，因此观察博弈捕捉到了不完美和不完全信息的方面。它们需要推理关于给定变量无法区分的一组估值的结果集。

    We introduce Boolean Observation Games, a subclass of multi-player finite strategic games with incomplete information and qualitative objectives. In Boolean observation games, each player is associated with a finite set of propositional variables of which only it can observe the value, and it controls whether and to whom it can reveal that value. It does not control the given, fixed, value of variables. Boolean observation games are a generalization of Boolean games, a well-studied subclass of strategic games but with complete information, and wherein each player controls the value of its variables.   In Boolean observation games, player goals describe multi-agent knowledge of variables. As in classical strategic games, players choose their strategies simultaneously and therefore observation games capture aspects of both imperfect and incomplete information. They require reasoning about sets of outcomes given sets of indistinguishable valuations of variables. An outcome relation betwee
    
[^146]: 自奖励语言模型

    Self-Rewarding Language Models. (arXiv:2401.10020v1 [cs.CL])

    [http://arxiv.org/abs/2401.10020](http://arxiv.org/abs/2401.10020)

    该论文提出了自奖励语言模型的概念，通过LLM作为评判者，使用语言模型自己提供训练过程中的奖励。研究表明，该方法不仅可以提高指令遵循能力，还可以为自己提供高质量的奖励。通过对Llama 2 70B模型的三次迭代微调，结果在AlpacaEval 2.0排行榜上超过了其他现有系统。这项工作为实现能够不断自我改进的模型开辟了新的可能性。

    

    我们假设要实现超人级的智能体，未来的模型需要超人级的反馈，以提供足够的训练信号。目前的方法通常是从人类偏好中训练奖励模型，这可能会受到人类表现水平的限制，而且这些独立的冻结奖励模型在LLM训练过程中无法学习改进。在这项工作中，我们研究了自奖励语言模型，其中语言模型本身通过LLM作为评判者的提示在训练过程中提供自己的奖励。我们表明，在迭代DPO训练中，不仅指令遵循能力得到了提高，而且能够为自己提供高质量的奖励。通过对Llama 2 70B进行我们方法的三次迭代的微调，得到的模型在AlpacaEval 2.0排行榜上胜过许多现有系统，包括Claude 2、Gemini Pro和GPT-4 0613。虽然这只是一项初步研究，但这项工作为可能实现能够不断自我改进的模型打开了大门。

    We posit that to achieve superhuman agents, future models require superhuman feedback in order to provide an adequate training signal. Current approaches commonly train reward models from human preferences, which may then be bottlenecked by human performance level, and secondly these separate frozen reward models cannot then learn to improve during LLM training. In this work, we study Self-Rewarding Language Models, where the language model itself is used via LLM-as-a-Judge prompting to provide its own rewards during training. We show that during Iterative DPO training that not only does instruction following ability improve, but also the ability to provide high-quality rewards to itself. Fine-tuning Llama 2 70B on three iterations of our approach yields a model that outperforms many existing systems on the AlpacaEval 2.0 leaderboard, including Claude 2, Gemini Pro, and GPT-4 0613. While only a preliminary study, this work opens the door to the possibility of models that can continuall
    
[^147]: 用空间自适应滤波重新思考谱图神经网络

    Rethinking Spectral Graph Neural Networks with Spatially Adaptive Filtering. (arXiv:2401.09071v1 [cs.LG])

    [http://arxiv.org/abs/2401.09071](http://arxiv.org/abs/2401.09071)

    本文重新思考了谱图神经网络，并揭示了谱滤波和空间聚合之间的联系。该研究发现，谱滤波在隐含地将原始图转换成适应性新图，并明确计算用于空间聚合的新图。适应性新图展现出非局部性，并能够反映节点之间的标签一致性。

    

    尽管谱图神经网络（GNN）在理论上在谱域中有很好的基础，但它们实际上依赖于多项式逼近，意味着它们与空间域有着深刻的联系。由于以前的研究很少从空间角度研究谱图GNN，因此它们在空间域的可解释性仍然难以捉摸，例如，谱图GNN在空间域中实际上编码了哪些信息？为了回答这个问题，本文在谱滤波和空间聚合之间建立了一个理论上的联系，揭示了谱滤波隐含地将原始图转换成适应性新图的内在交互作用，并明确地计算用于空间聚合的适应性新图。理论和经验研究表明，适应性新图不仅表现出非局部性，还能够容纳有符号的边权重以反映节点之间的标签一致性。因此，这些发现突显了谱图GNN在空间中的可解释性角色。

    Whilst spectral Graph Neural Networks (GNNs) are theoretically well-founded in the spectral domain, their practical reliance on polynomial approximation implies a profound linkage to the spatial domain. As previous studies rarely examine spectral GNNs from the spatial perspective, their spatial-domain interpretability remains elusive, e.g., what information is essentially encoded by spectral GNNs in the spatial domain? In this paper, to answer this question, we establish a theoretical connection between spectral filtering and spatial aggregation, unveiling an intrinsic interaction that spectral filtering implicitly leads the original graph to an adapted new graph, explicitly computed for spatial aggregation. Both theoretical and empirical investigations reveal that the adapted new graph not only exhibits non-locality but also accommodates signed edge weights to reflect label consistency between nodes. These findings thus highlight the interpretable role of spectral GNNs in the spatial 
    
[^148]: 通过遥感图像和多语义信息检测城市功能区的多模态学习

    Multimodal Learning for detecting urban functional zones using remote sensing image and multi-semantic information. (arXiv:2401.06550v1 [cs.CV])

    [http://arxiv.org/abs/2401.06550](http://arxiv.org/abs/2401.06550)

    本研究提出了一种利用遥感图像和多语义信息进行城市功能区检测的多模态学习算法，能够满足移动互联网在线到离线业务的精确要求。

    

    城市兴趣区（AOI）是指具有定义边界的整合的城市功能区域。城市商业的迅速发展导致了对定义AOI的更精确要求的增加。然而，现有研究主要集中于城市规划或区域经济分析的广泛AOI挖掘，未能满足移动互联网在线到离线业务的精确要求。这些业务需要到具体的社区、学校或医院的准确度。在本文中，我们提出了一种端到端的多模态深度学习算法，用于使用遥感图像和多语义参考信息检测AOI围栏多边形。然后，我们通过包含动态人员流动和物流地址信息的级联模块来评估其时效性。具体而言，我们从选择特定类别的兴趣点（POI）开始，并用它来召回相应的遥感图像、附近的POI、道路n

    Urban area-of-interest (AOI) refers to an integrated urban functional zone with defined boundaries. The rapid development of urban commerce has resulted in an increased demand for more precise requirements in defining AOIs. However, existing research primarily concentrates on broad AOI mining for urban planning or regional economic analysis, failing to cater to the precise requirements of mobile Internet online-to-offline businesses. These businesses necessitate accuracy down to a specific community, school, or hospital. In this paper, we propose an end-to-end multimodal deep learning algorithm for detecting AOI fence polygon using remote sensing images and multi-semantics reference information. We then evaluate its timeliness through a cascaded module that incorporates dynamic human mobility and logistics address information. Specifically, we begin by selecting a point-of-interest (POI) of specific category, and use it to recall corresponding remote sensing images, nearby POIs, road n
    
[^149]: RoSA: 通过鲁棒适应实现准确的参数高效微调

    RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation. (arXiv:2401.04679v1 [cs.CL])

    [http://arxiv.org/abs/2401.04679](http://arxiv.org/abs/2401.04679)

    RoSA是一种新的PEFT方法，通过在预训练权重上训练低秩和高度稀疏的组件，以高效近似完全微调的性能，来实现准确的参数高效微调。在多个生成任务中，RoSA表现出优于其他方法的性能。

    

    我们研究了在大语言模型 (LLMs) 的背景下，能够在有限的计算和内存预算下提供良好准确性的参数高效微调 (PEFT) 方法。我们提出了一种新的PEFT方法，称为RoSA，受鲁棒主成分分析 (PCA) 的启发，它在一组固定的预训练权重上共同训练$\textit{低秩}$和$\textit{高度稀疏}$的组件，以高效近似完全微调（FFT）解决方案的性能。我们展示了RoSA在一系列具有挑战性的生成任务上的性能，例如小学数学和SQL查询生成，这些任务需要进行微调以获得良好性能，我们证明了在相同的参数预算下，RoSA优于LoRA和纯粹的稀疏微调。我们通过稀疏GPU内核为RoSA提供系统支持，以补充训练算法，从而实现内存和计算效率的训练。我们的代码将在https://github.com/IST-DASLab上提供。

    We investigate parameter-efficient fine-tuning (PEFT) methods that can provide good accuracy under limited computational and memory budgets in the context of large language models (LLMs). We present a new PEFT method called Robust Adaptation (RoSA) inspired by robust principal component analysis (PCA) that jointly trains $\textit{low-rank}$ and $\textit{highly-sparse}$ components on top of a set of fixed pretrained weights to efficiently approximate the performance of a full-fine-tuning (FFT) solution. Across a series of challenging generative tasks such as grade-school math and SQL query generation, which require fine-tuning for good performance, we show that RoSA outperforms both LoRA and pure sparse fine-tuning, at the same parameter budget. We provide system support for RoSA to complement the training algorithm, specifically in the form of sparse GPU kernels which enable memoryand computationally-efficient training. Our code will be made available at https://github.com/IST-DASLab
    
[^150]: 上下文固定预算的最佳臂识别：适应性实验设计与策略学习

    Contextual Fixed-Budget Best Arm Identification: Adaptive Experimental Design with Policy Learning. (arXiv:2401.03756v1 [cs.LG])

    [http://arxiv.org/abs/2401.03756](http://arxiv.org/abs/2401.03756)

    该论文研究了个性化治疗推荐的问题，提出了一个上下文固定预算的最佳臂识别模型，通过自适应实验设计和策略学习来推荐最佳治疗方案，并通过最坏情况下的期望简单遗憾来衡量推荐的有效性。

    

    个性化治疗推荐是基于证据的决策中的关键任务。在这项研究中，我们将这个任务作为一个带有上下文信息的固定预算最佳臂识别（Best Arm Identification, BAI）问题来进行建模。在这个设置中，我们考虑了一个给定多个治疗臂的自适应试验。在每一轮中，决策者观察一个刻画实验单位的上下文（协变量），并将该单位分配给其中一个治疗臂。在实验结束时，决策者推荐一个在给定上下文条件下预计产生最高期望结果的治疗臂（最佳治疗臂）。该决策的有效性通过最坏情况下的期望简单遗憾（策略遗憾）来衡量，该遗憾表示在给定上下文条件下，最佳治疗臂和推荐治疗臂的条件期望结果之间的最大差异。我们的初始步骤是推导最坏情况下期望简单遗憾的渐近下界，该下界还暗示着解决该问题的一些思路。

    Individualized treatment recommendation is a crucial task in evidence-based decision-making. In this study, we formulate this task as a fixed-budget best arm identification (BAI) problem with contextual information. In this setting, we consider an adaptive experiment given multiple treatment arms. At each round, a decision-maker observes a context (covariate) that characterizes an experimental unit and assigns the unit to one of the treatment arms. At the end of the experiment, the decision-maker recommends a treatment arm estimated to yield the highest expected outcome conditioned on a context (best treatment arm). The effectiveness of this decision is measured in terms of the worst-case expected simple regret (policy regret), which represents the largest difference between the conditional expected outcomes of the best and recommended treatment arms given a context. Our initial step is to derive asymptotic lower bounds for the worst-case expected simple regret, which also implies idea
    
[^151]: 为多任务联邦学习提供公平性感知的作业调度

    Fairness-Aware Job Scheduling for Multi-Job Federated Learning. (arXiv:2401.02740v1 [cs.LG])

    [http://arxiv.org/abs/2401.02740](http://arxiv.org/abs/2401.02740)

    本文提出了一种公平感知联邦作业调度（FairFedJS）方法，以确保将高需求的FL客户端数据集公平分配给需要它们的FL作业，并在实验证明其优势。

    

    联邦学习（FL）使多个数据所有者（即FL客户端）能够在不泄露敏感私人数据的情况下共同训练机器学习模型。现有的FL研究主要关注垄断场景，在该场景中，单个FL服务器在每轮训练中选择一部分FL客户端来更新其本地模型。实际上，可能会有多个FL服务器同时尝试从同一个池中选择客户端。本文提出了一种首创的公平感知联邦作业调度（FairFedJS）方法来弥合这一差距。基于Lyapunov优化，它通过同时考虑当前需求和作业付款出价，确保将高需求的FL客户端数据集公平分配给需要它们的FL作业，以防止等待时间过长。基于两个数据集对FairFedJS与四种最先进的方法进行了大量实验证明了其显著优势。它在平均上击败了最佳基准线31.9%和1.0%。

    Federated learning (FL) enables multiple data owners (a.k.a. FL clients) to collaboratively train machine learning models without disclosing sensitive private data. Existing FL research mostly focuses on the monopoly scenario in which a single FL server selects a subset of FL clients to update their local models in each round of training. In practice, there can be multiple FL servers simultaneously trying to select clients from the same pool. In this paper, we propose a first-of-its-kind Fairness-aware Federated Job Scheduling (FairFedJS) approach to bridge this gap. Based on Lyapunov optimization, it ensures fair allocation of high-demand FL client datasets to FL jobs in need of them, by jointly considering the current demand and the job payment bids, in order to prevent prolonged waiting. Extensive experiments comparing FairFedJS against four state-of-the-art approaches on two datasets demonstrate its significant advantages. It outperforms the best baseline by 31.9% and 1.0% on avera
    
[^152]: 振动信号的二次时间频率分析用于诊断轴承故障

    Quadratic Time-Frequency Analysis of Vibration Signals for Diagnosing Bearing Faults. (arXiv:2401.01172v1 [cs.LG])

    [http://arxiv.org/abs/2401.01172](http://arxiv.org/abs/2401.01172)

    本文提出了一种融合时间频率分析和深度学习技术的方法，用于在实际条件下诊断带有时间变化速度和不同噪声水平的轴承故障。这种方法有效地解析与不同轴承故障相关的独特动态模式。

    

    轴承故障的诊断对于降低维修成本和设备停机至关重要。轴承故障是机器振动的主要原因，分析其信号形态可以揭示其健康状况。然而，现有的方法主要针对控制环境进行优化，忽略了实际条件下的时间变化的转速和振动的非平稳性。本文提出了一种时间频率分析和深度学习技术的融合方法，用于在时间变化速度和不同噪声水平下诊断轴承故障。首先，我们制定了轴承故障引起的振动，并讨论了它们的非平稳性与轴承固有和操作参数之间的联系。我们还阐述了二次时间频率分布，并验证了它们解析与不同轴承故障相关的独特动态模式的有效性。基于此，我们设计了一个时间频率卷积神经网络。

    Diagnosis of bearing faults is paramount to reducing maintenance costs and operational breakdowns. Bearing faults are primary contributors to machine vibrations, and analyzing their signal morphology offers insights into their health status. Unfortunately, existing approaches are optimized for controlled environments, neglecting realistic conditions such as time-varying rotational speeds and the vibration's non-stationary nature. This paper presents a fusion of time-frequency analysis and deep learning techniques to diagnose bearing faults under time-varying speeds and varying noise levels. First, we formulate the bearing fault-induced vibrations and discuss the link between their non-stationarity and the bearing's inherent and operational parameters. We also elucidate quadratic time-frequency distributions and validate their effectiveness in resolving distinctive dynamic patterns associated with different bearing faults. Based on this, we design a time-frequency convolutional neural n
    
[^153]: 能否大型语言模型捕捉全球变暖的公众意见？一项关于算法逼真性和偏见的实证评估

    Can Large Language Models Capture Public Opinion about Global Warming? An Empirical Assessment of Algorithmic Fidelity and Bias. (arXiv:2311.00217v1 [cs.AI])

    [http://arxiv.org/abs/2311.00217](http://arxiv.org/abs/2311.00217)

    本研究评估了大型语言模型（LLMs）的算法逼真性和偏见，并发现LLMs可以有效捕捉总统投票行为，但在准确表示全球变暖观点方面存在挑战。同时，LLMs对某些群体的观点估计存在偏差，特别是对非洲裔美国人对全球变暖的担忧低估。这些结果突出了LLMs在社会科学研究中的潜力，并强调了准确性的重要性。

    

    大型语言模型（LLMs）通过模拟人类的感知和行为，展示了它们在社会科学研究中的潜力，这被称为算法逼真性。本研究通过利用两个代表性的气候变化调查评估LLMs的算法逼真性和偏见。LLMs被条件化为基于人口统计学和/或心理协变量来模拟调查回答。研究结果表明，当相关协变量没有包含在内时，LLMs可以有效捕捉总统投票行为，但在准确表示全球变暖观点方面存在挑战。当LLMs被人口统计学和协变量同时条件化时，GPT-4表现出更好的性能。然而，LLMs对特定群体的观点估计存在差异，LLMs倾向于低估非洲裔美国人对全球变暖的担忧。虽然突出了LLMs在社会科学研究中的潜力，但这些结果强调了精确性的重要性。

    Large language models (LLMs) have demonstrated their potential in social science research by emulating human perceptions and behaviors, a concept referred to as algorithmic fidelity. This study assesses the algorithmic fidelity and bias of LLMs by utilizing two nationally representative climate change surveys. The LLMs were conditioned on demographics and/or psychological covariates to simulate survey responses. The findings indicate that LLMs can effectively capture presidential voting behaviors but encounter challenges in accurately representing global warming perspectives when relevant covariates are not included. GPT-4 exhibits improved performance when conditioned on both demographics and covariates. However, disparities emerge in LLM estimations of the views of certain groups, with LLMs tending to underestimate worry about global warming among Black Americans. While highlighting the potential of LLMs to aid social science research, these results underscore the importance of metic
    
[^154]: VFedMH: 垂直联合学习用于训练多参与方异构模型

    VFedMH: Vertical Federated Learning for Training Multi-party Heterogeneous Models. (arXiv:2310.13367v1 [cs.LG])

    [http://arxiv.org/abs/2310.13367](http://arxiv.org/abs/2310.13367)

    VFedMH是一种垂直联合学习方法，通过在前向传播过程中聚合参与者的嵌入来处理参与者之间的异构模型，解决了现有VFL方法面临的挑战。

    

    垂直联合学习（VFL）作为一种集成样本对齐和特征合并的新型训练范式，已经引起了越来越多的关注。然而，现有的VFL方法在处理参与者之间存在异构本地模型时面临挑战，这影响了优化收敛性和泛化能力。为了解决这个问题，本文提出了一种名为VFedMH的新方法，用于训练多方异构模型。VFedMH的重点是在前向传播期间聚合每个参与者知识的嵌入，而不是中间结果。主动方，拥有样本的标签和特征，在VFedMH中安全地聚合本地嵌入以获得全局知识嵌入，并将其发送给被动方。被动方仅拥有样本的特征，然后利用全局嵌入在其本地异构网络上进行前向传播。然而，被动方不拥有标签。

    Vertical Federated Learning (VFL) has gained increasing attention as a novel training paradigm that integrates sample alignment and feature union. However, existing VFL methods face challenges when dealing with heterogeneous local models among participants, which affects optimization convergence and generalization. To address this issue, this paper proposes a novel approach called Vertical Federated learning for training Multi-parties Heterogeneous models (VFedMH). VFedMH focuses on aggregating the embeddings of each participant's knowledge instead of intermediate results during forward propagation. The active party, who possesses labels and features of the sample, in VFedMH securely aggregates local embeddings to obtain global knowledge embeddings, and sends them to passive parties. The passive parties, who own only features of the sample, then utilize the global embeddings to propagate forward on their local heterogeneous networks. However, the passive party does not own the labels, 
    
[^155]: Lag-Llama: 用于时间序列预测的基础模型

    Lag-Llama: Towards Foundation Models for Time Series Forecasting. (arXiv:2310.08278v1 [cs.LG])

    [http://arxiv.org/abs/2310.08278](http://arxiv.org/abs/2310.08278)

    Lag-Llama是一个基于大量时间序列数据训练的通用预测模型，在未见过的数据集上展现出强大的零样本预测能力，并使用光滑断裂幂律模型来拟合和预测扩展行为。

    

    为了构建时间序列预测的基础模型并研究其扩展行为，我们在这里介绍了我们正在进行中的 Lag-Llama 工作，这是一个在大量时间序列数据上训练的通用单变量概率时间序列预测模型。该模型在未见过的“分布外”时间序列数据集上展现出良好的零样本预测能力，优于有监督基线方法。我们使用光滑断裂幂律来拟合和预测模型的扩展行为。开源代码可在 https://github.com/kashif/pytorch-transformer-ts 上获得。

    Aiming to build foundation models for time-series forecasting and study their scaling behavior, we present here our work-in-progress on Lag-Llama, a general-purpose univariate probabilistic time-series forecasting model trained on a large collection of time-series data. The model shows good zero-shot prediction capabilities on unseen "out-of-distribution" time-series datasets, outperforming supervised baselines. We use smoothly broken power-laws to fit and predict model scaling behavior. The open source code is made available at https://github.com/kashif/pytorch-transformer-ts.
    
[^156]: 一种面向形式定理证明的语言代理方法

    A Language-Agent Approach to Formal Theorem-Proving. (arXiv:2310.04353v1 [cs.LG])

    [http://arxiv.org/abs/2310.04353](http://arxiv.org/abs/2310.04353)

    COPRA是一种面向形式定理证明的语言代理方法，利用大型语言模型进行上下文学习，通过选择策略和检索定义和引理进行证明，在MiniF2F基准和Coq任务上表现出优异的性能。

    

    语言代理是利用大型语言模型（LLM）进行上下文学习来与外部环境进行交互的方法，最近被认为是一种有前景的控制任务方法。

    Language agents, which use a large language model (LLM) capable of in-context learning to interact with an external environment, have recently emerged as a promising approach to control tasks. We present the first language-agent approach to formal theorem-proving. Our method, COPRA, uses a high-capacity, black-box LLM (GPT-4) as part of a policy for a stateful backtracking search. During the search, the policy can select proof tactics and retrieve lemmas and definitions from an external database. Each selected tactic is executed in the underlying proof framework, and the execution feedback is used to build the prompt for the next policy invocation. The search also tracks selected information from its history and uses it to reduce hallucinations and unnecessary LLM queries.  We evaluate COPRA on the miniF2F benchmark for Lean and a set of Coq tasks from the Compcert project. On these benchmarks, COPRA is significantly better than one-shot invocations of GPT-4, as well as state-of-the-ar
    
[^157]: 教授文本到图像模型进行交流

    Teaching Text-to-Image Models to Communicate. (arXiv:2309.15516v1 [cs.CL])

    [http://arxiv.org/abs/2309.15516](http://arxiv.org/abs/2309.15516)

    本文提出了一种针对对话生成图像的高效方法，通过微调预训练的文本到图像模型，实现在给定对话背景下生成一致逼真的图像。

    

    在文本到图像生成的研究中，各种工作已经得到广泛研究。虽然现有模型在文本到图像生成方面表现良好，但是在直接应用于对话生成图像时存在重大挑战。在本文中，我们首先突出了一个新的问题：对话到图像生成，即在给定对话背景的情况下，模型应该生成一个与指定对话内容一致的逼真图像作为回应。为了解决这个问题，我们提出了一种无需中间转换的高效方法，该方法最大程度地提取对话中包含的语义信息。考虑到对话结构的特点，我们在对话中的每个说话回合之前放置分割标记，以区分不同的发言者。然后，我们对预训练的文本到图像模型进行微调，使其能够根据处理后的对话背景生成图像。经过微调后，我们的方法可以生成与处理后对话环境相一致的图像。

    Various works have been extensively studied in the research of text-to-image generation. Although existing models perform well in text-to-image generation, there are significant challenges when directly employing them to generate images in dialogs. In this paper, we first highlight a new problem: dialog-to-image generation, that is, given the dialog context, the model should generate a realistic image which is consistent with the specified conversation as response. To tackle the problem, we propose an efficient approach for dialog-to-image generation without any intermediate translation, which maximizes the extraction of the semantic information contained in the dialog. Considering the characteristics of dialog structure, we put segment token before each sentence in a turn of a dialog to differentiate different speakers. Then, we fine-tune pre-trained text-to-image models to enable them to generate images conditioning on processed dialog context. After fine-tuning, our approach can con
    
[^158]: GAMIX-VAE: 一种基于高斯混合后验的VAE

    GAMIX-VAE: A VAE with Gaussian Mixture Based Posterior. (arXiv:2309.13160v1 [cs.LG])

    [http://arxiv.org/abs/2309.13160](http://arxiv.org/abs/2309.13160)

    本文提出了一种基于高斯混合后验的VAE方法，重新定义了ELBO，引入正则化项和PatchGAN鉴别器，能够生成逼真的人脸。

    

    变分自动编码器（VAEs）已成为机器学习中生成建模和表示学习的基石。本文探讨了VAEs的一个细微方面，重点是解释KL Divergence，这是Evidence Lower Bound（ELBO）中的关键组成部分，它控制了重构准确性和正则化之间的权衡。虽然KL Divergence让潜变量分布与先验分布对齐，给整个潜空间加上结构约束，但却不限制各个变量分布。所提出的方法重新定义了带有高斯混合的后验概率的ELBO，引入了正则化项以防止方差崩溃，并使用PatchGAN鉴别器来增强纹理逼真度。实现细节涉及Encoder和Decoder的ResNetV2架构。实验证明了生成逼真的人脸的能力，为提供了一个有希望的解决方案。

    Variational Autoencoders (VAEs) have become a cornerstone in generative modeling and representation learning within machine learning. This paper explores a nuanced aspect of VAEs, focusing on interpreting the Kullback Leibler (KL) Divergence, a critical component within the Evidence Lower Bound (ELBO) that governs the trade-off between reconstruction accuracy and regularization. While the KL Divergence enforces alignment between latent variable distributions and a prior imposing a structure on the overall latent space but leaves individual variable distributions unconstrained. The proposed method redefines the ELBO with a mixture of Gaussians for the posterior probability, introduces a regularization term to prevent variance collapse, and employs a PatchGAN discriminator to enhance texture realism. Implementation details involve ResNetV2 architectures for both the Encoder and Decoder. The experiments demonstrate the ability to generate realistic faces, offering a promising solution for
    
[^159]: 用DiscoSCMs回答Layer 3查询

    Answering Layer 3 queries with DiscoSCMs. (arXiv:2309.09323v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2309.09323](http://arxiv.org/abs/2309.09323)

    本文介绍了DiscoSCMs，一种用于解决因果查询的模型。它通过扩展结构因果模型和潜在结果框架来解决一致性规则引发的退化问题，并在分析个性化激励场景中的潜在结果时展示了其有效性。通过引入独立潜在噪声条件，可以提高解决Layer 3查询的准确性和可解释性。

    

    在当代因果推断研究中，解决Pearl因果层次（PCH）下的关联、干预和反事实的因果查询是一个核心任务。本文针对一致性规则引发的退化问题，引入了分布一致性结构因果模型（DiscoSCMs），扩展了结构因果模型（SCM）和潜在结果框架。以个性化激励场景中潜在结果的相关模式$P(y_x, y'_{x'})$为案例研究。尽管反事实不再退化，但仍无法确定。因此，将独立潜在噪声条件纳入DiscoSCM。发现通过适应分布的嵌入式推断，可以极大地提高解决Layer 3查询的准确性和可解释性。

    Addressing causal queries across the Pearl Causal Hierarchy (PCH) (i.e., associational, interventional and counterfactual), which is formalized as \Layer{} Valuations, is a central task in contemporary causal inference research. Counterfactual questions, in particular, pose a significant challenge as they often necessitate a complete knowledge of structural equations. This paper identifies \textbf{the degeneracy problem} caused by the consistency rule. To tackle this, the \textit{Distribution-consistency Structural Causal Models} (DiscoSCMs) is introduced, which extends both the structural causal models (SCM) and the potential outcome framework. The correlation pattern of potential outcomes in personalized incentive scenarios, described by $P(y_x, y'_{x'})$, is used as a case study for elucidation. Although counterfactuals are no longer degenerate, they remain indeterminable. As a result, the condition of independent potential noise is incorporated into DiscoSCM. It is found that by ad
    
[^160]: 如何（不）在主观NLP任务中使用社会人口统计信息

    How (Not) to Use Sociodemographic Information for Subjective NLP Tasks. (arXiv:2309.07034v1 [cs.CL])

    [http://arxiv.org/abs/2309.07034](http://arxiv.org/abs/2309.07034)

    该论文研究了如何使用社会人口统计信息在主观NLP任务中，发现社会人口提示技术在某些任务上有效，但也存在一些限制和挑战。

    

    注释者的社会人口背景（即性别，年龄，教育背景等个体组成）对其在主观NLP任务中的决策有很大影响，比如仇恨言论检测。通常，异质的背景会导致高度分歧。为了建模这种差异，最近的研究探索了社会人口提示技术，这种技术将基于提示的模型的输出引导到具有特定社会人口特征的人类可能给出的答案。然而，现有的NLP文献对这种技术的效果存在分歧 - 它仍然不清楚它能在哪些任务和场景中有帮助，并且评估仅限于特定任务。我们通过展示迄今为止最大和最全面的社会人口提示研究来填补这一研究空白。具体来说，我们评估了七个数据集和六个经过指导调整的模型家族中的几个提示形式。我们发现，尽管社会人口提示对某些任务有效，但也存在一些限制和挑战。

    Annotators' sociodemographic backgrounds (i.e., the individual compositions of their gender, age, educational background, etc.) have a strong impact on their decisions when working on subjective NLP tasks, such as hate speech detection. Often, heterogeneous backgrounds result in high disagreements. To model this variation, recent work has explored sociodemographic prompting, a technique, which steers the output of prompt-based models towards answers that humans with specific sociodemographic profiles would give. However, the available NLP literature disagrees on the efficacy of this technique -- it remains unclear, for which tasks and scenarios it can help and evaluations are limited to specific tasks only. We address this research gap by presenting the largest and most comprehensive study of sociodemographic prompting today. Concretely, we evaluate several prompt formulations across seven datasets and six instruction-tuned model families. We find that (1) while sociodemographic prompt
    
[^161]: 授权临床医生并民主化数据科学：大型语言模型自动化临床研究的机器学习。 (arXiv:2308.14120v2 [cs.LG] 更新版)

    Empowering Clinicians and Democratizing Data Science: Large Language Models Automate Machine Learning for Clinical Studies. (arXiv:2308.14120v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2308.14120](http://arxiv.org/abs/2308.14120)

    chatGPT ADA是一种能够自主开发临床研究所需的最先进的机器学习模型的大型语言模型，可将高级分析工具民主化，使非数据科学家的临床医生能够轻松应用于医学领域。

    

    机器学习（ML）开发者（如数据科学家）和从业者（如临床医生）之间存在知识差距，阻碍了ML在临床数据分析中的充分利用。我们研究了chatGPT Advanced Data Analysis（ADA），即GPT-4的扩展，来弥合这一差距并高效执行ML分析的潜力。我们向chatGPT ADA提供了各种医学专业的大型试验的真实临床数据和研究详细信息，没有给出具体指导。ChatGPT ADA基于原始研究的训练数据自主开发了最先进的ML模型，用于预测临床结果，如癌症发展、癌症进展、疾病并发症或致病基因序列等生物标志物。令人惊讶的是，这些ML模型与其已发表的对应物相匹配甚至表现更好。我们得出结论，chatGPT ADA为民主化医学中的ML提供了一个有前景的途径，使非ML专家能够获得先进的分析工具并推动广泛应用。

    A knowledge gap persists between Machine Learning (ML) developers (e.g., data scientists) and practitioners (e.g., clinicians), hampering the full utilization of ML for clinical data analysis. We investigated the potential of the chatGPT Advanced Data Analysis (ADA), an extension of GPT-4, to bridge this gap and perform ML analyses efficiently. Real-world clinical datasets and study details from large trials across various medical specialties were presented to chatGPT ADA without specific guidance. ChatGPT ADA autonomously developed state-of-the-art ML models based on the original study's training data to predict clinical outcomes such as cancer development, cancer progression, disease complications, or biomarkers such as pathogenic gene sequences. Strikingly, these ML models matched or outperformed their published counterparts. We conclude that chatGPT ADA offers a promising avenue to democratize ML in medicine, making advanced analytics accessible to non-ML experts and promoting broa
    
[^162]: 学习基于团队导航：深度强化学习技术在多智能体路径规划中的综述

    Learning to Team-Based Navigation: A Review of Deep Reinforcement Learning Techniques for Multi-Agent Pathfinding. (arXiv:2308.05893v1 [cs.AI])

    [http://arxiv.org/abs/2308.05893](http://arxiv.org/abs/2308.05893)

    本文综述了在多智能体路径规划中深度强化学习技术的应用。与其他研究不同，我们重点介绍了DRL方法在MAPF中的整合，并解决了MAPF解决方案评估指标缺乏统一性的问题。我们讨论了基于模型的DRL作为未来发展方向，并提供了解决MAPF当前挑战所需的基础理解。

    

    多智能体路径规划(MAPF)是许多大规模机器人应用中的关键领域，通常是多智能体系统的基本步骤。然而，在复杂和拥挤的环境中，MAPF的复杂性不断增加，已有解决方案的有效性严重降低。与其他研究不同，我们在本综述论文中重点介绍了DRL方法在MAPF中的应用。此外，我们旨在填补目前在评估MAPF解决方案方面的缺口，通过解决缺乏统一评估指标的问题并对这些指标进行全面阐释。最后，我们的论文讨论了作为未来方向的基于模型的DRL的潜力，并提供了必要的基础理解以应对MAPF中的当前挑战。

    Multi-agent pathfinding (MAPF) is a critical field in many large-scale robotic applications, often being the fundamental step in multi-agent systems. The increasing complexity of MAPF in complex and crowded environments, however, critically diminishes the effectiveness of existing solutions. In contrast to other studies that have either presented a general overview of the recent advancements in MAPF or extensively reviewed Deep Reinforcement Learning (DRL) within multi-agent system settings independently, our work presented in this review paper focuses on highlighting the integration of DRL-based approaches in MAPF. Moreover, we aim to bridge the current gap in evaluating MAPF solutions by addressing the lack of unified evaluation metrics and providing comprehensive clarification on these metrics. Finally, our paper discusses the potential of model-based DRL as a promising future direction and provides its required foundational understanding to address current challenges in MAPF. Our o
    
[^163]: 谁回答的更好？对ChatGPT和Stack Overflow回答软件工程问题进行深入分析

    Who Answers It Better? An In-Depth Analysis of ChatGPT and Stack Overflow Answers to Software Engineering Questions. (arXiv:2308.02312v1 [cs.SE])

    [http://arxiv.org/abs/2308.02312](http://arxiv.org/abs/2308.02312)

    本研究深入分析了ChatGPT和Stack Overflow回答软件工程问题的特点和可用性。结果显示，ChatGPT回答中有52%错误，77%冗长，但由于其综合性和清晰的语言表达，仍然在39.34%的情况下被使用者偏好选择。

    

    Q&A平台在过去十年中一直是程序员网上求助行为的重要组成部分。然而，随着ChatGPT的推出，网上求助行为的范式正在发生变化。尽管ChatGPT很受欢迎，但尚未进行全面的研究来评估ChatGPT回答软件工程问题的特点或可用性。为了填补这个空白，我们对ChatGPT回答517个Stack Overflow（SO）问题进行了首次深入分析，并对ChatGPT回答的正确性、一致性、综合性和简洁性进行了检查。此外，我们进行了大规模的语言分析和用户研究，以了解ChatGPT回答在语言和人类方面的特点。我们的分析表明，52％的ChatGPT回答是错误的，77％的回答冗长。尽管如此，由于其综合性和清晰的语言表达，ChatGPT回答仍然在39.34％的情况下受到青睐。

    Q&A platforms have been an integral part of the web-help-seeking behavior of programmers over the past decade. However, with the recent introduction of ChatGPT, the paradigm of web-help-seeking behavior is experiencing a shift. Despite the popularity of ChatGPT, no comprehensive study has been conducted to evaluate the characteristics or usability of ChatGPT's answers to software engineering questions. To bridge the gap, we conducted the first in-depth analysis of ChatGPT's answers to 517 Stack Overflow (SO) questions and examined the correctness, consistency, comprehensiveness, and conciseness of ChatGPT's answers. Furthermore, we conducted a large-scale linguistic analysis, and a user study to understand the characteristics of ChatGPT answers from linguistic and human aspects. Our analysis shows that 52\% of ChatGPT answers are incorrect and 77\% are verbose. Nonetheless, ChatGPT answers are still preferred 39.34\% of the time due to their comprehensiveness and well-articulated langu
    
[^164]: 生成人工智能的强化学习：现状、机会和开放研究挑战

    Reinforcement Learning for Generative AI: State of the Art, Opportunities and Open Research Challenges. (arXiv:2308.00031v1 [cs.LG])

    [http://arxiv.org/abs/2308.00031](http://arxiv.org/abs/2308.00031)

    这篇论文调查了在生成人工智能中应用强化学习的现状、机会和开放研究问题。作者主要讨论了三种应用类型：无特定目标的生成方式、同时最大化目标函数的输出生成方式以及将无法通过目标函数捕捉的期望特征嵌入生成过程的方式。这个新兴领域中存在着丰富的机会和挑战。

    

    生成人工智能（AI）是近十年来计算机科学领域最令人兴奋的发展之一。与此同时，强化学习（RL）在各种机器学习任务中已经成为非常成功的范式。在本调查中，我们讨论了将RL应用于生成AI中的现状、机会和开放的研究问题。具体而言，我们将讨论三种应用类型，即作为一种无特定目标的生成方式，作为一种同时最大化目标函数的输出生成方式，以及作为一种将无法通过目标函数轻松捕捉的期望特征嵌入生成过程的方式。我们在调查结果中对这个迷人的新兴领域中的机会和挑战进行了深入的讨论。

    Generative Artificial Intelligence (AI) is one of the most exciting developments in Computer Science of the last decade. At the same time, Reinforcement Learning (RL) has emerged as a very successful paradigm for a variety of machine learning tasks. In this survey, we discuss the state of the art, opportunities and open research questions in applying RL to generative AI. In particular, we will discuss three types of applications, namely, RL as an alternative way for generation without specified objectives; as a way for generating outputs while concurrently maximizing an objective function; and, finally, as a way of embedding desired characteristics, which cannot be easily captured by means of an objective function, into the generative process. We conclude the survey with an in-depth discussion of the opportunities and challenges in this fascinating emerging area.
    
[^165]: 安全强化学习作为Wasserstein变分推理：可解释性的形式方法

    Safe Reinforcement Learning as Wasserstein Variational Inference: Formal Methods for Interpretability. (arXiv:2307.07084v1 [cs.LG])

    [http://arxiv.org/abs/2307.07084](http://arxiv.org/abs/2307.07084)

    本研究提出了一种新的自适应Wasserstein变分优化（AWaVO）方法，利用形式方法解决了顺序决策中的解释和透明性问题，并提供了奖励设计和策略收敛的概率解释。

    

    强化学习或最优控制可以为具有可变动态的顺序决策问题提供有效的推理。然而，在实际实施中，解释奖励函数和相应的最优策略一直是一个持久的挑战。因此，将顺序决策问题形式化为推理具有重要价值，因为概率推理原则上提供了多样且强大的数学工具来推断随机动态，同时提供了奖励设计和策略收敛的概率解释。在本研究中，我们提出了一种新颖的自适应Wasserstein变分优化（AWaVO）方法来解决这些顺序决策中的挑战。我们的方法利用形式方法来解释奖励设计，透明地训练收敛，以及对顺序决策的概率解释。为了证明实用性，我们展示了收敛训练并保证了收敛的训练。

    Reinforcement Learning or optimal control can provide effective reasoning for sequential decision-making problems with variable dynamics. Such reasoning in practical implementation, however, poses a persistent challenge in interpreting the reward function and corresponding optimal policy. Consequently, formalizing the sequential decision-making problems as inference has a considerable value, as probabilistic inference in principle offers diverse and powerful mathematical tools to infer the stochastic dynamics whilst suggesting a probabilistic interpretation of the reward design and policy convergence. In this study, we propose a novel Adaptive Wasserstein Variational Optimization (AWaVO) to tackle these challenges in sequential decision-making. Our approach utilizes formal methods to provide interpretations of reward design, transparency of training convergence, and probabilistic interpretation of sequential decisions. To demonstrate practicality, we show convergent training with guara
    
[^166]: S2vNTM: 半监督vMF神经主题建模

    S2vNTM: Semi-supervised vMF Neural Topic Modeling. (arXiv:2307.04804v1 [cs.CL])

    [http://arxiv.org/abs/2307.04804](http://arxiv.org/abs/2307.04804)

    S2vNTM是一种半监督的vMF神经主题建模方法，通过利用关键词的模式来识别潜在的主题，并优化主题关键词集的质量，提高了分类准确度，并且速度至少比基线模型快两倍。

    

    基于语言模型的方法对于文本分类来说是一种强大的技术。然而，这些模型存在一些缺点：（1）很难整合人类知识，比如关键词；（2）训练模型需要大量资源；（3）依赖大规模文本数据进行预训练。本文中，我们提出了半监督vMF神经主题建模（S2vNTM）来克服这些困难。S2vNTM将一些种子关键词作为主题的输入。S2vNTM利用关键词的模式来识别潜在的主题，并优化主题关键词集的质量。在各种数据集上，S2vNTM在提供有限关键词的情况下，在分类准确度方面优于现有的半监督主题建模方法。S2vNTM至少比基线模型快两倍。

    Language model based methods are powerful techniques for text classification. However, the models have several shortcomings. (1) It is difficult to integrate human knowledge such as keywords. (2) It needs a lot of resources to train the models. (3) It relied on large text data to pretrain. In this paper, we propose Semi-Supervised vMF Neural Topic Modeling (S2vNTM) to overcome these difficulties. S2vNTM takes a few seed keywords as input for topics. S2vNTM leverages the pattern of keywords to identify potential topics, as well as optimize the quality of topics' keywords sets. Across a variety of datasets, S2vNTM outperforms existing semi-supervised topic modeling methods in classification accuracy with limited keywords provided. S2vNTM is at least twice as fast as baselines.
    
[^167]: NeuralMatrix: 将整个神经网络移动到通用矩阵乘法以实现高效推理

    NeuralMatrix: Moving Entire Neural Networks to General Matrix Multiplication for Efficient Inference. (arXiv:2305.14405v1 [cs.LG])

    [http://arxiv.org/abs/2305.14405](http://arxiv.org/abs/2305.14405)

    NeuralMatrix是一种框架，能够在单个通用矩阵乘法加速器上计算深度神经网络(DNNs)，并可在保持推理准确度的情况下实现高达113倍至19.44倍的性能提升。

    

    本研究介绍了一种名为NeuralMatrix的新型框架，它使得可以在单个通用矩阵乘法（GEMM）加速器上计算多功能的深度神经网络（DNNs）。该方法克服了基于ASIC的加速器的专用性限制，同时实现了与CPU和GPU等通用处理器相比的应用特定加速水平。我们解决了将DNN计算中的线性和非线性运算映射到通用矩阵乘法以及使用GEMM加速器对DNN推理准确性的影响的挑战。我们在来自三种流行类别的各种DNN模型上进行了大量实验（即CNN，Transformers和GNN）作为示例的支撑模型。我们的结果表明，将DNN转换为通用矩阵乘法后仅会出现高达2.02％的准确度损失，同时将吞吐量与功率的比值与CPU和GPU相比提高了113倍到19.44倍。

    In this study, we introduce NeuralMatrix, a novel framework that enables the computation of versatile deep neural networks (DNNs) on a single general matrix multiplication (GEMM) accelerator. The proposed approach overcomes the specificity limitations of ASIC-based accelerators while achieving application-specific acceleration levels compared to general-purpose processors such as CPUs and GPUs. We address the challenges of mapping both linear and nonlinear operations in DNN computation to general matrix multiplications and the impact of using a GEMM accelerator on DNN inference accuracy. Extensive experiments are conducted on various DNN models from three popular categories (i.e., CNN, Transformers, and GNN) as illustrative backbone models. Our results demonstrate that DNNs suffer only up to a 2.02% accuracy loss after being converted to general matrix multiplication, while achieving 113x to 19.44x improvements in throughput per power compared to CPUs and GPUs.
    
[^168]: 利用室内WiFi系统进行无设备穿墙存在检测的注意增强深度学习

    Attention-Enhanced Deep Learning for Device-Free Through-the-Wall Presence Detection Using Indoor WiFi System. (arXiv:2304.13105v1 [cs.LG])

    [http://arxiv.org/abs/2304.13105](http://arxiv.org/abs/2304.13105)

    本文提出了一种利用WiFi信号进行人员存在检测的新系统，采用了关注机制和双向LSTM网络来提高准确性，并证明了其在现实场景中的稳健性。

    

    在室内环境中准确检测人员存在对于各种应用非常重要，例如能源管理和安全。本文提出了一种利用WiFi信号的通道状态信息（CSI）进行人员存在检测的新系统。我们的系统名为注意力增强深度学习（ALPD），采用关注机制从CSI数据中自动选择有信息量的子载波，并采用双向长短时记忆（LSTM）网络捕捉CSI中的时间依赖性。此外，我们利用一个静态特征来提高静态状态下人员存在检测的准确性。我们通过部署一对WiFi接入点（AP）来收集CSI数据集来评估所提出的ALPD系统，该系统进一步与几个基准进行比较。结果表明，我们的ALPD系统在准确性方面优于基准，特别是在存在干扰的情况下。此外，双向传输数据不会影响我们系统的性能，证明了其在现实场景中的稳健性。

    Accurate detection of human presence in indoor environments is important for various applications, such as energy management and security. In this paper, we propose a novel system for human presence detection using the channel state information (CSI) of WiFi signals. Our system named attention-enhanced deep learning for presence detection (ALPD) employs an attention mechanism to automatically select informative subcarriers from the CSI data and a bidirectional long short-term memory (LSTM) network to capture temporal dependencies in CSI. Additionally, we utilize a static feature to improve the accuracy of human presence detection in static states. We evaluate the proposed ALPD system by deploying a pair of WiFi access points (APs) for collecting CSI dataset, which is further compared with several benchmarks. The results demonstrate that our ALPD system outperforms the benchmarks in terms of accuracy, especially in the presence of interference. Moreover, bidirectional transmission data 
    
[^169]: Transformer介绍

    An Introduction to Transformers. (arXiv:2304.10557v1 [cs.LG])

    [http://arxiv.org/abs/2304.10557](http://arxiv.org/abs/2304.10557)

    Transformer是一种神经网络组件，可以学习序列或数据集表示，在自然语言处理、计算机视觉和时空建模方面取得了重大进展。本论文提供了一个数学精确、直观、简洁的Transformer架构描述。

    

    Transformer是一种可以学习序列或数据集表示的神经网络组件。Transformer在自然语言处理、计算机视觉和时空建模方面取得了重大进展。虽然有很多Transformer的介绍，但大多数都缺少对其架构的精确数学描述，其设计选择的直觉也常常缺失。此外，随着研究路径的曲折，Transformer部件的解释可能是异质的。在这篇论文中，我们旨在提供一个数学精确、直观、简洁的Transformer架构描述。

    The transformer is a neural network component that can be used to learn useful representations of sequences or sets of datapoints. The transformer has driven recent advances in natural language processing, computer vision, and spatio-temporal modelling. There are many introductions to transformers, but most do not contain precise mathematical descriptions of the architecture and the intuitions behind the design choices are often also missing. Moreover, as research takes a winding path, the explanations for the components of the transformer can be idiosyncratic. In this note we aim for a mathematically precise, intuitive, and clean description of the transformer architecture.
    
[^170]: 使用来自成对或$K$元比较的人类反馈的规范强化学习

    Principled Reinforcement Learning with Human Feedback from Pairwise or $K$-wise Comparisons. (arXiv:2301.11270v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11270](http://arxiv.org/abs/2301.11270)

    该论文提供了带有人类反馈强化学习问题的理论框架，证明了最大似然估计在Bradley-Terry-Luce和Plackett-Luce模型下收敛。此外，提出了在一定的覆盖假设下，基于悲观估计的MLE提供了性能更好的策略。在证明了真实MLE和以成对比较形式替代的备选MLE都可以在PL模型下收敛的同时，也表明了真实MLE的高效性。这些结果为RLHF算法提供了新的见解，并统一了RLHF问题和IRL问题。

    

    我们为带有人类反馈的强化学习问题提供了一个理论框架。我们的分析表明，当真实奖励函数为线性函数时，最大似然估计（MLE）在Bradley-Terry-Luce（BTL）模型和Plackett-Luce（PL）模型下均收敛。然而，我们发现当基于学得的奖励模型训练策略时，MLE会失败，而基于悲观估计的MLE在一定的覆盖假设下提供性能更好的策略。此外，我们证明在PL模型下，真实MLE和将$k$元比较拆分为成对比较的备选MLE都收敛。而真实MLE是渐近更为高效的。我们的结果验证了现有RLHF算法（如InstructGPT）的实验成功，并为算法设计提供了新的见解。此外，我们的结果统一了RLHF问题和最大熵反向强化学习(IRL)问题，并为其提供了第一个样本复杂度界。

    We provide a theoretical framework for Reinforcement Learning with Human Feedback (RLHF). Our analysis shows that when the true reward function is linear, the widely used maximum likelihood estimator (MLE) converges under both the Bradley-Terry-Luce (BTL) model and the Plackett-Luce (PL) model. However, we show that when training a policy based on the learned reward model, MLE fails while a pessimistic MLE provides policies with improved performance under certain coverage assumptions. Additionally, we demonstrate that under the PL model, the true MLE and an alternative MLE that splits the $K$-wise comparison into pairwise comparisons both converge. Moreover, the true MLE is asymptotically more efficient. Our results validate the empirical success of existing RLHF algorithms in InstructGPT and provide new insights for algorithm design. Furthermore, our results unify the problem of RLHF and max-entropy Inverse Reinforcement Learning (IRL), and provide the first sample complexity bound fo
    
[^171]: 面向共享自动驾驶出行服务的预测式车队调度：一种基于优化和学习的方法

    Anticipatory Fleet Repositioning for Shared-use Autonomous Mobility Services: An Optimization and Learning-Based Approach. (arXiv:2210.08659v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2210.08659](http://arxiv.org/abs/2210.08659)

    本文提出一种基于优化和学习的方法，通过预测未来需求和合作优化基于分配策略的重新平衡策略，从而改善SAMS车队的服务质量和效率，并在真实数据集上进行的数值实验表明该方法较传统启发式方法具有更好的性能和可靠性。

    

    移动出行服务、丰富的交通数据和自动驾驶汽车的发展为共享自动驾驶出行服务（SAMS）提供了重要机遇，以提供可访问和需求响应性的个人出行。本文旨在通过预测性地重新调度空闲的车辆，提高SAMS车队的效率和服务质量。把再平衡问题作为马可夫决策过程进行建模，并提出使用基于优势的演员-评论家（A2C）强化学习方法来解决该问题。所提出的方法学习了一种重新平衡策略，它预测未来需求并与基于优化的分配策略合作。该方法允许集中式的重新定位决策，并且可以处理大型汽车车队，因为问题大小不超过Fleetsize^2。

    The development of mobility-on-demand services, rich transportation data sources, and autonomous vehicles (AVs) creates significant opportunities for shared-use AV mobility services (SAMSs) to provide accessible and demand-responsive personal mobility. SAMS fleet operation involves multiple interrelated decisions, with a primary focus on efficiently fulfilling passenger ride requests with a high level of service quality. This paper focuses on improving the efficiency and service quality of a SAMS vehicle fleet via anticipatory repositioning of idle vehicles. The rebalancing problem is formulated as a Markov Decision Process, which we propose solving using an advantage actor critic (A2C) reinforcement learning-based method. The proposed approach learns a rebalancing policy that anticipates future demand and cooperates with an optimization-based assignment strategy. The approach allows for centralized repositioning decisions and can handle large vehicle fleets since the problem size does
    

