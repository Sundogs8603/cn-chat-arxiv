# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Evaluating Driver Readiness in Conditionally Automated Vehicles from Eye-Tracking Data and Head Pose.](http://arxiv.org/abs/2401.11284) | 本文通过结合头部姿势特征和眼动数据对驾驶员在有条件自动驾驶车辆中的准备性进行了全面分析，通过使用LSTM体系结构的机器学习技术进行建模，成功地评估了驾驶员的准备性。 |
| [^2] | [Measuring Policy Distance for Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2401.11257) | 本文提出了一种用于测量多智能体强化学习中政策差异的通用工具，即多智能体政策距离（MAPD）。通过学习智能体的决策条件表示，MAPD可以计算任意一对智能体之间的政策距离，并且可以扩展到定制化版本以量化智能体政策在特定方面的差异。这个工具不仅有助于评估多智能体系统中多样性的演变，还为基于多样性的MARL算法的设计提供指导。 |
| [^3] | [Automated Fusion of Multimodal Electronic Health Records for Better Medical Predictions.](http://arxiv.org/abs/2401.11252) | 该论文提出了一种自动融合多模态电子健康记录的神经架构搜索框架，用于改进医疗预测准确性。该框架可以自动搜索用于编码不同输入模态和融合策略的最佳模型架构，并在实验中取得了超越传统方法的效果。 |
| [^4] | [Evaluating if trust and personal information privacy concerns are barriers to using health insurance that explicitly utilizes AI.](http://arxiv.org/abs/2401.11249) | 本研究评估了信任和个人信息隐私关注是否成为使用明确利用人工智能的健康保险的障碍。研究发现，人工智能可见性降低了信任水平，而隐私关注在人工智能的情况下更高，但并没有统计显著性差异。 |
| [^5] | [TreeMIL: A Multi-instance Learning Framework for Time Series Anomaly Detection with Inexact Supervision.](http://arxiv.org/abs/2401.11235) | 本文提出了一个基于树的多实例学习框架(TreeMIL)，用于带有不精确监督的时间序列异常检测。该框架通过将整个序列分解成多个节点，并提取子序列特征，旨在解决集体异常的挑战。 |
| [^6] | [A Hybrid Approach of Transfer Learning and Physics-Informed Modeling: Improving Dissolved Oxygen Concentration Prediction in an Industrial Wastewater Treatment Plant.](http://arxiv.org/abs/2401.11217) | 本论文提出了一种传输学习和物理信息建模的混合方法，通过将其他任务中的知识转移到目标任务中，以提高工业废水处理厂溶解氧浓度预测的准确性。这种方法结合了开源模型的物理知识和另一个工业厂的数据，并使训练问题的目标函数具备物理信息建模的特点。 |
| [^7] | [Programming Distributed Collective Processes in the eXchange Calculus.](http://arxiv.org/abs/2401.11212) | 本研究在交换演算中考虑了集合设备的动态合作行为，提出了分布式集体过程的抽象表示，用于编程计算集体的行为。 |
| [^8] | [Navigating the Thin Line: Examining User Behavior in Search to Detect Engagement and Backfire Effects.](http://arxiv.org/abs/2401.11201) | 本研究调查了有意见的用户在搜索行为中关注度和反效应的问题，并发现暴露于偏见搜索结果会增加他们消费反对态度内容的数量。 |
| [^9] | [Fast and Exact Enumeration of Deep Networks Partitions Regions.](http://arxiv.org/abs/2401.11188) | 本文提出了第一个能够精确枚举DN分区的并行算法，可以评估常用的基于随机抽样的近似方法，发现如果只对具有“大”体积的区域感兴趣，那么对空间进行均匀抽样非常高效。 |
| [^10] | [Pixel-Wise Recognition for Holistic Surgical Scene Understanding.](http://arxiv.org/abs/2401.11174) | 本文提出了一个整体和多粒度外科场景理解数据集，以及一个基于变形器的模型，该模型有效地结合了全局视频特征提取和局部器械分割，可用于多层次理解外科活动。 |
| [^11] | [Generalizing Speaker Verification for Spoof Awareness in the Embedding Space.](http://arxiv.org/abs/2401.11156) | 本文提出了一种在嵌入空间中推广的演讲者验证系统，可以同时处理冒充者和欺骗攻击，提供更强的保护和更经济的计算。 |
| [^12] | [Gaussian Adaptive Attention is All You Need: Robust Contextual Representations Across Multiple Modalities.](http://arxiv.org/abs/2401.11143) | 该论文提出了一个名为GAAM的多头高斯自适应注意力机制，用于增强跨多个模态的信息聚合。通过将可学习的均值和方差纳入注意力机制中，GAAM能够动态地重新调整特征的重要性，从而在处理非平稳数据时取得了显著的性能提升，超过了目前现有的注意力技术。该方法的适应性强且参数数量较少，具有改进现有注意力框架的潜力。 |
| [^13] | [Stability Plasticity Decoupled Fine-tuning For Few-shot end-to-end Object Detection.](http://arxiv.org/abs/2401.11140) | 本文提出了一个解耦稳定性和可塑性的新的三阶段微调过程，用于缓解少样本目标检测中的稳定性-可塑性矛盾问题。 |
| [^14] | [Enhancing Large Language Models for Clinical Decision Support by Incorporating Clinical Practice Guidelines.](http://arxiv.org/abs/2401.11120) | 该论文研究了将临床实践指南纳入大型语言模型以增强临床决策支持的方法。他们开发了三种方法，并对四个大型语言模型进行了评估，在COVID-19门诊治疗方面取得了较高的性能。 |
| [^15] | [SPAND: Sleep Prediction Architecture using Network Dynamics.](http://arxiv.org/abs/2401.11113) | SPAND是一个利用网络动态的睡眠预测架构，可以通过图网络和移动设备数据来预测下一天的睡眠持续时间标签。 |
| [^16] | [TypeDance: Creating Semantic Typographic Logos from Image through Personalized Generation.](http://arxiv.org/abs/2401.11094) | 本论文介绍了一种名为TypeDance的AI辅助工具，通过结合设计理念与生成模型，实现了个性化语义排版标志设计。它利用从上传的图像实例中提取的设计先验知识，支持不同结构粒度上的字体-图像映射，达到多样化的美学设计和灵活的控制。 |
| [^17] | [FedRKG: A Privacy-preserving Federated Recommendation Framework via Knowledge Graph Enhancement.](http://arxiv.org/abs/2401.11089) | FedRKG是一种隐私保护的联邦推荐框架，通过增强知识图，构建全局知识图并利用关系感知的GNN模型，实现高阶用户-项目交互。 |
| [^18] | [Adaptive Global-Local Representation Learning and Selection for Cross-Domain Facial Expression Recognition.](http://arxiv.org/abs/2401.11085) | 本文提出了一个自适应的全局局部表征学习和选择框架，通过全局局部对抗适应和语义感知伪标签生成来增强域不变和辨别性特征的学习，在推理过程中使用全局局部预测一致性学习以提高分类结果。 |
| [^19] | [Learning from Aggregate responses: Instance Level versus Bag Level Loss Functions.](http://arxiv.org/abs/2401.11081) | 本文研究了从聚合响应中学习的两种损失函数：包级别损失和实例级别损失，并发现实例级别损失可以被视为包级别损失的正则化形式。 |
| [^20] | [PhotoBot: Reference-Guided Interactive Photography via Natural Language.](http://arxiv.org/abs/2401.11061) | PhotoBot是一个通过自然语言引导和机器人摄影师相互作用的自动化照片获取框架。它利用视觉语言模型和物体检测器来提供摄影建议，并通过视觉变换器计算相机的姿态调整，从而实现高质量的照片获取。 |
| [^21] | [The Significance of Data Abstraction Methods in Machine Learning Classification Processes for Critical Decision-Making.](http://arxiv.org/abs/2401.11044) | 本文研究了机器学习分类过程中数据抽象方法的重要性，提出了Small and Incomplete Dataset Analyser (SaNDA)采用ROC曲线方法开发的数据抽象协议，该方法在缺少值很少的情况下可以成为随机森林的可行替代品，始终保持高准确性。 |
| [^22] | [Analysis and Detection of Multilingual Hate Speech Using Transformer Based Deep Learning.](http://arxiv.org/abs/2401.11021) | 提出了一种基于Transformer模型的方法来检测社交媒体上的多语言仇恨言论。该模型在意大利语、英语、德语和孟加拉语上进行了测试，并取得了比现有模型更高的成功率。 |
| [^23] | [Fast Registration of Photorealistic Avatars for VR Facial Animation.](http://arxiv.org/abs/2401.11002) | 本论文针对虚拟现实头像注册和面部动画问题，发现头像和头显相机图像之间的领域差距是主要难点，并提出了一个系统设计来解决这个问题。 |
| [^24] | [MacroSwarm: A Field-based Compositional Framework for Swarm Programming.](http://arxiv.org/abs/2401.10969) | MacroSwarm是一种基于场的群体编程框架，通过可组合的功能模块实现复杂的群体行为，通过将感知场映射为执行目标场，提供了一种系统化的设计和实现群体行为的方法。 |
| [^25] | [Decentralizing Coordination in Open Vehicle Fleets for Scalable and Dynamic Task Allocation.](http://arxiv.org/abs/2401.10965) | 本文研究了在分散协调环境下开放车队的可扩展和动态任务分配，提出了多代理系统的表示方法，并对最近的研究结果进行了比较和批判性分析。同时，提出了数学模型来解决动态分配问题。 |
| [^26] | [AI Revolution on Chat Bot: Evidence from a Randomized Controlled Experiment.](http://arxiv.org/abs/2401.10956) | 本文通过一项现场随机对照试验研究了LLM工具在提供无监督信息检索支持服务方面的效果。 |
| [^27] | [Self context-aware emotion perception on human-robot interaction.](http://arxiv.org/abs/2401.10946) | 本论文提出了一种自我上下文感知模型（SCAM）用于人机交互中的情绪识别，在音频、视频和多模态方面取得了显著的改进，提高了准确率。 |
| [^28] | [Machine Unlearning for Recommendation Systems: An Insight.](http://arxiv.org/abs/2401.10942) | 本文探讨了机器反学习在推荐系统中的应用，解决了适应性、个性化、隐私和偏见等挑战。与传统模型不同，MUL根据用户偏好的变化和伦理考虑动态调整系统知识。通过批判性检验和文献梳理，本文提供了MUL如何改变推荐、用户信任以及未来研究路径的见解。强调个性化和隐私之间的权衡挑战，并鼓励以满足实际需求为目标的贡献，推动MUL在安全和适应性机器学习中的发展。 |
| [^29] | [Even-if Explanations: Formal Foundations, Priorities and Complexity.](http://arxiv.org/abs/2401.10938) | 本论文研究了解释性人工智能中的局部事后解释性查询，特别关注半事实的解释，并对线性模型和基于树的模型与神经网络的解释能力进行了比较。此外，提出了一种基于偏好的框架，允许用户根据自己的首选项个性化解释。最后，探讨了模型复杂度的问题。 |
| [^30] | [Subjective Causality.](http://arxiv.org/abs/2401.10937) | 本研究通过观察决策者对干预行为的偏好，展示了理解和识别决策者主观因果判断的可能性，为模型测试决策者偏好一致性提供了方法。 |
| [^31] | [SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents.](http://arxiv.org/abs/2401.10935) | SeeClick是一种基于屏幕截图的视觉GUI代理，通过GUI grounding预训练和自动化数据生成，实现了在复杂任务自动化中准确定位屏幕元素，并创建了全面覆盖移动、桌面和Web环境的GUI grounding数据集ScreenSpot。 |
| [^32] | [A New Creative Generation Pipeline for Click-Through Rate with Stable Diffusion Model.](http://arxiv.org/abs/2401.10934) | 基于用户信息和艺术设计的新的创意生成流程，通过融合用户信息和考虑用户特征来预测CTR分数，提供更具吸引力的创意设计。 |
| [^33] | [Artificial intelligence to automate the systematic review of scientific literature.](http://arxiv.org/abs/2401.10917) | 本论文介绍了一项调查研究，研究了使用人工智能实现科学文献系统综述的自动化方法。 |
| [^34] | [Metacognition is all you need? Using Introspection in Generative Agents to Improve Goal-directed Behavior.](http://arxiv.org/abs/2401.10910) | 本文介绍了一个使用内省的元认知模块，可以让生成式智能体观察自己的思考过程和行动，并通过修改策略来显著提高性能。通过在多种场景下测试，我们观察到该系统在与其他系统的比较中取得了优势，智能体能够适应和改进策略以完成任务。 |
| [^35] | [A Review of Findings from Neuroscience and Cognitive Psychology as Possible Inspiration for the Path to Artificial General Intelligence.](http://arxiv.org/abs/2401.10904) | 这项综述通过探索神经科学和认知心理学的发现，旨在为人工通用智能的发展提供启示，以克服深度学习模型在抽象推理和因果理解方面的局限性。 |
| [^36] | [Concrete Problems in AI Safety, Revisited.](http://arxiv.org/abs/2401.10899) | 通过分析真实案例，本研究重新审视了人工智能安全中的具体问题，并指出为了更好地理解人工智能系统在现实生活中的故障和成功，需要扩展社会技术框架。 |
| [^37] | [PuriDefense: Randomized Local Implicit Adversarial Purification for Defending Black-box Query-based Attacks.](http://arxiv.org/abs/2401.10586) | PuriDefense是一种高效的防御机制，通过使用轻量级净化模型进行随机路径净化，减缓基于查询的攻击的收敛速度，并有效防御黑盒基于查询的攻击。 |
| [^38] | [Catastrophic Interference is Mitigated in Naturalistic Power-Law Learning Environments.](http://arxiv.org/abs/2401.10393) | 本研究在自然学习环境中通过回忆方法减轻了灾难性干扰，该方法受到功率法则的启发。 |
| [^39] | [Noise Contrastive Estimation-based Matching Framework for Low-resource Security Attack Pattern Recognition.](http://arxiv.org/abs/2401.10337) | 该论文提出了一种基于噪声对比估计的低资源安全攻击模式识别匹配框架，通过直接语义相似度决定文本与攻击模式之间的关联，以降低大量类别、标签分布不均和标签空间复杂性带来的学习难度。 |
| [^40] | [Revolutionizing Pharma: Unveiling the AI and LLM Trends in the Pharmaceutical Industry.](http://arxiv.org/abs/2401.10273) | 这篇论文批判性概述了制药行业中人工智能的新兴趋势和重大进展，特别强调了机器学习算法等先进人工智能技术在制药运营的贡献。 |
| [^41] | [Chem-FINESE: Validating Fine-Grained Few-shot Entity Extraction through Text Reconstruction.](http://arxiv.org/abs/2401.10189) | 这篇论文提出了一种名为Chem-FINESE的方法来处理化学领域中细粒度少样本实体提取的问题。该方法通过使用序列到序列的实体提取器和自我验证模块来从输入句子中提取命名实体并重构原始输入句子。实验证明了该方法的有效性和可行性。 |
| [^42] | [All in How You Ask for It: Simple Black-Box Method for Jailbreak Attacks.](http://arxiv.org/abs/2401.09798) | 本研究提出了一种简单的黑盒方法，用于生成越狱攻击提示，克服了现有方法的复杂性和计算成本的限制。该方法通过使用语言模型自身，将有害提示重写为非有害表达，实现了超过80%的攻击成功率，并且即使模型更新，效果仍然有效。 |
| [^43] | [Towards Identifiable Unsupervised Domain Translation: A Diversified Distribution Matching Approach.](http://arxiv.org/abs/2401.09671) | 本研究旨在解决无监督领域转换中的可识别性问题，引入了一个MPA消除理论，解决了CycleGAN及其变体产生内容不对齐的限制。 |
| [^44] | [Diffusion-Driven Generative Framework for Molecular Conformation Prediction.](http://arxiv.org/abs/2401.09451) | 本文介绍了一种基于扩散驱动的生成框架\method{}，用于预测分子的三维构象，具有较高的预测精度并改进了传统方法的不足。 |
| [^45] | [Code Simulation Challenges for Large Language Models.](http://arxiv.org/abs/2401.09074) | 大型语言模型在模拟计算机代码和算法执行方面遇到挑战，性能随着代码长度的增加而迅速下降。在处理短程序或标准过程时，它们能以低错误率按顺序执行指令，但对于复杂的程序，特别是包含关键路径和冗余指令的程序，模拟效果较差。我们提出了一种逐行模拟代码执行的方法来解决这个问题。 |
| [^46] | [Augmenting Math Word Problems via Iterative Question Composing.](http://arxiv.org/abs/2401.09003) | 本研究通过引入MMIQC数据集和迭代组合问题(IQC)的新颖增强方法，成功提高了大型语言模型的数学推理能力，在竞赛级数学问题上取得了优于先前最佳结果的准确率。 |
| [^47] | [A Strategy for Implementing description Temporal Dynamic Algorithms in Dynamic Knowledge Graphs by SPIN.](http://arxiv.org/abs/2401.07890) | 本论文提出了一种使用SPIN在动态知识图中实现时态动态算法的策略，通过将行为嵌入到描述逻辑中，表示和推理行为，并且分析了相关的逻辑结构和工具。 |
| [^48] | [Learning Explainable and Better Performing Representations of POMDP Strategies.](http://arxiv.org/abs/2401.07656) | 本研究提出了一种学习部分可观测的马尔可夫决策过程（POMDP）策略自动机表示的方法。与传统的表格表示相比，该方法得到的自动机更小更易理解，且在学习过程中可改善策略性能。与其他方法相比，本方法在可扩展性上具有显著优势。 |
| [^49] | [Developing ChatGPT for Biology and Medicine: A Complete Review of Biomedical Question Answering.](http://arxiv.org/abs/2401.07510) | 开发用于生物学和医学的ChatGPT，通过自然语言处理和多模态范式，加速了医学问题回答的进展，并且能够处理医学环境中的大规模、多样化、无标签数据分析场景。 |
| [^50] | [Hierarchical Fashion Design with Multi-stage Diffusion Models.](http://arxiv.org/abs/2401.07450) | 本论文提出了一种名为HieraFashDiff的新型时尚设计方法，它使用多级扩散模型实现了从高级设计概念到低级服装属性的分层设计和编辑，解决了当前在时尚设计中的挑战。 |
| [^51] | [Efficient approximation of Earth Mover's Distance Based on Nearest Neighbor Search.](http://arxiv.org/abs/2401.07378) | 本文提出了一种基于最近邻搜索的新方法NNS-EMD来逼近地球移动距离（EMD），以实现高精度、低时间复杂度和高内存效率。该方法通过减少数据点的比较数量和并行处理提供了高效的近似计算，并通过在GPU上进行向量化加速，特别适用于大型数据集。 |
| [^52] | [PDE Generalization of In-Context Operator Networks: A Study on 1D Scalar Nonlinear Conservation Laws.](http://arxiv.org/abs/2401.07364) | 本文以一维标量非线性守恒定律为例，详细介绍了使用上下文操作符网络（ICON）解决PDE问题的方法，并展示了ICON模型在没有微调的情况下可以很好地泛化到具有新形式的PDEs。 |
| [^53] | [Semi-supervised Semantic Segmentation using Redesigned Self-Training for White Blood Cell.](http://arxiv.org/abs/2401.07278) | 本文通过引入半监督学习框架和结合FixMatch，提出了一种重新设计的自训练流程，用于解决白细胞分割中缺乏标记数据集和过时方法的问题。在深度学习架构和自训练方案的支持下，取得了在不同数据集上的优异性能。 |
| [^54] | [A Universal Knowledge Model and Cognitive Architecture for Prototyping AGI.](http://arxiv.org/abs/2401.06256) | 本文提出了一个普适的知识模型和认知架构，用于原型开发通用人工智能（AGI）。该架构包括42种认知架构和一组功能模块，用于接近AGI能力的智能系统。此外，本文还提出了一种通用的知识表示方法，可以将各种不同形式的知识表示整合到一个知识库中。 |
| [^55] | [Universal Vulnerabilities in Large Language Models: In-context Learning Backdoor Attacks.](http://arxiv.org/abs/2401.05949) | 本研究发现上下文学习范式在大型语言模型中存在漏洞，攻击者可以通过污染示范上下文来操控模型行为，而无需进行微调。这项研究设计了一种名为ICLAttack的后门攻击方法，可以通过污染示范样本和提示来使模型按照预定义的意图行事。 |
| [^56] | [The Impact of Reasoning Step Length on Large Language Models.](http://arxiv.org/abs/2401.04925) | 本研究探讨了推理步长对大型语言模型的影响，并发现在提示中增加推理步骤能显著提高模型的推理能力，而减少推理步骤则会降低模型的推理能力。 |
| [^57] | [The inherent goodness of well educated intelligence.](http://arxiv.org/abs/2401.04846) | 本文探讨了智能体变得智能的因素，强调了掌握特征和控制多个保守相互作用的子系统的能力。智能的核心是“集体如一体”和“了解局部行动的整体结果”。文章提出了一种对集体保守系统进行控制的替代方法。 |
| [^58] | [Agent Alignment in Evolving Social Norms.](http://arxiv.org/abs/2401.04620) | 本论文提出了一个名为EvolutionaryAgent的进化框架，将Agent对齐转化为适者生存的演化和选择过程，在不断演化的社会规范中，与当前社会规范更好适应的Agent将具有更高的生存和传播概率。 |
| [^59] | [Decision Making in Non-Stationary Environments with Policy-Augmented Search.](http://arxiv.org/abs/2401.03197) | 在非稳定环境下的决策制定是一个具有挑战性的问题，本文介绍了一种新的算法--策略增强蒙特卡洛树搜索（PA-MCTS），它将在线搜索与策略学习相结合。 |
| [^60] | [On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS).](http://arxiv.org/abs/2401.02500) | 本文研究了将大型语言模型（LLMs）与传统符号规划器集成的前景，并指出这种神经符号方法有望在解决复杂规划问题中发挥重要作用。 |
| [^61] | [Act as You Learn: Adaptive Decision-Making in Non-Stationary Markov Decision Processes.](http://arxiv.org/abs/2401.01841) | 本文提出了一种自适应蒙特卡洛树搜索算法来应对非稳态环境下的决策问题，解决了传统方法中对环境动态假设的限制和规划过程的悲观性问题。 |
| [^62] | [Task-Driven Causal Feature Distillation: Towards Trustworthy Risk Prediction.](http://arxiv.org/abs/2312.16113) | 该论文提出了一种任务驱动的因果特征提取模型（TDCFD），通过将原始特征值转化为因果特征归因来实现可信的风险预测。实验证实了该方法在精确度、召回率和可解释性方面的优势。 |
| [^63] | [When Model Meets New Normals: Test-time Adaptation for Unsupervised Time-series Anomaly Detection.](http://arxiv.org/abs/2312.11976) | 本论文针对无监督时间序列异常检测中的新常态问题，提出了一种基于趋势估计和自监督学习的测试时适应策略，实验证明该策略能够提高模型性能，增加对分布变化的鲁棒性。 |
| [^64] | [Topic-VQ-VAE: Leveraging Latent Codebooks for Flexible Topic-Guided Document Generation.](http://arxiv.org/abs/2312.11532) | 本文介绍了一种利用隐变量码本实现灵活的主题导向文档生成的新方法，通过名为TVQ-VAE的生成式主题模型，可以有效捕捉主题上下文，并支持灵活形式的文档生成。 |
| [^65] | [DeRDaVa: Deletion-Robust Data Valuation for Machine Learning.](http://arxiv.org/abs/2312.11413) | 提出了DeRDaVa：一种适用于机器学习的删除鲁棒数据估值框架。通过在预测删除后保持模型性能的前提下对每个数据源的贡献进行估值，避免了昂贵的重新计算。推广到Risk-DeRDaVa以满足对最坏/最好情况感到风险厌恶/寻求的模型所有者的需求。 |
| [^66] | [Self-Supervised Disentangled Representation Learning for Robust Target Speech Extraction.](http://arxiv.org/abs/2312.10305) | 该论文提出了一种自监督分解表示学习方法，通过逐步分离说话人身份信息和其他无关因素，解决了目标语音提取任务中存在的说话人混叠问题，并使用分解的说话人身份信息来指导语音提取网络。 |
| [^67] | [The DSA Transparency Database: Auditing Self-reported Moderation Actions by Social Media.](http://arxiv.org/abs/2312.10269) | DSA透明数据库对欧盟八大社交媒体平台在前100天提交的审核行动数据进行了全面分析，揭示了这些平台在审核行动方面的部分遵循程度。 |
| [^68] | [Can ChatGPT Play the Role of a Teaching Assistant in an Introductory Programming Course?.](http://arxiv.org/abs/2312.07343) | 这项研究探讨了将ChatGPT作为虚拟教学助理在初级编程课程中的潜力，并通过比较其在评分和反馈方面与人类教学助理的表现来评估其能力。 |
| [^69] | [Beyond Expected Return: Accounting for Policy Reproducibility when Evaluating Reinforcement Learning Algorithms.](http://arxiv.org/abs/2312.07178) | 本文提出了一种超越预期回报的评估方法，在强化学习中考虑策略的可复制性。现有的评估方法仅使用预期回报，无法充分考虑分布的扩散，这限制了其在比较策略时的有效性。 |
| [^70] | [Survey on Foundation Models for Prognostics and Health Management in Industrial Cyber-Physical Systems.](http://arxiv.org/abs/2312.06261) | 工业自动化系统中的预测和健康管理基础模型的调查，着重介绍了大规模基础模型的重大进展和其在ICPS中的应用潜力。 |
| [^71] | [GNN2R: Weakly-Supervised Rationale-Providing Question Answering over Knowledge Graphs.](http://arxiv.org/abs/2312.02317) | GNN2R是一种基于图神经网络的两步推理模型，通过弱监督训练，能够在知识图谱问答中提供最终答案以及推理子图的理由。该方法解决了现有方法缺乏解释以及效率低下的问题。 |
| [^72] | [Criticality-Guided Efficient Pruning in Spiking Neural Networks Inspired by Critical Brain Hypothesis.](http://arxiv.org/abs/2311.16141) | 本研究受到神经科学中的关键大脑假设的启发，提出了一种基于神经元关键性的高效SNN修剪方法，以加强特征提取和加速修剪过程，并取得了比当前最先进方法更好的性能。 |
| [^73] | [Large Language Model as a Policy Teacher for Training Reinforcement Learning Agents.](http://arxiv.org/abs/2311.13373) | 本论文介绍了一种用大规模语言模型作为教师来训练强化学习代理的框架，通过教师代理的指导，学生代理能够以更高效的方式训练，并且能够专门化于特定目标任务。 |
| [^74] | [Jailbreaking GPT-4V via Self-Adversarial Attacks with System Prompts.](http://arxiv.org/abs/2311.09127) | 通过自对抗攻击和系统提示漏洞，我们发现了GPT-4V中存在的安全风险，并提出了一种名为SASP的新型攻击方法，以搜索潜在的破解提示。我们通过添加人工修改，成功率提高到98.7%。我们还评估了修改系统提示对解锁GPT-4V的影响。 |
| [^75] | [Unifying the Perspectives of NLP and Software Engineering: A Survey on Language Models for Code.](http://arxiv.org/abs/2311.07989) | 这篇论文系统地回顾了代码处理方面的语言模型的最新进展，涵盖了50多个模型、30多个评估任务、170多个数据集和700多个相关工作。它突出了代码建模从统计模型和RNN到预训练的Transformer和LLM之间的历史转变，并讨论了代码特定的特性和关键挑战。 |
| [^76] | [Assessing the Interpretability of Programmatic Policies with Large Language Models.](http://arxiv.org/abs/2311.06979) | 本文介绍了一种使用大型语言模型评估编程策略可解释性的新方法，通过度量重建程序与原始程序的行为相似性来评估。这一方法在合成和人工制作的编程策略中得到了验证。 |
| [^77] | [In-Context Learning for MIMO Equalization Using Transformer-Based Sequence Models.](http://arxiv.org/abs/2311.06101) | 本研究利用上下文学习技术解决了多输入多输出（MIMO）均衡的逆问题，基于任务的上下文中的导频符号和未知的衰落信道以及信噪比（SNR）水平。这种方法展示了在实践中的潜力。 |
| [^78] | [A Comprehensive Study of GPT-4V's Multimodal Capabilities in Medical Imaging.](http://arxiv.org/abs/2310.20381) | 本文对GPT-4V在医学影像中的多模态能力进行了全面研究和评估，发现其在生成描述性报告和医学VQA方面有潜力，但在某些评估指标上仍需改进。 |
| [^79] | [Rosetta Stone at KSAA-RD Shared Task: A Hop From Language Modeling To Word--Definition Alignment.](http://arxiv.org/abs/2310.15823) | 本论文介绍了在KSAA-RD共享任务中Rosetta Stone的应用，将语言建模应用到词--定义对齐中。论文通过使用一组微调的阿拉伯BERT模型来预测给定定义的词嵌入，从而实现了阿拉伯词的向量表示。 |
| [^80] | [2D-3D Interlaced Transformer for Point Cloud Segmentation with Scene-Level Supervision.](http://arxiv.org/abs/2310.12817) | 本文提出了一种基于场景级监督的2D-3D交错Transformer模型，用于弱监督点云分割。该模型通过两个编码器计算2D和3D数据的自注意特征，并通过交替切换查询和键值对的角色，实现了2D和3D特征的融合。 |
| [^81] | [Radio Map Estimation in the Real-World: Empirical Validation and Analysis.](http://arxiv.org/abs/2310.11036) | 本文通过对现有的无线电地图估计器进行经验证据的评估，研究了性能和复杂性之间的权衡以及快速衰落的影响。尽管基于深度神经网络的估计器表现最佳，但需要大量的训练数据。一种混合了传统方案和深度神经网络的新算法表现良好。 |
| [^82] | [Interpreting CLIP's Image Representation via Text-Based Decomposition.](http://arxiv.org/abs/2310.05916) | 本文通过解析CLIP图像编码器的组件，揭示了图像表示的构成方式，并利用文本表示解释了其各个部分的作用。通过理解注意力头和图像块，作者实现了对模型的修复和改进，包括消除误特征和构建零样本图像分割器等方面。 |
| [^83] | [MathVista: Evaluating Math Reasoning in Visual Contexts with GPT-4V, Bard, and Other Large Multimodal Models.](http://arxiv.org/abs/2310.02255) | 本论文提出了MathVista，这是一个评估视觉场景中数学推理能力的基准测试。通过对12个著名的基础模型进行全面的定量评估，发现最好的GPT-4V模型相对于第二名的Bard模型在准确率上提升了15.1%。 |
| [^84] | [TWIZ-v2: The Wizard of Multimodal Conversational-Stimulus.](http://arxiv.org/abs/2310.02118) | TWIZ-v2是一个多模态对话刺激的巫师助手，旨在通过以人性化的方式提供信息、利用多种模态进行刺激以及改进对未见过场景的交互鲁棒性来引导用户成功完成复杂的手动任务。 |
| [^85] | [LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment.](http://arxiv.org/abs/2310.01852) | LanguageBind提出了将语言作为不同模态之间纽带的方法，通过冻结视频-语言预训练获取的语言编码器，并使用对比学习训练其他模态的编码器，实现了多模态的语义对齐。此外，作者还提出了VIDAL-10M数据集来支持该方法。 |
| [^86] | [FashionFlow: Leveraging Diffusion Models for Dynamic Fashion Video Synthesis from Static Imagery.](http://arxiv.org/abs/2310.00106) | 本研究提出了一种名为FashionFlow的图像到视频生成器，利用扩散模型从静态图像生成短视频。我们通过开发并连接与扩散模型相关的组件来实现这一目标，其中包括使用伪3D卷积层高效生成视频，并利用VAE和CLIP编码器捕捉关键特征。研究结果展示了成功合成时尚视频的能力，能够展示服装的合身度和外观，为在线时尚行业的购物体验提供改进和增强的潜力。 |
| [^87] | [Limits of Actor-Critic Algorithms for Decision Tree Policies Learning in IBMDPs.](http://arxiv.org/abs/2309.13365) | 该论文研究了在IBMDP中使用Actor-Critic算法学习决策树策略的局限性。结果表明，即使是在简单的玩具任务上，深度RL也可能失败。 |
| [^88] | [Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection.](http://arxiv.org/abs/2309.12247) | 大型语言模型对于假新闻检测的潜力仍未得到充分探索。实证研究发现，尽管复杂的大型语言模型能够揭示假新闻并提供多角度解释，但仍不如经过fine-tuned的小型语言模型表现出色。当前的大型语言模型可能无法取代小型语言模型，但可以作为一个良好的辅助顾问。 |
| [^89] | [ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events.](http://arxiv.org/abs/2309.12244) | ChaCha是一个利用大型语言模型（LLMs）的聊天机器人，鼓励儿童分享个人事件和相关情绪。通过一个探索性研究，发现儿童将ChaCha视为亲密的朋友，并愿意与其分享各种主题的故事。 |
| [^90] | [Federated Learning with Neural Graphical Models.](http://arxiv.org/abs/2309.11680) | 本研究提出了一种名为FedNGMs的联邦学习框架，利用概率神经图模型来处理多个客户端的数据，并在保持训练数据私密性的同时提升模型准确性。 |
| [^91] | [SingFake: Singing Voice Deepfake Detection.](http://arxiv.org/abs/2309.07525) | 本文提出了唱歌声音Deepfake检测任务，并通过提供一个特定的数据集和评估系统的方法，对这一问题进行了研究和解决。 |
| [^92] | [The Relational Bottleneck as an Inductive Bias for Efficient Abstraction.](http://arxiv.org/abs/2309.06629) | 本文介绍了一种新的归纳偏好方法——关系瓶颈，用于有效地诱导抽象概念的模型，强调了其在人类思维和大脑中抽象概念习得中的潜力。 |
| [^93] | [DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning.](http://arxiv.org/abs/2309.05173) | DePT通过将软提示分解为较短的软提示和一对低秩矩阵，并用两个不同的学习率来优化，以解决提示调整对训练和推理时间以及内存使用的影响，从而实现更好的性能。 |
| [^94] | [Decolonial AI Alignment: Vi\'{s}esadharma, Argument, and Artistic Expression.](http://arxiv.org/abs/2309.05030) | 本文提出了去殖民化人工智能对齐的三个建议：改变基本道德哲学为达尔玛哲学，允许多元主义的论证传统存在于对齐技术中，以及将价值认识论扩展到超越自然语言中的指令。 |
| [^95] | [ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning.](http://arxiv.org/abs/2309.01538) | 本论文提出了一个框架ChatRule，利用大型语言模型挖掘知识图谱中的逻辑规则。该框架通过充分利用知识图谱的语义和结构信息，能够提高推理性能并提供可解释的结果。 |
| [^96] | [Federated Fine-tuning of Billion-Sized Language Models across Mobile Devices.](http://arxiv.org/abs/2308.13894) | 这项工作引入了一种创新的FL协议FwdLLM，旨在提高在移动设备上进行十亿规模语言模型的联邦微调（FedLLM）的效率。FwdLLM通过使用无反向传播（BP）训练方法以及“扰动推断”来提高内存效率和时间效率。 |
| [^97] | [Does Asking Clarifying Questions Increases Confidence in Generated Code? On the Communication Skills of Large Language Models.](http://arxiv.org/abs/2308.13507) | 通过在生成代码之前提问澄清问题，大型语言模型的代码生成能力可以得到提升，增加了对生成代码的信心。 |
| [^98] | [Robust Uncertainty Quantification using Conformalised Monte Carlo Prediction.](http://arxiv.org/abs/2308.09647) | 这篇论文介绍了一种名为MC-CP的新型混合不确定性量化方法，通过将自适应蒙特卡洛dropout方法与合规预测相结合，实现了节省资源和产生鲁棒预测集/区间的目标。实验证明MC-CP在分类任务中相比其他先进方法具有显著提升 |
| [^99] | [Semantic Communications for Artificial Intelligence Generated Content (AIGC) Toward Effective Content Creation.](http://arxiv.org/abs/2308.04942) | 本论文提出了一个综合概念模型，用于集成人工智能生成内容（AIGC）和语义沟通（SemCom），以产生有意义和效果的内容。同时，提出了一个采用AIGC技术作为编码器和解码器的框架，优化了语义提取和评估指标。实验验证了该方法的有效性。 |
| [^100] | [Developmental Bootstrapping of AIs.](http://arxiv.org/abs/2308.04586) | 传统的符号AI方法和深度学习AI方法无法满足创建强大和可信赖的AI的挑战，然而，发展脱靴法通过模仿人类儿童的能力发展过程，为创建稳健可靠的AI提供了希望。 |
| [^101] | [Engineering LaCAM$^\ast$: Towards Real-Time, Large-Scale, and Near-Optimal Multi-Agent Pathfinding.](http://arxiv.org/abs/2308.04292) | 本文通过改进LaCAM*算法，解决了实时、大规模、接近最优的多智能体路径规划的挑战。改进技术的融合显著提高了LaCAM*的解决方案质量，推动了MAPF算法的边界。 |
| [^102] | [FedDRL: A Trustworthy Federated Learning Model Fusion Method Based on Staged Reinforcement Learning.](http://arxiv.org/abs/2307.13716) | FedDRL是一种分阶段强化学习的联邦学习模型融合方法，解决了传统方法中无法解决的客户端模型质量和恶意模型问题。 |
| [^103] | [Past-present temporal programs over finite traces.](http://arxiv.org/abs/2307.12620) | 本文研究了过去-现在时间程序的建模方法，通过在逻辑编程规则中引用过去和现在，保证了过去与未来的独立性。同时，我们扩展了补全和循环公式的定义，通过LTLf表达式捕捉了一组过去-现在时间程序的时间稳定模型。 |
| [^104] | [Prescriptive Process Monitoring Under Resource Constraints: A Reinforcement Learning Approach.](http://arxiv.org/abs/2307.06564) | 本论文提出了一种在资源限制下进行处方过程监控的强化学习方法。通过考虑对干预需求、及时性或效果预测的不确定性和资源利用水平，来触发干预，从而优化业务过程的性能。 |
| [^105] | [Streamlining Social Media Information Retrieval for Public Health Research with Deep Learning.](http://arxiv.org/abs/2306.16001) | 本研究介绍了一个使用深度学习简化社交媒体信息检索的框架，通过识别医学实体、标准化实体和分配UMLS概念，构建了一个用于COVID-19相关推文的症状词典。 |
| [^106] | [Data-Driven Regret Balancing for Online Model Selection in Bandits.](http://arxiv.org/abs/2306.02869) | 论文讨论在具有赌博反馈的随机环境中进行选择，提出了两种基于数据的模型选择算法，并证明了其保证。通过利用实际遗憾，这些算法在实际中取得了好效果。 |
| [^107] | [Gode -- Integrating Biochemical Knowledge Graph into Pre-training Molecule Graph Neural Network.](http://arxiv.org/abs/2306.01631) | 本研究提出了一种新的方法，在分子结构和生物医学知识图谱中集成多个领域信息，通过自我监督策略预先训练更广泛和更强大的表示，并在化学属性预测任务上展示出出色的性能。 |
| [^108] | [Medication Recommendation via Domain Knowledge Informed Deep Learning.](http://arxiv.org/abs/2305.19604) | 提出一种基于动态领域知识的药物推荐框架DKINet，将领域知识与患者临床表现相结合，此为首次实验。 |
| [^109] | [Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations.](http://arxiv.org/abs/2305.16326) | 本文研究了GPT-3和GPT-4在生物医学自然语言处理中的表现，分析了它们可能产生的错误类型，并提供了使用这些模型的建议。 |
| [^110] | [EXACT: Extensive Attack for Split Learning.](http://arxiv.org/abs/2305.12997) | 本文提出了一种名为EXACT的方法，可以安全地在分布式学习中进行梯度交换，同时保护隐私、保持准确性和效率性。 |
| [^111] | [A Framework for Designing Foundation Model based Systems.](http://arxiv.org/abs/2305.05352) | 本文提出了一个基于基础模型的系统分类体系，分类和比较了基础模型和基于基础模型的系统的特点。它为设计基于基础模型的系统时做出主要的设计决策提供了具体的指导，并突出了相关的权衡。 |
| [^112] | [Explaining RL Decisions with Trajectories.](http://arxiv.org/abs/2305.04073) | 本文提出一种用训练过程中遇到的轨迹解释强化学习决策的方法，并在离散和连续状态及行动空间的多样化环境中证明了其有效性。 |
| [^113] | [Large Language Models Are State-of-the-Art Evaluators of Code Generation.](http://arxiv.org/abs/2304.14317) | 本文提出了一个基于 GPT-3.5 的评估框架，解决了现有方法在代码生成任务上的局限性，取得了更好的相关性。 |
| [^114] | [Plotting Behind the Scenes: Towards Learnable Game Engines.](http://arxiv.org/abs/2303.13472) | 本文提出了一个方法，可以从单眼注释视频中训练出类似游戏引擎的神经模型，这个模型被称为可学习游戏引擎(LGE)，它可以通过指定高级和低级操作序列来玩游戏，并且解锁了导演模式，可以使用高级约束条件控制代理。 |
| [^115] | [What Makes Data Suitable for a Locally Connected Neural Network? A Necessary and Sufficient Condition Based on Quantum Entanglement.](http://arxiv.org/abs/2303.11249) | 本文通过采用量子物理学的理论工具，提出了一种判定数据适合于局部连接神经网络的必要且充分条件，并导出了一种相应的预处理方法。 |
| [^116] | [A Generalized Multi-Modal Fusion Detection Framework.](http://arxiv.org/abs/2303.07064) | 本文提出了一个通用的多模态融合检测框架，旨在在复杂场景中通过准确融合激光雷达和图像来提高3D检测的精度。 |
| [^117] | [Cal-QL: Calibrated Offline RL Pre-Training for Efficient Online Fine-Tuning.](http://arxiv.org/abs/2303.05479) | 本文介绍了一种计算机辅助脱机强化学习方法Cal-QL，该方法能够从脱机数据中学习一个保守的值函数初始化，使得在在线微调时同时保障了快速和性能。 |
| [^118] | [Bayesian Matrix Decomposition and Applications.](http://arxiv.org/abs/2302.11337) | 本书旨在介绍贝叶斯矩阵分解的概念和工具，并总结了贝叶斯矩阵分解方法在不同领域的应用。 |
| [^119] | [AV-data2vec: Self-supervised Learning of Audio-Visual Speech Representations with Contextualized Target Representations.](http://arxiv.org/abs/2302.06419) | AV-data2vec是一种使用自监督学习来构建音视频语音表示的方法，能够同时训练音频和视频的联合表示，并在语音识别任务中表现出优越性能。 |
| [^120] | [Identifying Generalized Neural Representation Across Hamiltonian Manifolds via Meta-learning.](http://arxiv.org/abs/2212.01168) | 通过元学习方法，在哈密顿流形中识别出普遍的神经表示，实现了对不同物理系统的快速适应能力。 |
| [^121] | [Proportional algebras.](http://arxiv.org/abs/2210.01751) | 本文引入了直比代数，探讨了保持比拟比例的函数的数学性质，将其与直比同态、同余和直比函子联系起来，为模拟比例和模拟推理的数学理论提供了进一步理解。 |
| [^122] | [Heterogeneous Multi-agent Zero-Shot Coordination by Coevolution.](http://arxiv.org/abs/2208.04957) | 本研究首次研究了异构零样本协同问题，并提出了一种基于协同进化的通用方法，通过配对、更新和选择的过程，实现了多智能体零样本协同。实验结果表明，考虑异构情况的必要性，并证明了该方法对于异构零样本协同任务的有前景的解决方案。 |
| [^123] | [Rethinking Unsupervised Domain Adaptation for Semantic Segmentation.](http://arxiv.org/abs/2207.00067) | 这项研究重新思考了语义分割的无监督领域自适应方法，提出了从数据中心的角度重新考虑无监督领域自适应问题，并探讨了使用最少的标记数据来确定UDA方法超参数的方法。 |
| [^124] | [Wavelet-based temporal models of human activity for anomaly detection in smart robot-assisted environments.](http://arxiv.org/abs/2002.11503) | 本文提出了一种基于小波变换的新方法，用于在智能机器人辅助环境中检测人类活动的异常情况。该方法通过预测智能传感器数据，并结合混合马尔科夫逻辑网络扩展，将不同的异常指标合并在一起，以提供时间先验，并检测人类环境中的意外事件。 |

# 详细

[^1]: 通过眼动数据和头部姿势评估有条件自动驾驶车辆中驾驶员的准备性

    Evaluating Driver Readiness in Conditionally Automated Vehicles from Eye-Tracking Data and Head Pose. (arXiv:2401.11284v1 [cs.CV])

    [http://arxiv.org/abs/2401.11284](http://arxiv.org/abs/2401.11284)

    本文通过结合头部姿势特征和眼动数据对驾驶员在有条件自动驾驶车辆中的准备性进行了全面分析，通过使用LSTM体系结构的机器学习技术进行建模，成功地评估了驾驶员的准备性。

    

    随着自动驾驶技术的进步，驾驶员在有条件自动驾驶车辆中恢复对车辆控制的角色变得越来越关键。在SAE Level 3或部分自动化的车辆中，驾驶员需要在必要时保持可用和准备好介入。因此，准确评估他们的准备性至关重要。本文通过结合头部姿势特征和眼动数据对驾驶员准备性评估进行了全面分析。该研究探讨了预测模型在评估驾驶员准备性方面的有效性，解决了数据集限制和有限的真实标签的挑战。利用机器学习技术，包括LSTM体系结构，建模驾驶员准备性基于驾驶员头部姿势和注视的时空状态。本文的实验结果显示，结合两个特征集的双向LSTM体系结构在DMD数据集上达到了0.363的平均绝对误差。

    As automated driving technology advances, the role of the driver to resume control of the vehicle in conditionally automated vehicles becomes increasingly critical. In the SAE Level 3 or partly automated vehicles, the driver needs to be available and ready to intervene when necessary. This makes it essential to evaluate their readiness accurately. This article presents a comprehensive analysis of driver readiness assessment by combining head pose features and eye-tracking data. The study explores the effectiveness of predictive models in evaluating driver readiness, addressing the challenges of dataset limitations and limited ground truth labels. Machine learning techniques, including LSTM architectures, are utilised to model driver readiness based on the Spatio-temporal status of the driver's head pose and eye gaze. The experiments in this article revealed that a Bidirectional LSTM architecture, combining both feature sets, achieves a mean absolute error of 0.363 on the DMD dataset, d
    
[^2]: 多智能体强化学习中的政策距离测量

    Measuring Policy Distance for Multi-Agent Reinforcement Learning. (arXiv:2401.11257v1 [cs.MA])

    [http://arxiv.org/abs/2401.11257](http://arxiv.org/abs/2401.11257)

    本文提出了一种用于测量多智能体强化学习中政策差异的通用工具，即多智能体政策距离（MAPD）。通过学习智能体的决策条件表示，MAPD可以计算任意一对智能体之间的政策距离，并且可以扩展到定制化版本以量化智能体政策在特定方面的差异。这个工具不仅有助于评估多智能体系统中多样性的演变，还为基于多样性的MARL算法的设计提供指导。

    

    多样性在改善多智能体强化学习（MARL）的性能中起着关键作用。目前，已经开发出许多基于多样性的方法，以克服传统MARL中过多参数共享的缺点。然而，目前缺乏一种通用的度量标准来量化智能体之间的政策差异。这样的度量标准不仅可以方便地评估多智能体系统中多样性的演变，还可以为基于多样性的MARL算法的设计提供指导。本文中，我们提出了多智能体政策距离（MAPD），这是一个用于测量MARL中政策差异的通用工具。通过学习智能体决策的条件表示，MAPD可以计算任意一对智能体之间的政策距离。此外，我们还将MAPD扩展为可定制的版本，可以量化在指定方面的智能体政策之间的差异。基于MAPD的在线部署，我们设计了一个多智能体动态参数共享（MAD）模型。

    Diversity plays a crucial role in improving the performance of multi-agent reinforcement learning (MARL). Currently, many diversity-based methods have been developed to overcome the drawbacks of excessive parameter sharing in traditional MARL. However, there remains a lack of a general metric to quantify policy differences among agents. Such a metric would not only facilitate the evaluation of the diversity evolution in multi-agent systems, but also provide guidance for the design of diversity-based MARL algorithms. In this paper, we propose the multi-agent policy distance (MAPD), a general tool for measuring policy differences in MARL. By learning the conditional representations of agents' decisions, MAPD can computes the policy distance between any pair of agents. Furthermore, we extend MAPD to a customizable version, which can quantify differences among agent policies on specified aspects. Based on the online deployment of MAPD, we design a multi-agent dynamic parameter sharing (MAD
    
[^3]: 自动融合多模态电子健康记录以提升医疗预测准确性

    Automated Fusion of Multimodal Electronic Health Records for Better Medical Predictions. (arXiv:2401.11252v1 [cs.LG])

    [http://arxiv.org/abs/2401.11252](http://arxiv.org/abs/2401.11252)

    该论文提出了一种自动融合多模态电子健康记录的神经架构搜索框架，用于改进医疗预测准确性。该框架可以自动搜索用于编码不同输入模态和融合策略的最佳模型架构，并在实验中取得了超越传统方法的效果。

    

    在医疗机构广泛采用电子健康记录（EHR）系统产生了大量医疗数据，为通过深度学习技术改进医疗服务提供了重要机会。然而，真实世界的EHR数据中复杂多样的模态和特征结构给深度学习模型设计带来了巨大挑战。为了解决EHR数据中的多模态问题，当前的方法主要依靠基于直觉和经验的手工模型架构，导致子优模型架构和有限性能。因此，为了自动化EHR数据挖掘模型设计的过程，我们提出了一种名为AutoFM的新颖神经架构搜索（NAS）框架，该框架能够自动搜索用于编码不同输入模态和融合策略的最佳模型架构。我们在真实的多模态EHR数据和预测任务上进行了全面的实验，实验证明了我们的方法的有效性和性能超越了传统方法。

    The widespread adoption of Electronic Health Record (EHR) systems in healthcare institutes has generated vast amounts of medical data, offering significant opportunities for improving healthcare services through deep learning techniques. However, the complex and diverse modalities and feature structures in real-world EHR data pose great challenges for deep learning model design. To address the multi-modality challenge in EHR data, current approaches primarily rely on hand-crafted model architectures based on intuition and empirical experiences, leading to sub-optimal model architectures and limited performance. Therefore, to automate the process of model design for mining EHR data, we propose a novel neural architecture search (NAS) framework named AutoFM, which can automatically search for the optimal model architectures for encoding diverse input modalities and fusion strategies. We conduct thorough experiments on real-world multi-modal EHR data and prediction tasks, and the results 
    
[^4]: 评估信任和个人信息隐私关注是否成为使用明确利用人工智能的健康保险的障碍

    Evaluating if trust and personal information privacy concerns are barriers to using health insurance that explicitly utilizes AI. (arXiv:2401.11249v1 [cs.CY])

    [http://arxiv.org/abs/2401.11249](http://arxiv.org/abs/2401.11249)

    本研究评估了信任和个人信息隐私关注是否成为使用明确利用人工智能的健康保险的障碍。研究发现，人工智能可见性降低了信任水平，而隐私关注在人工智能的情况下更高，但并没有统计显著性差异。

    

    信任和隐私已经成为在线交易中的重要关注点。分享健康信息尤其敏感，但对于购买和使用健康保险来说是必要的。证据表明，消费者越来越愿意使用技术代替人类，但人工智能的广泛使用可能改变这一点。本研究探讨了信任和隐私关注是否成为健康保险中人工智能采用的障碍。比较了两个情景：第一个情景中，有限的人工智能不在界面上，并且其存在没有明确告知消费者。在第二个情景中，有一个人工智能界面和人工智能评估，并且这一点明确告知消费者。使用SEM PLS-MGA模型对这两个情景进行了建模和比较。研究结果显示，信任在第二个情景中明显较低，也就是人工智能可见的情况。隐私关注在人工智能的情况下更高，但在模型内部并没有统计显著性差异。

    Trust and privacy have emerged as significant concerns in online transactions. Sharing information on health is especially sensitive but it is necessary for purchasing and utilizing health insurance. Evidence shows that consumers are increasingly comfortable with technology in place of humans, but the expanding use of AI potentially changes this. This research explores whether trust and privacy concern are barriers to the adoption of AI in health insurance. Two scenarios are compared: The first scenario has limited AI that is not in the interface and its presence is not explicitly revealed to the consumer. In the second scenario there is an AI interface and AI evaluation, and this is explicitly revealed to the consumer. The two scenarios were modeled and compared using SEM PLS-MGA. The findings show that trust is significantly lower in the second scenario where AI is visible. Privacy concerns are higher with AI but the difference is not statistically significant within the model.
    
[^5]: TreeMIL：一个用于带有不精确监督的时间序列异常检测的多实例学习框架

    TreeMIL: A Multi-instance Learning Framework for Time Series Anomaly Detection with Inexact Supervision. (arXiv:2401.11235v1 [cs.LG])

    [http://arxiv.org/abs/2401.11235](http://arxiv.org/abs/2401.11235)

    本文提出了一个基于树的多实例学习框架(TreeMIL)，用于带有不精确监督的时间序列异常检测。该框架通过将整个序列分解成多个节点，并提取子序列特征，旨在解决集体异常的挑战。

    

    时间序列异常检测在医疗、网络和工业等各个领域扮演着重要的角色。考虑到标签对于检测来说是至关重要但很难获得，我们转而研究带有不精确监督的时间序列异常检测：在训练阶段只提供序列级别的标签，在测试阶段预测出点级别的异常。之前的研究采用传统的多实例学习(MIL)方法，重点是鼓励在各个时间步骤中得到高的异常分数。然而，时间序列的异常不仅限于个别点异常，它们还可以是集体异常，通常在子序列中展示出异常模式。为了应对集体异常的挑战，本文提出了一种基于树的MIL框架(TreeMIL)。我们首先采用一个N叉树结构将整个序列分成多个节点，不同层级的节点表示具有不同长度的子序列。然后，子序列特征被提取来预测节点的异常得分。

    Time series anomaly detection (TSAD) plays a vital role in various domains such as healthcare, networks, and industry. Considering labels are crucial for detection but difficult to obtain, we turn to TSAD with inexact supervision: only series-level labels are provided during the training phase, while point-level anomalies are predicted during the testing phase. Previous works follow a traditional multi-instance learning (MIL) approach, which focuses on encouraging high anomaly scores at individual time steps. However, time series anomalies are not only limited to individual point anomalies, they can also be collective anomalies, typically exhibiting abnormal patterns over subsequences. To address the challenge of collective anomalies, in this paper, we propose a tree-based MIL framework (TreeMIL). We first adopt an N-ary tree structure to divide the entire series into multiple nodes, where nodes at different levels represent subsequences with different lengths. Then, the subsequence fe
    
[^6]: 一种传输学习和物理信息建模的混合方法：提高工业废水处理厂溶解氧浓度预测的准确性

    A Hybrid Approach of Transfer Learning and Physics-Informed Modeling: Improving Dissolved Oxygen Concentration Prediction in an Industrial Wastewater Treatment Plant. (arXiv:2401.11217v1 [cs.LG])

    [http://arxiv.org/abs/2401.11217](http://arxiv.org/abs/2401.11217)

    本论文提出了一种传输学习和物理信息建模的混合方法，通过将其他任务中的知识转移到目标任务中，以提高工业废水处理厂溶解氧浓度预测的准确性。这种方法结合了开源模型的物理知识和另一个工业厂的数据，并使训练问题的目标函数具备物理信息建模的特点。

    

    构建非线性和复杂系统（如废水处理单元）的第一原理模型是一项具有挑战性的任务。近年来，数据驱动模型被广泛用于解决复杂性问题。然而，它们常常面临着缺失、低质量或噪声数据等问题。传输学习是解决这个问题的一种方法，它将来自另一个任务的知识传输到目标任务中，以提高预测性能。本文旨在通过传输（i）捕获过程底层物理特性的开源仿真模型的知识，尽管与目标工厂有所不同，（ii）另一个特点是噪声和有限数据的同一炼油厂的工业厂的知识，以及（iii）来自（ii）模型，并将训练问题的目标函数建模为物理信息，从开源模型的导出物理信息。

    Constructing first principles models is a challenging task for nonlinear and complex systems such as a wastewater treatment unit. In recent years, data-driven models are widely used to overcome the complexity. However, they often suffer from issues such as missing, low quality or noisy data. Transfer learning is a solution for this issue where knowledge from another task is transferred to target one to increase the prediction performance. In this work, the objective is increasing the prediction performance of an industrial wastewater treatment plant by transferring the knowledge of (i) an open-source simulation model that captures the underlying physics of the process, albeit with dissimilarities to the target plant, (ii) another industrial plant characterized by noisy and limited data but located in the same refinery, and (iii) the model in (ii) and making the objective function of the training problem physics informed where the physics information derived from the open-source model i
    
[^7]: 在交换演算中编程分布式集体过程

    Programming Distributed Collective Processes in the eXchange Calculus. (arXiv:2401.11212v1 [cs.DC])

    [http://arxiv.org/abs/2401.11212](http://arxiv.org/abs/2401.11212)

    本研究在交换演算中考虑了集合设备的动态合作行为，提出了分布式集体过程的抽象表示，用于编程计算集体的行为。

    

    最近的趋势如物联网（IoT）提出了在几乎所有环境中密集和多尺度部署计算设备的愿景。一个突出的工程挑战围绕着编程这种计算生态系统的集体自适应行为。这需要能够捕捉概念（动态合作设备群组）和集体任务（由合奏组执行的联合活动）的抽象。在这项工作中，我们考虑与邻居交互并以几乎同步的感知-计算-交互循环执行的设备集合，其中计算由一个将感知值和传入消息映射到输出和传出消息的单个程序给出。为了支持整个计算集体的编程，我们提出了分布式集体过程的抽象，它可以同时定义合奏组的形成逻辑和它的集体任务。我们在交换演算中形式化了这种抽象。

    Recent trends like the Internet of Things (IoT) suggest a vision of dense and multi-scale deployments of computing devices in nearly all kinds of environments. A prominent engineering challenge revolves around programming the collective adaptive behaviour of such computational ecosystems. This requires abstractions able to capture concepts like ensembles (dynamic groups of cooperating devices) and collective tasks (joint activities carried out by ensembles). In this work, we consider collections of devices interacting with neighbours and that execute in nearly-synchronised sense-compute-interact rounds, where the computation is given by a single program mapping sensing values and incoming messages to output and outcoming messages. To support programming whole computational collectives, we propose the abstraction of a distributed collective process, which can be used to define at once the ensemble formation logic and its collective task. We formalise the abstraction in the eXchange Calc
    
[^8]: 在搜索中探究用户行为以检测参与度和反作用效应的薄线

    Navigating the Thin Line: Examining User Behavior in Search to Detect Engagement and Backfire Effects. (arXiv:2401.11201v1 [cs.IR])

    [http://arxiv.org/abs/2401.11201](http://arxiv.org/abs/2401.11201)

    本研究调查了有意见的用户在搜索行为中关注度和反效应的问题，并发现暴露于偏见搜索结果会增加他们消费反对态度内容的数量。

    

    带有偏见的用户经常寻求与其先前信念一致的信息，同时忽视相矛盾的证据，这是由于确认偏见所致。这种行为阻碍了他们在搜索网络时考虑替代立场的能力。尽管如此，很少有研究分析争议话题的搜索结果多样化如何影响高度有意见的用户的搜索行为。为此，我们进行了一项预注册的用户研究(n = 257)，调查了不同水平(低和高)的偏见指标和搜索结果展示(带或不带基于人工智能预测的立场标签)是否会影响有意见的用户在三个有争议的话题上(即无神论、知识产权和校服)的立场多样性消费和搜索行为。我们的结果表明，将参与者暴露于(反态度)偏见的搜索结果会增加他们消费反对态度内容的数量，但我们也发现偏见与趋向。

    Opinionated users often seek information that aligns with their preexisting beliefs while dismissing contradictory evidence due to confirmation bias. This conduct hinders their ability to consider alternative stances when searching the web. Despite this, few studies have analyzed how the diversification of search results on disputed topics influences the search behavior of highly opinionated users. To this end, we present a preregistered user study (n = 257) investigating whether different levels (low and high) of bias metrics and search results presentation (with or without AI-predicted stances labels) can affect the stance diversity consumption and search behavior of opinionated users on three debated topics (i.e., atheism, intellectual property rights, and school uniforms). Our results show that exposing participants to (counter-attitudinally) biased search results increases their consumption of attitude-opposing content, but we also found that bias was associated with a trend towar
    
[^9]: 快速准确枚举深度网络分区区域

    Fast and Exact Enumeration of Deep Networks Partitions Regions. (arXiv:2401.11188v1 [cs.LG])

    [http://arxiv.org/abs/2401.11188](http://arxiv.org/abs/2401.11188)

    本文提出了第一个能够精确枚举DN分区的并行算法，可以评估常用的基于随机抽样的近似方法，发现如果只对具有“大”体积的区域感兴趣，那么对空间进行均匀抽样非常高效。

    

    深度网络(DNs)的一个富有成果的表述方式是通过分段仿射样条来实现，它既能够进行理论研究，又能为从业者提供实践指导。在这个领域中，一个DN的输入映射被表达为按区域的仿射映射，其中这些区域由模型的架构隐式确定，并形成它们的输入空间的一个分区。迄今为止，这个分区——这个研究线中产生的所有结果都涉及到它——只在DN的输入空间的$2/3$维切片上计算过，或者通过随机抽样进行估计。在本文中，我们提出了第一个能够精确枚举DN分区区域的并行算法。所提出的算法最终能够对常用的近似方法进行评估，例如基于DN输入空间的随机抽样。我们的一个重要发现是，如果只对具有“大”体积的区域感兴趣，那么对空间进行均匀抽样非常高效。

    One fruitful formulation of Deep Networks (DNs) enabling their theoretical study and providing practical guidelines to practitioners relies on Piecewise Affine Splines. In that realm, a DN's input-mapping is expressed as per-region affine mapping where those regions are implicitly determined by the model's architecture and form a partition of their input space. That partition -- which is involved in all the results spanned from this line of research -- has so far only been computed on $2/3$-dimensional slices of the DN's input space or estimated by random sampling. In this paper, we provide the first parallel algorithm that does exact enumeration of the DN's partition regions. The proposed algorithm enables one to finally assess the closeness of the commonly employed approximations methods, e.g. based on random sampling of the DN input space. One of our key finding is that if one is only interested in regions with ``large'' volume, then uniform sampling of the space is highly efficient
    
[^10]: 像素级别识别用于整体外科场景理解

    Pixel-Wise Recognition for Holistic Surgical Scene Understanding. (arXiv:2401.11174v1 [cs.CV])

    [http://arxiv.org/abs/2401.11174](http://arxiv.org/abs/2401.11174)

    本文提出了一个整体和多粒度外科场景理解数据集，以及一个基于变形器的模型，该模型有效地结合了全局视频特征提取和局部器械分割，可用于多层次理解外科活动。

    

    本文提出了Prostatectomies的整体和多粒度外科场景理解（GraSP）数据集，该数据集对外科场景理解进行了层次化建模，包括不同粒度的互补任务。我们的方法实现了对外科活动的多层次理解，包括外科阶段和步骤的识别以及包括外科器械分割和原子可视动作检测在内的短期任务。为了利用我们提出的数据集，我们引入了基于变形器（Transformers）的行动、阶段、步骤和器械分割（TAPIS）模型，该模型将全局视频特征提取器与来自器械分割模型的局部区域建议相结合，以应对我们数据集的多粒度问题。通过广泛的实验，我们展示了在短期识别任务中包括分割注释的影响，并突显了不同的粒度要求。

    This paper presents the Holistic and Multi-Granular Surgical Scene Understanding of Prostatectomies (GraSP) dataset, a curated benchmark that models surgical scene understanding as a hierarchy of complementary tasks with varying levels of granularity. Our approach enables a multi-level comprehension of surgical activities, encompassing long-term tasks such as surgical phases and steps recognition and short-term tasks including surgical instrument segmentation and atomic visual actions detection. To exploit our proposed benchmark, we introduce the Transformers for Actions, Phases, Steps, and Instrument Segmentation (TAPIS) model, a general architecture that combines a global video feature extractor with localized region proposals from an instrument segmentation model to tackle the multi-granularity of our benchmark. Through extensive experimentation, we demonstrate the impact of including segmentation annotations in short-term recognition tasks, highlight the varying granularity require
    
[^11]: 在嵌入空间中推广演讲者验证以对抗欺骗意识

    Generalizing Speaker Verification for Spoof Awareness in the Embedding Space. (arXiv:2401.11156v1 [cs.CR])

    [http://arxiv.org/abs/2401.11156](http://arxiv.org/abs/2401.11156)

    本文提出了一种在嵌入空间中推广的演讲者验证系统，可以同时处理冒充者和欺骗攻击，提供更强的保护和更经济的计算。

    

    如今众所周知，自动演讲者验证（ASV）系统可以被各种类型的对手欺骗。对抗ASV系统的常见方法是开发一个独立的欺骗对策（CM）模块，将演讲输入分类为真实或伪造的话语。然而，这种设计在认证阶段需要额外的计算和利用。另一种策略是设计一个统一的ASV系统，可以处理零努力的冒充者（非目标）和欺骗攻击。这种具有欺骗意识的ASV系统有可能提供更强的保护和更经济的计算。为此，我们提出了在嵌入空间中推广独立ASV（G-SASV）来对抗欺骗攻击的方法，在测试（认证）阶段不涉及独立的CM模块，并利用来自CM的有限训练数据增强简单的后端。

    It is now well-known that automatic speaker verification (ASV) systems can be spoofed using various types of adversaries. The usual approach to counteract ASV systems against such attacks is to develop a separate spoofing countermeasure (CM) module to classify speech input either as a bonafide, or a spoofed utterance. Nevertheless, such a design requires additional computation and utilization efforts at the authentication stage. An alternative strategy involves a single monolithic ASV system designed to handle both zero-effort imposter (non-targets) and spoofing attacks. Such spoof-aware ASV systems have the potential to provide stronger protections and more economic computations. To this end, we propose to generalize the standalone ASV (G-SASV) against spoofing attacks, where we leverage limited training data from CM to enhance a simple backend in the embedding space, without the involvement of a separate CM module during the test (authentication) phase. We propose a novel yet simple 
    
[^12]: 高斯自适应注意力是唯一所需的：跨多个模态的健壮上下文表示

    Gaussian Adaptive Attention is All You Need: Robust Contextual Representations Across Multiple Modalities. (arXiv:2401.11143v1 [cs.LG])

    [http://arxiv.org/abs/2401.11143](http://arxiv.org/abs/2401.11143)

    该论文提出了一个名为GAAM的多头高斯自适应注意力机制，用于增强跨多个模态的信息聚合。通过将可学习的均值和方差纳入注意力机制中，GAAM能够动态地重新调整特征的重要性，从而在处理非平稳数据时取得了显著的性能提升，超过了目前现有的注意力技术。该方法的适应性强且参数数量较少，具有改进现有注意力框架的潜力。

    

    我们提出了多头高斯自适应注意力机制（GAAM），一种新颖的概率注意力框架，并设计了高斯自适应变压器（GAT），旨在增强跨多个模态（包括语音、文本和视觉）的信息聚合。GAAM将可学习的均值和方差融入其注意力机制中，采用多头框架实现，使其能够集体建模任何概率分布，以动态重新调整特征重要性。该方法在处理高度非平稳数据时表现出显著改进，通过识别特征空间中的关键元素，超越了现有的注意力技术在模型性能上的状态（精度增加约20%）。GAAM与基于点积的注意力模型兼容，并具有相对较低的参数数量，展示了其适应性和提升现有注意力框架的潜力。在实证方面，GAAM表现出卓越的适应性和功效。

    We propose the Multi-Head Gaussian Adaptive Attention Mechanism (GAAM), a novel probabilistic attention framework, and the Gaussian Adaptive Transformer (GAT), designed to enhance information aggregation across multiple modalities, including Speech, Text and Vision. GAAM integrates learnable mean and variance into its attention mechanism, implemented in a Multi-Headed framework enabling it to collectively model any Probability Distribution for dynamic recalibration of feature significance. This method demonstrates significant improvements, especially with highly non-stationary data, surpassing the state-of-the-art attention techniques in model performance (up to approximately +20% in accuracy) by identifying key elements within the feature space. GAAM's compatibility with dot-product-based attention models and relatively low number of parameters showcases its adaptability and potential to boost existing attention frameworks. Empirically, GAAM exhibits superior adaptability and efficacy
    
[^13]: 稳定与可塑性解耦的少样本端到端目标检测微调

    Stability Plasticity Decoupled Fine-tuning For Few-shot end-to-end Object Detection. (arXiv:2401.11140v1 [cs.CV])

    [http://arxiv.org/abs/2401.11140](http://arxiv.org/abs/2401.11140)

    本文提出了一个解耦稳定性和可塑性的新的三阶段微调过程，用于缓解少样本目标检测中的稳定性-可塑性矛盾问题。

    

    少样本目标检测（FSOD）旨在设计能够以尽可能少的标注样本高效适应目标检测器的方法。细调已被证明是一种有效且实用的方法。然而，以往的工作通常采用经典的基础-新颖两阶段微调过程，但忽略了不同模块之间的隐含稳定性-可塑性矛盾。具体而言，重新初始化的随机分类器需要更大的可塑性来适应新颖样本。继承预训练权重的其他模块需要更多的稳定性来保留其与类别无关的知识。常规微调将这两个部分的优化耦合在一起，在FSOD场景下损害了模型的泛化能力。在本文中，我们发现这个问题在端到端目标检测器Sparse R-CNN中尤为突出，因为它具有多分类器的级联结构。我们提出通过引入额外的可塑性分类器微调，采用新的三阶段微调过程来缓解这个矛盾。

    Few-shot object detection(FSOD) aims to design methods to adapt object detectors efficiently with only few annotated samples. Fine-tuning has been shown to be an effective and practical approach. However, previous works often take the classical base-novel two stage fine-tuning procedure but ignore the implicit stability-plasticity contradiction among different modules. Specifically, the random re-initialized classifiers need more plasticity to adapt to novel samples. The other modules inheriting pre-trained weights demand more stability to reserve their class-agnostic knowledge. Regular fine-tuning which couples the optimization of these two parts hurts the model generalization in FSOD scenarios. In this paper, we find that this problem is prominent in the end-to-end object detector Sparse R-CNN for its multi-classifier cascaded architecture. We propose to mitigate this contradiction by a new three-stage fine-tuning procedure by introducing an addtional plasticity classifier fine-tunin
    
[^14]: 将临床实践指南纳入大型语言模型以增强临床决策支持

    Enhancing Large Language Models for Clinical Decision Support by Incorporating Clinical Practice Guidelines. (arXiv:2401.11120v1 [cs.CL])

    [http://arxiv.org/abs/2401.11120](http://arxiv.org/abs/2401.11120)

    该论文研究了将临床实践指南纳入大型语言模型以增强临床决策支持的方法。他们开发了三种方法，并对四个大型语言模型进行了评估，在COVID-19门诊治疗方面取得了较高的性能。

    

    大型语言模型（LLM），搭配临床实践指南（CPGs），可以显著提高临床决策支持（CDS）。然而，将CPGs纳入LLMs的方法并未得到充分研究。我们开发了三种不同的方法将CPGs纳入LLMs：二元决策树（BDT），程序辅助图构建（PAGC），以及思维链少样本提示（CoT-FSP）。为评估所提方法的有效性，我们创建了一组合成患者描述，并对由四个LLMs生成的响应进行自动和人工评估：GPT-4，GPT-3.5 Turbo，LLaMA和PaLM 2。零样本提示（ZSP）被用作基线方法。我们以COVID-19门诊治疗的临床决策支持为案例研究。四个LLMs在增加了CPGs后相对于基线ZSP展现了提高的性能。BDT在自动评估中表现优于CoT-FSP和PAGC。所有提出的方法都表现出了较高的性能。

    Background Large Language Models (LLMs), enhanced with Clinical Practice Guidelines (CPGs), can significantly improve Clinical Decision Support (CDS). However, methods for incorporating CPGs into LLMs are not well studied. Methods We develop three distinct methods for incorporating CPGs into LLMs: Binary Decision Tree (BDT), Program-Aided Graph Construction (PAGC), and Chain-of-Thought-Few-Shot Prompting (CoT-FSP). To evaluate the effectiveness of the proposed methods, we create a set of synthetic patient descriptions and conduct both automatic and human evaluation of the responses generated by four LLMs: GPT-4, GPT-3.5 Turbo, LLaMA, and PaLM 2. Zero-Shot Prompting (ZSP) was used as the baseline method. We focus on CDS for COVID-19 outpatient treatment as the case study. Results All four LLMs exhibit improved performance when enhanced with CPGs compared to the baseline ZSP. BDT outperformed both CoT-FSP and PAGC in automatic evaluation. All of the proposed methods demonstrated high per
    
[^15]: SPAND: 使用网络动态的睡眠预测架构

    SPAND: Sleep Prediction Architecture using Network Dynamics. (arXiv:2401.11113v1 [cs.LG])

    [http://arxiv.org/abs/2401.11113](http://arxiv.org/abs/2401.11113)

    SPAND是一个利用网络动态的睡眠预测架构，可以通过图网络和移动设备数据来预测下一天的睡眠持续时间标签。

    

    睡眠行为对健康有重大影响，对身心健康的指示也非常重要。利用普遍存在的传感器监测和预测睡眠行为，可以帮助管理睡眠并追踪相关健康状况。虽然睡眠行为取决于个体的生理状况，但也受到数字媒体使用、社交网络传染以及周围天气等外部因素的影响。在本研究中，我们提出了SPAND（Sleep Prediction Architecture using Network Dynamics），这是一个利用图网络中的社交传染来预测睡眠行为的系统，并将其与从普遍存在的移动设备和可穿戴设备中提取的生理和手机数据集成，以预测下一天的睡眠持续时间标签。我们的架构通过设计一种注意机制，克服了包含与睡眠行为无关的连接的大规模图形的局限性。广泛的实验评估突显出该系统的性能。

    Sleep behavior significantly impacts health and acts as an indicator of physical and mental well-being. Monitoring and predicting sleep behavior with ubiquitous sensors may therefore assist in both sleep management and tracking of related health conditions. While sleep behavior depends on, and is reflected in the physiology of a person, it is also impacted by external factors such as digital media usage, social network contagion, and the surrounding weather. In this work, we propose SPAND (Sleep Prediction Architecture using Network Dynamics), a system that exploits social contagion in sleep behavior through graph networks and integrates it with physiological and phone data extracted from ubiquitous mobile and wearable devices for predicting next-day sleep labels about sleep duration. Our architecture overcomes the limitations of large-scale graphs containing connections irrelevant to sleep behavior by devising an attention mechanism. The extensive experimental evaluation highlights th
    
[^16]: TypeDance: 通过个性化生成从图像中创建语义排版的标志

    TypeDance: Creating Semantic Typographic Logos from Image through Personalized Generation. (arXiv:2401.11094v1 [cs.AI])

    [http://arxiv.org/abs/2401.11094](http://arxiv.org/abs/2401.11094)

    本论文介绍了一种名为TypeDance的AI辅助工具，通过结合设计理念与生成模型，实现了个性化语义排版标志设计。它利用从上传的图像实例中提取的设计先验知识，支持不同结构粒度上的字体-图像映射，达到多样化的美学设计和灵活的控制。

    

    语义排版的标志将字体和图像融为一体，以代表语义概念，同时保持可读性。传统的方法使用空间组合和形状替换受到几何形状不同的字体和语义之间无缝融合需求的限制。虽然最近的进展使得人工智能生成语义排版成为可能，但端到端的方法排除了设计师的参与，并忽视了个性化设计。本文介绍了一种名为TypeDance的AI辅助工具，它将设计理念与生成模型相结合，用于个性化语义排版标志设计。它利用从上传的图像实例中提取的可组合的设计先验知识，并支持在不同的结构粒度上进行字体-图像映射，实现多样化的美学设计，并具有灵活的控制。此外，我们在TypeDance中实例化了一个全面的设计工作流程，包括构思、选择、生成、评估等。

    Semantic typographic logos harmoniously blend typeface and imagery to represent semantic concepts while maintaining legibility. Conventional methods using spatial composition and shape substitution are hindered by the conflicting requirement for achieving seamless spatial fusion between geometrically dissimilar typefaces and semantics. While recent advances made AI generation of semantic typography possible, the end-to-end approaches exclude designer involvement and disregard personalized design. This paper presents TypeDance, an AI-assisted tool incorporating design rationales with the generative model for personalized semantic typographic logo design. It leverages combinable design priors extracted from uploaded image exemplars and supports type-imagery mapping at various structural granularity, achieving diverse aesthetic designs with flexible control. Additionally, we instantiate a comprehensive design workflow in TypeDance, including ideation, selection, generation, evaluation, an
    
[^17]: FedRKG：一种通过知识图增强实现隐私保护的联邦推荐框架

    FedRKG: A Privacy-preserving Federated Recommendation Framework via Knowledge Graph Enhancement. (arXiv:2401.11089v1 [cs.CR])

    [http://arxiv.org/abs/2401.11089](http://arxiv.org/abs/2401.11089)

    FedRKG是一种隐私保护的联邦推荐框架，通过增强知识图，构建全局知识图并利用关系感知的GNN模型，实现高阶用户-项目交互。

    

    联邦学习（FL）作为一种在推荐系统中通过本地训练模型来保护数据隐私的有希望的方法已经出现。最近，图神经网络（GNN）因其捕捉用户和项目之间高阶交互的能力而在推荐任务中受到了广泛关注。然而，隐私问题阻碍了整个用户-项目图的全局共享。为了解决这个限制，一些方法在图中创建了伪交互项或用户，以弥补每个客户端缺失信息。不幸的是，这些方法引入了随机噪声并引发隐私问题。在本文中，我们提出了一种新颖的联邦推荐系统FedRKG，在服务器上使用公开的项目信息构建和维护全局知识图（KG），从而实现更高阶的用户-项目交互。在客户端，一个关系感知的GNN模型利用多样的KG关系。为了保护本地交互项目和模糊梯度

    Federated Learning (FL) has emerged as a promising approach for preserving data privacy in recommendation systems by training models locally. Recently, Graph Neural Networks (GNN) have gained popularity in recommendation tasks due to their ability to capture high-order interactions between users and items. However, privacy concerns prevent the global sharing of the entire user-item graph. To address this limitation, some methods create pseudo-interacted items or users in the graph to compensate for missing information for each client. Unfortunately, these methods introduce random noise and raise privacy concerns. In this paper, we propose FedRKG, a novel federated recommendation system, where a global knowledge graph (KG) is constructed and maintained on the server using publicly available item information, enabling higher-order user-item interactions. On the client side, a relation-aware GNN model leverages diverse KG relationships. To protect local interaction items and obscure gradi
    
[^18]: 自适应的全局局部表征学习和选择用于跨域面部表情识别

    Adaptive Global-Local Representation Learning and Selection for Cross-Domain Facial Expression Recognition. (arXiv:2401.11085v1 [cs.CV])

    [http://arxiv.org/abs/2401.11085](http://arxiv.org/abs/2401.11085)

    本文提出了一个自适应的全局局部表征学习和选择框架，通过全局局部对抗适应和语义感知伪标签生成来增强域不变和辨别性特征的学习，在推理过程中使用全局局部预测一致性学习以提高分类结果。

    

    由于不同域之间的分布变化，领域变化对于跨域面部表情识别（CD-FER）提出了重大挑战。当前的研究主要集中在通过全局特征适应来学习域不变特征，而忽视了局部特征的可迁移性。此外，这些方法在目标数据集的训练中缺乏辨别式监督，导致目标域中的特征表示恶化。为了解决这些限制，我们提出了一种自适应的全局局部表征学习和选择（AGLRLS）框架。该框架结合了全局局部对抗适应和语义感知伪标签生成，以增强训练过程中域不变和辨别性特征的学习。同时，引入了全局局部预测一致性学习，以提高推理过程中的分类结果。具体而言，该框架包括单独的全局局部对抗学习

    Domain shift poses a significant challenge in Cross-Domain Facial Expression Recognition (CD-FER) due to the distribution variation across different domains. Current works mainly focus on learning domain-invariant features through global feature adaptation, while neglecting the transferability of local features. Additionally, these methods lack discriminative supervision during training on target datasets, resulting in deteriorated feature representation in target domain. To address these limitations, we propose an Adaptive Global-Local Representation Learning and Selection (AGLRLS) framework. The framework incorporates global-local adversarial adaptation and semantic-aware pseudo label generation to enhance the learning of domain-invariant and discriminative feature during training. Meanwhile, a global-local prediction consistency learning is introduced to improve classification results during inference. Specifically, the framework consists of separate global-local adversarial learnin
    
[^19]: 从聚合响应中学习：实例级别与包级别的损失函数比较

    Learning from Aggregate responses: Instance Level versus Bag Level Loss Functions. (arXiv:2401.11081v1 [cs.LG])

    [http://arxiv.org/abs/2401.11081](http://arxiv.org/abs/2401.11081)

    本文研究了从聚合响应中学习的两种损失函数：包级别损失和实例级别损失，并发现实例级别损失可以被视为包级别损失的正则化形式。

    

    由于隐私问题的增加，在许多实际应用中，训练数据在与学习者共享之前会被聚合起来，以保护用户敏感响应的隐私。在聚合学习框架中，数据集被分组成样本的包，每个包只提供一个聚合响应，提供了该包中个体响应的摘要。本文研究了从聚合响应中学习的两种自然损失函数：包级别损失和实例级别损失。在前者中，模型通过最小化聚合响应与聚合模型预测之间的损失来学习，而在后者中，模型旨在将个体预测与聚合响应拟合。在这项工作中，我们表明实例级别损失可以被视为包级别损失的正则化形式。这个观察让我们能够比较这两种方法关于所得估计值的偏差和方差，并引入了一种新的插值。

    Due to the rise of privacy concerns, in many practical applications the training data is aggregated before being shared with the learner, in order to protect privacy of users' sensitive responses. In an aggregate learning framework, the dataset is grouped into bags of samples, where each bag is available only with an aggregate response, providing a summary of individuals' responses in that bag. In this paper, we study two natural loss functions for learning from aggregate responses: bag-level loss and the instance-level loss. In the former, the model is learnt by minimizing a loss between aggregate responses and aggregate model predictions, while in the latter the model aims to fit individual predictions to the aggregate responses. In this work, we show that the instance-level loss can be perceived as a regularized form of the bag-level loss. This observation lets us compare the two approaches with respect to bias and variance of the resulting estimators, and introduce a novel interpol
    
[^20]: PhotoBot：通过自然语言引导的参考互动摄影

    PhotoBot: Reference-Guided Interactive Photography via Natural Language. (arXiv:2401.11061v1 [cs.CV])

    [http://arxiv.org/abs/2401.11061](http://arxiv.org/abs/2401.11061)

    PhotoBot是一个通过自然语言引导和机器人摄影师相互作用的自动化照片获取框架。它利用视觉语言模型和物体检测器来提供摄影建议，并通过视觉变换器计算相机的姿态调整，从而实现高质量的照片获取。

    

    我们介绍了一个名为PhotoBot的框架，它基于高级人类语言引导和机器人摄影师之间的相互作用，用于自动化的照片获取。我们建议通过从策展画廊中检索到的参考图片向用户传达摄影建议。我们利用视觉语言模型（VLM）和物体检测器，通过文本描述对参考图片进行特征化，并使用大型语言模型（LLM）通过基于用户语言查询的文本推理检索相关的参考图片。为了对应参考图片和观察到的场景，我们利用一个能够捕捉显著不同的图像的语义相似性的预训练特征的视觉变换器，通过解决一个透视n-点（PnP）问题来计算RGB-D相机的姿态调整。我们在配备有手腕相机的真实机械手臂上演示了我们的方法。我们的用户研究表明，由PhotoBot拍摄的照片具有良好的质量和效果。

    We introduce PhotoBot, a framework for automated photo acquisition based on an interplay between high-level human language guidance and a robot photographer. We propose to communicate photography suggestions to the user via a reference picture that is retrieved from a curated gallery. We exploit a visual language model (VLM) and an object detector to characterize reference pictures via textual descriptions and use a large language model (LLM) to retrieve relevant reference pictures based on a user's language query through text-based reasoning. To correspond the reference picture and the observed scene, we exploit pre-trained features from a vision transformer capable of capturing semantic similarity across significantly varying images. Using these features, we compute pose adjustments for an RGB-D camera by solving a Perspective-n-Point (PnP) problem. We demonstrate our approach on a real-world manipulator equipped with a wrist camera. Our user studies show that photos taken by PhotoBo
    
[^21]: 机器学习分类过程中数据抽象方法在关键决策中的重要性

    The Significance of Data Abstraction Methods in Machine Learning Classification Processes for Critical Decision-Making. (arXiv:2401.11044v1 [cs.LG])

    [http://arxiv.org/abs/2401.11044](http://arxiv.org/abs/2401.11044)

    本文研究了机器学习分类过程中数据抽象方法的重要性，提出了Small and Incomplete Dataset Analyser (SaNDA)采用ROC曲线方法开发的数据抽象协议，该方法在缺少值很少的情况下可以成为随机森林的可行替代品，始终保持高准确性。

    

    广泛采用的机器学习(ML)方法在分类方面的适用性受到了解释能力和不确定性的限制，特别是在医疗保健、行为科学和金融等领域，其中责任问题至关重要。最近，提出了Small and Incomplete Dataset Analyser (SaNDA)，通过使用基于ROC曲线的方法开发数据抽象协议，以增强在这些领域中执行分类的能力。本文关注于列间数据转换，即抽象，这对SaNDA的分类过程非常关键，并探讨了替代的抽象协议，如常量分箱和分位数。将最佳的方法与可解释方法的基准模型随机森林进行了比较。结果表明，即使数据不完整，SaNDA在缺少值很少的情况下仍然可以成为随机森林的可行替代品，并且始终保持高准确性。

    The applicability of widely adopted machine learning (ML) methods to classification is circumscribed by the imperatives of explicability and uncertainty, particularly evident in domains such as healthcare, behavioural sciences, and finances, wherein accountability assumes priority. Recently, Small and Incomplete Dataset Analyser (SaNDA) has been proposed to enhance the ability to perform classification in such domains, by developing a data abstraction protocol using a ROC curve-based method. This paper focuses on column-wise data transformations called abstractions, which are crucial for SaNDA's classification process and explores alternative abstractions protocols, such as constant binning and quantiles. The best-performing methods have been compared against Random Forest as a baseline for explainable methods. The results suggests that SaNDA can be a viable substitute for Random Forest when data is incomplete, even with minimal missing values. It consistently maintains high accuracy e
    
[^22]: 基于Transformer深度学习的多语言仇恨言论分析和检测

    Analysis and Detection of Multilingual Hate Speech Using Transformer Based Deep Learning. (arXiv:2401.11021v1 [cs.CL])

    [http://arxiv.org/abs/2401.11021](http://arxiv.org/abs/2401.11021)

    提出了一种基于Transformer模型的方法来检测社交媒体上的多语言仇恨言论。该模型在意大利语、英语、德语和孟加拉语上进行了测试，并取得了比现有模型更高的成功率。

    

    仇恨言论是直接攻击或宣传针对特定群体或个人的憎恨的有害内容，例如种族主义、宗教或性取向等。这会对社交媒体平台上的社会生活产生影响，因为通过社交媒体分享的仇恨内容可能会对个人和社区造成伤害。随着网络上仇恨言论的增加，自动化检测作为自然语言处理的一个任务的需求也在增加。在这项工作中，提出了一种使用基于Transformer模型在社交媒体上检测仇恨言论的方法，如Twitter、Facebook、WhatsApp、Instagram等。该模型独立于语言，并已在意大利语、英语、德语、孟加拉语上进行了测试。黄金标准数据集由知名研究者Zeerak Talat、Sara Tonelli、Melanie Siegel和Rezaul Karim收集。所提出模型在仇恨言论检测方面的成功率高于现有基准和最先进模型，准确率较高。

    Hate speech is harmful content that directly attacks or promotes hatred against members of groups or individuals based on actual or perceived aspects of identity, such as racism, religion, or sexual orientation. This can affect social life on social media platforms as hateful content shared through social media can harm both individuals and communities. As the prevalence of hate speech increases online, the demand for automated detection as an NLP task is increasing. In this work, the proposed method is using transformer-based model to detect hate speech in social media, like twitter, Facebook, WhatsApp, Instagram, etc. The proposed model is independent of languages and has been tested on Italian, English, German, Bengali. The Gold standard datasets were collected from renowned researcher Zeerak Talat, Sara Tonelli, Melanie Siegel, and Rezaul Karim. The success rate of the proposed model for hate speech detection is higher than the existing baseline and state-of-the-art models with acc
    
[^23]: 快速注册逼真的虚拟现实头像用于面部动画

    Fast Registration of Photorealistic Avatars for VR Facial Animation. (arXiv:2401.11002v1 [cs.CV])

    [http://arxiv.org/abs/2401.11002](http://arxiv.org/abs/2401.11002)

    本论文针对虚拟现实头像注册和面部动画问题，发现头像和头显相机图像之间的领域差距是主要难点，并提出了一个系统设计来解决这个问题。

    

    虚拟现实（VR）在社交互动方面拥有更具沉浸感的潜力。其中一个关键是能够在佩戴VR头显的情况下准确地模拟一个逼真的头像。虽然在离线环境中可以实现对特定个人头像进行高质量注册，并进行动画生成，但通用实时模型的性能明显下降。在线注册也面临诸多挑战，包括倾斜的摄像机视角和不同的模态。在这项工作中，我们首先表明头像与头显相机图像之间的领域差距是困难的主要源泉之一，基于转换器的架构在领域一致的数据上实现了高准确性，在引入领域差距后性能下降。基于此发现，我们提出了一个系统设计，将问题分解为两个部分：1）一个迭代细化模块，接收领域内输入，和2）一个通用的头像引导图像生成模块

    Virtual Reality (VR) bares promise of social interactions that can feel more immersive than other media. Key to this is the ability to accurately animate a photorealistic avatar of one's likeness while wearing a VR headset. Although high quality registration of person-specific avatars to headset-mounted camera (HMC) images is possible in an offline setting, the performance of generic realtime models are significantly degraded. Online registration is also challenging due to oblique camera views and differences in modality. In this work, we first show that the domain gap between the avatar and headset-camera images is one of the primary sources of difficulty, where a transformer-based architecture achieves high accuracy on domain-consistent data, but degrades when the domain-gap is re-introduced. Building on this finding, we develop a system design that decouples the problem into two parts: 1) an iterative refinement module that takes in-domain inputs, and 2) a generic avatar-guided imag
    
[^24]: MacroSwarm: 一种基于场的组合框架用于群体编程

    MacroSwarm: A Field-based Compositional Framework for Swarm Programming. (arXiv:2401.10969v1 [cs.AI])

    [http://arxiv.org/abs/2401.10969](http://arxiv.org/abs/2401.10969)

    MacroSwarm是一种基于场的群体编程框架，通过可组合的功能模块实现复杂的群体行为，通过将感知场映射为执行目标场，提供了一种系统化的设计和实现群体行为的方法。

    

    群体行为工程是一项旨在研究协调简单智能体团体内计算和行动的方法和技术，以实现复杂的全局目标，如图案形成、集体移动、聚类和分布式感知。尽管在群体（无人机、机器人、车辆）分析和工程方面取得了一些进展，但仍然需要通用的设计和实现方法和工具，以系统化的方式定义复杂的群体行为。为了对此做出贡献，本文提出了一种新的基于场的协调方法，称为MacroSwarm，以可重用且完全可组合的功能模块为基础，嵌入集体计算和协调。基于集成计算的宏编程范式，MacroSwarm提出了将每个群体行为块表示为将感知场映射为执行目标场的纯函数的思路。

    Swarm behaviour engineering is an area of research that seeks to investigate methods and techniques for coordinating computation and action within groups of simple agents to achieve complex global goals like pattern formation, collective movement, clustering, and distributed sensing. Despite recent progress in the analysis and engineering of swarms (of drones, robots, vehicles), there is still a need for general design and implementation methods and tools that can be used to define complex swarm behaviour in a principled way. To contribute to this quest, this article proposes a new field-based coordination approach, called MacroSwarm, to design and program swarm behaviour in terms of reusable and fully composable functional blocks embedding collective computation and coordination. Based on the macroprogramming paradigm of aggregate computing, MacroSwarm builds on the idea of expressing each swarm behaviour block as a pure function mapping sensing fields into actuation goal fields, e.g.
    
[^25]: 分散协调下开放车队的可扩展和动态任务分配

    Decentralizing Coordination in Open Vehicle Fleets for Scalable and Dynamic Task Allocation. (arXiv:2401.10965v1 [cs.MA])

    [http://arxiv.org/abs/2401.10965](http://arxiv.org/abs/2401.10965)

    本文研究了在分散协调环境下开放车队的可扩展和动态任务分配，提出了多代理系统的表示方法，并对最近的研究结果进行了比较和批判性分析。同时，提出了数学模型来解决动态分配问题。

    

    大规模、开放、协作和商业车队的协调中一个主要的挑战是动态任务分配。具有自我关注的个体理性车辆驾驶员有着本地和全局的目标，需要通过公平和高效的任务分配方法进行协调。本文主要研究可扩展和动态任务分配的文献，重点关注确定性和动态二维线性分配问题。我们将重点放在开放车队的多代理系统表示上，其中动态出现的车辆由软件代理表示，应分配到一组动态出现的任务。我们对最近的研究结果进行比较和批判性分析，着重关注集中式、分布式和分散式解决方法。此外，我们提出了数学模型，用于组合优化中众所周知的以下动态版本的分配问题：分配问题、瓶颈问题

    One of the major challenges in the coordination of large, open, collaborative, and commercial vehicle fleets is dynamic task allocation. Self-concerned individually rational vehicle drivers have both local and global objectives, which require coordination using some fair and efficient task allocation method. In this paper, we review the literature on scalable and dynamic task allocation focusing on deterministic and dynamic two-dimensional linear assignment problems. We focus on multiagent system representation of open vehicle fleets where dynamically appearing vehicles are represented by software agents that should be allocated to a set of dynamically appearing tasks. We give a comparison and critical analysis of recent research results focusing on centralized, distributed, and decentralized solution approaches. Moreover, we propose mathematical models for dynamic versions of the following assignment problems well known in combinatorial optimization: the assignment problem, bottleneck
    
[^26]: Chat Bot上的AI革命：一项随机对照实验的证据

    AI Revolution on Chat Bot: Evidence from a Randomized Controlled Experiment. (arXiv:2401.10956v1 [cs.HC])

    [http://arxiv.org/abs/2401.10956](http://arxiv.org/abs/2401.10956)

    本文通过一项现场随机对照试验研究了LLM工具在提供无监督信息检索支持服务方面的效果。

    

    近年来，生成式人工智能（generative AI）取得了重大进展，展示出显著的提升人类生产力的潜力。特别是，大型语言模型（LLM），以ChatGPT-4为例，引起了极大关注。许多文章已经研究了LLM工具在实验室环境下和设计任务或观察性研究中对人类生产力的影响。尽管最近取得了进展，但在实际环境中应用LLM工具的现场实验仍然有限。本文介绍了一项现场随机对照试验的研究结果，评估了LLM工具在提供无监督信息检索支持服务方面的有效性。

    In recent years, generative AI has undergone major advancements, demonstrating significant promise in augmenting human productivity. Notably, large language models (LLM), with ChatGPT-4 as an example, have drawn considerable attention. Numerous articles have examined the impact of LLM-based tools on human productivity in lab settings and designed tasks or in observational studies. Despite recent advances, field experiments applying LLM-based tools in realistic settings are limited. This paper presents the findings of a field randomized controlled trial assessing the effectiveness of LLM-based tools in providing unmonitored support services for information retrieval.
    
[^27]: 自我上下文感知下的人机交互情绪识别

    Self context-aware emotion perception on human-robot interaction. (arXiv:2401.10946v1 [cs.HC])

    [http://arxiv.org/abs/2401.10946](http://arxiv.org/abs/2401.10946)

    本论文提出了一种自我上下文感知模型（SCAM）用于人机交互中的情绪识别，在音频、视频和多模态方面取得了显著的改进，提高了准确率。

    

    情绪识别在人机交互的各个领域中起着至关重要的作用。在与人类的长期交互中，机器人需要持续准确地做出反应，然而，主流的情绪识别方法大多关注短期情绪识别，忽视了情绪感知的上下文。人们认为上下文信息和不同的背景可以导致完全不同的情绪表达。本文介绍了一种自我上下文感知模型（SCAM），它采用二维情绪坐标系统来锚定和重新标记不同的情绪。同时，它还融合了独特的信息保留结构和上下文损失。该方法在音频、视频和多模态方面都取得了显著的改进。在听觉模态下，准确率明显提高，从63.10%提升到72.46%。同样，视觉模态也表现出了提高的准确率，增加了...

    Emotion recognition plays a crucial role in various domains of human-robot interaction. In long-term interactions with humans, robots need to respond continuously and accurately, however, the mainstream emotion recognition methods mostly focus on short-term emotion recognition, disregarding the context in which emotions are perceived. Humans consider that contextual information and different contexts can lead to completely different emotional expressions. In this paper, we introduce self context-aware model (SCAM) that employs a two-dimensional emotion coordinate system for anchoring and re-labeling distinct emotions. Simultaneously, it incorporates its distinctive information retention structure and contextual loss. This approach has yielded significant improvements across audio, video, and multimodal. In the auditory modality, there has been a notable enhancement in accuracy, rising from 63.10% to 72.46%. Similarly, the visual modality has demonstrated improved accuracy, increasing f
    
[^28]: 机器反学习在推荐系统中的应用：一种洞察力

    Machine Unlearning for Recommendation Systems: An Insight. (arXiv:2401.10942v1 [cs.IR])

    [http://arxiv.org/abs/2401.10942](http://arxiv.org/abs/2401.10942)

    本文探讨了机器反学习在推荐系统中的应用，解决了适应性、个性化、隐私和偏见等挑战。与传统模型不同，MUL根据用户偏好的变化和伦理考虑动态调整系统知识。通过批判性检验和文献梳理，本文提供了MUL如何改变推荐、用户信任以及未来研究路径的见解。强调个性化和隐私之间的权衡挑战，并鼓励以满足实际需求为目标的贡献，推动MUL在安全和适应性机器学习中的发展。

    

    本综述探讨了推荐系统中的机器反学习（MUL），解决了适应性、个性化、隐私和偏见等挑战。与传统模型不同，MUL根据用户偏好的变化和伦理考虑动态调整系统知识。本文对MUL的基本原理、现实世界应用和算法透明性等挑战进行了批判性的检验。它梳理了相关文献，提供了MUL如何改变推荐的见解，探讨了用户信任，并提出了未来研究在负责任和用户关注的人工智能领域的路径。本文引导研究人员面对个性化和隐私之间的权衡挑战，鼓励以满足有针对性的数据删除实际需求为目标的贡献。强调MUL在安全和适应性机器学习中的作用，提出了推动其边界的方法。本文的创新之处在于探讨了这些方法的局限性。

    This review explores machine unlearning (MUL) in recommendation systems, addressing adaptability, personalization, privacy, and bias challenges. Unlike traditional models, MUL dynamically adjusts system knowledge based on shifts in user preferences and ethical considerations. The paper critically examines MUL's basics, real-world applications, and challenges like algorithmic transparency. It sifts through literature, offering insights into how MUL could transform recommendations, discussing user trust, and suggesting paths for future research in responsible and user-focused artificial intelligence (AI). The document guides researchers through challenges involving the trade-off between personalization and privacy, encouraging contributions to meet practical demands for targeted data removal. Emphasizing MUL's role in secure and adaptive machine learning, the paper proposes ways to push its boundaries. The novelty of this paper lies in its exploration of the limitations of the methods, w
    
[^29]: 即使解释：形式基础，优先级和复杂性

    Even-if Explanations: Formal Foundations, Priorities and Complexity. (arXiv:2401.10938v1 [cs.AI])

    [http://arxiv.org/abs/2401.10938](http://arxiv.org/abs/2401.10938)

    本论文研究了解释性人工智能中的局部事后解释性查询，特别关注半事实的解释，并对线性模型和基于树的模型与神经网络的解释能力进行了比较。此外，提出了一种基于偏好的框架，允许用户根据自己的首选项个性化解释。最后，探讨了模型复杂度的问题。

    

    解释性人工智能近年来受到了重要关注。机器学习模型通常作为黑盒子运行，缺乏解释和透明性，而又支持决策过程。局部事后解释性查询试图回答为什么给定模型如何对个体输入进行分类的问题。虽然关于反事实解释已经进行了重要工作，但对半事实解释的关注较少。本文关注于半事实的局部事后解释性查询以及不同模型类别中其计算复杂性，并表明线性和基于树的模型比神经网络更易于解释。接着，我们介绍了一种基于偏好的框架，使用户能够根据自己的偏好个性化解释，无论是在半事实还是反事实的情况下，提高解释能力和用户中心性。最后，我们探讨了模型复杂度。

    EXplainable AI has received significant attention in recent years. Machine learning models often operate as black boxes, lacking explainability and transparency while supporting decision-making processes. Local post-hoc explainability queries attempt to answer why individual inputs are classified in a certain way by a given model. While there has been important work on counterfactual explanations, less attention has been devoted to semifactual ones. In this paper, we focus on local post-hoc explainability queries within the semifactual `even-if' thinking and their computational complexity among different classes of models, and show that both linear and tree-based models are strictly more interpretable than neural networks. After this, we introduce a preference-based framework that enables users to personalize explanations based on their preferences, both in the case of semifactuals and counterfactuals, enhancing interpretability and user-centricity. Finally, we explore the complexity o
    
[^30]: 主观因果关系

    Subjective Causality. (arXiv:2401.10937v1 [econ.TH])

    [http://arxiv.org/abs/2401.10937](http://arxiv.org/abs/2401.10937)

    本研究通过观察决策者对干预行为的偏好，展示了理解和识别决策者主观因果判断的可能性，为模型测试决策者偏好一致性提供了方法。

    

    我们通过观察决策者对干预行为的偏好，展示了理解和识别决策者主观因果判断的可能性。根据Pearl [2000]的方法，我们使用因果模型（也称为结构方程模型）来表示因果关系，其中世界由一组变量组成，这些变量之间通过方程相关联。我们展示了如果干预行为的偏好关系满足某些公理（与反事实相关的标准公理），那么我们可以定义（i）一个因果模型，（ii）反映决策者对外部因素不确定性的概率，以及（iii）与每个干预行为相关联的效用，每个干预行为都有一个预期效用，并且干预行为A优于B当且仅当A的预期效用大于B的预期效用。此外，我们还对因果模型的唯一性进行了刻画。因此，我们的结果允许建模者测试一个假设，即决策者的偏好是否一致。

    We show that it is possible to understand and identify a decision maker's subjective causal judgements by observing her preferences over interventions. Following Pearl [2000], we represent causality using causal models (also called structural equations models), where the world is described by a collection of variables, related by equations. We show that if a preference relation over interventions satisfies certain axioms (related to standard axioms regarding counterfactuals), then we can define (i) a causal model, (ii) a probability capturing the decision-maker's uncertainty regarding the external factors in the world and (iii) a utility on outcomes such that each intervention is associated with an expected utility and such that intervention $A$ is preferred to $B$ iff the expected utility of $A$ is greater than that of $B$. In addition, we characterize when the causal model is unique. Thus, our results allow a modeler to test the hypothesis that a decision maker's preferences are cons
    
[^31]: SeeClick：利用GUI Grounding实现高级可视化GUI代理

    SeeClick: Harnessing GUI Grounding for Advanced Visual GUI Agents. (arXiv:2401.10935v1 [cs.HC])

    [http://arxiv.org/abs/2401.10935](http://arxiv.org/abs/2401.10935)

    SeeClick是一种基于屏幕截图的视觉GUI代理，通过GUI grounding预训练和自动化数据生成，实现了在复杂任务自动化中准确定位屏幕元素，并创建了全面覆盖移动、桌面和Web环境的GUI grounding数据集ScreenSpot。

    

    图形用户界面(GUI)代理被设计用于自动化数字设备上的复杂任务，如智能手机和桌面电脑。大多数现有的GUI代理通过提取的结构化数据与环境进行交互，这些数据可能特别冗长（例如HTML）且有时无法访问（例如在桌面上）。为了解决这个问题，我们提出了一种基于屏幕截图进行任务自动化的视觉GUI代理--SeeClick。在我们的初步研究中，我们发现了开发视觉GUI代理的一个关键挑战：GUI grounding - 根据指令准确定位屏幕元素的能力。为了解决这个挑战，我们提出了用GUI grounding预训练来增强SeeClick，并设计了一种自动化GUI grounding数据的方法。除了以上工作，我们还创建了ScreenSpot，第一个涵盖移动、桌面和Web环境的真实GUI grounding数据集。经过预训练，SeeClick展示了显著的改进。

    Graphical User Interface (GUI) agents are designed to automate complex tasks on digital devices, such as smartphones and desktops. Most existing GUI agents interact with the environment through extracted structured data, which can be notably lengthy (e.g., HTML) and occasionally inaccessible (e.g., on desktops). To alleviate this issue, we propose a visual GUI agent -- SeeClick, which only relies on screenshots for task automation. In our preliminary study, we have discovered a key challenge in developing visual GUI agents: GUI grounding -the capacity to accurately locate screen elements based on instructions. To tackle this challenge, we propose to enhance SeeClick with GUI grounding pre-training and devise a method to automate the curation of GUI grounding data. Along with the efforts above, we have also created ScreenSpot, the first realistic GUI grounding dataset that encompasses mobile, desktop, and web environments. After pre-training, SeeClick demonstrates significant improvem
    
[^32]: 一个新的创意生成流程用于点击率稳定扩散模型

    A New Creative Generation Pipeline for Click-Through Rate with Stable Diffusion Model. (arXiv:2401.10934v1 [cs.IR])

    [http://arxiv.org/abs/2401.10934](http://arxiv.org/abs/2401.10934)

    基于用户信息和艺术设计的新的创意生成流程，通过融合用户信息和考虑用户特征来预测CTR分数，提供更具吸引力的创意设计。

    

    在在线广告的场景中，销售商通常会创建多个创意以提供全面的演示，因此呈现出最吸引人的设计以最大化点击率（CTR）至关重要。然而，销售商通常难以考虑用户对创意设计的偏好，导致相对于基于人工智能（AI）的方法来说，美学和数量都较低。传统的基于AI的方法仍然面临同样的问题，即没有考虑用户信息，同时在设计师的美学知识方面有限。事实上，通过融合用户信息，生成的创意可能更具吸引力，因为不同的用户可能有不同的偏好。为了优化结果，传统方法中生成的创意会通过另一个被称为创意排名模型的模块进行排序。排名模型可以考虑用户特征来预测每个创意的CTR分数。然而，上述的两个阶段被视为两个不同的训练任务，使得生成的创意可能不够精准。

    In online advertising scenario, sellers often create multiple creatives to provide comprehensive demonstrations, making it essential to present the most appealing design to maximize the Click-Through Rate (CTR). However, sellers generally struggle to consider users preferences for creative design, leading to the relatively lower aesthetics and quantities compared to Artificial Intelligence (AI)-based approaches. Traditional AI-based approaches still face the same problem of not considering user information while having limited aesthetic knowledge from designers. In fact that fusing the user information, the generated creatives can be more attractive because different users may have different preferences. To optimize the results, the generated creatives in traditional methods are then ranked by another module named creative ranking model. The ranking model can predict the CTR score for each creative considering user features. However, the two above stages are regarded as two different t
    
[^33]: 人工智能实现科学文献系统综述的自动化

    Artificial intelligence to automate the systematic review of scientific literature. (arXiv:2401.10917v1 [cs.IR])

    [http://arxiv.org/abs/2401.10917](http://arxiv.org/abs/2401.10917)

    本论文介绍了一项调查研究，研究了使用人工智能实现科学文献系统综述的自动化方法。

    

    人工智能（AI）在现代计算中变得非常重要，因为它可以有效地解决人们传统上完成的复杂任务。AI提供了表示和推理知识、高效地处理文本和从大量数据中学习的方法。这些特点适用于许多人类找到费力或重复的活动，比如科学文献的分析。手动准备和撰写系统文献综述（SLR）需要相当长的时间和努力，因为它需要策划一个策略，进行文献搜索和分析，并报告结果。根据研究领域的不同，检索到的论文数量可能达到数百或数千篇，这意味着过滤出相关文献并提取关键信息是一个昂贵且容易出错的过程。然而，一些涉及的任务是重复的，因此可以通过AI自动化。在本文中，我们提出了一项调查研究

    Artificial intelligence (AI) has acquired notorious relevance in modern computing as it effectively solves complex tasks traditionally done by humans. AI provides methods to represent and infer knowledge, efficiently manipulate texts and learn from vast amount of data. These characteristics are applicable in many activities that human find laborious or repetitive, as is the case of the analysis of scientific literature. Manually preparing and writing a systematic literature review (SLR) takes considerable time and effort, since it requires planning a strategy, conducting the literature search and analysis, and reporting the findings. Depending on the area under study, the number of papers retrieved can be of hundreds or thousands, meaning that filtering those relevant ones and extracting the key information becomes a costly and error-prone process. However, some of the involved tasks are repetitive and, therefore, subject to automation by means of AI. In this paper, we present a survey
    
[^34]: 元认知是你所需要的吗？在生成式智能体中使用内省以提高目标导向行为

    Metacognition is all you need? Using Introspection in Generative Agents to Improve Goal-directed Behavior. (arXiv:2401.10910v1 [q-bio.NC])

    [http://arxiv.org/abs/2401.10910](http://arxiv.org/abs/2401.10910)

    本文介绍了一个使用内省的元认知模块，可以让生成式智能体观察自己的思考过程和行动，并通过修改策略来显著提高性能。通过在多种场景下测试，我们观察到该系统在与其他系统的比较中取得了优势，智能体能够适应和改进策略以完成任务。

    

    最近大型语言模型（LLMs）的进展在各种应用中展示了令人印象深刻的能力，然而LLMs面临着有限的上下文窗口和泛化困难等挑战。在本文中，我们引入了一个元认知模块用于生成式智能体，使其能够观察自己的思考过程和行动。这种元认知方法旨在模拟系统1和系统2的认知过程，使智能体能够通过修改策略显著提高性能。我们在各种场景下测试了元认知模块，包括生成式智能体必须在僵尸启示录中存活的情况，并观察到我们的系统在表现上超过其他系统，同时智能体能够随着时间适应和改进策略以完成任务。

    Recent advances in Large Language Models (LLMs) have shown impressive capabilities in various applications, yet LLMs face challenges such as limited context windows and difficulties in generalization. In this paper, we introduce a metacognition module for generative agents, enabling them to observe their own thought processes and actions. This metacognitive approach, designed to emulate System 1 and System 2 cognitive processes, allows agents to significantly enhance their performance by modifying their strategy. We tested the metacognition module on a variety of scenarios, including a situation where generative agents must survive a zombie apocalypse, and observe that our system outperform others, while agents adapt and improve their strategies to complete tasks over time.
    
[^35]: 通过探索神经科学和认知心理学的发现来寻求人工通用智能的启示的综述

    A Review of Findings from Neuroscience and Cognitive Psychology as Possible Inspiration for the Path to Artificial General Intelligence. (arXiv:2401.10904v1 [cs.AI])

    [http://arxiv.org/abs/2401.10904](http://arxiv.org/abs/2401.10904)

    这项综述通过探索神经科学和认知心理学的发现，旨在为人工通用智能的发展提供启示，以克服深度学习模型在抽象推理和因果理解方面的局限性。

    

    本综述旨在通过审视神经科学和认知心理学的方法，为人工通用智能的追求做出贡献。深度学习模型在各个领域取得了令人印象深刻的进展，但它们在抽象推理和因果理解方面仍然存在局限性。最终应将这些能力纳入人工智能系统中，以超越数据驱动的限制，并支持决策过程更类似于人类智能的方式。本研究是一项垂直综述，试图广泛探讨大脑功能，从低层生物神经元、脉冲神经网络和神经元集合到更高层面的概念，如脑解剖学、向量符号架构、认知和分类模型以及认知架构。希望这些概念能够为人工通用智能的解决方案提供启示。

    This review aims to contribute to the quest for artificial general intelligence by examining neuroscience and cognitive psychology methods for potential inspiration. Despite the impressive advancements achieved by deep learning models in various domains, they still have shortcomings in abstract reasoning and causal understanding. Such capabilities should be ultimately integrated into artificial intelligence systems in order to surpass data-driven limitations and support decision making in a way more similar to human intelligence. This work is a vertical review that attempts a wide-ranging exploration of brain function, spanning from lower-level biological neurons, spiking neural networks, and neuronal ensembles to higher-level concepts such as brain anatomy, vector symbolic architectures, cognitive and categorization models, and cognitive architectures. The hope is that these concepts may offer insights for solutions in artificial general intelligence.
    
[^36]: 重新审视人工智能安全中的具体问题

    Concrete Problems in AI Safety, Revisited. (arXiv:2401.10899v1 [cs.CY])

    [http://arxiv.org/abs/2401.10899](http://arxiv.org/abs/2401.10899)

    通过分析真实案例，本研究重新审视了人工智能安全中的具体问题，并指出为了更好地理解人工智能系统在现实生活中的故障和成功，需要扩展社会技术框架。

    

    随着人工智能系统在社会中的普及，人工智能社区越来越关注人工智能安全的概念，即在人工智能部署中，防止由于系统行为与设计者意图的意外偏离而导致故障。通过对此类事件的真实案例进行分析，我们证明尽管当前的术语涵盖了人工智能部署所遇到的各种问题，但为了更全面地理解人工智能系统和实施的安全机制在现实生活中的失败和成功，需要进行一个扩展的社会技术框架。

    As AI systems proliferate in society, the AI community is increasingly preoccupied with the concept of AI Safety, namely the prevention of failures due to accidents that arise from an unanticipated departure of a system's behavior from designer intent in AI deployment. We demonstrate through an analysis of real world cases of such incidents that although current vocabulary captures a range of the encountered issues of AI deployment, an expanded socio-technical framing will be required for a more complete understanding of how AI systems and implemented safety mechanisms fail and succeed in real life.
    
[^37]: PuriDefense：用于防御黑盒基于查询的攻击的随机局部隐式对抗净化

    PuriDefense: Randomized Local Implicit Adversarial Purification for Defending Black-box Query-based Attacks. (arXiv:2401.10586v1 [cs.CR])

    [http://arxiv.org/abs/2401.10586](http://arxiv.org/abs/2401.10586)

    PuriDefense是一种高效的防御机制，通过使用轻量级净化模型进行随机路径净化，减缓基于查询的攻击的收敛速度，并有效防御黑盒基于查询的攻击。

    

    黑盒基于查询的攻击对机器学习作为服务系统构成重大威胁，因为它们可以生成对抗样本而不需要访问目标模型的架构和参数。传统的防御机制，如对抗训练、梯度掩盖和输入转换，要么带来巨大的计算成本，要么损害非对抗输入的测试准确性。为了应对这些挑战，我们提出了一种高效的防御机制PuriDefense，在低推理成本的级别上使用轻量级净化模型的随机路径净化。这些模型利用局部隐式函数并重建自然图像流形。我们的理论分析表明，这种方法通过将随机性纳入净化过程来减缓基于查询的攻击的收敛速度。对CIFAR-10和ImageNet的大量实验验证了我们提出的净化器防御的有效性。

    Black-box query-based attacks constitute significant threats to Machine Learning as a Service (MLaaS) systems since they can generate adversarial examples without accessing the target model's architecture and parameters. Traditional defense mechanisms, such as adversarial training, gradient masking, and input transformations, either impose substantial computational costs or compromise the test accuracy of non-adversarial inputs. To address these challenges, we propose an efficient defense mechanism, PuriDefense, that employs random patch-wise purifications with an ensemble of lightweight purification models at a low level of inference cost. These models leverage the local implicit function and rebuild the natural image manifold. Our theoretical analysis suggests that this approach slows down the convergence of query-based attacks by incorporating randomness into purifications. Extensive experiments on CIFAR-10 and ImageNet validate the effectiveness of our proposed purifier-based defen
    
[^38]: 自然的功率法则学习环境中能够减轻灾难性干扰

    Catastrophic Interference is Mitigated in Naturalistic Power-Law Learning Environments. (arXiv:2401.10393v1 [cs.LG])

    [http://arxiv.org/abs/2401.10393](http://arxiv.org/abs/2401.10393)

    本研究在自然学习环境中通过回忆方法减轻了灾难性干扰，该方法受到功率法则的启发。

    

    神经网络通常遭受灾难性干扰（CI）：在学习新任务时，先前学习任务的表现显著下降。这与人类形成鲜明对比，人类可以连续学习新任务而不会明显忘记先前的任务。先前的工作已经探索了各种减轻CI的技术，例如正则化、回忆、生成性回放和浓缩方法。本研究采用了一种不同的方法，该方法受到认知科学研究的指导，该研究表明在自然环境中，遇到任务的概率与最后一次执行任务的时间成功率法则递减。我们认为，在模拟自然学习环境中进行减轻CI技术的真实评估是必要的。因此，我们评估了在类似人类面临的功率法则环境中训练简单的回忆方法时，CI的减轻程度。我们的工作探索了这种基于回忆的新方法。

    Neural networks often suffer from catastrophic interference (CI): performance on previously learned tasks drops off significantly when learning a new task. This contrasts strongly with humans, who can sequentially learn new tasks without appreciably forgetting previous tasks. Prior work has explored various techniques for mitigating CI such as regularization, rehearsal, generative replay, and distillation methods. The current work takes a different approach, one guided by cognitive science research showing that in naturalistic environments, the probability of encountering a task decreases as a power-law of the time since it was last performed. We argue that a realistic evaluation of techniques for the mitigation of CI should be performed in simulated naturalistic learning environments. Thus, we evaluate the extent of mitigation of CI when training simple rehearsal-based methods in power-law environments similar to the ones humans face. Our work explores this novel rehearsal-based appro
    
[^39]: 基于噪声对比估计的低资源安全攻击模式识别匹配框架

    Noise Contrastive Estimation-based Matching Framework for Low-resource Security Attack Pattern Recognition. (arXiv:2401.10337v1 [cs.LG])

    [http://arxiv.org/abs/2401.10337](http://arxiv.org/abs/2401.10337)

    该论文提出了一种基于噪声对比估计的低资源安全攻击模式识别匹配框架，通过直接语义相似度决定文本与攻击模式之间的关联，以降低大量类别、标签分布不均和标签空间复杂性带来的学习难度。

    

    战术、技术和程序（TTPs）是网络安全领域中复杂的攻击模式，在文本知识库中有详细的描述。在网络安全写作中识别TTPs，通常称为TTP映射，是一个重要而具有挑战性的任务。传统的学习方法通常以经典的多类或多标签分类设置为目标。由于存在大量的类别（即TTPs），标签分布的不均衡和标签空间的复杂层次结构，这种设置限制了模型的学习能力。我们采用了一种不同的学习范式来解决这个问题，其中将文本与TTP标签之间的直接语义相似度决定为文本分配给TTP标签，从而减少了仅仅在大型标签空间上竞争的复杂性。为此，我们提出了一种具有有效的基于采样的学习比较机制的神经匹配架构，促进学习过程。

    Tactics, Techniques and Procedures (TTPs) represent sophisticated attack patterns in the cybersecurity domain, described encyclopedically in textual knowledge bases. Identifying TTPs in cybersecurity writing, often called TTP mapping, is an important and challenging task. Conventional learning approaches often target the problem in the classical multi-class or multilabel classification setting. This setting hinders the learning ability of the model due to a large number of classes (i.e., TTPs), the inevitable skewness of the label distribution and the complex hierarchical structure of the label space. We formulate the problem in a different learning paradigm, where the assignment of a text to a TTP label is decided by the direct semantic similarity between the two, thus reducing the complexity of competing solely over the large labeling space. To that end, we propose a neural matching architecture with an effective sampling-based learn-to-compare mechanism, facilitating the learning pr
    
[^40]: 革新制药业：揭开药物行业中人工智能和法律语言模型的趋势

    Revolutionizing Pharma: Unveiling the AI and LLM Trends in the Pharmaceutical Industry. (arXiv:2401.10273v1 [cs.CY])

    [http://arxiv.org/abs/2401.10273](http://arxiv.org/abs/2401.10273)

    这篇论文批判性概述了制药行业中人工智能的新兴趋势和重大进展，特别强调了机器学习算法等先进人工智能技术在制药运营的贡献。

    

    本文对制药行业中人工智能的新兴趋势和重大进展进行了批判性概述。详细介绍了其在研发、动物测试、临床试验、医院临床阶段、生产、监管事务、质量控制和其他支持领域等关键运营领域的应用，文章系统地研究了人工智能在每个领域的作用。特别强调了机器学习算法等先进人工智能技术在制药运营各个方面的贡献。通过这一全面分析，文章突出了人工智能在重塑制药业未来的变革潜力。

    This document offers a critical overview of the emerging trends and significant advancements in artificial intelligence (AI) within the pharmaceutical industry. Detailing its application across key operational areas, including research and development, animal testing, clinical trials, hospital clinical stages, production, regulatory affairs, quality control and other supporting areas, the paper categorically examines AI's role in each sector. Special emphasis is placed on cutting-edge AI technologies like machine learning algorithms and their contributions to various aspects of pharmaceutical operations. Through this comprehensive analysis, the paper highlights the transformative potential of AI in reshaping the pharmaceutical industry's future.
    
[^41]: Chem-FINESE: 通过文本重构验证细粒度少样本实体提取

    Chem-FINESE: Validating Fine-Grained Few-shot Entity Extraction through Text Reconstruction. (arXiv:2401.10189v1 [cs.CL])

    [http://arxiv.org/abs/2401.10189](http://arxiv.org/abs/2401.10189)

    这篇论文提出了一种名为Chem-FINESE的方法来处理化学领域中细粒度少样本实体提取的问题。该方法通过使用序列到序列的实体提取器和自我验证模块来从输入句子中提取命名实体并重构原始输入句子。实验证明了该方法的有效性和可行性。

    

    在化学领域中，细粒度少样本实体提取面临两个独特的挑战。首先，与一般领域的实体提取任务相比，化学论文中的句子通常包含更多的实体。此外，实体提取模型通常难以提取长尾类型的实体。在本文中，我们提出了一种新颖的基于序列到序列的少样本实体提取方法Chem-FINESE来解决这两个挑战。我们的Chem-FINESE包含两个组件：一个序列到序列的实体提取器用于从输入句子中提取命名实体，以及一个序列到序列的自我验证模块用于从提取的实体中重构原始输入句子。受到一个好的实体提取系统需要忠实提取实体的事实启发，我们的新自我验证模块利用实体提取结果来重构原始输入句子。此外，我们设计了一种新的对比损失来减少在提取过程中的过度复制。

    Fine-grained few-shot entity extraction in the chemical domain faces two unique challenges. First, compared with entity extraction tasks in the general domain, sentences from chemical papers usually contain more entities. Moreover, entity extraction models usually have difficulty extracting entities of long-tailed types. In this paper, we propose Chem-FINESE, a novel sequence-to-sequence (seq2seq) based few-shot entity extraction approach, to address these two challenges. Our Chem-FINESE has two components: a seq2seq entity extractor to extract named entities from the input sentence and a seq2seq self-validation module to reconstruct the original input sentence from extracted entities. Inspired by the fact that a good entity extraction system needs to extract entities faithfully, our new self-validation module leverages entity extraction results to reconstruct the original input sentence. Besides, we design a new contrastive loss to reduce excessive copying during the extraction proces
    
[^42]: 一种简单的黑盒方法用于越狱攻击

    All in How You Ask for It: Simple Black-Box Method for Jailbreak Attacks. (arXiv:2401.09798v1 [cs.CL])

    [http://arxiv.org/abs/2401.09798](http://arxiv.org/abs/2401.09798)

    本研究提出了一种简单的黑盒方法，用于生成越狱攻击提示，克服了现有方法的复杂性和计算成本的限制。该方法通过使用语言模型自身，将有害提示重写为非有害表达，实现了超过80%的攻击成功率，并且即使模型更新，效果仍然有效。

    

    像ChatGPT这样的大型语言模型面临着“越狱”挑战，即规避保障措施以产生不符合伦理的提示。本研究引入了一种简单的黑盒方法，有效地生成越狱提示，克服了现有方法的高复杂性和计算成本的限制。该方法通过使用目标语言模型自身，迭代地将有害提示重写为非有害表达，基于假设认为语言模型可以直接生成规避保障的表达。通过在ChatGPT（GPT-3.5和GPT-4）和Gemini-Pro上进行实验证明，该方法在平均5次迭代内实现了超过80%的攻击成功率，并且即使模型更新，效果仍然有效。生成的越狱提示自然而简练，表明它们较不易被检测。结果表明，创建有效的越狱提示比先前研究认为的要简单，并且黑盒越狱攻击构成了一个重要的挑战。

    Large Language Models (LLMs) like ChatGPT face `jailbreak' challenges, where safeguards are bypassed to produce ethically harmful prompts. This study introduces a simple black-box method to effectively generate jailbreak prompts, overcoming the limitations of high complexity and computational costs associated with existing methods. The proposed technique iteratively rewrites harmful prompts into non-harmful expressions using the target LLM itself, based on the hypothesis that LLMs can directly sample safeguard-bypassing expressions. Demonstrated through experiments with ChatGPT (GPT-3.5 and GPT-4) and Gemini-Pro, this method achieved an attack success rate of over 80% within an average of 5 iterations and remained effective despite model updates. The jailbreak prompts generated were naturally-worded and concise, suggesting they are less detectable. The results indicate that creating effective jailbreak prompts is simpler than previously considered, and black-box jailbreak attacks pose 
    
[^43]: 迈向可识别的无监督领域转换：一种多样化分布匹配的方法

    Towards Identifiable Unsupervised Domain Translation: A Diversified Distribution Matching Approach. (arXiv:2401.09671v1 [cs.LG])

    [http://arxiv.org/abs/2401.09671](http://arxiv.org/abs/2401.09671)

    本研究旨在解决无监督领域转换中的可识别性问题，引入了一个MPA消除理论，解决了CycleGAN及其变体产生内容不对齐的限制。

    

    无监督领域转换（UDT）旨在找到将一个领域的样本（例如素描）转换为另一个领域（例如照片）的函数，同时不改变高层语义意义（也称为“内容”）。这些转换函数通常通过转换源领域和目标领域的概率分布来寻找。CycleGAN可以说是这一领域中最具代表性的方法。然而，文献中指出CycleGAN及其变体可能无法识别所需的转换函数，并产生内容不对齐的转换。这种局限性源于学习准则解空间中存在多个转换函数，称为“保度自同构（MPA）”。尽管意识到了这种可识别性问题，但解决方案仍然难以找到。本研究深入探究了核心的可识别性问题，并引入了MPA消除理论。我们的分析表明...

    Unsupervised domain translation (UDT) aims to find functions that convert samples from one domain (e.g., sketches) to another domain (e.g., photos) without changing the high-level semantic meaning (also referred to as ``content''). The translation functions are often sought by probability distribution matching of the transformed source domain and target domain. CycleGAN stands as arguably the most representative approach among this line of work. However, it was noticed in the literature that CycleGAN and variants could fail to identify the desired translation functions and produce content-misaligned translations. This limitation arises due to the presence of multiple translation functions -- referred to as ``measure-preserving automorphism" (MPA) -- in the solution space of the learning criteria. Despite awareness of such identifiability issues, solutions have remained elusive. This study delves into the core identifiability inquiry and introduces an MPA elimination theory. Our analysi
    
[^44]: 扩散驱动的分子构象预测生成框架

    Diffusion-Driven Generative Framework for Molecular Conformation Prediction. (arXiv:2401.09451v1 [q-bio.BM])

    [http://arxiv.org/abs/2401.09451](http://arxiv.org/abs/2401.09451)

    本文介绍了一种基于扩散驱动的生成框架\method{}，用于预测分子的三维构象，具有较高的预测精度并改进了传统方法的不足。

    

    从二维图形表示中推断出三维分子构型的任务在计算化学和药物开发领域具有重要意义。它对我们理解分子机制和相互作用起着基本作用。机器学习，特别是深度生成网络的快速发展，推动了这种预测建模精度的突破。传统方法通常采用分叉策略：首先估计原子间距，然后通过解决距离几何问题来塑造分子的空间结构。然而，这种顺序方法有时无法准确捕捉到局部原子排列的复杂性，从而损害结果结构模型的完整性。为了解决这些不足，本文引入了一个前卫的生成框架：\method{}，它基于扩散驱动的方法进行预测，并取得了重要的改进。

    The task of inferring three-dimensional molecular configurations from their two-dimensional graph representations is of critical significance in the domains of computational chemistry and the development of pharmaceuticals. It contributes fundamentally to our grasp of molecular mechanisms and interactions. The rapid evolution of machine learning, especially in the realm of deep generative networks, has catalyzed breakthroughs in the precision of such predictive modeling. Traditional methodologies typically employ a bifurcated strategy: initially estimating interatomic distances followed by sculpting the spatial molecular structure via solving a distance geometry problem. This sequential approach, however, occasionally fails to capture the intricacies of local atomic arrangements accurately, thus compromising the integrity of the resultant structural models. Addressing these deficiencies, this work introduces an avant-garde generative framework: \method{}, which is predicated on the dif
    
[^45]: 大型语言模型中的代码模拟挑战

    Code Simulation Challenges for Large Language Models. (arXiv:2401.09074v1 [cs.LG])

    [http://arxiv.org/abs/2401.09074](http://arxiv.org/abs/2401.09074)

    大型语言模型在模拟计算机代码和算法执行方面遇到挑战，性能随着代码长度的增加而迅速下降。在处理短程序或标准过程时，它们能以低错误率按顺序执行指令，但对于复杂的程序，特别是包含关键路径和冗余指令的程序，模拟效果较差。我们提出了一种逐行模拟代码执行的方法来解决这个问题。

    

    我们调查了大型语言模型（LLMs）在模拟计算机代码和算法执行方面的能力。我们首先研究了直线程序，并展示了当前LLMs在处理这样简单的程序时表现出的性能较差——性能随着代码长度的增加而迅速下降。接着，我们研究了LLMs在模拟包含关键路径和冗余指令的程序方面的能力。我们还通过排序算法和嵌套循环超越了直线程序的模拟，并展示了程序的计算复杂性直接影响LLMs模拟其执行的能力。我们观察到LLMs只有在处理短程序或标准过程时才能以低错误率按顺序执行指令。LLMs的代码模拟与它们的模式识别和记忆能力存在矛盾：在记忆对任务有害的情况下，我们提出了一种新的提示方法，逐行模拟代码的执行。

    We investigate the extent to which Large Language Models (LLMs) can simulate the execution of computer code and algorithms. We begin by looking straight line programs, and show that current LLMs demonstrate poor performance even with such simple programs -- performance rapidly degrades with the length of code. We then investigate the ability of LLMs to simulate programs that contain critical paths and redundant instructions. We also go beyond straight line program simulation with sorting algorithms and nested loops, and we show the computational complexity of a routine directly affects the ability of an LLM to simulate its execution. We observe that LLMs execute instructions sequentially and with a low error margin only for short programs or standard procedures. LLMs' code simulation is in tension with their pattern recognition and memorisation capabilities: on tasks where memorisation is detrimental, we propose a novel prompting method to simulate code execution line by line. Empirica
    
[^46]: 通过迭代组合问题来增强数学问题求解

    Augmenting Math Word Problems via Iterative Question Composing. (arXiv:2401.09003v1 [cs.CL])

    [http://arxiv.org/abs/2401.09003](http://arxiv.org/abs/2401.09003)

    本研究通过引入MMIQC数据集和迭代组合问题(IQC)的新颖增强方法，成功提高了大型语言模型的数学推理能力，在竞赛级数学问题上取得了优于先前最佳结果的准确率。

    

    尽管在改善大型语言模型(LLMs)的数学推理能力方面取得了一定进展，但在不使用外部工具的情况下解决竞赛级数学问题仍然对开源LLMs具有挑战性。在这项工作中，我们介绍了MMIQC数据集，这是一个混合处理的网络数据和合成问题-响应对的混合数据集，以提供基础模型更好的数学推理能力。通过在MMIQC上对Mistral-7B(arXiv:2310.06825)进行微调获得的模型Mistral-7B-MMIQC，在MATH(arXiv:2103.03874)上达到了36.0%的准确率，比之前(model size $\sim$7B)的最佳结果高出5.8%。我们的实验还表明，改进的一个重要部分归功于我们的新颖增强方法IQC(迭代组合问题)，其中我们迭代地要求LLM从给定的种子问题中组合新问题，并从另一个LLM中进行拒绝抽样。MMIQC现已在https://huggingface.co/datasets/Vivacem/MMIQC上发布。

    Despite recent progress in improving the mathematical reasoning ability of large language models(LLMs), solving competition-level math problems without the use of external tools remains challenging for open-source LLMs. In this work, we introduce the MMIQC dataset, a mixture of processed web data and synthetic question-response pairs, to equip base models with better mathematical reasoning skills. Mistral-7B-MMIQC, the model obtained by fine-tuning Mistral-7B(arXiv:2310.06825) on MMIQC, achieves 36.0\% accuracy on MATH(arXiv:2103.03874), 5.8\% higher than the previous (model size $\sim$7B) SOTA. Our experiments also show that a large part of the improvement attributes to our novel augmentation method IQC(Iterative Question Composing), where we iteratively ask an LLM to compose new questions from the given seed problems and do rejection sampling from another LLM. MMIQC has now been released on https://huggingface.co/datasets/Vivacem/MMIQC.
    
[^47]: 使用SPIN在动态知识图中实现时态动态算法的策略

    A Strategy for Implementing description Temporal Dynamic Algorithms in Dynamic Knowledge Graphs by SPIN. (arXiv:2401.07890v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2401.07890](http://arxiv.org/abs/2401.07890)

    本论文提出了一种使用SPIN在动态知识图中实现时态动态算法的策略，通过将行为嵌入到描述逻辑中，表示和推理行为，并且分析了相关的逻辑结构和工具。

    

    在最近的逻辑和计算机科学研究中，计划和推理动作和过程，以及推理命题，都是重要的问题。行为在日常生活中的广泛使用，如物联网、语义Web服务等，以及行为形式主义中的限制和问题，这两个因素促使我们研究如何表示行为。自2007年以来，一些想法将描述逻辑（DL）和行为形式主义集成起来，以表示静态和动态知识。同时，时间是动态情况下的重要因素，行为随时间改变状态。在这项研究中，我们一方面研究了相关的逻辑结构，如扩展的描述逻辑（DLs）、时间形式化和行为形式化。另一方面，我们分析了设计和开发知识与行动库（KAB）的可能工具。

    Planning and reasoning about actions and processes, in addition to reasoning about propositions, are important issues in recent logical and computer science studies. The widespread use of actions in everyday life such as IoT, semantic web services, etc., and the limitations and issues in the action formalisms are two factors that lead us to study how actions are represented.  Since 2007, there have been some ideas to integrate Description Logic (DL) and action formalisms for representing both static and dynamic knowledge. Meanwhile, time is an important factor in dynamic situations, and actions change states over time. In this study, on the one hand, we examined related logical structures such as extensions of description logics (DLs), temporal formalisms, and action formalisms. On the other hand, we analyzed possible tools for designing and developing the Knowledge and Action Base (KAB).  For representation and reasoning about actions, we embedded actions into DLs (such as Dynamic-ALC
    
[^48]: 学习可解释且性能更好的POMDP策略表示

    Learning Explainable and Better Performing Representations of POMDP Strategies. (arXiv:2401.07656v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2401.07656](http://arxiv.org/abs/2401.07656)

    本研究提出了一种学习部分可观测的马尔可夫决策过程（POMDP）策略自动机表示的方法。与传统的表格表示相比，该方法得到的自动机更小更易理解，且在学习过程中可改善策略性能。与其他方法相比，本方法在可扩展性上具有显著优势。

    

    部分可观测的马尔可夫决策过程（POMDP）的策略通常需要记忆。一种表示这种记忆的方法是使用自动机。我们提出了一种使用改进的L*算法学习策略的自动机表示的方法。与策略的表格表示相比，得到的自动机体积显著更小，因此更易于理解。此外，在学习过程中，我们的启发式方法甚至可以改善策略的性能。与直接从POMDP合成自动机以解决问题的方法相比，我们的方法具有不可比拟的可扩展性。

    Strategies for partially observable Markov decision processes (POMDP) typically require memory. One way to represent this memory is via automata. We present a method to learn an automaton representation of a strategy using a modification of the L*-algorithm. Compared to the tabular representation of a strategy, the resulting automaton is dramatically smaller and thus also more explainable. Moreover, in the learning process, our heuristics may even improve the strategy's performance. In contrast to approaches that synthesize an automaton directly from the POMDP thereby solving it, our approach is incomparably more scalable.
    
[^49]: 开发用于生物学和医学的ChatGPT：生物医学问题回答的完整综述

    Developing ChatGPT for Biology and Medicine: A Complete Review of Biomedical Question Answering. (arXiv:2401.07510v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.07510](http://arxiv.org/abs/2401.07510)

    开发用于生物学和医学的ChatGPT，通过自然语言处理和多模态范式，加速了医学问题回答的进展，并且能够处理医学环境中的大规模、多样化、无标签数据分析场景。

    

    ChatGPT通过自然语言处理（NLP）和多模态范式，通过增加医学领域数据的融入，探索了在提供医学诊断、治疗建议和其他医疗支持方面的问答（QA）的战略蓝图。通过将文本、图像、视频和其他模态从通用领域转向医学领域，这些技术加快了医学领域问题回答（MDQA）的进展。它们弥合了人类自然语言和复杂医学领域知识或专家手动注释之间的差距，处理了医学环境中的大规模、多样化、不平衡甚至无标签数据分析场景。我们重点研究的是利用语言模型和多模态范式进行医学问题回答，旨在指导研究界根据其特定的医学研究需求选择合适的机制。

    ChatGPT explores a strategic blueprint of question answering (QA) in delivering medical diagnosis, treatment recommendations, and other healthcare support. This is achieved through the increasing incorporation of medical domain data via natural language processing (NLP) and multimodal paradigms. By transitioning the distribution of text, images, videos, and other modalities from the general domain to the medical domain, these techniques have expedited the progress of medical domain question answering (MDQA). They bridge the gap between human natural language and sophisticated medical domain knowledge or expert manual annotations, handling large-scale, diverse, unbalanced, or even unlabeled data analysis scenarios in medical contexts. Central to our focus is the utilizing of language models and multimodal paradigms for medical question answering, aiming to guide the research community in selecting appropriate mechanisms for their specific medical research requirements. Specialized tasks
    
[^50]: 带有多级扩散模型的分层时尚设计

    Hierarchical Fashion Design with Multi-stage Diffusion Models. (arXiv:2401.07450v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2401.07450](http://arxiv.org/abs/2401.07450)

    本论文提出了一种名为HieraFashDiff的新型时尚设计方法，它使用多级扩散模型实现了从高级设计概念到低级服装属性的分层设计和编辑，解决了当前在时尚设计中的挑战。

    

    跨模态时尚合成和编辑通过自动生成和局部修改设计草图，为时尚设计师提供智能支持。尽管当前的扩散模型在图像合成方面表现出了可靠的稳定性和可控性，但在从抽象的设计元素中生成时尚设计和精细编辑方面仍面临重大挑战。高级设计概念，例如办公室、商务和派对，形成了抽象的感官表达方式，而袖长、领型和裤长等可衡量的方面被视为服装的低级属性。使用冗长的文字描述来控制和编辑时尚图像存在困难。在本文中，我们提出了一种名为HieraFashDiff的新型时尚设计方法，它使用共享的多级扩散模型，将高级设计概念和低级服装属性融入到分层结构中。具体而言，我们将输入文本分为不同的层次，并将其输入到多级扩散模型中。

    Cross-modal fashion synthesis and editing offer intelligent support to fashion designers by enabling the automatic generation and local modification of design drafts.While current diffusion models demonstrate commendable stability and controllability in image synthesis,they still face significant challenges in generating fashion design from abstract design elements and fine-grained editing.Abstract sensory expressions, \eg office, business, and party, form the high-level design concepts, while measurable aspects like sleeve length, collar type, and pant length are considered the low-level attributes of clothing.Controlling and editing fashion images using lengthy text descriptions poses a difficulty.In this paper, we propose HieraFashDiff,a novel fashion design method using the shared multi-stage diffusion model encompassing high-level design concepts and low-level clothing attributes in a hierarchical structure.Specifically, we categorized the input text into different levels and fed 
    
[^51]: 基于最近邻搜索的地球移动距离的高效逼近方法

    Efficient approximation of Earth Mover's Distance Based on Nearest Neighbor Search. (arXiv:2401.07378v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2401.07378](http://arxiv.org/abs/2401.07378)

    本文提出了一种基于最近邻搜索的新方法NNS-EMD来逼近地球移动距离（EMD），以实现高精度、低时间复杂度和高内存效率。该方法通过减少数据点的比较数量和并行处理提供了高效的近似计算，并通过在GPU上进行向量化加速，特别适用于大型数据集。

    

    地球移动距离（EMD）是计算机视觉和其他应用领域中的两个分布之间的重要相似度度量。然而，其精确计算的计算和内存消耗较大，限制了其在大规模问题上的可扩展性和适用性。为了降低计算成本，提出了各种近似EMD算法，但它们精度较低，可能需要额外的内存使用或手动参数调整。在本文中，我们提出了一种新颖的方法，称为NNS-EMD，使用最近邻搜索（NNS）来逼近EMD，以实现高精度、低时间复杂度和高内存效率。NNS操作减少了每次NNS迭代中所比较的数据点的数量，并提供了并行处理的机会。我们还通过在GPU上进行向量化来加速NNS-EMD，这对于大型数据集尤为有益。我们将NNS-EMD与精确EMD和最先进的近似EMD算法进行了比较。

    Earth Mover's Distance (EMD) is an important similarity measure between two distributions, used in computer vision and many other application domains. However, its exact calculation is computationally and memory intensive, which hinders its scalability and applicability for large-scale problems. Various approximate EMD algorithms have been proposed to reduce computational costs, but they suffer lower accuracy and may require additional memory usage or manual parameter tuning. In this paper, we present a novel approach, NNS-EMD, to approximate EMD using Nearest Neighbor Search (NNS), in order to achieve high accuracy, low time complexity, and high memory efficiency. The NNS operation reduces the number of data points compared in each NNS iteration and offers opportunities for parallel processing. We further accelerate NNS-EMD via vectorization on GPU, which is especially beneficial for large datasets. We compare NNS-EMD with both the exact EMD and state-of-the-art approximate EMD algori
    
[^52]: PDE广义化的上下文操作符网络：对一维标量非线性守恒定律的研究

    PDE Generalization of In-Context Operator Networks: A Study on 1D Scalar Nonlinear Conservation Laws. (arXiv:2401.07364v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.07364](http://arxiv.org/abs/2401.07364)

    本文以一维标量非线性守恒定律为例，详细介绍了使用上下文操作符网络（ICON）解决PDE问题的方法，并展示了ICON模型在没有微调的情况下可以很好地泛化到具有新形式的PDEs。

    

    我们能否构建一个针对各种PDE相关科学学习任务的单一大模型？这个模型能否在没有任何微调的情况下泛化到新的PDE，甚至是新形式的PDE？上下文操作符学习及其对应模型In-Context Operator Networks（ICON）代表了对这些问题的初步探索。之前已经证明了ICON对第一个问题的能力。在本文中，我们提出了一种用ICON解决PDE问题的详细方法，并展示了一个单一的ICON模型如何通过适当设计的数据提示来进行不同方程的正向和反向预测。我们展示了对第二个问题的积极证据，即ICON可以在没有任何微调的情况下很好地泛化到一些具有新形式的PDE。这通过对一维标量非线性守恒定律的研究加以说明，这是一类具有时间演化的PDE族群。我们还展示了如何扩展ICON模型能够解决的问题范围。

    Can we build a single large model for a wide range of PDE-related scientific learning tasks? Can this model generalize to new PDEs, even of new forms, without any fine-tuning? In-context operator learning and the corresponding model In-Context Operator Networks (ICON) represent an initial exploration of these questions. The capability of ICON regarding the first question has been demonstrated previously. In this paper, we present a detailed methodology for solving PDE problems with ICON, and show how a single ICON model can make forward and reverse predictions for different equations with different strides, provided with appropriately designed data prompts. We show the positive evidence to the second question, i.e., ICON can generalize well to some PDEs with new forms without any fine-tuning. This is exemplified through a study on 1D scalar nonlinear conservation laws, a family of PDEs with temporal evolution. We also show how to broaden the range of problems that an ICON model can add
    
[^53]: 基于重新设计的自训练方法的半监督语义分割在白细胞上的应用

    Semi-supervised Semantic Segmentation using Redesigned Self-Training for White Blood Cell. (arXiv:2401.07278v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2401.07278](http://arxiv.org/abs/2401.07278)

    本文通过引入半监督学习框架和结合FixMatch，提出了一种重新设计的自训练流程，用于解决白细胞分割中缺乏标记数据集和过时方法的问题。在深度学习架构和自训练方案的支持下，取得了在不同数据集上的优异性能。

    

    在医疗保健领域，特别是在白细胞癌症诊断中，人工智能（AI）受到两个主要挑战的阻碍：缺乏大规模的白细胞（WBC）分割的标记数据集和过时的分割方法。为了解决第一个挑战，应该引入一种半监督学习框架来高效地注释大数据集。在这项工作中，我们通过提出一种新颖的自训练流程并结合FixMatch来解决这个问题。我们发现，通过在自训练流程中结合FixMatch，大多数情况下性能得到了改善。我们的性能在DeepLab-V3架构和ResNet-50上采用了自训练方案和一致性，分别在Zheng 1、Zheng 2和LISC数据集上达到了90.69%、87.37%和76.49%。

    Artificial Intelligence (AI) in healthcare, especially in white blood cell cancer diagnosis, is hindered by two primary challenges: the lack of large-scale labeled datasets for white blood cell (WBC) segmentation and outdated segmentation methods. To address the first challenge, a semi-supervised learning framework should be brought to efficiently annotate the large dataset. In this work, we address this issue by proposing a novel self-training pipeline with the incorporation of FixMatch. We discover that by incorporating FixMatch in the self-training pipeline, the performance improves in the majority of cases. Our performance achieved the best performance with the self-training scheme with consistency on DeepLab-V3 architecture and ResNet-50, reaching 90.69%, 87.37%, and 76.49% on Zheng 1, Zheng 2, and LISC datasets, respectively.
    
[^54]: 一个用于原型开发通用人工智能的普适知识模型和认知架构

    A Universal Knowledge Model and Cognitive Architecture for Prototyping AGI. (arXiv:2401.06256v1 [cs.AI])

    [http://arxiv.org/abs/2401.06256](http://arxiv.org/abs/2401.06256)

    本文提出了一个普适的知识模型和认知架构，用于原型开发通用人工智能（AGI）。该架构包括42种认知架构和一组功能模块，用于接近AGI能力的智能系统。此外，本文还提出了一种通用的知识表示方法，可以将各种不同形式的知识表示整合到一个知识库中。

    

    本文确定了42种用于创建通用人工智能（AGI）的认知架构，并提出了一组相互关联的功能模块，这些模块是接近AGI能力的智能系统所应具备的。由于现有的架构中没有找到所需的功能模块集合，本文提出了一种新的认知架构，用于接近AGI能力的智能系统。作为架构框架中的关键解决方案之一，本文提出了一种通用的知识表示方法，可以将各种非形式化、部分和完全形式化的知识表示方法结合在一个知识库中，如自然语言文本、图像、音频和视频记录、图形、算法、数据库、神经网络、知识图、本体、框架、实质-属性-关系模型、推理系统、谓词演算模型、概念模型等。为了组合和结构化各个片段

    The article identified 42 cognitive architectures for creating general artificial intelligence (AGI) and proposed a set of interrelated functional blocks that an agent approaching AGI in its capabilities should possess. Since the required set of blocks is not found in any of the existing architectures, the article proposes a new cognitive architecture for intelligent systems approaching AGI in their capabilities. As one of the key solutions within the framework of the architecture, a universal method of knowledge representation is proposed, which allows combining various non-formalized, partially and fully formalized methods of knowledge representation in a single knowledge base, such as texts in natural languages, images, audio and video recordings, graphs, algorithms, databases, neural networks, knowledge graphs, ontologies, frames, essence-property-relation models, production systems, predicate calculus models, conceptual models, and others. To combine and structure various fragment
    
[^55]: 大型语言模型中的通用漏洞：上下文学习后门攻击

    Universal Vulnerabilities in Large Language Models: In-context Learning Backdoor Attacks. (arXiv:2401.05949v1 [cs.CL])

    [http://arxiv.org/abs/2401.05949](http://arxiv.org/abs/2401.05949)

    本研究发现上下文学习范式在大型语言模型中存在漏洞，攻击者可以通过污染示范上下文来操控模型行为，而无需进行微调。这项研究设计了一种名为ICLAttack的后门攻击方法，可以通过污染示范样本和提示来使模型按照预定义的意图行事。

    

    上下文学习是一种在预训练和微调之间弥合差距的范式，在几个自然语言处理任务中展现了高效性，特别是在少样本设置中。与传统的微调方法不同，上下文学习能够适应未见过的任务而无需更新任何参数。尽管被广泛应用，上下文学习仍然容易受到恶意攻击。本研究提出了对这一范式的安全性问题的关切。我们的研究表明，攻击者可以通过污染示范上下文来操控大型语言模型的行为，而无需对模型进行微调。具体来说，我们设计了一种新的后门攻击方法，命名为ICLAttack，针对基于上下文学习的大型语言模型。我们的方法包括两种类型的攻击：污染示范样本和污染提示，可以使模型按照预定义的意图行事。ICLAttack不需要额外的微调。

    In-context learning, a paradigm bridging the gap between pre-training and fine-tuning, has demonstrated high efficacy in several NLP tasks, especially in few-shot settings. Unlike traditional fine-tuning methods, in-context learning adapts pre-trained models to unseen tasks without updating any parameters. Despite being widely applied, in-context learning is vulnerable to malicious attacks. In this work, we raise security concerns regarding this paradigm. Our studies demonstrate that an attacker can manipulate the behavior of large language models by poisoning the demonstration context, without the need for fine-tuning the model. Specifically, we have designed a new backdoor attack method, named ICLAttack, to target large language models based on in-context learning. Our method encompasses two types of attacks: poisoning demonstration examples and poisoning prompts, which can make models behave in accordance with predefined intentions. ICLAttack does not require additional fine-tuning 
    
[^56]: 推理步长对大型语言模型的影响

    The Impact of Reasoning Step Length on Large Language Models. (arXiv:2401.04925v1 [cs.CL])

    [http://arxiv.org/abs/2401.04925](http://arxiv.org/abs/2401.04925)

    本研究探讨了推理步长对大型语言模型的影响，并发现在提示中增加推理步骤能显著提高模型的推理能力，而减少推理步骤则会降低模型的推理能力。

    

    思维链条（CoT）对于提高大型语言模型（LLM）的推理能力具有重要作用。然而，CoT的有效性与提示中推理步骤的长度之间的关系仍然不为人所知。为了揭示这一点，我们进行了几个实证实验来探索这些关系。具体而言，我们设计了一些实验，扩展和压缩CoT演示中的合理推理步骤，同时保持其他因素不变。我们得出了以下主要发现。首先，结果表明，在提示中延长推理步骤，即使没有向提示中添加新信息，也会显著提高LLM在多个数据集上的推理能力。相反，缩短推理步骤，即使保留关键信息，也会显著降低模型的推理能力。这一发现突显了CoT提示中步骤数量的重要性，并提供了实际指导。

    Chain of Thought (CoT) is significant in improving the reasoning abilities of large language models (LLMs). However, the correlation between the effectiveness of CoT and the length of reasoning steps in prompts remains largely unknown. To shed light on this, we have conducted several empirical experiments to explore the relations. Specifically, we design experiments that expand and compress the rationale reasoning steps within CoT demonstrations, while keeping all other factors constant. We have the following key findings. First, the results indicate that lengthening the reasoning steps in prompts, even without adding new information into the prompt, considerably enhances LLMs' reasoning abilities across multiple datasets. Alternatively, shortening the reasoning steps, even while preserving the key information, significantly diminishes the reasoning abilities of models. This finding highlights the importance of the number of steps in CoT prompts and provides practical guidance to make 
    
[^57]: 受过良好教育的智能的内在善良

    The inherent goodness of well educated intelligence. (arXiv:2401.04846v1 [econ.TH])

    [http://arxiv.org/abs/2401.04846](http://arxiv.org/abs/2401.04846)

    本文探讨了智能体变得智能的因素，强调了掌握特征和控制多个保守相互作用的子系统的能力。智能的核心是“集体如一体”和“了解局部行动的整体结果”。文章提出了一种对集体保守系统进行控制的替代方法。

    

    本文将探讨使一个智能体变得智能的因素，无论是生物体还是计算机上的人工智能。特别关注的是能够表征和控制多个保守相互作用的相同子系统的能力。智能的本质将被发现是黄金法则——“集体行动如一体”或“了解局部行动的整体结果”。集体的流动是由掌控着少量字符串的操纵者决定的，根据对称性确定的最小作用路径的测地线运动。控制集体保守系统是困难的，历史上一直通过为系统添加显著黏性来稳定期望的最大性能的亚稳平衡状态，但这会在过程中降低或破坏它们。有一种替代方案。

    This paper will examine what makes a being intelligent, whether that be a biological being or an artificial silicon being on a computer. Special attention will be paid to the being having the ability to characterize and control a collective system of many identical conservative sub-systems conservatively interacting. The essence of intelligence will be found to be the golden rule -- "the collective acts as one" or "knowing the global consequences of local actions". The flow of the collective is a small set of twinkling textures, that are governed by a puppeteer who is pulling a small number of strings according to a geodesic motion of least action, determined by the symmetries. Controlling collective conservative systems is difficult and has historically been done by adding significant viscosity to the system to stabilize the desirable meta stable equilibriums of maximum performance, but it degrades or destroys them in the process. There is an alternative. Once the optimum twinkling te
    
[^58]: 在不断演化的社会规范中的Agent对齐

    Agent Alignment in Evolving Social Norms. (arXiv:2401.04620v1 [cs.CL])

    [http://arxiv.org/abs/2401.04620](http://arxiv.org/abs/2401.04620)

    本论文提出了一个名为EvolutionaryAgent的进化框架，将Agent对齐转化为适者生存的演化和选择过程，在不断演化的社会规范中，与当前社会规范更好适应的Agent将具有更高的生存和传播概率。

    

    基于大型语言模型（LLM）的Agent越来越多地渗透到人类生产和生活的各个领域，凸显了将其与人类价值观对齐的重要性。目前AI系统的对齐主要集中在通过人为干预对LLM进行被动对齐。然而，Agent具有接受环境反馈和自我进化等特性，使得LLM对齐方法变得不足够。为此，我们提出了一个名为EvolutionaryAgent的Agent进化和对齐的进化框架，将Agent对齐转化为适者生存的演化和选择过程。在社会规范不断演化的环境中，与当前社会规范更好适应的Agent将具有更高的生存和传播概率，而对齐不足的Agent则逐渐减少。通过多个角度对与社会规范相对齐的Agent进行的实验结果进行评估。

    Agents based on Large Language Models (LLMs) are increasingly permeating various domains of human production and life, highlighting the importance of aligning them with human values. The current alignment of AI systems primarily focuses on passively aligning LLMs through human intervention. However, agents possess characteristics like receiving environmental feedback and self-evolution, rendering the LLM alignment methods inadequate. In response, we propose an evolutionary framework for agent evolution and alignment, named EvolutionaryAgent, which transforms agent alignment into a process of evolution and selection under the principle of survival of the fittest. In an environment where social norms continuously evolve, agents better adapted to the current social norms will have a higher probability of survival and proliferation, while those inadequately aligned dwindle over time. Experimental results assessing the agents from multiple perspectives in aligning with social norms demonstr
    
[^59]: 在非稳定环境下的决策制定与策略增强搜索

    Decision Making in Non-Stationary Environments with Policy-Augmented Search. (arXiv:2401.03197v1 [cs.AI])

    [http://arxiv.org/abs/2401.03197](http://arxiv.org/abs/2401.03197)

    在非稳定环境下的决策制定是一个具有挑战性的问题，本文介绍了一种新的算法--策略增强蒙特卡洛树搜索（PA-MCTS），它将在线搜索与策略学习相结合。

    

    在许多重要问题中，存在着不确定性下的连续决策制定。针对这类问题，传统的方法包括强化学习和在线搜索（如蒙特卡洛树搜索）。前者通过与环境的交互来学习策略（通常在执行之前完成），而后者在决策时使用环境的生成模型来采样有前景的行动轨迹。在非稳定环境下的决策制定尤为具有挑战性，因为代理操作的环境可能随时间变化。两种方法在这种情况下都存在缺陷--一方面，执行之前学习的策略在环境改变时变得陈旧，重新学习需要时间和计算资源。另一方面，在线搜索在允许的运行时间有限时可能会返回次优行动。本文介绍了一种新的算法--策略增强蒙特卡洛树搜索（PA-MCTS），它将在线搜索与策略学习相结合。

    Sequential decision-making under uncertainty is present in many important problems. Two popular approaches for tackling such problems are reinforcement learning and online search (e.g., Monte Carlo tree search). While the former learns a policy by interacting with the environment (typically done before execution), the latter uses a generative model of the environment to sample promising action trajectories at decision time. Decision-making is particularly challenging in non-stationary environments, where the environment in which an agent operates can change over time. Both approaches have shortcomings in such settings -- on the one hand, policies learned before execution become stale when the environment changes and relearning takes both time and computational effort. Online search, on the other hand, can return sub-optimal actions when there are limitations on allowed runtime. In this paper, we introduce \textit{Policy-Augmented Monte Carlo tree search} (PA-MCTS), which combines actio
    
[^60]: 论自动规划与调度中引入大型语言模型的前景

    On the Prospects of Incorporating Large Language Models (LLMs) in Automated Planning and Scheduling (APS). (arXiv:2401.02500v1 [cs.AI])

    [http://arxiv.org/abs/2401.02500](http://arxiv.org/abs/2401.02500)

    本文研究了将大型语言模型（LLMs）与传统符号规划器集成的前景，并指出这种神经符号方法有望在解决复杂规划问题中发挥重要作用。

    

    自动规划与调度是人工智能领域中增长迅速的领域之一，其中大型语言模型（LLMs）的应用越来越受到关注。本文基于对126篇论文的综合回顾，研究了LLMs在解决规划问题的各个方面中独特应用的八个类别：语言翻译、计划生成、模型构建、多智能体规划、交互式规划、启发式优化、工具集成和脑启发式规划。针对每个类别，我们明确了考虑的问题和现有的空白。我们回顾的一个重要观点是，在与传统符号规划器集成时，LLMs的真正潜力得以发挥，这指向了一种有前景的神经符号方法。这种方法有效地将LLMs的生成能力与经典规划方法的精确性结合起来。通过综合现有文献的见解，我们强调了这种集成在解决复杂规划问题上的潜力。

    Automated Planning and Scheduling is among the growing areas in Artificial Intelligence (AI) where mention of LLMs has gained popularity. Based on a comprehensive review of 126 papers, this paper investigates eight categories based on the unique applications of LLMs in addressing various aspects of planning problems: language translation, plan generation, model construction, multi-agent planning, interactive planning, heuristics optimization, tool integration, and brain-inspired planning. For each category, we articulate the issues considered and existing gaps. A critical insight resulting from our review is that the true potential of LLMs unfolds when they are integrated with traditional symbolic planners, pointing towards a promising neuro-symbolic approach. This approach effectively combines the generative aspects of LLMs with the precision of classical planning methods. By synthesizing insights from existing literature, we underline the potential of this integration to address comp
    
[^61]: 按照你的学习行动：非稳态马尔可夫决策过程中的自适应决策

    Act as You Learn: Adaptive Decision-Making in Non-Stationary Markov Decision Processes. (arXiv:2401.01841v1 [cs.AI])

    [http://arxiv.org/abs/2401.01841](http://arxiv.org/abs/2401.01841)

    本文提出了一种自适应蒙特卡洛树搜索算法来应对非稳态环境下的决策问题，解决了传统方法中对环境动态假设的限制和规划过程的悲观性问题。

    

    在顺序决策中，处理非稳态环境是一个基本（且在很大程度上是未解决的）挑战，其中外部环境条件随时间变化。这类问题通常被建模为非稳态马尔可夫决策过程（NSMDP）。然而，现有的NSMDP决策方法存在两个主要缺点：首先，它们假设当前时刻更新的环境动态是已知的（尽管未来动态可能会改变）；其次，规划过程主要是悲观的，即代理人会“安全行动”以考虑环境的非稳态演变。我们认为这两个假设在实践中是无效的-更新的环境条件很少是已知的，并且当代理人与环境交互时，它可以学习更新的动态并避免悲观，至少在其对动态有信心的状态下。我们提出了一种启发式搜索算法，称为自适应蒙特卡洛树搜索。

    A fundamental (and largely open) challenge in sequential decision-making is dealing with non-stationary environments, where exogenous environmental conditions change over time. Such problems are traditionally modeled as non-stationary Markov decision processes (NSMDP). However, existing approaches for decision-making in NSMDPs have two major shortcomings: first, they assume that the updated environmental dynamics at the current time are known (although future dynamics can change); and second, planning is largely pessimistic, i.e., the agent acts ``safely'' to account for the non-stationary evolution of the environment. We argue that both these assumptions are invalid in practice -updated environmental conditions are rarely known, and as the agent interacts with the environment, it can learn about the updated dynamics and avoid being pessimistic, at least in states whose dynamics it is confident about. We present a heuristic search algorithm called \textit{Adaptive Monte Carlo Tree Se
    
[^62]: 任务驱动的因果特征提取：朝着可信的风险预测迈进

    Task-Driven Causal Feature Distillation: Towards Trustworthy Risk Prediction. (arXiv:2312.16113v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.16113](http://arxiv.org/abs/2312.16113)

    该论文提出了一种任务驱动的因果特征提取模型（TDCFD），通过将原始特征值转化为因果特征归因来实现可信的风险预测。实验证实了该方法在精确度、召回率和可解释性方面的优势。

    

    由于人工智能在许多领域取得了巨大的成功，对其在可信和可解释的风险预测方面的潜力引起了极大的兴趣。然而，大多数模型缺乏因果推理，并且在类别不平衡的情况下难以应对，导致精确度和召回率较低。为了解决这个问题，我们提出了一种任务驱动的因果特征提取模型（TDCFD），将原始特征值转化为特定风险预测任务的因果特征归因。因果特征归因有助于描述该特征的值对风险预测结果的贡献程度。在因果特征提取之后，我们应用深度神经网络生成具有因果可解释性和高精确度/召回率的可信预测结果。我们在几个合成和真实数据集上评估了TDCFD方法的性能，结果表明其在精确度、召回率和可解释性方面优于现有方法。

    Since artificial intelligence has seen tremendous recent successes in many areas, it has sparked great interest in its potential for trustworthy and interpretable risk prediction. However, most models lack causal reasoning and struggle with class imbalance, leading to poor precision and recall. To address this, we propose a Task-Driven Causal Feature Distillation model (TDCFD) to transform original feature values into causal feature attributions for the specific risk prediction task. The causal feature attribution helps describe how much contribution the value of this feature can make to the risk prediction result. After the causal feature distillation, a deep neural network is applied to produce trustworthy prediction results with causal interpretability and high precision/recall. We evaluate the performance of our TDCFD method on several synthetic and real datasets, and the results demonstrate its superiority over the state-of-the-art methods regarding precision, recall, interpretabi
    
[^63]: 当模型遇见新常态：针对无监督时间序列异常检测的测试时适应

    When Model Meets New Normals: Test-time Adaptation for Unsupervised Time-series Anomaly Detection. (arXiv:2312.11976v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.11976](http://arxiv.org/abs/2312.11976)

    本论文针对无监督时间序列异常检测中的新常态问题，提出了一种基于趋势估计和自监督学习的测试时适应策略，实验证明该策略能够提高模型性能，增加对分布变化的鲁棒性。

    

    时间序列异常检测处理通过从观察序列中学习正常性来检测异常时间步骤的问题。然而，正常性的概念随时间演变，导致出现了“新常态问题”，即由于训练和测试数据之间的分布变化，正常性的分布可能发生改变。本文重点研究了无监督时间序列异常检测研究中新常态问题的普遍存在。为解决这个问题，我们提出了一种简单而有效的测试时适应策略，该策略基于趋势估计和自监督学习方法，在推断过程中学习新的正常性。对真实世界基准的广泛实验表明，将所提策略纳入异常检测器中，与基准相比，能够持续改善模型的性能，使其对分布变化具有鲁棒性。

    Time-series anomaly detection deals with the problem of detecting anomalous timesteps by learning normality from the sequence of observations. However, the concept of normality evolves over time, leading to a "new normal problem", where the distribution of normality can be changed due to the distribution shifts between training and test data. This paper highlights the prevalence of the new normal problem in unsupervised time-series anomaly detection studies. To tackle this issue, we propose a simple yet effective test-time adaptation strategy based on trend estimation and a self-supervised approach to learning new normalities during inference. Extensive experiments on real-world benchmarks demonstrate that incorporating the proposed strategy into the anomaly detector consistently improves the model's performance compared to the baselines, leading to robustness to the distribution shifts.
    
[^64]: Topic-VQ-VAE: 利用隐变量码本实现灵活的主题导向文档生成

    Topic-VQ-VAE: Leveraging Latent Codebooks for Flexible Topic-Guided Document Generation. (arXiv:2312.11532v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.11532](http://arxiv.org/abs/2312.11532)

    本文介绍了一种利用隐变量码本实现灵活的主题导向文档生成的新方法，通过名为TVQ-VAE的生成式主题模型，可以有效捕捉主题上下文，并支持灵活形式的文档生成。

    

    本文介绍了一种利用Vector-Quantized Variational Auto-Encoder（VQ-VAE）中的隐变量码本进行主题建模的新方法，离散地封装了预训练嵌入（例如预训练语言模型）的丰富信息。根据对隐变量码本和嵌入的新解释，我们提出了一种新的生成式主题模型，称为Topic-VQ-VAE（TVQ-VAE），它可以反向生成与相应隐变量码本相关的原始文档。TVQ-VAE可以通过包括传统的词袋（BoW）分布和自回归图像生成在内的各种生成分布来可视化主题。我们在文档分析和图像生成上的实验结果表明，TVQ-VAE可以有效捕捉主题上下文，揭示数据集的潜在结构，并支持灵活形式的文档生成。所提出的TVQ-VAE的官方实现可在https://github.com/clo找到。

    This paper introduces a novel approach for topic modeling utilizing latent codebooks from Vector-Quantized Variational Auto-Encoder~(VQ-VAE), discretely encapsulating the rich information of the pre-trained embeddings such as the pre-trained language model. From the novel interpretation of the latent codebooks and embeddings as conceptual bag-of-words, we propose a new generative topic model called Topic-VQ-VAE~(TVQ-VAE) which inversely generates the original documents related to the respective latent codebook. The TVQ-VAE can visualize the topics with various generative distributions including the traditional BoW distribution and the autoregressive image generation. Our experimental results on document analysis and image generation demonstrate that TVQ-VAE effectively captures the topic context which reveals the underlying structures of the dataset and supports flexible forms of document generation. Official implementation of the proposed TVQ-VAE is available at https://github.com/clo
    
[^65]: DeRDaVa: 机器学习中的删除鲁棒数据估值

    DeRDaVa: Deletion-Robust Data Valuation for Machine Learning. (arXiv:2312.11413v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.11413](http://arxiv.org/abs/2312.11413)

    提出了DeRDaVa：一种适用于机器学习的删除鲁棒数据估值框架。通过在预测删除后保持模型性能的前提下对每个数据源的贡献进行估值，避免了昂贵的重新计算。推广到Risk-DeRDaVa以满足对最坏/最好情况感到风险厌恶/寻求的模型所有者的需求。

    

    数据估值涉及确定在预测中对数据源进行公平估价以补偿它们，或确定最有用或最无用的训练样本。随着个人数据所有权和数据保护法规的增加，模型所有者可能需要满足更多的数据删除请求。这引发了现有工作尚未解决的问题：删除后数据估值分数是否仍然公平？是否必须昂贵地重新计算分数？答案是否定的。为了避免重新计算，我们提出在预测删除后保持模型性能的前提下，使用我们的数据估值框架DeRDaVa来对每个数据源的贡献进行估值。DeRDaVa可以高效地近似，并给更有用或更不容易被删除的数据分配更高的值。我们进一步推广了DeRDaVa到Risk-DeRDaVa，以满足对最坏/最好情况感到风险厌恶/寻求的模型所有者的需求。

    Data valuation is concerned with determining a fair valuation of data from data sources to compensate them or to identify training examples that are the most or least useful for predictions. With the rising interest in personal data ownership and data protection regulations, model owners will likely have to fulfil more data deletion requests. This raises issues that have not been addressed by existing works: Are the data valuation scores still fair with deletions? Must the scores be expensively recomputed? The answer is no. To avoid recomputations, we propose using our data valuation framework DeRDaVa upfront for valuing each data source's contribution to preserving robust model performance after anticipated data deletions. DeRDaVa can be efficiently approximated and will assign higher values to data that are more useful or less likely to be deleted. We further generalize DeRDaVa to Risk-DeRDaVa to cater to risk-averse/seeking model owners who are concerned with the worst/best-cases mo
    
[^66]: 自监督分解表示学习用于鲁棒目标语音提取

    Self-Supervised Disentangled Representation Learning for Robust Target Speech Extraction. (arXiv:2312.10305v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2312.10305](http://arxiv.org/abs/2312.10305)

    该论文提出了一种自监督分解表示学习方法，通过逐步分离说话人身份信息和其他无关因素，解决了目标语音提取任务中存在的说话人混叠问题，并使用分解的说话人身份信息来指导语音提取网络。

    

    语音信号本质上是复杂的，因为它包含全局声学特征和局部语义信息。然而，在目标语音提取任务中，参考语音中与说话人身份无关的全局和局部语义信息可能导致在语音提取网络中出现说话人混叠问题。为了克服这个挑战，我们提出了一种自监督分解表示学习方法。我们的方法通过一个两阶段过程来解决这个问题，利用参考语音编码网络和全局信息分解网络逐渐分解说话人身份信息和其他不相关因素。我们专门使用分解的说话人身份信息来指导语音提取网络。此外，我们引入自适应调制Transformer来确保混合信号的声学表示不受说话人嵌入的影响。

    Speech signals are inherently complex as they encompass both global acoustic characteristics and local semantic information. However, in the task of target speech extraction, certain elements of global and local semantic information in the reference speech, which are irrelevant to speaker identity, can lead to speaker confusion within the speech extraction network. To overcome this challenge, we propose a self-supervised disentangled representation learning method. Our approach tackles this issue through a two-phase process, utilizing a reference speech encoding network and a global information disentanglement network to gradually disentangle the speaker identity information from other irrelevant factors. We exclusively employ the disentangled speaker identity information to guide the speech extraction network. Moreover, we introduce the adaptive modulation Transformer to ensure that the acoustic representation of the mixed signal remains undisturbed by the speaker embeddings. This com
    
[^67]: DSA透明数据库：社交媒体自我报告的审核行动

    The DSA Transparency Database: Auditing Self-reported Moderation Actions by Social Media. (arXiv:2312.10269v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2312.10269](http://arxiv.org/abs/2312.10269)

    DSA透明数据库对欧盟八大社交媒体平台在前100天提交的审核行动数据进行了全面分析，揭示了这些平台在审核行动方面的部分遵循程度。

    

    从2023年9月开始，数字服务法案(DSA)要求大型在线平台向DSA透明数据库提交关于他们在欧盟内采取的每个审核行动的详细数据。从一开始，这个集中式数据库就引起了学术界的兴趣，因为它是现实世界在线审核数据的一个前所未有的、可能是独特的宝库。在这里，我们深入分析了欧盟八个最大社交媒体平台在数据库的前100天提交的所有3.53亿条记录。具体而言，我们对平台之间进行了比较研究，包括：审核行动的数量、决策依据、应用的限制类型、审核内容类型、审核行动的及时性和提交情况，以及使用的自动化程度。此外，我们系统地与平台自己的透明报告进行了内容交叉检查。我们的分析揭示了以下结果。(i)平台只在一定程度上遵循了审核行动的哲学和方法论。

    Since September 2023, the Digital Services Act (DSA) obliges large online platforms to submit detailed data on each moderation action they take within the European Union (EU) to the DSA Transparency Database. From its inception, this centralized database has sparked scholarly interest as an unprecedented and potentially unique trove of data on real-world online moderation. Here, we thoroughly analyze all 353.12M records submitted by the eight largest social media platforms in the EU during the first 100 days of the database. Specifically, we conduct a platform-wise comparative study of their: volume of moderation actions, grounds for decision, types of applied restrictions, types of moderated content, timeliness in undertaking and submitting moderation actions, and use of automation. Furthermore, we systematically cross-check the contents of the database with the platforms' own transparency reports. Our analyses reveal that (i) the platforms adhered only in part to the philosophy and s
    
[^68]: ChatGPT能在初级编程课程中担任教学助理的角色吗？

    Can ChatGPT Play the Role of a Teaching Assistant in an Introductory Programming Course?. (arXiv:2312.07343v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2312.07343](http://arxiv.org/abs/2312.07343)

    这项研究探讨了将ChatGPT作为虚拟教学助理在初级编程课程中的潜力，并通过比较其在评分和反馈方面与人类教学助理的表现来评估其能力。

    

    大型语言模型（LLM）的出现预计将对教育产生重大影响。本文探讨了将ChatGPT作为虚拟教学助理（TA）在初级编程课程中使用的潜力。我们通过将ChatGPT的表现与人类TA在一些重要的TA职能上的表现进行比较来评估ChatGPT的能力。我们重点关注的TA职能包括：（1）对学生代码提交进行评分，以及（2）对初级编程课程的本科生提供反馈。首先，我们使用给定的评分标准评估ChatGPT在对学生代码提交进行评分方面的熟练程度，并将其表现与人类TA的评分进行比较。其次，我们分析ChatGPT提供的反馈的质量和相关性。这个评估考虑了ChatGPT在从代码正确性和代码质量两个方面如何解决错误并提供改进建议。最后，我们讨论了一些在使用ChatGPT作为教学助理时所面临的挑战和限制。

    The emergence of Large language models (LLMs) is expected to have a major impact on education. This paper explores the potential of using ChatGPT, an LLM, as a virtual Teaching Assistant (TA) in an Introductory Programming Course. We evaluate ChatGPT's capabilities by comparing its performance with that of human TAs in some of the important TA functions. The TA functions which we focus on include (1) grading student code submissions, and (2) providing feedback to undergraduate students in an introductory programming course. Firstly, we assess ChatGPT's proficiency in grading student code submissions using a given grading rubric and compare its performance with the grades assigned by human TAs. Secondly, we analyze the quality and relevance of the feedback provided by ChatGPT. This evaluation considers how well ChatGPT addresses mistakes and offers suggestions for improvement in student solutions from both code correctness and code quality perspectives. We conclude with a discussion on 
    
[^69]: 超越预期回报：评估强化学习算法时考虑政策可复制性

    Beyond Expected Return: Accounting for Policy Reproducibility when Evaluating Reinforcement Learning Algorithms. (arXiv:2312.07178v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.07178](http://arxiv.org/abs/2312.07178)

    本文提出了一种超越预期回报的评估方法，在强化学习中考虑策略的可复制性。现有的评估方法仅使用预期回报，无法充分考虑分布的扩散，这限制了其在比较策略时的有效性。

    

    在强化学习中，许多应用通常在环境中存在噪声或随机性。除了对学习的影响之外，这些不确定性导致相同的策略在不同的试验中表现不同，即产生不同的回报。强化学习中常用的评估程序仅使用预期回报来总结结果分布，而不考虑分布的扩散。我们的工作将这种扩散定义为政策的可复制性：当多次试验时，政策获得类似性能的能力，在一些实际应用中这是至关重要的属性。我们指出，现有的仅使用预期回报的程序在两个方面存在局限性：第一，存在无数个回报分布，具有广泛的性能和可复制性的权衡，但是它们可以有相同的预期回报，限制了它在比较策略时的有效性；第二，预期回报度量没有留下足够的空间，以描述分布的其他关键性质。

    Many applications in Reinforcement Learning (RL) usually have noise or stochasticity present in the environment. Beyond their impact on learning, these uncertainties lead the exact same policy to perform differently, i.e. yield different return, from one roll-out to another. Common evaluation procedures in RL summarise the consequent return distributions using solely the expected return, which does not account for the spread of the distribution. Our work defines this spread as the policy reproducibility: the ability of a policy to obtain similar performance when rolled out many times, a crucial property in some real-world applications. We highlight that existing procedures that only use the expected return are limited on two fronts: first an infinite number of return distributions with a wide range of performance-reproducibility trade-offs can have the same expected return, limiting its effectiveness when used for comparing policies; second, the expected return metric does not leave an
    
[^70]: 工业自动化系统中预测和健康管理基础模型的调查

    Survey on Foundation Models for Prognostics and Health Management in Industrial Cyber-Physical Systems. (arXiv:2312.06261v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.06261](http://arxiv.org/abs/2312.06261)

    工业自动化系统中的预测和健康管理基础模型的调查，着重介绍了大规模基础模型的重大进展和其在ICPS中的应用潜力。

    

    工业物联网系统（ICPS）整合了计算机科学、通信技术和工程学的学科，成为当代制造业和工业的必不可少的组成部分。然而，ICPS在长期运营中面临各种挑战，包括设备故障、性能下降和安全威胁。为了实现高效的维护和管理，预测和健康管理（PHM）在ICPS中得到广泛应用，包括故障预测、健康监测和维护决策。大规模基础模型（LFMs）如BERT和GPT的出现标志着人工智能技术的重大进展，而ChatGPT则是在这一研究范式中的一项重要成就，具有潜力成为通用人工智能。考虑到数据采集技术和数据处理能力的不断提高，LFMs预计将在ICPS中扮演重要角色。

    Industrial Cyber-Physical Systems (ICPS) integrate the disciplines of computer science, communication technology, and engineering, and have emerged as integral components of contemporary manufacturing and industries. However, ICPS encounters various challenges in long-term operation, including equipment failures, performance degradation, and security threats. To achieve efficient maintenance and management, prognostics and health management (PHM) finds widespread application in ICPS for critical tasks, including failure prediction, health monitoring, and maintenance decision-making. The emergence of large-scale foundation models (LFMs) like BERT and GPT signifies a significant advancement in AI technology, and ChatGPT stands as a remarkable accomplishment within this research paradigm, harboring potential for General Artificial Intelligence. Considering the ongoing enhancement in data acquisition technology and data processing capability, LFMs are anticipated to assume a crucial role i
    
[^71]: GNN2R: 基于弱监督的知识图谱问答中提供理由的问题回答方法

    GNN2R: Weakly-Supervised Rationale-Providing Question Answering over Knowledge Graphs. (arXiv:2312.02317v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.02317](http://arxiv.org/abs/2312.02317)

    GNN2R是一种基于图神经网络的两步推理模型，通过弱监督训练，能够在知识图谱问答中提供最终答案以及推理子图的理由。该方法解决了现有方法缺乏解释以及效率低下的问题。

    

    目前大多数基于知识图谱的多跳问题回答方法只提供最终的确定答案，而没有解释，对于普通用户难以理解和查看的KG实体集。这严重限制了知识图谱问答在现实场景中的应用。本文提出了一种基于图神经网络的两步推理模型（GNN2R）来解决这个问题。GNN2R能够通过仅有的问题-最终答案对提供最终答案以及作为最终答案背后的推理子图的理由，且仅需要通过弱监督进行训练。我们对GNN2R进行了大量评估，并进行了详细的实验。

    Most current methods for multi-hop question answering (QA) over knowledge graphs (KGs) only provide final conclusive answers without explanations, such as a set of KG entities that is difficult for normal users to review and comprehend. This issue severely limits the application of KG-based QA in real-world scenarios. However, it is non-trivial to solve due to two challenges: First, annotations of reasoning chains of multi-hop questions, which could serve as supervision for explanation generation, are usually lacking. Second, it is difficult to maintain high efficiency when explicit KG triples need to be retrieved to generate explanations. In this paper, we propose a novel Graph Neural Network-based Two-Step Reasoning model (GNN2R) to solve this issue. GNN2R can provide both final answers and reasoning subgraphs as a rationale behind final answers efficiently with only weak supervision that is available through question-final answer pairs. We extensively evaluated GNN2R with detailed a
    
[^72]: SNNs中基于关键性的高效修剪方法，受到关键性大脑假设的启发

    Criticality-Guided Efficient Pruning in Spiking Neural Networks Inspired by Critical Brain Hypothesis. (arXiv:2311.16141v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2311.16141](http://arxiv.org/abs/2311.16141)

    本研究受到神经科学中的关键大脑假设的启发，提出了一种基于神经元关键性的高效SNN修剪方法，以加强特征提取和加速修剪过程，并取得了比当前最先进方法更好的性能。

    

    由于其节能和无乘法特性，SNNs已经引起了相当大的关注。深度SNNs规模的不断增长给模型部署带来了挑战。网络修剪通过压缩网络规模来减少模型部署的硬件资源需求。然而，现有的SNN修剪方法由于修剪迭代增加了SNNs的训练难度，导致修剪成本高昂且性能损失严重。本文受到神经科学中的关键大脑假设的启发，提出了一种基于神经元关键性的用于SNN修剪的再生机制，以增强特征提取并加速修剪过程。首先，我们提出了一种SNN中用于关键性的低成本度量方式。然后，在修剪后对所修剪结构进行重新排序，并再生那些具有较高关键性的结构，以获取关键网络。我们的方法表现优于当前的最先进方法。

    Spiking Neural Networks (SNNs) have gained considerable attention due to the energy-efficient and multiplication-free characteristics. The continuous growth in scale of deep SNNs poses challenges for model deployment. Network pruning reduces hardware resource requirements of model deployment by compressing the network scale. However, existing SNN pruning methods cause high pruning costs and performance loss because the pruning iterations amplify the training difficulty of SNNs. In this paper, inspired by the critical brain hypothesis in neuroscience, we propose a regeneration mechanism based on the neuron criticality for SNN pruning to enhance feature extraction and accelerate the pruning process. Firstly, we propose a low-cost metric for the criticality in SNNs. Then, we re-rank the pruned structures after pruning and regenerate those with higher criticality to obtain the critical network. Our method achieves higher performance than the current state-of-the-art (SOTA) method with up t
    
[^73]: 将大规模语言模型作为策略教师来训练强化学习代理

    Large Language Model as a Policy Teacher for Training Reinforcement Learning Agents. (arXiv:2311.13373v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2311.13373](http://arxiv.org/abs/2311.13373)

    本论文介绍了一种用大规模语言模型作为教师来训练强化学习代理的框架，通过教师代理的指导，学生代理能够以更高效的方式训练，并且能够专门化于特定目标任务。

    

    最近的研究揭示了大规模语言模型（LLM）在通过提供高级指导来解决复杂的顺序决策任务方面的潜力。然而，基于LLM的代理缺乏专门化处理特定目标问题的能力，尤其是在实时动态环境中。此外，将基于LLM的代理部署到实际场景中可能既昂贵又耗时。另一方面，强化学习（RL）方法训练专门化于目标任务的代理，但往往遭受低采样效率和高探索成本的困扰。本文介绍了一个新颖的框架，通过使用LLM教师代理的指导来训练一个较小、专门化的学生RL代理来解决这些挑战。通过将教师代理的先前知识融入学生代理中，学生代理能够凝聚LLM的知识到自己的模型中。因此，学生代理可以用更少的数据进行训练。此外，

    Recent studies have uncovered the potential of Large Language Models (LLMs) in addressing complex sequential decision-making tasks through the provision of high-level instructions. However, LLM-based agents lack specialization in tackling specific target problems, particularly in real-time dynamic environments. Additionally, deploying an LLM-based agent in practical scenarios can be both costly and time-consuming. On the other hand, reinforcement learning (RL) approaches train agents that specialize in the target task but often suffer from low sampling efficiency and high exploration costs. In this paper, we introduce a novel framework that addresses these challenges by training a smaller, specialized student RL agent using instructions from an LLM-based teacher agent. By incorporating the guidance from the teacher agent, the student agent can distill the prior knowledge of the LLM into its own model. Consequently, the student agent can be trained with significantly less data. Moreover
    
[^74]: 通过自对抗攻击和系统提示的破解GPT-4V

    Jailbreaking GPT-4V via Self-Adversarial Attacks with System Prompts. (arXiv:2311.09127v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2311.09127](http://arxiv.org/abs/2311.09127)

    通过自对抗攻击和系统提示漏洞，我们发现了GPT-4V中存在的安全风险，并提出了一种名为SASP的新型攻击方法，以搜索潜在的破解提示。我们通过添加人工修改，成功率提高到98.7%。我们还评估了修改系统提示对解锁GPT-4V的影响。

    

    现有关于破解多模态大型语言模型（MLLMs）的工作主要集中在对模型输入的对抗性样本上，较少关注模型API的漏洞。为填补这一研究空白，我们进行了以下工作：1）我们发现了GPT-4V中的系统提示泄漏漏洞。通过精心设计的对话，我们成功提取了GPT-4V的内部系统提示。这一发现表明MLLMs存在潜在的可利用的安全风险；2）基于获取的系统提示，我们提出了一种称为SASP（通过系统提示的自对抗攻击）的新型MLLM破解攻击方法。通过将GPT-4作为红队工具来针对自身进行攻击，我们旨在利用窃取的系统提示搜索潜在的破解提示。此外，为了提高攻击成功率，我们还根据GPT-4的分析添加了人工修改，将攻击成功率进一步提高到98.7％；3）我们评估了修改系统提示对解锁GPT-4V的影响。

    Existing work on jailbreak Multimodal Large Language Models (MLLMs) has focused primarily on adversarial examples in model inputs, with less attention to vulnerabilities, especially in model API. To fill the research gap, we carry out the following work: 1) We discover a system prompt leakage vulnerability in GPT-4V. Through carefully designed dialogue, we successfully extract the internal system prompts of GPT-4V. This finding indicates potential exploitable security risks in MLLMs; 2) Based on the acquired system prompts, we propose a novel MLLM jailbreaking attack method termed SASP (Self-Adversarial Attack via System Prompt). By employing GPT-4 as a red teaming tool against itself, we aim to search for potential jailbreak prompts leveraging stolen system prompts. Furthermore, in pursuit of better performance, we also add human modification based on GPT-4's analysis, which further improves the attack success rate to 98.7\%; 3) We evaluated the effect of modifying system prompts to d
    
[^75]: 统一自然语言处理和软件工程视角：代码语言模型综述

    Unifying the Perspectives of NLP and Software Engineering: A Survey on Language Models for Code. (arXiv:2311.07989v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.07989](http://arxiv.org/abs/2311.07989)

    这篇论文系统地回顾了代码处理方面的语言模型的最新进展，涵盖了50多个模型、30多个评估任务、170多个数据集和700多个相关工作。它突出了代码建模从统计模型和RNN到预训练的Transformer和LLM之间的历史转变，并讨论了代码特定的特性和关键挑战。

    

    在这项工作中，我们系统地回顾了最近在代码处理中的语言模型方面的进展，涵盖了50多个模型、30多个评估任务、170多个数据集和700多个相关工作。我们将代码处理模型分为通用语言模型（如GPT系列）和专门在代码上预训练的模型，通常具有专门的目标。我们讨论了这些模型之间的关系和差异，并突出了代码建模从统计模型和RNN到预训练的Transformer和LLM之间的历史转变，这正是NLP也经历的过程。我们还讨论了代码特定的特性，如AST、CFG和单元测试，以及它们在训练代码语言模型中的应用，并确定了该领域中的关键挑战和潜在的未来方向。我们将这份综述保持开放，并在GitHub上更新，网址为https://github.com/codefuse-ai/Awesome-Code-LLM。

    In this work we systematically review the recent advancements in code processing with language models, covering 50+ models, 30+ evaluation tasks, 170+ datasets, and 700+ related works. We break down code processing models into general language models represented by the GPT family and specialized models that are specifically pretrained on code, often with tailored objectives. We discuss the relations and differences between these models, and highlight the historical transition of code modeling from statistical models and RNNs to pretrained Transformers and LLMs, which is exactly the same course that had been taken by NLP. We also discuss code-specific features such as AST, CFG, and unit tests, along with their application in training code language models, and identify key challenges and potential future directions in this domain. We keep the survey open and updated on GitHub at https://github.com/codefuse-ai/Awesome-Code-LLM.
    
[^76]: 用大型语言模型评估编程策略的可解释性

    Assessing the Interpretability of Programmatic Policies with Large Language Models. (arXiv:2311.06979v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2311.06979](http://arxiv.org/abs/2311.06979)

    本文介绍了一种使用大型语言模型评估编程策略可解释性的新方法，通过度量重建程序与原始程序的行为相似性来评估。这一方法在合成和人工制作的编程策略中得到了验证。

    

    尽管合成编码策略的程序通常带有可解释性的承诺，但从未进行过系统评估以评估这些策略的可解释性，很可能是因为这样的评估的复杂性。在本文中，我们引入了一种使用大型语言模型（LLM）评估编程策略可解释性的新方法。对于我们的度量，LLM同时提供了一个程序和其相关编程语言的描述。然后，LLM利用自然语言解释形成一个程序的解释。然后，将该解释输入到第二个LLM中，该LLM试图从自然语言解释中重建程序。然后，我们的度量衡量了重建程序与原始程序之间的行为相似性。我们将我们的方法通过合成和人工制作的用于玩实时策略游戏的编程策略进行验证，将这些编程策略的可解释性得分与混淆的策略进行比较。

    Although the synthesis of programs encoding policies often carries the promise of interpretability, systematic evaluations were never performed to assess the interpretability of these policies, likely because of the complexity of such an evaluation. In this paper, we introduce a novel metric that uses large-language models (LLM) to assess the interpretability of programmatic policies. For our metric, an LLM is given both a program and a description of its associated programming language. The LLM then formulates a natural language explanation of the program. This explanation is subsequently fed into a second LLM, which tries to reconstruct the program from the natural-language explanation. Our metric then measures the behavioral similarity between the reconstructed program and the original. We validate our approach with synthesized and human-crafted programmatic policies for playing a real-time strategy game, comparing the interpretability scores of these programmatic policies to obfusc
    
[^77]: 使用基于Transformer的序列模型进行MIMO均衡的上下文学习

    In-Context Learning for MIMO Equalization Using Transformer-Based Sequence Models. (arXiv:2311.06101v2 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2311.06101](http://arxiv.org/abs/2311.06101)

    本研究利用上下文学习技术解决了多输入多输出（MIMO）均衡的逆问题，基于任务的上下文中的导频符号和未知的衰落信道以及信噪比（SNR）水平。这种方法展示了在实践中的潜力。

    

    最近的研究表明，大型预训练的序列模型（例如基于Transformer的架构）具有进行上下文学习（ICL）的能力。在ICL中，通过将输入和任务的上下文中的几个示例直接映射到输出变量，对新输入进行决策。无需显式更新模型参数即可调整决策以适应新任务。预训练是一种元学习形式，可以观察几个相关任务的示例。先前的研究已经展示了线性回归的ICL能力。在本研究中，我们利用ICL来解决基于导频符号上下文的多输入多输出（MIMO）均衡的逆问题。一个任务由未知的衰落信道和信噪比（SNR）水平定义，可能是已知的。为了突显该方法的实际潜力，我们允许接收到的信号存在量化。

    Large pre-trained sequence models, such as transformer-based architectures, have been recently shown to have the capacity to carry out in-context learning (ICL). In ICL, a decision on a new input is made via a direct mapping of the input and of a few examples from the given task, serving as the task's context, to the output variable. No explicit updates of the model parameters are needed to tailor the decision to a new task. Pre-training, which amounts to a form of meta-learning, is based on the observation of examples from several related tasks. Prior work has shown ICL capabilities for linear regression. In this study, we leverage ICL to address the inverse problem of multiple-input and multiple-output (MIMO) equalization based on a context given by pilot symbols. A task is defined by the unknown fading channel and by the signal-to-noise ratio (SNR) level, which may be known. To highlight the practical potential of the approach, we allow the presence of quantization of the received s
    
[^78]: GPT-4V在医学影像中的多模态能力的全面研究

    A Comprehensive Study of GPT-4V's Multimodal Capabilities in Medical Imaging. (arXiv:2310.20381v1 [cs.CV])

    [http://arxiv.org/abs/2310.20381](http://arxiv.org/abs/2310.20381)

    本文对GPT-4V在医学影像中的多模态能力进行了全面研究和评估，发现其在生成描述性报告和医学VQA方面有潜力，但在某些评估指标上仍需改进。

    

    本文对GPT-4V在不同医学影像任务中的能力进行了全面评估，包括放射学报告生成、医学视觉问答(VQA)和视觉定位。尽管先前的研究探索了GPT-4V在医学影像中的性能，但据我们所知，我们的研究是首个基于公开可用基准的定量评估。我们的研究发现，当给出结构良好的提示时，GPT-4V在胸部X射线图像的生成描述性报告方面具有潜力。然而，在MIMIC-CXR数据集基准上的表现揭示了某些评估指标(如CIDEr)的改进空间。在医学VQA领域，GPT-4V在区分问题类型方面表现出熟练，但在准确度方面不及现有基准。此外，我们的分析发现常规评估指标如BLEU分数的局限性，呼吁开发更好的评价指标。

    This paper presents a comprehensive evaluation of GPT-4V's capabilities across diverse medical imaging tasks, including Radiology Report Generation, Medical Visual Question Answering (VQA), and Visual Grounding. While prior efforts have explored GPT-4V's performance in medical imaging, to the best of our knowledge, our study represents the first quantitative evaluation on publicly available benchmarks. Our findings highlight GPT-4V's potential in generating descriptive reports for chest X-ray images, particularly when guided by well-structured prompts. However, its performance on the MIMIC-CXR dataset benchmark reveals areas for improvement in certain evaluation metrics, such as CIDEr. In the domain of Medical VQA, GPT-4V demonstrates proficiency in distinguishing between question types but falls short of prevailing benchmarks in terms of accuracy. Furthermore, our analysis finds the limitations of conventional evaluation metrics like the BLEU score, advocating for the development of m
    
[^79]: Rosetta Stone在KSAA-RD共享任务中：从语言建模到词--定义对齐的跃进。

    Rosetta Stone at KSAA-RD Shared Task: A Hop From Language Modeling To Word--Definition Alignment. (arXiv:2310.15823v1 [cs.CL])

    [http://arxiv.org/abs/2310.15823](http://arxiv.org/abs/2310.15823)

    本论文介绍了在KSAA-RD共享任务中Rosetta Stone的应用，将语言建模应用到词--定义对齐中。论文通过使用一组微调的阿拉伯BERT模型来预测给定定义的词嵌入，从而实现了阿拉伯词的向量表示。

    

    反向词典是一种工具，可根据提供的定义、含义或描述来发现一个词。这种技术在各种场景中都非常有价值，可以帮助掌握一个词的描述而不知其身份的语言学习者，并使寻求精确术语的写作者受益。这些场景通常涵盖被称为“舌尖上的词”现象。在这项工作中，我们呈现了我们在阿拉伯语反向词典共享任务中获胜的解决方案。该任务的重点是从伴随的描述中推导出阿拉伯词的向量表示。共享任务包括两个不同的子任务：第一个子任务涉及一个阿拉伯定义作为输入，而第二个子任务则使用一个英文定义。对于第一个子任务，我们的方法依赖于一组经过微调的阿拉伯BERT模型，来预测给定定义的词嵌入。最终表示是通过对每个模型输出的嵌入进行平均得到的。

    A Reverse Dictionary is a tool enabling users to discover a word based on its provided definition, meaning, or description. Such a technique proves valuable in various scenarios, aiding language learners who possess a description of a word without its identity, and benefiting writers seeking precise terminology. These scenarios often encapsulate what is referred to as the "Tip-of-the-Tongue" (TOT) phenomena. In this work, we present our winning solution for the Arabic Reverse Dictionary shared task. This task focuses on deriving a vector representation of an Arabic word from its accompanying description. The shared task encompasses two distinct subtasks: the first involves an Arabic definition as input, while the second employs an English definition. For the first subtask, our approach relies on an ensemble of finetuned Arabic BERT-based models, predicting the word embedding for a given definition. The final representation is obtained through averaging the output embeddings from each m
    
[^80]: 基于场景级监督的点云分割的2D-3D交错Transformer模型

    2D-3D Interlaced Transformer for Point Cloud Segmentation with Scene-Level Supervision. (arXiv:2310.12817v1 [cs.CV])

    [http://arxiv.org/abs/2310.12817](http://arxiv.org/abs/2310.12817)

    本文提出了一种基于场景级监督的2D-3D交错Transformer模型，用于弱监督点云分割。该模型通过两个编码器计算2D和3D数据的自注意特征，并通过交替切换查询和键值对的角色，实现了2D和3D特征的融合。

    

    本文提出了一种多模态交错Transformer模型（MIT），用于考虑2D和3D数据进行弱监督点云分割。研究表明，2D和3D特征在点云分割中互补。然而，现有方法需要额外的2D注释来实现2D-3D信息融合。鉴于点云的高注释成本，基于弱监督学习的有效2D和3D特征融合需求非常迫切。为此，我们提出了一个具有两个编码器和一个解码器的Transformer模型，仅使用场景级类标签进行弱监督点云分割。具体而言，两个编码器分别计算3D点云和2D多视图图像的自注意特征。解码器实现交错的2D-3D交叉注意力，并进行隐式2D和3D特征融合。我们在解码器层中交替切换查询和键值对的角色。实验证明，2D和3D特征是互补的。

    We present a Multimodal Interlaced Transformer (MIT) that jointly considers 2D and 3D data for weakly supervised point cloud segmentation. Research studies have shown that 2D and 3D features are complementary for point cloud segmentation. However, existing methods require extra 2D annotations to achieve 2D-3D information fusion. Considering the high annotation cost of point clouds, effective 2D and 3D feature fusion based on weakly supervised learning is in great demand. To this end, we propose a transformer model with two encoders and one decoder for weakly supervised point cloud segmentation using only scene-level class tags. Specifically, the two encoders compute the self-attended features for 3D point clouds and 2D multi-view images, respectively. The decoder implements interlaced 2D-3D cross-attention and carries out implicit 2D and 3D feature fusion. We alternately switch the roles of queries and key-value pairs in the decoder layers. It turns out that the 2D and 3D features are 
    
[^81]: 现实世界中的无线电地图估计：经验证和分析

    Radio Map Estimation in the Real-World: Empirical Validation and Analysis. (arXiv:2310.11036v1 [eess.SP])

    [http://arxiv.org/abs/2310.11036](http://arxiv.org/abs/2310.11036)

    本文通过对现有的无线电地图估计器进行经验证据的评估，研究了性能和复杂性之间的权衡以及快速衰落的影响。尽管基于深度神经网络的估计器表现最佳，但需要大量的训练数据。一种混合了传统方案和深度神经网络的新算法表现良好。

    

    无线电地图在地理区域的每个点上量化了接收信号强度或其他无线电频率环境的大小。这些地图在无线网络规划、频谱管理和通信系统优化等众多应用中起着重要作用。然而，对现有的大量无线电地图估计器的经验证据非常有限。为了填补这一空白，使用自主无人机（UAV）收集了大量的测量数据，并对这些估计器的代表性子集进行了评估。在这些评估中，广泛研究了性能和复杂性之间的权衡以及快速衰落的影响。尽管基于深度神经网络（DNN）的复杂估计器表现最佳，但它们需要大量的训练数据才能相对传统方案提供实质性优势。一种混合了两种类型估计器的新算法被发现具有良好的性能。

    Radio maps quantify received signal strength or other magnitudes of the radio frequency environment at every point of a geographical region. These maps play a vital role in a large number of applications such as wireless network planning, spectrum management, and optimization of communication systems. However, empirical validation of the large number of existing radio map estimators is highly limited. To fill this gap, a large data set of measurements has been collected with an autonomous unmanned aerial vehicle (UAV) and a representative subset of these estimators were evaluated on this data. The performance-complexity trade-off and the impact of fast fading are extensively investigated. Although sophisticated estimators based on deep neural networks (DNNs) exhibit the best performance, they are seen to require large volumes of training data to offer a substantial advantage relative to more traditional schemes. A novel algorithm that blends both kinds of estimators is seen to enjoy th
    
[^82]: 通过基于文本的分解解释CLIP图像表示

    Interpreting CLIP's Image Representation via Text-Based Decomposition. (arXiv:2310.05916v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2310.05916](http://arxiv.org/abs/2310.05916)

    本文通过解析CLIP图像编码器的组件，揭示了图像表示的构成方式，并利用文本表示解释了其各个部分的作用。通过理解注意力头和图像块，作者实现了对模型的修复和改进，包括消除误特征和构建零样本图像分割器等方面。

    

    本文通过分析个别模型组件对最终表示的影响，探讨了CLIP图像编码器。我们将图像表示分解为各个图像块、模型层和注意力头的求和，并使用CLIP的文本表示来解释这些求和项。通过解释注意力头，我们通过自动寻找能够跨越输出空间的文本表示来表征每个头的作用，揭示出许多头的特定属性角色（例如位置或形状）。接下来，通过解释图像块，我们揭示了CLIP中的紧密空间定位。最后，我们利用这一理解消除了CLIP中的误特征，并创建了一个强大的零样本图像分割器。我们的结果表明，可扩展的对Transformer模型的理解是可实现的，并可用于修复和改进模型。

    We investigate the CLIP image encoder by analyzing how individual model components affect the final representation. We decompose the image representation as a sum across individual image patches, model layers, and attention heads, and use CLIP's text representation to interpret the summands. Interpreting the attention heads, we characterize each head's role by automatically finding text representations that span its output space, which reveals property-specific roles for many heads (e.g. location or shape). Next, interpreting the image patches, we uncover an emergent spatial localization within CLIP. Finally, we use this understanding to remove spurious features from CLIP and to create a strong zero-shot image segmenter. Our results indicate that a scalable understanding of transformer models is attainable and can be used to repair and improve models.
    
[^83]: MathVista: 用GPT-4V、Bard和其他大型多模态模型评估视觉场景中的数学推理能力

    MathVista: Evaluating Math Reasoning in Visual Contexts with GPT-4V, Bard, and Other Large Multimodal Models. (arXiv:2310.02255v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2310.02255](http://arxiv.org/abs/2310.02255)

    本论文提出了MathVista，这是一个评估视觉场景中数学推理能力的基准测试。通过对12个著名的基础模型进行全面的定量评估，发现最好的GPT-4V模型相对于第二名的Bard模型在准确率上提升了15.1%。

    

    大型语言模型（LLMs）和大型多模态模型（LMMs）在许多任务和领域中展示出令人印象深刻的问题解决能力，但它们在视觉环境中的数学推理能力尚未得到系统研究。为了弥补这一差距，我们提出了MathVista，这是一个综合了不同数学和视觉任务的挑战的基准测试。它包含了6141个例子，其中有28个现有的多模态数据集和3个新创建的数据集（即IQTest、FunctionQA和PaperQA）。完成这些任务需要精细的、深入的视觉理解和组合推理，这些都是当前最先进的基础模型所面临的困难。通过MathVista，我们对12个著名的基础模型进行了全面的定量评估。表现最好的GPT-4V模型的整体准确率为49.9%，明显优于第二名的Bard模型，相差15.1%。我们的深入分析揭示了

    Large Language Models (LLMs) and Large Multimodal Models (LMMs) exhibit impressive problem-solving skills in many tasks and domains, but their ability in mathematical reasoning in visual contexts has not been systematically studied. To bridge this gap, we present MathVista, a benchmark designed to combine challenges from diverse mathematical and visual tasks. It consists of 6,141 examples, derived from 28 existing multimodal datasets involving mathematics and 3 newly created datasets (i.e., IQTest, FunctionQA, and PaperQA). Completing these tasks requires fine-grained, deep visual understanding and compositional reasoning, which all state-of-the-art foundation models find challenging. With MathVista, we have conducted a comprehensive, quantitative evaluation of 12 prominent foundation models. The best-performing GPT-4V model achieves an overall accuracy of 49.9%, substantially outperforming Bard, the second-best performer, by 15.1%. Our in-depth analysis reveals that the superiority of
    
[^84]: TWIZ-v2: 多模态对话刺激的巫师

    TWIZ-v2: The Wizard of Multimodal Conversational-Stimulus. (arXiv:2310.02118v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.02118](http://arxiv.org/abs/2310.02118)

    TWIZ-v2是一个多模态对话刺激的巫师助手，旨在通过以人性化的方式提供信息、利用多种模态进行刺激以及改进对未见过场景的交互鲁棒性来引导用户成功完成复杂的手动任务。

    

    在本报告中，我们描述了Task Wizard团队TWIZ在Alexa Prize TaskBot Challenge 2022中的愿景、挑战和科学贡献。我们的愿景是构建TWIZ机器人作为一个有用、多模态、知识丰富和引人入胜的助手，可以引导用户成功完成复杂的手动任务。为了实现这一目标，我们将我们的努力集中在三个主要的研究问题上：（1）以人性化的对话方式提供信息；（2）利用声音、图像和视频等各种模态进行多模态刺激；（3）零-shot对话流程，以提高对未见过场景的交互的鲁棒性。TWIZ是一个能支持各种任务的助手，具有创新的功能，如创意烹饪、通过声音导航视频和强大的TWIZ-LLM，一个用于复杂手动任务对话的大型语言模型。根据用户提供的评级和反馈，我们观察到

    In this report, we describe the vision, challenges, and scientific contributions of the Task Wizard team, TWIZ, in the Alexa Prize TaskBot Challenge 2022. Our vision, is to build TWIZ bot as an helpful, multimodal, knowledgeable, and engaging assistant that can guide users towards the successful completion of complex manual tasks. To achieve this, we focus our efforts on three main research questions: (1) Humanly-Shaped Conversations, by providing information in a knowledgeable way; (2) Multimodal Stimulus, making use of various modalities including voice, images, and videos; and (3) Zero-shot Conversational Flows, to improve the robustness of the interaction to unseen scenarios. TWIZ is an assistant capable of supporting a wide range of tasks, with several innovative features such as creative cooking, video navigation through voice, and the robust TWIZ-LLM, a Large Language Model trained for dialoguing about complex manual tasks. Given ratings and feedback provided by users, we observ
    
[^85]: LanguageBind:通过基于语义对齐的语言将视频-语言预训练扩展到N模态（arXiv:2310.01852v1[cs.CV]）

    LanguageBind: Extending Video-Language Pretraining to N-modality by Language-based Semantic Alignment. (arXiv:2310.01852v1 [cs.CV])

    [http://arxiv.org/abs/2310.01852](http://arxiv.org/abs/2310.01852)

    LanguageBind提出了将语言作为不同模态之间纽带的方法，通过冻结视频-语言预训练获取的语言编码器，并使用对比学习训练其他模态的编码器，实现了多模态的语义对齐。此外，作者还提出了VIDAL-10M数据集来支持该方法。

    

    视频-语言（VL）预训练在多个下游任务中取得了显著的进展。然而，当前的VL预训练框架难以将其扩展到除视觉和语言之外的多模态（N模态，N>=3）。因此，我们提出了LanguageBind，通过将语言作为不同模态之间的纽带，因为语言模态已经得到了很好的探索，包含丰富的语义信息。具体而言，我们使用VL预训练获取的语言编码器，并通过对比学习训练其他模态的编码器。结果是，所有模态被映射到一个共享的特征空间中，实现了多模态的语义对齐。虽然LanguageBind可以扩展VL模态到N模态，但我们还需要一个带有以语言为中心的对齐数据对的高质量数据集。因此，我们提出了VIDAL-10M，其中包含了视频、红外、深度、音频及其相应的语言数据，命名为VIDAL-10M。

    The video-language (VL) pretraining has achieved remarkable improvement in multiple downstream tasks. However, the current VL pretraining framework is hard to extend to multiple modalities (N modalities, N>=3) beyond vision and language. We thus propose LanguageBind, taking the language as the bind across different modalities because the language modality is well-explored and contains rich semantics. Specifically, we freeze the language encoder acquired by VL pretraining, then train encoders for other modalities with contrastive learning. As a result, all modalities are mapped to a shared feature space, implementing multi-modal semantic alignment. While LanguageBind ensures that we can extend VL modalities to N modalities, we also need a high-quality dataset with alignment data pairs centered on language. We thus propose VIDAL-10M with Video, Infrared, Depth, Audio and their corresponding Language, naming as VIDAL-10M. In our VIDAL-10M, all videos are from short video platforms with co
    
[^86]: FashionFlow: 利用扩散模型从静态图像生成动态时尚视频

    FashionFlow: Leveraging Diffusion Models for Dynamic Fashion Video Synthesis from Static Imagery. (arXiv:2310.00106v1 [cs.CV])

    [http://arxiv.org/abs/2310.00106](http://arxiv.org/abs/2310.00106)

    本研究提出了一种名为FashionFlow的图像到视频生成器，利用扩散模型从静态图像生成短视频。我们通过开发并连接与扩散模型相关的组件来实现这一目标，其中包括使用伪3D卷积层高效生成视频，并利用VAE和CLIP编码器捕捉关键特征。研究结果展示了成功合成时尚视频的能力，能够展示服装的合身度和外观，为在线时尚行业的购物体验提供改进和增强的潜力。

    

    我们的研究介绍了一种新的图像到视频生成器，称为FashionFlow。通过利用扩散模型，我们能够从静态图像创建短视频。我们的方法涉及开发并连接与扩散模型相关的组件，这使得我们的工作与众不同。这些组件包括使用伪3D卷积层高效生成视频。VAE和CLIP编码器从静态图像中捕捉到重要特征，以影响扩散模型。我们的研究展示了成功合成具有不同角度的模特一边摆姿势，展示服装的合身度和外观的时尚视频。我们的发现对于改进和提升在线时尚行业的购物体验有很大的潜力。

    Our study introduces a new image-to-video generator called FashionFlow. By utilising a diffusion model, we are able to create short videos from still images. Our approach involves developing and connecting relevant components with the diffusion model, which sets our work apart. The components include the use of pseudo-3D convolutional layers to generate videos efficiently. VAE and CLIP encoders capture vital characteristics from still images to influence the diffusion model. Our research demonstrates a successful synthesis of fashion videos featuring models posing from various angles, showcasing the fit and appearance of the garment. Our findings hold great promise for improving and enhancing the shopping experience for the online fashion industry.
    
[^87]: 决策树策略在IBMDP中的Actor-Critic算法的局限性（arXiv:2309.13365v2 [cs.LG] UPDATED）

    Limits of Actor-Critic Algorithms for Decision Tree Policies Learning in IBMDPs. (arXiv:2309.13365v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.13365](http://arxiv.org/abs/2309.13365)

    该论文研究了在IBMDP中使用Actor-Critic算法学习决策树策略的局限性。结果表明，即使是在简单的玩具任务上，深度RL也可能失败。

    

    AI模型的可解释性可以通过用户安全检查来建立对这些AI的信任。特别是，决策树（DT）提供了对学习模型的整体视角，并透明地揭示了哪些输入特征对于做出决策至关重要。然而，如果决策树过大，可解释性就会受到影响。为了学习紧凑的决策树，最近提出了一种强化学习（RL）框架，用于使用深度RL探索DT的空间。该框架通过增加动作来收集关于隐藏输入特征的信息，通过适当地对这些动作进行惩罚，代理学习如何在树的大小和性能之间进行最优权衡。在实践中，仍然存在一个开放问题，即需要学习部分可观察马尔可夫决策过程（MDP）的反应性策略。本文表明，即使在这一类简单的玩具任务上，深度RL也可能失败。

    Interpretability of AI models allows for user safety checks to build trust in such AIs. In particular, Decision Trees (DTs) provide a global look at the learned model and transparently reveal which features of the input are critical for making a decision. However, interpretability is hindered if the DT is too large. To learn compact trees, a recent Reinforcement Learning (RL) framework has been proposed to explore the space of DTs using deep RL. This framework augments a decision problem (e.g. a supervised classification task) with additional actions that gather information about the features of an otherwise hidden input. By appropriately penalizing these actions, the agent learns to optimally trade-off size and performance of DTs. In practice, a reactive policy for a partially observable Markov decision process (MDP) needs to be learned, which is still an open problem. We show in this paper that deep RL can fail even on simple toy tasks of this class. However, when the underlying deci
    
[^88]: 坏角色好顾问：探索大型语言模型在假新闻检测中的作用

    Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection. (arXiv:2309.12247v1 [cs.CL])

    [http://arxiv.org/abs/2309.12247](http://arxiv.org/abs/2309.12247)

    大型语言模型对于假新闻检测的潜力仍未得到充分探索。实证研究发现，尽管复杂的大型语言模型能够揭示假新闻并提供多角度解释，但仍不如经过fine-tuned的小型语言模型表现出色。当前的大型语言模型可能无法取代小型语言模型，但可以作为一个良好的辅助顾问。

    

    检测假新闻需要对多样线索有敏锐的感知和对现实世界背景有深入的理解，对于基于小型语言模型的检测器来说，由于其知识和能力的限制，这仍然是具有挑战性的。近期大型语言模型的进步在各种任务中表现出了卓越的性能，但大型语言模型能否以及如何帮助假新闻检测仍然未经过深入研究。在本文中，我们研究了大型语言模型在假新闻检测中的潜力。首先，我们进行了实证研究，发现像GPT 3.5这样的复杂大型语言模型通常能够揭示假新闻并提供理想的多角度解释，但仍然不如基础小型语言模型fine-tuned BERT表现出色。我们随后的分析将这种差距归因于大型语言模型不能正确选择并整合证据以得出结论。基于这些发现，我们提出当前的大型语言模型可能无法取代在假新闻检测中经过fine-tuned的小型语言模型，但可以作为一个良好的辅助顾问。

    Detecting fake news requires both a delicate sense of diverse clues and a profound understanding of the real-world background, which remains challenging for detectors based on small language models (SLMs) due to their knowledge and capability limitations. Recent advances in large language models (LLMs) have shown remarkable performance in various tasks, but whether and how LLMs could help with fake news detection remains underexplored. In this paper, we investigate the potential of LLMs in fake news detection. First, we conduct an empirical study and find that a sophisticated LLM such as GPT 3.5 could generally expose fake news and provide desirable multi-perspective rationales but still underperforms the basic SLM, fine-tuned BERT. Our subsequent analysis attributes such a gap to the LLM's inability to select and integrate rationales properly to conclude. Based on these findings, we propose that current LLMs may not substitute fine-tuned SLMs in fake news detection but can be a good a
    
[^89]: ChaCha：利用大型语言模型引导儿童分享与个人事件相关的情绪

    ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events. (arXiv:2309.12244v1 [cs.HC])

    [http://arxiv.org/abs/2309.12244](http://arxiv.org/abs/2309.12244)

    ChaCha是一个利用大型语言模型（LLMs）的聊天机器人，鼓励儿童分享个人事件和相关情绪。通过一个探索性研究，发现儿童将ChaCha视为亲密的朋友，并愿意与其分享各种主题的故事。

    

    儿童通常通过与家人或他人分享故事和感受来学习辨识和表达情绪，然而，由于儿童正在发展他们的交流技能，父母或兄弟姐妹很难与他们进行情感沟通。本文介绍了ChaCha，一个鼓励和引导儿童分享个人事件和相关情绪的聊天机器人。ChaCha结合了状态机和大型语言模型（LLMs），在进行自由对话的同时保持对话的方向性。通过与20名年龄在8-12岁的儿童进行的探索性研究，我们研究了ChaCha如何促使儿童分享个人事件并引导他们描述相关情绪。参与者认为ChaCha就像一个亲密的朋友，并分享了各种主题的故事，如家庭旅行和个人成就。基于定量和定性发现，我们讨论了利用LLMs设计适合儿童的聊天机器人的机遇。

    Children typically learn to identify and express emotions through sharing their stories and feelings with others, particularly their family. However, it is challenging for parents or siblings to have emotional communication with children since children are still developing their communication skills. We present ChaCha, a chatbot that encourages and guides children to share personal events and associated emotions. ChaCha combines a state machine and large language models (LLMs) to keep the dialogue on track while carrying on free-form conversations. Through an exploratory study with 20 children (aged 8-12), we examine how ChaCha prompts children to share personal events and guides them to describe associated emotions. Participants perceived ChaCha as a close friend and shared their stories on various topics, such as family trips and personal achievements. Based on the quantitative and qualitative findings, we discuss opportunities for leveraging LLMs to design child-friendly chatbots to
    
[^90]: 具有神经图模型的联邦学习

    Federated Learning with Neural Graphical Models. (arXiv:2309.11680v1 [cs.LG])

    [http://arxiv.org/abs/2309.11680](http://arxiv.org/abs/2309.11680)

    本研究提出了一种名为FedNGMs的联邦学习框架，利用概率神经图模型来处理多个客户端的数据，并在保持训练数据私密性的同时提升模型准确性。

    

    联邦学习（FL）解决了在多个客户端保留对数据的独占控制的同时，基于专有数据创建模型的需求。近期提出的神经图模型（NGMs）是概率图模型，利用神经网络的表达能力学习输入特征之间的复杂非线性依赖关系。它们学会捕捉底层的数据分布，并具有高效的推理和采样算法。我们开发了一个FL框架，它维护一个全局的NGM模型，从本地NGM模型中学习到平均信息，同时保持训练数据在客户端的环境中。我们的设计FedNGMs避免了神经元匹配框架（如联邦匹配平均）中模型参数爆炸的缺点和不足。我们的全局模型大小在整个过程中保持不变。

    Federated Learning (FL) addresses the need to create models based on proprietary data in such a way that multiple clients retain exclusive control over their data, while all benefit from improved model accuracy due to pooled resources. Recently proposed Neural Graphical Models (NGMs) are Probabilistic Graphical models that utilize the expressive power of neural networks to learn complex non-linear dependencies between the input features. They learn to capture the underlying data distribution and have efficient algorithms for inference and sampling. We develop a FL framework which maintains a global NGM model that learns the averaged information from the local NGM models while keeping the training data within the client's environment. Our design, FedNGMs, avoids the pitfalls and shortcomings of neuron matching frameworks like Federated Matched Averaging that suffers from model parameter explosion. Our global model size remains constant throughout the process. In the cases where clients 
    
[^91]: SingFake：唱歌声音Deepfake检测

    SingFake: Singing Voice Deepfake Detection. (arXiv:2309.07525v1 [cs.SD])

    [http://arxiv.org/abs/2309.07525](http://arxiv.org/abs/2309.07525)

    本文提出了唱歌声音Deepfake检测任务，并通过提供一个特定的数据集和评估系统的方法，对这一问题进行了研究和解决。

    

    合成唱歌声音的兴起给艺术家和行业利益相关者带来了未经授权的声音使用的重要挑战。与合成语音不同，合成唱歌声音通常在包含强烈背景音乐的歌曲中发布，这可能掩盖了合成造成的瑕疵。此外，唱歌声音与语音话语具有不同的声学和语言特征。这些独特的属性使得唱歌声音Deepfake检测成为一个相关但显着不同于合成语音检测的问题。在本文中，我们提出了唱歌声音Deepfake检测任务。首先，我们提供了SingFake，这是一个在野外精选的数据集，包含了40位歌手用五种语言演唱的28.93小时真实音频和29.40小时的Deepfake音频。我们提供了一个训练/验证/测试的划分，其中测试集包括不同的场景。然后，我们使用SingFake评估了四个在语音话语训练的最先进的语音对抗系统。我们发现这些系统在唱歌声音上的表现不同于在语音话语上的表现。

    The rise of singing voice synthesis presents critical challenges to artists and industry stakeholders over unauthorized voice usage. Unlike synthesized speech, synthesized singing voices are typically released in songs containing strong background music that may hide synthesis artifacts. Additionally, singing voices present different acoustic and linguistic characteristics from speech utterances. These unique properties make singing voice deepfake detection a relevant but significantly different problem from synthetic speech detection. In this work, we propose the singing voice deepfake detection task. We first present SingFake, the first curated in-the-wild dataset consisting of 28.93 hours of bonafide and 29.40 hours of deepfake song clips in five languages from 40 singers. We provide a train/val/test split where the test sets include various scenarios. We then use SingFake to evaluate four state-of-the-art speech countermeasure systems trained on speech utterances. We find these sys
    
[^92]: 作为有效抽象的归纳偏好的关系瓶颈

    The Relational Bottleneck as an Inductive Bias for Efficient Abstraction. (arXiv:2309.06629v1 [cs.AI])

    [http://arxiv.org/abs/2309.06629](http://arxiv.org/abs/2309.06629)

    本文介绍了一种新的归纳偏好方法——关系瓶颈，用于有效地诱导抽象概念的模型，强调了其在人类思维和大脑中抽象概念习得中的潜力。

    

    认知科学的一个核心挑战是解释如何从有限经验中获取抽象概念。这一努力常常被描述为经验主义和天赋主义方法之间的二分法，最近主要体现在有关深度神经网络和符号认知模型的争论中。在这里，我们强调了一种最近兴起的工作线路，该线路通过利用我们称之为关系瓶颈的归纳偏好，提出了这些方法的一种新的调和方式。我们回顾了一系列采用这种方法在数据有效的方式下诱导出抽象的模型，强调了它们作为人类思维和大脑中抽象概念习得的候选模型的潜力。

    A central challenge for cognitive science is to explain how abstract concepts are acquired from limited experience. This effort has often been framed in terms of a dichotomy between empiricist and nativist approaches, most recently embodied by debates concerning deep neural networks and symbolic cognitive models. Here, we highlight a recently emerging line of work that suggests a novel reconciliation of these approaches, by exploiting an inductive bias that we term the relational bottleneck. We review a family of models that employ this approach to induce abstractions in a data-efficient manner, emphasizing their potential as candidate models for the acquisition of abstract concepts in the human mind and brain.
    
[^93]: DePT:分解提示调整以实现参数高效微调

    DePT: Decomposed Prompt Tuning for Parameter-Efficient Fine-tuning. (arXiv:2309.05173v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.05173](http://arxiv.org/abs/2309.05173)

    DePT通过将软提示分解为较短的软提示和一对低秩矩阵，并用两个不同的学习率来优化，以解决提示调整对训练和推理时间以及内存使用的影响，从而实现更好的性能。

    

    提示调整（PT）是一种将可训练的少量软提示向量附加到语言模型（LM）输入中的参数高效微调（PEFT）方法，已在各种任务和模型中显示出了有希望的结果。 与其他PEFT方法相比，PT的竞争性能可以在可训练参数更少的情况下保持，并且随着模型规模的扩大，其参数并不会显著增加。 但是，PT引入了额外的软提示标记，导致输入序列变长，这对于Transformer的二次复杂度而言，在训练和推理时间以及内存使用方面会产生显著影响。 这对于面临大量每日查询的大型语言模型（LLMs）尤其令人担忧。

    Prompt tuning (PT), where a small amount of trainable soft (continuous) prompt vectors is affixed to the input of language models (LM), has shown promising results across various tasks and models for parameter-efficient fine-tuning (PEFT). PT stands out from other PEFT approaches because it maintains competitive performance with fewer trainable parameters and does not drastically scale up its parameters as the model size expands. However, PT introduces additional soft prompt tokens, leading to longer input sequences, which significantly impacts training and inference time and memory usage due to the Transformer's quadratic complexity. Particularly concerning for Large Language Models (LLMs) that face heavy daily querying. To address this issue, we propose Decomposed Prompt Tuning (DePT), which decomposes the soft prompt into a shorter soft prompt and a pair of low-rank matrices that are then optimised with two different learning rates. This allows DePT to achieve better performance whi
    
[^94]: 去殖民化的人工智能对齐：威色达尔玛、论证和艺术表达

    Decolonial AI Alignment: Vi\'{s}esadharma, Argument, and Artistic Expression. (arXiv:2309.05030v1 [cs.CY])

    [http://arxiv.org/abs/2309.05030](http://arxiv.org/abs/2309.05030)

    本文提出了去殖民化人工智能对齐的三个建议：改变基本道德哲学为达尔玛哲学，允许多元主义的论证传统存在于对齐技术中，以及将价值认识论扩展到超越自然语言中的指令。

    

    先前的研究已经阐明了人工智能（AI）开发和部署的殖民性。然而，这些研究很少涉及到对齐：即基于细致的人类反馈，调整大型语言模型（LLM）的行为与期望值一致。除了其他实践，殖民主义还有一部分是改变被殖民民族的信仰和价值观的历史；而当前的LLM对齐实践正是这一历史的复制。我们建议通过三个提议对AI对齐进行去殖民化：（a）将基本道德哲学从西方哲学转变为达尔玛哲学，（b）在对齐技术中允许论证和多元主义的传统，以及（c）将价值的认识论扩展到超越自然语言中的指令或命令。

    Prior work has explicated the coloniality of artificial intelligence (AI) development and deployment. One process that that work has not engaged with much is alignment: the tuning of large language model (LLM) behavior to be in line with desired values based on fine-grained human feedback. In addition to other practices, colonialism has a history of altering the beliefs and values of colonized peoples; this history is recapitulated in current LLM alignment practices. We suggest that AI alignment be decolonialized using three proposals: (a) changing the base moral philosophy from Western philosophy to dharma, (b) permitting traditions of argument and pluralism in alignment technologies, and (c) expanding the epistemology of values beyond instructions or commandments given in natural language.
    
[^95]: ChatRule：利用大型语言模型挖掘知识图谱推理中的逻辑规则

    ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning. (arXiv:2309.01538v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2309.01538](http://arxiv.org/abs/2309.01538)

    本论文提出了一个框架ChatRule，利用大型语言模型挖掘知识图谱中的逻辑规则。该框架通过充分利用知识图谱的语义和结构信息，能够提高推理性能并提供可解释的结果。

    

    逻辑规则对于发现关系之间的逻辑连接至关重要，可以提高推理性能并提供可解释的知识图谱结果。尽管已经有许多努力在知识图谱上挖掘有意义的逻辑规则，但现有方法在规则空间上搜索计算密集且缺乏可伸缩性，尤其是对于大规模知识图谱。此外，它们常常忽视了关系的语义，而这对于揭示逻辑连接至关重要。最近，大型语言模型（LLMs）在自然语言处理领域和各种应用中展现出了令人瞩目的性能，归功于它们的新能力和泛化能力。在本文中，我们提出了一个新颖的框架ChatRule，利用大型语言模型挖掘知识图谱中的逻辑规则。具体而言，该框架以基于LLM的规则生成器为初始，充分利用了知识图谱的语义和结构信息。

    Logical rules are essential for uncovering the logical connections between relations, which could improve the reasoning performance and provide interpretable results on knowledge graphs (KGs). Although there have been many efforts to mine meaningful logical rules over KGs, existing methods suffer from the computationally intensive searches over the rule space and a lack of scalability for large-scale KGs. Besides, they often ignore the semantics of relations which is crucial for uncovering logical connections. Recently, large language models (LLMs) have shown impressive performance in the field of natural language processing and various applications, owing to their emergent ability and generalizability. In this paper, we propose a novel framework, ChatRule, unleashing the power of large language models for mining logical rules over knowledge graphs. Specifically, the framework is initiated with an LLM-based rule generator, leveraging both the semantic and structural information of KGs 
    
[^96]: 在移动设备上进行十亿规模语言模型的联邦微调

    Federated Fine-tuning of Billion-Sized Language Models across Mobile Devices. (arXiv:2308.13894v1 [cs.AI])

    [http://arxiv.org/abs/2308.13894](http://arxiv.org/abs/2308.13894)

    这项工作引入了一种创新的FL协议FwdLLM，旨在提高在移动设备上进行十亿规模语言模型的联邦微调（FedLLM）的效率。FwdLLM通过使用无反向传播（BP）训练方法以及“扰动推断”来提高内存效率和时间效率。

    

    大规模语言模型（LLM）正在改变移动智能的格局。联邦学习（FL）是一种保护用户数据隐私的方法，通常用于对下游移动任务进行LLM的微调，这被称为FedLLM。尽管最近的研究已经解决了由庞大模型大小引起的网络问题，但它们在与移动设备的整合方面并没有实际缓解诸多挑战，比如显著的内存消耗和缓慢的模型收敛。为了应对这些挑战，本研究引入了一种创新的FL协议FwdLLM，旨在提高FedLLM的效率。FwdLLM的关键思想是采用无反向传播（BP）训练方法，只需要设备执行“扰动推断”。因此，FwdLLM具有更好的内存效率和时间效率（通过移动NPUs和扩大的参与设备数组）。FwdLLM围绕三个关键设计展开：（1）将无反向传播训练与p

    Large Language Models (LLMs) are transforming the landscape of mobile intelligence. Federated Learning (FL), a method to preserve user data privacy, is often employed in fine-tuning LLMs to downstream mobile tasks, an approach known as FedLLM. Though recent efforts have addressed the network issue induced by the vast model size, they have not practically mitigated vital challenges concerning integration with mobile devices, such as significant memory consumption and sluggish model convergence.  In response to these challenges, this work introduces FwdLLM, an innovative FL protocol designed to enhance the FedLLM efficiency. The key idea of FwdLLM to employ backpropagation (BP)-free training methods, requiring devices only to execute ``perturbed inferences''. Consequently, FwdLLM delivers way better memory efficiency and time efficiency (expedited by mobile NPUs and an expanded array of participant devices). FwdLLM centers around three key designs: (1) it combines BP-free training with p
    
[^97]: 提问澄清问题是否增加了生成代码的信心？关于大型语言模型的沟通能力的研究

    Does Asking Clarifying Questions Increases Confidence in Generated Code? On the Communication Skills of Large Language Models. (arXiv:2308.13507v1 [cs.SE])

    [http://arxiv.org/abs/2308.13507](http://arxiv.org/abs/2308.13507)

    通过在生成代码之前提问澄清问题，大型语言模型的代码生成能力可以得到提升，增加了对生成代码的信心。

    

    大型语言模型(LLMs)显著提高了代码生成任务的能力。然而，LLMs在成为顶级软件工程师方面仍存在差距。基于观察到顶级软件工程师通常会提出澄清问题以减少需求和编码解决方案的不确定性，我们认为在代码生成任务中，LLMs也应该采用同样的方法。通过在生成最终代码之前提出深入的问题，可以减轻使用LLMs进行编程所面临的挑战，如意图规范不明确、计算思维不足和代码质量不理想。这反过来增加了对生成代码的自信。在这项工作中，我们探讨如何利用更好的沟通技巧来增加对生成代码的信心。我们提出了一个以沟通为中心的过程，利用LLM生成的沟通器来识别高度不确定或信心低的问题。

    Large language models (LLMs) have significantly improved the ability to perform tasks in the field of code generation. However, there is still a gap between LLMs being capable coders and being top-tier software engineers. Based on the observation that top-level software engineers often ask clarifying questions to reduce ambiguity in both requirements and coding solutions, we argue that the same should be applied to LLMs for code generation tasks. By asking probing questions in various topics before generating the final code, the challenges of programming with LLMs, such as unclear intent specification, lack of computational thinking, and undesired code quality, may be alleviated. This, in turn, increases confidence in the generated code. In this work, we explore how to leverage better communication skills to achieve greater confidence in generated code. We propose a communication-centered process that uses an LLM-generated communicator to identify issues with high ambiguity or low conf
    
[^98]: 使用合规的蒙特卡洛预测实现鲁棒的不确定性量化

    Robust Uncertainty Quantification using Conformalised Monte Carlo Prediction. (arXiv:2308.09647v1 [cs.LG])

    [http://arxiv.org/abs/2308.09647](http://arxiv.org/abs/2308.09647)

    这篇论文介绍了一种名为MC-CP的新型混合不确定性量化方法，通过将自适应蒙特卡洛dropout方法与合规预测相结合，实现了节省资源和产生鲁棒预测集/区间的目标。实验证明MC-CP在分类任务中相比其他先进方法具有显著提升

    

    在安全关键应用中部署深度学习模型仍然是一项非常具有挑战性的任务，需要对这些模型的可靠运行提供保证。不确定性量化（UQ）方法估计每个预测的模型置信度，通过考虑随机性和模型错误规范化的影响来指导决策。尽管最先进的UQ方法取得了一些进展，但它们在计算上要么非常昂贵，要么产生保守的预测集/区间。我们引入了一种新的混合UQ方法MC-CP，它将一种新的自适应蒙特卡洛（MC）dropout方法与合规预测（CP）相结合。MC-CP在运行时自适应调节传统的MC dropout以节省内存和计算资源，使得预测可以被CP使用，得到鲁棒的预测集/区间。通过全面的实验，我们展示了MC-CP相比MC dropout、RAPS和CQR等先进的UQ方法能够显著改善分类性能

    Deploying deep learning models in safety-critical applications remains a very challenging task, mandating the provision of assurances for the dependable operation of these models. Uncertainty quantification (UQ) methods estimate the model's confidence per prediction, informing decision-making by considering the effect of randomness and model misspecification. Despite the advances of state-of-the-art UQ methods, they are computationally expensive or produce conservative prediction sets/intervals. We introduce MC-CP, a novel hybrid UQ method that combines a new adaptive Monte Carlo (MC) dropout method with conformal prediction (CP). MC-CP adaptively modulates the traditional MC dropout at runtime to save memory and computation resources, enabling predictions to be consumed by CP, yielding robust prediction sets/intervals. Throughout comprehensive experiments, we show that MC-CP delivers significant improvements over advanced UQ methods, like MC dropout, RAPS and CQR, both in classificati
    
[^99]: 人工智能生成内容的语义沟通对于有效的内容创造的影响

    Semantic Communications for Artificial Intelligence Generated Content (AIGC) Toward Effective Content Creation. (arXiv:2308.04942v1 [cs.NI])

    [http://arxiv.org/abs/2308.04942](http://arxiv.org/abs/2308.04942)

    本论文提出了一个综合概念模型，用于集成人工智能生成内容（AIGC）和语义沟通（SemCom），以产生有意义和效果的内容。同时，提出了一个采用AIGC技术作为编码器和解码器的框架，优化了语义提取和评估指标。实验验证了该方法的有效性。

    

    人工智能生成内容（AIGC）服务在数字内容创造领域有着巨大的潜力。AIGC的独特能力，如基于最小输入的内容生成，特别是在与语义沟通（SemCom）相结合时，具有巨大的潜力。本文提出了一个新的综合概念模型，用于AIGC和SemCom的集成。特别地，在语义层之上引入了一个内容生成层，清晰地概述了AIGC和SemCom如何相互作用以产生有意义和有效的内容。此外，提出了一个采用AIGC技术作为语义信息编码器和解码器的新框架，考虑到针对AIGC服务定制的语义提取和评估指标的联合优化。该框架可以适应不同类型的生成内容、所需的质量和所利用的语义信息。通过采用深度Q网络（DQN），对具体案例进行了实验验证。

    Artificial Intelligence Generated Content (AIGC) Services have significant potential in digital content creation. The distinctive abilities of AIGC, such as content generation based on minimal input, hold huge potential, especially when integrating with semantic communication (SemCom). In this paper, a novel comprehensive conceptual model for the integration of AIGC and SemCom is developed. Particularly, a content generation level is introduced on top of the semantic level that provides a clear outline of how AIGC and SemCom interact with each other to produce meaningful and effective content. Moreover, a novel framework that employs AIGC technology is proposed as an encoder and decoder for semantic information, considering the joint optimization of semantic extraction and evaluation metrics tailored to AIGC services. The framework can adapt to different types of content generated, the required quality, and the semantic information utilized. By employing a Deep Q Network (DQN), a case 
    
[^100]: AIs的发展脱靴法

    Developmental Bootstrapping of AIs. (arXiv:2308.04586v1 [cs.AI])

    [http://arxiv.org/abs/2308.04586](http://arxiv.org/abs/2308.04586)

    传统的符号AI方法和深度学习AI方法无法满足创建强大和可信赖的AI的挑战，然而，发展脱靴法通过模仿人类儿童的能力发展过程，为创建稳健可靠的AI提供了希望。

    

    尽管当前一些AI在封闭的世界，如棋盘游戏中超越了人类能力，但它们在混乱的现实世界中的表现有限。它们会犯奇怪的错误而且没有意识到。它们很难受到指导，不能运用常识，缺乏好奇心。它们不能成为良好的合作者。传统手动构建的符号AI方法构建的系统和使用生成和深度学习AI方法(包括大规模语言模型)构建的系统都无法应对这些挑战。它们不适合创建强大和可信赖的AI。尽管此方法不属于主流的AI方法，但发展脱靴法显示出希望。在发展脱靴法中，AI像人类儿童一样发展能力。它们从先天能力开始。像人类一样，它们与环境互动，并从互动中学习。它们通过自我发展的能力逐步扩展先天能力。它们互动并逐渐将所学应用于实际操作。

    Although some current AIs surpass human abilities especially in closed worlds such as board games, their performance in the messy real world is limited. They make strange mistakes and do not notice them. They cannot be instructed easily, fail to use common sense, and lack curiosity. They do not make good collaborators. Neither systems built using the traditional manually-constructed symbolic AI approach nor systems built using generative and deep learning AI approaches including large language models (LLMs) can meet the challenges. They are not well suited for creating robust and trustworthy AIs. Although it is outside of mainstream AI approaches, developmental bootstrapping shows promise. In developmental bootstrapping, AIs develop competences like human children do. They start with innate competences. Like humans, they interact with the environment and learn from their interactions. They incrementally extend their innate competences with self-developed competences. They interact and 
    
[^101]: 工程化LaCAM$: 实现实时、大规模、接近最优的多智能体路径规划

    Engineering LaCAM$^\ast$: Towards Real-Time, Large-Scale, and Near-Optimal Multi-Agent Pathfinding. (arXiv:2308.04292v1 [cs.AI])

    [http://arxiv.org/abs/2308.04292](http://arxiv.org/abs/2308.04292)

    本文通过改进LaCAM*算法，解决了实时、大规模、接近最优的多智能体路径规划的挑战。改进技术的融合显著提高了LaCAM*的解决方案质量，推动了MAPF算法的边界。

    

    本文通过对最近提出的LaCAM*算法的改进，解决了实时、大规模和接近最优的多智能体路径规划(MAPF)的挑战。LaCAM*是一种可扩展的基于搜索的算法，它保证对于累计转移成本能够最终找到最优解决方案。尽管它表现出了显著的规划成功率，超过了各种最先进的MAPF方法，但其初始解决方案的质量远非最优，并且其收敛速度较慢。为了克服这些局限性，本文引入了一些改进技术，部分借鉴了其他MAPF方法的灵感。我们提供了实证证据，证明这些技术的融合显著提高了LaCAM*的解决方案质量，进一步推动了MAPF算法的边界。

    This paper addresses the challenges of real-time, large-scale, and near-optimal multi-agent pathfinding (MAPF) through enhancements to the recently proposed LaCAM* algorithm. LaCAM* is a scalable search-based algorithm that guarantees the eventual finding of optimal solutions for cumulative transition costs. While it has demonstrated remarkable planning success rates, surpassing various state-of-the-art MAPF methods, its initial solution quality is far from optimal, and its convergence speed to the optimum is slow. To overcome these limitations, this paper introduces several improvement techniques, partly drawing inspiration from other MAPF methods. We provide empirical evidence that the fusion of these techniques significantly improves the solution quality of LaCAM*, thus further pushing the boundaries of MAPF algorithms.
    
[^102]: FedDRL: 一种基于分阶段强化学习的可信联邦学习模型融合方法

    FedDRL: A Trustworthy Federated Learning Model Fusion Method Based on Staged Reinforcement Learning. (arXiv:2307.13716v1 [cs.LG])

    [http://arxiv.org/abs/2307.13716](http://arxiv.org/abs/2307.13716)

    FedDRL是一种分阶段强化学习的联邦学习模型融合方法，解决了传统方法中无法解决的客户端模型质量和恶意模型问题。

    

    传统的联邦学习使用样本数量计算每个客户端模型的权重，并使用这个固定权重值来融合全局模型。然而，在实际场景中，每个客户端设备和数据的异质性导致每个客户端模型的质量存在差异。因此，对全局模型的贡献不仅仅取决于样本量。此外，如果客户端故意上传低质量或恶意模型，使用这些模型进行聚合将严重降低全局模型的准确性。传统的联邦学习算法没有解决这些问题。为了解决这个问题，我们提出了一种名为FedDRL的模型融合方法，它使用两个阶段的强化学习。在第一个阶段，我们的方法可以过滤掉恶意模型，并选择可信的客户端模型参与模型融合。在第二个阶段，FedDRL算法自适应地调整可信客户端模型的权重并聚合。

    Traditional federated learning uses the number of samples to calculate the weights of each client model and uses this fixed weight value to fusion the global model. However, in practical scenarios, each client's device and data heterogeneity leads to differences in the quality of each client's model. Thus the contribution to the global model is not wholly determined by the sample size. In addition, if clients intentionally upload low-quality or malicious models, using these models for aggregation will lead to a severe decrease in global model accuracy. Traditional federated learning algorithms do not address these issues. To solve this probelm, we propose FedDRL, a model fusion approach using reinforcement learning based on a two staged approach. In the first stage, Our method could filter out malicious models and selects trusted client models to participate in the model fusion. In the second stage, the FedDRL algorithm adaptively adjusts the weights of the trusted client models and ag
    
[^103]: 有限轨迹上的过去-现在时间程序

    Past-present temporal programs over finite traces. (arXiv:2307.12620v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2307.12620](http://arxiv.org/abs/2307.12620)

    本文研究了过去-现在时间程序的建模方法，通过在逻辑编程规则中引用过去和现在，保证了过去与未来的独立性。同时，我们扩展了补全和循环公式的定义，通过LTLf表达式捕捉了一组过去-现在时间程序的时间稳定模型。

    

    通过在过去-现在时间程序中使用来自时间逻辑的语言结构，如有限轨迹上的时间平衡逻辑（TELf），可以为建模动态应用提供具有表达力的计算框架。本文研究了所谓的过去-现在句法子类，它由一组逻辑编程规则组成，其体引用过去，头引用现在。这种限制确保了过去与未来的独立性，在大多数动态领域中是成立的。我们将补全和循环公式的定义扩展到过去-现在公式的情况，从而通过使用LTLf表达式捕捉一组过去-现在时间程序的时间稳定模型。

    Extensions of Answer Set Programming with language constructs from temporal logics, such as temporal equilibrium logic over finite traces (TELf), provide an expressive computational framework for modeling dynamic applications. In this paper, we study the so-called past-present syntactic subclass, which consists of a set of logic programming rules whose body references to the past and head to the present. Such restriction ensures that the past remains independent of the future, which is the case in most dynamic domains. We extend the definitions of completion and loop formulas to the case of past-present formulas, which allows capturing the temporal stable models of a set of past-present temporal programs by means of an LTLf expression.
    
[^104]: 在资源限制下的处方过程监控：一种强化学习方法

    Prescriptive Process Monitoring Under Resource Constraints: A Reinforcement Learning Approach. (arXiv:2307.06564v1 [cs.AI])

    [http://arxiv.org/abs/2307.06564](http://arxiv.org/abs/2307.06564)

    本论文提出了一种在资源限制下进行处方过程监控的强化学习方法。通过考虑对干预需求、及时性或效果预测的不确定性和资源利用水平，来触发干预，从而优化业务过程的性能。

    

    处方过程监控方法旨在通过在运行时触发干预来优化业务过程的性能，从而增加正面案例结果的概率。这些干预是根据干预策略触发的。强化学习被提出作为通过试错学习干预策略的一种方法。然而，现有方法在这一领域假设可用于执行干预的资源数量是无限的，这在实践中是不现实的。本文认为，在资源限制的情况下，处方过程监控领域面临的一个关键困境是基于对干预需求、及时性或效果的预测的不确定性和资源利用水平来触发干预。实际上，当对干预的必要性或效果存在高度不确定性时，将有限的资源用于干预是一项挑战。

    Prescriptive process monitoring methods seek to optimize the performance of business processes by triggering interventions at runtime, thereby increasing the probability of positive case outcomes. These interventions are triggered according to an intervention policy. Reinforcement learning has been put forward as an approach to learning intervention policies through trial and error. Existing approaches in this space assume that the number of resources available to perform interventions in a process is unlimited, an unrealistic assumption in practice. This paper argues that, in the presence of resource constraints, a key dilemma in the field of prescriptive process monitoring is to trigger interventions based not only on predictions of their necessity, timeliness, or effect but also on the uncertainty of these predictions and the level of resource utilization. Indeed, committing scarce resources to an intervention when the necessity or effects of this intervention are highly uncertain m
    
[^105]: 用深度学习简化社交媒体信息检索以支持公共卫生研究

    Streamlining Social Media Information Retrieval for Public Health Research with Deep Learning. (arXiv:2306.16001v1 [cs.CL])

    [http://arxiv.org/abs/2306.16001](http://arxiv.org/abs/2306.16001)

    本研究介绍了一个使用深度学习简化社交媒体信息检索的框架，通过识别医学实体、标准化实体和分配UMLS概念，构建了一个用于COVID-19相关推文的症状词典。

    

    社交媒体在流行病监测中的利用已经得到了很好的证实。然而，当使用预定义的词汇表来检索相关语料库时，常常会引入偏见。本研究介绍了一个框架，旨在构建医学俗语和统一医学语言系统（UMLS）概念的广泛字典。该框架由三个模块组成：基于BERT的命名实体识别（NER）模型，用于从社交媒体内容中识别出医学实体；深度学习驱动的标准化模块，用于对提取出的实体进行规范化处理；半监督聚类模块，将最可能的UMLS概念分配给每个规范化实体。我们将该框架应用于从2020年2月1日到2022年4月30日期间与COVID-19相关的推文，生成了一个症状词典（可在https://github.com/ningkko/UMLS_colloquialism/上获取），其中包含9,249个标准化实体，映射到876个UMLS概念和38,175个俚语表达。该框架的演示

    The utilization of social media in epidemic surveillance has been well established. Nonetheless, bias is often introduced when pre-defined lexicons are used to retrieve relevant corpus. This study introduces a framework aimed at curating extensive dictionaries of medical colloquialisms and Unified Medical Language System (UMLS) concepts. The framework comprises three modules: a BERT-based Named Entity Recognition (NER) model that identifies medical entities from social media content, a deep-learning powered normalization module that standardizes the extracted entities, and a semi-supervised clustering module that assigns the most probable UMLS concept to each standardized entity. We applied this framework to COVID-19-related tweets from February 1, 2020, to April 30, 2022, generating a symptom dictionary (available at https://github.com/ningkko/UMLS_colloquialism/) composed of 9,249 standardized entities mapped to 876 UMLS concepts and 38,175 colloquial expressions. This framework demo
    
[^106]: 基于数据驱动的遗憾平衡在线模型选择的研究

    Data-Driven Regret Balancing for Online Model Selection in Bandits. (arXiv:2306.02869v1 [cs.LG])

    [http://arxiv.org/abs/2306.02869](http://arxiv.org/abs/2306.02869)

    论文讨论在具有赌博反馈的随机环境中进行选择，提出了两种基于数据的模型选择算法，并证明了其保证。通过利用实际遗憾，这些算法在实际中取得了好效果。

    

    我们考虑在具有赌博反馈的随机环境中进行顺序决策模型选择，其中元学习器可以使用一组基本学习器，并根据每个基本学习器推荐的策略动态决策。我们通过遗憾平衡来执行模型选择，但与此相关的最近文献不同的是，我们没有假设任何关于基本学习器的先验知识，如候选遗憾保证；相反，我们以数据驱动的方式揭示这些数量。因此，元学习器能够利用每个基本学习器在给定的学习环境中产生的实际遗憾（而不是期望遗憾），并挑选出最佳的遗憾。我们设计了两个模型选择算法，操作更为雄心勃勃的遗憾概念，并且除了通过遗憾平衡证明模型选择保证外，我们还在实验中展示了处理实际遗憾的令人信服的实际优势。

    We consider model selection for sequential decision making in stochastic environments with bandit feedback, where a meta-learner has at its disposal a pool of base learners, and decides on the fly which action to take based on the policies recommended by each base learner. Model selection is performed by regret balancing but, unlike the recent literature on this subject, we do not assume any prior knowledge about the base learners like candidate regret guarantees; instead, we uncover these quantities in a data-driven manner. The meta-learner is therefore able to leverage the realized regret incurred by each base learner for the learning environment at hand (as opposed to the expected regret), and single out the best such regret. We design two model selection algorithms operating with this more ambitious notion of regret and, besides proving model selection guarantees via regret balancing, we experimentally demonstrate the compelling practical benefits of dealing with actual regrets ins
    
[^107]: Gode -- 将生物化学知识图谱集成到分子图神经网络的预训练中

    Gode -- Integrating Biochemical Knowledge Graph into Pre-training Molecule Graph Neural Network. (arXiv:2306.01631v1 [cs.LG])

    [http://arxiv.org/abs/2306.01631](http://arxiv.org/abs/2306.01631)

    本研究提出了一种新的方法，在分子结构和生物医学知识图谱中集成多个领域信息，通过自我监督策略预先训练更广泛和更强大的表示，并在化学属性预测任务上展示出出色的性能。

    

    分子属性的准确预测对于促进创新治疗方法的发展和理解化学物质和生物系统之间复杂的相互作用至关重要。本研究提出了一种新的方法，将单个分子结构的图表示与生物医学知识图谱 (KG) 的多个领域信息进行集成。通过集成两个级别的信息，我们可以使用自我监督策略预先训练更广泛和更强大的表示，用于分子级和 KG 级预测任务。在性能评估方面，我们在 11 个具有挑战性的化学属性预测任务上微调我们预先训练的模型。我们的框架的结果表明，我们微调的模型优于现有的最先进的模型。

    The precise prediction of molecular properties holds paramount importance in facilitating the development of innovative treatments and comprehending the intricate interplay between chemicals and biological systems. In this study, we propose a novel approach that integrates graph representations of individual molecular structures with multi-domain information from biomedical knowledge graphs (KGs). Integrating information from both levels, we can pre-train a more extensive and robust representation for both molecule-level and KG-level prediction tasks with our novel self-supervision strategy. For performance evaluation, we fine-tune our pre-trained model on 11 challenging chemical property prediction tasks. Results from our framework demonstrate our fine-tuned models outperform existing state-of-the-art models.
    
[^108]: 通过领域知识启示的深度学习进行药物推荐

    Medication Recommendation via Domain Knowledge Informed Deep Learning. (arXiv:2305.19604v1 [cs.AI])

    [http://arxiv.org/abs/2305.19604](http://arxiv.org/abs/2305.19604)

    提出一种基于动态领域知识的药物推荐框架DKINet，将领域知识与患者临床表现相结合，此为首次实验。

    

    药物推荐是医疗保健的基本但至关重要的分支，提供机会为复杂健康状况的患者支持临床医生更精确的药物处方。从电子健康记录（EHR）中学习推荐药物是先前研究中最常见的方法。然而，大多数研究忽视了根据患者的EHR中的临床表现纳入领域知识的问题。为了解决这些问题，我们提出了一种新颖的基于动态领域知识的药物推荐框架，即领域知识启示网络（DKINet），用于将领域知识与可观察的患者临床表现相结合。特别是，我们首先设计了一个基于领域知识的编码器来捕捉领域信息，然后开发了一个数据驱动的编码器将领域知识整合到可观察的EHR中。

    Medication recommendation is a fundamental yet crucial branch of healthcare, which provides opportunities to support clinical physicians with more accurate medication prescriptions for patients with complex health conditions. Learning from electronic health records (EHR) to recommend medications is the most common way in previous studies. However, most of them neglect incorporating domain knowledge according to the clinical manifestations in the EHR of the patient. To address these issues, we propose a novel \textbf{D}omain \textbf{K}nowledge \textbf{I}nformed \textbf{Net}work (DKINet) to integrate domain knowledge with observable clinical manifestations of the patient, which is the first dynamic domain knowledge informed framework toward medication recommendation. In particular, we first design a knowledge-driven encoder to capture the domain information and then develop a data-driven encoder to integrate domain knowledge into the observable EHR. To endow the model with the capability
    
[^109]: 生物医学自然语言处理中的大型语言模型: 基准、基线和建议

    Large language models in biomedical natural language processing: benchmarks, baselines, and recommendations. (arXiv:2305.16326v1 [cs.CL])

    [http://arxiv.org/abs/2305.16326](http://arxiv.org/abs/2305.16326)

    本文研究了GPT-3和GPT-4在生物医学自然语言处理中的表现，分析了它们可能产生的错误类型，并提供了使用这些模型的建议。

    

    生物医学文献呈指数级增长，手动筛选和提取知识变得困难。自动从生物医学文献中提取信息的生物医学自然语言处理（BioNLP）技术有助于减轻这种负担。近年来，如GPT-3和GPT-4等大型语言模型（LLMs）因其卓越的性能而受到重视。但是，它们在BioNLP任务中的有效性以及对方法开发和下游用户的影响仍未得到研究。本研究（1）在四个应用程序中在八个BioNLP数据集中建立了GPT-3和GPT-4在零-shot和一-shot设置下的基准表现，包括命名实体识别，关系提取，多标签文档分类和语义相似性和推理；（2）审查了LLMs产生的错误，并将错误分为三种类型：缺失，不一致和不需要的人工内容；（3）提出了使用LLMs的建议。

    Biomedical literature is growing rapidly, making it challenging to curate and extract knowledge manually. Biomedical natural language processing (BioNLP) techniques that can automatically extract information from biomedical literature help alleviate this burden. Recently, large Language Models (LLMs), such as GPT-3 and GPT-4, have gained significant attention for their impressive performance. However, their effectiveness in BioNLP tasks and impact on method development and downstream users remain understudied. This pilot study (1) establishes the baseline performance of GPT-3 and GPT-4 at both zero-shot and one-shot settings in eight BioNLP datasets across four applications: named entity recognition, relation extraction, multi-label document classification, and semantic similarity and reasoning, (2) examines the errors produced by the LLMs and categorized the errors into three types: missingness, inconsistencies, and unwanted artificial content, and (3) provides suggestions for using L
    
[^110]: EXACT：用于分布式学习的全面攻击方法

    EXACT: Extensive Attack for Split Learning. (arXiv:2305.12997v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.12997](http://arxiv.org/abs/2305.12997)

    本文提出了一种名为EXACT的方法，可以安全地在分布式学习中进行梯度交换，同时保护隐私、保持准确性和效率性。

    

    隐私保护机器学习可以帮助我们训练和部署利用私人信息的模型。在设备上进行机器学习可以使我们在推断期间完全避免与第三方服务器共享信息。然而，与服务器端相比，设备上的模型通常较不准确，因为它们通常只依赖于一小组设备特征且需要足够小才能在终端用户设备上高效运行。分布式学习是一种有前途的方法，可以克服这些限制。在分布式学习中，将一个大型的机器学习模型分成两部分，大部分位于服务器端，小部分在设备上执行，旨在整合私有特征。然而，这种模型的端到端训练需要在分界处交换梯度，这可能编码私有特征或标签。在本文中，我们提出了一种名为 EXACT（Extensive Attack for Split Learning）的新颖隐私保护方法，通过引入广泛的噪声实现安全的梯度交换，同时保持模型的准确性和效率。我们在三个基准数据集上评估了我们的方法，结果显示它在准确性和隐私保护方面优于现有隐私保护方法。

    Privacy-Preserving machine learning (PPML) can help us train and deploy models that utilize private information. In particular, on-device Machine Learning allows us to completely avoid sharing information with a third-party server during inference. However, on-device models are typically less accurate when compared to the server counterparts due to the fact that (1) they typically only rely on a small set of on-device features and (2) they need to be small enough to run efficiently on end-user devices. Split Learning (SL) is a promising approach that can overcome these limitations. In SL, a large machine learning model is divided into two parts, with the bigger part residing on the server-side and a smaller part executing on-device, aiming to incorporate the private features. However, end-to-end training of such models requires exchanging gradients at the cut layer, which might encode private features or labels. In this paper, we provide insights into potential privacy risks associated
    
[^111]: 基于基础模型的系统设计框架

    A Framework for Designing Foundation Model based Systems. (arXiv:2305.05352v1 [cs.SE])

    [http://arxiv.org/abs/2305.05352](http://arxiv.org/abs/2305.05352)

    本文提出了一个基于基础模型的系统分类体系，分类和比较了基础模型和基于基础模型的系统的特点。它为设计基于基础模型的系统时做出主要的设计决策提供了具体的指导，并突出了相关的权衡。

    

    最近推出了大型语言模型(LLM)的聊天机器人，如ChatGPT，这引起了人们对基础模型的广泛关注。基础模型被广泛认为将成为未来人工智能系统的基石。由于基础模型处于早期阶段，基于基础模型的系统设计尚未得到系统地探索。人们对在软件架构中引入基础模型的影响知之甚少。因此，在本文中，我们提出了一个基于基础模型的系统分类法，对基础模型和基于基础模型的系统的特点进行了分类和比较。我们的分类法包括三个类别：基础模型预训练和微调、基于基础模型的系统架构设计和负责任的AI设计。这个分类法为设计基于基础模型的系统时做出主要的设计决策提供了具体的指导，并突出了相关的权衡。

    The recent release of large language model (LLM) based chatbots, such as ChatGPT, has attracted significant attention on foundations models. It is widely believed that foundation models will serve as the fundamental building blocks for future AI systems. As foundation models are in their early stages, the design of foundation model based systems has not yet been systematically explored. There is little understanding about the impact of introducing foundation models in software architecture. Therefore, in this paper, we propose a taxonomy of foundation model based systems, which classifies and compares the characteristics of foundation models and foundation model based systems. Our taxonomy comprises three categories: foundation model pretraining and fine-tuning, architecture design of foundation model based systems, and responsible-AI-by-design. This taxonomy provides concrete guidance for making major design decisions when designing foundation model based systems and highlights trade-
    
[^112]: 用轨迹解释强化学习的决策

    Explaining RL Decisions with Trajectories. (arXiv:2305.04073v1 [cs.AI])

    [http://arxiv.org/abs/2305.04073](http://arxiv.org/abs/2305.04073)

    本文提出一种用训练过程中遇到的轨迹解释强化学习决策的方法，并在离散和连续状态及行动空间的多样化环境中证明了其有效性。

    

    解释是强化学习在许多实际决策问题中应用的关键组成部分。本文提出了一种补充这些解释的方法，特别是针对离线强化学习，即我们将训练过程中遇到的轨迹用编码的方式进行解释。

    Explanation is a key component for the adoption of reinforcement learning (RL) in many real-world decision-making problems. In the literature, the explanation is often provided by saliency attribution to the features of the RL agent's state. In this work, we propose a complementary approach to these explanations, particularly for offline RL, where we attribute the policy decisions of a trained RL agent to the trajectories encountered by it during training. To do so, we encode trajectories in offline training data individually as well as collectively (encoding a set of trajectories). We then attribute policy decisions to a set of trajectories in this encoded space by estimating the sensitivity of the decision with respect to that set. Further, we demonstrate the effectiveness of the proposed approach in terms of quality of attributions as well as practical scalability in diverse environments that involve both discrete and continuous state and action spaces such as grid-worlds, video gam
    
[^113]: 大型语言模型是代码生成的最先进评估器

    Large Language Models Are State-of-the-Art Evaluators of Code Generation. (arXiv:2304.14317v1 [cs.AI])

    [http://arxiv.org/abs/2304.14317](http://arxiv.org/abs/2304.14317)

    本文提出了一个基于 GPT-3.5 的评估框架，解决了现有方法在代码生成任务上的局限性，取得了更好的相关性。

    

    自然语言生成领域的最新进展推动了利用大型语言模型评估生成文本的能力。虽然这些模型在机器翻译和摘要等任务中表现出了很好的结果，但其在代码生成任务中的适用性仍然存在限制。这些任务所需的编程概念的复杂性使得开发评估指标以与人类判断相一致变得困难。以词汇匹配为基础的度量标准（如BLEU）在代码生成任务中与人工从业者的相关性较弱。此外，在低资源领域中利用人为编写的测试套件进行功能正确性评估也具有挑战性。为了克服这些障碍，我们提出了一个基于GPT-3.5的代码生成评估框架（\texttt{GPT-3.5-turbo}）。我们的框架通过取得更好的相关性来解决现有方法的局限性。

    Recent advancements in the field of natural language generation have facilitated the use of large language models to assess the quality of generated text. Although these models have shown promising results in tasks such as machine translation and summarization, their applicability in code generation tasks remains limited without human involvement. The complexity of programming concepts required for such tasks makes it difficult to develop evaluation metrics that align with human judgment. Token-matching-based metrics, such as BLEU, have demonstrated weak correlations with human practitioners in code generation tasks. Moreover, the utilization of human-written test suites to evaluate functional correctness can be challenging in domains with low resources. To overcome these obstacles, we propose a new evaluation framework based on the GPT-3.5 (\texttt{GPT-3.5-turbo}), for code generation assessments. Our framework addresses the limitations of existing approaches by achieving superior cor
    
[^114]: 幕后制作：面向可学习游戏引擎的研究

    Plotting Behind the Scenes: Towards Learnable Game Engines. (arXiv:2303.13472v1 [cs.CV])

    [http://arxiv.org/abs/2303.13472](http://arxiv.org/abs/2303.13472)

    本文提出了一个方法，可以从单眼注释视频中训练出类似游戏引擎的神经模型，这个模型被称为可学习游戏引擎(LGE)，它可以通过指定高级和低级操作序列来玩游戏，并且解锁了导演模式，可以使用高级约束条件控制代理。

    

    游戏引擎在计算机图形学中是强大的工具，但是它们的开发成本也是十分巨大的。本文提出了一个框架，可以从单眼注释视频中训练出类似游戏引擎的神经模型。该结果被称为Learnable Game Engine (LGE)，可以维护场景、物体和其中的代理状态，并且可以从可控制的视角渲染环境。类似于游戏引擎，它模拟了游戏的逻辑和底层物理规则，使用户可以通过指定高级和低级操作序列来玩游戏。最引人注目的是，我们的LGE解锁了导演模式，用户通过标注高层次的动作和目标来控制代理。这要求学习“游戏人工智能”，由我们的动画模型封装，以使用高级约束条件导航场景、与对手对战，设计赢得游戏的策略。

    Game engines are powerful tools in computer graphics. Their power comes at the immense cost of their development. In this work, we present a framework to train game-engine-like neural models, solely from monocular annotated videos. The result-a Learnable Game Engine (LGE)-maintains states of the scene, objects and agents in it, and enables rendering the environment from a controllable viewpoint. Similarly to a game engine, it models the logic of the game and the underlying rules of physics, to make it possible for a user to play the game by specifying both high- and low-level action sequences. Most captivatingly, our LGE unlocks the director's mode, where the game is played by plotting behind the scenes, specifying high-level actions and goals for the agents in the form of language and desired states. This requires learning "game AI", encapsulated by our animation model, to navigate the scene using high-level constraints, play against an adversary, devise the strategy to win a point. T
    
[^115]: 什么让数据适合于局部连接神经网络？一种基于量子纠缠的必要且充分条件

    What Makes Data Suitable for a Locally Connected Neural Network? A Necessary and Sufficient Condition Based on Quantum Entanglement. (arXiv:2303.11249v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.11249](http://arxiv.org/abs/2303.11249)

    本文通过采用量子物理学的理论工具，提出了一种判定数据适合于局部连接神经网络的必要且充分条件，并导出了一种相应的预处理方法。

    

    关于数据分布适用于深度学习的问题是一个基本的开放性问题。本文采用来自量子物理学的理论工具，针对包括卷积神经网络、循环神经网络和局部自注意力模型在内的广泛的局部连接神经网络，解决了这个问题。我们的主要理论结果是，在某些特征的规范划分下，当数据分布接受低量子纠缠时，特定的局部连接神经网络才能够准确地预测该数据分布。作为本结果的实际应用，我们导出了一种预处理方法，以增强数据分布适合局部连接神经网络的性能。在各种数据集上对广泛的模型进行实验，证明了我们的发现。我们希望我们使用量子纠缠将鼓励形式推理的物理工具来进一步采用。

    The question of what makes a data distribution suitable for deep learning is a fundamental open problem. Focusing on locally connected neural networks (a prevalent family of architectures that includes convolutional and recurrent neural networks as well as local self-attention models), we address this problem by adopting theoretical tools from quantum physics. Our main theoretical result states that a certain locally connected neural network is capable of accurate prediction over a data distribution if and only if the data distribution admits low quantum entanglement under certain canonical partitions of features. As a practical application of this result, we derive a preprocessing method for enhancing the suitability of a data distribution to locally connected neural networks. Experiments with widespread models over various datasets demonstrate our findings. We hope that our use of quantum entanglement will encourage further adoption of tools from physics for formally reasoning about 
    
[^116]: 一个通用的多模态融合检测框架

    A Generalized Multi-Modal Fusion Detection Framework. (arXiv:2303.07064v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.07064](http://arxiv.org/abs/2303.07064)

    本文提出了一个通用的多模态融合检测框架，旨在在复杂场景中通过准确融合激光雷达和图像来提高3D检测的精度。

    

    激光雷达点云已成为自动驾驶中最常见的数据来源，但由于点云的稀疏性，在特定场景下无法实现准确可靠的检测。图像因其与点云的互补性而越来越受到关注。虽然已有一些成功案例，但现有的融合方法要么进行硬融合，要么不直接进行融合。本文提出了一种称为MMFusion的通用的3D检测框架，使用多模态特征。该框架旨在实现在复杂场景中激光雷达和图像的准确融合，从而提高3D检测的精度。我们的框架由两个独立的流组成：激光雷达流和相机流，可以与任何单模态特征提取网络兼容。激光雷达流中的体素局部感知模块增强了局部特征表示，然后多模态特征融合模块有选择地将来自不同流的特征输出进行融合，实现。

    LiDAR point clouds have become the most common data source in autonomous driving. However, due to the sparsity of point clouds, accurate and reliable detection cannot be achieved in specific scenarios. Because of their complementarity with point clouds, images are getting increasing attention. Although with some success, existing fusion methods either perform hard fusion or do not fuse in a direct manner. In this paper, we propose a generic 3D detection framework called MMFusion, using multi-modal features. The framework aims to achieve accurate fusion between LiDAR and images to improve 3D detection in complex scenes. Our framework consists of two separate streams: the LiDAR stream and the camera stream, which can be compatible with any single-modal feature extraction network. The Voxel Local Perception Module in the LiDAR stream enhances local feature representation, and then the Multi-modal Feature Fusion Module selectively combines feature output from different streams to achieve b
    
[^117]: Cal-QL: 计算机辅助脱机强化学习预先训练用于高效在线微调

    Cal-QL: Calibrated Offline RL Pre-Training for Efficient Online Fine-Tuning. (arXiv:2303.05479v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.05479](http://arxiv.org/abs/2303.05479)

    本文介绍了一种计算机辅助脱机强化学习方法Cal-QL，该方法能够从脱机数据中学习一个保守的值函数初始化，使得在在线微调时同时保障了快速和性能。

    

    脱机强化学习方法可以用来从现有数据集中获取策略初始化并通过有限互动进行快速在线微调。然而，现有的脱机强化学习方法在在线微调中表现较差。本文研究了保守脱机强化学习方法中的微调问题，并设计了一种方法，可以从脱机数据中学习到有效的初始化，并使其具备快速的在线微调功能。我们的方法，即Cal-QL，通过学习一个保守的值函数初始化，低估从脱机数据中学到的策略的价值，同时确保学习到的Q值在合理的范围内。实验结果表明，我们的方法在多个基准环境中具有显著的性能优势，并且也能在真实机器人问题中进行有效的在线微调。

    A compelling use case of offline reinforcement learning (RL) is to obtain a policy initialization from existing datasets followed by fast online fine-tuning with limited interaction. However, existing offline RL methods tend to behave poorly during fine-tuning. In this paper, we study the fine-tuning problem in the context of conservative offline RL methods and we devise an approach for learning an effective initialization from offline data that also enables fast online fine-tuning capabilities. Our approach, calibrated Q-learning (Cal-QL), accomplishes this by learning a conservative value function initialization that underestimates the value of the learned policy from offline data, while also ensuring that the learned Q-values are at a reasonable scale. We refer to this property as calibration, and define it formally as providing a lower bound on the true value function of the learned policy and an upper bound on the value of some other (suboptimal) reference policy, which may simply
    
[^118]: 贝叶斯矩阵分解及应用

    Bayesian Matrix Decomposition and Applications. (arXiv:2302.11337v2 [math.NA] UPDATED)

    [http://arxiv.org/abs/2302.11337](http://arxiv.org/abs/2302.11337)

    本书旨在介绍贝叶斯矩阵分解的概念和工具，并总结了贝叶斯矩阵分解方法在不同领域的应用。

    

    本书的唯一目的是为了给出贝叶斯矩阵分解概念和数学工具的自包含介绍，以便在后续章节中无缝引入矩阵分解技术及其应用。然而，我们清楚地意识到我们无法覆盖关于贝叶斯矩阵分解的所有有用和有趣的结果，并且由于讨论的范围有限，例如分析变分推理以进行优化的分离分析。我们将读者引导到贝叶斯分析领域的文献中，以便更详细地介绍相关领域。本书主要总结了重要的贝叶斯矩阵分解方法（例如实值分解、非负矩阵分解、贝叶斯插值分解）的目的和意义，以及这些方法的起源和复杂性对其应用提供的启示。数学先决条件是第一门课程。

    The sole aim of this book is to give a self-contained introduction to concepts and mathematical tools in Bayesian matrix decomposition in order to seamlessly introduce matrix decomposition techniques and their applications in subsequent sections. However, we clearly realize our inability to cover all the useful and interesting results concerning Bayesian matrix decomposition and given the paucity of scope to present this discussion, e.g., the separated analysis of variational inference for conducting the optimization. We refer the reader to literature in the field of Bayesian analysis for a more detailed introduction to the related fields.  This book is primarily a summary of purpose, significance of important Bayesian matrix decomposition methods, e.g., real-valued decomposition, nonnegative matrix factorization, Bayesian interpolative decomposition, and the origin and complexity of the methods which shed light on their applications. The mathematical prerequisite is a first course in 
    
[^119]: AV-data2vec: 使用上下文化目标表示的自监督学习音视频语音表示

    AV-data2vec: Self-supervised Learning of Audio-Visual Speech Representations with Contextualized Target Representations. (arXiv:2302.06419v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2302.06419](http://arxiv.org/abs/2302.06419)

    AV-data2vec是一种使用自监督学习来构建音视频语音表示的方法，能够同时训练音频和视频的联合表示，并在语音识别任务中表现出优越性能。

    

    自监督学习已经显示出在语音识别方面具有很大的潜力，通过大大减少构建好的系统所需的标记数据量。然而，现有的方法要么不完全端到端，要么不能同时训练两种模态的联合表示。在本文中，我们引入了AV-data2vec，它解决了这些挑战，并基于预测上下文化表示构建音视频表示，这在单模态情况下取得了成功。该模型使用共享的Transformer编码器对音频和视频进行表示，并可以结合两种模态来改进语音识别。在LRS3上的结果表明，AV-data2vec在所有设置下都比现有方法表现更好，而使用的数据量和模型大小相同。

    Self-supervision has shown great potential for audio-visual speech recognition by vastly reducing the amount of labeled data required to build good systems. However, existing methods are either not entirely end-to-end or do not train joint representations of both modalities. In this paper, we introduce AV-data2vec which addresses these challenges and builds audio-visual representations based on predicting contextualized representations which has been successful in the uni-modal case. The model uses a shared transformer encoder for both audio and video and can combine both modalities to improve speech recognition. Results on LRS3 show that AV-data2vec consistently outperforms existing methods under all settings with the same amount of data and model size.
    
[^120]: 通过元学习在哈密顿流形中识别普遍的神经表示

    Identifying Generalized Neural Representation Across Hamiltonian Manifolds via Meta-learning. (arXiv:2212.01168v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.01168](http://arxiv.org/abs/2212.01168)

    通过元学习方法，在哈密顿流形中识别出普遍的神经表示，实现了对不同物理系统的快速适应能力。

    

    最近物理学中深度学习的进展集中在通过将物理先验或归纳偏见引入神经网络来发现目标系统的共享表示。然而，这些方法特定于系统，不允许轻松适应由不同物理法则驱动的新物理系统。例如，训练于质点弹簧系统的神经网络无法准确预测双体系统或任何具有不同物理法则的系统的行为。在本研究中，我们使用图神经网络模拟我们的系统，并采用元学习算法使模型在一系列任务中积累经验，并使其适应新的物理系统。我们的方法旨在学习跨各种哈密顿流形的通用表示，这是哈密顿系统数据分布的共同特征。我们使用由不同系统组成的数据集训练模型，每个系统都有其自身固有的动力学，并评估其性能。

    Recent advancements in deep learning for physics have focused on discovering shared representations of target systems by incorporating physics priors or inductive biases into neural networks. However, these approaches are system-specific and do not allow for easy adaptation to new physical systems governed by different laws. For example, a neural network trained on a mass-spring system cannot accurately predict the behavior of a two-body system or any other system with different governing physics. In this work, we model our system with a graph neural network and employ a meta-learning algorithm to enable the model to gain experience over a distribution of tasks and make it adapt to new physics. Our approach aims to learn a general representation across the various Hamiltonian manifolds, which is a common feature of the data distribution of Hamiltonian systems. We train our model using a dataset of different physical systems, each governed by its own inherent dynamics, and evaluate its 
    
[^121]: 直比代数

    Proportional algebras. (arXiv:2210.01751v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2210.01751](http://arxiv.org/abs/2210.01751)

    本文引入了直比代数，探讨了保持比拟比例的函数的数学性质，将其与直比同态、同余和直比函子联系起来，为模拟比例和模拟推理的数学理论提供了进一步理解。

    

    比拟比例是形式为"$a$对$b$，正如$c$对$d$"的表达式，是模拟推理的核心，而模拟推理又是人工智能的核心。本文引入了直比代数作为一种带有4元比拟比例关系$a:b::c:d$满足一组适当公理的代数结构。在人工智能中，保持比拟比例的函数已经被证明具有实际意义，而研究它们的数学性质对于理解比例是至关重要的。因此，我们引入了直比同态及其关联的同余和直比函子，并展示了它们之间的密切关联。从更广泛的意义上说，本文是迈向模拟比例和模拟推理的数学理论的进一步步骤。

    Analogical proportions are expressions of the form "$a$ is to $b$ what $c$ is to $d$" at the core of analogical reasoning which itself is at the core of artificial intelligence. This paper introduces proportional algebras as algebras endowed with a 4-ary analogical proportion relation $a:b::c:d$ satisfying a suitable set of axioms. Functions preserving analogical proportions have already proven to be of practical interest in artificial intelligence and studying their mathematical properties is essential for understanding proportions. We therefore introduce proportional homomorphisms and their associated congruences and proportional functors, and show that they are closely related notions. In a broader sense, this paper is a further step towards a mathematical theory of analogical proportions and analogical reasoning in general.
    
[^122]: 异构多智能体零样本协同进化研究

    Heterogeneous Multi-agent Zero-Shot Coordination by Coevolution. (arXiv:2208.04957v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2208.04957](http://arxiv.org/abs/2208.04957)

    本研究首次研究了异构零样本协同问题，并提出了一种基于协同进化的通用方法，通过配对、更新和选择的过程，实现了多智能体零样本协同。实验结果表明，考虑异构情况的必要性，并证明了该方法对于异构零样本协同任务的有前景的解决方案。

    

    在合作多智能体强化学习领域，生成能够与未知合作伙伴零样本协同的智能体是一个新的挑战。最近的一些研究在零样本协同方面取得了进展，通过训练过程中向智能体暴露多样化的合作伙伴。然而，这些方法通常在训练伙伴时涉及自我对弈，隐式地假设任务是同质的。然而，许多真实世界的任务是异构的，因此先前的方法可能效率低下。本文首次研究了异构零样本协同的问题，并提出了一种基于协同进化的通用方法，通过三个子过程：配对、更新和选择，对两个智能体和合作伙伴进行协同进化。对不同异构任务的实验结果突出了考虑异构情况的必要性，并证明我们提出的方法是解决异构零样本协同任务的一种有前景的解决方案。

    Generating agents that can achieve zero-shot coordination (ZSC) with unseen partners is a new challenge in cooperative multi-agent reinforcement learning (MARL). Recently, some studies have made progress in ZSC by exposing the agents to diverse partners during the training process. They usually involve self-play when training the partners, implicitly assuming that the tasks are homogeneous. However, many real-world tasks are heterogeneous, and hence previous methods may be inefficient. In this paper, we study the heterogeneous ZSC problem for the first time and propose a general method based on coevolution, which coevolves two populations of agents and partners through three sub-processes: pairing, updating and selection. Experimental results on various heterogeneous tasks highlight the necessity of considering the heterogeneous setting and demonstrate that our proposed method is a promising solution for heterogeneous ZSC tasks.
    
[^123]: 重新思考语义分割的无监督领域自适应

    Rethinking Unsupervised Domain Adaptation for Semantic Segmentation. (arXiv:2207.00067v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2207.00067](http://arxiv.org/abs/2207.00067)

    这项研究重新思考了语义分割的无监督领域自适应方法，提出了从数据中心的角度重新考虑无监督领域自适应问题，并探讨了使用最少的标记数据来确定UDA方法超参数的方法。

    

    无监督领域自适应（UDA）使用无标签数据将在一个领域中训练的模型（称为源领域）适应到一个新领域（称为目标领域）。由于注释成本高昂，研究人员开发了许多用于语义分割的UDA方法，这些方法假设目标领域中没有可用的标记样本。我们对这种假设的可行性提出了质疑，主要有两个原因。首先，在使用UDA方法训练模型之后，我们必须在部署之前对模型进行验证。其次，UDA方法至少有几个需要确定的超参数。解决这些问题的最确保的方法是使用验证数据评估模型，即一定数量的标记的目标领域样本。对UDA的这一基本假设的质疑使我们重新从数据中心的角度思考UDA。具体而言，我们假设我们可以访问一定水平的标记数据。然后，我们询问需要多少数据来找到现有UDA方法的良好超参数。然后，我们考虑在这个基础上可以对UDA方法进行什么样的改进。

    Unsupervised domain adaptation (UDA) adapts a model trained on one domain (called source) to a novel domain (called target) using only unlabeled data. Due to its high annotation cost, researchers have developed many UDA methods for semantic segmentation, which assume no labeled sample is available in the target domain. We question the practicality of this assumption for two reasons. First, after training a model with a UDA method, we must somehow verify the model before deployment. Second, UDA methods have at least a few hyper-parameters that need to be determined. The surest solution to these is to evaluate the model using validation data, i.e., a certain amount of labeled target-domain samples. This question about the basic assumption of UDA leads us to rethink UDA from a data-centric point of view. Specifically, we assume we have access to a minimum level of labeled data. Then, we ask how much is necessary to find good hyper-parameters of existing UDA methods. We then consider what 
    
[^124]: 基于小波的人类活动时间模型在智能机器人辅助环境中的异常检测

    Wavelet-based temporal models of human activity for anomaly detection in smart robot-assisted environments. (arXiv:2002.11503v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2002.11503](http://arxiv.org/abs/2002.11503)

    本文提出了一种基于小波变换的新方法，用于在智能机器人辅助环境中检测人类活动的异常情况。该方法通过预测智能传感器数据，并结合混合马尔科夫逻辑网络扩展，将不同的异常指标合并在一起，以提供时间先验，并检测人类环境中的意外事件。

    

    检测传感器数据模式中的异常在许多实际应用中非常重要，包括用于主动辅助生活的家庭活动监测。然而，如何表示和分析这些模式仍然是一个具有挑战性的任务，特别是当数据相对稀缺且需要明确的模型来对特定场景进行精细调整时。因此，本文提出了一种用于长时期人类活动在智能家居传感器上的时间建模的新方法，该方法用于在机器人辅助环境中检测异常情况。该模型基于小波变换，用于预测智能传感器数据，提供时间先验以检测人类环境中的意外事件。为此，开发了一种新的混合马尔科夫逻辑网络的扩展，将包括二元传感器检测到的活动、专家逻辑规则和基于小波的时间模型在内的不同异常指标合并在一起。

    Abstract. Detecting anomalies in patterns of sensor data is important in many practical applications, including domestic activity monitoring for Active Assisted Living (AAL). How to represent and analyse these patterns, however, remains a challenging task, especially when data is relatively scarce and an explicit model is required to be fine-tuned for specific scenarios. This paper, therefore, presents a new approach for temporal modelling of long-term human activities with smart-home sensors, which is used to detect anomalous situations in a robot-assisted environment. The model is based on wavelet transforms and used to forecast smart sensor data, providing a temporal prior to detect unexpected events in human environments. To this end, a new extension of Hybrid Markov Logic Networks has been developed that merges different anomaly indicators, including activities detected by binary sensors, expert logic rules, and wavelet-based temporal models. The latter in particular allows the in
    

