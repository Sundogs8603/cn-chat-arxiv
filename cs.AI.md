# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [POMP: Probability-driven Meta-graph Prompter for LLMs in Low-resource Unsupervised Neural Machine Translation.](http://arxiv.org/abs/2401.05596) | POMP是一种新颖的方法，使用动态的、基于抽样的多辅助语言图形，提高了语言模型在低资源语言中的翻译能力。 |
| [^2] | [The Impact of Reasoning Step Length on Large Language Models.](http://arxiv.org/abs/2401.04925) | 本研究探讨了推理步长对大型语言模型的影响，并发现在提示中增加推理步骤能显著提高模型的推理能力，而减少推理步骤则会降低模型的推理能力。 |
| [^3] | [The inherent goodness of well educated intelligence.](http://arxiv.org/abs/2401.04846) | 本文探讨了智能体变得智能的因素，强调了掌握特征和控制多个保守相互作用的子系统的能力。智能的核心是“集体如一体”和“了解局部行动的整体结果”。文章提出了一种对集体保守系统进行控制的替代方法。 |
| [^4] | [Sample-and-Bound for Non-Convex Optimization.](http://arxiv.org/abs/2401.04812) | 本论文提出了一种基于采样的非凸优化方法，采用Monte Carlo Tree Search (MCTS)来提高效率，并利用数值上估计的不确定度指标和采样估计的一阶和二阶信息，避免固定组合模式的树生长，积极缩小到有希望的区域，同时平衡探索和开发。 |
| [^5] | [Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models.](http://arxiv.org/abs/2401.04658) | 本文介绍了Lightning Attention-2，这是第一个能够实现线性注意力理论计算优势的线性注意力实现。通过利用平铺的思想，分别处理了线性注意力计算中的内部块和外部块组件。具体来说，采用传统的注意力计算机制处理内部块，并使用新的累积求和方法处理外部块。 |
| [^6] | [A Deep Network for Explainable Prediction of Non-Imaging Phenotypes using Anatomical Multi-View Data.](http://arxiv.org/abs/2401.04579) | 本论文研究了利用解剖多视图数据预测非成像表型的深度网络，提出了一个可解释的多视图网络（EMV-Net），通过融合不同解剖视图来提高预测性能。 |
| [^7] | [Towards Explainable Artificial Intelligence (XAI): A Data Mining Perspective.](http://arxiv.org/abs/2401.04374) | 本研究提出了一种“数据为中心”的视角，探讨了数据收集、处理和分析在可解释的人工智能中的作用。研究将现有工作分为三个类别：深度模型的解释、训练数据的影响和领域知识的见解。通过数据挖掘操作，我们总结了这些XAI方法。 |
| [^8] | [MobileAgent: enhancing mobile control via human-machine interaction and SOP integration.](http://arxiv.org/abs/2401.04124) | MobileAgent通过人机交互和SOP集成，提高了移动控制的效率和个性化用户需求的满足，同时解决了隐私问题和代理学习中的挑战。 |
| [^9] | [Has Your Pretrained Model Improved? A Multi-head Posterior Based Approach.](http://arxiv.org/abs/2401.02987) | 本研究提出一种基于多头后验的方法，通过利用实体的元特征和模型的表示之间的一致性作为度量标准，有效评估预训练模型在各个领域的表现。 |
| [^10] | [Unsupervised Federated Domain Adaptation for Segmentation of MRI Images.](http://arxiv.org/abs/2401.02941) | 本文提出了一种无监督的联邦领域适应方法，可以在未注释的目标域中使用多个带有注释的源领域的知识来进行MRI图像分割。 |
| [^11] | [Physics-Informed Neural Networks for High-Frequency and Multi-Scale Problems using Transfer Learning.](http://arxiv.org/abs/2401.02810) | 本论文提出使用迁移学习来提高物理信息神经网络（PINN）训练的鲁棒性和收敛性。经过两个案例研究，发现迁移学习可以有效地训练PINN来近似解决方案，从低频率问题到高频率问题，而不增加网络参数，且需要更少的数据点和更短的训练时间。 |
| [^12] | [Enhancing targeted transferability via feature space fine-tuning.](http://arxiv.org/abs/2401.02727) | 本文提出了一种通过特征空间微调AE，显著提高现有攻击的目标传递性的方法。实验结果表明，只需少量的微调即可普遍地增强攻击的传递能力，并显示出简单的迭代攻击可以与资源密集型方法相媲美甚至更好。 |
| [^13] | [Act as You Learn: Adaptive Decision-Making in Non-Stationary Markov Decision Processes.](http://arxiv.org/abs/2401.01841) | 本文提出了一种自适应蒙特卡洛树搜索算法来应对非稳态环境下的决策问题，解决了传统方法中对环境动态假设的限制和规划过程的悲观性问题。 |
| [^14] | [An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction.](http://arxiv.org/abs/2401.01326) | 这篇论文提出了一种新颖的方法，通过将联合实体和关系抽取问题作为条件序列生成问题来解决。该方法使用了基于跨度的图生成方式，并通过指向机制将生成的输出与原始文本对齐。评估结果证明了该方法的有效性，并获得了竞争性的结果。 |
| [^15] | [Unsupervised Outlier Detection using Random Subspace and Subsampling Ensembles of Dirichlet Process Mixtures.](http://arxiv.org/abs/2401.00773) | 提出一种基于随机子空间和子抽样集合的Dirichlet过程高斯混合模型的无监督异常检测方法，提高了计算效率和检测器的鲁棒性。 |
| [^16] | [ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios.](http://arxiv.org/abs/2401.00741) | ToolEyes是一个专门用于评估大型语言模型在真实情景中的工具学习能力的细粒度系统，通过对七个真实情景的详细分析，评估了LLMs在工具学习的五个关键维度，并提供了一个拥有600种工具的工具库作为中介。 |
| [^17] | [Improving Low-resource Prompt-based Relation Representation with Multi-view Decoupling Learning.](http://arxiv.org/abs/2312.17267) | 提出了一种名为MVRE的新方法，通过将关系解耦为不同的视角，生成多视角关系表示，并利用预训练语言模型（PLMs）的能力来提高低资源关系抽取任务的性能。 |
| [^18] | [TAPE: Leveraging Agent Topology for Cooperative Multi-Agent Policy Gradient.](http://arxiv.org/abs/2312.15667) | TAPE提出了一种代理拓扑框架，用于解决多智能体策略梯度方法中的集中-分散不匹配（CDM）问题，通过平衡合作和减轻CDM的影响。 |
| [^19] | [A Trade-off Analysis of Replacing Proprietary LLMs with Open Source SLMs in Production.](http://arxiv.org/abs/2312.14972) | 本文提出了一种系统的评估方法来比较专有LLMs和开源SLMs的权衡，并设计了一个自动化分析工具SLaM来测试产品功能。在实际产品功能替换时，对于现有能力是否能够被开源SLMs代替，还需要进一步研究。 |
| [^20] | [Turbulence: Systematically and Automatically Testing Instruction-Tuned Large Language Models for Code.](http://arxiv.org/abs/2312.14856) | 这项研究提出了一种通过新的基准测试Turbulence来系统评估针对代码生成的指令调整大型语言模型（LLMs）的正确性和鲁棒性的方法。通过构建一组问题模板，可以评估LLMs在解决相似编程问题时的准确性，并发现其代码生成能力的缺陷和异常情况。这项研究在五个LLMs上进行了实验。 |
| [^21] | [WellFactor: Patient Profiling using Integrative Embedding of Healthcare Data.](http://arxiv.org/abs/2312.14129) | WellFactor是一种使用综合嵌入医疗数据的患者分类方法，并通过使用受约束的低秩逼近、结合标签信息来优化嵌入结果，同时具有即时计算新数据嵌入的特点。在实际医疗数据上得到了验证。 |
| [^22] | [Image Clustering using Restricted Boltzman Machine.](http://arxiv.org/abs/2312.13845) | 本文提出了使用受限玻尔兹曼机进行图像聚类的方法，通过训练RBMs将图像转换为图像嵌入，并使用自底向上的聚类技术进行聚类。为了应对有限的测试图像数据，提出了AHC-RBM方法，通过训练通用的RBM模型和适应性RBM模型来生成RBM向量，从而实现有效的图像聚类。 |
| [^23] | [Knowledge Graph Error Detection with Contrastive Confidence Adaption.](http://arxiv.org/abs/2312.12108) | 本文提出了一种使用对比学习和交互式对比学习的知识图谱错误检测模型CCA，通过综合文本和图结构信息，更好地区分语义，从而在检测噪声方面优于当前最先进的方法。 |
| [^24] | [Traces of Memorisation in Large Language Models for Code.](http://arxiv.org/abs/2312.11658) | 大型语言模型在代码中有记忆痕迹，容易受到数据提取攻击。 |
| [^25] | ["Paraphrasing The Original Text" Makes High Accuracy Long-Context QA.](http://arxiv.org/abs/2312.11193) | 本论文提出了一种名为"原文改写"的任务来处理长文本问答，通过低成本高效的方法成功扩展了现有模型的上下文窗口至32k，并在多文档问答中达到了最先进的准确性。 |
| [^26] | [Advancing Surgical VQA with Scene Graph Knowledge.](http://arxiv.org/abs/2312.10251) | 本研究通过场景图知识推进了手术环境中的视觉问答（VQA），解决了手术VQA系统中的问题条件偏倚和缺乏场景感知推理的挑战。 |
| [^27] | [CARAT: Contrastive Feature Reconstruction and Aggregation for Multi-Modal Multi-Label Emotion Recognition.](http://arxiv.org/abs/2312.10201) | 本文提出了对比特征重构和聚合（CARAT）方法，用于多模态多标签情绪识别。通过对比学习模态分离和标签特定的特征，CARAT能更好地建模细粒度的模态对标签的依赖关系。 |
| [^28] | [Morphological Profiling for Drug Discovery in the Era of Deep Learning.](http://arxiv.org/abs/2312.07899) | 形态学特征分析在表型药物发现中具有重要价值。深度学习技术在分析大规模高内容图像方面取得了显著进展，促进了药物作用机制的理解和新治疗方法的开发。 |
| [^29] | [Characteristic Guidance: Non-linear Correction for Diffusion Model at Large Guidance Scale.](http://arxiv.org/abs/2312.07586) | 该论文提出了特征引导方法，用于对大尺度的导向下扩散模型进行非线性校正，以增强对图像生成的控制能力，减少颜色和曝光问题，并在各种应用中显示出效果。 |
| [^30] | [Guardians of Trust: Navigating Data Security in AIOps through Vendor Partnerships.](http://arxiv.org/abs/2312.06008) | 本文讨论了在AIOps中与供应商合作时数据安全的重要性，并探讨了如何通过采用最佳实践来保护数据和隐私。 |
| [^31] | [Exploring Parity Challenges in Reinforcement Learning through Curriculum Learning with Noisy Labels.](http://arxiv.org/abs/2312.05379) | 本论文通过带有噪声标签的课程学习，深入研究了在策略游戏中应用强化学习的奇偶性挑战。研究发现，即使存在最小的标签噪声，也会明显阻碍神经网络辨别有效策略的能力，这对RL训练提出了迫切需要先进方法的要求。 |
| [^32] | [CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models.](http://arxiv.org/abs/2312.04350) | 该论文提出了一个新的NLP任务，评估语言模型在因果推理方面的能力。作者构建了一个大规模的数据集CLadder，并利用oracle因果推理引擎将符号问题转化为自然语言。研究结果表明多个LLMs在该数据集上的表现，并引入并评估了一种定制的链式推理机制。 |
| [^33] | [Graph Convolutions Enrich the Self-Attention in Transformers!.](http://arxiv.org/abs/2312.04234) | 这项研究通过引入图卷积来改进Transformer模型中的自注意力机制，并在计算机视觉、自然语言处理等多个领域展示了其性能提升。 |
| [^34] | [Demand response for residential building heating: Effective Monte Carlo Tree Search control based on physics-informed neural networks.](http://arxiv.org/abs/2312.03365) | 本文重点研究了基于物理启发神经网络的蒙特卡洛树搜索控制方法在住宅建筑供暖的需求响应中的应用，该方法通过灵活的优化整合了外部约束条件，为实现能源消耗的优化和用户热舒适度的保证提供了有前景的解决方案。 |
| [^35] | [Multi-Weight Ranking for Multi-Criteria Decision Making.](http://arxiv.org/abs/2312.03006) | 这项研究将统计学的锥形分布函数转化为多准则决策制定工具，并通过扩展排名函数到集合，建立了集合优化方法与基于集合的多目标优化之间的联系。在机器学习中具有潜在应用。 |
| [^36] | [Entropy and the Kullback-Leibler Divergence for Bayesian Networks: Computational Complexity and Efficient Implementation.](http://arxiv.org/abs/2312.01520) | 本文提出了一种计算贝叶斯网络中Shannon熵和Kullback-Leibler散度的高效算法，并通过一系列数值示例进行了演示。此外，还展示了如何将高斯贝叶斯网络中KL的计算复杂度从立方降低到二次。 |
| [^37] | [Investigating Collaborative Data Practices: a Case Study on Artificial Intelligence for Healthcare Research.](http://arxiv.org/abs/2311.18424) | 本文通过研究英国多种长期疾病研究联盟中的参与者的访谈，探讨了协作数据实践的工具、沟通过程和环境，以及协作工作的条件和障碍。研究结果显示了工具的适应性和信息根据受众的个性化，以及电子医疗记录和数据集访问的限制。 |
| [^38] | [GraphPro: Graph Pre-training and Prompt Learning for Recommendation.](http://arxiv.org/abs/2311.16716) | GraphPro是一个结合了参数高效和动态图预训练与提示学习的框架，能够有效捕捉长期用户偏好和短期行为动态，从而在真实世界的推荐系统中提供准确和及时的推荐。 |
| [^39] | [Moving Sampling Physics-informed Neural Networks induced by Moving Mesh PDE.](http://arxiv.org/abs/2311.16167) | 这项工作提出了一种基于移动网格PDE的移动采样物理信息神经网络(MMPDE-Net)，通过解决移动网格PDE来自适应生成新的采样点，并且结合物理信息神经网络（PINN）提出了移动采样PINN（MS-PINN）的框架。数值实验验证了MS-PINN相对于PINN的性能改善。 |
| [^40] | [Evaluating the Efficacy of Hybrid Deep Learning Models in Distinguishing AI-Generated Text.](http://arxiv.org/abs/2311.15565) | 本研究评估了混合深度学习模型在准确区分AI生成文本和人类写作方面的有效性。通过应用先进的自然语言处理技术和复杂的神经网络，我们的研究成功地检测到了AI生成文本和人类写作之间的微妙差异。 |
| [^41] | [Charting New Territories: Exploring the Geographic and Geospatial Capabilities of Multimodal LLMs.](http://arxiv.org/abs/2311.14656) | 本论文探索了多模态大语言模型在地理和地理空间领域的能力，并通过实验分析了它们在各种视觉任务中的表现，发现了其卓越之处以及不足之处。 |
| [^42] | [AI-Generated Images Introduce Invisible Relevance Bias to Text-Image Retrieval.](http://arxiv.org/abs/2311.14084) | 本研究通过构建合适的基准和进行大量实验发现，由AI生成的图像对于文本-图像检索模型引入了一个不可见的相关偏差，即使这些生成的图像在视觉上与查询的相关特征相比并没有更多。这种不可见的相关偏差普遍存在于不同训练数据和架构的检索模型中。 |
| [^43] | [Curriculum Learning and Imitation Learning for Model-free Control on Financial Time-series.](http://arxiv.org/abs/2311.13326) | 本文通过在复杂时间序列数据上探索课程学习和模仿学习的方法，发现课程学习是改善复杂时间序列控制任务性能的新途径，而模仿学习也应该被应用。 |
| [^44] | [$\varepsilon$-fractional Core Stability in Hedonic Games.](http://arxiv.org/abs/2311.11101) | 提出了$\varepsilon$-分数核稳定的概念，通过允许最多$\varepsilon$比例的可能联盟成为核阻塞联盟来解决快乐博弈中的核稳定性问题。这一放松条件可以保证存在性和多项式时间计算。 |
| [^45] | [Testing learning-enabled cyber-physical systems with Large-Language Models: A Formal Approach.](http://arxiv.org/abs/2311.07377) | 本研究对学习增强型物联网系统的测试进行了形式化方法的探索，以应对当前测试方法的局限性。 |
| [^46] | [Multi-Agent Quantum Reinforcement Learning using Evolutionary Optimization.](http://arxiv.org/abs/2311.05546) | 本研究提出了三种基于变分量子线路的进化优化多智能体强化学习变体，并在Coin Game环境中证明了这些方法相比于经典方法表现显著更好。 |
| [^47] | [Locating Cross-Task Sequence Continuation Circuits in Transformers.](http://arxiv.org/abs/2311.04131) | 通过分析和比较Transformer模型中类似的序列继续任务的电路，研究发现共享的计算结构可以提高模型的行为预测能力、错误识别能力和编辑过程的安全性。 |
| [^48] | [ALYMPICS: Language Agents Meet Game Theory -- Exploring Strategic Decision-Making with AI Agents.](http://arxiv.org/abs/2311.03220) | 本文介绍了Alympics，一个利用大型语言模型代理人进行博弈论研究的系统性模拟框架。通过模拟人类战略互动，框架能够定性和定量地分析游戏决定因素、策略和结果，并对代理人在战略决策场景中的表现进行评估。 |
| [^49] | [Modelling Cellular Perturbations with the Sparse Additive Mechanism Shift Variational Autoencoder.](http://arxiv.org/abs/2311.02794) | 本研究提出了一种稀疏添加机制移位变分自动编码器（SAMS-VAE），用于建模细胞的扰动情况，并结合复合性、解缠和可解释性。通过稀疏化处理全局潜变量，SAMS-VAE能够识别出特定于干扰的潜在子空间，并在多个任务上进行了定量和定性评估。 |
| [^50] | [Learning Unsupervised World Models for Autonomous Driving via Discrete Diffusion.](http://arxiv.org/abs/2311.01017) | 本论文提出了一种通过离散扩散学习无监督的自动驾驶世界模型的新方法，通过使用VQVAE对传感器观察进行标记化并通过离散扩散预测未来，我们的模型在点云观察中实现了显著改进，将1秒预测的SOTA Chamfer距离降低了65%以上。 |
| [^51] | [LLMs may Dominate Information Access: Neural Retrievers are Biased Towards LLM-Generated Texts.](http://arxiv.org/abs/2310.20501) | 近期的研究发现，大型语言模型（LLMs）对信息检索系统产生了一种偏见，倾向于将LLM生成的文档排名较高。这种“来源偏见”可能对信息访问产生重大影响。 |
| [^52] | [Integrating Pre-trained Language Model into Neural Machine Translation.](http://arxiv.org/abs/2310.19680) | 该论文提出了PiNMT模型，将预训练语言模型整合到神经机器翻译中，通过三个关键部分和两种训练策略，实现了在IW数据集上的最先进性能。 |
| [^53] | [The Memory Perturbation Equation: Understanding Model's Sensitivity to Data.](http://arxiv.org/abs/2310.19273) | 这个论文介绍了记忆扰动方程（MPE），该方程通过应用贝叶斯原理将模型的敏感性与训练数据的扰动联系起来，并且能够准确预测模型在未见测试数据上的泛化能力。 |
| [^54] | [CXR-LLaVA: Multimodal Large Language Model for Interpreting Chest X-ray Images.](http://arxiv.org/abs/2310.18341) | 本研究开发了一种用于解读胸部X射线图像的开源多模态大型语言模型（CXR-LLaVA），通过预训练图像编码器和对比语言-图像预训练将图像与放射学异常对齐，并使用GPT-4进行微调，实现了问题回答的功能。 |
| [^55] | [Isometric Motion Manifold Primitives.](http://arxiv.org/abs/2310.17072) | Isometric Motion Manifold Primitives (IMMP) is proposed to address the degradation of Motion Manifold Primitive (MMP) performance due to geometric distortion in the latent space. IMMP preserves the geometry of the manifold in the latent coordinate space using a Riemannian metric, and experimental results show that IMMP significantly outperforms existing MMP methods. |
| [^56] | [Hierarchical Randomized Smoothing.](http://arxiv.org/abs/2310.16221) | 分层随机平滑是一种在复杂数据上进行鲁棒性认证的解决方案，通过只在一个对象的子集上添加随机噪声，以更有针对性的方式提供了更强的鲁棒性保证和高准确性。 |
| [^57] | [Penetrative AI: Making LLMs Comprehend the Physical World.](http://arxiv.org/abs/2310.09605) | 本文探讨了渗透式人工智能的概念，旨在使LLMs能够通过物联网传感器与执行器与物理世界进行交互和推理。初步研究结果表明，LLMs具有独特的能力，能够应用内嵌的世界知识解释物联网传感器数据并进行物理领域的推理。 |
| [^58] | [CP-KGC: Constrained-Prompt Knowledge Graph Completion with Large Language Models.](http://arxiv.org/abs/2310.08279) | CP-KGC方法利用大型语言模型，通过约束式提示来补全知识图谱，提高推断效果，展示了在低资源计算条件下的有效性，并在数据集上取得了优于之前方法的结果。 |
| [^59] | [What Matters to You? Towards Visual Representation Alignment for Robot Learning.](http://arxiv.org/abs/2310.07932) | 该论文提出了一种名为RAPL的方法，用于解决机器人学习中的视觉表示对齐问题，通过利用人类反馈将机器人的视觉表示与用户偏好对齐，并区分任务的关键要素。 |
| [^60] | [Learning Interactive Real-World Simulators.](http://arxiv.org/abs/2310.06114) | 通过生成建模学习交互体验的通用模拟器，以模拟人类、机器人和其他交互式代理人对真实世界中行为的响应。 |
| [^61] | [Multilingual Natural Language ProcessingModel for Radiology Reports -- The Summary is all you need!.](http://arxiv.org/abs/2310.00100) | 本研究通过在多语言文本到文本变换器模型上微调，开发了一个能够自动在多语言中总结放射学报告的模型。该模型有助于提高未来深度学习模型的研究和发展，且能够应用于不同族裔背景的患者数据。 |
| [^62] | [QAL-BP: An Augmented Lagrangian Quantum Approach for Bin Packing Problem.](http://arxiv.org/abs/2309.12678) | QAL-BP是一种增广拉格朗日量子方法，专门用于解决装箱问题。它利用增广拉格朗日方法将装箱约束加入目标函数，并通过分析估计启发式乘数，消除了需要根据实例计算Lagrangian系数的需求。 |
| [^63] | [Single and Few-step Diffusion for Generative Speech Enhancement.](http://arxiv.org/abs/2309.09677) | 本文提出了一种通过两阶段训练的方法来解决扩散模型在语音增强中的限制。第一阶段使用生成去噪评分匹配损失训练扩散模型，第二阶段通过解决反向过程来计算增强信号，并使用预测损失进行比较。这种方法只需要5个函数评估就能达到与基准模型相同的性能，而不是60个函数评估。 |
| [^64] | [CB-Whisper: Contextual Biasing Whisper using Open-Vocabulary Keyword-Spotting.](http://arxiv.org/abs/2309.09552) | CB-Whisper是一种基于OpenAI的Whisper模型的自动语音识别系统，通过使用开放词汇关键词检测（OV-KWS）识别罕见的命名实体，并使用这些实体作为提示来改进识别效果。实验证明，该方法在提高实体召回率的同时会略微增加混淆错误率（MER）。 |
| [^65] | [VoiceFlow: Efficient Text-to-Speech with Rectified Flow Matching.](http://arxiv.org/abs/2309.05027) | VoiceFlow使用矫正流匹配算法实现了高效文本转语音，并在合成质量上优于传统的扩散模型。 |
| [^66] | [Developmental Bootstrapping of AIs.](http://arxiv.org/abs/2308.04586) | 传统的符号AI方法和深度学习AI方法无法满足创建强大和可信赖的AI的挑战，然而，发展脱靴法通过模仿人类儿童的能力发展过程，为创建稳健可靠的AI提供了希望。 |
| [^67] | [An Effective LSTM-DDPM Scheme for Energy Theft Detection and Forecasting in Smart Grid.](http://arxiv.org/abs/2307.16149) | 这篇论文提出了一种利用LSTM和DDPM相结合的方案来解决智能电网系统中的能量盗窃检测和预测问题。通过重构和预测误差，系统能够准确识别能量盗窃的实例，并在实验中表现出较好的性能。 |
| [^68] | [Learning Multi-modal Representations by Watching Hundreds of Surgical Video Lectures.](http://arxiv.org/abs/2307.15220) | 通过观看手术视频讲座，我们提出了一种新方法，SurgVLP，通过利用手术视频讲座中的语音和视觉信息进行多模态表示学习，并解决了手术相关语言挑战。 |
| [^69] | [FedDRL: A Trustworthy Federated Learning Model Fusion Method Based on Staged Reinforcement Learning.](http://arxiv.org/abs/2307.13716) | FedDRL是一种分阶段强化学习的联邦学习模型融合方法，解决了传统方法中无法解决的客户端模型质量和恶意模型问题。 |
| [^70] | [Client-Level Differential Privacy via Adaptive Intermediary in Federated Medical Imaging.](http://arxiv.org/abs/2307.12542) | 本文在联邦医学成像中提出了一种客户端级差分隐私的优化策略，通过将客户端拆分为子客户端作为中介机构，来改善性能而不损害隐私。 |
| [^71] | [Multi-Stage Cable Routing through Hierarchical Imitation Learning.](http://arxiv.org/abs/2307.08927) | 本研究探讨了多阶段电缆布线任务中的层次化模仿学习方法，解决了处理可变形物体、视觉感知闭环和扩展行为的挑战。成功控制器需要能够从失败中恢复，并通过选择纠正低级控制器的缺陷。 |
| [^72] | [Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs.](http://arxiv.org/abs/2307.03393) | 本文探索了大规模语言模型（LLMs）在图学习中的潜力，并尝试了两种不同的流程：将LLMs作为增强器通过海量知识来增强节点的文本属性，并使用图神经网络（GNNs）生成预测，以及直接使用LLMs作为独立的预测器。 |
| [^73] | [iSCAN: Identifying Causal Mechanism Shifts among Nonlinear Additive Noise Models.](http://arxiv.org/abs/2306.17361) | 本文提出了一种识别非线性加性噪声模型中因果机制转变的方法，该方法专注于在相关的结构因果模型中识别功能机制的变化，而不需要估计整个有向无环图(DAG)的结构。 |
| [^74] | [Intelligence of Astronomical Optical Telescope: Present Status and Future Perspectives.](http://arxiv.org/abs/2306.16834) | 本文综合介绍了人工智能技术在天文学中的应用以及望远镜智能化的发展和研究热点，对各种研究方向进行了统计分析，并指出了各个望远镜智能化的研究趋势。 |
| [^75] | [DiffSketcher: Text Guided Vector Sketch Synthesis through Latent Diffusion Models.](http://arxiv.org/abs/2306.14685) | 本文介绍了DiffSketcher，一种通过隐式扩散模型实现文本引导的矢量素描合成的创新算法。DiffSketcher通过直接优化贝塞尔曲线和扩散模型损失来生成矢量化的手绘素描，并通过注意力图加快生成过程。实验结果表明DiffSketcher的素描质量高于之前方法。 |
| [^76] | [Progressive Energy-Based Cooperative Learning for Multi-Domain Image-to-Image Translation.](http://arxiv.org/abs/2306.14448) | 本文提出了一种渐进能量协作学习框架，用于多域图像到图像的转换。该框架包含描述器、翻译器、风格编码器和风格生成器四个组件。通过这种框架，可以实现多样化的图像生成和一对多的转换。 |
| [^77] | [Do as I can, not as I get.](http://arxiv.org/abs/2306.10345) | 该论文提出了一种名为TMR的模型，用于从模拟数据环境中挖掘有价值的信息。 |
| [^78] | [Residual Q-Learning: Offline and Online Policy Customization without Value.](http://arxiv.org/abs/2306.09526) | 该研究提出了一种新方法，使用动态控制残差的 Q 学习来进行离线和在线的策略定制，无需使用价值函数。 |
| [^79] | [ShiftAddViT: Mixture of Multiplication Primitives Towards Efficient Vision Transformer.](http://arxiv.org/abs/2306.06446) | ShiftAddViT通过使用位移和加法等多种乘法原语对ViT进行重新参数化，实现了减少乘法操作的高效视觉变换器模型，可以在GPU上实现端到端的推理加速，无需从头训练。 |
| [^80] | [Advancing Italian Biomedical Information Extraction with Large Language Models: Methodological Insights and Multicenter Practical Application.](http://arxiv.org/abs/2306.05323) | 该研究创建了意大利神经精神命名实体识别数据集，并使用巨型语言模型开发出多中心识别模型，整体 F1得分为84.77%。该模型将帮助临床从业者从非结构化的医疗记录中自动提取信息。 |
| [^81] | [Learn the Force We Can: Multi-Object Video Generation from Pixel-Level Interactions.](http://arxiv.org/abs/2306.03988) | 本论文提出了一种基于像素级交互的多目标视频生成方法，能够生成逼真的物体间相互作用的视频，且能准确跟随用户的控制，达到了最先进的视频生成先前工作相媲美甚至更好的效果。 |
| [^82] | [Optimal Decision Trees for Separable Objectives: Pushing the Limits of Dynamic Programming.](http://arxiv.org/abs/2305.19706) | 本研究提出了一种通用的动态规划方法来优化任何组合的可分离目标和约束条件，这种方法在可扩展性方面比通用求解器表现得更好。 |
| [^83] | [Exploring Phonetic Context in Lip Movement for Authentic Talking Face Generation.](http://arxiv.org/abs/2305.19556) | 本研究探讨了语音上下文对真实说话人脸生成的影响，提出了一种Context-Aware Lip-Sync框架（CALS），可利用语音上下文生成更加准确、稳定的唇部运动。 |
| [^84] | [Neural Task Synthesis for Visual Programming.](http://arxiv.org/abs/2305.18342) | 该论文提出了一种基于神经符号技术的可视化编程任务合成方法NeurTaskSyn。该方法能够针对规范中给出的解决方案代码所需要的编程概念和对可视化任务的限制，自动生成编程任务。 |
| [^85] | [Learning and Collusion in Multi-unit Auctions.](http://arxiv.org/abs/2305.17402) | 本论文研究了在多单位拍卖中学习和勾结的问题，分析了拍卖的离线和在线性质，提出了一个多项式时间算法来解决离线设置中的玩家出价最大化问题。 |
| [^86] | [Diffusion-Based Adversarial Sample Generation for Improved Stealthiness and Controllability.](http://arxiv.org/abs/2305.16494) | 本文提出了一个名为Diff-PGD的新框架，用于生成接近原始数据分布、逼真的对抗样本，具有较好的隐蔽性和对抗强度可调性。 |
| [^87] | [How to Turn Your Knowledge Graph Embeddings into Generative Models via Probabilistic Circuits.](http://arxiv.org/abs/2305.15944) | 本文提出了将知识图嵌入模型转化为生成模型的方法，允许精确MLE学习、有效抽样新的三元组以及保证逻辑约束，获得了比原始KGEs更具伸缩性的性能。 |
| [^88] | [PillarAcc: Sparse PointPillars Accelerator for Real-Time Point Cloud 3D Object Detection on Edge Devices.](http://arxiv.org/abs/2305.07522) | PillarAcc提出了一种稀疏算法-硬件协同设计，有效增强基于Pillar的三维物体检测网络，实现高效率的计算减少。 |
| [^89] | [Phase transitions in the mini-batch size for sparse and dense neural networks.](http://arxiv.org/abs/2305.06435) | 本文系统地研究了小批量大小对稀疏和密集神经网络训练的影响，发现在临界值处会出现尖锐的相变，阐明了神经网络优化的基本机制。 |
| [^90] | [Large-scale Online Ridesharing: The Effect of Assignment Optimality on System Performance.](http://arxiv.org/abs/2305.02209) | 本文介绍了一种名为VGA方法的拼车系统方法，可以用于计算大规模MoD系统中的最优乘客-车辆分配和相应的车辆路径。研究者比较了使用最优分配的MoD系统与使用普通分配的MoD系统的性能。 |
| [^91] | [Pgx: Hardware-accelerated parallel game simulation for reinforcement learning.](http://arxiv.org/abs/2303.17503) | Pgx是一个用JAX编写的游戏模拟器集合，具有强化学习硬件加速能力，支持并行执行，速度比现有的强化学习库快10倍。 它实现了Backgammon，Shogi和Go等基准测试游戏。 |
| [^92] | [A vision-based autonomous UAV inspection framework for unknown tunnel construction sites with dynamic obstacles.](http://arxiv.org/abs/2301.08422) | 本文提出了一种基于视觉的无人机视检测框架，用于动态隧道环境而无需使用先前的地图，通过分层规划方案将检测问题分解成不同层次，实现了最大化的自主水平。 |
| [^93] | [DeepSpeed Data Efficiency: Improving Deep Learning Model Quality and Training Efficiency via Efficient Data Sampling and Routing.](http://arxiv.org/abs/2212.03597) | DeepSpeed Data Efficiency提出了两种数据效率技术：高效的数据采样和高效的数据路由，能够提高深度学习模型的训练效率和质量。 |
| [^94] | [Undesirable biases in NLP: Averting a crisis of measurement.](http://arxiv.org/abs/2211.13709) | 这项研究提供了一个跨学科的方法来探讨NLP模型偏见的问题，通过采用心理测量学的视角，特别关注构念效度和测量工具的信度，在衡量模型偏见的情境中如何应用。 |
| [^95] | [Dealing with Drift of Adaptation Spaces in Learning-based Self-Adaptive Systems using Lifelong Self-Adaptation.](http://arxiv.org/abs/2211.02658) | 机器学习在自适应系统中成为热门方法，但利用机器学习会面临适应空间中的漂移问题。本文提出了一种名为"生命周期自适应"的新方法，能够更好地处理适应空间的漂移。 |
| [^96] | [Online LiDAR-Camera Extrinsic Parameters Self-checking.](http://arxiv.org/abs/2210.10537) | 本文提出了一种在线LiDAR-相机外参自检算法，解决了当前标定研究忽视标定结果正确性的问题。 |
| [^97] | [NormSAGE: Multi-Lingual Multi-Cultural Norm Discovery from Conversations On-the-Fly.](http://arxiv.org/abs/2210.08604) | NormSAGE是一个用于对话驱动的多语言多文化规范发现的框架，利用预训练的GPT-3语言模型进行知识引发，并通过自验证机制确保发现的规范正确且与源对话相关。 |
| [^98] | [A real-time dynamic obstacle tracking and mapping system for UAV navigation and collision avoidance with an RGB-D camera.](http://arxiv.org/abs/2209.08258) | 这项研究提出了一种使用RGB-D相机的实时动态障碍物跟踪和建图系统，实现无人机的导航和避障。系统使用深度图像生成动态障碍物区域，并利用卡尔曼滤波器和连续性滤波器跟踪障碍物。 |
| [^99] | [Vision-aided UAV navigation and dynamic obstacle avoidance using gradient-based B-spline trajectory optimization.](http://arxiv.org/abs/2209.07003) | 本文提出了一种基于梯度的B样条轨迹优化算法，利用机器人的内置视觉，实现了无人机在动态环境中的导航和动态避障的能力。 |
| [^100] | [You Actually Look Twice At it (YALTAi): using an object detection approach instead of region segmentation within the Kraken engine.](http://arxiv.org/abs/2207.11230) | 本研究使用对象检测方法替代了区域分割，提出了一种高效的布局分析方法。通过与Kraken和YOLOv5对比，我们发现使用YOLOv5在小数据集上的分割效果显著优于Kraken。研究还发布了两个历史文档数据集和一个新的p... |
| [^101] | [Impartial Games: A Challenge for Reinforcement Learning.](http://arxiv.org/abs/2205.12787) | AlphaZero-style reinforcement learning algorithms excel in various board games but face challenges with impartial games. The researchers present a concrete example of the game nim, and show that AlphaZero-style algorithms have difficulty learning these impartial games on larger board sizes. The difference between impartial games and partisan games can be explained by the vulnerability to adversarial attacks and perturbations. |
| [^102] | [TeleGraph: A Benchmark Dataset for Hierarchical Link Prediction.](http://arxiv.org/abs/2204.07703) | 本研究提出了一个新的基准数据集TeleGraph，用于评估和促进链接推断技术。研究结果表明，在近乎树状的网络上，现有的链接预测算法大多数无法产生满意的性能，这对实践中的链接预测算法设计和部署提出了特殊要求。 |
| [^103] | [Human Detection of Political Speech Deepfakes across Transcripts, Audio, and Video.](http://arxiv.org/abs/2202.12883) | 这项研究通过实验发现，人们在判断政治演讲的真实性时，音频和视觉信息对于准确区分真实和伪造的Deepfakes更为重要，而错误信息的基准影响较小。 |
| [^104] | [Continual learning under domain transfer with sparse synaptic bursting.](http://arxiv.org/abs/2108.12056) | 本文介绍了一个系统，通过稀疏突发神经突触，在领域转移中能够在先前未见的数据集上进行持续学习，减少遗忘。 |
| [^105] | [Hypothetical answers to continuous queries over data streams.](http://arxiv.org/abs/1905.09610) | 本文探讨了在数据流上进行连续查询时可能出现的阻塞操作和延迟答案的问题，并提出了一种能够提供假设答案的语义和相应答案的在线算法。 |
| [^106] | [PVNet: A LRCN Architecture for Spatio-Temporal Photovoltaic PowerForecasting from Numerical Weather Prediction.](http://arxiv.org/abs/1902.01453) | PVNet是一种利用数值天气预报数据的LRCN架构，用于预测24小时和48小时的光伏发电功率。该模型充分利用了时间和空间天气数据，通过与其他模型的比较，展现了较好的性能。 |

# 详细

[^1]: POMP:用于低资源无监督神经机器翻译中的概率驱动元图提示器

    POMP: Probability-driven Meta-graph Prompter for LLMs in Low-resource Unsupervised Neural Machine Translation. (arXiv:2401.05596v1 [cs.CL])

    [http://arxiv.org/abs/2401.05596](http://arxiv.org/abs/2401.05596)

    POMP是一种新颖的方法，使用动态的、基于抽样的多辅助语言图形，提高了语言模型在低资源语言中的翻译能力。

    

    低资源语言在有限的平行数据下面临着在监督神经机器翻译中的挑战，因此研究无监督方法。无监督神经机器翻译方法，包括反向翻译、迁移学习和基于枢轴的翻译，为低资源语言翻译提供了实用的解决方案，但是它们受到合成数据噪声、语言偏差和错误传播等问题的影响，这些问题可以通过大型语言模型进行缓解。语言模型通过上下文学习和有监督微调方法改进了NMT，但是训练数据不足使得在低资源语言上的性能较差。我们认为语言模型可以通过辅助语言减少语言噪声，提高低资源语言的翻译质量。在本文中，我们提出了一种名为POMP的概率驱动元图提示器，它采用了基于动态抽样的多个辅助语言的图形，以增强语言模型在低资源语言上的翻译能力。

    Low-resource languages (LRLs) face challenges in supervised neural machine translation due to limited parallel data, prompting research into unsupervised methods. Unsupervised neural machine translation (UNMT) methods, including back-translation, transfer learning, and pivot-based translation, offer practical solutions for LRL translation, but they are hindered by issues like synthetic data noise, language bias, and error propagation, which can potentially be mitigated by Large Language Models (LLMs). LLMs have advanced NMT with in-context learning (ICL) and supervised fine-tuning methods, but insufficient training data results in poor performance in LRLs. We argue that LLMs can mitigate the linguistic noise with auxiliary languages to improve translations in LRLs. In this paper, we propose Probability-driven Meta-graph Prompter (POMP), a novel approach employing a dynamic, sampling-based graph of multiple auxiliary languages to enhance LLMs' translation capabilities for LRLs. POMP inv
    
[^2]: 推理步长对大型语言模型的影响

    The Impact of Reasoning Step Length on Large Language Models. (arXiv:2401.04925v1 [cs.CL])

    [http://arxiv.org/abs/2401.04925](http://arxiv.org/abs/2401.04925)

    本研究探讨了推理步长对大型语言模型的影响，并发现在提示中增加推理步骤能显著提高模型的推理能力，而减少推理步骤则会降低模型的推理能力。

    

    思维链条（CoT）对于提高大型语言模型（LLM）的推理能力具有重要作用。然而，CoT的有效性与提示中推理步骤的长度之间的关系仍然不为人所知。为了揭示这一点，我们进行了几个实证实验来探索这些关系。具体而言，我们设计了一些实验，扩展和压缩CoT演示中的合理推理步骤，同时保持其他因素不变。我们得出了以下主要发现。首先，结果表明，在提示中延长推理步骤，即使没有向提示中添加新信息，也会显著提高LLM在多个数据集上的推理能力。相反，缩短推理步骤，即使保留关键信息，也会显著降低模型的推理能力。这一发现突显了CoT提示中步骤数量的重要性，并提供了实际指导。

    Chain of Thought (CoT) is significant in improving the reasoning abilities of large language models (LLMs). However, the correlation between the effectiveness of CoT and the length of reasoning steps in prompts remains largely unknown. To shed light on this, we have conducted several empirical experiments to explore the relations. Specifically, we design experiments that expand and compress the rationale reasoning steps within CoT demonstrations, while keeping all other factors constant. We have the following key findings. First, the results indicate that lengthening the reasoning steps in prompts, even without adding new information into the prompt, considerably enhances LLMs' reasoning abilities across multiple datasets. Alternatively, shortening the reasoning steps, even while preserving the key information, significantly diminishes the reasoning abilities of models. This finding highlights the importance of the number of steps in CoT prompts and provides practical guidance to make 
    
[^3]: 受过良好教育的智能的内在善良

    The inherent goodness of well educated intelligence. (arXiv:2401.04846v1 [econ.TH])

    [http://arxiv.org/abs/2401.04846](http://arxiv.org/abs/2401.04846)

    本文探讨了智能体变得智能的因素，强调了掌握特征和控制多个保守相互作用的子系统的能力。智能的核心是“集体如一体”和“了解局部行动的整体结果”。文章提出了一种对集体保守系统进行控制的替代方法。

    

    本文将探讨使一个智能体变得智能的因素，无论是生物体还是计算机上的人工智能。特别关注的是能够表征和控制多个保守相互作用的相同子系统的能力。智能的本质将被发现是黄金法则——“集体行动如一体”或“了解局部行动的整体结果”。集体的流动是由掌控着少量字符串的操纵者决定的，根据对称性确定的最小作用路径的测地线运动。控制集体保守系统是困难的，历史上一直通过为系统添加显著黏性来稳定期望的最大性能的亚稳平衡状态，但这会在过程中降低或破坏它们。有一种替代方案。

    This paper will examine what makes a being intelligent, whether that be a biological being or an artificial silicon being on a computer. Special attention will be paid to the being having the ability to characterize and control a collective system of many identical conservative sub-systems conservatively interacting. The essence of intelligence will be found to be the golden rule -- "the collective acts as one" or "knowing the global consequences of local actions". The flow of the collective is a small set of twinkling textures, that are governed by a puppeteer who is pulling a small number of strings according to a geodesic motion of least action, determined by the symmetries. Controlling collective conservative systems is difficult and has historically been done by adding significant viscosity to the system to stabilize the desirable meta stable equilibriums of maximum performance, but it degrades or destroys them in the process. There is an alternative. Once the optimum twinkling te
    
[^4]: 采样与束缚用于非凸优化

    Sample-and-Bound for Non-Convex Optimization. (arXiv:2401.04812v1 [cs.AI])

    [http://arxiv.org/abs/2401.04812](http://arxiv.org/abs/2401.04812)

    本论文提出了一种基于采样的非凸优化方法，采用Monte Carlo Tree Search (MCTS)来提高效率，并利用数值上估计的不确定度指标和采样估计的一阶和二阶信息，避免固定组合模式的树生长，积极缩小到有希望的区域，同时平衡探索和开发。

    

    针对非凸函数的全局优化标准方法，如分支和束缚，维护可用于系统剪枝的分区树。树的大小随维度的增加而呈指数增长。我们提出了一种新的基于采样的非凸优化方法，它改进了蒙特卡罗树搜索(MCTS)的效率。我们不再使用标准的访问计数来作为不确定度指标，而是利用目标的数值上估计作为不确定度指标，并考虑采样估计的一阶和二阶信息。我们的方法中的蒙特卡罗树避免了通常固定组合模式的树生长，并积极地缩小到有希望的区域，同时平衡探索和开发。我们将提出的算法与竞争基线在高维非凸优化基准上进行评估，并分析超参数的影响。

    Standard approaches for global optimization of non-convex functions, such as branch-and-bound, maintain partition trees to systematically prune the domain. The tree size grows exponentially in the number of dimensions. We propose new sampling-based methods for non-convex optimization that adapts Monte Carlo Tree Search (MCTS) to improve efficiency. Instead of the standard use of visitation count in Upper Confidence Bounds, we utilize numerical overapproximations of the objective as an uncertainty metric, and also take into account of sampled estimates of first-order and second-order information. The Monte Carlo tree in our approach avoids the usual fixed combinatorial patterns in growing the tree, and aggressively zooms into the promising regions, while still balancing exploration and exploitation. We evaluate the proposed algorithms on high-dimensional non-convex optimization benchmarks against competitive baselines and analyze the effects of the hyper parameters.
    
[^5]: Lightning Attention-2:在大型语言模型中处理无限序列长度的"免费午餐"

    Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models. (arXiv:2401.04658v1 [cs.CL])

    [http://arxiv.org/abs/2401.04658](http://arxiv.org/abs/2401.04658)

    本文介绍了Lightning Attention-2，这是第一个能够实现线性注意力理论计算优势的线性注意力实现。通过利用平铺的思想，分别处理了线性注意力计算中的内部块和外部块组件。具体来说，采用传统的注意力计算机制处理内部块，并使用新的累积求和方法处理外部块。

    

    线性注意力是一种高效的注意力机制，最近被认为是传统softmax注意力的一种有前景的替代方法。线性注意力理论上能够在线性的计算复杂度下处理无限长度的序列，而不会牺牲速度，即在固定的内存消耗下，能够以恒定的训练速度处理不同长度的序列。然而，由于累积求和（cumsum）的问题，当前的线性注意力算法无法在因果设置下展现其理论优势。本文提出了Lightning Attention-2，这是第一个能够实现线性注意力理论计算优势的线性注意力实现。为了实现这一点，我们利用了平铺（tiling）的思想，分别处理了线性注意力计算中的内部块和外部块组件。具体来说，我们利用传统的注意力计算机制来处理内部块，然后使用一种新的累积求和的方法来处理外部块。

    Linear attention is an efficient attention mechanism that has recently emerged as a promising alternative to conventional softmax attention. With its ability to process tokens in linear computational complexities, linear attention, in theory, can handle sequences of unlimited length without sacrificing speed, i.e., maintaining a constant training speed for various sequence lengths with a fixed memory consumption. However, due to the issue with cumulative summation (cumsum), current linear attention algorithms cannot demonstrate their theoretical advantage in a causal setting. In this paper, we present Lightning Attention-2, the first linear attention implementation that enables linear attention to realize its theoretical computational benefits. To achieve this, we leverage the thought of tiling, separately handling the intra-block and inter-block components in linear attention calculation. Specifically, we utilize the conventional attention computation mechanism for the intra-blocks an
    
[^6]: 使用解释型多视图数据预测非成像表型的深度网络

    A Deep Network for Explainable Prediction of Non-Imaging Phenotypes using Anatomical Multi-View Data. (arXiv:2401.04579v1 [q-bio.QM])

    [http://arxiv.org/abs/2401.04579](http://arxiv.org/abs/2401.04579)

    本论文研究了利用解剖多视图数据预测非成像表型的深度网络，提出了一个可解释的多视图网络（EMV-Net），通过融合不同解剖视图来提高预测性能。

    

    大型数据集通常包含多个不同的特征集或视图，这些视图提供了互补信息，可以通过多视图学习方法利用它们来提高结果。我们研究了解剖多视图数据，其中每个脑解剖结构用多个特征集描述。特别是，我们关注来自扩散MR（diffusion MRI）的白质微结构和连接特征集，以及来自结构MR（structural MRI）的灰质面积和厚度特征集。我们研究了应用多视图方法改进非成像表型（包括人口统计学特征（年龄）、运动（力量）和认知（词汇图像））预测的机器学习方法。我们提出了一个可解释的多视图网络（EMV-Net），可以利用不同的解剖视图来提高预测性能。在这个网络中，每个个体解剖视图都经过视图特定的特征提取器处理，然后将每个视图提取的信息融合在一起。

    Large datasets often contain multiple distinct feature sets, or views, that offer complementary information that can be exploited by multi-view learning methods to improve results. We investigate anatomical multi-view data, where each brain anatomical structure is described with multiple feature sets. In particular, we focus on sets of white matter microstructure and connectivity features from diffusion MRI, as well as sets of gray matter area and thickness features from structural MRI. We investigate machine learning methodology that applies multi-view approaches to improve the prediction of non-imaging phenotypes, including demographics (age), motor (strength), and cognition (picture vocabulary). We present an explainable multi-view network (EMV-Net) that can use different anatomical views to improve prediction performance. In this network, each individual anatomical view is processed by a view-specific feature extractor and the extracted information from each view is fused using a l
    
[^7]: 迈向可解释的人工智能（XAI）：一个数据挖掘的视角

    Towards Explainable Artificial Intelligence (XAI): A Data Mining Perspective. (arXiv:2401.04374v1 [cs.AI])

    [http://arxiv.org/abs/2401.04374](http://arxiv.org/abs/2401.04374)

    本研究提出了一种“数据为中心”的视角，探讨了数据收集、处理和分析在可解释的人工智能中的作用。研究将现有工作分为三个类别：深度模型的解释、训练数据的影响和领域知识的见解。通过数据挖掘操作，我们总结了这些XAI方法。

    

    鉴于深度神经网络（DNN）的复杂性和透明度不足，人们进行了大量努力，以使这些系统更具解释性或在可访问的术语中解释其行为。与大多数评论不同，该工作采用“数据为中心”的观点，研究数据收集，处理和分析如何促成可解释的人工智能（XAI）。我们将现有工作分为三类，根据其目的进行分类：深度模型的解释，涉及将数据点与模型输出相关联的特征归因和推理过程；训练数据的影响，研究训练数据细微差异（如数据评估和样本异常）对决策过程的影响；以及领域知识的见解，从数据和模型中发现潜在模式，并促进社会价值和科学发现的新知识。具体而言，我们将XAI方法论提炼为数据挖掘操作。

    Given the complexity and lack of transparency in deep neural networks (DNNs), extensive efforts have been made to make these systems more interpretable or explain their behaviors in accessible terms. Unlike most reviews, which focus on algorithmic and model-centric perspectives, this work takes a "data-centric" view, examining how data collection, processing, and analysis contribute to explainable AI (XAI). We categorize existing work into three categories subject to their purposes: interpretations of deep models, referring to feature attributions and reasoning processes that correlate data points with model outputs; influences of training data, examining the impact of training data nuances, such as data valuation and sample anomalies, on decision-making processes; and insights of domain knowledge, discovering latent patterns and fostering new knowledge from data and models to advance social values and scientific discovery. Specifically, we distill XAI methodologies into data mining op
    
[^8]: MobileAgent：通过人机交互和SOP集成增强移动控制

    MobileAgent: enhancing mobile control via human-machine interaction and SOP integration. (arXiv:2401.04124v1 [cs.HC])

    [http://arxiv.org/abs/2401.04124](http://arxiv.org/abs/2401.04124)

    MobileAgent通过人机交互和SOP集成，提高了移动控制的效率和个性化用户需求的满足，同时解决了隐私问题和代理学习中的挑战。

    

    现在以大型语言模型（LLM）为中心的代理能够为用户自动化移动设备操作。在针对学习用户的移动操作进行微调后，这些代理可以在线遵循高级用户指令。它们执行目标分解、子目标序列化和交互式环境探索等任务，直到实现最终目标。然而，在移动操作中存在与个性化用户数据相关的隐私问题，需要用户确认。此外，用户的真实操作是探索性的，行动数据复杂且冗余，给代理学习带来挑战。为了解决这些问题，在我们的实际应用中，我们设计了代理与人之间的交互任务，以识别敏感信息并与个性化用户需求对齐。此外，我们在模型的上下文学习中集成了标准操作规程（SOP）信息，以增强代理的理解能力。

    Agents centered around Large Language Models (LLMs) are now capable of automating mobile device operations for users. After fine-tuning to learn a user's mobile operations, these agents can adhere to high-level user instructions online. They execute tasks such as goal decomposition, sequencing of sub-goals, and interactive environmental exploration, until the final objective is achieved. However, privacy concerns related to personalized user data arise during mobile operations, requiring user confirmation. Moreover, users' real-world operations are exploratory, with action data being complex and redundant, posing challenges for agent learning. To address these issues, in our practical application, we have designed interactive tasks between agents and humans to identify sensitive information and align with personalized user needs. Additionally, we integrated Standard Operating Procedure (SOP) information within the model's in-context learning to enhance the agent's comprehension of comp
    
[^9]: 你的预训练模型有改进吗？一种基于多头后验的方法

    Has Your Pretrained Model Improved? A Multi-head Posterior Based Approach. (arXiv:2401.02987v1 [cs.CL])

    [http://arxiv.org/abs/2401.02987](http://arxiv.org/abs/2401.02987)

    本研究提出一种基于多头后验的方法，通过利用实体的元特征和模型的表示之间的一致性作为度量标准，有效评估预训练模型在各个领域的表现。

    

    预训练模型的出现对自然语言处理（NLP）、计算机视觉和关系型数据集等领域产生了显著影响。传统上，这些模型通过下游任务进行评估。然而，这引发了如何更高效、更有效地评估这些模型的问题。在本研究中，我们探索了一种新颖的方法，即利用与每个实体相关的元特征作为世界知识的来源，并利用模型的实体表示。我们提出使用这些表示和元特征之间的一致性作为评估预训练模型的度量标准。我们的方法在各个领域表现出了有效性，包括具有关系型数据集、大型语言模型和图像模型的模型。

    The emergence of pretrained models has significantly impacted from Natural Language Processing (NLP) and Computer Vision to relational datasets. Traditionally, these models are assessed through fine-tuned downstream tasks. However, this raises the question of how to evaluate these models more efficiently and more effectively. In this study, we explore a novel approach where we leverage the meta features associated with each entity as a source of worldly knowledge and employ entity representations from the models. We propose using the consistency between these representations and the meta features as a metric for evaluating pretrained models. Our method's effectiveness is demonstrated across various domains, including models with relational datasets, large language models and images models.
    
[^10]: 无监督的联邦领域适应用于MRI图像分割

    Unsupervised Federated Domain Adaptation for Segmentation of MRI Images. (arXiv:2401.02941v1 [cs.CV])

    [http://arxiv.org/abs/2401.02941](http://arxiv.org/abs/2401.02941)

    本文提出了一种无监督的联邦领域适应方法，可以在未注释的目标域中使用多个带有注释的源领域的知识来进行MRI图像分割。

    

    使用深度神经网络自动对磁共振成像（MRI）图像进行语义分割极大地有助于评估和规划各种临床应用的治疗。然而，训练这些模型需要大量标注数据来实施端到端的监督学习过程。即使我们标注了足够的数据，MRI图像由于患者、MRI扫描仪和成像协议的差异而显示出相当大的变异性。这种变异性需要对每个特定的应用领域重新训练神经网络，这又需要专家放射科医生对所有新领域进行手工注释。为了减轻对持续数据注释的需求，我们开发了一种无监督的联邦领域适应方法，该方法使用多个带有注释的源领域。我们的方法能够从多个带有注释的源域中转移知识，以适应在未注释的目标域中的有效使用。

    Automatic semantic segmentation of magnetic resonance imaging (MRI) images using deep neural networks greatly assists in evaluating and planning treatments for various clinical applications. However, training these models is conditioned on the availability of abundant annotated data to implement the end-to-end supervised learning procedure. Even if we annotate enough data, MRI images display considerable variability due to factors such as differences in patients, MRI scanners, and imaging protocols. This variability necessitates retraining neural networks for each specific application domain, which, in turn, requires manual annotation by expert radiologists for all new domains. To relax the need for persistent data annotation, we develop a method for unsupervised federated domain adaptation using multiple annotated source domains. Our approach enables the transfer of knowledge from several annotated source domains to adapt a model for effective use in an unannotated target domain. Init
    
[^11]: 使用迁移学习的物理信息神经网络解决高频率和多尺度问题

    Physics-Informed Neural Networks for High-Frequency and Multi-Scale Problems using Transfer Learning. (arXiv:2401.02810v1 [cs.LG])

    [http://arxiv.org/abs/2401.02810](http://arxiv.org/abs/2401.02810)

    本论文提出使用迁移学习来提高物理信息神经网络（PINN）训练的鲁棒性和收敛性。经过两个案例研究，发现迁移学习可以有效地训练PINN来近似解决方案，从低频率问题到高频率问题，而不增加网络参数，且需要更少的数据点和更短的训练时间。

    

    物理信息神经网络（PINN）是一种用于偏微分方程（ODEs/PDEs）的数据驱动求解器，提供了统一的框架来处理前向和反向问题。然而，目标函数的复杂性常常导致训练失败。当解决高频率和多尺度问题时，这个问题尤为突出。我们提出使用迁移学习来提高训练PINN的鲁棒性和收敛性，从低频率问题开始训练，并逐渐接近高频率问题。通过两个案例研究，我们发现迁移学习可以有效地训练PINN来近似解决方案，从低频率问题到高频率问题，而不增加网络参数。此外，它需要更少的数据点和更短的训练时间。我们详细描述了我们的训练策略，包括优化器的选择，并提出了使用迁移学习来训练神经网络的指南。

    Physics-informed neural network (PINN) is a data-driven solver for partial and ordinary differential equations(ODEs/PDEs). It provides a unified framework to address both forward and inverse problems. However, the complexity of the objective function often leads to training failures. This issue is particularly prominent when solving high-frequency and multi-scale problems. We proposed using transfer learning to boost the robustness and convergence of training PINN, starting training from low-frequency problems and gradually approaching high-frequency problems. Through two case studies, we discovered that transfer learning can effectively train PINN to approximate solutions from low-frequency problems to high-frequency problems without increasing network parameters. Furthermore, it requires fewer data points and less training time. We elaborately described our training strategy, including optimizer selection, and suggested guidelines for using transfer learning to train neural networks 
    
[^12]: 通过特征空间微调提高目标可传递性

    Enhancing targeted transferability via feature space fine-tuning. (arXiv:2401.02727v1 [cs.CV])

    [http://arxiv.org/abs/2401.02727](http://arxiv.org/abs/2401.02727)

    本文提出了一种通过特征空间微调AE，显著提高现有攻击的目标传递性的方法。实验结果表明，只需少量的微调即可普遍地增强攻击的传递能力，并显示出简单的迭代攻击可以与资源密集型方法相媲美甚至更好。

    

    由于其对隐私保护的潜力和激发鲁棒性神经网络的能力，对抗性示例（AEs）已经被广泛研究。然而，使目标AE在未知模型之间可传递仍然具有挑战性。在本文中，为了减轻现有简单迭代攻击所生成的AE中常见的过拟合困境，我们提出在特征空间中对其进行微调。具体而言，我们从基线攻击生成的AE开始，在源模型的中间层中鼓励有助于目标类别的特征，阻碍有助于原始类别的特征。大量实验表明，仅使用几次微调即可显著和普遍地提高现有攻击的目标传递性。我们的结果还验证了简单的迭代攻击可以产生与资源密集型方法相当甚至更好的传递性，后者依赖于训练特定目标分类器或生成特定的AE方法。

    Adversarial examples (AEs) have been extensively studied due to their potential for privacy protection and inspiring robust neural networks. However, making a targeted AE transferable across unknown models remains challenging. In this paper, to alleviate the overfitting dilemma common in an AE crafted by existing simple iterative attacks, we propose fine-tuning it in the feature space. Specifically, starting with an AE generated by a baseline attack, we encourage the features that contribute to the target class and discourage the features that contribute to the original class in a middle layer of the source model. Extensive experiments demonstrate that only a few iterations of fine-tuning can boost existing attacks in terms of targeted transferability nontrivially and universally. Our results also verify that the simple iterative attacks can yield comparable or even better transferability than the resource-intensive methods, which rely on training target-specific classifiers or generat
    
[^13]: 按照你的学习行动：非稳态马尔可夫决策过程中的自适应决策

    Act as You Learn: Adaptive Decision-Making in Non-Stationary Markov Decision Processes. (arXiv:2401.01841v1 [cs.AI])

    [http://arxiv.org/abs/2401.01841](http://arxiv.org/abs/2401.01841)

    本文提出了一种自适应蒙特卡洛树搜索算法来应对非稳态环境下的决策问题，解决了传统方法中对环境动态假设的限制和规划过程的悲观性问题。

    

    在顺序决策中，处理非稳态环境是一个基本（且在很大程度上是未解决的）挑战，其中外部环境条件随时间变化。这类问题通常被建模为非稳态马尔可夫决策过程（NSMDP）。然而，现有的NSMDP决策方法存在两个主要缺点：首先，它们假设当前时刻更新的环境动态是已知的（尽管未来动态可能会改变）；其次，规划过程主要是悲观的，即代理人会“安全行动”以考虑环境的非稳态演变。我们认为这两个假设在实践中是无效的-更新的环境条件很少是已知的，并且当代理人与环境交互时，它可以学习更新的动态并避免悲观，至少在其对动态有信心的状态下。我们提出了一种启发式搜索算法，称为自适应蒙特卡洛树搜索。

    A fundamental (and largely open) challenge in sequential decision-making is dealing with non-stationary environments, where exogenous environmental conditions change over time. Such problems are traditionally modeled as non-stationary Markov decision processes (NSMDP). However, existing approaches for decision-making in NSMDPs have two major shortcomings: first, they assume that the updated environmental dynamics at the current time are known (although future dynamics can change); and second, planning is largely pessimistic, i.e., the agent acts ``safely'' to account for the non-stationary evolution of the environment. We argue that both these assumptions are invalid in practice -updated environmental conditions are rarely known, and as the agent interacts with the environment, it can learn about the updated dynamics and avoid being pessimistic, at least in states whose dynamics it is confident about. We present a heuristic search algorithm called \textit{Adaptive Monte Carlo Tree Se
    
[^14]: 一种用于联合实体和关系抽取的自回归文本到图框架

    An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction. (arXiv:2401.01326v1 [cs.CL])

    [http://arxiv.org/abs/2401.01326](http://arxiv.org/abs/2401.01326)

    这篇论文提出了一种新颖的方法，通过将联合实体和关系抽取问题作为条件序列生成问题来解决。该方法使用了基于跨度的图生成方式，并通过指向机制将生成的输出与原始文本对齐。评估结果证明了该方法的有效性，并获得了竞争性的结果。

    

    本文提出了一种新颖的方法，将非结构化文本中的联合实体和关系抽取问题作为条件序列生成问题来解决。与传统的生成式信息抽取模型不同，我们的方法是基于跨度的，它生成一个线性化的图，其中节点表示文本跨度，边表示关系三元组。我们的方法采用了一个具有指向机制的转换器编码器-解码器架构，使用一个动态词汇表来表示跨度和关系类型。我们的模型能够通过跨度表示捕捉实体和关系的结构特征和边界，同时通过指向机制将生成的输出与原始文本进行对齐。在基准数据集上的评估验证了我们方法的有效性，展示了竞争性的结果。代码可在https://github.com/urchade/ATG找到。

    In this paper, we propose a novel method for joint entity and relation extraction from unstructured text by framing it as a conditional sequence generation problem. In contrast to conventional generative information extraction models that are left-to-right token-level generators, our approach is \textit{span-based}. It generates a linearized graph where nodes represent text spans and edges represent relation triplets. Our method employs a transformer encoder-decoder architecture with pointing mechanism on a dynamic vocabulary of spans and relation types. Our model can capture the structural characteristics and boundaries of entities and relations through span representations while simultaneously grounding the generated output in the original text thanks to the pointing mechanism. Evaluation on benchmark datasets validates the effectiveness of our approach, demonstrating competitive results. Code is available at https://github.com/urchade/ATG.
    
[^15]: 使用随机子空间和Dirichlet过程混合模型的子抽样集合进行无监督异常检测

    Unsupervised Outlier Detection using Random Subspace and Subsampling Ensembles of Dirichlet Process Mixtures. (arXiv:2401.00773v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2401.00773](http://arxiv.org/abs/2401.00773)

    提出一种基于随机子空间和子抽样集合的Dirichlet过程高斯混合模型的无监督异常检测方法，提高了计算效率和检测器的鲁棒性。

    

    概率混合模型被认为是一种有价值的工具，用于无监督异常检测，因为它们具有解释性，并且在统计原理上有直观基础。在这个框架内，Dirichlet过程混合模型作为传统有限混合模型在聚类和异常检测任务中的一个引人注目的替代选择。然而，尽管它们明显具有优势，但在无监督异常检测中广泛采用Dirichlet过程混合模型受到与构建检测器过程中的计算效率和对异常值的敏感性有关的挑战的阻碍。为了解决这些挑战，我们提出了一种基于Dirichlet过程高斯混合模型集合的新型异常检测方法。所提出的方法是一种完全无监督的算法，利用了随机子空间和子抽样集合，不仅确保了高效计算，还增强了结果异常检测器的鲁棒性。

    Probabilistic mixture models are acknowledged as a valuable tool for unsupervised outlier detection owing to their interpretability and intuitive grounding in statistical principles. Within this framework, Dirichlet process mixture models emerge as a compelling alternative to conventional finite mixture models for both clustering and outlier detection tasks. However, despite their evident advantages, the widespread adoption of Dirichlet process mixture models in unsupervised outlier detection has been hampered by challenges related to computational inefficiency and sensitivity to outliers during the construction of detectors. To tackle these challenges, we propose a novel outlier detection method based on ensembles of Dirichlet process Gaussian mixtures. The proposed method is a fully unsupervised algorithm that capitalizes on random subspace and subsampling ensembles, not only ensuring efficient computation but also enhancing the robustness of the resulting outlier detector. Moreover,
    
[^16]: ToolEyes：大型语言模型在实际情景中的工具学习能力的细粒度评估

    ToolEyes: Fine-Grained Evaluation for Tool Learning Capabilities of Large Language Models in Real-world Scenarios. (arXiv:2401.00741v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.00741](http://arxiv.org/abs/2401.00741)

    ToolEyes是一个专门用于评估大型语言模型在真实情景中的工具学习能力的细粒度系统，通过对七个真实情景的详细分析，评估了LLMs在工具学习的五个关键维度，并提供了一个拥有600种工具的工具库作为中介。

    

    现有的工具学习评估主要集中于验证大型语言模型（LLMs）选择的工具与期望结果的一致性。然而，这些方法依赖于一组有限的情景，在这些情景中答案可以事先确定，与真实需求背道而驰。此外，仅关注结果忽视了LLMs有效利用工具所需的复杂能力。为解决这个问题，我们提出了ToolEyes，这是一个特别针对LLMs工具学习能力在真实情景中评估的细粒度系统。该系统详细分析了七个真实情景，分析了对LLMs在工具学习中至关重要的五个维度：格式对齐，意图理解，行为规划，工具选择和答案组织。此外，ToolEyes还包含一个拥有约600种工具的工具库，作为LLMs与物理世界之间的中介。在涉及三个类别的十个LLMs的评估中，ToolEyes取得了如下的创新与贡献。

    Existing evaluations of tool learning primarily focus on validating the alignment of selected tools for large language models (LLMs) with expected outcomes. However, these approaches rely on a limited set of scenarios where answers can be pre-determined, diverging from genuine needs. Furthermore, a sole emphasis on outcomes disregards the intricate capabilities essential for LLMs to effectively utilize tools. To tackle this issue, we propose ToolEyes, a fine-grained system tailored for the evaluation of the LLMs' tool learning capabilities in authentic scenarios. The system meticulously examines seven real-world scenarios, analyzing five dimensions crucial to LLMs in tool learning: format alignment, intent comprehension, behavior planning, tool selection, and answer organization. Additionally, ToolEyes incorporates a tool library boasting approximately 600 tools, serving as an intermediary between LLMs and the physical world. Evaluations involving ten LLMs across three categories revea
    
[^17]: 通过多视角解耦学习改进低资源的基于提示的关系表示

    Improving Low-resource Prompt-based Relation Representation with Multi-view Decoupling Learning. (arXiv:2312.17267v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.17267](http://arxiv.org/abs/2312.17267)

    提出了一种名为MVRE的新方法，通过将关系解耦为不同的视角，生成多视角关系表示，并利用预训练语言模型（PLMs）的能力来提高低资源关系抽取任务的性能。

    

    最近，使用预训练语言模型（PLMs）进行提示调整已经展示出了显著的关系抽取（RE）任务的增强能力。然而，在低资源场景中，即训练数据有限的情况下，由于对关系的表层理解，先前基于提示的方法可能仍然表现不佳，用于表示学习。为此，我们强调在低资源场景中学习高质量关系表示对于RE的重要性，并提出了一种新的基于提示的关系表示方法，名为MVRE（多视角关系抽取），以更好地利用PLMs的能力来改善低资源提示调整范式下的RE性能。具体而言，MVRE将每个关系解耦为不同的视角，以包含多视角的关系表示，以最大化关系推断过程中的似然性。此外，我们还设计了一个全局性的低领域任务学习策略，以进一步提高关系表示的质量。

    Recently, prompt-tuning with pre-trained language models (PLMs) has demonstrated the significantly enhancing ability of relation extraction (RE) tasks. However, in low-resource scenarios, where the available training data is scarce, previous prompt-based methods may still perform poorly for prompt-based representation learning due to a superficial understanding of the relation. To this end, we highlight the importance of learning high-quality relation representation in low-resource scenarios for RE, and propose a novel prompt-based relation representation method, named MVRE (\underline{M}ulti-\underline{V}iew \underline{R}elation \underline{E}xtraction), to better leverage the capacity of PLMs to improve the performance of RE within the low-resource prompt-tuning paradigm. Specifically, MVRE decouples each relation into different perspectives to encompass multi-view relation representations for maximizing the likelihood during relation inference. Furthermore, we also design a Global-Lo
    
[^18]: TAPE: 利用代理拓扑进行协作多智能体策略梯度

    TAPE: Leveraging Agent Topology for Cooperative Multi-Agent Policy Gradient. (arXiv:2312.15667v2 [cs.MA] UPDATED)

    [http://arxiv.org/abs/2312.15667](http://arxiv.org/abs/2312.15667)

    TAPE提出了一种代理拓扑框架，用于解决多智能体策略梯度方法中的集中-分散不匹配（CDM）问题，通过平衡合作和减轻CDM的影响。

    

    多智能体策略梯度（MAPG）在近年取得了显著进展。然而，最先进的MAPG方法中的集中式评论器仍然面临集中-分散不匹配（CDM）问题，这意味着一些智能体的次优行动会影响其他智能体的策略学习。虽然使用单独的评论器可以避免这个问题，但它们严重限制了智能体之间的协作。为了解决这个问题，我们提出了一个代理拓扑框架，该框架决定了在策略梯度中是否应考虑其他代理，并在促进合作和减轻CDM问题之间取得平衡。代理拓扑允许代理使用合作效用作为学习目标，而不是由集中式评论器确定的全局效用或者由个体评论器确定的局部效用。为了构建代理拓扑，我们研究了多种模型。我们提出了基于拓扑的多智能体策略梯度（TAPE），适用于随机和确定性的MAPG方法。

    Multi-Agent Policy Gradient (MAPG) has made significant progress in recent years. However, centralized critics in state-of-the-art MAPG methods still face the centralized-decentralized mismatch (CDM) issue, which means sub-optimal actions by some agents will affect other agent's policy learning. While using individual critics for policy updates can avoid this issue, they severely limit cooperation among agents. To address this issue, we propose an agent topology framework, which decides whether other agents should be considered in policy gradient and achieves compromise between facilitating cooperation and alleviating the CDM issue. The agent topology allows agents to use coalition utility as learning objective instead of global utility by centralized critics or local utility by individual critics. To constitute the agent topology, various models are studied. We propose Topology-based multi-Agent Policy gradiEnt (TAPE) for both stochastic and deterministic MAPG methods. We prove the po
    
[^19]: 在生产中用开源SLMs替代专有LLMs的权衡分析

    A Trade-off Analysis of Replacing Proprietary LLMs with Open Source SLMs in Production. (arXiv:2312.14972v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2312.14972](http://arxiv.org/abs/2312.14972)

    本文提出了一种系统的评估方法来比较专有LLMs和开源SLMs的权衡，并设计了一个自动化分析工具SLaM来测试产品功能。在实际产品功能替换时，对于现有能力是否能够被开源SLMs代替，还需要进一步研究。

    

    许多公司依赖于管理的AI模型的API，如OpenAI的GPT-4，以在其产品中创建AI增强体验。除了使用便利和缩短生产时间的好处外，依赖专有API还具有模型控制、性能可靠性、上线可预测性和成本方面的缺点。与此同时，已经涌现了许多供商业使用的开源小型语言模型（SLMs）。然而，它们替代现有能力的准备情况尚不清楚，并且没有现成的系统方法来测试这些模型。在本文中，我们提出了一种系统的评估方法，该方法对现代开源SLMs及其在替代真实产品功能的专有LLM APIs时所做的权衡进行了表征。我们设计了一个名为SLaM的自动化分析工具，使得可以定量和定性地测试使用任意SLMs的产品功能。使用SLaM，我们对机器人进行了检验。

    Many companies rely on APIs of managed AI models such as OpenAI's GPT-4 to create AI-enabled experiences in their products. Along with the benefits of ease of use and shortened time to production, this reliance on proprietary APIs has downsides in terms of model control, performance reliability, up-time predictability, and cost. At the same time, there has been a flurry of open source small language models (SLMs) that have been made available for commercial use. However, their readiness to replace existing capabilities remains unclear, and a systematic approach to test these models is not readily available. In this paper, we present a systematic evaluation methodology for, and characterization of, modern open source SLMs and their trade-offs when replacing a proprietary LLM APIs for a real-world product feature. We have designed SLaM, an automated analysis tool that enables the quantitative and qualitative testing of product features utilizing arbitrary SLMs. Using SLaM, we examine bot
    
[^20]: 系统化和自动化测试针对代码的指令调整大型语言模型的涡流方法

    Turbulence: Systematically and Automatically Testing Instruction-Tuned Large Language Models for Code. (arXiv:2312.14856v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2312.14856](http://arxiv.org/abs/2312.14856)

    这项研究提出了一种通过新的基准测试Turbulence来系统评估针对代码生成的指令调整大型语言模型（LLMs）的正确性和鲁棒性的方法。通过构建一组问题模板，可以评估LLMs在解决相似编程问题时的准确性，并发现其代码生成能力的缺陷和异常情况。这项研究在五个LLMs上进行了实验。

    

    我们提出了一种通过一个新的基准测试Turbulence，系统评估针对代码生成的指令调整大型语言模型（LLM）的正确性和鲁棒性的方法。Turbulence包含一组大量的自然语言“问题模板”，每个模板都是一个编程问题，参数化使得可以以多种不同形式提问。每个问题模板都有一个相关的“测试预测器”，用来判断LLM返回的代码解决方案是否正确。因此，通过一个问题模板，可以向LLM提问一个非常相似的编程问题“邻域”，并评估每个问题返回的结果的正确性。这允许识别LLM代码生成能力的差距，包括LLM在邻域中解决“几乎所有”问题但对特定参数实例化失败的“异常”。我们针对OpenAI、Co等五个LLM进行了实验。

    We present a method for systematically evaluating the correctness and robustness of instruction-tuned large language models (LLMs) for code generation via a new benchmark, Turbulence. Turbulence consists of a large set of natural language $\textit{question templates}$, each of which is a programming problem, parameterised so that it can be asked in many different forms. Each question template has an associated $\textit{test oracle}$ that judges whether a code solution returned by an LLM is correct. Thus, from a single question template, it is possible to ask an LLM a $\textit{neighbourhood}$ of very similar programming questions, and assess the correctness of the result returned for each question. This allows gaps in an LLM's code generation abilities to be identified, including $\textit{anomalies}$ where the LLM correctly solves $\textit{almost all}$ questions in a neighbourhood but fails for particular parameter instantiations. We present experiments against five LLMs from OpenAI, Co
    
[^21]: WellFactor:使用综合嵌入医疗数据的患者分类方法

    WellFactor: Patient Profiling using Integrative Embedding of Healthcare Data. (arXiv:2312.14129v1 [cs.LG] CROSS LISTED)

    [http://arxiv.org/abs/2312.14129](http://arxiv.org/abs/2312.14129)

    WellFactor是一种使用综合嵌入医疗数据的患者分类方法，并通过使用受约束的低秩逼近、结合标签信息来优化嵌入结果，同时具有即时计算新数据嵌入的特点。在实际医疗数据上得到了验证。

    

    在快速发展的医疗行业中，平台现在不仅可以访问传统的医疗记录，还可以获取涵盖各种患者互动的各种数据集，例如来自医疗网站的数据。为了解决这种丰富的数据多样性，我们引入了WellFactor：一种通过整合这些来源信息来得出患者分类的方法。我们方法的核心是利用受约束的低秩逼近。WellFactor被优化为处理医疗数据中经常存在的稀疏性。此外，通过结合特定任务的标签信息，我们的方法改进了嵌入结果，提供了更加明智的患者视角。WellFactor的一个重要特点是能够即时计算新的、以前未观察到的患者数据的嵌入，消除了重新访问整个数据集或重新计算嵌入的需要。对实际医疗数据进行全面评估证明了WellFactor的有效性。

    In the rapidly evolving healthcare industry, platforms now have access to not only traditional medical records, but also diverse data sets encompassing various patient interactions, such as those from healthcare web portals. To address this rich diversity of data, we introduce WellFactor: a method that derives patient profiles by integrating information from these sources. Central to our approach is the utilization of constrained low-rank approximation. WellFactor is optimized to handle the sparsity that is often inherent in healthcare data. Moreover, by incorporating task-specific label information, our method refines the embedding results, offering a more informed perspective on patients. One important feature of WellFactor is its ability to compute embeddings for new, previously unobserved patient data instantaneously, eliminating the need to revisit the entire data set or recomputing the embedding. Comprehensive evaluations on real-world healthcare data demonstrate WellFactor's eff
    
[^22]: 使用受限玻尔兹曼机的图像聚类

    Image Clustering using Restricted Boltzman Machine. (arXiv:2312.13845v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.13845](http://arxiv.org/abs/2312.13845)

    本文提出了使用受限玻尔兹曼机进行图像聚类的方法，通过训练RBMs将图像转换为图像嵌入，并使用自底向上的聚类技术进行聚类。为了应对有限的测试图像数据，提出了AHC-RBM方法，通过训练通用的RBM模型和适应性RBM模型来生成RBM向量，从而实现有效的图像聚类。

    

    在各种验证系统中，受限玻尔兹曼机（RBMs）已经证明了在前端和后端处理中的有效性。本文提出使用RBMs进行图像聚类任务。RBMs被训练成将图像转换为图像嵌入。我们采用传统的自底向上的聚类（AHC）技术。为了解决有限的测试脸部图像数据的挑战，我们引入了基于受限玻尔兹曼机的自底向上聚类图像聚类方法（AHC-RBM）的两个主要步骤。首先，使用所有可用的训练数据集训练一个通用的RBM模型。随后，使用每个测试图像的数据训练一个适应性RBM模型。最后，通过连接这些适应性模型的可见到隐藏权重矩阵和偏置向量生成RBM向量，这些向量有效地保留了类别特定的信息，并在图像聚类中使用。

    In various verification systems, Restricted Boltzmann Machines (RBMs) have demonstrated their efficacy in both front-end and back-end processes. In this work, we propose the use of RBMs to the image clustering tasks. RBMs are trained to convert images into image embeddings. We employ the conventional bottom-up Agglomerative Hierarchical Clustering (AHC) technique. To address the challenge of limited test face image data, we introduce Agglomerative Hierarchical Clustering based Method for Image Clustering using Restricted Boltzmann Machine (AHC-RBM) with two major steps. Initially, a universal RBM model is trained using all available training dataset. Subsequently, we train an adapted RBM model using the data from each test image. Finally, RBM vectors which is the embedding vector is generated by concatenating the visible-to-hidden weight matrices of these adapted models, and the bias vectors. These vectors effectively preserve class-specific information and are utilized in image cluste
    
[^23]: 使用对比置信度调整的知识图谱错误检测

    Knowledge Graph Error Detection with Contrastive Confidence Adaption. (arXiv:2312.12108v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.12108](http://arxiv.org/abs/2312.12108)

    本文提出了一种使用对比学习和交互式对比学习的知识图谱错误检测模型CCA，通过综合文本和图结构信息，更好地区分语义，从而在检测噪声方面优于当前最先进的方法。

    

    知识图谱（KGs）中常常包含各种错误。以往关于KG错误检测的研究主要依赖于从图结构中嵌入的三元组。我们进行了实证研究发现，这些方法在区分噪声和语义相似的正确三元组方面存在困难。本文提出了一种KG错误检测模型CCA，通过从三元组重构中综合文本和图结构信息，更好地区分语义。我们设计了交互式对比学习来捕捉文本和结构模式之间的差异。此外，我们构建了具有语义相似噪声和对抗性噪声的实际数据集。实验结果表明，CCA在检测语义相似噪声和对抗性噪声方面优于当前最先进的基线方法。

    Knowledge graphs (KGs) often contain various errors. Previous works on detecting errors in KGs mainly rely on triplet embedding from graph structure. We conduct an empirical study and find that these works struggle to discriminate noise from semantically-similar correct triplets. In this paper, we propose a KG error detection model CCA to integrate both textual and graph structural information from triplet reconstruction for better distinguishing semantics. We design interactive contrastive learning to capture the differences between textual and structural patterns. Furthermore, we construct realistic datasets with semantically-similar noise and adversarial noise. Experimental results demonstrate that CCA outperforms state-of-the-art baselines, especially in detecting semantically-similar noise and adversarial noise.
    
[^24]: 《代码中的大型语言模型中的记忆痕迹》

    Traces of Memorisation in Large Language Models for Code. (arXiv:2312.11658v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2312.11658](http://arxiv.org/abs/2312.11658)

    大型语言模型在代码中有记忆痕迹，容易受到数据提取攻击。

    

    大型语言模型因其生成类似人类文本的能力和在软件工程等领域的潜在应用而受到广泛关注。代码的大型语言模型通常是在从互联网上抓取的大规模未经过滤的源代码语料库上进行训练的。这些数据集的内容被记住，并且可以通过数据提取攻击被攻击者提取出来。在本文中，我们探讨了大型代码语言模型中的记忆痕迹，并将记忆痕迹率与针对自然语言的大型语言模型进行了比较。我们采用了一个现有的自然语言基准，并通过识别容易受到攻击的样本构建了一个代码基准。我们运行了两个基准对多种模型进行测试，并进行了数据提取攻击。我们发现，代码的大型语言模型像它们的自然语言对应物一样容易受到数据提取攻击。从被确定为潜在受攻击的训练数据中，我们发现...

    Large language models have gained significant popularity because of their ability to generate human-like text and potential applications in various fields, such as Software Engineering. Large language models for code are commonly trained on large unsanitised corpora of source code scraped from the internet. The content of these datasets is memorised and can be extracted by attackers with data extraction attacks. In this work, we explore memorisation in large language models for code and compare the rate of memorisation with large language models trained on natural language. We adopt an existing benchmark for natural language and construct a benchmark for code by identifying samples that are vulnerable to attack. We run both benchmarks against a variety of models, and perform a data extraction attack. We find that large language models for code are vulnerable to data extraction attacks, like their natural language counterparts. From the training data that was identified to be potentiall
    
[^25]: "原文改写"提高了高精度长文本问答的效果

    "Paraphrasing The Original Text" Makes High Accuracy Long-Context QA. (arXiv:2312.11193v6 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.11193](http://arxiv.org/abs/2312.11193)

    本论文提出了一种名为"原文改写"的任务来处理长文本问答，通过低成本高效的方法成功扩展了现有模型的上下文窗口至32k，并在多文档问答中达到了最先进的准确性。

    

    当面对长文本时，大多数开源生成式语言模型的上下文窗口限制在4k以内，这限制了它们的能力。即使是具有更长上下文窗口的模型也无法在长上下文问题上保证令人满意的准确性。为了解决这个问题，我们从训练数据的角度出发，从理论上证明了提高处理长上下文能力需要的是"有效"而不仅仅是"长"的数据。基于这个洞见，我们提出了使用"原文改写"任务，并通过一种低成本高效的方法，成功将现有模型的上下文窗口扩展到32k。我们的微调模型在具有相近规模的模型中在多文档问答方面达到了最先进的准确性。模型和训练数据已经在HuggingFace（https://huggingface.co/yuyijiong/Qwen-14b-chat-yarn-32k）和WiseModel（https://wisemodel.cn/models/yuyijiong/Qwen-14b-chat-yarn-32k）上提供。

    Most open-source generative language models currently have a context window of no more than 4k, limiting their ability when facing long text. Even models with longer context windows cannot guarantee satisfactory accuracy on long-context problems. To tackle this issue, we explore from the perspective of training data and theoretically demonstrate that improving the capability to handle long contexts requires "effective" rather than simply "long" data. Based on this insight, we propose using the "original text paraphrasing" task and successfully extend the context window of existing models to 32k through a low-cost and effective method. Our fine-tuned model achieves state-of-the-art accuracy in multi-document-QA among models of comparable scale. The model and training data have been made available on HuggingFace(https://huggingface.co/yuyijiong/Qwen-14b-chat-yarn-32k) and WiseModel(https://wisemodel.cn/models/yuyijiong/Qwen-14b-chat-yarn-32k).
    
[^26]: 通过场景图知识推进外科视觉问答

    Advancing Surgical VQA with Scene Graph Knowledge. (arXiv:2312.10251v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.10251](http://arxiv.org/abs/2312.10251)

    本研究通过场景图知识推进了手术环境中的视觉问答（VQA），解决了手术VQA系统中的问题条件偏倚和缺乏场景感知推理的挑战。

    

    现代手术室越来越复杂，需要创新的术中支持系统。尽管外科数据科学的重点主要在于视频分析，但将外科计算机视觉与语言能力相结合成为必要的趋势。我们的工作旨在通过场景图知识推进手术环境中的视觉问答（VQA），解决当前手术VQA系统中的两个主要挑战：消除手术VQA数据集中的问题条件偏倚，以及在手术VQA模型设计中融入场景感知推理。首先，我们提出了一个基于手术场景图的数据集SSG-QA，通过在公开数据集上应用分割和检测模型来生成。我们使用仪器和解剖结构的空间和动作信息构建手术场景图。这些图被输入到一个问题引擎中，产生多样化的问答对。我们的SSG-QA数据集提供了一个更复杂、多样化、几何基础、无偏倚的数据集。

    Modern operating room is becoming increasingly complex, requiring innovative intra-operative support systems. While the focus of surgical data science has largely been on video analysis, integrating surgical computer vision with language capabilities is emerging as a necessity. Our work aims to advance Visual Question Answering (VQA) in the surgical context with scene graph knowledge, addressing two main challenges in the current surgical VQA systems: removing question-condition bias in the surgical VQA dataset and incorporating scene-aware reasoning in the surgical VQA model design. First, we propose a Surgical Scene Graph-based dataset, SSG-QA, generated by employing segmentation and detection models on publicly available datasets. We build surgical scene graphs using spatial and action information of instruments and anatomies. These graphs are fed into a question engine, generating diverse QA pairs. Our SSG-QA dataset provides a more complex, diverse, geometrically grounded, unbiase
    
[^27]: CARAT: 对于多模态多标签情绪识别的对比特征重构和聚合

    CARAT: Contrastive Feature Reconstruction and Aggregation for Multi-Modal Multi-Label Emotion Recognition. (arXiv:2312.10201v3 [cs.MM] UPDATED)

    [http://arxiv.org/abs/2312.10201](http://arxiv.org/abs/2312.10201)

    本文提出了对比特征重构和聚合（CARAT）方法，用于多模态多标签情绪识别。通过对比学习模态分离和标签特定的特征，CARAT能更好地建模细粒度的模态对标签的依赖关系。

    

    多模态多标签情绪识别旨在从多个模态中识别相关情绪。MMER的挑战在于如何有效地捕捉来自异构数据的多个标签的判别特征。最近的研究主要致力于探索各种融合策略，将多模态信息集成到统一表示中的所有标签。然而，这种学习方案不仅忽视了每种模态的特殊性，也无法捕捉不同标签的个别判别特征。此外，标签和模态的依赖关系也无法有效建模。为了解决这些问题，本文提出了一种用于MMER任务的对比特征重构和聚合（CARAT）方法。具体而言，我们设计了一种基于重构的融合机制，通过对比学习模态分离和标签特定的特征，更好地建模细粒度的模态对标签的依赖关系。

    Multi-modal multi-label emotion recognition (MMER) aims to identify relevant emotions from multiple modalities. The challenge of MMER is how to effectively capture discriminative features for multiple labels from heterogeneous data. Recent studies are mainly devoted to exploring various fusion strategies to integrate multi-modal information into a unified representation for all labels. However, such a learning scheme not only overlooks the specificity of each modality but also fails to capture individual discriminative features for different labels. Moreover, dependencies of labels and modalities cannot be effectively modeled. To address these issues, this paper presents ContrAstive feature Reconstruction and AggregaTion (CARAT) for the MMER task. Specifically, we devise a reconstruction-based fusion mechanism to better model fine-grained modality-to-label dependencies by contrastively learning modal-separated and label-specific features. To further exploit the modality complementarity
    
[^28]: 深度学习时代的药物发现中的形态学特征分析

    Morphological Profiling for Drug Discovery in the Era of Deep Learning. (arXiv:2312.07899v2 [q-bio.QM] UPDATED)

    [http://arxiv.org/abs/2312.07899](http://arxiv.org/abs/2312.07899)

    形态学特征分析在表型药物发现中具有重要价值。深度学习技术在分析大规模高内容图像方面取得了显著进展，促进了药物作用机制的理解和新治疗方法的开发。

    

    形态学特征分析是表型药物发现中的有价值工具。高通量自动成像的出现使得能够以单细胞分辨率捕捉细胞或生物体对干扰的形态学特征的广泛范围。与此同时，机器学习和深度学习，尤其是计算机视觉领域的重大进展，使得在高通量下分析大规模高内容图像的能力得到了显著提高。这些努力促进了对化合物作用机制、药物再利用、干扰下细胞形态动力学特征的了解，并最终有助于新治疗方法的开发。在本综述中，我们全面概述了形态学特征分析领域的最新进展。我们总结了图像分析工作流程，调查了包括特征工程和基于深度学习的分析策略在内的广泛范围的分析策略，并讨论了在这一领域的潜在应用。

    Morphological profiling is a valuable tool in phenotypic drug discovery. The advent of high-throughput automated imaging has enabled the capturing of a wide range of morphological features of cells or organisms in response to perturbations at the single-cell resolution. Concurrently, significant advances in machine learning and deep learning, especially in computer vision, have led to substantial improvements in analyzing large-scale high-content images at high-throughput. These efforts have facilitated understanding of compound mechanism-of-action (MOA), drug repurposing, characterization of cell morphodynamics under perturbation, and ultimately contributing to the development of novel therapeutics. In this review, we provide a comprehensive overview of the recent advances in the field of morphological profiling. We summarize the image profiling analysis workflow, survey a broad spectrum of analysis strategies encompassing feature engineering- and deep learning-based approaches, and i
    
[^29]: 特征引导：大尺度导向下扩散模型的非线性校正

    Characteristic Guidance: Non-linear Correction for Diffusion Model at Large Guidance Scale. (arXiv:2312.07586v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.07586](http://arxiv.org/abs/2312.07586)

    该论文提出了特征引导方法，用于对大尺度的导向下扩散模型进行非线性校正，以增强对图像生成的控制能力，减少颜色和曝光问题，并在各种应用中显示出效果。

    

    流行的导引去噪扩散概率模型(DDPM)线性地将不同的条件模型组合在一起，以提供对样本的增强控制。然而，这种方法忽视了当导向尺度变大时产生的非线性效应。为了解决这个问题，我们提出了特征引导，一种采样方法，为无分类器导向的DDPM提供了一种基于原理的非线性校正。这种校正迫使导向的DDPM遵守其底层扩散过程的福克-普朗克方程，这种方法无需训练，无需导数，与现有的采样方法兼容。实验证明，特征引导增强了对图像生成中的控制能力，并减少了颜色和曝光问题，对从潜在空间采样到解决物理问题如磁相变的各种应用都有效。

    Popular guidance for denoising diffusion probabilistic model (DDPM) linearly combines distinct conditional models together to provide enhanced control over samples. However, this approach overlooks nonlinear effects that become significant when guidance scale is large. To address this issue, we propose characteristic guidance, a sampling method that provides first-principle non-linear correction for classifier-free guided DDPMs. Such correction forces the guided DDPMs to respect the Fokker-Planck equation of their underlying diffusion process, in a way that is training-free, derivative-free, and compatible with existing sampling methods. Experiments show that characteristic guidance enhances control and reduces color and exposure issues in image generation, proving effective in diverse applications ranging from latent space sampling to solving physics problems like magnet phase transitions.
    
[^30]: 信任守护者：通过供应商合作在AIOps中导航数据安全

    Guardians of Trust: Navigating Data Security in AIOps through Vendor Partnerships. (arXiv:2312.06008v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2312.06008](http://arxiv.org/abs/2312.06008)

    本文讨论了在AIOps中与供应商合作时数据安全的重要性，并探讨了如何通过采用最佳实践来保护数据和隐私。

    

    IT运维中人工智能（AIOps）是一个快速发展的领域，应用人工智能和机器学习来自动化和优化IT运维。AIOps供应商提供服务，可以接收端到端日志、跟踪和指标，提供对IT系统的全栈监控。然而，这些数据源可能包含敏感信息，例如内部IP地址、主机名、HTTP头、SQL、方法/参数的返回值、URL和个人识别信息（PII）或机密业务数据。因此，在与AIOps供应商合作时，数据安全是一个重要的问题。在本文中，我们将讨论不同供应商所提供的安全特性，以及如何采用最佳实践来确保数据的保护和隐私。

    Artificial Intelligence for IT Operations (AIOps) is a rapidly growing field that applies artificial intelligence and machine learning to automate and optimize IT operations. AIOps vendors provide services that ingest end-to-end logs, traces, and metrics to offer a full stack observability of IT systems. However, these data sources may contain sensitive information such as internal IP addresses, hostnames, HTTP headers, SQLs, method/argument return values, URLs, personal identifiable information (PII), or confidential business data. Therefore, data security is a crucial concern when working with AIOps vendors. In this article, we will discuss the security features offered by different vendors and how we can adopt best practices to ensure data protection and privacy.
    
[^31]: 通过带有噪声标签的课程学习来探索强化学习中的奇偶性挑战

    Exploring Parity Challenges in Reinforcement Learning through Curriculum Learning with Noisy Labels. (arXiv:2312.05379v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.05379](http://arxiv.org/abs/2312.05379)

    本论文通过带有噪声标签的课程学习，深入研究了在策略游戏中应用强化学习的奇偶性挑战。研究发现，即使存在最小的标签噪声，也会明显阻碍神经网络辨别有效策略的能力，这对RL训练提出了迫切需要先进方法的要求。

    

    本论文深入研究了在策略游戏中应用强化学习（RL），特别是在围棋和国际象棋等特定局面以及更广泛的不偏博弈中存在的奇偶性挑战。我们提出了一个模拟学习过程，结构化在课程学习框架内，并通过噪声标签进行增强，以模拟自我对弈学习场景的复杂性。这种方法彻底分析了神经网络（NNs）如何从基本的到越来越复杂的游戏局面中适应和演变。我们的实证研究表明，即使存在最小的标签噪声，也会对NNs辨别有效策略的能力造成明显的阻碍，这一困难随着游戏局面复杂度的增加而加剧。这些发现强调了在RL训练中迫切需要先进的方法，专门应对由噪声评估所带来的障碍。研发这样的方法对于提高NN的专业水平至关重要。

    This paper delves into applying reinforcement learning (RL) in strategy games, particularly those characterized by parity challenges, as seen in specific positions of Go and Chess and a broader range of impartial games. We propose a simulated learning process, structured within a curriculum learning framework and augmented with noisy labels, to mirror the intricacies of self-play learning scenarios. This approach thoroughly analyses how neural networks (NNs) adapt and evolve from elementary to increasingly complex game positions. Our empirical research indicates that even minimal label noise can significantly impede NNs' ability to discern effective strategies, a difficulty that intensifies with the growing complexity of the game positions. These findings underscore the urgent need for advanced methodologies in RL training, specifically tailored to counter the obstacles imposed by noisy evaluations. The development of such methodologies is crucial not only for enhancing NN proficiency 
    
[^32]: CLadder: 评估语言模型因果推理能力的基准测试

    CLadder: A Benchmark to Assess Causal Reasoning Capabilities of Language Models. (arXiv:2312.04350v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.04350](http://arxiv.org/abs/2312.04350)

    该论文提出了一个新的NLP任务，评估语言模型在因果推理方面的能力。作者构建了一个大规模的数据集CLadder，并利用oracle因果推理引擎将符号问题转化为自然语言。研究结果表明多个LLMs在该数据集上的表现，并引入并评估了一种定制的链式推理机制。

    

    进行因果推理的能力被广泛视为智能的核心特征。本文研究了大型语言模型(LLMs)能否连贯地推理因果关系。现有的自然语言处理(NLP)工作主要关注评估LLMs中的常识因果推理，未能评估模型是否能够按照一组明确定义的形式规则执行因果推断。为了解决这个问题，我们提出了一个新的NLP任务，自然语言中的因果推断，受到Judea Pearl等人提出的“因果推断引擎”的启发。我们构建了一个包含10K个样本的大型数据集CLadder，通过一种oracle因果推理引擎，基于一组因果图和查询(联合、干预和反事实)，得到符号问题和真实答案，并将其翻译为自然语言。我们对数据集上的多个LLMs进行评估，并引入和评估了一种定制的链式推理机制。

    The ability to perform causal reasoning is widely considered a core feature of intelligence. In this work, we investigate whether large language models (LLMs) can coherently reason about causality. Much of the existing work in natural language processing (NLP) focuses on evaluating commonsense causal reasoning in LLMs, thus failing to assess whether a model can perform causal inference in accordance with a set of well-defined formal rules. To address this, we propose a new NLP task, causal inference in natural language, inspired by the "causal inference engine" postulated by Judea Pearl et al. We compose a large dataset, CLadder, with 10K samples: based on a collection of causal graphs and queries (associational, interventional, and counterfactual), we obtain symbolic questions and ground-truth answers, through an oracle causal inference engine. These are then translated into natural language. We evaluate multiple LLMs on our dataset, and we introduce and evaluate a bespoke chain-of-th
    
[^33]: 图卷积在Transformer的自注意力机制中起到了改进的作用！（arXiv：2312.04234v2 [cs.LG]已更新）

    Graph Convolutions Enrich the Self-Attention in Transformers!. (arXiv:2312.04234v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.04234](http://arxiv.org/abs/2312.04234)

    这项研究通过引入图卷积来改进Transformer模型中的自注意力机制，并在计算机视觉、自然语言处理等多个领域展示了其性能提升。

    

    Transformer因其自注意力机制而闻名，在自然语言处理、计算机视觉、时间序列建模等各种任务中取得了最先进的性能。然而，深度Transformer模型面临的挑战之一是过度平滑问题，即表示在各个层之间趋于无法区分的值，导致性能严重下降。我们将原始的自注意力机制解释为一种简单的图滤波器，并从图信号处理（GSP）的角度重新设计它。我们提出了基于图滤波器的自注意力机制（GFSA），以学习一种既通用又有效的机制，其复杂度略高于原始的自注意力机制。我们证明了GFSA在计算机视觉、自然语言处理、图模式分类、语音识别和代码分类等多个领域中改进了Transformer的性能。

    Transformers, renowned for their self-attention mechanism, have achieved state-of-the-art performance across various tasks in natural language processing, computer vision, time-series modeling, etc. However, one of the challenges with deep Transformer models is the oversmoothing problem, where representations across layers converge to indistinguishable values, leading to significant performance degradation. We interpret the original self-attention as a simple graph filter and redesign it from a graph signal processing (GSP) perspective. We propose graph-filter-based self-attention (GFSA) to learn a general yet effective one, whose complexity, however, is slightly larger than that of the original self-attention mechanism. We demonstrate that GFSA improves the performance of Transformers in various fields, including computer vision, natural language processing, graph pattern classification, speech recognition, and code classification.
    
[^34]: 住宅建筑供暖的需求响应：基于物理启发神经网络的有效蒙特卡洛树搜索控制

    Demand response for residential building heating: Effective Monte Carlo Tree Search control based on physics-informed neural networks. (arXiv:2312.03365v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2312.03365](http://arxiv.org/abs/2312.03365)

    本文重点研究了基于物理启发神经网络的蒙特卡洛树搜索控制方法在住宅建筑供暖的需求响应中的应用，该方法通过灵活的优化整合了外部约束条件，为实现能源消耗的优化和用户热舒适度的保证提供了有前景的解决方案。

    

    控制建筑物的能源消耗通过需求响应已成为减少全球碳排放和限制气候变化的越来越重要的手段。本文特别关注住宅建筑供暖系统的控制，以优化能源消耗同时保证用户的热舒适度。在这个领域，最近的研究主要集中在基于模型的控制，例如模型预测控制（MPC），或者基于模型无关的强化学习（RL）来实现实际的需求响应算法。蒙特卡洛树搜索（MCTS）是一种最近在棋盘游戏（围棋、国际象棋）等领域取得了令人印象深刻成功的RL方法。然而，在建筑控制方面，MCTS仍然被较少探索。因此，我们专门研究了MCTS在建筑需求响应方面的应用。其自然的结构允许灵活的优化，隐式地集成外部约束条件（与传统的RL解决方案相比），使MCTS成为一个有前景的候选方法。

    Controlling energy consumption in buildings through demand response (DR) has become increasingly important to reduce global carbon emissions and limit climate change. In this paper, we specifically focus on controlling the heating system of a residential building to optimize its energy consumption while respecting user's thermal comfort. Recent works in this area have mainly focused on either model-based control, e.g., model predictive control (MPC), or model-free reinforcement learning (RL) to implement practical DR algorithms. A specific RL method that recently has achieved impressive success in domains such as board games (go, chess) is Monte Carlo Tree Search (MCTS). Yet, for building control it has remained largely unexplored. Thus, we study MCTS specifically for building demand response. Its natural structure allows a flexible optimization that implicitly integrate exogenous constraints (as opposed, for example, to conventional RL solutions), making MCTS a promising candidate for
    
[^35]: 多准则决策制定的多权重排名

    Multi-Weight Ranking for Multi-Criteria Decision Making. (arXiv:2312.03006v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.03006](http://arxiv.org/abs/2312.03006)

    这项研究将统计学的锥形分布函数转化为多准则决策制定工具，并通过扩展排名函数到集合，建立了集合优化方法与基于集合的多目标优化之间的联系。在机器学习中具有潜在应用。

    

    统计学中的锥形分布函数被转化为多准则决策制定工具。通过例子展示，与纯加权总和标量化相比，这种标量化方法能够找出 Pareto 边界的“非凸”部分。同时，通过将排名函数扩展到集合，为集合偏好提供一元指标，首次建立了集合优化方法与基于集合的多目标优化之间的联系。文中还简述了在机器学习中的潜在应用。

    Cone distribution functions from statistics are turned into Multi-Criteria Decision Making tools. It is demonstrated that this procedure can be considered as an upgrade of the weighted sum scalarization insofar as it absorbs a whole collection of weighted sum scalarizations at once instead of fixing a particular one in advance. As examples show, this type of scalarization--in contrast to a pure weighted sum scalarization-is also able to detect ``non-convex" parts of the Pareto frontier. Situations are characterized in which different types of rank reversal occur, and it is explained why this might even be useful for analyzing the ranking procedure. The ranking functions are then extended to sets providing unary indicators for set preferences which establishes, for the first time, the link between set optimization methods and set-based multi-objective optimization. A potential application in machine learning is outlined.
    
[^36]: Bayesian网络的熵和Kullback-Leibler散度：计算复杂度和高效实现

    Entropy and the Kullback-Leibler Divergence for Bayesian Networks: Computational Complexity and Efficient Implementation. (arXiv:2312.01520v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.01520](http://arxiv.org/abs/2312.01520)

    本文提出了一种计算贝叶斯网络中Shannon熵和Kullback-Leibler散度的高效算法，并通过一系列数值示例进行了演示。此外，还展示了如何将高斯贝叶斯网络中KL的计算复杂度从立方降低到二次。

    

    贝叶斯网络（BNs）是机器学习和因果推断中的基础模型。它们的图结构可以处理高维问题，并将其分为稀疏的一系列较小问题，这是Judea Pearl的因果性的基础，也决定了它们的可解释性和可理解性。尽管它们很受欢迎，但在文献中几乎没有关于如何在最常见的分布假设下计算BNs的Shannon熵和Kullback-Leibler（KL）散度的资源。在本文中，我们利用BNs的图结构提供了计算效率高的算法，并用一整套数值示例说明了它们。在此过程中，我们展示了可以将高斯BNs的KL计算复杂度从立方降低到二次的可能性。

    Bayesian networks (BNs) are a foundational model in machine learning and causal inference. Their graphical structure can handle high-dimensional problems, divide them into a sparse collection of smaller ones, underlies Judea Pearl's causality, and determines their explainability and interpretability. Despite their popularity, there are almost no resources in the literature on how to compute Shannon's entropy and the Kullback-Leibler (KL) divergence for BNs under their most common distributional assumptions. In this paper, we provide computationally efficient algorithms for both by leveraging BNs' graphical structure, and we illustrate them with a complete set of numerical examples. In the process, we show it is possible to reduce the computational complexity of KL from cubic to quadratic for Gaussian BNs.
    
[^37]: 探究协作数据实践：以医疗健康研究中的人工智能为例的案例研究

    Investigating Collaborative Data Practices: a Case Study on Artificial Intelligence for Healthcare Research. (arXiv:2311.18424v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2311.18424](http://arxiv.org/abs/2311.18424)

    本文通过研究英国多种长期疾病研究联盟中的参与者的访谈，探讨了协作数据实践的工具、沟通过程和环境，以及协作工作的条件和障碍。研究结果显示了工具的适应性和信息根据受众的个性化，以及电子医疗记录和数据集访问的限制。

    

    开发医疗健康领域的人工智能工具是一项协作工作，将数据科学家、临床医生、患者和其他学科汇集在一起。本文通过对英国应用人工智能工具来理解和管理多种长期疾病的研究联盟中的参与者进行的13次半结构化访谈的归纳主题分析，探讨了协作数据实践的工具、沟通过程和环境，以及协作工作的条件和障碍。我们的研究结果揭示了共享知识所使用的工具的适应性以及根据受众，特别是临床医生或患者的观点进行信息定制。同时，我们还发现了电子医疗记录和数据集访问的限制限制了这种定制的能力。我们确定了会议是关键的环境设置。

    Developing artificial intelligence (AI) tools for healthcare is a collaborative effort, bringing data scientists, clinicians, patients and other disciplines together. In this paper, we explore the collaborative data practices of research consortia tasked with applying AI tools to understand and manage multiple long-term conditions in the UK. Through an inductive thematic analysis of 13 semi-structured interviews with participants of these consortia, we aimed to understand how collaboration happens based on the tools used, communication processes and settings, as well as the conditions and obstacles for collaborative work. Our findings reveal the adaptation of tools that are used for sharing knowledge and the tailoring of information based on the audience, particularly those from a clinical or patient perspective. Limitations on the ability to do this were also found to be imposed by the use of electronic healthcare records and access to datasets. We identified meetings as the key setti
    
[^38]: GraphPro: 面向推荐系统的图预训练和提示学习

    GraphPro: Graph Pre-training and Prompt Learning for Recommendation. (arXiv:2311.16716v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2311.16716](http://arxiv.org/abs/2311.16716)

    GraphPro是一个结合了参数高效和动态图预训练与提示学习的框架，能够有效捕捉长期用户偏好和短期行为动态，从而在真实世界的推荐系统中提供准确和及时的推荐。

    

    基于GNN的推荐系统通过多次消息传递在建模复杂的用户-物品交互方面表现出色。然而，现有方法往往忽视了不断变化的用户-物品交互的动态性，这限制了其在适应用户偏好变化和新到达数据分布变化方面的可扩展性和性能。因此，它们在真实世界的动态环境中的可扩展性和性能受到了限制。在这项研究中，我们提出了GraphPro，这是一个将参数高效和动态图预训练与提示学习相结合的框架。这种新颖的组合能够有效捕捉长期用户偏好和短期行为动态，从而实现准确和及时的推荐。我们的GraphPro框架通过无缝集成临时提示机制和图结构提示学习机制到预训练的GNN模型中来解决用户偏好不断变化的挑战。

    GNN-based recommenders have excelled in modeling intricate user-item interactions through multi-hop message passing. However, existing methods often overlook the dynamic nature of evolving user-item interactions, which impedes the adaption to changing user preferences and distribution shifts in newly arriving data. Thus, their scalability and performances in real-world dynamic environments are limited. In this study, we propose GraphPro, a framework that incorporates parameter-efficient and dynamic graph pre-training with prompt learning. This novel combination empowers GNNs to effectively capture both long-term user preferences and short-term behavior dynamics, enabling the delivery of accurate and timely recommendations. Our GraphPro framework addresses the challenge of evolving user preferences by seamlessly integrating a temporal prompt mechanism and a graph-structural prompt learning mechanism into the pre-trained GNN model. The temporal prompt mechanism encodes time information o
    
[^39]: 基于移动网格PDE的移动采样物理信息神经网络

    Moving Sampling Physics-informed Neural Networks induced by Moving Mesh PDE. (arXiv:2311.16167v2 [math.NA] UPDATED)

    [http://arxiv.org/abs/2311.16167](http://arxiv.org/abs/2311.16167)

    这项工作提出了一种基于移动网格PDE的移动采样物理信息神经网络(MMPDE-Net)，通过解决移动网格PDE来自适应生成新的采样点，并且结合物理信息神经网络（PINN）提出了移动采样PINN（MS-PINN）的框架。数值实验验证了MS-PINN相对于PINN的性能改善。

    

    在这项工作中，我们提出了一种基于移动网格方法的端到端自适应采样神经网络（MMPDE-Net），通过求解移动网格PDE，可以自适应生成新的采样点。该模型旨在改善采样点生成的质量。此外，我们基于MMPDE-Net开发了一种迭代算法，使得采样点更加精确和可控。由于MMPDE-Net是独立于深度学习求解器的框架，我们将其与物理信息神经网络（PINN）相结合，提出了移动采样PINN（MS-PINN），并在一些假设下通过误差分析验证了其有效性。最后，我们通过四个典型实例的数值实验验证了MS-PINN相对于PINN的性能改善，从而数值上证明了我们方法的有效性。

    In this work, we propose an end-to-end adaptive sampling neural network (MMPDE-Net) based on the moving mesh method, which can adaptively generate new sampling points by solving the moving mesh PDE. This model focuses on improving the quality of sampling points generation. Moreover, we develop an iterative algorithm based on MMPDE-Net, which makes the sampling points more precise and controllable. Since MMPDE-Net is a framework independent of the deep learning solver, we combine it with physics-informed neural networks (PINN) to propose moving sampling PINN (MS-PINN) and demonstrate its effectiveness by error analysis under some assumptions. Finally, we demonstrate the performance improvement of MS-PINN compared to PINN through numerical experiments of four typical examples, which numerically verify the effectiveness of our method.
    
[^40]: 评估混合深度学习模型在区分AI生成文本方面的有效性

    Evaluating the Efficacy of Hybrid Deep Learning Models in Distinguishing AI-Generated Text. (arXiv:2311.15565v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.15565](http://arxiv.org/abs/2311.15565)

    本研究评估了混合深度学习模型在准确区分AI生成文本和人类写作方面的有效性。通过应用先进的自然语言处理技术和复杂的神经网络，我们的研究成功地检测到了AI生成文本和人类写作之间的微妙差异。

    

    我的研究通过使用先进的混合深度学习模型，来准确区分AI生成的文本与人类写作。我应用了一种稳健的方法论，利用了一个精心选择的数据集，其中包括来自各种来源的AI和人类文本，每个文本都标有指示。先进的自然语言处理技术便于对文本特征进行分析。通过结合复杂的神经网络，这个定制模型使得它能够检测出AI和人类内容之间微妙的差异。

    My research investigates the use of cutting-edge hybrid deep learning models to accurately differentiate between AI-generated text and human writing. I applied a robust methodology, utilising a carefully selected dataset comprising AI and human texts from various sources, each tagged with instructions. Advanced natural language processing techniques facilitated the analysis of textual features. Combining sophisticated neural networks, the custom model enabled it to detect nuanced differences between AI and human content.
    
[^41]: 探索多模态LLMs的地理和地理空间能力：开辟新的领域

    Charting New Territories: Exploring the Geographic and Geospatial Capabilities of Multimodal LLMs. (arXiv:2311.14656v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2311.14656](http://arxiv.org/abs/2311.14656)

    本论文探索了多模态大语言模型在地理和地理空间领域的能力，并通过实验分析了它们在各种视觉任务中的表现，发现了其卓越之处以及不足之处。

    

    多模态大语言模型（MLLM）在广泛的任务中展示了卓越的能力，但它们在地理和地理空间领域的知识和能力尚未被探索，尽管对导航、环境研究、城市发展和灾难响应等领域有潜在的广泛好处。我们进行了一系列的实验，探索MLLM在这些领域内的各种视觉能力，特别关注前沿模型GPT-4V，并将其性能与开源对比。我们的方法包括挑战这些模型，使用一个小规模的地理基准测试套件，测试它们在各种复杂性的任务中的能力。分析揭示了这些模型在哪些方面表现出色，包括它们超过人类的情况，但也揭示了它们何处失败，提供了对它们在地理领域能力的平衡观点。为了比较和评估未来模型，我们提供了开源的实验代码和数据集。

    Multimodal large language models (MLLMs) have shown remarkable capabilities across a broad range of tasks but their knowledge and abilities in the geographic and geospatial domains are yet to be explored, despite potential wide-ranging benefits to navigation, environmental research, urban development, and disaster response. We conduct a series of experiments exploring various vision capabilities of MLLMs within these domains, particularly focusing on the frontier model GPT-4V, and benchmark its performance against open-source counterparts. Our methodology involves challenging these models with a small-scale geographic benchmark consisting of a suite of visual tasks, testing their abilities across a spectrum of complexity. The analysis uncovers not only where such models excel, including instances where they outperform humans, but also where they falter, providing a balanced view of their capabilities in the geographic domain. To enable the comparison and evaluation of future models, ou
    
[^42]: 由AI生成的图像对文本-图像检索引入了不可见的相关偏差

    AI-Generated Images Introduce Invisible Relevance Bias to Text-Image Retrieval. (arXiv:2311.14084v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2311.14084](http://arxiv.org/abs/2311.14084)

    本研究通过构建合适的基准和进行大量实验发现，由AI生成的图像对于文本-图像检索模型引入了一个不可见的相关偏差，即使这些生成的图像在视觉上与查询的相关特征相比并没有更多。这种不可见的相关偏差普遍存在于不同训练数据和架构的检索模型中。

    

    随着生成模型的进步，由人工智能生成的内容（AIGC）变得更加逼真，涌入互联网。最近的一项研究表明，这种现象导致了网络搜索中的源偏差。特别是，神经检索模型往往将生成的文本排名高于人工编写的文本。本文将这种偏差的研究扩展到跨模态检索。首先，我们成功构建了一个适合探索偏差存在的基准。随后，在这个基准上进行了大量实验，发现AI生成的图像对于文本-图像检索模型引入了一个不可见的相关偏差。具体来说，我们的实验表明，尽管AI生成的图像与查询相比没有更多的视觉相关特征，但文本-图像检索模型往往将AI生成的图像排名高于真实图像。这种不可见的相关偏差在不同训练数据和架构的检索模型中普遍存在。

    With the advancement of generation models, AI-generated content (AIGC) is becoming more realistic, flooding the Internet. A recent study suggests that this phenomenon causes source bias in text retrieval for web search. Specifically, neural retrieval models tend to rank generated texts higher than human-written texts. In this paper, we extend the study of this bias to cross-modal retrieval. Firstly, we successfully construct a suitable benchmark to explore the existence of the bias. Subsequent extensive experiments on this benchmark reveal that AI-generated images introduce an invisible relevance bias to text-image retrieval models. Specifically, our experiments show that text-image retrieval models tend to rank the AI-generated images higher than the real images, even though the AI-generated images do not exhibit more visually relevant features to the query than real images. This invisible relevance bias is prevalent across retrieval models with varying training data and architectures
    
[^43]: 《基于课程学习和模仿学习的金融时间序列模型无关控制》

    Curriculum Learning and Imitation Learning for Model-free Control on Financial Time-series. (arXiv:2311.13326v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2311.13326](http://arxiv.org/abs/2311.13326)

    本文通过在复杂时间序列数据上探索课程学习和模仿学习的方法，发现课程学习是改善复杂时间序列控制任务性能的新途径，而模仿学习也应该被应用。

    

    课程学习和模仿学习在机器人领域已被广泛运用。然而，在高度随机的时间序列数据上利用这些想法进行控制任务的研究非常有限。在本研究中，我们从理论和实证两个方面探讨了这些方法在复杂时间序列数据上的代表性控制任务中的应用。我们通过数据增强实现了课程学习的基本思想，而通过模仿学习从专家中蒸馏出策略来实现。我们的研究结果表明，课程学习在改进复杂时间序列控制的任务性能方面应被视为一种新的方向。我们的大量随机种子外样本实证和消融研究对于时间序列控制的课程学习非常鼓舞人心。这些发现尤其鼓舞人心，因为我们在基线上调整了所有重叠的超参数，给出了基线的优势。另一方面，我们发现模仿学习应该被使用。

    Curriculum learning and imitation learning have been leveraged extensively in the robotics domain. However, minimal research has been done on leveraging these ideas on control tasks over highly stochastic time-series data. Here, we theoretically and empirically explore these approaches in a representative control task over complex time-series data. We implement the fundamental ideas of curriculum learning via data augmentation, while imitation learning is implemented via policy distillation from an oracle. Our findings reveal that curriculum learning should be considered a novel direction in improving control-task performance over complex time-series. Our ample random-seed out-sample empirics and ablation studies are highly encouraging for curriculum learning for time-series control. These findings are especially encouraging as we tune all overlapping hyperparameters on the baseline -- giving an advantage to the baseline. On the other hand, we find that imitation learning should be use
    
[^44]: $\varepsilon$-分数核稳定在快乐博弈中的应用

    $\varepsilon$-fractional Core Stability in Hedonic Games. (arXiv:2311.11101v2 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2311.11101](http://arxiv.org/abs/2311.11101)

    提出了$\varepsilon$-分数核稳定的概念，通过允许最多$\varepsilon$比例的可能联盟成为核阻塞联盟来解决快乐博弈中的核稳定性问题。这一放松条件可以保证存在性和多项式时间计算。

    

    快乐博弈是一个经典的框架，用来模拟战略代理人通过个人偏好来形成联盟。根据这些偏好，理想的联盟结构（即将代理人划分为各个联盟）应该满足某种稳定性条件。其中最为知名和自然的概念之一是核稳定性。简单来说，如果没有代理人的子集希望通过重新分组成为一个所谓的核阻塞联盟来偏离原联盟结构，那么该划分就是核稳定的。不幸的是，核稳定的划分很少存在，即使存在，寻找这样的划分通常也是计算上困难的。为了解决这些问题，我们提出了$\varepsilon$-分数核稳定的概念，即最多允许$\varepsilon$比例的可能联盟成为核阻塞联盟。事实证明，这样的放松条件可以同时保证存在性和多项式时间计算。具体而言，我们设计了高效的算法来返回一个$\varepsilon$-分数的核稳定划分。

    Hedonic Games (HGs) are a classical framework modeling coalition formation of strategic agents guided by their individual preferences. According to these preferences, it is desirable that a coalition structure (i.e. a partition of agents into coalitions) satisfies some form of stability. The most well-known and natural of such notions is arguably core-stability. Informally, a partition is core-stable if no subset of agents would like to deviate by regrouping in a so-called core-blocking coalition. Unfortunately, core-stable partitions seldom exist and even when they do, it is often computationally intractable to find one. To circumvent these problems, we propose the notion of $\varepsilon$-fractional core-stability, where at most an $\varepsilon$-fraction of all possible coalitions is allowed to core-block. It turns out that such a relaxation may guarantee both existence and polynomial-time computation. Specifically, we design efficient algorithms returning an $\varepsilon$-fractional 
    
[^45]: 使用大型语言模型对学习增强型的物联网系统进行测试：一种形式化方法

    Testing learning-enabled cyber-physical systems with Large-Language Models: A Formal Approach. (arXiv:2311.07377v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2311.07377](http://arxiv.org/abs/2311.07377)

    本研究对学习增强型物联网系统的测试进行了形式化方法的探索，以应对当前测试方法的局限性。

    

    将机器学习（ML）整合到物联网系统（CPS）中，可以带来显著的好处，包括增强效率、预测能力、实时响应和实现自主运行。这种融合加速了一系列真实世界应用的开发和部署，例如自动驾驶车辆、送货无人机、服务机器人和远程医疗程序。然而，人工智能增强的CPS的软件开发生命周期（SDLC）与传统方法存在明显的差异，具有数据和学习作为两个关键组成部分。现有的验证和验证技术常常不足以应对这些新的范式。本研究旨在确定确保学习增强型CPS形式化安全性的主要挑战。我们首先考察了作为验证和验证最实用方法的测试，总结了当前最先进的方法论。认识到当前测试方法的局限性

    The integration of machine learning (ML) into cyber-physical systems (CPS) offers significant benefits, including enhanced efficiency, predictive capabilities, real-time responsiveness, and the enabling of autonomous operations. This convergence has accelerated the development and deployment of a range of real-world applications, such as autonomous vehicles, delivery drones, service robots, and telemedicine procedures. However, the software development life cycle (SDLC) for AI-infused CPS diverges significantly from traditional approaches, featuring data and learning as two critical components. Existing verification and validation techniques are often inadequate for these new paradigms. In this study, we pinpoint the main challenges in ensuring formal safety for learningenabled CPS.We begin by examining testing as the most pragmatic method for verification and validation, summarizing the current state-of-the-art methodologies. Recognizing the limitations in current testing approaches t
    
[^46]: 多智能体量子强化学习使用进化优化

    Multi-Agent Quantum Reinforcement Learning using Evolutionary Optimization. (arXiv:2311.05546v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2311.05546](http://arxiv.org/abs/2311.05546)

    本研究提出了三种基于变分量子线路的进化优化多智能体强化学习变体，并在Coin Game环境中证明了这些方法相比于经典方法表现显著更好。

    

    多智能体强化学习在自动驾驶和其他智能产业应用方面变得越来越重要。与此同时，利用量子力学的固有属性，采用新的有希望的强化学习方法，显著减少模型的可训练参数。然而，基于梯度的多智能体量子强化学习方法常常面临贫瘠平台问题，阻碍了它们与经典方法性能的匹配。我们在现有的无梯度量子强化学习方法基础上构建，并提出了三种基于变分量子线路的进化优化多智能体强化学习变体。我们在Coin Game环境中评估了我们的遗传变种，并与经典方法进行了比较。我们证明了我们的变分量子线路方法相比于具有类似参数数量的神经网络表现显著更好。

    Multi-Agent Reinforcement Learning is becoming increasingly more important in times of autonomous driving and other smart industrial applications. Simultaneously a promising new approach to Reinforcement Learning arises using the inherent properties of quantum mechanics, reducing the trainable parameters of a model significantly. However, gradient-based Multi-Agent Quantum Reinforcement Learning methods often have to struggle with barren plateaus, holding them back from matching the performance of classical approaches. We build upon an existing approach for gradient free Quantum Reinforcement Learning and propose three genetic variations with Variational Quantum Circuits for Multi-Agent Reinforcement Learning using evolutionary optimization. We evaluate our genetic variations in the Coin Game environment and also compare them to classical approaches. We showed that our Variational Quantum Circuit approaches perform significantly better compared to a neural network with a similar amount
    
[^47]: 在Transformer中定位跨任务序列继续电路

    Locating Cross-Task Sequence Continuation Circuits in Transformers. (arXiv:2311.04131v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.04131](http://arxiv.org/abs/2311.04131)

    通过分析和比较Transformer模型中类似的序列继续任务的电路，研究发现共享的计算结构可以提高模型的行为预测能力、错误识别能力和编辑过程的安全性。

    

    虽然Transformer模型在语言任务上展现出强大的能力，但其复杂的架构使其难以解释。最近的研究旨在将Transformer模型还原为可读的电路表示，用于实现算法功能。我们通过分析和比较类似的序列继续任务的电路来扩展这项研究，其中包括数字、数字词和月份的递增序列。通过应用电路分析技术，我们确定了负责检测序列成员和预测序列中下一个成员的关键子电路。我们的分析揭示了语义相关序列依赖于具有类似作用的共享电路子图。总体而言，记录共享的计算结构能够更好地预测模型行为，识别错误，并进行更安全的编辑过程。这种对Transformer的机械理解是构建更健壮、调试和编辑更安全的模型的关键一步。

    While transformer models exhibit strong capabilities on linguistic tasks, their complex architectures make them difficult to interpret. Recent work has aimed to reverse engineer transformer models into human-readable representations called circuits that implement algorithmic functions. We extend this research by analyzing and comparing circuits for similar sequence continuation tasks, which include increasing sequences of digits, number words, and months. Through the application of circuit analysis techniques, we identify key sub-circuits responsible for detecting sequence members and for predicting the next member in a sequence. Our analysis reveals that semantically related sequences rely on shared circuit subgraphs with analogous roles. Overall, documenting shared computational structures enables better prediction of model behaviors, identification of errors, and safer editing procedures. This mechanistic understanding of transformers is a critical step towards building more robust,
    
[^48]: ALYMPICS：语言代理人与博弈论相遇——用AI代理人探索战略决策

    ALYMPICS: Language Agents Meet Game Theory -- Exploring Strategic Decision-Making with AI Agents. (arXiv:2311.03220v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2311.03220](http://arxiv.org/abs/2311.03220)

    本文介绍了Alympics，一个利用大型语言模型代理人进行博弈论研究的系统性模拟框架。通过模拟人类战略互动，框架能够定性和定量地分析游戏决定因素、策略和结果，并对代理人在战略决策场景中的表现进行评估。

    

    本文介绍了Alympics（代理人的奥运会），这是一个利用大型语言模型（LLM）代理人进行博弈论研究的系统性模拟框架。Alympics创建了一个多功能平台，用于研究复杂的博弈论问题，通过提供一个控制环境来模拟与LLM代理人进行类似人类的战略互动，弥合了理论博弈论和实证研究之间的差距。在我们的试点案例研究中，“水资源分配挑战”，我们通过一个关注稀缺生存资源多轮拍卖的挑战性战略游戏来探索Alympics。这项研究展示了该框架在定性和定量分析游戏决定因素、策略和结果方面的能力。此外，我们进行了全面的人类评估和对LLM代理人在战略决策场景中的深入评估。我们的发现不仅扩展了对LLM代理人模拟人类战略行为能力的理解，还

    This paper introduces Alympics (Olympics for Agents), a systematic simulation framework utilizing Large Language Model (LLM) agents for game theory research. Alympics creates a versatile platform for studying complex game theory problems, bridging the gap between theoretical game theory and empirical investigations by providing a controlled environment for simulating human-like strategic interactions with LLM agents. In our pilot case study, the "Water Allocation Challenge," we explore Alympics through a challenging strategic game focused on the multi-round auction on scarce survival resources. This study demonstrates the framework's ability to qualitatively and quantitatively analyze game determinants, strategies, and outcomes. Additionally, we conduct a comprehensive human assessment and an in-depth evaluation of LLM agents in strategic decision-making scenarios. Our findings not only expand the understanding of LLM agents' proficiency in emulating human strategic behavior but also h
    
[^49]: 用稀疏添加机制移位变分自动编码器对细胞扰动进行建模

    Modelling Cellular Perturbations with the Sparse Additive Mechanism Shift Variational Autoencoder. (arXiv:2311.02794v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2311.02794](http://arxiv.org/abs/2311.02794)

    本研究提出了一种稀疏添加机制移位变分自动编码器（SAMS-VAE），用于建模细胞的扰动情况，并结合复合性、解缠和可解释性。通过稀疏化处理全局潜变量，SAMS-VAE能够识别出特定于干扰的潜在子空间，并在多个任务上进行了定量和定性评估。

    

    近年来，针对干预下观测数据的生成模型在机器学习和科学领域引起了广泛关注。例如，在药物发现中，需要对细胞的多种干预效应进行建模，以揭示未知的生物作用机制。我们提出了稀疏添加机制移位变分自动编码器（SAMS-VAE），以组合复合性、解缠和可解释性进行扰动模型。SAMS-VAE将扰动样本的潜在状态建模为一个局部潜在变量和稀疏全局变量之和，用于捕捉样本特定的变化和潜在干预效应。关键是，SAMS-VAE通过对各个干预的全局潜变量进行稀疏化处理，从而识别出解缠的、干扰特定的潜在子空间，这些子空间具有灵活的组合性。我们在两个流行的单细胞测序数据集上定量和定性评估了SAMS-VAE的性能。

    Generative models of observations under interventions have been a vibrant topic of interest across machine learning and the sciences in recent years. For example, in drug discovery, there is a need to model the effects of diverse interventions on cells in order to characterize unknown biological mechanisms of action. We propose the Sparse Additive Mechanism Shift Variational Autoencoder, SAMS-VAE, to combine compositionality, disentanglement, and interpretability for perturbation models. SAMS-VAE models the latent state of a perturbed sample as the sum of a local latent variable capturing sample-specific variation and sparse global variables of latent intervention effects. Crucially, SAMS-VAE sparsifies these global latent variables for individual perturbations to identify disentangled, perturbation-specific latent subspaces that are flexibly composable. We evaluate SAMS-VAE both quantitatively and qualitatively on a range of tasks using two popular single cell sequencing datasets. In 
    
[^50]: 通过离散扩散学习无监督的自动驾驶世界模型

    Learning Unsupervised World Models for Autonomous Driving via Discrete Diffusion. (arXiv:2311.01017v1 [cs.CV])

    [http://arxiv.org/abs/2311.01017](http://arxiv.org/abs/2311.01017)

    本论文提出了一种通过离散扩散学习无监督的自动驾驶世界模型的新方法，通过使用VQVAE对传感器观察进行标记化并通过离散扩散预测未来，我们的模型在点云观察中实现了显著改进，将1秒预测的SOTA Chamfer距离降低了65%以上。

    

    学习世界模型可以以无监督的方式教会智能体世界的运作方式。尽管它可以看作是序列建模的特殊情况，但在自动驾驶等机器人应用中，与使用生成预训练转换器（GPT）扩展语言模型相比，扩展世界模型的进展相对较慢。我们指出了两个主要瓶颈：处理复杂和无结构的观察空间以及具有可扩展性的生成模型。因此，我们提出了一种新颖的世界建模方法，首先使用VQVAE对传感器观察进行标记化，然后通过离散扩散预测未来。为了有效地并行解码和去噪标记，我们将遮蔽生成图像转换器转换为离散扩散框架，并进行了一些简单的改进，取得了显着的改进效果。当应用于点云观察的世界模型学习时，我们的模型将1秒预测的SOTA Chamfer距离降低了65%以上。

    Learning world models can teach an agent how the world works in an unsupervised manner. Even though it can be viewed as a special case of sequence modeling, progress for scaling world models on robotic applications such as autonomous driving has been somewhat less rapid than scaling language models with Generative Pre-trained Transformers (GPT). We identify two reasons as major bottlenecks: dealing with complex and unstructured observation space, and having a scalable generative model. Consequently, we propose a novel world modeling approach that first tokenizes sensor observations with VQVAE, then predicts the future via discrete diffusion. To efficiently decode and denoise tokens in parallel, we recast Masked Generative Image Transformer into the discrete diffusion framework with a few simple changes, resulting in notable improvement. When applied to learning world models on point cloud observations, our model reduces prior SOTA Chamfer distance by more than 65% for 1s prediction, an
    
[^51]: LLM可能主导信息访问：神经检索器对LLM生成的文本存在偏见。

    LLMs may Dominate Information Access: Neural Retrievers are Biased Towards LLM-Generated Texts. (arXiv:2310.20501v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2310.20501](http://arxiv.org/abs/2310.20501)

    近期的研究发现，大型语言模型（LLMs）对信息检索系统产生了一种偏见，倾向于将LLM生成的文档排名较高。这种“来源偏见”可能对信息访问产生重大影响。

    

    最近，大型语言模型（LLMs）的出现在信息检索（IR）应用，尤其是在网络搜索方面，彻底改变了范式。由于其在生成类人文本方面的卓越能力，LLMs在互联网上创造了大量的文本。因此，LLMs时代的IR系统面临一个新的挑战：索引的文档不仅是由人类撰写的，而且还包括由LLMs自动生成的文档。这些LLM生成的文档如何影响IR系统是一个紧迫且尚未探索的问题。在这项工作中，我们在涉及人类编写和LLM生成的文本的不同IR模型的场景中进行了定量评估。令人惊讶的是，我们的研究结果表明，神经检索模型倾向于将LLM生成的文档排名较高。我们将这种神经检索模型对LLM生成文本的偏见称为“来源偏见”。此外，我们发现这种偏见不仅限于f方相当的情况，而且在分类任务上也存在。

    Recently, the emergence of large language models (LLMs) has revolutionized the paradigm of information retrieval (IR) applications, especially in web search. With their remarkable capabilities in generating human-like texts, LLMs have created enormous texts on the Internet. As a result, IR systems in the LLMs era are facing a new challenge: the indexed documents now are not only written by human beings but also automatically generated by the LLMs. How these LLM-generated documents influence the IR systems is a pressing and still unexplored question. In this work, we conduct a quantitative evaluation of different IR models in scenarios where both human-written and LLM-generated texts are involved. Surprisingly, our findings indicate that neural retrieval models tend to rank LLM-generated documents higher. We refer to this category of biases in neural retrieval models towards the LLM-generated text as the \textbf{source bias}. Moreover, we discover that this bias is not confined to the f
    
[^52]: 将预训练语言模型整合到神经机器翻译中

    Integrating Pre-trained Language Model into Neural Machine Translation. (arXiv:2310.19680v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.19680](http://arxiv.org/abs/2310.19680)

    该论文提出了PiNMT模型，将预训练语言模型整合到神经机器翻译中，通过三个关键部分和两种训练策略，实现了在IW数据集上的最先进性能。

    

    通过广泛的研究和开发，神经机器翻译（NMT）已成为自然语言处理中的重要技术。然而，高质量的双语语言对数据的不足仍然是提高NMT性能的主要挑战。最近的研究一直在探索使用预训练语言模型（PLM）的上下文信息来解决这个问题。然而，PLM和NMT模型之间的不兼容问题尚未解决。本研究提出了PLM整合的NMT（PiNMT）模型来解决这些问题。PiNMT模型由三个关键组成部分组成，分别是PLM多层转换器，嵌入融合和余弦对齐，每个部分在向NMT提供有效的PLM信息方面发挥着重要作用。此外，本文还介绍了两种训练策略，分别是分离学习率和双步训练。通过实施所提出的PiNMT模型和训练策略，在IW数据集上实现了最先进的性能。

    Neural Machine Translation (NMT) has become a significant technology in natural language processing through extensive research and development. However, the deficiency of high-quality bilingual language pair data still poses a major challenge to improving NMT performance. Recent studies have been exploring the use of contextual information from pre-trained language model (PLM) to address this problem. Yet, the issue of incompatibility between PLM and NMT model remains unresolved. This study proposes PLM-integrated NMT (PiNMT) model to overcome the identified problems. PiNMT model consists of three critical components, PLM Multi Layer Converter, Embedding Fusion, and Cosine Alignment, each playing a vital role in providing effective PLM information to NMT. Furthermore, two training strategies, Separate Learning Rates and Dual Step Training, are also introduced in this paper. By implementing the proposed PiNMT model and training strategy, we achieve state-of-the-art performance on the IW
    
[^53]: The Memory Perturbation Equation: Understanding Model's Sensitivity to Data（理解模型对数据的敏感性的记忆扰动方程）

    The Memory Perturbation Equation: Understanding Model's Sensitivity to Data. (arXiv:2310.19273v1 [cs.LG])

    [http://arxiv.org/abs/2310.19273](http://arxiv.org/abs/2310.19273)

    这个论文介绍了记忆扰动方程（MPE），该方程通过应用贝叶斯原理将模型的敏感性与训练数据的扰动联系起来，并且能够准确预测模型在未见测试数据上的泛化能力。

    

    理解模型对其训练数据的敏感性对于训练过程至关重要，但也可能具有挑战性和成本高昂。为了简化这类问题，我们提出了记忆扰动方程（MPE），它将模型的敏感性与其训练数据的扰动联系起来。使用贝叶斯原理导出的MPE将现有的敏感性度量统一起来，泛化到各种模型和算法，并揭示了有关敏感性的有用性质。我们的实证结果表明，训练过程中获得的敏感性估计可以准确预测在未见测试数据上的泛化能力。该提出的方程预计将对未来的鲁棒和自适应学习研究有用。

    Understanding model's sensitivity to its training data is crucial but can also be challenging and costly, especially during training. To simplify such issues, we present the Memory-Perturbation Equation (MPE) which relates model's sensitivity to perturbation in its training data. Derived using Bayesian principles, the MPE unifies existing sensitivity measures, generalizes them to a wide-variety of models and algorithms, and unravels useful properties regarding sensitivities. Our empirical results show that sensitivity estimates obtained during training can be used to faithfully predict generalization on unseen test data. The proposed equation is expected to be useful for future research on robust and adaptive learning.
    
[^54]: CXR-LLaVA：用于解释胸部X射线图像的多模式大型语言模型

    CXR-LLaVA: Multimodal Large Language Model for Interpreting Chest X-ray Images. (arXiv:2310.18341v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.18341](http://arxiv.org/abs/2310.18341)

    本研究开发了一种用于解读胸部X射线图像的开源多模态大型语言模型（CXR-LLaVA），通过预训练图像编码器和对比语言-图像预训练将图像与放射学异常对齐，并使用GPT-4进行微调，实现了问题回答的功能。

    

    目的：最近大型语言模型（LLMs）的进步以多模态的方式扩展了它们的能力，可能复制人类放射科医师对图像的解释。本研究旨在开发用于解释胸部X射线图像的开源多模态大型语言模型（CXR-LLaVA）。我们还研究了提示工程和模型参数（如温度和核心采样）的影响。材料和方法：我们收集了659,287个公开可用的胸部X射线图像进行训练：417,336个图像带有某些放射学异常标签（数据集1）；241,951个图像带有自由文本放射学报告（数据集2）。在预训练Resnet50作为图像编码器之后，采用对比语言-图像预训练来对齐胸部X射线图像和相应的放射学异常。然后，使用数据集2对大型语言模型Meta AI-2进行微调，这些数据集经过GPT-4的改进，生成各种问题回答情景。代码可以在ht找到

    Purpose: Recent advancements in large language models (LLMs) have expanded their capabilities in a multimodal fashion, potentially replicating the image interpretation of human radiologists. This study aimed to develop open-source multimodal large language model for interpreting chest X-ray images (CXR-LLaVA). We also examined the effect of prompt engineering and model parameters such as temperature and nucleus sampling.  Materials and Methods: For training, we collected 659,287 publicly available CXRs: 417,336 CXRs had labels for certain radiographic abnormalities (dataset 1); 241,951 CXRs provided free-text radiology reports (dataset 2). After pre-training the Resnet50 as an image encoder, the contrastive language-image pre-training was used to align CXRs and corresponding radiographic abnormalities. Then, the Large Language Model Meta AI-2 was fine-tuned using dataset 2, which were refined using GPT-4, with generating various question answering scenarios. The code can be found at ht
    
[^55]: 等距运动流形基元

    Isometric Motion Manifold Primitives. (arXiv:2310.17072v1 [cs.AI])

    [http://arxiv.org/abs/2310.17072](http://arxiv.org/abs/2310.17072)

    Isometric Motion Manifold Primitives (IMMP) is proposed to address the degradation of Motion Manifold Primitive (MMP) performance due to geometric distortion in the latent space. IMMP preserves the geometry of the manifold in the latent coordinate space using a Riemannian metric, and experimental results show that IMMP significantly outperforms existing MMP methods.

    

    运动流形基元（MMP）为给定任务生成一系列连续轨迹流形，每一个轨迹流形都能成功完成任务。它由对流形进行参数化的解码函数以及潜在坐标空间中的概率密度组成。本文首先展示了由于潜在空间中的几何扭曲，MMP的性能可能会显著降低--通过变形，我们指的是相似的运动在潜在空间中无法相邻。然后，我们提出了等距运动流形基元（IMMP），其潜在坐标空间保持了流形的几何结构。为此，我们建立和使用了一个Riemannian度量，用于运动空间（即，参数化曲线空间），我们称之为CurveGeom Riemannian度量。对于平面障碍避让运动和推动操纵任务的实验表明，IMMP明显优于现有的MMP方法。代码可在https://github.com/Gabe-YHLee/IMMP找到。

    The Motion Manifold Primitive (MMP) produces, for a given task, a continuous manifold of trajectories each of which can successfully complete the task. It consists of the decoder function that parametrizes the manifold and the probability density in the latent coordinate space. In this paper, we first show that the MMP performance can significantly degrade due to the geometric distortion in the latent space -- by distortion, we mean that similar motions are not located nearby in the latent space. We then propose {\it Isometric Motion Manifold Primitives (IMMP)} whose latent coordinate space preserves the geometry of the manifold. For this purpose, we formulate and use a Riemannian metric for the motion space (i.e., parametric curve space), which we call a {\it CurveGeom Riemannian metric}. Experiments with planar obstacle-avoiding motions and pushing manipulation tasks show that IMMP significantly outperforms existing MMP methods. Code is available at https://github.com/Gabe-YHLee/IMMP
    
[^56]: 分层随机平滑

    Hierarchical Randomized Smoothing. (arXiv:2310.16221v1 [cs.LG])

    [http://arxiv.org/abs/2310.16221](http://arxiv.org/abs/2310.16221)

    分层随机平滑是一种在复杂数据上进行鲁棒性认证的解决方案，通过只在一个对象的子集上添加随机噪声，以更有针对性的方式提供了更强的鲁棒性保证和高准确性。

    

    真实世界的数据是复杂的，通常由可分解为多个实体的对象组成（例如，将图像分解为像素，将图形分解为相互连接的节点）。随机平滑是一种强大的框架，可以使模型在其输入的微小变化上具有证明的鲁棒性-通过在分类之前随机添加噪声来保证多数投票的鲁棒性。然而，当对手不是任意干扰整个对象（例如图像），而是对象的某个实体的子集（例如像素）时，通过随机平滑对这种复杂数据进行鲁棒性认证是具有挑战性的。作为解决方案，我们引入了分层随机平滑：我们通过仅在随机选择的实体子集上添加随机噪声来部分平滑对象。通过以比现有方法更有针对性的方式添加噪声，我们获得更强的鲁棒性保证，同时保持高准确性。我们使用不同的噪声分布初始化分层平滑，得到了新的鲁棒性保证。

    Real-world data is complex and often consists of objects that can be decomposed into multiple entities (e.g. images into pixels, graphs into interconnected nodes). Randomized smoothing is a powerful framework for making models provably robust against small changes to their inputs - by guaranteeing robustness of the majority vote when randomly adding noise before classification. Yet, certifying robustness on such complex data via randomized smoothing is challenging when adversaries do not arbitrarily perturb entire objects (e.g. images) but only a subset of their entities (e.g. pixels). As a solution, we introduce hierarchical randomized smoothing: We partially smooth objects by adding random noise only on a randomly selected subset of their entities. By adding noise in a more targeted manner than existing methods we obtain stronger robustness guarantees while maintaining high accuracy. We initialize hierarchical smoothing using different noising distributions, yielding novel robustness
    
[^57]: 渗透式人工智能：使LLMs理解物理世界

    Penetrative AI: Making LLMs Comprehend the Physical World. (arXiv:2310.09605v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.09605](http://arxiv.org/abs/2310.09605)

    本文探讨了渗透式人工智能的概念，旨在使LLMs能够通过物联网传感器与执行器与物理世界进行交互和推理。初步研究结果表明，LLMs具有独特的能力，能够应用内嵌的世界知识解释物联网传感器数据并进行物理领域的推理。

    

    最近大型语言模型（LLMs）的发展展示了它们在各种任务中的显著能力。然而，关于LLMs的性质以及它们在涉及真实物理世界信息的任务中整合常识人类知识的潜力仍存在疑问。本文通过探索LLMs如何通过物联网传感器和执行器与物理世界进行交互和推理来探讨这些问题，这一概念称为“渗透式人工智能”。论文在LLMs能够透过处理感知信号的两个层面上探索了这种扩展。我们的初步研究结果表明，LLMs（ChatGPT是我们研究中的代表性例子）在应用内嵌的世界知识解释物联网传感器数据并对物理领域的任务进行推理方面具有相当独特的能力。这不仅为LLMs开辟了新的应用领域。

    Recent developments in Large Language Models (LLMs) have demonstrated their remarkable capabilities across a range of tasks. Questions, however, persist about the nature of LLMs and their potential to integrate common-sense human knowledge when performing tasks involving information about the real physical world. This paper delves into these questions by exploring how LLMs can be extended to interact with and reason about the physical world through IoT sensors and actuators, a concept that we term "Penetrative AI". The paper explores such an extension at two levels of LLMs' ability to penetrate into the physical world via the processing of sensory signals. Our preliminary findings indicate that LLMs, with ChatGPT being the representative example in our exploration, have considerable and unique proficiency in employing the embedded world knowledge for interpreting IoT sensor data and reasoning over them about tasks in the physical realm. Not only this opens up new applications for LLMs 
    
[^58]: CP-KGC: 利用大型语言模型的约束式提示对知识图谱进行补全

    CP-KGC: Constrained-Prompt Knowledge Graph Completion with Large Language Models. (arXiv:2310.08279v1 [cs.CL])

    [http://arxiv.org/abs/2310.08279](http://arxiv.org/abs/2310.08279)

    CP-KGC方法利用大型语言模型，通过约束式提示来补全知识图谱，提高推断效果，展示了在低资源计算条件下的有效性，并在数据集上取得了优于之前方法的结果。

    

    知识图谱补全旨在利用现有知识推断和推测知识图谱中缺失的连接。SimKGC等基于文本的方法已经超过了图嵌入方法，展示了归纳式知识图谱补全的潜力。然而，基于文本的方法的效果取决于实体文本描述的质量。为了减轻LLM生成的文本中的幻觉，在本文中，我们引入了一种基于约束的提示方法，利用实体及其文本描述作为上下文约束来提高数据质量。我们的约束式提示知识图谱补全方法（CP-KGC）在低资源计算条件下表现出有效的推断能力，并超过了WN18RR和FB15K237数据集上的之前结果。这展示了LLMs在知识图谱补全任务中的整合，并为未来的研究提供了新的方向。

    Knowledge graph completion (KGC) aims to utilize existing knowledge to deduce and infer missing connections within knowledge graphs. Text-based approaches, like SimKGC, have outperformed graph embedding methods, showcasing the promise of inductive KGC. However, the efficacy of text-based methods hinges on the quality of entity textual descriptions. In this paper, we identify the key issue of whether large language models (LLMs) can generate effective text. To mitigate hallucination in LLM-generated text in this paper, we introduce a constraint-based prompt that utilizes the entity and its textual description as contextual constraints to enhance data quality. Our Constrained-Prompt Knowledge Graph Completion (CP-KGC) method demonstrates effective inference under low resource computing conditions and surpasses prior results on the WN18RR and FB15K237 datasets. This showcases the integration of LLMs in KGC tasks and provides new directions for future research.
    
[^59]: 你关心什么？为机器人学习实现视觉表示对齐

    What Matters to You? Towards Visual Representation Alignment for Robot Learning. (arXiv:2310.07932v1 [cs.RO])

    [http://arxiv.org/abs/2310.07932](http://arxiv.org/abs/2310.07932)

    该论文提出了一种名为RAPL的方法，用于解决机器人学习中的视觉表示对齐问题，通过利用人类反馈将机器人的视觉表示与用户偏好对齐，并区分任务的关键要素。

    

    在为人类服务时，机器人需要优化与最终用户偏好一致的奖励。由于机器人将依赖原始感知输入如RGB图像，它们的奖励将不可避免地使用视觉表示。最近，使用预训练视觉模型的表示引发了人们的兴趣，但在机器人领域使其起作用的关键是微调，通常通过代理任务如动力学预测或强制时间循环一致性来完成。然而，所有这些代理任务都绕过了人类对自己关心的事物的输入，加剧了虚假关联，并最终导致机器人的行为与用户偏好不一致。在这项工作中，我们提议机器人应该利用人类的反馈来与最终用户的视觉表示对齐，并区分任务的关键要素。我们提出了一种解决视觉表示对齐问题和视觉奖励问题的方法，即基于偏好的表示对齐学习（RAPL）方法。

    When operating in service of people, robots need to optimize rewards aligned with end-user preferences. Since robots will rely on raw perceptual inputs like RGB images, their rewards will inevitably use visual representations. Recently there has been excitement in using representations from pre-trained visual models, but key to making these work in robotics is fine-tuning, which is typically done via proxy tasks like dynamics prediction or enforcing temporal cycle-consistency. However, all these proxy tasks bypass the human's input on what matters to them, exacerbating spurious correlations and ultimately leading to robot behaviors that are misaligned with user preferences. In this work, we propose that robots should leverage human feedback to align their visual representations with the end-user and disentangle what matters for the task. We propose Representation-Aligned Preference-based Learning (RAPL), a method for solving the visual representation alignment problem and visual reward
    
[^60]: 学习交互式现实世界模拟器

    Learning Interactive Real-World Simulators. (arXiv:2310.06114v1 [cs.AI])

    [http://arxiv.org/abs/2310.06114](http://arxiv.org/abs/2310.06114)

    通过生成建模学习交互体验的通用模拟器，以模拟人类、机器人和其他交互式代理人对真实世界中行为的响应。

    

    训练在互联网数据上的生成模型已经彻底改变了文本、图像和视频内容的创建方式。也许生成模型的下一个里程碑是在人类、机器人和其他交互式代理人采取行动时模拟真实的体验。实际应用范围从游戏和电影中的可控内容创建，到仅在模拟环境中训练可以直接部署在现实世界中的体验式代理人。我们探索了通过生成建模来学习现实世界交互的通用模拟器(UniSim)的可能性。我们首先重要地观察到，用于学习现实世界模拟器的自然数据集通常在不同的方面丰富多样（例如，图像数据中丰富的物体，机器人数据中密集采样的动作，导航数据中多样的移动）。通过精心协调各种数据集，每个数据集都提供整体体验的不同方面，UniSim可以模拟人类与环境的交互方式。

    Generative models trained on internet data have revolutionized how text, image, and video content can be created. Perhaps the next milestone for generative models is to simulate realistic experience in response to actions taken by humans, robots, and other interactive agents. Applications of a real-world simulator range from controllable content creation in games and movies, to training embodied agents purely in simulation that can be directly deployed in the real world. We explore the possibility of learning a universal simulator (UniSim) of real-world interaction through generative modeling. We first make the important observation that natural datasets available for learning a real-world simulator are often rich along different axes (e.g., abundant objects in image data, densely sampled actions in robotics data, and diverse movements in navigation data). With careful orchestration of diverse datasets, each providing a different aspect of the overall experience, UniSim can emulate how
    
[^61]: 放射学报告的多语言自然语言处理模型--摘要是你需要的一切！

    Multilingual Natural Language ProcessingModel for Radiology Reports -- The Summary is all you need!. (arXiv:2310.00100v1 [cs.CL])

    [http://arxiv.org/abs/2310.00100](http://arxiv.org/abs/2310.00100)

    本研究通过在多语言文本到文本变换器模型上微调，开发了一个能够自动在多语言中总结放射学报告的模型。该模型有助于提高未来深度学习模型的研究和发展，且能够应用于不同族裔背景的患者数据。

    

    放射学报告的印象部分总结了重要的放射学发现，并在向医生传达这些发现时起到了关键作用。然而，对于放射科医生来说，准备这些摘要既耗时又容易出错。最近，已经开发了许多用于放射学报告摘要的模型。然而，目前还没有能够在多种语言中总结这些报告的模型。这样的模型可以极大地改进未来的研究和融合来自不同族裔背景的患者数据的深度学习模型的发展。本研究通过在公开可用的基于多语言文本到文本变换器的模型上微调，自动化地生成了不同语言的放射学印象，以总结英语、葡萄牙语和德语的放射学报告中的发现。在一项盲测中，两位有执业资格的放射科医生表示，对于至少70%的系统生成的摘要，其质量

    The impression section of a radiology report summarizes important radiology findings and plays a critical role in communicating these findings to physicians. However, the preparation of these summaries is time-consuming and error-prone for radiologists. Recently, numerous models for radiology report summarization have been developed. Nevertheless, there is currently no model that can summarize these reports in multiple languages. Such a model could greatly improve future research and the development of Deep Learning models that incorporate data from patients with different ethnic backgrounds. In this study, the generation of radiology impressions in different languages was automated by fine-tuning a model, publicly available, based on a multilingual text-to-text Transformer to summarize findings available in English, Portuguese, and German radiology reports. In a blind test, two board-certified radiologists indicated that for at least 70% of the system-generated summaries, the quality 
    
[^62]: QAL-BP:一种用于装箱问题的增广拉格朗日量子方法

    QAL-BP: An Augmented Lagrangian Quantum Approach for Bin Packing Problem. (arXiv:2309.12678v1 [quant-ph])

    [http://arxiv.org/abs/2309.12678](http://arxiv.org/abs/2309.12678)

    QAL-BP是一种增广拉格朗日量子方法，专门用于解决装箱问题。它利用增广拉格朗日方法将装箱约束加入目标函数，并通过分析估计启发式乘数，消除了需要根据实例计算Lagrangian系数的需求。

    

    装箱问题是人工智能领域中众所周知的NP-Hard问题，寻找高效解决方案面临重大挑战。相反，量子技术的最新进展显示出在某些问题类别（如组合优化）中实现大幅计算加速的潜力。在本研究中，我们介绍了QAL-BP，一种专门针对装箱问题设计的新型二次无约束二进制优化（QUBO）公式，适用于量子计算。QAL-BP采用增广拉格朗日方法将装箱约束嵌入到目标函数中，并便于对启发式乘数进行分析估计，使得模型更加灵活和可推广，消除了在其他QUBO公式中常遇到的需要根据实例计算Lagrangian系数的需求。

    The bin packing is a well-known NP-Hard problem in the domain of artificial intelligence, posing significant challenges in finding efficient solutions. Conversely, recent advancements in quantum technologies have shown promising potential for achieving substantial computational speedup, particularly in certain problem classes, such as combinatorial optimization. In this study, we introduce QAL-BP, a novel Quadratic Unconstrained Binary Optimization (QUBO) formulation designed specifically for bin packing and suitable for quantum computation. QAL-BP utilizes the augmented Lagrangian method to incorporate the bin packing constraints into the objective function while also facilitating an analytical estimation of heuristic, but empirically robust, penalty multipliers. This approach leads to a more versatile and generalizable model that eliminates the need for empirically calculating instance-dependent Lagrangian coefficients, a requirement commonly encountered in alternative QUBO formulati
    
[^63]: 单步和少步扩散用于生成式语音增强

    Single and Few-step Diffusion for Generative Speech Enhancement. (arXiv:2309.09677v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2309.09677](http://arxiv.org/abs/2309.09677)

    本文提出了一种通过两阶段训练的方法来解决扩散模型在语音增强中的限制。第一阶段使用生成去噪评分匹配损失训练扩散模型，第二阶段通过解决反向过程来计算增强信号，并使用预测损失进行比较。这种方法只需要5个函数评估就能达到与基准模型相同的性能，而不是60个函数评估。

    

    扩散模型在语音增强方面展示了有希望的结果，利用任务适应性扩散过程来生成给定嘈杂混合声音的纯净语音。然而，在测试时，用于评分估计的神经网络被多次调用以解决迭代的反向过程。这导致推理过程缓慢，并导致在采样轨迹中积累离散化误差。在本文中，我们通过两阶段训练方法解决了这些限制。在第一阶段，我们用生成去噪评分匹配损失的常规方式训练扩散模型。在第二阶段，我们通过解决反向过程来计算增强信号，并使用预测损失将结果估计与纯净语音目标进行比较。我们证明使用这个第二训练阶段只需要5个函数评估，就能达到与基准模型相同的性能，而不是60个函数评估。虽然基准模型的性能可能

    Diffusion models have shown promising results in speech enhancement, using a task-adapted diffusion process for the conditional generation of clean speech given a noisy mixture. However, at test time, the neural network used for score estimation is called multiple times to solve the iterative reverse process. This results in a slow inference process and causes discretization errors that accumulate over the sampling trajectory. In this paper, we address these limitations through a two-stage training approach. In the first stage, we train the diffusion model the usual way using the generative denoising score matching loss. In the second stage, we compute the enhanced signal by solving the reverse process and compare the resulting estimate to the clean speech target using a predictive loss. We show that using this second training stage enables achieving the same performance as the baseline model using only 5 function evaluations instead of 60 function evaluations. While the performance of
    
[^64]: CB-Whisper: 使用开放词汇关键词检测进行上下文偏置的Whisper

    CB-Whisper: Contextual Biasing Whisper using Open-Vocabulary Keyword-Spotting. (arXiv:2309.09552v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2309.09552](http://arxiv.org/abs/2309.09552)

    CB-Whisper是一种基于OpenAI的Whisper模型的自动语音识别系统，通过使用开放词汇关键词检测（OV-KWS）识别罕见的命名实体，并使用这些实体作为提示来改进识别效果。实验证明，该方法在提高实体召回率的同时会略微增加混淆错误率（MER）。

    

    自动语音识别系统往往难以识别罕见的命名实体，如个人姓名、组织机构和在训练数据中不经常遇到的专业术语。本文提出了一种基于OpenAI的Whisper模型的Contextual Biasing Whisper（CB-Whisper）自动语音识别系统，通过使用Whisper编码器的隐藏状态执行开放词汇关键词检测（OV-KWS）来识别用户定义的命名实体。识别出的实体被用作Whisper解码器的提示。我们首先提出了一种使用OV-KWS和ASR任务进行多任务训练的方法来优化模型。实验证明，与原始Whisper模型相比，这种方法在中国Aishell热词子集和两个内部代码切换测试集上显著提高了实体召回率。然而，由于灾难性遗忘，我们观察到在内部测试集上混淆错误率（MER）略微增加。为了解决这个问题并使用不同大小的Whisper模型，我们进一步提出了一种解决方案。

    End-to-end automatic speech recognition (ASR) systems often struggle to recognize rare name entities, such as personal names, organizations, and terminologies not frequently encountered in the training data. This paper presents Contextual Biasing Whisper (CB-Whisper), a novel ASR system based on OpenAI's Whisper model that can recognize user-defined name entities by performing open-vocabulary keyword-spotting (OV-KWS) using the hidden states of Whisper encoder. The recognized entities are used as prompts for the Whisper decoder. We first propose a multitask training approach with OV-KWS and ASR tasks to optimize the model. Experiments show that this approach substantially improves the entity recalls compared to the original Whisper model on Chinese Aishell hot word subsets and two internal code-switch test sets. However, we observed a slight increase in mixed-error-rate (MER) on internal test sets due to catastrophic forgetting. To address this problem and use different sizes of the Wh
    
[^65]: VoiceFlow: 使用矫正流匹配的高效文本转语音

    VoiceFlow: Efficient Text-to-Speech with Rectified Flow Matching. (arXiv:2309.05027v1 [eess.AS])

    [http://arxiv.org/abs/2309.05027](http://arxiv.org/abs/2309.05027)

    VoiceFlow使用矫正流匹配算法实现了高效文本转语音，并在合成质量上优于传统的扩散模型。

    

    尽管扩散模型在文本转语音中因其强大的生成能力而成为一种流行选择，但从扩散模型中进行采样的内在复杂性损害了其效率。相反，我们提出了VoiceFlow，一种利用矫正流匹配算法来实现高合成质量的声学模型，只需有限次采样步骤即可实现。VoiceFlow将生成mel-spectrograms的过程转化为一个普通微分方程，在文本输入的条件下进行求解，并估计出其向量场。然后，矫正流技术有效地使其采样轨迹直线化，实现高效合成。在单个和多个说话者语料库上进行的主观和客观评估显示，VoiceFlow相对于扩散模型具有更优异的合成质量。消融研究进一步验证了VoiceFlow中矫正流技术的有效性。

    Although diffusion models in text-to-speech have become a popular choice due to their strong generative ability, the intrinsic complexity of sampling from diffusion models harms their efficiency. Alternatively, we propose VoiceFlow, an acoustic model that utilizes a rectified flow matching algorithm to achieve high synthesis quality with a limited number of sampling steps. VoiceFlow formulates the process of generating mel-spectrograms into an ordinary differential equation conditional on text inputs, whose vector field is then estimated. The rectified flow technique then effectively straightens its sampling trajectory for efficient synthesis. Subjective and objective evaluations on both single and multi-speaker corpora showed the superior synthesis quality of VoiceFlow compared to the diffusion counterpart. Ablation studies further verified the validity of the rectified flow technique in VoiceFlow.
    
[^66]: AIs的发展脱靴法

    Developmental Bootstrapping of AIs. (arXiv:2308.04586v1 [cs.AI])

    [http://arxiv.org/abs/2308.04586](http://arxiv.org/abs/2308.04586)

    传统的符号AI方法和深度学习AI方法无法满足创建强大和可信赖的AI的挑战，然而，发展脱靴法通过模仿人类儿童的能力发展过程，为创建稳健可靠的AI提供了希望。

    

    尽管当前一些AI在封闭的世界，如棋盘游戏中超越了人类能力，但它们在混乱的现实世界中的表现有限。它们会犯奇怪的错误而且没有意识到。它们很难受到指导，不能运用常识，缺乏好奇心。它们不能成为良好的合作者。传统手动构建的符号AI方法构建的系统和使用生成和深度学习AI方法(包括大规模语言模型)构建的系统都无法应对这些挑战。它们不适合创建强大和可信赖的AI。尽管此方法不属于主流的AI方法，但发展脱靴法显示出希望。在发展脱靴法中，AI像人类儿童一样发展能力。它们从先天能力开始。像人类一样，它们与环境互动，并从互动中学习。它们通过自我发展的能力逐步扩展先天能力。它们互动并逐渐将所学应用于实际操作。

    Although some current AIs surpass human abilities especially in closed worlds such as board games, their performance in the messy real world is limited. They make strange mistakes and do not notice them. They cannot be instructed easily, fail to use common sense, and lack curiosity. They do not make good collaborators. Neither systems built using the traditional manually-constructed symbolic AI approach nor systems built using generative and deep learning AI approaches including large language models (LLMs) can meet the challenges. They are not well suited for creating robust and trustworthy AIs. Although it is outside of mainstream AI approaches, developmental bootstrapping shows promise. In developmental bootstrapping, AIs develop competences like human children do. They start with innate competences. Like humans, they interact with the environment and learn from their interactions. They incrementally extend their innate competences with self-developed competences. They interact and 
    
[^67]: 智能电网中一种有效的用于能量盗窃检测和预测的LSTM-DDPM方案

    An Effective LSTM-DDPM Scheme for Energy Theft Detection and Forecasting in Smart Grid. (arXiv:2307.16149v1 [cs.LG])

    [http://arxiv.org/abs/2307.16149](http://arxiv.org/abs/2307.16149)

    这篇论文提出了一种利用LSTM和DDPM相结合的方案来解决智能电网系统中的能量盗窃检测和预测问题。通过重构和预测误差，系统能够准确识别能量盗窃的实例，并在实验中表现出较好的性能。

    

    能量盗窃检测（ETD）和能量消耗预测（ECF）是智能电网系统中两个相互关联的挑战。共同解决这些问题对于确保系统安全至关重要。本论文解决了智能电网系统中的ETD和ECF的相互关联挑战。所提出的解决方案结合了长短期记忆（LSTM）和去噪扩散概率模型（DDPM），用于生成输入重构和预测。通过利用重构和预测误差，系统能够识别能量盗窃的实例，基于重构误差和预测误差的方法相互补充，可以检测不同类型的攻击。通过在真实和合成数据集上进行大量实验，所提出的方案在ETD和ECF问题上表现优于基准方法。集成方法显著提升了ETD性能，能够准确检测到基准方法未能检测到的能量盗窃攻击。该研究提供了一种可行的解决方案来解决智能电网系统中ETD和ECF的挑战。

    Energy theft detection (ETD) and energy consumption forecasting (ECF) are two interconnected challenges in smart grid systems. Addressing these issues collectively is crucial for ensuring system security. This paper addresses the interconnected challenges of ETD and ECF in smart grid systems. The proposed solution combines long short-term memory (LSTM) and a denoising diffusion probabilistic model (DDPM) to generate input reconstruction and forecasting. By leveraging the reconstruction and forecasting errors, the system identifies instances of energy theft, with the methods based on reconstruction error and forecasting error complementing each other in detecting different types of attacks. Through extensive experiments on real-world and synthetic datasets, the proposed scheme outperforms baseline methods in ETD and ECF problems. The ensemble method significantly enhances ETD performance, accurately detecting energy theft attacks that baseline methods fail to detect. The research offers
    
[^68]: 通过观看数百个手术视频讲座学习多模态表示

    Learning Multi-modal Representations by Watching Hundreds of Surgical Video Lectures. (arXiv:2307.15220v1 [cs.CV])

    [http://arxiv.org/abs/2307.15220](http://arxiv.org/abs/2307.15220)

    通过观看手术视频讲座，我们提出了一种新方法，SurgVLP，通过利用手术视频讲座中的语音和视觉信息进行多模态表示学习，并解决了手术相关语言挑战。

    

    最近在外科计算机视觉应用方面的进展主要依靠完全监督方法，主要使用视觉数据。这些方法依赖于手动注释的手术视频来预测一组固定的对象类别，限制了它们在未见手术程序和后续任务上的通用性。在这项工作中，我们提出了一个观点，即通过开放的手术电子学习平台提供的手术视频讲座可以为多模态表示学习提供有效的监督信号，而无需依赖手动注释。我们通过使用多个互补的自动语音识别系统生成文本转录来解决手术视频讲座中存在的手术相关语言挑战。然后，我们提出了一种新的方法，SurgVLP - 手术视觉语言预训练，用于多模态表示学习。SurgVLP构建了一种新的对比学习目标，将视频剪辑嵌入与相应的文本嵌入对齐。

    Recent advancements in surgical computer vision applications have been driven by fully-supervised methods, primarily using only visual data. These methods rely on manually annotated surgical videos to predict a fixed set of object categories, limiting their generalizability to unseen surgical procedures and downstream tasks. In this work, we put forward the idea that the surgical video lectures available through open surgical e-learning platforms can provide effective supervisory signals for multi-modal representation learning without relying on manual annotations. We address the surgery-specific linguistic challenges present in surgical video lectures by employing multiple complementary automatic speech recognition systems to generate text transcriptions. We then present a novel method, SurgVLP - Surgical Vision Language Pre-training, for multi-modal representation learning. SurgVLP constructs a new contrastive learning objective to align video clip embeddings with the corresponding m
    
[^69]: FedDRL: 一种基于分阶段强化学习的可信联邦学习模型融合方法

    FedDRL: A Trustworthy Federated Learning Model Fusion Method Based on Staged Reinforcement Learning. (arXiv:2307.13716v1 [cs.LG])

    [http://arxiv.org/abs/2307.13716](http://arxiv.org/abs/2307.13716)

    FedDRL是一种分阶段强化学习的联邦学习模型融合方法，解决了传统方法中无法解决的客户端模型质量和恶意模型问题。

    

    传统的联邦学习使用样本数量计算每个客户端模型的权重，并使用这个固定权重值来融合全局模型。然而，在实际场景中，每个客户端设备和数据的异质性导致每个客户端模型的质量存在差异。因此，对全局模型的贡献不仅仅取决于样本量。此外，如果客户端故意上传低质量或恶意模型，使用这些模型进行聚合将严重降低全局模型的准确性。传统的联邦学习算法没有解决这些问题。为了解决这个问题，我们提出了一种名为FedDRL的模型融合方法，它使用两个阶段的强化学习。在第一个阶段，我们的方法可以过滤掉恶意模型，并选择可信的客户端模型参与模型融合。在第二个阶段，FedDRL算法自适应地调整可信客户端模型的权重并聚合。

    Traditional federated learning uses the number of samples to calculate the weights of each client model and uses this fixed weight value to fusion the global model. However, in practical scenarios, each client's device and data heterogeneity leads to differences in the quality of each client's model. Thus the contribution to the global model is not wholly determined by the sample size. In addition, if clients intentionally upload low-quality or malicious models, using these models for aggregation will lead to a severe decrease in global model accuracy. Traditional federated learning algorithms do not address these issues. To solve this probelm, we propose FedDRL, a model fusion approach using reinforcement learning based on a two staged approach. In the first stage, Our method could filter out malicious models and selects trusted client models to participate in the model fusion. In the second stage, the FedDRL algorithm adaptively adjusts the weights of the trusted client models and ag
    
[^70]: 客户端级差分隐私通过自适应中介在联邦医学成像中

    Client-Level Differential Privacy via Adaptive Intermediary in Federated Medical Imaging. (arXiv:2307.12542v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2307.12542](http://arxiv.org/abs/2307.12542)

    本文在联邦医学成像中提出了一种客户端级差分隐私的优化策略，通过将客户端拆分为子客户端作为中介机构，来改善性能而不损害隐私。

    

    尽管最近在通过差分隐私（DP）增强联邦学习（FL）的隐私方面取得了进展，但在真实世界的医学场景中，DP在隐私保护和性能之间的权衡仍未充分探索。在本文中，我们提出在客户端级DP的背景下优化这种权衡，重点关注通信过程中的隐私。然而，医学成像的FL通常涉及的参与者（医院）比其他领域（如移动设备）少得多，因此确保客户端具有差分隐私更具挑战性。为了解决这个问题，我们提出了一种自适应中介策略，以提高性能而不损害隐私。具体来说，我们在理论上发现将客户端分为子客户端，作为医院和服务器之间的中介，可以减轻DP引入的噪音而不损害隐私。我们提出的方法在使用两个公共数据集进行分类和分割任务的实证评估中得到了验证。

    Despite recent progress in enhancing the privacy of federated learning (FL) via differential privacy (DP), the trade-off of DP between privacy protection and performance is still underexplored for real-world medical scenario. In this paper, we propose to optimize the trade-off under the context of client-level DP, which focuses on privacy during communications. However, FL for medical imaging involves typically much fewer participants (hospitals) than other domains (e.g., mobile devices), thus ensuring clients be differentially private is much more challenging. To tackle this problem, we propose an adaptive intermediary strategy to improve performance without harming privacy. Specifically, we theoretically find splitting clients into sub-clients, which serve as intermediaries between hospitals and the server, can mitigate the noises introduced by DP without harming privacy. Our proposed approach is empirically evaluated on both classification and segmentation tasks using two public dat
    
[^71]: 多阶段电缆布线的层次化模仿学习

    Multi-Stage Cable Routing through Hierarchical Imitation Learning. (arXiv:2307.08927v3 [cs.RO] CROSS LISTED)

    [http://arxiv.org/abs/2307.08927](http://arxiv.org/abs/2307.08927)

    本研究探讨了多阶段电缆布线任务中的层次化模仿学习方法，解决了处理可变形物体、视觉感知闭环和扩展行为的挑战。成功控制器需要能够从失败中恢复，并通过选择纠正低级控制器的缺陷。

    

    我们研究了学习如何执行多阶段机器人操作任务的问题，应用于电缆布线，其中机器人必须通过一系列夹子来布线。这个设置代表了复杂多阶段机器人操作场景的挑战：处理可变形物体，对视觉感知闭环，处理由多个步骤组成的扩展行为，必须成功执行才能完成整个任务。在这种设置中，为每个阶段学习成功率足够高的单个基元是不切实际的：如果每个阶段必须成功完成并且有较大的失败概率，整个任务成功完成的概率变得微不足道。因此，这样的多阶段任务的成功控制器必须能够从失败中恢复，并通过聪明地选择从而纠正低级控制器的缺陷。

    We study the problem of learning to perform multi-stage robotic manipulation tasks, with applications to cable routing, where the robot must route a cable through a series of clips. This setting presents challenges representative of complex multi-stage robotic manipulation scenarios: handling deformable objects, closing the loop on visual perception, and handling extended behaviors consisting of multiple steps that must be executed successfully to complete the entire task. In such settings, learning individual primitives for each stage that succeed with a high enough rate to perform a complete temporally extended task is impractical: if each stage must be completed successfully and has a non-negligible probability of failure, the likelihood of successful completion of the entire task becomes negligible. Therefore, successful controllers for such multi-stage tasks must be able to recover from failure and compensate for imperfections in low-level controllers by smartly choosing which con
    
[^72]: 探索大规模语言模型（LLMs）在图学习中的潜力

    Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs. (arXiv:2307.03393v1 [cs.LG])

    [http://arxiv.org/abs/2307.03393](http://arxiv.org/abs/2307.03393)

    本文探索了大规模语言模型（LLMs）在图学习中的潜力，并尝试了两种不同的流程：将LLMs作为增强器通过海量知识来增强节点的文本属性，并使用图神经网络（GNNs）生成预测，以及直接使用LLMs作为独立的预测器。

    

    图学习因其广泛的现实世界应用而引起了极大的关注。以文本节点属性为主的图学习最流行的流程主要依赖于图神经网络（GNN），并利用浅层文本嵌入作为初始节点表示，但存在通用知识和深刻语义理解方面的限制。近年来，大规模语言模型（LLMs）被证明具有广泛的常识和强大的语义理解能力，已经颠覆了现有的处理文本数据的工作流程。在本文中，我们旨在探索LLMs在图机器学习中的潜力，特别是节点分类任务，并研究两种可能的流程：LLMs作为增强器和LLMs作为预测器。前者利用LLMs通过其海量知识增强节点的文本属性，然后通过GNNs生成预测。后者试图直接使用LLMs作为独立的预测器。

    Learning on Graphs has attracted immense attention due to its wide real-world applications. The most popular pipeline for learning on graphs with textual node attributes primarily relies on Graph Neural Networks (GNNs), and utilizes shallow text embedding as initial node representations, which has limitations in general knowledge and profound semantic understanding. In recent years, Large Language Models (LLMs) have been proven to possess extensive common knowledge and powerful semantic comprehension abilities that have revolutionized existing workflows to handle text data. In this paper, we aim to explore the potential of LLMs in graph machine learning, especially the node classification task, and investigate two possible pipelines: LLMs-as-Enhancers and LLMs-as-Predictors. The former leverages LLMs to enhance nodes' text attributes with their massive knowledge and then generate predictions through GNNs. The latter attempts to directly employ LLMs as standalone predictors. We conduct 
    
[^73]: iSCAN：识别非线性加性噪声模型中的因果机制转变

    iSCAN: Identifying Causal Mechanism Shifts among Nonlinear Additive Noise Models. (arXiv:2306.17361v1 [cs.LG])

    [http://arxiv.org/abs/2306.17361](http://arxiv.org/abs/2306.17361)

    本文提出了一种识别非线性加性噪声模型中因果机制转变的方法，该方法专注于在相关的结构因果模型中识别功能机制的变化，而不需要估计整个有向无环图(DAG)的结构。

    

    结构因果模型(SCM)被广泛应用于各个领域，以表示复杂系统中变量之间的因果关系。然而，真正的底层有向无环图(DAG)结构通常是未知的，并且从观测数据或干预数据中确定它仍然是一项具有挑战性的任务。然而，在许多情况下，目标是识别相关SCM之间的因果机制的变化(转变)而不是恢复整个底层DAG结构。例子包括分析健康和癌症患者之间的基因调控网络结构变化，或者在不同细胞环境下理解生物途径的变化。本文重点研究了在相同的变量集上识别两个或多个相关SCM中的$\textit{功能}$机制转变，而不需要估计每个SCM的整个DAG结构。在这种设置下，先前的工作假设使用了具有高斯噪声的线性模型；而本文中我们则考虑了非线性加性噪声模型。

    Structural causal models (SCMs) are widely used in various disciplines to represent causal relationships among variables in complex systems. Unfortunately, the true underlying directed acyclic graph (DAG) structure is often unknown, and determining it from observational or interventional data remains a challenging task. However, in many situations, the end goal is to identify changes (shifts) in causal mechanisms between related SCMs rather than recovering the entire underlying DAG structure. Examples include analyzing gene regulatory network structure changes between healthy and cancerous individuals or understanding variations in biological pathways under different cellular contexts. This paper focuses on identifying $\textit{functional}$ mechanism shifts in two or more related SCMs over the same set of variables -$\textit{without estimating the entire DAG structure of each SCM}$. Prior work under this setting assumed linear models with Gaussian noises; instead, in this work we ass
    
[^74]: 天文光学望远镜的智能化：现状与未来展望

    Intelligence of Astronomical Optical Telescope: Present Status and Future Perspectives. (arXiv:2306.16834v1 [astro-ph.IM])

    [http://arxiv.org/abs/2306.16834](http://arxiv.org/abs/2306.16834)

    本文综合介绍了人工智能技术在天文学中的应用以及望远镜智能化的发展和研究热点，对各种研究方向进行了统计分析，并指出了各个望远镜智能化的研究趋势。

    

    人工智能技术在天文学中得到了广泛应用，不断涌现出新的人工智能技术和应用场景。目前，有大量的论文回顾了人工智能技术在天文学中的应用，然而很少有相关文章单独提及望远镜的智能化，并且很难从这些论文中了解到望远镜智能化的当前发展状况和研究热点。本文结合人工智能技术的发展历史和望远镜关键技术的困难，全面介绍了望远镜智能化的发展和研究热点，然后对望远镜智能化的各种研究方向进行了统计分析，并定义了各个研究方向的优点。评估了各种研究方向，并指出了每个望远镜智能化的研究趋势。

    Artificial intelligence technology has been widely used in astronomy, and new artificial intelligence technologies and application scenarios are constantly emerging. There have been a large number of papers reviewing the application of artificial intelligence technology in astronomy. However, relevant articles seldom mention telescope intelligence separately, and it is difficult to understand the current development status and research hotspots of telescope intelligence from these papers. This paper combines the development history of artificial intelligence technology and the difficulties of critical technologies of telescopes, comprehensively introduces the development and research hotspots of telescope intelligence, then conducts statistical analysis on various research directions of telescope intelligence and defines the research directions' merits. All kinds of research directions are evaluated, and the research trend of each telescope's intelligence is pointed out. Finally, accor
    
[^75]: DiffSketcher: 通过隐式扩散模型实现文本引导的矢量素描合成

    DiffSketcher: Text Guided Vector Sketch Synthesis through Latent Diffusion Models. (arXiv:2306.14685v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.14685](http://arxiv.org/abs/2306.14685)

    本文介绍了DiffSketcher，一种通过隐式扩散模型实现文本引导的矢量素描合成的创新算法。DiffSketcher通过直接优化贝塞尔曲线和扩散模型损失来生成矢量化的手绘素描，并通过注意力图加快生成过程。实验结果表明DiffSketcher的素描质量高于之前方法。

    

    尽管主要训练于图像，但我们发现预训练的扩散模型在引导素描合成方面表现出惊人的能力。本文提出了DiffSketcher，一种创新的算法，利用自然语言输入创建矢量化的手绘素描。DiffSketcher基于预训练的文本到图像扩散模型开发，通过使用扩展版本的得分蒸馏采样（SDS）损失直接优化一组贝塞尔曲线，使得我们可以将栅格级扩散模型作为先验来优化参数化的矢量素描生成器。此外，我们还探索了扩散模型中嵌入的注意力图，在生成过程中实现有效的笔画初始化以加快速度。生成的素描展示了多层次的抽象，同时保持了被绘制主题的可识别性、基本结构和重要的视觉细节。我们的实验证明，DiffSketcher的质量优于之前方法。

    Even though trained mainly on images, we discover that pretrained diffusion models show impressive power in guiding sketch synthesis. In this paper, we present DiffSketcher, an innovative algorithm that creates vectorized free-hand sketches using natural language input. DiffSketcher is developed based on a pre-trained text-to-image diffusion model. It performs the task by directly optimizing a set of Bezier curves with an extended version of the score distillation sampling (SDS) loss, which allows us to use a raster-level diffusion model as a prior for optimizing a parametric vectorized sketch generator. Furthermore, we explore attention maps embedded in the diffusion model for effective stroke initialization to speed up the generation process. The generated sketches demonstrate multiple levels of abstraction while maintaining recognizability, underlying structure, and essential visual details of the subject drawn. Our experiments show that DiffSketcher achieves greater quality than pr
    
[^76]: 渐进能量协作学习用于多域图像到图像的转换

    Progressive Energy-Based Cooperative Learning for Multi-Domain Image-to-Image Translation. (arXiv:2306.14448v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.14448](http://arxiv.org/abs/2306.14448)

    本文提出了一种渐进能量协作学习框架，用于多域图像到图像的转换。该框架包含描述器、翻译器、风格编码器和风格生成器四个组件。通过这种框架，可以实现多样化的图像生成和一对多的转换。

    

    本文研究了一种新颖的基于能量的合作学习框架，用于多域图像到图像的转换。该框架由四个组件组成：描述器、翻译器、风格编码器和风格生成器。描述器是一个多头能量模型，表示多域图像分布。翻译器、风格编码器和风格生成器的组件构成了一个多样化图像生成器。具体而言，给定一个来自源域的输入图像，翻译器根据风格代码将其转换为目标域的风格化输出图像，风格代码可以由风格编码器从参考图像推断出或由风格生成器从随机噪声生成。由于风格生成器被表示为特定于域的风格代码分布，翻译器可以在源域和目标域之间提供一对多的转换（即多样化生成）。为了训练我们的框架，我们提出了一个基于似然的多域合作学习方法。

    This paper studies a novel energy-based cooperative learning framework for multi-domain image-to-image translation. The framework consists of four components: descriptor, translator, style encoder, and style generator. The descriptor is a multi-head energy-based model that represents a multi-domain image distribution. The components of translator, style encoder, and style generator constitute a diversified image generator. Specifically, given an input image from a source domain, the translator turns it into a stylised output image of the target domain according to a style code, which can be inferred by the style encoder from a reference image or produced by the style generator from a random noise. Since the style generator is represented as an domain-specific distribution of style codes, the translator can provide a one-to-many transformation (i.e., diversified generation) between source domain and target domain. To train our framework, we propose a likelihood-based multi-domain cooper
    
[^77]: 做我能做的，而不是我得到的。(arXiv:2306.10345v2 [cs.AI] UPDATED)

    Do as I can, not as I get. (arXiv:2306.10345v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.10345](http://arxiv.org/abs/2306.10345)

    该论文提出了一种名为TMR的模型，用于从模拟数据环境中挖掘有价值的信息。

    

    本文提出了一种名为TMR的模型，用于从模拟数据环境中挖掘有价值的信息。我们打算完成本文的投稿。

    This paper proposes a model called TMR to mine valuable information from simulated data environments. We intend to complete the submission of this paper.
    
[^78]: 残差 Q 学习：无需价值的在线和离线策略定制

    Residual Q-Learning: Offline and Online Policy Customization without Value. (arXiv:2306.09526v1 [cs.LG])

    [http://arxiv.org/abs/2306.09526](http://arxiv.org/abs/2306.09526)

    该研究提出了一种新方法，使用动态控制残差的 Q 学习来进行离线和在线的策略定制，无需使用价值函数。

    

    模仿学习是一种广泛使用的框架，适用于从演示中学习模仿行为。当手工制作奖励函数困难或目标是模仿人类专家行为时，这种方法特别有吸引力。但是，学习的模仿策略只能遵循演示中的行为。在应用模仿策略时，我们可能需要根据不同的下游任务要求定制策略行为。同时，我们仍希望定制的策略保持其模仿性质。为此，我们提出了一种新的问题设置，称为策略定制。它将学习任务定义为训练一种策略，该策略继承先前策略的特性，同时满足目标下游任务强加的一些附加要求。我们提出了一种新颖和有原则的方法来解释和确定两个任务目标之间的权衡。具体而言，我们制定了一种动态控制残差的 Q 学习方法，该方法可以在不使用价值函数的情况下进行在线和离线策略定制。

    Imitation Learning (IL) is a widely used framework for learning imitative behavior from demonstrations. It is especially appealing for solving complex real-world tasks where handcrafting reward function is difficult, or when the goal is to mimic human expert behavior. However, the learned imitative policy can only follow the behavior in the demonstration. When applying the imitative policy, we may need to customize the policy behavior to meet different requirements coming from diverse downstream tasks. Meanwhile, we still want the customized policy to maintain its imitative nature. To this end, we formulate a new problem setting called policy customization. It defines the learning task as training a policy that inherits the characteristics of the prior policy while satisfying some additional requirements imposed by a target downstream task. We propose a novel and principled approach to interpret and determine the trade-off between the two task objectives. Specifically, we formulate the
    
[^79]: ShiftAddViT：多种乘法原语混合实现高效的视觉变换器

    ShiftAddViT: Mixture of Multiplication Primitives Towards Efficient Vision Transformer. (arXiv:2306.06446v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.06446](http://arxiv.org/abs/2306.06446)

    ShiftAddViT通过使用位移和加法等多种乘法原语对ViT进行重新参数化，实现了减少乘法操作的高效视觉变换器模型，可以在GPU上实现端到端的推理加速，无需从头训练。

    

    视觉变换器（ViT）展示了令人印象深刻的性能，并成为多个视觉任务的统一骨干。但是，ViTs中的注意力和多层感知器（MLPs）由于密集的乘法而不够高效，导致训练和推理代价高昂。为此，我们提出了一种将预训练的ViT以多种乘法原语（例如位移和加法）重新参数化的方法，以实现全新类型的减少乘法的模型，称为ShiftAddViT，旨在实现GPU上的端到端推理加速，无需从头开始训练。具体而言，我们将查询和键映射为汉明空间中的二进制码之后，采用加法核对查询、键和值之间的MatMul进行重新参数化。剩余的MLPs或线性层则采用位移核进行重新参数化。我们利用TVM在GPU上实施并优化这些定制核，以实现实际硬件部署。我们发现，这种重新参数化方法可以显著提高推理速度，而无需从头开始训练。

    Vision Transformers (ViTs) have shown impressive performance and have become a unified backbone for multiple vision tasks. But both attention and multi-layer perceptions (MLPs) in ViTs are not efficient enough due to dense multiplications, resulting in costly training and inference. To this end, we propose to reparameterize the pre-trained ViT with a mixture of multiplication primitives, e.g., bitwise shifts and additions, towards a new type of multiplication-reduced model, dubbed $\textbf{ShiftAddViT}$, which aims for end-to-end inference speedups on GPUs without the need of training from scratch. Specifically, all $\texttt{MatMuls}$ among queries, keys, and values are reparameterized by additive kernels, after mapping queries and keys to binary codes in Hamming space. The remaining MLPs or linear layers are then reparameterized by shift kernels. We utilize TVM to implement and optimize those customized kernels for practical hardware deployment on GPUs. We find that such a reparameter
    
[^80]: 巨型语言模型在意大利生物医学信息提取方面的应用：方法论研究和实际应用的多中心实践

    Advancing Italian Biomedical Information Extraction with Large Language Models: Methodological Insights and Multicenter Practical Application. (arXiv:2306.05323v1 [cs.CL])

    [http://arxiv.org/abs/2306.05323](http://arxiv.org/abs/2306.05323)

    该研究创建了意大利神经精神命名实体识别数据集，并使用巨型语言模型开发出多中心识别模型，整体 F1得分为84.77%。该模型将帮助临床从业者从非结构化的医疗记录中自动提取信息。

    

    医院引入计算机化医疗记录有助于减少手写和信息提取等繁琐操作。然而，由于从非结构化文本医疗记录中提取数据需要时间和精力，因此医疗记录中包含的数据仍然被充分利用程度低。自然语言处理的子领域信息提取可以帮助临床从业者克服这一限制，使用自动化文本挖掘流程。在这项工作中，我们创建了意大利神经精神命名实体识别数据集 PsyNIT，并使用它来开发这一任务的巨型语言模型。此外，我们还进行了多个实验，使用三个外部独立数据集来实现有效的多中心模型，整体 F1 得分为 84.77%，精确率为 83.16%，召回率为 86.44%。我们学到的经验是: (i) 一致的注释过程的关键作用和 (ii) 结合经典方法和“少量训练”的 fine-tuning 策略。

    The introduction of computerized medical records in hospitals has reduced burdensome operations like manual writing and information fetching. However, the data contained in medical records are still far underutilized, primarily because extracting them from unstructured textual medical records takes time and effort. Information Extraction, a subfield of Natural Language Processing, can help clinical practitioners overcome this limitation, using automated text-mining pipelines. In this work, we created the first Italian neuropsychiatric Named Entity Recognition dataset, PsyNIT, and used it to develop a Large Language Model for this task. Moreover, we conducted several experiments with three external independent datasets to implement an effective multicenter model, with overall F1-score 84.77%, Precision 83.16%, Recall 86.44%. The lessons learned are: (i) the crucial role of a consistent annotation process and (ii) a fine-tuning strategy that combines classical methods with a "few-shot" a
    
[^81]: 学习我们能够掌握的力量：基于像素级交互的多目标视频生成

    Learn the Force We Can: Multi-Object Video Generation from Pixel-Level Interactions. (arXiv:2306.03988v1 [cs.CV])

    [http://arxiv.org/abs/2306.03988](http://arxiv.org/abs/2306.03988)

    本论文提出了一种基于像素级交互的多目标视频生成方法，能够生成逼真的物体间相互作用的视频，且能准确跟随用户的控制，达到了最先进的视频生成先前工作相媲美甚至更好的效果。

    

    我们提出了一种新颖的无监督方法，通过单帧图像与稀疏运动输入来自我回归生成视频。我们训练的模型能够生成逼真的物体间相互作用，并在仅观测到它们在相关运动活动下时分离多个物体的动态和范围。我们方法的关键组件是随机化条件方案、输入运动控制的编码以及随机化和稀疏采样来打破相关性。我们称之为YODA的模型具有能够移动物体而无需实际触摸的能力。我们定量和定性地展示，YODA能够准确跟随用户的控制，并在多个数据集上呈现出与现有最先进的视频生成先前工作相媲美甚至更好的视频质量。详情请参阅我们的项目网站 https://araachie.github.io/yoda。

    We propose a novel unsupervised method to autoregressively generate videos from a single frame and a sparse motion input. Our trained model can generate realistic object-to-object interactions and separate the dynamics and the extents of multiple objects despite only observing them under correlated motion activities. Key components in our method are the randomized conditioning scheme, the encoding of the input motion control, and the randomized and sparse sampling to break correlations. Our model, which we call YODA, has the ability to move objects without physically touching them. We show both qualitatively and quantitatively that YODA accurately follows the user control, while yielding a video quality that is on par with or better than state of the art video generation prior work on several datasets. For videos, visit our project website https://araachie.github.io/yoda.
    
[^82]: 可分目标的最优决策树：推动动态规划的极限

    Optimal Decision Trees for Separable Objectives: Pushing the Limits of Dynamic Programming. (arXiv:2305.19706v1 [cs.LG])

    [http://arxiv.org/abs/2305.19706](http://arxiv.org/abs/2305.19706)

    本研究提出了一种通用的动态规划方法来优化任何组合的可分离目标和约束条件，这种方法在可扩展性方面比通用求解器表现得更好。

    

    决策树的全局优化在准确性，大小和人类可理解性方面表现出良好的前景。然而，许多方法仍然依赖于通用求解器，可扩展性仍然是一个问题。动态规划方法已被证明具有更好的可扩展性，因为它们通过将子树作为独立的子问题解决来利用树结构。然而，这仅适用于可以分别优化子树的任务。我们详细研究了这种关系，并展示了实现这种可分离约束和目标任意组合的动态规划方法。在四个应用领域的实验表明了这种方法的普适性，同时也比通用求解器具有更好的可扩展性。

    Global optimization of decision trees has shown to be promising in terms of accuracy, size, and consequently human comprehensibility. However, many of the methods used rely on general-purpose solvers for which scalability remains an issue. Dynamic programming methods have been shown to scale much better because they exploit the tree structure by solving subtrees as independent subproblems. However, this only works when an objective can be optimized separately for subtrees. We explore this relationship in detail and show necessary and sufficient conditions for such separability and generalize previous dynamic programming approaches into a framework that can optimize any combination of separable objectives and constraints. Experiments on four application domains show the general applicability of this framework, while outperforming the scalability of general-purpose solvers by a large margin.
    
[^83]: 探索唇部运动的语音上下文对真实说话人脸生成的影响

    Exploring Phonetic Context in Lip Movement for Authentic Talking Face Generation. (arXiv:2305.19556v1 [cs.CV])

    [http://arxiv.org/abs/2305.19556](http://arxiv.org/abs/2305.19556)

    本研究探讨了语音上下文对真实说话人脸生成的影响，提出了一种Context-Aware Lip-Sync框架（CALS），可利用语音上下文生成更加准确、稳定的唇部运动。

    

    说话人脸生成是将自然面部与驱动音频同步合成的任务。尽管在视觉质量、唇形同步和面部动作方面取得了很大进展，但当前的研究仍然难以解决粗糙和异步的唇部运动问题，这可能导致类似木偶动画的效果。本文发现，以往的作品通常将唇部运动与音频在不同的音素级别上进行相关联，然而，由于音素之间的协同发音（co-articulation）现象，即隔离的音素受前一个或下一个音素的影响，因此同一个音素的发音因音素上下文而异。因此，使用音素上下文模型可以生成更加空间和时间上对齐、稳定的唇部运动。基于此，我们研究了唇部运动中的语音上下文对于真实说话人脸生成的影响。我们提出了一种Context-Aware Lip-Sync框架（CALS），利用语音上下文生成更加空间和时间上对齐、稳定的唇部运动。

    Talking face generation is the task of synthesizing a natural face synchronous to driving audio. Although much progress has been made in terms of visual quality, lip synchronization, and facial motion of the talking face, current works still struggle to overcome issues of crude and asynchronous lip movement, which can result in puppetry-like animation. We identify that the prior works commonly correlate lip movement with audio at the phone level. However, due to co-articulation, where an isolated phone is influenced by the preceding or following phones, the articulation of a phone varies upon the phonetic context. Therefore, modeling lip motion with the phonetic context can generate more spatio-temporally aligned and stable lip movement. In this respect, we investigate the phonetic context in lip motion for authentic talking face generation. We propose a Context-Aware Lip-Sync framework (CALS), which leverages phonetic context to generate more spatio-temporally aligned and stable lip m
    
[^84]: 可视化编程中神经任务合成

    Neural Task Synthesis for Visual Programming. (arXiv:2305.18342v1 [cs.LG])

    [http://arxiv.org/abs/2305.18342](http://arxiv.org/abs/2305.18342)

    该论文提出了一种基于神经符号技术的可视化编程任务合成方法NeurTaskSyn。该方法能够针对规范中给出的解决方案代码所需要的编程概念和对可视化任务的限制，自动生成编程任务。

    

    通过合成新的内容，生成式神经模型在增强编程教育方面具有巨大的潜力。我们旨在设计神经模型，能够根据可视化编程环境下给定的规范自动生成编程任务。尽管近年来像 GPT-4 这样的大型生成模型获得了成功，但我们的初步结果显示，这些模型在合成可视化编程任务方面效果不佳，并且在逻辑和空间推理方面存在困难。我们提出了一种新颖的神经符号技术 NeurTaskSyn，该技术能够针对规范中给出的解决方案代码所需要的编程概念和对可视化任务的限制，合成编程任务。NeurTaskSyn 由两个部分构成：第一个部分通过模仿学习程序进行训练，生成可能的解决方案代码，第二个部分通过强化学习程序进行训练，指导底层符号执行引擎生成可视化任务。

    Generative neural models hold great promise in enhancing programming education by synthesizing new content for students. We seek to design neural models that can automatically generate programming tasks for a given specification in the context of visual programming domains. Despite the recent successes of large generative models like GPT-4, our initial results show that these models are ineffective in synthesizing visual programming tasks and struggle with logical and spatial reasoning. We propose a novel neuro-symbolic technique, NeurTaskSyn, that can synthesize programming tasks for a specification given in the form of desired programming concepts exercised by its solution code and constraints on the visual task. NeurTaskSyn has two components: the first component is trained via imitation learning procedure to generate possible solution codes, and the second component is trained via reinforcement learning procedure to guide an underlying symbolic execution engine that generates visua
    
[^85]: 学习与勾结在多单位拍卖中的应用

    Learning and Collusion in Multi-unit Auctions. (arXiv:2305.17402v2 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2305.17402](http://arxiv.org/abs/2305.17402)

    本论文研究了在多单位拍卖中学习和勾结的问题，分析了拍卖的离线和在线性质，提出了一个多项式时间算法来解决离线设置中的玩家出价最大化问题。

    

    我们考虑重复的多单位拍卖与统一定价，这种拍卖在实践中被广泛用于分配诸如碳排放许可证之类的商品。在每一轮中，$K$个相同的商品单元被卖给一组具有递减边际回报价值的买家。买家为商品单位提交出价，然后根据出价确定一个单位的价格$p$，使得所有单位都能被售出。我们考虑拍卖的两个变体，其中价格分别设为第$K$高出价和第$(K+1)$高出价。我们在离线和在线设置中分析了拍卖的性质。在离线设置中，我们考虑一个玩家$i$面临的问题：在过去的拍卖中，给定包含竞争对手提交的出价的数据集，找到一个出价向量，使得玩家$i$在该数据集上的累积效用最大化。我们设计了一个多项式时间算法来解决这个问题，通过将其等价于在仔细构造的有向图上找到最大权重路径。

    We consider repeated multi-unit auctions with uniform pricing, which are widely used in practice for allocating goods such as carbon licenses. In each round, $K$ identical units of a good are sold to a group of buyers that have valuations with diminishing marginal returns. The buyers submit bids for the units, and then a price $p$ is set per unit so that all the units are sold. We consider two variants of the auction, where the price is set to the $K$-th highest bid and $(K+1)$-st highest bid, respectively.  We analyze the properties of this auction in both the offline and online settings. In the offline setting, we consider the problem that one player $i$ is facing: given access to a data set that contains the bids submitted by competitors in past auctions, find a bid vector that maximizes player $i$'s cumulative utility on the data set. We design a polynomial time algorithm for this problem, by showing it is equivalent to finding a maximum-weight path on a carefully constructed direc
    
[^86]: 基于扩散的对抗样本生成以提高隐蔽性和可控性

    Diffusion-Based Adversarial Sample Generation for Improved Stealthiness and Controllability. (arXiv:2305.16494v1 [cs.CV])

    [http://arxiv.org/abs/2305.16494](http://arxiv.org/abs/2305.16494)

    本文提出了一个名为Diff-PGD的新框架，用于生成接近原始数据分布、逼真的对抗样本，具有较好的隐蔽性和对抗强度可调性。

    

    神经网络容易受到对抗样本的影响：这是一种特意制作的自然图片的微小变化，旨在误导模型。虽然这些对抗样本在数字和物理场景中可以轻松生成，但它们往往与自然图像的实际数据分布差异很大，导致强度与隐蔽性之间存在权衡。本文提出了一个名为扩散-投影梯度下降（Diff-PGD）的新框架，用于生成逼真的对抗样本。通过利用扩散模型引导的梯度，Diff-PGD确保对抗样本保持接近原始数据分布，同时保持它们的有效性。此外，我们的框架可以轻松定制特定任务，如数字攻击、物理攻击和基于样式的攻击。与现有的生成自然风格对抗样本方法相比，我们的框架可以分离优化对抗强度和隐蔽性，提供更大的灵活性和对生成样本的控制。

    Neural networks are known to be susceptible to adversarial samples: small variations of natural examples crafted to deliberately mislead the models. While they can be easily generated using gradient-based techniques in digital and physical scenarios, they often differ greatly from the actual data distribution of natural images, resulting in a trade-off between strength and stealthiness. In this paper, we propose a novel framework dubbed Diffusion-Based Projected Gradient Descent (Diff-PGD) for generating realistic adversarial samples. By exploiting a gradient guided by a diffusion model, Diff-PGD ensures that adversarial samples remain close to the original data distribution while maintaining their effectiveness. Moreover, our framework can be easily customized for specific tasks such as digital attacks, physical-world attacks, and style-based attacks. Compared with existing methods for generating natural-style adversarial samples, our framework enables the separation of optimizing adv
    
[^87]: 如何通过概率电路将您的知识图嵌入转化为生成模型

    How to Turn Your Knowledge Graph Embeddings into Generative Models via Probabilistic Circuits. (arXiv:2305.15944v1 [cs.LG])

    [http://arxiv.org/abs/2305.15944](http://arxiv.org/abs/2305.15944)

    本文提出了将知识图嵌入模型转化为生成模型的方法，允许精确MLE学习、有效抽样新的三元组以及保证逻辑约束，获得了比原始KGEs更具伸缩性的性能。

    

    一些成功的知识图嵌入模型可用作基于能量的模型，而这篇论文解释了这些模型的得分函数，将其重新解释成为电路形式--这是一种允许有效边际化的约束计算图。然后，我们设计了两个方法来获得有效的生成电路模型，其中一个方法是将其激活限制为非负数，另一个方法是将其输出平方。我们的解释不会影响到预测节点连边模型的性能，但电路框架使得MLE的精确学习、新三元组的有效抽样以及保证逻辑约束得以满足成为可能。此外，我们的模型在拥有数百万个实体的图上比原始的KGEs更具伸缩性。

    Some of the most successful knowledge graph embedding (KGE) models for link prediction -- CP, RESCAL, TuckER, ComplEx -- can be interpreted as energy-based models. Under this perspective they are not amenable for exact maximum-likelihood estimation (MLE), sampling and struggle to integrate logical constraints. This work re-interprets the score functions of these KGEs as circuits -- constrained computational graphs allowing efficient marginalisation. Then, we design two recipes to obtain efficient generative circuit models by either restricting their activations to be non-negative or squaring their outputs. Our interpretation comes with little or no loss of performance for link prediction, while the circuits framework unlocks exact learning by MLE, efficient sampling of new triples, and guarantee that logical constraints are satisfied by design. Furthermore, our models scale more gracefully than the original KGEs on graphs with millions of entities.
    
[^88]: PillarAcc: 稀疏点云Pillars加速器——边缘设备上实时三维物体检测

    PillarAcc: Sparse PointPillars Accelerator for Real-Time Point Cloud 3D Object Detection on Edge Devices. (arXiv:2305.07522v1 [cs.AR])

    [http://arxiv.org/abs/2305.07522](http://arxiv.org/abs/2305.07522)

    PillarAcc提出了一种稀疏算法-硬件协同设计，有效增强基于Pillar的三维物体检测网络，实现高效率的计算减少。

    

    使用点云(PC)数据进行三维物体检测对于自动驾驶感知管道至关重要，其中高效的编码是满足严格资源和延迟要求的关键。PointPillars是一种广泛采用的鸟瞰图(BEV)编码方法，将三维点云数据聚合到二维pillar中，实现高精度的三维物体检测。然而，大多数采用PointPillar的最先进方法都忽视了pillar编码的固有稀疏性，错失了大量计算减少的机会。在本研究中，我们提出了一种开创性的算法-硬件协同设计，加速稀疏卷积处理，并最大限度地利用pillar的稀疏性来进行基于pillar的三维物体检测网络。我们使用先进的pillar pruning方法对稀疏化机会进行了研究，并实现了精确性和稀疏性之间的最优平衡。我们引入了PillarAcc，这是一种最先进的稀疏支持机制，通过输入具有线性复杂度的方法增强稀疏pillar卷积。

    3D object detection using point cloud (PC) data is vital for autonomous driving perception pipelines, where efficient encoding is key to meeting stringent resource and latency requirements. PointPillars, a widely adopted bird's-eye view (BEV) encoding, aggregates 3D point cloud data into 2D pillars for high-accuracy 3D object detection. However, most state-of-the-art methods employing PointPillar overlook the inherent sparsity of pillar encoding, missing opportunities for significant computational reduction. In this study, we propose a groundbreaking algorithm-hardware co-design that accelerates sparse convolution processing and maximizes sparsity utilization in pillar-based 3D object detection networks. We investigate sparsification opportunities using an advanced pillar-pruning method, achieving an optimal balance between accuracy and sparsity. We introduce PillarAcc, a state-of-the-art sparsity support mechanism that enhances sparse pillar convolution through linear complexity input
    
[^89]: 稀疏和密集神经网络中的小批量大小的相变

    Phase transitions in the mini-batch size for sparse and dense neural networks. (arXiv:2305.06435v1 [cond-mat.dis-nn])

    [http://arxiv.org/abs/2305.06435](http://arxiv.org/abs/2305.06435)

    本文系统地研究了小批量大小对稀疏和密集神经网络训练的影响，发现在临界值处会出现尖锐的相变，阐明了神经网络优化的基本机制。

    

    在训练人工神经网络时，使用小批量数据现在非常普遍。尽管已经广泛使用，但缺少定量解释最佳小批量大小应该是多大的理论。本文尝试系统地理解小批量大小在训练两层神经网络中的作用。在教师-学生情境下，使用稀疏教师，并聚焦于不同复杂度的任务，我们量化了改变小批量大小m的影响。我们发现，通常情况下，学生的泛化性能强烈依赖于m，并且可能在临界值mc处经历尖锐的相变，这样当m< mc时，训练过程失败，而当m> mc时，学生可以完美地学习或很好地泛化教师。相变是由统计力学首次发现的集体现象，并在许多科学领域观察到。找到在深度学习中改变小批量大小的相变，可以阐明神经网络优化的基本机制。

    The use of mini-batches of data in training artificial neural networks is nowadays very common. Despite its broad usage, theories explaining quantitatively how large or small the optimal mini-batch size should be are missing. This work presents a systematic attempt at understanding the role of the mini-batch size in training two-layer neural networks. Working in the teacher-student scenario, with a sparse teacher, and focusing on tasks of different complexity, we quantify the effects of changing the mini-batch size $m$. We find that often the generalization performances of the student strongly depend on $m$ and may undergo sharp phase transitions at a critical value $m_c$, such that for $m<m_c$ the training process fails, while for $m>m_c$ the student learns perfectly or generalizes very well the teacher. Phase transitions are induced by collective phenomena firstly discovered in statistical mechanics and later observed in many fields of science. Finding a phase transition varying the 
    
[^90]: 大规模网上拼车：任务分配优化对系统性能的影响

    Large-scale Online Ridesharing: The Effect of Assignment Optimality on System Performance. (arXiv:2305.02209v1 [math.OC])

    [http://arxiv.org/abs/2305.02209](http://arxiv.org/abs/2305.02209)

    本文介绍了一种名为VGA方法的拼车系统方法，可以用于计算大规模MoD系统中的最优乘客-车辆分配和相应的车辆路径。研究者比较了使用最优分配的MoD系统与使用普通分配的MoD系统的性能。

    

    流动出行（MoD）系统由一群共享汽车组成，可用于单程点对点的乘坐。通过使用拼车，即将多名乘客分配到一辆车上，可以减少车辆和车队的行驶总里程。然而，在MoD系统中找到最优的乘客-车辆分配是一个困难的组合问题。本文介绍了一个名为VGA方法的最近提出的拼车系统方法，该方法可以用于计算大规模MoD系统中的最优乘客-车辆分配和相应的车辆路径。与现有的研究相比，我们解决了所有乘客-车辆分配问题，定期处理包含成千上万辆车和乘客的实例。此外，为了检查使用最优拼车分配的影响，我们比较了使用最优分配的MoD系统与使用普通分配的MoD系统的性能。

    Mobility-on-demand (MoD) systems consist of a fleet of shared vehicles that can be hailed for one-way point-to-point trips. The total distance driven by the vehicles and the fleet size can be reduced by employing ridesharing, i.e., by assigning multiple passengers to one vehicle. However, finding the optimal passenger-vehicle assignment in an MoD system is a hard combinatorial problem. In this work, we demonstrate how the VGA method, a recently proposed systematic method for ridesharing, can be used to compute the optimal passenger-vehicle assignments and corresponding vehicle routes in a massive-scale MoD system. In contrast to existing works, we solve all passenger-vehicle assignment problems to optimality, regularly dealing with instances containing thousands of vehicles and passengers. Moreover, to examine the impact of using optimal ridesharing assignments, we compare the performance of an MoD system that uses optimal assignments against an MoD system that uses assignments compute
    
[^91]: Pgx:强化学习硬件加速的并行游戏模拟器

    Pgx: Hardware-accelerated parallel game simulation for reinforcement learning. (arXiv:2303.17503v1 [cs.AI])

    [http://arxiv.org/abs/2303.17503](http://arxiv.org/abs/2303.17503)

    Pgx是一个用JAX编写的游戏模拟器集合，具有强化学习硬件加速能力，支持并行执行，速度比现有的强化学习库快10倍。 它实现了Backgammon，Shogi和Go等基准测试游戏。

    

    我们提出了Pgx，这是一个用JAX编写的棋盘游戏模拟器集合。由于JAX的自动向量化和即时编译功能，Pgx易于在GPU/TPU加速器上进行大规模并行执行。我们发现，在单个A100 GPU上的Pgx模拟比现有的强化学习库快10倍。Pgx实现了被认为是人工智能研究中至关重要的基准测试的游戏，如Backgammon，Shogi和Go。 Pgx可在https://github.com/sotetsuk/pgx获得。

    We propose Pgx, a collection of board game simulators written in JAX. Thanks to auto-vectorization and Just-In-Time compilation of JAX, Pgx scales easily to thousands of parallel execution on GPU/TPU accelerators. We found that the simulation of Pgx on a single A100 GPU is 10x faster than that of existing reinforcement learning libraries. Pgx implements games considered vital benchmarks in artificial intelligence research, such as Backgammon, Shogi, and Go. Pgx is available at https://github.com/sotetsuk/pgx.
    
[^92]: 一种用于未知隧道建设场地的基于视觉的自主无人机视检测框架（更新版）

    A vision-based autonomous UAV inspection framework for unknown tunnel construction sites with dynamic obstacles. (arXiv:2301.08422v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2301.08422](http://arxiv.org/abs/2301.08422)

    本文提出了一种基于视觉的无人机视检测框架，用于动态隧道环境而无需使用先前的地图，通过分层规划方案将检测问题分解成不同层次，实现了最大化的自主水平。

    

    基于钻炸法的隧道建设需要对挖掘前部位进行三维测量以评估压碎位置。为了考虑检测和测量任务的安全、成本和效益，部署轻便的自主机器人，如无人机（UAV），变得更加必要和普遍。大多数先前的工作都使用先前的地图进行检验视点的确定并没有考虑动态障碍物。为了最大限度地增加自主水平，本文提出了一种基于视觉的无人机视检测框架，用于动态隧道环境而无需使用先前的地图。我们的方法利用分层规划方案将检测问题分解成不同层次。高层决策者首先确定机器人的任务并生成目标点。然后，中层路径规划器找到途径点路径并优化免碰撞静态轨迹。最后，静态轨迹将输入低层控制器以实现控制。

    Tunnel construction using the drill-and-blast method requires the 3D measurement of the excavation front to evaluate underbreak locations. Considering the inspection and measurement task's safety, cost, and efficiency, deploying lightweight autonomous robots, such as unmanned aerial vehicles (UAV), becomes more necessary and popular. Most of the previous works use a prior map for inspection viewpoint determination and do not consider dynamic obstacles. To maximally increase the level of autonomy, this paper proposes a vision-based UAV inspection framework for dynamic tunnel environments without using a prior map. Our approach utilizes a hierarchical planning scheme, decomposing the inspection problem into different levels. The high-level decision maker first determines the task for the robot and generates the target point. Then, the mid-level path planner finds the waypoint path and optimizes the collision-free static trajectory. Finally, the static trajectory will be fed into the low-
    
[^93]: DeepSpeed数据效率：通过高效的数据采样和路由改善深度学习模型质量和训练效率

    DeepSpeed Data Efficiency: Improving Deep Learning Model Quality and Training Efficiency via Efficient Data Sampling and Routing. (arXiv:2212.03597v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.03597](http://arxiv.org/abs/2212.03597)

    DeepSpeed Data Efficiency提出了两种数据效率技术：高效的数据采样和高效的数据路由，能够提高深度学习模型的训练效率和质量。

    

    近年来，深度学习模型的进步以巨大的训练成本为代价。模型尺寸的增加是一个主要原因，但另一个不太被重视的事实是，数据规模实际上与模型规模以相似的速度增加，而训练成本与两者成比例。与不断发展的模型架构相比，如何高效利用训练数据（特别是对于昂贵的基础模型预训练）在较少被探索且难以实现，这是因为缺乏一个专注于数据效率能力的方便框架。为此，我们提出了DeepSpeed数据效率，一种能更好地利用数据、提高训练效率并改善模型质量的框架。具体而言，我们提出并结合了两种数据效率技术：通过通用课程学习库实现高效数据采样，以及通过一种新颖的随机逐层删除令牌的技术实现高效数据路由。针对GPT-3 1.3B语言模型预训练进行了实验验证。

    Recent advances on deep learning models come at the price of formidable training cost. The increasing model size is one of the root causes, but another less-emphasized fact is that data scale is actually increasing at a similar speed as model scale, and the training cost is proportional to both of them. Compared to the rapidly evolving model architecture, how to efficiently use the training data (especially for the expensive foundation model pretraining) is both less explored and difficult to realize due to the lack of a convenient framework that focuses on data efficiency capabilities. To this end, we present DeepSpeed Data Efficiency, a framework that makes better use of data, increases training efficiency, and improves model quality. Specifically, we propose and combine two data efficiency techniques: efficient data sampling via a general curriculum learning library, and efficient data routing via a novel random layerwise token dropping technique. For GPT-3 1.3B language model pretr
    
[^94]: NLP中的不良偏见：避免衡量危机

    Undesirable biases in NLP: Averting a crisis of measurement. (arXiv:2211.13709v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.13709](http://arxiv.org/abs/2211.13709)

    这项研究提供了一个跨学科的方法来探讨NLP模型偏见的问题，通过采用心理测量学的视角，特别关注构念效度和测量工具的信度，在衡量模型偏见的情境中如何应用。

    

    随着大型语言模型和自然语言处理（NLP）技术的快速发展和普及，预测其使用可能对人们造成伤害变得至关重要。近年来，一个受到关注的问题是这一技术在行为中显示出有害偏见。尽管已经投入了大量的努力来评估和减轻这些偏见，但我们衡量NLP模型偏见的方法存在严重问题（例如，通常不清楚它们到底衡量了什么）。在本文中，我们采用心理测量学的视角，提供了一个跨学科的方法来讨论NLP模型偏见的问题，心理测量学专注于衡量不直接可观察到的概念，如偏见。具体而言，我们将探讨心理测量学的两个核心概念，即构念效度和测量工具的信度，并讨论它们在衡量模型偏见的情境中如何应用。我们的目标是提供一个全面的视角来解决这个问题。

    As Large Language Models and Natural Language Processing (NLP) technology rapidly develops and spreads into daily life, it becomes crucial to anticipate how its use could harm people. One problem that has received a lot of attention in recent years is that this technology has displayed harmful biases in its behavior. Although a lot of effort has been invested in assessing and mitigating these biases, our methods of measuring the biases of NLP models have serious problems (e.g., it is often unclear what they actually measure). In this paper, we provide an interdisciplinary approach to discussing the issue of NLP model bias by adopting the lens of psychometrics -- a field specialized in the measurement of concepts like bias that are not directly observable. In particular, we will explore two central notions from psychometrics, the construct validity and the reliability of measurement tools, and discuss how they can be applied in the context of measuring model bias. Our goal is to provide
    
[^95]: 利用生命周期自适应处理学习自适应系统中适应空间的漂移

    Dealing with Drift of Adaptation Spaces in Learning-based Self-Adaptive Systems using Lifelong Self-Adaptation. (arXiv:2211.02658v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.02658](http://arxiv.org/abs/2211.02658)

    机器学习在自适应系统中成为热门方法，但利用机器学习会面临适应空间中的漂移问题。本文提出了一种名为"生命周期自适应"的新方法，能够更好地处理适应空间的漂移。

    

    最近，机器学习 (ML) 已成为支持自适应的热门方法。ML 已被用来处理自适应中的几个问题，例如在不确定性下维护最新的运行时模型和可扩展的决策制定。然而，利用 ML 存在固有的挑战。在本文中，我们着重讨论面向基于学习的自适应系统的一个特别重要的挑战：适应空间中的漂移。通过适应空间，我们指的是自适应系统在某一特定时间可以选择的适应选项的集合，以根据适应选项的质量属性进行适应。适应空间的漂移源于影响适应选项质量属性的不确定性。这种漂移可能意味着最终没有适应选项能够满足最初的适应目标，从而降低系统的质量，或者可能出现允许增强适应目标的适应选项。在 ML 中，这种漂移通常被称为概念漂移或实例漂移。为了解决这个挑战，我们提出了一种名为“生命周期自适应”的新方法。生命周期自适应对 ML powered self-adaptation 进行了扩展，使其能够更好地处理适应空间的漂移。

    Recently, machine learning (ML) has become a popular approach to support self-adaptation. ML has been used to deal with several problems in self-adaptation, such as maintaining an up-to-date runtime model under uncertainty and scalable decision-making. Yet, exploiting ML comes with inherent challenges. In this paper, we focus on a particularly important challenge for learning-based self-adaptive systems: drift in adaptation spaces. With adaptation space we refer to the set of adaptation options a self-adaptive system can select from at a given time to adapt based on the estimated quality properties of the adaptation options. Drift of adaptation spaces originates from uncertainties, affecting the quality properties of the adaptation options. Such drift may imply that eventually no adaptation option can satisfy the initial set of the adaptation goals, deteriorating the quality of the system, or adaptation options may emerge that allow enhancing the adaptation goals. In ML, such shift cor
    
[^96]: 在线LiDAR-相机外参自检

    Online LiDAR-Camera Extrinsic Parameters Self-checking. (arXiv:2210.10537v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.10537](http://arxiv.org/abs/2210.10537)

    本文提出了一种在线LiDAR-相机外参自检算法，解决了当前标定研究忽视标定结果正确性的问题。

    

    随着神经网络的发展和自动驾驶的普及，LiDAR和相机的标定越来越受到关注。这个标定任务是多模态的，相机捕捉到的丰富的颜色和纹理信息以及LiDAR获取到的精确的三维空间信息对于下游任务非常重要。目前的研究主要集中在通过信息融合获得准确的标定结果。然而，他们很少分析标定结果是否正确，这在实际应用中非常重要。例如，在大规模生产中，每辆智能车的LiDAR和相机在离开生产线时必须获得良好的校准，而在车辆使用期间，LiDAR和相机的位姿也应该持续受到监督以确保安全。为此，本文提出了一种自检算法。

    With the development of neural networks and the increasing popularity of automatic driving, the calibration of the LiDAR and the camera has attracted more and more attention. This calibration task is multi-modal, where the rich color and texture information captured by the camera and the accurate three-dimensional spatial information from the LiDAR is incredibly significant for downstream tasks. Current research interests mainly focus on obtaining accurate calibration results through information fusion. However, they seldom analyze whether the calibrated results are correct or not, which could be of significant importance in real-world applications. For example, in large-scale production, the LiDARs and the cameras of each smart car have to get well-calibrated as the car leaves the production line, while in the rest of the car life period, the poses of the LiDARs and cameras should also get continually supervised to ensure the security. To this end, this paper proposes a self-checking 
    
[^97]: NormSAGE: 多语言多文化对话中的规范发现

    NormSAGE: Multi-Lingual Multi-Cultural Norm Discovery from Conversations On-the-Fly. (arXiv:2210.08604v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.08604](http://arxiv.org/abs/2210.08604)

    NormSAGE是一个用于对话驱动的多语言多文化规范发现的框架，利用预训练的GPT-3语言模型进行知识引发，并通过自验证机制确保发现的规范正确且与源对话相关。

    

    规范发现对于理解和推理人类交流和互动中可接受的行为和潜在违规行为非常重要。我们介绍了NormSage，一个用于解决新颖任务的框架，即基于语言模型提示和自验证的对话驱动的多语言多文化规范发现。NormSAGE利用预训练的GPT-3语言模型架构的表达能力和隐式知识，通过针对规范发现任务和对话背景的有向问题引发关于规范的知识。它还通过自验证机制解决语言模型虚构的风险，确保发现的规范是正确的，并且在很大程度上与它们的源对话相关。评估结果显示，与基准相比，我们的方法能够在实时对话中发现更多相关且有洞察力的规范（Likert评分中增加了10%以上）。

    Norm discovery is important for understanding and reasoning about the acceptable behaviors and potential violations in human communication and interactions. We introduce NormSage, a framework for addressing the novel task of conversation-grounded multi-lingual, multi-cultural norm discovery, based on language model prompting and self-verification. NormSAGE leverages the expressiveness and implicit knowledge of the pretrained GPT-3 language model backbone, to elicit knowledge about norms through directed questions representing the norm discovery task and conversation context. It further addresses the risk of language model hallucination with a self-verification mechanism ensuring that the norms discovered are correct and are substantially grounded to their source conversations. Evaluation results show that our approach discovers significantly more relevant and insightful norms for conversations on-the-fly compared to baselines (>10+% in Likert scale rating). The norms discovered from Ch
    
[^98]: 无人机导航和避障的实时动态障碍物跟踪和建图系统（arXiv:2209.08258v3 [cs.RO] UPDATED）

    A real-time dynamic obstacle tracking and mapping system for UAV navigation and collision avoidance with an RGB-D camera. (arXiv:2209.08258v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2209.08258](http://arxiv.org/abs/2209.08258)

    这项研究提出了一种使用RGB-D相机的实时动态障碍物跟踪和建图系统，实现无人机的导航和避障。系统使用深度图像生成动态障碍物区域，并利用卡尔曼滤波器和连续性滤波器跟踪障碍物。

    

    在拥挤的空间中，实时动态环境感知对于自主机器人变得至关重要。虽然流行的基于体素的建图方法可以高效地表示具有任意复杂形状的3D障碍物，但它们很难区分静态和动态障碍物，导致避障性能有限。虽然自主驾驶中存在许多复杂的基于学习的动态障碍物检测算法，但四旋翼飞行器的有限计算资源无法使用这些方法实现实时性能。为了解决这些问题，我们提出了一种使用RGB-D相机的四旋翼飞行器避障的实时动态障碍物跟踪和建图系统。所提出的系统首先利用带有占据体素地图的深度图像生成潜在的动态障碍物区域作为候选。然后，利用卡尔曼滤波器和我们的连续性滤波器来跟踪每个动态障碍物。最后，使用环境模型和路径规划算法提供导航和避障指导。

    The real-time dynamic environment perception has become vital for autonomous robots in crowded spaces. Although the popular voxel-based mapping methods can efficiently represent 3D obstacles with arbitrarily complex shapes, they can hardly distinguish between static and dynamic obstacles, leading to the limited performance of obstacle avoidance. While plenty of sophisticated learning-based dynamic obstacle detection algorithms exist in autonomous driving, the quadcopter's limited computation resources cannot achieve real-time performance using those approaches. To address these issues, we propose a real-time dynamic obstacle tracking and mapping system for quadcopter obstacle avoidance using an RGB-D camera. The proposed system first utilizes a depth image with an occupancy voxel map to generate potential dynamic obstacle regions as proposals. With the obstacle region proposals, the Kalman filter and our continuity filter are applied to track each dynamic obstacle. Finally, the environ
    
[^99]: 基于梯度的B样条轨迹优化的视觉辅助无人机导航和动态避障

    Vision-aided UAV navigation and dynamic obstacle avoidance using gradient-based B-spline trajectory optimization. (arXiv:2209.07003v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2209.07003](http://arxiv.org/abs/2209.07003)

    本文提出了一种基于梯度的B样条轨迹优化算法，利用机器人的内置视觉，实现了无人机在动态环境中的导航和动态避障的能力。

    

    在动态环境中进行导航需要机器人生成无碰撞轨迹并主动避开移动障碍物。大多数先前的研究都设计了基于单一地图表示的路径规划算法，如几何地图、占用地图或ESDF地图。尽管它们在静态环境中表现出成功，但由于地图表示的限制，这些方法不能可靠地同时处理静态和动态障碍物。为解决这个问题，本文提出了一种基于梯度的B样条轨迹优化算法，利用机器人的内置视觉。深度视觉使机器人能够基于体素地图对动态物体进行几何跟踪和表示。提出的优化首先采用基于圆的导向点算法来近似避开静态障碍物的代价和梯度。然后，利用视觉检测到的移动物体，我们同时使用回退视野距离场来防止动态碰撞。最后，

    Navigating dynamic environments requires the robot to generate collision-free trajectories and actively avoid moving obstacles. Most previous works designed path planning algorithms based on one single map representation, such as the geometric, occupancy, or ESDF map. Although they have shown success in static environments, due to the limitation of map representation, those methods cannot reliably handle static and dynamic obstacles simultaneously. To address the problem, this paper proposes a gradient-based B-spline trajectory optimization algorithm utilizing the robot's onboard vision. The depth vision enables the robot to track and represent dynamic objects geometrically based on the voxel map. The proposed optimization first adopts the circle-based guide-point algorithm to approximate the costs and gradients for avoiding static obstacles. Then, with the vision-detected moving objects, our receding-horizon distance field is simultaneously used to prevent dynamic collisions. Finally,
    
[^100]: 使用对象检测方法而非区域分割在Kraken引擎中进行布局分析

    You Actually Look Twice At it (YALTAi): using an object detection approach instead of region segmentation within the Kraken engine. (arXiv:2207.11230v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2207.11230](http://arxiv.org/abs/2207.11230)

    本研究使用对象检测方法替代了区域分割，提出了一种高效的布局分析方法。通过与Kraken和YOLOv5对比，我们发现使用YOLOv5在小数据集上的分割效果显著优于Kraken。研究还发布了两个历史文档数据集和一个新的p...

    

    布局分析是光学字符识别等任务中线分割的第一步，它是识别区域和进行分类的过程。从边缘文本或标题中识别正文是提取数字化书籍全文和产生噪音输出之间的区别。我们发现，大多数分割器都专注于像素分类，而且尽管在2010年代初期是重点研究领域，但将此输出的多边形化作为历史文档最新竞赛（ICDAR 2017及以后）的目标尚未得到广泛应用。为了在效率上改进，我们提出将任务从基于像素分类的多边形化转变为使用等宽矩形的对象检测。通过对比Kraken和YOLOv5在分割方面的输出，我们发现后者在小数据集（1110个样本及以下）上表现优异。我们发布了两个历史文档培训和评估数据集，以及一个新的p...

    Layout Analysis (the identification of zones and their classification) is the first step along line segmentation in Optical Character Recognition and similar tasks. The ability of identifying main body of text from marginal text or running titles makes the difference between extracting the work full text of a digitized book and noisy outputs. We show that most segmenters focus on pixel classification and that polygonization of this output has not been used as a target for the latest competition on historical document (ICDAR 2017 and onwards), despite being the focus in the early 2010s. We propose to shift, for efficiency, the task from a pixel classification-based polygonization to an object detection using isothetic rectangles. We compare the output of Kraken and YOLOv5 in terms of segmentation and show that the later severely outperforms the first on small datasets (1110 samples and below). We release two datasets for training and evaluation on historical documents as well as a new p
    
[^101]: 公正游戏：对强化学习的挑战

    Impartial Games: A Challenge for Reinforcement Learning. (arXiv:2205.12787v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.12787](http://arxiv.org/abs/2205.12787)

    AlphaZero-style reinforcement learning algorithms excel in various board games but face challenges with impartial games. The researchers present a concrete example of the game nim, and show that AlphaZero-style algorithms have difficulty learning these impartial games on larger board sizes. The difference between impartial games and partisan games can be explained by the vulnerability to adversarial attacks and perturbations.

    

    类似AlphaZero的强化学习算法在各种棋盘游戏中表现出色，但在公正游戏中却面临挑战，这些游戏中玩家共享棋子。我们提供了一个具体的游戏例子，即小孩们玩的尼姆游戏，以及其他一些公正游戏，这些游戏似乎成为AlphaZero和类似的强化学习算法的绊脚石。我们的发现与最近的研究一致，表明AlphaZero-style算法容易受到敌对攻击和敌对扰动的影响，显示了在所有合法状态下学习掌握这些游戏的困难。我们发现尼姆游戏在小型棋盘上可以学习，但当棋盘尺寸增大时，AlphaZero-style算法的学习速度显著减慢。直观上，尼姆等公正游戏与象棋和围棋等党派游戏之间的区别在于，如果系统中添加了微小的噪音（例如，棋盘的一小部分被覆盖），对于公正游戏来说，这是一种典型的情况。

    AlphaZero-style reinforcement learning (RL) algorithms excel in various board games but face challenges with impartial games, where players share pieces. We present a concrete example of a game - namely the children's game of nim - and other impartial games that seem to be a stumbling block for AlphaZero-style and similar reinforcement learning algorithms.  Our findings are consistent with recent studies showing that AlphaZero-style algorithms are vulnerable to adversarial attacks and adversarial perturbations, showing the difficulty of learning to master the games in all legal states.  We show that nim can be learned on small boards, but AlphaZero-style algorithms learning dramatically slows down when the board size increases. Intuitively, the difference between impartial games like nim and partisan games like Chess and Go can be explained by the fact that if a tiny amount of noise is added to the system (e.g. if a small part of the board is covered), for impartial games, it is typica
    
[^102]: TeleGraph: 用于层次链接预测的基准数据集

    TeleGraph: A Benchmark Dataset for Hierarchical Link Prediction. (arXiv:2204.07703v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2204.07703](http://arxiv.org/abs/2204.07703)

    本研究提出了一个新的基准数据集TeleGraph，用于评估和促进链接推断技术。研究结果表明，在近乎树状的网络上，现有的链接预测算法大多数无法产生满意的性能，这对实践中的链接预测算法设计和部署提出了特殊要求。

    

    链接预测是网络结构化数据中的一个关键问题，由于其各种应用而吸引了大量的研究工作。目前的链接预测方法针对一般网络，并且过度依赖于网络的封闭三角形结构或节点属性。它们在稀疏或高度分层的网络上的性能尚未得到很好地研究。另一方面，现有的类似树状的基准数据集要么是模拟的，节点信息有限，要么规模较小。为了弥补这一差距，我们提出了一个新的基准数据集TeleGraph，这是一个高度稀疏且层次结构的电信网络，关联着丰富的节点属性，用于评估和促进链接推断技术。我们的实证结果表明，大多数算法在近乎树状的数据集上无法产生令人满意的性能，在实践中设计或部署链接预测算法时需要特别注意。

    Link prediction is a key problem for network-structured data, attracting considerable research efforts owing to its diverse applications. The current link prediction methods focus on general networks and are overly dependent on either the closed triangular structure of networks or node attributes. Their performance on sparse or highly hierarchical networks has not been well studied. On the other hand, the available tree-like benchmark datasets are either simulated, with limited node information, or small in scale. To bridge this gap, we present a new benchmark dataset TeleGraph, a highly sparse and hierarchical telecommunication network associated with rich node attributes, for assessing and fostering the link inference techniques. Our empirical results suggest that most of the algorithms fail to produce a satisfactory performance on a nearly tree-like dataset, which calls for special attention when designing or deploying the link prediction algorithm in practice.
    
[^103]: 跨转录本、音频和视频的政治演讲Deepfakes的人类检测

    Human Detection of Political Speech Deepfakes across Transcripts, Audio, and Video. (arXiv:2202.12883v3 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2202.12883](http://arxiv.org/abs/2202.12883)

    这项研究通过实验发现，人们在判断政治演讲的真实性时，音频和视觉信息对于准确区分真实和伪造的Deepfakes更为重要，而错误信息的基准影响较小。

    

    最近技术的飞速进步使得超逼真的视觉效果引发了人们对深度伪造的政治演讲视频是否很快就会与真实录像无法区分的担忧。传播理论中的常识预测，当同一个故事以视频形式和文本形式展示时，人们更容易上当受骗。我们进行了4个预先登记的随机实验，涉及2015名参与者，以评估人类在不同的错误信息基准、音频来源和媒体形式下，是否能够准确区分真实的政治演讲和伪造的演讲。我们发现错误信息的基准对辨别判断影响较小，使用最先进的文本转语音算法生成的带有音频的Deepfakes较使用声音演员音频的相同Deepfakes更难辨别。此外，我们发现音频和视觉信息比仅有文本能够更准确地进行辨别：人类的辨别更依赖于事物是如何被表达的，音频-视觉

    Recent advances in technology for hyper-realistic visual effects provoke the concern that deepfake videos of political speeches will soon be visually indistinguishable from authentic video recordings. The conventional wisdom in communication theory predicts people will fall for fake news more often when the same version of a story is presented as a video versus text. We conduct 4 pre-registered randomized experiments with 2,015 participants to evaluate how accurately humans distinguish real political speeches from fabrications across base rates of misinformation, audio sources, and media modalities. We find base rates of misinformation minimally influence discernment and deepfakes with audio produced by the state-of-the-art text-to-speech algorithms are harder to discern than the same deepfakes with voice actor audio. Moreover, we find audio and visual information enables more accurate discernment than text alone: human discernment relies more on how something is said, the audio-visual
    
[^104]: 在稀疏突发神经突触下的领域转移中的持续学习

    Continual learning under domain transfer with sparse synaptic bursting. (arXiv:2108.12056v9 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2108.12056](http://arxiv.org/abs/2108.12056)

    本文介绍了一个系统，通过稀疏突发神经突触，在领域转移中能够在先前未见的数据集上进行持续学习，减少遗忘。

    

    现有的机器是功能特定的工具，易于预测和控制。明天的机器可能更接近生物系统，具有可变性、韧性和自主性。但是首先，它们必须能够学习和保留新信息，而不必随机接触它。过去设计这样的系统的努力是通过构建或调节人工神经网络，使用唯一敏感于特定任务或输入的不相交的权重集合。然而，这尚未实现在长时间的先前未见数据序列上进行持续学习而不破坏现有知识的问题，这被称为灾难性遗忘。在本文中，我们介绍了一个系统，可以在先前未见的数据集（ImageNet，CIFAR-100）上以较小的遗忘逐步学习。这是通过基于输入控制卷积神经网络中权重的活动，使用由第二个前馈生成的自上而下调节来实现的。

    Existing machines are functionally specific tools that were made for easy prediction and control. Tomorrow's machines may be closer to biological systems in their mutability, resilience, and autonomy. But first they must be capable of learning and retaining new information without being exposed to it arbitrarily often. Past efforts to engineer such systems have sought to build or regulate artificial neural networks using disjoint sets of weights that are uniquely sensitive to specific tasks or inputs. This has not yet enabled continual learning over long sequences of previously unseen data without corrupting existing knowledge: a problem known as catastrophic forgetting. In this paper, we introduce a system that can learn sequentially over previously unseen datasets (ImageNet, CIFAR-100) with little forgetting over time. This is done by controlling the activity of weights in a convolutional neural network on the basis of inputs using top-down regulation generated by a second feed-forwa
    
[^105]: 在数据流上进行连续查询的假设答案探讨

    Hypothetical answers to continuous queries over data streams. (arXiv:1905.09610v3 [cs.PL] UPDATED)

    [http://arxiv.org/abs/1905.09610](http://arxiv.org/abs/1905.09610)

    本文探讨了在数据流上进行连续查询时可能出现的阻塞操作和延迟答案的问题，并提出了一种能够提供假设答案的语义和相应答案的在线算法。

    

    在数据流上进行连续查询可能遇到阻塞操作和/或无限等待的问题，这可能会延迟答案直到相关输入通过数据流到达。这些延迟可能导致答案在到达时对于有时不得不不依赖任何帮助做出决策的用户来说已经过时。因此，提供假设答案-“根据当前信息，在时间t时，X可能会变为真”而不是没有任何信息可能是有用的。在本文中，我们提出了一种涵盖了这种假设答案的查询和相应答案的语义，以及一种在线算法，用于更新与当前可用信息一致的事实集合。

    Continuous queries over data streams may suffer from blocking operations and/or unbound wait, which may delay answers until some relevant input arrives through the data stream. These delays may turn answers, when they arrive, obsolete to users who sometimes have to make decisions with no help whatsoever. Therefore, it can be useful to provide hypothetical answers - "given the current information, it is possible that X will become true at time t" instead of no information at all.  In this paper we present a semantics for queries and corresponding answers that covers such hypothetical answers, together with an online algorithm for updating the set of facts that are consistent with the currently available information.
    
[^106]: PVNet: 基于数值天气预报的时空光伏发电功率预测的 LRCN 架构

    PVNet: A LRCN Architecture for Spatio-Temporal Photovoltaic PowerForecasting from Numerical Weather Prediction. (arXiv:1902.01453v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1902.01453](http://arxiv.org/abs/1902.01453)

    PVNet是一种利用数值天气预报数据的LRCN架构，用于预测24小时和48小时的光伏发电功率。该模型充分利用了时间和空间天气数据，通过与其他模型的比较，展现了较好的性能。

    

    光伏发电是一种重要的可再生能源之一，然而其产量受天气条件（如太阳辐射和温度）的影响而具有高度的不确定性。即使是在24小时预测中，光伏发电的预测仍然是一个挑战，导致能源供应商需要启动（往往还会排放碳）的发电厂。在本文中，我们介绍了一种利用数值天气预报（NWP）的长期循环卷积网络，用于预测24小时和48小时的光伏发电预测。该网络架构充分利用了整个感兴趣地区上采样的时间和空间天气数据。我们使用美国国家海洋和大气管理局（NOAA）的NWP数据集对模型进行训练，以预测德国的空间聚合光伏发电量，并将其性能与持续模型和最先进的方法进行了比较。

    Photovoltaic (PV) power generation has emerged as one of the lead renewable energy sources. Yet, its production is characterized by high uncertainty, being dependent on weather conditions like solar irradiance and temperature. Predicting PV production, even in the 24-hour forecast, remains a challenge and leads energy providers to left idling - often carbon emitting - plants. In this paper, we introduce a Long-Term Recurrent Convolutional Network using Numerical Weather Predictions (NWP) to predict, in turn, PV production in the 24-hour and 48-hour forecast horizons. This network architecture fully leverages both temporal and spatial weather data, sampled over the whole geographical area of interest. We train our model on an NWP dataset from the National Oceanic and Atmospheric Administration (NOAA) to predict spatially aggregated PV production in Germany. We compare its performance to the persistence model and state-of-the-art methods.
    

