# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [HyperDreamBooth: HyperNetworks for Fast Personalization of Text-to-Image Models.](http://arxiv.org/abs/2307.06949) | HyperDreamBooth是一个超网络，可以从一个人的单张图片中快速生成个性化权重，从而实现在多种背景和风格下合成一个人的面部，保持高保真度并同时保留对多样化风格和语义修改的关键知识。 |
| [^2] | [Video-FocalNets: Spatio-Temporal Focal Modulation for Video Action Recognition.](http://arxiv.org/abs/2307.06947) | 本论文提出了一种名为视频焦点网络的视频识别架构，通过时空焦点调制来模拟局部和全局上下文，结合了Transformer和卷积设计的优点，既有效又高效。 |
| [^3] | [In-context Autoencoder for Context Compression in a Large Language Model.](http://arxiv.org/abs/2307.06945) | 在大型语言模型中，我们提出了一种称为In-context Autoencoder (ICAE)的上下文自编码器，它通过将长上下文压缩为有限数量的内存槽，实现了$4\times$的上下文压缩，并能够根据内存槽进行条件处理以响应各种提示。 |
| [^4] | [On the Connection between Game-Theoretic Feature Attributions and Counterfactual Explanations.](http://arxiv.org/abs/2307.06941) | 本研究通过建立理论联系，将博弈论特征归因和反事实解释相结合。通过变换和证明，在一定条件下它们是等价的。研究结果还指出了仅仅使用反事实解释来提供特征重要性的局限性。 |
| [^5] | [FDAPT: Federated Domain-adaptive Pre-training for Language Models.](http://arxiv.org/abs/2307.06933) | FDAPT是一种联邦领域自适应预训练的方法，在保护数据隐私的同时，能够通过利用敏感和分布式数据来增强模型适应能力。对于IID和非IID情况下的下游任务，FDAPT能够维持与中央基线相竞争的性能。提出的FFDAPT算法进一步提高了计算效率，并展现出与标准FDAPT类似的下游任务性能。此外，我们也确定了这个新研究领域的有希望的未来研究方向。 |
| [^6] | [DRAGON: A Dialogue-Based Robot for Assistive Navigation with Visual Language Grounding.](http://arxiv.org/abs/2307.06924) | DRAGON是一种基于对话的导航机器人，能够理解用户的指令并通过语言与用户沟通，为视力受损者提供导航和环境描述的帮助。 |
| [^7] | [LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT.](http://arxiv.org/abs/2307.06917) | 本文介绍了基于LLM辅助的知识图谱工程实验，展示了ChatGPT在开发和管理知识图谱方面的潜力。 |
| [^8] | [Uncovering Unique Concept Vectors through Latent Space Decomposition.](http://arxiv.org/abs/2307.06913) | 通过潜在空间分解和无监督聚类，我们提出了一种自动揭示深度学习模型学习到的概念向量的方法，这些概念向量与模型预测相关且具有语义的独特概念，并且在实验中表明这些概念对人类来说易于理解和与任务相关。 |
| [^9] | [Generating Benchmarks for Factuality Evaluation of Language Models.](http://arxiv.org/abs/2307.06908) | 该论文提出了一个名为FACTOR的方法，用于生成用于语言模型事实性评估的基准数据集。通过自动转换事实语料库，评估语言模型根据语料库生成真实事实的倾向与生成不正确陈述的能力。实验结果表明，该基准数据集的分数随模型大小增加而增加，在LM与检索方法结合时性能得到改善。困惑度和基准数据集分数之间存在相关性，但不总是一致。 |
| [^10] | [The complexity of non-stationary reinforcement learning.](http://arxiv.org/abs/2307.06877) | 强化学习中的非平稳学习是一个重要挑战，我们证明了在修改概率或奖励时需要花费大量的时间来保持值函数的最新状态，并且这个挑战与状态数目密切相关。 |
| [^11] | [Embodied Lifelong Learning for Task and Motion Planning.](http://arxiv.org/abs/2307.06870) | 这篇论文研究了在家中长期部署的机器人所面临的具身化终身学习问题，在任务和运动规划的背景下采用了新颖的问题建模方法。利用TAMP系统的模块化特性，提出了一个生成混合模型来产生规划器的候选参数。通过学习共享和非共享的模型，并根据代理任务来在线选择使用的模型，该方法在模拟的2D领域和BEHAVIOR基准测试中取得了显著的规划成功改进。 |
| [^12] | [DecompEval: Evaluating Generated Texts as Unsupervised Decomposed Question Answering.](http://arxiv.org/abs/2307.06869) | DecompEval提出了一种简单而有效的指标来评估自然语言生成任务，它将评估建模为一种类似指令的问答任务，并利用预训练语言模型进行衡量，以增强泛化能力和可解释性。 |
| [^13] | [Prompts Should not be Seen as Secrets: Systematically Measuring Prompt Extraction Attack Success.](http://arxiv.org/abs/2307.06865) | 本论文提出了一个系统地衡量提示提取攻击成功的框架，并通过多个实验发现，即使提示被保密，简单的基于文本的攻击仍然可以高概率地揭示提示。 |
| [^14] | [Unconventional Cognitive Intelligent Robotic Control: Quantum Soft Computing Approach in Human Being Emotion Estimation -- QCOptKB Toolkit Application.](http://arxiv.org/abs/2307.06858) | 该论文提出了一种基于量子和软计算的智能认知控制系统的策略，通过提取量子自组织知识库，改善了在危险控制情况下系统的鲁棒性，并展示了量子模糊推理门设计在嵌入式控制系统中的应用。 |
| [^15] | [Self-consistency for open-ended generations.](http://arxiv.org/abs/2307.06857) | 本论文提出了一种改进大规模预训练语言模型生成输出质量和一致性的新方法，通过扩展自洽性框架的适用性，实现了从一个候选集中恢复最优或接近最优的生成结果，并提出了一种轻量级无参数相似性函数来改进代码生成、自动形式化和摘要任务的效果。 |
| [^16] | [Self-Supervised Learning for Interactive Perception of Surgical Thread for Autonomous Suture Tail-Shortening.](http://arxiv.org/abs/2307.06845) | 本文提出了一种自主学习的方法，用于自动感知手术线，在三维环境中跟踪线的路径，并应用于自主进行手术缝合 "尾部缩短" 任务。该方法通过二维线检测和三维线重建实现了对线的准确感知和跟踪，具有鲁棒性。 |
| [^17] | [Garbage in, garbage out: Zero-shot detection of crime using Large Language Models.](http://arxiv.org/abs/2307.06844) | 本文利用大型语言模型学习的常识知识，通过将视频转换为文本描述，实现了零样本推理的犯罪检测。现有的视频转文本方法质量不足以支持推理。 |
| [^18] | [A Causal Framework to Unify Common Domain Generalization Approaches.](http://arxiv.org/abs/2307.06825) | 本文提出了一个因果框架用于统一常见领域泛化方法的理解，通过回答关键思想、理论基础和方法关系等问题，帮助研究者更好地理解和发展领域泛化方法。 |
| [^19] | [CLAIMED -- the open source framework for building coarse-grained operators for accelerated discovery in science.](http://arxiv.org/abs/2307.06824) | CLAIMED是一个开放源代码框架，用于在现代数据驱动的科学中构建可重用的运算符和可扩展的科学工作流程，从而解决了重复性和可重用性问题。 |
| [^20] | [TinyMetaFed: Efficient Federated Meta-Learning for TinyML.](http://arxiv.org/abs/2307.06822) | TinyMetaFed是一个适用于TinyML的高效联邦元学习框架，通过协同训练神经网络初始化，在小型设备上能够快速微调，同时实现通信节省和隐私保护。 |
| [^21] | [Negated Complementary Commonsense using Large Language Models.](http://arxiv.org/abs/2307.06794) | 本论文研究了使用大规模语言模型解决否定式互补问题的性能。作者发现，这种类型的问题会对模型的响应产生负面影响，并提出了一种模型无关的方法来改善性能。实验证明，该方法在少样本生成方面优于GPT-3，并强调了研究大规模语言模型在否定式互补问题中的重要性。 |
| [^22] | [A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media.](http://arxiv.org/abs/2307.06775) | 本研究创建了一个多模态深度学习模型，将文本和视觉数据相结合，能够准确识别社交媒体上的促进饮食紊乱的内容。最有效的模型是RoBERTa自然语言处理模型和MaxViT图像分类模型的融合模型，准确率和F1分数分别达到95.9%和0.959。 |
| [^23] | [Layered controller synthesis for dynamic multi-agent systems.](http://arxiv.org/abs/2307.06758) | 该论文提出了一种分层控制合成技术，用于解决动态多智能体系统的控制问题。通过分为三个阶段并使用强化学习训练神经网络控制策略，该方法可以实现更动态准确的解决方案。 |
| [^24] | [Vehicle Dispatching and Routing of On-Demand Intercity Ride-Pooling Services: A Multi-Agent Hierarchical Reinforcement Learning Approach.](http://arxiv.org/abs/2307.06742) | 本研究提出了一个基于多代理层次强化学习的框架，用于即时城际拼车服务的车辆调度和路径规划。数值研究证明该框架有效缓解了供给不足问题。 |
| [^25] | [MPR-Net:Multi-Scale Pattern Reproduction Guided Universality Time Series Interpretable Forecasting.](http://arxiv.org/abs/2307.06736) | 本文提出了一种名为MPR-Net的预测模型，通过自适应地分解多尺度历史序列模式，并基于模式重现的先验知识构建模式扩展预测方法，最后使用反卷积运算将未来模式重建为未来序列。MPR-Net能够有效地捕捉时间序列中的重要模式并实现可解释的预测。 |
| [^26] | [GRAN is superior to GraphRNN: node orderings, kernel- and graph embeddings-based metrics for graph generators.](http://arxiv.org/abs/2307.06709) | 本论文通过比较基于节点排序、核函数和图嵌入的度量，展示了GRAN优于GraphRNN的优势，并为小型图提供了有效的GraphRNN改进方法。此外，论文还提供了关于数据集选择和节点特征初始化的最佳实践指南。 |
| [^27] | [S-HR-VQVAE: Sequential Hierarchical Residual Learning Vector Quantized Variational Autoencoder for Video Prediction.](http://arxiv.org/abs/2307.06701) | S-HR-VQVAE是一种序列分层残差学习向量量化变分自编码器，通过结合分层残差向量量化变分自编码器（HR-VQVAE）和时空PixelCNN（ST-PixelCNN）的能力，解决了视频预测中的主要挑战，并在KTH人体动作和Moving-MNIST任务上取得了较好的实验结果。 |
| [^28] | [IntelliGraphs: Datasets for Benchmarking Knowledge Graph Generation.](http://arxiv.org/abs/2307.06698) | IntelliGraphs是一组新的知识图谱数据集，用于评估知识图谱生成。其中包含具有逻辑规则表达的语义的子图，用于评估子图推断的模型。 |
| [^29] | [Towards Ubiquitous Semantic Metaverse: Challenges, Approaches, and Opportunities.](http://arxiv.org/abs/2307.06687) | 走向普遍的语义元宇宙：通过人工智能、时空数据表示、语义物联网和语义增强数字孪生实现的智能、上下文感知的交互技术，在远程教育、工作与协作、娱乐与社交、医疗保健和电子商务营销等领域具有重要应用价值。 |
| [^30] | [Explainable Artificial Intelligence driven mask design for self-supervised seismic denoising.](http://arxiv.org/abs/2307.06682) | 本研究提出了使用可解释的人工智能方法进行自监督地震去噪，通过观察去噪网络中的黑盒子，替代对噪声统计的先验知识需求，并通过简单平均化输入像素的雅可比贡献，提供抑制地震数据中噪声的最有效蒙版。 |
| [^31] | [DeepIPCv2: LiDAR-powered Robust Environmental Perception and Navigational Control for Autonomous Vehicle.](http://arxiv.org/abs/2307.06647) | DeepIPCv2是一种利用LiDAR传感器感知环境的自动驾驶模型，通过使用点云作为感知输入，在各种条件下实现了更强大的驾驶性能。 |
| [^32] | [Image Transformation Sequence Retrieval with General Reinforcement Learning.](http://arxiv.org/abs/2307.06630) | 本文提出了一种使用通用强化学习的图像转换序列检索（ITSR）任务，并结合深度神经网络。通过在合成和真实领域进行实验，结果显示使用蒙特卡洛树搜索训练的模型在最简单和最复杂的情况下都能胜过监督训练的模型。 |
| [^33] | [SecureFalcon: The Next Cyber Reasoning System for Cyber Security.](http://arxiv.org/abs/2307.06616) | SecureFalcon是基于FalconLLM的网络推理系统，通过微调FalconLLM来实现网络安全应用，能够识别C代码样本中的漏洞和非漏洞内容。 |
| [^34] | [Introducing Foundation Models as Surrogate Models: Advancing Towards More Practical Adversarial Attacks.](http://arxiv.org/abs/2307.06608) | 本文将对抗攻击重新设定为下游任务，通过生成图像噪声来满足新兴趋势，并将基础模型引入作为代理模型。虽然基础模型的表现不佳，但通过在特征空间中进行分析，我们发现缺乏对应的特征。 |
| [^35] | [RVD: A Handheld Device-Based Fundus Video Dataset for Retinal Vessel Segmentation.](http://arxiv.org/abs/2307.06577) | 本研究介绍了首个基于便携设备进行数据获取的基于视频的视网膜数据集，该数据集包含635个由智能手机采集的眼底视频，并提供了在空间和时间维度上对视网膜结构进行全面和精确标注的数据，旨在推进血管分割的发展。 |
| [^36] | [Prescriptive Process Monitoring Under Resource Constraints: A Reinforcement Learning Approach.](http://arxiv.org/abs/2307.06564) | 本论文提出了一种在资源限制下进行处方过程监控的强化学习方法。通过考虑对干预需求、及时性或效果预测的不确定性和资源利用水平，来触发干预，从而优化业务过程的性能。 |
| [^37] | [On the Effective Horizon of Inverse Reinforcement Learning.](http://arxiv.org/abs/2307.06541) | 本研究分析了逆强化学习中时间视野的重要性，发现短于实际值的有效时间视野可以更快且更准确地估计奖励函数，减轻过拟合问题。此外，研究还呼吁在IRL中同时学习奖励和有效时间视野。 |
| [^38] | [Artificial Intelligence for Drug Discovery: Are We There Yet?.](http://arxiv.org/abs/2307.06521) | 本综述讨论了人工智能在药物发现中的应用，重点关注小分子药物。通过使用生成化学、机器学习和多属性优化等人工智能技术，已有多种化合物进入了临床试验。科学界必须仔细审查已知信息，以解决可重复性危机。只有具有足够的真实基准和适当的训练数据，才能实现人工智能在药物发现中的全部潜力。 |
| [^39] | [Leveraging Contextual Counterfactuals Toward Belief Calibration.](http://arxiv.org/abs/2307.06513) | 本文讨论了通过引入上下文反事实推理来准确校准AI系统中的信念的问题。研究发现，在高后悔情况下，上下文反事实和补救成本对于更新决策者的信念以及所持信念的强度至关重要。通过将信念的多样性分成两类:主观性和认识不确定性，可以更好地理解和处理信念的校准问题。 |
| [^40] | [Improving Nonalcoholic Fatty Liver Disease Classification Performance With Latent Diffusion Models.](http://arxiv.org/abs/2307.06507) | 本研究通过结合使用扩散模型生成的合成图像和真实图像，提高了非酒精性脂肪性肝病分类的性能。 |
| [^41] | [Hybrid Control Policy for Artificial Pancreas via Ensemble Deep Reinforcement Learning.](http://arxiv.org/abs/2307.06501) | 本研究提出了一种名为HyCPAP的混合控制策略，通过结合模型预测控制和集成深度强化学习，并充分利用它们各自的优势，以解决人工胰腺的复杂生理过程、延迟胰岛素反应和不准确血糖测量等挑战。 |
| [^42] | [Microbial Genetic Algorithm-based Black-box Attack against Interpretable Deep Learning Systems.](http://arxiv.org/abs/2307.06496) | 这项工作提出了一种基于微生物遗传算法的黑箱攻击方法，QuScore，对抗对解释模型进行耦合的可解释深度学习系统(IDLSes)。该方法能够在不了解目标模型的情况下，通过转移和评分方法减少查询次数，实现成功的攻击。 |
| [^43] | [Misclassification in Automated Content Analysis Causes Bias in Regression. Can We Fix It? Yes We Can!.](http://arxiv.org/abs/2307.06483) | 传播学领域中的自动化内容分析常忽视了错误分类的偏差，我们介绍并测试了统计方法来纠正这种偏差，并设计了一种新方法来修复之。 |
| [^44] | [Efficiently-Verifiable Strong Uniquely Solvable Puzzles and Matrix Multiplication.](http://arxiv.org/abs/2307.06463) | 本论文在Cohn-Umans框架上提出了一种高效可验证的强唯一可解谜题（SUSP）的新子类，名为可简化的SUSPs。研究结果表明，可简化的SUSPs可以达到与无穷族SUSPs相同的矩阵乘法指数边界，并且通过计算机搜索构造了更大的SUSPs，进一步提高了矩阵乘法指数的上界。 |
| [^45] | [No Train No Gain: Revisiting Efficient Training Algorithms For Transformer-based Language Models.](http://arxiv.org/abs/2307.06440) | 本论文重新审视了基于Transformer的语言模型的高效训练算法，包括动态架构，批量选择和高效优化器。然而，在使用这些算法预训练时，相对于基线方法，它们的训练、验证和下游收益消失了。同时，论文提出了一个评估协议来进行计算，并释放了代码来促进高效训练的研究。 |
| [^46] | [Distilling Large Language Models for Biomedical Knowledge Extraction: A Case Study on Adverse Drug Events.](http://arxiv.org/abs/2307.06439) | 本研究通过将大型语言模型蒸馏为特定任务的学生模型，成功地提升了在药物不良事件提取方面的性能，并在不使用标记数据的情况下达到了与监督式最先进模型相当的准确性，具有成本、效率和白盒模型访问等优势。 |
| [^47] | [Designing Behavior Trees from Goal-Oriented LTLf Formulas.](http://arxiv.org/abs/2307.06399) | 本论文介绍了一种将使用有限访问线性时态逻辑（LTL）的子集指定的目标转化为行为树（BT）的方法，并展示了通过这种方法能够解决一些规划问题。 |
| [^48] | [Introduction to Facial Micro Expressions Analysis Using Color and Depth Images: A Matlab Coding Approach (Second Edition, 2023).](http://arxiv.org/abs/2307.06396) | 该书介绍了用颜色和深度图像进行面部微表情分析的方法，通过MATLAB编程实现。它适用于初学者到专业读者，并提供了理论描述和可重现的实例。 |
| [^49] | [Maximizing Penetration Testing Success with Effective Reconnaissance Techniques using ChatGPT.](http://arxiv.org/abs/2307.06391) | 使用ChatGPT进行侦察阶段的渗透测试，能够获取有价值的情报数据，提高有效性和效率。 |
| [^50] | [Rethinking Answer Set Programming Templates.](http://arxiv.org/abs/2307.06382) | 本文提出了一种答案集编程模板的概念，通过使用简单的命名约定，强制某些谓词的局部性，从而实现了对模板预期结果的不变性，并且避免了名称冲突。 |
| [^51] | [Assessment of the suitability of degradation models for the planning of CCTV inspections of sewer pipes.](http://arxiv.org/abs/2307.06341) | 该论文评估了降解模型在排污管道CCTV检查规划中的适用性。结果表明，虽然集成模型具有最高的准确度，但无法推测长期降解；与此相反，逻辑回归模型准确度稍低，但能够产生可解释性强且一致的降解曲线。 |
| [^52] | [Reading Radiology Imaging Like The Radiologist.](http://arxiv.org/abs/2307.05921) | 提出一种以疾病为导向的方法，解决自动放射学报告生成中的细微差异关注、数据偏差和长文本生成的挑战。 |
| [^53] | [Rad-ReStruct: A Novel VQA Benchmark and Method for Structured Radiology Reporting.](http://arxiv.org/abs/2307.05766) | 本文提出了Rad-ReStruct，一个用于评估和比较不同方法的新型基准数据集，以X光图像的结构化报告形式提供了细粒度、按层次排序的注释。我们提出了一种新方法hi-VQA，将结构化报告任务建模为分层视觉问答(VQA)，并考虑先前提问和回答的上下文来填充结构化放射学报告。实验证明hi-VQA取得了与最先进方法相竞争的性能。 |
| [^54] | [Large Language Models for Supply Chain Optimization.](http://arxiv.org/abs/2307.03875) | 这项研究研究了利用大型语言模型（LLMs）来帮助解释和解读供应链优化结果的方法。他们设计了一个框架，可以接受普通文本查询作为输入，并输出关于底层优化结果的洞察。通过定量回答假设情况，该框架在不放弃最先进的组合优化技术的情况下帮助企业运营者更好地理解和信任优化结果。 |
| [^55] | [A multilevel framework for AI governance.](http://arxiv.org/abs/2307.03198) | 本文提出了一个多层级的AI治理框架，涉及政府、企业和公民三个相互依赖的利益相关者群体。通过信任的不同维度来研究它们之间的关系，并为进一步提升用户体验和制定AI相关公共政策提供实用见解。 |
| [^56] | [A Survey on Evaluation of Large Language Models.](http://arxiv.org/abs/2307.03109) | 本文综述了大型语言模型（LLMs）的评估方法，关注三个关键维度：评估什么、在哪里评估以及如何评估。评估任务包括自然语言处理、推理、医学应用、伦理学、教育、自然和社会科学、代理应用等多个领域。本文为社会层面对LLMs潜在风险的理解提供了重要参考。 |
| [^57] | [Towards Safe Autonomous Driving Policies using a Neuro-Symbolic Deep Reinforcement Learning Approach.](http://arxiv.org/abs/2307.01316) | 本文介绍了一种名为DRL with Symbolic Logics (DRLSL)的新颖神经符号无模型深度强化学习方法，旨在实现在真实环境中安全学习自主驾驶策略。该方法结合了深度强化学习和符号逻辑驱动的推理，允许通过与物理环境的实时交互来学习自主驾驶策略并确保安全性。 |
| [^58] | [PatternGPT :A Pattern-Driven Framework for Large Language Model Text Generation.](http://arxiv.org/abs/2307.00470) | PatternGPT是一种基于模式驱动的大型语言模型文本生成框架，通过利用大型语言模型的提取能力生成多样化的模式，并使用联邦学习的思想实现模式共享，最终通过搜索高质量模式指导生成模型。该框架具有生成多样化模式、保护数据隐私、结合外部知识等优势。 |
| [^59] | [TrustGuard: GNN-based Robust and Explainable Trust Evaluation with Dynamicity Support.](http://arxiv.org/abs/2306.13339) | TrustGuard是一种基于GNN的信任评估模型，支持信任动态性，抗击鲁棒并提供解释能力，它的实验结果在准确性、鲁棒性和可解释性方面都优于其他方法。 |
| [^60] | [FishRecGAN: An End to End GAN Based Network for Fisheye Rectification and Calibration.](http://arxiv.org/abs/2305.05222) | FishRecGAN提供了一种端到端的深度学习方法，以矫正鱼眼图像并同时校准相机内参和畸变参数。其快速校正网络具有良好的分辨率和鲁棒性，适用于摄像机型监控设备中的恒定标定，并使用大量合成数据集进行训练和验证，表现出了高分辨率的鲁棒性和显著的峰值信噪比。 |
| [^61] | [FR3D: Three-dimensional Flow Reconstruction and Force Estimation for Unsteady Flows Around Extruded Bluff Bodies via Conformal Mapping Aided Convolutional Autoencoders.](http://arxiv.org/abs/2302.01802) | 本研究提出了一种名为FR3D的卷积自动编码器模型，可以通过共形映射实现对不同横截面的拉出式三维物体周围的三维流场进行重构和力估计。 |
| [^62] | [A Survey on Transformers in Reinforcement Learning.](http://arxiv.org/abs/2301.03044) | 这篇论文是一项调查研究，总结了在强化学习领域使用Transformers的动机、进展和未来前景。 |
| [^63] | [Formal Controller Synthesis for Markov Jump Linear Systems with Uncertain Dynamics.](http://arxiv.org/abs/2212.00679) | 本文介绍了一种方法，用于合成马尔可夫跳变线性系统（MJLS）的控制器，以确保满足概率计算树逻辑（PCTL）公式，对于转移概率未知或已知但存在一定的区间的问题提出了解决方案。 |
| [^64] | [The Effectiveness of World Models for Continual Reinforcement Learning.](http://arxiv.org/abs/2211.15944) | 本论文展示了世界模型在连续学习中的应用，通过研究选择性经验回放方法的影响，提出了Continual-Dreamer模型，该模型在Minigrid和Minihack基准测试中表现优于最先进的任务不可知连续强化学习方法。 |
| [^65] | [Control Transformer: Robot Navigation in Unknown Environments through PRM-Guided Return-Conditioned Sequence Modeling.](http://arxiv.org/abs/2211.06407) | Control Transformer是一种通过采样规划引导的低层策略建模返回条件序列的方法，可以在未知环境中成功解决长时间范围的导航任务。 |
| [^66] | [Adversarial Policies Beat Superhuman Go AIs.](http://arxiv.org/abs/2211.00241) | 通过对抗性策略攻击，我们成功战胜了超级人类级围棋AI KataGo，揭示了其核心弱点，并展示了即使是超级AI系统也可能存在意想不到的失败模式。 |
| [^67] | [RulE: Neural-Symbolic Knowledge Graph Reasoning with Rule Embedding.](http://arxiv.org/abs/2210.14905) | RulE是一个框架，通过将实体、关系和逻辑规则统一表示在一个嵌入空间中，有效利用逻辑规则提升知识图推理。同时，RulE注入先前的逻辑规则信息，改进了实体/关系嵌入，使得知识图嵌入方法也表现更好。 |
| [^68] | [Revisiting Discrete Soft Actor-Critic.](http://arxiv.org/abs/2209.10081) | 本研究重新审视了将连续动作空间的Soft Actor-Critic方法调整为离散动作空间的问题，并提出了解决Q值低估和性能不稳定的方法，验证了其在Atari游戏和大规模MOBA游戏中的有效性。 |
| [^69] | [Data Augmentation is a Hyperparameter: Cherry-picked Self-Supervision for Unsupervised Anomaly Detection is Creating the Illusion of Success.](http://arxiv.org/abs/2208.07734) | 这项研究通过广泛的实验，证明数据增强与异常生成机制之间的对齐是自监督学习在无监督异常检测中取得成功的关键，并且在缺乏对齐时，自监督学习甚至可能降低准确性。 |
| [^70] | [TRUST-LAPSE: An Explainable and Actionable Mistrust Scoring Framework for Model Monitoring.](http://arxiv.org/abs/2207.11290) | TRUST-LAPSE是一个可解释和可操作的连续模型监控框架，通过使用潜空间嵌入评估每个输入样本的模型预测的可信度，并利用距离和相似度度量以及顺序相关性偏差来实现对模型的连续监控。 |
| [^71] | [Classification and Generation of real-world data with an Associative Memory Model.](http://arxiv.org/abs/2207.04827) | 本文提出了一种基于联想记忆模型的多模态框架，可以以容错的方式存储和检索大量真实世界数据，并且可以用于推断缺失的模态。 |
| [^72] | [Most Equitable Voting Rules.](http://arxiv.org/abs/2205.14838) | 该论文探讨了在社会选择理论中设计满足匿名性、中立性和可解决性的最佳投票规则的开放问题。作者提出了一种最公平改进的概念，该概念对满足两个公理的任何不确定规则都能最优地保持匿名性和中立性。 |
| [^73] | [Block shuffling learning for Deepfake Detection.](http://arxiv.org/abs/2202.02819) | 本文提出了一种新颖的块洗牌正则化方法，通过将图像分为块并应用洗牌技术，实现了权重共享和缓解了过拟合问题。大量实验证实了该方法的有效性。 |
| [^74] | [Prospective Learning: Principled Extrapolation to the Future.](http://arxiv.org/abs/2201.07372) | 这项研究提出了一种基于未来信息的学习方法，将学习问题重新定义为关于动态未来的概念，并认为前瞻性学习更准确地描述了现实世界中的许多问题。 |
| [^75] | [Emergent Neural Network Mechanisms for Generalization to Objects in Novel Orientations.](http://arxiv.org/abs/2109.13445) | 本研究提供了证据表明，深度神经网络具有通过传播方向不变性来泛化到新颖方向上的对象的能力。这种能力受到训练中使用的熟悉对象数量的影响，但仅限于涉及2D旋转的熟悉方向。 |
| [^76] | [Autonomous Navigation of Underactuated Bipedal Robots in Height-Constrained Environments.](http://arxiv.org/abs/2109.05714) | 本文提出了一个端到端的自主导航框架，使用三层规划器和可变步行高度控制器，使双足机器人能够安全地探索高度受限环境。 |
| [^77] | [A New Formalism, Method and Open Issues for Zero-Shot Coordination.](http://arxiv.org/abs/2106.06613) | 本研究提出了零知识协调问题的正式定义，并证明了之前的解决方法不是最优解。针对这一问题，引入了带有打破平局的其他对局算法作为最优解。 |
| [^78] | [Declarative Mechanism Design.](http://arxiv.org/abs/1912.13122) | 本文介绍了声明性机制设计的研究，提出了机构神经网络作为一种受管制的人工神经网络，引起人们对人工教学的关注，并提供了初步的答案。 |

# 详细

[^1]: HyperDreamBooth：用于快速个性化文本到图像模型的超网络

    HyperDreamBooth: HyperNetworks for Fast Personalization of Text-to-Image Models. (arXiv:2307.06949v1 [cs.CV])

    [http://arxiv.org/abs/2307.06949](http://arxiv.org/abs/2307.06949)

    HyperDreamBooth是一个超网络，可以从一个人的单张图片中快速生成个性化权重，从而实现在多种背景和风格下合成一个人的面部，保持高保真度并同时保留对多样化风格和语义修改的关键知识。

    

    个性化已经成为生成式人工智能领域中的一个重要方面，使得在不同背景和风格下合成个体成为可能，同时保持高保真度。然而，个性化过程在时间和内存需求方面存在困难。每个个性化模型的微调需要大量的GPU时间投入，为每个主题存储一个个性化模型会对存储容量提出要求。为了克服这些挑战，我们提出了HyperDreamBooth-一种能够从一个人的单张图片有效生成一组个性化权重的超网络。通过将这些权重组合到扩散模型中，并搭配快速微调，HyperDreamBooth能够以多种背景和风格生成一个人的面部，保持高主题细节同时也保持模型对多样化风格和语义修改的关键知识。我们的方法在大约50倍体现了面部个性化。

    Personalization has emerged as a prominent aspect within the field of generative AI, enabling the synthesis of individuals in diverse contexts and styles, while retaining high-fidelity to their identities. However, the process of personalization presents inherent challenges in terms of time and memory requirements. Fine-tuning each personalized model needs considerable GPU time investment, and storing a personalized model per subject can be demanding in terms of storage capacity. To overcome these challenges, we propose HyperDreamBooth-a hypernetwork capable of efficiently generating a small set of personalized weights from a single image of a person. By composing these weights into the diffusion model, coupled with fast finetuning, HyperDreamBooth can generate a person's face in various contexts and styles, with high subject details while also preserving the model's crucial knowledge of diverse styles and semantic modifications. Our method achieves personalization on faces in roughly 
    
[^2]: 视频焦点网络：用于视频动作识别的时空焦点调制

    Video-FocalNets: Spatio-Temporal Focal Modulation for Video Action Recognition. (arXiv:2307.06947v1 [cs.CV])

    [http://arxiv.org/abs/2307.06947](http://arxiv.org/abs/2307.06947)

    本论文提出了一种名为视频焦点网络的视频识别架构，通过时空焦点调制来模拟局部和全局上下文，结合了Transformer和卷积设计的优点，既有效又高效。

    

    最近的视频识别模型利用Transformer模型进行长距离时空上下文建模。视频Transformer设计基于自注意力，可以以高计算成本模拟全局上下文。相比之下，用于视频的卷积设计提供了一种高效的替代方法，但缺乏长距离依赖建模。为了实现这两种设计的最佳效果，本研究提出了视频焦点网络（Video-FocalNet），这是一种既有效又高效的视频识别架构，可以模拟局部和全局上下文。视频焦点网络基于时空焦点调制架构，对自注意力的交互和聚合步骤进行了颠倒，以提高效率。此外，聚合步骤和交互步骤都使用了高效的卷积和逐元素乘法操作来实现，其计算成本比视频表达中的自注意力对应部分要低得多。我们广泛探索了焦点调制的设计空间。

    Recent video recognition models utilize Transformer models for long-range spatio-temporal context modeling. Video transformer designs are based on self-attention that can model global context at a high computational cost. In comparison, convolutional designs for videos offer an efficient alternative but lack long-range dependency modeling. Towards achieving the best of both designs, this work proposes Video-FocalNet, an effective and efficient architecture for video recognition that models both local and global contexts. Video-FocalNet is based on a spatio-temporal focal modulation architecture that reverses the interaction and aggregation steps of self-attention for better efficiency. Further, the aggregation step and the interaction step are both implemented using efficient convolution and element-wise multiplication operations that are computationally less expensive than their self-attention counterparts on video representations. We extensively explore the design space of focal modu
    
[^3]: 在大型语言模型中的上下文压缩的上下文自编码器

    In-context Autoencoder for Context Compression in a Large Language Model. (arXiv:2307.06945v1 [cs.CL])

    [http://arxiv.org/abs/2307.06945](http://arxiv.org/abs/2307.06945)

    在大型语言模型中，我们提出了一种称为In-context Autoencoder (ICAE)的上下文自编码器，它通过将长上下文压缩为有限数量的内存槽，实现了$4\times$的上下文压缩，并能够根据内存槽进行条件处理以响应各种提示。

    

    我们提出了一种用于大型语言模型中上下文压缩的上下文自编码器（ICAE）。 ICAE有两个模块：一个可学习的编码器，通过从LLM中采用LoRA方式将长上下文压缩为有限数量的内存槽，以及一个固定的解码器，作为目标LLM，可以根据内存槽来进行各种目的的条件处理。我们首先使用自编码和语言建模目标在大规模文本数据上预训练ICAE，使其能够生成准确和全面表示原始上下文的内存槽。然后，我们使用少量指导数据对预训练的ICAE进行微调，以增强其与各种提示的交互，从而产生理想的响应。我们的实验结果表明，使用我们提出的预训练和微调范式学习的ICAE可以有效地产生$4\times$上下文压缩的内存槽，目标LLM可以很好地对其进行条件处理，以响应各种提示。

    We propose the In-context Autoencoder (ICAE) for context compression in a large language model (LLM). The ICAE has two modules: a learnable encoder adapted with LoRA from an LLM for compressing a long context into a limited number of memory slots, and a fixed decoder which is the target LLM that can condition on the memory slots for various purposes. We first pretrain the ICAE using both autoencoding and language modeling objectives on massive text data, enabling it to generate memory slots that accurately and comprehensively represent the original context. Then, we fine-tune the pretrained ICAE on a small amount of instruct data to enhance its interaction with various prompts for producing desirable responses. Our experimental results demonstrate that the ICAE learned with our proposed pretraining and fine-tuning paradigm can effectively produce memory slots with $4\times$ context compression, which can be well conditioned on by the target LLM to respond to various prompts. The promis
    
[^4]: 关于博弈论特征归因和反事实解释之间的联系

    On the Connection between Game-Theoretic Feature Attributions and Counterfactual Explanations. (arXiv:2307.06941v1 [cs.AI])

    [http://arxiv.org/abs/2307.06941](http://arxiv.org/abs/2307.06941)

    本研究通过建立理论联系，将博弈论特征归因和反事实解释相结合。通过变换和证明，在一定条件下它们是等价的。研究结果还指出了仅仅使用反事实解释来提供特征重要性的局限性。

    

    最近，可解释的人工智能（XAI）引起了广泛关注，其中两种最受欢迎的解释类型是特征归因和反事实解释。这两类方法一直在独立地进行研究，而对它们的调和只有少数试图是经验性的。本研究建立了博弈论特征归因（主要关注但不限于SHAP）和反事实解释之间的明确理论联系。通过对基于Shapley值的特征归因和反事实解释进行有效变换，并在一定条件下证明它们实际上是等价的。然后，我们将等价结果扩展到了Shapley值以外的博弈论解概念。此外，通过对等价条件的分析，我们揭示了只简单地使用反事实解释来提供特征重要性的局限性。在三个数据集上进行了定量实验。

    Explainable Artificial Intelligence (XAI) has received widespread interest in recent years, and two of the most popular types of explanations are feature attributions, and counterfactual explanations. These classes of approaches have been largely studied independently and the few attempts at reconciling them have been primarily empirical. This work establishes a clear theoretical connection between game-theoretic feature attributions, focusing on but not limited to SHAP, and counterfactuals explanations. After motivating operative changes to Shapley values based feature attributions and counterfactual explanations, we prove that, under conditions, they are in fact equivalent. We then extend the equivalency result to game-theoretic solution concepts beyond Shapley values. Moreover, through the analysis of the conditions of such equivalence, we shed light on the limitations of naively using counterfactual explanations to provide feature importances. Experiments on three datasets quantita
    
[^5]: FDAPT: 面向语言模型的联邦领域自适应预训练

    FDAPT: Federated Domain-adaptive Pre-training for Language Models. (arXiv:2307.06933v1 [cs.LG])

    [http://arxiv.org/abs/2307.06933](http://arxiv.org/abs/2307.06933)

    FDAPT是一种联邦领域自适应预训练的方法，在保护数据隐私的同时，能够通过利用敏感和分布式数据来增强模型适应能力。对于IID和非IID情况下的下游任务，FDAPT能够维持与中央基线相竞争的性能。提出的FFDAPT算法进一步提高了计算效率，并展现出与标准FDAPT类似的下游任务性能。此外，我们也确定了这个新研究领域的有希望的未来研究方向。

    

    将领域自适应预训练（DAPT）与联邦学习（FL）相结合可以通过利用更敏感和分布式数据来增强模型适应能力，同时保护数据隐私。然而，目前关于这种方法的研究还很少。因此，我们进行了第一次全面的实证研究，以评估联邦领域自适应预训练（FDAPT）的性能。我们证明了FDAPT在IID和非IID情况下都能维持与中央基线相竞争的下游任务性能。此外，我们提出了一种新算法，冻结的联邦领域自适应预训练（FFDAPT）。FFDAPT平均提高了12.1%的计算效率，并且在标准FDAPT的情况下展现出类似的下游任务性能，一般性能波动保持在1%以下。最后，通过对我们的工作进行批判性评估，我们确定了这个新的研究领域的有希望的未来研究方向。

    Combining Domain-adaptive Pre-training (DAPT) with Federated Learning (FL) can enhance model adaptation by leveraging more sensitive and distributed data while preserving data privacy. However, few studies have focused on this method. Therefore, we conduct the first comprehensive empirical study to evaluate the performance of Federated Domain-adaptive Pre-training (FDAPT). We demonstrate that FDAPT can maintain competitive downstream task performance to the centralized baseline in both IID and non-IID situations. Furthermore, we propose a novel algorithm, Frozen Federated Domain-adaptive Pre-training (FFDAPT). FFDAPT improves the computational efficiency by 12.1% on average and exhibits similar downstream task performance to standard FDAPT, with general performance fluctuations remaining less than 1%. Finally, through a critical evaluation of our work, we identify promising future research directions for this new research area.
    
[^6]: DRAGON: 一种基于对话的带有视觉语言关联的辅助导航机器人

    DRAGON: A Dialogue-Based Robot for Assistive Navigation with Visual Language Grounding. (arXiv:2307.06924v1 [cs.RO])

    [http://arxiv.org/abs/2307.06924](http://arxiv.org/abs/2307.06924)

    DRAGON是一种基于对话的导航机器人，能够理解用户的指令并通过语言与用户沟通，为视力受损者提供导航和环境描述的帮助。

    

    视力受损者在理解和导航周围空间方面存在困难。目前的导航技术要么只关注导航，要么提供有限的关于环境的沟通。受到最近在视觉语言关联和语义导航方面的进展的启发，我们提出了DRAGON，一种由对话系统驱动的导航机器人，并具有将环境与自然语言关联的能力。通过理解用户的指令，DRAGON能够引导用户到地图上的目标地标，描述环境，并通过视觉观察回答问题。通过有效利用对话，机器人可以将用户的自由形式描述与环境中的地标关联起来，并通过口语提供语义信息给用户。我们在日常室内环境中进行了盲目参与者的用户研究。我们的结果表明，DRAGON能够与用户顺畅地沟通，

    Persons with visual impairments (PwVI) have difficulties understanding and navigating spaces around them. Current wayfinding technologies either focus solely on navigation or provide limited communication about the environment. Motivated by recent advances in visual-language grounding and semantic navigation, we propose DRAGON, a guiding robot powered by a dialogue system and the ability to associate the environment with natural language. By understanding the commands from the user, DRAGON is able to guide the user to the desired landmarks on the map, describe the environment, and answer questions from visual observations. Through effective utilization of dialogue, the robot can ground the user's free-form descriptions to landmarks in the environment, and give the user semantic information through spoken language. We conduct a user study with blindfolded participants in an everyday indoor environment. Our results demonstrate that DRAGON is able to communicate with the user smoothly, pr
    
[^7]: 基于LLM辅助的知识图谱工程: ChatGPT实验

    LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT. (arXiv:2307.06917v1 [cs.AI])

    [http://arxiv.org/abs/2307.06917](http://arxiv.org/abs/2307.06917)

    本文介绍了基于LLM辅助的知识图谱工程实验，展示了ChatGPT在开发和管理知识图谱方面的潜力。

    

    知识图谱提供了一个结构化、灵活、透明、跨系统和协作的方式来组织社会和工业以及科学学科中各个领域的知识和数据。知识图谱在有效性方面超越了任何其他形式的表示。然而，知识图谱工程需要对图结构、网络技术、现有模型和词汇、规则集、逻辑以及最佳实践有深入的了解，同时还需要大量的工作。考虑到最近大规模语言模型（LLM）及其接口和应用的进展，我们对ChatGPT进行了全面实验，探索其在支持知识图谱工程方面的潜力。在本文中，我们展示了其中一些实验及其结果，以展示ChatGPT如何辅助我们开发和管理知识图谱。

    Knowledge Graphs (KG) provide us with a structured, flexible, transparent, cross-system, and collaborative way of organizing our knowledge and data across various domains in society and industrial as well as scientific disciplines. KGs surpass any other form of representation in terms of effectiveness. However, Knowledge Graph Engineering (KGE) requires in-depth experiences of graph structures, web technologies, existing models and vocabularies, rule sets, logic, as well as best practices. It also demands a significant amount of work. Considering the advancements in large language models (LLMs) and their interfaces and applications in recent years, we have conducted comprehensive experiments with ChatGPT to explore its potential in supporting KGE. In this paper, we present a selection of these experiments and their results to demonstrate how ChatGPT can assist us in the development and management of KGs.
    
[^8]: 通过潜在空间分解揭示独特的概念向量

    Uncovering Unique Concept Vectors through Latent Space Decomposition. (arXiv:2307.06913v1 [cs.LG])

    [http://arxiv.org/abs/2307.06913](http://arxiv.org/abs/2307.06913)

    通过潜在空间分解和无监督聚类，我们提出了一种自动揭示深度学习模型学习到的概念向量的方法，这些概念向量与模型预测相关且具有语义的独特概念，并且在实验中表明这些概念对人类来说易于理解和与任务相关。

    

    解释深度学习模型的内部工作对于建立信任和确保模型安全至关重要。基于概念的解释已经成为一种更易解释的方法，比如像素显著性等特征归因估计。然而，定义解释分析的概念会受到用户对概念期望的偏差影响。为了解决这个问题，我们提出了一种新的事后无监督方法，可以自动揭示深度模型在训练期间学习到的概念。通过分解一个层的潜在空间成奇异向量，并通过无监督聚类对其进行精炼，我们揭示了与模型预测相关的高方差方向上的概念向量，并指向语义上独特的概念。我们广泛的实验结果显示，我们的大部分概念对人类来说是易于理解的，具有一致性，并与所需任务相关。此外，我们还展示了...

    Interpreting the inner workings of deep learning models is crucial for establishing trust and ensuring model safety. Concept-based explanations have emerged as a superior approach that is more interpretable than feature attribution estimates such as pixel saliency. However, defining the concepts for the interpretability analysis biases the explanations by the user's expectations on the concepts. To address this, we propose a novel post-hoc unsupervised method that automatically uncovers the concepts learned by deep models during training. By decomposing the latent space of a layer in singular vectors and refining them by unsupervised clustering, we uncover concept vectors aligned with directions of high variance that are relevant to the model prediction, and that point to semantically distinct concepts. Our extensive experiments reveal that the majority of our concepts are readily understandable to humans, exhibit coherency, and bear relevance to the task at hand. Moreover, we showcase
    
[^9]: 生成用于语言模型事实性评估的基准数据集

    Generating Benchmarks for Factuality Evaluation of Language Models. (arXiv:2307.06908v1 [cs.CL])

    [http://arxiv.org/abs/2307.06908](http://arxiv.org/abs/2307.06908)

    该论文提出了一个名为FACTOR的方法，用于生成用于语言模型事实性评估的基准数据集。通过自动转换事实语料库，评估语言模型根据语料库生成真实事实的倾向与生成不正确陈述的能力。实验结果表明，该基准数据集的分数随模型大小增加而增加，在LM与检索方法结合时性能得到改善。困惑度和基准数据集分数之间存在相关性，但不总是一致。

    

    在将语言模型（LM）部署到特定领域之前，衡量其在该领域中生成事实错误信息的倾向很重要。现有的事实生成评估方法集中于从LM自身中采样的事实，因此无法控制评估事实的集合，并且可能低估了罕见和不太可能的事实。我们提出了FACTOR：通过语料库变换进行事实评估的方法，这是一种可扩展的方法来评估LM的事实性。FACTOR会自动将感兴趣的事实语料库转化为一个基准数据集，评估LM根据语料库生成真实事实的倾向与生成类似但不正确的陈述的能力。我们使用我们的框架创建了两个基准数据集：Wiki-FACTOR和News-FACTOR。我们的实验结果表明：（i）我们的基准数据集分数随模型大小增加而增加，并且当LM与检索方法结合使用时，性能得到改善；（ii）基准数据集分数与困惑度之间存在相关性，但这两个指标在模型排序上并不总是一致；以及（iii）当困惑度和基准数据集分数发生冲突时，基准数据集分数更能准确反映LM的事实性能。

    Before deploying a language model (LM) within a given domain, it is important to measure its tendency to generate factually incorrect information in that domain. Existing factual generation evaluation methods focus on facts sampled from the LM itself, and thus do not control the set of evaluated facts and might under-represent rare and unlikely facts. We propose FACTOR: Factual Assessment via Corpus TransfORmation, a scalable approach for evaluating LM factuality. FACTOR automatically transforms a factual corpus of interest into a benchmark evaluating an LM's propensity to generate true facts from the corpus vs. similar but incorrect statements. We use our framework to create two benchmarks: Wiki-FACTOR and News-FACTOR. We show that: (i) our benchmark scores increase with model size and improve when the LM is augmented with retrieval; (ii) benchmark score correlates with perplexity, but the two metrics do not always agree on model ranking; and (iii) when perplexity and benchmark score 
    
[^10]: 非平稳强化学习的复杂性

    The complexity of non-stationary reinforcement learning. (arXiv:2307.06877v1 [cs.LG])

    [http://arxiv.org/abs/2307.06877](http://arxiv.org/abs/2307.06877)

    强化学习中的非平稳学习是一个重要挑战，我们证明了在修改概率或奖励时需要花费大量的时间来保持值函数的最新状态，并且这个挑战与状态数目密切相关。

    

    非平稳强化学习的问题被认为是强化学习应用中的一个重要挑战。我们证明了最坏情况下的复杂性结果，我们认为这恰好捕捉到了这个挑战：修改强化学习问题中一个状态-动作对的概率或奖励，需要花费几乎与状态数目一样多的时间来及时更新值函数，除非强指数时间假设(SETH)是错误的；SETH是P≠NP猜想的广泛接受的加强版。需要注意的是，目前强化学习应用中的状态数目通常是天文数字级别的。相反，我们还展示了仅仅"添加"一个新的状态-动作对要容易得多。

    The problem of continual learning in the domain of reinforcement learning, often called non-stationary reinforcement learning, has been identified as an important challenge to the application of reinforcement learning. We prove a worst-case complexity result, which we believe captures this challenge: Modifying the probabilities or the reward of a single state-action pair in a reinforcement learning problem requires an amount of time almost as large as the number of states in order to keep the value function up to date, unless the strong exponential time hypothesis (SETH) is false; SETH is a widely accepted strengthening of the P $\neq$ NP conjecture. Recall that the number of states in current applications of reinforcement learning is typically astronomical. In contrast, we show that just $\textit{adding}$ a new state-action pair is considerably easier to implement.
    
[^11]: 任务和运动规划的具身化终身学习

    Embodied Lifelong Learning for Task and Motion Planning. (arXiv:2307.06870v1 [cs.RO])

    [http://arxiv.org/abs/2307.06870](http://arxiv.org/abs/2307.06870)

    这篇论文研究了在家中长期部署的机器人所面临的具身化终身学习问题，在任务和运动规划的背景下采用了新颖的问题建模方法。利用TAMP系统的模块化特性，提出了一个生成混合模型来产生规划器的候选参数。通过学习共享和非共享的模型，并根据代理任务来在线选择使用的模型，该方法在模拟的2D领域和BEHAVIOR基准测试中取得了显著的规划成功改进。

    

    在一个长时间内部署在家中的机器人面临着真正的终身学习问题。作为机器人寻求为用户提供帮助，它应该利用任何积累的经验来改进自己的知识，成为一个更熟练的助手。我们在任务和运动规划（TAMP）学习的背景下，对这种情况进行了新颖的终身学习问题建模。利用TAMP系统的模块化特性，我们开发了一个生成混合模型，为规划器生成候选连续参数。与大多数现有的终身学习方法预先确定数据如何在任务模型之间共享不同，我们的方法学习共享和非共享模型，并根据代理任务来决定在规划过程中在线使用哪个模型，这些任务作为每个模型对状态的理解的代理。我们的方法在模拟的2D领域和BEHAVIOR基准测试中的多个问题上展示了显著的规划成功的改进。

    A robot deployed in a home over long stretches of time faces a true lifelong learning problem. As it seeks to provide assistance to its users, the robot should leverage any accumulated experience to improve its own knowledge to become a more proficient assistant. We formalize this setting with a novel lifelong learning problem formulation in the context of learning for task and motion planning (TAMP). Exploiting the modularity of TAMP systems, we develop a generative mixture model that produces candidate continuous parameters for a planner. Whereas most existing lifelong learning approaches determine a priori how data is shared across task models, our approach learns shared and non-shared models and determines which to use online during planning based on auxiliary tasks that serve as a proxy for each model's understanding of a state. Our method exhibits substantial improvements in planning success on simulated 2D domains and on several problems from the BEHAVIOR benchmark.
    
[^12]: DecompEval：将生成的文本作为无监督分解问答进行评估

    DecompEval: Evaluating Generated Texts as Unsupervised Decomposed Question Answering. (arXiv:2307.06869v1 [cs.CL])

    [http://arxiv.org/abs/2307.06869](http://arxiv.org/abs/2307.06869)

    DecompEval提出了一种简单而有效的指标来评估自然语言生成任务，它将评估建模为一种类似指令的问答任务，并利用预训练语言模型进行衡量，以增强泛化能力和可解释性。

    

    现有的自然语言生成（NLG）任务评估指标面临着泛化能力和可解释性的挑战。具体而言，大多数表现良好的指标需要在特定的NLG任务和评估维度的评估数据集上进行训练，这可能导致对任务特定数据集的过拟合。此外，现有的指标仅提供每个维度的评估分数，而不揭示如何获得该分数的证据。为了应对这些挑战，我们提出了一种简单而有效的指标称为DecompEval。这个指标将NLG评估建模为一种类似指令的问答任务，并利用经过指令调整的预训练语言模型（PLMs）而不是在评估数据集上进行训练，旨在增强泛化能力。为了使评估过程更具可解释性，我们将关于生成文本质量的设计指令式问题分解为衡量子问题的问题

    Existing evaluation metrics for natural language generation (NLG) tasks face the challenges on generalization ability and interpretability. Specifically, most of the well-performed metrics are required to train on evaluation datasets of specific NLG tasks and evaluation dimensions, which may cause over-fitting to task-specific datasets. Furthermore, existing metrics only provide an evaluation score for each dimension without revealing the evidence to interpret how this score is obtained. To deal with these challenges, we propose a simple yet effective metric called DecompEval. This metric formulates NLG evaluation as an instruction-style question answering task and utilizes instruction-tuned pre-trained language models (PLMs) without training on evaluation datasets, aiming to enhance the generalization ability. To make the evaluation process more interpretable, we decompose our devised instruction-style question about the quality of generated texts into the subquestions that measure th
    
[^13]: 提示不应被视为秘密：系统地衡量提示提取攻击的成功性

    Prompts Should not be Seen as Secrets: Systematically Measuring Prompt Extraction Attack Success. (arXiv:2307.06865v1 [cs.CL])

    [http://arxiv.org/abs/2307.06865](http://arxiv.org/abs/2307.06865)

    本论文提出了一个系统地衡量提示提取攻击成功的框架，并通过多个实验发现，即使提示被保密，简单的基于文本的攻击仍然可以高概率地揭示提示。

    

    大型语言模型的生成通常通过提示技术来控制，其中用户对模型的查询以旨在指导模型在该查询上的行为的提示作为前缀。公司用于指导其模型的提示通常被视为秘密，隐藏在查询的用户之外。它们甚至被视为可以买卖的商品。然而，有经验性的证据显示，即使提示被保密，用户仍然可以提取它们。在本文中，我们提出了一个系统地衡量提示提取攻击成功的框架。在使用多个提示源和多个基础语言模型的实验中，我们发现简单的基于文本的攻击实际上可以高概率地揭示提示。

    The generations of large language models are commonly controlled through prompting techniques, where a user's query to the model is prefixed with a prompt that aims to guide the model's behaviour on the query. The prompts used by companies to guide their models are often treated as secrets, to be hidden from the user making the query. They have even been treated as commodities to be bought and sold. However, there has been anecdotal evidence showing that the prompts can be extracted by a user even when they are kept secret. In this paper, we present a framework for systematically measuring the success of prompt extraction attacks. In experiments with multiple sources of prompts and multiple underlying language models, we find that simple text-based attacks can in fact reveal prompts with high probability.
    
[^14]: 非传统的认知智能机器人控制：人类情感估计中的量子软计算方法-- QCOptKB工具包应用

    Unconventional Cognitive Intelligent Robotic Control: Quantum Soft Computing Approach in Human Being Emotion Estimation -- QCOptKB Toolkit Application. (arXiv:2307.06858v1 [quant-ph])

    [http://arxiv.org/abs/2307.06858](http://arxiv.org/abs/2307.06858)

    该论文提出了一种基于量子和软计算的智能认知控制系统的策略，通过提取量子自组织知识库，改善了在危险控制情况下系统的鲁棒性，并展示了量子模糊推理门设计在嵌入式控制系统中的应用。

    

    本论文介绍了基于量子和软计算的智能认知控制系统的策略。描述了从智能模糊控制器的不完美知识库中提取量子自组织知识库的协同效应。该技术改善了在危险控制情况下智能认知控制系统的鲁棒性，同时结合认知神经接口和不同类型的机器人合作。通过示例展示了引入量子模糊推理门设计作为嵌入式控制系统的可编程算法解决方案。展示了基于认知头盔和量子模糊控制器的神经接口应用于驾驶车辆的可能性。

    Strategy of intelligent cognitive control systems based on quantum and soft computing presented. Quantum self-organization knowledge base synergetic effect extracted from intelligent fuzzy controllers imperfect knowledge bases described. That technology improved of robustness of intelligent cognitive control systems in hazard control situations described with the cognitive neuro-interface and different types of robot cooperation. Examples demonstrated the introduction of quantum fuzzy inference gate design as prepared programmable algorithmic solution for board embedded control systems. The possibility of neuro-interface application based on cognitive helmet with quantum fuzzy controller for driving of the vehicle is shown.
    
[^15]: 自洽性方法用于无限生成问题的改进

    Self-consistency for open-ended generations. (arXiv:2307.06857v1 [cs.AI])

    [http://arxiv.org/abs/2307.06857](http://arxiv.org/abs/2307.06857)

    本论文提出了一种改进大规模预训练语言模型生成输出质量和一致性的新方法，通过扩展自洽性框架的适用性，实现了从一个候选集中恢复最优或接近最优的生成结果，并提出了一种轻量级无参数相似性函数来改进代码生成、自动形式化和摘要任务的效果。

    

    在这篇论文中，我们提出了一种改进大规模预训练语言模型生成输出的质量和一致性的新方法。自洽性已经被证明是一种有效的方法，对于具有固定答案的提示，选择得票最多的答案。我们引入了一个推广的自洽性框架，扩展了其适用性，超越了固定答案问题的范围。通过大量的模拟实验，我们证明了我们的方法能够从候选集中恢复最优或接近最优的生成结果。我们还提出了一种轻量级无参数相似性函数，即使没有访问到标记的概率，也能在代码生成、自动形式化和摘要任务中显著和一致地改进效果。我们的方法几乎没有计算开销，不需要额外的再排序模型或对现有模型的修改。

    In this paper, we present a novel approach for improving the quality and consistency of generated outputs from large-scale pre-trained language models (LLMs). Self-consistency has emerged as an effective approach for prompts with fixed answers, selecting the answer with the highest number of votes. In this paper, we introduce a generalized framework for self-consistency that extends its applicability beyond problems that have fixed-answer answers. Through extensive simulations, we demonstrate that our approach consistently recovers the optimal or near-optimal generation from a set of candidates. We also propose lightweight parameter-free similarity functions that show significant and consistent improvements across code generation, autoformalization, and summarization tasks, even without access to token log probabilities. Our method incurs minimal computational overhead, requiring no auxiliary reranker models or modifications to the existing model.
    
[^16]: 自主缝合术尾部缩短的手术线互动感知的自主学习

    Self-Supervised Learning for Interactive Perception of Surgical Thread for Autonomous Suture Tail-Shortening. (arXiv:2307.06845v1 [cs.RO])

    [http://arxiv.org/abs/2307.06845](http://arxiv.org/abs/2307.06845)

    本文提出了一种自主学习的方法，用于自动感知手术线，在三维环境中跟踪线的路径，并应用于自主进行手术缝合 "尾部缩短" 任务。该方法通过二维线检测和三维线重建实现了对线的准确感知和跟踪，具有鲁棒性。

    

    在自动化手术缝合中，准确感知缝合线是一个具有挑战性的问题，因为线的状态空间复杂，线的薄度和可变形性以及夹具和组织的可能遮挡。本文提出了一种在三维空间中跟踪手术线的方法，该方法对遮挡和复杂的线配置具有鲁棒性，并将其应用于自动执行手术缝合 "尾部缩短" 任务：将线拉通过组织直到所需的 "尾部" 长度保持暴露。该方法利用一个经过训练的二维手术线检测网络，在RGB图像中分割缝合线。然后，它在二维中识别线的路径，并通过从两个立体相机检测进行三角化，将线重建为三维的非均匀有理B样条曲线。一旦初始化了三维线模型，该方法会在随后的帧中跟踪线的移动。实验证明，该方法在具有挑战性的单帧三维线上达到1.33像素的平均重投影误差。

    Accurate 3D sensing of suturing thread is a challenging problem in automated surgical suturing because of the high state-space complexity, thinness and deformability of the thread, and possibility of occlusion by the grippers and tissue. In this work we present a method for tracking surgical thread in 3D which is robust to occlusions and complex thread configurations, and apply it to autonomously perform the surgical suture "tail-shortening" task: pulling thread through tissue until a desired "tail" length remains exposed. The method utilizes a learned 2D surgical thread detection network to segment suturing thread in RGB images. It then identifies the thread path in 2D and reconstructs the thread in 3D as a NURBS spline by triangulating the detections from two stereo cameras. Once a 3D thread model is initialized, the method tracks the thread across subsequent frames. Experiments suggest the method achieves a 1.33 pixel average reprojection error on challenging single-frame 3D thread 
    
[^17]: 垃圾进，垃圾出：利用大型语言模型进行零样本犯罪检测

    Garbage in, garbage out: Zero-shot detection of crime using Large Language Models. (arXiv:2307.06844v1 [cs.CL])

    [http://arxiv.org/abs/2307.06844](http://arxiv.org/abs/2307.06844)

    本文利用大型语言模型学习的常识知识，通过将视频转换为文本描述，实现了零样本推理的犯罪检测。现有的视频转文本方法质量不足以支持推理。

    

    本文提出利用大型语言模型学习的常识知识，在给定监控视频的文本描述的情况下进行关于犯罪的零样本推理。我们展示了当将视频手动转换为高质量的文本描述时，大型语言模型能够仅通过零样本推理实现具有最先进性能的犯罪检测和分类。然而，现有的自动化视频转文本方法无法生成足够质量的视频描述来支持推理（垃圾视频描述进入大型语言模型后，产生的结果也是垃圾）。

    This paper proposes exploiting the common sense knowledge learned by large language models to perform zero-shot reasoning about crimes given textual descriptions of surveillance videos. We show that when video is (manually) converted to high quality textual descriptions, large language models are capable of detecting and classifying crimes with state-of-the-art performance using only zero-shot reasoning. However, existing automated video-to-text approaches are unable to generate video descriptions of sufficient quality to support reasoning (garbage video descriptions into the large language model, garbage out).
    
[^18]: 一个统一常见领域泛化方法的因果框架

    A Causal Framework to Unify Common Domain Generalization Approaches. (arXiv:2307.06825v1 [cs.LG])

    [http://arxiv.org/abs/2307.06825](http://arxiv.org/abs/2307.06825)

    本文提出了一个因果框架用于统一常见领域泛化方法的理解，通过回答关键思想、理论基础和方法关系等问题，帮助研究者更好地理解和发展领域泛化方法。

    

    领域泛化(DG)是指学习能够很好地推广到与训练领域相关但不同的新领域的模型。它是机器学习中的一个基本问题，并在最近几年引起了很多关注。已提出了大量不同的方法。不同的方法从不同的角度出发，使得很难对这个领域有一个整体的理解。在本文中，我们提出了一个用于领域泛化的因果框架，并在框架中对常见的DG方法进行了理解。我们的工作为以下问题提供了新的观点：(1)每个DG方法背后的关键思想是什么？(2)理论上为什么期望它改善对新领域的推广能力？(3)不同的DG方法之间如何相关，有什么相对优势和局限性？通过提供对DG的统一视角，我们希望能帮助研究者更好地理解其中的原则并开发出更有效的方法。

    Domain generalization (DG) is about learning models that generalize well to new domains that are related to, but different from, the training domain(s). It is a fundamental problem in machine learning and has attracted much attention in recent years. A large number of approaches have been proposed. Different approaches are motivated from different perspectives, making it difficult to gain an overall understanding of the area. In this paper, we propose a causal framework for domain generalization and present an understanding of common DG approaches in the framework. Our work sheds new lights on the following questions: (1) What are the key ideas behind each DG method? (2) Why is it expected to improve generalization to new domains theoretically? (3) How are different DG methods related to each other and what are relative advantages and limitations? By providing a unified perspective on DG, we hope to help researchers better understand the underlying principles and develop more effective
    
[^19]: CLAIMED -- 在科学加速发现中构建粗粒度运算符的开放源代码框架

    CLAIMED -- the open source framework for building coarse-grained operators for accelerated discovery in science. (arXiv:2307.06824v1 [cs.AI])

    [http://arxiv.org/abs/2307.06824](http://arxiv.org/abs/2307.06824)

    CLAIMED是一个开放源代码框架，用于在现代数据驱动的科学中构建可重用的运算符和可扩展的科学工作流程，从而解决了重复性和可重用性问题。

    

    在现代数据驱动的科学中，重复性和重用性是关键挑战。科学家在从数据到出版的过程中有着丰富的经验。尽管一些出版渠道要求源代码和数据可获得，但重新运行和验证实验通常很困难，原因是缺乏标准。因此，重用现有的科学数据处理代码来自最新研究是困难的。这就是为什么我们引入CLAIMED，它在现代数据驱动的科学中解决了重复性和可重用性问题的科学研究实践。CLAIMED是一个框架，通过支持科学家从现有的粗粒度科学运算符库中重新组合工作流程，来构建可重用的运算符和可扩展的科学工作流程。尽管有各种实现，但CLAIMED是编程语言、科学库和执行环境无关的。

    In modern data-driven science, reproducibility and reusability are key challenges. Scientists are well skilled in the process from data to publication. Although some publication channels require source code and data to be made accessible, rerunning and verifying experiments is usually hard due to a lack of standards. Therefore, reusing existing scientific data processing code from state-of-the-art research is hard as well. This is why we introduce CLAIMED, which has a proven track record in scientific research for addressing the repeatability and reusability issues in modern data-driven science. CLAIMED is a framework to build reusable operators and scalable scientific workflows by supporting the scientist to draw from previous work by re-composing workflows from existing libraries of coarse-grained scientific operators. Although various implementations exist, CLAIMED is programming language, scientific library, and execution environment agnostic.
    
[^20]: TinyMetaFed: 高效的用于TinyML的联邦元学习

    TinyMetaFed: Efficient Federated Meta-Learning for TinyML. (arXiv:2307.06822v1 [cs.LG])

    [http://arxiv.org/abs/2307.06822](http://arxiv.org/abs/2307.06822)

    TinyMetaFed是一个适用于TinyML的高效联邦元学习框架，通过协同训练神经网络初始化，在小型设备上能够快速微调，同时实现通信节省和隐私保护。

    

    Tiny Machine Learning (TinyML)领域在使得机器学习在低功耗设备（如微控制器）上实现方面取得了重大进展。这些微型设备的普及引发了一个问题，即聚合它们的知识是否能够使TinyML应用受益。联邦元学习是这个问题的一个有前景的答案，因为它解决了现实世界中标记数据的稀缺性和设备之间的异构数据分布。然而，部署TinyML硬件面临着独特的资源限制，现有方法由于能源、隐私和通信限制而不实用。我们引入了TinyMetaFed，一个适用于TinyML的模型无关的元学习框架。TinyMetaFed促进了神经网络初始化的协同训练，可以在新设备上快速微调。它通过部分本地重构和Top-P%选择性通信提供通信节省和隐私保护，具有计算效果好。

    The field of Tiny Machine Learning (TinyML) has made substantial advancements in democratizing machine learning on low-footprint devices, such as microcontrollers. The prevalence of these miniature devices raises the question of whether aggregating their knowledge can benefit TinyML applications. Federated meta-learning is a promising answer to this question, as it addresses the scarcity of labeled data and heterogeneous data distribution across devices in the real world. However, deploying TinyML hardware faces unique resource constraints, making existing methods impractical due to energy, privacy, and communication limitations. We introduce TinyMetaFed, a model-agnostic meta-learning framework suitable for TinyML. TinyMetaFed facilitates collaborative training of a neural network initialization that can be quickly fine-tuned on new devices. It offers communication savings and privacy protection through partial local reconstruction and Top-P% selective communication, computational eff
    
[^21]: 使用大规模语言模型的否定式互补常识

    Negated Complementary Commonsense using Large Language Models. (arXiv:2307.06794v1 [cs.CL])

    [http://arxiv.org/abs/2307.06794](http://arxiv.org/abs/2307.06794)

    本论文研究了使用大规模语言模型解决否定式互补问题的性能。作者发现，这种类型的问题会对模型的响应产生负面影响，并提出了一种模型无关的方法来改善性能。实验证明，该方法在少样本生成方面优于GPT-3，并强调了研究大规模语言模型在否定式互补问题中的重要性。

    

    更大的语言模型，如GPT-3，在许多任务中表现出色。然而，我们证明，非常规问题可能会使模型失去警觉。本文主要关注在常识情景中寻找否定式互补问题的答案。我们阐述了这类问题对模型响应的不利影响。我们提出了一种模型无关的方法来提高在否定式互补情景中的性能。我们的方法在从GPT-3进行少样本生成方面表现优于（超过11个点），更重要的是，强调了研究大规模语言模型在否定式互补问题中的响应的重要性。代码、数据和实验可在以下链接找到：https://github.com/navidre/negated_complementary_commonsense。

    Larger language models, such as GPT-3, have shown to be excellent in many tasks. However, we demonstrate that out-of-ordinary questions can throw the model off guard. This work focuses on finding answers to negated complementary questions in commonsense scenarios. We illustrate how such questions adversely affect the model responses. We propose a model-agnostic methodology to improve the performance in negated complementary scenarios. Our method outperforms few-shot generation from GPT-3 (by more than 11 points) and, more importantly, highlights the significance of studying the response of large language models in negated complementary questions. The code, data, and experiments are available under: https://github.com/navidre/negated_complementary_commonsense.
    
[^22]: 一种新型的与平台无关的多模态深度学习模型，用于识别社交媒体上的促进饮食紊乱内容

    A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media. (arXiv:2307.06775v1 [cs.LG])

    [http://arxiv.org/abs/2307.06775](http://arxiv.org/abs/2307.06775)

    本研究创建了一个多模态深度学习模型，将文本和视觉数据相结合，能够准确识别社交媒体上的促进饮食紊乱的内容。最有效的模型是RoBERTa自然语言处理模型和MaxViT图像分类模型的融合模型，准确率和F1分数分别达到95.9%和0.959。

    

    在过去的十年中，饮食紊乱的诊断和与之相关的死亡数量大幅增加，尤其是在新冠疫情期间。这种巨大增长部分来源于疫情的压力，但也与社交媒体的暴露增加有关，社交媒体上充斥着促进饮食紊乱的内容。这些内容可以诱发观看者的饮食紊乱。本研究旨在创建一个多模态深度学习模型，能够基于视觉和文本数据的组合判断给定的社交媒体帖子是否促进饮食紊乱。从Twitter收集了一个带有标签的推文数据集，对其进行了十二个深度学习模型的训练和测试。根据模型的性能，最有效的深度学习模型是RoBERTa自然语言处理模型和MaxViT图像分类模型的多模态融合模型，准确率和F1分数分别达到95.9%和0.959。RoBERTa和MaxViT融合模型可以有效地识别社交媒体上的促进饮食紊乱的内容。

    Over the last decade, there has been a vast increase in eating disorder diagnoses and eating disorder-attributed deaths, reaching their zenith during the Covid-19 pandemic. This immense growth derived in part from the stressors of the pandemic but also from increased exposure to social media, which is rife with content that promotes eating disorders. Such content can induce eating disorders in viewers. This study aimed to create a multimodal deep learning model capable of determining whether a given social media post promotes eating disorders based on a combination of visual and textual data. A labeled dataset of Tweets was collected from Twitter, upon which twelve deep learning models were trained and tested. Based on model performance, the most effective deep learning model was the multimodal fusion of the RoBERTa natural language processing model and the MaxViT image classification model, attaining accuracy and F1 scores of 95.9% and 0.959 respectively. The RoBERTa and MaxViT fusion
    
[^23]: 动态多智能体系统的分层控制合成技术

    Layered controller synthesis for dynamic multi-agent systems. (arXiv:2307.06758v1 [cs.AI])

    [http://arxiv.org/abs/2307.06758](http://arxiv.org/abs/2307.06758)

    该论文提出了一种分层控制合成技术，用于解决动态多智能体系统的控制问题。通过分为三个阶段并使用强化学习训练神经网络控制策略，该方法可以实现更动态准确的解决方案。

    

    本文提出了一种分层控制方法，用于解决多智能体系统的控制问题。该方法分为三个阶段，每个阶段都建立在前一个阶段的结果基础上。首先，计算系统的粗略抽象的高级计划，使用增加了秒表的参数化定时自动机来有效地模拟这种系统的简化动力学。在第二阶段，基于SMT表述的高级计划主要处理问题的组合方面，提供了更动态准确的解决方案。这些阶段统称为SWA-SMT求解器，它们是构造正确的，但缺乏一个关键特性：不能实时执行。为了克服这个问题，我们将SWA-SMT的解作为最后一个阶段的初始训练数据集，该阶段旨在获得一个神经网络控制策略。我们使用强化学习来训练策略，并且证明初始数据集对于整个方法的成功至关重要。

    In this paper we present a layered approach for multi-agent control problem, decomposed into three stages, each building upon the results of the previous one. First, a high-level plan for a coarse abstraction of the system is computed, relying on parametric timed automata augmented with stopwatches as they allow to efficiently model simplified dynamics of such systems. In the second stage, the high-level plan, based on SMT-formulation, mainly handles the combinatorial aspects of the problem, provides a more dynamically accurate solution. These stages are collectively referred to as the SWA-SMT solver. They are correct by construction but lack a crucial feature: they cannot be executed in real time. To overcome this, we use SWA-SMT solutions as the initial training dataset for our last stage, which aims at obtaining a neural network control policy. We use reinforcement learning to train the policy, and show that the initial dataset is crucial for the overall success of the method.
    
[^24]: 基于多代理层次强化学习方法的即时城际拼车服务的车辆调度和路径规划

    Vehicle Dispatching and Routing of On-Demand Intercity Ride-Pooling Services: A Multi-Agent Hierarchical Reinforcement Learning Approach. (arXiv:2307.06742v1 [eess.SY])

    [http://arxiv.org/abs/2307.06742](http://arxiv.org/abs/2307.06742)

    本研究提出了一个基于多代理层次强化学习的框架，用于即时城际拼车服务的车辆调度和路径规划。数值研究证明该框架有效缓解了供给不足问题。

    

    城市群一体化的发展导致了对城际旅行的不断增长需求。城际拼车服务通过实施需求响应性增强措施，有望升级传统的城际客车服务。然而，其在线操作受到车辆资源分配和拼车车辆路径规划之间耦合性的固有复杂性的影响。为了解决这些挑战，本研究提出了一个两层框架，旨在促进在线车队管理。具体而言，在框架的上层，提出了一种新颖的多代理封建强化学习模型，用于协同分配闲置车辆到不同的城际线路，而在下层，则使用自适应大邻域搜索启发式算法更新车辆的路线。基于中国厦门及其周边城市的真实数据集进行的数值研究表明，所提出的框架有效地缓解了供给不足问题。

    The integrated development of city clusters has given rise to an increasing demand for intercity travel. Intercity ride-pooling service exhibits considerable potential in upgrading traditional intercity bus services by implementing demand-responsive enhancements. Nevertheless, its online operations suffer the inherent complexities due to the coupling of vehicle resource allocation among cities and pooled-ride vehicle routing. To tackle these challenges, this study proposes a two-level framework designed to facilitate online fleet management. Specifically, a novel multi-agent feudal reinforcement learning model is proposed at the upper level of the framework to cooperatively assign idle vehicles to different intercity lines, while the lower level updates the routes of vehicles using an adaptive large neighborhood search heuristic. Numerical studies based on the realistic dataset of Xiamen and its surrounding cities in China show that the proposed framework effectively mitigates the supp
    
[^25]: MPR-Net: 多尺度模式重现引导的通用时间序列可解释性预测

    MPR-Net:Multi-Scale Pattern Reproduction Guided Universality Time Series Interpretable Forecasting. (arXiv:2307.06736v1 [cs.LG])

    [http://arxiv.org/abs/2307.06736](http://arxiv.org/abs/2307.06736)

    本文提出了一种名为MPR-Net的预测模型，通过自适应地分解多尺度历史序列模式，并基于模式重现的先验知识构建模式扩展预测方法，最后使用反卷积运算将未来模式重建为未来序列。MPR-Net能够有效地捕捉时间序列中的重要模式并实现可解释的预测。

    

    时间序列预测由于其广泛的应用和固有的挑战性而受到了广泛的关注。研究的挑战在于识别历史序列中的有效模式，并将其应用于未来的预测。基于点对点连接的多层感知机和Transformer架构的先进模型具有强大的拟合能力，但其辅助计算复杂度限制了实用性。此外，这些结构固有地破坏了时间顺序，降低了信息利用率，并使预测过程解释性降低。为了解决这些问题，本文提出了一种预测模型MPR-Net。它首先使用卷积运算自适应地分解多尺度历史序列模式，然后基于模式重现的先验知识构建一种模式扩展预测方法，最后使用反卷积运算将未来模式重建为未来序列。通过利用时间依赖性，MPR-Net能够有效地捕捉时间序列中的重要模式并实现可解释的预测。

    Time series forecasting has received wide interest from existing research due to its broad applications and inherent challenging. The research challenge lies in identifying effective patterns in historical series and applying them to future forecasting. Advanced models based on point-wise connected MLP and Transformer architectures have strong fitting power, but their secondary computational complexity limits practicality. Additionally, those structures inherently disrupt the temporal order, reducing the information utilization and making the forecasting process uninterpretable. To solve these problems, this paper proposes a forecasting model, MPR-Net. It first adaptively decomposes multi-scale historical series patterns using convolution operation, then constructs a pattern extension forecasting method based on the prior knowledge of pattern reproduction, and finally reconstructs future patterns into future series using deconvolution operation. By leveraging the temporal dependencies 
    
[^26]: GRAN优于GraphRNN：基于节点排序、核函数和图嵌入的度量用于图生成器

    GRAN is superior to GraphRNN: node orderings, kernel- and graph embeddings-based metrics for graph generators. (arXiv:2307.06709v1 [cs.LG])

    [http://arxiv.org/abs/2307.06709](http://arxiv.org/abs/2307.06709)

    本论文通过比较基于节点排序、核函数和图嵌入的度量，展示了GRAN优于GraphRNN的优势，并为小型图提供了有效的GraphRNN改进方法。此外，论文还提供了关于数据集选择和节点特征初始化的最佳实践指南。

    

    针对图的生成模型已经被广泛提出，并在药物发现、道路网络、神经架构搜索和程序综合等领域得到应用。然而，生成图面临着理论上的挑战，如同构表示，评估生成模型的性能很困难。在应用领域中，如何选择合适的模型？我们对分布图不变量的核函数度量进行了广泛研究，并在图嵌入空间中研究了基于流形和基于核函数的度量。基于流形的度量在嵌入空间中表现出色。我们使用这些度量来比较两个著名的图生成模型GraphRNN和GRAN，并揭示了节点排序的影响。结果显示GRAN优于GraphRNN，而且我们提出的使用深度优先搜索排序的GraphRNN适用于小型图。我们提供了关于数据集选择和节点特征初始化的最佳实践指南。

    A wide variety of generative models for graphs have been proposed. They are used in drug discovery, road networks, neural architecture search, and program synthesis. Generating graphs has theoretical challenges, such as isomorphic representations -- evaluating how well a generative model performs is difficult. Which model to choose depending on the application domain?  We extensively study kernel-based metrics on distributions of graph invariants and manifold-based and kernel-based metrics in graph embedding space. Manifold-based metrics outperform kernel-based metrics in embedding space. We use these metrics to compare GraphRNN and GRAN, two well-known generative models for graphs, and unveil the influence of node orderings. It shows the superiority of GRAN over GraphRNN - further, our proposed adaptation of GraphRNN with a depth-first search ordering is effective for small-sized graphs.  A guideline on good practices regarding dataset selection and node feature initialization is prov
    
[^27]: S-HR-VQVAE: 序列分层残差学习向量量化变分自编码器用于视频预测

    S-HR-VQVAE: Sequential Hierarchical Residual Learning Vector Quantized Variational Autoencoder for Video Prediction. (arXiv:2307.06701v1 [cs.CV])

    [http://arxiv.org/abs/2307.06701](http://arxiv.org/abs/2307.06701)

    S-HR-VQVAE是一种序列分层残差学习向量量化变分自编码器，通过结合分层残差向量量化变分自编码器（HR-VQVAE）和时空PixelCNN（ST-PixelCNN）的能力，解决了视频预测中的主要挑战，并在KTH人体动作和Moving-MNIST任务上取得了较好的实验结果。

    

    我们提出了一种新的模型，将我们最近提出的分层残差向量量化变分自编码器（HR-VQVAE）与一种新颖的时空PixelCNN（ST-PixelCNN）相结合，用来解决视频预测任务。我们将这种方法称为序列分层残差学习向量量化变分自编码器（S-HR-VQVAE）。通过利用HR-VQVAE在对静止图像进行建模时的内在能力和紧凑表示，以及ST-PixelCNN处理时空信息的能力， S-HR-VQVAE能够更好地应对视频预测中的主要挑战，包括学习时空信息、处理高维数据、消除模糊预测和隐式建模物理特性。对KTH人体动作和Moving-MNIST任务的大量实验证明，我们的模型在定量和定性评估方面与顶级视频预测技术相比具有优势。

    We address the video prediction task by putting forth a novel model that combines (i) our recently proposed hierarchical residual vector quantized variational autoencoder (HR-VQVAE), and (ii) a novel spatiotemporal PixelCNN (ST-PixelCNN). We refer to this approach as a sequential hierarchical residual learning vector quantized variational autoencoder (S-HR-VQVAE). By leveraging the intrinsic capabilities of HR-VQVAE at modeling still images with a parsimonious representation, combined with the ST-PixelCNN's ability at handling spatiotemporal information, S-HR-VQVAE can better deal with chief challenges in video prediction. These include learning spatiotemporal information, handling high dimensional data, combating blurry prediction, and implicit modeling of physical characteristics. Extensive experimental results on the KTH Human Action and Moving-MNIST tasks demonstrate that our model compares favorably against top video prediction techniques both in quantitative and qualitative evalu
    
[^28]: IntelliGraphs: 用于评估知识图谱生成的数据集

    IntelliGraphs: Datasets for Benchmarking Knowledge Graph Generation. (arXiv:2307.06698v1 [cs.AI])

    [http://arxiv.org/abs/2307.06698](http://arxiv.org/abs/2307.06698)

    IntelliGraphs是一组新的知识图谱数据集，用于评估知识图谱生成。其中包含具有逻辑规则表达的语义的子图，用于评估子图推断的模型。

    

    知识图谱嵌入（KGE）模型用于学习实体和关系的连续表示。文献中一个关键的任务是预测实体之间的缺失链接。然而，知识图谱不仅仅是链接的集合，还具有其结构中的语义。语义在多个下游任务中至关重要，例如查询回答或推理。我们引入了子图推断任务，其中一个模型必须生成可能的并且语义上有效的子图。我们提出了IntelliGraphs，一个包含五个新的知识图谱数据集的集合。IntelliGraphs数据集包含具有逻辑规则表达的语义的子图，用于评估子图推断。我们还设计了产生合成数据集的数据集生成器。我们设计了四个新的基准模型，其中包括基于传统KGE的三个模型。我们评估了它们的表达能力，并展示了这些模型无法捕捉到语义。我们相信这一基准将促进该领域的发展。

    Knowledge Graph Embedding (KGE) models are used to learn continuous representations of entities and relations. A key task in the literature is predicting missing links between entities. However, Knowledge Graphs are not just sets of links but also have semantics underlying their structure. Semantics is crucial in several downstream tasks, such as query answering or reasoning. We introduce the subgraph inference task, where a model has to generate likely and semantically valid subgraphs. We propose IntelliGraphs, a set of five new Knowledge Graph datasets. The IntelliGraphs datasets contain subgraphs with semantics expressed in logical rules for evaluating subgraph inference. We also present the dataset generator that produced the synthetic datasets. We designed four novel baseline models, which include three models based on traditional KGEs. We evaluate their expressiveness and show that these models cannot capture the semantics. We believe this benchmark will encourage the development
    
[^29]: 走向普遍的语义元宇宙：挑战、方法和机遇

    Towards Ubiquitous Semantic Metaverse: Challenges, Approaches, and Opportunities. (arXiv:2307.06687v1 [cs.HC])

    [http://arxiv.org/abs/2307.06687](http://arxiv.org/abs/2307.06687)

    走向普遍的语义元宇宙：通过人工智能、时空数据表示、语义物联网和语义增强数字孪生实现的智能、上下文感知的交互技术，在远程教育、工作与协作、娱乐与社交、医疗保健和电子商务营销等领域具有重要应用价值。

    

    近年来，普遍的语义元宇宙被研究用来革新增强现实（AR）和虚拟现实（VR）用户的沉浸式网络虚拟体验，利用先进的语义理解与表示来实现在混合现实环境中的无缝、上下文感知的交互。本调查重点关注普遍的语义元宇宙中四个基本系统组件的智能和时空特征，即人工智能（AI）、时空数据表示（STDR）、语义物联网（SIoT）和语义增强数字孪生（SDT）。我们全面调查了这四个基本系统组件的典型技术，使得在普遍的语义元宇宙中能够进行智能、个性化、上下文感知的交互，并给出了典型的使用案例，如远程教育、工作与协作、娱乐与社交、医疗保健和电子商务营销等。

    In recent years, ubiquitous semantic Metaverse has been studied to revolutionize immersive cyber-virtual experiences for augmented reality (AR) and virtual reality (VR) users, which leverages advanced semantic understanding and representation to enable seamless, context-aware interactions within mixed-reality environments. This survey focuses on the intelligence and spatio-temporal characteristics of four fundamental system components in ubiquitous semantic Metaverse, i.e., artificial intelligence (AI), spatio-temporal data representation (STDR), semantic Internet of Things (SIoT), and semantic-enhanced digital twin (SDT). We thoroughly survey the representative techniques of the four fundamental system components that enable intelligent, personalized, and context-aware interactions with typical use cases of the ubiquitous semantic Metaverse, such as remote education, work and collaboration, entertainment and socialization, healthcare, and e-commerce marketing. Furthermore, we outline 
    
[^30]: 使用可解释的人工智能驱动的掩蔽设计进行自监督地震去噪

    Explainable Artificial Intelligence driven mask design for self-supervised seismic denoising. (arXiv:2307.06682v1 [physics.geo-ph])

    [http://arxiv.org/abs/2307.06682](http://arxiv.org/abs/2307.06682)

    本研究提出了使用可解释的人工智能方法进行自监督地震去噪，通过观察去噪网络中的黑盒子，替代对噪声统计的先验知识需求，并通过简单平均化输入像素的雅可比贡献，提供抑制地震数据中噪声的最有效蒙版。

    

    地震数据中存在的相干噪声会导致误差和不确定性，因此尽早和高效地抑制噪声是至关重要的。自监督去噪绕过了深度学习程序通常需要具有噪声-干净训练对的常规要求。然而，自监督相干噪声抑制方法需要对噪声统计的广泛了解。我们提出使用可解释的人工智能方法来观察去噪网络的内部，并利用所获得的知识来替代对噪声本身的任何先验知识的需求。实践中，我们通过利用无偏网络和相关雅可比矩阵所提供的输入和输出之间的直接线性关系，展示了通过对随机选择的若干输入像素的雅可比贡献进行简单平均化，可以提供抑制数据中存在的噪声的最有效蒙版的指示。

    The presence of coherent noise in seismic data leads to errors and uncertainties, and as such it is paramount to suppress noise as early and efficiently as possible. Self-supervised denoising circumvents the common requirement of deep learning procedures of having noisy-clean training pairs. However, self-supervised coherent noise suppression methods require extensive knowledge of the noise statistics. We propose the use of explainable artificial intelligence approaches to see inside the black box that is the denoising network and use the gained knowledge to replace the need for any prior knowledge of the noise itself. This is achieved in practice by leveraging bias-free networks and the direct linear link between input and output provided by the associated Jacobian matrix; we show that a simple averaging of the Jacobian contributions over a number of randomly selected input pixels, provides an indication of the most effective mask to suppress noise present in the data. The proposed me
    
[^31]: DeepIPCv2：利用LiDAR强化自动驾驶环境感知与导航控制

    DeepIPCv2: LiDAR-powered Robust Environmental Perception and Navigational Control for Autonomous Vehicle. (arXiv:2307.06647v1 [cs.RO])

    [http://arxiv.org/abs/2307.06647](http://arxiv.org/abs/2307.06647)

    DeepIPCv2是一种利用LiDAR传感器感知环境的自动驾驶模型，通过使用点云作为感知输入，在各种条件下实现了更强大的驾驶性能。

    

    我们提出了DeepIPCv2，一种利用LiDAR传感器感知环境的自动驾驶模型，以实现更强大的驾驶性能，特别是在光照条件较差的情况下。DeepIPCv2使用一组LiDAR点云作为其主要感知输入。由于点云不受光照变化的影响，它们可以提供清晰的环境观察，无论条件如何。这使得感知模块能够提供更好的场景理解和稳定的特征，从而支持控制模块准确估计导航控制。为了评估其性能，我们通过部署该模型来预测一组驾驶记录并在三种不同条件下进行真实自动驾驶的测试。我们还进行了消融和比较研究，以证明其性能。基于实验结果，DeepIPCv2在所有条件下均显示出强大的驾驶性能。

    We present DeepIPCv2, an autonomous driving model that perceives the environment using a LiDAR sensor for more robust drivability, especially when driving under poor illumination conditions. DeepIPCv2 takes a set of LiDAR point clouds for its main perception input. As point clouds are not affected by illumination changes, they can provide a clear observation of the surroundings no matter what the condition is. This results in a better scene understanding and stable features provided by the perception module to support the controller module in estimating navigational control properly. To evaluate its performance, we conduct several tests by deploying the model to predict a set of driving records and perform real automated driving under three different conditions. We also conduct ablation and comparative studies with some recent models to justify its performance. Based on the experimental results, DeepIPCv2 shows a robust performance by achieving the best drivability in all conditions. C
    
[^32]: 使用通用强化学习的图像转换序列检索

    Image Transformation Sequence Retrieval with General Reinforcement Learning. (arXiv:2307.06630v1 [cs.CV])

    [http://arxiv.org/abs/2307.06630](http://arxiv.org/abs/2307.06630)

    本文提出了一种使用通用强化学习的图像转换序列检索（ITSR）任务，并结合深度神经网络。通过在合成和真实领域进行实验，结果显示使用蒙特卡洛树搜索训练的模型在最简单和最复杂的情况下都能胜过监督训练的模型。

    

    在这项工作中，提出了一种新颖的图像转换序列检索（ITSR）任务，在这个任务中，模型必须检索出作为源和目标的两个给定图像之间的转换序列。鉴于挑战的某些特征，例如正确序列的多样性或过程的连续步骤之间的相关性，我们提出了一种使用通用模型基于强化学习（例如蒙特卡洛树搜索）的ITSR解决方案，结合了深度神经网络。我们的实验在合成和真实领域提供了一个基准，将所提出的方法与监督训练进行了比较。结果表明，使用蒙特卡洛树搜索训练的模型在最简单和最复杂的情况下都能胜过监督训练的模型。我们的工作对ITSR的本质及其相关挑战提出了有趣的结论。

    In this work, the novel Image Transformation Sequence Retrieval (ITSR) task is presented, in which a model must retrieve the sequence of transformations between two given images that act as source and target, respectively. Given certain characteristics of the challenge such as the multiplicity of a correct sequence or the correlation between consecutive steps of the process, we propose a solution to ITSR using a general model-based Reinforcement Learning such as Monte Carlo Tree Search (MCTS), which is combined with a deep neural network. Our experiments provide a benchmark in both synthetic and real domains, where the proposed approach is compared with supervised training. The results report that a model trained with MCTS is able to outperform its supervised counterpart in both the simplest and the most complex cases. Our work draws interesting conclusions about the nature of ITSR and its associated challenges.
    
[^33]: SecureFalcon:下一代面向网络安全的网络推理系统

    SecureFalcon: The Next Cyber Reasoning System for Cyber Security. (arXiv:2307.06616v1 [cs.CR])

    [http://arxiv.org/abs/2307.06616](http://arxiv.org/abs/2307.06616)

    SecureFalcon是基于FalconLLM的网络推理系统，通过微调FalconLLM来实现网络安全应用，能够识别C代码样本中的漏洞和非漏洞内容。

    

    软件漏洞导致各种不利影响，如崩溃、数据丢失和安全漏洞，严重影响软件应用和系统的市场采用率。尽管传统的方法，如自动化软件测试、故障定位和修复已经得到广泛研究，但静态分析工具最常用且有固有的误报率，给开发人员的生产力带来了实质性挑战。大型语言模型（LLM）为这些持久问题提供了有希望的解决方案。其中，FalconLLM在识别复杂模式和漏洞方面显示出重要潜力，因此在软件漏洞检测中至关重要。在本文中，我们首次对FalconLLM进行了针对网络安全应用的微调，从而推出了SecureFalcon，这是基于FalconLLM的创新模型架构。SecureFalcon被训练用于区分有漏洞和无漏洞的C代码样本。

    Software vulnerabilities leading to various detriments such as crashes, data loss, and security breaches, significantly hinder the quality, affecting the market adoption of software applications and systems. Although traditional methods such as automated software testing, fault localization, and repair have been intensively studied, static analysis tools are most commonly used and have an inherent false positives rate, posing a solid challenge to developer productivity. Large Language Models (LLMs) offer a promising solution to these persistent issues. Among these, FalconLLM has shown substantial potential in identifying intricate patterns and complex vulnerabilities, hence crucial in software vulnerability detection. In this paper, for the first time, FalconLLM is being fine-tuned for cybersecurity applications, thus introducing SecureFalcon, an innovative model architecture built upon FalconLLM. SecureFalcon is trained to differentiate between vulnerable and non-vulnerable C code sam
    
[^34]: 将基础模型作为代理模型引入：朝着更实用的对抗攻击迈进

    Introducing Foundation Models as Surrogate Models: Advancing Towards More Practical Adversarial Attacks. (arXiv:2307.06608v1 [cs.LG])

    [http://arxiv.org/abs/2307.06608](http://arxiv.org/abs/2307.06608)

    本文将对抗攻击重新设定为下游任务，通过生成图像噪声来满足新兴趋势，并将基础模型引入作为代理模型。虽然基础模型的表现不佳，但通过在特征空间中进行分析，我们发现缺乏对应的特征。

    

    最近，无盒对抗攻击成为了最实用且具有挑战性的攻击方式，攻击者无法访问模型的架构、权重和训练数据。然而，在无盒设置中，对于代理模型选择过程的潜力和灵活性缺乏认识。受到利用基础模型解决下游任务的兴趣的启发，本文采用了1）将对抗攻击重新设定为下游任务，具体而言，是生成图像噪声以满足新兴趋势；2）将基础模型引入作为代理模型的创新思想。通过利用非鲁棒特征的概念，我们阐述了选择代理模型的两个指导原则，以解释为什么基础模型是这一角色的最佳选择。然而，矛盾地的是，我们观察到这些基础模型表现不佳。通过在特征空间中分析这种意外行为，我们归因于缺乏上述指导原则所需的特征。

    Recently, the no-box adversarial attack, in which the attacker lacks access to the model's architecture, weights, and training data, become the most practical and challenging attack setup. However, there is an unawareness of the potential and flexibility inherent in the surrogate model selection process on no-box setting. Inspired by the burgeoning interest in utilizing foundational models to address downstream tasks, this paper adopts an innovative idea that 1) recasting adversarial attack as a downstream task. Specifically, image noise generation to meet the emerging trend and 2) introducing foundational models as surrogate models. Harnessing the concept of non-robust features, we elaborate on two guiding principles for surrogate model selection to explain why the foundational model is an optimal choice for this role. However, paradoxically, we observe that these foundational models underperform. Analyzing this unexpected behavior within the feature space, we attribute the lackluster
    
[^35]: 基于便携设备的眼底视频数据集用于视网膜血管分割

    RVD: A Handheld Device-Based Fundus Video Dataset for Retinal Vessel Segmentation. (arXiv:2307.06577v1 [cs.CV])

    [http://arxiv.org/abs/2307.06577](http://arxiv.org/abs/2307.06577)

    本研究介绍了首个基于便携设备进行数据获取的基于视频的视网膜数据集，该数据集包含635个由智能手机采集的眼底视频，并提供了在空间和时间维度上对视网膜结构进行全面和精确标注的数据，旨在推进血管分割的发展。

    

    通常，视网膜血管分割建立在使用台式设备采集的基于图像的数据集上。静态图像自然丧失了视网膜波动的动态特性，导致数据集的丰富性降低，而台式设备的使用进一步限制了数据集的可扩展性，因为其受限的可访问性。考虑到这些限制，我们首次利用便携设备进行数据获取，引入了第一个基于视频的视网膜数据集。该数据集包括从四个不同诊所收集的635个基于智能手机的眼底视频，涉及415名50至75岁的患者。它在空间和时间维度上提供了视网膜结构的全面和精确的标注，旨在推进血管分割的发展。具体而言，该数据集提供三个层次的空间标注：用于整体视网膜结构描绘的二值血管掩膜、用于区分静脉和动脉的常规静脉-动脉掩膜，以及...

    Retinal vessel segmentation is generally grounded in image-based datasets collected with bench-top devices. The static images naturally lose the dynamic characteristics of retina fluctuation, resulting in diminished dataset richness, and the usage of bench-top devices further restricts dataset scalability due to its limited accessibility. Considering these limitations, we introduce the first video-based retinal dataset by employing handheld devices for data acquisition. The dataset comprises 635 smartphone-based fundus videos collected from four different clinics, involving 415 patients from 50 to 75 years old. It delivers comprehensive and precise annotations of retinal structures in both spatial and temporal dimensions, aiming to advance the landscape of vasculature segmentation. Specifically, the dataset provides three levels of spatial annotations: binary vessel masks for overall retinal structure delineation, general vein-artery masks for distinguishing the vein and artery, and fi
    
[^36]: 在资源限制下的处方过程监控：一种强化学习方法

    Prescriptive Process Monitoring Under Resource Constraints: A Reinforcement Learning Approach. (arXiv:2307.06564v1 [cs.AI])

    [http://arxiv.org/abs/2307.06564](http://arxiv.org/abs/2307.06564)

    本论文提出了一种在资源限制下进行处方过程监控的强化学习方法。通过考虑对干预需求、及时性或效果预测的不确定性和资源利用水平，来触发干预，从而优化业务过程的性能。

    

    处方过程监控方法旨在通过在运行时触发干预来优化业务过程的性能，从而增加正面案例结果的概率。这些干预是根据干预策略触发的。强化学习被提出作为通过试错学习干预策略的一种方法。然而，现有方法在这一领域假设可用于执行干预的资源数量是无限的，这在实践中是不现实的。本文认为，在资源限制的情况下，处方过程监控领域面临的一个关键困境是基于对干预需求、及时性或效果的预测的不确定性和资源利用水平来触发干预。实际上，当对干预的必要性或效果存在高度不确定性时，将有限的资源用于干预是一项挑战。

    Prescriptive process monitoring methods seek to optimize the performance of business processes by triggering interventions at runtime, thereby increasing the probability of positive case outcomes. These interventions are triggered according to an intervention policy. Reinforcement learning has been put forward as an approach to learning intervention policies through trial and error. Existing approaches in this space assume that the number of resources available to perform interventions in a process is unlimited, an unrealistic assumption in practice. This paper argues that, in the presence of resource constraints, a key dilemma in the field of prescriptive process monitoring is to trigger interventions based not only on predictions of their necessity, timeliness, or effect but also on the uncertainty of these predictions and the level of resource utilization. Indeed, committing scarce resources to an intervention when the necessity or effects of this intervention are highly uncertain m
    
[^37]: 逆强化学习中的有效时间视野研究

    On the Effective Horizon of Inverse Reinforcement Learning. (arXiv:2307.06541v1 [cs.LG])

    [http://arxiv.org/abs/2307.06541](http://arxiv.org/abs/2307.06541)

    本研究分析了逆强化学习中时间视野的重要性，发现短于实际值的有效时间视野可以更快且更准确地估计奖励函数，减轻过拟合问题。此外，研究还呼吁在IRL中同时学习奖励和有效时间视野。

    

    逆强化学习（IRL）算法通常依赖于基于给定时间视野的（前向）强化学习或规划来计算一个近似最优策略，然后将该策略与专家演示匹配。时间视野在确定奖励估计的准确性和IRL算法的计算效率方面起着关键作用。有趣的是，比地面实际值更短的有效时间视野通常能更快地产生更好的结果。本文对此现象进行了正式分析并给出了解释：时间视野控制了引发策略类的复杂性，并在有限数据下减轻过拟合。这一分析为IRL的有效视野选择提供了原则性指导。它也促使我们重新审视经典的IRL公式：与仅具有给定视野的奖励相比，共同学习奖励和有效视野更加自然。我们的实验进一步验证了这一观点。

    Inverse reinforcement learning (IRL) algorithms often rely on (forward) reinforcement learning or planning over a given time horizon to compute an approximately optimal policy for a hypothesized reward function and then match this policy with expert demonstrations. The time horizon plays a critical role in determining both the accuracy of reward estimate and the computational efficiency of IRL algorithms. Interestingly, an effective time horizon shorter than the ground-truth value often produces better results faster. This work formally analyzes this phenomenon and provides an explanation: the time horizon controls the complexity of an induced policy class and mitigates overfitting with limited data. This analysis leads to a principled choice of the effective horizon for IRL. It also prompts us to reexamine the classic IRL formulation: it is more natural to learn jointly the reward and the effective horizon together rather than the reward alone with a given horizon. Our experimental re
    
[^38]: 药物发现中的人工智能：我们已经到达了吗？

    Artificial Intelligence for Drug Discovery: Are We There Yet?. (arXiv:2307.06521v1 [cs.AI])

    [http://arxiv.org/abs/2307.06521](http://arxiv.org/abs/2307.06521)

    本综述讨论了人工智能在药物发现中的应用，重点关注小分子药物。通过使用生成化学、机器学习和多属性优化等人工智能技术，已有多种化合物进入了临床试验。科学界必须仔细审查已知信息，以解决可重复性危机。只有具有足够的真实基准和适当的训练数据，才能实现人工智能在药物发现中的全部潜力。

    

    药物发现正在适应数据科学、信息学和人工智能等新技术，以加快有效治疗的开发，同时降低成本和动物实验。人工智能正在改变药物发现，投资者、工业和学术科学家以及立法者对此越来越感兴趣。成功的药物发现需要优化与药理动力学、药代动力学和临床结果相关的性质。本综述讨论了人工智能在药物发现的三个支柱：疾病、靶点和治疗模式中的应用，重点关注小分子药物。生成化学、机器学习和多属性优化等人工智能技术使得多种化合物进入了临床试验。科学界必须仔细审查已知信息，以解决可重复性危机。只有具有足够的真实基准和适当的训练数据，才能实现人工智能在药物发现中的全部潜力。

    Drug discovery is adapting to novel technologies such as data science, informatics, and artificial intelligence (AI) to accelerate effective treatment development while reducing costs and animal experiments. AI is transforming drug discovery, as indicated by increasing interest from investors, industrial and academic scientists, and legislators. Successful drug discovery requires optimizing properties related to pharmacodynamics, pharmacokinetics, and clinical outcomes. This review discusses the use of AI in the three pillars of drug discovery: diseases, targets, and therapeutic modalities, with a focus on small molecule drugs. AI technologies, such as generative chemistry, machine learning, and multi-property optimization, have enabled several compounds to enter clinical trials. The scientific community must carefully vet known information to address the reproducibility crisis. The full potential of AI in drug discovery can only be realized with sufficient ground truth and appropriate
    
[^39]: 利用上下文反事实推理实现信念校准

    Leveraging Contextual Counterfactuals Toward Belief Calibration. (arXiv:2307.06513v1 [cs.AI])

    [http://arxiv.org/abs/2307.06513](http://arxiv.org/abs/2307.06513)

    本文讨论了通过引入上下文反事实推理来准确校准AI系统中的信念的问题。研究发现，在高后悔情况下，上下文反事实和补救成本对于更新决策者的信念以及所持信念的强度至关重要。通过将信念的多样性分成两类:主观性和认识不确定性，可以更好地理解和处理信念的校准问题。

    

    通过调整数据采集原则或正则化训练过程中的损失函数等方式，人的信念和价值越来越多地被融入到我们的AI系统中。然而，元对齐问题是人类信念的多样性以及跨群体的不对齐性，而且即使在人类之间，每个信念的隐含强度也可能不好校准，特别是在尝试跨上下文进行推广时。具体而言，在高后悔情况下，我们观察到上下文反事实和补救成本对于更新决策者的信念以及所持信念的强度至关重要。因此，我们认为在对齐过程中引入反事实推理是准确校准信念的关键。为此，我们首先将信念的多样性分为两类：主观性（同一群体内的个体间）和认识不确定性（同一人在不同环境中）

    Beliefs and values are increasingly being incorporated into our AI systems through alignment processes, such as carefully curating data collection principles or regularizing the loss function used for training. However, the meta-alignment problem is that these human beliefs are diverse and not aligned across populations; furthermore, the implicit strength of each belief may not be well calibrated even among humans, especially when trying to generalize across contexts. Specifically, in high regret situations, we observe that contextual counterfactuals and recourse costs are particularly important in updating a decision maker's beliefs and the strengths to which such beliefs are held. Therefore, we argue that including counterfactuals is key to an accurate calibration of beliefs during alignment. To do this, we first segment belief diversity into two categories: subjectivity (across individuals within a population) and epistemic uncertainty (within an individual across different contexts
    
[^40]: 用潜在扩散模型改进非酒精性脂肪性肝病分类性能

    Improving Nonalcoholic Fatty Liver Disease Classification Performance With Latent Diffusion Models. (arXiv:2307.06507v1 [cs.CV])

    [http://arxiv.org/abs/2307.06507](http://arxiv.org/abs/2307.06507)

    本研究通过结合使用扩散模型生成的合成图像和真实图像，提高了非酒精性脂肪性肝病分类的性能。

    

    将深度学习与临床专业知识相结合在解决医疗挑战和提供改进诊断工具方面具有很大潜力。然而，往往需要有注释的医学图像成为充分利用机器学习模型强大能力的障碍。我们的研究表明，通过结合使用扩散模型生成的合成图像和真实图像，我们可以提高非酒精性脂肪性肝病（NAFLD）的分类性能。我们通过比较两个指标来评估合成图像的质量：基于扩散生成的图像和生成对抗网络（GANs）生成的图像计算的Inception Score（IS）和Fr\'{e}chet Inception Distance（FID）。我们的结果显示，扩散生成的图像具有卓越的性能，最大IS得分为1.90，而GANs为1.67，最小FID得分为69.45，而GANs为99.53。利用部分冻结的CNN骨干（EfficientNet v1）。

    Integrating deep learning with clinical expertise holds great potential for addressing healthcare challenges and empowering medical professionals with improved diagnostic tools. However, the need for annotated medical images is often an obstacle to leveraging the full power of machine learning models. Our research demonstrates that by combining synthetic images, generated using diffusion models, with real images, we can enhance nonalcoholic fatty liver disease (NAFLD) classification performance. We evaluate the quality of the synthetic images by comparing two metrics: Inception Score (IS) and Fr\'{e}chet Inception Distance (FID), computed on diffusion-generated images and generative adversarial networks (GANs)-generated images. Our results show superior performance for the diffusion-generated images, with a maximum IS score of $1.90$ compared to $1.67$ for GANs, and a minimum FID score of $69.45$ compared to $99.53$ for GANs. Utilizing a partially frozen CNN backbone (EfficientNet v1),
    
[^41]: 通过集成深度强化学习的混合控制策略实现人工胰腺

    Hybrid Control Policy for Artificial Pancreas via Ensemble Deep Reinforcement Learning. (arXiv:2307.06501v1 [cs.AI])

    [http://arxiv.org/abs/2307.06501](http://arxiv.org/abs/2307.06501)

    本研究提出了一种名为HyCPAP的混合控制策略，通过结合模型预测控制和集成深度强化学习，并充分利用它们各自的优势，以解决人工胰腺的复杂生理过程、延迟胰岛素反应和不准确血糖测量等挑战。

    

    目标：人工胰腺(AP)在实现1型糖尿病患者闭环血糖控制方面显示出有希望的潜力。然而，由于复杂的生理过程、延迟的胰岛素反应和不准确的血糖测量，设计一种有效的AP控制策略仍然具有挑战性。虽然模型预测控制(MPC)通过动态模型和安全约束提供了安全性和稳定性，但其缺乏个性化，并且受到未宣布的饮食影响。相反，深度强化学习(DRL)提供了个性化和自适应策略，但面临分布偏移和大量数据需求的挑战。方法：我们提出了一种混合控制策略，即HyCPAP，来应对上述挑战。HyCPAP将MPC策略与集成DRL策略相结合，充分利用两种策略的优势，同时弥补各自的局限性。

    Objective: The artificial pancreas (AP) has shown promising potential in achieving closed-loop glucose control for individuals with type 1 diabetes mellitus (T1DM). However, designing an effective control policy for the AP remains challenging due to the complex physiological processes, delayed insulin response, and inaccurate glucose measurements. While model predictive control (MPC) offers safety and stability through the dynamic model and safety constraints, it lacks individualization and is adversely affected by unannounced meals. Conversely, deep reinforcement learning (DRL) provides personalized and adaptive strategies but faces challenges with distribution shifts and substantial data requirements. Methods: We propose a hybrid control policy for the artificial pancreas (HyCPAP) to address the above challenges. HyCPAP combines an MPC policy with an ensemble DRL policy, leveraging the strengths of both policies while compensating for their respective limitations. To facilitate faste
    
[^42]: 基于微生物遗传算法的黑箱攻击对抗可解释深度学习系统

    Microbial Genetic Algorithm-based Black-box Attack against Interpretable Deep Learning Systems. (arXiv:2307.06496v1 [cs.CV])

    [http://arxiv.org/abs/2307.06496](http://arxiv.org/abs/2307.06496)

    这项工作提出了一种基于微生物遗传算法的黑箱攻击方法，QuScore，对抗对解释模型进行耦合的可解释深度学习系统(IDLSes)。该方法能够在不了解目标模型的情况下，通过转移和评分方法减少查询次数，实现成功的攻击。

    

    深度学习模型在白盒和黑盒环境中容易受到对抗样本的攻击。虽然先前的研究表明攻击成功率很高，但将DNN模型与解释模型相结合可以在人类专家介入时提供一种安全感，人类专家可以确定所给样本是良性的还是恶意的。然而，在白盒环境中，可解释的深度学习系统(IDLSes)易受恶意篡改的攻击。在黑盒设置中，由于对IDLSes组件的访问受限，对手更难以欺骗系统。在这项工作中，我们提出了一种基于查询效率和评分的黑箱攻击IDLSes的方法，称为QuScore，它不需要了解目标模型及其耦合的解释模型。QuScore基于转移和评分方法，采用一种有效的微生物遗传算法。我们的方法旨在减少必要的查询数量以进行成功的攻击。

    Deep learning models are susceptible to adversarial samples in white and black-box environments. Although previous studies have shown high attack success rates, coupling DNN models with interpretation models could offer a sense of security when a human expert is involved, who can identify whether a given sample is benign or malicious. However, in white-box environments, interpretable deep learning systems (IDLSes) have been shown to be vulnerable to malicious manipulations. In black-box settings, as access to the components of IDLSes is limited, it becomes more challenging for the adversary to fool the system. In this work, we propose a Query-efficient Score-based black-box attack against IDLSes, QuScore, which requires no knowledge of the target model and its coupled interpretation model. QuScore is based on transfer-based and score-based methods by employing an effective microbial genetic algorithm. Our method is designed to reduce the number of queries necessary to carry out success
    
[^43]: 自动化内容分析中的错误分类导致回归分析中的偏差。我们能修复吗？是的，我们能！

    Misclassification in Automated Content Analysis Causes Bias in Regression. Can We Fix It? Yes We Can!. (arXiv:2307.06483v1 [cs.LG])

    [http://arxiv.org/abs/2307.06483](http://arxiv.org/abs/2307.06483)

    传播学领域中的自动化内容分析常忽视了错误分类的偏差，我们介绍并测试了统计方法来纠正这种偏差，并设计了一种新方法来修复之。

    

    自动分类器（ACs）通常通过监督式机器学习（SML）构建，可以对从文本到图片和视频的大量数据进行分类，已经成为传播科学和相关领域中广泛流行的测量设备。尽管如此，即使是高度准确的分类器也会产生错误，这导致了错误分类的偏差和下游分析中误导性的结果，除非这些分析考虑到这些错误。通过对SML应用的系统文献综述，我们发现传播学者在很大程度上忽视了错误分类的偏差。原则上，现有的统计方法可以使用“黄金标准”验证数据（如由人类注释者创建的数据）来纠正错误分类的偏差，并产生一致的估计。我们介绍并测试了这些方法，包括我们在R包misclassificationmodels中设计和实现的一种新方法，通过蒙特卡洛模拟来揭示每种方法的局限性。

    Automated classifiers (ACs), often built via supervised machine learning (SML), can categorize large, statistically powerful samples of data ranging from text to images and video, and have become widely popular measurement devices in communication science and related fields. Despite this popularity, even highly accurate classifiers make errors that cause misclassification bias and misleading results in downstream analyses-unless such analyses account for these errors. As we show in a systematic literature review of SML applications, communication scholars largely ignore misclassification bias. In principle, existing statistical methods can use "gold standard" validation data, such as that created by human annotators, to correct misclassification bias and produce consistent estimates. We introduce and test such methods, including a new method we design and implement in the R package misclassificationmodels, via Monte Carlo simulations designed to reveal each method's limitations, which 
    
[^44]: 高效可验证的强唯一可解谜题与矩阵乘法

    Efficiently-Verifiable Strong Uniquely Solvable Puzzles and Matrix Multiplication. (arXiv:2307.06463v1 [cs.CC])

    [http://arxiv.org/abs/2307.06463](http://arxiv.org/abs/2307.06463)

    本论文在Cohn-Umans框架上提出了一种高效可验证的强唯一可解谜题（SUSP）的新子类，名为可简化的SUSPs。研究结果表明，可简化的SUSPs可以达到与无穷族SUSPs相同的矩阵乘法指数边界，并且通过计算机搜索构造了更大的SUSPs，进一步提高了矩阵乘法指数的上界。

    

    我们推进了Cohn-Umans框架，用于开发快速矩阵乘法算法。我们引入、分析和寻找了一种新的强唯一可解谜题（SUSP）的子类，称为可简化的SUSPs。我们证明了这些谜题可以高效地进行验证，而对于一般的SUSPs，这仍然是一个未解之谜。我们还展示了可简化的SUSPs可以达到与无穷族SUSPs相同的矩阵乘法指数$\omega$边界。根据计算机搜索，我们报告了宽度较小的SUSPs的更大构造，这与我们更紧密的分析相结合，将矩阵乘法指数的上界从$2.66$增强到$2.505$，接近Cohn等人手工构造的结果。

    We advance the Cohn-Umans framework for developing fast matrix multiplication algorithms. We introduce, analyze, and search for a new subclass of strong uniquely solvable puzzles (SUSP), which we call simplifiable SUSPs. We show that these puzzles are efficiently verifiable, which remains an open question for general SUSPs. We also show that individual simplifiable SUSPs can achieve the same strength of bounds on the matrix multiplication exponent $\omega$ that infinite families of SUSPs can. We report on the construction, by computer search, of larger SUSPs than previously known for small width. This, combined with our tighter analysis, strengthens the upper bound on the matrix multiplication exponent from $2.66$ to $2.505$ obtainable via this computational approach, and nears the results of the handcrafted constructions of Cohn et al.
    
[^45]: 没有训练就没有收益：重新审视基于Transformer的语言模型的高效训练算法

    No Train No Gain: Revisiting Efficient Training Algorithms For Transformer-based Language Models. (arXiv:2307.06440v1 [cs.LG])

    [http://arxiv.org/abs/2307.06440](http://arxiv.org/abs/2307.06440)

    本论文重新审视了基于Transformer的语言模型的高效训练算法，包括动态架构，批量选择和高效优化器。然而，在使用这些算法预训练时，相对于基线方法，它们的训练、验证和下游收益消失了。同时，论文提出了一个评估协议来进行计算，并释放了代码来促进高效训练的研究。

    

    近年来，训练Transformer-based语言模型所需的计算量急剧增加。这一趋势促使研究者们开展了针对高效训练算法的研究，旨在比标准训练更快地改善训练、验证和下游性能。在这项工作中，我们重新审视了三类这样的算法：动态架构（层叠、层丢弃）、批量选择（选择性反向传播、RHO损失）和高效优化器（Lion、Sophia）。当使用这些方法在固定计算预算下对BERT和T5进行预训练时，我们发现它们的训练、验证和下游收益相对于一个具有完全衰减学习率的基线而言会消失。我们定义了一个评估协议，可以通过将所有计算时间映射到一个称为参考系统时间的参考机器上，在任意机器上进行计算。我们讨论了我们提出的协议的局限性，并发布了我们的代码，以鼓励对高效训练的严格研究。

    The computation necessary for training Transformer-based language models has skyrocketed in recent years. This trend has motivated research on efficient training algorithms designed to improve training, validation, and downstream performance faster than standard training. In this work, we revisit three categories of such algorithms: dynamic architectures (layer stacking, layer dropping), batch selection (selective backprop, RHO loss), and efficient optimizers (Lion, Sophia). When pre-training BERT and T5 with a fixed computation budget using such methods, we find that their training, validation, and downstream gains vanish compared to a baseline with a fully-decayed learning rate. We define an evaluation protocol that enables computation to be done on arbitrary machines by mapping all computation time to a reference machine which we call reference system time. We discuss the limitations of our proposed protocol and release our code to encourage rigorous research in efficient training p
    
[^46]: 为生物医学知识提取而蒸馏大型语言模型：对药物不良事件的案例研究

    Distilling Large Language Models for Biomedical Knowledge Extraction: A Case Study on Adverse Drug Events. (arXiv:2307.06439v1 [cs.CL])

    [http://arxiv.org/abs/2307.06439](http://arxiv.org/abs/2307.06439)

    本研究通过将大型语言模型蒸馏为特定任务的学生模型，成功地提升了在药物不良事件提取方面的性能，并在不使用标记数据的情况下达到了与监督式最先进模型相当的准确性，具有成本、效率和白盒模型访问等优势。

    

    大型语言模型（LLMs），如GPT-4，在包括健康应用在内的各种任务中展示了卓越的能力。本文研究了如何利用LLMs来扩展生物医学知识整理。我们发现，尽管LLMs已经具备了结构化生物医学文本的良好能力，但通过自监督学习将其蒸馏为特定任务的学生模型可以取得显著的改进，同时具备成本、效率和白盒模型访问等额外优势。我们对不良药物事件（ADE）提取进行了案例研究，这是改进医疗的重要领域。在标准ADE提取评估中，经蒸馏的GPT-3.5 PubMedBERT模型在不使用任何标记数据的情况下，达到了与监督式最先进模型相当的准确性。尽管体积缩小了1000多倍，但蒸馏模型在F1指标上超过了其教师GPT-3.5约6个绝对点，超过了GPT-4约5个绝对点。

    Large language models (LLMs), such as GPT-4, have demonstrated remarkable capabilities across a wide range of tasks, including health applications. In this paper, we study how LLMs can be used to scale biomedical knowledge curation. We find that while LLMs already possess decent competency in structuring biomedical text, by distillation into a task-specific student model through self-supervised learning, substantial gains can be attained over out-of-box LLMs, with additional advantages such as cost, efficiency, and white-box model access.  We conduct a case study on adverse drug event (ADE) extraction, which is an important area for improving care. On standard ADE extraction evaluation, a GPT-3.5 distilled PubMedBERT model attained comparable accuracy as supervised state-of-the-art models without using any labeled data. Despite being over 1,000 times smaller, the distilled model outperformed its teacher GPT-3.5 by over 6 absolute points in F1 and GPT-4 by over 5 absolute points.  Ablat
    
[^47]: 从面向目标的LTLf公式设计行为树

    Designing Behavior Trees from Goal-Oriented LTLf Formulas. (arXiv:2307.06399v1 [cs.AI])

    [http://arxiv.org/abs/2307.06399](http://arxiv.org/abs/2307.06399)

    本论文介绍了一种将使用有限访问线性时态逻辑（LTL）的子集指定的目标转化为行为树（BT）的方法，并展示了通过这种方法能够解决一些规划问题。

    

    时间逻辑可以用于形式化指定自主代理目标，但合成能够保证目标满足的计划者可能具有计算上的限制。本文展示了如何将使用有限访问线性时态逻辑（LTL）的子集指定的目标转化为保证成功路径满足LTL目标的行为树（BT）。可以使用以实现目标为导向的任务任务语法来提取有用的LTL公式，其中由LTL运算符组合的任务构成任务。通过LTL公式构建BT导致了一种放松的行为合成问题，在该问题中，各种计划者可以实现BT中的动作节点。重要的是，计划者导致的任何成功路径都满足相应的LTL公式。该方法的有用性通过两种方式进行了演示：a) 探索两个计划者和LTL目标之间的对齐，b) 解决Fetch机器人的顺序门锁问题。

    Temporal logic can be used to formally specify autonomous agent goals, but synthesizing planners that guarantee goal satisfaction can be computationally prohibitive. This paper shows how to turn goals specified using a subset of finite trace Linear Temporal Logic (LTL) into a behavior tree (BT) that guarantees that successful traces satisfy the LTL goal. Useful LTL formulas for achievement goals can be derived using achievement-oriented task mission grammars, leading to missions made up of tasks combined using LTL operators. Constructing BTs from LTL formulas leads to a relaxed behavior synthesis problem in which a wide range of planners can implement the action nodes in the BT. Importantly, any successful trace induced by the planners satisfies the corresponding LTL formula. The usefulness of the approach is demonstrated in two ways: a) exploring the alignment between two planners and LTL goals, and b) solving a sequential key-door problem for a Fetch robot.
    
[^48]: 用颜色和深度图像进行面部微表情分析的介绍：Matlab编程方法（第二版，2023）

    Introduction to Facial Micro Expressions Analysis Using Color and Depth Images: A Matlab Coding Approach (Second Edition, 2023). (arXiv:2307.06396v1 [cs.CV])

    [http://arxiv.org/abs/2307.06396](http://arxiv.org/abs/2307.06396)

    该书介绍了用颜色和深度图像进行面部微表情分析的方法，通过MATLAB编程实现。它适用于初学者到专业读者，并提供了理论描述和可重现的实例。

    

    该书试图通过MATLAB编程环境引入颜色和深度图像在面部微表情识别（FMER）领域的温和介绍。FMER是图像处理的一个子集，是一个跨学科的分析主题。因此，它需要熟悉人工智能（AI）的其他主题，如机器学习、数字图像处理、心理学等。所以，为AI领域的初学者到专业读者编写一本涵盖所有这些主题的书籍是一个很好的机会，甚至没有AI背景的读者也可以从中受益。我们的目标是提供一本独立的介绍性书籍，以理论描述的形式介绍MFER分析领域，供没有图像处理背景的读者参考，并附有可重现的Matlab实际示例。此外，我们还描述了FMER分析和在文本中使用的MATLAB库的任何基本定义，以帮助读者将实验应用于真实世界应用。

    The book attempts to introduce a gentle introduction to the field of Facial Micro Expressions Recognition (FMER) using Color and Depth images, with the aid of MATLAB programming environment. FMER is a subset of image processing and it is a multidisciplinary topic to analysis. So, it requires familiarity with other topics of Artifactual Intelligence (AI) such as machine learning, digital image processing, psychology and more. So, it is a great opportunity to write a book which covers all of these topics for beginner to professional readers in the field of AI and even without having background of AI. Our goal is to provide a standalone introduction in the field of MFER analysis in the form of theorical descriptions for readers with no background in image processing with reproducible Matlab practical examples. Also, we describe any basic definitions for FMER analysis and MATLAB library which is used in the text, that helps final reader to apply the experiments in the real-world applicatio
    
[^49]: 使用ChatGPT的有效侦察技术最大化渗透测试的成功

    Maximizing Penetration Testing Success with Effective Reconnaissance Techniques using ChatGPT. (arXiv:2307.06391v1 [cs.CR])

    [http://arxiv.org/abs/2307.06391](http://arxiv.org/abs/2307.06391)

    使用ChatGPT进行侦察阶段的渗透测试，能够获取有价值的情报数据，提高有效性和效率。

    

    ChatGPT是一种使用人工智能实现的聊天机器人，通过生成式预训练转换器语言模型，能够对各种问题提供非常详细的回答。作为一种非常现代的现象，这个工具具有许多潜在的用例尚未被探索。ChatGPT在广泛的潜在主题上具有大量信息，可以为许多信息安全用例增加价值，无论是从效率角度还是提供另一种安全信息来源，可用于帮助保护组织的互联网可访问资产。侦察阶段是受益于ChatGPT的信息安全实践之一。本研究采用案例研究方法探索和调查ChatGPT在获得有价值的侦察数据方面的用途。ChatGPT能够提供许多类型的有关目标属性的情报，包括互联网网络拓扑、网络服务等。

    ChatGPT is a generative pretrained transformer language model created using artificial intelligence implemented as chatbot which can provide very detailed responses to a wide variety of questions. As a very contemporary phenomenon, this tool has a wide variety of potential use cases that have yet to be explored. With the significant extent of information on a broad assortment of potential topics, ChatGPT could add value to many information security uses cases both from an efficiency perspective as well as to offer another source of security information that could be used to assist with securing Internet accessible assets of organizations. One information security practice that could benefit from ChatGPT is the reconnaissance phase of penetration testing. This research uses a case study methodology to explore and investigate the uses of ChatGPT in obtaining valuable reconnaissance data. ChatGPT is able to provide many types of intel regarding targeted properties which includes Internet 
    
[^50]: 重新思考答案集编程模板

    Rethinking Answer Set Programming Templates. (arXiv:2307.06382v1 [cs.AI])

    [http://arxiv.org/abs/2307.06382](http://arxiv.org/abs/2307.06382)

    本文提出了一种答案集编程模板的概念，通过使用简单的命名约定，强制某些谓词的局部性，从而实现了对模板预期结果的不变性，并且避免了名称冲突。

    

    在命令式编程中，领域驱动设计方法论通过将领域中的不变量体现在代码中，帮助应对软件开发的复杂性。代码更清晰、更安全，因为任何隐含的假设都被移除，转而使用不变量，从而实现快速失败的思维方式并立即报告未预期的条件。本文介绍了一种答案集编程模板的概念，除了遵循不重复自己原则外，还通过简单的命名约定强制某些谓词的局部性。局部谓词被映射到主流引擎采用的通用全局命名空间，使用全局唯一标识符来避免名称冲突。这种方式，局部谓词可以用于在可能为空的应用上下文中强制执行对模板预期结果的不变性，而不受其他可以添加到该上下文的规则的影响。使用这种方式转换的模板应用可以被处理。

    In imperative programming, the Domain-Driven Design methodology helps in coping with the complexity of software development by materializing in code the invariants of a domain of interest. Code is cleaner and more secure because any implicit assumption is removed in favor of invariants, thus enabling a fail fast mindset and the immediate reporting of unexpected conditions. This article introduces a notion of template for Answer Set Programming that, in addition to the don't repeat yourself principle, enforces locality of some predicates by means of a simple naming convention. Local predicates are mapped to the usual global namespace adopted by mainstream engines, using universally unique identifiers to avoid name clashes. This way, local predicates can be used to enforce invariants on the expected outcome of a template in a possibly empty context of application, independently by other rules that can be added to such a context. Template applications transpiled this way can be processed 
    
[^51]: 评估降解模型在排污管道CCTV检查规划中的适用性

    Assessment of the suitability of degradation models for the planning of CCTV inspections of sewer pipes. (arXiv:2307.06341v1 [cs.LG])

    [http://arxiv.org/abs/2307.06341](http://arxiv.org/abs/2307.06341)

    该论文评估了降解模型在排污管道CCTV检查规划中的适用性。结果表明，虽然集成模型具有最高的准确度，但无法推测长期降解；与此相反，逻辑回归模型准确度稍低，但能够产生可解释性强且一致的降解曲线。

    

    排污管道的降解引起了重大的经济、环境和健康问题。这些资产的维护需要有结构化的计划来进行检查，考虑到结构和环境特征以及以前检查报告的结果，可以更高效地进行。这项工作提出了一种方法来评估降解模型在规划检查时的适用性，考虑了三个维度：准确度指标、能够产生长期降解曲线和可解释性。结果表明，虽然集成模型具有最高的准确度，但它们无法推测管道的长期降解，而逻辑回归则提供了略低准确度的模型，能够产生具有很高可解释性的一致的降解曲线。通过一个使用案例来演示该方法及其效果

    The degradation of sewer pipes poses significant economical, environmental and health concerns. The maintenance of such assets requires structured plans to perform inspections, which are more efficient when structural and environmental features are considered along with the results of previous inspection reports. The development of such plans requires degradation models that can be based on statistical and machine learning methods. This work proposes a methodology to assess their suitability to plan inspections considering three dimensions: accuracy metrics, ability to produce long-term degradation curves and explainability. Results suggest that although ensemble models yield the highest accuracy, they are unable to infer the long-term degradation of the pipes, whereas the Logistic Regression offers a slightly less accurate model that is able to produce consistent degradation curves with a high explainability. A use case is presented to demonstrate this methodology and the efficiency o
    
[^52]: 阅读放射学成像的方式，就像放射科医生一样

    Reading Radiology Imaging Like The Radiologist. (arXiv:2307.05921v1 [cs.CV])

    [http://arxiv.org/abs/2307.05921](http://arxiv.org/abs/2307.05921)

    提出一种以疾病为导向的方法，解决自动放射学报告生成中的细微差异关注、数据偏差和长文本生成的挑战。

    

    自动放射学报告生成旨在生成包含放射学成像的丰富、精细描述的放射学报告。与自然图像领域的图像描述相比，医学图像非常相似，仅在疾病发生的细微差异上有所不同。鉴于这些细微差异在放射学报告中的重要性，鼓励模型更加关注疾病发生的微妙区域至关重要。其次，视觉和文本数据偏差的问题很严重。不仅正常病例占数据集的大部分，还描绘有病变区域的句子只占段落的一小部分。最后，生成医学图像报告涉及到长文本的生成挑战，这需要更多医学知识的专业性和经验训练。因此，生成此类报告的难度增加。为了解决这些挑战，我们提出了一种以疾病为导向的方法。

    Automated radiology report generation aims to generate radiology reports that contain rich, fine-grained descriptions of radiology imaging. Compared with image captioning in the natural image domain, medical images are very similar to each other, with only minor differences in the occurrence of diseases. Given the importance of these minor differences in the radiology report, it is crucial to encourage the model to focus more on the subtle regions of disease occurrence. Secondly, the problem of visual and textual data biases is serious. Not only do normal cases make up the majority of the dataset, but sentences describing areas with pathological changes also constitute only a small part of the paragraph. Lastly, generating medical image reports involves the challenge of long text generation, which requires more expertise and empirical training in medical knowledge. As a result, the difficulty of generating such reports is increased. To address these challenges, we propose a disease-ori
    
[^53]: Rad-ReStruct: 一种新颖的结构化放射学报告的VQA基准和方法

    Rad-ReStruct: A Novel VQA Benchmark and Method for Structured Radiology Reporting. (arXiv:2307.05766v1 [cs.CV])

    [http://arxiv.org/abs/2307.05766](http://arxiv.org/abs/2307.05766)

    本文提出了Rad-ReStruct，一个用于评估和比较不同方法的新型基准数据集，以X光图像的结构化报告形式提供了细粒度、按层次排序的注释。我们提出了一种新方法hi-VQA，将结构化报告任务建模为分层视觉问答(VQA)，并考虑先前提问和回答的上下文来填充结构化放射学报告。实验证明hi-VQA取得了与最先进方法相竞争的性能。

    

    放射学报告是放射科医生与其他医务人员之间沟通的重要部分，但其可能耗时且容易出错。其中一种减轻这种情况的方法是结构化报告，它比自由文本报告更节约时间并且能够实现更精确的评估。然而，关于自动化结构化报告的研究有限，并且目前没有公开的基准用于评估和比较不同方法。为了弥补这一空白，我们介绍了Rad-ReStruct，这是一个新的基准数据集，提供了细粒度的、按层次排序的X光图像的结构化报告形式的注释。我们将结构化报告任务建模为分层视觉问答(VQA)，并提出了hi-VQA，一种考虑先前提问和回答的上下文以填充结构化放射学报告的新方法。我们的实验证明hi-VQA在医学VQA基准测试中取得了与最先进方法相竞争的性能。

    Radiology reporting is a crucial part of the communication between radiologists and other medical professionals, but it can be time-consuming and error-prone. One approach to alleviate this is structured reporting, which saves time and enables a more accurate evaluation than free-text reports. However, there is limited research on automating structured reporting, and no public benchmark is available for evaluating and comparing different methods. To close this gap, we introduce Rad-ReStruct, a new benchmark dataset that provides fine-grained, hierarchically ordered annotations in the form of structured reports for X-Ray images. We model the structured reporting task as hierarchical visual question answering (VQA) and propose hi-VQA, a novel method that considers prior context in the form of previously asked questions and answers for populating a structured radiology report. Our experiments show that hi-VQA achieves competitive performance to the state-of-the-art on the medical VQA benc
    
[^54]: 大型语言模型用于供应链优化

    Large Language Models for Supply Chain Optimization. (arXiv:2307.03875v1 [cs.AI])

    [http://arxiv.org/abs/2307.03875](http://arxiv.org/abs/2307.03875)

    这项研究研究了利用大型语言模型（LLMs）来帮助解释和解读供应链优化结果的方法。他们设计了一个框架，可以接受普通文本查询作为输入，并输出关于底层优化结果的洞察。通过定量回答假设情况，该框架在不放弃最先进的组合优化技术的情况下帮助企业运营者更好地理解和信任优化结果。

    

    传统上，供应链操作涉及各种复杂的决策问题。在过去几十年中，供应链受益于计算技术的进步，从手动处理过渡到自动化和成本效益优化。然而，企业运营者仍然需要花费大量精力来解释和解读优化结果给相关人士。受大型语言模型(LLMs)最近的进展的启发，我们研究了这种颠覆性技术如何帮助弥合供应链自动化和人类理解与信任之间的差距。我们设计了一个名为\name{}的框架，它接受普通文本查询作为输入，并输出关于底层优化结果的洞察。我们的框架并没有放弃最先进的组合优化技术，而是利用它来定量地回答假设情况（例如，如果我们使用供应商B而不是供应商A，成本会如何变化）。

    Supply chain operations traditionally involve a variety of complex decision making problems. Over the last few decades, supply chains greatly benefited from advances in computation, which allowed the transition from manual processing to automation and cost-effective optimization. Nonetheless, business operators still need to spend substantial efforts in \emph{explaining} and interpreting the optimization outcomes to stakeholders. Motivated by the recent advances in Large Language Models (LLMs), we study how this disruptive technology can help bridge the gap between supply chain automation and human comprehension and trust thereof. We design \name{} -- a framework that accepts as input queries in plain text, and outputs insights about the underlying optimization outcomes. Our framework does not forgo the state-of-the-art combinatorial optimization technology, but rather leverages it to quantitatively answer what-if scenarios (e.g., how would the cost change if we used supplier B instead
    
[^55]: 一个多层级的AI治理框架

    A multilevel framework for AI governance. (arXiv:2307.03198v1 [cs.CY])

    [http://arxiv.org/abs/2307.03198](http://arxiv.org/abs/2307.03198)

    本文提出了一个多层级的AI治理框架，涉及政府、企业和公民三个相互依赖的利益相关者群体。通过信任的不同维度来研究它们之间的关系，并为进一步提升用户体验和制定AI相关公共政策提供实用见解。

    

    为了实现人工智能的潜在益处并减轻可能的风险，有必要开发一个符合伦理和基本人类价值观的治理框架。尽管一些组织已经发布了可信AI的指南和伦理框架，但如果没有一个调节的治理结构，这些伦理原则将无法转化为实践。在本文中，我们提出了一个多层级治理方法，涉及三个相互依赖的利益相关者群体：政府、企业和公民。我们通过信任的维度（如能力、诚信和善意）来研究它们之间的相互关系。结合AI的治理水平和信任维度，提供了可用于进一步增强用户体验并为与AI相关的公共政策提供信息的实用见解。

    To realize the potential benefits and mitigate potential risks of AI, it is necessary to develop a framework of governance that conforms to ethics and fundamental human values. Although several organizations have issued guidelines and ethical frameworks for trustworthy AI, without a mediating governance structure, these ethical principles will not translate into practice. In this paper, we propose a multilevel governance approach that involves three groups of interdependent stakeholders: governments, corporations, and citizens. We examine their interrelationships through dimensions of trust, such as competence, integrity, and benevolence. The levels of governance combined with the dimensions of trust in AI provide practical insights that can be used to further enhance user experiences and inform public policy related to AI.
    
[^56]: 对大型语言模型评估的调查

    A Survey on Evaluation of Large Language Models. (arXiv:2307.03109v1 [cs.CL])

    [http://arxiv.org/abs/2307.03109](http://arxiv.org/abs/2307.03109)

    本文综述了大型语言模型（LLMs）的评估方法，关注三个关键维度：评估什么、在哪里评估以及如何评估。评估任务包括自然语言处理、推理、医学应用、伦理学、教育、自然和社会科学、代理应用等多个领域。本文为社会层面对LLMs潜在风险的理解提供了重要参考。

    

    大型语言模型（LLMs）由于在各种应用中表现出的前所未有的性能而在学术界和工业界越来越受欢迎。随着LLMs在研究和日常使用中继续发挥着重要作用，它们的评估变得越来越关键，不仅在任务水平上，而且在社会层面上，以更好地了解它们的潜在风险。在过去的几年里，已经做出了相当大的努力来从不同的角度来研究LLMs。本文综述了LLMs的这些评估方法，重点关注三个关键维度：评估什么、在哪里评估以及如何评估。首先，我们从评估任务的角度提供了一个概述，涵盖了一般的自然语言处理任务、推理、医学应用、伦理学、教育、自然科学和社会科学、代理应用和其他领域。其次，我们通过深入探讨评估方法和基准答案来回答“在哪里”和“如何”这两个问题。

    Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, educations, natural and social sciences, agent applications, and other areas. Secondly, we answer the `where' and `how' questions by diving into the evaluation methods and bench
    
[^57]: 用神经符号深度强化学习方法实现安全自主驾驶策略的研究

    Towards Safe Autonomous Driving Policies using a Neuro-Symbolic Deep Reinforcement Learning Approach. (arXiv:2307.01316v1 [cs.RO])

    [http://arxiv.org/abs/2307.01316](http://arxiv.org/abs/2307.01316)

    本文介绍了一种名为DRL with Symbolic Logics (DRLSL)的新颖神经符号无模型深度强化学习方法，旨在实现在真实环境中安全学习自主驾驶策略。该方法结合了深度强化学习和符号逻辑驱动的推理，允许通过与物理环境的实时交互来学习自主驾驶策略并确保安全性。

    

    自主驾驶中的动态驾驶环境和多样化道路使用者的存在给决策造成了巨大的挑战。深度强化学习(DRL)已成为解决这一问题的一种流行方法。然而，由于安全问题的限制，现有的DRL解决方案的应用主要局限于模拟环境，阻碍了它们在现实世界中的部署。为了克服这一局限，本文引入了一种新颖的神经符号无模型深度强化学习方法，称为带有符号逻辑的DRL(DRLSL)，它将DRL(从经验中学习)和符号一阶逻辑知识驱动的推理相结合，以实现在实际环境下安全学习自主驾驶的实时交互。这种创新的方法提供了一种通过积极与物理环境互动来学习自主驾驶政策并确保安全性的方式。我们使用高维度数据实现了自主驾驶的DRLSL框架。

    The dynamic nature of driving environments and the presence of diverse road users pose significant challenges for decision-making in autonomous driving. Deep reinforcement learning (DRL) has emerged as a popular approach to tackle this problem. However, the application of existing DRL solutions is mainly confined to simulated environments due to safety concerns, impeding their deployment in real-world. To overcome this limitation, this paper introduces a novel neuro-symbolic model-free DRL approach, called DRL with Symbolic Logics (DRLSL) that combines the strengths of DRL (learning from experience) and symbolic first-order logics knowledge-driven reasoning) to enable safe learning in real-time interactions of autonomous driving within real environments. This innovative approach provides a means to learn autonomous driving policies by actively engaging with the physical environment while ensuring safety. We have implemented the DRLSL framework in autonomous driving using the highD data
    
[^58]: PatternGPT: 一种基于模式的大型语言模型文本生成框架

    PatternGPT :A Pattern-Driven Framework for Large Language Model Text Generation. (arXiv:2307.00470v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.00470](http://arxiv.org/abs/2307.00470)

    PatternGPT是一种基于模式驱动的大型语言模型文本生成框架，通过利用大型语言模型的提取能力生成多样化的模式，并使用联邦学习的思想实现模式共享，最终通过搜索高质量模式指导生成模型。该框架具有生成多样化模式、保护数据隐私、结合外部知识等优势。

    

    大型语言模型(LLMs)展示了出色的文本生成能力，能够为许多下游任务生成流畅的响应。然而，将大型语言模型应用于现实世界的关键任务仍然具有挑战性，因为它们容易出现幻觉，并且无法直接使用外部知识。为解决上述问题，本文提出了PatternGPT，一种基于模式驱动的大型语言模型文本生成框架。首先，该框架利用大型语言模型的提取能力生成丰富多样的模式，然后借鉴联邦学习的思想，使用多个代理实现共享以获取更多样的模式。最后，它使用判断标准和优化算法搜索高质量的模式，并使用搜索到的模式指导模型进行生成。该框架具有生成多样化模式、保护数据隐私、结合外部知识等优势。

    Large language models(LLMS) have shown excellent text generation capabilities,capable of generating fluent responses for many downstream tasks. However,applying large language models to real-world critical tasks remains challenging due to their susceptibility to hallucinations and inability to directly use external knowledge. To address the above challenges,this paper proposes PatternGPT, a pattern-driven text generation framework for large language models. First,the framework utilizes the extraction capabilities of large language models to generate rich and diverse patterns and later draws on the idea of federated learning. Using multiple agents to achieve sharing to obtain more diverse patterns. Finally, it searches for high-quality patterns using judgment criteria and optimization algorithms and uses the searched patterns to guide the model for generation. This framework has the advantages of generating diversified patterns, protecting data privacy,combining external knowledge, and 
    
[^59]: TrustGuard: 基于GNN的动态支持鲁棒且可解释的信任评估

    TrustGuard: GNN-based Robust and Explainable Trust Evaluation with Dynamicity Support. (arXiv:2306.13339v1 [cs.LG])

    [http://arxiv.org/abs/2306.13339](http://arxiv.org/abs/2306.13339)

    TrustGuard是一种基于GNN的信任评估模型，支持信任动态性，抗击鲁棒并提供解释能力，它的实验结果在准确性、鲁棒性和可解释性方面都优于其他方法。

    

    信任评估评估实体之间的信任关系并促进决策。机器学习由于其学习能力而表现出巨大的潜力，因此对信任评估具有重要意义。近年来，作为一种新的机器学习范 paradigm，图神经网络（GNN）在处理图形数据方面表现出优越性。这激发了研究人员探索将其用于信任评估，因为实体之间的信任关系可以建模为图形。但是，使用GNN的当前信任评估方法未能完全满足信任的动态性，忽略了攻击对信任评估的不利影响，并且无法提供令人信服的评估结果解释。为解决这些问题，在本文中，我们提出了TrustGuard ：一种支持信任动态性、抗击鲁棒且通过可视化提供解释的精确信任评估模型。具体而言，TrustGuard 设计了一个由动态感知节点嵌入层、图卷积层、注意机制层和信任预测层组成的分层架构。为了评估提出的模型的有效性，我们对真实数据集进行了实验，并将TrustGuard与其他最先进的方法进行了比较。实验结果表明，TrustGuard 在准确性、鲁棒性和可解释性方面均优于其他方法。

    Trust evaluation assesses trust relationships between entities and facilitates decision-making. Machine Learning (ML) shows great potential for trust evaluation owing to its learning capabilities. In recent years, Graph Neural Networks (GNNs), as a new ML paradigm, have demonstrated superiority in dealing with graph data. This has motivated researchers to explore their use in trust evaluation, as trust relationships among entities can be modeled as a graph. However, current trust evaluation methods that employ GNNs fail to fully satisfy the dynamicity nature of trust, overlook the adverse effects of attacks on trust evaluation, and cannot provide convincing explanations on evaluation results. To address these problems, in this paper, we propose TrustGuard, a GNN-based accurate trust evaluation model that supports trust dynamicity, is robust against typical attacks, and provides explanations through visualization. Specifically, TrustGuard is designed with a layered architecture that con
    
[^60]: FishRecGAN：用于鱼眼图像矫正和相机内参和畸变参数标定的端到端GAN网络

    FishRecGAN: An End to End GAN Based Network for Fisheye Rectification and Calibration. (arXiv:2305.05222v1 [cs.CV])

    [http://arxiv.org/abs/2305.05222](http://arxiv.org/abs/2305.05222)

    FishRecGAN提供了一种端到端的深度学习方法，以矫正鱼眼图像并同时校准相机内参和畸变参数。其快速校正网络具有良好的分辨率和鲁棒性，适用于摄像机型监控设备中的恒定标定，并使用大量合成数据集进行训练和验证，表现出了高分辨率的鲁棒性和显著的峰值信噪比。

    

    我们提出了一种端到端的深度学习方法，以矫正鱼眼图像并同时校准相机内参和畸变参数。我们的方法由两部分组成：使用Pix2Pix GAN和Wasserstein GAN（W-Pix2PixGAN）开发的Quick Image Rectification模块，以及使用CNN架构的Calibration模块。我们的快速校正网络具有良好的分辨率和鲁棒性，适用于摄像机型监控设备中的恒定标定。为了实现高质量的标定，我们使用从Quick Image Rectification模块中输出的直线特征作为指导样本传递给Calibration模块，以学习校正前后的几何关系。我们使用大量合成数据集来训练和验证我们的方法，并应用于透视图像数据集，表现出了高分辨率的鲁棒性和显著的峰值信噪比。

    We propose an end-to-end deep learning approach to rectify fisheye images and simultaneously calibrate camera intrinsic and distortion parameters. Our method consists of two parts: a Quick Image Rectification Module developed with a Pix2Pix GAN and Wasserstein GAN (W-Pix2PixGAN), and a Calibration Module with a CNN architecture. Our Quick Rectification Network performs robust rectification with good resolution, making it suitable for constant calibration in camera-based surveillance equipment. To achieve high-quality calibration, we use the straightened output from the Quick Rectification Module as a guidance-like semantic feature map for the Calibration Module to learn the geometric relationship between the straightened feature and the distorted feature. We train and validate our method with a large synthesized dataset labeled with well-simulated parameters applied to a perspective image dataset. Our solution has achieved robust performance in high-resolution with a significant PSNR v
    
[^61]: FR3D: 通过协助共形映射的卷积自动编码器进行三维流场重构和力估计的研究

    FR3D: Three-dimensional Flow Reconstruction and Force Estimation for Unsteady Flows Around Extruded Bluff Bodies via Conformal Mapping Aided Convolutional Autoencoders. (arXiv:2302.01802v2 [physics.flu-dyn] UPDATED)

    [http://arxiv.org/abs/2302.01802](http://arxiv.org/abs/2302.01802)

    本研究提出了一种名为FR3D的卷积自动编码器模型，可以通过共形映射实现对不同横截面的拉出式三维物体周围的三维流场进行重构和力估计。

    

    在许多实际流体动力学实验中，只能在有限数量的传感器位置测量速度和压力等变量，对于一些二维平面或小型三维流场，知道完整的场是理解许多流动动力学的必要条件。深度学习重构稀疏测量得出的完整流场近年来引起了重要研究兴趣，作为克服这种限制的一种方法，这一任务被称为流场重构（FR）任务。在本研究中，我们提出了一种基于卷积自动编码器的神经网络模型FR3D，能够对不同横截面的拉出式三维物体周围的三维流场进行FR。创新的映射方法将多个流体域映射到一个环状区域，使得FR3D能够将其性能推广到在训练期间未遇到的物体。我们明确证明了这一点。

    In many practical fluid dynamics experiments, measuring variables such as velocity and pressure is possible only at a limited number of sensor locations, \textcolor{black}{for a few two-dimensional planes, or for a small 3D domain in the flow}. However, knowledge of the full fields is necessary to understand the dynamics of many flows. Deep learning reconstruction of full flow fields from sparse measurements has recently garnered significant research interest, as a way of overcoming this limitation. This task is referred to as the flow reconstruction (FR) task. In the present study, we propose a convolutional autoencoder based neural network model, dubbed FR3D, which enables FR to be carried out for three-dimensional flows around extruded 3D objects with different cross-sections. An innovative mapping approach, whereby multiple fluid domains are mapped to an annulus, enables FR3D to generalize its performance to objects not encountered during training. We conclusively demonstrate this 
    
[^62]: 关于强化学习中Transformers的调查

    A Survey on Transformers in Reinforcement Learning. (arXiv:2301.03044v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.03044](http://arxiv.org/abs/2301.03044)

    这篇论文是一项调查研究，总结了在强化学习领域使用Transformers的动机、进展和未来前景。

    

    Transformer已被认为是自然语言处理（NLP）和计算机视觉（CV）领域中的主导神经架构，主要应用于监督学习任务。最近，在强化学习（RL）领域中也出现了类似的使用Transformers的潮流，但面临着RL的特殊设计选择和挑战。然而，Transformers在RL中的发展尚未被充分揭示。在本文中，我们系统地回顾了在RL中使用Transformers的动机和进展，提供了一个现有工作的分类体系，讨论了每个子领域，并总结了未来的前景。

    Transformer has been considered the dominating neural architecture in NLP and CV, mostly under supervised settings. Recently, a similar surge of using Transformers has appeared in the domain of reinforcement learning (RL), but it is faced with unique design choices and challenges brought by the nature of RL. However, the evolution of Transformers in RL has not yet been well unraveled. In this paper, we seek to systematically review motivations and progress on using Transformers in RL, provide a taxonomy on existing works, discuss each sub-field, and summarize future prospects.
    
[^63]: 未知动态马尔可夫跳变线性系统的形式化控制器合成

    Formal Controller Synthesis for Markov Jump Linear Systems with Uncertain Dynamics. (arXiv:2212.00679v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2212.00679](http://arxiv.org/abs/2212.00679)

    本文介绍了一种方法，用于合成马尔可夫跳变线性系统（MJLS）的控制器，以确保满足概率计算树逻辑（PCTL）公式，对于转移概率未知或已知但存在一定的区间的问题提出了解决方案。

    

    在安全关键场景中，对于控制器的自动化合成可以确保系统的正确性至关重要。然而，混合特性和随机或未知的行为使得合成控制器的问题变得具有挑战性。本论文提出了一种方法，用于合成马尔可夫跳变线性系统（MJLS）的控制器，这是一类离散时钟模型的控制器，用于解决这些系统的安全问题，以确保满足概率计算树逻辑（PCTL）公式。一个MJLS由一组有限的随机线性动态和这些动态之间的离散跳变组成，这些跳变由一个马尔可夫决策过程（MDP）来管理。我们考虑了这个MDP的转移概率未知或已知但存在一定的区间。我们的方法基于一个有限状态抽象，捕捉了MJLS的离散（模式跳跃）和连续（随机线性）行为。我们将这个抽象形式化为一个区间MDP（iMDP），然后计算了状态转移区间。

    Automated synthesis of provably correct controllers for cyber-physical systems is crucial for deployment in safety-critical scenarios. However, hybrid features and stochastic or unknown behaviours make this problem challenging. We propose a method for synthesising controllers for Markov jump linear systems (MJLSs), a class of discrete-time models for cyber-physical systems, so that they certifiably satisfy probabilistic computation tree logic (PCTL) formulae. An MJLS consists of a finite set of stochastic linear dynamics and discrete jumps between these dynamics that are governed by a Markov decision process (MDP). We consider the cases where the transition probabilities of this MDP are either known up to an interval or completely unknown. Our approach is based on a finite-state abstraction that captures both the discrete (mode-jumping) and continuous (stochastic linear) behaviour of the MJLS. We formalise this abstraction as an interval MDP (iMDP) for which we compute intervals of tra
    
[^64]: 世界模型在连续强化学习中的有效性

    The Effectiveness of World Models for Continual Reinforcement Learning. (arXiv:2211.15944v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.15944](http://arxiv.org/abs/2211.15944)

    本论文展示了世界模型在连续学习中的应用，通过研究选择性经验回放方法的影响，提出了Continual-Dreamer模型，该模型在Minigrid和Minihack基准测试中表现优于最先进的任务不可知连续强化学习方法。

    

    世界模型是一些高效强化学习算法的基础。在这项工作中，我们展示了它们可以用于连续学习，即智能体面对不断变化的环境情况。世界模型通常使用回放缓冲区进行训练，这可以自然地扩展到连续学习中。我们系统地研究了不同的选择性经验回放方法对性能、遗忘和迁移的影响。我们还提供了关于使用世界模型的各种建模选项的建议。最佳选择是称为Continual-Dreamer的模型，它是任务不可知的，并利用世界模型进行连续探索。Continual-Dreamer具有高样本效率，并在Minigrid和Minihack基准测试中胜过最先进的任务不可知连续强化学习方法。

    World models power some of the most efficient reinforcement learning algorithms. In this work, we showcase that they can be harnessed for continual learning - a situation when the agent faces changing environments. World models typically employ a replay buffer for training, which can be naturally extended to continual learning. We systematically study how different selective experience replay methods affect performance, forgetting, and transfer. We also provide recommendations regarding various modeling options for using world models. The best set of choices is called Continual-Dreamer, it is task-agnostic and utilizes the world model for continual exploration. Continual-Dreamer is sample efficient and outperforms state-of-the-art task-agnostic continual reinforcement learning methods on Minigrid and Minihack benchmarks.
    
[^65]: 控制变压器：通过PRM-Guided Return-Conditioned序列建模在未知环境中的机器人导航

    Control Transformer: Robot Navigation in Unknown Environments through PRM-Guided Return-Conditioned Sequence Modeling. (arXiv:2211.06407v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2211.06407](http://arxiv.org/abs/2211.06407)

    Control Transformer是一种通过采样规划引导的低层策略建模返回条件序列的方法，可以在未知环境中成功解决长时间范围的导航任务。

    

    学习长时间范围的任务，如导航，对于成功应用强化学习到机器人领域提出了困难的挑战。从另一个角度来看，在已知环境下，基于采样的规划可以在不学习的情况下稳健地找到无碰撞路径。在这项工作中，我们提出了Control Transformer，通过由基于采样的概率地图（PRM）规划器引导的低层策略建模返回条件序列。我们证明了我们的框架可以使用仅局部信息解决长时间范围的导航任务。我们在部分观察的迷宫导航中评估了我们的方法，包括Ant，Point和Humanoid的MuJoCo机器人。我们展示了Control Transformer可以成功地在迷宫中导航并转移到未知环境中。此外，我们将我们的方法应用于差分驱动机器人（Turtlebot3），并展示了在噪声观测下的零样本sim2real转移。

    Learning long-horizon tasks such as navigation has presented difficult challenges for successfully applying reinforcement learning to robotics. From another perspective, under known environments, sampling-based planning can robustly find collision-free paths in environments without learning. In this work, we propose Control Transformer that models return-conditioned sequences from low-level policies guided by a sampling-based Probabilistic Roadmap (PRM) planner. We demonstrate that our framework can solve long-horizon navigation tasks using only local information. We evaluate our approach on partially-observed maze navigation with MuJoCo robots, including Ant, Point, and Humanoid. We show that Control Transformer can successfully navigate through mazes and transfer to unknown environments. Additionally, we apply our method to a differential drive robot (Turtlebot3) and show zero-shot sim2real transfer under noisy observations.
    
[^66]: 对抗性策略战胜超级人类级围棋AI

    Adversarial Policies Beat Superhuman Go AIs. (arXiv:2211.00241v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.00241](http://arxiv.org/abs/2211.00241)

    通过对抗性策略攻击，我们成功战胜了超级人类级围棋AI KataGo，揭示了其核心弱点，并展示了即使是超级AI系统也可能存在意想不到的失败模式。

    

    我们通过训练对抗性策略来攻击最先进的围棋AI系统KataGo，在超人类设置下取得了超过97%的胜率。我们的对手并不是通过出色地下围棋来获胜，而是通过诱使KataGo犯下严重失误。我们的攻击可以零损耗地传输给其他超级人类级围棋AI，并且对人类专家来说是可以理解的，他们可以在没有算法辅助的情况下实施这种攻击来持续战胜超级人类级AI。我们的攻击揭示了KataGo的核心弱点，即使是对抗性训练的KataGo代理也无法防御我们的攻击。我们的研究结果表明，即使是超级人类级的AI系统也可能存在意想不到的失败模式。

    We attack the state-of-the-art Go-playing AI system KataGo by training adversarial policies against it, achieving a >97% win rate against KataGo running at superhuman settings. Our adversaries do not win by playing Go well. Instead, they trick KataGo into making serious blunders. Our attack transfers zero-shot to other superhuman Go-playing AIs, and is comprehensible to the extent that human experts can implement it without algorithmic assistance to consistently beat superhuman AIs. The core vulnerability uncovered by our attack persists even in KataGo agents adversarially trained to defend against our attack. Our results demonstrate that even superhuman AI systems may harbor surprising failure modes. Example games are available https://goattack.far.ai/.
    
[^67]: RulE: 使用规则嵌入的神经-符号知识图推理

    RulE: Neural-Symbolic Knowledge Graph Reasoning with Rule Embedding. (arXiv:2210.14905v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2210.14905](http://arxiv.org/abs/2210.14905)

    RulE是一个框架，通过将实体、关系和逻辑规则统一表示在一个嵌入空间中，有效利用逻辑规则提升知识图推理。同时，RulE注入先前的逻辑规则信息，改进了实体/关系嵌入，使得知识图嵌入方法也表现更好。

    

    知识图（KG）推理对于知识图是一个重要问题。本文提出了一个新颖而有原则定位的框架，称为RulE（代表规则嵌入），以有效利用逻辑规则来增强KG推理。与知识图嵌入（KGE）方法不同，RulE通过在统一的嵌入空间中联合表示实体、关系和逻辑规则，从现有三元组和一阶规则中学习规则嵌入。基于学习到的规则嵌入，可以计算每个规则的置信度得分，反映其与观察到的三元组的一致性。这使得我们能够以软方式进行逻辑规则推理，从而减轻了逻辑的脆弱性。另一方面，RulE将先前的逻辑规则信息注入到嵌入空间中，丰富和规范化实体/关系嵌入。这也使得仅使用KGE的表现更好。RulE在概念上简单且在实验上有效。

    Knowledge graph (KG) reasoning is an important problem for knowledge graphs. In this paper, we propose a novel and principled framework called \textbf{RulE} (stands for {Rul}e {E}mbedding) to effectively leverage logical rules to enhance KG reasoning. Unlike knowledge graph embedding (KGE) methods, RulE learns rule embeddings from existing triplets and first-order {rules} by jointly representing \textbf{entities}, \textbf{relations} and \textbf{logical rules} in a unified embedding space. Based on the learned rule embeddings, a confidence score can be calculated for each rule, reflecting its consistency with the observed triplets. This allows us to perform logical rule inference in a soft way, thus alleviating the brittleness of logic. On the other hand, RulE injects prior logical rule information into the embedding space, enriching and regularizing the entity/relation embeddings. This makes KGE alone perform better too. RulE is conceptually simple and empirically effective. We conduct
    
[^68]: 重新审视离散型Soft Actor-Critic方法

    Revisiting Discrete Soft Actor-Critic. (arXiv:2209.10081v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.10081](http://arxiv.org/abs/2209.10081)

    本研究重新审视了将连续动作空间的Soft Actor-Critic方法调整为离散动作空间的问题，并提出了解决Q值低估和性能不稳定的方法，验证了其在Atari游戏和大规模MOBA游戏中的有效性。

    

    本文研究将连续动作空间的Soft Actor-Critic方法（SAC）调整为离散动作空间。我们重新审视了经典的SAC方法，并深入理解了在离散设置下其Q值低估和性能不稳定的问题。因此，我们提出了熵惩罚和具有Q-clip的双平均Q-learning方法来解决这些问题。通过对包括Atari游戏和一个大规模MOBA游戏在内的典型基准问题进行广泛实验，验证了我们方法的有效性。我们的代码可在以下链接找到: https://github.com/coldsummerday/Revisiting-Discrete-SAC.

    We study the adaption of soft actor-critic (SAC) from continuous action space to discrete action space. We revisit vanilla SAC and provide an in-depth understanding of its Q value underestimation and performance instability issues when applied to discrete settings. We thereby propose entropy-penalty and double average Q-learning with Q-clip to address these issues. Extensive experiments on typical benchmarks with discrete action space, including Atari games and a large-scale MOBA game, show the efficacy of our proposed method. Our code is at:https://github.com/coldsummerday/Revisiting-Discrete-SAC.
    
[^69]: 数据增强是一个超参数：精心筛选的自监督对于无监督异常检测的成功产生了幻象。

    Data Augmentation is a Hyperparameter: Cherry-picked Self-Supervision for Unsupervised Anomaly Detection is Creating the Illusion of Success. (arXiv:2208.07734v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.07734](http://arxiv.org/abs/2208.07734)

    这项研究通过广泛的实验，证明数据增强与异常生成机制之间的对齐是自监督学习在无监督异常检测中取得成功的关键，并且在缺乏对齐时，自监督学习甚至可能降低准确性。

    

    自监督学习（SSL）已经成为一种有希望的替代方法，用于为现实世界的问题创建监督信号，避免了手动标注的巨大成本。对于标记异常稀缺或几乎不存在的无监督任务（如异常检测），SSL特别有吸引力。过去已经使用了大量的数据增强函数来进行基于SSL的异常检测（SSAD）的图像数据，并且最近的研究表明数据增强的类型对准确性有着重要影响。受此启发，本研究通过对三种不同检测模型和420个异常检测任务的广泛实验，提供了全面的数字和可视证据，证明数据增强与异常生成机制之间的对齐是SSAD成功的关键，而在缺乏对齐的情况下，SSL甚至可能降低准确性。据我们所知，这是关于图像型SSAD的首次深入研究。

    Self-supervised learning (SSL) has emerged as a promising alternative to create supervisory signals to real-world problems, avoiding the extensive cost of manual labeling. SSL is particularly attractive for unsupervised tasks such as anomaly detection (AD), where labeled anomalies are rare or often nonexistent. A large catalog of augmentation functions has been used for SSL-based AD (SSAD) on image data, and recent works have reported that the type of augmentation has a significant impact on accuracy. Motivated by those, this work sets out to put image-based SSAD under a larger lens and investigate the role of data augmentation in SSAD. Through extensive experiments on 3 different detector models and across 420 AD tasks, we provide comprehensive numerical and visual evidences that the alignment between data augmentation and anomaly-generating mechanism is the key to the success of SSAD, and in the lack thereof, SSL may even impair accuracy. To the best of our knowledge, this is the fir
    
[^70]: TRUST-LAPSE：一种可解释和可操作的模型监控不信任评分框架

    TRUST-LAPSE: An Explainable and Actionable Mistrust Scoring Framework for Model Monitoring. (arXiv:2207.11290v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.11290](http://arxiv.org/abs/2207.11290)

    TRUST-LAPSE是一个可解释和可操作的连续模型监控框架，通过使用潜空间嵌入评估每个输入样本的模型预测的可信度，并利用距离和相似度度量以及顺序相关性偏差来实现对模型的连续监控。

    

    连续监测训练好的机器学习模型，在确定何时应该信任它们的预测和何时不应该信任它们的预测方面非常重要，这对于安全部署是必需的。我们提出了TRUST-LAPSE，这是一个用于连续模型监控的“不信任”评分框架。我们使用一系列潜空间嵌入来评估每个输入样本的模型预测的可信度。具体来说，（a）我们的潜空间不信任评分使用潜空间中的距离度量（马氏距离）和相似度度量（余弦相似度）来估计不信任度，（b）我们的顺序不信任评分使用非参数、滑动窗口算法来确定过去输入表示序列中的相关性偏差，从而实现可操作的连续监控。我们通过两个下游任务对TRUST-LAPSE进行评估：（1）分布偏移输入检测，（2）数据漂移检测。我们在不同领域进行评估-音频...

    Continuous monitoring of trained ML models to determine when their predictions should and should not be trusted is essential for their safe deployment. Such a framework ought to be high-performing, explainable, post-hoc and actionable. We propose TRUST-LAPSE, a "mistrust" scoring framework for continuous model monitoring. We assess the trustworthiness of each input sample's model prediction using a sequence of latent-space embeddings. Specifically, (a) our latent-space mistrust score estimates mistrust using distance metrics (Mahalanobis distance) and similarity metrics (cosine similarity) in the latent-space and (b) our sequential mistrust score determines deviations in correlations over the sequence of past input representations in a non-parametric, sliding-window based algorithm for actionable continuous monitoring. We evaluate TRUST-LAPSE via two downstream tasks: (1) distributionally shifted input detection, and (2) data drift detection. We evaluate across diverse domains - audio 
    
[^71]: 基于联想记忆模型的真实世界数据分类和生成

    Classification and Generation of real-world data with an Associative Memory Model. (arXiv:2207.04827v3 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2207.04827](http://arxiv.org/abs/2207.04827)

    本文提出了一种基于联想记忆模型的多模态框架，可以以容错的方式存储和检索大量真实世界数据，并且可以用于推断缺失的模态。

    This paper proposes a multi-modality framework based on the associative memory model, which can store and retrieve a large amount of real-world data in a fault-tolerant manner, and can be used to infer missing modalities.

    回忆起多年未见的朋友的面孔是一项困难的任务。然而，如果你们偶然相遇，你们会轻易地认出彼此。生物记忆配备了一个令人印象深刻的压缩算法，可以存储必要的信息，然后推断细节以匹配感知。Willshaw Memory是一种用于皮层计算的简单抽象模型，实现了生物记忆的机制。使用我们最近提出的用于视觉模式的稀疏编码规则[34]，该模型可以以容错的方式存储和检索大量真实世界数据。在本文中，我们通过使用多模态框架扩展了基本联想记忆模型的能力。在这种设置中，记忆同时存储每个模式的几种模态（例如，视觉或文本）。训练后，当只感知到子集时，记忆可以用于推断缺失的模态。使用简单的编码器-记忆解码器，我们可以生成具有多个模态的数据。

    Drawing from memory the face of a friend you have not seen in years is a difficult task. However, if you happen to cross paths, you would easily recognize each other. The biological memory is equipped with an impressive compression algorithm that can store the essential, and then infer the details to match perception. The Willshaw Memory is a simple abstract model for cortical computations which implements mechanisms of biological memories. Using our recently proposed sparse coding prescription for visual patterns [34], this model can store and retrieve an impressive amount of real-world data in a fault-tolerant manner. In this paper, we extend the capabilities of the basic Associative Memory Model by using a Multiple-Modality framework. In this setting, the memory stores several modalities (e.g., visual, or textual) of each pattern simultaneously. After training, the memory can be used to infer missing modalities when just a subset is perceived. Using a simple encoder-memory decoder a
    
[^72]: 最公平的投票规则

    Most Equitable Voting Rules. (arXiv:2205.14838v3 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2205.14838](http://arxiv.org/abs/2205.14838)

    该论文探讨了在社会选择理论中设计满足匿名性、中立性和可解决性的最佳投票规则的开放问题。作者提出了一种最公平改进的概念，该概念对满足两个公理的任何不确定规则都能最优地保持匿名性和中立性。

    

    在社会选择理论中，匿名性（所有代理人被平等对待）和中立性（所有替代方案被平等对待）被普遍认为是公平性和公正性的“最低要求”和“无争议”的公理。然而，ANR不可能性——没有满足匿名性、中立性和可解决性（总是选择一个获胜者）的投票规则——甚至在只有两个替代方案和两个代理人的简单情况下也成立。如何设计满足匿名性、中立性和可解决性的最佳投票规则仍然是一个开放的问题。我们解决了一种广泛的偏好和决策的最佳设计问题，包括排名列表和委员会。我们的概念贡献是一种新的和强大的最公平改进的概念，它对满足两个公理的任何不确定规则都能最优地保持匿名性和中立性。我们的技术贡献有两个方面。首先，我们刻画了ANR不可能性在普遍情况下成立的条件。

    In social choice theory, anonymity (all agents being treated equally) and neutrality (all alternatives being treated equally) are widely regarded as ``minimal demands'' and ``uncontroversial'' axioms of equity and fairness. However, the ANR impossibility -- there is no voting rule that satisfies anonymity, neutrality, and resolvability (always choosing one winner) -- holds even in the simple setting of two alternatives and two agents. How to design voting rules that optimally satisfy anonymity, neutrality, and resolvability remains an open question.  We address the optimal design question for a wide range of preferences and decisions that include ranked lists and committees. Our conceptual contribution is a novel and strong notion of most equitable refinements that optimally preserves anonymity and neutrality for any irresolute rule that satisfies the two axioms. Our technical contributions are twofold. First, we characterize the conditions for the ANR impossibility to hold under gener
    
[^73]: 深度伪造检测的块洗牌学习方法

    Block shuffling learning for Deepfake Detection. (arXiv:2202.02819v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2202.02819](http://arxiv.org/abs/2202.02819)

    本文提出了一种新颖的块洗牌正则化方法，通过将图像分为块并应用洗牌技术，实现了权重共享和缓解了过拟合问题。大量实验证实了该方法的有效性。

    

    基于卷积神经网络（CNN）的深度伪造检测方法已经证明具有很高的准确性。然而，当面对未知的伪造方法和常见的转换（如调整大小和模糊）时，这些方法往往会遇到性能下降的问题，导致训练和测试领域之间存在偏差。这种现象称为过拟合，是一个重要的挑战。为了解决这个问题，我们提出了一种新颖的块洗牌正则化方法。首先，我们的方法通过将图像划分为块并应用块内和块间洗牌技术，间接实现了不同维度之间的权重共享。其次，我们引入了对抗性损失算法来减轻洗牌噪声引起的过拟合问题。最后，我们恢复块的空间布局，以捕捉它们之间的语义关联。大量实验证实了我们提出的方法的有效性。

    Deepfake detection methods based on convolutional neural networks (CNN) have demonstrated high accuracy. \textcolor{black}{However, these methods often suffer from decreased performance when faced with unknown forgery methods and common transformations such as resizing and blurring, resulting in deviations between training and testing domains.} This phenomenon, known as overfitting, poses a significant challenge. To address this issue, we propose a novel block shuffling regularization method. Firstly, our approach involves dividing the images into blocks and applying both intra-block and inter-block shuffling techniques. This process indirectly achieves weight-sharing across different dimensions. Secondly, we introduce an adversarial loss algorithm to mitigate the overfitting problem induced by the shuffling noise. Finally, we restore the spatial layout of the blocks to capture the semantic associations among them. Extensive experiments validate the effectiveness of our proposed method
    
[^74]: 未来学习：基于未来信息的合理外推

    Prospective Learning: Principled Extrapolation to the Future. (arXiv:2201.07372v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.07372](http://arxiv.org/abs/2201.07372)

    这项研究提出了一种基于未来信息的学习方法，将学习问题重新定义为关于动态未来的概念，并认为前瞻性学习更准确地描述了现实世界中的许多问题。

    

    学习是一个可以根据过去的经验更新决策规则的过程，从而提高未来的性能。传统上，机器学习常常在假设未来与过去的分布相同或会以对抗的方式改变的情况下进行评估。但是这些假设对于现实世界中许多问题来说，可能过于乐观或悲观。现实世界的场景在多个时空尺度上演变，具有部分可预测的动力学。在这里，我们重新定义学习问题，将其聚焦于动态未来的概念，这种未来是部分可学习的。我们推测某些任务序列在回顾性学习中不可学习（其中数据分布固定），但在前瞻性学习中可学习（其中分布可能动态），这表明前瞻性学习在本质上比回顾性学习更困难。我们认为前瞻性学习更准确地描述了许多现实世界的问题，

    Learning is a process which can update decision rules, based on past experience, such that future performance improves. Traditionally, machine learning is often evaluated under the assumption that the future will be identical to the past in distribution or change adversarially. But these assumptions can be either too optimistic or pessimistic for many problems in the real world. Real world scenarios evolve over multiple spatiotemporal scales with partially predictable dynamics. Here we reformulate the learning problem to one that centers around this idea of dynamic futures that are partially learnable. We conjecture that certain sequences of tasks are not retrospectively learnable (in which the data distribution is fixed), but are prospectively learnable (in which distributions may be dynamic), suggesting that prospective learning is more difficult in kind than retrospective learning. We argue that prospective learning more accurately characterizes many real world problems that (1) cur
    
[^75]: 新颖方向上对象泛化的新兴神经网络机制

    Emergent Neural Network Mechanisms for Generalization to Objects in Novel Orientations. (arXiv:2109.13445v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2109.13445](http://arxiv.org/abs/2109.13445)

    本研究提供了证据表明，深度神经网络具有通过传播方向不变性来泛化到新颖方向上的对象的能力。这种能力受到训练中使用的熟悉对象数量的影响，但仅限于涉及2D旋转的熟悉方向。

    

    深度神经网络（DNNs）在识别训练数据分布之外的方向上的对象的能力尚不完全了解。我们提供证据表明，DNNs能够通过传播从多个视点观察到的熟悉对象获得的方向不变性来泛化到新颖方向上的对象。这种能力在训练DNN时使用越来越多的熟悉对象时会增强，但仅限于涉及到熟悉方向的2D旋转的方向。我们展示了这种传播是通过调整到熟悉和不熟悉对象之间共同特征的神经元实现的。这些结果揭示了类脑神经机制的泛化能力。

    The capability of Deep Neural Networks (DNNs) to recognize objects in orientations outside the distribution of the training data is not well understood. We present evidence that DNNs are capable of generalizing to objects in novel orientations by disseminating orientation-invariance obtained from familiar objects seen from many viewpoints. This capability strengthens when training the DNN with an increasing number of familiar objects, but only in orientations that involve 2D rotations of familiar orientations. We show that this dissemination is achieved via neurons tuned to common features between familiar and unfamiliar objects. These results implicate brain-like neural mechanisms for generalization.
    
[^76]: 在高度受限环境中自主导航欠驱动双足机器人

    Autonomous Navigation of Underactuated Bipedal Robots in Height-Constrained Environments. (arXiv:2109.05714v4 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2109.05714](http://arxiv.org/abs/2109.05714)

    本文提出了一个端到端的自主导航框架，使用三层规划器和可变步行高度控制器，使双足机器人能够安全地探索高度受限环境。

    

    在未知且杂乱的高度受限环境中导航大型机器人具有挑战性。不仅需要快速可靠的规划算法来绕过障碍物，机器人还应能够通过蹲下改变其内禀维度，以便在高度受限区域下行进。目前很少有能够处理此类挑战的移动机器人，而双足机器人提供了一种解决方案。然而，由于双足机器人具有非线性和混合动力学特性，同时确保在这些机器人上进行动态可行性和安全的轨迹规划具有挑战性。本文提出了一个端到端的自主导航框架，利用三层规划器和可变步行高度控制器，使双足机器人能够安全地探索高度受限的环境。引入了一个垂直驱动的弹簧负载倒立摆（vSLIP）模型，用于捕捉机器人平面行走和垂直行走高度的耦合动力学。

    Navigating a large-scaled robot in unknown and cluttered height-constrained environments is challenging. Not only is a fast and reliable planning algorithm required to go around obstacles, the robot should also be able to change its intrinsic dimension by crouching in order to travel underneath height-constrained regions. There are few mobile robots that are capable of handling such a challenge, and bipedal robots provide a solution. However, as bipedal robots have nonlinear and hybrid dynamics, trajectory planning while ensuring dynamic feasibility and safety on these robots is challenging. This paper presents an end-to-end autonomous navigation framework which leverages three layers of planners and a variable walking height controller to enable bipedal robots to safely explore height-constrained environments. A vertically-actuated Spring-Loaded Inverted Pendulum (vSLIP) model is introduced to capture the robot's coupled dynamics of planar walking and vertical walking height. This red
    
[^77]: 一种零知识协调的新形式、方法和未解之谜

    A New Formalism, Method and Open Issues for Zero-Shot Coordination. (arXiv:2106.06613v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2106.06613](http://arxiv.org/abs/2106.06613)

    本研究提出了零知识协调问题的正式定义，并证明了之前的解决方法不是最优解。针对这一问题，引入了带有打破平局的其他对局算法作为最优解。

    

    在许多协调问题中，独立推理的人类能够发现互相兼容的策略。相反，独立训练的自博弈策略通常是互不兼容的。零知识协调（ZSC）最近被提出作为多智能体强化学习中的一个新前沿，以解决这一基本问题。先前的研究通过假设玩家可以在学习算法上达成一致，但在行动和观测标签上无法达成一致，提出了其他对局作为一种最优解。然而，直到现在，这个“无标签”问题只是被非正式地定义。我们将这种设置形式化为无标签协调（LFC）问题，通过定义无标签协调博弈来解决。我们证明了其他对局不能成为LFC问题的最优解，因为它未能在不兼容的最大化者之间一致地打破平局。我们引入了算法的扩展，即带有打破平局的其他对局，同时证明了它的最优性。

    In many coordination problems, independently reasoning humans are able to discover mutually compatible policies. In contrast, independently trained self-play policies are often mutually incompatible. Zero-shot coordination (ZSC) has recently been proposed as a new frontier in multi-agent reinforcement learning to address this fundamental issue. Prior work approaches the ZSC problem by assuming players can agree on a shared learning algorithm but not on labels for actions and observations, and proposes other-play as an optimal solution. However, until now, this "label-free" problem has only been informally defined. We formalize this setting as the label-free coordination (LFC) problem by defining the label-free coordination game. We show that other-play is not an optimal solution to the LFC problem as it fails to consistently break ties between incompatible maximizers of the other-play objective. We introduce an extension of the algorithm, other-play with tie-breaking, and prove that it
    
[^78]: 声明性机制设计

    Declarative Mechanism Design. (arXiv:1912.13122v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/1912.13122](http://arxiv.org/abs/1912.13122)

    本文介绍了声明性机制设计的研究，提出了机构神经网络作为一种受管制的人工神经网络，引起人们对人工教学的关注，并提供了初步的答案。

    

    多智能体系统（MAS）和声明性电子机构（DEIs）的调控是过去十年涉及物理和软件智能体以及法律的多学科研究课题，但近年来逐渐演变为2016年起被称为新闻的机器律师。其中一种首次提出限制软件智能体行为的方案是电子机构。然而，随着人工神经网络（ANNs）被重新定义为深度学习（DL），有关DL使用的安全、隐私、伦理和法律问题引起了人工智能（AI）社区的关注。现在，MAS的规范几乎得到正确处理，我们提出将人工神经网络的规范作为一种特殊类型的受管制的人工神经网络，称之为机构神经网络（INN）。本文的主旨是引起人们对人工教学（AT）的关注，并给出一个初步的答案，展示了一种证明性的方法。

    Regulation of Multi-Agent Systems (MAS) and Declarative Electronic Institutions (DEIs) was a multidisciplinary research topic of the past decade involving (Physical and Software) Agents and Law since the beginning, but recently evolved towards News-claimed Robot Lawyer since 2016. One of these first proposals of restricting the behaviour of Software Agentswas Electronic Institutions.However, with the recent reformulation of Artificial Neural Networks (ANNs) as Deep Learning (DL), Security, Privacy,Ethical and Legal issues regarding the use of DL has raised concerns in the Artificial Intelligence (AI) Community. Now that the Regulation of MAS is almost correctly addressed, we propose the Regulation of Artificial Neural Networks as Agent-based Training of a special type of regulated Artificial Neural Network that we call Institutional Neural Network (INN).The main purpose of this paper is to bring attention to Artificial Teaching (AT) and to give a tentative answer showing a proof-of-con
    

