# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [FormalGeo: The First Step Toward Human-like IMO-level Geometric Automated Reasoning.](http://arxiv.org/abs/2310.18021) | FormalGeo是一种完整且兼容的正式平面几何系统，能够利用现代AI模型提供演绎推理解决方案，使AI能够像处理其他自然语言一样解决IMO级平面几何问题，证明可读、追溯和可验证。 |
| [^2] | [Is Channel Independent strategy optimal for Time Series Forecasting?.](http://arxiv.org/abs/2310.17658) | 本文重新考虑了当前通道独立策略在时间序列预测中是否是最佳解决方案，并提出了一种称为CSC的通道自聚类策略来增强性能并减小参数大小。 |
| [^3] | [GraphGPT: Graph Instruction Tuning for Large Language Models.](http://arxiv.org/abs/2310.13023) | 本论文提出了GraphGPT框架，它是一种面向图结构知识的大型语言模型，通过图指令调优实现高度泛化，即使在没有下游图数据的情况下也能在不同的下游数据集和任务上取得很好的效果。 |
| [^4] | [Long-Tailed Classification Based on Coarse-Grained Leading Forest and Multi-Center Loss.](http://arxiv.org/abs/2310.08206) | 本论文提出了一种基于粗粒度引导森林和多中心损失的长尾分类框架，名为Cognisance。该框架致力于解决长尾分类问题中的类间和类内不平衡，并通过不变特征学习构建多粒度联合解决模型。 |
| [^5] | [Divide-and-Conquer Dynamics in AI-Driven Disempowerment.](http://arxiv.org/abs/2310.06009) | 这项研究通过构建游戏理论模型，研究了AI驱动的剥夺中的不团结问题。研究发现，当前受害者需要让未来受害者认识到他们的利益同样面临严重和紧迫的威胁，以激励未来受害者以团结支持当前受害者。 |
| [^6] | [Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4 Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation.](http://arxiv.org/abs/2310.03780) | 本文研究了使用生成式人工智能和大型语言模型自动生成个性化编程反馈的方法。通过结合GPT-4作为“导师”模型生成提示，利用失败的测试用例的信息和修复方法，实现了更高质量的生成提示。然后，利用较弱的GPT-3.5模型作为“学生”模型进一步验证提示的有效性。 |
| [^7] | [LLMR: Real-time Prompting of Interactive Worlds using Large Language Models.](http://arxiv.org/abs/2309.12276) | LLMR是一个用于实时创建和修改交互式混合现实体验的框架，通过利用大型语言模型和新颖的策略，它能够解决训练数据稀缺和设计目标复杂的问题，并在性能上超过标准的GPT-4。我们展示了LLMR的跨平台互操作性，并通过评估和用户研究证明了其对于生成和编辑各种对象、工具和场景的能力。 |
| [^8] | [Exploring the Influence of Information Entropy Change in Learning Systems.](http://arxiv.org/abs/2309.10625) | 本研究探索了在深度学习系统中引入噪声对性能的影响，证明了特定噪声可以在降低任务复杂性的条件下提升深度架构的性能，通过实验证明了在大规模图像数据集中的显著性能提升。 |
| [^9] | [Conformal Temporal Logic Planning using Large Language Models: Knowing When to Do What and When to Ask for Help.](http://arxiv.org/abs/2309.10092) | 本文提出了一个使用大型语言模型的一致时间逻辑规划方法，用于解决多个高级子任务的移动机器人运动规划问题。其中的一个关键挑战是如何以正确性的角度推理机器人计划与基于自然语言的逻辑任务的关系。 |
| [^10] | [SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning.](http://arxiv.org/abs/2309.04766) | SeaEval是一个评估多语言基础模型的基准测试，研究了模型在自然语言理解、推理以及对文化实践、细微差别和价值观的理解能力上的表现。重要发现包括模型在给出改写指令时行为各异，受到暴露偏差的影响，对于语义等价的多语言查询的回答不一致，以及模型在情感相关问题上的一致性不同。 |
| [^11] | [Label Denoising through Cross-Model Agreement.](http://arxiv.org/abs/2308.13976) | 本文提出了一种通过跨模型一致性进行标签去噪的方法。通过观察发现，不同模型在干净示例上的预测相对相似，而在有噪声示例上的预测在不同模型之间变化更大。在这种观察的启发下，我们提出了使用跨模型一致性进行去噪的方法（DeCA），旨在最小化两个机器学习模型参数化的真实标签分布之间的KL散度，同时最大化数据观测的似然。 |
| [^12] | [LR-XFL: Logical Reasoning-based Explainable Federated Learning.](http://arxiv.org/abs/2308.12681) | LR-XFL是一种基于逻辑推理的可解释联邦学习方法，通过将逻辑规则和模型更新结合起来，实现了对FL模型的解释性提升和加权聚合，并在相关基准测试中取得了较好的效果。 |
| [^13] | [Finite Element Operator Network for Solving Parametric PDEs.](http://arxiv.org/abs/2308.04690) | 本文提出了一种新方法，通过有限元算子网络（FEONet）解决参数PDE。它结合了深度学习和传统数值方法，展示了在没有输入-输出训练数据的情况下解决参数PDE的有效性，并在准确度、泛化性和计算灵活性方面优于现有方法。 |
| [^14] | [Anonymizing Speech: Evaluating and Designing Speaker Anonymization Techniques.](http://arxiv.org/abs/2308.04455) | 本研究提出了匿名化语音的解决方案，并评估了匿名化的程度，以应对语音数据收集中的隐私问题和恶意使用的风险。 |
| [^15] | [Discrete Message via Online Clustering Labels in Decentralized POMDP.](http://arxiv.org/abs/2308.03358) | 本文通过建立回报差距上界，将多智能体通信问题转化为离散消息的在线聚类问题。该方法能够提供量化保证，并且具有通信开销低、可解释性好的特点。 |
| [^16] | [Designing Behavior Trees from Goal-Oriented LTLf Formulas.](http://arxiv.org/abs/2307.06399) | 本论文介绍了一种将使用有限访问线性时态逻辑（LTL）的子集指定的目标转化为行为树（BT）的方法，并展示了通过这种方法能够解决一些规划问题。 |
| [^17] | [HypLL: The Hyperbolic Learning Library.](http://arxiv.org/abs/2306.06154) | HypLL是一个使用希亚空间的深度学习库，基于PyTorch，旨在使其易于使用，搭建希亚网络模块，特别适用于处理层次化数据和使用少量嵌入维度，是一种新的、开放的研究方向。 |
| [^18] | [Adaptive action supervision in reinforcement learning from real-world multi-agent demonstrations.](http://arxiv.org/abs/2305.13030) | 本文提出了一种从多智能体场景真实世界展示中进行强化学习的自适应行动监督方法，实现了在复制和推广之间平衡的 RL 模型。 |
| [^19] | [Inventing painting styles through natural inspiration.](http://arxiv.org/abs/2305.12015) | 本文提出了两种方法，通过仅使用自然图像训练的模型创建绘画风格，而不需要艺术训练数据，这能为艺术中的生成AI合法使用铺平道路。 |
| [^20] | [GDP nowcasting with artificial neural networks: How much does long-term memory matter?.](http://arxiv.org/abs/2304.05805) | 通过比较四种人工神经网络和动态因子模型对美国GDP季度增长的预测表现，研究发现在平衡经济增长期间，更长的输入序列能够实现更准确的预测，但是这种效果会在不到两年的时间内消失。在经济动荡时期，长期记忆的效果变得明显。 |
| [^21] | [LossMix: Simplify and Generalize Mixup for Object Detection and Beyond.](http://arxiv.org/abs/2303.10343) | 本论文提出了一种称为 Supervision Interpolation 的新概念框架，通过放松和推广 Mixup 提供了一种全新的插值增强视角，并在此基础上提出了一种名为 LossMix 的简单而多功能的正则化方法，能够增强物体检测器的性能和鲁棒性，或者说LossMix 在目标检测和其他领域中表现出色。 |
| [^22] | [GPT-4 Technical Report.](http://arxiv.org/abs/2303.08774) | GPT-4是一个大规模多模态模型，可以接收图像和文本输入并产生文本输出，能够在各种专业和学术基准测试中表现出人类水平的表现，包括通过模拟的律师考试。该项目的核心组件是开发基础设施和优化方法，可在广泛的规模范围内表现预测性。 |
| [^23] | [Pseudo Contrastive Learning for Graph-based Semi-supervised Learning.](http://arxiv.org/abs/2302.09532) | 本论文提出了一种基于伪对比学习的半监督图神经网络方法，通过生成可靠的负样本对来改进伪标签的质量。 |
| [^24] | [Mathematical Foundations for a Compositional Account of the Bayesian Brain.](http://arxiv.org/abs/2212.12538) | 本文通过应用范畴论的方法为近似推断提供了函子语义，同时还提出了贝叶斯透镜的概念和统计博弈的纤维，对统计推断问题进行了分类。 |
| [^25] | [Risk-Sensitive Reinforcement Learning with Exponential Criteria.](http://arxiv.org/abs/2212.09010) | 本文介绍了一种风险敏感的强化学习算法，使用指数判据来提高其系统抗干扰性和实用性。作者进行了在模拟和实际机器人上的实验验证，表明该算法能够有效地提高样本效率和执行效果。 |
| [^26] | [Fake detection in imbalance dataset by Semi-supervised learning with GAN.](http://arxiv.org/abs/2212.01071) | 本文提出了一种在不平衡数据集中使用半监督学习和生成对抗网络进行虚假检测的方法，实验证明仅使用100个标记样本的情况下，准确率达到了91\%。 |
| [^27] | [Towards Human-centered Explainable AI: A Survey of User Studies for Model Explanations.](http://arxiv.org/abs/2210.11584) | 对模型解释的用户研究综述发现，可解释型人工智能（XAI）正在某些应用领域快速扩散，但用户评估仍然稀缺且几乎不涉及认知或社会科学的见解。 |
| [^28] | [Augmentation-Aware Self-Supervision for Data-Efficient GAN Training.](http://arxiv.org/abs/2205.15677) | 本文提出一种增强感知的自监督判别器用于对生成数据及其增强参数的预测，从而提高判别器的表现和生成模型的性能，实现了数据有效的 GAN 训练。 |
| [^29] | [Fictitious Play Outperforms Counterfactual Regret Minimization.](http://arxiv.org/abs/2001.11165) | 本研究比较了两种算法在近似多人博弈Nash均衡方面的表现，结果发现Fictitious Play比Counterfactual Regret Minimization更优秀。 |

# 详细

[^1]: FormalGeo：迈向人类级IMO水平几何自动推理的第一步

    FormalGeo: The First Step Toward Human-like IMO-level Geometric Automated Reasoning. (arXiv:2310.18021v1 [cs.AI])

    [http://arxiv.org/abs/2310.18021](http://arxiv.org/abs/2310.18021)

    FormalGeo是一种完整且兼容的正式平面几何系统，能够利用现代AI模型提供演绎推理解决方案，使AI能够像处理其他自然语言一样解决IMO级平面几何问题，证明可读、追溯和可验证。

    

    这是我们过去十年工作的第一篇文章。在这一系列论文中，我们构建了一个完整且兼容的正式平面几何系统。这将作为IMO级平面几何挑战与可读的AI自动推理之间的关键桥梁。有了这个正式系统，我们能够无缝地将现代AI模型与我们的正式系统集成在一起。在这个正式框架内，AI现在能够像处理其他自然语言一样对IMO级平面几何问题提供演绎推理解决方案，并且这些证明是可读的、可追溯的和可验证的。我们提出了几何形式化理论（GFT）来指导几何形式系统的发展。基于GFT，我们建立了FormalGeo，包括88个几何谓词和196个定理。它能够表示、验证和解决IMO级几何问题。我们还使用Python开发了FGPS（正式几何问题求解器）。

    This is the first article of our work over the past decade. In this series of papers, we have constructed a complete and compatible formal plane geometry system. This will serve as a crucial bridge between IMO-level plane geometry challenges and readable AI automated reasoning. With this formal system in place, we have been able to seamlessly integrate modern AI models with our formal system. Within this formal framework, AI is now capable of providing deductive reasoning solutions to IMO-level plane geometry problems, just like handling other natural languages, and these proofs are readable, traceable, and verifiable. We propose the geometry formalization theory (GFT) to guide the development of the geometry formal system. Based on the GFT, we have established the FormalGeo, which consists of 88 geometric predicates and 196 theorems. It can represent, validate, and solve IMO-level geometry problems. we also have crafted the FGPS (formal geometry problem solver) in Python. It serves as
    
[^2]: 通道独立策略是否是时间序列预测的最佳解？

    Is Channel Independent strategy optimal for Time Series Forecasting?. (arXiv:2310.17658v1 [cs.LG])

    [http://arxiv.org/abs/2310.17658](http://arxiv.org/abs/2310.17658)

    本文重新考虑了当前通道独立策略在时间序列预测中是否是最佳解决方案，并提出了一种称为CSC的通道自聚类策略来增强性能并减小参数大小。

    

    近年来出现了许多用于长期时间序列预测的模型。最近的研究表明，使用单一线性层的通道相关(CD)或通道独立(CI)建模，甚至可以超过许多复杂模型的性能。然而，当前的研究主要将CD和CI视为两种互补但互斥的方法，无法同时利用这两个极端。而且，CD和CI都是静态策略，无法在没有大量实验的情况下确定是特定数据集的最佳策略。在本文中，我们重新考虑了当前CI策略是否是时间序列预测的最佳解决方案。首先，我们提出了一种简单而有效的策略，称为CSC（通道自聚类策略），用于线性模型。我们的通道自聚类策略增强了CI策略的性能改进，并减小了参数大小。

    There has been an emergence of various models for long-term time series forecasting. Recent studies have demonstrated that a single linear layer, using Channel Dependent (CD) or Channel Independent (CI) modeling, can even outperform a large number of sophisticated models. However, current research primarily considers CD and CI as two complementary yet mutually exclusive approaches, unable to harness these two extremes simultaneously. And it is also a challenging issue that both CD and CI are static strategies that cannot be determined to be optimal for a specific dataset without extensive experiments. In this paper, we reconsider whether the current CI strategy is the best solution for time series forecasting. First, we propose a simple yet effective strategy called CSC, which stands for $\mathbf{C}$hannel $\mathbf{S}$elf-$\mathbf{C}$lustering strategy, for linear models. Our Channel Self-Clustering (CSC) enhances CI strategy's performance improvements while reducing parameter size, fo
    
[^3]: GraphGPT: 大型语言模型的图指令调优

    GraphGPT: Graph Instruction Tuning for Large Language Models. (arXiv:2310.13023v1 [cs.CL])

    [http://arxiv.org/abs/2310.13023](http://arxiv.org/abs/2310.13023)

    本论文提出了GraphGPT框架，它是一种面向图结构知识的大型语言模型，通过图指令调优实现高度泛化，即使在没有下游图数据的情况下也能在不同的下游数据集和任务上取得很好的效果。

    

    通过图节点之间的递归信息交换和聚合，图神经网络（GNN）在理解图结构方面取得了进展。为了提高模型的健壮性，自监督学习（SSL）已经成为一种有前途的数据增强方法。然而，现有的用于生成预训练图嵌入的方法通常依赖于对特定下游任务标签进行微调，这限制了它们在标记数据稀缺或不可用的情况下的可用性。为了解决这个问题，我们的研究重点是提升图模型在具有挑战性的零样本学习场景中的泛化能力。受大型语言模型（LLM）的成功启发，我们的目标是开发一种面向图结构知识的LLM，即使没有来自下游图数据的任何信息，也能在不同的下游数据集和任务上实现高度泛化。在这项工作中，我们提出了GraphGPT框架，通过图指令调优将LLM与图结构知识对齐。

    Graph Neural Networks (GNNs) have advanced graph structure understanding via recursive information exchange and aggregation among graph nodes. To improve model robustness, self-supervised learning (SSL) has emerged as a promising approach for data augmentation. However, existing methods for generating pre-trained graph embeddings often rely on fine-tuning with specific downstream task labels, which limits their usability in scenarios where labeled data is scarce or unavailable. To address this, our research focuses on advancing the generalization capabilities of graph models in challenging zero-shot learning scenarios. Inspired by the success of large language models (LLMs), we aim to develop a graph-oriented LLM that can achieve high generalization across diverse downstream datasets and tasks, even without any information available from the downstream graph data. In this work, we present the GraphGPT framework that aligns LLMs with graph structural knowledge with a graph instruction t
    
[^4]: 基于粗粒度引导森林和多中心损失的长尾分类

    Long-Tailed Classification Based on Coarse-Grained Leading Forest and Multi-Center Loss. (arXiv:2310.08206v1 [cs.CV])

    [http://arxiv.org/abs/2310.08206](http://arxiv.org/abs/2310.08206)

    本论文提出了一种基于粗粒度引导森林和多中心损失的长尾分类框架，名为Cognisance。该框架致力于解决长尾分类问题中的类间和类内不平衡，并通过不变特征学习构建多粒度联合解决模型。

    

    长尾分类是现实世界中不可避免且具有挑战性的问题。大部分现有的长尾分类方法仅关注解决类间不平衡，即头部类别的样本比尾部类别的样本多，而忽略了类内不平衡，即同一类别中头部属性样本数量远大于尾部属性样本数量。模型的偏差是由这两个因素引起的，由于大多数数据集中的属性是隐含的且属性组合非常复杂，处理类内不平衡更加困难。为此，我们提出了一种基于粗粒度引导森林（CLF）和多中心损失（MCL）的长尾分类框架，名为Cognisance，旨在通过不变特征学习构建多粒度联合解决模型。在这个方法中，我们设计了一种新颖的样本选择策略和损失函数，以平衡不同类别和属性之间的样本分布。

    Long-tailed(LT) classification is an unavoidable and challenging problem in the real world. Most of the existing long-tailed classification methods focus only on solving the inter-class imbalance in which there are more samples in the head class than in the tail class, while ignoring the intra-lass imbalance in which the number of samples of the head attribute within the same class is much larger than the number of samples of the tail attribute. The deviation in the model is caused by both of these factors, and due to the fact that attributes are implicit in most datasets and the combination of attributes is very complex, the intra-class imbalance is more difficult to handle. For this purpose, we proposed a long-tailed classification framework, known as \textbf{\textsc{Cognisance}}, which is founded on Coarse-Grained Leading Forest (CLF) and Multi-Center Loss (MCL), aiming to build a multi-granularity joint solution model by means of invariant feature learning. In this method, we desig
    
[^5]: AI驱动的剥夺中的分而治之动态

    Divide-and-Conquer Dynamics in AI-Driven Disempowerment. (arXiv:2310.06009v1 [cs.CY])

    [http://arxiv.org/abs/2310.06009](http://arxiv.org/abs/2310.06009)

    这项研究通过构建游戏理论模型，研究了AI驱动的剥夺中的不团结问题。研究发现，当前受害者需要让未来受害者认识到他们的利益同样面临严重和紧迫的威胁，以激励未来受害者以团结支持当前受害者。

    

    AI公司试图创造出在大部分经济价值工作上超越人类的AI系统。当前的AI模型已经自动化削弱了一些艺术家、演员和作家的生计。但是在那些优先考虑当前危害和未来危害之间存在着内讧。我们构建了一个博弈论模型来研究这种不团结的原因和后果。我们的模型还有助于解释为什么在历史上，面临共同威胁的利益相关方发现联合起来对抗该威胁是有利的，而该共同威胁又发现分而治之是有利的。在现实参数假设下，我们的模型提出了几个预测，在历史经验记录中得到了初步的证实。

    AI companies are attempting to create AI systems that outperform humans at most economically valuable work. Current AI models are already automating away the livelihoods of some artists, actors, and writers. But there is infighting between those who prioritize current harms and future harms. We construct a game-theoretic model of conflict to study the causes and consequences of this disunity. Our model also helps explain why throughout history, stakeholders sharing a common threat have found it advantageous to unite against it, and why the common threat has in turn found it advantageous to divide and conquer.  Under realistic parameter assumptions, our model makes several predictions that find preliminary corroboration in the historical-empirical record. First, current victims of AI-driven disempowerment need the future victims to realize that their interests are also under serious and imminent threat, so that future victims are incentivized to support current victims in solidarity. Se
    
[^6]: 自动化人工导师式编程反馈: 利用GPT-4导师模型生成提示和GPT-3.5学生模型进行提示验证

    Automating Human Tutor-Style Programming Feedback: Leveraging GPT-4 Tutor Model for Hint Generation and GPT-3.5 Student Model for Hint Validation. (arXiv:2310.03780v1 [cs.AI])

    [http://arxiv.org/abs/2310.03780](http://arxiv.org/abs/2310.03780)

    本文研究了使用生成式人工智能和大型语言模型自动生成个性化编程反馈的方法。通过结合GPT-4作为“导师”模型生成提示，利用失败的测试用例的信息和修复方法，实现了更高质量的生成提示。然后，利用较弱的GPT-3.5模型作为“学生”模型进一步验证提示的有效性。

    

    生成式人工智能和大型语言模型在提供个性化编程反馈方面具有巨大潜力。本文研究了生成式人工智能模型在提供人工导师式编程提示方面的作用，以帮助学生解决程序中的错误。然而，最新的研究工作虽然对各种反馈生成场景进行了评估，但其整体质量仍远不及人工导师，并且还没有准备好在实际环境中投入使用。为了提高生成式人工智能模型提供高质量编程提示的能力，我们开发了一种新的技术，名为GPT4Hints-GPT3.5Val。首先，我们的技术利用GPT-4作为“导师”模型生成提示，通过使用失败的测试用例的符号信息和提示中的修复方法，提高了生成质量。接下来，我们的技术利用较弱的GPT-3.5模型作为“学生”模型进一步验证提示的有效性。

    Generative AI and large language models hold great promise in enhancing programming education by automatically generating individualized feedback for students. We investigate the role of generative AI models in providing human tutor-style programming hints to help students resolve errors in their buggy programs. Recent works have benchmarked state-of-the-art models for various feedback generation scenarios; however, their overall quality is still inferior to human tutors and not yet ready for real-world deployment. In this paper, we seek to push the limits of generative AI models toward providing high-quality programming hints and develop a novel technique, GPT4Hints-GPT3.5Val. As a first step, our technique leverages GPT-4 as a ``tutor'' model to generate hints -- it boosts the generative quality by using symbolic information of failing test cases and fixes in prompts. As a next step, our technique leverages GPT-3.5, a weaker model, as a ``student'' model to further validate the hint 
    
[^7]: LLMR：使用大型语言模型实时提示交互式世界的框架

    LLMR: Real-time Prompting of Interactive Worlds using Large Language Models. (arXiv:2309.12276v1 [cs.HC])

    [http://arxiv.org/abs/2309.12276](http://arxiv.org/abs/2309.12276)

    LLMR是一个用于实时创建和修改交互式混合现实体验的框架，通过利用大型语言模型和新颖的策略，它能够解决训练数据稀缺和设计目标复杂的问题，并在性能上超过标准的GPT-4。我们展示了LLMR的跨平台互操作性，并通过评估和用户研究证明了其对于生成和编辑各种对象、工具和场景的能力。

    

    我们提出了用于混合现实场景的大型语言模型(LLMR)，这是一个框架，用于实时创建和修改交互式混合现实体验。LLMR利用了新颖的策略来解决训练数据稀缺或设计目标需要合成内部动态、直观分析或高级交互的困难情况。我们的框架依赖于文本交互和Unity游戏引擎。通过融合场景理解、任务规划、自我调试和内存管理技术，LLMR在平均错误率上比标准的GPT-4提高了4倍。我们展示了LLMR与几个示例世界的跨平台互操作性，并通过多个创建和修改任务对其进行了评估，以展示它能够生成和编辑各种对象、工具和场景。最后，我们进行了一个有多样性的可用性研究（N=11），揭示了参与者对该系统有积极的体验，并愿意再次使用它。

    We present Large Language Model for Mixed Reality (LLMR), a framework for the real-time creation and modification of interactive Mixed Reality experiences using LLMs. LLMR leverages novel strategies to tackle difficult cases where ideal training data is scarce, or where the design goal requires the synthesis of internal dynamics, intuitive analysis, or advanced interactivity. Our framework relies on text interaction and the Unity game engine. By incorporating techniques for scene understanding, task planning, self-debugging, and memory management, LLMR outperforms the standard GPT-4 by 4x in average error rate. We demonstrate LLMR's cross-platform interoperability with several example worlds, and evaluate it on a variety of creation and modification tasks to show that it can produce and edit diverse objects, tools, and scenes. Finally, we conducted a usability study (N=11) with a diverse set that revealed participants had positive experiences with the system and would use it again.
    
[^8]: 探索学习系统中信息熵变化的影响

    Exploring the Influence of Information Entropy Change in Learning Systems. (arXiv:2309.10625v1 [cs.AI])

    [http://arxiv.org/abs/2309.10625](http://arxiv.org/abs/2309.10625)

    本研究探索了在深度学习系统中引入噪声对性能的影响，证明了特定噪声可以在降低任务复杂性的条件下提升深度架构的性能，通过实验证明了在大规模图像数据集中的显著性能提升。

    

    在本研究中，我们通过向输入/隐含特征添加噪声来探索深度学习系统中熵变化的影响。本文的应用重点是计算机视觉中的深度学习任务，但所提出的理论可以进一步应用于其他领域。噪声通常被视为各种深度学习架构（如卷积神经网络和视觉变换器）以及图像分类和迁移学习等不同学习任务中的有害扰动。然而，本文旨在重新思考传统命题是否总是成立。我们证明了在特定条件下，特定噪声可以提升各种深度架构的性能。我们在信息熵定义的任务复杂性减少方面从理论上证明了正噪声的增强效果，并在大规模图像数据集（如ImageNet）中实验证明了显著的性能提升。

    In this work, we explore the influence of entropy change in deep learning systems by adding noise to the inputs/latent features. The applications in this paper focus on deep learning tasks within computer vision, but the proposed theory can be further applied to other fields. Noise is conventionally viewed as a harmful perturbation in various deep learning architectures, such as convolutional neural networks (CNNs) and vision transformers (ViTs), as well as different learning tasks like image classification and transfer learning. However, this paper aims to rethink whether the conventional proposition always holds. We demonstrate that specific noise can boost the performance of various deep architectures under certain conditions. We theoretically prove the enhancement gained from positive noise by reducing the task complexity defined by information entropy and experimentally show the significant performance gain in large image datasets, such as the ImageNet. Herein, we use the informat
    
[^9]: 使用大型语言模型的一致时间逻辑规划：知道何时做什么和何时寻求帮助。

    Conformal Temporal Logic Planning using Large Language Models: Knowing When to Do What and When to Ask for Help. (arXiv:2309.10092v1 [cs.RO])

    [http://arxiv.org/abs/2309.10092](http://arxiv.org/abs/2309.10092)

    本文提出了一个使用大型语言模型的一致时间逻辑规划方法，用于解决多个高级子任务的移动机器人运动规划问题。其中的一个关键挑战是如何以正确性的角度推理机器人计划与基于自然语言的逻辑任务的关系。

    

    本文解决了一个新的移动机器人运动规划问题，任务是以自然语言（NL）表达并以时间和逻辑顺序完成多个高级子任务。为了正式定义这样的任务，我们利用基于NL的原子谓词在LTL上定义了模型。这与相关的规划方法形成对比，这些方法在原子谓词上定义了捕捉所需低级系统配置的LTL任务。我们的目标是设计机器人计划，满足基于NL的原子命题定义的LTL任务。在这个设置中出现的一个新的技术挑战在于推理机器人计划的正确性与这些LTL编码的任务的关系。为了解决这个问题，我们提出了HERACLEs，一个分层一致的自然语言规划器，它依赖于现有工具的新型整合，包括（i）自动机理论，以确定机器人应该完成的NL指定的子任务以推进任务进展；

    This paper addresses a new motion planning problem for mobile robots tasked with accomplishing multiple high-level sub-tasks, expressed using natural language (NL), in a temporal and logical order. To formally define such missions, we leverage LTL defined over NL-based atomic predicates modeling the considered NL-based sub-tasks. This is contrast to related planning approaches that define LTL tasks over atomic predicates capturing desired low-level system configurations. Our goal is to design robot plans that satisfy LTL tasks defined over NL-based atomic propositions. A novel technical challenge arising in this setup lies in reasoning about correctness of a robot plan with respect to such LTL-encoded tasks. To address this problem, we propose HERACLEs, a hierarchical conformal natural language planner, that relies on a novel integration of existing tools that include (i) automata theory to determine the NL-specified sub-task the robot should accomplish next to make mission progress; (
    
[^10]: SeaEval多语言基础模型：从跨语言对齐到文化推理

    SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning. (arXiv:2309.04766v1 [cs.CL])

    [http://arxiv.org/abs/2309.04766](http://arxiv.org/abs/2309.04766)

    SeaEval是一个评估多语言基础模型的基准测试，研究了模型在自然语言理解、推理以及对文化实践、细微差别和价值观的理解能力上的表现。重要发现包括模型在给出改写指令时行为各异，受到暴露偏差的影响，对于语义等价的多语言查询的回答不一致，以及模型在情感相关问题上的一致性不同。

    

    我们提出了一种用于多语言基础模型的SeaEval基准测试。除了表征这些模型如何理解和推理自然语言外，我们还研究了它们对文化实践、细微差别和价值观的理解能力。除了标准的准确度指标，我们还调查了基础模型在语义和多语言性维度上的脆弱性。我们的分析涵盖了开源和闭源模型，从而得到了在经典的自然语言处理任务、推理和文化理解方面的实证结果。重要发现包括：（1）大多数模型在给出改写指令时的行为各异；（2）许多模型仍然受到暴露偏差的影响（如位置偏差、大多数标签偏差）；（3）对于根源于事实、科学和常识知识的问题，预期在语义上等价的多语言查询应该得到一致的回答。然而，大多数模型在这些查询上表现出令人意外的不一致性；（4）多语言情况下，模型对于情感相关的问题表现出不同程度的一致性。

    We present SeaEval, a benchmark for multilingual foundation models. In addition to characterizing how these models understand and reason with natural language, we also investigate how well they comprehend cultural practices, nuances, and values. Alongside standard accuracy metrics, we investigate the brittleness of foundation models in the dimensions of semantics and multilinguality. Our analyses span both open-sourced and closed models, leading to empirical results across classic NLP tasks, reasoning, and cultural comprehension. Key findings indicate (1) Most models exhibit varied behavior when given paraphrased instructions. (2) Many models still suffer from exposure bias (e.g., positional bias, majority label bias). (3) For questions rooted in factual, scientific, and commonsense knowledge, consistent responses are expected across multilingual queries that are semantically equivalent. Yet, most models surprisingly demonstrate inconsistent performance on these queries. (4) Multilingu
    
[^11]: 通过跨模型一致性进行标签去噪

    Label Denoising through Cross-Model Agreement. (arXiv:2308.13976v1 [cs.LG])

    [http://arxiv.org/abs/2308.13976](http://arxiv.org/abs/2308.13976)

    本文提出了一种通过跨模型一致性进行标签去噪的方法。通过观察发现，不同模型在干净示例上的预测相对相似，而在有噪声示例上的预测在不同模型之间变化更大。在这种观察的启发下，我们提出了使用跨模型一致性进行去噪的方法（DeCA），旨在最小化两个机器学习模型参数化的真实标签分布之间的KL散度，同时最大化数据观测的似然。

    

    在现实世界的机器学习应用中，从有噪声的标签学习是非常常见的。记忆这些有噪声的标签可能会影响模型的学习，从而导致次优的性能。在这项工作中，我们提出了一种新颖的框架，用于从有噪声标签中学习鲁棒的机器学习模型。通过实证研究，我们发现不同模型在干净示例上的预测相对相似，而在有噪声示例上的预测在不同模型之间变化更大。受到这一观察的启发，我们提出了使用跨模型一致性进行去噪（DeCA）的方法，该方法旨在最小化由两个机器学习模型参数化的真实标签分布之间的KL散度，同时最大化数据观测的似然。我们将提出的DeCA方法应用于二进制标签情景和多标签情景。对于二进制标签情景，我们选择隐式反馈推荐作为下游任务，并进行了四种最先进方法的实验。

    Learning from corrupted labels is very common in real-world machine-learning applications. Memorizing such noisy labels could affect the learning of the model, leading to sub-optimal performances. In this work, we propose a novel framework to learn robust machine-learning models from noisy labels. Through an empirical study, we find that different models make relatively similar predictions on clean examples, while the predictions on noisy examples vary much more across different models. Motivated by this observation, we propose \em denoising with cross-model agreement \em (DeCA) which aims to minimize the KL-divergence between the true label distributions parameterized by two machine learning models while maximizing the likelihood of data observation. We employ the proposed DeCA on both the binary label scenario and the multiple label scenario. For the binary label scenario, we select implicit feedback recommendation as the downstream task and conduct experiments with four state-of-the
    
[^12]: LR-XFL: 基于逻辑推理的可解释联邦学习

    LR-XFL: Logical Reasoning-based Explainable Federated Learning. (arXiv:2308.12681v1 [cs.AI])

    [http://arxiv.org/abs/2308.12681](http://arxiv.org/abs/2308.12681)

    LR-XFL是一种基于逻辑推理的可解释联邦学习方法，通过将逻辑规则和模型更新结合起来，实现了对FL模型的解释性提升和加权聚合，并在相关基准测试中取得了较好的效果。

    

    联邦学习 (FL) 是一种新兴的机器学习模型协作训练方法，能够保护数据隐私。隐私保护的需求使得FL模型很难实现全局透明度和可解释性。为了解决这个限制，我们提出了基于逻辑推理的可解释联邦学习 (LR-XFL) 方法，将逻辑推理融入FL中。在LR-XFL中，FL客户端根据其本地数据创建本地逻辑规则，并将其与模型更新一起发送到FL服务器。FL服务器通过适当的逻辑连接符将本地逻辑规则连接起来，该连接符基于客户端数据的属性进行推导，而无需访问原始数据。此外，服务器还根据客户端上传的逻辑规则反映的本地数据的质量，使用权重值对本地模型更新进行聚合。结果显示，LR-XFL在最相关的基准测试中超过1.19％，5.81％和5.41％。

    Federated learning (FL) is an emerging approach for training machine learning models collaboratively while preserving data privacy. The need for privacy protection makes it difficult for FL models to achieve global transparency and explainability. To address this limitation, we incorporate logic-based explanations into FL by proposing the Logical Reasoning-based eXplainable Federated Learning (LR-XFL) approach. Under LR-XFL, FL clients create local logic rules based on their local data and send them, along with model updates, to the FL server. The FL server connects the local logic rules through a proper logical connector that is derived based on properties of client data, without requiring access to the raw data. In addition, the server also aggregates the local model updates with weight values determined by the quality of the clients' local data as reflected by their uploaded logic rules. The results show that LR-XFL outperforms the most relevant baseline by 1.19%, 5.81% and 5.41% in
    
[^13]: 用于解决参数PDE的有限元算子网络

    Finite Element Operator Network for Solving Parametric PDEs. (arXiv:2308.04690v1 [math.NA])

    [http://arxiv.org/abs/2308.04690](http://arxiv.org/abs/2308.04690)

    本文提出了一种新方法，通过有限元算子网络（FEONet）解决参数PDE。它结合了深度学习和传统数值方法，展示了在没有输入-输出训练数据的情况下解决参数PDE的有效性，并在准确度、泛化性和计算灵活性方面优于现有方法。

    

    偏微分方程（PDE）是我们理解和预测物理、工程和金融等众多领域自然现象的基础。然而，解决参数PDE是一项复杂的任务，需要高效的数值方法。在本文中，我们提出了一种通过有限元算子网络（FEONet）解决参数PDE的新方法。我们的方法结合了深度学习和传统数值方法，特别是有限元法，以在没有任何配对的输入-输出训练数据的情况下解决参数PDE。我们在几个基准问题上展示了我们方法的效果，并且表明它在准确度、泛化性和计算灵活性方面优于现有的最先进方法。我们的FEONet框架在模拟具有不同边界条件和复杂域的各种领域中显示出潜力。

    Partial differential equations (PDEs) underlie our understanding and prediction of natural phenomena across numerous fields, including physics, engineering, and finance. However, solving parametric PDEs is a complex task that necessitates efficient numerical methods. In this paper, we propose a novel approach for solving parametric PDEs using a Finite Element Operator Network (FEONet). Our proposed method leverages the power of deep learning in conjunction with traditional numerical methods, specifically the finite element method, to solve parametric PDEs in the absence of any paired input-output training data. We demonstrate the effectiveness of our approach on several benchmark problems and show that it outperforms existing state-of-the-art methods in terms of accuracy, generalization, and computational flexibility. Our FEONet framework shows potential for application in various fields where PDEs play a crucial role in modeling complex domains with diverse boundary conditions and sin
    
[^14]: 匿名化语音：评估和设计说话人匿名化技术

    Anonymizing Speech: Evaluating and Designing Speaker Anonymization Techniques. (arXiv:2308.04455v1 [cs.CR])

    [http://arxiv.org/abs/2308.04455](http://arxiv.org/abs/2308.04455)

    本研究提出了匿名化语音的解决方案，并评估了匿名化的程度，以应对语音数据收集中的隐私问题和恶意使用的风险。

    

    随着语音用户界面的广泛使用，语音数据的收集和存储也大大增加。虽然数据收集可以为大多数语音服务提供高效的工具，但它也给用户的隐私造成严重的问题，因为集中存储使个人的语音数据容易受到网络威胁的侵害。随着亚马逊的Alexa，谷歌的Home和苹果的Siri等基于语音的数字助手的使用增加，以及个人语音数据收集变得越来越容易，声音克隆和说话人/性别/病理等识别的恶意使用的风险也增加了。本文提出了匿名化语音的解决方案，并评估匿名化的程度。在这项工作中，匿名化是指使个人语音数据与身份无法关联，同时保持语音信号的实用性（例如，访问语言内容）。我们首先确定了几个评估协议的挑战。

    The growing use of voice user interfaces has led to a surge in the collection and storage of speech data. While data collection allows for the development of efficient tools powering most speech services, it also poses serious privacy issues for users as centralized storage makes private personal speech data vulnerable to cyber threats. With the increasing use of voice-based digital assistants like Amazon's Alexa, Google's Home, and Apple's Siri, and with the increasing ease with which personal speech data can be collected, the risk of malicious use of voice-cloning and speaker/gender/pathological/etc. recognition has increased.  This thesis proposes solutions for anonymizing speech and evaluating the degree of the anonymization. In this work, anonymization refers to making personal speech data unlinkable to an identity while maintaining the usefulness (utility) of the speech signal (e.g., access to linguistic content). We start by identifying several challenges that evaluation protoco
    
[^15]: 分散式POMDP中基于在线聚类标签的离散消息传递

    Discrete Message via Online Clustering Labels in Decentralized POMDP. (arXiv:2308.03358v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.03358](http://arxiv.org/abs/2308.03358)

    本文通过建立回报差距上界，将多智能体通信问题转化为离散消息的在线聚类问题。该方法能够提供量化保证，并且具有通信开销低、可解释性好的特点。

    

    在部分可观察的马尔可夫决策过程中，通信对于解决合作多智能体强化学习任务至关重要。现有工作通常依赖于黑盒方法，将本地信息/特征编码成与其他智能体共享的消息。然而，这种黑盒方法无法对期望回报提供任何量化保证，常常导致生成通信开销高、可解释性差的连续消息。本文在理想策略与最优部分可观察策略之间建立了回报差距的上界。该结果使我们能够将多智能体通信重新定义为每个智能体的本地观察中的一种新颖的在线聚类问题，其中消息作为聚类标签，并且回报差距的上界作为聚类损失。通过最小化上界，我们提出了一个令人惊讶地简单的消息生成函数设计。

    Communication is crucial for solving cooperative Multi-Agent Reinforcement Learning tasks in Partially-Observable Markov Decision Processes. Existing works often rely on black-box methods to encode local information/features into messages shared with other agents. However, such black-box approaches are unable to provide any quantitative guarantees on the expected return and often lead to the generation of continuous messages with high communication overhead and poor interpretability. In this paper, we establish an upper bound on the return gap between an ideal policy with full observability and an optimal partially-observable policy with discrete communication. This result enables us to recast multi-agent communication into a novel online clustering problem over the local observations at each agent, with messages as cluster labels and the upper bound on the return gap as clustering loss. By minimizing the upper bound, we propose a surprisingly simple design of message generation functi
    
[^16]: 从面向目标的LTLf公式设计行为树

    Designing Behavior Trees from Goal-Oriented LTLf Formulas. (arXiv:2307.06399v1 [cs.AI])

    [http://arxiv.org/abs/2307.06399](http://arxiv.org/abs/2307.06399)

    本论文介绍了一种将使用有限访问线性时态逻辑（LTL）的子集指定的目标转化为行为树（BT）的方法，并展示了通过这种方法能够解决一些规划问题。

    

    时间逻辑可以用于形式化指定自主代理目标，但合成能够保证目标满足的计划者可能具有计算上的限制。本文展示了如何将使用有限访问线性时态逻辑（LTL）的子集指定的目标转化为保证成功路径满足LTL目标的行为树（BT）。可以使用以实现目标为导向的任务任务语法来提取有用的LTL公式，其中由LTL运算符组合的任务构成任务。通过LTL公式构建BT导致了一种放松的行为合成问题，在该问题中，各种计划者可以实现BT中的动作节点。重要的是，计划者导致的任何成功路径都满足相应的LTL公式。该方法的有用性通过两种方式进行了演示：a) 探索两个计划者和LTL目标之间的对齐，b) 解决Fetch机器人的顺序门锁问题。

    Temporal logic can be used to formally specify autonomous agent goals, but synthesizing planners that guarantee goal satisfaction can be computationally prohibitive. This paper shows how to turn goals specified using a subset of finite trace Linear Temporal Logic (LTL) into a behavior tree (BT) that guarantees that successful traces satisfy the LTL goal. Useful LTL formulas for achievement goals can be derived using achievement-oriented task mission grammars, leading to missions made up of tasks combined using LTL operators. Constructing BTs from LTL formulas leads to a relaxed behavior synthesis problem in which a wide range of planners can implement the action nodes in the BT. Importantly, any successful trace induced by the planners satisfies the corresponding LTL formula. The usefulness of the approach is demonstrated in two ways: a) exploring the alignment between two planners and LTL goals, and b) solving a sequential key-door problem for a Fetch robot.
    
[^17]: HypLL: 希亚空间深度学习库

    HypLL: The Hyperbolic Learning Library. (arXiv:2306.06154v1 [cs.LG])

    [http://arxiv.org/abs/2306.06154](http://arxiv.org/abs/2306.06154)

    HypLL是一个使用希亚空间的深度学习库，基于PyTorch，旨在使其易于使用，搭建希亚网络模块，特别适用于处理层次化数据和使用少量嵌入维度，是一种新的、开放的研究方向。

    

    在机器学习、多媒体和计算机视觉等领域，希亚空间深度学习正迅速引起关注。深度网络通常在欧几里得空间中运行，隐含地假设数据在规则网格上。最近的研究表明，当处理层次化数据和使用少量嵌入维度时，希亚几何提供了一个可行的深度学习基础。然而，目前没有可访问的开源库用于构建类似于众所周知的深度学习库的希亚网络模块。我们提出了HypLL, 即希亚空间深度学习库，以将希亚深度学习的进展聚集在一起。HypLL建立在PyTorch之上，特别强调其易用性设计，以吸引广泛的受众关注这个新的和开放的研究方向。代码可在以下网址找到：https://github.com/maxvanspengler/hyperbolic_learning_library。压缩文件可在以下网址找到：https://d

    Deep learning in hyperbolic space is quickly gaining traction in the fields of machine learning, multimedia, and computer vision. Deep networks commonly operate in Euclidean space, implicitly assuming that data lies on regular grids. Recent advances have shown that hyperbolic geometry provides a viable alternative foundation for deep learning, especially when data is hierarchical in nature and when working with few embedding dimensions. Currently however, no accessible open-source library exists to build hyperbolic network modules akin to well-known deep learning libraries. We present HypLL, the Hyperbolic Learning Library to bring the progress on hyperbolic deep learning together. HypLL is built on top of PyTorch, with an emphasis in its design for easy-of-use, in order to attract a broad audience towards this new and open-ended research direction. The code is available at: https://github.com/maxvanspengler/hyperbolic_learning_library. The compressed archive is available at: https://d
    
[^18]: 多智能体真实世界展示中强化学习的自适应行动监督

    Adaptive action supervision in reinforcement learning from real-world multi-agent demonstrations. (arXiv:2305.13030v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.13030](http://arxiv.org/abs/2305.13030)

    本文提出了一种从多智能体场景真实世界展示中进行强化学习的自适应行动监督方法，实现了在复制和推广之间平衡的 RL 模型。

    

    在各种科学和工程领域中，对真实世界生物多智能体进行建模是一个基本问题。强化学习（RL）是在网络空间中生成灵活和多样化行为的强大框架；然而，在建模真实世界生物多智能体时，在源（即真实世界数据）和目标（即 RL 的网络空间）之间存在域差异，并且源环境参数通常是未知的。在本文中，我们提出了一种从多智能体场景的真实世界展示中进行 RL 的自适应行动监督的方法。我们采用结合 RL 和监督学习的方法，通过选择基于动态时间扭曲的演示动作来在 RL 中利用未知源动态的信息。这种方法可以轻松应用于许多现有的神经网络架构，并为我们提供一个在复制和推广之间平衡的 RL 模型。

    Modeling of real-world biological multi-agents is a fundamental problem in various scientific and engineering fields. Reinforcement learning (RL) is a powerful framework to generate flexible and diverse behaviors in cyberspace; however, when modeling real-world biological multi-agents, there is a domain gap between behaviors in the source (i.e., real-world data) and the target (i.e., cyberspace for RL), and the source environment parameters are usually unknown. In this paper, we propose a method for adaptive action supervision in RL from real-world demonstrations in multi-agent scenarios. We adopt an approach that combines RL and supervised learning by selecting actions of demonstrations in RL based on the minimum distance of dynamic time warping for utilizing the information of the unknown source dynamics. This approach can be easily applied to many existing neural network architectures and provide us with an RL model balanced between reproducibility as imitation and generalization ab
    
[^19]: 通过自然灵感发明绘画风格

    Inventing painting styles through natural inspiration. (arXiv:2305.12015v1 [cs.CV])

    [http://arxiv.org/abs/2305.12015](http://arxiv.org/abs/2305.12015)

    本文提出了两种方法，通过仅使用自然图像训练的模型创建绘画风格，而不需要艺术训练数据，这能为艺术中的生成AI合法使用铺平道路。

    

    我们提出了两种通过仅使用自然图像训练的模型创建绘画风格的方法，从而提供了客观证据证明模型没有剽窃人类艺术风格。在第一种方法中，我们使用艺术媒介的归纳偏置来实现创造性的表达。通过使用重建损失来实现抽象。第二种方法使用额外的自然图像作为灵感来创建新的风格。这两种方法使得可以发明新的绘画风格，而无需艺术训练数据。我们相信，我们的方法可以帮助为艺术中生成AI的合法使用铺平道路，而不侵犯人类创造者的独创性。

    We propose two procedures to create painting styles using models trained only on natural images, providing objective proof that the model is not plagiarizing human art styles. In the first procedure we use the inductive bias from the artistic medium to achieve creative expression. Abstraction is achieved by using a reconstruction loss. The second procedure uses an additional natural image as inspiration to create a new style. These two procedures make it possible to invent new painting styles with no artistic training data. We believe that our approach can help pave the way for the ethical employment of generative AI in art, without infringing upon the originality of human creators.
    
[^20]: 用人工神经网络预测国内生产总值：长期记忆有多大的作用？

    GDP nowcasting with artificial neural networks: How much does long-term memory matter?. (arXiv:2304.05805v1 [econ.EM])

    [http://arxiv.org/abs/2304.05805](http://arxiv.org/abs/2304.05805)

    通过比较四种人工神经网络和动态因子模型对美国GDP季度增长的预测表现，研究发现在平衡经济增长期间，更长的输入序列能够实现更准确的预测，但是这种效果会在不到两年的时间内消失。在经济动荡时期，长期记忆的效果变得明显。

    

    在本研究中，我们将不同的统计模型应用于美国经济季度国内生产总值（GDP）增长预测。使用每月的FRED-MD数据库，我们比较了动态因子模型（DFM）和四个人工神经网络（ANNs）的预测表现：多层感知机（MLP）、一维卷积神经网络（1D CNN）、长短期记忆网络（LSTM）和门控循环单元（GRU）。实证分析呈现了两个不同评估周期的结果。第一个周期（2010年第1季度至2019年第4季度）具有平衡的经济增长，而第二个周期（2010年第1季度至2022年第3季度）还包括COVID-19衰退期间的时间。根据我们的结果，更长的输入序列在平衡经济增长期间能够实现更准确的预测。然而，在一个相对较低的阈值值（约六个季度或十八个月）以后，这种效应会消失。在经济动荡期（如COVID-19衰退期间），长期记忆的效果会变得较为明显。

    In our study, we apply different statistical models to nowcast quarterly GDP growth for the US economy. Using the monthly FRED-MD database, we compare the nowcasting performance of the dynamic factor model (DFM) and four artificial neural networks (ANNs): the multilayer perceptron (MLP), the one-dimensional convolutional neural network (1D CNN), the long short-term memory network (LSTM), and the gated recurrent unit (GRU). The empirical analysis presents the results from two distinctively different evaluation periods. The first (2010:Q1 -- 2019:Q4) is characterized by balanced economic growth, while the second (2010:Q1 -- 2022:Q3) also includes periods of the COVID-19 recession. According to our results, longer input sequences result in more accurate nowcasts in periods of balanced economic growth. However, this effect ceases above a relatively low threshold value of around six quarters (eighteen months). During periods of economic turbulence (e.g., during the COVID-19 recession), long
    
[^21]: LossMix：简化和广泛应用 Mixup 于目标检测和更多领域

    LossMix: Simplify and Generalize Mixup for Object Detection and Beyond. (arXiv:2303.10343v1 [cs.CV])

    [http://arxiv.org/abs/2303.10343](http://arxiv.org/abs/2303.10343)

    本论文提出了一种称为 Supervision Interpolation 的新概念框架，通过放松和推广 Mixup 提供了一种全新的插值增强视角，并在此基础上提出了一种名为 LossMix 的简单而多功能的正则化方法，能够增强物体检测器的性能和鲁棒性，或者说LossMix 在目标检测和其他领域中表现出色。

    

    数据混合增强广泛应用于图像分类任务中，但由于空间错位、前景/背景区分以及多个实例的挑战，这些技术不易应用于目标检测。本文提出一种称为监督插值的新概念框架，通过放松和推广 Mixup 提供了一种全新的插值增强视角，然后在这个框架的基础上，提出了 LossMix，这是一种简单而多功能的正则化方法，能够增强物体检测器的性能和鲁棒性。我们的关键insight是，通过插值损失误差来调整训练可以有效规范混合数据的训练，而不是使用ground truth标签。在PASCAL VOC和MS COCO数据集上的实证结果表明，LossMix始终优于当前流行的混合策略，并且我们设计了一种两阶段领域m...

    The success of data mixing augmentations in image classification tasks has been well-received. However, these techniques cannot be readily applied to object detection due to challenges such as spatial misalignment, foreground/background distinction, and plurality of instances. To tackle these issues, we first introduce a novel conceptual framework called Supervision Interpolation, which offers a fresh perspective on interpolation-based augmentations by relaxing and generalizing Mixup. Building on this framework, we propose LossMix, a simple yet versatile and effective regularization that enhances the performance and robustness of object detectors and more. Our key insight is that we can effectively regularize the training on mixed data by interpolating their loss errors instead of ground truth labels. Empirical results on the PASCAL VOC and MS COCO datasets demonstrate that LossMix consistently outperforms currently popular mixing strategies. Furthermore, we design a two-stage domain m
    
[^22]: GPT-4技术报告

    GPT-4 Technical Report. (arXiv:2303.08774v1 [cs.CL])

    [http://arxiv.org/abs/2303.08774](http://arxiv.org/abs/2303.08774)

    GPT-4是一个大规模多模态模型，可以接收图像和文本输入并产生文本输出，能够在各种专业和学术基准测试中表现出人类水平的表现，包括通过模拟的律师考试。该项目的核心组件是开发基础设施和优化方法，可在广泛的规模范围内表现预测性。

    

    我们报告了GPT-4的开发，它是一个可以接受图像和文本输入并产生文本输出的大规模多模态模型。虽然在许多现实场景中不如人类，但GPT-4在各种专业和学术基准测试中表现出人类水平的表现，包括通过模拟的律师考试，成绩排名在前10％左右。GPT-4是一个基于Transformer的模型，预训练用于预测文档中的下一个标记。后训练对齐过程提高了事实性和符合期望行为的性能指标。项目的核心组件是开发基础设施和优化方法，可在广泛的规模范围内表现预测性。这使我们能够准确预测GPT-4的某些性能方面，而这些性能是基于使用不超过GPT-4计算能力的1/1,000的模型训练的。

    We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.
    
[^23]: 基于伪对比学习的基于图的半监督学习

    Pseudo Contrastive Learning for Graph-based Semi-supervised Learning. (arXiv:2302.09532v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.09532](http://arxiv.org/abs/2302.09532)

    本论文提出了一种基于伪对比学习的半监督图神经网络方法，通过生成可靠的负样本对来改进伪标签的质量。

    

    伪标签是一种用于改进半监督图神经网络(GNNs)性能的技术，通过根据自信的预测生成附加的伪标签。然而，由于分类目标对给定标签的敏感性，生成的伪标签质量一直是一个长期存在的问题。为了避免不可靠的分类监督“一个节点属于特定类”，我们更喜欢容错性对比监督“两个节点不属于同一类”。因此，生成高质量伪标签问题转化为一个放松的版本，即识别可靠的负样本对。为了实现这一点，我们提出了一种通用的GNNs框架，称之为伪对比学习(PCL)。它将目标为相同类的正伪标签和负伪标签的两个节点分开。为了将拓扑知识纳入学习中，我们设计了一种拓扑加权对比学习方法

    Pseudo Labeling is a technique used to improve the performance of semi-supervised Graph Neural Networks (GNNs) by generating additional pseudo-labels based on confident predictions. However, the quality of generated pseudo-labels has been a longstanding concern due to the sensitivity of the classification objective with respect to the given labels. To avoid the untrustworthy classification supervision indicating ``a node belongs to a specific class,'' we favor the fault-tolerant contrasting supervision demonstrating ``two nodes do not belong to the same class.'' Thus, the problem of generating high-quality pseudo-labels is then transformed into a relaxed version, i.e., identifying reliable negative pairs. To achieve this, we propose a general framework for GNNs, termed Pseudo Contrastive Learning (PCL). It separates two nodes whose positive and negative pseudo-labels target the same class. To incorporate topological knowledge into learning, we devise a topologically weighted contrastiv
    
[^24]: 一种贝叶斯大脑的组合性解释的数学基础

    Mathematical Foundations for a Compositional Account of the Bayesian Brain. (arXiv:2212.12538v2 [q-bio.NC] UPDATED)

    [http://arxiv.org/abs/2212.12538](http://arxiv.org/abs/2212.12538)

    本文通过应用范畴论的方法为近似推断提供了函子语义，同时还提出了贝叶斯透镜的概念和统计博弈的纤维，对统计推断问题进行了分类。

    

    本篇论文报告了关于主动推断和贝叶斯大脑组合性解释的一些初步研究。具体而言，我们使用当代应用范畴论的工具为近似推断提供了函子语义。为此，我们在“语法”方面定义了新的贝叶斯透镜的概念，并展示了贝叶斯更新遵循组合透镜模式。利用贝叶斯透镜，并受组合博弈论的启发，我们定义了统计博弈的纤维和将各种统计推断问题分类为对应的部分：相对熵的链式规则被形式化为严格部分，而最大似然估计和自由能则给出了松弛部分。在这个过程中，我们引入了一种新的“复制-组合”的概念。在“语义”方面，我们将一般的开放动力系统（尤其是确定性、随机性和随机性，以及离散和连续时间）作为证明。

    This dissertation reports some first steps towards a compositional account of active inference and the Bayesian brain. Specifically, we use the tools of contemporary applied category theory to supply functorial semantics for approximate inference. To do so, we define on the `syntactic' side the new notion of Bayesian lens and show that Bayesian updating composes according to the compositional lens pattern. Using Bayesian lenses, and inspired by compositional game theory, we define fibrations of statistical games and classify various problems of statistical inference as corresponding sections: the chain rule of the relative entropy is formalized as a strict section, while maximum likelihood estimation and the free energy give lax sections. In the process, we introduce a new notion of `copy-composition'.  On the `semantic' side, we present a new formalization of general open dynamical systems (particularly: deterministic, stochastic, and random; and discrete- and continuous-time) as cert
    
[^25]: 风险敏感的强化学习算法：指数标准的应用

    Risk-Sensitive Reinforcement Learning with Exponential Criteria. (arXiv:2212.09010v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2212.09010](http://arxiv.org/abs/2212.09010)

    本文介绍了一种风险敏感的强化学习算法，使用指数判据来提高其系统抗干扰性和实用性。作者进行了在模拟和实际机器人上的实验验证，表明该算法能够有效地提高样本效率和执行效果。

    

    尽管风险中性的强化学习已经在很多应用中得到了实验成功，但是这种方法容易受到噪声和系统参数扰动的影响而不够稳健。因此,对风险敏感的强化学习算法进行了研究，以提高其系统抗干扰性，样本效率和实用性。本文介绍了一种新型的无模型风险敏感学习算法，将广泛使用的策略梯度算法进行变体，其实现过程类似。具体来说，本文研究了指数标准对强化学习代理的策略风险敏感性的影响，并开发了蒙特卡罗策略梯度算法和在线(时间差分)演员-评论家算法的变体。分析结果表明，指数标准的使用能够推广常用的特定正则化方法。作者在摆动杆和摆摆杆任务上进行了测试，验证了所提出的算法的实现性能和稳健性。

    While risk-neutral reinforcement learning has shown experimental success in a number of applications, it is well-known to be non-robust with respect to noise and perturbations in the parameters of the system. For this reason, risk-sensitive reinforcement learning algorithms have been studied to introduce robustness and sample efficiency, and lead to better real-life performance. In this work, we introduce new model-free risk-sensitive reinforcement learning algorithms as variations of widely-used Policy Gradient algorithms with similar implementation properties. In particular, we study the effect of exponential criteria on the risk-sensitivity of the policy of a reinforcement learning agent, and develop variants of the Monte Carlo Policy Gradient algorithm and the online (temporal-difference) Actor-Critic algorithm. Analytical results showcase that the use of exponential criteria generalize commonly used ad-hoc regularization approaches. The implementation, performance, and robustness 
    
[^26]: 通过半监督学习和生成对抗网络在不平衡数据集中进行虚假检测

    Fake detection in imbalance dataset by Semi-supervised learning with GAN. (arXiv:2212.01071v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.01071](http://arxiv.org/abs/2212.01071)

    本文提出了一种在不平衡数据集中使用半监督学习和生成对抗网络进行虚假检测的方法，实验证明仅使用100个标记样本的情况下，准确率达到了91\%。

    

    随着社交媒体的快速发展，骚扰行为变得更加普遍，这导致了虚假检测成为研究人员中引人注目的领域。数据的图形特性以及大量节点导致了许多障碍，包括矩阵中大量无关特征的高离散度和不平衡类别。为了解决这些问题，本文采用了自编码器和半监督学习与生成对抗网络算法的组合，即SGAN。本文将少量标签应用于SGAN作为分类器。实验结果表明，仅使用100个标记样本，该方法在检测虚假账户方面的准确率达到了91\%。

    As social media grows faster, harassment becomes more prevalent which leads to considered fake detection a fascinating field among researchers. The graph nature of data with the large number of nodes caused different obstacles including a considerable amount of unrelated features in matrices as high dispersion and imbalance classes in the dataset. To deal with these issues Auto-encoders and a combination of semi-supervised learning and the GAN algorithm which is called SGAN were used. This paper is deploying a smaller number of labels and applying SGAN as a classifier. The result of this test showed that the accuracy had reached 91\% in detecting fake accounts using only 100 labeled samples.
    
[^27]: 朝着以人为中心的可解释型人工智能：对模型解释的用户研究综述

    Towards Human-centered Explainable AI: A Survey of User Studies for Model Explanations. (arXiv:2210.11584v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2210.11584](http://arxiv.org/abs/2210.11584)

    对模型解释的用户研究综述发现，可解释型人工智能（XAI）正在某些应用领域快速扩散，但用户评估仍然稀缺且几乎不涉及认知或社会科学的见解。

    

    可解释型人工智能（XAI）被广泛认为是不断扩展的人工智能研究的必需条件。对XAI用户需求的更好理解以及可解释模型的人本评估既是必要性也是挑战。在本文中，我们通过系统性文献综述研究了HCI和AI研究人员如何进行XAI应用的用户研究。通过对过去五年中基于人类的XAI评估的97篇核心论文进行识别和深入分析，我们将其按照解释方法的测量特征（信任、理解、可用性和人工智能与人类的合作表现）进行分类。我们的研究表明，XAI在某些应用领域（如推荐系统）扩散更迅速，但用户评估仍相当稀缺，并且几乎没有融入认知或社会科学的任何见解。基于综合讨论的最佳实践，即常见模型、设计选择和度量方法。

    Explainable AI (XAI) is widely viewed as a sine qua non for ever-expanding AI research. A better understanding of the needs of XAI users, as well as human-centered evaluations of explainable models are both a necessity and a challenge. In this paper, we explore how HCI and AI researchers conduct user studies in XAI applications based on a systematic literature review. After identifying and thoroughly analyzing 97core papers with human-based XAI evaluations over the past five years, we categorize them along the measured characteristics of explanatory methods, namely trust, understanding, usability, and human-AI collaboration performance. Our research shows that XAI is spreading more rapidly in certain application domains, such as recommender systems than in others, but that user evaluations are still rather sparse and incorporate hardly any insights from cognitive or social sciences. Based on a comprehensive discussion of best practices, i.e., common models, design choices, and measures
    
[^28]: 数据有效的 GAN 训练中的自我监督增强技术

    Augmentation-Aware Self-Supervision for Data-Efficient GAN Training. (arXiv:2205.15677v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.15677](http://arxiv.org/abs/2205.15677)

    本文提出一种增强感知的自监督判别器用于对生成数据及其增强参数的预测，从而提高判别器的表现和生成模型的性能，实现了数据有效的 GAN 训练。

    

    有限数据情况下训练生成式对抗网络（GAN）是具有挑战性的，因为判别器容易过拟合。先前提出的可微增强技术改善了GAN训练的数据效率。但是，增强技术隐式地引入了不良不变性因素，因为它忽略了由数据转换引起的标签空间语义变化，这可能限制了判别器的表示学习能力，并最终影响生成模型的表现。为了减轻不变性的负面影响，同时继承数据增强的好处，我们提出了一种新的增强感知的自监督判别器，该判别器可以预测增强数据的参数。特别地，真实数据和生成数据的预测目标在训练过程中需要区别开来。我们还鼓励生成器对抗地生成其增强参数可以被判别器准确预测的数据，从而获得更多信息量和更高效的判别器，提高生成模型的性能。多个数据集上的实验表明，我们的方法在数据有效的 GAN 训练中实现了最先进的性能。

    Training generative adversarial networks (GANs) with limited data is challenging because discriminator is prone to overfitting. Previously proposed differentiable augmentation demonstrates improved data efficiency of training GANs. However, the augmentation implicitly introduces undesired invariance to augmentation for the discriminator since it ignores the change of semantics in the label space caused by data transformation, which may limit the representation learning ability of the discriminator and ultimately affect the generative modeling performance of the generator. To mitigate the negative impact of invariance while inheriting the benefits of data augmentation, we propose a novel augmentation-aware self-supervised discriminator that predicts the augmentation parameter of the augmented data. Particularly, the prediction targets of real data and generated data are required to be distinguished since they are different during training. We further encourage the generator to adversari
    
[^29]: Fictitious Play优于Counterfactual Regret Minimization

    Fictitious Play Outperforms Counterfactual Regret Minimization. (arXiv:2001.11165v7 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2001.11165](http://arxiv.org/abs/2001.11165)

    本研究比较了两种算法在近似多人博弈Nash均衡方面的表现，结果发现Fictitious Play比Counterfactual Regret Minimization更优秀。

    

    本文比较了两种广受欢迎的算法——Fictitious Play和Counterfactual Regret Minimization在近似多人博弈Nash均衡方面的表现。虽然Counterfactual Regret Minimization在多人扑克中取得了较大成功并被认为是更优秀的算法，但我们展示了Fictitious Play在各种类别和规模的游戏中都可以带来更好的Nash均衡近似效果。

    We compare the performance of two popular algorithms, fictitious play and counterfactual regret minimization, in approximating Nash equilibrium in multiplayer games. Despite recent success of counterfactual regret minimization in multiplayer poker and conjectures of its superiority, we show that fictitious play leads to improved Nash equilibrium approximation over a variety of game classes and sizes.
    

