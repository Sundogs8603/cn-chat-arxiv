# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Online Learning for Scheduling MIP Heuristics.](http://arxiv.org/abs/2304.03755) | 本文介绍了一种基于在线学习的启发式方法调度技术，针对单个问题实例采用适应性框架，超越现有文献中的工作，同时控制两个不同类型的启发式方法，经过基准测试表明该方法能有效提高性能。 |
| [^2] | [Perspectives on AI Architectures and Co-design for Earth System Predictability.](http://arxiv.org/abs/2304.03748) | 本研究探讨了人工智能架构和共设计对地球系统可预测性的影响，提供了发展新的架构和策略以促进应用人工智能在地球系统建模和预测领域的发展的观点。 |
| [^3] | [Predicting quantum chemical property with easy-to-obtain geometry via positional denoising.](http://arxiv.org/abs/2304.03724) | 该论文提出了一种方法，利用位置去噪预测易得几何结构的量子化学性质，可以用相对容易获得的几何结构，精确预测性质，在分子性质以及化学反应性质的预测任务中都表现优秀。 |
| [^4] | [Representer Theorems for Metric and Preference Learning: A Geometric Perspective.](http://arxiv.org/abs/2304.03720) | 该论文提出了度量学习和偏好学习的新的表现定理，解决了度量学习任务以三元组比较为基础的表现定理问题。这种表现定理可以用内积诱导的范数来表示。 |
| [^5] | [HumanLight: Incentivizing Ridesharing via Human-centric Deep Reinforcement Learning in Traffic Signal Control.](http://arxiv.org/abs/2304.03697) | 本文介绍了一种名为HumanLight的算法，采用人性化的强化学习方法，在交通信号控制中激励大家拼车，缓解交通拥堵和减少污染。算法通过奖励乘坐大容量载客工具的通勤者，实现对绿灯时间的公平分配。 |
| [^6] | [Feature Mining for Encrypted Malicious Traffic Detection with Deep Learning and Other Machine Learning Algorithms.](http://arxiv.org/abs/2304.03691) | 本文分析了恶意流量检测中的特征提取问题，并提出了一种专门针对加密恶意流量的特征和概念，同时提出了一个有深度学习和传统机器学习算法的检测框架，并在实验中取得了优异的检测表现。 |
| [^7] | [Machine Learning with Requirements: a Manifesto.](http://arxiv.org/abs/2304.03674) | 本文提出一个带需求的机器学习宣言，认为需求定义和满足可以在很大程度上使机器学习模型更适用于现实世界中的关键领域，作者提出了两个问题，其中（i）需求自然而然地出现，（ii）机器学习模型被或可以成功地部署，并且（iii）忽略需求可能会产生严重后果，提出了一种新型的金字塔式开发流程，在其中，需求定义可能会影响到流程中所有后续阶段，反之亦然。 |
| [^8] | [Don't Bet on Luck Alone: Enhancing Behavioral Reproducibility of Quality-Diversity Solutions in Uncertain Domains.](http://arxiv.org/abs/2304.03672) | 本文提出了一种称为ARIA的模块，可在任何QD算法中提高存档中存在的解决方案的可重现性。该方法通过优化解决方案的概率和适应度进行变异，从而应对不可预测的噪音环境。 |
| [^9] | [RSPT: Reconstruct Surroundings and Predict Trajectories for Generalizable Active Object Tracking.](http://arxiv.org/abs/2304.03623) | RSPT框架通过重构环境和预测目标轨迹实现了一般化主动物体跟踪。 |
| [^10] | [Look how they have grown: Non-destructive Leaf Detection and Size Estimation of Tomato Plants for 3D Growth Monitoring.](http://arxiv.org/abs/2304.03610) | 本文提出了一种基于图像的自动化非破坏性测量系统，利用Zivid 3D相机创建番茄植株的3D虚拟表示，通过检测叶片掩模提取叶片大小，实现了对植物生长的精准监测，有望应用于精准农业和温室管理领域。 |
| [^11] | [Pallet Detection from Synthetic Data Using Game Engines.](http://arxiv.org/abs/2304.03602) | 本研究使用游戏引擎生成合成训练数据的方式来检测托盘分割，自主仓储技术的发展对于机器视觉有很大帮助，Mask R-CNN流水线可以达到较高的准确率。 |
| [^12] | [Deep Reinforcement Learning-Based Mapless Crowd Navigation with Perceived Risk of the Moving Crowd for Mobile Robots.](http://arxiv.org/abs/2304.03593) | 本论文提出了一种基于碰撞概率的无图Crowd Navigation方法，使用深度强化学习(DRL)来感知人群的危险程度，确保机器人在通过拥挤环境时的安全，同时提高模型的可扩展性。 |
| [^13] | [On Efficient Training of Large-Scale Deep Learning Models: A Literature Review.](http://arxiv.org/abs/2304.03589) | 研究深度学习模型高效训练方法已有不少成果，但尚缺乏全面总结。本文综述分为数据中心化、模型中心化、超参数优化、深度学习硬件和训练策略等五个方面，比较详尽地回顾了加速深度学习模型训练的基本组件。 |
| [^14] | [HyperTab: Hypernetwork Approach for Deep Learning on Small Tabular Datasets.](http://arxiv.org/abs/2304.03543) | HyperTab是一种基于超网络结合了随机森林和神经网络优点的小型表格数据深度学习方法，使用每个特定低维视图处理数据，虚拟增加训练样本数量，避免过度拟合。 |
| [^15] | [ChatPipe: Orchestrating Data Preparation Program by Optimizing Human-ChatGPT Interactions.](http://arxiv.org/abs/2304.03540) | ChatPipe 提出了一个新系统，旨在通过自然语言交互优化 ChatGPT 编排 ML 数据准备程序，有效推荐下一个数据准备操作，方便用户进行程序的修改和版本切换，能够显著减少 ML 数据准备所需的时间和精力。 |
| [^16] | [SSS at SemEval-2023 Task 10: Explainable Detection of Online Sexism using Majority Voted Fine-Tuned Transformers.](http://arxiv.org/abs/2304.03518) | 本文描述了使用细调BERT模型和多数投票集成模型来检测和解释在线性别歧视的方法。翻转显着降低了女性在社交媒体平台上经历不成比例的性别歧视的风险。 |
| [^17] | [Local Rose Breeds Detection System Using Transfer Learning Techniques.](http://arxiv.org/abs/2304.03509) | 提出了一种使用迁移学习技术的玫瑰品种检测模型，使用1939张图像数据训练，检测六种不同品种的玫瑰，准确度达到97.89％。该模型可以为花卉行业识别和栽培不同品种的玫瑰提供帮助。 |
| [^18] | [Can we learn better with hard samples?.](http://arxiv.org/abs/2304.03486) | 该研究提出一种改进传统mini-batch算法的方案，该方案重点训练具有高损失的mini-batch网络，其在三个基准数据集上的实验结果表明，该方法可以显着提高测试准确性并加快收敛速度。 |
| [^19] | [Rethinking GNN-based Entity Alignment on Heterogeneous Knowledge Graphs: New Datasets and A New Method.](http://arxiv.org/abs/2304.03468) | 文章重新考虑了基于GNN的异构知识图谱实体对齐。为探究EA实际场景中的表现，提出了更接近现实的高度异构知识图谱数据集，并提出了新方法。 |
| [^20] | [AMS-DRL: Learning Multi-Pursuit Evasion for Safe Targeted Navigation of Drones.](http://arxiv.org/abs/2304.03443) | 本文提出了AMS-DRL方法用于训练对抗性神经网络，以学习和快速适应多个攻击者的行为，从而实现无人机的安全导航和到达目标。 |
| [^21] | [Generative Agents: Interactive Simulacra of Human Behavior.](http://arxiv.org/abs/2304.03442) | 本文介绍了一种生成代理的架构，它能够仿真出具有可信度的人类行为，填充交互式沙盒环境，为创造更加真实的人机交互体验提供了一种新的思路。 |
| [^22] | [Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4.](http://arxiv.org/abs/2304.03439) | 本文分析了多个逻辑推理数据集，评估了ChatGPT和GPT-4在逻辑推理任务上的表现，并构造了一个逻辑推理的分布之外的数据集来研究它们的鲁棒性。实验结果显示，ChatGPT在大多数逻辑推理基准测试中的表现远优于RoBERTa微调方法，而GPT-4的表现则更高。 |
| [^23] | [Domain Generalization In Robust Invariant Representation.](http://arxiv.org/abs/2304.03431) | 本文研究了不变表示的泛化性能，证明具有不变表示的模型可以学习到具有鲁棒性的非结构化潜在表示，因此使不变性成为域泛化的一个关键方面。 |
| [^24] | [Cleansing Jewel: A Neural Spelling Correction Model Built On Google OCR-ed Tibetan Manuscripts.](http://arxiv.org/abs/2304.03427) | 本文提出了一种基于谷歌OCR扫描的藏文手稿的神经拼写纠错模型，可以自动纠正OCR输出中的噪声。 |
| [^25] | [Adoption of AI Technology in the Music Mixing Workflow: An Investigation.](http://arxiv.org/abs/2304.03407) | 该研究调查了音乐混音工作流中AI技术的应用情况及不同用户群体的采用情况。结果显示，即使AI混音工具能够为业余爱好者提供不错的结果，职业业余爱好者和专业人员需要更为精确的控制和自定义选项，以及辅助和协作技术。 |
| [^26] | [Localized Region Contrast for Enhancing Self-Supervised Learning in Medical Image Segmentation.](http://arxiv.org/abs/2304.03406) | 本文提出了一种基于局部区域对比的医学图像自监督学习增强框架，以提高多器官分割等密集预测任务的性能，实验结果表明该方法可以超越最先进的自监督学习方法。 |
| [^27] | [CAPOT: Creating Robust Dense Query Encoders using Post Training Contrastive Alignment.](http://arxiv.org/abs/2304.03401) | CAPOT使用后训练对比对齐的方法，提高模型对于噪声查询的健壮性，表现类似于数据增强但没有其开销。 |
| [^28] | [Personalizing Digital Health Behavior Change Interventions using Machine Learning and Domain Knowledge.](http://arxiv.org/abs/2304.03392) | 该论文提出了一种采用机器学习和领域知识进行个性化数字健康行为变革干预的系统，其利用反事实例子进行特征控制以预测干预效果并优化干预效果。 |
| [^29] | [Handling Wikidata Qualifiers in Reasoning.](http://arxiv.org/abs/2304.03375) | 本文提出了处理Wikidata限定词的方法，包括对限定词进行分类和使用多排序逻辑语言形式化Wikidata模型，以应用于推理。 |
| [^30] | [Robust Decision-Focused Learning for Reward Transfer.](http://arxiv.org/abs/2304.03365) | 本文介绍了一种稳健决策重点（RDF）算法，利用非识别性的DF解，学习同时最大化期望回报和抵御奖励函数变化的模型，可以显著提高DF对奖励函数变化的稳健性，而不会降低智能体的总回报。 |
| [^31] | [Graph Collaborative Signals Denoising and Augmentation for Recommendation.](http://arxiv.org/abs/2304.03344) | 本文提出了一种新的图邻接矩阵，它包括了用户-用户和项目-项目的相关性，以及一个经过适当设计的用户-项目交互矩阵，并通过预训练和top-K采样增强了用户-项目交互矩阵，以更好地适应所有用户的需求。 |
| [^32] | [Maximal Ordinal Two-Factorizations.](http://arxiv.org/abs/2304.03338) | 本文研究了最大序数二次因子分解问题，证明了其判定是否存在是一个NP完全问题，并提供了用于计算最大因子分解的算法Ord2Factor。 |
| [^33] | [Explainable AI And Visual Reasoning: Insights From Radiology.](http://arxiv.org/abs/2304.03318) | 本研究探讨了当前可解释人工智能在放射学应用中的难点，提出了一种基于人类推理和证明的解释设计方法，并通过放射学案例，证明了这种方法可行。 |
| [^34] | [Comparing NARS and Reinforcement Learning: An Analysis of ONA and $Q$-Learning Algorithms.](http://arxiv.org/abs/2304.03291) | 本文比较了NARS和强化学习在解决序列任务方面的性能，发现NARS在各种环境中都有较好的表现，尤其是在非确定性环境中。 |
| [^35] | [Adaptive Feature Fusion: Enhancing Generalization in Deep Learning Models.](http://arxiv.org/abs/2304.03290) | 本研究提出了一种自适应特征融合（AFF）的方法，能够通过动态调整深度学习模型中特征融合过程来增强其泛化能力。该方法结合了数据驱动和基于模型的融合策略，能够根据数据特征和模型要求自适应融合特征。 |
| [^36] | [Synthesis of Mathematical programs from Natural Language Specifications.](http://arxiv.org/abs/2304.03287) | 本论文关注于通过自然语言规范中的目标和约束合成数学程序，并通过评估CodeT5和使用GPT-3来生成需要的示例进行实验。 |
| [^37] | [On the Pareto Front of Multilingual Neural Machine Translation.](http://arxiv.org/abs/2304.03216) | 本研究针对多语言神经机器翻译的数据不平衡问题，提出双重幂律方法用于预测独特的性能权衡前沿，并建立基于该方法的样本比例选择优化问题，取得更好的结果。 |
| [^38] | [ACTION++: Improving Semi-supervised Medical Image Segmentation with Adaptive Anatomical Contrast.](http://arxiv.org/abs/2304.02689) | 本文提出了一种改进的对比学习框架ACTION++，通过自适应的解剖对比来改善半监督医学图像分割。 |
| [^39] | [What Affects Learned Equivariance in Deep Image Recognition Models?.](http://arxiv.org/abs/2304.02628) | 本文研究了神经网络中学习到的等变性，提出了一种改进的等变性测量方法，并发现数据增强、减少模型容量和卷积操作可提高神经网络中学习到的等变性。 |
| [^40] | [GPTEval: NLG Evaluation using GPT-4 with Better Human Alignment.](http://arxiv.org/abs/2303.16634) | 本文介绍了GPTEval，一个利用链式思考和形式填充评价NLG生成的质量。实验表明，在文本摘要任务中，GPTEval结合GPT-4取得了0.514的斯皮尔曼相关系数，胜过其他方法。 |
| [^41] | [Viewpoint Equivariance for Multi-View 3D Object Detection.](http://arxiv.org/abs/2303.14548) | 本文提出了一种利用多视角几何学习视点等变性以提高三维物体检测定位精度的框架VEDet，并通过基于查询的transformer架构和视角条件的查询来实现。 |
| [^42] | [Online Learning for the Random Feature Model in the Student-Teacher Framework.](http://arxiv.org/abs/2303.14083) | 本研究考虑了一种两层神经网络模型的在线学习，研究发现，当学生的隐藏层大小呈指数增长时，完美泛化是可行的，但对于任何有限的隐藏层大小和输入维度比，学生都无法完美泛化。 |
| [^43] | [Revisiting the Fragility of Influence Functions.](http://arxiv.org/abs/2303.12922) | 本文研究了影响函数的脆弱性，并提出在非凸条件下使用深层模型和更复杂数据集来解决这一问题。 |
| [^44] | [Text Semantics to Image Generation: A method of building facades design base on Stable Diffusion model.](http://arxiv.org/abs/2303.12755) | 本文提出了一种多网络结合的文本到建筑立面图像生成方法，通过 LoRA 训练方法微调稳定扩散模型和 ControlNet 模型的添加，大大提高了文本到建筑立面图像生成的可控性和稳定性，为后续建筑图像生成研究提供了基础。 |
| [^45] | [Multi-agent Reinforcement Learning for Regional Signal control in Large-scale Grid Traffic network.](http://arxiv.org/abs/2303.11899) | 本文提出了一种新的训练框架 RegionLight，基于交叉口之间的邻接关系将智能体分配到每个区域中。同时，研究人员扩展了BDQ方法为DBDQ，以限制联合动作空间大小的增长并缓解智能体训练问题。 |
| [^46] | [Revisiting LQR Control from the Perspective of Receding-Horizon Policy Gradient.](http://arxiv.org/abs/2302.13144) | 本文从递推视角重新审视了LQR控制问题，并应用递推-视角策略梯度（RHPG）模型提供了一种采样复杂度分析，通过无需任何先验信息进行优化求解，并展示了RHPG在线性控制和估计中的普适性。 |
| [^47] | [Friend Ranking in Online Games via Pre-training Edge Transformers.](http://arxiv.org/abs/2302.10043) | 本文提出了一种使用边缘Transformer和预训练的链接预测方法，用于在在线游戏中进行好友排名，达到了最先进的结果。 |
| [^48] | [SAT Requires Exhaustive Search.](http://arxiv.org/abs/2302.09512) | 本文证明了对于一些具有大域和长子句的极难例子，要求进行彻底搜索才能解决，这意味着P $\neq$ NP。 |
| [^49] | [Complex QA and language models hybrid architectures, Survey.](http://arxiv.org/abs/2302.09051) | 本文综述了语言模型架构和策略的最新进展，并重点关注混合技术在复杂问题回答中的应用，讨论了该领域的挑战和未来研究方向。 |
| [^50] | [Evaluating Temporal Observation-Based Causal Discovery Techniques Applied to Road Driver Behaviour.](http://arxiv.org/abs/2302.00064) | 本文对10种当代观测性时间因果发现技术在自主驾驶领域进行了基准测试，突出了需要改进的地方，以促进这些方法的应用。 |
| [^51] | [Modality-Agnostic Variational Compression of Implicit Neural Representations.](http://arxiv.org/abs/2301.09479) | 提出了一种无模态偏见的隐式神经表示变分压缩算法，能够在不同的数据模态上表现出卓越的压缩性能和效果。 |
| [^52] | [Neural Shape Compiler: A Unified Framework for Transforming between Text, Point Cloud, and Program.](http://arxiv.org/abs/2212.12952) | 本篇论文提出了一个称为神经形状编译器的框架，用于将三维形状的不同抽象类型之间进行转换。该框架通过提出的形状代码转换器将三维形状转换为统一的离散形状代码，并在各种数据集上展示出了较强的转换能力。 |
| [^53] | [Multimodal and Explainable Internet Meme Classification.](http://arxiv.org/abs/2212.05612) | 本文提出了一种多模态和可解释的互联网迷因分类方法，旨在解决现有方法中忽略迷因语义和创建上下文导致公正内容管理困难的问题。作者采用示例和基于原型的推理并结合文本和视觉SOTA模型进行训练，成功在两个任务中检测了有害的迷因。 |
| [^54] | [SPIDR: SDF-based Neural Point Fields for Illumination and Deformation.](http://arxiv.org/abs/2210.08398) | 本文提出SPIDR，一种新的混合神经点场网络，并结合点云和神经隐式表示，可以实现更高质量的对象表面重建和光照估计。 |
| [^55] | [SC-Ques: A Sentence Completion Question Dataset for English as a Second Language Learners.](http://arxiv.org/abs/2206.12036) | 该论文介绍了一个针对英语学习者设计的大规模句子填空问题数据集\textsc{SC-Ques}，并且已经构建了一个综合基准来自动解决 SC 问题。 |
| [^56] | [PIDNet: A Real-time Semantic Segmentation Network Inspired by PID Controllers.](http://arxiv.org/abs/2206.02066) | 本文提出了一种新的三分支语义分割神经网络 PIDNet，采用边界注意力引导详细和上下文分支的融合，能够解决现有两分支模型中因详细特征被周围背景信息淹没导致的分割准确性问题，并在多个数据集上实现了最佳性能。 |
| [^57] | [Dynamic Multimodal Fusion.](http://arxiv.org/abs/2204.00102) | 本论文提出了一种动态多模态融合的新方法，可以自适应地融合多模态数据并根据计算需求生成数据相关的前向路径，在提高计算效率的同时兼顾准确度和性能。 |

# 详细

[^1]: 基于在线学习的混合整数规划启发式调度方法

    Online Learning for Scheduling MIP Heuristics. (arXiv:2304.03755v1 [math.OC])

    [http://arxiv.org/abs/2304.03755](http://arxiv.org/abs/2304.03755)

    本文介绍了一种基于在线学习的启发式方法调度技术，针对单个问题实例采用适应性框架，超越现有文献中的工作，同时控制两个不同类型的启发式方法，经过基准测试表明该方法能有效提高性能。

    

    混合整数规划(MIP)是NP难问题，但现代求解器通常可以在几分钟内解决大型实际问题。这种成功部分归功于启发式方法。由于它们的行为高度依赖于实例，因此依赖于从大型异构基准实例的经验测试推导出的硬编码规则可能会导致次优性能。在这项工作中，我们提出了一种基于在线学习的方法，使启发式方法能够适应当前问题实例。我们用一个适应性框架取代了通常使用的静态启发式处理方法，该框架利用关于启发式方法行为的过去观察结果来做出未来决策。特别地，我们将控制大邻域搜索和潜水 - 两个广泛且复杂的启发式方法的问题建模为多臂赌博机问题。超越了现有文献中的工作，我们通过单个学习代理同时控制了两个不同类别的启发式方法。我们在MIPLIB 2017基准集上验证了我们的方法，并表明我们的方法优于最先进的启发式处理技术。

    Mixed Integer Programming (MIP) is NP-hard, and yet modern solvers often solve large real-world problems within minutes. This success can partially be attributed to heuristics. Since their behavior is highly instance-dependent, relying on hard-coded rules derived from empirical testing on a large heterogeneous corpora of benchmark instances might lead to sub-optimal performance. In this work, we propose an online learning approach that adapts the application of heuristics towards the single instance at hand. We replace the commonly used static heuristic handling with an adaptive framework exploiting past observations about the heuristic's behavior to make future decisions. In particular, we model the problem of controlling Large Neighborhood Search and Diving - two broad and complex classes of heuristics as a multi-armed bandit problem. Going beyond existing work in the literature, we control two different classes of heuristics simultaneously by a single learning agent. We verify our
    
[^2]: 人工智能架构和共设计对地球系统可预测性的影响

    Perspectives on AI Architectures and Co-design for Earth System Predictability. (arXiv:2304.03748v1 [cs.LG])

    [http://arxiv.org/abs/2304.03748](http://arxiv.org/abs/2304.03748)

    本研究探讨了人工智能架构和共设计对地球系统可预测性的影响，提供了发展新的架构和策略以促进应用人工智能在地球系统建模和预测领域的发展的观点。

    

    美国能源部（DOE）科学办公室生物和环境研究（BER）和高级科学计算研究（ASCR）计划最近组织并举办了“面向地球系统可预测性的人工智能（AI4ESP）”研讨会系列。从这个研讨会中，DOE BER和ASCR社区得出的一个关键结论是需要发展一个新的地球系统可预测性范式，重点是在整个领域、实验室、建模和分析活动中实现人工智能（AI），称为ModEx。BER的“模型实验”，ModEx，是一种迭代方法，使过程模型能够生成假设。所开发的假设通知采集测量和观测数据的现场和实验室工作，随后用于参数化、驱动和测试模型（例如基于过程的）预测。在这个AI4ESP工作坊系列中共举行了17个技术会议。本文讨论了其中一次会议的主题“人工智能架构和共设计对地球系统可预测性的影响”。它提供了发展新的人工智能架构和共设计策略来解决地球系统建模和预测领域特定的科学和技术需求，以推进人工智能在地球系统可预测性中的作用的观点。

    Recently, the U.S. Department of Energy (DOE), Office of Science, Biological and Environmental Research (BER), and Advanced Scientific Computing Research (ASCR) programs organized and held the Artificial Intelligence for Earth System Predictability (AI4ESP) workshop series. From this workshop, a critical conclusion that the DOE BER and ASCR community came to is the requirement to develop a new paradigm for Earth system predictability focused on enabling artificial intelligence (AI) across the field, lab, modeling, and analysis activities, called ModEx. The BER's `Model-Experimentation', ModEx, is an iterative approach that enables process models to generate hypotheses. The developed hypotheses inform field and laboratory efforts to collect measurement and observation data, which are subsequently used to parameterize, drive, and test model (e.g., process-based) predictions. A total of 17 technical sessions were held in this AI4ESP workshop series. This paper discusses the topic of the `
    
[^3]: 利用位置去噪预测易得几何结构的量子化学性质

    Predicting quantum chemical property with easy-to-obtain geometry via positional denoising. (arXiv:2304.03724v1 [physics.chem-ph])

    [http://arxiv.org/abs/2304.03724](http://arxiv.org/abs/2304.03724)

    该论文提出了一种方法，利用位置去噪预测易得几何结构的量子化学性质，可以用相对容易获得的几何结构，精确预测性质，在分子性质以及化学反应性质的预测任务中都表现优秀。

    

    由于量子化学性质与其几何结构有重要关联，使用3D几何信息的图神经网络在许多任务中取得了较高的预测精度。然而，它们通常需要高级量子力学计算得出的3D几何结构，这在实际问题中是不可行的，限制了其在现实问题中的适用性。为了解决这个问题，我们提出了一种方法，利用相对容易获得的几何结构（例如来自分子力场的优化几何结构）精确预测性质。在这种方法中，输入几何结构逐渐接近正确几何结构，通过堆叠去噪层。我们使用3D消息传递体系结构研究了该方法在两个预测任务（分子性质和化学反应性质）中的性能。通过去噪过程减少位置误差有助于性能的提高。

    As quantum chemical properties have a significant dependence on their geometries, graph neural networks (GNNs) using 3D geometric information have achieved high prediction accuracy in many tasks. However, they often require 3D geometries obtained from high-level quantum mechanical calculations, which are practically infeasible, limiting their applicability in real-world problems. To tackle this, we propose a method to accurately predict the properties with relatively easy-to-obtain geometries (e.g., optimized geometries from the molecular force field). In this method, the input geometry, regarded as the corrupted geometry of the correct one, gradually approaches the correct one as it passes through the stacked denoising layers. We investigated the performance of the proposed method using 3D message-passing architectures for two prediction tasks: molecular properties and chemical reaction property. The reduction of positional errors through the denoising process contributed to performan
    
[^4]: 度量学习与偏好学习的表现定理：基于几何的视角

    Representer Theorems for Metric and Preference Learning: A Geometric Perspective. (arXiv:2304.03720v1 [cs.LG])

    [http://arxiv.org/abs/2304.03720](http://arxiv.org/abs/2304.03720)

    该论文提出了度量学习和偏好学习的新的表现定理，解决了度量学习任务以三元组比较为基础的表现定理问题。这种表现定理可以用内积诱导的范数来表示。

    

    我们探讨了希尔伯特空间中的度量学习和偏好学习问题，并获得了一种新的度量学习和偏好学习的表现定理。我们的关键观察是，表现定理可以根据问题结构内在的内积所诱导的范数来表示。此外，我们展示了如何将我们的框架应用于三元组比较的度量学习任务，并展示它导致了一个简单且自包含的该任务的表现定理。在再生核希尔伯特空间(RKHS)的情况下，我们展示了学习问题的解可以使用类似于经典表现定理的核术语表示。

    We explore the metric and preference learning problem in Hilbert spaces. We obtain a novel representer theorem for the simultaneous task of metric and preference learning. Our key observation is that the representer theorem can be formulated with respect to the norm induced by the inner product inherent in the problem structure. Additionally, we demonstrate how our framework can be applied to the task of metric learning from triplet comparisons and show that it leads to a simple and self-contained representer theorem for this task. In the case of Reproducing Kernel Hilbert Spaces (RKHS), we demonstrate that the solution to the learning problem can be expressed using kernel terms, akin to classical representer theorems.
    
[^5]: 人性化深度强化学习在交通信号控制中的应用：通过激励拼车来缓解交通拥堵和减少污染

    HumanLight: Incentivizing Ridesharing via Human-centric Deep Reinforcement Learning in Traffic Signal Control. (arXiv:2304.03697v1 [cs.LG])

    [http://arxiv.org/abs/2304.03697](http://arxiv.org/abs/2304.03697)

    本文介绍了一种名为HumanLight的算法，采用人性化的强化学习方法，在交通信号控制中激励大家拼车，缓解交通拥堵和减少污染。算法通过奖励乘坐大容量载客工具的通勤者，实现对绿灯时间的公平分配。

    

    单人驾车已成为许多通勤者最受青睐的交通方式，导致交通拥堵和空气污染问题加剧。信息技术的进步为实现城市“轻车化”提供了机遇，可以通过智能解决方案激励拼车和切换到大容量载客工具。本研究提出HumanLight，一种新型的分散式自适应交通信号控制算法，旨在优化交叉口的人员通行量。所提出的控制器基于强化学习，奖励函数嵌入了以人为本的交通概念。通过激励大容量载客工具的通勤者合并乘车以节约时间，HumanLight实现了对绿灯时间的公平分配。除了采用FRAP作为先进的基础模型外，HumanLight还引入了“活跃车辆”这个概念，大致定义是临近交叉口且可能干扰决策过程的任何车辆。

    Single occupancy vehicles are the most attractive transportation alternative for many commuters, leading to increased traffic congestion and air pollution. Advancements in information technologies create opportunities for smart solutions that incentivize ridesharing and mode shift to higher occupancy vehicles (HOVs) to achieve the car lighter vision of cities. In this study, we present HumanLight, a novel decentralized adaptive traffic signal control algorithm designed to optimize people throughput at intersections. Our proposed controller is founded on reinforcement learning with the reward function embedding the transportation-inspired concept of pressure at the person-level. By rewarding HOV commuters with travel time savings for their efforts to merge into a single ride, HumanLight achieves equitable allocation of green times. Apart from adopting FRAP, a state-of-the-art (SOTA) base model, HumanLight introduces the concept of active vehicles, loosely defined as vehicles in proximit
    
[^6]: 基于深度学习和其他机器学习算法的加密恶意流量检测中的特征挖掘

    Feature Mining for Encrypted Malicious Traffic Detection with Deep Learning and Other Machine Learning Algorithms. (arXiv:2304.03691v1 [cs.CR])

    [http://arxiv.org/abs/2304.03691](http://arxiv.org/abs/2304.03691)

    本文分析了恶意流量检测中的特征提取问题，并提出了一种专门针对加密恶意流量的特征和概念，同时提出了一个有深度学习和传统机器学习算法的检测框架，并在实验中取得了优异的检测表现。

    

    加密机制的普及对恶意流量检测提出了极大的挑战，传统检测技术在没有对加密流量解密的情况下无法工作。当前，对于不解密的加密恶意流量检测的研究集中在特征提取和机器学习或深度学习算法的选择上。本文首先提供流量特征的深入分析和比较不同的流量特征创建方法，同时提出了一种专门针对加密恶意流量分析设计的新概念和特征。此外，我们提出了一种用于加密恶意流量检测的框架，该框架是一个两层的检测框架，包括深度学习和传统机器学习算法。通过比较实验，该框架在检测准确度和假阳性率方面优于经典的深度学习和传统机器学习算法，如ResNet和随机森林。

    The popularity of encryption mechanisms poses a great challenge to malicious traffic detection. The reason is traditional detection techniques cannot work without the decryption of encrypted traffic. Currently, research on encrypted malicious traffic detection without decryption has focused on feature extraction and the choice of machine learning or deep learning algorithms. In this paper, we first provide an in-depth analysis of traffic features and compare different state-of-the-art traffic feature creation approaches, while proposing a novel concept for encrypted traffic feature which is specifically designed for encrypted malicious traffic analysis. In addition, we propose a framework for encrypted malicious traffic detection. The framework is a two-layer detection framework which consists of both deep learning and traditional machine learning algorithms. Through comparative experiments, it outperforms classical deep learning and traditional machine learning algorithms, such as Res
    
[^7]: 带需求的机器学习：一份宣言

    Machine Learning with Requirements: a Manifesto. (arXiv:2304.03674v1 [cs.LG])

    [http://arxiv.org/abs/2304.03674](http://arxiv.org/abs/2304.03674)

    本文提出一个带需求的机器学习宣言，认为需求定义和满足可以在很大程度上使机器学习模型更适用于现实世界中的关键领域，作者提出了两个问题，其中（i）需求自然而然地出现，（ii）机器学习模型被或可以成功地部署，并且（iii）忽略需求可能会产生严重后果，提出了一种新型的金字塔式开发流程，在其中，需求定义可能会影响到流程中所有后续阶段，反之亦然。

    

    在近年来，机器学习取得了长足的进步，成为许多不同应用领域突破的根源。然而，如何将它们应用到高风险或安全关键的应用领域仍然是一个未解决的问题，因为它们往往容易变得脆弱和不可靠。本文认为，需求定义和满足可以在很大程度上使机器学习模型更适用于现实世界中的关键领域。为此，我们提出了两个问题，其中（i）需求自然而然地出现，（ii）机器学习模型被或可以成功地部署，并且（iii）忽略需求可能会产生严重后果。我们展示了如何将需求规格说明有益地整合到标准的机器学习开发流程中，提出了一种新型的金字塔式开发流程，在其中，需求定义可能会影响到流程中所有后续阶段，反之亦然。

    In the recent years, machine learning has made great advancements that have been at the root of many breakthroughs in different application domains. However, it is still an open issue how make them applicable to high-stakes or safety-critical application domains, as they can often be brittle and unreliable. In this paper, we argue that requirements definition and satisfaction can go a long way to make machine learning models even more fitting to the real world, especially in critical domains. To this end, we present two problems in which (i) requirements arise naturally, (ii) machine learning models are or can be fruitfully deployed, and (iii) neglecting the requirements can have dramatic consequences. We show how the requirements specification can be fruitfully integrated into the standard machine learning development pipeline, proposing a novel pyramid development process in which requirements definition may impact all the subsequent phases in the pipeline, and viceversa.
    
[^8]: 不仅仅靠运气：提高质量多样性解决方案在不可预测领域中的行为重复性

    Don't Bet on Luck Alone: Enhancing Behavioral Reproducibility of Quality-Diversity Solutions in Uncertain Domains. (arXiv:2304.03672v1 [cs.NE])

    [http://arxiv.org/abs/2304.03672](http://arxiv.org/abs/2304.03672)

    本文提出了一种称为ARIA的模块，可在任何QD算法中提高存档中存在的解决方案的可重现性。该方法通过优化解决方案的概率和适应度进行变异，从而应对不可预测的噪音环境。

    

    质量多样性(QD)算法旨在在给定描述符空间中生成优秀解决方案的集合并最大化它们的多样性。然而，在存在不可预测的噪音的情况下，同一解决方案在不同评估中的适应度和描述符可能会有显著差异，导致估计这些值存在不确定性。鉴于QD算法的精英主义本质，在这些嘈杂的环境下，它们通常会得到许多退化的解决方案。在本文中，我们介绍了“档案可重现性改进算法”(ARIA)；一种即插即用的方法，它可以提高存档中存在的解决方案的可重现性。我们将其提议为一种单独的优化模块，依赖于自然进化策略，可以在任何QD算法的顶部执行。我们的模块对解决方案进行变异，以(1)优化其属于自己的领域的概率，和(2)最大化它们的适应度。我们的方法的性能在各种任务上进行了评估，包括...

    Quality-Diversity (QD) algorithms are designed to generate collections of high-performing solutions while maximizing their diversity in a given descriptor space. However, in the presence of unpredictable noise, the fitness and descriptor of the same solution can differ significantly from one evaluation to another, leading to uncertainty in the estimation of such values. Given the elitist nature of QD algorithms, they commonly end up with many degenerate solutions in such noisy settings. In this work, we introduce Archive Reproducibility Improvement Algorithm (ARIA); a plug-and-play approach that improves the reproducibility of the solutions present in an archive. We propose it as a separate optimization module, relying on natural evolution strategies, that can be executed on top of any QD algorithm. Our module mutates solutions to (1) optimize their probability of belonging to their niche, and (2) maximize their fitness. The performance of our method is evaluated on various tasks, incl
    
[^9]: RSPT: 用于一般化主动物体跟踪的重构环境和预测轨迹方法

    RSPT: Reconstruct Surroundings and Predict Trajectories for Generalizable Active Object Tracking. (arXiv:2304.03623v1 [cs.RO])

    [http://arxiv.org/abs/2304.03623](http://arxiv.org/abs/2304.03623)

    RSPT框架通过重构环境和预测目标轨迹实现了一般化主动物体跟踪。

    

    主动物体跟踪（AOT）旨在通过自主控制追踪器的运动系统来维持跟踪器与物体之间的特定关系。在移动机器人和自动驾驶等领域具有广泛的应用。然而，在具有杂乱障碍物和多样布局的非结构化环境中构建能够稳健地跨不同场景工作的通用主动追踪器仍然是一个挑战。本文提出了RSPT框架，通过重构环境和预测目标轨迹形成结构感知的运动表示。

    Active Object Tracking (AOT) aims to maintain a specific relation between the tracker and object(s) by autonomously controlling the motion system of a tracker given observations. AOT has wide-ranging applications, such as in mobile robots and autonomous driving. However, building a generalizable active tracker that works robustly across different scenarios remains a challenge, especially in unstructured environments with cluttered obstacles and diverse layouts. We argue that constructing a state representation capable of modeling the geometry structure of the surroundings and the dynamics of the target is crucial for achieving this goal. To address this challenge, we present RSPT, a framework that forms a structure-aware motion representation by Reconstructing the Surroundings and Predicting the target Trajectory. Additionally, we enhance the generalization of the policy network by training in an asymmetric dueling mechanism. We evaluate RSPT on various simulated scenarios and show tha
    
[^10]: 番茄植株的非破坏性叶片检测和大小估计的三维生长监测

    Look how they have grown: Non-destructive Leaf Detection and Size Estimation of Tomato Plants for 3D Growth Monitoring. (arXiv:2304.03610v1 [cs.CV])

    [http://arxiv.org/abs/2304.03610](http://arxiv.org/abs/2304.03610)

    本文提出了一种基于图像的自动化非破坏性测量系统，利用Zivid 3D相机创建番茄植株的3D虚拟表示，通过检测叶片掩模提取叶片大小，实现了对植物生长的精准监测，有望应用于精准农业和温室管理领域。

    

    随着技术的进步，智慧农业成为了一个不断增长的领域。植物特征是监测植物生长的重要指标。先前的研究已经用于估算像叶面积指数、叶片疾病和植株高度等特征。然而，很少有方法应用于非破坏性的叶片大小测量。本文介绍了一种自动化非破坏性图像测量系统，该系统使用Zivid 3D相机获取的2D和3D数据，创建番茄植株的3D虚拟表示（数字双胞胎）。叶子是从对应的2D RGB图像中检测到的，并且使用检测到的叶片掩模将它们映射到它们的3D点云上，然后将叶子点云传送到平面拟合算法中提取叶片大小，为生长监测提供数据。通过对现实世界的番茄植株进行全面试验并将其性能指标与基准测量进行比较，测量平台的性能得到了评估。分析了三个番茄植株的生长阶段，结果显示在估计叶子大小和植株高度方面具有高的精度。所提出的方法对于精准农业和温室管理中的非破坏性植物生长监测具有巨大的潜力。

    Smart farming is a growing field as technology advances. Plant characteristics are crucial indicators for monitoring plant growth. Research has been done to estimate characteristics like leaf area index, leaf disease, and plant height. However, few methods have been applied to non-destructive measurements of leaf size. In this paper, an automated non-destructive imaged-based measuring system is presented, which uses 2D and 3D data obtained using a Zivid 3D camera, creating 3D virtual representations (digital twins) of the tomato plants. Leaves are detected from corresponding 2D RGB images and mapped to their 3D point cloud using the detected leaf masks, which then pass the leaf point cloud to the plane fitting algorithm to extract the leaf size to provide data for growth monitoring. The performance of the measurement platform has been measured through a comprehensive trial on real-world tomato plants with quantified performance metrics compared to ground truth measurements. Three tomat
    
[^11]: 使用游戏引擎从合成数据中检测托盘

    Pallet Detection from Synthetic Data Using Game Engines. (arXiv:2304.03602v1 [cs.CV])

    [http://arxiv.org/abs/2304.03602](http://arxiv.org/abs/2304.03602)

    本研究使用游戏引擎生成合成训练数据的方式来检测托盘分割，自主仓储技术的发展对于机器视觉有很大帮助，Mask R-CNN流水线可以达到较高的准确率。

    

    本研究旨在评估使用游戏引擎生成合成训练数据来进行机器学习的可行性，以检测托盘分割为例。之前的研究已经证明使用合成数据可以是训练神经网络的可行手段，并且因为需要手动进行图像标注的需求降低，可以节省大量手工劳动时间。随着自动化仓储技术的发展，托盘检测的机器视觉可以受益于使用合成数据。根据我们的方法，我们开发了一种工具，能够以像素完美的准确率和比手动方法更快的速度从3D模型自动生成大量带注释的训练数据。对于图像分割，使用了Mask R-CNN流水线，对于单个托盘的AP50达到了86％。

    This research sets out to assess the viability of using game engines to generate synthetic training data for machine learning in the context of pallet segmentation. Using synthetic data has been proven in prior research to be a viable means of training neural networks and saves hours of manual labour due to the reduced need for manual image annotation. Machine vision for pallet detection can benefit from synthetic data as the industry increases the development of autonomous warehousing technologies. As per our methodology, we developed a tool capable of automatically generating large amounts of annotated training data from 3D models at pixel-perfect accuracy and a much faster rate than manual approaches. Regarding image segmentation, a Mask R-CNN pipeline was used, which achieved an AP50 of 86% for individual pallets.
    
[^12]: 基于深度强化学习的无图Crowd Navigation与感知风险控制的移动机器人

    Deep Reinforcement Learning-Based Mapless Crowd Navigation with Perceived Risk of the Moving Crowd for Mobile Robots. (arXiv:2304.03593v1 [cs.RO])

    [http://arxiv.org/abs/2304.03593](http://arxiv.org/abs/2304.03593)

    本论文提出了一种基于碰撞概率的无图Crowd Navigation方法，使用深度强化学习(DRL)来感知人群的危险程度，确保机器人在通过拥挤环境时的安全，同时提高模型的可扩展性。

    

    传统的基于地图的机器人导航方法在拥挤环境中往往会遇到“冻结机器人问题”。深度强化学习方法解决了此问题，但是存在泛化和可扩展性的问题。为了克服这些挑战，我们提出一种使用“碰撞概率”来帮助机器人安全通过人群的方法。将“碰撞概率”包括在观察空间中，给机器人提供了一个感知移动人群的危险程度的能力。机器人会在看似安全的情况下穿过人群，但在人群移动过于激烈时会绕路。通过关注最危险的障碍物，机器人不会在人群密度较高时混淆，确保模型的可扩展性。我们的方法使用深度强化学习(DRL)开发，并在Gazebo模拟器中进行了非合作人群环境中的训练，其中的障碍物以随机速度移动。

    Classical map-based navigation methods are commonly used for robot navigation, but they often struggle in crowded environments due to the Frozen Robot Problem (FRP). Deep reinforcement learning-based methods address the FRP problem, however, suffer from the issues of generalization and scalability. To overcome these challenges, we propose a method that uses Collision Probability (CP) to help the robot navigate safely through crowds. The inclusion of CP in the observation space gives the robot a sense of the level of danger of the moving crowd. The robot will navigate through the crowd when it appears safe but will take a detour when the crowd is moving aggressively. By focusing on the most dangerous obstacle, the robot will not be confused when the crowd density is high, ensuring scalability of the model. Our approach was developed using deep reinforcement learning (DRL) and trained using the Gazebo simulator in a non cooperative crowd environment with obstacles moving at randomized sp
    
[^13]: 大规模深度学习模型高效训练方法：文献综述

    On Efficient Training of Large-Scale Deep Learning Models: A Literature Review. (arXiv:2304.03589v1 [cs.LG])

    [http://arxiv.org/abs/2304.03589](http://arxiv.org/abs/2304.03589)

    研究深度学习模型高效训练方法已有不少成果，但尚缺乏全面总结。本文综述分为数据中心化、模型中心化、超参数优化、深度学习硬件和训练策略等五个方面，比较详尽地回顾了加速深度学习模型训练的基本组件。

    

    深度学习领域在计算机视觉、自然语言处理和语音等方面取得了显著进展。采用大规模模型并在海量数据上进行训练，对于实际应用具有巨大的潜力，可以增强工业生产力，促进社会发展。然而，随着对计算能力要求的增加，尽管有许多研究探讨了高效训练方法，对于训练深度学习模型的加速技术的全面总结仍然备受期待。在本综述中，我们详细回顾了训练加速的研究进展，并将基本组件分为五个主要视角：（1）数据中心化：包括数据集正则化、数据采样和数据中心化课程学习技术，这些方法可以显著减少数据样本的计算复杂度；（2）模型中心化：包括基本模块的加速、模型压缩和模型蒸馏技术；(剩下同上原文)

    The field of deep learning has witnessed significant progress, particularly in computer vision (CV), natural language processing (NLP), and speech. The use of large-scale models trained on vast amounts of data holds immense promise for practical applications, enhancing industrial productivity and facilitating social development. With the increasing demands on computational capacity, though numerous studies have explored the efficient training, a comprehensive summarization on acceleration techniques of training deep learning models is still much anticipated. In this survey, we present a detailed review for training acceleration. We consider the fundamental update formulation and split its basic components into five main perspectives: (1) data-centric: including dataset regularization, data sampling, and data-centric curriculum learning techniques, which can significantly reduce the computational complexity of the data samples; (2) model-centric, including acceleration of basic modules,
    
[^14]: HyperTab: 基于超网络的小型表格数据深度学习方法

    HyperTab: Hypernetwork Approach for Deep Learning on Small Tabular Datasets. (arXiv:2304.03543v1 [cs.LG])

    [http://arxiv.org/abs/2304.03543](http://arxiv.org/abs/2304.03543)

    HyperTab是一种基于超网络结合了随机森林和神经网络优点的小型表格数据深度学习方法，使用每个特定低维视图处理数据，虚拟增加训练样本数量，避免过度拟合。

    

    深度学习在许多领域取得了惊人的表现，例如计算机视觉和自然语言处理，但它在表格数据集上相对传统浅层方法的优势仍然值得商榷。在小型数据集（小于1k个样本）上超过树状集成（如XGBoost或随机森林）的表现尤其具有挑战性。为了解决这个问题，我们引入了HyperTab，这是一种基于超网络解决表格数据集小样本问题的方法。通过将随机森林和神经网络的优点结合起来，HyperTab生成了一个神经网络集合，其中每个目标模型专门处理数据的特定低维视图。由于每个视图扮演数据增强的角色，我们在保持可训练参数数量不变的情况下，虚拟增加了训练样本数量，从而避免了过度拟合。我们对40多个大小不同的表格数据集对HyperTab进行了评估。

    Deep learning has achieved impressive performance in many domains, such as computer vision and natural language processing, but its advantage over classical shallow methods on tabular datasets remains questionable. It is especially challenging to surpass the performance of tree-like ensembles, such as XGBoost or Random Forests, on small-sized datasets (less than 1k samples). To tackle this challenge, we introduce HyperTab, a hypernetwork-based approach to solving small sample problems on tabular datasets. By combining the advantages of Random Forests and neural networks, HyperTab generates an ensemble of neural networks, where each target model is specialized to process a specific lower-dimensional view of the data. Since each view plays the role of data augmentation, we virtually increase the number of training samples while keeping the number of trainable parameters unchanged, which prevents model overfitting. We evaluated HyperTab on more than 40 tabular datasets of a varying number
    
[^15]: ChatPipe：通过优化人-ChatGPT互动来编排数据准备程序

    ChatPipe: Orchestrating Data Preparation Program by Optimizing Human-ChatGPT Interactions. (arXiv:2304.03540v1 [cs.DB])

    [http://arxiv.org/abs/2304.03540](http://arxiv.org/abs/2304.03540)

    ChatPipe 提出了一个新系统，旨在通过自然语言交互优化 ChatGPT 编排 ML 数据准备程序，有效推荐下一个数据准备操作，方便用户进行程序的修改和版本切换，能够显著减少 ML 数据准备所需的时间和精力。

    

    编排高质量的数据准备程序对于成功的机器学习（ML）至关重要，但众所周知，这是耗时费力的。尽管像ChatGPT这样的大型语言模型在通过自然语言提示与用户交互生成程序方面具有令人印象深刻的能力，但仍存在限制。具体而言，用户必须提供特定的提示来引导ChatGPT迭代地改进数据准备程序，这需要对编程、使用的数据集和ML任务有一定的专业知识。此外，一旦生成了程序，在不重新开始整个过程的情况下回顾先前的版本或对程序进行更改是很困难的。在本文中，我们提出了ChatPipe，这是一个新颖的系统，旨在促进用户和ChatGPT之间的无缝交互。 ChatPipe为用户提供关于下一个数据准备操作的有效建议，并指导ChatGPT生成操作的程序。另外，Chatpipe使用户能够轻松修改生成的程序或切换到先前的版本。我们对三个真实的数据集进行了实验，结果表明，ChatPipe可以显著减少为ML任务准备数据所需的时间和精力。

    Orchestrating a high-quality data preparation program is essential for successful machine learning (ML), but it is known to be time and effort consuming. Despite the impressive capabilities of large language models like ChatGPT in generating programs by interacting with users through natural language prompts, there are still limitations. Specifically, a user must provide specific prompts to iteratively guide ChatGPT in improving data preparation programs, which requires a certain level of expertise in programming, the dataset used and the ML task. Moreover, once a program has been generated, it is non-trivial to revisit a previous version or make changes to the program without starting the process over again. In this paper, we present ChatPipe, a novel system designed to facilitate seamless interaction between users and ChatGPT. ChatPipe provides users with effective recommendation on next data preparation operations, and guides ChatGPT to generate program for the operations. Also, Cha
    
[^16]: SSS在SemEval-2023任务10中的论文：使用投票细调变压器可解释的检测在线性别歧视。 (arXiv：2304.03518v1 [cs.CL])

    SSS at SemEval-2023 Task 10: Explainable Detection of Online Sexism using Majority Voted Fine-Tuned Transformers. (arXiv:2304.03518v1 [cs.CL])

    [http://arxiv.org/abs/2304.03518](http://arxiv.org/abs/2304.03518)

    本文描述了使用细调BERT模型和多数投票集成模型来检测和解释在线性别歧视的方法。翻转显着降低了女性在社交媒体平台上经历不成比例的性别歧视的风险。

    

    本文描述了我们在SemEval 2023任务10中提交的作品-可解释的在线性别歧视检测（EDOS），分为三个子任务。社交媒体平台的不断增长导致女性在社交媒体平台上面临不成比例的性别歧视。这使得检测和解释在线性别歧视内容变得比以往更加重要，以使社交媒体对女性更加安全和可访问。我们的方法包括实验和微调基于BERT的模型，并使用多数投票集合模型，该模型优于单个基线模型得分。我们的系统在任务A中实现了宏F1分数0.8392，在任务B中为0.6092，在任务C中为0.4319。

    This paper describes our submission to Task 10 at SemEval 2023-Explainable Detection of Online Sexism (EDOS), divided into three subtasks. The recent rise in social media platforms has seen an increase in disproportionate levels of sexism experienced by women on social media platforms. This has made detecting and explaining online sexist content more important than ever to make social media safer and more accessible for women. Our approach consists of experimenting and finetuning BERT-based models and using a Majority Voting ensemble model that outperforms individual baseline model scores. Our system achieves a macro F1 score of 0.8392 for Task A, 0.6092 for Task B, and 0.4319 for Task C.
    
[^17]: 采用迁移学习技术的本地玫瑰品种检测系统

    Local Rose Breeds Detection System Using Transfer Learning Techniques. (arXiv:2304.03509v1 [cs.CV])

    [http://arxiv.org/abs/2304.03509](http://arxiv.org/abs/2304.03509)

    提出了一种使用迁移学习技术的玫瑰品种检测模型，使用1939张图像数据训练，检测六种不同品种的玫瑰，准确度达到97.89％。该模型可以为花卉行业识别和栽培不同品种的玫瑰提供帮助。

    

    花卉品种检测并给出品种详细信息，包括栽培过程和照顾方式，对于花卉栽培、品种发明和花卉业务非常重要。在孟加拉国所有的本地花卉中，玫瑰是最受欢迎和需求量最大的花卉之一。玫瑰不仅在孟加拉国，而且在世界范围内都是最受欢迎的花卉之一。玫瑰除了用于装饰外，还可以用于许多其他用途。由于玫瑰在花卉行业具有巨大的需求，因此玫瑰品种检测非常重要。然而，与不同花卉的分类不同，目前没有关于特定花卉品种检测的显著工作。本研究提出了一种使用迁移学习技术从图像中检测玫瑰品种的模型。对于花卉方面的这项工作，图像处理和分类的资源不足，因此我们需要大量的图像数据来训练模型。我们使用了1939张不同玫瑰品种的原始图像。我们提出的模型在检测六种不同品种的玫瑰方面获得了97.89％的准确度。该模型可以大大帮助花卉行业识别和栽培不同品种的玫瑰，并为每个品种提出最佳的栽培和照顾实践。

    Flower breed detection and giving details of that breed with the suggestion of cultivation processes and the way of taking care is important for flower cultivation, breed invention, and the flower business. Among all the local flowers in Bangladesh, the rose is one of the most popular and demanded flowers. Roses are the most desirable flower not only in Bangladesh but also throughout the world. Roses can be used for many other purposes apart from decoration. As roses have a great demand in the flower business so rose breed detection will be very essential. However, there is no remarkable work for breed detection of a particular flower unlike the classification of different flowers. In this research, we have proposed a model to detect rose breeds from images using transfer learning techniques. For such work in flowers, resources are not enough in image processing and classification, so we needed a large dataset of the massive number of images to train our model. we have used 1939 raw im
    
[^18]: 我们可以通过难样本来更好地学习吗?

    Can we learn better with hard samples?. (arXiv:2304.03486v1 [cs.CV])

    [http://arxiv.org/abs/2304.03486](http://arxiv.org/abs/2304.03486)

    该研究提出一种改进传统mini-batch算法的方案，该方案重点训练具有高损失的mini-batch网络，其在三个基准数据集上的实验结果表明，该方法可以显着提高测试准确性并加快收敛速度。

    

    在深度学习中，常用mini-batch训练优化网络参数。然而，传统的mini-batch方法可能无法学习数据中的次数较少的样本和复杂的模式，导致泛化时间更长。为了解决这个问题，提出了一种改进传统算法的方案，该方案重点训练具有高损失的mini-batch网络。该研究评估了在三个基准数据集（CIFAR-10，CIFAR-100和STL-10）上训练的各种深度神经网络（ResNet-18，ResNet-50，Efficient Net B4，EfficientNetV2-S和MobilenetV3-S）的效果。实验结果表明，与传统的mini-batch训练方法相比，所提出的方法可以显着提高测试准确性并加快收敛速度。此外，我们引入了一个超参数delta ({\delta})，它决定有多少个mini-batch被考虑用于训练。

    In deep learning, mini-batch training is commonly used to optimize network parameters. However, the traditional mini-batch method may not learn the under-represented samples and complex patterns in the data, leading to a longer time for generalization. To address this problem, a variant of the traditional algorithm has been proposed, which trains the network focusing on mini-batches with high loss. The study evaluates the effectiveness of the proposed training using various deep neural networks trained on three benchmark datasets (CIFAR-10, CIFAR-100, and STL-10). The deep neural networks used in the study are ResNet-18, ResNet-50, Efficient Net B4, EfficientNetV2-S, and MobilenetV3-S. The experimental results showed that the proposed method can significantly improve the test accuracy and speed up the convergence compared to the traditional mini-batch training method. Furthermore, we introduce a hyper-parameter delta ({\delta}) that decides how many mini-batches are considered for trai
    
[^19]: 重新考虑基于GNN的异构知识图谱实体对齐：新数据集和新方法

    Rethinking GNN-based Entity Alignment on Heterogeneous Knowledge Graphs: New Datasets and A New Method. (arXiv:2304.03468v1 [cs.LG])

    [http://arxiv.org/abs/2304.03468](http://arxiv.org/abs/2304.03468)

    文章重新考虑了基于GNN的异构知识图谱实体对齐。为探究EA实际场景中的表现，提出了更接近现实的高度异构知识图谱数据集，并提出了新方法。

    

    知识图谱（KG）应用的发展导致了需要从各种来源提取的异构KG之间的实体对齐（EA）的不断增长需求。近来，由于GNN的出色结构信息捕捉能力，在EA任务中广泛采用GNN。然而，我们观察到现有常见EA数据集的过于简单化的设置与现实场景相距甚远，这妨碍了对最近方法所取得进展的全面理解。这种现象使我们深思：现有基于GNN的EA方法是否真的取得了伟大进展？为了研究EA方法在现实情况下的性能，本文聚焦于高度异构的KG（HHKG）（例如，事件KG和通用KG）的对齐，这些KG在规模和结构上不同，并共享更少的重叠实体。首先，我们清理了不合理的设置，并提出了两个新的HHKG数据集，其密切地模拟了现实世界场景。

    The development of knowledge graph (KG) applications has led to a rising need for entity alignment (EA) between heterogeneous KGs that are extracted from various sources. Recently, graph neural networks (GNNs) have been widely adopted in EA tasks due to GNNs' impressive ability to capture structure information. However, we have observed that the oversimplified settings of the existing common EA datasets are distant from real-world scenarios, which obstructs a full understanding of the advancements achieved by recent methods. This phenomenon makes us ponder: Do existing GNN-based EA methods really make great progress?  In this paper, to study the performance of EA methods in realistic settings, we focus on the alignment of highly heterogeneous KGs (HHKGs) (e.g., event KGs and general KGs) which are different with regard to the scale and structure, and share fewer overlapping entities. First, we sweep the unreasonable settings, and propose two new HHKG datasets that closely mimic real-wo
    
[^20]: AMS-DRL: 学习多目标逃避以实现无人机安全导航

    AMS-DRL: Learning Multi-Pursuit Evasion for Safe Targeted Navigation of Drones. (arXiv:2304.03443v1 [cs.RO])

    [http://arxiv.org/abs/2304.03443](http://arxiv.org/abs/2304.03443)

    本文提出了AMS-DRL方法用于训练对抗性神经网络，以学习和快速适应多个攻击者的行为，从而实现无人机的安全导航和到达目标。

    

    在多个袭击者存在的情况下，无人机的安全导航是一项具有挑战性的任务。本文提出了一种新方法，异步多阶段深度强化学习(AMS-DRL)，来训练对抗性神经网络，该网络可以从多个攻击者的行动中学习和快速适应它们的行为，使无人机能够避免攻击并到达目标。我们的方法通过确保博弈论分析中的代理之间的Nash均衡来保证收敛性。我们在广泛的模拟中评估了我们的方法，并展示了它比基线方法具有更高的导航成功率。我们还分析了一些参数如相对最大速度如何影响导航性能。此外，我们进行了物理实验，并验证了实时飞行中受训策略的有效性。介绍了成功率热图，以说明空间几何对导航结果的影响。项目网站：https://gi

    Safe navigation of drones in the presence of adversarial physical attacks from multiple pursuers is a challenging task. This paper proposes a novel approach, asynchronous multi-stage deep reinforcement learning (AMS-DRL), to train an adversarial neural network that can learn from the actions of multiple pursuers and adapt quickly to their behavior, enabling the drone to avoid attacks and reach its target. Our approach guarantees convergence by ensuring Nash Equilibrium among agents from the game-theory analysis. We evaluate our method in extensive simulations and show that it outperforms baselines with higher navigation success rates. We also analyze how parameters such as the relative maximum speed affect navigation performance. Furthermore, we have conducted physical experiments and validated the effectiveness of the trained policies in real-time flights. A success rate heatmap is introduced to elucidate how spatial geometry influences navigation outcomes. Project website: https://gi
    
[^21]: 生成代理: 人类行为的交互仿真器

    Generative Agents: Interactive Simulacra of Human Behavior. (arXiv:2304.03442v1 [cs.HC])

    [http://arxiv.org/abs/2304.03442](http://arxiv.org/abs/2304.03442)

    本文介绍了一种生成代理的架构，它能够仿真出具有可信度的人类行为，填充交互式沙盒环境，为创造更加真实的人机交互体验提供了一种新的思路。

    

    可信的人类行为仿真可赋能于从沉浸式环境到人际交流排练空间到原型工具的交互式应用程序。在本文中，我们介绍了生成代理——具有可信度的人类行为仿真的计算机软件代理。生成代理会起床，做早餐，去工作；艺术家画画，作家写作；他们形成观点，互相注意，并开始交谈；他们回忆过去的日子并计划未来。为了使生成代理能够实现，我们描述了一种架构，它将大型语言模型扩展到使用自然语言存储代理的经历的完整记录，随着时间的推移综合这些记忆到更高层次的反思，以及动态检索这些记忆以规划行为。我们实例化生成代理以填充受《模拟人生》启发的交互式沙盒环境，最终用户可以使用自然语言对话系统与25个代理交互。

    Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents--computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent's experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty five agents using natur
    
[^22]: 评估ChatGPT和GPT-4的逻辑推理能力

    Evaluating the Logical Reasoning Ability of ChatGPT and GPT-4. (arXiv:2304.03439v1 [cs.CL])

    [http://arxiv.org/abs/2304.03439](http://arxiv.org/abs/2304.03439)

    本文分析了多个逻辑推理数据集，评估了ChatGPT和GPT-4在逻辑推理任务上的表现，并构造了一个逻辑推理的分布之外的数据集来研究它们的鲁棒性。实验结果显示，ChatGPT在大多数逻辑推理基准测试中的表现远优于RoBERTa微调方法，而GPT-4的表现则更高。

    

    利用逻辑推理能力是一个全面的自然语言理解任务。随着先进的生成预训练转换器4（GPT-4）的发布，我们渴望了解GPT-4在各种逻辑推理任务上的表现。本文分析了多个逻辑推理数据集，包括LogiQA和ReClor等常用基准测试，以及像AR-LSAT这样的新发布的数据集。我们对需要逻辑推理的基准测试进行了多项选择阅读理解和自然语言推理任务测试。我们进一步构造了一个逻辑推理的分布之外的数据集，以研究ChatGPT和GPT-4的鲁棒性。我们还进行了ChatGPT和GPT-4之间的性能比较。实验结果表明，在大多数逻辑推理基准测试中，ChatGPT的表现远远优于RoBERTa微调方法。GPT-4在我们的手动测试中表现更高。在基准测试中，ChatGPT和GPT-4的表现相对较为均衡。

    Harnessing logical reasoning ability is a comprehensive natural language understanding endeavor. With the release of Generative Pretrained Transformer 4 (GPT-4), highlighted as "advanced" at reasoning tasks, we are eager to learn the GPT-4 performance on various logical reasoning tasks. This report analyses multiple logical reasoning datasets, with popular benchmarks like LogiQA and ReClor, and newly-released datasets like AR-LSAT. We test the multi-choice reading comprehension and natural language inference tasks with benchmarks requiring logical reasoning. We further construct a logical reasoning out-of-distribution dataset to investigate the robustness of ChatGPT and GPT-4. We also make a performance comparison between ChatGPT and GPT-4. Experiment results show that ChatGPT performs significantly better than the RoBERTa fine-tuning method on most logical reasoning benchmarks. GPT-4 shows even higher performance on our manual tests. Among benchmarks, ChatGPT and GPT-4 do relatively w
    
[^23]: 鲁棒不变表示中的域泛化

    Domain Generalization In Robust Invariant Representation. (arXiv:2304.03431v1 [cs.LG])

    [http://arxiv.org/abs/2304.03431](http://arxiv.org/abs/2304.03431)

    本文研究了不变表示的泛化性能，证明具有不变表示的模型可以学习到具有鲁棒性的非结构化潜在表示，因此使不变性成为域泛化的一个关键方面。

    

    无监督学习常见变换的不变表示方法常用于目标识别。学习不变性使得模型更加鲁棒，并在实际场景中更容易应用。由于不改变对象固有属性的数据变换是识别任务中主要的复杂性来源，对这些变换具有不变性的模型有助于减少所需的训练数据。这进一步提高了模型的效率并简化了训练过程。本文研究了不变表示的泛化性能，并试图回答一个问题：具有某些变换不变性的模型在先前未见域中是否仍具有不变性？通过广泛的实验，我们证明了具有不变表示的模型可以学习到具有鲁棒性的非结构化潜在表示，因此使不变性成为域泛化的一个关键方面。

    Unsupervised approaches for learning representations invariant to common transformations are used quite often for object recognition. Learning invariances makes models more robust and practical to use in real-world scenarios. Since data transformations that do not change the intrinsic properties of the object cause the majority of the complexity in recognition tasks, models that are invariant to these transformations help reduce the amount of training data required. This further increases the model's efficiency and simplifies training. In this paper, we investigate the generalization of invariant representations on out-of-distribution data and try to answer the question: Do model representations invariant to some transformations in a particular seen domain also remain invariant in previously unseen domains? Through extensive experiments, we demonstrate that the invariant model learns unstructured latent representations that are robust to distribution shifts, thus making invariance a de
    
[^24]: 基于谷歌OCR扫描的藏文手稿的神经拼写纠错模型

    Cleansing Jewel: A Neural Spelling Correction Model Built On Google OCR-ed Tibetan Manuscripts. (arXiv:2304.03427v1 [cs.CL])

    [http://arxiv.org/abs/2304.03427](http://arxiv.org/abs/2304.03427)

    本文提出了一种基于谷歌OCR扫描的藏文手稿的神经拼写纠错模型，可以自动纠正OCR输出中的噪声。

    

    人文学者在研究历史、宗教和社会政治结构等方面经常依赖于古代手稿。虽然OCR技术可以将这些宝贵手稿数字化，但多数手稿因磨损而过时，OCR程序没办法识别翻页的虚淡或污渍。本文提出了一种基于谷歌OCR扫描的藏文手稿的神经拼写纠错模型，可以自动纠正OCR输出中的噪声。本文分为四个部分：数据集、模型架构、训练和分析。首先，我们对原始藏文电子文本语料库进行了特征工程，并将其转化为两组结构化数据框——一组匹配的玩具数据和一组匹配的真实数据。然后，我们在Transformer架构中实现了置信度得分机制来执行拼写校正任务。根据损失和字符错误率，我们的Transformer + 置信度得分机制比其他常用的拼写校正算法表现更好。

    Scholars in the humanities rely heavily on ancient manuscripts to study history, religion, and socio-political structures in the past. Many efforts have been devoted to digitizing these precious manuscripts using OCR technology, but most manuscripts were blemished over the centuries so that an Optical Character Recognition (OCR) program cannot be expected to capture faded graphs and stains on pages. This work presents a neural spelling correction model built on Google OCR-ed Tibetan Manuscripts to auto-correct OCR-ed noisy output. This paper is divided into four sections: dataset, model architecture, training and analysis. First, we feature-engineered our raw Tibetan etext corpus into two sets of structured data frames -- a set of paired toy data and a set of paired real data. Then, we implemented a Confidence Score mechanism into the Transformer architecture to perform spelling correction tasks. According to the Loss and Character Error Rate, our Transformer + Confidence score mechani
    
[^25]: 音乐混音工作流中的人工智能技术应用调查研究

    Adoption of AI Technology in the Music Mixing Workflow: An Investigation. (arXiv:2304.03407v1 [cs.HC])

    [http://arxiv.org/abs/2304.03407](http://arxiv.org/abs/2304.03407)

    该研究调查了音乐混音工作流中AI技术的应用情况及不同用户群体的采用情况。结果显示，即使AI混音工具能够为业余爱好者提供不错的结果，职业业余爱好者和专业人员需要更为精确的控制和自定义选项，以及辅助和协作技术。

    

    人工智能技术在音乐行业中的应用正在推动音乐创作、制作和混音的重大变化。本研究调查了人工智能在混音工作流程中的当前状态以及不同用户群体对其采纳情况。通过半结构化访谈、基于问卷的研究和分析网络论坛，本研究确认了包括业余爱好者、职业业余爱好者和专业人士在内的三个用户群体。研究结果表明，虽然AI混音工具能够简化过程并为业余爱好者提供不错的结果，职业业余爱好者需要精确的控制和自定义选项，而专业人员除了需要控制和自定义选项外，还需要辅助和协作技术。本研究为设计针对不同用户群体的有效的AI混音工具提供了策略，并概述了未来的方向。

    The integration of artificial intelligence (AI) technology in the music industry is driving a significant change in the way music is being composed, produced and mixed. This study investigates the current state of AI in the mixing workflows and its adoption by different user groups. Through semi-structured interviews, a questionnaire-based study, and analyzing web forums, the study confirms three user groups comprising amateurs, pro-ams, and professionals. Our findings show that while AI mixing tools can simplify the process and provide decent results for amateurs, pro-ams seek precise control and customization options, while professionals desire control and customization options in addition to assistive and collaborative technologies. The study provides strategies for designing effective AI mixing tools for different user groups and outlines future directions.
    
[^26]: 基于局部区域对比的医学图像自监督学习增强技术

    Localized Region Contrast for Enhancing Self-Supervised Learning in Medical Image Segmentation. (arXiv:2304.03406v1 [cs.CV])

    [http://arxiv.org/abs/2304.03406](http://arxiv.org/abs/2304.03406)

    本文提出了一种基于局部区域对比的医学图像自监督学习增强框架，以提高多器官分割等密集预测任务的性能，实验结果表明该方法可以超越最先进的自监督学习方法。

    

    最近自监督学习取得了很大的进展，表明可以从无标签图像中学习有效的视觉表示。这导致人们对将自监督学习应用于医学领域的兴趣增加了，因为无标签图像丰富而有标签图像很难获得。然而，大多数自监督学习方法被建模为图像级别的判别或生成代理任务，这可能无法捕捉多器官分割等密集预测任务所需的更细致级别的表示。本文提出了一种新颖的对比学习框架，它集成了局部区域对比（LRC）以增强现有的医学图像分割自监督预训练方法。我们的方法涉及使用Felzenszwalb算法识别超像素，并使用新的对比采样损失进行局部对比学习。通过在三个多器官分割数据集上进行广泛实验，我们证明了我们的方法可以提高分割性能并超越最先进的自监督学习方法。

    Recent advancements in self-supervised learning have demonstrated that effective visual representations can be learned from unlabeled images. This has led to increased interest in applying self-supervised learning to the medical domain, where unlabeled images are abundant and labeled images are difficult to obtain. However, most self-supervised learning approaches are modeled as image level discriminative or generative proxy tasks, which may not capture the finer level representations necessary for dense prediction tasks like multi-organ segmentation. In this paper, we propose a novel contrastive learning framework that integrates Localized Region Contrast (LRC) to enhance existing self-supervised pre-training methods for medical image segmentation. Our approach involves identifying Super-pixels by Felzenszwalb's algorithm and performing local contrastive learning using a novel contrastive sampling loss. Through extensive experiments on three multi-organ segmentation datasets, we demon
    
[^27]: CAPOT: 使用后训练对比对齐创建强健的密集查询编码器

    CAPOT: Creating Robust Dense Query Encoders using Post Training Contrastive Alignment. (arXiv:2304.03401v1 [cs.IR])

    [http://arxiv.org/abs/2304.03401](http://arxiv.org/abs/2304.03401)

    CAPOT使用后训练对比对齐的方法，提高模型对于噪声查询的健壮性，表现类似于数据增强但没有其开销。

    

    上下文词表示的成功和神经信息检索的进步使得基于密集向量的检索成为段落和文档排名的标准方法。双编码器虽然有效和高效，但对查询分布和嘈杂查询变化很脆弱。数据增强可以使模型更加健壮，但会引入训练集生成的开销，并需要重新训练和索引重建。我们提出了 Contrastive Alignment POst Training (CAPOT)，一种高效的微调方法，通过冻结文档编码器，让查询编码器学习将嘈杂查询与其未更改的根对齐，以提高模型的健壮性。我们评估了 CAPOT 在 MSMARCO、自然问题和 Trivia QA 段落检索的嘈杂变体上，发现 CAPOT 具有与数据增强类似的影响，但没有它的开销。

    The success of contextual word representations and advances in neural information retrieval have made dense vector-based retrieval a standard approach for passage and document ranking. While effective and efficient, dual-encoders are brittle to variations in query distributions and noisy queries. Data augmentation can make models more robust but introduces overhead to training set generation and requires retraining and index regeneration. We present Contrastive Alignment POst Training (CAPOT), a highly efficient finetuning method that improves model robustness without requiring index regeneration, the training set optimization, or alteration. CAPOT enables robust retrieval by freezing the document encoder while the query encoder learns to align noisy queries with their unaltered root. We evaluate CAPOT noisy variants of MSMARCO, Natural Questions, and Trivia QA passage retrieval, finding CAPOT has a similar impact as data augmentation with none of its overhead.
    
[^28]: 应用机器学习和领域知识个性化数字健康行为变革干预

    Personalizing Digital Health Behavior Change Interventions using Machine Learning and Domain Knowledge. (arXiv:2304.03392v1 [cs.LG])

    [http://arxiv.org/abs/2304.03392](http://arxiv.org/abs/2304.03392)

    该论文提出了一种采用机器学习和领域知识进行个性化数字健康行为变革干预的系统，其利用反事实例子进行特征控制以预测干预效果并优化干预效果。

    

    我们正在开发一种虚拟教练系统，帮助患者坚持行为变革干预（BCI）。我们的系统预测患者是否会执行目标行为，并使用反事实例子进行特征控制，以指导个性化BCI。我们使用具有不同响应水平的模拟患者数据评估了我们的预测模型。

    We are developing a virtual coaching system that helps patients adhere to behavior change interventions (BCI). Our proposed system predicts whether a patient will perform the targeted behavior and uses counterfactual examples with feature control to guide personalizsation of BCI. We evaluated our prediction model using simulated patient data with varying levels of receptivity to intervention.
    
[^29]: 推理中处理Wikidata限定词的问题

    Handling Wikidata Qualifiers in Reasoning. (arXiv:2304.03375v1 [cs.AI])

    [http://arxiv.org/abs/2304.03375](http://arxiv.org/abs/2304.03375)

    本文提出了处理Wikidata限定词的方法，包括对限定词进行分类和使用多排序逻辑语言形式化Wikidata模型，以应用于推理。

    

    Wikidata是一个被许多社区广泛应用于各种应用程序的知识图谱。Wikidata语句带有限定词值对，用于描述信息，例如语句的有效上下文，其因果关系，来源等。在推理中处理限定词是一个具有挑战性的问题。本文提出了一个解决方法，即通过对限定符进行分类和将Wikidata模型形式化为一种多排序的逻辑语言来解决此问题，通过将该逻辑与语义Web规则语言（SWRL）相结合，演示了我们的方法的实用性。

    Wikidata is a knowledge graph increasingly adopted by many communities for diverse applications. Wikidata statements are annotated with qualifier-value pairs that are used to depict information, such as the validity context of the statement, its causality, provenances, etc. Handling the qualifiers in reasoning is a challenging problem. When defining inference rules (in particular, rules on ontological properties (x subclass of y, z instance of x, etc.)), one must consider the qualifiers, as most of them participate in the semantics of the statements. This poses a complex problem because a) there is a massive number of qualifiers, and b) the qualifiers of the inferred statement are often a combination of the qualifiers in the rule condition. In this work, we propose to address this problem by a) defining a categorization of the qualifiers b) formalizing the Wikidata model with a many-sorted logical language; the sorts of this language are the qualifier categories. We couple this logic w
    
[^30]: 奖励转移的稳健决策重点学习

    Robust Decision-Focused Learning for Reward Transfer. (arXiv:2304.03365v1 [cs.LG])

    [http://arxiv.org/abs/2304.03365](http://arxiv.org/abs/2304.03365)

    本文介绍了一种稳健决策重点（RDF）算法，利用非识别性的DF解，学习同时最大化期望回报和抵御奖励函数变化的模型，可以显著提高DF对奖励函数变化的稳健性，而不会降低智能体的总回报。

    

    最近，决策重点（Decision-focused，DF）的基于模型的强化学习被介绍为一种强有力的算法，它可以专注于学习最有利于获得高报酬的MDP动态。虽然这种方法通过专注于直接优化报酬来提高智能体的性能，但从MLE的角度来看，它学习的动力学不够准确，因此可能对奖励函数的变化很脆弱。在这项工作中，我们开发了稳健决策重点（RDF）算法，它利用DF解的非识别性，学习同时最大化期望回报和抵御奖励函数变化的模型。我们在各种玩具示例和医疗模拟器上展示了RDF显着增加了DF对奖励函数变化的稳健性，而不会降低智能体的总回报。

    Decision-focused (DF) model-based reinforcement learning has recently been introduced as a powerful algorithm which can focus on learning the MDP dynamics which are most relevant for obtaining high rewards. While this approach increases the performance of agents by focusing the learning towards optimizing for the reward directly, it does so by learning less accurate dynamics (from a MLE standpoint), and may thus be brittle to changes in the reward function. In this work, we develop the robust decision-focused (RDF) algorithm which leverages the non-identifiability of DF solutions to learn models which maximize expected returns while simultaneously learning models which are robust to changes in the reward function. We demonstrate on a variety of toy example and healthcare simulators that RDF significantly increases the robustness of DF to changes in the reward function, without decreasing the overall return the agent obtains.
    
[^31]: 推荐系统的图协作信号去噪与增强

    Graph Collaborative Signals Denoising and Augmentation for Recommendation. (arXiv:2304.03344v1 [cs.IR])

    [http://arxiv.org/abs/2304.03344](http://arxiv.org/abs/2304.03344)

    本文提出了一种新的图邻接矩阵，它包括了用户-用户和项目-项目的相关性，以及一个经过适当设计的用户-项目交互矩阵，并通过预训练和top-K采样增强了用户-项目交互矩阵，以更好地适应所有用户的需求。

    

    图协作过滤（GCF）是捕捉推荐系统中高阶协同信号的流行技术。然而，GCF的双向邻接矩阵，其定义了基于用户-项目交互进行聚合的邻居，对于有大量交互但不足的用户/项目来说可能是嘈杂的。此外，邻接矩阵忽略了用户-用户和项目-项目之间的相关性，这可能限制了聚合的有益邻居的范围。在这项工作中，我们提出了一种新的图邻接矩阵，它包括了用户-用户和项目-项目的相关性，以及一个经过适当设计的用户-项目交互矩阵，以平衡所有用户之间的交互数量。为了实现这一点，我们预先训练了一个基于图的推荐方法来获得用户/项目嵌入，然后通过top-K采样增强了用户-项目交互矩阵。我们还增强了对称的用户-用户和项目-项目相关组件，以更好地适应所有用户的需求。

    Graph collaborative filtering (GCF) is a popular technique for capturing high-order collaborative signals in recommendation systems. However, GCF's bipartite adjacency matrix, which defines the neighbors being aggregated based on user-item interactions, can be noisy for users/items with abundant interactions and insufficient for users/items with scarce interactions. Additionally, the adjacency matrix ignores user-user and item-item correlations, which can limit the scope of beneficial neighbors being aggregated.  In this work, we propose a new graph adjacency matrix that incorporates user-user and item-item correlations, as well as a properly designed user-item interaction matrix that balances the number of interactions across all users. To achieve this, we pre-train a graph-based recommendation method to obtain users/items embeddings, and then enhance the user-item interaction matrix via top-K sampling. We also augment the symmetric user-user and item-item correlation components to th
    
[^32]: 最大序数二次因子分解

    Maximal Ordinal Two-Factorizations. (arXiv:2304.03338v1 [cs.AI])

    [http://arxiv.org/abs/2304.03338](http://arxiv.org/abs/2304.03338)

    本文研究了最大序数二次因子分解问题，证明了其判定是否存在是一个NP完全问题，并提供了用于计算最大因子分解的算法Ord2Factor。

    

    在一个形式背景中，序数因子是其关系的子集，形成概念格中的链，即对应于线性顺序的数据集的一部分。为了可视化形式上下文中的数据，Ganter和Glodeanu提出了基于两个序数因子的双图。为了使双图有用，重要的是这些因子尽可能包含更多数据点，即覆盖尽可能多的关系。本文研究这样的序数二次因子分解。首先，我们研究了省略序数二次因子分解的形式背景中两个因子的不相交性。然后，我们证明判定给定大小的二次因子分解是否存在是一个NP完全问题，这使得计算最大因子分解具有计算成本。最后，我们提供了算法Ord2Factor，它允许我们计算大的序数二次因子分解。

    Given a formal context, an ordinal factor is a subset of its incidence relation that forms a chain in the concept lattice, i.e., a part of the dataset that corresponds to a linear order. To visualize the data in a formal context, Ganter and Glodeanu proposed a biplot based on two ordinal factors. For the biplot to be useful, it is important that these factors comprise as much data points as possible, i.e., that they cover a large part of the incidence relation. In this work, we investigate such ordinal two-factorizations. First, we investigate for formal contexts that omit ordinal two-factorizations the disjointness of the two factors. Then, we show that deciding on the existence of two-factorizations of a given size is an NP-complete problem which makes computing maximal factorizations computationally expensive. Finally, we provide the algorithm Ord2Factor that allows us to compute large ordinal two-factorizations.
    
[^33]: 可解释人工智能和视觉推理：来自放射学的见解

    Explainable AI And Visual Reasoning: Insights From Radiology. (arXiv:2304.03318v1 [cs.HC])

    [http://arxiv.org/abs/2304.03318](http://arxiv.org/abs/2304.03318)

    本研究探讨了当前可解释人工智能在放射学应用中的难点，提出了一种基于人类推理和证明的解释设计方法，并通过放射学案例，证明了这种方法可行。

    

    为什么可解释人工智能（XAI）在放射学中的解释，尽管承诺透明度，仍然无法获得人类的信任？当前的XAI方法提供了有关预测的证明，但这些方法不能满足从业者的需求。这些XAI解释缺乏直观的证据基础覆盖，这是采用的一个重要障碍。我们认为，与传统的热图等视觉解释不同，模仿人类推理和证明的XAI解释可能比较有用和可靠。通过放射学案例研究，我们演示了放射学从业者如何让其他从业者看到诊断结论的有效性。机器学习的分类缺乏这种证据基础，因此未能引起潜在用户的信任和采用。本研究的洞见可能适用于基于人类推理和证明的面向人类解释设计的指导原则。

    Why do explainable AI (XAI) explanations in radiology, despite their promise of transparency, still fail to gain human trust? Current XAI approaches provide justification for predictions, however, these do not meet practitioners' needs. These XAI explanations lack intuitive coverage of the evidentiary basis for a given classification, posing a significant barrier to adoption. We posit that XAI explanations that mirror human processes of reasoning and justification with evidence may be more useful and trustworthy than traditional visual explanations like heat maps. Using a radiology case study, we demonstrate how radiology practitioners get other practitioners to see a diagnostic conclusion's validity. Machine-learned classifications lack this evidentiary grounding and consequently fail to elicit trust and adoption by potential users. Insights from this study may generalize to guiding principles for human-centered explanation design based on human reasoning and justification of evidence
    
[^34]: 比较NARS和强化学习：对ONA和$Q$-Learning算法的分析

    Comparing NARS and Reinforcement Learning: An Analysis of ONA and $Q$-Learning Algorithms. (arXiv:2304.03291v1 [cs.LG])

    [http://arxiv.org/abs/2304.03291](http://arxiv.org/abs/2304.03291)

    本文比较了NARS和强化学习在解决序列任务方面的性能，发现NARS在各种环境中都有较好的表现，尤其是在非确定性环境中。

    

    近年来，强化学习（RL）已成为解决机器学习中基于序列任务的流行方法。然而，寻找RL的可行替代方案仍然是一个令人兴奋和创新的研究领域。其中一个备受关注的替代方案是非公理推理系统（NARS），它是一个通用的认知推理框架。本文研究了NARS作为RL替代方案在解决基于序列任务方面的潜力。为了研究这一点，我们在使用Open AI gym创建的各种环境中，对ONA作为NARS实现和$Q$-Learning的性能进行了比较分析。这些环境具有不同的难度级别，从简单到复杂不等。我们的研究结果表明，在各种环境中，尤其是在非确定性环境中，NARS是一个有竞争力的RL替代方案。

    In recent years, reinforcement learning (RL) has emerged as a popular approach for solving sequence-based tasks in machine learning. However, finding suitable alternatives to RL remains an exciting and innovative research area. One such alternative that has garnered attention is the Non-Axiomatic Reasoning System (NARS), which is a general-purpose cognitive reasoning framework. In this paper, we delve into the potential of NARS as a substitute for RL in solving sequence-based tasks. To investigate this, we conduct a comparative analysis of the performance of ONA as an implementation of NARS and $Q$-Learning in various environments that were created using the Open AI gym. The environments have different difficulty levels, ranging from simple to complex. Our results demonstrate that NARS is a promising alternative to RL, with competitive performance in diverse environments, particularly in non-deterministic ones.
    
[^35]: 自适应特征融合：增强深度学习模型的泛化能力

    Adaptive Feature Fusion: Enhancing Generalization in Deep Learning Models. (arXiv:2304.03290v1 [cs.CV])

    [http://arxiv.org/abs/2304.03290](http://arxiv.org/abs/2304.03290)

    本研究提出了一种自适应特征融合（AFF）的方法，能够通过动态调整深度学习模型中特征融合过程来增强其泛化能力。该方法结合了数据驱动和基于模型的融合策略，能够根据数据特征和模型要求自适应融合特征。

    

    近年来，深度学习模型在计算机视觉、自然语言处理和语音识别等领域展示出了显着的成功。然而，这些模型的泛化能力可能会受到特征融合技术的限制而受到负面影响。本文引入了一种创新性的方法，自适应特征融合（AFF），通过动态调整特征表示的融合过程来增强深度学习模型的泛化能力。所提出的AFF框架旨在将融合层融入到现有的深度学习架构中，实现无缝集成和改进性能。通过结合数据驱动和基于模型的融合策略，AFF能够根据数据特征和模型要求自适应地融合特征。本文详细介绍了AFF框架的设计和实现，包括适用于各种深度学习模型的融合层。

    In recent years, deep learning models have demonstrated remarkable success in various domains, such as computer vision, natural language processing, and speech recognition. However, the generalization capabilities of these models can be negatively impacted by the limitations of their feature fusion techniques. This paper introduces an innovative approach, Adaptive Feature Fusion (AFF), to enhance the generalization of deep learning models by dynamically adapting the fusion process of feature representations.  The proposed AFF framework is designed to incorporate fusion layers into existing deep learning architectures, enabling seamless integration and improved performance. By leveraging a combination of data-driven and model-based fusion strategies, AFF is able to adaptively fuse features based on the underlying data characteristics and model requirements. This paper presents a detailed description of the AFF framework, including the design and implementation of fusion layers for vario
    
[^36]: 自然语言规范中的数学程序合成

    Synthesis of Mathematical programs from Natural Language Specifications. (arXiv:2304.03287v1 [cs.AI])

    [http://arxiv.org/abs/2304.03287](http://arxiv.org/abs/2304.03287)

    本论文关注于通过自然语言规范中的目标和约束合成数学程序，并通过评估CodeT5和使用GPT-3来生成需要的示例进行实验。

    

    在各个商业领域中遇到的几个决策问题可以被建模为数学程序，即优化问题。进行这种建模的过程通常需要涉及到受过运筹学和高级算法培训的专家。令人惊讶的是，尽管程序和代码合成，AutoML，学习优化等方面的方法取得了重大进展，但几乎没有人关注自动化合成数学程序的任务。我们想象一种情景，在这种情况下，建模的规范，即目标和约束以自然语言的形式表达，并且必须从这样的自然语言规范中合成数学程序。在这项工作中，我们评估了使用带有数据增强和束后处理的CodeT5的功效。我们利用GPT-3进行背翻译以生成合成示例。此外，我们应用线性规划规则来评分。

    Several decision problems that are encountered in various business domains can be modeled as mathematical programs, i.e. optimization problems. The process of conducting such modeling often requires the involvement of experts trained in operations research and advanced algorithms. Surprisingly, despite the significant advances in the methods for program and code synthesis, AutoML, learning to optimize etc., there has been little or no attention paid to automating the task of synthesizing mathematical programs. We imagine a scenario where the specifications for modeling, i.e. the objective and constraints are expressed in an unstructured form in natural language (NL) and the mathematical program has to be synthesized from such an NL specification. In this work we evaluate the efficacy of employing CodeT5 with data augmentation and post-processing of beams. We utilize GPT-3 with back translation for generation of synthetic examples. Further we apply rules of linear programming to score b
    
[^37]: 关于多语言神经机器翻译的Pareto前沿研究

    On the Pareto Front of Multilingual Neural Machine Translation. (arXiv:2304.03216v1 [cs.CL])

    [http://arxiv.org/abs/2304.03216](http://arxiv.org/abs/2304.03216)

    本研究针对多语言神经机器翻译的数据不平衡问题，提出双重幂律方法用于预测独特的性能权衡前沿，并建立基于该方法的样本比例选择优化问题，取得更好的结果。

    

    本研究探讨了在多语言神经机器翻译中，给定方向的泛化性能如何随其采样比例的变化而变化。通过训练200多个具有不同模型大小、方向和总任务数量的多语言模型，我们发现在训练语料库存在数据不平衡时，标量化导致了一个多任务权衡前沿，该前沿偏离了传统的Pareto前沿。基于我们的观察，我们提出了双重幂律来预测MNMT中独特的性能权衡前沿，该方法在各种语言、数据充足性和任务数量方面都很鲁棒。最后，我们将MNMT中的样本比例选择问题建模为基于双重幂律的优化问题，取得了更好的结果。

    In this work, we study how the generalization performance of a given direction changes with its sampling ratio in Multilingual Neural Machine Translation (MNMT). By training over 200 multilingual models with various model sizes, directions, and total numbers of tasks, we find that scalarization leads to a multitask trade-off front that deviates from the traditional Pareto front when there exists data imbalance in the training corpus. That is, the performance of certain translation directions does not improve with the increase of its weight in the multi-task optimization objective, which poses greater challenge to improve the overall performance of all directions. Based on our observations, we propose the Double Power Law to predict the unique performance trade-off front in MNMT, which is robust across various languages, data adequacy and number of tasks. Finally, we formulate sample ratio selection in MNMT as an optimization problem based on the Double Power Law, which achieves better 
    
[^38]: ACTION++：使用自适应解剖对比度改善半监督医学图像分割

    ACTION++: Improving Semi-supervised Medical Image Segmentation with Adaptive Anatomical Contrast. (arXiv:2304.02689v1 [cs.CV])

    [http://arxiv.org/abs/2304.02689](http://arxiv.org/abs/2304.02689)

    本文提出了一种改进的对比学习框架ACTION++，通过自适应的解剖对比来改善半监督医学图像分割。

    

    医学数据通常表现为长尾分布，存在严重的类别不平衡，这自然导致少数类别（即边界区域或罕见物体）的分类困难。最近的工作通过配备无监督对比标准，在长尾场景中显着改进了半监督医学图像分割。然而，在类别分布也高度不平衡的标记数据部分中，它们的表现仍不清楚。在这项工作中，我们提出了ACTION++，一种改进的具有自适应解剖对比的对比学习框架，用于半监督医学分割。

    Medical data often exhibits long-tail distributions with heavy class imbalance, which naturally leads to difficulty in classifying the minority classes (i.e., boundary regions or rare objects). Recent work has significantly improved semi-supervised medical image segmentation in long-tailed scenarios by equipping them with unsupervised contrastive criteria. However, it remains unclear how well they will perform in the labeled portion of data where class distribution is also highly imbalanced. In this work, we present ACTION++, an improved contrastive learning framework with adaptive anatomical contrast for semi-supervised medical segmentation. Specifically, we propose an adaptive supervised contrastive loss, where we first compute the optimal locations of class centers uniformly distributed on the embedding space (i.e., off-line), and then perform online contrastive matching training by encouraging different class features to adaptively match these distinct and uniformly distributed cla
    
[^39]: 影响深度图像识别模型中学习等变性的因素是什么？

    What Affects Learned Equivariance in Deep Image Recognition Models?. (arXiv:2304.02628v1 [cs.CV])

    [http://arxiv.org/abs/2304.02628](http://arxiv.org/abs/2304.02628)

    本文研究了神经网络中学习到的等变性，提出了一种改进的等变性测量方法，并发现数据增强、减少模型容量和卷积操作可提高神经网络中学习到的等变性。

    

    神经网络中与几何变换相关的等变性可以提高数据效率、参数效率和对域外透视变换的鲁棒性。当等变性没有被设计到神经网络中时，网络仍然可以从数据中学习等变函数。本文提出了一种改进的等变性测量方法来量化这种学习到的等变性，并发现学习到的翻译等变性与在ImageNet上的验证准确性之间存在相关性。因此，我们研究了如何增加神经网络中学习到的等变性，并发现数据增强、减少模型容量以及卷积形式的归纳偏差可以在神经网络中引入更高的学习到的等变性。

    Equivariance w.r.t. geometric transformations in neural networks improves data efficiency, parameter efficiency and robustness to out-of-domain perspective shifts. When equivariance is not designed into a neural network, the network can still learn equivariant functions from the data. We quantify this learned equivariance, by proposing an improved measure for equivariance. We find evidence for a correlation between learned translation equivariance and validation accuracy on ImageNet. We therefore investigate what can increase the learned equivariance in neural networks, and find that data augmentation, reduced model capacity and inductive bias in the form of convolutions induce higher learned equivariance in neural networks.
    
[^40]: GPTEval：使用GPT-4和更好的人类对齐来评估NLG

    GPTEval: NLG Evaluation using GPT-4 with Better Human Alignment. (arXiv:2303.16634v1 [cs.CL])

    [http://arxiv.org/abs/2303.16634](http://arxiv.org/abs/2303.16634)

    本文介绍了GPTEval，一个利用链式思考和形式填充评价NLG生成的质量。实验表明，在文本摘要任务中，GPTEval结合GPT-4取得了0.514的斯皮尔曼相关系数，胜过其他方法。

    

    自然语言生成（NLG）系统生成的文本质量很难进行自动测量。传统的基于参考的度量标准，如BLEU和ROUGE已被证明在需要创造性和多样性的任务中与人类判断的相关性相对较低。最近的研究建议使用大型语言模型（LLMs）作为无参考的NLG评估度量标准，这些模型适用于缺乏人类参考的新任务。然而，这些基于LLM的评估器仍然比中等规模的神经评估器的人类对应度低。在这项工作中，我们提出了GPTEval，一个使用链式思考（CoT）和形式填充范式来评估NLG输出质量的框架。我们针对两个生成任务，文本摘要和对话生成进行了实验。我们展示出，GPTEval结合GPT-4作为骨干模型，在摘要任务上实现了0.514的斯皮尔曼相关系数，胜过其他方法。

    The quality of texts generated by natural language generation (NLG) systems is hard to measure automatically. Conventional reference-based metrics, such as BLEU and ROUGE, have been shown to have relatively low correlation with human judgments, especially for tasks that require creativity and diversity. Recent studies suggest using large language models (LLMs) as reference-free metrics for NLG evaluation, which have the benefit of being applicable to new tasks that lack human references. However, these LLM-based evaluators still have lower human correspondence than medium-size neural evaluators. In this work, we present GPTEval, a framework of using large language models with chain-of-thoughts (CoT) and a form-filling paradigm, to assess the quality of NLG outputs. We experiment with two generation tasks, text summarization and dialogue generation. We show that GPTEval with GPT-4 as the backbone model achieves a Spearman correlation of 0.514 with human on summarization task, outperform
    
[^41]: 多视角三维物体检测的观点等变性

    Viewpoint Equivariance for Multi-View 3D Object Detection. (arXiv:2303.14548v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.14548](http://arxiv.org/abs/2303.14548)

    本文提出了一种利用多视角几何学习视点等变性以提高三维物体检测定位精度的框架VEDet，并通过基于查询的transformer架构和视角条件的查询来实现。

    

    从视觉传感器进行三维物体检测是机器人系统的关键能力。现代方法侧重于从多视角相机输入推理和解码物体边界框。本文利用多视角一致性在三维场景理解和几何学习中的重要作用，介绍了VEDet，一种新颖的三维物体检测框架，通过视点感知和等变性利用三维多视角几何来提高定位精度。VEDet利用基于查询的transformer架构，并通过将图像特征和来自它们的三维透视几何的位置编码相结合来编码三维场景。我们在输出层设计了视角条件的查询，这使得在训练期间生成多个虚拟帧，通过强制多视角一致性来学习视点等变性。在输入层注入的多视角几何作为位置编码，并在损失层中进行正则化，提供了丰富的地理信息。

    3D object detection from visual sensors is a cornerstone capability of robotic systems. State-of-the-art methods focus on reasoning and decoding object bounding boxes from multi-view camera input. In this work we gain intuition from the integral role of multi-view consistency in 3D scene understanding and geometric learning. To this end, we introduce VEDet, a novel 3D object detection framework that exploits 3D multi-view geometry to improve localization through viewpoint awareness and equivariance. VEDet leverages a query-based transformer architecture and encodes the 3D scene by augmenting image features with positional encodings from their 3D perspective geometry. We design view-conditioned queries at the output level, which enables the generation of multiple virtual frames during training to learn viewpoint equivariance by enforcing multi-view consistency. The multi-view geometry injected at the input level as positional encodings and regularized at the loss level provides rich geo
    
[^42]: 学生-教师框架下随机特征模型的在线学习

    Online Learning for the Random Feature Model in the Student-Teacher Framework. (arXiv:2303.14083v1 [cs.LG])

    [http://arxiv.org/abs/2303.14083](http://arxiv.org/abs/2303.14083)

    本研究考虑了一种两层神经网络模型的在线学习，研究发现，当学生的隐藏层大小呈指数增长时，完美泛化是可行的，但对于任何有限的隐藏层大小和输入维度比，学生都无法完美泛化。

    

    深度神经网络是一种广泛应用的预测算法，随着权重数量的增加，其性能通常会提高，导致过度参数化。我们考虑一种两层神经网络，其第一层是冻结的，而最后一层是可训练的，称为随机特征模型。我们在学生-教师框架下研究了过度参数化，通过导出一组学习动态的微分方程。对于任何有限的隐藏层大小和输入维度比，学生都无法完美泛化，并计算非零渐近泛化误差。只有当学生的隐藏层大小呈指数增长时，才有可能实现完美泛化。

    Deep neural networks are widely used prediction algorithms whose performance often improves as the number of weights increases, leading to over-parametrization. We consider a two-layered neural network whose first layer is frozen while the last layer is trainable, known as the random feature model. We study over-parametrization in the context of a student-teacher framework by deriving a set of differential equations for the learning dynamics. For any finite ratio of hidden layer size and input dimension, the student cannot generalize perfectly, and we compute the non-zero asymptotic generalization error. Only when the student's hidden layer size is exponentially larger than the input dimension, an approach to perfect generalization is possible.
    
[^43]: 重新审视影响函数的脆弱性

    Revisiting the Fragility of Influence Functions. (arXiv:2303.12922v1 [cs.LG])

    [http://arxiv.org/abs/2303.12922](http://arxiv.org/abs/2303.12922)

    本文研究了影响函数的脆弱性，并提出在非凸条件下使用深层模型和更复杂数据集来解决这一问题。

    

    最近几年有很多论文致力于解释深度学习模型的预测。然而，很少有方法被提出来验证这些解释的准确性或可信度。最近，影响函数被证明是一种评估深度神经网络在单个样本上的灵敏度的方法。但是，先前的研究表明影响函数易受噪声和数据分布不对称性影响，缺乏鲁棒性。本文旨在研究影响函数的脆弱性，通过探究影响函数背后的机理，从而为增强影响函数的鲁棒性提供新思路。

    In the last few years, many works have tried to explain the predictions of deep learning models. Few methods, however, have been proposed to verify the accuracy or faithfulness of these explanations. Recently, influence functions, which is a method that approximates the effect that leave-one-out training has on the loss function, has been shown to be fragile. The proposed reason for their fragility remains unclear. Although previous work suggests the use of regularization to increase robustness, this does not hold in all cases. In this work, we seek to investigate the experiments performed in the prior work in an effort to understand the underlying mechanisms of influence function fragility. First, we verify influence functions using procedures from the literature under conditions where the convexity assumptions of influence functions are met. Then, we relax these assumptions and study the effects of non-convexity by using deeper models and more complex datasets. Here, we analyze the k
    
[^44]: 从文本到图像生成: 基于稳定扩散模型构建建筑立面设计的方法

    Text Semantics to Image Generation: A method of building facades design base on Stable Diffusion model. (arXiv:2303.12755v1 [cs.CV])

    [http://arxiv.org/abs/2303.12755](http://arxiv.org/abs/2303.12755)

    本文提出了一种多网络结合的文本到建筑立面图像生成方法，通过 LoRA 训练方法微调稳定扩散模型和 ControlNet 模型的添加，大大提高了文本到建筑立面图像生成的可控性和稳定性，为后续建筑图像生成研究提供了基础。

    

    稳定扩散模型已广泛应用于建筑图像生成的研究中，但目前仍有提高生成图像内容可控性的机会。本文提出了一种多网络结合的文本到建筑立面图像生成方法。我们首先通过 LoRA（低秩自适应）方法在 CMP Fa-cades 数据集上对稳定扩散模型进行了微调，然后应用 ControlNet 模型进一步控制输出。最后，我们对不同建筑风格文本内容和控制策略下的立面生成结果进行了对比。结果表明，LoRA 训练方法显着降低了微调稳定扩散大模型的可能性，而 ControlNet 模型的添加增加了文本到建筑立面图像的可控性。这为后续关于建筑图像生成的研究提供了基础。

    Stable Diffusion model has been extensively employed in the study of archi-tectural image generation, but there is still an opportunity to enhance in terms of the controllability of the generated image content. A multi-network combined text-to-building facade image generating method is proposed in this work. We first fine-tuned the Stable Diffusion model on the CMP Fa-cades dataset using the LoRA (Low-Rank Adaptation) approach, then we ap-ply the ControlNet model to further control the output. Finally, we contrast-ed the facade generating outcomes under various architectural style text con-tents and control strategies. The results demonstrate that the LoRA training approach significantly decreases the possibility of fine-tuning the Stable Dif-fusion large model, and the addition of the ControlNet model increases the controllability of the creation of text to building facade images. This pro-vides a foundation for subsequent studies on the generation of architectural images.
    
[^45]: 多智能体强化学习用于大规模格网交通网络区域信号控制

    Multi-agent Reinforcement Learning for Regional Signal control in Large-scale Grid Traffic network. (arXiv:2303.11899v1 [cs.AI])

    [http://arxiv.org/abs/2303.11899](http://arxiv.org/abs/2303.11899)

    本文提出了一种新的训练框架 RegionLight，基于交叉口之间的邻接关系将智能体分配到每个区域中。同时，研究人员扩展了BDQ方法为DBDQ，以限制联合动作空间大小的增长并缓解智能体训练问题。

    

    多智能体强化学习（MARL）的自适应交通信号控制是当前非常流行的研究领域。大多数现有方法中，一个智能体控制单个路口，这些方法侧重于路口之间的协作。然而，MARL的非稳态性质随着交通网络规模的增长，仍然限制着上述方法的性能。一种妥协的策略是将一名智能体分配到一组路口中，以减少智能体数量。这种策略存在两个挑战，一个是如何将交通网络划分成小区域，另一个是如何搜索区域内的最优联合动作。本文提出了一种新的训练框架RegionLight，其中我们的区域划分规则基于交叉口之间的邻接关系，并扩展了Branching Dueling Q-Network(BDQ)。该方法将BDQ进一步优化为Dynamic Branching Dueling Q-Network(DBDQ)，以限制联合动作空间大小的增长并缓解智能体训练问题。

    Adaptive traffic signal control with Multi-agent Reinforcement Learning(MARL) is a very popular topic nowadays. In most existing novel methods, one agent controls single intersections and these methods focus on the cooperation between intersections. However, the non-stationary property of MARL still limits the performance of the above methods as the size of traffic networks grows. One compromised strategy is to assign one agent with a region of intersections to reduce the number of agents. There are two challenges in this strategy, one is how to partition a traffic network into small regions and the other is how to search for the optimal joint actions for a region of intersections. In this paper, we propose a novel training framework RegionLight where our region partition rule is based on the adjacency between the intersection and extended Branching Dueling Q-Network(BDQ) to Dynamic Branching Dueling Q-Network(DBDQ) to bound the growth of the size of joint action space and alleviate th
    
[^46]: 从递推视角重新审视LQR控制

    Revisiting LQR Control from the Perspective of Receding-Horizon Policy Gradient. (arXiv:2302.13144v2 [math.OC] UPDATED)

    [http://arxiv.org/abs/2302.13144](http://arxiv.org/abs/2302.13144)

    本文从递推视角重新审视了LQR控制问题，并应用递推-视角策略梯度（RHPG）模型提供了一种采样复杂度分析，通过无需任何先验信息进行优化求解，并展示了RHPG在线性控制和估计中的普适性。

    

    本文从递推视角重新审视了离散时间线性二次调节器（LQR）问题。结合递推-视角策略梯度（RHPG）模型无需任何先验信息进行优化求解，提供了一种采样复杂度分析，能够学习到在ε-范数意义下接近LQR最优解的优化控制策略。在最近将RHPG应用于学习卡尔曼滤波中进行拓展分析之后，我们展示了RHPG在线性控制和估计中的普适性。

    We revisit in this paper the discrete-time linear quadratic regulator (LQR) problem from the perspective of receding-horizon policy gradient (RHPG), a newly developed model-free learning framework for control applications. We provide a fine-grained sample complexity analysis for RHPG to learn a control policy that is both stabilizing and $\epsilon$-close to the optimal LQR solution, and our algorithm does not require knowing a stabilizing control policy for initialization. Combined with the recent application of RHPG in learning the Kalman filter, we demonstrate the general applicability of RHPG in linear control and estimation with streamlined analyses.
    
[^47]: 利用预训练的边缘Transformer在在线游戏中进行好友排名

    Friend Ranking in Online Games via Pre-training Edge Transformers. (arXiv:2302.10043v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.10043](http://arxiv.org/abs/2302.10043)

    本文提出了一种使用边缘Transformer和预训练的链接预测方法，用于在在线游戏中进行好友排名，达到了最先进的结果。

    

    在线游戏中，好友回忆是提高每日活跃用户数量的重要途径。本文将好友回忆问题视为链接预测问题，并探讨了可以使用（活跃的和失落的）玩家特征以及历史事件的几种链接预测方法。此外，我们提出了一种新颖的边缘Transformer模型，并通过掩码自动编码器进行预训练。我们的方法在三款腾讯游戏的离线实验和在线A/B测试中取得了最先进的结果。

    Friend recall is an important way to improve Daily Active Users (DAU) in online games. The problem is to generate a proper lost friend ranking list essentially. Traditional friend recall methods focus on rules like friend intimacy or training a classifier for predicting lost players' return probability, but ignore feature information of (active) players and historical friend recall events. In this work, we treat friend recall as a link prediction problem and explore several link prediction methods which can use features of both active and lost players, as well as historical events. Furthermore, we propose a novel Edge Transformer model and pre-train the model via masked auto-encoders. Our method achieves state-of-the-art results in the offline experiments and online A/B Tests of three Tencent games.
    
[^48]: SAT需要彻底搜索

    SAT Requires Exhaustive Search. (arXiv:2302.09512v4 [cs.CC] CROSS LISTED)

    [http://arxiv.org/abs/2302.09512](http://arxiv.org/abs/2302.09512)

    本文证明了对于一些具有大域和长子句的极难例子，要求进行彻底搜索才能解决，这意味着P $\neq$ NP。

    

    本文通过构造具有大域和长子句的CSP和SAT的极难例子，证明这些例子无法在不进行彻底搜索的情况下解决，这意味着一个较弱的结论P $\neq$ NP。本文采用的是一种证明不可能性结果的建设性方法，与目前计算复杂性理论中使用的方法非常不同，但与Kurt G\"{o}del在证明他著名的逻辑不可能性结果时使用的方法相似。正如G\"{o}del的结果表明，在数学中证明形式上的不可证明性是可行的一样，本文的结果表明，在数学中证明计算上的难度不是很难的。具体来说，对许多问题，如3-SAT，证明下界可能具有挑战性，因为这些问题有各种有效的策略可用于避免进行彻底搜索。然而，在极难的例子中，彻底搜索可能是唯一可行的选择，证明其必要性变得更加重要。

    In this paper, by constructing extremely hard examples of CSP (with large domains) and SAT (with long clauses), we prove that such examples cannot be solved without exhaustive search, which implies a weaker conclusion P $\neq$ NP. This constructive approach for proving impossibility results is very different (and missing) from those currently used in computational complexity theory, but is similar to that used by Kurt G\"{o}del in proving his famous logical impossibility results. Just as shown by G\"{o}del's results that proving formal unprovability is feasible in mathematics, the results of this paper show that proving computational hardness is not hard in mathematics. Specifically, proving lower bounds for many problems, such as 3-SAT, can be challenging because these problems have various effective strategies available for avoiding exhaustive search. However, in cases of extremely hard examples, exhaustive search may be the only viable option, and proving its necessity becomes more 
    
[^49]: 复杂问答和语言模型混合架构综述

    Complex QA and language models hybrid architectures, Survey. (arXiv:2302.09051v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.09051](http://arxiv.org/abs/2302.09051)

    本文综述了语言模型架构和策略的最新进展，并重点关注混合技术在复杂问题回答中的应用，讨论了该领域的挑战和未来研究方向。

    

    本文回顾了语言模型架构和策略的最新进展，重点关注混合技术在复杂问题回答中的应用。大型语言模型能够在标准问题上利用公共数据，但在解决更具体的复杂问题时（如在不同文化中个人自由概念的变化如何？什么是为减少气候变化而实现的最佳发电方法组合？），需要特定的架构、知识、技能、方法、敏感数据保护、可解释性、人类审批和多功能反馈。最近的项目如ChatGPT和GALACTICA允许非专业人员了解LLM在复杂QA中的巨大潜力以及同等强大的局限性。在本文中，我们首先审查所需的技能和评估技术。然后，我们综述了现有的混合架构，将LLM与基于规则的方法、信息检索、知识图谱和其他AI/ML技术相结合。最后，我们指出这些CQA系统的挑战，并提出未来研究的可能方向。

    This paper reviews the state-of-the-art of language models architectures and strategies for "complex" question-answering (QA, CQA, CPS) with a focus on hybridization. Large Language Models (LLM) are good at leveraging public data on standard problems but once you want to tackle more specific complex questions or problems (e.g. How does the concept of personal freedom vary between different cultures ? What is the best mix of power generation methods to reduce climate change ?) you may need specific architecture, knowledge, skills, methods, sensitive data protection, explainability, human approval and versatile feedback... Recent projects like ChatGPT and GALACTICA have allowed non-specialists to grasp the great potential as well as the equally strong limitations of LLM in complex QA. In this paper, we start by reviewing required skills and evaluation techniques. We integrate findings from the robust community edited research papers BIG, BLOOM and HELM which open source, benchmark and an
    
[^50]: 应用于道路驾驶行为的时间观测基因因果发现技术的评估

    Evaluating Temporal Observation-Based Causal Discovery Techniques Applied to Road Driver Behaviour. (arXiv:2302.00064v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.00064](http://arxiv.org/abs/2302.00064)

    本文对10种当代观测性时间因果发现技术在自主驾驶领域进行了基准测试，突出了需要改进的地方，以促进这些方法的应用。

    

    自主机器人需要推理其环境中动态实体的行为。描述这些关系的模型通常是通过应用基因因果发现技术来完成的。然而，目前的观测性因果发现技术往往难以应对自主体领域中在线使用期间通常出现的因果稀疏和非稳态等条件。同时，由于领域限制，干预技术并不总是可行的。为了更好地探索观察技术面临的问题并促进进一步讨论这些问题，我们在自主驾驶领域对10种当代观测性时间因果发现方法进行了基准测试。通过对来自真实世界数据集以及生成的场景进行评估，我们突出了需要改进的地方，以促进这些方法的应用。

    Autonomous robots are required to reason about the behaviour of dynamic agents in their environment. The creation of models to describe these relationships is typically accomplished through the application of causal discovery techniques. However, as it stands observational causal discovery techniques struggle to adequately cope with conditions such as causal sparsity and non-stationarity typically seen during online usage in autonomous agent domains. Meanwhile, interventional techniques are not always feasible due to domain restrictions. In order to better explore the issues facing observational techniques and promote further discussion of these topics we carry out a benchmark across 10 contemporary observational temporal causal discovery methods in the domain of autonomous driving. By evaluating these methods upon causal scenes drawn from real world datasets in addition to those generated synthetically we highlight where improvements need to be made in order to facilitate the applicat
    
[^51]: 无模态偏见的隐式神经表示变分压缩算法

    Modality-Agnostic Variational Compression of Implicit Neural Representations. (arXiv:2301.09479v3 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2301.09479](http://arxiv.org/abs/2301.09479)

    提出了一种无模态偏见的隐式神经表示变分压缩算法，能够在不同的数据模态上表现出卓越的压缩性能和效果。

    

    我们提出了一种基于数据的函数视图，并用隐式神经表示（INR）参数化的无模态神经压缩算法。我们通过软门控机制将非线性映射到紧凑的潜在表示中，从而弥合了潜在编码和稀疏性之间的差距。这允许每个数据项通过子网络选择来定制共享的INR网络的专业化。在获取这种潜在表示的数据集后，我们在无模态空间中直接优化速率/失真的折衷方案，使用神经压缩。隐式神经表示的变分压缩（VC-INR）在具有相同表示容量的量化之前显示出改进的性能，同时优于其他INR技术所使用的先前量化方案。我们的实验结果显示，使用相同的算法而不需要任何特定于模态的归纳偏差，可以在各种不同的模态上取得卓越的结果。我们展示了在图像、气候数据、文本和音频数据上的结果。

    We introduce a modality-agnostic neural compression algorithm based on a functional view of data and parameterised as an Implicit Neural Representation (INR). Bridging the gap between latent coding and sparsity, we obtain compact latent representations non-linearly mapped to a soft gating mechanism. This allows the specialisation of a shared INR network to each data item through subnetwork selection. After obtaining a dataset of such latent representations, we directly optimise the rate/distortion trade-off in a modality-agnostic space using neural compression. Variational Compression of Implicit Neural Representations (VC-INR) shows improved performance given the same representational capacity pre quantisation while also outperforming previous quantisation schemes used for other INR techniques. Our experiments demonstrate strong results over a large set of diverse modalities using the same algorithm without any modality-specific inductive biases. We show results on images, climate dat
    
[^52]: 神经形状编译器：在文本、点云和程序之间进行转换的统一框架。

    Neural Shape Compiler: A Unified Framework for Transforming between Text, Point Cloud, and Program. (arXiv:2212.12952v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.12952](http://arxiv.org/abs/2212.12952)

    本篇论文提出了一个称为神经形状编译器的框架，用于将三维形状的不同抽象类型之间进行转换。该框架通过提出的形状代码转换器将三维形状转换为统一的离散形状代码，并在各种数据集上展示出了较强的转换能力。

    

    三维形状有着互补的抽象级别，从低级的几何形状到基于部件的层次结构再到语言，传递了不同级别的信息。本文提出了一个统一的框架，用于在形状抽象之间进行翻译：$\textit{文本}$ $\Longleftrightarrow$ $\textit{点云}$ $\Longleftrightarrow$ $\textit{程序}$。我们提出了$\textbf{神经形状编译器}$来将抽象转换建模为一种条件生成过程。它将三种抽象类型的三维形状转换为统一的离散形状代码，通过所提出的$\textit{形状代码转换器}$将每个形状代码转换为其他抽象类型的代码，并将其解码以输出目标形状抽象。通过所提出的$\textit{Point}$VQVAE，以类不确定方式获得点云代码。在Text2Shape、ShapeGlot、ABO、Genre和Program Synthetic数据集上，神经形状编译器在$\textit{文本}$ $\Longrightarrow$ $\textit{点云}$、$\textit{点云}$ $\Longrightarrow$ $\textit{程序}$和$\textit{程序}$ $\Longrightarrow$ $\textit{点云}$转换方面表现出优势。

    3D shapes have complementary abstractions from low-level geometry to part-based hierarchies to languages, which convey different levels of information. This paper presents a unified framework to translate between pairs of shape abstractions: $\textit{Text}$ $\Longleftrightarrow$ $\textit{Point Cloud}$ $\Longleftrightarrow$ $\textit{Program}$. We propose $\textbf{Neural Shape Compiler}$ to model the abstraction transformation as a conditional generation process. It converts 3D shapes of three abstract types into unified discrete shape code, transforms each shape code into code of other abstract types through the proposed $\textit{ShapeCode Transformer}$, and decodes them to output the target shape abstraction. Point Cloud code is obtained in a class-agnostic way by the proposed $\textit{Point}$VQVAE. On Text2Shape, ShapeGlot, ABO, Genre, and Program Synthetic datasets, Neural Shape Compiler shows strengths in $\textit{Text}$ $\Longrightarrow$ $\textit{Point Cloud}$, $\textit{Point Cloud
    
[^53]: 多模态和可解释的互联网迷因分类

    Multimodal and Explainable Internet Meme Classification. (arXiv:2212.05612v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.05612](http://arxiv.org/abs/2212.05612)

    本文提出了一种多模态和可解释的互联网迷因分类方法，旨在解决现有方法中忽略迷因语义和创建上下文导致公正内容管理困难的问题。作者采用示例和基于原型的推理并结合文本和视觉SOTA模型进行训练，成功在两个任务中检测了有害的迷因。

    

    在当前的环境中，网络平台已经被有效地武器化，被用于各种地缘政治事件和社会问题中，互联网迷因使得大规模的公正内容管理更加困难。现有的迷因分类和跟踪工作主要采用黑盒方法，没有明确考虑迷因的语义或其创建的上下文。在本文中，我们追求一种模块化和可解释的互联网迷因理解架构。我们设计并实现了多模态分类方法，对训练案例进行示例和基于原型的推理，并利用文本和视觉SOTA模型来表示各个案例。 我们研究了我们的模块化和可解释模型在检测两个现有任务中有害迷因的相关性：仇恨言论检测和厌女症分类。我们比较了基于示例和基于原型的方法以及文本，视觉和多模态模型之间的性能差异在不同的任务上。

    In the current context where online platforms have been effectively weaponized in a variety of geo-political events and social issues, Internet memes make fair content moderation at scale even more difficult. Existing work on meme classification and tracking has focused on black-box methods that do not explicitly consider the semantics of the memes or the context of their creation. In this paper, we pursue a modular and explainable architecture for Internet meme understanding. We design and implement multimodal classification methods that perform example- and prototype-based reasoning over training cases, while leveraging both textual and visual SOTA models to represent the individual cases. We study the relevance of our modular and explainable models in detecting harmful memes on two existing tasks: Hate Speech Detection and Misogyny Classification. We compare the performance between example- and prototype-based methods, and between text, vision, and multimodal models, across differen
    
[^54]: SPIDR：基于SDF的神经点场网络实现光照和变形

    SPIDR: SDF-based Neural Point Fields for Illumination and Deformation. (arXiv:2210.08398v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.08398](http://arxiv.org/abs/2210.08398)

    本文提出SPIDR，一种新的混合神经点场网络，并结合点云和神经隐式表示，可以实现更高质量的对象表面重建和光照估计。

    

    最近，神经辐射场（NeRF）已成为3D重建和新视角合成的有前途的方法。然而，基于NeRF的方法隐式地编码了形状、反射和光照，这使得用户难以显式地操作这些属性在渲染图像。现有的方法只能在场景编辑和几何变形方面进行有限的编辑。此外，没有现有的工作在对象变形后能够实现准确的场景照明。在这项工作中，我们介绍了SPIDR，一种新的混合神经场表示。SPIDR结合了点云和神经隐式表示，以实现更高质量的对象表面重建和光照估计。

    Neural radiance fields (NeRFs) have recently emerged as a promising approach for 3D reconstruction and novel view synthesis. However, NeRF-based methods encode shape, reflectance, and illumination implicitly and this makes it challenging for users to manipulate these properties in the rendered images explicitly. Existing approaches only enable limited editing of the scene and deformation of the geometry. Furthermore, no existing work enables accurate scene illumination after object deformation. In this work, we introduce SPIDR, a new hybrid neural SDF representation. SPIDR combines point cloud and neural implicit representations to enable the reconstruction of higher quality object surfaces for geometry deformation and lighting estimation. meshes and surfaces for object deformation and lighting estimation. To more accurately capture environment illumination for scene relighting, we propose a novel neural implicit model to learn environment light. To enable more accurate illumination up
    
[^55]: SC-Ques：为英语学习者设计的句子填空问题数据集

    SC-Ques: A Sentence Completion Question Dataset for English as a Second Language Learners. (arXiv:2206.12036v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.12036](http://arxiv.org/abs/2206.12036)

    该论文介绍了一个针对英语学习者设计的大规模句子填空问题数据集\textsc{SC-Ques}，并且已经构建了一个综合基准来自动解决 SC 问题。

    

    句子填空（SC）问题提供了一个带有一个或多个空白需要填写的句子，并提供三至五个可能的单词或短语作为选项。 SC问题广泛用于学习英语作为第二语言（ESL）的学生。本文介绍了一个大规模的SC数据集\textsc{SC-Ques}，由来自真实标准英语考试的289,148个ESL SC问题组成。此外，我们通过在提出的\textsc{SC-Ques}数据集上训练大规模预训练语言模型，构建了一个自动解决SC问题的综合基准。我们对基线模型的性能、限制和权衡进行了详细的分析。数据和代码可用于研究目的：\url{https://github.com/ai4ed/SC-Ques}。

    Sentence completion (SC) questions present a sentence with one or more blanks that need to be filled in, three to five possible words or phrases as options. SC questions are widely used for students learning English as a Second Language (ESL). In this paper, we present a large-scale SC dataset, \textsc{SC-Ques}, which is made up of 289,148 ESL SC questions from real-world standardized English examinations. Furthermore, we build a comprehensive benchmark of automatically solving the SC questions by training the large-scale pre-trained language models on the proposed \textsc{SC-Ques} dataset. We conduct detailed analysis of the baseline models performance, limitations and trade-offs. The data and our code are available for research purposes from: \url{https://github.com/ai4ed/SC-Ques}.
    
[^56]: PIDNet: 一种受 PID 控制器启发的实时语义分割网络

    PIDNet: A Real-time Semantic Segmentation Network Inspired by PID Controllers. (arXiv:2206.02066v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.02066](http://arxiv.org/abs/2206.02066)

    本文提出了一种新的三分支语义分割神经网络 PIDNet，采用边界注意力引导详细和上下文分支的融合，能够解决现有两分支模型中因详细特征被周围背景信息淹没导致的分割准确性问题，并在多个数据集上实现了最佳性能。

    

    两个分支的网络结构已经在实时语义分割任务中展现出其高效性和有效性。然而，高分辨率细节和低频率背景信息的直接融合存在细节特征容易被周围背景信息淹没的缺点，这种超调现象限制了现有两个分支模型的分割准确性改善。本文将卷积神经网络 (CNN) 和 比例积分微分 (PID) 控制器建立起联系，并揭示出两个分支网络相当于一个比例积分 (PI) 控制器，其本质上也存在类似的超调问题。为了缓解这个问题，我们提出了一种新颖的三分支网络结构：PIDNet，其中包括三个分支，分别解析详细、上下文和边界信息，采用边界注意力引导详细和上下文分支的融合。我们的 PIDNet 系列在各种数据集上实现了最佳的实时语义分割表现，包括 Cityscapes、CamVid 和 COCO-Stuff。

    Two-branch network architecture has shown its efficiency and effectiveness in real-time semantic segmentation tasks. However, direct fusion of high-resolution details and low-frequency context has the drawback of detailed features being easily overwhelmed by surrounding contextual information. This overshoot phenomenon limits the improvement of the segmentation accuracy of existing two-branch models. In this paper, we make a connection between Convolutional Neural Networks (CNN) and Proportional-Integral-Derivative (PID) controllers and reveal that a two-branch network is equivalent to a Proportional-Integral (PI) controller, which inherently suffers from similar overshoot issues. To alleviate this problem, we propose a novel three-branch network architecture: PIDNet, which contains three branches to parse detailed, context and boundary information, respectively, and employs boundary attention to guide the fusion of detailed and context branches. Our family of PIDNets achieve the best 
    
[^57]: 动态多模态融合

    Dynamic Multimodal Fusion. (arXiv:2204.00102v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2204.00102](http://arxiv.org/abs/2204.00102)

    本论文提出了一种动态多模态融合的新方法，可以自适应地融合多模态数据并根据计算需求生成数据相关的前向路径，在提高计算效率的同时兼顾准确度和性能。

    

    深度多模态学习近年来取得了长足的进步。然而，当前的融合方法在本质上是静态的，即它们使用相同的计算处理和融合多模态输入，而不考虑不同多模态数据的不同计算需求。在这项工作中，我们提出了动态多模态融合（DynMM），一种新的方法，它自适应地融合多模态数据并在推理期间生成数据相关的前向路径。为此，我们提出了一个门控函数，根据多模态特征提供模态级或融合级决策，以及一个资源感知的损失函数，以鼓励计算效率。对各种多模态任务的结果表明了我们方法的有效性和广泛适用性。例如，DynMM可以在只有微不足道的准确度损失的情况下将计算成本降低46.5%（CMU-MOSEI情感分析），并在计算中节省超过21%的开销以提高分段性能（NYU Depth V2语义分割）。

    Deep multimodal learning has achieved great progress in recent years. However, current fusion approaches are static in nature, i.e., they process and fuse multimodal inputs with identical computation, without accounting for diverse computational demands of different multimodal data. In this work, we propose dynamic multimodal fusion (DynMM), a new approach that adaptively fuses multimodal data and generates data-dependent forward paths during inference. To this end, we propose a gating function to provide modality-level or fusion-level decisions on-the-fly based on multimodal features and a resource-aware loss function that encourages computational efficiency. Results on various multimodal tasks demonstrate the efficiency and wide applicability of our approach. For instance, DynMM can reduce the computation costs by 46.5% with only a negligible accuracy loss (CMU-MOSEI sentiment analysis) and improve segmentation performance with over 21% savings in computation (NYU Depth V2 semantic s
    

