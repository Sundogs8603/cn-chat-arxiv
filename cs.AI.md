# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Coaching a Teachable Student.](http://arxiv.org/abs/2306.10014) | 本研究提出了一种新颖的知识蒸馏框架，通过设计一个学生模型并支持其传感器运动学习任务，实现了学生与教师之间的优化差距尽量小，进而提高了学生驾驶行为的学习质量。 |
| [^2] | [MagicBrush: A Manually Annotated Dataset for Instruction-Guided Image Editing.](http://arxiv.org/abs/2306.10012) | MagicBrush是第一个大规模的手动标注的数据集，用于指导真实图像的编辑。它包括超过10K个手动标注的三元组，支持大规模的文本指导图像编辑模型训练。在此数据集上微调InstructPix2Pix可以根据人类评估提供更好的图像。 |
| [^3] | [Group Orthogonalization Regularization For Vision Models Adaptation and Robustness.](http://arxiv.org/abs/2306.10001) | 该论文提出了一种新的正则化技术，称为组正交正则化，能够提高视觉模型自适应和鲁棒性。实验结果表明，此种正则化可以应用于不同的深度学习模型，并且能够有效地优化模型性能。 |
| [^4] | [Fairness in Preference-based Reinforcement Learning.](http://arxiv.org/abs/2306.09995) | 该论文提出了一种名为FPbRL的新的公平偏好强化学习方法，旨在通过广义Gini福利函数最大化策略学习来实现多目标优化并处理每个目标的公平性。 |
| [^5] | [Ensemble Framework for Cardiovascular Disease Prediction.](http://arxiv.org/abs/2306.09989) | 本文介绍了一个使用机器学习方法预测心血管疾病的集成框架，采用了IEEE Data Port 数据集，旨在早期准确诊断心脏问题，提高生命几率。 |
| [^6] | [Evaluating Superhuman Models with Consistency Checks.](http://arxiv.org/abs/2306.09983) | 本文提出了一个用一致性检查评估超人模型的框架，可以发现决策制定中的逻辑不一致性，即使对于超人模型的决策正确性可能是不可能评估的情况。 |
| [^7] | [Creating Multi-Level Skill Hierarchies in Reinforcement Learning.](http://arxiv.org/abs/2306.09980) | 本文提出了一种基于代理人与环境交互的图形结构的答案，使用分层图划分产生具有多个抽象层次的技能层次结构。技能能将代理人移动到状态空间中互相连接紧密但相互连接较弱的区域，有效提高了强化学习的效率。 |
| [^8] | [Evaluation of Speech Representations for MOS prediction.](http://arxiv.org/abs/2306.09979) | 本文评估了语音表征的特征提取模型，并提出了一种模型通过比较受监督和自监督学习模型的嵌入与说话人验证模型的嵌入来预测MOS，表明Whisper模型是最为合适的。 |
| [^9] | [HePCo: Data-Free Heterogeneous Prompt Consolidation for Continual Federated Learning.](http://arxiv.org/abs/2306.09970) | 本文提出了一种名为HePCo的轻量级提示合并算法，解决了在连续联邦学习中的数据异构和遗忘问题，并在不共享或存储任何数据的情况下最小化了通信开销。在真实数据集和合成数据集上实现了最先进的结果，并且保持了数据隐私。 |
| [^10] | [Data-Driven Model Discrimination of Switched Nonlinear Systems with Temporal Logic Inference.](http://arxiv.org/abs/2306.09966) | 本文提出了针对未知非线性切换系统的数据驱动模型区分问题的解决方案，包括数据驱动方法来过估计未知动态和推断未知规范，以及优化算法来分析学习/推断模型-任务对的可区分性，并提出缩小推断规范大小的方法以提高区分的效率。 |
| [^11] | [Vehicle Occurrence-based Parking Space Detection.](http://arxiv.org/abs/2306.09940) | 本文提出了一种利用车辆出现信息生成热力图的自动检测停车位方法，并在PKLot和CNRPark-EXT数据集上取得了较高的准确率。 |
| [^12] | [Trained Transformers Learn Linear Models In-Context.](http://arxiv.org/abs/2306.09927) | 本文研究了Transformer在具有单层线性自注意层的线性回归任务上通过梯度流进行训练的ICL机制，揭示了梯度流具有找到目标函数全局最小值的能力。 |
| [^13] | [Learning to Summarize and Answer Questions about a Virtual Robot's Past Actions.](http://arxiv.org/abs/2306.09922) | 本论文介绍了一种学习总结和回答机器人动作历史的方法，能够通过一种语言模型同时完成总结和回答任务，并提供了自动生成问题和答案的方法来进行训练。此方法能够实现从问题回答中学习对象表示的零-shot转移。 |
| [^14] | [No Strong Feelings One Way or Another: Re-operationalizing Neutrality in Natural Language Inference.](http://arxiv.org/abs/2306.09918) | 本文讨论了自然语言推理(NLI)中标签操作存在的缺点，提出了NLI需要更精细的评价体系的观点，并比较了处理注释者一致性的方法。 |
| [^15] | [Demystifying GPT Self-Repair for Code Generation.](http://arxiv.org/abs/2306.09896) | 本文分析了 GPT-3.5 和 GPT-4 在 APPS 数据集上执行自我修复的能力，发现自我修复在 GPT 模型中的有效性严重取决于任务的质量和复杂性，自我修复在较短和较简单的任务中效果更好，仅在某些代码部分上应用自我修复可以非常有效，本文提出的引导修复方法在 APPS 数据集上获得性能提升。 |
| [^16] | [Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX.](http://arxiv.org/abs/2306.09884) | Jumanji是JAX中一套可扩展的强化学习系统，提供了一系列高度可定制的环境，具有快速、灵活、可扩展和模块化特点，利用硬件加速器赋能更有能力的代理人。 |
| [^17] | [Generalizable One-shot Rope Manipulation with Parameter-Aware Policy.](http://arxiv.org/abs/2306.09872) | GenORM通过增加可变形绳索参数和使用各种可变形绳索的模拟训练操作策略，实现利用一次真实演示处理不同可形变绳索，从而节省演示时间和提高适用性。 |
| [^18] | [Energy-Based Cross Attention for Bayesian Context Update in Text-to-Image Diffusion Models.](http://arxiv.org/abs/2306.09869) | 本论文提出了能量交叉注意力的EBM框架，通过更新和转移上下文向量，隐式最小化能量函数的嵌套层次，优化文本到图像扩散模型的语义对齐问题，实现零样本组合生成。 |
| [^19] | [DoubleAdapt: A Meta-learning Approach to Incremental Learning for Stock Trend Forecasting.](http://arxiv.org/abs/2306.09862) | DoubleAdapt是一个增量学习的方法，用于股票趋势预测。它利用元学习技术自动学习如何将股票数据适应到本地平稳分布空间中，从而有效地适应数据和模型，减轻分布漂移的影响。 |
| [^20] | [Are Large Language Models Really Good Logical Reasoners? A Comprehensive Evaluation From Deductive, Inductive and Abductive Views.](http://arxiv.org/abs/2306.09841) | 本文评估了大型语言模型的逻辑推理能力，选择了15个典型数据集，考虑了演绎、归纳、阿布达斯和混合推理形式，并选择了三个代表性的LLMs进行零样本、一次和三次的设置下评估。提出精细级别的评估方法。 |
| [^21] | [Subset Selection Based On Multiple Rankings in the Presence of Bias: Effectiveness of Fairness Constraints for Multiwinner Voting Score Functions.](http://arxiv.org/abs/2306.09835) | 本文研究了存在偏差时的子集选择问题，提出了在兼顾公平的前提下，使所选的子集满足群体公平性约束来提高选择质量，不同的多赢家评分函数对于公平性的依赖性可能不同。 |
| [^22] | [Process Knowledge-infused Learning for Clinician-friendly Explanations.](http://arxiv.org/abs/2306.09824) | 本论文介绍了一种名为PK-iL的新学习范式，可以在语言模型输出上添加临床流程知识结构，从而使医生能够理解和解释模型的输出，从而为心理卫生护理和预防策略提供支持和帮助。 |
| [^23] | [Inspire creativity with ORIBA: Transform Artists' Original Characters into Chatbots through Large Language Model.](http://arxiv.org/abs/2306.09776) | 该论文介绍了一种名为ORIBA的聊天机器人，可定制的AI代理，能够与插画家的原创角色进行交互，以加强创意领域中的人机交互。 |
| [^24] | [Politeness Stereotypes and Attack Vectors: Gender Stereotypes in Japanese and Korean Language Models.](http://arxiv.org/abs/2306.09752) | 中文总结该论文主要研究了日语和韩语语言模型中与礼貌水平相关的语法性别偏见，发现礼貌水平是网络欺凌检测模型中的攻击向量。 |
| [^25] | [Fedstellar: A Platform for Decentralized Federated Learning.](http://arxiv.org/abs/2306.09750) | Fedstellar是一个联邦学习平台，支持物理或虚拟设备的去中心化、半去中心化和中心化的方式训练模型，旨在解决现有平台在处理异构联盟网络拓扑等问题时的挑战。 |
| [^26] | [Temporal Difference Learning with Experience Replay.](http://arxiv.org/abs/2306.09746) | 本文提出具有经验回放的TD学习，在马尔科夫观测模型下，通过对噪声项的分解，提供了有限时间误差界限，可以通过调整回放缓冲区和小批量的大小来控制误差。 |
| [^27] | [Pushing the Limits of ChatGPT on NLP Tasks.](http://arxiv.org/abs/2306.09719) | 本研究提出了一系列通用模块以解决 ChatGPT 在自然语言处理任务中的弱点，包括利用多个提示符来适应更多演示、使用精细调整模型以获得更好的演示检索、转换任务为更适合生成性质的格式以及采用针对 NLP 任务设计的推理策略。 |
| [^28] | [Label-noise-tolerant medical image classification via self-attention and self-supervised learning.](http://arxiv.org/abs/2306.09718) | 本文提出结合对比学习和自我注意力混合策略的抗噪声训练方法，以缓解医学图像分类中噪声标签的影响，实验证明该方法显著提高了DNN对标签噪声的鲁棒性和准确性。 |
| [^29] | [Semi-Offline Reinforcement Learning for Optimized Text Generation.](http://arxiv.org/abs/2306.09712) | 该研究提出了一种半离线强化学习范式，该范式平衡了探索能力和培训成本，提供了一个理论基础来比较不同的强化学习设置，并在优化成本、渐近误差和过度拟合误差界方面实现了最优的RL设置。实验结果表明，该方法高效且性能优异。 |
| [^30] | [Multi-Classification using One-versus-One Deep Learning Strategy with Joint Probability Estimates.](http://arxiv.org/abs/2306.09668) | 本文提出了一种基于联合概率估计的一对一深度学习多分类模型，该模型通过特定的距离度量来校准二分类器的概率输出，并通过联合概率的距离最小化来获得对主体的类别概率估计。实验结果表明，该模型在多个应用中都具有更高的分类精度。 |
| [^31] | [Cooperative Multi-Objective Reinforcement Learning for Traffic Signal Control and Carbon Emission Reduction.](http://arxiv.org/abs/2306.09662) | 本文提出了一种合作的多目标架构，称为MOMA-DDPG，用于交通信号控制和碳减排问题。该方法涉及两种类型的智能体：一个专注于优化每个路口的本地交通，而另一个旨在优化全局交通吞吐量。结果显示，该方法优于现有最先进的方法，并解决了等待时间和碳排放量两个问题。 |
| [^32] | [BISCUIT: Causal Representation Learning from Binary Interactions.](http://arxiv.org/abs/2306.09643) | 本文提出了一种名为BISCUIT的方法，可以在许多常见的设置中确定因果变量，并在机器人启发的数据集上进行了测试，表现良好。 |
| [^33] | [Clickbait Detection via Large Language Models.](http://arxiv.org/abs/2306.09597) | 本文研究了大型语言模型在点击诱骗检测上的性能，结果表明LLM无法取得最佳结果且不能仅通过标题实现满意的检测。 |
| [^34] | [Structured Cooperative Learning with Graphical Model Priors.](http://arxiv.org/abs/2306.09595) | 本文提出了结构化协作学习算法，在不同设备之间通过协作完成分散任务。通过图模型先验生成的协作图，算法可以自动捕捉设备之间的跨任务相关性。 |
| [^35] | [CMLM-CSE: Based on Conditional MLM Contrastive Learning for Sentence Embeddings.](http://arxiv.org/abs/2306.09594) | 本论文提出了一种基于条件MLM的无监督对比学习框架CMLM-CSE，强制句子嵌入学习更多的掩码词信息，可以在文本相似度任务中超越SimCSE。 |
| [^36] | [Is the Volume of a Credal Set a Good Measure for Epistemic Uncertainty?.](http://arxiv.org/abs/2306.09586) | 本文探讨了将不确定性表示为一个置信集而非单一概率分布的方法。并发现，在二元分类中，信任集的体积是一种有意义的衡量认知不确定性的方法，但在多类分类中则没有这种效果。 |
| [^37] | [How do different tokenizers perform on downstream tasks in scriptio continua languages?: A case study in Japanese.](http://arxiv.org/abs/2306.09572) | 本文研究了在日语这种连续书写文字语言中，不同的分词器对预训练语言模型在下游任务中的影响，发现每个下游任务都有一个最佳的形态学分析器，并且无论任务类型如何，最好使用字节对编码或Unigram作为子词分词器。 |
| [^38] | [QH9: A Quantum Hamiltonian Prediction Benchmark for QM9 Molecules.](http://arxiv.org/abs/2306.09549) | 该论文提出了一种新的量子哈密顿数据集QH9，用于为各种分子提供精确的哈密顿矩阵。通过设计基准任务，展示了当前机器学习模型有能力预测任意分子的哈密顿矩阵。 |
| [^39] | [Graph Extraction for Assisting Crash Simulation Data Analysis.](http://arxiv.org/abs/2306.09538) | 本文提出了一种将CAE数据转为图形的方法，可以比较模拟数据并突出未探索的实验设计，并对不同设计进行相关性分析。特别关注了车辆碰撞安全性分析中的负荷路径检测。 |
| [^40] | [Residual Q-Learning: Offline and Online Policy Customization without Value.](http://arxiv.org/abs/2306.09526) | 该研究提出了一种新方法，使用动态控制残差的 Q 学习来进行离线和在线的策略定制，无需使用价值函数。 |
| [^41] | [Explaining Legal Concepts with Augmented Large Language Models (GPT-4).](http://arxiv.org/abs/2306.09525) | 本文评估了利用GPT-4增强解释法律术语性能的方法。与基准设置相比，使用增强的法律信息检索模块可以提高法律术语解释的质量，并消除模型的幻觉问题，从而为在法律领域使用大型语言模型开辟了新的途径。 |
| [^42] | [Tighter Prediction Intervals for Causal Outcomes Under Hidden Confounding.](http://arxiv.org/abs/2306.09520) | 本文提出了一种名为Caus-Modens的算法，通过调制集合来描述因果结果区间，相比符合性预测方法，能够在实践中给出更紧密的结果区间。 |
| [^43] | [Granger-Causal Hierarchical Skill Discovery.](http://arxiv.org/abs/2306.09509) | 本文介绍了一种名为HIntS的算法，使用无监督检测器，基于Granger因果性捕捉因素之间的关键事件，发现和训练一系列操作因素化环境中的因素的技能，其展示了在机器人推动任务上有2-3倍的样本效率和最终性能的提高，有效的处理了复杂问题和转移学习。 |
| [^44] | [A Hybrid Feature Selection and Construction Method for Detection of Wind Turbine Generator Heating Faults.](http://arxiv.org/abs/2306.09491) | 该论文提出了一种用于检测风力涡轮机发电机加热故障的混合特征选取和构造方法，旨在通过特征构造和选取提高分类精度和降低计算负担。 |
| [^45] | [The 2023 Video Similarity Dataset and Challenge.](http://arxiv.org/abs/2306.09489) | 本文介绍了一个视频复制检测和定位问题的数据集、基准和挑战。我们提出了一个评估方法并分析了挑战结果和方法。 |
| [^46] | [Sample-Efficient Learning of Novel Visual Concepts.](http://arxiv.org/abs/2306.09482) | 本文提出了一种通过加入符号知识图谱来有效进行少样本分类的方法。与现有分类器不同，该方法考虑到物体之间的相互关系，不仅能够识别物体，还包括抽象概念和功能。 |
| [^47] | [Improving Path Planning Performance through Multimodal Generative Models with Local Critics.](http://arxiv.org/abs/2306.09470) | 本文提出了一种使用Wasserstein生成对抗性网络，结合连续潜在空间中的变分自动编码器和本地批评者的方法，加速在未知场景与障碍中的路径规划任务，有效提升了成功率和速度。 |
| [^48] | [FFB: A Fair Fairness Benchmark for In-Processing Group Fairness Methods.](http://arxiv.org/abs/2306.09468) | 本文提出了针对处理中组公平方法的公平公正基准框架（FFB），并进行了全面分析。该工作的关键贡献包括提供灵活、可扩展、极简和面向研究的开源代码；建立统一的公平方法基准测试流水线；进行广泛的基准测试，从 $\mathbf{45,079}$ 个实验中获取关键见解。 |
| [^49] | [Kriging Convolutional Networks.](http://arxiv.org/abs/2306.09463) | 该研究介绍了一种新的Kriging卷积网络方法，结合了Kriging和图卷积网络的优点，并在多个应用中表现出了更好的性能。 |
| [^50] | [Motion Comfort Optimization for Autonomous Vehicles: Concepts, Methods, and Techniques.](http://arxiv.org/abs/2306.09462) | 本文介绍了针对人类舒适度的自动驾驶架构和与其相关的补充框架。讨论了自动驾驶舒适性、响应时间、运动晕车和优化技术等方面的技术细节和挑战。 |
| [^51] | [Recurrent Memory Decision Transformer.](http://arxiv.org/abs/2306.09459) | 本文提出了循环记忆决策变压器（RMDT）模型，用于处理强化学习中的长序列问题。在Atari游戏和MoJoCo控制问题上的实验表明，采用循环记忆机制的RMDT模型显着优于其没有循环记忆机制的对应模型。 |
| [^52] | [Host-Based Network Intrusion Detection via Feature Flattening and Two-stage Collaborative Classifier.](http://arxiv.org/abs/2306.09451) | 该论文提出了一种混合网络入侵检测系统，结合 NIDS 和 HIDS，利用特征展平技术和两阶段协作分类进行合作分类以提高入侵检测的准确率。 |
| [^53] | [Understanding the Application of Utility Theory in Robotics and Artificial Intelligence: A Survey.](http://arxiv.org/abs/2306.09445) | 本文是一项了解机器人和人工智能中效用理论应用的调查，探讨了如何通过合适的效用模型指导智能体选择合理策略来实现系统的最优效用和保证每个群体成员的可持续发展。 |
| [^54] | [Explore, Establish, Exploit: Red Teaming Language Models from Scratch.](http://arxiv.org/abs/2306.09442) | 本文提出了一种新的红队行动，通过从高层次、抽象的规范出发来考虑语言模型的行为，以探究模型的创新和贡献。 |
| [^55] | [Towards Practical Federated Causal Structure Learning.](http://arxiv.org/abs/2306.09433) | 为了解决联邦学习条件下的因果结构学习难题，提出了一种基于联邦条件独立性检验的因果结构学习方案FedC2SL，无需收集原始数据且对数据变异具有更强的抵抗力。 |
| [^56] | [Diff-TTSG: Denoising probabilistic integrated speech and gesture synthesis.](http://arxiv.org/abs/2306.09417) | Diff-TTSG是第一个基于扩散的概率模型，用于联合学习合成语音和手势，相比于先前最新技术的非概率方法，它可以更好地捕捉人类讲话和运动的变化，产生更逼真和多样化的集成语音和手势合成。 |
| [^57] | [ChatGPT for Suicide Risk Assessment on Social Media: Quantitative Evaluation of Model Performance, Potentials and Limitations.](http://arxiv.org/abs/2306.09390) | 本文量化评估了基于社交媒体的 ChatGPT 模型在自杀倾向评估方面的表现，比较了其结果与两个微调模型，并探讨了模型响应生成的最佳温度，研究结果显示，以人工标注数据集为基础微调的 Transformer 模型表现更佳，这篇论文为心理健康专家提供了重要的模型评估和参数优化建议。 |
| [^58] | [Adaptive Hierarchical SpatioTemporal Network for Traffic Forecasting.](http://arxiv.org/abs/2306.09386) | 本文提出了一种自适应分层时空网络（AHSTN），通过利用空间层次结构和建模多尺度空间相关性促进交通预测，AHSTN在节点级别的基础上引入了自适应的时空块，来自适应地处理不同层次之间的相关性，同时使用分层注意机制来选择性地聚合不同尺度的信息，具有优越性。 |
| [^59] | [Employing Multimodal Machine Learning for Stress Detection.](http://arxiv.org/abs/2306.09385) | 本文提出了一个基于多模态AI的框架，旨在通过融合多种信息来精确监测人的工作行为和压力水平。该框架使用卷积神经网络、时延神经网络和多层感知器等深度学习技术，能够高精度地检测高压力和低压力状态。 |
| [^60] | [MobileASR: A resource-aware on-device personalisation framework for automatic speech recognition in mobile phones.](http://arxiv.org/abs/2306.09384) | 本文提出了一种资源感知的子模型训练方法，能够在移动设备上有效训练用户语音个性化的ASR模型，同时考虑了移动设备的评估指标和电池限制。在实验中发现，微调模型和选择超参数值需要在性能度量和本地训练时间之间进行权衡。 |
| [^61] | [Spatiotemporal-Augmented Graph Neural Networks for Human Mobility Simulation.](http://arxiv.org/abs/2306.09381) | STAR框架通过设计多种时空图来捕捉位置的动态时空效应，为人类移动模拟任务提供新的方法。 |
| [^62] | [Understanding Parameter Sharing in Transformers.](http://arxiv.org/abs/2306.09380) | 本文从模型复杂度和梯度范围两个角度研究了Transformer中参数共享的有效性，发现提高训练收敛性是其中主要原因，模型复杂度只有一小部分贡献。 |
| [^63] | [Language Aligned Visual Representations Predict Human Behavior in Naturalistic Learning Tasks.](http://arxiv.org/abs/2306.09377) | 语言对齐的视觉表示方式比纯视觉表示方式更有效地预测人类在自然学习任务中的行为。 |
| [^64] | [Modularizing while Training: a New Paradigm for Modularizing DNN Models.](http://arxiv.org/abs/2306.09376) | 本文提出了一种新方法，将模块化纳入模型训练过程中，即在训练时模块化(MwT)，通过两个损失函数实现模型结构上的模块化，进而实现模块的重用，能够在较短的训练时间内达到可比较的模型精度，并且相对于最先进的训练后模块化方法需要更少的参数。 |
| [^65] | [From Database Repairs to Causality in Databases and Beyond.](http://arxiv.org/abs/2306.09374) | 本文介绍了新颖的利用反事实推理进行数据库查询答案分数解释的方法。 |
| [^66] | [Equitable Multi-task Learning.](http://arxiv.org/abs/2306.09373) | 该论文提出了一种名为EMTL的多任务优化方法，以实现公平的多任务学习。通过规范化不同任务的相对贡献，可以提高MTL的泛化性能，并利用方差正则化和高效的优化算法保证收敛。实验证明，该方法在合成和真实数据集上均表现出了更好的性能。 |
| [^67] | [Warpformer: A Multi-scale Modeling Approach for Irregular Clinical Time Series.](http://arxiv.org/abs/2306.09368) | Warpformer是一种能够完整考虑序列内不规则性和序列间差异性的多尺度建模方法。 |
| [^68] | [Fault Detection in Induction Motors using Functional Dimensionality Reduction Methods.](http://arxiv.org/abs/2306.09365) | 本研究提出了一种采用函数降维方法结合电机电流特征分析策略的故障检测方法，能够实时检测感应电动机中的故障，并且可以通过离线分析识别更多类型的故障。 |
| [^69] | [TSMixer: Lightweight MLP-Mixer Model for Multivariate Time Series Forecasting.](http://arxiv.org/abs/2306.09364) | TSMixer是一种用于多元时间序列预测的轻量级MLP-Mixer模型，可以有效地捕捉时间序列属性并在准确性方面超越了Transformers的方法。 |
| [^70] | [A Simple Data Augmentation for Feature Distribution Skewed Federated Learning.](http://arxiv.org/abs/2306.09363) | 本文针对特征分布偏斜的联邦学习提出了FedRDN方法，在输入层级上实现了数据增强，将整个联邦数据集的统计信息注入到本地客户端数据中，以缓解特征漂移问题。 |
| [^71] | [Datasets and Benchmarks for Offline Safe Reinforcement Learning.](http://arxiv.org/abs/2306.09303) | 该论文提出了一个专门针对离线安全强化学习的基准套件，包含了安全策略、数据集和高质量RL算法实现。作者还提供了一种数据收集流程，利用先进算法生成多样性数据集，用于38个受欢迎的安全RL任务。该套件可加速该领域的研究进展。 |
| [^72] | [Probabilistic Learning of Multivariate Time Series with Temporal Irregularity.](http://arxiv.org/abs/2306.09147) | 本文提出了一种针对具有时间不规则性的多元时间序列的概率学习方法，通过允许观察到达时间在模型构建中发挥核心作用，使用新颖的非参数先验模型明确融入时间不规则性。 |
| [^73] | [Skill-Critic: Refining Learned Skills for Reinforcement Learning.](http://arxiv.org/abs/2306.08388) | 基于技能筛选与优化的Skill-Critic算法能够提高稀疏奖励环境下强化学习中低层策略的可靠性，并显著提高了性能。 |
| [^74] | [h2oGPT: Democratizing Large Language Models.](http://arxiv.org/abs/2306.08161) | 本文介绍了h2oGPT，这是一套开源代码库，用于创建和使用基于GPTs的大语言模型（LLMs），包括100％私有文档搜索。目标是创建真正开源的替代封闭源GPTs，提高人工智能的开发和可靠性。 |
| [^75] | [DreamSparse: Escaping from Plato's Cave with 2D Diffusion Model Given Sparse Views.](http://arxiv.org/abs/2306.03414) | 本文提出了 DreamSparse 框架，该框架通过利用先前训练的扩散模型的 2D 先验知识，通过几何模块和空间引导模型来解决 2D 模型缺乏 3D 感知能力的问题，进一步实现了从少视角情况下合成高质量的新视角图像。 |
| [^76] | [Evaluating GPT-3 Generated Explanations for Hateful Content Moderation.](http://arxiv.org/abs/2305.17680) | 本文通过调查和分析，评估了使用GPT-3生成的针对仇恨内容的解释是否准确和有用。结果显示，GPT-3生成的解释普遍存在过于模糊、聚焦不当等缺点，同时也存在不同类型仇恨言论生成的解释质量差异大的问题。 |
| [^77] | [Do Not Train It: A Linear Neural Architecture Search of Graph Neural Networks.](http://arxiv.org/abs/2305.14065) | 本文提出了一种新的图神经网络结构搜索方法——神经结构编码（NAC），它通过稀疏编码寻找最优结构参数，无需训练就能发挥表现力，在多个基准数据集上实现了最先进性能，并且运算速度比强基线方法快了200倍，精度提高了18.8％。 |
| [^78] | [On Data Sampling Strategies for Training Neural Network Speech Separation Models.](http://arxiv.org/abs/2304.07142) | 本文研究了训练神经网络语音分离模型的数据采样策略对模型性能的影响。研究表明，对于特定的信号长度分布，采用特定的训练信号长度限制可以获得更好的性能。 |
| [^79] | [INoD: Injected Noise Discriminator for Self-Supervised Representation Learning in Agricultural Fields.](http://arxiv.org/abs/2303.18101) | 本文提出了一个名为INoD的注入噪声鉴别器，通过特征替换和数据集鉴别的原则进行农田自监督表示学习，提升了模型性能。 |
| [^80] | [Artificial Intelligence in Ovarian Cancer Histopathology: A Systematic Review.](http://arxiv.org/abs/2303.18005) | 通过对36篇文章的综述，该研究发现人工智能模型在卵巢癌的诊断和预后中显示出有希望的结果，但现有研究受到小样本量，潜在偏见和缺乏外部验证的限制。 |
| [^81] | [Robotic Packaging Optimization with Reinforcement Learning.](http://arxiv.org/abs/2303.14693) | 本论文提出了一个强化学习框架，用于优化机器人包装中的传送带速度，并减少对余下控制系统的干扰。 |
| [^82] | [Iterative Partial Fulfillment of Counterfactual Explanations: Benefits and Risks.](http://arxiv.org/abs/2303.11111) | 迭代部分满足的反事实解释被广泛用于解释机器学习模型在高风险领域中的推理，我们提出了一个新颖的属性：这种解释在迭代部分履行下的行为。主体可以在接收的解释中部分地履行请求一个新的预测和新的解释，重复此过程，直到预测为正面。 |
| [^83] | [Seq-HyGAN: Sequence Classification via Hypergraph Attention Network.](http://arxiv.org/abs/2303.02393) | 本文提出了一种基于超图注意力网络的序列分类模型Seq-HyGAN，通过创建超图和引入注意力机制来处理序列数据中的复杂结构相似性，从而提高分类准确率。 |
| [^84] | [Augmenting Rule-based DNS Censorship Detection at Scale with Machine Learning.](http://arxiv.org/abs/2302.02031) | 本文探讨了如何使用机器学习模型来帮助简化DNS审查检测过程，提高检测的可靠性，并发现启发式方法所错过的新审查实例和阻止标志。 |
| [^85] | [Cognitive Accident Prediction in Driving Scenes: A Multimodality Benchmark.](http://arxiv.org/abs/2212.09381) | 本篇论文提出了一种名为CAP的方法，它通过文本描述和驾驶员注意力来改善行车视频中的交通事故预测。这个方法考虑了长尾数据分布和环境变化等挑战，希望能为未来的安全驾驶系统提供决策支持。 |
| [^86] | [Strong-AI Autoepistemic Robots Build on Intensional First Order Logic.](http://arxiv.org/abs/2212.07935) | 本文研究了内涵一阶逻辑作为现代机器人的符号架构，可以推理自身知识、使用自然语言与人类交流、抽象语言属性。同时，通过机器人神经架构的经验获得机器人语言的基础，将其与IFOL理论中的非定义语言概念相联系。 |
| [^87] | [PASTA: Proportional Amplitude Spectrum Training Augmentation for Syn-to-Real Domain Generalization.](http://arxiv.org/abs/2212.00979) | 本文提出了一种基于比例幅度谱训练增强的方法 PASTA，可有效提高合成数据到真实数据的泛化性能，在多个 Syn-to-Real 任务上均具有优越性能。 |
| [^88] | [Learning Combinatorial Structures via Markov Random Fields with Sampling through Lov\'asz Local Lemma.](http://arxiv.org/abs/2212.00296) | Nelson是一种基于神经网络和Lov\'asz Local Lemma的方法，使用约束的马尔可夫随机场模型生成满足组合约束条件的样本。 |
| [^89] | [Adversarial Cheap Talk.](http://arxiv.org/abs/2211.11030) | 本文提出了一种新型对抗性设置，在其中对手只能将信息附加到受害者的观察中，从而产生最小的影响范围，并提出对抗性廉价交流（ACT）算法进行对手训练。在高度受限的情况下，使用ACT训练的对手仍会对受害者的训练和测试表现产生显著影响，揭示了强化学习算法中的一种新的攻击向量。 |
| [^90] | [Explainable Action Advising for Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2211.07882) | 引入可解释行为建议的多智能体强化学习框架，使得学生可以理解所学的内容并进行推理从而提高样本效率和学习效果 |
| [^91] | [Training Debiased Subnetworks with Contrastive Weight Pruning.](http://arxiv.org/abs/2210.05247) | 本文探讨了在存在强假相关的偏置网络中提取最优无偏子网络的问题，并提出了使用对比剪枝权重训练实现去偏置子网络的算法 DCWP，在多个应用中都有良好的效果。 |
| [^92] | [The Best Decisions Are Not the Best Advice: Making Adherence-Aware Recommendations.](http://arxiv.org/abs/2209.01874) | 论文提出了一个考虑服从度的优化框架，来捕获推荐策略和实际执行策略之间的差异。通过分析部分服从度对最佳建议的影响，发现忽略部分服从度可能导致任意严重的性能恶化。 |
| [^93] | [Resolving the Human Subjects Status of Machine Learning's Crowdworkers.](http://arxiv.org/abs/2206.04039) | 机器学习在研究中使用的众包工作者问题引起了对其受试者身份的争议与监管合规性，本文针对该问题进行研究，重点关注了自然语言处理领域中的研究监管挑战。 |
| [^94] | [On the preferred extensions of argumentation frameworks: bijections with naive sets.](http://arxiv.org/abs/2202.05506) | 本文通过与另一个框架的纯朴集合双射的方法解决了找到一个论证框架的优先推理的问题。其中，识别纯朴-双射的论证框架是困难的，但入度有限的框架中可行。此外，引入了不可简化的自卫集合的概念，并证明了一个论证框架的优先推理与另一个框架的纯朴集合之间存在双射。 |
| [^95] | [A Post-Quantum Associative Memory.](http://arxiv.org/abs/2201.12305) | 该论文研究了一种基于广义概率理论(GPT)的联想记忆的模型，证明了GPT可以比经典和量子理论更好地处理具有指数级优势的特定任务。 |
| [^96] | [Knowledge-driven Active Learning.](http://arxiv.org/abs/2110.08265) | 本文提出了基于知识的主动学习(KAL)框架，将通用领域知识转换为逻辑约束，作为样本选择的指南，使非专业用户能够用更少的样本训练模型，并在降低标记数据需求量的同时保持出色性能。 |

# 详细

[^1]: 指导可教导学生：一种基于知识蒸馏的传感器运动代理驾驶框架

    Coaching a Teachable Student. (arXiv:2306.10014v1 [cs.CV])

    [http://arxiv.org/abs/2306.10014](http://arxiv.org/abs/2306.10014)

    本研究提出了一种新颖的知识蒸馏框架，通过设计一个学生模型并支持其传感器运动学习任务，实现了学生与教师之间的优化差距尽量小，进而提高了学生驾驶行为的学习质量。

    

    本论文提出了一种新颖的知识蒸馏框架，有效地教导传感器运动代理在特权教师代理的监督下驾驶。目前针对传感器运动代理的蒸馏方法往往导致学生的驾驶行为学习不佳，我们猜测这是由于两个代理之间输入、建模能力和优化过程方面固有的差异所致。我们设计了一种新颖的蒸馏方案，以解决这些限制并缩小传感器运动代理与其特权教师之间的差距。我们的关键洞察是设计一个学生模型，学生可以学习将其输入特征与教师的特权鸟瞰空间对齐。然后学生可以从教师对内部表示学习的直接监督中受益。为了支持困难的传感器运动学习任务，学生模型通过学生节奏的辅助指导机制进行优化。我们进一步提出了一种改进的无监督辅助学习机制和一种学生选择监督的自适应蒸馏框架。

    We propose a novel knowledge distillation framework for effectively teaching a sensorimotor student agent to drive from the supervision of a privileged teacher agent. Current distillation for sensorimotor agents methods tend to result in suboptimal learned driving behavior by the student, which we hypothesize is due to inherent differences between the input, modeling capacity, and optimization processes of the two agents. We develop a novel distillation scheme that can address these limitations and close the gap between the sensorimotor agent and its privileged teacher. Our key insight is to design a student which learns to align their input features with the teacher's privileged Bird's Eye View (BEV) space. The student then can benefit from direct supervision by the teacher over the internal representation learning. To scaffold the difficult sensorimotor learning task, the student model is optimized via a student-paced coaching mechanism with various auxiliary supervision. We further 
    
[^2]: MagicBrush: 人工标注的用于指导图像编辑的数据集

    MagicBrush: A Manually Annotated Dataset for Instruction-Guided Image Editing. (arXiv:2306.10012v1 [cs.CV])

    [http://arxiv.org/abs/2306.10012](http://arxiv.org/abs/2306.10012)

    MagicBrush是第一个大规模的手动标注的数据集，用于指导真实图像的编辑。它包括超过10K个手动标注的三元组，支持大规模的文本指导图像编辑模型训练。在此数据集上微调InstructPix2Pix可以根据人类评估提供更好的图像。

    

    文本指导的图像编辑从个人使用到专业应用（如Photoshop）广泛需要。然而，现有的方法要么是零样本，要么是在自动合成的数据集上进行训练，其中含有大量的噪声。因此，它们在实践中仍需要大量的手动调整才能产生理想的结果。为了解决这个问题，我们介绍了MagicBrush，第一个大规模的手动标注的数据集，用于指导真实图像的编辑，包括单个操作、多个操作、提供掩码和不提供掩码等不同场景。MagicBrush包括超过10K个手动标注的三元组（源图像，指令，目标图像），支持大规模的文本指导图像编辑模型训练。我们在MagicBrush上微调InstructPix2Pix，并展示了新模型可以根据人类评估提供更好的图像。我们还进行了广泛的实验评估，以评估模型的泛化能力和使用效果。

    Text-guided image editing is widely needed in daily life, ranging from personal use to professional applications such as Photoshop. However, existing methods are either zero-shot or trained on an automatically synthesized dataset, which contains a high volume of noise. Thus, they still require lots of manual tuning to produce desirable outcomes in practice. To address this issue, we introduce MagicBrush (https://osu-nlp-group.github.io/MagicBrush/), the first large-scale, manually annotated dataset for instruction-guided real image editing that covers diverse scenarios: single-turn, multi-turn, mask-provided, and mask-free editing. MagicBrush comprises over 10K manually annotated triples (source image, instruction, target image), which supports trainining large-scale text-guided image editing models. We fine-tune InstructPix2Pix on MagicBrush and show that the new model can produce much better images according to human evaluation. We further conduct extensive experiments to evaluate cu
    
[^3]: 组正交正则化：用于视觉模型自适应和鲁棒性的方法

    Group Orthogonalization Regularization For Vision Models Adaptation and Robustness. (arXiv:2306.10001v1 [cs.CV])

    [http://arxiv.org/abs/2306.10001](http://arxiv.org/abs/2306.10001)

    该论文提出了一种新的正则化技术，称为组正交正则化，能够提高视觉模型自适应和鲁棒性。实验结果表明，此种正则化可以应用于不同的深度学习模型，并且能够有效地优化模型性能。

    

    随着神经网络变得越来越深，参数内部的冗余度也随之增加。这种现象导致了许多试图减少卷积滤波器之间相关性的方法的出现。我们提出了一种计算高效的正则化技术，它鼓励同一层内滤波器组之间的正交性。我们的实验表明，当结合最新的扩散模型适应方法和视觉转换器（ViTs）时，这种正则化可以提高下游任务的性能。我们进一步展示了当在对抗训练过程中强制进行组正交性时的增强鲁棒性。我们的代码可在https://github.com/YoavKurtz/GOR获得。

    As neural networks become deeper, the redundancy within their parameters increases. This phenomenon has led to several methods that attempt to reduce the correlation between convolutional filters. We propose a computationally efficient regularization technique that encourages orthonormality between groups of filters within the same layer. Our experiments show that when incorporated into recent adaptation methods for diffusion models and vision transformers (ViTs), this regularization improves performance on downstream tasks. We further show improved robustness when group orthogonality is enforced during adversarial training. Our code is available at https://github.com/YoavKurtz/GOR.
    
[^4]: 基于偏好的强化学习中的公平性

    Fairness in Preference-based Reinforcement Learning. (arXiv:2306.09995v1 [cs.LG])

    [http://arxiv.org/abs/2306.09995](http://arxiv.org/abs/2306.09995)

    该论文提出了一种名为FPbRL的新的公平偏好强化学习方法，旨在通过广义Gini福利函数最大化策略学习来实现多目标优化并处理每个目标的公平性。

    

    本文研究了在多目标情况下偏好强化学习(PbRL)中的公平性问题。主要目标是设计控制策略，既能够优化多个目标，又能够公平地处理每个目标。为实现这一目标，我们设计了一种新的公平偏好强化学习(FPbRL)方法。FPbRL的主要思想是通过新的福利偏好而不是PbRL中的基于奖励的偏好来学习与多目标关联的向量奖励函数，并通过最大化广义Gini福利函数进行策略学习。最后，在三个不同的环境上进行实验研究，展示了所提出的FPbRL方法能够实现有效和公平的控制策略的学习。

    In this paper, we address the issue of fairness in preference-based reinforcement learning (PbRL) in the presence of multiple objectives. The main objective is to design control policies that can optimize multiple objectives while treating each objective fairly. Toward this objective, we design a new fairness-induced preference-based reinforcement learning or FPbRL. The main idea of FPbRL is to learn vector reward functions associated with multiple objectives via new welfare-based preferences rather than reward-based preference in PbRL, coupled with policy learning via maximizing a generalized Gini welfare function. Finally, we provide experiment studies on three different environments to show that the proposed FPbRL approach can achieve both efficiency and equity for learning effective and fair policies.
    
[^5]: 心血管疾病预测的集成框架

    Ensemble Framework for Cardiovascular Disease Prediction. (arXiv:2306.09989v1 [cs.LG])

    [http://arxiv.org/abs/2306.09989](http://arxiv.org/abs/2306.09989)

    本文介绍了一个使用机器学习方法预测心血管疾病的集成框架，采用了IEEE Data Port 数据集，旨在早期准确诊断心脏问题，提高生命几率。

    

    心脏病是全球非传染性和缄默死亡的主要原因。心脏疾病或心血管疾病分为四种类型：冠状动脉心脏病、心力衰竭、先天性心脏病和心肌病。早期准确诊断心脏疾病对于避免进一步损伤并挽救患者的生命至关重要。因此，我们需要一个能够在心血管疾病变成危机之前预测其发生的系统。机器学习引起了医学科学研究人员的兴趣。针对心脏疾病预测，研究人员实施了各种机器学习方法和方法。在此工作中，我们采用了IEEE Data Port数据集，这是一种在线可用于心血管疾病个体的最大数据集之一。该数据集是由匈牙利，克里夫兰，长滩VA，瑞士和Statlog数据集组成，具有重要特征，如最大心率

    Heart disease is the major cause of non-communicable and silent death worldwide. Heart diseases or cardiovascular diseases are classified into four types: coronary heart disease, heart failure, congenital heart disease, and cardiomyopathy. It is vital to diagnose heart disease early and accurately in order to avoid further injury and save patients' lives. As a result, we need a system that can predict cardiovascular disease before it becomes a critical situation. Machine learning has piqued the interest of researchers in the field of medical sciences. For heart disease prediction, researchers implement a variety of machine learning methods and approaches. In this work, to the best of our knowledge, we have used the dataset from IEEE Data Port which is one of the online available largest datasets for cardiovascular diseases individuals. The dataset isa combination of Hungarian, Cleveland, Long Beach VA, Switzerland & Statlog datasets with important features such as Maximum Heart Rate Ac
    
[^6]: 用一致性检查评估超人模型

    Evaluating Superhuman Models with Consistency Checks. (arXiv:2306.09983v1 [cs.LG])

    [http://arxiv.org/abs/2306.09983](http://arxiv.org/abs/2306.09983)

    本文提出了一个用一致性检查评估超人模型的框架，可以发现决策制定中的逻辑不一致性，即使对于超人模型的决策正确性可能是不可能评估的情况。

    

    如果机器学习模型在各种推理或决策任务上实现了超人能力，那么我们该如何评估这些模型，考虑到人类代理会产生偏差? 在本文中，我们提出了一个用一致性检查评估超人模型的框架。我们的前提是，虽然评估超人决策的正确性可能是不可能的，但是如果模型的决策未能满足某些逻辑上、可解释的规则，我们仍然可以发现错误。我们将我们的框架实现在三个任务上，这些任务的决策正确性由于超人模型能力或其他缺乏基本事实而难以评估：评估国际象棋局面、预测未来事件和作出法律判断。我们表明，无论模型在这些任务上的表现如何(可能是超人的)，我们都能发现决策制定中的逻辑不一致性。例如：国际象棋引擎给出对局中棋子相对估值的不同排列。

    If machine learning models were to achieve superhuman abilities at various reasoning or decision-making tasks, how would we go about evaluating such models, given that humans would necessarily be poor proxies for ground truth? In this paper, we propose a framework for evaluating superhuman models via consistency checks. Our premise is that while the correctness of superhuman decisions may be impossible to evaluate, we can still surface mistakes if the model's decisions fail to satisfy certain logical, human-interpretable rules. We instantiate our framework on three tasks where correctness of decisions is hard to evaluate due to either superhuman model abilities, or to otherwise missing ground truth: evaluating chess positions, forecasting future events, and making legal judgments. We show that regardless of a model's (possibly superhuman) performance on these tasks, we can discover logical inconsistencies in decision making. For example: a chess engine assigning opposing valuations to 
    
[^7]: 论文标题：在强化学习中创建多级技能层次结构。

    Creating Multi-Level Skill Hierarchies in Reinforcement Learning. (arXiv:2306.09980v1 [cs.LG])

    [http://arxiv.org/abs/2306.09980](http://arxiv.org/abs/2306.09980)

    本文提出了一种基于代理人与环境交互的图形结构的答案，使用分层图划分产生具有多个抽象层次的技能层次结构。技能能将代理人移动到状态空间中互相连接紧密但相互连接较弱的区域，有效提高了强化学习的效率。

    

    摘要：什么样的技能层次结构对于自主代理人是有用的？我们提出了一种基于代理人与环境交互的图形结构的答案。我们的方法使用分层图划分来揭示图在不同时间尺度上的结构，从而产生具有多个抽象层次的技能层次结构。在层次结构的每个层次上，技能将代理人移动到状态空间中互相连接紧密但相互连接较弱的区域。我们在强化学习的广泛领域中展示了所提出的技能层次结构的效用。

    What is a useful skill hierarchy for an autonomous agent? We propose an answer based on the graphical structure of an agent's interaction with its environment. Our approach uses hierarchical graph partitioning to expose the structure of the graph at varying timescales, producing a skill hierarchy with multiple levels of abstraction. At each level of the hierarchy, skills move the agent between regions of the state space that are well connected within themselves but weakly connected to each other. We illustrate the utility of the proposed skill hierarchy in a wide variety of domains in the context of reinforcement learning.
    
[^8]: 评估语音表征对MOS预测的影响

    Evaluation of Speech Representations for MOS prediction. (arXiv:2306.09979v1 [cs.SD])

    [http://arxiv.org/abs/2306.09979](http://arxiv.org/abs/2306.09979)

    本文评估了语音表征的特征提取模型，并提出了一种模型通过比较受监督和自监督学习模型的嵌入与说话人验证模型的嵌入来预测MOS，表明Whisper模型是最为合适的。

    

    本文评估了用于预测语音质量的特征提取模型，并提出了一种模型结构来比较受监督和自监督学习模型的嵌入与说话人验证模型的嵌入来预测度量MOS。我们在VCC2018数据集和为这项工作创建的巴西葡萄牙语数据集BRSpeechMOS上进行了实验。结果显示Whisper模型在所有场景下都是合适的：使用VCC2018和BRSpeechMOS数据集。在使用BRSpeechMOS的受监督和自监督学习模型中，Whisper-Small获得了最佳的线性相关性0.6980，说话人验证模型SpeakerNet的线性相关性为0.6963。在使用VCC2018时，最佳的受监督和自监督学习模型Whisper-Large获得了0.7274的线性相关性，而最好的模型说话人验证模型TitaNet获得了0.6933的线性相关性。

    In this paper, we evaluate feature extraction models for predicting speech quality. We also propose a model architecture to compare embeddings of supervised learning and self-supervised learning models with embeddings of speaker verification models to predict the metric MOS. Our experiments were performed on the VCC2018 dataset and a Brazilian-Portuguese dataset called BRSpeechMOS, which was created for this work. The results show that the Whisper model is appropriate in all scenarios: with both the VCC2018 and BRSpeech- MOS datasets. Among the supervised and self-supervised learning models using BRSpeechMOS, Whisper-Small achieved the best linear correlation of 0.6980, and the speaker verification model, SpeakerNet, had linear correlation of 0.6963. Using VCC2018, the best supervised and self-supervised learning model, Whisper-Large, achieved linear correlation of 0.7274, and the best model speaker verification, TitaNet, achieved a linear correlation of 0.6933. Although the results of
    
[^9]: HePCo：用于连续联邦学习的无数据异构提示合并方法

    HePCo: Data-Free Heterogeneous Prompt Consolidation for Continual Federated Learning. (arXiv:2306.09970v1 [cs.CV])

    [http://arxiv.org/abs/2306.09970](http://arxiv.org/abs/2306.09970)

    本文提出了一种名为HePCo的轻量级提示合并算法，解决了在连续联邦学习中的数据异构和遗忘问题，并在不共享或存储任何数据的情况下最小化了通信开销。在真实数据集和合成数据集上实现了最先进的结果，并且保持了数据隐私。

    

    本文研究了连续联邦学习的重要但鲜为人知的问题。在这种情况下，服务器与一组客户端通信，以逐步学习新的概念，同时不共享或存储任何数据。由于来自连续和联邦学习角度的挑战，此问题的复杂性受到了加剧。本文尝试在不需要访问任何存储数据的情况下解决遗忘和异构问题，同时最小化开销。我们通过采用一种基于提示的方法并提出一种名为HePCo的新颖轻量级提示合并算法，实现了此目标。我们的方法在真实数据集和合成数据集上均能取得最先进的结果并保持低通信开销，同时不影响数据隐私。

    In this paper, we focus on the important yet understudied problem of Continual Federated Learning (CFL), where a server communicates with a set of clients to incrementally learn new concepts over time without sharing or storing any data. The complexity of this problem is compounded by challenges from both the Continual and Federated Learning perspectives. Specifically, models trained in a CFL setup suffer from catastrophic forgetting which is exacerbated by data heterogeneity across clients. Existing attempts at this problem tend to impose large overheads on clients and communication channels or require access to stored data which renders them unsuitable for real-world use due to privacy. In this paper, we attempt to tackle forgetting and heterogeneity while minimizing overhead costs and without requiring access to any stored data. We achieve this by leveraging a prompting based approach (such that only prompts and classifier heads have to be communicated) and proposing a novel and lig
    
[^10]: 利用时间逻辑推理的非线性切换系统数据驱动模型区分

    Data-Driven Model Discrimination of Switched Nonlinear Systems with Temporal Logic Inference. (arXiv:2306.09966v1 [cs.AI])

    [http://arxiv.org/abs/2306.09966](http://arxiv.org/abs/2306.09966)

    本文提出了针对未知非线性切换系统的数据驱动模型区分问题的解决方案，包括数据驱动方法来过估计未知动态和推断未知规范，以及优化算法来分析学习/推断模型-任务对的可区分性，并提出缩小推断规范大小的方法以提高区分的效率。

    

    本文讨论了针对未知非线性切换系统的数据驱动模型区分问题，其中这些切换系统的模式序列受其任务，即未知线性时间逻辑要求所控制，只有未知的动态和任务的采样数据可用。为了解决这个问题，我们提出了数据驱动方法来过估计未知动态和推断未知规范，从而保证未知动态的集合成员模型和LTL公式均包括真实模型和规范/任务。此外，我们提出了基于优化的算法来分析一组学习/推断的模型-任务对的可区分性，以及用于排除在运行时与新观测不一致的模型-任务对的模型区分算法。此外，我们提出了一种缩小推断规范大小的方法，以提高模型区分的计算效率。

    This paper addresses the problem of data-driven model discrimination for unknown switched systems with unknown linear temporal logic (LTL) specifications, representing tasks, that govern their mode sequences, where only sampled data of the unknown dynamics and tasks are available. To tackle this problem, we propose data-driven methods to over-approximate the unknown dynamics and to infer the unknown specifications such that both set-membership models of the unknown dynamics and LTL formulas are guaranteed to include the ground truth model and specification/task. Moreover, we present an optimization-based algorithm for analyzing the distinguishability of a set of learned/inferred model-task pairs as well as a model discrimination algorithm for ruling out model-task pairs from this set that are inconsistent with new observations at run time. Further, we present an approach for reducing the size of inferred specifications to increase the computational efficiency of the model discriminatio
    
[^11]: 基于车辆出现的停车位检测

    Vehicle Occurrence-based Parking Space Detection. (arXiv:2306.09940v1 [cs.CV])

    [http://arxiv.org/abs/2306.09940](http://arxiv.org/abs/2306.09940)

    本文提出了一种利用车辆出现信息生成热力图的自动检测停车位方法，并在PKLot和CNRPark-EXT数据集上取得了较高的准确率。

    

    智能停车解决方案利用传感器、相机和数据分析提高停车效率、减少交通拥堵。计算机视觉方法近年来广泛用于停车场管理问题的解决，但大多数作品假定停车位是手动标注的，影响部署的成本和可行性。为了填补这一空白，本研究提出了一种自动检测停车位的方法，该方法接收一个停车场图像序列，并返回一个标识检测到的停车位的坐标列表。所提出的方法采用实例分割来识别汽车，并使用车辆出现来生成停车位的热力图。来自PKLot和CNRPark-EXT停车场数据集的12个不同子集的结果表明，该方法实现了最高95.60％的AP25分数和最高79.90％的AP50分数。

    Smart-parking solutions use sensors, cameras, and data analysis to improve parking efficiency and reduce traffic congestion. Computer vision-based methods have been used extensively in recent years to tackle the problem of parking lot management, but most of the works assume that the parking spots are manually labeled, impacting the cost and feasibility of deployment. To fill this gap, this work presents an automatic parking space detection method, which receives a sequence of images of a parking lot and returns a list of coordinates identifying the detected parking spaces. The proposed method employs instance segmentation to identify cars and, using vehicle occurrence, generate a heat map of parking spaces. The results using twelve different subsets from the PKLot and CNRPark-EXT parking lot datasets show that the method achieved an AP25 score up to 95.60\% and AP50 score up to 79.90\%.
    
[^12]: 训练好的Transformer在上下文中学习线性模型

    Trained Transformers Learn Linear Models In-Context. (arXiv:2306.09927v1 [stat.ML])

    [http://arxiv.org/abs/2306.09927](http://arxiv.org/abs/2306.09927)

    本文研究了Transformer在具有单层线性自注意层的线性回归任务上通过梯度流进行训练的ICL机制，揭示了梯度流具有找到目标函数全局最小值的能力。

    

    基于注意力的神经网络，例如Transformers，在上下文学习（ICL）方面表现出了非凡的能力：给定一个来自未见过的任务的短语序列的提示，它们可以制定相关的每个令牌和下一个令牌的预测，而不需要任何参数更新。通过将标记的训练数据和未标记的测试数据序列嵌入到提示中，这使得Transformer表现得像有监督学习算法。事实上，最近的工作表明，在随机实例上训练Transformer体系结构的线性回归问题时，这些模型的预测会模仿普通最小二乘法的预测。

    Attention-based neural networks such as transformers have demonstrated a remarkable ability to exhibit in-context learning (ICL): Given a short prompt sequence of tokens from an unseen task, they can formulate relevant per-token and next-token predictions without any parameter updates. By embedding a sequence of labeled training data and unlabeled test data as a prompt, this allows for transformers to behave like supervised learning algorithms. Indeed, recent work has shown that when training transformer architectures over random instances of linear regression problems, these models' predictions mimic those of ordinary least squares.  Towards understanding the mechanisms underlying this phenomenon, we investigate the dynamics of ICL in transformers with a single linear self-attention layer trained by gradient flow on linear regression tasks. We show that despite non-convexity, gradient flow with a suitable random initialization finds a global minimum of the objective function. At this 
    
[^13]: 学习总结和回答与虚拟机器人过去动作相关的问题

    Learning to Summarize and Answer Questions about a Virtual Robot's Past Actions. (arXiv:2306.09922v1 [cs.RO])

    [http://arxiv.org/abs/2306.09922](http://arxiv.org/abs/2306.09922)

    本论文介绍了一种学习总结和回答机器人动作历史的方法，能够通过一种语言模型同时完成总结和回答任务，并提供了自动生成问题和答案的方法来进行训练。此方法能够实现从问题回答中学习对象表示的零-shot转移。

    

    当机器人执行长序列的动作时，用户需要轻松、可靠地了解它们所做的事情。因此，我们演示了使用自然语言学习总结和回答关于机器人代理过去动作的问题的任务。一个核心为大型语言模型的单一系统被训练用于总结和回答关于虚拟机器人的自我中心视频帧和问题提示的动作序列。为了实现问题回答的训练，我们开发了一种方法来自动生成关于对象、动作和在虚拟环境中机器人动作序列期间动作发生的时间顺序的英文问题和答案。将一个模型用于总结和回答问题使得从问题回答中学习的对象表示的零-shot转移能够提高动作总结的能力，包括在训练中未见过的对象。

    When robots perform long action sequences, users will want to easily and reliably find out what they have done. We therefore demonstrate the task of learning to summarize and answer questions about a robot agent's past actions using natural language alone. A single system with a large language model at its core is trained to both summarize and answer questions about action sequences given ego-centric video frames of a virtual robot and a question prompt. To enable training of question answering, we develop a method to automatically generate English-language questions and answers about objects, actions, and the temporal order in which actions occurred during episodes of robot action in the virtual environment. Training one model to both summarize and answer questions enables zero-shot transfer of representations of objects learned through question answering to improved action summarization. % involving objects not seen in training to summarize.
    
[^14]: 理性一无所感：在自然语言推理中重新操作中立性

    No Strong Feelings One Way or Another: Re-operationalizing Neutrality in Natural Language Inference. (arXiv:2306.09918v1 [cs.CL])

    [http://arxiv.org/abs/2306.09918](http://arxiv.org/abs/2306.09918)

    本文讨论了自然语言推理(NLI)中标签操作存在的缺点，提出了NLI需要更精细的评价体系的观点，并比较了处理注释者一致性的方法。

    

    自然语言推理(NLI)一直是评估语言模型推理能力的基石任务。然而，NLI中使用的标准三分类模式在评估模型捕捉人类推理的微妙之处方面存在已知缺点。在本文中，我们认为当前NLI数据集中中立标签的操作化效度很低，解释不一致，并且通常忽略至少一个重要的中立意义。我们揭示了这些缺点的有害影响，在某些情况下导致注释数据集实际上降低了下游任务的性能。我们比较了处理注释者不一致的方法，并确定了最近的一个NLI数据集中存在的问题操作化的注释者研究的缺陷。我们的研究结果凸显了NLI需要更精细的评估框架，我们希望引发NLP社区对于改善语言模型评估的讨论和行动。

    Natural Language Inference (NLI) has been a cornerstone task in evaluating language models' inferential reasoning capabilities. However, the standard three-way classification scheme used in NLI has well-known shortcomings in evaluating models' ability to capture the nuances of natural human reasoning. In this paper, we argue that the operationalization of the neutral label in current NLI datasets has low validity, is interpreted inconsistently, and that at least one important sense of neutrality is often ignored. We uncover the detrimental impact of these shortcomings, which in some cases leads to annotation datasets that actually decrease performance on downstream tasks. We compare approaches of handling annotator disagreement and identify flaws in a recent NLI dataset that designs an annotator study based on a problematic operationalization. Our findings highlight the need for a more refined evaluation framework for NLI, and we hope to spark further discussion and action in the NLP c
    
[^15]: 揭秘 GPT 自我修复代码生成能力

    Demystifying GPT Self-Repair for Code Generation. (arXiv:2306.09896v1 [cs.CL])

    [http://arxiv.org/abs/2306.09896](http://arxiv.org/abs/2306.09896)

    本文分析了 GPT-3.5 和 GPT-4 在 APPS 数据集上执行自我修复的能力，发现自我修复在 GPT 模型中的有效性严重取决于任务的质量和复杂性，自我修复在较短和较简单的任务中效果更好，仅在某些代码部分上应用自我修复可以非常有效，本文提出的引导修复方法在 APPS 数据集上获得性能提升。

    

    大型语言模型 (LLM) 在代码生成方面表现出色，但在挑战性编程任务上仍面临困难。自我修复——即模型调试并修复自己的代码——最近成为提高性能的一种流行方式。然而，关于自我修复如何有效地发挥作用的研究还非常有限。有人会想知道，当同一模型生成代码时，模型究竟能否提供准确的反馈。在本文中，我们分析了 GPT-3.5 和 GPT-4 在 APPS 数据集上执行自我修复的能力，这是一个由多种编码挑战组成的具有挑战性的数据集。我们首先建立了一种新的评估策略 pass@t，该策略衡量了任务通过率与从模型中抽样的总标记数，从而实现对仅基于抽样的方法的公平比较。通过这种评估策略，我们发现自我修复在 GPT 模型中的有效性严重取决于任务的质量和复杂性，并确定了影响自我修复表现的几个因素。具体而言，我们发现，在输入噪声较少且模型对初始输出不太自信的较短和较简单的任务中，自我修复效果更好。我们还表明，仅在某些代码部分上应用自我修复可以非常有效。此外，我们提出了一种新的引导修复方法，利用外部反馈来增强 GPT 模型的自我修复能力，在 APPS 数据集上获得性能提升。

    Large Language Models (LLMs) have shown remarkable aptitude in code generation but still struggle on challenging programming tasks. Self-repair -in which the model debugs and fixes mistakes in its own code -- has recently become a popular way to boost performance in these settings. However, only very limited studies on how and when self-repair works effectively exist in the literature, and one might wonder to what extent a model is really capable of providing accurate feedback on why the code is wrong when that code was generated by the same model. In this paper, we analyze GPT-3.5 and GPT-4's ability to perform self-repair on APPS, a challenging dataset consisting of diverse coding challenges. To do so, we first establish a new evaluation strategy dubbed pass@t that measures the pass rate of the tasks against the total number of tokens sampled from the model, enabling a fair comparison to purely sampling-based approaches. With this evaluation strategy, we find that the effectiveness
    
[^16]: Jumanji: JAX中一套多样化可扩展的强化学习环境

    Jumanji: a Diverse Suite of Scalable Reinforcement Learning Environments in JAX. (arXiv:2306.09884v1 [cs.LG])

    [http://arxiv.org/abs/2306.09884](http://arxiv.org/abs/2306.09884)

    Jumanji是JAX中一套可扩展的强化学习系统，提供了一系列高度可定制的环境，具有快速、灵活、可扩展和模块化特点，利用硬件加速器赋能更有能力的代理人。

    

    开源强化学习环境在推动AI算法的发展方面起到了关键作用。现代强化学习研究需要模拟环境具备性能、可扩展性和模块化特点，以扩展其在更广泛的实际应用中的可用性。因此，我们提出了Jumanji，这是一套设计用于快速、灵活和可扩展的不同RL环境的强化学习系统。Jumanji提供了一系列的环境，专注于工业中经常遇到的组合问题，以及挑战性的一般决策任务。通过利用JAX和GPU、TPU等硬件加速器的效率，Jumanji能够迅速迭代研究思路和大规模实验，最终赋能更有能力的代理人。与现有的强化学习环境套件不同，Jumanji具有高度可定制性，允许用户根据其需求调整初始状态分布和问题复杂度。

    Open-source reinforcement learning (RL) environments have played a crucial role in driving progress in the development of AI algorithms. In modern RL research, there is a need for simulated environments that are performant, scalable, and modular to enable their utilization in a wider range of potential real-world applications. Therefore, we present Jumanji, a suite of diverse RL environments specifically designed to be fast, flexible, and scalable. Jumanji provides a suite of environments focusing on combinatorial problems frequently encountered in industry, as well as challenging general decision-making tasks. By leveraging the efficiency of JAX and hardware accelerators like GPUs and TPUs, Jumanji enables rapid iteration of research ideas and large-scale experimentation, ultimately empowering more capable agents. Unlike existing RL environment suites, Jumanji is highly customizable, allowing users to tailor the initial state distribution and problem complexity to their needs. Further
    
[^17]: 可泛化的一次性绳索操作策略及其参数感知性。

    Generalizable One-shot Rope Manipulation with Parameter-Aware Policy. (arXiv:2306.09872v1 [cs.LG])

    [http://arxiv.org/abs/2306.09872](http://arxiv.org/abs/2306.09872)

    GenORM通过增加可变形绳索参数和使用各种可变形绳索的模拟训练操作策略，实现利用一次真实演示处理不同可形变绳索，从而节省演示时间和提高适用性。

    

    以绳索在运动过程中的固有不确定性为因素，以往绳索操作方法往往需要数百次真实演示来为每个绳索训练操作策略，即使是简单的“到达目标”任务，这限制了它们在我们不断变化的世界中的应用。为了解决这个问题，我们介绍了GenORM，一个框架，它可以让操作策略通过一次真实演示就可以处理不同可形变的绳索。我们通过在策略上增加可变形绳索参数并使用各种模拟可变形绳索来训练它，使策略能够根据不同的绳索参数调整行动。在推断时，GenORM通过最小化真实演示和模拟点云的网格密度差异来估计可变形绳索参数。通过可微分物理模拟器的帮助，我们仅需要一次演示数据就可以处理不同的绳索。

    Due to the inherent uncertainty in their deformability during motion, previous methods in rope manipulation often require hundreds of real-world demonstrations to train a manipulation policy for each rope, even for simple tasks such as rope goal reaching, which hinder their applications in our ever-changing world. To address this issue, we introduce GenORM, a framework that allows the manipulation policy to handle different deformable ropes with a single real-world demonstration. To achieve this, we augment the policy by conditioning it on deformable rope parameters and training it with a diverse range of simulated deformable ropes so that the policy can adjust actions based on different rope parameters. At the time of inference, given a new rope, GenORM estimates the deformable rope parameters by minimizing the disparity between the grid density of point clouds of real-world demonstrations and simulations. With the help of a differentiable physics simulator, we require only a single r
    
[^18]: 文本到图像扩散模型中的能量交叉注意力用于贝叶斯上下文更新

    Energy-Based Cross Attention for Bayesian Context Update in Text-to-Image Diffusion Models. (arXiv:2306.09869v1 [cs.CV])

    [http://arxiv.org/abs/2306.09869](http://arxiv.org/abs/2306.09869)

    本论文提出了能量交叉注意力的EBM框架，通过更新和转移上下文向量，隐式最小化能量函数的嵌套层次，优化文本到图像扩散模型的语义对齐问题，实现零样本组合生成。

    

    尽管文本到图像扩散模型在图像生成任务中表现出色，但最近的研究提出了一个问题，即生成的图像有时无法捕捉到文本提示的预期语义内容，这种现象通常被称为语义错位。为了解决这个问题，我们提出了一种新颖的基于能量的模型（EBM）框架。具体而言，我们首先在去噪自编码器的每个交叉注意力层中制定潜在图像表示和文本嵌入的EBM。然后，我们获得上下文向量的对数后验梯度，可以更新和转移到后续的交叉注意力层，从而隐式地最小化嵌套层次的能量函数。我们的潜在EBMs还允许零样本组合生成，即通过不同上下文的交叉注意力输出的线性组合。通过大量实验，我们证明了所提出的方法在处理各种图像生成任务方面非常有效，并可以显著降低文本提示和生成图像之间的语义错位现象。

    Despite the remarkable performance of text-to-image diffusion models in image generation tasks, recent studies have raised the issue that generated images sometimes cannot capture the intended semantic contents of the text prompts, which phenomenon is often called semantic misalignment. To address this, here we present a novel energy-based model (EBM) framework. Specifically, we first formulate EBMs of latent image representations and text embeddings in each cross-attention layer of the denoising autoencoder. Then, we obtain the gradient of the log posterior of context vectors, which can be updated and transferred to the subsequent cross-attention layer, thereby implicitly minimizing a nested hierarchy of energy functions. Our latent EBMs further allow zero-shot compositional generation as a linear combination of cross-attention outputs from different contexts. Using extensive experiments, we demonstrate that the proposed method is highly effective in handling various image generation 
    
[^19]: DoubleAdapt：一种用于股票趋势预测的增量学习元学习方法

    DoubleAdapt: A Meta-learning Approach to Incremental Learning for Stock Trend Forecasting. (arXiv:2306.09862v1 [q-fin.ST])

    [http://arxiv.org/abs/2306.09862](http://arxiv.org/abs/2306.09862)

    DoubleAdapt是一个增量学习的方法，用于股票趋势预测。它利用元学习技术自动学习如何将股票数据适应到本地平稳分布空间中，从而有效地适应数据和模型，减轻分布漂移的影响。

    

    股票趋势预测是量化投资的基本任务之一，准确预测价格趋势是不可或缺的。作为一项在线服务，股票数据随时随地持续到达。使用最新数据对预测模型进行增量更新是实用而高效的，因为这些新数据可能揭示了未来股票市场中会重复出现的一些新模式。然而，由于分布漂移（即概念漂移）的挑战，股票趋势预测的增量学习仍然没有得到充分探索。随着股票市场动态演变，未来数据的分布可能会与增量数据稍微或显着地不同，从而阻碍增量更新的有效性。为了解决这一挑战，我们提出了一个利用两个适配器的端到端框架——DoubleAdapt，可以有效地适应数据和模型，以减轻分布漂移的影响。我们的关键洞察力是利用元学习技术自动学习如何将股票数据适应到本地平稳分布空间中。

    Stock trend forecasting is a fundamental task of quantitative investment where precise predictions of price trends are indispensable. As an online service, stock data continuously arrive over time. It is practical and efficient to incrementally update the forecast model with the latest data which may reveal some new patterns recurring in the future stock market. However, incremental learning for stock trend forecasting still remains under-explored due to the challenge of distribution shifts (a.k.a. concept drifts). With the stock market dynamically evolving, the distribution of future data can slightly or significantly differ from incremental data, hindering the effectiveness of incremental updates. To address this challenge, we propose DoubleAdapt, an end-to-end framework with two adapters, which can effectively adapt the data and the model to mitigate the effects of distribution shifts. Our key insight is to automatically learn how to adapt stock data into a locally stationary distri
    
[^20]: 大型语言模型真的是良好的逻辑推理者吗？基于演绎、归纳和阿布达斯观点的全面评估。

    Are Large Language Models Really Good Logical Reasoners? A Comprehensive Evaluation From Deductive, Inductive and Abductive Views. (arXiv:2306.09841v1 [cs.CL])

    [http://arxiv.org/abs/2306.09841](http://arxiv.org/abs/2306.09841)

    本文评估了大型语言模型的逻辑推理能力，选择了15个典型数据集，考虑了演绎、归纳、阿布达斯和混合推理形式，并选择了三个代表性的LLMs进行零样本、一次和三次的设置下评估。提出精细级别的评估方法。

    

    大型语言模型(LLMs)在各种自然语言任务中取得了巨大成功。对LLMs的具体推理能力进行评估，如多语言推理和数学推理，引起了广泛关注。然而，作为关键推理视角之一，逻辑推理能力还没有得到彻底评估。本文旨在填补这些差距并提供全面的评估。首先，为了进行系统化评估，本文选择了15个典型的逻辑推理数据集，并将它们组织成演绎、归纳、阿布达斯和混合形式的推理设置。考虑评估的全面性，我们选择了三个代表性的LLMs（text-davinci-003，ChatGPT和BARD），并在零样本、一次和三次的设置下对所有选择的数据集进行评估。其次，与以往仅依赖简单指标（如准确性）的评估不同，我们提出了从目标推理角度进行的精细级别评估。

    Large Language Models (LLMs) have achieved great success in various natural language tasks. It has aroused much interest in evaluating the specific reasoning capability of LLMs, such as multilingual reasoning and mathematical reasoning. However, as one of the key reasoning perspectives, logical reasoning capability has not yet been thoroughly evaluated. In this work, we aim to bridge those gaps and provide comprehensive evaluations. Firstly, to offer systematic evaluations, this paper selects fifteen typical logical reasoning datasets and organizes them into deductive, inductive, abductive and mixed-form reasoning settings. Considering the comprehensiveness of evaluations, we include three representative LLMs (i.e., text-davinci-003, ChatGPT and BARD) and evaluate them on all selected datasets under zero-shot, one-shot and three-shot settings. Secondly, different from previous evaluations relying only on simple metrics (e.g., accuracy), we propose fine-level evaluations from objective 
    
[^21]: 存在偏差时基于多个排名的子集选择：多赢家投票评分函数的公平限制的有效性

    Subset Selection Based On Multiple Rankings in the Presence of Bias: Effectiveness of Fairness Constraints for Multiwinner Voting Score Functions. (arXiv:2306.09835v1 [cs.CY])

    [http://arxiv.org/abs/2306.09835](http://arxiv.org/abs/2306.09835)

    本文研究了存在偏差时的子集选择问题，提出了在兼顾公平的前提下，使所选的子集满足群体公平性约束来提高选择质量，不同的多赢家评分函数对于公平性的依赖性可能不同。

    

    本文考虑了子集选择问题，其中给定多个项目的排名，目标是选择最高“质量”的子集。来自多赢家投票文献的评分函数已用于将排名聚合为子集的质量得分。我们研究了在此设置下的子集选择问题，当排名可能包含对一组项目的系统性或无意识的偏见时，我们的目标是在兼顾公平的前提下，提高选择质量。对于输入排名和偏见的一般模型，我们表明要求所选的子集满足群体公平性约束，可以提高选择在没有偏见的排名中的质量。重要的是，我们表明，对于公平性限制要有效，不同的多赢家评分函数可能需要极其不同数量的排名：对于一些函数，公平性限制需要指数级数量的排名才能恢复接近最优解，而对于其他函数，这种依赖性仅为多项式。这个结果依赖于一个新颖的概念。

    We consider the problem of subset selection where one is given multiple rankings of items and the goal is to select the highest ``quality'' subset. Score functions from the multiwinner voting literature have been used to aggregate rankings into quality scores for subsets. We study this setting of subset selection problems when, in addition, rankings may contain systemic or unconscious biases toward a group of items. For a general model of input rankings and biases, we show that requiring the selected subset to satisfy group fairness constraints can improve the quality of the selection with respect to unbiased rankings. Importantly, we show that for fairness constraints to be effective, different multiwinner score functions may require a drastically different number of rankings: While for some functions, fairness constraints need an exponential number of rankings to recover a close-to-optimal solution, for others, this dependency is only polynomial. This result relies on a novel notion 
    
[^22]: 基于流程知识注入的医生友好型解释学习

    Process Knowledge-infused Learning for Clinician-friendly Explanations. (arXiv:2306.09824v1 [cs.CL])

    [http://arxiv.org/abs/2306.09824](http://arxiv.org/abs/2306.09824)

    本论文介绍了一种名为PK-iL的新学习范式，可以在语言模型输出上添加临床流程知识结构，从而使医生能够理解和解释模型的输出，从而为心理卫生护理和预防策略提供支持和帮助。

    

    语言模型有潜力利用社交媒体数据评估心理健康。通过分析在线帖子和交流，这些模型可以检测表明抑郁症、焦虑症或自杀倾向等心理健康情况的模式。它们通过关键词、语言标记和情感来洞察个体的心理健康状况。这些信息对于早期检测、干预和支持至关重要，可以改善心理卫生护理和预防策略。然而，利用语言模型从社交媒体对心理健康进行评估有两个局限性：(1)它们不会将帖子与临床医生的诊断过程进行比较，(2)使用临床医生能够理解的概念（即医生友好型解释）解释语言模型的输出是具有挑战性的。在本研究中，我们介绍了基于流程知识注入的学习（PK-iL），这是一种新的学习范式，可以在语言模型输出上添加临床流程知识结构，使医生能够理解和解释模型的输出。

    Language models have the potential to assess mental health using social media data. By analyzing online posts and conversations, these models can detect patterns indicating mental health conditions like depression, anxiety, or suicidal thoughts. They examine keywords, language markers, and sentiment to gain insights into an individual's mental well-being. This information is crucial for early detection, intervention, and support, improving mental health care and prevention strategies. However, using language models for mental health assessments from social media has two limitations: (1) They do not compare posts against clinicians' diagnostic processes, and (2) It's challenging to explain language model outputs using concepts that the clinician can understand, i.e., clinician-friendly explanations. In this study, we introduce Process Knowledge-infused Learning (PK-iL), a new learning paradigm that layers clinical process knowledge structures on language model outputs, enabling clinicia
    
[^23]: 通过大型语言模型，使用ORIBA将艺术家的原创角色转化为聊天机器人以激发创造力

    Inspire creativity with ORIBA: Transform Artists' Original Characters into Chatbots through Large Language Model. (arXiv:2306.09776v1 [cs.MM])

    [http://arxiv.org/abs/2306.09776](http://arxiv.org/abs/2306.09776)

    该论文介绍了一种名为ORIBA的聊天机器人，可定制的AI代理，能够与插画家的原创角色进行交互，以加强创意领域中的人机交互。

    

    该研究探讨插图艺术和人工智能（AI）的交集，重点关注插画家如何与代表其原创角色（OC）的AI代理进行互动。我们推出了“ORIBA”，这是一个可定制的AI聊天机器人，允许插画家与其OC进行对话。此方法不仅使艺术家能够收到OC的回应，还能观察其内心独白和行为。尽管存在着艺术家和AI之间的紧张关系，我们的研究探索了鼓舞人心的创新合作方法，旨在增强创意领域中的人机交互，其潜在应用可以扩展到交互式叙事等领域。

    This research delves into the intersection of illustration art and artificial intelligence (AI), focusing on how illustrators engage with AI agents that embody their original characters (OCs). We introduce 'ORIBA', a customizable AI chatbot that enables illustrators to converse with their OCs. This approach allows artists to not only receive responses from their OCs but also to observe their inner monologues and behavior. Despite the existing tension between artists and AI, our study explores innovative collaboration methods that are inspiring to illustrators. By examining the impact of AI on the creative process and the boundaries of authorship, we aim to enhance human-AI interactions in creative fields, with potential applications extending beyond illustration to interactive storytelling and more.
    
[^24]: 礼貌刻板印象和攻击向量：日韩语言模型中的性别刻板印象

    Politeness Stereotypes and Attack Vectors: Gender Stereotypes in Japanese and Korean Language Models. (arXiv:2306.09752v1 [cs.CL])

    [http://arxiv.org/abs/2306.09752](http://arxiv.org/abs/2306.09752)

    中文总结该论文主要研究了日语和韩语语言模型中与礼貌水平相关的语法性别偏见，发现礼貌水平是网络欺凌检测模型中的攻击向量。

    

    为了跟上大型语言模型的快速发展和使用，性别偏见研究在自然语言处理中变得越来越普遍。然而，非英语偏见研究还处于起步阶段，大多数工作都集中在英语上。在我们的工作中，我们研究了与礼貌水平相关的语法性别偏见在日语和韩语语言模型中的表现。这些语言的语言学研究已经确定了性别偏见和礼貌水平之间的联系，但尚不清楚语言模型是否会复制这些偏见。我们通过模板分析男性和女性语法性别的相对预测概率，并发现非正式礼貌语言最能表现出女性语法性别，而粗鲁和正式语言最能表现出男性语法性别。此外，我们发现礼貌水平是网络欺凌检测模型中的一种攻击向量，可以通过简单的技巧回避检测。

    In efforts to keep up with the rapid progress and use of large language models, gender bias research is becoming more prevalent in NLP. Non-English bias research, however, is still in its infancy with most work focusing on English. In our work, we study how grammatical gender bias relating to politeness levels manifests in Japanese and Korean language models. Linguistic studies in these languages have identified a connection between gender bias and politeness levels, however it is not yet known if language models reproduce these biases. We analyze relative prediction probabilities of the male and female grammatical genders using templates and find that informal polite speech is most indicative of the female grammatical gender, while rude and formal speech is most indicative of the male grammatical gender. Further, we find politeness levels to be an attack vector for allocational gender bias in cyberbullying detection models. Cyberbullies can evade detection through simple techniques ab
    
[^25]: Fedstellar：一个去中心化联邦学习平台

    Fedstellar: A Platform for Decentralized Federated Learning. (arXiv:2306.09750v1 [cs.LG])

    [http://arxiv.org/abs/2306.09750](http://arxiv.org/abs/2306.09750)

    Fedstellar是一个联邦学习平台，支持物理或虚拟设备的去中心化、半去中心化和中心化的方式训练模型，旨在解决现有平台在处理异构联盟网络拓扑等问题时的挑战。

    

    2016年，谷歌提出了联邦学习（FL）作为一种新的范式，可以在保护数据隐私的同时跨联盟参与者训练机器学习（ML）模型。虽然中心化联邦学习（CFL）是最常用的方法，但它存在通信瓶颈、单点故障和对中央服务器的依赖等局限。去中心化联邦学习（DFL）通过实现去中心化模型聚合和最小化对中央实体的依赖，来解决这些问题。然而，目前训练DFL模型的平台在处理异构联盟网络拓扑等关键问题方面存在困难。为了克服这些挑战，本文提出了Fedstellar，这是一个新型的平台，旨在在物理或虚拟设备的不同联盟中以去中心化、半去中心化和中心化的方式训练FL模型。

    In 2016, Google proposed Federated Learning (FL) as a novel paradigm to train Machine Learning (ML) models across the participants of a federation while preserving data privacy. Since its birth, Centralized FL (CFL) has been the most used approach, where a central entity aggregates participants' models to create a global one. However, CFL presents limitations such as communication bottlenecks, single point of failure, and reliance on a central server. Decentralized Federated Learning (DFL) addresses these issues by enabling decentralized model aggregation and minimizing dependency on a central entity. Despite these advances, current platforms training DFL models struggle with key issues such as managing heterogeneous federation network topologies. To overcome these challenges, this paper presents Fedstellar, a novel platform designed to train FL models in a decentralized, semi-decentralized, and centralized fashion across diverse federations of physical or virtualized devices. The Feds
    
[^26]: 《具有经验回放的时序差分学习》

    Temporal Difference Learning with Experience Replay. (arXiv:2306.09746v1 [cs.LG])

    [http://arxiv.org/abs/2306.09746](http://arxiv.org/abs/2306.09746)

    本文提出具有经验回放的TD学习，在马尔科夫观测模型下，通过对噪声项的分解，提供了有限时间误差界限，可以通过调整回放缓冲区和小批量的大小来控制误差。

    

    时序差分学习被普遍认为是强化学习领域中最受欢迎的算法之一。本文研究了其有限时间行为，包括均方误差和样本复杂度的有限时间界限。在经验方面，经验回放是深度强化学习算法成功的关键因素之一，但其在强化学习中的理论效应尚未被完全理解。本文提出了马尔科夫噪声项的简单分解，并为具有经验回放的TD学习提供了有限时间误差界限。具体而言，在马尔科夫观测模型下，我们证明了对于平均迭代和最终迭代情况下，常数步长引起的误差术语可以通过回放缓冲区的大小和从经验回放缓冲区中抽样的小批量来有效控制。

    Temporal-difference (TD) learning is widely regarded as one of the most popular algorithms in reinforcement learning (RL). Despite its widespread use, it has only been recently that researchers have begun to actively study its finite time behavior, including the finite time bound on mean squared error and sample complexity. On the empirical side, experience replay has been a key ingredient in the success of deep RL algorithms, but its theoretical effects on RL have yet to be fully understood. In this paper, we present a simple decomposition of the Markovian noise terms and provide finite-time error bounds for TD-learning with experience replay. Specifically, under the Markovian observation model, we demonstrate that for both the averaged iterate and final iterate cases, the error term induced by a constant step-size can be effectively controlled by the size of the replay buffer and the mini-batch sampled from the experience replay buffer.
    
[^27]: 推动 ChatGPT 在自然语言处理任务上的极限

    Pushing the Limits of ChatGPT on NLP Tasks. (arXiv:2306.09719v1 [cs.CL])

    [http://arxiv.org/abs/2306.09719](http://arxiv.org/abs/2306.09719)

    本研究提出了一系列通用模块以解决 ChatGPT 在自然语言处理任务中的弱点，包括利用多个提示符来适应更多演示、使用精细调整模型以获得更好的演示检索、转换任务为更适合生成性质的格式以及采用针对 NLP 任务设计的推理策略。

    

    尽管 ChatGPT 取得了成功，但在大多数自然语言处理任务上，其表现仍远低于基线模型。本研究探究了其中的原因，发现其表现欠佳的原因主要有：（1）提示符中的令牌限制不允许充分利用监督数据集；（2）ChatGPT 生成性质与 NLP 任务之间存在不匹配；（3）基于语言模型的固有弱点，如产生幻觉、过度关注特定关键词等。本研究提出了一系列通用模块以解决这些问题，旨在推动 ChatGPT 在 NLP 任务上的极限。我们提出的模块包括：（1）一种输入多提示的策略，使用多个提示符来适应更多演示；（2）使用精细调整模型以获得更好的演示检索；（3）将任务转换为更适合生成性质的格式；（4）采用针对 NLP 任务设计的推理策略。

    Despite the success of ChatGPT, its performances on most NLP tasks are still well below the supervised baselines. In this work, we looked into the causes, and discovered that its subpar performance was caused by the following factors: (1) token limit in the prompt does not allow for the full utilization of the supervised datasets; (2) mismatch between the generation nature of ChatGPT and NLP tasks; (3) intrinsic pitfalls of LLMs models, e.g., hallucination, overly focus on certain keywords, etc.  In this work, we propose a collection of general modules to address these issues, in an attempt to push the limits of ChatGPT on NLP tasks. Our proposed modules include (1) a one-input-multiple-prompts strategy that employs multiple prompts for one input to accommodate more demonstrations; (2) using fine-tuned models for better demonstration retrieval; (3) transforming tasks to formats that are more tailored to the generation nature; (4) employing reasoning strategies that are tailored to addr
    
[^28]: 自我注意力与自监督学习在医学图像分类领域中的标签噪声容忍方法研究

    Label-noise-tolerant medical image classification via self-attention and self-supervised learning. (arXiv:2306.09718v1 [cs.CV])

    [http://arxiv.org/abs/2306.09718](http://arxiv.org/abs/2306.09718)

    本文提出结合对比学习和自我注意力混合策略的抗噪声训练方法，以缓解医学图像分类中噪声标签的影响，实验证明该方法显著提高了DNN对标签噪声的鲁棒性和准确性。

    

    深度神经网络（DNN）已广泛应用于医学图像分类，并取得了显著的分类性能。然而，这些成就严重依赖于大规模准确注释的训练数据。然而，标签噪声不可避免地会在医学图像注释过程中被引入，因为标注过程严重依赖于注释人员的专业知识和经验。同时，DNN容易过拟合噪声标签，从而降低模型性能。因此，本文创新性地提出了一种抗噪声训练方法，以缓解医学图像分类中噪声标签的不利影响。具体而言，我们将对比学习和组内注意力混合策略纳入基础监督学习。特征提取器的对比学习有助于增强DNN的视觉表示能力。组内注意力混合模块构建组并为组内样本分配自注意力权重，随后整合加权特征以减少标签噪声的影响。在多个医学图像数据集上的实验表明，该方法显著提高了DNN对标签噪声的鲁棒性和准确性。

    Deep neural networks (DNNs) have been widely applied in medical image classification and achieve remarkable classification performance. These achievements heavily depend on large-scale accurately annotated training data. However, label noise is inevitably introduced in the medical image annotation, as the labeling process heavily relies on the expertise and experience of annotators. Meanwhile, DNNs suffer from overfitting noisy labels, degrading the performance of models. Therefore, in this work, we innovatively devise noise-robust training approach to mitigate the adverse effects of noisy labels in medical image classification. Specifically, we incorporate contrastive learning and intra-group attention mixup strategies into the vanilla supervised learning. The contrastive learning for feature extractor helps to enhance visual representation of DNNs. The intra-group attention mixup module constructs groups and assigns self-attention weights for group-wise samples, and subsequently inte
    
[^29]: 半离线强化学习用于优化文本生成

    Semi-Offline Reinforcement Learning for Optimized Text Generation. (arXiv:2306.09712v1 [cs.LG])

    [http://arxiv.org/abs/2306.09712](http://arxiv.org/abs/2306.09712)

    该研究提出了一种半离线强化学习范式，该范式平衡了探索能力和培训成本，提供了一个理论基础来比较不同的强化学习设置，并在优化成本、渐近误差和过度拟合误差界方面实现了最优的RL设置。实验结果表明，该方法高效且性能优异。

    

    在强化学习中，与环境交互有两种主要方式：在线和离线。在线方法探索环境所需时间较长，而离线方法通过牺牲探索能力有效地获得奖励信号。我们提出了半离线RL，一种新的范式，可以平滑地从离线转换到在线设置，平衡探索能力和培训成本，并为比较不同RL设置提供理论基础。基于半离线公式，我们提出了在优化成本、渐近误差和过度拟合误差界方面最优的RL设置。广泛的实验表明，我们的半离线方法效率高，与最先进的方法相比具有可比性或更好的性能。

    In reinforcement learning (RL), there are two major settings for interacting with the environment: online and offline. Online methods explore the environment at significant time cost, and offline methods efficiently obtain reward signals by sacrificing exploration capability. We propose semi-offline RL, a novel paradigm that smoothly transits from offline to online settings, balances exploration capability and training cost, and provides a theoretical foundation for comparing different RL settings. Based on the semi-offline formulation, we present the RL setting that is optimal in terms of optimization cost, asymptotic error, and overfitting error bound. Extensive experiments show that our semi-offline approach is efficient and yields comparable or often better performance compared with state-of-the-art methods.
    
[^30]: 一种基于联合概率估计的一对一深度学习多分类模型

    Multi-Classification using One-versus-One Deep Learning Strategy with Joint Probability Estimates. (arXiv:2306.09668v1 [cs.LG])

    [http://arxiv.org/abs/2306.09668](http://arxiv.org/abs/2306.09668)

    本文提出了一种基于联合概率估计的一对一深度学习多分类模型，该模型通过特定的距离度量来校准二分类器的概率输出，并通过联合概率的距离最小化来获得对主体的类别概率估计。实验结果表明，该模型在多个应用中都具有更高的分类精度。

    

    One-versus-One（OvO）策略是一种多分类模型，它侧重于训练每一对类之间的二分类器。本文提出了一种新的OvO多分类模型，该模型采用联合概率估计方法，通过深度学习框架校准二分类器的概率输出，并通过联合概率的距离最小化来获得对主体的类别概率估计。实验表明，相对于传统方法，该模型具有更高的分类精度。

    The One-versus-One (OvO) strategy is an approach of multi-classification models which focuses on training binary classifiers between each pair of classes. While the OvO strategy takes advantage of balanced training data, the classification accuracy is usually hindered by the voting mechanism to combine all binary classifiers. In this paper, a novel OvO multi-classification model incorporating a joint probability measure is proposed under the deep learning framework. In the proposed model, a two-stage algorithm is developed to estimate the class probability from the pairwise binary classifiers. Given the binary classifiers, the pairwise probability estimate is calibrated by a distance measure on the separating feature hyperplane. From that, the class probability of the subject is estimated by solving a joint probability-based distance minimization problem. Numerical experiments in different applications show that the proposed model achieves generally higher classification accuracy than 
    
[^31]: 合作多目标强化学习用于交通信号控制和碳减排

    Cooperative Multi-Objective Reinforcement Learning for Traffic Signal Control and Carbon Emission Reduction. (arXiv:2306.09662v1 [cs.LG])

    [http://arxiv.org/abs/2306.09662](http://arxiv.org/abs/2306.09662)

    本文提出了一种合作的多目标架构，称为MOMA-DDPG，用于交通信号控制和碳减排问题。该方法涉及两种类型的智能体：一个专注于优化每个路口的本地交通，而另一个旨在优化全局交通吞吐量。结果显示，该方法优于现有最先进的方法，并解决了等待时间和碳排放量两个问题。

    

    现有的交通信号控制系统依赖于过于简化的基于规则的方法，甚至基于强化学习的方法也经常是次优的和不稳定的。为了解决这个问题，我们提出了一个合作的多目标架构，称为多目标多智能体深度确定性策略梯度（MOMA-DDPG），使用衰减权重来估计交通信号控制优化的多个奖励项。我们的方法涉及两种类型的智能体：一个专注于优化每个路口的本地交通，而另一个旨在优化全局交通吞吐量。我们使用从一个亚洲国家的交通摄像头收集到的真实世界交通数据来评估我们的方法。尽管包含了一个全局智能体，但我们的解决方案仍然是分散的，因为这个智能体在推理阶段不再是必要的。我们的结果证明了MOMA-DDPG的有效性，在所有性能指标上优于最先进的方法。此外，我们提出的系统最小化了等待时间和碳排放量两方面的问题。

    Existing traffic signal control systems rely on oversimplified rule-based methods, and even RL-based methods are often suboptimal and unstable. To address this, we propose a cooperative multi-objective architecture called Multi-Objective Multi-Agent Deep Deterministic Policy Gradient (MOMA-DDPG), which estimates multiple reward terms for traffic signal control optimization using age-decaying weights. Our approach involves two types of agents: one focuses on optimizing local traffic at each intersection, while the other aims to optimize global traffic throughput. We evaluate our method using real-world traffic data collected from an Asian country's traffic cameras. Despite the inclusion of a global agent, our solution remains decentralized as this agent is no longer necessary during the inference stage. Our results demonstrate the effectiveness of MOMA-DDPG, outperforming state-of-the-art methods across all performance metrics. Additionally, our proposed system minimizes both waiting ti
    
[^32]: BISCUIT: 从二进制交互中学习因果关系表征

    BISCUIT: Causal Representation Learning from Binary Interactions. (arXiv:2306.09643v1 [cs.LG])

    [http://arxiv.org/abs/2306.09643](http://arxiv.org/abs/2306.09643)

    本文提出了一种名为BISCUIT的方法，可以在许多常见的设置中确定因果变量，并在机器人启发的数据集上进行了测试，表现良好。

    

    在机器人和实体AI等应用中，识别环境中的因果变量以及如何对它们进行干预具有核心价值。本文提出了一种方法，即在许多常见的设置中，例如加性高斯噪声模型中仍然可以确定因果变量，如果智能体与因果变量的交互可以用未知的二进制变量描述。我们通过这一可识别性结果提出BISCUIT，一种同时学习因果变量及其对应二进制交互变量的方法。在三个机器人启发的数据集上，BISCUIT准确地识别出因果变量，甚至可以扩展到复杂的、逼真的实体AI环境中。

    Identifying the causal variables of an environment and how to intervene on them is of core value in applications such as robotics and embodied AI. While an agent can commonly interact with the environment and may implicitly perturb the behavior of some of these causal variables, often the targets it affects remain unknown. In this paper, we show that causal variables can still be identified for many common setups, e.g., additive Gaussian noise models, if the agent's interactions with a causal variable can be described by an unknown binary variable. This happens when each causal variable has two different mechanisms, e.g., an observational and an interventional one. Using this identifiability result, we propose BISCUIT, a method for simultaneously learning causal variables and their corresponding binary interaction variables. On three robotic-inspired datasets, BISCUIT accurately identifies causal variables and can even be scaled to complex, realistic environments for embodied AI.
    
[^33]: 基于大型语言模型的点击诱骗检测

    Clickbait Detection via Large Language Models. (arXiv:2306.09597v1 [cs.CL])

    [http://arxiv.org/abs/2306.09597](http://arxiv.org/abs/2306.09597)

    本文研究了大型语言模型在点击诱骗检测上的性能，结果表明LLM无法取得最佳结果且不能仅通过标题实现满意的检测。

    

    点击诱骗（Clickbait）会通过一些令人惊讶甚至引人入胜的标题来诱导用户进行点击，几乎渗透到所有在线内容发布者，如新闻门户和社交媒体。最近，大型语言模型 (LLM)已成为一种强大的工具，并在一系列NLP下游任务中取得了巨大成功。但是，LLM是否可以作为高质量的点击诱骗检测系统还不为人所知。本文分析了LLM在多个英文和中文基准数据集的少样本场景下的性能。实验结果表明，与最先进的深度和微调PLM方法相比，LLM无法达到最佳结果。与人类直觉不同，实验表明LLM不能仅通过标题实现满意的点击诱骗检测。

    Clickbait, which aims to induce users with some surprising and even thrilling headlines for increasing click-through rates, permeates almost all online content publishers, such as news portals and social media. Recently, Large Language Models (LLMs) have emerged as a powerful instrument and achieved tremendous success in a serious of NLP downstream tasks. However, it is not yet known whether LLMs can be served as a high-quality clickbait detection system. In this paper, we analyze the performance of LLMs in the few-shot scenarios on a number of English and Chinese benchmark datasets. Experimental results show that LLMs cannot achieve the best results compared to the state-of-the-art deep and fine-tuning PLMs methods. Different from the human intuition, the experiments demonstrated that LLMs cannot make satisfied clickbait detection just by the headlines.
    
[^34]: 结构化图模型先验下的协作学习

    Structured Cooperative Learning with Graphical Model Priors. (arXiv:2306.09595v1 [cs.LG])

    [http://arxiv.org/abs/2306.09595](http://arxiv.org/abs/2306.09595)

    本文提出了结构化协作学习算法，在不同设备之间通过协作完成分散任务。通过图模型先验生成的协作图，算法可以自动捕捉设备之间的跨任务相关性。

    

    我们研究了如何在分散设备上对不同任务进行个性化建模，这些设备的局部数据受限。我们提出了“结构化协作学习（SCooL）”，其中一个跨设备的协作图由图模型先验生成，以自动协调设备之间的相互学习。通过选择施加不同结构的图模型，我们可以通过变分推断推导出一类丰富的现有和新型去中心化学习算法。特别地，我们展示了三种 SCooL 的示例，在其中以 Dirac 分布、随机块模型（SBM）和注意力作为生成协作图的先验。这些 EM 类型的算法通过更新协作图和协同本地模型学习之间进行交替，仅通过监视模型更新来优化协作图，从而可以自动捕捉设备之间的跨任务相关性。

    We study how to train personalized models for different tasks on decentralized devices with limited local data. We propose "Structured Cooperative Learning (SCooL)", in which a cooperation graph across devices is generated by a graphical model prior to automatically coordinate mutual learning between devices. By choosing graphical models enforcing different structures, we can derive a rich class of existing and novel decentralized learning algorithms via variational inference. In particular, we show three instantiations of SCooL that adopt Dirac distribution, stochastic block model (SBM), and attention as the prior generating cooperation graphs. These EM-type algorithms alternate between updating the cooperation graph and cooperative learning of local models. They can automatically capture the cross-task correlations among devices by only monitoring their model updating in order to optimize the cooperation graph. We evaluate SCooL and compare it with existing decentralized learning met
    
[^35]: 基于条件MLM对比学习的句子嵌入技术CMLM-CSE

    CMLM-CSE: Based on Conditional MLM Contrastive Learning for Sentence Embeddings. (arXiv:2306.09594v1 [cs.CL])

    [http://arxiv.org/abs/2306.09594](http://arxiv.org/abs/2306.09594)

    本论文提出了一种基于条件MLM的无监督对比学习框架CMLM-CSE，强制句子嵌入学习更多的掩码词信息，可以在文本相似度任务中超越SimCSE。

    

    传统的比较学习句子嵌入技术直接使用编码器提取句子特征，然后通过比较损失函数进行学习。然而，这种方法过于关注句子主体，而忽略了句子中一些词对句子语义的影响。为此，我们提出了CMLM-CSE，这是一种基于条件MLM的无监督对比学习框架。在传统对比学习的基础上，增加一个附加的网络来集成句子嵌入以执行MLM任务，强制句子嵌入学习更多的掩码词信息。最后，当使用Bertbase作为预训练语言模型时，我们在文本相似度任务中比SimCSE高0.55个百分点，在使用Robertabase作为预训练语言模型时，在文本相似度任务中平均超过SimCSE 0.3个百分点。

    Traditional comparative learning sentence embedding directly uses the encoder to extract sentence features, and then passes in the comparative loss function for learning. However, this method pays too much attention to the sentence body and ignores the influence of some words in the sentence on the sentence semantics. To this end, we propose CMLM-CSE, an unsupervised contrastive learning framework based on conditional MLM. On the basis of traditional contrastive learning, an additional auxiliary network is added to integrate sentence embedding to perform MLM tasks, forcing sentence embedding to learn more masked word information. Finally, when Bertbase was used as the pretraining language model, we exceeded SimCSE by 0.55 percentage points on average in textual similarity tasks, and when Robertabase was used as the pretraining language model, we exceeded SimCSE by 0.3 percentage points on average in textual similarity tasks.
    
[^36]: 一个置信集的数量是否是一种衡量认知不确定性的好方法？

    Is the Volume of a Credal Set a Good Measure for Epistemic Uncertainty?. (arXiv:2306.09586v1 [cs.LG])

    [http://arxiv.org/abs/2306.09586](http://arxiv.org/abs/2306.09586)

    本文探讨了将不确定性表示为一个置信集而非单一概率分布的方法。并发现，在二元分类中，信任集的体积是一种有意义的衡量认知不确定性的方法，但在多类分类中则没有这种效果。

    

    充分的不确定性表示和量化在各种科学学科中变得非常重要，特别是在机器学习和人工智能领域。作为表示不确定性的一种替代方法，我们考虑信任集（一组概率分布的凸集）。信任集的几何表示作为$d$维多面体意味着对（认知）不确定性的几何直觉。在本文中，我们展示了在二元分类的情况下，信任集的几何表示的体积是认知不确定性的一种有意义的度量方法，但在多类分类时则不那么有效。我们的理论发现强调了在机器学习中指定和使用正确的不确定性度量方法以及意识到可能的风险的关键作用。

    Adequate uncertainty representation and quantification have become imperative in various scientific disciplines, especially in machine learning and artificial intelligence. As an alternative to representing uncertainty via one single probability measure, we consider credal sets (convex sets of probability measures). The geometric representation of credal sets as $d$-dimensional polytopes implies a geometric intuition about (epistemic) uncertainty. In this paper, we show that the volume of the geometric representation of a credal set is a meaningful measure of epistemic uncertainty in the case of binary classification, but less so for multi-class classification. Our theoretical findings highlight the crucial role of specifying and employing uncertainty measures in machine learning in an appropriate way, and for being aware of possible pitfalls.
    
[^37]: 不同的分词器在连续书写文字中的下游任务中的表现如何？以日语为例研究。

    How do different tokenizers perform on downstream tasks in scriptio continua languages?: A case study in Japanese. (arXiv:2306.09572v1 [cs.CL])

    [http://arxiv.org/abs/2306.09572](http://arxiv.org/abs/2306.09572)

    本文研究了在日语这种连续书写文字语言中，不同的分词器对预训练语言模型在下游任务中的影响，发现每个下游任务都有一个最佳的形态学分析器，并且无论任务类型如何，最好使用字节对编码或Unigram作为子词分词器。

    

    本文研究了在连续书写文字语言中，分词器对预训练语言模型（PLMs）在下游任务中的影响，以日语为案例研究。这种语言的分词器通常由形态学分析器和子词分词器组成，需要我们对所有可能的组合进行综合研究。然而，以前的研究缺乏这种全面性。因此，我们训练了大量的分词器集，并使用每个集合构建了一个PLM，并在广泛的任务范围内测量了下游性能。我们的结果表明，每个下游任务都有一个不同的最佳形态学分析器，并且无论任务类型如何，最好使用字节对编码或Unigram而不是WordPiece作为子词分词器。

    This paper investigates the effect of tokenizers on the downstream performance of pretrained language models (PLMs) in scriptio continua languages where no explicit spaces exist between words, using Japanese as a case study. The tokenizer for such languages often consists of a morphological analyzer and a subword tokenizer, requiring us to conduct a comprehensive study of all possible pairs. However, previous studies lack this comprehensiveness. We therefore train extensive sets of tokenizers, build a PLM using each, and measure the downstream performance on a wide range of tasks. Our results demonstrate that each downstream task has a different optimal morphological analyzer, and that it is better to use Byte-Pair-Encoding or Unigram rather than WordPiece as a subword tokenizer, regardless of the type of task.
    
[^38]: QH9：QM9分子的量子哈密顿预测基准测试

    QH9: A Quantum Hamiltonian Prediction Benchmark for QM9 Molecules. (arXiv:2306.09549v1 [physics.chem-ph])

    [http://arxiv.org/abs/2306.09549](http://arxiv.org/abs/2306.09549)

    该论文提出了一种新的量子哈密顿数据集QH9，用于为各种分子提供精确的哈密顿矩阵。通过设计基准任务，展示了当前机器学习模型有能力预测任意分子的哈密顿矩阵。

    

    监督式机器学习方法越来越被用于加速电子结构预测，作为第一性原理计算方法（如密度泛函理论（DFT））的替代品。虽然许多量子化学数据集侧重于化学性质和原子力，但准确且高效地预测哈密顿矩阵的能力是非常重要和基本的物理量，它确定了物理系统和化学性质的量子状态。在这项工作中，我们生成了一个新的量子哈密顿数据集，命名为QH9，基于QM9数据集为2,399个分子动力学轨迹和130,831个稳定分子几何形态提供精确的哈密顿矩阵。通过设计各种分子的基准任务，我们展示了当前机器学习模型有能力预测任意分子的哈密顿矩阵。QH9数据集和基准模型都提供。

    Supervised machine learning approaches have been increasingly used in accelerating electronic structure prediction as surrogates of first-principle computational methods, such as density functional theory (DFT). While numerous quantum chemistry datasets focus on chemical properties and atomic forces, the ability to achieve accurate and efficient prediction of the Hamiltonian matrix is highly desired, as it is the most important and fundamental physical quantity that determines the quantum states of physical systems and chemical properties. In this work, we generate a new Quantum Hamiltonian dataset, named as QH9, to provide precise Hamiltonian matrices for 2,399 molecular dynamics trajectories and 130,831 stable molecular geometries, based on the QM9 dataset. By designing benchmark tasks with various molecules, we show that current machine learning models have the capacity to predict Hamiltonian matrices for arbitrary molecules. Both the QH9 dataset and the baseline models are provided
    
[^39]: 用于协助车辆碰撞模拟数据分析的图形提取

    Graph Extraction for Assisting Crash Simulation Data Analysis. (arXiv:2306.09538v1 [cs.AI])

    [http://arxiv.org/abs/2306.09538](http://arxiv.org/abs/2306.09538)

    本文提出了一种将CAE数据转为图形的方法，可以比较模拟数据并突出未探索的实验设计，并对不同设计进行相关性分析。特别关注了车辆碰撞安全性分析中的负荷路径检测。

    

    本文提出了一种从计算机辅助工程（CAE）数据中提取信息并转换成图形的方法。这种图形化呈现CAE数据可以优化设计指南、支持推荐系统，通过比较模拟数据来突出未探索的实验设计，并对不同设计进行相关性分析。我们的重点是车辆设计中一个复杂的子学科——碰撞安全性分析中的负荷路径。负荷路径是吸收碰撞能量的大部分零部件的顺序。为了检测负荷路径，我们从CAE数据生成了一个有向带权图。节点代表车辆零部件，边代表零部件之间的连通性抽象。边的方向遵循碰撞的时间顺序，其中边的权重反映了能量吸收的方面。我们引入并评估了三种图形提取方法和一种进一步更新每个图形的方法，该方法可以使用序列数据来提高CAE数据的精度。

    In this work, we establish a method for abstracting information from Computer Aided Engineering (CAE) into graphs. Such graph representations of CAE data can improve design guidelines and support recommendation systems by enabling the comparison of simulations, highlighting unexplored experimental designs, and correlating different designs. We focus on the load-path in crashworthiness analysis, a complex sub-discipline in vehicle design. The load-path is the sequence of parts that absorb most of the energy caused by the impact. To detect the load-path, we generate a directed weighted graph from the CAE data. The vertices represent the vehicle's parts, and the edges are an abstraction of the connectivity of the parts. The edge direction follows the temporal occurrence of the collision, where the edge weights reflect aspects of the energy absorption. We introduce and assess three methods for graph extraction and an additional method for further updating each graph with the sequences of a
    
[^40]: 残差 Q 学习：无需价值的在线和离线策略定制

    Residual Q-Learning: Offline and Online Policy Customization without Value. (arXiv:2306.09526v1 [cs.LG])

    [http://arxiv.org/abs/2306.09526](http://arxiv.org/abs/2306.09526)

    该研究提出了一种新方法，使用动态控制残差的 Q 学习来进行离线和在线的策略定制，无需使用价值函数。

    

    模仿学习是一种广泛使用的框架，适用于从演示中学习模仿行为。当手工制作奖励函数困难或目标是模仿人类专家行为时，这种方法特别有吸引力。但是，学习的模仿策略只能遵循演示中的行为。在应用模仿策略时，我们可能需要根据不同的下游任务要求定制策略行为。同时，我们仍希望定制的策略保持其模仿性质。为此，我们提出了一种新的问题设置，称为策略定制。它将学习任务定义为训练一种策略，该策略继承先前策略的特性，同时满足目标下游任务强加的一些附加要求。我们提出了一种新颖和有原则的方法来解释和确定两个任务目标之间的权衡。具体而言，我们制定了一种动态控制残差的 Q 学习方法，该方法可以在不使用价值函数的情况下进行在线和离线策略定制。

    Imitation Learning (IL) is a widely used framework for learning imitative behavior from demonstrations. It is especially appealing for solving complex real-world tasks where handcrafting reward function is difficult, or when the goal is to mimic human expert behavior. However, the learned imitative policy can only follow the behavior in the demonstration. When applying the imitative policy, we may need to customize the policy behavior to meet different requirements coming from diverse downstream tasks. Meanwhile, we still want the customized policy to maintain its imitative nature. To this end, we formulate a new problem setting called policy customization. It defines the learning task as training a policy that inherits the characteristics of the prior policy while satisfying some additional requirements imposed by a target downstream task. We propose a novel and principled approach to interpret and determine the trade-off between the two task objectives. Specifically, we formulate the
    
[^41]: 利用增强型大型语言模型（GPT-4）解释法律概念

    Explaining Legal Concepts with Augmented Large Language Models (GPT-4). (arXiv:2306.09525v1 [cs.CL])

    [http://arxiv.org/abs/2306.09525](http://arxiv.org/abs/2306.09525)

    本文评估了利用GPT-4增强解释法律术语性能的方法。与基准设置相比，使用增强的法律信息检索模块可以提高法律术语解释的质量，并消除模型的幻觉问题，从而为在法律领域使用大型语言模型开辟了新的途径。

    

    解释法律开放性术语的含义是法律专业人员的重要任务。先前法院案例中该术语的应用是解释其含义的重要来源。本文评估了GPT-4生成法律术语解释的准确性、清晰性和相关性的性能。我们将GPT-4被直接要求解释法律术语的基准设置的性能与增强方法进行了比较，在增强方法中，一个法律信息检索模块被用来为模型提供相关背景，即来自案例法的句子。我们发现，直接应用GPT-4产生的解释在表面上似乎非常高质量。然而，详细分析揭示了解释的实际准确性方面存在的限制。此外，我们发现增强性能可以提高质量，并似乎消除了幻觉问题，即模型发明不正确的陈述。这些发现为在法律领域中使用大型语言模型开辟了新的途径。

    Interpreting the meaning of legal open-textured terms is a key task of legal professionals. An important source for this interpretation is how the term was applied in previous court cases. In this paper, we evaluate the performance of GPT-4 in generating factually accurate, clear and relevant explanations of terms in legislation. We compare the performance of a baseline setup, where GPT-4 is directly asked to explain a legal term, to an augmented approach, where a legal information retrieval module is used to provide relevant context to the model, in the form of sentences from case law. We found that the direct application of GPT-4 yields explanations that appear to be of very high quality on their surface. However, detailed analysis uncovered limitations in terms of the factual accuracy of the explanations. Further, we found that the augmentation leads to improved quality, and appears to eliminate the issue of hallucination, where models invent incorrect statements. These findings ope
    
[^42]: 针对潜在混淆下的因果结果的更紧密预测区间

    Tighter Prediction Intervals for Causal Outcomes Under Hidden Confounding. (arXiv:2306.09520v1 [cs.LG])

    [http://arxiv.org/abs/2306.09520](http://arxiv.org/abs/2306.09520)

    本文提出了一种名为Caus-Modens的算法，通过调制集合来描述因果结果区间，相比符合性预测方法，能够在实践中给出更紧密的结果区间。

    

    在存在隐藏混淆因素的情况下进行确切个体治疗结果的因果推断很少可能。因此，最近的研究改进了符合性预测方法，以产生结果区间。不幸的是，这类方法往往过于保守，有时会给出无信息量的区间。我们介绍了一种另类方法Caus-Modens，用于通过调制集合来描述因果结果区间。受到贝叶斯统计和集成不确定性量化的启发，Caus-Modens在实践中给出更紧密的结果区间，并通过三个分离基准测试的必要区间大小来实现足够的覆盖率。最后一个基准是使用未知但可探明的基础事实开展观察实验的GPT-4的新型用途。

    Causal inference of exact individual treatment outcomes in the presence of hidden confounders is rarely possible. Instead, recent work has adapted conformal prediction to produce outcome intervals. Unfortunately this family of methods tends to be overly conservative, sometimes giving uninformative intervals. We introduce an alternative approach termed Caus-Modens, for characterizing causal outcome intervals by modulated ensembles. Motivated from Bayesian statistics and ensembled uncertainty quantification, Caus-Modens gives tighter outcome intervals in practice, measured by the necessary interval size to achieve sufficient coverage on three separate benchmarks. The last benchmark is a novel usage of GPT-4 for observational experiments with unknown but probeable ground truth.
    
[^43]: Granger因果的分层技能发现

    Granger-Causal Hierarchical Skill Discovery. (arXiv:2306.09509v1 [cs.AI])

    [http://arxiv.org/abs/2306.09509](http://arxiv.org/abs/2306.09509)

    本文介绍了一种名为HIntS的算法，使用无监督检测器，基于Granger因果性捕捉因素之间的关键事件，发现和训练一系列操作因素化环境中的因素的技能，其展示了在机器人推动任务上有2-3倍的样本效率和最终性能的提高，有效的处理了复杂问题和转移学习。

    

    强化学习已经在学习复杂任务的策略方面显示出了有希望的结果，但往往会遭受低样本效率和有限转移的问题。本文介绍了一种名为HIntS的算法，它使用学习得到的交互检测器来发现和训练一系列技能，这些技能操作因素化环境中的因素。受Granger因果性的启发，这些无监督检测器捕捉到因素之间的关键事件，以便高效地学习有用的技能，并将这些技能转移到其他相关任务，这些任务是许多强化学习技术所面临的困境。我们在一个带有障碍物的机器人推动任务上评估了HIntS - 这是一个具有挑战性的领域，在这个领域，其他RL和HRL方法都表现不佳。学习到的技能不仅展示了使用Breakout的变体的转移，而且与可比较的强化学习基线相比，还表现出2-3倍的样本效率和最终性能的提高。HIntS一起证明了一种层次结构的技能发现方法，可以处理复杂问题。

    Reinforcement Learning (RL) has shown promising results learning policies for complex tasks, but can often suffer from low sample efficiency and limited transfer. We introduce the Hierarchy of Interaction Skills (HIntS) algorithm, which uses learned interaction detectors to discover and train a hierarchy of skills that manipulate factors in factored environments. Inspired by Granger causality, these unsupervised detectors capture key events between factors to sample efficiently learn useful skills and transfer those skills to other related tasks -- tasks where many reinforcement learning techniques struggle. We evaluate HIntS on a robotic pushing task with obstacles -- a challenging domain where other RL and HRL methods fall short. The learned skills not only demonstrate transfer using variants of Breakout, a common RL benchmark, but also show 2-3x improvement in both sample efficiency and final performance compared to comparable RL baselines. Together, HIntS demonstrates a proof of co
    
[^44]: 风力涡轮机发电机加热故障检测的混合特征选取和构造方法

    A Hybrid Feature Selection and Construction Method for Detection of Wind Turbine Generator Heating Faults. (arXiv:2306.09491v1 [cs.LG])

    [http://arxiv.org/abs/2306.09491](http://arxiv.org/abs/2306.09491)

    该论文提出了一种用于检测风力涡轮机发电机加热故障的混合特征选取和构造方法，旨在通过特征构造和选取提高分类精度和降低计算负担。

    

    信息预处理是机器学习应用有效设计的关键步骤。特征构造和选取是实现这一目的的强大技术。本文提出了一种用于检测风力涡轮机发电机加热故障的特征选取和构造方法。该方法通过从监控控制和数据采集（SCADA）系统收集数据，建立包含风力特征、操作数据、温度测量和状态信息的原始特征，并在特征构造步骤中创建新特征以获得更有力的故障指示信息。构造新特征后，采用混合特征选取技术在整个特征集中找出最相关的特征，以提高分类精度和降低计算负担。

    Preprocessing of information is an essential step for the effective design of machine learning applications. Feature construction and selection are powerful techniques used for this aim. In this paper, a feature selection and construction approach is presented for the detection of wind turbine generator heating faults. Data were collected from Supervisory Control and Data Acquisition (SCADA) system of a wind turbine. The original features directly collected from the data collection system consist of wind characteristics, operational data, temperature measurements and status information. In addition to these original features, new features were created in the feature construction step to obtain information that can be more powerful indications of the faults. After the construction of new features, a hybrid feature selection technique was implemented to find out the most relevant features in the overall set to increase the classification accuracy and decrease the computational burden. Fe
    
[^45]: 2023年视频相似度数据集及挑战

    The 2023 Video Similarity Dataset and Challenge. (arXiv:2306.09489v1 [cs.CV])

    [http://arxiv.org/abs/2306.09489](http://arxiv.org/abs/2306.09489)

    本文介绍了一个视频复制检测和定位问题的数据集、基准和挑战。我们提出了一个评估方法并分析了挑战结果和方法。

    

    本文介绍了一个视频复制检测和定位问题的数据集、基准和挑战。问题包括两个不同但相关的任务：确定一个查询视频是否与一个参考视频共享内容（“检测”），并在每个视频中定位共享的内容（“定位”）。基准旨在评估这两个任务的方法，并模拟了一个现实中的大海捞针的情境，其中大多数查询和参考视频都是包含没有复制内容的“干扰项”。我们提出了一个反映检测和定位准确性的度量标准。相关的挑战包括两个相应的轨道，每个轨道都有反映现实世界情境的限制。我们提供了用于评估和基线的实现代码。我们还分析了挑战中排名前几名的提交结果和方法。该数据集、基线方法和评估代码是公开可用的，将进行讨论。

    This work introduces a dataset, benchmark, and challenge for the problem of video copy detection and localization. The problem comprises two distinct but related tasks: determining whether a query video shares content with a reference video ("detection"), and additionally temporally localizing the shared content within each video ("localization"). The benchmark is designed to evaluate methods on these two tasks, and simulates a realistic needle-in-haystack setting, where the majority of both query and reference videos are "distractors" containing no copied content. We propose a metric that reflects both detection and localization accuracy. The associated challenge consists of two corresponding tracks, each with restrictions that reflect real-world settings. We provide implementation code for evaluation and baselines. We also analyze the results and methods of the top submissions to the challenge. The dataset, baseline methods and evaluation code is publicly available and will be discus
    
[^46]: 有效学习新视觉概念的样本节约方法

    Sample-Efficient Learning of Novel Visual Concepts. (arXiv:2306.09482v1 [cs.CV])

    [http://arxiv.org/abs/2306.09482](http://arxiv.org/abs/2306.09482)

    本文提出了一种通过加入符号知识图谱来有效进行少样本分类的方法。与现有分类器不同，该方法考虑到物体之间的相互关系，不仅能够识别物体，还包括抽象概念和功能。

    

    尽管在视觉目标识别方面已取得了进展，但现有深度学习模型在少数提供有限示例的情况下仍然难以有效识别新物体。本文提出一种新方法，在先进识别模型中加入符号知识图谱，以有效进行少样本分类。该神经符号学架构及训练方法，将由少量示例提取的附加关系加入到知识图谱中，通过考虑相互连接实体的存在，提高了其识别新物体的能力。与现有的少样本分类器不同，我们的模型不仅能够识别物体，还包括抽象概念和功能。

    Despite the advances made in visual object recognition, state-of-the-art deep learning models struggle to effectively recognize novel objects in a few-shot setting where only a limited number of examples are provided. Unlike humans who excel at such tasks, these models often fail to leverage known relationships between entities in order to draw conclusions about such objects. In this work, we show that incorporating a symbolic knowledge graph into a state-of-the-art recognition model enables a new approach for effective few-shot classification. In our proposed neuro-symbolic architecture and training methodology, the knowledge graph is augmented with additional relationships extracted from a small set of examples, improving its ability to recognize novel objects by considering the presence of interconnected entities. Unlike existing few-shot classifiers, we show that this enables our model to incorporate not only objects but also abstract concepts and affordances. The existence of the 
    
[^47]: 通过本地批评者的多模态生成模型改善路径规划性能

    Improving Path Planning Performance through Multimodal Generative Models with Local Critics. (arXiv:2306.09470v1 [cs.RO])

    [http://arxiv.org/abs/2306.09470](http://arxiv.org/abs/2306.09470)

    本文提出了一种使用Wasserstein生成对抗性网络，结合连续潜在空间中的变分自动编码器和本地批评者的方法，加速在未知场景与障碍中的路径规划任务，有效提升了成功率和速度。

    

    本文提出了一种新的方法来加速路径规划任务，该任务在未知场景与障碍中利用带有渐变惩罚（GP）的Wasserstein生成对抗性网络（WGANs）来近似自由条件配置空间的分布。我们的方法将WGAN-GP与连续潜在空间中的变分自动编码器结合起来，以处理多模态数据集。但是，使用WGAN-GP训练变分自动编码器可能对于从图像到配置空间的问题具有挑战性，因为KL损失函数通常会收敛到一个随机分布。为了解决这个问题，我们将配置空间简化为一组高斯分布，并将数据集划分为几个本地模型。这使我们不仅可以学习模型，还可以加速其收敛。我们使用流形的同调秩和几何得分评估重构的配置空间。此外，我们提出了一种新颖的评估指标，用于度量本地批评者在为多模态Wasserstein生成对抗性网络with Gradient Penalty提供反馈方面的有效性。实验结果表明，我们的方法在路径规划速度和成功率方面优于现有的最先进方法。

    This paper presents a novel method for accelerating path planning tasks in unknown scenes with obstacles by utilizing Wasserstein Generative Adversarial Networks (WGANs) with Gradient Penalty (GP) to approximate the distribution of the free conditioned configuration space. Our proposed approach involves conditioning the WGAN-GP with a Variational Auto-Encoder in a continuous latent space to handle multimodal datasets. However, training a Variational Auto-Encoder with WGAN-GP can be challenging for image-to-configuration-space problems, as the Kullback-Leibler loss function often converges to a random distribution. To overcome this issue, we simplify the configuration space as a set of Gaussian distributions and divide the dataset into several local models. This enables us to not only learn the model but also speed up its convergence. We evaluate the reconstructed configuration space using the homology rank of manifolds for datasets with the geometry score. Furthermore, we propose a nov
    
[^48]: FFB:面向处理组公平方法的公平公正基准

    FFB: A Fair Fairness Benchmark for In-Processing Group Fairness Methods. (arXiv:2306.09468v1 [cs.LG])

    [http://arxiv.org/abs/2306.09468](http://arxiv.org/abs/2306.09468)

    本文提出了针对处理中组公平方法的公平公正基准框架（FFB），并进行了全面分析。该工作的关键贡献包括提供灵活、可扩展、极简和面向研究的开源代码；建立统一的公平方法基准测试流水线；进行广泛的基准测试，从 $\mathbf{45,079}$ 个实验中获取关键见解。

    

    本文介绍了公平公正基准（FFB），这是一种针对处理中组公平方法的基准框架。确保机器学习的公平性对于符合道德和法律要求至关重要。然而，由于实验设置的不一致，缺乏易于访问的算法实现以及当前公平度量工具的有限可扩展性，存在比较和开发公平度量方法的挑战。为了解决这些问题，我们介绍了一个开源、标准化的基准，用于评估处理中的组公平方法，并提供了对确保不同民族/种族群体公平的最先进方法的全面分析。该工作提供了以下关键贡献：提供灵活、可扩展、极简和面向研究的开源代码；建立统一的公平方法基准测试流水线；进行广泛的基准测试，从 $\mathbf{45,079}$ 个实验中获取关键见解。

    This paper introduces the Fair Fairness Benchmark (\textsf{FFB}), a benchmarking framework for in-processing group fairness methods. Ensuring fairness in machine learning is critical for ethical and legal compliance. However, there exist challenges in comparing and developing of fairness methods due to inconsistencies in experimental settings, lack of accessible algorithmic implementations, and limited extensibility of current fairness packages and tools. To address these issues, we introduce an open-source, standardized benchmark for evaluating in-processing group fairness methods and provide a comprehensive analysis of state-of-the-art methods to ensure different notions of group fairness. This work offers the following key contributions: the provision of flexible, extensible, minimalistic, and research-oriented open-source code; the establishment of unified fairness method benchmarking pipelines; and extensive benchmarking, which yields key insights from $\mathbf{45,079}$ experiment
    
[^49]: Kriging卷积网络

    Kriging Convolutional Networks. (arXiv:2306.09463v1 [cs.LG])

    [http://arxiv.org/abs/2306.09463](http://arxiv.org/abs/2306.09463)

    该研究介绍了一种新的Kriging卷积网络方法，结合了Kriging和图卷积网络的优点，并在多个应用中表现出了更好的性能。

    

    空间插值是一类估计问题，其中已知值的位置用于估计其他位置的值，着重于利用空间局部性和趋势。传统的Kriging方法具有强烈的高斯假设，因此常常无法捕捉数据内部的复杂性。受最近图神经网络进展的启发，我们介绍了Kriging卷积网络（KCN），它将图卷积网络（GCN）和Kriging的优点相结合。与标准GCN相比，KCN在产生预测时直接利用相邻观测值。此外，KCN还将Kriging方法作为特定配置包含在内。我们通过添加注意力来进一步提高模型的性能。通过实验证明，这种模型在几个应用中的性能优于GCN和Kriging。使用PyTorch实现的KCN在GitHub存储库上公开：https://github.com/tufts-ml/kcn-torch。

    Spatial interpolation is a class of estimation problems where locations with known values are used to estimate values at other locations, with an emphasis on harnessing spatial locality and trends. Traditional Kriging methods have strong Gaussian assumptions, and as a result, often fail to capture complexities within the data. Inspired by the recent progress of graph neural networks, we introduce Kriging Convolutional Networks (KCN), a method of combining the advantages of Graph Convolutional Networks (GCN) and Kriging. Compared to standard GCNs, KCNs make direct use of neighboring observations when generating predictions. KCNs also contain the Kriging method as a specific configuration. We further improve the model's performance by adding attention. Empirically, we show that this model outperforms GCNs and Kriging in several applications. The implementation of KCN using PyTorch is publicized at the GitHub repository: https://github.com/tufts-ml/kcn-torch.
    
[^50]: 自动驾驶车辆的行驶舒适优化：概念、方法和技术

    Motion Comfort Optimization for Autonomous Vehicles: Concepts, Methods, and Techniques. (arXiv:2306.09462v1 [cs.RO])

    [http://arxiv.org/abs/2306.09462](http://arxiv.org/abs/2306.09462)

    本文介绍了针对人类舒适度的自动驾驶架构和与其相关的补充框架。讨论了自动驾驶舒适性、响应时间、运动晕车和优化技术等方面的技术细节和挑战。

    

    本文从人类舒适性的角度概述了自动驾驶的架构和相关补充框架。介绍了衡量自动驾驶用户舒适性和心理分析的技术元素。同时，本文介绍了与自动驾驶结构和反应时间相关的技术。我们还讨论了自动驾驶舒适系统、AV驾驶员响应时间、AV舒适水平、运动晕车以及相关优化技术的技术细节。传感器的功能受到各种因素的影响。由于自动驾驶的传感器主要感知车辆周围的环境，包括“天气”，因此在不同的天气条件下，二手传感器在自动驾驶汽车中存在挑战和局限性。自动驾驶的舒适性和安全性也是影响自主发展的因素。

    This article outlines the architecture of autonomous driving and related complementary frameworks from the perspective of human comfort. The technical elements for measuring Autonomous Vehicle (AV) user comfort and psychoanalysis are listed here. At the same time, this article introduces the technology related to the structure of automatic driving and the reaction time of automatic driving. We also discuss the technical details related to the automatic driving comfort system, the response time of the AV driver, the comfort level of the AV, motion sickness, and related optimization technologies. The function of the sensor is affected by various factors. Since the sensor of automatic driving mainly senses the environment around a vehicle, including "the weather" which introduces the challenges and limitations of second-hand sensors in autonomous vehicles under different weather conditions. The comfort and safety of autonomous driving are also factors that affect the development of autono
    
[^51]: 循环记忆决策变压器

    Recurrent Memory Decision Transformer. (arXiv:2306.09459v1 [cs.LG])

    [http://arxiv.org/abs/2306.09459](http://arxiv.org/abs/2306.09459)

    本文提出了循环记忆决策变压器（RMDT）模型，用于处理强化学习中的长序列问题。在Atari游戏和MoJoCo控制问题上的实验表明，采用循环记忆机制的RMDT模型显着优于其没有循环记忆机制的对应模型。

    

    变革性模型最初是为自然语言问题而开发的，最近在离线强化学习任务中得到广泛应用。这是因为代理的历史可以表示为序列，并且整个任务可以缩减为序列建模任务。然而，变压器操作的二次复杂性限制了上下文的潜在增加。因此，为了在自然语言中处理长序列，使用了不同版本的记忆机制。在本文中，我们提出了循环记忆决策变压器（RMDT），这是一种在强化学习问题中使用循环记忆机制的模型。我们在Atari游戏和MoJoCo控制问题上进行了彻底的实验，并表明我们提出的模型在Atari游戏上显着优于没有循环记忆机制的对应模型。我们还仔细研究了记忆对所提出的模型绩效的影响。这些发现为开发更高效和更有效的处理长序列的强化学习模型提供了启示。

    Transformative models, originally developed for natural language problems, have recently been widely used in offline reinforcement learning tasks. This is due to the fact that the agent's history can be represented as a sequence, and the whole task can be reduced to the sequence modeling task. However, the quadratic complexity of the transformer operation limits the potential increase in context. Therefore, to work with long sequences in a natural language, different versions of the memory mechanism are used. In this paper, we propose the Recurrent Memory Decision Transformer (RMDT), a model that uses a recurrent memory mechanism for reinforcement learning problems. We conduct thorough experiments on Atari games and MoJoCo control problems, and show that our proposed model is significantly superior to its counterparts without the recurrent memory mechanism on Atari games. We also carefully study the effect of memory on the performance of the proposed model. These findings shed light on
    
[^52]: 基于特征展平和两阶段协作分类器的主机网络入侵检测

    Host-Based Network Intrusion Detection via Feature Flattening and Two-stage Collaborative Classifier. (arXiv:2306.09451v1 [cs.CR])

    [http://arxiv.org/abs/2306.09451](http://arxiv.org/abs/2306.09451)

    该论文提出了一种混合网络入侵检测系统，结合 NIDS 和 HIDS，利用特征展平技术和两阶段协作分类进行合作分类以提高入侵检测的准确率。

    

    网络入侵检测系统（NIDS）通过监控真实网络流量并分析可疑活动来进行广泛的研究。但是，NIDS 在检测特定类型的攻击（如高级持续性威胁）方面存在局限性。此外，由于加密流量或缺乏权限，NIDS 受制于观察完整的流量信息。为解决这些限制，提出了一种混合网络入侵检测系统，将 NIDS 和基于主机的入侵检测系统（HIDS）相结合，以提高入侵检测性能。将特征展平技术应用于将二维基于主机的特征展平为一维向量，可直接供传统的机器学习模型使用。应用两阶段协作分类器进行合作分类，以提高入侵检测的准确率。

    Network Intrusion Detection Systems (NIDS) have been extensively investigated by monitoring real network traffic and analyzing suspicious activities. However, there are limitations in detecting specific types of attacks with NIDS, such as Advanced Persistent Threats (APT). Additionally, NIDS is restricted in observing complete traffic information due to encrypted traffic or a lack of authority. To address these limitations, a Host-based Intrusion Detection system (HIDS) evaluates resources in the host, including logs, files, and folders, to identify APT attacks that routinely inject malicious files into victimized nodes. In this study, a hybrid network intrusion detection system that combines NIDS and HIDS is proposed to improve intrusion detection performance. The feature flattening technique is applied to flatten two-dimensional host-based features into one-dimensional vectors, which can be directly used by traditional Machine Learning (ML) models. A two-stage collaborative classifie
    
[^53]: 了解效用理论在机器人和人工智能中的应用：一项调查

    Understanding the Application of Utility Theory in Robotics and Artificial Intelligence: A Survey. (arXiv:2306.09445v1 [cs.RO])

    [http://arxiv.org/abs/2306.09445](http://arxiv.org/abs/2306.09445)

    本文是一项了解机器人和人工智能中效用理论应用的调查，探讨了如何通过合适的效用模型指导智能体选择合理策略来实现系统的最优效用和保证每个群体成员的可持续发展。

    

    作为经济学、博弈论和运筹学中的一个统一概念，效用在机器人和人工智能领域中被用来评估个体需求、偏好和利益水平。特别是在多智能体/机器人系统（MAS/MRS）的决策和学习中，合适的效用模型可以指导智能体选择合理的策略来实现其当前需求并学会合作和组织其行为，优化系统的效用，建立稳定可靠的关系，并保证每个群体成员的可持续发展，类似于人类社会。虽然这些系统的复杂、大规模和长期的行为很大程度上由底层关系的基本特性决定，但在机器人和人工智能领域，对机制的理论方面和应用领域的讨论较少。本文引入了一个以效用为导向的需求范式，描述和评估了内部和外部关系。

    As a unifying concept in economics, game theory, and operations research, even in the Robotics and AI field, the utility is used to evaluate the level of individual needs, preferences, and interests. Especially for decision-making and learning in multi-agent/robot systems (MAS/MRS), a suitable utility model can guide agents in choosing reasonable strategies to achieve their current needs and learning to cooperate and organize their behaviors, optimizing the system's utility, building stable and reliable relationships, and guaranteeing each group member's sustainable development, similar to the human society. Although these systems' complex, large-scale, and long-term behaviors are strongly determined by the fundamental characteristics of the underlying relationships, there has been less discussion on the theoretical aspects of mechanisms and the fields of applications in Robotics and AI. This paper introduces a utility-orient needs paradigm to describe and evaluate inter and outer rela
    
[^54]: 从零开始实现红队对抗语言模型的探索与建立

    Explore, Establish, Exploit: Red Teaming Language Models from Scratch. (arXiv:2306.09442v1 [cs.CL])

    [http://arxiv.org/abs/2306.09442](http://arxiv.org/abs/2306.09442)

    本文提出了一种新的红队行动，通过从高层次、抽象的规范出发来考虑语言模型的行为，以探究模型的创新和贡献。

    

    部署大型语言模型（LLMs）可能会产生有害输出，例如有毒或不诚实陈述。先前的研究已经引入了工具以调查有害输出，以识别和减轻这些风险。虽然这是确保语言模型安全的有价值步骤，但这些方法通常依赖于现有的针对不希望的输出的分类器。这限制了它们在只有预先知道有害行为类型的情况下的应用。然而，这跳过了红队行动的核心挑战：开发模型可能展示的行为的上下文理解。此外，当这样的分类器已经存在时，红队行动的边际价值有限，因为分类器可以用于过滤训练数据或模型输出。本文考虑在假设对手从高级、抽象的不良行为规范出发的情况下进行红队行动。红队应该在精化/扩展此规范的同时对抗该模型。

    Deploying Large language models (LLMs) can pose hazards from harmful outputs such as toxic or dishonest speech. Prior work has introduced tools that elicit harmful outputs in order to identify and mitigate these risks. While this is a valuable step toward securing language models, these approaches typically rely on a pre-existing classifier for undesired outputs. This limits their application to situations where the type of harmful behavior is known with precision beforehand. However, this skips a central challenge of red teaming: developing a contextual understanding of the behaviors that a model can exhibit. Furthermore, when such a classifier already exists, red teaming has limited marginal value because the classifier could simply be used to filter training data or model outputs. In this work, we consider red teaming under the assumption that the adversary is working from a high-level, abstract specification of undesired behavior. The red team is expected to refine/extend this spec
    
[^55]: 实用联邦因果结构学习之路

    Towards Practical Federated Causal Structure Learning. (arXiv:2306.09433v1 [cs.LG])

    [http://arxiv.org/abs/2306.09433](http://arxiv.org/abs/2306.09433)

    为了解决联邦学习条件下的因果结构学习难题，提出了一种基于联邦条件独立性检验的因果结构学习方案FedC2SL，无需收集原始数据且对数据变异具有更强的抵抗力。

    

    理解因果关系对于科学发现至关重要。因果结构学习的过程涉及从观测数据中识别因果图以理解这种关系。通常，一个中央服务器执行此任务，但与服务器共享数据会带来隐私风险。联邦学习可以解决这个问题，但现有的联邦因果结构学习解决方案对数据做出了不切实际的假设，并缺乏收敛保证。FedC2SL是一种联邦基于约束的因果结构学习方案，它使用联邦条件独立性检验来学习因果图，该检验在不收集客户端原始数据的情况下检查两个变量在一组条件下的条件独立性。FedC2SL对数据做出了更弱和更现实的假设，并更强地抵御了客户端之间的数据变异。FedPC和FedFCI是FedC2SL的两个变体，用于因果充分性和因果不充分性情况下的因果结构学习。

    Understanding causal relations is vital in scientific discovery. The process of causal structure learning involves identifying causal graphs from observational data to understand such relations. Usually, a central server performs this task, but sharing data with the server poses privacy risks. Federated learning can solve this problem, but existing solutions for federated causal structure learning make unrealistic assumptions about data and lack convergence guarantees. FedC2SL is a federated constraint-based causal structure learning scheme that learns causal graphs using a federated conditional independence test, which examines conditional independence between two variables under a condition set without collecting raw data from clients. FedC2SL requires weaker and more realistic assumptions about data and offers stronger resistance to data variability among clients. FedPC and FedFCI are the two variants of FedC2SL for causal structure learning in causal sufficiency and causal insuffic
    
[^56]: Diff-TTSG: 去噪概率集成语音和手势合成

    Diff-TTSG: Denoising probabilistic integrated speech and gesture synthesis. (arXiv:2306.09417v1 [eess.AS])

    [http://arxiv.org/abs/2306.09417](http://arxiv.org/abs/2306.09417)

    Diff-TTSG是第一个基于扩散的概率模型，用于联合学习合成语音和手势，相比于先前最新技术的非概率方法，它可以更好地捕捉人类讲话和运动的变化，产生更逼真和多样化的集成语音和手势合成。

    

    随着朗读语音合成实现高自然度评分，越来越多的研究开始关注合成自然言语。然而，人类面对面的自发对话既有口头的，也有非语言的（例如，共同言语手势）。最近才开始研究联合合成这两种模态在一个单一的系统中的好处。先前的最新技术使用非概率方法，无法捕捉人类讲话和运动的变化，并可能产生过度平滑的伪影和次优的合成质量。我们提出了第一个基于扩散的概率模型，称为 Diff-TTSG，共同学习合成语音和手势。我们的方法可以从头开始使用小型数据集进行训练。此外，我们描述了一组小心的单模态和多模态主观测试，用于评估集成语音和手势合成系统，并用它们来验证我们提出的方法。对于合成的样例而言，Diff-TTSG优于先前的最新技术，产生更逼真和多样化的集成语音和手势合成。

    With read-aloud speech synthesis achieving high naturalness scores, there is a growing research interest in synthesising spontaneous speech. However, human spontaneous face-to-face conversation has both spoken and non-verbal aspects (here, co-speech gestures). Only recently has research begun to explore the benefits of jointly synthesising these two modalities in a single system. The previous state of the art used non-probabilistic methods, which fail to capture the variability of human speech and motion, and risk producing oversmoothing artefacts and sub-optimal synthesis quality. We present the first diffusion-based probabilistic model, called Diff-TTSG, that jointly learns to synthesise speech and gestures together. Our method can be trained on small datasets from scratch. Furthermore, we describe a set of careful uni- and multi-modal subjective tests for evaluating integrated speech and gesture synthesis systems, and use them to validate our proposed approach. For synthesised examp
    
[^57]: 基于社交媒体的 ChatGPT 自杀风险评估：模型性能、潜力和限制的量化评估

    ChatGPT for Suicide Risk Assessment on Social Media: Quantitative Evaluation of Model Performance, Potentials and Limitations. (arXiv:2306.09390v1 [cs.CL])

    [http://arxiv.org/abs/2306.09390](http://arxiv.org/abs/2306.09390)

    本文量化评估了基于社交媒体的 ChatGPT 模型在自杀倾向评估方面的表现，比较了其结果与两个微调模型，并探讨了模型响应生成的最佳温度，研究结果显示，以人工标注数据集为基础微调的 Transformer 模型表现更佳，这篇论文为心理健康专家提供了重要的模型评估和参数优化建议。

    

    本文提出了一个新的框架来量化评估交互式 ChatGPT 模型在社交媒体帖子中进行自杀倾向评估的能力，利用马里兰大学 Reddit 自杀倾向数据集。我们使用零样本和少样本实验来对 ChatGPT 在这个任务中的表现进行技术评估，并将其结果与两个基于 transformer 的微调模型进行比较。此外，我们调查不同温度参数对 ChatGPT 响应生成的影响，并讨论基于 ChatGPT 不确定性率的最佳温度参数。我们的研究结果表明，虽然 ChatGPT 在这个任务中具有相当高的准确性，但以人工标注数据集为基础微调的 Transformer 模型表现更优。此外，我们的分析还阐明了如何通过调整 ChatGPT 的超参数来提高其在这一关键任务中帮助心理健康专家的能力。

    This paper presents a novel framework for quantitatively evaluating the interactive ChatGPT model in the context of suicidality assessment from social media posts, utilizing the University of Maryland Reddit suicidality dataset. We conduct a technical evaluation of ChatGPT's performance on this task using Zero-Shot and Few-Shot experiments and compare its results with those of two fine-tuned transformer-based models. Additionally, we investigate the impact of different temperature parameters on ChatGPT's response generation and discuss the optimal temperature based on the inconclusiveness rate of ChatGPT. Our results indicate that while ChatGPT attains considerable accuracy in this task, transformer-based models fine-tuned on human-annotated datasets exhibit superior performance. Moreover, our analysis sheds light on how adjusting the ChatGPT's hyperparameters can improve its ability to assist mental health professionals in this critical task.
    
[^58]: 自适应分层时空网络用于交通预测。

    Adaptive Hierarchical SpatioTemporal Network for Traffic Forecasting. (arXiv:2306.09386v1 [cs.LG])

    [http://arxiv.org/abs/2306.09386](http://arxiv.org/abs/2306.09386)

    本文提出了一种自适应分层时空网络（AHSTN），通过利用空间层次结构和建模多尺度空间相关性促进交通预测，AHSTN在节点级别的基础上引入了自适应的时空块，来自适应地处理不同层次之间的相关性，同时使用分层注意机制来选择性地聚合不同尺度的信息，具有优越性。

    

    精确的交通预测对于智能交通系统至关重要，该系统被广泛采用以解决城市交通问题。现有的交通预测研究着重于建模交通数据中的空间 - 时间动态，其中，图卷积网络（GCN）是利用路网格中嵌入的空间依赖性的核心。然而，这些基于GCN的方法仅在节点级别（例如道路和交叉口）上运行，而忽略了整个城市的空间层次结构。诸如交叉口和道路段之类的节点可以形成簇（例如区域），这些节点在更高的层次上还可以相互作用并共享相似之处。在这项工作中，我们提出了一种自适应分层空间时间网络（AHSTN），通过利用空间层次结构和建模多尺度空间相关性促进交通预测。除了节点级别的时空块，AHSTN引入了自适应时空块，分别捕捉本地、区域和全球的依赖关系，以自适应地建模不同层次的相关性。此外，我们提出了一种分层注意机制，以选择性地聚合来自不同尺度的信息。对真实世界数据集的广泛实验表明，与最先进的方法相比，提出的AHSTN具有优越性。

    Accurate traffic forecasting is vital to intelligent transportation systems, which are widely adopted to solve urban traffic issues. Existing traffic forecasting studies focus on modeling spatial-temporal dynamics in traffic data, among which the graph convolution network (GCN) is at the center for exploiting the spatial dependency embedded in the road network graphs. However, these GCN-based methods operate intrinsically on the node level (e.g., road and intersection) only whereas overlooking the spatial hierarchy of the whole city. Nodes such as intersections and road segments can form clusters (e.g., regions), which could also have interactions with each other and share similarities at a higher level. In this work, we propose an Adaptive Hierarchical SpatioTemporal Network (AHSTN) to promote traffic forecasting by exploiting the spatial hierarchy and modeling multi-scale spatial correlations. Apart from the node-level spatiotemporal blocks, AHSTN introduces the adaptive spatiotempor
    
[^59]: 应用多模态机器学习进行压力检测

    Employing Multimodal Machine Learning for Stress Detection. (arXiv:2306.09385v1 [cs.LG])

    [http://arxiv.org/abs/2306.09385](http://arxiv.org/abs/2306.09385)

    本文提出了一个基于多模态AI的框架，旨在通过融合多种信息来精确监测人的工作行为和压力水平。该框架使用卷积神经网络、时延神经网络和多层感知器等深度学习技术，能够高精度地检测高压力和低压力状态。

    

    在当前时代，人类的生活方式越来越注重知识，导致久坐的工作方式变得更加普遍。这导致许多健康和心理障碍。心理健康是当今世界上最被忽视但也是最关键的方面之一。心理健康问题会直接或间接地影响到人体其他部分，并妨碍个人的日常活动和表现。然而，确定压力并找出导致严重心理疾病的压力趋势对于个人来说是具有挑战性的，并涉及多个因素。通过融合由行为模式产生的多个模态（由于各种因素）可以准确地实现这种识别。文献中已经确定了一些技术来实现这个目的。然而，为此目的提出的基于机器学习的多模态融合方法非常少。本文提出了一个基于多模态AI的框架，通过融合面部表情、语音模式、生理信号和自报数据，准确监测人的工作行为和压力水平。所提出的框架采用了卷积神经网络(Convolutional Neural Networks, CNNs)、时延神经网络(Time-delay Neural Networks, TDNNs)和多层感知器(Multi-Layer Perceptron, MLP)等先进的深度学习技术，能够高精度地分类高压力和低压力状态。在公共压力数据集和从医疗保健专业人员那里收集的数据集上获得的结果展示了所提出的框架在准确检测压力方面的有效性。

    In the current age, human lifestyle has become more knowledge oriented leading to generation of sedentary employment. This has given rise to a number of health and mental disorders. Mental wellness is one of the most neglected but crucial aspects of today's world. Mental health issues can, both directly and indirectly, affect other sections of human physiology and impede an individual's day-to-day activities and performance. However, identifying the stress and finding the stress trend for an individual leading to serious mental ailments is challenging and involves multiple factors. Such identification can be achieved accurately by fusing these multiple modalities (due to various factors) arising from behavioral patterns. Certain techniques are identified in the literature for this purpose; however, very few machine learning-based methods are proposed for such multimodal fusion tasks. In this work, a multimodal AI-based framework is proposed to monitor a person's working behavior and st
    
[^60]: MobileASR: 一种面向移动电话的资源感知本地个性化自动语音识别框架

    MobileASR: A resource-aware on-device personalisation framework for automatic speech recognition in mobile phones. (arXiv:2306.09384v1 [eess.AS])

    [http://arxiv.org/abs/2306.09384](http://arxiv.org/abs/2306.09384)

    本文提出了一种资源感知的子模型训练方法，能够在移动设备上有效训练用户语音个性化的ASR模型，同时考虑了移动设备的评估指标和电池限制。在实验中发现，微调模型和选择超参数值需要在性能度量和本地训练时间之间进行权衡。

    

    本文提出了一种综合方法，通过在移动设备上进行有效的模型训练，使用户数据和模型在本地存储和使用，从而开发用户语音个性化的ASR模型。为实现这一目标，我们提出了一种资源感知的子模型训练方法，考虑了移动设备的RAM和电池容量，并探讨了可用资源与训练时间之间的关系，突出了在这种情况下使用子模型的有效性。通过考虑移动设备的评估指标和电池限制，我们能够进行有效的训练并相应地停止该过程。为了模拟真实用户，我们使用具有各种口音的发言者。然后，在各个品牌的各种移动设备上测试整个本地训练和评估框架。我们展示了微调模型和选择正确的超参数值是性能度量最低的可达到性和本地训练时间之间的权衡。

    We describe a comprehensive methodology for developing user-voice personalised ASR models by effectively training models on mobile phones, allowing user data and models to be stored and used locally. To achieve this, we propose a resource-aware sub-model based training approach that considers the RAM, and battery capabilities of mobile phones. We also investigate the relationship between available resources and training time, highlighting the effectiveness of using sub-models in such scenarios. By taking into account the evaluation metric and battery constraints of the mobile phones, we are able to perform efficient training and halt the process accordingly. To simulate real users, we use speakers with various accents. The entire on-device training and evaluation framework was then tested on various mobile phones across brands. We show that fine-tuning the models and selecting the right hyperparameter values is a trade-off between the lowest achievable performance metric, on-device tra
    
[^61]: 基于时空扩展图神经网络的人类移动模拟

    Spatiotemporal-Augmented Graph Neural Networks for Human Mobility Simulation. (arXiv:2306.09381v1 [cs.LG])

    [http://arxiv.org/abs/2306.09381](http://arxiv.org/abs/2306.09381)

    STAR框架通过设计多种时空图来捕捉位置的动态时空效应，为人类移动模拟任务提供新的方法。

    

    人类移动模式在政策决策和经济行为研究中有着重要的应用。人类移动模拟任务旨在给定一小组轨迹数据生成人类移动轨迹，但由于人类移动数据的稀缺性和稀疏性，引起了广泛关注。现有方法大多依赖于地点之间的静态关系，而很大程度上忽略了位置的动态时空效应。因此，我们提出了一种新的框架，即SpatioTemporal-Augmented gRaph神经网络（STAR），来模拟位置的动态时空效应。

    Human mobility patterns have shown significant applications in policy-decision scenarios and economic behavior researches. The human mobility simulation task aims to generate human mobility trajectories given a small set of trajectory data, which have aroused much concern due to the scarcity and sparsity of human mobility data. Existing methods mostly rely on the static relationships of locations, while largely neglect the dynamic spatiotemporal effects of locations. On the one hand, spatiotemporal correspondences of visit distributions reveal the spatial proximity and the functionality similarity of locations. On the other hand, the varying durations in different locations hinder the iterative generation process of the mobility trajectory. Therefore, we propose a novel framework to model the dynamic spatiotemporal effects of locations, namely SpatioTemporal-Augmented gRaph neural networks (STAR). The STAR framework designs various spatiotemporal graphs to capture the spatiotemporal co
    
[^62]: 理解Transformer中的参数共享

    Understanding Parameter Sharing in Transformers. (arXiv:2306.09380v1 [cs.LG])

    [http://arxiv.org/abs/2306.09380](http://arxiv.org/abs/2306.09380)

    本文从模型复杂度和梯度范围两个角度研究了Transformer中参数共享的有效性，发现提高训练收敛性是其中主要原因，模型复杂度只有一小部分贡献。

    

    参数共享已经被证明是一种高效的方法。在Transformer上的先前工作集中在在不同层次上共享参数，这可以通过增加模型深度来提高有限参数模型的性能。在本文中，我们从两个角度研究为什么此方法有效。首先，增加模型深度会使模型更加复杂，我们假设原因与模型复杂度（指FLOPs）有关。其次，由于每个共享参数在向前传播中会参与网络计算多次，其对应的梯度值与原模型的梯度值范围不同，这将影响模型的收敛性。基于此，我们假设训练收敛性也是其中之一的原因。通过进一步的分析，我们显示此方法的成功很大程度上归功于更好的收敛性，只有一小部分归因于增加的模型复杂度。这启发了我们进行更深层次的研究。

    Parameter sharing has proven to be a parameter-efficient approach. Previous work on Transformers has focused on sharing parameters in different layers, which can improve the performance of models with limited parameters by increasing model depth. In this paper, we study why this approach works from two perspectives. First, increasing model depth makes the model more complex, and we hypothesize that the reason is related to model complexity (referring to FLOPs). Secondly, since each shared parameter will participate in the network computation several times in forward propagation, its corresponding gradient will have a different range of values from the original model, which will affect the model convergence. Based on this, we hypothesize that training convergence may also be one of the reasons. Through further analysis, we show that the success of this approach can be largely attributed to better convergence, with only a small part due to the increased model complexity. Inspired by this
    
[^63]: 对齐语言的视觉表示预测人类在自然学习任务中的行为

    Language Aligned Visual Representations Predict Human Behavior in Naturalistic Learning Tasks. (arXiv:2306.09377v1 [cs.LG])

    [http://arxiv.org/abs/2306.09377](http://arxiv.org/abs/2306.09377)

    语言对齐的视觉表示方式比纯视觉表示方式更有效地预测人类在自然学习任务中的行为。

    

    人类具备识别和概括自然物体相关特征的能力，在各种情境中有所帮助。为了研究这种现象并确定最有效的表示方式以预测人类行为，我们进行了两个涉及类别学习和奖励学习的实验。我们的实验使用逼真的图像作为刺激物，并要求参与者基于所有试验的新型刺激物作出准确的决策，因此需要泛化。在两个任务中，底层规则是使用人类相似性判断提取的刺激维度生成的简单线性函数。值得注意的是，参与者在几次试验内就成功地确定了相关的刺激特征，证明了有效的泛化。我们进行了广泛的模型比较，评估了各种深度学习模型的表示对人类选择的逐次预测准确性。有趣的是，自然语言处理任务（如语言建模和机器翻译）训练的模型表示优于视觉任务训练的模型表示，表明对齐语言的视觉表示可能更有效地预测人类在自然学习任务中的行为。

    Humans possess the ability to identify and generalize relevant features of natural objects, which aids them in various situations. To investigate this phenomenon and determine the most effective representations for predicting human behavior, we conducted two experiments involving category learning and reward learning. Our experiments used realistic images as stimuli, and participants were tasked with making accurate decisions based on novel stimuli for all trials, thereby necessitating generalization. In both tasks, the underlying rules were generated as simple linear functions using stimulus dimensions extracted from human similarity judgments. Notably, participants successfully identified the relevant stimulus features within a few trials, demonstrating effective generalization. We performed an extensive model comparison, evaluating the trial-by-trial predictive accuracy of diverse deep learning models' representations of human choices. Intriguingly, representations from models train
    
[^64]: 模型训练中的模块化：一种新的模块化深度神经网络的范式

    Modularizing while Training: a New Paradigm for Modularizing DNN Models. (arXiv:2306.09376v1 [cs.LG])

    [http://arxiv.org/abs/2306.09376](http://arxiv.org/abs/2306.09376)

    本文提出了一种新方法，将模块化纳入模型训练过程中，即在训练时模块化(MwT)，通过两个损失函数实现模型结构上的模块化，进而实现模块的重用，能够在较短的训练时间内达到可比较的模型精度，并且相对于最先进的训练后模块化方法需要更少的参数。

    

    深度神经网络(DNN)模型已成为智能软件系统中越来越关键的组成部分。然而，训练DNN模型通常在时间和成本方面都很昂贵。为了解决这个问题，研究人员最近开始关注重用现有的DNN模型-借鉴软件工程中的代码重用思想。但是，重用整个模型可能会造成额外的开销或从不需要的功能中继承弱点。因此，现有的工作提出将已经训练好的模型分解成模块，即训练后的模块化，并实现模块的重用。但是，由于已经训练好的模型并不是为了模块化而构建的，所以训练后的模块化会导致巨大的开销和模型精度损失。本文提出了一种新方法，将模块化纳入模型训练过程中，即在训练时模块化（MwT）。我们通过两个损失函数在模型训练过程中使模型具有结构上的模块化能力，这两个损失函数同时优化模块内的内聚性和模块之间的独立性，从而得到一个真正的模块化模型。我们展示了我们的方法可以在较短的训练时间内达到可比较的模型精度，并且相对于最先进的训练后模块化方法需要更少的参数。

    Deep neural network (DNN) models have become increasingly crucial components in intelligent software systems. However, training a DNN model is typically expensive in terms of both time and money. To address this issue, researchers have recently focused on reusing existing DNN models - borrowing the idea of code reuse in software engineering. However, reusing an entire model could cause extra overhead or inherits the weakness from the undesired functionalities. Hence, existing work proposes to decompose an already trained model into modules, i.e., modularizing-after-training, and enable module reuse. Since trained models are not built for modularization, modularizing-after-training incurs huge overhead and model accuracy loss. In this paper, we propose a novel approach that incorporates modularization into the model training process, i.e., modularizing-while-training (MwT). We train a model to be structurally modular through two loss functions that optimize intra-module cohesion and int
    
[^65]: 从数据库修复到数据库因果及其拓展

    From Database Repairs to Causality in Databases and Beyond. (arXiv:2306.09374v1 [cs.DB])

    [http://arxiv.org/abs/2306.09374](http://arxiv.org/abs/2306.09374)

    本文介绍了新颖的利用反事实推理进行数据库查询答案分数解释的方法。

    

    我们描述了一些最近用于数据库中查询答案分数解释的方法。重点介绍了作者及其合作者的工作。特别强调了利用反事实推理进行分数规范和计算的方法。展示了几个示例以说明这些方法的灵活性。

    We describe some recent approaches to score-based explanations for query answers in databases. The focus is on work done by the author and collaborators. Special emphasis is placed on the use of counterfactual reasoning for score specification and computation. Several examples that illustrate the flexibility of these methods are shown.
    
[^66]: 公平的多任务学习

    Equitable Multi-task Learning. (arXiv:2306.09373v1 [cs.LG])

    [http://arxiv.org/abs/2306.09373](http://arxiv.org/abs/2306.09373)

    该论文提出了一种名为EMTL的多任务优化方法，以实现公平的多任务学习。通过规范化不同任务的相对贡献，可以提高MTL的泛化性能，并利用方差正则化和高效的优化算法保证收敛。实验证明，该方法在合成和真实数据集上均表现出了更好的性能。

    

    多任务学习（MTL）在各个研究领域（如计算机视觉、自然语言处理和信息检索等）中取得了巨大成功。但是，由于任务之间存在复杂且相互竞争的相关性，单纯地训练所有任务可能会导致不公平的学习，即一些任务被很好地学习，而其他任务则被忽视。多任务优化（MTO）旨在同时提高所有任务的表现，但传统方法往往在任务损失规模或梯度范数差异较大的情况下表现不佳。为了解决这个问题，我们深入研究了MTL的公平性问题，并发现在更新共享参数时，规范化不同任务的相对贡献（即任务特定损失值除以其原始梯度范数的值）可以提高MTL的泛化性能。基于我们的理论分析，我们提出了一种新的多任务优化方法，名为EMTL，以实现公平的MTL。具体来说，我们有效地添加了方差正则化，使不同任务的相对贡献更具可比性，并开发了一种高效的优化算法来保证收敛。我们在合成和真实数据集上进行了大量实验，结果表明了我们方法的有效性和优越性。

    Multi-task learning (MTL) has achieved great success in various research domains, such as CV, NLP and IR etc. Due to the complex and competing task correlation, na\"ive training all tasks may lead to inequitable learning, \textit{i.e.} some tasks are learned well while others are overlooked. Multi-task optimization (MTO) aims to improve all tasks at same time, but conventional methods often perform poor when tasks with large loss scale or gradient norm magnitude difference. To solve the issue, we in-depth investigate the equity problem for MTL and find that regularizing relative contribution of different tasks (\textit{i.e.} value of task-specific loss divides its raw gradient norm) in updating shared parameter can improve generalization performance of MTL. Based on our theoretical analysis, we propose a novel multi-task optimization method, named \textit{EMTL}, to achieve equitable MTL. Specifically, we efficiently add variance regularization to make different tasks' relative contribu
    
[^67]: Warpformer: 一种用于不规则临床时间序列建模的多尺度方法

    Warpformer: A Multi-scale Modeling Approach for Irregular Clinical Time Series. (arXiv:2306.09368v1 [cs.LG])

    [http://arxiv.org/abs/2306.09368](http://arxiv.org/abs/2306.09368)

    Warpformer是一种能够完整考虑序列内不规则性和序列间差异性的多尺度建模方法。

    

    不规则采样的多变量时间序列在各个领域中都很常见，特别是在医疗保健领域，呈现出序列内不规则性和序列间差异性。序列内不规则性指时间序列信号通常在不规则的时间间隔内记录，而序列间差异性则指不同序列之间的采样率显著变化。然而，最近关于不规则时间序列的研究主要集中在解决序列内不规则性问题，而忽略了序列间差异性问题。为了填补这一空白，我们提出了一种新方法：Warpformer，它充分考虑了这两种特征。

    Irregularly sampled multivariate time series are ubiquitous in various fields, particularly in healthcare, and exhibit two key characteristics: intra-series irregularity and inter-series discrepancy. Intra-series irregularity refers to the fact that time-series signals are often recorded at irregular intervals, while inter-series discrepancy refers to the significant variability in sampling rates among diverse series. However, recent advances in irregular time series have primarily focused on addressing intra-series irregularity, overlooking the issue of inter-series discrepancy. To bridge this gap, we present Warpformer, a novel approach that fully considers these two characteristics. In a nutshell, Warpformer has several crucial designs, including a specific input representation that explicitly characterizes both intra-series irregularity and inter-series discrepancy, a warping module that adaptively unifies irregular time series in a given scale, and a customized attention module fo
    
[^68]: 采用函数降维方法进行感应电动机故障检测

    Fault Detection in Induction Motors using Functional Dimensionality Reduction Methods. (arXiv:2306.09365v1 [eess.SY])

    [http://arxiv.org/abs/2306.09365](http://arxiv.org/abs/2306.09365)

    本研究提出了一种采用函数降维方法结合电机电流特征分析策略的故障检测方法，能够实时检测感应电动机中的故障，并且可以通过离线分析识别更多类型的故障。

    

    在旋转电机上实施故障检测和诊断策略对于现代工业系统的可靠性和安全性至关重要。本文的贡献是提出了一种方法，将传统的电机电流特征分析策略与函数降维方法（即函数主成分分析和函数扩散映射）相结合，以检测和分类感应电动机中的故障条件。所提出的方案获得了非常鼓舞人心的结果，不仅可以实时检测感应电动机中故障的存在，而且还可以通过离线分析识别更多类型的故障。

    The implementation of strategies for fault detection and diagnosis on rotating electrical machines is crucial for the reliability and safety of modern industrial systems. The contribution of this work is a methodology that combines conventional strategy of Motor Current Signature Analysis with functional dimensionality reduction methods, namely Functional Principal Components Analysis and Functional Diffusion Maps, for detecting and classifying fault conditions in induction motors. The results obtained from the proposed scheme are very encouraging, revealing a potential use in the future not only for real-time detection of the presence of a fault in an induction motor, but also in the identification of a greater number of types of faults present through an offline analysis.
    
[^69]: TSMixer: 用于多元时间序列预测的轻量级MLP-Mixer模型

    TSMixer: Lightweight MLP-Mixer Model for Multivariate Time Series Forecasting. (arXiv:2306.09364v1 [cs.LG])

    [http://arxiv.org/abs/2306.09364](http://arxiv.org/abs/2306.09364)

    TSMixer是一种用于多元时间序列预测的轻量级MLP-Mixer模型，可以有效地捕捉时间序列属性并在准确性方面超越了Transformers的方法。

    

    Transformers因其能够捕捉长序列交互而在时间序列预测中备受青睐。然而，其内存和计算要求高的问题对长期预测构成了严重瓶颈。为了解决这一问题，我们提出了TSMixer，这是一种轻量级神经架构，专为多元预测和补丁时间序列表示学习而设计，是Transformers的有效替代。我们的模型借鉴了MLP-Mixer模型在计算机视觉中的成功经验。我们展示了将视觉MLP-Mixer适应于时间序列的挑战，并引入了经过实验证实的组件以提高准确性。这包括一种新的设计范式，即将在线协调头附加到MLP-Mixer骨干上，以显式地建模时间序列的属性，如层次结构和通道相关性。我们还提出了一种混合通道建模方法，平衡了编码多个时间序列通道和保留单个通道信息之间的权衡。我们的实验表明，TSMixer在一元和多元时间序列预测任务中均实现了最先进的性能，同时需要比基于Transformers的方法少得多的参数。

    Transformers have gained popularity in time series forecasting for their ability to capture long-sequence interactions. However, their high memory and computing requirements pose a critical bottleneck for long-term forecasting. To address this, we propose TSMixer, a lightweight neural architecture exclusively composed of multi-layer perceptron (MLP) modules. TSMixer is designed for multivariate forecasting and representation learning on patched time series, providing an efficient alternative to Transformers. Our model draws inspiration from the success of MLP-Mixer models in computer vision. We demonstrate the challenges involved in adapting Vision MLP-Mixer for time series and introduce empirically validated components to enhance accuracy. This includes a novel design paradigm of attaching online reconciliation heads to the MLP-Mixer backbone, for explicitly modeling the time-series properties such as hierarchy and channel-correlations. We also propose a Hybrid channel modeling approa
    
[^70]: 一种简单的面向特征分布偏斜联邦学习的数据增强方法

    A Simple Data Augmentation for Feature Distribution Skewed Federated Learning. (arXiv:2306.09363v1 [cs.LG])

    [http://arxiv.org/abs/2306.09363](http://arxiv.org/abs/2306.09363)

    本文针对特征分布偏斜的联邦学习提出了FedRDN方法，在输入层级上实现了数据增强，将整个联邦数据集的统计信息注入到本地客户端数据中，以缓解特征漂移问题。

    

    联邦学习（FL）是一种分布式协作学习方法，可以确保隐私保护。然而，由于数据异构性（即非独立同分布数据），它的性能必然受到影响。本文针对特征分布偏斜的FL场景展开研究，提出了一种通用的数据增强方法，以减轻由本地数据集之间潜在分布不同导致的特征漂移问题。

    Federated learning (FL) facilitates collaborative learning among multiple clients in a distributed manner, while ensuring privacy protection. However, its performance is inevitably degraded as suffering data heterogeneity, i.e., non-IID data. In this paper, we focus on the feature distribution skewed FL scenario, which is widespread in real-world applications. The main challenge lies in the feature shift caused by the different underlying distributions of local datasets. While the previous attempts achieved progress, few studies pay attention to the data itself, the root of this issue. Therefore, the primary goal of this paper is to develop a general data augmentation technique at the input level, to mitigate the feature shift. To achieve this goal, we propose FedRDN, a simple yet remarkably effective data augmentation method for feature distribution skewed FL, which randomly injects the statistics of the dataset from the entire federation into the client's data. By this, our method ca
    
[^71]: 离线安全强化学习的数据集和基准

    Datasets and Benchmarks for Offline Safe Reinforcement Learning. (arXiv:2306.09303v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.09303](http://arxiv.org/abs/2306.09303)

    该论文提出了一个专门针对离线安全强化学习的基准套件，包含了安全策略、数据集和高质量RL算法实现。作者还提供了一种数据收集流程，利用先进算法生成多样性数据集，用于38个受欢迎的安全RL任务。该套件可加速该领域的研究进展。

    

    本文提出了一个专门针对离线安全强化学习（RL）挑战的综合基准套件，旨在促进开发和评估训练和部署阶段中的安全学习算法的进展。我们的基准套件包含三个组件：1）专家制作的安全策略，2）D4RL样式的数据集以及环境包装器，以及3）高质量的离线安全RL基准实现。我们提供了一种有条理的数据收集流程，由先进的安全RL算法支持，可以促进在38个受欢迎的安全RL任务中生成各种数据集，从机器人控制到自动驾驶。我们还引入了一系列数据后处理过滤器，能够修改每个数据集的多样性，从而模拟各种数据收集条件。此外，我们提供了流行的离线安全RL算法的精美且可扩展的实现，以加速该领域的研究。 通过广泛的实验

    This paper presents a comprehensive benchmarking suite tailored to offline safe reinforcement learning (RL) challenges, aiming to foster progress in the development and evaluation of safe learning algorithms in both the training and deployment phases. Our benchmark suite contains three packages: 1) expertly crafted safe policies, 2) D4RL-styled datasets along with environment wrappers, and 3) high-quality offline safe RL baseline implementations. We feature a methodical data collection pipeline powered by advanced safe RL algorithms, which facilitates the generation of diverse datasets across 38 popular safe RL tasks, from robot control to autonomous driving. We further introduce an array of data post-processing filters, capable of modifying each dataset's diversity, thereby simulating various data collection conditions. Additionally, we provide elegant and extensible implementations of prevalent offline safe RL algorithms to accelerate research in this area. Through extensive experime
    
[^72]: 具有时间不规则性的多元时间序列的概率学习

    Probabilistic Learning of Multivariate Time Series with Temporal Irregularity. (arXiv:2306.09147v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.09147](http://arxiv.org/abs/2306.09147)

    本文提出了一种针对具有时间不规则性的多元时间序列的概率学习方法，通过允许观察到达时间在模型构建中发挥核心作用，使用新颖的非参数先验模型明确融入时间不规则性。

    

    在实践中收集的多元序列数据经常表现出时间的不规则性，包括非均匀时间间隔和组件错位。然而，如果不均匀的间距和异步是数据内生特征而不是不足观察的结果，则这些不规则性的信息内容在表征多元依赖结构时发挥决定性作用。现有的概率预测方法要么忽略了由此产生的统计异质性，要么易受到插补偏差的影响，要么将参数假设强加于数据分布上。本文提出了一种端到端解决方案，通过允许观察到达时间在模型构建中发挥核心作用来克服这些限制，这是时间不规则性的核心。为了认识到时间的不规则性，我们首先为组件启用唯一的隐藏状态，以便到达时间可以指导何时、如何和哪个隐藏状态应该更新。然后，我们通过一种新颖的非参数先验模型明确地融入了时间不规则性，该模型联合建模观测和隐藏状态，并自适应地捕获了跨组件的时间异质性和条件依赖性。我们使用合成数据和实际数据集展示了我们方法的优越性。

    Multivariate sequential data collected in practice often exhibit temporal irregularities, including nonuniform time intervals and component misalignment. However, if uneven spacing and asynchrony are endogenous characteristics of the data rather than a result of insufficient observation, the information content of these irregularities plays a defining role in characterizing the multivariate dependence structure. Existing approaches for probabilistic forecasting either overlook the resulting statistical heterogeneities, are susceptible to imputation biases, or impose parametric assumptions on the data distribution. This paper proposes an end-to-end solution that overcomes these limitations by allowing the observation arrival times to play the central role of model construction, which is at the core of temporal irregularities. To acknowledge temporal irregularities, we first enable unique hidden states for components so that the arrival times can dictate when, how, and which hidden state
    
[^73]: Skill-Critic: 用于强化学习中学习技能的筛选与优化

    Skill-Critic: Refining Learned Skills for Reinforcement Learning. (arXiv:2306.08388v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.08388](http://arxiv.org/abs/2306.08388)

    基于技能筛选与优化的Skill-Critic算法能够提高稀疏奖励环境下强化学习中低层策略的可靠性，并显著提高了性能。

    

    分层强化学习可以通过时间抽象将一个策略分为多个层次，加快长期决策的速度。在稀疏奖励的环境中，技能即原始动作的序列，已经取得了有望的结果。通常情况下，技能的潜在空间和策略是从离线数据中发现的，但由于演示覆盖范围低或分布转移，所得到的低层策略可能不可靠。因此，我们提出了一种Fine-tuning低层策略与高层技能选择相结合的解决方案。我们的Skill-Critic算法优化了低层和高层策略，并通过从离线演示数据中学习的潜在空间进行初始化和规范化，以引导联合策略优化。我们在多个稀疏强化学习环境中验证了我们的方法，包括Gran Turismo Sport中新的稀疏奖励自主赛车任务。实验表明，Skill-Critic的低层策略Fine-tuning和演示引导策略初始化显著提高了性能。

    Hierarchical reinforcement learning (RL) can accelerate long-horizon decision-making by temporally abstracting a policy into multiple levels. Promising results in sparse reward environments have been seen with skills, i.e. sequences of primitive actions. Typically, a skill latent space and policy are discovered from offline data, but the resulting low-level policy can be unreliable due to low-coverage demonstrations or distribution shifts. As a solution, we propose fine-tuning the low-level policy in conjunction with high-level skill selection. Our Skill-Critic algorithm optimizes both the low and high-level policies; these policies are also initialized and regularized by the latent space learned from offline demonstrations to guide the joint policy optimization. We validate our approach in multiple sparse RL environments, including a new sparse reward autonomous racing task in Gran Turismo Sport. The experiments show that Skill-Critic's low-level policy fine-tuning and demonstration-g
    
[^74]: h2oGPT：民主化大语言模型

    h2oGPT: Democratizing Large Language Models. (arXiv:2306.08161v1 [cs.CL])

    [http://arxiv.org/abs/2306.08161](http://arxiv.org/abs/2306.08161)

    本文介绍了h2oGPT，这是一套开源代码库，用于创建和使用基于GPTs的大语言模型（LLMs），包括100％私有文档搜索。目标是创建真正开源的替代封闭源GPTs，提高人工智能的开发和可靠性。

    

    基于生成预训练变压器（GPTs），大语言模型（LLMs）如GPT-4因其在自然语言处理方面的现实应用而成为人工智能革命的一部分。然而，它们也带来了许多重大的风险，如存在有偏见、私人或有害文本和未经授权的版权材料。本文介绍了h2oGPT，这是一套开源代码库，用于创建和使用基于GPTs的大语言模型（LLMs）。该项目的目标是创建世界上最好的真正开源的替代封闭源GPTs。与开源社区合作，作为其一部分，我们开源了几个LLM，其参数从7亿到400亿，可在完全自由的Apache 2.0许可下商用。我们的发布包括使用自然语言的100％私有文档搜索。开源语言模型有助于促进人工智能的发展并使其更加可靠。

    Foundation Large Language Models (LLMs) such as GPT-4 represent a revolution in AI due to their real-world applications though natural language processing. However, they also pose many significant risks such as the presence of biased, private, or harmful text, and the unauthorized inclusion of copyrighted material.  We introduce h2oGPT, a suite of open-source code repositories for the creation and use of Large Language Models (LLMs) based on Generative Pretrained Transformers (GPTs). The goal of this project is to create the world's best truly open-source alternative to closed-source GPTs. In collaboration with and as part of the incredible and unstoppable open-source community, we open-source several fine-tuned h2oGPT models from 7 to 40 Billion parameters, ready for commercial use under fully permissive Apache 2.0 licenses. Included in our release is 100% private document search using natural language.  Open-source language models help boost AI development and make it more accessible
    
[^75]: DreamSparse: 利用 2D 扩散模型从稀疏视角中合成图像

    DreamSparse: Escaping from Plato's Cave with 2D Diffusion Model Given Sparse Views. (arXiv:2306.03414v1 [cs.CV])

    [http://arxiv.org/abs/2306.03414](http://arxiv.org/abs/2306.03414)

    本文提出了 DreamSparse 框架，该框架通过利用先前训练的扩散模型的 2D 先验知识，通过几何模块和空间引导模型来解决 2D 模型缺乏 3D 感知能力的问题，进一步实现了从少视角情况下合成高质量的新视角图像。

    

    从少量视角中合成新的图像是一个具有挑战性但实际的问题。现有方法通常难以产生高质量的结果或在此类少视角设置中需要逐个对象优化，因为提供的信息不足。在这项工作中，我们探索利用预先训练的扩散模型的强大的 2D 先验知识，来合成新颖的视角图像。然而，2D 扩散模型缺乏 3D 感知能力，导致图像合成失真，影响了图像的识别性。为了解决这些问题，我们提出了 DreamSparse，一个可以生成几何和识别联合一致的新视角图像的框架。具体而言，DreamSparse 包括一个几何模块，用于从稀疏视角获取 3D 特征作为 3D 先验，随后引入一个空间引导模型将这些 3D 特征图转换为生成过程的空间信息。这些信息然后用于通过对抗损失指导预训练扩散模型合成高质量的新视角图像。实验结果显示，DreamSparse 在少视角图像合成方面取得了最先进的结果，并且可以生成准确和稳健的物体几何和识别。

    Synthesizing novel view images from a few views is a challenging but practical problem. Existing methods often struggle with producing high-quality results or necessitate per-object optimization in such few-view settings due to the insufficient information provided. In this work, we explore leveraging the strong 2D priors in pre-trained diffusion models for synthesizing novel view images. 2D diffusion models, nevertheless, lack 3D awareness, leading to distorted image synthesis and compromising the identity. To address these problems, we propose DreamSparse, a framework that enables the frozen pre-trained diffusion model to generate geometry and identity-consistent novel view image. Specifically, DreamSparse incorporates a geometry module designed to capture 3D features from sparse views as a 3D prior. Subsequently, a spatial guidance model is introduced to convert these 3D feature maps into spatial information for the generative process. This information is then used to guide the pre-
    
[^76]: 评估GPT-3生成的仇恨内容审核解释

    Evaluating GPT-3 Generated Explanations for Hateful Content Moderation. (arXiv:2305.17680v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17680](http://arxiv.org/abs/2305.17680)

    本文通过调查和分析，评估了使用GPT-3生成的针对仇恨内容的解释是否准确和有用。结果显示，GPT-3生成的解释普遍存在过于模糊、聚焦不当等缺点，同时也存在不同类型仇恨言论生成的解释质量差异大的问题。

    

    最近的研究聚焦于使用基于大型语言模型（LLMs）的Fine-tune或提示生成仇恨言论的解释。尽管这个领域越来越受关注，但这些生成解释的有效性和潜在限制仍然不为人们所了解。一个关键问题是，由LLMs生成的这些解释可能会导致用户和内容审核员对标记内容本质做出错误判断。我们提出一个分析框架来检查仇恨言论解释，并进行了一个广泛的调查来评估这些解释。我们在GPT-3上输入仇恨和非仇恨内容，发现受调查者在人工审核GPT生成的解释时，将仇恨言论解释评价为不够准确和有用。

    Recent research has focused on using large language models (LLMs) to generate explanations for hate speech through fine-tuning or prompting. Despite the growing interest in this area, these generated explanations' effectiveness and potential limitations remain poorly understood. A key concern is that these explanations, generated by LLMs, may lead to erroneous judgments about the nature of flagged content by both users and content moderators. For instance, an LLM-generated explanation might inaccurately convince a content moderator that a benign piece of content is hateful. In light of this, we propose an analytical framework for examining hate speech explanations and conducted an extensive survey on evaluating such explanations. Specifically, we prompted GPT-3 to generate explanations for both hateful and non-hateful content, and a survey was conducted with 2,400 unique respondents to evaluate the generated explanations. Our findings reveal that (1) human evaluators rated the GPT-gene
    
[^77]: 不要训练它：图神经网络的线性神经架构搜索

    Do Not Train It: A Linear Neural Architecture Search of Graph Neural Networks. (arXiv:2305.14065v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.14065](http://arxiv.org/abs/2305.14065)

    本文提出了一种新的图神经网络结构搜索方法——神经结构编码（NAC），它通过稀疏编码寻找最优结构参数，无需训练就能发挥表现力，在多个基准数据集上实现了最先进性能，并且运算速度比强基线方法快了200倍，精度提高了18.8％。

    

    图神经网络的神经架构搜索（NAS-GNN）已经显著地提高了手动设计的图神经网络的性能。然而，这些方法继承了传统NAS方法的问题，如高计算成本和优化难度。更重要的是，以前的NAS方法忽视了GNN的独特性，即GNN具有无需训练就具有表现力的特点。采用随机初始化的权重，我们可以通过稀疏编码目标寻找最优的架构参数，并得出一种新的NAS-GNN方法，即神经结构编码（NAC）。因此，我们的NAC在GNN上实现了无更新方案，可以在线性时间内高效计算。在多个GNN基准数据集上的实证评估表明，我们的方法导致了最先进的性能，比强基线方法快200倍，精度提高了18.8％。

    Neural architecture search (NAS) for Graph neural networks (GNNs), called NAS-GNNs, has achieved significant performance over manually designed GNN architectures. However, these methods inherit issues from the conventional NAS methods, such as high computational cost and optimization difficulty. More importantly, previous NAS methods have ignored the uniqueness of GNNs, where GNNs possess expressive power without training. With the randomly-initialized weights, we can then seek the optimal architecture parameters via the sparse coding objective and derive a novel NAS-GNNs method, namely neural architecture coding (NAC). Consequently, our NAC holds a no-update scheme on GNNs and can efficiently compute in linear time. Empirical evaluations on multiple GNN benchmark datasets demonstrate that our approach leads to state-of-the-art performance, which is up to $200\times$ faster and $18.8\%$ more accurate than the strong baselines.
    
[^78]: 训练神经网络语音分离模型的数据采样策略研究

    On Data Sampling Strategies for Training Neural Network Speech Separation Models. (arXiv:2304.07142v1 [cs.SD])

    [http://arxiv.org/abs/2304.07142](http://arxiv.org/abs/2304.07142)

    本文研究了训练神经网络语音分离模型的数据采样策略对模型性能的影响。研究表明，对于特定的信号长度分布，采用特定的训练信号长度限制可以获得更好的性能。

    

    语音分离仍然是多说话信号处理的重要领域。深度神经网络（DNN）模型在许多语音分离基准上取得了最佳性能。一些模型需要较长的训练时间和较高的内存需求。以前的研究提出了缩短训练示例以解决这些问题，但这对模型性能的影响尚不清楚。本文分析了应用这些训练信号长度（TSL）限制对两个语音分离模型（SepFormer，一个变换器模型，和Conv-TasNet，一个卷积模型）的影响。使用WJS0-2Mix，WHAMR和Libri2Mix数据集来分析信号长度分布及其对训练效率的影响。研究表明，对于特定的分布，应用特定的TSL限制可以获得更好的性能。这主要是由于对波形起始索引进行随机采样导致更多独特的示例用于训练。

    Speech separation remains an important area of multi-speaker signal processing. Deep neural network (DNN) models have attained the best performance on many speech separation benchmarks. Some of these models can take significant time to train and have high memory requirements. Previous work has proposed shortening training examples to address these issues but the impact of this on model performance is not yet well understood. In this work, the impact of applying these training signal length (TSL) limits is analysed for two speech separation models: SepFormer, a transformer model, and Conv-TasNet, a convolutional model. The WJS0-2Mix, WHAMR and Libri2Mix datasets are analysed in terms of signal length distribution and its impact on training efficiency. It is demonstrated that, for specific distributions, applying specific TSL limits results in better performance. This is shown to be mainly due to randomly sampling the start index of the waveforms resulting in more unique examples for tra
    
[^79]: 农田自监督表示学习的注入噪声鉴别器

    INoD: Injected Noise Discriminator for Self-Supervised Representation Learning in Agricultural Fields. (arXiv:2303.18101v1 [cs.CV])

    [http://arxiv.org/abs/2303.18101](http://arxiv.org/abs/2303.18101)

    本文提出了一个名为INoD的注入噪声鉴别器，通过特征替换和数据集鉴别的原则进行农田自监督表示学习，提升了模型性能。

    

    农业领域的感知数据集数量和多样性都受限，这影响了监督学习方法的有效训练。自监督学习技术可以缓解此问题，但现有方法没有针对农业领域的密集预测任务进行优化，导致模型性能下降。本文提出了注入噪声鉴别器（INoD），利用特征替换和数据集鉴别的原则进行自监督表示学习。INoD通过在两个不同数据集的卷积编码中交错特征图，并预测产生的特征图的数据集隶属关系作为预文本任务。我们的方法使网络能够学习一个数据集中对象的明确表示，同时与不同数据集中的相似特征一起观察。

    Perception datasets for agriculture are limited both in quantity and diversity which hinders effective training of supervised learning approaches. Self-supervised learning techniques alleviate this problem, however, existing methods are not optimized for dense prediction tasks in agriculture domains which results in degraded performance. In this work, we address this limitation with our proposed Injected Noise Discriminator (INoD) which exploits principles of feature replacement and dataset discrimination for self-supervised representation learning. INoD interleaves feature maps from two disjoint datasets during their convolutional encoding and predicts the dataset affiliation of the resultant feature map as a pretext task. Our approach enables the network to learn unequivocal representations of objects seen in one dataset while observing them in conjunction with similar features from the disjoint dataset. This allows the network to reason about higher-level semantics of the entailed o
    
[^80]: 卵巢癌组织病理学中的人工智能：一项系统综述

    Artificial Intelligence in Ovarian Cancer Histopathology: A Systematic Review. (arXiv:2303.18005v1 [eess.IV])

    [http://arxiv.org/abs/2303.18005](http://arxiv.org/abs/2303.18005)

    通过对36篇文章的综述，该研究发现人工智能模型在卵巢癌的诊断和预后中显示出有希望的结果，但现有研究受到小样本量，潜在偏见和缺乏外部验证的限制。

    

    目的-特征化和评估已发表的研究，评估利用组织病理学数据进行卵巢癌诊断或预后的人工智能（AI）方法的质量。方法-在2022年1月12日之前，对5个来源进行搜索。包括标准要求研究评估AI在卵巢癌的组织病理学图像上，对卵巢癌，包括输卵管卵巢和腹膜肿瘤的诊断或预后推断。排除评论和非英语文章。对每个包含的模型使用PROBAST评估偏倚风险。结果-共发现1434篇研究文章，其中36篇符合纳入标准。这些研究报告了62个感兴趣的模型，其中包括35个分类器，14个生存预测模型，7个分割模型和6个回归模型。使用1-1375张从1-664个卵巢癌患者中得到的幻灯片开发了这些模型。预测了广泛的结果，包括总体生存（9/62），组织学亚型（7/62）和淋巴结状态（6/62）。结论-基于可用的文献，AI模型在卵巢癌组织病理学的诊断和预后中显示出有希望的结果。但是，现有的研究受到样本量小、潜在的偏见和缺乏外部验证的限制。

    Purpose - To characterise and assess the quality of published research evaluating artificial intelligence (AI) methods for ovarian cancer diagnosis or prognosis using histopathology data. Methods - A search of 5 sources was conducted up to 01/12/2022. The inclusion criteria required that research evaluated AI on histopathology images for diagnostic or prognostic inferences in ovarian cancer, including tubo-ovarian and peritoneal tumours. Reviews and non-English language articles were excluded. The risk of bias was assessed for every included model using PROBAST. Results - A total of 1434 research articles were identified, of which 36 were eligible for inclusion. These studies reported 62 models of interest, including 35 classifiers, 14 survival prediction models, 7 segmentation models, and 6 regression models. Models were developed using 1-1375 slides from 1-664 ovarian cancer patients. A wide array of outcomes were predicted, including overall survival (9/62), histological subtypes (7
    
[^81]: 强化学习优化机器人包装

    Robotic Packaging Optimization with Reinforcement Learning. (arXiv:2303.14693v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.14693](http://arxiv.org/abs/2303.14693)

    本论文提出了一个强化学习框架，用于优化机器人包装中的传送带速度，并减少对余下控制系统的干扰。

    

    随着极大地提升生产效率和灵活性的需求的增加，智能制造变得越来越重要。本论文研究自动化二次食品包装解决方案，将食品产品从传送带转移到容器中。这些解决方案的一个主要问题是不同的产品供应可能会导致生产率的急剧下降。传统的基于规则的方法往往是不适当的，会导致行业要求的违规。强化学习则通过学习响应和预测策略解决这个问题。然而，在复杂的控制方案中使用强化学习是具有挑战性的。本文提出了一个强化学习框架，旨在优化传送带速度，同时最大程度地减少对余下控制系统的干扰。经过对真实数据的测试，该框架的表现良好。

    Intelligent manufacturing is becoming increasingly important due to the growing demand for maximizing productivity and flexibility while minimizing waste and lead times. This work investigates automated secondary robotic food packaging solutions that transfer food products from the conveyor belt into containers. A major problem in these solutions is varying product supply which can cause drastic productivity drops. Conventional rule-based approaches, used to address this issue, are often inadequate, leading to violation of the industry's requirements. Reinforcement learning, on the other hand, has the potential of solving this problem by learning responsive and predictive policy, based on experience. However, it is challenging to utilize it in highly complex control schemes. In this paper, we propose a reinforcement learning framework, designed to optimize the conveyor belt speed while minimizing interference with the rest of the control system. When tested on real-world data, the fram
    
[^82]: 迭代部分满足的反事实解释：益处和风险

    Iterative Partial Fulfillment of Counterfactual Explanations: Benefits and Risks. (arXiv:2303.11111v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.11111](http://arxiv.org/abs/2303.11111)

    迭代部分满足的反事实解释被广泛用于解释机器学习模型在高风险领域中的推理，我们提出了一个新颖的属性：这种解释在迭代部分履行下的行为。主体可以在接收的解释中部分地履行请求一个新的预测和新的解释，重复此过程，直到预测为正面。

    

    反事实（CF）解释，也称为对比解释和算法回归，被广泛用于解释高风险领域中的机器学习模型。针对一个受到负面预测的主体（例如，拒绝房贷申请），CF解释是相似的情况，但预测结果为正面，这告知主体改进的方法。尽管它们的各种属性已经被研究，例如有效性和稳定性，但我们提供了一种新颖的属性：在迭代部分履行（IPF）下的行为。具体地，在接收到CF解释后，主体可能只能部分地履行它，然后请求一个新的预测及新的解释，重复此过程直到预测为正面。这种部分履行可能是由于主体的能力有限（例如，此时只能支付四张信用卡帐户中的两张）或试图冒险（例如，押注800美元的月薪增长足够）。

    Counterfactual (CF) explanations, also known as contrastive explanations and algorithmic recourses, are popular for explaining machine learning models in high-stakes domains. For a subject that receives a negative model prediction (e.g., mortgage application denial), the CF explanations are similar instances but with positive predictions, which informs the subject of ways to improve. While their various properties have been studied, such as validity and stability, we contribute a novel one: their behaviors under iterative partial fulfillment (IPF). Specifically, upon receiving a CF explanation, the subject may only partially fulfill it before requesting a new prediction with a new explanation, and repeat until the prediction is positive. Such partial fulfillment could be due to the subject's limited capability (e.g., can only pay down two out of four credit card accounts at this moment) or an attempt to take the chance (e.g., betting that a monthly salary increase of $800 is enough eve
    
[^83]: Seq-HyGAN: 基于超图注意力网络的序列分类

    Seq-HyGAN: Sequence Classification via Hypergraph Attention Network. (arXiv:2303.02393v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.02393](http://arxiv.org/abs/2303.02393)

    本文提出了一种基于超图注意力网络的序列分类模型Seq-HyGAN，通过创建超图和引入注意力机制来处理序列数据中的复杂结构相似性，从而提高分类准确率。

    

    序列分类在不同领域有广泛的实际应用，例如在健康领域中的基因组分类和在商业领域的异常检测。然而，序列数据中缺乏显式的特征，这使得机器学习模型难以处理。虽然神经网络模型通过自动学习特征来解决这个问题，但它们仅限于捕获相邻结构连接并忽略序列之间的全局、高阶信息。为了解决序列分类问题中的这些挑战，我们提出了一种新的超图注意力网络模型——Seq-HyGAN。为了捕捉序列数据之间的复杂结构相似性，我们首先创建一个超图，其中序列被描绘为超边，从序列中提取的子序列被描绘为节点。此外，我们引入了基于注意力的超图神经网络模型，它利用了双层注意力机制。该模型生成一个序列表示

    Sequence classification has a wide range of real-world applications in different domains, such as genome classification in health and anomaly detection in business. However, the lack of explicit features in sequence data makes it difficult for machine learning models. While Neural Network (NN) models address this with learning features automatically, they are limited to capturing adjacent structural connections and ignore global, higher-order information between the sequences. To address these challenges in the sequence classification problems, we propose a novel Hypergraph Attention Network model, namely Seq-HyGAN. To capture the complex structural similarity between sequence data, we first create a hypergraph where the sequences are depicted as hyperedges and subsequences extracted from sequences are depicted as nodes. Additionally, we introduce an attention-based Hypergraph Neural Network model that utilizes a two-level attention mechanism. This model generates a sequence representa
    
[^84]: 用机器学习扩展规则型域名系统DNS审查检测的规模

    Augmenting Rule-based DNS Censorship Detection at Scale with Machine Learning. (arXiv:2302.02031v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.02031](http://arxiv.org/abs/2302.02031)

    本文探讨了如何使用机器学习模型来帮助简化DNS审查检测过程，提高检测的可靠性，并发现启发式方法所错过的新审查实例和阻止标志。

    

    全球审查的增加导致了大量监测和曝光的测量平台的发展。域名系统（DNS）的审查是不同国家使用的关键机制，目前通过对特定目的地的DNS查询和响应（探针）样本应用启发式方法来检测。然而，这些启发式方法既与平台特定相关，也发现当审查者改变其阻止行为时的脆弱性，需要更可靠的自动化过程来检测审查。在本文中，我们探讨了机器学习（ML）模型如何（1）帮助简化检测过程，（2）提高使用大规模数据集进行审查检测的潜力，（3）发现现有启发式方法所错过的新审查实例和阻止标志。我们的研究表明，经过专家派生标签训练的监督模型可以学习检测审查和异常的已知实例。

    The proliferation of global censorship has led to the development of a plethora of measurement platforms to monitor and expose it. Censorship of the domain name system (DNS) is a key mechanism used across different countries. It is currently detected by applying heuristics to samples of DNS queries and responses (probes) for specific destinations. These heuristics, however, are both platform-specific and have been found to be brittle when censors change their blocking behavior, necessitating a more reliable automated process for detecting censorship.  In this paper, we explore how machine learning (ML) models can (1) help streamline the detection process, (2) improve the potential of using large-scale datasets for censorship detection, and (3) discover new censorship instances and blocking signatures missed by existing heuristic methods. Our study shows that supervised models, trained using expert-derived labels on instances of known anomalies and possible censorship, can learn the det
    
[^85]: 行车场景中的认知事故预测:一种多模态基准方法

    Cognitive Accident Prediction in Driving Scenes: A Multimodality Benchmark. (arXiv:2212.09381v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.09381](http://arxiv.org/abs/2212.09381)

    本篇论文提出了一种名为CAP的方法，它通过文本描述和驾驶员注意力来改善行车视频中的交通事故预测。这个方法考虑了长尾数据分布和环境变化等挑战，希望能为未来的安全驾驶系统提供决策支持。

    

    行车视频的交通事故预测旨在提早发现事故的发生，支持安全驾驶系统的决策。以往的研究通常关注物体级上下文的时空相关性，而不太适合内在的长尾数据分布，并且容易受到严重环境变化的影响。在本研究中，我们提出了一种认知事故预测（CAP）方法，明确地利用了人类启发的对视觉观察和驾驶员注意力上的文本描述的认知来促进模型训练。特别地，文本描述为交通场景的主要上下文提供了密集的语义描述指导，而驾驶员的注意力提供了一个牵引力，使其专注于与安全驾驶密切相关的关键区域。CAP由注重文本到视觉转移融合模块、注重场景上下文转移模块和驾驶员注意力引导的事故预测网络三个部分组成。

    Traffic accident prediction in driving videos aims to provide an early warning of the accident occurrence, and supports the decision making of safe driving systems. Previous works usually concentrate on the spatial-temporal correlation of object-level context, while they do not fit the inherent long-tailed data distribution well and are vulnerable to severe environmental change. In this work, we propose a Cognitive Accident Prediction (CAP) method that explicitly leverages human-inspired cognition of text description on the visual observation and the driver attention to facilitate model training. In particular, the text description provides a dense semantic description guidance for the primary context of the traffic scene, while the driver attention provides a traction to focus on the critical region closely correlating with safe driving. CAP is formulated by an attentive text-to-vision shift fusion module, an attentive scene context transfer module, and the driver attention guided acc
    
[^86]: 基于内涵一阶逻辑的强人工智能自我确切机器人

    Strong-AI Autoepistemic Robots Build on Intensional First Order Logic. (arXiv:2212.07935v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.07935](http://arxiv.org/abs/2212.07935)

    本文研究了内涵一阶逻辑作为现代机器人的符号架构，可以推理自身知识、使用自然语言与人类交流、抽象语言属性。同时，通过机器人神经架构的经验获得机器人语言的基础，将其与IFOL理论中的非定义语言概念相联系。

    

    神经符号化人工智能试图以互补的方式集成神经和符号架构，以应对每种架构的优点和缺点，以支持具有推理、学习和认知建模能力的强人工智能系统。本文考虑了内涵一阶逻辑(IFOL)作为现代机器人的符号架构，能够使用自然语言与人类进行交流，并使用自我参照和抽象语言属性推理其自身知识。我们试图通过机器人使用其神经架构的经验来获得机器人语言的基础，并将这种经验与IFOL的PRP（属性/关系/命题）理论中的非定义语言概念（特定/个体和普遍概念）的挖掘（感觉）相联系。我们考虑机器人的四级知识结构：特定自然语言的语法层面（意大利语、法语等）、两个通用语言层面：其语义关系及它的内涵逻辑结构和其它语言概念的陈述。

    Neuro-symbolic AI attempts to integrate neural and symbolic architectures in a manner that addresses strengths and weaknesses of each, in a complementary fashion, in order to support robust strong AI capable of reasoning, learning, and cognitive modeling. In this paper we consider the  intensional First Order Logic (IFOL) as a symbolic architecture of modern robots, able to use natural languages to communicate with humans and to reason about their own knowledge with self-reference and abstraction language property.  We intend to obtain the grounding of robot's language by experience of how it uses its neuronal architectures and hence by associating this experience with the mining (sense) of non-defined language concepts (particulars/individuals and universals) in PRP (Properties/Relations/Propositions) theory of IFOL.  We consider the robot's four-levels knowledge structure: The syntax level of particular natural language (Italian, French, etc..), two universal language levels: its sem
    
[^87]: PASTA：比例幅度谱训练增强用于 Syn-to-Real 领域泛化

    PASTA: Proportional Amplitude Spectrum Training Augmentation for Syn-to-Real Domain Generalization. (arXiv:2212.00979v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.00979](http://arxiv.org/abs/2212.00979)

    本文提出了一种基于比例幅度谱训练增强的方法 PASTA，可有效提高合成数据到真实数据的泛化性能，在多个 Syn-to-Real 任务上均具有优越性能。

    

    合成数据可以提供廉价且丰富的训练数据，适用于真实世界数据稀缺的情况。然而，在真实世界数据上评估的模型在合成数据上训练时表现显著不佳。在本文中，我们提出了 Proportional Amplitude Spectrum Training Augmentation (PASTA)，一种简单而有效的增强策略，可提高合成到真实（Syn-to-Real）泛化性能。 PASTA 在 Fourier 领域中扰动合成图像的幅度谱以生成增强视图。具体而言，使用 PASTA，我们提出了一种结构化扰动策略，其中高频分量相对于低频分量更容易受到扰动。对于语义分割（GTAV-to-Real），目标检测（Sim10K-to-Real）和对象识别（VisDA-C Syn-to-Real）任务，在总共5个 Syn-to-Real 转移中，我们发现 PASTA 的性能优于更复杂的最先进的泛化方法，同时具有互补性。

    Synthetic data offers the promise of cheap and bountiful training data for settings where labeled real-world data is scarce. However, models trained on synthetic data significantly underperform when evaluated on real-world data. In this paper, we propose Proportional Amplitude Spectrum Training Augmentation (PASTA), a simple and effective augmentation strategy to improve out-of-the-box synthetic-to-real (syn-to-real) generalization performance. PASTA perturbs the amplitude spectra of synthetic images in the Fourier domain to generate augmented views. Specifically, with PASTA we propose a structured perturbation strategy where high-frequency components are perturbed relatively more than the low-frequency ones. For the tasks of semantic segmentation (GTAV-to-Real), object detection (Sim10K-to-Real), and object recognition (VisDA-C Syn-to-Real), across a total of 5 syn-to-real shifts, we find that PASTA outperforms more complex state-of-the-art generalization methods while being complemen
    
[^88]: 通过 Lov\'asz Local Lemma 进行采样的马尔可夫随机场学习组合结构

    Learning Combinatorial Structures via Markov Random Fields with Sampling through Lov\'asz Local Lemma. (arXiv:2212.00296v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.00296](http://arxiv.org/abs/2212.00296)

    Nelson是一种基于神经网络和Lov\'asz Local Lemma的方法，使用约束的马尔可夫随机场模型生成满足组合约束条件的样本。

    

    学习组合结构的生成模型在许多应用中具有革命性的影响，但现有方法无法提供高效且准确的学习结果，由于学习目标受到组合约束条件的制约，其梯度估计非常复杂。我们开发了基于 Lov\'asz Local Lemma 的神经网络（Nelson），它能够从约束的马尔可夫随机场模型的分布中生成满足组合约束条件的样本。

    Generative models for learning combinatorial structures have transformative impacts in many applications. However, existing approaches fail to offer efficient and accurate learning results. Because of the highly intractable nature of the gradient estimation of the learning objective subject to combinatorial constraints. Existing gradient estimation methods would easily run into exponential time/memory space, or incur huge estimation errors due to improper approximation. We develop NEural Lovasz Sampler (Nelson), a neural network based on Lov\'asz Local Lemma (LLL). We show it guarantees to generate samples satisfying combinatorial constraints from the distribution of the constrained Markov Random Fields model (MRF) under certain conditions. We further present a fully differentiable contrastive-divergence-based learning framework on constrained MRF (Nelson-CD). Meanwhile, Nelson-CD being fully differentiable allows us to take advantage of the parallel computing power of GPUs, resulting 
    
[^89]: 对抗性廉价交流

    Adversarial Cheap Talk. (arXiv:2211.11030v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.11030](http://arxiv.org/abs/2211.11030)

    本文提出了一种新型对抗性设置，在其中对手只能将信息附加到受害者的观察中，从而产生最小的影响范围，并提出对抗性廉价交流（ACT）算法进行对手训练。在高度受限的情况下，使用ACT训练的对手仍会对受害者的训练和测试表现产生显著影响，揭示了强化学习算法中的一种新的攻击向量。

    

    强化学习中的对抗性攻击通常假定攻击者可以高度特权地访问受害者的参数、环境或数据。本文提出了一种称为廉价交流MDP的新型对抗性设置，其中对手只能将确定性信息附加到受害者的观察中，从而产生最小的影响范围。对手不能掩盖地面事实，影响基本环境动态或奖励信号，引入不稳定性，增加随机性，看到受害者的动作或访问他们的参数。此外，我们提出了一种简单的元学习算法，称为对抗性廉价交流（ACT），在这种设置中对对手进行训练。我们证明，即使在高度受限的情况下，使用ACT训练的对手仍会显着影响受害者的训练和测试表现。影响训练时间表现揭示了一种新的攻击向量，并为现有强化学习算法的成功和失败模式提供了见解。

    Adversarial attacks in reinforcement learning (RL) often assume highly-privileged access to the victim's parameters, environment, or data. Instead, this paper proposes a novel adversarial setting called a Cheap Talk MDP in which an Adversary can merely append deterministic messages to the Victim's observation, resulting in a minimal range of influence. The Adversary cannot occlude ground truth, influence underlying environment dynamics or reward signals, introduce non-stationarity, add stochasticity, see the Victim's actions, or access their parameters. Additionally, we present a simple meta-learning algorithm called Adversarial Cheap Talk (ACT) to train Adversaries in this setting. We demonstrate that an Adversary trained with ACT still significantly influences the Victim's training and testing performance, despite the highly constrained setting. Affecting train-time performance reveals a new attack vector and provides insight into the success and failure modes of existing RL algorith
    
[^90]: 可解释的多智能体强化学习中的行为建议

    Explainable Action Advising for Multi-Agent Reinforcement Learning. (arXiv:2211.07882v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.07882](http://arxiv.org/abs/2211.07882)

    引入可解释行为建议的多智能体强化学习框架，使得学生可以理解所学的内容并进行推理从而提高样本效率和学习效果

    

    行为建议是一种基于师生范式的强化学习知识转移技术。专家老师在训练期间提供建议，以提高学生的样本效率和策略表现。这种建议通常以状态-动作对的形式给出。然而，这使得学生难以推理和应用于新颖状态。我们引入了可解释的行为建议，其中老师提供行为建议和相关的解释，说明为什么选取该行为.这允许学生自我反思所学的内容，实现建议的泛化，并导致学习效率的提高——即使在老师不理想的情况下，也可以有效地应用于单智能体和多智能体场景中。我们通过实验证明，与最先进的方法相比，我们的框架可以产生更好的策略回报和收敛速率。

    Action advising is a knowledge transfer technique for reinforcement learning based on the teacher-student paradigm. An expert teacher provides advice to a student during training in order to improve the student's sample efficiency and policy performance. Such advice is commonly given in the form of state-action pairs. However, it makes it difficult for the student to reason with and apply to novel states. We introduce Explainable Action Advising, in which the teacher provides action advice as well as associated explanations indicating why the action was chosen. This allows the student to self-reflect on what it has learned, enabling advice generalization and leading to improved sample efficiency and learning performance - even in environments where the teacher is sub-optimal. We empirically show that our framework is effective in both single-agent and multi-agent scenarios, yielding improved policy returns and convergence rates when compared to state-of-the-art methods
    
[^91]: 使用对比剪枝权重训练去偏置子网络

    Training Debiased Subnetworks with Contrastive Weight Pruning. (arXiv:2210.05247v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.05247](http://arxiv.org/abs/2210.05247)

    本文探讨了在存在强假相关的偏置网络中提取最优无偏子网络的问题，并提出了使用对比剪枝权重训练实现去偏置子网络的算法 DCWP，在多个应用中都有良好的效果。

    

    神经网络通常存在偏置性，导致提供具有误导性的统计证据，不能很好地推广。因此，提出了在偏置网络中提取最优无偏功能子网络的问题。本文首先提出了现有算法在探索具有强假相关性的无偏子网络存在限制的理论洞见，然后进一步阐明了偏差冲突样本对结构学习的重要性，并基于学习的（伪）无偏样本和选择性偏差冲突样本，提出了去偏置对比剪枝（DCWP）算法。在图像分类、语言模型和强化学习等各种应用中验证了 DCWP 的有效性。

    Neural networks are often biased to spuriously correlated features that provide misleading statistical evidence that does not generalize. This raises an interesting question: ``Does an optimal unbiased functional subnetwork exist in a severely biased network? If so, how to extract such subnetwork?" While empirical evidence has been accumulated about the existence of such unbiased subnetworks, these observations are mainly based on the guidance of ground-truth unbiased samples. Thus, it is unexplored how to discover the optimal subnetworks with biased training datasets in practice. To address this, here we first present our theoretical insight that alerts potential limitations of existing algorithms in exploring unbiased subnetworks in the presence of strong spurious correlations. We then further elucidate the importance of bias-conflicting samples on structure learning. Motivated by these observations, we propose a Debiased Contrastive Weight Pruning (DCWP) algorithm, which probes unbi
    
[^92]: 最佳决策并不是最佳建议：制定考虑服从度的推荐

    The Best Decisions Are Not the Best Advice: Making Adherence-Aware Recommendations. (arXiv:2209.01874v3 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2209.01874](http://arxiv.org/abs/2209.01874)

    论文提出了一个考虑服从度的优化框架，来捕获推荐策略和实际执行策略之间的差异。通过分析部分服从度对最佳建议的影响，发现忽略部分服从度可能导致任意严重的性能恶化。

    

    许多高风险决策遵循专家参与的结构，即人类操作员从算法中接收建议但最终是决策制定者。因此，算法的建议可能与实践中实际执行的决策不同。然而，大多数算法建议是通过解决优化问题获得的，该问题假定建议将完美执行。我们提出了一种考虑服从度的优化框架，以捕获推荐策略和实际执行策略之间的差异，并分析部分服从度对最佳建议的影响。我们发现，忽略部分服从度现象，与目前大多数推荐引擎所做的，可能导致与当前人类基线性能和推荐算法预期性能相比，出现任意严重的性能恶化。我们的框架还提供了有用的工具来分析结构和计算最佳推荐方案。

    Many high-stake decisions follow an expert-in-loop structure in that a human operator receives recommendations from an algorithm but is the ultimate decision maker. Hence, the algorithm's recommendation may differ from the actual decision implemented in practice. However, most algorithmic recommendations are obtained by solving an optimization problem that assumes recommendations will be perfectly implemented. We propose an adherence-aware optimization framework to capture the dichotomy between the recommended and the implemented policy and analyze the impact of partial adherence on the optimal recommendation. We show that overlooking the partial adherence phenomenon, as is currently being done by most recommendation engines, can lead to arbitrarily severe performance deterioration, compared with both the current human baseline performance and what is expected by the recommendation algorithm. Our framework also provides useful tools to analyze the structure and to compute optimal recom
    
[^93]: 解决机器学习众包工作者的人类受试者身份问题

    Resolving the Human Subjects Status of Machine Learning's Crowdworkers. (arXiv:2206.04039v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2206.04039](http://arxiv.org/abs/2206.04039)

    机器学习在研究中使用的众包工作者问题引起了对其受试者身份的争议与监管合规性，本文针对该问题进行研究，重点关注了自然语言处理领域中的研究监管挑战。

    

    近年来，机器学习(Machine Learning, ML)在构建数据集和解决需要人类交互或判断的研究问题方面，已经严重依赖于众包工作者。由于执行的任务多样化和数据用途的多样性，很难确定何时将众包工作者视为工人(而非人类受试者)。这些困难加剧了政策的冲突，一些机构和研究人员将所有ML众包工作者视为人类受试者，而其他人则认为它们很少构成人类受试者。值得注意的是，包括众包工作的鲜有ML论文提到IRB的监督，引发了违反道德和法规要求的可能性。我们研究了ML众包研究的适当划定，并关注自然语言处理领域暴露出的独特研究监督挑战。至关重要的是，在美国公共规则下，这些判断取决于关于问题的确定，涉及谁(或什么)的问题。

    In recent years, machine learning (ML) has relied heavily on crowdworkers both for building datasets and for addressing research questions requiring human interaction or judgment. The diverse tasks performed and uses of the data produced render it difficult to determine when crowdworkers are best thought of as workers (versus human subjects). These difficulties are compounded by conflicting policies, with some institutions and researchers regarding all ML crowdworkers as human subjects and others holding that they rarely constitute human subjects. Notably few ML papers involving crowdwork mention IRB oversight, raising the prospect of non-compliance with ethical and regulatory requirements. We investigate the appropriate designation of ML crowdsourcing studies, focusing our inquiry on natural language processing to expose unique challenges for research oversight. Crucially, under the U.S. Common Rule, these judgments hinge on determinations of aboutness, concerning both whom (or what) 
    
[^94]: 论论证框架的优先推理：与纯朴集合的双射

    On the preferred extensions of argumentation frameworks: bijections with naive sets. (arXiv:2202.05506v2 [math.CO] UPDATED)

    [http://arxiv.org/abs/2202.05506](http://arxiv.org/abs/2202.05506)

    本文通过与另一个框架的纯朴集合双射的方法解决了找到一个论证框架的优先推理的问题。其中，识别纯朴-双射的论证框架是困难的，但入度有限的框架中可行。此外，引入了不可简化的自卫集合的概念，并证明了一个论证框架的优先推理与另一个框架的纯朴集合之间存在双射。

    

    本文讨论了通过与另一个框架的纯朴集合双射的方法来找到一个论证框架的优先推理的问题。首先，我们考虑了一个论证框架是纯朴-双射的情况：其纯朴集合和优先推理相等。识别纯朴-双射的论证框架是困难的，但我们证明了在入度有限的框架中这是可行的。接下来，我们介绍了一个论证框架的优先推理与一个与其相同的论点集上的另一个框架的纯朴集合是可接受封闭的（两个可接受集合的交是可接受的）的双射。另一方面，我们证明了鉴别可接受封闭的论证框架是coNP完备的。最后，我们引入了不可简化的自卫集合的概念，这些集合不是其他集合的并集。结果发现，一个论证框架的优先推理与另一个框架的纯朴集合之间存在双射。

    This paper deals with the problem of finding the preferred extensions of an argumentation framework by means of a bijection with the naive sets of another framework. First, we consider the case where an argumentation framework is naive-bijective: its naive sets and preferred extensions are equal. Recognizing naive-bijective argumentation frameworks is hard, but we show that it is tractable for frameworks with bounded in-degree. Next, we give a bijection between the preferred extensions of an argumentation framework being admissible-closed (the intersection of two admissible sets is admissible) and the naive sets of another framework on the same set of arguments. On the other hand, we prove that identifying admissible-closed argumentation frameworks is coNP-complete. At last, we introduce the notion of irreducible self-defending sets as those that are not the union of others. It turns out there exists a bijection between the preferred extensions of an argumentation framework and the nai
    
[^95]: 后量子联想记忆

    A Post-Quantum Associative Memory. (arXiv:2201.12305v2 [quant-ph] CROSS LISTED)

    [http://arxiv.org/abs/2201.12305](http://arxiv.org/abs/2201.12305)

    该论文研究了一种基于广义概率理论(GPT)的联想记忆的模型，证明了GPT可以比经典和量子理论更好地处理具有指数级优势的特定任务。

    

    联想记忆是一种可以通过部分信息检索完整信息的设备。在广义概率论（GPT）的框架内，我们研究了一种联想记忆的玩具模型，以及它所受到的极限限制。在GPT的规定下，我们探讨了可以容纳$2^m$个状态且其中的任意$N$个状态都是完全可区分的最小GPT维度$d(N,m)$。通过引用Danzer和Grünbaum的老结果，我们证明了当$m$为2时$d(2,m)=m+1$，而在需要GPT分别为经典或量子理论的情况下，该维度分别为$O(2^m)$。这提供了一个例子表明，在某些任务上GPT比经典和量子理论都有指数级的优势。更一般地，我们解决了固定$N$和渐近大的$m$的情况，证明了$d(N,m) \leq m^{1+o_N(1)}$（当$m\to\infty$时）。

    Associative memories are devices storing information that can be fully retrieved given partial disclosure of it. We examine a toy model of associative memory and the ultimate limitations it is subjected to within the framework of general probabilistic theories (GPTs), which represent the most general class of physical theories satisfying some basic operational axioms. We ask ourselves how large the dimension of a GPT should be so that it can accommodate $2^m$ states with the property that any $N$ of them are perfectly distinguishable. Call $d(N,m)$ the minimal such dimension. Invoking an old result by Danzer and Gr\"unbaum, we prove that $d(2,m)=m+1$, to be compared with $O(2^m)$ when the GPT is required to be either classical or quantum. This yields an example of a task where GPTs outperform both classical and quantum theory exponentially. More generally, we resolve the case of fixed $N$ and asymptotically large $m$, proving that $d(N,m) \leq m^{1+o_N(1)}$ (as $m\to\infty$) for every 
    
[^96]: 基于知识的主动学习

    Knowledge-driven Active Learning. (arXiv:2110.08265v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.08265](http://arxiv.org/abs/2110.08265)

    本文提出了基于知识的主动学习(KAL)框架，将通用领域知识转换为逻辑约束，作为样本选择的指南，使非专业用户能够用更少的样本训练模型，并在降低标记数据需求量的同时保持出色性能。

    

    深度学习模型的部署仍然受限于有限的监督数据问题。为了解决这个问题，主动学习策略旨在最小化训练深度学习模型所需的标记数据量。大多数主动学习策略基于不确定性样本选择，通常仅限于位于决策边界附近的样本。这些技术在理论上是可行的，但基于内容对所选样本的理解并不直观，这进一步导致非专业人士将深度学习视为黑盒子。在这里，我们首次提出考虑通用领域知识，并使非专业用户能够用更少的样本来训练模型。在我们的基于知识的主动学习(KAL)框架中，基于规则的知识被转换为逻辑约束，并检查其违反作为样本选择的自然指南。我们展示了即使是数据和输出类别之间的简单关系也可以提供出色的性能，同时降低标记数据需求量。

    The deployment of Deep Learning (DL) models is still precluded in those contexts where the amount of supervised data is limited. To answer this issue, active learning strategies aim at minimizing the amount of labelled data required to train a DL model. Most active strategies are based on uncertain sample selection, and even often restricted to samples lying close to the decision boundary. These techniques are theoretically sound, but an understanding of the selected samples based on their content is not straightforward, further driving non-experts to consider DL as a black-box. For the first time, here we propose to take into consideration common domain-knowledge and enable non-expert users to train a model with fewer samples. In our Knowledge-driven Active Learning (KAL) framework, rule-based knowledge is converted into logic constraints and their violation is checked as a natural guide for sample selection. We show that even simple relationships among data and output classes offer a
    

