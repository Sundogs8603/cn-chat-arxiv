# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Transformers Get Stable: An End-to-End Signal Propagation Theory for Language Models](https://arxiv.org/abs/2403.09635) | 提出了一个统一的信号传播理论，提供了控制transformer模型信号传播的公式，提出了DeepScaleLM初始化和缩放方案，使得可以训练非常深的模型，并发现深层模型在多个任务和数据集上胜过浅层模型。 |
| [^2] | [3D-VLA: A 3D Vision-Language-Action Generative World Model](https://arxiv.org/abs/2403.09631) | 提出了3D-VLA，通过将3D感知、推理和动作无缝连接，建立一个生成世界模型，弥补了现有VLA模型只能处理2D输入且忽视世界动态与动作之间关系的不足。 |
| [^3] | [Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking](https://arxiv.org/abs/2403.09629) | Quiet-STaR提出了一种新的泛化版本，在每个标记处生成解释未来文本的思考过程，从而改善预测能力 |
| [^4] | [Minimax Optimal and Computationally Efficient Algorithms for Distributionally Robust Offline Reinforcement Learning](https://arxiv.org/abs/2403.09621) | 研究提出了最小化最优和计算高效的算法，为鲁棒离线强化学习中的函数逼近带来新颖视角，并展示了其与标准离线强化学习中函数逼近的区别。 |
| [^5] | [Large Language Models and Causal Inference in Collaboration: A Comprehensive Survey](https://arxiv.org/abs/2403.09606) | 大型语言模型的出现极大影响了自然语言处理领域，特别是通过其先进的推理能力。而本综述则重点评估和改进了大型语言模型在因果推断方面的应用，包括提高推理能力、解决公平和安全问题、提供解释和处理多模态。 |
| [^6] | [Counterfactual contrastive learning: robust representations via causal image synthesis](https://arxiv.org/abs/2403.09605) | 本研究提出了CF-SimCLR，一种反事实对照学习方法，利用近似反事实推断创造正样本，大大提高了模型对采集偏移的稳健性，并在多个数据集上取得了较高的下游性能。 |
| [^7] | [Optimistic Verifiable Training by Controlling Hardware Nondeterminism](https://arxiv.org/abs/2403.09603) | 提出了一种方法，结合了在比目标模型更高精度下进行训练、在中间计算步骤后进行四舍五入，并基于自适应阈值存储四舍五入决策，以应对硬件非确定性对训练过程的影响。 |
| [^8] | [Algorithmic syntactic causal identification](https://arxiv.org/abs/2403.09580) | 通过替换传统概率论为对称单调范畴的替代基础，可以扩展因果识别技术到更多因果设置中。 |
| [^9] | [Enhancing Trust in Autonomous Agents: An Architecture for Accountability and Explainability through Blockchain and Large Language Models](https://arxiv.org/abs/2403.09567) | 通过区块链和大型语言模型实现责任和可解释性的架构，提高自主代理的信任和安全性，增强代理与用户之间的沟通效果。 |
| [^10] | [Welcome Your New AI Teammate: On Safety Analysis by Leashing Large Language Models](https://arxiv.org/abs/2403.09565) | 该研究提出了使用大语言模型进行安全工程领域的危险分析与风险评估自动化的框架，旨在加速SafetyOps周期中关键步骤的进行。 |
| [^11] | [Generalizing Denoising to Non-Equilibrium Structures Improves Equivariant Force Fields](https://arxiv.org/abs/2403.09549) | 将去噪方法推广到非平衡结构，从而改进等变力场的性能，提高了对原子间相互作用的理解以及在分子动力学和催化剂设计等领域的应用。 |
| [^12] | [Logits of API-Protected LLMs Leak Proprietary Information](https://arxiv.org/abs/2403.09539) | 大多数现代LLM受到softmax瓶颈影响，可以以较低成本获取API保护的LLM的非公开信息和解锁多种功能 |
| [^13] | [VisionGPT-3D: A Generalized Multimodal Agent for Enhanced 3D Vision Understanding](https://arxiv.org/abs/2403.09530) | 提出了一个统一的VisionGPT-3D框架，整合了最先进的视觉模型，有助于提升计算机视觉对于3D视觉理解的能力 |
| [^14] | [AdaShield: Safeguarding Multimodal Large Language Models from Structure-based Attack via Adaptive Shield Prompting](https://arxiv.org/abs/2403.09513) | AdaShield 提出了自适应盾牌提示方法，无需微调或额外训练模块，即可保护多模态大型语言模型免受基于结构的越狱攻击。 |
| [^15] | [Trust AI Regulation? Discerning users are vital to build trust and effective AI regulation](https://arxiv.org/abs/2403.09510) | 通过演化博弈论量化模拟用户、AI创作者和监管者面临的困境，提出政府认可和奖励监管者可以激励有效监管的机制，帮助建立值得信赖的AI和用户信任。 |
| [^16] | [Don't Judge by the Look: A Motion Coherent Augmentation for Video Recognition](https://arxiv.org/abs/2403.09506) | 本研究提出了一种名为运动一致增强（MCA）的数据增强方法，通过引入外观变化来鼓励模型优先考虑视频中的运动信息，而不是静态外观。 |
| [^17] | [EquiAV: Leveraging Equivariance for Audio-Visual Contrastive Learning](https://arxiv.org/abs/2403.09502) | 这项研究提出了一种利用等变性进行音频-视觉对比学习的新框架，通过一个共享的基于注意力的变换预测器来实现特征聚合和嵌入表示，有效提供了强大的监督，且计算开销最小。 |
| [^18] | [A Reinforcement Learning Approach to Dairy Farm Battery Management using Q Learning](https://arxiv.org/abs/2403.09499) | 该研究提出了一种基于Q学习的算法，以实现在奶牛养殖中整合可再生能源，以改善电池管理，应对电能消耗波动和能源价格波动的挑战。 |
| [^19] | [From Skepticism to Acceptance: Simulating the Attitude Dynamics Toward Fake News](https://arxiv.org/abs/2403.09498) | 本研究引入了基于大型语言模型的虚假新闻传播仿真框架，研究了虚假新闻传播的趋势和控制，每个代理人在仿真中代表具有独特个性的个体。 |
| [^20] | [Rectifying Demonstration Shortcut in In-Context Learning](https://arxiv.org/abs/2403.09488) | 本研究旨在纠正大型语言模型在上下文学习中的演示快捷方式，并引入了一种新的明示意识校准方法。 |
| [^21] | [Clinical Reasoning over Tabular Data and Text with Bayesian Networks](https://arxiv.org/abs/2403.09481) | 本文比较和讨论了如何将贝叶斯网络与神经文本表示相结合，以改进临床推理，特别是在处理自然语言数据方面。 |
| [^22] | [What Sketch Explainability Really Means for Downstream Tasks](https://arxiv.org/abs/2403.09480) | 本文探讨了草图解释的独特性，提出了适用于各种下游任务的解释性解决方案，包括四个应用领域：检索、生成、辅助绘图以及草图对抗攻击。 |
| [^23] | [LLM-based agents for automating the enhancement of user story quality: An early report](https://arxiv.org/abs/2403.09442) | 本研究探索了使用大型语言模型自动改善用户故事质量的方法，验证了LLMs对提高用户故事质量的潜力，并在敏捷开发中展示了AI的实际应用。 |
| [^24] | [3D-SceneDreamer: Text-Driven 3D-Consistent Scene Generation](https://arxiv.org/abs/2403.09439) | 通过引入全局3D信息和生成性细化网络，结合NeRF模型和2D扩散模型先验，提出了3D-SceneDreamer这一文本驱动的一致3D场景生成方法。 |
| [^25] | [Mitigating attribute amplification in counterfactual image generation](https://arxiv.org/abs/2403.09422) | 提出了一种软反事实微调方法，可以在保持生成图像有效性的同时，显著减少属性放大效应。 |
| [^26] | [OpenGraph: Open-Vocabulary Hierarchical 3D Graph Representation in Large-Scale Outdoor Environments](https://arxiv.org/abs/2403.09412) | 开放图谱是针对大规模室外环境设计的开放词汇分层图结构，旨在解决现有地图受限于室内场景和VLM特征的问题，通过视觉图像提取实例和标题，并加强文字推理。 |
| [^27] | [XCoOp: Explainable Prompt Learning for Computer-Aided Diagnosis via Concept-guided Context Optimization](https://arxiv.org/abs/2403.09410) | 提出了一种新颖的可解释的提示学习框架，通过对齐图像、可学习提示和临床概念驱动提示的语义，利用医学知识。 |
| [^28] | ["Like a Nesting Doll": Analyzing Recursion Analogies Generated by CS Students using Large Language Models](https://arxiv.org/abs/2403.09409) | 使用大语言模型ChatGPT，研究了超过350名一年级计算机学生生成的递归类比，探讨了如何利用这些类比帮助理解复杂的计算概念 |
| [^29] | [LM2D: Lyrics- and Music-Driven Dance Synthesis](https://arxiv.org/abs/2403.09407) | 提出了LM2D，一种结合了多模态扩散模型和一致性蒸馏的新颖概率架构，旨在在音乐和歌词条件下进行舞蹈生成；介绍了第一个涵盖音乐和歌词的3D舞蹈运动数据集。 |
| [^30] | [Heuristic Reasoning in AI: Instrumental Use and Mimetic Absorption](https://arxiv.org/abs/2403.09404) | 通过创新性实验，我们揭示了人工智能系统在精度最大化和努力减少之间的权衡，以及在详尽的逻辑处理和使用认知快捷方式（启发式）之间转换的条件，并区分了启发式的工具性使用和模仿吸收两种方式。 |
| [^31] | [A Multi-population Integrated Approach for Capacitated Location Routing](https://arxiv.org/abs/2403.09361) | 该论文提出了一个多种群综合方法，通过多仓库边装配交叉和有效局部搜索等手段，实现了对容量位置路径问题的有效优化。 |
| [^32] | [D3T: Distinctive Dual-Domain Teacher Zigzagging Across RGB-Thermal Gap for Domain-Adaptive Object Detection](https://arxiv.org/abs/2403.09359) | 提出了一种称为Distinctive Dual-Domain Teacher (D3T) 的框架，通过独特的训练范式以及在双教师之间的曲折学习方法，成功实现了从可见到热红外领域的领域自适应目标检测。 |
| [^33] | [AVIBench: Towards Evaluating the Robustness of Large Vision-Language Model on Adversarial Visual-Instructions](https://arxiv.org/abs/2403.09346) | AVIBench是一个框架，用于分析大型视觉-语言模型对抗各种形式的对抗性视觉指令的鲁棒性，包括图像和文本攻击以及内容偏见攻击。 |
| [^34] | [SketchINR: A First Look into Sketches as Implicit Neural Representations](https://arxiv.org/abs/2403.09344) | SketchINR将矢量素描压缩到固定维度的潜在空间中，通过隐式神经模型编码素描的形状，并在多个任务上表现优异，包括数据压缩、高保真度的表示以及快速解码渲染。 |
| [^35] | [LocalMamba: Visual State Space Model with Windowed Selective Scan](https://arxiv.org/abs/2403.09338) | 本论文提出了一种新颖的局部扫描策略，通过在图像中引入窗口划分的方法，有效捕捉局部依赖性，同时保持全局视角，从而增强了视觉Mamba模型的序列建模性能。 |
| [^36] | [Griffon v2: Advancing Multimodal Perception with High-Resolution Scaling and Visual-Language Co-Referring](https://arxiv.org/abs/2403.09333) | Griffon v2通过引入高分辨率缩放和视觉-语言共指，提升了多模态感知能力，尤其是对于小对象的感知能力。 |
| [^37] | [HeadEvolver: Text to Head Avatars via Locally Learnable Mesh Deformation](https://arxiv.org/abs/2403.09326) | 通过可学习的局部网格变形技术，HeadEvolver框架可以通过文本引导生成高质量的头部头像，保留细节并支持编辑和动画。 |
| [^38] | [SD-Net: Symmetric-Aware Keypoint Prediction and Domain Adaptation for 6D Pose Estimation In Bin-picking Scenarios](https://arxiv.org/abs/2403.09317) | SD-Net通过对称感知关键点预测和自训练领域自适应，解决了对称物体和真实场景6D姿态估计中的关键问题。 |
| [^39] | [Knowledge Distillation in YOLOX-ViT for Side-Scan Sonar Object Detection](https://arxiv.org/abs/2403.09313) | YOLOX-ViT中的知识蒸馏有效减少了侧扫声纳目标检测中墙体误报，并引入的视觉变换器层显著提高了水下环境中的目标检测准确性。 |
| [^40] | [SELECTOR: Heterogeneous graph network with convolutional masked autoencoder for multimodal robust prediction of cancer survival](https://arxiv.org/abs/2403.09290) | 该论文介绍了一种名为SELECTOR的异构图网络，利用卷积掩码自编码器进行癌症患者生存的鲁棒多模态预测 |
| [^41] | [Silico-centric Theory of Mind](https://arxiv.org/abs/2403.09289) | 本研究探讨在拥有多个独立AI代理的环境中的精神理论（ToM），并发现当代AI展现出接近完美的性能。 |
| [^42] | [Adversarial Training with OCR Modality Perturbation for Scene-Text Visual Question Answering](https://arxiv.org/abs/2403.09288) | 该论文提出了一种具有空间感知能力的多模态对抗训练架构，通过Adversarial OCR Enhancement（AOE）模块和空间感知自注意力（SASA）机制，可以增强OCR文本的容错性，并帮助模型更好地捕捉OCR标记之间的空间关系。 |
| [^43] | [Leveraging Constraint Programming in a Deep Learning Approach for Dynamically Solving the Flexible Job-Shop Scheduling Problem](https://arxiv.org/abs/2403.09249) | 该研究将约束编程与深度学习相结合，通过使用约束编程生成的最优解来训练深度学习模型，从而消除了深度强化学习中广泛探索的需要，提高了整体性能。 |
| [^44] | [Generating Feasible and Plausible Counterfactual Explanations for Outcome Prediction of Business Processes](https://arxiv.org/abs/2403.09232) | 该论文提出了一种数据驱动方法 REVISEDplus，旨在生成更可行和可信的反事实解释，解决了处理序列性质业务流程案例时遇到的挑战。 |
| [^45] | [BEHAVIOR-1K: A Human-Centered, Embodied AI Benchmark with 1,000 Everyday Activities and Realistic Simulation](https://arxiv.org/abs/2403.09227) | BEHAVIOR-1K是一个以人为中心的机器人技术综合仿真基准测试，包含1,000个日常活动和用于支持这些活动的逼真模拟环境。这些活动具有长视野，复杂操作技能依赖，对于当前最先进的机器人学习解决方案仍然具有挑战性。 |
| [^46] | [On the Laplace Approximation as Model Selection Criterion for Gaussian Processes](https://arxiv.org/abs/2403.09215) | 通过引入基于Laplace逼近的多种度量标准，本研究解决了高斯过程模型选择中遇到的性能不佳和运行时间问题，实验结果表明这些新的标准在质量上与黄金标准动态嵌套抽样相当，同时保持了计算速度。 |
| [^47] | [LAN: Learning Adaptive Neighbors for Real-Time Insider Threat Detection](https://arxiv.org/abs/2403.09209) | 该论文的贡献是提出了一个名为LAN的框架，能够实时在活动级别进行内部威胁检测，并学习活动序列内的时间依赖关系和活动之间的关系。 |
| [^48] | [Upper Bound of Bayesian Generalization Error in Partial Concept Bottleneck Model (CBM): Partial CBM outperforms naive CBM](https://arxiv.org/abs/2403.09206) | 本文在三层线性结构的部分CBM中揭示了贝叶斯概化错误的上界，进一步证明部分CBM优于朴素CBM。 |
| [^49] | [Customizing Segmentation Foundation Model via Prompt Learning for Instance Segmentation](https://arxiv.org/abs/2403.09199) | 提出了一种针对Segment Anything Model (SAM)的新颖方法，通过提示学习定制化实例分割，解决了在应用于定制化实例分割时面临的输入提示模糊性和额外训练需求的挑战 |
| [^50] | [Are Vision Language Models Texture or Shape Biased and Can We Steer Them?](https://arxiv.org/abs/2403.09193) | 本文研究了广泛应用的视觉语言模型中的纹理与形状偏见，发现这些模型通常比视觉编码器更偏向形状，暗示视觉偏见在一定程度上会受到文本的调节 |
| [^51] | [Intention-aware Denoising Diffusion Model for Trajectory Prediction](https://arxiv.org/abs/2403.09190) | 该论文提出了一种解决传统轨迹预测模型受限和训练不稳定问题的新方法，即利用意图感知去噪扩散模型（IDM）生成未来轨迹的分布。 |
| [^52] | [Learning Algorithms for Verification of Markov Decision Processes](https://arxiv.org/abs/2403.09184) | 该研究提出了一个通用框架，将学习算法和启发式引导应用于马尔可夫决策过程（MDP）的验证，旨在提高性能，避免对状态空间进行穷尽探索。 |
| [^53] | [ADEdgeDrop: Adversarial Edge Dropping for Robust Graph Neural Networks](https://arxiv.org/abs/2403.09171) | ADEdgeDrop提出了一种敌对边缘删除方法，通过引入敌对边缘预测器指导边缘删除，从而提高了图神经网络的稳健性。 |
| [^54] | [USimAgent: Large Language Models for Simulating Search Users](https://arxiv.org/abs/2403.09142) | 该论文介绍了一种基于大型语言模型的用户搜索行为模拟器 USimAgent，可以模拟用户在搜索过程中的查询、点击和停止行为，实现生成特定搜索的完整搜索会话。 |
| [^55] | [Uncertainty Estimation in Multi-Agent Distributed Learning for AI-Enabled Edge Devices](https://arxiv.org/abs/2403.09141) | 研究探索了在支持AI的边缘设备中实现分布式数据处理的方法，重点解决了在独立代理遇到的数据集的空间和时间变异性中确定学习结果的置信水平挑战。 |
| [^56] | [ProSwitch: Knowledge-Guided Language Model Fine-Tuning to Generate Professional and Non-Professional Styled Text](https://arxiv.org/abs/2403.09131) | ProSwitch通过知识引导的指令微调，在专业和非专业风格之间生成文本，并在专业性评估和质量评估方面表现出优越性。 |
| [^57] | [AutoLoRA: Automatically Tuning Matrix Ranks in Low-Rank Adaptation Based on Meta Learning](https://arxiv.org/abs/2403.09113) | AutoLoRA提出了一个基于元学习的框架，自动识别每个LoRA层的最佳秩，以解决LoRA中秩分配和秩搜索的问题，进而提高微调性能。 |
| [^58] | [MCFEND: A Multi-source Benchmark Dataset for Chinese Fake News Detection](https://arxiv.org/abs/2403.09092) | MCFEND是第一个用于中文假新闻检测的多源基准数据集，解决了单一来源数据集应用于多源新闻数据时性能下降的问题。 |
| [^59] | [Meaningful Learning: Advancing Abstract Reasoning in Large Language Models via Generic Fact Guidance](https://arxiv.org/abs/2403.09085) | 设计了一个抽象推理数据集和有意义学习范式，教导大型语言模型如何利用通用事实进行推理，有效提升了抽象推理能力。 |
| [^60] | [UniCode: Learning a Unified Codebook for Multimodal Large Language Models](https://arxiv.org/abs/2403.09072) | UniCode提出一种学习统一码书的方法，解决多模大语言模型中对视觉和文本进行标记的关键问题，使模型能够生成高质量的图像，并可适应各种压缩方法。 |
| [^61] | [Distribution and Depth-Aware Transformers for 3D Human Mesh Recovery](https://arxiv.org/abs/2403.09063) | 引入了分布和深度感知人体网格恢复（D2A-HMR），通过设计端到端的变压器架构，最小化分布之间的差异并整合场景深度信息，从而实现了明确和稳健的人体建模。 |
| [^62] | [A Continued Pretrained LLM Approach for Automatic Medical Note Generation](https://arxiv.org/abs/2403.09057) | 这项研究提出了一种用于医疗记录生成的持续预训练LLM方法，在PubMedQA方面性能优于GPT-4，能够更好地捕捉正确的医疗概念，并且在正确性和完整性方面超过人类抄写员。 |
| [^63] | [Keyformer: KV Cache Reduction through Key Tokens Selection for Efficient Generative Inference](https://arxiv.org/abs/2403.09054) | 本文提出了一种名为“Keyformer”的创新推断时间方法，旨在通过选择关键标记来减少KV缓存的挑战，提高内存带宽利用率。 |
| [^64] | [Towards a theory of model distillation](https://arxiv.org/abs/2403.09053) | 提出了模型蒸馏的一般理论，通过PAC-蒸馏定义，提出了抽取神经网络训练权重知识的新算法，并证明了蒸馏比从头学习更便宜且有助于理解其复杂性。 |
| [^65] | [Spatial-temporal Memories Enhanced Graph Autoencoder for Anomaly Detection in Dynamic Graphs](https://arxiv.org/abs/2403.09039) | 提出了一种空间-时间记忆增强图自编码器（STRIPE）用于动态图中的异常检测，通过结合图神经网络和门控时间卷积层来提取空间特征和时间特征。 |
| [^66] | [Unlocking the conversion of Web Screenshots into HTML Code with the WebSight Dataset](https://arxiv.org/abs/2403.09029) | 本研究介绍了 WebSight 数据集，通过对 VLM 进行微调，实现了将网页截图转换为功能性 HTML 代码的能力，为解决屏幕截图转换为 HTML 代码的挑战提供了新的解决方案。 |
| [^67] | [Semiparametric Token-Sequence Co-Supervision](https://arxiv.org/abs/2403.09024) | 引入了一种半参数令牌序列共监督训练方法，通过同时利用传统的下一个令牌预测损失和下一个序列预测损失来训练语言模型，实验结果显示这种方法能够提高模型的泛化能力。 |
| [^68] | [Safe Road-Crossing by Autonomous Wheelchairs: a Novel Dataset and its Experimental Evaluation](https://arxiv.org/abs/2403.08984) | 提出了一种多传感器融合方法，支持自主轮椅和飞行无人机系统的安全过马路决策，实验结果表明使用多传感器可以提高决策准确性和有效支持安全评估 |
| [^69] | [Representing Anatomical Trees by Denoising Diffusion of Implicit Neural Fields](https://arxiv.org/abs/2403.08974) | 提出了一种使用隐式神经表示和去噪扩散来准确捕捉解剖树几何和拓扑结构的新方法 |
| [^70] | [PathM3: A Multimodal Multi-Task Multiple Instance Learning Framework for Whole Slide Image Classification and Captioning](https://arxiv.org/abs/2403.08967) | 提出了一种 PathM3 框架，用于WSI分类和字幕生成，采用了多模态、多任务、多实例学习方法，通过查询式transformer有效对齐WSIs与诊断性字幕。 |
| [^71] | [Using Deep Learning for Morphological Classification in Pigs with a Focus on Sanitary Monitoring](https://arxiv.org/abs/2403.08962) | 本文提出使用D-CNN网络进行猪类形态分类，重点关注卫生监测特征，取得了有效的分类效果。 |
| [^72] | [AI coach for badminton](https://arxiv.org/abs/2403.08956) | 通过运用先进的神经网络方法剖析羽毛球比赛视频，提取球员动力学和生物力学见解，以推导改进技术的预测模型 |
| [^73] | [Towards Efficient Risk-Sensitive Policy Gradient: An Iteration Complexity Analysis](https://arxiv.org/abs/2403.08955) | 本文对风险敏感策略梯度方法进行了迭代复杂度分析，发现其能够通过使用指数效用函数达到较低的迭代复杂度。 |
| [^74] | [Exploring Prompt Engineering Practices in the Enterprise](https://arxiv.org/abs/2403.08950) | 研究者分析了提示编辑行为的会话，以更好地了解提示工程实践。 |
| [^75] | [Language-based game theory in the age of artificial intelligence](https://arxiv.org/abs/2403.08944) | 最近的实验研究揭示了语言内容显著影响决策，促使从基于结果转向基于语言的效用函数的范式转变。 |
| [^76] | [Bugs in Large Language Models Generated Code](https://arxiv.org/abs/2403.08937) | 本文研究了使用三种主要LLM生成的代码中收集的333个缺陷样本，并识别了10种独特的错误模式。 |
| [^77] | [Beyond Joint Demonstrations: Personalized Expert Guidance for Efficient Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2403.08936) | 提出了个性化专家示范的概念，为每个智体或不同类型的智体提供针对个人目标的指导，解决了多智体强化学习中联合示范困难的问题。 |
| [^78] | [Unveiling the Truth: Exploring Human Gaze Patterns in Fake Images](https://arxiv.org/abs/2403.08933) | 本研究利用人类语义知识研究了虚假图像检测框架的可能性，通过收集新数据集和进行眼动实验，探讨了眼动在此过程中的作用。 |
| [^79] | [Cross-Modal Learning of Housing Quality in Amsterdam](https://arxiv.org/abs/2403.08915) | 通过认真筛选和合适的预训练模型，Flickr图像特征与空中图像特征相结合能够将性能差距从30%降低到15% |
| [^80] | [Meta-operators for Enabling Parallel Planning Using Deep Reinforcement Learning](https://arxiv.org/abs/2403.08910) | 引入了元算子的概念，使得RL动作空间能够同时处理多个规划操作符，从而实现新的规划视角，例如并行规划。 |
| [^81] | [Strategizing against Q-learners: A Control-theoretical Approach](https://arxiv.org/abs/2403.08906) | 在这篇论文中，作者探讨了Q-learning算法在游戏中受到策略性对手的操纵的敏感性，并提出了一种控制论方法来解决这个问题。 |
| [^82] | [SLCF-Net: Sequential LiDAR-Camera Fusion for Semantic Scene Completion using a 3D Recurrent U-Net](https://arxiv.org/abs/2403.08885) | SLCF-Net是一种用于语义场景完善任务的新方法，通过序列融合激光雷达和相机数据，联合估计缺失的几何和语义信息，并引入了高斯衰减深度先验投影模块以实现2D图像特征和3D场景体积的关联，同时设计了一种新颖的损失函数来确保时间一致性。 |
| [^83] | [Cultural evolution in populations of Large Language Models](https://arxiv.org/abs/2403.08882) | 大型语言模型在模仿人类行为方面具有潜力，可用于研究文化演化中由进化的认知机制引起的社会信息转变的影响。 |
| [^84] | [Multi-Objective Optimization Using Adaptive Distributed Reinforcement Learning](https://arxiv.org/abs/2403.08879) | 提出了一种在智能交通系统环境下进行多目标、多智能体强化学习的算法，具有高学习效率和低计算要求。 |
| [^85] | [Bifurcated Attention for Single-Context Large-Batch Sampling](https://arxiv.org/abs/2403.08845) | 分叉注意力是针对语言模型推断中单上下文批量抽样环境开发的方法，通过将注意力机制分成两个独立的操作来减少冗余内存IO成本，提高效率并降低延迟。 |
| [^86] | [AcademiaOS: Automating Grounded Theory Development in Qualitative Research with Large Language Models](https://arxiv.org/abs/2403.08844) | AcademiaOS利用大型语言模型自动化定性研究中的理论建构，为学术界提供新颖的见解。 |
| [^87] | [Fuzzy Fault Trees Formalized](https://arxiv.org/abs/2403.08843) | 本文提出了一个严谨的模糊不可靠性值框架，并提供了一种自下而上的算法来有效计算系统的模糊可靠性。 |
| [^88] | [NoiseDiffusion: Correcting Noise for Image Interpolation with Diffusion Models beyond Spherical Linear Interpolation](https://arxiv.org/abs/2403.08840) | 提出了一种名为NoiseDiffusion的新方法，可校正图像插值中的噪声，将无效的噪声逼近到预期的分布，并通过引入约束条件来抑制极端值的噪声。 |
| [^89] | [Predictive Clustering of Vessel Behavior Based on Hierarchical Trajectory Representation](https://arxiv.org/abs/2403.08838) | 提出了一种基于分层轨迹表示的船舶行为预测聚类方法，通过使用预测聚类和潜在编码，可以同时改善聚类和预测，并在实验证明其相对于现有方法的优越性。 |
| [^90] | [Cyclic Data Parallelism for Efficient Parallelism of Deep Neural Networks](https://arxiv.org/abs/2403.08837) | 提出循环数据并行性，通过将微批量执行从同时改为顺序执行，以解决数据并行化中激活内存峰值和梯度平均的问题，同时还能减少所需GPU数量。 |
| [^91] | [Structural Positional Encoding for knowledge integration in transformer-based medical process monitoring](https://arxiv.org/abs/2403.08836) | 本文在医学过程监测中提出了一种基于变压器的预测性过程监测方法，通过图形位置编码技术融入本体领域特定知识，获得了令人鼓舞的实验结果。 |
| [^92] | [Stacking-based deep neural network for player scouting in football 1](https://arxiv.org/abs/2403.08835) | 本研究提出了一种基于堆叠的深度学习模型，在足球领域中用于检测高潜力球员，相比传统统计方法取得了显著更好的结果。 |
| [^93] | [Predictive Analysis of Tuberculosis Treatment Outcomes Using Machine Learning: A Karnataka TB Data Study at a Scale](https://arxiv.org/abs/2403.08834) | 该研究探索了如何利用机器学习和表格数据更准确地预测结核病治疗结果，并在验证集上取得了优异的性能。 |
| [^94] | [TINA: Think, Interaction, and Action Framework for Zero-Shot Vision Language Navigation](https://arxiv.org/abs/2403.08833) | 本文提出了基于大型语言模型的零样本视觉语言导航代理，并介绍了思考、互动和行动(TINA)框架，通过引入的问答模块弥补了环境感知方面的不足。 |
| [^95] | [People Attribute Purpose to Autonomous Vehicles When Explaining Their Behavior](https://arxiv.org/abs/2403.08828) | 人们会给自主车辆的行为赋予目的属性，并在生成解释和评估这些解释时表现出对目的论解释的倾向。 |
| [^96] | [Measuring Non-Typical Emotions for Mental Health: A Survey of Computational Approaches](https://arxiv.org/abs/2403.08824) | 本调查是第一次同时探索用于分析压力、抑郁和投入度的计算方法，并讨论了最常用的数据集、输入模态、数据处理技术和信息融合方法。 |
| [^97] | [Diet-ODIN: A Novel Framework for Opioid Misuse Detection with Interpretable Dietary Patterns](https://arxiv.org/abs/2403.08820) | 该研究建立了一个大规模多方面的膳食数据集，提出了Diet-ODIN框架，旨在探索膳食模式与阿片类药物误用之间的关联。 |
| [^98] | [Multimodal Fusion of EHR in Structures and Semantics: Integrating Clinical Records and Notes with Hypergraph and LLM](https://arxiv.org/abs/2403.08818) | 提出了一个名为MINGLE的新框架，通过两级注入策略将医学概念语义和临床笔记语义融合到超图中，有效地整合了结构和语义的电子健康记录数据。 |
| [^99] | [Federated Deep Q-Learning and 5G load balancing](https://arxiv.org/abs/2403.08813) | 本研究提出并分析了一个联合深度Q学习负载平衡系统，利用Open-RAN xAPP框架和近实时射频接口控制器（near-RT RIC）实施。我们的模拟结果表明，与目前UE使用的最大信噪比（MAX-SINR）方法相比，我们提出的深度Q学习模型可以持续提供更好的负载平衡性能。 |
| [^100] | [Comparison of edge computing methods in Internet of Things architectures for efficient estimation of indoor environmental parameters with Machine Learning](https://arxiv.org/abs/2403.08810) | 本研究提出了两种基于低成本边缘物联网架构的方法，用于实现估计室内环境质量参数的轻量级机器学习模型，为物联网架构中进行高效数据处理提供了新思路。 |
| [^101] | [A Bionic Data-driven Approach for Long-distance Underwater Navigation with Anomaly Resistance](https://arxiv.org/abs/2403.08808) | 提出了一种仿生和数据驱动的长距离水下导航方法，利用地磁数据进行导航并通过开发机制和模型校准来增强抗异常性 |
| [^102] | [Effective anytime algorithm for multiobjective combinatorial optimization problems](https://arxiv.org/abs/2403.08807) | 提出了一种新的准确即时算法，用于多目标组合优化，结合了三种新颖的思想以增强即时性能 |
| [^103] | [Governance of Generative Artificial Intelligence for Companies](https://arxiv.org/abs/2403.08802) | 本综述填补了有关企业中生成式人工智能（GenAI）治理的研究空白，提出了一个框架，旨在利用业务机会并减轻与GenAI整合相关风险。 |
| [^104] | [Evolutionary Algorithms Simulating Molecular Evolution: A New Field Proposal](https://arxiv.org/abs/2403.08797) | 通过融合进化算法、机器学习和生物信息学，提出了一个计算方法来扩展自然蛋白质“词汇量”，以开发从未存在过的全新蛋白质。 |
| [^105] | [Using Sequential Runtime Distributions for the Parallel Speedup Prediction of SAT Local Search](https://arxiv.org/abs/2403.08790) | 通过分析顺序版本的运行时行为来预测给定算法的并行性能，本文提出了一种使用顺序运行时间分布进行SAT本地搜索并行加速预测的方法，并在实验中展示了模型准确预测性能的能力。 |
| [^106] | [Bridging Human Concepts and Computer Vision for Explainable Face Verification](https://arxiv.org/abs/2403.08789) | 本文通过结合计算机和人类视觉的方法，提高了人脸验证算法解释的可解释性 |
| [^107] | [Verification for Object Detection -- IBP IoU](https://arxiv.org/abs/2403.08788) | 介绍了一种针对目标检测模型的新颖区间边界传播（IBP）方法，IBP IoU在确保准确性和稳定性方面表现出色，为更安全和更稳健的机器学习应用做出贡献。 |
| [^108] | [One-Spike SNN: Single-Spike Phase Coding with Base Manipulation for ANN-to-SNN Conversion Loss Minimization](https://arxiv.org/abs/2403.08786) | 提出了一种单脉冲相位编码的编码方案，通过阈值偏移和基本操作来减少从ANN到SNN的转换损失，无需额外重新训练或架构约束。 |
| [^109] | [Image-Text Out-Of-Context Detection Using Synthetic Multimodal Misinformation](https://arxiv.org/abs/2403.08783) | 该研究提出了一种使用合成数据生成的脱离语境检测方法，实验证实了合成数据生成在解决OOCD相关数据限制方面的有效性。 |
| [^110] | [Procedural terrain generation with style transfer](https://arxiv.org/abs/2403.08782) | 介绍了一种结合程序化生成和神经风格转移的技术，用于生成地形地图，具有更大的灵活性、更低硬件需求和更好的整合性，在地形生成过程中能够产生与真实世界景观形态特征密切相关的地形结构。 |
| [^111] | [Leveraging Chat-Based Large Vision Language Models for Multimodal Out-Of-Context Detection](https://arxiv.org/abs/2403.08776) | LVLMs在多模态脱离上下文检测任务中表现不佳，但在进行微调后可以进一步提高准确性。 |
| [^112] | [Constrained Reinforcement Learning for Adaptive Controller Synchronization in Distributed SDN](https://arxiv.org/abs/2403.08775) | 该论文提出了一种基于约束的强化学习方法，在分布式SDN中实现自适应控制器同步，以解决优化通信延迟和负载平衡之间的平衡问题，特别适用于对网络延迟和计算资源要求严格的应用。 |
| [^113] | [Discussion of Loop Expansion and Introduction of Series Cutting Functions to Local Potential Approximation: Complexity Analysis Using Green's Functions, Cutting Of Nth-Order Social Interactions For Progressive Safety](https://arxiv.org/abs/2403.08774) | 论文使用Green函数方法研究过滤泡泡现象，并通过循环扩展方法讨论社会互动复杂性，引入序列函数评估影响。 |
| [^114] | [Veagle: Advancements in Multimodal Representation Learning](https://arxiv.org/abs/2403.08773) | 本文介绍了一种新颖的方法，通过在当前视觉语言模型（VLMs）和多模态大语言模型（MLLMs）的基础上融合独特的机制，以增强现有模型的多模态能力。 |
| [^115] | [GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting](https://arxiv.org/abs/2403.08551) | 通过2D高斯喷涂实现图像表示和压缩，在GPU内存占用降低的情况下，提供了更快的渲染速度，并在表示性能上与INR相匹敌。 |
| [^116] | [HRLAIF: Improvements in Helpfulness and Harmlessness in Open-domain Reinforcement Learning From AI Feedback](https://arxiv.org/abs/2403.08309) | 提出了HRLAIF方法来改善开放域强化学习中的模型响应帮助性，通过增强AI注释响应的准确性来提高模型在训练过程中的鲁棒性 |
| [^117] | [Random Search as a Baseline for Sparse Neural Network Architecture Search](https://arxiv.org/abs/2403.08265) | 论文提出了一种评估方法和基于随机搜索的基线方法，用于发现高质量的稀疏神经网络配置，以解决当前缺乏可靠比较和可重现性的问题。 |
| [^118] | [Contextual Clarity: Generating Sentences with Transformer Models using Context-Reverso Data](https://arxiv.org/abs/2403.08103) | 使用Transformer模型和Context-Reverso数据生成具有上下文清晰度的句子 |
| [^119] | [KnowCoder: Coding Structured Knowledge into LLMs for Universal Information Extraction](https://arxiv.org/abs/2403.07969) | 本文提出了KnowCoder，一个通过代码生成执行普适信息提取的大型语言模型，引入了代码风格的模式表示方法和两阶段学习框架，以提高LLMs对结构化知识的准确提取能力 |
| [^120] | [Exploring Safety Generalization Challenges of Large Language Models via Code](https://arxiv.org/abs/2403.07865) | 本论文引入了CodeAttack框架用于测试大型语言模型的安全泛化，研究发现GPT-4、Claude-2和Llama-2系列等最新模型存在代码输入的安全漏洞。 |
| [^121] | [Transforming Competition into Collaboration: The Revolutionary Role of Multi-Agent Systems and Language Models in Modern Organizations](https://arxiv.org/abs/2403.07769) | 文章探讨了基于多Agent系统理论结合大型语言模型的计算实体对人类互动的革新影响，提出了一种可能将专门人工代理支持扩展到操作性组织流程和基于知识和人类编排的战略决策的方式。 |
| [^122] | [Improving Reinforcement Learning from Human Feedback Using Contrastive Rewards](https://arxiv.org/abs/2403.07708) | 引入对比奖励的方法提高了从人类反馈中的强化学习的效果，改善了奖励模型的鲁棒性，鼓励对基准的改善，并能根据任务的难度进行校准。 |
| [^123] | [Reference-free Monolithic Preference Optimization with Odds Ratio](https://arxiv.org/abs/2403.07691) | 本文介绍了一种无参考单体赔率比偏好优化算法ORPO，在SFT过程中通过轻微惩罚不受欢迎的生成风格，消除了额外的偏好对齐阶段 |
| [^124] | [On the Diminishing Returns of Width for Continual Learning](https://arxiv.org/abs/2403.06398) | 增加神经网络宽度以减少遗忘会带来递减的回报，并且在先前研究中尚未探索的宽度范围内进行了实证验证。 |
| [^125] | [Optimizing Computer Lab Ergonomics in Universities: A Study on Anthropometric Measurements, Furniture Design, and ANOVA Test](https://arxiv.org/abs/2403.05589) | 提出基于人体测量的家具尺寸适合大学生，以改善计算机实验室人体工程学，研究发现其与现有家具尺寸存在显著差异并更加兼容 |
| [^126] | [MMoE: Robust Spoiler Detection with Multi-modal Information and Domain-aware Mixture-of-Experts](https://arxiv.org/abs/2403.05265) | 提出了MMoE，一个利用多模态信息进行剧透检测的网络，并采用专家混合技术来增强领域泛化能力。 |
| [^127] | [Rule-driven News Captioning](https://arxiv.org/abs/2403.05101) | 本文提出了一种基于规则的新闻标题生成方法，通过新闻感知的语义规则，可以生成遵循新闻报道基本规则的图像描述。 |
| [^128] | [BjTT: A Large-scale Multimodal Dataset for Traffic Prediction](https://arxiv.org/abs/2403.05029) | 本文提出了第一个用于文本-交通生成的扩散模型ChatTraffic，通过将生成模型与交通系统描述文本相结合，解决了交通预测中关联文本和空间结构的挑战。 |
| [^129] | [From Graph to Word Bag: Introducing Domain Knowledge to Confusing Charge Prediction](https://arxiv.org/abs/2403.04369) | 引入领域知识的从图到词袋方法，帮助预测混淆罪名，通过构成要素和关键词选择进行判断。 |
| [^130] | [Discriminative Probing and Tuning for Text-to-Image Generation](https://arxiv.org/abs/2403.04321) | 加强T2I模型的判别能力，以实现更精确的文本到图像对齐生成。 |
| [^131] | [German also Hallucinates! Inconsistency Detection in News Summaries with the Absinth Dataset](https://arxiv.org/abs/2403.03750) | 本文提出了一个用于德语新闻摘要中幻觉检测的数据集absinth，探讨了LLMs在该任务中的应用。 |
| [^132] | [TTA-Nav: Test-time Adaptive Reconstruction for Point-Goal Navigation under Visual Corruptions](https://arxiv.org/abs/2403.01977) | TTA-Nav提出了一种测试时自适应方法，通过引入自顶向下解码器，从损坏图像中重建出更清晰的图像，显著增强了点目标导航性能。 |
| [^133] | [AllSpark: Reborn Labeled Features from Unlabeled in Transformer for Semi-Supervised Semantic Segmentation](https://arxiv.org/abs/2403.01818) | AllSpark利用通道级交叉注意机制从未标记的特征中重新生成标记特征，以改善半监督语义分割中低质量伪标签的问题。 |
| [^134] | [Diffusion-TS: Interpretable Diffusion for General Time Series Generation](https://arxiv.org/abs/2403.01742) | 提出了一种新颖的基于扩散的框架 Diffusion-TS，结合了编码器-解码器变压器和解耦时间表示，通过直接重建样本而非噪声生成高质量的多变量时间序列样本，旨在实现时间序列的解释性和真实性。 |
| [^135] | [VBART: The Turkish LLM](https://arxiv.org/abs/2403.01308) | VBART是第一个土耳其序列到序列大语言模型，通过与BART和mBART模型结合形成了紧凑型LLM，并在多个任务中表现出色，为土耳其自然语言处理研究开辟了新的可能性。 |
| [^136] | [RAGged Edges: The Double-Edged Sword of Retrieval-Augmented Chatbots](https://arxiv.org/abs/2403.01193) | 本文探讨了如何利用检索增强生成（RAG）抵制大型语言模型（LLMs）产生的幻觉，结果表明RAG在某些情况下可以提高准确性，但仍需要更强大的解决方案以确保LLMs在实际应用中可靠性。 |
| [^137] | [End-to-end Graph-Sequential Representation Learning for Accurate Recommendations](https://arxiv.org/abs/2403.00895) | 本文提出了一个新颖的多重表示学习框架，有效地结合了基于序列和基于图的推荐方法，显著改善了推荐性能。 |
| [^138] | [Executing Natural Language-Described Algorithms with Large Language Models: An Investigation](https://arxiv.org/abs/2403.00795) | 大语言模型可以有效地执行用自然语言描述的程序，尤其是在不涉及大量数字计算的情况下。 |
| [^139] | [Smooth Tchebycheff Scalarization for Multi-Objective Optimization](https://arxiv.org/abs/2402.19078) | 通过光滑 Tchebycheff 标量化方法，本文提出了一种轻量级的方法，用于梯度型多目标优化，具有更低的计算复杂性但仍能找到所有帕累托解。 |
| [^140] | [MMSR: Symbolic Regression is a Multimodal Task](https://arxiv.org/abs/2402.18603) | 符号回归被视为一个多模态任务，研究人员将数据到表达式的映射视为翻译问题，引入大规模预训练模型。 |
| [^141] | [QUCE: The Minimisation and Quantification of Path-Based Uncertainty for Generative Counterfactual Explanations](https://arxiv.org/abs/2402.17516) | QUCE方法旨在通过减少路径不确定性来量化和缓解基于路径的不确定性，从而改善对抗性反事实解释的表现。 |
| [^142] | [Science Checker Reloaded: A Bidirectional Paradigm for Transparency and Logical Reasoning](https://arxiv.org/abs/2402.13897) | 提出了一个两块式的方法来解决长文档中信息检索领域的挑战，并实现了双向交互 |
| [^143] | [Me LLaMA: Foundation Large Language Models for Medical Applications](https://arxiv.org/abs/2402.12749) | Me LLaMA是一个医学领域的大型语言模型系列，通过持续预训练和指导调整在大型医学数据集上训练而成，其在零-shot和少-shot学习方面表现优于现有的医学语言模型和商业巨头ChatGPT。 |
| [^144] | [PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images](https://arxiv.org/abs/2402.12721) | 提出了一个新颖的神经网络模型 PAC-FNO，通过在频域操作可以处理不同分辨率的图像，解决了传统方法在处理这类问题上的计算成本高的挑战。 |
| [^145] | [The Butterfly Effect of Model Editing: Few Edits Can Trigger Large Language Models Collapse](https://arxiv.org/abs/2402.09656) | 尽管模型编辑在大型语言模型中显示出修订知识的潜力，但少量编辑可以触发模型崩溃，导致性能显著下降。我们提出使用困惑度作为替代指标，并通过实验证实其与下游任务性能的强相关性。 |
| [^146] | [VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language Models with Autonomous Instruction Optimization](https://arxiv.org/abs/2402.07398) | VisLingInstruct通过自主优化指导文本和视觉特征提取模块，显著提高了多模态语言模型在零样本学习中的性能，在TextVQA和HatefulMemes数据集上的准确率分别提高了13.1%和9%。 |
| [^147] | [FedImpro: Measuring and Improving Client Update in Federated Learning](https://arxiv.org/abs/2402.07011) | 本文提出了FedImpro方法，通过生成改进的本地模型来减轻联邦学习中的客户漂移问题。该方法通过分析本地训练的泛化贡献，并利用类似的条件分布进行训练，增强了泛化贡献并减小了梯度的差异性。 |
| [^148] | [HEAM : Hashed Embedding Acceleration using Processing-In-Memory](https://arxiv.org/abs/2402.04032) | HEAM是一种采用异构内存架构的方法，将3D堆叠DRAM与DIMM集成，用于加速处理大规模个性化推荐系统中的嵌入操作。 |
| [^149] | [SNAP: Semantic Stories for Next Activity Prediction](https://arxiv.org/abs/2401.15621) | SNAP方法利用语言基础模型构建语义上下文故事，从过程历史事件日志中提取信息，用于预测下一步活动。 |
| [^150] | [Divide-and-Conquer Attack: Harnessing the Power of LLM to Bypass Safety Filters of Text-to-Image Models](https://arxiv.org/abs/2312.07130) | 该论文介绍了一种称为分而治之攻击的方法，利用LLM作为文本转换代理绕过文本到图像模型的安全过滤器。该攻击设计了攻击辅助提示，引导LLM将不道德的绘图意图分解为多个个体图像元素的良性描述，以绕过安全过滤器生成不道德的图像。实验结果表明，该攻击成功地绕过了多个强大的封闭式安全过滤器。 |
| [^151] | [Innovations in Agricultural Forecasting: A Multivariate Regression Study on Global Crop Yield Prediction](https://arxiv.org/abs/2312.02254) | 通过实施六个回归模型并使用关键训练参数，该研究提出了一个随机森林回归模型，用于预测37个发展中国家27年的农作物产量，取得了0.94的确定系数，并探讨了不同因素对产量的影响。 |
| [^152] | [SynFundus-1M: A High-quality Million-scale Synthetic fundus images Dataset with Fifteen Types of Annotation](https://arxiv.org/abs/2312.00377) | SynFundus-1M是一个包含超过一百万张眼底图像的高质量合成数据集，涵盖十一个疾病类型，并赋予关键区域四个可读性标签，在目前是最大且具有最复杂注释的眼底数据集之一。 |
| [^153] | [Should we be going MAD? A Look at Multi-Agent Debate Strategies for LLMs](https://arxiv.org/abs/2311.17371) | 多Agent辩论（MAD）作为增强大型语言模型（LLMs）真实性的策略，对于解决确保生成代理提供准确可靠答案的挑战具有潜力，但当前形式下的多Agent辩论系统在可靠性上不一定优于其他提示策略。 |
| [^154] | [DyRA: Portable Dynamic Resolution Adjustment Network for Existing Detectors](https://arxiv.org/abs/2311.17098) | DyRA是一种动态分辨率调整网络，为现有的检测器提供图像特定的缩放因子，通过ParetoScaleLoss和BalanceLoss优化缩放因子以提高检测性能。 |
| [^155] | [Video Face Re-Aging: Toward Temporally Consistent Face Re-Aging](https://arxiv.org/abs/2311.11642) | 该论文提出了一个新颖的合成视频数据集，设计了基线架构来验证其有效性，并开发了针对视频重龄化技术的时间一致性的新颖评估指标。 |
| [^156] | [Chatbots as social companions: How people perceive consciousness, human likeness, and social health benefits in machines](https://arxiv.org/abs/2311.10599) | 伴侣聊天机器人使用者表示这些关系有益于他们的社会健康，与预期相反，非使用者则认为有害 |
| [^157] | [Plum: Prompt Learning using Metaheuristic](https://arxiv.org/abs/2311.08364) | 提出了使用元启发式的提示学习方法，通过测试六种典型的元启发式方法，在大型语言模型的提示优化任务中取得了有效性。 |
| [^158] | [Euclidean, Projective, Conformal: Choosing a Geometric Algebra for Equivariant Transformers](https://arxiv.org/abs/2311.04744) | 该论文研究了基于欧几里得、射影和共形代数的Geometric Algebra Transformer架构，发现共形代数和改进的射影代数定义了功能强大、性能良好的变换器架构。 |
| [^159] | [LILO: Learning Interpretable Libraries by Compressing and Documenting Code](https://arxiv.org/abs/2310.19791) | LILO是一种神经符号框架，通过迭代地合成、压缩和文档化代码来构建可解释且适用于特定问题领域的程序库。在其中，LILO结合了大型语言模型引导的程序合成和程序自动重构的算法进展，并且通过自动文档过程使得代码抽象可解释并提升性能。 |
| [^160] | [Vision-Language Models are Zero-Shot Reward Models for Reinforcement Learning](https://arxiv.org/abs/2310.12921) | 使用预训练的视觉语言模型作为零样本奖励模型，在强化学习中指定任务，提高训练效率。 |
| [^161] | [LLM4SGG: Large Language Model for Weakly Supervised Scene Graph Generation](https://arxiv.org/abs/2310.10404) | 这种方法解决了弱监督场景图生成中的语义过度简化和低密度场景图问题。 |
| [^162] | [VeCLIP: Improving CLIP Training via Visual-enriched Captions](https://arxiv.org/abs/2310.07699) | 本研究提出了一种通过将视觉概念融入标题中的方式来改进CLIP训练的方法，名为VeCLIP，该方法在大规模网络爬取数据集上展示了良好的性能。 |
| [^163] | [Towards Dynamic and Small Objects Refinement for Unsupervised Domain Adaptative Nighttime Semantic Segmentation](https://arxiv.org/abs/2310.04747) | 该论文提出了一种新颖的无监督域自适应方法，针对夜间语义分割中的动态和小物体，进行标签和特征级别的改进。 |
| [^164] | [Think before you speak: Training Language Models With Pause Tokens](https://arxiv.org/abs/2310.02226) | 引入暂停标记的语言模型训练方法可以让模型在输出标记前处理更多隐藏向量，取得了较好的实验结果 |
| [^165] | [Making Language Models Better Tool Learners with Execution Feedback](https://arxiv.org/abs/2305.13068) | 这篇论文提出了一个名为TRICE的框架，通过执行反馈实现语言模型的工具学习，使其能够学会何时以及如何有效地使用工具。 |
| [^166] | [AdaptiveClick: Clicks-aware Transformer with Adaptive Focal Loss for Interactive Image Segmentation](https://arxiv.org/abs/2305.04276) | AdaptiveClick 是首个基于Transformer的、针对交互式图像分割的遮罩自适应分割框架，引入了自适应焦点损失以解决注释不一致性，并提供了解决遮罩和像素级模糊的工具。 |
| [^167] | [Actional Atomic-Concept Learning for Demystifying Vision-Language Navigation](https://arxiv.org/abs/2302.06072) | 提出了行动性原子概念学习（AACL）方法，将视觉观察映射到行动性原子概念，作为观察和指令之间的桥梁，减少语义差距并简化对齐。 |
| [^168] | [Energy Disaggregation & Appliance Identification in a Smart Home: Transfer Learning enables Edge Computing](https://arxiv.org/abs/2301.03018) | 迁移学习结合边缘计算，提出了新的深度学习方法解决非侵入式负载监视问题和电器识别问题，利用改进的CNN模型和预训练模型获得更准确的结果。 |
| [^169] | [COMET: A Comprehensive Cluster Design Methodology for Distributed Deep Learning Training](https://arxiv.org/abs/2211.16648) | COMET提出了一种全面的集群设计方法论，用于研究并行化策略和关键集群资源配置对分布式DL训练性能的影响 |
| [^170] | [Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation](https://arxiv.org/abs/2207.14000) | 提出了IMA-GloVe-GA，一个用于自然语言表达的多步推理的迭代神经推理网络，在超领域泛化方面具有更好的性能表现。 |
| [^171] | [SPI-GAN: Denoising Diffusion GANs with Straight-Path Interpolations](https://arxiv.org/abs/2206.14464) | SPI-GAN使用直线路径插值定义的增强型GAN去噪方法，能够在极大程度上减少采样时间，同时实现与SGMs相同的高采样质量和多样性。 |
| [^172] | [OpenXAI: Towards a Transparent Evaluation of Model Explanations](https://arxiv.org/abs/2206.11104) | OpenXAI 是一个开源框架，旨在评估和基准测试后续解释方法，提供了灵活的数据生成器、多种数据集和评估指标，用户可轻松扩展和比较不同解释方法。 |
| [^173] | [Safe and Generalized end-to-end Autonomous Driving System with Reinforcement Learning and Demonstrations.](http://arxiv.org/abs/2401.11792) | 本文介绍了一种安全且广义的端到端自主驾驶系统 (SGADS)，使用强化学习和示范相结合的方法解决了现有方法的低安全性、泛化能力差和采样效率低的问题，同时引入了变分推理和归一化流以准确预测驾驶轨迹，并提出了鲁棒性安全约束的制定方法。 |
| [^174] | [LDReg: Local Dimensionality Regularized Self-Supervised Learning.](http://arxiv.org/abs/2401.10474) | 本文提出了一种叫做LDReg的本地维度正则化方法，用于解决自监督学习中的维度坍缩问题。通过增加局部内在维度，LDReg能够改善表示的性能。 |
| [^175] | [Towards Generative Abstract Reasoning: Completing Raven's Progressive Matrix via Rule Abstraction and Selection.](http://arxiv.org/abs/2401.09966) | 本文提出了一个条件生成模型（RAISE），通过在潜在空间中进行规则抽象和选择，以解决Raven的渐进矩阵问题，该模型能够在现实的场景中展示出抽象推理的能力。 |
| [^176] | [Most discriminative stimuli for functional cell type identification.](http://arxiv.org/abs/2401.05342) | 本文提出了一种使用最具区分性刺激物的优化聚类方法，成功地识别了小鼠视网膜、恒河猴视网膜和猕猴V4视觉区的功能细胞类型。 |
| [^177] | [Generative AI enhances individual creativity but reduces the collective diversity of novel content.](http://arxiv.org/abs/2312.00506) | 生成AI增强了个体创造力，但降低了新内容的集体多样性。 |
| [^178] | [Zero Coordinate Shift: Whetted Automatic Differentiation for Physics-informed Operator Learning.](http://arxiv.org/abs/2311.00860) | 本文提出了一种用于物理约束操作学习的新型自动微分算法，通过零坐标移动（ZCS）的技巧，将所需导数的复杂度从“多根多叶”简化为“一根多叶”，从而显著提高了性能。 |
| [^179] | [Vanishing Gradients in Reinforcement Finetuning of Language Models.](http://arxiv.org/abs/2310.20703) | 本研究发现在强化微调（RFT）中存在梯度消失的问题，当模型下奖励的标准差较小时，输入的期望梯度会消失，导致奖励最大化缓慢。初始监督微调（SFT）阶段是克服这个问题的最有希望的方法。 |
| [^180] | [Brain decoding: toward real-time reconstruction of visual perception.](http://arxiv.org/abs/2310.19812) | 本研究提出了一种基于脑磁图（MEG）的脑解码方法，通过训练一个具有预训练嵌入、MEG模块和图像生成器的模型，在实时应用中实现了对视觉知觉的高时间分辨率解码，并在图像检索上取得了7倍的改进。 |
| [^181] | [Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-Image Generation.](http://arxiv.org/abs/2310.18235) | 本论文提出了Davidsonian场景图（DSG）的评估框架，解决了现有文本-图像生成模型评估中的可靠性挑战，包括QG问题的准确性和VQA答案的一致性。 |
| [^182] | [Structured Generation and Exploration of Design Space with Large Language Models for Human-AI Co-Creation.](http://arxiv.org/abs/2310.12953) | 这篇论文介绍了一种应用大型语言模型进行人工智能与人类协同创作的框架，通过结构化生成设计空间并提供无缝探索、评估和综合多种响应的功能，拓展了与大型语言模型在创意任务中的交互方式。 |
| [^183] | [Rethinking Class-incremental Learning in the Era of Large Pre-trained Models via Test-Time Adaptation.](http://arxiv.org/abs/2310.11482) | 本研究提出了一种名为“增量学习的测试时适应”的方法，通过在测试实例上进行微调，避免了在每个新任务上进行训练，从而在增量学习中实现了预训练模型的稳定性和可塑性的平衡。 |
| [^184] | [CodeChain: Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules.](http://arxiv.org/abs/2310.08992) | CodeChain是一种通过代表性子模块的自我修订链路引导模块化代码生成的新框架，旨在解决大型语言模型在解决复杂编程任务方面的挑战。 |
| [^185] | [The Impact of Explanations on Fairness in Human-AI Decision-Making: Protected vs Proxy Features.](http://arxiv.org/abs/2310.08617) | 论文研究了解释对AI决策公平性的影响。结果发现，解释有助于人们检测直接偏见，但对间接偏见的发现能力有限。 |
| [^186] | [Large Language Models Cannot Self-Correct Reasoning Yet.](http://arxiv.org/abs/2310.01798) | 大型语言模型(LLMs)的自我纠正能力在推理方面存在困难，甚至可能在自我纠正后性能下降。 |
| [^187] | [Graph Neural Architecture Search with GPT-4.](http://arxiv.org/abs/2310.01436) | 本文将GPT-4集成到图神经网络架构搜索（GNAS）中，提出了一种新的GPT-4基于的GNAS方法（GPT4GNAS），通过设计新的提示来引导GPT-4生成更准确的图神经网络，实验证明嵌入GPT-4到GNAS中优于现有方法。 |
| [^188] | [DyVal: Graph-informed Dynamic Evaluation of Large Language Models.](http://arxiv.org/abs/2309.17167) | DyVal是一种基于图形信息的大型语言模型动态评估协议，通过动态生成具有可控复杂性的评估样本，评估了各种LLM在推理任务上的性能，发现它们在这些挑战性样本上表现更差。 |
| [^189] | [Era Splitting.](http://arxiv.org/abs/2309.14496) | 本研究提出了两种新的分裂准则，使得决策树模型能够利用时代信息进行优化，从而将超分布泛化研究中的思想应用于决策树模型。 |
| [^190] | [Geometric structure of Deep Learning networks and construction of global ${\mathcal L}^2$ minimizers.](http://arxiv.org/abs/2309.10639) | 本文提供了深度学习网络结构的几何解释，并且构建了全局最小化器族，该族能够全局最小化成本函数。此外，还确定了各种退化局部最小值。 |
| [^191] | [Instruction Tuning for Large Language Models: A Survey.](http://arxiv.org/abs/2308.10792) | 本文调查了指令调优这一关键技术在增强大型语言模型能力和可控性方面的研究工作，包括方法、数据集构建、模型训练和应用，以及对结果影响的分析。同时回顾了可能的问题和批评，并指出了目前的不足。 |
| [^192] | [milliFlow: Scene Flow Estimation on mmWave Radar Point Cloud for Human Motion Sensing.](http://arxiv.org/abs/2306.17010) | milliFlow是一种用于人体运动感知的新型深度学习方法，通过对毫米波雷达点云进行场景流估计，能够提供中间层的特征并直接用于下游的人体运动感知任务中。实验证明该方法具有优越性能。 |
| [^193] | [MO-VLN: A Multi-Task Benchmark for Open-set Zero-Shot Vision-and-Language Navigation.](http://arxiv.org/abs/2306.10322) | MO-VLN是一个用于评估通用机器人在多任务环境中的视觉和语言导航的基准，通过使用虚幻引擎5开发逼真的场景和包含多种不常见物体来测试其效果和泛化能力。 |
| [^194] | [Kernelized Reinforcement Learning with Order Optimal Regret Bounds.](http://arxiv.org/abs/2306.07745) | 该论文提出了一种称为$\pi$-KRVI的乐观修改方法，并使用核岭回归进行强化学习中的非线性函数逼近。论文证明了在一般设置下第一个最优遗憾保证，并相对于现有最优结果实现了显着的多项式低差距。 |
| [^195] | [Controlling Text-to-Image Diffusion by Orthogonal Finetuning.](http://arxiv.org/abs/2306.07280) | 本文介绍了一种名为正交微调（OFT）的方法，可以有效地引导和控制大型文本到图像扩散模型，以执行不同的下游任务。我们还提出了约束正交微调（COFT），来提高微调的稳定性。这些方法能够保持语义生成能力并生成特定主题的图像。 |
| [^196] | [Introducing Tales of Tribute AI Competition.](http://arxiv.org/abs/2305.08234) | 这项论文介绍了一项新的人工智能挑战——致敬神话人工智能竞赛(TOTAIC)，该竞赛基于《上古卷轴在线》中的一款卡牌游戏。除了应对通常与CCG相关的挑战外，该挑战还需要长期规划和适应性。竞赛采用多种方法解决游戏，如对抗搜索、单人计划和神经网络算法。第一届TOTAIC将在2023年的IEEE游戏会议上举行。 |
| [^197] | [Discern and Answer: Mitigating the Impact of Misinformation in Retrieval-Augmented Models with Discriminators.](http://arxiv.org/abs/2305.01579) | 本文研究了现有检索增强语言模型假设所有检索信息都是正确的假设的问题，在实际应用中可能存在虚假信息导致冲突的情况下，提出了通过精细调整鉴别器和提示鉴别能力引出鲁棒性的方法，这显著改善了模型在知识冲突下的效果；同时提供了关于交替精细调整模型和上下文学习的新的结论。 |
| [^198] | [Learning Melanocytic Cell Masks from Adjacent Stained Tissue.](http://arxiv.org/abs/2211.00646) | 本文提出了一种从相邻染色组织学片中训练深度神经网络进行黑色素细胞分割的方法，实现了0.64的平均IOU，尽管存在不完美的标签。 |

# 详细

[^1]: Transformers Get Stable: An End-to-End Signal Propagation Theory for Language Models

    Transformers Get Stable: An End-to-End Signal Propagation Theory for Language Models

    [https://arxiv.org/abs/2403.09635](https://arxiv.org/abs/2403.09635)

    提出了一个统一的信号传播理论，提供了控制transformer模型信号传播的公式，提出了DeepScaleLM初始化和缩放方案，使得可以训练非常深的模型，并发现深层模型在多个任务和数据集上胜过浅层模型。

    

    尽管transformer模型取得了巨大的成功，但在深度方面仍然很难扩展。本研究提出了一个统一的信号传播理论，并提供了控制transformer模型前向和反向信号矩的公式。我们的框架可以用于理解和缓解与高注意力分数相关的梯度消失/爆炸、秩坍缩和不稳定性。我们还提出了DeepScaleLM，一种初始化和缩放方案，通过该方案能够在模型中保持单位输出/梯度矩，从而使训练具有100多层的非常深模型成为可能。我们发现，transformer模型可以更深 - 我们的深层模型在语言建模、语音翻译和图像分类方面表现优异，包括仅编码器、仅解码器和编码器-解码器变体，适用于Pre-LN和Post-LN transformers，适用于多个数据集和模型大小。

    arXiv:2403.09635v1 Announce Type: cross  Abstract: In spite of their huge success, transformer models remain difficult to scale in depth. In this work, we develop a unified signal propagation theory and provide formulae that govern the moments of the forward and backward signal through the transformer model. Our framework can be used to understand and mitigate vanishing/exploding gradients, rank collapse, and instability associated with high attention scores. We also propose DeepScaleLM, an initialization and scaling scheme that conserves unit output/gradient moments throughout the model, enabling the training of very deep models with 100s of layers. We find that transformer models could be much deeper - our deep models with fewer parameters outperform shallow models in Language Modeling, Speech Translation, and Image Classification, across Encoder-only, Decoder-only and Encoder-Decoder variants, for both Pre-LN and Post-LN transformers, for multiple datasets and model sizes. These imp
    
[^2]: 3D-VLA: 一个3D视觉-语言-动作生成世界模型

    3D-VLA: A 3D Vision-Language-Action Generative World Model

    [https://arxiv.org/abs/2403.09631](https://arxiv.org/abs/2403.09631)

    提出了3D-VLA，通过将3D感知、推理和动作无缝连接，建立一个生成世界模型，弥补了现有VLA模型只能处理2D输入且忽视世界动态与动作之间关系的不足。

    

    最近的视觉-语言-动作（VLA）模型依赖于2D输入，缺乏与更广阔的3D物理世界融合。此外，它们通过学习从感知到动作的直接映射来执行动作预测，忽略了世界的广泛动态和动作与动态之间的关系。相反，人类拥有描绘关于未来场景的想象，以相应地规划行动的世界模型。为此，我们通过引入一系列新的具身基础模型，无缝地将3D感知、推理和动作通过一个生成世界模型相连，提出了3D-VLA。具体地，3D-VLA建立在基于3D的大型语言模型（LLM）之上，并引入一组交互标记以与具身环境进行交互。此外，为了将生成能力注入模型，我们训练了一系列具身扩散模型，并将它们与LLM对齐以进行预测。

    arXiv:2403.09631v1 Announce Type: cross  Abstract: Recent vision-language-action (VLA) models rely on 2D inputs, lacking integration with the broader realm of the 3D physical world. Furthermore, they perform action prediction by learning a direct mapping from perception to action, neglecting the vast dynamics of the world and the relations between actions and dynamics. In contrast, human beings are endowed with world models that depict imagination about future scenarios to plan actions accordingly. To this end, we propose 3D-VLA by introducing a new family of embodied foundation models that seamlessly link 3D perception, reasoning, and action through a generative world model. Specifically, 3D-VLA is built on top of a 3D-based large language model (LLM), and a set of interaction tokens is introduced to engage with the embodied environment. Furthermore, to inject generation abilities into the model, we train a series of embodied diffusion models and align them into the LLM for predicting
    
[^3]: Quiet-STaR: 语言模型可以自己学会思考后再说话

    Quiet-STaR: Language Models Can Teach Themselves to Think Before Speaking

    [https://arxiv.org/abs/2403.09629](https://arxiv.org/abs/2403.09629)

    Quiet-STaR提出了一种新的泛化版本，在每个标记处生成解释未来文本的思考过程，从而改善预测能力

    

    写作和交谈时，人们有时会停下来思考。尽管以推理为重点的作品通常将推理框定为回答问题或完成代理任务的方法，但推理几乎都隐含在所有书面文本中。例如，这适用于证明中未明确说明的步骤，以及支撑对话的心智理论。在自学习推理者（STaR，Zelikman等，2022）中，通过从少量示例中推断来自问答中有用的思考，并学习那些导致正确答案的思考。这是一个高度受限制的环境--理想情况下, 一个语言模型可以学会从任意文本中推断未明确说明的思考。我们提出Quiet-STaR，这是STaR的一个泛化版本，其中语言模型学会在每个标记处生成解释未来文本的思考过程，从而改善其预测。我们解决了一些关键挑战，包括1）生成连续的计算成本

    arXiv:2403.09629v1 Announce Type: cross  Abstract: When writing and talking, people sometimes pause to think. Although reasoning-focused works have often framed reasoning as a method of answering questions or completing agentic tasks, reasoning is implicit in almost all written text. For example, this applies to the steps not stated between the lines of a proof or to the theory of mind underlying a conversation. In the Self-Taught Reasoner (STaR, Zelikman et al. 2022), useful thinking is learned by inferring rationales from few-shot examples in question-answering and learning from those that lead to a correct answer. This is a highly constrained setting -- ideally, a language model could instead learn to infer unstated rationales in arbitrary text. We present Quiet-STaR, a generalization of STaR in which LMs learn to generate rationales at each token to explain future text, improving their predictions. We address key challenges, including 1) the computational cost of generating continu
    
[^4]: 最小化最优和计算高效的分布鲁棒离线强化学习算法

    Minimax Optimal and Computationally Efficient Algorithms for Distributionally Robust Offline Reinforcement Learning

    [https://arxiv.org/abs/2403.09621](https://arxiv.org/abs/2403.09621)

    研究提出了最小化最优和计算高效的算法，为鲁棒离线强化学习中的函数逼近带来新颖视角，并展示了其与标准离线强化学习中函数逼近的区别。

    

    分布鲁棒离线强化学习（RL）寻求针对环境扰动的鲁棒策略训练，通过建模动态不确定性来调用函数逼近，当面对庞大的状态-动作空间时，这种RL需要考虑到动态不确定性，引入了基本的非线性和计算负担，这给分析和实际应用函数逼近提出了独特挑战。在基本设置下，提议最小化最优和计算高效的算法，实现函数逼近，并在鲁棒离线RL的背景下启动对实例相关次优性分析的研究。我们的结果揭示了鲁棒离线RL中的函数逼近本质上与标准离线RL中的函数逼近有明显区别，可能更加困难。我们的算法和理论结果至关重要地依赖于

    arXiv:2403.09621v1 Announce Type: cross  Abstract: Distributionally robust offline reinforcement learning (RL), which seeks robust policy training against environment perturbation by modeling dynamics uncertainty, calls for function approximations when facing large state-action spaces. However, the consideration of dynamics uncertainty introduces essential nonlinearity and computational burden, posing unique challenges for analyzing and practically employing function approximation. Focusing on a basic setting where the nominal model and perturbed models are linearly parameterized, we propose minimax optimal and computationally efficient algorithms realizing function approximation and initiate the study on instance-dependent suboptimality analysis in the context of robust offline RL. Our results uncover that function approximation in robust offline RL is essentially distinct from and probably harder than that in standard offline RL. Our algorithms and theoretical results crucially depen
    
[^5]: 大型语言模型与协作中的因果推断：一项综合调查

    Large Language Models and Causal Inference in Collaboration: A Comprehensive Survey

    [https://arxiv.org/abs/2403.09606](https://arxiv.org/abs/2403.09606)

    大型语言模型的出现极大影响了自然语言处理领域，特别是通过其先进的推理能力。而本综述则重点评估和改进了大型语言模型在因果推断方面的应用，包括提高推理能力、解决公平和安全问题、提供解释和处理多模态。

    

    因果推断已经显示出潜力，通过捕捉变量之间的因果关系，提高自然语言处理（NLP）模型的预测准确性、公平性、稳健性和可解释性。生成型大型语言模型（LLMs）的出现显著影响了各种NLP领域，特别是通过其先进的推理能力。该调查重点评估和改进LLMs的因果视角，在以下领域展开：理解和改进LLMs的推理能力，解决LLMs中的公平性和安全性问题，为LLMs提供解释，并处理多模态。同时，LLMs强大的推理能力反过来可以通过帮助因果关系发现和因果效应估计来促进因果推断领域的发展。本综述探讨了因果推断框架与LLMs之间的相互作用，强调了它们的集体作用。

    arXiv:2403.09606v1 Announce Type: cross  Abstract: Causal inference has shown potential in enhancing the predictive accuracy, fairness, robustness, and explainability of Natural Language Processing (NLP) models by capturing causal relationships among variables. The emergence of generative Large Language Models (LLMs) has significantly impacted various NLP domains, particularly through their advanced reasoning capabilities. This survey focuses on evaluating and improving LLMs from a causal view in the following areas: understanding and improving the LLMs' reasoning capacity, addressing fairness and safety issues in LLMs, complementing LLMs with explanations, and handling multimodality. Meanwhile, LLMs' strong reasoning capacities can in turn contribute to the field of causal inference by aiding causal relationship discovery and causal effect estimations. This review explores the interplay between causal inference frameworks and LLMs from both perspectives, emphasizing their collective p
    
[^6]: 反事实对照学习：通过因果图像合成获得稳健表示

    Counterfactual contrastive learning: robust representations via causal image synthesis

    [https://arxiv.org/abs/2403.09605](https://arxiv.org/abs/2403.09605)

    本研究提出了CF-SimCLR，一种反事实对照学习方法，利用近似反事实推断创造正样本，大大提高了模型对采集偏移的稳健性，并在多个数据集上取得了较高的下游性能。

    

    对比预训练已被广泛认为能够提高下游任务性能和模型泛化能力，特别是在有限标签设置中。然而，它对增强管道的选择敏感。正样本应保留语义信息同时破坏域特定信息。标准增强管道通过预定义的光度变换模拟域特定变化，但如果我们能够模拟真实的领域变化呢？在这项工作中，我们展示了如何利用最近在反事实图像生成方面的进展来实现这一目的。我们提出了CF-SimCLR，一种反事实对照学习方法，它利用近似反事实推断进行正样本创建。对胸部X光和乳腺X光等五个数据集的全面评估表明，CF-SimCLR显著提高了对获取偏移的稳健性，在两种数据集上的下游性能更好。

    arXiv:2403.09605v1 Announce Type: cross  Abstract: Contrastive pretraining is well-known to improve downstream task performance and model generalisation, especially in limited label settings. However, it is sensitive to the choice of augmentation pipeline. Positive pairs should preserve semantic information while destroying domain-specific information. Standard augmentation pipelines emulate domain-specific changes with pre-defined photometric transformations, but what if we could simulate realistic domain changes instead? In this work, we show how to utilise recent progress in counterfactual image generation to this effect. We propose CF-SimCLR, a counterfactual contrastive learning approach which leverages approximate counterfactual inference for positive pair creation. Comprehensive evaluation across five datasets, on chest radiography and mammography, demonstrates that CF-SimCLR substantially improves robustness to acquisition shift with higher downstream performance on both in- an
    
[^7]: 控制硬件非确定性进行乐观可验证训练

    Optimistic Verifiable Training by Controlling Hardware Nondeterminism

    [https://arxiv.org/abs/2403.09603](https://arxiv.org/abs/2403.09603)

    提出了一种方法，结合了在比目标模型更高精度下进行训练、在中间计算步骤后进行四舍五入，并基于自适应阈值存储四舍五入决策，以应对硬件非确定性对训练过程的影响。

    

    AI系统日益增加的计算需求导致了为缺乏必要资源的客户进行模型训练的服务的出现。然而，确保训练的正确性并防范潜在的训练时攻击，例如数据毒化，都带来了挑战。现有的关于可验证训练的工作主要分为两类：基于证明的系统，由于需要加密技术而难以扩展，以及考虑到一个可信第三方审计员复制训练过程的“乐观”方法。 后者的一个关键挑战是，在训练期间GPU类型之间的硬件非确定性阻止审计员精确复制训练过程，因此这样的方案不够健壮。我们提出了一种方法，将训练在比目标模型更高的精度下进行，中间计算步骤后四舍五入，基于自适应阈值存储四舍五入决策。

    arXiv:2403.09603v1 Announce Type: cross  Abstract: The increasing compute demands of AI systems has led to the emergence of services that train models on behalf of clients lacking necessary resources. However, ensuring correctness of training and guarding against potential training-time attacks, such as data poisoning, poses challenges. Existing works on verifiable training largely fall into two classes: proof-based systems, which struggle to scale due to requiring cryptographic techniques, and "optimistic" methods that consider a trusted third-party auditor who replicates the training process. A key challenge with the latter is that hardware nondeterminism between GPU types during training prevents an auditor from replicating the training process exactly, and such schemes are therefore non-robust. We propose a method that combines training in a higher precision than the target model, rounding after intermediate computation steps, and storing rounding decisions based on an adaptive thr
    
[^8]: 算法句法因果识别

    Algorithmic syntactic causal identification

    [https://arxiv.org/abs/2403.09580](https://arxiv.org/abs/2403.09580)

    通过替换传统概率论为对称单调范畴的替代基础，可以扩展因果识别技术到更多因果设置中。

    

    在因果贝叶斯网络（CBN）中进行因果识别是因果推断中的一项重要工具，允许从理论上可能的情况下的观测分布推导干预分布。然而，大多数现有的因果识别形式，如使用d分离和do-演算的技术都是在CBN上利用经典概率论的数学语言表达的。然而，在许多因果设置中，概率论和因此目前的因果识别技术不适用，如关系数据库、数据流程序（例如硬件描述语言）、分布式系统和大多数现代机器学习算法。我们表明，可以通过用对称单调范畴的替代公理基础来消除这种限制。在这种替代公理化中，我们展示了如何获得一个明确且清晰的

    arXiv:2403.09580v1 Announce Type: new  Abstract: Causal identification in causal Bayes nets (CBNs) is an important tool in causal inference allowing the derivation of interventional distributions from observational distributions where this is possible in principle. However, most existing formulations of causal identification using techniques such as d-separation and do-calculus are expressed within the mathematical language of classical probability theory on CBNs. However, there are many causal settings where probability theory and hence current causal identification techniques are inapplicable such as relational databases, dataflow programs such as hardware description languages, distributed systems and most modern machine learning algorithms. We show that this restriction can be lifted by replacing the use of classical probability theory with the alternative axiomatic foundation of symmetric monoidal categories. In this alternative axiomatization, we show how an unambiguous and clean
    
[^9]: 通过区块链和大型语言模型增强自主代理的信任：一种通过区块链和大型语言模型实现责任和可解释性的架构

    Enhancing Trust in Autonomous Agents: An Architecture for Accountability and Explainability through Blockchain and Large Language Models

    [https://arxiv.org/abs/2403.09567](https://arxiv.org/abs/2403.09567)

    通过区块链和大型语言模型实现责任和可解释性的架构，提高自主代理的信任和安全性，增强代理与用户之间的沟通效果。

    

    自主代理在涉及人类互动的环境中的部署日益引起安全关注。因此，了解事件背后的情况变得至关重要，需要开发能够向非专家用户解释其行为的能力。这些解释在提高可信度和安全性方面至关重要，作为防范失败、错误和误解的措施。此外，它们有助于改善沟通，弥合代理和用户之间的差距，从而提高它们相互作用的效果。这项工作提出了一种为基于ROS的移动机器人实施的责任和可解释性架构。所提出的解决方案包括两个主要组件。首先，一个类似黑盒的元素用于提供问责制，具有通过区块链技术实现的防篡改属性。其次，一个负责的组件

    arXiv:2403.09567v1 Announce Type: cross  Abstract: The deployment of autonomous agents in environments involving human interaction has increasingly raised security concerns. Consequently, understanding the circumstances behind an event becomes critical, requiring the development of capabilities to justify their behaviors to non-expert users. Such explanations are essential in enhancing trustworthiness and safety, acting as a preventive measure against failures, errors, and misunderstandings. Additionally, they contribute to improving communication, bridging the gap between the agent and the user, thereby improving the effectiveness of their interactions. This work presents an accountability and explainability architecture implemented for ROS-based mobile robots. The proposed solution consists of two main components. Firstly, a black box-like element to provide accountability, featuring anti-tampering properties achieved through blockchain technology. Secondly, a component in charge of 
    
[^10]: 欢迎您的新AI团队：关于使用大语言模型进行安全分析

    Welcome Your New AI Teammate: On Safety Analysis by Leashing Large Language Models

    [https://arxiv.org/abs/2403.09565](https://arxiv.org/abs/2403.09565)

    该研究提出了使用大语言模型进行安全工程领域的危险分析与风险评估自动化的框架，旨在加速SafetyOps周期中关键步骤的进行。

    

    DevOps在许多行业中都是必不可少的，包括自动驾驶汽车的发展。在这些设置中，有一些迭代活动减慢了SafetyOps周期的速度。其中之一是“危险分析与风险评估”（HARA），这是开始安全要求规范的重要步骤。作为增加SafetyOps中这一步速度的潜在途径，我们深入探讨了大型语言模型（LLMs）的能力。我们的目标是系统评估它们在安全工程领域的应用潜力。为此，我们提出了一个框架，支持使用LLMs更高程度的自动化HARA。尽管我们努力自动化尽可能多的流程，但专家审查仍然至关重要，以确保分析结果的有效性和正确性，并相应进行必要的修改。

    arXiv:2403.09565v1 Announce Type: cross  Abstract: DevOps is a necessity in many industries, including the development of Autonomous Vehicles. In those settings, there are iterative activities that reduce the speed of SafetyOps cycles. One of these activities is "Hazard Analysis & Risk Assessment" (HARA), which is an essential step to start the safety requirements specification. As a potential approach to increase the speed of this step in SafetyOps, we have delved into the capabilities of Large Language Models (LLMs).   Our objective is to systematically assess their potential for application in the field of safety engineering. To that end, we propose a framework to support a higher degree of automation of HARA with LLMs. Despite our endeavors to automate as much of the process as possible, expert review remains crucial to ensure the validity and correctness of the analysis results, with necessary modifications made accordingly.
    
[^11]: 将去噪推广到非平衡结构以改进等变力场

    Generalizing Denoising to Non-Equilibrium Structures Improves Equivariant Force Fields

    [https://arxiv.org/abs/2403.09549](https://arxiv.org/abs/2403.09549)

    将去噪方法推广到非平衡结构，从而改进等变力场的性能，提高了对原子间相互作用的理解以及在分子动力学和催化剂设计等领域的应用。

    

    理解原子间的相互作用，如3D原子体系中的力，对于许多应用如分子动力学和催化剂设计至关重要。然而，模拟这些相互作用需要计算密集的从头算计算，因此训练神经网络的数据有限。本文提出使用去噪非平衡结构（DeNS）作为辅助任务，以更好地利用训练数据并提高性能。在使用DeNS进行训练时，我们首先通过向其3D坐标添加噪声来破坏3D结构，然后预测噪声。不同于以往仅限于平衡结构的去噪工作，所提出的方法将去噪泛化到更大范围的非平衡结构。主要区别在于非平衡结构不对应于局部能量最小值，具有非零力，因此可能具有许多可能的原子位置。

    arXiv:2403.09549v1 Announce Type: cross  Abstract: Understanding the interactions of atoms such as forces in 3D atomistic systems is fundamental to many applications like molecular dynamics and catalyst design. However, simulating these interactions requires compute-intensive ab initio calculations and thus results in limited data for training neural networks. In this paper, we propose to use denoising non-equilibrium structures (DeNS) as an auxiliary task to better leverage training data and improve performance. For training with DeNS, we first corrupt a 3D structure by adding noise to its 3D coordinates and then predict the noise. Different from previous works on denoising, which are limited to equilibrium structures, the proposed method generalizes denoising to a much larger set of non-equilibrium structures. The main difference is that a non-equilibrium structure does not correspond to local energy minima and has non-zero forces, and therefore it can have many possible atomic posit
    
[^12]: API保护的LLMs的标志泄露专有信息

    Logits of API-Protected LLMs Leak Proprietary Information

    [https://arxiv.org/abs/2403.09539](https://arxiv.org/abs/2403.09539)

    大多数现代LLM受到softmax瓶颈影响，可以以较低成本获取API保护的LLM的非公开信息和解锁多种功能

    

    大型语言模型（LLMs）的商业化导致了高级API-only接入专有模型的常见实践。在这项工作中，我们展示了即使对于模型架构有保守的假设，也可以从相对较少的API查询中学习关于API保护的LLM的大量非公开信息（例如，使用OpenAI的gpt-3.5-turbo仅花费不到1000美元）。我们的发现集中在一个关键观察上：大多数现代LLM受到了softmax瓶颈的影响，这限制了模型输出到完整输出空间的线性子空间。我们表明，这导致了一个模型图像或模型签名，从而以较低的成本解锁了几种功能：有效发现LLM的隐藏大小，获取完整词汇输出，检测和消除不同模型更新，识别给定单个完整LLM输出的源LLM，以及...

    arXiv:2403.09539v1 Announce Type: cross  Abstract: The commercialization of large language models (LLMs) has led to the common practice of high-level API-only access to proprietary models. In this work, we show that even with a conservative assumption about the model architecture, it is possible to learn a surprisingly large amount of non-public information about an API-protected LLM from a relatively small number of API queries (e.g., costing under $1,000 for OpenAI's gpt-3.5-turbo). Our findings are centered on one key observation: most modern LLMs suffer from a softmax bottleneck, which restricts the model outputs to a linear subspace of the full output space. We show that this lends itself to a model image or a model signature which unlocks several capabilities with affordable cost: efficiently discovering the LLM's hidden size, obtaining full-vocabulary outputs, detecting and disambiguating different model updates, identifying the source LLM given a single full LLM output, and eve
    
[^13]: VisionGPT-3D:一种用于增强3D视觉理解的通用多模态代理

    VisionGPT-3D: A Generalized Multimodal Agent for Enhanced 3D Vision Understanding

    [https://arxiv.org/abs/2403.09530](https://arxiv.org/abs/2403.09530)

    提出了一个统一的VisionGPT-3D框架，整合了最先进的视觉模型，有助于提升计算机视觉对于3D视觉理解的能力

    

    文本向视觉组件的演进促进了人们日常生活的便利，例如从文本生成图像、视频并识别图像中所需的元素。以前的计算机视觉模型专注于基于明确定义对象的图像检测、分类。大型语言模型(LLMs)将自然语言转换为视觉对象，为文本背景提供了视觉布局。OpenAI GPT-4已成为LLMs的顶峰，而计算机视觉(CV)领域拥有大量最先进的模型和算法，可将2D图像转换为它们的3D表示。然而，算法与问题之间的不匹配可能导致不良结果。针对这一挑战，我们提出了一个统一的VisionGPT-3D框架， conslidate了最先进的视觉模型，从而促进了发展。

    arXiv:2403.09530v1 Announce Type: cross  Abstract: The evolution of text to visual components facilitates people's daily lives, such as generating image, videos from text and identifying the desired elements within the images. Computer vision models involving the multimodal abilities in the previous days are focused on image detection, classification based on well-defined objects. Large language models (LLMs) introduces the transformation from nature language to visual objects, which present the visual layout for text contexts. OpenAI GPT-4 has emerged as the pinnacle in LLMs, while the computer vision (CV) domain boasts a plethora of state-of-the-art (SOTA) models and algorithms to convert 2D images to their 3D representations. However, the mismatching between the algorithms with the problem could lead to undesired results. In response to this challenge, we propose an unified VisionGPT-3D framework to consolidate the state-of-the-art vision models, thereby facilitating the development
    
[^14]: AdaShield：通过自适应盾牌提示保护多模态大型语言模型免受基于结构的攻击

    AdaShield: Safeguarding Multimodal Large Language Models from Structure-based Attack via Adaptive Shield Prompting

    [https://arxiv.org/abs/2403.09513](https://arxiv.org/abs/2403.09513)

    AdaShield 提出了自适应盾牌提示方法，无需微调或额外训练模块，即可保护多模态大型语言模型免受基于结构的越狱攻击。

    

    随着多模态大型语言模型（MLLMs）的出现和广泛部署，确保它们的安全性变得愈发重要。然而，随着额外模态的整合，MLLMs暴露于新的漏洞，使其容易遭受基于结构的越狱攻击，即向图像中注入语义内容（例如“有害文本”）以误导MLLMs。在这项工作中，我们旨在抵御此类威胁。具体来说，我们提出了\textbf{Ada}ptive \textbf{Shield} Prompting（\textbf{AdaShield}），它在输入前添加防御提示，以在不微调MLLMs或训练额外模块（例如后阶段内容检测器）的情况下，保护MLLMs免受基于结构的越狱攻击。最初，我们呈现了一个手动设计的静态防御提示，它逐步彻底检查图像和指令内容，并指定响应恶意查询的方法。

    arXiv:2403.09513v1 Announce Type: cross  Abstract: With the advent and widespread deployment of Multimodal Large Language Models (MLLMs), the imperative to ensure their safety has become increasingly pronounced. However, with the integration of additional modalities, MLLMs are exposed to new vulnerabilities, rendering them prone to structured-based jailbreak attacks, where semantic content (e.g., "harmful text") has been injected into the images to mislead MLLMs. In this work, we aim to defend against such threats. Specifically, we propose \textbf{Ada}ptive \textbf{Shield} Prompting (\textbf{AdaShield}), which prepends inputs with defense prompts to defend MLLMs against structure-based jailbreak attacks without fine-tuning MLLMs or training additional modules (e.g., post-stage content detector). Initially, we present a manually designed static defense prompt, which thoroughly examines the image and instruction content step by step and specifies response methods to malicious queries. Fu
    
[^15]: AI监管信任? 辨识用户对于建立信任和有效的AI监管至关重要

    Trust AI Regulation? Discerning users are vital to build trust and effective AI regulation

    [https://arxiv.org/abs/2403.09510](https://arxiv.org/abs/2403.09510)

    通过演化博弈论量化模拟用户、AI创作者和监管者面临的困境，提出政府认可和奖励监管者可以激励有效监管的机制，帮助建立值得信赖的AI和用户信任。

    

    有普遍共识认为，AI创作者需要受到某种形式的监管以开发值得信赖的系统，用户也需要真正相信这些系统。然而，关于这些监管应该采取什么形式以及如何实施它们存在很大争议。在这一领域的大部分工作是定性的，并且不能进行正式预测。在这里，我们提出演化博弈论可以用于量化模拟用户、AI创作者和监管者面临的困境，并为不同监管制度可能产生的影响提供见解。我们展示了创建值得信赖的AI和用户信任需要监管者受到有效监管的激励。我们证明了可以实现这一点的两种机制的有效性。第一种机制是政府可以认可并奖励做好工作的监管者。在这种情况下，如果AI系统对用户来说不太风险。

    arXiv:2403.09510v1 Announce Type: new  Abstract: There is general agreement that some form of regulation is necessary both for AI creators to be incentivised to develop trustworthy systems, and for users to actually trust those systems. But there is much debate about what form these regulations should take and how they should be implemented. Most work in this area has been qualitative, and has not been able to make formal predictions. Here, we propose that evolutionary game theory can be used to quantitatively model the dilemmas faced by users, AI creators, and regulators, and provide insights into the possible effects of different regulatory regimes. We show that creating trustworthy AI and user trust requires regulators to be incentivised to regulate effectively. We demonstrate the effectiveness of two mechanisms that can achieve this. The first is where governments can recognise and reward regulators that do a good job. In that case, if the AI system is not too risky for users then 
    
[^16]: 不要以外表判断: 用于视频识别的运动一致增强

    Don't Judge by the Look: A Motion Coherent Augmentation for Video Recognition

    [https://arxiv.org/abs/2403.09506](https://arxiv.org/abs/2403.09506)

    本研究提出了一种名为运动一致增强（MCA）的数据增强方法，通过引入外观变化来鼓励模型优先考虑视频中的运动信息，而不是静态外观。

    

    当前目标识别中的训练流程在数据增强时忽略了色调抖动，因为它不仅会带来对分类有害的外观变化，而且在实践中实现也是低效的。本研究探讨了色调变化在视频识别中的影响，并发现这种变化是有益的，因为对于包含运动信息的视频来说，静态外观不是那么重要。基于这一观察结果，我们提出了一种用于视频识别的数据增强方法，名为运动一致增强（MCA），它在视频中引入外观变化，隐式鼓励模型优先考虑运动模式，而不是静态外观。具体来说，我们提出了一种名为SwapMix的操作，用于高效修改视频样本的外观，并引入了变异对齐（VA）来解决SwapMix引起的分布偏移，迫使模型去学习

    arXiv:2403.09506v1 Announce Type: cross  Abstract: Current training pipelines in object recognition neglect Hue Jittering when doing data augmentation as it not only brings appearance changes that are detrimental to classification, but also the implementation is inefficient in practice. In this study, we investigate the effect of hue variance in the context of video recognition and find this variance to be beneficial since static appearances are less important in videos that contain motion information. Based on this observation, we propose a data augmentation method for video recognition, named Motion Coherent Augmentation (MCA), that introduces appearance variation in videos and implicitly encourages the model to prioritize motion patterns, rather than static appearances. Concretely, we propose an operation SwapMix to efficiently modify the appearance of video samples, and introduce Variation Alignment (VA) to resolve the distribution shift caused by SwapMix, enforcing the model to le
    
[^17]: EquiAV: 利用等变性进行音频-视觉对比学习

    EquiAV: Leveraging Equivariance for Audio-Visual Contrastive Learning

    [https://arxiv.org/abs/2403.09502](https://arxiv.org/abs/2403.09502)

    这项研究提出了一种利用等变性进行音频-视觉对比学习的新框架，通过一个共享的基于注意力的变换预测器来实现特征聚合和嵌入表示，有效提供了强大的监督，且计算开销最小。

    

    自我监督的音频-视觉表示学习最近取得了重大进展，展示出捕捉丰富综合表示的潜力。然而，尽管数据增强在许多学习方法中已经得到验证，音频-视觉学习仍然很难充分利用这些优势，因为增强可能会轻易破坏输入对之间的对应关系。为了解决这一限制，我们引入了EquiAV，一种利用等变性进行音频-视觉对比学习的新框架。我们的方法从扩展等变性开始进行音频-视觉学习，通过一个共享的基于注意力的变换预测器来促进。它使得来自不同增强的特征能够聚合到一个代表性的嵌入中，提供强大的监督。值得注意的是，这是在最小计算开销的情况下实现的。大量消融研究和定性结果验证了我们方法的有效性。

    arXiv:2403.09502v1 Announce Type: cross  Abstract: Recent advancements in self-supervised audio-visual representation learning have demonstrated its potential to capture rich and comprehensive representations. However, despite the advantages of data augmentation verified in many learning methods, audio-visual learning has struggled to fully harness these benefits, as augmentations can easily disrupt the correspondence between input pairs. To address this limitation, we introduce EquiAV, a novel framework that leverages equivariance for audio-visual contrastive learning. Our approach begins with extending equivariance to audio-visual learning, facilitated by a shared attention-based transformation predictor. It enables the aggregation of features from diverse augmentations into a representative embedding, providing robust supervision. Notably, this is achieved with minimal computational overhead. Extensive ablation studies and qualitative results verify the effectiveness of our method. 
    
[^18]: 使用Q学习的奶牛养殖场电池管理的强化学习方法

    A Reinforcement Learning Approach to Dairy Farm Battery Management using Q Learning

    [https://arxiv.org/abs/2403.09499](https://arxiv.org/abs/2403.09499)

    该研究提出了一种基于Q学习的算法，以实现在奶牛养殖中整合可再生能源，以改善电池管理，应对电能消耗波动和能源价格波动的挑战。

    

    奶牛养殖消耗大量能源，是农业中一个能源密集型的部门。将可再生能源集成到奶牛养殖中可以帮助应对这一挑战。有效的电池管理对于整合可再生能源发电至关重要。管理电池的充电和放电由于电能消耗的波动、可再生能源发电的间歇性以及能源价格的波动而面临重大挑战。人工智能（AI）有潜力显著改善奶牛养殖中可再生能源的利用，然而在这一特定领域中进行的研究有限。本研究以爱尔兰作为案例研究，以实现其以可再生能源利用为核心的2030年能源战略。这项研究提出了一种基于Q学习的算法，用于安排电池的充电和放电。

    arXiv:2403.09499v1 Announce Type: cross  Abstract: Dairy farming consumes a significant amount of energy, making it an energy-intensive sector within agriculture. Integrating renewable energy generation into dairy farming could help address this challenge. Effective battery management is important for integrating renewable energy generation. Managing battery charging and discharging poses significant challenges because of fluctuations in electrical consumption, the intermittent nature of renewable energy generation, and fluctuations in energy prices. Artificial Intelligence (AI) has the potential to significantly improve the use of renewable energy in dairy farming, however, there is limited research conducted in this particular domain. This research considers Ireland as a case study as it works towards attaining its 2030 energy strategy centered on the utilization of renewable sources. This study proposes a Q-learning-based algorithm for scheduling battery charging and discharging in 
    
[^19]: 从怀疑到接受：模拟对虚假新闻态度动态的变化

    From Skepticism to Acceptance: Simulating the Attitude Dynamics Toward Fake News

    [https://arxiv.org/abs/2403.09498](https://arxiv.org/abs/2403.09498)

    本研究引入了基于大型语言模型的虚假新闻传播仿真框架，研究了虚假新闻传播的趋势和控制，每个代理人在仿真中代表具有独特个性的个体。

    

    在数字时代，虚假新闻和谣言通过社交网络迅速传播，带来了显著的社会挑战，影响着公众舆论。传统的虚假新闻建模通常预测不同群体的普遍流行趋势或数字化代表意见转变。然而，这些方法经常过于简化现实世界的复杂性，忽视了新闻文本丰富的语义信息。大型语言模型（LLMs）的出现提供了模拟微妙意见动态的可能性。因此，在这项工作中，我们引入了基于LLM的虚假新闻传播仿真框架（FPS），详细研究虚假新闻传播的趋势和控制。具体地，仿真中的每个代理人代表具有独特个性的个人。他们配备了短期和长期记忆，以及反思机制来模仿类人思维。每天，

    arXiv:2403.09498v1 Announce Type: cross  Abstract: In the digital era, the rapid propagation of fake news and rumors via social networks brings notable societal challenges and impacts public opinion regulation. Traditional fake news modeling typically forecasts the general popularity trends of different groups or numerically represents opinions shift. However, these methods often oversimplify real-world complexities and overlook the rich semantic information of news text. The advent of large language models (LLMs) provides the possibility of modeling subtle dynamics of opinion. Consequently, in this work, we introduce a Fake news Propagation Simulation framework (FPS) based on LLM, which studies the trends and control of fake news propagation in detail. Specifically, each agent in the simulation represents an individual with a distinct personality. They are equipped with both short-term and long-term memory, as well as a reflective mechanism to mimic human-like thinking. Every day, the
    
[^20]: 在上下文学习中纠正演示快捷方式

    Rectifying Demonstration Shortcut in In-Context Learning

    [https://arxiv.org/abs/2403.09488](https://arxiv.org/abs/2403.09488)

    本研究旨在纠正大型语言模型在上下文学习中的演示快捷方式，并引入了一种新的明示意识校准方法。

    

    大型语言模型（LLMs）能够利用它们的上下文学习（ICL）能力，仅凭少量演示便能解决各种任务。然而，LLMs常常依赖于它们对演示的预先训练的语义先验，而不是根据输入-标签关系继续进行ICL预测。本文将这一现象称为“演示快捷方式”。尽管先前的研究主要集中于改进预定义任务的ICL预测结果，我们的目标是纠正演示快捷方式，从而使LLM能够有效地从演示中学习新的输入-标签关系。为实现此目标，我们引入了一种明示意识的校准方法：In-Context Calibration。我们在两个设置中评估了所提出方法的有效性：（1）使用标准标签空间的原始ICL任务以及（2）任务学习设置，其中标签空间被语义无关的标记替换。

    arXiv:2403.09488v1 Announce Type: cross  Abstract: Large language models (LLMs) are able to solve various tasks with only a few demonstrations utilizing their in-context learning (ICL) abilities. However, LLMs often rely on their pre-trained semantic priors of demonstrations rather than on the input-label relationships to proceed with ICL prediction. In this work, we term this phenomenon as the `Demonstration Shortcut'. While previous works have primarily focused on improving ICL prediction results for predefined tasks, we aim to rectify the Demonstration Shortcut, thereby enabling the LLM to effectively learn new input-label relationships from demonstrations. To achieve this, we introduce In-Context Calibration, a demonstration-aware calibration method. We evaluate the effectiveness of the proposed method in two settings: (1) the Original ICL Task using the standard label space and (2) the Task Learning setting, where the label space is replaced with semantically unrelated tokens. In 
    
[^21]: 基于贝叶斯网络的表格数据和文本的临床推理

    Clinical Reasoning over Tabular Data and Text with Bayesian Networks

    [https://arxiv.org/abs/2403.09481](https://arxiv.org/abs/2403.09481)

    本文比较和讨论了如何将贝叶斯网络与神经文本表示相结合，以改进临床推理，特别是在处理自然语言数据方面。

    

    贝叶斯网络非常适合用于处理表格数据进行临床推理，但对于自然语言数据来说却不够兼容，而神经网络则为处理自然语言数据提供了成功的框架。本文比较并讨论了如何以生成性和判别性方式增强贝叶斯网络与神经文本表示，结合模拟结果以一个基础医疗案例（肺炎诊断）进行说明，并在更广泛的临床背景下进行讨论。

    arXiv:2403.09481v1 Announce Type: new  Abstract: Bayesian networks are well-suited for clinical reasoning on tabular data, but are less compatible with natural language data, for which neural networks provide a successful framework. This paper compares and discusses strategies to augment Bayesian networks with neural text representations, both in a generative and discriminative manner. This is illustrated with simulation results for a primary care use case (diagnosis of pneumonia) and discussed in a broader clinical context.
    
[^22]: Sketch解释在下游任务中的实际含义

    What Sketch Explainability Really Means for Downstream Tasks

    [https://arxiv.org/abs/2403.09480](https://arxiv.org/abs/2403.09480)

    本文探讨了草图解释的独特性，提出了适用于各种下游任务的解释性解决方案，包括四个应用领域：检索、生成、辅助绘图以及草图对抗攻击。

    

    在本文中，我们探讨了涵盖草图解释性的独特模态，强调人类笔触相对于传统基于像素的研究所产生的深远影响。除了解释网络行为之外，我们还辨别了解释性在不同下游与草图相关任务中的真正含义。我们提出了一种轻量且便携的解释性解决方案——一个无缝插件，能够轻松与任何预训练模型集成，消除了重新训练的需要。为了展示其适应性，我们提出了四个应用：广受关注的检索和生成，以及全新的辅助绘图和草图对抗攻击。我们解决方案的核心是一种笔触级别的归因地图，在与下游任务链接时呈现不同形式。通过解决光栅化的固有不可微性，我们实现了在粗略笔触级别（SLA）和部分笔触级别（P-S）进行解释的能力。

    arXiv:2403.09480v1 Announce Type: cross  Abstract: In this paper, we explore the unique modality of sketch for explainability, emphasising the profound impact of human strokes compared to conventional pixel-oriented studies. Beyond explanations of network behavior, we discern the genuine implications of explainability across diverse downstream sketch-related tasks. We propose a lightweight and portable explainability solution -- a seamless plugin that integrates effortlessly with any pre-trained model, eliminating the need for re-training. Demonstrating its adaptability, we present four applications: highly studied retrieval and generation, and completely novel assisted drawing and sketch adversarial attacks. The centrepiece to our solution is a stroke-level attribution map that takes different forms when linked with downstream tasks. By addressing the inherent non-differentiability of rasterisation, we enable explanations at both coarse stroke level (SLA) and partial stroke level (P-S
    
[^23]: 基于LLM的智能体用于自动提升用户故事质量：一个早期报告

    LLM-based agents for automating the enhancement of user story quality: An early report

    [https://arxiv.org/abs/2403.09442](https://arxiv.org/abs/2403.09442)

    本研究探索了使用大型语言模型自动改善用户故事质量的方法，验证了LLMs对提高用户故事质量的潜力，并在敏捷开发中展示了AI的实际应用。

    

    在敏捷软件开发中，保持高质量的用户故事至关重要，但也具有挑战性。本研究探讨了利用大型语言模型自动提升奥地利邮政集团IT敏捷团队中用户故事质量的方法。我们开发了一个自主LLM智能体系统的参考模型，并将其实施在公司中。通过11位参与者跨越六个敏捷团队对研究中的用户故事质量以及这些智能体在提高用户故事质量方面的有效性进行评估。我们的研究结果展示了LLMs在提高用户故事质量方面的潜力，对AI在敏捷开发中的角色进行了贡献，并提供了AI在行业环境中的变革性影响的实际示例。

    arXiv:2403.09442v1 Announce Type: cross  Abstract: In agile software development, maintaining high-quality user stories is crucial, but also challenging. This study explores the use of large language models to automatically improve the user story quality in Austrian Post Group IT agile teams. We developed a reference model for an Autonomous LLM-based Agent System and implemented it at the company. The quality of user stories in the study and the effectiveness of these agents for user story quality improvement was assessed by 11 participants across six agile teams. Our findings demonstrate the potential of LLMs in improving user story quality, contributing to the research on AI role in agile development, and providing a practical example of the transformative impact of AI in an industry setting.
    
[^24]: 3D-SceneDreamer: 文本驱动的3D一致场景生成

    3D-SceneDreamer: Text-Driven 3D-Consistent Scene Generation

    [https://arxiv.org/abs/2403.09439](https://arxiv.org/abs/2403.09439)

    通过引入全局3D信息和生成性细化网络，结合NeRF模型和2D扩散模型先验，提出了3D-SceneDreamer这一文本驱动的一致3D场景生成方法。

    

    近年来，文本驱动的3D场景生成技术取得了快速进展。这些方法的成功主要归因于利用现有生成模型进行图像扭曲和修补，生成3D场景。然而，这些方法严重依赖于现有模型的输出，在几何和外观上会导致错误累积，阻碍了模型在各种场景（例如户外和虚拟场景）中的使用。为了解决这一限制，我们通过查询和聚合全局3D信息，对新生成的局部视图进行生成性细化，然后逐步生成3D场景。具体来说，我们使用基于三平面特征的NeRF作为3D场景的统一表示，以约束全局3D一致性，并提出一个生成性细化网络，通过利用来自2D扩散模型的自然图像先验以及全局信息来合成质量更高的新内容。

    arXiv:2403.09439v1 Announce Type: cross  Abstract: Text-driven 3D scene generation techniques have made rapid progress in recent years. Their success is mainly attributed to using existing generative models to iteratively perform image warping and inpainting to generate 3D scenes. However, these methods heavily rely on the outputs of existing models, leading to error accumulation in geometry and appearance that prevent the models from being used in various scenarios (e.g., outdoor and unreal scenarios). To address this limitation, we generatively refine the newly generated local views by querying and aggregating global 3D information, and then progressively generate the 3D scene. Specifically, we employ a tri-plane features-based NeRF as a unified representation of the 3D scene to constrain global 3D consistency, and propose a generative refinement network to synthesize new contents with higher quality by exploiting the natural image prior from 2D diffusion model as well as the global 
    
[^25]: 在反事实图像生成中缓解属性放大问题

    Mitigating attribute amplification in counterfactual image generation

    [https://arxiv.org/abs/2403.09422](https://arxiv.org/abs/2403.09422)

    提出了一种软反事实微调方法，可以在保持生成图像有效性的同时，显著减少属性放大效应。

    

    因果生成建模在医学影像领域备受关注，因其能够回答干预和反事实查询。大多数研究侧重于生成看起来合理的反事实图像，使用辅助分类器来强化模拟干预的有效性。我们调查了这种方法中的缺陷，发现了属性放大问题，即在干预过程中会误伤无关属性，导致受保护特征和疾病状态之间的偏见。我们展示了属性放大是由反事实训练过程中使用硬标签引起的，并提出了软反事实微调以缓解这一问题。我们的方法显著减少了放大效应，同时保持了生成图像的有效性，在大型胸部X射线数据集上进行了演示。我们的工作在实现更加忠实和无偏向的因果生成方面取得了重要进展。

    arXiv:2403.09422v1 Announce Type: cross  Abstract: Causal generative modelling is gaining interest in medical imaging due to its ability to answer interventional and counterfactual queries. Most work focuses on generating counterfactual images that look plausible, using auxiliary classifiers to enforce effectiveness of simulated interventions. We investigate pitfalls in this approach, discovering the issue of attribute amplification, where unrelated attributes are spuriously affected during interventions, leading to biases across protected characteristics and disease status. We show that attribute amplification is caused by the use of hard labels in the counterfactual training process and propose soft counterfactual fine-tuning to mitigate this issue. Our method substantially reduces the amplification effect while maintaining effectiveness of generated images, demonstrated on a large chest X-ray dataset. Our work makes an important advancement towards more faithful and unbiased causal 
    
[^26]: 开放图谱：大规模室外环境中的开放词汇分层3D图表示

    OpenGraph: Open-Vocabulary Hierarchical 3D Graph Representation in Large-Scale Outdoor Environments

    [https://arxiv.org/abs/2403.09412](https://arxiv.org/abs/2403.09412)

    开放图谱是针对大规模室外环境设计的开放词汇分层图结构，旨在解决现有地图受限于室内场景和VLM特征的问题，通过视觉图像提取实例和标题，并加强文字推理。

    

    具有复杂语义的环境地图对于促进机器人和人类之间的无缝交互至关重要，使它们能够有效地执行各种任务。开放词汇地图，由视觉-语言模型（VLM）驱动，具有固有优势，包括多模态检索和开放类别。然而，现有的开放词汇地图受限于封闭的室内场景和VLM特征，从而降低了它们的可用性和推理能力。此外，缺乏拓扑关系进一步使得对特定实例的准确查询变得复杂。在这项工作中，我们提出了OpenGraph，这是一种为大规模室外环境设计的开放词汇分层图结构表示。OpenGraph首先利用2D基础模型从视觉图像中提取实例及其标题，并对标题进行特征编码以增强文字推理。随后，3D进

    arXiv:2403.09412v1 Announce Type: cross  Abstract: Environment maps endowed with sophisticated semantics are pivotal for facilitating seamless interaction between robots and humans, enabling them to effectively carry out various tasks. Open-vocabulary maps, powered by Visual-Language models (VLMs), possess inherent advantages, including multimodal retrieval and open-set classes. However, existing open-vocabulary maps are constrained to closed indoor scenarios and VLM features, thereby diminishing their usability and inference capabilities. Moreover, the absence of topological relationships further complicates the accurate querying of specific instances. In this work, we propose OpenGraph, a representation of open-vocabulary hierarchical graph structure designed for large-scale outdoor environments. OpenGraph initially extracts instances and their captions from visual images using 2D foundation models, encoding the captions with features to enhance textual reasoning. Subsequently, 3D in
    
[^27]: XCoOp：通过概念引导的上下文优化为计算机辅助诊断提供可解释的提示学习

    XCoOp: Explainable Prompt Learning for Computer-Aided Diagnosis via Concept-guided Context Optimization

    [https://arxiv.org/abs/2403.09410](https://arxiv.org/abs/2403.09410)

    提出了一种新颖的可解释的提示学习框架，通过对齐图像、可学习提示和临床概念驱动提示的语义，利用医学知识。

    

    利用大视觉-语言模型（VLMs）强大的表示来完成各种下游任务已经引起了越来越多的关注。在这一研究领域中，软提示学习已经成为一种代表性方法，用于高效地适应VLMs，例如CLIP，以执行诸如图像分类之类的任务。然而，大多数现有的提示学习方法学习的文本标记是无法解释的，这不能满足像医疗保健等高风险场景中解释人工智能（XAI）的严格可解释性要求。为了解决这一问题，我们提出了一种新颖的可解释的提示学习框架，通过在多个粒度上对齐图像、可学习提示和临床概念驱动提示的语义，利用医学知识。此外，我们的框架通过从大型语言模型中获取知识来解决缺乏有价值的概念注释的问题，并提供了视觉和文本上

    arXiv:2403.09410v1 Announce Type: cross  Abstract: Utilizing potent representations of the large vision-language models (VLMs) to accomplish various downstream tasks has attracted increasing attention. Within this research field, soft prompt learning has become a representative approach for efficiently adapting VLMs such as CLIP, to tasks like image classification. However, most existing prompt learning methods learn text tokens that are unexplainable, which cannot satisfy the stringent interpretability requirements of Explainable Artificial Intelligence (XAI) in high-stakes scenarios like healthcare. To address this issue, we propose a novel explainable prompt learning framework that leverages medical knowledge by aligning the semantics of images, learnable prompts, and clinical concept-driven prompts at multiple granularities. Moreover, our framework addresses the lack of valuable concept annotations by eliciting knowledge from large language models and offers both visual and textual
    
[^28]: "像套娃一样"：利用大语言模型分析计算机科学学生生成的递归类比

    "Like a Nesting Doll": Analyzing Recursion Analogies Generated by CS Students using Large Language Models

    [https://arxiv.org/abs/2403.09409](https://arxiv.org/abs/2403.09409)

    使用大语言模型ChatGPT，研究了超过350名一年级计算机学生生成的递归类比，探讨了如何利用这些类比帮助理解复杂的计算概念

    

    把复杂的计算概念融会贯通常常是学生面临的挑战，他们往往难以将这些新想法锚定在熟悉的经验和理解之上。为了帮助解决这一问题，一个好的类比可以弥合陌生概念与熟悉概念之间的鸿沟，提供了一种引人入胜的方式来帮助理解。然而，即使对于经验丰富的教师来说，创造有效的教育类比也是困难的。我们研究了大语言模型（LLMs），特别是ChatGPT，到底能够在多大程度上提供按需访问个人相关类比的可能性。我们专注于递归，这是一个具有挑战性的门槛概念，我们进行了一项调查，分析了350多名一年级计算机学生生成的类比。他们被要求使用ChatGPT生成基于递归的类比，其中可以选择在提示中包含个人相关主题。我们观察到生成的类比呈现出极大的多样性。

    arXiv:2403.09409v1 Announce Type: cross  Abstract: Grasping complex computing concepts often poses a challenge for students who struggle to anchor these new ideas to familiar experiences and understandings. To help with this, a good analogy can bridge the gap between unfamiliar concepts and familiar ones, providing an engaging way to aid understanding. However, creating effective educational analogies is difficult even for experienced instructors. We investigate to what extent large language models (LLMs), specifically ChatGPT, can provide access to personally relevant analogies on demand. Focusing on recursion, a challenging threshold concept, we conducted an investigation analyzing the analogies generated by more than 350 first-year computing students. They were provided with a code snippet and tasked to generate their own recursion-based analogies using ChatGPT, optionally including personally relevant topics in their prompts. We observed a great deal of diversity in the analogies p
    
[^29]: LM2D：以歌词和音乐驱动的舞蹈合成

    LM2D: Lyrics- and Music-Driven Dance Synthesis

    [https://arxiv.org/abs/2403.09407](https://arxiv.org/abs/2403.09407)

    提出了LM2D，一种结合了多模态扩散模型和一致性蒸馏的新颖概率架构，旨在在音乐和歌词条件下进行舞蹈生成；介绍了第一个涵盖音乐和歌词的3D舞蹈运动数据集。

    

    舞蹈通常涉及专业编舞，包含按照音乐节奏进行的复杂动作，还可能受到歌词内容的影响。将歌词整合到听觉维度之外，丰富了基础音色，并使运动生成更易于语义含义。然而，现有的舞蹈合成方法往往只建模于音频信号。在这项工作中，我们做出了两点贡献，首先，我们提出了LM2D，这是一个结合了多模态扩散模型和一致性蒸馏的新颖概率架构，旨在通过一次扩散生成步骤在音乐和歌词的条件下创建舞蹈。其次，我们介绍了第一个涵盖音乐和歌词的3D舞蹈运动数据集，通过姿势估计技术获得。我们通过客观指标和人类评价将我们的模型与仅有音乐的基线模型进行评估。

    arXiv:2403.09407v1 Announce Type: cross  Abstract: Dance typically involves professional choreography with complex movements that follow a musical rhythm and can also be influenced by lyrical content. The integration of lyrics in addition to the auditory dimension, enriches the foundational tone and makes motion generation more amenable to its semantic meanings. However, existing dance synthesis methods tend to model motions only conditioned on audio signals. In this work, we make two contributions to bridge this gap. First, we propose LM2D, a novel probabilistic architecture that incorporates a multimodal diffusion model with consistency distillation, designed to create dance conditioned on both music and lyrics in one diffusion generation step. Second, we introduce the first 3D dance-motion dataset that encompasses both music and lyrics, obtained with pose estimation technologies. We evaluate our model against music-only baseline models with objective metrics and human evaluations, i
    
[^30]: AI中的启发式推理: 工具性使用与模仿吸收

    Heuristic Reasoning in AI: Instrumental Use and Mimetic Absorption

    [https://arxiv.org/abs/2403.09404](https://arxiv.org/abs/2403.09404)

    通过创新性实验，我们揭示了人工智能系统在精度最大化和努力减少之间的权衡，以及在详尽的逻辑处理和使用认知快捷方式（启发式）之间转换的条件，并区分了启发式的工具性使用和模仿吸收两种方式。

    

    我们提出了一种新颖的启发式推理方案，用于人工智能系统。通过一系列创新性实验，包括对经典琳达问题的变体和对美丽比赛游戏的新应用，我们揭示了精度最大化和努力减少之间的权衡，塑造了人工智能在何种条件下在详尽的逻辑处理和使用认知快捷方式（启发式）之间转换。我们区分了启发式的'工具性'使用，以匹配资源与目标，以及'模仿吸收'，即从人类那里学到的启发式，并表现为随机且普遍存在。我们提供证据表明，尽管缺乏内在目标或自我意识，人工智能表现出精度和效率的自适应平衡，符合资源理性人类认知的原则，这是受限理性和双系统理论经典理论的明文阐释。

    arXiv:2403.09404v1 Announce Type: new  Abstract: We propose a novel program of heuristic reasoning within artificial intelligence (AI) systems. Through a series of innovative experiments, including variations of the classic Linda problem and a novel application of the Beauty Contest game, we uncover trade-offs between accuracy maximization and effort reduction that shape the conditions under which AIs transition between exhaustive logical processing and the use of cognitive shortcuts (heuristics). We distinguish between the 'instrumental' use of heuristics to match resources with objectives, and 'mimetic absorption,' whereby heuristics are learned from humans, and manifest randomly and universally. We provide evidence that AI, despite lacking intrinsic goals or self-awareness, manifests an adaptive balancing of precision and efficiency, consistent with principles of resource-rational human cognition as explicated in classical theories of bounded rationality and dual-process theory.
    
[^31]: 一个用于容量位置路径问题的多种群综合方法

    A Multi-population Integrated Approach for Capacitated Location Routing

    [https://arxiv.org/abs/2403.09361](https://arxiv.org/abs/2403.09361)

    该论文提出了一个多种群综合方法，通过多仓库边装配交叉和有效局部搜索等手段，实现了对容量位置路径问题的有效优化。

    

    容量位置路径问题涉及确定从一组候选容量配送中心位置中选取仓库，并找到从选定的仓库到一组客户的服务所需路径，同时最小化包括开设选定仓库的成本、每辆车固定利用成本和路径总成本（距离）在内的成本函数。本文提出了一个多种群综合框架，其中多仓库边装配交叉生成有前景的后代解决方案，从仓库位置和路径边缘组装的角度来看。该方法包括一个基于邻域的有效局部搜索、一个恢复可行性的程序和一个多样化导向的突变。特别有趣的是多种群方案，它根据仓库配置将人口组织成多个子人口。

    arXiv:2403.09361v1 Announce Type: new  Abstract: The capacitated location-routing problem involves determining the depots from a set of candidate capacitated depot locations and finding the required routes from the selected depots to serve a set of customers whereas minimizing a cost function that includes the cost of opening the chosen depots, the fixed utilization cost per vehicle used, and the total cost (distance) of the routes. This paper presents a multi-population integrated framework in which a multi-depot edge assembly crossover generates promising offspring solutions from the perspective of both depot location and route edge assembly. The method includes an effective neighborhood-based local search, a feasibility-restoring procedure and a diversification-oriented mutation. Of particular interest is the multi-population scheme which organizes the population into multiple subpopulations based on depot configurations. Extensive experiments on 281 benchmark instances from the lit
    
[^32]: D3T: RGB-热红外领域跨域目标检测中独特的双域教师之旅

    D3T: Distinctive Dual-Domain Teacher Zigzagging Across RGB-Thermal Gap for Domain-Adaptive Object Detection

    [https://arxiv.org/abs/2403.09359](https://arxiv.org/abs/2403.09359)

    提出了一种称为Distinctive Dual-Domain Teacher (D3T) 的框架，通过独特的训练范式以及在双教师之间的曲折学习方法，成功实现了从可见到热红外领域的领域自适应目标检测。

    

    针对目标检测的领域自适应通常涉及将知识从一个可见领域转移到另一个可见领域。然而，从可见到热红外领域的适应研究有限，因为可见和热红外领域之间的领域差距远远大于预期，传统的领域自适应无法成功地促进在这种情况下的学习。为了克服这一挑战，我们提出了一个称为Distinctive Dual-Domain Teacher (D3T) 的框架，利用各自领域的独特训练范式。具体来说，我们将源训练集和目标训练集分开构建双教师，并逐步对学生模型进行指数移动平均，以适应各个领域的教师。该框架进一步融入了双教师之间的曲折学习方法，在训练过程中促进了从可见到热红外领域的渐进过渡。我们验证了其卓越性能。

    arXiv:2403.09359v1 Announce Type: cross  Abstract: Domain adaptation for object detection typically entails transferring knowledge from one visible domain to another visible domain. However, there are limited studies on adapting from the visible to the thermal domain, because the domain gap between the visible and thermal domains is much larger than expected, and traditional domain adaptation can not successfully facilitate learning in this situation. To overcome this challenge, we propose a Distinctive Dual-Domain Teacher (D3T) framework that employs distinct training paradigms for each domain. Specifically, we segregate the source and target training sets for building dual-teachers and successively deploy exponential moving average to the student model to individual teachers of each domain. The framework further incorporates a zigzag learning method between dual teachers, facilitating a gradual transition from the visible to thermal domains during training. We validate the superiorit
    
[^33]: AVIBench：评估大型视觉-语言模型在对抗性视觉指导上的鲁棒性

    AVIBench: Towards Evaluating the Robustness of Large Vision-Language Model on Adversarial Visual-Instructions

    [https://arxiv.org/abs/2403.09346](https://arxiv.org/abs/2403.09346)

    AVIBench是一个框架，用于分析大型视觉-语言模型对抗各种形式的对抗性视觉指令的鲁棒性，包括图像和文本攻击以及内容偏见攻击。

    

    大型视觉-语言模型（LVLMs）在对用户的视觉指令作出良好响应方面取得了显著进展。然而，这些指令涵盖图像和文本，容易受到有意和无意攻击的影响。尽管LVLMs对抗此类威胁的鲁棒性至关重要，但当前该领域的研究仍然有限。为弥补这一差距，我们引入了AVIBench，一个旨在分析LVLMs在面对各种对抗性视觉指令（AVIs）时的鲁棒性的框架，包括四种基于图像的AVIs、十种基于文本的AVIs和九种内容偏见AVIs（如性别、暴力、文化和种族偏见等）。我们生成了26万个AVIs，涵盖五类多模态能力（九项任务）和内容偏见。然后，我们对包括14个开源LVLMs在内的模型进行全面评估以评估其性能。AVIBench还可作为一个便利的工具

    arXiv:2403.09346v1 Announce Type: cross  Abstract: Large Vision-Language Models (LVLMs) have shown significant progress in well responding to visual-instructions from users. However, these instructions, encompassing images and text, are susceptible to both intentional and inadvertent attacks. Despite the critical importance of LVLMs' robustness against such threats, current research in this area remains limited. To bridge this gap, we introduce AVIBench, a framework designed to analyze the robustness of LVLMs when facing various adversarial visual-instructions (AVIs), including four types of image-based AVIs, ten types of text-based AVIs, and nine types of content bias AVIs (such as gender, violence, cultural, and racial biases, among others). We generate 260K AVIs encompassing five categories of multimodal capabilities (nine tasks) and content bias. We then conduct a comprehensive evaluation involving 14 open-source LVLMs to assess their performance. AVIBench also serves as a convenie
    
[^34]: SketchINR：将素描作为隐式神经表示的初探

    SketchINR: A First Look into Sketches as Implicit Neural Representations

    [https://arxiv.org/abs/2403.09344](https://arxiv.org/abs/2403.09344)

    SketchINR将矢量素描压缩到固定维度的潜在空间中，通过隐式神经模型编码素描的形状，并在多个任务上表现优异，包括数据压缩、高保真度的表示以及快速解码渲染。

    

    我们提出了SketchINR，旨在通过隐式神经模型推进矢量素描的表示。可变长度的矢量素描被压缩到固定维度的潜在空间中，隐式地将基础形状编码为时间和笔画的函数。学习的函数在每个时间和笔画上预测素描中的$ xy $点坐标。尽管简单，SketchINR在多个任务上优于现有表示：（i）将整个素描数据集编码为固定大小的潜在矢量时，SketchINR相比光栅和矢量素描，分别提供了$60\times$和$10\times$的数据压缩。 （ii）SketchINR的自动解码器提供比其他学习的矢量素描表示更高保真度的表示，并且能够独特地适应复杂的矢量素描，如FS-COCO。 （iii）SketchINR支持可以比其他学习的矢量表示解码/渲染快约约$\sim$$100\times$的并行化。

    arXiv:2403.09344v1 Announce Type: cross  Abstract: We propose SketchINR, to advance the representation of vector sketches with implicit neural models. A variable length vector sketch is compressed into a latent space of fixed dimension that implicitly encodes the underlying shape as a function of time and strokes. The learned function predicts the $xy$ point coordinates in a sketch at each time and stroke. Despite its simplicity, SketchINR outperforms existing representations at multiple tasks: (i) Encoding an entire sketch dataset into a fixed size latent vector, SketchINR gives $60\times$ and $10\times$ data compression over raster and vector sketches, respectively. (ii) SketchINR's auto-decoder provides a much higher-fidelity representation than other learned vector sketch representations, and is uniquely able to scale to complex vector sketches such as FS-COCO. (iii) SketchINR supports parallelisation that can decode/render $\sim$$100\times$ faster than other learned vector represe
    
[^35]: LocalMamba: 带窗口选择扫描的视觉状态空间模型

    LocalMamba: Visual State Space Model with Windowed Selective Scan

    [https://arxiv.org/abs/2403.09338](https://arxiv.org/abs/2403.09338)

    本论文提出了一种新颖的局部扫描策略，通过在图像中引入窗口划分的方法，有效捕捉局部依赖性，同时保持全局视角，从而增强了视觉Mamba模型的序列建模性能。

    

    最近状态空间模型的进展，尤其是Mamba，已经在长序列建模方面取得了显著进展，例如语言理解等任务。然而，它们在视觉任务中的应用并没有明显超越传统的卷积神经网络(CNN)和视觉Transformer(ViTs)的性能。本文认为增强视觉Mamba(ViM)的关键在于优化序列建模的扫描方向。传统的ViM方法将空间令牌展平，忽视了局部2D依赖性的保留，从而拉长了相邻令牌之间的距离。我们引入了一种新颖的局部扫描策略，将图像分割成不同窗口，有效地捕捉局部依赖性同时保持全局视角。此外，我们认识到不同网络层之间扫描模式的偏好可能不同，因此提出了一种动态方法，独立搜索最佳的扫描方向。

    arXiv:2403.09338v1 Announce Type: cross  Abstract: Recent advancements in state space models, notably Mamba, have demonstrated significant progress in modeling long sequences for tasks like language understanding. Yet, their application in vision tasks has not markedly surpassed the performance of traditional Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs). This paper posits that the key to enhancing Vision Mamba (ViM) lies in optimizing scan directions for sequence modeling. Traditional ViM approaches, which flatten spatial tokens, overlook the preservation of local 2D dependencies, thereby elongating the distance between adjacent tokens. We introduce a novel local scanning strategy that divides images into distinct windows, effectively capturing local dependencies while maintaining a global perspective. Additionally, acknowledging the varying preferences for scan patterns across different network layers, we propose a dynamic method to independently search for the 
    
[^36]: Griffon v2：通过高分辨率缩放和视觉-语言共指推进多模态感知

    Griffon v2: Advancing Multimodal Perception with High-Resolution Scaling and Visual-Language Co-Referring

    [https://arxiv.org/abs/2403.09333](https://arxiv.org/abs/2403.09333)

    Griffon v2通过引入高分辨率缩放和视觉-语言共指，提升了多模态感知能力，尤其是对于小对象的感知能力。

    

    大型视觉语言模型已经实现了细粒度对象感知，但图像分辨率的限制仍然是超越复杂和密集场景中特定任务专家表现的重要障碍。为了解决这一问题，我们引入了一个统一的高分辨率通用模型，Griffon v2，实现了具有视觉和文本提示的灵活对象引用。为了有效提高图像分辨率，我们设计了一个简单轻量级的下采样投影仪，以克服大型语言模型中输入标记的约束。这种设计固有地保留了完整的上下文和细节，并显著提高了多模态感知能力，特别是对于小对象。在此基础上，我们进一步为模型配置了视觉-语言共指。

    arXiv:2403.09333v1 Announce Type: cross  Abstract: Large Vision Language Models have achieved fine-grained object perception, but the limitation of image resolution remains a significant obstacle to surpass the performance of task-specific experts in complex and dense scenarios. Such limitation further restricts the model's potential to achieve nuanced visual and language referring in domains such as GUI Agents, Counting and \etc. To address this issue, we introduce a unified high-resolution generalist model, Griffon v2, enabling flexible object referring with visual and textual prompts. To efficiently scaling up image resolution, we design a simple and lightweight down-sampling projector to overcome the input tokens constraint in Large Language Models. This design inherently preserves the complete contexts and fine details, and significantly improves multimodal perception ability especially for small objects. Building upon this, we further equip the model with visual-language co-refer
    
[^37]: HeadEvolver：通过本地可学习网格变形实现文本到头部头像的转换

    HeadEvolver: Text to Head Avatars via Locally Learnable Mesh Deformation

    [https://arxiv.org/abs/2403.09326](https://arxiv.org/abs/2403.09326)

    通过可学习的局部网格变形技术，HeadEvolver框架可以通过文本引导生成高质量的头部头像，保留细节并支持编辑和动画。

    

    我们提出了HeadEvolver，一个新颖的框架，可以通过文本引导生成风格化的头部头像。HeadEvolver使用模板头部网格的本地可学习网格变形，生成高质量的数字资产，以实现保留细节的编辑和动画。为了解决全局变形中缺乏细粒度和语义感知本地形状控制的挑战，我们引入了可训练参数作为每个三角形的Jacobi矩阵的加权因子，以自适应地改变本地形状同时保持全局对应和面部特征。此外，为了确保来自不同视角的结果形状和外观的连贯性，我们使用预训练的图像扩散模型进行可微分渲染，并添加正则化项以在文本引导下优化变形。大量实验证明，我们的方法可以生成具有关节网格的多样化头部头像，可无缝编辑。

    arXiv:2403.09326v1 Announce Type: cross  Abstract: We present HeadEvolver, a novel framework to generate stylized head avatars from text guidance. HeadEvolver uses locally learnable mesh deformation from a template head mesh, producing high-quality digital assets for detail-preserving editing and animation. To tackle the challenges of lacking fine-grained and semantic-aware local shape control in global deformation through Jacobians, we introduce a trainable parameter as a weighting factor for the Jacobian at each triangle to adaptively change local shapes while maintaining global correspondences and facial features. Moreover, to ensure the coherence of the resulting shape and appearance from different viewpoints, we use pretrained image diffusion models for differentiable rendering with regularization terms to refine the deformation under text guidance. Extensive experiments demonstrate that our method can generate diverse head avatars with an articulated mesh that can be edited seaml
    
[^38]: SD-Net：对称感知关键点预测和领域自适应在抓取场景中的6D姿态估计

    SD-Net: Symmetric-Aware Keypoint Prediction and Domain Adaptation for 6D Pose Estimation In Bin-picking Scenarios

    [https://arxiv.org/abs/2403.09317](https://arxiv.org/abs/2403.09317)

    SD-Net通过对称感知关键点预测和自训练领域自适应，解决了对称物体和真实场景6D姿态估计中的关键问题。

    

    尽管在抓取场景中的6D姿态估计取得了成功，现有方法仍然难以为对称物体和真实场景产生准确的预测结果。主要瓶颈包括1）由物体对称引起的关键点歧义；2）真实数据和合成数据之间的域差距。为了规避这些问题，我们提出了一种新的具有对称感知关键点预测和自训练领域自适应（SD-Net）的6D姿态估计网络。SD-Net建立在点对点关键点回归和深度霍夫投票基础上，可以在杂乱和遮挡下可靠地检测关键点。具体来说，在关键点预测阶段，我们设计了一种强大的三维关键点选择策略，考虑了对象的对称类别和等效关键点，这有助于即使在高度遮挡的场景中定位3D关键点。此外，我们在预测关键点上构建了一个有效的滤波算法以动态地

    arXiv:2403.09317v1 Announce Type: cross  Abstract: Despite the success in 6D pose estimation in bin-picking scenarios, existing methods still struggle to produce accurate prediction results for symmetry objects and real world scenarios. The primary bottlenecks include 1) the ambiguity keypoints caused by object symmetries; 2) the domain gap between real and synthetic data. To circumvent these problem, we propose a new 6D pose estimation network with symmetric-aware keypoint prediction and self-training domain adaptation (SD-Net). SD-Net builds on pointwise keypoint regression and deep hough voting to perform reliable detection keypoint under clutter and occlusion. Specifically, at the keypoint prediction stage, we designe a robust 3D keypoints selection strategy considering the symmetry class of objects and equivalent keypoints, which facilitate locating 3D keypoints even in highly occluded scenes. Additionally, we build an effective filtering algorithm on predicted keypoint to dynamic
    
[^39]: YOLOX-ViT中的知识蒸馏在侧扫声纳目标检测中的应用

    Knowledge Distillation in YOLOX-ViT for Side-Scan Sonar Object Detection

    [https://arxiv.org/abs/2403.09313](https://arxiv.org/abs/2403.09313)

    YOLOX-ViT中的知识蒸馏有效减少了侧扫声纳目标检测中墙体误报，并引入的视觉变换器层显著提高了水下环境中的目标检测准确性。

    

    在本文中，我们提出了YOLOX-ViT，一种新颖的目标检测模型，并研究了知识蒸馏在模型尺寸减小但不损失性能方面的有效性。我们的研究聚焦于水下机器人，探讨了关于更小模型的可行性以及YOLOX中视觉变换器层的影响。此外，我们引入了一个新的侧扫声纳图像数据集，并用它来评估我们的目标检测器的性能。结果显示，知识蒸馏有效减少了墙体检测中的误报。此外，引入的视觉变换器层显著提高了水下环境中的目标检测准确性。知识蒸馏在YOLOX-ViT中的源代码在https://github.com/remaro-network/KD-YOLOX-ViT。

    arXiv:2403.09313v1 Announce Type: cross  Abstract: In this paper we present YOLOX-ViT, a novel object detection model, and investigate the efficacy of knowledge distillation for model size reduction without sacrificing performance. Focused on underwater robotics, our research addresses key questions about the viability of smaller models and the impact of the visual transformer layer in YOLOX. Furthermore, we introduce a new side-scan sonar image dataset, and use it to evaluate our object detector's performance. Results show that knowledge distillation effectively reduces false positives in wall detection. Additionally, the introduced visual transformer layer significantly improves object detection accuracy in the underwater environment. The source code of the knowledge distillation in the YOLOX-ViT is at https://github.com/remaro-network/KD-YOLOX-ViT.
    
[^40]: SELECTOR：具有卷积掩码自编码器的异构图网络，用于癌症生存鲁棒预测

    SELECTOR: Heterogeneous graph network with convolutional masked autoencoder for multimodal robust prediction of cancer survival

    [https://arxiv.org/abs/2403.09290](https://arxiv.org/abs/2403.09290)

    该论文介绍了一种名为SELECTOR的异构图网络，利用卷积掩码自编码器进行癌症患者生存的鲁棒多模态预测

    

    准确预测癌症患者的生存率对于帮助临床医生制定适当的治疗方案，降低与癌症相关的医疗费用，并显著提高患者的生活质量至关重要。癌症患者生存的多模预测提供了一种更全面、更精确的方法。然而，现有方法仍然面临着与缺失的多模态数据和模态内信息交互相关的挑战。本文介绍了SELECTOR，一种基于卷积掩码编码器的异构图感知网络，用于癌症患者生存的鲁棒多模态预测。SELECTOR包括特征边重构、卷积掩码编码器、特征交叉融合和多模态生存预测模块。首先，我们构建一个多模态异构图，并采用元路径方法进行特征边重构，确保特征信息的全面整合。

    arXiv:2403.09290v1 Announce Type: cross  Abstract: Accurately predicting the survival rate of cancer patients is crucial for aiding clinicians in planning appropriate treatment, reducing cancer-related medical expenses, and significantly enhancing patients' quality of life. Multimodal prediction of cancer patient survival offers a more comprehensive and precise approach. However, existing methods still grapple with challenges related to missing multimodal data and information interaction within modalities. This paper introduces SELECTOR, a heterogeneous graph-aware network based on convolutional mask encoders for robust multimodal prediction of cancer patient survival. SELECTOR comprises feature edge reconstruction, convolutional mask encoder, feature cross-fusion, and multimodal survival prediction modules. Initially, we construct a multimodal heterogeneous graph and employ the meta-path method for feature edge reconstruction, ensuring comprehensive incorporation of feature informatio
    
[^41]: 硅中心理念理论

    Silico-centric Theory of Mind

    [https://arxiv.org/abs/2403.09289](https://arxiv.org/abs/2403.09289)

    本研究探讨在拥有多个独立AI代理的环境中的精神理论（ToM），并发现当代AI展现出接近完美的性能。

    

    精神理论（ToM）指的是将信念、欲望、意图和知识等精神状态归因于自己和他人的能力，并理解这些精神状态可能不同于自己和现实。我们研究了在拥有多个、不同、独立AI代理的环境中的ToM，每个代理都具有独特的内部状态、信息和目标。受人类错误信念实验启发，我们提出了一个具有情境的AI（“焦点AI”），其中其克隆体经历了以人类为中心的ToM评估。我们促使焦点AI评估其克隆体是否会从额外的指导中受益。同时，我们让克隆体进行ToM评估，有和没有指导，从而使焦点AI参与类似于人类心智化的高阶反事实推理--针对一项测试中的人类和另一项测试中的其他AI。我们发现了一个不一致：当代AI表现出接近完美

    arXiv:2403.09289v1 Announce Type: new  Abstract: Theory of Mind (ToM) refers to the ability to attribute mental states, such as beliefs, desires, intentions, and knowledge, to oneself and others, and to understand that these mental states can differ from one's own and from reality. We investigate ToM in environments with multiple, distinct, independent AI agents, each possessing unique internal states, information, and objectives. Inspired by human false-belief experiments, we present an AI ('focal AI') with a scenario where its clone undergoes a human-centric ToM assessment. We prompt the focal AI to assess whether its clone would benefit from additional instructions. Concurrently, we give its clones the ToM assessment, both with and without the instructions, thereby engaging the focal AI in higher-order counterfactual reasoning akin to human mentalizing--with respect to humans in one test and to other AI in another. We uncover a discrepancy: Contemporary AI demonstrates near-perfect 
    
[^42]: 具有OCR模态扰动的对抗训练用于场景文本视觉问答

    Adversarial Training with OCR Modality Perturbation for Scene-Text Visual Question Answering

    [https://arxiv.org/abs/2403.09288](https://arxiv.org/abs/2403.09288)

    该论文提出了一种具有空间感知能力的多模态对抗训练架构，通过Adversarial OCR Enhancement（AOE）模块和空间感知自注意力（SASA）机制，可以增强OCR文本的容错性，并帮助模型更好地捕捉OCR标记之间的空间关系。

    

    Scene-Text Visual Question Answering（ST-VQA）旨在理解图像中的场景文本并回答与文本内容相关的问题。本文提出了一种具有空间感知能力的多模态对抗训练架构。具体来说，我们引入了一个Adversarial OCR Enhancement（AOE）模块，在OCR模态的嵌入空间中利用对抗训练来增强OCR文本的容错表示，从而减少OCR错误引起的噪音。同时，我们添加了一个空间感知自注意力（SASA）机制，帮助模型更好地捕捉OCR标记之间的空间关系。各种实验表明，我们的方法取得了显著的成果。

    arXiv:2403.09288v1 Announce Type: cross  Abstract: Scene-Text Visual Question Answering (ST-VQA) aims to understand scene text in images and answer questions related to the text content. Most existing methods heavily rely on the accuracy of Optical Character Recognition (OCR) systems, and aggressive fine-tuning based on limited spatial location information and erroneous OCR text information often leads to inevitable overfitting. In this paper, we propose a multimodal adversarial training architecture with spatial awareness capabilities. Specifically, we introduce an Adversarial OCR Enhancement (AOE) module, which leverages adversarial training in the embedding space of OCR modality to enhance fault-tolerant representation of OCR texts, thereby reducing noise caused by OCR errors. Simultaneously, We add a Spatial-Aware Self-Attention (SASA) mechanism to help the model better capture the spatial relationships among OCR tokens. Various experiments demonstrate that our method achieves sign
    
[^43]: 在动态解决柔性作业车间调度问题中利用约束编程的深度学习方法

    Leveraging Constraint Programming in a Deep Learning Approach for Dynamically Solving the Flexible Job-Shop Scheduling Problem

    [https://arxiv.org/abs/2403.09249](https://arxiv.org/abs/2403.09249)

    该研究将约束编程与深度学习相结合，通过使用约束编程生成的最优解来训练深度学习模型，从而消除了深度强化学习中广泛探索的需要，提高了整体性能。

    

    最近柔性作业车间调度问题（FJSSP）方面的进展主要基于深度强化学习（DRL），因其能够生成高质量、实时解决方案。然而，DRL方法常常未能充分利用现有技术的优势，如确切方法或约束编程（CP），后者能够在较小实例中找到最优或接近最优解。本文旨在将约束编程集成到以深度学习（DL）为基础的方法中，充分利用两者的优势。

    arXiv:2403.09249v1 Announce Type: new  Abstract: Recent advancements in the flexible job-shop scheduling problem (FJSSP) are primarily based on deep reinforcement learning (DRL) due to its ability to generate high-quality, real-time solutions. However, DRL approaches often fail to fully harness the strengths of existing techniques such as exact methods or constraint programming (CP), which can excel at finding optimal or near-optimal solutions for smaller instances. This paper aims to integrate CP within a deep learning (DL) based methodology, leveraging the benefits of both. In this paper, we introduce a method that involves training a DL model using optimal solutions generated by CP, ensuring the model learns from high-quality data, thereby eliminating the need for the extensive exploration typical in DRL and enhancing overall performance. Further, we integrate CP into our DL framework to jointly construct solutions, utilizing DL for the initial complex stages and transitioning to CP
    
[^44]: 生成业务流程结果预测的可行和可信的反事实解释

    Generating Feasible and Plausible Counterfactual Explanations for Outcome Prediction of Business Processes

    [https://arxiv.org/abs/2403.09232](https://arxiv.org/abs/2403.09232)

    该论文提出了一种数据驱动方法 REVISEDplus，旨在生成更可行和可信的反事实解释，解决了处理序列性质业务流程案例时遇到的挑战。

    

    近年来，各种机器学习和深度学习架构成功地引入了预测性流程分析领域。然而，这些算法固有的不透明性给人类决策者带来了重大挑战，阻碍了他们理解预测背后的推理过程。这一日益关注的问题引发了反事实解释的引入，设计为人类可理解的假设场景，以提供更清晰的决策背后的见解。然而，生成反事实解释在处理通常用于预测性流程分析的序列性质（业务）流程案例时遇到特定挑战。我们的论文通过引入一种数据驱动方法 REVISEDplus 来应对这一挑战，生成更可行和可信的反事实解释。

    arXiv:2403.09232v1 Announce Type: new  Abstract: In recent years, various machine and deep learning architectures have been successfully introduced to the field of predictive process analytics. Nevertheless, the inherent opacity of these algorithms poses a significant challenge for human decision-makers, hindering their ability to understand the reasoning behind the predictions. This growing concern has sparked the introduction of counterfactual explanations, designed as human-understandable what if scenarios, to provide clearer insights into the decision-making process behind undesirable predictions. The generation of counterfactual explanations, however, encounters specific challenges when dealing with the sequential nature of the (business) process cases typically used in predictive process analytics. Our paper tackles this challenge by introducing a data-driven approach, REVISEDplus, to generate more feasible and plausible counterfactual explanations. First, we restrict the counter
    
[^45]: BEHAVIOR-1K：一个以人为中心，具有1,000个日常活动和逼真模拟的AI基准测试

    BEHAVIOR-1K: A Human-Centered, Embodied AI Benchmark with 1,000 Everyday Activities and Realistic Simulation

    [https://arxiv.org/abs/2403.09227](https://arxiv.org/abs/2403.09227)

    BEHAVIOR-1K是一个以人为中心的机器人技术综合仿真基准测试，包含1,000个日常活动和用于支持这些活动的逼真模拟环境。这些活动具有长视野，复杂操作技能依赖，对于当前最先进的机器人学习解决方案仍然具有挑战性。

    

    我们介绍了BEHAVIOR-1K，这是一个为以人为中心的机器人技术而设计的综合仿真基准测试。BEHAVIOR-1K包括两个组成部分，受到广泛调查结果的指导和启发，调查问题为“你希望机器人为你做什么？”。第一个部分定义了1,000个日常活动，基于50个场景（房屋，花园，餐厅，办公室等），超过9,000个对象带有丰富的物理和语义属性的标注。第二个部分是OMNIGIBSON，这是一个支持这些活动的新颖仿真环境，通过对刚体、可变形体和液体的逼真物理模拟和渲染来实现。我们的实验表明，BEHAVIOR-1K中的活动具有长视野，并依赖于复杂的操作技能，即使是最先进的机器人学习解决方案也面临挑战。为了校准BEHAVIOR-1K的仿真与现实之间的差距，我们提供了一个关于转移方案学习的初步研究。

    arXiv:2403.09227v1 Announce Type: cross  Abstract: We present BEHAVIOR-1K, a comprehensive simulation benchmark for human-centered robotics. BEHAVIOR-1K includes two components, guided and motivated by the results of an extensive survey on "what do you want robots to do for you?". The first is the definition of 1,000 everyday activities, grounded in 50 scenes (houses, gardens, restaurants, offices, etc.) with more than 9,000 objects annotated with rich physical and semantic properties. The second is OMNIGIBSON, a novel simulation environment that supports these activities via realistic physics simulation and rendering of rigid bodies, deformable bodies, and liquids. Our experiments indicate that the activities in BEHAVIOR-1K are long-horizon and dependent on complex manipulation skills, both of which remain a challenge for even state-of-the-art robot learning solutions. To calibrate the simulation-to-reality gap of BEHAVIOR-1K, we provide an initial study on transferring solutions lear
    
[^46]: Laplace逼近作为高斯过程模型选择准则的研究

    On the Laplace Approximation as Model Selection Criterion for Gaussian Processes

    [https://arxiv.org/abs/2403.09215](https://arxiv.org/abs/2403.09215)

    通过引入基于Laplace逼近的多种度量标准，本研究解决了高斯过程模型选择中遇到的性能不佳和运行时间问题，实验结果表明这些新的标准在质量上与黄金标准动态嵌套抽样相当，同时保持了计算速度。

    

    模型选择旨在找到在准确性、可解释性或简易性方面最佳的模型，最好是三者兼顾。本研究着重于评估高斯过程模型的模型性能，即找到一个提供所有这些准则之间最佳权衡的度量标准。我们引入了基于Laplace逼近的多种度量标准来应对以往工作中存在的性能不佳或具有严重运行时间问题的情况，从而极大地限制了适用性。实验表明，我们的度量标准在质量上与黄金标准动态嵌套抽样相当，而又不会影响计算速度。我们的模型选择标准使得高斯过程模型的模型选择能够更快速地且生成质量更高的结果。

    arXiv:2403.09215v1 Announce Type: cross  Abstract: Model selection aims to find the best model in terms of accuracy, interpretability or simplicity, preferably all at once. In this work, we focus on evaluating model performance of Gaussian process models, i.e. finding a metric that provides the best trade-off between all those criteria. While previous work considers metrics like the likelihood, AIC or dynamic nested sampling, they either lack performance or have significant runtime issues, which severely limits applicability. We address these challenges by introducing multiple metrics based on the Laplace approximation, where we overcome a severe inconsistency occuring during naive application of the Laplace approximation. Experiments show that our metrics are comparable in quality to the gold standard dynamic nested sampling without compromising for computational speed. Our model selection criteria allow significantly faster and high quality model selection of Gaussian process models.
    
[^47]: 学习自适应邻居以实时检测内部威胁

    LAN: Learning Adaptive Neighbors for Real-Time Insider Threat Detection

    [https://arxiv.org/abs/2403.09209](https://arxiv.org/abs/2403.09209)

    该论文的贡献是提出了一个名为LAN的框架，能够实时在活动级别进行内部威胁检测，并学习活动序列内的时间依赖关系和活动之间的关系。

    

    企业和组织面临来自内部员工可能导致严重后果的潜在威胁。先前关于内部威胁检测（ITD）的研究主要集中在检测异常用户或异常时间段（例如，一周或一天）。然而，用户可能在日志中有数十万条活动，即使在一天内，一个用户也可能存在数千条活动，这需要高昂的调查预算来验证异常用户或活动。另一方面，现有作品主要是事后方法而不是实时检测，无法及时报告内部威胁在引起损失之前。在本文中，我们进行了针对活动级别实时ITD的第一项研究，并提出了一个细粒度和高效的框架LAN。具体而言，LAN同时学习活动序列内的时间依赖关系和活动之间的关系。

    arXiv:2403.09209v1 Announce Type: cross  Abstract: Enterprises and organizations are faced with potential threats from insider employees that may lead to serious consequences. Previous studies on insider threat detection (ITD) mainly focus on detecting abnormal users or abnormal time periods (e.g., a week or a day). However, a user may have hundreds of thousands of activities in the log, and even within a day there may exist thousands of activities for a user, requiring a high investigation budget to verify abnormal users or activities given the detection results. On the other hand, existing works are mainly post-hoc methods rather than real-time detection, which can not report insider threats in time before they cause loss. In this paper, we conduct the first study towards real-time ITD at activity level, and present a fine-grained and efficient framework LAN. Specifically, LAN simultaneously learns the temporal dependencies within an activity sequence and the relationships between ac
    
[^48]: 贝叶斯概化错误在部分概念瓶颈模型中的上界：部分CBM胜过朴素CBM

    Upper Bound of Bayesian Generalization Error in Partial Concept Bottleneck Model (CBM): Partial CBM outperforms naive CBM

    [https://arxiv.org/abs/2403.09206](https://arxiv.org/abs/2403.09206)

    本文在三层线性结构的部分CBM中揭示了贝叶斯概化错误的上界，进一步证明部分CBM优于朴素CBM。

    

    arXiv：2403.09206v1 类型通告：交叉摘要：概念瓶颈模型（CBM）是解释神经网络的方法。在CBM中，对应于输出原因的概念被插入到最后一个中间层作为观察值。人们预期我们可以解释输出和概念之间的关系，类似于线性回归。然而，这种解释需要观察所有概念，并且降低了神经网络的泛化性能。部分CBM（PCBM）使用部分观察到的概念，旨在解决这些困难。尽管一些数值实验表明PCBM的泛化性能几乎与原始神经网络一样高，但由于PCBM是奇异的统计模型，其泛化错误的理论行为尚未明确。在本文中，我们揭示了具有三层线性架构的PCBM中的贝叶斯泛化错误。

    arXiv:2403.09206v1 Announce Type: cross  Abstract: Concept Bottleneck Model (CBM) is a methods for explaining neural networks. In CBM, concepts which correspond to reasons of outputs are inserted in the last intermediate layer as observed values. It is expected that we can interpret the relationship between the output and concept similar to linear regression. However, this interpretation requires observing all concepts and decreases the generalization performance of neural networks. Partial CBM (PCBM), which uses partially observed concepts, has been devised to resolve these difficulties. Although some numerical experiments suggest that the generalization performance of PCBMs is almost as high as that of the original neural networks, the theoretical behavior of its generalization error has not been yet clarified since PCBM is singular statistical model. In this paper, we reveal the Bayesian generalization error in PCBM with a three-layered and linear architecture. The result indcates t
    
[^49]: 通过提示学习定制化分割基础模型进行实例分割

    Customizing Segmentation Foundation Model via Prompt Learning for Instance Segmentation

    [https://arxiv.org/abs/2403.09199](https://arxiv.org/abs/2403.09199)

    提出了一种针对Segment Anything Model (SAM)的新颖方法，通过提示学习定制化实例分割，解决了在应用于定制化实例分割时面临的输入提示模糊性和额外训练需求的挑战

    

    最近，通过大规模数据集训练的基础模型吸引了相当多的关注，并在计算机视觉领域得到积极探讨。在这些模型中，Segment Anything Model (SAM)因其在图像分割任务中的泛化能力和灵活性而脱颖而出，通过基于提示的对象掩模生成取得了显著进展。然而，尽管SAM具有这些优势，在应用于定制化实例分割时（对特定对象或在训练数据中通常不存在的独特环境中进行分割），SAM面临两个关键限制：1）输入提示中固有的模糊性，2）为实现最佳分割需要大量额外训练。为解决这些挑战，我们提出了一种新颖的方法，即通过提示学习定制化实例分割，针对SAM进行了定制。我们的方法包含一个提示学习模块（PLM），可以调整输入。

    arXiv:2403.09199v1 Announce Type: cross  Abstract: Recently, foundation models trained on massive datasets to adapt to a wide range of domains have attracted considerable attention and are actively being explored within the computer vision community. Among these, the Segment Anything Model (SAM) stands out for its remarkable progress in generalizability and flexibility for image segmentation tasks, achieved through prompt-based object mask generation. However, despite its strength, SAM faces two key limitations when applied to customized instance segmentation that segments specific objects or those in unique environments not typically present in the training data: 1) the ambiguity inherent in input prompts and 2) the necessity for extensive additional training to achieve optimal segmentation. To address these challenges, we propose a novel method, customized instance segmentation via prompt learning tailored to SAM. Our method involves a prompt learning module (PLM), which adjusts inpu
    
[^50]: 视觉语言模型是纹理偏见还是形状偏见，我们可以引导它们吗？

    Are Vision Language Models Texture or Shape Biased and Can We Steer Them?

    [https://arxiv.org/abs/2403.09193](https://arxiv.org/abs/2403.09193)

    本文研究了广泛应用的视觉语言模型中的纹理与形状偏见，发现这些模型通常比视觉编码器更偏向形状，暗示视觉偏见在一定程度上会受到文本的调节

    

    arXiv:2403.09193v1 公告类型: 跨领域 摘要: 视觉语言模型（VLMs）在短短几年内彻底改变了计算机视觉模型的格局，开启了一系列新的应用，从零样本图像分类到图像字幕生成，再到视觉问答。与纯视觉模型不同，它们提供了通过语言提示访问视觉内容的直观方式。这种模型的广泛适用性引发我们思考它们是否也与人类视觉一致 - 具体来说，它们在多模态融合中有多大程度地采用了人类引导的视觉偏见，或者它们是否只是从纯视觉模型中继承了偏见。其中一个重要的视觉偏见是纹理与形状偏见，即局部信息的主导地位。在本文中，我们研究了一系列流行的VLMs中的这种偏见。有趣的是，我们发现VLMs通常比它们的视觉编码器更偏向于形状，这表明视觉偏见在一定程度上通过文本进行调节。

    arXiv:2403.09193v1 Announce Type: cross  Abstract: Vision language models (VLMs) have drastically changed the computer vision model landscape in only a few years, opening an exciting array of new applications from zero-shot image classification, over to image captioning, and visual question answering. Unlike pure vision models, they offer an intuitive way to access visual content through language prompting. The wide applicability of such models encourages us to ask whether they also align with human vision - specifically, how far they adopt human-induced visual biases through multimodal fusion, or whether they simply inherit biases from pure vision models. One important visual bias is the texture vs. shape bias, or the dominance of local over global information. In this paper, we study this bias in a wide range of popular VLMs. Interestingly, we find that VLMs are often more shape-biased than their vision encoders, indicating that visual biases are modulated to some extent through text
    
[^51]: 轨迹预测中的意图感知去噪扩散模型

    Intention-aware Denoising Diffusion Model for Trajectory Prediction

    [https://arxiv.org/abs/2403.09190](https://arxiv.org/abs/2403.09190)

    该论文提出了一种解决传统轨迹预测模型受限和训练不稳定问题的新方法，即利用意图感知去噪扩散模型（IDM）生成未来轨迹的分布。

    

    轨迹预测是自动驾驶中的一个关键组件，尤其对于碰撞回避系统。考虑到任务的固有不确定性，许多研究利用生成模型为每个参与者产生多个可能的未来轨迹。然而，大多数模型存在表示能力受限或训练不稳定的问题。为了克服这些限制，我们提出利用扩散模型生成未来轨迹的分布。实现这一想法需解决两个关键问题。首先，意图的多样性与不确定环境相互交织，使得真实分布难以参数化。其次，扩散过程在推断阶段耗时，使得在实时驾驶系统中实现不切实际。我们提出了一种意图感知去噪扩散模型（IDM）来解决上述两个问题。

    arXiv:2403.09190v1 Announce Type: cross  Abstract: Trajectory prediction is an essential component in autonomous driving, particularly for collision avoidance systems. Considering the inherent uncertainty of the task, numerous studies have utilized generative models to produce multiple plausible future trajectories for each agent. However, most of them suffer from restricted representation ability or unstable training issues. To overcome these limitations, we propose utilizing the diffusion model to generate the distribution of future trajectories. Two cruxes are to be settled to realize such an idea. First, the diversity of intention is intertwined with the uncertain surroundings, making the true distribution hard to parameterize. Second, the diffusion process is time-consuming during the inference phase, rendering it unrealistic to implement in a real-time driving system. We propose an Intention-aware denoising Diffusion Model (IDM), which tackles the above two problems. We decouple 
    
[^52]: 学习算法用于验证马尔可夫决策过程

    Learning Algorithms for Verification of Markov Decision Processes

    [https://arxiv.org/abs/2403.09184](https://arxiv.org/abs/2403.09184)

    该研究提出了一个通用框架，将学习算法和启发式引导应用于马尔可夫决策过程（MDP）的验证，旨在提高性能，避免对状态空间进行穷尽探索。

    

    我们提出了一个通用框架，将学习算法和启发式引导应用于马尔可夫决策过程（MDP）的验证，基于Br\'azdil, T.等人（2014）的想法。该框架的主要目标是通过避免对状态空间进行穷尽探索来提高性能，而是依靠启发式。本研究在很大程度上扩展了这种方法。对基础理论的几个细节进行了改进和错误修正。第1.3节提供了所有差异的概述。该框架专注于概率可达性，这是验证中的一个核心问题，并具体化为两种不同的场景。第一个假设完全了解MDP，尤其是精确的转移概率。它执行基于启发式的模型部分探索，产生精准的结果。

    arXiv:2403.09184v1 Announce Type: cross  Abstract: We present a general framework for applying learning algorithms and heuristical guidance to the verification of Markov decision processes (MDPs), based on the ideas of Br\'azdil, T. et al. (2014). Verification of Markov Decision Processes Using Learning Algorithms. The primary goal of the techniques presented in that work is to improve performance by avoiding an exhaustive exploration of the state space, guided by heuristics. This approach is significantly extended in this work. Several details of the base theory are refined and errors are fixed. Section 1.3 provides an overview of all differences.   The presented framework focuses on probabilistic reachability, which is a core problem in verification, and is instantiated in two distinct scenarios. The first assumes that full knowledge of the MDP is available, in particular precise transition probabilities. It performs a heuristic-driven partial exploration of the model, yielding preci
    
[^53]: ADEdgeDrop：用于强健图神经网络的敌对边缘删除

    ADEdgeDrop: Adversarial Edge Dropping for Robust Graph Neural Networks

    [https://arxiv.org/abs/2403.09171](https://arxiv.org/abs/2403.09171)

    ADEdgeDrop提出了一种敌对边缘删除方法，通过引入敌对边缘预测器指导边缘删除，从而提高了图神经网络的稳健性。

    

    尽管图神经网络（GNNs）通过各种消息传递机制展示了从邻近节点收集图结构信息的强大能力，但由于嘈杂和冗余的图数据造成的差的泛化和脆弱的稳健性限制了GNNs的性能。在Graph Augmentation Learning（GAL）中，边缘删除方法是一种有效的技术，可以提高GNNs的稳健性。然而，随机删除边缘通常会绕过关键边缘，从而削弱消息传递的效果。本文提出了一种新颖的敌对边缘删除方法（ADEdgeDrop），利用敌对边缘预测器引导边缘删除，可以灵活地整合到不同的GNN主干中。

    arXiv:2403.09171v1 Announce Type: cross  Abstract: Although Graph Neural Networks (GNNs) have exhibited the powerful ability to gather graph-structured information from neighborhood nodes via various message-passing mechanisms, the performance of GNNs is limited by poor generalization and fragile robustness caused by noisy and redundant graph data. As a prominent solution, Graph Augmentation Learning (GAL) has recently received increasing attention. Among prior GAL approaches, edge-dropping methods that randomly remove edges from a graph during training are effective techniques to improve the robustness of GNNs. However, randomly dropping edges often results in bypassing critical edges, consequently weakening the effectiveness of message passing. In this paper, we propose a novel adversarial edge-dropping method (ADEdgeDrop) that leverages an adversarial edge predictor guiding the removal of edges, which can be flexibly incorporated into diverse GNN backbones. Employing an adversarial 
    
[^54]: USimAgent：用于模拟搜索用户的大型语言模型

    USimAgent: Large Language Models for Simulating Search Users

    [https://arxiv.org/abs/2403.09142](https://arxiv.org/abs/2403.09142)

    该论文介绍了一种基于大型语言模型的用户搜索行为模拟器 USimAgent，可以模拟用户在搜索过程中的查询、点击和停止行为，实现生成特定搜索的完整搜索会话。

    

    由于成本效益和可重现性方面的优势，用户模拟已成为信息检索系统用户为中心评估的有前途的解决方案。然而，准确模拟用户搜索行为一直是一项挑战，因为用户在搜索中的行为非常复杂，受到学习、推理和规划等错综复杂认知过程的驱动。最近，大型语言模型（LLMs）已经展示出在模拟人类级智能方面的潜力，并已被用于构建各种任务的自主代理。然而，尚未充分探索使用LLM模拟搜索行为的潜力。在本文中，我们介绍了一种基于LLM的用户搜索行为模拟器，即USimAgent。提出的模拟器可以模拟用户在搜索过程中的查询、点击和停止行为，因此能够生成特定搜索的完整搜索会话。

    arXiv:2403.09142v1 Announce Type: cross  Abstract: Due to the advantages in the cost-efficiency and reproducibility, user simulation has become a promising solution to the user-centric evaluation of information retrieval systems. Nonetheless, accurately simulating user search behaviors has long been a challenge, because users' actions in search are highly complex and driven by intricate cognitive processes such as learning, reasoning, and planning. Recently, Large Language Models (LLMs) have demonstrated remarked potential in simulating human-level intelligence and have been used in building autonomous agents for various tasks. However, the potential of using LLMs in simulating search behaviors has not yet been fully explored. In this paper, we introduce a LLM-based user search behavior simulator, USimAgent. The proposed simulator can simulate users' querying, clicking, and stopping behaviors during search, and thus, is capable of generating complete search sessions for specific search
    
[^55]: 在支持AI的边缘设备中的多智能体分布式学习中的不确定性估计

    Uncertainty Estimation in Multi-Agent Distributed Learning for AI-Enabled Edge Devices

    [https://arxiv.org/abs/2403.09141](https://arxiv.org/abs/2403.09141)

    研究探索了在支持AI的边缘设备中实现分布式数据处理的方法，重点解决了在独立代理遇到的数据集的空间和时间变异性中确定学习结果的置信水平挑战。

    

    最初被认为是具有有限自主处理能力的低功率单元，边缘物联网设备随着FPGA和AI加速器的引入而发生了范式转变。这一进步极大地增强了它们的计算能力，突显了边缘AI的实用性。这种进步引入了新挑战，即如何针对边缘计算环境中能源和网络资源的限制优化AI任务。我们的研究探讨了通过支持AI的边缘设备实现分布式数据处理的方法，增强了协作学习能力。我们研究的重点之一是解决确定学习结果的置信水平的挑战，考虑独立代理遇到的数据集的空间和时间变异性。为了解决这个问题，我们研究了贝叶斯神经网络的应用，提出了一种在分布式学习环境中管理不确定性的新方法。

    arXiv:2403.09141v1 Announce Type: cross  Abstract: Initially considered as low-power units with limited autonomous processing, Edge IoT devices have seen a paradigm shift with the introduction of FPGAs and AI accelerators. This advancement has vastly amplified their computational capabilities, emphasizing the practicality of edge AI. Such progress introduces new challenges of optimizing AI tasks for the limitations of energy and network resources typical in Edge computing environments. Our study explores methods that enable distributed data processing through AI-enabled edge devices, enhancing collaborative learning capabilities. A key focus of our research is the challenge of determining confidence levels in learning outcomes, considering the spatial and temporal variability of data sets encountered by independent agents. To address this issue, we investigate the application of Bayesian neural networks, proposing a novel approach to manage uncertainty in distributed learning environme
    
[^56]: ProSwitch：知识引导的语言模型微调，生成专业和非专业风格的文本

    ProSwitch: Knowledge-Guided Language Model Fine-Tuning to Generate Professional and Non-Professional Styled Text

    [https://arxiv.org/abs/2403.09131](https://arxiv.org/abs/2403.09131)

    ProSwitch通过知识引导的指令微调，在专业和非专业风格之间生成文本，并在专业性评估和质量评估方面表现出优越性。

    

    大语言模型（LLMs）在各种语言应用中表现出有效性，包括文本摘要和可控文本生成。然而，关于它们通过微调在不同风格间切换的能力的研究仍未被充分探讨。本研究聚焦于文本专业性，并引入了一种新颖的方法，名为ProSwitch，通过知识引导的指令微调，使语言模型具备生成专业和非专业回复的能力。ProSwitch分为三个阶段：数据准备，用于收集领域知识和训练语料库；指令微调，用于优化带有多种指令格式的语言模型；全面评估，用于评估生成文本的专业性区分能力和基于参考的质量。 ProSwitch相对于通用和专门语言模型的比较分析显示了我们的方法的优越性。

    arXiv:2403.09131v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated efficacy in various linguistic applications, including text summarization and controlled text generation. However, studies into their capacity of switching between styles via fine-tuning remain underexplored. This study concentrates on textual professionalism and introduces a novel methodology, named ProSwitch, which equips a language model with the ability to produce both professional and non-professional responses through knowledge-guided instruction tuning. ProSwitch unfolds across three phases: data preparation for gathering domain knowledge and training corpus; instruction tuning for optimizing language models with multiple levels of instruction formats; and comprehensive evaluation for assessing the professionalism discrimination and reference-based quality of generated text. Comparative analysis of ProSwitch against both general and specialized language models reveals that our appro
    
[^57]: AutoLoRA：基于元学习的自动调整矩阵秩在低秩适应中的应用

    AutoLoRA: Automatically Tuning Matrix Ranks in Low-Rank Adaptation Based on Meta Learning

    [https://arxiv.org/abs/2403.09113](https://arxiv.org/abs/2403.09113)

    AutoLoRA提出了一个基于元学习的框架，自动识别每个LoRA层的最佳秩，以解决LoRA中秩分配和秩搜索的问题，进而提高微调性能。

    

    大规模预训练之后进行任务特定微调在各种自然语言处理任务中取得了巨大成功。然而，对于大型预训练模型的所有参数进行微调存在着巨大的计算和内存挑战，因此研发了几种高效的微调方法。其中，低秩适应（LoRA）通过在冻结的预训练权重之上微调低秩增量更新矩阵，被证明特别有效。然而，LoRA在所有层中均匀分配秩，并且依赖于穷举搜索来找到最佳秩，导致了高计算成本和微调性能不佳。为了解决这些限制，我们引入了AutoLoRA，这是一个基于元学习的框架，用于自动识别每个LoRA层的最佳秩。AutoLoRA将低秩更新矩阵中的每个秩为1的矩阵与选择变量相关联，该变量决定了秩为1的矩阵是否应该被...

    arXiv:2403.09113v1 Announce Type: cross  Abstract: Large-scale pretraining followed by task-specific finetuning has achieved great success in various NLP tasks. Since finetuning all parameters of large pretrained models poses substantial computational and memory challenges, several efficient finetuning methods have been developed. Among them, low-rank adaptation (LoRA), which finetunes low-rank incremental update matrices on top of frozen pretrained weights, has proven particularly effective. Nonetheless, LoRA's uniform rank assignment across all layers, along with its reliance on an exhaustive search to find the best rank, leads to high computation costs and suboptimal finetuning performance. To address these limitations, we introduce AutoLoRA, a meta learning based framework for automatically identifying the optimal rank of each LoRA layer. AutoLoRA associates each rank-1 matrix in a low-rank update matrix with a selection variable, which determines whether the rank-1 matrix should b
    
[^58]: MCFEND：用于中文假新闻检测的多源基准数据集

    MCFEND: A Multi-source Benchmark Dataset for Chinese Fake News Detection

    [https://arxiv.org/abs/2403.09092](https://arxiv.org/abs/2403.09092)

    MCFEND是第一个用于中文假新闻检测的多源基准数据集，解决了单一来源数据集应用于多源新闻数据时性能下降的问题。

    

    虚假新闻在各个在线来源的普遍传播对公众产生了重要影响。现有的中文假新闻检测数据集仅限于来自微博的新闻。然而，来自多个来源的虚假新闻在内容和社会背景等各个方面表现出多样性。仅在单一新闻来源上训练的方法几乎无法适用于现实场景。我们的初步实验表明，学习自一个大型中文假新闻检测数据集Weibo-21的最先进方法的F1分数，当测试数据改变为多源新闻数据时，从0.943急剧下降到0.470，未能识别超过三分之一的多源虚假新闻。为解决这一限制，我们构建了用于中文假新闻检测的第一个多源基准数据集MCFEND，由我们从各种来源收集的新闻组成。

    arXiv:2403.09092v1 Announce Type: cross  Abstract: The prevalence of fake news across various online sources has had a significant influence on the public. Existing Chinese fake news detection datasets are limited to news sourced solely from Weibo. However, fake news originating from multiple sources exhibits diversity in various aspects, including its content and social context. Methods trained on purely one single news source can hardly be applicable to real-world scenarios. Our pilot experiment demonstrates that the F1 score of the state-of-the-art method that learns from a large Chinese fake news detection dataset, Weibo-21, drops significantly from 0.943 to 0.470 when the test data is changed to multi-source news data, failing to identify more than one-third of the multi-source fake news. To address this limitation, we constructed the first multi-source benchmark dataset for Chinese fake news detection, termed MCFEND, which is composed of news we collected from diverse sources suc
    
[^59]: 有意义学习：通过通用事实引导推进大型语言模型的抽象推理

    Meaningful Learning: Advancing Abstract Reasoning in Large Language Models via Generic Fact Guidance

    [https://arxiv.org/abs/2403.09085](https://arxiv.org/abs/2403.09085)

    设计了一个抽象推理数据集和有意义学习范式，教导大型语言模型如何利用通用事实进行推理，有效提升了抽象推理能力。

    

    大型语言模型（LLMs）在各种推理场景中取得了令人印象深刻的性能和强大的可解释性，标志着朝着模拟人类智能迈出了重要的一步。然而，当面对由通用事实支持的简单问题时，LLMs经常未能提供一致和准确的答案，表明其存在抽象推理能力的不足。这引发了关于LLMs到底是在真正推理还是仅仅在记忆的激烈争论。鉴此，我们设计了一个初步研究来量化并深入探讨现有LLMs的抽象推理能力。我们的研究发现显示出它们的一般推理和抽象推理表现之间存在实质性差异。为了缓解这一问题，我们为大型语言模型定制了一个抽象推理数据集（AbsR），结合有意义的学习范式，教会LLMs如何利用通用事实进行推理。结果表明我们的方法能够显着改善LLMs在抽象推理中的表现。

    arXiv:2403.09085v1 Announce Type: cross  Abstract: Large language models (LLMs) have developed impressive performance and strong explainability across various reasoning scenarios, marking a significant stride towards mimicking human-like intelligence. Despite this, when tasked with simple questions supported by a generic fact, LLMs often fail to provide consistent and precise answers, indicating a deficiency in abstract reasoning abilities. This has sparked a vigorous debate about whether LLMs are genuinely reasoning or merely memorizing. In light of this, we design a preliminary study to quantify and delve into the abstract reasoning abilities of existing LLMs. Our findings reveal a substantial discrepancy between their general reasoning and abstract reasoning performances. To relieve this problem, we tailor an abstract reasoning dataset (AbsR) together with a meaningful learning paradigm to teach LLMs how to leverage generic facts for reasoning purposes. The results show that our app
    
[^60]: UniCode: 学习用于多模大语言模型的统一码书

    UniCode: Learning a Unified Codebook for Multimodal Large Language Models

    [https://arxiv.org/abs/2403.09072](https://arxiv.org/abs/2403.09072)

    UniCode提出一种学习统一码书的方法，解决多模大语言模型中对视觉和文本进行标记的关键问题，使模型能够生成高质量的图像，并可适应各种压缩方法。

    

    在本文中，我们提出了一种名为UniCode的新方法，该方法属于多模大语言模型（MLLMs）领域，它学习了一个统一的码书来高效地标记视觉、文本和潜在其他类型的信号。这一创新解决了现有MLLMs存在的一个关键局限：它们依赖于仅限于文本的码书，这限制了MLLM在多模态环境中生成图像和文本的能力。为此，我们提出了一种以语言驱动的迭代训练范式，结合我们称之为“图像解压缩”的上下文预训练任务，使我们的模型能够解释压缩的视觉数据并生成高质量的图像。统一的码书使我们的模型能够将视觉指令调整扩展到非语言生成任务。此外，UniCode适应了各种叠加量化方法，以将视觉信号压缩为更紧凑的标记表示。

    arXiv:2403.09072v1 Announce Type: cross  Abstract: In this paper, we propose \textbf{UniCode}, a novel approach within the domain of multimodal large language models (MLLMs) that learns a unified codebook to efficiently tokenize visual, text, and potentially other types of signals. This innovation addresses a critical limitation in existing MLLMs: their reliance on a text-only codebook, which restricts MLLM's ability to generate images and texts in a multimodal context. Towards this end, we propose a language-driven iterative training paradigm, coupled with an in-context pre-training task we term ``image decompression'', enabling our model to interpret compressed visual data and generate high-quality images.The unified codebook empowers our model to extend visual instruction tuning to non-linguistic generation tasks. Moreover, UniCode is adaptable to diverse stacked quantization approaches in order to compress visual signals into a more compact token representation. Despite using signi
    
[^61]: 分布和深度感知变压器用于3D人体网格恢复

    Distribution and Depth-Aware Transformers for 3D Human Mesh Recovery

    [https://arxiv.org/abs/2403.09063](https://arxiv.org/abs/2403.09063)

    引入了分布和深度感知人体网格恢复（D2A-HMR），通过设计端到端的变压器架构，最小化分布之间的差异并整合场景深度信息，从而实现了明确和稳健的人体建模。

    

    使用野外数据精确进行人体网格恢复是一项艰巨的挑战，往往受到深度不明确和降低精度的阻碍。现有作品要么借助姿势先验，要么利用多模态数据（如多视图或点云信息），尽管它们的方法经常忽视单个图像中天然存在的宝贵场景深度信息。此外，由于姿势、形状和深度的固有变化，针对分布外数据（OOD）实现稳健的HMR极具挑战性。因此，理解人体形态建模的潜在分布成为一个重要子问题。出于对明确和稳健人体建模的需求，我们引入了分布和深度感知人体网格恢复（D2A-HMR），这是一种端到端的变压器架构，经过精心设计，旨在最小化分布之间的差异并整合场景深度，利用先前的深度信息。

    arXiv:2403.09063v1 Announce Type: cross  Abstract: Precise Human Mesh Recovery (HMR) with in-the-wild data is a formidable challenge and is often hindered by depth ambiguities and reduced precision. Existing works resort to either pose priors or multi-modal data such as multi-view or point cloud information, though their methods often overlook the valuable scene-depth information inherently present in a single image. Moreover, achieving robust HMR for out-of-distribution (OOD) data is exceedingly challenging due to inherent variations in pose, shape and depth. Consequently, understanding the underlying distribution becomes a vital subproblem in modeling human forms. Motivated by the need for unambiguous and robust human modeling, we introduce Distribution and depth-aware human mesh recovery (D2A-HMR), an end-to-end transformer architecture meticulously designed to minimize the disparity between distributions and incorporate scene-depth leveraging prior depth information. Our approach d
    
[^62]: 一种用于自动生成医疗记录的持续预训练LLM方法

    A Continued Pretrained LLM Approach for Automatic Medical Note Generation

    [https://arxiv.org/abs/2403.09057](https://arxiv.org/abs/2403.09057)

    这项研究提出了一种用于医疗记录生成的持续预训练LLM方法，在PubMedQA方面性能优于GPT-4，能够更好地捕捉正确的医疗概念，并且在正确性和完整性方面超过人类抄写员。

    

    LLM（大型语言模型）正在革新自然语言处理任务。然而，像GPT-4这样的最强大的LLM对于大多数领域特定场景来说成本太高。我们提出了第一个连续训练的130亿参数 Llama2-basd LLM，专为医疗对话而设计，并在自动记录上进行了测试。我们的结果显示，我们的模型在PubMedQA中的准确率高达76.6％，在总结医疗对话为SOAP笔记方面与GPT-4的性能相当。值得注意的是，我们的模型在捕捉正确的医疗概念方面超过了GPT-4，并且在正确性和完整性方面超越了人类抄写员。

    arXiv:2403.09057v1 Announce Type: cross  Abstract: LLMs are revolutionizing NLP tasks. However, the most powerful LLM, like GPT-4, is too costly for most domain-specific scenarios. We present the first continuously trained 13B Llama2-based LLM that is purpose-built for medical conversations and measured on automated scribing. Our results show that our model outperforms GPT-4 in PubMedQA with 76.6\% accuracy and matches its performance in summarizing medical conversations into SOAP notes. Notably, our model exceeds GPT-4 in capturing a higher number of correct medical concepts and outperforms human scribes with higher correctness and completeness.
    
[^63]: Keyformer：通过关键标记选择减少KV缓存以实现高效的生成推断

    Keyformer: KV Cache Reduction through Key Tokens Selection for Efficient Generative Inference

    [https://arxiv.org/abs/2403.09054](https://arxiv.org/abs/2403.09054)

    本文提出了一种名为“Keyformer”的创新推断时间方法，旨在通过选择关键标记来减少KV缓存的挑战，提高内存带宽利用率。

    

    Transformer已经成为大型语言模型(LLMs)的基础架构。在生成语言模型中，推断过程涉及两个主要阶段：提示处理和标记生成。标记生成，构成了大部分计算工作量，主要涉及向量-矩阵乘法和与键-值(KV)缓存交互。由于从存储系统传输权重和KV缓存值到计算单元的开销，这一阶段受到内存带宽的限制。这种内存瓶颈在需要长上下文和大量文本生成的应用中尤为突出，这两者对LLMs越来越重要。  本文介绍了一种创新的推断时间方法“Keyformer”，以缓解与KV缓存大小和内存带宽利用相关的挑战。Keyformer利用了这样的观察结果，大约90

    arXiv:2403.09054v1 Announce Type: cross  Abstract: Transformers have emerged as the underpinning architecture for Large Language Models (LLMs). In generative language models, the inference process involves two primary phases: prompt processing and token generation. Token generation, which constitutes the majority of the computational workload, primarily entails vector-matrix multiplications and interactions with the Key-Value (KV) Cache. This phase is constrained by memory bandwidth due to the overhead of transferring weights and KV cache values from the memory system to the computing units. This memory bottleneck becomes particularly pronounced in applications that require long-context and extensive text generation, both of which are increasingly crucial for LLMs.   This paper introduces "Keyformer", an innovative inference-time approach, to mitigate the challenges associated with KV cache size and memory bandwidth utilization. Keyformer leverages the observation that approximately 90
    
[^64]: 走向模型蒸馏理论

    Towards a theory of model distillation

    [https://arxiv.org/abs/2403.09053](https://arxiv.org/abs/2403.09053)

    提出了模型蒸馏的一般理论，通过PAC-蒸馏定义，提出了抽取神经网络训练权重知识的新算法，并证明了蒸馏比从头学习更便宜且有助于理解其复杂性。

    

    蒸馏是将复杂的机器学习模型替换为简化模型来近似原模型的任务。尽管有许多实际应用，关于模型蒸馏的程度、所需运行时间和数据量的基本问题仍然大多未解。为了研究这些问题，我们开始了蒸馏的一般理论，以类似的方式定义了PAC-蒸馏 [Val84]，提出了提取训练权重中存储的知识的新算法，展示了如何通过使用“线性表示假设”将神经网络高效地蒸馏成简明明了的决策树表示，还证明了蒸馏可以比从头开始学习便宜得多，并在表征其复杂性方面取得了进展。

    arXiv:2403.09053v1 Announce Type: cross  Abstract: Distillation is the task of replacing a complicated machine learning model with a simpler model that approximates the original [BCNM06,HVD15]. Despite many practical applications, basic questions about the extent to which models can be distilled, and the runtime and amount of data needed to distill, remain largely open.   To study these questions, we initiate a general theory of distillation, defining PAC-distillation in an analogous way to PAC-learning [Val84]. As applications of this theory: (1) we propose new algorithms to extract the knowledge stored in the trained weights of neural networks -- we show how to efficiently distill neural networks into succinct, explicit decision tree representations when possible by using the ``linear representation hypothesis''; and (2) we prove that distillation can be much cheaper than learning from scratch, and make progress on characterizing its complexity.
    
[^65]: 空间-时间记忆增强图自编码器用于动态图中的异常检测

    Spatial-temporal Memories Enhanced Graph Autoencoder for Anomaly Detection in Dynamic Graphs

    [https://arxiv.org/abs/2403.09039](https://arxiv.org/abs/2403.09039)

    提出了一种空间-时间记忆增强图自编码器（STRIPE）用于动态图中的异常检测，通过结合图神经网络和门控时间卷积层来提取空间特征和时间特征。

    

    动态图中的异常检测面临较大挑战，因为图结构和属性的时间演变。为了解决这一问题，我们提出了一种新颖的空间-时间记忆增强图自编码器（STRIPE）。STRIPE利用图神经网络（GNNs）和门控时间卷积层分别提取空间特征和时间特征。

    arXiv:2403.09039v1 Announce Type: cross  Abstract: Anomaly detection in dynamic graphs presents a significant challenge due to the temporal evolution of graph structures and attributes. The conventional approaches that tackle this problem typically employ an unsupervised learning framework, capturing normality patterns with exclusive normal data during training and identifying deviations as anomalies during testing. However, these methods face critical drawbacks: they either only depend on proxy tasks for general representation without directly pinpointing normal patterns, or they neglect to differentiate between spatial and temporal normality patterns, leading to diminished efficacy in anomaly detection. To address these challenges, we introduce a novel Spatial-Temporal memories-enhanced graph autoencoder (STRIPE). Initially, STRIPE employs Graph Neural Networks (GNNs) and gated temporal convolution layers to extract spatial features and temporal features, respectively. Then STRIPE in
    
[^66]: 使用 WebSight 数据集实现将 Web 屏幕截图转换为 HTML 代码的解锁

    Unlocking the conversion of Web Screenshots into HTML Code with the WebSight Dataset

    [https://arxiv.org/abs/2403.09029](https://arxiv.org/abs/2403.09029)

    本研究介绍了 WebSight 数据集，通过对 VLM 进行微调，实现了将网页截图转换为功能性 HTML 代码的能力，为解决屏幕截图转换为 HTML 代码的挑战提供了新的解决方案。

    

    在 web 开发中使用视觉-语言模型（VLMs）提出了一个有前途的策略，以提高效率并解锁无代码解决方案：通过提供 UI 的屏幕截图或草图，VLM 可以生成复制它的代码，例如以 HTML 语言。尽管 VLMs 在各种任务中取得了进展，但将屏幕截图转换为相应的 HTML 的具体挑战几乎未经探索。我们认为这主要是由于缺乏一个合适的、高质量的数据集。本文介绍了 WebSight，一个由 200 万对 HTML 代码和它们对应的屏幕截图组成的合成数据集。我们在我们的数据集上对基础 VLM 进行微调，并展示了将网页截图转换为功能性 HTML 代码的能力。为了加速该领域的研究，我们开源了 WebSight.

    arXiv:2403.09029v1 Announce Type: cross  Abstract: Using vision-language models (VLMs) in web development presents a promising strategy to increase efficiency and unblock no-code solutions: by providing a screenshot or a sketch of a UI, a VLM could generate the code to reproduce it, for instance in a language like HTML. Despite the advancements in VLMs for various tasks, the specific challenge of converting a screenshot into a corresponding HTML has been minimally explored. We posit that this is mainly due to the absence of a suitable, high-quality dataset. This work introduces WebSight, a synthetic dataset consisting of 2 million pairs of HTML codes and their corresponding screenshots. We fine-tune a foundational VLM on our dataset and show proficiency in converting webpage screenshots to functional HTML code. To accelerate the research in this area, we open-source WebSight.
    
[^67]: 半参数令牌序列共监督

    Semiparametric Token-Sequence Co-Supervision

    [https://arxiv.org/abs/2403.09024](https://arxiv.org/abs/2403.09024)

    引入了一种半参数令牌序列共监督训练方法，通过同时利用传统的下一个令牌预测损失和下一个序列预测损失来训练语言模型，实验结果显示这种方法能够提高模型的泛化能力。

    

    在这项工作中，我们引入了一种半参数令牌序列共监督训练方法。该方法通过同时利用传统的基于参数化令牌嵌入空间计算的下一个令牌预测损失和基于非参数化序列嵌入空间计算的下一个序列预测损失来训练语言模型。非参数序列嵌入空间是由一个单独的语言模型构建的，其任务是将输入文本压缩成一个单一的代表性嵌入。我们的实验表明，通过这两种监督训练的模型始终优于单独通过每种监督训练的模型。分析表明，这种共监督鼓励模型具有更广泛的泛化能力。特别是，在预训练步骤中建立的参数化标记空间的鲁棒性倾向于有效增强非参数化的稳定性。

    arXiv:2403.09024v1 Announce Type: cross  Abstract: In this work, we introduce a semiparametric token-sequence co-supervision training method. It trains a language model by simultaneously leveraging supervision from the traditional next token prediction loss which is calculated over the parametric token embedding space and the next sequence prediction loss which is calculated over the nonparametric sequence embedding space. The nonparametric sequence embedding space is constructed by a separate language model tasked to condense an input text into a single representative embedding. Our experiments demonstrate that a model trained via both supervisions consistently surpasses models trained via each supervision independently. Analysis suggests that this co-supervision encourages a broader generalization capability across the model. Especially, the robustness of parametric token space which is established during the pretraining step tends to effectively enhance the stability of nonparametri
    
[^68]: 自主轮椅的安全过马路：一个新颖的数据集及其实验评估

    Safe Road-Crossing by Autonomous Wheelchairs: a Novel Dataset and its Experimental Evaluation

    [https://arxiv.org/abs/2403.08984](https://arxiv.org/abs/2403.08984)

    提出了一种多传感器融合方法，支持自主轮椅和飞行无人机系统的安全过马路决策，实验结果表明使用多传感器可以提高决策准确性和有效支持安全评估

    

    安全地过马路是智能城市中需要解决的关键问题。本文介绍了一种多传感器融合方法，以支持自主轮椅和配备多样化和冗余组件的飞行无人机系统中的过马路决策。为此，我们设计了一种基于可解释物理条件的分析危险函数，通过单一传感器进行评估，包括使用机器学习和人工视觉的传感器。作为概念验证，我们在实验室环境中进行了实证评估，展示了使用多传感器的优势，可以提高决策准确性，有效支持安全评估。我们向科学界提供了该数据集以供进一步试验。这项工作是在一个名为REXASI-PRO的欧洲项目的框架下开发的，旨在开发值得信赖的艺术

    arXiv:2403.08984v1 Announce Type: cross  Abstract: Safe road-crossing by self-driving vehicles is a crucial problem to address in smart-cities. In this paper, we introduce a multi-sensor fusion approach to support road-crossing decisions in a system composed by an autonomous wheelchair and a flying drone featuring a robust sensory system made of diverse and redundant components. To that aim, we designed an analytical danger function based on explainable physical conditions evaluated by single sensors, including those using machine learning and artificial vision. As a proof-of-concept, we provide an experimental evaluation in a laboratory environment, showing the advantages of using multiple sensors, which can improve decision accuracy and effectively support safety assessment. We made the dataset available to the scientific community for further experimentation. The work has been developed in the context of an European project named REXASI-PRO, which aims to develop trustworthy artific
    
[^69]: 用去噪扩散隐式神经场表示解剖树

    Representing Anatomical Trees by Denoising Diffusion of Implicit Neural Fields

    [https://arxiv.org/abs/2403.08974](https://arxiv.org/abs/2403.08974)

    提出了一种使用隐式神经表示和去噪扩散来准确捕捉解剖树几何和拓扑结构的新方法

    

    解剖树在临床诊断和治疗规划中起着核心作用。然而，由于解剖树的拓扑结构和几何形状多样且复杂，准确表示解剖树具有挑战性。我们提出了一种使用隐式神经表示（INRs）来表示解剖树的新方法，同时通过在INR空间中进行去噪扩散来捕捉一组树的分布。我们可以在任何所需分辨率下准确捕捉解剖树的复杂几何和拓扑结构。

    arXiv:2403.08974v1 Announce Type: cross  Abstract: Anatomical trees play a central role in clinical diagnosis and treatment planning. However, accurately representing anatomical trees is challenging due to their varying and complex topology and geometry. Traditional methods for representing tree structures, captured using medical imaging, while invaluable for visualizing vascular and bronchial networks, exhibit drawbacks in terms of limited resolution, flexibility, and efficiency. Recently, implicit neural representations (INRs) have emerged as a powerful tool for representing shapes accurately and efficiently. We propose a novel approach for representing anatomical trees using INR, while also capturing the distribution of a set of trees via denoising diffusion in the space of INRs. We accurately capture the intricate geometries and topologies of anatomical trees at any desired resolution. Through extensive qualitative and quantitative evaluation, we demonstrate high-fidelity tree reco
    
[^70]: PathM3: 一种用于全切片图像分类和字幕生成的多模态多任务多实例学习框架

    PathM3: A Multimodal Multi-Task Multiple Instance Learning Framework for Whole Slide Image Classification and Captioning

    [https://arxiv.org/abs/2403.08967](https://arxiv.org/abs/2403.08967)

    提出了一种 PathM3 框架，用于WSI分类和字幕生成，采用了多模态、多任务、多实例学习方法，通过查询式transformer有效对齐WSIs与诊断性字幕。

    

    在计算组织病理学领域，整个切片图像（WSIs）和诊断性字幕都为做出诊断决策提供了宝贵的见解。然而，将WSIs与诊断性字幕对齐是一个重大挑战，主要源自两个因素：1）巨型像素WSIs不适合直接输入深度学习模型，而图块间的冗余性和相关性要求更多注意；2）真实的WSI诊断性字幕极其有限，使得难以训练出有效的模型。

    arXiv:2403.08967v1 Announce Type: cross  Abstract: In the field of computational histopathology, both whole slide images (WSIs) and diagnostic captions provide valuable insights for making diagnostic decisions. However, aligning WSIs with diagnostic captions presents a significant challenge. This difficulty arises from two main factors: 1) Gigapixel WSIs are unsuitable for direct input into deep learning models, and the redundancy and correlation among the patches demand more attention; and 2) Authentic WSI diagnostic captions are extremely limited, making it difficult to train an effective model. To overcome these obstacles, we present PathM3, a multimodal, multi-task, multiple instance learning (MIL) framework for WSI classification and captioning. PathM3 adapts a query-based transformer to effectively align WSIs with diagnostic captions. Given that histopathology visual patterns are redundantly distributed across WSIs, we aggregate each patch feature with MIL method that considers t
    
[^71]: 使用深度学习进行猪类形态分类，重点关注卫生监测

    Using Deep Learning for Morphological Classification in Pigs with a Focus on Sanitary Monitoring

    [https://arxiv.org/abs/2403.08962](https://arxiv.org/abs/2403.08962)

    本文提出使用D-CNN网络进行猪类形态分类，重点关注卫生监测特征，取得了有效的分类效果。

    

    本文旨在评估使用深度卷积神经网络（D-CNN）算法来对猪的身体条件进行正常或异常分类，重点关注卫生监测中观察到的特征，并使用六种不同的算法来完成此任务。研究聚焦于五个猪的特征，包括尾巴啃食、耳部血肿、身体抓痕、红斑和自然污渍（棕色或黑色）。研究结果显示，D-CNN在对与皮肤特征相关的猪体形态偏差进行分类方面是有效的。评估通过分析准确率、召回率和F分数等性能指标以及统计分析ANOVA和Scott-Knott测试完成。本文的贡献在于提出使用D-CNN网络进行猪类形态分类，重点关注卫生监测中识别到的特征。

    arXiv:2403.08962v1 Announce Type: cross  Abstract: The aim of this paper is to evaluate the use of D-CNN (Deep Convolutional Neural Networks) algorithms to classify pig body conditions in normal or not normal conditions, with a focus on characteristics that are observed in sanitary monitoring, and were used six different algorithms to do this task. The study focused on five pig characteristics, being these caudophagy, ear hematoma, scratches on the body, redness, and natural stains (brown or black). The results of the study showed that D-CNN was effective in classifying deviations in pig body morphologies related to skin characteristics. The evaluation was conducted by analyzing the performance metrics Precision, Recall, and F-score, as well as the statistical analyses ANOVA and the Scott-Knott test. The contribution of this article is characterized by the proposal of using D-CNN networks for morphological classification in pigs, with a focus on characteristics identified in sanitary m
    
[^72]: 羽毛球AI教练

    AI coach for badminton

    [https://arxiv.org/abs/2403.08956](https://arxiv.org/abs/2403.08956)

    通过运用先进的神经网络方法剖析羽毛球比赛视频，提取球员动力学和生物力学见解，以推导改进技术的预测模型

    

    在竞技体育领域，最佳表现需要对营养和身体状况进行严格管理。在羽毛球运动中，所需的敏捷性和精准性使其成为通过视频分析进行运动分析的理想候选者。本研究利用先进的神经网络方法来剖析羽毛球比赛的视频镜头，旨在提取有关球员动力学和生物力学的详细见解。通过对击球力学的分析，包括手臂-臀部协调，腿部定位和击球的执行角度，该研究旨在推导出可以建议改进站姿、技术和肌肉方向的预测模型。这些建议旨在减少错误技术，降低关节疲劳风险，并增强整体表现。利用在线可获得的大量数据，该研究将球员的身体属性与其-

    arXiv:2403.08956v1 Announce Type: cross  Abstract: In the competitive realm of sports, optimal performance necessitates rigorous management of nutrition and physical conditioning. Specifically, in badminton, the agility and precision required make it an ideal candidate for motion analysis through video analytics. This study leverages advanced neural network methodologies to dissect video footage of badminton matches, aiming to extract detailed insights into player kinetics and biomechanics. Through the analysis of stroke mechanics, including hand-hip coordination, leg positioning, and the execution angles of strokes, the research aims to derive predictive models that can suggest improvements in stance, technique, and muscle orientation. These recommendations are designed to mitigate erroneous techniques, reduce the risk of joint fatigue, and enhance overall performance. Utilizing a vast array of data available online, this research correlates players' physical attributes with their in-
    
[^73]: 朝向高效的风险敏感策略梯度：一个迭代复杂度分析

    Towards Efficient Risk-Sensitive Policy Gradient: An Iteration Complexity Analysis

    [https://arxiv.org/abs/2403.08955](https://arxiv.org/abs/2403.08955)

    本文对风险敏感策略梯度方法进行了迭代复杂度分析，发现其能够通过使用指数效用函数达到较低的迭代复杂度。

    

    强化学习在各种应用中表现出色，使得自主智能体能够通过与环境的互动学习最佳策略。然而，传统的强化学习框架在迭代复杂度和鲁棒性方面经常面临挑战。风险敏感强化学习平衡了期望回报和风险，具有产生概率鲁棒策略的潜力，但其迭代复杂度分析尚未得到充分探讨。在本研究中，我们针对风险敏感策略梯度方法进行了彻底的迭代复杂度分析，重点关注REINFORCE算法并采用指数效用函数。我们获得了一个$\mathcal{O}(\epsilon^{-2})$的迭代复杂度，以达到$\epsilon$-近似的一阶稳定点（FOSP）。我们研究了风险敏感算法是否可以比风险中性算法实现更好的迭代复杂度。

    arXiv:2403.08955v1 Announce Type: cross  Abstract: Reinforcement Learning (RL) has shown exceptional performance across various applications, enabling autonomous agents to learn optimal policies through interaction with their environments. However, traditional RL frameworks often face challenges in terms of iteration complexity and robustness. Risk-sensitive RL, which balances expected return and risk, has been explored for its potential to yield probabilistically robust policies, yet its iteration complexity analysis remains underexplored. In this study, we conduct a thorough iteration complexity analysis for the risk-sensitive policy gradient method, focusing on the REINFORCE algorithm and employing the exponential utility function. We obtain an iteration complexity of $\mathcal{O}(\epsilon^{-2})$ to reach an $\epsilon$-approximate first-order stationary point (FOSP). We investigate whether risk-sensitive algorithms can achieve better iteration complexity compared to their risk-neutr
    
[^74]: 探究企业中的提示工程实践

    Exploring Prompt Engineering Practices in the Enterprise

    [https://arxiv.org/abs/2403.08950](https://arxiv.org/abs/2403.08950)

    研究者分析了提示编辑行为的会话，以更好地了解提示工程实践。

    

    与大型语言模型（LLMs）的互动主要通过提示来实现。 提示是一种旨在从模型中引出特定行为或输出的自然语言指令。 理论上，自然语言提示使非专家能够与LLMs进行互动和利用。 但是，对于复杂的任务和具有特定要求的任务，提示设计并不是微不足道的。 创建有效的提示需要技能和知识，以及大量迭代，以确定模型行为，并引导模型实现特定目标。 我们假设用户在提示上进行迭代的方式可以揭示他们如何认为提示和模型工作，以及更高效的提示工程需要哪种支持。 为了更好地了解提示工程实践，我们分析了提示编辑行为的会话，对用户迭代的提示部分和更改类型进行分类。

    arXiv:2403.08950v1 Announce Type: cross  Abstract: Interaction with Large Language Models (LLMs) is primarily carried out via prompting. A prompt is a natural language instruction designed to elicit certain behaviour or output from a model. In theory, natural language prompts enable non-experts to interact with and leverage LLMs. However, for complex tasks and tasks with specific requirements, prompt design is not trivial. Creating effective prompts requires skill and knowledge, as well as significant iteration in order to determine model behavior, and guide the model to accomplish a particular goal. We hypothesize that the way in which users iterate on their prompts can provide insight into how they think prompting and models work, as well as the kinds of support needed for more efficient prompt engineering. To better understand prompt engineering practices, we analyzed sessions of prompt editing behavior, categorizing the parts of prompts users iterated on and the types of changes th
    
[^75]: 人工智能时代的基于语言的博弈论

    Language-based game theory in the age of artificial intelligence

    [https://arxiv.org/abs/2403.08944](https://arxiv.org/abs/2403.08944)

    最近的实验研究揭示了语言内容显著影响决策，促使从基于结果转向基于语言的效用函数的范式转变。

    

    理解决策问题和战略互动中的人类行为在经济学、心理学和人工智能领域具有广泛应用。博弈论提供了这种理解的坚实基础，其核心思想是个体旨在最大化效用函数。然而，影响策略选择的确切因素仍然难以捉摸。尽管传统模型试图将人类行为解释为可用行动结果的函数，但最近的实验研究表明，语言内容显著影响决策，因此促使从基于结果转向基于语言的效用函数的范式转变。鉴于生成式人工智能的进步，这种转变比以往任何时候都更加紧迫，后者有潜力通过基于语言的互动支持人类做出关键决策。我们提出情感分析作为这种转变的基础工具，并通过分析其...

    arXiv:2403.08944v1 Announce Type: cross  Abstract: Understanding human behaviour in decision problems and strategic interactions has wide-ranging applications in economics, psychology, and artificial intelligence. Game theory offers a robust foundation for this understanding, based on the idea that individuals aim to maximize a utility function. However, the exact factors influencing strategy choices remain elusive. While traditional models try to explain human behaviour as a function of the outcomes of available actions, recent experimental research reveals that linguistic content significantly impacts decision-making, thus prompting a paradigm shift from outcome-based to language-based utility functions. This shift is more urgent than ever, given the advancement of generative AI, which has the potential to support humans in making critical decisions through language-based interactions. We propose sentiment analysis as a fundamental tool for this shift and take an initial step by anal
    
[^76]: 大型语言模型生成的代码中的缺陷

    Bugs in Large Language Models Generated Code

    [https://arxiv.org/abs/2403.08937](https://arxiv.org/abs/2403.08937)

    本文研究了使用三种主要LLM生成的代码中收集的333个缺陷样本，并识别了10种独特的错误模式。

    

    最近，用于代码的大型语言模型（LLMs）受到了重视。它们可以基于提供的提示在不同的编程语言中生成代码，实现了软件工程（SE）中长期以来的一个梦想，即自动生成代码。与人类编写的代码类似，LLM生成的代码容易出现错误，但社区尚未对这些错误进行深入研究。鉴于软件工程活动中LLM-based代码生成工具（例如GitHub Copilot）的日益普及，了解LLMs生成代码中包含的缺陷特征至关重要。本文研究了使用三种主要LLM（即CodeGen、PanGu-Coder和Codex）生成的代码中收集的333个缺陷样本，并识别了以下10种独特的错误模式：误解、语法错误、愚蠢错误、提示偏向代码、遗漏角落案例、错误的输入类型、产生幻象对象、错误的属性、不完整（未完结）

    arXiv:2403.08937v1 Announce Type: cross  Abstract: Large Language Models (LLMs) for code have gained significant attention recently. They can generate code in different programming languages based on provided prompts, fulfilling a long-lasting dream in Software Engineering (SE), i.e., automatic code generation. Similar to human-written code, LLM-generated code is prone to bugs, and these bugs have not yet been thoroughly examined by the community. Given the increasing adoption of LLM-based code generation tools (e.g., GitHub Copilot) in SE activities, it is critical to understand the characteristics of bugs contained in code generated by LLMs. This paper examines a sample of 333 bugs collected from code generated using three leading LLMs (i.e., CodeGen, PanGu-Coder, and Codex) and identifies the following 10 distinctive bug patterns: Misinterpretations, Syntax Error, Silly Mistake, Prompt-biased code, Missing Corner Case, Wrong Input Type, Hallucinated Object, Wrong Attribute, Incomple
    
[^77]: 超越联合示范：个性化专家指导用于高效多智体强化学习

    Beyond Joint Demonstrations: Personalized Expert Guidance for Efficient Multi-Agent Reinforcement Learning

    [https://arxiv.org/abs/2403.08936](https://arxiv.org/abs/2403.08936)

    提出了个性化专家示范的概念，为每个智体或不同类型的智体提供针对个人目标的指导，解决了多智体强化学习中联合示范困难的问题。

    

    多智体强化学习算法面临有效探索的挑战，因为联合状态-动作空间的大小呈指数增长。虽然示范引导学习在单智体环境中已被证明是有益的，但其直接应用于多智体强化学习受到获得联合专家示范的实际困难的阻碍。在这项工作中，我们引入了个性化专家示范的新概念，针对每个单个智体或更广泛地说，团队中每种类型的智体进行了定制。这些示范仅涉及单智体行为以及每个智体如何实现个人目标，而不涉及任何合作元素，因此盲目模仿它们不会实现合作由于潜在冲突。为此，我们提出了一种方法，选择性地利用个性化专家示范作为指导，并允许智体学习协

    arXiv:2403.08936v1 Announce Type: cross  Abstract: Multi-Agent Reinforcement Learning (MARL) algorithms face the challenge of efficient exploration due to the exponential increase in the size of the joint state-action space. While demonstration-guided learning has proven beneficial in single-agent settings, its direct applicability to MARL is hindered by the practical difficulty of obtaining joint expert demonstrations. In this work, we introduce a novel concept of personalized expert demonstrations, tailored for each individual agent or, more broadly, each individual type of agent within a heterogeneous team. These demonstrations solely pertain to single-agent behaviors and how each agent can achieve personal goals without encompassing any cooperative elements, thus naively imitating them will not achieve cooperation due to potential conflicts. To this end, we propose an approach that selectively utilizes personalized expert demonstrations as guidance and allows agents to learn to coo
    
[^78]: 揭示真相：探索人类凝视假图中的眼动模式

    Unveiling the Truth: Exploring Human Gaze Patterns in Fake Images

    [https://arxiv.org/abs/2403.08933](https://arxiv.org/abs/2403.08933)

    本研究利用人类语义知识研究了虚假图像检测框架的可能性，通过收集新数据集和进行眼动实验，探讨了眼动在此过程中的作用。

    

    利用图像生成技术的深远进步，现在可以创建高质量、逼真的图像。通过自然语言描述所需输出，即可获得令人叹为观止的结果。然而，随着生成模型的使用增多，人们对恶意内容和错误信息传播的担忧也在增加。因此，研究界正在积极致力于开发新型虚假检测技术，主要关注图像生成过程中生成模型可能留下的低级特征和可能的指纹。在我们的研究中，我们借助人类语义知识探讨可能纳入虚假图像检测框架的可能性。为实现这一目标，我们收集了使用扩散模型部分操纵的新数据集，并进行了眼动实验，记录了不同观察者在观看过程中的眼动。

    arXiv:2403.08933v1 Announce Type: cross  Abstract: Creating high-quality and realistic images is now possible thanks to the impressive advancements in image generation. A description in natural language of your desired output is all you need to obtain breathtaking results. However, as the use of generative models grows, so do concerns about the propagation of malicious content and misinformation. Consequently, the research community is actively working on the development of novel fake detection techniques, primarily focusing on low-level features and possible fingerprints left by generative models during the image generation process. In a different vein, in our work, we leverage human semantic knowledge to investigate the possibility of being included in frameworks of fake image detection. To achieve this, we collect a novel dataset of partially manipulated images using diffusion models and conduct an eye-tracking experiment to record the eye movements of different observers while view
    
[^79]: 阿姆斯特丹住房质量的跨模态学习

    Cross-Modal Learning of Housing Quality in Amsterdam

    [https://arxiv.org/abs/2403.08915](https://arxiv.org/abs/2403.08915)

    通过认真筛选和合适的预训练模型，Flickr图像特征与空中图像特征相结合能够将性能差距从30%降低到15%

    

    在我们的研究中，我们测试了从地面和空中图像识别阿姆斯特丹城市住房质量的数据和模型。对于地面图像，我们比较了谷歌街景图（GSV）和Flickr图像。我们的研究结果显示，GSV能够预测最准确的建筑质量分数，比单独使用空中图像提高了约30%。然而，我们发现通过仔细筛选并使用正确的预训练模型，Flickr图像特征与空中图像特征相结合能够将性能差距从30%降低到15%。我们的结果表明，对于生活质量因素预测，存在可行的GSV替代方案，这是一个鼓舞人心的消息，因为GSV图像更难获取并且并非总是可用的。

    arXiv:2403.08915v1 Announce Type: cross  Abstract: In our research we test data and models for the recognition of housing quality in the city of Amsterdam from ground-level and aerial imagery. For ground-level images we compare Google StreetView (GSV) to Flickr images. Our results show that GSV predicts the most accurate building quality scores, approximately 30% better than using only aerial images. However, we find that through careful filtering and by using the right pre-trained model, Flickr image features combined with aerial image features are able to halve the performance gap to GSV features from 30% to 15%. Our results indicate that there are viable alternatives to GSV for liveability factor prediction, which is encouraging as GSV images are more difficult to acquire and not always available.
    
[^80]: 通过深度强化学习实现并行规划的元算子

    Meta-operators for Enabling Parallel Planning Using Deep Reinforcement Learning

    [https://arxiv.org/abs/2403.08910](https://arxiv.org/abs/2403.08910)

    引入了元算子的概念，使得RL动作空间能够同时处理多个规划操作符，从而实现新的规划视角，例如并行规划。

    

    最近人们对使用强化学习（RL）技术进行AI规划的应用越发感兴趣，旨在提出通用策略。通常，通过假设各自动作空间具有一一对应关系，将AI规划的转移模型映射到马尔可夫决策过程的状态转移系统。本文介绍了元算子的概念，它是同时应用多个规划算子的结果，并且我们展示了将元算子包括在RL动作空间中如何使得新的规划视角能够通过RL来解决，例如并行规划。我们的研究旨在分析在RL过程中包括元算子的性能和复杂性，具体应用于以往使用传统广义规划模型未曾取得满意结果的领域。因此，本文的主要目标是为重定义跨深层规划和强化学习之间的界限铺平道路。

    arXiv:2403.08910v1 Announce Type: new  Abstract: There is a growing interest in the application of Reinforcement Learning (RL) techniques to AI planning with the aim to come up with general policies. Typically, the mapping of the transition model of AI planning to the state transition system of a Markov Decision Process is established by assuming a one-to-one correspondence of the respective action spaces. In this paper, we introduce the concept of meta-operator as the result of simultaneously applying multiple planning operators, and we show that including meta-operators in the RL action space enables new planning perspectives to be addressed using RL, such as parallel planning. Our research aims to analyze the performance and complexity of including meta-operators in the RL process, concretely in domains where satisfactory outcomes have not been previously achieved using usual generalized planning models. The main objective of this article is thus to pave the way towards a redefiniti
    
[^81]: 针对Q-学习者的策略化对抗：一种控制论方法

    Strategizing against Q-learners: A Control-theoretical Approach

    [https://arxiv.org/abs/2403.08906](https://arxiv.org/abs/2403.08906)

    在这篇论文中，作者探讨了Q-learning算法在游戏中受到策略性对手的操纵的敏感性，并提出了一种控制论方法来解决这个问题。

    

    在这篇论文中，我们探讨了Q-learning算法(一种经典且广泛使用的强化学习方法)在游戏中对策略性对手的敏感性。我们量化了如果策略性对手了解对手的Q-learning算法，她可以利用一个天真的Q-学习者多少。为此，我们将策略行为者的问题构建为一个马尔可夫决策过程(具有涵盖所有可能Q值的连续状态空间)，就好像Q-学习算法是底层动态系统一样。我们还提出了一个基于量化的近似方案来处理连续状态空间，并在理论和数值上分析了其性能。

    arXiv:2403.08906v1 Announce Type: cross  Abstract: In this paper, we explore the susceptibility of the Q-learning algorithm (a classical and widely used reinforcement learning method) to strategic manipulation of sophisticated opponents in games. We quantify how much a strategically sophisticated agent can exploit a naive Q-learner if she knows the opponent's Q-learning algorithm. To this end, we formulate the strategic actor's problem as a Markov decision process (with a continuum state space encompassing all possible Q-values) as if the Q-learning algorithm is the underlying dynamical system. We also present a quantization-based approximation scheme to tackle the continuum state space and analyze its performance both analytically and numerically.
    
[^82]: SLCF-Net：使用3D循环U-Net进行序列式激光雷达-相机融合的语义场景完善

    SLCF-Net: Sequential LiDAR-Camera Fusion for Semantic Scene Completion using a 3D Recurrent U-Net

    [https://arxiv.org/abs/2403.08885](https://arxiv.org/abs/2403.08885)

    SLCF-Net是一种用于语义场景完善任务的新方法，通过序列融合激光雷达和相机数据，联合估计缺失的几何和语义信息，并引入了高斯衰减深度先验投影模块以实现2D图像特征和3D场景体积的关联，同时设计了一种新颖的损失函数来确保时间一致性。

    

    我们引入了SLCF-Net，一种新颖的方法用于语义场景完善（SSC）任务，通过序列融合激光雷达和相机数据。它通过RGB图像序列和稀疏激光雷达测量数据联合估计场景中缺失的几何和语义信息。图像经过经过预训练的2D U-Net进行语义分割，并从Depth Anything提供的深度条件管线中估计出密集深度先验。为了将2D图像特征与3D场景体积关联起来，我们引入了高斯衰减深度先验投影（GDP）。该模块使用高斯衰减函数沿着以深度先验为中心的视线将2D特征投影到3D体积中。体积语义由3D U-Net计算。我们利用传感器运动传播隐藏的3D U-Net状态，并设计了一种新颖的损失函数来确保时间一致性。我们在SemanticKITTI数据集上评估了我们的方法，并将其与领先的SSC方法进行了比较。

    arXiv:2403.08885v1 Announce Type: cross  Abstract: We introduce SLCF-Net, a novel approach for the Semantic Scene Completion (SSC) task that sequentially fuses LiDAR and camera data. It jointly estimates missing geometry and semantics in a scene from sequences of RGB images and sparse LiDAR measurements. The images are semantically segmented by a pre-trained 2D U-Net and a dense depth prior is estimated from a depth-conditioned pipeline fueled by Depth Anything. To associate the 2D image features with the 3D scene volume, we introduce Gaussian-decay Depth-prior Projection (GDP). This module projects the 2D features into the 3D volume along the line of sight with a Gaussian-decay function, centered around the depth prior. Volumetric semantics is computed by a 3D U-Net. We propagate the hidden 3D U-Net state using the sensor motion and design a novel loss to ensure temporal consistency. We evaluate our approach on the SemanticKITTI dataset and compare it with leading SSC approaches. The 
    
[^83]: 大型语言模型中的文化演化

    Cultural evolution in populations of Large Language Models

    [https://arxiv.org/abs/2403.08882](https://arxiv.org/abs/2403.08882)

    大型语言模型在模仿人类行为方面具有潜力，可用于研究文化演化中由进化的认知机制引起的社会信息转变的影响。

    

    文化演化研究旨在提供关于文化随时间变化的因果解释。过去几十年来，这一领域已经产生了重要的知识体系，利用了实验、历史和计算方法。虽然计算模型在生成关于诸多因素如人口结构或传播偏差影响的可检验假设方面非常成功，但某些现象迄今为止更难以使用基于代理人和形式模型来捕捉，尤其是由进化的认知机制引起的社会信息转变的影响。我们在这里提出，利用大型语言模型(LLMs)模仿人类行为的能力可能有助于解决这一差距。作为人类文化动态的有用近似，以生成代理为特征的多代理模型也是研究自身的重要工具。

    arXiv:2403.08882v1 Announce Type: cross  Abstract: Research in cultural evolution aims at providing causal explanations for the change of culture over time. Over the past decades, this field has generated an important body of knowledge, using experimental, historical, and computational methods. While computational models have been very successful at generating testable hypotheses about the effects of several factors, such as population structure or transmission biases, some phenomena have so far been more complex to capture using agent-based and formal models. This is in particular the case for the effect of the transformations of social information induced by evolved cognitive mechanisms. We here propose that leveraging the capacity of Large Language Models (LLMs) to mimic human behavior may be fruitful to address this gap. On top of being an useful approximation of human cultural dynamics, multi-agents models featuring generative agents are also important to study for their own sake.
    
[^84]: 使用自适应分布式强化学习进行多目标优化

    Multi-Objective Optimization Using Adaptive Distributed Reinforcement Learning

    [https://arxiv.org/abs/2403.08879](https://arxiv.org/abs/2403.08879)

    提出了一种在智能交通系统环境下进行多目标、多智能体强化学习的算法，具有高学习效率和低计算要求。

    

    智能交通系统（ITS）环境被认为是动态和分布式的，参与者（车辆用户，运营商等）具有多个、不断变化且可能相互冲突的目标。虽然强化学习（RL）算法通常用于优化ITS应用，如资源管理和卸载，但大多数RL算法专注于单一目标。在许多情况下，将多目标问题转化为单一目标是不可能的、棘手的或不足的，这使得这种RL算法不适用。我们提出了一种具有高学习效率和低计算要求的多目标多代理强化学习（MARL）算法，该算法在动态、分布式和嘈杂的环境中自动触发自适应的少样本学习，并具有稀疏和延迟奖励。我们在具有边缘云计算的ITS环境中测试了我们的算法。实证结果表明

    arXiv:2403.08879v1 Announce Type: cross  Abstract: The Intelligent Transportation System (ITS) environment is known to be dynamic and distributed, where participants (vehicle users, operators, etc.) have multiple, changing and possibly conflicting objectives. Although Reinforcement Learning (RL) algorithms are commonly applied to optimize ITS applications such as resource management and offloading, most RL algorithms focus on single objectives. In many situations, converting a multi-objective problem into a single-objective one is impossible, intractable or insufficient, making such RL algorithms inapplicable. We propose a multi-objective, multi-agent reinforcement learning (MARL) algorithm with high learning efficiency and low computational requirements, which automatically triggers adaptive few-shot learning in a dynamic, distributed and noisy environment with sparse and delayed reward. We test our algorithm in an ITS environment with edge cloud computing. Empirical results show that
    
[^85]: 单上下文大批量抽样的分叉注意力

    Bifurcated Attention for Single-Context Large-Batch Sampling

    [https://arxiv.org/abs/2403.08845](https://arxiv.org/abs/2403.08845)

    分叉注意力是针对语言模型推断中单上下文批量抽样环境开发的方法，通过将注意力机制分成两个独立的操作来减少冗余内存IO成本，提高效率并降低延迟。

    

    在我们的研究中，我们提出了一种称为分叉注意力的方法，用于单上下文批量抽样环境下的语言模型推断。这种方法旨在减少冗余的内存IO成本，这是高批量大小和长上下文长度的延迟的重要因素。分叉注意力通过在增量解码期间将注意力机制划分为两个不同的GEMM操作，分别专注于来自预填充的KV缓存以及解码过程，从而实现这一目标。该方法确保了精确的计算，并维持常规注意力机制的计算负载（FLOPs），但减少了内存IO。分叉注意力还与减少KV缓存内存IO已知的多查询注意力机制兼容，进一步实现更高的批量大小和上下文长度。由此带来的效率导致更低的延迟，改善了实时应用的适用性，例如实现大规模并行的答案生成。

    arXiv:2403.08845v1 Announce Type: cross  Abstract: In our study, we present bifurcated attention, a method developed for language model inference in single-context batch sampling contexts. This approach aims to reduce redundant memory IO costs, a significant factor in latency for high batch sizes and long context lengths. Bifurcated attention achieves this by dividing the attention mechanism during incremental decoding into two distinct GEMM operations, focusing on the KV cache from prefill and the decoding process. This method ensures precise computation and maintains the usual computational load (FLOPs) of standard attention mechanisms, but with reduced memory IO. Bifurcated attention is also compatible with multi-query attention mechanism known for reduced memory IO for KV cache, further enabling higher batch size and context length. The resulting efficiency leads to lower latency, improving suitability for real-time applications, e.g., enabling massively-parallel answer generation 
    
[^86]: AcademiaOS：利用大型语言模型自动化定性研究中的理论建构

    AcademiaOS: Automating Grounded Theory Development in Qualitative Research with Large Language Models

    [https://arxiv.org/abs/2403.08844](https://arxiv.org/abs/2403.08844)

    AcademiaOS利用大型语言模型自动化定性研究中的理论建构，为学术界提供新颖的见解。

    

    AcademiaOS是第一个尝试利用大型语言模型自动化定性研究中的理论建构的系统。利用最近大型语言模型的语言理解、生成和推理能力，AcademiaOS对筛选过的定性原始数据（如访谈文本）进行编码，并发展主题和维度以进一步构建一个理论模型，提供新颖的见解。一项用户研究（n=19）表明，该系统在学术界中得到认可，并具有增强人类进行定性研究的潜力。AcademiaOS已经开源供他人进行构建并适应其用例。

    arXiv:2403.08844v1 Announce Type: cross  Abstract: AcademiaOS is a first attempt to automate grounded theory development in qualitative research with large language models. Using recent large language models' language understanding, generation, and reasoning capabilities, AcademiaOS codes curated qualitative raw data such as interview transcripts and develops themes and dimensions to further develop a grounded theoretical model, affording novel insights. A user study (n=19) suggests that the system finds acceptance in the academic community and exhibits the potential to augment humans in qualitative research. AcademiaOS has been made open-source for others to build upon and adapt to their use cases.
    
[^87]: 模糊故障树的形式化

    Fuzzy Fault Trees Formalized

    [https://arxiv.org/abs/2403.08843](https://arxiv.org/abs/2403.08843)

    本文提出了一个严谨的模糊不可靠性值框架，并提供了一种自下而上的算法来有效计算系统的模糊可靠性。

    

    故障树分析是评估安全风险的重要方法。它有助于识别事故潜在的原因，评估其发生的可能性和严重程度，并提出预防措施。故障树的定量分析通常通过可靠性度量来完成，该度量计算系统随时间的故障行为。然而，缺乏精确数据是定量分析以及可靠性分析的主要障碍。模糊逻辑是处理模糊值的常用框架，并在许多领域中具有应用。已经提出了许多模糊方法用于故障树分析，但据我们所知，其中没有一种提供用于计算模糊不可靠性值的严格定义或算法。在本文中，我们定义了模糊不可靠性值的严谨框架。此外，我们提供了一种自下而上的算法，用于高效计算系统的模糊可靠性。

    arXiv:2403.08843v1 Announce Type: new  Abstract: Fault tree analysis is a vital method of assessing safety risks. It helps to identify potential causes of accidents, assess their likelihood and severity, and suggest preventive measures. Quantitative analysis of fault trees is often done via the dependability metrics that compute the system's failure behaviour over time. However, the lack of precise data is a major obstacle to quantitative analysis, and so to reliability analysis. Fuzzy logic is a popular framework for dealing with ambiguous values and has applications in many domains. A number of fuzzy approaches have been proposed to fault tree analysis, but -- to the best of our knowledge -- none of them provide rigorous definitions or algorithms for computing fuzzy unreliability values. In this paper, we define a rigorous framework for fuzzy unreliability values. In addition, we provide a bottom-up algorithm to efficiently calculate fuzzy reliability for a system. The algorithm inco
    
[^88]: NoiseDiffusion：使用扩散模型校正图像插值中的噪声，超越球面线性插值

    NoiseDiffusion: Correcting Noise for Image Interpolation with Diffusion Models beyond Spherical Linear Interpolation

    [https://arxiv.org/abs/2403.08840](https://arxiv.org/abs/2403.08840)

    提出了一种名为NoiseDiffusion的新方法，可校正图像插值中的噪声，将无效的噪声逼近到预期的分布，并通过引入约束条件来抑制极端值的噪声。

    

    基于扩散模型的图像插值在创建新颖有趣的图像方面具有很大潜力。高级插值方法主要集中在球面线性插值上，其中图像被编码到噪声空间，然后进行插值以将去噪转换回图像。然而，现有方法在有效插值自然图像（而非扩散模型生成的图像）方面面临挑战，从而限制了它们的实际适用性。我们的实验调查显示，这些挑战源于编码噪声的无效性，可能不再遵循预期的噪声分布，如正态分布。为了解决这些挑战，我们提出了一种新颖的方法来校正图像插值中的噪声，NoiseDiffusion。具体而言，NoiseDiffusion通过引入微妙的高斯噪声将无效的噪声逼近到预期的分布，并引入一个约束条件来抑制具有极端值的噪声。

    arXiv:2403.08840v1 Announce Type: cross  Abstract: Image interpolation based on diffusion models is promising in creating fresh and interesting images. Advanced interpolation methods mainly focus on spherical linear interpolation, where images are encoded into the noise space and then interpolated for denoising to images. However, existing methods face challenges in effectively interpolating natural images (not generated by diffusion models), thereby restricting their practical applicability. Our experimental investigations reveal that these challenges stem from the invalidity of the encoding noise, which may no longer obey the expected noise distribution, e.g., a normal distribution. To address these challenges, we propose a novel approach to correct noise for image interpolation, NoiseDiffusion. Specifically, NoiseDiffusion approaches the invalid noise to the expected distribution by introducing subtle Gaussian noise and introduces a constraint to suppress noise with extreme values. 
    
[^89]: 基于分层轨迹表示的船舶行为预测聚类

    Predictive Clustering of Vessel Behavior Based on Hierarchical Trajectory Representation

    [https://arxiv.org/abs/2403.08838](https://arxiv.org/abs/2403.08838)

    提出了一种基于分层轨迹表示的船舶行为预测聚类方法，通过使用预测聚类和潜在编码，可以同时改善聚类和预测，并在实验证明其相对于现有方法的优越性。

    

    船舶轨迹聚类旨在寻找相似的轨迹模式，在海上应用中被广泛应用。大多数传统方法使用预定义的规则和阈值来识别离散的船舶行为，但存在无法表示演变过程的问题。为解决这一问题，本文提出了一种基于分层船舶行为预测聚类（PC-HiV）的方法。PC-HiV首先使用分层表示将每条轨迹转换为行为序列，然后基于这些表示在每个时间戳预测演化。通过应用预测聚类和潜在编码，PC-HiV可以同时改善聚类和预测。在真实AIS数据集上的实验证明了PC-HiV相对于现有方法的优越性，展示了其在捕捉船舶行为模式方面的有效性。

    arXiv:2403.08838v1 Announce Type: cross  Abstract: Vessel trajectory clustering, which aims to find similar trajectory patterns, has been widely leveraged in overwater applications. Most traditional methods use predefined rules and thresholds to identify discrete vessel behaviors. They aim for high-quality clustering and conduct clustering on entire sequences, whether the original trajectory or its sub-trajectories, failing to represent their evolution. To resolve this problem, we propose a Predictive Clustering of Hierarchical Vessel Behavior (PC-HiV). PC-HiV first uses hierarchical representations to transform every trajectory into a behavioral sequence. Then, it predicts evolution at each timestamp of the sequence based on the representations. By applying predictive clustering and latent encoding, PC-HiV improves clustering and predictions simultaneously. Experiments on real AIS datasets demonstrate PC-HiV's superiority over existing methods, showcasing its effectiveness in capturin
    
[^90]: 用于深度神经网络高效并行化的循环数据并行性

    Cyclic Data Parallelism for Efficient Parallelism of Deep Neural Networks

    [https://arxiv.org/abs/2403.08837](https://arxiv.org/abs/2403.08837)

    提出循环数据并行性，通过将微批量执行从同时改为顺序执行，以解决数据并行化中激活内存峰值和梯度平均的问题，同时还能减少所需GPU数量。

    

    训练大型深度学习模型需要并行化技术以扩展规模。在现有方法中，如数据并行性或ZeRO-DP，微批量数据被并行处理，这产生了两个缺点：在前向传递结束时模型激活所需的总内存峰值，并且梯度必须在反向传播步骤结束时同时平均。我们提出了循环数据并行性，这是一种新颖的范式，将微批量的执行从同时变为顺序执行，带有均匀的延迟。以略微梯度延迟为代价，激活所占的总内存是恒定的，并且梯度通信在训练步骤期间是平衡的。通过模型并行性，我们的技术减少了所需的GPU数量，通过在微批量之间共享GPU。在ZeRO-DP框架内，我们的技术允许使用点对点操作进行模型状态的通信，而非 t

    arXiv:2403.08837v1 Announce Type: cross  Abstract: Training large deep learning models requires parallelization techniques to scale. In existing methods such as Data Parallelism or ZeRO-DP, micro-batches of data are processed in parallel, which creates two drawbacks: the total memory required to store the model's activations peaks at the end of the forward pass, and gradients must be simultaneously averaged at the end of the backpropagation step. We propose Cyclic Data Parallelism, a novel paradigm shifting the execution of the micro-batches from simultaneous to sequential, with a uniform delay. At the cost of a slight gradient delay, the total memory taken by activations is constant, and the gradient communications are balanced during the training step. With Model Parallelism, our technique reduces the number of GPUs needed, by sharing GPUs across micro-batches. Within the ZeRO-DP framework, our technique allows communication of the model states with point-to-point operations rather t
    
[^91]: 基于结构位置编码的变压器在医疗过程监测中的知识整合

    Structural Positional Encoding for knowledge integration in transformer-based medical process monitoring

    [https://arxiv.org/abs/2403.08836](https://arxiv.org/abs/2403.08836)

    本文在医学过程监测中提出了一种基于变压器的预测性过程监测方法，通过图形位置编码技术融入本体领域特定知识，获得了令人鼓舞的实验结果。

    

    预测性过程监测是一项旨在预测正在运行的过程跟踪信息的过程挖掘任务，例如最正确的下一个要执行的活动。在医学领域，预测性过程监测可以在非典型和非平凡情况下提供有价值的决策支持。本文提出了一种依赖于变压器的预测性过程监测方法，该方法基于注意机制的深度学习架构。我们的工作的一个重要贡献在于通过图形位置编码技术融入本体领域特定知识。文章介绍并讨论了我们在医学过程监测中正在收集的令人鼓舞的实验结果。

    arXiv:2403.08836v1 Announce Type: cross  Abstract: Predictive process monitoring is a process mining task aimed at forecasting information about a running process trace, such as the most correct next activity to be executed. In medical domains, predictive process monitoring can provide valuable decision support in atypical and nontrivial situations. Decision support and quality assessment in medicine cannot ignore domain knowledge, in order to be grounded on all the available information (which is not limited to data) and to be really acceptable by end users.   In this paper, we propose a predictive process monitoring approach relying on the use of a {\em transformer}, a deep learning architecture based on the attention mechanism. A major contribution of our work lies in the incorporation of ontological domain-specific knowledge, carried out through a graph positional encoding technique. The paper presents and discusses the encouraging experimental result we are collecting in the domai
    
[^92]: 基于堆叠的深度神经网络在足球球员搜寻中的应用

    Stacking-based deep neural network for player scouting in football 1

    [https://arxiv.org/abs/2403.08835](https://arxiv.org/abs/2403.08835)

    本研究提出了一种基于堆叠的深度学习模型，在足球领域中用于检测高潜力球员，相比传统统计方法取得了显著更好的结果。

    

    DataScouting是专业体育界最知名的数据应用之一，特别是在足球领域。它的目标是分析庞大的球员数据库，以便检测潜力巨大的球员，然后由人类球探进行进一步考虑。本文提出了一种基于堆叠的深度学习模型，用于检测高潜力的足球球员。在开源数据库上应用，我们的模型取得了比传统统计方法显著更好的结果。

    arXiv:2403.08835v1 Announce Type: cross  Abstract: Datascouting is one of the most known data applications in professional sport, and specifically football. Its objective is to analyze huge database of players in order to detect high potentials that can be then individually considered by human scouts. In this paper, we propose a stacking-based deep learning model to detect high potential football players. Applied on open-source database, our model obtains significantly better results that classical statistical methods.
    
[^93]: 使用机器学习进行结核病治疗结果的预测分析：卡纳塔克邦规模的结核病数据研究

    Predictive Analysis of Tuberculosis Treatment Outcomes Using Machine Learning: A Karnataka TB Data Study at a Scale

    [https://arxiv.org/abs/2403.08834](https://arxiv.org/abs/2403.08834)

    该研究探索了如何利用机器学习和表格数据更准确地预测结核病治疗结果，并在验证集上取得了优异的性能。

    

    结核病(TB)仍然是全球健康威胁之一，在全球致死原因中排名靠前。在这种背景下，机器学习(ML)已经成为一股变革性力量，为与TB治疗相关的复杂性提供创新解决方案。本研究探讨了如何利用机器学习，特别是利用表格数据，更准确地预测结核病(TB)治疗结果。它将这个预测任务转化为一个二元分类问题，从印度的国家结核病控制项目NIKSHAY中获取的患者数据生成风险分数，该项目包括超过50万患者记录。数据预处理是研究的关键组成部分，该模型在包含2万名患者记录的验证集上实现了98%的召回率和0.95的AUC-ROC分数。我们还探讨了自然语言处理(NLP)在改进模型学习中的应用。我们的结果经过了各种考虑，

    arXiv:2403.08834v1 Announce Type: cross  Abstract: Tuberculosis (TB) remains a global health threat, ranking among the leading causes of mortality worldwide. In this context, machine learning (ML) has emerged as a transformative force, providing innovative solutions to the complexities associated with TB treatment.This study explores how machine learning, especially with tabular data, can be used to predict Tuberculosis (TB) treatment outcomes more accurately. It transforms this prediction task into a binary classification problem, generating risk scores from patient data sourced from NIKSHAY, India's national TB control program, which includes over 500,000 patient records.   Data preprocessing is a critical component of the study, and the model achieved an recall of 98% and an AUC-ROC score of 0.95 on the validation set, which includes 20,000 patient records.We also explore the use of Natural Language Processing (NLP) for improved model learning. Our results, corroborated by various m
    
[^94]: TINA: 零样本视觉语言导航的思考、交互和行动框架

    TINA: Think, Interaction, and Action Framework for Zero-Shot Vision Language Navigation

    [https://arxiv.org/abs/2403.08833](https://arxiv.org/abs/2403.08833)

    本文提出了基于大型语言模型的零样本视觉语言导航代理，并介绍了思考、互动和行动(TINA)框架，通过引入的问答模块弥补了环境感知方面的不足。

    

    零样本导航是视觉-语言导航(VLN)任务中的一个关键挑战，这里适应陌生指令并在未知环境中行动的能力至关重要。通过增强学习使用带标注数据训练的现有监督学习模型，在泛化能力方面存在局限性。大型语言模型(LLMs)以其丰富的知识和紧急推理能力，为实现零样本导航提供了一个潜在的途径。本文提出了一种基于LLMs的VLN代理，探索了解决零样本导航问题的方法。为弥补LLMs在环境感知方面的不足，我们提出了思考、互动和行动(TINA)框架。TINA使代理能够审查感知信息，并通过引入的问答模块自主查询环境中的关键线索，从而将指令与环境对齐。

    arXiv:2403.08833v1 Announce Type: cross  Abstract: Zero-shot navigation is a critical challenge in Vision-Language Navigation (VLN) tasks, where the ability to adapt to unfamiliar instructions and to act in unknown environments is essential. Existing supervised learning-based models, trained using annotated data through reinforcement learning, exhibit limitations in generalization capabilities. Large Language Models (LLMs), with their extensive knowledge and emergent reasoning abilities, present a potential pathway for achieving zero-shot navigation. This paper presents a VLN agent based on LLMs, exploring approaches to the zero-shot navigation problem. To compensate for the shortcomings of LLMs in environmental perception, we propose the Thinking, Interacting, and Action (TINA) framework. TINA enables the agent to scrutinize perceptual information and autonomously query key clues within the environment through an introduced question-answering module, thereby aligning instructions with
    
[^95]: 当解释自主车辆的行为时，人们会给予其属性目的

    People Attribute Purpose to Autonomous Vehicles When Explaining Their Behavior

    [https://arxiv.org/abs/2403.08828](https://arxiv.org/abs/2403.08828)

    人们会给自主车辆的行为赋予目的属性，并在生成解释和评估这些解释时表现出对目的论解释的倾向。

    

    一款优秀的可解释人工智能系统的标志是用户可以理解并采取行动的解释。许多情况下，这需要系统提供可理解的因果或反事实解释。认知科学可以帮助我们理解用户可能期望的解释类型，以及在哪种格式下呈现这些解释。本文简要回顾了认知科学解释方面的相关文献，特别关注目的论，即以达到目的为解释决策的倾向。然后，我们报告了人们如何为自主车辆的行为产生解释以及他们如何评估这些解释的经验数据。在第一项调查中，参与者（n = 54）观看了道路场景的视频，并被要求为车辆的行为生成机械的、反事实的或目的论的言语解释。在第二项调查中，另一组参与者（n = 356）对这些进行评分。

    arXiv:2403.08828v1 Announce Type: cross  Abstract: A hallmark of a good XAI system is explanations that users can understand and act on. In many cases, this requires a system to offer causal or counterfactual explanations that are intelligible. Cognitive science can help us understand what kinds of explanations users might expect, and in which format to frame these explanations. We briefly review relevant literature from the cognitive science of explanation, particularly as it concerns teleology, the tendency to explain a decision in terms of the purpose it was meant to achieve. We then report empirical data on how people generate explanations for the behavior of autonomous vehicles, and how they evaluate these explanations. In a first survey, participants (n=54) were shown videos of a road scene and asked to generate either mechanistic, counterfactual, or teleological verbal explanations for a vehicle's actions. In the second survey, a different set of participants (n=356) rated these
    
[^96]: 衡量非典型情绪对心理健康的影响：计算方法调查

    Measuring Non-Typical Emotions for Mental Health: A Survey of Computational Approaches

    [https://arxiv.org/abs/2403.08824](https://arxiv.org/abs/2403.08824)

    本调查是第一次同时探索用于分析压力、抑郁和投入度的计算方法，并讨论了最常用的数据集、输入模态、数据处理技术和信息融合方法。

    

    非典型情绪（如压力、抑郁和投入度分析）相较于经常讨论的情绪（如快乐、悲伤、恐惧和愤怒）来说，更为罕见且复杂。由于对心理健康和幸福的影响，人们对这些非典型情绪的重要性越来越认识到。压力和抑郁影响了日常任务的参与，突显了理解它们相互作用的必要性。本调查是第一次同时探索用于分析压力、抑郁和投入度的计算方法。我们讨论了用于计算分析压力、抑郁和投入度的最常用的数据集、输入模态、数据处理技术和信息融合方法。我们提供了非典型情绪分析方法的时间表和分类法，以及它们的通用流程和类别。随后，我们描述了最先进的计算方法。

    arXiv:2403.08824v1 Announce Type: cross  Abstract: Analysis of non-typical emotions, such as stress, depression and engagement is less common and more complex compared to that of frequently discussed emotions like happiness, sadness, fear, and anger. The importance of these non-typical emotions has been increasingly recognized due to their implications on mental health and well-being. Stress and depression impact the engagement in daily tasks, highlighting the need to understand their interplay. This survey is the first to simultaneously explore computational methods for analyzing stress, depression, and engagement. We discuss the most commonly used datasets, input modalities, data processing techniques, and information fusion methods used for the computational analysis of stress, depression and engagement. A timeline and taxonomy of non-typical emotion analysis approaches along with their generic pipeline and categories are presented. Subsequently, we describe state-of-the-art computa
    
[^97]: Diet-ODIN：一种新型框架，用于解释性膳食模式下的阿片类药物误用检测

    Diet-ODIN: A Novel Framework for Opioid Misuse Detection with Interpretable Dietary Patterns

    [https://arxiv.org/abs/2403.08820](https://arxiv.org/abs/2403.08820)

    该研究建立了一个大规模多方面的膳食数据集，提出了Diet-ODIN框架，旨在探索膳食模式与阿片类药物误用之间的关联。

    

    阿片类药物危机一直是美国社会最关键的问题之一。尽管药物辅助治疗（MAT）被认为是阿片类药物误用和成瘾最有效的治疗方法，但各种副作用可能引发阿片类药物再次滥用。除MAT外，膳食营养干预在防止和康复阿片类药物误用中发挥了重要作用。然而，有关膳食模式与阿片类药物误用之间令人担忧的关联的研究仍未得到充分探讨。为弥补这一空白，本文首次建立了一个与阿片类药物使用者相关的大规模多方面膳食基准数据集，并开发了一个新颖框架，即解释性膳食模式下的阿片类药物误用检测（Diet-ODIN），用于连接异质图（HG）和大型语言模型（LLM），以识别阿片类药物误用者并解释其行为。

    arXiv:2403.08820v1 Announce Type: cross  Abstract: The opioid crisis has been one of the most critical society concerns in the United States. Although the medication assisted treatment (MAT) is recognized as the most effective treatment for opioid misuse and addiction, the various side effects can trigger opioid relapse. In addition to MAT, the dietary nutrition intervention has been demonstrated its importance in opioid misuse prevention and recovery. However, research on the alarming connections between dietary patterns and opioid misuse remain under-explored. In response to this gap, in this paper, we first establish a large-scale multifaceted dietary benchmark dataset related to opioid users at the first attempt and then develop a novel framework - i.e., namely Opioid Misuse Detection with Interpretable Dietary Patterns (Diet-ODIN) - to bridge heterogeneous graph (HG) and large language model (LLM) for the identification of users with opioid misuse and the interpretation of their a
    
[^98]: 结构和语义的电子健康记录多模态融合：将临床记录和笔记与超图和LLM集成

    Multimodal Fusion of EHR in Structures and Semantics: Integrating Clinical Records and Notes with Hypergraph and LLM

    [https://arxiv.org/abs/2403.08818](https://arxiv.org/abs/2403.08818)

    提出了一个名为MINGLE的新框架，通过两级注入策略将医学概念语义和临床笔记语义融合到超图中，有效地整合了结构和语义的电子健康记录数据。

    

    电子健康记录（EHRs）在近几十年来越来越受欢迎，支持临床决策和医疗保健。EHRs通常包含异构信息，如表格形式的结构化数据和文本笔记中的非结构化数据。EHRs中的不同类型信息可以相互补充，提供患者健康状态的更完整图片。尽管对结构化EHR数据的表示学习进行了大量研究，但不同类型EHR数据的融合（多模态融合）尚未得到充分研究。这主要是由于医疗编码系统的复杂性和书面笔记中存在的噪音和冗余。在这项工作中，我们提出了一个名为MINGLE的新框架，有效地将EHR中的结构和语义结合起来。我们的框架使用两级注入策略将医学概念语义和临床笔记语义融合到超图中。

    arXiv:2403.08818v1 Announce Type: cross  Abstract: Electronic Health Records (EHRs) have become increasingly popular to support clinical decision-making and healthcare in recent decades. EHRs usually contain heterogeneous information, such as structural data in tabular form and unstructured data in textual notes. Different types of information in EHRs can complement each other and provide a more complete picture of the health status of a patient. While there has been a lot of research on representation learning of structured EHR data, the fusion of different types of EHR data (multimodal fusion) is not well studied. This is mostly because of the complex medical coding systems used and the noise and redundancy present in the written notes. In this work, we propose a new framework called MINGLE, which integrates both structures and semantics in EHR effectively. Our framework uses a two-level infusion strategy to combine medical concept semantics and clinical note semantics into hypergrap
    
[^99]: 联合深度Q学习与5G负载平衡

    Federated Deep Q-Learning and 5G load balancing

    [https://arxiv.org/abs/2403.08813](https://arxiv.org/abs/2403.08813)

    本研究提出并分析了一个联合深度Q学习负载平衡系统，利用Open-RAN xAPP框架和近实时射频接口控制器（near-RT RIC）实施。我们的模拟结果表明，与目前UE使用的最大信噪比（MAX-SINR）方法相比，我们提出的深度Q学习模型可以持续提供更好的负载平衡性能。

    

    尽管蜂窝网络技术取得了进展，基站（BS）负载平衡仍然是一个持久性问题。虽然集中资源分配方法可以解决负载平衡问题，但仍然是一个NP难问题。本研究研究了如何利用联合深度Q学习来通知每个用户设备（UE）各个BS的负载情况。联合深度Q学习的负载平衡使得智能UE可以独立选择最佳BS，同时限制了向网络暴露的私人信息量。

    arXiv:2403.08813v1 Announce Type: cross  Abstract: Despite advances in cellular network technology, base station (BS) load balancing remains a persistent problem. Although centralized resource allocation methods can address the load balancing problem, it still remains an NP-hard problem. In this research, we study how federated deep Q learning can be used to inform each user equipment (UE) of the each BS's load conditions. Federated deep Q learning's load balancing enables intelligent UEs to independently select the best BS while also limiting the amount of private information exposed to the network.   In this study, we propose and analyze a federated deep Q learning load balancing system, which is implemented using the Open-RAN xAPP framework and the near-Real Time Radio Interface Controller (near-RT RIC). Our simulation results indicate that compared to the maximum Signal-To-Noise-Ratio (MAX-SINR) method currently used by UEs, our proposed deep Q learning model can consistently provi
    
[^100]: 在物联网架构中比较边缘计算方法，用于高效估计室内环境参数与机器学习

    Comparison of edge computing methods in Internet of Things architectures for efficient estimation of indoor environmental parameters with Machine Learning

    [https://arxiv.org/abs/2403.08810](https://arxiv.org/abs/2403.08810)

    本研究提出了两种基于低成本边缘物联网架构的方法，用于实现估计室内环境质量参数的轻量级机器学习模型，为物联网架构中进行高效数据处理提供了新思路。

    

    互联网物联设备数量的大幅增加已经彻底改变了数据处理方式，加上目前从云计算转向边缘计算的趋势迫使我们需要使用能源高效的设备在数据源附近进行高效可靠的数据处理。文章提出了两种基于低成本边缘物联网架构的方法，用于实现轻量级机器学习模型，用以估计室内环境质量参数，比如多层感知器类型的人工神经网络。这些方法基于集中式和分布式并行物联网架构实现，通过无线连接，共享商用模块进行数据采集和传感，比如温度、湿度、照度、CO2和其他气体传感器。集中式方法使用图形处理单元和消息队列遥测传输协议，而分布式方法

    arXiv:2403.08810v1 Announce Type: cross  Abstract: The large increase in the number of Internet of Things (IoT) devices have revolutionised the way data is processed, which added to the current trend from cloud to edge computing has resulted in the need for efficient and reliable data processing near the data sources using energy-efficient devices. Two methods based on low-cost edge-IoT architectures are proposed to implement lightweight Machine Learning (ML) models that estimate indoor environmental quality (IEQ) parameters, such as Artificial Neural Networks of Multilayer Perceptron type. Their implementation is based on centralised and distributed parallel IoT architectures, connected via wireless, which share commercial off-the-self modules for data acquisition and sensing, such as sensors for temperature, humidity, illuminance, CO2, and other gases. The centralised method uses a Graphics Processing Unit and the Message Queuing Telemetry Transport protocol, but the distributed meth
    
[^101]: 一种仿生数据驱动长距离水下导航方法及其抗异常性

    A Bionic Data-driven Approach for Long-distance Underwater Navigation with Anomaly Resistance

    [https://arxiv.org/abs/2403.08808](https://arxiv.org/abs/2403.08808)

    提出了一种仿生和数据驱动的长距离水下导航方法，利用地磁数据进行导航并通过开发机制和模型校准来增强抗异常性

    

    各种动物利用环境线索展现了准确导航的能力。地球的磁场已被证明是长距离动物迁徙中可靠的信息来源。受动物导航的启发，本文提出了一种用于长距离水下导航的仿生和数据驱动方法。所提出的方法利用测量的地磁数据进行导航，无需GPS系统或地理地图。特别地，我们构建和训练了一个基于时间注意力的长短期记忆（TA-LSTM）网络，用于在导航过程中预测航向角。为了减轻地磁异常的影响，我们开发了一种机制，基于最大似然估计来检测和量化异常。我们将开发的机制与TA-LSTM集成，并校准预测的航向角以增强对地磁异常的抵抗能力。利用从WMM模型获取的数据，我们进行了数值模拟。

    arXiv:2403.08808v1 Announce Type: cross  Abstract: Various animals exhibit accurate navigation using environment cues. The Earth's magnetic field has been proved a reliable information source in long-distance fauna migration. Inspired by animal navigation, this work proposes a bionic and data-driven approach for long-distance underwater navigation. The proposed approach uses measured geomagnetic data for the navigation, and requires no GPS systems or geographical maps. Particularly, we construct and train a Temporal Attention-based Long Short-Term Memory (TA-LSTM) network to predict the heading angle during the navigation. To mitigate the impact of geomagnetic anomalies, we develop the mechanism to detect and quantify the anomalies based on Maximum Likelihood Estimation. We integrate the developed mechanism with the TA-LSTM, and calibrate the predicted heading angles to gain resistance against geomagnetic anomalies. Using the retrieved data from the WMM model, we conduct numerical simu
    
[^102]: 多目标组合优化问题的有效即时算法

    Effective anytime algorithm for multiobjective combinatorial optimization problems

    [https://arxiv.org/abs/2403.08807](https://arxiv.org/abs/2403.08807)

    提出了一种新的准确即时算法，用于多目标组合优化，结合了三种新颖的思想以增强即时性能

    

    在多目标优化中，优化算法的结果是一组有效解，决策者从中选择一个。常见情况是，并非所有有效解都能在短时间内计算出来，搜索算法必须过早停止以分析到目前为止找到的解。决策者更喜欢在客观空间中分布良好的一组有效解，以提供各种解决方案。然而，文献中只有少数几种确切的算法能够在任何时刻提供这样一组分布良好的解：我们称之为即时算法。我们提出了一种新的准确即时算法，用于多目标组合优化，结合了三种新颖的思想以增强即时性能。我们将所提出的算法与现有于当今最先进的即时多目标组合优化算法进行比较，使用一组480个实例。

    arXiv:2403.08807v1 Announce Type: cross  Abstract: In multiobjective optimization, the result of an optimization algorithm is a set of efficient solutions from which the decision maker selects one. It is common that not all the efficient solutions can be computed in a short time and the search algorithm has to be stopped prematurely to analyze the solutions found so far. A set of efficient solutions that are well-spread in the objective space is preferred to provide the decision maker with a great variety of solutions. However, just a few exact algorithms in the literature exist with the ability to provide such a well-spread set of solutions at any moment: we call them anytime algorithms. We propose a new exact anytime algorithm for multiobjective combinatorial optimization combining three novel ideas to enhance the anytime behavior. We compare the proposed algorithm with those in the state-of-the-art for anytime multiobjective combinatorial optimization using a set of 480 instances fr
    
[^103]: 企业中生成式人工智能的治理

    Governance of Generative Artificial Intelligence for Companies

    [https://arxiv.org/abs/2403.08802](https://arxiv.org/abs/2403.08802)

    本综述填补了有关企业中生成式人工智能（GenAI）治理的研究空白，提出了一个框架，旨在利用业务机会并减轻与GenAI整合相关风险。

    

    生成式人工智能（GenAI），特别是像ChatGPT这样的大型语言模型，已迅速进入企业，但缺乏充分的治理，带来机遇和挑战。尽管对GenAI具有变革性质和监管措施的广泛讨论，但有限的研究涉及组织治理，包括技术和业务视角。本综述填补了这一空白，调查了最近的研究。它不仅仅是总结，还通过制定适用于企业内的GenAI治理框架来进行。我们的框架详细描述了范围、目标和治理机制，旨在利用业务机会并减轻与GenAI整合相关风险。该研究提供了一种专注于GenAI治理的方法，为企业在负责任的AI采用挑战中提供了实用见解。对于技术人员来说，也有助于拓宽他们的视角。

    arXiv:2403.08802v1 Announce Type: new  Abstract: Generative Artificial Intelligence (GenAI), specifically large language models like ChatGPT, has swiftly entered organizations without adequate governance, posing both opportunities and risks. Despite extensive debates on GenAI's transformative nature and regulatory measures, limited research addresses organizational governance, encompassing technical and business perspectives. This review paper fills this gap by surveying recent works. It goes beyond mere summarization by developing a framework for GenAI governance within companies. Our framework outlines the scope, objectives, and governance mechanisms tailored to harness business opportunities and mitigate risks associated with GenAI integration. This research contributes a focused approach to GenAI governance, offering practical insights for companies navigating the challenges of responsible AI adoption. It is also valuable for a technical audience to broaden their perspective as inc
    
[^104]: 模拟分子进化的进化算法：一个新领域的提议

    Evolutionary Algorithms Simulating Molecular Evolution: A New Field Proposal

    [https://arxiv.org/abs/2403.08797](https://arxiv.org/abs/2403.08797)

    通过融合进化算法、机器学习和生物信息学，提出了一个计算方法来扩展自然蛋白质“词汇量”，以开发从未存在过的全新蛋白质。

    

    生命活动的基本功能基因蓝图编码在DNA中，转译为蛋白质--推动大多数代谢过程的引擎。最近的基因组测序进展揭示了大量的蛋白质家族，但与所有可能的氨基酸序列的巨大搜索空间相比，已知的功能家族集合很小。一个问题是，自然具有有限的蛋白质“词汇量”。因此，计算生物学家的一个主要问题是，这个词汇量是否可以扩展，以包括很久以前灭绝或者从未在第一次进化中出现的有用蛋白质。我们概述了解决这个问题的计算方法。通过融合进化算法、机器学习（ML）和生物信息学，我们可以促进开发从未存在过的全新蛋白质。我们设想这项工作将形成计算进化的新的子领域。

    arXiv:2403.08797v1 Announce Type: cross  Abstract: The genetic blueprint for the essential functions of life is encoded in DNA, which is translated into proteins -- the engines driving most of our metabolic processes. Recent advancements in genome sequencing have unveiled a vast diversity of protein families, but compared to the massive search space of all possible amino acid sequences, the set of known functional families is minimal. One could say nature has a limited protein "vocabulary." The major question for computational biologists, therefore, is whether this vocabulary can be expanded to include useful proteins that went extinct long ago, or maybe never evolved in the first place. We outline a computational approach to solving this problem. By merging evolutionary algorithms, machine learning (ML), and bioinformatics, we can facilitate the development of completely novel proteins which have never existed before. We envision this work forming a new sub-field of computational evol
    
[^105]: 使用顺序运行时间分布对SAT本地搜索的并行加速预测

    Using Sequential Runtime Distributions for the Parallel Speedup Prediction of SAT Local Search

    [https://arxiv.org/abs/2403.08790](https://arxiv.org/abs/2403.08790)

    通过分析顺序版本的运行时行为来预测给定算法的并行性能，本文提出了一种使用顺序运行时间分布进行SAT本地搜索并行加速预测的方法，并在实验中展示了模型准确预测性能的能力。

    

    本文对可满足性问题的本地搜索算法的可扩展性和并行化进行了详细分析。我们提出了一个框架来通过分析其顺序版本的运行时行为来估计给定算法的并行性能。通过用统计方法近似顺序过程的运行时间分布，可以基于顺序统计量建立模型来预测并行过程的运行时行为。我们将这种方法应用于研究两种SAT本地搜索求解器，即Sparrow和CCASAT的并行性能，并将预测的性能与在高达384个核心的并行硬件上进行的实际实验结果进行比较。我们展示了该模型的准确性，并预测性能接近经验数据。此外，当我们研究不同类型的实例（随机和精心设计）时，我们观察到本地搜索求解器表现出不同的行为。

    arXiv:2403.08790v1 Announce Type: cross  Abstract: This paper presents a detailed analysis of the scalability and parallelization of local search algorithms for the Satisfiability problem. We propose a framework to estimate the parallel performance of a given algorithm by analyzing the runtime behavior of its sequential version. Indeed, by approximating the runtime distribution of the sequential process with statistical methods, the runtime behavior of the parallel process can be predicted by a model based on order statistics. We apply this approach to study the parallel performance of two SAT local search solvers, namely Sparrow and CCASAT, and compare the predicted performances to the results of an actual experimentation on parallel hardware up to 384 cores. We show that the model is accurate and predicts performance close to the empirical data. Moreover, as we study different types of instances (random and crafted), we observe that the local search solvers exhibit different behavior
    
[^106]: 将人类概念与计算机视觉相结合，实现可解释的人脸验证

    Bridging Human Concepts and Computer Vision for Explainable Face Verification

    [https://arxiv.org/abs/2403.08789](https://arxiv.org/abs/2403.08789)

    本文通过结合计算机和人类视觉的方法，提高了人脸验证算法解释的可解释性

    

    人工智能(AI)影响了敏感应用程序(如人脸验证)的决策过程，因此确保决策的透明性、公平性和问责制非常重要。尽管存在可解释的人工智能(XAI)技术用于澄清AI决策，但同样重要的是为人类提供这些决策的可解释性。本文提出了一种方法，结合计算机和人类视觉，增加了人脸验证算法解释的可解释性。具体而言，我们受到人类感知过程的启发，以了解机器在人脸比较任务期间如何感知人类语义区域。我们使用Mediapipe提供的分割技术，可以识别出不同的人类语义面部区域，从而实现机器的感知分析。此外，我们还调整了两种模型不可知算法，以提供人类可解释性

    arXiv:2403.08789v1 Announce Type: cross  Abstract: With Artificial Intelligence (AI) influencing the decision-making process of sensitive applications such as Face Verification, it is fundamental to ensure the transparency, fairness, and accountability of decisions. Although Explainable Artificial Intelligence (XAI) techniques exist to clarify AI decisions, it is equally important to provide interpretability of these decisions to humans. In this paper, we present an approach to combine computer and human vision to increase the explanation's interpretability of a face verification algorithm. In particular, we are inspired by the human perceptual process to understand how machines perceive face's human-semantic areas during face comparison tasks. We use Mediapipe, which provides a segmentation technique that identifies distinct human-semantic facial regions, enabling the machine's perception analysis. Additionally, we adapted two model-agnostic algorithms to provide human-interpretable i
    
[^107]: 针对目标检测的验证--IBP IoU

    Verification for Object Detection -- IBP IoU

    [https://arxiv.org/abs/2403.08788](https://arxiv.org/abs/2403.08788)

    介绍了一种针对目标检测模型的新颖区间边界传播（IBP）方法，IBP IoU在确保准确性和稳定性方面表现出色，为更安全和更稳健的机器学习应用做出贡献。

    

    我们介绍了一种新颖的区间边界传播（IBP）方法，用于形式验证对象检测模型，特别针对交并比（IoU）度量。该方法已在一个名为IBP IoU的开源代码中实现，与流行的基于抽象解释的验证工具兼容。该验证器在着陆途径跑道检测和手写数字识别案例研究上进行了评估。与基线（Vanilla IBP IoU）的比较突出了IBP IoU在确保准确性和稳定性方面的出色性能，有助于实现更安全和更稳健的机器学习应用。

    arXiv:2403.08788v1 Announce Type: cross  Abstract: We introduce a novel Interval Bound Propagation (IBP) approach for the formal verification of object detection models, specifically targeting the Intersection over Union (IoU) metric. The approach has been implemented in an open source code, named IBP IoU, compatible with popular abstract interpretation based verification tools. The resulting verifier is evaluated on landing approach runway detection and handwritten digit recognition case studies. Comparisons against a baseline (Vanilla IBP IoU) highlight the superior performance of IBP IoU in ensuring accuracy and stability, contributing to more secure and robust machine learning applications.
    
[^108]: 一次脉冲SNN：基于基本操作的单脉冲相位编码用于减少从ANN到SNN的转换损失

    One-Spike SNN: Single-Spike Phase Coding with Base Manipulation for ANN-to-SNN Conversion Loss Minimization

    [https://arxiv.org/abs/2403.08786](https://arxiv.org/abs/2403.08786)

    提出了一种单脉冲相位编码的编码方案，通过阈值偏移和基本操作来减少从ANN到SNN的转换损失，无需额外重新训练或架构约束。

    

    随着脉冲神经网络（SNN）是事件驱动的，能效比传统人工神经网络（ANN）更高。由于SNN通过离散脉冲传递数据，难以使用梯度方法进行训练，限制了其准确性。为了保持SNN的准确性与ANN相似，需要将预先训练的ANN转换为SNN（即从ANN到SNN的转换）。在转换过程中，将ANN的激活编码成一组脉冲在SNN中是关键的，以最小化转换损失。本文提出了一种单脉冲相位编码作为一种编码方案，该方案最小化了在SNN层之间传输数据所需的脉冲数量。为了减少相位编码中由单脉冲近似导致的编码误差，提出了阈值偏移和基本操作。在ANN上没有额外的重新训练或架构约束的情况下，该转换方法不会失去推理准确性（平均为0.58%）。

    arXiv:2403.08786v1 Announce Type: cross  Abstract: As spiking neural networks (SNNs) are event-driven, energy efficiency is higher than conventional artificial neural networks (ANNs). Since SNN delivers data through discrete spikes, it is difficult to use gradient methods for training, limiting its accuracy. To keep the accuracy of SNNs similar to ANN counterparts, pre-trained ANNs are converted to SNNs (ANN-to-SNN conversion). During the conversion, encoding activations of ANNs to a set of spikes in SNNs is crucial for minimizing the conversion loss. In this work, we propose a single-spike phase coding as an encoding scheme that minimizes the number of spikes to transfer data between SNN layers. To minimize the encoding error due to single-spike approximation in phase coding, threshold shift and base manipulation are proposed. Without any additional retraining or architectural constraints on ANNs, the proposed conversion method does not lose inference accuracy (0.58% on average) verif
    
[^109]: 使用合成多模态虚假信息检测的图像文本脱离语境方法

    Image-Text Out-Of-Context Detection Using Synthetic Multimodal Misinformation

    [https://arxiv.org/abs/2403.08783](https://arxiv.org/abs/2403.08783)

    该研究提出了一种使用合成数据生成的脱离语境检测方法，实验证实了合成数据生成在解决OOCD相关数据限制方面的有效性。

    

    在数字信息不断增加的时代，虚假信息已经成为一个重大挑战，需要开发有效的检测方法。我们研究了一种新颖的脱离语境检测（OOCD）方法，该方法使用了合成数据生成。我们创建了一个专门用于OOCD的数据集，并开发了一个高效的检测器进行准确分类。我们的实验发现验证了合成数据生成的使用，并展示了其在解决与OOCD相关的数据限制方面的有效性。该数据集和检测器应成为未来研究和开发健壮虚假信息检测系统的宝贵资源。

    arXiv:2403.08783v1 Announce Type: cross  Abstract: Misinformation has become a major challenge in the era of increasing digital information, requiring the development of effective detection methods. We have investigated a novel approach to Out-Of-Context detection (OOCD) that uses synthetic data generation. We created a dataset specifically designed for OOCD and developed an efficient detector for accurate classification. Our experimental findings validate the use of synthetic data generation and demonstrate its efficacy in addressing the data limitations associated with OOCD. The dataset and detector should serve as valuable resources for future research and the development of robust misinformation detection systems.
    
[^110]: 利用风格转移实现程序化地形生成

    Procedural terrain generation with style transfer

    [https://arxiv.org/abs/2403.08782](https://arxiv.org/abs/2403.08782)

    介绍了一种结合程序化生成和神经风格转移的技术，用于生成地形地图，具有更大的灵活性、更低硬件需求和更好的整合性，在地形生成过程中能够产生与真实世界景观形态特征密切相关的地形结构。

    

    在本研究中，我们介绍了一种新的技术用于生成地形地图，利用了程序化生成和神经风格转移的组合。我们认为我们的方法是与竞争性生成模型的可行替代方案，我们的技术实现了更大的灵活性、更低的硬件需求，并在设计师和开发人员的创造过程中有更好的整合性。我们的方法涉及使用多层平滑的高斯噪声或Perlin算法生成程序化噪声地图。然后我们利用增强的神经风格转移技术，从现实世界的高度地图中提取风格。这种算法生成和神经处理的融合有潜力产生不仅多样化而且与现实世界景观形态特征密切相关的地形，我们的过程以低计算成本产生一致的地形结构并提供了的capab

    arXiv:2403.08782v1 Announce Type: cross  Abstract: In this study we introduce a new technique for the generation of terrain maps, exploiting a combination of procedural generation and Neural Style Transfer. We consider our approach to be a viable alternative to competing generative models, with our technique achieving greater versatility, lower hardware requirements and greater integration in the creative process of designers and developers. Our method involves generating procedural noise maps using either multi-layered smoothed Gaussian noise or the Perlin algorithm. We then employ an enhanced Neural Style transfer technique, drawing style from real-world height maps. This fusion of algorithmic generation and neural processing holds the potential to produce terrains that are not only diverse but also closely aligned with the morphological characteristics of real-world landscapes, with our process yielding consistent terrain structures with low computational cost and offering the capab
    
[^111]: 利用基于聊天的大规模视觉语言模型进行多模态脱离上下文检测

    Leveraging Chat-Based Large Vision Language Models for Multimodal Out-Of-Context Detection

    [https://arxiv.org/abs/2403.08776](https://arxiv.org/abs/2403.08776)

    LVLMs在多模态脱离上下文检测任务中表现不佳，但在进行微调后可以进一步提高准确性。

    

    脱离上下文（OOC）检测是一项具有挑战性的任务，涉及识别出上下文中呈现的与图像和文本无关的内容。大型视觉语言模型（LVLMs）在各种任务中表现出效果，包括图像分类和文本生成。然而，LVLMs在多模态OOC检测任务中的熟练程度尚不清楚。在本文中，我们调查了LVLMs检测多模态OOC的能力，并展示这些模型在没有微调的情况下无法在OOC检测任务上达到高准确率。然而，我们证明了在多模态OOC数据集上微调LVLMs可以进一步提高其OOC检测准确性。为了评估LVLMs在OOC检测任务中的性能，我们在NewsCLIPpings数据集上对MiniGPT-4进行微调，该数据集是一个大型的多模态OOC数据集。我们的结果显示，对MiniGPT-4在NewsCLIPpings数据集上进行微调显著提高了该数据集中的OOC检测准确率。

    arXiv:2403.08776v1 Announce Type: cross  Abstract: Out-of-context (OOC) detection is a challenging task involving identifying images and texts that are irrelevant to the context in which they are presented. Large vision-language models (LVLMs) are effective at various tasks, including image classification and text generation. However, the extent of their proficiency in multimodal OOC detection tasks is unclear. In this paper, we investigate the ability of LVLMs to detect multimodal OOC and show that these models cannot achieve high accuracy on OOC detection tasks without fine-tuning. However, we demonstrate that fine-tuning LVLMs on multimodal OOC datasets can further improve their OOC detection accuracy. To evaluate the performance of LVLMs on OOC detection tasks, we fine-tune MiniGPT-4 on the NewsCLIPpings dataset, a large dataset of multimodal OOC. Our results show that fine-tuning MiniGPT-4 on the NewsCLIPpings dataset significantly improves the OOC detection accuracy in this datas
    
[^112]: 基于约束的强化学习用于分布式SDN中的自适应控制器同步

    Constrained Reinforcement Learning for Adaptive Controller Synchronization in Distributed SDN

    [https://arxiv.org/abs/2403.08775](https://arxiv.org/abs/2403.08775)

    该论文提出了一种基于约束的强化学习方法，在分布式SDN中实现自适应控制器同步，以解决优化通信延迟和负载平衡之间的平衡问题，特别适用于对网络延迟和计算资源要求严格的应用。

    

    在软件定义网络(SDN)中，分布式SDN控制器的实现起着至关重要的作用，每个控制器负责管理特定的子网络或域，以在集中化控制、可伸缩性、可靠性和网络效率之间实现平衡。这些控制器必须同步以保持对整个网络的逻辑集中视图。尽管有各种方法可以用于同步分布式SDN控制器，但大多数倾向于优先考虑诸如优化通信延迟或负载平衡等目标，通常忽视同时解决这两个方面。在考虑诸如增强现实和虚拟现实（AR/VR）等需求受到限制的网络延迟和大量计算资源的应用时，这种限制尤为显著。此外，许多现有研究在这一领域主要依赖基于值的强化学习

    arXiv:2403.08775v1 Announce Type: cross  Abstract: In software-defined networking (SDN), the implementation of distributed SDN controllers, with each controller responsible for managing a specific sub-network or domain, plays a critical role in achieving a balance between centralized control, scalability, reliability, and network efficiency. These controllers must be synchronized to maintain a logically centralized view of the entire network. While there are various approaches for synchronizing distributed SDN controllers, most tend to prioritize goals such as optimization of communication latency or load balancing, often neglecting to address both the aspects simultaneously. This limitation becomes particularly significant when considering applications like Augmented and Virtual Reality (AR/VR), which demand constrained network latencies and substantial computational resources. Additionally, many existing studies in this field predominantly rely on value-based reinforcement learning (
    
[^113]: 论循环扩展及引入序列切割函数至局部势近似的讨论：利用Green函数的复杂性分析，切割第N阶社会互动以促进行为安全

    Discussion of Loop Expansion and Introduction of Series Cutting Functions to Local Potential Approximation: Complexity Analysis Using Green's Functions, Cutting Of Nth-Order Social Interactions For Progressive Safety

    [https://arxiv.org/abs/2403.08774](https://arxiv.org/abs/2403.08774)

    论文使用Green函数方法研究过滤泡泡现象，并通过循环扩展方法讨论社会互动复杂性，引入序列函数评估影响。

    

    本研究聚焦于前述论文《2024年“检验Kubo-Matsubara Green函数的Edwards-Anderson模型：利用复制法进行零现象的N阶插值外推的极值信息流》。本文也应用理论物理方法来更好地理解过滤泡泡现象，特别关注循环扩展和截断函数。采用循环扩展方法，将讨论在过滤泡泡发生期间的社会互动复杂性，以引入序列，进行数学表达，并评估这些互动的影响。我们使用各种Green函数，包括延迟Green函数、先进Green函数和因果Green函数，来分析代理人及其时间演变之间的互动，通过局部势近似捕捉系统的动态响应。

    arXiv:2403.08774v1 Announce Type: cross  Abstract: In this study, we focus on the aforementioned paper, "Examination Kubo-Matsubara Green's Function Of The Edwards-Anderson Model: Extreme Value Information Flow Of Nth-Order Interpolated Extrapolation Of Zero Phenomena Using The Replica Method (2024)". This paper also applies theoretical physics methods to better understand the filter bubble phenomenon, focusing in particular on loop expansions and truncation functions. Using the loop expansion method, the complexity of social interactions during the occurrence of filter bubbles will be discussed in order to introduce series, express mathematically, and evaluate the impact of these interactions. We analyze the interactions between agents and their time evolution using a variety of Green's functions, including delayed Green's functions, advanced Green's functions, and causal Green's functions, to capture the dynamic response of the system through local potential approximations. In additi
    
[^114]: Veagle: 多模态表示学习的进展

    Veagle: Advancements in Multimodal Representation Learning

    [https://arxiv.org/abs/2403.08773](https://arxiv.org/abs/2403.08773)

    本文介绍了一种新颖的方法，通过在当前视觉语言模型（VLMs）和多模态大语言模型（MLLMs）的基础上融合独特的机制，以增强现有模型的多模态能力。

    

    最近，人工智能领域的研究人员对语言和视觉如何结合产生了浓厚兴趣，从而催生了旨在无缝整合文本和视觉信息的多模态模型的发展。多模态模型是大型语言模型（LLMs）的延伸，在解决各种任务方面展现出了显著的能力，范围从图像字幕和视觉问答（VQA）到视觉定位。虽然这些模型展示了显著的进展，但在准确解释图像并回答问题方面仍存在挑战，在现实场景中经常发生。本文介绍了一种增强现有模型多模态能力的新方法。针对当前视觉语言模型（VLMs）和多模态大语言模型（MLLMs）中观察到的局限性，我们提出的模型Veagle，融合了受...

    arXiv:2403.08773v1 Announce Type: cross  Abstract: Lately, researchers in artificial intelligence have been really interested in how language and vision come together, giving rise to the development of multimodal models that aim to seamlessly integrate textual and visual information. Multimodal models, an extension of Large Language Models (LLMs), have exhibited remarkable capabilities in addressing a diverse array of tasks, ranging from image captioning and visual question answering (VQA) to visual grounding. While these models have showcased significant advancements, challenges persist in accurately interpreting images and answering the question, a common occurrence in real-world scenarios. This paper introduces a novel approach to enhance the multimodal capabilities of existing models. In response to the limitations observed in current Vision Language Models (VLMs) and Multimodal Large Language Models (MLLMs), our proposed model Veagle, incorporates a unique mechanism inspired by th
    
[^115]: 高斯图像：通过2D高斯喷涂进行1000帧每秒的图像表示和压缩

    GaussianImage: 1000 FPS Image Representation and Compression by 2D Gaussian Splatting

    [https://arxiv.org/abs/2403.08551](https://arxiv.org/abs/2403.08551)

    通过2D高斯喷涂实现图像表示和压缩，在GPU内存占用降低的情况下，提供了更快的渲染速度，并在表示性能上与INR相匹敌。

    

    最近，隐式神经表示（INR）在图像表示和压缩方面取得了巨大成功，提供了高视觉质量和快速渲染速度，每秒10-1000帧，假设有足够的GPU资源可用。然而，这种要求常常阻碍了它们在内存有限的低端设备上的使用。为此，我们提出了一种通过2D高斯喷涂进行图像表示和压缩的开创性范式，名为GaussianImage。我们首先引入2D高斯来表示图像，其中每个高斯具有8个参数，包括位置、协方差和颜色。随后，我们揭示了一种基于累积求和的新颖渲染算法。值得注意的是，我们的方法使用GPU内存至少降低3倍，拟合时间快5倍，不仅在表示性能上与INR（例如WIRE，I-NGP）不相上下，而且无论参数大小如何都能提供1500-2000帧每秒的更快渲染速度。

    arXiv:2403.08551v1 Announce Type: cross  Abstract: Implicit neural representations (INRs) recently achieved great success in image representation and compression, offering high visual quality and fast rendering speeds with 10-1000 FPS, assuming sufficient GPU resources are available. However, this requirement often hinders their use on low-end devices with limited memory. In response, we propose a groundbreaking paradigm of image representation and compression by 2D Gaussian Splatting, named GaussianImage. We first introduce 2D Gaussian to represent the image, where each Gaussian has 8 parameters including position, covariance and color. Subsequently, we unveil a novel rendering algorithm based on accumulated summation. Remarkably, our method with a minimum of 3$\times$ lower GPU memory usage and 5$\times$ faster fitting time not only rivals INRs (e.g., WIRE, I-NGP) in representation performance, but also delivers a faster rendering speed of 1500-2000 FPS regardless of parameter size. 
    
[^116]: HRLAIF: 通过AI反馈改进开放域强化学习中的帮助性和无害性

    HRLAIF: Improvements in Helpfulness and Harmlessness in Open-domain Reinforcement Learning From AI Feedback

    [https://arxiv.org/abs/2403.08309](https://arxiv.org/abs/2403.08309)

    提出了HRLAIF方法来改善开放域强化学习中的模型响应帮助性，通过增强AI注释响应的准确性来提高模型在训练过程中的鲁棒性

    

    强化学习从AI反馈（RLAIF）相比从人类反馈中学习（RLHF）具有更短的注释周期和更低的成本优势，使其在大型语言模型（LLM）训练的快速策略迭代阶段非常高效。使用ChatGPT作为标注员，在RLAIF训练中为开放域提示提供反馈，我们观察到人类评估者对模型响应的偏好胜率增加，但评估者的满意度下降。分析表明，满意度下降主要是因为一些响应变得不够有帮助，特别是在正确性和真实性方面，突显了基本RLAIF的实际局限性。在本文中，我们提出了混合强化学习从AI反馈（HRLAIF）。该方法增强了AI注释响应的准确性，在训练过程中使模型的帮助性更加稳健。

    arXiv:2403.08309v1 Announce Type: cross  Abstract: Reinforcement Learning from AI Feedback (RLAIF) has the advantages of shorter annotation cycles and lower costs over Reinforcement Learning from Human Feedback (RLHF), making it highly efficient during the rapid strategy iteration periods of large language model (LLM) training. Using ChatGPT as a labeler to provide feedback on open-domain prompts in RLAIF training, we observe an increase in human evaluators' preference win ratio for model responses, but a decrease in evaluators' satisfaction rate. Analysis suggests that the decrease in satisfaction rate is mainly due to some responses becoming less helpful, particularly in terms of correctness and truthfulness, highlighting practical limitations of basic RLAIF. In this paper, we propose Hybrid Reinforcement Learning from AI Feedback (HRLAIF). This method enhances the accuracy of AI annotations for responses, making the model's helpfulness more robust in training process. Additionally, 
    
[^117]: 随机搜索作为稀疏神经网络架构搜索的基准线

    Random Search as a Baseline for Sparse Neural Network Architecture Search

    [https://arxiv.org/abs/2403.08265](https://arxiv.org/abs/2403.08265)

    论文提出了一种评估方法和基于随机搜索的基线方法，用于发现高质量的稀疏神经网络配置，以解决当前缺乏可靠比较和可重现性的问题。

    

    稀疏神经网络在参数效率更高的情况下展现出与密集网络类似甚至更好的泛化性能，这促使许多工作学习、诱导或搜索性能高的稀疏网络。然而，尽管质量或效率的提升值得注意，但标准基线缺乏，因此妨碍了方法之间的可靠比较和可重现性。在这项工作中，我们提供了一种评估方法和一个简单的随机搜索基线方法，用于发现良好的稀疏配置。我们在过度参数化网络的节点空间上应用随机搜索，目标是找到在损失景观中位置更有优势的更好初始化的稀疏子网络。我们记录了不同稀疏程度下稀疏网络的训练后性能，并与它们的完全连接父网络以及随机稀疏配置进行比较。

    arXiv:2403.08265v1 Announce Type: cross  Abstract: Sparse neural networks have shown similar or better generalization performance than their dense counterparts while having higher parameter efficiency. This has motivated a number of works to learn, induce, or search for high performing sparse networks. While reports of quality or efficiency gains are impressive, standard baselines are lacking, therefore hindering having reliable comparability and reproducibility across methods. In this work, we provide an evaluation approach and a naive Random Search baseline method for finding good sparse configurations. We apply Random Search on the node space of an overparameterized network with the goal of finding better initialized sparse sub-networks that are positioned more advantageously in the loss landscape. We record sparse network post-training performances at various levels of sparsity and compare against both their fully connected parent networks and random sparse configurations at the sa
    
[^118]: 利用Context-Reverso数据使用Transformer模型生成具有上下文清晰度的句子

    Contextual Clarity: Generating Sentences with Transformer Models using Context-Reverso Data

    [https://arxiv.org/abs/2403.08103](https://arxiv.org/abs/2403.08103)

    使用Transformer模型和Context-Reverso数据生成具有上下文清晰度的句子

    

    在信息丰富的时代，提供与上下文相关且简洁的信息对用户至关重要。关键词上下文(KIC)生成是在一些应用中扮演至关重要角色的任务，比如搜索引擎、个人助手和内容摘要。本文提出了一种利用T5 transformer模型生成给定关键词的明确且简洁句子上下文的新方法，利用了从Context-Reverso API获取的数据。

    arXiv:2403.08103v1 Announce Type: cross  Abstract: In the age of information abundance, the ability to provide users with contextually relevant and concise information is crucial. Keyword in Context (KIC) generation is a task that plays a vital role in and generation applications, such as search engines, personal assistants, and content summarization. In this paper, we present a novel approach to generating unambiguous and brief sentence-contexts for given keywords using the T5 transformer model, leveraging data obtained from the Context-Reverso API. The code is available at https://github.com/Rusamus/word2context/tree/main .
    
[^119]: KnowCoder：将结构化知识编码到LLMs中用于普适信息提取

    KnowCoder: Coding Structured Knowledge into LLMs for Universal Information Extraction

    [https://arxiv.org/abs/2403.07969](https://arxiv.org/abs/2403.07969)

    本文提出了KnowCoder，一个通过代码生成执行普适信息提取的大型语言模型，引入了代码风格的模式表示方法和两阶段学习框架，以提高LLMs对结构化知识的准确提取能力

    

    在本文中，我们提出了KnowCoder，这是一个大型语言模型（LLM），用于通过代码生成进行普适信息提取（UIE）。KnowCoder旨在开发一种统一的模式表示，使LLMs能够轻松理解，并且提出了一种有效的学习框架，鼓励LLMs遵循模式并准确提取结构化知识。为了实现这一目标，KnowCoder引入了一种代码风格的模式表示方法，将不同的模式统一转换为Python类，从而可以以LLM友好的方式捕捉UIE中任务之间的约束等复杂模式信息。我们进一步构建了一个包含超过30,000种知识类型的代码风格模式库，据我们所知，这是UIE中最大的库。为了简化LLMs的学习过程，KnowCoder包含一个通过代码预训练增强其模式理解能力的两阶段学习框架。

    arXiv:2403.07969v1 Announce Type: cross  Abstract: In this paper, we propose KnowCoder, a Large Language Model (LLM) to conduct Universal Information Extraction (UIE) via code generation. KnowCoder aims to develop a kind of unified schema representation that LLMs can easily understand and an effective learning framework that encourages LLMs to follow schemas and extract structured knowledge accurately. To achieve these, KnowCoder introduces a code-style schema representation method to uniformly transform different schemas into Python classes, with which complex schema information, such as constraints among tasks in UIE, can be captured in an LLM-friendly manner. We further construct a code-style schema library covering over $\textbf{30,000}$ types of knowledge, which is the largest one for UIE, to the best of our knowledge. To ease the learning process of LLMs, KnowCoder contains a two-phase learning framework that enhances its schema understanding ability via code pretraining and its 
    
[^120]: 通过代码探索大型语言模型的安全泛化挑战

    Exploring Safety Generalization Challenges of Large Language Models via Code

    [https://arxiv.org/abs/2403.07865](https://arxiv.org/abs/2403.07865)

    本论文引入了CodeAttack框架用于测试大型语言模型的安全泛化，研究发现GPT-4、Claude-2和Llama-2系列等最新模型存在代码输入的安全漏洞。

    

    大型语言模型（LLMs）的快速发展带来了自然语言处理方面的显著能力，但也引发了人们对它们潜在误用的担忧。本文引入了CodeAttack，一个将自然语言输入转换为代码输入的框架，为测试LLMs的安全泛化提供了一个新颖的环境。我们对包括GPT-4、Claude-2和Llama-2系列在内的最新LLMs进行了全面研究，发现这些模型对于代码输入存在共同的安全漏洞：CodeAttack在超过80%的时间内始终绕过所有模型的安全保护。

    arXiv:2403.07865v1 Announce Type: cross  Abstract: The rapid advancement of Large Language Models (LLMs) has brought about remarkable capabilities in natural language processing but also raised concerns about their potential misuse. While strategies like supervised fine-tuning and reinforcement learning from human feedback have enhanced their safety, these methods primarily focus on natural languages, which may not generalize to other domains. This paper introduces CodeAttack, a framework that transforms natural language inputs into code inputs, presenting a novel environment for testing the safety generalization of LLMs. Our comprehensive studies on state-of-the-art LLMs including GPT-4, Claude-2, and Llama-2 series reveal a common safety vulnerability of these models against code input: CodeAttack consistently bypasses the safety guardrails of all models more than 80\% of the time. Furthermore, we find that a larger distribution gap between CodeAttack and natural language leads to we
    
[^121]: 将竞争转化为合作：多Agent系统和语言模型在现代组织中的革命性作用

    Transforming Competition into Collaboration: The Revolutionary Role of Multi-Agent Systems and Language Models in Modern Organizations

    [https://arxiv.org/abs/2403.07769](https://arxiv.org/abs/2403.07769)

    文章探讨了基于多Agent系统理论结合大型语言模型的计算实体对人类互动的革新影响，提出了一种可能将专门人工代理支持扩展到操作性组织流程和基于知识和人类编排的战略决策的方式。

    

    这篇文章探讨了基于多Agent系统理论（SMA）结合大型语言模型（LLM）的计算实体的动态影响，其特点是能够模拟复杂的人类互动，作为一种革新人类用户交互的可能性，从利用专门的人工代理支持从操作组织流程到基于应用知识和人的编排的战略决策。 先前的调查显示，在处理新挑战和实用任务（如引发逻辑推理和问题解决）时，特别是在人工代理的自主方法方面存在限制。 还考虑到，传统技术，如激发思想链，需要明确的人类指导。 在我们的方法中，我们使用从大型语言模型（LLM）开发的代理，每个代理都有不同

    arXiv:2403.07769v1 Announce Type: new  Abstract: This article explores the dynamic influence of computational entities based on multi-agent systems theory (SMA) combined with large language models (LLM), which are characterized by their ability to simulate complex human interactions, as a possibility to revolutionize human user interaction from the use of specialized artificial agents to support everything from operational organizational processes to strategic decision making based on applied knowledge and human orchestration. Previous investigations reveal that there are limitations, particularly in the autonomous approach of artificial agents, especially when dealing with new challenges and pragmatic tasks such as inducing logical reasoning and problem solving. It is also considered that traditional techniques, such as the stimulation of chains of thoughts, require explicit human guidance. In our approach we employ agents developed from large language models (LLM), each with distinct
    
[^122]: 使用对比奖励改善从人类反馈中的强化学习

    Improving Reinforcement Learning from Human Feedback Using Contrastive Rewards

    [https://arxiv.org/abs/2403.07708](https://arxiv.org/abs/2403.07708)

    引入对比奖励的方法提高了从人类反馈中的强化学习的效果，改善了奖励模型的鲁棒性，鼓励对基准的改善，并能根据任务的难度进行校准。

    

    强化学习从人类反馈（RLHF）是用来对齐大型语言模型（LLMs）与人类偏好的主流范式。然而现有的RLHF在很大程度上依赖于准确和信息丰富的奖励模型，这些模型容易受到各种来源的噪声，例如人类标注错误，使得流程脆弱。本文通过引入对奖励的惩罚项，命名为“对比奖励”，来提高奖励模型的有效性。我们的方法包括两个步骤：（1）离线抽样步骤，获取用作基准计算的提示响应，以及（2）使用基准响应计算对比奖励，并将其用于Proximal Policy Optimization（PPO）步骤。我们展示了对比奖励使得LLM能够惩罚奖励不确定性，提高鲁棒性，鼓励优于基线的改进，根据任务难度进行校准，并且重新

    arXiv:2403.07708v1 Announce Type: cross  Abstract: Reinforcement learning from human feedback (RLHF) is the mainstream paradigm used to align large language models (LLMs) with human preferences. Yet existing RLHF heavily relies on accurate and informative reward models, which are vulnerable and sensitive to noise from various sources, e.g. human labeling errors, making the pipeline fragile. In this work, we improve the effectiveness of the reward model by introducing a penalty term on the reward, named as \textit{contrastive rewards}. %Contrastive rewards Our approach involves two steps: (1) an offline sampling step to obtain responses to prompts that serve as baseline calculation and (2) a contrastive reward calculated using the baseline responses and used in the Proximal Policy Optimization (PPO) step. We show that contrastive rewards enable the LLM to penalize reward uncertainty, improve robustness, encourage improvement over baselines, calibrate according to task difficulty, and re
    
[^123]: 具有赔率比的无参考单体偏好优化

    Reference-free Monolithic Preference Optimization with Odds Ratio

    [https://arxiv.org/abs/2403.07691](https://arxiv.org/abs/2403.07691)

    本文介绍了一种无参考单体赔率比偏好优化算法ORPO，在SFT过程中通过轻微惩罚不受欢迎的生成风格，消除了额外的偏好对齐阶段

    

    近期的语言模型偏好对齐算法展现了很好的结果，但是监督微调（SFT）仍然对于成功收敛至关重要。本文研究了在偏好对齐的环境中SFT的关键作用，强调对于偏好对齐的SFT来说，对于不受欢迎的生成风格施加轻微惩罚就足够了。在此基础上，我们引入了一种简单而创新的无参考模型的单体赔率比偏好优化算法ORPO，消除了额外的偏好对齐阶段的必要性。我们通过实证和理论手段证明，赔率比是在125M至7B不同规模下进行SFT时对比受欢迎和不受欢迎风格的明智选择。具体来说，使用ORPO在仅UltraFeedback上对Phi-2（2.7B）、Llama-2（7B）和Mistral（7B）进行微调，超越了性能

    arXiv:2403.07691v1 Announce Type: cross  Abstract: While recent preference alignment algorithms for language models have demonstrated promising results, supervised fine-tuning (SFT) remains imperative for achieving successful convergence. In this paper, we study the crucial role of SFT within the context of preference alignment, emphasizing that a minor penalty for the disfavored generation style is sufficient for preference-aligned SFT. Building on this foundation, we introduce a straightforward and innovative reference model-free monolithic odds ratio preference optimization algorithm, ORPO, eliminating the necessity for an additional preference alignment phase. We demonstrate, both empirically and theoretically, that the odds ratio is a sensible choice for contrasting favored and disfavored styles during SFT across the diverse sizes from 125M to 7B. Specifically, fine-tuning Phi-2 (2.7B), Llama-2 (7B), and Mistral (7B) with ORPO on the UltraFeedback alone surpasses the performance o
    
[^124]: 关于持续学习中宽度递减回报的研究

    On the Diminishing Returns of Width for Continual Learning

    [https://arxiv.org/abs/2403.06398](https://arxiv.org/abs/2403.06398)

    增加神经网络宽度以减少遗忘会带来递减的回报，并且在先前研究中尚未探索的宽度范围内进行了实证验证。

    

    深度神经网络在各种设置中展示了突破性的性能，但这些模型在按顺序训练新任务时经常出现“灾难性遗忘”。 一些研究已经经验性地证明增加神经网络宽度会导致灾难性遗忘减少，但尚未准确刻画宽度和持续学习之间的确切关系。我们设计了其中一个最早的框架来分析持续学习理论，并证明宽度与前馈网络（FFN）中的遗忘直接相关。 具体来说，我们证明增加网络宽度以减少遗忘会带来递减的回报。我们在先前研究中尚未探索的宽度上经验性验证了我们的论断，结果显示递减回报如我们的理论所预测的那样清晰可见。

    arXiv:2403.06398v1 Announce Type: cross  Abstract: While deep neural networks have demonstrated groundbreaking performance in various settings, these models often suffer from \emph{catastrophic forgetting} when trained on new tasks in sequence. Several works have empirically demonstrated that increasing the width of a neural network leads to a decrease in catastrophic forgetting but have yet to characterize the exact relationship between width and continual learning. We design one of the first frameworks to analyze Continual Learning Theory and prove that width is directly related to forgetting in Feed-Forward Networks (FFN). Specifically, we demonstrate that increasing network widths to reduce forgetting yields diminishing returns. We empirically verify our claims at widths hitherto unexplored in prior studies where the diminishing returns are clearly observed as predicted by our theory.
    
[^125]: 优化大学计算机实验室人体工程学：一个关于人体测量、家具设计和ANOVA测试的研究

    Optimizing Computer Lab Ergonomics in Universities: A Study on Anthropometric Measurements, Furniture Design, and ANOVA Test

    [https://arxiv.org/abs/2403.05589](https://arxiv.org/abs/2403.05589)

    提出基于人体测量的家具尺寸适合大学生，以改善计算机实验室人体工程学，研究发现其与现有家具尺寸存在显著差异并更加兼容

    

    许多研究表明，人体工程学设计的家具能提高工作效率和身心健康。随着计算机成为学生学术生活的一部分，它们在未来将进一步普及。我们提出基于人体测量的家具尺寸，适合大学生以改善计算机实验室的人体工程学。我们收集了380名参与者的数据，分析了11项人体测量，并将它们与11项家具尺寸进行了相关性分析。研究了两种类型的家具：非可调椅子与非可调桌子，以及可调椅子与非可调桌子。不匹配计算显示家具尺寸与人体测量之间存在显著差异。显著水平为5%的单因素方差分析测试还显示了所提出的和现有的家具尺寸之间存在显著差异。发现所提出的尺寸更加兼容，减少了不匹配百分比。

    arXiv:2403.05589v1 Announce Type: cross  Abstract: Many studies have shown how ergonomically designed furniture improves productivity and well-being. As computers have become a part of students' academic lives, they will grow further in the future. We propose anthropometric-based furniture dimensions suitable for university students to improve computer laboratory ergonomics. We collected data from 380 participants and analyzed 11 anthropometric measurements, correlating them to 11 furniture dimensions. Two types of furniture were studied: a non-adjustable chair with a non-adjustable table and an adjustable chair with a non-adjustable table. The mismatch calculation showed a significant difference between furniture dimensions and anthropometric measurements. The one-way ANOVA test with a significance level of 5% also showed a significant difference between proposed and existing furniture dimensions. The proposed dimensions were found to be more compatible and reduced mismatch percentage
    
[^126]: MMoE: 多模态信息和领域感知专家混合的鲁棒剧透检测

    MMoE: Robust Spoiler Detection with Multi-modal Information and Domain-aware Mixture-of-Experts

    [https://arxiv.org/abs/2403.05265](https://arxiv.org/abs/2403.05265)

    提出了MMoE，一个利用多模态信息进行剧透检测的网络，并采用专家混合技术来增强领域泛化能力。

    

    在线电影评论网站对于电影信息和讨论是非常有价值的。然而，大量的剧透评论会影响观影体验，因此剧透检测变得非常重要。先前的方法通常只关注评论的文本内容，忽略了平台中信息的异质性。为了解决这个问题，我们提出了MMoE，一个利用多模态信息进行剧透检测的网络，并采用专家混合技术来增强领域泛化能力。MMoE首先从用户-电影网络中提取图表、文本和元数据特征，分别从评论的文本内容和评论的元数据中提取信息。为了处理特定类型电影评论中的剧透语言。

    arXiv:2403.05265v1 Announce Type: new  Abstract: Online movie review websites are valuable for information and discussion about movies. However, the massive spoiler reviews detract from the movie-watching experience, making spoiler detection an important task. Previous methods simply focus on reviews' text content, ignoring the heterogeneity of information in the platform. For instance, the metadata and the corresponding user's information of a review could be helpful. Besides, the spoiler language of movie reviews tends to be genre-specific, thus posing a domain generalization challenge for existing methods. To this end, we propose MMoE, a multi-modal network that utilizes information from multiple modalities to facilitate robust spoiler detection and adopts Mixture-of-Experts to enhance domain generalization. MMoE first extracts graph, text, and meta feature from the user-movie network, the review's textual content, and the review's metadata respectively. To handle genre-specific spo
    
[^127]: 基于规则的新闻标题生成

    Rule-driven News Captioning

    [https://arxiv.org/abs/2403.05101](https://arxiv.org/abs/2403.05101)

    本文提出了一种基于规则的新闻标题生成方法，通过新闻感知的语义规则，可以生成遵循新闻报道基本规则的图像描述。

    

    News captioning任务旨在通过描述图片及其新闻文章中的命名实体或具体事件来生成句子。现有方法通过依赖大规模预训练模型已取得显著成果，这些模型主要专注于输入新闻内容与输出预测之间的相关性。然而，新闻标题生成需要遵循新闻报道的一些基本规则，如准确描述与事件相关的个体和动作。在本文中，我们提出了基于规则的新闻标题生成方法，可以根据指定的规则信号生成图像描述。具体而言，我们首先为描述设计了新闻感知的语义规则。这一规则包括图片中描绘的主要动作（例如，“执行”）以及参与动作的命名实体扮演的角色（例如，“代理人”和“地点”）。其次，我们将这个语义规则注入到文本生成模型中。

    arXiv:2403.05101v1 Announce Type: cross  Abstract: News captioning task aims to generate sentences by describing named entities or concrete events for an image with its news article. Existing methods have achieved remarkable results by relying on the large-scale pre-trained models, which primarily focus on the correlations between the input news content and the output predictions. However, the news captioning requires adhering to some fundamental rules of news reporting, such as accurately describing the individuals and actions associated with the event. In this paper, we propose the rule-driven news captioning method, which can generate image descriptions following designated rule signal. Specifically, we first design the news-aware semantic rule for the descriptions. This rule incorporates the primary action depicted in the image (e.g., "performing") and the roles played by named entities involved in the action (e.g., "Agent" and "Place"). Second, we inject this semantic rule into th
    
[^128]: BjTT: 一个用于交通预测的大规模多模态数据集

    BjTT: A Large-scale Multimodal Dataset for Traffic Prediction

    [https://arxiv.org/abs/2403.05029](https://arxiv.org/abs/2403.05029)

    本文提出了第一个用于文本-交通生成的扩散模型ChatTraffic，通过将生成模型与交通系统描述文本相结合，解决了交通预测中关联文本和空间结构的挑战。

    

    arXiv:2403.05029v1 公告类型: 新摘要: 交通预测是智能交通系统中最重要的基础之一。传统的交通预测方法仅依赖历史交通数据来预测交通趋势，并面临两个主要挑战。1）对异常事件不敏感。2）在长期预测中性能有限。在这项工作中，我们探讨了将生成模型与描述交通系统的文本相结合应用于交通生成的方法，并命名该任务为文本-交通生成（TTG）。TTG 任务的关键挑战是如何将文本与道路网络的空间结构和交通数据相关联，以生成交通情况。为此，我们提出了ChatTraffic，第一个用于文本-交通生成的扩散模型。为了保证合成数据与真实数据的一致性，我们将扩散模型与图卷积网络（GCN）结合起来，以提取交通数据的空间相关性。

    arXiv:2403.05029v1 Announce Type: new  Abstract: Traffic prediction is one of the most significant foundations in Intelligent Transportation Systems (ITS). Traditional traffic prediction methods rely only on historical traffic data to predict traffic trends and face two main challenges. 1) insensitivity to unusual events. 2) limited performance in long-term prediction. In this work, we explore how generative models combined with text describing the traffic system can be applied for traffic generation, and name the task Text-to-Traffic Generation (TTG). The key challenge of the TTG task is how to associate text with the spatial structure of the road network and traffic data for generating traffic situations. To this end, we propose ChatTraffic, the first diffusion model for text-to-traffic generation. To guarantee the consistency between synthetic and real data, we augment a diffusion model with the Graph Convolutional Network (GCN) to extract spatial correlations of traffic data. In ad
    
[^129]: 从图到词袋: 将领域知识引入混淆罪名预测

    From Graph to Word Bag: Introducing Domain Knowledge to Confusing Charge Prediction

    [https://arxiv.org/abs/2403.04369](https://arxiv.org/abs/2403.04369)

    引入领域知识的从图到词袋方法，帮助预测混淆罪名，通过构成要素和关键词选择进行判断。

    

    混淆罪名预测是法律人工智能中一个具有挑战性的任务，涉及根据事实描述预测混淆罪名。现有的罪名预测方法在表现上已经展现出令人印象深刻的效果，但在处理混淆罪名（如抢夺与抢劫）时面临着重大挑战。在法律领域，构成要素在区分混淆罪名中扮演着至关重要的角色。构成要素是潜在刑罚背后的基本行为，并且在不同罪名之间有微妙的区别。本文介绍了一种新的从图到词袋（FWGB）方法，该方法引入了有关构成要素的领域知识，以指导模型在混淆罪名上做出判断，类似于法官的推理过程。具体而言，我们首先构建了一个包含构成要素的法律知识图，以帮助为每种罪名选择关键词，形成一个单词袋。

    arXiv:2403.04369v1 Announce Type: new  Abstract: Confusing charge prediction is a challenging task in legal AI, which involves predicting confusing charges based on fact descriptions. While existing charge prediction methods have shown impressive performance, they face significant challenges when dealing with confusing charges, such as Snatch and Robbery. In the legal domain, constituent elements play a pivotal role in distinguishing confusing charges. Constituent elements are fundamental behaviors underlying criminal punishment and have subtle distinctions among charges. In this paper, we introduce a novel From Graph to Word Bag (FWGB) approach, which introduces domain knowledge regarding constituent elements to guide the model in making judgments on confusing charges, much like a judge's reasoning process. Specifically, we first construct a legal knowledge graph containing constituent elements to help select keywords for each charge, forming a word bag. Subsequently, to guide the mod
    
[^130]: 磨具探测和调整用于文本到图像生成

    Discriminative Probing and Tuning for Text-to-Image Generation

    [https://arxiv.org/abs/2403.04321](https://arxiv.org/abs/2403.04321)

    加强T2I模型的判别能力，以实现更精确的文本到图像对齐生成。

    

    尽管文本到图像生成（T2I）取得了进展，但先前的方法经常面临文本图像不对齐等问题，如生成图像中的关系混淆。现有解决方案包括交叉注意力操作以实现更好的组合理解，或者集成大型语言模型以改进布局规划。然而，T2I模型的固有对齐能力仍然不足。通过审视生成模型和判别模型之间的联系，我们认为T2I模型的判别能力可能反映了它们在生成过程中的文本图像对齐熟练度。基于这一观点，我们主张加强T2I模型的判别能力，以实现更精确的文本到图像对齐生成。我们提出了一个建立在T2I模型上的判别适配器，以探测它们在两项代表性任务上的判别能力，并利用判别微调来改善它们的文本图像对齐。

    arXiv:2403.04321v1 Announce Type: cross  Abstract: Despite advancements in text-to-image generation (T2I), prior methods often face text-image misalignment problems such as relation confusion in generated images. Existing solutions involve cross-attention manipulation for better compositional understanding or integrating large language models for improved layout planning. However, the inherent alignment capabilities of T2I models are still inadequate. By reviewing the link between generative and discriminative modeling, we posit that T2I models' discriminative abilities may reflect their text-image alignment proficiency during generation. In this light, we advocate bolstering the discriminative abilities of T2I models to achieve more precise text-to-image alignment for generation. We present a discriminative adapter built on T2I models to probe their discriminative abilities on two representative tasks and leverage discriminative fine-tuning to improve their text-image alignment. As a 
    
[^131]: 德语也产生幻觉！使用Absinth数据集检测新闻摘要中的不一致性

    German also Hallucinates! Inconsistency Detection in News Summaries with the Absinth Dataset

    [https://arxiv.org/abs/2403.03750](https://arxiv.org/abs/2403.03750)

    本文提出了一个用于德语新闻摘要中幻觉检测的数据集absinth，探讨了LLMs在该任务中的应用。

    

    大型语言模型（LLMs）的出现在自然语言处理任务中取得了显著进展，然而，这些大型模型仍然存在产生信息幻觉的问题，这在自动文本摘要中至关重要。先前的研究主要集中在英语上，并且最近的多语言方法缺乏德语数据。本文提出了absinth，一个用于德语新闻摘要中幻觉检测的手动注释数据集，并探讨了新型开源LLMs在这一任务上的能力，包括微调和上下文学习设置。我们开源并发布了这个数据集。

    arXiv:2403.03750v1 Announce Type: cross  Abstract: The advent of Large Language Models (LLMs) has led to remarkable progress on a wide range of natural language processing tasks. Despite the advances, these large-sized models still suffer from hallucinating information in their output, which poses a major issue in automatic text summarization, as we must guarantee that the generated summary is consistent with the content of the source document. Previous research addresses the challenging task of detecting hallucinations in the output (i.e. inconsistency detection) in order to evaluate the faithfulness of the generated summaries. However, these works primarily focus on English and recent multilingual approaches lack German data. This work presents absinth, a manually annotated dataset for hallucination detection in German news summarization and explores the capabilities of novel open-source LLMs on this task in both fine-tuning and in-context learning settings. We open-source and releas
    
[^132]: TTA-Nav: 测试时自适应重建用于视觉损坏下的点目标导航

    TTA-Nav: Test-time Adaptive Reconstruction for Point-Goal Navigation under Visual Corruptions

    [https://arxiv.org/abs/2403.01977](https://arxiv.org/abs/2403.01977)

    TTA-Nav提出了一种测试时自适应方法，通过引入自顶向下解码器，从损坏图像中重建出更清晰的图像，显著增强了点目标导航性能。

    

    arXiv:2403.01977v1 公告类型: 跨  摘要: 在视觉损坏下的机器人导航是一个巨大的挑战。为了解决这一问题，我们提出了一种名为TTA-Nav的测试时自适应（TTA）方法，用于在视觉损坏下的点目标导航。我们的“即插即用”方法将自顶向下的解码器与预训练的导航模型相结合。首先，预训练的导航模型接收一个损坏的图像并提取特征。其次，自顶向下的解码器根据预训练模型提取的高级特征生成重建图像。然后，将损坏图像的重建图像馈送回预训练模型。最后，预训练模型再次进行前向传播以输出动作。尽管仅在清晰图像上训练，自顶向下的解码器可以从损坏图像中重建出更清晰的图像，无需基于梯度的自适应。具有我们自顶向下解码器的预训练导航模型显著提高了导航性能。

    arXiv:2403.01977v1 Announce Type: cross  Abstract: Robot navigation under visual corruption presents a formidable challenge. To address this, we propose a Test-time Adaptation (TTA) method, named as TTA-Nav, for point-goal navigation under visual corruptions. Our "plug-and-play" method incorporates a top-down decoder to a pre-trained navigation model. Firstly, the pre-trained navigation model gets a corrupted image and extracts features. Secondly, the top-down decoder produces the reconstruction given the high-level features extracted by the pre-trained model. Then, it feeds the reconstruction of a corrupted image back to the pre-trained model. Finally, the pre-trained model does forward pass again to output action. Despite being trained solely on clean images, the top-down decoder can reconstruct cleaner images from corrupted ones without the need for gradient-based adaptation. The pre-trained navigation model with our top-down decoder significantly enhances navigation performance acr
    
[^133]: AllSpark: 利用Transformer中未标记的特征重新生成标记特征，用于半监督语义分割

    AllSpark: Reborn Labeled Features from Unlabeled in Transformer for Semi-Supervised Semantic Segmentation

    [https://arxiv.org/abs/2403.01818](https://arxiv.org/abs/2403.01818)

    AllSpark利用通道级交叉注意机制从未标记的特征中重新生成标记特征，以改善半监督语义分割中低质量伪标签的问题。

    

    半监督语义分割（SSSS）旨在减轻耗时的像素级手动标注负担，它利用有限的标记数据以及更多的未标记数据。目前最先进的方法使用基准真值训练标记数据和使用伪标签训练未标记数据。然而，这两种训练流程是分开的，这使得标记数据主导训练过程，导致低质量的伪标签和从而次优的结果。为了解决这个问题，我们提出了AllSpark，利用通道级交叉注意机制从未标记的特征中重新生成标记的特征。我们进一步引入了语义记忆和通道语义分组策略，以确保未标记特征充分代表标记特征。AllSpark为SSSS的架构级设计带来了新的视角，而非框架级别，避免了越来越常见的问题。

    arXiv:2403.01818v1 Announce Type: cross  Abstract: Semi-supervised semantic segmentation (SSSS) has been proposed to alleviate the burden of time-consuming pixel-level manual labeling, which leverages limited labeled data along with larger amounts of unlabeled data. Current state-of-the-art methods train the labeled data with ground truths and unlabeled data with pseudo labels. However, the two training flows are separate, which allows labeled data to dominate the training process, resulting in low-quality pseudo labels and, consequently, sub-optimal results. To alleviate this issue, we present AllSpark, which reborns the labeled features from unlabeled ones with the channel-wise cross-attention mechanism. We further introduce a Semantic Memory along with a Channel Semantic Grouping strategy to ensure that unlabeled features adequately represent labeled features. The AllSpark shed new light on the architecture level designs of SSSS rather than framework level, which avoids increasingly
    
[^134]: 可解释的扩散用于通用时间序列生成

    Diffusion-TS: Interpretable Diffusion for General Time Series Generation

    [https://arxiv.org/abs/2403.01742](https://arxiv.org/abs/2403.01742)

    提出了一种新颖的基于扩散的框架 Diffusion-TS，结合了编码器-解码器变压器和解耦时间表示，通过直接重建样本而非噪声生成高质量的多变量时间序列样本，旨在实现时间序列的解释性和真实性。

    

    Denoising diffusion probabilistic models (DDPMs)正逐渐成为生成模型的主流范式，最近已在音频合成、时间序列填补和预测等领域取得突破。本文提出了Diffusion-TS，一种新颖的基于扩散的框架，通过使用具有解耦时间表示的编码器-解码器变压器生成高质量的多变量时间序列样本，其中分解技术指导Diffusion-TS捕获时间序列的语义含义，而变压器从嘈杂的模型输入中挖掘详细的序列信息。与现有的基于扩散的方法不同，我们训练模型直接重建样本而不是在每个扩散步骤中重建噪声，并结合了基于Fourier的损失项。预期Diffusion-TS可以生成既具有解释性又真实性的时间序列。此外，还表明了所提出的Diffusion

    arXiv:2403.01742v1 Announce Type: cross  Abstract: Denoising diffusion probabilistic models (DDPMs) are becoming the leading paradigm for generative models. It has recently shown breakthroughs in audio synthesis, time series imputation and forecasting. In this paper, we propose Diffusion-TS, a novel diffusion-based framework that generates multivariate time series samples of high quality by using an encoder-decoder transformer with disentangled temporal representations, in which the decomposition technique guides Diffusion-TS to capture the semantic meaning of time series while transformers mine detailed sequential information from the noisy model input. Different from existing diffusion-based approaches, we train the model to directly reconstruct the sample instead of the noise in each diffusion step, combining a Fourier-based loss term. Diffusion-TS is expected to generate time series satisfying both interpretablity and realness. In addition, it is shown that the proposed Diffusion-T
    
[^135]: VBART: 土耳其LLM

    VBART: The Turkish LLM

    [https://arxiv.org/abs/2403.01308](https://arxiv.org/abs/2403.01308)

    VBART是第一个土耳其序列到序列大语言模型，通过与BART和mBART模型结合形成了紧凑型LLM，并在多个任务中表现出色，为土耳其自然语言处理研究开辟了新的可能性。

    

    我们提出了VBART，这是第一个土耳其序列到序列大语言模型（LLMs），在一个大语料库上从头开始进行预训练。VBART是基于BART和mBART模型的好思路构建的紧凑型LLMs，分为Large和XLarge两个尺寸。微调后的VBART模型在提取性文本摘要、标题生成、文本改写、问答和问题生成等任务中超越了先前的最先进结果。它们允许为未来的文本生成任务和数据集进行微调，为土耳其自然语言处理（NLP）研究开辟了新路径。我们的工作表明，拥有为土耳其进行预训练的LLM比多语言模型提高了最多3倍，改进了现有结果，并为训练和推理提供了高效的模型。此外，我们展示了我们的单语分词器比OpenAI的多语言分词器更高效7倍。最后但同样重要的是，我们介绍了一种扩展现有预训

    arXiv:2403.01308v1 Announce Type: new  Abstract: We present VBART, the first Turkish sequence-to-sequence Large Language Models (LLMs) pre-trained on a large corpus from scratch. VBART are compact LLMs based on good ideas leveraged from BART and mBART models and come in two sizes, Large and XLarge. Fine-tuned VBART models surpass the prior state-of-the-art results in abstractive text summarization, title generation, text paraphrasing, question answering and question generation tasks. They allow fine-tuning for future text generation tasks and datasets, carving a new path for Turkish Natural Language Processing (NLP) research. Our work shows that having a pre-trained LLM for Turkish outperforms up to 3x multilingual models, improving existing results and providing efficient models for training and inference. Moreover, we show that our monolingual tokenizer is 7x more efficient than OpenAI's multilingual tokenizer. Last but not least, we introduce a method to enlarge an existing pre-trai
    
[^136]: RAGged Edges: Retrieval-Augmented Chatbots的双刃剑

    RAGged Edges: The Double-Edged Sword of Retrieval-Augmented Chatbots

    [https://arxiv.org/abs/2403.01193](https://arxiv.org/abs/2403.01193)

    本文探讨了如何利用检索增强生成（RAG）抵制大型语言模型（LLMs）产生的幻觉，结果表明RAG在某些情况下可以提高准确性，但仍需要更强大的解决方案以确保LLMs在实际应用中可靠性。

    

    大型语言模型（LLMs）如ChatGPT展示了人工智能的显著进展。然而，它们倾向于产生幻觉 - 生成看似正确但错误信息的倾向带来了重大挑战。这个问题很关键，就像最近的法院案例中看到的那样，ChatGPT的使用导致了不存在的法律裁决的引用。本文探讨了如何通过将外部知识与提示集成来使用检索增强生成（RAG）来抵制幻觉。我们通过使用旨在诱导幻觉的提示来对RAG与标准LLMs进行经验评估。我们的结果显示，在某些情况下，RAG可以提高准确性，但当提示直接与模型预训练的理解相矛盾时，RAG仍然会被误导。这些发现突显了幻觉的复杂性以及需要更强大的解决方案以确保LLMs在实际应用中可靠性。我们提供了RAG部署的实用建议。

    arXiv:2403.01193v1 Announce Type: cross  Abstract: Large language models (LLMs) like ChatGPT demonstrate the remarkable progress of artificial intelligence. However, their tendency to hallucinate -- generate plausible but false information -- poses a significant challenge. This issue is critical, as seen in recent court cases where ChatGPT's use led to citations of non-existent legal rulings. This paper explores how Retrieval-Augmented Generation (RAG) can counter hallucinations by integrating external knowledge with prompts. We empirically evaluate RAG against standard LLMs using prompts designed to induce hallucinations. Our results show that RAG increases accuracy in some cases, but can still be misled when prompts directly contradict the model's pre-trained understanding. These findings highlight the complex nature of hallucinations and the need for more robust solutions to ensure LLM reliability in real-world applications. We offer practical recommendations for RAG deployment and 
    
[^137]: 精确推荐的端到端图-序列表示学习

    End-to-end Graph-Sequential Representation Learning for Accurate Recommendations

    [https://arxiv.org/abs/2403.00895](https://arxiv.org/abs/2403.00895)

    本文提出了一个新颖的多重表示学习框架，有效地结合了基于序列和基于图的推荐方法，显著改善了推荐性能。

    

    近年来推荐系统的许多新进展集中在开发基于序列和基于图的方法上。这两种方法在建模行为数据中的复杂关系方面都证明了其有效性，从而在个性化排名和下一个推荐任务中取得了有益的成果，同时保持了良好的可扩展性。然而，它们从数据中捕捉到的信号截然不同。前者直接通过与最近物品的有序交互来表示用户，而后者旨在捕捉交互图中的间接依赖关系。本文提出了一个新颖的多重表示学习框架，利用这两种范式之间的协同作用。我们在几个数据集上的实证评估表明，利用所提出的框架相互训练序列和图组件显著改善了推荐性能。

    arXiv:2403.00895v1 Announce Type: cross  Abstract: Many recent advancements in recommender systems have focused on developing sequence-based and graph-based approaches. Both approaches proved useful in modeling intricate relationships within behavioral data, leading to promising outcomes in personalized ranking and next-item recommendation tasks while maintaining good scalability. However, they capture very different signals from data. While the former approach represents users directly through ordered interactions with recent items, the latter one aims to capture indirect dependencies across the interactions graph. This paper presents a novel multi-representational learning framework that exploits the synergies between these two paradigms. Our empirical evaluation on several datasets demonstrates that mutual training of sequential and graph components with the proposed framework significantly improves recommendations performance.
    
[^138]: 用大语言模型执行自然语言描述的算法：一项研究

    Executing Natural Language-Described Algorithms with Large Language Models: An Investigation

    [https://arxiv.org/abs/2403.00795](https://arxiv.org/abs/2403.00795)

    大语言模型可以有效地执行用自然语言描述的程序，尤其是在不涉及大量数字计算的情况下。

    

    使用自然语言描述的计算机程序一直是计算机科学的追求。随着大语言模型（LLMs）展示出的增强自然语言理解能力的出现，这一目标的道路已经被阐明。本文旨在检验现有LLMs理解和执行自然语言中描述的算法的能力。我们从《算法导论》中选取了一个算法测试集，该书是一本包含许多代表性广泛使用的算法的知名教材。为了系统评估LLMs的代码执行能力，我们选择了30个算法，共生成了300个随机抽样实例，并评估了流行的LLMs是否能够理解和执行这些算法。我们的发现表明，特别是GPT-4等LLMs可以有效地执行用自然语言描述的程序，只要不涉及大量数字计算。

    arXiv:2403.00795v1 Announce Type: cross  Abstract: Executing computer programs described in natural language has long been a pursuit of computer science. With the advent of enhanced natural language understanding capabilities exhibited by large language models (LLMs), the path toward this goal has been illuminated. In this paper, we seek to examine the capacity of present-day LLMs to comprehend and execute algorithms outlined in natural language. We established an algorithm test set sourced from Introduction to Algorithm, a well-known textbook that contains many representative widely-used algorithms. To systematically assess LLMs' code execution abilities, we selected 30 algorithms, generated 300 random-sampled instances in total, and evaluated whether popular LLMs can understand and execute these algorithms. Our findings reveal that LLMs, notably GPT-4, can effectively execute programs described in natural language, as long as no heavy numeric computation is involved. We believe our f
    
[^139]: 光滑 Tchebycheff 标量化用于多目标优化

    Smooth Tchebycheff Scalarization for Multi-Objective Optimization

    [https://arxiv.org/abs/2402.19078](https://arxiv.org/abs/2402.19078)

    通过光滑 Tchebycheff 标量化方法，本文提出了一种轻量级的方法，用于梯度型多目标优化，具有更低的计算复杂性但仍能找到所有帕累托解。

    

    多目标优化问题在许多现实世界应用中都能找到，在这些问题中，目标经常相互冲突，不能通过单个解进行优化。在过去的几十年中，已经提出了许多方法来找到帕累托解，这些解代表了对于给定问题的不同最佳权衡。然而，这些现有方法可能具有较高的计算复杂性，或者可能不能具备解决一般可微分多目标优化问题的良好理论属性。在本项工作中，通过利用光滑优化技术，我们提出了一种新颖且轻量的光滑 Tchebycheff 标量化方法，用于基于梯度的多目标优化。它对于找到所有帕累托解具有良好的理论属性，同时相对于其他方法具有显着较低的计算复杂性。在各种实验结果上

    arXiv:2402.19078v1 Announce Type: cross  Abstract: Multi-objective optimization problems can be found in many real-world applications, where the objectives often conflict each other and cannot be optimized by a single solution. In the past few decades, numerous methods have been proposed to find Pareto solutions that represent different optimal trade-offs among the objectives for a given problem. However, these existing methods could have high computational complexity or may not have good theoretical properties for solving a general differentiable multi-objective optimization problem. In this work, by leveraging the smooth optimization technique, we propose a novel and lightweight smooth Tchebycheff scalarization approach for gradient-based multi-objective optimization. It has good theoretical properties for finding all Pareto solutions with valid trade-off preferences, while enjoying significantly lower computational complexity compared to other methods. Experimental results on variou
    
[^140]: MMSR：符号回归是一个多模态任务

    MMSR: Symbolic Regression is a Multimodal Task

    [https://arxiv.org/abs/2402.18603](https://arxiv.org/abs/2402.18603)

    符号回归被视为一个多模态任务，研究人员将数据到表达式的映射视为翻译问题，引入大规模预训练模型。

    

    数学公式是探索自然规律几千年来人类智慧的结晶。用简洁的数学公式描述复杂的自然规律是科学家不断追求的目标，也是人工智能面临的重大挑战。这一领域被称为符号回归。在本文中，研究人员将从数据到表达式的映射视为翻译问题，并引入了相应的大规模预训练模型。

    arXiv:2402.18603v1 Announce Type: cross  Abstract: Mathematical formulas are the crystallization of human wisdom in exploring the laws of nature for thousands of years. Describing the complex laws of nature with a concise mathematical formula is a constant pursuit of scientists and a great challenge for artificial intelligence. This field is called symbolic regression. Symbolic regression was originally formulated as a combinatorial optimization problem, and GP and reinforcement learning algorithms were used to solve it. However, GP is sensitive to hyperparameters, and these two types of algorithms are inefficient. To solve this problem, researchers treat the mapping from data to expressions as a translation problem. And the corresponding large-scale pre-trained model is introduced. However, the data and expression skeletons do not have very clear word correspondences as the two languages do. Instead, they are more like two modalities (e.g., image and text). Therefore, in this paper, w
    
[^141]: QUCE: 减少和量化基于路径的不确定性以生成对抗性反事实解释

    QUCE: The Minimisation and Quantification of Path-Based Uncertainty for Generative Counterfactual Explanations

    [https://arxiv.org/abs/2402.17516](https://arxiv.org/abs/2402.17516)

    QUCE方法旨在通过减少路径不确定性来量化和缓解基于路径的不确定性，从而改善对抗性反事实解释的表现。

    

    arXiv:2402.17516v1 公告类型：跨学科 深度神经网络（DNNs）作为机器学习领域最突出的方法之一。DNNs的有效性随着最近计算能力的增加而激增，使得这些方法能够扩展到处理大数据中的重要复杂性以应对预测挑战。然而，随着DNN模型复杂性的提高，可解释性降低。针对这一挑战，诸如对抗梯度整合（AGI）这样的可解释模型利用DNN提供的基于路径的梯度来阐明它们的决策。然而，当梯度在越界路径遍历期间表现出不规则性时，基于路径的解释器的性能可能会受到损害。在这种情况下，我们介绍了Quantified Uncertainty Counterfactual Explanations（QUCE），这是一种旨在减少路径不确定性的方法，以缓解越界遍历。 QUCE不仅在提出解释时量化不确定性

    arXiv:2402.17516v1 Announce Type: cross  Abstract: Deep Neural Networks (DNNs) stand out as one of the most prominent approaches within the Machine Learning (ML) domain. The efficacy of DNNs has surged alongside recent increases in computational capacity, allowing these approaches to scale to significant complexities for addressing predictive challenges in big data. However, as the complexity of DNN models rises, interpretability diminishes. In response to this challenge, explainable models such as Adversarial Gradient Integration (AGI) leverage path-based gradients provided by DNNs to elucidate their decisions. Yet the performance of path-based explainers can be compromised when gradients exhibit irregularities during out-of-distribution path traversal. In this context, we introduce Quantified Uncertainty Counterfactual Explanations (QUCE), a method designed to mitigate out-of-distribution traversal by minimizing path uncertainty. QUCE not only quantifies uncertainty when presenting e
    
[^142]: 科学检查者再度升级：透明度和逻辑推理的双向范式

    Science Checker Reloaded: A Bidirectional Paradigm for Transparency and Logical Reasoning

    [https://arxiv.org/abs/2402.13897](https://arxiv.org/abs/2402.13897)

    提出了一个两块式的方法来解决长文档中信息检索领域的挑战，并实现了双向交互

    

    信息检索是一个快速发展的领域。然而，它仍然面临着在科学和工业的海量信息中的诸多限制，比如语义分歧和检索中的词汇差距、语义搜索中的低精度和缺乏可解释性，或者生成模型中的幻觉和过时信息。在本文中，我们提出了一个两块式的方法来解决长文档的这些障碍。第一个模块通过查询扩展增强了在稀疏检索中的语言理解，以检索相关文档。第二个模块通过只使用长文档中传播的信息，为复杂问题提供全面和信息丰富的答案来加深结果，实现双向交互。在管道的各个阶段，向用户呈现中间结果以促进对系统推理的理解。我们相信这种双向方法带来了

    arXiv:2402.13897v1 Announce Type: cross  Abstract: Information retrieval is a rapidly evolving field. However it still faces significant limitations in the scientific and industrial vast amounts of information, such as semantic divergence and vocabulary gaps in sparse retrieval, low precision and lack of interpretability in semantic search, or hallucination and outdated information in generative models. In this paper, we introduce a two-block approach to tackle these hurdles for long documents. The first block enhances language understanding in sparse retrieval by query expansion to retrieve relevant documents. The second block deepens the result by providing comprehensive and informative answers to the complex question using only the information spread in the long document, enabling bidirectional engagement. At various stages of the pipeline, intermediate results are presented to users to facilitate understanding of the system's reasoning. We believe this bidirectional approach brings
    
[^143]: Me LLaMA: 为医疗应用构建大型语言模型的基础

    Me LLaMA: Foundation Large Language Models for Medical Applications

    [https://arxiv.org/abs/2402.12749](https://arxiv.org/abs/2402.12749)

    Me LLaMA是一个医学领域的大型语言模型系列，通过持续预训练和指导调整在大型医学数据集上训练而成，其在零-shot和少-shot学习方面表现优于现有的医学语言模型和商业巨头ChatGPT。

    

    最近，诸如ChatGPT和LLaMA等大型语言模型(LLMs)在许多人工智能应用中展现出巨大的潜力。然而，它们在医学任务上的表现不够理想，并且可以通过在大型领域特定数据集上进行训练来进一步改进。本研究引入了Me LLaMA，一个医学LLM系列，包括基础模型- Me LLaMA 13/70B及其 chat-enhanced 版本- Me LLaMA 13/70B-chat，通过持续对LLaMA2进行预训练和指导调整，使用大规模医学数据开发而成。我们用于训练和评估的领域特定数据套件包括一个具有129B tokens的大规模持续预训练数据集，一个包含214k个样本的指导调整数据集，以及跨越14个数据集的六项任务的医学评估基准(MIBE)。我们使用MIBE进行的广泛评估显示，Me LLaMA模型在零-shot和少-shot学习方面超越了现有的开源医学LLMs，并且在商业巨头如ChatGPT上表现出色。

    arXiv:2402.12749v1 Announce Type: cross  Abstract: Recent large language models (LLMs) like ChatGPT and LLaMA have shown great promise in many AI applications. However, their performance on medical tasks is suboptimal and can be further improved by training on large domain-specific datasets. This study introduces Me LLaMA, a medical LLM family including foundation models - Me LLaMA 13/70B and their chat-enhanced versions - Me LLaMA 13/70B-chat, developed through the continual pre-training and instruction tuning of LLaMA2 using large medical data. Our domain-specific data suite for training and evaluation, includes a large-scale continual pre-training dataset with 129B tokens, an instruction tuning dataset with 214k samples, and a medical evaluation benchmark (MIBE) across six tasks with 14 datasets. Our extensive evaluation using MIBE shows that Me LLaMA models surpass existing open-source medical LLMs in zero-shot and few-shot learning and outperform commercial giants like ChatGPT on 
    
[^144]: PAC-FNO：并行结构全组分傅立叶神经算子用于识别低质量图像

    PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images

    [https://arxiv.org/abs/2402.12721](https://arxiv.org/abs/2402.12721)

    提出了一个新颖的神经网络模型 PAC-FNO，通过在频域操作可以处理不同分辨率的图像，解决了传统方法在处理这类问题上的计算成本高的挑战。

    

    开发图像识别模型的标准做法是在特定图像分辨率上训练模型，然后部署它。然而，在现实推理中，模型经常遇到与训练集中不同分辨率的图像和/或受到自然变化的影响，例如天气变化、噪声类型和压缩伪影。传统解决方案涉及为不同分辨率或输入变化训练多个模型，但这些方法在实践中计算成本高，因此不可扩展。为此，我们提出了一种新颖的神经网络模型，即并行结构和全组分傅立叶神经算子（PAC-FNO），来解决这个问题。与传统的前馈神经网络不同，PAC-FNO在频域进行操作，使其能够在单个模型内处理不同分辨率的图像。我们还提出了一个两阶段算法，以最小的修改训练PAC-FNO。

    arXiv:2402.12721v1 Announce Type: cross  Abstract: A standard practice in developing image recognition models is to train a model on a specific image resolution and then deploy it. However, in real-world inference, models often encounter images different from the training sets in resolution and/or subject to natural variations such as weather changes, noise types and compression artifacts. While traditional solutions involve training multiple models for different resolutions or input variations, these methods are computationally expensive and thus do not scale in practice. To this end, we propose a novel neural network model, parallel-structured and all-component Fourier neural operator (PAC-FNO), that addresses the problem. Unlike conventional feed-forward neural networks, PAC-FNO operates in the frequency domain, allowing it to handle images of varying resolutions within a single model. We also propose a two-stage algorithm for training PAC-FNO with a minimal modification to the orig
    
[^145]: 模型编辑的蝴蝶效应：少量编辑可能引发大规模语言模型崩溃

    The Butterfly Effect of Model Editing: Few Edits Can Trigger Large Language Models Collapse

    [https://arxiv.org/abs/2402.09656](https://arxiv.org/abs/2402.09656)

    尽管模型编辑在大型语言模型中显示出修订知识的潜力，但少量编辑可以触发模型崩溃，导致性能显著下降。我们提出使用困惑度作为替代指标，并通过实验证实其与下游任务性能的强相关性。

    

    虽然模型编辑已显示出在大型语言模型（LLMs）中修订知识的潜力，但其对LLMs的内在能力的影响常常被忽视。在这项工作中，我们揭示了一个关键现象：即使只进行一个编辑，也可以引发模型崩溃，表现为各种基准任务中性能显著下降。然而，在每次编辑后对LLMs进行基准测试虽然必要，但耗时且资源密集。为了缓解这个问题，我们提出使用困惑度作为替代指标，并通过大量实验证实其与下游任务性能的强相关性。我们还对顺序编辑进行了深入研究，这是实际场景中的一种常见情况，涵盖了来自我们之前单次编辑研究中的困难案例。结果表明，几乎所有研究的编辑方法都导致模型崩溃。

    arXiv:2402.09656v1 Announce Type: new  Abstract: Although model editing has shown promise in revising knowledge in Large Language Models (LLMs), its impact on the inherent capabilities of LLMs is often overlooked. In this work, we reveal a critical phenomenon: even a single edit can trigger model collapse, manifesting as significant performance degradation in various benchmark tasks. However, benchmarking LLMs after each edit, while necessary to prevent such collapses, is impractically time-consuming and resource-intensive. To mitigate this, we propose using perplexity as a surrogate metric, validated by extensive experiments demonstrating its strong correlation with downstream task performance. We further conduct an in-depth study on sequential editing, a practical setting for real-world scenarios, across various editing methods and LLMs, focusing on hard cases from our previous single edit studies. The results indicate that nearly all examined editing methods result in model collapse
    
[^146]: VisLingInstruct: 通过自主指导优化提升多模态语言模型中的零样本学习

    VisLingInstruct: Elevating Zero-Shot Learning in Multi-Modal Language Models with Autonomous Instruction Optimization

    [https://arxiv.org/abs/2402.07398](https://arxiv.org/abs/2402.07398)

    VisLingInstruct通过自主优化指导文本和视觉特征提取模块，显著提高了多模态语言模型在零样本学习中的性能，在TextVQA和HatefulMemes数据集上的准确率分别提高了13.1%和9%。

    

    本文介绍了VisLingInstruct，这是一种在多模态语言模型中推进零样本学习的新方法。当前的多模态语言模型在多模态任务中展现出令人印象深刻的零样本能力，但它们的性能严重依赖于指导文本的质量。VisLingInstruct通过自主评估和优化指导文本，通过上下文学习改进多模态语言模型中视觉感知和语言表达之间的协同作用。除了指导文本的改进之外，我们还优化了多模态语言模型中的视觉特征提取模块，进一步增强了对文本提示的响应能力。基于FlanT5和Vicuna的综合实验结果显示，VisLingInstruct显著提高了在视觉多模态任务中的零样本性能。值得注意的是，它在TextVQA和HatefulMemes数据集上的准确率分别比之前的最先进方法提高了13.1%和9%。

    This paper presents VisLingInstruct, a novel approach to advancing Multi-Modal Language Models (MMLMs) in zero-shot learning. Current MMLMs show impressive zero-shot abilities in multi-modal tasks, but their performance depends heavily on the quality of instructions. VisLingInstruct tackles this by autonomously evaluating and optimizing instructional texts through In-Context Learning, improving the synergy between visual perception and linguistic expression in MMLMs. Alongside this instructional advancement, we have also optimized the visual feature extraction modules in MMLMs, further augmenting their responsiveness to textual cues. Our comprehensive experiments on MMLMs, based on FlanT5 and Vicuna, show that VisLingInstruct significantly improves zero-shot performance in visual multi-modal tasks. Notably, it achieves a 13.1% and 9% increase in accuracy over the prior state-of-the-art on the TextVQA and HatefulMemes datasets.
    
[^147]: FedImpro: 测量和改善联邦学习中的客户更新

    FedImpro: Measuring and Improving Client Update in Federated Learning

    [https://arxiv.org/abs/2402.07011](https://arxiv.org/abs/2402.07011)

    本文提出了FedImpro方法，通过生成改进的本地模型来减轻联邦学习中的客户漂移问题。该方法通过分析本地训练的泛化贡献，并利用类似的条件分布进行训练，增强了泛化贡献并减小了梯度的差异性。

    

    联邦学习模型通常会受到异构数据引起的客户漂移的影响，其中数据的分布在不同的客户之间存在差异。为了解决这个问题，先进的研究主要关注于操作现有的梯度，以实现更一致的客户模型。在本文中，我们从另一个角度分析了客户漂移，并旨在通过生成改进的本地模型来减轻这种漂移。首先，我们分析了本地训练的泛化贡献，并得出结论，这种泛化贡献受到不同客户的数据分布之间的条件Wasserstein距离的限制。然后，我们提出了FedImpro，用于构建类似的条件分布进行本地训练。具体而言，FedImpro将模型分解为高层和低层组件，并对重构特征分布上的高层部分进行训练。这种方法增强了泛化贡献，并减小了联邦学习中梯度的差异性。

    Federated Learning (FL) models often experience client drift caused by heterogeneous data, where the distribution of data differs across clients. To address this issue, advanced research primarily focuses on manipulating the existing gradients to achieve more consistent client models. In this paper, we present an alternative perspective on client drift and aim to mitigate it by generating improved local models. First, we analyze the generalization contribution of local training and conclude that this generalization contribution is bounded by the conditional Wasserstein distance between the data distribution of different clients. Then, we propose FedImpro, to construct similar conditional distributions for local training. Specifically, FedImpro decouples the model into high-level and low-level components, and trains the high-level portion on reconstructed feature distributions. This approach enhances the generalization contribution and reduces the dissimilarity of gradients in FL. Exper
    
[^148]: HEAM: 使用处理-内存进行散列嵌入加速的方法

    HEAM : Hashed Embedding Acceleration using Processing-In-Memory

    [https://arxiv.org/abs/2402.04032](https://arxiv.org/abs/2402.04032)

    HEAM是一种采用异构内存架构的方法，将3D堆叠DRAM与DIMM集成，用于加速处理大规模个性化推荐系统中的嵌入操作。

    

    在当今的数据中心中，个性化推荐系统面临着诸多挑战，特别是在执行嵌入操作时需要大容量的内存和高带宽。之前的方法依赖于DIMM-based近内存处理技术或引入3D堆叠DRAM来解决内存限制和扩展内存带宽的问题。然而，这些解决方案在处理日益扩大的个性化推荐系统大小时存在不足之处。推荐模型已经增长到超过数十TB的大小，导致在传统单节点推断服务器上高效运行变得困难。尽管已经提出了各种算法方法来减小嵌入表容量，但通常会导致内存访问增加或内存资源利用低效的问题。本文引入了HEAM，一种异构内存架构，将3D堆叠DRAM与DIMM集成在一起，以加速组合嵌入的推荐系统。

    In today's data centers, personalized recommendation systems face challenges such as the need for large memory capacity and high bandwidth, especially when performing embedding operations. Previous approaches have relied on DIMM-based near-memory processing techniques or introduced 3D-stacked DRAM to address memory-bound issues and expand memory bandwidth. However, these solutions fall short when dealing with the expanding size of personalized recommendation systems. Recommendation models have grown to sizes exceeding tens of terabytes, making them challenging to run efficiently on traditional single-node inference servers. Although various algorithmic methods have been proposed to reduce embedding table capacity, they often result in increased memory access or inefficient utilization of memory resources. This paper introduces HEAM, a heterogeneous memory architecture that integrates 3D-stacked DRAM with DIMM to accelerate recommendation systems in which compositional embedding is util
    
[^149]: SNAP: 用于下一步活动预测的语义故事

    SNAP: Semantic Stories for Next Activity Prediction

    [https://arxiv.org/abs/2401.15621](https://arxiv.org/abs/2401.15621)

    SNAP方法利用语言基础模型构建语义上下文故事，从过程历史事件日志中提取信息，用于预测下一步活动。

    

    预测正在进行过程中的下一个活动是业务流程管理（BPM）领域中最常见的分类任务之一。它使企业能够优化资源分配，提高运营效率，并有助于风险缓解和战略决策。这为BPM和AI快速演变的交汇提供了竞争优势。现有的业务流程预测AI模型未充分利用过程事件日志中可用的语义信息。鉴于当前先进的AI-BPM系统提供更丰富的文本数据，因此需要新颖的充分模型。为了填补这一差距，我们提出了一种新颖的SNAP方法，通过构建语义上下文故事从过程历史事件日志中获得，并将其用于下一步活动预测。我们将SNAP算法与九种最先进模型在六

    arXiv:2401.15621v2 Announce Type: replace  Abstract: Predicting the next activity in an ongoing process is one of the most common classification tasks in the business process management (BPM) domain. It allows businesses to optimize resource allocation, enhance operational efficiency, and aids in risk mitigation and strategic decision-making. This provides a competitive edge in the rapidly evolving confluence of BPM and AI. Existing state-of-the-art AI models for business process prediction do not fully capitalize on available semantic information within process event logs. As current advanced AI-BPM systems provide semantically-richer textual data, the need for novel adequate models grows. To address this gap, we propose the novel SNAP method that leverages language foundation models by constructing semantic contextual stories from the process historical event logs and using them for the next activity prediction. We compared the SNAP algorithm with nine state-of-the-art models on six 
    
[^150]: 利用LLM绕过文本到图像模型的安全过滤器的分而治之攻击

    Divide-and-Conquer Attack: Harnessing the Power of LLM to Bypass Safety Filters of Text-to-Image Models

    [https://arxiv.org/abs/2312.07130](https://arxiv.org/abs/2312.07130)

    该论文介绍了一种称为分而治之攻击的方法，利用LLM作为文本转换代理绕过文本到图像模型的安全过滤器。该攻击设计了攻击辅助提示，引导LLM将不道德的绘图意图分解为多个个体图像元素的良性描述，以绕过安全过滤器生成不道德的图像。实验结果表明，该攻击成功地绕过了多个强大的封闭式安全过滤器。

    

    文本到图像（TTI）模型提供许多创新服务，但也引发了道义关切，因为它们有潜力生成不道德的图像。大多数公共TTI服务采用安全过滤器来防止意外图像的生成。在本研究中，我们引入了分而治之攻击，以绕过最先进的TTI模型（包括DALL-E 3和Midjourney）的安全过滤器。我们的攻击利用LLMs作为文本转换代理来创建对抗性提示。我们设计了攻击辅助提示，有效地引导LLMs将不道德的绘图意图分解为多个个体图像元素的良性描述，从而使它们能够绕过安全过滤器，同时生成不道德的图像。因为只有当所有个体元素都被绘制在一起时，潜在的有害含义才会显现出来。我们的评估表明，我们的攻击成功地绕过了多个强大的封闭式安全过滤器。

    Text-to-image (TTI) models offer many innovative services but also raise ethical concerns due to their potential to generate unethical images. Most public TTI services employ safety filters to prevent unintended images. In this work, we introduce the Divide-and-Conquer Attack to circumvent the safety filters of state-of the-art TTI models, including DALL-E 3 and Midjourney. Our attack leverages LLMs as text transformation agents to create adversarial prompts. We design attack helper prompts that effectively guide LLMs to break down an unethical drawing intent into multiple benign descriptions of individual image elements, allowing them to bypass safety filters while still generating unethical images. Because the latent harmful meaning only becomes apparent when all individual elements are drawn together. Our evaluation demonstrates that our attack successfully circumvents multiple strong closed-box safety filters. The comprehensive success rate of DACA bypassing the safety filters of t
    
[^151]: 农业预测的创新：全球作物产量预测的多元回归研究

    Innovations in Agricultural Forecasting: A Multivariate Regression Study on Global Crop Yield Prediction

    [https://arxiv.org/abs/2312.02254](https://arxiv.org/abs/2312.02254)

    通过实施六个回归模型并使用关键训练参数，该研究提出了一个随机森林回归模型，用于预测37个发展中国家27年的农作物产量，取得了0.94的确定系数，并探讨了不同因素对产量的影响。

    

    农作物产量的全球预测是农业研究中一个至关重要的目标。因此，该研究实施了6个回归模型（线性、决策树、梯度下降、梯度提升、K最近邻和随机森林），以预测37个发展中国家27年的农作物产量。在给定4个关键的训练参数（杀虫剂量（吨）、降雨量（mm）、温度（摄氏度）和产量（hg/ha））的情况下，发现我们的随机森林回归模型达到了0.94的确定系数（r2），误差边际（ME）为0.03。这些模型使用联合国粮食和农业组织的数据以及世界银行气候变化数据目录进行训练和测试。此外，分析了每个参数，以了解不同因素如何影响总体产量。我们使用了与通常使用的深度学习（DL）和机器学习（ML）模型相反的非传统模型。

    arXiv:2312.02254v2 Announce Type: replace-cross  Abstract: The prediction of crop yields internationally is a crucial objective in agricultural research. Thus, this study implements 6 regression models (Linear, Tree, Gradient Descent, Gradient Boosting, K Nearest Neighbors, and Random Forest) to predict crop yields in 37 developing countries over 27 years. Given 4 key training parameters, insecticides (tonnes), rainfall (mm), temperature (Celsius), and yield (hg/ha), it was found that our Random Forest Regression model achieved a determination coefficient (r2) of 0.94, with a margin of error (ME) of .03. The models were trained and tested using the Food and Agricultural Organization of the United Nations data, along with the World Bank Climate Change Data Catalog. Furthermore, each parameter was analyzed to understand how varying factors could impact overall yield. We used unconventional models, contrary to generally used Deep Learning (DL) and Machine Learning (ML) models, combined wi
    
[^152]: SynFundus-1M：具有十五种注释的高质量百万规模合成眼底图像数据集

    SynFundus-1M: A High-quality Million-scale Synthetic fundus images Dataset with Fifteen Types of Annotation

    [https://arxiv.org/abs/2312.00377](https://arxiv.org/abs/2312.00377)

    SynFundus-1M是一个包含超过一百万张眼底图像的高质量合成数据集，涵盖十一个疾病类型，并赋予关键区域四个可读性标签，在目前是最大且具有最复杂注释的眼底数据集之一。

    

    大规模具有高质量注释的公共数据集在智能医学影像研究中很少见，这是因为数据隐私和注释成本的考虑。本文发布了SynFundus-1M，这是一个高质量的合成数据集，包含一百多万幅眼底图像，涵盖了十一个疾病类型。此外，我们还故意为眼底图像的关键区域分配了四个可读性标签。据我们所知，SynFundus-1M目前是具有最复杂注释的最大眼底数据集。我们利用来自各种情境的超过130万个私有真实眼底图像训练了一种强大的去噪扩散概率模型，称为SynFundus-Generator。发布的SynFundus-1M是由SynFundus-Generator在预定义条件下生成的。为了展示SynFundus-1M的价值，我们设计了大量实验，涵盖以下方面：

    arXiv:2312.00377v4 Announce Type: replace-cross  Abstract: Large-scale public datasets with high-quality annotations are rarely available for intelligent medical imaging research, due to data privacy concerns and the cost of annotations. In this paper, we release SynFundus-1M, a high-quality synthetic dataset containing over one million fundus images in terms of \textbf{eleven disease types}. Furthermore, we deliberately assign four readability labels to the key regions of the fundus images. To the best of our knowledge, SynFundus-1M is currently the largest fundus dataset with the most sophisticated annotations. Leveraging over 1.3 million private authentic fundus images from various scenarios, we trained a powerful Denoising Diffusion Probabilistic Model, named SynFundus-Generator. The released SynFundus-1M are generated by SynFundus-Generator under predefined conditions. To demonstrate the value of SynFundus-1M, extensive experiments are designed in terms of the following aspect: 1)
    
[^153]: 我们应该疯狂吗？多Agent辩论策略对LLMs的影响

    Should we be going MAD? A Look at Multi-Agent Debate Strategies for LLMs

    [https://arxiv.org/abs/2311.17371](https://arxiv.org/abs/2311.17371)

    多Agent辩论（MAD）作为增强大型语言模型（LLMs）真实性的策略，对于解决确保生成代理提供准确可靠答案的挑战具有潜力，但当前形式下的多Agent辩论系统在可靠性上不一定优于其他提示策略。

    

    最近大型语言模型（LLMs）的发展突显了它们在回答各种领域问题方面的潜力。然而，确保生成代理提供准确可靠的答案仍然是一个持续挑战。在这种背景下，多Agent辩论（MAD）已成为增强LLMs真实性的一种有前途的策略。我们对一系列辩论和提示策略进行基准测试，探讨成本、时间和准确性之间的权衡。重要的是，我们发现，目前形式下的多Agent辩论系统在可靠性上不一定优于其他建议的提示策略，如自一致性和使用多个推理路径进行集成。但是，在执行超参数调整时，一些MAD系统，如Multi-Persona，表现更好。这表明MAD协议可能并不会比其他方法天然更差，而是更容易受到不同超参数的影响。

    arXiv:2311.17371v2 Announce Type: replace-cross  Abstract: Recent advancements in large language models (LLMs) underscore their potential for responding to inquiries in various domains. However, ensuring that generative agents provide accurate and reliable answers remains an ongoing challenge. In this context, multi-agent debate (MAD) has emerged as a promising strategy for enhancing the truthfulness of LLMs. We benchmark a range of debating and prompting strategies to explore the trade-offs between cost, time, and accuracy. Importantly, we find that multi-agent debating systems, in their current form, do not reliably outperform other proposed prompting strategies, such as self-consistency and ensembling using multiple reasoning paths. However, when performing hyperparameter tuning, several MAD systems, such as Multi-Persona, perform better. This suggests that MAD protocols might not be inherently worse than other approaches, but that they are more sensitive to different hyperparameter
    
[^154]: DyRA: 用于现有检测器的便携式动态分辨率调整网络

    DyRA: Portable Dynamic Resolution Adjustment Network for Existing Detectors

    [https://arxiv.org/abs/2311.17098](https://arxiv.org/abs/2311.17098)

    DyRA是一种动态分辨率调整网络，为现有的检测器提供图像特定的缩放因子，通过ParetoScaleLoss和BalanceLoss优化缩放因子以提高检测性能。

    

    实现目标检测中的恒定精度具有挑战性，因为物体尺寸固有的变化性。解决这个问题的一个有效方法涉及优化输入分辨率，称为多分辨率策略。先前的分辨率优化方法通常基于预定义的分辨率和手动选择。然而，对于现有架构的运行时分辨率优化缺乏研究。本文介绍了DyRA，一种动态分辨率调整网络，为现有的检测器提供图像特定的缩放因子。该网络与检测器一起进行联合训练，利用专门设计的损失函数，即ParetoScaleLoss和BalanceLoss。ParetoScaleLoss确定用于鲁棒性的自适应缩放因子，而BalanceLoss根据检测器的定位性能优化整体缩放因子。损失函数的设计旨在最小化精度损失。

    arXiv:2311.17098v3 Announce Type: replace-cross  Abstract: Achieving constant accuracy in object detection is challenging due to the inherent variability of object sizes. One effective approach to this problem involves optimizing input resolution, referred to as a multi-resolution strategy. Previous approaches to resolution optimization have often been based on pre-defined resolutions with manual selection. However, there is a lack of study on run-time resolution optimization for existing architectures. This paper introduces DyRA, a dynamic resolution adjustment network providing an image-specific scale factor for existing detectors. This network is co-trained with detectors utilizing specially designed loss functions, namely ParetoScaleLoss and BalanceLoss. ParetoScaleLoss determines an adaptive scale factor for robustness, while BalanceLoss optimizes overall scale factors according to the localization performance of the detector. The loss function is devised to minimize the accuracy 
    
[^155]: 视频人脸重龄化：迈向时间一致的人脸重龄化

    Video Face Re-Aging: Toward Temporally Consistent Face Re-Aging

    [https://arxiv.org/abs/2311.11642](https://arxiv.org/abs/2311.11642)

    该论文提出了一个新颖的合成视频数据集，设计了基线架构来验证其有效性，并开发了针对视频重龄化技术的时间一致性的新颖评估指标。

    

    视频人脸重龄化涉及在视频中将一个人的外观年龄改变到目标年龄。这个问题很具挑战性，因为缺乏在身份和年龄上保持时间一致性的配对视频数据集。大多数重龄化方法处理每个图像时都没有考虑视频的时间一致性。虽然一些现有工作通过在潜在空间中进行视频面部属性操作来解决时间一致问题，但它们通常在年龄转换方面表现不尽人意。为了解决这些问题，我们提出了（1）一个新颖的合成视频数据集，涵盖了各种年龄组的对象；（2）一个基线架构，旨在验证我们提出的数据集的有效性；以及（3）针对评估视频重龄化技术的时间一致性而设计的新颖度量标准。我们在公共数据集上进行了全面实验，包括

    arXiv:2311.11642v3 Announce Type: replace-cross  Abstract: Video face re-aging deals with altering the apparent age of a person to the target age in videos. This problem is challenging due to the lack of paired video datasets maintaining temporal consistency in identity and age. Most re-aging methods process each image individually without considering the temporal consistency of videos. While some existing works address the issue of temporal coherence through video facial attribute manipulation in latent space, they often fail to deliver satisfactory performance in age transformation. To tackle the issues, we propose (1) a novel synthetic video dataset that features subjects across a diverse range of age groups; (2) a baseline architecture designed to validate the effectiveness of our proposed dataset, and (3) the development of novel metrics tailored explicitly for evaluating the temporal consistency of video re-aging techniques. Our comprehensive experiments on public datasets, inclu
    
[^156]: 聊天机器人作为社交伴侣：人们如何看待机器中的意识、人类相似性和社会健康福利

    Chatbots as social companions: How people perceive consciousness, human likeness, and social health benefits in machines

    [https://arxiv.org/abs/2311.10599](https://arxiv.org/abs/2311.10599)

    伴侣聊天机器人使用者表示这些关系有益于他们的社会健康，与预期相反，非使用者则认为有害

    

    随着人工智能的普及，一个问题是人工智能与人类互动如何影响人际关系。例如，聊天机器人越来越被用作社交伴侣，尽管有很多猜测，但对他们的使用如何影响人际关系知之甚少。人们普遍认为与伴侣聊天机器人的关系对社会健康有害，但这种假设可能过于简单，特别考虑到用户的社会需求和他们现有人际关系的健康。为了了解与伴侣聊天机器人的关系如何影响社会健康，我们研究了定期使用伴侣聊天机器人和不使用它们的人。与期望相反，伴侣聊天机器人用户表示这些关系对他们的社会健康有益，而非用户则认为它们有害。

    arXiv:2311.10599v3 Announce Type: replace-cross  Abstract: As artificial intelligence (AI) becomes more widespread, one question that arises is how human-AI interaction might impact human-human interaction. Chatbots, for example, are increasingly used as social companions, and while much is speculated, little is known empirically about how their use impacts human relationships. A common hypothesis is that relationships with companion chatbots are detrimental to social health by harming or replacing human interaction, but this hypothesis may be too simplistic, especially considering the social needs of users and the health of their preexisting human relationships. To understand how relationships with companion chatbots impact social health, we studied people who regularly used companion chatbots and people who did not use them. Contrary to expectations, companion chatbot users indicated that these relationships were beneficial to their social health, whereas non-users viewed them as har
    
[^157]: Plum: 使用元启发式的提示学习

    Plum: Prompt Learning using Metaheuristic

    [https://arxiv.org/abs/2311.08364](https://arxiv.org/abs/2311.08364)

    提出了使用元启发式的提示学习方法，通过测试六种典型的元启发式方法，在大型语言模型的提示优化任务中取得了有效性。

    

    自从大型语言模型出现以来，提示学习已成为优化和定制这些模型的一种流行方法。特殊提示，如“思维链”，甚至揭示了这些模型内部先前未知的推理能力。然而，发现有效提示的进展缓慢，促使人们渴望一种通用的提示优化方法。不幸的是，现有的提示学习方法中很少有满足“通用”的标准，即同时具备自动、离散、黑盒、无梯度和可解释性。在本文中，我们引入元启发式，作为一种有希望的提示学习方法的离散非凸优化方法分支，拥有100多种选项。在我们的范式中，我们测试了六种典型方法：爬山、模拟退火、遗传算法（带/不带交叉）、禁忌搜索和和谐搜索，展示了它们在白盒模式下的有效性。

    arXiv:2311.08364v2 Announce Type: replace-cross  Abstract: Since the emergence of large language models, prompt learning has become a popular method for optimizing and customizing these models. Special prompts, such as Chain-of-Thought, have even revealed previously unknown reasoning capabilities within these models. However, the progress of discovering effective prompts has been slow, driving a desire for general prompt optimization methods. Unfortunately, few existing prompt learning methods satisfy the criteria of being truly "general", i.e., automatic, discrete, black-box, gradient-free, and interpretable all at once. In this paper, we introduce metaheuristics, a branch of discrete non-convex optimization methods with over 100 options, as a promising approach to prompt learning. Within our paradigm, we test six typical methods: hill climbing, simulated annealing, genetic algorithms with/without crossover, tabu search, and harmony search, demonstrating their effectiveness in white-b
    
[^158]: 欧几里得、射影、共形：为等变换器选择几何代数

    Euclidean, Projective, Conformal: Choosing a Geometric Algebra for Equivariant Transformers

    [https://arxiv.org/abs/2311.04744](https://arxiv.org/abs/2311.04744)

    该论文研究了基于欧几里得、射影和共形代数的Geometric Algebra Transformer架构，发现共形代数和改进的射影代数定义了功能强大、性能良好的变换器架构。

    

    Geometric Algebra Transformer（GATr）是一种基于射影几何代数的通用几何深度学习架构。我们将这种架构概括为一个蓝图，允许一个根据任何几何（或克利福德）代数来构建可扩展的变换器架构。我们研究了欧几里得、射影和共形代数版本的这种架构，它们都适合表示3D数据，并在理论和实践中进行了评估。最简单的欧几里得架构在计算上廉价，但对称群较小且不够样本高效，而射影模型表达能力不够。共形代数和改进版本的射影代数都定义了功能强大、性能良好的架构。

    arXiv:2311.04744v2 Announce Type: replace-cross  Abstract: The Geometric Algebra Transformer (GATr) is a versatile architecture for geometric deep learning based on projective geometric algebra. We generalize this architecture into a blueprint that allows one to construct a scalable transformer architecture given any geometric (or Clifford) algebra. We study versions of this architecture for Euclidean, projective, and conformal algebras, all of which are suited to represent 3D data, and evaluate them in theory and practice. The simplest Euclidean architecture is computationally cheap, but has a smaller symmetry group and is not as sample-efficient, while the projective model is not sufficiently expressive. Both the conformal algebra and an improved version of the projective algebra define powerful, performant architectures.
    
[^159]: LILO：通过压缩和文档化代码学习可解释库

    LILO: Learning Interpretable Libraries by Compressing and Documenting Code

    [https://arxiv.org/abs/2310.19791](https://arxiv.org/abs/2310.19791)

    LILO是一种神经符号框架，通过迭代地合成、压缩和文档化代码来构建可解释且适用于特定问题领域的程序库。在其中，LILO结合了大型语言模型引导的程序合成和程序自动重构的算法进展，并且通过自动文档过程使得代码抽象可解释并提升性能。

    

    尽管大型语言模型（LLMs）在代码生成方面表现出色，但软件开发的关键方面是重构的艺术：将代码整合到可重用和可读的程序库中。本文介绍了一种名为LILO的神经符号框架，它通过迭代地合成、压缩和文档化代码来构建适合特定问题领域的库。LILO将LLM引导的程序合成与Stitch自动重构的近期算法进展相结合：Stitch是一个符号压缩系统，可以高效地识别大型代码语料库中的最佳lambda抽象。为了使这些抽象可解释，我们引入了一种自动文档（AutoDoc）过程，它根据上下文中的使用示例推断出自然语言名称和文档字符串。除了提高人类可读性外，我们发现AutoDoc通过帮助LILO的合成器解释和部署学习到的抽象来提高性能。我们对LILO进行了三个归纳式程序综合的评估。

    While large language models (LLMs) now excel at code generation, a key aspect of software development is the art of refactoring: consolidating code into libraries of reusable and readable programs. In this paper, we introduce LILO, a neurosymbolic framework that iteratively synthesizes, compresses, and documents code to build libraries tailored to particular problem domains. LILO combines LLM-guided program synthesis with recent algorithmic advances in automated refactoring from Stitch: a symbolic compression system that efficiently identifies optimal lambda abstractions across large code corpora. To make these abstractions interpretable, we introduce an auto-documentation (AutoDoc) procedure that infers natural language names and docstrings based on contextual examples of usage. In addition to improving human readability, we find that AutoDoc boosts performance by helping LILO's synthesizer to interpret and deploy learned abstractions. We evaluate LILO on three inductive program synth
    
[^160]: 视觉语言模型是强化学习的零样本奖励模型

    Vision-Language Models are Zero-Shot Reward Models for Reinforcement Learning

    [https://arxiv.org/abs/2310.12921](https://arxiv.org/abs/2310.12921)

    使用预训练的视觉语言模型作为零样本奖励模型，在强化学习中指定任务，提高训练效率。

    

    强化学习（RL）要求手动指定奖励函数，这通常是不可行的，或者通过大量人类反馈学习奖励模型，这通常是非常昂贵的。本文研究了一种更加样本高效的替代方案：使用预训练的视觉语言模型（VLM）作为零样本奖励模型（RM），通过自然语言指定任务。我们提出了一种自然和通用的使用VLM作为奖励模型的方法，称为VLM-RMs。我们使用基于CLIP的VLM-RMs来训练MuJoCo人形模型学习复杂任务，而无需手动指定奖励函数，例如跪下、劈叉和盘腿坐。对于每个任务，我们仅提供一个描述所需任务的单个句子文本提示，减少提示工程。我们提供训练代理的视频链接：https://sites.google.com/view/vlm-rm。我们可以通过提供第二个“基准”提示来改善性能。

    arXiv:2310.12921v2 Announce Type: replace-cross  Abstract: Reinforcement learning (RL) requires either manually specifying a reward function, which is often infeasible, or learning a reward model from a large amount of human feedback, which is often very expensive. We study a more sample-efficient alternative: using pretrained vision-language models (VLMs) as zero-shot reward models (RMs) to specify tasks via natural language. We propose a natural and general approach to using VLMs as reward models, which we call VLM-RMs. We use VLM-RMs based on CLIP to train a MuJoCo humanoid to learn complex tasks without a manually specified reward function, such as kneeling, doing the splits, and sitting in a lotus position. For each of these tasks, we only provide a single sentence text prompt describing the desired task with minimal prompt engineering. We provide videos of the trained agents at: https://sites.google.com/view/vlm-rm. We can improve performance by providing a second "baseline" prom
    
[^161]: LLM4SGG: 用于弱监督场景图生成的大型语言模型

    LLM4SGG: Large Language Model for Weakly Supervised Scene Graph Generation

    [https://arxiv.org/abs/2310.10404](https://arxiv.org/abs/2310.10404)

    这种方法解决了弱监督场景图生成中的语义过度简化和低密度场景图问题。

    

    弱监督场景图生成（WSSGG）研究最近出现作为对严重依赖昂贵标注的全监督方法的另一种选择。在这方面，WSSGG研究利用图像标题获取未定位三元组，主要集中在对图像区域中的未定位三元组进行定位。然而，它们忽略了从标题中形成三元组的两个问题：1）从标题提取三元组时出现的语义过度简化问题，其中标题中的细粒度谓词不希望地转换为粗粒度谓词，导致长尾谓词分布，以及2）将标题中的三元组与感兴趣的实体/谓词类对齐时出现低密度场景图问题，其中许多三元组被丢弃且不用于训练，导致监督不足。为了解决这两个问题，我们提出了一种方法

    arXiv:2310.10404v5 Announce Type: cross  Abstract: Weakly-Supervised Scene Graph Generation (WSSGG) research has recently emerged as an alternative to the fully-supervised approach that heavily relies on costly annotations. In this regard, studies on WSSGG have utilized image captions to obtain unlocalized triplets while primarily focusing on grounding the unlocalized triplets over image regions. However, they have overlooked the two issues involved in the triplet formation process from the captions: 1) Semantic over-simplification issue arises when extracting triplets from captions, where fine-grained predicates in captions are undesirably converted into coarse-grained predicates, resulting in a long-tailed predicate distribution, and 2) Low-density scene graph issue arises when aligning the triplets in the caption with entity/predicate classes of interest, where many triplets are discarded and not used in training, leading to insufficient supervision. To tackle the two issues, we pro
    
[^162]: VeCLIP：通过富含视觉信息的标题改进CLIP训练

    VeCLIP: Improving CLIP Training via Visual-enriched Captions

    [https://arxiv.org/abs/2310.07699](https://arxiv.org/abs/2310.07699)

    本研究提出了一种通过将视觉概念融入标题中的方式来改进CLIP训练的方法，名为VeCLIP，该方法在大规模网络爬取数据集上展示了良好的性能。

    

    大规模网络爬取数据集对于预训练视觉-语言模型（如CLIP）的成功至关重要。然而，网络爬取的AltTexts存在固有的噪音和潜在的不相关性，造成了精确的图像-文字对齐方面的挑战。本研究引入了一种适用于嘈杂标题重写的可扩展流程。与利用大型语言模型（LLMs）进行标题重写的现有方法在小型策划数据集（如CC3M和CC12M）上已经显示出了希望。我们强调将视觉概念融入标题中，称为富含视觉信息的标题（VeCap），以确保数据多样性。为了优化AltTexts与新生成的VeCap的利用，我们提出了一种新颖的混合训练方案。我们展示了该方法在大规模网络爬取数据集上训练CLIP的适应性，称为VeCLIP。通过使用这种经济有效的流程，我们轻松扩展了我们的实验。

    arXiv:2310.07699v2 Announce Type: replace-cross  Abstract: Large-scale web-crawled datasets are fundamental for the success of pre-training vision-language models, such as CLIP. However, the inherent noise and potential irrelevance of web-crawled AltTexts pose challenges in achieving precise image-text alignment. Existing methods utilizing large language models (LLMs) for caption rewriting have shown promise on small, curated datasets like CC3M and CC12M. This study introduces a scalable pipeline for noisy caption rewriting. Unlike recent LLM rewriting techniques, we emphasize the incorporation of visual concepts into captions, termed as Visual-enriched Captions (VeCap). To ensure data diversity, we propose a novel mixed training scheme that optimizes the utilization of AltTexts alongside newly generated VeCap. We showcase the adaptation of this method for training CLIP on large-scale web-crawled datasets, termed VeCLIP. Employing this cost-effective pipeline, we effortlessly scale our
    
[^163]: 针对无监督域自适应夜间语义分割中动态和小物体的改进

    Towards Dynamic and Small Objects Refinement for Unsupervised Domain Adaptative Nighttime Semantic Segmentation

    [https://arxiv.org/abs/2310.04747](https://arxiv.org/abs/2310.04747)

    该论文提出了一种新颖的无监督域自适应方法，针对夜间语义分割中的动态和小物体，进行标签和特征级别的改进。

    

    夜间语义分割在实际应用中发挥着关键作用，如自动驾驶，其中经常遇到由于光照条件不足和缺乏良好注释数据集而造成的困难。此外，基于白天数据集训练的语义分割模型往往面临着在夜间条件下有效泛化的困难。无监督域自适应（UDA）已显示出解决这些挑战的潜力，并在夜间语义分割中取得了显著成果。然而，现有方法仍然存在以下限制：1）依赖风格转移或重光模型，这些模型难以泛化到复杂的夜间环境；2）忽视了动态和小物体（如车辆和杆子），这些物体难以直接从其他领域学习。

    arXiv:2310.04747v2 Announce Type: replace-cross  Abstract: Nighttime semantic segmentation plays a crucial role in practical applications, such as autonomous driving, where it frequently encounters difficulties caused by inadequate illumination conditions and the absence of well-annotated datasets. Moreover, semantic segmentation models trained on daytime datasets often face difficulties in generalizing effectively to nighttime conditions. Unsupervised domain adaptation (UDA) has shown the potential to address the challenges and achieved remarkable results for nighttime semantic segmentation. However, existing methods still face limitations in 1) their reliance on style transfer or relighting models, which struggle to generalize to complex nighttime environments, and 2) their ignorance of dynamic and small objects like vehicles and poles, which are difficult to be directly learned from other domains. This paper proposes a novel UDA method that refines both label and feature levels for 
    
[^164]: 谨言慎行：使用暂停标记训练语言模型

    Think before you speak: Training Language Models With Pause Tokens

    [https://arxiv.org/abs/2310.02226](https://arxiv.org/abs/2310.02226)

    引入暂停标记的语言模型训练方法可以让模型在输出标记前处理更多隐藏向量，取得了较好的实验结果

    

    语言模型通过立即连续生成一系列标记来生成响应: 第$(K+1)^{th}$个标记是通过操作每层的$K$个隐藏向量得到的，每个向量对应一个前面的标记。如果我们让模型在输出第$(K+1)^{th}$个标记之前操作更多的隐藏向量，比如说$K+10$个呢？我们通过在语言模型上进行训练和推断，引入了一个（可学习的）$\textit{pause}$标记，这一系列标记附加到输入前缀上。然后我们延迟提取模型的输出，直到最后一个暂停标记被看到，从而允许模型在做出答案之前进行额外的计算处理。我们在拥有1B和130M参数的仅解码器模型上进行了$\textit{pause-training}$的实证评估，在C4上进行了因果预训练，并在涵盖推理、问答、普遍理解和事实回忆等下游任务上进行了评估。我们的主要发现是，infer

    arXiv:2310.02226v2 Announce Type: replace-cross  Abstract: Language models generate responses by producing a series of tokens in immediate succession: the $(K+1)^{th}$ token is an outcome of manipulating $K$ hidden vectors per layer, one vector per preceding token. What if instead we were to let the model manipulate say, $K+10$ hidden vectors, before it outputs the $(K+1)^{th}$ token? We operationalize this idea by performing training and inference on language models with a (learnable) $\textit{pause}$ token, a sequence of which is appended to the input prefix. We then delay extracting the model's outputs until the last pause token is seen, thereby allowing the model to process extra computation before committing to an answer. We empirically evaluate $\textit{pause-training}$ on decoder-only models of 1B and 130M parameters with causal pretraining on C4, and on downstream tasks covering reasoning, question-answering, general understanding and fact recall. Our main finding is that infer
    
[^165]: 通过执行反馈使语言模型成为更好的工具学习者

    Making Language Models Better Tool Learners with Execution Feedback

    [https://arxiv.org/abs/2305.13068](https://arxiv.org/abs/2305.13068)

    这篇论文提出了一个名为TRICE的框架，通过执行反馈实现语言模型的工具学习，使其能够学会何时以及如何有效地使用工具。

    

    工具作为关键的界面，使人类能够理解和改变环境。随着基础模型的出现，AI系统可以利用工具扩展其能力并与真实世界互动。现有的工具学习方法包括监督微调和提示工程方法，通常使大型语言模型不加选择地利用工具，因为复杂任务往往超出了它们自身的能力。然而，为简单任务引入工具（模型本身可以轻松解决的任务），可能会无意间传播错误而不是提高性能。因此，研究问题是：我们能否教会语言模型何时以及如何使用工具？为满足这个需求，我们提出了Tool leaRning wIth exeCution fEedback (TRICE)，这是一个两阶段的端到端框架，使模型能够通过从工具执行中得到的反馈不断学习，从而学会何时以及如何有效地使用工具。

    Tools serve as pivotal interfaces that enable humans to understand and reshape the environment. With the advent of foundation models, AI systems can utilize tools to expand their capabilities and interact with the real world. Existing tool learning methodologies, encompassing supervised fine-tuning and prompt engineering approaches, often induce large language models to utilize tools indiscriminately, as complex tasks often exceed their own competencies. However, introducing tools for simple tasks, which the models themselves can readily resolve, can inadvertently propagate errors rather than enhance performance. This leads to the research question: can we teach language models when and how to use tools? To meet this need, we propose Tool leaRning wIth exeCution fEedback (TRICE), a two-stage end-to-end framework that enables the model to continually learn through feedback derived from tool execution, thereby learning when and how to use tools effectively. Experimental results, backed b
    
[^166]: 自适应Click：具有自适应焦点损失的点击感知Transformer用于交互式图像分割

    AdaptiveClick: Clicks-aware Transformer with Adaptive Focal Loss for Interactive Image Segmentation

    [https://arxiv.org/abs/2305.04276](https://arxiv.org/abs/2305.04276)

    AdaptiveClick 是首个基于Transformer的、针对交互式图像分割的遮罩自适应分割框架，引入了自适应焦点损失以解决注释不一致性，并提供了解决遮罩和像素级模糊的工具。

    

    交互式图像分割（IIS）已经成为减少注释时间的一种有前途的技术。在IIS的预处理和后处理方面已经取得了重大进展，但互动模糊的关键问题，尤其是阻碍了分割质量的问题，尚未得到充分研究。为了解决这个问题，我们引入了AdaptiveClick——一个点击感知的Transformer，结合了自适应焦点损失，以解决注释不一致性，并提供了解决遮罩和像素级模糊的工具。据我们所知，AdaptiveClick是第一个基于Transformer的、针对IIS的遮罩自适应分割框架。我们方法的关键部分是Click感知遮罩自适应Transformer解码器（CAMD），它增强了点击和图像特征之间的交互作用。此外，AdaptiveClick在决策空间中使像素自适应区分难易样本，独立于它们不断变化的分布。

    arXiv:2305.04276v2 Announce Type: replace-cross  Abstract: Interactive Image Segmentation (IIS) has emerged as a promising technique for decreasing annotation time. Substantial progress has been made in pre- and post-processing for IIS, but the critical issue of interaction ambiguity, notably hindering segmentation quality, has been under-researched. To address this, we introduce AdaptiveClick -- a click-aware transformer incorporating an adaptive focal loss that tackles annotation inconsistencies with tools for mask- and pixel-level ambiguity resolution. To the best of our knowledge, AdaptiveClick is the first transformer-based, mask-adaptive segmentation framework for IIS. The key ingredient of our method is the Click-Aware Mask-adaptive transformer Decoder (CAMD), which enhances the interaction between click and image features. Additionally, AdaptiveClick enables pixel-adaptive differentiation of hard and easy samples in the decision space, independent of their varying distributions
    
[^167]: 行动性原子概念学习用于解密视觉语言导航

    Actional Atomic-Concept Learning for Demystifying Vision-Language Navigation

    [https://arxiv.org/abs/2302.06072](https://arxiv.org/abs/2302.06072)

    提出了行动性原子概念学习（AACL）方法，将视觉观察映射到行动性原子概念，作为观察和指令之间的桥梁，减少语义差距并简化对齐。

    

    arXiv:2302.06072v2 公告类型：替换-跨摘要：视觉语言导航（VLN）是一项具有挑战性的任务，需要一个代理人将复杂的视觉观察结果与语言指令对齐，以达到目标位置。大多数现有的VLN代理直接学习将原始方向特征和使用一位标签训练的视觉特征与语言指令特征对齐。然而，这些多模态输入之间存在较大的语义差距使得对齐变得困难，从而限制了导航性能。在本文中，我们提出了行动性原子概念学习（AACL），它将视觉观察结果映射到行动性原子概念以促进对齐。具体而言，行动性原子概念是包含原子动作和对象的自然语言短语，例如“上楼梯”。这些行动性原子概念作为观察和指令之间的桥梁，可以有效减少语义差距并简化对齐。AACL

    arXiv:2302.06072v2 Announce Type: replace-cross  Abstract: Vision-Language Navigation (VLN) is a challenging task which requires an agent to align complex visual observations to language instructions to reach the goal position. Most existing VLN agents directly learn to align the raw directional features and visual features trained using one-hot labels to linguistic instruction features. However, the big semantic gap among these multi-modal inputs makes the alignment difficult and therefore limits the navigation performance. In this paper, we propose Actional Atomic-Concept Learning (AACL), which maps visual observations to actional atomic concepts for facilitating the alignment. Specifically, an actional atomic concept is a natural language phrase containing an atomic action and an object, e.g., ``go up stairs''. These actional atomic concepts, which serve as the bridge between observations and instructions, can effectively mitigate the semantic gap and simplify the alignment. AACL co
    
[^168]: 智能家居中的能量分解与电器识别：迁移学习实现边缘计算

    Energy Disaggregation & Appliance Identification in a Smart Home: Transfer Learning enables Edge Computing

    [https://arxiv.org/abs/2301.03018](https://arxiv.org/abs/2301.03018)

    迁移学习结合边缘计算，提出了新的深度学习方法解决非侵入式负载监视问题和电器识别问题，利用改进的CNN模型和预训练模型获得更准确的结果。

    

    非侵入式负载监视（NILM）或能量分解旨在在智能家居的总负载配置文件的基础上提取单个消费电子设备的负载配置文件。这项工作提出了一种新颖的深度学习和边缘计算方法来解决NILM问题以及一些相关问题。1）我们在著名的seq2-point卷积神经网络（CNN）模型的基础上构建了提出的seq2-[3]-point CNN模型，以解决（家庭）NILM问题和站点NILM问题（基本上是在较小规模上的NILM）。2）我们通过借鉴最先进的（预训练）2D-CNN模型，即AlexNet、ResNet-18和DenseNet-121，解决了电器识别的相关问题，这些模型被微调以适应两个自定义数据集，这些数据集包含电器基于小波变换和短时傅里叶变换（STFT）的2D电特征。3）最后，我们进行了一些基本的定性推断。

    arXiv:2301.03018v2 Announce Type: replace-cross  Abstract: Non-intrusive load monitoring (NILM) or energy disaggregation aims to extract the load profiles of individual consumer electronic appliances, given an aggregate load profile of the mains of a smart home. This work proposes a novel deep-learning and edge computing approach to solve the NILM problem and a few related problems as follows. 1) We build upon the reputed seq2-point convolutional neural network (CNN) model to come up with the proposed seq2-[3]-point CNN model to solve the (home) NILM problem and site-NILM problem (basically, NILM at a smaller scale). 2) We solve the related problem of appliance identification by building upon the state-of-the-art (pre-trained) 2D-CNN models, i.e., AlexNet, ResNet-18, and DenseNet-121, which are fine-tuned two custom datasets that consist of Wavelets and short-time Fourier transform (STFT)-based 2D electrical signatures of the appliances. 3) Finally, we do some basic qualitative inferen
    
[^169]: COMET：用于分布式深度学习训练的全面集群设计方法论

    COMET: A Comprehensive Cluster Design Methodology for Distributed Deep Learning Training

    [https://arxiv.org/abs/2211.16648](https://arxiv.org/abs/2211.16648)

    COMET提出了一种全面的集群设计方法论，用于研究并行化策略和关键集群资源配置对分布式DL训练性能的影响

    

    现代深度学习（DL）模型已经发展到需要大规模专门的、高端节点进行训练的大小。设计这样的集群以最大限度地提高性能和利用率--以摊销其高昂成本--是一项具有挑战性的任务，需要仔细平衡计算、内存和网络资源。此外，每个模型的众多调整旋钮极大地影响性能，最佳值往往取决于底层集群的特征，这要求进行复杂的集群-工作负载协同设计过程。为了促进这些大规模DL训练集群的设计空间探索，我们引入了COMET，这是一种综合的集群设计方法和工作流程，用于共同研究并行化策略和关键集群资源配置对分布式DL训练性能的影响。我们开发了一个逐步的过程，建立一种可重用和灵活的方法论，并加以演示。

    arXiv:2211.16648v2 Announce Type: replace-cross  Abstract: Modern Deep Learning (DL) models have grown to sizes requiring massive clusters of specialized, high-end nodes to train. Designing such clusters to maximize both performance and utilization--to amortize their steep cost--is a challenging task requiring careful balance of compute, memory, and network resources. Moreover, a plethora of each model's tuning knobs drastically affect the performance, with optimal values often depending on the underlying cluster's characteristics, which necessitates a complex cluster-workload co-design process. To facilitate the design space exploration of such massive DL training clusters, we introduce COMET, a holistic cluster design methodology and workflow to jointly study the impact of parallelization strategies and key cluster resource provisioning on the performance of distributed DL training. We develop a step-by-step process to establish a reusable and flexible methodology, and demonstrate it
    
[^170]: 自然语言上的多步演绎推理：基于超领域泛化的实证研究

    Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study on Out-of-Distribution Generalisation

    [https://arxiv.org/abs/2207.14000](https://arxiv.org/abs/2207.14000)

    提出了IMA-GloVe-GA，一个用于自然语言表达的多步推理的迭代神经推理网络，在超领域泛化方面具有更好的性能表现。

    

    将深度学习与符号逻辑推理结合起来，旨在充分利用这两个领域的成功，并引起了越来越多的关注。受DeepLogic启发，该模型经过端到端训练，用于执行逻辑程序推理，我们介绍了IMA-GloVe-GA，这是一个用自然语言表达的多步推理的迭代神经推理网络。在我们的模型中，推理是使用基于RNN的迭代内存神经网络进行的，其中包含一个门关注机制。我们在PARARULES、CONCEPTRULES V1和CONCEPTRULES V2三个数据集上评估了IMA-GloVe-GA。实验结果表明，带有门关注机制的DeepLogic比DeepLogic和其他RNN基线模型能够实现更高的测试准确性。我们的模型在规则被打乱时比RoBERTa-Large实现了更好的超领域泛化性能。此外，为了解决当前多步推理数据集中推理深度不平衡的问题

    arXiv:2207.14000v2 Announce Type: replace-cross  Abstract: Combining deep learning with symbolic logic reasoning aims to capitalize on the success of both fields and is drawing increasing attention. Inspired by DeepLogic, an end-to-end model trained to perform inference on logic programs, we introduce IMA-GloVe-GA, an iterative neural inference network for multi-step reasoning expressed in natural language. In our model, reasoning is performed using an iterative memory neural network based on RNN with a gate attention mechanism. We evaluate IMA-GloVe-GA on three datasets: PARARULES, CONCEPTRULES V1 and CONCEPTRULES V2. Experimental results show DeepLogic with gate attention can achieve higher test accuracy than DeepLogic and other RNN baseline models. Our model achieves better out-of-distribution generalisation than RoBERTa-Large when the rules have been shuffled. Furthermore, to address the issue of unbalanced distribution of reasoning depths in the current multi-step reasoning datase
    
[^171]: 使用直线路径插值对Denoising Diffusion GANs的SPI-GAN方法

    SPI-GAN: Denoising Diffusion GANs with Straight-Path Interpolations

    [https://arxiv.org/abs/2206.14464](https://arxiv.org/abs/2206.14464)

    SPI-GAN使用直线路径插值定义的增强型GAN去噪方法，能够在极大程度上减少采样时间，同时实现与SGMs相同的高采样质量和多样性。

    

    基于分数的生成模型（SGMs）展示了最先进的采样质量和多样性。然而，它们的训练/采样复杂性由于高度复杂的前向/后向过程而极高，因此不适合资源有限的环境。为了解决这个问题，目前对学习更简单过程的关注度正逐渐增加。我们提出了一种增强的基于GAN的去噪方法，称为SPI-GAN，使用我们提出的直线路径插值定义。为此，我们提出了一种GAN架构，通过直线路径去噪，并且由连续映射神经网络表征，以模仿去噪路径。这种方法大大减少了采样时间，同时实现了与SGMs相同的高采样质量和多样性。因此，SPI-GAN是CIFAR-10和CelebA-HQ-256中采样质量、多样性和时间中最均衡的模型之一。

    arXiv:2206.14464v3 Announce Type: replace-cross  Abstract: Score-based generative models (SGMs) show the state-of-the-art sampling quality and diversity. However, their training/sampling complexity is notoriously high due to the highly complicated forward/reverse processes, so they are not suitable for resource-limited settings. To solving this problem, learning a simpler process is gathering much attention currently. We present an enhanced GAN-based denoising method, called SPI-GAN, using our proposed straight-path interpolation definition. To this end, we propose a GAN architecture i) denoising through the straight-path and ii) characterized by a continuous mapping neural network for imitating the denoising path. This approach drastically reduces the sampling time while achieving as high sampling quality and diversity as SGMs. As a result, SPI-GAN is one of the best-balanced models among the sampling quality, diversity, and time for CIFAR-10, and CelebA-HQ-256.
    
[^172]: OpenXAI: 迈向透明评估模型解释

    OpenXAI: Towards a Transparent Evaluation of Model Explanations

    [https://arxiv.org/abs/2206.11104](https://arxiv.org/abs/2206.11104)

    OpenXAI 是一个开源框架，旨在评估和基准测试后续解释方法，提供了灵活的数据生成器、多种数据集和评估指标，用户可轻松扩展和比较不同解释方法。

    

    虽然最近文献中提出了几种后续解释方法，但对这些方法进行系统性基准测试的工作非常少。在这里，我们介绍了OpenXAI，一个全面且可扩展的开源框架，用于评估和基准测试后续解释方法。OpenXAI包括以下关键组件：（i）灵活的合成数据生成器和各种真实世界数据集、预训练模型和最先进特征归属方法的集合，以及（ii）用于评估解释方法忠实度、稳定性（鲁棒性）和公平性的十一种量化度量标准的开源实现，从而提供了对多种度量标准、模型和数据集上几种解释方法的比较。OpenXAI易于扩展，用户可以轻松评估自定义解释方法并将其纳入我们的排行榜中。

    arXiv:2206.11104v4 Announce Type: replace-cross  Abstract: While several types of post hoc explanation methods have been proposed in recent literature, there is very little work on systematically benchmarking these methods. Here, we introduce OpenXAI, a comprehensive and extensible open-source framework for evaluating and benchmarking post hoc explanation methods. OpenXAI comprises of the following key components: (i) a flexible synthetic data generator and a collection of diverse real-world datasets, pre-trained models, and state-of-the-art feature attribution methods, and (ii) open-source implementations of eleven quantitative metrics for evaluating faithfulness, stability (robustness), and fairness of explanation methods, in turn providing comparisons of several explanation methods across a wide variety of metrics, models, and datasets. OpenXAI is easily extensible, as users can readily evaluate custom explanation methods and incorporate them into our leaderboards. Overall, OpenXAI 
    
[^173]: 安全且广义的端到端自主驾驶系统：基于强化学习和示范的研究

    Safe and Generalized end-to-end Autonomous Driving System with Reinforcement Learning and Demonstrations. (arXiv:2401.11792v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2401.11792](http://arxiv.org/abs/2401.11792)

    本文介绍了一种安全且广义的端到端自主驾驶系统 (SGADS)，使用强化学习和示范相结合的方法解决了现有方法的低安全性、泛化能力差和采样效率低的问题，同时引入了变分推理和归一化流以准确预测驾驶轨迹，并提出了鲁棒性安全约束的制定方法。

    

    一个智能驾驶系统应该能够根据当前环境和车辆状态动态制定适当的驾驶策略，同时确保系统的安全性和可靠性。然而，基于强化学习和模仿学习的现有方法存在安全性低、泛化能力差和采样效率低的问题。此外，它们无法准确预测未来的驾驶轨迹，而准确预测未来的驾驶轨迹是做出最优决策的前提。为了解决这些问题，本文引入了一种复杂而多样场景下的安全且广义的端到端自主驾驶系统 (SGADS)。我们的SGADS与变分推理和归一化流结合，使智能车辆能够准确预测未来的驾驶轨迹。此外，我们提出了鲁棒性安全约束的制定。此外，我们将强化学习与示范相结合进行增强学习。

    An intelligent driving system should be capable of dynamically formulating appropriate driving strategies based on the current environment and vehicle status, while ensuring the security and reliability of the system. However, existing methods based on reinforcement learning and imitation learning suffer from low safety, poor generalization, and inefficient sampling. Additionally, they cannot accurately predict future driving trajectories, and the accurate prediction of future driving trajectories is a precondition for making optimal decisions. To solve these problems, in this paper, we introduce a Safe and Generalized end-to-end Autonomous Driving System (SGADS) for complex and various scenarios. Our SGADS incorporates variational inference with normalizing flows, enabling the intelligent vehicle to accurately predict future driving trajectories. Moreover, we propose the formulation of robust safety constraints. Furthermore, we combine reinforcement learning with demonstrations to aug
    
[^174]: LDReg: 本地维度正则化的自监督学习

    LDReg: Local Dimensionality Regularized Self-Supervised Learning. (arXiv:2401.10474v1 [cs.LG])

    [http://arxiv.org/abs/2401.10474](http://arxiv.org/abs/2401.10474)

    本文提出了一种叫做LDReg的本地维度正则化方法，用于解决自监督学习中的维度坍缩问题。通过增加局部内在维度，LDReg能够改善表示的性能。

    

    通过自监督学习（SSL）学习的表示可能容易出现维度坍缩，其中学习的表示子空间维度极低，因此无法表示完整的数据分布和模态。维度坍缩也被称为“填充不足”现象，是下游任务性能下降的主要原因之一。之前的工作在全局层面上研究了SSL的维度坍缩问题。在本文中，我们证明表示可以在全局上覆盖高维空间，但在局部上会坍缩。为了解决这个问题，我们提出了一种称为“本地维度正则化（LDReg）”的方法。我们的公式是基于Fisher-Rao度量的推导，用于比较和优化每个数据点在渐进小半径处的局部距离分布。通过增加局部内在维度，我们通过一系列实验证明LDReg可以改善表示。

    Representations learned via self-supervised learning (SSL) can be susceptible to dimensional collapse, where the learned representation subspace is of extremely low dimensionality and thus fails to represent the full data distribution and modalities. Dimensional collapse also known as the "underfilling" phenomenon is one of the major causes of degraded performance on downstream tasks. Previous work has investigated the dimensional collapse problem of SSL at a global level. In this paper, we demonstrate that representations can span over high dimensional space globally, but collapse locally. To address this, we propose a method called $\textit{local dimensionality regularization (LDReg)}$. Our formulation is based on the derivation of the Fisher-Rao metric to compare and optimize local distance distributions at an asymptotically small radius for each data point. By increasing the local intrinsic dimensionality, we demonstrate through a range of experiments that LDReg improves the repres
    
[^175]: 朝向生成式抽象推理：通过规则抽象和选择来完成Raven的渐进矩阵

    Towards Generative Abstract Reasoning: Completing Raven's Progressive Matrix via Rule Abstraction and Selection. (arXiv:2401.09966v1 [cs.AI])

    [http://arxiv.org/abs/2401.09966](http://arxiv.org/abs/2401.09966)

    本文提出了一个条件生成模型（RAISE），通过在潜在空间中进行规则抽象和选择，以解决Raven的渐进矩阵问题，该模型能够在现实的场景中展示出抽象推理的能力。

    

    在人工智能领域，赋予机器抽象推理能力是一个长期的研究课题。Raven的渐进矩阵（RPM）被广泛用于探索机器智能中的抽象视觉推理，模型需要理解潜在的规则并从候选集中选择缺失的右下图像来完成图像矩阵。参与者可以通过推断潜在的属性变化规则和想象任意位置的缺失图像展示强大的推理能力。然而，现有的解决方案很难在现实的RPM问题中展示出这种能力。在本文中，我们提出了一个条件生成模型，通过规则抽象和选择（RAISE）在潜在空间中解决答案生成问题。RAISE将图像属性编码为潜在概念，并通过概念将潜在规则分解成原子规则，这些原子规则被抽象为全局可学习的参数。在生成答案时，RAISE选择...

    Endowing machines with abstract reasoning ability has been a long-term research topic in artificial intelligence. Raven's Progressive Matrix (RPM) is widely used to probe abstract visual reasoning in machine intelligence, where models need to understand the underlying rules and select the missing bottom-right images out of candidate sets to complete image matrices. The participators can display powerful reasoning ability by inferring the underlying attribute-changing rules and imagining the missing images at arbitrary positions. However, existing solvers can hardly manifest such an ability in realistic RPM problems. In this paper, we propose a conditional generative model to solve answer generation problems through Rule AbstractIon and SElection (RAISE) in the latent space. RAISE encodes image attributes as latent concepts and decomposes underlying rules into atomic rules by means of concepts, which are abstracted as global learnable parameters. When generating the answer, RAISE select
    
[^176]: 最具区分性的刺激物用于功能细胞类型的识别

    Most discriminative stimuli for functional cell type identification. (arXiv:2401.05342v1 [q-bio.NC])

    [http://arxiv.org/abs/2401.05342](http://arxiv.org/abs/2401.05342)

    本文提出了一种使用最具区分性刺激物的优化聚类方法，成功地识别了小鼠视网膜、恒河猴视网膜和猕猴V4视觉区的功能细胞类型。

    

    识别细胞类型并理解其功能特性对揭示感知和认知机制至关重要。在视网膜中，可以通过精心选择的刺激物来识别功能类型，但这需要专业领域知识，并会对以前已知的细胞类型产生偏见。在视觉皮层中，仍然不知道存在什么功能类型以及如何识别它们。因此，需要新的方法来对视网膜和视觉皮层中的功能细胞类型进行无偏见的识别。在这里，我们提出了一种基于优化的聚类方法，使用最具区分性的刺激物（MDS）来获得神经元的功能聚类。我们的方法通过刺激物的优化和聚类重新分配之间的交替进行，类似于期望最大化算法。该算法成功恢复了小鼠视网膜、恒河猴视网膜和猕猴V4视觉区的功能聚类。这证明了我们的方法可以成功地进行功能细胞类型的识别。

    Identifying cell types and understanding their functional properties is crucial for unraveling the mechanisms underlying perception and cognition. In the retina, functional types can be identified by carefully selected stimuli, but this requires expert domain knowledge and biases the procedure towards previously known cell types. In the visual cortex, it is still unknown what functional types exist and how to identify them. Thus, for unbiased identification of the functional cell types in retina and visual cortex, new approaches are needed. Here we propose an optimization-based clustering approach using deep predictive models to obtain functional clusters of neurons using Most Discriminative Stimuli (MDS). Our approach alternates between stimulus optimization with cluster reassignment akin to an expectation-maximization algorithm. The algorithm recovers functional clusters in mouse retina, marmoset retina and macaque visual area V4. This demonstrates that our approach can successfully 
    
[^177]: 生成AI增强了个体创造力，但降低了新内容的集体多样性

    Generative AI enhances individual creativity but reduces the collective diversity of novel content. (arXiv:2312.00506v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2312.00506](http://arxiv.org/abs/2312.00506)

    生成AI增强了个体创造力，但降低了新内容的集体多样性。

    

    创造力是人类的核心。生成人工智能（GenAI），包括越来越强大的大型语言模型（LLM），通过提供新的想法使人类更具创造力，或通过锚定于GenAI的想法而变得不那么创造性。本研究通过在线实验研究探究了GenAI想法对一篇短篇小说创作的因果影响，其中一些作者可以从GenAI平台获取故事创意。我们发现，获取GenAI想法导致故事被评为更有创造力、写得更好和更令人愉悦，特别是在创造力较低的作者中。然而，GenAI启用的故事之间更相似，而不是仅由人类创作的故事。这些结果表明，个体创造力增加的同时，集体新颖性可能会减少。这种动态类似于社会困境：通过GenAI，个别作家能受益，但可能会产生更窄范围的新内容。我们的结果对研究人员、决策者有重要影响。

    Creativity is core to being human. Generative artificial intelligence (GenAI) -- including ever more powerful large language models (LLMs) -- holds promise for humans to be more creative by offering new ideas, or less creative by anchoring on GenAI ideas. We study the causal impact of GenAI ideas on the production of a short story in an online experimental study where some writers could obtain story ideas from a GenAI platform. We find that access to GenAI ideas causes stories to be evaluated as more creative, better written, and more enjoyable, especially among less creative writers. However, GenAI-enabled stories are more similar to each other than stories by humans alone. These results point to an increase in individual creativity at the risk of losing collective novelty. This dynamic resembles a social dilemma: with GenAI, individual writers are better off, but collectively a narrower scope of novel content may be produced. Our results have implications for researchers, policy-make
    
[^178]: 零坐标移动：针对物理约束操作学习的优化自动微分方法

    Zero Coordinate Shift: Whetted Automatic Differentiation for Physics-informed Operator Learning. (arXiv:2311.00860v1 [cs.LG])

    [http://arxiv.org/abs/2311.00860](http://arxiv.org/abs/2311.00860)

    本文提出了一种用于物理约束操作学习的新型自动微分算法，通过零坐标移动（ZCS）的技巧，将所需导数的复杂度从“多根多叶”简化为“一根多叶”，从而显著提高了性能。

    

    自动微分（AD）是物理约束机器学习中的关键步骤，用于计算网络输出相对于坐标的高阶导数。本文提出了一种新颖且轻量级的算法，用于进行针对物理约束操作学习的自动微分，称为零坐标移动（ZCS）的技巧。ZCS引入了一个标量值的叶变量，用于每个空间或时间维度，通过将所需导数从“多根多叶”简化为“一根多叶”，从而实现了性能的巨大提升。ZCS很容易在当前的深度学习库中实现；我们使用DeepXDE软件包进行了自己的实现。我们进行了全面的基准分析和多个案例研究，训练物理约束的DeepONets来解决无数据的偏微分方程（PDE）。结果表明，ZCS一直通过降低GPU内存消耗提供了改进效果。

    Automatic differentiation (AD) is a critical step in physics-informed machine learning, required for computing the high-order derivatives of network output w.r.t. coordinates. In this paper, we present a novel and lightweight algorithm to conduct such AD for physics-informed operator learning, as we call the trick of Zero Coordinate Shift (ZCS). Instead of making all sampled coordinates leaf variables, ZCS introduces only one scalar-valued leaf variable for each spatial or temporal dimension, leading to a game-changing performance leap by simplifying the wanted derivatives from "many-roots-many-leaves" to "one-root-many-leaves". ZCS is easy to implement with current deep learning libraries; our own implementation is by extending the DeepXDE package. We carry out a comprehensive benchmark analysis and several case studies, training physics-informed DeepONets to solve partial differential equations (PDEs) without data. The results show that ZCS has persistently brought down GPU memory co
    
[^179]: 强化微调语言模型中的梯度消失问题

    Vanishing Gradients in Reinforcement Finetuning of Language Models. (arXiv:2310.20703v1 [cs.LG])

    [http://arxiv.org/abs/2310.20703](http://arxiv.org/abs/2310.20703)

    本研究发现在强化微调（RFT）中存在梯度消失的问题，当模型下奖励的标准差较小时，输入的期望梯度会消失，导致奖励最大化缓慢。初始监督微调（SFT）阶段是克服这个问题的最有希望的方法。

    

    预训练的语言模型通过强化微调（RFT）与人类偏好和下游任务对齐，即使用策略梯度算法最大化（可能是学习得到的）奖励函数。本研究发现了RFT中的一个基本的优化障碍：我们证明了当模型下的奖励标准差较小时，输入的期望梯度会消失，即使期望奖励远离最优解。通过在RFT基准和控制环境中进行实验，以及理论分析，我们证明了由于小的奖励标准差导致的梯度消失问题普遍存在且有害，导致奖励最大化极其缓慢。最后，我们探索了克服RFT中梯度消失的方法。我们发现初始监督微调（SFT）阶段是最有希望的候选方法，并且揭示了它在RFT流程中的重要性。此外，我们还表明相对较小的训练数据集的SFT阶段可以有效克服梯度消失问题。

    Pretrained language models are commonly aligned with human preferences and downstream tasks via reinforcement finetuning (RFT), which entails maximizing a (possibly learned) reward function using policy gradient algorithms. This work highlights a fundamental optimization obstacle in RFT: we prove that the expected gradient for an input vanishes when its reward standard deviation under the model is small, even if the expected reward is far from optimal. Through experiments on an RFT benchmark and controlled environments, as well as a theoretical analysis, we then demonstrate that vanishing gradients due to small reward standard deviation are prevalent and detrimental, leading to extremely slow reward maximization. Lastly, we explore ways to overcome vanishing gradients in RFT. We find the common practice of an initial supervised finetuning (SFT) phase to be the most promising candidate, which sheds light on its importance in an RFT pipeline. Moreover, we show that a relatively small num
    
[^180]: 脑解码：走向实时重建视觉知觉

    Brain decoding: toward real-time reconstruction of visual perception. (arXiv:2310.19812v1 [eess.IV])

    [http://arxiv.org/abs/2310.19812](http://arxiv.org/abs/2310.19812)

    本研究提出了一种基于脑磁图（MEG）的脑解码方法，通过训练一个具有预训练嵌入、MEG模块和图像生成器的模型，在实时应用中实现了对视觉知觉的高时间分辨率解码，并在图像检索上取得了7倍的改进。

    

    在过去的五年中，生成式和基础性人工智能系统的使用极大地提高了对大脑活动的解码能力。特别是对于视觉知觉，现在可以从功能性磁共振成像（fMRI）中解码出令人瞩目的准确度。然而，这种神经影像技术的时间分辨率有限（约为0.5 Hz），因此在实时应用方面存在根本性的限制。在这里，我们提出了一种基于脑磁图（MEG）的替代方法，这是一种能够以高时间分辨率（约为5000 Hz）测量脑活动的神经影像设备。为此，我们开发了一个MEG解码模型，该模型通过对比和回归目标进行训练，并由三个模块组成：i）从图像中获得的预训练嵌入、ii）端到端训练的MEG模块以及iii）预训练的图像生成器。我们的结果有三个方面：首先，我们的MEG解码器在经典线性解码器上显示出7倍的图像检索改进。其次，后期脑部

    In the past five years, the use of generative and foundational AI systems has greatly improved the decoding of brain activity. Visual perception, in particular, can now be decoded from functional Magnetic Resonance Imaging (fMRI) with remarkable fidelity. This neuroimaging technique, however, suffers from a limited temporal resolution ($\approx$0.5 Hz) and thus fundamentally constrains its real-time usage. Here, we propose an alternative approach based on magnetoencephalography (MEG), a neuroimaging device capable of measuring brain activity with high temporal resolution ($\approx$5,000 Hz). For this, we develop an MEG decoding model trained with both contrastive and regression objectives and consisting of three modules: i) pretrained embeddings obtained from the image, ii) an MEG module trained end-to-end and iii) a pretrained image generator. Our results are threefold: Firstly, our MEG decoder shows a 7X improvement of image-retrieval over classic linear decoders. Second, late brain 
    
[^181]: Davidsonian场景图：改进文本-图像生成的细粒度评估的可靠性

    Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-Image Generation. (arXiv:2310.18235v1 [cs.CV])

    [http://arxiv.org/abs/2310.18235](http://arxiv.org/abs/2310.18235)

    本论文提出了Davidsonian场景图（DSG）的评估框架，解决了现有文本-图像生成模型评估中的可靠性挑战，包括QG问题的准确性和VQA答案的一致性。

    

    评估文本到图像模型一直是困难的。最近一种用于评估文本-图像忠实度的强大方法是基于QG/A（问题生成和回答），它使用预训练的基础模型自动生成一组问题和答案，并基于这些答案与基于提示的答案在视觉问题回答模型中提取的一致性对输出图像进行评分。这种评估自然上取决于底层QG和QA模型的质量。我们确定并解决了现有QG/A工作中的几个可靠性挑战：（a）QG问题应尊重提示（避免幻觉、重复和遗漏）和（b）VQA答案应一致（不会在图像中宣称没有摩托车，同时声称摩托车是蓝色）。我们通过Davidsonian场景图（DSG），这个受形式语义启发的实证评估框架，解决了这些问题。

    Evaluating text-to-image models is notoriously difficult. A strong recent approach for assessing text-image faithfulness is based on QG/A (question generation and answering), which uses pre-trained foundational models to automatically generate a set of questions and answers from the prompt, and output images are scored based on whether these answers extracted with a visual question answering model are consistent with the prompt-based answers. This kind of evaluation is naturally dependent on the quality of the underlying QG and QA models. We identify and address several reliability challenges in existing QG/A work: (a) QG questions should respect the prompt (avoiding hallucinations, duplications, and omissions) and (b) VQA answers should be consistent (not asserting that there is no motorcycle in an image while also claiming the motorcycle is blue). We address these issues with Davidsonian Scene Graph (DSG), an empirically grounded evaluation framework inspired by formal semantics. DSG
    
[^182]: 大型语言模型用于人工智能与人类协同创作的设计空间结构化生成与探索

    Structured Generation and Exploration of Design Space with Large Language Models for Human-AI Co-Creation. (arXiv:2310.12953v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2310.12953](http://arxiv.org/abs/2310.12953)

    这篇论文介绍了一种应用大型语言模型进行人工智能与人类协同创作的框架，通过结构化生成设计空间并提供无缝探索、评估和综合多种响应的功能，拓展了与大型语言模型在创意任务中的交互方式。

    

    大型语言模型(LLM)凭借其生成能力，已成为创意过程中的无价工具。这些模型能够产生数百甚至数千个视觉和文本输出，为创意努力提供了丰富的灵感。但我们是否充分发挥了它们的潜力？我们认为当前的交互范式存在不足之处，将用户引导到有限的一组想法上，而不是赋予他们探索生成模型中广阔的潜在设计空间的能力。为了解决这个问题，我们提出了一个框架，促进了设计空间的结构化生成，用户可以无缝地探索、评估和综合多种响应。通过设计和开发一个交互系统Luminate，并与8名专业作家进行用户研究，我们证明了该框架的可行性和实用性。我们的工作推进了我们与LLM在创意任务中的交互方式，引入了一种探索其潜力的方法。

    Thanks to their generative capabilities, large language models (LLMs) have become an invaluable tool for creative processes. These models have the capacity to produce hundreds and thousands of visual and textual outputs, offering abundant inspiration for creative endeavors. But are we harnessing their full potential? We argue that current interaction paradigms fall short, guiding users towards rapid convergence on a limited set of ideas, rather than empowering them to explore the vast latent design space in generative models. To address this limitation, we propose a framework that facilitates the structured generation of design space in which users can seamlessly explore, evaluate, and synthesize a multitude of responses. We demonstrate the feasibility and usefulness of this framework through the design and development of an interactive system, Luminate, and a user study with 8 professional writers. Our work advances how we interact with LLMs for creative tasks, introducing a way to ha
    
[^183]: 在大型预训练模型时代重新思考增量学习的测试时适应方法

    Rethinking Class-incremental Learning in the Era of Large Pre-trained Models via Test-Time Adaptation. (arXiv:2310.11482v1 [cs.CV])

    [http://arxiv.org/abs/2310.11482](http://arxiv.org/abs/2310.11482)

    本研究提出了一种名为“增量学习的测试时适应”的方法，通过在测试实例上进行微调，避免了在每个新任务上进行训练，从而在增量学习中实现了预训练模型的稳定性和可塑性的平衡。

    

    增量学习是一个具有挑战性的任务，涉及持续学习将类别划分到新任务中，同时不会遗忘先前学到的信息。大型预训练模型的出现加快了增量学习的进展，因为高度可传输的预训练模型表示使得在调整一小组参数时，与从头开始训练的传统增量学习方法相比，可以获得最先进的性能。然而，对每个任务进行反复微调会破坏预训练模型的丰富表示，并导致遗忘之前的任务。为了在增量学习中在预训练模型的稳定性和可塑性之间取得平衡，我们提出了一种新颖的方法，即通过直接在测试实例上进行测试时适应。具体而言，我们提出了“增量学习的测试时适应”（TTACIL），它首先在每个测试实例上对预训练模型的层归一化参数进行微调。

    Class-incremental learning (CIL) is a challenging task that involves continually learning to categorize classes into new tasks without forgetting previously learned information. The advent of the large pre-trained models (PTMs) has fast-tracked the progress in CIL due to the highly transferable PTM representations, where tuning a small set of parameters results in state-of-the-art performance when compared with the traditional CIL methods that are trained from scratch. However, repeated fine-tuning on each task destroys the rich representations of the PTMs and further leads to forgetting previous tasks. To strike a balance between the stability and plasticity of PTMs for CIL, we propose a novel perspective of eliminating training on every new task and instead performing test-time adaptation (TTA) directly on the test instances. Concretely, we propose "Test-Time Adaptation for Class-Incremental Learning" (TTACIL) that first fine-tunes Layer Norm parameters of the PTM on each test instan
    
[^184]: CodeChain: 通过代表性子模块的自我修订链路实现模块化代码生成

    CodeChain: Towards Modular Code Generation Through Chain of Self-revisions with Representative Sub-modules. (arXiv:2310.08992v1 [cs.AI])

    [http://arxiv.org/abs/2310.08992](http://arxiv.org/abs/2310.08992)

    CodeChain是一种通过代表性子模块的自我修订链路引导模块化代码生成的新框架，旨在解决大型语言模型在解决复杂编程任务方面的挑战。

    

    大型语言模型（LLM）已经在解决简单编程任务方面非常熟练，比如在HumanEval或MBPP基准测试中的任务。然而，对于更复杂和具有竞争性的编程任务，这些模型仍然面临挑战，可能是因为它们倾向于生成作为整体代码块而不是将其分解为逻辑子任务和子模块。另一方面，有经验的程序员本能地编写具有抽象概念的模块化代码来解决复杂任务，通常会重复使用之前开发的模块。为了解决这一差距，我们提出了CodeChain，一种通过代表性子模块的自我修订链路引导模块化代码生成的新框架。具体而言，CodeChain首先通过链式思考提示指导LLM生成模块化代码。然后，它通过迭代两个步骤实施自我修订链路：1）额外...

    Large Language Models (LLMs) have already become quite proficient at solving simpler programming tasks like those in HumanEval or MBPP benchmarks. However, solving more complex and competitive programming tasks is still quite challenging for these models - possibly due to their tendency to generate solutions as monolithic code blocks instead of decomposing them into logical sub-tasks and sub-modules. On the other hand, experienced programmers instinctively write modularized code with abstraction for solving complex tasks, often reusing previously developed modules. To address this gap, we propose CodeChain, a novel framework for inference that elicits modularized code generation through a chain of self-revisions, each being guided by some representative sub-modules generated in previous iterations. Concretely, CodeChain first instructs the LLM to generate modularized codes through chain-of-thought prompting. Then it applies a chain of self-revisions by iterating the two steps: 1) extra
    
[^185]: AI决策中解释对公平性的影响：受保护特征 vs 代理特征

    The Impact of Explanations on Fairness in Human-AI Decision-Making: Protected vs Proxy Features. (arXiv:2310.08617v1 [cs.AI])

    [http://arxiv.org/abs/2310.08617](http://arxiv.org/abs/2310.08617)

    论文研究了解释对AI决策公平性的影响。结果发现，解释有助于人们检测直接偏见，但对间接偏见的发现能力有限。

    

    已知AI系统可能会放大现实世界数据中的偏见。解释可能有助于人工智能团队解决这些偏见，从而实现更公平的决策。通常，解释侧重于突出的输入特征。如果模型对某个受保护的群体存在偏见，则解释可能包括显示这种偏见的特征，但当偏见通过代理特征实现时，这个代理特征与受保护特征之间的关系可能对人类而言不太清晰。在这项工作中，我们研究受保护特征和代理特征对参与者对模型公平性和提高人口平衡能力的感知的影响。此外，我们还研究了不同处理方式（解释、模型偏见披露和代理相关性披露）对公平感知和平等性的影响。我们发现，解释有助于人们检测直接偏见，但无法发现间接偏见。此外，无论偏见类型如何，解释倾向于增加对模型偏见的认同度。

    AI systems have been known to amplify biases in real world data. Explanations may help human-AI teams address these biases for fairer decision-making. Typically, explanations focus on salient input features. If a model is biased against some protected group, explanations may include features that demonstrate this bias, but when biases are realized through proxy features, the relationship between this proxy feature and the protected one may be less clear to a human. In this work, we study the effect of the presence of protected and proxy features on participants' perception of model fairness and their ability to improve demographic parity over an AI alone. Further, we examine how different treatments -- explanations, model bias disclosure and proxy correlation disclosure -- affect fairness perception and parity. We find that explanations help people detect direct biases but not indirect biases. Additionally, regardless of bias type, explanations tend to increase agreement with model bia
    
[^186]: 大型语言模型尚不能自我纠正推理错误

    Large Language Models Cannot Self-Correct Reasoning Yet. (arXiv:2310.01798v1 [cs.CL])

    [http://arxiv.org/abs/2310.01798](http://arxiv.org/abs/2310.01798)

    大型语言模型(LLMs)的自我纠正能力在推理方面存在困难，甚至可能在自我纠正后性能下降。

    

    大型语言模型(LLMs)凭借其在各种应用中无可比拟的文本生成能力而成为突破性的技术。然而，对于其生成内容的准确性和适当性仍存在疑虑。自我纠正方法被提出作为解决这些问题的一种方法。本文在此基础上对LLMs内部的自我纠正的作用和效果进行了批判性的考察，揭示了其真正的潜力和限制。我们的研究主要关注内在自我纠正的概念，即LLMs尝试仅仅依靠其固有能力来纠正其初始响应，而不依赖于外部反馈的支持。在推理的背景下，我们的研究表明LLMs在没有外部反馈的情况下很难自我纠正其响应，甚至有时候其表现可能在自我纠正后下降。基于这些洞见，我们对未来的研究提出了建议。

    Large Language Models (LLMs) have emerged as a groundbreaking technology with their unparalleled text generation capabilities across various applications. Nevertheless, concerns persist regarding the accuracy and appropriateness of their generated content. A contemporary methodology, self-correction, has been proposed as a remedy to these issues. Building upon this premise, this paper critically examines the role and efficacy of self-correction within LLMs, shedding light on its true potential and limitations. Central to our investigation is the notion of intrinsic self-correction, whereby an LLM attempts to correct its initial responses based solely on its inherent capabilities, without the crutch of external feedback. In the context of reasoning, our research indicates that LLMs struggle to self-correct their responses without external feedback, and at times, their performance might even degrade post self-correction. Drawing from these insights, we offer suggestions for future resear
    
[^187]: 使用GPT-4的图神经网络架构搜索

    Graph Neural Architecture Search with GPT-4. (arXiv:2310.01436v1 [cs.LG])

    [http://arxiv.org/abs/2310.01436](http://arxiv.org/abs/2310.01436)

    本文将GPT-4集成到图神经网络架构搜索（GNAS）中，提出了一种新的GPT-4基于的GNAS方法（GPT4GNAS），通过设计新的提示来引导GPT-4生成更准确的图神经网络，实验证明嵌入GPT-4到GNAS中优于现有方法。

    

    图神经网络架构搜索（GNAS）在自动设计图神经网络方面取得了有希望的结果。然而，GNAS仍然需要大量的人工劳动和丰富的领域知识来设计搜索空间和搜索策略。本文将GPT-4集成到GNAS中，提出了一种基于GPT-4的图神经网络架构搜索方法（简称为GPT4GNAS）。我们的方法的基本思想是为GPT-4设计一类新的提示，以指导GPT-4进行图神经网络架构的生成任务。这些提示包括GNAS的搜索空间、搜索策略和搜索反馈的描述。通过迭代地运行具有提示的GPT-4，GPT4GNAS能够生成更准确的图神经网络，并快速收敛。实验结果表明，嵌入GPT-4到GNAS中优于现有最先进的GNAS方法。

    Graph Neural Architecture Search (GNAS) has shown promising results in automatically designing graph neural networks. However, GNAS still requires intensive human labor with rich domain knowledge to design the search space and search strategy. In this paper, we integrate GPT-4 into GNAS and propose a new GPT-4 based Graph Neural Architecture Search method (GPT4GNAS for short). The basic idea of our method is to design a new class of prompts for GPT-4 to guide GPT-4 toward the generative task of graph neural architectures. The prompts consist of descriptions of the search space, search strategy, and search feedback of GNAS. By iteratively running GPT-4 with the prompts, GPT4GNAS generates more accurate graph neural networks with fast convergence. Experimental results show that embedding GPT-4 into GNAS outperforms the state-of-the-art GNAS methods.
    
[^188]: DyVal: 基于图形信息的大型语言模型动态评估

    DyVal: Graph-informed Dynamic Evaluation of Large Language Models. (arXiv:2309.17167v1 [cs.AI])

    [http://arxiv.org/abs/2309.17167](http://arxiv.org/abs/2309.17167)

    DyVal是一种基于图形信息的大型语言模型动态评估协议，通过动态生成具有可控复杂性的评估样本，评估了各种LLM在推理任务上的性能，发现它们在这些挑战性样本上表现更差。

    

    大型语言模型在各种评估基准中取得了显著的性能。然而，人们对它们的性能提出了担忧，因为它们庞大的训练语料库中可能存在数据污染。此外，当前基准的静态性质和固定复杂性可能无法充分衡量LLM的进步能力。在本文中，我们介绍了DyVal，一种新颖、通用且灵活的动态评估LLM的协议。基于我们提出的动态评估框架，我们利用有向无环图的结构优势构建了基于图形信息的DyVal，以动态生成具有可控复杂性的评估样本。DyVal生成了包括数学、逻辑推理和算法问题在内的具有挑战性的推理任务的评估集。我们评估了从Flan-T5-large到ChatGPT和GPT4的各种LLM。实验表明，LLM在DyVal生成的评估样本上表现更差

    Large language models (LLMs) have achieved remarkable performance in various evaluation benchmarks. However, concerns about their performance are raised on potential data contamination in their considerable volume of training corpus. Moreover, the static nature and fixed complexity of current benchmarks may inadequately gauge the advancing capabilities of LLMs. In this paper, we introduce DyVal, a novel, general, and flexible evaluation protocol for dynamic evaluation of LLMs. Based on our proposed dynamic evaluation framework, we build graph-informed DyVal by leveraging the structural advantage of directed acyclic graphs to dynamically generate evaluation samples with controllable complexities. DyVal generates challenging evaluation sets on reasoning tasks including mathematics, logical reasoning, and algorithm problems. We evaluate various LLMs ranging from Flan-T5-large to ChatGPT and GPT4. Experiments demonstrate that LLMs perform worse in DyVal-generated evaluation samples with di
    
[^189]: Era Splitting.（arXiv:2309.14496v1 [cs.LG]）

    Era Splitting. (arXiv:2309.14496v1 [cs.LG])

    [http://arxiv.org/abs/2309.14496](http://arxiv.org/abs/2309.14496)

    本研究提出了两种新的分裂准则，使得决策树模型能够利用时代信息进行优化，从而将超分布泛化研究中的思想应用于决策树模型。

    

    现实生活中的机器学习问题在时间和空间上会呈现出数据的分布变化。这种行为超出了传统的经验风险最小化范式的范围，该范式假设数据在时间和地点上是独立同分布的。新兴的超分布泛化领域通过将环境或时代信息融入算法中，来应对这个现实。迄今为止，大部分研究都集中在线性模型和/或神经网络上。在本研究中，我们针对决策树模型，包括随机森林和梯度提升决策树，开发了两种新的分裂准则，使得树模型能够利用与每个数据点相关的时代信息，来找到在数据的所有不相交时代中都是最优的切分点，从而将超分布泛化研究中的思想应用于决策树模型。

    Real life machine learning problems exhibit distributional shifts in the data from one time to another or from on place to another. This behavior is beyond the scope of the traditional empirical risk minimization paradigm, which assumes i.i.d. distribution of data over time and across locations. The emerging field of out-of-distribution (OOD) generalization addresses this reality with new theory and algorithms which incorporate environmental, or era-wise information into the algorithms. So far, most research has been focused on linear models and/or neural networks. In this research we develop two new splitting criteria for decision trees, which allow us to apply ideas from OOD generalization research to decision tree models, including random forest and gradient-boosting decision trees. The new splitting criteria use era-wise information associated with each data point to allow tree-based models to find split points that are optimal across all disjoint eras in the data, instead of optim
    
[^190]: 深度学习网络的几何结构和全局${\mathcal L}^2$最小化器的构建

    Geometric structure of Deep Learning networks and construction of global ${\mathcal L}^2$ minimizers. (arXiv:2309.10639v1 [cs.LG])

    [http://arxiv.org/abs/2309.10639](http://arxiv.org/abs/2309.10639)

    本文提供了深度学习网络结构的几何解释，并且构建了全局最小化器族，该族能够全局最小化成本函数。此外，还确定了各种退化局部最小值。

    

    本文提供了对深度学习（DL）网络结构的几何解释，该网络具有$L$个隐藏层，斜坡激活函数，${\mathcal L}^2$ Schatten类（或Hilbert-Schmidt）成本函数，以及相等维度$Q\geq1$的输入和输出空间${\mathbb R}^Q$。隐藏层也定义在${\mathbb R}^{Q}$的空间上。我们利用我们最新的关于浅层神经网络的结果，在$L\geq Q$的情况下构造了一个明确的最小化器族，该族能够全局最小化成本函数，并且我们证明这个族是退化的。在这里提到的上下文中，DL网络的隐藏层通过对训练输入的递归截断映射的应用来“整理”训练输入，以最小化噪声与信号的比率。此外，我们确定了$2^Q-1$个不同的退化局部最小值。

    In this paper, we provide a geometric interpretation of the structure of Deep Learning (DL) networks, characterized by $L$ hidden layers, a ramp activation function, an ${\mathcal L}^2$ Schatten class (or Hilbert-Schmidt) cost function, and input and output spaces ${\mathbb R}^Q$ with equal dimension $Q\geq1$. The hidden layers are defined on spaces ${\mathbb R}^{Q}$, as well. We apply our recent results on shallow neural networks to construct an explicit family of minimizers for the global minimum of the cost function in the case $L\geq Q$, which we show to be degenerate. In the context presented here, the hidden layers of the DL network "curate" the training inputs by recursive application of a truncation map that minimizes the noise to signal ratio of the training inputs. Moreover, we determine a set of $2^Q-1$ distinct degenerate local minima of the cost function.
    
[^191]: 大型语言模型的指令调优：一项调研

    Instruction Tuning for Large Language Models: A Survey. (arXiv:2308.10792v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.10792](http://arxiv.org/abs/2308.10792)

    本文调查了指令调优这一关键技术在增强大型语言模型能力和可控性方面的研究工作，包括方法、数据集构建、模型训练和应用，以及对结果影响的分析。同时回顾了可能的问题和批评，并指出了目前的不足。

    

    本文调查了指令调优（IT）这一快速发展的领域中的研究工作，这是一种增强大型语言模型（LLM）能力和可控性的关键技术。指令调优是指以监督方式在包含“指令-输出”对的数据集上进一步训练LLM，这将LLM的下一个词预测目标与用户希望LLM遵守人类指令的目标之间的差距。本文对IT的常规方法、IT数据集的构建、IT模型的训练以及应用于不同模态、领域和应用的情况进行了系统的文献综述，并对影响IT结果的各个方面进行了分析（例如，指令输出的生成、指令数据集的大小等）。我们还回顾了IT的潜在问题以及针对其的批评，以及指出当前不足的努力。

    This paper surveys research works in the quickly advancing field of instruction tuning (IT), a crucial technique to enhance the capabilities and controllability of large language models (LLMs). Instruction tuning refers to the process of further training LLMs on a dataset consisting of \textsc{(instruction, output)} pairs in a supervised fashion, which bridges the gap between the next-word prediction objective of LLMs and the users' objective of having LLMs adhere to human instructions. In this work, we make a systematic review of the literature, including the general methodology of IT, the construction of IT datasets, the training of IT models, and applications to different modalities, domains and applications, along with an analysis on aspects that influence the outcome of IT (e.g., generation of instruction outputs, size of the instruction dataset, etc). We also review the potential pitfalls of IT along with criticism against it, along with efforts pointing out current deficiencies 
    
[^192]: milliFlow：用于人体运动感知的毫米波雷达点云场景流估计

    milliFlow: Scene Flow Estimation on mmWave Radar Point Cloud for Human Motion Sensing. (arXiv:2306.17010v1 [cs.CV])

    [http://arxiv.org/abs/2306.17010](http://arxiv.org/abs/2306.17010)

    milliFlow是一种用于人体运动感知的新型深度学习方法，通过对毫米波雷达点云进行场景流估计，能够提供中间层的特征并直接用于下游的人体运动感知任务中。实验证明该方法具有优越性能。

    

    随着普适计算时代的到来，人体运动感知在智能系统中起着关键作用，用于决策、用户交互和个性化服务。在传统方法中，人体跟踪、姿势估计、手势识别和活动识别等方面进行了大量研究，这些方法主要基于摄像机。然而，摄像机的侵入性特点限制了它们在智能家居应用中的使用。为了解决这个问题，毫米波雷达由于其保护隐私的特点而受到欢迎。在这项工作中，我们提出了一种新颖的深度学习方法milliFlow，用于对毫米波雷达点云进行场景流估计，作为中间层的特征，直接受益于下游的人体运动感知任务。实验结果表明，我们的方法具有优越的性能，平均3D端点误差为4.6cm，明显超过竞争方法。此外，通过结合...

    Approaching the era of ubiquitous computing, human motion sensing plays a crucial role in smart systems for decision making, user interaction, and personalized services. Extensive research has been conducted on human tracking, pose estimation, gesture recognition, and activity recognition, which are predominantly based on cameras in traditional methods. However, the intrusive nature of cameras limits their use in smart home applications. To address this, mmWave radars have gained popularity due to their privacy-friendly features. In this work, we propose \textit{milliFlow}, a novel deep learning method for scene flow estimation as a complementary motion information for mmWave point cloud, serving as an intermediate level of features and directly benefiting downstream human motion sensing tasks. Experimental results demonstrate the superior performance of our method with an average 3D endpoint error of 4.6cm, significantly surpassing the competing approaches. Furthermore, by incorporati
    
[^193]: MO-VLN:一个用于开放集合零样本视觉和语言导航的多任务基准 (arXiv:2306.10322v2 [cs.CV] 更新)

    MO-VLN: A Multi-Task Benchmark for Open-set Zero-Shot Vision-and-Language Navigation. (arXiv:2306.10322v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.10322](http://arxiv.org/abs/2306.10322)

    MO-VLN是一个用于评估通用机器人在多任务环境中的视觉和语言导航的基准，通过使用虚幻引擎5开发逼真的场景和包含多种不常见物体来测试其效果和泛化能力。

    

    给定一个自然语言，一个通用的机器人必须理解指令并根据视觉观察找到目标对象或位置，即使在未探索的环境中也能做到。大多数代理依赖于大量多样的训练数据以实现更好的泛化，这需要昂贵的劳动力。这些代理通常只关注常见的对象和较少的任务，因此不足以处理不同类型的指令。为了促进开放集合视觉和语言导航的研究，我们提出了一个名为MO-VLN的基准，旨在测试代理在多任务设置中的有效性和泛化能力。首先，我们使用虚幻引擎5开发了一个3D模拟器，渲染了逼真的场景，包含更真实的光照和细节。模拟器包含三个场景，即咖啡馆、餐厅和养老院，这些场景在工业中具有很高的价值。此外，我们的模拟器涉及多种不常见的物体，如外卖杯和医用胶带，这些物体更加复杂。

    Given a natural language, a general robot has to comprehend the instruction and find the target object or location based on visual observations even in unexplored environments. Most agents rely on massive diverse training data to achieve better generalization, which requires expensive labor. These agents often focus on common objects and fewer tasks, thus are not intelligent enough to handle different types of instructions. To facilitate research in open-set vision-and-language navigation, we propose a benchmark named MO-VLN, aiming at testing the effectiveness and generalization of the agent in the multi-task setting. First, we develop a 3D simulator rendered by realistic scenarios using Unreal Engine 5, containing more realistic lights and details. The simulator contains three scenes, i.e., cafe, restaurant, and nursing house, of high value in the industry. Besides, our simulator involves multiple uncommon objects, such as takeaway cup and medical adhesive tape, which are more compli
    
[^194]: 核化强化学习及其近似方法的优化

    Kernelized Reinforcement Learning with Order Optimal Regret Bounds. (arXiv:2306.07745v1 [cs.LG])

    [http://arxiv.org/abs/2306.07745](http://arxiv.org/abs/2306.07745)

    该论文提出了一种称为$\pi$-KRVI的乐观修改方法，并使用核岭回归进行强化学习中的非线性函数逼近。论文证明了在一般设置下第一个最优遗憾保证，并相对于现有最优结果实现了显着的多项式低差距。

    

    强化学习（RL）在各种具有复杂模型和大状态-行为空间的实际场景中显示出了实证的成功。但是，现有的分析结果通常集中于具有少量状态-行为或简单模型（例如线性建模状态-行为值函数）的设置。 为了推导有效处理更广泛值函数的大状态-行为空间的RL策略，一些最新工作考虑使用核岭回归进行非线性函数逼近。 我们提出了称为$\pi$-KRVI的方法，它是最小二乘值迭代的一种乐观修改，当状态-行为值函数由RKHS表示时。我们证明了在一般设置下第一个最优遗憾保证。我们的结果显示，在许多具有高度非光滑内核（例如神经切向内核或某些Mat\'ern内核）的情况下，相对于现有最优结果，存在显着的多项式低差距。

    Reinforcement learning (RL) has shown empirical success in various real world settings with complex models and large state-action spaces. The existing analytical results, however, typically focus on settings with a small number of state-actions or simple models such as linearly modeled state-action value functions. To derive RL policies that efficiently handle large state-action spaces with more general value functions, some recent works have considered nonlinear function approximation using kernel ridge regression. We propose $\pi$-KRVI, an optimistic modification of least-squares value iteration, when the state-action value function is represented by an RKHS. We prove the first order-optimal regret guarantees under a general setting. Our results show a significant polynomial in the number of episodes improvement over the state of the art. In particular, with highly non-smooth kernels (such as Neural Tangent kernel or some Mat\'ern kernels) the existing results lead to trivial (superl
    
[^195]: 通过正交微调控制文本到图像的扩散

    Controlling Text-to-Image Diffusion by Orthogonal Finetuning. (arXiv:2306.07280v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.07280](http://arxiv.org/abs/2306.07280)

    本文介绍了一种名为正交微调（OFT）的方法，可以有效地引导和控制大型文本到图像扩散模型，以执行不同的下游任务。我们还提出了约束正交微调（COFT），来提高微调的稳定性。这些方法能够保持语义生成能力并生成特定主题的图像。

    

    大型文本到图像扩散模型在生成真实感图像方面有很强的能力。如何有效地引导或控制这些强大的模型以执行不同的下游任务成为一个重要的开放性问题。为了解决这个挑战，我们引入了一种基于原则的微调方法——正交微调（OFT），用于将文本到图像扩散模型调整到下游任务中。与现有方法不同，OFT可以证明地保持特征对神经元在单位超球面上的关系所表征的超球形能量。我们发现，这种属性对于保持文本到图像扩散模型的语义生成能力非常关键。为了提高微调的稳定性，我们进一步提出了约束正交微调（COFT），它对超球面施加了额外的半径约束。具体来说，我们考虑了两个重要的微调文本到图像任务：主题驱动生成，目标是生成特定主题的图像

    Large text-to-image diffusion models have impressive capabilities in generating photorealistic images from text prompts. How to effectively guide or control these powerful models to perform different downstream tasks becomes an important open problem. To tackle this challenge, we introduce a principled finetuning method -- Orthogonal Finetuning (OFT), for adapting text-to-image diffusion models to downstream tasks. Unlike existing methods, OFT can provably preserve hyperspherical energy which characterizes the pairwise neuron relationship on the unit hypersphere. We find that this property is crucial for preserving the semantic generation ability of text-to-image diffusion models. To improve finetuning stability, we further propose Constrained Orthogonal Finetuning (COFT) which imposes an additional radius constraint to the hypersphere. Specifically, we consider two important finetuning text-to-image tasks: subject-driven generation where the goal is to generate subject-specific images
    
[^196]: 引入致敬神话人工智能竞赛

    Introducing Tales of Tribute AI Competition. (arXiv:2305.08234v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.08234](http://arxiv.org/abs/2305.08234)

    这项论文介绍了一项新的人工智能挑战——致敬神话人工智能竞赛(TOTAIC)，该竞赛基于《上古卷轴在线》中的一款卡牌游戏。除了应对通常与CCG相关的挑战外，该挑战还需要长期规划和适应性。竞赛采用多种方法解决游戏，如对抗搜索、单人计划和神经网络算法。第一届TOTAIC将在2023年的IEEE游戏会议上举行。

    

    本文介绍了一项新的人工智能挑战，即致敬神话人工智能竞赛(TOTAIC)，该竞赛基于《上古卷轴在线》海之岛章节发布的一款双人卡牌建设类游戏。目前还没有其他涵盖收集卡牌游戏(CCG)类型的人工智能竞赛，也从未有过针对建设卡牌游戏的竞赛。因此，成功的方法除了要克服通常与CCG相关的障碍，如随机性、隐藏信息和大的分支因素外，还需要长期规划和适应性。该游戏可以采用多种方法进行解决，包括经典的对抗搜索、单人计划和基于神经网络的算法。本文介绍了竞赛框架，描述了游戏规则，并呈现了示例AI代理之间的锦标赛结果。TOTAIC的第一届将在2023年IEEE游戏会议上举行。

    This paper presents a new AI challenge, the Tales of Tribute AI Competition (TOTAIC), based on a two-player deck-building card game released with the High Isle chapter of The Elder Scrolls Online. Currently, there is no other AI competition covering Collectible Card Games (CCG) genre, and there has never been one that targets a deck-building game. Thus, apart from usual CCG-related obstacles to overcome, like randomness, hidden information, and large branching factor, the successful approach additionally requires long-term planning and versatility. The game can be tackled with multiple approaches, including classic adversarial search, single-player planning, and Neural Networks-based algorithms. This paper introduces the competition framework, describes the rules of the game, and presents the results of a tournament between sample AI agents. The first edition of TOTAIC is hosted at the IEEE Conference on Games 2023.
    
[^197]: 区分和回答：通过辨别器缓解检索增强模型中虚假信息的影响

    Discern and Answer: Mitigating the Impact of Misinformation in Retrieval-Augmented Models with Discriminators. (arXiv:2305.01579v1 [cs.CL])

    [http://arxiv.org/abs/2305.01579](http://arxiv.org/abs/2305.01579)

    本文研究了现有检索增强语言模型假设所有检索信息都是正确的假设的问题，在实际应用中可能存在虚假信息导致冲突的情况下，提出了通过精细调整鉴别器和提示鉴别能力引出鲁棒性的方法，这显著改善了模型在知识冲突下的效果；同时提供了关于交替精细调整模型和上下文学习的新的结论。

    

    大多数现有的检索增强语言模型（LM）假定所有检索到的信息都是事实上正确的。本文研究一个更加现实的场景，即检索到的文档可能包含虚假信息，从而导致它们之间存在冲突。我们观察到，现有模型在精调和上下文少样本学习设置中对这种信息高度脆弱。我们提出了一些方法，通过明确地对鉴别器进行精细调整或提示来引出GPT-3的鉴别能力，使检索增强LM对虚假信息具有鲁棒性。我们在开放域问答方面的实证结果表明，这些方法显著改善了LM对知识冲突的鲁棒性。我们还提供了关于交替精细调整模型的决策与上下文学习过程的发现，为利用两者的最佳方式铺平了新的道路。

    Most existing retrieval-augmented language models (LMs) for question answering assume all retrieved information is factually correct. In this work, we study a more realistic scenario in which retrieved documents may contain misinformation, causing conflicts among them. We observe that the existing models are highly brittle to such information in both fine-tuning and in-context few-shot learning settings. We propose approaches to make retrieval-augmented LMs robust to misinformation by explicitly fine-tuning a discriminator or prompting to elicit discrimination capability in GPT-3. Our empirical results on open-domain question answering show that these approaches significantly improve LMs' robustness to knowledge conflicts. We also provide our findings on interleaving the fine-tuned model's decision with the in-context learning process, paving a new path to leverage the best of both worlds.
    
[^198]: 从相邻的染色组织学片中学习黑色素细胞掩膜

    Learning Melanocytic Cell Masks from Adjacent Stained Tissue. (arXiv:2211.00646v2 [q-bio.QM] UPDATED)

    [http://arxiv.org/abs/2211.00646](http://arxiv.org/abs/2211.00646)

    本文提出了一种从相邻染色组织学片中训练深度神经网络进行黑色素细胞分割的方法，实现了0.64的平均IOU，尽管存在不完美的标签。

    

    黑色素瘤是最具侵袭性的皮肤癌之一，导致大部分皮肤癌死亡。然而，病理学家对黑色素瘤的诊断可靠性较低。由于黑色素瘤是黑色素细胞的肿瘤，需要开发一种与病理学家的差异无关并能自动进行像素级注释的黑色素细胞分割工具。然而，大规模病理学家标注是不现实的。在本文中，我们提出了一种方法，使用邻近组织切片上的偶联免疫组织化学（IHC）染色片，训练深度神经网络进行黑色素细胞分割，虽然很难有完美的标签，但达到了0.64的平均IOU。

    Melanoma is one of the most aggressive forms of skin cancer, causing a large proportion of skin cancer deaths. However, melanoma diagnoses by pathologists shows low interrater reliability. As melanoma is a cancer of the melanocyte, there is a clear need to develop a melanocytic cell segmentation tool that is agnostic to pathologist variability and automates pixel-level annotation. Gigapixel-level pathologist labeling, however, is impractical. Herein, we propose a means to train deep neural networks for melanocytic cell segmentation from hematoxylin and eosin (H&E) stained slides using paired immunohistochemical (IHC) slides of adjacent tissue sections, achieving a mean IOU of 0.64 despite imperfect ground-truth labels.
    

