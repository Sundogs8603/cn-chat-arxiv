# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities.](http://arxiv.org/abs/2308.02490) | MM-Vet是一个评估标准，用于评估大型多模态模型在复杂任务上的综合能力。该标准解决了如何结构化和评估复杂多模态任务、设计适用于不同问题和回答类型的评估指标以及如何提供模型洞察的问题。通过整合不同的核心视觉-语言能力，MM-Vet展示了有趣的能力和解决复杂任务的方法。 |
| [^2] | [Nonprehensile Planar Manipulation through Reinforcement Learning with Multimodal Categorical Exploration.](http://arxiv.org/abs/2308.02459) | 本研究提出了一种多模态分类探索方法，通过此方法能够训练出平滑且准确的非抓取平面操作控制器。此方法能够捕捉任务的混合动力学特性，解决了之前使用的单模态探索策略无法实现准确性和平滑轨迹的问题。 |
| [^3] | [A Survey on Temporal Knowledge Graph Completion: Taxonomy, Progress, and Prospects.](http://arxiv.org/abs/2308.02457) | 这篇论文是关于时态知识图补全的综述，主要介绍了该领域的分类、进展和前景展望。由于新知识的不断涌现、提取结构化信息的算法不足以及源数据集中信息的缺失，时态知识图往往不完整。因此，时态知识图补全任务越来越受关注，旨在基于可用信息预测缺失项。 |
| [^4] | [SoK: Assessing the State of Applied Federated Machine Learning.](http://arxiv.org/abs/2308.02454) | 本研究评估了Federated Machine Learning（FedML）在实际应用中的现状，并发现了阻碍其实际应用的挑战。 |
| [^5] | [From Military to Healthcare: Adopting and Expanding Ethical Principles for Generative Artificial Intelligence.](http://arxiv.org/abs/2308.02448) | 这项研究探讨了从军事到医疗保健领域采纳和扩展伦理原则以应用生成式人工智能的可行性和重要性。 |
| [^6] | [AI Literature Review Suite.](http://arxiv.org/abs/2308.02443) | 这个AI文献综述套件利用大型语言模型和自然语言处理的能力，提供了一个简化文献综述过程的解决方案，包括搜索、下载、整理PDF文件、提取文章内容，并提供了简明的综述摘要。这是一个自动化和优化学术和工业研究中文献综述过程的强大工具。 |
| [^7] | [How to Design and Deliver Courses for Higher Education in the AI Era: Insights from Exam Data Analysis.](http://arxiv.org/abs/2308.02441) | 在人工智能时代，设计和开展高等教育课程需要考虑人工智能的优势和局限性，并遵循教育学教育目标。本研究利用数据分析研究了七场考试的结果，发现学生的学习成绩与ChatGPT的使用没有相关性。 |
| [^8] | [A large language model-assisted education tool to provide feedback on open-ended responses.](http://arxiv.org/abs/2308.02439) | 这个工具利用大型语言模型辅助教学，能够自动回答开放性问题并提供个性化的反馈，有助于提高学生的学习效果。 |
| [^9] | [Designing Fiduciary Artificial Intelligence.](http://arxiv.org/abs/2308.02435) | 本文综合了计算机科学和法律领域的最新研究，提出了一种设计和审计信托人工智能的方法，用于解决数据主体在与复杂技术系统交互时同意不完全性的问题。 |
| [^10] | [Performance of Large Language Models in a Computer Science Degree Program.](http://arxiv.org/abs/2308.02432) | 该论文研究了在一所应用科学大学的计算机科学本科课程中不同大型语言模型的性能。通过将它们作为教学辅助工具，在不同计算机科学领域的课程中进行评估，展示了这些模型的强大性能，同时强调了在这样一个学位课程的背景下的限制和约束。 |
| [^11] | [Unlocking the Potential of Similarity Matching: Scalability, Supervision and Pre-training.](http://arxiv.org/abs/2308.02427) | 本研究提出了一种基于相似性匹配的学习模式，通过使用PyTorch实现了扩展到大型数据集的卷积非负相似性匹配，引入了局部监督的SM目标，以及利用PyTorch实现预训练网络结构的特征评估对比。这将生物学合理性的算法与计算成本相结合，提供了一种在线、本地化且具有生物学合理性的学习方法。 |
| [^12] | [Implementing Smart Contracts: The case of NFT-rental with pay-per-like.](http://arxiv.org/abs/2308.02424) | 本研究介绍了一种基于区块链技术的NFT租赁解决方案，采用按赞付费的定价模型。然而，区块链费用可能不公平，并且对于小众艺术家可能会产生阻碍文化多样性的影响。 |
| [^13] | [Multimodal Indoor Localisation in Parkinson's Disease for Detecting Medication Use: Observational Pilot Study in a Free-Living Setting.](http://arxiv.org/abs/2308.02419) | 该研究提出了一种基于变压器的方法，使用穿戴设备的RSSI和加速度计数据进行室内定位，以改善当前方法的有效性。研究还探讨了室内定位是否可以通过检测帕金森病患者的药物使用情况来评估运动波动。 |
| [^14] | [Car-Driver Drowsiness Assessment through 1D Temporal Convolutional Networks.](http://arxiv.org/abs/2308.02415) | 该研究设计了一种新型生物传感器，通过分析光电容积图（PPG）信号来评估驾驶员的生理状态。 |
| [^15] | [Self-Supervised Learning for WiFi CSI-Based Human Activity Recognition: A Systematic Study.](http://arxiv.org/abs/2308.02412) | 本研究对基于WiFi CSI的人体活动识别进行了自监督学习，提出了一种解决深度学习中数据不足的方法。通过将深度学习技术与CSI数据相结合，实现了最先进的性能，无需专家知识。研究人员通过分析不同类型的自监督学习算法的潜力，对缺乏标记CSI数据的挑战进行了全面的整理和分析。 |
| [^16] | [Mental Workload Estimation with Electroencephalogram Signals by Combining Multi-Space Deep Models.](http://arxiv.org/abs/2308.02409) | 该论文通过融合多个空间维度的方法，使用脑电信号对心理负荷进行分类和估计连续级别。在时间域中使用了时态卷积网络，而在频率域中引入了新的架构——多维残差块。 |
| [^17] | [Evaluating the structure of cognitive tasks with transfer learning.](http://arxiv.org/abs/2308.02408) | 本研究通过迁移学习探索了在脑电图解码任务中，不同任务之间深度学习表征的可迁移性，并展示了即使是线性探测转移，也可以显著提高解码性能，相较于纯监督方法，改进幅度高达28%。 |
| [^18] | [Scaling Survival Analysis in Healthcare with Federated Survival Forests: A Comparative Study on Heart Failure and Breast Cancer Genomics.](http://arxiv.org/abs/2308.02382) | 本研究针对医疗保健中生存数据的挑战，提出了FedSurF++算法，这是一种联合学习算法用于处理分布式的、具有隐私保密要求的生存分析。该算法可以大规模建模和处理生存数据，解决了数据稀缺和隐私保密的问题。 |
| [^19] | [A Machine Learning Method for Predicting Traffic Signal Timing from Probe Vehicle Data.](http://arxiv.org/abs/2308.02370) | 本文提出了使用机器学习方法从探测车数据预测交通信号灯定时的方法，利用XGBoost模型估计信号周期长度，利用神经网络模型确定红灯时间，并根据周期长度和红灯时间计算绿灯时间。结果显示，对信号周期长度的估计误差小于0.56秒，红灯时间的预测误差平均在7.2秒以内。 |
| [^20] | [Universal Defensive Underpainting Patch: Making Your Text Invisible to Optical Character Recognition.](http://arxiv.org/abs/2308.02369) | 提出了一种通用防御底纹补丁（UDUP）机制，通过修改文本图像的底纹而非字符，有效地防御未经授权的光学字符识别（OCR）盗版，无论截屏范围或图像背景的复杂性，都适用。 |
| [^21] | [Flexible Differentially Private Vertical Federated Learning with Adaptive Feature Embeddings.](http://arxiv.org/abs/2308.02362) | 本文提出了一种灵活的差分隐私垂直联邦学习方法（VFL），通过应用范数剪裁实现了严格的隐私保证，并通过自适应调整特征嵌入的尺度和分布来优化任务效用，而不损害隐私保护。 |
| [^22] | [Text2KGBench: A Benchmark for Ontology-Driven Knowledge Graph Generation from Text.](http://arxiv.org/abs/2308.02357) | Text2KGBench是一种用于评估语言模型根据本体从自然语言文本中生成知识图谱的能力的基准测试工具，在两个数据集上通过七个评估指标来衡量事实提取的性能。 |
| [^23] | [Adapting to Change: Robust Counterfactual Explanations in Dynamic Data Landscapes.](http://arxiv.org/abs/2308.02353) | 这项研究介绍了一种新颖的半监督图形因果解释器 (DyGRACE)，它通过学习数据表示并利用已知数据分布的初始知识，在动态数据环境中搜索有效的因果解释。该方法独立于底层预测模型。 |
| [^24] | [RAHNet: Retrieval Augmented Hybrid Network for Long-tailed Graph Classification.](http://arxiv.org/abs/2308.02335) | 我们提出了一种检索增强型混合网络(RAHNet)用于长尾图分类任务，通过联合学习稳健的特征提取器和无偏的分类器，解决了图神经网络在长尾类别分布下的偏差和泛化能力有限的问题。 |
| [^25] | [A Controllable Co-Creative Agent for Game System Design.](http://arxiv.org/abs/2308.02317) | 这项研究通过创建一个可控的合作创作代理，改善了游戏系统设计中合作创作的局限性，使其适用于任何类型的游戏，并解决了人类设计师的创造力问题。 |
| [^26] | [Who Answers It Better? An In-Depth Analysis of ChatGPT and Stack Overflow Answers to Software Engineering Questions.](http://arxiv.org/abs/2308.02312) | 本研究深入分析了ChatGPT和Stack Overflow回答软件工程问题的特点和可用性。结果显示，ChatGPT回答中有52%错误，77%冗长，但由于其综合性和清晰的语言表达，仍然在39.34%的情况下被使用者偏好选择。 |
| [^27] | [Learning to Select the Relevant History Turns in Conversational Question Answering.](http://arxiv.org/abs/2308.02294) | 这篇论文提出了一个名为DHS-ConvQA的框架，用于在会话式问答中动态选择相关的历史转折点，以指导答案的准确预测。 |
| [^28] | [A stochastic optimization approach to train non-linear neural networks with regularization of higher-order total variation.](http://arxiv.org/abs/2308.02293) | 通过引入高阶总变差正则化的随机优化算法，可以高效地训练非线性神经网络，避免过拟合问题。 |
| [^29] | [Frustratingly Easy Model Generalization by Dummy Risk Minimization.](http://arxiv.org/abs/2308.02287) | 通过虚拟风险最小化，本文提出了一种令人沮丧地简单且通用的技术（DuRM），能够显著改善经验风险最小化（ERM）的泛化能力。通过理论和经验验证，我们展示了DuRM可以通过增加梯度的方差来促进模型的泛化效果，并在不同任务和数据集上进行的实验证明了DuRM的有效性。 |
| [^30] | [DIVERSIFY: A General Framework for Time Series Out-of-distribution Detection and Generalization.](http://arxiv.org/abs/2308.02282) | DIVERSIFY是一个通用框架，用于解决时间序列离群检测和推广的挑战，通过利用数据集中的子域来对抗时间序列的非平稳性，并通过迭代过程减小潜在分布之间的差距。 |
| [^31] | [DTF-Net: Category-Level Pose Estimation and Shape Reconstruction via Deformable Template Field.](http://arxiv.org/abs/2308.02239) | DTF-Net是一种基于隐式神经场的姿态估计和形状重建框架，通过设计可变形模板场来捕捉物体类别的形状特征和几何变形特征。 |
| [^32] | [Should we trust web-scraped data?.](http://arxiv.org/abs/2308.02231) | 本论文指出天真的网络抓取程序可能导致收集数据中的抽样偏差，并描述了来源于网络内容易变性、个性化和未索引的抽样偏差。通过例子说明了抽样偏差的普遍性和程度，并提供了克服抽样偏差的建议。 |
| [^33] | [Federated Learning: Organizational Opportunities, Challenges, and Adoption Strategies.](http://arxiv.org/abs/2308.02219) | 本文探讨了联邦学习的技术基础和潜在应用，提出了联邦学习的采用策略框架，并指出联邦学习为商业和信息系统工程学界提供了跨学科研究机会。 |
| [^34] | [Towards Personalized Prompt-Model Retrieval for Generative Recommendation.](http://arxiv.org/abs/2308.02205) | 该论文提出了一个个性化提示-模型检索的方法，以实现个性化的生成式推荐任务。通过GEMRec-18K数据集的研究，作者设计了一个两阶段的框架，分别是提示-模型检索和生成项排序，以解决这一新任务的挑战。 |
| [^35] | [A Survey of Spanish Clinical Language Models.](http://arxiv.org/abs/2308.02199) | 这项调查研究了西班牙语临床语言模型的应用，回顾了17个专注于临床任务的语料库的贡献，并对最相关的西班牙语语言模型和西班牙临床语言模型进行了彻底比较，提供了3000多个进行微调的模型。为了便于未来的研究和挑战，所有测试过的语料库和最佳模型都被以可访问的方式公开。 |
| [^36] | [Explaining Relation Classification Models with Semantic Extents.](http://arxiv.org/abs/2308.02193) | 本研究提出了一种解释关系分类模型的方法，即使用语义范围分析模型的决策模式。语义范围是关于分类决策的文本中最有影响力的部分。通过将人类和模型的语义范围进行比较，发现模型往往从数据中学习到了快捷模式。 |
| [^37] | [AutoML4ETC: Automated Neural Architecture Search for Real-World Encrypted Traffic Classification.](http://arxiv.org/abs/2308.02182) | AutoML4ETC是一个自动设计高效且高性能神经架构的工具，用于加密流量分类。其通过定义新颖的搜索空间和使用不同的搜索策略，在多个数据集上优于当前最先进的加密流量分类器。 |
| [^38] | [Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization.](http://arxiv.org/abs/2308.02151) | 本文介绍了一种通过策略梯度优化的回顾性大型语言代理框架，该框架通过学习环境反馈来调整语言代理的提示，从而优化其性能。这种代理能够从多个环境和任务中学习奖励，并通过总结以前任务的根本原因来改进语言代理提示。 |
| [^39] | [Semantics-guided Transformer-based Sensor Fusion for Improved Waypoint Prediction.](http://arxiv.org/abs/2308.02126) | 该论文提出一种基于语义引导的传感器融合方法，通过融合多个传感器的特征和使用辅助任务来改进自动驾驶代理的航点预测。 |
| [^40] | [Model Provenance via Model DNA.](http://arxiv.org/abs/2308.02121) | 本文介绍了模型来源证明的新概念模型DNA，通过编码模型的训练数据和输入输出信息作为紧凑全面的表示，来确定源模型是否作为目标模型的来源证明。 |
| [^41] | [VQGraph: Graph Vector-Quantization for Bridging GNNs and MLPs.](http://arxiv.org/abs/2308.02117) | VQGraph是一个框架，通过学习一个强大的图形表示空间，用于连接GNN和MLPs。它采用矢量量化变分自编码器（VQ-VAE）的编码器作为结构感知图标记器，有效地表示底层图的多样化局部结构。通过 VQGraph，可以实现从GNN到MLP的知识转移。 |
| [^42] | [AdvFAS: A robust face anti-spoofing framework against adversarial examples.](http://arxiv.org/abs/2308.02116) | 提出了AdvFAS框架，它利用两个耦合得分准确区分对抗攻击中的人脸图像，在不同环境下展示了高效的防御水平。 |
| [^43] | [N-gram Boosting: Improving Contextual Biasing with Normalized N-gram Targets.](http://arxiv.org/abs/2308.02092) | 本文提出了一种N-gram增强技术，通过规范化目标词组来改善上下文偏差，提高关键词识别率。 |
| [^44] | [Efficient Model Adaptation for Continual Learning at the Edge.](http://arxiv.org/abs/2308.02084) | 这篇论文提出了一个名为Encoder-Adaptor-Reconfigurator（EAR）框架，用于在领域漂移下进行高效的持续学习。该框架使用了固定的深度神经网络（DNN）特征编码器，并在编码器之上训练浅层网络来处理新数据。通过结合DNN和超维计算（HDC），该框架能够检测新数据是否属于分布之外（OOD），并能够识别出... (摘要内容省略) |
| [^45] | [Mitigating Task Interference in Multi-Task Learning via Explicit Task Routing with Non-Learnable Primitives.](http://arxiv.org/abs/2308.02066) | 本文提出了ETR-NLP模型来减轻多任务学习中的任务干扰，通过使用非可学习原语和显式任务路由的协同组合，在共享分支和任务特定分支中显式地分离可学习参数，以实现任务之间的最小化干扰。 |
| [^46] | [On the Biometric Capacity of Generative Face Models.](http://arxiv.org/abs/2308.02065) | 这篇论文提出了一种统计方法，用于估计在超球特征空间中生成的人脸图像的生物特征容量，并在多个生成模型上进行了实证研究。 |
| [^47] | [Accurate Neural Network Pruning Requires Rethinking Sparse Optimization.](http://arxiv.org/abs/2308.02060) | 这项工作研究了高稀疏对神经网络训练的影响，发现使用传统的密集训练策略进行稀疏训练效果不佳，提出了新的方法来解决这个问题，并在视觉和语言模型上都取得了最先进的结果。 |
| [^48] | [Incorporating Recklessness to Collaborative Filtering based Recommender Systems.](http://arxiv.org/abs/2308.02058) | 本文提出了一种将鲁莽行为引入基于矩阵分解的推荐系统学习过程的方法，通过控制风险水平来提高预测的数量和质量。 |
| [^49] | [The Unequal Opportunities of Large Language Models: Revealing Demographic Bias through Job Recommendations.](http://arxiv.org/abs/2308.02053) | 通过职位推荐分析了大型语言模型（LLMs）的人口统计偏见，发现这些模型对于墨西哥工人一直建议低薪工作，并向女性更倾向于推荐秘书职位。这项研究强调了理解LLMs偏见的重要性。 |
| [^50] | [Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough.](http://arxiv.org/abs/2308.02047) | 本文批判性评估了欧洲提议的AI法案的风险管理和风险可接受性方法。与法案的狭义解释不同，议会的草案修改引入了更具可行性的“合理性”原则，并更透明地表明风险可接受性判断的价值取向和情境性质，更好地平衡了相称性和可信赖性的目标。 |
| [^51] | [Artificial Intelligence in archival and historical scholarship workflow: HTS and ChatGPT.](http://arxiv.org/abs/2308.02044) | 本文研究了人工智能在档案数字化过程中的应用，重点是自动转录和校正手稿，以及标准化文本。通过测试ChatGPT系统，在对信函进行文本标准化时取得了一定效果。总体而言，数字化和人工智能可以显著提升档案和历史研究能力。 |
| [^52] | [Disease Insight through Digital Biomarkers Developed by Remotely Collected Wearables and Smartphone Data.](http://arxiv.org/abs/2308.02043) | 通过远程收集患者数据，利用数字生物标志物和远程监测技术可以提供有价值的疾病洞察力，从而补充传统医疗环境中的治疗方法。 |
| [^53] | [A short review of the main concerns in A.I. development and application within the public sector supported by NLP and TM.](http://arxiv.org/abs/2308.02042) | 本文通过回顾过去两年发表的研究论文，结合自然语言处理和文本挖掘的基本概念，捕捉了公共部门中人工智能发展和应用的数据隐私、伦理、可解释性、可信度和公平性等关注点。其中，公平性是最频繁关注的问题，而数据隐私是最不突出的话题。 |
| [^54] | [Regulating AI manipulation: Applying Insights from behavioral economics and psychology to enhance the practicality of the EU AI Act.](http://arxiv.org/abs/2308.02041) | 本文通过运用心理学和行为经济学的见解，澄清了欧盟AI法案中的术语并提高了保护效果。 |
| [^55] | [CLGT: A Graph Transformer for Student Performance Prediction in Collaborative Learning.](http://arxiv.org/abs/2308.02038) | 该论文提出了一个基于图转换器的框架，用于在协作学习中评估和预测学生的绩效。 |
| [^56] | [The Growth of E-Bike Use: A Machine Learning Approach.](http://arxiv.org/abs/2308.02034) | 本研究使用机器学习方法，预测了美国电动自行车销量的增长，并评估了影响电动自行车使用的因素。根据预测结果，预计2025年电动自行车销售量为130万辆，2028年为211.3万辆。 |
| [^57] | [AI and the EU Digital Markets Act: Addressing the Risks of Bigness in Generative AI.](http://arxiv.org/abs/2308.02033) | 这项研究旨在探讨如何应对生成式AI中的巨头风险，并提出了将某些AI软件作为核心平台服务，将某些开发者分类为守门人，并对相关义务进行评估的建议。这有助于欧盟在生成式AI服务中维护多样性和开放性。 |
| [^58] | [JusticeBot: A Methodology for Building Augmented Intelligence Tools for Laypeople to Increase Access to Justice.](http://arxiv.org/abs/2308.02032) | JusticeBot是一种为非法律专业人士提供法律决策支持的增强智能工具，通过混合案例和规则推理的方法，帮助用户探索他们在特定情况下的法律权利，并提供相关的法律信息和案例参考。 |
| [^59] | [Knowledge-enhanced Neuro-Symbolic AI for Cybersecurity and Privacy.](http://arxiv.org/abs/2308.02031) | 知识增强的神经符号人工智能将深度神经网络和符号知识图相结合，提高了人工智能系统的可解释性和安全性，在网络安全和隐私保护领域具有潜在应用价值。 |
| [^60] | [Perceptions of the Fourth Industrial Revolution and Artificial Intelligence Impact on Society.](http://arxiv.org/abs/2308.02030) | 本研究调查了不同信息流分类下个体对AI的看法，结果显示参与者关注AI对就业、隐私和信息准确性的影响。然而，他们也认识到AI能够解决复杂问题和增加便利。对于政府在第四次工业革命中的角色，意见各异。 |
| [^61] | [Evaluation of STT-MRAM as a Scratchpad for Training in ML Accelerators.](http://arxiv.org/abs/2308.02024) | 本研究评估了STT-MRAM作为训练加速器中的Scratchpad的效果，发现它具有高密度、低泄漏功率和合理的访问时间等优点，但写操作需要较高的能量和延迟。 |
| [^62] | [On the Transition from Neural Representation to Symbolic Knowledge.](http://arxiv.org/abs/2308.02000) | 该论文提出了一种神经-符号过渡字典学习框架，可以将神经网络与符号思维进行结合。通过学习过渡表示，并自监督地发现隐含的谓词结构，以及通过博弈和强化学习调整学习到的原型，该框架可以实现对高维信息的压缩和符号表示的学习。 |
| [^63] | [Domain specificity and data efficiency in typo tolerant spell checkers: the case of search in online marketplaces.](http://arxiv.org/abs/2308.01976) | 本研究针对在线市场中拼写错误的问题，通过数据增强方法和递归神经网络实现了领域特定的拼写检查器，并将其应用在微软AppSource市场的实时推断API中。我们的数据有效解决方案表明，控制高质量的合成数据可能成为一个有力的工具，特别是考虑到当前大语言模型所依赖的巨大且难以控制的数据集。 |
| [^64] | [SpaDen : Sparse and Dense Keypoint Estimation for Real-World Chart Understanding.](http://arxiv.org/abs/2308.01971) | 本文介绍了一种用于提取图表数据的新型自下而上方法。通过检测连续和离散的关键点来实现对绘图区域内组件的重构，进而获取数据系列名称。实验结果证明了该方法的有效性。 |
| [^65] | [Discriminative Graph-level Anomaly Detection via Dual-students-teacher Model.](http://arxiv.org/abs/2308.01947) | 本论文提出了一种基于双学生-教师模型的判别性图级异常检测方法，通过定义异常图信息和采用节点级和图级信息差来识别异常图，并引入教师模型和两个竞争的学生模型来提高异常检测的效果。 |
| [^66] | [Digital twin brain: a bridge between biological intelligence and artificial intelligence.](http://arxiv.org/abs/2308.01941) | 本文提出了数字双胞胎脑作为一个桥梁，将生物智能和人工智能联系在一起，通过将神经科学和人工智能的进展结合起来，更好地理解大脑的复杂性和如何产生智能。 |
| [^67] | [Training Data Protection with Compositional Diffusion Models.](http://arxiv.org/abs/2308.01937) | 使用分区扩散模型（CDM）训练不同的扩散模型，并在推断时任意组合它们，实现了训练数据保护和选择性遗忘，同时还可以根据用户访问权限提供定制模型。 |
| [^68] | [Why Do We Need Neuro-symbolic AI to Model Pragmatic Analogies?.](http://arxiv.org/abs/2308.01936) | 本文讨论了神经符号人工智能在处理逐渐复杂的类比推理时的必要性，以提供超越文字内容的广泛、多样化的知识，并结合统计和符号人工智能技术来增强和引导映射过程。 |
| [^69] | [Machine Learning-Based Diabetes Detection Using Photoplethysmography Signal Features.](http://arxiv.org/abs/2308.01930) | 基于光电脉搏信号特征的机器学习方法用于糖尿病检测，通过非侵入性PPG信号和LR、XGBoost算法的分类，实现了免创伤且连续监测的糖尿病检测。 |
| [^70] | [A Transformer-based Prediction Method for Depth of Anesthesia During Target-controlled Infusion of Propofol and Remifentanil.](http://arxiv.org/abs/2308.01929) | 这项研究提出了一种基于Transformer的方法来预测丙泊酚和瑞芬太尼的麻醉深度。该方法通过利用长短时记忆和门控残差网络来提高特征融合的效率，并应用注意机制来发现药物之间的相互作用。实验证明，该方法优于传统的PK-PD模型和先前的深度学习方法，能够有效预测麻醉深度。 |
| [^71] | [An Empirical Study on Fairness Improvement with Multiple Protected Attributes.](http://arxiv.org/abs/2308.01923) | 本文通过广泛研究，发现对于单个保护属性的公平性改善会大大降低对未考虑保护属性的公平性，但在多属性模式下可以保持准确性。 |
| [^72] | [Transferable Graph Neural Fingerprint Models for Quick Response to Future Bio-Threats.](http://arxiv.org/abs/2308.01921) | 该论文提出了一种可转移的图神经指纹模型，用于快速应对未来的生物威胁。通过利用包含30万种候选药物和23个冠状病毒蛋白靶的COVID-19药物对接数据集，训练了高通量虚拟COVID-19药物筛选的图神经指纹模型。与传统指纹方法相比，该模型在对接得分上具有较高的预测准确性，并且提出了可转移的图神经指纹方法，能够适用于未知的靶点。 |
| [^73] | [Emotion recognition based on multi-modal electrophysiology multi-head attention Contrastive Learning.](http://arxiv.org/abs/2308.01919) | ME-MHACL是一种基于自监督对比学习的多模态情感识别方法，通过从未标记的电生理信号中学习特征表示，并利用多头注意力机制进行特征融合，来提高情感识别性能。 |
| [^74] | [Semi Supervised Meta Learning for Spatiotemporal Learning.](http://arxiv.org/abs/2308.01916) | 本文探讨了半监督元学习在时空学习中的应用，通过将元学习应用于自监督遮蔽自编码器，并结合状态-of-the-art表示学习架构，提出了一种新的框架来解决视频重建和动作分类任务。 |
| [^75] | [AI Increases Global Access to Reliable Flood Forecasts.](http://arxiv.org/abs/2307.16104) | 本研究开发了一个人工智能模型，可以准确预测未经测量流域的极端水文事件，从而提高了全球洪水预警的覆盖范围。 |
| [^76] | [AI4GCC - Team: Below Sea Level: Score and Real World Relevance.](http://arxiv.org/abs/2307.13892) | 我们提出了一种谈判协议来解决碳泄漏问题，通过与代表性浓度路径和共享社会经济路径进行比较，我们的方法显示出了良好的效果，此外我们还分析了协议的合规性、可行性和伦理关切。 |
| [^77] | [Automatic Design of Semantic Similarity Ensembles Using Grammatical Evolution.](http://arxiv.org/abs/2307.00925) | 本研究首次使用语法演化自动设计语义相似性集合，通过自动选择和聚合候选度量来优化集合与人类判断的相关性，提高相似度评估准确性，并证明了使用集合对语义相似性任务的益处。 |
| [^78] | [Inductive reasoning in humans and large language models.](http://arxiv.org/abs/2306.06548) | 本研究使用GPT-3.5和GPT-4对人类归纳推理中的属性归纳问题进行了实验。结果表明，尽管GPT-3.5有一些困难，但GPT-4的表现与人类相似，除了未能捕捉到前提的非单调性现象。这项工作为人类和机器智能提供了有趣的比较，并提供了用作未来研究基准的两个大型数据集。 |
| [^79] | [Teacher Agent: A Non-Knowledge Distillation Method for Rehearsal-based Video Incremental Learning.](http://arxiv.org/abs/2306.00393) | 提出了一种教师代理方法，能够从先前学习的知识中生成高质量样本的数据集，从而使学生网络可以从样本的多种观点中进行学习，在标准基准上优于基于知识蒸馏的方法。 |
| [^80] | [A Survey on Large Language Models for Recommendation.](http://arxiv.org/abs/2305.19860) | 本综述介绍了基于大语言模型的推荐系统，提出了判别式LLMs和生成式LLMs两种模型范式，总结了这些模型的最新进展，强调了该领域的挑战和研究方向。 |
| [^81] | [Mitigating Label Biases for In-context Learning.](http://arxiv.org/abs/2305.19148) | 本文针对上下文学习（ICL）中的三种标签偏差提出分类法，并提出一种简单的偏差校准方法，使用随机的领域词估算语言模型的标签偏差。 |
| [^82] | [Null-text Guidance in Diffusion Models is Secretly a Cartoon-style Creator.](http://arxiv.org/abs/2305.06710) | 本文发现，模型扩散中的无标注文本实际上是一个能够生成卡通风格图片的工具。通过简单地扰动无标注文本指导，这一功能得以实现。回滚扰动能够将生成的图像有效转换成卡通图像，而图像扰动则能够产生高保真度、多样性的卡通图像。 |
| [^83] | [Multi-view Vision-Prompt Fusion Network: Can 2D Pre-trained Model Boost 3D Point Cloud Data-scarce Learning?.](http://arxiv.org/abs/2304.10224) | 本文提出了一种针对3D点云分类的少样本学习网络MvNet，它能够利用现有的2D预训练模型来缓解现有基线模型对大规模注释3D点云数据的过度依赖问题。 |
| [^84] | [SPeC: A Soft Prompt-Based Calibration on Mitigating Performance Variability in Clinical Notes Summarization.](http://arxiv.org/abs/2303.13035) | 研究通过引入软提示嵌入，提出Soft Prompt-Based Calibration (SPeC)管道，来减轻输入变量对输出多样性的影响，降低性能变异. 此方法不仅比大语言模型(LLM)性能稳定，而且在临床笔记摘要任务上表现优于最先进的模型. |
| [^85] | [Audio-Visual Deception Detection: DOLOS Dataset and Parameter-Efficient Crossmodal Learning.](http://arxiv.org/abs/2303.12745) | 该论文介绍了DOLOS数据集，这是最大的游戏节目欺骗检测数据集，包含1,675个视频片段和丰富的欺骗对话。同时，该论文提出了一种参数高效的跨模态学习方法（PECL），可以有效地学习多模态特征。 |
| [^86] | [A multi-functional simulation platform for on-demand ride service operations.](http://arxiv.org/abs/2303.12336) | 本文介绍了一种用于按需乘车服务操作的多功能模拟平台，该平台具有高度的模块化，可扩展性和灵活性，在操作效率和公平性评估，优化算法调整以及实时动态操作控制等方面均能发挥作用，并为研究人员和实践者提供了一个公共的平台。 |
| [^87] | [A closer look at the training dynamics of knowledge distillation.](http://arxiv.org/abs/2303.11098) | 本文对知识蒸馏的训练动态进行了详细研究，实验证明投影器的设计决策、表示的标准化和软最大函数的选择对学生的性能有着重要影响，同时提出了一种解决容量差异问题的简单方法，以及与当前最先进的知识蒸馏技术相媲美的计算效率更高的方法。 |
| [^88] | [Meaningful human command: Advance control directives as a method to enable moral and legal responsibility for autonomous weapons systems.](http://arxiv.org/abs/2303.06813) | 本文探讨了如何确保在超越实时或非常缓慢的操作中的自主系统的道德和法律责任，并提出了建立“预先控制指令”框架的“自主命令”，来实现自主武器系统的问责和责任所需的深思熟虑的过程。 |
| [^89] | [Exploiting Multiple Abstractions in Episodic RL via Reward Shaping.](http://arxiv.org/abs/2303.00516) | 在这项工作中，我们通过引入一种新颖的奖励塑形形式，利用多层次的抽象来改善强化学习的效率，并且对抽象模型的设计要求较少，具有容忍性。 |
| [^90] | [Explainable Contextual Anomaly Detection using Quantile Regression Forests.](http://arxiv.org/abs/2302.11239) | 该论文提出了一种可解释的上下文异常检测方法，运用分位数回归森林来模拟特征之间的依赖关系，能够更准确和可解释地识别偏离类似对象上下文的其他对象。 |
| [^91] | [Universal Morphology Control via Contextual Modulation.](http://arxiv.org/abs/2302.11070) | 本文提出了通过上下文调节实现通用形态控制的方法，包括使用超网络生成形态相关的控制参数以及利用固定的注意机制调节机器人中不同肢体之间的交互作用。这种方法可以提高学习效率和泛化能力。 |
| [^92] | [DiSProD: Differentiable Symbolic Propagation of Distributions for Planning.](http://arxiv.org/abs/2302.01491) | DiSProD是一个用于连续状态和动作空间中概率转移的在线规划器，它可以通过使用概率分布近似传播生成可微分的符号图表示策略价值，在处理稀疏奖励和随机环境方面优于现有规划器。 |
| [^93] | [Emergent Analogical Reasoning in Large Language Models.](http://arxiv.org/abs/2212.09196) | GPT-3在许多类比任务中表现出与甚至超越人类的能力，揭示了大型语言模型的紧急能力。 |
| [^94] | [Formal Controller Synthesis for Markov Jump Linear Systems with Uncertain Dynamics.](http://arxiv.org/abs/2212.00679) | 本文介绍了一种方法，用于合成马尔可夫跳变线性系统（MJLS）的控制器，以确保满足概率计算树逻辑（PCTL）公式，对于转移概率未知或已知但存在一定的区间的问题提出了解决方案。 |
| [^95] | [Automatic Emergency Dust-Free solution on-board International Space Station with Bi-GRU (AED-ISS).](http://arxiv.org/abs/2210.08549) | 该论文旨在解决国际空间站上颗粒物对仪器的危害问题，通过Bi-GRU算法构建早期预警系统，预测颗粒物水平，并为宇航员提供充足的反应时间。这项研究还有潜力发展为与火灾相关的遥感烟雾报警装置。 |
| [^96] | [SSIVD-Net: A Novel Salient Super Image Classification & Detection Technique for Weaponized Violence.](http://arxiv.org/abs/2207.12850) | 本文提出了一种名为SSIVD-Net的新技术，用于暴力识别任务。通过使用显著-超级图像表示减少了3D视频数据的复杂性，提高了推断、性能和可解释性。作者还提出了一种新颖的架构“Salient-Classifier”，将核方法和残差学习策略相结合。该方法在多个数据集上表现良好。 |
| [^97] | [Mondrian Forest for Data Stream Classification Under Memory Constraints.](http://arxiv.org/abs/2205.07871) | 本文将在线Mondrian Forest分类算法适应到在数据流上具有内存限制的情况下，并设计了内存不足策略和修剪机制。研究表明，在所有配置中，Extend Node策略是最佳的内存不足策略。 |

# 详细

[^1]: MM-Vet: 评估大型多模态模型的综合能力

    MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities. (arXiv:2308.02490v1 [cs.AI])

    [http://arxiv.org/abs/2308.02490](http://arxiv.org/abs/2308.02490)

    MM-Vet是一个评估标准，用于评估大型多模态模型在复杂任务上的综合能力。该标准解决了如何结构化和评估复杂多模态任务、设计适用于不同问题和回答类型的评估指标以及如何提供模型洞察的问题。通过整合不同的核心视觉-语言能力，MM-Vet展示了有趣的能力和解决复杂任务的方法。

    

    我们提出了MM-Vet，一个评估标准，用于检查在复杂多模态任务上的大型多模态模型（LMM）的表现。最近的LMM展示了各种有趣的能力，例如解决书写在黑板上的数学问题，推理新闻图片中的事件和名人，以及解释视觉笑话。快速的模型进步给评估标准的开发带来了挑战。问题包括：（1）如何系统地构建和评估复杂的多模态任务；（2）如何设计适用于不同类型问题和回答的评估指标；（3）如何给出超出简单性能排名的模型洞察。为此，我们提出了MM-Vet，基于这样一个洞察：解决复杂任务的有趣能力通常通过一种通才模型能够整合不同的核心视觉-语言（VL）能力来实现。MM-Vet定义了6个核心VL能力，并检查了从这些能力组合中得出的16种有趣的整合方式。

    We propose MM-Vet, an evaluation benchmark that examines large multimodal models (LMMs) on complicated multimodal tasks. Recent LMMs have shown various intriguing abilities, such as solving math problems written on the blackboard, reasoning about events and celebrities in news images, and explaining visual jokes. Rapid model advancements pose challenges to evaluation benchmark development. Problems include: (1) How to systematically structure and evaluate the complicated multimodal tasks; (2) How to design evaluation metrics that work well across question and answer types; and (3) How to give model insights beyond a simple performance ranking. To this end, we present MM-Vet, designed based on the insight that the intriguing ability to solve complicated tasks is often achieved by a generalist model being able to integrate different core vision-language (VL) capabilities. MM-Vet defines 6 core VL capabilities and examines the 16 integrations of interest derived from the capability combin
    
[^2]: 通过多模态分类探索的强化学习实现非抓取平面操作

    Nonprehensile Planar Manipulation through Reinforcement Learning with Multimodal Categorical Exploration. (arXiv:2308.02459v1 [cs.RO])

    [http://arxiv.org/abs/2308.02459](http://arxiv.org/abs/2308.02459)

    本研究提出了一种多模态分类探索方法，通过此方法能够训练出平滑且准确的非抓取平面操作控制器。此方法能够捕捉任务的混合动力学特性，解决了之前使用的单模态探索策略无法实现准确性和平滑轨迹的问题。

    

    开发能够实现灵巧的非抓取平面操作的机器人控制器是具有挑战性的。问题的欠驱动和混合动力学特性，再加上摩擦力交互所产生的不确定性，需要复杂的控制行为。强化学习（RL）是开发此类机器人控制器的强大框架。然而，先前的RL文献解决非抓取推动任务时的准确性低、轨迹不平滑，并且仅实现简单的运动，即不旋转被操作的对象。我们推测之前使用的单模态探索策略无法捕捉任务的混合动力学特性，因为机器人和物体之间可能存在不同的接触交互模式，如粘着、滑动和分离。在这项工作中，我们提出了一种通过分类分布进行多模态探索的方法，使我们能够训练出平滑且准确的非抓取平面操作控制器。

    Developing robot controllers capable of achieving dexterous nonprehensile manipulation, such as pushing an object on a table, is challenging. The underactuated and hybrid-dynamics nature of the problem, further complicated by the uncertainty resulting from the frictional interactions, requires sophisticated control behaviors. Reinforcement Learning (RL) is a powerful framework for developing such robot controllers. However, previous RL literature addressing the nonprehensile pushing task achieves low accuracy, non-smooth trajectories, and only simple motions, i.e. without rotation of the manipulated object. We conjecture that previously used unimodal exploration strategies fail to capture the inherent hybrid-dynamics of the task, arising from the different possible contact interaction modes between the robot and the object, such as sticking, sliding, and separation. In this work, we propose a multimodal exploration approach through categorical distributions, which enables us to train p
    
[^3]: 关于时态知识图补全的综述：分类、进展和前景展望

    A Survey on Temporal Knowledge Graph Completion: Taxonomy, Progress, and Prospects. (arXiv:2308.02457v1 [cs.AI])

    [http://arxiv.org/abs/2308.02457](http://arxiv.org/abs/2308.02457)

    这篇论文是关于时态知识图补全的综述，主要介绍了该领域的分类、进展和前景展望。由于新知识的不断涌现、提取结构化信息的算法不足以及源数据集中信息的缺失，时态知识图往往不完整。因此，时态知识图补全任务越来越受关注，旨在基于可用信息预测缺失项。

    

    时间特征在大量知识中明显可见，这突显了时态知识图在学术界和工业界中的关键作用。然而，时态知识图往往因为三个主要原因而不完整：新知识的不断出现，从非结构化数据中提取结构化信息的算法的不足，以及源数据集中信息的缺失。因此，时态知识图补全任务引起了越来越多的关注，旨在基于可用信息预测缺失项。本文对时态知识图补全方法及其细节进行了全面的综述。具体而言，本文主要由三个部分组成，即1）背景，涵盖了时态知识图补全方法的基础知识，训练所需的损失函数，以及数据集和评估协议；2）插值，用于估计和预测缺失的元素或元素集合

    Temporal characteristics are prominently evident in a substantial volume of knowledge, which underscores the pivotal role of Temporal Knowledge Graphs (TKGs) in both academia and industry. However, TKGs often suffer from incompleteness for three main reasons: the continuous emergence of new knowledge, the weakness of the algorithm for extracting structured information from unstructured data, and the lack of information in the source dataset. Thus, the task of Temporal Knowledge Graph Completion (TKGC) has attracted increasing attention, aiming to predict missing items based on the available information. In this paper, we provide a comprehensive review of TKGC methods and their details. Specifically, this paper mainly consists of three components, namely, 1)Background, which covers the preliminaries of TKGC methods, loss functions required for training, as well as the dataset and evaluation protocol; 2)Interpolation, that estimates and predicts the missing elements or set of elements th
    
[^4]: 研究Federated Machine Learning在实际领域中的应用现状

    SoK: Assessing the State of Applied Federated Machine Learning. (arXiv:2308.02454v1 [cs.LG])

    [http://arxiv.org/abs/2308.02454](http://arxiv.org/abs/2308.02454)

    本研究评估了Federated Machine Learning（FedML）在实际应用中的现状，并发现了阻碍其实际应用的挑战。

    

    机器学习在各种应用中展现了巨大的潜力；然而，由于对数据隐私的担忧，它在需要保护隐私的领域的应用受到了限制。Federated Machine Learning（FedML）是解决这个问题的一种有希望的解决方案，它是一种面向数据的模型方法，更加重视数据隐私。通过使机器学习算法直接应用于分布式数据源而不共享原始数据，FedML提供了增强隐私保护，适用于需要保护隐私的环境。尽管在理论上具有显著优势，FedML在实践中并没有得到广泛应用。本研究旨在探索应用FedML的当前状态，并确定阻碍其实际应用的挑战。通过全面系统的文献回顾，我们评估了74篇相关论文，分析了FedML在实际应用中的可行性。我们的分析关注FedML实现的特征和新兴趋势，以及驱动力和应用方面的动机。

    Machine Learning (ML) has shown significant potential in various applications; however, its adoption in privacy-critical domains has been limited due to concerns about data privacy. A promising solution to this issue is Federated Machine Learning (FedML), a model-to-data approach that prioritizes data privacy. By enabling ML algorithms to be applied directly to distributed data sources without sharing raw data, FedML offers enhanced privacy protections, making it suitable for privacy-critical environments. Despite its theoretical benefits, FedML has not seen widespread practical implementation. This study aims to explore the current state of applied FedML and identify the challenges hindering its practical adoption. Through a comprehensive systematic literature review, we assess 74 relevant papers to analyze the real-world applicability of FedML. Our analysis focuses on the characteristics and emerging trends of FedML implementations, as well as the motivational drivers and application
    
[^5]: 从军事到医疗保健：采纳和扩展用于生成式人工智能的伦理原则

    From Military to Healthcare: Adopting and Expanding Ethical Principles for Generative Artificial Intelligence. (arXiv:2308.02448v1 [cs.CY])

    [http://arxiv.org/abs/2308.02448](http://arxiv.org/abs/2308.02448)

    这项研究探讨了从军事到医疗保健领域采纳和扩展伦理原则以应用生成式人工智能的可行性和重要性。

    

    在2020年，美国国防部正式公布了一套指导未来战场上人工智能技术使用的伦理原则。尽管存在明显差异，但军事和医疗服务之间存在核心的相似之处。战场上的战士经常面临需要快速决策的改变生活的情况。医疗服务提供者在快速变化的医疗环境中也面临类似的挑战，例如在急诊科或治疗危及生命的状况下进行手术。生成式人工智能是一种新兴技术，旨在高效生成有价值的信息，具有巨大潜力。随着计算能力的日益普及和大量的健康数据（如电子健康记录、心电图和医学图像）的增加，医疗保健领域必将被这项技术革命化。最近，生成式人工智能在研究界引起了广泛关注，引发了关于其伦理问题的讨论。

    In 2020, the U.S. Department of Defense officially disclosed a set of ethical principles to guide the use of Artificial Intelligence (AI) technologies on future battlefields. Despite stark differences, there are core similarities between the military and medical service. Warriors on battlefields often face life-altering circumstances that require quick decision-making. Medical providers experience similar challenges in a rapidly changing healthcare environment, such as in the emergency department or during surgery treating a life-threatening condition. Generative AI, an emerging technology designed to efficiently generate valuable information, holds great promise. As computing power becomes more accessible and the abundance of health data, such as electronic health records, electrocardiograms, and medical images, increases, it is inevitable that healthcare will be revolutionized by this technology. Recently, generative AI has captivated the research community, leading to debates about 
    
[^6]: AI文献综述套件

    AI Literature Review Suite. (arXiv:2308.02443v1 [cs.DL])

    [http://arxiv.org/abs/2308.02443](http://arxiv.org/abs/2308.02443)

    这个AI文献综述套件利用大型语言模型和自然语言处理的能力，提供了一个简化文献综述过程的解决方案，包括搜索、下载、整理PDF文件、提取文章内容，并提供了简明的综述摘要。这是一个自动化和优化学术和工业研究中文献综述过程的强大工具。

    

    进行文献综述往往是一项耗时且工作量大的过程。为了简化这个过程，我提出了一个AI文献综述套件，集成了多种功能，提供了全面的文献综述。该工具利用开放访问科学、大型语言模型和自然语言处理的能力，实现了PDF文件的搜索、下载和整理，以及从文章中提取内容。语义搜索查询用于数据检索，而使用大型语言模型的文本嵌入和摘要提供简明的文献综述。通过用户友好的图形用户界面（GUI），增强了与PDF的交互。该套件还具有用于文献资料组织、交互和查询以及文献综述摘要的集成程序。这个工具提供了一个强大的解决方案，以自动化和优化学术和工业研究中的文献综述过程。

    The process of conducting literature reviews is often time-consuming and labor-intensive. To streamline this process, I present an AI Literature Review Suite that integrates several functionalities to provide a comprehensive literature review. This tool leverages the power of open access science, large language models (LLMs) and natural language processing to enable the searching, downloading, and organizing of PDF files, as well as extracting content from articles. Semantic search queries are used for data retrieval, while text embeddings and summarization using LLMs present succinct literature reviews. Interaction with PDFs is enhanced through a user-friendly graphical user interface (GUI). The suite also features integrated programs for bibliographic organization, interaction and query, and literature review summaries. This tool presents a robust solution to automate and optimize the process of literature review in academic and industrial research.
    
[^7]: 在人工智能时代设计和开展高等教育课程：基于考试数据分析的洞见

    How to Design and Deliver Courses for Higher Education in the AI Era: Insights from Exam Data Analysis. (arXiv:2308.02441v1 [cs.CY])

    [http://arxiv.org/abs/2308.02441](http://arxiv.org/abs/2308.02441)

    在人工智能时代，设计和开展高等教育课程需要考虑人工智能的优势和局限性，并遵循教育学教育目标。本研究利用数据分析研究了七场考试的结果，发现学生的学习成绩与ChatGPT的使用没有相关性。

    

    在本篇观点论文中，我们主张在人工智能时代，课程和考试的设计必须基于两个因素：（1）人工智能的优势和局限性，（2）教育学教育目标。基于对Delors教育报告的洞察[1]，我们首先讨论了教育的作用，并回顾了教育机构在任何技术下都必须努力实现的主要目标。然后，我们基于当前人工智能的进展探讨了人工智能的优势和局限性。我们解释了如何根据这些优势和局限性设计课程和考试，并提供了IT、英语和艺术领域的不同示例。我们展示了我们从2023年1月到2023年5月采用了受苏格拉底教学法启发的教学方法。然后，我们呈现了2022年12月至2023年3月举行的七场ChatGPT授权考试的数据分析结果。我们的考试数据结果表明，学生的学习成绩与考试中的ChatGPT 不具有相关性。

    In this position paper, we advocate for the idea that courses and exams in the AI era have to be designed based on two factors: (1) the strengths and limitations of AI, and (2) the pedagogical educational objectives. Based on insights from the Delors report on education [1], we first address the role of education and recall the main objectives that educational institutes must strive to achieve independently of any technology. We then explore the strengths and limitations of AI, based on current advances in AI. We explain how courses and exams can be designed based on these strengths and limitations of AI, providing different examples in the IT, English, and Art domains. We show how we adopted a pedagogical approach that is inspired from the Socratic teaching method from January 2023 to May 2023. Then, we present the data analysis results of seven ChatGPT-authorized exams conducted between December 2022 and March 2023. Our exam data results show that there is no correlation between stud
    
[^8]: 一种利用大型语言模型辅助教学的教育工具，用于对开放性问题作出反馈

    A large language model-assisted education tool to provide feedback on open-ended responses. (arXiv:2308.02439v1 [cs.CY])

    [http://arxiv.org/abs/2308.02439](http://arxiv.org/abs/2308.02439)

    这个工具利用大型语言模型辅助教学，能够自动回答开放性问题并提供个性化的反馈，有助于提高学生的学习效果。

    

    开放性问题是教师评估学生理解和鼓励对课程材料进行批判性探索的常用工具。为这些回答提供反馈是一项耗时的任务，可能导致教师不堪重负，反馈质量下降。许多教师转而使用更简单的问题格式，如多项选择题，这种格式提供即时反馈，但无法提供个性化和深入的评论。在这里，我们提出了一种工具，利用大型语言模型（LLMs），根据教师定义的标准，自动回答开放性问题。我们的工具提供快速的个性化反馈，使学生能够快速测试他们的知识并找出需要改进的领域。我们提供了开源的参考实现，既可以作为Web应用程序，也可以作为与教学编码或数学笔记本一起使用的Jupyter Notebook小部件。在教师的指导下，LLMs有望提高学生的学习效果。

    Open-ended questions are a favored tool among instructors for assessing student understanding and encouraging critical exploration of course material. Providing feedback for such responses is a time-consuming task that can lead to overwhelmed instructors and decreased feedback quality. Many instructors resort to simpler question formats, like multiple-choice questions, which provide immediate feedback but at the expense of personalized and insightful comments. Here, we present a tool that uses large language models (LLMs), guided by instructor-defined criteria, to automate responses to open-ended questions. Our tool delivers rapid personalized feedback, enabling students to quickly test their knowledge and identify areas for improvement. We provide open-source reference implementations both as a web application and as a Jupyter Notebook widget that can be used with instructional coding or math notebooks. With instructor guidance, LLMs hold promise to enhance student learning outcomes a
    
[^9]: 设计信托人工智能

    Designing Fiduciary Artificial Intelligence. (arXiv:2308.02435v1 [cs.CY])

    [http://arxiv.org/abs/2308.02435](http://arxiv.org/abs/2308.02435)

    本文综合了计算机科学和法律领域的最新研究，提出了一种设计和审计信托人工智能的方法，用于解决数据主体在与复杂技术系统交互时同意不完全性的问题。

    

    信托人是一位受信任的代理人，具有对雇佣他们的委托人以忠诚和关心的法律义务。当信托组织通过数字界面与用户交互，或以人工智能方式自动化其操作时，他们需要设计这些人工智能系统以符合他们的职责。本文综合了计算机科学和法律领域的最新研究，提出了一种设计和审计信托人工智能的方法。信托人工智能的设计者应了解系统的背景，确定其委托人，并评估这些委托人的最佳利益。然后，设计者必须以与利益相关的方式忠诚且谨慎。我们将此过程中的步骤与可信人工智能的维度（如隐私和一致性）联系起来。信托人工智能是解决数据主体在与复杂技术系统交互时同意不完全性的一种有前景的方法。

    A fiduciary is a trusted agent that has the legal duty to act with loyalty and care towards a principal that employs them. When fiduciary organizations interact with users through a digital interface, or otherwise automate their operations with artificial intelligence, they will need to design these AI systems to be compliant with their duties. This article synthesizes recent work in computer science and law to develop a procedure for designing and auditing Fiduciary AI. The designer of a Fiduciary AI should understand the context of the system, identify its principals, and assess the best interests of those principals. Then the designer must be loyal with respect to those interests, and careful in an contextually appropriate way. We connect the steps in this procedure to dimensions of Trustworthy AI, such as privacy and alignment. Fiduciary AI is a promising means to address the incompleteness of data subject's consent when interacting with complex technical systems.
    
[^10]: 在计算机科学学位课程中大型语言模型的性能

    Performance of Large Language Models in a Computer Science Degree Program. (arXiv:2308.02432v1 [cs.CY])

    [http://arxiv.org/abs/2308.02432](http://arxiv.org/abs/2308.02432)

    该论文研究了在一所应用科学大学的计算机科学本科课程中不同大型语言模型的性能。通过将它们作为教学辅助工具，在不同计算机科学领域的课程中进行评估，展示了这些模型的强大性能，同时强调了在这样一个学位课程的背景下的限制和约束。

    

    ChatGPT-3.5和GPT-4.0等大型语言模型在当前的讨论中无处不在并且占据主导地位。它们具有变革性的能力已经引起了我们与（基于文本的）信息互动和利用的范式转变。每天都有新的可能性来利用这些模型的能力。本文介绍了在一所应用科学大学的计算机科学本科课程中不同大型语言模型的性能研究结果。我们的主要目标是通过将它们作为教学辅助工具在课程中使用来评估这些模型的有效性。通过使用课堂材料、练习任务和过去的考试来启发模型，我们旨在评估它们在不同计算机科学领域的熟练程度。我们展示了当前大型语言模型的强大性能，同时强调了在这样一个学位课程的背景下的限制和约束。

    Large language models such as ChatGPT-3.5 and GPT-4.0 are ubiquitous and dominate the current discourse. Their transformative capabilities have led to a paradigm shift in how we interact with and utilize (text-based) information. Each day, new possibilities to leverage the capabilities of these models emerge. This paper presents findings on the performance of different large language models in a university of applied sciences' undergraduate computer science degree program. Our primary objective is to assess the effectiveness of these models within the curriculum by employing them as educational aids. By prompting the models with lecture material, exercise tasks, and past exams, we aim to evaluate their proficiency across different computer science domains. We showcase the strong performance of current large language models while highlighting limitations and constraints within the context of such a degree program. We found that ChatGPT-3.5 averaged 79.9% of the total score in 10 tested 
    
[^11]: 解锁相似性匹配的潜力：可扩展性、监督和预训练

    Unlocking the Potential of Similarity Matching: Scalability, Supervision and Pre-training. (arXiv:2308.02427v1 [cs.NE])

    [http://arxiv.org/abs/2308.02427](http://arxiv.org/abs/2308.02427)

    本研究提出了一种基于相似性匹配的学习模式，通过使用PyTorch实现了扩展到大型数据集的卷积非负相似性匹配，引入了局部监督的SM目标，以及利用PyTorch实现预训练网络结构的特征评估对比。这将生物学合理性的算法与计算成本相结合，提供了一种在线、本地化且具有生物学合理性的学习方法。

    

    尽管有效，反向传播算法在生物合理性、计算成本和在线学习适应性方面存在局限性。因此，人们对于基于局部学习规则的可替代生物学合理性学习方法越来越感兴趣。本研究重点研究了主要是非监督的相似性匹配(SM)框架，该框架与生物系统中观察到的机制相一致，并提供了在线、本地化和生物学上合理的算法。i) 为了将相似性匹配(SM)扩展到大型数据集，我们提出了使用PyTorch的卷积非负SM的实现。ii) 我们引入了一种类似于典型相关性分析的局部监督SM目标，便于堆叠SM层。iii) 我们利用PyTorch实现预训练网络结构，如LeNet，并将其特征评估与反向传播训练的模型进行比较。本研究将具有生物合理性的算法与计算成本相结合

    While effective, the backpropagation (BP) algorithm exhibits limitations in terms of biological plausibility, computational cost, and suitability for online learning. As a result, there has been a growing interest in developing alternative biologically plausible learning approaches that rely on local learning rules. This study focuses on the primarily unsupervised similarity matching (SM) framework, which aligns with observed mechanisms in biological systems and offers online, localized, and biologically plausible algorithms. i) To scale SM to large datasets, we propose an implementation of Convolutional Nonnegative SM using PyTorch. ii) We introduce a localized supervised SM objective reminiscent of canonical correlation analysis, facilitating stacking SM layers. iii) We leverage the PyTorch implementation for pre-training architectures such as LeNet and compare the evaluation of features against BP-trained models. This work combines biologically plausible algorithms with computationa
    
[^12]: 实现智能合约：NFT租赁与按赞付费的案例

    Implementing Smart Contracts: The case of NFT-rental with pay-per-like. (arXiv:2308.02424v1 [cs.CY])

    [http://arxiv.org/abs/2308.02424](http://arxiv.org/abs/2308.02424)

    本研究介绍了一种基于区块链技术的NFT租赁解决方案，采用按赞付费的定价模型。然而，区块链费用可能不公平，并且对于小众艺术家可能会产生阻碍文化多样性的影响。

    

    非同质化代币（NFTs）正在兴起。它们可以代表在公司网页或在线商店上展示的艺术品——与实体艺术品类似进行市场宣传。NFT的出租是所有者的一种吸引人的 pass passive 收入形式，但也伴随着风险（例如，物品没有归还）和代管机构的费用。同样，租借人难以预测艺术品的影响，例如，NFT的观众如何感知它们。为了解决这些挑战，我们引入了一种基于区块链技术的NFT租赁解决方案，采用按赞付费的定价模型，即基于以太坊链的智能合约。我们发现，区块链解决方案享有许多也适用于其他应用程序的优势，但有趣的是，我们还观察到（大型）区块链费用的负面影响。区块链解决方案对于小众艺术家似乎是不公平的，并且可能阻碍文化多样性。此外，出现了信任成本权衡以处理外部 parties 引起的欺诈行为。

    Non-fungible tokens(NFTs) are on the rise. They can represent artworks exhibited for marketing purposes on webpages of companies or online stores -analogously to physical artworks. Lending of NFTs is an attractive form of passive income for owners but comes with risks (e.g., items are not returned) and costs for escrow agents. Similarly, renters have difficulties in anticipating the impact of artworks, e.g., how spectators of NFTs perceive them. To address these challenges, we introduce an NFT rental solution based on a pay-per-like pricing model using blockchain technology, i.e., smart contracts based on the Ethereum chain. We find that blockchain solutions enjoy many advantages also reported for other applications, but interestingly, we also observe dark sides of (large) blockchain fees. Blockchain solutions appear unfair to niche artists and potentially hamper cultural diversity. Furthermore, a trust-cost tradeoff arises to handle fraud caused by manipulation from parties outside 
    
[^13]: 在帕金森病中用于检测药物使用的多模态室内定位：在自由生活环境中的观察性试验

    Multimodal Indoor Localisation in Parkinson's Disease for Detecting Medication Use: Observational Pilot Study in a Free-Living Setting. (arXiv:2308.02419v1 [eess.SP])

    [http://arxiv.org/abs/2308.02419](http://arxiv.org/abs/2308.02419)

    该研究提出了一种基于变压器的方法，使用穿戴设备的RSSI和加速度计数据进行室内定位，以改善当前方法的有效性。研究还探讨了室内定位是否可以通过检测帕金森病患者的药物使用情况来评估运动波动。

    

    帕金森病（PD）是一种缓慢进展的神经退行性疾病，导致包括步态障碍在内的运动症状。运动波动是指在左多巴疗法（“开”）和PD症状再度出现（“关”）之间的变化，因药物效果减退而引起。这些波动经常影响步态速度，并随着PD进展而增加其致残影响。为了提高当前室内定位方法的有效性，提出了一种基于变压器的方法，利用可穿戴设备的接收信号强度指示器（RSSI）和加速度计数据提供互补的运动视角。一个次目标旨在评估室内定位，包括其家庭步态速度特征（即在房间之间行走所需的时间），是否可以用于通过检测帕金森病患者是否正在使用左多巴药物或患者是否停用药物来评估运动波动。

    Parkinson's disease (PD) is a slowly progressive, debilitating neurodegenerative disease which causes motor symptoms including gait dysfunction. Motor fluctuations are alterations between periods with a positive response to levodopa therapy ("on") and periods marked by re-emergency of PD symptoms ("off") as the response to medication wears off. These fluctuations often affect gait speed and they increase in their disabling impact as PD progresses. To improve the effectiveness of current indoor localisation methods, a transformer-based approach utilising dual modalities which provide complementary views of movement, Received Signal Strength Indicator (RSSI) and accelerometer data from wearable devices, is proposed. A sub-objective aims to evaluate whether indoor localisation, including its in-home gait speed features (i.e. the time taken to walk between rooms), could be used to evaluate motor fluctuations by detecting whether the person with PD is taking levodopa medications or withhold
    
[^14]: 通过1D时间卷积网络评估驾驶员的疲劳状态

    Car-Driver Drowsiness Assessment through 1D Temporal Convolutional Networks. (arXiv:2308.02415v1 [eess.SP])

    [http://arxiv.org/abs/2308.02415](http://arxiv.org/abs/2308.02415)

    该研究设计了一种新型生物传感器，通过分析光电容积图（PPG）信号来评估驾驶员的生理状态。

    

    最近，先进驾驶辅助系统解决方案（ADAS）的科学进展在提高驾驶的整体安全性方面起到了关键作用。ADAS技术使得能够主动控制车辆以预防潜在的危险情况。研究人员关注的一个重要方面是驾驶员注意力水平的分析，因为最近的报告证实了由疲劳或缺乏注意力导致的事故数量的增加。为了解决这个问题，各种研究建议监测驾驶员的生理状态，因为自主神经系统（ANS）与注意力水平之间存在着很好的联系。对于我们的研究，我们设计了一种创新的生物传感器，包括近红外LED发射器和光电传感器，特别是硅光倍增器装置。这使我们能够通过分析相关的光电容积图（PPG）信号来评估驾驶员的生理状态。

    Recently, the scientific progress of Advanced Driver Assistance System solutions (ADAS) has played a key role in enhancing the overall safety of driving. ADAS technology enables active control of vehicles to prevent potentially risky situations. An important aspect that researchers have focused on is the analysis of the driver attention level, as recent reports confirmed a rising number of accidents caused by drowsiness or lack of attentiveness. To address this issue, various studies have suggested monitoring the driver physiological state, as there exists a well-established connection between the Autonomic Nervous System (ANS) and the level of attention. For our study, we designed an innovative bio-sensor comprising near-infrared LED emitters and photo-detectors, specifically a Silicon PhotoMultiplier device. This allowed us to assess the driver physiological status by analyzing the associated PhotoPlethysmography (PPG) signal.Furthermore, we developed an embedded time-domain hyper-fi
    
[^15]: 基于WiFi CSI的自监督学习的人体活动识别：系统性研究

    Self-Supervised Learning for WiFi CSI-Based Human Activity Recognition: A Systematic Study. (arXiv:2308.02412v1 [eess.SP])

    [http://arxiv.org/abs/2308.02412](http://arxiv.org/abs/2308.02412)

    本研究对基于WiFi CSI的人体活动识别进行了自监督学习，提出了一种解决深度学习中数据不足的方法。通过将深度学习技术与CSI数据相结合，实现了最先进的性能，无需专家知识。研究人员通过分析不同类型的自监督学习算法的潜力，对缺乏标记CSI数据的挑战进行了全面的整理和分析。

    

    最近，随着物联网（IoT）的发展，基于WiFi CSI的人体活动识别(HAR)引起了学术界和工业界的越来越多的关注。通过将深度学习技术与基于CSI的HAR相结合，研究人员在不需要专家知识的情况下实现了最先进的性能。然而，在基于CSI的HAR的背景下，标记CSI数据的稀缺性仍然是应用深度学习模型时最突出的挑战，这是由于CSI数据的隐私性和不可理解性。另一方面，自监督学习（SSL）作为一种在不重视标记示例的情况下从数据中学习有意义表示的有前途的方法已经出现。因此，通过利用SSL算法来解决深度学习中数据不足的挑战已经做出了相当大的努力。在本文中，我们对不同类型的SSL算法的潜力进行了全面的整理和分析，包括以前研究过的算法和那些还没有得到广泛研究的算法。

    Recently, with the advancement of the Internet of Things (IoT), WiFi CSI-based HAR has gained increasing attention from academic and industry communities. By integrating the deep learning technology with CSI-based HAR, researchers achieve state-of-the-art performance without the need of expert knowledge. However, the scarcity of labeled CSI data remains the most prominent challenge when applying deep learning models in the context of CSI-based HAR due to the privacy and incomprehensibility of CSI-based HAR data. On the other hand, SSL has emerged as a promising approach for learning meaningful representations from data without heavy reliance on labeled examples. Therefore, considerable efforts have been made to address the challenge of insufficient data in deep learning by leveraging SSL algorithms. In this paper, we undertake a comprehensive inventory and analysis of the potential held by different categories of SSL algorithms, including those that have been previously studied and tho
    
[^16]: 通过融合多空间深度模型的脑电信号来估计心理负荷

    Mental Workload Estimation with Electroencephalogram Signals by Combining Multi-Space Deep Models. (arXiv:2308.02409v1 [eess.SP])

    [http://arxiv.org/abs/2308.02409](http://arxiv.org/abs/2308.02409)

    该论文通过融合多个空间维度的方法，使用脑电信号对心理负荷进行分类和估计连续级别。在时间域中使用了时态卷积网络，而在频率域中引入了新的架构——多维残差块。

    

    人脑在工作和休息时都处于持续活动的状态。心理活动是日常过程中的一部分，当大脑过度劳累时，会对人体健康产生负面影响。近年来，人们对于早期检测心理健康问题的重视逐渐增加，因为这可以帮助预防严重的健康问题，并改善生活质量。多种信号被用于评估心理状态，但由于大量提供关于大脑信息的特点，脑电图（EEG）被研究人员广泛使用。本文旨在将心理负荷分为三种状态并估计连续级别。我们的方法通过融合多个空间维度来实现最佳的心理估计结果。在时间域方法中，我们使用了时态卷积网络，而在频率域上，我们提出了一种名为多维残差块的新架构，它结合了残差块。

    The human brain is in a continuous state of activity during both work and rest. Mental activity is a daily process, and when the brain is overworked, it can have negative effects on human health. In recent years, great attention has been paid to early detection of mental health problems because it can help prevent serious health problems and improve quality of life. Several signals are used to assess mental state, but the electroencephalogram (EEG) is widely used by researchers because of the large amount of information it provides about the brain. This paper aims to classify mental workload into three states and estimate continuum levels. Our method combines multiple dimensions of space to achieve the best results for mental estimation. In the time domain approach, we use Temporal Convolutional Networks, and in the frequency domain, we propose a new architecture called the Multi-Dimensional Residual Block, which combines residual blocks.
    
[^17]: 通过迁移学习评估认知任务的结构

    Evaluating the structure of cognitive tasks with transfer learning. (arXiv:2308.02408v1 [eess.SP])

    [http://arxiv.org/abs/2308.02408](http://arxiv.org/abs/2308.02408)

    本研究通过迁移学习探索了在脑电图解码任务中，不同任务之间深度学习表征的可迁移性，并展示了即使是线性探测转移，也可以显著提高解码性能，相较于纯监督方法，改进幅度高达28%。

    

    由于标记数据有限，脑电图（EEG）解码是一项具有挑战性的任务。虽然迁移学习是解决这一挑战的一种有前景的技术，但它假设可传递的数据领域和任务是已知的，而在这个设置中并非如此。本研究调查了不同EEG解码任务之间深度学习表示的可迁移性。我们使用最先进的解码模型对最近发布的ERP CORE和M$^3$CV两个EEG数据集进行了大量实验，这两个数据集包含超过140个受试者和11个不同的认知任务。我们通过在一个任务上对深度神经网络进行预训练，并评估它们解码后续任务的能力，来衡量学到的表示的可迁移性。我们的实验表明，即使是线性探测转移，也可以获得显著的解码性能改进，相较于纯监督方法，改进幅度高达28%。此外，我们发现了证据证明...

    Electroencephalography (EEG) decoding is a challenging task due to the limited availability of labelled data. While transfer learning is a promising technique to address this challenge, it assumes that transferable data domains and task are known, which is not the case in this setting. This study investigates the transferability of deep learning representations between different EEG decoding tasks. We conduct extensive experiments using state-of-the-art decoding models on two recently released EEG datasets, ERP CORE and M$^3$CV, containing over 140 subjects and 11 distinct cognitive tasks. We measure the transferability of learned representations by pre-training deep neural networks on one task and assessing their ability to decode subsequent tasks. Our experiments demonstrate that, even with linear probing transfer, significant improvements in decoding performance can be obtained, with gains of up to 28% compare with the pure supervised approach. Additionally, we discover evidence tha
    
[^18]: 《使用联合生存森林在医疗保健中扩展生存分析: 心力衰竭和乳腺癌基因组的比较研究》

    Scaling Survival Analysis in Healthcare with Federated Survival Forests: A Comparative Study on Heart Failure and Breast Cancer Genomics. (arXiv:2308.02382v1 [cs.LG])

    [http://arxiv.org/abs/2308.02382](http://arxiv.org/abs/2308.02382)

    本研究针对医疗保健中生存数据的挑战，提出了FedSurF++算法，这是一种联合学习算法用于处理分布式的、具有隐私保密要求的生存分析。该算法可以大规模建模和处理生存数据，解决了数据稀缺和隐私保密的问题。

    

    生存分析是医学中的一种基本工具，用于对人群中发生感兴趣事件的时间进行建模。然而，在现实世界的应用中，生存数据通常是不完整、被审查、分布式和保密的，特别是在隐私保密至关重要的医疗保健环境中。数据稀缺严重限制了生存模型在依赖大型数据池的分布式应用中的可扩展性。联合学习是一种有望通过在多个数据集上训练机器学习模型而不损害用户隐私的技术，因此特别适合解决生存数据和大规模生存应用的挑战。尽管联合学习在分类和回归领域取得了重大发展，但在生存分析领域仍有许多未探索的方向。在本研究中，我们提出了联合生存森林算法的扩展，称为FedSurF++。这种联合集成方法可以对大规模生存数据进行建模并处理分布式情况。

    Survival analysis is a fundamental tool in medicine, modeling the time until an event of interest occurs in a population. However, in real-world applications, survival data are often incomplete, censored, distributed, and confidential, especially in healthcare settings where privacy is critical. The scarcity of data can severely limit the scalability of survival models to distributed applications that rely on large data pools. Federated learning is a promising technique that enables machine learning models to be trained on multiple datasets without compromising user privacy, making it particularly well-suited for addressing the challenges of survival data and large-scale survival applications. Despite significant developments in federated learning for classification and regression, many directions remain unexplored in the context of survival analysis. In this work, we propose an extension of the Federated Survival Forest algorithm, called FedSurF++. This federated ensemble method const
    
[^19]: 使用机器学习方法从探测车数据预测交通信号灯定时

    A Machine Learning Method for Predicting Traffic Signal Timing from Probe Vehicle Data. (arXiv:2308.02370v1 [cs.LG])

    [http://arxiv.org/abs/2308.02370](http://arxiv.org/abs/2308.02370)

    本文提出了使用机器学习方法从探测车数据预测交通信号灯定时的方法，利用XGBoost模型估计信号周期长度，利用神经网络模型确定红灯时间，并根据周期长度和红灯时间计算绿灯时间。结果显示，对信号周期长度的估计误差小于0.56秒，红灯时间的预测误差平均在7.2秒以内。

    

    交通信号灯在交通运输中起着重要作用，它们能够管理交通流量并确保交叉路口的安全。此外，了解交通信号灯的相位和定时数据可以实现最佳车辆行驶路线，提高时间和能源效率，进行生态驾驶以及准确模拟有信号的道路网络。本文提出了一种利用机器学习方法从车辆探测数据估计交通信号灯定时信息的方法。据作者所知，很少有研究利用机器学习技术从车辆探测数据确定交通信号灯定时参数的工作。在本研究中，我们开发了一种极限梯度增强（XGBoost）模型来估计信号周期长度，并利用神经网络模型从探测数据中确定相应的红灯时间。然后根据周期长度和红灯时间计算绿灯时间。我们的结果显示，信号周期长度的误差小于0.56秒，红灯时间的预测误差平均在7.2秒以内。

    Traffic signals play an important role in transportation by enabling traffic flow management, and ensuring safety at intersections. In addition, knowing the traffic signal phase and timing data can allow optimal vehicle routing for time and energy efficiency, eco-driving, and the accurate simulation of signalized road networks. In this paper, we present a machine learning (ML) method for estimating traffic signal timing information from vehicle probe data. To the authors best knowledge, very few works have presented ML techniques for determining traffic signal timing parameters from vehicle probe data. In this work, we develop an Extreme Gradient Boosting (XGBoost) model to estimate signal cycle lengths and a neural network model to determine the corresponding red times per phase from probe data. The green times are then be derived from the cycle length and red times. Our results show an error of less than 0.56 sec for cycle length, and red times predictions within 7.2 sec error on ave
    
[^20]: 通用防御底纹补丁：使您的文本对光学字符识别变得隐形

    Universal Defensive Underpainting Patch: Making Your Text Invisible to Optical Character Recognition. (arXiv:2308.02369v1 [cs.CV])

    [http://arxiv.org/abs/2308.02369](http://arxiv.org/abs/2308.02369)

    提出了一种通用防御底纹补丁（UDUP）机制，通过修改文本图像的底纹而非字符，有效地防御未经授权的光学字符识别（OCR）盗版，无论截屏范围或图像背景的复杂性，都适用。

    

    光学字符识别（OCR）可以从扫描或数字化的文本图像中自动提取文本，但也使得从这些图像中盗取有价值或敏感的文本变得容易。以往用于防止OCR盗版的方法通过扭曲文本图像中的字符，在现实场景中是不实际的，因为盗版者可以捕获文本图像的任意部分，使防御措施失效。在这项工作中，我们提出了一种新颖而有效的防御机制，称为通用防御底纹补丁（UDUP），它修改文本图像的底纹而不是字符。UDUP是通过迭代优化过程创建的，用于制作一个小型的、固定大小的防御补丁，可以为任意大小的文本图像生成非重叠的底纹。实验结果表明，在任何截屏范围或复杂图像背景的情况下，UDUP有效地防御未经授权的OCR。它对内容、大小、颜色和语言都是无关的。

    Optical Character Recognition (OCR) enables automatic text extraction from scanned or digitized text images, but it also makes it easy to pirate valuable or sensitive text from these images. Previous methods to prevent OCR piracy by distorting characters in text images are impractical in real-world scenarios, as pirates can capture arbitrary portions of the text images, rendering the defenses ineffective. In this work, we propose a novel and effective defense mechanism termed the Universal Defensive Underpainting Patch (UDUP) that modifies the underpainting of text images instead of the characters. UDUP is created through an iterative optimization process to craft a small, fixed-size defensive patch that can generate non-overlapping underpainting for text images of any size. Experimental results show that UDUP effectively defends against unauthorized OCR under the setting of any screenshot range or complex image background. It is agnostic to the content, size, colors, and languages of 
    
[^21]: 灵活的差分隐私垂直联邦学习与自适应特征嵌入

    Flexible Differentially Private Vertical Federated Learning with Adaptive Feature Embeddings. (arXiv:2308.02362v1 [cs.CR])

    [http://arxiv.org/abs/2308.02362](http://arxiv.org/abs/2308.02362)

    本文提出了一种灵活的差分隐私垂直联邦学习方法（VFL），通过应用范数剪裁实现了严格的隐私保证，并通过自适应调整特征嵌入的尺度和分布来优化任务效用，而不损害隐私保护。

    

    垂直联邦学习（VFL）的出现引发了对隐私保护不完善的担忧，因为共享的特征嵌入可能在隐私攻击下泄露敏感信息。本文研究了VFL在差分隐私（DP）下数据隐私和任务效用目标之间的微妙平衡。为了解决现有技术的通用性问题，本文提出了一种灵活且通用的方法，将这两个目标分解并逐步解决。具体而言，我们首先通过对共享特征嵌入应用范数剪裁，得到了严格的隐私保证，该方法适用于各种数据集和模型。随后，我们证明通过对特征嵌入的尺度和分布进行自适应调整，以一种注重准确性的方式，可以优化任务效用，而不损害已建立的DP机制。我们将这一观察结果具体化为提出的VFL-AFE框架，该框架对抗了先验攻击，并显示出了有效性。

    The emergence of vertical federated learning (VFL) has stimulated concerns about the imperfection in privacy protection, as shared feature embeddings may reveal sensitive information under privacy attacks. This paper studies the delicate equilibrium between data privacy and task utility goals of VFL under differential privacy (DP). To address the generality issue of prior arts, this paper advocates a flexible and generic approach that decouples the two goals and addresses them successively. Specifically, we initially derive a rigorous privacy guarantee by applying norm clipping on shared feature embeddings, which is applicable across various datasets and models. Subsequently, we demonstrate that task utility can be optimized via adaptive adjustments on the scale and distribution of feature embeddings in an accuracy-appreciative way, without compromising established DP mechanisms. We concretize our observation into the proposed VFL-AFE framework, which exhibits effectiveness against pri
    
[^22]: Text2KGBench：一种从文本生成本体驱动的知识图谱的基准测试

    Text2KGBench: A Benchmark for Ontology-Driven Knowledge Graph Generation from Text. (arXiv:2308.02357v1 [cs.CL])

    [http://arxiv.org/abs/2308.02357](http://arxiv.org/abs/2308.02357)

    Text2KGBench是一种用于评估语言模型根据本体从自然语言文本中生成知识图谱的能力的基准测试工具，在两个数据集上通过七个评估指标来衡量事实提取的性能。

    

    近年来，大型语言模型(LLM)和具有新兴能力的基础模型的进展已经证明可以改善许多自然语言处理任务的性能。LLM和知识图谱(KG)可以相互补充，LLM可以用于KG的构建或补全，而现有的KG可以用于不同的任务，例如使LLM的输出更易解释或进行类脑符号化的事实检查。本文提出了Text2KGBench，一种用于评估语言模型根据本体从自然语言文本中生成知识图谱的能力的基准测试。给定一个输入本体和一组句子，任务是从文本中提取事实，同时符合给定的本体(概念、关系、域/值范围约束)并忠实于输入句子。我们提供了两个数据集：(i)具有10个本体和13,474个句子的Wikidata-TekGen和(ii)具有19个本体和4,860个句子的DBpedia-WebNLG。我们定义了七个评估指标来衡量事实提取的性能。

    The recent advances in large language models (LLM) and foundation models with emergent capabilities have been shown to improve the performance of many NLP tasks. LLMs and Knowledge Graphs (KG) can complement each other such that LLMs can be used for KG construction or completion while existing KGs can be used for different tasks such as making LLM outputs explainable or fact-checking in Neuro-Symbolic manner. In this paper, we present Text2KGBench, a benchmark to evaluate the capabilities of language models to generate KGs from natural language text guided by an ontology. Given an input ontology and a set of sentences, the task is to extract facts from the text while complying with the given ontology (concepts, relations, domain/range constraints) and being faithful to the input sentences. We provide two datasets (i) Wikidata-TekGen with 10 ontologies and 13,474 sentences and (ii) DBpedia-WebNLG with 19 ontologies and 4,860 sentences. We define seven evaluation metrics to measure fact 
    
[^23]: 适应变化：在动态数据环境中的强韧因果解释

    Adapting to Change: Robust Counterfactual Explanations in Dynamic Data Landscapes. (arXiv:2308.02353v1 [cs.LG])

    [http://arxiv.org/abs/2308.02353](http://arxiv.org/abs/2308.02353)

    这项研究介绍了一种新颖的半监督图形因果解释器 (DyGRACE)，它通过学习数据表示并利用已知数据分布的初始知识，在动态数据环境中搜索有效的因果解释。该方法独立于底层预测模型。

    

    我们引入了一种新颖的半监督图形因果解释器 (GCE) 方法，称为动态图形因果解释器 (DyGRACE)。它利用已知数据分布的初始知识，在搜索有效的因果解释时避免使用潜在过时的决策函数的信息。DyGRACE利用两个图形自编码器 (GAE) 来学习二元分类问题中每个类的表示。GAE通过在训练过程中最小化原始图形与其学习表示之间的重建误差。该方法包括 (i) 通过最大化事实自编码器的重建误差来优化参数化密度函数 (实现为逻辑回归函数) ，以识别因果解释，(ii) 最小化因果自编码器的误差，(iii) 最大化事实图形与因果图形之间的相似性。这种半监督方法独立于基础黑盒预测模型。

    We introduce a novel semi-supervised Graph Counterfactual Explainer (GCE) methodology, Dynamic GRAph Counterfactual Explainer (DyGRACE). It leverages initial knowledge about the data distribution to search for valid counterfactuals while avoiding using information from potentially outdated decision functions in subsequent time steps. Employing two graph autoencoders (GAEs), DyGRACE learns the representation of each class in a binary classification scenario. The GAEs minimise the reconstruction error between the original graph and its learned representation during training. The method involves (i) optimising a parametric density function (implemented as a logistic regression function) to identify counterfactuals by maximising the factual autoencoder's reconstruction error, (ii) minimising the counterfactual autoencoder's error, and (iii) maximising the similarity between the factual and counterfactual graphs. This semi-supervised approach is independent of an underlying black-box oracle
    
[^24]: RAHNet: 检索增强型混合网络用于长尾图分类

    RAHNet: Retrieval Augmented Hybrid Network for Long-tailed Graph Classification. (arXiv:2308.02335v1 [cs.LG])

    [http://arxiv.org/abs/2308.02335](http://arxiv.org/abs/2308.02335)

    我们提出了一种检索增强型混合网络(RAHNet)用于长尾图分类任务，通过联合学习稳健的特征提取器和无偏的分类器，解决了图神经网络在长尾类别分布下的偏差和泛化能力有限的问题。

    

    图分类是许多实际多媒体应用中的关键任务，图可以表示各种多媒体数据类型，如图像、视频和社交网络。以往的研究在平衡的情况下应用图神经网络(GNN)，其中类分布是平衡的。然而，实际数据通常呈现出长尾类别分布，导致在使用GNN时对头部类别存在偏差，且对尾部类别的泛化能力有限。最近的方法主要集中在模型训练过程中重新平衡不同的类别，但这种方法未能明确引入新知识，并牺牲了头部类别的性能。为了解决这些缺点，我们提出了一种新的框架，称为检索增强型混合网络(RAHNet)，以分离的方式联合学习稳健的特征提取器和无偏的分类器。在特征提取器训练阶段，我们开发了一个图检索模块来搜索相关图形。

    Graph classification is a crucial task in many real-world multimedia applications, where graphs can represent various multimedia data types such as images, videos, and social networks. Previous efforts have applied graph neural networks (GNNs) in balanced situations where the class distribution is balanced. However, real-world data typically exhibit long-tailed class distributions, resulting in a bias towards the head classes when using GNNs and limited generalization ability over the tail classes. Recent approaches mainly focus on re-balancing different classes during model training, which fails to explicitly introduce new knowledge and sacrifices the performance of the head classes. To address these drawbacks, we propose a novel framework called Retrieval Augmented Hybrid Network (RAHNet) to jointly learn a robust feature extractor and an unbiased classifier in a decoupled manner. In the feature extractor training stage, we develop a graph retrieval module to search for relevant grap
    
[^25]: 一种可控的合作创作代理用于游戏系统设计

    A Controllable Co-Creative Agent for Game System Design. (arXiv:2308.02317v1 [cs.AI])

    [http://arxiv.org/abs/2308.02317](http://arxiv.org/abs/2308.02317)

    这项研究通过创建一个可控的合作创作代理，改善了游戏系统设计中合作创作的局限性，使其适用于任何类型的游戏，并解决了人类设计师的创造力问题。

    

    在游戏中，程序化内容生成取得了许多进展，并且通过混合倡议合作，对人类设计师具有巨大的潜力。然而，用于游戏生成的合作创作系统通常局限于特定的类型、规则或游戏，限制了设计师的创造力。我们希望对游戏进行足够抽象的建模，以适用于任何类型的游戏，并重点关注游戏系统和机制的设计，并创建一个可控的合作创作代理来共同设计这些游戏。我们提出了使用类似状态机的组件和资源流的游戏模型，一组可控的度量标准，使用这些度量标准进行模拟游玩的设计评估器，以及进化设计平衡器和生成器。我们发现这个系统能够表达广泛的游戏，并且可以为未来的合作创作应用提供人类可控性。

    Many advancements have been made in procedural content generation for games, and with mixed-initiative co-creativity, have the potential for great benefits to human designers. However, co-creative systems for game generation are typically limited to specific genres, rules, or games, limiting the creativity of the designer. We seek to model games abstractly enough to apply to any genre, focusing on designing game systems and mechanics, and create a controllable, co-creative agent that can collaborate on these designs. We present a model of games using state-machine-like components and resource flows, a set of controllable metrics, a design evaluator simulating playthroughs with these metrics, and an evolutionary design balancer and generator. We find this system to be both able to express a wide range of games and able to be human-controllable for future co-creative applications.
    
[^26]: 谁回答的更好？对ChatGPT和Stack Overflow回答软件工程问题进行深入分析

    Who Answers It Better? An In-Depth Analysis of ChatGPT and Stack Overflow Answers to Software Engineering Questions. (arXiv:2308.02312v1 [cs.SE])

    [http://arxiv.org/abs/2308.02312](http://arxiv.org/abs/2308.02312)

    本研究深入分析了ChatGPT和Stack Overflow回答软件工程问题的特点和可用性。结果显示，ChatGPT回答中有52%错误，77%冗长，但由于其综合性和清晰的语言表达，仍然在39.34%的情况下被使用者偏好选择。

    

    Q&A平台在过去十年中一直是程序员网上求助行为的重要组成部分。然而，随着ChatGPT的推出，网上求助行为的范式正在发生变化。尽管ChatGPT很受欢迎，但尚未进行全面的研究来评估ChatGPT回答软件工程问题的特点或可用性。为了填补这个空白，我们对ChatGPT回答517个Stack Overflow（SO）问题进行了首次深入分析，并对ChatGPT回答的正确性、一致性、综合性和简洁性进行了检查。此外，我们进行了大规模的语言分析和用户研究，以了解ChatGPT回答在语言和人类方面的特点。我们的分析表明，52％的ChatGPT回答是错误的，77％的回答冗长。尽管如此，由于其综合性和清晰的语言表达，ChatGPT回答仍然在39.34％的情况下受到青睐。

    Q&A platforms have been an integral part of the web-help-seeking behavior of programmers over the past decade. However, with the recent introduction of ChatGPT, the paradigm of web-help-seeking behavior is experiencing a shift. Despite the popularity of ChatGPT, no comprehensive study has been conducted to evaluate the characteristics or usability of ChatGPT's answers to software engineering questions. To bridge the gap, we conducted the first in-depth analysis of ChatGPT's answers to 517 Stack Overflow (SO) questions and examined the correctness, consistency, comprehensiveness, and conciseness of ChatGPT's answers. Furthermore, we conducted a large-scale linguistic analysis, and a user study to understand the characteristics of ChatGPT answers from linguistic and human aspects. Our analysis shows that 52\% of ChatGPT answers are incorrect and 77\% are verbose. Nonetheless, ChatGPT answers are still preferred 39.34\% of the time due to their comprehensiveness and well-articulated langu
    
[^27]: 学习选择会话问答中相关的历史对话转折点

    Learning to Select the Relevant History Turns in Conversational Question Answering. (arXiv:2308.02294v1 [cs.CL])

    [http://arxiv.org/abs/2308.02294](http://arxiv.org/abs/2308.02294)

    这篇论文提出了一个名为DHS-ConvQA的框架，用于在会话式问答中动态选择相关的历史转折点，以指导答案的准确预测。

    

    对于基于网络的数字助手的日益需求，引起了信息检索(IR)社区对会话式问答(ConvQA)领域的兴趣。然而，ConvQA的一个关键方面是有效选择会话历史转折点以回答当前问题。相关历史选择与正确答案预测之间的依赖关系是一个有趣但未被充分探索的领域。选择的相关上下文可以更好地指导系统在文章中寻找答案的确切位置。而不相关的上下文则给系统带来噪音，从而导致模型性能下降。本文提出了一个框架DHS-ConvQA（会话问答中的动态历史选择），首先为所有历史转折点生成上下文和问题实体，然后根据它们与问题的相似度进行修剪。

    The increasing demand for the web-based digital assistants has given a rapid rise in the interest of the Information Retrieval (IR) community towards the field of conversational question answering (ConvQA). However, one of the critical aspects of ConvQA is the effective selection of conversational history turns to answer the question at hand. The dependency between relevant history selection and correct answer prediction is an intriguing but under-explored area. The selected relevant context can better guide the system so as to where exactly in the passage to look for an answer. Irrelevant context, on the other hand, brings noise to the system, thereby resulting in a decline in the model's performance. In this paper, we propose a framework, DHS-ConvQA (Dynamic History Selection in Conversational Question Answering), that first generates the context and question entities for all the history turns, which are then pruned on the basis of similarity they share in common with the question at
    
[^28]: 用正则化高阶总变差的随机优化方法训练非线性神经网络

    A stochastic optimization approach to train non-linear neural networks with regularization of higher-order total variation. (arXiv:2308.02293v1 [stat.ME])

    [http://arxiv.org/abs/2308.02293](http://arxiv.org/abs/2308.02293)

    通过引入高阶总变差正则化的随机优化算法，可以高效地训练非线性神经网络，避免过拟合问题。

    

    尽管包括深度神经网络在内的高度表达的参数模型可以更好地建模复杂概念，但训练这种高度非线性模型已知会导致严重的过拟合风险。针对这个问题，本研究考虑了一种k阶总变差（k-TV）正则化，它被定义为要训练的参数模型的k阶导数的平方积分，通过惩罚k-TV来产生一个更平滑的函数，从而避免过拟合。尽管将k-TV项应用于一般的参数模型由于积分而导致计算复杂，本研究提供了一种随机优化算法，可以高效地训练带有k-TV正则化的一般模型，而无需进行显式的数值积分。这种方法可以应用于结构任意的深度神经网络的训练，因为它只需要进行简单的随机梯度优化即可实现。

    While highly expressive parametric models including deep neural networks have an advantage to model complicated concepts, training such highly non-linear models is known to yield a high risk of notorious overfitting. To address this issue, this study considers a $k$th order total variation ($k$-TV) regularization, which is defined as the squared integral of the $k$th order derivative of the parametric models to be trained; penalizing the $k$-TV is expected to yield a smoother function, which is expected to avoid overfitting. While the $k$-TV terms applied to general parametric models are computationally intractable due to the integration, this study provides a stochastic optimization algorithm, that can efficiently train general models with the $k$-TV regularization without conducting explicit numerical integration. The proposed approach can be applied to the training of even deep neural networks whose structure is arbitrary, as it can be implemented by only a simple stochastic gradien
    
[^29]: 通过虚拟风险最小化实现令人沮丧的模型泛化

    Frustratingly Easy Model Generalization by Dummy Risk Minimization. (arXiv:2308.02287v1 [cs.LG])

    [http://arxiv.org/abs/2308.02287](http://arxiv.org/abs/2308.02287)

    通过虚拟风险最小化，本文提出了一种令人沮丧地简单且通用的技术（DuRM），能够显著改善经验风险最小化（ERM）的泛化能力。通过理论和经验验证，我们展示了DuRM可以通过增加梯度的方差来促进模型的泛化效果，并在不同任务和数据集上进行的实验证明了DuRM的有效性。

    

    经验风险最小化（ERM）是机器学习中的一个基本范例。然而，在各种任务中，它的泛化能力有限。在本文中，我们设计了虚拟风险最小化（DuRM），一种令人沮丧地简单和通用的技术来提高ERM的泛化能力。DuRM非常简单实现：只需扩大输出logits的维度，然后使用标准梯度下降进行优化。此外，我们通过理论和经验验证DuRM的有效性。从理论上讲，我们展示了DuRM导致更大的梯度方差，通过观察更好的平坦局部最小值促进模型泛化。从经验上讲，我们针对不同的数据集，模态和网络架构，在不同的任务上进行了DuRM的评估，包括传统分类，语义分割，超出分布泛化，对抗训练和长尾识别。结果表明，DuRM能够持续改进模型的泛化能力。

    Empirical risk minimization (ERM) is a fundamental machine learning paradigm. However, its generalization ability is limited in various tasks. In this paper, we devise Dummy Risk Minimization (DuRM), a frustratingly easy and general technique to improve the generalization of ERM. DuRM is extremely simple to implement: just enlarging the dimension of the output logits and then optimizing using standard gradient descent. Moreover, we validate the efficacy of DuRM on both theoretical and empirical analysis. Theoretically, we show that DuRM derives greater variance of the gradient, which facilitates model generalization by observing better flat local minima. Empirically, we conduct evaluations of DuRM across different datasets, modalities, and network architectures on diverse tasks, including conventional classification, semantic segmentation, out-of-distribution generalization, adverserial training, and long-tailed recognition. Results demonstrate that DuRM could consistently improve the 
    
[^30]: DIVERSIFY: 一般化时间序列离群检测和推广的通用框架

    DIVERSIFY: A General Framework for Time Series Out-of-distribution Detection and Generalization. (arXiv:2308.02282v1 [cs.LG])

    [http://arxiv.org/abs/2308.02282](http://arxiv.org/abs/2308.02282)

    DIVERSIFY是一个通用框架，用于解决时间序列离群检测和推广的挑战，通过利用数据集中的子域来对抗时间序列的非平稳性，并通过迭代过程减小潜在分布之间的差距。

    

    时间序列仍然是机器学习研究中最具挑战性的模态之一。由于其非平稳性质，时间序列的离群检测和推广往往受到困扰，即分布随时间变化。时间序列中的动态分布给现有算法带来了很大的挑战，因为它们主要关注领域信息已知的情况。本文尝试利用数据集中的子域来对抗非平稳性引发的问题，实现广义表示学习。我们提出了DIVERSIFY，一个针对动态时间序列分布的离群检测和推广的通用框架。DIVERSIFY采用迭代过程：首先通过对抗训练获得“最坏情况”潜在分布情景，然后减小这些潜在分布之间的差距。我们通过结合现有的离群检测方法实现了DIVERSIFY。

    Time series remains one of the most challenging modalities in machine learning research. The out-of-distribution (OOD) detection and generalization on time series tend to suffer due to its non-stationary property, i.e., the distribution changes over time. The dynamic distributions inside time series pose great challenges to existing algorithms to identify invariant distributions since they mainly focus on the scenario where the domain information is given as prior knowledge. In this paper, we attempt to exploit subdomains within a whole dataset to counteract issues induced by non-stationary for generalized representation learning. We propose DIVERSIFY, a general framework, for OOD detection and generalization on dynamic distributions of time series. DIVERSIFY takes an iterative process: it first obtains the "worst-case" latent distribution scenario via adversarial training, then reduces the gap between these latent distributions. We implement DIVERSIFY via combining existing OOD detect
    
[^31]: DTF-Net: 基于可变形模板场的物体类别级姿态估计和形状重建

    DTF-Net: Category-Level Pose Estimation and Shape Reconstruction via Deformable Template Field. (arXiv:2308.02239v1 [cs.CV])

    [http://arxiv.org/abs/2308.02239](http://arxiv.org/abs/2308.02239)

    DTF-Net是一种基于隐式神经场的姿态估计和形状重建框架，通过设计可变形模板场来捕捉物体类别的形状特征和几何变形特征。

    

    在RGB-深度图像对中估计物体的六维姿态和重建三维形状是具有挑战性的。许多现有方法依赖于学习与特定模板对应的几何特征，而忽视了同一类别中物体的形状变化和姿态差异。因此，这些方法在处理复杂环境中的未见过的物体实例时性能不佳。相反，其他方法通过利用归一化的几何结构先验来实现类别级估计和重建，但基于静态先验的重建在类内变化大的情况下面临困难。为解决这些问题，我们提出了DTF-Net，一种基于物体类别的隐式神经场的姿态估计和形状重建新框架。在DTF-Net中，我们设计了一个可变形模板场，用于表示通用的类别形状潜在特征和类内几何变形特征。

    Estimating 6D poses and reconstructing 3D shapes of objects in open-world scenes from RGB-depth image pairs is challenging. Many existing methods rely on learning geometric features that correspond to specific templates while disregarding shape variations and pose differences among objects in the same category. As a result, these methods underperform when handling unseen object instances in complex environments. In contrast, other approaches aim to achieve category-level estimation and reconstruction by leveraging normalized geometric structure priors, but the static prior-based reconstruction struggles with substantial intra-class variations. To solve these problems, we propose the DTF-Net, a novel framework for pose estimation and shape reconstruction based on implicit neural fields of object categories. In DTF-Net, we design a deformable template field to represent the general category-wise shape latent features and intra-category geometric deformation features. The field establishe
    
[^32]: 我们应该相信网络抓取的数据吗？

    Should we trust web-scraped data?. (arXiv:2308.02231v1 [econ.GN])

    [http://arxiv.org/abs/2308.02231](http://arxiv.org/abs/2308.02231)

    本论文指出天真的网络抓取程序可能导致收集数据中的抽样偏差，并描述了来源于网络内容易变性、个性化和未索引的抽样偏差。通过例子说明了抽样偏差的普遍性和程度，并提供了克服抽样偏差的建议。

    

    实证研究人员越来越多地采用计量经济学和机器学习方法，导致了对一种数据收集方法的广泛使用：网络抓取。网络抓取指的是使用自动化计算机程序访问网站并下载其内容。本文的主要论点是，天真的网络抓取程序可能会导致收集数据中的抽样偏差。本文描述了网络抓取数据中的三种抽样偏差来源。更具体地说，抽样偏差源于网络内容的易变性（即可能发生变化）、个性化（即根据请求特征呈现）和未索引（即人口登记簿的丰富性）。通过一系列例子，我说明了抽样偏差的普遍性和程度。为了支持研究人员和审稿人，本文提供了关于对网络抓取数据的抽样偏差进行预期、检测和克服的建议。

    The increasing adoption of econometric and machine-learning approaches by empirical researchers has led to a widespread use of one data collection method: web scraping. Web scraping refers to the use of automated computer programs to access websites and download their content. The key argument of this paper is that na\"ive web scraping procedures can lead to sampling bias in the collected data. This article describes three sources of sampling bias in web-scraped data. More specifically, sampling bias emerges from web content being volatile (i.e., being subject to change), personalized (i.e., presented in response to request characteristics), and unindexed (i.e., abundance of a population register). In a series of examples, I illustrate the prevalence and magnitude of sampling bias. To support researchers and reviewers, this paper provides recommendations on anticipating, detecting, and overcoming sampling bias in web-scraped data.
    
[^33]: 联邦学习：机构机遇、挑战和采用策略

    Federated Learning: Organizational Opportunities, Challenges, and Adoption Strategies. (arXiv:2308.02219v1 [cs.CY])

    [http://arxiv.org/abs/2308.02219](http://arxiv.org/abs/2308.02219)

    本文探讨了联邦学习的技术基础和潜在应用，提出了联邦学习的采用策略框架，并指出联邦学习为商业和信息系统工程学界提供了跨学科研究机会。

    

    在许多行业中，数据共享的限制性规则导致联邦学习的发展。联邦学习是一种机器学习技术，允许分布式客户端合作训练模型，而无需与他人共享其各自的训练数据。本文首先探讨了联邦学习的技术基础和潜在应用。其次，我们提出了一个用于采用联邦学习的概念框架，将组织按照其人工智能能力和环境进行了映射。然后，我们讨论了为什么不同行业的典型组织，包括行业联盟、建立银行、公共机构和数据密集型中小企业可能考虑不同的联邦学习方法。最后，我们认为联邦学习为商业和信息系统工程学界提供了充满跨学科研究机会的机构转变。

    Restrictive rules for data sharing in many industries have led to the development of \ac{FL}. \ac{FL} is a \ac{ML} technique that allows distributed clients to train models collaboratively without the need to share their respective training data with others. In this article, we first explore the technical basics of FL and its potential applications. Second, we present a conceptual framework for the adoption of \ac{FL}, mapping organizations along the lines of their \ac{AI} capabilities and environment. We then discuss why exemplary organizations in different industries, including industry consortia, established banks, public authorities, and data-intensive SMEs might consider different approaches to \ac{FL}. To conclude, we argue that \ac{FL} presents an institutional shift with ample interdisciplinary research opportunities for the business and information systems engineering community.
    
[^34]: 个性化生成式推荐的个性化提示-模型检索方法

    Towards Personalized Prompt-Model Retrieval for Generative Recommendation. (arXiv:2308.02205v1 [cs.IR])

    [http://arxiv.org/abs/2308.02205](http://arxiv.org/abs/2308.02205)

    该论文提出了一个个性化提示-模型检索的方法，以实现个性化的生成式推荐任务。通过GEMRec-18K数据集的研究，作者设计了一个两阶段的框架，分别是提示-模型检索和生成项排序，以解决这一新任务的挑战。

    

    推荐系统旨在检索与用户信息需求相关的内容。现有的候选库通常由一组已准备好的项组成，如视频、产品或文章。随着生成式AI如GPT和Diffusion模型的近期进展，还有一种新形式的推荐任务待探索，即通过个性化提示由生成模型创建项。以图像生成为例，凭借用户的单个提示和生成模型的访问权限，在几分钟内可以生成数百个新图像。在“无限”项的存在下，我们如何实现个性化？在这项初步研究中，我们提出了一个两阶段的框架，即提示-模型检索和生成项排序，来解决这个新的任务形式。我们发布了一个名为GEMRec-18K的数据集，其中包含由200个公开可用的生成模型生成的18K图像，并与一套多样化的90个文本提示相配对。

    Recommender Systems are built to retrieve relevant items to satisfy users' information needs. The candidate corpus usually consists of a finite set of items that are ready to be served, such as videos, products, or articles. With recent advances in Generative AI such as GPT and Diffusion models, a new form of recommendation task is yet to be explored where items are to be created by generative models with personalized prompts. Taking image generation as an example, with a single prompt from the user and access to a generative model, it is possible to generate hundreds of new images in a few minutes. How shall we attain personalization in the presence of "infinite" items? In this preliminary study, we propose a two-stage framework, namely Prompt-Model Retrieval and Generated Item Ranking, to approach this new task formulation. We release GEMRec-18K, a prompt-model interaction dataset with 18K images generated by 200 publicly-available generative models paired with a diverse set of 90 te
    
[^35]: 西班牙临床语言模型调查

    A Survey of Spanish Clinical Language Models. (arXiv:2308.02199v1 [cs.CL])

    [http://arxiv.org/abs/2308.02199](http://arxiv.org/abs/2308.02199)

    这项调查研究了西班牙语临床语言模型的应用，回顾了17个专注于临床任务的语料库的贡献，并对最相关的西班牙语语言模型和西班牙临床语言模型进行了彻底比较，提供了3000多个进行微调的模型。为了便于未来的研究和挑战，所有测试过的语料库和最佳模型都被以可访问的方式公开。

    

    本调查聚焦于使用编码器语言模型来解决西班牙语临床领域任务的问题。我们回顾了17个主要专注于临床任务的语料库的贡献，然后列出了最相关的西班牙语语言模型和西班牙临床语言模型。我们通过对可用语料库的精选子集进行基准测试，对这些模型进行了彻底的比较，以找到表现最佳的模型；总共超过3000个模型被针对这项研究进行了微调。所有测试的语料库和最佳模型都以可访问的方式公开，以便独立团队可以重现结果或在未来创建新的西班牙临床语言模型时进行挑战。

    This survey focuses in encoder Language Models for solving tasks in the clinical domain in the Spanish language. We review the contributions of 17 corpora focused mainly in clinical tasks, then list the most relevant Spanish Language Models and Spanish Clinical Language models. We perform a thorough comparison of these models by benchmarking them over a curated subset of the available corpora, in order to find the best-performing ones; in total more than 3000 models were fine-tuned for this study. All the tested corpora and the best models are made publically available in an accessible way, so that the results can be reproduced by independent teams or challenged in the future when new Spanish Clinical Language models are created.
    
[^36]: 用语义范围解释关系分类模型

    Explaining Relation Classification Models with Semantic Extents. (arXiv:2308.02193v1 [cs.CL])

    [http://arxiv.org/abs/2308.02193](http://arxiv.org/abs/2308.02193)

    本研究提出了一种解释关系分类模型的方法，即使用语义范围分析模型的决策模式。语义范围是关于分类决策的文本中最有影响力的部分。通过将人类和模型的语义范围进行比较，发现模型往往从数据中学习到了快捷模式。

    

    近年来，大规模预训练语言模型（如BERT和GPT）的发展显著改进了各种任务中的信息抽取系统，包括关系分类。最先进的系统在科学基准上具有很高的准确性。目前，缺乏可解释性是许多真实世界应用中的一个复杂因素。可理解的系统对于防止有偏见、违反直觉或有害的决策是必要的。我们引入了一种分析关系分类任务决策模式的概念，即语义范围。语义范围是关于分类决策的文本中最有影响力的部分。我们的定义允许类似的过程来确定人类和模型的语义范围。我们提供了一个注释工具和一个软件框架，以便方便、可重复地确定人类和模型的语义范围。比较两者发现，模型往往从数据中学习到了快捷模式。这些模式很难被人类解释或理解。

    In recent years, the development of large pretrained language models, such as BERT and GPT, significantly improved information extraction systems on various tasks, including relation classification. State-of-the-art systems are highly accurate on scientific benchmarks. A lack of explainability is currently a complicating factor in many real-world applications. Comprehensible systems are necessary to prevent biased, counterintuitive, or harmful decisions.  We introduce semantic extents, a concept to analyze decision patterns for the relation classification task. Semantic extents are the most influential parts of texts concerning classification decisions. Our definition allows similar procedures to determine semantic extents for humans and models. We provide an annotation tool and a software framework to determine semantic extents for humans and models conveniently and reproducibly. Comparing both reveals that models tend to learn shortcut patterns from data. These patterns are hard to d
    
[^37]: AutoML4ETC: 自动化神经架构搜索实现现实世界加密流量分类

    AutoML4ETC: Automated Neural Architecture Search for Real-World Encrypted Traffic Classification. (arXiv:2308.02182v1 [cs.NI])

    [http://arxiv.org/abs/2308.02182](http://arxiv.org/abs/2308.02182)

    AutoML4ETC是一个自动设计高效且高性能神经架构的工具，用于加密流量分类。其通过定义新颖的搜索空间和使用不同的搜索策略，在多个数据集上优于当前最先进的加密流量分类器。

    

    在实验环境中，深度学习（DL）已成功应用于加密网络流量分类。然而，在实际应用中，DL分类器的性能随时间不可避免地下降。仅仅对新数据集进行模型重新训练只能部分提高其性能。手动调整模型架构以满足新数据集上的性能期望耗时且需要领域专业知识。本文提出了一种新颖的工具AutoML4ETC，用于自动设计高效且高性能的神经架构以进行加密流量分类。我们定义了一个新颖而强大的搜索空间，专门针对使用数据包头字节进行近实时加密流量分类。通过在搜索空间上使用不同的搜索策略，我们展示了AutoML4ETC生成的神经架构在多个数据集上均优于当前最先进的加密流量分类器，包括公共基准数据集。

    Deep learning (DL) has been successfully applied to encrypted network traffic classification in experimental settings. However, in production use, it has been shown that a DL classifier's performance inevitably decays over time. Re-training the model on newer datasets has been shown to only partially improve its performance. Manually re-tuning the model architecture to meet the performance expectations on newer datasets is time-consuming and requires domain expertise. We propose AutoML4ETC, a novel tool to automatically design efficient and high-performing neural architectures for encrypted traffic classification. We define a novel, powerful search space tailored specifically for the near real-time classification of encrypted traffic using packet header bytes. We show that with different search strategies over our search space, AutoML4ETC generates neural architectures that outperform the state-of-the-art encrypted traffic classifiers on several datasets, including public benchmark dat
    
[^38]: Retroformer：使用策略梯度优化的回顾性大型语言代理

    Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization. (arXiv:2308.02151v1 [cs.CL])

    [http://arxiv.org/abs/2308.02151](http://arxiv.org/abs/2308.02151)

    本文介绍了一种通过策略梯度优化的回顾性大型语言代理框架，该框架通过学习环境反馈来调整语言代理的提示，从而优化其性能。这种代理能够从多个环境和任务中学习奖励，并通过总结以前任务的根本原因来改进语言代理提示。

    

    最近几个月，出现了一个强大的新趋势，即将大型语言模型（LLMs）增强成能够自主完成目标导向多步骤任务的语言代理，而不仅仅是回答人类用户的查询。然而，大多数现有的语言代理没有使用环境特定的奖励进行优化。尽管一些代理通过口头反馈实现了迭代改进，但它们不能以与基于梯度的奖励学习相兼容的方式进行推理和规划。本文提出了一个原则性的框架，通过学习回顾模型，通过策略梯度自动调整语言代理的提示，从环境反馈中优化代理的工作。具体而言，我们提出的代理架构通过学习多个环境和任务的奖励来微调预训练语言模型，从而通过总结以前任务的根本原因来改进语言代理提示。

    Recent months have seen the emergence of a powerful new trend in which large language models (LLMs) are augmented to become autonomous language agents capable of performing objective oriented multi-step tasks on their own, rather than merely responding to queries from human users. Most existing language agents, however, are not optimized using environment-specific rewards. Although some agents enable iterative refinement through verbal feedback, they do not reason and plan in ways that are compatible with gradient-based learning from rewards. This paper introduces a principled framework for reinforcing large language agents by learning a retrospective model, which automatically tunes the language agent prompts from environment feedback through policy gradient. Specifically, our proposed agent architecture learns from rewards across multiple environments and tasks, for fine-tuning a pre-trained language model which refines the language agent prompt by summarizing the root cause of prior
    
[^39]: 基于语义引导的基于Transformer的传感器融合方法改进航点预测

    Semantics-guided Transformer-based Sensor Fusion for Improved Waypoint Prediction. (arXiv:2308.02126v1 [cs.RO])

    [http://arxiv.org/abs/2308.02126](http://arxiv.org/abs/2308.02126)

    该论文提出一种基于语义引导的传感器融合方法，通过融合多个传感器的特征和使用辅助任务来改进自动驾驶代理的航点预测。

    

    对于智能自动驾驶代理来说，传感器融合方法仍然是驾驶场景理解的关键，通过从输入传感器获取的视觉全局环境。具体而言，对于局部航点预测任务，单模态网络仍然受限于对输入传感器的灵敏度的强依赖性，因此最近的工作推广了在特征级别上融合多个传感器的使用。虽然众所周知多个数据模态能促进相互的上下文交互，但在实际驾驶场景中实时进行全局三维场景理解并进行最小计算，因此在给定有限数量的可实际使用的传感器的情况下，对训练策略的重要性更加突出。在这一背景下，我们通过融合与目标任务（如交通灯识别和语义分割）高度相关的精心选取的辅助任务特征，并使用辅助头为航点预测进行了利用。

    Sensor fusion approaches for intelligent self-driving agents remain key to driving scene understanding given visual global contexts acquired from input sensors. Specifically, for the local waypoint prediction task, single-modality networks are still limited by strong dependency on the sensitivity of the input sensor, and thus recent works promote the use of multiple sensors in fusion in feature level. While it is well known that multiple data modalities promote mutual contextual exchange, deployment to practical driving scenarios requires global 3D scene understanding in real-time with minimal computations, thus placing greater significance on training strategies given a limited number of practically usable sensors. In this light, we exploit carefully selected auxiliary tasks that are highly correlated with the target task of interest (e.g., traffic light recognition and semantic segmentation) by fusing auxiliary task features and also using auxiliary heads for waypoint prediction base
    
[^40]: 通过模型DNA的模型来源证明

    Model Provenance via Model DNA. (arXiv:2308.02121v1 [cs.LG])

    [http://arxiv.org/abs/2308.02121](http://arxiv.org/abs/2308.02121)

    本文介绍了模型来源证明的新概念模型DNA，通过编码模型的训练数据和输入输出信息作为紧凑全面的表示，来确定源模型是否作为目标模型的来源证明。

    

    了解机器学习（ML）模型的生命周期是一个有趣的研究领域（例如，了解模型的来源，训练方式以及使用方式）。本文聚焦于这一领域内的一个新问题，即模型来源证明（MP），该问题涉及目标模型与其预训练模型之间的关系，并旨在确定一个源模型是否作为目标模型的来源证明。这是一个重要的问题，对于确保机器学习模型的安全性和知识产权具有重要意义，但在文献中并没有得到很多关注。为了填补这一空白，我们引入了一个新概念，即模型DNA，它代表了机器学习模型的独特特征。我们利用数据驱动和模型驱动的表示学习方法，将模型的训练数据和输入输出信息编码为模型的紧凑且全面的表示（即DNA）。

    Understanding the life cycle of the machine learning (ML) model is an intriguing area of research (e.g., understanding where the model comes from, how it is trained, and how it is used). This paper focuses on a novel problem within this field, namely Model Provenance (MP), which concerns the relationship between a target model and its pre-training model and aims to determine whether a source model serves as the provenance for a target model. This is an important problem that has significant implications for ensuring the security and intellectual property of machine learning models but has not received much attention in the literature. To fill in this gap, we introduce a novel concept of Model DNA which represents the unique characteristics of a machine learning model. We utilize a data-driven and model-driven representation learning method to encode the model's training data and input-output information as a compact and comprehensive representation (i.e., DNA) of the model. Using this 
    
[^41]: VQGraph: 图形向量量化用于连接GNN和MLPs

    VQGraph: Graph Vector-Quantization for Bridging GNNs and MLPs. (arXiv:2308.02117v1 [cs.LG])

    [http://arxiv.org/abs/2308.02117](http://arxiv.org/abs/2308.02117)

    VQGraph是一个框架，通过学习一个强大的图形表示空间，用于连接GNN和MLPs。它采用矢量量化变分自编码器（VQ-VAE）的编码器作为结构感知图标记器，有效地表示底层图的多样化局部结构。通过 VQGraph，可以实现从GNN到MLP的知识转移。

    

    图神经网络（GNNs）进行信息传递，聚合局部邻居以更新节点表示。这种信息传递导致在实际的延迟约束应用程序中存在可扩展性问题。为了解决这个问题，最近的方法采用知识蒸馏（KD）通过模仿GNN的输出来学习计算效率高的多层感知机（MLP）。然而，现有的GNN表示空间可能不足以表示底层图的多样化局部结构，这限制了从GNN到MLP的知识转移。在这里，我们提出了一个新颖的框架VQGraph，用于学习一个强大的图形表示空间，用于连接GNN和MLPs。我们采用一种变体的矢量量化变分自编码器（VQ-VAE）的编码器作为结构感知图标记器，它将多样化的局部结构节点明确表示为大量离散令牌，并构成一个有意义的代码书。配备了学习的代码书，我们提出

    Graph Neural Networks (GNNs) conduct message passing which aggregates local neighbors to update node representations. Such message passing leads to scalability issues in practical latency-constrained applications. To address this issue, recent methods adopt knowledge distillation (KD) to learn computationally-efficient multi-layer perceptron (MLP) by mimicking the output of GNN. However, the existing GNN representation space may not be expressive enough for representing diverse local structures of the underlying graph, which limits the knowledge transfer from GNN to MLP. Here we present a novel framework VQGraph to learn a powerful graph representation space for bridging GNNs and MLPs. We adopt the encoder of a variant of a vector-quantized variational autoencoder (VQ-VAE) as a structure-aware graph tokenizer, which explicitly represents the nodes of diverse local structures as numerous discrete tokens and constitutes a meaningful codebook. Equipped with the learned codebook, we propos
    
[^42]: AdvFAS：一种针对对抗样本的强鲁棒人脸防疏松框架

    AdvFAS: A robust face anti-spoofing framework against adversarial examples. (arXiv:2308.02116v1 [cs.CV])

    [http://arxiv.org/abs/2308.02116](http://arxiv.org/abs/2308.02116)

    提出了AdvFAS框架，它利用两个耦合得分准确区分对抗攻击中的人脸图像，在不同环境下展示了高效的防御水平。

    

    确保人脸识别系统对付展示攻击的可靠性需要部署人脸反疏松技术。尽管在这个领域取得了相当大的进展，但即使是最先进的方法也很难防御对抗性样本。虽然已经提出了几种对抗性防御策略，但它们通常受限于普适性、效果和效率之间的不可避免的权衡。为了克服这些挑战，我们深入研究对抗性检测与人脸反疏松之间的关联关系。基于此，我们提出了一种强鲁棒的人脸反疏松框架，即AdvFAS，它利用两个耦合得分准确区分正确检测和错误检测的人脸图像。广泛的实验证明了我们框架在不同的攻击、数据集和骨干网络等多种环境下的有效性。

    Ensuring the reliability of face recognition systems against presentation attacks necessitates the deployment of face anti-spoofing techniques. Despite considerable advancements in this domain, the ability of even the most state-of-the-art methods to defend against adversarial examples remains elusive. While several adversarial defense strategies have been proposed, they typically suffer from constrained practicability due to inevitable trade-offs between universality, effectiveness, and efficiency. To overcome these challenges, we thoroughly delve into the coupled relationship between adversarial detection and face anti-spoofing. Based on this, we propose a robust face anti-spoofing framework, namely AdvFAS, that leverages two coupled scores to accurately distinguish between correctly detected and wrongly detected face images. Extensive experiments demonstrate the effectiveness of our framework in a variety of settings, including different attacks, datasets, and backbones, meanwhile e
    
[^43]: N-gram增强：通过规范化N-gram目标改善上下文偏差

    N-gram Boosting: Improving Contextual Biasing with Normalized N-gram Targets. (arXiv:2308.02092v1 [cs.CL])

    [http://arxiv.org/abs/2308.02092](http://arxiv.org/abs/2308.02092)

    本文提出了一种N-gram增强技术，通过规范化目标词组来改善上下文偏差，提高关键词识别率。

    

    在商务谈话的语音到文本应用中，准确转录专有名词和技术术语尤为重要。这些词对于理解对话至关重要，但往往很少出现，因此在文本和音频训练数据中很可能缺乏，这在这个领域中造成了很大的挑战。我们提出了一个两步关键词增强机制，它成功地使用规范化的单词和n-gram而不仅仅是单个标记，从而消除了关键词目标的丢失问题。此外，我们展示了如何调整增强权重逻辑以避免过度增强多个标记的关键词。在我们的专有领域数据集上，我们的关键词识别率相对提高了26％，在LibriSpeech上提高了2％。这种方法对涉及非字母字符或具有非标准发音的目标特别有用。

    Accurate transcription of proper names and technical terms is particularly important in speech-to-text applications for business conversations. These words, which are essential to understanding the conversation, are often rare and therefore likely to be under-represented in text and audio training data, creating a significant challenge in this domain. We present a two-step keyword boosting mechanism that successfully works on normalized unigrams and n-grams rather than just single tokens, which eliminates missing hits issues with boosting raw targets. In addition, we show how adjusting the boosting weight logic avoids over-boosting multi-token keywords. This improves our keyword recognition rate by 26% relative on our proprietary in-domain dataset and 2% on LibriSpeech. This method is particularly useful on targets that involve non-alphabetic characters or have non-standard pronunciations.
    
[^44]: 在边缘端的高效模型适应用于持续学习

    Efficient Model Adaptation for Continual Learning at the Edge. (arXiv:2308.02084v1 [cs.LG])

    [http://arxiv.org/abs/2308.02084](http://arxiv.org/abs/2308.02084)

    这篇论文提出了一个名为Encoder-Adaptor-Reconfigurator（EAR）框架，用于在领域漂移下进行高效的持续学习。该框架使用了固定的深度神经网络（DNN）特征编码器，并在编码器之上训练浅层网络来处理新数据。通过结合DNN和超维计算（HDC），该框架能够检测新数据是否属于分布之外（OOD），并能够识别出... (摘要内容省略)

    

    大多数机器学习系统在训练和部署过程中假设数据分布是固定和匹配的，但这通常是错误的假设。当机器学习模型部署在真实设备上时，数据分布常常会随时间变化，原因是环境因素、传感器特性和感兴趣的任务发生了变化。本文提出了一种名为Encoder-Adaptor-Reconfigurator（EAR）框架的方法，用于处理领域漂移下的高效持续学习。EAR框架利用固定的深度神经网络（DNN）特征编码器，并在编码器之上训练浅层网络来处理新数据。EAR框架能够通过将DNN与超维计算（HDC）相结合，检测出新数据是否属于分布之外（OOD），并能够识别出

    Most machine learning (ML) systems assume stationary and matching data distributions during training and deployment. This is often a false assumption. When ML models are deployed on real devices, data distributions often shift over time due to changes in environmental factors, sensor characteristics, and task-of-interest. While it is possible to have a human-in-the-loop to monitor for distribution shifts and engineer new architectures in response to these shifts, such a setup is not cost-effective. Instead, non-stationary automated ML (AutoML) models are needed. This paper presents the Encoder-Adaptor-Reconfigurator (EAR) framework for efficient continual learning under domain shifts. The EAR framework uses a fixed deep neural network (DNN) feature encoder and trains shallow networks on top of the encoder to handle novel data. The EAR framework is capable of 1) detecting when new data is out-of-distribution (OOD) by combining DNNs with hyperdimensional computing (HDC), 2) identifying l
    
[^45]: 通过使用非可学习原语的显式任务路由来减轻多任务学习中的任务干扰

    Mitigating Task Interference in Multi-Task Learning via Explicit Task Routing with Non-Learnable Primitives. (arXiv:2308.02066v1 [cs.CV])

    [http://arxiv.org/abs/2308.02066](http://arxiv.org/abs/2308.02066)

    本文提出了ETR-NLP模型来减轻多任务学习中的任务干扰，通过使用非可学习原语和显式任务路由的协同组合，在共享分支和任务特定分支中显式地分离可学习参数，以实现任务之间的最小化干扰。

    

    多任务学习（MTL）通过利用任务之间的共享信息来学习一个模型来完成多个任务。然而，现有的MTL模型已经被发现存在负面干扰问题。为了减轻任务干扰，已有的努力主要集中在损失/梯度平衡或隐式参数划分上。在本文中，我们提出了ETR-NLP来通过非可学习原语（NLP）和显式任务路由（ETR）的协同组合来减轻任务干扰。我们的关键思想是使用非可学习原语来提取一组多样化的与任务无关的特征，并将它们重新组合成一个共享于所有任务的分支和专门为每个任务保留的显式任务特定分支。非可学习原语和可学习参数的显式解耦为最小化任务干扰提供了所需的灵活性。我们评估了ETR-NLP网络的有效性。

    Multi-task learning (MTL) seeks to learn a single model to accomplish multiple tasks by leveraging shared information among the tasks. Existing MTL models, however, have been known to suffer from negative interference among tasks. Efforts to mitigate task interference have focused on either loss/gradient balancing or implicit parameter partitioning with partial overlaps among the tasks. In this paper, we propose ETR-NLP to mitigate task interference through a synergistic combination of non-learnable primitives (NLPs) and explicit task routing (ETR). Our key idea is to employ non-learnable primitives to extract a diverse set of task-agnostic features and recombine them into a shared branch common to all tasks and explicit task-specific branches reserved for each task. The non-learnable primitives and the explicit decoupling of learnable parameters into shared and task-specific ones afford the flexibility needed for minimizing task interference. We evaluate the efficacy of ETR-NLP networ
    
[^46]: 关于生成人脸模型的生物特征容量

    On the Biometric Capacity of Generative Face Models. (arXiv:2308.02065v1 [cs.CV])

    [http://arxiv.org/abs/2308.02065](http://arxiv.org/abs/2308.02065)

    这篇论文提出了一种统计方法，用于估计在超球特征空间中生成的人脸图像的生物特征容量，并在多个生成模型上进行了实证研究。

    

    在过去几年中，生成逼真面孔的进展非常大。尽管有这些进展，一个关键的问题仍然没有答案：“给定一个生成的人脸模型，它能够生成多少个独特的身份？”换句话说，生成人脸模型的生物特征容量是多少？回答这个问题的科学依据将有助于评估和比较不同的生成人脸模型，并确定它们的可扩展性的上限。本文提出了一种统计方法来估计在一个超球特征空间中生成的人脸图像的生物特征容量。我们在多个生成模型上应用了我们的方法，包括无条件生成器如StyleGAN、潜在扩散模型和“生成的照片”，以及DCF面，一个类条件生成器。我们还估计了与性别和年龄等人口属性相关的容量。我们的容量估计表明，在虚假接受条件下，使用ArcFace表示：

    There has been tremendous progress in generating realistic faces with high fidelity over the past few years. Despite this progress, a crucial question remains unanswered: "Given a generative face model, how many unique identities can it generate?" In other words, what is the biometric capacity of the generative face model? A scientific basis for answering this question will benefit evaluating and comparing different generative face models and establish an upper bound on their scalability. This paper proposes a statistical approach to estimate the biometric capacity of generated face images in a hyperspherical feature space. We employ our approach on multiple generative models, including unconditional generators like StyleGAN, Latent Diffusion Model, and "Generated Photos," as well as DCFace, a class-conditional generator. We also estimate capacity w.r.t. demographic attributes such as gender and age. Our capacity estimates indicate that (a) under ArcFace representation at a false accep
    
[^47]: 准确的神经网络剪枝需要重新思考稀疏优化

    Accurate Neural Network Pruning Requires Rethinking Sparse Optimization. (arXiv:2308.02060v1 [cs.LG])

    [http://arxiv.org/abs/2308.02060](http://arxiv.org/abs/2308.02060)

    这项工作研究了高稀疏对神经网络训练的影响，发现使用传统的密集训练策略进行稀疏训练效果不佳，提出了新的方法来解决这个问题，并在视觉和语言模型上都取得了最先进的结果。

    

    在模型压缩领域，获得既高精确又高稀疏的深度神经网络版本是一个主要挑战，社区已经对几种高性能的剪枝技术进行了研究。然而，我们对稀疏性和用于训练稀疏网络的标准随机优化技术的交互了解较少，大多数现有工作使用标准的密集训练计划和超参数来训练稀疏网络。在这项工作中，我们通过使用标准的计算机视觉和自然语言处理稀疏基准来研究高稀疏对模型训练的影响。我们首先展示了使用标准的密集训练策略进行稀疏训练是次优的，导致欠训练。我们提供了新的方法来解决这个问题，既可以用于视觉模型（如ResNet50/ImageNet）的稀疏预训练，也可以用于语言模型（如BERT/GLUE）的稀疏微调，实现了最先进的结果。

    Obtaining versions of deep neural networks that are both highly-accurate and highly-sparse is one of the main challenges in the area of model compression, and several high-performance pruning techniques have been investigated by the community. Yet, much less is known about the interaction between sparsity and the standard stochastic optimization techniques used for training sparse networks, and most existing work uses standard dense schedules and hyperparameters for training sparse networks. In this work, we examine the impact of high sparsity on model training using the standard computer vision and natural language processing sparsity benchmarks. We begin by showing that using standard dense training recipes for sparse training is suboptimal, and results in under-training. We provide new approaches for mitigating this issue for both sparse pre-training of vision models (e.g. ResNet50/ImageNet) and sparse fine-tuning of language models (e.g. BERT/GLUE), achieving state-of-the-art resul
    
[^48]: 整合鲁莽行为到基于协同过滤的推荐系统中

    Incorporating Recklessness to Collaborative Filtering based Recommender Systems. (arXiv:2308.02058v1 [cs.IR])

    [http://arxiv.org/abs/2308.02058](http://arxiv.org/abs/2308.02058)

    本文提出了一种将鲁莽行为引入基于矩阵分解的推荐系统学习过程的方法，通过控制风险水平来提高预测的数量和质量。

    

    包含可靠性测量的推荐系统往往在预测中更加保守，因为它们需要保持可靠性。这导致了这些系统可以提供的覆盖范围和新颖性的显著下降。在本文中，我们提出了在矩阵分解型推荐系统的学习过程中加入一项新的项，称为鲁莽行为，它可以控制在做出关于预测可靠性的决策时所希望的风险水平。实验结果表明，鲁莽行为不仅允许进行风险调控，还提高了推荐系统提供的预测的数量和质量。

    Recommender systems that include some reliability measure of their predictions tend to be more conservative in forecasting, due to their constraint to preserve reliability. This leads to a significant drop in the coverage and novelty that these systems can provide. In this paper, we propose the inclusion of a new term in the learning process of matrix factorization-based recommender systems, called recklessness, which enables the control of the risk level desired when making decisions about the reliability of a prediction. Experimental results demonstrate that recklessness not only allows for risk regulation but also improves the quantity and quality of predictions provided by the recommender system.
    
[^49]: 大型语言模型的不平等机会: 通过职位推荐揭示人口统计偏见

    The Unequal Opportunities of Large Language Models: Revealing Demographic Bias through Job Recommendations. (arXiv:2308.02053v1 [cs.CL])

    [http://arxiv.org/abs/2308.02053](http://arxiv.org/abs/2308.02053)

    通过职位推荐分析了大型语言模型（LLMs）的人口统计偏见，发现这些模型对于墨西哥工人一直建议低薪工作，并向女性更倾向于推荐秘书职位。这项研究强调了理解LLMs偏见的重要性。

    

    大型语言模型（LLMs）已在各种实际应用中得到广泛应用。了解这些偏见对于理解在使用LLMs进行决策时潜在的后续影响至关重要，特别是对于历史上处于劣势的群体。在这项工作中，我们提出了一种简单的方法来通过职位推荐的角度分析和比较LLMs中的人口统计偏见。我们通过测量ChatGPT和LLaMA这两个前沿LLMs内的交叉偏见来证明我们方法的有效性。我们的实验主要集中在揭示性别认同和国籍偏见上；然而，我们的方法可以扩展到任何人口统计身份的交叉偏见的研究。我们在两个模型中发现了明显的偏见，例如两个模型一直建议墨西哥工人从事低薪工作，或者更倾向于向女性推荐秘书职位。我们的研究强调了测量和理解LLMs中的偏见的重要性。

    Large Language Models (LLMs) have seen widespread deployment in various real-world applications. Understanding these biases is crucial to comprehend the potential downstream consequences when using LLMs to make decisions, particularly for historically disadvantaged groups. In this work, we propose a simple method for analyzing and comparing demographic bias in LLMs, through the lens of job recommendations. We demonstrate the effectiveness of our method by measuring intersectional biases within ChatGPT and LLaMA, two cutting-edge LLMs. Our experiments primarily focus on uncovering gender identity and nationality bias; however, our method can be extended to examine biases associated with any intersection of demographic identities. We identify distinct biases in both models toward various demographic identities, such as both models consistently suggesting low-paying jobs for Mexican workers or preferring to recommend secretarial roles to women. Our study highlights the importance of measu
    
[^50]: 欧洲提议的AI法案中可接受的风险：对决定风险管理的合理性和其他原则的评估

    Acceptable risks in Europe's proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough. (arXiv:2308.02047v1 [cs.CY])

    [http://arxiv.org/abs/2308.02047](http://arxiv.org/abs/2308.02047)

    本文批判性评估了欧洲提议的AI法案的风险管理和风险可接受性方法。与法案的狭义解释不同，议会的草案修改引入了更具可行性的“合理性”原则，并更透明地表明风险可接受性判断的价值取向和情境性质，更好地平衡了相称性和可信赖性的目标。

    

    本文对欧洲委员会提议的AI法案中的风险管理和风险可接受性方法进行了批判性评估，该法案针对对基本权利和安全构成风险的高风险AI系统。该法案旨在推广“可信赖”的AI，并承担相称的监管负担。其关于风险可接受性的规定要求尽可能减少或消除高风险系统的残余风险，考虑“技术水平”。特别是如果狭义解释，这个标准是行不通的，既不促进相称的监管负担，也不促进可信赖性。相比之下，议会对风险管理规定最近的草案修改引入了“合理性”、成本效益分析，并对风险可接受性判断的价值取向和情境性质更加透明。本文认为议会的方法更具可行性，更能平衡相称性和可信赖性的目标。解释了议会的方法如何环绕风险管理的不同方面进行。

    This paper critically evaluates the European Commission's proposed AI Act's approach to risk management and risk acceptability for high-risk AI systems that pose risks to fundamental rights and safety. The Act aims to promote "trustworthy" AI with a proportionate regulatory burden. Its provisions on risk acceptability require residual risks from high-risk systems to be reduced or eliminated "as far as possible", having regard to the "state of the art". This criterion, especially if interpreted narrowly, is unworkable and promotes neither proportionate regulatory burden, nor trustworthiness. By contrast the Parliament's most recent draft amendments to the risk management provisions introduce "reasonableness", cost-benefit analysis, and are more transparent about the value-laden and contextual nature of risk acceptability judgements. This paper argues that the Parliament's approach is more workable, and better balances the goals of proportionality and trustworthiness. It explains what re
    
[^51]: 档案和历史学领域的人工智能应用：HTS和ChatGPT

    Artificial Intelligence in archival and historical scholarship workflow: HTS and ChatGPT. (arXiv:2308.02044v1 [cs.DL])

    [http://arxiv.org/abs/2308.02044](http://arxiv.org/abs/2308.02044)

    本文研究了人工智能在档案数字化过程中的应用，重点是自动转录和校正手稿，以及标准化文本。通过测试ChatGPT系统，在对信函进行文本标准化时取得了一定效果。总体而言，数字化和人工智能可以显著提升档案和历史研究能力。

    

    本文研究了人工智能对档案遗产数字化过程的影响，特别是对手稿的自动转录、校正和标准化的影响。它强调了数字化推动学者重新定义档案和历史领域，并通过数字化和大数据的整合提供模拟源文件的便捷性。研究聚焦于两个人工智能系统，分别是Transkribus和ChatGPT，它们使得对数字化源文件的高效分析和转录成为可能。文章还介绍了对ChatGPT的测试，该测试用于对保存在Biscari档案（卡塔尼亚）的信函部分中的366封信件进行文本标准化。尽管人工智能存在一些限制导致一些不准确性，但纠正后的文本仍然达到了期望。总的来说，文章得出结论，数字化和人工智能可以显著提升档案和历史研究，允许对大量数据进行分析和处理。

    This article examines the impact of Artificial Intelligence on the archival heritage digitization processes, specifically regarding the manuscripts' automatic transcription, their correction, and normalization. It highlights how digitality has compelled scholars to redefine Archive and History field and has facilitated the accessibility of analogue sources through digitization and integration into big data. The study focuses on two AI systems, namely Transkribus and ChatGPT, which enable efficient analysis and transcription of digitized sources. The article presents a test of ChatGPT, which was utilized to normalize the text of 366 letters stored in the Correspondence section of the Biscari Archive (Catania). Although the AI exhibited some limitations that resulted in inaccuracies, the corrected texts met expectations. Overall, the article concludes that digitization and AI can significantly enhance archival and historical research by allowing the analysis of vast amounts of data and t
    
[^52]: 通过远程收集穿戴设备和智能手机数据开发的数字生物标志物对疾病的洞察力

    Disease Insight through Digital Biomarkers Developed by Remotely Collected Wearables and Smartphone Data. (arXiv:2308.02043v1 [cs.CY])

    [http://arxiv.org/abs/2308.02043](http://arxiv.org/abs/2308.02043)

    通过远程收集患者数据，利用数字生物标志物和远程监测技术可以提供有价值的疾病洞察力，从而补充传统医疗环境中的治疗方法。

    

    数字生物标志物和远程患者监测可以及时提供有价值的见解，了解患者应对病情（疾病进展、治疗反应等）的情况，以补充传统医疗环境中的治疗。嵌入和连接传感器的智能手机通过各种应用和移动健康（mHealth）平台具有巨大的改进医疗保健的潜力。这种能力可以通过远程收集患者的长期纵向数据来开发可靠的数字生物标志物。我们构建了一个开源平台RADAR-base，以支持远程监测研究中的大规模数据收集。RADAR-base是一个现代化的远程数据收集平台，基于Confluent的Apache Kafka构建，支持可扩展性、可拓展性、安全性、隐私性和数据质量。它提供了研究设计和设置、主动（如患者报告的测量）和被动（如手机传感器、可穿戴设备和物联网）远程数据收集能力。

    Digital Biomarkers and remote patient monitoring can provide valuable and timely insights into how a patient is coping with their condition (disease progression, treatment response, etc.), complementing treatment in traditional healthcare settings.Smartphones with embedded and connected sensors have immense potential for improving healthcare through various apps and mHealth (mobile health) platforms. This capability could enable the development of reliable digital biomarkers from long-term longitudinal data collected remotely from patients. We built an open-source platform, RADAR-base, to support large-scale data collection in remote monitoring studies. RADAR-base is a modern remote data collection platform built around Confluent's Apache Kafka, to support scalability, extensibility, security, privacy and quality of data. It provides support for study design and set-up, active (eg PROMs) and passive (eg. phone sensors, wearable devices and IoT) remote data collection capabilities with 
    
[^53]: 在公共部门中支持自然语言处理和文本挖掘的人工智能发展和应用的主要关注点的简要回顾

    A short review of the main concerns in A.I. development and application within the public sector supported by NLP and TM. (arXiv:2308.02042v1 [cs.CY])

    [http://arxiv.org/abs/2308.02042](http://arxiv.org/abs/2308.02042)

    本文通过回顾过去两年发表的研究论文，结合自然语言处理和文本挖掘的基本概念，捕捉了公共部门中人工智能发展和应用的数据隐私、伦理、可解释性、可信度和公平性等关注点。其中，公平性是最频繁关注的问题，而数据隐私是最不突出的话题。

    

    人工智能并不是一个新的课题，商业、工业和公共部门以不同的方式和背景使用它，考虑多个关注点。本研究通过对ACM Digital Library和IEEE Xplore会议论文集中过去两年发表的研究论文进行回顾，并结合自然语言处理和文本挖掘的基本概念，旨在捕捉公共部门中数据隐私、伦理、可解释性、可信度和公平的洞察。该方法节省了分析时间，并能检索到包含相关信息的论文。结果显示，公平性是最频繁引起关注的问题。最不突出的话题是数据隐私（尽管嵌入在大多数文章中），而最突出的是可信度。最后，也成功地获得了有关公共部门中人工智能应用相关问题的有益见解。

    Artificial Intelligence is not a new subject, and business, industry and public sectors have used it in different ways and contexts and considering multiple concerns. This work reviewed research papers published in ACM Digital Library and IEEE Xplore conference proceedings in the last two years supported by fundamental concepts of Natural Language Processing (NLP) and Text Mining (TM). The objective was to capture insights regarding data privacy, ethics, interpretability, explainability, trustworthiness, and fairness in the public sector. The methodology has saved analysis time and could retrieve papers containing relevant information. The results showed that fairness was the most frequent concern. The least prominent topic was data privacy (although embedded in most articles), while the most prominent was trustworthiness. Finally, gathering helpful insights about those concerns regarding A.I. applications in the public sector was also possible.
    
[^54]: 调节AI操纵：运用行为经济学和心理学的见解增强欧盟AI法案的实用性

    Regulating AI manipulation: Applying Insights from behavioral economics and psychology to enhance the practicality of the EU AI Act. (arXiv:2308.02041v1 [cs.CY])

    [http://arxiv.org/abs/2308.02041](http://arxiv.org/abs/2308.02041)

    本文通过运用心理学和行为经济学的见解，澄清了欧盟AI法案中的术语并提高了保护效果。

    

    欧盟AI法案第5条旨在调节AI操纵，以防止潜在的有害后果。然而，由于术语模糊和操纵技术表述不清晰，这项立法的实际执行存在挑战。此外，第5条也受到保护效果不足的批评。本文试图通过整合心理学和行为经济学的见解，澄清术语并提高保护效果。首先，本文运用认知心理学研究阐明潜意识技巧及其相关表述。此外，本文将行为经济学中可以引发行为变化的一组思维快捷方式，即启发式，扩展到操纵技术领域。术语的阐明和扩展不仅提供了对法律规定更准确的理解，还增强了其保护效果。

    The EU AI Act Article 5 is designed to regulate AI manipulation to prevent potential harmful consequences. However, the practical implementation of this legislation is challenging due to the ambiguous terminologies and the unclear presentations of manipulative techniques. Moreover, the Article 5 also suffers criticize of inadequate protective efficacy. This paper attempts to clarify terminologies and to enhance the protective efficacy by integrating insights from psychology and behavioral economics. Firstly, this paper employs cognitive psychology research to elucidate the term subliminal techniques and its associated representation. Additionally, this paper extends the study of heuristics: a set of thinking shortcuts which can be aroused for behavior changing from behavior economics to the realm of manipulative techniques. The elucidation and expansion of terminologies not only provide a more accurate understanding of the legal provision but also enhance its protective efficacy. Secon
    
[^55]: CLGT: 用于协作学习中学生绩效预测的图转换器

    CLGT: A Graph Transformer for Student Performance Prediction in Collaborative Learning. (arXiv:2308.02038v1 [cs.CY])

    [http://arxiv.org/abs/2308.02038](http://arxiv.org/abs/2308.02038)

    该论文提出了一个基于图转换器的框架，用于在协作学习中评估和预测学生的绩效。

    

    对于协作学习范式中学生的绩效进行建模和预测是一项重要任务。大多数关于协作学习的研究都集中在讨论论坛和社交学习网络上。只有很少的研究涉及学生在团队项目中如何相互交互以及这种交互如何影响他们的学术表现。为了弥补这一差距，我们选择一个软件工程课程作为研究对象。参与软件工程课程的学生需要组队完成一个软件项目。在这项工作中，我们根据不同团队的学生活动构建了一个交互图。基于这个学生交互图，我们提出了一个扩展的协作学习图转换器框架（CLGT），用于评估和预测学生的表现。此外，提出的CLGT包含一个解释模块，用于解释学生的绩效预测结果。

    Modeling and predicting the performance of students in collaborative learning paradigms is an important task. Most of the research presented in literature regarding collaborative learning focuses on the discussion forums and social learning networks. There are only a few works that investigate how students interact with each other in team projects and how such interactions affect their academic performance. In order to bridge this gap, we choose a software engineering course as the study subject. The students who participate in a software engineering course are required to team up and complete a software project together. In this work, we construct an interaction graph based on the activities of students grouped in various teams. Based on this student interaction graph, we present an extended graph transformer framework for collaborative learning (CLGT) for evaluating and predicting the performance of students. Moreover, the proposed CLGT contains an interpretation module that explains
    
[^56]: 电动自行车使用的增长：一种机器学习方法

    The Growth of E-Bike Use: A Machine Learning Approach. (arXiv:2308.02034v1 [cs.CY])

    [http://arxiv.org/abs/2308.02034](http://arxiv.org/abs/2308.02034)

    本研究使用机器学习方法，预测了美国电动自行车销量的增长，并评估了影响电动自行车使用的因素。根据预测结果，预计2025年电动自行车销售量为130万辆，2028年为211.3万辆。

    

    本文介绍了电动自行车（电单车）及其对美国政策制定者的影响。电动自行车作为一种快速和环保的交通选择，已经获得了显著的流行。在我们追求可持续能源计划的过程中，了解电动自行车的增长和影响对政策制定者至关重要。我们的数学模型为电动自行车的价值和其在未来的角色提供了洞察。我们使用ARIMA模型，一种监督式的机器学习算法，预测了美国电动自行车销量的增长。我们的模型基于从2006年1月到2022年12月的历史销售数据进行训练，预测2025年销售量为130万辆，2028年销售量为211.3万辆。为了评估影响电动自行车使用的因素，我们采用了随机森林回归模型。影响电动自行车销量增长最显著的因素是可支配个人收入和受欢迎程度。此外，我们还研究了电动自行车对环境和健康的影响。

    We present our work on electric bicycles (e-bikes) and their implications for policymakers in the United States. E-bikes have gained significant popularity as a fast and eco-friendly transportation option. As we strive for a sustainable energy plan, understanding the growth and impact of e-bikes is crucial for policymakers. Our mathematical modeling offers insights into the value of e-bikes and their role in the future. Using an ARIMA model, a supervised machine-learning algorithm, we predicted the growth of e-bike sales in the U.S. Our model, trained on historical sales data from January 2006 to December 2022, projected sales of 1.3 million units in 2025 and 2.113 million units in 2028. To assess the factors contributing to e-bike usage, we employed a Random Forest regression model. The most significant factors influencing e-bike sales growth were disposable personal income and popularity. Furthermore, we examined the environmental and health impacts of e-bikes. Through Monte Carlo si
    
[^57]: AI与欧盟数字市场法案：应对生成式AI中的巨头风险

    AI and the EU Digital Markets Act: Addressing the Risks of Bigness in Generative AI. (arXiv:2308.02033v1 [cs.CY])

    [http://arxiv.org/abs/2308.02033](http://arxiv.org/abs/2308.02033)

    这项研究旨在探讨如何应对生成式AI中的巨头风险，并提出了将某些AI软件作为核心平台服务，将某些开发者分类为守门人，并对相关义务进行评估的建议。这有助于欧盟在生成式AI服务中维护多样性和开放性。

    

    随着人工智能技术的快速发展，对数字市场巨头风险的关注也日益增加。欧盟的数字市场法案旨在解决这些风险。然而，目前的框架可能未能充分覆盖可能成为AI服务入口的生成式AI系统。本文主张将某些AI软件整合为核心平台服务，并将某些开发者分类为数字市场法案的守门人。我们还提议对守门人义务进行评估，以确保它们涵盖生成式AI服务。随着欧盟考虑生成式AI特定规则和可能的数字市场法案修正案，本文为生成式AI服务的多样化和开放性提供了见解。

    As AI technology advances rapidly, concerns over the risks of bigness in digital markets are also growing. The EU's Digital Markets Act (DMA) aims to address these risks. Still, the current framework may not adequately cover generative AI systems that could become gateways for AI-based services. This paper argues for integrating certain AI software as core platform services and classifying certain developers as gatekeepers under the DMA. We also propose an assessment of gatekeeper obligations to ensure they cover generative AI services. As the EU considers generative AI-specific rules and possible DMA amendments, this paper provides insights towards diversity and openness in generative AI services.
    
[^58]: JusticeBot：一种为非法律专业人士构建增强智能工具以增加公众获取司法资源的方法论

    JusticeBot: A Methodology for Building Augmented Intelligence Tools for Laypeople to Increase Access to Justice. (arXiv:2308.02032v1 [cs.CY])

    [http://arxiv.org/abs/2308.02032](http://arxiv.org/abs/2308.02032)

    JusticeBot是一种为非法律专业人士提供法律决策支持的增强智能工具，通过混合案例和规则推理的方法，帮助用户探索他们在特定情况下的法律权利，并提供相关的法律信息和案例参考。

    

    非法律专业人士常常在解决法律问题时遇到困难。在这项工作中，我们提出了JusticeBot方法论。该方法论可以用于构建法律决策支持工具，以混合案例和规则推理的方式帮助非法律专业人士探讨他们在特定情况下的法律权利。系统会询问用户与他们情况相关的问题，并为他们提供法律信息、参考以前类似案例和可能的下一步行动。这些信息可能有助于用户解决问题，例如通过和解案件或在法庭上维护自己的权益。我们提出了构建此类工具的方法论，包括从法规和案例法中发现通常适用的法律规则，并对以前的案例进行编码以支持用户。我们还介绍了使用该方法论构建工具的界面，并展示了首个部署的JusticeBot版本的案例研究，重点关注土地租赁。

    Laypeople (i.e. individuals without legal training) may often have trouble resolving their legal problems. In this work, we present the JusticeBot methodology. This methodology can be used to build legal decision support tools, that support laypeople in exploring their legal rights in certain situations, using a hybrid case-based and rule-based reasoning approach. The system ask the user questions regarding their situation and provides them with legal information, references to previous similar cases and possible next steps. This information could potentially help the user resolve their issue, e.g. by settling their case or enforcing their rights in court. We present the methodology for building such tools, which consists of discovering typically applied legal rules from legislation and case law, and encoding previous cases to support the user. We also present an interface to build tools using this methodology and a case study of the first deployed JusticeBot version, focused on landlo
    
[^59]: 基于知识增强的神经符号人工智能用于网络安全和隐私保护

    Knowledge-enhanced Neuro-Symbolic AI for Cybersecurity and Privacy. (arXiv:2308.02031v1 [cs.CY])

    [http://arxiv.org/abs/2308.02031](http://arxiv.org/abs/2308.02031)

    知识增强的神经符号人工智能将深度神经网络和符号知识图相结合，提高了人工智能系统的可解释性和安全性，在网络安全和隐私保护领域具有潜在应用价值。

    

    神经符号人工智能是一个新兴且快速发展的领域，它将（深度）神经网络的子符号优势与知识图中的显式符号知识相结合，以提高人工智能系统的可解释性和安全性。这种方法解决了当前一代系统的关键问题，即它们无法为其结果生成人类可理解的解释，并在存在“未知未知”（例如网络安全、隐私）情况下确保安全行为。神经网络（擅长探索复杂数据空间）和符号知识图的整合（代表领域知识）使得人工智能系统能够以专家可理解的方式进行推理、学习和泛化。本文描述了神经符号人工智能如何在网络安全和隐私保护领域中应用，并且这两个领域对于人工智能的可解释性和在复杂环境中的高准确性需求最大，可以从神经符号人工智能中获益。

    Neuro-Symbolic Artificial Intelligence (AI) is an emerging and quickly advancing field that combines the subsymbolic strengths of (deep) neural networks and explicit, symbolic knowledge contained in knowledge graphs to enhance explainability and safety in AI systems. This approach addresses a key criticism of current generation systems, namely their inability to generate human-understandable explanations for their outcomes and ensure safe behaviors, especially in scenarios with \textit{unknown unknowns} (e.g. cybersecurity, privacy). The integration of neural networks, which excel at exploring complex data spaces, and symbolic knowledge graphs, which represent domain knowledge, allows AI systems to reason, learn, and generalize in a manner understandable to experts. This article describes how applications in cybersecurity and privacy, two most demanding domains in terms of the need for AI to be explainable while being highly accurate in complex environments, can benefit from Neuro-Symb
    
[^60]: 对第四次工业革命和人工智能对社会的影响的看法

    Perceptions of the Fourth Industrial Revolution and Artificial Intelligence Impact on Society. (arXiv:2308.02030v1 [cs.CY])

    [http://arxiv.org/abs/2308.02030](http://arxiv.org/abs/2308.02030)

    本研究调查了不同信息流分类下个体对AI的看法，结果显示参与者关注AI对就业、隐私和信息准确性的影响。然而，他们也认识到AI能够解决复杂问题和增加便利。对于政府在第四次工业革命中的角色，意见各异。

    

    第四次工业革命，尤其是人工智能（AI），对社会产生了深远影响，引发了对其影响和伦理考虑的担忧。文本生成AI工具（如ChatGPT）的出现进一步加剧了人们对伦理、安全、隐私和版权的担忧。本研究旨在研究不同信息流分类的个体对AI的看法。结果揭示了参与者提供的AI和第四次工业革命的定义中的关键主题，强调了人工智能的复制、机器学习、自动化和数字技术的整合。参与者对AI替代工作岗位、侵犯隐私以及AI提供的不准确信息表示担忧。然而，他们也认识到AI的好处，如解决复杂问题和增加便利。关于政府在塑造第四次工业革命方面的参与，意见不一。

    The Fourth Industrial Revolution, particularly Artificial Intelligence (AI), has had a profound impact on society, raising concerns about its implications and ethical considerations. The emergence of text generative AI tools like ChatGPT has further intensified concerns regarding ethics, security, privacy, and copyright. This study aims to examine the perceptions of individuals in different information flow categorizations toward AI. The results reveal key themes in participant-supplied definitions of AI and the fourth industrial revolution, emphasizing the replication of human intelligence, machine learning, automation, and the integration of digital technologies. Participants expressed concerns about job replacement, privacy invasion, and inaccurate information provided by AI. However, they also recognized the benefits of AI, such as solving complex problems and increasing convenience. Views on government involvement in shaping the fourth industrial revolution varied, with some advoc
    
[^61]: STT-MRAM作为机器学习加速器中的Scratchpad的评估

    Evaluation of STT-MRAM as a Scratchpad for Training in ML Accelerators. (arXiv:2308.02024v1 [cs.AR])

    [http://arxiv.org/abs/2308.02024](http://arxiv.org/abs/2308.02024)

    本研究评估了STT-MRAM作为训练加速器中的Scratchpad的效果，发现它具有高密度、低泄漏功率和合理的访问时间等优点，但写操作需要较高的能量和延迟。

    

    在过去十年中，人工智能和机器学习的进展是由于训练更大的深度神经网络(DNNs)的能力推动的，这导致了远远超过摩尔定律提供的硬件性能增长的计算需求。训练DNNs是一个极其内存密集的过程，需要存储整个minibatch的模型权重、激活和梯度。提供高密度和低泄漏的片上存储器的需求促使我们探索新兴的非易失性存储器用于训练加速器。自旋转矩传输磁阻存储器(STT-MRAM)在训练加速器中具有几个令人满意的特性，包括比SRAM高3-4倍的密度，大大降低的泄漏功率，高耐久性和合理的访问时间。然而，MRAM的写操作由于需要确保可靠切换，会产生高写能量和延迟。在本研究中，我们进行了全面的从器件到系统的评估和协同优化。

    Progress in artificial intelligence and machine learning over the past decade has been driven by the ability to train larger deep neural networks (DNNs), leading to a compute demand that far exceeds the growth in hardware performance afforded by Moore's law. Training DNNs is an extremely memory-intensive process, requiring not just the model weights but also activations and gradients for an entire minibatch to be stored. The need to provide high-density and low-leakage on-chip memory motivates the exploration of emerging non-volatile memory for training accelerators. Spin-Transfer-Torque MRAM (STT-MRAM) offers several desirable properties for training accelerators, including 3-4x higher density than SRAM, significantly reduced leakage power, high endurance and reasonable access time. On the one hand, MRAM write operations require high write energy and latency due to the need to ensure reliable switching.  In this study, we perform a comprehensive device-to-system evaluation and co-opti
    
[^62]: 从神经表示到符号知识的过渡

    On the Transition from Neural Representation to Symbolic Knowledge. (arXiv:2308.02000v1 [cs.AI])

    [http://arxiv.org/abs/2308.02000](http://arxiv.org/abs/2308.02000)

    该论文提出了一种神经-符号过渡字典学习框架，可以将神经网络与符号思维进行结合。通过学习过渡表示，并自监督地发现隐含的谓词结构，以及通过博弈和强化学习调整学习到的原型，该框架可以实现对高维信息的压缩和符号表示的学习。

    

    弥合神经表示与符号表示之间的巨大差距可能使符号思维从本质上融入神经网络。受人类如何逐渐从通过知觉和环境交互学习到的原型符号构建复杂的符号表示的启发，我们提出了一种神经-符号过渡字典学习（TDL）框架，该框架使用EM算法学习数据的过渡表示，将输入的高维视觉部分信息压缩到一组张量作为神经变量，并自监督地发现隐含的谓词结构。我们通过将输入分解视为合作博弈来实现框架，使用扩散模型学习谓词，并通过RL基于扩散模型的马尔可夫性质进一步调整学习到的原型，以融入主观因素。

    Bridging the huge disparity between neural and symbolic representation can potentially enable the incorporation of symbolic thinking into neural networks from essence. Motivated by how human gradually builds complex symbolic representation from the prototype symbols that are learned through perception and environmental interactions. We propose a Neural-Symbolic Transitional Dictionary Learning (TDL) framework that employs an EM algorithm to learn a transitional representation of data that compresses high-dimension information of visual parts of an input into a set of tensors as neural variables and discover the implicit predicate structure in a self-supervised way. We implement the framework with a diffusion model by regarding the decomposition of input as a cooperative game, then learn predicates by prototype clustering. We additionally use RL enabled by the Markovian of diffusion models to further tune the learned prototypes by incorporating subjective factors. Extensive experiments 
    
[^63]: 拼写检查器在在线市场中的领域特异性和数据效率：以在线市场搜索为例

    Domain specificity and data efficiency in typo tolerant spell checkers: the case of search in online marketplaces. (arXiv:2308.01976v1 [cs.LG])

    [http://arxiv.org/abs/2308.01976](http://arxiv.org/abs/2308.01976)

    本研究针对在线市场中拼写错误的问题，通过数据增强方法和递归神经网络实现了领域特定的拼写检查器，并将其应用在微软AppSource市场的实时推断API中。我们的数据有效解决方案表明，控制高质量的合成数据可能成为一个有力的工具，特别是考虑到当前大语言模型所依赖的巨大且难以控制的数据集。

    

    由于在线市场的领域特定性和用户短查询的特点，错字是在线市场访问者的主要困扰。传统的拼写检查解决方案在纠正拼写错误方面表现不佳。我们提出了一种数据增强方法来解决缺乏标注拼写错误数据的问题，并使用递归神经网络训练了上下文限制的领域特定嵌入。这些嵌入被部署在微软AppSource市场的实时推断API中，以在错误拼写的用户查询和可用产品名称之间找到最接近的匹配。我们的数据有效解决方案表明，受到当前大语言模型的影响，控制高质量的合成数据可能成为一个有力的工具，而这些模型依赖于巨大且难以控制的数据集。

    Typographical errors are a major source of frustration for visitors of online marketplaces. Because of the domain-specific nature of these marketplaces and the very short queries users tend to search for, traditional spell cheking solutions do not perform well in correcting typos. We present a data augmentation method to address the lack of annotated typo data and train a recurrent neural network to learn context-limited domain-specific embeddings. Those embeddings are deployed in a real-time inferencing API for the Microsoft AppSource marketplace to find the closest match between a misspelled user query and the available product names. Our data efficient solution shows that controlled high quality synthetic data may be a powerful tool especially considering the current climate of large language models which rely on prohibitively huge and often uncontrolled datasets.
    
[^64]: SpaDen: 用于现实世界图表理解的稀疏和稠密关键点估计

    SpaDen : Sparse and Dense Keypoint Estimation for Real-World Chart Understanding. (arXiv:2308.01971v1 [cs.CV])

    [http://arxiv.org/abs/2308.01971](http://arxiv.org/abs/2308.01971)

    本文介绍了一种用于提取图表数据的新型自下而上方法。通过检测连续和离散的关键点来实现对绘图区域内组件的重构，进而获取数据系列名称。实验结果证明了该方法的有效性。

    

    我们引入了一种新颖的自下而上方法来提取图表数据。我们的模型利用图表图像作为输入，并学习检测关键点（KP），用于重构绘图区域内的组件。我们的创新点在于检测连续和离散KP的融合，作为预测的热图。我们应用稀疏和稠密逐像素目标的组合，结合单模态自注意力特征融合层来学习KP嵌入。进一步利用深度度量学习进行无监督聚类，可以将图表绘图区域分割成各种对象。通过将图表组件与图例进行匹配，我们能够获得数据系列名称。对KP嵌入应用后处理阈值，以进一步改进对象的重构并提高准确性。我们的实验包括评估不同模块用于KP估计以及深层聚合和角点池化方法的组合。

    We introduce a novel bottom-up approach for the extraction of chart data. Our model utilizes images of charts as inputs and learns to detect keypoints (KP), which are used to reconstruct the components within the plot area. Our novelty lies in detecting a fusion of continuous and discrete KP as predicted heatmaps. A combination of sparse and dense per-pixel objectives coupled with a uni-modal self-attention-based feature-fusion layer is applied to learn KP embeddings. Further leveraging deep metric learning for unsupervised clustering, allows us to segment the chart plot area into various objects. By further matching the chart components to the legend, we are able to obtain the data series names. A post-processing threshold is applied to the KP embeddings to refine the object reconstructions and improve accuracy. Our extensive experiments include an evaluation of different modules for KP estimation and the combination of deep layer aggregation and corner pooling approaches. The results
    
[^65]: 基于双学生-教师模型的判别性图级异常检测

    Discriminative Graph-level Anomaly Detection via Dual-students-teacher Model. (arXiv:2308.01947v1 [cs.LG])

    [http://arxiv.org/abs/2308.01947](http://arxiv.org/abs/2308.01947)

    本论文提出了一种基于双学生-教师模型的判别性图级异常检测方法，通过定义异常图信息和采用节点级和图级信息差来识别异常图，并引入教师模型和两个竞争的学生模型来提高异常检测的效果。

    

    不同于当前的节点级异常检测任务，图级异常检测的目标是寻找在图集中与其他图显著不同的异常图。由于对图级异常检测的研究较少，关于图级异常的详细描述不足。此外，现有工作集中于捕捉异常图信息以学习更好的图表示，但忽视了对评估异常图的有效异常得分函数的重要性。因此，在这项工作中，我们首先定义了在图集中包括节点和图属性异常的异常图信息，并分别采用节点级和图级信息差来识别它们。然后，我们引入了一个具有双学生-教师模型的判别性图级异常检测框架，其中教师模型通过一种启发式损失进行训练，使得图表示更为分散。然后，两个竞争的学生模型通过争夺任务来提高异常检测效果。

    Different from the current node-level anomaly detection task, the goal of graph-level anomaly detection is to find abnormal graphs that significantly differ from others in a graph set. Due to the scarcity of research on the work of graph-level anomaly detection, the detailed description of graph-level anomaly is insufficient. Furthermore, existing works focus on capturing anomalous graph information to learn better graph representations, but they ignore the importance of an effective anomaly score function for evaluating abnormal graphs. Thus, in this work, we first define anomalous graph information including node and graph property anomalies in a graph set and adopt node-level and graph-level information differences to identify them, respectively. Then, we introduce a discriminative graph-level anomaly detection framework with dual-students-teacher model, where the teacher model with a heuristic loss are trained to make graph representations more divergent. Then, two competing studen
    
[^66]: 数字双胞胎脑：生物智能和人工智能之间的桥梁

    Digital twin brain: a bridge between biological intelligence and artificial intelligence. (arXiv:2308.01941v1 [q-bio.NC])

    [http://arxiv.org/abs/2308.01941](http://arxiv.org/abs/2308.01941)

    本文提出了数字双胞胎脑作为一个桥梁，将生物智能和人工智能联系在一起，通过将神经科学和人工智能的进展结合起来，更好地理解大脑的复杂性和如何产生智能。

    

    最近几年，神经科学和人工智能的进展为理解大脑的复杂性以及通过计算系统来模拟大脑铺平了道路。神经科学研究的前沿进展揭示了大脑结构和功能之间错综复杂的关系，而人工神经网络的成功强调了网络架构的重要性。现在是将它们结合起来更好地揭示智能是如何从大脑的多尺度存储库中产生的时候了。在这篇综述中，我们提出数字双胞胎脑(DTB)作为一个将生物智能和人工智能联系起来的转变性平台。它包括三个核心元素：对双胞胎过程至关重要的大脑结构、用于生成大脑功能的底层模型，以及其广泛的应用领域。关键是，大脑图谱提供了一个重要的约束条件，保持了大脑的网络组织。

    In recent years, advances in neuroscience and artificial intelligence have paved the way for unprecedented opportunities for understanding the complexity of the brain and its emulation by computational systems. Cutting-edge advancements in neuroscience research have revealed the intricate relationship between brain structure and function, while the success of artificial neural networks highlights the importance of network architecture. Now is the time to bring them together to better unravel how intelligence emerges from the brain's multiscale repositories. In this review, we propose the Digital Twin Brain (DTB) as a transformative platform that bridges the gap between biological and artificial intelligence. It consists of three core elements: the brain structure that is fundamental to the twinning process, bottom-layer models to generate brain functions, and its wide spectrum of applications. Crucially, brain atlases provide a vital constraint, preserving the brain's network organizat
    
[^67]: 使用组合扩散模型实现训练数据保护

    Training Data Protection with Compositional Diffusion Models. (arXiv:2308.01937v1 [cs.LG])

    [http://arxiv.org/abs/2308.01937](http://arxiv.org/abs/2308.01937)

    使用分区扩散模型（CDM）训练不同的扩散模型，并在推断时任意组合它们，实现了训练数据保护和选择性遗忘，同时还可以根据用户访问权限提供定制模型。

    

    我们引入了分区扩散模型（CDM），一种在不同数据源上训练不同扩散模型（或提示）并在推断时任意组合它们的方法。这些单独的模型可以在孤立状态下、在不同时间、在不同分布和领域上进行训练，并可以后续组合以达到与同时训练所有数据的理想模型相当的性能。此外，每个模型只包含其在训练期间接触到的数据子集的信息，可以实现多种形式的训练数据保护。特别是，CDM是第一种可以实现大规模扩散模型的选择性遗忘和持续学习的方法，并且允许根据用户访问权限提供定制模型。CDM还可以确定生成特定样本的数据子集的重要性。

    We introduce Compartmentalized Diffusion Models (CDM), a method to train different diffusion models (or prompts) on distinct data sources and arbitrarily compose them at inference time. The individual models can be trained in isolation, at different times, and on different distributions and domains and can be later composed to achieve performance comparable to a paragon model trained on all data simultaneously. Furthermore, each model only contains information about the subset of the data it was exposed to during training, enabling several forms of training data protection. In particular, CDMs are the first method to enable both selective forgetting and continual learning for large-scale diffusion models, as well as allowing serving customized models based on the user's access rights. CDMs also allow determining the importance of a subset of the data in generating particular samples.
    
[^68]: 为什么我们需要神经符号人工智能来建模实用的类比?

    Why Do We Need Neuro-symbolic AI to Model Pragmatic Analogies?. (arXiv:2308.01936v1 [cs.AI])

    [http://arxiv.org/abs/2308.01936](http://arxiv.org/abs/2308.01936)

    本文讨论了神经符号人工智能在处理逐渐复杂的类比推理时的必要性，以提供超越文字内容的广泛、多样化的知识，并结合统计和符号人工智能技术来增强和引导映射过程。

    

    智能的一个特点是能够利用熟悉的领域对不那么熟悉的领域进行推理，即类比推理。本文探讨了大型语言模型（LLMs）在处理在非结构化文本中表达的逐渐复杂的类比时的性能。我们讨论了四个不同复杂级别的类比：词汇类比、句法类比、语义类比和实用类比。随着类比变得越来越复杂，它们需要超出文本内容的广泛、多样化的知识，这在支持LLMs的词汇共现统计中不太可能找到。为了解决这个问题，我们讨论了采用神经符号人工智能技术的必要性，这些技术结合了统计和符号人工智能，根据非结构化文本提供信息以突出和增强相关内容，提供抽象和引导映射过程。我们的知识驱动方法在保持LLMs的效率的同时保持其性能。

    A hallmark of intelligence is the ability to use a familiar domain to make inferences about a less familiar domain, known as analogical reasoning. In this article, we delve into the performance of Large Language Models (LLMs) in dealing with progressively complex analogies expressed in unstructured text. We discuss analogies at four distinct levels of complexity: lexical analogies, syntactic analogies, semantic analogies, and pragmatic analogies. As the analogies become more complex, they require increasingly extensive, diverse knowledge beyond the textual content, unlikely to be found in the lexical co-occurrence statistics that power LLMs. To address this, we discuss the necessity of employing Neuro-symbolic AI techniques that combine statistical and symbolic AI, informing the representation of unstructured text to highlight and augment relevant content, provide abstraction and guide the mapping process. Our knowledge-informed approach maintains the efficiency of LLMs while preservin
    
[^69]: 基于机器学习的光电脉搏信号特征的糖尿病检测

    Machine Learning-Based Diabetes Detection Using Photoplethysmography Signal Features. (arXiv:2308.01930v1 [cs.LG])

    [http://arxiv.org/abs/2308.01930](http://arxiv.org/abs/2308.01930)

    基于光电脉搏信号特征的机器学习方法用于糖尿病检测，通过非侵入性PPG信号和LR、XGBoost算法的分类，实现了免创伤且连续监测的糖尿病检测。

    

    糖尿病是一种常见的慢性疾病，在全球范围内影响着数百万人的健康。需要无创方法来预防和控制糖尿病，但大多数用于测量血糖水平的设备是有创的，不适合连续监测。在这里，我们提出了一种基于非侵入性光学光电脉搏图（PPG）的方法来检测糖尿病，以克服这些缺点。我们使用PPG信号和元数据对非糖尿病和糖尿病患者进行分类，用于训练逻辑回归（LR）和极限梯度提升（XGBoost）算法。我们使用了一个公开可用的数据集中的PPG信号。为了防止过拟合，我们将数据分成五个部分进行交叉验证。通过确保训练集中的患者不在测试集中，可以在未见过的受试者的数据上评估模型的性能，提供更准确的评估其泛化能力。我们的模型在F1-Score和AUC上分别达到了$58.8\pm20.0\%$和$7

    Diabetes is a prevalent chronic condition that compromises the health of millions of people worldwide. Minimally invasive methods are needed to prevent and control diabetes but most devices for measuring glucose levels are invasive and not amenable for continuous monitoring. Here, we present an alternative method to overcome these shortcomings based on non-invasive optical photoplethysmography (PPG) for detecting diabetes. We classify non-Diabetic and Diabetic patients using the PPG signal and metadata for training Logistic Regression (LR) and eXtreme Gradient Boosting (XGBoost) algorithms. We used PPG signals from a publicly available dataset. To prevent overfitting, we divided the data into five folds for cross-validation. By ensuring that patients in the training set are not in the testing set, the model's performance can be evaluated on unseen subjects' data, providing a more accurate assessment of its generalization. Our model achieved an F1-Score and AUC of $58.8\pm20.0\%$ and $7
    
[^70]: 一种基于Transformer的预测靶控输注丙泊酚和瑞芬太尼麻醉深度的方法

    A Transformer-based Prediction Method for Depth of Anesthesia During Target-controlled Infusion of Propofol and Remifentanil. (arXiv:2308.01929v1 [cs.LG])

    [http://arxiv.org/abs/2308.01929](http://arxiv.org/abs/2308.01929)

    这项研究提出了一种基于Transformer的方法来预测丙泊酚和瑞芬太尼的麻醉深度。该方法通过利用长短时记忆和门控残差网络来提高特征融合的效率，并应用注意机制来发现药物之间的相互作用。实验证明，该方法优于传统的PK-PD模型和先前的深度学习方法，能够有效预测麻醉深度。

    

    准确预测麻醉效果对于靶控输注系统至关重要。传统的药物动力学-药效学模型需要手动选择模型参数，在临床环境中可能具有挑战性。最近提出的深度学习方法只能捕捉到一般趋势，可能无法预测BIS的突变。为了解决这些问题，我们提出了一种基于Transformer的方法，利用丙泊酚和瑞芬太尼的药物输注来预测麻醉深度。我们的方法采用了长短时记忆（LSTM）和门控残差网络（GRN）来提高特征融合的效率，并应用了注意机制来发现药物之间的相互作用。我们还使用标签分布平滑和重新加权损失来处理数据不平衡。实验结果表明，我们提出的方法优于传统的PK-PD模型和先前的深度学习方法，能够有效预测麻醉深度。

    Accurately predicting anesthetic effects is essential for target-controlled infusion systems. The traditional (PK-PD) models for Bispectral index (BIS) prediction require manual selection of model parameters, which can be challenging in clinical settings. Recently proposed deep learning methods can only capture general trends and may not predict abrupt changes in BIS. To address these issues, we propose a transformer-based method for predicting the depth of anesthesia (DOA) using drug infusions of propofol and remifentanil. Our method employs long short-term memory (LSTM) and gate residual network (GRN) networks to improve the efficiency of feature fusion and applies an attention mechanism to discover the interactions between the drugs. We also use label distribution smoothing and reweighting losses to address data imbalance. Experimental results show that our proposed method outperforms traditional PK-PD models and previous deep learning methods, effectively predicting anesthetic dept
    
[^71]: 多重保护属性的公平性改善的实证研究

    An Empirical Study on Fairness Improvement with Multiple Protected Attributes. (arXiv:2308.01923v1 [cs.LG])

    [http://arxiv.org/abs/2308.01923](http://arxiv.org/abs/2308.01923)

    本文通过广泛研究，发现对于单个保护属性的公平性改善会大大降低对未考虑保护属性的公平性，但在多属性模式下可以保持准确性。

    

    现有研究主要关注单个保护属性的机器学习（ML）软件的公平性改善，但考虑到许多用户具有多个保护属性，这是不现实的。本文对多个保护属性的公平性改善进行了广泛研究，涵盖了11种最先进的公平性改善方法。我们分析了在考虑多个保护属性时，这些方法在不同数据集、评估指标和ML模型上的有效性。结果显示，改善单个保护属性的公平性大大降低了未考虑的保护属性的公平性。在88.3％的情况下观察到这种降低（平均为57.5％）。更令人惊讶的是，在考虑单个和多个保护属性时，准确率损失方面几乎没有差异，这表明在多属性模式下可以保持准确性。然而，在处理多个保护属性时，精确度和召回率的影响较大。

    Existing research mostly improves the fairness of Machine Learning (ML) software regarding a single protected attribute at a time, but this is unrealistic given that many users have multiple protected attributes. This paper conducts an extensive study of fairness improvement regarding multiple protected attributes, covering 11 state-of-the-art fairness improvement methods. We analyze the effectiveness of these methods with different datasets, metrics, and ML models when considering multiple protected attributes. The results reveal that improving fairness for a single protected attribute can largely decrease fairness regarding unconsidered protected attributes. This decrease is observed in up to 88.3% of scenarios (57.5% on average). More surprisingly, we find little difference in accuracy loss when considering single and multiple protected attributes, indicating that accuracy can be maintained in the multiple-attribute paradigm. However, the effect on precision and recall when handling
    
[^72]: 可转移的图神经指纹模型快速应对未来生物威胁

    Transferable Graph Neural Fingerprint Models for Quick Response to Future Bio-Threats. (arXiv:2308.01921v1 [q-bio.BM])

    [http://arxiv.org/abs/2308.01921](http://arxiv.org/abs/2308.01921)

    该论文提出了一种可转移的图神经指纹模型，用于快速应对未来的生物威胁。通过利用包含30万种候选药物和23个冠状病毒蛋白靶的COVID-19药物对接数据集，训练了高通量虚拟COVID-19药物筛选的图神经指纹模型。与传统指纹方法相比，该模型在对接得分上具有较高的预测准确性，并且提出了可转移的图神经指纹方法，能够适用于未知的靶点。

    

    基于配体结合亲和力的药物分子快速筛选是药物发现管线中的重要步骤。图神经指纹是一种用于开发高通量和高准确性分子对接代理的有希望方法。在这项研究中，我们建立了一个包含约30万种药物候选物和23个冠状病毒蛋白靶的COVID-19药物对接数据集。利用这个数据集，我们训练了图神经指纹对接模型，用于高通量虚拟COVID-19药物筛选。图神经指纹模型在对接得分上具有很高的预测准确性，对大多数对接靶点的均方误差低于0.21 kcal/mol，相比传统圆形指纹方法有显著改进。为了使神经指纹适用于未知的靶点，我们还提出了一种在多个靶点上训练的可转移的图神经指纹方法。

    Fast screening of drug molecules based on the ligand binding affinity is an important step in the drug discovery pipeline. Graph neural fingerprint is a promising method for developing molecular docking surrogates with high throughput and great fidelity. In this study, we built a COVID-19 drug docking dataset of about 300,000 drug candidates on 23 coronavirus protein targets. With this dataset, we trained graph neural fingerprint docking models for high-throughput virtual COVID-19 drug screening. The graph neural fingerprint models yield high prediction accuracy on docking scores with the mean squared error lower than $0.21$ kcal/mol for most of the docking targets, showing significant improvement over conventional circular fingerprint methods. To make the neural fingerprints transferable for unknown targets, we also propose a transferable graph neural fingerprint method trained on multiple targets. With comparable accuracy to target-specific graph neural fingerprint models, the transf
    
[^73]: 基于多模态电生理多头注意力对比学习的情感识别

    Emotion recognition based on multi-modal electrophysiology multi-head attention Contrastive Learning. (arXiv:2308.01919v1 [cs.MM])

    [http://arxiv.org/abs/2308.01919](http://arxiv.org/abs/2308.01919)

    ME-MHACL是一种基于自监督对比学习的多模态情感识别方法，通过从未标记的电生理信号中学习特征表示，并利用多头注意力机制进行特征融合，来提高情感识别性能。

    

    情感识别是人工智能中的一个重要研究方向，帮助机器理解和适应人类的情感状态。多模态电生理信号，如脑电图(EEG)，皮肤电(ED)，呼吸(Resp)和温度(Temp)，是反映人类情感变化的有效生物标志物。然而，利用电生理信号进行情感识别面临数据稀缺、标注不一致、难以在个体间泛化等挑战。为解决这些问题，我们提出了ME-MHACL，一种基于自监督对比学习的多模态情感识别方法，可以从未标记的电生理信号中学习有意义的特征表示，并利用多头注意力机制进行特征融合，提高识别性能。我们的方法包括两个阶段：首先，我们使用Meiosis方法对未标记的电生理信号进行样本组合和增强，并设计了自监督对比学习方法用于训练特征表示器；然后，我们使用多头注意力机制将多模态特征进行融合，从而实现情感识别。

    Emotion recognition is an important research direction in artificial intelligence, helping machines understand and adapt to human emotional states. Multimodal electrophysiological(ME) signals, such as EEG, GSR, respiration(Resp), and temperature(Temp), are effective biomarkers for reflecting changes in human emotions. However, using electrophysiological signals for emotion recognition faces challenges such as data scarcity, inconsistent labeling, and difficulty in cross-individual generalization. To address these issues, we propose ME-MHACL, a self-supervised contrastive learning-based multimodal emotion recognition method that can learn meaningful feature representations from unlabeled electrophysiological signals and use multi-head attention mechanisms for feature fusion to improve recognition performance. Our method includes two stages: first, we use the Meiosis method to group sample and augment unlabeled electrophysiological signals and design a self-supervised contrastive learnin
    
[^74]: 半监督元学习在时空学习中的应用

    Semi Supervised Meta Learning for Spatiotemporal Learning. (arXiv:2308.01916v1 [cs.CV])

    [http://arxiv.org/abs/2308.01916](http://arxiv.org/abs/2308.01916)

    本文探讨了半监督元学习在时空学习中的应用，通过将元学习应用于自监督遮蔽自编码器，并结合状态-of-the-art表示学习架构，提出了一种新的框架来解决视频重建和动作分类任务。

    

    我们通过三个步骤来将元学习应用于自监督遮蔽自编码器以进行时空学习。广义上说，我们旨在理解将元学习应用于现有的最先进的表示学习架构的影响。因此，我们通过以下方式测试时空学习：仅元学习架构、仅表示学习架构以及将表示学习与元学习架构相结合的架构。我们利用了增强记忆神经网络（MANN）架构将元学习应用于我们的框架。具体而言，我们首先尝试在小规模时空数据集上应用预训练的自监督遮蔽自编码器，并进行视频重建任务的微调。接下来，我们尝试训练自监督遮蔽自编码器的编码器，并应用分类头进行动作分类任务。最后，我们尝试在预训练的自监督遮蔽自编码器的基础上，用MANN骨干进行微调，用于动作分类任务。

    We approached the goal of applying meta-learning to self-supervised masked autoencoders for spatiotemporal learning in three steps. Broadly, we seek to understand the impact of applying meta-learning to existing state-of-the-art representation learning architectures. Thus, we test spatiotemporal learning through: a meta-learning architecture only, a representation learning architecture only, and an architecture applying representation learning alongside a meta learning architecture. We utilize the Memory Augmented Neural Network (MANN) architecture to apply meta-learning to our framework. Specifically, we first experiment with applying a pre-trained MAE and fine-tuning on our small-scale spatiotemporal dataset for video reconstruction tasks. Next, we experiment with training an MAE encoder and applying a classification head for action classification tasks. Finally, we experiment with applying a pre-trained MAE and fine-tune with MANN backbone for action classification tasks.
    
[^75]: 人工智能提高了全球可靠洪水预警的覆盖范围

    AI Increases Global Access to Reliable Flood Forecasts. (arXiv:2307.16104v1 [cs.LG])

    [http://arxiv.org/abs/2307.16104](http://arxiv.org/abs/2307.16104)

    本研究开发了一个人工智能模型，可以准确预测未经测量流域的极端水文事件，从而提高了全球洪水预警的覆盖范围。

    

    洪水是最常见和影响最大的自然灾害之一，对发展中国家尤其具有不对称的影响，这些国家往往缺乏密集的水流监测网络。准确及时的预警对于减轻洪水风险至关重要，但准确的水文模拟模型通常需要根据每个应用的流域中的长时间数据记录进行校准。我们开发了一个人工智能（AI）模型，可以预测7天内的极端水文事件。该模型在所有大洲、前导时间和重现期中均明显优于当前最先进的全球水文模型（Copernicus应急管理服务全球洪水意识系统）。AI在未经测量的流域中的预测尤其有效，这很重要，因为全球只有百分之几的流域具有流量观测站，而发展中国家的未经测量的流域数量占比很高，对人类特别脆弱。

    Floods are one of the most common and impactful natural disasters, with a disproportionate impact in developing countries that often lack dense streamflow monitoring networks. Accurate and timely warnings are critical for mitigating flood risks, but accurate hydrological simulation models typically must be calibrated to long data records in each watershed where they are applied. We developed an Artificial Intelligence (AI) model to predict extreme hydrological events at timescales up to 7 days in advance. This model significantly outperforms current state of the art global hydrology models (the Copernicus Emergency Management Service Global Flood Awareness System) across all continents, lead times, and return periods. AI is especially effective at forecasting in ungauged basins, which is important because only a few percent of the world's watersheds have stream gauges, with a disproportionate number of ungauged basins in developing countries that are especially vulnerable to the human 
    
[^76]: AI4GCC - 团队: 海平面以下: 评分和实际世界相关性

    AI4GCC - Team: Below Sea Level: Score and Real World Relevance. (arXiv:2307.13892v1 [cs.CY])

    [http://arxiv.org/abs/2307.13892](http://arxiv.org/abs/2307.13892)

    我们提出了一种谈判协议来解决碳泄漏问题，通过与代表性浓度路径和共享社会经济路径进行比较，我们的方法显示出了良好的效果，此外我们还分析了协议的合规性、可行性和伦理关切。

    

    作为我们参加AI for Global Climate Cooperation (AI4GCC)竞赛的第三项跟踪任务的提交，我们针对RICE-N气候经济模拟提出了一种谈判协议。我们的提议通过受到碳边境调整机制(CBAM)和气候俱乐部(CC)启发的方法来应对碳泄漏的挑战。我们通过将模拟结果与代表性浓度路径(RCP)和共享社会经济路径(SSP)进行比较，证明了我们方法的有效性。我们的协议导致了与RCP 3.4/4.5和SSP 2相当的温度上升。此外，我们对我们的协议的世界贸易组织合规性、行政和政治可行性以及伦理关切进行了分析。我们意识到我们的提议可能会对最不发达国家造成伤害，因此我们建议采取特定的纠正措施，避免加剧现有的不平等，例如技术共享和财富再分配。未来的研究应该改进...

    As our submission for track three of the AI for Global Climate Cooperation (AI4GCC) competition, we propose a negotiation protocol for use in the RICE-N climate-economic simulation. Our proposal seeks to address the challenges of carbon leakage through methods inspired by the Carbon Border Adjustment Mechanism (CBAM) and Climate Clubs (CC). We demonstrate the effectiveness of our approach by comparing simulated outcomes to representative concentration pathways (RCP) and shared socioeconomic pathways (SSP). Our protocol results in a temperature rise comparable to RCP 3.4/4.5 and SSP 2. Furthermore, we provide an analysis of our protocol's World Trade Organization compliance, administrative and political feasibility, and ethical concerns. We recognize that our proposal risks hurting the least developing countries, and we suggest specific corrective measures to avoid exacerbating existing inequalities, such as technology sharing and wealth redistribution. Future research should improve th
    
[^77]: 使用语法演化自动设计语义相似性集合

    Automatic Design of Semantic Similarity Ensembles Using Grammatical Evolution. (arXiv:2307.00925v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.00925](http://arxiv.org/abs/2307.00925)

    本研究首次使用语法演化自动设计语义相似性集合，通过自动选择和聚合候选度量来优化集合与人类判断的相关性，提高相似度评估准确性，并证明了使用集合对语义相似性任务的益处。

    

    语义相似性度量在自然语言处理中被广泛应用于多种与计算机相关的任务。然而，没有单一的语义相似性度量适用于所有任务，研究人员经常使用集合策略来确保性能。本研究提出了一种自动设计语义相似性集合的方法。事实上，我们提出的方法首次使用语法演化来自动选择和聚合一组候选度量，以创建一个最大化与人类判断相关性的集合。该方法在多个基准数据集上进行了评估，并与最先进的集合进行了比较，结果显示它可以显著提高相似度评估的准确性，并在某些情况下优于现有方法。因此，我们的研究既展示了使用语法演化来自动比较文本的潜力，也证明了使用集合对语义相似性任务的益处。

    Semantic similarity measures are widely used in natural language processing to catalyze various computer-related tasks. However, no single semantic similarity measure is the most appropriate for all tasks, and researchers often use ensemble strategies to ensure performance. This research work proposes a method for automatically designing semantic similarity ensembles. In fact, our proposed method uses grammatical evolution, for the first time, to automatically select and aggregate measures from a pool of candidates to create an ensemble that maximizes correlation to human judgment. The method is evaluated on several benchmark datasets and compared to state-of-the-art ensembles, showing that it can significantly improve similarity assessment accuracy and outperform existing methods in some cases. As a result, our research demonstrates the potential of using grammatical evolution to automatically compare text and prove the benefits of using ensembles for semantic similarity tasks. The so
    
[^78]: 人类和大型语言模型中的归纳推理

    Inductive reasoning in humans and large language models. (arXiv:2306.06548v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.06548](http://arxiv.org/abs/2306.06548)

    本研究使用GPT-3.5和GPT-4对人类归纳推理中的属性归纳问题进行了实验。结果表明，尽管GPT-3.5有一些困难，但GPT-4的表现与人类相似，除了未能捕捉到前提的非单调性现象。这项工作为人类和机器智能提供了有趣的比较，并提供了用作未来研究基准的两个大型数据集。

    

    大型语言模型的卓越性能引发了人们对其是否能作为普通智能的模型或类似于人类认知的程度的疑问。我们通过将GPT-3.5和GPT-4应用于人类归纳推理中的一个经典问题，即属性归纳，来解决这个问题。通过两个实验，我们获取了人类在多个领域上的属性归纳任务上的判断。尽管GPT-3.5在捕捉人类行为的许多方面上有困难，但GPT-4更加成功：在很大程度上，它的表现与人类的表现在质上相匹配，唯一显著的例外是其未能捕捉到前提的非单调性现象。我们的工作证明了属性归纳可以对人类和机器智能进行有趣的比较，并提供了两个大型数据集，可以作为未来在这一领域中的基准。

    The impressive recent performance of large language models has led many to wonder to what extent they can serve as models of general intelligence or are similar to human cognition. We address this issue by applying GPT-3.5 and GPT-4 to a classic problem in human inductive reasoning known as property induction. Over two experiments, we elicit human judgments on a range of property induction tasks spanning multiple domains. Although GPT-3.5 struggles to capture many aspects of human behaviour, GPT-4 is much more successful: for the most part, its performance qualitatively matches that of humans, and the only notable exception is its failure to capture the phenomenon of premise non-monotonicity. Our work demonstrates that property induction allows for interesting comparisons between human and machine intelligence and provides two large datasets that can serve as benchmarks for future work in this vein.
    
[^79]: Teacher Agent：一种基于重复训练的视频增量学习非知识蒸馏方法

    Teacher Agent: A Non-Knowledge Distillation Method for Rehearsal-based Video Incremental Learning. (arXiv:2306.00393v1 [cs.CV])

    [http://arxiv.org/abs/2306.00393](http://arxiv.org/abs/2306.00393)

    提出了一种教师代理方法，能够从先前学习的知识中生成高质量样本的数据集，从而使学生网络可以从样本的多种观点中进行学习，在标准基准上优于基于知识蒸馏的方法。

    

    随着基于视频的社交媒体的普及，不断有新的视频类别被生成，迫切需要稳健的增量学习技术来理解这些视频。其中最大的挑战之一是灾难性遗忘，在学习新类别的同时，网络往往会忘记先前学习过的数据。为了解决此问题，知识蒸馏是一种广泛使用的技术，它通过将不同类别之间的相似性的重要信息传输到学生模型中来增强其性能。因此，最好有一个强大的教师模型来指导学生。然而，网络本身的有限表现和灾难性遗忘的发生可能导致教师网络对某些记忆样本做出不准确的预测，从而限制了学生网络的性能。基于这些观察，我们提出了一种教师代理，能够从先前学习的知识中生成高质量样本的数据集，从而使学生网络可以从样本的多种观点中进行学习。我们的方法在视频分类任务的标准基准上优于基于知识蒸馏的方法。

    With the rise in popularity of video-based social media, new categories of videos are constantly being generated, creating an urgent need for robust incremental learning techniques for video understanding. One of the biggest challenges in this task is catastrophic forgetting, where the network tends to forget previously learned data while learning new categories. To overcome this issue, knowledge distillation is a widely used technique for rehearsal-based video incremental learning that involves transferring important information on similarities among different categories to enhance the student model. Therefore, it is preferable to have a strong teacher model to guide the students. However, the limited performance of the network itself and the occurrence of catastrophic forgetting can result in the teacher network making inaccurate predictions for some memory exemplars, ultimately limiting the student network's performance. Based on these observations, we propose a teacher agent capabl
    
[^80]: 基于大语言模型的推荐系统综述

    A Survey on Large Language Models for Recommendation. (arXiv:2305.19860v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2305.19860](http://arxiv.org/abs/2305.19860)

    本综述介绍了基于大语言模型的推荐系统，提出了判别式LLMs和生成式LLMs两种模型范式，总结了这些模型的最新进展，强调了该领域的挑战和研究方向。

    

    大语言模型（LLMs）已成为自然语言处理（NLP）领域强大的工具，并在推荐系统领域引起了重视。这些模型使用自监督学习在海量数据上进行训练，已在学习通用表示方面取得了显着成功，并有可能通过一些有效的转移技术（如微调和提示调整）等手段提高推荐系统的各个方面的性能。利用大语言模型增强推荐质量的关键是利用它们高质量的文本特征表示和大量的外部知识覆盖，建立项目和用户之间的相关性。为了全面了解现有基于LLM的推荐系统，本综述提出了一种分类法，将这些模型分为两种主要范式，分别是判别式LLMs和生成式LLMs。此外，我们总结了这些范式的最新进展，并强调了这个新兴领域的挑战和开放性研究问题。

    Large Language Models (LLMs) have emerged as powerful tools in the field of Natural Language Processing (NLP) and have recently gained significant attention in the domain of Recommendation Systems (RS). These models, trained on massive amounts of data using self-supervised learning, have demonstrated remarkable success in learning universal representations and have the potential to enhance various aspects of recommendation systems by some effective transfer techniques such as fine-tuning and prompt tuning, and so on. The crucial aspect of harnessing the power of language models in enhancing recommendation quality is the utilization of their high-quality representations of textual features and their extensive coverage of external knowledge to establish correlations between items and users. To provide a comprehensive understanding of the existing LLM-based recommendation systems, this survey presents a taxonomy that categorizes these models into two major paradigms, respectively Discrimi
    
[^81]: 缓解上下文学习的标签偏差

    Mitigating Label Biases for In-context Learning. (arXiv:2305.19148v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.19148](http://arxiv.org/abs/2305.19148)

    本文针对上下文学习（ICL）中的三种标签偏差提出分类法，并提出一种简单的偏差校准方法，使用随机的领域词估算语言模型的标签偏差。

    

    上下文学习（ICL）的各种设计设置，如选择和顺序的上下文示例，可能使模型对某种特定预测偏见，而这种预测并不反映对任务的理解。虽然许多研究讨论了这些设计选择，但对它们进行分类和减缓其影响的系统调查很少。在本文中，我们为文本分类中上下文学习（ICL）中的三种标签偏差定义了一个分类法：香草标签偏差、上下文标签偏差和领域标签偏差（我们首次概念化和检测到）。我们的分析表明，先前的标签偏差校准方法不能解决所有三种偏差。特别是，领域标签偏差使LLM在许多任务上只能实现随机级别的性能，而不管上下文示例的选择如何。为了缓解这些偏差的影响，我们提出一个简单的偏差校准方法，使用随机的领域词估算语言模型的标签偏差。

    Various design settings for in-context learning (ICL), such as the choice and order of the in-context examples, can bias a model toward a particular prediction without being reflective of an understanding of the task. While many studies discuss these design choices, there have been few systematic investigations into categorizing them and mitigating their impact. In this work, we define a typology for three types of label biases in ICL for text classification: vanilla-label bias, context-label bias, and domain-label bias (which we conceptualize and detect for the first time).  Our analysis demonstrates that prior label bias calibration methods fall short of addressing all three types of biases. Specifically, domain-label bias restricts LLMs to random-level performance on many tasks regardless of the choice of in-context examples. To mitigate the effect of these biases, we propose a simple bias calibration method that estimates a language model's label bias using random in-domain words f
    
[^82]: 模型扩散中的无标注文本实际上是卡通风格生成器

    Null-text Guidance in Diffusion Models is Secretly a Cartoon-style Creator. (arXiv:2305.06710v1 [cs.CV])

    [http://arxiv.org/abs/2305.06710](http://arxiv.org/abs/2305.06710)

    本文发现，模型扩散中的无标注文本实际上是一个能够生成卡通风格图片的工具。通过简单地扰动无标注文本指导，这一功能得以实现。回滚扰动能够将生成的图像有效转换成卡通图像，而图像扰动则能够产生高保真度、多样性的卡通图像。

    

    无分类器指导是扩散模型中被广泛采用的一种有效的采样技术。其主要思想是在文本指导方向上对模型进行外推，并远离无标注文本指导。在本文中，我们展示了模型扩散中的无标注文本实际上是一个卡通风格生成器，即通过简单地扰动无标注文本指导就可以有效地将生成的图像转换成卡通图像。具体地，我们提出了两种扰动方法：回滚扰动（Back-D）和图像扰动（Image-D），用于构造在采样过程中用于预测无标注文本指导和文本指导的嘈杂图像之间的错位。Back-D通过通过将$x_t$替换为$x_{t+\Delta t}$来改变无标注嘈杂图像的噪声水平从而实现卡通化。Image-D则通过产生高保真度、多样性的卡通图像。

    Classifier-free guidance is an effective sampling technique in diffusion models that has been widely adopted. The main idea is to extrapolate the model in the direction of text guidance and away from null-text guidance. In this paper, we demonstrate that null-text guidance in diffusion models is secretly a cartoon-style creator, i.e., the generated images can be efficiently transformed into cartoons by simply perturbing the null-text guidance. Specifically, we proposed two disturbance methods, i.e., Rollback disturbance (Back-D) and Image disturbance (Image-D), to construct misalignment between the noisy images used for predicting null-text guidance and text guidance (subsequently referred to as \textbf{null-text noisy image} and \textbf{text noisy image} respectively) in the sampling process. Back-D achieves cartoonization by altering the noise level of null-text noisy image via replacing $x_t$ with $x_{t+\Delta t}$. Image-D, alternatively, produces high-fidelity, diverse cartoons by 
    
[^83]: 多视图视觉提示融合网络：2D预训练模型能否增强3D点云数据稀缺学习？

    Multi-view Vision-Prompt Fusion Network: Can 2D Pre-trained Model Boost 3D Point Cloud Data-scarce Learning?. (arXiv:2304.10224v1 [cs.CV])

    [http://arxiv.org/abs/2304.10224](http://arxiv.org/abs/2304.10224)

    本文提出了一种针对3D点云分类的少样本学习网络MvNet，它能够利用现有的2D预训练模型来缓解现有基线模型对大规模注释3D点云数据的过度依赖问题。

    

    基于点云的3D深度模型在许多领域中具有广泛的应用，例如自动驾驶、家庭机器人等。本文提出了一种新颖的多视图视觉提示融合网络（MvNet），用于少样本3D点云分类，灵感源自于最近在自然语言处理中的提示性学习。MvNet 探讨了利用现有2D预训练模型实现少样本分类的可能性，这可以缓解现有基线模型对大规模注释3D点云数据的过度依赖问题。具体而言，MvNet首先将3D点云编码成多视图图像特征，然后开发了一种新的多视图提示融合模块，以有效地融合来自不同视角的信息，以弥合3D点云数据和2D预训练模型之间的差距。然后可以派生一组2D图像提示以更好地描述适当的先验知识以进行大规模预训练。

    Point cloud based 3D deep model has wide applications in many applications such as autonomous driving, house robot, and so on. Inspired by the recent prompt learning in natural language processing, this work proposes a novel Multi-view Vision-Prompt Fusion Network (MvNet) for few-shot 3D point cloud classification. MvNet investigates the possibility of leveraging the off-the-shelf 2D pre-trained models to achieve the few-shot classification, which can alleviate the over-dependence issue of the existing baseline models towards the large-scale annotated 3D point cloud data. Specifically, MvNet first encodes a 3D point cloud into multi-view image features for a number of different views. Then, a novel multi-view prompt fusion module is developed to effectively fuse information from different views to bridge the gap between 3D point cloud data and 2D pre-trained models. A set of 2D image prompts can then be derived to better describe the suitable prior knowledge for a large-scale pre-train
    
[^84]: SPeC：软提示校准在临床笔记摘要中降低性能变异的研究

    SPeC: A Soft Prompt-Based Calibration on Mitigating Performance Variability in Clinical Notes Summarization. (arXiv:2303.13035v1 [cs.CL])

    [http://arxiv.org/abs/2303.13035](http://arxiv.org/abs/2303.13035)

    研究通过引入软提示嵌入，提出Soft Prompt-Based Calibration (SPeC)管道，来减轻输入变量对输出多样性的影响，降低性能变异. 此方法不仅比大语言模型(LLM)性能稳定，而且在临床笔记摘要任务上表现优于最先进的模型.

    

    电子健康记录（EHR）存储着包括病历、诊断、治疗和检测结果在内的大量患者信息。这些记录对于医疗保健专业人员做出明智的患者护理决策非常关键。摘要临床笔记可以帮助医疗保健专业人员更好地发现潜在健康风险，以及做出更好的决策。这一过程通过确保医疗保健专业人员可以访问最相关和最新的患者数据，有助于减少错误并提高患者的护理效果。最近的研究表明，将提示与大语言模型（LLM）相结合可以显著提高摘要任务的效率。然而，我们发现这种方法也会导致输出方差增加，即使提示意义相似，输出也会有明显的差异。为了解决这一挑战，我们引入了一个模型无关的软提示校准（SPeC）流程，该流程采用软提示嵌入来减轻输入变量对输出多样性的影响。我们的实验表明，SPeC不仅可以降低LLM的性能变异，而且在临床笔记摘要任务上优于现有的最先进模型。

    Electronic health records (EHRs) store an extensive array of patient information, encompassing medical histories, diagnoses, treatments, and test outcomes. These records are crucial for enabling healthcare providers to make well-informed decisions regarding patient care. Summarizing clinical notes further assists healthcare professionals in pinpointing potential health risks and making better-informed decisions. This process contributes to reducing errors and enhancing patient outcomes by ensuring providers have access to the most pertinent and current patient data. Recent research has shown that incorporating prompts with large language models (LLMs) substantially boosts the efficacy of summarization tasks. However, we show that this approach also leads to increased output variance, resulting in notably divergent outputs even when prompts share similar meanings. To tackle this challenge, we introduce a model-agnostic Soft Prompt-Based Calibration (SPeC) pipeline that employs soft prom
    
[^85]: 音视频欺骗检测：DOLOS数据集和参数高效跨模态学习

    Audio-Visual Deception Detection: DOLOS Dataset and Parameter-Efficient Crossmodal Learning. (arXiv:2303.12745v1 [cs.CV])

    [http://arxiv.org/abs/2303.12745](http://arxiv.org/abs/2303.12745)

    该论文介绍了DOLOS数据集，这是最大的游戏节目欺骗检测数据集，包含1,675个视频片段和丰富的欺骗对话。同时，该论文提出了一种参数高效的跨模态学习方法（PECL），可以有效地学习多模态特征。

    

    对话中的欺诈检测是一项具有挑战性但非常重要的任务，在商业的可信度评估、多媒体防欺诈和定制安全等许多领域都有重要的应用。然而，由于缺乏高质量的欺诈数据集以及学习多模态特征的困难，欺诈检测研究受到了阻碍。为了解决这个问题，我们引入了DOLOS数据集，这是包含丰富的欺骗对话的最大游戏节目欺骗检测数据集。DOLOS包括1,675个视频片段，涉及213个被试者，并且已经用音视频特征注释进行了标注。我们提供了训练-测试、持续时间和性别协议来调查不同因素的影响。我们在先前提出的欺骗检测方法上对我们的数据集进行了基准测试。为了通过微调更少的参数进一步提高性能，我们提出了参数高效跨模态学习（PECL），其中统一时间适配器（UT-Adapter）探索时间

    Deception detection in conversations is a challenging yet important task, having pivotal applications in many fields such as credibility assessment in business, multimedia anti-frauds, and custom security. Despite this, deception detection research is hindered by the lack of high-quality deception datasets, as well as the difficulties of learning multimodal features effectively. To address this issue, we introduce DOLOS, the largest gameshow deception detection dataset with rich deceptive conversations. DOLOS includes 1,675 video clips featuring 213 subjects, and it has been labeled with audio-visual feature annotations. We provide train-test, duration, and gender protocols to investigate the impact of different factors. We benchmark our dataset on previously proposed deception detection approaches. To further improve the performance by fine-tuning fewer parameters, we propose Parameter-Efficient Crossmodal Learning (PECL), where a Uniform Temporal Adapter (UT-Adapter) explores tempora
    
[^86]: 一种用于按需乘车服务运营的多功能模拟平台

    A multi-functional simulation platform for on-demand ride service operations. (arXiv:2303.12336v1 [cs.AI])

    [http://arxiv.org/abs/2303.12336](http://arxiv.org/abs/2303.12336)

    本文介绍了一种用于按需乘车服务操作的多功能模拟平台，该平台具有高度的模块化，可扩展性和灵活性，在操作效率和公平性评估，优化算法调整以及实时动态操作控制等方面均能发挥作用，并为研究人员和实践者提供了一个公共的平台。

    

    过去十年中，按需乘车服务或乘车共享服务飞速发展。已经开发了各种数学模型和优化算法，帮助乘车共享平台设计更高效的运营策略。然而，由于成本和可靠性问题（对于真实操作实现不成熟的算法可能导致系统波动），在实际世界乘车共享平台内验证这些模型并训练/测试这些优化算法通常是不可行的。作为一个有用的测试平台，乘车共享系统的模拟平台将非常重要，以通过试验和误差进行算法训练/测试或模型验证。尽管先前的研究已经为他们自己的任务建立了各种模拟器，但缺少一个公正和公开的平台来比较不同研究人员提出的模型或算法。此外，现有的模拟器面临许多挑战，从灵活性、可扩展性到真实度都有。在本文中，我们介绍了一种用于按需乘车服务操作的多功能模拟平台，其具有高度的模块化、可扩展性和灵活性，能够实现各种用户场景和系统配置。我们通过几个案例研究展示了我们平台的有用性，包括操作效率和公平性评估，优化算法调整以及实时动态操作控制。我们的平台不仅为研究人员提供了一个比较各种算法和模型的公共平台，而且还可以由实践者直接使用，以提高他们的操作效率和用户体验。

    On-demand ride services or ride-sourcing services have been experiencing fast development in the past decade. Various mathematical models and optimization algorithms have been developed to help ride-sourcing platforms design operational strategies with higher efficiency. However, due to cost and reliability issues (implementing an immature algorithm for real operations may result in system turbulence), it is commonly infeasible to validate these models and train/test these optimization algorithms within real-world ride sourcing platforms. Acting as a useful test bed, a simulation platform for ride-sourcing systems will be very important to conduct algorithm training/testing or model validation through trails and errors. While previous studies have established a variety of simulators for their own tasks, it lacks a fair and public platform for comparing the models or algorithms proposed by different researchers. In addition, the existing simulators still face many challenges, ranging fr
    
[^87]: 对知识蒸馏的训练动态进行详细研究

    A closer look at the training dynamics of knowledge distillation. (arXiv:2303.11098v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.11098](http://arxiv.org/abs/2303.11098)

    本文对知识蒸馏的训练动态进行了详细研究，实验证明投影器的设计决策、表示的标准化和软最大函数的选择对学生的性能有着重要影响，同时提出了一种解决容量差异问题的简单方法，以及与当前最先进的知识蒸馏技术相媲美的计算效率更高的方法。

    

    本文重新审视将知识蒸馏作为函数匹配和度量学习问题时的有效性。通过验证三个重要设计决策，即标准化、软最大函数和投影层作为关键要素，我们有理论地显示出投影器隐含地编码了关于过去样本的信息，从而为学生提供了关联梯度。然后，我们展示了表示的标准化与投影器的训练动态密切相关，这可能对学生的性能产生重大影响。最后，我们展示了简单的软最大函数可以用来解决任何显著容量差异的问题。在各种基准数据集上的实验结果表明，利用这些见解可以实现与最先进的知识蒸馏技术相媲美或优于其性能，同时计算效率更高。特别是在图像分类任务上取得了这些结果。

    In this paper we revisit the efficacy of knowledge distillation as a function matching and metric learning problem. In doing so we verify three important design decisions, namely the normalisation, soft maximum function, and projection layers as key ingredients. We theoretically show that the projector implicitly encodes information on past examples, enabling relational gradients for the student. We then show that the normalisation of representations is tightly coupled with the training dynamics of this projector, which can have a large impact on the students performance. Finally, we show that a simple soft maximum function can be used to address any significant capacity gap problems. Experimental results on various benchmark datasets demonstrate that using these insights can lead to superior or comparable performance to state-of-the-art knowledge distillation techniques, despite being much more computationally efficient. In particular, we obtain these results across image classificati
    
[^88]: 意义深远的人类指令：作为实现自主武器系统道德和法律责任的方法的高级控制指令

    Meaningful human command: Advance control directives as a method to enable moral and legal responsibility for autonomous weapons systems. (arXiv:2303.06813v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.06813](http://arxiv.org/abs/2303.06813)

    本文探讨了如何确保在超越实时或非常缓慢的操作中的自主系统的道德和法律责任，并提出了建立“预先控制指令”框架的“自主命令”，来实现自主武器系统的问责和责任所需的深思熟虑的过程。

    

    21世纪战争的速度正在加快，常规部队与大规模使用自主系统和人机集成相结合。然而，一个重要的挑战是人类如何确保在正常时间参数之外运行的系统的道德和法律责任。本章考虑了人类是否可以站在实时之外，并通过先建立合同授权自主系统的行动，在未来的情况下特别是在超越实时或非常缓慢的操作中，人类的意识和集中力可能无法充分知情。在“预先医疗法律先例”中找到的经验表明，通过“预先控制指令”（ACD）可以实现武器系统的问责和责任所需的耗时、深思熟虑的过程，提出了“自主命令”的构想，并通过ACD的构建和法律伦理框架进行支撑和合法化。这将使自主武器系统的接受责任和问责制成为可能，并建立意义深远的人类控制。

    21st Century war is increasing in speed, with conventional forces combined with massed use of autonomous systems and human-machine integration. However, a significant challenge is how humans can ensure moral and legal responsibility for systems operating outside of normal temporal parameters. This chapter considers whether humans can stand outside of real time and authorise actions for autonomous systems by the prior establishment of a contract, for actions to occur in a future context particularly in faster than real time or in very slow operations where human consciousness and concentration could not remain well informed. The medical legal precdent found in 'advance care directives' suggests how the time-consuming, deliberative process required for accountability and responsibility of weapons systems may be achievable outside real time captured in an 'advance control driective' (ACD). The chapter proposes 'autonomy command' scaffolded and legitimised through the construction of ACD a
    
[^89]: 通过奖励塑形在基于情节的RL中利用多重抽象

    Exploiting Multiple Abstractions in Episodic RL via Reward Shaping. (arXiv:2303.00516v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00516](http://arxiv.org/abs/2303.00516)

    在这项工作中，我们通过引入一种新颖的奖励塑形形式，利用多层次的抽象来改善强化学习的效率，并且对抽象模型的设计要求较少，具有容忍性。

    

    强化学习（RL）在许多实际领域应用的一个主要限制是需要大量的样本来学习最优策略。为了解决这个问题并提高学习效率，我们考虑了基于目标领域的马尔可夫决策过程（MDP）的线性层次的抽象层次。每个层次都是一个表示比层次结构下方即刻模型更粗糙的模型的MDP。在这项工作中，我们提出了一种新颖的奖励塑形形式，其中在抽象层面获得的解决方案用于向更具体的MDP提供奖励，以使抽象解决方案指导更复杂领域中的学习。与层次RL中的其他工作相比，我们的技术在抽象模型的设计方面有很少的要求，并且也对建模错误具有容忍性，从而使所提出的方法变得实用。我们正式分析了抽象模型与引发探索启发式的关系

    One major limitation to the applicability of Reinforcement Learning (RL) to many practical domains is the large number of samples required to learn an optimal policy. To address this problem and improve learning efficiency, we consider a linear hierarchy of abstraction layers of the Markov Decision Process (MDP) underlying the target domain. Each layer is an MDP representing a coarser model of the one immediately below in the hierarchy. In this work, we propose a novel form of Reward Shaping where the solution obtained at the abstract level is used to offer rewards to the more concrete MDP, in such a way that the abstract solution guides the learning in the more complex domain. In contrast with other works in Hierarchical RL, our technique has few requirements in the design of the abstract models and it is also tolerant to modeling errors, thus making the proposed approach practical. We formally analyze the relationship between the abstract models and the exploration heuristic induced 
    
[^90]: 使用分位数回归森林的可解释上下文异常检测

    Explainable Contextual Anomaly Detection using Quantile Regression Forests. (arXiv:2302.11239v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.11239](http://arxiv.org/abs/2302.11239)

    该论文提出了一种可解释的上下文异常检测方法，运用分位数回归森林来模拟特征之间的依赖关系，能够更准确和可解释地识别偏离类似对象上下文的其他对象。

    

    传统的异常检测方法通过平等对待所有特征来识别偏离大多数其他对象的对象。相比之下，上下文异常检测方法通过将特征划分为上下文特征和行为特征，旨在检测偏离类似对象上下文的其他对象。在本文中，我们建立了依赖于传统的基于依赖的异常检测方法和上下文异常检测方法之间的联系。基于由此获得的见解，我们提出了一种新颖的方法，采用分位数回归森林来模拟特征之间的依赖关系，实现内在的可解释上下文异常检测。各种合成和真实世界数据集上的广泛实验表明，我们的方法在识别上下文异常方面的准确性和可解释性方面优于现有的状态-of-art异常检测方法。

    Traditional anomaly detection methods aim to identify objects that deviate from most other objects by treating all features equally. In contrast, contextual anomaly detection methods aim to detect objects that deviate from other objects within a context of similar objects by dividing the features into contextual features and behavioral features. In this paper, we develop connections between dependency-based traditional anomaly detection methods and contextual anomaly detection methods. Based on resulting insights, we propose a novel approach to inherently interpretable contextual anomaly detection that uses Quantile Regression Forests to model dependencies between features. Extensive experiments on various synthetic and real-world datasets demonstrate that our method outperforms state-of-the-art anomaly detection methods in identifying contextual anomalies in terms of accuracy and interpretability.
    
[^91]: 通过上下文调控实现通用形态控制

    Universal Morphology Control via Contextual Modulation. (arXiv:2302.11070v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.11070](http://arxiv.org/abs/2302.11070)

    本文提出了通过上下文调节实现通用形态控制的方法，包括使用超网络生成形态相关的控制参数以及利用固定的注意机制调节机器人中不同肢体之间的交互作用。这种方法可以提高学习效率和泛化能力。

    

    在连续控制中，学习一种适用于不同机器人形态的通用策略可以显著提高学习效率和泛化能力。然而，这会带来一个具有挑战性的多任务强化学习问题，因为最优策略可能在不同机器人之间有很大差异，并且严重依赖于形态。现有的方法利用图神经网络或transformers来处理不同形态之间的异构状态和动作空间，但对机器人的控制策略与形态上下文的依赖性关注较少。在本文中，我们提出了一种分层架构，通过上下文调节更好地建模这种依赖关系，其中包括两个关键子模块：（1）我们使用超网络生成形态相关的控制参数，而不是对机器人之间强制进行硬参数共享；（2）我们提出了一个固定的注意机制，仅依赖于形态，来调节机器人中不同肢体之间的交互作用。

    Learning a universal policy across different robot morphologies can significantly improve learning efficiency and generalization in continuous control. However, it poses a challenging multi-task reinforcement learning problem, as the optimal policy may be quite different across robots and critically depend on the morphology. Existing methods utilize graph neural networks or transformers to handle heterogeneous state and action spaces across different morphologies, but pay little attention to the dependency of a robot's control policy on its morphology context. In this paper, we propose a hierarchical architecture to better model this dependency via contextual modulation, which includes two key submodules: (1) Instead of enforcing hard parameter sharing across robots, we use hypernetworks to generate morphology-dependent control parameters; (2) We propose a fixed attention mechanism that solely depends on the morphology to modulate the interactions between different limbs in a robot. Ex
    
[^92]: DiSProD：用于规划的可微分符号分布传播

    DiSProD: Differentiable Symbolic Propagation of Distributions for Planning. (arXiv:2302.01491v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2302.01491](http://arxiv.org/abs/2302.01491)

    DiSProD是一个用于连续状态和动作空间中概率转移的在线规划器，它可以通过使用概率分布近似传播生成可微分的符号图表示策略价值，在处理稀疏奖励和随机环境方面优于现有规划器。

    

    该论文介绍了一个在线规划器DiSProD，用于处理连续状态和动作空间中概率转移的环境。DiSProD建立一个符号图，捕捉未来轨迹的分布，基于给定的策略，使用独立假设和概率分布的近似传播。该符号图提供了策略价值的可微分表示，使得可以进行长时间搜索的高效梯度优化。近似分布的传播可以看作是许多轨迹的聚合，非常适合处理稀疏奖励和随机环境。通过在离散时间规划和实时控制机器人系统方面进行广泛的实验性评估，该论文将DiSProD与最先进的规划器进行了比较。所提出的方法在处理随机环境、对搜索深度的敏感性、奖励的稀疏性和大的动作空间方面比现有规划器有所提高。

    The paper introduces DiSProD, an online planner developed for environments with probabilistic transitions in continuous state and action spaces. DiSProD builds a symbolic graph that captures the distribution of future trajectories, conditioned on a given policy, using independence assumptions and approximate propagation of distributions. The symbolic graph provides a differentiable representation of the policy's value, enabling efficient gradient-based optimization for long-horizon search. The propagation of approximate distributions can be seen as an aggregation of many trajectories, making it well-suited for dealing with sparse rewards and stochastic environments. An extensive experimental evaluation compares DiSProD to state-of-the-art planners in discrete-time planning and real-time control of robotic systems. The proposed method improves over existing planners in handling stochastic environments, sensitivity to search depth, sparsity of rewards, and large action spaces. Additional
    
[^93]: 大型语言模型中的类比推理的紧急性

    Emergent Analogical Reasoning in Large Language Models. (arXiv:2212.09196v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.09196](http://arxiv.org/abs/2212.09196)

    GPT-3在许多类比任务中表现出与甚至超越人类的能力，揭示了大型语言模型的紧急能力。

    

    大型语言模型的出现重新点燃了人们对于这样一种问题的辩论：足够的训练数据是否能使这些通用模型内涵人类认知能力。特别的，这些模型的零样本推理能力——不经过任何直接训练，就能够推理出新问题，特别令人关注。在人类认知中，这种能力与一种通过类比推理的能力密切相关。在本文中，我们在一系列类比任务中进行了直接的人机比较，包括一种新颖的基于文本的矩阵推理任务，该任务与 Raven's Progressive Matrices密切相关。我们发现，GPT-3呈现出了一种令人惊讶的抽象模式归纳能力，甚至在大部分情况下与或甚至超越了人类的能力。我们的结果表明，像GPT-3这样的大型语言模型已经获得了在广泛的类比问题上找到零样本解决方案的紧急能力。

    The recent advent of large language models has reinvigorated debate over whether human cognitive capacities might emerge in such generic models given sufficient training data. Of particular interest is the ability of these models to reason about novel problems zero-shot, without any direct training. In human cognition, this capacity is closely tied to an ability to reason by analogy. Here, we performed a direct comparison between human reasoners and a large language model (the text-davinci-003 variant of GPT-3) on a range of analogical tasks, including a novel text-based matrix reasoning task closely modeled on Raven's Progressive Matrices. We found that GPT-3 displayed a surprisingly strong capacity for abstract pattern induction, matching or even surpassing human capabilities in most settings. Our results indicate that large language models such as GPT-3 have acquired an emergent ability to find zero-shot solutions to a broad range of analogy problems.
    
[^94]: 未知动态马尔可夫跳变线性系统的形式化控制器合成

    Formal Controller Synthesis for Markov Jump Linear Systems with Uncertain Dynamics. (arXiv:2212.00679v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2212.00679](http://arxiv.org/abs/2212.00679)

    本文介绍了一种方法，用于合成马尔可夫跳变线性系统（MJLS）的控制器，以确保满足概率计算树逻辑（PCTL）公式，对于转移概率未知或已知但存在一定的区间的问题提出了解决方案。

    

    在安全关键场景中，对于控制器的自动化合成可以确保系统的正确性至关重要。然而，混合特性和随机或未知的行为使得合成控制器的问题变得具有挑战性。本论文提出了一种方法，用于合成马尔可夫跳变线性系统（MJLS）的控制器，这是一类离散时钟模型的控制器，用于解决这些系统的安全问题，以确保满足概率计算树逻辑（PCTL）公式。一个MJLS由一组有限的随机线性动态和这些动态之间的离散跳变组成，这些跳变由一个马尔可夫决策过程（MDP）来管理。我们考虑了这个MDP的转移概率未知或已知但存在一定的区间。我们的方法基于一个有限状态抽象，捕捉了MJLS的离散（模式跳跃）和连续（随机线性）行为。我们将这个抽象形式化为一个区间MDP（iMDP），然后计算了状态转移区间。

    Automated synthesis of provably correct controllers for cyber-physical systems is crucial for deployment in safety-critical scenarios. However, hybrid features and stochastic or unknown behaviours make this problem challenging. We propose a method for synthesising controllers for Markov jump linear systems (MJLSs), a class of discrete-time models for cyber-physical systems, so that they certifiably satisfy probabilistic computation tree logic (PCTL) formulae. An MJLS consists of a finite set of stochastic linear dynamics and discrete jumps between these dynamics that are governed by a Markov decision process (MDP). We consider the cases where the transition probabilities of this MDP are either known up to an interval or completely unknown. Our approach is based on a finite-state abstraction that captures both the discrete (mode-jumping) and continuous (stochastic linear) behaviour of the MJLS. We formalise this abstraction as an interval MDP (iMDP) for which we compute intervals of tra
    
[^95]: 国际空间站自动紧急无尘解决方案: 带有Bi-GRU的(AED-ISS)

    Automatic Emergency Dust-Free solution on-board International Space Station with Bi-GRU (AED-ISS). (arXiv:2210.08549v2 [stat.AP] UPDATED)

    [http://arxiv.org/abs/2210.08549](http://arxiv.org/abs/2210.08549)

    该论文旨在解决国际空间站上颗粒物对仪器的危害问题，通过Bi-GRU算法构建早期预警系统，预测颗粒物水平，并为宇航员提供充足的反应时间。这项研究还有潜力发展为与火灾相关的遥感烟雾报警装置。

    

    随着对PM2.5或PM0.3问题的关注不断增加，颗粒物不仅对环境和人类构成潜在威胁，而且对国际空间站上的仪器也会产生不利影响。本研究团队旨在将各种颗粒物浓度与磁场、湿度、加速度、温度、压力和CO2浓度关联起来。我们的目标是建立一个早期预警系统(EWS)，能够预测颗粒物水平，并为宇航员提供充足的反应时间，以保护他们在某些实验中的仪器，或者提高测量的准确性；此外，所构建的模型还可以进一步发展为与火灾相关的遥感烟雾报警装置的原型。本文中，我们将实现Bi-GRU(双向门控循环单元)算法，收集过去90分钟的数据，并预测超过2.5微米的颗粒物水平。

    With a rising attention for the issue of PM2.5 or PM0.3, particulate matters have become not only a potential threat to both the environment and human, but also a harming existence to instruments onboard International Space Station (ISS). Our team is aiming to relate various concentration of particulate matters to magnetic fields, humidity, acceleration, temperature, pressure and CO2 concentration. Our goal is to establish an early warning system (EWS), which is able to forecast the levels of particulate matters and provides ample reaction time for astronauts to protect their instruments in some experiments or increase the accuracy of the measurements; In addition, the constructed model can be further developed into a prototype of a remote-sensing smoke alarm for applications related to fires. In this article, we will implement the Bi-GRU (Bidirectional Gated Recurrent Unit) algorithms that collect data for past 90 minutes and predict the levels of particulates which over 2.5 micromete
    
[^96]: SSIVD-Net：一种新的武器化暴力显著超级图像分类和检测技术

    SSIVD-Net: A Novel Salient Super Image Classification & Detection Technique for Weaponized Violence. (arXiv:2207.12850v6 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2207.12850](http://arxiv.org/abs/2207.12850)

    本文提出了一种名为SSIVD-Net的新技术，用于暴力识别任务。通过使用显著-超级图像表示减少了3D视频数据的复杂性，提高了推断、性能和可解释性。作者还提出了一种新颖的架构“Salient-Classifier”，将核方法和残差学习策略相结合。该方法在多个数据集上表现良好。

    

    在闭路电视（CCTV）监控录像中检测暴力和武器化暴力需要一个全面的方法。本文引入了“智慧城市CCTV暴力检测（SCVD）”数据集，旨在促进对监控视频中武器分布的学习。为了解决分析3D监控视频进行暴力识别任务的复杂性，我们提出了一种新技术，称为SSIVD-Net（用于暴力检测的显著-超级-图像），通过使用显著-超级图像表示减少3D视频数据复杂性、降维和信息损失，同时提高推断、性能和可解释性。考虑到未来智慧城市的可扩展性和可持续性要求，作者提出了一种新颖的架构“Salient-Classifier”，将核方法和残差学习策略相结合。我们评估了SSIVD-Net在SCVD、Hockey Fight、Moviescope以及Large-Scale Fight Detection数据集上的性能，并与现有算法进行了比较。

    Detection of violence and weaponized violence in closed-circuit television (CCTV) footage requires a comprehensive approach. In this work, we introduce the \emph{Smart-City CCTV Violence Detection (SCVD)} dataset, specifically designed to facilitate the learning of weapon distribution in surveillance videos. To tackle the complexities of analyzing 3D surveillance video for violence recognition tasks, we propose a novel technique called, \emph{SSIVD-Net} (\textbf{S}alient-\textbf{S}uper-\textbf{I}mage for \textbf{V}iolence \textbf{D}etection). Our method reduces 3D video data complexity, dimensionality, and information loss while improving inference, performance, and explainability through the use of Salient-Super-Image representations. Considering the scalability and sustainability requirements of futuristic smart cities, the authors introduce the \emph{Salient-Classifier}, a novel architecture combining a kernelized approach with a residual learning strategy. We evaluate variations of
    
[^97]: 在内存限制下用于数据流分类的Mondrian Forest论文

    Mondrian Forest for Data Stream Classification Under Memory Constraints. (arXiv:2205.07871v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.07871](http://arxiv.org/abs/2205.07871)

    本文将在线Mondrian Forest分类算法适应到在数据流上具有内存限制的情况下，并设计了内存不足策略和修剪机制。研究表明，在所有配置中，Extend Node策略是最佳的内存不足策略。

    

    监督学习算法通常假设在训练和测试阶段有足够的内存来存储数据模型。然而，在物联网中，当数据以无限数据流的形式出现时，或者当学习算法部署在具有较少内存的设备上时，这个假设是不现实的。在本文中，我们将在线Mondrian Forest分类算法适应到在数据流上具有内存限制的情况下。具体而言，我们设计了五种内存不足策略，以在达到内存限制时更新Mondrian树的新数据点。此外，我们设计了修剪机制，在内存限制下使Mondrian树对概念漂移更加稳健。我们在各种真实和模拟数据集上评估了我们的算法，并最后给出了在不同情况下使用它们的建议：在所有配置中，Extend Node策略似乎是最佳的内存不足策略，而修剪机制则因具体情况而异。

    Supervised learning algorithms generally assume the availability of enough memory to store their data model during the training and test phases. However, in the Internet of Things, this assumption is unrealistic when data comes in the form of infinite data streams, or when learning algorithms are deployed on devices with reduced amounts of memory. In this paper, we adapt the online Mondrian forest classification algorithm to work with memory constraints on data streams. In particular, we design five out-of-memory strategies to update Mondrian trees with new data points when the memory limit is reached. Moreover, we design trimming mechanisms to make Mondrian trees more robust to concept drifts under memory constraints. We evaluate our algorithms on a variety of real and simulated datasets, and we conclude with recommendations on their use in different situations: the Extend Node strategy appears as the best out-of-memory strategy in all configurations, whereas different trimming mechan
    

