# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Point-Bind & Point-LLM: Aligning Point Cloud with Multi-modality for 3D Understanding, Generation, and Instruction Following.](http://arxiv.org/abs/2309.00615) | Point-Bind和Point-LLM是用于3D理解、生成和指导跟随的多模态点云对齐模型，能实现任意到3D生成、3D嵌入算术和3D开放世界的理解，并且Point-LLM能实现3D和多模态问答功能。 |
| [^2] | [Iterative Multi-granular Image Editing using Diffusion Models.](http://arxiv.org/abs/2309.00613) | 本研究提出了一种名为EMILIE的迭代多粒度图像编辑器，通过重新利用预训练的扩散模型来实现迭代编辑，并引入梯度控制操作来实现对图像编辑的粒度控制。 |
| [^3] | [Curating Naturally Adversarial Datasets for Trustworthy AI in Healthcare.](http://arxiv.org/abs/2309.00543) | 提出了一种方法来筛选自然对立示例的数据集，以评估模型的鲁棒性，并通过自动弱监督标注获得的概率标签来实现这一方法。 |
| [^4] | [Learning-based NLOS Detection and Uncertainty Prediction of GNSS Observations with Transformer-Enhanced LSTM Network.](http://arxiv.org/abs/2309.00480) | 本研究提出了一种基于深度学习的方法，通过构建Transformer-like注意机制增强LSTM网络，检测GNSS观测中的NLOS接收并预测GNSS伪距误差，从而提高了车辆定位的精度和系统的可靠性。 |
| [^5] | [A Theoretical and Practical Framework for Evaluating Uncertainty Calibration in Object Detection.](http://arxiv.org/abs/2309.00464) | 本文提出了一种评估目标检测中不确定性校准的理论和实践框架，并通过实验证明了所提出指标的有效性。 |
| [^6] | [New metrics for analyzing continual learners.](http://arxiv.org/abs/2309.00462) | 该论文提出了分析持续学习者的新指标，针对现有指标的局限性进行了分析，并提出解决了分类任务逐渐增加难度的问题。 |
| [^7] | [CPSP: Learning Speech Concepts From Phoneme Supervision.](http://arxiv.org/abs/2309.00424) | 论文提出了一种名为CPSP的方法，通过对比学习来从语音中提取细粒度的中间表示，使得提取的信息既包含语言内容又去除了发言人身份和声学细节，适用于TTS、VC和ASR等任务。 |
| [^8] | [Declarative Reasoning on Explanations Using Constraint Logic Programming.](http://arxiv.org/abs/2309.00422) | 这项研究提出了使用约束逻辑编程进行解释性推理的方法，可以为决策树提供声明性、交互式的解释，克服了当前解释方法中对背景知识的不充分结合和与用户的缺乏抽象和互动的问题。 |
| [^9] | [Area-norm COBRA on Conditional Survival Prediction.](http://arxiv.org/abs/2309.00417) | 本文提出了一种基于组合回归的条件生存预测方法，其中使用面积作为相似度度量，通过选择最重要的变量来提高模型性能。 |
| [^10] | [Boosting AND/OR-Based Computational Protein Design: Dynamic Heuristics and Generalizable UFO.](http://arxiv.org/abs/2309.00408) | 该研究专注于提升蛋白质重设计算法AOBB-K*的扩展性，通过引入增强版、带有动态启发式和带有下溢优化的新版本，显著提升了其可扩展性。 |
| [^11] | [Dense Voxel 3D Reconstruction Using a Monocular Event Camera.](http://arxiv.org/abs/2309.00385) | 这项研究探索了使用单目事件相机进行稠密体素三维重建的应用。以往的研究主要集中在深度图估计方面，而本研究提出了一种利用单个事件相机进行稠密三维重建的方法，并在虚拟现实应用中进行了探索。 |
| [^12] | [Scenario-based model predictive control of water reservoir systems.](http://arxiv.org/abs/2309.00373) | 针对水库系统的最优操作问题，本文首次提出了一种基于场景的随机模型预测控制方法。通过直接从过去数据生成未来水流的一组可能情景，优化控制策略，使控制器更加谨慎，同时满足农业用水需求，并应对干旱期的挑战。 |
| [^13] | [Discrete Versus Continuous Algorithms in Dynamics of Affective Decision Making.](http://arxiv.org/abs/2309.00357) | 本文比较了情感决策制定中离散和连续算法的表现，并发现根据网络参数的不同，两种算法可能得到不同的理论预测，这对于实际问题的描述具有重要影响。 |
| [^14] | [Explainable Active Learning for Preference Elicitation.](http://arxiv.org/abs/2309.00356) | 本研究关注于冷启动问题中的偏好获取，在该问题中，推荐系统缺乏用户存在或访问其他用户数据受限。我们采用可解释的主动学习方法，通过最小化用户工作量最大化信息获取，并在偏好获取过程中采用无监督、半监督和监督机器学习方法。 |
| [^15] | [A Text-based Approach For Link Prediction on Wikipedia Articles.](http://arxiv.org/abs/2309.00317) | 本研究提出了一种基于文本的维基百科文章链接预测方法，通过利用传统的机器学习模型和词性标注特征，实现了对两个节点是否有链接的分类预测，并在比赛中取得了较高的成绩。 |
| [^16] | [On the Aggregation of Rules for Knowledge Graph Completion.](http://arxiv.org/abs/2309.00306) | 本论文研究了知识图谱补全的规则聚合问题，证明了现有的聚合方法可以表达为对预测规则的边际推断操作，并提出了一个高效且被忽视的基准方法，与计算代价更高的方法竞争。 |
| [^17] | [Identifiable Cognitive Diagnosis with Encoder-decoder for Modelling Students' Performance.](http://arxiv.org/abs/2309.00300) | 本文提出了一个可识别的认知诊断框架，该框架能够从学生的答题记录中直接诊断可识别和可解释的考生特征和题目特征，并通过重建答题记录来确保诊断结果的可识别性。 |
| [^18] | [End-to-end Lidar-Driven Reinforcement Learning for Autonomous Racing.](http://arxiv.org/abs/2309.00296) | 本研究提出了一种基于激光雷达的端到端强化学习方法，用于解决在汽车赛车领域中复杂环境下的自主导航问题，并通过实验验证了该方法的可行性和潜力。 |
| [^19] | [RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback.](http://arxiv.org/abs/2309.00267) | RLAIF是一种新的强化学习方法，利用AI反馈代替人类标注偏好，相比强化学习从人类反馈中学习（RLHF），在摘要任务上取得了类似的改进效果，并且在人类评估中得到了相同的认可。这提供了一种有潜力解决RLHF的可扩展性限制的解决方案。 |
| [^20] | [Leveraging Learning Metrics for Improved Federated Learning.](http://arxiv.org/abs/2309.00257) | 本论文将联邦学习与学习度量方法相结合，提出了首个联邦学习度量聚合方法，并证明了有效秩适用于联邦问题，并通过开发新型权重聚合方案取得了优于基准的联邦平均效果。 |
| [^21] | [DiffuGen: Adaptable Approach for Generating Labeled Image Datasets using Stable Diffusion Models.](http://arxiv.org/abs/2309.00248) | DiffuGen是一种利用稳定扩散模型高效生成标记图像数据集的简单而可适应的方法，并结合无监督和监督标注技术，以确保生成数据集的质量和提供多功能解决方案。 |
| [^22] | [City electric power consumption forecasting based on big data & neural network under smart grid background.](http://arxiv.org/abs/2309.00245) | 本论文利用大数据和神经网络，考虑了各种非线性因素，建立了一个模型来预测城市电力消费，为智能电网和智能城市提供重要参考。 |
| [^23] | [FactLLaMA: Optimizing Instruction-Following Language Models with External Knowledge for Automated Fact-Checking.](http://arxiv.org/abs/2309.00240) | 本研究提出了一种结合外部知识检索来增强指令追踪语言模型的自动事实核查方法，通过利用搜索引擎检索相关证据，并指导调整语言模型，从而提高了事实核查的准确性。 |
| [^24] | [ALJP: An Arabic Legal Judgment Prediction in Personal Status Cases Using Machine Learning Models.](http://arxiv.org/abs/2309.00238) | 这项研究开发了一个使用深度学习和自然语言处理技术预测阿拉伯个人身份案件法律判决的系统，有助于改进法官和律师的工作效率，减少判决差异，并帮助诉讼当事人事先分析案件的可能结果。 |
| [^25] | [Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes.](http://arxiv.org/abs/2309.00237) | 使用合成临床记录构建的临床大语言模型可以克服临床记录的有限可及性和可用性的问题，并在现实应用中表现出潜在的良好性能。 |
| [^26] | [Large Language Models for Semantic Monitoring of Corporate Disclosures: A Case Study on Korea's Top 50 KOSPI Companies.](http://arxiv.org/abs/2309.00208) | 本研究探讨了OpenAI的GPT-3.5-turbo和GPT-4在韩国上市公司披露中的语义分析能力，并发现GPT-4在人类评估中表现出显著的准确性。 |
| [^27] | [Gap and Overlap Detection in Automated Fiber Placement.](http://arxiv.org/abs/2309.00206) | 本文介绍了一种新方法，利用光学相干断层扫描（OCT）传感器和计算机视觉技术，在自动化纤维放置（AFP）中检测和定位复合零件中的间隙和重叠。 |
| [^28] | [Subjectivity in Unsupervised Machine Learning Model Selection.](http://arxiv.org/abs/2309.00201) | 无监督机器学习模型选择具有主观性，模型选择结果受模型构建者偏好的影响，并可能导致选择的不一致性。需要对模型选择过程进行更加深入的研究和标准化。 |
| [^29] | [Diffusion Model with Clustering-based Conditioning for Food Image Generation.](http://arxiv.org/abs/2309.00199) |  |
| [^30] | [Detecting Evidence of Organization in groups by Trajectories.](http://arxiv.org/abs/2309.00172) | 本文介绍了两种新的方法来检测基于代理轨迹的网络结构推理，通过评估图熵和聚类指数的质量，这些方法在动物模拟实验中表现出了更好的效果。 |
| [^31] | [LLM in the Shell: Generative Honeypots.](http://arxiv.org/abs/2309.00155) | 本研究引入了一种基于大型语言模型的新方法来创建动态和真实的软件蜜罐，解决了以往蜜罐的重要局限性，并通过实验验证了其高准确率。 |
| [^32] | [Fuzzy Approach for Audio-Video Emotion Recognition in Computer Games for Children.](http://arxiv.org/abs/2309.00138) | 本文提出了一种基于模糊方法的框架，通过分析音视频数据来识别儿童游戏中的情感。使用FER数据集检测面部表情，使用CREMA-D、TESS、RAVDESS和Savee数据集识别声音情感，然后通过模糊推理系统融合结果。系统还能检测情感稳定性和多样性。 |
| [^33] | [Predicting Financial Market Trends using Time Series Analysis and Natural Language Processing.](http://arxiv.org/abs/2309.00136) | 本研究通过分析推文中表达的情绪，使用时间序列分析和自然语言处理预测了特斯拉、苹果等主要公司股票价格的波动。结果表明，积极性、消极性和主观性是股票价格波动的主要决定因素。 |
| [^34] | [Construction Grammar and Artificial Intelligence.](http://arxiv.org/abs/2309.00135) | 建构语法和人工智能之间有着紧密的关系，人工智能领域的洞见和技术对于操作化建构主义方法以及构建智能代理非常重要。 |
| [^35] | [Open-Vocabulary Semantic Segmentation via Attribute Decomposition-Aggregation.](http://arxiv.org/abs/2309.00096) | 本研究提出了一种通过属性分解聚合的框架来解决开放词汇语义分割中存在的问题，该框架受到人类认知解释新概念的启发。 |
| [^36] | [Large language models in medicine: the potentials and pitfalls.](http://arxiv.org/abs/2309.00087) | 医学中大规模语言模型（LLMs）的潜力和风险。LLMs已经被广泛应用于医疗任务，但在使用时存在潜在的问题。本文回顾了LLMs的发展、应用和可能的限制，以帮助医疗从业者理解和应对LLMs在医学中的挑战。 |
| [^37] | [RePo: Resilient Model-Based Reinforcement Learning by Regularizing Posterior Predictability.](http://arxiv.org/abs/2309.00082) | 本文提出了RePo算法，通过正则化后验可预测性的方式，增强了视觉模型基础强化学习方法的弹性。该方法通过学习一个对冗余和伪变化具有弹性的潜在表示，提高了方法对视觉干扰的鲁棒性，使其能够在动态环境中运行。 |
| [^38] | [On the Implicit Bias of Adam.](http://arxiv.org/abs/2309.00079) | 本文证明了RMSProp和Adam存在隐式规范化作用，其取决于超参数和训练阶段，并讨论了这些证明事实对泛化的影响。 |
| [^39] | [YaRN: Efficient Context Window Extension of Large Language Models.](http://arxiv.org/abs/2309.00071) | YaRN是一种高效的上下文窗口扩展方法，可以在大型语言模型中有效利用和推断比原始预训练允许的上下文长度更长的上下文，同时超越了之前的最新研究成果。 |
| [^40] | [Ethical Framework for Harnessing the Power of AI in Healthcare and Beyond.](http://arxiv.org/abs/2309.00064) | 这篇论文研究了与人工智能技术在医疗保健领域快速发展密切相关的伦理维度，并提出了一个以透明度、公平性、问责性和以人为本为核心价值的伦理框架。 |
| [^41] | [FACET: Fairness in Computer Vision Evaluation Benchmark.](http://arxiv.org/abs/2309.00035) | FACET是一个用于评估计算机视觉模型公平性的大型基准，提供了可公开访问的图像集，对于常见的视觉任务进行了标注，同时使用专家评审员手动标注人类属性和类别信息，并用于对最先进的视觉模型进行基准测试。 |
| [^42] | [Exploring the Potential of Large Language Models to Generate Formative Programming Feedback.](http://arxiv.org/abs/2309.00029) | 本文探索了大型语言模型（LLM）在计算机教育方面的潜力，研究了其在编程任务中生成的反馈，结果表明学生可以从中受益，但教育者应该提供使用指导。 |
| [^43] | [Unsupervised discovery of Interpretable Visual Concepts.](http://arxiv.org/abs/2309.00018) | 本文提出了两种方法（MAGE和Ms-IV），用于解释深度学习模型的决策，提高全局可解释性。MAGE可以发现形成语义含义的特征组合，将其称为概念，并通过聚类分组为“概念”，然后通过Ms-IV进行可视化。这一方法受到阻断和敏感性分析的启发，并使用一种新的指标（CaOC）全局评估模型最重要的图像区域。 |
| [^44] | [Irregular Traffic Time Series Forecasting Based on Asynchronous Spatio-Temporal Graph Convolutional Network.](http://arxiv.org/abs/2308.16818) | 该论文提出了一种基于异步时空图卷积网络的不规则交通时间序列预测方法，用于解决智能交叉口产生的异步空间依赖、不规则时间依赖和可变长度序列预测等挑战。 |
| [^45] | [Robust Networked Federated Learning for Localization.](http://arxiv.org/abs/2308.16737) | 本文提出了一种鲁棒的网络化联邦学习方法，通过采用$L_1$-范数鲁棒性和分布式次梯度框架，解决了在分布式环境中定位问题中的异常数据干扰和算法收敛挑战。 |
| [^46] | [Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations.](http://arxiv.org/abs/2308.16505) | 本论文的创新点是将推荐模型和大型语言模型（LLMs）融合，创建了一个多功能交互式推荐系统，解决了推荐模型在提供解释和参与对话任务方面的困难。 |
| [^47] | [Calibrated Explanations for Regression.](http://arxiv.org/abs/2308.16245) | 本文介绍了一种针对回归问题的特征重要性解释方法的扩展，可以量化特征重要性的不确定性。 |
| [^48] | [Is the U.S. Legal System Ready for AI's Challenges to Human Values?.](http://arxiv.org/abs/2308.15906) | 美国法律需要加强应对生成式人工智能对人类价值观挑战的能力，并提供积极、可审计的指导，以填补现有法律框架在保护基本价值观方面的空白和不确定性。 |
| [^49] | [Efficient and Explainable Graph Neural Architecture Search via Monte-Carlo Tree Search.](http://arxiv.org/abs/2308.15734) | 该论文提出了一种高效且可解释的图神经网络架构搜索方法，名为ExGNAS。它包括适应各种图形的简单搜索空间和能解释决策过程的搜索算法。通过蒙特卡洛树搜索高效地搜索最佳GNN架构。 |
| [^50] | [A Comprehensive Augmentation Framework for Anomaly Detection.](http://arxiv.org/abs/2308.15068) | 本文提出了一种用于异常检测的综合增强框架，该框架通过选择性地利用适当的组合，分析并压缩模拟异常的关键特征，与基于重构的方法相结合，并采用分割训练策略，能够在MVTec异常检测数据集上优于以前的最先进方法。 |
| [^51] | [On Reward Structures of Markov Decision Processes.](http://arxiv.org/abs/2308.14919) | 该论文研究了马尔可夫决策过程中的奖励结构，提出了一种估计器用于估计单个状态值，并通过根据奖励代替常用的基于转移的常数，提供了对强化学习中技巧的理论解释。 |
| [^52] | [FAM: fast adaptive meta-learning.](http://arxiv.org/abs/2308.13970) | 本论文提出了一个快速自适应联邦元学习（FAM）框架，可以协作学习一个全局模型，并在个别客户端上进行个性化。这解决了数据分布发散和隐私限制的问题，并且适用于需要在不同客户端之间进行个性化的领域转变。 |
| [^53] | [Stochastic Configuration Machines for Industrial Artificial Intelligence.](http://arxiv.org/abs/2308.13570) | 本文提出了一种新颖的随机学习器模型，称为随机配置机（SCMs），其基于随机配置网络（SCNs），旨在强调工业人工智能中的有效建模和节约数据大小。SCMs通过压缩模型存储，并保持有利的预测性能，具有在工业应用中很大的潜力。 |
| [^54] | [Human Comprehensible Active Learning of Genome-Scale Metabolic Networks.](http://arxiv.org/abs/2308.12740) | 这项研究介绍了一种人类可理解的基因组规模代谢网络的主动学习方法，基于归纳逻辑编程(ILP)框架进行逻辑推理，并通过从实验中学习新的逻辑结构，以有效探索假设空间和指导实验设计。 |
| [^55] | [Efficient Benchmarking (of Language Models).](http://arxiv.org/abs/2308.11696) | 本研究提出了一种名为"Efficient Benchmarking"的问题，旨在智能地减少语言模型评估的计算成本而不降低可靠性，并使用一种名为Decision Impact on Reliability（DIoR）的新度量来评估决策的可靠性。通过HELM基准测试的案例研究，发现只需删除一个低排名模型即可改变领先者，并仅需少量示例即可得到正确的基准测试排名。 |
| [^56] | [Temporal-Distributed Backdoor Attack Against Video Based Action Recognition.](http://arxiv.org/abs/2308.11070) | 本文介绍了一种针对视频数据的简单而有效的背门攻击方法，通过在转换领域中添加难以察觉的、时间上分布的触发器来实现误分类。 |
| [^57] | [CSM-H-R: An Automatic Context Reasoning Framework for Interoperable Intelligent Systems and Privacy Protection.](http://arxiv.org/abs/2308.11066) | CSM-H-R是一个自动上下文推理框架，用于可互操作的智能系统和隐私保护。该框架结合了本体和状态，在运行时识别有意义的高级上下文，并可应用于不同的推理技术。在智能校园环境中进行了智能电梯系统的案例研究，并展示了使用先进的数学和概率模型的潜力。 |
| [^58] | [Artificial intelligence is ineffective and potentially harmful for fact checking.](http://arxiv.org/abs/2308.10800) | 这项研究发现人工智能语言模型在事实核查中表现出色，但在帮助用户判断标题准确性和分享准确新闻方面影响不大。然而，在某些情况下，它会误导用户对真实标题的信仰，并增加对未确定虚假标题的信仰。 |
| [^59] | [Proceedings of the 2nd International Workshop on Adaptive Cyber Defense.](http://arxiv.org/abs/2308.09520) | 第二届自适应网络防御国际研讨会的目标是探索利用人工智能和机器学习作为自适应网络防御基础能力的研究，并通过填补AI和网络研究人员之间的差距来加速开发半自主网络防御系统。 |
| [^60] | [Graph Structural Residuals: A Learning Approach to Diagnosis.](http://arxiv.org/abs/2308.06961) | 本文提出了一种新颖的框架，将模型诊断的概念与深度图结构学习相结合，通过数据学习系统的底层结构并提供动态观察。研究通过重新定义系统表示、观察和故障的构建，引入自监督图结构学习模型以及在耦合振荡器系统上的实验，展示了数据驱动的诊断方法的潜力。 |
| [^61] | [A Smart Robotic System for Industrial Plant Supervision.](http://arxiv.org/abs/2308.05612) | 我们提出了一个智能机器人系统，可以自动检查化工生产厂的完整性并提供关键操作条件的有用信息。 |
| [^62] | [Minimally-Supervised Speech Synthesis with Conditional Diffusion Model and Language Model: A Comparative Study of Semantic Coding.](http://arxiv.org/abs/2307.15484) | 本文提出了两种语音合成方法来解决自回归和非自回归模型中的问题，并在语义编码方面进行了比较研究。 |
| [^63] | [Psy-LLM: Scaling up Global Mental Health Psychological Services with AI-based Large Language Models.](http://arxiv.org/abs/2307.11991) | Psy-LLM是一个基于人工智能的系统，利用大型语言模型（LLMs）为在线心理咨询提供问答服务，前端工具可让医疗专业人员提供即时响应和正念活动，同时还可作为筛查工具辅助识别紧急案例。 |
| [^64] | [AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity using Contrastive Learning and Structured Knowledge.](http://arxiv.org/abs/2307.07851) | AspectCSE是一种使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入方法，它在信息检索任务中相比之前的最好结果平均提高了3.97%，通过同时考虑多个特定方面的嵌入模型优于单方面嵌入。 |
| [^65] | [Learning to Prompt in the Classroom to Understand AI Limits: A pilot study.](http://arxiv.org/abs/2307.01540) | 在本研究中，通过学习提示，试图在课堂环境中理解人工智能的限制。人工智能的进展带来了巨大的潜力，但也引发了负面情绪。当前大型语言模型的能力限制被忽视，导致了错误的自信和不准确的建议。承认人工智能的不可靠性是解决这个问题的关键。 |
| [^66] | [RS5M: A Large Scale Vision-Language Dataset for Remote Sensing Vision-Language Foundation Model.](http://arxiv.org/abs/2306.11300) | 本文提出了一个新的框架RS5M，该框架包括领域基础模型（DFM），用于实现通用基础模型（GFM）和领域特定下游任务之间的转换。另外，还介绍了一个遥感领域的大规模图像-文本配对数据集RS5M，该数据集是通过过滤公开可用的图像-文本配对数据集并使用预训练的视觉-语言基础模型为标签数据集生成标题。 |
| [^67] | [Fairness in Preference-based Reinforcement Learning.](http://arxiv.org/abs/2306.09995) | 该论文提出了一种名为FPbRL的新的公平偏好强化学习方法，旨在通过广义Gini福利函数最大化策略学习来实现多目标优化并处理每个目标的公平性。 |
| [^68] | [Nonparametric Identification and Estimation of Earnings Dynamics using a Hidden Markov Model: Evidence from the PSID.](http://arxiv.org/abs/2306.01760) | 本研究使用隐马尔科夫模型揭示了收入持续性的复杂本质，并证实了收入具有非线性持续性、条件偏斜性和条件峰度等特征，并发现了ARCH效应以及非高斯瞬时性成分所产生的明显分布不对称性影响。 |
| [^69] | [Causal Policy Gradient for Whole-Body Mobile Manipulation.](http://arxiv.org/abs/2305.04866) | 本文提出了一种新框架——因果MoMa，可以训练适用于典型MoMa任务的策略，在此框架下，机动和交互自由度可以同时组合，并且不需要人类领域知识来划分动作空间或将动作部分与子目标匹配。 |
| [^70] | [A Case-Based Reasoning Framework for Adaptive Prompting in Cross-Domain Text-to-SQL.](http://arxiv.org/abs/2304.13301) | 本文提出了一个基于案例推理框架的跨域文本到SQL自适应提示的解决方案，可以精确控制与案例相关和不相关的知识，解决了大型语言模型提示设计不良限制性能的问题。 |
| [^71] | [Multi-granulariy Time-based Transformer for Knowledge Tracing.](http://arxiv.org/abs/2304.05257) | 本文提出了一种基于Transformer的架构用于准确地预测学生在标准化测试中的表现。该模型考虑了学生的历史数据，包括他们以往的考试成绩、学习习惯和其他相关信息，并在解码器输入中使用了多个时间特征粒度以显著提高模型性能。与LightGBM相比，该方法更加准确，为教育领域的AI发展提供了一个可伸缩和准确的预测学生成果的工具。 |
| [^72] | [Interpretable Outlier Summarization.](http://arxiv.org/abs/2303.06261) | STAIR提出了一种可解释的异常值汇总方法，通过学习一组紧凑的人类可理解规则，以汇总和解释异常检测结果，具有强大的可解释性，以准确地总结检测结果。 |
| [^73] | [Understanding the Diffusion Objective as a Weighted Integral of ELBOs.](http://arxiv.org/abs/2303.00848) | 本文深入理解了扩散目标，并揭示了加权损失和ELBO目标之间的直接关系。 |
| [^74] | [Improving Differentiable Architecture Search via Self-Distillation.](http://arxiv.org/abs/2302.05629) | 本文提出了自我蒸馏可微分神经架构搜索（SD-DARTS）方法，通过从超网的先前步骤中蒸馏知识来指导其训练，有效降低了超网损失的尖锐度，从而缓解了离散化差距。 |
| [^75] | [Domain-Agnostic Molecular Generation with Self-feedback.](http://arxiv.org/abs/2301.11259) | MolGen是一个专注于分子生成的预训练语言模型，使用了领域无关的分子前缀调整和自我反馈的范式，实现了化学有效性、多样性、新颖性和复杂性的突破，在分子生成领域表现出了出色的性能。 |
| [^76] | [Identifying Generalized Neural Representation Across Hamiltonian Manifolds via Meta-learning.](http://arxiv.org/abs/2212.01168) | 通过元学习方法，在哈密顿流形中识别出普遍的神经表示，实现了对不同物理系统的快速适应能力。 |
| [^77] | [ComCLIP: Training-Free Compositional Image and Text Matching.](http://arxiv.org/abs/2211.13854) | 本文提出了一个无需训练的组合图像与文本匹配模型 ComCLIP，通过将输入图像分解为主体、对象和动作子图像，并结合视觉编码器和文本编码器进行逐步匹配，以解决组合图像与文本匹配中的伪匹配问题。 |
| [^78] | [From prediction markets to interpretable collective intelligence.](http://arxiv.org/abs/2204.13424) | 本文提出了一个机制，可以从任意专家组中收集到关于任意逻辑命题真实概率的信息，并提供具有明确形式的解释。该机制可以激励专家直接交流信息，解决科学或医学问题。 |

# 详细

[^1]: Point-Bind和Point-LLM：用于3D理解、生成和指导跟随的多模态点云对齐

    Point-Bind & Point-LLM: Aligning Point Cloud with Multi-modality for 3D Understanding, Generation, and Instruction Following. (arXiv:2309.00615v1 [cs.CV])

    [http://arxiv.org/abs/2309.00615](http://arxiv.org/abs/2309.00615)

    Point-Bind和Point-LLM是用于3D理解、生成和指导跟随的多模态点云对齐模型，能实现任意到3D生成、3D嵌入算术和3D开放世界的理解，并且Point-LLM能实现3D和多模态问答功能。

    

    我们引入了Point-Bind，一个将点云与2D图像、语言、音频和视频对齐的3D多模态模型。在ImageBind的指导下，我们构建了一个将3D和多模态嵌入空间进行结合的模型，实现了许多有前景的应用，例如任意到3D生成、3D嵌入算术和3D开放世界的理解。在此基础上，我们进一步提出了Point-LLM，第一个遵循3D多模态指令的大型语言模型（LLM）。通过参数高效调优技术，Point-LLM将Point-Bind的语义注入到预训练的LLMs中，例如LLaMA，不需要3D指令数据但展现出卓越的3D和多模态问答能力。我们希望我们的工作能为将3D点云扩展到多模态应用的研究社区提供启示。代码可在https://github.com/ZiyuGuo99/Point-Bind_Point-LLM找到。

    We introduce Point-Bind, a 3D multi-modality model aligning point clouds with 2D image, language, audio, and video. Guided by ImageBind, we construct a joint embedding space between 3D and multi-modalities, enabling many promising applications, e.g., any-to-3D generation, 3D embedding arithmetic, and 3D open-world understanding. On top of this, we further present Point-LLM, the first 3D large language model (LLM) following 3D multi-modal instructions. By parameter-efficient fine-tuning techniques, Point-LLM injects the semantics of Point-Bind into pre-trained LLMs, e.g., LLaMA, which requires no 3D instruction data, but exhibits superior 3D and multi-modal question-answering capacity. We hope our work may cast a light on the community for extending 3D point clouds to multi-modality applications. Code is available at https://github.com/ZiyuGuo99/Point-Bind_Point-LLM.
    
[^2]: 使用扩散模型的多粒度迭代图像编辑

    Iterative Multi-granular Image Editing using Diffusion Models. (arXiv:2309.00613v1 [cs.CV])

    [http://arxiv.org/abs/2309.00613](http://arxiv.org/abs/2309.00613)

    本研究提出了一种名为EMILIE的迭代多粒度图像编辑器，通过重新利用预训练的扩散模型来实现迭代编辑，并引入梯度控制操作来实现对图像编辑的粒度控制。

    

    最近，文本引导的图像合成的进展极大地改变了创意专业人员生成艺术和审美上令人愉悦的视觉资产的方式。为了充分支持这样的创意努力，该过程应具备以下能力：1）迭代地编辑生成的图像，2）控制所需变化的空间范围（全局、局部或介于两者之间）。我们将这个实用的问题设定正式化为迭代多粒度编辑。虽然在图像合成和编辑方面，基于扩散模型取得了重大进展，但它们都是一次性操作（即没有迭代编辑能力），并且不能自然产生多粒度控制（即涵盖从局部到全局编辑的全谱）。为了克服这些缺点，我们提出了EMILIE：迭代多粒度图像编辑器。EMILIE引入了一种新颖的潜在迭代策略，利用预训练的扩散模型来促进迭代编辑。同时，还引入了梯度控制操作来实现对所需变化的粒度控制。

    Recent advances in text-guided image synthesis has dramatically changed how creative professionals generate artistic and aesthetically pleasing visual assets. To fully support such creative endeavors, the process should possess the ability to: 1) iteratively edit the generations and 2) control the spatial reach of desired changes (global, local or anything in between). We formalize this pragmatic problem setting as Iterative Multi-granular Editing. While there has been substantial progress with diffusion-based models for image synthesis and editing, they are all one shot (i.e., no iterative editing capabilities) and do not naturally yield multi-granular control (i.e., covering the full spectrum of local-to-global edits). To overcome these drawbacks, we propose EMILIE: Iterative Multi-granular Image Editor. EMILIE introduces a novel latent iteration strategy, which re-purposes a pre-trained diffusion model to facilitate iterative editing. This is complemented by a gradient control opera
    
[^3]: 为了构建可信赖的医疗AI系统，筛选天然对立数据集

    Curating Naturally Adversarial Datasets for Trustworthy AI in Healthcare. (arXiv:2309.00543v1 [cs.LG])

    [http://arxiv.org/abs/2309.00543](http://arxiv.org/abs/2309.00543)

    提出了一种方法来筛选自然对立示例的数据集，以评估模型的鲁棒性，并通过自动弱监督标注获得的概率标签来实现这一方法。

    

    深度学习模型在时间序列的医疗应用中展示出了有希望的预测准确性。然而，确保这些模型的鲁棒性对于构建可信赖的AI系统至关重要。现有研究主要关注于对合成对立示例的鲁棒性，这些示例是通过向清洁输入数据添加难以察觉的扰动而制作出来的。然而，这些合成对立示例并不能准确反映最具挑战性的现实场景，特别是在医疗数据的背景下。因此，对合成对立示例的鲁棒性未必能够转化为对自然产生的对立示例的鲁棒性，而这对于可信赖的AI而言是非常重要的。我们提出了一种筛选由自然对立示例组成的数据集来评估模型鲁棒性的方法。该方法依赖于通过自动弱监督标注获得的概率标签，这种标签结合了嘈杂且易获得的标注启发式方法。

    Deep learning models have shown promising predictive accuracy for time-series healthcare applications. However, ensuring the robustness of these models is vital for building trustworthy AI systems. Existing research predominantly focuses on robustness to synthetic adversarial examples, crafted by adding imperceptible perturbations to clean input data. However, these synthetic adversarial examples do not accurately reflect the most challenging real-world scenarios, especially in the context of healthcare data. Consequently, robustness to synthetic adversarial examples may not necessarily translate to robustness against naturally occurring adversarial examples, which is highly desirable for trustworthy AI. We propose a method to curate datasets comprised of natural adversarial examples to evaluate model robustness. The method relies on probabilistic labels obtained from automated weakly-supervised labeling that combines noisy and cheap-to-obtain labeling heuristics. Based on these labels
    
[^4]: 基于学习的GNSS观测的NLOS检测与不确定性预测的Transformer增强LSTM网络

    Learning-based NLOS Detection and Uncertainty Prediction of GNSS Observations with Transformer-Enhanced LSTM Network. (arXiv:2309.00480v1 [cs.RO])

    [http://arxiv.org/abs/2309.00480](http://arxiv.org/abs/2309.00480)

    本研究提出了一种基于深度学习的方法，通过构建Transformer-like注意机制增强LSTM网络，检测GNSS观测中的NLOS接收并预测GNSS伪距误差，从而提高了车辆定位的精度和系统的可靠性。

    

    全球导航卫星系统（GNSS）在交通系统中对于精确和一致的车辆定位至关重要。然而，在城市峡谷等复杂环境中，由于多路径效应和非直达（NLOS）接收的影响，GNSS观测可以产生扭曲。在这种情况下，传统的分类与排除错误GNSS观测的方法可能会失败，导致不可靠的状态估计和不安全的系统操作。本研究提出了一种基于深度学习的方法，通过将GNSS观测视为空时建模问题，检测NLOS接收并预测GNSS伪距误差。与先前的工作相比，我们构建了一个类似Transformer的注意机制，增强了长短期记忆（LSTM）网络，提高了模型的性能和普适性。对于所提出的网络的训练和评估，我们使用了香港和亚琛的标记数据集。我们还介绍了一个数据集生成过程来标记...

    The global navigation satellite systems (GNSS) play a vital role in transport systems for accurate and consistent vehicle localization. However, GNSS observations can be distorted due to multipath effects and non-line-of-sight (NLOS) receptions in challenging environments such as urban canyons. In such cases, traditional methods to classify and exclude faulty GNSS observations may fail, leading to unreliable state estimation and unsafe system operations. This work proposes a Deep-Learning-based method to detect NLOS receptions and predict GNSS pseudorange errors by analyzing GNSS observations as a spatio-temporal modeling problem. Compared to previous works, we construct a transformer-like attention mechanism to enhance the long short-term memory (LSTM) networks, improving model performance and generalization. For the training and evaluation of the proposed network, we used labeled datasets from the cities of Hong Kong and Aachen. We also introduce a dataset generation process to label
    
[^5]: 评估目标检测中的不确定性校准的理论和实践框架

    A Theoretical and Practical Framework for Evaluating Uncertainty Calibration in Object Detection. (arXiv:2309.00464v1 [cs.CV])

    [http://arxiv.org/abs/2309.00464](http://arxiv.org/abs/2309.00464)

    本文提出了一种评估目标检测中不确定性校准的理论和实践框架，并通过实验证明了所提出指标的有效性。

    

    深度神经网络的普及导致机器学习系统在各种实际应用中越来越常见。因此，在考虑深度学习的未来时，不确定性校准问题成为至关重要的问题，尤其是在考虑到在自动驾驶和机器人等安全关键应用中常见的目标检测系统。基于此，本研究提出了一种新颖的理论和实践框架，以评估目标检测系统的不确定性校准。通过一系列代表性实验展示了所提出不确定性校准指标的鲁棒性。所提出不确定性校准指标的代码可在以下链接找到：https://github.com/pedrormconde/Uncertainty_Calibration_Object_Detection。

    The proliferation of Deep Neural Networks has resulted in machine learning systems becoming increasingly more present in various real-world applications. Consequently, there is a growing demand for highly reliable models in these domains, making the problem of uncertainty calibration pivotal, when considering the future of deep learning. This is especially true when considering object detection systems, that are commonly present in safety-critical application such as autonomous driving and robotics. For this reason, this work presents a novel theoretical and practical framework to evaluate object detection systems in the context of uncertainty calibration. The robustness of the proposed uncertainty calibration metrics is shown through a series of representative experiments. Code for the proposed uncertainty calibration metrics at: https://github.com/pedrormconde/Uncertainty_Calibration_Object_Detection.
    
[^6]: 分析持续学习者的新指标

    New metrics for analyzing continual learners. (arXiv:2309.00462v1 [cs.LG])

    [http://arxiv.org/abs/2309.00462](http://arxiv.org/abs/2309.00462)

    该论文提出了分析持续学习者的新指标，针对现有指标的局限性进行了分析，并提出解决了分类任务逐渐增加难度的问题。

    

    深度神经网络在从固定的类别集合中进行独立和同分布的数据训练时表现出了显著的性能。然而，在现实世界的场景中，对于连续流的数据进行模型训练可能是有益的，其中多个分类任务按顺序呈现。这种情况被称为持续学习（CL），对于标准学习算法来说，它们在学习新任务的同时难以保持旧任务的知识。这种稳定性与可塑性的困境仍然是持续学习的核心问题，已经提出了多种指标来充分衡量稳定性和可塑性。然而，没有一个指标考虑到分类任务的逐渐增加的难度，这从本质上导致任何模型的性能下降。在这方面，我们分析了当前指标的一些限制，并确定了设置引起的遗忘的存在。因此，我们提出了考虑任务逐渐增加难度的新指标。

    Deep neural networks have shown remarkable performance when trained on independent and identically distributed data from a fixed set of classes. However, in real-world scenarios, it can be desirable to train models on a continuous stream of data where multiple classification tasks are presented sequentially. This scenario, known as Continual Learning (CL) poses challenges to standard learning algorithms which struggle to maintain knowledge of old tasks while learning new ones. This stability-plasticity dilemma remains central to CL and multiple metrics have been proposed to adequately measure stability and plasticity separately. However, none considers the increasing difficulty of the classification task, which inherently results in performance loss for any model. In that sense, we analyze some limitations of current metrics and identify the presence of setup-induced forgetting. Therefore, we propose new metrics that account for the task's increasing difficulty. Through experiments on 
    
[^7]: CPSP: 从音素监督中学习语音概念

    CPSP: Learning Speech Concepts From Phoneme Supervision. (arXiv:2309.00424v1 [eess.AS])

    [http://arxiv.org/abs/2309.00424](http://arxiv.org/abs/2309.00424)

    论文提出了一种名为CPSP的方法，通过对比学习来从语音中提取细粒度的中间表示，使得提取的信息既包含语言内容又去除了发言人身份和声学细节，适用于TTS、VC和ASR等任务。

    

    对于诸如最小监督的文本转语音（TTS）、语音转换（VC）和自动语音识别（ASR）等细粒度生成和识别任务，从语音中提取的中间表示应包含介于文本编码和声学编码之间的信息。语言内容突出，而发言人身份和声学细节等语音信息应该被去除。然而，现有的从语音中提取细粒度中间表示的方法存在冗余性过高和维度爆炸的问题。此外，音频领域中现有的对比学习方法主要关注提取用于下游音频分类任务的全局描述信息，不适合TTS、VC和ASR任务。为了解决这些问题，我们提出了一种名为对比音素-语音预训练（CPSP）的方法，该方法使用三个编码器、一个解码器和对比学习来将音素和语音信息相结合。

    For fine-grained generation and recognition tasks such as minimally-supervised text-to-speech (TTS), voice conversion (VC), and automatic speech recognition (ASR), the intermediate representation extracted from speech should contain information that is between text coding and acoustic coding. The linguistic content is salient, while the paralinguistic information such as speaker identity and acoustic details should be removed. However, existing methods for extracting fine-grained intermediate representations from speech suffer from issues of excessive redundancy and dimension explosion. Additionally, existing contrastive learning methods in the audio field focus on extracting global descriptive information for downstream audio classification tasks, making them unsuitable for TTS, VC, and ASR tasks. To address these issues, we propose a method named Contrastive Phoneme-Speech Pretraining (CPSP), which uses three encoders, one decoder, and contrastive learning to bring phoneme and speech
    
[^8]: 使用约束逻辑编程进行解释性推理

    Declarative Reasoning on Explanations Using Constraint Logic Programming. (arXiv:2309.00422v1 [cs.AI])

    [http://arxiv.org/abs/2309.00422](http://arxiv.org/abs/2309.00422)

    这项研究提出了使用约束逻辑编程进行解释性推理的方法，可以为决策树提供声明性、交互式的解释，克服了当前解释方法中对背景知识的不充分结合和与用户的缺乏抽象和互动的问题。

    

    解释不透明的机器学习模型是一个日益重要的问题。当前的解释方法在人工智能（XAI）中存在一些缺点，包括对背景知识的不充分结合，以及与用户的缺乏抽象和互动。我们提出了基于约束逻辑编程（CLP）的REASONX解释方法。REASONX可以为决策树提供声明性的交互式解释，这些决策树可以是分析的机器学习模型或任何黑盒模型的全局/局部替代模型。用户可以使用线性约束和基于事实和对比实例的特征的MILP优化来表达背景知识或常识，并通过约束投影在不同抽象级别上与答案约束进行交互。我们在这里介绍了REASONX的架构，它由接近用户的Python层和CLP层组成。REASONX的核心执行引擎是一个具有声明性语义的Prolog元编程。

    Explaining opaque Machine Learning (ML) models is an increasingly relevant problem. Current explanation in AI (XAI) methods suffer several shortcomings, among others an insufficient incorporation of background knowledge, and a lack of abstraction and interactivity with the user. We propose REASONX, an explanation method based on Constraint Logic Programming (CLP). REASONX can provide declarative, interactive explanations for decision trees, which can be the ML models under analysis or global/local surrogate models of any black-box model. Users can express background or common sense knowledge using linear constraints and MILP optimization over features of factual and contrastive instances, and interact with the answer constraints at different levels of abstraction through constraint projection. We present here the architecture of REASONX, which consists of a Python layer, closer to the user, and a CLP layer. REASONX's core execution engine is a Prolog meta-program with declarative seman
    
[^9]: 条件生存预测中的面积规范COBRA

    Area-norm COBRA on Conditional Survival Prediction. (arXiv:2309.00417v1 [cs.LG])

    [http://arxiv.org/abs/2309.00417](http://arxiv.org/abs/2309.00417)

    本文提出了一种基于组合回归的条件生存预测方法，其中使用面积作为相似度度量，通过选择最重要的变量来提高模型性能。

    

    本文探讨了一种不同的组合回归策略来计算条件生存函数。我们使用基于回归的弱学习器来创建所提出的集成技术。所提出的组合回归策略使用相似度度量作为两个生存曲线之间的面积。所提出的模型表明其表现优于随机生存森林。本文讨论了一种在组合回归设置中选择最重要变量的新技术。我们进行了一项模拟研究，表明我们对变量相关性的提议效果很好。我们还使用了三个真实数据集来说明该模型。

    The paper explores a different variation of combined regression strategy to calculate the conditional survival function. We use regression based weak learners to create the proposed ensemble technique. The proposed combined regression strategy uses proximity measure as area between two survival curves. The proposed model shows a construction which ensures that it performs better than the Random Survival Forest. The paper discusses a novel technique to select the most important variable in the combined regression setup. We perform a simulation study to show that our proposition for finding relevance of the variables works quite well. We also use three real-life datasets to illustrate the model.
    
[^10]: 提升基于AND/OR的计算蛋白质设计：动态启发式和可泛化的UFO

    Boosting AND/OR-Based Computational Protein Design: Dynamic Heuristics and Generalizable UFO. (arXiv:2309.00408v1 [q-bio.BM])

    [http://arxiv.org/abs/2309.00408](http://arxiv.org/abs/2309.00408)

    该研究专注于提升蛋白质重设计算法AOBB-K*的扩展性，通过引入增强版、带有动态启发式和带有下溢优化的新版本，显著提升了其可扩展性。

    

    科学计算在神经网络等技术的推动下取得了飞速发展。然而，某些重要任务对于这些技术来说并不适用，因此需要对传统推理方案进行创新。其中一个任务就是蛋白质重设计。最近引入了一种新的重设计算法AOBB-K*，在小规模蛋白质重设计问题上与最先进的BBK*算法具有竞争力。然而，AOBB-K*在扩展性上表现不佳。在本研究中，我们专注于扩展AOBB-K*算法，并引入了三个新版本：AOBB-K*-b（增强版）、AOBB-K*-DH（带有动态启发式）和AOBB-K*-UFO（带有下溢优化），显著提升了扩展性。

    Scientific computing has experienced a surge empowered by advancements in technologies such as neural networks. However, certain important tasks are less amenable to these technologies, benefiting from innovations to traditional inference schemes. One such task is protein re-design. Recently a new re-design algorithm, AOBB-K*, was introduced and was competitive with state-of-the-art BBK* on small protein re-design problems. However, AOBB-K* did not scale well. In this work we focus on scaling up AOBB-K* and introduce three new versions: AOBB-K*-b (boosted), AOBB-K*-DH (with dynamic heuristics), and AOBB-K*-UFO (with underflow optimization) that significantly enhance scalability.
    
[^11]: 使用单目事件相机进行稠密体素三维重建

    Dense Voxel 3D Reconstruction Using a Monocular Event Camera. (arXiv:2309.00385v1 [cs.CV])

    [http://arxiv.org/abs/2309.00385](http://arxiv.org/abs/2309.00385)

    这项研究探索了使用单目事件相机进行稠密体素三维重建的应用。以往的研究主要集中在深度图估计方面，而本研究提出了一种利用单个事件相机进行稠密三维重建的方法，并在虚拟现实应用中进行了探索。

    

    事件相机是受生物系统启发的传感器，专门用于捕捉亮度变化。这些新兴相机相比传统的基于帧的相机具有许多优势，包括高动态范围、高帧率和极低的功耗。由于这些优点，事件相机越来越多地被应用于帧插值、语义分割、里程计和SLAM等各个领域。然而，事件相机在虚拟现实应用的三维重建方面的应用还不够深入。以前在这个领域的方法主要集中在通过深度图估计进行三维重建上。产生稠密三维重建的方法通常需要多个相机，而利用单个事件相机只能产生半稠密的结果。其他可以产生稠密三维重建的单目相机方法依赖于创建一个流水线，其中要么结合前述方法，要么结合其他现有的运动结构（SfM）或多视图方法。

    Event cameras are sensors inspired by biological systems that specialize in capturing changes in brightness. These emerging cameras offer many advantages over conventional frame-based cameras, including high dynamic range, high frame rates, and extremely low power consumption. Due to these advantages, event cameras have increasingly been adapted in various fields, such as frame interpolation, semantic segmentation, odometry, and SLAM. However, their application in 3D reconstruction for VR applications is underexplored. Previous methods in this field mainly focused on 3D reconstruction through depth map estimation. Methods that produce dense 3D reconstruction generally require multiple cameras, while methods that utilize a single event camera can only produce a semi-dense result. Other single-camera methods that can produce dense 3D reconstruction rely on creating a pipeline that either incorporates the aforementioned methods or other existing Structure from Motion (SfM) or Multi-view S
    
[^12]: 水库系统的基于场景的模型预测控制

    Scenario-based model predictive control of water reservoir systems. (arXiv:2309.00373v1 [eess.SY])

    [http://arxiv.org/abs/2309.00373](http://arxiv.org/abs/2309.00373)

    针对水库系统的最优操作问题，本文首次提出了一种基于场景的随机模型预测控制方法。通过直接从过去数据生成未来水流的一组可能情景，优化控制策略，使控制器更加谨慎，同时满足农业用水需求，并应对干旱期的挑战。

    

    水库系统的最优操作是一个涉及多个相互矛盾目标的挑战性任务。复杂性的主要来源是水流入作为系统上的一种外生、高度不确定的扰动。当采用模型预测控制（MPC）时，通常基于（预测的）水流轨迹计算最优的水释放。当实际水流与预测不同的时候，这种选择可能会危及闭环性能。在这项工作中，我们首次考虑了一种用于水库的随机MPC方法，其中控制是基于从过去数据直接生成的一组可能的未来水流进行优化的。这种基于场景的MPC策略允许控制器更加谨慎，为干旱期间（例如湖水位低于干枯界限）采取对策，同时确保满足农业用水需求。通过验证该方法的有效性来证明...

    The optimal operation of water reservoir systems is a challenging task involving multiple conflicting objectives. The main source of complexity is the presence of the water inflow, which acts as an exogenous, highly uncertain disturbance on the system. When model predictive control (MPC) is employed, the optimal water release is usually computed based on the (predicted) trajectory of the inflow. This choice may jeopardize the closed-loop performance when the actual inflow differs from its forecast. In this work, we consider - for the first time - a stochastic MPC approach for water reservoirs, in which the control is optimized based on a set of plausible future inflows directly generated from past data. Such a scenario-based MPC strategy allows the controller to be more cautious, counteracting droughty periods (e.g., the lake level going below the dry limit) while at the same time guaranteeing that the agricultural water demand is satisfied. The method's effectiveness is validated thro
    
[^13]: 情感决策制定中的离散与连续算法的比较

    Discrete Versus Continuous Algorithms in Dynamics of Affective Decision Making. (arXiv:2309.00357v1 [cs.AI])

    [http://arxiv.org/abs/2309.00357](http://arxiv.org/abs/2309.00357)

    本文比较了情感决策制定中离散和连续算法的表现，并发现根据网络参数的不同，两种算法可能得到不同的理论预测，这对于实际问题的描述具有重要影响。

    

    本文考虑了情感决策制定的动态过程，针对由具有长期和短期记忆的不同类型代理组成的智能网络。研究基于概率情感决策理论，该理论考虑了替代方案的理性效用和情感吸引力。本文的目标是比较智能网络中两种多步操作算法：基于离散动力学和基于连续动力学的算法。通过数值分析，结果显示，根据网络参数的不同，连续和离散操作的特征概率可能呈现出接近或截然不同的行为。因此，根据所采用的算法（离散或连续），理论预测可能会有相当大的差异，这不允许对实际问题进行唯一定义的描述。这一发现对于理解情感决策制定过程是重要的。

    The dynamics of affective decision making is considered for an intelligent network composed of agents with different types of memory: long-term and short-term memory. The consideration is based on probabilistic affective decision theory, which takes into account the rational utility of alternatives as well as the emotional alternative attractiveness. The objective of this paper is the comparison of two multistep operational algorithms of the intelligent network: one based on discrete dynamics and the other on continuous dynamics. By means of numerical analysis, it is shown that, depending on the network parameters, the characteristic probabilities for continuous and discrete operations can exhibit either close or drastically different behavior. Thus, depending on which algorithm is employed, either discrete or continuous, theoretical predictions can be rather different, which does not allow for a uniquely defined description of practical problems. This finding is important for understa
    
[^14]: 可解释的主动学习用于偏好获取

    Explainable Active Learning for Preference Elicitation. (arXiv:2309.00356v1 [cs.LG])

    [http://arxiv.org/abs/2309.00356](http://arxiv.org/abs/2309.00356)

    本研究关注于冷启动问题中的偏好获取，在该问题中，推荐系统缺乏用户存在或访问其他用户数据受限。我们采用可解释的主动学习方法，通过最小化用户工作量最大化信息获取，并在偏好获取过程中采用无监督、半监督和监督机器学习方法。

    

    深入了解新用户的偏好，并随后个性化推荐，需要智能地处理用户交互，即提出相关问题以有效获取有价值的信息。在本研究中，我们关注的是冷启动问题的特定情景，在该情景中，推荐系统缺乏足够的用户存在或访问其他用户数据受限，阻碍了利用系统中现有数据的用户建模方法。我们采用主动学习(AL)来解决这个问题，目标是在最小用户工作量的情况下最大化信息获取。AL从一个大型无标签集合中选择信息丰富的数据向询问预测标签，并最终更新机器学习(ML)模型。我们在解释性偏好获取过程中采用了无监督、半监督和监督ML的集成过程。它利用用户对系统返回推荐的反馈（给予系统的注意或喜好）和用户对问题的反馈向他们解释和辅助保持用户满意度和参与度。

    Gaining insights into the preferences of new users and subsequently personalizing recommendations necessitate managing user interactions intelligently, namely, posing pertinent questions to elicit valuable information effectively. In this study, our focus is on a specific scenario of the cold-start problem, where the recommendation system lacks adequate user presence or access to other users' data is restricted, obstructing employing user profiling methods utilizing existing data in the system. We employ Active Learning (AL) to solve the addressed problem with the objective of maximizing information acquisition with minimal user effort. AL operates for selecting informative data from a large unlabeled set to inquire an oracle to label them and eventually updating a machine learning (ML) model. We operate AL in an integrated process of unsupervised, semi-supervised, and supervised ML within an explanatory preference elicitation process. It harvests user feedback (given for the system's 
    
[^15]: 基于文本的维基百科文章链接预测方法

    A Text-based Approach For Link Prediction on Wikipedia Articles. (arXiv:2309.00317v1 [cs.AI])

    [http://arxiv.org/abs/2309.00317](http://arxiv.org/abs/2309.00317)

    本研究提出了一种基于文本的维基百科文章链接预测方法，通过利用传统的机器学习模型和词性标注特征，实现了对两个节点是否有链接的分类预测，并在比赛中取得了较高的成绩。

    

    本文介绍了我们在DSAA 2023挑战中关于维基百科文章链接预测的工作。我们利用传统的机器学习模型以及从文本中提取的词性标注特征来训练分类模型，用于预测两个节点是否有链接。然后，我们使用这些特征在各种机器学习模型上进行测试。我们通过F1得分为0.99999获得了第7名。我们的源代码可以在以下链接中公开获取：https://github.com/Tam1032/DSAA2023-Challenge-Link-prediction-DS-UIT_SAT

    This paper present our work in the DSAA 2023 Challenge about Link Prediction for Wikipedia Articles. We use traditional machine learning models with POS tags (part-of-speech tags) features extracted from text to train the classification model for predicting whether two nodes has the link. Then, we use these tags to test on various machine learning models. We obtained the results by F1 score at 0.99999 and got 7th place in the competition. Our source code is publicly available at this link: https://github.com/Tam1032/DSAA2023-Challenge-Link-prediction-DS-UIT_SAT
    
[^16]: 关于知识图谱补全规则聚合的研究

    On the Aggregation of Rules for Knowledge Graph Completion. (arXiv:2309.00306v1 [cs.AI])

    [http://arxiv.org/abs/2309.00306](http://arxiv.org/abs/2309.00306)

    本论文研究了知识图谱补全的规则聚合问题，证明了现有的聚合方法可以表达为对预测规则的边际推断操作，并提出了一个高效且被忽视的基准方法，与计算代价更高的方法竞争。

    

    知识图谱补全的规则学习方法高效、可解释性强，与纯神经模型具有竞争力。规则聚合问题涉及如何为同时被多个规则预测的候选事实找到一个合理性得分。尽管这个问题非常普遍，但由于数据驱动的规则学习可能导致噪声和庞大的规则集，因此该问题在文献中占比较少，其理论基础尚未在此背景下进行研究。在这项工作中，我们证明了现有的聚合方法可以表达为对预测规则的边际推断操作。特别地，我们展示了常见的最大聚合策略，即根据置信度最高的规则为候选事实评分，具有概率解释。最后，我们提出了一个高效且被忽视的基准方法，结合了之前的策略，并能与计算代价更高的方法竞争。

    Rule learning approaches for knowledge graph completion are efficient, interpretable and competitive to purely neural models. The rule aggregation problem is concerned with finding one plausibility score for a candidate fact which was simultaneously predicted by multiple rules. Although the problem is ubiquitous, as data-driven rule learning can result in noisy and large rulesets, it is underrepresented in the literature and its theoretical foundations have not been studied before in this context. In this work, we demonstrate that existing aggregation approaches can be expressed as marginal inference operations over the predicting rules. In particular, we show that the common Max-aggregation strategy, which scores candidates based on the rule with the highest confidence, has a probabilistic interpretation. Finally, we propose an efficient and overlooked baseline which combines the previous strategies and is competitive to computationally more expensive approaches.
    
[^17]: 用编码-解码器进行可识别的认知诊断模型来建模学生的表现

    Identifiable Cognitive Diagnosis with Encoder-decoder for Modelling Students' Performance. (arXiv:2309.00300v1 [cs.AI])

    [http://arxiv.org/abs/2309.00300](http://arxiv.org/abs/2309.00300)

    本文提出了一个可识别的认知诊断框架，该框架能够从学生的答题记录中直接诊断可识别和可解释的考生特征和题目特征，并通过重建答题记录来确保诊断结果的可识别性。

    

    认知诊断旨在根据学生在考试题目上的答题成绩来诊断他们的知识水平，这是许多领域如计算自适应测试的基础。现有的认知诊断模型（CDMs）遵循了一个能力-响应范式，即将诊断结果视为学生响应的原因，并通过优化来学习诊断结果。然而，这种范式很容易导致不可识别的诊断结果和解释过拟合问题，这对于学生学习表现的量化是有害的。为了解决这些问题，我们提出了一种新的可识别的认知诊断框架。具体而言，我们首先提出了一个灵活的诊断模块，该模块直接从响应日志中诊断可识别和可解释的考生特征和题目特征。接下来，我们利用一个通用的预测模块从诊断结果中重建响应日志，以确保诊断结果的可识别性。

    Cognitive diagnosis aims to diagnose students' knowledge proficiencies based on their response scores on exam questions, which is the basis of many domains such as computerized adaptive testing. Existing cognitive diagnosis models (CDMs) follow a proficiency-response paradigm, which views diagnostic results as learnable embeddings that are the cause of students' responses and learns the diagnostic results through optimization. However, such a paradigm can easily lead to unidentifiable diagnostic results and the explainability overfitting problem, which is harmful to the quantification of students' learning performance. To address these problems, we propose a novel identifiable cognitive diagnosis framework. Specifically, we first propose a flexible diagnostic module which directly diagnose identifiable and explainable examinee traits and question features from response logs. Next, we leverage a general predictive module to reconstruct response logs from the diagnostic results to ensure
    
[^18]: 基于激光雷达的端到端强化学习用于自主赛车

    End-to-end Lidar-Driven Reinforcement Learning for Autonomous Racing. (arXiv:2309.00296v1 [cs.RO])

    [http://arxiv.org/abs/2309.00296](http://arxiv.org/abs/2309.00296)

    本研究提出了一种基于激光雷达的端到端强化学习方法，用于解决在汽车赛车领域中复杂环境下的自主导航问题，并通过实验验证了该方法的可行性和潜力。

    

    强化学习已经成为自动化和机器人领域的一种革命性方法，为传统方法难以解决的复杂问题提供了强大的解决方案。在问题定义模糊且难以量化的情况下，学习为基础的解决方案如强化学习尤其有价值。本研究旨在开发和训练一个利用前馈原始激光雷达和速度数据在模拟环境中进行自主导航的强化学习智能体。经过在模拟环境中训练后，该智能体的性能在真实赛车场景中进行实验评估。这项研究突出了强化学习算法在增强自主赛车性能方面的可行性和潜在好处，特别是在先前地图信息有限的环境中。

    Reinforcement Learning (RL) has emerged as a transformative approach in the domains of automation and robotics, offering powerful solutions to complex problems that conventional methods struggle to address. In scenarios where the problem definitions are elusive and challenging to quantify, learning-based solutions such as RL become particularly valuable. One instance of such complexity can be found in the realm of car racing, a dynamic and unpredictable environment that demands sophisticated decision-making algorithms. This study focuses on developing and training an RL agent to navigate a racing environment solely using feedforward raw lidar and velocity data in a simulated context. The agent's performance, trained in the simulation environment, is then experimentally evaluated in a real-world racing scenario. This exploration underlines the feasibility and potential benefits of RL algorithm enhancing autonomous racing performance, especially in the environments where prior map inform
    
[^19]: RLAIF: 使用AI反馈来扩展强化学习从人类反馈中学习

    RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback. (arXiv:2309.00267v1 [cs.CL])

    [http://arxiv.org/abs/2309.00267](http://arxiv.org/abs/2309.00267)

    RLAIF是一种新的强化学习方法，利用AI反馈代替人类标注偏好，相比强化学习从人类反馈中学习（RLHF），在摘要任务上取得了类似的改进效果，并且在人类评估中得到了相同的认可。这提供了一种有潜力解决RLHF的可扩展性限制的解决方案。

    

    从人类反馈中进行强化学习（RLHF）对于将大型语言模型（LLMs）与人类偏好相一致是有效的，但是收集高质量的人类偏好标签是一个关键瓶颈。我们比较了RLHF和利用现成的LLM进行标记的RL from AI Feedback (RLAIF)技术，并发现它们都能获得类似的改善效果。在摘要任务上，人类评估者在约70%的案例中都更喜欢RLAIF和RLHF产生的文本，而不是基准的监督微调模型。此外，当被要求评估RLAIF和RLHF的摘要时，人类以相同的比率更喜欢两者。这些结果表明，RLAIF可以达到人类水平的性能，为克服RLHF的可扩展性限制提供了潜在的解决方案。

    Reinforcement learning from human feedback (RLHF) is effective at aligning large language models (LLMs) to human preferences, but gathering high quality human preference labels is a key bottleneck. We conduct a head-to-head comparison of RLHF vs. RL from AI Feedback (RLAIF) - a technique where preferences are labeled by an off-the-shelf LLM in lieu of humans, and we find that they result in similar improvements. On the task of summarization, human evaluators prefer generations from both RLAIF and RLHF over a baseline supervised fine-tuned model in ~70% of cases. Furthermore, when asked to rate RLAIF vs. RLHF summaries, humans prefer both at equal rates. These results suggest that RLAIF can yield human-level performance, offering a potential solution to the scalability limitations of RLHF.
    
[^20]: 利用学习度量改进联邦学习

    Leveraging Learning Metrics for Improved Federated Learning. (arXiv:2309.00257v1 [cs.LG])

    [http://arxiv.org/abs/2309.00257](http://arxiv.org/abs/2309.00257)

    本论文将联邦学习与学习度量方法相结合，提出了首个联邦学习度量聚合方法，并证明了有效秩适用于联邦问题，并通过开发新型权重聚合方案取得了优于基准的联邦平均效果。

    

    目前在联邦学习环境中，没有学习方案利用可解释的人工智能（XAI）中的新学习度量，尤其是有助于确定模型学习情况的新学习度量。其中一种新的学习度量被称为“有效秩”（ER），它衡量矩阵奇异值的香农熵，从而确定层的映射效果。通过结合联邦学习和学习度量方法，本研究将(1)提供第一个联邦学习度量聚合方法，(2)证明有效秩适用于联邦问题，优于基准的联邦平均方法，(3)开发一种依赖有效秩的新型权重聚合方案。

    Currently in the federated setting, no learning schemes leverage the emerging research of explainable artificial intelligence (XAI) in particular the novel learning metrics that help determine how well a model is learning. One of these novel learning metrics is termed `Effective Rank' (ER) which measures the Shannon Entropy of the singular values of a matrix, thus enabling a metric determining how well a layer is mapping. By joining federated learning and the learning metric, effective rank, this work will \textbf{(1)} give the first federated learning metric aggregation method \textbf{(2)} show that effective rank is well-suited to federated problems by out-performing baseline Federated Averaging \cite{konevcny2016federated} and \textbf{(3)} develop a novel weight-aggregation scheme relying on effective rank.
    
[^21]: DiffuGen：使用稳定扩散模型生成标记图像数据集的可适应方法

    DiffuGen: Adaptable Approach for Generating Labeled Image Datasets using Stable Diffusion Models. (arXiv:2309.00248v1 [cs.CV])

    [http://arxiv.org/abs/2309.00248](http://arxiv.org/abs/2309.00248)

    DiffuGen是一种利用稳定扩散模型高效生成标记图像数据集的简单而可适应的方法，并结合无监督和监督标注技术，以确保生成数据集的质量和提供多功能解决方案。

    

    在计算机视觉领域，生成高质量的标记图像数据集对于训练准确且鲁棒的机器学习模型至关重要。然而，手动标注真实图像的过程往往耗时且昂贵。为了解决与数据集生成相关的挑战，我们提出了“DiffuGen”，这是一种简单且可适应的方法，利用稳定扩散模型高效地创建带标记的图像数据集。通过利用稳定扩散模型，我们的方法不仅确保了生成数据集的质量，还为标签生成提供了多功能解决方案。本文介绍了DiffuGen的方法论，将扩散模型的能力与两种不同的标注技术：无监督和监督相结合。独特之处在于，DiffuGen采用了适应性图像生成的提示模板和文本反演以增强扩散模型的能力。

    Generating high-quality labeled image datasets is crucial for training accurate and robust machine learning models in the field of computer vision. However, the process of manually labeling real images is often time-consuming and costly. To address these challenges associated with dataset generation, we introduce "DiffuGen," a simple and adaptable approach that harnesses the power of stable diffusion models to create labeled image datasets efficiently. By leveraging stable diffusion models, our approach not only ensures the quality of generated datasets but also provides a versatile solution for label generation. In this paper, we present the methodology behind DiffuGen, which combines the capabilities of diffusion models with two distinct labeling techniques: unsupervised and supervised. Distinctively, DiffuGen employs prompt templating for adaptable image generation and textual inversion to enhance diffusion model capabilities.
    
[^22]: 基于大数据和神经网络的智能电网背景下的城市电力消费预测

    City electric power consumption forecasting based on big data & neural network under smart grid background. (arXiv:2309.00245v1 [eess.SY])

    [http://arxiv.org/abs/2309.00245](http://arxiv.org/abs/2309.00245)

    本论文利用大数据和神经网络，考虑了各种非线性因素，建立了一个模型来预测城市电力消费，为智能电网和智能城市提供重要参考。

    

    随着电力系统的发展，智能电网已成为智能城市的重要组成部分。合理传输电能和保证智能电网供电对智能城市非常重要，智能城市可以通过智能电网提供更好的服务。其中，预测和判断城市电力消费与电力供应和调控、发电厂的位置以及电力传输损耗的控制等密切相关。本文基于大数据建立了一个神经网络，并考虑了各种非线性因素对城市电力消费的影响，建立了一个模型以实现对电力消费的预测。基于置换重要性测试，构建了城市电力消费影响因素的评估模型，获取了城市电力消费预测的核心特征值，可以提供重要参考。

    With the development of the electric power system, the smart grid has become an important part of the smart city. The rational transmission of electric energy and the guarantee of power supply of the smart grid are very important to smart cities, smart cities can provide better services through smart grids. Among them, predicting and judging city electric power consumption is closely related to electricity supply and regulation, the location of power plants, and the control of electricity transmission losses. Based on big data, this paper establishes a neural network and considers the influence of various nonlinear factors on city electric power consumption. A model is established to realize the prediction of power consumption. Based on the permutation importance test, an evaluation model of the influencing factors of city electric power consumption is constructed to obtain the core characteristic values of city electric power consumption prediction, which can provide an important refe
    
[^23]: FactLLaMA: 基于外部知识优化指令追踪语言模型以实现自动事实核查

    FactLLaMA: Optimizing Instruction-Following Language Models with External Knowledge for Automated Fact-Checking. (arXiv:2309.00240v1 [cs.CL])

    [http://arxiv.org/abs/2309.00240](http://arxiv.org/abs/2309.00240)

    本研究提出了一种结合外部知识检索来增强指令追踪语言模型的自动事实核查方法，通过利用搜索引擎检索相关证据，并指导调整语言模型，从而提高了事实核查的准确性。

    

    自动事实核查在打击虚假信息传播中发挥了重要作用。大型语言模型（LLM）和指令追踪变种，如InstructGPT和Alpaca，在各种自然语言处理任务中展现出了显著的性能。然而，它们的知识可能并不总是最新或充分的，可能导致事实核查的不准确性。为了解决这个问题，我们提出了将指令追踪语言模型与外部证据检索相结合，以增强事实核查性能。我们的方法涉及利用搜索引擎检索与给定输入声明相关的证据。这些外部证据作为有价值的补充信息，可以增强预训练语言模型的知识。然后，我们使用这些证据对一个名为LLaMA的开源语言模型进行指令调整，从而使其更准确地预测输入声明的真实性。为了评估我们的方法，我们进行了一系列实验。

    Automatic fact-checking plays a crucial role in combating the spread of misinformation. Large Language Models (LLMs) and Instruction-Following variants, such as InstructGPT and Alpaca, have shown remarkable performance in various natural language processing tasks. However, their knowledge may not always be up-to-date or sufficient, potentially leading to inaccuracies in fact-checking. To address this limitation, we propose combining the power of instruction-following language models with external evidence retrieval to enhance fact-checking performance. Our approach involves leveraging search engines to retrieve relevant evidence for a given input claim. This external evidence serves as valuable supplementary information to augment the knowledge of the pretrained language model. Then, we instruct-tune an open-sourced language model, called LLaMA, using this evidence, enabling it to predict the veracity of the input claim more accurately. To evaluate our method, we conducted experiments 
    
[^24]: ALJP: 使用机器学习模型预测阿拉伯个人身份案件的法律判决

    ALJP: An Arabic Legal Judgment Prediction in Personal Status Cases Using Machine Learning Models. (arXiv:2309.00238v1 [cs.AI])

    [http://arxiv.org/abs/2309.00238](http://arxiv.org/abs/2309.00238)

    这项研究开发了一个使用深度学习和自然语言处理技术预测阿拉伯个人身份案件法律判决的系统，有助于改进法官和律师的工作效率，减少判决差异，并帮助诉讼当事人事先分析案件的可能结果。

    

    法律判决预测（LJP）旨在基于案情描述预测判决结果。一些研究人员已经开发出了一些技术，通过预测法律职业的结果来帮助潜在的客户。然而，没有一种提出的技术是用阿拉伯语实现的，只有少数尝试采用英语、汉语和印地语实现。在本文中，我们开发了一个系统，利用深度学习（DL）和自然语言处理（NLP）技术，从阿拉伯语案情脚本中预测判决结果，特别是在抚养权和婚姻无效的案件中。该系统将帮助法官和律师提高工作和时间效率，同时减少判决差异。此外，在审判之前，它将帮助诉讼当事人、律师和法学生分析任何给定案件的可能结果。我们使用了不同的机器和深度学习模型，如支持向量机（SVM）、逻辑回归（LR）、长短期记忆（LSTM）和双向。

    Legal Judgment Prediction (LJP) aims to predict judgment outcomes based on case description. Several researchers have developed techniques to assist potential clients by predicting the outcome in the legal profession. However, none of the proposed techniques were implemented in Arabic, and only a few attempts were implemented in English, Chinese, and Hindi. In this paper, we develop a system that utilizes deep learning (DL) and natural language processing (NLP) techniques to predict the judgment outcome from Arabic case scripts, especially in cases of custody and annulment of marriage. This system will assist judges and attorneys in improving their work and time efficiency while reducing sentencing disparity. In addition, it will help litigants, lawyers, and law students analyze the probable outcomes of any given case before trial. We use a different machine and deep learning models such as Support Vector Machine (SVM), Logistic regression (LR), Long Short Term Memory (LSTM), and Bidir
    
[^25]: 基于合成临床记录的公开可共享的临床大语言模型

    Publicly Shareable Clinical Large Language Model Built on Synthetic Clinical Notes. (arXiv:2309.00237v1 [cs.CL])

    [http://arxiv.org/abs/2309.00237](http://arxiv.org/abs/2309.00237)

    使用合成临床记录构建的临床大语言模型可以克服临床记录的有限可及性和可用性的问题，并在现实应用中表现出潜在的良好性能。

    

    基于合成的临床案例报告，我们首先创建了大规模的合成临床记录，以解决临床记录的有限可及性和可用性的问题。然后，我们使用这些合成记录来训练我们的专门的临床大语言模型Asclepius。虽然Asclepius是在合成数据上训练的，但我们通过使用真实临床记录对其进行评估，以评估其在现实应用中的潜在性能。我们将Asclepius与包括GPT-3.5-turbo和其他开源替代方案在内的几种其他大语言模型进行了基准测试。为了进一步验证我们使用合成记录的方法，我们还将Asclepius与其在真实临床记录上训练的变体进行了比较。我们的发现有力地证明，合成临床记录在构建临床大语言模型时可以作为可行的替代品。

    The development of large language models tailored for handling patients' clinical notes is often hindered by the limited accessibility and usability of these notes due to strict privacy regulations. To address these challenges, we first create synthetic large-scale clinical notes using publicly available case reports extracted from biomedical literature. We then use these synthetic notes to train our specialized clinical large language model, Asclepius. While Asclepius is trained on synthetic data, we assess its potential performance in real-world applications by evaluating it using real clinical notes. We benchmark Asclepius against several other large language models, including GPT-3.5-turbo and other open-source alternatives. To further validate our approach using synthetic notes, we also compare Asclepius with its variants trained on real clinical notes. Our findings convincingly demonstrate that synthetic clinical notes can serve as viable substitutes for real ones when constructi
    
[^26]: 用于语义监测公司披露的大型语言模型：韩国KOSPI前50家公司的案例研究

    Large Language Models for Semantic Monitoring of Corporate Disclosures: A Case Study on Korea's Top 50 KOSPI Companies. (arXiv:2309.00208v1 [cs.CL])

    [http://arxiv.org/abs/2309.00208](http://arxiv.org/abs/2309.00208)

    本研究探讨了OpenAI的GPT-3.5-turbo和GPT-4在韩国上市公司披露中的语义分析能力，并发现GPT-4在人类评估中表现出显著的准确性。

    

    在快速发展的人工智能领域中，OpenAI的GPT-3.5-turbo和GPT-4等最先进的语言模型为自动化复杂任务提供了前所未有的机会。本研究深入探讨了这些模型在韩国情境下语义分析公司披露的能力，特别是对及时披露的能力。研究聚焦于韩国KOSPI上市的市值前50家上市公司，并在17个月的时间内详细审查了它们的月度披露摘要。每个摘要都按照从1（非常负面）到5（非常正面）的比例进行了情感评级。为了衡量语言模型的有效性，将它们的情感评级与人工专家生成的评级进行了比较。我们的研究结果显示了GPT-3.5-turbo和GPT-4之间明显的性能差异，后者在人类评估测试中展现出了显著的准确性。

    In the rapidly advancing domain of artificial intelligence, state-of-the-art language models such as OpenAI's GPT-3.5-turbo and GPT-4 offer unprecedented opportunities for automating complex tasks. This research paper delves into the capabilities of these models for semantically analyzing corporate disclosures in the Korean context, specifically for timely disclosure. The study focuses on the top 50 publicly traded companies listed on the Korean KOSPI, based on market capitalization, and scrutinizes their monthly disclosure summaries over a period of 17 months. Each summary was assigned a sentiment rating on a scale ranging from 1(very negative) to 5(very positive). To gauge the effectiveness of the language models, their sentiment ratings were compared with those generated by human experts. Our findings reveal a notable performance disparity between GPT-3.5-turbo and GPT-4, with the latter demonstrating significant accuracy in human evaluation tests. The Spearman correlation coefficie
    
[^27]: 自动化纤维放置中的间隙和重叠检测

    Gap and Overlap Detection in Automated Fiber Placement. (arXiv:2309.00206v1 [cs.CV])

    [http://arxiv.org/abs/2309.00206](http://arxiv.org/abs/2309.00206)

    本文介绍了一种新方法，利用光学相干断层扫描（OCT）传感器和计算机视觉技术，在自动化纤维放置（AFP）中检测和定位复合零件中的间隙和重叠。

    

    识别和修正制造缺陷，特别是间隙和重叠的问题，对确保通过自动化纤维放置（AFP）生产的高质量复合零件至关重要。这些缺陷是最常见的问题，可能会严重影响复合零件的整体质量。手动检查既耗时又劳动密集，效率低下。为了克服这一挑战，实施自动缺陷检测系统是最佳解决方案。在本文中，我们介绍了一种使用光学相干断层扫描（OCT）传感器和计算机视觉技术来检测和定位复合零件中间隙和重叠的新方法。我们的方法涉及生成复合表面的深度图像，突出显示表面上复合带（或线）的高度。通过检测每个线的边界，我们的算法可以比较相邻的线，并识别出间隙或重叠。

    The identification and correction of manufacturing defects, particularly gaps and overlaps, are crucial for ensuring high-quality composite parts produced through Automated Fiber Placement (AFP). These imperfections are the most commonly observed issues that can significantly impact the overall quality of the composite parts. Manual inspection is both time-consuming and labor-intensive, making it an inefficient approach. To overcome this challenge, the implementation of an automated defect detection system serves as the optimal solution. In this paper, we introduce a novel method that uses an Optical Coherence Tomography (OCT) sensor and computer vision techniques to detect and locate gaps and overlaps in composite parts. Our approach involves generating a depth map image of the composite surface that highlights the elevation of composite tapes (or tows) on the surface. By detecting the boundaries of each tow, our algorithm can compare consecutive tows and identify gaps or overlaps tha
    
[^28]: 无监督机器学习模型选择中的主观性

    Subjectivity in Unsupervised Machine Learning Model Selection. (arXiv:2309.00201v1 [cs.LG])

    [http://arxiv.org/abs/2309.00201](http://arxiv.org/abs/2309.00201)

    无监督机器学习模型选择具有主观性，模型选择结果受模型构建者偏好的影响，并可能导致选择的不一致性。需要对模型选择过程进行更加深入的研究和标准化。

    

    模型选择是无监督机器学习中必要的步骤。尽管有很多标准和指标，但模型选择仍然存在主观性。高度主观性可能会对各种机器学习研究的重复性和可再现性产生疑问，并对实际部署的模型的稳健性产生怀疑。然而，模型选择结果中模型构建者的偏好影响的影响尚未得到充分探索。本研究以隐马尔可夫模型为例，调查了模型选择中的主观性。我们邀请了33位参与者和三个大型语言模型（LLMs），在三个场景中进行模型选择。结果显示，无论是参与者还是LLMs的选择都存在变异性和不一致性，尤其是当不同的标准和指标存在分歧时。主观性来源包括对不同标准和指标重要性的不同意见，对模型应该有多简洁的不同看法，以及对数据规模的大小的看法。

    Model selection is a necessary step in unsupervised machine learning. Despite numerous criteria and metrics, model selection remains subjective. A high degree of subjectivity may lead to questions about repeatability and reproducibility of various machine learning studies and doubts about the robustness of models deployed in the real world. Yet, the impact of modelers' preferences on model selection outcomes remains largely unexplored. This study uses the Hidden Markov Model as an example to investigate the subjectivity involved in model selection. We asked 33 participants and three Large Language Models (LLMs) to make model selections in three scenarios. Results revealed variability and inconsistencies in both the participants' and the LLMs' choices, especially when different criteria and metrics disagree. Sources of subjectivity include varying opinions on the importance of different criteria and metrics, differing views on how parsimonious a model should be, and how the size of a da
    
[^29]: 基于聚类的条件扩散模型用于食物图像生成

    Diffusion Model with Clustering-based Conditioning for Food Image Generation. (arXiv:2309.00199v1 [cs.CV])

    [http://arxiv.org/abs/2309.00199](http://arxiv.org/abs/2309.00199)

    

    

    基于图像的膳食评估是使用进食场合图像作为输入的高效准确的记录和分析营养摄入的解决方案。基于深度学习的技术通常用于进行食物分类、分割和份量估计等图像分析任务，这些任务依赖于大量带有注释的食物图像进行训练。然而，这种数据依赖性对于真实世界应用来说存在重大障碍，因为获取大量丰富多样且平衡的食物图像集可能具有挑战性。一种潜在的解决方案是使用合成的食物图像进行数据增强。尽管现有的研究已经探索了基于生成对抗网络（GAN）的结构进行生成，但合成食物图像的质量仍然不理想。此外，尽管扩散式生成模型已经在一般图像生成任务中显示出了良好的结果，但生成食物图像可能具有挑战性，因为要生成真实的食物外观和细节是困难的。

    Image-based dietary assessment serves as an efficient and accurate solution for recording and analyzing nutrition intake using eating occasion images as input. Deep learning-based techniques are commonly used to perform image analysis such as food classification, segmentation, and portion size estimation, which rely on large amounts of food images with annotations for training. However, such data dependency poses significant barriers to real-world applications, because acquiring a substantial, diverse, and balanced set of food images can be challenging. One potential solution is to use synthetic food images for data augmentation. Although existing work has explored the use of generative adversarial networks (GAN) based structures for generation, the quality of synthetic food images still remains subpar. In addition, while diffusion-based generative models have shown promising results for general image generation tasks, the generation of food images can be challenging due to the substan
    
[^30]: 检测群体中组织证据的轨迹方法

    Detecting Evidence of Organization in groups by Trajectories. (arXiv:2309.00172v1 [cs.AI])

    [http://arxiv.org/abs/2309.00172](http://arxiv.org/abs/2309.00172)

    本文介绍了两种新的方法来检测基于代理轨迹的网络结构推理，通过评估图熵和聚类指数的质量，这些方法在动物模拟实验中表现出了更好的效果。

    

    有效地检测组织对于打击犯罪和维护公共安全至关重要，特别是考虑到有限的人力资源和处理展现共同移动模式的每个群体的工具。本文着重解决网络结构推理（NSI）挑战。因此，我们介绍了两种基于代理轨迹的检测网络结构推理的新方法。第一种方法基于图熵的评估，而第二种方法考虑聚类指数的质量。为了评估新方法的有效性，我们在NetLogo平台上使用基于动物王国的四个场景模拟进行了实验：蚂蚁、狼羊捕食、群聚和蚂蚁适应。此外，我们将所得结果与文献中先前提出的方法进行了比较，将所有方法应用于NetLogo平台的模拟。结果表明，我们的新检测方法能够更好地发现组织证据。

    Effective detection of organizations is essential for fighting crime and maintaining public safety, especially considering the limited human resources and tools to deal with each group that exhibits co-movement patterns. This paper focuses on solving the Network Structure Inference (NSI) challenge. Thus, we introduce two new approaches to detect network structure inferences based on agent trajectories. The first approach is based on the evaluation of graph entropy, while the second considers the quality of clustering indices. To evaluate the effectiveness of the new approaches, we conducted experiments using four scenario simulations based on the animal kingdom, available on the NetLogo platform: Ants, Wolf Sheep Predation, Flocking, and Ant Adaptation. Furthermore, we compare the results obtained with those of an approach previously proposed in the literature, applying all methods to simulations of the NetLogo platform. The results demonstrate that our new detection approaches can mor
    
[^31]: LLM在Shell中的应用：生成式蜜罐

    LLM in the Shell: Generative Honeypots. (arXiv:2309.00155v1 [cs.CR])

    [http://arxiv.org/abs/2309.00155](http://arxiv.org/abs/2309.00155)

    本研究引入了一种基于大型语言模型的新方法来创建动态和真实的软件蜜罐，解决了以往蜜罐的重要局限性，并通过实验验证了其高准确率。

    

    蜜罐是网络安全中的重要工具。然而，大多数蜜罐（即使是高交互式的）缺乏足够的真实感来欺骗攻击者。这个限制使得它们很容易被识别，从而影响到它们的有效性。本研究引入了一种基于大型语言模型的新方法来创建动态和真实的软件蜜罐。初步结果表明，LLM能够创建可信且动态的蜜罐，能够解决以往蜜罐的重要局限性，如确定性响应、缺乏适应性等。我们通过与需要判断蜜罐回应是否虚假的攻击者进行实验来评估每个命令的真实性。我们提出的蜜罐，称为shelLM，达到了0.92的准确率。

    Honeypots are essential tools in cybersecurity. However, most of them (even the high-interaction ones) lack the required realism to engage and fool human attackers. This limitation makes them easily discernible, hindering their effectiveness. This work introduces a novel method to create dynamic and realistic software honeypots based on Large Language Models. Preliminary results indicate that LLMs can create credible and dynamic honeypots capable of addressing important limitations of previous honeypots, such as deterministic responses, lack of adaptability, etc. We evaluated the realism of each command by conducting an experiment with human attackers who needed to say if the answer from the honeypot was fake or not. Our proposed honeypot, called shelLM, reached an accuracy rate of 0.92.
    
[^32]: 游戏中基于模糊方法的儿童音视频情感识别

    Fuzzy Approach for Audio-Video Emotion Recognition in Computer Games for Children. (arXiv:2309.00138v1 [cs.AI])

    [http://arxiv.org/abs/2309.00138](http://arxiv.org/abs/2309.00138)

    本文提出了一种基于模糊方法的框架，通过分析音视频数据来识别儿童游戏中的情感。使用FER数据集检测面部表情，使用CREMA-D、TESS、RAVDESS和Savee数据集识别声音情感，然后通过模糊推理系统融合结果。系统还能检测情感稳定性和多样性。

    

    如今，电脑游戏已经广泛普及，受到各个年龄段人们的喜爱。但是对于儿童来说，玩这些游戏不仅仅是一种娱乐，更是他们发展重要技能和建立情感智力的方式。儿童在游戏过程中产生的面部表情和声音反映了他们的情绪、想法和心情。本文提出了一种新颖的框架，通过分析音频和视频数据，集成了模糊方法来识别情感。我们的重点在于儿童专用的游戏环境，旨在提升他们的用户体验。我们使用FER数据集检测从游戏屏幕上记录的视频帧中的面部表情。对于儿童在游戏过程中产生的声音的情感识别，我们使用CREMA-D、TESS、RAVDESS和Savee数据集。接下来，我们使用模糊推理系统来融合结果。除此之外，我们的系统还可以检测情感稳定性和情感多样性。

    Computer games are widespread nowadays and enjoyed by people of all ages. But when it comes to kids, playing these games can be more than just fun, it is a way for them to develop important skills and build emotional intelligence. Facial expressions and sounds that kids produce during gameplay reflect their feelings, thoughts, and moods. In this paper, we propose a novel framework that integrates a fuzzy approach for the recognition of emotions through the analysis of audio and video data. Our focus lies within the specific context of computer games tailored for children, aiming to enhance their overall user experience. We use the FER dataset to detect facial emotions in video frames recorded from the screen during the game. For the audio emotion recognition of sounds a kid produces during the game, we use CREMA-D, TESS, RAVDESS, and Savee datasets. Next, a fuzzy inference system is used for the fusion of results. Besides this, our system can detect emotion stability and emotion divers
    
[^33]: 使用时间序列分析和自然语言处理预测金融市场趋势

    Predicting Financial Market Trends using Time Series Analysis and Natural Language Processing. (arXiv:2309.00136v1 [q-fin.ST])

    [http://arxiv.org/abs/2309.00136](http://arxiv.org/abs/2309.00136)

    本研究通过分析推文中表达的情绪，使用时间序列分析和自然语言处理预测了特斯拉、苹果等主要公司股票价格的波动。结果表明，积极性、消极性和主观性是股票价格波动的主要决定因素。

    

    通过时间序列分析和自然语言处理预测金融市场趋势是一项复杂而具有挑战性的任务，因为许多变量可以影响股票价格。这些变量涵盖了一系列经济和政治事件，以及当前的公众态度。最近的研究表明，社交媒体平台上公众情绪的表达（如Twitter）可能对股票价格的确定产生重要影响。本研究旨在评估Twitter情绪作为预测特斯拉、苹果等主要公司股票价格的工具的可行性。我们的研究发现，推文中传达的情绪与股票价格的波动之间存在强有力的关联。我们的研究结果表明，积极性、消极性和主观性是股票价格波动的主要决定因素。数据使用了长短期记忆神经网络（LSTM）模型进行分析。

    Forecasting financial market trends through time series analysis and natural language processing poses a complex and demanding undertaking, owing to the numerous variables that can influence stock prices. These variables encompass a spectrum of economic and political occurrences, as well as prevailing public attitudes. Recent research has indicated that the expression of public sentiments on social media platforms such as Twitter may have a noteworthy impact on the determination of stock prices. The objective of this study was to assess the viability of Twitter sentiments as a tool for predicting stock prices of major corporations such as Tesla, Apple. Our study has revealed a robust association between the emotions conveyed in tweets and fluctuations in stock prices. Our findings indicate that positivity, negativity, and subjectivity are the primary determinants of fluctuations in stock prices. The data was analyzed utilizing the Long-Short Term Memory neural network (LSTM) model, whi
    
[^34]: 建构语法与人工智能的关系

    Construction Grammar and Artificial Intelligence. (arXiv:2309.00135v1 [cs.AI])

    [http://arxiv.org/abs/2309.00135](http://arxiv.org/abs/2309.00135)

    建构语法和人工智能之间有着紧密的关系，人工智能领域的洞见和技术对于操作化建构主义方法以及构建智能代理非常重要。

    

    在本文中，我们认为对于当代的建构语法学者来说，深入理解建构语法与人工智能研究领域之间的紧密关系非常有益。我们首先揭示了两个领域之间的历史联系，展示了它们的关系根植于对人类沟通和语言的共同态度。然后我们讨论了第一个影响方向，特别关注人工智能领域的洞见和技术在操作化、验证和扩展语言建构主义方法中的重要作用。然后，我们进一步讨论了第二个影响方向，强调建构语法洞见和分析对于构建真正智能代理的人工智能努力的重要性。我们用各种例子支持我们的观点，并得出结论认为进一步发展这种关系十分重要。

    In this chapter, we argue that it is highly beneficial for the contemporary construction grammarian to have a thorough understanding of the strong relationship between the research fields of construction grammar and artificial intelligence. We start by unravelling the historical links between the two fields, showing that their relationship is rooted in a common attitude towards human communication and language. We then discuss the first direction of influence, focussing in particular on how insights and techniques from the field of artificial intelligence play an important role in operationalising, validating and scaling constructionist approaches to language. We then proceed to the second direction of influence, highlighting the relevance of construction grammar insights and analyses to the artificial intelligence endeavour of building truly intelligent agents. We support our case with a variety of illustrative examples and conclude that the further elaboration of this relationship wi
    
[^35]: 开放词汇语义分割通过属性分解聚合

    Open-Vocabulary Semantic Segmentation via Attribute Decomposition-Aggregation. (arXiv:2309.00096v1 [cs.CV])

    [http://arxiv.org/abs/2309.00096](http://arxiv.org/abs/2309.00096)

    本研究提出了一种通过属性分解聚合的框架来解决开放词汇语义分割中存在的问题，该框架受到人类认知解释新概念的启发。

    

    开放词汇语义分割是一项具有挑战性的任务，需要在推理时对新的对象类别进行分割。最近的研究探索了视觉-语言预训练来处理这个任务，但在实际场景中存在不切实际的假设，即低质量的文本类别名称。例如，这种范式假设新的文本类别将被准确完整地提供，并且存在于预训练期间的词典中。然而，当遇到简短或不完整的名称、在预训练的词典中不存在的新词以及难以描述的类别时，异常情况经常发生。为了解决这些问题，本文提出了一种新的分解-聚合框架，受人类认知在理解新概念方面的启发。具体地，在分解阶段，我们将类别名称分解为多样的属性描述，以丰富语义上下文。设计了两种属性构建策略：使用大型语言

    Open-vocabulary semantic segmentation is a challenging task that requires segmenting novel object categories at inference time. Recent works explore vision-language pre-training to handle this task, but suffer from unrealistic assumptions in practical scenarios, i.e., low-quality textual category names. For example, this paradigm assumes that new textual categories will be accurately and completely provided, and exist in lexicons during pre-training. However, exceptions often happen when meet with ambiguity for brief or incomplete names, new words that are not present in the pre-trained lexicons, and difficult-to-describe categories for users. To address these issues, this work proposes a novel decomposition-aggregation framework, inspired by human cognition in understanding new concepts. Specifically, in the decomposition stage, we decouple class names into diverse attribute descriptions to enrich semantic contexts. Two attribute construction strategies are designed: using large langu
    
[^36]: 医学中的大语言模型：潜力与风险

    Large language models in medicine: the potentials and pitfalls. (arXiv:2309.00087v1 [cs.CL])

    [http://arxiv.org/abs/2309.00087](http://arxiv.org/abs/2309.00087)

    医学中大规模语言模型（LLMs）的潜力和风险。LLMs已经被广泛应用于医疗任务，但在使用时存在潜在的问题。本文回顾了LLMs的发展、应用和可能的限制，以帮助医疗从业者理解和应对LLMs在医学中的挑战。

    

    大规模语言模型（LLMs）已经被应用于医疗中的各种任务，从医学考试问题到回答患者问题。随着生产LLMs的公司与医疗系统之间的机构合作增加，真实世界的临床应用正逐渐成为现实。随着这些模型的推广，医疗从业者了解LLMs是什么，它们的发展以及在医学中的当前和潜在应用，以及在使用LLMs时可能出现的问题至关重要。本综述和配套教程旨在为医疗从业者提供关于这些主题的概述，以帮助他们理解LLMs在医学中应用的快速变化的情况。

    Large language models (LLMs) have been applied to tasks in healthcare, ranging from medical exam questions to responding to patient questions. With increasing institutional partnerships between companies producing LLMs and healthcare systems, real world clinical application is coming closer to reality. As these models gain traction, it is essential for healthcare practitioners to understand what LLMs are, their development, their current and potential applications, and the associated pitfalls when utilized in medicine. This review and accompanying tutorial aim to give an overview of these topics to aid healthcare practitioners in understanding the rapidly changing landscape of LLMs as applied to medicine.
    
[^37]: RePo: 通过正则化后验可预测性增强弹性模型基础强化学习

    RePo: Resilient Model-Based Reinforcement Learning by Regularizing Posterior Predictability. (arXiv:2309.00082v1 [cs.LG])

    [http://arxiv.org/abs/2309.00082](http://arxiv.org/abs/2309.00082)

    本文提出了RePo算法，通过正则化后验可预测性的方式，增强了视觉模型基础强化学习方法的弹性。该方法通过学习一个对冗余和伪变化具有弹性的潜在表示，提高了方法对视觉干扰的鲁棒性，使其能够在动态环境中运行。

    

    视觉模型基础强化学习方法通常将图像观测编码为低维表示方式，这种方式未能消除冗余信息。这使得这些方法容易受到伪变化的影响，即与任务无关的组成部分的变化，如背景干扰因素或光照条件的变化。本文提出了一种视觉模型基础强化学习方法，该方法学习到了一种对这种伪变化具有弹性的潜在表示。我们的训练目标鼓励该表示在动力学和奖励预测方面具有最大的预测性，同时限制了观测到潜在表示的信息流。我们证明了这一目标极大增强了视觉模型基础强化学习方法对视觉干扰的弹性，使其能够在动态环境中运行。然后我们展示了虽然学习到的编码器对伪变化具有弹性，但在显著分布变化下并没有不变性。为了解决这个问题，我们提出了一个简单的奖励方案。

    Visual model-based RL methods typically encode image observations into low-dimensional representations in a manner that does not eliminate redundant information. This leaves them susceptible to spurious variations -- changes in task-irrelevant components such as background distractors or lighting conditions. In this paper, we propose a visual model-based RL method that learns a latent representation resilient to such spurious variations. Our training objective encourages the representation to be maximally predictive of dynamics and reward, while constraining the information flow from the observation to the latent representation. We demonstrate that this objective significantly bolsters the resilience of visual model-based RL methods to visual distractors, allowing them to operate in dynamic environments. We then show that while the learned encoder is resilient to spirious variations, it is not invariant under significant distribution shift. To address this, we propose a simple reward-f
    
[^38]: 关于Adam的隐式偏差

    On the Implicit Bias of Adam. (arXiv:2309.00079v1 [cs.LG])

    [http://arxiv.org/abs/2309.00079](http://arxiv.org/abs/2309.00079)

    本文证明了RMSProp和Adam存在隐式规范化作用，其取决于超参数和训练阶段，并讨论了这些证明事实对泛化的影响。

    

    在以前的文献中，后向误差分析被用来找到近似梯度下降轨迹的常微分方程（ODEs）。发现有限步长会隐式地规范化解决方案，因为出现在ODE中的项会惩罚损失梯度的二范数。我们证明了RMSProp和Adam中是否存在类似的隐式规范化取决于它们的超参数和训练阶段，但涉及的“范数”不同：对应的ODE项要么惩罚（扰动的）损失梯度的一范数，要么相反地阻止其减小（后一种情况是典型的）。我们还进行了数值实验，并讨论了这些证明事实如何影响泛化。

    In previous literature, backward error analysis was used to find ordinary differential equations (ODEs) approximating the gradient descent trajectory. It was found that finite step sizes implicitly regularize solutions because terms appearing in the ODEs penalize the two-norm of the loss gradients. We prove that the existence of similar implicit regularization in RMSProp and Adam depends on their hyperparameters and the training stage, but with a different "norm" involved: the corresponding ODE terms either penalize the (perturbed) one-norm of the loss gradients or, on the contrary, hinder its decrease (the latter case being typical). We also conduct numerical experiments and discuss how the proven facts can influence generalization.
    
[^39]: YaRN: 大型语言模型的高效上下文窗口扩展方法

    YaRN: Efficient Context Window Extension of Large Language Models. (arXiv:2309.00071v1 [cs.CL])

    [http://arxiv.org/abs/2309.00071](http://arxiv.org/abs/2309.00071)

    YaRN是一种高效的上下文窗口扩展方法，可以在大型语言模型中有效利用和推断比原始预训练允许的上下文长度更长的上下文，同时超越了之前的最新研究成果。

    

    旋转位置嵌入（RoPE）已被证明可以有效地编码transformer-based语言模型中的位置信息。然而，这些模型在超过它们训练的序列长度时无法泛化。我们提出了YaRN（Yet another RoPE extensioN method），一种计算高效的方法来扩展这些模型的上下文窗口，需要的tokens数量和训练步骤少于之前的方法的10倍和2.5倍。使用YaRN，我们展示了LLaMA模型可以有效地利用和推断比原始预训练允许的上下文长度更长的上下文，并且在上下文窗口扩展方面超过了之前的最新研究成果。此外，我们还展示了YaRN具有超越微调数据集有限上下文的能力。我们在https://github.com/jquesnelle/yarn上发布了使用64k和128k上下文窗口进行Fine-tuning的Llama 2 7B/13B的检查点。

    Rotary Position Embeddings (RoPE) have been shown to effectively encode positional information in transformer-based language models. However, these models fail to generalize past the sequence length they were trained on. We present YaRN (Yet another RoPE extensioN method), a compute-efficient method to extend the context window of such models, requiring 10x less tokens and 2.5x less training steps than previous methods. Using YaRN, we show that LLaMA models can effectively utilize and extrapolate to context lengths much longer than their original pre-training would allow, while also surpassing previous the state-of-the-art at context window extension. In addition, we demonstrate that YaRN exhibits the capability to extrapolate beyond the limited context of a fine-tuning dataset. We publish the checkpoints of Llama 2 7B/13B fine-tuned using YaRN with 64k and 128k context windows at https://github.com/jquesnelle/yarn
    
[^40]: 在医疗保健领域和其他领域利用人工智能的伦理框架

    Ethical Framework for Harnessing the Power of AI in Healthcare and Beyond. (arXiv:2309.00064v1 [cs.CY])

    [http://arxiv.org/abs/2309.00064](http://arxiv.org/abs/2309.00064)

    这篇论文研究了与人工智能技术在医疗保健领域快速发展密切相关的伦理维度，并提出了一个以透明度、公平性、问责性和以人为本为核心价值的伦理框架。

    

    在过去的十年中，深度学习（人工智能）方法的应用已经在各种真实应用中普遍存在，往往涉及到安全关键的情境。本研究全面探讨了与人工智能技术的快速发展密切相关的伦理维度，特别关注了医疗保健领域。在深入研究中，它探索了多个方面，包括透明度、熟练的数据管理、人工监督、教育要求以及人工智能进步领域的国际合作。本文的核心是提出了一个良知意识的人工智能框架，精心设计以突显透明度、公平性、问责性和以人为本的导向。本文的第二个贡献是对人工智能系统固有局限性的深入和全面讨论。它精明地识别出潜在的偏见和导航多重挑战的复杂问题。

    In the past decade, the deployment of deep learning (Artificial Intelligence (AI)) methods has become pervasive across a spectrum of real-world applications, often in safety-critical contexts. This comprehensive research article rigorously investigates the ethical dimensions intricately linked to the rapid evolution of AI technologies, with a particular focus on the healthcare domain. Delving deeply, it explores a multitude of facets including transparency, adept data management, human oversight, educational imperatives, and international collaboration within the realm of AI advancement. Central to this article is the proposition of a conscientious AI framework, meticulously crafted to accentuate values of transparency, equity, answerability, and a human-centric orientation. The second contribution of the article is the in-depth and thorough discussion of the limitations inherent to AI systems. It astutely identifies potential biases and the intricate challenges of navigating multiface
    
[^41]: FACET:计算机视觉评估基准中的公平性

    FACET: Fairness in Computer Vision Evaluation Benchmark. (arXiv:2309.00035v1 [cs.CV])

    [http://arxiv.org/abs/2309.00035](http://arxiv.org/abs/2309.00035)

    FACET是一个用于评估计算机视觉模型公平性的大型基准，提供了可公开访问的图像集，对于常见的视觉任务进行了标注，同时使用专家评审员手动标注人类属性和类别信息，并用于对最先进的视觉模型进行基准测试。

    

    计算机视觉模型在性别和肤色等属性上存在已知的性能差异。这意味着在分类和检测等任务中，模型对于特定类别的性能会根据图像中人的人口统计学而有所不同。这些差异已被证明存在，但直到现在还没有一个统一的方法来衡量计算机视觉模型在常见的用例中的这些差异。我们提出了一个名为FACET（FAirness in Computer Vision EvaluaTion）的新基准，这是一个公开可用的大型评估集，包含了三种最常见的视觉任务-图像分类、物体检测和分割的32k张图片。对于FACET中的每一张图片，我们雇用专家评审员手动标注与人相关的属性，如感知的肤色和发型类型，手动绘制边界框，并标记细粒度的与人相关的类别，如碟艺人或吉他手。此外，我们使用FACET来评估最先进的视觉模型。

    Computer vision models have known performance disparities across attributes such as gender and skin tone. This means during tasks such as classification and detection, model performance differs for certain classes based on the demographics of the people in the image. These disparities have been shown to exist, but until now there has not been a unified approach to measure these differences for common use-cases of computer vision models. We present a new benchmark named FACET (FAirness in Computer Vision EvaluaTion), a large, publicly available evaluation set of 32k images for some of the most common vision tasks - image classification, object detection and segmentation. For every image in FACET, we hired expert reviewers to manually annotate person-related attributes such as perceived skin tone and hair type, manually draw bounding boxes and label fine-grained person-related classes such as disk jockey or guitarist. In addition, we use FACET to benchmark state-of-the-art vision models 
    
[^42]: 探索大型语言模型在生成编程反馈方面的潜力

    Exploring the Potential of Large Language Models to Generate Formative Programming Feedback. (arXiv:2309.00029v1 [cs.AI])

    [http://arxiv.org/abs/2309.00029](http://arxiv.org/abs/2309.00029)

    本文探索了大型语言模型（LLM）在计算机教育方面的潜力，研究了其在编程任务中生成的反馈，结果表明学生可以从中受益，但教育者应该提供使用指导。

    

    自从大型语言模型（LLM）和相关应用如ChatGPT出现以来，其在编程任务中的性能和错误分析一直是研究的对象。本文中，我们研究了这样的LLM对计算机教育工作者和学习者的潜力，分析其对包含程序代码的输入所生成的反馈。特别地，我们旨在（1）探索像ChatGPT这样的LLM对寻求帮助于入门级编程任务的学生的回应，以及（2）识别其回应中的反馈类型。为了实现这些目标，我们使用了从一个CS1课程中收集的学生编程序列作为ChatGPT的输入，并提出了问题以引导反馈和正确的解决方案。结果显示，ChatGPT在某些入门级编程任务和学生错误方面表现得相当不错，这意味着学生有可能从中受益。然而，教育者应该提供如何使用这些模型的指导。

    Ever since the emergence of large language models (LLMs) and related applications, such as ChatGPT, its performance and error analysis for programming tasks have been subject to research. In this work-in-progress paper, we explore the potential of such LLMs for computing educators and learners, as we analyze the feedback it generates to a given input containing program code. In particular, we aim at (1) exploring how an LLM like ChatGPT responds to students seeking help with their introductory programming tasks, and (2) identifying feedback types in its responses. To achieve these goals, we used students' programming sequences from a dataset gathered within a CS1 course as input for ChatGPT along with questions required to elicit feedback and correct solutions. The results show that ChatGPT performs reasonably well for some of the introductory programming tasks and student errors, which means that students can potentially benefit. However, educators should provide guidance on how to us
    
[^43]: 无监督发现可解释的视觉概念

    Unsupervised discovery of Interpretable Visual Concepts. (arXiv:2309.00018v1 [cs.CV])

    [http://arxiv.org/abs/2309.00018](http://arxiv.org/abs/2309.00018)

    本文提出了两种方法（MAGE和Ms-IV），用于解释深度学习模型的决策，提高全局可解释性。MAGE可以发现形成语义含义的特征组合，将其称为概念，并通过聚类分组为“概念”，然后通过Ms-IV进行可视化。这一方法受到阻断和敏感性分析的启发，并使用一种新的指标（CaOC）全局评估模型最重要的图像区域。

    

    深度学习模型的可解释性对于非专家用户非常重要，但是在实际应用中，提供给用户的模型解释性是一项具有挑战性的任务。诸如集成梯度等可解释性方法产生了包含大量信息但难以解释的归因映射。本文提出了两种方法，最大激活组提取（MAGE）和多尺度可解释性可视化（Ms-IV），用于解释模型的决策，提高全局可解释性。MAGE可以找到给定CNN中形成语义含义的特征组合，我们将其称为概念，并通过聚类将这些相似特征模式分组为“概念”，然后通过Ms-IV进行可视化。这一方法受到阻断和敏感性分析的启发（包括因果关系），并使用一种新的指标，称为类别感知顺序相关性（CaOC），全局评估根据模型预测结果最重要的图像区域。

    Providing interpretability of deep-learning models to non-experts, while fundamental for a responsible real-world usage, is challenging. Attribution maps from xAI techniques, such as Integrated Gradients, are a typical example of a visualization technique containing a high level of information, but with difficult interpretation. In this paper, we propose two methods, Maximum Activation Groups Extraction (MAGE) and Multiscale Interpretable Visualization (Ms-IV), to explain the model's decision, enhancing global interpretability. MAGE finds, for a given CNN, combinations of features which, globally, form a semantic meaning, that we call concepts. We group these similar feature patterns by clustering in ``concepts'', that we visualize through Ms-IV. This last method is inspired by Occlusion and Sensitivity analysis (incorporating causality), and uses a novel metric, called Class-aware Order Correlation (CaOC), to globally evaluate the most important image regions according to the model's 
    
[^44]: 基于异步时空图卷积网络的不规则交通时间序列预测

    Irregular Traffic Time Series Forecasting Based on Asynchronous Spatio-Temporal Graph Convolutional Network. (arXiv:2308.16818v1 [cs.LG])

    [http://arxiv.org/abs/2308.16818](http://arxiv.org/abs/2308.16818)

    该论文提出了一种基于异步时空图卷积网络的不规则交通时间序列预测方法，用于解决智能交叉口产生的异步空间依赖、不规则时间依赖和可变长度序列预测等挑战。

    

    准确预测智能交通信号控制系统中受智能交叉口控制的交叉口的交通流量对于提升交通出行效率至关重要。然而，由于智能交叉口产生的交通时间序列不规则，交通流量预测任务变得更加困难，并且面临三个主要挑战：1）异步的空间依赖性，2）交通数据的不规则时间依赖性，3) 需要预测的可变长度序列，严重影响了当前交通流量预测方法的性能。为此，我们提出了一种异步时空图卷积网络(ASeer)来预测智能交叉口进入车道的交通状态。具体而言，通过在交通扩散图上连接车道，我们首先提出了一种异步图扩散网络来模拟车道的异步空间依赖性。

    Accurate traffic forecasting at intersections governed by intelligent traffic signals is critical for the advancement of an effective intelligent traffic signal control system. However, due to the irregular traffic time series produced by intelligent intersections, the traffic forecasting task becomes much more intractable and imposes three major new challenges: 1) asynchronous spatial dependency, 2) irregular temporal dependency among traffic data, and 3) variable-length sequence to be predicted, which severely impede the performance of current traffic forecasting methods. To this end, we propose an Asynchronous Spatio-tEmporal graph convolutional nEtwoRk (ASeer) to predict the traffic states of the lanes entering intelligent intersections in a future time window. Specifically, by linking lanes via a traffic diffusion graph, we first propose an Asynchronous Graph Diffusion Network to model the asynchronous spatial dependency between the time-misaligned traffic state measurements of la
    
[^45]: 鲁棒的网络化联邦学习在定位中的应用

    Robust Networked Federated Learning for Localization. (arXiv:2308.16737v1 [cs.LG])

    [http://arxiv.org/abs/2308.16737](http://arxiv.org/abs/2308.16737)

    本文提出了一种鲁棒的网络化联邦学习方法，通过采用$L_1$-范数鲁棒性和分布式次梯度框架，解决了在分布式环境中定位问题中的异常数据干扰和算法收敛挑战。

    

    本文解决了在数据分布在多设备上的联邦环境中，本质上是非凸非光滑的定位问题。由于联邦环境的分散性质，分布式学习成为可伸缩性和适应性的关键。此外，这些环境经常受到异常数据的干扰，使得传统方法在维护估计精度和确保算法收敛方面面临重大挑战。为了解决这些挑战，我们提出了一种采用分布式次梯度框架中$L_1$-范数鲁棒性的方法，专门设计用于处理这些障碍。我们的方法以原始形式解决问题，而不是采用迭代简化或近似方法，从而提高计算效率和估计精度。我们证明了我们的方法收敛到一个稳定点，突出了其有效性。

    This paper addresses the problem of localization, which is inherently non-convex and non-smooth in a federated setting where the data is distributed across a multitude of devices. Due to the decentralized nature of federated environments, distributed learning becomes essential for scalability and adaptability. Moreover, these environments are often plagued by outlier data, which presents substantial challenges to conventional methods, particularly in maintaining estimation accuracy and ensuring algorithm convergence. To mitigate these challenges, we propose a method that adopts an $L_1$-norm robust formulation within a distributed sub-gradient framework, explicitly designed to handle these obstacles. Our approach addresses the problem in its original form, without resorting to iterative simplifications or approximations, resulting in enhanced computational efficiency and improved estimation accuracy. We demonstrate that our method converges to a stationary point, highlighting its effec
    
[^46]: 推荐AI代理：将大型语言模型整合到交互式推荐中

    Recommender AI Agent: Integrating Large Language Models for Interactive Recommendations. (arXiv:2308.16505v1 [cs.IR])

    [http://arxiv.org/abs/2308.16505](http://arxiv.org/abs/2308.16505)

    本论文的创新点是将推荐模型和大型语言模型（LLMs）融合，创建了一个多功能交互式推荐系统，解决了推荐模型在提供解释和参与对话任务方面的困难。

    

    推荐模型通过利用广泛的用户行为数据来提供领域特定的物品推荐，展现出轻量级领域专家的能力。然而，它们在提供解释和参与对话等多样化任务方面存在困难。另一方面，大型语言模型（LLMs）代表了人工通用智能的重要进展，在指令理解、常识推理和人类交互方面表现出了显著能力。然而，LLMs缺乏领域特定物品目录和行为模式的知识，特别是在与一般世界知识不同的领域，如在线电子商务。为每个领域微调LLMs既不经济又不高效。在本文中，我们将推荐模型和LLMs之间的差距，结合各自的优势，创建了一个多功能交互式推荐系统。我们引入了一个高效的框架称为RecAgent，该框架使用LLMs

    Recommender models excel at providing domain-specific item recommendations by leveraging extensive user behavior data. Despite their ability to act as lightweight domain experts, they struggle to perform versatile tasks such as providing explanations and engaging in conversations. On the other hand, large language models (LLMs) represent a significant step towards artificial general intelligence, showcasing remarkable capabilities in instruction comprehension, commonsense reasoning, and human interaction. However, LLMs lack the knowledge of domain-specific item catalogs and behavioral patterns, particularly in areas that diverge from general world knowledge, such as online e-commerce. Finetuning LLMs for each domain is neither economic nor efficient.  In this paper, we bridge the gap between recommender models and LLMs, combining their respective strengths to create a versatile and interactive recommender system. We introduce an efficient framework called RecAgent, which employs LLMs a
    
[^47]: 回归问题的校准解释

    Calibrated Explanations for Regression. (arXiv:2308.16245v1 [cs.LG])

    [http://arxiv.org/abs/2308.16245](http://arxiv.org/abs/2308.16245)

    本文介绍了一种针对回归问题的特征重要性解释方法的扩展，可以量化特征重要性的不确定性。

    

    人工智能（AI）通常是现代决策支持系统（DSS）的一部分。在基于AI的DSS中使用的最佳预测模型缺乏透明度。可解释的人工智能（XAI）旨在创建能够向人类用户解释其理由的AI系统。XAI中的局部解释可以提供关于个别预测的原因的信息，即特征重要性。然而，现有局部解释方法的一个关键缺点是无法量化与特征重要性相关的不确定性。本文介绍了特征重要性解释方法Calibrated Explanations（CE）的扩展，之前只支持分类，现在支持标准回归和概率回归，即目标超过任意阈值的概率。回归问题的扩展保留了CE的所有优点，例如将底层模型的预测与置信度校准。

    Artificial Intelligence (AI) is often an integral part of modern decision support systems (DSSs). The best-performing predictive models used in AI-based DSSs lack transparency. Explainable Artificial Intelligence (XAI) aims to create AI systems that can explain their rationale to human users. Local explanations in XAI can provide information about the causes of individual predictions in terms of feature importance. However, a critical drawback of existing local explanation methods is their inability to quantify the uncertainty associated with a feature's importance. This paper introduces an extension of a feature importance explanation method, Calibrated Explanations (CE), previously only supporting classification, with support for standard regression and probabilistic regression, i.e., the probability that the target is above an arbitrary threshold. The extension for regression keeps all the benefits of CE, such as calibration of the prediction from the underlying model with confidenc
    
[^48]: 美国法律体系是否准备好应对人工智能对人类价值观的挑战？

    Is the U.S. Legal System Ready for AI's Challenges to Human Values?. (arXiv:2308.15906v1 [cs.CY])

    [http://arxiv.org/abs/2308.15906](http://arxiv.org/abs/2308.15906)

    美国法律需要加强应对生成式人工智能对人类价值观挑战的能力，并提供积极、可审计的指导，以填补现有法律框架在保护基本价值观方面的空白和不确定性。

    

    我们的跨学科研究调查了美国法律在面对生成式人工智能对人类价值观挑战时的有效性。通过分析专家研讨会期间制定的多种假设情景，我们发现现有法律框架在保护自主权、隐私权、尊严、多样性、平等以及身心健康等基本价值观方面存在明显的空白和不确定性。宪法和民权法似乎无法对人工智能生成的歧视性产出提供足够的保护。此外，即使我们排除第230条款提供的责任保护，由于人工智能系统的复杂和不透明性，证明诽谤和产品责任索赔的因果关系也是一项具有挑战性的任务。为了应对生成式人工智能带来的独特和难以预测的威胁，我们主张建立能够适应新威胁并为行业利益相关者提供积极、可审计的指导的法律框架。

    Our interdisciplinary study investigates how effectively U.S. laws confront the challenges posed by Generative AI to human values. Through an analysis of diverse hypothetical scenarios crafted during an expert workshop, we have identified notable gaps and uncertainties within the existing legal framework regarding the protection of fundamental values, such as autonomy, privacy, dignity, diversity, equality, and physical/mental well-being. Constitutional and civil rights, it appears, may not provide sufficient protection against AI-generated discriminatory outputs. Furthermore, even if we exclude the liability shield provided by Section 230, proving causation for defamation and product liability claims is a challenging endeavor due to the intricate and opaque nature of AI systems. To address the unique and unforeseeable threats posed by Generative AI, we advocate for legal frameworks that evolve to recognize new threat and provide proactive, auditable guidelines to industry stakeholders
    
[^49]: 高效且可解释的图神经网络架构搜索通过蒙特卡洛树搜索

    Efficient and Explainable Graph Neural Architecture Search via Monte-Carlo Tree Search. (arXiv:2308.15734v1 [cs.LG])

    [http://arxiv.org/abs/2308.15734](http://arxiv.org/abs/2308.15734)

    该论文提出了一种高效且可解释的图神经网络架构搜索方法，名为ExGNAS。它包括适应各种图形的简单搜索空间和能解释决策过程的搜索算法。通过蒙特卡洛树搜索高效地搜索最佳GNN架构。

    

    图神经网络（GNNs）是在各个领域进行数据科学任务的强大工具。尽管我们在广泛的应用场景中使用GNNs，但对研究人员和实践者来说，在不同的图中设计/选择最佳GNN架构是一项费力的任务。为了节省人力和计算成本，已经使用图神经网络架构搜索（Graph NAS）来搜索结合现有组件的次优GNN架构。然而，目前没有现有的Graph NAS方法能够同时满足可解释性、高效性和适应多样化图形的要求。因此，我们提出了一种高效且可解释的Graph NAS方法，称为ExGNAS，它包括（i）一个可以适应各种图形的简单搜索空间和（ii）一个能够解释决策过程的搜索算法。搜索空间仅包含可以处理同质和异质图的基本函数。搜索算法通过蒙特卡洛树搜索高效地搜索最佳GNN架构。

    Graph neural networks (GNNs) are powerful tools for performing data science tasks in various domains. Although we use GNNs in wide application scenarios, it is a laborious task for researchers and practitioners to design/select optimal GNN rchitectures in diverse graphs. To save human efforts and computational costs, graph neural architecture search (Graph NAS) has been used to search for a sub-optimal GNN architecture that combines existing components. However, there are no existing Graph NAS methods that satisfy explainability, efficiency, and adaptability to various graphs. Therefore, we propose an efficient and explainable Graph NAS method, called ExGNAS, which consists of (i) a simple search space that can adapt to various graphs and (ii) a search algorithm that makes the decision process explainable. The search space includes only fundamental functions that can handle homophilic and heterophilic graphs. The search algorithm efficiently searches for the best GNN architecture via M
    
[^50]: 一种用于异常检测的综合增强框架

    A Comprehensive Augmentation Framework for Anomaly Detection. (arXiv:2308.15068v1 [cs.AI])

    [http://arxiv.org/abs/2308.15068](http://arxiv.org/abs/2308.15068)

    本文提出了一种用于异常检测的综合增强框架，该框架通过选择性地利用适当的组合，分析并压缩模拟异常的关键特征，与基于重构的方法相结合，并采用分割训练策略，能够在MVTec异常检测数据集上优于以前的最先进方法。

    

    数据增强方法通常被整合到异常检测模型的训练中。以往的方法主要集中在复制真实世界的异常或增加多样性，而没有考虑到异常的标准在不同类别之间存在差异，这可能导致训练分布的偏差。本文分析了对重构网络训练有贡献的模拟异常的关键特征，并将其压缩成几种方法，从而通过选择性地使用适当的组合来创建一个综合框架。此外，将这个框架与基于重构的方法相结合，并同时提出了一种分割训练策略，既减轻过拟合问题，又避免对重构过程引入干扰。在MVTec异常检测数据集上进行的评估表明，我们的方法在性能上优于以前的最先进方法，特别是在目标相关指标方面。

    Data augmentation methods are commonly integrated into the training of anomaly detection models. Previous approaches have primarily focused on replicating real-world anomalies or enhancing diversity, without considering that the standard of anomaly varies across different classes, potentially leading to a biased training distribution.This paper analyzes crucial traits of simulated anomalies that contribute to the training of reconstructive networks and condenses them into several methods, thus creating a comprehensive framework by selectively utilizing appropriate combinations.Furthermore, we integrate this framework with a reconstruction-based approach and concurrently propose a split training strategy that alleviates the issue of overfitting while avoiding introducing interference to the reconstruction process. The evaluations conducted on the MVTec anomaly detection dataset demonstrate that our method outperforms the previous state-of-the-art approach, particularly in terms of objec
    
[^51]: 论马尔可夫决策过程的奖励结构

    On Reward Structures of Markov Decision Processes. (arXiv:2308.14919v1 [cs.LG])

    [http://arxiv.org/abs/2308.14919](http://arxiv.org/abs/2308.14919)

    该论文研究了马尔可夫决策过程中的奖励结构，提出了一种估计器用于估计单个状态值，并通过根据奖励代替常用的基于转移的常数，提供了对强化学习中技巧的理论解释。

    

    马尔可夫决策过程可以通过转移核与奖励函数参数化。这两个因素在强化学习研究中起着重要作用，正如它们在贝尔曼方程中的存在所证明的那样。针对机器人应用中的需求，我们研究了与强化学习相关的各种"成本"，奖励是理解马尔可夫决策过程结构的核心，奖励中心概念可以阐明强化学习中的重要概念。具体而言，我们研究了策略评估的样本复杂性，并开发了一种新的估计器，其实例特定的误差界为$\tilde{O}(\sqrt{\frac{\tau_s}{n}})$，用于估计单个状态值。在在线遗憾最小化设置下，我们将基于转移的MDP常数，直径，改进为基于奖励的常数，最大预期到达成本，并通过该常数为一种广为人知的技术，基于潜力的奖励形状提供了理论解释。

    A Markov decision process can be parameterized by a transition kernel and a reward function. Both play essential roles in the study of reinforcement learning as evidenced by their presence in the Bellman equations. In our inquiry of various kinds of ``costs'' associated with reinforcement learning inspired by the demands in robotic applications, rewards are central to understanding the structure of a Markov decision process and reward-centric notions can elucidate important concepts in reinforcement learning. Specifically, we studied the sample complexity of policy evaluation and developed a novel estimator with an instance-specific error bound of $\tilde{O}(\sqrt{\frac{\tau_s}{n}})$ for estimating a single state value. Under the online regret minimization setting, we refined the transition-based MDP constant, diameter, into a reward-based constant, maximum expected hitting cost, and with it, provided a theoretical explanation for how a well-known technique, potential-based reward shap
    
[^52]: FAM：快速自适应元学习

    FAM: fast adaptive meta-learning. (arXiv:2308.13970v1 [cs.LG])

    [http://arxiv.org/abs/2308.13970](http://arxiv.org/abs/2308.13970)

    本论文提出了一个快速自适应联邦元学习（FAM）框架，可以协作学习一个全局模型，并在个别客户端上进行个性化。这解决了数据分布发散和隐私限制的问题，并且适用于需要在不同客户端之间进行个性化的领域转变。

    

    在这项工作中，我们提出了一个快速自适应联邦元学习（FAM）框架，用于协作学习一个单一全局模型，然后可以在个别客户端上个性化。联邦学习使多个客户端能够协作训练模型而不共享数据。参与联邦学习的客户端由于数据不足或数据多样性导致学习受到影响。然而，当数据分布发散时，学习会受到困扰。有必要学习一个可以使用客户端特定信息进行自适应的全局模型，并在客户端上创建个性化模型。MRI数据存在这个问题，第一，由于数据采集挑战，在某个地点的本地数据足以训练准确的模型，第二，由于隐私问题有数据共享限制，第三，由于客户端站点之间的领域转变，需要对学习的共享全局模型进行个性化。

    In this work, we propose a fast adaptive federated meta-learning (FAM) framework for collaboratively learning a single global model, which can then be personalized locally on individual clients. Federated learning enables multiple clients to collaborate to train a model without sharing data. Clients with insufficient data or data diversity participate in federated learning to learn a model with superior performance. Nonetheless, learning suffers when data distributions diverge. There is a need to learn a global model that can be adapted using client's specific information to create personalised models on clients is required. MRI data suffers from this problem, wherein, one, due to data acquisition challenges, local data at a site is sufficient for training an accurate model and two, there is a restriction of data sharing due to privacy concerns and three, there is a need for personalization of a learnt shared global model on account of domain shift across client sites. The global model
    
[^53]: 工业人工智能中的随机配置机

    Stochastic Configuration Machines for Industrial Artificial Intelligence. (arXiv:2308.13570v1 [cs.LG])

    [http://arxiv.org/abs/2308.13570](http://arxiv.org/abs/2308.13570)

    本文提出了一种新颖的随机学习器模型，称为随机配置机（SCMs），其基于随机配置网络（SCNs），旨在强调工业人工智能中的有效建模和节约数据大小。SCMs通过压缩模型存储，并保持有利的预测性能，具有在工业应用中很大的潜力。

    

    在工业人工智能（IAI）中，需要实时、准确的预测建模，神经网络在其中起到关键作用。工业人工智能中的神经网络需要强大的高性能计算设备来处理大量的浮点数据。本文基于随机配置网络（SCNs），提出了一种新的随机学习器模型，称为随机配置机（SCMs），以强调对于工业应用非常有用和有价值的有效建模和节约数据大小。与具有二值化实现的随机向量功能链接（RVFL）网络相比，SCMs的模型存储可以显著压缩，同时保持有利的预测性能。除了SCM学习器模型的架构和学习算法，作为本文的重要部分，我们还通过分析模型的复杂性提供了SCMs的学习能力的理论基础。实验研究也进行了。

    Real-time predictive modelling with desired accuracy is highly expected in industrial artificial intelligence (IAI), where neural networks play a key role. Neural networks in IAI require powerful, high-performance computing devices to operate a large number of floating point data. Based on stochastic configuration networks (SCNs), this paper proposes a new randomized learner model, termed stochastic configuration machines (SCMs), to stress effective modelling and data size saving that are useful and valuable for industrial applications. Compared to SCNs and random vector functional-link (RVFL) nets with binarized implementation, the model storage of SCMs can be significantly compressed while retaining favourable prediction performance. Besides the architecture of the SCM learner model and its learning algorithm, as an important part of this contribution, we also provide a theoretical basis on the learning capacity of SCMs by analysing the model's complexity. Experimental studies are ca
    
[^54]: 人类可理解的基因组规模代谢网络的主动学习

    Human Comprehensible Active Learning of Genome-Scale Metabolic Networks. (arXiv:2308.12740v1 [cs.AI])

    [http://arxiv.org/abs/2308.12740](http://arxiv.org/abs/2308.12740)

    这项研究介绍了一种人类可理解的基因组规模代谢网络的主动学习方法，基于归纳逻辑编程(ILP)框架进行逻辑推理，并通过从实验中学习新的逻辑结构，以有效探索假设空间和指导实验设计。

    

    合成生物学的一个重要应用是将宿主细胞系统工程化以产生有用的产品。然而，宿主系统规模的增加导致设计空间巨大，并需要大量高昂的验证试验。为了宿主细胞系统的设计-构建-测试-学习（Design-Build-Test-Learn，DBTL）周期，迫切需要一种能有效探索假设空间并指导实验设计的可理解的机器学习方法。我们引入了一种基于归纳逻辑编程（ILP）的新型机器学习框架ILP-iML1515，它通过诱导逻辑推理和从训练实例中积极学习来执行说明性的逻辑推理。与数值模型不同，ILP-iML1515建立在对基因组规模代谢模型的可理解的逻辑表示上，并可以通过从缺乏营养的突变体试验中学习新的逻辑结构来更新模型。ILP-iML1515框架具有高通量模拟能力，并能主动选择实验。

    An important application of Synthetic Biology is the engineering of the host cell system to yield useful products. However, an increase in the scale of the host system leads to huge design space and requires a large number of validation trials with high experimental costs. A comprehensible machine learning approach that efficiently explores the hypothesis space and guides experimental design is urgently needed for the Design-Build-Test-Learn (DBTL) cycle of the host cell system. We introduce a novel machine learning framework ILP-iML1515 based on Inductive Logic Programming (ILP) that performs abductive logical reasoning and actively learns from training examples. In contrast to numerical models, ILP-iML1515 is built on comprehensible logical representations of a genome-scale metabolic model and can update the model by learning new logical structures from auxotrophic mutant trials. The ILP-iML1515 framework 1) allows high-throughput simulations and 2) actively selects experiments that 
    
[^55]: 有效的语言模型基准测试

    Efficient Benchmarking (of Language Models). (arXiv:2308.11696v1 [cs.CL])

    [http://arxiv.org/abs/2308.11696](http://arxiv.org/abs/2308.11696)

    本研究提出了一种名为"Efficient Benchmarking"的问题，旨在智能地减少语言模型评估的计算成本而不降低可靠性，并使用一种名为Decision Impact on Reliability（DIoR）的新度量来评估决策的可靠性。通过HELM基准测试的案例研究，发现只需删除一个低排名模型即可改变领先者，并仅需少量示例即可得到正确的基准测试排名。

    

    语言模型的多功能性增加导致了一类全面评估广泛能力的基准测试的出现。这些基准测试与大规模计算成本相关，每个模型需要数千个GPU小时。然而，关于评估效率方面的问题在文献中讨论较少。本文提出了一种名为"Efficient Benchmarking"的问题，即在不损害可靠性的情况下智能地减少语言模型评估的计算成本。通过使用HELM基准测试作为示例，我们研究了不同基准测试设计选择如何影响计算-可靠性权衡。我们提出使用一种名为Decision Impact on Reliability（DIoR）的新度量来评估这些决策的可靠性。例如，我们发现仅通过从基准测试中删除一个低排名模型，当前在HELM上的领先者可能会改变，并且观察到只需一小部分示例即可获得正确的基准测试排名。

    The increasing versatility of language models LMs has given rise to a new class of benchmarks that comprehensively assess a broad range of capabilities. Such benchmarks are associated with massive computational costs reaching thousands of GPU hours per model. However the efficiency aspect of these evaluation efforts had raised little discussion in the literature. In this work we present the problem of Efficient Benchmarking namely intelligently reducing the computation costs of LM evaluation without compromising reliability. Using the HELM benchmark as a test case we investigate how different benchmark design choices affect the computation-reliability tradeoff. We propose to evaluate the reliability of such decisions by using a new measure Decision Impact on Reliability DIoR for short. We find for example that the current leader on HELM may change by merely removing a low-ranked model from the benchmark and observe that a handful of examples suffice to obtain the correct benchmark rank
    
[^56]: 基于时间分布的视频行为识别背门攻击

    Temporal-Distributed Backdoor Attack Against Video Based Action Recognition. (arXiv:2308.11070v1 [cs.CV])

    [http://arxiv.org/abs/2308.11070](http://arxiv.org/abs/2308.11070)

    本文介绍了一种针对视频数据的简单而有效的背门攻击方法，通过在转换领域中添加难以察觉的、时间上分布的触发器来实现误分类。

    

    深度神经网络在包括视频行为识别在内的各种应用中取得了巨大成功，但仍然容易受到背门攻击（特洛伊）。当测试实例（来自非目标类）嵌入特定触发器时，被背门破坏的模型会误分类为攻击者选择的目标类，同时在无攻击实例上保持高准确率。尽管对于图像数据的背门攻击已经进行了广泛研究，但视频系统在背门攻击下的易受攻击性仍然很少被探索。当前的研究是对图像数据的方法的直接延伸，例如，触发器是\textbf{独立}嵌入帧中的，容易被现有防御机制检测到。在本文中，我们介绍了一种\textit{简单}但\textit{有效}的视频数据背门攻击。我们提出的攻击在一个转换的领域中添加扰动，以嵌入\textbf{难以察觉的，时间上分布的}触发器。

    Deep neural networks (DNNs) have achieved tremendous success in various applications including video action recognition, yet remain vulnerable to backdoor attacks (Trojans). The backdoor-compromised model will mis-classify to the target class chosen by the attacker when a test instance (from a non-target class) is embedded with a specific trigger, while maintaining high accuracy on attack-free instances. Although there are extensive studies on backdoor attacks against image data, the susceptibility of video-based systems under backdoor attacks remains largely unexplored. Current studies are direct extensions of approaches proposed for image data, e.g., the triggers are \textbf{independently} embedded within the frames, which tend to be detectable by existing defenses. In this paper, we introduce a \textit{simple} yet \textit{effective} backdoor attack against video data. Our proposed attack, adding perturbations in a transformed domain, plants an \textbf{imperceptible, temporally distr
    
[^57]: CSM-H-R: 一种用于可互操作智能系统和隐私保护的自动上下文推理框架

    CSM-H-R: An Automatic Context Reasoning Framework for Interoperable Intelligent Systems and Privacy Protection. (arXiv:2308.11066v1 [cs.AI])

    [http://arxiv.org/abs/2308.11066](http://arxiv.org/abs/2308.11066)

    CSM-H-R是一个自动上下文推理框架，用于可互操作的智能系统和隐私保护。该框架结合了本体和状态，在运行时识别有意义的高级上下文，并可应用于不同的推理技术。在智能校园环境中进行了智能电梯系统的案例研究，并展示了使用先进的数学和概率模型的潜力。

    

    在物联网时代，智能系统对高级上下文(HLC)推理的自动化变得至关重要，这是因为上下文数据的不断积累、多源数据融合的趋势以及基于上下文决策过程的固有复杂性和动态性。为了解决这个问题，我们提出了一种自动上下文推理框架CSM-H-R，该框架在运行时以编程方式组合本体和状态，并结合模型存储阶段，以实现识别有意义的HLC的能力，所得到的数据表示可应用于不同的推理技术。在智能校园环境中基于智能电梯系统开展了案例研究。框架的实现-CSM引擎以及将HLC推理转化为矢量和矩阵计算的实验，特别关注上下文的动态特性，并展示了使用先进的数学和概率模型的潜力。

    Automation of High-Level Context (HLC) reasoning for intelligent systems at scale is imperative due to the unceasing accumulation of contextual data in the IoT era, the trend of the fusion of data from multi-sources, and the intrinsic complexity and dynamism of the context-based decision-making process. To mitigate this issue, we propose an automatic context reasoning framework CSM-H-R, which programmatically combines ontologies and states at runtime and the model-storage phase for attaining the ability to recognize meaningful HLC, and the resulting data representation can be applied to different reasoning techniques. Case studies are developed based on an intelligent elevator system in a smart campus setting. An implementation of the framework - a CSM Engine, and the experiments of translating the HLC reasoning into vector and matrix computing especially take care of the dynamic aspects of context and present the potentiality of using advanced mathematical and probabilistic models to 
    
[^58]: 人工智能在事实核查中无效且具有潜在危害性

    Artificial intelligence is ineffective and potentially harmful for fact checking. (arXiv:2308.10800v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2308.10800](http://arxiv.org/abs/2308.10800)

    这项研究发现人工智能语言模型在事实核查中表现出色，但在帮助用户判断标题准确性和分享准确新闻方面影响不大。然而，在某些情况下，它会误导用户对真实标题的信仰，并增加对未确定虚假标题的信仰。

    

    事实核查是对抗错误信息的有效策略，但是它在规模上的实施受到了网络上信息过于庞大的阻碍。近期的人工智能语言模型在事实核查任务中展现出了令人印象深刻的能力，但人们在使用这些模型提供的事实核查信息时的作用机制并不清楚。在这里，我们通过一项预先登记的随机对照实验，研究了一款热门人工智能模型生成的事实核查对政治新闻信仰和分享意图的影响。尽管该人工智能在揭穿虚假标题方面表现得相当不错，但我们发现它并没有对参与者识别标题准确性或分享准确新闻的能力产生显著影响。然而，在特定情况下，该人工智能事实核查器具有危害性：将一些真实标题误标为虚假会降低对其的信仰，而对其未确定的虚假标题则会增加对其的信仰。在积极方面，该人工智能提高了正确标定标题的分享意愿。

    Fact checking can be an effective strategy against misinformation, but its implementation at scale is impeded by the overwhelming volume of information online. Recent artificial intelligence (AI) language models have shown impressive ability in fact-checking tasks, but how humans interact with fact-checking information provided by these models is unclear. Here we investigate the impact of fact checks generated by a popular AI model on belief in, and sharing intent of, political news in a preregistered randomized control experiment. Although the AI performs reasonably well in debunking false headlines, we find that it does not significantly affect participants' ability to discern headline accuracy or share accurate news. However, the AI fact-checker is harmful in specific cases: it decreases beliefs in true headlines that it mislabels as false and increases beliefs for false headlines that it is unsure about. On the positive side, the AI increases sharing intents for correctly labeled t
    
[^59]: 第二届自适应网络防御国际研讨会论文集

    Proceedings of the 2nd International Workshop on Adaptive Cyber Defense. (arXiv:2308.09520v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2308.09520](http://arxiv.org/abs/2308.09520)

    第二届自适应网络防御国际研讨会的目标是探索利用人工智能和机器学习作为自适应网络防御基础能力的研究，并通过填补AI和网络研究人员之间的差距来加速开发半自主网络防御系统。

    

    第二届自适应网络防御国际研讨会在佛罗里达理工学院举行，该研讨会旨在分享利用人工智能（AI）和机器学习（ML）作为自适应网络防御基础能力的研究。当前的网络领域无法可靠有效地进行防御，必须广泛依赖人工专家。熟练的网络防御人员供应不足，往往无法及时应对网络威胁。借鉴AI和ML的最新进展，网络防御研究社区被激励着通过将AI和ML技术应用于网络环境中，开发新的动态可持续的防御措施。填补AI和网络研究人员与实践者之间的关键差距可以加速创建能够学习识别和应对网络攻击，或者发现和减轻弱点的半自主网络防御系统的努力。

    The 2nd International Workshop on Adaptive Cyber Defense was held at the Florida Institute of Technology, Florida. This workshop was organized to share research that explores unique applications of Artificial Intelligence (AI) and Machine Learning (ML) as foundational capabilities for the pursuit of adaptive cyber defense. The cyber domain cannot currently be reliably and effectively defended without extensive reliance on human experts. Skilled cyber defenders are in short supply and often cannot respond fast enough to cyber threats.  Building on recent advances in AI and ML the Cyber defense research community has been motivated to develop new dynamic and sustainable defenses through the adoption of AI and ML techniques to cyber settings. Bridging critical gaps between AI and Cyber researchers and practitioners can accelerate efforts to create semi-autonomous cyber defenses that can learn to recognize and respond to cyber attacks or discover and mitigate weaknesses in cooperation with
    
[^60]: 图结构残差：一种诊断的学习方法

    Graph Structural Residuals: A Learning Approach to Diagnosis. (arXiv:2308.06961v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.06961](http://arxiv.org/abs/2308.06961)

    本文提出了一种新颖的框架，将模型诊断的概念与深度图结构学习相结合，通过数据学习系统的底层结构并提供动态观察。研究通过重新定义系统表示、观察和故障的构建，引入自监督图结构学习模型以及在耦合振荡器系统上的实验，展示了数据驱动的诊断方法的潜力。

    

    传统的基于模型的诊断依赖于构建明确的系统模型，这个过程可能费时且需要专业知识。本文提出了一种新颖的框架，将模型诊断的概念与深度图结构学习相结合。这种数据驱动的方法利用数据学习系统的底层结构，并提供由两个不同的图邻接矩阵表示的动态观察。我们的工作通过三个主要贡献实现了图结构学习与模型诊断的无缝集成：(i)重新定义系统表示、观察和故障的构建、(ii)引入两种不同版本的自监督图结构学习模型架构、(iii)通过耦合振荡器系统的实验展示了我们数据驱动的诊断方法的潜力。

    Traditional model-based diagnosis relies on constructing explicit system models, a process that can be laborious and expertise-demanding. In this paper, we propose a novel framework that combines concepts of model-based diagnosis with deep graph structure learning. This data-driven approach leverages data to learn the system's underlying structure and provide dynamic observations, represented by two distinct graph adjacency matrices. Our work facilitates a seamless integration of graph structure learning with model-based diagnosis by making three main contributions: (i) redefining the constructs of system representation, observations, and faults (ii) introducing two distinct versions of a self-supervised graph structure learning model architecture and (iii) demonstrating the potential of our data-driven diagnostic method through experiments on a system of coupled oscillators.
    
[^61]: 自动化工厂监控的智能机器人系统

    A Smart Robotic System for Industrial Plant Supervision. (arXiv:2308.05612v1 [cs.RO])

    [http://arxiv.org/abs/2308.05612](http://arxiv.org/abs/2308.05612)

    我们提出了一个智能机器人系统，可以自动检查化工生产厂的完整性并提供关键操作条件的有用信息。

    

    在现代化工生产厂中，人工操作员经常对工厂的完整性进行检查，以确保高安全标准，因此可能是第一个遇到危险操作条件的人。为了减轻他们在故障检测和监控方面的任务，我们提出了一个机器人系统，该系统由一个自主导航机器人和各种传感器和数据处理器组成。我们的目标是模拟人类的视觉、嗅觉和听觉感知和解释能力，以进行自动化检查。我们在一个废水处理设施中对我们的系统进行了广泛的评估，结果表明该系统能够稳定地导航工厂并提供有关关键操作条件的有用信息。

    In today's chemical production plants, human field operators perform frequent checks on the plant's integrity to guarantee high safety standards, and thus are possibly the first to encounter dangerous operating conditions. To alleviate their tasks of failure detection and monitoring by audio, visual, and olfactory perceptions, we present a robotic system that consists of an autonomously navigating robot integrated with various sensors and data processing. We aim to resemble the human sensing and interpretation capabilities of sight, smell, and hearing, for providing automated inspection. We evaluate our system extensively at a wastewater facility in full working conditions. Our results demonstrate that the system is able to robustly navigate a plant and to provide useful information about critical operating conditions.
    
[^62]: 用条件扩散模型和语言模型进行最小监督语音合成：基于语义编码的比较研究

    Minimally-Supervised Speech Synthesis with Conditional Diffusion Model and Language Model: A Comparative Study of Semantic Coding. (arXiv:2307.15484v1 [cs.SD])

    [http://arxiv.org/abs/2307.15484](http://arxiv.org/abs/2307.15484)

    本文提出了两种语音合成方法来解决自回归和非自回归模型中的问题，并在语义编码方面进行了比较研究。

    

    近年来，对于能够采用最小监督训练方法的文本到语音(TTS)技术越来越受关注，该方法通过结合两种离散语音表示并使用两种序列到序列任务来解耦TTS。为了解决离散表示中的高维度和波形失真的挑战，我们提出了Diff-LM-Speech方法，该方法基于扩散模型将语义嵌入模型为基于mel频谱图，并引入基于变分自动编码器和韵律瓶颈的提示编码结构，以提高提示表示能力。自回归语言模型常常遇到缺失和重复单词的问题，而非自回归框架由于预测模型的存在导致表达平均问题。为了解决这些问题，我们提出了Tetra-Diff-Speech，该方法设计了一个时长扩散模型以实现多样化的韵律表达。我们期望语义编码的信息内容介于...

    Recently, there has been a growing interest in text-to-speech (TTS) methods that can be trained with minimal supervision by combining two types of discrete speech representations and using two sequence-to-sequence tasks to decouple TTS. To address the challenges associated with high dimensionality and waveform distortion in discrete representations, we propose Diff-LM-Speech, which models semantic embeddings into mel-spectrogram based on diffusion models and introduces a prompt encoder structure based on variational autoencoders and prosody bottlenecks to improve prompt representation capabilities. Autoregressive language models often suffer from missing and repeated words, while non-autoregressive frameworks face expression averaging problems due to duration prediction models. To address these issues, we propose Tetra-Diff-Speech, which designs a duration diffusion model to achieve diverse prosodic expressions. While we expect the information content of semantic coding to be between t
    
[^63]: 用基于人工智能的大型语言模型扩展全球心理健康心理服务的Psy-LLM

    Psy-LLM: Scaling up Global Mental Health Psychological Services with AI-based Large Language Models. (arXiv:2307.11991v1 [cs.CL])

    [http://arxiv.org/abs/2307.11991](http://arxiv.org/abs/2307.11991)

    Psy-LLM是一个基于人工智能的系统，利用大型语言模型（LLMs）为在线心理咨询提供问答服务，前端工具可让医疗专业人员提供即时响应和正念活动，同时还可作为筛查工具辅助识别紧急案例。

    

    近年来，心理咨询的需求显著增长，特别是随着全球COVID-19的爆发，这加强了及时和专业的心理健康支持的需求。在线心理咨询成为应对这一需求的主要服务方式。在本研究中，我们提出了Psy-LLM框架，这是一种基于人工智能的系统，利用大型语言模型（LLMs）进行在线心理咨询中的问答。我们的框架结合了经过预训练的LLMs和从心理学家和广泛收集的心理文章中获取的真实世界专业问答。Psy-LLM框架作为医疗专业人员的前端工具，允许他们提供即时响应和正念活动来缓解患者压力，同时还可以作为筛查工具，识别需要进一步协助的紧急案例。我们使用困惑度等内在度量标准和外部度量标准对框架进行了评估。

    The demand for psychological counseling has grown significantly in recent years, particularly with the global outbreak of COVID-19, which has heightened the need for timely and professional mental health support. Online psychological counseling has emerged as the predominant mode of providing services in response to this demand. In this study, we propose the Psy-LLM framework, an AI-based system leveraging Large Language Models (LLMs) for question-answering in online psychological consultation. Our framework combines pre-trained LLMs with real-world professional Q&A from psychologists and extensively crawled psychological articles. The Psy-LLM framework serves as a front-end tool for healthcare professionals, allowing them to provide immediate responses and mindfulness activities to alleviate patient stress. Additionally, it functions as a screening tool to identify urgent cases requiring further assistance. We evaluated the framework using intrinsic metrics, such as perplexity, and ex
    
[^64]: AspectCSE: 使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入

    AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity using Contrastive Learning and Structured Knowledge. (arXiv:2307.07851v1 [cs.CL])

    [http://arxiv.org/abs/2307.07851](http://arxiv.org/abs/2307.07851)

    AspectCSE是一种使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入方法，它在信息检索任务中相比之前的最好结果平均提高了3.97%，通过同时考虑多个特定方面的嵌入模型优于单方面嵌入。

    

    通用的句子嵌入提供了对语义文本相似性的粗略近似，但忽略了使文本相似的特定方面。相反，基于方面的句子嵌入提供了基于预定义方面的文本相似性。因此，文本的相似性预测更加针对特定要求，并且更容易解释。在本文中，我们提出了AspectCSE，一种用于基于方面的对比学习句子嵌入的方法。结果表明，与之前最好的结果相比，AspectCSE在多个方面的信息检索任务中实现了平均改善3.97%。我们还提出使用Wikidata知识图属性来训练多方面句子嵌入模型，其中在相似性预测过程中同时考虑多个特定方面。我们证明了多方面嵌入在特定方面信息检索任务上优于单方面嵌入。最后，我们展示了嵌入模型的可解释性，并提出通过对比学习来改进嵌入质量。

    Generic sentence embeddings provide a coarse-grained approximation of semantic textual similarity but ignore specific aspects that make texts similar. Conversely, aspect-based sentence embeddings provide similarities between texts based on certain predefined aspects. Thus, similarity predictions of texts are more targeted to specific requirements and more easily explainable. In this paper, we present AspectCSE, an approach for aspect-based contrastive learning of sentence embeddings. Results indicate that AspectCSE achieves an average improvement of 3.97% on information retrieval tasks across multiple aspects compared to the previous best results. We also propose using Wikidata knowledge graph properties to train models of multi-aspect sentence embeddings in which multiple specific aspects are simultaneously considered during similarity predictions. We demonstrate that multi-aspect embeddings outperform single-aspect embeddings on aspect-specific information retrieval tasks. Finally, w
    
[^65]: 在课堂上学习提示以了解人工智能的限制：一项试点研究

    Learning to Prompt in the Classroom to Understand AI Limits: A pilot study. (arXiv:2307.01540v1 [cs.HC])

    [http://arxiv.org/abs/2307.01540](http://arxiv.org/abs/2307.01540)

    在本研究中，通过学习提示，试图在课堂环境中理解人工智能的限制。人工智能的进展带来了巨大的潜力，但也引发了负面情绪。当前大型语言模型的能力限制被忽视，导致了错误的自信和不准确的建议。承认人工智能的不可靠性是解决这个问题的关键。

    

    人工智能的进展在帮助社会解决紧迫的社会问题方面具有巨大的潜力。特别是大型语言模型（LLM）和派生的聊天机器人，如ChatGPT，大大改进了AI系统的自然语言处理能力，使其能够处理前所未有的大量非结构化数据。由此产生的炒作也产生了负面情绪，即使在新颖的AI方法取得令人惊讶的贡献之后。造成这种情况的原因之一，但也是一个重要的问题本身，是越来越多人错误地认为自己能够轻松访问和处理任何形式的知识，以解决任何领域的问题，无需对AI或问题领域有任何专业知识，而忽视了当前LLMs的限制，例如幻觉和推理限制。承认人工智能的不可靠性对于解决由LLMs生成的可能错误建议可能产生的盲目过度自信的影响至关重要。同时，这可以减少恐惧和其他负面态度。

    Artificial intelligence's progress holds great promise in assisting society in addressing pressing societal issues. In particular Large Language Models (LLM) and the derived chatbots, like ChatGPT, have highly improved the natural language processing capabilities of AI systems allowing them to process an unprecedented amount of unstructured data. The consequent hype has also backfired, raising negative sentiment even after novel AI methods' surprising contributions. One of the causes, but also an important issue per se, is the rising and misleading feeling of being able to access and process any form of knowledge to solve problems in any domain with no effort or previous expertise in AI or problem domain, disregarding current LLMs limits, such as hallucinations and reasoning limits. Acknowledging AI fallibility is crucial to address the impact of dogmatic overconfidence in possibly erroneous suggestions generated by LLMs. At the same time, it can reduce fear and other negative attitude
    
[^66]: RS5M：用于遥感视觉-语言基础模型的大规模视觉-语言数据集

    RS5M: A Large Scale Vision-Language Dataset for Remote Sensing Vision-Language Foundation Model. (arXiv:2306.11300v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.11300](http://arxiv.org/abs/2306.11300)

    本文提出了一个新的框架RS5M，该框架包括领域基础模型（DFM），用于实现通用基础模型（GFM）和领域特定下游任务之间的转换。另外，还介绍了一个遥感领域的大规模图像-文本配对数据集RS5M，该数据集是通过过滤公开可用的图像-文本配对数据集并使用预训练的视觉-语言基础模型为标签数据集生成标题。

    

    利用大量图像-文本配对数据进行预训练的视觉-语言基础模型展示了前所未有的图像-文本关联能力，在各种下游任务中取得了显著的成果。关键挑战是如何利用已有的大规模预训练的视觉-语言基础模型，在域相关的下游任务中进行领域特定的迁移。本文提出了一个新的框架，包括领域基础模型（DFM），弥合了通用基础模型（GFM）和领域特定下游任务之间的差距。此外，我们还介绍了一个遥感领域（RS）的图像-文本配对数据集RS5M，其中包含了500万张带有英文描述的RS图像。该数据集是通过过滤公开可用的图像-文本配对数据集，并使用预训练的视觉-语言基础模型为仅带标签的RS数据集生成标题。这是第一个大规模的RS图像-文本配对数据集。

    Pre-trained Vision-Language Foundation Models utilizing extensive image-text paired data have demonstrated unprecedented image-text association capabilities, achieving remarkable results across various downstream tasks. A critical challenge is how to make use of existing large-scale pre-trained VLMs, which are trained on common objects, to perform the domain-specific transfer for accomplishing domain-related downstream tasks. In this paper, we propose a new framework that includes the Domain Foundation Model (DFM), bridging the gap between the General Foundation Model (GFM) and domain-specific downstream tasks. Moreover, we present an image-text paired dataset in the field of remote sensing (RS), RS5M, which has 5 million RS images with English descriptions. The dataset is obtained from filtering publicly available image-text paired datasets and captioning label-only RS datasets with pre-trained VLM. These constitute the first large-scale RS image-text paired dataset. Additionally, we 
    
[^67]: 基于偏好的强化学习中的公平性

    Fairness in Preference-based Reinforcement Learning. (arXiv:2306.09995v1 [cs.LG])

    [http://arxiv.org/abs/2306.09995](http://arxiv.org/abs/2306.09995)

    该论文提出了一种名为FPbRL的新的公平偏好强化学习方法，旨在通过广义Gini福利函数最大化策略学习来实现多目标优化并处理每个目标的公平性。

    

    本文研究了在多目标情况下偏好强化学习(PbRL)中的公平性问题。主要目标是设计控制策略，既能够优化多个目标，又能够公平地处理每个目标。为实现这一目标，我们设计了一种新的公平偏好强化学习(FPbRL)方法。FPbRL的主要思想是通过新的福利偏好而不是PbRL中的基于奖励的偏好来学习与多目标关联的向量奖励函数，并通过最大化广义Gini福利函数进行策略学习。最后，在三个不同的环境上进行实验研究，展示了所提出的FPbRL方法能够实现有效和公平的控制策略的学习。

    In this paper, we address the issue of fairness in preference-based reinforcement learning (PbRL) in the presence of multiple objectives. The main objective is to design control policies that can optimize multiple objectives while treating each objective fairly. Toward this objective, we design a new fairness-induced preference-based reinforcement learning or FPbRL. The main idea of FPbRL is to learn vector reward functions associated with multiple objectives via new welfare-based preferences rather than reward-based preference in PbRL, coupled with policy learning via maximizing a generalized Gini welfare function. Finally, we provide experiment studies on three different environments to show that the proposed FPbRL approach can achieve both efficiency and equity for learning effective and fair policies.
    
[^68]: 非参数模型揭示收入动态演化：基于PSID数据的隐马尔科夫模型研究 (arXiv:2306.01760v1 [stat.AP])

    Nonparametric Identification and Estimation of Earnings Dynamics using a Hidden Markov Model: Evidence from the PSID. (arXiv:2306.01760v1 [stat.AP])

    [http://arxiv.org/abs/2306.01760](http://arxiv.org/abs/2306.01760)

    本研究使用隐马尔科夫模型揭示了收入持续性的复杂本质，并证实了收入具有非线性持续性、条件偏斜性和条件峰度等特征，并发现了ARCH效应以及非高斯瞬时性成分所产生的明显分布不对称性影响。

    

    本文提出了一种隐马尔科夫模型，以揭示收入持续性的复杂本质。所提出的模型假定对数收入残差包括持久性和瞬时性两个部分，均遵循马尔科夫过程。通过对线性算子进行谱分解实现非参数识别，并引入改进的随机EM算法进行模型估计。将该框架应用于收入动态研究（PSID）数据集中，我们发现收入过程呈现非线性持续性、条件偏斜性和条件峰度。此外，瞬时性成分具有非高斯性质，在高收入家庭面临负冲击或低收入家庭遭遇正冲击时会产生明显的不对称分布影响。我们的实证研究还发现，在2至8年的时间范围内，收入具有ARCH效应。

    This paper presents a hidden Markov model designed to investigate the complex nature of earnings persistence. The proposed model assumes that the residuals of log-earnings consist of a persistent component and a transitory component, both following general Markov processes. Nonparametric identification is achieved through spectral decomposition of linear operators, and a modified stochastic EM algorithm is introduced for model estimation. Applying the framework to the Panel Study of Income Dynamics (PSID) dataset, we find that the earnings process displays nonlinear persistence, conditional skewness, and conditional kurtosis. Additionally, the transitory component is found to possess non-Gaussian properties, resulting in a significantly asymmetric distributional impact when high-earning households face negative shocks or low-earning households encounter positive shocks. Our empirical findings also reveal the presence of ARCH effects in earnings at horizons ranging from 2 to 8 years, fu
    
[^69]: 移动机器人全身操作的因果策略梯度

    Causal Policy Gradient for Whole-Body Mobile Manipulation. (arXiv:2305.04866v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2305.04866](http://arxiv.org/abs/2305.04866)

    本文提出了一种新框架——因果MoMa，可以训练适用于典型MoMa任务的策略，在此框架下，机动和交互自由度可以同时组合，并且不需要人类领域知识来划分动作空间或将动作部分与子目标匹配。

    

    开发下一代家庭机器人助手需要结合机动和交互能力，即通常所说的移动操作。由于机器人的大动作空间和任务常见的多目标性质，例如能够有效地达到目标且避免障碍，移动操作任务很难。目前的方法通常根据人工匹配动作空间的部分到移动操作子目标（例如用于移动目标的基础动作和用于操作的手臂动作）将任务分为不带操作的导航和不带机动的固定操作。此解决方案防止了机动和交互自由度的同时组合，并且需要人类领域知识来划分动作空间并将动作部分与子目标匹配。在本文中，我们介绍了一种新的框架——因果MoMa，该框架用于训练典型MoMa任务的策略。

    Developing the next generation of household robot helpers requires combining locomotion and interaction capabilities, which is generally referred to as mobile manipulation (MoMa). MoMa tasks are difficult due to the large action space of the robot and the common multi-objective nature of the task, e.g., efficiently reaching a goal while avoiding obstacles. Current approaches often segregate tasks into navigation without manipulation and stationary manipulation without locomotion by manually matching parts of the action space to MoMa sub-objectives (e.g. base actions for locomotion objectives and arm actions for manipulation). This solution prevents simultaneous combinations of locomotion and interaction degrees of freedom and requires human domain knowledge for both partitioning the action space and matching the action parts to the sub-objectives. In this paper, we introduce Causal MoMa, a new framework to train policies for typical MoMa tasks that makes use of the most favorable subsp
    
[^70]: 跨域文本到SQL自适应提示的基于案例推理框架

    A Case-Based Reasoning Framework for Adaptive Prompting in Cross-Domain Text-to-SQL. (arXiv:2304.13301v1 [cs.CL])

    [http://arxiv.org/abs/2304.13301](http://arxiv.org/abs/2304.13301)

    本文提出了一个基于案例推理框架的跨域文本到SQL自适应提示的解决方案，可以精确控制与案例相关和不相关的知识，解决了大型语言模型提示设计不良限制性能的问题。

    

    最近流行的大型语言模型（例如Codex、ChatGPT和GPT-4）在AI社区方面有了显著的进展，包括文本到SQL的任务。一些关于大型语言模型的评估和分析表明，它们有潜力生成SQL查询，但是它们所使用的提示设计不良（例如简单的结构或随机抽样）限制了大型语言模型的性能，并可能导致不必要或无关的输出。为了解决这些问题，我们提出了CBR-ApSQL，这是一个基于案例推理（CBR）的框架，与GPT-3.5相结合，用于在文本到SQL任务中对与案例相关和不相关的知识进行精确控制。我们设计了自适应提示，以灵活调整GPT-3.5的输入，其中涉及（1）通过去语义化输入问题来自适应检索案例，根据问题意图，以及（2）自适应回退机制，以确保提示的信息量和案例与提示之间的相关性。在去语义化阶段中，我们设计了Semantic D

    Recent advancements in Large Language Models (LLMs), such as Codex, ChatGPT and GPT-4 have significantly impacted the AI community, including Text-to-SQL tasks. Some evaluations and analyses on LLMs show their potential to generate SQL queries but they point out poorly designed prompts (e.g. simplistic construction or random sampling) limit LLMs' performance and may cause unnecessary or irrelevant outputs. To address these issues, we propose CBR-ApSQL, a Case-Based Reasoning (CBR)-based framework combined with GPT-3.5 for precise control over case-relevant and case-irrelevant knowledge in Text-to-SQL tasks. We design adaptive prompts for flexibly adjusting inputs for GPT-3.5, which involves (1) adaptively retrieving cases according to the question intention by de-semantizing the input question, and (2) an adaptive fallback mechanism to ensure the informativeness of the prompt, as well as the relevance between cases and the prompt. In the de-semanticization phase, we designed Semantic D
    
[^71]: 多粒度时间变换器用于知识追踪

    Multi-granulariy Time-based Transformer for Knowledge Tracing. (arXiv:2304.05257v1 [cs.LG])

    [http://arxiv.org/abs/2304.05257](http://arxiv.org/abs/2304.05257)

    本文提出了一种基于Transformer的架构用于准确地预测学生在标准化测试中的表现。该模型考虑了学生的历史数据，包括他们以往的考试成绩、学习习惯和其他相关信息，并在解码器输入中使用了多个时间特征粒度以显著提高模型性能。与LightGBM相比，该方法更加准确，为教育领域的AI发展提供了一个可伸缩和准确的预测学生成果的工具。

    

    本文提出了一种基于Transformer的架构，用于预测标准化测试中学生的表现。具体来说，我们利用学生的历史数据，包括他们以往的考试成绩、学习习惯和其他相关信息，为每个学生创建一个个性化的模型。然后，我们使用这些模型来预测学生在给定测试中的未来表现。将该模型应用于RIIID数据集，我们证明使用多个时间特征粒度作为解码器输入可以显着提高模型性能。我们的结果还表明了我们方法的有效性，相对于LightGBM方法有很大的改进。我们的工作为教育领域的AI发展做出了贡献，提供了一个可伸缩和准确的预测学生成果的工具。

    In this paper, we present a transformer architecture for predicting student performance on standardized tests. Specifically, we leverage students historical data, including their past test scores, study habits, and other relevant information, to create a personalized model for each student. We then use these models to predict their future performance on a given test. Applying this model to the RIIID dataset, we demonstrate that using multiple granularities for temporal features as the decoder input significantly improve model performance. Our results also show the effectiveness of our approach, with substantial improvements over the LightGBM method. Our work contributes to the growing field of AI in education, providing a scalable and accurate tool for predicting student outcomes.
    
[^72]: 可解释的异常值汇总

    Interpretable Outlier Summarization. (arXiv:2303.06261v1 [cs.LG])

    [http://arxiv.org/abs/2303.06261](http://arxiv.org/abs/2303.06261)

    STAIR提出了一种可解释的异常值汇总方法，通过学习一组紧凑的人类可理解规则，以汇总和解释异常检测结果，具有强大的可解释性，以准确地总结检测结果。

    STAIR proposes an interpretable outlier summarization method by learning a compact set of human understandable rules to summarize and explain the anomaly detection results, which has strong interpretability to accurately summarize the detection results.

    异常值检测在实际应用中是至关重要的，以防止金融欺诈、防御网络入侵或检测即将发生的设备故障。为了减少人力评估异常值检测结果的工作量，并有效地将异常值转化为可操作的见解，用户通常希望系统自动产生可解释的异常值检测结果的子组的汇总。然而，到目前为止，没有这样的系统存在。为了填补这一空白，我们提出了STAIR，它学习了一组紧凑的人类可理解规则，以汇总和解释异常检测结果。STAIR不使用经典的决策树算法来产生这些规则，而是提出了一个新的优化目标，以产生少量规则，具有最小的复杂性，因此具有强大的可解释性，以准确地总结检测结果。STAIR的学习算法通过迭代分割大规则来产生规则集，并在每个i中最大化这个目标，是最优的。

    Outlier detection is critical in real applications to prevent financial fraud, defend network intrusions, or detecting imminent device failures. To reduce the human effort in evaluating outlier detection results and effectively turn the outliers into actionable insights, the users often expect a system to automatically produce interpretable summarizations of subgroups of outlier detection results. Unfortunately, to date no such systems exist. To fill this gap, we propose STAIR which learns a compact set of human understandable rules to summarize and explain the anomaly detection results. Rather than use the classical decision tree algorithms to produce these rules, STAIR proposes a new optimization objective to produce a small number of rules with least complexity, hence strong interpretability, to accurately summarize the detection results. The learning algorithm of STAIR produces a rule set by iteratively splitting the large rules and is optimal in maximizing this objective in each i
    
[^73]: 以ELBOs的加权积分理解扩散目标

    Understanding the Diffusion Objective as a Weighted Integral of ELBOs. (arXiv:2303.00848v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00848](http://arxiv.org/abs/2303.00848)

    本文深入理解了扩散目标，并揭示了加权损失和ELBO目标之间的直接关系。

    

    文献中的扩散模型采用不同的目标进行优化，并且这些目标都是加权损失的特例，其中加权函数指定每个噪声级别的权重。均匀加权对应于最大似然的原则性近似ELBO的最大化。但是实际上，由于更好的样本质量，目前的扩散模型使用非均匀加权。本文揭示了加权损失（带有任何加权）和ELBO目标之间的直接关系。我们展示了加权损失可以被写成一种ELBOs的加权积分形式，其中每个噪声级别都有一个ELBO。如果权重函数是单调的，那么加权损失是一种基于似然的目标：它在简单的数据增强下（即高斯噪声扰动）下最大化ELBO。我们的主要贡献是更深入地理解了扩散目标，但我们还进行了一些比较单调和非单调权重的实验。

    Diffusion models in the literature are optimized with various objectives that are special cases of a weighted loss, where the weighting function specifies the weight per noise level. Uniform weighting corresponds to maximizing the ELBO, a principled approximation of maximum likelihood. In current practice diffusion models are optimized with non-uniform weighting due to better results in terms of sample quality. In this work we expose a direct relationship between the weighted loss (with any weighting) and the ELBO objective.  We show that the weighted loss can be written as a weighted integral of ELBOs, with one ELBO per noise level. If the weighting function is monotonic, then the weighted loss is a likelihood-based objective: it maximizes the ELBO under simple data augmentation, namely Gaussian noise perturbation. Our main contribution is a deeper theoretical understanding of the diffusion objective, but we also performed some experiments comparing monotonic with non-monotonic weight
    
[^74]: 通过自我蒸馏改进可微分架构搜索方法

    Improving Differentiable Architecture Search via Self-Distillation. (arXiv:2302.05629v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.05629](http://arxiv.org/abs/2302.05629)

    本文提出了自我蒸馏可微分神经架构搜索（SD-DARTS）方法，通过从超网的先前步骤中蒸馏知识来指导其训练，有效降低了超网损失的尖锐度，从而缓解了离散化差距。

    

    可微分架构搜索（DARTS）是一种简单且高效的神经架构搜索（NAS）方法。DARTS在搜索阶段通过联合优化架构参数和网络参数来训练超网。在评估阶段，DARTS将超网离散化，从而得到基于架构参数的最优架构。然而，最近的研究表明，在训练过程中，超网往往会收敛到尖锐的极小值点而不是平坦的极小值点。这体现在超网损失曲面的尖锐程度较高，最终导致超网与最优架构之间存在性能差距。本文提出了自我蒸馏可微分神经架构搜索（SD-DARTS）来缓解离散化差距。我们利用自我蒸馏从超网的先前步骤中蒸馏知识，引导其在当前步骤中的训练，有效降低了超网损失的尖锐度。

    Differentiable Architecture Search (DARTS) is a simple yet efficient Neural Architecture Search (NAS) method. During the search stage, DARTS trains a supernet by jointly optimizing architecture parameters and network parameters. During the evaluation stage, DARTS discretizes the supernet to derive the optimal architecture based on architecture parameters. However, recent research has shown that during the training process, the supernet tends to converge towards sharp minima rather than flat minima. This is evidenced by the higher sharpness of the loss landscape of the supernet, which ultimately leads to a performance gap between the supernet and the optimal architecture. In this paper, we propose Self-Distillation Differentiable Neural Architecture Search (SD-DARTS) to alleviate the discretization gap. We utilize self-distillation to distill knowledge from previous steps of the supernet to guide its training in the current step, effectively reducing the sharpness of the supernet's loss
    
[^75]: 领域无关的分子生成与自我反馈

    Domain-Agnostic Molecular Generation with Self-feedback. (arXiv:2301.11259v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11259](http://arxiv.org/abs/2301.11259)

    MolGen是一个专注于分子生成的预训练语言模型，使用了领域无关的分子前缀调整和自我反馈的范式，实现了化学有效性、多样性、新颖性和复杂性的突破，在分子生成领域表现出了出色的性能。

    

    分子的生成已经受到极大的关注，其革新了科学家设计分子结构的方式，并为化学和药物设计提供了宝贵的支持。然而，尽管在分子生成中使用语言模型具有潜力，但它们面临着许多挑战，比如生成语法或化学存在缺陷的分子，狭窄的领域专注以及由于缺乏注释数据或外部分子数据库而限制了生成多样性和可行性。因此，我们引入了MolGen，它是一个专门用于分子生成的预训练分子语言模型。MolGen通过重构一亿多个分子SELFIES获得了固有的结构和语法概念，并通过领域无关的分子前缀调整促进了不同领域之间的知识传递。此外，我们提出了一种自我反馈范式，启发预训练模型与最终下游目标对齐，有助于更稳健和高效的分子生成。我们在基准数据集上的实验表明，MolGen在化学有效性，多样性，新颖性和复杂性方面优于现有技术。

    The generation of molecules with desired properties has gained tremendous popularity, revolutionizing the way scientists design molecular structures and providing valuable support for chemical and drug design. However, despite the potential of language models in molecule generation, they face numerous challenges such as the generation of syntactically or chemically flawed molecules, narrow domain focus, and limitations in creating diverse and directionally feasible molecules due to a dearth of annotated data or external molecular databases. To this end, we introduce MolGen, a pre-trained molecular language model tailored specifically for molecule generation. MolGen acquires intrinsic structural and grammatical insights by reconstructing over 100 million molecular SELFIES, while facilitating knowledge transfer between different domains through domain-agnostic molecular prefix tuning. Moreover, we present a self-feedback paradigm that inspires the pre-trained model to align with the ulti
    
[^76]: 通过元学习在哈密顿流形中识别普遍的神经表示

    Identifying Generalized Neural Representation Across Hamiltonian Manifolds via Meta-learning. (arXiv:2212.01168v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.01168](http://arxiv.org/abs/2212.01168)

    通过元学习方法，在哈密顿流形中识别出普遍的神经表示，实现了对不同物理系统的快速适应能力。

    

    最近物理学中深度学习的进展集中在通过将物理先验或归纳偏见引入神经网络来发现目标系统的共享表示。然而，这些方法特定于系统，不允许轻松适应由不同物理法则驱动的新物理系统。例如，训练于质点弹簧系统的神经网络无法准确预测双体系统或任何具有不同物理法则的系统的行为。在本研究中，我们使用图神经网络模拟我们的系统，并采用元学习算法使模型在一系列任务中积累经验，并使其适应新的物理系统。我们的方法旨在学习跨各种哈密顿流形的通用表示，这是哈密顿系统数据分布的共同特征。我们使用由不同系统组成的数据集训练模型，每个系统都有其自身固有的动力学，并评估其性能。

    Recent advancements in deep learning for physics have focused on discovering shared representations of target systems by incorporating physics priors or inductive biases into neural networks. However, these approaches are system-specific and do not allow for easy adaptation to new physical systems governed by different laws. For example, a neural network trained on a mass-spring system cannot accurately predict the behavior of a two-body system or any other system with different governing physics. In this work, we model our system with a graph neural network and employ a meta-learning algorithm to enable the model to gain experience over a distribution of tasks and make it adapt to new physics. Our approach aims to learn a general representation across the various Hamiltonian manifolds, which is a common feature of the data distribution of Hamiltonian systems. We train our model using a dataset of different physical systems, each governed by its own inherent dynamics, and evaluate its 
    
[^77]: ComCLIP: 无需训练的组合图像与文本匹配

    ComCLIP: Training-Free Compositional Image and Text Matching. (arXiv:2211.13854v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.13854](http://arxiv.org/abs/2211.13854)

    本文提出了一个无需训练的组合图像与文本匹配模型 ComCLIP，通过将输入图像分解为主体、对象和动作子图像，并结合视觉编码器和文本编码器进行逐步匹配，以解决组合图像与文本匹配中的伪匹配问题。

    

    对比语言-图像预训练（CLIP）已经展示了在图像与文本匹配方面的很好的零样本性能。然而，将 CLIP 这样的视觉-语言预训练模型适应于更具挑战性的组合图像与文本匹配仍然具有挑战性，这需要模型理解组合词概念和视觉组件。为了实现更好的零样本图像与文本匹配中的组合泛化能力，本文从因果关系的角度研究了该问题：单个实体的错误语义本质上是导致匹配失败的混淆因素。因此，我们提出了一种新颖的“无需训练”的组合 CLIP 模型（ComCLIP）。ComCLIP将输入图像分解为主体、对象和动作子图像，并组合 CLIP 的视觉编码器和文本编码器，以在组合文本嵌入和子图像嵌入之上进行逐步匹配。通过这种方式，ComCLIP 可以减轻伪匹配问题。

    Contrastive Language-Image Pretraining (CLIP) has demonstrated great zero-shot performance for matching images and text. However, it is still challenging to adapt vision-lanaguage pretrained models like CLIP to compositional image and text matching -- a more challenging image and text matching task requiring the model understanding of compositional word concepts and visual components. Towards better compositional generalization in zero-shot image and text matching, in this paper, we study the problem from a causal perspective: the erroneous semantics of individual entities are essentially confounders that cause the matching failure. Therefore, we propose a novel \textbf{\textit{training-free}} compositional CLIP model (ComCLIP). ComCLIP disentangles input images into subjects, objects, and action sub-images and composes CLIP's vision encoder and text encoder to perform evolving matching over compositional text embedding and sub-image embeddings. In this way, ComCLIP can mitigate spurio
    
[^78]: 从预测市场到可解释的集体智能

    From prediction markets to interpretable collective intelligence. (arXiv:2204.13424v3 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2204.13424](http://arxiv.org/abs/2204.13424)

    本文提出了一个机制，可以从任意专家组中收集到关于任意逻辑命题真实概率的信息，并提供具有明确形式的解释。该机制可以激励专家直接交流信息，解决科学或医学问题。

    

    我们概述了如何创建一种机制，能够以最优的方式从任意专家组中引出关于任意逻辑命题真实概率的信息，并提供具有明确形式的集体信息来解释这种概率。特别地，我们提供了强有力的论据，证明了开发一种使用虚拟货币激励专家之间直接信息交流的自解决预测市场的可能性。这样的系统可以同时激励许多专家以非常高效的方式共同解决科学或医学问题。我们还指出，在我们的考虑中，并不假设专家们是贝叶斯主义者。

    We outline how to create a mechanism that provides an optimal way to elicit, from an arbitrary group of experts, the probability of the truth of an arbitrary logical proposition together with collective information that has an explicit form and interprets this probability. Namely, we provide strong arguments for the possibility of the development of a self-resolving prediction market with play money that incentivizes direct information exchange between experts. Such a system could, in particular, motivate simultaneously many experts to collectively solve scientific or medical problems in a very efficient manner. We also note that in our considerations, experts are not assumed to be Bayesian.
    

