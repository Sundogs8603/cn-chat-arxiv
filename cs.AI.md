# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning](https://arxiv.org/abs/2403.03218) | WMDP基准是一个公开发布的数据集，包含4157个多项选择问题，用作生物安全、网络安全和化学安全危险知识的代理测量。 |
| [^2] | [CLEVR-POC: Reasoning-Intensive Visual Question Answering in Partially Observable Environments](https://arxiv.org/abs/2403.03203) | 我们提出了一个名为CLEVR-POC的新型基准，用于在部分可观测环境中进行理性密集型视觉问答，需要利用逻辑约束的知识来生成可能的答案。 |
| [^3] | [Towards Democratized Flood Risk Management: An Advanced AI Assistant Enabled by GPT-4 for Enhanced Interpretability and Public Engagement](https://arxiv.org/abs/2403.03188) | 引入基于GPT-4的定制AI助手，旨在促进决策者、普通公众和洪水预报员之间的有效沟通，提升可解释性和公众参与度。 |
| [^4] | [Reliable, Adaptable, and Attributable Language Models with Retrieval](https://arxiv.org/abs/2403.03187) | 持续面临挑战的参数化语言模型LMs，作者主张使用具有检索功能的LMs作为下一代LMs，以提高可靠性、适应性和可追溯性。 |
| [^5] | [Towards General Computer Control: A Multimodal Agent for Red Dead Redemption II as a Case Study](https://arxiv.org/abs/2403.03186) | 提出了通用计算机控制（GCC）设置，通过基于屏幕图像和可能的音频输入的基金代理框架Cradle，实现了对《荒野大镖客2》中复杂任务的控制。 |
| [^6] | [Preventing Reward Hacking with Occupancy Measure Regularization](https://arxiv.org/abs/2403.03185) | 用占用度测量正则化方法可以有效防止奖励欺骗，通过考虑代理与真实奖励之间大的状态占用度偏差来避免潜在的灾难后果。 |
| [^7] | [How Well Can Transformers Emulate In-context Newton's Method?](https://arxiv.org/abs/2403.03183) | Transformers能够实现高阶优化算法，线性注意力Transformer可以在 logistic 回归任务中近似实现二阶优化算法，并展示即使是线性注意力的Transformer也可以实现矩阵求逆的牛顿迭代。 |
| [^8] | [Behavior Generation with Latent Actions](https://arxiv.org/abs/2403.03181) | 这项工作介绍了一种名为矢量量化行为转换器（VQ-BeT）的多功能行为生成模型，通过对连续动作进行标记化处理多模态动作预测、条件生成和部分观察。 |
| [^9] | [Unifying and Certifying Top-Quality Planning](https://arxiv.org/abs/2403.03176) | 现有的高质量规划定义可以统一为基于支配关系的一个定义，从而实现认证解决方案的高质量，并提出了有效认证各种高质量规划问题的方法，并且提出了一种新的转换来有效地认证无环高质量规划。 |
| [^10] | [MOKA: Open-Vocabulary Robotic Manipulation through Mark-Based Visual Prompting](https://arxiv.org/abs/2403.03174) | MOKA方法利用视觉语言模型解决机器人操作任务，实现了开放词汇的机器人操作。 |
| [^11] | [Reaching Consensus in Cooperative Multi-Agent Reinforcement Learning with Goal Imagination](https://arxiv.org/abs/2403.03172) | 提出了一种基于模型的共识机制，使用多智能体目标想象框架引导智能体达成共识，从而提高合作多智能体强化学习的性能。 |
| [^12] | [SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection](https://arxiv.org/abs/2403.03170) | SNIFFER是一种专门为超出上下文误传检测和解释而设计的新型多模大语言模型，通过两阶段指导微调，在解释生成方面取得了突破。 |
| [^13] | [Learning Explicitly Conditioned Sparsifying Transforms](https://arxiv.org/abs/2403.03168) | 该论文提出了一种新的稀疏变换模型，通过显式控制数据表示质量和条件数，有效地学习保证数据在稀疏域中具有良好表示的优化变换。 |
| [^14] | [Leveraging Federated Learning and Edge Computing for Recommendation Systems within Cloud Computing Networks](https://arxiv.org/abs/2403.03165) | 边缘智能结合了AI和边缘计算，利用联邦学习实现隐私保护的机器学习，在FL网络中提出分层联邦学习（HFL）框架以提高通信效率。 |
| [^15] | [Quantum Many-Body Physics Calculations with Large Language Models](https://arxiv.org/abs/2403.03154) | 使用大型语言模型准确地执行理论物理研究论文中关键的Hartree-Fock方法计算。 |
| [^16] | [Simplicity in Complexity](https://arxiv.org/abs/2403.03134) | 本研究提出使用基于区段的图像表示来建模复杂性，与之前复杂的图像复杂性模型不同，这种方法既能泛化，又能为理论理解提供指导。 |
| [^17] | [Equilibria in Two-Stage Facility Location with Atomic Clients](https://arxiv.org/abs/2403.03114) | 本文研究了竞争性设施选址的两阶段多代理系统，针对不可分割权重的客户提出了混合策略，展示了在给定设施布置时可能出现截然不同的客户均衡。 |
| [^18] | [Improved LiDAR Odometry and Mapping using Deep Semantic Segmentation and Novel Outliers Detection](https://arxiv.org/abs/2403.03111) | 提出了一个新颖的框架，利用深度学习模型产生的语义信息改进了LiDAR数据的点线匹配和点面匹配，从而实现更准确的运动估计。 |
| [^19] | ["In Dialogues We Learn": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning](https://arxiv.org/abs/2403.03102) | 提出了一种In-Dialogue Learning框架，通过对话历史刻画个人设来完成个性化对话生成任务，无需预定义个人资料，并在实验证明其显著改进对话生成性能。 |
| [^20] | [KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents](https://arxiv.org/abs/2403.03101) | KnowAgent引入了显式动作知识，通过动作知识库和知识型自学习策略来增强LLM的规划能力，从而改善语言Agent的规划表现。 |
| [^21] | [NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models](https://arxiv.org/abs/2403.03100) | NaturalSpeech 3利用分解设计的扩散模型实现零-shot方式生成自然语音 |
| [^22] | [VQSynery: Robust Drug Synergy Prediction With Vector Quantization Mechanism](https://arxiv.org/abs/2403.03089) | VQSynergy通过矢量量化机制以及其他创新技术提高了药物协同预测的精度和泛化能力，在处理高斯噪声条件下表现出色。 |
| [^23] | [Recall-Oriented Continual Learning with Generative Adversarial Meta-Model](https://arxiv.org/abs/2403.03082) | 框架提出了召回导向的持续学习方法，通过生成对抗元模型(GAMM)在学习新任务时最大化过去知识的稳定性。 |
| [^24] | [Neural Codebook Design for Network Beam Management](https://arxiv.org/abs/2403.03053) | 本文提出了一种端到端的学习码本设计算法，网络波束学习（NBL），能够优化码本以减少干扰并最大化性能，适用于大型混合阵列系统。 |
| [^25] | [Unifying Controller Design for Stabilizing Nonlinear Systems with Norm-Bounded Control Inputs](https://arxiv.org/abs/2403.03030) | 提出了一种统一的控制器设计方法，通过引入通用的缩放项，实现了针对非线性系统稳定控制器设计的通用性并生成了多种有利特性的备选通用公式。 |
| [^26] | [Word Importance Explains How Prompts Affect Language Model Outputs](https://arxiv.org/abs/2403.03028) | 通过改变提示中的单词，本研究提出了一种方法来解释大型语言模型（LLMs）的工作原理，从而揭示其对模型输出的影响。 |
| [^27] | [SplAgger: Split Aggregation for Meta-Reinforcement Learning](https://arxiv.org/abs/2403.03020) | 本文展示了任务推断序列模型在元强化学习中的益处。 |
| [^28] | [OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following](https://arxiv.org/abs/2403.03017) | OPEx框架提出了对解决嵌入式学习任务至关重要的核心组件-观察者、规划者和执行者，并通过深入评估分析了各组件对于嵌入式指导遵循任务性能的影响。 |
| [^29] | [Knowledge Graphs as Context Sources for LLM-Based Explanations of Learning Recommendations](https://arxiv.org/abs/2403.03008) | 本文提出了一种利用知识图谱作为事实上下文的来源，为基于LLM的学习推荐提供解释，以降低模型幻觉风险，确保高精度，并保持学习上下文的方法。 |
| [^30] | [Mem-elements based Neuromorphic Hardware for Neural Network Application](https://arxiv.org/abs/2403.03002) | 这项研究提出了利用记忆元件交叉阵列设计低功耗机器学习加速器的方法，并且成功实现了在CIFAR-10数据集上使用memristive和memcapacitive交叉阵列在8层VGG网络上实现出色训练准确度。 |
| [^31] | [Mitigating Label Flipping Attacks in Malicious URL Detectors Using Ensemble Trees](https://arxiv.org/abs/2403.02995) | 本研究旨在利用集成树来缓解恶意URL检测器中的标签翻转攻击，从而在机器学习模型中集成防御机制以防范潜在攻击。 |
| [^32] | [Localized Zeroth-Order Prompt Optimization](https://arxiv.org/abs/2403.02993) | 提出了一种本地化的零阶提示优化方法，通过研究发现，局部最优解通常普遍存在且表现良好，有助于高效的提示优化。 |
| [^33] | [Data Augmentation using LLMs: Data Perspectives, Learning Paradigms and Challenges](https://arxiv.org/abs/2403.02990) | 探讨了大型语言模型（LLMs）对数据增强的转变性影响，独特挑战和机遇，突出了LLMs在数据增强中引入的范式转变。 |
| [^34] | [Evolution Transformer: In-Context Evolutionary Optimization](https://arxiv.org/abs/2403.02985) | 提出了一种Evolution Transformer架构，可以通过元优化直接发现强大的优化原则，达到改进搜索分布的目的。 |
| [^35] | [Federated Learning Under Attack: Exposing Vulnerabilities through Data Poisoning Attacks in Computer Networks](https://arxiv.org/abs/2403.02983) | 该研究旨在探索计算机网络领域中数据中毒攻击的严重性，使用了两种类型的攻击：标签翻转和特征中毒，采用了新颖的方法。 |
| [^36] | [A General and Flexible Multi-concept Parsing Framework for Multilingual Semantic Matching](https://arxiv.org/abs/2403.02975) | 提出一个通用灵活的多概念解析框架用于多语言语义匹配，以解决关键词和意图概念识别以及外部NER依赖的问题 |
| [^37] | [Evidence-Focused Fact Summarization for Knowledge-Augmented Zero-Shot Question Answering](https://arxiv.org/abs/2403.02966) | 提出了一种面向证据的事实摘要化框架EFSum，用于增强LLMs的零-shot QA性能，并确保摘要的有益性和忠实性。 |
| [^38] | [ChatGPT and biometrics: an assessment of face recognition, gender detection, and age estimation capabilities](https://arxiv.org/abs/2403.02965) | 本文评估了ChatGPT在面部识别、性别检测和年龄估计等生物识别任务中的表现，结果显示ChatGPT在面部识别方面具有较高准确性，并在性别检测方面表现显著，在年龄估计任务中也具有相当准确性。 |
| [^39] | [WikiTableEdit: A Benchmark for Table Editing by Natural Language Instruction](https://arxiv.org/abs/2403.02962) | 本研究介绍了WikiTableEdit数据集，通过26,531个表格生成自然语言指令，针对表格编辑任务中的不规则结构，为解决复杂表格代码编辑问题提供了新途径。 |
| [^40] | [SimuCourt: Building Judicial Decision-Making Agents with Real-world Judgement Documents](https://arxiv.org/abs/2403.02959) | 提出了SimuCourt司法基准，包括真实世界的司法文件，并引入了司法决策任务和多代理框架，评估了代理的司法分析和决策能力 |
| [^41] | [Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation](https://arxiv.org/abs/2403.02951) | 大型语言模型在文本生成SQL任务中表现出色，但对于最佳提示模板和设计框架仍无共识，新数据集和评估任务有助于全面评估各种方法的表现，并提出了优化解决方案。 |
| [^42] | [A general approach to enhance the survivability of backdoor attacks by decision path coupling](https://arxiv.org/abs/2403.02950) | Venom是一种通用的后门攻击增强器，通过采用关注模仿损失，强迫受损样本的决策路径与良性样本的关键决策路径耦合，从而提高现有后门攻击对模型重建型防御的生存能力。 |
| [^43] | [SAFFIRA: a Framework for Assessing the Reliability of Systolic-Array-Based DNN Accelerators](https://arxiv.org/abs/2403.02946) | 介绍了一种针对基于Systolic Array的DNN加速器的新型分层软件化硬件感知故障注入策略，以解决可靠性评估中的时间效率问题。 |
| [^44] | [PaperWeaver: Enriching Topical Paper Alerts by Contextualizing Recommended Papers with User-collected Papers](https://arxiv.org/abs/2403.02939) | PaperWeaver通过将用户收集的论文与推荐论文上下文化，为研究人员提供了更丰富的主题论文提醒 |
| [^45] | [AdAM: Adaptive Fault-Tolerant Approximate Multiplier for Edge DNN Accelerators](https://arxiv.org/abs/2403.02936) | 提出了一种适用于ASIC-based DNN加速器的自适应容错近似乘法器架构。 |
| [^46] | [Fuzzy Datalog$^\exists$ over Arbitrary t-Norms](https://arxiv.org/abs/2403.02933) | 将Datalog与存在规则泛化到模糊环境中，利用任意t-范数进行推理，保持了计算复杂性结果和推理技术的适用性 |
| [^47] | [TaylorShift: Shifting the Complexity of Self-Attention from Squared to Linear (and Back) using Taylor-Softmax](https://arxiv.org/abs/2403.02920) | TaylorShift通过引入TaylorSoftmax重新计算全记号之间的交互，将自注意力机制的复杂度由平方级降低到线性级，从而提高了处理长序列的效率。 |
| [^48] | [DynST: Dynamic Sparse Training for Resource-Constrained Spatio-Temporal Forecasting](https://arxiv.org/abs/2403.02914) | 传统传感器部署方法在地球科学系统中存在困难，本研究提出了一种动态稀疏训练方法，能够有效优化传感器的部署和数据收集过程。 |
| [^49] | [ImgTrojan: Jailbreaking Vision-Language Models with ONE Image](https://arxiv.org/abs/2403.02910) | 本文提出了一种针对视觉-语言模型的新型越狱攻击，通过在训练数据中插入恶意文本提示，成功实施越狱攻击，并分析了有毒数据比率和可训练参数位置对攻击成功率的影响。 |
| [^50] | [A Comprehensive Survey on Process-Oriented Automatic Text Summarization with Exploration of LLM-Based Methods](https://arxiv.org/abs/2403.02901) | 本综合调查从“过程导向模式“视角提供了自动文本摘要的全面概述，全面审视了最新的基于LLM的ATS工作，并提供了关于ATS最新的调查，弥补了文献中的两年间隔。 |
| [^51] | [Domain-Agnostic Mutual Prompting for Unsupervised Domain Adaptation](https://arxiv.org/abs/2403.02899) | 提出了领域无关互相提示（DAMP）方法，通过互相对齐视觉和文本嵌入来利用领域不变语义，弥合了传统无监督领域自适应方法的局限性。 |
| [^52] | [Zero-Shot Cross-Lingual Document-Level Event Causality Identification with Heterogeneous Graph Contrastive Transfer Learning](https://arxiv.org/abs/2403.02893) | 提出了一种使用异构图对比迁移学习的方法，实现了零样本跨语言文档级事件因果识别，并在实验证明在F1得分上优于之前的最先进模型。 |
| [^53] | [Enhancing Long-Term Person Re-Identification Using Global, Local Body Part, and Head Streams](https://arxiv.org/abs/2403.02892) | 提出了一个新框架，结合全局和局部信息，利用三个流（全局、局部身体部位和头部），用于增强长期人员再识别任务。 |
| [^54] | [MathScale: Scaling Instruction Tuning for Mathematical Reasoning](https://arxiv.org/abs/2403.02884) | MathScale提出了一种简单可扩展的方法来创建高质量的数学推理数据，展现出在数学数据集大小方面的有效可扩展性。 |
| [^55] | [ActiveAD: Planning-Oriented Active Learning for End-to-End Autonomous Driving](https://arxiv.org/abs/2403.02877) | 设计了一种面向规划的主动学习方法，通过多样性和有用性标准逐步注释采集的原始数据，以实现端到端自动驾驶的样本和标记效率。 |
| [^56] | [Precise Extraction of Deep Learning Models via Side-Channel Attacks on Edge/Endpoint Devices](https://arxiv.org/abs/2403.02870) | 该研究揭示了对深度学习模型进行精确提取的新型攻击方法，通过边缘/端点设备的侧信道攻击可以获取模型架构和图像维度等重要信息。 |
| [^57] | [FLGuard: Byzantine-Robust Federated Learning via Ensemble of Contrastive Models](https://arxiv.org/abs/2403.02846) | 通过对比模型集合，提出了FLGuard方法增强联邦学习的拜占庭-鲁棒性。 |
| [^58] | [Reconstruction for Sparse View Tomography of Long Objects Applied to Imaging in the Wood Industry](https://arxiv.org/abs/2403.02820) | 本研究提出了一种基于学习原始-对偶神经网络的迭代重建方法，适用于顺序扫描几何形状，可以在稀疏视角下进行原木的三维层析成像重建。 |
| [^59] | [InjectTST: A Transformer Method of Injecting Global Information into Independent Channels for Long Time Series Forecasting](https://arxiv.org/abs/2403.02814) | 提出了InjectTST这种将全局信息注入独立通道的变压器方法，用于改进多变量时间序列（MTS）预测性能。 |
| [^60] | [Dynamic Gaussian Graph Operator: Learning parametric partial differential equations in arbitrary discrete mechanics problems](https://arxiv.org/abs/2403.02810) | 提出了一种新颖的操作学习算法，称为动态高斯图算子（DGGO），可以在任意离散力学问题中学习参数化PDEs。 |
| [^61] | [DPPA: Pruning Method for Large Language Model to Model Merging](https://arxiv.org/abs/2403.02799) | 提出了一种名为动态修剪分区增强（DPPA）的双阶段方法，用于解决合并复杂微调模型的挑战。 |
| [^62] | [Evaluating and Optimizing Educational Content with Large Language Model Judgments](https://arxiv.org/abs/2403.02795) | 使用语言模型作为教育专家来评估教育内容的影响，展示了LMs作为可靠评估者的潜力，并介绍了一种指导优化方法。 |
| [^63] | [A Distance Metric Learning Model Based On Variational Information Bottleneck](https://arxiv.org/abs/2403.02794) | 本文首次将变分信息瓶颈与度量学习模型相结合，提出了一种新的度量学习模型 VIB-DML 用于评分预测，限制潜空间特征向量的互信息以提高模型鲁棒性并满足欧氏距离的假设。 |
| [^64] | [Semi-Supervised Graph Representation Learning with Human-centric Explanation for Predicting Fatty Liver Disease](https://arxiv.org/abs/2403.02786) | 该研究在半监督学习框架内探索了图表示学习的潜力，通过人类中心解释提供了个性化特征重要性得分，以增强解释性和临床相关性。 |
| [^65] | [Where the Really Hard Quadratic Assignment Problems Are: the QAP-SAT instances](https://arxiv.org/abs/2403.02783) | 通过引入基于子模性的新QAP-SAT设计，研究二次分配问题的相变现象，提出了一个相变参数，可预测禁忌搜索中困难实例的解决难度。 |
| [^66] | [EasyQuant: An Efficient Data-free Quantization Algorithm for LLMs](https://arxiv.org/abs/2403.02775) | EasyQuant是一种无需训练的、无需数据的仅针对权重的量化算法，旨在减少量化误差并保证LLM的泛化性能。 |
| [^67] | [Rehabilitation Exercise Quality Assessment through Supervised Contrastive Learning with Hard and Soft Negatives](https://arxiv.org/abs/2403.02772) | 这项研究引入了一种新的有监督对比学习框架，通过结合硬和软负样本，有效地解决了康复锻炼评估中样本稀缺的问题 |
| [^68] | [Emerging Synergies Between Large Language Models and Machine Learning in Ecommerce Recommendations](https://arxiv.org/abs/2403.02760) | 大型语言模型的兴起对电子商务推荐系统带来了新的发展机遇，突破了基于深度神经网络的推荐方法的局限性。 |
| [^69] | [Speckle Noise Reduction in Ultrasound Images using Denoising Auto-encoder with Skip Connection](https://arxiv.org/abs/2403.02750) | 本文通过比较七种不同的散斑去除方法，证明带有跳跃连接的去噪自编码器在减少超声图像散斑噪声时能够有效保留特征和边缘。 |
| [^70] | [CURATRON: Complete Robust Preference Data for Robust Alignment of Large Language Models](https://arxiv.org/abs/2403.02745) | 本论文提出了一种新方法，通过彻底重校准偏好数据集中的价值观，以增强大型语言模型对问题的韧性。 |
| [^71] | [Bootstrapping Rare Object Detection in High-Resolution Satellite Imagery](https://arxiv.org/abs/2403.02736) | 本文提出了一种在高分辨率卫星图像中引导稀有物体检测的方法，通过离线和在线基于聚类的采样方法，显著提高了正样本暴露率，实现了从2%到30%的正样本采样率增加，从而有效地实现了机器学习映射。 |
| [^72] | [HARGPT: Are LLMs Zero-Shot Human Activity Recognizers?](https://arxiv.org/abs/2403.02727) | HARGPT研究表明LLMs可以通过适当提示理解原始IMU数据，实现零样本人类活动识别，并在性能上优于传统机器学习和最先进深度分类模型。 |
| [^73] | [Bias in Generative AI](https://arxiv.org/abs/2403.02726) | 本研究揭示了生成AI工具中存在的系统性性别和种族偏见，以及对面部表情和外表的微妙偏见。 |
| [^74] | [Minimum Topology Attacks for Graph Neural Networks](https://arxiv.org/abs/2403.02723) | 提出了一种新型的最小预算拓扑攻击，名为MiBTack，旨在自适应地找到对每个节点成功攻击所需的最小扰动。 |
| [^75] | [Multi-Scale Subgraph Contrastive Learning](https://arxiv.org/abs/2403.02719) | 提出了一种多尺度子图对比学习方法，能够表征细粒度语义信息，解决了在图增强后原有假设不再成立的问题 |
| [^76] | [Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of Vietnamese Large Language Models](https://arxiv.org/abs/2403.02715) | 该研究通过对LLMs在越南语上进行微调和综合评估，发现微调后的模型在越南语理解和生成方面表现出良好能力，同时指出模型参数数量与性能之间存在着权衡关系，训练或微调数据集的质量是影响LLM性能的关键因素。 |
| [^77] | [Fighting Game Adaptive Background Music for Improved Gameplay](https://arxiv.org/abs/2403.02701) | 本文介绍了一种通过添加自适应特性改进DareFightingICE游戏玩法的背景音乐方法，并通过实验证明Blind DL AI在使用自适应背景音乐时比不使用时表现更好。 |
| [^78] | [Privacy-Aware Semantic Cache for Large Language Models](https://arxiv.org/abs/2403.02694) | MeanCache是一种面向LLMs的语义缓存，能够识别语义上相似的查询，从而减少查询成本，服务提供商负载和环境影响。 |
| [^79] | [DOCTOR: Dynamic On-Chip Remediation Against Temporally-Drifting Thermal Variations Toward Self-Corrected Photonic Tensor Accelerators](https://arxiv.org/abs/2403.02688) | 首次提出了轻量级的动态片上矫正框架DOCTOR，针对光子张量加速器中的时间漂移变化问题，实现自适应、原位准确度恢复 |
| [^80] | [Enhanced DareFightingICE Competitions: Sound Design and AI Competitions](https://arxiv.org/abs/2403.02687) | 本文介绍了一个增强版的DareFightingICE平台，分为声音设计比赛和AI比赛，通过改进音频系统和发送音频数据的方法，使得平台更容易为视障玩家添加新功能，并改进了声音设计竞赛的评估方法。 |
| [^81] | [Learning at the Speed of Wireless: Online Real-Time Learning for AI-Enabled MIMO in NextG](https://arxiv.org/abs/2403.02651) | 将AI/ML工具应用于MIMO，实现对于NextG蜂窝网络中无线环境动态性的在线实时学习和适应性调节。 |
| [^82] | [Remove that Square Root: A New Efficient Scale-Invariant Version of AdaGrad](https://arxiv.org/abs/2403.02648) | KATE是一种新的优化算法，提出了一种与AdaGrad标度不变的适应方法，并在广义线性模型和一般的非凸问题中证明了其标度不变性。数值实验结果表明，KATE在各种场景中均优于AdaGrad并与Adam性能匹配/超越。 |
| [^83] | [FinReport: Explainable Stock Earnings Forecasting via News Factor Analyzing Model](https://arxiv.org/abs/2403.02647) | FinReport是一个自动系统，通过金融新闻公告和多因素模型来生成专业的股票盈利预测报告，旨在帮助普通投资者收集信息、分析数据并生成报告。 |
| [^84] | [PPS-QMIX: Periodically Parameter Sharing for Accelerating Convergence of Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2403.02635) | 提出了三种简单的新方法来加速多智体强化学习训练过程，即平均周期参数共享（A-PPS）、奖励可伸缩性周期参数共享（RS-PPS）和部分个性化周期参数共享（PP-PPS）机制。 |
| [^85] | [Pareto-Optimal Estimation and Policy Learning on Short-term and Long-term Treatment Effects](https://arxiv.org/abs/2403.02624) | 该论文提出了帕累托最优估计和策略学习的方法，用于确定如何在短期和长期治疗效果之间进行权衡从而实现最佳治疗。 |
| [^86] | [World Models for Autonomous Driving: An Initial Survey](https://arxiv.org/abs/2403.02622) | 世界模型在自主驾驶领域的重要性和作用，是通过准确预测未来事件和评估其影响来帮助决策过程，从而推动自主驾驶技术发展的革命性方法。 |
| [^87] | [Unsupervised Spatio-Temporal State Estimation for Fine-grained Adaptive Anomaly Diagnosis of Industrial Cyber-physical Systems](https://arxiv.org/abs/2403.02616) | 提出了一种细粒度自适应异常诊断方法（MAD-Transformer），通过构建时间状态矩阵和空间状态矩阵来揭示工业CPS工作状态的时空关联关系和演变机制 |
| [^88] | [Large Language Models and Video Games: A Preliminary Scoping Review](https://arxiv.org/abs/2403.02613) | 大型语言模型在视频游戏领域的研究正在迅速发展，本文通过初步范围审查了76篇关于LLMs和视频游戏的论文，为未来研究和评论奠定了基础。 |
| [^89] | [A Unified Framework for Microscopy Defocus Deblur with Multi-Pyramid Transformer and Contrastive Learning](https://arxiv.org/abs/2403.02611) | 该论文提出了一个统一的框架，结合了多金字塔变换器和扩展频率对比正规化，以解决显微镜去模糊中的长距离交互和特征不足挑战。 |
| [^90] | [ChatGPT4PCG 2 Competition: Prompt Engineering for Science Birds Level Generation](https://arxiv.org/abs/2403.02610) | 本文介绍了2024年IEEE游戏大会上第二届ChatGPT4PCG比赛，引入多样性作为新的指标，允许提交Python程序以实现更灵活的先进提示工程方法。 |
| [^91] | [MEBS: Multi-task End-to-end Bid Shading for Multi-slot Display Advertising](https://arxiv.org/abs/2403.02607) | 本研究引入了出价遮蔽到多槽位展示广告中，通过MEBS方法实现了竞价价格调整，并在理论上证明了其最优性，在实验证明了其性能有效性和效率，实现了毛利量的7.01%增长和投资回报率的7.42%增长 |
| [^92] | [MUSIC: Accelerated Convergence for Distributed Optimization With Inexact and Exact Methods](https://arxiv.org/abs/2403.02589) | 提出了一个名为MUSIC的加速框架，允许每个代理执行多个本地更新和每个迭代中的单个组合，同时将不精确和精确的分布式优化方法结合，实现了加速的线性收敛和高通信效率。 |
| [^93] | [ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature Summary](https://arxiv.org/abs/2403.02574) | ChatCite是一个LLM代理，通过人工工作流引导进行比较文学综述，利用反思逐步机制生成摘要。 |
| [^94] | [Eliciting Better Multilingual Structured Reasoning from LLMs through Code](https://arxiv.org/abs/2403.02567) | LLMs在多语言推理任务上表现出较弱的性能，本文提出了通过代码训练和推理来改善多语言结构化推理能力的方法。 |
| [^95] | [Wukong: Towards a Scaling Law for Large-Scale Recommendation](https://arxiv.org/abs/2403.02545) | Wukong通过堆叠因子分解机和协同增长策略，在推荐领域建立了一个标度律，并在质量上优于现有模型。 |
| [^96] | [DACO: Towards Application-Driven and Comprehensive Data Analysis via Code Generation](https://arxiv.org/abs/2403.02528) | 该论文通过自动生成高质量答案注释的方法，构建了DACO数据集，旨在激发未来对数据分析这一关键且具有挑战性任务的研究。 |
| [^97] | [Transformer for Times Series: an Application to the S&P500](https://arxiv.org/abs/2403.02523) | 本文探讨了将Transformer模型应用于金融时间序列预测中的可行性，并展示了在合成和真实数据集上的一些鼓舞人心的结果。 |
| [^98] | [HeAR -- Health Acoustic Representations](https://arxiv.org/abs/2403.02522) | HeAR是一个基于自监督学习的深度学习系统，通过大规模数据集训练，在33个健康声学任务上表现优越，有望推动健康声学研究的发展。 |
| [^99] | [Purpose for Open-Ended Learning Robots: A Computational Taxonomy, Definition, and Operationalisation](https://arxiv.org/abs/2403.02514) | 提出了设定机器人目的的概念，以帮助机器人更加关注获取与目的相关的知识。 |
| [^100] | [SPUQ: Perturbation-Based Uncertainty Quantification for Large Language Models](https://arxiv.org/abs/2403.02509) | SPUQ是一种新颖的基于扰动的大型语言模型不确定性量化方法，旨在同时处理现象性和认知性不确定性 |
| [^101] | [A Tutorial on the Pretrain-Finetune Paradigm for Natural Language Processing](https://arxiv.org/abs/2403.02504) | 预训练-微调范式在自然语言处理中展现了显著的效率，尤其对社会科学研究中数据有限的情况下具有益处。 |
| [^102] | [Trial and Error: Exploration-Based Trajectory Optimization for LLM Agents](https://arxiv.org/abs/2403.02502) | 提出了一种面向LLM代理的基于探索的轨迹优化方法，通过允许代理从探索失败中学习，实现了性能的改进。 |
| [^103] | [Pseudo-Labeling and Contextual Curriculum Learning for Online Grasp Learning in Robotic Bin Picking](https://arxiv.org/abs/2403.02495) | 提出了一种将半监督学习和强化学习相结合的SSL-ConvSAC方法，有效利用未标记数据增强在线抓取学习，并通过基于情境课程的方法解决标记和未标记数据不平衡问题，在真实世界数据集上验证了在垃圾桶挑选任务中改进在线抓取学习的潜力。 |
| [^104] | [Encodings for Prediction-based Neural Architecture Search](https://arxiv.org/abs/2403.02484) | 预测器方法在神经架构搜索方面起到了显著作用，本文对不同类型的神经编码进行了分类和研究，并引入了统一编码，扩展了NAS预测器到多个搜索空间。 |
| [^105] | [MORBDD: Multiobjective Restricted Binary Decision Diagrams by Learning to Sparsify](https://arxiv.org/abs/2403.02482) | 本文提出了一种基于机器学习的BDD稀疏化器MORBDD，通过训练二元分类器来消除不太可能贡献于帕累托解的BDD节点。 |
| [^106] | [The Ink Splotch Effect: A Case Study on ChatGPT as a Co-Creative Game Designer](https://arxiv.org/abs/2403.02454) | 本研究通过将大型语言模型应用于游戏设计中，探讨了人工智能辅助对游戏质量的影响，并在用户研究中对其进行了验证。 |
| [^107] | [Anatomically Constrained Tractography of the Fetal Brain](https://arxiv.org/abs/2403.02444) | 提出了一种基于精确分割胎儿大脑组织的解剖约束纤维束追踪方法，并通过深度学习方法实现自动分割，有效改善了对胎儿大脑的纤维束追踪准确性。 |
| [^108] | [Root Causing Prediction Anomalies Using Explainable AI](https://arxiv.org/abs/2403.02439) | 本文介绍了在根本上解决个性化广告中模型性能下降问题的方法，通过解释人工智能技术分析预测异常。 |
| [^109] | [SoK: Challenges and Opportunities in Federated Unlearning](https://arxiv.org/abs/2403.02437) | 联邦学习引入了新的隐私要求，促使研究开始关注适用于联邦学习环境的反学习机制。 |
| [^110] | [Towards efficient deep autoencoders for multivariate time series anomaly detection](https://arxiv.org/abs/2403.02429) | 本文提出了面向多变量时间序列异常检测的深度自编码器的高效压缩方法，通过修剪减少权重数量并防止精度灾难性下降，以在有限时间和内存约束的实时系统中获得最佳结果。 |
| [^111] | [Are More LLM Calls All You Need? Towards Scaling Laws of Compound Inference Systems](https://arxiv.org/abs/2403.02419) | 本文研究了复合推理系统的扩展定律，发现投票推理系统的性能随LLM调用次数增加先增加后下降。 |
| [^112] | [OTClean: Data Cleaning for Conditional Independence Violations using Optimal Transport](https://arxiv.org/abs/2403.02372) | 使用最优输运理论的OTClean框架解决了在条件独立性（CI）约束下数据清洗的问题，通过将数据修复问题转化为正则化优化问题，并提出了受Sinkhorn矩阵缩放算法启发的迭代算法，克服了可伸缩性挑战。 |
| [^113] | [NeuroVoz: a Castillian Spanish corpus of parkinsonian speech](https://arxiv.org/abs/2403.02371) | 这一研究提出了一个包含108位母语为卡斯蒂利亚语说话者的帕金森病患者语音语料库，涵盖了多种语音任务，通过手动和自动转录确保了数据的准确性和可靠性。 |
| [^114] | [adaptMLLM: Fine-Tuning Multilingual Language Models on Low-Resource Languages with Integrated LLM Playgrounds](https://arxiv.org/abs/2403.02370) | 该论文介绍了adaptMLLM，一个旨在解决低资源语言机器翻译问题的开源应用程序，该应用程序简化了对多语言语言模型进行微调的所有流程。 |
| [^115] | [A Novel Hybrid Feature Importance and Feature Interaction Detection Framework for Predictive Optimization in Industry 4.0 Applications](https://arxiv.org/abs/2403.02368) | 该论文提出了一个新型混合框架，结合特征重要性检测和特征交互检测，以提高工业4.0应用中的预测优化准确性。 |
| [^116] | [adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation](https://arxiv.org/abs/2403.02367) | adaptNMT是一个开源的神经机器翻译开发环境，简化了模型开发和部署流程，特别适用于新手用户，并提供图形展示、子词分割模型等功能。 |
| [^117] | [Human Evaluation of English--Irish Transformer-Based NMT](https://arxiv.org/abs/2403.02366) | 本研究评估了超参数设置对低资源英-爱变压器神经机器翻译质量的影响，并发现优化的Transformer模型在16k BPE子词模型下表现最佳，相较于基准RNN模型提高了7.8个BLEU分数，并在与谷歌翻译的比较中展示出显著的改进。 |
| [^118] | [Addressing Long-Tail Noisy Label Learning Problems: a Two-Stage Solution with Label Refurbishment Considering Label Rarity](https://arxiv.org/abs/2403.02363) | 提出了一种两阶段方法，通过软标签修复和多专家集成学习结合，解决了长尾嘈杂标签学习问题。 |
| [^119] | [Towards Optimal Customized Architecture for Heterogeneous Federated Learning with Contrastive Cloud-Edge Model Decoupling](https://arxiv.org/abs/2403.02360) | 通过对比云边模型解耦，提出了一种为异构联邦学习定制架构，该架构将深度神经网络分为捕获共享表示的主体和处理数据异构性的个性化头部，以优化联邦学习性能。 |
| [^120] | [Temporal Knowledge Graph Completion with Time-sensitive Relations in Hypercomplex Space](https://arxiv.org/abs/2403.02355) | 该论文提出在超复数空间中利用更具表现力的四元数表示进行时间知识图补全，着重捕捉时间敏感关系，并理论上验证了方法可以建模各种关系模式，实验表明该方法达到了最新的性能水平。 |
| [^121] | [Spatio-Temporal Field Neural Networks for Air Quality Inference](https://arxiv.org/abs/2403.02354) | 该研究提出了基于时空场神经网络的新模型和金字塔推断框架，在空气质量推断中取得了最先进的性能。 |
| [^122] | [ATP: Enabling Fast LLM Serving via Attention on Top Principal Keys](https://arxiv.org/abs/2403.02352) | 提出了一种新的注意机制ATP，通过关注顶级主要键而非每个标记，以实现对输入序列的快速处理，并能够在降低注意力复杂度的同时捕捉输入序列的语义关系。 |
| [^123] | [Entanglement: Balancing Punishment and Compensation, Repeated Dilemma Game-Theoretic Analysis of Maximum Compensation Problem for Bypass and Least Cost Paths in Fact-Checking, Case of Fake News with Weak Wallace's Law](https://arxiv.org/abs/2403.02342) | 通过研究最大补偿问题和惩罚优势问题，在信息传播中设计了一种策略来最大程度地减少虚假新闻传播并最大化可信信息传播，以重新评估新闻提供者的激励措施对信息市场平衡的影响。 |
| [^124] | [Neural Redshift: Random Networks are not Random Functions](https://arxiv.org/abs/2403.02241) | 本论文研究了未经训练的随机权重网络，发现即使简单的MLPs也具有强烈的归纳偏见，不同于传统观点的是，NNs并不具有固有的“简单偏见”，而是依赖于组件的作用。 |
| [^125] | [Cognition is All You Need - The Next Layer of AI Above Large Language Models](https://arxiv.org/abs/2403.02164) | 提出了认知人工智能，一个用于在大型语言模型之上实现以程序定义的神经符号认知的高级框架，为能够执行复杂多步知识工作的人工智能系统提供了路径。 |
| [^126] | [In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation](https://arxiv.org/abs/2403.01548) | 本研究从内部表征角度深入探讨了大型语言模型幻觉的机制，发现了幻觉的一个显著模式，即在上下文标记的隐藏状态中，正确生成具有更清晰的上下文激活。我们提出了一种基于熵的度量方法，将“锐度”纳入解码过程中，制定了一种受限解码方法，实验证明其在知识寻求和幻觉任务上的有效性。 |
| [^127] | [Leveraging Biomolecule and Natural Language through Multi-Modal Learning: A Survey](https://arxiv.org/abs/2403.01528) | 生物分子与自然语言相结合的多模态学习为全面表示和分析生物分子开辟了新途径。 |
| [^128] | [LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation](https://arxiv.org/abs/2403.01131) | LLaMoCo是第一个旨在以代码对代码方式调整LLMs以解决优化问题的指令调优框架，通过全面指令集和新颖的两阶段学习策略，实现了优越的性能。 |
| [^129] | [Seeing Unseen: Discover Novel Biomedical Concepts via GeometryConstrained Probabilistic Modeling](https://arxiv.org/abs/2403.01053) | 提出了一种通过几何限制概率建模处理方法来解决生物医学数据中存在的非 i.i.d. 数据分布、类别不平衡等问题。 |
| [^130] | [Resolution of Simpson's paradox via the common cause principle](https://arxiv.org/abs/2403.00957) | 通过对共同原因$C$进行条件设定，解决了辛普森悖论，推广了悖论，并表明在二元共同原因$C$上进行条件设定的关联方向与原始$B$上进行条件设定相同 |
| [^131] | [Improving Android Malware Detection Through Data Augmentation Using Wasserstein Generative Adversarial Networks](https://arxiv.org/abs/2403.00890) | 通过使用Wasserstein生成对抗网络生成的数据进行数据增强，该研究提出了一种利用卷积神经网络识别未知Android恶意软件应用程序的方法，并通过降低存储需求来改进Android恶意软件检测的效果。 |
| [^132] | [Text classification of column headers with a controlled vocabulary: leveraging LLMs for metadata enrichment](https://arxiv.org/abs/2403.00884) | 通过利用LLMs，我们提出了一种方法，使用ChatGPT-3.5、GoogleBard和GoogleGemini对列标题进行主题注释的元数据丰富化，研究它们在对领域特定主题进行分类的能力，并评估其内部一致性、机器对齐性和人机一致性。ChatGPT和GoogleGemini在内部一致性以及与人一致性方面优于GoogleBard。 |
| [^133] | [Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes](https://arxiv.org/abs/2403.00867) | 本文提出了一种名为Gradient Cuff的方法，通过探索拒绝损失地形图来检测对大语言模型的越狱攻击，成功设计了一种有效的两步检测策略。 |
| [^134] | [CLLMs: Consistency Large Language Models](https://arxiv.org/abs/2403.00835) | 提出了一种新方法，通过精细调整目标LLM实现了对雅各比轨迹上固定点的一致性预测，有效提高了生成速度2.4倍到3.4倍。 |
| [^135] | [Self-Retrieval: Building an Information Retrieval System with One Large Language Model](https://arxiv.org/abs/2403.00801) | 提出了自主检索(Self-Retrieval)，利用一个大型语言模型完全内化信息检索系统的能力，深度利用大型语言模型在信息检索过程中的能力。 |
| [^136] | [Know your exceptions: Towards an Ontology of Exceptions in Knowledge Representation](https://arxiv.org/abs/2403.00685) | 提出了基于异常性和可辩识性的框架，用于比较形式化体系并揭示其本体论承诺，应用框架比较了四个系统，展示了从本体论角度可能发生的差异。 |
| [^137] | [Metamorpheus: Interactive, Affective, and Creative Dream Narration Through Metaphorical Visual Storytelling](https://arxiv.org/abs/2403.00632) | 本研究提出了Metamorpheus，一种情感接口，通过创造性的视觉叙事来参与用户在梦境中的情感经历，利用生成式人工智能生成视觉隐喻和文本描绘，促使自我反思。 |
| [^138] | [GraphPub: Generation of Differential Privacy Graph with High Availability](https://arxiv.org/abs/2403.00030) | 提出了一种名为GraphPub的新型图边保护框架，通过反向学习和编码器-解码器机制，在保护图拓扑结构的同时保证数据的可用性基本不变。 |
| [^139] | [Improving Legal Judgement Prediction in Romanian with Long Text Encoders](https://arxiv.org/abs/2402.19170) | 本研究关注通过扩展Transformer模型的序列长度来更好理解法律语料库中的长文档，并在罗马尼亚的4个LJP数据集上进行了广泛实验。 |
| [^140] | [FedUV: Uniformity and Variance for Heterogeneous Federated Learning](https://arxiv.org/abs/2402.18372) | 提出了FedUV框架，通过引入两种正则化项，促使局部模型在异构分布数据中表现得更均匀和稳定 |
| [^141] | [BiVRec: Bidirectional View-based Multimodal Sequential Recommendation](https://arxiv.org/abs/2402.17334) | 提出了一个创新框架 BiVRec，在推荐任务中联合训练 ID 和多模态视图，双向增强推荐性能。 |
| [^142] | [Codebook-enabled Generative End-to-end Semantic Communication Powered by Transformer](https://arxiv.org/abs/2402.16868) | 本文提出了一个强大的码书辅助图像语义通信系统，通过联合构建语义编解码器和码书、设计向量-索引变换器来实现图像生成，并且借助高质量码书帮助Transformer，提高系统对抗信道噪声的鲁棒性。 |
| [^143] | [GraphEdit: Large Language Models for Graph Structure Learning](https://arxiv.org/abs/2402.15183) | 本研究提出了一种名为GraphEdit的方法，利用大型语言模型（LLMs）学习复杂的图结构化数据中的节点关系，通过在图结构上进行指导调整，增强LLMs的推理能力，从而提高图结构学习的可靠性。 |
| [^144] | [Recursive Speculative Decoding: Accelerating LLM Inference via Sampling Without Replacement](https://arxiv.org/abs/2402.14160) | 提出了递归推测解码(RSD)方法，通过无重复抽样最大化树的多样性，从而进一步加速LLM推理过程。 |
| [^145] | [Neural Control System for Continuous Glucose Monitoring and Maintenance](https://arxiv.org/abs/2402.13852) | 引入了一种新颖的神经控制系统，用于连续葡萄糖监测和维护，实时动态调整胰岛素输送，增强葡萄糖优化，最大化效率并确保个性化护理。 |
| [^146] | [PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images](https://arxiv.org/abs/2402.12721) | 提出了一个新颖的神经网络模型 PAC-FNO，通过在频域操作可以处理不同分辨率的图像，解决了传统方法在处理这类问题上的计算成本高的挑战。 |
| [^147] | [Mafin: Enhancing Black-Box Embeddings with Model Augmented Fine-tuning](https://arxiv.org/abs/2402.12177) | Mafin通过引入模型增强微调的方法，能够在只有黑盒嵌入可用的情况下显著提高性能。 |
| [^148] | [ASGEA: Exploiting Logic Rules from Align-Subgraphs for Entity Alignment](https://arxiv.org/abs/2402.11000) | 提出了一个新的实体对齐框架ASGEA，利用Align-Subgraphs中的逻辑规则，设计了可解释的基于路径的图神经网络ASGNN，引入了多模态注意机制，取得了令人满意的实验结果 |
| [^149] | [Exploring Neuron Interactions and Emergence in LLMs: From the Multifractal Analysis Perspective](https://arxiv.org/abs/2402.09099) | 该论文通过多重分形分析视角，深入研究了LLMs中神经元相互作用和出现现象。通过引入自组织和多重分形分析的概念，研究了神经元相互作用的动态演化过程，尤其关注训练中的复杂行为。通过提出基于神经元的多重分形分析方法，实现了对大型模型中神经元相互作用的定量分析。 |
| [^150] | [Entropy-Regularized Token-Level Policy Optimization for Large Language Models](https://arxiv.org/abs/2402.06700) | 本文提出了一种熵正则化的令牌级策略优化方法（ETPO），用于优化大规模语言模型（LLMs）。该方法能够通过直接与任务特定环境进行交互，并解决在如何分配令牌级学分和最大化奖励之间的冲突问题。 |
| [^151] | [The VampPrior Mixture Model](https://arxiv.org/abs/2402.04412) | 本论文提出了VampPrior混合模型（VMM），它是一种新颖的DLVM先验，可用于深度潜变量模型的集成和聚类，通过改善当前聚类先验的不足，并提出了一个清晰区分变分和先验参数的推理过程。使用VMM的变分自动编码器在基准数据集上取得了强大的聚类性能，将VMM与scVI相结合可以显著提高其性能，并自动将细胞分组为具有生物意义的聚类。 |
| [^152] | [LLMLight: Large Language Models as Traffic Signal Control Agents](https://arxiv.org/abs/2312.16044) | LLMLight是一个采用大型语言模型作为交通信号控制代理的新框架，通过借助先进的泛化能力和类似人类直觉的推理和决策过程，实现了有效的交通控制。此外，通过构建专为TSC任务定制的骨干语言模型LightGPT，进一步提升了LLMLight的效果和性能。 |
| [^153] | [Can It Edit? Evaluating the Ability of Large Language Models to Follow Code Editing Instructions](https://arxiv.org/abs/2312.12450) | 该研究评估了大型语言模型遵循代码编辑指令的能力，在指令式代码编辑任务上发现了开放和封闭模型之间的显著差距。 |
| [^154] | [RDR: the Recap, Deliberate, and Respond Method for Enhanced Language Understanding](https://arxiv.org/abs/2312.09932) | RDR方法提出了通过回顾、审慎和回应三个目标来增强语言理解的神经网络管道，解决了神经模型操纵NLU基准测试的问题 |
| [^155] | [Mitigating Biases with Diverse Ensembles and Diffusion Models](https://arxiv.org/abs/2311.16176) | 通过利用扩散概率模型（DPMs）生成新特征组合的图像，可以在集成模型中增加模型多样性，并减轻捷径偏见，而无需额外监督信号。 |
| [^156] | [Identification for Tree-shaped Structural Causal Models in Polynomial Time](https://arxiv.org/abs/2311.14058) | 本文提出了一个随机化多项式时间算法，用于解决树状结构因果模型的识别问题，是对传统Gröbner基础方法的显著改进。 |
| [^157] | [Can LLMs Fix Issues with Reasoning Models? Towards More Likely Models for AI Planning](https://arxiv.org/abs/2311.13720) | 这项研究探索了将大型语言模型（LLMs）用于自动规划任务中的模型空间编辑，并展示了LLMs在模型空间推理中的性能与传统组合搜索方法的对比，为未来更深入研究LLMs在规划任务中的应用提供了有希望的结果。 |
| [^158] | [On Leakage in Machine Learning Pipelines](https://arxiv.org/abs/2311.04179) | 本论文旨在扩展对设计、实施和评估机器学习管道时导致信息泄漏的原因的理解，通过具体示例提供了各种可能在机器学习管道中出现的泄漏的全面概述和讨论。 |
| [^159] | [Sequence-Level Certainty Reduces Hallucination In Knowledge-Grounded Dialogue Generation](https://arxiv.org/abs/2310.18794) | 序列级确定性是减少基于知识的对话生成中幻觉的关键，这项工作提出了基于概率确定性和语义确定性的序列级确定性，结果表明更高水平的确定性对应更低水平的幻觉，进一步提出了基于确定性的响应排序方法 |
| [^160] | [Evaluating Spatial Understanding of Large Language Models](https://arxiv.org/abs/2310.14540) | 本研究评估了大型语言模型对空间结构的理解能力，发现LLMs在表示和推理空间结构时的表现存在显著差异，具有捕捉空间结构隐含特征的潜力。 |
| [^161] | [A Safe Deep Reinforcement Learning Approach for Energy Efficient Federated Learning in Wireless Communication Networks](https://arxiv.org/abs/2308.10664) | 提出一种新的安全深度强化学习方法，利用惩罚函数在训练时惩罚违反环境约束的策略，以确保无线通信网络中能源高效联邦学习的总能耗最小化。 |
| [^162] | [Machine Unlearning: Solutions and Challenges](https://arxiv.org/abs/2308.07061) | 本文提供了对机器遗忘解决方案的全面分类和分析，明确了完全遗忘方法和近似遗忘方法，并讨论了它们的优势和局限性，提出了推进机器遗忘的未来方向。 |
| [^163] | [Fast Training of Diffusion Models with Masked Transformers](https://arxiv.org/abs/2306.09305) | 该论文提出了一种使用Masked Transformers快速训练扩散模型的方法，首次利用Masked training显著降低了模型的训练成本，并引入了不对称的编码器-解码器架构和辅助任务，以提升对全patches的长程理解。 |
| [^164] | [Agent-based Modeling and Simulation of Human Muscle For Development of Human Gait Analyzer Application](https://arxiv.org/abs/2212.12760) | 提出了一种基于代理的人体肌肉模型，用于计算步态周期中下半身的神经刺激，检测肌肉群的工作情况，并设计了Boots算法进行人体运动的逆动力学，最终开发出用户友好的应用程序。 |
| [^165] | [Directed Acyclic Graph Structure Learning from Dynamic Graphs](https://arxiv.org/abs/2211.17029) | 在动态图中，我们研究了节点特征生成机制的学习问题，通过同时估计节点特征之间的同时关系和时滞交互关系来构建有向无环图，有效地描述了特征生成过程 |
| [^166] | [Trust Your $\nabla$: Gradient-based Intervention Targeting for Causal Discovery](https://arxiv.org/abs/2211.13715) | 提出了一种基于梯度的干预目标定位方法，GIT，在因果发现中能够通过信号梯度估计器降低干预次数，在低数据量情况下优于竞争基线。 |
| [^167] | [Generalizing Graph Neural Networks on Out-Of-Distribution Graphs](https://arxiv.org/abs/2111.10657) | 提出了一个名为StableGNN的通用因果表示框架，通过提取高级图表示并利用因果推断的区分能力，帮助模型在分布外图上实现稳定的泛化能力。 |
| [^168] | [Counterfactual Effect Generalization: A Combinatorial Definition](https://arxiv.org/abs/2108.04376) | 提出了一种用于干预效应外部有效性的组合定义，揭示了效应概括的两个限制，并重新审视了原始反事实公式中的多个问题。 |
| [^169] | [Making deep neural networks right for the right scientific reasons by interacting with their explanations](https://arxiv.org/abs/2001.05371) | 通过“解释交互学习”(XIL)学习设置，研究者可以与深度神经网络进行交互，有助于避免其利用混淆因素而导致的高性能，同时增强对模型的信任。 |
| [^170] | [Augmenting Replay in World Models for Continual Reinforcement Learning.](http://arxiv.org/abs/2401.16650) | 本研究通过在回放缓冲区中应用增强方法，成功地解决了增强连续强化学习中的内存限制问题，并在世界模型中有效防止灾难性遗忘。 |
| [^171] | [Norm Enforcement with a Soft Touch: Faster Emergence, Happier Agents.](http://arxiv.org/abs/2401.16461) | 通过温和的规范执行，该研究提出了一种新的方法，通过智能体之间的交流推动合作并促进规范的出现。 |
| [^172] | [DevEval: Evaluating Code Generation in Practical Software Projects.](http://arxiv.org/abs/2401.06401) | 本文提出了一个名为DevEval的新基准测试，用于评估实际软件项目中的代码生成。与之前的基准测试相比，DevEval在真实的项目分布、充足的依赖和足够规模的项目背景等方面更贴合实际。通过对五个流行的大型语言模型进行评估，我们揭示了它们在代码生成中的实际能力。 |
| [^173] | [DiffDA: a diffusion model for weather-scale data assimilation.](http://arxiv.org/abs/2401.05932) | DiffDA是一种用于气象尺度数据同化的扩散模型，通过机器学习的方法将预测状态和稀疏观测同化，生成与观测一致的初始条件，并能对预测进行后处理到未来。 |
| [^174] | [Masked Audio Generation using a Single Non-Autoregressive Transformer.](http://arxiv.org/abs/2401.04577) | MAGNeT是一种遮蔽生成序列建模方法，使用单一非自回归Transformer生成具有高质量的音频，并引入了一种新颖的重新评分方法来提高生成音频的质量。同时，MAGNeT还探索了混合版本，可在自回归模式和非自回归模式下生成序列。在实验中证明MAGNeT在文本到音乐和文本到音频生成任务中具有高效性。 |
| [^175] | [A Generalized Neural Diffusion Framework on Graphs.](http://arxiv.org/abs/2312.08616) | 本文提出了一个通用的扩散方程框架，通过带有保真度项的方程，正式建立了GNN与扩散过程之间的关系。通过实验证明，该框架能够描述高阶邻居的标签相似性。 |
| [^176] | [Identifying Representations for Intervention Extrapolation.](http://arxiv.org/abs/2310.04295) | 本文研究了干预外推的任务，证明了可识别的表示方法能够有效地解决这个任务，即使干预对结果产生非线性影响。 |
| [^177] | [AXNav: Replaying Accessibility Tests from Natural Language.](http://arxiv.org/abs/2310.02424) | 这篇论文研究了一种从自然语言中重放无障碍测试的系统，该系统利用大型语言模型和基于像素的用户界面理解模型执行测试并生成可导航的视频。通过这种方式，开发人员和质量保证测试人员能够更高效地测试无障碍功能。 |
| [^178] | [A Prefrontal Cortex-inspired Architecture for Planning in Large Language Models.](http://arxiv.org/abs/2310.00194) | 这个论文提出了一个受前额叶皮层启发的大型语言模型规划架构，利用多个基于LLM的模块实现规划的自主协调，从而在处理需要多步推理或目标导向规划的任务时取得了较好的效果。 |
| [^179] | [SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning.](http://arxiv.org/abs/2309.04766) | SeaEval是一个评估多语言基础模型的基准测试，研究了模型在自然语言理解、推理以及对文化实践、细微差别和价值观的理解能力上的表现。重要发现包括模型在给出改写指令时行为各异，受到暴露偏差的影响，对于语义等价的多语言查询的回答不一致，以及模型在情感相关问题上的一致性不同。 |
| [^180] | [Large Language Models to Identify Social Determinants of Health in Electronic Health Records.](http://arxiv.org/abs/2308.06354) | 本研究利用大型语言模型从电子健康记录中提取社会健康决定因素（SDoH），并通过合成临床文本改进了这些极有价值但很少被记录的临床数据的提取。最佳模型为经过微调的Flan-T5 XL和Flan-T5 XXL，其中小型模型改进了性能。 |
| [^181] | [Exploring the psychology of GPT-4's Moral and Legal Reasoning.](http://arxiv.org/abs/2308.01264) | 本文探究了GPT-4的道德和法律推理，发现其与人类之间在意图归因、因果判断、欺骗的道德性、道德基础、道德运气对法律判断的影响、同意的概念以及规则违反判断方面存在高相关性。 |
| [^182] | [On the use of associative memory in Hopfield networks designed to solve propositional satisfiability problems.](http://arxiv.org/abs/2307.16807) | 该论文研究了在解决命题可满足性问题的Hopfield网络中使用关联记忆的方法。通过自我优化模型，网络可以解决具体的组合问题。然而，研究还发现在某些情况下，关键信息可能会永久丢失，导致网络产生看似最优但实际上不适用的解决方案。这一发现对理解网络解决难以处理问题的过程很有启发。 |
| [^183] | [Nonparametric Linear Feature Learning in Regression Through Regularisation.](http://arxiv.org/abs/2307.12754) | 本研究提出了一种新的非参数线性特征学习方法，对于监督学习中存在于低维线性子空间中的相关信息的预测和解释能力的提升是非常有帮助的。 |
| [^184] | [DRAGON: A Dialogue-Based Robot for Assistive Navigation with Visual Language Grounding.](http://arxiv.org/abs/2307.06924) | DRAGON是一种基于对话的导航机器人，能够理解用户的指令并通过语言与用户沟通，为视力受损者提供导航和环境描述的帮助。 |
| [^185] | [Towards Personalized Cold-Start Recommendation with Prompts.](http://arxiv.org/abs/2306.17256) | 本研究旨在解决个性化冷启动推荐问题，通过利用预训练语言模型的能力，将推荐过程转化为自然语言情感分析，提供适用于创业企业和用户参与历史不足的平台的个性化推荐。 |
| [^186] | [Soft-prompt Tuning for Large Language Models to Evaluate Bias.](http://arxiv.org/abs/2306.04735) | 本文使用软提示调整来量化大型语言模型中的偏差，避免手动设计提示导致的人为偏差注入。通过分组公平性检查模型对不同敏感属性的偏见，发现了有趣的偏差模式。 |
| [^187] | [Multiscale Positive-Unlabeled Detection of AI-Generated Texts.](http://arxiv.org/abs/2305.18149) | 本文提出了一种多尺度正负样本的训练框架，以解决多尺度AI生成文本的检测问题。通过将短机器文本标记为“未标记”来重新表述文本分类问题，并提出了一个规则化损失函数来优化检测性能，有效性能显著优于现有的方法。 |
| [^188] | [Fine-tuning Language Models with Generative Adversarial Feedback.](http://arxiv.org/abs/2305.06176) | 本研究探讨了一种新的方法，使用生成对抗反馈的强化学习(RLGAF)对大型语言模型进行微调，以取代仅受人类反馈的强化学习(RLHF)，从而消除评估者的专业限制并提高性能。 |
| [^189] | [Game-based Platforms for Artificial Intelligence Research.](http://arxiv.org/abs/2304.13269) | 本文回顾了基于游戏的人工智能研究平台，讨论了不同研究领域和创意设计在其中的应用和发展，并探讨了其未来趋势。 |
| [^190] | [Partially Observable Mean Field Multi-Agent Reinforcement Learning Based on Graph-Attention.](http://arxiv.org/abs/2304.12653) | 本文提出了一种新的基于图注意力的部分可观察均场多智能体强化学习算法，使用图注意力来捕获周围邻居智能体的特征信息，可以提高大规模多智能体环境中部分可观察MARL的性能。 |
| [^191] | [A Review on Longitudinal Car-Following Model.](http://arxiv.org/abs/2304.07143) | 这篇论文综述了逐车跟驰模型的不同原则和分类，以及面临的挑战和局限性。 |
| [^192] | [Personalised Language Modelling of Screen Characters Using Rich Metadata Annotations.](http://arxiv.org/abs/2303.16618) | 本篇论文研究了如何使用丰富的元数据注释的信息进行屏幕角色的个性化语言建模，测试表明这样可以有效地进行个性化语言模型的构建，即使对于零样本的演说家也可以应用。 |
| [^193] | [Adaptive Background Music for a Fighting Game: A Multi-Instrument Volume Modulation Approach.](http://arxiv.org/abs/2303.15734) | 本文介绍了一种自适应背景音乐的方法，它由五种不同的乐器演奏名为“空中小姐曲”的古典音乐组成，并通过改变乐器的音量来适应游戏的不同元素。实验结果表明，使用这种自适应背景音乐可以改善游戏的体验。 |
| [^194] | [Rethinking Symbolic Regression Datasets and Benchmarks for Scientific Discovery.](http://arxiv.org/abs/2206.10540) | 本文重新审视并重新创建了符号回归数据集，以评估符号回归在科学发现中的潜力和能力，并提出使用归一化编辑距离进行度量。 |
| [^195] | [AutoGL: A Library for Automated Graph Learning.](http://arxiv.org/abs/2104.04987) | AutoGL是第一个专门用于自动图机器学习的开源库，使用方便且易于扩展。它提供了一个完整的自动图学习流程，并支持各种图应用。 |

# 详细

[^1]: WMDP基准：通过遗忘测量和减少恶意使用

    The WMDP Benchmark: Measuring and Reducing Malicious Use With Unlearning

    [https://arxiv.org/abs/2403.03218](https://arxiv.org/abs/2403.03218)

    WMDP基准是一个公开发布的数据集，包含4157个多项选择问题，用作生物安全、网络安全和化学安全危险知识的代理测量。

    

    arXiv:2403.03218v1 公告类型：交叉领域 摘要：白宫关于人工智能的行政命令强调了大型语言模型(LLMs)赋予恶意行为者开发生物、网络和化学武器的风险。为了衡量这些恶意使用的风险，政府机构和主要人工智能实验室正在开发LLMs的危险能力评估。然而，当前的评估是私人的，阻碍了进一步研究如何减少风险。此外，它们仅专注于几条高度特定的恶意使用途径。为了填补这些空白，我们公开发布了大规模杀伤性武器代理（WMDP）基准，这是一个包含4157个多项选择问题的数据集，作为生物安全、网络安全和化学安全危险知识的代理测量。WMDP由一组学术界和技术顾问联合开发，并在公开发布前严格过滤以消除敏感信息。WMDP有两个服务

    arXiv:2403.03218v1 Announce Type: cross  Abstract: The White House Executive Order on Artificial Intelligence highlights the risks of large language models (LLMs) empowering malicious actors in developing biological, cyber, and chemical weapons. To measure these risks of malicious use, government institutions and major AI labs are developing evaluations for hazardous capabilities in LLMs. However, current evaluations are private, preventing further research into mitigating risk. Furthermore, they focus on only a few, highly specific pathways for malicious use. To fill these gaps, we publicly release the Weapons of Mass Destruction Proxy (WMDP) benchmark, a dataset of 4,157 multiple-choice questions that serve as a proxy measurement of hazardous knowledge in biosecurity, cybersecurity, and chemical security. WMDP was developed by a consortium of academics and technical consultants, and was stringently filtered to eliminate sensitive information prior to public release. WMDP serves two r
    
[^2]: CLEVR-POC：部分可观测环境中理性密集型视觉问答

    CLEVR-POC: Reasoning-Intensive Visual Question Answering in Partially Observable Environments

    [https://arxiv.org/abs/2403.03203](https://arxiv.org/abs/2403.03203)

    我们提出了一个名为CLEVR-POC的新型基准，用于在部分可观测环境中进行理性密集型视觉问答，需要利用逻辑约束的知识来生成可能的答案。

    

    人工智能领域对学习和推理的整合非常关注，但目前对利用现有背景知识来推理部分可观测场景以回答关于场景的问题还缺乏研究。我们人类经常利用这种知识来推断视觉问题的合理答案，这种知识通常以对象约束的形式存在，并且往往高度特定于领域或环境。本文提出了一个名为CLEVR-POC的新型基准，用于在受约束的部分可观测环境中进行理性密集型视觉问答（VQA）。在CLEVR-POC中，需要利用逻辑约束的知识来生成关于给定局部场景中隐藏对象的问题的合理答案。例如，如果某人知道所有杯子要么被涂成红色、绿色或蓝色，并且有o

    arXiv:2403.03203v1 Announce Type: new  Abstract: The integration of learning and reasoning is high on the research agenda in AI. Nevertheless, there is only a little attention to use existing background knowledge for reasoning about partially observed scenes to answer questions about the scene. Yet, we as humans use such knowledge frequently to infer plausible answers to visual questions (by eliminating all inconsistent ones). Such knowledge often comes in the form of constraints about objects and it tends to be highly domain or environment-specific. We contribute a novel benchmark called CLEVR-POC for reasoning-intensive visual question answering (VQA) in partially observable environments under constraints. In CLEVR-POC, knowledge in the form of logical constraints needs to be leveraged to generate plausible answers to questions about a hidden object in a given partial scene. For instance, if one has the knowledge that all cups are colored either red, green or blue and that there is o
    
[^3]: 达成民主化洪水风险管理：基于GPT-4的先进AI助手实现增强的可解释性和公众参与度

    Towards Democratized Flood Risk Management: An Advanced AI Assistant Enabled by GPT-4 for Enhanced Interpretability and Public Engagement

    [https://arxiv.org/abs/2403.03188](https://arxiv.org/abs/2403.03188)

    引入基于GPT-4的定制AI助手，旨在促进决策者、普通公众和洪水预报员之间的有效沟通，提升可解释性和公众参与度。

    

    实时洪水预测在促进及时有效的应急响应方面起着至关重要的作用。然而，一个重大挑战在于弥合复杂数字洪水模型与实际决策之间的差距。决策者经常依赖专家解释这些模型，以优化洪水减灾策略。公众需要复杂的技术来调查和理解社会文化和制度因素，这经常阻碍了公众对洪水风险的理解。为了克服这些挑战，我们的研究引入了一项创新解决方案：由GPT-4大型语言模型支持的定制AI助手。这个AI助手旨在促进决策者、普通公众和洪水预报员之间的有效沟通，而无需专业知识。这一新框架利用了GPT-4先进的自然语言理解和函数调用能力来实现这一目标。

    arXiv:2403.03188v1 Announce Type: new  Abstract: Real-time flood forecasting plays a crucial role in enabling timely and effective emergency responses. However, a significant challenge lies in bridging the gap between complex numerical flood models and practical decision-making. Decision-makers often rely on experts to interpret these models for optimizing flood mitigation strategies. And the public requires complex techniques to inquiry and understand socio-cultural and institutional factors, often hinders the public's understanding of flood risks. To overcome these challenges, our study introduces an innovative solution: a customized AI Assistant powered by the GPT-4 Large Language Model. This AI Assistant is designed to facilitate effective communication between decision-makers, the general public, and flood forecasters, without the requirement of specialized knowledge. The new framework utilizes GPT-4's advanced natural language understanding and function calling capabilities to pr
    
[^4]: 具有检索功能的可靠、适应性强且可追溯的语言模型

    Reliable, Adaptable, and Attributable Language Models with Retrieval

    [https://arxiv.org/abs/2403.03187](https://arxiv.org/abs/2403.03187)

    持续面临挑战的参数化语言模型LMs，作者主张使用具有检索功能的LMs作为下一代LMs，以提高可靠性、适应性和可追溯性。

    

    参数化语言模型（LMs）在海量网络数据上训练，表现出卓越的灵活性和能力。然而，它们仍然面临着幻觉、难以适应新数据分布和缺乏可验证性等实际挑战。在这篇立场论文中，我们主张用具备检索功能的LMs取代参数化LMs作为下一代LMs。通过在推理过程中整合大规模数据存储，具有检索功能的LMs可以更加可靠、适应性更强、可追溯。

    arXiv:2403.03187v1 Announce Type: cross  Abstract: Parametric language models (LMs), which are trained on vast amounts of web data, exhibit remarkable flexibility and capability. However, they still face practical challenges such as hallucinations, difficulty in adapting to new data distributions, and a lack of verifiability. In this position paper, we advocate for retrieval-augmented LMs to replace parametric LMs as the next generation of LMs. By incorporating large-scale datastores during inference, retrieval-augmented LMs can be more reliable, adaptable, and attributable. Despite their potential, retrieval-augmented LMs have yet to be widely adopted due to several obstacles: specifically, current retrieval-augmented LMs struggle to leverage helpful text beyond knowledge-intensive tasks such as question answering, have limited interaction between retrieval and LM components, and lack the infrastructure for scaling. To address these, we propose a roadmap for developing general-purpose
    
[^5]: 通往通用计算机控制：多模态代理在《荒野大镖客2》中的案例研究

    Towards General Computer Control: A Multimodal Agent for Red Dead Redemption II as a Case Study

    [https://arxiv.org/abs/2403.03186](https://arxiv.org/abs/2403.03186)

    提出了通用计算机控制（GCC）设置，通过基于屏幕图像和可能的音频输入的基金代理框架Cradle，实现了对《荒野大镖客2》中复杂任务的控制。

    

    最近的研究表明，基于基金的代理在特定任务或场景中取得了成功。然而，现有代理无法跨不同场景泛化，主要是由于它们多样化的观察和行动空间以及语义差距，或依赖于特定任务的资源。在这项工作中，我们提出了通用计算机控制（GCC）设置：通过仅获取计算机的屏幕图像（以及可能的音频）作为输入，并产生键盘和鼠标操作作为输出，类似于人机交互，构建可以精通任何计算机任务的基金代理。为了针对GCC，我们提出了Cradle，一个代理框架，具有强大的推理能力，包括自我反思、任务推理和技能整理，以确保在各种任务中的泛化和自我改进。为了展示Cradle的能力，我们将其部署在复杂的AAA游戏《荒野大镖客2》中，作为通向G的初步尝试。

    arXiv:2403.03186v1 Announce Type: new  Abstract: Recent studies have demonstrated the success of foundation agents in specific tasks or scenarios. However, existing agents cannot generalize across different scenarios, mainly due to their diverse observation and action spaces and semantic gaps, or reliance on task-specific resources. In this work, we propose the General Computer Control (GCC) setting: building foundation agents that can master any computer task by taking only screen images (and possibly audio) of the computer as input, and producing keyboard and mouse operations as output, similar to human-computer interaction. To target GCC, we propose Cradle, an agent framework with strong reasoning abilities, including self-reflection, task inference, and skill curation, to ensure generalizability and self-improvement across various tasks. To demonstrate the capabilities of Cradle, we deploy it in the complex AAA game Red Dead Redemption II, serving as a preliminary attempt towards G
    
[^6]: 用占用度测量正则化防止奖励欺骗

    Preventing Reward Hacking with Occupancy Measure Regularization

    [https://arxiv.org/abs/2403.03185](https://arxiv.org/abs/2403.03185)

    用占用度测量正则化方法可以有效防止奖励欺骗，通过考虑代理与真实奖励之间大的状态占用度偏差来避免潜在的灾难后果。

    

    当代理根据一个“代理”奖励函数（可能是手动指定或学习的）表现出色，但相对于未知的真实奖励却表现糟糕时，就会发生奖励欺骗。由于确保代理和真实奖励之间良好对齐极为困难，预防奖励欺骗的一种方法是保守地优化代理。以往的研究特别关注于通过惩罚他们的行为分布之间的KL散度来强制让学习到的策略表现类似于“安全”策略。然而，行为分布的正则化并不总是有效，因为在单个状态下行为分布的微小变化可能导致潜在的灾难性后果，而较大的变化可能并不代表任何危险活动。我们的见解是，当奖励欺骗时，代理访问的状态与安全策略达到的状态截然不同，导致状态占用度的巨大偏差。

    arXiv:2403.03185v1 Announce Type: cross  Abstract: Reward hacking occurs when an agent performs very well with respect to a "proxy" reward function (which may be hand-specified or learned), but poorly with respect to the unknown true reward. Since ensuring good alignment between the proxy and true reward is extremely difficult, one approach to prevent reward hacking is optimizing the proxy conservatively. Prior work has particularly focused on enforcing the learned policy to behave similarly to a "safe" policy by penalizing the KL divergence between their action distributions (AD). However, AD regularization doesn't always work well since a small change in action distribution at a single state can lead to potentially calamitous outcomes, while large changes might not be indicative of any dangerous activity. Our insight is that when reward hacking, the agent visits drastically different states from those reached by the safe policy, causing large deviations in state occupancy measure (OM
    
[^7]: Transformers能多好地模拟 Newton 方法上下文中的表现？

    How Well Can Transformers Emulate In-context Newton's Method?

    [https://arxiv.org/abs/2403.03183](https://arxiv.org/abs/2403.03183)

    Transformers能够实现高阶优化算法，线性注意力Transformer可以在 logistic 回归任务中近似实现二阶优化算法，并展示即使是线性注意力的Transformer也可以实现矩阵求逆的牛顿迭代。

    

    基于Transformer的模型展示了显著的上下文学习能力，引发了对其基础机制的广泛研究。最近的研究表明，Transformers可以实现一阶优化算法进行上下文学习，甚至对于线性回归的情况，可以实现二阶优化算法。在这项工作中，我们研究了Transformer是否能够执行高阶优化方法，超越了线性回归的情况。我们确定具有ReLU层的线性注意力Transformer可以近似实现二阶优化算法，用于逻辑回归任务，并且仅使用对数到错误更多的层可以达到$\epsilon$误差。作为副产品，我们展示了即使是仅具有线性注意力的Transformer也可以在仅两层的情况下实现矩阵求逆的牛顿迭代的单步。这些结果表明了Transformer架构实现的潜力。

    arXiv:2403.03183v1 Announce Type: cross  Abstract: Transformer-based models have demonstrated remarkable in-context learning capabilities, prompting extensive research into its underlying mechanisms. Recent studies have suggested that Transformers can implement first-order optimization algorithms for in-context learning and even second order ones for the case of linear regression. In this work, we study whether Transformers can perform higher order optimization methods, beyond the case of linear regression. We establish that linear attention Transformers with ReLU layers can approximate second order optimization algorithms for the task of logistic regression and achieve $\epsilon$ error with only a logarithmic to the error more layers. As a by-product we demonstrate the ability of even linear attention-only Transformers in implementing a single step of Newton's iteration for matrix inversion with merely two layers. These results suggest the ability of the Transformer architecture to im
    
[^8]: 具有潜在动作的行为生成

    Behavior Generation with Latent Actions

    [https://arxiv.org/abs/2403.03181](https://arxiv.org/abs/2403.03181)

    这项工作介绍了一种名为矢量量化行为转换器（VQ-BeT）的多功能行为生成模型，通过对连续动作进行标记化处理多模态动作预测、条件生成和部分观察。

    

    从带标签的数据集中生成复杂行为的生成建模一直是决策制定中长期存在的问题。与语言或图像生成不同，决策制定需要建模动作 - 连续值向量，其在分布上是多模态的，可能来自未经筛选的来源，在顺序预测中生成误差可能会相互累积。最近一类称为行为转换器（BeT）的模型通过使用k-means聚类对动作进行离散化以捕捉不同模式来解决这个问题。然而，k-means在处理高维动作空间或长序列时存在困难，并且缺乏梯度信息，因此BeT在建模长距离动作时存在困难。在这项工作中，我们提出了一种名为矢量量化行为转换器（VQ-BeT）的多功能行为生成模型，用于处理多模态动作预测、条件生成和部分观察。VQ-BeT通过对连续动作进行标记化来增强BeT

    arXiv:2403.03181v1 Announce Type: cross  Abstract: Generative modeling of complex behaviors from labeled datasets has been a longstanding problem in decision making. Unlike language or image generation, decision making requires modeling actions - continuous-valued vectors that are multimodal in their distribution, potentially drawn from uncurated sources, where generation errors can compound in sequential prediction. A recent class of models called Behavior Transformers (BeT) addresses this by discretizing actions using k-means clustering to capture different modes. However, k-means struggles to scale for high-dimensional action spaces or long sequences, and lacks gradient information, and thus BeT suffers in modeling long-range actions. In this work, we present Vector-Quantized Behavior Transformer (VQ-BeT), a versatile model for behavior generation that handles multimodal action prediction, conditional generation, and partial observations. VQ-BeT augments BeT by tokenizing continuous
    
[^9]: 统一并认证高质量规划

    Unifying and Certifying Top-Quality Planning

    [https://arxiv.org/abs/2403.03176](https://arxiv.org/abs/2403.03176)

    现有的高质量规划定义可以统一为基于支配关系的一个定义，从而实现认证解决方案的高质量，并提出了有效认证各种高质量规划问题的方法，并且提出了一种新的转换来有效地认证无环高质量规划。

    

    实际场景中对规划工具的日益利用引发了对生成多个高质量计划的兴趣。因此，在短时间内引入了一系列涵盖顶级质量规划的计算问题，每个都有自己的定义。在这项工作中，我们展示了现有的定义可以统一为基于支配关系的一个定义。因此，不同的计算问题简单地对应于不同的支配关系。在给定统一定义的情况下，我们现在可以证明解决方案的高质量，利用现有的不可解性和最优性认证。我们展示了现有文献中发现的任务转换可用于有效认证各种高质量规划问题，并提出了一个新的转换来有效地认证无环高质量规划。

    arXiv:2403.03176v1 Announce Type: new  Abstract: The growing utilization of planning tools in practical scenarios has sparked an interest in generating multiple high-quality plans. Consequently, a range of computational problems under the general umbrella of top-quality planning were introduced over a short time period, each with its own definition. In this work, we show that the existing definitions can be unified into one, based on a dominance relation. The different computational problems, therefore, simply correspond to different dominance relations. Given the unified definition, we can now certify the top-quality of the solutions, leveraging existing certification of unsolvability and optimality. We show that task transformations found in the existing literature can be employed for the efficient certification of various top-quality planning problems and propose a novel transformation to efficiently certify loopless top-quality planning.
    
[^10]: MOKA：基于标记的视觉提示实现开放词汇的机器人操作

    MOKA: Open-Vocabulary Robotic Manipulation through Mark-Based Visual Prompting

    [https://arxiv.org/abs/2403.03174](https://arxiv.org/abs/2403.03174)

    MOKA方法利用视觉语言模型解决机器人操作任务，实现了开放词汇的机器人操作。

    

    开放词汇的泛化要求机器人系统执行涉及复杂和多样化环境以及任务目标的任务。本文提出了一种名为MOKA（Marking Open-vocabulary Keypoint Affordances）的方法，利用视觉语言模型（VLMs）来解决由自由形式语言描述指定的机器人操作任务。

    arXiv:2403.03174v1 Announce Type: cross  Abstract: Open-vocabulary generalization requires robotic systems to perform tasks involving complex and diverse environments and task goals. While the recent advances in vision language models (VLMs) present unprecedented opportunities to solve unseen problems, how to utilize their emergent capabilities to control robots in the physical world remains an open question. In this paper, we present MOKA (Marking Open-vocabulary Keypoint Affordances), an approach that employs VLMs to solve robotic manipulation tasks specified by free-form language descriptions. At the heart of our approach is a compact point-based representation of affordance and motion that bridges the VLM's predictions on RGB images and the robot's motions in the physical world. By prompting a VLM pre-trained on Internet-scale data, our approach predicts the affordances and generates the corresponding motions by leveraging the concept understanding and commonsense knowledge from br
    
[^11]: 使用目标想象在合作多智能体强化学习中实现共识

    Reaching Consensus in Cooperative Multi-Agent Reinforcement Learning with Goal Imagination

    [https://arxiv.org/abs/2403.03172](https://arxiv.org/abs/2403.03172)

    提出了一种基于模型的共识机制，使用多智能体目标想象框架引导智能体达成共识，从而提高合作多智能体强化学习的性能。

    

    达成一致意见对于多智能体协调至关重要。为了完成协作任务，智能体需要协调地选择最佳的联合动作，以最大化团队奖励。然而，当前的合作多智能体强化学习方法通常不明确考虑一致性，这可能导致协调问题。在本文中，我们提出了一种基于模型的共识机制，以明确协调多个智能体。提出的多智能体目标想象（MAGI）框架引导智能体通过想象出的共同目标达成一致。共同目标是一个具有高价值的可实现状态，通过从未来状态分布中采样获得。我们直接使用自我监督生成模型对此分布进行建模，从而缓解了模型方法中常用的多智能体多步骤策略展开引起的“维度灾难”问题。我们展示了这种高效的共识机制可以提高合作多智能体强化学习的性能。

    arXiv:2403.03172v1 Announce Type: new  Abstract: Reaching consensus is key to multi-agent coordination. To accomplish a cooperative task, agents need to coherently select optimal joint actions to maximize the team reward. However, current cooperative multi-agent reinforcement learning (MARL) methods usually do not explicitly take consensus into consideration, which may cause miscoordination problem. In this paper, we propose a model-based consensus mechanism to explicitly coordinate multiple agents. The proposed Multi-agent Goal Imagination (MAGI) framework guides agents to reach consensus with an Imagined common goal. The common goal is an achievable state with high value, which is obtained by sampling from the distribution of future states. We directly model this distribution with a self-supervised generative model, thus alleviating the "curse of dimensinality" problem induced by multi-agent multi-step policy rollout commonly used in model-based methods. We show that such efficient c
    
[^12]: SNIFFER: 可解释的跨文本信息误传检测的多模大语言模型

    SNIFFER: Multimodal Large Language Model for Explainable Out-of-Context Misinformation Detection

    [https://arxiv.org/abs/2403.03170](https://arxiv.org/abs/2403.03170)

    SNIFFER是一种专门为超出上下文误传检测和解释而设计的新型多模大语言模型，通过两阶段指导微调，在解释生成方面取得了突破。

    

    虚假信息是一个普遍的社会问题，由于潜在的高风险。超出上下文（OOC）的误传，即真实图像被伪造的文本再利用，是误导观众的最简单和最有效的方法之一。当前的方法侧重于评估图像-文本一致性，但缺乏说服力的解释来支持他们的判断，这对于揭示误传至关重要。虽然多模大语言模型（MLLMs）具有丰富的知识和内在的视觉推理和解释生成能力，但它们仍然缺乏理解和发现微妙的跨模态差异的复杂性。在本文中，我们介绍了SNIFFER，这是一种专门为OOC误传检测和解释而设计的新颖的多模大语言模型。SNIFFER在InstructBLIP上采用了两阶段的指导微调。第一阶段通过新闻领域实体与通用对象的模型概念对齐，

    arXiv:2403.03170v1 Announce Type: cross  Abstract: Misinformation is a prevalent societal issue due to its potential high risks. Out-of-context (OOC) misinformation, where authentic images are repurposed with false text, is one of the easiest and most effective ways to mislead audiences. Current methods focus on assessing image-text consistency but lack convincing explanations for their judgments, which is essential for debunking misinformation. While Multimodal Large Language Models (MLLMs) have rich knowledge and innate capability for visual reasoning and explanation generation, they still lack sophistication in understanding and discovering the subtle crossmodal differences. In this paper, we introduce SNIFFER, a novel multimodal large language model specifically engineered for OOC misinformation detection and explanation. SNIFFER employs two-stage instruction tuning on InstructBLIP. The first stage refines the model's concept alignment of generic objects with news-domain entities a
    
[^13]: 学习显式条件化稀疏变换

    Learning Explicitly Conditioned Sparsifying Transforms

    [https://arxiv.org/abs/2403.03168](https://arxiv.org/abs/2403.03168)

    该论文提出了一种新的稀疏变换模型，通过显式控制数据表示质量和条件数，有效地学习保证数据在稀疏域中具有良好表示的优化变换。

    

    在过去的几十年里，稀疏化变换已经成为一种广为人知的工具，用于在某些变换域中找到信号的结构稀疏表示。尽管像DCT和小波这样的经典变换很受欢迎，但最近在一系列论文中已经分析了学习保证数据在稀疏域中具有良好表示的最优变换。学习方块变换的条件数和表示能力通常是互补的关键特征，可能在给定的优化模型中不能明确控制。与现有文献中的方法不同，在我们的论文中，我们考虑了一种新的稀疏变换模型，该模型强制在学习变换的数据表示质量和条件数上进行显式控制。我们通过数值实验确认，我们的模型比最先进的模型具有更好的数值行为。

    arXiv:2403.03168v1 Announce Type: cross  Abstract: Sparsifying transforms became in the last decades widely known tools for finding structured sparse representations of signals in certain transform domains. Despite the popularity of classical transforms such as DCT and Wavelet, learning optimal transforms that guarantee good representations of data into the sparse domain has been recently analyzed in a series of papers. Typically, the conditioning number and representation ability are complementary key features of learning square transforms that may not be explicitly controlled in a given optimization model. Unlike the existing approaches from the literature, in our paper, we consider a new sparsifying transform model that enforces explicit control over the data representation quality and the condition number of the learned transforms. We confirm through numerical experiments that our model presents better numerical behavior than the state-of-the-art.
    
[^14]: 利用联邦学习和边缘计算实现云计算网络中的推荐系统

    Leveraging Federated Learning and Edge Computing for Recommendation Systems within Cloud Computing Networks

    [https://arxiv.org/abs/2403.03165](https://arxiv.org/abs/2403.03165)

    边缘智能结合了AI和边缘计算，利用联邦学习实现隐私保护的机器学习，在FL网络中提出分层联邦学习（HFL）框架以提高通信效率。

    

    为了实现人工智能（AI）的大规模高效部署，AI和边缘计算的结合产生了边缘智能，利用末端设备和边缘服务器的计算和通信能力来更接近数据生成地处理数据。边缘智能的关键技术之一是隐私保护的机器学习范式联邦学习（FL），使数据所有者能够在无需将原始数据传输至第三方服务器的情况下训练模型。然而，FL网络预计会涉及数千个异构分布式设备。因此，通信效率仍然是一个关键瓶颈。为了减少节点故障和设备退出，提出了一种分层联邦学习（HFL）框架，其中指定的集群领导者通过中间模型聚合来支持数据所有者。

    arXiv:2403.03165v1 Announce Type: new  Abstract: To enable large-scale and efficient deployment of artificial intelligence (AI), the combination of AI and edge computing has spawned Edge Intelligence, which leverages the computing and communication capabilities of end devices and edge servers to process data closer to where it is generated. A key technology for edge intelligence is the privacy-protecting machine learning paradigm known as Federated Learning (FL), which enables data owners to train models without having to transfer raw data to third-party servers. However, FL networks are expected to involve thousands of heterogeneous distributed devices. As a result, communication efficiency remains a key bottleneck. To reduce node failures and device exits, a Hierarchical Federated Learning (HFL) framework is proposed, where a designated cluster leader supports the data owner through intermediate model aggregation. Therefore, based on the improvement of edge server resource utilizatio
    
[^15]: 使用大型语言模型进行量子多体物理计算

    Quantum Many-Body Physics Calculations with Large Language Models

    [https://arxiv.org/abs/2403.03154](https://arxiv.org/abs/2403.03154)

    使用大型语言模型准确地执行理论物理研究论文中关键的Hartree-Fock方法计算。

    

    大型语言模型（LLMs）展示了在多个领域（包括数学和科学推理）执行复杂任务的前所未有能力。我们证明，通过精心设计的提示，LLMs可以准确地执行理论物理研究论文中的关键计算。我们专注于量子物理中广泛使用的近似方法：Hartree-Fock方法，该方法需要进行分析性的多步计算，导出近似哈密顿量和相应的自洽方程。为了使用LLMs进行计算，我们设计了多步提示模板，将分析计算拆分为标准步骤，并为问题特定信息留出占位符。我们评估了GPT-4在执行过去十年的15篇研究论文中的计算表现，结果表明，通过修正中间步骤，它可以正确地推导出最终的Hartree-Fock哈密顿量。

    arXiv:2403.03154v1 Announce Type: cross  Abstract: Large language models (LLMs) have demonstrated an unprecedented ability to perform complex tasks in multiple domains, including mathematical and scientific reasoning. We demonstrate that with carefully designed prompts, LLMs can accurately carry out key calculations in research papers in theoretical physics. We focus on a broadly used approximation method in quantum physics: the Hartree-Fock method, requiring an analytic multi-step calculation deriving approximate Hamiltonian and corresponding self-consistency equations. To carry out the calculations using LLMs, we design multi-step prompt templates that break down the analytic calculation into standardized steps with placeholders for problem-specific information. We evaluate GPT-4's performance in executing the calculation for 15 research papers from the past decade, demonstrating that, with correction of intermediate steps, it can correctly derive the final Hartree-Fock Hamiltonian i
    
[^16]: 复杂中的简单

    Simplicity in Complexity

    [https://arxiv.org/abs/2403.03134](https://arxiv.org/abs/2403.03134)

    本研究提出使用基于区段的图像表示来建模复杂性，与之前复杂的图像复杂性模型不同，这种方法既能泛化，又能为理论理解提供指导。

    

    视觉刺激的复杂性在许多认知现象中起着重要作用，包括注意力、参与度、易记性、时间感知和美学评价。然而，尽管其重要性，复杂性仍然知之甚少，讽刺的是，先前的图像复杂性模型相当复杂。早先的模型试图寻找手工制作的特征来解释复杂性，但这些特征通常是特定于数据集的，因此无法泛化。与此同时，最近的研究采用了深度神经网络来预测复杂性，但这些模型仍然难以解释，并且不指导对问题的理论理解。在本文中，我们提出使用基于区段的图像表示来建模复杂性。我们使用最先进的分割模型SAM和FC-CLIP，来量化图像中的多个粒度的区段数量，以及图像中的类别数量。

    arXiv:2403.03134v1 Announce Type: cross  Abstract: The complexity of visual stimuli plays an important role in many cognitive phenomena, including attention, engagement, memorability, time perception and aesthetic evaluation. Despite its importance, complexity is poorly understood and ironically, previous models of image complexity have been quite \textit{complex}. There have been many attempts to find handcrafted features that explain complexity, but these features are usually dataset specific, and hence fail to generalise. On the other hand, more recent work has employed deep neural networks to predict complexity, but these models remain difficult to interpret, and do not guide a theoretical understanding of the problem. Here we propose to model complexity using segment-based representations of images. We use state-of-the-art segmentation models, SAM and FC-CLIP, to quantify the number of segments at multiple granularities, and the number of classes in an image respectively. We find 
    
[^17]: 两阶段设施选址中的均衡与原子客户

    Equilibria in Two-Stage Facility Location with Atomic Clients

    [https://arxiv.org/abs/2403.03114](https://arxiv.org/abs/2403.03114)

    本文研究了竞争性设施选址的两阶段多代理系统，针对不可分割权重的客户提出了混合策略，展示了在给定设施布置时可能出现截然不同的客户均衡。

    

    我们将竞争性设施选址视为一个带有两种客户类型的两阶段多代理系统。对于具有加权客户的主机图，首先设施代理者战略性地选择开设设施的顶点。然后，客户战略性地选择在其邻域内的哪个开设设施消费。设施希望尽可能吸引更多客户权重，客户希望最小化所选设施上的拥挤。所有最近研究的此模型版本都假定客户可以战略性地分担他们的权重。我们考虑具有不可分割权重的客户，但允许混合策略。因此，客户可以在哪个设施消费上随机选择。除了对自然客户行为进行建模外，这种微妙的变化会产生 drast 剧烈的变化，例如，在给定设施布置时，可能出现截然不同的客户均衡。作为我们的主要结果，我们展示了纯子博弈完美

    arXiv:2403.03114v1 Announce Type: cross  Abstract: We consider competitive facility location as a two-stage multi-agent system with two types of clients. For a given host graph with weighted clients on the vertices, first facility agents strategically select vertices for opening their facilities. Then, the clients strategically select which of the opened facilities in their neighborhood to patronize. Facilities want to attract as much client weight as possible, clients want to minimize congestion on the chosen facility.   All recently studied versions of this model assume that clients can split their weight strategically. We consider clients with unsplittable weights, but allow mixed strategies. So clients may randomize over which facility to patronize. Besides modeling a natural client behavior, this subtle change yields drastic changes, e.g., for a given facility placement, qualitatively different client equilibria are possible.   As our main result, we show that pure subgame perfect
    
[^18]: 使用深度语义分割和新型离群点检测改进LiDAR里程计与地图制作

    Improved LiDAR Odometry and Mapping using Deep Semantic Segmentation and Novel Outliers Detection

    [https://arxiv.org/abs/2403.03111](https://arxiv.org/abs/2403.03111)

    提出了一个新颖的框架，利用深度学习模型产生的语义信息改进了LiDAR数据的点线匹配和点面匹配，从而实现更准确的运动估计。

    

    感知是实现智能自主导航的关键要素。理解周围环境的语义和准确的车辆姿态估计对于自动驾驶汽车和执行复杂任务的移动机器人等自主车辆至关重要。本文提出了一个新颖的框架，用于快速移动平台的实时LiDAR里程计与地图制作，基于LOAM架构。我们的框架利用深度学习模型产生的语义信息，改进了LiDAR扫描之间的点线匹配和点面匹配，并构建了环境的语义地图，从而利用LiDAR数据更准确地估计运动。我们观察到，在匹配过程中包含语义信息会引入一种新类型的离群匹配，匹配过程中出现了匹配情况

    arXiv:2403.03111v1 Announce Type: cross  Abstract: Perception is a key element for enabling intelligent autonomous navigation. Understanding the semantics of the surrounding environment and accurate vehicle pose estimation are essential capabilities for autonomous vehicles, including self-driving cars and mobile robots that perform complex tasks. Fast moving platforms like self-driving cars impose a hard challenge for localization and mapping algorithms. In this work, we propose a novel framework for real-time LiDAR odometry and mapping based on LOAM architecture for fast moving platforms. Our framework utilizes semantic information produced by a deep learning model to improve point-to-line and point-to-plane matching between LiDAR scans and build a semantic map of the environment, leading to more accurate motion estimation using LiDAR data. We observe that including semantic information in the matching process introduces a new type of outlier matches to the process, where matching occ
    
[^19]: “在对话中学习”：通过对话中学习实现无需预定义个人资料的个性化对话

    "In Dialogues We Learn": Towards Personalized Dialogue Without Pre-defined Profiles through In-Dialogue Learning

    [https://arxiv.org/abs/2403.03102](https://arxiv.org/abs/2403.03102)

    提出了一种In-Dialogue Learning框架，通过对话历史刻画个人设来完成个性化对话生成任务，无需预定义个人资料，并在实验证明其显著改进对话生成性能。

    

    个性化对话系统近年来备受关注，因其能够生成与不同人设一致的响应。然而，大多数现有方法依赖预定义的个人资料，这不仅耗时且劳动密集，还缺乏灵活性。我们提出了In-Dialogue Learning（IDL），一种微调框架，增强了预训练的大型语言模型利用对话历史来刻画个人设，以完成个性化对话生成任务，而无需预定义个人资料。我们在三个数据集上的实验表明，IDL带来了显著的改进，BLEU和ROUGE分数分别增加了高达200%和247%。此外，人工评估的结果进一步验证了我们提出方法的有效性。

    arXiv:2403.03102v1 Announce Type: cross  Abstract: Personalized dialogue systems have gained significant attention in recent years for their ability to generate responses in alignment with different personas. However, most existing approaches rely on pre-defined personal profiles, which are not only time-consuming and labor-intensive to create but also lack flexibility. We propose In-Dialogue Learning (IDL), a fine-tuning framework that enhances the ability of pre-trained large language models to leverage dialogue history to characterize persona for completing personalized dialogue generation tasks without pre-defined profiles. Our experiments on three datasets demonstrate that IDL brings substantial improvements, with BLEU and ROUGE scores increasing by up to 200% and 247%, respectively. Additionally, the results of human evaluations further validate the efficacy of our proposed method.
    
[^20]: KnowAgent: 知识增强规划用于基于LLM的Agent

    KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents

    [https://arxiv.org/abs/2403.03101](https://arxiv.org/abs/2403.03101)

    KnowAgent引入了显式动作知识，通过动作知识库和知识型自学习策略来增强LLM的规划能力，从而改善语言Agent的规划表现。

    

    大型语言模型(LLMs)在复杂推理任务中表现出巨大潜力，但在处理更复杂的挑战时仍有所不足，特别是与环境互动通过生成可执行动作时。这种不足主要来自于语言Agent中缺乏内置动作知识，导致在任务求解过程中无法有效引导规划轨迹，从而导致规划幻觉。为了解决这个问题，我们引入了KnowAgent，一种旨在通过整合显式动作知识来增强LLM规划能力的新方法。具体而言，KnowAgent采用了一个动作知识库和一个知识型自学习策略来限制规划过程中的行动路径，实现更合理的轨迹合成，进而提高语言Agent的计划性能。基于HotpotQA和ALFWorld的实验结果基于不同的主干模型。

    arXiv:2403.03101v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated great potential in complex reasoning tasks, yet they fall short when tackling more sophisticated challenges, especially when interacting with environments through generating executable actions. This inadequacy primarily stems from the lack of built-in action knowledge in language agents, which fails to effectively guide the planning trajectories during task solving and results in planning hallucination. To address this issue, we introduce KnowAgent, a novel approach designed to enhance the planning capabilities of LLMs by incorporating explicit action knowledge. Specifically, KnowAgent employs an action knowledge base and a knowledgeable self-learning strategy to constrain the action path during planning, enabling more reasonable trajectory synthesis, and thereby enhancing the planning performance of language agents. Experimental results on HotpotQA and ALFWorld based on various backbone m
    
[^21]: NaturalSpeech 3: 利用分解编解码器和扩散模型实现零-shot语音合成

    NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models

    [https://arxiv.org/abs/2403.03100](https://arxiv.org/abs/2403.03100)

    NaturalSpeech 3利用分解设计的扩散模型实现零-shot方式生成自然语音

    

    近期大规模文本到语音（TTS）模型取得了显著进展，然而在语音质量、相似度和韵律方面仍存在不足。鉴于语音复杂地包含各种属性（例如内容、韵律、音色和声学细节），给生成带来了重大挑战，一个自然的想法是将语音因子分解为代表不同属性的各个子空间，并单独生成它们。在此基础上，我们提出了NaturalSpeech 3，这是一个具有新颖的分解扩散模型的TTS系统，可以以零-shot方式生成自然语音。具体来说，1) 我们设计了一个具有分解向量量化（FVQ）的神经编解码器，将语音波形分解为内容、韵律、音色和声学细节的子空间；2) 我们提出了一个分解扩散模型，根据其相应的提示生成每个子空间中的属性。借助这种分解设计，NaturalSpeech 3能够ef

    arXiv:2403.03100v1 Announce Type: cross  Abstract: While recent large-scale text-to-speech (TTS) models have achieved significant progress, they still fall short in speech quality, similarity, and prosody. Considering speech intricately encompasses various attributes (e.g., content, prosody, timbre, and acoustic details) that pose significant challenges for generation, a natural idea is to factorize speech into individual subspaces representing different attributes and generate them individually. Motivated by it, we propose NaturalSpeech 3, a TTS system with novel factorized diffusion models to generate natural speech in a zero-shot way. Specifically, 1) we design a neural codec with factorized vector quantization (FVQ) to disentangle speech waveform into subspaces of content, prosody, timbre, and acoustic details; 2) we propose a factorized diffusion model to generate attributes in each subspace following its corresponding prompt. With this factorization design, NaturalSpeech 3 can ef
    
[^22]: VQSynergy: 利用矢量量化机制进行稳健的药物协同预测

    VQSynery: Robust Drug Synergy Prediction With Vector Quantization Mechanism

    [https://arxiv.org/abs/2403.03089](https://arxiv.org/abs/2403.03089)

    VQSynergy通过矢量量化机制以及其他创新技术提高了药物协同预测的精度和泛化能力，在处理高斯噪声条件下表现出色。

    

    近年来高通量筛选和计算创新的出现引领了一种更高效的探索药物相互作用方法学的转变。本研究提出了VQSynergy，这是一个采用了矢量量化（VQ）机制、与门控残差和量身定制的注意机制相结合的新颖框架，以增强药物协同预测的精度和泛化能力。我们的研究结果表明，在高斯噪声条件下，VQSynergy在鲁棒性方面超过了现有模型，突显了其在复杂且常常嘈杂的药物协同研究领域中的卓越表现和实用性。

    arXiv:2403.03089v1 Announce Type: cross  Abstract: The pursuit of optimizing cancer therapies is significantly advanced by the accurate prediction of drug synergy. Traditional methods, such as clinical trials, are reliable yet encumbered by extensive time and financial demands. The emergence of high-throughput screening and computational innovations has heralded a shift towards more efficient methodologies for exploring drug interactions. In this study, we present VQSynergy, a novel framework that employs the Vector Quantization (VQ) mechanism, integrated with gated residuals and a tailored attention mechanism, to enhance the precision and generalizability of drug synergy predictions. Our findings demonstrate that VQSynergy surpasses existing models in terms of robustness, particularly under Gaussian noise conditions, highlighting its superior performance and utility in the complex and often noisy domain of drug synergy research. This study underscores the potential of VQSynergy in rev
    
[^23]: 具有生成对抗元模型的召回导向的持续学习

    Recall-Oriented Continual Learning with Generative Adversarial Meta-Model

    [https://arxiv.org/abs/2403.03082](https://arxiv.org/abs/2403.03082)

    框架提出了召回导向的持续学习方法，通过生成对抗元模型(GAMM)在学习新任务时最大化过去知识的稳定性。

    

    稳定性-可塑性困境是持续学习中的主要挑战，因为它涉及在学习新任务的同时保持对以前任务性能的平衡。本文提出了召回导向的持续学习框架来解决这一挑战。灵感来自于人类大脑分离稳定性和可塑性机制的能力，我们的框架包括一个两级体系结构，其中推理网络有效地获取新知识，而生成网络在需要时回顾过去的知识。具体地，为了最大化过去知识的稳定性，我们研究了不同表示取决于知识复杂度，从而引入了增量学习任务特定参数而不是任务的输入数据样本的生成对抗元模型（GAMM）。通过实验证明，我们的框架不仅

    arXiv:2403.03082v1 Announce Type: cross  Abstract: The stability-plasticity dilemma is a major challenge in continual learning, as it involves balancing the conflicting objectives of maintaining performance on previous tasks while learning new tasks. In this paper, we propose the recall-oriented continual learning framework to address this challenge. Inspired by the human brain's ability to separate the mechanisms responsible for stability and plasticity, our framework consists of a two-level architecture where an inference network effectively acquires new knowledge and a generative network recalls past knowledge when necessary. In particular, to maximize the stability of past knowledge, we investigate the complexity of knowledge depending on different representations, and thereby introducing generative adversarial meta-model (GAMM) that incrementally learns task-specific parameters instead of input data samples of the task. Through our experiments, we show that our framework not only 
    
[^24]: 神经码本设计用于网络波束管理

    Neural Codebook Design for Network Beam Management

    [https://arxiv.org/abs/2403.03053](https://arxiv.org/abs/2403.03053)

    本文提出了一种端到端的学习码本设计算法，网络波束学习（NBL），能够优化码本以减少干扰并最大化性能，适用于大型混合阵列系统。

    

    获得准确及时的信道状态信息（CSI）是大型天线系统面临的根本挑战。移动系统如5G使用一个波束管理框架，将初始接入、波束成形、CSI获取和数据传输相结合。然而，由于它们之间的相互关系、不断变化的阵列大小以及特定于站点的信道和用户分布，这些阶段的码本设计具有挑战性。此外，波束管理通常集中在单扇区运营上，而忽视了总体网络和系统级别的优化。在本文中，我们提出了一种端到端的学习码本设计算法，网络波束学习（NBL），它捕捉和优化码本，以减少干扰，同时通过极大混合阵列最大化可实现的性能。所提出的算法需要有限的共享信息，却设计出优于传统码本的码本。

    arXiv:2403.03053v1 Announce Type: cross  Abstract: Obtaining accurate and timely channel state information (CSI) is a fundamental challenge for large antenna systems. Mobile systems like 5G use a beam management framework that joins the initial access, beamforming, CSI acquisition, and data transmission. The design of codebooks for these stages, however, is challenging due to their interrelationships, varying array sizes, and site-specific channel and user distributions. Furthermore, beam management is often focused on single-sector operations while ignoring the overarching network- and system-level optimization. In this paper, we proposed an end-to-end learned codebook design algorithm, network beamspace learning (NBL), that captures and optimizes codebooks to mitigate interference while maximizing the achievable performance with extremely large hybrid arrays. The proposed algorithm requires limited shared information yet designs codebooks that outperform traditional codebooks by over
    
[^25]: 统一控制器设计用于稳定具有范数有界控制输入的非线性系统

    Unifying Controller Design for Stabilizing Nonlinear Systems with Norm-Bounded Control Inputs

    [https://arxiv.org/abs/2403.03030](https://arxiv.org/abs/2403.03030)

    提出了一种统一的控制器设计方法，通过引入通用的缩放项，实现了针对非线性系统稳定控制器设计的通用性并生成了多种有利特性的备选通用公式。

    

    本文重新审视了设计非线性系统稳定控制器面临的经典挑战，通过扩展Lin-Sontag的通用公式并引入一种通用（依赖于状态）的缩放项，提出了一种统一的控制器设计方法。引入这种通用的缩放项给出了一个统一的控制器，并使得能够推导出具有各种有利特性的备选通用公式，使其适用于定制控制设计以满足特定要求，并提供跨不同控制场景的通用性。此外，我们提出了一种确定最优缩放项的构造方法，导致一个明确的解决方案，称为基于优化的通用公式的优化问题。得到的控制器确保渐近稳定性，满足范数有界的输入约束，并优化预定义的成本函数。

    arXiv:2403.03030v1 Announce Type: cross  Abstract: This paper revisits a classical challenge in the design of stabilizing controllers for nonlinear systems with a norm-bounded input constraint. By extending Lin-Sontag's universal formula and introducing a generic (state-dependent) scaling term, a unifying controller design method is proposed. The incorporation of this generic scaling term gives a unified controller and enables the derivation of alternative universal formulas with various favorable properties, which makes it suitable for tailored control designs to meet specific requirements and provides versatility across different control scenarios. Additionally, we present a constructive approach to determine the optimal scaling term, leading to an explicit solution to an optimization problem, named optimization-based universal formula. The resulting controller ensures asymptotic stability, satisfies a norm-bounded input constraint, and optimizes a predefined cost function. Finally, 
    
[^26]: 单词重要性解释了提示如何影响语言模型输出

    Word Importance Explains How Prompts Affect Language Model Outputs

    [https://arxiv.org/abs/2403.03028](https://arxiv.org/abs/2403.03028)

    通过改变提示中的单词，本研究提出了一种方法来解释大型语言模型（LLMs）的工作原理，从而揭示其对模型输出的影响。

    

    大型语言模型（LLMs）的出现彻底改变了各行各业的许多应用。然而，它们的“黑盒”性质常常阻碍了我们对其如何做出具体决策的理解，引发了人们对其透明性、可靠性和道德使用的担忧。本研究提出了一种方法，通过改变提示中的单词来提高LLMs的可解释性，以揭示其在模型输出上的统计影响。该方法受表格数据的排列重要性启发，屏蔽系统提示中的每个单词，并根据可用文本分数在多个用户输入上进行聚合来评估其对输出的影响。与传统注意力不同，单词重要性衡量提示中单词对任意定义的文本分数的影响，从而能够将单词的重要性分解为具体的感兴趣的度量-- 包括偏见、阅读水平、冗余等。此程序还使测量

    arXiv:2403.03028v1 Announce Type: new  Abstract: The emergence of large language models (LLMs) has revolutionized numerous applications across industries. However, their "black box" nature often hinders the understanding of how they make specific decisions, raising concerns about their transparency, reliability, and ethical use. This study presents a method to improve the explainability of LLMs by varying individual words in prompts to uncover their statistical impact on the model outputs. This approach, inspired by permutation importance for tabular data, masks each word in the system prompt and evaluates its effect on the outputs based on the available text scores aggregated over multiple user inputs. Unlike classical attention, word importance measures the impact of prompt words on arbitrarily-defined text scores, which enables decomposing the importance of words into the specific measures of interest--including bias, reading level, verbosity, etc. This procedure also enables measur
    
[^27]: SplAgger：用于元强化学习的分割聚合

    SplAgger: Split Aggregation for Meta-Reinforcement Learning

    [https://arxiv.org/abs/2403.03020](https://arxiv.org/abs/2403.03020)

    本文展示了任务推断序列模型在元强化学习中的益处。

    

    强化学习的一个核心目标是创建能快速学习新任务的智能体。元强化学习旨在通过直接学习这些智能体来实现这一目标。一类元强化学习方法被称为黑盒方法，通过端到端训练现成的序列模型来实现这一目标。与之形成对比的是另一类方法，它们明确地推断出未知任务的后验分布。这些方法通常具有不同的目标和序列模型，旨在实现任务推断，因此被称为任务推断方法。本文提出了强有力的证据，证明任务推断序列模型仍然具有益处。

    arXiv:2403.03020v1 Announce Type: cross  Abstract: A core ambition of reinforcement learning (RL) is the creation of agents capable of rapid learning in novel tasks. Meta-RL aims to achieve this by directly learning such agents. One category of meta-RL methods, called black box methods, does so by training off-the-shelf sequence models end-to-end. In contrast, another category of methods have been developed that explicitly infer a posterior distribution over the unknown task. These methods generally have distinct objectives and sequence models designed to enable task inference, and so are known as task inference methods. However, recent evidence suggests that task inference objectives are unnecessary in practice. Nonetheless, it remains unclear whether task inference sequence models are beneficial even when task inference objectives are not. In this paper, we present strong evidence that task inference sequence models are still beneficial. In particular, we investigate sequence models 
    
[^28]: OPEx:对基于LLM的坐标指导智能体进行组件级分析

    OPEx: A Component-Wise Analysis of LLM-Centric Agents in Embodied Instruction Following

    [https://arxiv.org/abs/2403.03017](https://arxiv.org/abs/2403.03017)

    OPEx框架提出了对解决嵌入式学习任务至关重要的核心组件-观察者、规划者和执行者，并通过深入评估分析了各组件对于嵌入式指导遵循任务性能的影响。

    

    嵌入式指导遵循(Embodied Instruction Following，EIF)是嵌入式学习中一个关键任务，要求智能体通过以自我为中心的观察与环境互动，以完成自然语言指令。最近的进展看到在以框架为中心的方法中广泛采用大型语言模型(LLMs)来增强在嵌入式学习任务中，包括EIF任务中的表现。尽管有这些努力，但目前缺乏有关各种组件(从视觉感知到动作执行)对任务性能影响的统一理解。为解决这一差距，我们介绍了OPEx，一个详尽的框架，详细说明了解决嵌入式学习任务所必需的核心组件:观察者(Observer)、规划者(Planner)和执行者(Executor)。通过广泛的评估，我们对每个组件如何影响EIF任务性能进行了深入分析。此外，在这一领域内，我们通过部署多智能体对话策略进行了创新。

    arXiv:2403.03017v1 Announce Type: new  Abstract: Embodied Instruction Following (EIF) is a crucial task in embodied learning, requiring agents to interact with their environment through egocentric observations to fulfill natural language instructions. Recent advancements have seen a surge in employing large language models (LLMs) within a framework-centric approach to enhance performance in embodied learning tasks, including EIF. Despite these efforts, there exists a lack of a unified understanding regarding the impact of various components-ranging from visual perception to action execution-on task performance. To address this gap, we introduce OPEx, a comprehensive framework that delineates the core components essential for solving embodied learning tasks: Observer, Planner, and Executor. Through extensive evaluations, we provide a deep analysis of how each component influences EIF task performance. Furthermore, we innovate within this space by deploying a multi-agent dialogue strateg
    
[^29]: 知识图谱作为基于LLM的学习推荐解释的上下文来源

    Knowledge Graphs as Context Sources for LLM-Based Explanations of Learning Recommendations

    [https://arxiv.org/abs/2403.03008](https://arxiv.org/abs/2403.03008)

    本文提出了一种利用知识图谱作为事实上下文的来源，为基于LLM的学习推荐提供解释，以降低模型幻觉风险，确保高精度，并保持学习上下文的方法。

    

    在个性化教育时代，为学习推荐提供易于理解的解释对于增强学习者对推荐学习内容的理解和参与至关重要。大型语言模型（LLMs）和生成式人工智能近期为生成类似人类的解释，为学习推荐开辟了新的可能性。然而，在敏感领域如教育中，它们的准确性仍远未达到可接受水平。为了利用LLMs的能力，同时确保对学习者意图的高精度，本文提出了一种方法，即利用知识图谱（KG）作为事实上下文的来源，用于LLM提示，降低模型幻觉的风险，防止错误或不准确的信息，并保持应用意图的学习上下文。我们利用知识图谱中的语义关系来提供相关性的上下文信息。

    arXiv:2403.03008v1 Announce Type: new  Abstract: In the era of personalized education, the provision of comprehensible explanations for learning recommendations is of a great value to enhance the learner's understanding and engagement with the recommended learning content. Large language models (LLMs) and generative AI in general have recently opened new doors for generating human-like explanations, for and along learning recommendations. However, their precision is still far away from acceptable in a sensitive field like education. To harness the abilities of LLMs, while still ensuring a high level of precision towards the intent of the learners, this paper proposes an approach to utilize knowledge graphs (KG) as a source of factual context, for LLM prompts, reducing the risk of model hallucinations, and safeguarding against wrong or imprecise information, while maintaining an application-intended learning context. We utilize the semantic relations in the knowledge graph to offer cura
    
[^30]: 基于Mem元件的神经形态硬件在神经网络应用中的应用

    Mem-elements based Neuromorphic Hardware for Neural Network Application

    [https://arxiv.org/abs/2403.03002](https://arxiv.org/abs/2403.03002)

    这项研究提出了利用记忆元件交叉阵列设计低功耗机器学习加速器的方法，并且成功实现了在CIFAR-10数据集上使用memristive和memcapacitive交叉阵列在8层VGG网络上实现出色训练准确度。

    

    这篇论文研究了在低功耗机器学习加速器中利用记忆电阻和记忆电容交叉阵列，提供了一个全面的深度神经网络（DNN）协同设计框架。该模型采用混合Python和PyTorch方法实现，考虑了各种非理想因素，在8层VGG网络上，使用记忆电阻和记忆电容交叉阵列对CIFAR-10数据集实现了出色的训练准确度，分别为90.02%和91.03%。此外，论文引入了一种使用运算跨导放大器（OTA）和电容器来模拟meminductor器件的新方法，展示了可调行为。在180纳米CMOS技术的晶体管级模拟中，以60 MHz运行，验证了提出的meminductor模拟器具有0.337 mW功耗的可行性。该设计进一步在神经形态电路和CNN加速器中验证，取得了训练和测试准确性。

    arXiv:2403.03002v1 Announce Type: cross  Abstract: The thesis investigates the utilization of memristive and memcapacitive crossbar arrays in low-power machine learning accelerators, offering a comprehensive co-design framework for deep neural networks (DNN). The model, implemented through a hybrid Python and PyTorch approach, accounts for various non-idealities, achieving exceptional training accuracies of 90.02% and 91.03% for the CIFAR-10 dataset with memristive and memcapacitive crossbar arrays on an 8-layer VGG network. Additionally, the thesis introduces a novel approach to emulate meminductor devices using Operational Transconductance Amplifiers (OTA) and capacitors, showcasing adjustable behavior. Transistor-level simulations in 180 nm CMOS technology, operating at 60 MHz, demonstrate the proposed meminductor emulator's viability with a power consumption of 0.337 mW. The design is further validated in neuromorphic circuits and CNN accelerators, achieving training and testing ac
    
[^31]: 使用集成树在恶意URL检测器中缓解标签翻转攻击

    Mitigating Label Flipping Attacks in Malicious URL Detectors Using Ensemble Trees

    [https://arxiv.org/abs/2403.02995](https://arxiv.org/abs/2403.02995)

    本研究旨在利用集成树来缓解恶意URL检测器中的标签翻转攻击，从而在机器学习模型中集成防御机制以防范潜在攻击。

    

    恶意URL提供了跨各行业（包括交通、医疗保健、能源和银行业）的对抗性机会，可能对业务运营造成重大损害。因此，检测这些URL的重要性不言而喻；然而，当前的机器学习（ML）模型容易受到后门攻击的影响。这些攻击涉及操纵少量训练数据标签，如标签翻转（LF），将良性标签更改为恶意标签，反之亦然。这种操纵导致误分类，并导致模型行为不正确。因此，在ML模型架构中集成防御机制成为加固潜在攻击的必要考虑因素。本研究关注在使用集成树进行URL检测背景下的后门攻击。通过阐明此类攻击背后的动机，突出攻击者的角色，并强调

    arXiv:2403.02995v1 Announce Type: cross  Abstract: Malicious URLs provide adversarial opportunities across various industries, including transportation, healthcare, energy, and banking which could be detrimental to business operations. Consequently, the detection of these URLs is of crucial importance; however, current Machine Learning (ML) models are susceptible to backdoor attacks. These attacks involve manipulating a small percentage of training data labels, such as Label Flipping (LF), which changes benign labels to malicious ones and vice versa. This manipulation results in misclassification and leads to incorrect model behavior. Therefore, integrating defense mechanisms into the architecture of ML models becomes an imperative consideration to fortify against potential attacks.   The focus of this study is on backdoor attacks in the context of URL detection using ensemble trees. By illuminating the motivations behind such attacks, highlighting the roles of attackers, and emphasizi
    
[^32]: 本地化的零阶提示优化

    Localized Zeroth-Order Prompt Optimization

    [https://arxiv.org/abs/2403.02993](https://arxiv.org/abs/2403.02993)

    提出了一种本地化的零阶提示优化方法，通过研究发现，局部最优解通常普遍存在且表现良好，有助于高效的提示优化。

    

    大型语言模型（LLMs）在理解和生成自然语言方面的有效性引起了广泛兴趣，促使人们开发了基于提示的方法来利用黑盒LLMs的能力。现有方法通常优先考虑全局优化以寻找全局最优解，然而在某些任务中表现不佳。这促使我们重新考虑提示优化中寻找全局最优解的必要性。为了回答这个问题，我们对提示优化进行了彻底的实证研究，并得出了两个主要见解。与全局最优解的罕见性形成对比，局部最优解通常普遍存在且表现良好，这对于高效的提示优化可能更具价值（见解I）。输入领域的选择，包括提示的生成和表示，影响了优化良好的局部最优解的识别（见解II）。受到这些见解的启发，我们提出了一种新颖的算法。

    arXiv:2403.02993v1 Announce Type: new  Abstract: The efficacy of large language models (LLMs) in understanding and generating natural language has aroused a wide interest in developing prompt-based methods to harness the power of black-box LLMs. Existing methodologies usually prioritize a global optimization for finding the global optimum, which however will perform poorly in certain tasks. This thus motivates us to re-think the necessity of finding a global optimum in prompt optimization. To answer this, we conduct a thorough empirical study on prompt optimization and draw two major insights. Contrasting with the rarity of global optimum, local optima are usually prevalent and well-performed, which can be more worthwhile for efficient prompt optimization (Insight I). The choice of the input domain, covering both the generation and the representation of prompts, affects the identification of well-performing local optima (Insight II). Inspired by these insights, we propose a novel algor
    
[^33]: 使用LLMs的数据增强：数据视角、学习范式和挑战

    Data Augmentation using LLMs: Data Perspectives, Learning Paradigms and Challenges

    [https://arxiv.org/abs/2403.02990](https://arxiv.org/abs/2403.02990)

    探讨了大型语言模型（LLMs）对数据增强的转变性影响，独特挑战和机遇，突出了LLMs在数据增强中引入的范式转变。

    

    在机器学习（ML）领域快速发展中，数据增强（DA）已成为一种关键技术，通过使训练样本多样化而无需额外数据收集来增强模型性能。本调查探讨了大型语言模型（LLMs）对数据增强的转变性影响，特别是在自然语言处理（NLP）领域及其他领域中它们提供的独特挑战和机遇。从数据视角和学习视角，我们研究了利用大型语言模型进行数据增强的各种策略，包括对LLM生成数据进行进一步训练的新颖学习范式的探索。此外，本文还阐明了该领域面临的主要挑战，从可控数据增强到多模态数据增强等。本调查突显了LLMs在数据增强中引入的范式转变，旨在作为一种...

    arXiv:2403.02990v1 Announce Type: cross  Abstract: In the rapidly evolving field of machine learning (ML), data augmentation (DA) has emerged as a pivotal technique for enhancing model performance by diversifying training examples without the need for additional data collection. This survey explores the transformative impact of Large Language Models (LLMs) on DA, particularly addressing the unique challenges and opportunities they present in the context of natural language processing (NLP) and beyond. From a data perspective and a learning perspective, we examine various strategies that utilize Large Language Models for data augmentation, including a novel exploration of learning paradigms where LLM-generated data is used for further training. Additionally, this paper delineates the primary challenges faced in this domain, ranging from controllable data augmentation to multi modal data augmentation. This survey highlights the paradigm shift introduced by LLMs in DA, aims to serve as a 
    
[^34]: 进化Transformer：上下文进化优化

    Evolution Transformer: In-Context Evolutionary Optimization

    [https://arxiv.org/abs/2403.02985](https://arxiv.org/abs/2403.02985)

    提出了一种Evolution Transformer架构，可以通过元优化直接发现强大的优化原则，达到改进搜索分布的目的。

    

    进化优化算法通常从宽泛的生物类比中衍生出来，在优化的连续过程中难以利用所获得的信息。另一种有前途的方法是利用数据，通过元优化直接发现强大的优化原则。在这项工作中，我们遵循这样的范式，引入了Evolution Transformer，一个因果Transformer架构，可以灵活地描述一类进化策略。给定评估轨迹和搜索分布统计数据，Evolution Transformer输出一个改进搜索分布的更新。该架构施加了一组适当的归纳偏差，即在一代中个体成员顺序不变的分布更新和对搜索维度顺序的等变性。我们使用进化算法蒸馏训练模型权重，这是一种技术。

    arXiv:2403.02985v1 Announce Type: new  Abstract: Evolutionary optimization algorithms are often derived from loose biological analogies and struggle to leverage information obtained during the sequential course of optimization. An alternative promising approach is to leverage data and directly discover powerful optimization principles via meta-optimization. In this work, we follow such a paradigm and introduce Evolution Transformer, a causal Transformer architecture, which can flexibly characterize a family of Evolution Strategies. Given a trajectory of evaluations and search distribution statistics, Evolution Transformer outputs a performance-improving update to the search distribution. The architecture imposes a set of suitable inductive biases, i.e. the invariance of the distribution update to the order of population members within a generation and equivariance to the order of the search dimensions. We train the model weights using Evolutionary Algorithm Distillation, a technique fo
    
[^35]: 受攻击的联邦学习：通过数据中毒攻击揭示在计算机网络中的漏洞

    Federated Learning Under Attack: Exposing Vulnerabilities through Data Poisoning Attacks in Computer Networks

    [https://arxiv.org/abs/2403.02983](https://arxiv.org/abs/2403.02983)

    该研究旨在探索计算机网络领域中数据中毒攻击的严重性，使用了两种类型的攻击：标签翻转和特征中毒，采用了新颖的方法。

    

    arXiv:2403.02983v1 公告类型: 跨领域  摘要: 联邦学习(FL)是一种机器学习(ML)方法，使多个分散的设备或边缘服务器协作训练共享模型，而无需交换原始数据。在客户端和服务器之间的训练和模型更新共享过程中，数据和模型容易受到不同的数据中毒攻击。在本研究中，我们旨在探讨计算机网络领域中数据中毒攻击的严重性，因为它们很容易实施但很难检测。我们考虑了两种类型的数据中毒攻击，即标签翻转(LF)和特征中毒(FP)，并采用了一种新颖的方法。在LF中，我们随机翻转了良性数据的标签，并在操纵后的数据上训练模型。对于FP，我们随机操纵了使用随机森林算法确定的高贡献特征。该实验使用的数据集为与计算机网络相关的CIC和UNSW数据集。

    arXiv:2403.02983v1 Announce Type: cross  Abstract: Federated Learning (FL) is a machine learning (ML) approach that enables multiple decentralized devices or edge servers to collaboratively train a shared model without exchanging raw data. During the training and sharing of model updates between clients and servers, data and models are susceptible to different data-poisoning attacks.   In this study, our motivation is to explore the severity of data poisoning attacks in the computer network domain because they are easy to implement but difficult to detect. We considered two types of data-poisoning attacks, label flipping (LF) and feature poisoning (FP), and applied them with a novel approach. In LF, we randomly flipped the labels of benign data and trained the model on the manipulated data. For FP, we randomly manipulated the highly contributing features determined using the Random Forest algorithm. The datasets used in this experiment were CIC and UNSW related to computer networks. We
    
[^36]: 一个通用灵活的多概念解析框架用于多语言语义匹配

    A General and Flexible Multi-concept Parsing Framework for Multilingual Semantic Matching

    [https://arxiv.org/abs/2403.02975](https://arxiv.org/abs/2403.02975)

    提出一个通用灵活的多概念解析框架用于多语言语义匹配，以解决关键词和意图概念识别以及外部NER依赖的问题

    

    句子语义匹配是自然语言处理中的研究热点，在社区问答、搜索、聊天机器人和推荐等各种重要场景中具有相当重要的意义。本文提出了DC-Match来解开句子中的关键词和意图概念，并利用它们来优化匹配性能，以解决现有先进模型直接模拟两个句子之间单词的语义相关性而忽略关键词和意图概念的问题。尽管DC-Match是一个简单而有效的语义匹配方法，但它高度依赖外部NER技术来识别句子的关键词，这限制了对次要语言的语义匹配性能，因为通常很难获得令人满意的NER工具。

    arXiv:2403.02975v1 Announce Type: cross  Abstract: Sentence semantic matching is a research hotspot in natural language processing, which is considerably significant in various key scenarios, such as community question answering, searching, chatbot, and recommendation. Since most of the advanced models directly model the semantic relevance among words between two sentences while neglecting the \textit{keywords} and \textit{intents} concepts of them, DC-Match is proposed to disentangle keywords from intents and utilizes them to optimize the matching performance. Although DC-Match is a simple yet effective method for semantic matching, it highly depends on the external NER techniques to identify the keywords of sentences, which limits the performance of semantic matching for minor languages since satisfactory NER tools are usually hard to obtain. In this paper, we propose to generally and flexibly resolve the text into multi concepts for multilingual semantic matching to liberate the mod
    
[^37]: 面向证据的事实摘要化用于知识增强的零-shot问答

    Evidence-Focused Fact Summarization for Knowledge-Augmented Zero-Shot Question Answering

    [https://arxiv.org/abs/2403.02966](https://arxiv.org/abs/2403.02966)

    提出了一种面向证据的事实摘要化框架EFSum，用于增强LLMs的零-shot QA性能，并确保摘要的有益性和忠实性。

    

    最近的研究探讨了利用知识图谱（KGs）来增强大语言模型（LLMs）的问答（QA）性能，然而结构化的KG形式化仍然具有挑战性。现有方法，如三元组形式或三元组事实的自由文本转换，遇到了一些问题。这些问题包括由于重复实体或关系而导致的证据密度降低，以及由于无法强调关键证据而导致的证据清晰度降低。为解决这些问题，我们提出了EFSum，一个面向证据的事实摘要化框架，用于通过知识增强的LLMs增强QA。我们通过蒸馏和偏好对齐来优化一个开源的LLM作为事实摘要器。我们的广泛实验证明，EFSum提高了LLM的零-shot QA性能，并且可以确保摘要的同时有益和忠实。

    arXiv:2403.02966v1 Announce Type: cross  Abstract: Recent studies have investigated utilizing Knowledge Graphs (KGs) to enhance Quesetion Answering (QA) performance of Large Language Models (LLMs), yet structured KG verbalization remains challengin. Existing methods, such as triple-form or free-form textual conversion of triple-form facts, encounter several issues. These include reduced evidence density due to duplicated entities or relationships, and reduced evidence clarity due to an inability to emphasize crucial evidence. To address these issues, we propose EFSum, an Evidence-focused Fact Summarization framework for enhanced QA with knowledge-augmented LLMs. We optimize an open-source LLM as a fact summarizer through distillation and preference alignment. Our extensive experiments show that EFSum improves LLM's zero-shot QA performance, and it is possible to ensure both the helpfulness and faithfulness of the summary.
    
[^38]: ChatGPT与生物识别技术：对面部识别、性别检测和年龄估计能力的评估

    ChatGPT and biometrics: an assessment of face recognition, gender detection, and age estimation capabilities

    [https://arxiv.org/abs/2403.02965](https://arxiv.org/abs/2403.02965)

    本文评估了ChatGPT在面部识别、性别检测和年龄估计等生物识别任务中的表现，结果显示ChatGPT在面部识别方面具有较高准确性，并在性别检测方面表现显著，在年龄估计任务中也具有相当准确性。

    

    本文探讨了大型语言模型（LLMs），如ChatGPT，在生物识别任务中的应用。我们特别检验了ChatGPT在执行生物识别相关任务方面的能力，重点关注面部识别、性别检测和年龄估计。由于生物识别被视为敏感信息，ChatGPT避免回答直接提示，因此我们设计了提示策略来绕过其保护措施，并评估生物识别任务的能力。我们的研究表明，ChatGPT能够以相当高的准确性识别面部身份并在两个面部图像之间区分。此外，实验结果显示在性别检测方面性能显著，并对年龄估计任务有相当准确性能。我们的发现揭示了在生物识别中应用LLMs和基础模型具有广阔的潜力。

    arXiv:2403.02965v1 Announce Type: cross  Abstract: This paper explores the application of large language models (LLMs), like ChatGPT, for biometric tasks. We specifically examine the capabilities of ChatGPT in performing biometric-related tasks, with an emphasis on face recognition, gender detection, and age estimation. Since biometrics are considered as sensitive information, ChatGPT avoids answering direct prompts, and thus we crafted a prompting strategy to bypass its safeguard and evaluate the capabilities for biometrics tasks. Our study reveals that ChatGPT recognizes facial identities and differentiates between two facial images with considerable accuracy. Additionally, experimental results demonstrate remarkable performance in gender detection and reasonable accuracy for the age estimation tasks. Our findings shed light on the promising potentials in the application of LLMs and foundation models for biometrics.
    
[^39]: WikiTableEdit: 自然语言指令表格编辑的基准

    WikiTableEdit: A Benchmark for Table Editing by Natural Language Instruction

    [https://arxiv.org/abs/2403.02962](https://arxiv.org/abs/2403.02962)

    本研究介绍了WikiTableEdit数据集，通过26,531个表格生成自然语言指令，针对表格编辑任务中的不规则结构，为解决复杂表格代码编辑问题提供了新途径。

    

    表格数据作为数据表示的一种关键形式，存在于Web上的各种格式中。当面对复杂和不规则的表格时，手动修改变得繁琐。本文研究了大型语言模型（LLMs）在表格编辑任务中的性能。现有研究主要集中在规则形状的表格，其中指令用于生成SQL、Python或Excel Office-script中的代码，用于操作表格。然而，使用代码编辑具有不规则结构的表格，尤其是那些包含跨多行合并单元格的表格，会面临挑战。为了解决这个问题，我们介绍了WikiTableEdit数据集。利用来自WikiSQL数据集的26,531个表格，我们自动生成了六种不同基本操作的自然语言指令以及相应的结果，产生了超过200,000个实例。随后，我们评估了几个代表性的...

    arXiv:2403.02962v1 Announce Type: new  Abstract: Tabular data, as a crucial form of data representation, exists in diverse formats on the Web. When confronted with complex and irregular tables, manual modification becomes a laborious task. This paper investigates the performance of Large Language Models (LLMs) in the context of table editing tasks. Existing research mainly focuses on regular-shaped tables, wherein instructions are used to generate code in SQL, Python, or Excel Office-script for manipulating the tables. Nevertheless, editing tables with irregular structures, particularly those containing merged cells spanning multiple rows, poses a challenge when using code. To address this, we introduce the WikiTableEdit dataset. Leveraging 26,531 tables from the WikiSQL dataset, we automatically generate natural language instructions for six distinct basic operations and the corresponding outcomes, resulting in over 200,000 instances. Subsequently, we evaluate several representative l
    
[^40]: SimuCourt: 利用真实司法判决文件构建司法决策代理

    SimuCourt: Building Judicial Decision-Making Agents with Real-world Judgement Documents

    [https://arxiv.org/abs/2403.02959](https://arxiv.org/abs/2403.02959)

    提出了SimuCourt司法基准，包括真实世界的司法文件，并引入了司法决策任务和多代理框架，评估了代理的司法分析和决策能力

    

    随着深度学习、自然语言处理技术的发展，有效提高了传统司法行业各个方面的效率。然而，目前大多数工作主要集中在个别司法阶段，忽视了跨阶段的协作。随着由大型语言模型提供支持的自主代理在现实环境中变得越来越智能，并能做出复杂决策，为司法智能提供了新的见解。本文介绍了SimuCourt，一个司法基准，包括来自真实世界的420份判决文件，涵盖了三种最常见类型的司法案例，以及一个新颖任务司法决策，用于评估代理的司法分析和决策能力。为了支持这一任务，我们构建了一个大规模司法知识库，JudicialKB，其中包含多种法律知识。我们提出了一种新颖的多代理框架，AgentsCourt

    arXiv:2403.02959v1 Announce Type: cross  Abstract: With the development of deep learning, natural language processing technology has effectively improved the efficiency of various aspects of the traditional judicial industry. However, most current efforts focus solely on individual judicial stage, overlooking cross-stage collaboration. As the autonomous agents powered by large language models are becoming increasingly smart and able to make complex decisions in real-world settings, offering new insights for judicial intelligence. In this paper, (1) we introduce SimuCourt, a judicial benchmark that encompasses 420 judgment documents from real-world, spanning the three most common types of judicial cases, and a novel task Judicial Decision-Making to evaluate the judicial analysis and decision-making power of agents. To support this task, we construct a large-scale judicial knowledge base, JudicialKB, with multiple legal knowledge. (2) we propose a novel multi-agent framework, AgentsCourt
    
[^41]: 评估大型语言模型的文本生成SQL能力：全面评估

    Benchmarking the Text-to-SQL Capability of Large Language Models: A Comprehensive Evaluation

    [https://arxiv.org/abs/2403.02951](https://arxiv.org/abs/2403.02951)

    大型语言模型在文本生成SQL任务中表现出色，但对于最佳提示模板和设计框架仍无共识，新数据集和评估任务有助于全面评估各种方法的表现，并提出了优化解决方案。

    

    大型语言模型（LLMs）已经成为推动文本生成SQL任务的强大工具，明显优于传统方法。然而，作为一个新兴的研究领域，对于最佳提示模板和设计框架仍然没有达成共识。

    arXiv:2403.02951v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have emerged as a powerful tool in advancing the Text-to-SQL task, significantly outperforming traditional methods. Nevertheless, as a nascent research field, there is still no consensus on the optimal prompt templates and design frameworks. Additionally, existing benchmarks inadequately explore the performance of LLMs across the various sub-tasks of the Text-to-SQL process, which hinders the assessment of LLMs' cognitive capabilities and the optimization of LLM-based solutions.To address the aforementioned issues, we firstly construct a new dataset designed to mitigate the risk of overfitting in LLMs. Then we formulate five evaluation tasks to comprehensively assess the performance of diverse methods across various LLMs throughout the Text-to-SQL process.Our study highlights the performance disparities among LLMs and proposes optimal in-context learning solutions tailored to each task. These findings offer
    
[^42]: 一种通过决策路径耦合增强后门攻击生存能力的通用方法

    A general approach to enhance the survivability of backdoor attacks by decision path coupling

    [https://arxiv.org/abs/2403.02950](https://arxiv.org/abs/2403.02950)

    Venom是一种通用的后门攻击增强器，通过采用关注模仿损失，强迫受损样本的决策路径与良性样本的关键决策路径耦合，从而提高现有后门攻击对模型重建型防御的生存能力。

    

    后门攻击一直是深度神经网络（DNN）面临的新兴安全威胁之一，导致严重后果。其中一种主流后门防御方法是基于模型重建的。这些防御采用模型遗忘或剪枝来消除后门。然而，对于如何从这些防御中幸存下来却鲜有研究。为了弥合这一差距，我们提出了Venom，这是第一个通用的后门攻击增强器，用于提高现有后门攻击对基于模型重建的防御的生存能力。我们将Venom形式化为一个二元任务优化问题。其中一个任务是原始后门攻击任务，以保留原始攻击能力，而另一个任务是攻击增强任务，以提高攻击的生存能力。为了实现第二个任务，我们提出了关注模仿损失，来强制后门模型中受损样本的决策路径与良性样本的关键决策路径耦合。

    arXiv:2403.02950v1 Announce Type: new  Abstract: Backdoor attacks have been one of the emerging security threats to deep neural networks (DNNs), leading to serious consequences. One of the mainstream backdoor defenses is model reconstruction-based. Such defenses adopt model unlearning or pruning to eliminate backdoors. However, little attention has been paid to survive from such defenses. To bridge the gap, we propose Venom, the first generic backdoor attack enhancer to improve the survivability of existing backdoor attacks against model reconstruction-based defenses. We formalize Venom as a binary-task optimization problem. The first is the original backdoor attack task to preserve the original attack capability, while the second is the attack enhancement task to improve the attack survivability. To realize the second task, we propose attention imitation loss to force the decision path of poisoned samples in backdoored models to couple with the crucial decision path of benign samples,
    
[^43]: SAFFIRA: 一种评估基于Systolic Array的DNN加速器可靠性的框架

    SAFFIRA: a Framework for Assessing the Reliability of Systolic-Array-Based DNN Accelerators

    [https://arxiv.org/abs/2403.02946](https://arxiv.org/abs/2403.02946)

    介绍了一种针对基于Systolic Array的DNN加速器的新型分层软件化硬件感知故障注入策略，以解决可靠性评估中的时间效率问题。

    

    Systolic array已经成为深度神经网络(DNN)硬件加速器的显着架构，提供高吞吐量和低延迟性能，对于在各种应用中部署DNN至关重要。然而，在安全关键应用中使用时，必须进行可靠性评估以确保DNN加速器的正确行为。虽然故障注入作为一种成熟实用且稳健的可靠性评估方法，但仍然是一个非常耗时的过程。本文通过引入一种针对基于systolic array的DNN加速器量身定制的新型分层软件化硬件感知故障注入策略，解决了时间效率问题。

    arXiv:2403.02946v1 Announce Type: new  Abstract: Systolic array has emerged as a prominent architecture for Deep Neural Network (DNN) hardware accelerators, providing high-throughput and low-latency performance essential for deploying DNNs across diverse applications. However, when used in safety-critical applications, reliability assessment is mandatory to guarantee the correct behavior of DNN accelerators. While fault injection stands out as a well-established practical and robust method for reliability assessment, it is still a very time-consuming process. This paper addresses the time efficiency issue by introducing a novel hierarchical software-based hardware-aware fault injection strategy tailored for systolic array-based DNN accelerators.
    
[^44]: PaperWeaver：通过将用户收集的论文与推荐论文上下文化，丰富主题论文提醒

    PaperWeaver: Enriching Topical Paper Alerts by Contextualizing Recommended Papers with User-collected Papers

    [https://arxiv.org/abs/2403.02939](https://arxiv.org/abs/2403.02939)

    PaperWeaver通过将用户收集的论文与推荐论文上下文化，为研究人员提供了更丰富的主题论文提醒

    

    随着学术档案的迅速增长，研究人员订阅“论文提醒”系统，定期为他们推荐最近发表的与之前收集的论文相似的论文。然而，研究人员有时很难理解推荐论文与他们自己研究背景之间微妙的联系，因为现有系统只呈现论文标题和摘要。为了帮助研究人员发现这些联系，我们提出了PaperWeaver，这是一个丰富的论文提醒系统，根据用户收集的论文提供推荐论文的上下文化文本描述。PaperWeaver采用基于大语言模型（LLMs）的计算方法，从用户收集的论文中推断用户的研究兴趣，提取论文的特定背景，并在这些背景上比较推荐论文和收集的论文。我们的用户研究（N=15）表明，使用PaperWeaver的参与者能够

    arXiv:2403.02939v1 Announce Type: cross  Abstract: With the rapid growth of scholarly archives, researchers subscribe to "paper alert" systems that periodically provide them with recommendations of recently published papers that are similar to previously collected papers. However, researchers sometimes struggle to make sense of nuanced connections between recommended papers and their own research context, as existing systems only present paper titles and abstracts. To help researchers spot these connections, we present PaperWeaver, an enriched paper alerts system that provides contextualized text descriptions of recommended papers based on user-collected papers. PaperWeaver employs a computational method based on Large Language Models (LLMs) to infer users' research interests from their collected papers, extract context-specific aspects of papers, and compare recommended and collected papers on these aspects. Our user study (N=15) showed that participants using PaperWeaver were able to
    
[^45]: AdAM: 适用于边缘DNN加速器的自适应容错近似乘法器

    AdAM: Adaptive Fault-Tolerant Approximate Multiplier for Edge DNN Accelerators

    [https://arxiv.org/abs/2403.02936](https://arxiv.org/abs/2403.02936)

    提出了一种适用于ASIC-based DNN加速器的自适应容错近似乘法器架构。

    

    这篇论文提出了一种专为基于ASIC的DNN加速器定制的新型自适应容错近似乘法器的架构。

    arXiv:2403.02936v1 Announce Type: new  Abstract: In this paper, we propose an architecture of a novel adaptive fault-tolerant approximate multiplier tailored for ASIC-based DNN accelerators.
    
[^46]: 多值拓展的模糊Datalog在任意t-范数上的应用

    Fuzzy Datalog$^\exists$ over Arbitrary t-Norms

    [https://arxiv.org/abs/2403.02933](https://arxiv.org/abs/2403.02933)

    将Datalog与存在规则泛化到模糊环境中，利用任意t-范数进行推理，保持了计算复杂性结果和推理技术的适用性

    

    神经符号人工智能领域的主要挑战之一是在神经元和符号数据共存的情况下进行逻辑推理。 为了允许这种推理，我们将标准基于规则的语言Datalog与存在规则进行了泛化，允许在规则主体中的经典连接词的位置上使用任意t-范数。 结果的形式允许我们对与不确定度程度相关的数据进行推理，同时保留了计算复杂性结果和为标准Datalog设置建立的推理技术的适用性。 特别地，我们提供了Datalog chase的模糊扩展，产生模糊的通用模型，并利用它们来展示

    arXiv:2403.02933v1 Announce Type: new  Abstract: One of the main challenges in the area of Neuro-Symbolic AI is to perform logical reasoning in the presence of both neural and symbolic data. This requires combining heterogeneous data sources such as knowledge graphs, neural model predictions, structured databases, crowd-sourced data, and many more. To allow for such reasoning, we generalise the standard rule-based language Datalog with existential rules (commonly referred to as tuple-generating dependencies) to the fuzzy setting, by allowing for arbitrary t-norms in the place of classical conjunctions in rule bodies. The resulting formalism allows us to perform reasoning about data associated with degrees of uncertainty while preserving computational complexity results and the applicability of reasoning techniques established for the standard Datalog setting. In particular, we provide fuzzy extensions of Datalog chases which produce fuzzy universal models and we exploit them to show th
    
[^47]: TaylorShift：利用TaylorSoftmax将自注意力机制的复杂度从平方级转变为线性级（再转回去）

    TaylorShift: Shifting the Complexity of Self-Attention from Squared to Linear (and Back) using Taylor-Softmax

    [https://arxiv.org/abs/2403.02920](https://arxiv.org/abs/2403.02920)

    TaylorShift通过引入TaylorSoftmax重新计算全记号之间的交互，将自注意力机制的复杂度由平方级降低到线性级，从而提高了处理长序列的效率。

    

    注意机制的二次复杂度是使用Transformer处理长序列时面临的最大障碍之一。当前的方法依赖于稀疏表示或有状态的循环，牺牲了记号之间的交互，最终导致性能上的妥协。本文介绍了TaylorShift，一种新颖的Taylor softmax 重构，能够在线性时间和空间内计算全体记号之间的交互。我们通过分析确定了使用TaylorShift比传统注意力更加高效的交叉点，这与实证测量结果密切匹配。具体来说，我们的研究结果表明，TaylorShift提高了对短至800个记号的序列的内存效率，并加速了对长达约1700个记号及以上输入的推断。对于较短的序列，TaylorShift与原始注意力的性能相当。此外，一种分类...

    arXiv:2403.02920v1 Announce Type: cross  Abstract: The quadratic complexity of the attention mechanism represents one of the biggest hurdles for processing long sequences using Transformers. Current methods, relying on sparse representations or stateful recurrence, sacrifice token-to-token interactions, which ultimately leads to compromises in performance. This paper introduces TaylorShift, a novel reformulation of the Taylor softmax that enables computing full token-to-token interactions in linear time and space. We analytically determine the crossover points where employing TaylorShift becomes more efficient than traditional attention, aligning closely with empirical measurements. Specifically, our findings demonstrate that TaylorShift enhances memory efficiency for sequences as short as 800 tokens and accelerates inference for inputs of approximately 1700 tokens and beyond. For shorter sequences, TaylorShift scales comparably with the vanilla attention. Furthermore, a classification
    
[^48]: DynST：资源受限时空预测的动态稀疏训练

    DynST: Dynamic Sparse Training for Resource-Constrained Spatio-Temporal Forecasting

    [https://arxiv.org/abs/2403.02914](https://arxiv.org/abs/2403.02914)

    传统传感器部署方法在地球科学系统中存在困难，本研究提出了一种动态稀疏训练方法，能够有效优化传感器的部署和数据收集过程。

    

    随着传感器服务的不断增加，尽管为面向深度学习的地球科学提供了宝贵的路径并提供了大量的地球系统数据，但这也给它们的工业级部署带来了困难。具体来说，地球科学系统在很大程度上依赖于传感器的广泛部署，然而，由于复杂的地理和社会因素，传感器数据的收集受到限制，这使得实现全面覆盖和统一部署具有挑战性。为了减轻这一障碍，传统的传感器部署方法利用特定算法设计和部署传感器。这些方法动态调整传感器的激活时间，以优化对每个子区域的检测过程。遗憾的是，基于历史观测和地理特征制定激活策略，这些方法和生成的模型既不简单也不实用。

    arXiv:2403.02914v1 Announce Type: new  Abstract: The ever-increasing sensor service, though opening a precious path and providing a deluge of earth system data for deep-learning-oriented earth science, sadly introduce a daunting obstacle to their industrial level deployment. Concretely, earth science systems rely heavily on the extensive deployment of sensors, however, the data collection from sensors is constrained by complex geographical and social factors, making it challenging to achieve comprehensive coverage and uniform deployment. To alleviate the obstacle, traditional approaches to sensor deployment utilize specific algorithms to design and deploy sensors. These methods dynamically adjust the activation times of sensors to optimize the detection process across each sub-region. Regrettably, formulating an activation strategy generally based on historical observations and geographic characteristics, which make the methods and resultant models were neither simple nor practical. Wo
    
[^49]: ImgTrojan: 用一张图片对视觉-语言模型进行越狱

    ImgTrojan: Jailbreaking Vision-Language Models with ONE Image

    [https://arxiv.org/abs/2403.02910](https://arxiv.org/abs/2403.02910)

    本文提出了一种针对视觉-语言模型的新型越狱攻击，通过在训练数据中插入恶意文本提示，成功实施越狱攻击，并分析了有毒数据比率和可训练参数位置对攻击成功率的影响。

    

    近来，对于大型语言模型（LLMs）与人类价值观的对齐引起了越来越多的关注。然而，它们与视觉模块集成的安全问题，即视觉-语言模型（VLMs），仍然相对未被充分探讨。本文提出了一种针对VLMs的新型越狱攻击，旨在当用户输入有害指令时绕过其安全阻碍。假设我们的有毒（图像，文本）数据对包含在训练数据中。通过用恶意越狱提示替换原始文本标题，我们的方法可以利用有毒图像执行越狱攻击。此外，我们分析了有毒比率和可训练参数位置对攻击成功率的影响。为了评估，我们设计了两个度量标准来量化我们攻击的成功率和隐蔽性。结合一系列策划的有害指令，可以衡量攻击的有效性。

    arXiv:2403.02910v1 Announce Type: cross  Abstract: There has been an increasing interest in the alignment of large language models (LLMs) with human values. However, the safety issues of their integration with a vision module, or vision language models (VLMs), remain relatively underexplored. In this paper, we propose a novel jailbreaking attack against VLMs, aiming to bypass their safety barrier when a user inputs harmful instructions. A scenario where our poisoned (image, text) data pairs are included in the training data is assumed. By replacing the original textual captions with malicious jailbreak prompts, our method can perform jailbreak attacks with the poisoned images. Moreover, we analyze the effect of poison ratios and positions of trainable parameters on our attack's success rate. For evaluation, we design two metrics to quantify the success rate and the stealthiness of our attack. Together with a list of curated harmful instructions, a benchmark for measuring attack efficac
    
[^50]: 关于过程导向自动文本摘要的综合调查，并探讨基于LLM的方法

    A Comprehensive Survey on Process-Oriented Automatic Text Summarization with Exploration of LLM-Based Methods

    [https://arxiv.org/abs/2403.02901](https://arxiv.org/abs/2403.02901)

    本综合调查从“过程导向模式“视角提供了自动文本摘要的全面概述，全面审视了最新的基于LLM的ATS工作，并提供了关于ATS最新的调查，弥补了文献中的两年间隔。

    

    arXiv:2403.02901v1 公告类型: 新的 摘要: 自动文本摘要（ATS）利用自然语言处理（NLP）算法，旨在创建简洁准确的摘要，从而显著减少处理大量文本所需的人力。ATS在学术界和工业界都引起了极大兴趣。过去已进行了许多研究来调查ATS的方法; 但是，它们通常缺乏对实际实施的实用性，因为它们经常从理论的角度对以往的方法进行分类。此外，大型语言模型（LLMs）的出现改变了传统的ATS方法。在这项调查中，我们旨在 1）从“过程导向模式”视角提供ATS的全面概述，最符合实际应用; 2) 全面审视最新的基于LLM的ATS工作; 以及 3）提供关于ATS的最新调查，弥补文献中两年间隔之处。令人感到满意

    arXiv:2403.02901v1 Announce Type: new  Abstract: Automatic Text Summarization (ATS), utilizing Natural Language Processing (NLP) algorithms, aims to create concise and accurate summaries, thereby significantly reducing the human effort required in processing large volumes of text. ATS has drawn considerable interest in both academic and industrial circles. Many studies have been conducted in the past to survey ATS methods; however, they generally lack practicality for real-world implementations, as they often categorize previous methods from a theoretical standpoint. Moreover, the advent of Large Language Models (LLMs) has altered conventional ATS methods. In this survey, we aim to 1) provide a comprehensive overview of ATS from a ``Process-Oriented Schema'' perspective, which is best aligned with real-world implementations; 2) comprehensively review the latest LLM-based ATS works; and 3) deliver an up-to-date survey of ATS, bridging the two-year gap in the literature. To the best of o
    
[^51]: 针对无监督领域自适应的领域无关互相提示

    Domain-Agnostic Mutual Prompting for Unsupervised Domain Adaptation

    [https://arxiv.org/abs/2403.02899](https://arxiv.org/abs/2403.02899)

    提出了领域无关互相提示（DAMP）方法，通过互相对齐视觉和文本嵌入来利用领域不变语义，弥合了传统无监督领域自适应方法的局限性。

    

    传统的无监督领域自适应（UDA）致力于最小化不同领域之间的分布差异，忽略了从数据中获取丰富语义并且难以处理复杂的领域转变。一种有前途的技术是利用大规模预训练的视觉-语言模型的知识来进行更有指导性的自适应。尽管一些尝试，但目前的方法通常学习文本提示将领域语义嵌入源领域和目标领域分别进行分类，限制了跨领域知识传递。此外，仅提示语言分支缺乏动态适应两种模态的灵活性。为了弥合这一差距，我们提出了一种领域无关互相提示（DAMP）方法，通过互相对齐视觉和文本嵌入来利用领域不变语义。

    arXiv:2403.02899v1 Announce Type: new  Abstract: Conventional Unsupervised Domain Adaptation (UDA) strives to minimize distribution discrepancy between domains, which neglects to harness rich semantics from data and struggles to handle complex domain shifts. A promising technique is to leverage the knowledge of large-scale pre-trained vision-language models for more guided adaptation. Despite some endeavors, current methods often learn textual prompts to embed domain semantics for source and target domains separately and perform classification within each domain, limiting cross-domain knowledge transfer. Moreover, prompting only the language branch lacks flexibility to adapt both modalities dynamically. To bridge this gap, we propose Domain-Agnostic Mutual Prompting (DAMP) to exploit domain-invariant semantics by mutually aligning visual and textual embeddings. Specifically, the image contextual information is utilized to prompt the language branch in a domain-agnostic and instance-con
    
[^52]: 使用异构图对比迁移学习实现零样本跨语言文档级事件因果识别

    Zero-Shot Cross-Lingual Document-Level Event Causality Identification with Heterogeneous Graph Contrastive Transfer Learning

    [https://arxiv.org/abs/2403.02893](https://arxiv.org/abs/2403.02893)

    提出了一种使用异构图对比迁移学习的方法，实现了零样本跨语言文档级事件因果识别，并在实验证明在F1得分上优于之前的最先进模型。

    

    事件因果识别（ECI）指的是在文本中检测事件之间的因果关系。然而，大多数现有研究都集中在高资源语言下的句子级ECI，而对于低资源语言下更具挑战性的文档级ECI（DECI）却尚未得到充分探索。在本文中，我们提出了一种带有多粒度对比传递学习（GIMC）的异构图交互模型，用于实现零样本跨语言文档级ECI。具体来说，我们引入了一个异构图交互网络来建模文档中分散事件之间的远距离依赖关系。然后，为了提高从源语言学习到的因果知识的跨语言可转移性，我们提出了一个多粒度对比传递学习模块，以调整跨语言间的因果表示。大量实验证明，我们的框架在平均F1得分上优于之前的最先进模型约9.4%和8.2%。

    arXiv:2403.02893v1 Announce Type: cross  Abstract: Event Causality Identification (ECI) refers to detect causal relations between events in texts. However, most existing studies focus on sentence-level ECI with high-resource language, leaving more challenging document-level ECI (DECI) with low-resource languages under-explored. In this paper, we propose a Heterogeneous Graph Interaction Model with Multi-granularity Contrastive Transfer Learning (GIMC) for zero-shot cross-lingual document-level ECI. Specifically, we introduce a heterogeneous graph interaction network to model the long-distance dependencies between events that are scattered over document. Then, to improve cross-lingual transferability of causal knowledge learned from source language, we propose a multi-granularity contrastive transfer learning module to align the causal representations across languages. Extensive experiments show our framework outperforms previous state-of-the-art model by 9.4% and 8.2% of average F1 sco
    
[^53]: 利用全局，局部身体部位和头部流增强长期人员再识别

    Enhancing Long-Term Person Re-Identification Using Global, Local Body Part, and Head Streams

    [https://arxiv.org/abs/2403.02892](https://arxiv.org/abs/2403.02892)

    提出了一个新框架，结合全局和局部信息，利用三个流（全局、局部身体部位和头部），用于增强长期人员再识别任务。

    

    本文研究长期人员再识别任务。通常，人员再识别假设人们不会更换衣服，这限制了其应用于短期场景。为了克服这一限制，我们研究了考虑换衣与一致着装两种情景的长期人员再识别。我们提出了一个有效学习和利用全局和局部信息的新框架。提出的框架包括三个流：全局、局部身体部位和头部流。全局和头部流分别编码来自整个图像和头部区域裁剪图像的与身份相关信息。两个流利用对抗性擦除，最大池化和平均池化的组合编码最明显的，不太明显的和平均特征。

    arXiv:2403.02892v1 Announce Type: cross  Abstract: This work addresses the task of long-term person re-identification. Typically, person re-identification assumes that people do not change their clothes, which limits its applications to short-term scenarios. To overcome this limitation, we investigate long-term person re-identification, which considers both clothes-changing and clothes-consistent scenarios. In this paper, we propose a novel framework that effectively learns and utilizes both global and local information. The proposed framework consists of three streams: global, local body part, and head streams. The global and head streams encode identity-relevant information from an entire image and a cropped image of the head region, respectively. Both streams encode the most distinct, less distinct, and average features using the combinations of adversarial erasing, max pooling, and average pooling. The local body part stream extracts identity-related information for each body part,
    
[^54]: MathScale: 数学推理的指导优化尺度

    MathScale: Scaling Instruction Tuning for Mathematical Reasoning

    [https://arxiv.org/abs/2403.02884](https://arxiv.org/abs/2403.02884)

    MathScale提出了一种简单可扩展的方法来创建高质量的数学推理数据，展现出在数学数据集大小方面的有效可扩展性。

    

    大型语言模型（LLMs）在问题解决方面展现了出色的能力，但它们在解决数学问题方面的熟练程度仍然不足。我们提出了MathScale，这是一种简单且可扩展的方法，使用前沿的LLMs（例如GPT-3.5）创建高质量的数学推理数据。受人类数学学习中的认知机制启发，它首先从种子数学问题中提取主题和知识点，然后构建一个概念图，随后用于生成新的数学问题。MathScale在我们生成的数学数据集的大小方面展现出了有效的可扩展性。因此，我们创建了一个包含两百万数学问题-答案对的数学推理数据集（MathScaleQA）。为了全面评估LLMs的数学推理能力，我们构建了MwpBench，这是一个数学问题词汇问题基准，包括十个数据集。

    arXiv:2403.02884v1 Announce Type: cross  Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in problem-solving. However, their proficiency in solving mathematical problems remains inadequate. We propose MathScale, a simple and scalable method to create high-quality mathematical reasoning data using frontier LLMs (e.g., {\tt GPT-3.5}). Inspired by the cognitive mechanism in human mathematical learning, it first extracts topics and knowledge points from seed math questions and then build a concept graph, which is subsequently used to generate new math questions. MathScale exhibits effective scalability along the size axis of the math dataset that we generate. As a result, we create a mathematical reasoning dataset (MathScaleQA) containing two million math question-answer pairs. To evaluate mathematical reasoning abilities of LLMs comprehensively, we construct {\sc MwpBench}, a benchmark of Math Word Problems, which is a collection of ten datasets (including 
    
[^55]: ActiveAD: 面向规划的端到端自动驾驶主动学习

    ActiveAD: Planning-Oriented Active Learning for End-to-End Autonomous Driving

    [https://arxiv.org/abs/2403.02877](https://arxiv.org/abs/2403.02877)

    设计了一种面向规划的主动学习方法，通过多样性和有用性标准逐步注释采集的原始数据，以实现端到端自动驾驶的样本和标记效率。

    

    最近，端到端可微学习成为自动驾驶 (AD) 的一个突出范例。其中一个主要瓶颈在于其对高质量标记数据的渴望，例如 3D 边界框和语义分割，这些数据的手动注释费用极高。困难之处进一步体现在 AD 样本内部行为往往受长尾分布的影响。换句话说，采集到的数据中大部分可能是微不足道的（例如在笔直道路上简单行驶），而只有少数情况是安全关键的。本文探讨了一个实际重要但尚未深入研究的问题，即如何实现端到端 AD 的样本和标记效率。具体来说，我们设计了一种面向规划的主动学习方法，根据所提出的多样性和有用性标准逐步对采集的原始数据进行注释，以规划路线。

    arXiv:2403.02877v1 Announce Type: cross  Abstract: End-to-end differentiable learning for autonomous driving (AD) has recently become a prominent paradigm. One main bottleneck lies in its voracious appetite for high-quality labeled data e.g. 3D bounding boxes and semantic segmentation, which are notoriously expensive to manually annotate. The difficulty is further pronounced due to the prominent fact that the behaviors within samples in AD often suffer from long tailed distribution. In other words, a large part of collected data can be trivial (e.g. simply driving forward in a straight road) and only a few cases are safety-critical. In this paper, we explore a practically important yet under-explored problem about how to achieve sample and label efficiency for end-to-end AD. Specifically, we design a planning-oriented active learning method which progressively annotates part of collected raw data according to the proposed diversity and usefulness criteria for planning routes. Empirical
    
[^56]: 通过边缘/端点设备的侧信道攻击精确提取深度学习模型

    Precise Extraction of Deep Learning Models via Side-Channel Attacks on Edge/Endpoint Devices

    [https://arxiv.org/abs/2403.02870](https://arxiv.org/abs/2403.02870)

    该研究揭示了对深度学习模型进行精确提取的新型攻击方法，通过边缘/端点设备的侧信道攻击可以获取模型架构和图像维度等重要信息。

    

    随着深度学习（DL）模型日益普及，模型规模越来越大，只有拥有庞大训练数据集和巨大计算能力的公司才能应对业务需求的这些大型模型。大多数DL模型是公司专有的，因此这些公司努力保护他们的私有模型，以免受到模型提取攻击（MEA）的侵害，该攻击目的是通过训练代理模型来窃取模型。如今，公司倾向于将模型从中央服务器转移到边缘/端点设备。正如最新研究揭示的那样，攻击者利用这一机会作为启动侧信道攻击（SCA）的新攻击向量，针对运行受害模型的设备发动攻击，获取模型信息的各种要点，例如模型架构（MA）和图像维度（ID）。我们的工作首次全面理解了这种关系，将有助于未来MEA研究在进攻和防御方面取得进展。

    arXiv:2403.02870v1 Announce Type: new  Abstract: With growing popularity, deep learning (DL) models are becoming larger-scale, and only the companies with vast training datasets and immense computing power can manage their business serving such large models. Most of those DL models are proprietary to the companies who thus strive to keep their private models safe from the model extraction attack (MEA), whose aim is to steal the model by training surrogate models. Nowadays, companies are inclined to offload the models from central servers to edge/endpoint devices. As revealed in the latest studies, adversaries exploit this opportunity as new attack vectors to launch side-channel attack (SCA) on the device running victim model and obtain various pieces of the model information, such as the model architecture (MA) and image dimension (ID). Our work provides a comprehensive understanding of such a relationship for the first time and would benefit future MEA studies in both offensive and de
    
[^57]: FLGuard: 通过对比模型集合实现拜占庭-鲁棒的联邦学习

    FLGuard: Byzantine-Robust Federated Learning via Ensemble of Contrastive Models

    [https://arxiv.org/abs/2403.02846](https://arxiv.org/abs/2403.02846)

    通过对比模型集合，提出了FLGuard方法增强联邦学习的拜占庭-鲁棒性。

    

    联邦学习（FL）通过仅共享本地模型的参数来训练全局模型，从而在训练具有私人训练数据集的众多客户时蓬勃发展。然而，最近的研究提出了投毒攻击，当对手假扮为良性客户并存在于一组客户中时，会导致全局模型准确性的灾难性损失。因此，最近的研究提出了拜占庭-鲁棒的FL方法，允许服务器即使在系统中存在对手也能训练准确的全局模型。然而，许多现有方法要求知道恶意客户的数量或辅助（干净）数据集，或者在私有数据集非独立同分布（non-IID）时其有效性报告明显降低。在这项工作中，我们提出

    arXiv:2403.02846v1 Announce Type: cross  Abstract: Federated Learning (FL) thrives in training a global model with numerous clients by only sharing the parameters of their local models trained with their private training datasets. Therefore, without revealing the private dataset, the clients can obtain a deep learning (DL) model with high performance. However, recent research proposed poisoning attacks that cause a catastrophic loss in the accuracy of the global model when adversaries, posed as benign clients, are present in a group of clients. Therefore, recent studies suggested byzantine-robust FL methods that allow the server to train an accurate global model even with the adversaries present in the system. However, many existing methods require the knowledge of the number of malicious clients or the auxiliary (clean) dataset or the effectiveness reportedly decreased hugely when the private dataset was non-independently and identically distributed (non-IID). In this work, we propose
    
[^58]: 针对木材工业中应用于稀疏视角层析成像的长物体的重建

    Reconstruction for Sparse View Tomography of Long Objects Applied to Imaging in the Wood Industry

    [https://arxiv.org/abs/2403.02820](https://arxiv.org/abs/2403.02820)

    本研究提出了一种基于学习原始-对偶神经网络的迭代重建方法，适用于顺序扫描几何形状，可以在稀疏视角下进行原木的三维层析成像重建。

    

    在木材工业中，通过在移动传送带上从几个源位置进行离散X射线扫描来对原木进行常规质量筛查。通常，通过顺序扫描几何形状获得二维（2D）切片测量。每个2D切片单独不包含足够信息进行三维层析重建，在其中感兴趣的原木生物特征得以很好保留。在本研究中，我们提出了一种基于学习原始-对偶神经网络的迭代重建方法，适用于顺序扫描几何形状。我们的方法在重建过程中积累了相邻切片之间的信息，而不是仅在重建期间考虑单个切片。我们的定量和定性评价结果显示，我们的方法在仅使用五个源位置的情况下产生的原木重建足够准确，以识别像节（分支）、心材等生物特征。

    arXiv:2403.02820v1 Announce Type: new  Abstract: In the wood industry, logs are commonly quality screened by discrete X-ray scans on a moving conveyor belt from a few source positions. Typically, two-dimensional (2D) slice-wise measurements are obtained by a sequential scanning geometry. Each 2D slice alone does not carry sufficient information for a three-dimensional tomographic reconstruction in which biological features of interest in the log are well preserved. In the present work, we propose a learned iterative reconstruction method based on the Learned Primal-Dual neural network, suited for sequential scanning geometries. Our method accumulates information between neighbouring slices, instead of only accounting for single slices during reconstruction. Our quantitative and qualitative evaluations with as few as five source positions show that our method yields reconstructions of logs that are sufficiently accurate to identify biological features like knots (branches), heartwood an
    
[^59]: InjectTST: 将全局信息注入独立通道的变压器方法用于长时间序列预测

    InjectTST: A Transformer Method of Injecting Global Information into Independent Channels for Long Time Series Forecasting

    [https://arxiv.org/abs/2403.02814](https://arxiv.org/abs/2403.02814)

    提出了InjectTST这种将全局信息注入独立通道的变压器方法，用于改进多变量时间序列（MTS）预测性能。

    

    变压器已成为多变量时间序列（MTS）预测中最流行的架构之一。最近基于Transformer的MTS模型通常倾向于具有通道独立结构，因为通道独立可以减轻噪声和分布漂移问题，从而更具鲁棒性。然而，值得注意的是，通道依赖性仍然是MTS的固有特性，蕴含着宝贵的信息。设计一个结合了通道独立和通道混合结构优点的模型是进一步改进MTS预测的关键，这带来了一个具有挑战性的难题。为了解决这个问题，在本文中提出了一种将全局信息注入通道无关Transformer的注入方法InjectTST。我们没有直接设计一个混合通道模型，而是保留了通道独立的框架，并逐渐将全局信息注入到单个通道中。

    arXiv:2403.02814v1 Announce Type: cross  Abstract: Transformer has become one of the most popular architectures for multivariate time series (MTS) forecasting. Recent Transformer-based MTS models generally prefer channel-independent structures with the observation that channel independence can alleviate noise and distribution drift issues, leading to more robustness. Nevertheless, it is essential to note that channel dependency remains an inherent characteristic of MTS, carrying valuable information. Designing a model that incorporates merits of both channel-independent and channel-mixing structures is a key to further improvement of MTS forecasting, which poses a challenging conundrum. To address the problem, an injection method for global information into channel-independent Transformer, InjectTST, is proposed in this paper. Instead of designing a channel-mixing model directly, we retain the channel-independent backbone and gradually inject global information into individual channels
    
[^60]: 动态高斯图算子：在任意离散力学问题中学习参数化偏微分方程

    Dynamic Gaussian Graph Operator: Learning parametric partial differential equations in arbitrary discrete mechanics problems

    [https://arxiv.org/abs/2403.02810](https://arxiv.org/abs/2403.02810)

    提出了一种新颖的操作学习算法，称为动态高斯图算子（DGGO），可以在任意离散力学问题中学习参数化PDEs。

    

    深度学习方法可以用于解决由参数化偏微分方程（PDEs）控制的物理系统，因为有大量科学数据可供使用。最近，已经发展了一种操作学习方法，专注于学习无限维函数空间之间的非线性映射，提供了从观测数据到解决方案的接口。然而，最先进的神经算子仅限于恒定和均匀离散化，从而导致在计算域的任意离散化方案上泛化不足。在这项工作中，我们提出了一种新颖的操作学习算法，称为动态高斯图算子（DGGO），将神经算子扩展到在任意离散力学问题中学习参数化PDEs。动态高斯图（DGG）核学习将在一般欧几里得空间中定义的观察向量映射到高维均匀度量中定义的度量向量。

    arXiv:2403.02810v1 Announce Type: cross  Abstract: Deep learning methods have access to be employed for solving physical systems governed by parametric partial differential equations (PDEs) due to massive scientific data. It has been refined to operator learning that focuses on learning non-linear mapping between infinite-dimensional function spaces, offering interface from observations to solutions. However, state-of-the-art neural operators are limited to constant and uniform discretization, thereby leading to deficiency in generalization on arbitrary discretization schemes for computational domain. In this work, we propose a novel operator learning algorithm, referred to as Dynamic Gaussian Graph Operator (DGGO) that expands neural operators to learning parametric PDEs in arbitrary discrete mechanics problems. The Dynamic Gaussian Graph (DGG) kernel learns to map the observation vectors defined in general Euclidean space to metric vectors defined in high-dimensional uniform metric s
    
[^61]: DPPA：用于大型语言模型的修剪方法以进行模型合并

    DPPA: Pruning Method for Large Language Model to Model Merging

    [https://arxiv.org/abs/2403.02799](https://arxiv.org/abs/2403.02799)

    提出了一种名为动态修剪分区增强（DPPA）的双阶段方法，用于解决合并复杂微调模型的挑战。

    

    模型合并是将从多个领域衍生出的微调模型相结合，旨在增强模型在各个领域的熟练度。主要关注点是解决参数冲突。现有大量研究已解决了合并阶段的这个问题，最新研究集中在通过修剪阶段来解决这个问题。DARE方法在应用于简单微调模型时表现出有希望的结果。然而，当用于显示与基线模型相比存在显著参数偏差的复杂微调模型时，该方法的有效性往往会减弱。本文介绍了一种名为动态修剪分区增强（DPPA）的双阶段方法，旨在解决合并复杂微调模型的挑战。首先，我们介绍了动态修剪（DP），这是一种基于量剪枝的改进方法，其目的是增强p

    arXiv:2403.02799v1 Announce Type: cross  Abstract: Model merging is to combine fine-tuned models derived from multiple domains, with the intent of enhancing the model's proficiency across various domains. The principal concern is the resolution of parameter conflicts. A substantial amount of existing research remedy this issue during the merging stage, with the latest study focusing on resolving this issue throughout the pruning stage. The DARE approach has exhibited promising outcomes when applied to a simplistic fine-tuned model. However, the efficacy of this method tends to wane when employed on complex fine-tuned models that show a significant parameter bias relative to the baseline model. In this paper, we introduce a dual-stage method termed Dynamic Pruning Partition Amplification (DPPA), devised to tackle the challenge of merging complex fine-tuned models. Initially, we introduce Dynamically Pruning (DP), an improved approach based on magnitude pruning, which aim is to enhance p
    
[^62]: 用大型语言模型评估和优化教育内容

    Evaluating and Optimizing Educational Content with Large Language Model Judgments

    [https://arxiv.org/abs/2403.02795](https://arxiv.org/abs/2403.02795)

    使用语言模型作为教育专家来评估教育内容的影响，展示了LMs作为可靠评估者的潜力，并介绍了一种指导优化方法。

    

    创建有效的教育材料通常需要对学生学习成果进行昂贵且耗时的研究。为了克服这一障碍，一个想法是构建学生学习的计算模型，并使用它们来优化教学材料。然而，模拟学习动态的认知过程是困难的。我们提出了一种使用语言模型（LMs）作为教育专家来评估各种指导对学习结果影响的替代方法。具体地，我们使用GPT-3.5来评估指导材料对不同学生群体的整体影响，并发现它可以复制诸如专业逆转效应和变异效应等已经建立的教育发现。这展示了LMs作为教育内容可靠评估者的潜力。基于这一见解，我们介绍了一种指导优化方法，其中一个LM生成指导。

    arXiv:2403.02795v1 Announce Type: new  Abstract: Creating effective educational materials generally requires expensive and time-consuming studies of student learning outcomes. To overcome this barrier, one idea is to build computational models of student learning and use them to optimize instructional materials. However, it is difficult to model the cognitive processes of learning dynamics. We propose an alternative approach that uses Language Models (LMs) as educational experts to assess the impact of various instructions on learning outcomes. Specifically, we use GPT-3.5 to evaluate the overall effect of instructional materials on different student groups and find that it can replicate well-established educational findings such as the Expertise Reversal Effect and the Variability Effect. This demonstrates the potential of LMs as reliable evaluators of educational content. Building on this insight, we introduce an instruction optimization approach in which one LM generates instruction
    
[^63]: 基于变分信息瓶颈的距离度量学习模型

    A Distance Metric Learning Model Based On Variational Information Bottleneck

    [https://arxiv.org/abs/2403.02794](https://arxiv.org/abs/2403.02794)

    本文首次将变分信息瓶颈与度量学习模型相结合，提出了一种新的度量学习模型 VIB-DML 用于评分预测，限制潜空间特征向量的互信息以提高模型鲁棒性并满足欧氏距离的假设。

    

    近年来，个性化推荐技术蓬勃发展，成为研究热点之一。先后提出的矩阵分解模型和度量学习模型已被广泛研究和应用。后者使用欧氏距离而非前者所使用的点积来衡量潜空间向量。本文首次将变分信息瓶颈与度量学习模型相结合，提出了一种新的度量学习模型 VIB-DML（变分信息瓶颈距离度量学习）用于评分预测，限制潜空间特征向量的互信息，提高模型的鲁棒性并满足欧氏距离的假设。

    arXiv:2403.02794v1 Announce Type: cross  Abstract: In recent years, personalized recommendation technology has flourished and become one of the hot research directions. The matrix factorization model and the metric learning model which proposed successively have been widely studied and applied. The latter uses the Euclidean distance instead of the dot product used by the former to measure the latent space vector. While avoiding the shortcomings of the dot product, the assumption of Euclidean distance is neglected, resulting in limited recommendation quality of the model. In order to solve this problem, this paper combines the Variationl Information Bottleneck with metric learning model for the first time, and proposes a new metric learning model VIB-DML (Variational Information Bottleneck Distance Metric Learning) for rating prediction, which limits the mutual information of the latent space feature vector to improve the robustness of the model and satisfiy the assumption of Euclidean 
    
[^64]: 基于人类中心解释的半监督图表示学习用于预测脂肪肝病的研究

    Semi-Supervised Graph Representation Learning with Human-centric Explanation for Predicting Fatty Liver Disease

    [https://arxiv.org/abs/2403.02786](https://arxiv.org/abs/2403.02786)

    该研究在半监督学习框架内探索了图表示学习的潜力，通过人类中心解释提供了个性化特征重要性得分，以增强解释性和临床相关性。

    

    在临床环境中，特别是在预测脂肪肝病方面，由于有限的标记数据，这项研究探索了在半监督学习框架内利用图表示学习的潜力。通过利用图神经网络（GNNs），我们的方法构建了一个主题相似性图，从健康检查数据中识别风险模式。我们展示了在这一背景下各种GNN方法的有效性，即使有最少的标记样本。我们方法的核心是通过可解释的GNNs包含人类中心解释，为增强的可解释性和临床相关性提供个性化特征重要性得分，从而强调了我们的方法在促进健康实践方面的潜力，重点关注图表示学习和人类中心解释。

    arXiv:2403.02786v1 Announce Type: cross  Abstract: Addressing the challenge of limited labeled data in clinical settings, particularly in the prediction of fatty liver disease, this study explores the potential of graph representation learning within a semi-supervised learning framework. Leveraging graph neural networks (GNNs), our approach constructs a subject similarity graph to identify risk patterns from health checkup data. The effectiveness of various GNN approaches in this context is demonstrated, even with minimal labeled samples. Central to our methodology is the inclusion of human-centric explanations through explainable GNNs, providing personalized feature importance scores for enhanced interpretability and clinical relevance, thereby underscoring the potential of our approach in advancing healthcare practices with a keen focus on graph representation learning and human-centric explanation.
    
[^65]: QAP-SAT实例中真正困难的二次分配问题所在

    Where the Really Hard Quadratic Assignment Problems Are: the QAP-SAT instances

    [https://arxiv.org/abs/2403.02783](https://arxiv.org/abs/2403.02783)

    通过引入基于子模性的新QAP-SAT设计，研究二次分配问题的相变现象，提出了一个相变参数，可预测禁忌搜索中困难实例的解决难度。

    

    二次分配问题（QAP）是进化计算领域的一个重要领域，也在组合优化领域中更广泛地使用。本文研究了QAP的相变现象，它可以描述为问题的计算复杂性和可满足性在一定范围内的剧烈变化。为了探究这一现象，我们基于子模性介绍了一个新的QAP-SAT初始问题设计，以捕捉其困难性与新特性。并利用分支定界和禁忌搜索解这种分解的问题。随后提出了一个相变参数，表明禁忌搜索的相变满意度临界参数与解决难度高度相关，从而能够预测困难实例。

    arXiv:2403.02783v1 Announce Type: new  Abstract: The Quadratic Assignment Problem (QAP) is one of the major domains in the field of evolutionary computation, and more widely in combinatorial optimization. This paper studies the phase transition of the QAP, which can be described as a dramatic change in the problem's computational complexity and satisfiability, within a narrow range of the problem parameters. To approach this phenomenon, we introduce a new QAP-SAT design of the initial problem based on submodularity to capture its difficulty with new features. This decomposition is studied experimentally using branch-and-bound and tabu search solvers. A phase transition parameter is then proposed. The critical parameter of phase transition satisfaction and that of the solving effort are shown to be highly correlated for tabu search, thus allowing the prediction of difficult instances.
    
[^66]: EasyQuant: 一种用于LLM的高效无数据量化算法

    EasyQuant: An Efficient Data-free Quantization Algorithm for LLMs

    [https://arxiv.org/abs/2403.02775](https://arxiv.org/abs/2403.02775)

    EasyQuant是一种无需训练的、无需数据的仅针对权重的量化算法，旨在减少量化误差并保证LLM的泛化性能。

    

    大型语言模型(LLMs)在各种任务中已被证明要比传统方法优越得多。然而，它们昂贵的计算和高内存需求使其难以部署。模型量化是减少这种开销的有效方法。然而，大多数先前的工作中，量化模型是使用少量训练数据样本进行校准的，这可能会影响前人工作里量化后的LLMs对未知情况和任务的泛化性能。因此，在这项工作中，我们探讨了一个重要问题：我们是否可以为LLM设计一种无数据量化方法以保证其泛化性能？在这项工作中，我们提出了EasyQuant，一种用于LLM的无需训练和无数据的仅针对权重的量化算法。我们的观察表明，权重和量化范围中的异常值是减少量化误差的关键因素。因此，在EasyQuant中，我们保留了这些异常值（待续）。

    arXiv:2403.02775v1 Announce Type: new  Abstract: Large language models (LLMs) have proven to be very superior to conventional methods in various tasks. However, their expensive computations and high memory requirements are prohibitive for deployment. Model quantization is an effective method for reducing this overhead. The problem is that in most previous works, the quantized model was calibrated using few samples from the training data, which might affect the generalization of the quantized LLMs to unknown cases and tasks. Hence in this work, we explore an important question: Can we design a data-independent quantization method for LLMs to guarantee its generalization performance? In this work, we propose EasyQuant, a training-free and data-independent weight-only quantization algorithm for LLMs. Our observation indicates that two factors: outliers in the weight and quantization ranges, are essential for reducing the quantization error. Therefore, in EasyQuant, we leave the outliers (
    
[^67]: 通过有监督对比学习进行康复锻炼质量评估，结合硬负样本和软负样本

    Rehabilitation Exercise Quality Assessment through Supervised Contrastive Learning with Hard and Soft Negatives

    [https://arxiv.org/abs/2403.02772](https://arxiv.org/abs/2403.02772)

    这项研究引入了一种新的有监督对比学习框架，通过结合硬和软负样本，有效地解决了康复锻炼评估中样本稀缺的问题

    

    基于锻炼的康复计划已被证明在提高生活质量、降低死亡率和再住院率方面是有效的。利用人工智能驱动的虚拟康复，患者可以在家独立完成锻炼，利用AI算法分析锻炼数据，为患者提供反馈，并向临床医生更新他们的进展情况。这些计划通常会指定各种锻炼类型，这导致康复锻炼评估数据集面临独特挑战：虽然在整体训练样本中丰富，但这些数据集通常对每种具体锻练类型的样本数量有限。这种差异影响了现有方法训练具有小样本量的每种锻练的可泛化模型的能力。为了解决这个问题，我们的论文引入了一种新颖的带有硬负样本和软负样本的有监督对比学习框架，有效利用了整个

    arXiv:2403.02772v1 Announce Type: cross  Abstract: Exercise-based rehabilitation programs have proven to be effective in enhancing the quality of life and reducing mortality and rehospitalization rates. AI-driven virtual rehabilitation, which allows patients to independently complete exercises at home, utilizes AI algorithms to analyze exercise data, providing feedback to patients and updating clinicians on their progress. These programs commonly prescribe a variety of exercise types, leading to a distinct challenge in rehabilitation exercise assessment datasets: while abundant in overall training samples, these datasets often have a limited number of samples for each individual exercise type. This disparity hampers the ability of existing approaches to train generalizable models with such a small sample size per exercise. Addressing this issue, our paper introduces a novel supervised contrastive learning framework with hard and soft negative samples that effectively utilizes the entir
    
[^68]: 大型语言模型与机器学习在电子商务推荐中的新兴协同作用

    Emerging Synergies Between Large Language Models and Machine Learning in Ecommerce Recommendations

    [https://arxiv.org/abs/2403.02760](https://arxiv.org/abs/2403.02760)

    大型语言模型的兴起对电子商务推荐系统带来了新的发展机遇，突破了基于深度神经网络的推荐方法的局限性。

    

    随着电子商务和网络应用的蓬勃发展，推荐系统已成为我们日常生活中的重要组成部分，根据用户的偏好提供个性化推荐。深度神经网络（DNNs）通过模拟用户和商品之间的互动并融入其文本信息，取得了改善推荐系统的重大进展，但这些基于DNN的方法仍然存在一些限制，如难以有效理解用户的兴趣和捕捉文本信息。此外，大型语言模型（LLMs）的出现如ChatGPT和GPT-4，由于在语言理解等基本任务中具有卓越能力，已经彻底改变了自然语言处理（NLP）和人工智能（AI）领域。

    arXiv:2403.02760v1 Announce Type: new  Abstract: With the boom of e-commerce and web applications, recommender systems have become an important part of our daily lives, providing personalized recommendations based on the user's preferences. Although deep neural networks (DNNs) have made significant progress in improving recommendation systems by simulating the interaction between users and items and incorporating their textual information, these DNN-based approaches still have some limitations, such as the difficulty of effectively understanding users' interests and capturing textual information. It is not possible to generalize to different seen/unseen recommendation scenarios and reason about their predictions. At the same time, the emergence of large language models (LLMs), represented by ChatGPT and GPT-4, has revolutionized the fields of natural language processing (NLP) and artificial intelligence (AI) due to their superior capabilities in the basic tasks of language understandin
    
[^69]: 使用带有跳跃连接的去噪自编码器降低超声图像中的散斑噪声

    Speckle Noise Reduction in Ultrasound Images using Denoising Auto-encoder with Skip Connection

    [https://arxiv.org/abs/2403.02750](https://arxiv.org/abs/2403.02750)

    本文通过比较七种不同的散斑去除方法，证明带有跳跃连接的去噪自编码器在减少超声图像散斑噪声时能够有效保留特征和边缘。

    

    超声是一种广泛应用于非侵入性诊断的医学工具，但其图像通常包含散斑噪声，这可能降低图像的分辨率和信噪比。减少散斑噪声对于超声图像的预处理是一个至关重要的步骤。研究人员提出了几种散斑减少方法，但没有一种方法能够考虑所有相关因素。本文比较了七种这样的方法：中值、高斯、双边、平均、维纳、各向异性和不带跳跃连接的去噪自编码器及带有跳跃连接的去噪自编码器，从它们在保持特征和边缘的能力以及有效降噪方面进行了比较。

    arXiv:2403.02750v1 Announce Type: cross  Abstract: Ultrasound is a widely used medical tool for non-invasive diagnosis, but its images often contain speckle noise which can lower their resolution and contrast-to-noise ratio. This can make it more difficult to extract, recognize, and analyze features in the images, as well as impair the accuracy of computer-assisted diagnostic techniques and the ability of doctors to interpret the images. Reducing speckle noise, therefore, is a crucial step in the preprocessing of ultrasound images. Researchers have proposed several speckle reduction methods, but no single method takes all relevant factors into account. In this paper, we compare seven such methods: Median, Gaussian, Bilateral, Average, Weiner, Anisotropic and Denoising auto-encoder without and with skip connections in terms of their ability to preserve features and edges while effectively reducing noise. In an experimental study, a convolutional noise-removing auto-encoder with skip con
    
[^70]: CURATRON：完整健壮偏好数据用于大型语言模型的健壮对齐

    CURATRON: Complete Robust Preference Data for Robust Alignment of Large Language Models

    [https://arxiv.org/abs/2403.02745](https://arxiv.org/abs/2403.02745)

    本论文提出了一种新方法，通过彻底重校准偏好数据集中的价值观，以增强大型语言模型对问题的韧性。

    

    这篇论文解决了通过偏好学习（PL）将大型语言模型（LLMs）与人类价值观对齐的挑战，重点关注偏好数据集中不完整和损坏的问题。我们提出了一种新方法，通过彻底和完全地重新校准这些数据集中的价值观，以增强LLMs对问题的韧性。特别是，我们设计了一个有保证的多项式时间排名算法，可以增强几种现有模型的健壮性，比如经典的Bradley–Terry–Luce（BTL）（Bradley和Terry，1952）模型以及对其某些推广。据我们所知，我们的工作是第一个提出一种可证明在高概率下恢复{\epsilon}-最优排序的算法，同时允许每个模型响应多达O(n)扰动的成对比较结果。此外，我们展示了在部分观察设置下的健壮恢复结果。我们的实验证实了我们的算法

    arXiv:2403.02745v1 Announce Type: new  Abstract: This paper addresses the challenges of aligning large language models (LLMs) with human values via preference learning (PL), with a focus on the issues of incomplete and corrupted data in preference datasets. We propose a novel method for robustly and completely recalibrating values within these datasets to enhance LLMs resilience against the issues. In particular, we devise a guaranteed polynomial time ranking algorithm that robustifies several existing models, such as the classic Bradley--Terry--Luce (BTL) (Bradley and Terry, 1952) model and certain generalizations of it. To the best of our knowledge, our present work is the first to propose an algorithm that provably recovers an {\epsilon}-optimal ranking with high probability while allowing as large as O(n) perturbed pairwise comparison results per model response. Furthermore, we show robust recovery results in the partially observed setting. Our experiments confirm that our algorith
    
[^71]: 在高分辨率卫星图像中引导稀有物体检测

    Bootstrapping Rare Object Detection in High-Resolution Satellite Imagery

    [https://arxiv.org/abs/2403.02736](https://arxiv.org/abs/2403.02736)

    本文提出了一种在高分辨率卫星图像中引导稀有物体检测的方法，通过离线和在线基于聚类的采样方法，显著提高了正样本暴露率，实现了从2%到30%的正样本采样率增加，从而有效地实现了机器学习映射。

    

    稀有物体检测是应用地理空间机器学习中的一项基本任务，然而由于大量的高分辨率卫星或航空图像以及几乎没有标记的正样本，这往往是具有挑战性的。本文针对这一稀有物体检测任务的引导问题提出解决方案，假设没有标记数据，也没有有关感兴趣区域的空间先验信息。我们提出了新颖的离线和在线基于聚类的方法，用于采样贴片，这种方法在暴露正样本给人类标注者方面比随机采样要高效得多。我们将这些方法应用于肯尼亚和坦桑尼亚的Serengeti Mara地区的boma（牧群动物的小围场）识别。我们展示了检测效率的显著提升，将正样本采样率从2%（随机）提高到30%。这一进展使得即使只有有限的正样本标记，也能实现有效的机器学习映射。

    arXiv:2403.02736v1 Announce Type: cross  Abstract: Rare object detection is a fundamental task in applied geospatial machine learning, however is often challenging due to large amounts of high-resolution satellite or aerial imagery and few or no labeled positive samples to start with. This paper addresses the problem of bootstrapping such a rare object detection task assuming there is no labeled data and no spatial prior over the area of interest. We propose novel offline and online cluster-based approaches for sampling patches that are significantly more efficient, in terms of exposing positive samples to a human annotator, than random sampling. We apply our methods for identifying bomas, or small enclosures for herd animals, in the Serengeti Mara region of Kenya and Tanzania. We demonstrate a significant enhancement in detection efficiency, achieving a positive sampling rate increase from 2% (random) to 30%. This advancement enables effective machine learning mapping even with minima
    
[^72]: HARGPT：LLMs是否可以进行零样本人类活动识别？

    HARGPT: Are LLMs Zero-Shot Human Activity Recognizers?

    [https://arxiv.org/abs/2403.02727](https://arxiv.org/abs/2403.02727)

    HARGPT研究表明LLMs可以通过适当提示理解原始IMU数据，实现零样本人类活动识别，并在性能上优于传统机器学习和最先进深度分类模型。

    

    关于大型语言模型（LLMs）作为与网络物理系统（CPS）无缝集成的基础模型在解释物理世界方面的潜力存在持续的争论。本文通过进行案例研究来回答以下问题：LLMs是否能够进行零样本的人类活动识别（HAR）。我们的研究，HARGPT，通过展示LLMs可以理解原始IMU数据并以零样本方式执行HAR任务，仅需适当的提示，肯定了这个问题。HARGPT将原始IMU数据输入LLMs，并利用角色扮演和逐步思考策略进行提示。我们在GPT4上对HARGPT进行基准测试，使用了两个不同类间相似性的公共数据集，并比较了基于传统机器学习和最先进深度分类模型的各种基线。显著地，LLMs成功地从原始IMU数据中识别人类活动，并始终优于

    arXiv:2403.02727v1 Announce Type: cross  Abstract: There is an ongoing debate regarding the potential of Large Language Models (LLMs) as foundational models seamlessly integrated with Cyber-Physical Systems (CPS) for interpreting the physical world. In this paper, we carry out a case study to answer the following question: Are LLMs capable of zero-shot human activity recognition (HAR). Our study, HARGPT, presents an affirmative answer by demonstrating that LLMs can comprehend raw IMU data and perform HAR tasks in a zero-shot manner, with only appropriate prompts. HARGPT inputs raw IMU data into LLMs and utilizes the role-play and think step-by-step strategies for prompting. We benchmark HARGPT on GPT4 using two public datasets of different inter-class similarities and compare various baselines both based on traditional machine learning and state-of-the-art deep classification models. Remarkably, LLMs successfully recognize human activities from raw IMU data and consistently outperform 
    
[^73]: 生成AI中的偏见

    Bias in Generative AI

    [https://arxiv.org/abs/2403.02726](https://arxiv.org/abs/2403.02726)

    本研究揭示了生成AI工具中存在的系统性性别和种族偏见，以及对面部表情和外表的微妙偏见。

    

    本研究分析了三种流行的生成人工智能（AI）工具（Midjourney，Stable Diffusion和DALLE 2）生成的代表各种职业的图像，以调查AI生成器中潜在的偏见。我们的分析揭示了这些AI生成器存在的两个主要关注领域，包括（1）系统性的性别和种族偏见，以及（2）对面部表情和外表的微妙偏见。首先，我们发现这三种AI生成器都存在对女性和非裔美国人的偏见。此外，我们发现，我们分析中揭示的明显的性别和种族偏见，与劳动力统计数据或Google图像相比，甚至更加显著，加剧了社会中我们正在积极努力纠正的有害偏见。其次，我们的研究揭示了在表现情绪和外表方面更加微妙的偏见。例如，女性被描绘为年轻且更多地微笑。

    arXiv:2403.02726v1 Announce Type: cross  Abstract: This study analyzed images generated by three popular generative artificial intelligence (AI) tools - Midjourney, Stable Diffusion, and DALLE 2 - representing various occupations to investigate potential bias in AI generators. Our analysis revealed two overarching areas of concern in these AI generators, including (1) systematic gender and racial biases, and (2) subtle biases in facial expressions and appearances. Firstly, we found that all three AI generators exhibited bias against women and African Americans. Moreover, we found that the evident gender and racial biases uncovered in our analysis were even more pronounced than the status quo when compared to labor force statistics or Google images, intensifying the harmful biases we are actively striving to rectify in our society. Secondly, our study uncovered more nuanced prejudices in the portrayal of emotions and appearances. For example, women were depicted as younger with more smi
    
[^74]: 图神经网络的最小拓扑攻击

    Minimum Topology Attacks for Graph Neural Networks

    [https://arxiv.org/abs/2403.02723](https://arxiv.org/abs/2403.02723)

    提出了一种新型的最小预算拓扑攻击，名为MiBTack，旨在自适应地找到对每个节点成功攻击所需的最小扰动。

    

    随着图神经网络（GNNs）的流行，它们对拓扑对抗性攻击的稳健性受到了重视。之前提出了许多攻击方法，但主要集中在固定预算攻击上，目的是在为目标节点找到固定预算内最具敌对性的扰动。然而，考虑到每个节点的稳健性不同，固定预算会造成一个困境，即在预算相对较小时找不到成功扰动，而如果预算太大，导致多余的扰动将伤害不可见性。为了突破这一困境，我们提出了一种新类型的拓扑攻击，称为最小预算拓扑攻击，旨在自适应地找到对每个节点成功攻击所需的最小扰动。为此，我们提出了一种攻击模型，名为MiBTack，基于动态投影梯度下降算法，可以有效地

    arXiv:2403.02723v1 Announce Type: new  Abstract: With the great popularity of Graph Neural Networks (GNNs), their robustness to adversarial topology attacks has received significant attention. Although many attack methods have been proposed, they mainly focus on fixed-budget attacks, aiming at finding the most adversarial perturbations within a fixed budget for target node. However, considering the varied robustness of each node, there is an inevitable dilemma caused by the fixed budget, i.e., no successful perturbation is found when the budget is relatively small, while if it is too large, the yielding redundant perturbations will hurt the invisibility. To break this dilemma, we propose a new type of topology attack, named minimum-budget topology attack, aiming to adaptively find the minimum perturbation sufficient for a successful attack on each node. To this end, we propose an attack model, named MiBTack, based on a dynamic projected gradient descent algorithm, which can effectively
    
[^75]: 多尺度子图对比学习

    Multi-Scale Subgraph Contrastive Learning

    [https://arxiv.org/abs/2403.02719](https://arxiv.org/abs/2403.02719)

    提出了一种多尺度子图对比学习方法，能够表征细粒度语义信息，解决了在图增强后原有假设不再成立的问题

    

    图级对比学习旨在通过对比两个增强图来学习每个图的表示，受到了广泛关注。先前的研究通常简单地假设一个图及其增强图为正对，否则为负对。然而，众所周知，图结构通常复杂且多尺度，这带来了一个根本问题：在图增强后，先前的假设是否仍然成立？通过实验分析，我们发现增强图结构的语义信息可能不一致于原始图结构，并且两个增强图是正对还是负对与多尺度结构密切相关。基于这一发现，我们提出了一种能够表征细粒度语义信息的多尺度子图对比学习方法。具体地，我们生成全局和局部

    arXiv:2403.02719v1 Announce Type: new  Abstract: Graph-level contrastive learning, aiming to learn the representations for each graph by contrasting two augmented graphs, has attracted considerable attention. Previous studies usually simply assume that a graph and its augmented graph as a positive pair, otherwise as a negative pair. However, it is well known that graph structure is always complex and multi-scale, which gives rise to a fundamental question: after graph augmentation, will the previous assumption still hold in reality? By an experimental analysis, we discover the semantic information of an augmented graph structure may be not consistent as original graph structure, and whether two augmented graphs are positive or negative pairs is highly related with the multi-scale structures. Based on this finding, we propose a multi-scale subgraph contrastive learning method which is able to characterize the fine-grained semantic information. Specifically, we generate global and local 
    
[^76]: 跨越语言视野：越南大型语言模型的微调和综合评估

    Crossing Linguistic Horizons: Finetuning and Comprehensive Evaluation of Vietnamese Large Language Models

    [https://arxiv.org/abs/2403.02715](https://arxiv.org/abs/2403.02715)

    该研究通过对LLMs在越南语上进行微调和综合评估，发现微调后的模型在越南语理解和生成方面表现出良好能力，同时指出模型参数数量与性能之间存在着权衡关系，训练或微调数据集的质量是影响LLM性能的关键因素。

    

    最近大型语言模型（LLMs）的进展强调了它们在人工智能发展中的重要性。然而，尽管在多语言数据集上进行了广泛的预训练，但目前开源的LLMs在处理越南语方面的效果有限。这一挑战是由于缺乏专门针对越南语LLM评估的系统化基准数据集和指标。为了缓解这些问题，我们专门为越南语进行了LLM的微调，并开发了一个涵盖10个常见任务和31个指标的综合评估框架。我们的评估结果表明，经过微调的LLMs在越南语方面表现出了增强的理解和生成能力。此外，我们的分析表明，具有更多参数的模型可能会带来更多的偏见和未校准的输出，而影响LLM性能的关键因素是训练或微调数据集的质量。

    arXiv:2403.02715v1 Announce Type: cross  Abstract: Recent advancements in large language models (LLMs) have underscored their importance in the evolution of artificial intelligence. However, despite extensive pretraining on multilingual datasets, available open-sourced LLMs exhibit limited effectiveness in processing Vietnamese. The challenge is exacerbated by the absence of systematic benchmark datasets and metrics tailored for Vietnamese LLM evaluation. To mitigate these issues, we have finetuned LLMs specifically for Vietnamese and developed a comprehensive evaluation framework encompassing 10 common tasks and 31 metrics. Our evaluation results reveal that the fine-tuned LLMs exhibit enhanced comprehension and generative capabilities in Vietnamese. Moreover, our analysis indicates that models with more parameters can introduce more biases and uncalibrated outputs and the key factor influencing LLM performance is the quality of the training or fine-tuning datasets. These insights und
    
[^77]: 改进游戏玩法的对战游戏自适应背景音乐

    Fighting Game Adaptive Background Music for Improved Gameplay

    [https://arxiv.org/abs/2403.02701](https://arxiv.org/abs/2403.02701)

    本文介绍了一种通过添加自适应特性改进DareFightingICE游戏玩法的背景音乐方法，并通过实验证明Blind DL AI在使用自适应背景音乐时比不使用时表现更好。

    

    本文介绍了我们通过添加自适应特性来增强DareFightingICE中背景音乐（BGM）的工作。自适应BGM由三种不同类别的乐器组成，播放2022年DareFightingICE比赛中获胜者音效设计的BGM。BGM通过改变每个类别乐器的音量来进行调整。每个类别与游戏的不同元素相连。我们通过使用一种只使用音频作为输入的深度强化学习AI代理（Blind DL AI）来运行实验以评估自适应BGM。结果显示，与没有自适应BGM时相比，Blind DL AI在玩游戏时表现得更好。

    arXiv:2403.02701v1 Announce Type: cross  Abstract: This paper presents our work to enhance the background music (BGM) in DareFightingICE by adding adaptive features. The adaptive BGM consists of three different categories of instruments playing the BGM of the winner sound design from the 2022 DareFightingICE Competition. The BGM adapts by changing the volume of each category of instruments. Each category is connected to a different element of the game. We then run experiments to evaluate the adaptive BGM by using a deep reinforcement learning AI agent that only uses audio as input (Blind DL AI). The results show that the performance of the Blind DL AI improves while playing with the adaptive BGM as compared to playing without the adaptive BGM.
    
[^78]: 面向大型语言模型的隐私感知语义缓存

    Privacy-Aware Semantic Cache for Large Language Models

    [https://arxiv.org/abs/2403.02694](https://arxiv.org/abs/2403.02694)

    MeanCache是一种面向LLMs的语义缓存，能够识别语义上相似的查询，从而减少查询成本，服务提供商负载和环境影响。

    

    大型语言模型（LLMs）如ChatGPT、Google Bard、Claude和Llama 2彻底改变了自然语言处理和搜索引擎动态。然而，这些模型造成了异常高的计算成本。本文介绍了MeanCache，一种用于LLMs的语义缓存，它能够识别语义上相似的查询以确定缓存命中或未命中。

    arXiv:2403.02694v1 Announce Type: cross  Abstract: Large Language Models (LLMs) like ChatGPT, Google Bard, Claude, and Llama 2 have revolutionized natural language processing and search engine dynamics. However, these models incur exceptionally high computational costs. For instance, GPT-3 consists of 175 billion parameters and inference on these models also demands billions of floating-point operations. Caching is a natural solution to reduce LLM inference costs on repeated queries. However, existing caching methods are incapable of finding semantic similarities among LLM queries, leading to unacceptable false hit-and-miss rates.   This paper introduces MeanCache, a semantic cache for LLMs that identifies semantically similar queries to determine cache hit or miss. Using MeanCache, the response to a user's semantically similar query can be retrieved from a local cache rather than re-querying the LLM, thus reducing costs, service provider load, and environmental impact. MeanCache lever
    
[^79]: DOCTOR: 针对时间漂移热变化的动态芯片矫正方法，用于自我校正的光子张量加速器

    DOCTOR: Dynamic On-Chip Remediation Against Temporally-Drifting Thermal Variations Toward Self-Corrected Photonic Tensor Accelerators

    [https://arxiv.org/abs/2403.02688](https://arxiv.org/abs/2403.02688)

    首次提出了轻量级的动态片上矫正框架DOCTOR，针对光子张量加速器中的时间漂移变化问题，实现自适应、原位准确度恢复

    

    Photonic computing作为加速计算密集型人工智能(AI)工作负载的一种有前途的解决方案已经出现，特别是在资源有限、延迟敏感的边缘计算环境中提供了无与伦比的速度和能量效率。然而，模拟光子张量加速器的部署遇到了可靠性挑战，由于硬件噪声和环境变化。虽然已经提出了脱机噪声感知训练和片上训练来增强对具有适度、静态噪声的光学神经加速器的变化容忍度，但我们观察到由于时间漂移变化导致的显著性能下降，这需要实时、原位校准机制。为了解决这些具有挑战性的可靠性问题，我们首次提出了一种轻量级的动态片上矫正框架，称为DOCTOR，提供适应性的、原位的准确度恢复，针对时间

    arXiv:2403.02688v1 Announce Type: cross  Abstract: Photonic computing has emerged as a promising solution for accelerating computation-intensive artificial intelligence (AI) workloads, offering unparalleled speed and energy efficiency, especially in resource-limited, latency-sensitive edge computing environments. However, the deployment of analog photonic tensor accelerators encounters reliability challenges due to hardware noises and environmental variations. While off-chip noise-aware training and on-chip training have been proposed to enhance the variation tolerance of optical neural accelerators with moderate, static noises, we observe a notable performance degradation over time due to temporally drifting variations, which requires a real-time, in-situ calibration mechanism. To tackle this challenging reliability issues, for the first time, we propose a lightweight dynamic on-chip remediation framework, dubbed DOCTOR, providing adaptive, in-situ accuracy recovery against temporally
    
[^80]: 增强的DareFightingICE竞赛：声音设计和AI竞赛

    Enhanced DareFightingICE Competitions: Sound Design and AI Competitions

    [https://arxiv.org/abs/2403.02687](https://arxiv.org/abs/2403.02687)

    本文介绍了一个增强版的DareFightingICE平台，分为声音设计比赛和AI比赛，通过改进音频系统和发送音频数据的方法，使得平台更容易为视障玩家添加新功能，并改进了声音设计竞赛的评估方法。

    

    本文介绍了一个新的改进版DareFightingICE平台，这是一个专注于视障玩家（VIPs）的格斗游戏平台，基于Unity游戏引擎。它将DareFightingICE竞赛分为两个独立的比赛，分别是DareFightingICE Sound Design Competition和DareFightingICE AI Competition，将在2024年IEEE游戏会议（CoG）上举行，使用一个新平台。这个新平台是旧DareFightingICE平台的增强版本，拥有更好的音频系统以传达3D声音，还有更好的方法将音频数据发送给AI代理。通过这种增强和利用Unity，新的DareFightingICE平台在为VIPs和未来音频研究添加新功能方面更加易于访问。本文还改进了评估声音设计的评估方法，这将确保VIPs获得更好的声音设计。

    arXiv:2403.02687v1 Announce Type: cross  Abstract: This paper presents a new and improved DareFightingICE platform, a fighting game platform with a focus on visually impaired players (VIPs), in the Unity game engine. It also introduces the separation of the DareFightingICE Competition into two standalone competitions called DareFightingICE Sound Design Competition and DareFightingICE AI Competition--at the 2024 IEEE Conference on Games (CoG)--in which a new platform will be used. This new platform is an enhanced version of the old DareFightingICE platform, having a better audio system to convey 3D sound and a better way to send audio data to AI agents. With this enhancement and by utilizing Unity, the new DareFightingICE platform is more accessible in terms of adding new features for VIPs and future audio research. This paper also improves the evaluation method for evaluating sound designs in the Sound Design Competition which will ensure a better sound design for VIPs as this competit
    
[^81]: 以无线速度学习：AI-启用MIMO的在线实时学习在NextG中的应用

    Learning at the Speed of Wireless: Online Real-Time Learning for AI-Enabled MIMO in NextG

    [https://arxiv.org/abs/2403.02651](https://arxiv.org/abs/2403.02651)

    将AI/ML工具应用于MIMO，实现对于NextG蜂窝网络中无线环境动态性的在线实时学习和适应性调节。

    

    人工智能（AI）和机器学习（ML）与空中接口的整合被视为下一代（NextG）蜂窝网络的关键技术。在空中接口，多输入多输出（MIMO）及其变种如多用户MIMO（MU-MIMO）和大规模/全维 MIMO 已成为连续发展的蜂窝网络中的关键推动因素，面临日益复杂的设计挑战。开始积极调研利用AI/ML工具来解决MIMO挑战，成为朝着AI启用NextG空中接口的关键一步。 在NextG空中接口，基础无线环境将极为动态，由MIMO操作（如MU-MIMO调度和秩/链路调整）在亚毫秒级别执行操作适应。鉴于极其庞大的操作适应可能性，我们认为在线实时AI / ML-基

    arXiv:2403.02651v1 Announce Type: cross  Abstract: Integration of artificial intelligence (AI) and machine learning (ML) into the air interface has been envisioned as a key technology for next-generation (NextG) cellular networks. At the air interface, multiple-input multiple-output (MIMO) and its variants such as multi-user MIMO (MU-MIMO) and massive/full-dimension MIMO have been key enablers across successive generations of cellular networks with evolving complexity and design challenges. Initiating active investigation into leveraging AI/ML tools to address these challenges for MIMO becomes a critical step towards an AI-enabled NextG air interface. At the NextG air interface, the underlying wireless environment will be extremely dynamic with operation adaptations performed on a sub-millisecond basis by MIMO operations such as MU-MIMO scheduling and rank/link adaptation. Given the enormously large number of operation adaptation possibilities, we contend that online real-time AI/ML-ba
    
[^82]: 移除平方根：一种新的高效标度不变版本的AdaGrad

    Remove that Square Root: A New Efficient Scale-Invariant Version of AdaGrad

    [https://arxiv.org/abs/2403.02648](https://arxiv.org/abs/2403.02648)

    KATE是一种新的优化算法，提出了一种与AdaGrad标度不变的适应方法，并在广义线性模型和一般的非凸问题中证明了其标度不变性。数值实验结果表明，KATE在各种场景中均优于AdaGrad并与Adam性能匹配/超越。

    

    自适应方法在机器学习中非常流行，因为它们可以降低学习速率调整的成本。本文引入了一种名为KATE的新型优化算法，它提出了一个著名的AdaGrad算法的标度不变适应。我们证明了KATE在广义线性模型案例中的标度不变性。此外，对于一般的光滑非凸问题，我们为KATE建立了一个收敛速率为$O \left(\frac{\log T}{\sqrt{T}} \right)$，与AdaGrad和Adam的最佳收敛速率相匹配。我们还通过不同问题的数值实验将KATE与其他最先进的自适应算法Adam和AdaGrad进行了比较，包括在真实数据上进行图像分类和文本分类等复杂机器学习任务。结果表明，在所有考虑到的场景中，KATE始终胜过AdaGrad，并且在性能上匹配/超越Adam。

    arXiv:2403.02648v1 Announce Type: cross  Abstract: Adaptive methods are extremely popular in machine learning as they make learning rate tuning less expensive. This paper introduces a novel optimization algorithm named KATE, which presents a scale-invariant adaptation of the well-known AdaGrad algorithm. We prove the scale-invariance of KATE for the case of Generalized Linear Models. Moreover, for general smooth non-convex problems, we establish a convergence rate of $O \left(\frac{\log T}{\sqrt{T}} \right)$ for KATE, matching the best-known ones for AdaGrad and Adam. We also compare KATE to other state-of-the-art adaptive algorithms Adam and AdaGrad in numerical experiments with different problems, including complex machine learning tasks like image classification and text classification on real data. The results indicate that KATE consistently outperforms AdaGrad and matches/surpasses the performance of Adam in all considered scenarios.
    
[^83]: FinReport: 通过新闻因素分析模型解释可解释的股票盈利预测

    FinReport: Explainable Stock Earnings Forecasting via News Factor Analyzing Model

    [https://arxiv.org/abs/2403.02647](https://arxiv.org/abs/2403.02647)

    FinReport是一个自动系统，通过金融新闻公告和多因素模型来生成专业的股票盈利预测报告，旨在帮助普通投资者收集信息、分析数据并生成报告。

    

    arXiv:2403.02647v1 公告类型: 跨领域 摘要: 由于实际情况下投资者的需求，股票盈利预测这一任务受到了相当多的关注。然而，与金融机构相比，普通投资者很难挖掘因素并分析新闻。另一方面，尽管金融领域的大型语言模型可以以对话机器人的形式为用户提供服务，但仍需要用户具备金融知识提出合理问题。为了提高用户体验，我们旨在构建一个自动系统，名为FinReport，以便普通投资者收集信息、分析信息，并在总结后生成报告。

    arXiv:2403.02647v1 Announce Type: cross  Abstract: The task of stock earnings forecasting has received considerable attention due to the demand investors in real-world scenarios. However, compared with financial institutions, it is not easy for ordinary investors to mine factors and analyze news. On the other hand, although large language models in the financial field can serve users in the form of dialogue robots, it still requires users to have financial knowledge to ask reasonable questions. To serve the user experience, we aim to build an automatic system, FinReport, for ordinary investors to collect information, analyze it, and generate reports after summarizing.   Specifically, our FinReport is based on financial news announcements and a multi-factor model to ensure the professionalism of the report. The FinReport consists of three modules: news factorization module, return forecasting module, risk assessment module. The news factorization module involves understanding news infor
    
[^84]: PPS-QMIX: 周期参数共享用于加速多智体强化学习的收敛

    PPS-QMIX: Periodically Parameter Sharing for Accelerating Convergence of Multi-Agent Reinforcement Learning

    [https://arxiv.org/abs/2403.02635](https://arxiv.org/abs/2403.02635)

    提出了三种简单的新方法来加速多智体强化学习训练过程，即平均周期参数共享（A-PPS）、奖励可伸缩性周期参数共享（RS-PPS）和部分个性化周期参数共享（PP-PPS）机制。

    

    训练多智体强化学习（MARL）是一个耗时的过程，因为每个智体的分布偏移导致的。一个缺点是MARL中每个智体的策略是独立的，实际上是合作的。因此，多智体强化学习领域的一个重要问题是如何有效加速训练过程。为了解决这个问题，当前研究利用跨多智体的中心化功能（CF）来学习每个智体团队奖励的贡献。然而，基于CF的方法会在值网络估计中引入其他智体的联合误差。受到联邦学习的启发，我们提出了三种简单的新方法，即平均周期参数共享（A-PPS）、奖励可伸缩性周期参数共享（RS-PPS）和部分个性化周期参数共享（PP-PPS）机制来加速MARL训练。智体在训练过程中周期性地共享Q值网络。

    arXiv:2403.02635v1 Announce Type: new  Abstract: Training for multi-agent reinforcement learning(MARL) is a time-consuming process caused by distribution shift of each agent. One drawback is that strategy of each agent in MARL is independent but actually in cooperation. Thus, a vertical issue in multi-agent reinforcement learning is how to efficiently accelerate training process. To address this problem, current research has leveraged a centralized function(CF) across multiple agents to learn contribution of the team reward for each agent. However, CF based methods introduce joint error from other agents in estimation of value network. In so doing, inspired by federated learning, we propose three simple novel approaches called Average Periodically Parameter Sharing(A-PPS), Reward-Scalability Periodically Parameter Sharing(RS-PPS) and Partial Personalized Periodically Parameter Sharing(PP-PPS) mechanism to accelerate training of MARL. Agents share Q-value network periodically during the
    
[^85]: Pareto-Optimal Estimation and Policy Learning on Short-term and Long-term Treatment Effects

    Pareto-Optimal Estimation and Policy Learning on Short-term and Long-term Treatment Effects

    [https://arxiv.org/abs/2403.02624](https://arxiv.org/abs/2403.02624)

    该论文提出了帕累托最优估计和策略学习的方法，用于确定如何在短期和长期治疗效果之间进行权衡从而实现最佳治疗。

    

    这篇论文专注于发展帕累托最优估计和策略学习，以确定最有效的治疗方法，从而最大化来自短期和长期效果的总奖励，这可能会相互冲突。 例如，药物剂量的增加可能会提高患者康复速度（短期），但也可能导致严重的长期副作用。虽然最近的研究已经探讨了有关短期或长期效应或两者的问题，但如何在它们之间取得平衡以实现最佳治疗仍然是一个悬而未决的挑战。此外，当使用传统因果表示学习直接估计多个目标时，各种任务之间的优化方向也可能发生冲突。在这篇论文中，我们系统地研究了这些问题，并引入了一个帕累托有效算法，包括帕累托最优估计（POE）和帕累托最优策略学习（POPL）。

    arXiv:2403.02624v1 Announce Type: cross  Abstract: This paper focuses on developing Pareto-optimal estimation and policy learning to identify the most effective treatment that maximizes the total reward from both short-term and long-term effects, which might conflict with each other. For example, a higher dosage of medication might increase the speed of a patient's recovery (short-term) but could also result in severe long-term side effects. Although recent works have investigated the problems about short-term or long-term effects or the both, how to trade-off between them to achieve optimal treatment remains an open challenge. Moreover, when multiple objectives are directly estimated using conventional causal representation learning, the optimization directions among various tasks can conflict as well. In this paper, we systematically investigate these issues and introduce a Pareto-Efficient algorithm, comprising Pareto-Optimal Estimation (POE) and Pareto-Optimal Policy Learning (POPL
    
[^86]: 自主驾驶的世界模型：一项初步调查

    World Models for Autonomous Driving: An Initial Survey

    [https://arxiv.org/abs/2403.02622](https://arxiv.org/abs/2403.02622)

    世界模型在自主驾驶领域的重要性和作用，是通过准确预测未来事件和评估其影响来帮助决策过程，从而推动自主驾驶技术发展的革命性方法。

    

    在自主驾驶领域不断发展的背景下，准确预测未来事件并评估其影响对于安全和效率至关重要，关键地帮助决策过程。世界模型已经成为一种革命性方法，使自主驾驶系统能够综合和解释大量传感器数据，从而预测潜在的未来情景并弥补信息缺口。本文对自主驾驶中世界模型的当前状态和未来发展进行了初步审查，涵盖了其理论基础、实际应用以及旨在克服现有限制的正在进行的研究工作。强调了世界模型在推动自主驾驶技术发展中的重要作用，本调查旨在成为研究社区的基础参考，便于快速获得和应用。

    arXiv:2403.02622v1 Announce Type: cross  Abstract: In the rapidly evolving landscape of autonomous driving, the capability to accurately predict future events and assess their implications is paramount for both safety and efficiency, critically aiding the decision-making process. World models have emerged as a transformative approach, enabling autonomous driving systems to synthesize and interpret vast amounts of sensor data, thereby predicting potential future scenarios and compensating for information gaps. This paper provides an initial review of the current state and prospective advancements of world models in autonomous driving, spanning their theoretical underpinnings, practical applications, and the ongoing research efforts aimed at overcoming existing limitations. Highlighting the significant role of world models in advancing autonomous driving technologies, this survey aspires to serve as a foundational reference for the research community, facilitating swift access to and com
    
[^87]: 工业物理系统细粒度自适应异常诊断的无监督时空状态估计

    Unsupervised Spatio-Temporal State Estimation for Fine-grained Adaptive Anomaly Diagnosis of Industrial Cyber-physical Systems

    [https://arxiv.org/abs/2403.02616](https://arxiv.org/abs/2403.02616)

    提出了一种细粒度自适应异常诊断方法（MAD-Transformer），通过构建时间状态矩阵和空间状态矩阵来揭示工业CPS工作状态的时空关联关系和演变机制

    

    精确检测和诊断异常行为，如多变量时间序列（MTS）中的网络攻击，对于确保工业物理系统（CPS）的稳定有效运行至关重要。然而，现有研究很少关注系统工作状态之间的逻辑依赖关系，并且难以解释异常信号的演变机制。为了揭示工业CPS工作状态的时空关联关系和演变机制，本文提出了一种细粒度自适应异常诊断方法（即MAD-Transformer），用于识别和诊断MTS中的异常。

    arXiv:2403.02616v1 Announce Type: cross  Abstract: Accurate detection and diagnosis of abnormal behaviors such as network attacks from multivariate time series (MTS) are crucial for ensuring the stable and effective operation of industrial cyber-physical systems (CPS). However, existing researches pay little attention to the logical dependencies among system working states, and have difficulties in explaining the evolution mechanisms of abnormal signals. To reveal the spatio-temporal association relationships and evolution mechanisms of the working states of industrial CPS, this paper proposes a fine-grained adaptive anomaly diagnosis method (i.e. MAD-Transformer) to identify and diagnose anomalies in MTS. MAD-Transformer first constructs a temporal state matrix to characterize and estimate the change patterns of the system states in the temporal dimension. Then, to better locate the anomalies, a spatial state matrix is also constructed to capture the inter-sensor state correlation rel
    
[^88]: 大型语言模型和视频游戏：初步范围审查

    Large Language Models and Video Games: A Preliminary Scoping Review

    [https://arxiv.org/abs/2403.02613](https://arxiv.org/abs/2403.02613)

    大型语言模型在视频游戏领域的研究正在迅速发展，本文通过初步范围审查了76篇关于LLMs和视频游戏的论文，为未来研究和评论奠定了基础。

    

    大型语言模型（LLMs）在视频游戏的设计、开发和研究中具有有趣的潜力。 本文基于游戏中生成人工智能的几十年前的研究，许多研究人员加快了对LLMs在游戏中的力量和潜力进行研究。 鉴于最近LLM相关研究在游戏领域的激增，已经有大量相关研究可供调查。 为了捕捉LLM在游戏中的研究状态，在未来工作的基础上，我们进行了一项关于迄今为止已发表的相关论文的初步范围审查。 本文审查了2022年至2024年初发表的76篇有关LLMs和视频游戏的论文，重点关注游戏人工智能、游戏开发、叙事以及游戏研究和评论等关键领域。 我们的论文提供了该领域的初步研究现状，并为未来关于此主题的研究和评论奠定了基础。

    arXiv:2403.02613v1 Announce Type: cross  Abstract: Large language models (LLMs) hold interesting potential for the design, development, and research of video games. Building on the decades of prior research on generative AI in games, many researchers have sped to investigate the power and potential of LLMs for games. Given the recent spike in LLM-related research in games, there is already a wealth of relevant research to survey. In order to capture a snapshot of the state of LLM research in games, and to help lay the foundation for future work, we carried out an initial scoping review of relevant papers published so far. In this paper, we review 76 papers published between 2022 to early 2024 on LLMs and video games, with key focus areas in game AI, game development, narrative, and game research and reviews. Our paper provides an early state of the field and lays the groundwork for future research and reviews on this topic.
    
[^89]: 一种统一的显微镜焦外模糊去除框架: 多金字塔变换器和对比学习

    A Unified Framework for Microscopy Defocus Deblur with Multi-Pyramid Transformer and Contrastive Learning

    [https://arxiv.org/abs/2403.02611](https://arxiv.org/abs/2403.02611)

    该论文提出了一个统一的框架，结合了多金字塔变换器和扩展频率对比正规化，以解决显微镜去模糊中的长距离交互和特征不足挑战。

    

    虚焦模糊是显微镜成像中的持续问题，对病理解释和细胞显微镜和显微手术中的医疗干预造成伤害。为了解决这一问题，提出了一个包括多金字塔变换器（MPT）和扩展频率对比正规化（EFCR）的统一框架，以解决显微镜去模糊中的两个突出挑战：较长的注意力跨度和特征不足。MPT在每个网络阶段使用显式金字塔结构，集成了跨尺度窗口注意力（CSWA）、内尺度通道注意力（ISCA）和特征增强前向网络（FEFN），以捕获长距离跨尺度空间交互和全局通道上下文。EFCR通过探索不同频段的潜在去模糊信号来解决特征不足的问题。它还使去模糊知识传输，从额外数据中学习跨域信息。

    arXiv:2403.02611v1 Announce Type: cross  Abstract: Defocus blur is a persistent problem in microscope imaging that poses harm to pathology interpretation and medical intervention in cell microscopy and microscope surgery. To address this problem, a unified framework including multi-pyramid transformer (MPT) and extended frequency contrastive regularization (EFCR) is proposed to tackle two outstanding challenges in microscopy deblur: longer attention span and feature deficiency. The MPT employs an explicit pyramid structure at each network stage that integrates the cross-scale window attention (CSWA), the intra-scale channel attention (ISCA), and the feature-enhancing feed-forward network (FEFN) to capture long-range cross-scale spatial interaction and global channel context. The EFCR addresses the feature deficiency problem by exploring latent deblur signals from different frequency bands. It also enables deblur knowledge transfer to learn cross-domain information from extra data, impr
    
[^90]: ChatGPT4PCG 2比赛：为科学鸟级别生成设计提示工程

    ChatGPT4PCG 2 Competition: Prompt Engineering for Science Birds Level Generation

    [https://arxiv.org/abs/2403.02610](https://arxiv.org/abs/2403.02610)

    本文介绍了2024年IEEE游戏大会上第二届ChatGPT4PCG比赛，引入多样性作为新的指标，允许提交Python程序以实现更灵活的先进提示工程方法。

    

    本文介绍了2024年IEEE游戏大会上第二届ChatGPT4PCG比赛。在这一届比赛中，我们沿袭第一届的基础上做出了几项改进和变化。我们引入了一个新的评估指标，并允许参与者以更灵活的格式提交作品，并对评估流程进行了几项改进。延续第一届比赛的精神，我们旨在促进和探索提示工程（PE）在程序内容生成（PCG）中的应用。虽然第一次比赛取得了成功，但也受到了各种限制的阻碍；我们旨在在这次比赛中缓解这些限制。我们引入了多样性作为一个新的指标，以阻止产生重复结构的作品。此外，为了更灵活地实现先进的PE方法，我们允许提交Python程序而不是提示文本文件，这些方法可能需要控制流，包括条件

    arXiv:2403.02610v1 Announce Type: new  Abstract: This paper presents the second ChatGPT4PCG competition at the 2024 IEEE Conference on Games. In this edition of the competition, we follow the first edition, but make several improvements and changes. We introduce a new evaluation metric along with allowing a more flexible format for participants' submissions and making several improvements to the evaluation pipeline. Continuing from the first edition, we aim to foster and explore the realm of prompt engineering (PE) for procedural content generation (PCG). While the first competition saw success, it was hindered by various limitations; we aim to mitigate these limitations in this edition. We introduce diversity as a new metric to discourage submissions aimed at producing repetitive structures. Furthermore, we allow submission of a Python program instead of a prompt text file for greater flexibility in implementing advanced PE approaches, which may require control flow, including conditi
    
[^91]: MEBS: 多任务端到端出价遮蔽用于多槽位展示广告

    MEBS: Multi-task End-to-end Bid Shading for Multi-slot Display Advertising

    [https://arxiv.org/abs/2403.02607](https://arxiv.org/abs/2403.02607)

    本研究引入了出价遮蔽到多槽位展示广告中，通过MEBS方法实现了竞价价格调整，并在理论上证明了其最优性，在实验证明了其性能有效性和效率，实现了毛利量的7.01%增长和投资回报率的7.42%增长

    

    arXiv:2403.02607v1 公告类型: 交叉摘要: 在线竞价和拍卖是在线广告行业的关键方面。传统上，只有一个广告槽位用于广告展示，大多数当前研究都集中在此。如今，多槽位展示广告逐渐流行起来，可以在列表中展示许多广告，并整体展示给用户。然而，多槽位展示广告导致不同的成本效益。广告主有动机调整竞标价格，以赢得最经济的广告位置。在这项研究中，我们引入了出价遮蔽到多槽位展示广告中，通过一种多任务端到端出价遮蔽（MEBS）方法进行竞价价格调整。我们在理论上证明了我们方法的最优性，并通过实验证明了其性能。通过大量的离线和在线实验，我们展示了我们方法的有效性和效率，并获得了毛利量的7.01%增长，投资回报率的7.42%增长。

    arXiv:2403.02607v1 Announce Type: cross  Abstract: Online bidding and auction are crucial aspects of the online advertising industry. Conventionally, there is only one slot for ad display and most current studies focus on it. Nowadays, multi-slot display advertising is gradually becoming popular where many ads could be displayed in a list and shown as a whole to users. However, multi-slot display advertising leads to different cost-effectiveness. Advertisers have the incentive to adjust bid prices so as to win the most economical ad positions. In this study, we introduce bid shading into multi-slot display advertising for bid price adjustment with a Multi-task End-to-end Bid Shading(MEBS) method. We prove the optimality of our method theoretically and examine its performance experimentally. Through extensive offline and online experiments, we demonstrate the effectiveness and efficiency of our method, and we obtain a 7.01% lift in Gross Merchandise Volume, a 7.42% lift in Return on Inv
    
[^92]: MUSIC: 具有不精确和精确方法的分布式优化加速收敛

    MUSIC: Accelerated Convergence for Distributed Optimization With Inexact and Exact Methods

    [https://arxiv.org/abs/2403.02589](https://arxiv.org/abs/2403.02589)

    提出了一个名为MUSIC的加速框架，允许每个代理执行多个本地更新和每个迭代中的单个组合，同时将不精确和精确的分布式优化方法结合，实现了加速的线性收敛和高通信效率。

    

    梯度型分布式优化方法已经成为解决网络化代理系统上的最小化学习任务的最重要工具之一。然而，每次迭代只能实现一个梯度更新，难以实现收敛加速。在本文中，我们提出了一个名为MUSIC的加速框架，允许每个代理执行多个本地更新和每个迭代中的单个组合。更重要的是，我们将不精确和精确的分布式优化方法装备到这个框架中，因此开发出两种新算法，表现出加速的线性收敛和高通信效率。我们的严格收敛分析揭示了由不精确策略引起的稳态误差的来源，并提供了有效的解决方案。基于合成和真实数据集的数值结果展示了我们的理论动机和分析，以及性能优势。

    arXiv:2403.02589v1 Announce Type: cross  Abstract: Gradient-type distributed optimization methods have blossomed into one of the most important tools for solving a minimization learning task over a networked agent system. However, only one gradient update per iteration is difficult to achieve a substantive acceleration of convergence. In this paper, we propose an accelerated framework named as MUSIC allowing each agent to perform multiple local updates and a single combination in each iteration. More importantly, we equip inexact and exact distributed optimization methods into this framework, thereby developing two new algorithms that exhibit accelerated linear convergence and high communication efficiency. Our rigorous convergence analysis reveals the sources of steady-state errors arising from inexact policies and offers effective solutions. Numerical results based on synthetic and real datasets demonstrate both our theoretical motivations and analysis, as well as performance advanta
    
[^93]: ChatCite：LLM代理与人工工作流引导用于比较文学综述

    ChatCite: LLM Agent with Human Workflow Guidance for Comparative Literature Summary

    [https://arxiv.org/abs/2403.02574](https://arxiv.org/abs/2403.02574)

    ChatCite是一个LLM代理，通过人工工作流引导进行比较文学综述，利用反思逐步机制生成摘要。

    

    arXiv:2403.02574v1 公告类型：跨学科 摘要：文献综述是研究过程中不可或缺的一步。它有助于理解研究问题，并在进行以往作品比较分析时了解当前研究情况。然而，文献总结是具有挑战性和耗时的。先前基于LLM的文献综述研究主要集中在完整过程，包括文献检索、筛选和总结。然而，对于总结步骤，简单的CoT方法往往缺乏提供广泛比较总结的能力。在这项工作中，我们首先专注于独立文献总结步骤并引入ChatCite，一个具有人工工作流引导用于比较文学综述的LLM代理。该代理通过模仿人类工作流，首先从相关文献中提取关键要素，然后使用反思逐步机制生成摘要。

    arXiv:2403.02574v1 Announce Type: cross  Abstract: The literature review is an indispensable step in the research process. It provides the benefit of comprehending the research problem and understanding the current research situation while conducting a comparative analysis of prior works. However, literature summary is challenging and time consuming. The previous LLM-based studies on literature review mainly focused on the complete process, including literature retrieval, screening, and summarization. However, for the summarization step, simple CoT method often lacks the ability to provide extensive comparative summary. In this work, we firstly focus on the independent literature summarization step and introduce ChatCite, an LLM agent with human workflow guidance for comparative literature summary. This agent, by mimicking the human workflow, first extracts key elements from relevant literature and then generates summaries using a Reflective Incremental Mechanism. In order to better ev
    
[^94]: 通过代码从LLMs中引出更好的多语言结构推理

    Eliciting Better Multilingual Structured Reasoning from LLMs through Code

    [https://arxiv.org/abs/2403.02567](https://arxiv.org/abs/2403.02567)

    LLMs在多语言推理任务上表现出较弱的性能，本文提出了通过代码训练和推理来改善多语言结构化推理能力的方法。

    

    大型语言模型（LLM）的发展在推理方面取得了进展，但研究仅限于英语或简单的推理任务。因此，我们引入了一个名为xSTREET的多语言结构化推理和解释数据集，涵盖了六种语言的四个任务。xSTREET暴露了基本LLM在英语和非英语推理任务之间的性能差距。然后，我们提出了两种方法来弥补这一差距，建立在LLM在代码上训练更好的推理这一观点基础上。首先，在训练时，我们使用机器翻译将代码数据集增强为多语言注释，同时保持程序代码不变。其次，在推断时，我们通过采用包含逐步代码原语的提示结构来弥合训练和推断之间的差距，以推导出新事实并找到解决方案。我们的方法在xSTREET上表现出了改进的多语言性能，尤其是在科学常识推理方面。

    arXiv:2403.02567v1 Announce Type: cross  Abstract: Development of large language models (LLM) have shown progress on reasoning, though studies have been limited to English or simple reasoning tasks. We thus introduce a multilingual structured reasoning and explanation dataset, termed xSTREET, that covers four tasks across six languages. xSTREET exposes a gap in base LLM performance between English and non-English reasoning tasks. We then propose two methods to remedy this gap, building on the insight that LLMs trained on code are better reasoners. First, at training time, we augment a code dataset with multi-lingual comments using machine translation while keeping program code as-is. Second, at inference time, we bridge the gap between training and inference by employing a prompt structure that incorporates step-by-step code primitives to derive new facts and find a solution. Our methods show improved multilingual performance on xSTREET, most notably on the scientific commonsense reaso
    
[^95]: Wukong: 迈向大规模推荐的标度律

    Wukong: Towards a Scaling Law for Large-Scale Recommendation

    [https://arxiv.org/abs/2403.02545](https://arxiv.org/abs/2403.02545)

    Wukong通过堆叠因子分解机和协同增长策略，在推荐领域建立了一个标度律，并在质量上优于现有模型。

    

    缩放定律在提高模型质量方面起着关键作用。然而，迄今为止的推荐模型并没有展现出类似于大型语言模型领域观察到的定律，这是由于它们的升级机制的低效性。本文提出了一种基于纯堆叠因子分解机和协同增长策略的有效网络架构，统称为Wukong，以在推荐领域建立一个标度律。Wukong的独特设计使其能够通过更高更宽的层次简单捕获各种任意阶的交互。我们在六个公共数据集上进行了广泛评估，结果表明，与最先进的模型相比，Wukong在质量方面始终表现优越。此外，我们评估了Wuko

    arXiv:2403.02545v1 Announce Type: cross  Abstract: Scaling laws play an instrumental role in the sustainable improvement in model quality. Unfortunately, recommendation models to date do not exhibit such laws similar to those observed in the domain of large language models, due to the inefficiencies of their upscaling mechanisms. This limitation poses significant challenges in adapting these models to increasingly more complex real-world datasets. In this paper, we propose an effective network architecture based purely on stacked factorization machines, and a synergistic upscaling strategy, collectively dubbed Wukong, to establish a scaling law in the domain of recommendation. Wukong's unique design makes it possible to capture diverse, any-order of interactions simply through taller and wider layers. We conducted extensive evaluations on six public datasets, and our results demonstrate that Wukong consistently outperforms state-of-the-art models quality-wise. Further, we assessed Wuko
    
[^96]: DACO: 通过代码生成实现应用驱动和全面的数据分析

    DACO: Towards Application-Driven and Comprehensive Data Analysis via Code Generation

    [https://arxiv.org/abs/2403.02528](https://arxiv.org/abs/2403.02528)

    该论文通过自动生成高质量答案注释的方法，构建了DACO数据集，旨在激发未来对数据分析这一关键且具有挑战性任务的研究。

    

    数据分析是一个关键的分析过程，用于生成深入研究和结论性见解，全面回答给定用户对表格数据的查询。本文旨在提出新的资源和基准，激发未来对这一关键但具有挑战性和未充分挖掘的任务的研究。我们提出了利用LLM的代码生成能力和多轮提示技术自动产生高质量答案注释，构建了DACO数据集，包含440个来自真实场景的数据库（表格数据），约2k个查询-答案对可作为模型训练的弱监督，以及一个人工精细调整的标注的紧凑但高质量测试集，作为我们的主要评估基准。

    arXiv:2403.02528v1 Announce Type: cross  Abstract: Data analysis is a crucial analytical process to generate in-depth studies and conclusive insights to comprehensively answer a given user query for tabular data. In this work, we aim to propose new resources and benchmarks to inspire future research on this crucial yet challenging and under-explored task. However, collecting data analysis annotations curated by experts can be prohibitively expensive. We propose to automatically generate high-quality answer annotations leveraging the code-generation capabilities of LLMs with a multi-turn prompting technique. We construct the DACO dataset, containing (1) 440 databases (of tabular data) collected from real-world scenarios, (2) ~2k query-answer pairs that can serve as weak supervision for model training, and (3) a concentrated but high-quality test set with human refined annotations that serves as our main evaluation benchmark. We train a 6B supervised fine-tuning (SFT) model on DACO datas
    
[^97]: 变压器用于时间序列：以S&P500为例

    Transformer for Times Series: an Application to the S&P500

    [https://arxiv.org/abs/2403.02523](https://arxiv.org/abs/2403.02523)

    本文探讨了将Transformer模型应用于金融时间序列预测中的可行性，并展示了在合成和真实数据集上的一些鼓舞人心的结果。

    

    变压器模型已被广泛应用于许多机器学习领域，包括大型语言模型和图像生成等，本文探讨了将这种方法应用于金融时间序列的可能性。我们首先介绍了两种典型情况下的数据集构造：一种是均值回归的合成Ornstein-Uhlenbeck过程，另一种是真实的S&P500数据。然后，我们详细介绍了提出的Transformer架构，最后讨论了一些令人鼓舞的结果。对于合成数据，我们能够相当准确地预测下一步的走势，而对于S&P500，我们得到了一些与二次变动和波动率预测相关的有趣结果。

    arXiv:2403.02523v1 Announce Type: new  Abstract: The transformer models have been extensively used with good results in a wide area of machine learning applications including Large Language Models and image generation. Here, we inquire on the applicability of this approach to financial time series. We first describe the dataset construction for two prototypical situations: a mean reverting synthetic Ornstein-Uhlenbeck process on one hand and real S&P500 data on the other hand. Then, we present in detail the proposed Transformer architecture and finally we discuss some encouraging results. For the synthetic data we predict rather accurately the next move, and for the S&P500 we get some interesting results related to quadratic variation and volatility prediction.
    
[^98]: 健康声学表示：HeAR

    HeAR -- Health Acoustic Representations

    [https://arxiv.org/abs/2403.02522](https://arxiv.org/abs/2403.02522)

    HeAR是一个基于自监督学习的深度学习系统，通过大规模数据集训练，在33个健康声学任务上表现优越，有望推动健康声学研究的发展。

    

    健康声学声音，如咳嗽和呼吸声，已知包含有用的健康信号，具有监测健康和疾病的重要潜力，但在医疗机器学习社区中尚未得到充分探讨。现有的健康声学深度学习系统通常只针对单一任务进行狭窄训练和评估，这受到数据限制，可能限制了对其他任务的泛化能力。为了弥合这些差距，我们开发了HeAR，这是一个可伸缩的基于自监督学习的深度学习系统，使用了一个包含3.13亿个两秒长音频剪辑的大型数据集来训练掩码自编码器。通过线性探测，我们将HeAR确立为在六个数据集上的33个健康声学任务基准上的最先进的健康音频嵌入模型。通过引入这项工作，我们希望能够启用和加速进一步的健康声学研究。

    arXiv:2403.02522v1 Announce Type: cross  Abstract: Health acoustic sounds such as coughs and breaths are known to contain useful health signals with significant potential for monitoring health and disease, yet are underexplored in the medical machine learning community. The existing deep learning systems for health acoustics are often narrowly trained and evaluated on a single task, which is limited by data and may hinder generalization to other tasks. To mitigate these gaps, we develop HeAR, a scalable self-supervised learning-based deep learning system using masked autoencoders trained on a large dataset of 313 million two-second long audio clips. Through linear probes, we establish HeAR as a state-of-the-art health audio embedding model on a benchmark of 33 health acoustic tasks across 6 datasets. By introducing this work, we hope to enable and accelerate further health acoustics research.
    
[^99]: 为开放式学习机器人设定目的：一个计算分类、定义和操作化

    Purpose for Open-Ended Learning Robots: A Computational Taxonomy, Definition, and Operationalisation

    [https://arxiv.org/abs/2403.02514](https://arxiv.org/abs/2403.02514)

    提出了设定机器人目的的概念，以帮助机器人更加关注获取与目的相关的知识。

    

    arXiv:2403.02514v1 公告类型: 跨领域 摘要: 自主开放式学习(OEL)机器人能够通过与环境的直接交互累积获取新技能和知识，例如依靠内在动机和自动生成的目标的指导。OEL机器人对应用具有很高的相关性，因为它们可以使用自主获取的知识来完成对人类用户有关的任务。然而，OEL机器人面临一个重要限制：这可能导致获取的知识对完成用户任务并不那么重要。本文分析了这个问题的一个可能解决方案，它围绕“目的”这一新概念展开。目的表示设计者和/或用户希望机器人从中获得什么。机器人应使用目的的内部表征，这里称为“愿望”，来将其开放式探索集中于获取与其完成目的相关的知识。这项工作有助于发展一个共同

    arXiv:2403.02514v1 Announce Type: cross  Abstract: Autonomous open-ended learning (OEL) robots are able to cumulatively acquire new skills and knowledge through direct interaction with the environment, for example relying on the guidance of intrinsic motivations and self-generated goals. OEL robots have a high relevance for applications as they can use the autonomously acquired knowledge to accomplish tasks relevant for their human users. OEL robots, however, encounter an important limitation: this may lead to the acquisition of knowledge that is not so much relevant to accomplish the users' tasks. This work analyses a possible solution to this problem that pivots on the novel concept of `purpose'. Purposes indicate what the designers and/or users want from the robot. The robot should use internal representations of purposes, called here `desires', to focus its open-ended exploration towards the acquisition of knowledge relevant to accomplish them. This work contributes to develop a co
    
[^100]: SPUQ：基于扰动的大型语言模型不确定性量化

    SPUQ: Perturbation-Based Uncertainty Quantification for Large Language Models

    [https://arxiv.org/abs/2403.02509](https://arxiv.org/abs/2403.02509)

    SPUQ是一种新颖的基于扰动的大型语言模型不确定性量化方法，旨在同时处理现象性和认知性不确定性

    

    近年来，大型语言模型（LLMs）越来越普遍，提供了出色的文本生成能力。然而，它们倾向于做出自信错误的预测，突显了在LLMs中进行不确定性量化（UQ）的重要性。尽管先前的工作主要集中在解决现象性不确定性，但对包括认知性在内的不确定性的全谱尚未充分探索。受到这一差距的启发，我们引入了一种新颖的UQ方法，即适用于UQ的扰动采样（SPUQ），旨在应对现象性和认知性不确定性。该方法涉及为LLM输入生成一组扰动，对每个扰动进行输出采样，并结合一个聚合模块，该聚合模块概括了用于文本生成任务的采样不确定性方法。通过对各种数据集上的广泛实验，我们研究了不同的扰动和聚合方式。

    arXiv:2403.02509v1 Announce Type: cross  Abstract: In recent years, large language models (LLMs) have become increasingly prevalent, offering remarkable text generation capabilities. However, a pressing challenge is their tendency to make confidently wrong predictions, highlighting the critical need for uncertainty quantification (UQ) in LLMs. While previous works have mainly focused on addressing aleatoric uncertainty, the full spectrum of uncertainties, including epistemic, remains inadequately explored. Motivated by this gap, we introduce a novel UQ method, sampling with perturbation for UQ (SPUQ), designed to tackle both aleatoric and epistemic uncertainties. The method entails generating a set of perturbations for LLM inputs, sampling outputs for each perturbation, and incorporating an aggregation module that generalizes the sampling uncertainty approach for text generation tasks. Through extensive experiments on various datasets, we investigated different perturbation and aggrega
    
[^101]: 自然语言处理中的预训练-微调范式教程

    A Tutorial on the Pretrain-Finetune Paradigm for Natural Language Processing

    [https://arxiv.org/abs/2403.02504](https://arxiv.org/abs/2403.02504)

    预训练-微调范式在自然语言处理中展现了显著的效率，尤其对社会科学研究中数据有限的情况下具有益处。

    

    预训练-微调范式代表了自然语言处理中的一种变革性方法。该范式通过使用大型预训练语言模型区别于众，展示了在微调任务中即使训练数据有限也具有显著的效率。这种效率对社会科学研究特别有益，因为注释样本的数量通常非常有限。我们的教程全面介绍了预训练-微调范式。我们首先深入探讨了预训练和微调的基本概念，然后进行了实际应用的案例练习。我们展示了该范式在各种任务中的应用，包括多类别分类和回归。强调其高效性和用户友好性，该教程旨在鼓励更广泛地采纳这种范式。为此，我们提供了所有代码和数据集的开放访问。

    arXiv:2403.02504v1 Announce Type: cross  Abstract: The pretrain-finetune paradigm represents a transformative approach in natural language processing (NLP). This paradigm distinguishes itself through the use of large pretrained language models, demonstrating remarkable efficiency in finetuning tasks, even with limited training data. This efficiency is especially beneficial for research in social sciences, where the number of annotated samples is often quite limited. Our tutorial offers a comprehensive introduction to the pretrain-finetune paradigm. We first delve into the fundamental concepts of pretraining and finetuning, followed by practical exercises using real-world applications. We demonstrate the application of the paradigm across various tasks, including multi-class classification and regression. Emphasizing its efficacy and user-friendliness, the tutorial aims to encourage broader adoption of this paradigm. To this end, we have provided open access to all our code and datasets
    
[^102]: 试错法：面向LLM代理的基于探索的轨迹优化

    Trial and Error: Exploration-Based Trajectory Optimization for LLM Agents

    [https://arxiv.org/abs/2403.02502](https://arxiv.org/abs/2403.02502)

    提出了一种面向LLM代理的基于探索的轨迹优化方法，通过允许代理从探索失败中学习，实现了性能的改进。

    

    大型语言模型（LLMs）已经成为各种自主代理系统中不可或缺的组成部分。在这项研究中，我们提出一种基于探索的轨迹优化方法，称为ETO。这种学习方法旨在提高开放LLM代理的性能。与先前专门训练成功专家轨迹的研究相反，我们的方法允许代理从其探索失败中学习。这通过迭代优化框架实现了性能的改进。在探索阶段，代理与环境互动，完成指定任务，收集失败轨迹以创建对比轨迹对。在随后的训练阶段，代理利用这些轨迹偏好对更新其策略，使用类似DPO的对比学习方法。这种探索和训练的迭代循环促进了代理的持续改进。

    arXiv:2403.02502v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have become integral components in various autonomous agent systems. In this study, we present an exploration-based trajectory optimization approach, referred to as ETO. This learning method is designed to enhance the performance of open LLM agents. Contrary to previous studies that exclusively train on successful expert trajectories, our method allows agents to learn from their exploration failures. This leads to improved performance through an iterative optimization framework. During the exploration phase, the agent interacts with the environment while completing given tasks, gathering failure trajectories to create contrastive trajectory pairs. In the subsequent training phase, the agent utilizes these trajectory preference pairs to update its policy using contrastive learning methods like DPO. This iterative cycle of exploration and training fosters continued improvement in the agents. Our experiments o
    
[^103]: 机器人抓取中的伪标签和情境课程学习

    Pseudo-Labeling and Contextual Curriculum Learning for Online Grasp Learning in Robotic Bin Picking

    [https://arxiv.org/abs/2403.02495](https://arxiv.org/abs/2403.02495)

    提出了一种将半监督学习和强化学习相结合的SSL-ConvSAC方法，有效利用未标记数据增强在线抓取学习，并通过基于情境课程的方法解决标记和未标记数据不平衡问题，在真实世界数据集上验证了在垃圾桶挑选任务中改进在线抓取学习的潜力。

    

    目前的抓取预测方法主要依赖于离线学习，忽视了实时适应新颖挑选场景中发生的动态抓取学习。本文引入一种新方法SSL-ConvSAC，将半监督学习和强化学习相结合，用于在线抓取学习。通过将带有奖励反馈的像素视为标记数据，其他像素视为未标记数据，有效地利用未标记数据以增强学习。此外，我们提出了一种基于情境课程的方法来解决标记和未标记数据之间的不平衡。我们在真实世界的评估数据上验证了所提方法，并展示了利用具有吸盘夹具的物理7自由度Franka Emika机械臂改进在线抓取学习的潜力。

    arXiv:2403.02495v1 Announce Type: cross  Abstract: The prevailing grasp prediction methods predominantly rely on offline learning, overlooking the dynamic grasp learning that occurs during real-time adaptation to novel picking scenarios. These scenarios may involve previously unseen objects, variations in camera perspectives, and bin configurations, among other factors. In this paper, we introduce a novel approach, SSL-ConvSAC, that combines semi-supervised learning and reinforcement learning for online grasp learning. By treating pixels with reward feedback as labeled data and others as unlabeled, it efficiently exploits unlabeled data to enhance learning. In addition, we address the imbalance between labeled and unlabeled data by proposing a contextual curriculum-based method. We ablate the proposed approach on real-world evaluation data and demonstrate promise for improving online grasp learning on bin picking tasks using a physical 7-DoF Franka Emika robot arm with a suction grippe
    
[^104]: 基于预测的神经架构搜索的编码方式

    Encodings for Prediction-based Neural Architecture Search

    [https://arxiv.org/abs/2403.02484](https://arxiv.org/abs/2403.02484)

    预测器方法在神经架构搜索方面起到了显著作用，本文对不同类型的神经编码进行了分类和研究，并引入了统一编码，扩展了NAS预测器到多个搜索空间。

    

    预测器方法大大增强了神经架构搜索（NAS）优化的效果。这些预测器的有效性在很大程度上取决于神经网络架构的编码方法。本文对三种主要类型的神经编码进行了分类和研究：结构型、学习型和基于分数的。此外，我们扩展了这些编码，并引入了“统一编码”，将NAS预测器扩展到多个搜索空间。我们的分析来自于在NASBench-101（NB101）、NB201、NB301、网络设计空间（NDS）和TransNASBench-101等NAS空间上进行的超过150万个神经网络架构的实验。根据我们的研究，我们提出了

    arXiv:2403.02484v1 Announce Type: cross  Abstract: Predictor-based methods have substantially enhanced Neural Architecture Search (NAS) optimization. The efficacy of these predictors is largely influenced by the method of encoding neural network architectures. While traditional encodings used an adjacency matrix describing the graph structure of a neural network, novel encodings embrace a variety of approaches from unsupervised pretraining of latent representations to vectors of zero-cost proxies. In this paper, we categorize and investigate neural encodings from three main types: structural, learned, and score-based. Furthermore, we extend these encodings and introduce \textit{unified encodings}, that extend NAS predictors to multiple search spaces. Our analysis draws from experiments conducted on over 1.5 million neural network architectures on NAS spaces such as NASBench-101 (NB101), NB201, NB301, Network Design Spaces (NDS), and TransNASBench-101. Building on our study, we present 
    
[^105]: MORBDD：通过学习稀疏化实现的多目标约束二进制决策图

    MORBDD: Multiobjective Restricted Binary Decision Diagrams by Learning to Sparsify

    [https://arxiv.org/abs/2403.02482](https://arxiv.org/abs/2403.02482)

    本文提出了一种基于机器学习的BDD稀疏化器MORBDD，通过训练二元分类器来消除不太可能贡献于帕累托解的BDD节点。

    

    在多标准决策中，用户寻求约束多目标优化问题的非支配解集，即所谓的帕累托前沿。本文旨在将一种精确的多目标整数线性规划方法引入到启发式领域。我们着眼于二进制决策图（BDDs），首先构建一个代表问题所有可行解的图形，然后遍历该图以提取帕累托前沿。由于帕累托前沿可能呈指数增长，BDD上的枚举可能耗时。我们探讨了如何通过机器学习（ML）将已被证明对单目标问题有效的受限BDDs调整为多目标优化。我们的基于ML的BDD稀疏化器MORBDD首先训练一个二元分类器，以消除不太可能贡献于帕累托解的BDD节点。

    arXiv:2403.02482v1 Announce Type: new  Abstract: In multicriteria decision-making, a user seeks a set of non-dominated solutions to a (constrained) multiobjective optimization problem, the so-called Pareto frontier. In this work, we seek to bring a state-of-the-art method for exact multiobjective integer linear programming into the heuristic realm. We focus on binary decision diagrams (BDDs) which first construct a graph that represents all feasible solutions to the problem and then traverse the graph to extract the Pareto frontier. Because the Pareto frontier may be exponentially large, enumerating it over the BDD can be time-consuming. We explore how restricted BDDs, which have already been shown to be effective as heuristics for single-objective problems, can be adapted to multiobjective optimization through the use of machine learning (ML). MORBDD, our ML-based BDD sparsifier, first trains a binary classifier to eliminate BDD nodes that are unlikely to contribute to Pareto solution
    
[^106]: 墨迹效应：以ChatGPT为共创游戏设计师的案例研究

    The Ink Splotch Effect: A Case Study on ChatGPT as a Co-Creative Game Designer

    [https://arxiv.org/abs/2403.02454](https://arxiv.org/abs/2403.02454)

    本研究通过将大型语言模型应用于游戏设计中，探讨了人工智能辅助对游戏质量的影响，并在用户研究中对其进行了验证。

    

    本文研究了大型语言模型（LLMs）如何作为有效的高层次创意合作者和游戏设计的“灵感泉源”。我们通过模仿艺术家使用的练习，即观看无定形的墨迹斑点以获得创意灵感，来构建这项研究的设计。我们的目标是确定人工智能辅助相对于人类设计师的创造意图实施时，是否可以改善、阻碍或提供另一种游戏质量。LLMs作为游戏设计师的能力通过将其置于决策过程的前沿来进行压力测试。在3个不同的流派中设计了三款原型游戏：（1）极简基础游戏，（2）由人类游戏设计师添加功能和游戏感元素的游戏，以及（3）从ChatGPT提示的输出直接实现功能和感觉元素的游戏。进行了用户研究，并要求参与者盲目评估游戏的质量和它们...

    arXiv:2403.02454v1 Announce Type: new  Abstract: This paper studies how large language models (LLMs) can act as effective, high-level creative collaborators and ``muses'' for game design. We model the design of this study after the exercises artists use by looking at amorphous ink splotches for creative inspiration. Our goal is to determine whether AI-assistance can improve, hinder, or provide an alternative quality to games when compared to the creative intents implemented by human designers. The capabilities of LLMs as game designers are stress tested by placing it at the forefront of the decision making process. Three prototype games are designed across 3 different genres: (1) a minimalist base game, (2) a game with features and game feel elements added by a human game designer, and (3) a game with features and feel elements directly implemented from prompted outputs of the LLM, ChatGPT. A user study was conducted and participants were asked to blindly evaluate the quality and their
    
[^107]: 胎儿大脑解剖约束下的纤维束追踪

    Anatomically Constrained Tractography of the Fetal Brain

    [https://arxiv.org/abs/2403.02444](https://arxiv.org/abs/2403.02444)

    提出了一种基于精确分割胎儿大脑组织的解剖约束纤维束追踪方法，并通过深度学习方法实现自动分割，有效改善了对胎儿大脑的纤维束追踪准确性。

    

    弥敦路:2403.02444v1 公告类型：跨过摘要：扩散加权磁共振成像（dMRI）被越来越广泛地用于研究子宫内的胎儿大脑。 dMRI使得流线追踪成为可能的重要计算，其具有独特的应用，如对脑白质进行纤维束特异性分析和结构连接性评估。然而，由于胎儿dMRI数据质量较低且纤维束追踪具有挑战性，现有方法往往会产生高度不准确的结果。它们生成许多虚假的流线，同时未能重构构成主要白质纤维束的流线。在本文中，我们提倡在dMRI空间中直接对胎儿大脑组织进行准确分割的解剖约束纤维束追踪。我们开发了一种深度学习方法来自动计算分割。对独立测试数据的实验表明，该方法可以准确分割胎儿大脑组织，并显著改善tra

    arXiv:2403.02444v1 Announce Type: cross  Abstract: Diffusion-weighted Magnetic Resonance Imaging (dMRI) is increasingly used to study the fetal brain in utero. An important computation enabled by dMRI is streamline tractography, which has unique applications such as tract-specific analysis of the brain white matter and structural connectivity assessment. However, due to the low fetal dMRI data quality and the challenging nature of tractography, existing methods tend to produce highly inaccurate results. They generate many false streamlines while failing to reconstruct streamlines that constitute the major white matter tracts. In this paper, we advocate for anatomically constrained tractography based on an accurate segmentation of the fetal brain tissue directly in the dMRI space. We develop a deep learning method to compute the segmentation automatically. Experiments on independent test data show that this method can accurately segment the fetal brain tissue and drastically improve tra
    
[^108]: 使用可解释人工智能 (XAI) 分析预测异常根本原因

    Root Causing Prediction Anomalies Using Explainable AI

    [https://arxiv.org/abs/2403.02439](https://arxiv.org/abs/2403.02439)

    本文介绍了在根本上解决个性化广告中模型性能下降问题的方法，通过解释人工智能技术分析预测异常。

    

    本文介绍了可解释人工智能（XAI）在根因分析机器学习模型性能下降中的创新应用，该模型不断从用户参与数据中学习。在这些系统中，单个特征损坏可能导致级联特征、标签和概念漂移。我们已成功将这一技术应用于提高个性化广告中使用的模型的可靠性。在这种系统中，性能下降表现为模型中的预测异常。

    arXiv:2403.02439v1 Announce Type: cross  Abstract: This paper presents a novel application of explainable AI (XAI) for root-causing performance degradation in machine learning models that learn continuously from user engagement data. In such systems a single feature corruption can cause cascading feature, label and concept drifts. We have successfully applied this technique to improve the reliability of models used in personalized advertising. Performance degradation in such systems manifest as prediction anomalies in the models. These models are typically trained continuously using features that are produced by hundreds of real time data processing pipelines or derived from other upstream models. A failure in any of these pipelines or an instability in any of the upstream models can cause feature corruption, causing the model's predicted output to deviate from the actual output and the training data to become corrupted. The causal relationship between the features and the predicted ou
    
[^109]: SoK: 联邦反学习中的挑战与机遇

    SoK: Challenges and Opportunities in Federated Unlearning

    [https://arxiv.org/abs/2403.02437](https://arxiv.org/abs/2403.02437)

    联邦学习引入了新的隐私要求，促使研究开始关注适用于联邦学习环境的反学习机制。

    

    引入于2017年的联邦学习（FL）促进了不信任方之间的合作学习，无需各方明确共享其数据。这允许在尊重GDPR和CPRA等隐私规定的同时，在用户数据上训练模型。然而，新兴的隐私要求可能要求模型所有者能够“遗忘”一些已学习的数据，例如当数据所有者或执法机构要求时。这催生了一个名为“机器反学习”的活跃研究领域。在FL的背景下，许多为集中式环境开发的反学习技术并不容易应用！这是由于FL中集中式和分布式学习之间的独特差异，特别是互动性、随机性、异构性和有限可访问性。为应对这一挑战，最近的一系列研究工作聚焦于开发适用于FL的反学习机制。

    arXiv:2403.02437v1 Announce Type: cross  Abstract: Federated learning (FL), introduced in 2017, facilitates collaborative learning between non-trusting parties with no need for the parties to explicitly share their data among themselves. This allows training models on user data while respecting privacy regulations such as GDPR and CPRA. However, emerging privacy requirements may mandate model owners to be able to \emph{forget} some learned data, e.g., when requested by data owners or law enforcement. This has given birth to an active field of research called \emph{machine unlearning}. In the context of FL, many techniques developed for unlearning in centralized settings are not trivially applicable! This is due to the unique differences between centralized and distributed learning, in particular, interactivity, stochasticity, heterogeneity, and limited accessibility in FL. In response, a recent line of work has focused on developing unlearning mechanisms tailored to FL.   This SoK pape
    
[^110]: 面向高效多变量时间序列异常检测的深度自编码器

    Towards efficient deep autoencoders for multivariate time series anomaly detection

    [https://arxiv.org/abs/2403.02429](https://arxiv.org/abs/2403.02429)

    本文提出了面向多变量时间序列异常检测的深度自编码器的高效压缩方法，通过修剪减少权重数量并防止精度灾难性下降，以在有限时间和内存约束的实时系统中获得最佳结果。

    

    多变量时间序列异常检测在许多工业和研究应用中是一个关键问题。及时检测异常允许防止制造过程中的缺陷和网络物理系统中的故障。深度学习方法由于其对复杂多变量数据进行准确和稳健分析的特点而备受青睐。然而，一个关键方面是能够及时提取预测结果，以适应不同应用中的实时需求。在深度学习模型中，模型缩减对于在具有有限时间和内存约束的实时系统中实现最佳结果非常重要。在本文中，我们通过提出一种涉及三个关键因素的深度自动编码器新压缩方法来解决这个问题。首先，修剪减少权重数量，同时通过快速搜索过程防止精度的灾难性下降。

    arXiv:2403.02429v1 Announce Type: cross  Abstract: Multivariate time series anomaly detection is a crucial problem in many industrial and research applications. Timely detection of anomalies allows, for instance, to prevent defects in manufacturing processes and failures in cyberphysical systems. Deep learning methods are preferred among others for their accuracy and robustness for the analysis of complex multivariate data. However, a key aspect is being able to extract predictions in a timely manner, to accommodate real-time requirements in different applications. In the case of deep learning models, model reduction is extremely important to achieve optimal results in real-time systems with limited time and memory constraints. In this paper, we address this issue by proposing a novel compression method for deep autoencoders that involves three key factors. First, pruning reduces the number of weights, while preventing catastrophic drops in accuracy by means of a fast search process th
    
[^111]: 你需要更多LLM调用吗？走向复合推理系统的扩展定律

    Are More LLM Calls All You Need? Towards Scaling Laws of Compound Inference Systems

    [https://arxiv.org/abs/2403.02419](https://arxiv.org/abs/2403.02419)

    本文研究了复合推理系统的扩展定律，发现投票推理系统的性能随LLM调用次数增加先增加后下降。

    

    许多最近语言任务中的最先进结果是通过执行多个大型语言模型（LLM）调用并汇总它们的响应的复合系统实现的。然而，对于LLM调用次数的影响 -- 例如，当要求LLM多次回答每个问题并取得共识时 -- 对于这种复合系统的性能了解甚少。在本文中，我们开始研究复合推理系统的扩展定律。我们从理论和实证的角度分析了LLM调用次数如何影响一个层级投票推理系统的性能 -- 这是最简单的复合系统之一，它通过多数投票聚合LLM的响应。我们实验证明，在多个语言任务中，令人惊讶的是，投票推理系统的性能随着LLM调用次数的增加而先增加后下降。我们的理论结果表明，这种非单调性是由于

    arXiv:2403.02419v1 Announce Type: cross  Abstract: Many recent state-of-the-art results in language tasks were achieved using compound systems that perform multiple Large Language Model (LLM) calls and aggregate their responses. However, there is little understanding of how the number of LLM calls -- e.g., when asking the LLM to answer each question multiple times and taking a consensus -- affects such a compound system's performance. In this paper, we initiate the study of scaling laws of compound inference systems. We analyze, theoretically and empirically, how the number of LLM calls affects the performance of one-layer Voting Inference Systems -- one of the simplest compound systems, which aggregates LLM responses via majority voting. We find empirically that across multiple language tasks, surprisingly, Voting Inference Systems' performance first increases but then decreases as a function of the number of LLM calls. Our theoretical results suggest that this non-monotonicity is due
    
[^112]: OTClean：使用最优输运进行条件独立性违规数据清洗

    OTClean: Data Cleaning for Conditional Independence Violations using Optimal Transport

    [https://arxiv.org/abs/2403.02372](https://arxiv.org/abs/2403.02372)

    使用最优输运理论的OTClean框架解决了在条件独立性（CI）约束下数据清洗的问题，通过将数据修复问题转化为正则化优化问题，并提出了受Sinkhorn矩阵缩放算法启发的迭代算法，克服了可伸缩性挑战。

    

    确保条件独立性（CI）约束对于公平和可信赖的机器学习模型的发展至关重要。本文介绍了一个名为OTClean的框架，利用最优输运理论在CI约束下进行数据修复。最优输运理论提供了一个严格的框架来衡量概率分布之间的差异，从而确保对数据效用的控制。我们将涉及CI的数据修复问题形式化为一个二次约束线性规划（QCLP），并提出了一种用于解决该问题的交替方法。然而，由于计算最优输运距离（如Wasserstein距离）所涉及的计算成本，这种方法面临可伸缩性问题。为了克服这些可伸缩性挑战，我们将问题重新构建为正则化优化问题，从而使我们能够开发一个受Sinkhorn矩阵缩放算法启发的迭代算法，从而使我们能够进行可伸缩的数据修复。

    arXiv:2403.02372v1 Announce Type: cross  Abstract: Ensuring Conditional Independence (CI) constraints is pivotal for the development of fair and trustworthy machine learning models. In this paper, we introduce \sys, a framework that harnesses optimal transport theory for data repair under CI constraints. Optimal transport theory provides a rigorous framework for measuring the discrepancy between probability distributions, thereby ensuring control over data utility. We formulate the data repair problem concerning CIs as a Quadratically Constrained Linear Program (QCLP) and propose an alternating method for its solution. However, this approach faces scalability issues due to the computational cost associated with computing optimal transport distances, such as the Wasserstein distance. To overcome these scalability challenges, we reframe our problem as a regularized optimization problem, enabling us to develop an iterative algorithm inspired by Sinkhorn's matrix scaling algorithm, which e
    
[^113]: NeuroVoz：帕金森病患者语音的卡斯蒂利亚语语料库

    NeuroVoz: a Castillian Spanish corpus of parkinsonian speech

    [https://arxiv.org/abs/2403.02371](https://arxiv.org/abs/2403.02371)

    这一研究提出了一个包含108位母语为卡斯蒂利亚语说话者的帕金森病患者语音语料库，涵盖了多种语音任务，通过手动和自动转录确保了数据的准确性和可靠性。

    

    通过语音分析进行帕金森病（PD）诊断的进展受到公开可用、多样化的语言数据集的显著缺乏的阻碍，限制了现有研究结果的可再现性和进一步探索。为了弥补这一空白，我们引入了一个全面的语料库，包括来自108位母语为卡斯蒂利亚语的说话者，包括55名健康对照组和53名被诊断患有PD的个体，所有这些个体都在药物治疗下，并且在药物优化状态下进行记录。 这一独特数据集涵盖了广泛的语音任务，包括持续发音五个西班牙元音、发音测试、16个听后重复的话语以及自由独白。该数据集通过专家手动转录听后重复任务强调准确性和可靠性，并利用Whisper进行自动独白转录，使其成为帕金森病患者语音的最完整的公开语料库。

    arXiv:2403.02371v1 Announce Type: cross  Abstract: The advancement of Parkinson's Disease (PD) diagnosis through speech analysis is hindered by a notable lack of publicly available, diverse language datasets, limiting the reproducibility and further exploration of existing research.   In response to this gap, we introduce a comprehensive corpus from 108 native Castilian Spanish speakers, comprising 55 healthy controls and 53 individuals diagnosed with PD, all of whom were under pharmacological treatment and recorded in their medication-optimized state. This unique dataset features a wide array of speech tasks, including sustained phonation of the five Spanish vowels, diadochokinetic tests, 16 listen-and-repeat utterances, and free monologues. The dataset emphasizes accuracy and reliability through specialist manual transcriptions of the listen-and-repeat tasks and utilizes Whisper for automated monologue transcriptions, making it the most complete public corpus of Parkinsonian speech, 
    
[^114]: adaptMLLM：在低资源语言上用集成LLM游乐场对多语言语言模型进行微调

    adaptMLLM: Fine-Tuning Multilingual Language Models on Low-Resource Languages with Integrated LLM Playgrounds

    [https://arxiv.org/abs/2403.02370](https://arxiv.org/abs/2403.02370)

    该论文介绍了adaptMLLM，一个旨在解决低资源语言机器翻译问题的开源应用程序，该应用程序简化了对多语言语言模型进行微调的所有流程。

    

    Multilingual Language Models (MLLMs)和Large Language Models的出现，在自然语言处理的许多领域引发了创新。尽管这项技术具有令人兴奋的潜力，但其对低资源语言开发高质量的机器翻译（MT）输出的影响相对较少探讨。此外，尚未推出一个开源应用程序，专门用于对MLLM进行微调，并管理低资源语言的完整MT工作流程。我们旨在通过开发adaptMLLM来解决这些不平衡，该应用程序简化了用于MT的MLLM微调的所有流程。这个开源应用程序专门为从事MT的开发人员、翻译人员和用户量身定制。直观的界面允许轻松地自定义超参数，该应用程序提供一系列用于模型评估的指标，并具有部署模型作为翻译服务的能力。

    arXiv:2403.02370v1 Announce Type: cross  Abstract: The advent of Multilingual Language Models (MLLMs) and Large Language Models has spawned innovation in many areas of natural language processing. Despite the exciting potential of this technology, its impact on developing high-quality Machine Translation (MT) outputs for low-resource languages remains relatively under-explored. Furthermore, an open-source application, dedicated to both fine-tuning MLLMs and managing the complete MT workflow for low-resources languages, remains unavailable. We aim to address these imbalances through the development of adaptMLLM, which streamlines all processes involved in the fine-tuning of MLLMs for MT. This open-source application is tailored for developers, translators, and users who are engaged in MT. An intuitive interface allows for easy customisation of hyperparameters, and the application offers a range of metrics for model evaluation and the capability to deploy models as a translation service 
    
[^115]: 适用于工业4.0应用中预测优化的新型混合特征重要性和特征交互检测框架

    A Novel Hybrid Feature Importance and Feature Interaction Detection Framework for Predictive Optimization in Industry 4.0 Applications

    [https://arxiv.org/abs/2403.02368](https://arxiv.org/abs/2403.02368)

    该论文提出了一个新型混合框架，结合特征重要性检测和特征交互检测，以提高工业4.0应用中的预测优化准确性。

    

    先进的机器学习算法越来越被广泛应用于工业4.0中提供基于数据的预测和决策支持。然而，现有模型所达到的预测准确性不足以保证在现实应用中的实际实施。这是因为现实世界数据集中并非所有特征都与正在进行的预测分析直接相关。因此，精心选择特征的结合有潜力对结果产生重大积极影响。为了填补研究空白，本文提出了一个新颖的混合框架，将特征重要性检测器——局部可解释的模型无关解释（LIME）和特征交互检测器——神经交互检测（NID）相结合，以提高预测准确性。通过应用所提出的框架，可以消除不必要的特征，并对交互作用进行编码以生成

    arXiv:2403.02368v1 Announce Type: cross  Abstract: Advanced machine learning algorithms are increasingly utilized to provide data-based prediction and decision-making support in Industry 4.0. However, the prediction accuracy achieved by the existing models is insufficient to warrant practical implementation in real-world applications. This is because not all features present in real-world datasets possess a direct relevance to the predictive analysis being conducted. Consequently, the careful incorporation of select features has the potential to yield a substantial positive impact on the outcome. To address the research gap, this paper proposes a novel hybrid framework that combines the feature importance detector - local interpretable model-agnostic explanations (LIME) and the feature interaction detector - neural interaction detection (NID), to improve prediction accuracy. By applying the proposed framework, unnecessary features can be eliminated, and interactions are encoded to gene
    
[^116]: adaptNMT：一种面向神经机器翻译的开源、语言无关的开发环境

    adaptNMT: an open-source, language-agnostic development environment for Neural Machine Translation

    [https://arxiv.org/abs/2403.02367](https://arxiv.org/abs/2403.02367)

    adaptNMT是一个开源的神经机器翻译开发环境，简化了模型开发和部署流程，特别适用于新手用户，并提供图形展示、子词分割模型等功能。

    

    arXiv：2403.02367v1 公告类型：跨越 摘要：adaptNMT简化了RNN和Transformer神经翻译模型的开发和部署中涉及的所有流程。作为一款开源应用程序，它旨在面向机器翻译领域的技术和非技术用户。该应用是建立在广泛采用的OpenNMT生态系统之上的，对于新进入该领域的用户特别有用，因为开发环境的设置以及创建训练、验证和测试分割被大大简化。应用程序内置图形展示了模型训练的进度，并使用SentencePiece创建子词分割模型。通过直观的用户界面，可以便捷地定制超参数，实施了一键式模型开发方法。由adaptNMT开发的模型可以使用各种指标进行评估，并作为翻译服务在应用程序中部署。

    arXiv:2403.02367v1 Announce Type: cross  Abstract: adaptNMT streamlines all processes involved in the development and deployment of RNN and Transformer neural translation models. As an open-source application, it is designed for both technical and non-technical users who work in the field of machine translation. Built upon the widely-adopted OpenNMT ecosystem, the application is particularly useful for new entrants to the field since the setup of the development environment and creation of train, validation and test splits is greatly simplified. Graphing, embedded within the application, illustrates the progress of model training, and SentencePiece is used for creating subword segmentation models. Hyperparameter customization is facilitated through an intuitive user interface, and a single-click model development approach has been implemented. Models developed by adaptNMT can be evaluated using a range of metrics, and deployed as a translation service within the application. To support
    
[^117]: 人类评估英爱变压器基于NMT的翻译质量

    Human Evaluation of English--Irish Transformer-Based NMT

    [https://arxiv.org/abs/2403.02366](https://arxiv.org/abs/2403.02366)

    本研究评估了超参数设置对低资源英-爱变压器神经机器翻译质量的影响，并发现优化的Transformer模型在16k BPE子词模型下表现最佳，相较于基准RNN模型提高了7.8个BLEU分数，并在与谷歌翻译的比较中展示出显著的改进。

    

    在本研究中，对超参数设置如何影响低资源英语-爱尔兰文对的变压器神经机器翻译（NMT）质量进行了人类评估。使用Byte Pair Encoding（BPE）和unigram方法的SentencePiece模型受到了评价。模型架构的变化包括修改层数，评估注意力的最佳头数以及测试各种正则化技术。在一个优化了的16k BPE子词模型下，Transformer优化模型的性能表现得最好。与基准循环神经网络（RNN）模型相比，Transformer优化模型的BLEU分数提高了7.8个点。与谷歌翻译相比，我们的翻译引擎展示了显著的改进。此外，进行了定量细粒度的手动评估，比较了机器翻译的性能。

    arXiv:2403.02366v1 Announce Type: cross  Abstract: In this study, a human evaluation is carried out on how hyperparameter settings impact the quality of Transformer-based Neural Machine Translation (NMT) for the low-resourced English--Irish pair. SentencePiece models using both Byte Pair Encoding (BPE) and unigram approaches were appraised. Variations in model architectures included modifying the number of layers, evaluating the optimal number of heads for attention and testing various regularisation techniques. The greatest performance improvement was recorded for a Transformer-optimized model with a 16k BPE subword model. Compared with a baseline Recurrent Neural Network (RNN) model, a Transformer-optimized model demonstrated a BLEU score improvement of 7.8 points. When benchmarked against Google Translate, our translation engines demonstrated significant improvements. Furthermore, a quantitative fine-grained manual evaluation was conducted which compared the performance of machine t
    
[^118]: 解决长尾嘈杂标签学习问题：考虑标签稀有性的两阶段解决方案

    Addressing Long-Tail Noisy Label Learning Problems: a Two-Stage Solution with Label Refurbishment Considering Label Rarity

    [https://arxiv.org/abs/2403.02363](https://arxiv.org/abs/2403.02363)

    提出了一种两阶段方法，通过软标签修复和多专家集成学习结合，解决了长尾嘈杂标签学习问题。

    

    真实世界的数据集通常表现出嘈杂标签和类别不平衡，如长尾分布。先前的研究通过区分嘈杂和干净样本来解决这个问题，但依赖于基于嘈杂长尾数据的预测信息会引入潜在错误。为了克服先前研究的局限性，我们提出了一种有效的两阶段方法，将软标签修复与多专家集成学习相结合。在稳健的软标签修复的第一阶段中，我们通过对比学习获得无偏特征，使用经过精心设计的BAlanced Noise-tolerant Cross-entropy (BANC) 损失训练的分类器进行初步预测。在第二阶段，我们的标签修复方法被应用于为多专家集成学习获取软标签，为长尾嘈杂标签问题提供了一个原则性的解决方案。在多个基准测试中进行的实验表明，我们的方法在各个方面均优于现有技术。

    arXiv:2403.02363v1 Announce Type: cross  Abstract: Real-world datasets commonly exhibit noisy labels and class imbalance, such as long-tailed distributions. While previous research addresses this issue by differentiating noisy and clean samples, reliance on information from predictions based on noisy long-tailed data introduces potential errors. To overcome the limitations of prior works, we introduce an effective two-stage approach by combining soft-label refurbishing with multi-expert ensemble learning. In the first stage of robust soft label refurbishing, we acquire unbiased features through contrastive learning, making preliminary predictions using a classifier trained with a carefully designed BAlanced Noise-tolerant Cross-entropy (BANC) loss. In the second stage, our label refurbishment method is applied to obtain soft labels for multi-expert ensemble learning, providing a principled solution to the long-tail noisy label problem. Experiments conducted across multiple benchmarks v
    
[^119]: 面向异构联邦学习的定制架构研究: 对比云边模型解耦

    Towards Optimal Customized Architecture for Heterogeneous Federated Learning with Contrastive Cloud-Edge Model Decoupling

    [https://arxiv.org/abs/2403.02360](https://arxiv.org/abs/2403.02360)

    通过对比云边模型解耦，提出了一种为异构联邦学习定制架构，该架构将深度神经网络分为捕获共享表示的主体和处理数据异构性的个性化头部，以优化联邦学习性能。

    

    联邦学习作为一种有前途的分布式学习范例，实现了多个网络边缘客户端之间全局模型的协作训练，而无需进行中央数据收集。然而，边缘数据分布的异构性使得模型倾向于局部极小值，这些极小值可能远离全局最优。这种异构性通常导致收敛速度缓慢且通信开销巨大。为解决这些问题，我们提出了一种名为FedCMD的新型联邦学习框架，即适应云边支持的联邦学习的模型解耦，将深度神经网络分为用于获取云端共享表示的主体和用于迁移数据异构性的个性化头部。我们的动机是，通过深入研究选择不同神经网络层作为个性化头部的性能，发现将最后一层刚性分配为个性化头部可能无法最大化改善异构性数据性能，从而提出了一种自动化选择个性化头部的方法。

    arXiv:2403.02360v1 Announce Type: cross  Abstract: Federated learning, as a promising distributed learning paradigm, enables collaborative training of a global model across multiple network edge clients without the need for central data collecting. However, the heterogeneity of edge data distribution drags the model towards the local minima, which can be distant from the global optimum. Such heterogeneity often leads to slow convergence and substantial communication overhead. To address these issues, we propose a novel federated learning framework called FedCMD, a model decoupling tailored to the Cloud-edge supported federated learning that separates deep neural networks into a body for capturing shared representations in Cloud and a personalized head for migrating data heterogeneity. Our motivation is that, by the deep investigation of the performance of selecting different neural network layers as the personalized head, we found rigidly assigning the last layer as the personalized he
    
[^120]: 在超复数空间中利用时间敏感关系进行时间知识图补全

    Temporal Knowledge Graph Completion with Time-sensitive Relations in Hypercomplex Space

    [https://arxiv.org/abs/2403.02355](https://arxiv.org/abs/2403.02355)

    该论文提出在超复数空间中利用更具表现力的四元数表示进行时间知识图补全，着重捕捉时间敏感关系，并理论上验证了方法可以建模各种关系模式，实验表明该方法达到了最新的性能水平。

    

    时间知识图补全（TKGC）旨在在给定特定时间的时间知识图中填补缺失的事实。本文通过引入更具表现力的四元数表示在超复数空间中进行TKGC，超越了传统方法。我们的研究聚焦于捕捉时间敏感关系，而不是时间感知实体，通过时间感知的旋转和周期性时间平移来建模时间敏感关系，有效捕捉复杂的时间变化。此外，我们在理论上证明了我们的方法能够建模对称、非对称、逆向、组合和演变的关系模式。公共数据集上的综合实验验证了我们提出的方法实现了最新的性能。

    arXiv:2403.02355v1 Announce Type: cross  Abstract: Temporal knowledge graph completion (TKGC) aims to fill in missing facts within a given temporal knowledge graph at a specific time. Existing methods, operating in real or complex spaces, have demonstrated promising performance in this task. This paper advances beyond conventional approaches by introducing more expressive quaternion representations for TKGC within hypercomplex space. Unlike existing quaternion-based methods, our study focuses on capturing time-sensitive relations rather than time-aware entities. Specifically, we model time-sensitive relations through time-aware rotation and periodic time translation, effectively capturing complex temporal variability. Furthermore, we theoretically demonstrate our method's capability to model symmetric, asymmetric, inverse, compositional, and evolutionary relation patterns. Comprehensive experiments on public datasets validate that our proposed approach achieves state-of-the-art perform
    
[^121]: 基于时空场神经网络的空气质量推断

    Spatio-Temporal Field Neural Networks for Air Quality Inference

    [https://arxiv.org/abs/2403.02354](https://arxiv.org/abs/2403.02354)

    该研究提出了基于时空场神经网络的新模型和金字塔推断框架，在空气质量推断中取得了最先进的性能。

    

    空气质量推断问题旨在利用来自有限观测站的历史数据推断未知位置的空气质量指数。考虑到观测站高昂的维护成本导致数据稀疏性，良好的推断算法可以有效节约成本并细化数据粒度。尽管时空图神经网络在这个问题上取得了显著进展，但它们对现实的非欧几里得和离散数据结构建模限制了潜力。本文首次尝试通过提出一个新模型，即时空场神经网络，及其对应的新框架，金字塔推断，将两种不同的时空观点，场和图，相结合。大量实验证实我们的模型在中国大陆全国范围内的空气质量推断中实现了最新技术水平，展示了我们提出的模型的优越性。

    arXiv:2403.02354v1 Announce Type: cross  Abstract: The air quality inference problem aims to utilize historical data from a limited number of observation sites to infer the air quality index at an unknown location. Considering the sparsity of data due to the high maintenance cost of the stations, good inference algorithms can effectively save the cost and refine the data granularity. While spatio-temporal graph neural networks have made excellent progress on this problem, their non-Euclidean and discrete data structure modeling of reality limits its potential. In this work, we make the first attempt to combine two different spatio-temporal perspectives, fields and graphs, by proposing a new model, Spatio-Temporal Field Neural Network, and its corresponding new framework, Pyramidal Inference. Extensive experiments validate that our model achieves state-of-the-art performance in nationwide air quality inference in the Chinese Mainland, demonstrating the superiority of our proposed model 
    
[^122]: ATP: 通过对顶级主要键进行关注实现快速LLM服务

    ATP: Enabling Fast LLM Serving via Attention on Top Principal Keys

    [https://arxiv.org/abs/2403.02352](https://arxiv.org/abs/2403.02352)

    提出了一种新的注意机制ATP，通过关注顶级主要键而非每个标记，以实现对输入序列的快速处理，并能够在降低注意力复杂度的同时捕捉输入序列的语义关系。

    

    我们提出了一种具有线性复杂度的新型注意机制 ATP，该机制将注意力集中在顶级主要键上，而不是每个单独的标记上。特别地，ATP受到一个重要观察的驱动，即输入序列通常具有低秩结构，即输入序列可以由少量主要基表示。因此，ATP将输入转换为正交空间，并仅在顶级主要基上计算注意力。由于输入序列中观察到的低秩结构，ATP能够仅通过少量主要基捕捉输入序列中的语义关系。此外，注意复杂度从二次降低到线性，而不会引起明显的性能下降。ATP进一步为具有低秩输入的其他线性层减少了复杂度，与仅单纯进行注意力计算的先前工作相比，实现了更大的加速。

    arXiv:2403.02352v1 Announce Type: cross  Abstract: We propose a new attention mechanism with linear complexity, ATP, that fixates \textbf{A}ttention on \textbf{T}op \textbf{P}rincipal keys, rather than on each individual token. Particularly, ATP is driven by an important observation that input sequences are typically low-rank, i.e., input sequences can be represented by a few principal bases. Therefore, instead of directly iterating over all the input tokens, ATP transforms inputs into an orthogonal space and computes attention only on the top principal bases (keys). Owing to the observed low-rank structure in input sequences, ATP is able to capture semantic relationships in input sequences with a few principal keys. Furthermore, the attention complexity is reduced from \emph{quadratic} to \emph{linear} without incurring a noticeable performance drop. ATP further reduces complexity for other linear layers with low-rank inputs, leading to more speedup compared to prior works that solely
    
[^123]: 纠缠: 在事实核实中平衡惩罚和补偿的最大补偿问题重复困境博弈分析，虚假新闻与弱沃勒斯定律案例

    Entanglement: Balancing Punishment and Compensation, Repeated Dilemma Game-Theoretic Analysis of Maximum Compensation Problem for Bypass and Least Cost Paths in Fact-Checking, Case of Fake News with Weak Wallace's Law

    [https://arxiv.org/abs/2403.02342](https://arxiv.org/abs/2403.02342)

    通过研究最大补偿问题和惩罚优势问题，在信息传播中设计了一种策略来最大程度地减少虚假新闻传播并最大化可信信息传播，以重新评估新闻提供者的激励措施对信息市场平衡的影响。

    

    这篇研究笔记以一种新颖的方法来解决与虚假新闻传播和有效事实核实相关的问题。重点放在最小成本路径问题上，讨论围绕着使用Metzler函数和Metzler矩阵来模拟新闻提供者之间信息传播动态的方法。我们设计了一种策略来最小化虚假新闻的传播，同时最大化可信信息的传播。通过惩罚优势问题和最大补偿问题，我们开发并研究了一种重新评估新闻提供者激励措施的路径，并分析它们对信息市场平衡的影响。通过将纠缠概念应用于信息传播的背景中，我们揭示了新闻提供者之间相互作用的复杂性。

    arXiv:2403.02342v1 Announce Type: cross  Abstract: This research note is organized with respect to a novel approach to solving problems related to the spread of fake news and effective fact-checking. Focusing on the least-cost routing problem, the discussion is organized with respect to the use of Metzler functions and Metzler matrices to model the dynamics of information propagation among news providers. With this approach, we designed a strategy to minimize the spread of fake news, which is detrimental to informational health, while at the same time maximizing the spread of credible information. In particular, through the punitive dominance problem and the maximum compensation problem, we developed and examined a path to reassess the incentives of news providers to act and to analyze their impact on the equilibrium of the information market. By applying the concept of entanglement to the context of information propagation, we shed light on the complexity of interactions among news pr
    
[^124]: 神经红移：随机网络并非随机函数

    Neural Redshift: Random Networks are not Random Functions

    [https://arxiv.org/abs/2403.02241](https://arxiv.org/abs/2403.02241)

    本论文研究了未经训练的随机权重网络，发现即使简单的MLPs也具有强烈的归纳偏见，不同于传统观点的是，NNs并不具有固有的“简单偏见”，而是依赖于组件的作用。

    

    我们对神经网络（NNs）的泛化能力的理解仍不完整。目前的解释基于梯度下降（GD）的隐含偏见，但无法解释梯度自由方法中模型的能力，也无法解释最近观察到的未经训练网络的简单偏见。本文寻找NNs中的其他泛化源。为了独立于GD理解体系结构提供的归纳偏见，我们研究未经训练的随机权重网络。即使是简单的MLPs也表现出强烈的归纳偏见：在权重空间中进行均匀抽样会产生一个非常偏向于复杂性的函数分布。但与常规智慧不同，NNs并不具有固有的“简单偏见”。这一特性取决于组件，如ReLU、残差连接和层归一化。可利用替代体系结构构建偏向于任何复杂性水平的偏见。Transformers也具有这一特性。

    arXiv:2403.02241v1 Announce Type: cross  Abstract: Our understanding of the generalization capabilities of neural networks (NNs) is still incomplete. Prevailing explanations are based on implicit biases of gradient descent (GD) but they cannot account for the capabilities of models from gradient-free methods nor the simplicity bias recently observed in untrained networks. This paper seeks other sources of generalization in NNs.   Findings. To understand the inductive biases provided by architectures independently from GD, we examine untrained, random-weight networks. Even simple MLPs show strong inductive biases: uniform sampling in weight space yields a very biased distribution of functions in terms of complexity. But unlike common wisdom, NNs do not have an inherent "simplicity bias". This property depends on components such as ReLUs, residual connections, and layer normalizations. Alternative architectures can be built with a bias for any level of complexity. Transformers also inher
    
[^125]: 认知就是你需要的一切 - 大语言模型之上的人工智能下一层

    Cognition is All You Need - The Next Layer of AI Above Large Language Models

    [https://arxiv.org/abs/2403.02164](https://arxiv.org/abs/2403.02164)

    提出了认知人工智能，一个用于在大型语言模型之上实现以程序定义的神经符号认知的高级框架，为能够执行复杂多步知识工作的人工智能系统提供了路径。

    

    最近对话式人工智能工具的研究，比如由大型语言模型驱动的聊天机器人在复杂的实际知识工作中的应用已经显示出了与推理和多步问题解决相关的局限性。我们提出认知人工智能，这是一个用于在大型语言模型之上和之外实现以程序定义的神经符号认知的高级框架。具体而言，我们提出了认知人工智能的双层功能架构，作为能够执行复杂多步知识工作的人工智能系统的路线图。

    arXiv:2403.02164v1 Announce Type: new  Abstract: Recent studies of the applications of conversational AI tools, such as chatbots powered by large language models, to complex real-world knowledge work have shown limitations related to reasoning and multi-step problem solving. Specifically, while existing chatbots simulate shallow reasoning and understanding they are prone to errors as problem complexity increases. The failure of these systems to address complex knowledge work is due to the fact that they do not perform any actual cognition. In this position paper, we present Cognitive AI, a higher-level framework for implementing programmatically defined neuro-symbolic cognition above and outside of large language models. Specifically, we propose a dual-layer functional architecture for Cognitive AI that serves as a roadmap for AI systems that can perform complex multi-step knowledge work. We propose that Cognitive AI is a necessary precursor for the evolution of higher forms of AI, suc
    
[^126]: 基于内部表征的上下文锐度作为警报：减少幻觉的一个视角

    In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination Mitigation

    [https://arxiv.org/abs/2403.01548](https://arxiv.org/abs/2403.01548)

    本研究从内部表征角度深入探讨了大型语言模型幻觉的机制，发现了幻觉的一个显著模式，即在上下文标记的隐藏状态中，正确生成具有更清晰的上下文激活。我们提出了一种基于熵的度量方法，将“锐度”纳入解码过程中，制定了一种受限解码方法，实验证明其在知识寻求和幻觉任务上的有效性。

    

    大型语言模型（LLMs）经常会产生幻觉并产生事实错误，然而我们对它们为什么会犯这些错误的理解仍然有限。在本研究中，我们从内部表征的角度深入探讨LLM幻觉的潜在机制，并发现与幻觉相关的一个突出模式：正确的生成在上下文标记的隐藏状态中具有更清晰的上下文激活，而不正确的生成则没有。利用这一见解，我们提出了一种基于熵的度量来量化上下文隐藏状态之间的“锐度”，并将其纳入解码过程中以制定一种受限解码方法。在各种知识寻求和幻觉基准测试上的实验证明了我们方法的一致有效性，例如，在TruthfulQA上实现了高达8.6点的改进。我们相信这项研究可以提高我们对幻觉的理解。

    arXiv:2403.01548v1 Announce Type: cross  Abstract: Large language models (LLMs) frequently hallucinate and produce factual errors, yet our understanding of why they make these errors remains limited. In this study, we delve into the underlying mechanisms of LLM hallucinations from the perspective of inner representations, and discover a salient pattern associated with hallucinations: correct generations tend to have sharper context activations in the hidden states of the in-context tokens, compared to the incorrect ones. Leveraging this insight, we propose an entropy-based metric to quantify the ``sharpness'' among the in-context hidden states and incorporate it into the decoding process to formulate a constrained decoding approach. Experiments on various knowledge-seeking and hallucination benchmarks demonstrate our approach's consistent effectiveness, for example, achieving up to an 8.6 point improvement on TruthfulQA. We believe this study can improve our understanding of hallucinat
    
[^127]: 利用生物分子和自然语言的多模态学习：一项综述

    Leveraging Biomolecule and Natural Language through Multi-Modal Learning: A Survey

    [https://arxiv.org/abs/2403.01528](https://arxiv.org/abs/2403.01528)

    生物分子与自然语言相结合的多模态学习为全面表示和分析生物分子开辟了新途径。

    

    集成生物分子建模与自然语言（BL）已经成为人工智能、化学和生物学交叉领域中的一个具有前景的跨学科领域。这种方法利用文本数据源中包含的生物分子的丰富多面描述，增强我们对基本理解，并实现生物分子性质预测等计算任务。通过将自然语言中表达的微妙叙述与通过各种分子建模技术描述的生物分子的结构和功能细节融合，打开了全面表征和分析生物分子的新途径。通过将围绕生物分子的上下文语言数据纳入建模中，BL旨在捕捉包含语言传达的符号特性以及数量化结构特征的整体视图。

    arXiv:2403.01528v1 Announce Type: cross  Abstract: The integration of biomolecular modeling with natural language (BL) has emerged as a promising interdisciplinary area at the intersection of artificial intelligence, chemistry and biology. This approach leverages the rich, multifaceted descriptions of biomolecules contained within textual data sources to enhance our fundamental understanding and enable downstream computational tasks such as biomolecule property prediction. The fusion of the nuanced narratives expressed through natural language with the structural and functional specifics of biomolecules described via various molecular modeling techniques opens new avenues for comprehensively representing and analyzing biomolecules. By incorporating the contextual language data that surrounds biomolecules into their modeling, BL aims to capture a holistic view encompassing both the symbolic qualities conveyed through language as well as quantitative structural characteristics. In this r
    
[^128]: LLaMoCo：用于优化代码生成的大型语言模型指令调优

    LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation

    [https://arxiv.org/abs/2403.01131](https://arxiv.org/abs/2403.01131)

    LLaMoCo是第一个旨在以代码对代码方式调整LLMs以解决优化问题的指令调优框架，通过全面指令集和新颖的两阶段学习策略，实现了优越的性能。

    

    最近的研究探讨了使用大型语言模型（LLMs）进行优化，方法包括从LLMs迭代地寻找下一步解决方案，或直接提示LLMs以获取优化器。然而，这些方法存在固有限制，包括操作效率低、对提示设计敏感度高以及缺乏领域特定知识。我们介绍了LLaMoCo，这是第一个旨在以代码对代码方式调整LLMs以解决优化问题的指令调优框架。具体地，我们建立了一个包含清晰描述的问题提示和有效优化代码的全面指令集。然后我们开发了一种新颖的两阶段学习策略，在指令调优阶段之前，该策略整合了基于对比学习的热身过程，以增强模型微调期间的收敛行为。实验结果表明，通过我们的LLaMoCo精调的CodeGen（350M）模型达到了卓越的性能。

    arXiv:2403.01131v1 Announce Type: cross  Abstract: Recent research explores optimization using large language models (LLMs) by either iteratively seeking next-step solutions from LLMs or directly prompting LLMs for an optimizer. However, these approaches exhibit inherent limitations, including low operational efficiency, high sensitivity to prompt design, and a lack of domain-specific knowledge. We introduce LLaMoCo, the first instruction-tuning framework designed to adapt LLMs for solving optimization problems in a code-to-code manner. Specifically, we establish a comprehensive instruction set containing well-described problem prompts and effective optimization codes. We then develop a novel two-phase learning strategy that incorporates a contrastive learning-based warm-up procedure before the instruction-tuning phase to enhance the convergence behavior during model fine-tuning. The experiment results demonstrate that a CodeGen (350M) model fine-tuned by our LLaMoCo achieves superior 
    
[^129]: 透过几何限制概率建模发现新生物医学概念

    Seeing Unseen: Discover Novel Biomedical Concepts via GeometryConstrained Probabilistic Modeling

    [https://arxiv.org/abs/2403.01053](https://arxiv.org/abs/2403.01053)

    提出了一种通过几何限制概率建模处理方法来解决生物医学数据中存在的非 i.i.d. 数据分布、类别不平衡等问题。

    

    arXiv:2403.01053v1 通告类型: 交叉  摘要: 机器学习以其数据驱动的特性，对科学发现的基本实践具有巨大的潜力改变。随着不断增加的研究数据收集，自动探索观测数据中的模式和见解，发现新的表型类别和概念将会变得更加吸引人。然而，在生物医学领域，累积数据中存在若干挑战，阻碍了新类发现的进展。非 i.i.d. 数据分布伴随着不同类别组之间的严重不平衡，本质上导致模糊和偏倚的语义表示。在这项工作中，我们提出了一种几何限制概率建模处理方法来解决所识别的问题。首先，我们建议将实例嵌入的近似后验参数化为边际 von Mises-Fisher 分布，以解决神经嵌入方案的模糊性与偏见性。

    arXiv:2403.01053v1 Announce Type: cross  Abstract: Machine learning holds tremendous promise for transforming the fundamental practice of scientific discovery by virtue of its data-driven nature. With the ever-increasing stream of research data collection, it would be appealing to autonomously explore patterns and insights from observational data for discovering novel classes of phenotypes and concepts. However, in the biomedical domain, there are several challenges inherently presented in the cumulated data which hamper the progress of novel class discovery. The non-i.i.d. data distribution accompanied by the severe imbalance among different groups of classes essentially leads to ambiguous and biased semantic representations. In this work, we present a geometry-constrained probabilistic modeling treatment to resolve the identified issues. First, we propose to parameterize the approximated posterior of instance embedding as a marginal von MisesFisher distribution to account for the int
    
[^130]: 利用共因原则解决辛普森悖论

    Resolution of Simpson's paradox via the common cause principle

    [https://arxiv.org/abs/2403.00957](https://arxiv.org/abs/2403.00957)

    通过对共同原因$C$进行条件设定，解决了辛普森悖论，推广了悖论，并表明在二元共同原因$C$上进行条件设定的关联方向与原始$B$上进行条件设定相同

    

    辛普森悖论是建立两个事件$a_1$和$a_2$之间的概率关联时的障碍，给定第三个（潜在的）随机变量$B$。我们关注的情景是随机变量$A$（汇总了$a_1$、$a_2$及其补集）和$B$有一个可能未被观察到的共同原因$C$。或者，我们可以假设$C$将$A$从$B$中筛选出去。对于这种情况，正确的$a_1$和$a_2$之间的关联应该通过对$C$进行条件设定来定义。这一设置将原始辛普森悖论推广了。现在它的两个相互矛盾的选项简单地指的是两个特定且不同的原因$C$。我们表明，如果$B$和$C$是二进制的，$A$是四进制的（对于有效的辛普森悖论来说是最小且最常见的情况），在任何二元共同原因$C$上进行条件设定将建立与在原始$B$上进行条件设定相同的$a_1$和$a_2$之间的关联方向。

    arXiv:2403.00957v1 Announce Type: cross  Abstract: Simpson's paradox is an obstacle to establishing a probabilistic association between two events $a_1$ and $a_2$, given the third (lurking) random variable $B$. We focus on scenarios when the random variables $A$ (which combines $a_1$, $a_2$, and their complements) and $B$ have a common cause $C$ that need not be observed. Alternatively, we can assume that $C$ screens out $A$ from $B$. For such cases, the correct association between $a_1$ and $a_2$ is to be defined via conditioning over $C$. This set-up generalizes the original Simpson's paradox. Now its two contradicting options simply refer to two particular and different causes $C$. We show that if $B$ and $C$ are binary and $A$ is quaternary (the minimal and the most widespread situation for valid Simpson's paradox), the conditioning over any binary common cause $C$ establishes the same direction of the association between $a_1$ and $a_2$ as the conditioning over $B$ in the original
    
[^131]: 通过Wasserstein生成对抗网络使用数据增强改进Android恶意软件检测

    Improving Android Malware Detection Through Data Augmentation Using Wasserstein Generative Adversarial Networks

    [https://arxiv.org/abs/2403.00890](https://arxiv.org/abs/2403.00890)

    通过使用Wasserstein生成对抗网络生成的数据进行数据增强，该研究提出了一种利用卷积神经网络识别未知Android恶意软件应用程序的方法，并通过降低存储需求来改进Android恶意软件检测的效果。

    

    生成对抗网络（GANs）已经展示了它们在各种应用中的多功能性，包括数据增强和恶意软件检测。这项研究探讨了利用GAN生成的数据来训练一个用于检测Android恶意软件的模型的有效性。鉴于Android应用的存储需求相当大，该研究提出了一种使用GAN来合成表示数据的方法，从而降低存储需求。所提出的方法涉及创建从现有数据集中提取的特征的图像表示。然后，使用GAN模型生成由逼真的合成灰度图像组成的更广泛的数据集。随后，这个合成数据集被用来训练一个卷积神经网络（CNN），旨在识别以前看不到的Android恶意应用程序。该研究包括对当CNN在真实图像与GAN生成图像上进行训练时性能的比较分析。

    arXiv:2403.00890v1 Announce Type: cross  Abstract: Generative Adversarial Networks (GANs) have demonstrated their versatility across various applications, including data augmentation and malware detection. This research explores the effectiveness of utilizing GAN-generated data to train a model for the detection of Android malware. Given the considerable storage requirements of Android applications, the study proposes a method to synthetically represent data using GANs, thereby reducing storage demands. The proposed methodology involves creating image representations of features extracted from an existing dataset. A GAN model is then employed to generate a more extensive dataset consisting of realistic synthetic grayscale images. Subsequently, this synthetic dataset is utilized to train a Convolutional Neural Network (CNN) designed to identify previously unseen Android malware applications. The study includes a comparative analysis of the CNN's performance when trained on real images v
    
[^132]: 利用LLMs进行元数据丰富化的受控词汇列标题文本分类

    Text classification of column headers with a controlled vocabulary: leveraging LLMs for metadata enrichment

    [https://arxiv.org/abs/2403.00884](https://arxiv.org/abs/2403.00884)

    通过利用LLMs，我们提出了一种方法，使用ChatGPT-3.5、GoogleBard和GoogleGemini对列标题进行主题注释的元数据丰富化，研究它们在对领域特定主题进行分类的能力，并评估其内部一致性、机器对齐性和人机一致性。ChatGPT和GoogleGemini在内部一致性以及与人一致性方面优于GoogleBard。

    

    传统的数据集检索系统主要在元数据信息而非数据值上建立索引。因此主要依赖于手动注释和高质量的元数据，这些过程被认为是耗时且难以自动化的。我们提出了一种方法，利用三种大型语言模型（LLMs）支持对列标题进行主题注释的元数据丰富化：ChatGPT-3.5、GoogleBard和GoogleGemini。我们研究了LLMs基于受控词汇的领域特定主题对列标题进行分类的能力。我们通过评估LLMs的内部一致性、机器间对齐以及人机对主题分类任务的一致性来评估我们的方法。此外，我们还探讨了上下文信息（即数据集描述）对分类结果的影响。我们的结果表明，ChatGPT和GoogleGemini在内部一致性以及LLM与人之间的一致性方面表现优于GoogleBard。

    arXiv:2403.00884v1 Announce Type: cross  Abstract: Traditional dataset retrieval systems index on metadata information rather than on the data values. Thus relying primarily on manual annotations and high-quality metadata, processes known to be labour-intensive and challenging to automate. We propose a method to support metadata enrichment with topic annotations of column headers using three Large Language Models (LLMs): ChatGPT-3.5, GoogleBard and GoogleGemini. We investigate the LLMs ability to classify column headers based on domain-specific topics from a controlled vocabulary. We evaluate our approach by assessing the internal consistency of the LLMs, the inter-machine alignment, and the human-machine agreement for the topic classification task. Additionally, we investigate the impact of contextual information (i.e. dataset description) on the classification outcomes. Our results suggest that ChatGPT and GoogleGemini outperform GoogleBard for internal consistency as well as LLM-hum
    
[^133]: 梯度被罚：通过探索拒绝损失地形图来检测针对大语言模型的越狱攻击

    Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes

    [https://arxiv.org/abs/2403.00867](https://arxiv.org/abs/2403.00867)

    本文提出了一种名为Gradient Cuff的方法，通过探索拒绝损失地形图来检测对大语言模型的越狱攻击，成功设计了一种有效的两步检测策略。

    

    大型语言模型（LLMs）正成为一种突出的生成式AI工具，用户输入查询，LLM生成答案。为了减少伤害和滥用，人们通过使用先进的训练技术如来自人类反馈的强化学习（RLHF）来将这些LLMs与人类价值观保持一致。然而，最近的研究突显了LLMs对于试图颠覆嵌入的安全防护措施的对抗性越狱尝试的脆弱性。为了解决这一挑战，本文定义并调查了LLMs的拒绝损失，然后提出了一种名为Gradient Cuff的方法来检测越狱尝试。Gradient Cuff利用拒绝损失地形图中观察到的独特特性，包括功能值及其光滑性，设计了一种有效的两步检测策略。

    arXiv:2403.00867v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are becoming a prominent generative AI tool, where the user enters a query and the LLM generates an answer. To reduce harm and misuse, efforts have been made to align these LLMs to human values using advanced training techniques such as Reinforcement Learning from Human Feedback (RLHF). However, recent studies have highlighted the vulnerability of LLMs to adversarial jailbreak attempts aiming at subverting the embedded safety guardrails. To address this challenge, this paper defines and investigates the Refusal Loss of LLMs and then proposes a method called Gradient Cuff to detect jailbreak attempts. Gradient Cuff exploits the unique properties observed in the refusal loss landscape, including functional values and its smoothness, to design an effective two-step detection strategy. Experimental results on two aligned LLMs (LLaMA-2-7B-Chat and Vicuna-7B-V1.5) and six types of jailbreak attacks (GCG, AutoDAN,
    
[^134]: CLLMs: 一致性大型语言模型

    CLLMs: Consistency Large Language Models

    [https://arxiv.org/abs/2403.00835](https://arxiv.org/abs/2403.00835)

    提出了一种新方法，通过精细调整目标LLM实现了对雅各比轨迹上固定点的一致性预测，有效提高了生成速度2.4倍到3.4倍。

    

    并行解码方法，如雅可比解码，显示出有望实现更高效的LLM推断，因为它打破了LLM解码过程的顺序性，并将其转换为可并行化计算。然而，在实践中，与传统的自回归（AR）解码相比，雅可比解码很少能在单个固定点迭代步骤中准确预测多个标记，因此在速度上取得的提升相对较小。为了解决这个问题，我们开发了一种新方法，旨在实现从任何状态快速收敛到雅各比轨迹上的固定点。通过精细调整目标LLM，以便在任何输入状态下一致地预测固定点。大量实验证明了我们方法的有效性，在领域特定和开放域基准测试中显示出生成速度提高了2.4倍到3.4倍，同时保持了生成质量。

    arXiv:2403.00835v1 Announce Type: cross  Abstract: Parallel decoding methods such as Jacobi decoding show promise for more efficient LLM inference as it breaks the sequential nature of the LLM decoding process and transforms it into parallelizable computation. However, in practice, it achieves little speedup compared to traditional autoregressive (AR) decoding, primarily because Jacobi decoding seldom accurately predicts more than one token in a single fixed-point iteration step. To address this, we develop a new approach aimed at realizing fast convergence from any state to the fixed point on a Jacobi trajectory. This is accomplished by refining the target LLM to consistently predict the fixed point given any state as input. Extensive experiments demonstrate the effectiveness of our method, showing 2.4$\times$ to 3.4$\times$ improvements in generation speed while preserving generation quality across both domain-specific and open-domain benchmarks.
    
[^135]: 自主检索：利用一个大型语言模型构建信息检索系统

    Self-Retrieval: Building an Information Retrieval System with One Large Language Model

    [https://arxiv.org/abs/2403.00801](https://arxiv.org/abs/2403.00801)

    提出了自主检索(Self-Retrieval)，利用一个大型语言模型完全内化信息检索系统的能力，深度利用大型语言模型在信息检索过程中的能力。

    

    大型语言模型的兴起改变了信息检索系统在人类获取信息过程中的角色。由于现有信息检索系统具有孤立的架构和有限的相互作用，无法完全适应直接向人类提供信息转变为间接为大型语言模型提供服务的变化。本文提出了自主检索(Self-Retrieval)，这是一个端到端、以大型语言模型驱动的信息检索架构，可以完全内化信息检索系统所需的能力到单个大型语言模型中，并深度利用大型语言模型在信息检索过程中的能力。具体来说，自主检索通过自然语言索引架构将要检索的语料内化为一个大型语言模型。然后整个检索过程被重新定义为文档生成和自我评估的过程，可以使用单个大型语言模型端到端执行。实验结果表明S

    arXiv:2403.00801v1 Announce Type: cross  Abstract: The rise of large language models (LLMs) has transformed the role of information retrieval (IR) systems in the way to humans accessing information. Due to the isolated architecture and the limited interaction, existing IR systems are unable to fully accommodate the shift from directly providing information to humans to indirectly serving large language models. In this paper, we propose Self-Retrieval, an end-to-end, LLM-driven information retrieval architecture that can fully internalize the required abilities of IR systems into a single LLM and deeply leverage the capabilities of LLMs during IR process. Specifically, Self-retrieval internalizes the corpus to retrieve into a LLM via a natural language indexing architecture. Then the entire retrieval process is redefined as a procedure of document generation and self-assessment, which can be end-to-end executed using a single large language model. Experimental results demonstrate that S
    
[^136]: 认识你的异常：走向知识表示中的异常本体论

    Know your exceptions: Towards an Ontology of Exceptions in Knowledge Representation

    [https://arxiv.org/abs/2403.00685](https://arxiv.org/abs/2403.00685)

    提出了基于异常性和可辩识性的框架，用于比较形式化体系并揭示其本体论承诺，应用框架比较了四个系统，展示了从本体论角度可能发生的差异。

    

    可辩驳推理是一种推理形式，其中一些概括在某些情况下可能无效，也就是通常情况下的一般性结论在某些情况下可能会失败。已经开发了各种形式化体系来模拟这种推理，这是普通常识背景下的特征。然而，对于一个模型者来说，从本体论的角度选择最适合其领域的体系并不容易。在本文中，我们首先提出了一个基于异常性和可辩识性的框架，以便比较形式化体系并揭示其本体论承诺。然后，我们应用该框架来比较四个系统，展示了从本体论角度可能发生的差异。

    arXiv:2403.00685v1 Announce Type: new  Abstract: Defeasible reasoning is a kind of reasoning where some generalisations may not be valid in all circumstances, that is general conclusions may fail in some cases. Various formalisms have been developed to model this kind of reasoning, which is characteristic of common-sense contexts. However, it is not easy for a modeller to choose among these systems the one that better fits its domain from an ontological point of view. In this paper we first propose a framework based on the notions of exceptionality and defeasibility in order to be able to compare formalisms and reveal their ontological commitments. Then, we apply this framework to compare four systems, showing the differences that may occur from an ontological perspective.
    
[^137]: 形态变异：通过隐喻视觉叙事进行互动、情感和创造性梦境叙述

    Metamorpheus: Interactive, Affective, and Creative Dream Narration Through Metaphorical Visual Storytelling

    [https://arxiv.org/abs/2403.00632](https://arxiv.org/abs/2403.00632)

    本研究提出了Metamorpheus，一种情感接口，通过创造性的视觉叙事来参与用户在梦境中的情感经历，利用生成式人工智能生成视觉隐喻和文本描绘，促使自我反思。

    

    人类的情感基本上是由生活经验塑造的，我们从中构建个性化意义。参与这种意义塑造过程已经被作为各种心理治疗中的一种干预来促进健康。然而，支持在日常生活中回忆和叙述生活经验仍然在人机交互领域鲜有探讨。如何利用生成式人工智能模型等技术来促进意义塑造过程，最终支持情感正念仍然是未知的。在本文中，我们呈现了Metamorpheus，一种情感接口，通过创造性的视觉叙事来参与用户在梦境中的情感经历。Metamorpheus根据梦境的情感弧线排列故事情节，并通过创造隐喻图像和文本描绘来促使自我反思。该系统提供隐喻建议，并利用生成式人工智能生成视觉隐喻和文本描绘。

    arXiv:2403.00632v1 Announce Type: cross  Abstract: Human emotions are essentially molded by lived experiences, from which we construct personalised meaning. The engagement in such meaning-making process has been practiced as an intervention in various psychotherapies to promote wellness. Nevertheless, to support recollecting and recounting lived experiences in everyday life remains under explored in HCI. It also remains unknown how technologies such as generative AI models can facilitate the meaning making process, and ultimately support affective mindfulness. In this paper we present Metamorpheus, an affective interface that engages users in a creative visual storytelling of emotional experiences during dreams. Metamorpheus arranges the storyline based on a dream's emotional arc, and provokes self-reflection through the creation of metaphorical images and text depictions. The system provides metaphor suggestions, and generates visual metaphors and text depictions using generative AI m
    
[^138]: GraphPub: 具有高可用性的差分隐私图生成

    GraphPub: Generation of Differential Privacy Graph with High Availability

    [https://arxiv.org/abs/2403.00030](https://arxiv.org/abs/2403.00030)

    提出了一种名为GraphPub的新型图边保护框架，通过反向学习和编码器-解码器机制，在保护图拓扑结构的同时保证数据的可用性基本不变。

    

    近年来，随着图神经网络（GNN）的快速发展，越来越多的图数据集被用于GNN任务。然而，当上游数据所有者发布图数据时，往往会存在许多隐私问题，因为许多现实世界的图数据包含像个人的朋友列表等敏感信息。差分隐私（DP）是一种常用的保护隐私的方法，但由于图数据的复杂拓扑结构，将DP应用在图上往往会影响GNN模型的消息传递和聚合，导致模型准确性下降。本文提出了一种新颖的图边保护框架GraphPub，可以保护图拓扑结构同时确保数据的可用性基本不变。通过反向学习和编码器-解码器机制，我们搜索一些对节点特征聚合没有太大负面影响的虚假边。

    arXiv:2403.00030v1 Announce Type: cross  Abstract: In recent years, with the rapid development of graph neural networks (GNN), more and more graph datasets have been published for GNN tasks. However, when an upstream data owner publishes graph data, there are often many privacy concerns, because many real-world graph data contain sensitive information like person's friend list. Differential privacy (DP) is a common method to protect privacy, but due to the complex topological structure of graph data, applying DP on graphs often affects the message passing and aggregation of GNN models, leading to a decrease in model accuracy. In this paper, we propose a novel graph edge protection framework, graph publisher (GraphPub), which can protect graph topology while ensuring that the availability of data is basically unchanged. Through reverse learning and the encoder-decoder mechanism, we search for some false edges that do not have a large negative impact on the aggregation of node features, 
    
[^139]: 通过长文本编码器提升罗马尼亚法律判决预测的能力

    Improving Legal Judgement Prediction in Romanian with Long Text Encoders

    [https://arxiv.org/abs/2402.19170](https://arxiv.org/abs/2402.19170)

    本研究关注通过扩展Transformer模型的序列长度来更好理解法律语料库中的长文档，并在罗马尼亚的4个LJP数据集上进行了广泛实验。

    

    最近几年，自然语言处理（NLP）领域取得了惊人的新成果，在各种任务上实现了接近人类水平的性能。法律NLP领域也随之发展迅猛。然而，通用模型并不直接适用于法律领域。由于其专业词汇、长文档等特点，法律NLP通常需要特定模型和方法。本文研究了专业和通用模型用于预测法律案例的最终裁决的方法，即法律判决预测（LJP）任务。我们特别关注如何扩展基于Transformer模型的序列长度，以更好地理解法律语料库中的长文档。在来自两个来源、规模和文档长度显著不同时的4个罗马尼亚LJP数据集上进行了大量实验，结果显示专门模型...

    arXiv:2402.19170v1 Announce Type: cross  Abstract: In recent years,the entire field of Natural Language Processing (NLP) has enjoyed amazing novel results achieving almost human-like performance on a variety of tasks. Legal NLP domain has also been part of this process, as it has seen an impressive growth. However, general-purpose models are not readily applicable for legal domain. Due to the nature of the domain (e.g. specialized vocabulary, long documents) specific models and methods are often needed for Legal NLP. In this work we investigate both specialized and general models for predicting the final ruling of a legal case, task known as Legal Judgment Prediction (LJP). We particularly focus on methods to extend to sequence length of Transformer-based models to better understand the long documents present in legal corpora. Extensive experiments on 4 LJP datasets in Romanian, originating from 2 sources with significantly different sizes and document lengths, show that specialized mo
    
[^140]: FedUV: 异构联邦学习的均匀性和方差

    FedUV: Uniformity and Variance for Heterogeneous Federated Learning

    [https://arxiv.org/abs/2402.18372](https://arxiv.org/abs/2402.18372)

    提出了FedUV框架，通过引入两种正则化项，促使局部模型在异构分布数据中表现得更均匀和稳定

    

    联邦学习是一种训练神经网络的有希望的框架，能够处理广泛分布的数据。然而，性能很大程度上会随着异构分布的数据而下降。最近的研究表明，这是由于网络的最终层最容易出现局部偏差，一些研究发现通过将最终层冻结为正交分类器可以取得成功。我们通过对权重应用奇异值分解来研究分类器的训练动态，这是受到冻结权重导致奇异值恒定的观察启发的。我们发现在IID和非IID设置下训练时存在差异。基于这一发现，我们引入两种局部训练的正则化项，以持续模拟IID设置：（1）分类器的维度概率分布方差和（2）编码器表示的超球均匀性。这些正则化促使局部模型表现得好像在IID设置中一样。

    arXiv:2402.18372v1 Announce Type: cross  Abstract: Federated learning is a promising framework to train neural networks with widely distributed data. However, performance degrades heavily with heterogeneously distributed data. Recent work has shown this is due to the final layer of the network being most prone to local bias, some finding success freezing the final layer as an orthogonal classifier. We investigate the training dynamics of the classifier by applying SVD to the weights motivated by the observation that freezing weights results in constant singular values. We find that there are differences when training in IID and non-IID settings. Based on this finding, we introduce two regularization terms for local training to continuously emulate IID settings: (1) variance in the dimension-wise probability distribution of the classifier and (2) hyperspherical uniformity of representations of the encoder. These regularizations promote local models to act as if it were in an IID setting
    
[^141]: BiVRec: 双向基于视图的多模态顺序推荐

    BiVRec: Bidirectional View-based Multimodal Sequential Recommendation

    [https://arxiv.org/abs/2402.17334](https://arxiv.org/abs/2402.17334)

    提出了一个创新框架 BiVRec，在推荐任务中联合训练 ID 和多模态视图，双向增强推荐性能。

    

    多模态信息融入顺序推荐系统近来引起了研究的广泛关注。在多模态顺序推荐模型的初期阶段，主流范式是ID主导推荐，即多模态信息作为辅助信息进行融合。然而，由于其在可转移性和信息侵入方面的局限性，另一种范式出现了，即直接利用多模态特征进行推荐，实现跨数据集的推荐。尽管如此，它忽略了用户ID信息，导致信息利用率低和训练成本高。为此，我们提出了一个创新框架，BiVRec，通过联合训练ID和多模态视图中的推荐任务，利用它们之间的协同关系双向增强推荐性能。为了解决信息异构性问题，我们...

    arXiv:2402.17334v1 Announce Type: cross  Abstract: The integration of multimodal information into sequential recommender systems has attracted significant attention in recent research. In the initial stages of multimodal sequential recommendation models, the mainstream paradigm was ID-dominant recommendations, wherein multimodal information was fused as side information. However, due to their limitations in terms of transferability and information intrusion, another paradigm emerged, wherein multimodal features were employed directly for recommendation, enabling recommendation across datasets. Nonetheless, it overlooked user ID information, resulting in low information utilization and high training costs. To this end, we propose an innovative framework, BivRec, that jointly trains the recommendation tasks in both ID and multimodal views, leveraging their synergistic relationship to enhance recommendation performance bidirectionally. To tackle the information heterogeneity issue, we fir
    
[^142]: 由Transformer驱动的端到端语义通信的码书生成方法

    Codebook-enabled Generative End-to-end Semantic Communication Powered by Transformer

    [https://arxiv.org/abs/2402.16868](https://arxiv.org/abs/2402.16868)

    本文提出了一个强大的码书辅助图像语义通信系统，通过联合构建语义编解码器和码书、设计向量-索引变换器来实现图像生成，并且借助高质量码书帮助Transformer，提高系统对抗信道噪声的鲁棒性。

    

    基于码书的生成式语义通信引起了越来越多的关注，因为当码书在发送者和接收者之间共享时，只需要传输索引。然而，由于码向量之间的语义关系未必与对应码索引的距离相关，码书启用的语义通信系统性能容易受到信道噪声的影响。因此，如何提高系统对抗噪声的鲁棒性需要仔细设计。本文提出了一个强大的码书辅助图像语义通信系统，其中首先联合构建语义编解码器和码书，然后设计了向量-索引变换器，根据码书引导以消除信道噪声的影响，并实现图像生成。由于高质量码书对Transformer的辅助，接收端生成的图像效果优于...

    arXiv:2402.16868v1 Announce Type: cross  Abstract: Codebook-based generative semantic communication attracts increasing attention, since only indices are required to be transmitted when the codebook is shared between transmitter and receiver. However, due to the fact that the semantic relations among code vectors are not necessarily related to the distance of the corresponding code indices, the performance of the codebook-enabled semantic communication system is susceptible to the channel noise. Thus, how to improve the system robustness against the noise requires careful design. This paper proposes a robust codebook-assisted image semantic communication system, where semantic codec and codebook are first jointly constructed, and then vector-to-index transformer is designed guided by the codebook to eliminate the effects of channel noise, and achieve image generation. Thanks to the assistance of the high-quality codebook to the Transformer, the generated images at the receiver outperfo
    
[^143]: GraphEdit：用于图结构学习的大型语言模型

    GraphEdit: Large Language Models for Graph Structure Learning

    [https://arxiv.org/abs/2402.15183](https://arxiv.org/abs/2402.15183)

    本研究提出了一种名为GraphEdit的方法，利用大型语言模型（LLMs）学习复杂的图结构化数据中的节点关系，通过在图结构上进行指导调整，增强LLMs的推理能力，从而提高图结构学习的可靠性。

    

    图结构学习（GSL）致力于通过生成新颖的图结构来捕捉图结构数据中节点之间的固有依赖性和相互作用。本文提出了一种名为GraphEdit的方法，利用大型语言模型（LLMs）学习图结构化数据中复杂的节点关系。通过在图结构上进行指导调整，增强LLMs的推理能力，我们旨在克服显式图结构信息带来的挑战，并提高图结构学习的可靠性。

    arXiv:2402.15183v1 Announce Type: cross  Abstract: Graph Structure Learning (GSL) focuses on capturing intrinsic dependencies and interactions among nodes in graph-structured data by generating novel graph structures. Graph Neural Networks (GNNs) have emerged as promising GSL solutions, utilizing recursive message passing to encode node-wise inter-dependencies. However, many existing GSL methods heavily depend on explicit graph structural information as supervision signals, leaving them susceptible to challenges such as data noise and sparsity. In this work, we propose GraphEdit, an approach that leverages large language models (LLMs) to learn complex node relationships in graph-structured data. By enhancing the reasoning capabilities of LLMs through instruction-tuning over graph structures, we aim to overcome the limitations associated with explicit graph structural information and enhance the reliability of graph structure learning. Our approach not only effectively denoises noisy co
    
[^144]: 递归推测解码：通过无重复抽样加速LLM推理

    Recursive Speculative Decoding: Accelerating LLM Inference via Sampling Without Replacement

    [https://arxiv.org/abs/2402.14160](https://arxiv.org/abs/2402.14160)

    提出了递归推测解码(RSD)方法，通过无重复抽样最大化树的多样性，从而进一步加速LLM推理过程。

    

    推测解码是一种用于大型语言模型(LLMs)的推理加速方法，其中一个小型语言模型生成一个草稿令牌序列，该序列进一步由目标LLM并行验证。最近的研究通过建立草稿令牌树推进了这种方法，实现了优于单序列推测解码的性能。然而，这些工作在树的每个级别独立生成令牌，没有利用整个树的多样性。此外，尽管固定序列长度已经显示出更好的性能，但这些作品在固定目标计算资源上并没有进行实证研究，这是对于资源受限设备至关重要的。我们提出了递归推测解码(RSD)，一种新的基于树的方法，它对不重复抽样的草稿令牌进行最大化，并最大限度地实现了多样性。

    arXiv:2402.14160v1 Announce Type: cross  Abstract: Speculative decoding is an inference-acceleration method for large language models (LLMs) where a small language model generates a draft-token sequence which is further verified by the target LLM in parallel. Recent works have advanced this method by establishing a draft-token tree, achieving superior performance over a single-sequence speculative decoding. However, those works independently generate tokens at each level of the tree, not leveraging the tree's entire diversifiability. Besides, their empirical superiority has been shown for fixed length of sequences, implicitly granting more computational resource to LLM for the tree-based methods. None of the existing works has conducted empirical studies with fixed target computational budgets despite its importance to resource-bounded devices. We present Recursive Speculative Decoding (RSD), a novel tree-based method that samples draft tokens without replacement and maximizes the dive
    
[^145]: 连续葡萄糖监测和维护的神经控制系统

    Neural Control System for Continuous Glucose Monitoring and Maintenance

    [https://arxiv.org/abs/2402.13852](https://arxiv.org/abs/2402.13852)

    引入了一种新颖的神经控制系统，用于连续葡萄糖监测和维护，实时动态调整胰岛素输送，增强葡萄糖优化，最大化效率并确保个性化护理。

    

    精确的葡萄糖水平管理对于糖尿病患者至关重要，可以避免严重并发症。本研究引入了一种新颖的神经控制系统，用于连续葡萄糖监测和维护，利用微分预测控制。我们的系统受到复杂神经策略和可区分建模的指导，实时动态调整胰岛素输送，增强葡萄糖优化。这种端到端方法最大化效率，确保个性化护理和改善健康结果，如经验发现所证实。

    arXiv:2402.13852v1 Announce Type: cross  Abstract: Precise glucose level management is pivotal for individuals with diabetes, averting severe complications. In this work, we introduce a novel neural control system for continuous glucose monitoring and maintenance, utilizing differential predictive control. Our system, guided by a sophisticated neural policy and differentiable modeling, dynamically adjusts insulin delivery in real-time, enhancing glucose optimization. This end-to-end approach maximizes efficiency, ensuring personalized care and improved health outcomes, as affirmed by empirical findings.
    
[^146]: PAC-FNO：并行结构全组分傅立叶神经算子用于识别低质量图像

    PAC-FNO: Parallel-Structured All-Component Fourier Neural Operators for Recognizing Low-Quality Images

    [https://arxiv.org/abs/2402.12721](https://arxiv.org/abs/2402.12721)

    提出了一个新颖的神经网络模型 PAC-FNO，通过在频域操作可以处理不同分辨率的图像，解决了传统方法在处理这类问题上的计算成本高的挑战。

    

    开发图像识别模型的标准做法是在特定图像分辨率上训练模型，然后部署它。然而，在现实推理中，模型经常遇到与训练集中不同分辨率的图像和/或受到自然变化的影响，例如天气变化、噪声类型和压缩伪影。传统解决方案涉及为不同分辨率或输入变化训练多个模型，但这些方法在实践中计算成本高，因此不可扩展。为此，我们提出了一种新颖的神经网络模型，即并行结构和全组分傅立叶神经算子（PAC-FNO），来解决这个问题。与传统的前馈神经网络不同，PAC-FNO在频域进行操作，使其能够在单个模型内处理不同分辨率的图像。我们还提出了一个两阶段算法，以最小的修改训练PAC-FNO。

    arXiv:2402.12721v1 Announce Type: cross  Abstract: A standard practice in developing image recognition models is to train a model on a specific image resolution and then deploy it. However, in real-world inference, models often encounter images different from the training sets in resolution and/or subject to natural variations such as weather changes, noise types and compression artifacts. While traditional solutions involve training multiple models for different resolutions or input variations, these methods are computationally expensive and thus do not scale in practice. To this end, we propose a novel neural network model, parallel-structured and all-component Fourier neural operator (PAC-FNO), that addresses the problem. Unlike conventional feed-forward neural networks, PAC-FNO operates in the frequency domain, allowing it to handle images of varying resolutions within a single model. We also propose a two-stage algorithm for training PAC-FNO with a minimal modification to the orig
    
[^147]: Mafin: 用模型增强微调来增强黑盒嵌入

    Mafin: Enhancing Black-Box Embeddings with Model Augmented Fine-tuning

    [https://arxiv.org/abs/2402.12177](https://arxiv.org/abs/2402.12177)

    Mafin通过引入模型增强微调的方法，能够在只有黑盒嵌入可用的情况下显著提高性能。

    

    检索增强生成（RAG）已经成为缓解大型语言模型（LLMs）中幻觉的有效解决方案。RAG中的检索阶段通常涉及预训练的嵌入模型，将查询和段落转换为向量以捕获它们的语义。然而，当应用于特定领域知识时，标准的预训练嵌入模型可能表现出次优性能，需要进行微调。本文解决了仅能从黑盒模型获取嵌入的情况。我们引入了模型增强微调（Mafin）--一种通过用可训练的嵌入模型增强黑盒嵌入模型来进行微调的新方法。我们的结果表明，Mafin仅需要训练一个小的增强模型就可以显著提高黑盒嵌入的性能。我们验证了我们的方法在有标签和无标签数据集上的有效性。

    arXiv:2402.12177v1 Announce Type: cross  Abstract: Retrieval Augmented Generation (RAG) has emerged as an effective solution for mitigating hallucinations in Large Language Models (LLMs). The retrieval stage in RAG typically involves a pre-trained embedding model, which converts queries and passages into vectors to capture their semantics. However, a standard pre-trained embedding model may exhibit sub-optimal performance when applied to specific domain knowledge, necessitating fine-tuning. This paper addresses scenarios where the embeddings are only available from a black-box model. We introduce Model augmented fine-tuning (Mafin) -- a novel approach for fine-tuning a black-box embedding model by augmenting it with a trainable embedding model. Our results demonstrate that Mafin significantly enhances the performance of the black-box embeddings by only requiring the training of a small augmented model. We validate the effectiveness of our method on both labeled and unlabeled datasets, 
    
[^148]: ASGEA：利用Align-Subgraphs中的逻辑规则进行实体对齐

    ASGEA: Exploiting Logic Rules from Align-Subgraphs for Entity Alignment

    [https://arxiv.org/abs/2402.11000](https://arxiv.org/abs/2402.11000)

    提出了一个新的实体对齐框架ASGEA，利用Align-Subgraphs中的逻辑规则，设计了可解释的基于路径的图神经网络ASGNN，引入了多模态注意机制，取得了令人满意的实验结果

    

    实体对齐（EA）旨在识别代表相同现实世界对象的不同知识图中的实体。最近基于嵌入的EA方法在EA方面取得了最先进的性能，但面临着解释性挑战，因为它们完全依赖于嵌入距离，并忽视了一对对齐实体背后的逻辑规则。在本文中，我们提出了Align-Subgraph实体对齐（ASGEA）框架来利用Align-Subgraphs中的逻辑规则。ASGEA使用锚链接作为桥梁来构建Align-Subgraphs，并沿着跨知识图的路径传播，这使其区别于基于嵌入的方法。此外，我们设计了一种可解释的基于路径的图神经网络ASGNN，以有效识别和整合跨知识图的逻辑规则。我们还引入了一个节点级多模态注意机制，结合多模态增强的锚点来增强Align-Subgraph。我们的实验结果

    arXiv:2402.11000v1 Announce Type: cross  Abstract: Entity alignment (EA) aims to identify entities across different knowledge graphs that represent the same real-world objects. Recent embedding-based EA methods have achieved state-of-the-art performance in EA yet faced interpretability challenges as they purely rely on the embedding distance and neglect the logic rules behind a pair of aligned entities. In this paper, we propose the Align-Subgraph Entity Alignment (ASGEA) framework to exploit logic rules from Align-Subgraphs. ASGEA uses anchor links as bridges to construct Align-Subgraphs and spreads along the paths across KGs, which distinguishes it from the embedding-based methods. Furthermore, we design an interpretable Path-based Graph Neural Network, ASGNN, to effectively identify and integrate the logic rules across KGs. We also introduce a node-level multi-modal attention mechanism coupled with multi-modal enriched anchors to augment the Align-Subgraph. Our experimental results 
    
[^149]: 通过多重分形分析视角探索LLMs中的神经元相互作用和出现现象

    Exploring Neuron Interactions and Emergence in LLMs: From the Multifractal Analysis Perspective

    [https://arxiv.org/abs/2402.09099](https://arxiv.org/abs/2402.09099)

    该论文通过多重分形分析视角，深入研究了LLMs中神经元相互作用和出现现象。通过引入自组织和多重分形分析的概念，研究了神经元相互作用的动态演化过程，尤其关注训练中的复杂行为。通过提出基于神经元的多重分形分析方法，实现了对大型模型中神经元相互作用的定量分析。

    

    在以往的大型模型中，关于出现现象的研究主要集中在大型语言模型（LLMs）的功能能力如何随模型规模的扩大而增加。然而，我们的研究超越了这一传统范式，旨在通过不仅仅依赖于模型规模，而更加关注训练过程中神经元相互作用的复杂行为，加深我们对LLMs内部出现现象的理解。通过引入“自组织”和“多重分形分析”概念，我们探索了神经元相互作用在训练过程中如何动态演化，从而导致“出现现象”，这种现象反映了自然系统中简单的微观相互作用如何导致复杂的宏观行为。为了定量分析训练过程中大型模型中神经元之间不断演化的相互作用，我们提出了基于神经元的多重分形分析（NeuroMFA）。利用NeuroMFA，我们进行了一系列的实验

    arXiv:2402.09099v1 Announce Type: new Abstract: Prior studies on the emergence in large models have primarily focused on how the functional capabilities of large language models (LLMs) scale with model size. Our research, however, transcends this traditional paradigm, aiming to deepen our understanding of the emergence within LLMs by placing a special emphasis not just on the model size but more significantly on the complex behavior of neuron interactions during the training process. By introducing the concepts of "self-organization" and "multifractal analysis," we explore how neuron interactions dynamically evolve during training, leading to "emergence," mirroring the phenomenon in natural systems where simple micro-level interactions give rise to complex macro-level behaviors. To quantitatively analyze the continuously evolving interactions among neurons in large models during training, we propose the Neuron-based Multifractal Analysis (NeuroMFA). Utilizing NeuroMFA, we conduct a com
    
[^150]: 熵正则化的令牌级策略优化用于大规模语言模型

    Entropy-Regularized Token-Level Policy Optimization for Large Language Models

    [https://arxiv.org/abs/2402.06700](https://arxiv.org/abs/2402.06700)

    本文提出了一种熵正则化的令牌级策略优化方法（ETPO），用于优化大规模语言模型（LLMs）。该方法能够通过直接与任务特定环境进行交互，并解决在如何分配令牌级学分和最大化奖励之间的冲突问题。

    

    大规模语言模型（LLMs）在交互式决策任务中表现出了智能代理的潜力。传统方法通常依赖于精心设计的提示、高质量的示例或额外的奖励模型进行上下文学习、监督微调或RLHF。强化学习（RL）提供了一种动态的解决方案，使LLMs能够通过直接与任务特定环境进行交互来克服这些依赖关系。尽管如此，它面临着重重困难：1）由于巨大的动作空间需要探索而产生的不稳定性；2）基于动作级奖励信号分配令牌级学分的挑战，导致最大化奖励和准确建模语料库数据之间的冲突。为了应对这些挑战，我们引入了熵正则化的令牌级策略优化（ETPO），这是一种专为在令牌级优化LLMs而设计的熵增强强化学习方法。ETPO的核心是我们的一种新颖的逐令牌软Bellman更新算法，

    Large Language Models (LLMs) have shown promise as intelligent agents in interactive decision-making tasks. Traditional approaches often depend on meticulously designed prompts, high-quality examples, or additional reward models for in-context learning, supervised fine-tuning, or RLHF. Reinforcement learning (RL) presents a dynamic alternative for LLMs to overcome these dependencies by engaging directly with task-specific environments. Nonetheless, it faces significant hurdles: 1) instability stemming from the exponentially vast action space requiring exploration; 2) challenges in assigning token-level credit based on action-level reward signals, resulting in discord between maximizing rewards and accurately modeling corpus data. In response to these challenges, we introduce Entropy-Regularized Token-level Policy Optimization (ETPO), an entropy-augmented RL method tailored for optimizing LLMs at the token level. At the heart of ETPO is our novel per-token soft Bellman update, designed 
    
[^151]: VampPrior混合模型

    The VampPrior Mixture Model

    [https://arxiv.org/abs/2402.04412](https://arxiv.org/abs/2402.04412)

    本论文提出了VampPrior混合模型（VMM），它是一种新颖的DLVM先验，可用于深度潜变量模型的集成和聚类，通过改善当前聚类先验的不足，并提出了一个清晰区分变分和先验参数的推理过程。使用VMM的变分自动编码器在基准数据集上取得了强大的聚类性能，将VMM与scVI相结合可以显著提高其性能，并自动将细胞分组为具有生物意义的聚类。

    

    当前用于深度潜变量模型（DLVMs）的聚类先验需要预先定义聚类的数量，并且容易受到较差的初始化的影响。解决这些问题可以通过同时执行集成和聚类的方式极大地改进基于深度学习的scRNA-seq分析。我们将VampPrior（Tomczak和Welling，2018）调整为Dirichlet过程高斯混合模型，得到VampPrior混合模型（VMM），这是一种新颖的DLVM先验。我们提出了一个推理过程，交替使用变分推理和经验贝叶斯，以清楚地区分变分和先验参数。在基准数据集上使用VMM的变分自动编码器获得了极具竞争力的聚类性能。将VMM与广受欢迎的scRNA-seq集成方法scVI（Lopez等，2018）相结合，显著改善了其性能，并自动将细胞分组为具有生物意义的聚类。

    Current clustering priors for deep latent variable models (DLVMs) require defining the number of clusters a-priori and are susceptible to poor initializations. Addressing these deficiencies could greatly benefit deep learning-based scRNA-seq analysis by performing integration and clustering simultaneously. We adapt the VampPrior (Tomczak & Welling, 2018) into a Dirichlet process Gaussian mixture model, resulting in the VampPrior Mixture Model (VMM), a novel prior for DLVMs. We propose an inference procedure that alternates between variational inference and Empirical Bayes to cleanly distinguish variational and prior parameters. Using the VMM in a Variational Autoencoder attains highly competitive clustering performance on benchmark datasets. Augmenting scVI (Lopez et al., 2018), a popular scRNA-seq integration method, with the VMM significantly improves its performance and automatically arranges cells into biologically meaningful clusters.
    
[^152]: LLMLight: 大型语言模型作为交通信号控制代理

    LLMLight: Large Language Models as Traffic Signal Control Agents

    [https://arxiv.org/abs/2312.16044](https://arxiv.org/abs/2312.16044)

    LLMLight是一个采用大型语言模型作为交通信号控制代理的新框架，通过借助先进的泛化能力和类似人类直觉的推理和决策过程，实现了有效的交通控制。此外，通过构建专为TSC任务定制的骨干语言模型LightGPT，进一步提升了LLMLight的效果和性能。

    

    交通信号控制（TSC）是城市交通管理的关键组成部分，旨在优化道路网络效率和减少拥堵。传统的TSC方法主要基于交通工程和强化学习（RL），往往在各种交通场景中存在泛化性不足和缺乏解释性等限制。本文提出了LLMLight，这是一个采用大型语言模型（LLMs）作为TSC决策代理的新框架。具体而言，该框架通过向LLM提供详细的实时交通状况说明作为指导，借助LLM的先进泛化能力，LLMLight实现了类似人类直觉的推理和决策过程，从而实现有效的交通控制。此外，我们构建了LightGPT，这是一个专为TSC任务量身定制的骨干LLM。通过学习细微的交通模式和控制策略，LightGPT在经济成本方面提升了LLMLight框架的效果。进行了大量的实验验证了LLMLight的有效性和性能优势。

    Traffic Signal Control (TSC) is a crucial component in urban traffic management, aiming to optimize road network efficiency and reduce congestion. Traditional methods in TSC, primarily based on transportation engineering and reinforcement learning (RL), often exhibit limitations in generalization across varied traffic scenarios and lack interpretability. This paper presents LLMLight, a novel framework employing Large Language Models (LLMs) as decision-making agents for TSC. Specifically, the framework begins by instructing the LLM with a knowledgeable prompt detailing real-time traffic conditions. Leveraging the advanced generalization capabilities of LLMs, LLMLight engages a reasoning and decision-making process akin to human intuition for effective traffic control. Moreover, we build LightGPT, a specialized backbone LLM tailored for TSC tasks. By learning nuanced traffic patterns and control strategies, LightGPT enhances the LLMLight framework cost-effectively. Extensive experiments 
    
[^153]: 大型语言模型能否进行编辑？评估其遵循代码编辑指令的能力

    Can It Edit? Evaluating the Ability of Large Language Models to Follow Code Editing Instructions

    [https://arxiv.org/abs/2312.12450](https://arxiv.org/abs/2312.12450)

    该研究评估了大型语言模型遵循代码编辑指令的能力，在指令式代码编辑任务上发现了开放和封闭模型之间的显著差距。

    

    大量研究集中在开发和评估大型语言模型用于各种代码合成任务。这些任务包括从自然语言指令中合成代码，从代码中合成测试，以及从代码中合成解释。与此相反，使用LLMs进行指令式代码编辑的行为研究不足。这些任务要求模型按照提供的提示更新一块代码。编辑指令可能要求添加或删除功能，描述错误并要求修复，要求不同类型的解决方案，或者其他常见的代码编辑任务。我们引入了一个精心设计的代码编辑任务基准，并用它评估了几个最先进的LLMs。我们的评估展示了当前最先进的开放和封闭模型之间的显著差距。例如，即使是GPT-3.5-Turbo也比最好的开放模型在编辑代码方面好了8.8%。

    arXiv:2312.12450v4 Announce Type: replace-cross  Abstract: A significant amount of research is focused on developing and evaluating large language models for a variety of code synthesis tasks. These include synthesizing code from natural language instructions, synthesizing tests from code, and synthesizing explanations of code. In contrast, the behavior of instructional code editing with LLMs is understudied. These are tasks in which the model is instructed to update a block of code provided in a prompt. The editing instruction may ask for a feature to added or removed, describe a bug and ask for a fix, ask for a different kind of solution, or many other common code editing tasks.   We introduce a carefully crafted benchmark of code editing tasks and use it evaluate several cutting edge LLMs. Our evaluation exposes a significant gap between the capabilities of state-of-the-art open and closed models. For example, even GPT-3.5-Turbo is 8.8% better than the best open model at editing cod
    
[^154]: RDR：增强语言理解的回顾、审慎和回应方法

    RDR: the Recap, Deliberate, and Respond Method for Enhanced Language Understanding

    [https://arxiv.org/abs/2312.09932](https://arxiv.org/abs/2312.09932)

    RDR方法提出了通过回顾、审慎和回应三个目标来增强语言理解的神经网络管道，解决了神经模型操纵NLU基准测试的问题

    

    自然语言理解（NLU）使用神经网络管道通常需要额外的上下文，而这些上下文并不仅仅存在于输入数据中。通过先前的研究，已经明显地证明了NLU基准测试对神经模型的操纵敏感，这些模型利用编码的外部知识中的统计特征人为地提高了下游任务的性能指标。我们提出的方法称为回顾、审慎和回应（RDR）范式，通过在神经网络管道中引入三个不同的目标来解决这个问题。首先，回顾目标涉及使用一个释义模型对输入文本进行释义，以便对其进行总结和概括。其次，审慎目标涉及利用图嵌入模型对与输入文本中提到的实体相关的外部图信息进行编码。最后，回应目标e

    arXiv:2312.09932v2 Announce Type: replace-cross  Abstract: Natural language understanding (NLU) using neural network pipelines often requires additional context that is not solely present in the input data. Through Prior research, it has been evident that NLU benchmarks are susceptible to manipulation by neural models, wherein these models exploit statistical artifacts within the encoded external knowledge to artificially inflate performance metrics for downstream tasks. Our proposed approach, known as the Recap, Deliberate, and Respond (RDR) paradigm, addresses this issue by incorporating three distinct objectives within the neural network pipeline. Firstly, the Recap objective involves paraphrasing the input text using a paraphrasing model in order to summarize and encapsulate its essence. Secondly, the Deliberation objective entails encoding external graph information related to entities mentioned in the input text, utilizing a graph embedding model. Finally, the Respond objective e
    
[^155]: 通过多样化合成和扩散模型减轻偏见

    Mitigating Biases with Diverse Ensembles and Diffusion Models

    [https://arxiv.org/abs/2311.16176](https://arxiv.org/abs/2311.16176)

    通过利用扩散概率模型（DPMs）生成新特征组合的图像，可以在集成模型中增加模型多样性，并减轻捷径偏见，而无需额外监督信号。

    

    数据中的虚假相关性，即多个线索可以预测目标标签，常常导致一种称为捷径偏见的现象，即模型依赖于错误的、易学的线索，而忽略可靠的线索。在这项工作中，我们提出了一种利用扩散概率模型（DPMs）的集成多样化框架，用于减轻捷径偏见。我们展示了在特定的训练间隔中，DPMs可以生成具有新特征组合的图像，即使在显示相关输入特征的样本上进行训练。我们利用这一关键属性通过集成不一致性生成合成反事实来增加模型的多样性。我们展示了DPM引导的多样化足以消除对主要捷径线索的依赖，无需额外的监督信号。我们进一步在几个多样化目标上在实证上量化其有效性，并最终展示了改进的泛化性能。

    arXiv:2311.16176v2 Announce Type: replace-cross  Abstract: Spurious correlations in the data, where multiple cues are predictive of the target labels, often lead to a phenomenon known as shortcut bias, where a model relies on erroneous, easy-to-learn cues while ignoring reliable ones. In this work, we propose an ensemble diversification framework exploiting Diffusion Probabilistic Models (DPMs) for shortcut bias mitigation. We show that at particular training intervals, DPMs can generate images with novel feature combinations, even when trained on samples displaying correlated input features. We leverage this crucial property to generate synthetic counterfactuals to increase model diversity via ensemble disagreement. We show that DPM-guided diversification is sufficient to remove dependence on primary shortcut cues, without a need for additional supervised signals. We further empirically quantify its efficacy on several diversification objectives, and finally show improved generalizati
    
[^156]: 在多项式时间内识别树状结构因果模型

    Identification for Tree-shaped Structural Causal Models in Polynomial Time

    [https://arxiv.org/abs/2311.14058](https://arxiv.org/abs/2311.14058)

    本文提出了一个随机化多项式时间算法，用于解决树状结构因果模型的识别问题，是对传统Gröbner基础方法的显著改进。

    

    线性结构因果模型（SCM）用于表示和分析随机变量之间的关系。直接因果效应表示为有向边，混淆因素表示为双向边。从节点之间的相关性中识别因果参数是人工智能中的一个未解问题。本文研究了其有向分量形成树状的SCM。Van der Zander等人（AISTATS'22，PLMR 151，第6770--6792页，2022年）给出了这种情况下的识别问题的PSPACE算法，这是对一般Gr\"obner基础方法的重大改进，后者在结构参数数量的指数时间复杂度。在本文中，我们提出了一种随机化多项式时间算法，用于解决树状SCM的识别问题。对于每个结构参数，我们的算法确定其是否是一般可识别的，一般2-identifiabl

    arXiv:2311.14058v2 Announce Type: replace  Abstract: Linear structural causal models (SCMs) are used to express and analyse the relationships between random variables. Direct causal effects are represented as directed edges and confounding factors as bidirected edges. Identifying the causal parameters from correlations between the nodes is an open problem in artificial intelligence. In this paper, we study SCMs whose directed component forms a tree. Van der Zander et al. (AISTATS'22, PLMR 151, pp. 6770--6792, 2022) give a PSPACE-algorithm for the identification problem in this case, which is a significant improvement over the general Gr\"obner basis approach, which has doubly-exponential time complexity in the number of structural parameters. In this work, we present a randomized polynomial-time algorithm, which solves the identification problem for tree-shaped SCMs. For every structural parameter, our algorithms decides whether it is generically identifiable, generically 2-identifiabl
    
[^157]: 可以通过LLMs修复推理模型的问题吗？朝着更可能的AI规划模型

    Can LLMs Fix Issues with Reasoning Models? Towards More Likely Models for AI Planning

    [https://arxiv.org/abs/2311.13720](https://arxiv.org/abs/2311.13720)

    这项研究探索了将大型语言模型（LLMs）用于自动规划任务中的模型空间编辑，并展示了LLMs在模型空间推理中的性能与传统组合搜索方法的对比，为未来更深入研究LLMs在规划任务中的应用提供了有希望的结果。

    

    这是第一项研究将大型语言模型（LLMs）应用于自动规划任务中的模型空间编辑的工作。为此联盟铺平道路，我们探讨了AI规划文献中研究的两种不同味道的模型空间问题，并探讨了LLM对这些任务的影响。我们在实证中演示了LLM的性能如何与组合搜索（CS）形成对比 -- 传统上用于解决规划中模型空间任务的方法，LLM既扮演独立的模型空间推理者的角色，也与CS方法一起作为两阶段过程的一部分的统计信号的角色。我们的实验显示了有希望的结果，暗示LLMs在未来更深入地涉足规划任务中的模型空间推理这一激动人心的领域。

    arXiv:2311.13720v2 Announce Type: replace  Abstract: This is the first work to look at the application of large language models (LLMs) for the purpose of model space edits in automated planning tasks. To set the stage for this union, we explore two different flavors of model space problems that have been studied in the AI planning literature and explore the effect of an LLM on those tasks. We empirically demonstrate how the performance of an LLM contrasts with combinatorial search (CS) -- an approach that has been traditionally used to solve model space tasks in planning, both with the LLM in the role of a standalone model space reasoner as well as in the role of a statistical signal in concert with the CS approach as part of a two-stage process. Our experiments show promising results suggesting further forays of LLMs into the exciting world of model space reasoning for planning tasks in the future.
    
[^158]: 机器学习管道中的信息泄漏问题

    On Leakage in Machine Learning Pipelines

    [https://arxiv.org/abs/2311.04179](https://arxiv.org/abs/2311.04179)

    本论文旨在扩展对设计、实施和评估机器学习管道时导致信息泄漏的原因的理解，通过具体示例提供了各种可能在机器学习管道中出现的泄漏的全面概述和讨论。

    

    机器学习（ML）提供了强大的预测建模工具，其受欢迎程度源自于在物理学、市场营销、医疗保健等各个领域中应用样本级别的预测的承诺。然而，如果未经适当实施和评估，ML管道可能包含泄漏，通常导致过度乐观的性能估计并且无法推广到新数据。这可能对财务和社会产生严重负面影响。我们的目标是在设计、实施和评估ML管道时扩展与导致泄漏相关的原因的理解。通过具体示例说明，我们提供了在ML管道中可能出现的各种类型泄漏的综合概述和讨论。

    arXiv:2311.04179v2 Announce Type: replace-cross  Abstract: Machine learning (ML) provides powerful tools for predictive modeling. ML's popularity stems from the promise of sample-level prediction with applications across a variety of fields from physics and marketing to healthcare. However, if not properly implemented and evaluated, ML pipelines may contain leakage typically resulting in overoptimistic performance estimates and failure to generalize to new data. This can have severe negative financial and societal implications. Our aim is to expand understanding associated with causes leading to leakage when designing, implementing, and evaluating ML pipelines. Illustrated by concrete examples, we provide a comprehensive overview and discussion of various types of leakage that may arise in ML pipelines.
    
[^159]: 序列级确定性降低基于知识的对话生成中的虚构情况

    Sequence-Level Certainty Reduces Hallucination In Knowledge-Grounded Dialogue Generation

    [https://arxiv.org/abs/2310.18794](https://arxiv.org/abs/2310.18794)

    序列级确定性是减少基于知识的对话生成中幻觉的关键，这项工作提出了基于概率确定性和语义确定性的序列级确定性，结果表明更高水平的确定性对应更低水平的幻觉，进一步提出了基于确定性的响应排序方法

    

    在这项工作中，我们提出了序列级确定性作为基于知识的对话生成中虚构情况的共同主题。我们探讨了幻觉水平与两种序列级确定性之间的相关性：概率确定性和语义确定性。实证结果表明，模型响应中两种序列级确定性水平的提高与虚构水平的降低相关。我们进一步提出了基于确定性的响应排序（CRR），这是一种解码时的幻觉缓解方法，根据它们的序列级确定性对响应候选进行排序，并输出具有最高确定性水平的答案。与我们关于序列级确定性的定义相一致，我们设计了两种CRR方法：概率CRR（P-CRR）和语义CRR（S-CRR）。P-CRR使用整个序列的算术平均对各个单独抽样的模型响应进行排名

    arXiv:2310.18794v2 Announce Type: replace-cross  Abstract: In this work, we propose sequence-level certainty as a common theme over hallucination in Knowledge Grounded Dialogue Generation (KGDG). We explore the correlation between the level of hallucination and two types of sequence-level certainty: probabilistic certainty and semantic certainty. Empirical results reveal that a higher level of both types of sequence-level certainty in model responses is correlated with a lower level of hallucination. We further propose Certainty-based Response Ranking (CRR), a decoding-time hallucination mitigation method that ranks response candidates based on their sequence-level certainty and outputs the answer with the highest certainty level. Aligning with our definitions of sequence-level certainty, we design 2 types of CRR approaches: Probabilistic CRR (P-CRR) and Semantic CRR (S-CRR). P-CRR ranks individually sampled model responses using the arithmetic mean log-probability of the entire sequen
    
[^160]: 评估大型语言模型的空间理解能力

    Evaluating Spatial Understanding of Large Language Models

    [https://arxiv.org/abs/2310.14540](https://arxiv.org/abs/2310.14540)

    本研究评估了大型语言模型对空间结构的理解能力，发现LLMs在表示和推理空间结构时的表现存在显著差异，具有捕捉空间结构隐含特征的潜力。

    

    大型语言模型 (LLMs) 在各种任务中展现出卓越的能力。尽管这些模型在训练中只看到文本，但一些最近的研究表明，LLM表示隐含地捕捉了地面概念的几个方面。在这里，我们探讨了LLM表示对一种特别显著的基础知识 -- 空间关系的表现。我们设计了自然语言导航任务，评估了LLMs，特别是GPT-3.5-turbo、GPT-4 和 Llama2 系列模型，表示和推理空间结构的能力。这些任务揭示了LLM在不同空间结构 (包括正方形、六边形和三角形格、环和树) 上的性能差异。在广泛的错误分析中，我们发现LLMs的错误反映了空间和非空间因素。这些发现表明，LLMs似乎隐含地捕捉了空间结构的某些方面，但仍有提升的空间。

    arXiv:2310.14540v2 Announce Type: replace-cross  Abstract: Large language models (LLMs) show remarkable capabilities across a variety of tasks. Despite the models only seeing text in training, several recent studies suggest that LLM representations implicitly capture aspects of the underlying grounded concepts. Here, we explore LLM representations of a particularly salient kind of grounded knowledge -- spatial relationships. We design natural-language navigation tasks and evaluate the ability of LLMs, in particular GPT-3.5-turbo, GPT-4, and Llama2 series models, to represent and reason about spatial structures. These tasks reveal substantial variability in LLM performance across different spatial structures, including square, hexagonal, and triangular grids, rings, and trees. In extensive error analysis, we find that LLMs' mistakes reflect both spatial and non-spatial factors. These findings suggest that LLMs appear to capture certain aspects of spatial structure implicitly, but room f
    
[^161]: 一种用于无线通信网络中能源高效联邦学习的安全深度强化学习方法

    A Safe Deep Reinforcement Learning Approach for Energy Efficient Federated Learning in Wireless Communication Networks

    [https://arxiv.org/abs/2308.10664](https://arxiv.org/abs/2308.10664)

    提出一种新的安全深度强化学习方法，利用惩罚函数在训练时惩罚违反环境约束的策略，以确保无线通信网络中能源高效联邦学习的总能耗最小化。

    

    向着人工智能（AI）赋能的无线网络新时代迈进，行业和学术界对AI的环境影响提出了关注。联邦学习（FL）作为一种关键的隐私保护的分散式AI技术已经出现。尽管目前在FL方面已经做出努力，但其环境影响仍然是一个尚未解决的问题。为了最小化FL过程的总能耗，我们提出了编排参与设备的计算和通信资源，以最小化所需的总能量，同时保证模型的一定性能。为此，我们提出了一种Soft Actor Critic Deep Reinforcement Learning (DRL)解决方案，在训练过程中引入了一种惩罚函数，惩罚违反环境约束的策略，有助于实现安全的RL过程。

    arXiv:2308.10664v3 Announce Type: replace-cross  Abstract: Progressing towards a new era of Artificial Intelligence (AI) - enabled wireless networks, concerns regarding the environmental impact of AI have been raised both in industry and academia. Federated Learning (FL) has emerged as a key privacy preserving decentralized AI technique. Despite efforts currently being made in FL, its environmental impact is still an open problem. Targeting the minimization of the overall energy consumption of an FL process, we propose the orchestration of computational and communication resources of the involved devices to minimize the total energy required, while guaranteeing a certain performance of the model. To this end, we propose a Soft Actor Critic Deep Reinforcement Learning (DRL) solution, where a penalty function is introduced during training, penalizing the strategies that violate the constraints of the environment, and contributing towards a safe RL process. A device level synchronization 
    
[^162]: 机器遗忘：解决方案与挑战

    Machine Unlearning: Solutions and Challenges

    [https://arxiv.org/abs/2308.07061](https://arxiv.org/abs/2308.07061)

    本文提供了对机器遗忘解决方案的全面分类和分析，明确了完全遗忘方法和近似遗忘方法，并讨论了它们的优势和局限性，提出了推进机器遗忘的未来方向。

    

    机器学习模型可能无意中记住敏感、未经授权或恶意数据，存在隐私泄露、安全漏洞和性能降级的风险。为了解决这些问题，机器遗忘已经成为一种重要的技术，可以有选择地消除特定训练数据点对训练模型的影响。本文对机器遗忘中的解决方案进行了全面分类和分析。我们将现有解决方案分为完全遗忘方法和有效减少数据影响的近似遗忘方法。通过全面回顾解决方案，我们确定并讨论它们的优势和局限性。此外，我们提出了未来的发展方向，以推进机器遗忘并将其建立为值得信赖和适应性机器学习模型的重要能力。本文为研究人员提供了一份路线图。

    arXiv:2308.07061v2 Announce Type: replace-cross  Abstract: Machine learning models may inadvertently memorize sensitive, unauthorized, or malicious data, posing risks of privacy breaches, security vulnerabilities, and performance degradation. To address these issues, machine unlearning has emerged as a critical technique to selectively remove specific training data points' influence on trained models. This paper provides a comprehensive taxonomy and analysis of the solutions in machine unlearning. We categorize existing solutions into exact unlearning approaches that remove data influence thoroughly and approximate unlearning approaches that efficiently minimize data influence. By comprehensively reviewing solutions, we identify and discuss their strengths and limitations. Furthermore, we propose future directions to advance machine unlearning and establish it as an essential capability for trustworthy and adaptive machine learning models. This paper provides researchers with a roadmap
    
[^163]: 使用Masked Transformers快速训练扩散模型

    Fast Training of Diffusion Models with Masked Transformers

    [https://arxiv.org/abs/2306.09305](https://arxiv.org/abs/2306.09305)

    该论文提出了一种使用Masked Transformers快速训练扩散模型的方法，首次利用Masked training显著降低了模型的训练成本，并引入了不对称的编码器-解码器架构和辅助任务，以提升对全patches的长程理解。

    

    我们提出了一种有效的方法，使用Masked Transformers来训练大型扩散模型。尽管Masked Transformers已经被广泛探索用于表示学习，在视觉领域中，它们在生成学习方面的应用却较少被探讨。我们的工作是第一个利用Masked training显著降低扩散模型的训练成本。具体地，在训练过程中，我们随机屏蔽扩散输入图像中高比例（例如50%）的patches。为了进行Masked training，我们引入了一个不对称的编码器-解码器架构，其中包括仅在未屏蔽patches上运行的transformer编码器和在全部patches上运行的轻量级transformer解码器。为了提升对全patches的长程理解，我们加入了一个辅助任务，即重构屏蔽patches，这是为了denoising score matching目标学习未屏蔽patches的score。我们在ImageNet-256x256和ImageNet-512x...上进行了实验。

    arXiv:2306.09305v2 Announce Type: replace-cross  Abstract: We propose an efficient approach to train large diffusion models with masked transformers. While masked transformers have been extensively explored for representation learning, their application to generative learning is less explored in the vision domain. Our work is the first to exploit masked training to reduce the training cost of diffusion models significantly. Specifically, we randomly mask out a high proportion (e.g., 50%) of patches in diffused input images during training. For masked training, we introduce an asymmetric encoder-decoder architecture consisting of a transformer encoder that operates only on unmasked patches and a lightweight transformer decoder on full patches. To promote a long-range understanding of full patches, we add an auxiliary task of reconstructing masked patches to the denoising score matching objective that learns the score of unmasked patches. Experiments on ImageNet-256x256 and ImageNet-512x
    
[^164]: 基于代理的人体肌肉建模与仿真用于人体步态分析应用

    Agent-based Modeling and Simulation of Human Muscle For Development of Human Gait Analyzer Application

    [https://arxiv.org/abs/2212.12760](https://arxiv.org/abs/2212.12760)

    提出了一种基于代理的人体肌肉模型，用于计算步态周期中下半身的神经刺激，检测肌肉群的工作情况，并设计了Boots算法进行人体运动的逆动力学，最终开发出用户友好的应用程序。

    

    尽管仅有少部分肌肉受到运动疾病和紊乱的影响，但医疗疗法并未区分健康与不健康肌肉。本文提出了一种方法来计算步态周期中下半身的神经刺激，并检查是否有任何肌肉群没有正常工作。为此，提出了人体肌肉的基于代理的模型。该代理能够将神经刺激转化为肌肉产生的力，反之亦然。它可以在包括医学教育和研究以及假肢开发在内的许多研究中使用。然后，基于人体下半身的生物力学模型设计了Boots算法，通过计算每个肌肉群生成的力来进行人体运动的逆动力学。利用基于代理的人体肌肉模型和Boots算法，开发了一个用户友好的应用程序，可以计算神经刺激的数量。

    arXiv:2212.12760v2 Announce Type: replace  Abstract: Despite the fact that only a small portion of muscles are affected in motion disease and disorders, medical therapies do not distinguish between healthy and unhealthy muscles. In this paper, a method is devised in order to calculate the neural stimuli of the lower body during gait cycle and check if any group of muscles are not acting properly. For this reason, an agent-based model of human muscle is proposed. The agent is able to convert neural stimuli to force generated by the muscle and vice versa. It can be used in many researches including medical education and research and prosthesis development. Then, Boots algorithm is designed based on a biomechanical model of human lower body to do a reverse dynamics of human motion by computing the forces generated by each muscle group. Using the agent-driven model of human muscle and boots algorithm, a user-friendly application is developed which can calculate the number of neural stimuli
    
[^165]: 从动态图中学习有向无环图结构

    Directed Acyclic Graph Structure Learning from Dynamic Graphs

    [https://arxiv.org/abs/2211.17029](https://arxiv.org/abs/2211.17029)

    在动态图中，我们研究了节点特征生成机制的学习问题，通过同时估计节点特征之间的同时关系和时滞交互关系来构建有向无环图，有效地描述了特征生成过程

    

    估计特征（变量）的有向无环图（DAG）结构在揭示潜在数据生成过程和提供各种应用中的因果洞见方面发挥着至关重要的作用。虽然已经有许多关于不同数据类型结构学习的研究，但动态图上的结构学习尚未被探索，因此我们研究了这种无处不在的动态图数据上的节点特征生成机制的学习问题。在动态图中，我们提出同时估计节点特征之间的同时关系和时滞交互关系。这两种关系形成一个DAG，能够有效地简洁描述特征生成过程。为了学习这样的DAG，我们将学习问题建模为一个连续的基于分数的优化问题，其中包括一个可微分的得分函数来衡量有效性

    arXiv:2211.17029v2 Announce Type: replace-cross  Abstract: Estimating the structure of directed acyclic graphs (DAGs) of features (variables) plays a vital role in revealing the latent data generation process and providing causal insights in various applications. Although there have been many studies on structure learning with various types of data, the structure learning on the dynamic graph has not been explored yet, and thus we study the learning problem of node feature generation mechanism on such ubiquitous dynamic graph data. In a dynamic graph, we propose to simultaneously estimate contemporaneous relationships and time-lagged interaction relationships between the node features. These two kinds of relationships form a DAG, which could effectively characterize the feature generation process in a concise way. To learn such a DAG, we cast the learning problem as a continuous score-based optimization problem, which consists of a differentiable score function to measure the validity 
    
[^166]: 相信您的 $\nabla$: 基于梯度的干预目标定位用于因果发现

    Trust Your $\nabla$: Gradient-based Intervention Targeting for Causal Discovery

    [https://arxiv.org/abs/2211.13715](https://arxiv.org/abs/2211.13715)

    提出了一种基于梯度的干预目标定位方法，GIT，在因果发现中能够通过信号梯度估计器降低干预次数，在低数据量情况下优于竞争基线。

    

    从数据中推断因果结构是科学中一项具有基础重要性的挑战性任务。观测数据通常不足以唯一确定系统的因果结构。虽然进行干预（即实验）可以改善可识别性，但这些样本通常难以获得且成本高昂。因此，因果发现的实验设计方法旨在通过估计最具信息性的干预目标来最小化干预次数。在这项工作中，我们提出了一种新颖的基于梯度的干预目标定位方法，简称为GIT，它‘相信’了基于梯度的因果发现框架的梯度估计器，以提供干预采集函数的信号。我们在模拟和真实世界数据集上进行了大量实验，并证明GIT在低数据量情况下表现与竞争基线相当，甚至在某些情况下超越它们。

    arXiv:2211.13715v4 Announce Type: replace-cross  Abstract: Inferring causal structure from data is a challenging task of fundamental importance in science. Observational data are often insufficient to identify a system's causal structure uniquely. While conducting interventions (i.e., experiments) can improve the identifiability, such samples are usually challenging and expensive to obtain. Hence, experimental design approaches for causal discovery aim to minimize the number of interventions by estimating the most informative intervention target. In this work, we propose a novel Gradient-based Intervention Targeting method, abbreviated GIT, that 'trusts' the gradient estimator of a gradient-based causal discovery framework to provide signals for the intervention acquisition function. We provide extensive experiments in simulated and real-world datasets and demonstrate that GIT performs on par with competitive baselines, surpassing them in the low-data regime.
    
[^167]: 在分布外图上推广图神经网络

    Generalizing Graph Neural Networks on Out-Of-Distribution Graphs

    [https://arxiv.org/abs/2111.10657](https://arxiv.org/abs/2111.10657)

    提出了一个名为StableGNN的通用因果表示框架，通过提取高级图表示并利用因果推断的区分能力，帮助模型在分布外图上实现稳定的泛化能力。

    

    图神经网络（GNNs）在没有考虑训练和测试图之间的分布差异的情况下提出，导致GNNs在分布外（OOD）设置上的泛化能力下降。这种退化的根本原因是大多数GNNs是基于独立同分布假设开发的。在这种设置中，GNNs倾向于利用训练集中存在的细微统计相关性进行预测，即使这是一种伪相关性。然而，这种伪相关性在测试环境中可能会改变，导致GNNs失败。因此，消除伪相关性的影响对于稳定的GNNs至关重要。为此，我们提出了一个名为StableGNN的通用因果表示框架。主要思想是首先从图数据中提取高级表示，然后借助因果推断的区分能力来帮助模型获得稳定的预测效果。

    arXiv:2111.10657v3 Announce Type: replace-cross  Abstract: Graph Neural Networks (GNNs) are proposed without considering the agnostic distribution shifts between training and testing graphs, inducing the degeneration of the generalization ability of GNNs on Out-Of-Distribution (OOD) settings. The fundamental reason for such degeneration is that most GNNs are developed based on the I.I.D hypothesis. In such a setting, GNNs tend to exploit subtle statistical correlations existing in the training set for predictions, even though it is a spurious correlation. However, such spurious correlations may change in testing environments, leading to the failure of GNNs. Therefore, eliminating the impact of spurious correlations is crucial for stable GNNs. To this end, we propose a general causal representation framework, called StableGNN. The main idea is to extract high-level representations from graph data first and resort to the distinguishing ability of causal inference to help the model get ri
    
[^168]: 反事实效应概括：一种组合定义

    Counterfactual Effect Generalization: A Combinatorial Definition

    [https://arxiv.org/abs/2108.04376](https://arxiv.org/abs/2108.04376)

    提出了一种用于干预效应外部有效性的组合定义，揭示了效应概括的两个限制，并重新审视了原始反事实公式中的多个问题。

    

    “反事实”定义的因果效应广泛用于偏差和准确性的推导，但并非泛化性。我们提出了一种用于干预效应外部有效性（EV）的组合定义。我们首先定义了一种效应观察“背景”的概念。然后，我们根据其（可观察和不可观察的）背景集合制定了效应概括的条件。这揭示了效应概括的两个限制：（1）当效应在所有可以枚举的背景下被观察时，或者（2）当背景变得足够随机时。我们利用由此产生的组合框架重新审视了原始反事实公式中的几个问题：样本外有效性、同时估计多个效应、偏差-方差权衡、统计功效以及与当前预测和解释技术的联系。

    arXiv:2108.04376v4 Announce Type: replace-cross  Abstract: The widely used 'Counterfactual' definition of Causal Effects was derived for unbiasedness and accuracy - and not generalizability. We propose a Combinatorial definition for the External Validity (EV) of intervention effects. We first define the concept of an effect observation 'background'. We then formulate conditions for effect generalization based on their sets of (observable and unobservable) backgrounds. This reveals two limits for effect generalization: (1) when effects are observed under all their enumerable backgrounds, or, (2) when backgrounds have become sufficiently randomized. We use the resulting combinatorial framework to re-examine several issues in the original counterfactual formulation: out-of-sample validity, concurrent estimation of multiple effects, bias-variance tradeoffs, statistical power, and connections to current predictive and explaining techniques.   Methodologically, the definitions also allow us 
    
[^169]: 通过与解释进行交互，使深度神经网络出于正确的科学原因

    Making deep neural networks right for the right scientific reasons by interacting with their explanations

    [https://arxiv.org/abs/2001.05371](https://arxiv.org/abs/2001.05371)

    通过“解释交互学习”(XIL)学习设置，研究者可以与深度神经网络进行交互，有助于避免其利用混淆因素而导致的高性能，同时增强对模型的信任。

    

    深度神经网络在许多现实应用中表现出色。不幸的是，它们可能会表现出“聪明的汉斯”式的行为，利用数据集中的混淆因素以实现高性能。本研究引入了“解释交互学习”(XIL)的新型学习设置，并在植物表型研究任务中展示了其好处。XIL将科学家引入训练循环，使她通过对模型解释的反馈进行交互式修订。我们的实验结果表明，XIL可以帮助避免机器学习中的“聪明汉斯”时刻，并鼓励（或鼓励，如果合适的话）对基础模型的信任。

    arXiv:2001.05371v4 Announce Type: replace-cross  Abstract: Deep neural networks have shown excellent performances in many real-world applications. Unfortunately, they may show "Clever Hans"-like behavior -- making use of confounding factors within datasets -- to achieve high performance. In this work, we introduce the novel learning setting of "explanatory interactive learning" (XIL) and illustrate its benefits on a plant phenotyping research task. XIL adds the scientist into the training loop such that she interactively revises the original model via providing feedback on its explanations. Our experimental results demonstrate that XIL can help avoiding Clever Hans moments in machine learning and encourages (or discourages, if appropriate) trust into the underlying model.
    
[^170]: 增强连续强化学习中的回放在世界模型中

    Augmenting Replay in World Models for Continual Reinforcement Learning. (arXiv:2401.16650v1 [cs.LG])

    [http://arxiv.org/abs/2401.16650](http://arxiv.org/abs/2401.16650)

    本研究通过在回放缓冲区中应用增强方法，成功地解决了增强连续强化学习中的内存限制问题，并在世界模型中有效防止灾难性遗忘。

    

    在连续强化学习中，强化学习代理的环境会发生变化。成功的系统应该适当平衡保持已学习任务上的代理性能、稳定性和学习新任务的可塑性之间的矛盾要求。首进先出缓冲区通常用于增强此类设置中的学习，但需要大量内存。我们探索了将增强方法应用于此缓冲区中，以缓解内存限制，并与基于世界模型的强化学习算法一起使用，评估其在促进连续学习方面的效果。我们在Procgen和Atari强化学习基准测试中评估了我们方法的有效性，并证明了在潜在世界模型的背景下，回放缓冲区中的分布匹配增强可以成功防止灾难性遗忘，并显著降低计算开销。然而，我们也发现这种解决方案并非完全无懈可击，

    In continual RL, the environment of a reinforcement learning (RL) agent undergoes change. A successful system should appropriately balance the conflicting requirements of retaining agent performance on already learned tasks, stability, whilst learning new tasks, plasticity. The first-in-first-out buffer is commonly used to enhance learning in such settings but requires significant memory. We explore the application of an augmentation to this buffer which alleviates the memory constraints, and use it with a world model model-based reinforcement learning algorithm, to evaluate its effectiveness in facilitating continual learning. We evaluate the effectiveness of our method in Procgen and Atari RL benchmarks and show that the distribution matching augmentation to the replay-buffer used in the context of latent world models can successfully prevent catastrophic forgetting with significantly reduced computational overhead. Yet, we also find such a solution to not be entirely infallible, and
    
[^171]: 温和的规范执行：更快的出现，更快乐的智能体

    Norm Enforcement with a Soft Touch: Faster Emergence, Happier Agents. (arXiv:2401.16461v1 [cs.MA])

    [http://arxiv.org/abs/2401.16461](http://arxiv.org/abs/2401.16461)

    通过温和的规范执行，该研究提出了一种新的方法，通过智能体之间的交流推动合作并促进规范的出现。

    

    多智能体系统可视为一个自主智能体的社会，通过社会规范可以有效地调控智能体的交互。一般来说，一个社会的规范并不是硬编码的，而是从智能体的交互中产生的。具体来说，一个社会中的智能体对另一个智能体的行为作出的反应以及对他人反应的回应，决定了社会中出现哪些规范。我们将一个智能体对另一个智能体的满意或不满意行为的反应视为第一个智能体向第二个智能体的交流。理解这些交流是一种社会智能：这些交流通过推动智能体朝着某些行为进行，从而促进规范的出现。虽然众所周知惩罚可以导致规范的出现，但我们认为更宽泛的社会智能可能在促进多智能体系统中的合作方面更有效。因此，我们开发了一种被称为Ne的方法

    A multiagent system can be viewed as a society of autonomous agents, whose interactions can be effectively regulated via social norms. In general, the norms of a society are not hardcoded but emerge from the agents' interactions. Specifically, how the agents in a society react to each other's behavior and respond to the reactions of others determines which norms emerge in the society. We think of these reactions by an agent to the satisfactory or unsatisfactory behaviors of another agent as communications from the first agent to the second agent. Understanding these communications is a kind of social intelligence: these communications provide natural drivers for norm emergence by pushing agents toward certain behaviors, which can become established as norms. Whereas it is well-known that sanctioning can lead to the emergence of norms, we posit that a broader kind of social intelligence can prove more effective in promoting cooperation in a multiagent system.  Accordingly, we develop Ne
    
[^172]: DevEval: 评估实际软件项目中的代码生成

    DevEval: Evaluating Code Generation in Practical Software Projects. (arXiv:2401.06401v1 [cs.SE])

    [http://arxiv.org/abs/2401.06401](http://arxiv.org/abs/2401.06401)

    本文提出了一个名为DevEval的新基准测试，用于评估实际软件项目中的代码生成。与之前的基准测试相比，DevEval在真实的项目分布、充足的依赖和足够规模的项目背景等方面更贴合实际。通过对五个流行的大型语言模型进行评估，我们揭示了它们在代码生成中的实际能力。

    

    如何评估大型语言模型（LLMs）在代码生成中的表现是一个开放的问题。许多基准测试已经提出，但是与实际软件项目不一致，例如虚构的程序分布，依赖不足和小规模项目背景。因此，LLMs在实际项目中的能力还不清楚。在本文中，我们提出了一个名为DevEval的新基准测试，与开发人员在实际项目中的经验相吻合。DevEval通过一个严格的流程收集到了来自119个实际项目的2690个样本，涵盖10个领域。与之前的基准测试相比，DevEval在多个维度上与实际项目相吻合，例如真实的程序分布，充足的依赖和足够规模的项目背景。我们在DevEval上评估了五个流行的LLMs（例如gpt-4，gpt-3.5-turbo，CodeLLaMa和StarCoder），并揭示了它们在代码生成中的实际能力。例如，gpt-3.5-turbo的最高Pass@1只有42。

    How to evaluate Large Language Models (LLMs) in code generation is an open question. Many benchmarks have been proposed but are inconsistent with practical software projects, e.g., unreal program distributions, insufficient dependencies, and small-scale project contexts. Thus, the capabilities of LLMs in practical projects are still unclear. In this paper, we propose a new benchmark named DevEval, aligned with Developers' experiences in practical projects. DevEval is collected through a rigorous pipeline, containing 2,690 samples from 119 practical projects and covering 10 domains. Compared to previous benchmarks, DevEval aligns to practical projects in multiple dimensions, e.g., real program distributions, sufficient dependencies, and enough-scale project contexts. We assess five popular LLMs on DevEval (e.g., gpt-4, gpt-3.5-turbo, CodeLLaMa, and StarCoder) and reveal their actual abilities in code generation. For instance, the highest Pass@1 of gpt-3.5-turbo only is 42 in our experim
    
[^173]: DiffDA:一种用于气象尺度数据同化的扩散模型

    DiffDA: a diffusion model for weather-scale data assimilation. (arXiv:2401.05932v1 [cs.CE])

    [http://arxiv.org/abs/2401.05932](http://arxiv.org/abs/2401.05932)

    DiffDA是一种用于气象尺度数据同化的扩散模型，通过机器学习的方法将预测状态和稀疏观测同化，生成与观测一致的初始条件，并能对预测进行后处理到未来。

    

    通过准确的数据同化生成初始条件对于可靠的天气预报和气候模拟至关重要。我们提出了DiffDA作为一种基于机器学习的数据同化方法，能够使用预测状态和稀疏观测来同化大气变量。我们将预训练的GraphCast天气预报模型作为去噪扩散模型。我们的方法应用了两阶段条件：在训练和推理过程中对预测状态进行条件化，在推理过程中只对稀疏观测进行条件化。作为副产品，这种策略还能将预测后处理到未来，在这种情况下没有可用的观测数据。通过基于再分析数据集的实验证明，我们的方法可以以0.25度分辨率生成与观测一致的同化全球大气数据。实验证明，通过我们的方法生成的初始条件可以用于具有较小损失的预报模型。

    The generation of initial conditions via accurate data assimilation is crucial for reliable weather forecasting and climate modeling. We propose the DiffDA as a machine learning based data assimilation method capable of assimilating atmospheric variables using predicted states and sparse observations. We adapt the pretrained GraphCast weather forecast model as a denoising diffusion model. Our method applies two-phase conditioning: on the predicted state during both training and inference, and on sparse observations during inference only. As a byproduct, this strategy also enables the post-processing of predictions into the future, for which no observations are available.Through experiments based on a reanalysis dataset, we have verified that our method can produce assimilated global atmospheric data consistent with observations at 0.25degree resolution. The experiments also show that the initial conditions that are generated via our approach can be used for forecast models with a loss 
    
[^174]: 使用单一非自回归Transformer生成遮蔽音频

    Masked Audio Generation using a Single Non-Autoregressive Transformer. (arXiv:2401.04577v1 [cs.SD])

    [http://arxiv.org/abs/2401.04577](http://arxiv.org/abs/2401.04577)

    MAGNeT是一种遮蔽生成序列建模方法，使用单一非自回归Transformer生成具有高质量的音频，并引入了一种新颖的重新评分方法来提高生成音频的质量。同时，MAGNeT还探索了混合版本，可在自回归模式和非自回归模式下生成序列。在实验中证明MAGNeT在文本到音乐和文本到音频生成任务中具有高效性。

    

    我们介绍了一种名为MAGNeT的遮蔽生成序列建模方法，它直接操作多个音频令牌流。与以往的方法不同，MAGNeT由单阶段非自回归Transformer组成。在训练过程中，我们根据遮蔽计划器预测遮蔽令牌的范围，而在推断过程中，我们逐步构建输出序列使用多个解码步骤。为了进一步提高生成音频的质量，我们引入了一种新颖的重新评分方法，其中我们利用外部预训练模型来重新评分和排名MAGNeT的预测结果，这些结果将被用于后续的解码步骤。最后，我们探索了MAGNeT的混合版本，其中我们在自回归模式下生成前几秒钟，而其余的序列则以并行方式进行解码。我们展示了MAGNeT在文本到音乐和文本到音频生成任务中的效率，并进行了广泛的实验验证。

    We introduce MAGNeT, a masked generative sequence modeling method that operates directly over several streams of audio tokens. Unlike prior work, MAGNeT is comprised of a single-stage, non-autoregressive transformer. During training, we predict spans of masked tokens obtained from a masking scheduler, while during inference we gradually construct the output sequence using several decoding steps. To further enhance the quality of the generated audio, we introduce a novel rescoring method in which, we leverage an external pre-trained model to rescore and rank predictions from MAGNeT, which will be then used for later decoding steps. Lastly, we explore a hybrid version of MAGNeT, in which we fuse between autoregressive and non-autoregressive models to generate the first few seconds in an autoregressive manner while the rest of the sequence is being decoded in parallel. We demonstrate the efficiency of MAGNeT for the task of text-to-music and text-to-audio generation and conduct an extensi
    
[^175]: 图上的通用神经扩散框架

    A Generalized Neural Diffusion Framework on Graphs. (arXiv:2312.08616v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2312.08616](http://arxiv.org/abs/2312.08616)

    本文提出了一个通用的扩散方程框架，通过带有保真度项的方程，正式建立了GNN与扩散过程之间的关系。通过实验证明，该框架能够描述高阶邻居的标签相似性。

    

    最近的研究揭示了GNN和扩散过程之间的联系，这激发了许多基于扩散的GNN的提出。然而，由于这两种机制密切相关，一个基本的问题自然地产生：是否存在一个可以正式统一这些GNN的通用扩散框架？这个问题的答案不仅可以加深我们对GNN学习过程的理解，而且还可能打开一个设计广泛新的GNN类别的新大门。在本文中，我们提出了一个带有保真度项的通用扩散方程框架，它正式建立了扩散过程与更多GNN之间的关系。同时，通过这个框架，我们确定了图扩散网络的一个特征，即当前神经扩散过程只对应于一阶扩散方程。然而，通过实验证明，高阶邻居的标签实际上表现出单一性特征，这引发了相似性。

    Recent studies reveal the connection between GNNs and the diffusion process, which motivates many diffusion-based GNNs to be proposed. However, since these two mechanisms are closely related, one fundamental question naturally arises: Is there a general diffusion framework that can formally unify these GNNs? The answer to this question can not only deepen our understanding of the learning process of GNNs, but also may open a new door to design a broad new class of GNNs. In this paper, we propose a general diffusion equation framework with the fidelity term, which formally establishes the relationship between the diffusion process with more GNNs. Meanwhile, with this framework, we identify one characteristic of graph diffusion networks, i.e., the current neural diffusion process only corresponds to the first-order diffusion equation. However, by an experimental investigation, we show that the labels of high-order neighbors actually exhibit monophily property, which induces the similarit
    
[^176]: 识别干预外推的表示方法

    Identifying Representations for Intervention Extrapolation. (arXiv:2310.04295v1 [cs.LG])

    [http://arxiv.org/abs/2310.04295](http://arxiv.org/abs/2310.04295)

    本文研究了干预外推的任务，证明了可识别的表示方法能够有效地解决这个任务，即使干预对结果产生非线性影响。

    

    可识别和因果关系表示学习的前提是改进当前的表示学习范式，以提高泛化性或鲁棒性。尽管在可识别性问题上取得了近期的进展，但仍需要更多理论结果来证明这些方法对下游任务的具体优势。在本文中，我们考虑干预外推的任务：预测干预如何影响结果，即使这些干预在训练时没有观察到，我们证明了可识别的表示能够为这个任务提供有效的解决方案，即使干预对结果产生非线性影响。我们的设置包括一个结果Y，观察到的特征X，这些特征是潜在特征Z的非线性转换，以及影响Z的外生行为变量A。干预外推的目标是预测位于训练支持之外的A上的干预如何影响Y。在这里，外推变得重要。

    The premise of identifiable and causal representation learning is to improve the current representation learning paradigm in terms of generalizability or robustness. Despite recent progress in questions of identifiability, more theoretical results demonstrating concrete advantages of these methods for downstream tasks are needed. In this paper, we consider the task of intervention extrapolation: predicting how interventions affect an outcome, even when those interventions are not observed at training time, and show that identifiable representations can provide an effective solution to this task even if the interventions affect the outcome non-linearly. Our setup includes an outcome Y, observed features X, which are generated as a non-linear transformation of latent features Z, and exogenous action variables A, which influence Z. The objective of intervention extrapolation is to predict how interventions on A that lie outside the training support of A affect Y. Here, extrapolation becom
    
[^177]: AXNav: 从自然语言中重放无障碍测试

    AXNav: Replaying Accessibility Tests from Natural Language. (arXiv:2310.02424v1 [cs.HC])

    [http://arxiv.org/abs/2310.02424](http://arxiv.org/abs/2310.02424)

    这篇论文研究了一种从自然语言中重放无障碍测试的系统，该系统利用大型语言模型和基于像素的用户界面理解模型执行测试并生成可导航的视频。通过这种方式，开发人员和质量保证测试人员能够更高效地测试无障碍功能。

    

    开发者和质量保证测试人员通常依赖手动测试来在产品生命周期中测试无障碍功能。然而，手动测试可能很乏味，范围庞大，并且很难安排在其他开发里程碑之间。最近，大型语言模型（LLMs）已被用于各种任务，包括自动化用户界面，但据我们了解，迄今为止还没有人探索过它们在控制辅助技术以支持无障碍测试方面的应用。在本文中，我们从一项形成性研究开始，探讨基于自然语言的无障碍测试工作流程的要求。我们构建了一个系统，该系统以手动无障碍测试为输入（例如，“在VoiceOver中搜索一个节目”），并使用LLM结合基于像素的用户界面理解模型来执行测试并生成章节划分的可导航视频。在每个视频中，为了帮助质量保证测试人员，我们应用启发式方法来检测和标记ac。

    Developers and quality assurance testers often rely on manual testing to test accessibility features throughout the product lifecycle. Unfortunately, manual testing can be tedious, often has an overwhelming scope, and can be difficult to schedule amongst other development milestones. Recently, Large Language Models (LLMs) have been used for a variety of tasks including automation of UIs, however to our knowledge no one has yet explored their use in controlling assistive technologies for the purposes of supporting accessibility testing. In this paper, we explore the requirements of a natural language based accessibility testing workflow, starting with a formative study. From this we build a system that takes as input a manual accessibility test (e.g., ``Search for a show in VoiceOver'') and uses an LLM combined with pixel-based UI Understanding models to execute the test and produce a chaptered, navigable video. In each video, to help QA testers we apply heuristics to detect and flag ac
    
[^178]: 受前额叶皮层启发的大型语言模型规划架构

    A Prefrontal Cortex-inspired Architecture for Planning in Large Language Models. (arXiv:2310.00194v1 [cs.AI])

    [http://arxiv.org/abs/2310.00194](http://arxiv.org/abs/2310.00194)

    这个论文提出了一个受前额叶皮层启发的大型语言模型规划架构，利用多个基于LLM的模块实现规划的自主协调，从而在处理需要多步推理或目标导向规划的任务时取得了较好的效果。

    

    大型语言模型（LLM）在许多任务上展现出惊人的性能，但它们经常在需要多步推理或目标导向规划的任务中遇到困难。为了解决这个问题，我们从人脑中获取灵感，即通过前额叶皮层（PFC）中专门模块的重复交互来完成规划。这些模块执行冲突监测、状态预测、状态评估、任务分解和任务协调等功能。我们发现LLM有时能够单独执行这些功能，但在服务于一个目标时往往难以自主协调它们。因此，我们提出了一个带有多个基于LLM（GPT-4）模块的黑盒架构。该架构通过专门的PFC启发模块的交互将一个更大的问题分解为多个对LLM的简短自动调用，从而改善规划能力。我们在两个具有挑战性的规划任务上评估了组合架构。

    Large language models (LLMs) demonstrate impressive performance on a wide variety of tasks, but they often struggle with tasks that require multi-step reasoning or goal-directed planning. To address this, we take inspiration from the human brain, in which planning is accomplished via the recurrent interaction of specialized modules in the prefrontal cortex (PFC). These modules perform functions such as conflict monitoring, state prediction, state evaluation, task decomposition, and task coordination. We find that LLMs are sometimes capable of carrying out these functions in isolation, but struggle to autonomously coordinate them in the service of a goal. Therefore, we propose a black box architecture with multiple LLM-based (GPT-4) modules. The architecture improves planning through the interaction of specialized PFC-inspired modules that break down a larger problem into multiple brief automated calls to the LLM. We evaluate the combined architecture on two challenging planning tasks -
    
[^179]: SeaEval多语言基础模型：从跨语言对齐到文化推理

    SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning. (arXiv:2309.04766v1 [cs.CL])

    [http://arxiv.org/abs/2309.04766](http://arxiv.org/abs/2309.04766)

    SeaEval是一个评估多语言基础模型的基准测试，研究了模型在自然语言理解、推理以及对文化实践、细微差别和价值观的理解能力上的表现。重要发现包括模型在给出改写指令时行为各异，受到暴露偏差的影响，对于语义等价的多语言查询的回答不一致，以及模型在情感相关问题上的一致性不同。

    

    我们提出了一种用于多语言基础模型的SeaEval基准测试。除了表征这些模型如何理解和推理自然语言外，我们还研究了它们对文化实践、细微差别和价值观的理解能力。除了标准的准确度指标，我们还调查了基础模型在语义和多语言性维度上的脆弱性。我们的分析涵盖了开源和闭源模型，从而得到了在经典的自然语言处理任务、推理和文化理解方面的实证结果。重要发现包括：（1）大多数模型在给出改写指令时的行为各异；（2）许多模型仍然受到暴露偏差的影响（如位置偏差、大多数标签偏差）；（3）对于根源于事实、科学和常识知识的问题，预期在语义上等价的多语言查询应该得到一致的回答。然而，大多数模型在这些查询上表现出令人意外的不一致性；（4）多语言情况下，模型对于情感相关的问题表现出不同程度的一致性。

    We present SeaEval, a benchmark for multilingual foundation models. In addition to characterizing how these models understand and reason with natural language, we also investigate how well they comprehend cultural practices, nuances, and values. Alongside standard accuracy metrics, we investigate the brittleness of foundation models in the dimensions of semantics and multilinguality. Our analyses span both open-sourced and closed models, leading to empirical results across classic NLP tasks, reasoning, and cultural comprehension. Key findings indicate (1) Most models exhibit varied behavior when given paraphrased instructions. (2) Many models still suffer from exposure bias (e.g., positional bias, majority label bias). (3) For questions rooted in factual, scientific, and commonsense knowledge, consistent responses are expected across multilingual queries that are semantically equivalent. Yet, most models surprisingly demonstrate inconsistent performance on these queries. (4) Multilingu
    
[^180]: 大型语言模型在电子健康记录中识别社会健康决定因素

    Large Language Models to Identify Social Determinants of Health in Electronic Health Records. (arXiv:2308.06354v1 [cs.CL])

    [http://arxiv.org/abs/2308.06354](http://arxiv.org/abs/2308.06354)

    本研究利用大型语言模型从电子健康记录中提取社会健康决定因素（SDoH），并通过合成临床文本改进了这些极有价值但很少被记录的临床数据的提取。最佳模型为经过微调的Flan-T5 XL和Flan-T5 XXL，其中小型模型改进了性能。

    

    社会健康决定因素（SDoH）对患者的结果有重要影响，但在电子健康记录（EHR）中的收集不完整。本研究研究了大型语言模型从EHR中提取SDoH的能力，并探讨了合成临床文本在改进这些少见但极有价值的临床数据提取中的作用。对800份患者记录进行了SDoH类别的注释，并评估了几个基于transformer的模型。本研究还尝试了合成数据生成，并评估了算法偏差。我们表现最佳的模型是经过微调的Flan-T5 XL（macro-F1 0.71）用于任何SDoH，以及Flan-T5 XXL（macro-F1 0.70）。通过合成数据辅助微调的效益因模型架构和大小而异，在较小的Flan-T5模型（基础和大型）中表现出最大的性能提升（delta F1 +0.12到+0.23）。模型性能。

    Social determinants of health (SDoH) have an important impact on patient outcomes but are incompletely collected from the electronic health records (EHR). This study researched the ability of large language models to extract SDoH from free text in EHRs, where they are most commonly documented, and explored the role of synthetic clinical text for improving the extraction of these scarcely documented, yet extremely valuable, clinical data. 800 patient notes were annotated for SDoH categories, and several transformer-based models were evaluated. The study also experimented with synthetic data generation and assessed for algorithmic bias. Our best-performing models were fine-tuned Flan-T5 XL (macro-F1 0.71) for any SDoH, and Flan-T5 XXL (macro-F1 0.70). The benefit of augmenting fine-tuning with synthetic data varied across model architecture and size, with smaller Flan-T5 models (base and large) showing the greatest improvements in performance (delta F1 +0.12 to +0.23). Model performance 
    
[^181]: 探索GPT-4的道德和法律推理的心理学研究

    Exploring the psychology of GPT-4's Moral and Legal Reasoning. (arXiv:2308.01264v1 [cs.AI])

    [http://arxiv.org/abs/2308.01264](http://arxiv.org/abs/2308.01264)

    本文探究了GPT-4的道德和法律推理，发现其与人类之间在意图归因、因果判断、欺骗的道德性、道德基础、道德运气对法律判断的影响、同意的概念以及规则违反判断方面存在高相关性。

    

    大型语言模型已被用作高度复杂的人工智能的基础，能够对法律和道德问题作出与人类类似的回应。然而，这些模型对于自身内部工作的指导是不可靠的，即使是它们的创建工程团队也无法解释它们如何获得当前所有能力的具体过程。机器心理学这一新兴领域旨在深入了解这些模型拥有的过程和概念。在本文中，我们运用心理学的方法来探究GPT-4的道德和法律推理。具体而言，我们研究了GPT-4与人类在意图归因、因果判断、欺骗的道德性、道德基础、道德运气对法律判断的影响、同意的概念以及规则违反判断方面的相似性和差异。我们发现人类和人工智能的回答之间存在较高的相关性。

    Large language models have been used as the foundation of highly sophisticated artificial intelligences, capable of delivering human-like responses to probes about legal and moral issues. However, these models are unreliable guides to their own inner workings, and even the engineering teams behind their creation are unable to explain exactly how they came to develop all of the capabilities they currently have. The emerging field of machine psychology seeks to gain insight into the processes and concepts that these models possess. In this paper, we employ the methods of psychology to probe into GPT-4's moral and legal reasoning. More specifically, we investigate the similarities and differences between GPT-4 and humans when it comes to intentionality ascriptions, judgments about causation, the morality of deception, moral foundations, the impact of moral luck on legal judgments, the concept of consent, and rule violation judgments. We find high correlations between human and AI response
    
[^182]: 关于在解决命题可满足性问题的Hopfield网络中使用关联记忆的研究

    On the use of associative memory in Hopfield networks designed to solve propositional satisfiability problems. (arXiv:2307.16807v2 [nlin.AO] UPDATED)

    [http://arxiv.org/abs/2307.16807](http://arxiv.org/abs/2307.16807)

    该论文研究了在解决命题可满足性问题的Hopfield网络中使用关联记忆的方法。通过自我优化模型，网络可以解决具体的组合问题。然而，研究还发现在某些情况下，关键信息可能会永久丢失，导致网络产生看似最优但实际上不适用的解决方案。这一发现对理解网络解决难以处理问题的过程很有启发。

    

    Hopfield网络由于提供了一种生物学上可行的机制，因此在解决许多类型的计算问题时是一个有吸引力的选择。自我优化（SO）模型通过使用基于生物学原理的赫布学习规则和重复的网络重置到任意初始状态，来优化网络行为以达到网络中编码的某个希望的目标状态。为了更好地理解该过程，我们首先证明了SO模型可以通过使用Liars问题和地图着色问题的两个例子来解决具体的组合问题。此外，我们展示了在某些条件下关键信息可能永远丢失，从而使得学习网络产生看似最优解但实际上对所要解决的问题不合适。这种SO模型的副作用看似不好，却可以对其解决难以处理的问题的过程提供洞察力。

    Hopfield networks are an attractive choice for solving many types of computational problems because they provide a biologically plausible mechanism. The Self-Optimization (SO) model adds to the Hopfield network by using a biologically founded Hebbian learning rule, in combination with repeated network resets to arbitrary initial states, for optimizing its own behavior towards some desirable goal state encoded in the network. In order to better understand that process, we demonstrate first that the SO model can solve concrete combinatorial problems in SAT form, using two examples of the Liars problem and the map coloring problem. In addition, we show how under some conditions critical information might get lost forever with the learned network producing seemingly optimal solutions that are in fact inappropriate for the problem it was tasked to solve. What appears to be an undesirable side-effect of the SO model, can provide insight into its process for solving intractable problems.
    
[^183]: 非参数线性特征学习在回归中的应用通过正则化

    Nonparametric Linear Feature Learning in Regression Through Regularisation. (arXiv:2307.12754v2 [stat.ME] UPDATED)

    [http://arxiv.org/abs/2307.12754](http://arxiv.org/abs/2307.12754)

    本研究提出了一种新的非参数线性特征学习方法，对于监督学习中存在于低维线性子空间中的相关信息的预测和解释能力的提升是非常有帮助的。

    

    表征学习在自动化特征选择中发挥着关键作用，特别是在高维数据的背景下，非参数方法常常很难应对。在本研究中，我们专注于监督学习场景，其中相关信息存在于数据的低维线性子空间中，即多指数模型。如果已知该子空间，将大大增强预测、计算和解释能力。为了解决这一挑战，我们提出了一种新颖的非参数预测的线性特征学习方法，同时估计预测函数和线性子空间。我们的方法采用经验风险最小化，并加上函数导数的惩罚项，以保证其多样性。通过利用Hermite多项式的正交性和旋转不变性特性，我们引入了我们的估计器RegFeaL。通过利用替代最小化，我们迭代地旋转数据以改善与线性子空间的对齐。

    Representation learning plays a crucial role in automated feature selection, particularly in the context of high-dimensional data, where non-parametric methods often struggle. In this study, we focus on supervised learning scenarios where the pertinent information resides within a lower-dimensional linear subspace of the data, namely the multi-index model. If this subspace were known, it would greatly enhance prediction, computation, and interpretation. To address this challenge, we propose a novel method for linear feature learning with non-parametric prediction, which simultaneously estimates the prediction function and the linear subspace. Our approach employs empirical risk minimisation, augmented with a penalty on function derivatives, ensuring versatility. Leveraging the orthogonality and rotation invariance properties of Hermite polynomials, we introduce our estimator, named RegFeaL. By utilising alternative minimisation, we iteratively rotate the data to improve alignment with 
    
[^184]: DRAGON: 一种基于对话的带有视觉语言关联的辅助导航机器人

    DRAGON: A Dialogue-Based Robot for Assistive Navigation with Visual Language Grounding. (arXiv:2307.06924v1 [cs.RO])

    [http://arxiv.org/abs/2307.06924](http://arxiv.org/abs/2307.06924)

    DRAGON是一种基于对话的导航机器人，能够理解用户的指令并通过语言与用户沟通，为视力受损者提供导航和环境描述的帮助。

    

    视力受损者在理解和导航周围空间方面存在困难。目前的导航技术要么只关注导航，要么提供有限的关于环境的沟通。受到最近在视觉语言关联和语义导航方面的进展的启发，我们提出了DRAGON，一种由对话系统驱动的导航机器人，并具有将环境与自然语言关联的能力。通过理解用户的指令，DRAGON能够引导用户到地图上的目标地标，描述环境，并通过视觉观察回答问题。通过有效利用对话，机器人可以将用户的自由形式描述与环境中的地标关联起来，并通过口语提供语义信息给用户。我们在日常室内环境中进行了盲目参与者的用户研究。我们的结果表明，DRAGON能够与用户顺畅地沟通，

    Persons with visual impairments (PwVI) have difficulties understanding and navigating spaces around them. Current wayfinding technologies either focus solely on navigation or provide limited communication about the environment. Motivated by recent advances in visual-language grounding and semantic navigation, we propose DRAGON, a guiding robot powered by a dialogue system and the ability to associate the environment with natural language. By understanding the commands from the user, DRAGON is able to guide the user to the desired landmarks on the map, describe the environment, and answer questions from visual observations. Through effective utilization of dialogue, the robot can ground the user's free-form descriptions to landmarks in the environment, and give the user semantic information through spoken language. We conduct a user study with blindfolded participants in an everyday indoor environment. Our results demonstrate that DRAGON is able to communicate with the user smoothly, pr
    
[^185]: 以提示为基础的个性化冷启动推荐的研究

    Towards Personalized Cold-Start Recommendation with Prompts. (arXiv:2306.17256v1 [cs.IR])

    [http://arxiv.org/abs/2306.17256](http://arxiv.org/abs/2306.17256)

    本研究旨在解决个性化冷启动推荐问题，通过利用预训练语言模型的能力，将推荐过程转化为自然语言情感分析，提供适用于创业企业和用户参与历史不足的平台的个性化推荐。

    

    推荐系统在根据用户过去的行为帮助用户发现与其兴趣相符的信息方面发挥着关键作用。然而，当用户和物品之间的历史交互记录不可用时，开发个性化推荐系统变得具有挑战性，这就是所谓的系统冷启动推荐问题。此问题在创业企业或用户参与历史不足的平台中尤为突出。以往的研究集中在用户或物品的冷启动场景，其中系统仍然通过在同一领域中的历史用户和物品交互进行训练来为新用户或物品提供推荐，而无法解决我们的问题。为了弥合这一鸿沟，我们的研究引入了一种创新且有效的方法，利用预训练语言模型的能力。我们将推荐过程转化为自然语言情感分析，其中包含用户资料和物品属性的信息。

    Recommender systems play a crucial role in helping users discover information that aligns with their interests based on their past behaviors. However, developing personalized recommendation systems becomes challenging when historical records of user-item interactions are unavailable, leading to what is known as the system cold-start recommendation problem. This issue is particularly prominent in start-up businesses or platforms with insufficient user engagement history. Previous studies focus on user or item cold-start scenarios, where systems could make recommendations for new users or items but are still trained with historical user-item interactions in the same domain, which cannot solve our problem. To bridge the gap, our research introduces an innovative and effective approach, capitalizing on the capabilities of pre-trained language models. We transform the recommendation process into sentiment analysis of natural languages containing information of user profiles and item attribu
    
[^186]: 大型语言模型的软提示调整方法用于评估偏差

    Soft-prompt Tuning for Large Language Models to Evaluate Bias. (arXiv:2306.04735v1 [cs.CL])

    [http://arxiv.org/abs/2306.04735](http://arxiv.org/abs/2306.04735)

    本文使用软提示调整来量化大型语言模型中的偏差，避免手动设计提示导致的人为偏差注入。通过分组公平性检查模型对不同敏感属性的偏见，发现了有趣的偏差模式。

    

    近年来，大型语言模型的提示功能因无需标记数据即可产生良好结果而备受青睐。然而，这需要进行提示调整以获得引导更好模型性能的最佳提示。本文中，我们探讨了在情感分类任务中使用软提示调整来量化大型语言模型（LLMs）如Open Pre-trained Transformers（OPT）和Galactica语言模型中的偏差。由于这些模型是在可能偏向某些人群的真实数据上训练的，因此识别这些潜在问题非常重要。使用软提示来评估偏差给我们带来了额外的优势，可以避免手动设计提示导致的人为偏差注入。我们使用分组公平性（偏差）检查模型对不同敏感属性的偏见，并找到了有趣的偏差模式。由于LLMs已在各种应用中被用于工业中，因此我们对其进行的偏见评估具有实际意义。

    Prompting large language models has gained immense popularity in recent years due to the advantage of producing good results even without the need for labelled data. However, this requires prompt tuning to get optimal prompts that lead to better model performances. In this paper, we explore the use of soft-prompt tuning on sentiment classification task to quantify the biases of large language models (LLMs) such as Open Pre-trained Transformers (OPT) and Galactica language model. Since these models are trained on real-world data that could be prone to bias toward certain groups of populations, it is important to identify these underlying issues. Using soft-prompts to evaluate bias gives us the extra advantage of avoiding the human-bias injection that can be caused by manually designed prompts. We check the model biases on different sensitive attributes using the group fairness (bias) and find interesting bias patterns. Since LLMs have been used in the industry in various applications, i
    
[^187]: 多尺度正负样本检测AI生成文本

    Multiscale Positive-Unlabeled Detection of AI-Generated Texts. (arXiv:2305.18149v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.18149](http://arxiv.org/abs/2305.18149)

    本文提出了一种多尺度正负样本的训练框架，以解决多尺度AI生成文本的检测问题。通过将短机器文本标记为“未标记”来重新表述文本分类问题，并提出了一个规则化损失函数来优化检测性能，有效性能显著优于现有的方法。

    

    最近发布的大型语言模型（LLM）如ChatGPT等在生成类似于人类的文本方面令人惊讶，但它们可能被用于制造虚假的学术文本、虚假新闻、虚假推特等。先前的作品提出了检测这些多尺度AI生成文本的方法，包括简单的ML分类器、基于预训练模型的训练不可知方法和精调的语言分类模型。然而，主流检测器在构建时没有考虑到文本长度的因素：短文本的缺乏信息特征，使其更难检测。针对多尺度文本检测的挑战，本文提出了一个多尺度正负样本（MPU）训练框架。首先，我们承认短的机器文本具有类人属性，并将文本分类重新表述为一个正负样本问题，即通过在训练期间标记这些短的机器文本为"unlabeled"来解决这个问题。在这个正负样本的背景下，我们提出了

    Recent releases of Large Language Models (LLMs), e.g. ChatGPT, are astonishing at generating human-like texts, but they may get misused for fake scholarly texts, fake news, fake tweets, et cetera. Previous works have proposed methods to detect these multiscale AI-generated texts, including simple ML classifiers, pretrained-model-based training-agnostic methods, and finetuned language classification models. However, mainstream detectors are formulated without considering the factor of corpus length: shorter corpuses are harder to detect compared with longer ones for shortage of informative features. In this paper, a Multiscale Positive-Unlabeled (MPU) training framework is proposed to address the challenge of multiscale text detection. Firstly, we acknowledge the human-resemblance property of short machine texts, and rephrase text classification as a Positive-Unlabeled (PU) problem by marking these short machine texts as "unlabeled" during training. In this PU context, we propose the le
    
[^188]: 通过生成对抗反馈对语言模型进行微调

    Fine-tuning Language Models with Generative Adversarial Feedback. (arXiv:2305.06176v1 [cs.CL])

    [http://arxiv.org/abs/2305.06176](http://arxiv.org/abs/2305.06176)

    本研究探讨了一种新的方法，使用生成对抗反馈的强化学习(RLGAF)对大型语言模型进行微调，以取代仅受人类反馈的强化学习(RLHF)，从而消除评估者的专业限制并提高性能。

    

    通过人类反馈的强化学习已经显著提高了大型语言模型(LLMs)的性能，使其输出与人类期望的价值观保持一致。然而，RLHF受到人类评估者的专业知识和生产力限制。在本研究中，我们研究了一种替代方法: 使用生成对抗反馈的强化学习(RLGAF)代替RLHF。我们的初步发现表明，RLGAF可以帮助对齐LLM的输出，同时不会受到RLHF固有的限制，为进一步自动化AI对齐的研究提供了有希望的途径。

    Reinforcement Learning with Human Feedback (RLHF) has been demonstrated to significantly enhance the performance of large language models (LLMs) by aligning their outputs with desired human values. However, RLHF is constrained by the expertise and productivity limitations of human evaluators. In this study, we investigate an alternative approach: Reinforcement Learning with Generative Adversarial Feedback (RLGAF) to RLHF. Our preliminary findings indicate that RLGAF can help align LLMs outputs while not suffering from the inherent restrictions of RLHF, suggesting promising avenues for further research on automating AI alignment.
    
[^189]: 基于游戏的人工智能研究平台

    Game-based Platforms for Artificial Intelligence Research. (arXiv:2304.13269v1 [cs.AI])

    [http://arxiv.org/abs/2304.13269](http://arxiv.org/abs/2304.13269)

    本文回顾了基于游戏的人工智能研究平台，讨论了不同研究领域和创意设计在其中的应用和发展，并探讨了其未来趋势。

    

    游戏具有现实世界场景的广泛特征，成为了人工智能研究的理想测试基地，共同的研究领域包括学习和优化、动态和不确定环境下的决策制定、博弈论、计划与排程、设计和教育等。已实施了许多开源游戏或基于游戏的环境用于研究人工智能。除了单人或多人、合作或对抗性游戏外，在创意设计方面也越来越受到关注。这些平台为探索和比较人工智能的思想和技术提供了理想基准。本文回顾了基于游戏的人工智能研究平台，讨论了由这些平台演变引起的研究趋势，并展望了未来。

    Games have been the perfect test-beds for artificial intelligence research for the characteristics that widely exist in real-world scenarios. Learning and optimisation, decision making in dynamic and uncertain environments, game theory, planning and scheduling, design and education are common research areas shared between games and real-world problems. Numerous open-sourced games or game-based environments have been implemented for studying artificial intelligence. In addition to single- or multi-player, collaborative or adversarial games, there has also been growing interest in implementing platforms for creative design in recent years. Those platforms provide ideal benchmarks for exploring and comparing artificial intelligence ideas and techniques. This paper reviews the game-based platforms for artificial intelligence research, discusses the research trend induced by the evolution of those platforms, and gives an outlook.
    
[^190]: 基于图注意力的部分可观察均场多智能体强化学习

    Partially Observable Mean Field Multi-Agent Reinforcement Learning Based on Graph-Attention. (arXiv:2304.12653v1 [cs.AI])

    [http://arxiv.org/abs/2304.12653](http://arxiv.org/abs/2304.12653)

    本文提出了一种新的基于图注意力的部分可观察均场多智能体强化学习算法，使用图注意力来捕获周围邻居智能体的特征信息，可以提高大规模多智能体环境中部分可观察MARL的性能。

    

    传统的多智能体强化学习算法难以在大规模多智能体环境中应用。最近引入的均场理论提高了多智能体强化学习的可扩展性。本文考虑部分可观察的多智能体强化学习，其中每个智能体只能观察到固定范围内的其他智能体。这种部分可观察性影响了智能体评估周围智能体行动质量的能力。本文着重于开发一种从局部观测中获取更有效信息以选择更有效行动的方法。在这个领域的以前工作使用概率分布或加权均场来更新邻居智能体平均行动，但它没有充分考虑周围邻居的特征信息，导致了局部最优。本文提出了一种新的多智能体强化学习算法，基于图注意力的部分可观察均场多智能体强化学习，它使用图注意力来捕获周围邻居智能体的特征信息。我们的方法可以提高大规模多智能体环境中部分可观察MARL的性能。

    Traditional multi-agent reinforcement learning algorithms are difficultly applied in a large-scale multi-agent environment. The introduction of mean field theory has enhanced the scalability of multi-agent reinforcement learning in recent years. This paper considers partially observable multi-agent reinforcement learning (MARL), where each agent can only observe other agents within a fixed range. This partial observability affects the agent's ability to assess the quality of the actions of surrounding agents. This paper focuses on developing a method to capture more effective information from local observations in order to select more effective actions. Previous work in this field employs probability distributions or weighted mean field to update the average actions of neighborhood agents, but it does not fully consider the feature information of surrounding neighbors and leads to a local optimum. In this paper, we propose a novel multi-agent reinforcement learning algorithm, Partially
    
[^191]: 逐车跟驰模型综述

    A Review on Longitudinal Car-Following Model. (arXiv:2304.07143v1 [eess.SY])

    [http://arxiv.org/abs/2304.07143](http://arxiv.org/abs/2304.07143)

    这篇论文综述了逐车跟驰模型的不同原则和分类，以及面临的挑战和局限性。

    

    车跟车模型是交通仿真的核心组成部分，已经内置于许多配备ADAS的汽车中。对车跟车行为的研究使我们能够确定由基本的车辆交互过程引起的不同宏观现象的根源。本文提供了一份详尽的调查，重点介绍了各种车跟车模型之间的区别、互补性和重叠之处。该审查将在不同原则中概念化的车跟车模型进行分类。

    The car-following (CF) model is the core component for traffic simulations and has been built-in in many production vehicles with Advanced Driving Assistance Systems (ADAS). Research of CF behavior allows us to identify the sources of different macro phenomena induced by the basic process of pairwise vehicle interaction. The CF behavior and control model encompasses various fields, such as traffic engineering, physics, cognitive science, machine learning, and reinforcement learning. This paper provides a comprehensive survey highlighting differences, complementarities, and overlaps among various CF models according to their underlying logic and principles. We reviewed representative algorithms, ranging from the theory-based kinematic models, stimulus-response models, and cruise control models to data-driven Behavior Cloning (BC) and Imitation Learning (IL) and outlined their strengths and limitations. This review categorizes CF models that are conceptualized in varying principles and s
    
[^192]: 使用丰富的元数据注释的屏幕角色的个性化语言建模

    Personalised Language Modelling of Screen Characters Using Rich Metadata Annotations. (arXiv:2303.16618v1 [cs.CL])

    [http://arxiv.org/abs/2303.16618](http://arxiv.org/abs/2303.16618)

    本篇论文研究了如何使用丰富的元数据注释的信息进行屏幕角色的个性化语言建模，测试表明这样可以有效地进行个性化语言模型的构建，即使对于零样本的演说家也可以应用。

    

    语言模型的个性化为对话敏感，能更好地捕捉特定特征的人员和/或特定环境中的说话模式。然而，丰富的角色注释难以得到和成功利用。在此工作中，我们发布并描述了一组新颖的手动注释，涵盖了来自流行的 Cornell 电影对话语料库的 863 名演讲者，包括特征引用和角色描述，以及超过 95％ 的特色电影的一组自动提取的六个元数据。我们对两个语料库进行了广泛的实验，并表明可以有效地使用此类注释来个性化语言模型，将困惑减少高达 8.5％。我们的方法甚至可以应用于零样本的演讲者，即对于没有先前培训数据的演讲者，依赖于角色的人口特征的组合。由于收集此类元数据成本高昂，因此我们还贡献了一项成本效益分析，以突出显示

    Personalisation of language models for dialogue sensitises them to better capture the speaking patterns of people of specific characteristics, and/or in specific environments. However, rich character annotations are difficult to come by and to successfully leverage. In this work, we release and describe a novel set of manual annotations for 863 speakers from the popular Cornell Movie Dialog Corpus, including features like characteristic quotes and character descriptions, and a set of six automatically extracted metadata for over 95% of the featured films. We perform extensive experiments on two corpora and show that such annotations can be effectively used to personalise language models, reducing perplexity by up to 8.5%. Our method can be applied even zero-shot for speakers for whom no prior training data is available, by relying on combinations of characters' demographic characteristics. Since collecting such metadata is costly, we also contribute a cost-benefit analysis to highlight
    
[^193]: 一个多乐器体积调制的方法增强格斗游戏中的背景音乐：自适应背景音乐

    Adaptive Background Music for a Fighting Game: A Multi-Instrument Volume Modulation Approach. (arXiv:2303.15734v1 [cs.SD])

    [http://arxiv.org/abs/2303.15734](http://arxiv.org/abs/2303.15734)

    本文介绍了一种自适应背景音乐的方法，它由五种不同的乐器演奏名为“空中小姐曲”的古典音乐组成，并通过改变乐器的音量来适应游戏的不同元素。实验结果表明，使用这种自适应背景音乐可以改善游戏的体验。

    

    本文介绍了我们在 DareFightingICE 中添加自适应背景音乐以增强游戏体验的工作。自适应背景音乐由五种不同的乐器演奏名为“空中小姐曲”的古典音乐组成，通过改变乐器的音量来适应游戏的不同元素。我们进行了一项实验来评估自适应背景音乐，并使用了一种只使用音频作为输入的深度增强学习 AI（Blind DL AI）。结果表明，与没有自适应背景音乐时相比，Blind DL AI 在与自适应背景音乐一起播放时表现更好。

    This paper presents our work to enhance the background music (BGM) in DareFightingICE by adding an adaptive BGM. The adaptive BGM consists of five different instruments playing a classical music piece called "Air on G-String." The BGM adapts by changing the volume of the instruments. Each instrument is connected to a different element of the game. We then run experiments to evaluate the adaptive BGM by using a deep reinforcement learning AI that only uses audio as input (Blind DL AI). The results show that the performance of the Blind DL AI improves while playing with the adaptive BGM as compared to playing without the adaptive BGM.
    
[^194]: 重新思考科学发现中符号回归数据集和基准

    Rethinking Symbolic Regression Datasets and Benchmarks for Scientific Discovery. (arXiv:2206.10540v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.10540](http://arxiv.org/abs/2206.10540)

    本文重新审视并重新创建了符号回归数据集，以评估符号回归在科学发现中的潜力和能力，并提出使用归一化编辑距离进行度量。

    

    本文重新审视符号回归（SR）的数据集和评估标准，特别关注其在科学发现中的潜力。针对现有数据集中基于费曼物理讲义的一组公式，我们重新创建了120个数据集，讨论符号回归在科学发现中的性能（SRSD）。对于这120个SRSD数据集，我们仔细审查了公式及其变量的属性，设计了合理的实值范围来采样值，以便我们的新SRSD数据集可用于评估SRSD的潜力，如SR方法是否能从这样的数据集中（重新）发现物理定律。我们还创建了另外120个包含虚拟变量的数据集，以检验SR方法是否能够仅选择必要变量。另外，我们提出使用预测方程与真实方程树之间的归一化编辑距离（NED）来解决现有SR度量存在的一个关键问题，即二元度量问题。

    This paper revisits datasets and evaluation criteria for Symbolic Regression (SR), specifically focused on its potential for scientific discovery. Focused on a set of formulas used in the existing datasets based on Feynman Lectures on Physics, we recreate 120 datasets to discuss the performance of symbolic regression for scientific discovery (SRSD). For each of the 120 SRSD datasets, we carefully review the properties of the formula and its variables to design reasonably realistic sampling ranges of values so that our new SRSD datasets can be used for evaluating the potential of SRSD such as whether or not an SR method can (re)discover physical laws from such datasets. We also create another 120 datasets that contain dummy variables to examine whether SR methods can choose necessary variables only. Besides, we propose to use normalized edit distances (NED) between a predicted equation and the true equation trees for addressing a critical issue that existing SR metrics are either binary
    
[^195]: AutoGL：自动图学习库

    AutoGL: A Library for Automated Graph Learning. (arXiv:2104.04987v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2104.04987](http://arxiv.org/abs/2104.04987)

    AutoGL是第一个专门用于自动图机器学习的开源库，使用方便且易于扩展。它提供了一个完整的自动图学习流程，并支持各种图应用。

    

    近年来，图上的机器学习的研究兴趣和应用不断增加。然而，为不同的图数据集和任务手动设计最优的机器学习算法是不灵活、费时，并且需要专业知识，限制了其适应性和适用性。图上自动机器学习（AutoML）旨在为给定的图数据集和任务自动设计最优的机器学习算法，受到了相当大的关注。然而，现有的库中没有一个能完全支持图上的AutoML。为了填补这一空白，我们提出了自动图学习（AutoGL），这是第一个专门用于自动图机器学习的库。AutoGL是开源的，易于使用，而且易于扩展。具体而言，我们提出了一个包含与设备交互的后端、完整的自动图学习流程和支持的图应用的三层架构。

    Recent years have witnessed an upsurge in research interests and applications of machine learning on graphs. However, manually designing the optimal machine learning algorithms for different graph datasets and tasks is inflexible, labor-intensive, and requires expert knowledge, limiting its adaptivity and applicability. Automated machine learning (AutoML) on graphs, aiming to automatically design the optimal machine learning algorithm for a given graph dataset and task, has received considerable attention. However, none of the existing libraries can fully support AutoML on graphs. To fill this gap, we present Automated Graph Learning (AutoGL), the first dedicated library for automated machine learning on graphs. AutoGL is open-source, easy to use, and flexible to be extended. Specifically, we propose a three-layer architecture, consisting of backends to interface with devices, a complete automated graph learning pipeline, and supported graph applications. The automated machine learning
    

