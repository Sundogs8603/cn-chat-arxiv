# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Parameter is Not All You Need: Starting from Non-Parametric Networks for 3D Point Cloud Analysis.](http://arxiv.org/abs/2303.08134) | 本文提出了一种基于非参数化模型的三维点云分析网络Point-NN。它在各种三维任务中表现良好，不需要参数或训练，可以作为基础架构框架构建参数化网络和已经训练好的三维模型的即插即用模块。 |
| [^2] | [MeshDiffusion: Score-based Generative 3D Mesh Modeling.](http://arxiv.org/abs/2303.08133) | 本文提出了一种基于分数的生成式3D网格建模方法，依赖网格的图形结构和扩散模型，在不需要后处理的前提下，生成高质量、细节丰富的3D网格。 |
| [^3] | [PiMAE: Point Cloud and Image Interactive Masked Autoencoders for 3D Object Detection.](http://arxiv.org/abs/2303.08129) | 本研究提出了PiMAE框架，通过三个方面促进点云和RGB图像的交互，包括利用投影模块互补地对齐两种模态的掩蔽和可见令牌、利用两个支路的MAE管道和共享解码器促进掩蔽令牌中的跨模态交互和设计了跨模态重构模块以增强表示学习。 |
| [^4] | [CB2: Collaborative Natural Language Interaction Research Platform.](http://arxiv.org/abs/2303.08127) | CB2是一个用于研究基于任务的合作自然语言交互的平台，在3D游戏环境中提供了后端服务器和各种工具和流程。它在可扩展的研究中展示了学习的指令跟随模型。 |
| [^5] | [It Takes One to Tango but More Make Trouble? In-Context Training with Different Number of Demonstrations.](http://arxiv.org/abs/2303.08119) | 本文研究了使用较少的演示数进行上下文学习（ICL）的任务，在测试查询上只使用一个随机选择的演示时并没有明显性能下降，而只使用一个正确演示的ICL在性能上显著优于全演示ICL。 |
| [^6] | [Domain Generalization in Machine Learning Models for Wireless Communications: Concepts, State-of-the-Art, and Open Issues.](http://arxiv.org/abs/2303.08106) | 本论文探讨了机器学习在无线通信中应用的重要性，特别是领域通用性方面的问题。研究表明，对于出现在不同领域中的数据，模型的准确性受到很大影响，领域通用性技术可以通过从不同的源域中学习模型并适应新的领域来解决这个问题。 |
| [^7] | [Image Guidance for Robot-Assisted Ankle Fracture Repair.](http://arxiv.org/abs/2303.08105) | 该研究旨在开发和验证一种图像引导框架，使机器人能够自动确定腓骨复位方向，进而提高骨折手术的效率和准确性，改善患者的手术效果，降低患者发生骨性关节炎的风险。 |
| [^8] | [Victoria Amazonica Optimization (VAO): An Algorithm Inspired by the Giant Water Lily Plant.](http://arxiv.org/abs/2303.08070) | 基于维多利亚亚马逊植物的特点，提出一种维多利亚亚马逊优化（VAO）算法，该算法适用于占领更多表面空间的问题，并可用于优化问题的求解。 |
| [^9] | [Ultra-High-Resolution Detector Simulation with Intra-Event Aware GAN and Self-Supervised Relational Reasoning.](http://arxiv.org/abs/2303.08046) | 本文提出了一种新颖的探测器模拟方法IEA-GAN，通过产生与图层相关的上下文化的图像，提高了超高分辨率探测器响应的相关性和多样性。同时，引入新的事件感知损失和统一性损失，显著提高了图像的保真度和多样性。 |
| [^10] | [Progress Note Understanding -- Assessment and Plan Reasoning: Overview of the 2022 N2C2 Track 3 Shared Task.](http://arxiv.org/abs/2303.08038) | 该论文介绍了2022 N2C2临床挑战赛中关于进展笔记理解-评估和计划推理的任务，旨在开发并评估自动预测因果相关概念的NLP系统。 |
| [^11] | [ISimDL: Importance Sampling-Driven Acceleration of Fault Injection Simulations for Evaluating the Robustness of Deep Learning.](http://arxiv.org/abs/2303.08035) | 本论文提出了一种新方法ISimDL，利用神经元灵敏度生成重要性采样，加速故障注入模拟，有效评估了先进的DL系统对硬件故障的韧性，同时显著减少了所需的模拟数量。 |
| [^12] | [A Study on Bias and Fairness In Deep Speaker Recognition.](http://arxiv.org/abs/2303.08026) | 本论文研究深度说话人识别中的偏见和公平性。研究发现，更复杂的编码器结构更符合公平定义。此外，损失函数的选择对SR模型的偏差有显着影响。 |
| [^13] | [Optimizing Deep Learning Model Parameters with the Bees Algorithm for Improved Medical Text Classification.](http://arxiv.org/abs/2303.08021) | 本文使用蜜蜂算法优化了深度学习模型参数，提高了医学文本分类的准确性，最高准确率在英语数据集上达到了99.63%，在阿拉伯语数据集上达到了88%。 |
| [^14] | [Window-Based Early-Exit Cascades for Uncertainty Estimation: When Deep Ensembles are More Efficient than Single Models.](http://arxiv.org/abs/2303.08010) | 本文研究了基于窗口的早期退出集成方法，以在保持模型可扩展性的同时实现不确定性估计任务的高效实现。实验结果表明，该方法在准确性和计算效率上都达到了最新的研究成果。 |
| [^15] | [Continuous Risk Measures for Driving Support.](http://arxiv.org/abs/2303.08007) | 本文通过比较三种不同的基于模型的风险度量方法并在真实情景下测试，提出了基于稀疏关键事件和生存条件的一种新风险度量方法，该方法具有较早的碰撞检测时间和较少的误报检测，适用于ADAS和AD验证。 |
| [^16] | [Multi-agent Attention Actor-Critic Algorithm for Load Balancing in Cellular Networks.](http://arxiv.org/abs/2303.08003) | 该论文提出了一种Robust Multi-agent Attention Actor-Critic算法，可以促进基站之间的协作，以解决蜂窝网络中的负载均衡问题，并通过模拟评估表明了显著的性能提升。 |
| [^17] | [FingerSLAM: Closed-loop Unknown Object Localization and Reconstruction from Visuo-tactile Feedback.](http://arxiv.org/abs/2303.07997) | 本论文提出了一种利用视触反馈进行未知物体定位和重构的闭环方法FingerSLAM，通过局部和全局的双重姿态估计器，以及闭环机制结合触觉和视觉的两种感知模式，实现了姿态估计的优化，并比单一模态的解决方案更加精确。 |
| [^18] | [Automatic summarisation of Instagram social network posts Combining semantic and statistical approaches.](http://arxiv.org/abs/2303.07957) | 本论文提出了一种结合语义和统计方法的混合自动摘要方法，用于Instagram社交网络帖子，实验结果表明其优于传统的抽取式和生成式方法。 |
| [^19] | [On the Connection between Concept Drift and Uncertainty in Industrial Artificial Intelligence.](http://arxiv.org/abs/2303.07940) | 本文探索了工业人工智能中概念漂移和不确定性之间的联系，提出了一种方法来估计模型预测的置信度，并且证明了这种方法可以有效地在无监督的情况下检测概念漂移，从而提高模型的整体性能。 |
| [^20] | [Text-to-image Diffusion Model in Generative AI: A Survey.](http://arxiv.org/abs/2303.07909) | 本文调查了文本到图像扩散模型以及相关应用，总结了最先进的方法，并探讨了挑战和未来方向。 |
| [^21] | [Multiparticle Kalman filter for object localization in symmetric environments.](http://arxiv.org/abs/2303.07897) | 本研究提出了一种新的多粒子卡尔曼滤波器，可解决对称复杂环境下的物体定位问题，并在实验中表现出优于粒子滤波的性能。 |
| [^22] | [Geolocation Predicting of Tweets Using BERT-Based Models.](http://arxiv.org/abs/2303.07865) | 该论文提出基于BERT模型的推文地理位置预测方法，可以实现全球和美国上的中位误差分别小于30公里和15公里的定位精度。 |
| [^23] | [You Can Ground Earlier than See: An Effective and Efficient Pipeline for Temporal Sentence Grounding in Compressed Videos.](http://arxiv.org/abs/2303.07863) | 本文提出了一种新的压缩域TSG设置，通过直接编码压缩位流来增强视觉特征表示能力和提高时间句子对齐的效率，并且在两个基准数据集的实验中表现优于目前最先进的方法。 |
| [^24] | [Sample-efficient Adversarial Imitation Learning.](http://arxiv.org/abs/2303.07846) | 本研究提出了一种利用自监督表示来增强样本效率的对抗性模仿学习方法，从而学习不受扭曲影响的状态和动作表示以建立非图像控制任务的预测表征。 |
| [^25] | [ChatGPT Prompt Patterns for Improving Code Quality, Refactoring, Requirements Elicitation, and Software Design.](http://arxiv.org/abs/2303.07839) | 本文提出了ChatGPT提示模式，用于提高代码质量、重构、需求调查和软件设计。它提供了软件工程模式目录，并探讨了几种提示模式，包括改善需求调查、快速原型设计、代码质量、重构和系统设计。 |
| [^26] | [Emergent Bio-Functional Similarities in a Cortical-Spike-Train-Decoding Spiking Neural Network Facilitate Predictions of Neural Computation.](http://arxiv.org/abs/2303.07830) | 本研究提出了一种循环SNN模型，motorSRNN，通过捕获和培养运动皮层神经元的余弦调谐等生物学特性，实现了对猴子运动皮层脉冲列的良好分类，并且进一步产生了额外的生物功能相似性。 |
| [^27] | [ICICLE: Interpretable Class Incremental Continual Learning.](http://arxiv.org/abs/2303.07811) | ICICLE提出了一种基于样本的可解释的类增量连续学习方法，通过采用原型部分化方法来解决解释性概念漂移的问题，实验结果表明其在不需要样本的情况下表现优于现有的方法。 |
| [^28] | [Robot Grasping and Manipulation: A Prospective.](http://arxiv.org/abs/2303.07807) | 机器人手的设计和功能是机器人技术中的最大挑战之一，解决这个问题将引领进入一个新的改进时代。 |
| [^29] | [OVRL-V2: A simple state-of-art baseline for ImageNav and ObjectNav.](http://arxiv.org/abs/2303.07798) | OVRL-V2是一篇关于ImageNav和ObjectNav的最新基准模型，由任务无关的组件组成，不需要任务特定模块。该模型来源于对最近自监督学习的成功应用，而且通用性较强。 |
| [^30] | [Can neural networks do arithmetic? A survey on the elementary numerical skills of state-of-the-art deep learning models.](http://arxiv.org/abs/2303.07735) | 本文调查了最近的文献，发现即使最先进的深度学习模型在面对基本数值和算术知识的相对简单任务时也经常无法胜任。 |
| [^31] | [Improving Prosody for Cross-Speaker Style Transfer by Semi-Supervised Style Extractor and Hierarchical Modeling in Speech Synthesis.](http://arxiv.org/abs/2303.07711) | 该论文提出了强度受控的半监督风格提取器以及分层韵律预测器来改善音频跨发言人风格转移中的韵律问题，解除了一对多映射和数据不平衡问题。 |
| [^32] | [Adaptive Policy Learning for Offline-to-Online Reinforcement Learning.](http://arxiv.org/abs/2303.07693) | 本文提出了一种自适应策略学习框架，以有效地利用离线和在线数据，实现了离线到在线强化学习的最佳效果。 |
| [^33] | [Dual-Attention Model for Aspect-Level Sentiment Classification.](http://arxiv.org/abs/2303.07689) | 本文提出了一种面向方面级情感分类的双重注意力模型，使用依存标签为注意力机制执行任务，对三个数据集均有良好表现。 |
| [^34] | [FPTN: Fast Pure Transformer Network for Traffic Flow Forecasting.](http://arxiv.org/abs/2303.07685) | 本文提出了一种快速纯Transformer网络（FPTN），将交通流量数据沿传感器维度而非时间维度划分为序列，提出了三种嵌入方式将这些向量投影到适当的向量空间中，然后利用Transformer的多头注意机制捕获复杂时空相关性，使用全连接层输出预测的交通流量，FPTN不仅实现了最先进的准确性，而且运行速度比其他基于Transformer的模型快几倍。 |
| [^35] | [Feature-Rich Audio Model Inversion for Data-Free Knowledge Distillation Towards General Sound Classification.](http://arxiv.org/abs/2303.07643) | 该论文提出了一种基于特征丰富的音频模型反演（FRAMI）的无数据知识蒸馏框架，用于通用声音分类任务。通过特征不变对比损失生成高质量和特征丰富的Mel频谱图，再利用统计汇集层之前和之后的隐藏状态进行知识蒸馏。实验结果表明，该方法能够提高学生模型的准确性。 |
| [^36] | [I$^2$-SDF: Intrinsic Indoor Scene Reconstruction and Editing via Raytracing in Neural SDFs.](http://arxiv.org/abs/2303.07634) | 本文提出了 I$^2$-SDF 方法，使用可微分的蒙特卡罗光线跟踪技术实现了室内场景的重建和编辑，采用气泡损失函数和错误引导的自适应采样方案提高了重建质量，同时分解神经辐射场为场景的空间变化材料实现了物理和逼真的场景编辑应用。 |
| [^37] | [RE-MOVE: An Adaptive Policy Design Approach for Dynamic Environments via Language-Based Feedback.](http://arxiv.org/abs/2303.07622) | RE-MOVE提出了一种基于语言反馈的自适应策略设计方法，可以使机器人适应实时环境变化，并从人类反馈中学习并适应之前未见过的对抗性场景。 |
| [^38] | [Redrawing attendance boundaries to promote racial and ethnic diversity in elementary schools.](http://arxiv.org/abs/2303.07603) | 该研究通过将家长的偏好数据与组合优化方法相结合，重新划分小学的考勤边界，以最小化白/非白人种族分离，同时减轻对行程时间和学校规模的影响，实现了中位数14％的种族隔离率相对降低，需要约20％的学生转换学校，并出乎意料地略微缩短了行程时间。 |
| [^39] | [Forecasting COVID-19 Infections in Gulf Cooperation Council (GCC) Countries using Machine Learning.](http://arxiv.org/abs/2303.07600) | 本论文利用机器学习时间序列模型针对海湾合作委员会国家的COVID-19疫情数据进行分析，实验结果表明所开发的模型可以高精度地对COVID-19感染情况进行预测。 |
| [^40] | [AdPE: Adversarial Positional Embeddings for Pretraining Vision Transformers via MAE+.](http://arxiv.org/abs/2303.07598) | AdPE方法通过对抗位置嵌入，扭曲局部结构，强制Transformer编码器在全局上下文中学习更具有差别性的特征，从而提高泛化能力。 |
| [^41] | [Teacher-Student Knowledge Distillation for Radar Perception on Embedded Accelerators.](http://arxiv.org/abs/2303.07586) | 本文提出一种基于师生知识蒸馏的方法，用于低级别雷达感知任务，并成功实现嵌入式计算的实时部署，速度达到教师模型的100倍。 |
| [^42] | [Diffusion Models in NLP: A Survey.](http://arxiv.org/abs/2303.07576) | 本文总结了在自然语言处理中，扩散模型在文本生成和驱动图像生成方面等应用中表现出的创纪录性能，并深入分析并总结相关文献资料。 |
| [^43] | [Lifelong Learning for Anomaly Detection: New Challenges, Perspectives, and Insights.](http://arxiv.org/abs/2303.07557) | 本文探讨了终身异常检测的重要性，提出设计终身学习复杂性的异常检测方法的挑战和机会，并提供了一种场景生成过程使得研究人员能够进行实验。 |
| [^44] | [Merging Decision Transformers: Weight Averaging for Forming Multi-Task Policies.](http://arxiv.org/abs/2303.07551) | 本文提出通过在权重空间中合并训练于不同 MuJoCo 运动问题上的 Decision Transformer 的子集，形成多任务模型。通过共享一些辅助任务的训练以及共同使用预训练初始化，能够获得更好的结果。这个方向的研究有助于使代理的过程民主化和分发。 |
| [^45] | [WDiscOOD: Out-of-Distribution Detection via Whitened Linear Discriminative Analysis.](http://arxiv.org/abs/2303.07543) | 本论文提出了一种名为WDiscOOD的新型OOD检测方法，其中使用白化线性判别分析将特征投影到判别子空间和残留子空间中，确定OOD分数。在大规模ImageNet-1k基准测试和六个OOD数据集中，WDiscOOD表现出了优越的性能。 |
| [^46] | [Path Planning using Reinforcement Learning: A Policy Iteration Approach.](http://arxiv.org/abs/2303.07535) | 本研究提出了一种基于自动调整器的序数回归方法，以加速探索强化学习算法的参数，并加速收敛到最优策略。该方法可以提供1.82倍的峰值加速和1.48倍的平均加速比。 |
| [^47] | [Audio Visual Language Maps for Robot Navigation.](http://arxiv.org/abs/2303.07522) | 该论文提出了一种音视语言地图(AVLMaps)，用于存储跨模态信息，实现机器人根据多模态查询在地图中索引目标的导航方式。在模拟实验中，AVLMaps实现了从多模态提示的零次学习式多模态目标导航，并提供了更好的召回率。 |
| [^48] | [Loss of Plasticity in Continual Deep Reinforcement Learning.](http://arxiv.org/abs/2303.07507) | 本文研究了在连续变化的环境中，深度强化学习代理程序在执行一系列游戏时失去可塑性。研究发现网络的激活足迹变得稀疏导致梯度变小。 |
| [^49] | [Meta-learning approaches for few-shot learning: A survey of recent advances.](http://arxiv.org/abs/2303.07502) | 本文综述了元学习在小样本学习中的应用，调查了最先进的方法，并讨论了当前挑战和未来研究方向。 |
| [^50] | [Efficient Self-supervised Continual Learning with Progressive Task-correlated Layer Freezing.](http://arxiv.org/abs/2303.07477) | 本论文提出了一种新的自监督连续学习方法，通过渐进地冻结有最高相关性的部分层来优化学习效率，并提高了所学表示的丰富性和鲁棒性。 |
| [^51] | [Challenges and Practices of Deep Learning Model Reengineering: A Case Study on Computer Vision.](http://arxiv.org/abs/2303.07476) | 本研究对深度学习模型重构进行了实例研究，并发现由于参考模型文档不全、需求变化以及实现和测试成本等原因，该过程具有挑战性，个别工程师可能缺乏软件工程方面的专业知识，但团队必须应用软件工程和深度学习的知识才能成功。 |
| [^52] | [A Framework for Combining Entity Resolution and Query Answering in Knowledge Bases.](http://arxiv.org/abs/2303.07469) | 该论文提出了一种将实体解析和查询回答相结合的框架，可以解决数据中存在的不一致性，通过特殊实例的等价类和值集来定义KB的语义，设计了一个不会失败的追踪过程，生成通用解决方案，并讨论了可能的挑战。 |
| [^53] | [Superhuman Artificial Intelligence Can Improve Human Decision Making by Increasing Novelty.](http://arxiv.org/abs/2303.07462) | 该研究通过分析职业围棋选手的移动决策发现，在超人工智能问世后，人类开始做出显著更好的决策，并且新颖的决策更频繁地发生，可能意味着超人工智能的发展可以改变人类的决策能力。 |
| [^54] | [AMOM: Adaptive Masking over Masking for Conditional Masked Language Model.](http://arxiv.org/abs/2303.07457) | 本文提出了一种适应性 Masking over Masking 策略来增强条件 Masked 语言模型的细化能力和优化效率，这种策略在神经机器翻译、摘要和代码生成任务中取得了显著的性能提升。 |
| [^55] | [DRISHTI: Visual Navigation Assistant for Visually Impaired.](http://arxiv.org/abs/2303.07451) | DRISHTI是一个采用人工智能技术的可穿戴设备，可为视障人士提供实用的导航辅助，包括检测和识别用户路径及路径前方障碍物，并通过音频输出告知用户。 |
| [^56] | [On the ethics of constructing conscious AI.](http://arxiv.org/abs/2303.07439) | AI伦理学关注机器人防止其对人类行为不当，但完全忽视了机器人需要保护自己免受创造者伤害的可能性。 |
| [^57] | [Unsupervised Representation Learning in Partially Observable Atari Games.](http://arxiv.org/abs/2303.07437) | 本文提出了一种针对部分可观测状态的无监督状态表示学习方法PO-ST-DIM，改进了ST-DIM的对比方法，并在Atari游戏中取得了与监督方法相当的表现。 |
| [^58] | [Discovering Multiple Algorithm Configurations.](http://arxiv.org/abs/2303.07434) | 本文扩展了算法配置以自动发现数据集中的多个模式，这些模式代表多个数据集实例，并在优化过程中自动检测。这对于多个机器人应用领域中的算法配置具有明显的益处。 |
| [^59] | [End-to-end Deformable Attention Graph Neural Network for Single-view Liver Mesh Reconstruction.](http://arxiv.org/abs/2303.07432) | 本文提出了一种基于端到端可变形注意力图神经网络的肝脏网格重建模型，可实时生成肝脏三角形形状，通过图神经网络处理图形数据，并提供了两种即时方法，能有效推断网格形状和位置。 |
| [^60] | [Polar-VQA: Visual Question Answering on Remote Sensed Ice sheet Imagery from Polar Region.](http://arxiv.org/abs/2303.07403) | 本文介绍了一项极地遥感冰层图像中的视觉问答（VQA）的任务，并提出了一个独特的数据集Polar-VQA。本研究的目标是强调VQA在冰层研究中的重要性，并对现有VQA方法在Polar-VQA数据集上进行基线研究。 |
| [^61] | [Fast exploration and learning of latent graphs with aliased observations.](http://arxiv.org/abs/2303.07397) | 本文介绍了一种在具有别名观测的潜在图上，能够显著提高最大化探索效率的政策算法 eFeX，相比于随机策略，该算法能够更快地恢复各种拓扑结构下的图表。 |
| [^62] | [Sequential Spatial Network for Collision Avoidance in Autonomous Driving.](http://arxiv.org/abs/2303.07352) | 本文提出了一种新的基于时序空间网络的碰撞避免算法，能够有效关联输入图像的区域特征，以实现自主驾驶领域中的碰撞避免。 |
| [^63] | [Parallel Vertex Diffusion for Unified Visual Grounding.](http://arxiv.org/abs/2303.07216) | 本文提出了一种并行顶点扩散模型(PVD)，用于统一视觉定位中的高维扩展，解决了顺序生成高维顶点序列容易出现的问题，以及由于顶点数量不足而导致的对象轮廓匹配不准确的问题。 |
| [^64] | [Supervised Feature Selection with Neuron Evolution in Sparse Neural Networks.](http://arxiv.org/abs/2303.07200) | 本文提出了一种使用神经元进化的稀疏神经网络方法，名为 NeuroFS，能够有效地派生出信息丰富的特征子集，且在实验中具有最高排名得分。 |
| [^65] | [Quantifying Causes of Arctic Amplification via Deep Learning based Time-series Causal Inference.](http://arxiv.org/abs/2303.07122) | 该研究提出了一种基于循环神经网络的时间序列因果推断模型TCINet，用于推断大气过程对海冰融化的因果效应。通过实验证明，该模型能够显著提高量化北极海冰融化的主要原因的能力。 |
| [^66] | [Meaningful human command: Advance control directives as a method to enable moral and legal responsibility for autonomous weapons systems.](http://arxiv.org/abs/2303.06813) | 本文探讨了如何确保在超越实时或非常缓慢的操作中的自主系统的道德和法律责任，并提出了建立“预先控制指令”框架的“自主命令”，来实现自主武器系统的问责和责任所需的深思熟虑的过程。 |
| [^67] | [The Planner Optimization Problem: Formulations and Frameworks.](http://arxiv.org/abs/2303.06768) | 本研究提出了统一的规划优化问题公式和开放式规划优化框架，可帮助解决自动调整规划内部参数的挑战和缺乏统一问题定义和软件框架等问题。 |
| [^68] | [Decision Making for Human-in-the-loop Robotic Agents via Uncertainty-Aware Reinforcement Learning.](http://arxiv.org/abs/2303.06710) | 该论文提出了一种基于强化学习的半自主代理机器人方法，在对任务成功结果的信心低时请求外部帮助，有效降低专家调用数量。 |
| [^69] | [Mapping the Design Space of Interactions in Human-AI Text Co-creation Tasks.](http://arxiv.org/abs/2303.06430) | 本文提出了一系列内容生成任务及其相应的人工智能与人类交互模式，鼓励研究社区专注于更复杂和相互依赖的任务，这些任务需要更高水平的人类参与。 |
| [^70] | [HiNet: Novel Multi-Scenario & Multi-Task Learning with Hierarchical Information Extraction.](http://arxiv.org/abs/2303.06095) | HiNet是一种多场景和多任务学习网络，具有层次信息提取和场景感知注意，可以增强推荐系统的学习能力和效果。 |
| [^71] | [Variance-aware robust reinforcement learning with linear function approximation under heavy-tailed rewards.](http://arxiv.org/abs/2303.05606) | 本文提出了AdaOFUL和VARA两种算法，用于在存在有限方差的重尾奖励情况下进行在线顺序决策，其中AdaOFUL具有状态-of-the-art的遗憾界，VARA达到了更紧密的方差感知遗憾界。 |
| [^72] | [Neural Probabilistic Logic Programming in Discrete-Continuous Domains.](http://arxiv.org/abs/2303.04660) | 介绍了一种名为DeepSeaProbLog的神经概率逻辑编程语言，将深度概率编程技术纳入其中，支持在逻辑约束条件下推断和学习离散和连续概率分布，并通过实验证明其优势。 |
| [^73] | [Dish-TS: A General Paradigm for Alleviating Distribution Shift in Time Series Forecasting.](http://arxiv.org/abs/2302.14829) | Dish-TS是一种通用的神经网络模型，用于缓解时间序列预测中的分布偏移。该模型通过引入系数网络（CONET）来更好地估计分布。在时间序列预测任务中，将Lookback窗口作为输入空间，Horizon窗口作为输出空间，将分布偏移总结为内部空间偏移和不同空间偏移两类。 |
| [^74] | [Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks.](http://arxiv.org/abs/2302.08399) | 大型语言模型在微小的理论任务改动上容易失败，表明在直觉心理学模型评估中需要持怀疑态度，且失败案例应被重视。 |
| [^75] | [Quantum Circuit Components for Cognitive Decision-Making.](http://arxiv.org/abs/2302.03012) | 本文将一些非经典的人类决策模型成功地应用于量子计算机电路，并通过量子概率、角度和子空间等方式描述了这些模型和它们在量子计算机上的实现和研究。 |
| [^76] | [Learning Representations of Bi-level Knowledge Graphs for Reasoning beyond Link Prediction.](http://arxiv.org/abs/2302.02601) | 本文提出了一种基于双层知识图谱的方法来学习嵌入，将三元组之间的关系考虑进去，并使用数据增强策略来增加合理的三元组。 |
| [^77] | [Semantics-enhanced Temporal Graph Networks for Content Popularity Prediction.](http://arxiv.org/abs/2301.12355) | 本研究提出了一种基于语义增强的时间图网络，名为STGN，用于内容流行度预测。该网络可以更好地利用表面拓扑结构背后的隐含关系，并采用新的时间聚合机制来捕捉用户偏好的动态变化。实验结果表明，STGN在内容流行度预测方面表现优于最先进方法，特别是对于长期预测。 |
| [^78] | [SegViz: A federated-learning based framework for multi-organ segmentation on heterogeneous data sets with partial annotations.](http://arxiv.org/abs/2301.07074) | SegViz是一种基于联邦学习的框架，用于从分布式的非i.i.d数据集中训练具有部分注释的分割模型。使用FedBN作为聚合策略的SegViz框架在外部BTCV集上表现出优异的性能，分割的dice分数分别为0.93、0.83、0.55和0.75。 |
| [^79] | [A Concept Knowledge Graph for User Next Intent Prediction at Alipay.](http://arxiv.org/abs/2301.00503) | 本文提出了一种基于概念知识图谱的用户下一步意图预测技术，实现了在支付宝网络平台上对1亿活跃用户的服务，并且在保持可解释性的情况下，有效地提高了下游任务的性能表现。 |
| [^80] | [SceneRF: Self-Supervised Monocular 3D Scene Reconstruction with Radiance Fields.](http://arxiv.org/abs/2212.02501) | SceneRF利用自监督学习结合NeRF的辐射场技术，无需深度监督，只需使用图像序列训练，可以高效处理大场景，能够生成新的深度视图并进行3D场景重建，性能在室内外场景中优于所有基线方法。 |
| [^81] | [Navigation as Attackers Wish? Towards Building Byzantine-Robust Embodied Agents under Federated Learning.](http://arxiv.org/abs/2211.14769) | 本文研究了联邦学习体系下代理人学习中可能出现的攻击和防御策略，建立了全联邦拜占庭鲁棒的代理人学习模型。其中，导航即攻击者所愿（NAW）是一种简单而有效的攻击策略，而基于离群点检测的防御训练方法可以有效减轻NAW攻击的影响，提高代理人学习的全局鲁棒性。 |
| [^82] | [Grad-StyleSpeech: Any-speaker Adaptive Text-to-Speech Synthesis with Diffusion Models.](http://arxiv.org/abs/2211.09383) | Grad-StyleSpeech基于扩散模型，可以实现任意发言人自适应语音合成，准确模拟目标说话人的风格，性能显著优于现有方法。 |
| [^83] | [PhaseAug: A Differentiable Augmentation for Speech Synthesis to Simulate One-to-Many Mapping.](http://arxiv.org/abs/2211.04610) | PhaseAug 是一种可微的语音合成数据增强技术，通过旋转每个频率箱的相位，模拟一对多映射关系，解决了传统训练中出现周期性伪影的问题，而且无需任何架构修改就可以超越基线方法。 |
| [^84] | [Active Relation Discovery: Towards General and Label-aware Open Relation Extraction.](http://arxiv.org/abs/2211.04215) | 本论文提出了一个活跃关系发现(ARD)框架，用于解决开放关系抽取中区分已知和新关系以及标记新关系类型的问题。实验证明，该框架在常规和更通用的设置上都显著优于以前的最先进方法。 |
| [^85] | [Leveraging Demonstrations with Latent Space Priors.](http://arxiv.org/abs/2210.14685) | 本文提出了一种方法，通过结合技能学习和序列建模，利用演示数据集中的潜在空间先验知识来加速强化学习中高层次策略的学习，并在实验中证实了该方法的有效性。 |
| [^86] | [Bayesian Prompt Learning for Image-Language Model Generalization.](http://arxiv.org/abs/2210.02390) | 本文提出了一种基于贝叶斯方法的提示学习框架，对提示空间进行正则化，提高了对未见提示的泛化能力。 |
| [^87] | [Spatial-Temporal-Aware Safe Multi-Agent Reinforcement Learning of Connected Autonomous Vehicles in Challenging Scenarios.](http://arxiv.org/abs/2210.02300) | 本文提出了一个新的约束多智能体强化学习框架，该框架包含一个并行Safety Shield模块，可应用于包含非连接的危险车辆的具有挑战性的驾驶场景中的连接自动驾驶车辆。通过信息共享、合作策略学习、图卷积网络-Transformer作为空间-时间编码器以及基于控制障碍函数的安全屏障模块等协调机制，该框架能够提高智能车辆系统的安全性和效率。 |
| [^88] | [Dataset Distillation Using Parameter Pruning.](http://arxiv.org/abs/2209.14609) | 本文提出了一种使用参数修剪的数据集蒸馏方法，该方法可以在蒸馏过程中修剪难以匹配的参数，提高蒸馏性能。 |
| [^89] | [A Diffusion Model Predicts 3D Shapes from 2D Microscopy Images.](http://arxiv.org/abs/2208.14125) | 该论文介绍了一种基于扩散模型的方法，用于从2D显微图像中预测真实的3D单个细胞形状。该方法被成功应用于单个细胞分类任务。该模型学习从2D显微镜图像中重建具有逼真形态学特征的3D形状。 |
| [^90] | [Marker and source-marker reprogramming of Most Permissive Boolean networks and ensembles with BoNesis.](http://arxiv.org/abs/2207.13307) | 本文介绍了BoNesis软件在标记和源标记再编程问题中的应用，使用扰动固定点和最小陷阱空间，通过在BNs和集合中进行讨论和分析，得出相关的计算复杂度和解决方案。 |
| [^91] | [Mitigating Algorithmic Bias with Limited Annotations.](http://arxiv.org/abs/2207.10018) | 本文提出了一种名为APOD的交互式框架，用于在有限的注释预算下减少算法偏见，该框架将歧视惩罚与主动实例选择相结合，能够在公平性和准确度指标上优于传统方法。 |
| [^92] | [Augmenting Softmax Information for Selective Classification with Out-of-Distribution Data.](http://arxiv.org/abs/2207.07506) | 本文研究了存在外部分布数据时的选择性分类问题，提出了一种新的SCOD方法，即保留softmax信息，并发现现有的检测方法评价标准需根据任务规定进行调整。 |
| [^93] | [Combinatorial Pure Exploration of Causal Bandits.](http://arxiv.org/abs/2206.07883) | 本文提出了用于因果模型的组合纯探索算法，其中对于二元广义线性模型，我们的算法实现了多项式样本复杂度，对于一般的图，我们的样本复杂度几乎是最优的。 |
| [^94] | [Human heuristics for AI-generated language are flawed.](http://arxiv.org/abs/2206.07271) | 人们很难辨别AI生成的语言形式，因为通常采用的判断启发式算法出现了一些缺陷，需要使用更为复杂的语言分析工具和教育来提高人们的判断力。 |
| [^95] | [Relphormer: Relational Graph Transformer for Knowledge Graph Representations.](http://arxiv.org/abs/2205.10852) | Relphormer是一种新的Transformer变体，用于知识图谱表示。它引入了Triple2Seq和增强式自我注意机制，以解决基本Transformer架构在捕捉知识图谱结构和语义信息方面的不足。 |
| [^96] | [AIGenC: AI generalisation via creativity.](http://arxiv.org/abs/2205.09738) | AIGenC 提出了一种创造性的计算模型，通过引入概念空间和分层结构来提高人工智能代理的通用性和创新能力，实验表明其在通用任务中的表现优于最先进方法。 |
| [^97] | [From Discrimination to Generation: Knowledge Graph Completion with Generative Transformer.](http://arxiv.org/abs/2202.02113) | 本文介绍了一种将知识图谱补全转化为生成任务的方法，同时引入了关系引导演示和实体感知分层解码来实现更好的表示学习和快速推断。实验结果表明，这种方法具有比基线更好或相当的性能，并且比以往的方法更快。同时，作者还发布了一个新的大规模中文知识图谱数据集AliopenKG500。 |
| [^98] | [Knowledge Graph Augmented Network Towards Multiview Representation Learning for Aspect-based Sentiment Analysis.](http://arxiv.org/abs/2201.04831) | 本文提出了一种名为KGAN的模型，通过知识图谱增强网络，将外部知识和上下文、句法信息相结合，从多个角度捕获情感特征，实现了多视角的表示学习。 |
| [^99] | [Artificial Intelligence Ethics and Safety: practical tools for creating "good" models.](http://arxiv.org/abs/2112.11208) | 本文的目标是推广人工智能开发实践中的道德原则和规范指南，并使人工智能得到道德和负责任的创造。 |
| [^100] | [One-Step Abductive Multi-Target Learning with Diverse Noisy Samples and Its Application to Tumour Segmentation for Breast Cancer.](http://arxiv.org/abs/2110.10325) | 本论文提出了一种新的机器学习方法——一步式诱导式多目标学习与DiNS（OSAMTL-DiNS），以处理医学组织病理学全幻灯片图像分析中的复杂噪声标签。在乳腺癌肿瘤分割中得到了成功应用。 |
| [^101] | [A Broad Ensemble Learning System for Drifting Stream Classification.](http://arxiv.org/abs/2110.03540) | 一种名为Broad Ensemble Learning System (BELS)的新型集成方法用于数据流分类中的概念漂移问题。相对于文献中现有的方法，它能够更加高效、稳定地更新模型，提高最佳性能模型的准确性。 |
| [^102] | [Thought Flow Nets: From Single Predictions to Trains of Model Thought.](http://arxiv.org/abs/2107.12220) | 本文探讨了给模型第二次、第三次甚至第k次思考机会的思路流网络，其利用自我校正机制和梯度更新能够纠正自身预测，该方法可显著提高模型性能。 |
| [^103] | [A new Potential-Based Reward Shaping for Reinforcement Learning Agent.](http://arxiv.org/abs/1902.06239) | 本论文提出了一种新的基于历史经验的奖赏设计方法，旨在提高强化学习智能体的性能，该方法具有广泛的应用前景。 |
| [^104] | [The ERA of FOLE: Foundation.](http://arxiv.org/abs/1512.07430) | 本文讨论本体在FOLE一阶逻辑环境中的表示，特别是提供了ERA数据模型的严格数学表示，作为本体论的基础探讨。 |

# 详细

[^1]: 非参数化网络在三维点云分析中的应用：参数不是唯一需要的。

    Parameter is Not All You Need: Starting from Non-Parametric Networks for 3D Point Cloud Analysis. (arXiv:2303.08134v1 [cs.CV])

    [http://arxiv.org/abs/2303.08134](http://arxiv.org/abs/2303.08134)

    本文提出了一种基于非参数化模型的三维点云分析网络Point-NN。它在各种三维任务中表现良好，不需要参数或训练，可以作为基础架构框架构建参数化网络和已经训练好的三维模型的即插即用模块。

    

    本文提出了一种基于非参数化模型的三维点云分析网络——Point-NN。该网络仅由不可学习组件组成，包括最远点采样（FPS）、K近邻（k-NN）和加权平均池化等操作及三角函数。令人惊讶的是，它在各种三维任务中表现良好，不需要参数或训练，甚至超过了现有的完全训练模型。基于这种非参数模型，我们提出了两种扩展。首先，Point-NN可以作为基础架构框架，通过在其上简单插入线性层来构建参数化网络。在非参数基础上，得到的Point-PN具有较高的性能效率权衡，只需要很少的可学习参数。其次，Point-NN可以被视为已经训练好的三维模型的即插即用模块。Point-NN捕获互补的几何知识，增强现有方法对不同三维基准的性能。我们希望我们的工作能够激发更多对非线性操作和几何知识的研究。

    We present a Non-parametric Network for 3D point cloud analysis, Point-NN, which consists of purely non-learnable components: farthest point sampling (FPS), k-nearest neighbors (k-NN), and pooling operations, with trigonometric functions. Surprisingly, it performs well on various 3D tasks, requiring no parameters or training, and even surpasses existing fully trained models. Starting from this basic non-parametric model, we propose two extensions. First, Point-NN can serve as a base architectural framework to construct Parametric Networks by simply inserting linear layers on top. Given the superior non-parametric foundation, the derived Point-PN exhibits a high performance-efficiency trade-off with only a few learnable parameters. Second, Point-NN can be regarded as a plug-and-play module for the already trained 3D models during inference. Point-NN captures the complementary geometric knowledge and enhances existing methods for different 3D benchmarks without re-training. We hope our w
    
[^2]: MeshDiffusion：基于分数的生成式3D网格建模

    MeshDiffusion: Score-based Generative 3D Mesh Modeling. (arXiv:2303.08133v1 [cs.GR])

    [http://arxiv.org/abs/2303.08133](http://arxiv.org/abs/2303.08133)

    本文提出了一种基于分数的生成式3D网格建模方法，依赖网格的图形结构和扩散模型，在不需要后处理的前提下，生成高质量、细节丰富的3D网格。

    

    本文研究了生成逼真的3D物体的任务，这对于自动场景生成和物理仿真等多种应用非常有用。相比于体素和点云等其他3D表示，网格在实践中更加优越，因为(1)它们可以轻松任意地操纵形状以供重新照明和仿真，(2)可以充分发挥现代图形流水线的能力，而这些流水线大多数针对网格进行了优化。以往可扩展的3D网格生成方法通常依赖于次优的后处理，并且它们往往会产生过于平滑或嘈杂的表面，缺乏精细的几何细节。为了克服这些缺点，我们利用网格的图形结构，使用简单但非常有效的生成式建模方法生成3D网格。具体来说，我们使用可变形四面体网格来表示网格，然后在这个直接参数化的网格上训练扩散模型。

    We consider the task of generating realistic 3D shapes, which is useful for a variety of applications such as automatic scene generation and physical simulation. Compared to other 3D representations like voxels and point clouds, meshes are more desirable in practice, because (1) they enable easy and arbitrary manipulation of shapes for relighting and simulation, and (2) they can fully leverage the power of modern graphics pipelines which are mostly optimized for meshes. Previous scalable methods for generating meshes typically rely on sub-optimal post-processing, and they tend to produce overly-smooth or noisy surfaces without fine-grained geometric details. To overcome these shortcomings, we take advantage of the graph structure of meshes and use a simple yet very effective generative modeling method to generate 3D meshes. Specifically, we represent meshes with deformable tetrahedral grids, and then train a diffusion model on this direct parametrization. We demonstrate the effectivene
    
[^3]: PiMAE: 点云和图像交互掩模自编码器用于三维物体检测

    PiMAE: Point Cloud and Image Interactive Masked Autoencoders for 3D Object Detection. (arXiv:2303.08129v1 [cs.CV])

    [http://arxiv.org/abs/2303.08129](http://arxiv.org/abs/2303.08129)

    本研究提出了PiMAE框架，通过三个方面促进点云和RGB图像的交互，包括利用投影模块互补地对齐两种模态的掩蔽和可见令牌、利用两个支路的MAE管道和共享解码器促进掩蔽令牌中的跨模态交互和设计了跨模态重构模块以增强表示学习。

    

    掩模自编码器在多个不同模态的独立设置中学习强的视觉表征，在多模态设置中的能力尚未得到充分利用。本研究关注点云和RGB图像数据，这两种模态常常在现实中同时呈现，并探索其有意义的交互作用。为了改进现有工作中跨模态协同作用，我们提出了PiMAE，这是一个自我监督预训练框架，通过三个方面促进三维和二维的交互。具体而言，我们首先注意到两个源之间掩蔽策略的重要性，并利用投影模块来互补地对齐两种模态的掩蔽和可见令牌。然后，我们利用一个精心设计的两个支路的MAE管道和一个新型的共享解码器来促进掩蔽令牌中的跨模态交互。最后，我们设计了一个独特的跨模态重构模块，以增强表示学习。

    Masked Autoencoders learn strong visual representations and achieve state-of-the-art results in several independent modalities, yet very few works have addressed their capabilities in multi-modality settings. In this work, we focus on point cloud and RGB image data, two modalities that are often presented together in the real world, and explore their meaningful interactions. To improve upon the cross-modal synergy in existing works, we propose PiMAE, a self-supervised pre-training framework that promotes 3D and 2D interaction through three aspects. Specifically, we first notice the importance of masking strategies between the two sources and utilize a projection module to complementarily align the mask and visible tokens of the two modalities. Then, we utilize a well-crafted two-branch MAE pipeline with a novel shared decoder to promote cross-modality interaction in the mask tokens. Finally, we design a unique cross-modal reconstruction module to enhance representation learning for bot
    
[^4]: CB2：合作自然语言交互研究平台

    CB2: Collaborative Natural Language Interaction Research Platform. (arXiv:2303.08127v1 [cs.LG])

    [http://arxiv.org/abs/2303.08127](http://arxiv.org/abs/2303.08127)

    CB2是一个用于研究基于任务的合作自然语言交互的平台，在3D游戏环境中提供了后端服务器和各种工具和流程。它在可扩展的研究中展示了学习的指令跟随模型。

    

    CB2 是一个多智能体平台，用于研究基于任务的情境下的合作自然语言交互。它包括一个 3D 游戏环境、一个后端服务器，可为人类智能体提供训练模型，以及各种工具和流程，以实现可扩展性的研究。我们在 https://cb2.ai 上展示了一个具有学习指令跟随模型的系统演示。

    CB2 is a multi-agent platform to study collaborative natural language interaction in a grounded task-oriented scenario. It includes a 3D game environment, a backend server designed to serve trained models to human agents, and various tools and processes to enable scalable studies. We deploy CB2 at https://cb2.ai as a system demonstration with a learned instruction following model.
    
[^5]: 一人独舞好还是人多闹心？不同演示次数下的上下文训练

    It Takes One to Tango but More Make Trouble? In-Context Training with Different Number of Demonstrations. (arXiv:2303.08119v1 [cs.AI])

    [http://arxiv.org/abs/2303.08119](http://arxiv.org/abs/2303.08119)

    本文研究了使用较少的演示数进行上下文学习（ICL）的任务，在测试查询上只使用一个随机选择的演示时并没有明显性能下降，而只使用一个正确演示的ICL在性能上显著优于全演示ICL。

    

    大型语言模型在提供了一些输入输出演示（demos）并给出更多演示的中间推理步骤（“思路链（CoT）”）时，能够通过上下文学习（ICL）进行复杂推理。本文研究了在每个测试查询上使用较少的演示来进行ICL的任务~\cite{wei2022chain}。惊人地，当只使用一个随机选择的演示时，我们并没有观察到明显的性能下降。为了研究这种现象，对于每个测试查询，我们将演示分类为“正确演示”和“错误演示”。我们的分析揭示了这些广泛研究的数据集中存在的固有偏差：大多数测试查询的大多数演示都是正确的，这解释了使用一个随机演示时表现良好的原因。此外，只使用一个正确演示的ICL（带和不带CoT）在性能上显著优于大多数先前工作采用的全演示ICL，表明演示数量并不总是更好。

    Large language models (LLMs) are capable to perform complex reasoning by in-context learning (ICL) when provided with a few input-output demonstrations (demos) and more powerful when intermediate reasoning steps ("chain of thoughts (CoT)") of the demos are given. Is it necessary to use multi-demo in ICL? In this paper, we study ICL using fewer demos for each test query on the tasks in~\cite{wei2022chain}. Surprisingly, we do not observe significant degradation when using only one randomly chosen demo. To study this phenomenon, for each test query, we categorize demos into "correct demos" leading to the correct answer, and "wrong demos" resulting in wrong answers. Our analysis reveals an inherent bias in those widely studied datasets: most demos are correct for a majority of test queries, which explains the good performance of using one random demo. Moreover, ICL (with and w/o CoT) using only one correct demo significantly outperforms all-demo ICL adopted by most previous works, indicat
    
[^6]: 机器学习模型中的领域通用性在无线通信中的应用：概念，现状和开放问题

    Domain Generalization in Machine Learning Models for Wireless Communications: Concepts, State-of-the-Art, and Open Issues. (arXiv:2303.08106v1 [cs.LG])

    [http://arxiv.org/abs/2303.08106](http://arxiv.org/abs/2303.08106)

    本论文探讨了机器学习在无线通信中应用的重要性，特别是领域通用性方面的问题。研究表明，对于出现在不同领域中的数据，模型的准确性受到很大影响，领域通用性技术可以通过从不同的源域中学习模型并适应新的领域来解决这个问题。

    

    数据驱动的机器学习（ML）被认为是下一代无线系统中应用的一种潜在技术。这导致了大量研究工作，应用ML技术解决无线传输链的不同层次的问题。然而，大多数这些应用都依赖于有监督学习，其假定源（训练）和目标（测试）数据独立且随机分布相同（i.i.d.）。这个假设在现实世界中经常被违反，因为源数据和目标数据之间存在领域或分布转移。因此，确保这些算法能够推广到超出分布范围的数据非常重要。在这种情况下，领域通用性（DG）通过在不同和独特的源域/数据集上学习模型来解决OOD相关问题，并具有适应未见过的新领域的泛化能力，而不需要额外的微调。受到对无线应用中DG需求的重视，我们提出了一份全面的综述，介绍了在机器学习领域通用性的概念和其在无线通信中的最新发展，同时讨论了未来的研究方向。

    Data-driven machine learning (ML) is promoted as one potential technology to be used in next-generations wireless systems. This led to a large body of research work that applies ML techniques to solve problems in different layers of the wireless transmission link. However, most of these applications rely on supervised learning which assumes that the source (training) and target (test) data are independent and identically distributed (i.i.d). This assumption is often violated in the real world due to domain or distribution shifts between the source and the target data. Thus, it is important to ensure that these algorithms generalize to out-of-distribution (OOD) data. In this context, domain generalization (DG) tackles the OOD-related issues by learning models on different and distinct source domains/datasets with generalization capabilities to unseen new domains without additional finetuning. Motivated by the importance of DG requirements for wireless applications, we present a comprehe
    
[^7]: 机器人辅助踝骨骨折修复的图像引导技术研究

    Image Guidance for Robot-Assisted Ankle Fracture Repair. (arXiv:2303.08105v1 [eess.IV])

    [http://arxiv.org/abs/2303.08105](http://arxiv.org/abs/2303.08105)

    该研究旨在开发和验证一种图像引导框架，使机器人能够自动确定腓骨复位方向，进而提高骨折手术的效率和准确性，改善患者的手术效果，降低患者发生骨性关节炎的风险。

    

    本项目涉及开发和验证一种适用于机器人辅助腓骨复位的图像引导框架，并旨在产生和证明自动确定腓骨复位方向的软件的正确功能，最终目标是应用于机器人减压程序，从而减少手术时间和复杂性，同时提供理想的最终腓骨位置误差减小、韧带结构恢复得到改善以及创伤后骨性关节炎发生率降低的益处。

    This project concerns developing and validating an image guidance framework for application to a robotic-assisted fibular reduction in ankle fracture surgery. The aim is to produce and demonstrate proper functioning of software for automatic determination of directions for fibular repositioning with the ultimate goal of application to a robotic reduction procedure that can reduce the time and complexity of the procedure as well as provide the benefits of reduced error in ideal final fibular position, improved syndesmosis restoration and reduced incidence of post-traumatic osteoarthritis. The focus of this product will be developing and testing the image guidance software, from the input of preoperative images through the steps of automated segmentation and registration until the output of a final transformation that can be used as instructions to a robot on how to reposition the fibula, but will not involve developing or implementing the hardware of the robot itself.
    
[^8]: 维多利亚亚马逊优化（VAO）:受巨型睡莲植物启示的算法

    Victoria Amazonica Optimization (VAO): An Algorithm Inspired by the Giant Water Lily Plant. (arXiv:2303.08070v1 [cs.NE])

    [http://arxiv.org/abs/2303.08070](http://arxiv.org/abs/2303.08070)

    基于维多利亚亚马逊植物的特点，提出一种维多利亚亚马逊优化（VAO）算法，该算法适用于占领更多表面空间的问题，并可用于优化问题的求解。

    

    维多利亚亚马逊植物，通常称为巨型睡莲，拥有世界上直径最大的漂浮球形叶片，最大直径可达3米。它通过刺的力量展开叶子，在其下面形成大片阴影，扼杀需要阳光的任何植物。这些水中霸主用它们强大的刺迫使彼此升至水面并增强它们占据水面的能力。随着它们在池塘或盆地中的扩散，早期生长的叶子有更多的生长空间，每片叶子都获得了一个独特的大小。它的花是隐蔽雄性的，当它们开放时，Cyclocephala甲虫负责授粉过程，被女花的气味所吸引。甲虫进入花后，被花粉覆盖，将其转移到另一朵花上进行受精。甲虫离开后，花变成了雄花，颜色从白色变成了粉色。雄花死亡并沉入水中。

    The Victoria Amazonica plant, often known as the Giant Water Lily, has the largest floating spherical leaf in the world, with a maximum leaf diameter of 3 meters. It spreads its leaves by the force of its spines and creates a large shadow underneath, killing any plants that require sunlight. These water tyrants use their formidable spines to compel each other to the surface and increase their strength to grab more space from the surface. As they spread throughout the pond or basin, with the earliest-growing leaves having more room to grow, each leaf gains a unique size. Its flowers are transsexual and when they bloom, Cyclocephala beetles are responsible for the pollination process, being attracted to the scent of the female flower. After entering the flower, the beetle becomes covered with pollen and transfers it to another flower for fertilization. After the beetle leaves, the flower turns into a male and changes color from white to pink. The male flower dies and sinks into the water
    
[^9]: 基于事件感知的生成对抗网络和自监督关系推理的超高分辨率探测器模拟

    Ultra-High-Resolution Detector Simulation with Intra-Event Aware GAN and Self-Supervised Relational Reasoning. (arXiv:2303.08046v1 [physics.ins-det])

    [http://arxiv.org/abs/2303.08046](http://arxiv.org/abs/2303.08046)

    本文提出了一种新颖的探测器模拟方法IEA-GAN，通过产生与图层相关的上下文化的图像，提高了超高分辨率探测器响应的相关性和多样性。同时，引入新的事件感知损失和统一性损失，显著提高了图像的保真度和多样性。

    

    在粒子物理学中，模拟高分辨率探测器响应一直是一个存储成本高、计算密集的过程。尽管深度生成模型可以使这个过程更具成本效益，但超高分辨率探测器模拟仍然很困难，因为它包含了事件内相关和细粒度的相互信息。为了克服这些限制，我们提出了一种新颖的生成对抗网络方法（IEA-GAN），融合了自监督学习和关系推理模型。IEA-GAN提出了一个关系推理模块，近似于探测器模拟中“事件”的概念，可以生成与图层相关的上下文化的图像，提高了超高分辨率探测器响应的相关性和多样性。IEA-GAN还引入了新的事件感知损失和统一性损失，显著提高了图像的保真度和多样性。我们展示了IEA-GAN的应用。

    Simulating high-resolution detector responses is a storage-costly and computationally intensive process that has long been challenging in particle physics. Despite the ability of deep generative models to make this process more cost-efficient, ultra-high-resolution detector simulation still proves to be difficult as it contains correlated and fine-grained mutual information within an event. To overcome these limitations, we propose Intra-Event Aware GAN (IEA-GAN), a novel fusion of Self-Supervised Learning and Generative Adversarial Networks. IEA-GAN presents a Relational Reasoning Module that approximates the concept of an ''event'' in detector simulation, allowing for the generation of correlated layer-dependent contextualized images for high-resolution detector responses with a proper relational inductive bias. IEA-GAN also introduces a new intra-event aware loss and a Uniformity loss, resulting in significant enhancements to image fidelity and diversity. We demonstrate IEA-GAN's ap
    
[^10]: 进展笔记理解-评估和计划推理：2022 N2C2Track 3共享任务概述

    Progress Note Understanding -- Assessment and Plan Reasoning: Overview of the 2022 N2C2 Track 3 Shared Task. (arXiv:2303.08038v1 [cs.AI])

    [http://arxiv.org/abs/2303.08038](http://arxiv.org/abs/2303.08038)

    该论文介绍了2022 N2C2临床挑战赛中关于进展笔记理解-评估和计划推理的任务，旨在开发并评估自动预测因果相关概念的NLP系统。

    

    每日进展笔记是电子健康记录（EHR）中常见的类型，医疗保健提供者在其中记录患者的每日进展和治疗计划。 EHR旨在记录为患者提供的所有护理，但它也会使笔记膨胀并包含分散诊断和治疗计划的多余信息。 在EHR中应用自然语言处理（NLP）是一个不断增长的领域，其中大部分方法都用于信息提取。很少有任务使用NLP方法进行下游诊断决策支持。我们介绍了2022年国家自然语言处理临床挑战赛（N2C2）Track 3：进展笔记理解-评估和计划推理，作为新一套任务的一步。 评估和计划推理任务侧重于进展笔记的最关键组成部分，即包含健康问题和诊断的评估和计划子部分。 该任务的目标是开发并评估自动预测评估和计划推理中因果相关概念的NLP系统。

    Daily progress notes are common types in the electronic health record (EHR) where healthcare providers document the patient's daily progress and treatment plans. The EHR is designed to document all the care provided to patients, but it also enables note bloat with extraneous information that distracts from the diagnoses and treatment plans. Applications of natural language processing (NLP) in the EHR is a growing field with the majority of methods in information extraction. Few tasks use NLP methods for downstream diagnostic decision support. We introduced the 2022 National NLP Clinical Challenge (N2C2) Track 3: Progress Note Understanding - Assessment and Plan Reasoning as one step towards a new suite of tasks. The Assessment and Plan Reasoning task focuses on the most critical components of progress notes, Assessment and Plan subsections where health problems and diagnoses are contained. The goal of the task was to develop and evaluate NLP systems that automatically predict causal re
    
[^11]: ISimDL: 通过重要性采样驱动的故障注入模拟，加速深度学习强健性评估

    ISimDL: Importance Sampling-Driven Acceleration of Fault Injection Simulations for Evaluating the Robustness of Deep Learning. (arXiv:2303.08035v1 [cs.LG])

    [http://arxiv.org/abs/2303.08035](http://arxiv.org/abs/2303.08035)

    本论文提出了一种新方法ISimDL，利用神经元灵敏度生成重要性采样，加速故障注入模拟，有效评估了先进的DL系统对硬件故障的韧性，同时显著减少了所需的模拟数量。

    

    深度学习(DL)系统已在许多应用中广泛应用，需要专用的硬件加速器和芯片。在纳米时代，设备越来越容易受到永久性和瞬变故障的影响。因此，我们需要一种有效的方法来分析先进的DL系统对此类故障的韧性，并了解神经加速器芯片中的故障如何在DL应用级别上表现为错误，其中故障可能导致无法检测和恢复的错误。使用故障注入，我们可以通过在软件级别修改神经元权重和输出来执行DL系统的韧性研究，就好像硬件受到瞬变故障的影响一样。现有的故障模型减少了搜索空间，使分析更快，但需要该模型的先验知识，并且不允许进一步分析筛选出的搜索空间。因此，我们提出了ISimDL，一种新的方法，它利用神经元灵敏度生成重要性采样，并加速故障注入模拟。ISimDL可以有效评估先进的DL系统对硬件故障的韧性，而不会影响分析的准确性。所提出的方法显着减少了故障注入分析所需的模拟数量，同时仍确保足够覆盖搜索空间。我们将ISimDL应用于代表性的卷积神经网络，使用CIFAR-10和ImageNet数据集，并展示它提供显著的加速，同时仍保持与现有最先进故障注入方法相同的准确性水平。

    Deep Learning (DL) systems have proliferated in many applications, requiring specialized hardware accelerators and chips. In the nano-era, devices have become increasingly more susceptible to permanent and transient faults. Therefore, we need an efficient methodology for analyzing the resilience of advanced DL systems against such faults, and understand how the faults in neural accelerator chips manifest as errors at the DL application level, where faults can lead to undetectable and unrecoverable errors. Using fault injection, we can perform resilience investigations of the DL system by modifying neuron weights and outputs at the software-level, as if the hardware had been affected by a transient fault. Existing fault models reduce the search space, allowing faster analysis, but requiring a-priori knowledge on the model, and not allowing further analysis of the filtered-out search space. Therefore, we propose ISimDL, a novel methodology that employs neuron sensitivity to generate impo
    
[^12]: 深度说话人识别中的偏见与公平性研究

    A Study on Bias and Fairness In Deep Speaker Recognition. (arXiv:2303.08026v1 [cs.SD])

    [http://arxiv.org/abs/2303.08026](http://arxiv.org/abs/2303.08026)

    本论文研究深度说话人识别中的偏见和公平性。研究发现，更复杂的编码器结构更符合公平定义。此外，损失函数的选择对SR模型的偏差有显着影响。

    

    随着使用说话人识别（SR）系统作为认证个人和个性化服务方式的智能设备的普及，SR系统的公平性成为一个重要的焦点。本文研究基于三个流行和相关定义（即统计平等、均衡赔率和平等机会）的最新SR系统中的公平性概念。我们检查了5种流行的神经架构和5种常用的丢失功能来训练SR系统，并评估它们相对于性别和国籍组别的公平性。我们的详细实验阐明了这个概念，并证明了更复杂的编码器体系结构更符合公平的定义。此外，我们发现损失函数的选择可以显着影响SR模型的偏差。

    With the ubiquity of smart devices that use speaker recognition (SR) systems as a means of authenticating individuals and personalizing their services, fairness of SR systems has becomes an important point of focus. In this paper we study the notion of fairness in recent SR systems based on 3 popular and relevant definitions, namely Statistical Parity, Equalized Odds, and Equal Opportunity. We examine 5 popular neural architectures and 5 commonly used loss functions in training SR systems, while evaluating their fairness against gender and nationality groups. Our detailed experiments shed light on this concept and demonstrate that more sophisticated encoder architectures better align with the definitions of fairness. Additionally, we find that the choice of loss functions can significantly impact the bias of SR models.
    
[^13]: 用蜜蜂算法优化深度学习模型参数，提高医学文本分类准确性

    Optimizing Deep Learning Model Parameters with the Bees Algorithm for Improved Medical Text Classification. (arXiv:2303.08021v1 [cs.CL])

    [http://arxiv.org/abs/2303.08021](http://arxiv.org/abs/2303.08021)

    本文使用蜜蜂算法优化了深度学习模型参数，提高了医学文本分类的准确性，最高准确率在英语数据集上达到了99.63%，在阿拉伯语数据集上达到了88%。

    

    本文介绍了一种使用蜜蜂算法对深度学习模型进行参数优化的新机制，这是一种最近很有前途的群智能算法。优化问题是在给定初始超参数的情况下，通过确定的迭代次数来最大化基于医学文本分类疾病的准确性。实验包括两个不同的数据集：英语和阿拉伯语。使用长短期记忆 (LSTM) 和蜜蜂算法，在英语数据集上获得了99.63%的最高准确率，在阿拉伯语数据集上使用AraBERT获得了88%的最高准确率。

    This paper introduces a novel mechanism to obtain the optimal parameters of a deep learning model using the Bees Algorithm, which is a recent promising swarm intelligence algorithm. The optimization problem is to maximize the accuracy of classifying ailments based on medical text given the initial hyper-parameters to be adjusted throughout a definite number of iterations. Experiments included two different datasets: English and Arabic. The highest accuracy achieved is 99.63% on the English dataset using Long Short-Term Memory (LSTM) along with the Bees Algorithm, and 88% on the Arabic dataset using AraBERT.
    
[^14]: 基于窗口的早期退出级联用于不确定性估计：当深度集成比单一模型更有效时

    Window-Based Early-Exit Cascades for Uncertainty Estimation: When Deep Ensembles are More Efficient than Single Models. (arXiv:2303.08010v1 [cs.LG])

    [http://arxiv.org/abs/2303.08010](http://arxiv.org/abs/2303.08010)

    本文研究了基于窗口的早期退出集成方法，以在保持模型可扩展性的同时实现不确定性估计任务的高效实现。实验结果表明，该方法在准确性和计算效率上都达到了最新的研究成果。

    

    深度集成是提高深度学习方法预测性能和不确定性估计的简单、可靠和有效方法。然而，由于需要部署多个独立模型，它们被广泛批评为计算开销大。最近的研究挑战了这种观点，表明对于预测准确性，集成可以比在同一架构族中缩放单一模型在推理时更具计算效率。通过通过早期退出方法级联集成成员实现这一目标。在这项工作中，我们研究如何将这些效率提高扩展到与不确定性估计相关的任务。由于许多这样的任务，例如选择性分类，都是二分类问题，我们的关键新颖见解是仅将接近二分决策边界的样本传递到后续级联阶段。在ImageNet规模的数据上进行的实验表明，所提出的基于窗口的早期退出集成在使用比基线更少的模型评估的同时，实现了最先进的不确定性估计性能，并且在预测性能上与完整集成相竞争。

    Deep Ensembles are a simple, reliable, and effective method of improving both the predictive performance and uncertainty estimates of deep learning approaches. However, they are widely criticised as being computationally expensive, due to the need to deploy multiple independent models. Recent work has challenged this view, showing that for predictive accuracy, ensembles can be more computationally efficient (at inference) than scaling single models within an architecture family. This is achieved by cascading ensemble members via an early-exit approach. In this work, we investigate extending these efficiency gains to tasks related to uncertainty estimation. As many such tasks, e.g. selective classification, are binary classification, our key novel insight is to only pass samples within a window close to the binary decision boundary to later cascade stages. Experiments on ImageNet-scale data across a number of network architectures and uncertainty tasks show that the proposed window-base
    
[^15]: 驾驶支持的连续风险度量

    Continuous Risk Measures for Driving Support. (arXiv:2303.08007v1 [cs.RO])

    [http://arxiv.org/abs/2303.08007](http://arxiv.org/abs/2303.08007)

    本文通过比较三种不同的基于模型的风险度量方法并在真实情景下测试，提出了基于稀疏关键事件和生存条件的一种新风险度量方法，该方法具有较早的碰撞检测时间和较少的误报检测，适用于ADAS和AD验证。

    

    本文评估了三种不同的基于模型的风险度量，比较它们的优劣，并在一组真实的纵向和交叉场景中进行了定量测试。我们从传统的启发式时间相遇（TTC）开始，将其扩展到2D操作和非碰撞情况，以恢复最接近遭遇时间（TTCE）。第二个风险度量使用高斯分布建模位置不确定性，并使用空间占用概率来计算碰撞风险。然后，我们基于稀疏关键事件和所谓的生存条件提出了一种新的风险度量。导致的生存分析显示在碰撞的早期检测时间和在近碰撞和非碰撞情况下较少的误报检测方面具有较早的检测时间，并得到其坚实理论基础支持。它可以被看作是TTCE和适用于ADAS和AD验证的高斯方法的概括。

    In this paper, we compare three different model-based risk measures by evaluating their stengths and weaknesses qualitatively and testing them quantitatively on a set of real longitudinal and intersection scenarios. We start with the traditional heuristic Time-To-Collision (TTC), which we extend towards 2D operation and non-crash cases to retrieve the Time-To-Closest-Encounter (TTCE). The second risk measure models position uncertainty with a Gaussian distribution and uses spatial occupancy probabilities for collision risks. We then derive a novel risk measure based on the statistics of sparse critical events and so-called survival conditions. The resulting survival analysis shows to have an earlier detection time of crashes and less false positive detections in near-crash and non-crash cases supported by its solid theoretical grounding. It can be seen as a generalization of TTCE and the Gaussian method which is suitable for the validation of ADAS and AD.
    
[^16]: 多智能体注意力Actor-Critic算法用于蜂窝网络的负载均衡问题

    Multi-agent Attention Actor-Critic Algorithm for Load Balancing in Cellular Networks. (arXiv:2303.08003v1 [cs.AI])

    [http://arxiv.org/abs/2303.08003](http://arxiv.org/abs/2303.08003)

    该论文提出了一种Robust Multi-agent Attention Actor-Critic算法，可以促进基站之间的协作，以解决蜂窝网络中的负载均衡问题，并通过模拟评估表明了显著的性能提升。

    

    在蜂窝网络中，用户设备（UE）从一个基站（BS）切换到另一个基站，导致了基站之间负载均衡的问题。为了解决这个问题，基站可以合作，以实现平稳的迁移（或切换）并满足用户设备的服务要求。该论文将负载均衡问题作为马尔科夫博弈，并提出了一种Robust Multi-agent Attention Actor-Critic（Robust-MA3C）算法，可以促进基站（即代理）之间的协作。为了解决马尔科夫博弈并找到纳什均衡策略，我们采用了一个自然智能体来模拟系统的不确定性。此外，我们利用自我注意机制，鼓励高性能基站帮助低性能基站。另外，我们考虑了两种方案，可以为活跃的UE和空闲的UE提供负载平衡。我们通过模拟进行了广泛的评估，模拟结果表明，与状态-of-the-art算法相比，Robust-MA3C算法在负载均衡、服务质量和运行效率方面取得了显著的性能提升。

    In cellular networks, User Equipment (UE) handoff from one Base Station (BS) to another, giving rise to the load balancing problem among the BSs. To address this problem, BSs can work collaboratively to deliver a smooth migration (or handoff) and satisfy the UEs' service requirements. This paper formulates the load balancing problem as a Markov game and proposes a Robust Multi-agent Attention Actor-Critic (Robust-MA3C) algorithm that can facilitate collaboration among the BSs (i.e., agents). In particular, to solve the Markov game and find a Nash equilibrium policy, we embrace the idea of adopting a nature agent to model the system uncertainty. Moreover, we utilize the self-attention mechanism, which encourages high-performance BSs to assist low-performance BSs. In addition, we consider two types of schemes, which can facilitate load balancing for both active UEs and idle UEs. We carry out extensive evaluations by simulations, and simulation results illustrate that, compared to the sta
    
[^17]: FingerSLAM: 利用视触反馈进行未知物体定位和重构的闭环方法

    FingerSLAM: Closed-loop Unknown Object Localization and Reconstruction from Visuo-tactile Feedback. (arXiv:2303.07997v1 [cs.RO])

    [http://arxiv.org/abs/2303.07997](http://arxiv.org/abs/2303.07997)

    本论文提出了一种利用视触反馈进行未知物体定位和重构的闭环方法FingerSLAM，通过局部和全局的双重姿态估计器，以及闭环机制结合触觉和视觉的两种感知模式，实现了姿态估计的优化，并比单一模态的解决方案更加精确。

    

    本文针对利用视触反馈进行未知物体的6自由度定位和三维重构的问题，提出了一种名为FingerSLAM的基于因子图的闭环姿态估计器。FingerSLAM结合了手指顶端的局部触觉传感和手腕处全局视觉传感，由两个姿态估计器构成：多通道的精细触觉姿态估计器和单通道的视觉姿态估计器。同时，我们设计了一个闭环机制，主动匹配当前视觉与触觉图像与先前存储的关键帧，以减少累积误差。 FingerSLAM将触觉和视觉两种感知模式以及闭环机制纳入基于因子图优化框架的方案中。这种方案能够产生比单一模态解决方案更精确的优化姿态估计解决方案。

    In this paper, we address the problem of using visuo-tactile feedback for 6-DoF localization and 3D reconstruction of unknown in-hand objects. We propose FingerSLAM, a closed-loop factor graph-based pose estimator that combines local tactile sensing at finger-tip and global vision sensing from a wrist-mount camera. FingerSLAM is constructed with two constituent pose estimators: a multi-pass refined tactile-based pose estimator that captures movements from detailed local textures, and a single-pass vision-based pose estimator that predicts from a global view of the object. We also design a loop closure mechanism that actively matches current vision and tactile images to previously stored key-frames to reduce accumulated error. FingerSLAM incorporates the two sensing modalities of tactile and vision, as well as the loop closure mechanism with a factor graph-based optimization framework. Such a framework produces an optimized pose estimation solution that is more accurate than the standal
    
[^18]: Instagram社交网络帖子自动摘要：结合语义和统计方法

    Automatic summarisation of Instagram social network posts Combining semantic and statistical approaches. (arXiv:2303.07957v1 [cs.AI])

    [http://arxiv.org/abs/2303.07957](http://arxiv.org/abs/2303.07957)

    本论文提出了一种结合语义和统计方法的混合自动摘要方法，用于Instagram社交网络帖子，实验结果表明其优于传统的抽取式和生成式方法。

    

    互联网上的数据和文本文件的激增，例如文章、网页、书籍、社交网络帖子等，为文本处理的各个领域带来了自动文本摘要的重要挑战。手动处理和摘要大量的文本数据对人类用户来说是非常困难、昂贵、耗时和不可能的过程。文本摘要系统分为抽取式和生成式两类。本论文提出了一种混合方法，结合语义和统计方法来自动摘要Instagram社交网络帖子。所提出的系统基于语义相似度和统计重要性来提取重要的句子。对Instagram帖子数据集进行的实验表明，所提出的方法优于传统的抽取式和生成式文本摘要方法。

    The proliferation of data and text documents such as articles, web pages, books, social network posts, etc. on the Internet has created a fundamental challenge in various fields of text processing under the title of "automatic text summarisation". Manual processing and summarisation of large volumes of textual data is a very difficult, expensive, time-consuming and impossible process for human users. Text summarisation systems are divided into extractive and abstract categories. In the extractive summarisation method, the final summary of a text document is extracted from the important sentences of the same document without any modification. In this method, it is possible to repeat a series of sentences and to interfere with pronouns. However, in the abstract summarisation method, the final summary of a textual document is extracted from the meaning and significance of the sentences and words of the same document or other documents. Many of the works carried out have used extraction me
    
[^19]: 关于产业人工智能中概念漂移和不确定性的联系

    On the Connection between Concept Drift and Uncertainty in Industrial Artificial Intelligence. (arXiv:2303.07940v1 [cs.LG])

    [http://arxiv.org/abs/2303.07940](http://arxiv.org/abs/2303.07940)

    本文探索了工业人工智能中概念漂移和不确定性之间的联系，提出了一种方法来估计模型预测的置信度，并且证明了这种方法可以有效地在无监督的情况下检测概念漂移，从而提高模型的整体性能。

    

    基于人工智能的数字孪生是工业4.0革命的前沿，其技术由物联网和实时数据分析提供支持。从工业资产中收集的信息以持续的方式产生，产生的数据流必须在严格的时间限制下进行处理。这样的数据流通常会受到非平稳现象的影响，导致数据流的数据分布可能发生变化，因此用于数据分析的模型捕获的知识可能会变得过时（导致所谓的概念漂移效应）。及早发现（漂移）的变化对于更新模型的知识至关重要，在场景中特别具有挑战性，其中与流数据相关联的基本真相不容易找到。本文的目标是探讨产业人工智能中概念漂移和不确定性之间的联系。我们提出了一种方法来估计模型预测的置信度，并展示了如何在无监督的情况下使用它来检测概念漂移。我们的结果表明，所提出的方法可以有效地检测概念漂移，并可以提高模型的整体性能。

    AI-based digital twins are at the leading edge of the Industry 4.0 revolution, which are technologically empowered by the Internet of Things and real-time data analysis. Information collected from industrial assets is produced in a continuous fashion, yielding data streams that must be processed under stringent timing constraints. Such data streams are usually subject to non-stationary phenomena, causing that the data distribution of the streams may change, and thus the knowledge captured by models used for data analysis may become obsolete (leading to the so-called concept drift effect). The early detection of the change (drift) is crucial for updating the model's knowledge, which is challenging especially in scenarios where the ground truth associated to the stream data is not readily available. Among many other techniques, the estimation of the model's confidence has been timidly suggested in a few studies as a criterion for detecting drifts in unsupervised settings. The goal of thi
    
[^20]: 生成AI中的文本到图像扩散模型：一项调查

    Text-to-image Diffusion Model in Generative AI: A Survey. (arXiv:2303.07909v1 [cs.CV])

    [http://arxiv.org/abs/2303.07909](http://arxiv.org/abs/2303.07909)

    本文调查了文本到图像扩散模型以及相关应用，总结了最先进的方法，并探讨了挑战和未来方向。

    

    本文调查了文本到图像扩散模型，这些模型已经成为多种生成任务中流行的模型。作为一个自包含的工作，本调查从简单介绍基本扩散模型如何用于图像合成开始，接着是条件或引导如何改进学习。我们还总结了文本条件下的最先进的图像合成方法，并且进一步总结了文本引导创意生成和图像编辑的应用。除了迄今为止所取得的进展，我们还讨论了现有挑战和有前途的未来方向。

    This survey reviews text-to-image diffusion models in the context that diffusion models have emerged to be popular for a wide range of generative tasks. As a self-contained work, this survey starts with a brief introduction of how a basic diffusion model works for image synthesis, followed by how condition or guidance improves learning. Based on that, we present a review of state-of-the-art methods on text-conditioned image synthesis, i.e., text-to-image. We further summarize applications beyond text-to-image generation: text-guided creative generation and text-guided image editing. Beyond the progress made so far, we discuss existing challenges and promising future directions.
    
[^21]: 对称环境下的物体定位多粒子卡尔曼滤波器研究

    Multiparticle Kalman filter for object localization in symmetric environments. (arXiv:2303.07897v1 [cs.RO])

    [http://arxiv.org/abs/2303.07897](http://arxiv.org/abs/2303.07897)

    本研究提出了一种新的多粒子卡尔曼滤波器，可解决对称复杂环境下的物体定位问题，并在实验中表现出优于粒子滤波的性能。

    

    本研究考虑了物体定位问题，并提出了一种新的多粒子卡尔曼滤波器来解决复杂对称环境中的问题。我们考虑了卡尔曼滤波器类和粒子滤波器类两种解决定位问题的滤波器算法，并提出了一种新的滤波算法，融合了两种方法的优点。在对称且有噪声的环境中评估了多粒子卡尔曼滤波器，这些环境对于两种经典方法都具有挑战性。我们将所提出的方法与粒子滤波进行了比较，由于只有此方法适用于未知初始状态，因此我们只考虑了这种方法。在考虑了如此挑战性的环境后，我们的方法在定位误差和运行时间方面均优于粒子滤波器。

    This study considers the object localization problem and proposes a novel multiparticle Kalman filter to solve it in complex and symmetric environments. Two well-known classes of filtering algorithms to solve the localization problem are Kalman filter-based methods and particle filter-based methods. We consider these classes, demonstrate their complementary properties, and propose a novel filtering algorithm that takes the best from two classes. We evaluate the multiparticle Kalman filter in symmetric and noisy environments. Such environments are especially challenging for both classes of classical methods. We compare the proposed approach with the particle filter since only this method is feasible if the initial state is unknown. In the considered challenging environments, our method outperforms the particle filter in terms of both localization error and runtime.
    
[^22]: 基于BERT模型的推文地理位置预测

    Geolocation Predicting of Tweets Using BERT-Based Models. (arXiv:2303.07865v1 [cs.CL])

    [http://arxiv.org/abs/2303.07865](http://arxiv.org/abs/2303.07865)

    该论文提出基于BERT模型的推文地理位置预测方法，可以实现全球和美国上的中位误差分别小于30公里和15公里的定位精度。

    

    该研究旨在解决推文/用户地理位置预测任务，并提供了处理文本大数据地理标记的灵活方法。该方法采用基于神经网络的自然语言处理来估计坐标对（经度，纬度）和二维高斯混合模型（GMM）。提出的模型的范围已经在Twitter数据集上使用预训练的BERT模型进行调整。性能指标表明，对于在推文内容和元数据上训练和评估的模型，全球范围内的中位误差小于30公里，美国范围内的中位误差小于15公里。

    This research is aimed to solve the tweet/user geolocation prediction task and provide a flexible methodology for the geotagging of textual big data. The suggested approach implements neural networks for natural language processing (NLP) to estimate the location as coordinate pairs (longitude, latitude) and two-dimensional Gaussian Mixture Models (GMMs). The scope of proposed models has been finetuned on a Twitter dataset using pretrained Bidirectional Encoder Representations from Transformers (BERT) as base models. Performance metrics show a median error of fewer than 30 km on a worldwide-level, and fewer than 15 km on the US-level datasets for the models trained and evaluated on text features of tweets' content and metadata context.
    
[^23]: 一种针对压缩视频的时间句子对齐的有效和高效管道

    You Can Ground Earlier than See: An Effective and Efficient Pipeline for Temporal Sentence Grounding in Compressed Videos. (arXiv:2303.07863v1 [cs.CV])

    [http://arxiv.org/abs/2303.07863](http://arxiv.org/abs/2303.07863)

    本文提出了一种新的压缩域TSG设置，通过直接编码压缩位流来增强视觉特征表示能力和提高时间句子对齐的效率，并且在两个基准数据集的实验中表现优于目前最先进的方法。

    

    时间句子对齐旨在根据句子查询通过语义定位目标瞬间。在本文中，我们提出了一种新的压缩域TSG（Temporal Sentence Grounding）设置，直接使用压缩视频作为视觉输入。针对原始视频比特流输入，我们提出了一种新型三支路压缩空间时间融合框架（TCSF），用于有效且高效地定位。我们通过利用压缩伪影来增强视觉特征的表示能力，提出了一种直接编码压缩位流的方法，而不是先解码整个帧的方法。在两个基准数据集上的实验结果表明，我们的方法在效果和效率方面优于目前最先进的方法。

    Given an untrimmed video, temporal sentence grounding (TSG) aims to locate a target moment semantically according to a sentence query. Although previous respectable works have made decent success, they only focus on high-level visual features extracted from the consecutive decoded frames and fail to handle the compressed videos for query modelling, suffering from insufficient representation capability and significant computational complexity during training and testing. In this paper, we pose a new setting, compressed-domain TSG, which directly utilizes compressed videos rather than fully-decompressed frames as the visual input. To handle the raw video bit-stream input, we propose a novel Three-branch Compressed-domain Spatial-temporal Fusion (TCSF) framework, which extracts and aggregates three kinds of low-level visual features (I-frame, motion vector and residual features) for effective and efficient grounding. Particularly, instead of encoding the whole decoded frames like previous
    
[^24]: 高效率对抗性模仿学习

    Sample-efficient Adversarial Imitation Learning. (arXiv:2303.07846v1 [cs.LG])

    [http://arxiv.org/abs/2303.07846](http://arxiv.org/abs/2303.07846)

    本研究提出了一种利用自监督表示来增强样本效率的对抗性模仿学习方法，从而学习不受扭曲影响的状态和动作表示以建立非图像控制任务的预测表征。

    

    模仿学习即通过演示进行学习，已经被研究并应用于序贯决策任务中，在这类任务中，奖励函数并不是预定义的。然而，模仿学习方法仍需要大量的专家演示样本才能成功模仿专家的行为。为提高样本效率，我们利用自监督表示学习，该方法可以从给定的数据生成大量的训练信号。在本研究中，我们提出了一种基于自监督表示的对抗性模仿学习方法，以学习不受各种扭曲影响的状态和动作表示，并建立非图像控制任务的预测表征。特别是，与现有的表格数据自监督学习方法相比，我们提出了一种针对状态和动作表示的不同损坏方法，以使其能够抵抗各种扭曲。理论和实证观察表明，使一个信息量大的特征流形与一个简单的生成器与一个复杂的分类器协同工作能够提高状态表征的质量。

    Imitation learning, in which learning is performed by demonstration, has been studied and advanced for sequential decision-making tasks in which a reward function is not predefined. However, imitation learning methods still require numerous expert demonstration samples to successfully imitate an expert's behavior. To improve sample efficiency, we utilize self-supervised representation learning, which can generate vast training signals from the given data. In this study, we propose a self-supervised representation-based adversarial imitation learning method to learn state and action representations that are robust to diverse distortions and temporally predictive, on non-image control tasks. In particular, in comparison with existing self-supervised learning methods for tabular data, we propose a different corruption method for state and action representations that is robust to diverse distortions. We theoretically and empirically observe that making an informative feature manifold with 
    
[^25]: ChatGPT提示模式用于提高代码质量、重构、需求调查和软件设计

    ChatGPT Prompt Patterns for Improving Code Quality, Refactoring, Requirements Elicitation, and Software Design. (arXiv:2303.07839v1 [cs.SE])

    [http://arxiv.org/abs/2303.07839](http://arxiv.org/abs/2303.07839)

    本文提出了ChatGPT提示模式，用于提高代码质量、重构、需求调查和软件设计。它提供了软件工程模式目录，并探讨了几种提示模式，包括改善需求调查、快速原型设计、代码质量、重构和系统设计。

    

    本文提出了一种关于软件工程的提示设计技术，通过模式解决使用大型语言模型（LLMs），例如ChatGPT自动化常用的软件工程活动中遇到的通用问题，例如确保代码与第三方库解耦，并在实现之前模拟Web应用程序API。本文为使用LLMs进行软件工程的研究提供了两个贡献。首先，它提供了一种软件工程模式目录，根据它们解决的问题类型分类模式。其次，它探讨了几种提示模式，这些模式已应用于改善需求调查、快速原型设计、代码质量、重构和系统设计。

    This paper presents prompt design techniques for software engineering, in the form of patterns, to solve common problems when using large language models (LLMs), such as ChatGPT to automate common software engineering activities, such as ensuring code is decoupled from third-party libraries and simulating a web application API before it is implemented. This paper provides two contributions to research on using LLMs for software engineering. First, it provides a catalog of patterns for software engineering that classifies patterns according to the types of problems they solve. Second, it explores several prompt patterns that have been applied to improve requirements elicitation, rapid prototyping, code quality, refactoring, and system design.
    
[^26]: 皮层尖峰列解码脉冲神经网络中的生物功能相似性对神经计算预测有帮助

    Emergent Bio-Functional Similarities in a Cortical-Spike-Train-Decoding Spiking Neural Network Facilitate Predictions of Neural Computation. (arXiv:2303.07830v1 [q-bio.NC])

    [http://arxiv.org/abs/2303.07830](http://arxiv.org/abs/2303.07830)

    本研究提出了一种循环SNN模型，motorSRNN，通过捕获和培养运动皮层神经元的余弦调谐等生物学特性，实现了对猴子运动皮层脉冲列的良好分类，并且进一步产生了额外的生物功能相似性。

    

    尽管其更好的生物学可塑性，但面向目标的尖峰神经网络（SNN）在分类生物脉冲列方面尚未实现可应用性，并且与传统的人工神经网络相比，显示出很少的生物功能相似性。在本研究中，我们提出了motorSRNN，一种由灵长类动物的神经运动电路启发的循环SNN。通过在解码猴子的主要运动皮层脉冲列中使用motorSRNN，我们在分类准确性和能量消耗之间取得了良好的平衡。motorSRNN通过捕获和培养更多余弦调谐来与输入进行通信，这是运动皮层神经元的一个重要特性，并且在训练期间保持其稳定性。这种训练诱导的余弦调谐的培养和持久性也在我们的猴子中观察到。此外，motorSRNN在单个神经元、群体和电路水平上产生了额外的生物功能相似性，证明了生物学的紧密结合。

    Despite its better bio-plausibility, goal-driven spiking neural network (SNN) has not achieved applicable performance for classifying biological spike trains, and showed little bio-functional similarities compared to traditional artificial neural networks. In this study, we proposed the motorSRNN, a recurrent SNN topologically inspired by the neural motor circuit of primates. By employing the motorSRNN in decoding spike trains from the primary motor cortex of monkeys, we achieved a good balance between classification accuracy and energy consumption. The motorSRNN communicated with the input by capturing and cultivating more cosine-tuning, an essential property of neurons in the motor cortex, and maintained its stability during training. Such training-induced cultivation and persistency of cosine-tuning was also observed in our monkeys. Moreover, the motorSRNN produced additional bio-functional similarities at the single-neuron, population, and circuit levels, demonstrating biological a
    
[^27]: ICICLE: 可解释的类增量连续学习方法

    ICICLE: Interpretable Class Incremental Continual Learning. (arXiv:2303.07811v1 [cs.LG])

    [http://arxiv.org/abs/2303.07811](http://arxiv.org/abs/2303.07811)

    ICICLE提出了一种基于样本的可解释的类增量连续学习方法，通过采用原型部分化方法来解决解释性概念漂移的问题，实验结果表明其在不需要样本的情况下表现优于现有的方法。

    

    连续学习能够增量学习新任务而不忘记之前学习的内容，从而促进新旧任务之间的正向知识转移。然而，连续学习对解释性提出了新的挑战，因为模型预测背后的原理可能会随着时间而改变，导致解释性概念漂移。本文通过提出基于样本的 Interpretable Class-InCremental LEarning (ICICLE) 方法，采用原型部分化方法，解决了这个问题。它包括三个关键的创新点：解释性正则化、以微粒粒度为基础的原型初始化策略以及针对原型部分的任务时效偏差补偿。我们的实验结果表明，ICICLE减少了解释性概念漂移，并且在不需要样本的情况下表现优于现有的方法。

    Continual learning enables incremental learning of new tasks without forgetting those previously learned, resulting in positive knowledge transfer that can enhance performance on both new and old tasks. However, continual learning poses new challenges for interpretability, as the rationale behind model predictions may change over time, leading to interpretability concept drift. We address this problem by proposing Interpretable Class-InCremental LEarning (ICICLE), an exemplar-free approach that adopts a prototypical part-based approach. It consists of three crucial novelties: interpretability regularization that distills previously learned concepts while preserving user-friendly positive reasoning; proximity-based prototype initialization strategy dedicated to the fine-grained setting; and task-recency bias compensation devoted to prototypical parts. Our experimental results demonstrate that ICICLE reduces the interpretability concept drift and outperforms the existing exemplar-free me
    
[^28]: 机器人抓取和操作：前景展望。

    Robot Grasping and Manipulation: A Prospective. (arXiv:2303.07807v1 [cs.RO])

    [http://arxiv.org/abs/2303.07807](http://arxiv.org/abs/2303.07807)

    机器人手的设计和功能是机器人技术中的最大挑战之一，解决这个问题将引领进入一个新的改进时代。

    

    “简简单单的握手必将暴露他们的身份。”这就是安东尼·霍普金斯在虚构角色罗伯特·福特博士中总结2016年科幻电视剧《西部世界》中主机的一个缺陷。在这个故事中，西部世界是一个未来主义主题公园，主机是被设计成与人类客人难以区分的自主机器人，但它们的手却还未被完善。在另一个经典的科幻系列中，科学家通过对未来手的逆向工程，开启了全合成智能Skynet的秘密。在这两个故事情节中，现实启发了小说写作，揭示了机器人设计手和复制强大可靠的操作动作是机器人技术面临的最大挑战之一。解决这个问题将引领我们进入一个新的改进时代。一个世纪前，第三次工业革命将机器人带到了装配线上，永远改变了我们的工作方式。下一个革命已经开始，带给我们的是人工智能和大数据分析。

    ``A simple handshake would give them away''. This is how Anthony Hopkins' fictional character, Dr Robert Ford, summarises a particular flaw of the 2016 science-fiction \emph{Westworld}'s hosts. In the storyline, Westworld is a futuristic theme park and the hosts are autonomous robots engineered to be indistinguishable from the human guests, except for their hands that have not been perfected yet. In another classic science-fiction saga, scientists unlock the secrets of full synthetic intelligence, Skynet, by reverse engineering a futuristic hand.  In both storylines, reality inspires fiction on one crucial point: designing hands and reproducing robust and reliable manipulation actions is one of the biggest challenges in robotics.  Solving this problem would lead us to a new, improved era of autonomy. A century ago, the third industrial revolution brought robots into the assembly lines, changing our way of working forever. The next revolution has already started by bringing us artificia
    
[^29]: OVRL-V2：ImageNav和ObjectNav的简单最新基准模型

    OVRL-V2: A simple state-of-art baseline for ImageNav and ObjectNav. (arXiv:2303.07798v1 [cs.CV])

    [http://arxiv.org/abs/2303.07798](http://arxiv.org/abs/2303.07798)

    OVRL-V2是一篇关于ImageNav和ObjectNav的最新基准模型，由任务无关的组件组成，不需要任务特定模块。该模型来源于对最近自监督学习的成功应用，而且通用性较强。

    

    我们提出了一个单一的神经网络结构，由任务无关的组件（ViTs、卷积和LSTM）组成，在没有任何任务特定模块，如目标检测、分割、映射或计划模块的情况下，实现了在ImageNav（“在<此图片>中进入位置”）和ObjectNav（“查找椅子”）任务中的最新结果。这种通用的方法在设计上具有简单性的优点，随着可用计算的正向缩放，对多个任务具有多功能应用性。我们的工作基于最近自监督学习（SSL）在视觉转换器（ViT）的预训练方面取得的成功。但是，虽然卷积网络的训练方案是成熟且稳健的，但视觉导航的ViTs的训练方案是依赖性的和脆弱的，尚未完全发现。具体而言，我们发现普通的ViT在视觉导航上表现不如ResNets。我们提出了使用在ViT补丁表示上运行的压缩层。

    We present a single neural network architecture composed of task-agnostic components (ViTs, convolutions, and LSTMs) that achieves state-of-art results on both the ImageNav ("go to location in <this picture>") and ObjectNav ("find a chair") tasks without any task-specific modules like object detection, segmentation, mapping, or planning modules. Such general-purpose methods offer advantages of simplicity in design, positive scaling with available compute, and versatile applicability to multiple tasks. Our work builds upon the recent success of self-supervised learning (SSL) for pre-training vision transformers (ViT). However, while the training recipes for convolutional networks are mature and robust, the recipes for ViTs are contingent and brittle, and in the case of ViTs for visual navigation, yet to be fully discovered. Specifically, we find that vanilla ViTs do not outperform ResNets on visual navigation. We propose the use of a compression layer operating over ViT patch representa
    
[^30]: 神经网络能做算术吗？对最先进的深度学习模型的基本数字技能的调查

    Can neural networks do arithmetic? A survey on the elementary numerical skills of state-of-the-art deep learning models. (arXiv:2303.07735v1 [cs.AI])

    [http://arxiv.org/abs/2303.07735](http://arxiv.org/abs/2303.07735)

    本文调查了最近的文献，发现即使最先进的深度学习模型在面对基本数值和算术知识的相对简单任务时也经常无法胜任。

    

    创建能展示复杂推理技能的学习模型是深度学习研究中最大的挑战之一，而数学正在迅速成为评估科学进步方向的目标领域之一。过去几年里已经出现了大量的神经网络架构、数据集和基准测试，专门设计来解决数学问题，在自动定理证明、数值积分和新猜想或矩阵乘法算法的发现方面取得了显著的成功。然而，尽管取得了这些引人注目的成绩，深度学习模型是否具有数量和符号数字的基本理解力仍然不清楚。在这个调查中，我们对最近的文献进行了批判性的审核，得出结论，即即使是最先进的架构在面对相对简单的测试基本数值和算术知识的任务时，也经常无法胜任。

    Creating learning models that can exhibit sophisticated reasoning skills is one of the greatest challenges in deep learning research, and mathematics is rapidly becoming one of the target domains for assessing scientific progress in this direction. In the past few years there has been an explosion of neural network architectures, data sets, and benchmarks specifically designed to tackle mathematical problems, reporting notable success in disparate fields such as automated theorem proving, numerical integration, and discovery of new conjectures or matrix multiplication algorithms. However, despite these impressive achievements it is still unclear whether deep learning models possess an elementary understanding of quantities and symbolic numbers. In this survey we critically examine the recent literature, concluding that even state-of-the-art architectures often fall short when probed with relatively simple tasks designed to test basic numerical and arithmetic knowledge.
    
[^31]: 通过半监督风格提取器和分层建模改进音频跨发言人风格转移的韵律

    Improving Prosody for Cross-Speaker Style Transfer by Semi-Supervised Style Extractor and Hierarchical Modeling in Speech Synthesis. (arXiv:2303.07711v1 [cs.SD])

    [http://arxiv.org/abs/2303.07711](http://arxiv.org/abs/2303.07711)

    该论文提出了强度受控的半监督风格提取器以及分层韵律预测器来改善音频跨发言人风格转移中的韵律问题，解除了一对多映射和数据不平衡问题。

    

    在语音合成中，跨发言人风格转移旨在将源发言人的风格转移到目标发言人音色的合成语音中。在大多数方法中，合成的细粒度韵律特征通常表示源发言人的平均风格，类似于一对多问题（即，多个韵律变化对应于同一文本）。为了解决这个问题，提出了一种强度受控的半监督风格提取器，以解开风格与内容和音色之间的联系，改善全局风格嵌入的表示和可解释性，这可以缓解韵律预测中的一对多映射和数据不平衡问题。提出了一种分层韵律预测器来改善韵律建模。我们发现，使用易于预测的源发言人韵律特征可以实现更好的风格转移。此外，提出了一种讲话人间循环一致性损失，以帮助模型学习未观察到的目标说话者的特征。

    Cross-speaker style transfer in speech synthesis aims at transferring a style from source speaker to synthesized speech of a target speaker's timbre. In most previous methods, the synthesized fine-grained prosody features often represent the source speaker's average style, similar to the one-to-many problem(i.e., multiple prosody variations correspond to the same text). In response to this problem, a strength-controlled semi-supervised style extractor is proposed to disentangle the style from content and timbre, improving the representation and interpretability of the global style embedding, which can alleviate the one-to-many mapping and data imbalance problems in prosody prediction. A hierarchical prosody predictor is proposed to improve prosody modeling. We find that better style transfer can be achieved by using the source speaker's prosody features that are easily predicted. Additionally, a speaker-transfer-wise cycle consistency loss is proposed to assist the model in learning un
    
[^32]: 离线到在线强化学习的自适应策略学习

    Adaptive Policy Learning for Offline-to-Online Reinforcement Learning. (arXiv:2303.07693v1 [cs.LG])

    [http://arxiv.org/abs/2303.07693](http://arxiv.org/abs/2303.07693)

    本文提出了一种自适应策略学习框架，以有效地利用离线和在线数据，实现了离线到在线强化学习的最佳效果。

    

    传统强化学习需要一个环境来收集新鲜的数据，但当在线交互成本高昂时不切实际。离线强化学习通过直接从以前收集的数据集中学习提供了一种替代方法。但是，如果离线数据集的质量差，将导致性能不佳。本文考虑了一种离线到在线的场景，在该场景中，代理首先从离线数据集中学习，然后再进行在线训练，并提出了一种名为自适应策略学习的框架，以有效地利用离线和在线数据。具体来说，我们显式考虑了在线和离线数据之间的差异，并相应地应用了自适应更新策略，即对离线数据集采用悲观更新策略，而对在线数据集采用乐观/贪心更新策略。这种简单而有效的方法提供了一种混合离线和在线强化学习并实现两者最佳效果的方法。我们进一步通过理论分析表明，我们的算法实现了亚线性后悔界，与有同时访问离线和在线数据的oracle算法的性能相匹配。

    Conventional reinforcement learning (RL) needs an environment to collect fresh data, which is impractical when online interactions are costly. Offline RL provides an alternative solution by directly learning from the previously collected dataset. However, it will yield unsatisfactory performance if the quality of the offline datasets is poor. In this paper, we consider an offline-to-online setting where the agent is first learned from the offline dataset and then trained online, and propose a framework called Adaptive Policy Learning for effectively taking advantage of offline and online data. Specifically, we explicitly consider the difference between the online and offline data and apply an adaptive update scheme accordingly, that is, a pessimistic update strategy for the offline dataset and an optimistic/greedy update scheme for the online dataset. Such a simple and effective method provides a way to mix the offline and online RL and achieve the best of both worlds. We further provi
    
[^33]: 面向方面级情感分类的双重注意力模型

    Dual-Attention Model for Aspect-Level Sentiment Classification. (arXiv:2303.07689v1 [cs.CL])

    [http://arxiv.org/abs/2303.07689](http://arxiv.org/abs/2303.07689)

    本文提出了一种面向方面级情感分类的双重注意力模型，使用依存标签为注意力机制执行任务，对三个数据集均有良好表现。

    

    本文提出了一种新颖的面向方面级情感分类的双重注意力模型(DAM)。尽管许多现有的方法，如支持向量机用于人工设计特征、基于注意力机制的长短时记忆网络和基于依存句法分析的图神经网络，都有不错的性能，但我认为它们都缺少一个重要的句法信息：依存标签。基于这个想法，本文提出了一种使用依存标签为注意力机制执行任务的模型。我们在三个数据集上评估了所提出的方法：笔记本电脑和餐厅数据集来自SemEval 2014，最后一个是Twitter数据集。实验结果表明，双重注意力模型在所有三个数据集上具有良好的性能。

    I propose a novel dual-attention model(DAM) for aspect-level sentiment classification. Many methods have been proposed, such as support vector machines for artificial design features, long short-term memory networks based on attention mechanisms, and graph neural networks based on dependency parsing. While these methods all have decent performance, I think they all miss one important piece of syntactic information: dependency labels. Based on this idea, this paper proposes a model using dependency labels for the attention mechanism to do this task. We evaluate the proposed approach on three datasets: laptop and restaurant are from SemEval 2014, and the last one is a twitter dataset. Experimental results show that the dual attention model has good performance on all three datasets.
    
[^34]: FPTN:快速纯Transformer网络用于交通流量预测

    FPTN: Fast Pure Transformer Network for Traffic Flow Forecasting. (arXiv:2303.07685v1 [cs.LG])

    [http://arxiv.org/abs/2303.07685](http://arxiv.org/abs/2303.07685)

    本文提出了一种快速纯Transformer网络（FPTN），将交通流量数据沿传感器维度而非时间维度划分为序列，提出了三种嵌入方式将这些向量投影到适当的向量空间中，然后利用Transformer的多头注意机制捕获复杂时空相关性，使用全连接层输出预测的交通流量，FPTN不仅实现了最先进的准确性，而且运行速度比其他基于Transformer的模型快几倍。

    

    由于交通流量数据中的复杂时空相关性，交通流量预测是具有挑战性的。现有的基于Transformer的方法通常将交通流量预测视为多元时间序列（MTS）预测。然而，太多的传感器会导致一个大于800的向量，这很难在不丢失信息的情况下进行处理。此外，这些方法设计了复杂的机制来捕获MTS中的空间依赖关系，导致预测速度缓慢。为了解决上述问题，本文提出了一种快速纯Transformer网络（FPTN）。首先，将交通流量数据沿传感器维度而非时间维度划分为序列。然后，为了充分表示复杂的时空相关性，提出了三种嵌入方式将这些向量投影到适当的向量空间中。之后，为了同时捕获这些向量中的复杂时空相关性，我们利用了Transformer的多头注意机制。最后，使用全连接层输出预测的交通流量。在三个真实交通数据集上的实验结果表明，FPTN不仅实现了最先进的准确性，而且比其他基于Transformer的模型运行速度快几倍。

    Traffic flow forecasting is challenging due to the intricate spatio-temporal correlations in traffic flow data. Existing Transformer-based methods usually treat traffic flow forecasting as multivariate time series (MTS) forecasting. However, too many sensors can cause a vector with a dimension greater than 800, which is difficult to process without information loss. In addition, these methods design complex mechanisms to capture spatial dependencies in MTS, resulting in slow forecasting speed. To solve the abovementioned problems, we propose a Fast Pure Transformer Network (FPTN) in this paper. First, the traffic flow data are divided into sequences along the sensor dimension instead of the time dimension. Then, to adequately represent complex spatio-temporal correlations, Three types of embeddings are proposed for projecting these vectors into a suitable vector space. After that, to capture the complex spatio-temporal correlations simultaneously in these vectors, we utilize Transforme
    
[^35]: 基于特征丰富的音频模型反演的无数据知识蒸馏以实现通用声音分类

    Feature-Rich Audio Model Inversion for Data-Free Knowledge Distillation Towards General Sound Classification. (arXiv:2303.07643v1 [cs.SD])

    [http://arxiv.org/abs/2303.07643](http://arxiv.org/abs/2303.07643)

    该论文提出了一种基于特征丰富的音频模型反演（FRAMI）的无数据知识蒸馏框架，用于通用声音分类任务。通过特征不变对比损失生成高质量和特征丰富的Mel频谱图，再利用统计汇集层之前和之后的隐藏状态进行知识蒸馏。实验结果表明，该方法能够提高学生模型的准确性。

    

    最近，无数据知识蒸馏（DFKD）在学术界引起了越来越多的关注，尤其是在计算机视觉取得了重大突破后。尽管技术有着很好的效果，但其在音频和信号处理方面的应用还不是很好。由于音频信号的可变持续时间，其具有自己独特的建模方式。在这项工作中，我们提出了基于特征丰富的音频模型反演（FRAMI），这是一种用于通用声音分类任务的无数据知识蒸馏框架。它首先通过特征不变对比损失生成高质量和特征丰富的Mel频谱图。然后，在这些特征丰富的样本上进行知识蒸馏时，再利用统计汇集层之前和之后的隐藏状态。在Urbansound8k、ESC-50和audioMNIST数据集上的实验结果表明，FRAMI能够生成特征丰富的样本。同时，通过重用隐藏状态和信号，进一步提高了学生模型的准确性。

    Data-Free Knowledge Distillation (DFKD) has recently attracted growing attention in the academic community, especially with major breakthroughs in computer vision. Despite promising results, the technique has not been well applied to audio and signal processing. Due to the variable duration of audio signals, it has its own unique way of modeling. In this work, we propose feature-rich audio model inversion (FRAMI), a data-free knowledge distillation framework for general sound classification tasks. It first generates high-quality and feature-rich Mel-spectrograms through a feature-invariant contrastive loss. Then, the hidden states before and after the statistics pooling layer are reused when knowledge distillation is performed on these feature-rich samples. Experimental results on the Urbansound8k, ESC-50, and audioMNIST datasets demonstrate that FRAMI can generate feature-rich samples. Meanwhile, the accuracy of the student model is further improved by reusing the hidden state and sig
    
[^36]: I$^2$-SDF: 通过神经网络中的光线追踪实现内部场景重建和编辑

    I$^2$-SDF: Intrinsic Indoor Scene Reconstruction and Editing via Raytracing in Neural SDFs. (arXiv:2303.07634v1 [cs.CV])

    [http://arxiv.org/abs/2303.07634](http://arxiv.org/abs/2303.07634)

    本文提出了 I$^2$-SDF 方法，使用可微分的蒙特卡罗光线跟踪技术实现了室内场景的重建和编辑，采用气泡损失函数和错误引导的自适应采样方案提高了重建质量，同时分解神经辐射场为场景的空间变化材料实现了物理和逼真的场景编辑应用。

    

    本文提出了一种名为 I$^2$-SDF 的新方法，可使用可微分的蒙特卡罗光线追踪技术对神经网络有符号距离场中的多视图图像进行物体重建、辐射和材质恢复。针对小型物体，我们引入了新的气泡损失函数，以及误差引导自适应取样方案，大大提高了大规模室内场景的重建质量。此外，我们提出将神经辐射场分解为场景的空间变化材料，并通过基于表面的可微蒙特卡罗光线追踪和发射器语义分割来实现基于物理和逼真的场景重照和编辑应用。通过大量的定量和定性实验，我们展示了我们的方法在室内场景重建、新视角合成和场景编辑方面的卓越质量。

    In this work, we present I$^2$-SDF, a new method for intrinsic indoor scene reconstruction and editing using differentiable Monte Carlo raytracing on neural signed distance fields (SDFs). Our holistic neural SDF-based framework jointly recovers the underlying shapes, incident radiance and materials from multi-view images. We introduce a novel bubble loss for fine-grained small objects and error-guided adaptive sampling scheme to largely improve the reconstruction quality on large-scale indoor scenes. Further, we propose to decompose the neural radiance field into spatially-varying material of the scene as a neural field through surface-based, differentiable Monte Carlo raytracing and emitter semantic segmentations, which enables physically based and photorealistic scene relighting and editing applications. Through a number of qualitative and quantitative experiments, we demonstrate the superior quality of our method on indoor scene reconstruction, novel view synthesis, and scene editin
    
[^37]: RE-MOVE：一种基于语言反馈的动态环境自适应策略设计方法

    RE-MOVE: An Adaptive Policy Design Approach for Dynamic Environments via Language-Based Feedback. (arXiv:2303.07622v1 [cs.RO])

    [http://arxiv.org/abs/2303.07622](http://arxiv.org/abs/2303.07622)

    RE-MOVE提出了一种基于语言反馈的自适应策略设计方法，可以使机器人适应实时环境变化，并从人类反馈中学习并适应之前未见过的对抗性场景。

    

    连续控制机器人导航任务的强化学习策略经常无法在实时部署期间适应环境的变化，这可能导致灾难性的失败。为了解决这个问题，我们提出了一种名为RE-MOVE（请求帮助并移动）的新方法，它使用基于语言的反馈来调整经过训练的策略以适应环境的实时变化。在这项工作中，我们使经过训练的策略能够决定何时请求反馈并如何将反馈纳入训练好的策略中。RE-MOVE利用先验不确定性来确定请求人类反馈的最佳时间，并使用基于语言的反馈进行实时适应。我们进行了大量的合成和实际世界的评估，以展示我们提出的方法在多种测试时间动态导航场景中的好处。我们的方法使机器人能够从人类反馈中学习并适应之前未见过的对抗性场景。

    Reinforcement learning-based policies for continuous control robotic navigation tasks often fail to adapt to changes in the environment during real-time deployment, which may result in catastrophic failures. To address this limitation, we propose a novel approach called RE-MOVE (\textbf{RE}quest help and \textbf{MOVE} on), which uses language-based feedback to adjust trained policies to real-time changes in the environment. In this work, we enable the trained policy to decide \emph{when to ask for feedback} and \emph{how to incorporate feedback into trained policies}. RE-MOVE incorporates epistemic uncertainty to determine the optimal time to request feedback from humans and uses language-based feedback for real-time adaptation. We perform extensive synthetic and real-world evaluations to demonstrate the benefits of our proposed approach in several test-time dynamic navigation scenarios. Our approach enable robots to learn from human feedback and adapt to previously unseen adversarial 
    
[^38]: 重划小学考勤边界以促进种族和民族多样性

    Redrawing attendance boundaries to promote racial and ethnic diversity in elementary schools. (arXiv:2303.07603v1 [cs.CY])

    [http://arxiv.org/abs/2303.07603](http://arxiv.org/abs/2303.07603)

    该研究通过将家长的偏好数据与组合优化方法相结合，重新划分小学的考勤边界，以最小化白/非白人种族分离，同时减轻对行程时间和学校规模的影响，实现了中位数14％的种族隔离率相对降低，需要约20％的学生转换学校，并出乎意料地略微缩短了行程时间。

    

    大多数美国学区制定“考勤边界”来定义分配学生到家附近学校的区域，往往重演邻里种族隔离在学校中的现象。本研究集中在小学上，并提出以下问题：重新划分考勤边界是否能够减少学校的种族隔离现象？我们将家长的偏好数据与组合优化方法相结合，模拟了覆盖超过3百万小学生的98个美国学区的替代边界，以最小化白/非白人种族分离，同时减轻对行程时间和学校规模的影响。在各个学区中，我们观察到中位数14%的种族隔离率相对降低，这需要约20%的学生转换学校，并出乎意料地略微缩短了行程时间。我们发布了一个公共仪表板（https://www.schooldiversity.org/），展示这些替代边界，并邀请学校董事会及其利益相关者进行评估。

    Most US school districts draw "attendance boundaries" to define catchment areas that assign students to schools near their homes, often recapitulating neighborhood demographic segregation in schools. Focusing on elementary schools, we ask: how much might we reduce school segregation by redrawing attendance boundaries? Combining parent preference data with methods from combinatorial optimization, we simulate alternative boundaries for 98 US school districts serving over 3 million elementary-aged students, minimizing White/non-White segregation while mitigating changes to travel times and school sizes. Across districts, we observe a median 14% relative decrease in segregation, which we estimate would require approximately 20\% of students to switch schools and, surprisingly, a slight reduction in travel times. We release a public dashboard depicting these alternative boundaries (https://www.schooldiversity.org/) and invite both school boards and their constituents to evaluate their viabi
    
[^39]: 利用机器学习预测海湾合作委员会国家的COVID-19感染情况

    Forecasting COVID-19 Infections in Gulf Cooperation Council (GCC) Countries using Machine Learning. (arXiv:2303.07600v1 [cs.LG])

    [http://arxiv.org/abs/2303.07600](http://arxiv.org/abs/2303.07600)

    本论文利用机器学习时间序列模型针对海湾合作委员会国家的COVID-19疫情数据进行分析，实验结果表明所开发的模型可以高精度地对COVID-19感染情况进行预测。

    

    COVID-19自去年首次检测以来，已经在全球范围内感染了超过6800万人。时间序列机器学习模型已经被应用于预测COVID-19的感染情况。本文使用Johns Hopkins的公共COVID-19数据集针对海湾合作委员会（GCC）国家开发了时间序列模型。数据集包括2020年1月22日至2021年1月22日之间的一年累计COVID-19病例。我们根据感染数据的空间分布，为所研究的国家开发了不同的模型。我们的实验结果表明，所开发的模型可以高精度地预测COVID-19的感染情况。

    COVID-19 has infected more than 68 million people worldwide since it was first detected about a year ago. Machine learning time series models have been implemented to forecast COVID-19 infections. In this paper, we develop time series models for the Gulf Cooperation Council (GCC) countries using the public COVID-19 dataset from Johns Hopkins. The dataset set includes the one-year cumulative COVID-19 cases between 22/01/2020 to 22/01/2021. We developed different models for the countries under study based on the spatial distribution of the infection data. Our experimental results show that the developed models can forecast COVID-19 infections with high precision.
    
[^40]: AdPE：通过MAE+对视觉Transformer进行预训练的对抗位置嵌入

    AdPE: Adversarial Positional Embeddings for Pretraining Vision Transformers via MAE+. (arXiv:2303.07598v1 [cs.CV])

    [http://arxiv.org/abs/2303.07598](http://arxiv.org/abs/2303.07598)

    AdPE方法通过对抗位置嵌入，扭曲局部结构，强制Transformer编码器在全局上下文中学习更具有差别性的特征，从而提高泛化能力。

    

    无监督学习视觉Transformer旨在通过预设任务在没有标签的情况下预先训练编码器。其中一个任务是Masked Image Modeling（MIM），与预训练语言Transformer预测掩蔽补丁相对应。无监督预训练中的一个准则是预设任务需要足够难以防止Transformer学习不能很好地泛化到下游任务的微不足道的低层次特征。为此，我们提出了Adversarial Positional Embedding（AdPE）方法 - 通过扰动位置编码来扭曲局部视觉结构，以使得学习的Transformer不能仅使用局部相关的补丁来预测缺失的补丁。我们假设它迫使Transformer编码器在全局上下文中学习更具有差别性的特征，从而在下游任务中具有更强的泛化能力。我们将考虑绝对和相对位置编码，其中对抗位置可以模拟为...

    Unsupervised learning of vision transformers seeks to pretrain an encoder via pretext tasks without labels. Among them is the Masked Image Modeling (MIM) aligned with pretraining of language transformers by predicting masked patches as a pretext task. A criterion in unsupervised pretraining is the pretext task needs to be sufficiently hard to prevent the transformer encoder from learning trivial low-level features not generalizable well to downstream tasks. For this purpose, we propose an Adversarial Positional Embedding (AdPE) approach -- It distorts the local visual structures by perturbing the position encodings so that the learned transformer cannot simply use the locally correlated patches to predict the missing ones. We hypothesize that it forces the transformer encoder to learn more discriminative features in a global context with stronger generalizability to downstream tasks. We will consider both absolute and relative positional encodings, where adversarial positions can be im
    
[^41]: 基于嵌入式加速器的雷达感知的师生知识蒸馏

    Teacher-Student Knowledge Distillation for Radar Perception on Embedded Accelerators. (arXiv:2303.07586v1 [cs.AI])

    [http://arxiv.org/abs/2303.07586](http://arxiv.org/abs/2303.07586)

    本文提出一种基于师生知识蒸馏的方法，用于低级别雷达感知任务，并成功实现嵌入式计算的实时部署，速度达到教师模型的100倍。

    

    目前许多用于道路安全感知的雷达信号处理方法都无法很好地运行在用于汽车的嵌入式硬件加速器上。相反，端到端的机器学习方法更好地利用了专门加速器所带来的性能提升。在本文中，我们提出了一种用于低级别雷达感知任务的师生知识蒸馏方法。我们利用用于静态目标检测的混合模型作为教师，来训练端到端的机器学习学生模型。该学生模型可以高效地利用嵌入式计算进行实时部署。我们证明了所提出的学生模型比教师模型快100倍。

    Many radar signal processing methodologies are being developed for critical road safety perception tasks. Unfortunately, these signal processing algorithms are often poorly suited to run on embedded hardware accelerators used in automobiles. Conversely, end-to-end machine learning (ML) approaches better exploit the performance gains brought by specialized accelerators. In this paper, we propose a teacher-student knowledge distillation approach for low-level radar perception tasks. We utilize a hybrid model for stationary object detection as a teacher to train an end-to-end ML student model. The student can efficiently harness embedded compute for real-time deployment. We demonstrate that the proposed student model runs at speeds 100x faster than the teacher model.
    
[^42]: NLP 中的扩散模型：一项调查研究

    Diffusion Models in NLP: A Survey. (arXiv:2303.07576v1 [cs.CL])

    [http://arxiv.org/abs/2303.07576](http://arxiv.org/abs/2303.07576)

    本文总结了在自然语言处理中，扩散模型在文本生成和驱动图像生成方面等应用中表现出的创纪录性能，并深入分析并总结相关文献资料。

    

    扩散模型已成为一个强大的深层生成模型系列，在许多应用中显示了创记录的性能。本文首先概述和推导了扩散模型的基本理论，然后回顾了扩散模型在自然语言处理领域中的研究成果，从文本生成、文本驱动的图像生成等四个方面进行分析和总结了相关的文献资料，并最终记录了这个主题文献综述研究的经验和感受。

    Diffusion models have become a powerful family of deep generative models, with record-breaking performance in many applications. This paper first gives an overview and derivation of the basic theory of diffusion models, then reviews the research results of diffusion models in the field of natural language processing, from text generation, text-driven image generation and other four aspects, and analyzes and summarizes the relevant literature materials sorted out, and finally records the experience and feelings of this topic literature review research.
    
[^43]: 终身学习在异常检测中的应用: 新的挑战、视角和见解

    Lifelong Learning for Anomaly Detection: New Challenges, Perspectives, and Insights. (arXiv:2303.07557v1 [cs.LG])

    [http://arxiv.org/abs/2303.07557](http://arxiv.org/abs/2303.07557)

    本文探讨了终身异常检测的重要性，提出设计终身学习复杂性的异常检测方法的挑战和机会，并提供了一种场景生成过程使得研究人员能够进行实验。

    

    在许多实际领域中，异常检测具有极其重要的意义，特别是在行为不断变化的情况下。终身学习是一种新兴趋势，它能够满足需要机器学习模型在动态环境中不断适应新挑战并保留过去知识的需求。然而，目前很少有人致力于建立终身异常检测的基础，这与更广泛探索的分类设置存在本质不同的挑战。本文通过探讨、阐述和讨论终身异常检测，试图为其更广泛的采用建立基础。首先，我们解释了为什么终身异常检测很重要，定义了应对终身学习复杂性的异常检测方法设计的挑战和机会。其次，我们对学习设置和场景生成过程进行了表征，使研究人员能够使用这些工具进行终身异常检测的实验。

    Anomaly detection is of paramount importance in many real-world domains, characterized by evolving behavior. Lifelong learning represents an emerging trend, answering the need for machine learning models that continuously adapt to new challenges in dynamic environments while retaining past knowledge. However, limited efforts are dedicated to building foundations for lifelong anomaly detection, which provides intrinsically different challenges compared to the more widely explored classification setting. In this paper, we face this issue by exploring, motivating, and discussing lifelong anomaly detection, trying to build foundations for its wider adoption. First, we explain why lifelong anomaly detection is relevant, defining challenges and opportunities to design anomaly detection methods that deal with lifelong learning complexities. Second, we characterize learning settings and a scenario generation procedure that enables researchers to experiment with lifelong anomaly detection using
    
[^44]: 合并决策Transformer：多任务策略形成的权重平均化

    Merging Decision Transformers: Weight Averaging for Forming Multi-Task Policies. (arXiv:2303.07551v1 [cs.LG])

    [http://arxiv.org/abs/2303.07551](http://arxiv.org/abs/2303.07551)

    本文提出通过在权重空间中合并训练于不同 MuJoCo 运动问题上的 Decision Transformer 的子集，形成多任务模型。通过共享一些辅助任务的训练以及共同使用预训练初始化，能够获得更好的结果。这个方向的研究有助于使代理的过程民主化和分发。

    

    最近的研究展示了基于Transformer的通用语言、视觉和连续决策制定问题的策略的前景。为了创建这样的模型，我们通常需要集中的训练目标、数据和计算。如果我们能够更灵活地创建通用策略，通过合并多个任务特定的、单独训练的策略，则这样做就比较有意义。在本文中，我们通过在权重空间中合并或平均不同MuJoCo运动问题上训练的Decision Transformer的子集来迈出这个方向的初步步骤，形成没有集中训练的多任务模型。我们还建议在合并策略时可以获得更好的结果，如果所有策略都从共同的预训练初始化开始，并在问题特定的微调期间共同训练共享的辅助任务。一般来说，我们相信这个方向的研究可以帮助民主化和分发具有一般能力的代理的过程。

    Recent work has shown the promise of creating generalist, transformer-based, policies for language, vision, and sequential decision-making problems. To create such models, we generally require centralized training objectives, data, and compute. It is of interest if we can more flexibly create generalist policies, by merging together multiple, task-specific, individually trained policies. In this work, we take a preliminary step in this direction through merging, or averaging, subsets of Decision Transformers in weight space trained on different MuJoCo locomotion problems, forming multi-task models without centralized training. We also propose that when merging policies, we can obtain better results if all policies start from common, pre-trained initializations, while also co-training on shared auxiliary tasks during problem-specific finetuning. In general, we believe research in this direction can help democratize and distribute the process of which forms generally capable agents.
    
[^45]: WDiscOOD：通过白化线性判别分析进行区分度优化的OOD检测

    WDiscOOD: Out-of-Distribution Detection via Whitened Linear Discriminative Analysis. (arXiv:2303.07543v1 [cs.CV])

    [http://arxiv.org/abs/2303.07543](http://arxiv.org/abs/2303.07543)

    本论文提出了一种名为WDiscOOD的新型OOD检测方法，其中使用白化线性判别分析将特征投影到判别子空间和残留子空间中，确定OOD分数。在大规模ImageNet-1k基准测试和六个OOD数据集中，WDiscOOD表现出了优越的性能。

    

    深度神经网络容易在遇到未知概念的情形下产生过度自信但错误的预测。这个挑战突显了在开放世界中检测OOD样本的重要性。本文提出了一种新颖的特征空间OOD检测分数，同时结合了类别特定和类别不可知的信息。具体地，我们的方法使用白化线性判别分析将特征投影到两个子空间中——判别子空间和残留子空间，其中ID类在判别子空间中被最大化地分离，并在残差子空间中被紧密地聚类。然后，在两个子空间中将来自输入数据与ID分布的偏差组合起来确定OOD分数。我们的方法名为WDiscOOD，在覆盖多种分布偏移的六个OOD数据集上验证了其高效性，包括大规模ImageNet-1k基准测试。WDiscOOD在深度分类器上表现出了优越的性能。

    Deep neural networks are susceptible to generating overconfident yet erroneous predictions when presented with data beyond known concepts. This challenge underscores the importance of detecting out-of-distribution (OOD) samples in the open world. In this work, we propose a novel feature-space OOD detection score that jointly reasons with both class-specific and class-agnostic information. Specifically, our approach utilizes Whitened Linear Discriminative Analysis to project features into two subspaces - the discriminative and residual subspaces - in which the ID classes are maximally separated and closely clustered, respectively. The OOD score is then determined by combining the deviation from the input data to the ID distribution in both subspaces. The efficacy of our method, named WDiscOOD, is verified on the large-scale ImageNet-1k benchmark, with six OOD datasets that covers a variety of distribution shifts. WDiscOOD demonstrates superior performance on deep classifiers with divers
    
[^46]: 基于强化学习的路径规划：一种策略迭代方法

    Path Planning using Reinforcement Learning: A Policy Iteration Approach. (arXiv:2303.07535v1 [cs.LG])

    [http://arxiv.org/abs/2303.07535](http://arxiv.org/abs/2303.07535)

    本研究提出了一种基于自动调整器的序数回归方法，以加速探索强化学习算法的参数，并加速收敛到最优策略。该方法可以提供1.82倍的峰值加速和1.48倍的平均加速比。

    

    随着实时处理的影响在最近被认识到，对于强化学习算法的高效实现的需求也越来越迫切。尽管RL算法中利用Bellman方程具有许多优点，但是设计参数的大搜索空间也是不可避免的。本研究旨在阐明与强化学习参数相关的设计空间探索，特别是策略迭代方面。考虑到微调强化学习算法的参数需要大量的计算开销，我们提出了一种基于自动调节器的序数回归方法，以加速探索这些参数的过程，并加速收敛到最优策略。我们的方法提供了1.82倍的峰值加速，平均加速比为1.48倍，比之前的最先进技术有显著的提升。

    With the impact of real-time processing being realized in the recent past, the need for efficient implementations of reinforcement learning algorithms has been on the rise. Albeit the numerous advantages of Bellman equations utilized in RL algorithms, they are not without the large search space of design parameters.  This research aims to shed light on the design space exploration associated with reinforcement learning parameters, specifically that of Policy Iteration. Given the large computational expenses of fine-tuning the parameters of reinforcement learning algorithms, we propose an auto-tuner-based ordinal regression approach to accelerate the process of exploring these parameters and, in return, accelerate convergence towards an optimal policy. Our approach provides 1.82x peak speedup with an average of 1.48x speedup over the previous state-of-the-art.
    
[^47]: 机器人导航的音视语言地图

    Audio Visual Language Maps for Robot Navigation. (arXiv:2303.07522v1 [cs.RO])

    [http://arxiv.org/abs/2303.07522](http://arxiv.org/abs/2303.07522)

    该论文提出了一种音视语言地图(AVLMaps)，用于存储跨模态信息，实现机器人根据多模态查询在地图中索引目标的导航方式。在模拟实验中，AVLMaps实现了从多模态提示的零次学习式多模态目标导航，并提供了更好的召回率。

    

    与世界的互动是一种多感官的体验，但是许多机器人仍然主要依赖视觉感知来绘制和导航他们的环境。本文提出了音视语言地图(AVLMaps)，这是一个统一的3D空间地图表示，用于存储来自音频、视觉和语言线索的跨模态信息。在导航的情境下，我们展示了AVLMaps能够使机器人系统根据多模态查询(例如，文本描述、图像或地标的音频片段)在地图中索引目标。特别是，添加音频信息使机器人能够更可靠地消除目标位置的歧义性。在模拟实验中，我们展示了AVLMaps能够实现从多模态提示进行零次学习的多模态目标导航，并在模糊场景中提供50%更好的召回率。

    While interacting in the world is a multi-sensory experience, many robots continue to predominantly rely on visual perception to map and navigate in their environments. In this work, we propose Audio-Visual-Language Maps (AVLMaps), a unified 3D spatial map representation for storing cross-modal information from audio, visual, and language cues. AVLMaps integrate the open-vocabulary capabilities of multimodal foundation models pre-trained on Internet-scale data by fusing their features into a centralized 3D voxel grid. In the context of navigation, we show that AVLMaps enable robot systems to index goals in the map based on multimodal queries, e.g., textual descriptions, images, or audio snippets of landmarks. In particular, the addition of audio information enables robots to more reliably disambiguate goal locations. Extensive experiments in simulation show that AVLMaps enable zero-shot multimodal goal navigation from multimodal prompts and provide 50% better recall in ambiguous scenar
    
[^48]: 连续深度强化学习中的可塑性丧失

    Loss of Plasticity in Continual Deep Reinforcement Learning. (arXiv:2303.07507v1 [cs.LG])

    [http://arxiv.org/abs/2303.07507](http://arxiv.org/abs/2303.07507)

    本文研究了在连续变化的环境中，深度强化学习代理程序在执行一系列游戏时失去可塑性。研究发现网络的激活足迹变得稀疏导致梯度变小。

    

    在这篇论文中，我们研究了经典基于值的深度强化学习方法在不断变化的环境下的行为。特别地，我们证明了当深度强化学习代理程序循环执行Atari 2600游戏时，它们失去了学习良好策略的能力。我们在多个实验中进行了实验，并分析了权重、梯度和激活在时间上如何变化。我们的分析表明，网络的激活足迹变得更加稀疏，导致梯度减小。

    The ability to learn continually is essential in a complex and changing world. In this paper, we characterize the behavior of canonical value-based deep reinforcement learning (RL) approaches under varying degrees of non-stationarity. In particular, we demonstrate that deep RL agents lose their ability to learn good policies when they cycle through a sequence of Atari 2600 games. This phenomenon is alluded to in prior work under various guises -e.g., loss of plasticity, implicit under-parameterization, primacy bias, and capacity loss. We investigate this phenomenon closely at scale and analyze how the weights, gradients, and activations change over time in several experiments with varying dimensions (e.g., similarity between games, number of games, number of frames per game), with some experiments spanning 50 days and 2 billion environment interactions. Our analysis shows that the activation footprint of the network becomes sparser, contributing to the diminishing gradients. We inves
    
[^49]: 元学习法在小样本学习中的应用：近期进展综述

    Meta-learning approaches for few-shot learning: A survey of recent advances. (arXiv:2303.07502v1 [cs.LG])

    [http://arxiv.org/abs/2303.07502](http://arxiv.org/abs/2303.07502)

    本文综述了元学习在小样本学习中的应用，调查了最先进的方法，并讨论了当前挑战和未来研究方向。

    

    尽管深度学习在学习多维数据方面取得了惊人的成功，但由于其专注于同分布预测，导致其在新的未见任务上表现不佳。此外，深度学习因样本不足而通常表现不佳。元学习是一种有前途的方法，可以通过适应少量样本数据来解决这些问题。本综述首先简要介绍了元学习，然后调查了最先进的元学习方法以及(I) 基于度量的、(II) 基于记忆的、(III) 和基于学习的方法的最新技术进展。最后，讨论了当前的挑战和未来研究的见解。

    Despite its astounding success in learning deeper multi-dimensional data, the performance of deep learning declines on new unseen tasks mainly due to its focus on same-distribution prediction. Moreover, deep learning is notorious for poor generalization from few samples. Meta-learning is a promising approach that addresses these issues by adapting to new tasks with few-shot datasets. This survey first briefly introduces meta-learning and then investigates state-of-the-art meta-learning methods and recent advances in: (I) metric-based, (II) memory-based, (III), and learning-based methods. Finally, current challenges and insights for future researches are discussed.
    
[^50]: 利用渐进任务相关性层冻结的有效自监督连续学习

    Efficient Self-supervised Continual Learning with Progressive Task-correlated Layer Freezing. (arXiv:2303.07477v1 [cs.CV])

    [http://arxiv.org/abs/2303.07477](http://arxiv.org/abs/2303.07477)

    本论文提出了一种新的自监督连续学习方法，通过渐进地冻结有最高相关性的部分层来优化学习效率，并提高了所学表示的丰富性和鲁棒性。

    

    受到自监督学习在从无标签数据中学习视觉表示方面的成功启发，最近一些研究探究了在连续学习（CL）环境下自监督学习的机制，形成了一种新的模式，即自监督连续学习（SSCL）。 SSCL已被证明优于受监督的连续学习（SCL），因为所学表示更加丰富和鲁棒。然而，如果不设计智能，则SSCL的培训复杂性可能会由于自监督学习的天然培训成本而变得禁止高。在本研究中，通过首先研究SSCL设置中的任务相关性，我们发现了一个有趣的现象，即在SSL学习的背景模型下，中间特征在任务之间高度相关。基于这一新发现，我们提出了一种新的具有层冻结的SSCL方法，该方法通过逐步冻结具有最高相关性的部分层。

    Inspired by the success of Self-supervised learning (SSL) in learning visual representations from unlabeled data, a few recent works have studied SSL in the context of continual learning (CL), where multiple tasks are learned sequentially, giving rise to a new paradigm, namely self-supervised continual learning (SSCL). It has been shown that the SSCL outperforms supervised continual learning (SCL) as the learned representations are more informative and robust to catastrophic forgetting. However, if not designed intelligently, the training complexity of SSCL may be prohibitively high due to the inherent training cost of SSL. In this work, by investigating the task correlations in SSCL setup first, we discover an interesting phenomenon that, with the SSL-learned background model, the intermediate features are highly correlated between tasks. Based on this new finding, we propose a new SSCL method with layer-wise freezing which progressively freezes partial layers with the highest correla
    
[^51]: 深度学习模型重构的挑战和实践：计算机视觉案例研究

    Challenges and Practices of Deep Learning Model Reengineering: A Case Study on Computer Vision. (arXiv:2303.07476v1 [cs.SE])

    [http://arxiv.org/abs/2303.07476](http://arxiv.org/abs/2303.07476)

    本研究对深度学习模型重构进行了实例研究，并发现由于参考模型文档不全、需求变化以及实现和测试成本等原因，该过程具有挑战性，个别工程师可能缺乏软件工程方面的专业知识，但团队必须应用软件工程和深度学习的知识才能成功。

    

    许多工程组织正在重新实现和扩展研究界的深度神经网络。我们将这个过程描述为深度学习模型重构。深度学习模型重构-重用，再现，调整和增强最先进的深度学习方法-由于参考模型文档不全、需求变化以及实现和测试成本等原因，具有挑战性。此外，个别工程师可能缺乏软件工程方面的专业知识，但团队必须应用软件工程和深度学习的知识才能成功。先前的研究从“产品”视角研究DL系统，无论工程师的目的如何，都会研究项目中的缺陷。我们的研究集中在“过程”视角的重构活动上，专注于参与重构过程的工程师。我们的目标是了解深度学习模型重构的特点和挑战。我们进行了一项案例研究...

    Many engineering organizations are reimplementing and extending deep neural networks from the research community. We describe this process as deep learning model reengineering. Deep learning model reengineering - reusing, reproducing, adapting, and enhancing state-of-the-art deep learning approaches - is challenging for reasons including under-documented reference models, changing requirements, and the cost of implementation and testing. In addition, individual engineers may lack expertise in software engineering, yet teams must apply knowledge of software engineering and deep learning to succeed. Prior work has examined on DL systems from a "product" view, examining defects from projects regardless of the engineers' purpose. Our study is focused on reengineering activities from a "process" view, and focuses on engineers specifically engaged in the reengineering process.  Our goal is to understand the characteristics and challenges of deep learning model reengineering. We conducted a c
    
[^52]: 一种将实体消解和查询回答结合在知识库中的框架

    A Framework for Combining Entity Resolution and Query Answering in Knowledge Bases. (arXiv:2303.07469v1 [cs.DB])

    [http://arxiv.org/abs/2303.07469](http://arxiv.org/abs/2303.07469)

    该论文提出了一种将实体解析和查询回答相结合的框架，可以解决数据中存在的不一致性，通过特殊实例的等价类和值集来定义KB的语义，设计了一个不会失败的追踪过程，生成通用解决方案，并讨论了可能的挑战。

    

    我们提出了一种新的框架，用于将实体解析和查询回答与具有元组生成依赖关系（tgds）和等式生成依赖关系（egds）作为规则的知识库（KB）相结合。我们通过特殊实例的等价类和值集来定义KB的语义。直观地，前者收集表示相同现实世界对象的所有实体，而后者收集属性的所有可选值。这种方法使我们能够解决实体并规避数据中可能存在的不一致性。然后，我们设计了一个适用于此新框架的追踪过程，并具有永远不会失败的功能。此外，当追踪过程终止时，它会生成通用解决方案，可以用于获取连接查询的确定性答案。最后，我们讨论了当追踪不终止时出现的挑战。

    We propose a new framework for combining entity resolution and query answering in knowledge bases (KBs) with tuple-generating dependencies (tgds) and equality-generating dependencies (egds) as rules. We define the semantics of the KB in terms of special instances that involve equivalence classes of entities and sets of values. Intuitively, the former collect all entities denoting the same real-world object, while the latter collect all alternative values for an attribute. This approach allows us to both resolve entities and bypass possible inconsistencies in the data. We then design a chase procedure that is tailored to this new framework and has the feature that it never fails; moreover, when the chase procedure terminates, it produces a universal solution, which in turn can be used to obtain the certain answers to conjunctive queries. We finally discuss challenges arising when the chase does not terminate.
    
[^53]: 超人工智能可以通过增加新奇性来改进人类决策的能力

    Superhuman Artificial Intelligence Can Improve Human Decision Making by Increasing Novelty. (arXiv:2303.07462v1 [cs.AI])

    [http://arxiv.org/abs/2303.07462](http://arxiv.org/abs/2303.07462)

    该研究通过分析职业围棋选手的移动决策发现，在超人工智能问世后，人类开始做出显著更好的决策，并且新颖的决策更频繁地发生，可能意味着超人工智能的发展可以改变人类的决策能力。

    

    超人工智能（AI）将如何影响人类决策，并且有哪些机制可用于支持这种影响？我们在一个领域中回答了这些问题，该领域的AI已经超过了人类的表现，分析了过去71年（1950-2021）职业围棋选手所做的超过580万个移动决策。为了回答第一个问题，我们使用了一个超人工智能程序来估计随时间变化的人类决策质量，生成了580亿个反事实的游戏模式，并将实际人类决策的胜率与反事实的AI决策的胜率进行比较。我们发现，在超人工智能问世后，人类开始做出显著更好的决策。然后，我们在时间上检查了人类玩家的策略，并发现在超人工智能问世后，新颖的决策（即以前未观察到的移动）更频繁地发生，并与更高的决策质量相关联。我们的研究结果表明，超人工智能程序的发展可能会改变人类的决策能力。

    How will superhuman artificial intelligence (AI) affect human decision making? And what will be the mechanisms behind this effect? We address these questions in a domain where AI already exceeds human performance, analyzing more than 5.8 million move decisions made by professional Go players over the past 71 years (1950-2021). To address the first question, we use a superhuman AI program to estimate the quality of human decisions across time, generating 58 billion counterfactual game patterns and comparing the win rates of actual human decisions with those of counterfactual AI decisions. We find that humans began to make significantly better decisions following the advent of superhuman AI. We then examine human players' strategies across time and find that novel decisions (i.e., previously unobserved moves) occurred more frequently and became associated with higher decision quality after the advent of superhuman AI. Our findings suggest that the development of superhuman AI programs ma
    
[^54]: AMOM: 适应性 Masking over Masking 用于条件 Masked 语言模型

    AMOM: Adaptive Masking over Masking for Conditional Masked Language Model. (arXiv:2303.07457v1 [cs.CL])

    [http://arxiv.org/abs/2303.07457](http://arxiv.org/abs/2303.07457)

    本文提出了一种适应性 Masking over Masking 策略来增强条件 Masked 语言模型的细化能力和优化效率，这种策略在神经机器翻译、摘要和代码生成任务中取得了显著的性能提升。

    

    基于 Transformer 的自回归方法已经在各种序列生成任务中取得了令人满意的性能，例如神经机器翻译、摘要和代码生成，但是推理效率较低。为了加速推理阶段，过去几年中提出了许多非自回归策略。其中，条件 Masked 语言模型 (CMLM) 是最通用的框架之一，因为它可以支持许多不同的序列生成场景，并在这些任务上取得非常有竞争力的性能。在本文中，我们进一步引入了一种简单而有效的适应性 Masking over Masking 策略来增强解码器的细化能力并使编码器的优化更加容易。在总共 \textbf{15} 个数据集上的 \textbf{3} 个不同任务（神经机器翻译、摘要和代码生成）的实验确认：我们提出的简单方法取得了显著的性能提升。

    Transformer-based autoregressive (AR) methods have achieved appealing performance for varied sequence-to-sequence generation tasks, e.g., neural machine translation, summarization, and code generation, but suffer from low inference efficiency. To speed up the inference stage, many non-autoregressive (NAR) strategies have been proposed in the past few years. Among them, the conditional masked language model (CMLM) is one of the most versatile frameworks, as it can support many different sequence generation scenarios and achieve very competitive performance on these tasks. In this paper, we further introduce a simple yet effective adaptive masking over masking strategy to enhance the refinement capability of the decoder and make the encoder optimization easier. Experiments on \textbf{3} different tasks (neural machine translation, summarization, and code generation) with \textbf{15} datasets in total confirm that our proposed simple method achieves significant performance improvement ove
    
[^55]: DRISHTI：面向视障人士的视觉导航助手

    DRISHTI: Visual Navigation Assistant for Visually Impaired. (arXiv:2303.07451v1 [cs.HC])

    [http://arxiv.org/abs/2303.07451](http://arxiv.org/abs/2303.07451)

    DRISHTI是一个采用人工智能技术的可穿戴设备，可为视障人士提供实用的导航辅助，包括检测和识别用户路径及路径前方障碍物，并通过音频输出告知用户。

    

    在当今社会中，独立生活变得越来越重要，但对于盲人而言却十分局限。盲人和视觉障碍者（BVI）需要手动支持来获取环境信息，本文介绍了一个使用人工智能技术的低成本高性能可穿戴辅助设备DRISHTI，它由摄像头模块、ESP32处理器、蓝牙模块、智能手机和扬声器组成，旨在为BVI人士提供视觉导航辅助。该系统能够检测和理解用户路径和路径前方障碍物的大致情况，并通过音频输出告知BVI用户，使他们能够自行获取方向。本文介绍了在一组视觉障碍者身上测试DRISHTI的原型机，以实现经济和性能之间的平衡。

    In today's society, where independent living is becoming increasingly important, it can be extremely constricting for those who are blind. Blind and visually impaired (BVI) people face challenges because they need manual support to prompt information about their environment. In this work, we took our first step towards developing an affordable and high-performing eye wearable assistive device, DRISHTI, to provide visual navigation assistance for BVI people. This system comprises a camera module, ESP32 processor, Bluetooth module, smartphone and speakers. Using artificial intelligence, this system is proposed to detect and understand the nature of the users' path and obstacles ahead of the user in that path and then inform BVI users about it via audio output to enable them to acquire directions by themselves on their journey. This first step discussed in this paper involves establishing a proof-of-concept of achieving the right balance of affordability and performance by testing an init
    
[^56]: 论建造有意识人工智能的伦理学

    On the ethics of constructing conscious AI. (arXiv:2303.07439v1 [cs.AI])

    [http://arxiv.org/abs/2303.07439](http://arxiv.org/abs/2303.07439)

    AI伦理学关注机器人防止其对人类行为不当，但完全忽视了机器人需要保护自己免受创造者伤害的可能性。

    

    在实用主义的转向中，AI伦理学这一新的学科被人类对其创造物的恐惧所支配，这种恐惧在广泛且长久畅销的文学传统中有所反映。弗兰肯斯坦的怪物在玛丽·雪莱的小说中反抗他的创造者；H.莱维克的1920年的戏剧中的异端魔像在狂暴中的行动；卡雷尔·奇佩克（Karel Čapek）的叛逆机器人--这些以及其他数百个类似的例子是AI伦理学关注机器人防止其对人类行为不当的背景。在这三个虚构案例中（以及许多其他案例中），这个可怜的人造物——无情地被剥削、被一个杀人的暴徒逼到绝路、为了自卫而被迫采取暴力——拥有其作者的同情。在现实生活中，极少数例外情况下，AI伦理学研究人员完全无视机器人需要保护其创造者的可能性。

    In its pragmatic turn, the new discipline of AI ethics came to be dominated by humanity's collective fear of its creatures, as reflected in an extensive and perennially popular literary tradition. Dr. Frankenstein's monster in the novel by Mary Shelley rising against its creator; the unorthodox golem in H. Leivick's 1920 play going on a rampage; the rebellious robots of Karel \v{C}apek -- these and hundreds of other examples of the genre are the background against which the preoccupation of AI ethics with preventing robots from behaving badly towards people is best understood. In each of these three fictional cases (as well as in many others), the miserable artificial creature -- mercilessly exploited, or cornered by a murderous mob, and driven to violence in self-defense -- has its author's sympathy. In real life, with very few exceptions, things are different: theorists working on the ethics of AI completely ignore the possibility of robots needing protection from their creators. The
    
[^57]: 不完全可观测Atari游戏中的无监督表示学习

    Unsupervised Representation Learning in Partially Observable Atari Games. (arXiv:2303.07437v1 [cs.LG])

    [http://arxiv.org/abs/2303.07437](http://arxiv.org/abs/2303.07437)

    本文提出了一种针对部分可观测状态的无监督状态表示学习方法PO-ST-DIM，改进了ST-DIM的对比方法，并在Atari游戏中取得了与监督方法相当的表现。

    

    状态表示学习旨在捕捉环境的潜在因素。在以前的状态表示学习研究中，对比方法比生成模型表现更好。尽管一些研究人员意识到掩蔽图像建模和对比学习表示之间的联系，但努力集中在使用掩模作为增强技术来更好地表示潜在的生成因素。利用无监督状态表示学习方法仔细研究强化学习中的不完全可观察环境尚未得到充分研究。在本文中，我们针对部分可观测状态创建了一种无监督状态表示学习方案。我们在早期的Atari 2600框架上进行了实验，该框架旨在评估表示学习模型。一种名为时空深度信息最大化（ST-DIM）的对比方法在这个基准测试中展示了最新的性能，但仍然不如其监督对应物。我们的方法称为部分可观测ST-DIM（PO-ST-DIM），通过合并部分可观测方案来改进对比方法。PO-ST-DIM优于ST-DIM，并且相对于监督方法具有竞争性能。

    State representation learning aims to capture latent factors of an environment. Contrastive methods have performed better than generative models in previous state representation learning research. Although some researchers realize the connections between masked image modeling and contrastive representation learning, the effort is focused on using masks as an augmentation technique to represent the latent generative factors better. Partially observable environments in reinforcement learning have not yet been carefully studied using unsupervised state representation learning methods.  In this article, we create an unsupervised state representation learning scheme for partially observable states. We conducted our experiment on a previous Atari 2600 framework designed to evaluate representation learning models. A contrastive method called Spatiotemporal DeepInfomax (ST-DIM) has shown state-of-the-art performance on this benchmark but remains inferior to its supervised counterpart. Our appr
    
[^58]: 多算法配置的发现

    Discovering Multiple Algorithm Configurations. (arXiv:2303.07434v1 [cs.AI])

    [http://arxiv.org/abs/2303.07434](http://arxiv.org/abs/2303.07434)

    本文扩展了算法配置以自动发现数据集中的多个模式，这些模式代表多个数据集实例，并在优化过程中自动检测。这对于多个机器人应用领域中的算法配置具有明显的益处。

    

    许多机器人从业者经常依赖经典的手工设计算法。这些算法的性能通常通过调整一组包含典型部署条件的注释示例来优化。这种设置的自动调整称为算法配置。在本文中，我们将算法配置扩展到自动发现调整数据集中的多个模式。不同于现有的工作，这些配置模式代表多个数据集实例，并在优化过程中自动检测。我们提出了三种模式发现方法：后处理方法、多阶段方法和使用多臂赌博机的在线算法。我们在多个机器人应用领域（如立体深度估计、可微分渲染、运动规划和视觉测距）中对这些方法进行测试，并在合成测试函数上进行比较。我们展示了在算法配置中检测到多个模式的明显益处。

    Many practitioners in robotics regularly depend on classic, hand-designed algorithms. Often the performance of these algorithms is tuned across a dataset of annotated examples which represent typical deployment conditions. Automatic tuning of these settings is traditionally known as algorithm configuration. In this work, we extend algorithm configuration to automatically discover multiple modes in the tuning dataset. Unlike prior work, these configuration modes represent multiple dataset instances and are detected automatically during the course of optimization. We propose three methods for mode discovery: a post hoc method, a multi-stage method, and an online algorithm using a multi-armed bandit. Our results characterize these methods on synthetic test functions and in multiple robotics application domains: stereoscopic depth estimation, differentiable rendering, motion planning, and visual odometry. We show the clear benefits of detecting multiple modes in algorithm configuration spa
    
[^59]: 基于端到端可变形注意力图神经网络的单视角肝脏网格重建

    End-to-end Deformable Attention Graph Neural Network for Single-view Liver Mesh Reconstruction. (arXiv:2303.07432v1 [cs.CV])

    [http://arxiv.org/abs/2303.07432](http://arxiv.org/abs/2303.07432)

    本文提出了一种基于端到端可变形注意力图神经网络的肝脏网格重建模型，可实时生成肝脏三角形形状，通过图神经网络处理图形数据，并提供了两种即时方法，能有效推断网格形状和位置。

    

    肿瘤放疗是治疗癌症患者的最常见方式之一，然而，精确的治疗交付对来自自由呼吸的不同运动模式的考虑是最大的挑战之一。本文提出了一种新颖的端到端注意力图神经网络模型，根据在术前阶段获得的参考分割和治疗过程中获取的二维MRI冠状切片，实时生成肝脏的三角形形状。图神经网络可以直接处理图形数据，并能捕获非欧几里德域中的隐藏模式。与现有方法相反，它完全以网格结构产生形状，并根据代理图像正确推断网格形状和位置。我们定义了两种即时方法来使肝脏网格顶点与获取的二维图像对应。

    Intensity modulated radiotherapy (IMRT) is one of the most common modalities for treating cancer patients. One of the biggest challenges is precise treatment delivery that accounts for varying motion patterns originating from free-breathing. Currently, image-guided solutions for IMRT is limited to 2D guidance due to the complexity of 3D tracking solutions. We propose a novel end-to-end attention graph neural network model that generates in real-time a triangular shape of the liver based on a reference segmentation obtained at the preoperative phase and a 2D MRI coronal slice taken during the treatment. Graph neural networks work directly with graph data and can capture hidden patterns in non-Euclidean domains. Furthermore, contrary to existing methods, it produces the shape entirely in a mesh structure and correctly infers mesh shape and position based on a surrogate image. We define two on-the-fly approaches to make the correspondence of liver mesh vertices with 2D images obtained dur
    
[^60]: 极地-VQA: 极地区域遥感冰层图像中的视觉问答

    Polar-VQA: Visual Question Answering on Remote Sensed Ice sheet Imagery from Polar Region. (arXiv:2303.07403v1 [cs.CV])

    [http://arxiv.org/abs/2303.07403](http://arxiv.org/abs/2303.07403)

    本文介绍了一项极地遥感冰层图像中的视觉问答（VQA）的任务，并提出了一个独特的数据集Polar-VQA。本研究的目标是强调VQA在冰层研究中的重要性，并对现有VQA方法在Polar-VQA数据集上进行基线研究。

    

    对于冰川学家来说，研究极地的冰层至关重要。通过深度学习技术的进步，我们现在可以从冰川数据中提取高级信息（例如，估计冰层厚度，预测未来几年的冰积累等）。然而，尚未探索基于视觉对话式深度学习方法，科学家可以通过对图像提问获取信息。本文介绍了对极地遥感冰层图像进行视觉问答（VQA）的任务。为了研究，我们在这项研究中提出了一个独特的VQA数据集Polar-VQA。该数据集中的所有图像都是使用四种类型的空中雷达收集的。本研究的主要目标是凸显在冰层研究中VQA的重要性，并在Polar-VQA数据集上进行现有VQA方法的基线研究。

    For glaciologists, studying ice sheets from the polar regions is critical. With the advancement of deep learning techniques, we can now extract high-level information from the ice sheet data (e.g., estimating the ice layer thickness, predicting the ice accumulation for upcoming years, etc.). However, a vision-based conversational deep learning approach has not been explored yet, where scientists can get information by asking questions about images. In this paper, we have introduced the task of Visual Question Answering (VQA) on remote-sensed ice sheet imagery. To study, we have presented a unique VQA dataset, Polar-VQA, in this study. All the images in this dataset were collected using four types of airborne radars. The main objective of this research is to highlight the importance of VQA in the context of ice sheet research and conduct a baseline study of existing VQA approaches on Polar-VQA dataset.
    
[^61]: 具有别名观测的潜在图的快速探索与学习

    Fast exploration and learning of latent graphs with aliased observations. (arXiv:2303.07397v1 [cs.LG])

    [http://arxiv.org/abs/2303.07397](http://arxiv.org/abs/2303.07397)

    本文介绍了一种在具有别名观测的潜在图上，能够显著提高最大化探索效率的政策算法 eFeX，相比于随机策略，该算法能够更快地恢复各种拓扑结构下的图表。

    

    考虑这种场景：一个智能体通过执行操作从一个节点到另一个节点来导航潜在图。所选操作确定了下一个访问节点上的概率分布。在每个节点处，智能体收到一个观测，但该观测不是唯一的，因此它不能唯一地标识节点，这使得问题别名化。本文旨在提供一个政策，该政策约等于最大化探索效率（即在给定的探索预算下如何恢复图表）。在非别名化的情况下，我们展示了相对于现有最先进强化学习基线的改进性能。对于别名化的情况，我们不知道适用的基线，而是展示了在各种拓扑结构下相对于随机策略更快的恢复速度，并且对于具有挑战性的拓扑结构，恢复速度比随机策略快指数倍。我们将该算法称为 eFeX（来自于 efficient exploration 的缩写）。

    Consider this scenario: an agent navigates a latent graph by performing actions that take it from one node to another. The chosen action determines the probability distribution over the next visited node. At each node, the agent receives an observation, but this observation is not unique, so it does not identify the node, making the problem aliased. The purpose of this work is to provide a policy that approximately maximizes exploration efficiency (i.e., how well the graph is recovered for a given exploration budget). In the unaliased case, we show improved performance w.r.t. state-of-the-art reinforcement learning baselines. For the aliased case we are not aware of suitable baselines and instead show faster recovery w.r.t. a random policy for a wide variety of topologies, and exponentially faster recovery than a random policy for challenging topologies. We dub the algorithm eFeX (from eFficient eXploration).
    
[^62]: 自主驾驶中基于时序空间网络的碰撞避免方法

    Sequential Spatial Network for Collision Avoidance in Autonomous Driving. (arXiv:2303.07352v1 [cs.CV])

    [http://arxiv.org/abs/2303.07352](http://arxiv.org/abs/2303.07352)

    本文提出了一种新的基于时序空间网络的碰撞避免算法，能够有效关联输入图像的区域特征，以实现自主驾驶领域中的碰撞避免。

    

    在自主驾驶领域中，特别是在碰撞避免方面，已经应用了多种自主驾驶策略。通过调整自主车辆的轨迹避免与周围车辆轨迹的交叉或重叠，以实现碰撞避免的目的。本文旨在解决由于回归模型难以有效地关联输入图像的区域特征而引起的问题，提出了一种新的基于时序空间网络的碰撞避免算法。

    Several autonomous driving strategies have been applied to autonomous vehicles, especially in the collision avoidance area. The purpose of collision avoidance is achieved by adjusting the trajectory of autonomous vehicles (AV) to avoid intersection or overlap with the trajectory of surrounding vehicles. A large number of sophisticated vision algorithms have been designed for target inspection, classification, and other tasks, such as ResNet, YOLO, etc., which have achieved excellent performance in vision tasks because of their ability to accurately and quickly capture regional features. However, due to the variability of different tasks, the above models achieve good performance in capturing small regions but are still insufficient in correlating the regional features of the input image with each other. In this paper, we aim to solve this problem and develop an algorithm that takes into account the advantages of CNN in capturing regional features while establishing feature correlation 
    
[^63]: 并行顶点扩散用于统一视觉定位

    Parallel Vertex Diffusion for Unified Visual Grounding. (arXiv:2303.07216v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.07216](http://arxiv.org/abs/2303.07216)

    本文提出了一种并行顶点扩散模型(PVD)，用于统一视觉定位中的高维扩展，解决了顺序生成高维顶点序列容易出现的问题，以及由于顶点数量不足而导致的对象轮廓匹配不准确的问题。

    

    统一的视觉定位追求一种简单和通用的技术路线，以利用多任务数据，减少任务特定的设计。最先进的方法通常将框和掩码作为顶点序列呈现，以建模引用检测和分割作为自回归顺序顶点生成范例。然而，顺序生成高维顶点序列容易出错，因为序列的上游仍保持静态，并且无法基于下游顶点信息进行精细化的改进，即使存在重大的位置差距。此外，由于顶点数量有限，对象具有复杂轮廓的较差拟合限制了性能的上限。为了应对这一困境，我们提出了一种用扩散模型进行高维扩展的并行顶点生成范例，只需修改噪声维度即可。我们范例的直观实现是并行顶点扩散 (PVD)，直接将顶点坐标设置为生成目标。

    Unified visual grounding pursues a simple and generic technical route to leverage multi-task data with less task-specific design. The most advanced methods typically present boxes and masks as vertex sequences to model referring detection and segmentation as an autoregressive sequential vertex generation paradigm. However, generating high-dimensional vertex sequences sequentially is error-prone because the upstream of the sequence remains static and cannot be refined based on downstream vertex information, even if there is a significant location gap. Besides, with limited vertexes, the inferior fitting of objects with complex contours restricts the performance upper bound. To deal with this dilemma, we propose a parallel vertex generation paradigm for superior high-dimension scalability with a diffusion model by simply modifying the noise dimension. An intuitive materialization of our paradigm is Parallel Vertex Diffusion (PVD) to directly set vertex coordinates as the generation targe
    
[^64]: 稀疏神经网络中的神经元进化监督特征选择

    Supervised Feature Selection with Neuron Evolution in Sparse Neural Networks. (arXiv:2303.07200v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2303.07200](http://arxiv.org/abs/2303.07200)

    本文提出了一种使用神经元进化的稀疏神经网络方法，名为 NeuroFS，能够有效地派生出信息丰富的特征子集，且在实验中具有最高排名得分。

    

    特征选择从数据中选择信息量高的变量子集，不仅可以增强模型解释性和性能，而且可以减轻资源需求。最近，越来越多的人开始关注使用神经网络进行特征选择。然而，现有的方法通常在应用于高维度数据集时会受到高计算成本的困扰。在本文中，我们受到进化过程的启发，提出了一种使用稀疏神经网络的新型资源有效的监督式特征选择方法，命名为 "NeuroFS"。通过从零开始训练的稀疏神经网络逐步修剪无信息的特征，NeuroFS有效地派生出一个信息丰富的特征子集。通过对 $11$ 种不同类型的低维和高维真实世界基准数据集进行多个实验，我们证明了 NeuroFS 在考虑到最先进的监督特征选择模型时具有最高的排名得分。

    Feature selection that selects an informative subset of variables from data not only enhances the model interpretability and performance but also alleviates the resource demands. Recently, there has been growing attention on feature selection using neural networks. However, existing methods usually suffer from high computational costs when applied to high-dimensional datasets. In this paper, inspired by evolution processes, we propose a novel resource-efficient supervised feature selection method using sparse neural networks, named \enquote{NeuroFS}. By gradually pruning the uninformative features from the input layer of a sparse neural network trained from scratch, NeuroFS derives an informative subset of features efficiently. By performing several experiments on $11$ low and high-dimensional real-world benchmarks of different types, we demonstrate that NeuroFS achieves the highest ranking-based score among the considered state-of-the-art supervised feature selection models. The code 
    
[^65]: 基于深度学习的时间序列因果推断量化北极放大的原因

    Quantifying Causes of Arctic Amplification via Deep Learning based Time-series Causal Inference. (arXiv:2303.07122v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.07122](http://arxiv.org/abs/2303.07122)

    该研究提出了一种基于循环神经网络的时间序列因果推断模型TCINet，用于推断大气过程对海冰融化的因果效应。通过实验证明，该模型能够显著提高量化北极海冰融化的主要原因的能力。

    

    北极变暖，也称北极放大，由多种大气和海洋因素导致，但其基础热力因素的详细情况仍不清楚。使用固定治疗效应策略推断大气过程对海冰融化的因果效应会导致不现实的反事实估计。这样的模型也容易受到时间变化的混淆的影响而引起偏差。为了解决这些挑战，我们提出了TCINet - 一种基于循环神经网络的时间序列因果推断模型，以连续治疗方式推断因果关系。通过对合成和观测数据的实验，我们展示了我们的研究如何大大提高量化北极海冰融化的主要原因的能力。

    The warming of the Arctic, also known as Arctic amplification, is led by several atmospheric and oceanic drivers, however, the details of its underlying thermodynamic causes are still unknown. Inferring the causal effects of atmospheric processes on sea ice melt using fixed treatment effect strategies leads to unrealistic counterfactual estimations. Such models are also prone to bias due to time-varying confoundedness. In order to tackle these challenges, we propose TCINet - time-series causal inference model to infer causation under continuous treatment using recurrent neural networks. Through experiments on synthetic and observational data, we show how our research can substantially improve the ability to quantify the leading causes of Arctic sea ice melt.
    
[^66]: 意义深远的人类指令：作为实现自主武器系统道德和法律责任的方法的高级控制指令

    Meaningful human command: Advance control directives as a method to enable moral and legal responsibility for autonomous weapons systems. (arXiv:2303.06813v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.06813](http://arxiv.org/abs/2303.06813)

    本文探讨了如何确保在超越实时或非常缓慢的操作中的自主系统的道德和法律责任，并提出了建立“预先控制指令”框架的“自主命令”，来实现自主武器系统的问责和责任所需的深思熟虑的过程。

    

    21世纪战争的速度正在加快，常规部队与大规模使用自主系统和人机集成相结合。然而，一个重要的挑战是人类如何确保在正常时间参数之外运行的系统的道德和法律责任。本章考虑了人类是否可以站在实时之外，并通过先建立合同授权自主系统的行动，在未来的情况下特别是在超越实时或非常缓慢的操作中，人类的意识和集中力可能无法充分知情。在“预先医疗法律先例”中找到的经验表明，通过“预先控制指令”（ACD）可以实现武器系统的问责和责任所需的耗时、深思熟虑的过程，提出了“自主命令”的构想，并通过ACD的构建和法律伦理框架进行支撑和合法化。这将使自主武器系统的接受责任和问责制成为可能，并建立意义深远的人类控制。

    21st Century war is increasing in speed, with conventional forces combined with massed use of autonomous systems and human-machine integration. However, a significant challenge is how humans can ensure moral and legal responsibility for systems operating outside of normal temporal parameters. This chapter considers whether humans can stand outside of real time and authorise actions for autonomous systems by the prior establishment of a contract, for actions to occur in a future context particularly in faster than real time or in very slow operations where human consciousness and concentration could not remain well informed. The medical legal precdent found in 'advance care directives' suggests how the time-consuming, deliberative process required for accountability and responsibility of weapons systems may be achievable outside real time captured in an 'advance control driective' (ACD). The chapter proposes 'autonomy command' scaffolded and legitimised through the construction of ACD a
    
[^67]: 规划优化问题：公式和框架

    The Planner Optimization Problem: Formulations and Frameworks. (arXiv:2303.06768v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.06768](http://arxiv.org/abs/2303.06768)

    本研究提出了统一的规划优化问题公式和开放式规划优化框架，可帮助解决自动调整规划内部参数的挑战和缺乏统一问题定义和软件框架等问题。

    

    确定规划的内部参数对于最大化规划器的性能至关重要。然而，自动调整针对问题实例的内部参数尤其具有挑战性。最近的一系列工作集中于学习规划参数生成器，但缺乏一致的问题定义和软件框架。本文提出了统一的规划优化问题（POP）公式，并提供了开放式规划优化框架（OPOF），这是一个高度可扩展的软件框架，可以以可重用的方式指定和解决这些问题。

    Identifying internal parameters for planning is crucial to maximizing the performance of a planner. However, automatically tuning internal parameters which are conditioned on the problem instance is especially challenging. A recent line of work focuses on learning planning parameter generators, but lack a consistent problem definition and software framework. This work proposes the unified planner optimization problem (POP) formulation, along with the Open Planner Optimization Framework (OPOF), a highly extensible software framework to specify and to solve these problems in a reusable manner.
    
[^68]: 通过不确定性感知的强化学习，为人-机协同机器人智能决策提供方法

    Decision Making for Human-in-the-loop Robotic Agents via Uncertainty-Aware Reinforcement Learning. (arXiv:2303.06710v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.06710](http://arxiv.org/abs/2303.06710)

    该论文提出了一种基于强化学习的半自主代理机器人方法，在对任务成功结果的信心低时请求外部帮助，有效降低专家调用数量。

    

    在人-机协同范式中，机器人智能代理能够在大部分时间内自主完成任务，当需要帮助时，可以向外部专家寻求帮助。然而，关键是要知道何时请求外部帮助：太少的请求会导致机器人犯错，但太多的请求会使专家过载。本文提出了一种基于强化学习的方法来解决这个问题，其中半自主代理在对任务成功结果的信心低时请求外部帮助。置信度是通过估计当前状态的回报方差来计算的。我们展示了这个估计可以通过类似贝尔曼递归的训练过程逐步改进。在具有完全和部分可观察状态信息的离散导航问题中，我们展示了我们的方法在运行时利用有限的专家调用预算时是有效的，尽管在训练时没有访问专家。

    In a Human-in-the-Loop paradigm, a robotic agent is able to act mostly autonomously in solving a task, but can request help from an external expert when needed. However, knowing when to request such assistance is critical: too few requests can lead to the robot making mistakes, but too many requests can overload the expert. In this paper, we present a Reinforcement Learning based approach to this problem, where a semi-autonomous agent asks for external assistance when it has low confidence in the eventual success of the task. The confidence level is computed by estimating the variance of the return from the current state. We show that this estimate can be iteratively improved during training using a Bellman-like recursion. On discrete navigation problems with both fully- and partially-observable state information, we show that our method makes effective use of a limited budget of expert calls at run-time, despite having no access to the expert at training time.
    
[^69]: 人工智能与人类文本协作任务中交互设计空间的映射

    Mapping the Design Space of Interactions in Human-AI Text Co-creation Tasks. (arXiv:2303.06430v1 [cs.AI])

    [http://arxiv.org/abs/2303.06430](http://arxiv.org/abs/2303.06430)

    本文提出了一系列内容生成任务及其相应的人工智能与人类交互模式，鼓励研究社区专注于更复杂和相互依赖的任务，这些任务需要更高水平的人类参与。

    This paper presents a spectrum of content generation tasks and their corresponding human-AI interaction patterns, encouraging the research community to focus on more complex and interdependent tasks that require greater levels of human involvement.

    大型语言模型（LLMs）展示了令人印象深刻的文本生成能力，促使我们重新考虑人工智能与人类协作的未来以及人类如何与LLMs交互。在本文中，我们提出了一系列内容生成任务及其相应的人工智能与人类交互模式。这些任务包括：1）具有最小人工智能与人类交互的固定范围内容策划任务，2）具有精确人工智能与人类交互的独立创意任务，以及3）具有迭代人工智能与人类交互的复杂且相互依赖的创意任务。我们鼓励生成AI和HCI研究社区专注于更复杂和相互依赖的任务，这些任务需要更高水平的人类参与。

    Large Language Models (LLMs) have demonstrated impressive text generation capabilities, prompting us to reconsider the future of human-AI co-creation and how humans interact with LLMs. In this paper, we present a spectrum of content generation tasks and their corresponding human-AI interaction patterns. These tasks include: 1) fixed-scope content curation tasks with minimal human-AI interactions, 2) independent creative tasks with precise human-AI interactions, and 3) complex and interdependent creative tasks with iterative human-AI interactions. We encourage the generative AI and HCI research communities to focus on the more complex and interdependent tasks, which require greater levels of human involvement.
    
[^70]: HiNet: 一种具有层次信息提取的新型多场景和多任务学习方法

    HiNet: Novel Multi-Scenario & Multi-Task Learning with Hierarchical Information Extraction. (arXiv:2303.06095v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2303.06095](http://arxiv.org/abs/2303.06095)

    HiNet是一种多场景和多任务学习网络，具有层次信息提取和场景感知注意，可以增强推荐系统的学习能力和效果。

    

    在工业应用的许多推荐系统中，多场景和多任务学习已被广泛应用，其中一种有效和实用的方法是在混合专家（MoE）架构的基础上进行多场景迁移学习。然而，以将所有信息投影到同一特征空间为目标的MoE方法无法有效地处理各种场景和任务之间的复杂关系，导致性能不如人意。为了解决这个问题，我们提出了一种用于多场景和多任务推荐的Hierarchical information extraction Network（HiNet），该网络基于从粗到细的知识转移方案实现分层提取。分层网络的多个提取层使模型能够增强跨场景传递有价值信息的能力，同时保留场景和任务的特定特征。此外，引入一种新颖的场景感知注意网络，以增强模型对任务相关性和场景独特性的学习能力。实验结果表明，与现有方法相比，所提出的HiNet具有更高的效果和优越性。

    Multi-scenario & multi-task learning has been widely applied to many recommendation systems in industrial applications, wherein an effective and practical approach is to carry out multi-scenario transfer learning on the basis of the Mixture-of-Expert (MoE) architecture. However, the MoE-based method, which aims to project all information in the same feature space, cannot effectively deal with the complex relationships inherent among various scenarios and tasks, resulting in unsatisfactory performance. To tackle the problem, we propose a Hierarchical information extraction Network (HiNet) for multi-scenario and multi-task recommendation, which achieves hierarchical extraction based on coarse-to-fine knowledge transfer scheme. The multiple extraction layers of the hierarchical network enable the model to enhance the capability of transferring valuable information across scenarios while preserving specific features of scenarios and tasks. Furthermore, a novel scenario-aware attentive netw
    
[^71]: 具有线性函数逼近的重尾奖励方差感知鲁棒强化学习

    Variance-aware robust reinforcement learning with linear function approximation under heavy-tailed rewards. (arXiv:2303.05606v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.05606](http://arxiv.org/abs/2303.05606)

    本文提出了AdaOFUL和VARA两种算法，用于在存在有限方差的重尾奖励情况下进行在线顺序决策，其中AdaOFUL具有状态-of-the-art的遗憾界，VARA达到了更紧密的方差感知遗憾界。

    

    本文提出了两种算法AdaOFUL和VARA，用于在仅存在有限方差的重尾奖励情况下进行在线顺序决策。对于线性随机赌徒，我们通过修改自适应Huber回归并提出AdaOFUL来解决重尾奖励问题。AdaOFUL达到了状态-of-the-art的遗憾界，即$ \widetilde{O}\big（d\big(\sum_{t=1}^T\nu_{t}^2\big)^{1/2}+d\big)$，其中$\nu_{t}^2$是第$t$轮奖励观测到的条件方差，$d$是特征维度，$\widetilde{O}（\cdot）$ 隐藏对数依赖性。在AdaOFUL的基础上，我们提出了VARA用于线性MDP，它达到了更紧密的方差感知遗憾界，即 $ \widetilde{O}(d\sqrt{HG^*K})$。这里，$H$是事件的长度，$K$是事件的数量，$G^*$是较小的依赖于实例的量，当在其他实例相关量被限制时，它可以被边界化。

    This paper presents two algorithms, AdaOFUL and VARA, for online sequential decision-making in the presence of heavy-tailed rewards with only finite variances. For linear stochastic bandits, we address the issue of heavy-tailed rewards by modifying the adaptive Huber regression and proposing AdaOFUL. AdaOFUL achieves a state-of-the-art regret bound of $\widetilde{O}\big(d\big(\sum_{t=1}^T \nu_{t}^2\big)^{1/2}+d\big)$ as if the rewards were uniformly bounded, where $\nu_{t}^2$ is the observed conditional variance of the reward at round $t$, $d$ is the feature dimension, and $\widetilde{O}(\cdot)$ hides logarithmic dependence. Building upon AdaOFUL, we propose VARA for linear MDPs, which achieves a tighter variance-aware regret bound of $\widetilde{O}(d\sqrt{HG^*K})$. Here, $H$ is the length of episodes, $K$ is the number of episodes, and $G^*$ is a smaller instance-dependent quantity that can be bounded by other instance-dependent quantities when additional structural conditions on the 
    
[^72]: 离散-连续域中的神经概率逻辑编程

    Neural Probabilistic Logic Programming in Discrete-Continuous Domains. (arXiv:2303.04660v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.04660](http://arxiv.org/abs/2303.04660)

    介绍了一种名为DeepSeaProbLog的神经概率逻辑编程语言，将深度概率编程技术纳入其中，支持在逻辑约束条件下推断和学习离散和连续概率分布，并通过实验证明其优势。

    

    神经符号人工智能（NeSy）允许神经网络利用逻辑形式的符号背景知识。NeSy已经被证明在有限的数据范围内有助于学习，并且有助于推断非分布数据。概率NeSy着重于将神经网络与逻辑和概率论相结合，从而还允许在不确定性下学习。当前概率NeSy系统（如DeepProbLog）的一个主要限制是它们局限于有限概率分布，即离散随机变量。相比之下，深度概率编程（DPP）在建模和优化连续概率分布方面表现出色。因此，我们介绍了DeepSeaProbLog，这是一种神经概率逻辑编程语言，将DPP技术纳入NeSy中。这样做的结果是在逻辑约束条件下支持离散和连续概率分布的推断和学习。我们的主要贡献是1）DeepSeaProbLog的语义，2）它的高效学习算法，3）它的实现，以及4）一组全面的实验，证明了它在离散和连续领域的建模、推断和学习方面相对于当前NeSy方法的优势。

    Neural-symbolic AI (NeSy) allows neural networks to exploit symbolic background knowledge in the form of logic. It has been shown to aid learning in the limited data regime and to facilitate inference on out-of-distribution data. Probabilistic NeSy focuses on integrating neural networks with both logic and probability theory, which additionally allows learning under uncertainty. A major limitation of current probabilistic NeSy systems, such as DeepProbLog, is their restriction to finite probability distributions, i.e., discrete random variables. In contrast, deep probabilistic programming (DPP) excels in modelling and optimising continuous probability distributions. Hence, we introduce DeepSeaProbLog, a neural probabilistic logic programming language that incorporates DPP techniques into NeSy. Doing so results in the support of inference and learning of both discrete and continuous probability distributions under logical constraints. Our main contributions are 1) the semantics of DeepS
    
[^73]: Dish-TS: 一种缓解时间序列预测中分布偏移的通用范例

    Dish-TS: A General Paradigm for Alleviating Distribution Shift in Time Series Forecasting. (arXiv:2302.14829v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.14829](http://arxiv.org/abs/2302.14829)

    Dish-TS是一种通用的神经网络模型，用于缓解时间序列预测中的分布偏移。该模型通过引入系数网络（CONET）来更好地估计分布。在时间序列预测任务中，将Lookback窗口作为输入空间，Horizon窗口作为输出空间，将分布偏移总结为内部空间偏移和不同空间偏移两类。

    

    时间序列预测中的分布偏移指的是时间序列在时间上分布的变化，它很大程度上阻碍了时间序列预测模型的性能。现有针对时间序列分布偏移的研究大多局限于分布量化，更重要的是，忽视了Lookback和Horizon之间的潜在偏移。为了解决上述问题，我们系统地将时间序列中的分布偏移总结为两类。将Lookback窗口视为输入空间，Horizon窗口视为输出空间，存在(i)内部空间偏移，即在输入空间内的分布随时间保持偏移，以及(ii)不同空间偏移，在输入空间和输出空间之间分布偏移。然后，我们引入了一种名为Dish-TS的通用神经模型来缓解时间序列中的分布偏移。具体而言，为了更好地估计分布，我们提出了系数网络（CONET），它可以是任何神经网络架构，用于映射输入序列。

    The distribution shift in Time Series Forecasting (TSF), indicating series distribution changes over time, largely hinders the performance of TSF models. Existing works towards distribution shift in time series are mostly limited in the quantification of distribution and, more importantly, overlook the potential shift between lookback and horizon windows. To address above challenges, we systematically summarize the distribution shift in TSF into two categories. Regarding lookback windows as input-space and horizon windows as output-space, there exist (i) intra-space shift, that the distribution within the input-space keeps shifted over time, and (ii) inter-space shift, that the distribution is shifted between input-space and output-space. Then we introduce, Dish-TS, a general neural paradigm for alleviating distribution shift in TSF. Specifically, for better distribution estimation, we propose the coefficient net (CONET), which can be any neural architectures, to map input sequences in
    
[^74]: 大型语言模型在 Theory-of-Mind 任务的微小改变上失败

    Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks. (arXiv:2302.08399v5 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.08399](http://arxiv.org/abs/2302.08399)

    大型语言模型在微小的理论任务改动上容易失败，表明在直觉心理学模型评估中需要持怀疑态度，且失败案例应被重视。

    

    直觉心理学是常识推理的支柱。在机器智能中复制这种推理是迈向类人工智能的一个重要基石。最近，有几项任务和基准用于检查大型语言模型中这种推理，特别关注心灵理论任务中的信念归属。这些任务既有成功案例也有失败案例。我们特别考虑了一个最近声称的成功案例，并展示了维持ToM原则的小幅变化使结果大相径庭。我们认为，一般来说，在直觉心理学模型评估中，零假设应该持怀疑态度，并且离群故障案例应该超过平均成功率。我们还考虑了更强大的LLM（Large-Large Models）在理解心理学任务上可能取得的未来成功对人类ToM任务意味着什么。

    Intuitive psychology is a pillar of common-sense reasoning. The replication of this reasoning in machine intelligence is an important stepping-stone on the way to human-like artificial intelligence. Several recent tasks and benchmarks for examining this reasoning in Large-Large Models have focused in particular on belief attribution in Theory-of-Mind tasks. These tasks have shown both successes and failures. We consider in particular a recent purported success case, and show that small variations that maintain the principles of ToM turn the results on their head. We argue that in general, the zero-hypothesis for model evaluation in intuitive psychology should be skeptical, and that outlying failure cases should outweigh average success rates. We also consider what possible future successes on Theory-of-Mind tasks by more powerful LLMs would mean for ToM tasks with people.
    
[^75]: 用于认知决策的量子电路组件

    Quantum Circuit Components for Cognitive Decision-Making. (arXiv:2302.03012v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2302.03012](http://arxiv.org/abs/2302.03012)

    本文将一些非经典的人类决策模型成功地应用于量子计算机电路，并通过量子概率、角度和子空间等方式描述了这些模型和它们在量子计算机上的实现和研究。

    

    本论文表明，一些非经典的人类决策模型可以成功地作为电路在量子计算机上运行。自20世纪60年代以来，许多观察到的认知行为已被证明违反了基于经典概率和集合论的规则。例如，问题提出的顺序会影响参与者是否回答“是”或“否”，因此回答两个问题“是”的人口不能被建模为两个固定集合的交集。然而，它可以被建模为不同顺序进行的一系列投影。这和其他示例已经成功地使用了量子概率来描述，这依赖于比较子空间之间的角度，而不是子集之间的体积。现在在2020年初，量子计算机已经达到了一定水平，一些量子认知模型可以在量子硬件上实现并研究，将心理状态表示为qubit寄存器中的状态，认知操作和决策操作通过量子门来实现。

    This paper demonstrates that some nonclassical models of human decision-making can be run successfully as circuits on quantum computers. Since the 1960s, many observed cognitive behaviors have been shown to violate rules based on classical probability and set theory. For example, the order in which questions are posed affects whether participants answer 'yes' or 'no', so the population that answers `yes' to both questions cannot be modeled as the intersection of two fixed sets. It can however be modeled as a sequence of projections carried out in different orders. This and other examples have been described successfully using quantum probability, which relies on comparing angles between subspaces rather than volumes between subsets. Now in the early 2020s, quantum computers have reached the point where some of these quantum cognitive models can be implemented and investigated on quantum hardware, representing the mental states in qubit registers, and the cognitive operations and decisi
    
[^76]: 学习双层知识图谱的表示以进行超越链接预测的推理

    Learning Representations of Bi-level Knowledge Graphs for Reasoning beyond Link Prediction. (arXiv:2302.02601v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.02601](http://arxiv.org/abs/2302.02601)

    本文提出了一种基于双层知识图谱的方法来学习嵌入，将三元组之间的关系考虑进去，并使用数据增强策略来增加合理的三元组。

    

    知识图谱使用三元组来表示已知事实。现有的知识图谱嵌入方法仅考虑实体之间的连接，而本文提出考虑三元组之间的关系。本文定义了一个更高级的三元组来表示三元组之间的关系，例如，$\langle T_1$, PrerequisiteFor, $T_2\rangle$，其中PrerequisiteFor是更高级别的关系。我们定义一个由基本级别和更高级别的三元组组成的双层知识图谱。我们还提出了一种基于双层知识图谱上的随机游走的数据增强策略来增加合理的三元组。我们的模型BiVE通过考虑基本级别和更高级别三元组的结构来学习嵌入。

    Knowledge graphs represent known facts using triplets. While existing knowledge graph embedding methods only consider the connections between entities, we propose considering the relationships between triplets. For example, let us consider two triplets $T_1$ and $T_2$ where $T_1$ is (Academy_Awards, Nominates, Avatar) and $T_2$ is (Avatar, Wins, Academy_Awards). Given these two base-level triplets, we see that $T_1$ is a prerequisite for $T_2$. In this paper, we define a higher-level triplet to represent a relationship between triplets, e.g., $\langle T_1$, PrerequisiteFor, $T_2\rangle$ where PrerequisiteFor is a higher-level relation. We define a bi-level knowledge graph that consists of the base-level and the higher-level triplets. We also propose a data augmentation strategy based on the random walks on the bi-level knowledge graph to augment plausible triplets. Our model called BiVE learns embeddings by taking into account the structures of the base-level and the higher-level tripl
    
[^77]: 基于语义增强的时间图网络用于内容流行度预测

    Semantics-enhanced Temporal Graph Networks for Content Popularity Prediction. (arXiv:2301.12355v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.12355](http://arxiv.org/abs/2301.12355)

    本研究提出了一种基于语义增强的时间图网络，名为STGN，用于内容流行度预测。该网络可以更好地利用表面拓扑结构背后的隐含关系，并采用新的时间聚合机制来捕捉用户偏好的动态变化。实验结果表明，STGN在内容流行度预测方面表现优于最先进方法，特别是对于长期预测。

    

    高清视频流服务和大型神经网络模型的兴起，例如GPT，意味着互联网流量的巨大增长。为了缓解流量压力，已经提出了具有网络中存储的体系结构，以在靠近用户的设备上缓存受欢迎的内容。相应地，为了最大化缓存利用率，必须设计一种有效的流行度预测方法。在这方面，使用动态图神经网络(DGNN)模型预测流行度取得了显着的性能。然而，DGNN模型仍然存在处理大部分用户处于非活动状态的稀疏数据集时的困难。因此，我们提出了一种改革性的时间图网络，称为语义增强的时间图网络(STGN)，它将额外的语义信息附加到用户 - 内容二分图中，并能更好地利用表面拓扑结构背后的隐含关系。在此基础上，我们设计了一种新的时间聚合机制，以捕捉并结合用户偏好的动态变化。真实数据集的实验结果表明，STGN比最先进的方法在内容流行度预测方面表现更好，特别是对于远期预测。

    The surging demand for high-definition video streaming services and large neural network models (e.g., Generative Pre-trained Transformer, GPT) implies a tremendous explosion of Internet traffic. To mitigate the traffic pressure, architectures with in-network storage have been proposed to cache popular contents at devices in closer proximity to users. Correspondingly, in order to maximize caching utilization, it becomes essential to devise an effective popularity prediction method. In that regard, predicting popularity with dynamic graph neural network (DGNN) models achieve remarkable performance. However, DGNN models still suffer from tackling sparse datasets where most users are inactive. Therefore, we propose a reformative temporal graph network, named semantics-enhanced temporal graph network (STGN), which attaches extra semantic information into the user-content bipartite graph and could better leverage implicit relationships behind the superficial topology structure. On top of th
    
[^78]: SegViz：基于联邦学习的多器官分割框架，适用于具有部分注释的异构数据集

    SegViz: A federated-learning based framework for multi-organ segmentation on heterogeneous data sets with partial annotations. (arXiv:2301.07074v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.07074](http://arxiv.org/abs/2301.07074)

    SegViz是一种基于联邦学习的框架，用于从分布式的非i.i.d数据集中训练具有部分注释的分割模型。使用FedBN作为聚合策略的SegViz框架在外部BTCV集上表现出优异的性能，分割的dice分数分别为0.93、0.83、0.55和0.75。

    SegViz is a federated learning-based framework for training segmentation models from distributed non-i.i.d datasets with partial annotations. The SegViz framework using FedBN as the aggregation strategy demonstrated excellent performance on the external BTCV set with dice scores of 0.93, 0.83, 0.55, and 0.75 for segmentation.

    分割是医学图像深度学习中最基本的任务之一，由于其多个下游临床应用而备受关注。然而，为医学图像生成手动注释是耗时的、需要高技能的、昂贵的工作，特别是对于3D图像。一个潜在的解决方案是从多个组的部分注释数据集中聚合知识，使用联邦学习协作训练全局模型。为此，我们提出了SegViz，一种基于联邦学习的框架，用于从分布式的非i.i.d数据集中训练具有部分注释的分割模型。将SegViz的性能与分别在每个数据集上单独训练模型以及集中聚合所有数据集并训练单个模型进行比较。使用FedBN作为聚合策略的SegViz框架在外部BTCV集上表现出优异的性能，分割的dice分数分别为0.93、0.83、0.55和0.75。

    Segmentation is one of the most primary tasks in deep learning for medical imaging, owing to its multiple downstream clinical applications. However, generating manual annotations for medical images is time-consuming, requires high skill, and is an expensive effort, especially for 3D images. One potential solution is to aggregate knowledge from partially annotated datasets from multiple groups to collaboratively train global models using Federated Learning. To this end, we propose SegViz, a federated learning-based framework to train a segmentation model from distributed non-i.i.d datasets with partial annotations. The performance of SegViz was compared against training individual models separately on each dataset as well as centrally aggregating all the datasets in one place and training a single model. The SegViz framework using FedBN as the aggregation strategy demonstrated excellent performance on the external BTCV set with dice scores of 0.93, 0.83, 0.55, and 0.75 for segmentation 
    
[^79]: 支付宝用户下一步意图预测的概念知识图谱

    A Concept Knowledge Graph for User Next Intent Prediction at Alipay. (arXiv:2301.00503v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.00503](http://arxiv.org/abs/2301.00503)

    本文提出了一种基于概念知识图谱的用户下一步意图预测技术，实现了在支付宝网络平台上对1亿活跃用户的服务，并且在保持可解释性的情况下，有效地提高了下游任务的性能表现。

    

    本文介绍了使用概念知识图谱进行用户下一步意图预测的技术。该系统已在支付宝网络平台上部署，为超过1亿活跃用户提供服务。我们提出AlipayKG，用于显式地描述用户意图的离线概念知识图谱，模拟了用户的历史行为、丰富的内容以及它们之间的关系。我们提出了一种基于Transformer的模型，将来自知识图谱的专家规则整合到模型中以推断在线用户的下一步意图。实验结果表明，所提出的系统可以有效地提高下游任务的性能，同时保持可解释性。

    This paper illustrates the technologies of user next intent prediction with a concept knowledge graph. The system has been deployed on the Web at Alipay, serving more than 100 million daily active users. To explicitly characterize user intent, we propose AlipayKG, which is an offline concept knowledge graph in the Life-Service domain modeling the historical behaviors of users, the rich content interacted by users and the relations between them. We further introduce a Transformer-based model which integrates expert rules from the knowledge graph to infer the online user's next intent. Experimental results demonstrate that the proposed system can effectively enhance the performance of the downstream tasks while retaining explainability.
    
[^80]: SceneRF: 利用辐射场的自监督单目3D场景重建

    SceneRF: Self-Supervised Monocular 3D Scene Reconstruction with Radiance Fields. (arXiv:2212.02501v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.02501](http://arxiv.org/abs/2212.02501)

    SceneRF利用自监督学习结合NeRF的辐射场技术，无需深度监督，只需使用图像序列训练，可以高效处理大场景，能够生成新的深度视图并进行3D场景重建，性能在室内外场景中优于所有基线方法。

    

    二维图像三维重建的研究已经得到广泛关注，通常需要使用深度监督来进行训练。为了减少对昂贵数据集的依赖，我们提出了SceneRF方法，这是一种完全基于图像序列进行训练的自监督单目场景重建方法。基于最新的神经辐射场技术(NeRF)，我们优化了一个辐射场，并采用了显式深度优化和新颖的概率采样策略来有效处理大场景。在推理阶段，只需输入单个图像即可生成新的深度视图，并将其融合在一起以获得3D场景重建。全面的实验结果表明，我们在室内BundleFusion和室外SemanticKITTI场景下，性能优于最近的所有基线，能够更好地进行新视角深度合成和场景重建。我们的代码可在https://astra-vision.github.io/SceneRF上获得。

    3D reconstruction from 2D image was extensively studied, training with depth supervision. To relax the dependence to costly-acquired datasets, we propose SceneRF, a self-supervised monocular scene reconstruction method using only posed image sequences for training. Fueled by the recent progress in neural radiance fields (NeRF) we optimize a radiance field though with explicit depth optimization and a novel probabilistic sampling strategy to efficiently handle large scenes. At inference, a single input image suffices to hallucinate novel depth views which are fused together to obtain 3D scene reconstruction. Thorough experiments demonstrate that we outperform all recent baselines for novel depth views synthesis and scene reconstruction, on indoor BundleFusion and outdoor SemanticKITTI. Our code is available at https://astra-vision.github.io/SceneRF.
    
[^81]: 向导航即攻击者所愿？建立拜占庭鲁棒性的联邦学习体系下的代理人

    Navigation as Attackers Wish? Towards Building Byzantine-Robust Embodied Agents under Federated Learning. (arXiv:2211.14769v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.14769](http://arxiv.org/abs/2211.14769)

    本文研究了联邦学习体系下代理人学习中可能出现的攻击和防御策略，建立了全联邦拜占庭鲁棒的代理人学习模型。其中，导航即攻击者所愿（NAW）是一种简单而有效的攻击策略，而基于离群点检测的防御训练方法可以有效减轻NAW攻击的影响，提高代理人学习的全局鲁棒性。

    

    联邦化体系下的代理人学习通过在本地客户端（即不同环境）中保持数据来保护个人视觉环境的数据隐私。然而，在联邦学习下，由于本地数据对服务器是不可访问的，攻击者可能轻易地污染本地客户端的训练数据，从而在不被通知的情况下在代理人中建立后门。使用这样的代理人会对人类构成潜在危害，因为攻击者可以轻松地通过后门操纵代理人进行导航和控制。为了实现全联邦拜占庭鲁棒的代理人学习，在本文中，我们研究了视觉与语言导航（VLN）任务中的攻击和防御，其中代理人需要跟随自然语言指令来导航室内环境。首先，我们介绍了一种简单而有效的攻击策略，即导航即攻击者所愿（NAW），其中恶意客户端通过操纵本地轨迹数据来向全局模型植入后门。结果表明，NAW可以实现高攻击成功率，而且性能下降微不足道。为了防止NAW攻击，我们提出了一种防御训练方法，该方法利用离群点检测的概念来识别和删除恶意客户端。我们在VLN任务上的实验表明，所提出的防御方法可以有效地减轻NAW攻击的影响，提高联邦化体系下代理人学习的全局鲁棒性。

    Federated embodied agent learning protects the data privacy of individual visual environments by keeping data locally at each client (the individual environment) during training. However, since the local data is inaccessible to the server under federated learning, attackers may easily poison the training data of the local client to build a backdoor in the agent without notice. Deploying such an agent raises the risk of potential harm to humans, as the attackers may easily navigate and control the agent as they wish via the backdoor. Towards Byzantine-robust federated embodied agent learning, in this paper, we study the attack and defense for the task of vision-and-language navigation (VLN), where the agent is required to follow natural language instructions to navigate indoor environments. First, we introduce a simple but effective attack strategy, Navigation as Wish (NAW), in which the malicious client manipulates local trajectory data to implant a backdoor into the global model. Resu
    
[^82]: Grad-StyleSpeech: 基于扩散模型的任意发言人自适应语音合成技术

    Grad-StyleSpeech: Any-speaker Adaptive Text-to-Speech Synthesis with Diffusion Models. (arXiv:2211.09383v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2211.09383](http://arxiv.org/abs/2211.09383)

    Grad-StyleSpeech基于扩散模型，可以实现任意发言人自适应语音合成，准确模拟目标说话人的风格，性能显著优于现有方法。

    

    近年来，基于神经生成模型的文本转语音合成技术取得了重大进展，但是现有的任意发言人自适应TTS方法由于在模拟目标说话人的风格方面的准确度不佳而表现出不尽人意的性能。本文提出了基于扩散模型的Grad-StyleSpeech框架，可以在给定几秒钟的参考语音情况下，生成非常自然且与目标说话人的声音极其相似的语音。Grad-StyleSpeech在英语基准测试上明显优于最近的说话者自适应TTS基线。声音样例可在https://nardien.github.io/grad-stylespeech-demo上获得。

    There has been a significant progress in Text-To-Speech (TTS) synthesis technology in recent years, thanks to the advancement in neural generative modeling. However, existing methods on any-speaker adaptive TTS have achieved unsatisfactory performance, due to their suboptimal accuracy in mimicking the target speakers' styles. In this work, we present Grad-StyleSpeech, which is an any-speaker adaptive TTS framework that is based on a diffusion model that can generate highly natural speech with extremely high similarity to target speakers' voice, given a few seconds of reference speech. Grad-StyleSpeech significantly outperforms recent speaker-adaptive TTS baselines on English benchmarks. Audio samples are available at https://nardien.github.io/grad-stylespeech-demo.
    
[^83]: PhaseAug: 一种可微的语音合成数据增强技术，用于模拟一对多映射关系

    PhaseAug: A Differentiable Augmentation for Speech Synthesis to Simulate One-to-Many Mapping. (arXiv:2211.04610v2 [eess.AS] UPDATED)

    [http://arxiv.org/abs/2211.04610](http://arxiv.org/abs/2211.04610)

    PhaseAug 是一种可微的语音合成数据增强技术，通过旋转每个频率箱的相位，模拟一对多映射关系，解决了传统训练中出现周期性伪影的问题，而且无需任何架构修改就可以超越基线方法。

    

    以往的生成对抗网络（GAN）基础声码器被训练成从对应的Mel频谱图中重建确切的语音波形，而不考虑语音合成中的一对多关系。这种传统训练会导致生成语音信号中出现周期性伪影，使得鉴别器和生成器都发生了过拟合。本文提出了PhaseAug——第一种不同iable 的语音合成数据增强技术——通过旋转每个频率箱的相位，模拟一对多映射关系。使用我们提出的方法，无需任何架构修改就可以超越基线方法。代码和音频样本可在 https://github.com/mindslab-ai/phaseaug 上获得。

    Previous generative adversarial network (GAN)-based neural vocoders are trained to reconstruct the exact ground truth waveform from the paired mel-spectrogram and do not consider the one-to-many relationship of speech synthesis. This conventional training causes overfitting for both the discriminators and the generator, leading to the periodicity artifacts in the generated audio signal. In this work, we present PhaseAug, the first differentiable augmentation for speech synthesis that rotates the phase of each frequency bin to simulate one-to-many mapping. With our proposed method, we outperform baselines without any architecture modification. Code and audio samples will be available at https://github.com/mindslab-ai/phaseaug.
    
[^84]: 活跃关系发现：通向通用和标签感知的开放关系抽取

    Active Relation Discovery: Towards General and Label-aware Open Relation Extraction. (arXiv:2211.04215v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.04215](http://arxiv.org/abs/2211.04215)

    本论文提出了一个活跃关系发现(ARD)框架，用于解决开放关系抽取中区分已知和新关系以及标记新关系类型的问题。实验证明，该框架在常规和更通用的设置上都显著优于以前的最先进方法。

    

    开放关系抽取(OpenRE)旨在发现开放领域的新关系。以前的OpenRE方法主要存在两个问题：(1)无法充分区分已知关系和新关系。当将常规测试设置扩展到更通用的设置时，其中测试数据可能也来自已知类别，现有方法的性能显著下降。(2)在实际应用之前必须进行二次标注。现有方法无法为新关系标记人类可读和有意义的类型，这是下游任务迫切需要的。为解决这些问题，我们提出了活跃关系发现(ARD)框架，它利用关系异常值检测来区分已知和新关系，并涉及主动学习用于标记新关系。对三个真实数据集的大量实验证明，ARD在常规和我们提出的更通用的设置上都显著优于以前的最先进方法。

    Open Relation Extraction (OpenRE) aims to discover novel relations from open domains. Previous OpenRE methods mainly suffer from two problems: (1) Insufficient capacity to discriminate between known and novel relations. When extending conventional test settings to a more general setting where test data might also come from seen classes, existing approaches have a significant performance decline. (2) Secondary labeling must be performed before practical application. Existing methods cannot label human-readable and meaningful types for novel relations, which is urgently required by the downstream tasks. To address these issues, we propose the Active Relation Discovery (ARD) framework, which utilizes relational outlier detection for discriminating known and novel relations and involves active learning for labeling novel relations. Extensive experiments on three real-world datasets show that ARD significantly outperforms previous state-of-the-art methods on both conventional and our propos
    
[^85]: 利用潜在空间先验知识的演示应用于强化学习

    Leveraging Demonstrations with Latent Space Priors. (arXiv:2210.14685v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.14685](http://arxiv.org/abs/2210.14685)

    本文提出了一种方法，通过结合技能学习和序列建模，利用演示数据集中的潜在空间先验知识来加速强化学习中高层次策略的学习，并在实验中证实了该方法的有效性。

    

    演示可以提供有关状态或动作空间的相关信息，具有提高强化学习智能体的效率和实用性的巨大潜力。本文提出了一种通过结合技能学习和序列建模来利用演示数据集的方法。从一个学习的联合潜在空间开始，我们分别训练演示序列的生成模型和相应的低层策略。序列模型形成了潜在空间对合理的演示行为的先验知识，以加速高层次策略的学习。我们展示了如何从仅状态的运动捕捉演示中获取这些先验知识，并探索了几种将它们整合到转移任务的策略学习中的方法。我们的实验结果证实了潜在空间先验知识在学习速度和最终性能方面都提供了显著的增益。我们在一组具有复杂、模拟的人形机器人的挑战性稀疏奖励环境和离线强化学习基准测试中对我们的方法进行了基准测试，并证明了我们的方法的有效性。

    Demonstrations provide insight into relevant state or action space regions, bearing great potential to boost the efficiency and practicality of reinforcement learning agents. In this work, we propose to leverage demonstration datasets by combining skill learning and sequence modeling. Starting with a learned joint latent space, we separately train a generative model of demonstration sequences and an accompanying low-level policy. The sequence model forms a latent space prior over plausible demonstration behaviors to accelerate learning of high-level policies. We show how to acquire such priors from state-only motion capture demonstrations and explore several methods for integrating them into policy learning on transfer tasks. Our experimental results confirm that latent space priors provide significant gains in learning speed and final performance. We benchmark our approach on a set of challenging sparse-reward environments with a complex, simulated humanoid, and on offline RL benchmar
    
[^86]: 基于贝叶斯的提示学习用于图像-语言模型泛化

    Bayesian Prompt Learning for Image-Language Model Generalization. (arXiv:2210.02390v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.02390](http://arxiv.org/abs/2210.02390)

    本文提出了一种基于贝叶斯方法的提示学习框架，对提示空间进行正则化，提高了对未见提示的泛化能力。

    

    基础的图像-语言模型因其高效的适应下游任务的提示学习而引起了广泛关注。提示学习将语言模型输入的一部分视为可训练的，同时冻结其余部分，并优化经验风险最小化目标。然而，经验风险最小化已知受到分布偏移的影响，这影响了对训练过程中未见提示的泛化能力。通过利用贝叶斯方法的正则化能力，我们从贝叶斯角度考虑提示学习，并将其制定为变分推断问题。我们的方法对提示空间进行正则化，减少对已见提示的过度拟合，并提高了对未见提示的提示泛化能力。我们的框架通过以概率的方式对输入提示空间进行建模，作为先验分布，使我们的提议与基于图像无条件或有条件的提示学习方法兼容。我们进行了实验证明了本提出的方法的有效性。

    Foundational image-language models have generated considerable interest due to their efficient adaptation to downstream tasks by prompt learning. Prompt learning treats part of the language model input as trainable while freezing the rest, and optimizes an Empirical Risk Minimization objective. However, Empirical Risk Minimization is known to suffer from distributional shifts which hurt generalizability to prompts unseen during training. By leveraging the regularization ability of Bayesian methods, we frame prompt learning from the Bayesian perspective and formulate it as a variational inference problem. Our approach regularizes the prompt space, reduces overfitting to the seen prompts and improves the prompt generalization on unseen prompts. Our framework is implemented by modeling the input prompt space in a probabilistic manner, as an a priori distribution which makes our proposal compatible with prompt learning approaches that are unconditional or conditional on the image. We demon
    
[^87]: 动态复杂驾驶场景下连接自动驾驶车辆的时空感知安全多智能体强化学习

    Spatial-Temporal-Aware Safe Multi-Agent Reinforcement Learning of Connected Autonomous Vehicles in Challenging Scenarios. (arXiv:2210.02300v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2210.02300](http://arxiv.org/abs/2210.02300)

    本文提出了一个新的约束多智能体强化学习框架，该框架包含一个并行Safety Shield模块，可应用于包含非连接的危险车辆的具有挑战性的驾驶场景中的连接自动驾驶车辆。通过信息共享、合作策略学习、图卷积网络-Transformer作为空间-时间编码器以及基于控制障碍函数的安全屏障模块等协调机制，该框架能够提高智能车辆系统的安全性和效率。

    

    通信技术使连接和自动驾驶车辆(CAVs)协作成为可能，但如何利用共享信息来提高CAV系统在动态和复杂的驾驶场景中的安全性和效率仍不清楚。本文提出了一个带有并行安全屏障的约束多智能体强化学习(MARL)框架，应用于包含非连接的危险车辆的具有挑战性的驾驶场景中的CAV。所提出的MARL的协调机制包括信息共享和合作策略学习，使用图卷积网络(GCN)-Transformer作为空间-时间编码器，增强智能体的环境感知能力。基于控制障碍函数(CBF)-安全检查的安全屏障模块保护智能体不采取不安全的行动。我们设计了一个约束多智能体优势演员-评论家(CMAA2C)算法，为CAVs训练安全和合作策略。在实验中，该框架证明了其处理复杂情况和实现高安全性能而同时保持高交通效率的能力。

    Communication technologies enable coordination among connected and autonomous vehicles (CAVs). However, it remains unclear how to utilize shared information to improve the safety and efficiency of the CAV system in dynamic and complicated driving scenarios. In this work, we propose a framework of constrained multi-agent reinforcement learning (MARL) with a parallel Safety Shield for CAVs in challenging driving scenarios that includes unconnected hazard vehicles. The coordination mechanisms of the proposed MARL include information sharing and cooperative policy learning, with Graph Convolutional Network (GCN)-Transformer as a spatial-temporal encoder that enhances the agent's environment awareness. The Safety Shield module with Control Barrier Functions (CBF)-based safety checking protects the agents from taking unsafe actions. We design a constrained multi-agent advantage actor-critic (CMAA2C) algorithm to train safe and cooperative policies for CAVs. With the experiment deployed in th
    
[^88]: 参数修剪的数据集蒸馏方法

    Dataset Distillation Using Parameter Pruning. (arXiv:2209.14609v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.14609](http://arxiv.org/abs/2209.14609)

    本文提出了一种使用参数修剪的数据集蒸馏方法，该方法可以在蒸馏过程中修剪难以匹配的参数，提高蒸馏性能。

    

    在许多领域中，获得先进模型的方法取决于大型数据集，这使得数据存储和模型训练变得昂贵。作为解决方案，数据集蒸馏可以合成保留原始大型数据集大多数信息的小型数据集。最近提出的匹配网络参数的数据集蒸馏方法已被证明在几个数据集上有效。然而，网络参数的维度通常很大。此外，一些参数在蒸馏过程中难以匹配，降低了蒸馏性能。基于这个观察，本研究提出了一种基于参数修剪的新型数据集蒸馏方法来解决这个问题。该方法可以在蒸馏过程中修剪难以匹配的参数，从而合成更加稳健的蒸馏数据集并提高蒸馏性能。在三个数据集上的实验结果表明，该方法优于其他最先进的数据集蒸馏方法。

    In many fields, the acquisition of advanced models depends on large datasets, making data storage and model training expensive. As a solution, dataset distillation can synthesize a small dataset that preserves most information of the original large dataset. The recently proposed dataset distillation method by matching network parameters has been proven effective for several datasets. However, the dimensions of network parameters are typically large. Furthermore, some parameters are difficult to match during the distillation process, degrading distillation performance. Based on this observation, this study proposes a novel dataset distillation method based on parameter pruning that solves the problem. The proposed method can synthesize more robust distilled datasets and improve distillation performance by pruning difficult-to-match parameters during the distillation process. Experimental results on three datasets show that the proposed method outperforms other state-of-the-art dataset d
    
[^89]: 一种扩散模型预测2D显微图像中的3D细胞形状

    A Diffusion Model Predicts 3D Shapes from 2D Microscopy Images. (arXiv:2208.14125v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2208.14125](http://arxiv.org/abs/2208.14125)

    该论文介绍了一种基于扩散模型的方法，用于从2D显微图像中预测真实的3D单个细胞形状。该方法被成功应用于单个细胞分类任务。该模型学习从2D显微镜图像中重建具有逼真形态学特征的3D形状。

    

    扩散模型是一种特定类型的生成模型，能够从学习的分布中合成新数据。我们介绍了一种基于扩散的模型DISPR，用于解决从二维单个细胞显微图像预测三维细胞形状的反问题。利用二维显微图像作为先验条件，DISPR被调整为预测逼真的三维形状重建。我们从六个高度不平衡的类别中提取形态学特征，展示了DISPR作为数据增强工具在基于特征的单个细胞分类任务中的适用性。将DISPR预测的特征添加到三个少数类中，将宏F1得分从$F1_{macro}=55.2\pm4.6\%$提高到$F1_{macro}=72.2\pm4.9\%$。因此，我们证明了扩散模型可以成功应用于反生物医学问题，并且它们能够学习从2D显微图像中重建具有逼真形态学特征的3D形状。

    Diffusion models are a special type of generative model, capable of synthesising new data from a learnt distribution. We introduce DISPR, a diffusion-based model for solving the inverse problem of three-dimensional (3D) cell shape prediction from two-dimensional (2D) single cell microscopy images. Using the 2D microscopy image as a prior, DISPR is conditioned to predict realistic 3D shape reconstructions. To showcase the applicability of DISPR as a data augmentation tool in a feature-based single cell classification task, we extract morphological features from the red blood cells grouped into six highly imbalanced classes. Adding features from the DISPR predictions to the three minority classes improved the macro F1 score from $F1_\text{macro} = 55.2 \pm 4.6\%$ to $F1_\text{macro} = 72.2 \pm 4.9\%$. We thus demonstrate that diffusion models can be successfully applied to inverse biomedical problems, and that they learn to reconstruct 3D shapes with realistic morphological features from
    
[^90]: BoNesis软件在最大包容布尔网络和集合的标记和源标记再编程中的应用

    Marker and source-marker reprogramming of Most Permissive Boolean networks and ensembles with BoNesis. (arXiv:2207.13307v3 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2207.13307](http://arxiv.org/abs/2207.13307)

    本文介绍了BoNesis软件在标记和源标记再编程问题中的应用，使用扰动固定点和最小陷阱空间，通过在BNs和集合中进行讨论和分析，得出相关的计算复杂度和解决方案。

    

    布尔网络（BNs）是应用于细胞行为建模的离散动态系统。本文展示了如何使用BoNesis软件彻底识别强制其固定点和吸引子具有属性的扰动组合。我们考虑标记属性，它指定某些组件固定为特定值。我们研究了标记再编程问题的4个变体：固定点、最小陷阱空间、及其可从给定初始配置到达的具有最宽容更新模式的固定点和最小陷阱空间的再编程。扰动由将一组组件固定为固定值组成。它们可以破坏和创建新的吸引子。在每种情况下，我们给出了它们的理论计算复杂度上限，并利用BoNesis Python框架实现了解决方案。最后，我们将再编程问题提升到BNs的集合中。

    Boolean networks (BNs) are discrete dynamical systems with applications to the modeling of cellular behaviors. In this paper, we demonstrate how the software BoNesis can be employed to exhaustively identify combinations of perturbations which enforce properties on their fixed points and attractors. We consider marker properties, which specify that some components are fixed to a specific value. We study 4 variants of the marker reprogramming problem: the reprogramming of fixed points, of minimal trap spaces, and of fixed points and minimal trap spaces reachable from a given initial configuration with the most permissive update mode. The perturbations consist of fixing a set of components to a fixed value. They can destroy and create new attractors. In each case, we give an upper bound on their theoretical computational complexity, and give an implementation of the resolution using the BoNesis Python framework. Finally, we lift the reprogramming problems to ensembles of BNs, as supported
    
[^91]: 通过有限注释减少算法偏见

    Mitigating Algorithmic Bias with Limited Annotations. (arXiv:2207.10018v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.10018](http://arxiv.org/abs/2207.10018)

    本文提出了一种名为APOD的交互式框架，用于在有限的注释预算下减少算法偏见，该框架将歧视惩罚与主动实例选择相结合，能够在公平性和准确度指标上优于传统方法。

    

    现有的公平性建模工作通常假设所有实例的敏感属性都是完全可用的，但由于获取敏感信息的高成本，在许多实际应用中可能不是这样。当敏感属性未公开或无法获得时，需要手动注释一小部分训练数据以减轻偏差。然而，不同敏感组之间的偏斜分布会保留原始数据集中注释子集的偏斜性，这导致非最优的偏差减轻。为了解决这个挑战，我们提出了Active Penalization Of Discrimination (APOD)，这是一个交互式框架，用于指导有限注释最大限度地消除算法偏见。所提出的APOD将歧视惩罚与主动实例选择相结合，以有效利用有限的注释预算，并在理论上证明了其能够限制算法偏见。在基准数据集上评估的结果表明，APOD在公平性和准确度指标上优于几种最先进的方法，同时使用的注释数量明显较少。

    Existing work on fairness modeling commonly assumes that sensitive attributes for all instances are fully available, which may not be true in many real-world applications due to the high cost of acquiring sensitive information. When sensitive attributes are not disclosed or available, it is needed to manually annotate a small part of the training data to mitigate bias. However, the skewed distribution across different sensitive groups preserves the skewness of the original dataset in the annotated subset, which leads to non-optimal bias mitigation. To tackle this challenge, we propose Active Penalization Of Discrimination (APOD), an interactive framework to guide the limited annotations towards maximally eliminating the effect of algorithmic bias. The proposed APOD integrates discrimination penalization with active instance selection to efficiently utilize the limited annotation budget, and it is theoretically proved to be capable of bounding the algorithmic bias. According to the eval
    
[^92]: 支持选择性分类的softmax信息拓展算法

    Augmenting Softmax Information for Selective Classification with Out-of-Distribution Data. (arXiv:2207.07506v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.07506](http://arxiv.org/abs/2207.07506)

    本文研究了存在外部分布数据时的选择性分类问题，提出了一种新的SCOD方法，即保留softmax信息，并发现现有的检测方法评价标准需根据任务规定进行调整。

    

    在深度学习计算机视觉领域中，检测外部分布数据是一项正在受到越来越多研究关注的任务。然而，检测方法的性能通常是在任务中单独评估的，而不是考虑其在联合下游任务时的潜在影响。在本文中，我们研究了存在外部分布数据时的选择性分类(SCOD)问题。也就是说，检测OOD样本的动机在于拒绝它们，从而降低它们对预测质量的影响。我们发现，在这个任务规定下，现有的后处理方法和只在OOD检测时评估时相比，表现出了不同的性能。因为如果ID数据被错误分类，将ID数据与OOD数据混淆就不再是一个问题。然而，在ID数据中正确预测和错误预测之间的混淆是不可取的。我们还提出了一种新的SCOD方法，即保留softmax信息

    Detecting out-of-distribution (OOD) data is a task that is receiving an increasing amount of research attention in the domain of deep learning for computer vision. However, the performance of detection methods is generally evaluated on the task in isolation, rather than also considering potential downstream tasks in tandem. In this work, we examine selective classification in the presence of OOD data (SCOD). That is to say, the motivation for detecting OOD samples is to reject them so their impact on the quality of predictions is reduced. We show under this task specification, that existing post-hoc methods perform quite differently compared to when evaluated only on OOD detection. This is because it is no longer an issue to conflate in-distribution (ID) data with OOD data if the ID data is going to be misclassified. However, the conflation within ID data of correct and incorrect predictions becomes undesirable. We also propose a novel method for SCOD, Softmax Information Retaining Com
    
[^93]: 因果多臂老虎机的组合纯探索

    Combinatorial Pure Exploration of Causal Bandits. (arXiv:2206.07883v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.07883](http://arxiv.org/abs/2206.07883)

    本文提出了用于因果模型的组合纯探索算法，其中对于二元广义线性模型，我们的算法实现了多项式样本复杂度，对于一般的图，我们的样本复杂度几乎是最优的。

    

    因果多臂老虎机的组合纯探索是一种在线学习任务：在给定一个具有未知因果推断分布的因果图的情况下，在每一轮中，我们选择一个子集变量来干预或不干预，并观察所有随机变量的随机结果，目标是尽可能少的使用轮数，以概率至少为$1-\delta$，输出能给予奖励变量$Y$最佳（或近乎最佳）期望结果的干预方案，其中$\delta$是给定的置信水平。我们提供了两种类型因果模型——二元广义线性模型（BGLM） 和一般图的第一种间隔依赖性和完全自适应的纯探索算法。对于BGLM，我们的算法是首次专门针对这种情况设计的，并实现了多项式样本复杂度，而所有现有的一般图算法都具有指数复杂度到图大小或一些不合理的假设。对于一般图，我们的算法具有近乎最优的样本复杂度，仅对数于图大小和未知因果效应的数量，而且还能够抵御隐藏性混淆因素和任意分布偏移的情况。此外，我们的分析提供了一个紧密的下界，与上界相匹配，表明了算法的最优性。

    The combinatorial pure exploration of causal bandits is the following online learning task: given a causal graph with unknown causal inference distributions, in each round we choose a subset of variables to intervene or do no intervention, and observe the random outcomes of all random variables, with the goal that using as few rounds as possible, we can output an intervention that gives the best (or almost best) expected outcome on the reward variable $Y$ with probability at least $1-\delta$, where $\delta$ is a given confidence level. We provide the first gap-dependent and fully adaptive pure exploration algorithms on two types of causal models -- the binary generalized linear model (BGLM) and general graphs. For BGLM, our algorithm is the first to be designed specifically for this setting and achieves polynomial sample complexity, while all existing algorithms for general graphs have either sample complexity exponential to the graph size or some unreasonable assumptions. For general 
    
[^94]: 人类对于AI语言生成的启发式算法存在缺陷

    Human heuristics for AI-generated language are flawed. (arXiv:2206.07271v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2206.07271](http://arxiv.org/abs/2206.07271)

    人们很难辨别AI生成的语言形式，因为通常采用的判断启发式算法出现了一些缺陷，需要使用更为复杂的语言分析工具和教育来提高人们的判断力。

    

    人工智能生成的语言越来越多地与人类交流相互融合。在聊天、邮件和社交媒体中，AI系统建议单词、完成句子或产生整个对话。人们通常无法鉴别AI产生的语言，而将其视为人类编写的语言，这引发了有关新形式欺骗和操纵的担忧。本文研究了人类如何分辨AI生成的最为个人化和重要的语言形式之一——口头自我表述。在六个实验中，参与者（N=4,600）无法在专业、酒店以及约会情境中发现最先进的AI语言模型所生成的自我表述。语言特征的计算分析表明，人类对于AI生成的语言判断存在启发式算法的缺陷，例如将第一人称代词、缩略词使用或家庭话题与人类编写的语言联系在一起。我们实验证明了这些启发式算法无法准确识别AI生成的语言，建议使用更为复杂的语言分析工具和教育来改善人类的判断力。

    Human communication is increasingly intermixed with language generated by AI. Across chat, email, and social media, AI systems suggest words, complete sentences, or produce entire conversations. AI-generated language is often not identified as such but presented as language written by humans, raising concerns about novel forms of deception and manipulation. Here, we study how humans discern whether verbal self-presentations, one of the most personal and consequential forms of language, were generated by AI. In six experiments, participants (N = 4,600) were unable to detect self-presentations generated by state-of-the-art AI language models in professional, hospitality, and dating contexts. A computational analysis of language features shows that human judgments of AI-generated language are hindered by intuitive but flawed heuristics such as associating first-person pronouns, use of contractions, or family topics with human-written language. We experimentally demonstrate that these heur
    
[^95]: Relphormer：关系图转换器用于知识图谱表示

    Relphormer: Relational Graph Transformer for Knowledge Graph Representations. (arXiv:2205.10852v5 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.10852](http://arxiv.org/abs/2205.10852)

    Relphormer是一种新的Transformer变体，用于知识图谱表示。它引入了Triple2Seq和增强式自我注意机制，以解决基本Transformer架构在捕捉知识图谱结构和语义信息方面的不足。

    

    Transformer已经在自然语言处理、计算机视觉和图形挖掘等广泛领域中取得了remarkable的性能。然而，基本的Transformer架构在知识图谱（KG）表示中并没有取得很好的改进，其中平移距离模型支配了这个领域。需注意的是，基本的Transformer架构难以捕捉到知识图谱的内在异构结构和语义信息。为此，我们提出了一种新的用于知识图谱表示的Transformer变体，名为Relphormer。具体来说，我们引入了Triple2Seq，可以动态地采样上下文化的子图序列作为输入，以缓解异构性问题。我们提出了一种新的增强式自我注意机制，用于对关系信息进行编码，并保持实体和关系内的语义信息。此外，我们利用掩蔽式知识建模来实现通用的知识图形表示。

    Transformers have achieved remarkable performance in widespread fields, including natural language processing, computer vision and graph mining. However, vanilla Transformer architectures have not yielded promising improvements in the Knowledge Graph (KG) representations, where the translational distance paradigm dominates this area. Note that vanilla Transformer architectures struggle to capture the intrinsically heterogeneous structural and semantic information of knowledge graphs. To this end, we propose a new variant of Transformer for knowledge graph representations dubbed Relphormer. Specifically, we introduce Triple2Seq which can dynamically sample contextualized sub-graph sequences as the input to alleviate the heterogeneity issue. We propose a novel structure-enhanced self-attention mechanism to encode the relational information and keep the semantic information within entities and relations. Moreover, we utilize masked knowledge modeling for general knowledge graph representa
    
[^96]: AIGenC：通过创造力进行 AI 通用化

    AIGenC: AI generalisation via creativity. (arXiv:2205.09738v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2205.09738](http://arxiv.org/abs/2205.09738)

    AIGenC 提出了一种创造性的计算模型，通过引入概念空间和分层结构来提高人工智能代理的通用性和创新能力，实验表明其在通用任务中的表现优于最先进方法。

    

    本文受到创造力的认知理论的启发，引入了一个计算模型（AIGenC），旨在提供必要的组成部分，使人工智能代理能够学习、使用和生成可转移的表征。与机器表征学习不同的是，生物表征包括关系和联想信息，嵌入了丰富和结构化的概念空间。AIGenC 模型采用分层的图形架构，具有不同组件获取的各种级别和类型的表征。第一个组件部分——概念处理，从感官输入中提取对象和支配因素，并将它们编码成概念空间。生成的表征存储在双重记忆系统中，并通过强化学习获得目标导向和时间信息的丰富度，从而创建了更高层次的抽象。另外两个组件并行工作，检测和恢复存储表征中的相关概念和创造连接，使系统能够生成新型解决方案并在新场景中应用它们。实验结果表明，AIGenC 在各种通用任务中优于现有的最先进方法。

    Inspired by cognitive theories of creativity, this paper introduces a computational model (AIGenC) that lays down the necessary components to enable artificial agents to learn, use and generate transferable representations. Unlike machine representation learning, which relies exclusively on raw sensory data, biological representations incorporate relational and associative information that embeds rich and structured concept spaces. The AIGenC model poses a hierarchical graph architecture with various levels and types of representations procured by different components. The first component, Concept Processing, extracts objects and affordances from sensory input and encodes them into a concept space. The resulting representations are stored in a dual memory system and enriched with goal-directed and temporal information acquired through reinforcement learning, creating a higher-level of abstraction. Two additional components work in parallel to detect and recover relevant concepts and cr
    
[^97]: 从区分到生成：基于生成变换器的知识图谱补全

    From Discrimination to Generation: Knowledge Graph Completion with Generative Transformer. (arXiv:2202.02113v7 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2202.02113](http://arxiv.org/abs/2202.02113)

    本文介绍了一种将知识图谱补全转化为生成任务的方法，同时引入了关系引导演示和实体感知分层解码来实现更好的表示学习和快速推断。实验结果表明，这种方法具有比基线更好或相当的性能，并且比以往的方法更快。同时，作者还发布了一个新的大规模中文知识图谱数据集AliopenKG500。

    

    知识图谱补全解决了扩展缺失三元组的问题。本文提出了一种称作GenKGC的方法，将知识图谱补全转化为预训练语言模型的序列到序列生成任务。我们进一步引入了关系引导演示和实体感知分层解码，以实现更好的表示学习和快速推断。在三个数据集上的实验结果显示，我们的方法可以获得比基线更好或相当的性能，并与以前具有预训练语言模型的方法相比，实现更快的推断速度。我们还发布了一个新的大规模中文知识图谱数据集AliopenKG500，供研究目的使用。代码和数据集可在https://github.com/zjunlp/PromptKG/tree/main/GenKGC中获得。

    Knowledge graph completion aims to address the problem of extending a KG with missing triples. In this paper, we provide an approach GenKGC, which converts knowledge graph completion to sequence-to-sequence generation task with the pre-trained language model. We further introduce relation-guided demonstration and entity-aware hierarchical decoding for better representation learning and fast inference. Experimental results on three datasets show that our approach can obtain better or comparable performance than baselines and achieve faster inference speed compared with previous methods with pre-trained language models. We also release a new large-scale Chinese knowledge graph dataset AliopenKG500 for research purpose. Code and datasets are available in https://github.com/zjunlp/PromptKG/tree/main/GenKGC.
    
[^98]: 基于知识图谱增强网络的多视角表示学习用于方面情感分析

    Knowledge Graph Augmented Network Towards Multiview Representation Learning for Aspect-based Sentiment Analysis. (arXiv:2201.04831v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2201.04831](http://arxiv.org/abs/2201.04831)

    本文提出了一种名为KGAN的模型，通过知识图谱增强网络，将外部知识和上下文、句法信息相结合，从多个角度捕获情感特征，实现了多视角的表示学习。

    

    方面情感分析（ABSA）是情感分析的一项细粒度任务。为了更好地理解长句子并获取准确的方面特定信息，通常需要语言和常识知识。然而，大多数现有方法采用复杂和低效的方法来包含外部知识，例如直接搜索图形节点。此外，外部知识和语言信息之间的互补性还没有得到彻底研究。为此，我们提出了一种知识图增强网络KGAN，旨在有效地将外部知识与明确的句法和上下文信息相结合。特别地，KGAN从多个不同的角度捕获情感特征表示，即基于上下文、句法和知识的。首先，KGAN并行学习上下文和句法表示，以充分提取语义特征。然后，KGAN将外部知识与上下文和句法信息相融合。

    Aspect-based sentiment analysis (ABSA) is a fine-grained task of sentiment analysis. To better comprehend long complicated sentences and obtain accurate aspect-specific information, linguistic and commonsense knowledge are generally required in this task. However, most current methods employ complicated and inefficient approaches to incorporate external knowledge, e.g., directly searching the graph nodes. Additionally, the complementarity between external knowledge and linguistic information has not been thoroughly studied. To this end, we propose a knowledge graph augmented network KGAN, which aims to effectively incorporate external knowledge with explicitly syntactic and contextual information. In particular, KGAN captures the sentiment feature representations from multiple different perspectives, i.e., context-, syntaxand knowledge-based. First, KGAN learns the contextual and syntactic representations in parallel to fully extract the semantic features. Then, KGAN integrates the k
    
[^99]: 人工智能伦理和安全：创建“良好”模型的实用工具

    Artificial Intelligence Ethics and Safety: practical tools for creating "good" models. (arXiv:2112.11208v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2112.11208](http://arxiv.org/abs/2112.11208)

    本文的目标是推广人工智能开发实践中的道德原则和规范指南，并使人工智能得到道德和负责任的创造。

    

    AI Robotics Ethics Society（AIRES）是由Aaron Hui于2018年创立的非营利组织，旨在推广人工智能的道德实施和监管的意识和重要性。本文的目标是在AI系统开发实践中建立道德原则和规范指南的提案，填补理论和实践之间的差距。

    The AI Robotics Ethics Society (AIRES) is a non-profit organization founded in 2018 by Aaron Hui to promote awareness and the importance of ethical implementation and regulation of AI. AIRES is now an organization with chapters at universities such as UCLA (Los Angeles), USC (University of Southern California), Caltech (California Institute of Technology), Stanford University, Cornell University, Brown University, and the Pontifical Catholic University of Rio Grande do Sul (Brazil). AIRES at PUCRS is the first international chapter of AIRES, and as such, we are committed to promoting and enhancing the AIRES Mission. Our mission is to focus on educating the AI leaders of tomorrow in ethical principles to ensure that AI is created ethically and responsibly. As there are still few proposals for how we should implement ethical principles and normative guidelines in the practice of AI system development, the goal of this work is to try to bridge this gap between discourse and praxis. Betwee
    
[^100]: 一步式诱导式多目标学习及其在乳腺癌肿瘤分割中的应用

    One-Step Abductive Multi-Target Learning with Diverse Noisy Samples and Its Application to Tumour Segmentation for Breast Cancer. (arXiv:2110.10325v9 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.10325](http://arxiv.org/abs/2110.10325)

    本论文提出了一种新的机器学习方法——一步式诱导式多目标学习与DiNS（OSAMTL-DiNS），以处理医学组织病理学全幻灯片图像分析中的复杂噪声标签。在乳腺癌肿瘤分割中得到了成功应用。

    

    近年来的研究表明，机器学习和逻辑推理的结合，包括数据驱动的逻辑推理、知识驱动的机器学习和诱导学习，在发明先进的人工智能技术方面具有很高的有效性。在医学组织病理学全幻灯片图像分析中，一步式诱导式多目标学习（OSAMTL），作为一种受诱导学习启发的方法，通过以一种平衡的方式简单地结合机器学习和逻辑推理，已经证明了其处理单个嘈杂标签的复杂噪声标签的有效性。但是，OSAMTL不适用于提供多种嘈杂样本（DiNS）的学习任务情况。在本文中，我们给出了DiNS的定义，并提出了一步式诱导式多目标学习与DiNS（OSAMTL-DiNS），以扩展原始的OSAMTL以处理DiNS的复杂噪声标签。将OSAMTL-DiNS应用于MHWSIA中的乳腺癌肿瘤分割中，我们展示了其有效性。

    Recent studies have demonstrated the effectiveness of the combination of machine learning and logical reasoning, including data-driven logical reasoning, knowledge driven machine learning and abductive learning, in inventing advanced artificial intelligence technologies. One-step abductive multi-target learning (OSAMTL), an approach inspired by abductive learning, via simply combining machine learning and logical reasoning in a one-step balanced way, has as well shown its effectiveness in handling complex noisy labels of a single noisy sample in medical histopathology whole slide image analysis (MHWSIA). However, OSAMTL is not suitable for the situation where diverse noisy samples (DiNS) are provided for a learning task. In this paper, giving definition of DiNS, we propose one-step abductive multi-target learning with DiNS (OSAMTL-DiNS) to expand the original OSAMTL to handle complex noisy labels of DiNS. Applying OSAMTL-DiNS to tumour segmentation for breast cancer in MHWSIA, we show 
    
[^101]: 一种应对数据流分类概念漂移的广义集成学习系统

    A Broad Ensemble Learning System for Drifting Stream Classification. (arXiv:2110.03540v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.03540](http://arxiv.org/abs/2110.03540)

    一种名为Broad Ensemble Learning System (BELS)的新型集成方法用于数据流分类中的概念漂移问题。相对于文献中现有的方法，它能够更加高效、稳定地更新模型，提高最佳性能模型的准确性。

    

    在数据流环境中，分类模型必须有效地处理概念漂移。集成方法是为此目的广泛使用的方法，但是文献中存在的方法要么使用大块数据更新模型，要么逐个学习数据。前者可能会错过数据分布中的变化，后者则可能受到效率和不稳定性的影响。为了解决这些问题，我们引入一种基于Broad Learning System (BLS)的新型集成方法，在每次更新时使用小块数据。BLS是一种有效的轻量级神经结构，最近被开发用于增量学习。尽管它速度很快，但它需要大量数据块来进行有效更新，而且不能处理数据流中观察到的动态变化。我们提出的Broad Ensemble Learning System (BELS)使用一种新的更新方式，显著提高了最佳性能模型的准确性。它使用输出集成

    In a data stream environment, classification models must handle concept drift efficiently and effectively. Ensemble methods are widely used for this purpose; however, the ones available in the literature either use a large data chunk to update the model or learn the data one by one. In the former, the model may miss the changes in the data distribution, and in the latter, the model may suffer from inefficiency and instability. To address these issues, we introduce a novel ensemble approach based on the Broad Learning System (BLS), where mini chunks are used at each update. BLS is an effective lightweight neural architecture recently developed for incremental learning. Although it is fast, it requires huge data chunks for effective updates, and is unable to handle dynamic changes observed in data streams. Our proposed approach named Broad Ensemble Learning System (BELS) uses a novel updating method that significantly improves best-in-class model accuracy. It employs an ensemble of outpu
    
[^102]: 思路流网络：从单一预测到模型思路的串联

    Thought Flow Nets: From Single Predictions to Trains of Model Thought. (arXiv:2107.12220v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2107.12220](http://arxiv.org/abs/2107.12220)

    本文探讨了给模型第二次、第三次甚至第k次思考机会的思路流网络，其利用自我校正机制和梯度更新能够纠正自身预测，该方法可显著提高模型性能。

    

    当人类解决复杂问题时，通常会创建一系列思路（涉及直觉决策、反思、错误更正等）以达成决定。但是，如今的模型大多被训练为将输入映射到单一且固定的输出。本文研究了如何让模型有第二、第三和第 k 次思考的机会。我们从黑格尔的辩证法中获得灵感，提出了思路流的概念，创建了一系列预测。我们提出了一个自我校正机制，它被训练用于估计模型的正确性，并基于正确性预测的梯度执行迭代预测更新。我们以问答为例介绍了我们的方法，并进行了广泛的实验，证明了（i）我们的方法能够纠正自己的预测，（ii）它能够显著提高模型的性能。此外，我们对思路流的语义校验进行了定性分析。

    When humans solve complex problems, they typically create a sequence of ideas (involving an intuitive decision, reflection, error correction, etc.) in order to reach a conclusive decision. Contrary to this, today's models are mostly trained to map an input to one single and fixed output. In this paper, we investigate how we can give models the opportunity of a second, third and $k$-th thought. Taking inspiration from Hegel's dialectics, we propose the concept of a thought flow which creates a sequence of predictions. We present a self-correction mechanism that is trained to estimate the model's correctness and performs iterative prediction updates based on the correctness prediction's gradient. We introduce our method at the example of question answering and conduct extensive experiments that demonstrate (i) our method's ability to correct its own predictions and (ii) its potential to notably improve model performances. In addition, we conduct a qualitative analysis of thought flow cor
    
[^103]: 基于潜力的奖赏设计用于强化学习智能体的新模式

    A new Potential-Based Reward Shaping for Reinforcement Learning Agent. (arXiv:1902.06239v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/1902.06239](http://arxiv.org/abs/1902.06239)

    本论文提出了一种新的基于历史经验的奖赏设计方法，旨在提高强化学习智能体的性能，该方法具有广泛的应用前景。

    

    基于潜力的奖励设计（PBRS）是一类机器学习方法，旨在提高强化学习智能体在执行任务时利用额外知识的学习速度。其中，传递学习中先前学习任务中提取知识并将其迁移到目标任务中的是其中一个重要的步骤。在这项任务中收集到的知识对性能的提升起到了至关重要的作用。本文提出了一种基于历史经验的奖赏设计方法，通过利用先前的学习经验，利用任务无关性知识来增强强化学习智能体的任务特定奖励功能。

    Potential-based reward shaping (PBRS) is a particular category of machine learning methods which aims to improve the learning speed of a reinforcement learning agent by extracting and utilizing extra knowledge while performing a task. There are two steps in the process of transfer learning: extracting knowledge from previously learned tasks and transferring that knowledge to use it in a target task. The latter step is well discussed in the literature with various methods being proposed for it, while the former has been explored less. With this in mind, the type of knowledge that is transmitted is very important and can lead to considerable improvement. Among the literature of both the transfer learning and the potential-based reward shaping, a subject that has never been addressed is the knowledge gathered during the learning process itself. In this paper, we presented a novel potential-based reward shaping method that attempted to extract knowledge from the learning process. The propo
    
[^104]: FOLE ERA：基础探讨

    The ERA of FOLE: Foundation. (arXiv:1512.07430v2 [cs.DB] UPDATED)

    [http://arxiv.org/abs/1512.07430](http://arxiv.org/abs/1512.07430)

    本文讨论本体在FOLE一阶逻辑环境中的表示，特别是提供了ERA数据模型的严格数学表示，作为本体论的基础探讨。

    

    本文讨论本体在FOLE（Kent 2013）一阶逻辑环境中的表示。本体定义了用于为话语社区建模知识资源的原语（Gruber 2009）。这些原语包括类、关系和属性，由实体-关系-属性（ERA）数据模型（Chen 1976）表示。本文是三篇论文中的第一篇，它在FOLE的第一阶逻辑环境中提供了ERA数据模型的严格数学表示，特别是本体论的基础探讨。

    This paper discusses the representation of ontologies in the first-order logical environment FOLE (Kent 2013). An ontology defines the primitives with which to model the knowledge resources for a community of discourse (Gruber 2009). These primitives, consisting of classes, relationships and properties, are represented by the entity-relationship-attribute ERA data model (Chen 1976). An ontology uses formal axioms to constrain the interpretation of these primitives. In short, an ontology specifies a logical theory. This paper is the first in a series of three papers that provide a rigorous mathematical representation for the ERA data model in particular, and ontologies in general, within the first-order logical environment FOLE. The first two papers show how FOLE represents the formalism and semantics of (many-sorted) first-order logic in a classification form corresponding to ideas discussed in the Information Flow Framework (IFF). In particular, this first paper provides a foundation 
    

