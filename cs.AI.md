# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Automated Mapping of CVE Vulnerability Records to MITRE CWE Weaknesses.](http://arxiv.org/abs/2304.11130) | 该论文介绍了一种自动将CVE漏洞记录映射到MITRE CWE弱点的方法，并提供了一个手动注释的数据集，可用于解决此问题的监督式机器学习。 |
| [^2] | [Tree-structured Parzen estimator: Understanding its algorithm components and their roles for better empirical performance.](http://arxiv.org/abs/2304.11127) | 该论文介绍了一种广泛使用的贝叶斯优化方法 Tree-structured Parzen estimator (TPE)，并对其控制参数的作用和算法直觉进行了讨论和分析，提供了一组推荐设置并证明其能够提高TPE的性能表现。 |
| [^3] | [Semantics, Ontology and Explanation.](http://arxiv.org/abs/2304.11124) | 本文讨论了语义学、本体论和解释中的概念，并介绍了一种本体拆包的解释概念，即通过揭示符号领域描述的真相制造者来解释概念模型等；还讨论了本体论驱动的概念模型在各种AI决策制定中的关键作用。 |
| [^4] | [China and the U.S. produce more impactful AI research when collaborating together.](http://arxiv.org/abs/2304.11123) | 中国和美国在人工智能领域合作能产生更大影响力，最近数据显示两国自2000年来一直处于领导地位，而大多数人才流失在两国之间。 |
| [^5] | [BoDiffusion: Diffusing Sparse Observations for Full-Body Human Motion Synthesis.](http://arxiv.org/abs/2304.11118) | BoDiffusion是一种应用于全身人体运动合成的生成扩散模型，可以通过利用稀疏跟踪输入生成平滑逼真的完整全身运动序列，该方法在逼真度和重建误差方面优于现有最先进的方法。 |
| [^6] | [Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT.](http://arxiv.org/abs/2304.11116) | 本文旨在通过Graph-ToolFormer框架赋予LLMs图形推理能力，并解决现有LLMs在执行图形学习任务中存在的固有弱点。 |
| [^7] | [Inducing anxiety in large language models increases exploration and bias.](http://arxiv.org/abs/2304.11111) | 对大型语言模型施加焦虑能影响它们的探索性和偏见，这需要更多道德考虑和监管。 |
| [^8] | [ChatABL: Abductive Learning via Natural Language Interaction with ChatGPT.](http://arxiv.org/abs/2304.11107) | 本研究提出了一种新方法ChatABL，将大型语言模型LLM整合到归纳学习ABL框架中，通过自然语言对话实现交互式学习，旨在以更加用户友好和易理解的方式统一感知、语言理解和推理能力。实验结果显示，ChatABL可以更有效和高效地学习解决归纳推理问题。 |
| [^9] | [Approximate Shielding of Atari Agents for Safe Exploration.](http://arxiv.org/abs/2304.11104) | 本文提出了一种基于屏蔽概念的安全探索的算法，使用世界模型验证策略回滚，不依赖于安全相关抽象或高保真度模拟器。在少量Atari游戏上的实验结果表明，该算法有效性高，减少了安全违规率。 |
| [^10] | [Is Cross-modal Information Retrieval Possible without Training?.](http://arxiv.org/abs/2304.11095) | 本论文研究了不需要训练，基于简单映射的跨模态信息检索方法，利用来自预训练深度学习模型的编码表示。这种方法可以在语义上将不同模态的数据映射到同一空间，并在文本和图像之间达到有竞争力的性能水平。 |
| [^11] | [Effectiveness of Debiasing Techniques: An Indigenous Qualitative Analysis.](http://arxiv.org/abs/2304.11094) | 本文以本土的视角探讨了针对预训练语言模型去偏见技术的有效性，呼吁在算法中纳入本地知识和理解以确保公正，特别是在面对资源受限的社会时。 |
| [^12] | [Hi Sheldon! Creating Deep Personalized Characters from TV Shows.](http://arxiv.org/abs/2304.11093) | 从多模态数据中通过DPCC创造出能够与用户进行视听交互的深度个性化数字角色，并收集了一个包含近10k个话语和6个小时音频/视频的角色中心多模态对话数据集。 |
| [^13] | [Towards Responsible AI in the Era of ChatGPT: A Reference Architecture for Designing Foundation Model-based AI Systems.](http://arxiv.org/abs/2304.11090) | 本文提出了一个以模式为导向的负责任AI-by-design参考架构，用于设计基于基础模型的AI系统，重点关注可解释性、公平性、安全性和鲁棒性等关键设计元素。 |
| [^14] | [Profiling the news spreading barriers using news headlines.](http://arxiv.org/abs/2304.11088) | 本文利用新闻标题的语义知识和情感特征来对新闻传播障碍进行分类，可以有效地检测新闻传播障碍。 |
| [^15] | [AI Product Security: A Primer for Developers.](http://arxiv.org/abs/2304.11087) | 本文旨在为AI软件产品的开发人员、设计师、管理者和研究人员介绍AI产品安全的基础，让他们了解机器学习产品的威胁并避免常见陷阱。 |
| [^16] | [Development of Authenticated Clients and Applications for ICICLE CI Services -- Final Report for the REHS Program, June-August, 2022.](http://arxiv.org/abs/2304.11086) | 本论文介绍了ICICLE智能环境计算学习人工智能研究所开发的Jupyter Notebooks和Python命令行客户端，使用ICICLE身份验证机制访问ICICLE资源和服务。使用了Tapis框架和Neo4j将数据组织成一个知识图谱（KG），并演示了使用该软件的几个客户端，验证了使用Tapis和Neo4j开发认证客户端访问网络基础设施服务的可行性。 |
| [^17] | [Fundamental Limitations of Alignment in Large Language Models.](http://arxiv.org/abs/2304.11082) | 本文通过提出一种理论方法——行为期望边界（BEB），展示了大型语言模型中对齐的基本限制，并证明任何对齐过程都无法根除不希望的行为，这对于防止恶意攻击是不安全的。 |
| [^18] | [HeRo: RoBERTa and Longformer Hebrew Language Models.](http://arxiv.org/abs/2304.11077) | 本论文提供了希伯来语言处理社区所需的最大预训练数据集HeDC4，以及两种表现最先进的预训练语言模型：用于标准长度输入的HeRo和用于长输入序列的LongHeRo。两个模型在多项任务中实现了最先进的性能。 |
| [^19] | [Can ChatGPT-like Generative Models Guarantee Factual Accuracy? On the Mistakes of New Generation Search Engines.](http://arxiv.org/abs/2304.11076) | 论文质疑类ChatGPT生成模型是否能保证事实准确性，很多新一代搜索引擎的公开演示中存在事实错误，呼吁科研人员和开发人员提高透明度和事实正确性。 |
| [^20] | [An Unbiased Transformer Source Code Learning with Semantic Vulnerability Graph.](http://arxiv.org/abs/2304.11072) | 该论文提出了一种基于语义漏洞图的无偏Transformer源代码学习方法，通过利用从源代码中得到的语义漏洞图（SVG）表示来解决当前漏洞筛选技术对于识别新漏洞或为开发人员提供漏洞和分类方面的效果不佳的问题，并在公开数据集上实现了最先进的性能。 |
| [^21] | [Conversational Process Modelling: State of the Art, Applications, and Implications in Practice.](http://arxiv.org/abs/2304.11065) | 本文系统的研究了现有聊天机器人对于支持对话式流程建模所提供的应用场景，并推导出了在实践中使用聊天机器人进行对话式流程建模的建议。 |
| [^22] | [Think Before You Act: Unified Policy for Interleaving Language Reasoning with Actions.](http://arxiv.org/abs/2304.11063) | 本文提出了一种新的方法，将语言推理与动作统一在单个策略中，利用 transformer 模型，能够生成交替使用动作的文本标题。在 BabyAI 任务中测试，我们的推理策略始终优于没有标题的基准线。 |
| [^23] | [Scaling Transformer to 1M tokens and beyond with RMT.](http://arxiv.org/abs/2304.11062) | 本文介绍了一种利用循环记忆扩展BERT上下文长度的方法，成功扩展到了前所未有的200万个标记，有望增强自然语言处理中的长期依赖处理并为内存密集型应用程序实现大规模上下文处理。 |
| [^24] | [CEIL: A General Classification-Enhanced Iterative Learning Framework for Text Clustering.](http://arxiv.org/abs/2304.11061) | CEIL是一种迭代学习框架，通过引入分类目标来改进特征表示和文本聚类效果，能够普适于不同领域的文本聚类任务。 |
| [^25] | [SkillGPT: a RESTful API service for skill extraction and standardization using a Large Language Model.](http://arxiv.org/abs/2304.11060) | SkillGPT是一种使用大型语言模型进行技能提取和标准化的RESTful API服务，通过摘要和向量相似性搜索平衡速度和准确度。 |
| [^26] | [A Multiagent CyberBattleSim for RL Cyber Operation Agents.](http://arxiv.org/abs/2304.11052) | 本文介绍了一种新的对抗训练环境——CyberBattleSim，设计用于RL网络操作代理的训练。本文着重报道了对防御型蓝色代理训练的改进，结果表明红色代理与蓝色代理联合训练可以有效提高蓝色代理的防御能力。 |
| [^27] | [Affective social anthropomorphic intelligent system.](http://arxiv.org/abs/2304.11046) | 本研究提出了一种情感社交化人形智能系统，可以更好地理解人类声音的情感语义，实现类人对话。 |
| [^28] | [Analog Feedback-Controlled Memristor programming Circuit for analog Content Addressable Memory.](http://arxiv.org/abs/2304.11030) | 本文提出了一种模拟反馈控制忆阻器编程电路，使用新颖的基于查找表的编程算法，可以在单向顺序过程中执行忆阻器的编程和验证，解决了现有算法中频繁切换带来的高动态功率和长编程时间的缺陷。 |
| [^29] | [Exogenous Data in Forecasting: FARM -- An Approach for Relevance Evaluation.](http://arxiv.org/abs/2304.11028) | 该论文介绍了一种名为FARM的方法，用于有效处理实时数据流并提供平衡的相关性度量，进而确定外部数据在预测中的重要性。 |
| [^30] | [Robot-Enabled Construction Assembly with Automated Sequence Planning based on ChatGPT: RoboGPT.](http://arxiv.org/abs/2304.11018) | 该论文介绍了一种基于大型语言模型ChatGPT的RoboGPT系统，用于机器人辅助施工装配中的自动化顺序规划。该系统可克服其他方法在适应能力和可扩展性方面的局限性。 |
| [^31] | [DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction.](http://arxiv.org/abs/2304.11015) | DIN-SQL通过将复杂的文本到SQL任务分解为子问题，并将这些子问题的解决方案馈入到大型语言模型中，显著提高了它们的表现，使准确性超过了当前最先进的技术。 |
| [^32] | [BERT Based Clinical Knowledge Extraction for Biomedical Knowledge Graph Construction and Analysis.](http://arxiv.org/abs/2304.10996) | 本文提出了一种基于BERT和CRF技术的生物医学临床笔记知识提取和分析的端到端方法，用于构建和分析生物医学知识图谱。 |
| [^33] | [Launching a Robust Backdoor Attack under Capability Constrained Scenarios.](http://arxiv.org/abs/2304.10985) | 深度神经网络的后门攻击一直是一个安全性问题，现有的改进方法需要强大的攻击者能力，在能力受限场景下还没有找到令人满意的解决办法，此外，模型鲁棒性仍然值得关注。 |
| [^34] | [IBBT: Informed Batch Belief Trees for Motion Planning Under Uncertainty.](http://arxiv.org/abs/2304.10984) | 本文提出使用信息饱和批次置信树算法解决了运动和传感器不确定性下的运动规划，先构建标准轨迹的图，再利用所提出的启发式代价计算解决原问题，最后通过搜索标准轨迹的树来生成置信度树。 |
| [^35] | [LEIA: Linguistic Embeddings for the Identification of Affect.](http://arxiv.org/abs/2304.10973) | 该论文提出了一种名为LEIA的情感识别模型，使用了由超过6百万个自注释文本帖子组成的数据集进行训练，利用掩蔽单词的方法增强模型预训练过程中对情感单词的学习，并在三个测试数据集上实现了约73的宏F1值，优于其他方法。 |
| [^36] | [Gradient Derivation for Learnable Parameters in Graph Attention Networks.](http://arxiv.org/abs/2304.10939) | 本文对GATv2的可训练模型参数的梯度进行了全面推导，在不同的数据集上实现的性能表现不一致的原因仍然是一个开放的研究问题。 |
| [^37] | [Self-Supervised Adversarial Imitation Learning.](http://arxiv.org/abs/2304.10914) | 本文介绍了一种解决自我监督模型陷入坏局部最小值的方法，即通过将鉴别器纳入模型，不需要人工干预，帮助学习，并解决了常见的学习问题。 |
| [^38] | [Transformer-based models and hardware acceleration analysis in autonomous driving: A survey.](http://arxiv.org/abs/2304.10891) | 本文综述了基于Transformer的模型在自动驾驶中的应用，探讨了不同体系结构和运算符的优缺点，重点讨论了针对便携计算平台的硬件加速方案，并对卷积神经网络和Transformer的层进行了对比。 |
| [^39] | [AMP in the wild: Learning robust, agile, natural legged locomotion skills.](http://arxiv.org/abs/2304.10888) | 本文提出了一种新算法，可推断动态系统参数信息并从之前的观察数据中估计机器人状态的重要信息。将该算法与Adversarial Motion Priors相结合，实现了在仿真和真实世界中健壮、灵活、自然的步态，可用于穿越具有挑战性的地形。 |
| [^40] | [How Well Does the Metropolis Algorithm Cope With Local Optima?.](http://arxiv.org/abs/2304.10848) | Metropolis算法的局部搜索策略并不总是优于进化算法，还需要进一步改进和完善。 |
| [^41] | [Learn to Cluster Faces with Better Subgraphs.](http://arxiv.org/abs/2304.10831) | 本文提出了一种有效的邻域感知子图调整方法，可以显著减少噪声，提高子图的召回率，从而可以推动远距离的节点向相同的中心收敛。 |
| [^42] | [Auditing and Generating Synthetic Data with Controllable Trust Trade-offs.](http://arxiv.org/abs/2304.10819) | 本论文提出了一个审计框架，能够以全面的方式评估合成数据和AI模型的具体效果，包括偏见和歧视预防、对真实数据的忠实程度、效用、鲁棒性和隐私保护。在多个用例中，审计框架平衡了信任和效用之间的权衡。 |
| [^43] | [Can SAM Count Anything? An Empirical Study on SAM Counting.](http://arxiv.org/abs/2304.10817) | 本文探讨了将Segment Anything模型用于少样本物体计数的挑战性任务，并与其他计数方法进行了比较。我们发现SAM的表现仍需进一步微调，特别是对于小型和拥挤的物体。 |
| [^44] | [RPLKG: Robust Prompt Learning with Knowledge Graph.](http://arxiv.org/abs/2304.10805) | 本研究提出了一种基于知识图谱的鲁棒提示学习方法，通过自动设计有意义和可解释的提示集，提高小样本学习的泛化性能。 |
| [^45] | [Contrastive Language, Action, and State Pre-training for Robot Learning.](http://arxiv.org/abs/2304.10782) | 本文介绍了一种名为CLASP的方法，将语言、动作和状态信息统一到共享的嵌入空间中，用于机器人学习中的一系列下游任务。通过分布式编码器实现了不同的文本命令与单个行为相关联，并反之亦然。模型在零样本文本行为检索、为未见机器人行为加标题以及学习一个行为先验知识以进行语言依存的强化学习方面表现出卓越的性能。 |
| [^46] | [DEIR: Efficient and Robust Exploration through Discriminative-Model-Based Episodic Intrinsic Rewards.](http://arxiv.org/abs/2304.10770) | 提出了一种探索强化学习算法DEIR，借助区分性模型实现理论上导出的内在奖励，能够高效且鲁棒地进行探索，适用于面对外部奖励稀疏的情况。 |
| [^47] | [Towards Realizing the Value of Labeled Target Samples: a Two-Stage Approach for Semi-Supervised Domain Adaptation.](http://arxiv.org/abs/2304.10762) | 该论文提出了一种基于双阶段方法的半监督领域自适应方法，成功利用了少量有限的标记目标样本，相对于其他方法取得了更好的性能表现。 |
| [^48] | [Interpretable and Robust AI in EEG Systems: A Survey.](http://arxiv.org/abs/2304.10755) | 这篇论文综述了近年来脑电图系统中可解释和鲁棒的AI技术的发展。其中，作者提出了解释性分类法，详细介绍了鲁棒AI的方法，包括对抗攻击和防御、迁移学习和不确定性建模，并讨论了未来的研究方向和挑战。 |
| [^49] | [Forecast Ergodicity: Prediction Modeling Using Algorithmic Information Theory.](http://arxiv.org/abs/2304.10752) | 本论文讨论了预测遍历性（forecast ergodicity）的概念，即从过去数据中预测未来事件的能力的度量。文章使用算法复杂性模拟这个能力的限制。 |
| [^50] | [Improving Grounded Language Understanding in a Collaborative Environment by Interacting with Agents Through Help Feedback.](http://arxiv.org/abs/2304.10750) | 研究通过互动反馈与代理交互来提高协作环境下基于实地理解的能力。 |
| [^51] | [Multi-scale Evolutionary Neural Architecture Search for Deep Spiking Neural Networks.](http://arxiv.org/abs/2304.10749) | 本文提出了一种新方法--多尺度进化神经架构搜索，用于自动设计脉冲神经网络，同时考虑微观、中观和宏观尺度的脑拓扑结构。MSE-NAS可以帮助SNN实现多电路模式的自组织集成，并通过全局性的跨模式连接来优化网络性能。 |
| [^52] | [Joint Client Assignment and UAV Route Planning for Indirect-Communication Federated Learning.](http://arxiv.org/abs/2304.10744) | 提出了一种新的FedEx框架，利用无人机等移动传输器建立间接通信通道，在解决客户端和服务器之间无法直接通信的问题时，本文提出了一种联合客户端分配和无人机路径规划的方法，最小化整体训练时间和通信成本。 |
| [^53] | [KitchenScale: Learning to predict ingredient quantities from recipe contexts.](http://arxiv.org/abs/2304.10739) | KitchenScale是一个经过Fine-tuned的预训练语言模型（PLM），可根据食谱上下文预测目标成分的数量和测量单位。该模型采用离散潜在指数（DExp）方法处理食谱语料库中数字尺度的高方差，尝试从食谱文本到PLMs的转移学习。在新构建的数据集和推荐示例上进行实验，证明了KitchenScale具有泛化性并可以理解各种食谱语境，同时提供了一个Web应用程序来为用户提供所需的食品量的配方特定的测量单位。 |
| [^54] | [RoCOCO: Robust Benchmark MS-COCO to Stress-test Robustness of Image-Text Matching Models.](http://arxiv.org/abs/2304.10727) | 本文提出了一个新的评估基准来测试ITM模型的鲁棒性，通过将一些“愚弄”的图片和标题添加到检索池中，在MS COCO数据集上为各种最先进的模型进行鲁棒性测试，揭示了它们的不足之处。 |
| [^55] | [Reinforcement Learning Approaches for Traffic Signal Control under Missing Data.](http://arxiv.org/abs/2304.10722) | 本文提出了在交通路网中缺少传感器的情况下，使用强化学习方法通过补充流量状态或状态和动作来实现自适应控制和条件融合。 |
| [^56] | [Fooling Thermal Infrared Detectors in Physical World.](http://arxiv.org/abs/2304.10712) | 本论文提出一种新颖的物理攻击方法——对抗性红外块（AdvIB），可以从多个角度对热成像系统执行隐蔽的黑盒攻击，成功诱导目标红外检测器在物理场景中对对象或人类进行误分类，并且不被人类察觉。 |
| [^57] | [Graph based Label Enhancement for Multi-instance Multi-label learning.](http://arxiv.org/abs/2304.10705) | 本文提出了一种基于图标签增强的新型MIML框架GLEMIML，通过提高标签重要性来提高MIML的分类性能，并在实验中证明了其优越性。 |
| [^58] | [Interactive System-wise Anomaly Detection.](http://arxiv.org/abs/2304.10704) | 本文提出了 InterSAD 方法，利用马尔可夫决策过程模拟交互式系统，并通过找到有效的激活信号和实时交互，解决了系统级异常检测的问题。 |
| [^59] | [ReCEval: Evaluating Reasoning Chains via Correctness and Informativeness.](http://arxiv.org/abs/2304.10703) | 本文提出了一种基于推导链正确性和信息量的推理链评估框架ReCEval，用以评估多步推理能力。该框架能够客观、系统和准确地评估推理链，并在多个数据集上实现了良好的效果。 |
| [^60] | [Meta Semantics: Towards better natural language understanding and reasoning.](http://arxiv.org/abs/2304.10663) | 该论文提出了解决词汇外问题的两种策略以及一个用于更好的自然语言理解和推理的语义模型，旨在克服深度神经网络方法和基于规则方法的不足。 |
| [^61] | ["HOT" ChatGPT: The promise of ChatGPT in detecting and discriminating hateful, offensive, and toxic comments on social media.](http://arxiv.org/abs/2304.10619) | 本研究使用ChatGPT探究了生成式AI模型检测社交媒体上有害评论的可行性，结果显示ChatGPT可以达到约80%的准确性。 |
| [^62] | [An Attention Free Conditional Autoencoder For Anomaly Detection in Cryptocurrencies.](http://arxiv.org/abs/2304.10614) | 本篇论文提出了一种无注意力条件自编码器(AF-CA)，用于检测时间序列中的异常，在处理噪声时更可靠，可以提高异常检测的能力。 |
| [^63] | [Text2Seg: Remote Sensing Image Semantic Segmentation via Text-Guided Visual Foundation Models.](http://arxiv.org/abs/2304.10597) | 本文介绍了一种名为 Text2Seg 的遥感图像语义分割流程，利用多个基础模型和文本引导，取得了初步成果。 |
| [^64] | [Enhancing Artificial intelligence Policies with Fusion and Forecasting: Insights from Indian Patents Using Network Analysis.](http://arxiv.org/abs/2304.10596) | 本研究利用网络分析揭示了塑造AI发展格局和领域成熟度的重要组成部分，为AI公共政策的数据驱动带来了新的视角。 |
| [^65] | [A Review of Symbolic, Subsymbolic and Hybrid Methods for Sequential Decision Making.](http://arxiv.org/abs/2304.10590) | 本文综述了顺序决策制定的符号、亚符号和混合方法，旨在解决顺序决策过程（SDP）中的问题。无论是基于自动化规划（AP）还是强化学习（RL），都涵盖了解决SDP的方法和学习其结构的方面。对于可扩展性方面的挑战，也进行了讨论。 |
| [^66] | [Quantifying the Benefit of Artificial Intelligence for Scientific Research.](http://arxiv.org/abs/2304.10578) | 该篇论文通过将自然语言处理技术应用于数百万篇文献来估计人工智能的直接使用和潜在受益，发现人工智能在科学研究中的应用似乎在所有科学领域中普遍，使用人工智能的论文具有更高的影响力。 |
| [^67] | [IDQL: Implicit Q-Learning as an Actor-Critic Method with Diffusion Policies.](http://arxiv.org/abs/2304.10573) | 本文重新解释隐式Q学习(IQL)作为Actor-Critic方法，提出使用扩散行为策略和评判器权重来平衡奖励最大化和与行为策略的分歧。这个方法能够处理复杂和多峰特征的Actor问题。 |
| [^68] | [Using Z3 for Formal Modeling and Verification of FNN Global Robustness.](http://arxiv.org/abs/2304.10558) | 本文介绍了使用Z3求解器对全局鲁棒性可验证框架DeepGlobal进行更明确的定义和优化的工作，来建立FNN的形式化模型，以实现更有效的验证。 |
| [^69] | [An Introduction to Transformers.](http://arxiv.org/abs/2304.10557) | Transformer是一种神经网络组件，可以学习序列或数据集表示，在自然语言处理、计算机视觉和时空建模方面取得了重大进展。本论文提供了一个数学精确、直观、简洁的Transformer架构描述。 |
| [^70] | [A Reference Model for Collaborative Business Intelligence Virtual Assistants.](http://arxiv.org/abs/2304.10556) | 本文介绍了协同商务智能的虚拟助手参考模型，旨在提高不同利益相关者之间的知识共享和协作。该模型可用于支持商业分析中的各种活动，促进更好的决策制定。 |
| [^71] | [Sparsity in neural networks can improve their privacy.](http://arxiv.org/abs/2304.10553) | 稀疏性能够提高神经网络的隐私，并且能够保持网络的表现 |
| [^72] | [Deep Transfer Learning Applications in Intrusion Detection Systems: A Comprehensive Review.](http://arxiv.org/abs/2304.10550) | 本文全面回顾了深度迁移学习在入侵检测系统中的应用，特别是基于IDS的深度迁移学习，该技术利用多个领域的知识融合和/或适应以提高目标任务的性能，尤其是在目标领域中的标记数据非常少的情况下。 |
| [^73] | [A note on the connectedness property of union-free generic sets of partial orders.](http://arxiv.org/abs/2304.10549) | 本文证明了偏序数据深度函数的背景下Blocher等人[2023]中介绍的无交通用集合具有连通性属性。 |
| [^74] | [Supporting Qualitative Analysis with Large Language Models: Combining Codebook with GPT-3 for Deductive Coding.](http://arxiv.org/abs/2304.10548) | 本研究探讨了使用大型语言模型来支持定性分析中的演绎编码。通过结合GPT-3和专家编写的编码本，研究人员成功地实现了与专家编码结果相近的标记结果，并且还允许进行高效和有效的编码本优化。 |
| [^75] | [The Design Space of Generative Models.](http://arxiv.org/abs/2304.10547) | 本文探索开发一个AI模型设计空间的含义，提出两个设计空间与生成AI模型相关：第一个考虑HCI如何影响生成模型;第二个考虑生成模型如何影响HCI。 |
| [^76] | [Towards a Benchmark for Scientific Understanding in Humans and Machines.](http://arxiv.org/abs/2304.10327) | 该论文提出了一个框架来创建衡量人类和人工智能科学理解的基准。他们使用了行为观念，提出了一组问题以衡量不同水平的科学理解。这个框架可以帮助评估和比较不同水平和方法的科学理解。 |
| [^77] | [LARD -- Landing Approach Runway Detection -- Dataset for Vision Based Landing.](http://arxiv.org/abs/2304.09938) | LARD数据集是用于着陆和进场阶段的跑道检测任务的高质量航拍图像数据集。它由大量合成图像和一些人工标注的实际着陆镜头图像组成，同时还提供了生成器以产生此类合成图像并自动注释跑道拐角点。 |
| [^78] | [Accelerate Support Vector Clustering via Spectrum-Preserving Data Compression?.](http://arxiv.org/abs/2304.09868) | 本文介绍了一种通过保留谱的数据压缩来加速支持向量聚类的方法，可以显著提高聚类速度而不牺牲聚类质量。 |
| [^79] | [MATURE-HEALTH: HEALTH Recommender System for MAndatory FeaTURE choices.](http://arxiv.org/abs/2304.09099) | 该论文提出和实施了一个名为MATURE-HEALTH的健康推荐系统，该系统能够预测电解质不平衡并推荐营养平衡的食物，从而增加早期检测疾病的机会并防止健康进一步恶化。 |
| [^80] | [Implementing Responsible AI: Tensions and Trade-Offs Between Ethics Aspects.](http://arxiv.org/abs/2304.08275) | 本文讨论了负责任人工智能伦理原则之间的紧张关系和权衡，并提出一个目录以帮助人们提高对相互作用的认识。 |
| [^81] | [Chinese Open Instruction Generalist: A Preliminary Release.](http://arxiv.org/abs/2304.07987) | 本论文旨在通过适应不同子任务的固有特性，创建一个中文指令数据集，以填补指令调整技术在中文语言领域的空白。 |
| [^82] | [TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings.](http://arxiv.org/abs/2304.01433) | TPU v4是一款支持嵌入式硬件的可重构光学超级计算机，采用光学电路交换机重新配置互连拓扑，提高规模、可用性、利用率、模块化、部署、安全、功率和性能，它通过SparseCores加速嵌入式模型，性能优越，功耗低。 |
| [^83] | [Wasserstein Auto-encoded MDPs: Formal Verification of Efficiently Distilled RL Policies with Many-sided Guarantees.](http://arxiv.org/abs/2303.12558) | 该论文提出了一种名为WAE-MDP的潜在空间模型，可以从任何RL策略中提取形式可验证控制器，并且具有平衡控制性能和安全之间的效果和解决一些学习缺陷的多方保证。 |
| [^84] | [Hybrid Approach for Solving Real-World Bin Packing Problem Instances Using Quantum Annealers.](http://arxiv.org/abs/2303.01977) | 该研究提出了一个量子-经典混合框架，名为Q4RealBPP，可以考虑真实世界的限制特征，解决三维装箱问题，支持工业和物流行业的需求。 |
| [^85] | [Fairguard: Harness Logic-based Fairness Rules in Smart Cities.](http://arxiv.org/abs/2302.11137) | 本文提出了一种基于时间逻辑的公正智慧城市政策调整和生成方法Fairguard，通过两个阶段的静态生成和动态调节，缓解由多种数据和算法偏见导致的不公正预测结果。 |
| [^86] | [Combat AI With AI: Counteract Machine-Generated Fake Restaurant Reviews on Social Media.](http://arxiv.org/abs/2302.07731) | 本文针对机器生成的虚假评论提出了一种用高质量餐厅评论生成虚假评论并微调GPT输出检测器的方法，该方法预测虚假评论的性能优于现有解决方案。同时，我们还探索了预测非精英评论的模型，并在几个维度上对这些评论进行分析，此类机器生成的虚假评论是社交媒体平台面临的持续挑战。 |
| [^87] | [Anti-unification and Generalization: A Survey.](http://arxiv.org/abs/2302.00277) | 反升级或概括是归纳推理中使用的基本操作，是定理证明的双重操作之一。该调查报告对反升级的研究和应用进行了系统归纳和总结。 |
| [^88] | [PyExperimenter: Easily distribute experiments and track results.](http://arxiv.org/abs/2301.06348) | PyExperimenter是一个专门为算法实证研究设计的工具，能够简化实验设置、执行、文档编写与结果评估，节省大量手动工作。 |
| [^89] | [Speeding up Multi-objective Non-hierarchical Hyperparameter Optimization by Task Similarity-Based Meta-Learning for the Tree-structured Parzen Estimator.](http://arxiv.org/abs/2212.06751) | 本文提出了一种基于任务相似度元学习的方法来加速树形结构Parzen估计中的多目标非分层超参数最优化，实现了最先进的性能。 |
| [^90] | [From CNNs to Shift-Invariant Twin Models Based on Complex Wavelets.](http://arxiv.org/abs/2212.00394) | 论文提出了一种消除OCV（Aliasing）的方法，该方法基于复数卷积，同时采用Gabor样式的卷积核，可以提高卷积神经网络的分类准确性。 |
| [^91] | [c-TPE: Tree-structured Parzen Estimator with Inequality Constraints for Expensive Hyperparameter Optimization.](http://arxiv.org/abs/2211.14411) | 本文提出了约束TPE（c-TPE）方法，是树形Parzen估计器（TPE）的扩展，可有效处理在性能要求之上施加的约束限制，实验证明在81个昂贵的HPO设置中表现出最佳性能排名。 |
| [^92] | [Event Tables for Efficient Experience Replay.](http://arxiv.org/abs/2211.00576) | 本文提出了一种叫做SSET的经验回放采样方法，将缓冲区分为事件表，并采用现有的优先采样策略，大大提高了学习速度和稳定性。 |
| [^93] | [Adaptive patch foraging in deep reinforcement learning agents.](http://arxiv.org/abs/2210.08085) | 本文针对深度强化学习智能体的生态补丁觅食任务，首次证明机器学习智能体可以学习自适应地进行补丁觅食，并且逼近最优行为，并在智能体的内部出现了类似于非人类灵长类动物觅食的单细胞记录的新现象。 |
| [^94] | [GraphMLP: A Graph MLP-Like Architecture for 3D Human Pose Estimation.](http://arxiv.org/abs/2206.06420) | 提出了一种名为GraphMLP的图形增强的MLP式架构，它将图形结构纳入MLP模型中，以满足3D人体姿态的领域特定需求，同时允许局部和全局的空间交互作用。在此基础上，还将GraphMLP灵活高效地扩展到视频领域，并成功地进行了时间动力学的建模。 |
| [^95] | [Translation Consistent Semi-supervised Segmentation for 3D Medical Images.](http://arxiv.org/abs/2203.14523) | 本论文提出了一种名为TraCoCo的半监督学习方法，通过改变输入数据视图的不同空间上下文来扰动训练，从而使模型能够从可视化对象中学习分割模式，实现了三维医学图像的翻译一致半监督分割。 |
| [^96] | [Graph-Relational Domain Adaptation.](http://arxiv.org/abs/2202.03628) | 本研究使用领域图对领域相邻性进行编码，放宽了领域适应的统一对齐方法，实现了非平凡的对齐，并成功地融合了领域信息。 |
| [^97] | [Automatic Identification of Self-Admitted Technical Debt from Four Different Sources.](http://arxiv.org/abs/2202.02387) | 本文提出了一种整合多种来源的自动SATD识别方法，能够有效地找到代码/设计债务、需求债务、文档债务和测试债务。 |
| [^98] | [Cognitively Inspired Learning of Incremental Drifting Concepts.](http://arxiv.org/abs/2110.04662) | 本研究提出了一种基于神经系统学习机制的计算模型，使深度神经网络能够在连续学习环境中学习新概念，并将其学到的知识拓展到新领域。此模型结合多模态分布空间和伪排练记忆机制，可用于克服灾难性遗忘。 |
| [^99] | [MeToo Tweets Sentiment Analysis Using Multi Modal frameworks.](http://arxiv.org/abs/2104.05331) | 本文使用多个模型，在MeToo运动相关的推文中进行情感分类，并在IEEEMBigMM 2020大赛中获得了第5名的好成绩。 |

# 详细

[^1]: 自动将CVE漏洞记录映射到MITRE CWE弱点

    Automated Mapping of CVE Vulnerability Records to MITRE CWE Weaknesses. (arXiv:2304.11130v1 [cs.CR])

    [http://arxiv.org/abs/2304.11130](http://arxiv.org/abs/2304.11130)

    该论文介绍了一种自动将CVE漏洞记录映射到MITRE CWE弱点的方法，并提供了一个手动注释的数据集，可用于解决此问题的监督式机器学习。

    

    最近几年，网络安全威胁和多样性的增加导致了漏洞报告和分析的增加。为了应对这一问题，许多非营利组织在这一领域崛起，如MITRE和OSWAP，他们一直在积极追踪漏洞，并以标准化格式发布防御建议。由于手动生产这种格式的数据非常耗时，因此一些提议试图自动化该过程。不幸的是，采用监督式机器学习解决此问题的一个重要障碍是缺乏公开的专业数据集。在此，我们旨在弥合这一差距。特别是，我们专注于将CVE记录映射到MITRE CWE弱点，并向研究社区发布了一个手动注释的数据集，其中包含4,012条记录。在考虑到人在循环框架的情况下，我们将问题视为排名任务，并旨在采用强化学习来利用其中。

    In recent years, a proliferation of cyber-security threats and diversity has been on the rise culminating in an increase in their reporting and analysis. To counter that, many non-profit organizations have emerged in this domain, such as MITRE and OSWAP, which have been actively tracking vulnerabilities, and publishing defense recommendations in standardized formats. As producing data in such formats manually is very time-consuming, there have been some proposals to automate the process. Unfortunately, a major obstacle to adopting supervised machine learning for this problem has been the lack of publicly available specialized datasets. Here, we aim to bridge this gap. In particular, we focus on mapping CVE records into MITRE CWE Weaknesses, and we release to the research community a manually annotated dataset of 4,012 records for this task. With a human-in-the-loop framework in mind, we approach the problem as a ranking task and aim to incorporate reinforced learning to make use of the
    
[^2]: 树状Parzen估计器：理解其算法组成部分及其在提高实证表现中的作用

    Tree-structured Parzen estimator: Understanding its algorithm components and their roles for better empirical performance. (arXiv:2304.11127v1 [cs.LG])

    [http://arxiv.org/abs/2304.11127](http://arxiv.org/abs/2304.11127)

    该论文介绍了一种广泛使用的贝叶斯优化方法 Tree-structured Parzen estimator (TPE)，并对其控制参数的作用和算法直觉进行了讨论和分析，提供了一组推荐设置并证明其能够提高TPE的性能表现。

    

    许多领域中最近的进展要求更加复杂的实验设计。这种复杂的实验通常有许多参数，需要参数调整。Tree-structured Parzen estimator (TPE) 是一种贝叶斯优化方法，在最近的参数调整框架中被广泛使用。尽管它很受欢迎，但控制参数的角色和算法直觉尚未得到讨论。在本教程中，我们将确定每个控制参数的作用以及它们对超参数优化的影响，使用多种基准测试。我们将从剖析研究中得出的推荐设置与基准方法进行比较，并证明我们的推荐设置提高了TPE的性能。我们的TPE实现可在https://github.com/nabenabe0928/tpe/tree/single-opt中获得。

    Recent advances in many domains require more and more complicated experiment design. Such complicated experiments often have many parameters, which necessitate parameter tuning. Tree-structured Parzen estimator (TPE), a Bayesian optimization method, is widely used in recent parameter tuning frameworks. Despite its popularity, the roles of each control parameter and the algorithm intuition have not been discussed so far. In this tutorial, we will identify the roles of each control parameter and their impacts on hyperparameter optimization using a diverse set of benchmarks. We compare our recommended setting drawn from the ablation study with baseline methods and demonstrate that our recommended setting improves the performance of TPE. Our TPE implementation is available at https://github.com/nabenabe0928/tpe/tree/single-opt.
    
[^3]: 语义学、本体论与解释

    Semantics, Ontology and Explanation. (arXiv:2304.11124v1 [cs.AI])

    [http://arxiv.org/abs/2304.11124](http://arxiv.org/abs/2304.11124)

    本文讨论了语义学、本体论和解释中的概念，并介绍了一种本体拆包的解释概念，即通过揭示符号领域描述的真相制造者来解释概念模型等；还讨论了本体论驱动的概念模型在各种AI决策制定中的关键作用。

    

    “语义”和“本体论”这两个词越来越与“解释”一起出现，不仅在科学文献中，而且在组织交流中也频繁出现。然而，所有这些术语都被大量超载。在本文中，我们讨论它们之间的强关联性，特别是我们讨论了一种解释概念，称为本体拆包，旨在通过揭示其假定的真相制造者——即使那些描述中的命题为真的本体论实体，来解释符号领域描述（概念模型、知识图和逻辑规范）。为了说明这个想法，我们采用了关系的本体论理论，通过揭示标准建模语言UML中编码的非常简单的符号模型的隐藏语义来解释它。我们还讨论了由本形式的解释造成的本体论驱动的概念模型，以及它们在各种形式的基于AI的决策制定中所发挥的关键作用。

    The terms 'semantics' and 'ontology' are increasingly appearing together with 'explanation', not only in the scientific literature, but also in organizational communication. However, all of these terms are also being significantly overloaded. In this paper, we discuss their strong relation under particular interpretations. Specifically, we discuss a notion of explanation termed ontological unpacking, which aims at explaining symbolic domain descriptions (conceptual models, knowledge graphs, logical specifications) by revealing their ontological commitment in terms of their assumed truthmakers, i.e., the entities in one's ontology that make the propositions in those descriptions true. To illustrate this idea, we employ an ontological theory of relations to explain (by revealing the hidden semantics of) a very simple symbolic model encoded in the standard modeling language UML. We also discuss the essential role played by ontology-driven conceptual models (resulting from this form of exp
    
[^4]: 中美合作时，中国和美国在人工智能领域能够产生更大的影响力

    China and the U.S. produce more impactful AI research when collaborating together. (arXiv:2304.11123v1 [cs.CY])

    [http://arxiv.org/abs/2304.11123](http://arxiv.org/abs/2304.11123)

    中国和美国在人工智能领域合作能产生更大影响力，最近数据显示两国自2000年来一直处于领导地位，而大多数人才流失在两国之间。

    

    人工智能已经成为颠覆性技术，有望为掌握其力量的国家带来显著的经济和战略优势。最近，中国推动人工智能技术的采用，正在挑战美国在这一领域的全球领导地位。考虑到人工智能的巨大潜力，以及两国之间激烈的地缘政治紧张局势，已经制定了一些政策，以防止人工智能科学家移民到对方国家或与之合作。然而，这种人才流失和跨境合作的程度还没有被完全了解。在此，我们分析了超过350,000名人工智能科学家和5,000,000篇人工智能文献的数据集。我们发现自2000年以来，中国和美国在影响力、创新性、生产力和劳动力方面一直处于领先地位。大多数移民到中国的人工智能科学家来自美国，而移民到美国的人工智能科学家来自中国，凸显出明显的人才流失现象。

    Artificial Intelligence (AI) has become a disruptive technology, promising to grant a significant economic and strategic advantage to the nations that harness its power. China, with its recent push towards AI adoption, is challenging the U.S.'s position as the global leader in this field. Given AI's massive potential, as well as the fierce geopolitical tensions between the two nations, a number of policies have been put in place that discourage AI scientists from migrating to, or collaborating with, the other country. However, the extents of such brain drain and cross-border collaboration are not fully understood. Here, we analyze a dataset of over 350,000 AI scientists and 5,000,000 AI papers. We find that, since the year 2000, China and the U.S. have been leading the field in terms of impact, novelty, productivity, and workforce. Most AI scientists who migrate to China come from the U.S., and most who migrate to the U.S. come from China, highlighting a notable brain drain in both dir
    
[^5]: BoDiffusion：应用于全身人体运动合成的稀疏观测扩散

    BoDiffusion: Diffusing Sparse Observations for Full-Body Human Motion Synthesis. (arXiv:2304.11118v1 [cs.CV])

    [http://arxiv.org/abs/2304.11118](http://arxiv.org/abs/2304.11118)

    BoDiffusion是一种应用于全身人体运动合成的生成扩散模型，可以通过利用稀疏跟踪输入生成平滑逼真的完整全身运动序列，该方法在逼真度和重建误差方面优于现有最先进的方法。

    

    混合现实应用需要跟踪用户的全身运动以实现沉浸式体验。然而，典型的头戴式设备只能跟踪头部和手部运动，导致由于下半身姿态的变异性而对完整的全身运动重建存在限制。本文提出了BoDiffusion——一种用于运动合成的生成扩散模型，以应对这种欠约束的重建问题。我们提出了一种时空条件方案，使BoDiffusion能够利用稀疏跟踪输入同时生成平滑、逼真的完整全身运动序列。据我们所知，这是第一种利用反向扩散过程将全身跟踪建模为条件序列生成任务的方法。我们在大规模动作捕捉数据集AMASS上进行实验，并证明我们的方法在全身运动逼真度和关节重建误差方面显著优于现有最先进的方法。

    Mixed reality applications require tracking the user's full-body motion to enable an immersive experience. However, typical head-mounted devices can only track head and hand movements, leading to a limited reconstruction of full-body motion due to variability in lower body configurations. We propose BoDiffusion -- a generative diffusion model for motion synthesis to tackle this under-constrained reconstruction problem. We present a time and space conditioning scheme that allows BoDiffusion to leverage sparse tracking inputs while generating smooth and realistic full-body motion sequences. To the best of our knowledge, this is the first approach that uses the reverse diffusion process to model full-body tracking as a conditional sequence generation task. We conduct experiments on the large-scale motion-capture dataset AMASS and show that our approach outperforms the state-of-the-art approaches by a significant margin in terms of full-body motion realism and joint reconstruction error.
    
[^6]: Graph-ToolFormer: 通过ChatGPT增强的提示，赋予LLMs图形推理能力

    Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT. (arXiv:2304.11116v1 [cs.AI])

    [http://arxiv.org/abs/2304.11116](http://arxiv.org/abs/2304.11116)

    本文旨在通过Graph-ToolFormer框架赋予LLMs图形推理能力，并解决现有LLMs在执行图形学习任务中存在的固有弱点。

    

    本文旨在开发一个能够对复杂图形数据进行推理的大语言模型（LLM）。当前，LLMs在各种自然语言学习任务上取得了非常出色的表现，这些扩展也已被应用于研究具有多模态数据的视觉任务。然而，在图形学习任务中，现有的LLMs由于在执行多步逻辑推理、精确的数学计算以及对空间和时间因素的感知方面存在一些固有弱点，因此呈现出非常严重的缺陷。为了解决这些挑战，本文将调查探索赋予现有LLMs图形推理能力的原理、方法和算法，这将对LLMs和图形学习的当前研究产生巨大影响。受最新的ChatGPT和Toolformer模型的启发，我们提出了Graph-ToolFormer（面向图形推理的Toolformer）框架，通过ChatGPT增强的提示来教导LLMs自身，旨在培养他们的图形推理能力。

    In this paper, we aim to develop a large language model (LLM) with the reasoning ability on complex graph data. Currently, LLMs have achieved very impressive performance on various natural language learning tasks, extensions of which have also been applied to study the vision tasks with multi-modal data. However, when it comes to the graph learning tasks, existing LLMs present very serious flaws due to their several inherited weaknesses in performing {multi-step logic reasoning}, {precise mathematical calculation} and {perception about the spatial and temporal factors}.  To address such challenges, in this paper, we will investigate the principles, methodologies and algorithms to empower existing LLMs with graph reasoning ability, which will have tremendous impacts on the current research of both LLMs and graph learning. Inspired by the latest ChatGPT and Toolformer models, we propose the Graph-ToolFormer (Graph Reasoning oriented Toolformer) framework to teach LLMs themselves with pro
    
[^7]: 引发大型语言模型的焦虑会增加它们的探索性和偏见

    Inducing anxiety in large language models increases exploration and bias. (arXiv:2304.11111v1 [cs.CL])

    [http://arxiv.org/abs/2304.11111](http://arxiv.org/abs/2304.11111)

    对大型语言模型施加焦虑能影响它们的探索性和偏见，这需要更多道德考虑和监管。

    

    大型语言模型正在改变机器学习研究，引发公众的辩论。理解这些模型不仅何时能够正常工作和成功，也为什么会失败和行为失常，具有巨大的社会意义。我们提出将计算精神病学的视角转向这些模型产生的输出。本文着眼于Generative Pre-Trained Transformer 3.5，并将其置于精神病学中常见的任务中。结果表明，GPT-3.5对常见的焦虑问卷做出有力的反应，产生比人类主体更高的焦虑分数。此外，使用情绪感应提示可以可预测地改变GPT-3.5的反应。情感感应不仅影响GPT-3.5在衡量探索决策-making的认知任务中的行为，还影响其在之前建立的衡量种族主义和失能主义等偏见的任务中的行为。至关重要的是，GPT-3.5在受到焦虑诱导时呈现出明显的探索性和偏见增加，表明其输出容易受到情感操纵的影响。这些结果突显了在语言模型的开发和使用过程中需要更多的道德考虑和监管。

    Large language models are transforming research on machine learning while galvanizing public debates. Understanding not only when these models work well and succeed but also why they fail and misbehave is of great societal relevance. We propose to turn the lens of computational psychiatry, a framework used to computationally describe and modify aberrant behavior, to the outputs produced by these models. We focus on the Generative Pre-Trained Transformer 3.5 and subject it to tasks commonly studied in psychiatry. Our results show that GPT-3.5 responds robustly to a common anxiety questionnaire, producing higher anxiety scores than human subjects. Moreover, GPT-3.5's responses can be predictably changed by using emotion-inducing prompts. Emotion-induction not only influences GPT-3.5's behavior in a cognitive task measuring exploratory decision-making but also influences its behavior in a previously-established task measuring biases such as racism and ableism. Crucially, GPT-3.5 shows a s
    
[^8]: ChatABL：通过与ChatGPT的自然语言交互实现归纳学习

    ChatABL: Abductive Learning via Natural Language Interaction with ChatGPT. (arXiv:2304.11107v1 [cs.CL])

    [http://arxiv.org/abs/2304.11107](http://arxiv.org/abs/2304.11107)

    本研究提出了一种新方法ChatABL，将大型语言模型LLM整合到归纳学习ABL框架中，通过自然语言对话实现交互式学习，旨在以更加用户友好和易理解的方式统一感知、语言理解和推理能力。实验结果显示，ChatABL可以更有效和高效地学习解决归纳推理问题。

    

    最近，像ChatGPT这样的大型语言模型(LLM)已经展示出在数学能力方面的重大潜力，并提供了一种与人类自然语言一致的有价值的推理范式。然而，由于它们之间底层信息流的不兼容性，LLM目前难以在感知、语言理解和推理能力之间建立桥梁，使得实现自主任务变得具有挑战性。另一方面，用于将感知和推理两种能力整合的归纳学习(ABL)框架在不完整事实的逆向解密方面取得了重大成功，但它受到逻辑推理规则的语义理解不足以及依赖于复杂的领域知识表示的限制。本文提出了一种新方法(ChatABL)，将LLM整合到ABL框架中，旨在以更加用户友好和易理解的方式统一这三种能力。所提出的方法利用LLM的优势通过自然语言交流进行交互式学习，实现归纳推理。ChatABL框架旨在使LLM在感知和推理能力之间建立桥梁，结合深度学习和符号推理的自然语言处理能力。实验结果表明，与现有的ABL模型相比，ChatABL可以更有效和高效地学习解决归纳推理问题。

    Large language models (LLMs) such as ChatGPT have recently demonstrated significant potential in mathematical abilities, providing valuable reasoning paradigm consistent with human natural language. However, LLMs currently have difficulty in bridging perception, language understanding and reasoning capabilities due to incompatibility of the underlying information flow among them, making it challenging to accomplish tasks autonomously. On the other hand, abductive learning (ABL) frameworks for integrating the two abilities of perception and reasoning has seen significant success in inverse decipherment of incomplete facts, but it is limited by the lack of semantic understanding of logical reasoning rules and the dependence on complicated domain knowledge representation. This paper presents a novel method (ChatABL) for integrating LLMs into the ABL framework, aiming at unifying the three abilities in a more user-friendly and understandable manner. The proposed method uses the strengths o
    
[^9]: Atari智能体的近似屏蔽使得安全探索成为可能

    Approximate Shielding of Atari Agents for Safe Exploration. (arXiv:2304.11104v1 [cs.AI])

    [http://arxiv.org/abs/2304.11104](http://arxiv.org/abs/2304.11104)

    本文提出了一种基于屏蔽概念的安全探索的算法，使用世界模型验证策略回滚，不依赖于安全相关抽象或高保真度模拟器。在少量Atari游戏上的实验结果表明，该算法有效性高，减少了安全违规率。

    

    在受限制的情况下平衡探索与保守性是使用强化学习在真实世界中完成有意义任务的一个重要问题。本文提出了一种基于屏蔽概念的安全探索的原理性算法。我们的工作基于潜在屏蔽这一想法，利用世界模型在学习的动力学模型的潜在空间中验证策略回滚。与之前的屏蔽方法不同的是，我们的方法不依赖于安全相关抽象或高保真度模拟器。我们的新算法在此基础上使用安全批判和其他附加特性来提高算法的稳定性和远见性。我们在一小组包含状态相关安全标签的Atari游戏上运行实验，展示了我们方法的有效性。初步结果表明，我们的近似屏蔽算法有效降低了安全违规率。

    Balancing exploration and conservatism in the constrained setting is an important problem if we are to use reinforcement learning for meaningful tasks in the real world. In this paper, we propose a principled algorithm for safe exploration based on the concept of shielding. Previous approaches to shielding assume access to a safety-relevant abstraction of the environment or a high-fidelity simulator. Instead, our work is based on latent shielding another approach that leverages world models to verify policy roll-outs in the latent space of a learned dynamics model. Our novel algorithm builds on this previous work, using safety critics and other additional features to improve the stability and farsightedness of the algorithm. We demonstrate the effectiveness of our approach by running experiments on a small set of Atari games with state dependent safety labels. We present preliminary results that show our approximate shielding algorithm effectively reduces the rate of safety violation
    
[^10]: 不需要训练，跨模态信息检索是否可行？

    Is Cross-modal Information Retrieval Possible without Training?. (arXiv:2304.11095v1 [cs.LG])

    [http://arxiv.org/abs/2304.11095](http://arxiv.org/abs/2304.11095)

    本论文研究了不需要训练，基于简单映射的跨模态信息检索方法，利用来自预训练深度学习模型的编码表示。这种方法可以在语义上将不同模态的数据映射到同一空间，并在文本和图像之间达到有竞争力的性能水平。

    

    预训练深度学习模型中编码的表示(例如BERT文本嵌入，图像的倒数第二个卷积神经网络层激活)传递了一组有益的信息检索特征。给定数据模态的嵌入存在自己的高维空间中，但可以通过简单的映射进行语义对齐。在本文中，我们使用来自最小二乘法和奇异值分解 (SVD) 的简单映射作为Procrustes问题的解决方案，从而实现跨模态信息检索的手段。也就是说，给定一个模态中的信息，例如文本，该映射可以帮助我们在另一个模态中找到与其语义相当的数据项，例如图像。使用现成的预训练深度学习模型，我们在文本到图像和图像到文本的检索任务中尝试了上述简单的跨模态映射。尽管简单，我们的映射表现出竞争性的性能，并达到了与最先进方法相当的水平。

    Encoded representations from a pretrained deep learning model (e.g., BERT text embeddings, penultimate CNN layer activations of an image) convey a rich set of features beneficial for information retrieval. Embeddings for a particular modality of data occupy a high-dimensional space of its own, but it can be semantically aligned to another by a simple mapping without training a deep neural net. In this paper, we take a simple mapping computed from the least squares and singular value decomposition (SVD) for a solution to the Procrustes problem to serve a means to cross-modal information retrieval. That is, given information in one modality such as text, the mapping helps us locate a semantically equivalent data item in another modality such as image. Using off-the-shelf pretrained deep learning models, we have experimented the aforementioned simple cross-modal mappings in tasks of text-to-image and image-to-text retrieval. Despite simplicity, our mappings perform reasonably well reachin
    
[^11]: 去偏见技术的有效性：一个本土的定性分析

    Effectiveness of Debiasing Techniques: An Indigenous Qualitative Analysis. (arXiv:2304.11094v1 [cs.CL])

    [http://arxiv.org/abs/2304.11094](http://arxiv.org/abs/2304.11094)

    本文以本土的视角探讨了针对预训练语言模型去偏见技术的有效性，呼吁在算法中纳入本地知识和理解以确保公正，特别是在面对资源受限的社会时。

    

    本文以本土的视角，探讨了针对预训练语言模型（PLMs）去偏见技术的有效性。目前衡量与去偏见PLMs使用的技术存在美国种族偏见的倾向，并且依赖于预定义的偏见属性（例如“黑人”与“白人”）。有些技术需要大量数据集和进一步的预训练。这样的技术并不能捕捉其他国家中被较少代表的土著人口，例如新西兰的毛利人。必须纳入本地的知识和理解，以确保公正的算法，特别是在面对资源受限的社会时。

    An indigenous perspective on the effectiveness of debiasing techniques for pre-trained language models (PLMs) is presented in this paper. The current techniques used to measure and debias PLMs are skewed towards the US racial biases and rely on pre-defined bias attributes (e.g. "black" vs "white"). Some require large datasets and further pre-training. Such techniques are not designed to capture the underrepresented indigenous populations in other countries, such as M\=aori in New Zealand. Local knowledge and understanding must be incorporated to ensure unbiased algorithms, especially when addressing a resource-restricted society.
    
[^12]: Hi Sheldon! 从电视剧中创建深度个性化角色。

    Hi Sheldon! Creating Deep Personalized Characters from TV Shows. (arXiv:2304.11093v1 [cs.CL])

    [http://arxiv.org/abs/2304.11093](http://arxiv.org/abs/2304.11093)

    从多模态数据中通过DPCC创造出能够与用户进行视听交互的深度个性化数字角色，并收集了一个包含近10k个话语和6个小时音频/视频的角色中心多模态对话数据集。

    

    想象一下，你可以与一个通过人工智能生成的数字角色进行视听交互，其外貌和个性与《生活大爆炸》中的Sheldon几乎一模一样。为了实现这一神奇的视听交互场景，我们提出了一个名为"Deep Personalized Character Creation（DPCC）"的创新任务：从电视剧等多模态数据中创造出个性化角色。具体而言，给定单一或多个模式的文本、音频或视频输入，DPCC旨在生成与某个特定角色（如Sheldon）的个性特点非常匹配且质量高的多模态（文本、音频、视频）响应。为了支持这一创新任务，我们进一步收集了一个名为"Deep Personalized Character Dataset（DPCD）"的角色中心多模态对话数据集，该数据集包含~10k个话语和~6个小时的音频/视频。

    Imagine an interesting multimodal interactive scenario that you can see, hear, and chat with an AI-generated digital character, who is capable of behaving like Sheldon from The Big Bang Theory, as a DEEP copy from appearance to personality. Towards this fantastic multimodal chatting scenario, we propose a novel task, named Deep Personalized Character Creation (DPCC): creating multimodal chat personalized characters from multimodal data such as TV shows. Specifically, given a single- or multi-modality input (text, audio, video), the goal of DPCC is to generate a multi-modality (text, audio, video) response, which should be well-matched the personality of a specific character such as Sheldon, and of high quality as well. To support this novel task, we further collect a character centric multimodal dialogue dataset, named Deep Personalized Character Dataset (DPCD), from TV shows. DPCD contains character-specific multimodal dialogue data of ~10k utterances and ~6 hours of audio/video per c
    
[^13]: 在ChatGPT时代迈向负责任的人工智能：用于设计基于基础模型的AI系统的参考架构

    Towards Responsible AI in the Era of ChatGPT: A Reference Architecture for Designing Foundation Model-based AI Systems. (arXiv:2304.11090v1 [cs.CL])

    [http://arxiv.org/abs/2304.11090](http://arxiv.org/abs/2304.11090)

    本文提出了一个以模式为导向的负责任AI-by-design参考架构，用于设计基于基础模型的AI系统，重点关注可解释性、公平性、安全性和鲁棒性等关键设计元素。

    

    ChatGPT、Bard和其他大型语言模型(LLM)聊天机器人的推出在全球范围内引起了巨大关注。基础模型将成为未来大多数AI系统的基础构建块的趋势正在增长。然而，将基础模型纳入AI系统引发了对负责任AI的重大关注，这是由于其黑匣子性质和快速发展的超级智能引起的。此外，基础模型的增长能力最终可能会吞噬AI系统的其他组件，引入架构设计中的运动边界和接口演变挑战。为了应对这些挑战，本文提出了一种以模式为导向的负责任AI-by-design参考架构，用于设计基于基础模型的AI系统。特别地，本文首先呈现了基于基础模型的AI系统在架构演进方面的发展，从"基础模型作为连接器"到"基础模型作为单片机核"。然后，它提出了一个参考架构，包括五个类别的模式，重点关注关键设计元素，例如可解释性、公平性、安全性和鲁棒性。所提出的参考架构为设计负责任的基础模型的AI系统提供了系统化和透明的方法。

    The release of ChatGPT, Bard, and other large language model (LLM)-based chatbots has drawn huge attention on foundations models worldwide. There is a growing trend that foundation models will serve as the fundamental building blocks for most of the future AI systems. However, incorporating foundation models in AI systems raises significant concerns about responsible AI due to their black box nature and rapidly advancing super-intelligence. Additionally, the foundation model's growing capabilities can eventually absorb the other components of AI systems, introducing the moving boundary and interface evolution challenges in architecture design. To address these challenges, this paper proposes a pattern-oriented responsible-AI-by-design reference architecture for designing foundation model-based AI systems. Specially, the paper first presents an architecture evolution of AI systems in the era of foundation models, from "foundation-model-as-a-connector" to "foundation-model-as-a-monolithi
    
[^14]: 使用新闻标题来分析新闻传播障碍

    Profiling the news spreading barriers using news headlines. (arXiv:2304.11088v1 [cs.CL])

    [http://arxiv.org/abs/2304.11088](http://arxiv.org/abs/2304.11088)

    本文利用新闻标题的语义知识和情感特征来对新闻传播障碍进行分类，可以有效地检测新闻传播障碍。

    

    新闻标题可以是检测新闻媒体中新闻传播障碍的好数据源，在许多实际应用中非常有用。本文利用基于推理的模型COMET的语义知识和新闻标题的情感特征来对障碍进行分类。我们考虑了文化、经济、政治、语言和地理等五种障碍，以及包括健康、运动、科学、娱乐、游戏、住房、社会、购物、计算机和商业等不同类型的新闻标题。为此，我们利用新闻出版商的元数据自动收集和标记新闻标题，以此来检测新闻传播障碍。我们将我们的方法与传统的文本分类方法、深度学习和基于transformer的方法进行了比较。结果表明，利用推理为基础的语义知识和情感特征的方法可以有效地检测新闻传播障碍。

    News headlines can be a good data source for detecting the news spreading barriers in news media, which may be useful in many real-world applications. In this paper, we utilize semantic knowledge through the inference-based model COMET and sentiments of news headlines for barrier classification. We consider five barriers including cultural, economic, political, linguistic, and geographical, and different types of news headlines including health, sports, science, recreation, games, homes, society, shopping, computers, and business. To that end, we collect and label the news headlines automatically for the barriers using the metadata of news publishers. Then, we utilize the extracted commonsense inferences and sentiments as features to detect the news spreading barriers. We compare our approach to the classical text classification methods, deep learning, and transformer-based methods. The results show that the proposed approach using inferences-based semantic knowledge and sentiment offe
    
[^15]: AI产品安全：开发者入门指南

    AI Product Security: A Primer for Developers. (arXiv:2304.11087v1 [cs.CR])

    [http://arxiv.org/abs/2304.11087](http://arxiv.org/abs/2304.11087)

    本文旨在为AI软件产品的开发人员、设计师、管理者和研究人员介绍AI产品安全的基础，让他们了解机器学习产品的威胁并避免常见陷阱。

    

    不久以前，AI安全就意味着如何利用AI增强网络安全的研究和实践，即安全的AI。自从Ian Goodfellow及其团队广泛应用对抗性攻击于机器学习之后，AI安全成为一个重要的问题，也是AI安全的一部分。了解机器学习产品的威胁并避免AI产品开发中的常见陷阱至关重要。本文面向AI软件产品的开发人员、设计师、管理者和研究人员。

    Not too long ago, AI security used to mean the research and practice of how AI can empower cybersecurity, that is, AI for security. Ever since Ian Goodfellow and his team popularized adversarial attacks on machine learning, security for AI became an important concern and also part of AI security. It is imperative to understand the threats to machine learning products and avoid common pitfalls in AI product development. This article is addressed to developers, designers, managers and researchers of AI software products.
    
[^16]: ICICLE CI服务认证的客户端和应用程序的开发--REHS计划最终报告（2022年6月-8月）。

    Development of Authenticated Clients and Applications for ICICLE CI Services -- Final Report for the REHS Program, June-August, 2022. (arXiv:2304.11086v1 [cs.CR])

    [http://arxiv.org/abs/2304.11086](http://arxiv.org/abs/2304.11086)

    本论文介绍了ICICLE智能环境计算学习人工智能研究所开发的Jupyter Notebooks和Python命令行客户端，使用ICICLE身份验证机制访问ICICLE资源和服务。使用了Tapis框架和Neo4j将数据组织成一个知识图谱（KG），并演示了使用该软件的几个客户端，验证了使用Tapis和Neo4j开发认证客户端访问网络基础设施服务的可行性。

    

    ICICLE智能环境计算学习人工智能研究所的目标是通过建立下一代网络基础设施，使人工智能更具普适性并推动其在更大范围内的民主化。本研究描述了我们开发的Jupyter Notebooks和Python命令行客户端，这些客户端使用ICICLE身份验证机制访问ICICLE资源和服务。我们使用支持科学家访问、利用和管理多院校资源和服务的Tapis框架来连接客户端。我们使用Neo4j将数据组织成一个知识图谱（KG）。然后，我们将KG托管在Tapis Pod上，Tapis Pod提供一个特别为Neo4j KG而制作的模板进行持久数据存储。为了演示我们软件的功能，我们开发了几个客户端：Jupyter笔记本身份验证、使用ICICLE资源进行神经网络训练，以及用于访问ICICLE服务的命令行界面。我们的工作证明了使用Tapis和Neo4j开发访问网络基础设施服务的认证客户端的可行性。

    The Artificial Intelligence (AI) institute for Intelligent Cyberinfrastructure with Computational Learning in the Environment (ICICLE) is funded by the NSF to build the next generation of Cyberinfrastructure to render AI more accessible to everyone and drive its further democratization in the larger society. We describe our efforts to develop Jupyter Notebooks and Python command line clients that would access these ICICLE resources and services using ICICLE authentication mechanisms. To connect our clients, we used Tapis, which is a framework that supports computational research to enable scientists to access, utilize, and manage multi-institution resources and services. We used Neo4j to organize data into a knowledge graph (KG). We then hosted the KG on a Tapis Pod, which offers persistent data storage with a template made specifically for Neo4j KGs. In order to demonstrate the capabilities of our software, we developed several clients: Jupyter notebooks authentication, Neural Network
    
[^17]: 大型语言模型对齐的基本限制

    Fundamental Limitations of Alignment in Large Language Models. (arXiv:2304.11082v1 [cs.CL])

    [http://arxiv.org/abs/2304.11082](http://arxiv.org/abs/2304.11082)

    本文通过提出一种理论方法——行为期望边界（BEB），展示了大型语言模型中对齐的基本限制，并证明任何对齐过程都无法根除不希望的行为，这对于防止恶意攻击是不安全的。

    

    开发与人交互的语言模型的重要方面是对齐其行为，使其对其人类用户有用且无害。这通常通过调整模型的方式来实现，以增强所需的行为并抑制不希望的行为。在本文中，我们提出了一种名为行为期望边界(BEB)的理论方法，它允许我们正式研究大型语言模型中的几个内在特征和对齐的限制。重要的是，我们证明对于任何具有被该模型表现出的有限概率的行为，都存在可以触发模型输出此行为的提示，其概率随提示的长度增加而增加。这意味着任何减弱不希望的行为但未将其完全消除的对齐过程都无法抵御针对性攻击。此外，我们的框架提示了领先的

    An important aspect in developing language models that interact with humans is aligning their behavior to be useful and unharmful for their human users. This is usually achieved by tuning the model in a way that enhances desired behaviors and inhibits undesired ones, a process referred to as alignment. In this paper, we propose a theoretical approach called Behavior Expectation Bounds (BEB) which allows us to formally investigate several inherent characteristics and limitations of alignment in large language models. Importantly, we prove that for any behavior that has a finite probability of being exhibited by the model, there exist prompts that can trigger the model into outputting this behavior, with probability that increases with the length of the prompt. This implies that any alignment process that attenuates undesired behavior but does not remove it altogether, is not safe against adversarial prompting attacks. Furthermore, our framework hints at the mechanism by which leading al
    
[^18]: HeRo: RoBERTa和 Longformer的希伯来语言模型

    HeRo: RoBERTa and Longformer Hebrew Language Models. (arXiv:2304.11077v1 [cs.CL])

    [http://arxiv.org/abs/2304.11077](http://arxiv.org/abs/2304.11077)

    本论文提供了希伯来语言处理社区所需的最大预训练数据集HeDC4，以及两种表现最先进的预训练语言模型：用于标准长度输入的HeRo和用于长输入序列的LongHeRo。两个模型在多项任务中实现了最先进的性能。

    

    本文填补了希伯来语自然语言处理（NLP）社区现有资源的空白，提供迄今最大的预训练数据集HeDC4、用于标准长度输入的最先进的预训练语言模型HeRo以及用于长输入序列的高效transformer LongHeRo. HeRo 模型在情感分析、命名实体识别和问答任务中进行了评估，而 LongHeRo 模型在由长文档组成的文档分类任务中进行了评估。 这两个模型均呈现出最先进的性能。本文使用的数据集和模型检查点是公开可用的。

    In this paper, we fill in an existing gap in resources available to the Hebrew NLP community by providing it with the largest so far pre-train dataset HeDC4, a state-of-the-art pre-trained language model HeRo for standard length inputs and an efficient transformer LongHeRo for long input sequences. The HeRo model was evaluated on the sentiment analysis, the named entity recognition, and the question answering tasks while the LongHeRo model was evaluated on the document classification task with a dataset composed of long documents. Both HeRo and LongHeRo presented state-of-the-art performance. The dataset and model checkpoints used in this work are publicly available.
    
[^19]: “类ChatGPT生成模型能否保证事实准确性？新一代搜索引擎的失误”

    Can ChatGPT-like Generative Models Guarantee Factual Accuracy? On the Mistakes of New Generation Search Engines. (arXiv:2304.11076v1 [cs.CL])

    [http://arxiv.org/abs/2304.11076](http://arxiv.org/abs/2304.11076)

    论文质疑类ChatGPT生成模型是否能保证事实准确性，很多新一代搜索引擎的公开演示中存在事实错误，呼吁科研人员和开发人员提高透明度和事实正确性。

    

    尽管像OpenAI的ChatGPT这样的大型对话型AI模型展现出了巨大的潜力，但我们质疑这些模型能否保证事实准确性。最近，微软和谷歌等科技公司宣布了旨在将搜索引擎与对话型AI相结合的新服务。然而，我们发现公开演示中存在许多错误，这表明我们不应轻易相信AI模型的事实主张。我们希望呼吁研究人员和开发人员改善AI模型的透明度和事实正确性，而不是批评特定的模型或公司。

    Although large conversational AI models such as OpenAI's ChatGPT have demonstrated great potential, we question whether such models can guarantee factual accuracy. Recently, technology companies such as Microsoft and Google have announced new services which aim to combine search engines with conversational AI. However, we have found numerous mistakes in the public demonstrations that suggest we should not easily trust the factual claims of the AI models. Rather than criticizing specific models or companies, we hope to call on researchers and developers to improve AI models' transparency and factual correctness.
    
[^20]: 一种基于语义漏洞图的无偏Transformer源代码学习方法

    An Unbiased Transformer Source Code Learning with Semantic Vulnerability Graph. (arXiv:2304.11072v1 [cs.CR])

    [http://arxiv.org/abs/2304.11072](http://arxiv.org/abs/2304.11072)

    该论文提出了一种基于语义漏洞图的无偏Transformer源代码学习方法，通过利用从源代码中得到的语义漏洞图（SVG）表示来解决当前漏洞筛选技术对于识别新漏洞或为开发人员提供漏洞和分类方面的效果不佳的问题，并在公开数据集上实现了最先进的性能。

    

    随着时间的推移，开源软件系统已经成为威胁行为者的猎物。尽管开源社区快速采取措施修补漏洞，但代码漏洞筛选应该成为敏捷软件开发的一部分，以便从一开始就能够识别新漏洞或向开发人员提供漏洞和分类。然而，当前的漏洞筛选技术对于识别新漏洞或为开发人员提供代码漏洞和分类方面的效果不佳。此外，用于漏洞学习的数据集由于攻击者部署的新攻击策略而展示出与实际测试分布的差异，导致机器学习模型的性能可能会受到阻碍或偏倚。为了解决这些问题，我们提出了一个联合插值多任务无偏漏洞分类器，包括Transformer "RoBERTa"和图卷积神经网络（GCN）。我们提出了一个训练过程，利用从源代码中得到的语义漏洞图（SVG）表示，该表示是由代码结构和函数创建的。我们的方法在公开数据集上实现了最先进的性能，解决了性能偏差的问题，并提高了识别新漏洞的准确性。

    Over the years, open-source software systems have become prey to threat actors. Even as open-source communities act quickly to patch the breach, code vulnerability screening should be an integral part of agile software development from the beginning. Unfortunately, current vulnerability screening techniques are ineffective at identifying novel vulnerabilities or providing developers with code vulnerability and classification. Furthermore, the datasets used for vulnerability learning often exhibit distribution shifts from the real-world testing distribution due to novel attack strategies deployed by adversaries and as a result, the machine learning model's performance may be hindered or biased. To address these issues, we propose a joint interpolated multitasked unbiased vulnerability classifier comprising a transformer "RoBERTa" and graph convolution neural network (GCN). We present a training process utilizing a semantic vulnerability graph (SVG) representation from source code, creat
    
[^21]: 对话过程建模：现状、应用和实践影响的综述

    Conversational Process Modelling: State of the Art, Applications, and Implications in Practice. (arXiv:2304.11065v1 [cs.CL])

    [http://arxiv.org/abs/2304.11065](http://arxiv.org/abs/2304.11065)

    本文系统的研究了现有聊天机器人对于支持对话式流程建模所提供的应用场景，并推导出了在实践中使用聊天机器人进行对话式流程建模的建议。

    

    最近Chatbots等聊天机器人引起了极大的关注。对于BPM应用来说，如何应用聊天机器人来生成商业价值通常是不明确的。因此，本文旨在系统地分析现有的聊天机器人对于支持对话式流程建模作为面向流程的能力的支持。该研究识别了沿流程生命周期的应用场景，然后进行了对话式流程建模的系统文献综述。得出的分类学用作对话式流程建模的应用场景的识别，包括流程描述的释义和改进。应用场景基于高等教育领域的实际测试集对现有聊天机器人进行评估。该测试集包含流程描述及其对应的流程模型，以及模型质量的评估。基于文献和应用场景分析，得出了关于在对话式流程建模中使用聊天机器人的建议。

    Chatbots such as ChatGPT have caused a tremendous hype lately. For BPM applications, it is often not clear how to apply chatbots to generate business value. Hence, this work aims at the systematic analysis of existing chatbots for their support of conversational process modelling as process-oriented capability. Application scenarios are identified along the process life cycle. Then a systematic literature review on conversational process modelling is performed. The resulting taxonomy serves as input for the identification of application scenarios for conversational process modelling, including paraphrasing and improvement of process descriptions. The application scenarios are evaluated for existing chatbots based on a real-world test set from the higher education domain. It contains process descriptions as well as corresponding process models, together with an assessment of the model quality. Based on the literature and application scenario analyses, recommendations for the usage (prac
    
[^22]: 慎思之后再行动：将语言推理与动作统一的交错策略方法

    Think Before You Act: Unified Policy for Interleaving Language Reasoning with Actions. (arXiv:2304.11063v1 [cs.CL])

    [http://arxiv.org/abs/2304.11063](http://arxiv.org/abs/2304.11063)

    本文提出了一种新的方法，将语言推理与动作统一在单个策略中，利用 transformer 模型，能够生成交替使用动作的文本标题。在 BabyAI 任务中测试，我们的推理策略始终优于没有标题的基准线。

    

    带有语言建模目标的 transformer 模型的成功训练为强化学习框架带来了一个有前途的机会，Decision Transformer 是朝着这个方向迈出的一步，展示了如何在离线数据上训练类似的下一步预测目标的 transformers；而这个领域的另一个重要发展是近期出现了从互联网收集而来的大规模数据集，例如由视频教程和字幕组成的数据集，其中的人们讲述他们正在做的事情。为了利用这种语言组件，我们提出了一种将语言推理和动作统一在单个策略中的新方法。具体来说，我们增加了一个带有单词输出的 transformer 策略，以便它可以生成交替使用动作的文本标题。在最具挑战性的 BabyAI 任务中测试，我们的推理策略在描述下一个子目标的标题上，始终优于没有标题的基准线。

    The success of transformer models trained with a language modeling objective brings a promising opportunity to the reinforcement learning framework. Decision Transformer is a step towards this direction, showing how to train transformers with a similar next-step prediction objective on offline data. Another important development in this area is the recent emergence of large-scale datasets collected from the internet, such as the ones composed of tutorial videos with captions where people talk about what they are doing. To take advantage of this language component, we propose a novel method for unifying language reasoning with actions in a single policy. Specifically, we augment a transformer policy with word outputs, so it can generate textual captions interleaved with actions. When tested on the most challenging task in BabyAI, with captions describing next subgoals, our reasoning policy consistently outperforms the caption-free baseline.
    
[^23]: 利用RMT将Transformer扩展到100万个标记及以上。

    Scaling Transformer to 1M tokens and beyond with RMT. (arXiv:2304.11062v1 [cs.CL])

    [http://arxiv.org/abs/2304.11062](http://arxiv.org/abs/2304.11062)

    本文介绍了一种利用循环记忆扩展BERT上下文长度的方法，成功扩展到了前所未有的200万个标记，有望增强自然语言处理中的长期依赖处理并为内存密集型应用程序实现大规模上下文处理。

    

    本技术报告介绍了一种利用循环记忆扩展BERT上下文长度的方法，BERT是自然语言处理中最有效的基于Transformer模型之一。通过利用循环记忆Transformer架构，我们成功地将模型的有效上下文长度增加到了前所未有的200万个标记，同时保持了高的内存检索准确性。我们的方法允许存储和处理本地和全局信息，并通过使用循环实现输入序列各部分之间的信息流动。我们的实验证明了我们的方法的有效性，具有显著的潜力来增强自然语言理解和生成任务中的长期依赖处理，并能够为内存密集型应用程序实现大规模上下文处理。

    This technical report presents the application of a recurrent memory to extend the context length of BERT, one of the most effective Transformer-based models in natural language processing. By leveraging the Recurrent Memory Transformer architecture, we have successfully increased the model's effective context length to an unprecedented two million tokens, while maintaining high memory retrieval accuracy. Our method allows for the storage and processing of both local and global information and enables information flow between segments of the input sequence through the use of recurrence. Our experiments demonstrate the effectiveness of our approach, which holds significant potential to enhance long-term dependency handling in natural language understanding and generation tasks as well as enable large-scale context processing for memory-intensive applications.
    
[^24]: CEIL：一种通用的分类增强迭代学习框架用于文本聚类

    CEIL: A General Classification-Enhanced Iterative Learning Framework for Text Clustering. (arXiv:2304.11061v1 [cs.CL])

    [http://arxiv.org/abs/2304.11061](http://arxiv.org/abs/2304.11061)

    CEIL是一种迭代学习框架，通过引入分类目标来改进特征表示和文本聚类效果，能够普适于不同领域的文本聚类任务。

    

    作为无监督学习中最基本的挑战之一，文本聚类旨在将语义上相似的文本段分组，而不依赖于人工注释。随着深度学习的迅速发展，深度聚类在传统聚类方法上取得了显著优势。尽管有效，大多数现有的深度文本聚类方法严重依赖于在一般领域预训练的表示，这可能不是在特定目标领域聚类的最佳解决方案。为了解决这个问题，我们提出了CEIL，一种新颖的短文本聚类分类增强迭代学习框架，旨在通过将分类目标引入迭代地改进特征表示的方法，从而普遍提高聚类性能。在每个迭代中，我们首先采用语言模型检索初始文本表示，然后使用我们提出的分类不可分割分布（CDC）模块收集聚类结果。然后，我们引入分类模块将分类目标整合到聚类框架中，并使用得到的改进特征表示在下一次迭代中。对多个基准数据集的广泛实验证明了CEIL的有效性以及其优于现有最先进算法的优越性。

    Text clustering, as one of the most fundamental challenges in unsupervised learning, aims at grouping semantically similar text segments without relying on human annotations. With the rapid development of deep learning, deep clustering has achieved significant advantages over traditional clustering methods. Despite the effectiveness, most existing deep text clustering methods rely heavily on representations pre-trained in general domains, which may not be the most suitable solution for clustering in specific target domains. To address this issue, we propose CEIL, a novel Classification-Enhanced Iterative Learning framework for short text clustering, which aims at generally promoting the clustering performance by introducing a classification objective to iteratively improve feature representations. In each iteration, we first adopt a language model to retrieve the initial text representations, from which the clustering results are collected using our proposed Category Disentangled Contr
    
[^25]: SkillGPT: 一种使用大型语言模型进行技能提取和标准化的RESTful API服务

    SkillGPT: a RESTful API service for skill extraction and standardization using a Large Language Model. (arXiv:2304.11060v1 [cs.CL])

    [http://arxiv.org/abs/2304.11060](http://arxiv.org/abs/2304.11060)

    SkillGPT是一种使用大型语言模型进行技能提取和标准化的RESTful API服务，通过摘要和向量相似性搜索平衡速度和准确度。

    

    我们提出了 SkillGPT，一种利用开源的大型语言模型 (LLM) 进行从自由风格职位描述和用户资料中进行技能提取和标准化 (SES) 的工具。与大多数类似任务的以前方法不同，SkillGPT 直接使用最新的对话 LLM 进行标准技能的提示，通过摘要和向量相似性搜索来平衡速度和准确度。因此，我们的免费 SkillGPT 让用户能够高效可靠地进行对话型 SES。

    We present SkillGPT, a tool for skill extraction and standardization (SES) from free-style job descriptions and user profiles with an open-source Large Language Model (LLM) as backbone. Most previous methods for similar tasks either need supervision or rely on heavy data-preprocessing and feature engineering. Directly prompting the latest conversational LLM for standard skills, however, is slow, costly and inaccurate. In contrast, SkillGPT utilizes a LLM to perform its tasks in steps via summarization and vector similarity search, to balance speed with precision. The backbone LLM of SkillGPT is based on Llama, free for academic use and thus useful for exploratory research and prototype development. Hence, our cost-free SkillGPT gives users the convenience of conversational SES, efficiently and reliably.
    
[^26]: RL网络操作代理的多智能体网络战仿真

    A Multiagent CyberBattleSim for RL Cyber Operation Agents. (arXiv:2304.11052v1 [cs.CR])

    [http://arxiv.org/abs/2304.11052](http://arxiv.org/abs/2304.11052)

    本文介绍了一种新的对抗训练环境——CyberBattleSim，设计用于RL网络操作代理的训练。本文着重报道了对防御型蓝色代理训练的改进，结果表明红色代理与蓝色代理联合训练可以有效提高蓝色代理的防御能力。

    

    硬化网络资产既至关重要，又需要耗费大量的人力。近年来，机器学习（ML）和强化学习（RL）等技术已经展现了在自动化任务方面的巨大潜力，可以自主完成人力无法胜任的重复性任务。然而，开发自主RL代理需要一个对抗训练环境，可以快速评估各种情况，并针对不同场景进行训练。CyberBattleSim便是这样一个针对红色代理（即攻击者）的训练环境，在其基础上添加了针对蓝色代理（即防御者）的训练控制，本文介绍了我们的这些改进，以及在使用这些改进后针对蓝色代理训练时所获得的结果。我们的结果表明针对蓝色代理的训练确实能够增强其对抗攻击的能力，特别是和红色代理一起训练时其效果更佳。

    Hardening cyber physical assets is both crucial and labor-intensive. Recently, Machine Learning (ML) in general and Reinforcement Learning RL) more specifically has shown great promise to automate tasks that otherwise would require significant human insight/intelligence. The development of autonomous RL agents requires a suitable training environment that allows us to quickly evaluate various alternatives, in particular how to arrange training scenarios that pit attackers and defenders against each other. CyberBattleSim is a training environment that supports the training of red agents, i.e., attackers. We added the capability to train blue agents, i.e., defenders. The paper describes our changes and reports on the results we obtained when training blue agents, either in isolation or jointly with red agents. Our results show that training a blue agent does lead to stronger defenses against attacks. In particular, training a blue agent jointly with a red agent increases the blue agent's
    
[^27]: 情感社交化人形智能系统

    Affective social anthropomorphic intelligent system. (arXiv:2304.11046v1 [cs.SD])

    [http://arxiv.org/abs/2304.11046](http://arxiv.org/abs/2304.11046)

    本研究提出了一种情感社交化人形智能系统，可以更好地理解人类声音的情感语义，实现类人对话。

    

    人类的对话风格可以通过幽默感、个性和语调来衡量。这些特征已经成为对话智能虚拟助手的关键。然而，大多数最先进的智能虚拟助手（IVAs）无法解释人类声音的情感语义。本研究提出了一个人形智能系统，可以通过表达情感和个性来进行类人对话。同时，提出了一种语音风格转换方法，可以将特定情感的属性映射出来。首先，通过将时间音频波形数据转换为频域数据（Mel-Spectrogram），创建了离散的音频特征模式，如音符、音调、节奏、旋律等等。并使用一个外部CNN-Transformer-Encoder模型来预测声音中的七种不同的情感状态。同时，该模型将语音输入到一个RNN模型（Deep-speech）中，生成对音频的文本转录。然后，转录文本将通过一个transformer解码器与相应情感的响应一起产生。

    Human conversational styles are measured by the sense of humor, personality, and tone of voice. These characteristics have become essential for conversational intelligent virtual assistants. However, most of the state-of-the-art intelligent virtual assistants (IVAs) are failed to interpret the affective semantics of human voices. This research proposes an anthropomorphic intelligent system that can hold a proper human-like conversation with emotion and personality. A voice style transfer method is also proposed to map the attributes of a specific emotion. Initially, the frequency domain data (Mel-Spectrogram) is created by converting the temporal audio wave data, which comprises discrete patterns for audio features such as notes, pitch, rhythm, and melody. A collateral CNN-Transformer-Encoder is used to predict seven different affective states from voice. The voice is also fed parallelly to the deep-speech, an RNN model that generates the text transcription from the spectrogram. Then t
    
[^28]: 用于模拟内容可寻址存储器的模拟反馈控制忆阻器编程电路

    Analog Feedback-Controlled Memristor programming Circuit for analog Content Addressable Memory. (arXiv:2304.11030v1 [cs.ET])

    [http://arxiv.org/abs/2304.11030](http://arxiv.org/abs/2304.11030)

    本文提出了一种模拟反馈控制忆阻器编程电路，使用新颖的基于查找表的编程算法，可以在单向顺序过程中执行忆阻器的编程和验证，解决了现有算法中频繁切换带来的高动态功率和长编程时间的缺陷。

    

    最近的联想存储器突破表明，硅存储器正越来越接近人类记忆，特别是对于能够读写模拟值的忆阻器内容可寻址存储器（CAM）。然而，现有的忆阻器编程算法需要频繁地在验证和编程忆阻器导纳之间进行切换，这带来许多缺陷，如高动态功率和长的编程时间。本文提出了一种模拟反馈控制忆阻器编程电路，该电路采用新颖的基于查找表的编程算法。使用所提出的算法，可以在单向顺序过程中执行忆阻器的编程和验证。此外，我们还将单个所提出的编程电路与8个模拟CAM（aCAM）单元集成，以构建aCAM阵列。我们在TSMC 28nm工艺上进行了SPICE仿真。理论分析表明：1. A

    Recent breakthroughs in associative memories suggest that silicon memories are coming closer to human memories, especially for memristive Content Addressable Memories (CAMs) which are capable to read and write in analog values. However, the Program-Verify algorithm, the state-of-the-art memristor programming algorithm, requires frequent switching between verifying and programming memristor conductance, which brings many defects such as high dynamic power and long programming time. Here, we propose an analog feedback-controlled memristor programming circuit that makes use of a novel look-up table-based (LUT-based) programming algorithm. With the proposed algorithm, the programming and the verification of a memristor can be performed in a single-direction sequential process. Besides, we also integrated a single proposed programming circuit with eight analog CAM (aCAM) cells to build an aCAM array. We present SPICE simulations on TSMC 28nm process. The theoretical analysis shows that 1. A
    
[^29]: 预测中的外在数据：一种用于关联评估的FARM方法

    Exogenous Data in Forecasting: FARM -- An Approach for Relevance Evaluation. (arXiv:2304.11028v1 [eess.SP])

    [http://arxiv.org/abs/2304.11028](http://arxiv.org/abs/2304.11028)

    该论文介绍了一种名为FARM的方法，用于有效处理实时数据流并提供平衡的相关性度量，进而确定外部数据在预测中的重要性。

    

    外在数据被认为在提高预测准确性方面起着关键作用。针对恰当的选择，全面的相关性分析是一个基本的第一步，从外在数据与参考时间序列的相似性开始。受现有时间序列相似性指标的启发，我们介绍了一种名为FARM（前向角相关度量）的新方法，能够有效地处理实时数据流。我们的前向方法依赖于一种角度特征，该特征利用后续数据点的变化比较来对齐经过时间变形的序列。所提出的算法结合了本地和全局指标，提供了一个平衡的相关性度量。这导致将部分、中间匹配也视为外在数据序列重要指标的考虑因素。作为第一步验证，我们介绍了我们的FARM方法对合成但具有代表性的信号和真实世界时间序列记录的应用。同时展示了FARM方法提高了预测准确度的结果。

    Exogenous data is believed to play a key role for increasing forecasting accuracy. For an appropriate selection, a throughout relevance analysis is a fundamental first step, starting from the exogenous data similarity with the reference time series. Inspired by existing metrics for time series similarity, we introduce a new approach named FARM - Forward Angular Relevance Measure, able to effectively deal with real-time data streams. Our forward method relies on an angular feature that compares changes in subsequent data points to align time-warped series in an efficient way. The proposed algorithm combines local and global measures to provide a balanced relevance measure. This results in considering also partial, intermediate matches as relevant indicators for exogenous data series significance. As a first validation step, we present the application of our FARM approach to both synthetic but representative signals and real-world time series recordings. While demonstrating the improved 
    
[^30]: 机器人辅助施工装配的自动化顺序规划：基于ChatGPT的RoboGPT

    Robot-Enabled Construction Assembly with Automated Sequence Planning based on ChatGPT: RoboGPT. (arXiv:2304.11018v1 [cs.RO])

    [http://arxiv.org/abs/2304.11018](http://arxiv.org/abs/2304.11018)

    该论文介绍了一种基于大型语言模型ChatGPT的RoboGPT系统，用于机器人辅助施工装配中的自动化顺序规划。该系统可克服其他方法在适应能力和可扩展性方面的局限性。

    

    机器人在施工中的应用已经成为解决诸多挑战的有希望的解决方案，如成本上涨、劳动力短缺以及对安全、高效施工工艺的需求。然而，实现这些机器人系统的全部潜力面临的一个主要障碍是对施工任务进行有效且高效的顺序规划。目前的方法包括数学和启发式技术或机器学习方法，在适应能力和可扩展性方面存在局限性。为了扩展当前机器人系统的顺序理解能力，本文介绍了基于大型语言模型ChatGPT的先进推理能力的RoboGPT，用于机器人辅助施工装配中的自动化顺序规划。该系统采用了ChatGPT构建施工顺序规划，通过实验证明其可行性和有效性。

    Robot-based assembly in construction has emerged as a promising solution to address numerous challenges such as increasing costs, labor shortages, and the demand for safe and efficient construction processes. One of the main obstacles in realizing the full potential of these robotic systems is the need for effective and efficient sequence planning for construction tasks. Current approaches, including mathematical and heuristic techniques or machine learning methods, face limitations in their adaptability and scalability to dynamic construction environments. To expand the ability of the current robot system in sequential understanding, this paper introduces RoboGPT, a novel system that leverages the advanced reasoning capabilities of ChatGPT, a large language model, for automated sequence planning in robot-based assembly applied to construction tasks. The proposed system adapts ChatGPT for construction sequence planning and demonstrate its feasibility and effectiveness through experimen
    
[^31]: DIN-SQL: 自纠正的文本到SQL分解式上下文学习

    DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction. (arXiv:2304.11015v1 [cs.CL])

    [http://arxiv.org/abs/2304.11015](http://arxiv.org/abs/2304.11015)

    DIN-SQL通过将复杂的文本到SQL任务分解为子问题，并将这些子问题的解决方案馈入到大型语言模型中，显著提高了它们的表现，使准确性超过了当前最先进的技术。

    

    本文研究了将复杂的文本到SQL任务分解为较小的子任务，并且这种分解如何显著提高大型语言模型在推理过程中的表现。我们展示了尽管SQL查询具有声明式结构，但可以将其分解为子问题，并将这些子问题的解决方案馈入到大型语言模型中，从而显著提高它们的表现。我们的实验表明，这种方法能够稳定提高三种大型语言模型的表现，大约提高了10％，将大型语言模型的准确性推向最新水平，并在Holdout Spider数据集上甚至超过了经过精调的大型模型。

    We study the problem of decomposing a complex text-to-sql task into smaller sub-tasks and how such a decomposition can significantly improve the performance of Large Language Models (LLMs) in the reasoning process. There is currently a significant gap between the performance of fine-tuned models and prompting approaches using LLMs on challenging text-to-sql datasets such as Spider. We show that SQL queries, despite their declarative structure, can be broken down into sub-problems and the solutions of those sub-problems can be fed into LLMs to significantly improve their performance. Our experiments with three LLMs show that this approach consistently improves their performance by roughly 10%, pushing the accuracy of LLMs towards state-of-the-art, and even beating large fine-tuned models on the holdout Spider dataset.
    
[^32]: 基于BERT的临床知识提取用于生物医学知识图谱构建和分析

    BERT Based Clinical Knowledge Extraction for Biomedical Knowledge Graph Construction and Analysis. (arXiv:2304.10996v1 [cs.CL])

    [http://arxiv.org/abs/2304.10996](http://arxiv.org/abs/2304.10996)

    本文提出了一种基于BERT和CRF技术的生物医学临床笔记知识提取和分析的端到端方法，用于构建和分析生物医学知识图谱。

    

    背景：知识随时间而演变，往往是由于新的发现或推理方法的变化导致。此外，可能会有新的事实或证据出现，导致对复杂现象的新理解。这在生物医学领域尤为真实，科学家和医生不断努力寻找新的诊断、治疗方法和最终的治愈。知识图谱（KG）提供了一种真实的方法来组织和检索大量增长的生物医学知识。

    Background : Knowledge is evolving over time, often as a result of new discoveries or changes in the adopted methods of reasoning. Also, new facts or evidence may become available, leading to new understandings of complex phenomena. This is particularly true in the biomedical field, where scientists and physicians are constantly striving to find new methods of diagnosis, treatment and eventually cure. Knowledge Graphs (KGs) offer a real way of organizing and retrieving the massive and growing amount of biomedical knowledge.  Objective : We propose an end-to-end approach for knowledge extraction and analysis from biomedical clinical notes using the Bidirectional Encoder Representations from Transformers (BERT) model and Conditional Random Field (CRF) layer.  Methods : The approach is based on knowledge graphs, which can effectively process abstract biomedical concepts such as relationships and interactions between medical entities. Besides offering an intuitive way to visualize these co
    
[^33]: 在能力受限场景下启动强韧后门攻击

    Launching a Robust Backdoor Attack under Capability Constrained Scenarios. (arXiv:2304.10985v1 [cs.CR])

    [http://arxiv.org/abs/2304.10985](http://arxiv.org/abs/2304.10985)

    深度神经网络的后门攻击一直是一个安全性问题，现有的改进方法需要强大的攻击者能力，在能力受限场景下还没有找到令人满意的解决办法，此外，模型鲁棒性仍然值得关注。

    

    随着深度神经网络在关键领域的应用不断增加，人们开始担心它们的安全性。由于缺乏透明度，深度学习模型容易受到后门攻击的威胁。污染的后门模型在普通环境下可能表现正常，但当输入包含触发器时，会显示出恶意行为。目前对后门攻击的研究集中于改善触发器的秘密性，大多数方法需要强大的攻击者能力，例如对模型结构的了解或对训练过程的控制。由于在大多数情况下攻击者的能力受到限制，这些攻击是不切实际的。此外，模型鲁棒性的问题还未得到充分关注。例如，模型蒸馏常用于简化模型大小，但随着参数数量指数级增长，以前的许多后门攻击在模型蒸馏后均失败;图像增强操作可以破坏触发器，从而使后门攻击失效。

    As deep neural networks continue to be used in critical domains, concerns over their security have emerged. Deep learning models are vulnerable to backdoor attacks due to the lack of transparency. A poisoned backdoor model may perform normally in routine environments, but exhibit malicious behavior when the input contains a trigger. Current research on backdoor attacks focuses on improving the stealthiness of triggers, and most approaches require strong attacker capabilities, such as knowledge of the model structure or control over the training process. These attacks are impractical since in most cases the attacker's capabilities are limited. Additionally, the issue of model robustness has not received adequate attention. For instance, model distillation is commonly used to streamline model size as the number of parameters grows exponentially, and most of previous backdoor attacks failed after model distillation; the image augmentation operations can destroy the trigger and thus disabl
    
[^34]: IBBT: 信息饱和批次置信树用于不确定情况下的运动规划

    IBBT: Informed Batch Belief Trees for Motion Planning Under Uncertainty. (arXiv:2304.10984v1 [cs.RO])

    [http://arxiv.org/abs/2304.10984](http://arxiv.org/abs/2304.10984)

    本文提出使用信息饱和批次置信树算法解决了运动和传感器不确定性下的运动规划，先构建标准轨迹的图，再利用所提出的启发式代价计算解决原问题，最后通过搜索标准轨迹的树来生成置信度树。

    

    本论文提出了信息饱和批次置信树（IBBT）算法，用于解决运动和传感器不确定性下的运动规划问题。该算法将随机运动规划问题分为确定性运动规划问题和图搜问题两部分，使用基于采样的方法构建一个标准轨迹的图，并计算出原问题的信息启发式代价。最后，通过使用所提出的启发式策略，搜索标准轨迹的图来生成置信度树。IBBT采用所提出的策略，交替进行状态采样，标准轨迹图构建，启发式计算和图搜以找到置信度空间的运动规划。IBBT是一种任何时候的增量算法，随着批次样本数量的不断增加，算法找到的运动规划会逐渐趋向于最优结果，因此效率很高，且可以在不同样本集之间重复利用结果。

    In this work, we propose the Informed Batch Belief Trees (IBBT) algorithm for motion planning under motion and sensing uncertainties. The original stochastic motion planning problem is divided into a deterministic motion planning problem and a graph search problem. We solve the deterministic planning problem using sampling-based methods such as PRM or RRG to construct a graph of nominal trajectories. Then, an informed cost-to-go heuristic for the original problem is computed based on the nominal trajectory graph. Finally, we grow a belief tree by searching over the graph using the proposed heuristic. IBBT interleaves between batch state sampling, nominal trajectory graph construction, heuristic computing, and search over the graph to find belief space motion plans. IBBT is an anytime, incremental algorithm. With an increasing number of batches of samples added to the graph, the algorithm finds motion plans that converge to the optimal one. IBBT is efficient by reusing results between s
    
[^35]: LEIA：语言嵌入用于情感识别

    LEIA: Linguistic Embeddings for the Identification of Affect. (arXiv:2304.10973v1 [cs.CL])

    [http://arxiv.org/abs/2304.10973](http://arxiv.org/abs/2304.10973)

    该论文提出了一种名为LEIA的情感识别模型，使用了由超过6百万个自注释文本帖子组成的数据集进行训练，利用掩蔽单词的方法增强模型预训练过程中对情感单词的学习，并在三个测试数据集上实现了约73的宏F1值，优于其他方法。

    

    社交媒体产生了大量文本数据，使得使用语言模型分析情感变得更加容易。这些模型通常在由读者生成的小型而昂贵的文本注释数据集上进行训练，这些读者猜测社交媒体帖子中表达的情感。这影响了情感识别方法的质量，因为存在训练数据大小限制和用于模型开发的标签生产中的噪声。我们提出了LEIA，这是一种文本情感识别模型，它基于由超过6百万个帖子组成的数据集进行训练，其中这些帖子具有自注释的情感标签，包括快乐、亲情、悲伤、愤怒和恐惧。LEIA基于一种掩蔽单词的方法，增强了模型预训练过程中对情感单词的学习。LEIA在三个测试数据集上实现了约73的宏F1值，优于其他监督和无监督方法，并在强基准测试中表现出LEIA可以概括不同的帖子、用户和时间段。

    The wealth of text data generated by social media has enabled new kinds of analysis of emotions with language models. These models are often trained on small and costly datasets of text annotations produced by readers who guess the emotions expressed by others in social media posts. This affects the quality of emotion identification methods due to training data size limitations and noise in the production of labels used in model development. We present LEIA, a model for emotion identification in text that has been trained on a dataset of more than 6 million posts with self-annotated emotion labels for happiness, affection, sadness, anger, and fear. LEIA is based on a word masking method that enhances the learning of emotion words during model pre-training. LEIA achieves macro-F1 values of approximately 73 on three in-domain test datasets, outperforming other supervised and unsupervised methods in a strong benchmark that shows that LEIA generalizes across posts, users, and time periods.
    
[^36]: 图注意力网络中可学习参数的梯度推导

    Gradient Derivation for Learnable Parameters in Graph Attention Networks. (arXiv:2304.10939v1 [cs.LG])

    [http://arxiv.org/abs/2304.10939](http://arxiv.org/abs/2304.10939)

    本文对GATv2的可训练模型参数的梯度进行了全面推导，在不同的数据集上实现的性能表现不一致的原因仍然是一个开放的研究问题。

    

    本文对图注意力网络（GAT）的广泛实现之一——GATv2的可训练模型参数的梯度进行了全面的推导。虽然GAT已被证明是处理图结构数据的强大框架，但是在不同数据集上实现的性能表现不一致，其原因仍然是一个开放的研究问题。由于梯度流为统计学习模型的训练动态提供了有价值的洞见，因此本文推导了GATv2的可训练模型参数的梯度。这些梯度推导补充了[2]的工作，后者调查了GATv2的潜在陷阱。

    This work provides a comprehensive derivation of the parameter gradients for GATv2 [4], a widely used implementation of Graph Attention Networks (GATs). GATs have proven to be powerful frameworks for processing graph-structured data and, hence, have been used in a range of applications. However, the achieved performance by these attempts has been found to be inconsistent across different datasets and the reasons for this remains an open research question. As the gradient flow provides valuable insights into the training dynamics of statistically learning models, this work obtains the gradients for the trainable model parameters of GATv2. The gradient derivations supplement the efforts of [2], where potential pitfalls of GATv2 are investigated.
    
[^37]: 自监督对抗仿真学习

    Self-Supervised Adversarial Imitation Learning. (arXiv:2304.10914v1 [cs.LG])

    [http://arxiv.org/abs/2304.10914](http://arxiv.org/abs/2304.10914)

    本文介绍了一种解决自我监督模型陷入坏局部最小值的方法，即通过将鉴别器纳入模型，不需要人工干预，帮助学习，并解决了常见的学习问题。

    

    行为克隆是一种通过专家演示来教授智能体如何行为的仿真学习技术。最近的方法使用自我监督的完全可观察未标记状态的快照来将状态对解码为动作。然而，这些技术采用的迭代学习方案容易陷入坏的局部最小值。先前的工作使用目标感知策略来解决这个问题。然而，这需要人工介入来验证智能体是否达到了目标。我们通过将鉴别器纳入原始框架来解决这个限制，提供了两个关键优势，并直接解决了以前的一个学习问题。首先，它不需要人工干预。其次，它通过指导基于专家轨迹的状态转换的函数逼近来帮助学习。第三，鉴别器解决了策略模型常见的学习问题，即有时会执行“无动作”。

    Behavioural cloning is an imitation learning technique that teaches an agent how to behave via expert demonstrations. Recent approaches use self-supervision of fully-observable unlabelled snapshots of the states to decode state pairs into actions. However, the iterative learning scheme employed by these techniques is prone to get trapped into bad local minima. Previous work uses goal-aware strategies to solve this issue. However, this requires manual intervention to verify whether an agent has reached its goal. We address this limitation by incorporating a discriminator into the original framework, offering two key advantages and directly solving a learning problem previous work had. First, it disposes of the manual intervention requirement. Second, it helps in learning by guiding function approximation based on the state transition of the expert's trajectories. Third, the discriminator solves a learning issue commonly present in the policy model, which is to sometimes perform a `no ac
    
[^38]: 自动驾驶中基于Transformer的模型及其硬件加速分析：综述 (arXiv:2304.10891v1 [cs.LG])

    Transformer-based models and hardware acceleration analysis in autonomous driving: A survey. (arXiv:2304.10891v1 [cs.LG])

    [http://arxiv.org/abs/2304.10891](http://arxiv.org/abs/2304.10891)

    本文综述了基于Transformer的模型在自动驾驶中的应用，探讨了不同体系结构和运算符的优缺点，重点讨论了针对便携计算平台的硬件加速方案，并对卷积神经网络和Transformer的层进行了对比。

    

    近年来，Transformer架构在各种自动驾驶应用中表现出了很好的性能。另一方面，将其专门用于便携式计算平台的硬件加速已成为实际部署在真实自动汽车中的下一步关键步骤。本综述论文提供了针对自动驾驶任务的基于Transformer的模型的全面概述、基准和分析，例如车道检测、分割、跟踪、规划和决策制定。我们审查了不同的体系结构，用于组织Transformer的输入和输出，例如编码器-解码器和仅编码器结构，并探讨了它们各自的优缺点。此外，我们深入讨论了Transformer相关的运算符及其硬件加速方案，考虑到关键因素，如量化和运行时。我们特别在移动和桌面平台上对卷积神经网络的层与基于Transformer的模型的运算符进行了对比。总的来说，本综述论文为研究人员和从业者提供了系统的指南，以了解基于Transformer的模型及其在自动驾驶中的硬件加速的当前进展和挑战。

    Transformer architectures have exhibited promising performance in various autonomous driving applications in recent years. On the other hand, its dedicated hardware acceleration on portable computational platforms has become the next critical step for practical deployment in real autonomous vehicles. This survey paper provides a comprehensive overview, benchmark, and analysis of Transformer-based models specifically tailored for autonomous driving tasks such as lane detection, segmentation, tracking, planning, and decision-making. We review different architectures for organizing Transformer inputs and outputs, such as encoder-decoder and encoder-only structures, and explore their respective advantages and disadvantages. Furthermore, we discuss Transformer-related operators and their hardware acceleration schemes in depth, taking into account key factors such as quantization and runtime. We specifically illustrate the operator level comparison between layers from convolutional neural ne
    
[^39]: 野外环境下的AMP：学习健壮、灵活、自然的有腿移动技能

    AMP in the wild: Learning robust, agile, natural legged locomotion skills. (arXiv:2304.10888v1 [cs.RO])

    [http://arxiv.org/abs/2304.10888](http://arxiv.org/abs/2304.10888)

    本文提出了一种新算法，可推断动态系统参数信息并从之前的观察数据中估计机器人状态的重要信息。将该算法与Adversarial Motion Priors相结合，实现了在仿真和真实世界中健壮、灵活、自然的步态，可用于穿越具有挑战性的地形。

    

    将一个学习控制器从仿真环境转移到真实世界中的四足机器人需要不仅能够识别系统，而且还需要准确地估计机器人的状态。本文提出了一种新算法，不仅可以推断动态系统参数信息，还可以从之前的观察数据中估计机器人状态的重要信息。我们将该算法与Adversarial Motion Priors相结合，在仿真和在Unitree A1四足机器人真实世界中实现了健壮、灵活、自然的步态。实证结果表明，与基准方法相比，我们提出的算法能够以更低的功耗穿越具有挑战性的地形。本文提供了定性和定量的结果。

    The successful transfer of a learned controller from simulation to the real world for a legged robot requires not only the ability to identify the system, but also accurate estimation of the robot's state. In this paper, we propose a novel algorithm that can infer not only information about the parameters of the dynamic system, but also estimate important information about the robot's state from previous observations. We integrate our algorithm with Adversarial Motion Priors and achieve a robust, agile, and natural gait in both simulation and on a Unitree A1 quadruped robot in the real world. Empirical results demonstrate that our proposed algorithm enables traversing challenging terrains with lower power consumption compared to the baselines. Both qualitative and quantitative results are presented in this paper.
    
[^40]: Metropolis算法在处理局部最优时的效果如何？

    How Well Does the Metropolis Algorithm Cope With Local Optima?. (arXiv:2304.10848v1 [cs.NE])

    [http://arxiv.org/abs/2304.10848](http://arxiv.org/abs/2304.10848)

    Metropolis算法的局部搜索策略并不总是优于进化算法，还需要进一步改进和完善。

    

    Metropolis算法（MA）是一种经典的随机局部搜索启发式算法。它通过偶尔接受次优解避免陷入局部最优。为了更好地并以严格的方式理解这种能力，我们对CLIFF基准测试中的MA进行了数学运行时间分析。除了一个局部最优解外，cliff函数向全局最优解单调递增。因此，为了优化cliff函数，MA只需要一次接受一个劣质解。尽管看起来这是MA从其主要工作原理中获利的理想基准测试，但我们的数学运行时间分析表明这一希望并没有实现。即使在最优温度下（MA的唯一参数），MA优化大多数cliff函数的效率也不如简单的精英进化算法（EAs），后者只能通过生成可能相距很远的优秀解来离开局部最优解。这个结果表明，我们对MA为什么有效的理解需要进一步完善。

    The Metropolis algorithm (MA) is a classic stochastic local search heuristic. It avoids getting stuck in local optima by occasionally accepting inferior solutions. To better and in a rigorous manner understand this ability, we conduct a mathematical runtime analysis of the MA on the CLIFF benchmark. Apart from one local optimum, cliff functions are monotonically increasing towards the global optimum. Consequently, to optimize a cliff function, the MA only once needs to accept an inferior solution. Despite seemingly being an ideal benchmark for the MA to profit from its main working principle, our mathematical runtime analysis shows that this hope does not come true. Even with the optimal temperature (the only parameter of the MA), the MA optimizes most cliff functions less efficiently than simple elitist evolutionary algorithms (EAs), which can only leave the local optimum by generating a superior solution possibly far away. This result suggests that our understanding of why the MA is 
    
[^41]: 学习如何使用更好的子图进行人脸聚类

    Learn to Cluster Faces with Better Subgraphs. (arXiv:2304.10831v1 [cs.CV])

    [http://arxiv.org/abs/2304.10831](http://arxiv.org/abs/2304.10831)

    本文提出了一种有效的邻域感知子图调整方法，可以显著减少噪声，提高子图的召回率，从而可以推动远距离的节点向相同的中心收敛。

    

    人脸聚类可以为海量无标签人脸数据提供伪标签，并提高不同人脸识别模型的性能。现有的聚类方法通常是在子图内聚合特征，这些子图通常基于统一的阈值或学习得到的截止位置实现。这可能会降低子图的召回率，从而降低聚类性能。本文提出了一种有效的邻域感知子图调整方法，可以显著减少噪声，提高子图的召回率，从而可以推动远距离的节点向相同的中心收敛。具体来说，所提出的方法包括两个组件，即使用邻居的嵌入来增强人脸嵌入，并对节点对进行封闭子图构建以提取结构信息。将嵌入组合起来，预测所有节点对的链接概率以替换余弦相似度来生成新的子图。

    Face clustering can provide pseudo-labels to the massive unlabeled face data and improve the performance of different face recognition models. The existing clustering methods generally aggregate the features within subgraphs that are often implemented based on a uniform threshold or a learned cutoff position. This may reduce the recall of subgraphs and hence degrade the clustering performance. This work proposed an efficient neighborhood-aware subgraph adjustment method that can significantly reduce the noise and improve the recall of the subgraphs, and hence can drive the distant nodes to converge towards the same centers. More specifically, the proposed method consists of two components, i.e. face embeddings enhancement using the embeddings from neighbors, and enclosed subgraph construction of node pairs for structural information extraction. The embeddings are combined to predict the linkage probabilities for all node pairs to replace the cosine similarities to produce new subgraphs
    
[^42]: 可控的信任权衡下的合成数据审计与生成

    Auditing and Generating Synthetic Data with Controllable Trust Trade-offs. (arXiv:2304.10819v1 [cs.LG])

    [http://arxiv.org/abs/2304.10819](http://arxiv.org/abs/2304.10819)

    本论文提出了一个审计框架，能够以全面的方式评估合成数据和AI模型的具体效果，包括偏见和歧视预防、对真实数据的忠实程度、效用、鲁棒性和隐私保护。在多个用例中，审计框架平衡了信任和效用之间的权衡。

    

    现实中收集的数据往往存在偏差、不平衡，并且有泄露敏感和隐私信息的风险。这一事实引发了创建合成数据集的想法，以减轻真实数据中固有的风险、偏见、伤害和隐私问题。这个概念依赖于生成AI模型，以产生不偏执、保护隐私的合成数据，同时忠实于真实数据。在这种新范式中，我们如何知道这种方法是否兑现了其承诺？我们提出了一个审计框架，提供了对合成数据集和基于它们训练的AI模型的全面评估，围绕偏见和歧视的预防、对真实数据的忠实程度、效用、鲁棒性和隐私保护。我们通过审计多个生成模型在不同用例中展示了我们的框架，包括教育、医疗保健、银行、人力资源，以及从表格，时间序列到自然语言的不同模态。我们的用例展示了在合成数据生成中平衡信任和效用的权衡的重要性。

    Data collected from the real world tends to be biased, unbalanced, and at risk of exposing sensitive and private information. This reality has given rise to the idea of creating synthetic datasets to alleviate risk, bias, harm, and privacy concerns inherent in the real data. This concept relies on Generative AI models to produce unbiased, privacy-preserving synthetic data while being true to the real data. In this new paradigm, how can we tell if this approach delivers on its promises? We present an auditing framework that offers a holistic assessment of synthetic datasets and AI models trained on them, centered around bias and discrimination prevention, fidelity to the real data, utility, robustness, and privacy preservation. We showcase our framework by auditing multiple generative models on diverse use cases, including education, healthcare, banking, human resources, and across different modalities, from tabular, to time-series, to natural language. Our use cases demonstrate the imp
    
[^43]: SAM能够计数所有物体吗？对SAM计数的实证研究

    Can SAM Count Anything? An Empirical Study on SAM Counting. (arXiv:2304.10817v1 [cs.CV])

    [http://arxiv.org/abs/2304.10817](http://arxiv.org/abs/2304.10817)

    本文探讨了将Segment Anything模型用于少样本物体计数的挑战性任务，并与其他计数方法进行了比较。我们发现SAM的表现仍需进一步微调，特别是对于小型和拥挤的物体。

    

    Meta AI最近发布了Segment Anything模型(SAM)，由于在类无关分割中表现出色，该模型引起了人们的关注。本研究探讨了将SAM用于少样本物体计数的挑战性任务，该任务涉及通过提供几个示例的边界框来计数未见过类别的物体。我们将SAM的性能与其他少样本计数方法进行比较，并发现在没有进一步微调的情况下，它的表现仍然不令人满意，特别是对于小型和拥挤的物体。代码可在\url{https://github.com/Vision-Intelligence-and-Robots-Group/count-anything}上找到。

    Meta AI recently released the Segment Anything model (SAM), which has garnered attention due to its impressive performance in class-agnostic segmenting. In this study, we explore the use of SAM for the challenging task of few-shot object counting, which involves counting objects of an unseen category by providing a few bounding boxes of examples. We compare SAM's performance with other few-shot counting methods and find that it is currently unsatisfactory without further fine-tuning, particularly for small and crowded objects. Code can be found at \url{https://github.com/Vision-Intelligence-and-Robots-Group/count-anything}.
    
[^44]: RPLKG: 基于知识图谱的鲁棒提示学习

    RPLKG: Robust Prompt Learning with Knowledge Graph. (arXiv:2304.10805v1 [cs.AI])

    [http://arxiv.org/abs/2304.10805](http://arxiv.org/abs/2304.10805)

    本研究提出了一种基于知识图谱的鲁棒提示学习方法，通过自动设计有意义和可解释的提示集，提高小样本学习的泛化性能。

    

    大规模预训练模型已经被证明是可迁移的，并且对未知数据集具有很好的泛化性能。最近，诸如CLIP之类的多模态预训练模型在各种实验中表现出显着的性能提升。然而，当标记数据集有限时，新数据集或领域的泛化仍然具有挑战性。为了提高小样本学习的泛化性能，已经进行了各种努力，如提示学习和适配器。然而，当前的少样本自适应方法不具备可解释性，并且需要高计算成本来进行自适应。在本研究中，我们提出了一种新的方法，即基于知识图谱的鲁棒提示学习（RPLKG）。基于知识图谱，我们自动设计出各种可解释和有意义的提示集。我们的模型在大型预训练模型的一次正向传递后获得提示集的缓存嵌入。之后，模型使用GumbelSoftmax优化提示选择过程。

    Large-scale pre-trained models have been known that they are transferable, and they generalize well on the unseen dataset. Recently, multimodal pre-trained models such as CLIP show significant performance improvement in diverse experiments. However, when the labeled dataset is limited, the generalization of a new dataset or domain is still challenging. To improve the generalization performance on few-shot learning, there have been diverse efforts, such as prompt learning and adapter. However, the current few-shot adaptation methods are not interpretable, and they require a high computation cost for adaptation. In this study, we propose a new method, robust prompt learning with knowledge graph (RPLKG). Based on the knowledge graph, we automatically design diverse interpretable and meaningful prompt sets. Our model obtains cached embeddings of prompt sets after one forwarding from a large pre-trained model. After that, model optimizes the prompt selection processes with GumbelSoftmax. In
    
[^45]: 机器人学习中的对比语言、动作和状态预训练

    Contrastive Language, Action, and State Pre-training for Robot Learning. (arXiv:2304.10782v1 [cs.RO])

    [http://arxiv.org/abs/2304.10782](http://arxiv.org/abs/2304.10782)

    本文介绍了一种名为CLASP的方法，将语言、动作和状态信息统一到共享的嵌入空间中，用于机器人学习中的一系列下游任务。通过分布式编码器实现了不同的文本命令与单个行为相关联，并反之亦然。模型在零样本文本行为检索、为未见机器人行为加标题以及学习一个行为先验知识以进行语言依存的强化学习方面表现出卓越的性能。

    

    本文介绍了一种方法，将语言、动作和状态信息统一到共享的嵌入空间中，以促进机器人学习中的一系列下游任务。我们的方法名为对比语言、动作和状态预训练（CLASP），扩展了CLIP公式，结合分布式学习，捕捉行为文本对齐中的固有复杂性和一对多关系。通过为文本和行为编码器提供分布输出，我们的模型有效地将不同的文本命令与单个行为相关联，并反之亦然。我们展示了我们的方法在以下下游任务中的实用性：零样本文本行为检索、为未见机器人行为加标题以及学习一个行为先验知识以进行语言依存的强化学习。我们的分布式编码器在未见数据集上表现出卓越的检索和标题性能，以及从文本命令生成有意义的探索性行为的能力。

    In this paper, we introduce a method for unifying language, action, and state information in a shared embedding space to facilitate a range of downstream tasks in robot learning. Our method, Contrastive Language, Action, and State Pre-training (CLASP), extends the CLIP formulation by incorporating distributional learning, capturing the inherent complexities and one-to-many relationships in behaviour-text alignment. By employing distributional outputs for both text and behaviour encoders, our model effectively associates diverse textual commands with a single behaviour and vice-versa. We demonstrate the utility of our method for the following downstream tasks: zero-shot text-behaviour retrieval, captioning unseen robot behaviours, and learning a behaviour prior for language-conditioned reinforcement learning. Our distributional encoders exhibit superior retrieval and captioning performance on unseen datasets, and the ability to generate meaningful exploratory behaviours from textual com
    
[^46]: DEIR: 基于区分性模型的情节内在奖励，高效且鲁棒的探索方法

    DEIR: Efficient and Robust Exploration through Discriminative-Model-Based Episodic Intrinsic Rewards. (arXiv:2304.10770v1 [cs.LG])

    [http://arxiv.org/abs/2304.10770](http://arxiv.org/abs/2304.10770)

    提出了一种探索强化学习算法DEIR，借助区分性模型实现理论上导出的内在奖励，能够高效且鲁棒地进行探索，适用于面对外部奖励稀疏的情况。

    

    探索是强化学习中的一个基本方面，其有效性关键地影响着强化学习算法的性能，尤其是面对稀疏的外部奖励时更为重要。最近的研究表明，从观测中估计新颖性的内在奖励可以有效鼓励探索。然而，由于环境的随机性以及代理的行为可能会影响观察结果，因此一个观测的新颖性与探索之间存在差距。为了准确估计探索行为，我们提出了DEIR，一种新颖的方法，其中我们从条件互信息项中理论上导出内在奖励，该奖励主要与代理的探索行为所贡献的新颖性成比例，并借助区分性的前向模型实现奖励。我们在MiniGrid中进行了广泛的实验，包括标准和硬核探索游戏，在结果上DEIR比基线学习更快并且具有更高的成功率和鲁棒性，适应环境动态变化。

    Exploration is a fundamental aspect of reinforcement learning (RL), and its effectiveness crucially decides the performance of RL algorithms, especially when facing sparse extrinsic rewards. Recent studies showed the effectiveness of encouraging exploration with intrinsic rewards estimated from novelty in observations. However, there is a gap between the novelty of an observation and an exploration in general, because the stochasticity in the environment as well as the behavior of an agent may affect the observation. To estimate exploratory behaviors accurately, we propose DEIR, a novel method where we theoretically derive an intrinsic reward from a conditional mutual information term that principally scales with the novelty contributed by agent explorations, and materialize the reward with a discriminative forward model. We conduct extensive experiments in both standard and hardened exploration games in MiniGrid to show that DEIR quickly learns a better policy than baselines. Our eval
    
[^47]: 半监督领域自适应的双阶段方法：实现标记目标样本价值的方法

    Towards Realizing the Value of Labeled Target Samples: a Two-Stage Approach for Semi-Supervised Domain Adaptation. (arXiv:2304.10762v1 [cs.CV])

    [http://arxiv.org/abs/2304.10762](http://arxiv.org/abs/2304.10762)

    该论文提出了一种基于双阶段方法的半监督领域自适应方法，成功利用了少量有限的标记目标样本，相对于其他方法取得了更好的性能表现。

    

    半监督领域自适应（SSDA）是一个新兴的研究主题，它是从广泛研究的无监督领域适应（UDA）扩展而来，通过进一步标记一些目标样本来训练模型，即使用标记的源样本、未标记的目标样本以及少量标记的目标样本进行训练。与UDA相比，SSDA的关键在于如何最有效地利用一些有限的标记目标样本。现有的SSDA方法将少数宝贵的标记目标样本简单合并到大量的标记源样本中或进一步对齐它们，这会削弱标记目标样本的价值，因此仍然会得到有偏差的模型。为了解决这个问题，本文提出了将SSDA分解为UDA问题和半监督学习问题的方法，我们首先使用标记源和未标记目标样本学习UDA模型，然后再使用标记和未标记目标样本以半监督的方式调整所学的UDA模型。通过利用标记源样本，我们在几个基准数据集上实现了最先进的半监督领域自适应性能。

    Semi-Supervised Domain Adaptation (SSDA) is a recently emerging research topic that extends from the widely-investigated Unsupervised Domain Adaptation (UDA) by further having a few target samples labeled, i.e., the model is trained with labeled source samples, unlabeled target samples as well as a few labeled target samples. Compared with UDA, the key to SSDA lies how to most effectively utilize the few labeled target samples. Existing SSDA approaches simply merge the few precious labeled target samples into vast labeled source samples or further align them, which dilutes the value of labeled target samples and thus still obtains a biased model. To remedy this, in this paper, we propose to decouple SSDA as an UDA problem and a semi-supervised learning problem where we first learn an UDA model using labeled source and unlabeled target samples and then adapt the learned UDA model in a semi-supervised way using labeled and unlabeled target samples. By utilizing the labeled source samples
    
[^48]: 可解释和鲁棒的脑电图AI系统综述

    Interpretable and Robust AI in EEG Systems: A Survey. (arXiv:2304.10755v1 [eess.SP])

    [http://arxiv.org/abs/2304.10755](http://arxiv.org/abs/2304.10755)

    这篇论文综述了近年来脑电图系统中可解释和鲁棒的AI技术的发展。其中，作者提出了解释性分类法，详细介绍了鲁棒AI的方法，包括对抗攻击和防御、迁移学习和不确定性建模，并讨论了未来的研究方向和挑战。

    

    在人工智能时代，人工智能（AI）和脑电图（EEG）的密切耦合极大地推动了人机交互（HCI）技术的发展。相较于传统的EEG系统，基于AI的EEG系统的可解释性和鲁棒性变得尤为关键。可解释性能够阐释AI模型的内部工作机制，因此可以获得用户的信任。鲁棒性则反映了AI对抗攻击和扰动的可靠性，这对于敏感和脆弱的EEG信号来说是至关重要的。因此，EEG系统中AI的可解释性和鲁棒性受到越来越多的关注，并且最近的研究取得了巨大进展。然而，关于这一领域的最新进展仍然没有综述。本文首先提出了一种解释性分类法，通过特征化模型、数据和输出解释性，总结了脑电图系统中解释性和鲁棒的AI技术，并详细介绍了鲁棒AI的方法，包括对抗攻击和防御、迁移学习和不确定性建模。最后，我们讨论了这一领域未来的方向和面临的挑战。

    The close coupling of artificial intelligence (AI) and electroencephalography (EEG) has substantially advanced human-computer interaction (HCI) technologies in the AI era. Different from traditional EEG systems, the interpretability and robustness of AI-based EEG systems are becoming particularly crucial. The interpretability clarifies the inner working mechanisms of AI models and thus can gain the trust of users. The robustness reflects the AI's reliability against attacks and perturbations, which is essential for sensitive and fragile EEG signals. Thus the interpretability and robustness of AI in EEG systems have attracted increasing attention, and their research has achieved great progress recently. However, there is still no survey covering recent advances in this field. In this paper, we present the first comprehensive survey and summarize the interpretable and robust AI techniques for EEG systems. Specifically, we first propose a taxonomy of interpretability by characterizing it 
    
[^49]: 预测遍历性：使用算法信息论进行预测建模

    Forecast Ergodicity: Prediction Modeling Using Algorithmic Information Theory. (arXiv:2304.10752v1 [cs.IT])

    [http://arxiv.org/abs/2304.10752](http://arxiv.org/abs/2304.10752)

    本论文讨论了预测遍历性（forecast ergodicity）的概念，即从过去数据中预测未来事件的能力的度量。文章使用算法复杂性模拟这个能力的限制。

    

    计算机智能的能力受到过去数据预测未来的潜力的限制。深度学习工具用于发现可用数据中的结构，以便预测未来。但这些结构必须首先存在于可用数据中，并且在未来也必须适用。预测遍历性是从过去数据中预测未来事件的能力的度量。我们通过可用数据的算法复杂性来模拟这个限制。

    The capabilities of machine intelligence are bounded by the potential of data from the past to forecast the future. Deep learning tools are used to find structures in the available data to make predictions about the future. Such structures have to be present in the available data in the first place and they have to be applicable in the future. Forecast ergodicity is a measure of the ability to forecast future events from data in the past. We model this bound by the algorithmic complexity of the available data.
    
[^50]: 通过互动反馈与代理交互来提高协作环境下基于实地理解（Grounded Language Understanding）的能力

    Improving Grounded Language Understanding in a Collaborative Environment by Interacting with Agents Through Help Feedback. (arXiv:2304.10750v1 [cs.CL])

    [http://arxiv.org/abs/2304.10750](http://arxiv.org/abs/2304.10750)

    研究通过互动反馈与代理交互来提高协作环境下基于实地理解的能力。

    

    许多自然语言处理任务通常被视为单步问题。在这些任务中，代理接收一个指令，执行它，然后根据最终结果进行评估。然而，人类语言本质上是交互式的，我们主张人工智能与人类的协作也应是交互式的，人类监督人工智能代理的工作，并提供代理可以理解和利用的反馈信息。在这项工作中，我们探讨了通过Help Feedback实现这一目标的方向。

    Many approaches to Natural Language Processing (NLP) tasks often treat them as single-step problems, where an agent receives an instruction, executes it, and is evaluated based on the final outcome. However, human language is inherently interactive, as evidenced by the back-and-forth nature of human conversations. In light of this, we posit that human-AI collaboration should also be interactive, with humans monitoring the work of AI agents and providing feedback that the agent can understand and utilize. Further, the AI agent should be able to detect when it needs additional information and proactively ask for help. Enabling this scenario would lead to more natural, efficient, and engaging human-AI collaborations.  In this work, we explore these directions using the challenging task defined by the IGLU competition, an interactive grounded language understanding task in a MineCraft-like world. We explore multiple types of help players can give to the AI to guide it and analyze the impac
    
[^51]: 多尺度进化神经架构搜索用于深度脉冲神经网络

    Multi-scale Evolutionary Neural Architecture Search for Deep Spiking Neural Networks. (arXiv:2304.10749v1 [cs.NE])

    [http://arxiv.org/abs/2304.10749](http://arxiv.org/abs/2304.10749)

    本文提出了一种新方法--多尺度进化神经架构搜索，用于自动设计脉冲神经网络，同时考虑微观、中观和宏观尺度的脑拓扑结构。MSE-NAS可以帮助SNN实现多电路模式的自组织集成，并通过全局性的跨模式连接来优化网络性能。

    

    脉冲神经网络（SNN）不仅因其离散信号处理的能源效率卓越，而且因其天然适合于集成多尺度生物可塑性而受到广泛关注。然而，大多数SNN直接采用成熟的DNN结构，很少自动设计神经架构搜索（NAS）用于SNN。人类大脑神经模式的拓扑结构，模块化的区域结构和全局性的跨脑区连接是自然进化的产物，可以作为设计基于脑的SNN架构的完美参考。本文提出了一种多尺度进化神经架构搜索（MSE-NAS），同时考虑微观、中观和宏观尺度的脑拓扑作为进化搜索空间。 MSE-NAS通过基于大脑启发的间接方式，进化单个神经元操作，多个电路模式的自组织集成以及跨模式的全局连通性。

    Spiking Neural Networks (SNNs) have received considerable attention not only for their superiority in energy efficient with discrete signal processing, but also for their natural suitability to integrate multi-scale biological plasticity. However, most SNNs directly adopt the structure of the well-established DNN, rarely automatically design Neural Architecture Search (NAS) for SNNs. The neural motifs topology, modular regional structure and global cross-brain region connection of the human brain are the product of natural evolution and can serve as a perfect reference for designing brain-inspired SNN architecture. In this paper, we propose a Multi-Scale Evolutionary Neural Architecture Search (MSE-NAS) for SNN, simultaneously considering micro-, meso- and macro-scale brain topologies as the evolutionary search space. MSE-NAS evolves individual neuron operation, self-organized integration of multiple circuit motifs, and global connectivity across motifs through a brain-inspired indirec
    
[^52]: 基于间接通信的联邦学习中的客户端分配和无人机路径规划

    Joint Client Assignment and UAV Route Planning for Indirect-Communication Federated Learning. (arXiv:2304.10744v1 [cs.DC])

    [http://arxiv.org/abs/2304.10744](http://arxiv.org/abs/2304.10744)

    提出了一种新的FedEx框架，利用无人机等移动传输器建立间接通信通道，在解决客户端和服务器之间无法直接通信的问题时，本文提出了一种联合客户端分配和无人机路径规划的方法，最小化整体训练时间和通信成本。

    

    联邦学习是一种机器学习方法，可以创建用于强大应用程序的共享模型，同时允许数据保留在设备上，提供了改进的数据隐私性、安全性和降低的延迟等优点。然而，在某些系统中，客户端和服务器之间的直接通信可能不可能，例如没有适当通信基础设施的远程地区。为了解决这一问题，提出了一种新的框架 FedEx（通过模型传递实现联邦学习），这个框架利用移动传输器，如无人机，建立了服务器和客户端之间的间接通信通道。这些传输器作为中介，允许模型信息的交换。间接通信的使用为收敛分析和优化带来了新的挑战，因为传输器运动引入的延迟对全局模型分发和本地模型收集都会产生问题。为了解决这些问题，本文提出了一种联合客户端分配和无人机路径规划方法，优化了移动传输器的使用，同时最小化总体训练时间和通信成本。

    Federated Learning (FL) is a machine learning approach that enables the creation of shared models for powerful applications while allowing data to remain on devices. This approach provides benefits such as improved data privacy, security, and reduced latency. However, in some systems, direct communication between clients and servers may not be possible, such as remote areas without proper communication infrastructure. To overcome this challenge, a new framework called FedEx (Federated Learning via Model Express Delivery) is proposed. This framework employs mobile transporters, such as UAVs, to establish indirect communication channels between the server and clients. These transporters act as intermediaries and allow for model information exchange. The use of indirect communication presents new challenges for convergence analysis and optimization, as the delay introduced by the transporters' movement creates issues for both global model dissemination and local model collection. To addre
    
[^53]: KitchenScale: 从食谱上下文中学习预测成分量。

    KitchenScale: Learning to predict ingredient quantities from recipe contexts. (arXiv:2304.10739v1 [cs.CL])

    [http://arxiv.org/abs/2304.10739](http://arxiv.org/abs/2304.10739)

    KitchenScale是一个经过Fine-tuned的预训练语言模型（PLM），可根据食谱上下文预测目标成分的数量和测量单位。该模型采用离散潜在指数（DExp）方法处理食谱语料库中数字尺度的高方差，尝试从食谱文本到PLMs的转移学习。在新构建的数据集和推荐示例上进行实验，证明了KitchenScale具有泛化性并可以理解各种食谱语境，同时提供了一个Web应用程序来为用户提供所需的食品量的配方特定的测量单位。

    

    在烹饪实践中，确定成分的适当量对于丰富口感和促进健康至关重要。我们介绍了KitchenScale，这是一个经过Fine-tuned的预训练语言模型（PLM），根据食谱上下文预测目标成分的数量和测量单位。为了有效地训练我们的KitchenScale模型，我们制定了一个包括三个子任务的成分量预测任务，这些子任务是成分测量类型分类、单位分类和数量回归任务。此外，我们利用了从食谱文本到PLMs的烹饪知识的转移学习。我们采用了离散潜在指数（DExp）方法来应对食谱语料库中数字尺度的高方差。我们使用我们新构建的数据集和推荐示例进行实验，证明了KitchenScale理解各种食谱语境以及在预测成分量方面具有泛化性。我们实现了一个Web应用程序，为用户提供所需的用于所需人数食品量的配方特定的测量单位。

    Determining proper quantities for ingredients is an essential part of cooking practice from the perspective of enriching tastiness and promoting healthiness. We introduce KitchenScale, a fine-tuned Pre-trained Language Model (PLM) that predicts a target ingredient's quantity and measurement unit given its recipe context. To effectively train our KitchenScale model, we formulate an ingredient quantity prediction task that consists of three sub-tasks which are ingredient measurement type classification, unit classification, and quantity regression task. Furthermore, we utilized transfer learning of cooking knowledge from recipe texts to PLMs. We adopted the Discrete Latent Exponent (DExp) method to cope with high variance of numerical scales in recipe corpora. Experiments with our newly constructed dataset and recommendation examples demonstrate KitchenScale's understanding of various recipe contexts and generalizability in predicting ingredient quantities. We implemented a web applicati
    
[^54]: RoCOCO：稳健的基准MS-COCO评估图文匹配模型的鲁棒性

    RoCOCO: Robust Benchmark MS-COCO to Stress-test Robustness of Image-Text Matching Models. (arXiv:2304.10727v1 [cs.CV])

    [http://arxiv.org/abs/2304.10727](http://arxiv.org/abs/2304.10727)

    本文提出了一个新的评估基准来测试ITM模型的鲁棒性，通过将一些“愚弄”的图片和标题添加到检索池中，在MS COCO数据集上为各种最先进的模型进行鲁棒性测试，揭示了它们的不足之处。

    

    近年来，大规模的视觉语言预训练模型和视觉语义嵌入方法显著提高了MS COCO 5K测试集上图文匹配（ITM）的准确性。然而，当将这些最先进的模型用于实际应用时，它们的鲁棒性仍不清楚。本文提出了一个新的评估基准来测试ITM模型的鲁棒性。为此，我们将各种“愚弄”的图片和标题添加到检索池中。具体而言，我们通过插入不相关的图像来更改图像，并通过替换名词来更改标题，从而改变句子的含义。我们发现，仅仅将这些新创建的图像和标题添加到测试集中就可以降低各种最先进模型的性能（例如，在BLIP中从81.9％降至64.5％，在VSE∞中从66.1％降至37.5％）。我们希望我们的发现能为提高视觉语言模型的鲁棒性和设计更多样化的压力测试提供启示。

    Recently, large-scale vision-language pre-training models and visual semantic embedding methods have significantly improved image-text matching (ITM) accuracy on MS COCO 5K test set. However, it is unclear how robust these state-of-the-art (SOTA) models are when using them in the wild. In this paper, we propose a novel evaluation benchmark to stress-test the robustness of ITM models. To this end, we add various fooling images and captions to a retrieval pool. Specifically, we change images by inserting unrelated images, and change captions by substituting a noun, which can change the meaning of a sentence. We discover that just adding these newly created images and captions to the test set can degrade performances (i.e., Recall@1) of a wide range of SOTA models (e.g., 81.9% $\rightarrow$ 64.5% in BLIP, 66.1% $\rightarrow$ 37.5% in VSE$\infty$). We expect that our findings can provide insights for improving the robustness of the vision-language models and devising more diverse stress-te
    
[^55]: 缺失数据下的交通信号控制的强化学习方法

    Reinforcement Learning Approaches for Traffic Signal Control under Missing Data. (arXiv:2304.10722v1 [cs.LG])

    [http://arxiv.org/abs/2304.10722](http://arxiv.org/abs/2304.10722)

    本文提出了在交通路网中缺少传感器的情况下，使用强化学习方法通过补充流量状态或状态和动作来实现自适应控制和条件融合。

    

    强化学习方法在交通信号控制任务中的应用已经取得了比传统的基于规则的方法更好的性能。然而，现实中交通状态的缺失可能经常发生，使得现有的强化学习方法在缺少传感器的路网上无法应用。本文旨在控制交通信号在现实环境下的设置中，其中一些路口没有安装传感器，因此周围没有直接观察数据。在我们所知道的范围内，我们是第一个使用强化学习方法来解决这个现实世界中的交通信号控制问题。具体地，我们提出了两种解决方案：第一种方案补充流量状态以实现自适应控制，第二种方案补充状态和动作以进行条件融合。

    The emergence of reinforcement learning (RL) methods in traffic signal control tasks has achieved better performance than conventional rule-based approaches. Most RL approaches require the observation of the environment for the agent to decide which action is optimal for a long-term reward. However, in real-world urban scenarios, missing observation of traffic states may frequently occur due to the lack of sensors, which makes existing RL methods inapplicable on road networks with missing observation. In this work, we aim to control the traffic signals in a real-world setting, where some of the intersections in the road network are not installed with sensors and thus with no direct observations around them. To the best of our knowledge, we are the first to use RL methods to tackle the traffic signal control problem in this real-world setting. Specifically, we propose two solutions: the first one imputes the traffic states to enable adaptive control, and the second one imputes both stat
    
[^56]: 物理世界中愚弄热红外探测器

    Fooling Thermal Infrared Detectors in Physical World. (arXiv:2304.10712v1 [cs.CV])

    [http://arxiv.org/abs/2304.10712](http://arxiv.org/abs/2304.10712)

    本论文提出一种新颖的物理攻击方法——对抗性红外块（AdvIB），可以从多个角度对热成像系统执行隐蔽的黑盒攻击，成功诱导目标红外检测器在物理场景中对对象或人类进行误分类，并且不被人类察觉。

    

    红外成像系统在行人检测和自动驾驶等方面有着广泛的应用前景，并且它们的安全性能备受关注。然而，很少有研究探索了红外成像系统在真实世界环境下的安全性。过去的研究使用物理干扰，如小灯泡和热“QR代码”来攻击红外成像探测器，但这种方法很容易被察觉，缺乏隐秘性。其他研究人员使用热和冷块来欺骗红外成像探测器，但这种方法在从多个角度执行攻击方面的能力有限。为了解决这些缺点，我们提出了一种新颖的物理攻击方法，称为对抗性红外块（AdvIB）。通过优化对抗性红外块的物理参数，这种方法可以从多个角度对热成像系统执行隐蔽的黑盒攻击。我们根据其有效性、隐秘性和稳健性评估了所提出的方法。结果表明，AdvIB可以成功诱导目标红外检测器在物理场景中对对象或人类进行误分类，并且不被人类察觉。我们的工作强调了在红外成像系统中提高安全措施的必要性，特别是在真实世界环境中。

    Infrared imaging systems have a vast array of potential applications in pedestrian detection and autonomous driving, and their safety performance is of great concern. However, few studies have explored the safety of infrared imaging systems in real-world settings. Previous research has used physical perturbations such as small bulbs and thermal "QR codes" to attack infrared imaging detectors, but such methods are highly visible and lack stealthiness. Other researchers have used hot and cold blocks to deceive infrared imaging detectors, but this method is limited in its ability to execute attacks from various angles. To address these shortcomings, we propose a novel physical attack called adversarial infrared blocks (AdvIB). By optimizing the physical parameters of the adversarial infrared blocks, this method can execute a stealthy black-box attack on thermal imaging system from various angles. We evaluate the proposed method based on its effectiveness, stealthiness, and robustness. Our
    
[^57]: 基于图的标签增强的多示例多标签学习

    Graph based Label Enhancement for Multi-instance Multi-label learning. (arXiv:2304.10705v1 [cs.CV])

    [http://arxiv.org/abs/2304.10705](http://arxiv.org/abs/2304.10705)

    本文提出了一种基于图标签增强的新型MIML框架GLEMIML，通过提高标签重要性来提高MIML的分类性能，并在实验中证明了其优越性。

    

    多示例多标签（MIML）学习被广泛应用于许多领域，如图像分类，其中一个图像包含同时与多个逻辑标签相关的多个示例。现有 MIML 中的相关标签都被假定为具有相等意义的逻辑标签。然而，在 MIML 的实际应用中，每个标签对于每个多示例背包（如一个图像）的重要性差异显著。忽略标签的重要性将大大损失对象的语义信息，使 MIML 在复杂场景中的学习性能不佳。为此，本文提出了一种基于图标签增强的新型 MIML 框架，即 GLEMIML，通过利用标签重要性来提高 MIML 的分类性能。GLEMIML 首先通过建立图来识别实例之间的关联，然后通过邻域传播将从特征空间中挖掘的隐式信息迁移到标签空间中。最后，提出一种基于图的标签增强策略，以增强不同重要性级别的实例标签。实验结果表明，与几种最先进的 MIML 方法相比，GLEMIML 的有效性和优越性都得到了证明。

    Multi-instance multi-label (MIML) learning is widely applicated in numerous domains, such as the image classification where one image contains multiple instances correlated with multiple logic labels simultaneously. The related labels in existing MIML are all assumed as logical labels with equal significance. However, in practical applications in MIML, significance of each label for multiple instances per bag (such as an image) is significant different. Ignoring labeling significance will greatly lose the semantic information of the object, so that MIML is not applicable in complex scenes with a poor learning performance. To this end, this paper proposed a novel MIML framework based on graph label enhancement, namely GLEMIML, to improve the classification performance of MIML by leveraging label significance. GLEMIML first recognizes the correlations among instances by establishing the graph and then migrates the implicit information mined from the feature space to the label space via n
    
[^58]: 交互式系统级异常检测

    Interactive System-wise Anomaly Detection. (arXiv:2304.10704v1 [cs.LG])

    [http://arxiv.org/abs/2304.10704](http://arxiv.org/abs/2304.10704)

    本文提出了 InterSAD 方法，利用马尔可夫决策过程模拟交互式系统，并通过找到有效的激活信号和实时交互，解决了系统级异常检测的问题。

    

    异常检测在各种应用中发挥着基础性的作用，其目的是找到包含不同于大多数的特征模式的数据实例。然而，现有方法很难处理其中实例是系统的情况，因为系统的特征不易观察作为数据。需要适当的交互来与系统进行交互并识别那些具有异常响应的系统，这是一个具有挑战性的任务。本文提出了交互式系统级异常检测方法来解决这些挑战。具体而言，我们采用马尔可夫决策过程来模拟交互式系统，并定义了系统级异常检测问题。同时，我们通过找到有效的激活信号来与系统进行交互，并通过实时交互确保稳定的训练过程。

    Anomaly detection, where data instances are discovered containing feature patterns different from the majority, plays a fundamental role in various applications. However, it is challenging for existing methods to handle the scenarios where the instances are systems whose characteristics are not readily observed as data. Appropriate interactions are needed to interact with the systems and identify those with abnormal responses. Detecting system-wise anomalies is a challenging task due to several reasons including: how to formally define the system-wise anomaly detection problem; how to find the effective activation signal for interacting with systems to progressively collect the data and learn the detector; how to guarantee stable training in such a non-stationary scenario with real-time interactions? To address the challenges, we propose InterSAD (Interactive System-wise Anomaly Detection). Specifically, first, we adopt Markov decision process to model the interactive systems, and defi
    
[^59]: 通过正确性和信息量评估推理链的ReCEval

    ReCEval: Evaluating Reasoning Chains via Correctness and Informativeness. (arXiv:2304.10703v1 [cs.CL])

    [http://arxiv.org/abs/2304.10703](http://arxiv.org/abs/2304.10703)

    本文提出了一种基于推导链正确性和信息量的推理链评估框架ReCEval，用以评估多步推理能力。该框架能够客观、系统和准确地评估推理链，并在多个数据集上实现了良好的效果。

    

    多步推理能力在许多自然语言任务中都是基础，但什么构成好的推理链以及如何评估它们尚不清楚。大多数现有方法仅关注推理链是否导致正确的结论，但这种以答案为导向的观点可能会将好的推理质量与其他用于预测答案的假捷径混淆。为了弥补这一差距，我们将推理链视为推导最终答案的非正式证明，通过评估推理链的两个关键特性——（1）正确性，即每个步骤基于步骤，前置步骤和输入上下文中包含的信息进行有效推理，以及（2）信息量，即每个步骤提供新信息有助于推导生成的答案——我们提出了ReCEval（推理链评估）框架。我们使用自然语言推理模型和信息理论测量实现了ReCEval。在多个数据集上的实验表明，我们的框架在评估推理链方面比现有方法更加客观、系统和准确。

    Multi-step reasoning ability is fundamental to many natural language tasks, yet it is unclear what constitutes a good reasoning chain and how to evaluate them. Most existing methods focus solely on whether the reasoning chain leads to the correct conclusion, but this answer-oriented view may confound the quality of reasoning with other spurious shortcuts to predict the answer. To bridge this gap, we evaluate reasoning chains by viewing them as informal proofs that derive the final answer. Specifically, we propose ReCEval (Reasoning Chain Evaluation), a framework that evaluates reasoning chains through two key properties: (1) correctness, i.e., each step makes a valid inference based on the information contained within the step, preceding steps, and input context, and (2) informativeness, i.e., each step provides new information that is helpful towards deriving the generated answer. We implement ReCEval using natural language inference models and information-theoretic measures. On multi
    
[^60]: 元语义学：迈向更好的自然语言理解和推理

    Meta Semantics: Towards better natural language understanding and reasoning. (arXiv:2304.10663v1 [cs.CL])

    [http://arxiv.org/abs/2304.10663](http://arxiv.org/abs/2304.10663)

    该论文提出了解决词汇外问题的两种策略以及一个用于更好的自然语言理解和推理的语义模型，旨在克服深度神经网络方法和基于规则方法的不足。

    

    自然语言理解是人工智能中最具挑战性的问题之一。深度神经网络方法，特别是大型语言模块（LLM）方法，如ChatGPT和GPT-3，具有采用非正式文本的强大灵活性，但在逻辑推导上较弱，并且受到词汇外（OOV）问题的影响。另一方面，基于规则的方法，如Mathematica、语义网络和Lean，在推理方面表现出色，但无法处理复杂和易变的非正式文本。受到语用学和结构主义的启发，我们提出了两种策略来解决OOV问题，并提出了一个语义模型，用于更好的自然语言理解和推理。

    Natural language understanding is one of the most challenging topics in artificial intelligence. Deep neural network methods, particularly large language module (LLM) methods such as ChatGPT and GPT-3, have powerful flexibility to adopt informal text but are weak on logical deduction and suffer from the out-of-vocabulary (OOV) problem. On the other hand, rule-based methods such as Mathematica, Semantic web, and Lean, are excellent in reasoning but cannot handle the complex and changeable informal text. Inspired by pragmatics and structuralism, we propose two strategies to solve the OOV problem and a semantic model for better natural language understanding and reasoning.
    
[^61]: “HOT” ChatGPT：ChatGPT在社交媒体上检测和识别令人讨厌、令人不悦和有害评论的潜力

    "HOT" ChatGPT: The promise of ChatGPT in detecting and discriminating hateful, offensive, and toxic comments on social media. (arXiv:2304.10619v1 [cs.CL])

    [http://arxiv.org/abs/2304.10619](http://arxiv.org/abs/2304.10619)

    本研究使用ChatGPT探究了生成式AI模型检测社交媒体上有害评论的可行性，结果显示ChatGPT可以达到约80%的准确性。

    

    社交媒体上危害性内容的存在对在线社区和参与产生了负面影响。解决这个问题的方法之一是开发需要人工标注的检测模型。然而，构建这样的模型需要曝露标注者于有害和冒犯性内容的任务，可能需要大量的时间和成本。生成式AI模型有潜力理解和检测有害内容。为了研究这个潜力，我们使用ChatGPT，并将其性能与MTurker注释进行了比较，这些注释与有害内容相关的三个经常讨论的概念：令人讨厌、令人不悦和有害（HOT）。我们设计了五个提示与ChatGPT进行交互，并进行了四个实验来引出HOT的分类。我们的结果显示，与MTurker注释相比，ChatGPT可以达到约80％的准确性。具体而言，与HOT评论相比，模型对非HOT评论的分类更加一致。

    Harmful content is pervasive on social media, poisoning online communities and negatively impacting participation. A common approach to address this issue is to develop detection models that rely on human annotations. However, the tasks required to build such models expose annotators to harmful and offensive content and may require significant time and cost to complete. Generative AI models have the potential to understand and detect harmful content. To investigate this potential, we used ChatGPT and compared its performance with MTurker annotations for three frequently discussed concepts related to harmful content: Hateful, Offensive, and Toxic (HOT). We designed five prompts to interact with ChatGPT and conducted four experiments eliciting HOT classifications. Our results show that ChatGPT can achieve an accuracy of approximately 80% when compared to MTurker annotations. Specifically, the model displays a more consistent classification for non-HOT comments than HOT comments compared 
    
[^62]: 无注意力条件自编码器用于加密货币异常检测

    An Attention Free Conditional Autoencoder For Anomaly Detection in Cryptocurrencies. (arXiv:2304.10614v1 [cs.LG])

    [http://arxiv.org/abs/2304.10614](http://arxiv.org/abs/2304.10614)

    本篇论文提出了一种无注意力条件自编码器(AF-CA)，用于检测时间序列中的异常，在处理噪声时更可靠，可以提高异常检测的能力。

    

    在时间序列中识别异常很困难，尤其是在存在大量噪声的情况下。降噪技术可以去除噪声，但这可能会导致信息的显著损失。为了检测时间序列中的异常，我们提出了一种无注意力条件自编码器(AF-CA)。我们从自编码器条件模型开始，添加了一个无注意力LSTM层\cite{inzirillo2022attention}，以使异常检测能力更可靠，并增加异常检测的功率。我们将我们的Attention Free Conditional Autoencoder与LSTM Autoencoder的结果进行了比较，明显提高了模型的解释能力，因此可以更好地检测噪声时间序列中的异常。

    It is difficult to identify anomalies in time series, especially when there is a lot of noise. Denoising techniques can remove the noise but this technique can cause a significant loss of information. To detect anomalies in the time series we have proposed an attention free conditional autoencoder (AF-CA). We started from the autoencoder conditional model on which we added an Attention-Free LSTM layer \cite{inzirillo2022attention} in order to make the anomaly detection capacity more reliable and to increase the power of anomaly detection. We compared the results of our Attention Free Conditional Autoencoder with those of an LSTM Autoencoder and clearly improved the explanatory power of the model and therefore the detection of anomaly in noisy time series.
    
[^63]: Text2Seg: 通过文本引导视觉基础模型的遥感图像语义分割

    Text2Seg: Remote Sensing Image Semantic Segmentation via Text-Guided Visual Foundation Models. (arXiv:2304.10597v1 [cs.CV])

    [http://arxiv.org/abs/2304.10597](http://arxiv.org/abs/2304.10597)

    本文介绍了一种名为 Text2Seg 的遥感图像语义分割流程，利用多个基础模型和文本引导，取得了初步成果。

    

    最近，基础模型（FMs），如 GPT-4 和 LLaMA，在零样本学习方案中表现出色，吸引了大量关注。类似地，在视觉学习领域，Grounding DINO 和 Segment Anything Model（SAM）等模型在开放式检测和实例分割任务中展现了显著的进步。本研究专注于遥感领域，其中图片与传统场景中的图片明显不同。我们开发了一个流程，利用多个 FMs，以文本提示为指导，促进遥感图像语义分割任务，我们将其称为 Text2Seg 。该管道在多个广泛使用的遥感数据集上进行基准测试，并提供初步结果以证明其有效性。

    Recent advancements in foundation models (FMs), such as GPT-4 and LLaMA, have attracted significant attention due to their exceptional performance in zero-shot learning scenarios. Similarly, in the field of visual learning, models like Grounding DINO and the Segment Anything Model (SAM) have exhibited remarkable progress in open-set detection and instance segmentation tasks. It is undeniable that these FMs will profoundly impact a wide range of real-world visual learning tasks, ushering in a new paradigm shift for developing such models. In this study, we concentrate on the remote sensing domain, where the images are notably dissimilar from those in conventional scenarios. We developed a pipeline that leverages multiple FMs to facilitate remote sensing image semantic segmentation tasks guided by text prompt, which we denote as Text2Seg. The pipeline is benchmarked on several widely-used remote sensing datasets, and we present preliminary results to demonstrate its effectiveness. Throug
    
[^64]: 利用网络分析来从印度专利中探究人工智能政策的融合与预测

    Enhancing Artificial intelligence Policies with Fusion and Forecasting: Insights from Indian Patents Using Network Analysis. (arXiv:2304.10596v1 [cs.AI])

    [http://arxiv.org/abs/2304.10596](http://arxiv.org/abs/2304.10596)

    本研究利用网络分析揭示了塑造AI发展格局和领域成熟度的重要组成部分，为AI公共政策的数据驱动带来了新的视角。

    

    本文利用网络分析的中心度测量、聚类系数和融合度测量等方法，研究人工智能（AI）技术的互联互通和相互依存。通过在不同时间窗口内分析和量化这些技术的重要性，揭示了塑造AI发展格局和领域成熟度的重要组成部分。该研究结果对未来人工智能的发展和进步具有重大意义，并清晰地了解了融合技术的关键技术领域。此外，本文通过提供一种数据驱动的视角，为AI公共政策研究做出了贡献。然而，需要注意本研究的局限性，并呼吁进一步研究来建立这些结果的基础。通过这些发现，我们希望指导未来的研究。

    This paper presents a study of the interconnectivity and interdependence of various Artificial intelligence (AI) technologies through the use of centrality measures, clustering coefficients, and degree of fusion measures. By analyzing the technologies through different time windows and quantifying their importance, we have revealed important insights into the crucial components shaping the AI landscape and the maturity level of the domain. The results of this study have significant implications for future development and advancements in artificial intelligence and provide a clear understanding of key technology areas of fusion. Furthermore, this paper contributes to AI public policy research by offering a data-driven perspective on the current state and future direction of the field. However, it is important to acknowledge the limitations of this research and call for further studies to build on these results. With these findings, we hope to inform and guide future research in the fiel
    
[^65]: 顺序决策制定的符号、亚符号和混合方法综述

    A Review of Symbolic, Subsymbolic and Hybrid Methods for Sequential Decision Making. (arXiv:2304.10590v1 [cs.AI])

    [http://arxiv.org/abs/2304.10590](http://arxiv.org/abs/2304.10590)

    本文综述了顺序决策制定的符号、亚符号和混合方法，旨在解决顺序决策过程（SDP）中的问题。无论是基于自动化规划（AP）还是强化学习（RL），都涵盖了解决SDP的方法和学习其结构的方面。对于可扩展性方面的挑战，也进行了讨论。

    

    顺序决策制定（SDM）领域提供了解决顺序决策过程（SDP）的工具，其中智能体必须做出一系列决策以完成任务或实现目标。历史上，两种竞争的SDM范例主导了该领域。自动化规划（AP）提出通过对世界模型的推理过程解决SDP，通常使用符号表示。相反，强化学习（RL）则提出从数据中学习SDP的解决方案，不需要世界模型，并以亚符号形式表示学习到的知识。本综述在协调两种方法的基础上，对SDM的符号、亚符号和混合方法进行了综述。我们涵盖了解决SDP的方法（例如AP、RL和学习规划的技术）以及学习其结构的方面（例如世界模型、状态不变量和地标）。据我们所知，该领域中没有其他综述提供相同的范围。作为额外的贡献，我们还讨论了各种方法在可扩展性方面的挑战，例如如何将方法扩展到更大、更复杂的领域中。

    The field of Sequential Decision Making (SDM) provides tools for solving Sequential Decision Processes (SDPs), where an agent must make a series of decisions in order to complete a task or achieve a goal. Historically, two competing SDM paradigms have view for supremacy. Automated Planning (AP) proposes to solve SDPs by performing a reasoning process over a model of the world, often represented symbolically. Conversely, Reinforcement Learning (RL) proposes to learn the solution of the SDP from data, without a world model, and represent the learned knowledge subsymbolically. In the spirit of reconciliation, we provide a review of symbolic, subsymbolic and hybrid methods for SDM. We cover both methods for solving SDPs (e.g., AP, RL and techniques that learn to plan) and for learning aspects of their structure (e.g., world models, state invariants and landmarks). To the best of our knowledge, no other review in the field provides the same scope. As an additional contribution, we discuss w
    
[^66]: 量化人工智能在科学研究中的益处

    Quantifying the Benefit of Artificial Intelligence for Scientific Research. (arXiv:2304.10578v1 [cs.DL])

    [http://arxiv.org/abs/2304.10578](http://arxiv.org/abs/2304.10578)

    该篇论文通过将自然语言处理技术应用于数百万篇文献来估计人工智能的直接使用和潜在受益，发现人工智能在科学研究中的应用似乎在所有科学领域中普遍，使用人工智能的论文具有更高的影响力。

    

    持续不断的人工智能（AI）革命有可能改变几乎所有的行业。随着AI能力的提高，精度、鲁棒性和应用范围的增加，AI可能会在许多有价值的任务上超过甚至取代人类专家。尽管人们不断努力研究AI对劳动力和经济的影响，以及它在促进科学发现和进步方面的最近成功，但我们缺乏一个系统的理解，即AI的进步如何在不同学科和领域中受益于科学研究。在此，我们开发了一个衡量框架，通过将自然语言处理技术应用于87.6百万篇论文和7.1百万份专利，来估计AI的直接使用和潜在受益。我们发现，AI在研究中的应用似乎在所有科学领域中普遍，特别是自2015年以来开始迅速增长，并且使用AI的论文具有更高的影响力，更可能在内外部被高度引用。

    The ongoing artificial intelligence (AI) revolution has the potential to change almost every line of work. As AI capabilities continue to improve in accuracy, robustness, and reach, AI may outperform and even replace human experts across many valuable tasks. Despite enormous efforts devoted to understanding AI's impact on labor and the economy and its recent success in accelerating scientific discovery and progress, we lack a systematic understanding of how advances in AI may benefit scientific research across disciplines and fields. Here we develop a measurement framework to estimate both the direct use of AI and the potential benefit of AI in scientific research by applying natural language processing techniques to 87.6 million publications and 7.1 million patents. We find that the use of AI in research appears widespread throughout the sciences, growing especially rapidly since 2015, and papers that use AI exhibit an impact premium, more likely to be highly cited both within and out
    
[^67]: IDQL: 作为一种扩散策略的Actor-Critic方法的隐式Q学习。 (arXiv:2304.10573v1 [cs.LG])

    IDQL: Implicit Q-Learning as an Actor-Critic Method with Diffusion Policies. (arXiv:2304.10573v1 [cs.LG])

    [http://arxiv.org/abs/2304.10573](http://arxiv.org/abs/2304.10573)

    本文重新解释隐式Q学习(IQL)作为Actor-Critic方法，提出使用扩散行为策略和评判器权重来平衡奖励最大化和与行为策略的分歧。这个方法能够处理复杂和多峰特征的Actor问题。

    

    有效的离线RL方法需要正确处理超出分布的行为。隐式Q学习（IQL）通过仅使用数据集行动通过修改后的Bellman Backup来训练Q函数来解决此问题。但是，不清楚哪个策略实际上实现了此隐含训练的Q函数所代表的值。在本文中，我们将IQL重新解释为Actor-Critic方法，通过广义化评判目标并将其连接到行为规范化的隐式Actor来实现。这种泛化显示了引入的Actor如何平衡奖励最大化和与行为策略的分歧，具体的损失选择决定了这种权衡的性质。值得注意的是，这个Actor可以表现出复杂和多峰的特征，这表明了利用优势加权回归（AWR）中使用的条件高斯Actor的拟合问题。相反，我们建议使用来自参数化扩散行为策略的样本和由评判器计算的权重，然后将其导入。

    Effective offline RL methods require properly handling out-of-distribution actions. Implicit Q-learning (IQL) addresses this by training a Q-function using only dataset actions through a modified Bellman backup. However, it is unclear which policy actually attains the values represented by this implicitly trained Q-function. In this paper, we reinterpret IQL as an actor-critic method by generalizing the critic objective and connecting it to a behavior-regularized implicit actor. This generalization shows how the induced actor balances reward maximization and divergence from the behavior policy, with the specific loss choice determining the nature of this tradeoff. Notably, this actor can exhibit complex and multimodal characteristics, suggesting issues with the conditional Gaussian actor fit with advantage weighted regression (AWR) used in prior methods. Instead, we propose using samples from a diffusion parameterized behavior policy and weights computed from the critic to then importa
    
[^68]: 使用Z3进行FNN全局鲁棒性的形式化建模和验证

    Using Z3 for Formal Modeling and Verification of FNN Global Robustness. (arXiv:2304.10558v1 [cs.LG])

    [http://arxiv.org/abs/2304.10558](http://arxiv.org/abs/2304.10558)

    本文介绍了使用Z3求解器对全局鲁棒性可验证框架DeepGlobal进行更明确的定义和优化的工作，来建立FNN的形式化模型，以实现更有效的验证。

    

    虽然前馈神经网络（FNN）在各种任务中取得了显著的成功，但它们对对抗样本很容易受到攻击。已经开发了几种技术来验证FNN的对抗鲁棒性，但大多数技术都集中在针对单个数据点的局部扰动邻域的鲁棒性验证上。全局鲁棒性分析仍存在较大的研究空白。DeepGlobal是一种全局鲁棒性可验证框架，旨在确定FNN的所有可能的对抗危险区域（ADR），不限于测试集中的数据样本。本文提出了DeepGlobal的完整规范和实现，利用SMT求解器Z3进行更明确的定义，并提出了几项改进以进行更高效的验证。为了评估我们的实现和改进的有效性，我们对一组基准数据集进行了广泛的实验。我们的实验结果进行了可视化。

    While Feedforward Neural Networks (FNNs) have achieved remarkable success in various tasks, they are vulnerable to adversarial examples. Several techniques have been developed to verify the adversarial robustness of FNNs, but most of them focus on robustness verification against the local perturbation neighborhood of a single data point. There is still a large research gap in global robustness analysis. The global-robustness verifiable framework DeepGlobal has been proposed to identify \textit{all} possible Adversarial Dangerous Regions (ADRs) of FNNs, not limited to data samples in a test set. In this paper, we propose a complete specification and implementation of DeepGlobal utilizing the SMT solver Z3 for more explicit definition, and propose several improvements to DeepGlobal for more efficient verification. To evaluate the effectiveness of our implementation and improvements, we conduct extensive experiments on a set of benchmark datasets. Visualization of our experiment results s
    
[^69]: Transformer介绍

    An Introduction to Transformers. (arXiv:2304.10557v1 [cs.LG])

    [http://arxiv.org/abs/2304.10557](http://arxiv.org/abs/2304.10557)

    Transformer是一种神经网络组件，可以学习序列或数据集表示，在自然语言处理、计算机视觉和时空建模方面取得了重大进展。本论文提供了一个数学精确、直观、简洁的Transformer架构描述。

    

    Transformer是一种可以学习序列或数据集表示的神经网络组件。Transformer在自然语言处理、计算机视觉和时空建模方面取得了重大进展。虽然有很多Transformer的介绍，但大多数都缺少对其架构的精确数学描述，其设计选择的直觉也常常缺失。此外，随着研究路径的曲折，Transformer部件的解释可能是异质的。在这篇论文中，我们旨在提供一个数学精确、直观、简洁的Transformer架构描述。

    The transformer is a neural network component that can be used to learn useful representations of sequences or sets of datapoints. The transformer has driven recent advances in natural language processing, computer vision, and spatio-temporal modelling. There are many introductions to transformers, but most do not contain precise mathematical descriptions of the architecture and the intuitions behind the design choices are often also missing. Moreover, as research takes a winding path, the explanations for the components of the transformer can be idiosyncratic. In this note we aim for a mathematically precise, intuitive, and clean description of the transformer architecture.
    
[^70]: 一种协同商务智能虚拟助手参考模型

    A Reference Model for Collaborative Business Intelligence Virtual Assistants. (arXiv:2304.10556v1 [cs.HC])

    [http://arxiv.org/abs/2304.10556](http://arxiv.org/abs/2304.10556)

    本文介绍了协同商务智能的虚拟助手参考模型，旨在提高不同利益相关者之间的知识共享和协作。该模型可用于支持商业分析中的各种活动，促进更好的决策制定。

    

    协同商务分析(CBA)是一种方法论，它涉及将不同的利益相关者，包括业务用户、分析师和技术专家，聚集在一起，协同分析数据并获取对业务运营的洞察。CBA的主要目标是鼓励知识共享和协作，从而可以更全面地理解数据并做出更好的决策。CBA通常需要进行各种活动，包括数据收集和分析、头脑风暴、问题解决、决策和知识共享。这些活动可以通过各种渠道进行，例如面对面会议、虚拟协作工具或在线论坛。本文讨论了虚拟协作工具作为商务智能(BI)平台重要组成部分。协同商务智能(CBI)工具变得更加用户友好、可访问和灵活，可实现跨团队协作。

    Collaborative Business Analysis (CBA) is a methodology that involves bringing together different stakeholders, including business users, analysts, and technical specialists, to collaboratively analyze data and gain insights into business operations. The primary objective of CBA is to encourage knowledge sharing and collaboration between the different groups involved in business analysis, as this can lead to a more comprehensive understanding of the data and better decision-making. CBA typically involves a range of activities, including data gathering and analysis, brainstorming, problem-solving, decision-making and knowledge sharing. These activities may take place through various channels, such as in-person meetings, virtual collaboration tools or online forums. This paper deals with virtual collaboration tools as an important part of Business Intelligence (BI) platform. Collaborative Business Intelligence (CBI) tools are becoming more user-friendly, accessible, and flexible, allowing
    
[^71]: 稀疏性能够提高神经网络的隐私

    Sparsity in neural networks can improve their privacy. (arXiv:2304.10553v1 [cs.LG])

    [http://arxiv.org/abs/2304.10553](http://arxiv.org/abs/2304.10553)

    稀疏性能够提高神经网络的隐私，并且能够保持网络的表现

    

    本文研究稀疏性如何提高神经网络对成员推理攻击的鲁棒性。实验结果表明，稀疏性能够提高网络的隐私，同时保持其在任务上的相似表现。这个实证研究完善和扩展了现有文献。

    This article measures how sparsity can make neural networks more robust to membership inference attacks. The obtained empirical results show that sparsity improves the privacy of the network, while preserving comparable performances on the task at hand. This empirical study completes and extends existing literature.
    
[^72]: 深度迁移学习在入侵检测系统中的应用：综述

    Deep Transfer Learning Applications in Intrusion Detection Systems: A Comprehensive Review. (arXiv:2304.10550v1 [cs.CR])

    [http://arxiv.org/abs/2304.10550](http://arxiv.org/abs/2304.10550)

    本文全面回顾了深度迁移学习在入侵检测系统中的应用，特别是基于IDS的深度迁移学习，该技术利用多个领域的知识融合和/或适应以提高目标任务的性能，尤其是在目标领域中的标记数据非常少的情况下。

    

    全球范围内，外部互联网越来越多地与当代工业控制系统相连接。因此，有一个迫切的需求保护网络免受各种威胁。可以使用入侵检测系统（IDS）来保护工业活动的关键基础设施，这是一种预防性措施机制，用于识别新的危险威胁和敌对活动。本文研究了用于在许多种工业控制网络中创建IDS的最新人工智能（AI）技术，特别侧重于基于IDS的深度迁移学习（DTL）。DTL可以看作是将来自多个领域的知识融合和/或适应以增强目标任务的性能的一种信息融合。重点是当目标域中的标记数据很少时，DTL可以帮助提高IDS的性能。考虑了2015年之后的出版物。这些选定的出版物被分为三类：仅DTL和仅IDS，具有迁移学习（TL）的IDS，以及基于深度迁移学习的IDS。该研究全面回顾了入侵检测系统中深度迁移学习应用的最新技术和方法。

    Globally, the external Internet is increasingly being connected to the contemporary industrial control system. As a result, there is an immediate need to protect the network from several threats. The key infrastructure of industrial activity may be protected from harm by using an intrusion detection system (IDS), a preventive measure mechanism, to recognize new kinds of dangerous threats and hostile activities. The most recent artificial intelligence (AI) techniques used to create IDS in many kinds of industrial control networks are examined in this study, with a particular emphasis on IDS-based deep transfer learning (DTL). This latter can be seen as a type of information fusion that merge, and/or adapt knowledge from multiple domains to enhance the performance of the target task, particularly when the labeled data in the target domain is scarce. Publications issued after 2015 were taken into account. These selected publications were divided into three categories: DTL-only and IDS-onl
    
[^73]: 关于无交集偏序通用集合的连通性属性的注记

    A note on the connectedness property of union-free generic sets of partial orders. (arXiv:2304.10549v1 [cs.LG])

    [http://arxiv.org/abs/2304.10549](http://arxiv.org/abs/2304.10549)

    本文证明了偏序数据深度函数的背景下Blocher等人[2023]中介绍的无交通用集合具有连通性属性。

    

    本短文描述并证明了在偏序数据深度函数的背景下Blocher等人[2023]引入的连通性属性。 连通性属性为无交通用集合提供了结构性的深入认识。这些集合是在Blocher等人[2023]中介绍的，它们使用在形式概念分析理论中自然出现的所有偏序集合上的闭包运算进行定义。在形式概念分析的语言中，连通性的属性可以生动地被证明。但是，由于在Blocher等人[2023]中我们没有讨论形式概念分析,因此我们把证明放到了这里。

    This short note describes and proves a connectedness property which was introduced in Blocher et al. [2023] in the context of data depth functions for partial orders. The connectedness property gives a structural insight into union-free generic sets. These sets, presented in Blocher et al. [2023], are defined by using a closure operator on the set of all partial orders which naturally appears within the theory of formal concept analysis. In the language of formal concept analysis, the property of connectedness can be vividly proven. However, since within Blocher et al. [2023] we did not discuss formal concept analysis, we outsourced the proof to this note.
    
[^74]: 结合编码本和GPT-3支持定性分析的大语言模型

    Supporting Qualitative Analysis with Large Language Models: Combining Codebook with GPT-3 for Deductive Coding. (arXiv:2304.10548v1 [cs.CL])

    [http://arxiv.org/abs/2304.10548](http://arxiv.org/abs/2304.10548)

    本研究探讨了使用大型语言模型来支持定性分析中的演绎编码。通过结合GPT-3和专家编写的编码本，研究人员成功地实现了与专家编码结果相近的标记结果，并且还允许进行高效和有效的编码本优化。

    

    对文本内容进行定性分析通过给数据打上标签揭示了丰富而有价值的信息。然而，处理大型数据集时，这个过程往往需要耗费大量人力资源。虽然最近的基于人工智能的工具展示了其实用性，但研究人员可能无法获得现成的人工智能资源和技术，更不必说挑战那些任务特定模型的有限泛化能力了。在本研究中，我们探讨了在支持演绎编码的情况下，使用大型语言模型（LLM）的可能性。演绎编码是定性分析的主要类别之一，研究人员使用预先确定的编码本将数据标记到一组固定的编码中。我们发现，使用基于好奇心驱动的问题编码任务作为案例研究，通过将GPT-3与专家制定的编码本相结合，我们的方法与专家编码结果实现了公平到相当大的一致性，并允许有效地进行编码本的优化。我们的研究发现结合LLM和演绎编码是定性分析的一个有前途的方向，并具有潜在的实践意义。

    Qualitative analysis of textual contents unpacks rich and valuable information by assigning labels to the data. However, this process is often labor-intensive, particularly when working with large datasets. While recent AI-based tools demonstrate utility, researchers may not have readily available AI resources and expertise, let alone be challenged by the limited generalizability of those task-specific models. In this study, we explored the use of large language models (LLMs) in supporting deductive coding, a major category of qualitative analysis where researchers use pre-determined codebooks to label the data into a fixed set of codes. Instead of training task-specific models, a pre-trained LLM could be used directly for various tasks without fine-tuning through prompt learning. Using a curiosity-driven questions coding task as a case study, we found, by combining GPT-3 with expert-drafted codebooks, our proposed approach achieved fair to substantial agreements with expert-coded resu
    
[^75]: 生成模型的设计空间

    The Design Space of Generative Models. (arXiv:2304.10547v1 [cs.AI])

    [http://arxiv.org/abs/2304.10547](http://arxiv.org/abs/2304.10547)

    本文探索开发一个AI模型设计空间的含义，提出两个设计空间与生成AI模型相关：第一个考虑HCI如何影响生成模型;第二个考虑生成模型如何影响HCI。

    

    Card等人的经典论文"输入设备的设计空间"建立了设计空间作为HCI分析和发明工具的价值。我们认为，为新兴的预训练生成AI模型开发设计空间是支持它们融入以人为中心的系统和实践所必需的。我们通过提出与生成AI模型相关的两个设计空间来探讨开发AI模型设计空间的含义：第一个考虑HCI如何影响生成模型（即模型的界面），第二个考虑生成模型如何影响HCI（即模型作为HCI原型材料）。

    Card et al.'s classic paper "The Design Space of Input Devices" established the value of design spaces as a tool for HCI analysis and invention. We posit that developing design spaces for emerging pre-trained, generative AI models is necessary for supporting their integration into human-centered systems and practices. We explore what it means to develop an AI model design space by proposing two design spaces relating to generative AI models: the first considers how HCI can impact generative models (i.e., interfaces for models) and the second considers how generative models can impact HCI (i.e., models as an HCI prototyping material).
    
[^76]: 向着人类和机器科学理解的基准迈进

    Towards a Benchmark for Scientific Understanding in Humans and Machines. (arXiv:2304.10327v1 [cs.AI])

    [http://arxiv.org/abs/2304.10327](http://arxiv.org/abs/2304.10327)

    该论文提出了一个框架来创建衡量人类和人工智能科学理解的基准。他们使用了行为观念，提出了一组问题以衡量不同水平的科学理解。这个框架可以帮助评估和比较不同水平和方法的科学理解。

    

    科学理解是科学的基本目标，它使我们能够解释世界。目前还没有好的方法来衡量代理人的科学理解，无论它们是人类还是人工智能系统。缺乏清晰的基准，难以评估和比较不同水平和方法的科学理解。在此路线图中，我们提出了一个框架，利用科学哲学工具创建科学理解的基准。我们采用行为观念，认为真正的理解应该被认为是执行某些任务的能力。我们通过考虑一组问题来扩展这个概念，这些问题可以衡量不同水平的科学理解，包括信息检索，安排信息以生成解释的能力以及在不同情况下推断事物会有哪些不同。Scientific Understanding Benchmark（SUB）由

    Scientific understanding is a fundamental goal of science, allowing us to explain the world. There is currently no good way to measure the scientific understanding of agents, whether these be humans or Artificial Intelligence systems. Without a clear benchmark, it is challenging to evaluate and compare different levels of and approaches to scientific understanding. In this Roadmap, we propose a framework to create a benchmark for scientific understanding, utilizing tools from philosophy of science. We adopt a behavioral notion according to which genuine understanding should be recognized as an ability to perform certain tasks. We extend this notion by considering a set of questions that can gauge different levels of scientific understanding, covering information retrieval, the capability to arrange information to produce an explanation, and the ability to infer how things would be different under different circumstances. The Scientific Understanding Benchmark (SUB), which is formed by 
    
[^77]: 基于视觉的着陆数据集-- LARD（Landing Approach Runway Detection Dataset）

    LARD -- Landing Approach Runway Detection -- Dataset for Vision Based Landing. (arXiv:2304.09938v1 [cs.CV])

    [http://arxiv.org/abs/2304.09938](http://arxiv.org/abs/2304.09938)

    LARD数据集是用于着陆和进场阶段的跑道检测任务的高质量航拍图像数据集。它由大量合成图像和一些人工标注的实际着陆镜头图像组成，同时还提供了生成器以产生此类合成图像并自动注释跑道拐角点。

    

    随着对自主系统的兴趣不断增长，收集足够且代表性的真实世界数据成为一个关键挑战。尽管航空航天领域的自主着陆系统具有强烈的实用和商业价值，但缺乏开源的航空影像数据集。为了解决这一问题，我们提出了一个高质量的航拍图像数据集-LARD，用于着陆和进场阶段的跑道检测任务。数据集大部分由合成图像组成，但我们还提供了人工标注的实际着陆镜头图像，以扩展检测任务到更现实的场景。此外，我们提供了生成器，可以产生这样的合成前视图像，并通过几何变换实现跑道拐角点的自动注释。该数据集为进一步研究，如数据集质量分析或开发模型应对检测任务，铺平了道路。

    As the interest in autonomous systems continues to grow, one of the major challenges is collecting sufficient and representative real-world data. Despite the strong practical and commercial interest in autonomous landing systems in the aerospace field, there is a lack of open-source datasets of aerial images. To address this issue, we present a dataset-lard-of high-quality aerial images for the task of runway detection during approach and landing phases. Most of the dataset is composed of synthetic images but we also provide manually labelled images from real landing footages, to extend the detection task to a more realistic setting. In addition, we offer the generator which can produce such synthetic front-view images and enables automatic annotation of the runway corners through geometric transformations. This dataset paves the way for further research such as the analysis of dataset quality or the development of models to cope with the detection tasks. Find data, code and more up-to
    
[^78]: 通过保留谱的数据压缩加速支持向量聚类

    Accelerate Support Vector Clustering via Spectrum-Preserving Data Compression?. (arXiv:2304.09868v1 [cs.LG])

    [http://arxiv.org/abs/2304.09868](http://arxiv.org/abs/2304.09868)

    本文介绍了一种通过保留谱的数据压缩来加速支持向量聚类的方法，可以显著提高聚类速度而不牺牲聚类质量。

    

    支持向量聚类是一种重要的聚类方法，但是由于其计算昂贵的簇分配步骤，它面临着可伸缩性问题。在本文中，我们通过保留谱的数据压缩来加速支持向量聚类。具体而言，我们将原始数据集压缩成少量谱表示的聚合数据点，然后在压缩后的数据集上执行标准的支持向量聚类，最后将压缩数据集的聚类结果映射回原始数据集以发现簇。我们在真实数据集上的大量实验结果表明，相较于标准支持向量聚类，我们的方法大大提高了速度，而不会损失聚类质量。

    Support vector clustering is an important clustering method. However, it suffers from a scalability issue due to its computational expensive cluster assignment step. In this paper we accelertate the support vector clustering via spectrum-preserving data compression. Specifically, we first compress the original data set into a small amount of spectrally representative aggregated data points. Then, we perform standard support vector clustering on the compressed data set. Finally, we map the clustering results of the compressed data set back to discover the clusters in the original data set. Our extensive experimental results on real-world data set demonstrate dramatically speedups over standard support vector clustering without sacrificing clustering quality.
    
[^79]: MATURE-HEALTH: MAndatory FeaTURE选择的健康推荐系统

    MATURE-HEALTH: HEALTH Recommender System for MAndatory FeaTURE choices. (arXiv:2304.09099v1 [cs.IR])

    [http://arxiv.org/abs/2304.09099](http://arxiv.org/abs/2304.09099)

    该论文提出和实施了一个名为MATURE-HEALTH的健康推荐系统，该系统能够预测电解质不平衡并推荐营养平衡的食物，从而增加早期检测疾病的机会并防止健康进一步恶化。

    

    平衡电解质对于人体器官的适当功能至关重要和必不可少，因为电解质失衡可能是潜在病理生理学发展的指示。高效监测电解质失衡不仅可以增加疾病早期检测的机会，而且可以通过严格遵循营养控制饮食以平衡电解质从而防止健康进一步恶化。本研究提出并实施了一个推荐系统MATURE Health，该系统预测血液中必需电解质和其他物质的不平衡，然后推荐含有平衡营养的食物，以避免电解质不平衡的发生。该模型考虑到用户最近的实验室结果和每日食物摄入量来预测电解质不平衡。MATURE Health依赖于MATURE Food算法推荐食物，后者仅推荐那些

    Balancing electrolytes is utmost important and essential for appropriate functioning of organs in human body as electrolytes imbalance can be an indication of the development of underlying pathophysiology. Efficient monitoring of electrolytes imbalance not only can increase the chances of early detection of disease, but also prevents the further deterioration of the health by strictly following nutrient controlled diet for balancing the electrolytes post disease detection. In this research, a recommender system MATURE Health is proposed and implemented, which predicts the imbalance of mandatory electrolytes and other substances presented in blood and recommends the food items with the balanced nutrients to avoid occurrence of the electrolytes imbalance. The proposed model takes user most recent laboratory results and daily food intake into account to predict the electrolytes imbalance. MATURE Health relies on MATURE Food algorithm to recommend food items as latter recommends only those
    
[^80]: 负责任人工智能的实施：伦理方面的紧张和权衡

    Implementing Responsible AI: Tensions and Trade-Offs Between Ethics Aspects. (arXiv:2304.08275v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2304.08275](http://arxiv.org/abs/2304.08275)

    本文讨论了负责任人工智能伦理原则之间的紧张关系和权衡，并提出一个目录以帮助人们提高对相互作用的认识。

    

    针对人工智能/机器学习系统的滥用和不当使用引起的担忧，已经提出了许多负责任人工智能的伦理原则。这些准则的基本方面包括隐私、准确性、公平性、稳健性、可解释性和透明度。然而，这些方面之间存在潜在的紧张关系，这给寻求遵循这些原则的AI/ML开发者带来了困难。例如，提高AI/ML系统的准确性可能会降低其可解释性。本文旨在汇编和讨论10个突出的紧张关系、权衡和其他基本方面之间的相互作用，以便在持续努力将这些原则转化为实践的过程中，提高对可能出现的伦理原则方面之间相互作用的认识，并通过在广泛文献中的支持进行双面互动的重点讨论。这个目录对于提高人们对伦理准则方面之间可能相互作用的认识以及促进设计人员和开发人员做出有充分依据的判断可能有所帮助。

    Many sets of ethics principles for responsible AI have been proposed to allay concerns about misuse and abuse of AI/ML systems. The underlying aspects of such sets of principles include privacy, accuracy, fairness, robustness, explainability, and transparency. However, there are potential tensions between these aspects that pose difficulties for AI/ML developers seeking to follow these principles. For example, increasing the accuracy of an AI/ML system may reduce its explainability. As part of the ongoing effort to operationalise the principles into practice, in this work we compile and discuss a catalogue of 10 notable tensions, trade-offs and other interactions between the underlying aspects. We primarily focus on two-sided interactions, drawing on support spread across a diverse literature. This catalogue can be helpful in raising awareness of the possible interactions between aspects of ethics principles, as well as facilitating well-supported judgements by the designers and develo
    
[^81]: 中文开放式指令广义语言模型：初步发布

    Chinese Open Instruction Generalist: A Preliminary Release. (arXiv:2304.07987v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.07987](http://arxiv.org/abs/2304.07987)

    本论文旨在通过适应不同子任务的固有特性，创建一个中文指令数据集，以填补指令调整技术在中文语言领域的空白。

    

    指令调整被广泛认为是构建广义语言模型的关键技术，随着InstructGPT和ChatGPT的发布，它已经引起了研究人员和公众的关注。尽管英语为基础的大规模语言模型取得了令人瞩目的进展，但是还未探索英语为基础的语言模型在多语任务上是否可以像英语任务那样通过精心设计的指令调整来执行，以及我们如何构建所需的语料库进行调整。为填补这一空白，我们提出了一个项目，试图通过适应4个子任务的固有特性，采用各种方法创建一个中文指令数据集。我们收集了约20万个中文指令调整样本，并进行了人工检查以确保高质量。我们还总结了现有的英文和中文指令语料库，并对一些潜在的应用进行了简要描述。

    Instruction tuning is widely recognized as a key technique for building generalist language models, which has attracted the attention of researchers and the public with the release of InstructGPT~\citep{ouyang2022training} and ChatGPT\footnote{\url{https://chat.openai.com/}}. Despite impressive progress in English-oriented large-scale language models (LLMs), it is still under-explored whether English-based foundation LLMs can perform similarly on multilingual tasks compared to English tasks with well-designed instruction tuning and how we can construct the corpora needed for the tuning.  To remedy this gap, we propose the project as an attempt to create a Chinese instruction dataset by various methods adapted to the intrinsic characteristics of 4 sub-tasks. We collect around 200k Chinese instruction tuning samples, which have been manually checked to guarantee high quality. We also summarize the existing English and Chinese instruction corpora and briefly describe some potential applic
    
[^82]: TPU v4：一款支持嵌入式硬件的可重构光学超级计算机用于机器学习

    TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings. (arXiv:2304.01433v1 [cs.AR])

    [http://arxiv.org/abs/2304.01433](http://arxiv.org/abs/2304.01433)

    TPU v4是一款支持嵌入式硬件的可重构光学超级计算机，采用光学电路交换机重新配置互连拓扑，提高规模、可用性、利用率、模块化、部署、安全、功率和性能，它通过SparseCores加速嵌入式模型，性能优越，功耗低。

    

    针对机器学习模型的创新，生产工作负载发生了根本性和迅速的变化。TPU v4是谷歌的第五代面向特定领域架构（DSA），是其第三个用于处理此类机器学习模型的超级计算机。光学电路交换机（OCS）动态重新配置其互连拓扑，以提高规模、可用性、利用率、模块化、部署、安全、功率和性能。部署自2020年以来，TPU v4超级计算机的表现优于TPU v3，同时性能/Watt提高了2.7倍。

    In response to innovations in machine learning (ML) models, production workloads changed radically and rapidly. TPU v4 is the fifth Google domain specific architecture (DSA) and its third supercomputer for such ML models. Optical circuit switches (OCSes) dynamically reconfigure its interconnect topology to improve scale, availability, utilization, modularity, deployment, security, power, and performance; users can pick a twisted 3D torus topology if desired. Much cheaper, lower power, and faster than Infiniband, OCSes and underlying optical components are <5% of system cost and <3% of system power. Each TPU v4 includes SparseCores, dataflow processors that accelerate models that rely on embeddings by 5x-7x yet use only 5% of die area and power. Deployed since 2020, TPU v4 outperforms TPU v3 by 2.1x and improves performance/Watt by 2.7x. The TPU v4 supercomputer is 4x larger at 4096 chips and thus ~10x faster overall, which along with OCS flexibility helps large language models. For sim
    
[^83]: Wasserstein自编码MDPs：具有多方保证的高效RL策略正式验证

    Wasserstein Auto-encoded MDPs: Formal Verification of Efficiently Distilled RL Policies with Many-sided Guarantees. (arXiv:2303.12558v1 [cs.LG])

    [http://arxiv.org/abs/2303.12558](http://arxiv.org/abs/2303.12558)

    该论文提出了一种名为WAE-MDP的潜在空间模型，可以从任何RL策略中提取形式可验证控制器，并且具有平衡控制性能和安全之间的效果和解决一些学习缺陷的多方保证。

    

    尽管深度强化学习（DRL）有许多成功案例，但通过这些先进技术学习的决策者在安全关键场景中的大规模部署受到正式保证不足的阻碍。变分马尔可夫决策过程（VAE-MDPs）是离散潜在空间模型，提供了从任何RL策略中提取形式可验证控制器的可靠框架。虽然相关保证涵盖了实际问题的满足性和安全性等方面，但VAE方法因缺乏抽象和表示保证以支持潜在最优化而遭受多种学习缺陷（后验崩塌，学习速度慢，动力学估计不良）。我们引入了Wasserstein自编码MDP（WAE-MDP），这是一种潜在空间模型，通过最小化执行原始策略的智能体行为和提取出的策略之间的最优转运的惩罚形式来解决这些问题。我们证明了所提出的方法可以有利于控制性能和安全之间的平衡，同时减轻了上述的学习问题。我们推导了关于性能和安全的理论保证，并在不同的RL基准上验证了该方法。

    Although deep reinforcement learning (DRL) has many success stories, the large-scale deployment of policies learned through these advanced techniques in safety-critical scenarios is hindered by their lack of formal guarantees. Variational Markov Decision Processes (VAE-MDPs) are discrete latent space models that provide a reliable framework for distilling formally verifiable controllers from any RL policy. While the related guarantees address relevant practical aspects such as the satisfaction of performance and safety properties, the VAE approach suffers from several learning flaws (posterior collapse, slow learning speed, poor dynamics estimates), primarily due to the absence of abstraction and representation guarantees to support latent optimization. We introduce the Wasserstein auto-encoded MDP (WAE-MDP), a latent space model that fixes those issues by minimizing a penalized form of the optimal transport between the behaviors of the agent executing the original policy and the disti
    
[^84]: 用量子退火器解决现实世界中的装箱问题的混合方法

    Hybrid Approach for Solving Real-World Bin Packing Problem Instances Using Quantum Annealers. (arXiv:2303.01977v2 [cs.ET] UPDATED)

    [http://arxiv.org/abs/2303.01977](http://arxiv.org/abs/2303.01977)

    该研究提出了一个量子-经典混合框架，名为Q4RealBPP，可以考虑真实世界的限制特征，解决三维装箱问题，支持工业和物流行业的需求。

    

    高效地将物品装入箱子是一项常见的日常任务，也被称为“装箱问题”。由于行业和物流领域的广泛关注，它在人工智能领域得到了广泛研究。自几十年以来，许多变种已被提出，其中三维装箱问题是最接近实际用例的一个。我们介绍了一个混合的量子-经典框架，用于解决考虑不同现实特征的三维装箱问题（Q4RealBPP），例如：（i）包装和箱子尺寸，（ii）超重限制，（iii）物品类别之间的亲和力和（iv）物品排序的偏好。Q4RealBPP允许解决考虑到工业和物流部门广泛评价的限制的3dBPP的现实导向的实例。

    Efficient packing of items into bins is a common daily task. Known as Bin Packing Problem, it has been intensively studied in the field of artificial intelligence, thanks to the wide interest from industry and logistics. Since decades, many variants have been proposed, with the three-dimensional Bin Packing Problem as the closest one to real-world use cases. We introduce a hybrid quantum-classical framework for solving real-world three-dimensional Bin Packing Problems (Q4RealBPP), considering different realistic characteristics, such as: i) package and bin dimensions, ii) overweight restrictions, iii) affinities among item categories and iv) preferences for item ordering. Q4RealBPP permits the solving of real-world oriented instances of 3dBPP, contemplating restrictions well appreciated by industrial and logistics sectors.
    
[^85]: Fairguard: 在智慧城市中利用基于逻辑的公正规则

    Fairguard: Harness Logic-based Fairness Rules in Smart Cities. (arXiv:2302.11137v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.11137](http://arxiv.org/abs/2302.11137)

    本文提出了一种基于时间逻辑的公正智慧城市政策调整和生成方法Fairguard，通过两个阶段的静态生成和动态调节，缓解由多种数据和算法偏见导致的不公正预测结果。

    

    智慧城市运行在计算预测框架上，收集、整合和利用大规模传感器网络的数据。然而，这些框架容易受到多种数据和算法偏见的影响，这经常导致不公正的预测结果。本文首先通过研究田纳西州查塔努加的真实城市数据，展示了偏见在微观层面上在时间和空间上仍然存在。为了缓解这种偏见问题，我们引入了Fairguard，这是一种基于微观层面时间逻辑的方法，用于在复杂的时间空间域中进行公正的智慧城市政策调整和生成。Fairguard框架由两个阶段组成：首先，我们开发了一个静态生成器，能够通过最小化所选属性之间的相关性，基于时间逻辑条件来减少数据偏见。然后，为了确保预测算法的公正性，我们设计了一个动态组件来调节预测结果，并利用逻辑规则生成未来的公正预测。

    Smart cities operate on computational predictive frameworks that collect, aggregate, and utilize data from large-scale sensor networks. However, these frameworks are prone to multiple sources of data and algorithmic bias, which often lead to unfair prediction results. In this work, we first demonstrate that bias persists at a micro-level both temporally and spatially by studying real city data from Chattanooga, TN. To alleviate the issue of such bias, we introduce Fairguard, a micro-level temporal logic-based approach for fair smart city policy adjustment and generation in complex temporal-spatial domains. The Fairguard framework consists of two phases: first, we develop a static generator that is able to reduce data bias based on temporal logic conditions by minimizing correlations between selected attributes. Then, to ensure fairness in predictive algorithms, we design a dynamic component to regulate prediction results and generate future fair predictions by harnessing logic rules. E
    
[^86]: AI对抗AI：在社交媒体上打击机器生成的虚假餐厅评论

    Combat AI With AI: Counteract Machine-Generated Fake Restaurant Reviews on Social Media. (arXiv:2302.07731v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.07731](http://arxiv.org/abs/2302.07731)

    本文针对机器生成的虚假评论提出了一种用高质量餐厅评论生成虚假评论并微调GPT输出检测器的方法，该方法预测虚假评论的性能优于现有解决方案。同时，我们还探索了预测非精英评论的模型，并在几个维度上对这些评论进行分析，此类机器生成的虚假评论是社交媒体平台面临的持续挑战。

    

    最近生成模型（如GPT）的发展使得以更低的成本制造出难以区分的虚假顾客评论，从而对社交媒体平台检测这些机器生成的虚假评论造成挑战。本文提出利用Yelp验证的高质量的精英餐厅评论来生成OpenAI GPT评论生成器的虚假评论，并最终微调GPT输出检测器来预测明显优于现有解决方案的虚假评论。我们进一步将模型应用于预测非精英评论，并在几个维度（如评论、用户和餐厅特征以及写作风格）上识别模式。我们展示了社交媒体平台正在不断面临机器生成的虚假评论的挑战，尽管他们可能实施检测系统以过滤出可疑的评论。

    Recent advances in generative models such as GPT may be used to fabricate indistinguishable fake customer reviews at a much lower cost, thus posing challenges for social media platforms to detect these machine-generated fake reviews. We propose to leverage the high-quality elite restaurant reviews verified by Yelp to generate fake reviews from the OpenAI GPT review creator and ultimately fine-tune a GPT output detector to predict fake reviews that significantly outperform existing solutions. We further apply the model to predict non-elite reviews and identify the patterns across several dimensions, such as review, user and restaurant characteristics, and writing style. We show that social media platforms are continuously challenged by machine-generated fake reviews, although they may implement detection systems to filter out suspicious reviews.
    
[^87]: 反升级与概括：一份调查报告

    Anti-unification and Generalization: A Survey. (arXiv:2302.00277v3 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2302.00277](http://arxiv.org/abs/2302.00277)

    反升级或概括是归纳推理中使用的基本操作，是定理证明的双重操作之一。该调查报告对反升级的研究和应用进行了系统归纳和总结。

    

    反升级（AU）又称概括，是归纳推理中使用的基本操作，是定理证明基础上的双重操作之一。 AI和相关社区对AU的兴趣日益增长，但没有系统研究该概念，也没有现有工作的调查，调查往往会采用特定于应用的方法，而这些方法可能已经被现有方法覆盖。我们提供了第一份有关AU研究及其应用的调查报告，以及一种将现有和未来发展分类的通用框架。

    Anti-unification (AU), also known as generalization, is a fundamental operation used for inductive inference and is the dual operation to unification, an operation at the foundation of theorem proving. Interest in AU from the AI and related communities is growing, but without a systematic study of the concept, nor surveys of existing work, investigations7 often resort to developing application-specific methods that may be covered by existing approaches. We provide the first survey of AU research and its applications, together with a general framework for categorizing existing and future developments.
    
[^88]: PyExperimenter：简单地分发实验并跟踪结果。

    PyExperimenter: Easily distribute experiments and track results. (arXiv:2301.06348v2 [cs.DC] UPDATED)

    [http://arxiv.org/abs/2301.06348](http://arxiv.org/abs/2301.06348)

    PyExperimenter是一个专门为算法实证研究设计的工具，能够简化实验设置、执行、文档编写与结果评估，节省大量手动工作。

    

    PyExperimenter是一个工具，旨在简化算法实证研究的设置、文档编写、执行和随后的结果评估，并特别设计为显著减少所涉及的手动工作。它旨在被人工智能领域的研究人员使用，但并不仅限于此领域。

    PyExperimenter is a tool to facilitate the setup, documentation, execution, and subsequent evaluation of results from an empirical study of algorithms and in particular is designed to reduce the involved manual effort significantly. It is intended to be used by researchers in the field of artificial intelligence, but is not limited to those.
    
[^89]: 基于任务相似度元学习加速多目标非分层超参数最优化的树形结构Parzen估计

    Speeding up Multi-objective Non-hierarchical Hyperparameter Optimization by Task Similarity-Based Meta-Learning for the Tree-structured Parzen Estimator. (arXiv:2212.06751v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.06751](http://arxiv.org/abs/2212.06751)

    本文提出了一种基于任务相似度元学习的方法来加速树形结构Parzen估计中的多目标非分层超参数最优化，实现了最先进的性能。

    

    超参数优化是提高深度学习性能的关键步骤。实践者通常面临多个方面的权衡，如准确性和延迟时间。在深度学习的高计算需求和对高效超参数优化的不断增长需求下，加速多目标优化变得越来越重要。本文将TPE的收购函数扩展到元学习设置中，使用由任务之间顶级域之间的重叠度定义的任务相似性。我们也从理论上分析并解决了任务相似性的局限性。在实验中，我们展示了我们的方法在表格HPO基准上加速了MO-TPE，并获得了最先进的性能。我们的方法还通过赢得AutoML 2022来得到外部验证。

    Hyperparameter optimization (HPO) is a vital step in improving performance in deep learning (DL). Practitioners are often faced with the trade-off between multiple criteria, such as accuracy and latency. Given the high computational needs of DL and the growing demand for efficient HPO, the acceleration of multi-objective (MO) optimization becomes ever more important. Despite the significant body of work on meta-learning for HPO, existing methods are inapplicable to MO tree-structured Parzen estimator (MO-TPE), a simple yet powerful MO-HPO algorithm. In this paper, we extend TPE's acquisition function to the meta-learning setting using a task similarity defined by the overlap of top domains between tasks. We also theoretically analyze and address the limitations of our task similarity. In the experiments, we demonstrate that our method speeds up MO-TPE on tabular HPO benchmarks and attains state-of-the-art performance. Our method was also validated externally by winning the AutoML 2022 
    
[^90]: 从CNN到基于复小波的平移不变双模型

    From CNNs to Shift-Invariant Twin Models Based on Complex Wavelets. (arXiv:2212.00394v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.00394](http://arxiv.org/abs/2212.00394)

    论文提出了一种消除OCV（Aliasing）的方法，该方法基于复数卷积，同时采用Gabor样式的卷积核，可以提高卷积神经网络的分类准确性。

    

    我们提出了一种新颖的抗混叠方法来增加卷积神经网络中的平移不变性和预测准确性。具体来说，我们用“复值卷积+模运算”（$\mathbb{C}$Mod）代替第一层的“实值卷积+最大池化”（$\mathbb{R}$Max），因为它稳定于平移。为了证明我们的方法，我们声称当卷积核是带通和定向的（类似于Gabor滤波器）时，$\mathbb{C}$Mod和$\mathbb{R}$Max产生可比较的输出。在这种情况下，$\mathbb{C}$Mod可以被认为是$\mathbb{R}$Max的稳定替代品。因此，在抗混叠之前，我们强制卷积核采用这种Gabor样式的结构。相应的架构称为数学双模型，因为它使用一个明确定义的数学运算符来模拟原始的自由训练模型的行为。我们的抗混叠方法在Imagenet和CIFAR-10分类任务上实现了比之前更高的准确性。

    We propose a novel antialiasing method to increase shift invariance and prediction accuracy in convolutional neural networks. Specifically, we replace the first-layer combination "real-valued convolutions + max pooling" ($\mathbb{R}$Max) by "complex-valued convolutions + modulus" ($\mathbb{C}$Mod), which is stable to translations. To justify our approach, we claim that $\mathbb{C}$Mod and $\mathbb{R}$Max produce comparable outputs when the convolution kernel is band-pass and oriented (Gabor-like filter). In this context, $\mathbb{C}$Mod can be considered as a stable alternative to $\mathbb{R}$Max. Thus, prior to antialiasing, we force the convolution kernels to adopt such a Gabor-like structure. The corresponding architecture is called mathematical twin, because it employs a well-defined mathematical operator to mimic the behavior of the original, freely-trained model. Our antialiasing approach achieves superior accuracy on ImageNet and CIFAR-10 classification tasks, compared to prior 
    
[^91]: c-TPE:基于树形结构的带不等式约束的帕捷斯特估计器用于昂贵超参数优化

    c-TPE: Tree-structured Parzen Estimator with Inequality Constraints for Expensive Hyperparameter Optimization. (arXiv:2211.14411v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.14411](http://arxiv.org/abs/2211.14411)

    本文提出了约束TPE（c-TPE）方法，是树形Parzen估计器（TPE）的扩展，可有效处理在性能要求之上施加的约束限制，实验证明在81个昂贵的HPO设置中表现出最佳性能排名。

    

    超参数优化（HPO）对于深度学习算法的强大性能至关重要，实际应用通常会在性能要求之上施加一些限制，例如内存使用或延迟等。在本文中，我们提出了约束TPE（c-TPE），这是广泛使用的多功能贝叶斯优化方法——树形Parzen估计器（TPE）的扩展，以处理这些约束。我们提出的扩展不仅是简单地将现有收益函数和原始TPE组合起来，而是包括修改来解决导致性能不佳的问题。我们从经验和理论上深入分析这些修改，提供了有关它们如何有效地克服这些挑战的见解。在实验中，我们证明了c-TPE在81个昂贵的HPO设置中表现出最佳的平均排名性能，具有统计显着性。

    Hyperparameter optimization (HPO) is crucial for strong performance of deep learning algorithms and real-world applications often impose some constraints, such as memory usage, or latency on top of the performance requirement. In this work, we propose constrained TPE (c-TPE), an extension of the widely-used versatile Bayesian optimization method, tree-structured Parzen estimator (TPE), to handle these constraints. Our proposed extension goes beyond a simple combination of an existing acquisition function and the original TPE, and instead includes modifications that address issues that cause poor performance. We thoroughly analyze these modifications both empirically and theoretically, providing insights into how they effectively overcome these challenges. In the experiments, we demonstrate that c-TPE exhibits the best average rank performance among existing methods with statistical significance on 81 expensive HPO settings.
    
[^92]: 有效经验回放的事件表

    Event Tables for Efficient Experience Replay. (arXiv:2211.00576v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.00576](http://arxiv.org/abs/2211.00576)

    本文提出了一种叫做SSET的经验回放采样方法，将缓冲区分为事件表，并采用现有的优先采样策略，大大提高了学习速度和稳定性。

    

    经验回放(ER)是许多深度强化学习(RL)系统的关键组成部分。然而，从ER缓冲区进行统一采样可能导致缓慢的收敛和不稳定的渐近行为。本文介绍了事件表的分层采样（SSET），将ER缓冲区分为事件表，每个事件表捕获了最优行为的重要子序列。我们证明相对于传统的统一缓冲区方法，这种方法具有理论优势，并将SSET与现有的优先采样策略结合起来，进一步提高了学习速度和稳定性。在具有挑战性的MiniGrid领域，基准RL环境以及高保真度的汽车赛车模拟器中的实证结果表明了SSET相对于现有ER缓冲区采样方法的优势和多功能性。

    Experience replay (ER) is a crucial component of many deep reinforcement learning (RL) systems. However, uniform sampling from an ER buffer can lead to slow convergence and unstable asymptotic behaviors. This paper introduces Stratified Sampling from Event Tables (SSET), which partitions an ER buffer into Event Tables, each capturing important subsequences of optimal behavior. We prove a theoretical advantage over the traditional monolithic buffer approach and combine SSET with an existing prioritized sampling strategy to further improve learning speed and stability. Empirical results in challenging MiniGrid domains, benchmark RL environments, and a high-fidelity car racing simulator demonstrate the advantages and versatility of SSET over existing ER buffer sampling approaches.
    
[^93]: 深度强化学习智能体的自适应补丁觅食行为研究

    Adaptive patch foraging in deep reinforcement learning agents. (arXiv:2210.08085v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2210.08085](http://arxiv.org/abs/2210.08085)

    本文针对深度强化学习智能体的生态补丁觅食任务，首次证明机器学习智能体可以学习自适应地进行补丁觅食，并且逼近最优行为，并在智能体的内部出现了类似于非人类灵长类动物觅食的单细胞记录的新现象。

    

    补丁觅食是生物学中研究最广泛的行为优化挑战之一。然而，尽管这种行为优化问题对于生物智能至关重要，但在人工智能研究中被忽视。本文研究了生态补丁觅食任务中的深度强化学习智能体。本文首次表明，机器学习智能体可以学习自适应地进行补丁觅食，并逼近最优的补丁觅食行为，同时考虑时间折现。最后，我们展示了这些智能体内部出现了类似于非人类灵长类动物觅食的单细胞记录的新现象，这对于生物觅食的神经机制的实验和理论研究具有补充作用。

    Patch foraging is one of the most heavily studied behavioral optimization challenges in biology. However, despite its importance to biological intelligence, this behavioral optimization problem is understudied in artificial intelligence research. Patch foraging is especially amenable to study given that it has a known optimal solution, which may be difficult to discover given current techniques in deep reinforcement learning. Here, we investigate deep reinforcement learning agents in an ecological patch foraging task. For the first time, we show that machine learning agents can learn to patch forage adaptively in patterns similar to biological foragers, and approach optimal patch foraging behavior when accounting for temporal discounting. Finally, we show emergent internal dynamics in these agents that resemble single-cell recordings from foraging non-human primates, which complements experimental and theoretical work on the neural mechanisms of biological foraging. This work suggests 
    
[^94]: GraphMLP：一种用于3D人体姿态估计的图形MLP式架构

    GraphMLP: A Graph MLP-Like Architecture for 3D Human Pose Estimation. (arXiv:2206.06420v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.06420](http://arxiv.org/abs/2206.06420)

    提出了一种名为GraphMLP的图形增强的MLP式架构，它将图形结构纳入MLP模型中，以满足3D人体姿态的领域特定需求，同时允许局部和全局的空间交互作用。在此基础上，还将GraphMLP灵活高效地扩展到视频领域，并成功地进行了时间动力学的建模。

    

    现代多层感知器（MLP）模型已经展现出在没有自我注意力的情况下学习视觉表示方面的竞争性结果，然而，现有的MLP模型并不擅长捕捉局部细节，也缺乏有关人体构型的先验知识，这限制了它们用于骨骼表示学习的建模能力。为了解决这些问题，我们提出了一种简单而有效的图形增强的MLP式架构，称为GraphMLP，它结合了MLP和图形卷积网络（GCN）在全局-局部-图形统一架构中用于3D人体姿态估计。GraphMLP将人体的图形结构纳入MLP模型中，以满足3D人体姿态的领域特定需求，同时允许局部和全局的空间交互作用。此外，我们提出了将GraphMLP灵活高效地扩展到视频领域，并展示了可以以可忽略的计算代价来有效地建模复杂的时间动力学。

    Modern multi-layer perceptron (MLP) models have shown competitive results in learning visual representations without self-attention. However, existing MLP models are not good at capturing local details and lack prior knowledge of human body configurations, which limits their modeling power for skeletal representation learning. To address these issues, we propose a simple yet effective graph-reinforced MLP-Like architecture, named GraphMLP, that combines MLPs and graph convolutional networks (GCNs) in a global-local-graphical unified architecture for 3D human pose estimation. GraphMLP incorporates the graph structure of human bodies into an MLP model to meet the domain-specific demand of the 3D human pose, while allowing for both local and global spatial interactions. Furthermore, we propose to flexibly and efficiently extend the GraphMLP to the video domain and show that complex temporal dynamics can be effectively modeled in a simple way with negligible computational cost gains in the
    
[^95]: 三维医学图像的翻译一致半监督分割

    Translation Consistent Semi-supervised Segmentation for 3D Medical Images. (arXiv:2203.14523v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2203.14523](http://arxiv.org/abs/2203.14523)

    本论文提出了一种名为TraCoCo的半监督学习方法，通过改变输入数据视图的不同空间上下文来扰动训练，从而使模型能够从可视化对象中学习分割模式，实现了三维医学图像的翻译一致半监督分割。

    

    三维医学图像分割的方法已经成功，但其依赖于涵盖大量体素的注释数据，这是一个需要解决的劣势，因为获取这种注释的成本很高。半监督学习（SSL）通过使用大量未标记的数据集和少量标记的数据集来训练模型来解决这个问题。最成功的SSL方法基于一致性学习，该方法通过最小化从未标记数据的扰动视图获得的模型响应之间的距离来实现。这些扰动通常会保持视图之间的空间输入上下文相当一致，这可能会使模型从空间输入上下文中学习分割模式，而不是从分割对象本身中学习。在本文中，我们介绍了翻译一致协同训练（TraCoCo），这是一种一致性学习SSL方法，它通过改变不同的空间输入上下文来扰动输入数据视图，使模型能够从可视化对象中学习分割模式。

    3D medical image segmentation methods have been successful, but their dependence on large amounts of voxel-level annotated data is a disadvantage that needs to be addressed given the high cost to obtain such annotation. Semi-supervised learning (SSL) solve this issue by training models with a large unlabelled and a small labelled dataset. The most successful SSL approaches are based on consistency learning that minimises the distance between model responses obtained from perturbed views of the unlabelled data. These perturbations usually keep the spatial input context between views fairly consistent, which may cause the model to learn segmentation patterns from the spatial input contexts instead of the segmented objects. In this paper, we introduce the Translation Consistent Co-training (TraCoCo) which is a consistency learning SSL method that perturbs the input data views by varying their spatial input context, allowing the model to learn segmentation patterns from visual objects. Fur
    
[^96]: 图关系领域适应

    Graph-Relational Domain Adaptation. (arXiv:2202.03628v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.03628](http://arxiv.org/abs/2202.03628)

    本研究使用领域图对领域相邻性进行编码，放宽了领域适应的统一对齐方法，实现了非平凡的对齐，并成功地融合了领域信息。

    

    现有的领域适应方法往往将每个领域等同对待并完美对齐，忽略了不同领域之间的拓扑结构，因此对于相邻领域可能有利，但对于远离领域则可能无益。本文通过使用领域图对领域相邻性进行编码，例如以美国不同州为领域创建的状态图，使得领域可以根据图结构灵活对齐，从而放宽了这种统一的对齐方法。我们使用一种新的图判别器将现有的对抗学习框架进行了推广，并使用编码条件图嵌入。理论分析表明，在均衡状态下，当图是一个团时，我们的方法会恢复经典的领域适应方法，并为其他类型的图实现了非平凡的对齐。实证结果表明，我们的方法可以成功地推广统一的对齐方法，并自然地融合了领域信息。

    Existing domain adaptation methods tend to treat every domain equally and align them all perfectly. Such uniform alignment ignores topological structures among different domains; therefore it may be beneficial for nearby domains, but not necessarily for distant domains. In this work, we relax such uniform alignment by using a domain graph to encode domain adjacency, e.g., a graph of states in the US with each state as a domain and each edge indicating adjacency, thereby allowing domains to align flexibly based on the graph structure. We generalize the existing adversarial learning framework with a novel graph discriminator using encoding-conditioned graph embeddings. Theoretical analysis shows that at equilibrium, our method recovers classic domain adaptation when the graph is a clique, and achieves non-trivial alignment for other types of graphs. Empirical results show that our approach successfully generalizes uniform alignment, naturally incorporates domain information represented b
    
[^97]: 来源多元化的自我承认技术债务的自动识别

    Automatic Identification of Self-Admitted Technical Debt from Four Different Sources. (arXiv:2202.02387v5 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2202.02387](http://arxiv.org/abs/2202.02387)

    本文提出了一种整合多种来源的自动SATD识别方法，能够有效地找到代码/设计债务、需求债务、文档债务和测试债务。

    

    技术债务是指为达到短期目标而采取捷径，而牺牲软件系统的长期可维护性和可发展性。大部分技术债务是由开发人员自己明确报告的；这通常被称为自我承认的技术债务（SATD）。以往的工作重点是从源代码注释和问题跟踪器中识别SATD。然而，目前没有可自动从其他来源（如提交消息和拉请求）或通过多种来源组合自动识别SATD的方法。因此，我们提出并评估了一种自动SATD识别方法，该方法整合了四个来源：源代码注释、提交消息、拉请求和问题跟踪系统。我们的研究发现，我们的方法优于基准方法，在识别四种类型的SATD（即代码/设计债务、需求债务、文档债务和测试债务）时达到了平均F1得分0.611。

    Technical debt refers to taking shortcuts to achieve short-term goals while sacrificing the long-term maintainability and evolvability of software systems. A large part of technical debt is explicitly reported by the developers themselves; this is commonly referred to as Self-Admitted Technical Debt or SATD. Previous work has focused on identifying SATD from source code comments and issue trackers. However, there are no approaches available for automatically identifying SATD from other sources such as commit messages and pull requests, or by combining multiple sources. Therefore, we propose and evaluate an approach for automated SATD identification that integrates four sources: source code comments, commit messages, pull requests, and issue tracking systems. Our findings show that our approach outperforms baseline approaches and achieves an average F1-score of 0.611 when detecting four types of SATD (i.e., code/design debt, requirement debt, documentation debt, and test debt) from the 
    
[^98]: 基于认知的增量漂移概念学习

    Cognitively Inspired Learning of Incremental Drifting Concepts. (arXiv:2110.04662v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.04662](http://arxiv.org/abs/2110.04662)

    本研究提出了一种基于神经系统学习机制的计算模型，使深度神经网络能够在连续学习环境中学习新概念，并将其学到的知识拓展到新领域。此模型结合多模态分布空间和伪排练记忆机制，可用于克服灾难性遗忘。

    

    人类不断将自己学到的知识拓展到新的领域，并且在学习新的概念时不会对以前学习的经验有任何干扰。相反，机器学习模型在连续的学习环境中表现不佳，因为输入数据的分布会随着时间的推移而变化。受神经系统学习机制的启发，我们开发了一种计算模型，使深度神经网络能够在连续学习环境中学习新概念，并将其学到的知识拓展到新领域。我们依靠并行分布处理理论，在一个多模态分布空间中，用内部数据表示在隐藏网络层中建模抽象概念。同时，我们还利用补充学习系统理论，通过实现伪排练来为模型配备记忆机制，以克服灾难性遗忘。我们的模型可以生成伪数据点进行经验回放和知识积累，这些点将被用作新数据的训练输入。

    Humans continually expand their learned knowledge to new domains and learn new concepts without any interference with past learned experiences. In contrast, machine learning models perform poorly in a continual learning setting, where input data distribution changes over time. Inspired by the nervous system learning mechanisms, we develop a computational model that enables a deep neural network to learn new concepts and expand its learned knowledge to new domains incrementally in a continual learning setting. We rely on the Parallel Distributed Processing theory to encode abstract concepts in an embedding space in terms of a multimodal distribution. This embedding space is modeled by internal data representations in a hidden network layer. We also leverage the Complementary Learning Systems theory to equip the model with a memory mechanism to overcome catastrophic forgetting through implementing pseudo-rehearsal. Our model can generate pseudo-data points for experience replay and accum
    
[^99]: 基于多模态框架的MeToo推文情感分析

    MeToo Tweets Sentiment Analysis Using Multi Modal frameworks. (arXiv:2104.05331v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2104.05331](http://arxiv.org/abs/2104.05331)

    本文使用多个模型，在MeToo运动相关的推文中进行情感分类，并在IEEEMBigMM 2020大赛中获得了第5名的好成绩。

    

    本文介绍了我们针对IEEEMBigMM 2020大挑战赛（BMGC）的方法，用于识别与MeToo运动相关的推文的情感。该模型基于卷积神经网络、双向LSTM和DNN的集成，以进行最终分类。本文旨在提供模型和结果的详细分析。我们的成绩为0.51491，在10个团队中排名第5。

    In this paper, We present our approach for IEEEBigMM 2020, Grand Challenge (BMGC), Identifying senti-ments from tweets related to the MeToo movement. The modelis based on an ensemble of Convolutional Neural Network,Bidirectional LSTM and a DNN for final classification. Thispaper is aimed at providing a detailed analysis of the modeland the results obtained. We have ranked 5th out of 10 teamswith a score of 0.51491
    

