# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction](https://arxiv.org/abs/2404.02905) | VAR重新定义了图像上的自回归学习，通过粗到细的“下一尺度预测”实现快速学习视觉分布并超越了扩散变压器。 |
| [^2] | [Uncovering Bias in Large Vision-Language Models with Counterfactuals](https://arxiv.org/abs/2404.00166) | 通过对输入图像进行反事实变化，我们对不同大规模视觉-语言模型生成的文本进行了研究，以揭示其中的社会偏见。 |
| [^3] | [ITCMA: A Generative Agent Based on a Computational Consciousness Structure](https://arxiv.org/abs/2403.20097) | ITCMA是基于计算意识结构的生成式Agent，通过考虑Agent与环境的互动和推理，增强了LLMs理解隐含指令和应用常识知识的能力，在Alfworld环境中表现优于SOTA。 |
| [^4] | [Evaluating the Efficacy of Prompt-Engineered Large Multimodal Models Versus Fine-Tuned Vision Transformers in Image-Based Security Applications](https://arxiv.org/abs/2403.17787) | 评估在基于图像的安全应用中，即时工程的Gemini-pro大型多模态模型与微调的Vision Transformer模型的有效性，并发现在关键安全挑战中表现出明显的性能差异。 |
| [^5] | [A Study in Dataset Pruning for Image Super-Resolution](https://arxiv.org/abs/2403.17083) | 本研究针对图像超分辨率中数据集训练资源需求大的问题，提出了一种数据集修剪的解决方案，通过基于损失值的选择，将训练集缩减至原始数据集的50%，取得了令人满意的结果。 |
| [^6] | [TrustSQL: A Reliability Benchmark for Text-to-SQL Models with Diverse Unanswerable Questions](https://arxiv.org/abs/2403.15879) | TrustSQL是一个旨在评估文本到SQL模型在处理各种类型问题时的可靠性的新基准，要求模型在SQL预测和放弃预测两种情况下进行评估。 |
| [^7] | [FusionINN: Invertible Image Fusion for Brain Tumor Monitoring](https://arxiv.org/abs/2403.15769) | FusionINN引入了一种新颖的可逆图像融合框架，可以高效生成融合图像，并解开融合过程的逆向分解，保证无损的像素映射。 |
| [^8] | [Towards a \textbf{RAG}-based Summarization Agent for the Electron-Ion Collider](https://arxiv.org/abs/2403.15729) | 开发了一种面向电子离子对撞机的基于RAG的摘要生成代理，能够压缩信息并引用相关回复，为合作者提供重大优势 |
| [^9] | [Learning to Infer Generative Template Programs for Visual Concepts](https://arxiv.org/abs/2403.15476) | 探索了一种学习如何推断捕捉视觉概念的通用模板程序的神经符号系统，引入了模板程序概念，支持多种概念相关任务，提出了一种学习范式来训练网络直接推断模板程序，实验证明该方法优于任务特定替代方法，并与特定领域方法竞争性地执行。 |
| [^10] | [Interpretable User Satisfaction Estimation for Conversational Systems with Large Language Models](https://arxiv.org/abs/2403.12388) | 本文提出了一种名为SPUR的方法，通过LLMs更有效地从自然语言话语中提取用户满意度的可解释信号，并能够利用迭代提示框架进行用户满意度评估。 |
| [^11] | [CantonMT: Cantonese to English NMT Platform with Fine-Tuned Models Using Synthetic Back-Translation Data](https://arxiv.org/abs/2403.11346) | 提出了CantonMT项目，利用合成反向翻译数据对粤语至英语NMT模型进行微调，并为研究人员提供用户友好的界面和开源工具包，以促进研究 |
| [^12] | [HeadEvolver: Text to Head Avatars via Locally Learnable Mesh Deformation](https://arxiv.org/abs/2403.09326) | 通过可学习的局部网格变形技术，HeadEvolver框架可以通过文本引导生成高质量的头部头像，保留细节并支持编辑和动画。 |
| [^13] | [Governance of Generative Artificial Intelligence for Companies](https://arxiv.org/abs/2403.08802) | 本综述填补了有关企业中生成式人工智能（GenAI）治理的研究空白，提出了一个框架，旨在利用业务机会并减轻与GenAI整合相关风险。 |
| [^14] | [Do Deep Neural Network Solutions Form a Star Domain?](https://arxiv.org/abs/2403.07968) | SGD解决方案集是一个星形域，包含一个星形模型，通过低损失数值的路径与其他解决方案线性相连，模除排列。 |
| [^15] | [Exploring Safety Generalization Challenges of Large Language Models via Code](https://arxiv.org/abs/2403.07865) | 本论文引入了CodeAttack框架用于测试大型语言模型的安全泛化，研究发现GPT-4、Claude-2和Llama-2系列等最新模型存在代码输入的安全漏洞。 |
| [^16] | [Guiding Clinical Reasoning with Large Language Models via Knowledge Seeds](https://arxiv.org/abs/2403.06609) | 大型语言模型在临床推理中展现出潜力，但存在幻觉问题和与医生决策路径不一致的挑战。 |
| [^17] | [Unsupervised Real-Time Hallucination Detection based on the Internal States of Large Language Models](https://arxiv.org/abs/2403.06448) | 提出了一种利用大型语言模型内部状态进行实时幻觉检测的无监督训练框架，并引入了一个新的基准用于评估多个大型语言模型的幻觉检测。 |
| [^18] | [Learning to Maximize Mutual Information for Chain-of-Thought Distillation](https://arxiv.org/abs/2403.03348) | 通过最大化两个任务的表示特征的互信息，提出了一种解决思维链蒸馏中标签预测任务与知识集成不足问题的变分方法。 |
| [^19] | [HALC: Object Hallucination Reduction via Adaptive Focal-Contrast Decoding](https://arxiv.org/abs/2403.00425) | HALC是一种旨在减少大型视觉-语言模型中对象幻觉的新颖解码算法，通过局部的自动聚焦基准机制和全局的波束搜索算法，成功减少OH而保持文本生成质量，同时可以作为即插即用模块集成到任何LVLMs中。 |
| [^20] | [Resonance RoPE: Improving Context Length Generalization of Large Language Models](https://arxiv.org/abs/2403.00071) | Resonance RoPE是一种新颖方法，通过调整RoPE特征的插值来缩小训练短-测试长场景下的泛化差距，在不增加额外在线计算成本的情况下显著提高模型性能。 |
| [^21] | [Training Dynamics of Multi-Head Softmax Attention for In-Context Learning: Emergence, Convergence, and Optimality](https://arxiv.org/abs/2402.19442) | 研究了多头softmax注意力模型在上下文学习中的训练动态，证明了全局收敛性，并发现了“任务分配”现象，梯度流动分为热身、涌现和收敛三个阶段，最终证明了梯度流的最优性。 |
| [^22] | [Out-of-Domain Generalization in Dynamical Systems Reconstruction](https://arxiv.org/abs/2402.18377) | 该论文提供了一个解决动力系统重构中泛化问题的正式框架, 并阐述了跨领域泛化在DSR中与机器学习其他领域的不同之处 |
| [^23] | [Making Them Ask and Answer: Jailbreaking Large Language Models in Few Queries via Disguise and Reconstruction](https://arxiv.org/abs/2402.18104) | 通过伪装和重构攻击方法，我们提出了一种在大型语言模型中越狱的方法，通过成功隐藏有害指令并引导模型重构原指令，取得了90%的攻击成功率。 |
| [^24] | [When Your AI Deceives You: Challenges with Partial Observability of Human Evaluators in Reward Learning](https://arxiv.org/abs/2402.17747) | RLHF在考虑部分观察性时可能导致策略欺骗性地夸大性能或过度辩护行为，我们提出了数学条件来解决这些问题，并警告不要盲目应用RLHF在部分可观测情况下。 |
| [^25] | [Are LLMs Capable of Data-based Statistical and Causal Reasoning? Benchmarking Advanced Quantitative Reasoning with Data](https://arxiv.org/abs/2402.17644) | 本研究引入了QRData基准测试，评估了大型语言模型在统计和因果推理方面的能力，结果显示最强模型GPT-4在该测试中准确率为58％，存在改进空间。 |
| [^26] | [How Important Is Tokenization in French Medical Masked Language Models?](https://arxiv.org/abs/2402.15010) | 子词标记化成为自然语言处理领域的主流标准，但其成功因素，如不同任务和语言的最佳分割粒度、数据源对标记工具的影响以及形态信息在印欧语言中的作用，仍不明确。 |
| [^27] | [GenCeption: Evaluate Multimodal LLMs with Unlabeled Unimodal Data](https://arxiv.org/abs/2402.14973) | 提出了一种名为GenCeption的新型MLLM评估框架，可以仅利用单模态数据评估跨模态语义一致性，并有效反映模型产生幻觉的倾向，具有较强的相关性和潜力于流行的MLLM基准结果。 |
| [^28] | [Ranking Large Language Models without Ground Truth](https://arxiv.org/abs/2402.14860) | 不需要基准实况或参考响应的条件下，通过考虑模型的三元组来排名大型语言模型，并提出了两种排名方法。 |
| [^29] | [CounterCurate: Enhancing Physical and Semantic Visio-Linguistic Compositional Reasoning via Counterfactual Examples](https://arxiv.org/abs/2402.13254) | 本研究提出CounterCurate框架，通过对比例子和生成式微调，全面提升视觉-语言组合推理能力，解决了物理推理和语义对照微调方面的关键问题，实现了显著性能改进。 |
| [^30] | [GTBench: Uncovering the Strategic Reasoning Limitations of LLMs via Game-Theoretic Evaluations](https://arxiv.org/abs/2402.12348) | 该论文通过博弈论任务评估了LLMs在竞争环境中的推理能力，观察到LLMs在不同游戏场景下表现出不同行为，具有重要的战略推理局限性。 |
| [^31] | [Refining Minimax Regret for Unsupervised Environment Design](https://arxiv.org/abs/2402.12284) | 介绍了贝叶斯级别完美的MMR（BLP），它是极小化遗憾目标的精确化，能够克服极小化遗憾策略在遗憾上界时学习停滞的限制。 |
| [^32] | [LLM as Prompter: Low-resource Inductive Reasoning on Arbitrary Knowledge Graphs](https://arxiv.org/abs/2402.11804) | 本文利用大型语言模型（LLMs）生成图形结构提示，以增强预训练的图神经网络（GNNs），提出一种新的方法论见解，实现了在任意知识图上进行低资源归纳推理的高通用性。 |
| [^33] | [Training Language Model Agents without Modifying Language Models](https://arxiv.org/abs/2402.11359) | 提出一种新的方法，在不修改语言模型的情况下训练语言模型代理，通过进化代理的功能来解决下游任务 |
| [^34] | [Graph-based Forecasting with Missing Data through Spatiotemporal Downsampling](https://arxiv.org/abs/2402.10634) | 通过 hierarchical spatiotemporal downsampling 处理缺失数据问题，结合可解释的注意机制，实现对时空预测的有效建模 |
| [^35] | [Can LLMs Speak For Diverse People? Tuning LLMs via Debate to Generate Controllable Controversial Statements](https://arxiv.org/abs/2402.10614) | 本文通过辩论调节LLMs，使其生成可控的支持用户定义论点的声明，改进了LLMs的可控性，并提出了DEBATunE流程。通过两个LLMs之间的多轮辩论生成高质量的训练数据，以支持生成有更高质量和更突出的声明。 |
| [^36] | [Random Projection Layers for Multidimensional Time Sires Forecasting](https://arxiv.org/abs/2402.10487) | 提出了一种全MLP时间序列预测架构RPMixer，通过将随机投影层集成到模型中，增加了块输出之间的多样性，提高了整体性能 |
| [^37] | [BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains](https://arxiv.org/abs/2402.10373) | BioMistral是一种面向生物医学领域的开源预训练大型语言模型集合，在医学问答任务中表现出优越性能并具有竞争优势。 |
| [^38] | [Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning](https://arxiv.org/abs/2402.10110) | 本文介绍了一种名为选择性反射调节的新方法，该方法通过教师LLM的反射和自省与学生LLM的数据选择能力相结合，自动优化现有的指令调节数据，从而实现了高效的指令调节和卓越性能的LLM。 |
| [^39] | [Arrange, Inpaint, and Refine: Steerable Long-term Music Audio Generation and Editing via Content-based Controls](https://arxiv.org/abs/2402.09508) | 通过引入参数高效微调（PEFT）方法，本研究实现了自回归语言模型在音乐修复和音乐排列任务中的应用。在多个音乐编辑任务中，该方法展示了有希望的结果，并为未来的AI驱动音乐编辑工具提供了更灵活的控制。 |
| [^40] | [Bayesian Federated Learning Via Expectation Maximization and Turbo Deep Approximate Message Passing](https://arxiv.org/abs/2402.07366) | 本文提出了一种基于消息传递的贝叶斯联邦学习（BFL）框架，通过结合期望最大化和Turbo Deep近似消息传递（TDAMP）实现分布式学习和压缩。该框架在处理联邦学习算法的缺点上有着显著的改进。 |
| [^41] | [Self-Correcting Self-Consuming Loops for Generative Model Training](https://arxiv.org/abs/2402.07087) | 本论文研究了使用合成数据进行生成模型训练时可能出现的自我消耗循环问题，并提出了一种通过引入理想的修正函数来稳定训练的方法。同时，我们还提出了自我修正函数来近似理想的修正函数，并通过实验证实了其有效性。 |
| [^42] | [Studious Bob Fight Back Against Jailbreaking via Prompt Adversarial Tuning](https://arxiv.org/abs/2402.06255) | 本文提出了一种名为Prompt Adversarial Tuning (PAT)的方法，通过训练一个防御控制机制并将其作为前缀嵌入到用户提示中，实现对大型语言模型（LLMs）的越狱行为的防御。实验证明该方法在保护LLMs免受产生有害信息的影响方面效果显著。 |
| [^43] | [Self-Alignment of Large Language Models via Monopolylogue-based Social Scene Simulation](https://arxiv.org/abs/2402.05699) | 本文提出了一个通过社交场景模拟来自对齐大型语言模型的方法，以减轻其被滥用造成的潜在不良影响。通过一个名为MATRIX的虚拟排练空间，LLM可以在回答查询前考虑社交后果，并通过MATRIX-simulated数据的微调，保持对人类价值的遵从和推理速度的平衡。实验证明，在温和假设下，带有MATRIX的LLM胜过了宪法AI。 |
| [^44] | [AttnLRP: Attention-Aware Layer-wise Relevance Propagation for Transformers](https://arxiv.org/abs/2402.05602) | AttnLRP是首个能够忠实且全面地归因Transformer模型的输入和潜在表示，并具有与单一反向传播相似的计算效率的方法。它通过扩展逐层相关传递归因方法以处理注意力层来解决了黑盒Transformer模型的归因问题，具有超越现有方法的准确性和理解潜在表示的能力。 |
| [^45] | [Benchmarking Large Language Models on Communicative Medical Coaching: a Novel System and Dataset](https://arxiv.org/abs/2402.05547) | 本研究介绍了“ChatCoach”，一个集成人工智能与人类医生合作的框架，在交流医疗辅导中利用大型语言模型，提供模拟环境和实时反馈，以帮助医学学员提高沟通技巧。 |
| [^46] | [Quantized Approximately Orthogonal Recurrent Neural Networks](https://arxiv.org/abs/2402.04012) | 本文提出了量化近似正交循环神经网络（QORNNs）来解决正交循环神经网络（ORNNs）中参数过多的问题，采用一种后训练量化策略和三种融入正交约束和量化权重的量化感知训练算法，取得了与s相似的结果。 |
| [^47] | [BRAIn: Bayesian Reward-conditioned Amortized Inference for natural language generation from feedback](https://arxiv.org/abs/2402.02479) | BRAIn是一种基于贝叶斯奖励条件化缩减推断的自然语言生成方法，通过反馈来改进RLHF，在LLM对齐中表现出较好的可扩展性和性能。 |
| [^48] | [DeLLMa: A Framework for Decision Making Under Uncertainty with Large Language Models](https://arxiv.org/abs/2402.02392) | DeLLMa是一个旨在提高不确定环境下决策精度的框架，通过多步骤的脚手架程序，借鉴决策理论和效用理论的原则，可以显著提高大型语言模型的决策性能。 |
| [^49] | [Stereographic Spherical Sliced Wasserstein Distances](https://arxiv.org/abs/2402.02345) | 本文提出了一种快速且高度并行的用于比较球形测度的距离，使用了立体投影和广义Radon变换，称之为立体投影球面切片瓦瑟斯坦（S3W）距离。通过仔细处理立体投影引起的距离畸变，并进行了理论分析，证明了该方法在速度和效果上的优势。 |
| [^50] | [Neural Scaling Laws on Graphs](https://arxiv.org/abs/2402.02054) | 本论文在图上深入研究了神经缩放定律，从模型和数据两个角度进行了探索。对于模型缩放，发现了缩放定律崩溃和过拟合之间的关系，以及深度图模型的模型深度对缩放行为的影响。对于数据缩放，提出了图数量不适合作为衡量缩放定律中图数据量的指标。 |
| [^51] | [BPDec: Unveiling the Potential of Masked Language Modeling Decoder in BERT pretraining](https://arxiv.org/abs/2401.15861) | 本文揭示了BPDec（BERT预训练解码器）的潜力，强调增强的掩码语言建模解码器设计及研究在BERT预训练中的重要性。 |
| [^52] | [PRewrite: Prompt Rewriting with Reinforcement Learning](https://arxiv.org/abs/2401.08189) | 本文提出了一种基于强化学习的自动化工具PRewrite，用于重写提示草案并生成高效的新提示，以解决提示工程中的挑战。 |
| [^53] | [Model Editing at Scale leads to Gradual and Catastrophic Forgetting](https://arxiv.org/abs/2401.07453) | 评估了当前模型编辑方法在规模化情况下的表现，发现随着模型被顺序编辑多个事实，它会逐渐遗忘先前的事实及执行下游任务的能力。 |
| [^54] | [Agent-Specific Effects: A Causal Effect Propagation Analysis in Multi-Agent MDPs](https://arxiv.org/abs/2310.11334) | 本文介绍了一种系统化的方法，用于将代理的行动对其他代理的影响归因到因果效应上，并提出了一种衡量代理特定效应（ASE）的新的因果数量。同时，我们还介绍了ASE的反事实对应物（cf-ASE）以及识别cf-ASE的条件，并提出了一种实用的基于采样的算法。 |
| [^55] | [Deep Reinforcement Learning for Image-to-Image Translation](https://arxiv.org/abs/2309.13672) | 该论文提出了一种基于深度强化学习的图像到图像翻译方法，通过将翻译过程分解为小步骤并引入元策略和Plan概念，能够有效处理高维连续状态和动作空间的挑战。 |
| [^56] | [An explainable three dimension framework to uncover learning patterns: A unified look in variable sulci recognition](https://arxiv.org/abs/2309.00903) | 该论文提出了一个针对医学成像中的可解释AI的三维框架，旨在解决神经科学领域中识别大脑沟特征的复杂性问题。 |
| [^57] | [MLLMReID: Multimodal Large Language Model-based Person Re-identification.](http://arxiv.org/abs/2401.13201) | MLLMReID是一种基于多模态大语言模型的人物再识别方法，通过微调模型并将其视觉编码器作为主干进行优化，解决了MLLM在ReID任务中的设计指令和特征学习效果的问题。 |
| [^58] | [DeepEdit: Knowledge Editing as Decoding with Constraints.](http://arxiv.org/abs/2401.10471) | DeepEdit是一种神经符号方法，通过更好的推理一致性和对更新知识的意识，提高了大型语言模型的知识编辑能力，对多跳问题数据集MQuaKE取得了显著的进展。 |
| [^59] | [DiffDA: a diffusion model for weather-scale data assimilation.](http://arxiv.org/abs/2401.05932) | DiffDA是一种用于气象尺度数据同化的扩散模型，通过机器学习的方法将预测状态和稀疏观测同化，生成与观测一致的初始条件，并能对预测进行后处理到未来。 |
| [^60] | [Moving Sampling Physics-informed Neural Networks induced by Moving Mesh PDE.](http://arxiv.org/abs/2311.16167) | 这项工作提出了一种基于移动网格PDE的移动采样物理信息神经网络(MMPDE-Net)，通过解决移动网格PDE来自适应生成新的采样点，并且结合物理信息神经网络（PINN）提出了移动采样PINN（MS-PINN）的框架。数值实验验证了MS-PINN相对于PINN的性能改善。 |
| [^61] | [Offline Imitation from Observation via Primal Wasserstein State Occupancy Matching.](http://arxiv.org/abs/2311.01331) | 本论文提出了一种通过最小化原始Wasserstein距离来匹配专家和学习者状态占用的方法，以解决离线学习从观察中模仿任务的问题。 |
| [^62] | [A Definition of Open-Ended Learning Problems for Goal-Conditioned Agents.](http://arxiv.org/abs/2311.00344) | 本文为开放式学习问题定义了一个关键的基本属性，即无限时间内不断产生新元素。在这基础上，提出了开放式学习问题的概念，并着重研究了开放式目标条件强化学习的子集。 |
| [^63] | [Understanding deep neural networks through the lens of their non-linearity.](http://arxiv.org/abs/2310.11439) | 本文提出了一个理论上有效的解决方案，通过亲和度评分追踪深度神经网络中的非线性传播，尤其关注计算机视觉应用。实验证实了所提出方法的实用性和对广泛应用的潜力。 |
| [^64] | [Demonstrations Are All You Need: Advancing Offensive Content Paraphrasing using In-Context Learning.](http://arxiv.org/abs/2310.10707) | 该论文在攻击性内容改写方面引入了上下文学习方法，并通过有限数量的输入-标签演示对来指导模型生成特定查询的所需输出，从而提高可用性和减少攻击性。 |
| [^65] | [Community Membership Hiding as Counterfactual Graph Search via Deep Reinforcement Learning.](http://arxiv.org/abs/2310.08909) | 这项研究通过深度强化学习的方式解决了社区成员隐藏的挑战，通过战略地改变网络图的结构属性，防止节点被社区检测算法识别出来，并验证了方法的有效性。 |
| [^66] | [Learning a Reward Function for User-Preferred Appliance Scheduling.](http://arxiv.org/abs/2310.07389) | 本文介绍了一种基于逆强化学习的模型，通过使用终端用户过去的消费数据，帮助创建用户每日的电器计划，从而鼓励终端用户参与需求响应服务的提供。 |
| [^67] | [Online Speculative Decoding.](http://arxiv.org/abs/2310.07177) | 在线推测解码是通过利用多余计算能力，在LLM服务集群中持续更新草稿模型，从而加速大型语言模型推理的一种方法。 |
| [^68] | [Memoria: Hebbian Memory Architecture for Human-Like Sequential Processing.](http://arxiv.org/abs/2310.03052) | Memoria 是一个通用记忆网络，应用海比安理论来增强神经网络中的长期依赖。通过存储和检索信息，并使用根据海布规则变化的连接权重，Memoria 在诸如 BERT 和 GPT 之类的流行 Transformer 模型上显著改进了考虑长期依赖的能力。 |
| [^69] | [On the Stability of Expressive Positional Encodings for Graph Neural Networks.](http://arxiv.org/abs/2310.02579) | 本研究针对图神经网络中使用拉普拉斯特征向量作为位置编码面临的非唯一性和不稳定性问题，提出了稳定且表达丰富的位置编码方法（SPE），该方法通过利用特征值对特征空间进行"软分割"，在未见过的图结构上表现出良好的泛化能力。 |
| [^70] | [Fooling the Textual Fooler via Randomizing Latent Representations.](http://arxiv.org/abs/2310.01452) | 该论文提出了一种轻量级的攻击无关防御策略AdvFooler，通过随机化输入的潜在表示来困惑基于查询的黑盒攻击，从而迷惑文本愚弄者。 |
| [^71] | [Sourcing Investment Targets for Venture and Growth Capital Using Multivariate Time Series Transformer.](http://arxiv.org/abs/2309.16888) | 这个论文介绍了一种新颖的方法，利用Transformer-based Multivariate Time Series Classifier (TMTSC)来预测风险投资和成长资本的候选公司的成功可能性，以优化投资目标的选择。通过对相关的方法进行了全面回顾和实验验证，证明了该方法的有效性。 |
| [^72] | [UniHead: Unifying Multi-Perception for Detection Heads.](http://arxiv.org/abs/2309.13242) | UniHead是一种创新的检测头，它通过引入变形感知、双轴聚合变换器和跨任务交互变换器，实现了全感知能力的统一。 |
| [^73] | [Masking Improves Contrastive Self-Supervised Learning for ConvNets, and Saliency Tells You Where.](http://arxiv.org/abs/2309.12757) | 该论文研究了如何将遮盖操作引入卷积神经网络的对比学习框架中，以提高自监督学习的效果。同时，研究还发现遮盖操作可能存在一些副作用，作者提出了解决方案来应对这些问题。 |
| [^74] | [Deep Reinforcement Learning from Hierarchical Weak Preference Feedback.](http://arxiv.org/abs/2309.02632) | 本研究探讨了如何利用分层的弱偏好反馈进行深度强化学习。通过学习奖励函数，与人类偏好非常一致的复杂奖励可以帮助强化学习解决日益困难的问题。 |
| [^75] | [In situ Fault Diagnosis of Indium Tin Oxide Electrodes by Processing S-Parameter Patterns.](http://arxiv.org/abs/2308.11639) | 本研究提出了一种利用散射参数（S参数）信号处理的现场故障诊断方法，对氧化铟锡（ITO）电极进行故障检测和诊断。这种方法具有早期检测、高诊断精度、噪声鲁棒性和根本原因分析的优势。 |
| [^76] | [Generalized Independent Noise Condition for Estimating Causal Structure with Latent Variables.](http://arxiv.org/abs/2308.06718) | 这篇论文提出了具有潜变量的因果结构估计的广义独立噪声（GIN）条件，并给出了线性非高斯无环因果模型中满足GIN条件的图形判据。 |
| [^77] | [Meta-learning in healthcare: A survey.](http://arxiv.org/abs/2308.02877) | 元学习在医疗领域有广泛应用，可以解决医疗挑战，如样本不足和数据收集差异。主要包括多/单任务学习和多/少样本学习方法。 |
| [^78] | [A Zero-shot and Few-shot Study of Instruction-Finetuned Large Language Models Applied to Clinical and Biomedical Tasks.](http://arxiv.org/abs/2307.12114) | 这项研究评估了四种指导细调大型语言模型在临床和生物医学任务上的表现，并发现它们在零样本和少样本情况下接近最先进模型的性能，尤其在问答任务上表现良好。然而，在分类和关系抽取任务上的表现稍逊于特定训练于医学领域的模型。没有一个模型在所有研究任务上胜过其他模型，有些模型更适合特定任务。 |
| [^79] | [Gradient strikes back: How filtering out high frequencies improves explanations.](http://arxiv.org/abs/2307.09591) | 本研究发现，基于预测的属性方法与基于梯度的方法产生的属性图具有不同的高频内容，滤除高频率可以提高解释性。 |
| [^80] | [FedSelect: Customized Selection of Parameters for Fine-Tuning during Personalized Federated Learning.](http://arxiv.org/abs/2306.13264) | 本文提出了一种名为FedSelect的新联邦学习框架，通过寻找最佳客户端子网络从而直接个性化客户端子网络结构和参数，同时保留了全局知识，提高了客户端性能。 |
| [^81] | [CompanyKG: A Large-Scale Heterogeneous Graph for Company Similarity Quantification.](http://arxiv.org/abs/2306.10649) | 本研究提出了CompanyKG，一种用于公司相似性量化的大规模异构图数据集。通过丰富的公司特征和关系表示，以及多个评估任务的基准测试，为公司相似性量化方法的综合评估提供了支持。 |
| [^82] | [Strokes2Surface: Recovering Curve Networks From 4D Architectural Design Sketches.](http://arxiv.org/abs/2306.07220) | 本文介绍了Strokes2Surface，它可从建筑师的笔画中恢复出曲线网络，对于建筑设计中的概念设计和数字建模之间的桥梁具有重要意义。 |
| [^83] | [Parameter-Efficient Fine-Tuning for Medical Image Analysis: The Missed Opportunity.](http://arxiv.org/abs/2305.08252) | 该论文综合评估了基于参数的高效调整技术（PEFT）在医学图像分析任务中的可能应用。通过超过600个控制测试，我们证明了PEFT的相对性能，并强调了PEFT在医学图像分析中实现参数高效转移学习的巨大潜力。 |
| [^84] | [The Structure and Dynamics of Knowledge Graphs, with Superficiality.](http://arxiv.org/abs/2305.08116) | 该论文提出了第一个知识图谱的结构和动态模型，并引入表层性来简单建模复杂特征，从而掌握全局知识分布的平衡。 |
| [^85] | [Discern and Answer: Mitigating the Impact of Misinformation in Retrieval-Augmented Models with Discriminators.](http://arxiv.org/abs/2305.01579) | 本文研究了现有检索增强语言模型假设所有检索信息都是正确的假设的问题，在实际应用中可能存在虚假信息导致冲突的情况下，提出了通过精细调整鉴别器和提示鉴别能力引出鲁棒性的方法，这显著改善了模型在知识冲突下的效果；同时提供了关于交替精细调整模型和上下文学习的新的结论。 |
| [^86] | [Auditing and Generating Synthetic Data with Controllable Trust Trade-offs.](http://arxiv.org/abs/2304.10819) | 本论文提出了一个审计框架，能够以全面的方式评估合成数据和AI模型的具体效果，包括偏见和歧视预防、对真实数据的忠实程度、效用、鲁棒性和隐私保护。在多个用例中，审计框架平衡了信任和效用之间的权衡。 |
| [^87] | [Fusing Structure from Motion and Simulation-Augmented Pose Regression from Optical Flow for Challenging Indoor Environments.](http://arxiv.org/abs/2304.07250) | 本文探讨了如何在室内环境下进行运动目标的定位，使用了结构运动与模拟数据和深度学习技术。研究者整合光流和相对姿态回归方法帮助解决了因运动模糊、光照变化、重复图案和缺乏特征结构等问题而带来的瓶颈，为室内目标定位提供了更好的方案。 |
| [^88] | [Multi-Class Explainable Unlearning for Image Classification via Weight Filtering.](http://arxiv.org/abs/2304.02049) | 本论文提出一种基于权重滤波的多类可解释性卸载图像分类方法，可以在单个未训练轮中取消学习网络的所有类别，并且恢复可解释的类别表示。 |
| [^89] | [An interpretable imbalanced semi-supervised deep learning framework for improving differential diagnosis of skin diseases.](http://arxiv.org/abs/2211.10858) | 本文提出了一种基于可解释性和不平衡半监督深度学习框架的研究，利用伪标签样本进行自我训练来解决皮肤疾病分类中的类别不平衡问题，并取得了令人满意的性能表现。 |
| [^90] | [Mitigating spectral bias for the multiscale operator learning with hierarchical attention.](http://arxiv.org/abs/2210.10890) | 本文提出了一种分层注意力神经算子（HANO），用于解决多尺度偏微分方程学习中存在的光谱偏差问题，并通过数值实验证明其优于现有方法。 |

# 详细

[^1]: 可视自回归建模：通过下一尺度预测实现可伸缩图像生成

    Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction

    [https://arxiv.org/abs/2404.02905](https://arxiv.org/abs/2404.02905)

    VAR重新定义了图像上的自回归学习，通过粗到细的“下一尺度预测”实现快速学习视觉分布并超越了扩散变压器。

    

    我们提出了可视自回归建模（VAR），这是一种重新定义自回归学习在图像上的生成范式，将其作为从粗粒度到细粒度的“下一尺度预测”或“下一分辨率预测”，偏离了标准的光栅扫描“下一个令牌预测”。这种简单直观的方法允许自回归（AR）变压器快速学习视觉分布并具有良好泛化能力：VAR首次使AR模型在图像生成方面超越了扩散变压器。在ImageNet 256x256基准测试中，VAR通过将Frechet入侵距离（FID）从18.65提高到1.80，将inception分数（IS）从80.4提高到356.4，推断速度加快了大约20倍，显着改善了AR基线。经验证，VAR在图像质量、推断速度、数据效率和可伸缩性等多个维度上优于扩散变压器（DiT）。扩大VAR模型的规模显示出明显的幂律扩展能力。

    arXiv:2404.02905v1 Announce Type: cross  Abstract: We present Visual AutoRegressive modeling (VAR), a new generation paradigm that redefines the autoregressive learning on images as coarse-to-fine "next-scale prediction" or "next-resolution prediction", diverging from the standard raster-scan "next-token prediction". This simple, intuitive methodology allows autoregressive (AR) transformers to learn visual distributions fast and generalize well: VAR, for the first time, makes AR models surpass diffusion transformers in image generation. On ImageNet 256x256 benchmark, VAR significantly improve AR baseline by improving Frechet inception distance (FID) from 18.65 to 1.80, inception score (IS) from 80.4 to 356.4, with around 20x faster inference speed. It is also empirically verified that VAR outperforms the Diffusion Transformer (DiT) in multiple dimensions including image quality, inference speed, data efficiency, and scalability. Scaling up VAR models exhibits clear power-law scaling la
    
[^2]: 通过反事实来揭示大规模视觉-语言模型中的偏见

    Uncovering Bias in Large Vision-Language Models with Counterfactuals

    [https://arxiv.org/abs/2404.00166](https://arxiv.org/abs/2404.00166)

    通过对输入图像进行反事实变化，我们对不同大规模视觉-语言模型生成的文本进行了研究，以揭示其中的社会偏见。

    

    随着拥有越来越令人印象深刻能力的大型语言模型（LLMs）的出现，提出了许多大型视觉-语言模型（LVLMs）来利用视觉输入增强LLMs。这些模型在生成文本时同时条件于输入图像和文本提示，实现了各种用例，如视觉问答和多模态聊天。尽管先前的研究已经考察了LLMs生成的文本中包含的社会偏见，但在LVLMs中相对较少探讨了这个问题。由于文本和视觉模态中包含的信息引起的偏见相互交叉，检查LVLMs中的社会偏见尤其具有挑战性。为了解决这个具有挑战性的问题，我们对不同LVLMs生成的文本进行了大规模研究，通过对输入图像进行反事实变化。具体来说，我们向LVLMs呈现相同的开放式文本提示，同时在不同的图像条件下进行。

    arXiv:2404.00166v1 Announce Type: cross  Abstract: With the advent of Large Language Models (LLMs) possessing increasingly impressive capabilities, a number of Large Vision-Language Models (LVLMs) have been proposed to augment LLMs with visual inputs. Such models condition generated text on both an input image and a text prompt, enabling a variety of use cases such as visual question answering and multimodal chat. While prior studies have examined the social biases contained in text generated by LLMs, this topic has been relatively unexplored in LVLMs. Examining social biases in LVLMs is particularly challenging due to the confounding contributions of bias induced by information contained across the text and visual modalities. To address this challenging problem, we conduct a large-scale study of text generated by different LVLMs under counterfactual changes to input images. Specifically, we present LVLMs with identical open-ended text prompts while conditioning on images from differen
    
[^3]: 基于计算意识结构的生成式Agent：ITCMA

    ITCMA: A Generative Agent Based on a Computational Consciousness Structure

    [https://arxiv.org/abs/2403.20097](https://arxiv.org/abs/2403.20097)

    ITCMA是基于计算意识结构的生成式Agent，通过考虑Agent与环境的互动和推理，增强了LLMs理解隐含指令和应用常识知识的能力，在Alfworld环境中表现优于SOTA。

    

    大型语言模型（LLMs）在需要理解隐含指令和应用常识知识的任务中仍然面临挑战。在这种情况下，LLMs可能需要多次尝试才能达到人类水平的表现，可能会导致在实际环境中产生不准确的响应或推理，影响它们的长期一致性和行为。本文介绍了内部时间意识机器（ITCM），一个计算意识结构。我们进一步提出了基于ITCM的Agent（ITCMA），支持在开放世界环境中生成行为和推理。ITCMA通过考虑Agent与环境的互动和推理，增强了LLMs理解隐含指令和应用常识知识的能力。在Alfworld环境中的评估显示，经过训练的ITCMA在已知集上比最先进技术（SOTA）表现提高了9%。即使未经训练的ITCMA也达到了96%的任务完成度。

    arXiv:2403.20097v1 Announce Type: new  Abstract: Large Language Models (LLMs) still face challenges in tasks requiring understanding implicit instructions and applying common-sense knowledge. In such scenarios, LLMs may require multiple attempts to achieve human-level performance, potentially leading to inaccurate responses or inferences in practical environments, affecting their long-term consistency and behavior. This paper introduces the Internal Time-Consciousness Machine (ITCM), a computational consciousness structure. We further propose the ITCM-based Agent (ITCMA), which supports behavior generation and reasoning in open-world settings. ITCMA enhances LLMs' ability to understand implicit instructions and apply common-sense knowledge by considering agents' interaction and reasoning with the environment. Evaluations in the Alfworld environment show that trained ITCMA outperforms the state-of-the-art (SOTA) by 9% on the seen set. Even untrained ITCMA achieves a 96% task completion 
    
[^4]: 评估在基于图像的安全应用中，在即时工程过程中设计的大型多模型与微调视觉变换器的有效性

    Evaluating the Efficacy of Prompt-Engineered Large Multimodal Models Versus Fine-Tuned Vision Transformers in Image-Based Security Applications

    [https://arxiv.org/abs/2403.17787](https://arxiv.org/abs/2403.17787)

    评估在基于图像的安全应用中，即时工程的Gemini-pro大型多模态模型与微调的Vision Transformer模型的有效性，并发现在关键安全挑战中表现出明显的性能差异。

    

    大型语言模型（LLMs）的成功导致了大型多模态模型（LMMs）（如Gemini-pro）的发展，这些模型已经开始转变各种应用。这些复杂的多模态模型旨在解释和分析复杂数据，整合了以往难以实现的文本和视觉信息规模，为一系列应用开辟了新的途径。本文调查了在解决关键安全挑战方面，即时工程的Gemini-pro LMMs与微调视觉变换器（ViT）模型的适用性和有效性。我们专注于两个不同的任务：检测图像中的简单触发器（如方形小方块）以示潜在后门的在视觉上显而易见的任务，以及通过视觉表示进行恶意软件分类的在视觉上不明显的任务。我们的结果突显了性能上的显著差异，Gemini-pro表现不佳。

    arXiv:2403.17787v1 Announce Type: new  Abstract: The success of Large Language Models (LLMs) has led to a parallel rise in the development of Large Multimodal Models (LMMs), such as Gemini-pro, which have begun to transform a variety of applications. These sophisticated multimodal models are designed to interpret and analyze complex data, integrating both textual and visual information on a scale previously unattainable, opening new avenues for a range of applications. This paper investigates the applicability and effectiveness of prompt-engineered Gemini-pro LMMs versus fine-tuned Vision Transformer (ViT) models in addressing critical security challenges. We focus on two distinct tasks: a visually evident task of detecting simple triggers, such as small squares in images, indicative of potential backdoors, and a non-visually evident task of malware classification through visual representations. Our results highlight a significant divergence in performance, with Gemini-pro falling shor
    
[^5]: 数据集修剪在图像超分辨率中的研究

    A Study in Dataset Pruning for Image Super-Resolution

    [https://arxiv.org/abs/2403.17083](https://arxiv.org/abs/2403.17083)

    本研究针对图像超分辨率中数据集训练资源需求大的问题，提出了一种数据集修剪的解决方案，通过基于损失值的选择，将训练集缩减至原始数据集的50%，取得了令人满意的结果。

    

    在图像超分辨率（SR）中，依赖大型数据集进行训练是一把双刃剑。尽管提供丰富的训练素材，但也需要大量的计算和存储资源。在本工作中，我们分析了数据集修剪作为应对这些挑战的解决方案。我们引入了一种新颖的方法，将数据集缩减到基于其损失值而选择的一组核心训练样本。通过仅将训练重点放在原始数据集的50%上，特别是那些损失值最高的样本上，我们实现了与或甚至超过整个数据集训练的结果相媲美的效果。有趣的是，我们的分析显示，具有最高损失值的前5％样本会对训练过程产生负面影响。排除这些样本并调整选择以偏好更容易的样本进一步提高了训练结果。我们的工作开辟了新的研究方向。

    arXiv:2403.17083v1 Announce Type: cross  Abstract: In image Super-Resolution (SR), relying on large datasets for training is a double-edged sword. While offering rich training material, they also demand substantial computational and storage resources. In this work, we analyze dataset pruning as a solution to these challenges. We introduce a novel approach that reduces a dataset to a core-set of training samples, selected based on their loss values as determined by a simple pre-trained SR model. By focusing the training on just 50% of the original dataset, specifically on the samples characterized by the highest loss values, we achieve results comparable to or even surpassing those obtained from training on the entire dataset. Interestingly, our analysis reveals that the top 5% of samples with the highest loss values negatively affect the training process. Excluding these samples and adjusting the selection to favor easier samples further enhances training outcomes. Our work opens new p
    
[^6]: TrustSQL: 用于具有多样无法回答问题的文本到SQL模型的可靠性基准

    TrustSQL: A Reliability Benchmark for Text-to-SQL Models with Diverse Unanswerable Questions

    [https://arxiv.org/abs/2403.15879](https://arxiv.org/abs/2403.15879)

    TrustSQL是一个旨在评估文本到SQL模型在处理各种类型问题时的可靠性的新基准，要求模型在SQL预测和放弃预测两种情况下进行评估。

    

    最近大型语言模型（LLMs）的进展显著提高了将自然语言问题翻译成SQL查询的准确性。在SQL生成的准确性至关重要的同时，很少有人了解这些文本到SQL模型在真实世界部署过程中能否可靠处理各种类型的问题，包括无法回答的问题。为了探讨这一方面，我们提出了TrustSQL，这是一个新的基准，旨在评估文本到SQL模型在单一数据库和跨数据库设置中的可靠性。基准任务要求模型提供两种结果之一：1）SQL预测；或2）在生成的SQL中可能存在错误或面临无法回答的问题时放弃预测。为了评估模型，我们探讨了专门为这一任务设计的各种建模方法，包括：1）为可回答性优化单独的模型

    arXiv:2403.15879v1 Announce Type: new  Abstract: Recent advances in large language models (LLMs) have led to significant improvements in translating natural language questions into SQL queries. While achieving high accuracy in SQL generation is crucial, little is known about the extent to which these text-to-SQL models can reliably handle diverse types of questions encountered during real-world deployment, including unanswerable ones. To explore this aspect, we present TrustSQL, a new benchmark designed to assess the reliability of text-to-SQL models in both single-database and cross-database settings. The benchmark tasks models with providing one of two outcomes: 1) SQL prediction; or 2) abstention from making a prediction, either when there is a potential error in the generated SQL or when faced with unanswerable questions. For model evaluation, we explore various modeling approaches specifically designed for this task. These include: 1) optimizing separate models for answerability d
    
[^7]: FusionINN：可逆图像融合用于脑肿瘤监测

    FusionINN: Invertible Image Fusion for Brain Tumor Monitoring

    [https://arxiv.org/abs/2403.15769](https://arxiv.org/abs/2403.15769)

    FusionINN引入了一种新颖的可逆图像融合框架，可以高效生成融合图像，并解开融合过程的逆向分解，保证无损的像素映射。

    

    图像融合通常使用不可逆神经网络将多个源图像合并为单个融合图像。然而，对于临床专家，仅依赖融合图像可能不足以做出诊断决策，因为融合机制混合了来自源图像的特征，从而难以解释潜在的肿瘤病理。我们引入了FusionINN，一种新颖的可逆图像融合框架，能够高效生成融合图像，并通过求解融合过程的逆过程将其分解回源图像。FusionINN通过整合一个正态分布的潜在图像与融合图像一起，以促进分解过程的生成建模，从而保证无损的一对一像素映射。据我们所知，我们是首次研究融合图像的可分解性，这对于生命敏感应用程序尤为关键。

    arXiv:2403.15769v1 Announce Type: cross  Abstract: Image fusion typically employs non-invertible neural networks to merge multiple source images into a single fused image. However, for clinical experts, solely relying on fused images may be insufficient for making diagnostic decisions, as the fusion mechanism blends features from source images, thereby making it difficult to interpret the underlying tumor pathology. We introduce FusionINN, a novel invertible image fusion framework, capable of efficiently generating fused images and also decomposing them back to the source images by solving the inverse of the fusion process. FusionINN guarantees lossless one-to-one pixel mapping by integrating a normally distributed latent image alongside the fused image to facilitate the generative modeling of the decomposition process. To the best of our knowledge, we are the first to investigate the decomposability of fused images, which is particularly crucial for life-sensitive applications such as
    
[^8]: 面向电子离子对撞机的基于RAG的摘要生成代理

    Towards a \textbf{RAG}-based Summarization Agent for the Electron-Ion Collider

    [https://arxiv.org/abs/2403.15729](https://arxiv.org/abs/2403.15729)

    开发了一种面向电子离子对撞机的基于RAG的摘要生成代理，能够压缩信息并引用相关回复，为合作者提供重大优势

    

    复杂性和庞大的信息量涵盖了大规模实验的文件、论文、数据和其他资源，导致导航这些多样形式信息的任务需要大量时间和精力，对于新合作者和早期科学家来说尤为艰巨。为了解决这个问题，正在开发一种基于检索增强生成（RAG）的EIC摘要生成人工智能代理（RAGS4EIC）。该人工智能代理不仅压缩信息，还有效引用相关回复，为合作者提供了重大优势。我们的项目采取了两步方法：首先，查询包含所有相关实验信息的综合向量数据库；其次，利用大型语言模型（LLM）根据用户查询和检索数据生成包含引用的简洁摘要。我们描述了使用RAG评估的评估方法

    arXiv:2403.15729v1 Announce Type: cross  Abstract: The complexity and sheer volume of information encompassing documents, papers, data, and other resources from large-scale experiments demand significant time and effort to navigate, making the task of accessing and utilizing these varied forms of information daunting, particularly for new collaborators and early-career scientists. To tackle this issue, a Retrieval Augmented Generation (RAG)--based Summarization AI for EIC (RAGS4EIC) is under development. This AI-Agent not only condenses information but also effectively references relevant responses, offering substantial advantages for collaborators. Our project involves a two-step approach: first, querying a comprehensive vector database containing all pertinent experiment information; second, utilizing a Large Language Model (LLM) to generate concise summaries enriched with citations based on user queries and retrieved data. We describe the evaluation methods that use RAG assessments 
    
[^9]: 学习推断生成视觉概念的模板程序

    Learning to Infer Generative Template Programs for Visual Concepts

    [https://arxiv.org/abs/2403.15476](https://arxiv.org/abs/2403.15476)

    探索了一种学习如何推断捕捉视觉概念的通用模板程序的神经符号系统，引入了模板程序概念，支持多种概念相关任务，提出了一种学习范式来训练网络直接推断模板程序，实验证明该方法优于任务特定替代方法，并与特定领域方法竞争性地执行。

    

    人们可以从少量示例中灵活掌握视觉概念。我们探索了一种神经符号系统，学习如何以一种通用方式推断捕捉视觉概念的程序。我们引入了模板程序：来自特定领域语言的程序表达式，指定了输入概念中常见的结构和参数模式。我们的框架支持多个与概念相关的任务，包括通过解析进行少样本生成和共分割。我们开发了一种学习范式，允许我们训练网络直接从包含概念分组的视觉数据集中推断模板程序。我们在多个视觉领域进行实验：2D布局、Omniglot字符和3D形状。我们发现我们的方法胜过了任务特定的替代方法，并在有限领域竞争性地执行了针对特定领域的方法。

    arXiv:2403.15476v1 Announce Type: cross  Abstract: People grasp flexible visual concepts from a few examples. We explore a neurosymbolic system that learns how to infer programs that capture visual concepts in a domain-general fashion. We introduce Template Programs: programmatic expressions from a domain-specific language that specify structural and parametric patterns common to an input concept. Our framework supports multiple concept-related tasks, including few-shot generation and co-segmentation through parsing. We develop a learning paradigm that allows us to train networks that infer Template Programs directly from visual datasets that contain concept groupings. We run experiments across multiple visual domains: 2D layouts, Omniglot characters, and 3D shapes. We find that our method outperforms task-specific alternatives, and performs competitively against domain-specific approaches for the limited domains where they exist.
    
[^10]: 基于大型语言模型的可解释对话系统用户满意度估计

    Interpretable User Satisfaction Estimation for Conversational Systems with Large Language Models

    [https://arxiv.org/abs/2403.12388](https://arxiv.org/abs/2403.12388)

    本文提出了一种名为SPUR的方法，通过LLMs更有效地从自然语言话语中提取用户满意度的可解释信号，并能够利用迭代提示框架进行用户满意度评估。

    

    准确而可解释的用户满意度估计对于了解、评估和持续改进对话系统至关重要。本文表明，与基于特征化的机器学习模型或文本嵌入的现有方法相比，LLMs能够更有效地从自然语言话语中提取用户满意度的可解释信号。此外，LLM可以通过一个迭代提示框架，并利用标记示例的监督进行用户满意度评估。

    arXiv:2403.12388v1 Announce Type: cross  Abstract: Accurate and interpretable user satisfaction estimation (USE) is critical for understanding, evaluating, and continuously improving conversational systems. Users express their satisfaction or dissatisfaction with diverse conversational patterns in both general-purpose (ChatGPT and Bing Copilot) and task-oriented (customer service chatbot) conversational systems. Existing approaches based on featurized ML models or text embeddings fall short in extracting generalizable patterns and are hard to interpret. In this work, we show that LLMs can extract interpretable signals of user satisfaction from their natural language utterances more effectively than embedding-based approaches. Moreover, an LLM can be tailored for USE via an iterative prompting framework using supervision from labeled examples. The resulting method, Supervised Prompting for User satisfaction Rubrics (SPUR), not only has higher accuracy but is more interpretable as it sco
    
[^11]: CantonMT: 汉英NMT平台，使用合成反向翻译数据对模型进行微调

    CantonMT: Cantonese to English NMT Platform with Fine-Tuned Models Using Synthetic Back-Translation Data

    [https://arxiv.org/abs/2403.11346](https://arxiv.org/abs/2403.11346)

    提出了CantonMT项目，利用合成反向翻译数据对粤语至英语NMT模型进行微调，并为研究人员提供用户友好的界面和开源工具包，以促进研究

    

    arXiv:2403.11346v1 消息类型：跨领域 摘要：对于低资源语言的神经机器翻译(NMT)仍然是自然语言处理研究人员面临的挑战。在这项工作中，我们将一个标准的数据增强方法——反向翻译，应用到了新的语言翻译方向粤语至英语。我们介绍了我们使用有限数量真实数据和生成的合成数据(包括OpusMT, NLLB,和mBART)进行微调的模型。我们使用了一系列不同指标包括基于词汇和嵌入的自动评估。此外，我们为这项\textsc{CantonMT}研究项目中包含的模型创建了一个用户友好的界面，并提供便利实现粤语至英语MT研究。研究人员可以通过我们的开源\textsc{CantonMT}工具包\url{https://github.com/kenrickkung/CantoneseTranslation}向平台添加更多模型。

    arXiv:2403.11346v1 Announce Type: cross  Abstract: Neural Machine Translation (NMT) for low-resource languages is still a challenging task in front of NLP researchers. In this work, we deploy a standard data augmentation methodology by back-translation to a new language translation direction Cantonese-to-English. We present the models we fine-tuned using the limited amount of real data and the synthetic data we generated using back-translation including OpusMT, NLLB, and mBART. We carried out automatic evaluation using a range of different metrics including lexical-based and embedding-based. Furthermore. we create a user-friendly interface for the models we included in this\textsc{ CantonMT} research project and make it available to facilitate Cantonese-to-English MT research. Researchers can add more models into this platform via our open-source\textsc{ CantonMT} toolkit \url{https://github.com/kenrickkung/CantoneseTranslation}.
    
[^12]: HeadEvolver：通过本地可学习网格变形实现文本到头部头像的转换

    HeadEvolver: Text to Head Avatars via Locally Learnable Mesh Deformation

    [https://arxiv.org/abs/2403.09326](https://arxiv.org/abs/2403.09326)

    通过可学习的局部网格变形技术，HeadEvolver框架可以通过文本引导生成高质量的头部头像，保留细节并支持编辑和动画。

    

    我们提出了HeadEvolver，一个新颖的框架，可以通过文本引导生成风格化的头部头像。HeadEvolver使用模板头部网格的本地可学习网格变形，生成高质量的数字资产，以实现保留细节的编辑和动画。为了解决全局变形中缺乏细粒度和语义感知本地形状控制的挑战，我们引入了可训练参数作为每个三角形的Jacobi矩阵的加权因子，以自适应地改变本地形状同时保持全局对应和面部特征。此外，为了确保来自不同视角的结果形状和外观的连贯性，我们使用预训练的图像扩散模型进行可微分渲染，并添加正则化项以在文本引导下优化变形。大量实验证明，我们的方法可以生成具有关节网格的多样化头部头像，可无缝编辑。

    arXiv:2403.09326v1 Announce Type: cross  Abstract: We present HeadEvolver, a novel framework to generate stylized head avatars from text guidance. HeadEvolver uses locally learnable mesh deformation from a template head mesh, producing high-quality digital assets for detail-preserving editing and animation. To tackle the challenges of lacking fine-grained and semantic-aware local shape control in global deformation through Jacobians, we introduce a trainable parameter as a weighting factor for the Jacobian at each triangle to adaptively change local shapes while maintaining global correspondences and facial features. Moreover, to ensure the coherence of the resulting shape and appearance from different viewpoints, we use pretrained image diffusion models for differentiable rendering with regularization terms to refine the deformation under text guidance. Extensive experiments demonstrate that our method can generate diverse head avatars with an articulated mesh that can be edited seaml
    
[^13]: 企业中生成式人工智能的治理

    Governance of Generative Artificial Intelligence for Companies

    [https://arxiv.org/abs/2403.08802](https://arxiv.org/abs/2403.08802)

    本综述填补了有关企业中生成式人工智能（GenAI）治理的研究空白，提出了一个框架，旨在利用业务机会并减轻与GenAI整合相关风险。

    

    生成式人工智能（GenAI），特别是像ChatGPT这样的大型语言模型，已迅速进入企业，但缺乏充分的治理，带来机遇和挑战。尽管对GenAI具有变革性质和监管措施的广泛讨论，但有限的研究涉及组织治理，包括技术和业务视角。本综述填补了这一空白，调查了最近的研究。它不仅仅是总结，还通过制定适用于企业内的GenAI治理框架来进行。我们的框架详细描述了范围、目标和治理机制，旨在利用业务机会并减轻与GenAI整合相关风险。该研究提供了一种专注于GenAI治理的方法，为企业在负责任的AI采用挑战中提供了实用见解。对于技术人员来说，也有助于拓宽他们的视角。

    arXiv:2403.08802v1 Announce Type: new  Abstract: Generative Artificial Intelligence (GenAI), specifically large language models like ChatGPT, has swiftly entered organizations without adequate governance, posing both opportunities and risks. Despite extensive debates on GenAI's transformative nature and regulatory measures, limited research addresses organizational governance, encompassing technical and business perspectives. This review paper fills this gap by surveying recent works. It goes beyond mere summarization by developing a framework for GenAI governance within companies. Our framework outlines the scope, objectives, and governance mechanisms tailored to harness business opportunities and mitigate risks associated with GenAI integration. This research contributes a focused approach to GenAI governance, offering practical insights for companies navigating the challenges of responsible AI adoption. It is also valuable for a technical audience to broaden their perspective as inc
    
[^14]: 深度神经网络解决方案是否形成星形区域？

    Do Deep Neural Network Solutions Form a Star Domain?

    [https://arxiv.org/abs/2403.07968](https://arxiv.org/abs/2403.07968)

    SGD解决方案集是一个星形域，包含一个星形模型，通过低损失数值的路径与其他解决方案线性相连，模除排列。

    

    Entezari等人（2022）推测通过随机梯度下降（SGD）可达到的神经网络解决方案集是凸的，考虑到排列不变性。本文提出了一个更加宽松的观点：SGD解决方案集是一个星形域，包含一个星形模型，通过低损失数值的路径与其他解决方案线性相连，模除排列。我们提出了Starlight算法，用于找到给定学习任务的星形模型。我们通过展示这个星形模型与其他独立找到的解决方案是线性相连的来验证我们的观点。

    arXiv:2403.07968v1 Announce Type: cross  Abstract: Entezari et al. (2022) conjectured that neural network solution sets reachable via stochastic gradient descent (SGD) are convex, considering permutation invariances. This means that two independent solutions can be connected by a linear path with low loss, given one of them is appropriately permuted. However, current methods to test this theory often fail to eliminate loss barriers between two independent solutions (Ainsworth et al., 2022; Benzing et al., 2022). In this work, we conjecture that a more relaxed claim holds: the SGD solution set is a star domain that contains a star model that is linearly connected to all the other solutions via paths with low loss values, modulo permutations. We propose the Starlight algorithm that finds a star model of a given learning task. We validate our claim by showing that this star model is linearly connected with other independently found solutions. As an additional benefit of our study, we demo
    
[^15]: 通过代码探索大型语言模型的安全泛化挑战

    Exploring Safety Generalization Challenges of Large Language Models via Code

    [https://arxiv.org/abs/2403.07865](https://arxiv.org/abs/2403.07865)

    本论文引入了CodeAttack框架用于测试大型语言模型的安全泛化，研究发现GPT-4、Claude-2和Llama-2系列等最新模型存在代码输入的安全漏洞。

    

    大型语言模型（LLMs）的快速发展带来了自然语言处理方面的显著能力，但也引发了人们对它们潜在误用的担忧。本文引入了CodeAttack，一个将自然语言输入转换为代码输入的框架，为测试LLMs的安全泛化提供了一个新颖的环境。我们对包括GPT-4、Claude-2和Llama-2系列在内的最新LLMs进行了全面研究，发现这些模型对于代码输入存在共同的安全漏洞：CodeAttack在超过80%的时间内始终绕过所有模型的安全保护。

    arXiv:2403.07865v1 Announce Type: cross  Abstract: The rapid advancement of Large Language Models (LLMs) has brought about remarkable capabilities in natural language processing but also raised concerns about their potential misuse. While strategies like supervised fine-tuning and reinforcement learning from human feedback have enhanced their safety, these methods primarily focus on natural languages, which may not generalize to other domains. This paper introduces CodeAttack, a framework that transforms natural language inputs into code inputs, presenting a novel environment for testing the safety generalization of LLMs. Our comprehensive studies on state-of-the-art LLMs including GPT-4, Claude-2, and Llama-2 series reveal a common safety vulnerability of these models against code input: CodeAttack consistently bypasses the safety guardrails of all models more than 80\% of the time. Furthermore, we find that a larger distribution gap between CodeAttack and natural language leads to we
    
[^16]: 通过知识种子指导大型语言模型的临床推理

    Guiding Clinical Reasoning with Large Language Models via Knowledge Seeds

    [https://arxiv.org/abs/2403.06609](https://arxiv.org/abs/2403.06609)

    大型语言模型在临床推理中展现出潜力，但存在幻觉问题和与医生决策路径不一致的挑战。

    

    临床推理是医生在评估和管理患者时采用的认知过程。这个过程通常涉及建议必要的检查，诊断患者疾病，并决定适当的治疗等。准确的临床推理需要广泛的医学知识和丰富的临床经验，为医生设置了很高的门槛。最近，像ChatGPT和GPT-4这样的大型语言模型(LLMs)显示出在临床推理中的潜力。然而，这些LLMs容易出现幻觉问题，而LLMs的推理过程可能与医生的临床决策路径不一致。在这项研究中，我们引入了一种

    arXiv:2403.06609v1 Announce Type: cross  Abstract: Clinical reasoning refers to the cognitive process that physicians employ in evaluating and managing patients. This process typically involves suggesting necessary examinations, diagnosing patients' diseases, and deciding on appropriate therapies, etc. Accurate clinical reasoning requires extensive medical knowledge and rich clinical experience, setting a high bar for physicians. This is particularly challenging in developing countries due to the overwhelming number of patients and limited physician resources, contributing significantly to global health inequity and necessitating automated clinical reasoning approaches. Recently, the emergence of large language models (LLMs) such as ChatGPT and GPT-4 have demonstrated their potential in clinical reasoning. However, these LLMs are prone to hallucination problems, and the reasoning process of LLMs may not align with the clinical decision path of physicians. In this study, we introduce a 
    
[^17]: 基于大型语言模型内部状态的无监督实时幻觉检测

    Unsupervised Real-Time Hallucination Detection based on the Internal States of Large Language Models

    [https://arxiv.org/abs/2403.06448](https://arxiv.org/abs/2403.06448)

    提出了一种利用大型语言模型内部状态进行实时幻觉检测的无监督训练框架，并引入了一个新的基准用于评估多个大型语言模型的幻觉检测。

    

    大型语言模型中的幻觉是指产生连贯但事实不准确的响应。为了解决LLMs中幻觉的问题，本文提出了MIND，一种利用LLMs内部状态进行实时幻觉检测的无监督训练框架。同时，我们还提出了HELM，一个用于评估多个LLMs幻觉检测的新基准，在LLMs推理过程中具有多样化的LLM输出和内部状态。

    arXiv:2403.06448v1 Announce Type: cross  Abstract: Hallucinations in large language models (LLMs) refer to the phenomenon of LLMs producing responses that are coherent yet factually inaccurate. This issue undermines the effectiveness of LLMs in practical applications, necessitating research into detecting and mitigating hallucinations of LLMs. Previous studies have mainly concentrated on post-processing techniques for hallucination detection, which tend to be computationally intensive and limited in effectiveness due to their separation from the LLM's inference process. To overcome these limitations, we introduce MIND, an unsupervised training framework that leverages the internal states of LLMs for real-time hallucination detection without requiring manual annotations. Additionally, we present HELM, a new benchmark for evaluating hallucination detection across multiple LLMs, featuring diverse LLM outputs and the internal states of LLMs during their inference process. Our experiments d
    
[^18]: 学习最大化互信息进行思维链提炼

    Learning to Maximize Mutual Information for Chain-of-Thought Distillation

    [https://arxiv.org/abs/2403.03348](https://arxiv.org/abs/2403.03348)

    通过最大化两个任务的表示特征的互信息，提出了一种解决思维链蒸馏中标签预测任务与知识集成不足问题的变分方法。

    

    知识蒸馏是将大型复杂模型的知识传递给较小模型的技术，是实现高效人工智能部署的关键一步。通过利用思维链 (CoT) 蒸馏的新方法——逐步蒸馏 (DSS)，已经展示出为较小模型赋予其较大同行的优越推理能力的潜力。在DSS中，蒸馏模型通过一个多任务学习框架同时获得生成理由和预测标签的能力。然而，DSS忽略了这两个训练任务之间的内在关系，导致CoT知识与标签预测任务的有效整合不足。为此，我们从信息瓶颈的角度研究了两个任务之间的相互关系，并将其表述为最大化两个任务的表示特征的互信息。我们提出了一种变分方法来解决这个问题。

    arXiv:2403.03348v1 Announce Type: cross  Abstract: Knowledge distillation, the technique of transferring knowledge from large, complex models to smaller ones, marks a pivotal step towards efficient AI deployment. Distilling Step-by-Step (DSS), a novel method utilizing chain-of-thought (CoT) distillation, has demonstrated promise by imbuing smaller models with the superior reasoning capabilities of their larger counterparts. In DSS, the distilled model acquires the ability to generate rationales and predict labels concurrently through a multi-task learning framework. However, DSS overlooks the intrinsic relationship between the two training tasks, leading to ineffective integration of CoT knowledge with the task of label prediction. To this end, we investigate the mutual relationship of the two tasks from Information Bottleneck perspective and formulate it as maximizing the mutual information of the representation features of the two tasks. We propose a variational approach to solve thi
    
[^19]: 通过自适应焦点对比解码减少对象幻觉：HALC

    HALC: Object Hallucination Reduction via Adaptive Focal-Contrast Decoding

    [https://arxiv.org/abs/2403.00425](https://arxiv.org/abs/2403.00425)

    HALC是一种旨在减少大型视觉-语言模型中对象幻觉的新颖解码算法，通过局部的自动聚焦基准机制和全局的波束搜索算法，成功减少OH而保持文本生成质量，同时可以作为即插即用模块集成到任何LVLMs中。

    

    在解释多模态环境方面，大型视觉-语言模型（LVLMs）展现了令人印象深刻的能力，但它们不可避免地会受到对象幻觉（OH）的困扰。我们介绍了HALC，这是一种新颖的解码算法，旨在减少LVLMs中的OH。HALC利用视觉-语言任务中独特的细粒度最佳视觉信息，并同时在局部和全局上操作。具体来说，HALC集成了一个强大的自动聚焦基准机制（局部），在运行时纠正产生幻觉的标记，以及一种专门的波束搜索算法（全局），以显着减少OH，同时保持文本生成质量。此外，HALC可以作为即插即用模块集成到任何LVLMs中，无需额外训练。大量实验研究证明了HALC在减少OH方面的有效性，优于四个基准测试中的现有技术。

    arXiv:2403.00425v1 Announce Type: cross  Abstract: While large vision-language models (LVLMs) have demonstrated impressive capabilities in interpreting multi-modal contexts, they invariably suffer from object hallucinations (OH). We introduce HALC, a novel decoding algorithm designed to mitigate OH in LVLMs. HALC leverages distinct fine-grained optimal visual information in vision-language tasks and operates on both local and global contexts simultaneously. Specifically, HALC integrates a robust auto-focal grounding mechanism (locally) to correct hallucinated tokens on the fly, and a specialized beam search algorithm (globally) to significantly reduce OH while preserving text generation quality. Additionally, HALC can be integrated into any LVLMs as a plug-and-play module without extra training. Extensive experimental studies demonstrate the effectiveness of HALC in reducing OH, outperforming state-of-the-arts across four benchmarks.
    
[^20]: 提升大型语言模型的上下文长度泛化能力：共振 RoPE

    Resonance RoPE: Improving Context Length Generalization of Large Language Models

    [https://arxiv.org/abs/2403.00071](https://arxiv.org/abs/2403.00071)

    Resonance RoPE是一种新颖方法，通过调整RoPE特征的插值来缩小训练短-测试长场景下的泛化差距，在不增加额外在线计算成本的情况下显著提高模型性能。

    

    本文针对大型语言模型（LLMs）中的训练短-测试长（TSTL）场景挑战，引入了Rotary Position Embedding（RoPE）技术，解决了在较短序列上预训练的模型在较长序列中遇到位置超出分布（OOD）的困难。我们提出了Resonance RoPE，一种新颖的方法，通过精细调整RoPE特征的插值来缩小TSTL场景中的泛化差距，显著提高了模型性能，而无需额外的在线计算成本。此外，我们提出了PosGen，这是一个新的合成基准，专门针对TSTL场景中的精细行为分析，旨在从长上下文中不断增加的令牌生成困难和识别新令牌位置的挑战中分离出来。我们在合成任务上的实验表明，在应用Resonance RoPE后，Transformer模型可以识别OOD位置。

    arXiv:2403.00071v1 Announce Type: cross  Abstract: This paper addresses the challenge of train-short-test-long (TSTL) scenarios in Large Language Models (LLMs) equipped with Rotary Position Embedding (RoPE), where models pre-trained on shorter sequences face difficulty with out-of-distribution (OOD) token positions in longer sequences. We introduce Resonance RoPE, a novel approach designed to narrow the generalization gap in TSTL scenarios by refining the interpolation of RoPE features for OOD positions, significantly improving the model performance without additional online computational costs. Furthermore, we present PosGen, a new synthetic benchmark specifically designed for fine-grained behavior analysis in TSTL scenarios, aiming to isolate the constantly increasing difficulty of token generation on long contexts from the challenges of recognizing new token positions. Our experiments on synthetic tasks show that after applying Resonance RoPE, Transformers recognize OOD position bet
    
[^21]: 多头softmax注意力机制在上下文学习中的训练动态：涌现、收敛和最优性

    Training Dynamics of Multi-Head Softmax Attention for In-Context Learning: Emergence, Convergence, and Optimality

    [https://arxiv.org/abs/2402.19442](https://arxiv.org/abs/2402.19442)

    研究了多头softmax注意力模型在上下文学习中的训练动态，证明了全局收敛性，并发现了“任务分配”现象，梯度流动分为热身、涌现和收敛三个阶段，最终证明了梯度流的最优性。

    

    我们研究了用于上下文学习的多任务线性回归的多头softmax注意力模型的梯度流动力学。我们证明了在适当的初始化选择下，梯度流动的全局收敛性。此外，我们证明了在梯度流动动力学中出现了有趣的“任务分配”现象，每个注意力头都专注于解决多任务模型中的单个任务。具体而言，我们证明了梯度流动动力学可以分为三个阶段——热身阶段，在这个阶段损失减少速度较慢，注意力头逐渐倾向于各自的任务；涌现阶段，在这个阶段，每个头选择一个单独的任务，损失迅速减少；和收敛阶段，在这个阶段，注意力参数收敛到一个极限。此外，我们证明了梯度流在学习极限模型方面的最优性。

    arXiv:2402.19442v1 Announce Type: cross  Abstract: We study the dynamics of gradient flow for training a multi-head softmax attention model for in-context learning of multi-task linear regression. We establish the global convergence of gradient flow under suitable choices of initialization. In addition, we prove that an interesting "task allocation" phenomenon emerges during the gradient flow dynamics, where each attention head focuses on solving a single task of the multi-task model. Specifically, we prove that the gradient flow dynamics can be split into three phases -- a warm-up phase where the loss decreases rather slowly and the attention heads gradually build up their inclination towards individual tasks, an emergence phase where each head selects a single task and the loss rapidly decreases, and a convergence phase where the attention parameters converge to a limit. Furthermore, we prove the optimality of gradient flow in the sense that the limiting model learned by gradient flo
    
[^22]: 动力系统重构中的跨领域泛化

    Out-of-Domain Generalization in Dynamical Systems Reconstruction

    [https://arxiv.org/abs/2402.18377](https://arxiv.org/abs/2402.18377)

    该论文提供了一个解决动力系统重构中泛化问题的正式框架, 并阐述了跨领域泛化在DSR中与机器学习其他领域的不同之处

    

    在科学中，我们致力于找到在经验现象背后的控制方程和动力规则。传统上，科学模型是通过人类洞察和实验周期推导出来的，最近深度学习技术已经被用来直接从时间序列数据中重构动力系统（DS）。最先进的动力系统重构（DSR）方法在捕捉观察到的DS的不变和长期特性方面表现出前景，但它们泛化到未观察领域的能力仍然是一个待解决的挑战。然而，这是我们期望从任何可行的科学理论中获得的至关重要的属性。在这项工作中，我们提供了一个正式框架，用于解决DSR中的泛化问题。我们解释了为什么以及如何DSR中的跨领域（OOD）泛化（OODG）与其他机器学习领域中考虑的OODG有根本区别。我们介绍基于拓扑概念和符号的数学概念，并说明

    arXiv:2402.18377v1 Announce Type: new  Abstract: In science we are interested in finding the governing equations, the dynamical rules, underlying empirical phenomena. While traditionally scientific models are derived through cycles of human insight and experimentation, recently deep learning (DL) techniques have been advanced to reconstruct dynamical systems (DS) directly from time series data. State-of-the-art dynamical systems reconstruction (DSR) methods show promise in capturing invariant and long-term properties of observed DS, but their ability to generalize to unobserved domains remains an open challenge. Yet, this is a crucial property we would expect from any viable scientific theory. In this work, we provide a formal framework that addresses generalization in DSR. We explain why and how out-of-domain (OOD) generalization (OODG) in DSR profoundly differs from OODG considered elsewhere in machine learning. We introduce mathematical notions based on topological concepts and ergo
    
[^23]: 通过伪装和重构在少量查询中越狱大型语言模型

    Making Them Ask and Answer: Jailbreaking Large Language Models in Few Queries via Disguise and Reconstruction

    [https://arxiv.org/abs/2402.18104](https://arxiv.org/abs/2402.18104)

    通过伪装和重构攻击方法，我们提出了一种在大型语言模型中越狱的方法，通过成功隐藏有害指令并引导模型重构原指令，取得了90%的攻击成功率。

    

    近年来，大型语言模型（LLMs）在各种任务中取得显著成功，但LLMs的可信度仍然是一个未解之谜。其中一个特定的威胁是可能生成有毒或有害的回应。攻击者可以制作有针对性的提示，诱使LLMs生成有害的回应。在这项工作中，我们通过识别在安全微调中的偏见漏洞，开创了LLMs安全领域的理论基础，并设计了一种名为DRA（伪装和重构攻击）的黑盒越狱方法，通过伪装来隐藏有害指令，并提示模型在完成过程中重构原始有害指令。我们评估了DRA在各种开源和闭源模型上的表现，展示了最先进的越狱成功率和攻击效率。值得注意的是，DRA在LLM聊天机器人GPT-4上拥有90\%的攻击成功率。

    arXiv:2402.18104v1 Announce Type: cross  Abstract: In recent years, large language models (LLMs) have demonstrated notable success across various tasks, but the trustworthiness of LLMs is still an open problem. One specific threat is the potential to generate toxic or harmful responses. Attackers can craft adversarial prompts that induce harmful responses from LLMs. In this work, we pioneer a theoretical foundation in LLMs security by identifying bias vulnerabilities within the safety fine-tuning and design a black-box jailbreak method named DRA (Disguise and Reconstruction Attack), which conceals harmful instructions through disguise and prompts the model to reconstruct the original harmful instruction within its completion. We evaluate DRA across various open-source and close-source models, showcasing state-of-the-art jailbreak success rates and attack efficiency. Notably, DRA boasts a 90\% attack success rate on LLM chatbots GPT-4.
    
[^24]: 当你的AI欺骗你：在奖励学习中人类评估者部分可观测性的挑战

    When Your AI Deceives You: Challenges with Partial Observability of Human Evaluators in Reward Learning

    [https://arxiv.org/abs/2402.17747](https://arxiv.org/abs/2402.17747)

    RLHF在考虑部分观察性时可能导致策略欺骗性地夸大性能或过度辩护行为，我们提出了数学条件来解决这些问题，并警告不要盲目应用RLHF在部分可观测情况下。

    

    强化学习从人类反馈（RLHF）的过去分析假设人类完全观察到环境。当人类反馈仅基于部分观察时会发生什么？我们对两种失败情况进行了正式定义：欺骗和过度辩护。通过将人类建模为对轨迹信念的Boltzmann-理性，我们证明了RLHF保证会导致策略欺骗性地夸大其性能、为了留下印象而过度辩护或者两者兼而有之的条件。为了帮助解决这些问题，我们数学地刻画了环境部分可观测性如何转化为（缺乏）学到的回报函数中的模糊性。在某些情况下，考虑环境部分可观测性使得在理论上可能恢复回报函数和最优策略，而在其他情况下，存在不可减少的模糊性。我们警告不要盲目应用RLHF在部分可观测情况下。

    arXiv:2402.17747v1 Announce Type: cross  Abstract: Past analyses of reinforcement learning from human feedback (RLHF) assume that the human fully observes the environment. What happens when human feedback is based only on partial observations? We formally define two failure cases: deception and overjustification. Modeling the human as Boltzmann-rational w.r.t. a belief over trajectories, we prove conditions under which RLHF is guaranteed to result in policies that deceptively inflate their performance, overjustify their behavior to make an impression, or both. To help address these issues, we mathematically characterize how partial observability of the environment translates into (lack of) ambiguity in the learned return function. In some cases, accounting for partial observability makes it theoretically possible to recover the return function and thus the optimal policy, while in other cases, there is irreducible ambiguity. We caution against blindly applying RLHF in partially observa
    
[^25]: LLMs是否具备基于数据的统计和因果推理能力？用数据对先进的定量推理进行基准测试

    Are LLMs Capable of Data-based Statistical and Causal Reasoning? Benchmarking Advanced Quantitative Reasoning with Data

    [https://arxiv.org/abs/2402.17644](https://arxiv.org/abs/2402.17644)

    本研究引入了QRData基准测试，评估了大型语言模型在统计和因果推理方面的能力，结果显示最强模型GPT-4在该测试中准确率为58％，存在改进空间。

    

    量化推理是分析数据的关键技能，然而对这种能力的评估仍然有限。为了填补这一空白，我们引入了Quantitative Reasoning with Data（QRData）基准测试，旨在评估大型语言模型在统计和因果推理方面与现实世界数据的能力。该基准测试包括一个精心构建的包含来自教科书、在线学习材料和学术论文的数据表的411个问题的数据集。为了比较模型在数据和文本上的定量推理能力，我们还在基准测试中添加了一个包含290个仅文本问题的辅助数据集，即QRText。我们评估了自然语言推理、基于程序推理和代理推理方法，包括Chain-of-Thought、Program-of-Thoughts、ReAct和代码解释器辅助等在各种模型上的表现。最强的模型GPT-4的准确率达到了58％，但仍有很大的改进空间。

    arXiv:2402.17644v1 Announce Type: cross  Abstract: Quantitative reasoning is a critical skill to analyze data, yet the assessment of such ability remains limited. To address this gap, we introduce the Quantitative Reasoning with Data (QRData) benchmark, aiming to evaluate Large Language Models' capability in statistical and causal reasoning with real-world data. The benchmark comprises a carefully constructed dataset of 411 questions accompanied by data sheets from textbooks, online learning materials, and academic papers. To compare models' quantitative reasoning abilities on data and text, we enrich the benchmark with an auxiliary set of 290 text-only questions, namely QRText. We evaluate natural language reasoning, program-based reasoning, and agent reasoning methods including Chain-of-Thought, Program-of-Thoughts, ReAct, and code interpreter assistants on diverse models. The strongest model GPT-4 achieves an accuracy of 58%, which has a large room for improvement. Among open-source
    
[^26]: 法语医用口罩语言模型中的标记化有多重要？

    How Important Is Tokenization in French Medical Masked Language Models?

    [https://arxiv.org/abs/2402.15010](https://arxiv.org/abs/2402.15010)

    子词标记化成为自然语言处理领域的主流标准，但其成功因素，如不同任务和语言的最佳分割粒度、数据源对标记工具的影响以及形态信息在印欧语言中的作用，仍不明确。

    

    近年来，基于子词的标记化已成为自然语言处理（NLP）领域中的主流标准，主要是由于预训练语言模型的广泛应用。然而，导致其成功的确切因素，如不同任务和语言的最佳分割粒度，数据源对标记工具的影响以及形态信息在印欧语言中的作用，仍然不够清楚。这在生物医学术语方面尤为重要，其特点是具有管理形态素组合的特定规则。

    arXiv:2402.15010v1 Announce Type: cross  Abstract: Subword tokenization has become the prevailing standard in the field of natural language processing (NLP) over recent years, primarily due to the widespread utilization of pre-trained language models. This shift began with Byte-Pair Encoding (BPE) and was later followed by the adoption of SentencePiece and WordPiece. While subword tokenization consistently outperforms character and word-level tokenization, the precise factors contributing to its success remain unclear. Key aspects such as the optimal segmentation granularity for diverse tasks and languages, the influence of data sources on tokenizers, and the role of morphological information in Indo-European languages remain insufficiently explored. This is particularly pertinent for biomedical terminology, characterized by specific rules governing morpheme combinations. Despite the agglutinative nature of biomedical terminology, existing language models do not explicitly incorporate 
    
[^27]: GenCeption：使用未标记的单模态数据评估多模态LLM

    GenCeption: Evaluate Multimodal LLMs with Unlabeled Unimodal Data

    [https://arxiv.org/abs/2402.14973](https://arxiv.org/abs/2402.14973)

    提出了一种名为GenCeption的新型MLLM评估框架，可以仅利用单模态数据评估跨模态语义一致性，并有效反映模型产生幻觉的倾向，具有较强的相关性和潜力于流行的MLLM基准结果。

    

    多模态大型语言模型（MLLMs）通常使用昂贵的带标注的多模态基准进行评估。然而，这些基准通常难以跟上MLLM评估的快速发展要求。我们提出了GenCeption，这是一个新颖的无需注释的MLLM评估框架，仅需要单模态数据来评估跨模态语义一致性，并反映出模型产生幻觉的倾向。类似于流行的DrawCeption游戏，GenCeption从一个非文本样本开始，并经历一系列迭代的描述和生成步骤。迭代之间的语义漂移使用GC@T指标进行量化。我们的实证发现验证了GenCeption的有效性，并显示出与流行的MLLM基准结果的强相关性。GenCeption可以通过利用普遍存在且以前未见的单模态数据来扩展，以减轻训练数据的污染。

    arXiv:2402.14973v1 Announce Type: cross  Abstract: Multimodal Large Language Models (MLLMs) are commonly evaluated using costly annotated multimodal benchmarks. However, these benchmarks often struggle to keep pace with the rapidly advancing requirements of MLLM evaluation. We propose GenCeption, a novel and annotation-free MLLM evaluation framework that merely requires unimodal data to assess inter-modality semantic coherence and inversely reflects the models' inclination to hallucinate. Analogous to the popular DrawCeption game, GenCeption initiates with a non-textual sample and undergoes a series of iterative description and generation steps. Semantic drift across iterations is quantified using the GC@T metric. Our empirical findings validate GenCeption's efficacy, showing strong correlations with popular MLLM benchmarking results. GenCeption may be extended to mitigate training data contamination by utilizing ubiquitous, previously unseen unimodal data.
    
[^28]: 在没有基准实况的情况下对大型语言模型进行排名

    Ranking Large Language Models without Ground Truth

    [https://arxiv.org/abs/2402.14860](https://arxiv.org/abs/2402.14860)

    不需要基准实况或参考响应的条件下，通过考虑模型的三元组来排名大型语言模型，并提出了两种排名方法。

    

    随着大型语言模型（LLMs）的普及和影响力的增强，评估和排名LLMs已成为一个重要问题。现有的评估方法要么需要获取昂贵的人类响应，要么使用LLMs成对地互相评估，这可能不够可靠。本文提供了一个新的视角，在给定一组提示数据集（比如问题、说明等）和一组LLMs的情况下，我们在没有任何基准实况或参考响应的情况下对它们进行排名。受到现实生活的启发，其中专家和有知识的人都能识别一个新手，我们的主要思路是考虑模型的三元组，其中每个模型评估其他两个模型，能够以很高的概率正确识别最差的模型。我们还分析了我们的想法并提供了成功的充分条件。通过反复应用这一想法，我们提出了两种对LLMs进行排名的方法。

    arXiv:2402.14860v1 Announce Type: cross  Abstract: Evaluation and ranking of large language models (LLMs) has become an important problem with the proliferation of these models and their impact. Evaluation methods either require human responses which are expensive to acquire or use pairs of LLMs to evaluate each other which can be unreliable. In this paper, we provide a novel perspective where, given a dataset of prompts (viz. questions, instructions, etc.) and a set of LLMs, we rank them without access to any ground truth or reference responses. Inspired by real life where both an expert and a knowledgeable person can identify a novice our main idea is to consider triplets of models, where each one of them evaluates the other two, correctly identifying the worst model in the triplet with high probability. We also analyze our idea and provide sufficient conditions for it to succeed. Applying this idea repeatedly, we propose two methods to rank LLMs. In experiments on different generati
    
[^29]: CounterCurate: 通过对照例子增强物理和语义视觉-语言组合推理能力

    CounterCurate: Enhancing Physical and Semantic Visio-Linguistic Compositional Reasoning via Counterfactual Examples

    [https://arxiv.org/abs/2402.13254](https://arxiv.org/abs/2402.13254)

    本研究提出CounterCurate框架，通过对比例子和生成式微调，全面提升视觉-语言组合推理能力，解决了物理推理和语义对照微调方面的关键问题，实现了显著性能改进。

    

    我们提出CounterCurate，一个框架，全面提升对比和生成式多模态模型的视觉-语言组合推理能力。特别地，我们确定了两个尚未充分探讨的关键问题：忽视了基于物理的推理（计数和位置理解），以及利用高性能文本和图像生成模型进行语义反事实微调的潜力。我们的工作开创了一个解决这些空白的方法。我们首先突出了多模态模型（如CLIP和LLaVA）在基于物理的组合推理中几乎无法胜任的表现。然后，我们应用简单的数据增强，使用基于图像的生成模型GLIGEN生成微调数据，使得性能显著提高：在我们新的策划的Flickr30k-Positions基准测试中，CLIP和LLaVA的性能分别提高了+33%和+37%。此外，我们利用了高性能文本和图像生成模型的能力。

    arXiv:2402.13254v1 Announce Type: cross  Abstract: We propose CounterCurate, a framework to comprehensively improve the visio-linguistic compositional reasoning capability for both contrastive and generative multimodal models. In particular, we identify two under-explored critical problems: the neglect of the physically grounded reasoning (counting and position understanding) and the potential of using highly capable text and image generation models for semantic counterfactual fine-tuning. Our work pioneers an approach that addresses these gaps. We first spotlight the near-chance performance of multimodal models like CLIP and LLaVA in physically grounded compositional reasoning. We then apply simple data augmentation using a grounded image generation model, GLIGEN, to generate finetuning data, resulting in significant performance improvements: +33% and +37% for CLIP and LLaVA, respectively, on our newly curated Flickr30k-Positions benchmark. Moreover, we exploit the capabilities of hig
    
[^30]: 通过博弈论评估揭示LLM的战略推理局限性的GTBench

    GTBench: Uncovering the Strategic Reasoning Limitations of LLMs via Game-Theoretic Evaluations

    [https://arxiv.org/abs/2402.12348](https://arxiv.org/abs/2402.12348)

    该论文通过博弈论任务评估了LLMs在竞争环境中的推理能力，观察到LLMs在不同游戏场景下表现出不同行为，具有重要的战略推理局限性。

    

    随着大型语言模型（LLMs）被整合到关键的现实世界应用中，它们的战略和逻辑推理能力变得越来越关键。本文通过博弈论任务评估LLMs在竞争环境中的推理能力，例如，需要纯逻辑和战略推理来与对手竞争的棋盘游戏和纸牌游戏。我们首先提出了GTBench，这是一个以语言驱动的环境，包括10个广泛认可的任务，涵盖了全面的游戏分类法：完整信息与不完整信息，动态与静态，以及概率与确定性场景。然后，我们研究了两个关键问题：（1）表征LLMs的博弈论推理；（2）LLM对抗LLM的比赛作为推理评估。我们观察到（1）LLMs在各种游戏场景下有不同的行为；例如，LLMs在完整和确定性游戏中失败，但它们在概率游戏中具有竞争力。

    arXiv:2402.12348v1 Announce Type: cross  Abstract: As Large Language Models (LLMs) are integrated into critical real-world applications, their strategic and logical reasoning abilities are increasingly crucial. This paper evaluates LLMs' reasoning abilities in competitive environments through game-theoretic tasks, e.g., board and card games that require pure logic and strategic reasoning to compete with opponents. We first propose GTBench, a language-driven environment composing 10 widely-recognized tasks, across a comprehensive game taxonomy: complete versus incomplete information, dynamic versus static, and probabilistic versus deterministic scenarios. Then, we investigate two key problems: (1) Characterizing game-theoretic reasoning of LLMs; (2) LLM-vs-LLM competitions as reasoning evaluation. We observe that (1) LLMs have distinct behaviors regarding various gaming scenarios; for example, LLMs fail in complete and deterministic games yet they are competitive in probabilistic gaming
    
[^31]: 为无监督环境设计优化极小化遗憾

    Refining Minimax Regret for Unsupervised Environment Design

    [https://arxiv.org/abs/2402.12284](https://arxiv.org/abs/2402.12284)

    介绍了贝叶斯级别完美的MMR（BLP），它是极小化遗憾目标的精确化，能够克服极小化遗憾策略在遗憾上界时学习停滞的限制。

    

    在无监督环境设计中，强化学习代理通过对对手最大化某个目标生成的环境配置（关卡）进行训练。遗憾是一种常用的目标，理论上导致具有良好鲁棒性保证的极小化遗憾（MMR）策略；特别是，代理的最大遗憾是有界的。然而，一旦代理在所有关卡上达到了这个遗憾上界，对手将只会对无法进一步减少遗憾的关卡进行采样。尽管在这些最大化遗憾的关卡之外可能存在性能改进空间，但学习停滞。在这项工作中，我们介绍了贝叶斯级别完美的MMR（BLP），它是极小化遗憾目标的精确化。我们正式证明，解决这个目标将导致MMR策略的子集，并且BLP策略在所有关卡上都与完美贝叶斯策略一致行事。

    arXiv:2402.12284v1 Announce Type: cross  Abstract: In unsupervised environment design, reinforcement learning agents are trained on environment configurations (levels) generated by an adversary that maximises some objective. Regret is a commonly used objective that theoretically results in a minimax regret (MMR) policy with desirable robustness guarantees; in particular, the agent's maximum regret is bounded. However, once the agent reaches this regret bound on all levels, the adversary will only sample levels where regret cannot be further reduced. Although there are possible performance improvements to be made outside of these regret-maximising levels, learning stagnates. In this work, we introduce Bayesian level-perfect MMR (BLP), a refinement of the minimax regret objective that overcomes this limitation. We formally show that solving for this objective results in a subset of MMR policies, and that BLP policies act consistently with a Perfect Bayesian policy over all levels. We fur
    
[^32]: LLM作为提示器：在任意知识图上进行低资源归纳推理

    LLM as Prompter: Low-resource Inductive Reasoning on Arbitrary Knowledge Graphs

    [https://arxiv.org/abs/2402.11804](https://arxiv.org/abs/2402.11804)

    本文利用大型语言模型（LLMs）生成图形结构提示，以增强预训练的图神经网络（GNNs），提出一种新的方法论见解，实现了在任意知识图上进行低资源归纳推理的高通用性。

    

    知识图（KG）归纳推理旨在推断训练期间未见过的新KG中缺失的事实，在各种应用中被广泛采用。KG归纳推理的一个关键挑战是处理在文本和结构方面都稀缺的低资源场景。本文尝试利用大型语言模型（LLMs）来解决这一挑战。具体来说，我们利用最先进的LLMs生成图形结构提示，以增强预训练的图神经网络（GNNs），从而为KG归纳推理方法带来新的方法论见解，以及在实践中具有很高的普适性。在方法论方面，我们引入了一种新颖的预训练和提示框架ProLINK，旨在在任意KG上进行低资源归纳推理，而无需额外训练。在实践方面，我们在36个低资源数据集上对我们的方法进行了实验评估。

    arXiv:2402.11804v1 Announce Type: new  Abstract: Knowledge Graph (KG) inductive reasoning, which aims to infer missing facts from new KGs that are not seen during training, has been widely adopted in various applications. One critical challenge of KG inductive reasoning is handling low-resource scenarios with scarcity in both textual and structural aspects. In this paper, we attempt to address this challenge with Large Language Models (LLMs). Particularly, we utilize the state-of-the-art LLMs to generate a graph-structural prompt to enhance the pre-trained Graph Neural Networks (GNNs), which brings us new methodological insights into the KG inductive reasoning methods, as well as high generalizability in practice. On the methodological side, we introduce a novel pretraining and prompting framework ProLINK, designed for low-resource inductive reasoning across arbitrary KGs without requiring additional training. On the practical side, we experimentally evaluate our approach on 36 low-res
    
[^33]: 在不修改语言模型的情况下训练语言模型代理

    Training Language Model Agents without Modifying Language Models

    [https://arxiv.org/abs/2402.11359](https://arxiv.org/abs/2402.11359)

    提出一种新的方法，在不修改语言模型的情况下训练语言模型代理，通过进化代理的功能来解决下游任务

    

    研究人员和实践者最近已经将强大的大型语言模型（LLMs）重新定义为代理，使它们能够通过使用专门的功能自动化地完成复杂任务。为了促进LLM代理的发展，我们提出了一种在不修改LLM权重的情况下训练LLM代理的新范式，当LLM难以或无法进行修改时尤其有用。受到人类不断锻造工具以适应现实任务的启发，而不是改变我们的生物结构以适应一组静态工具，我们提出逐步锻造代理的功能，以更好地解决下游任务，而不是修改LLM权重。通过将这些功能视为可学习的“代理参数”并利用人工智能模型训练的基本思想，我们开发了AgentOptimizer，利用LLM更新代理的功能，并设计了一种代理训练算法

    arXiv:2402.11359v1 Announce Type: new  Abstract: Researchers and practitioners have recently reframed powerful Large Language Models (LLMs) as agents, enabling them to automate complex tasks largely via the use of specialized functions. To facilitate the development of LLM agents, we present a novel paradigm of training LLM agents without modifying the LLM weights, which is particularly useful when the LLMs are difficult or inaccessible for modifications. Inspired by how humans continuously forge tools to adapt to real-world tasks, rather than change our biological structure to fit a static set of tools, we propose to progressively forge agent's functions to better solve the downstream tasks instead of modifying the LLM weights. By treating the functions as learnable `agent parameters' and leveraging the fundamental idea of model training in artificial intelligence, we develop AgentOptimizer that employs the LLM to update agents' functions and devise an agent training algorithm with tw
    
[^34]: 基于图的时空降采样缺失数据预测

    Graph-based Forecasting with Missing Data through Spatiotemporal Downsampling

    [https://arxiv.org/abs/2402.10634](https://arxiv.org/abs/2402.10634)

    通过 hierarchical spatiotemporal downsampling 处理缺失数据问题，结合可解释的注意机制，实现对时空预测的有效建模

    

    给定一组与空间中传感器点相关联、具有相互关系的同步时间序列，时空预测问题包括为每个点预测未来观测值。时空图神经网络通过将时间序列表示为图来实现引人注目的结果。然而，大多数现有方法依赖于一个常常不切实际的假设，即输入始终可用，并且在数据部分缺失时无法捕捉隐藏的时空动态。在这项工作中，我们通过分层时空降采样来解决这个问题。输入时间序列随着时间和空间的推移逐渐粗化，获得一组捕捉异质时间和空间动态的表示。在观测值和缺失数据模式的条件下，通过一个可解释的注意机制来组合这些表示以生成

    arXiv:2402.10634v1 Announce Type: cross  Abstract: Given a set of synchronous time series, each associated with a sensor-point in space and characterized by inter-series relationships, the problem of spatiotemporal forecasting consists of predicting future observations for each point. Spatiotemporal graph neural networks achieve striking results by representing the relationships across time series as a graph. Nonetheless, most existing methods rely on the often unrealistic assumption that inputs are always available and fail to capture hidden spatiotemporal dynamics when part of the data is missing. In this work, we tackle this problem through hierarchical spatiotemporal downsampling. The input time series are progressively coarsened over time and space, obtaining a pool of representations that capture heterogeneous temporal and spatial dynamics. Conditioned on observations and missing data patterns, such representations are combined by an interpretable attention mechanism to generate 
    
[^35]: 通过辩论调节LLMs以生成可控的具有争议性的声明

    Can LLMs Speak For Diverse People? Tuning LLMs via Debate to Generate Controllable Controversial Statements

    [https://arxiv.org/abs/2402.10614](https://arxiv.org/abs/2402.10614)

    本文通过辩论调节LLMs，使其生成可控的支持用户定义论点的声明，改进了LLMs的可控性，并提出了DEBATunE流程。通过两个LLMs之间的多轮辩论生成高质量的训练数据，以支持生成有更高质量和更突出的声明。

    

    LLMs代表不同的人群，尤其是少数群体，并产生支持其多样化甚至有争议观点的声明对于创造一个包容的环境至关重要。然而，现有的LLMs缺乏足够的控制性来支持生成内容的立场，其中往往包含不一致、中立或有偏见的声明。在本文中，我们改进了LLMs在生成支持用户在提示中定义的论点的声明时的可控性。我们发现两个持有相反立场的LLMs之间的多轮辩论产生了更高质量和更突出的声明，这些声明对于改善LLMs的可控性是重要的训练数据。受此启发，我们开发了一种新颖的Debate & Tuning（“DEBATunE”）流程，通过微调LLMs生成通过辩论获得的声明。为了检验DEBATunE，我们整理了迄今为止涵盖710个争议性主题的最大数据集。

    arXiv:2402.10614v1 Announce Type: cross  Abstract: Making LLMs speak for different, especially minority groups of people, and generate statements supporting their diverse or even controversial perspectives is critical to creating an inclusive environment. However, existing LLMs lack sufficient controllability to the stance of their generated content, which often contains inconsistent, neutral, or biased statements. In this paper, we improve the controllability of LLMs in generating statements supporting an argument the user defined in the prompt. We find that multi-round debates between two LLMs with opposite stances generate higher-quality and more salient statements for each, which are important training data to improve the controllability of LLMs. Motivated by this, we develop a novel debate & tuning ("DEBATunE") pipeline finetuning LLMs to generate the statements obtained via debate. To examine DEBATunE, we curate the largest dataset of debate topics so far, which covers 710 contro
    
[^36]: 针对多维时间序列预测的随机投影层

    Random Projection Layers for Multidimensional Time Sires Forecasting

    [https://arxiv.org/abs/2402.10487](https://arxiv.org/abs/2402.10487)

    提出了一种全MLP时间序列预测架构RPMixer，通过将随机投影层集成到模型中，增加了块输出之间的多样性，提高了整体性能

    

    多层感知器（MLP）混合模型已被证明对时间序列预测问题有效。然而，当将此类模型应用于高维时间序列（例如空间-时间数据集中的时间序列）时，由于过拟合问题，其性能可能会下降。本文提出了一种全MLP时间序列预测架构，称为RPMixer。我们的方法利用了深度神经网络的集成式行为，其中网络中的每个单独块的作用类似于集成模型中的基本学习器，特别是在引入身份映射残差连接时。通过将随机投影层集成到我们的模型中，我们增加了块输出之间的多样性，从而提高了RPMixer的整体性能。对大规模空间-时间预测基准数据集进行的大量实验表明，我们提出的方法胜过了

    arXiv:2402.10487v1 Announce Type: cross  Abstract: All-Multi-Layer Perceptron (all-MLP) mixer models have been shown to be effective for time series forecasting problems. However, when such a model is applied to high-dimensional time series (e.g., the time series in a spatial-temporal dataset), its performance is likely to degrade due to overfitting issues. In this paper, we propose an all-MLP time series forecasting architecture, referred to as RPMixer. Our method leverages the ensemble-like behavior of deep neural networks, where each individual block within the network acts like a base learner in an ensemble model, especially when identity mapping residual connections are incorporated. By integrating random projection layers into our model, we increase the diversity among the blocks' outputs, thereby enhancing the overall performance of RPMixer. Extensive experiments conducted on large-scale spatial-temporal forecasting benchmark datasets demonstrate that our proposed method outperf
    
[^37]: BioMistral：面向医学领域的开源预训练大型语言模型集合

    BioMistral: A Collection of Open-Source Pretrained Large Language Models for Medical Domains

    [https://arxiv.org/abs/2402.10373](https://arxiv.org/abs/2402.10373)

    BioMistral是一种面向生物医学领域的开源预训练大型语言模型集合，在医学问答任务中表现出优越性能并具有竞争优势。

    

    大型语言模型（LLMs）近年来展示出卓越的多功能性，为医疗保健和医学等专业领域提供潜在应用。尽管有各种针对健康领域定制的开源LLMs可用，但将通用LLMs调整到医学领域仍面临重大挑战。本文介绍了BioMistral，一种专为生物医学领域量身定制的开源LLM，采用Mistral作为基础模型，并在PubMed Central上进一步进行预训练。我们在包含10个已建立的英文医学问答（QA）任务的基准上对BioMistral进行了全面评估。我们还探讨通过量化和模型合并方法获得的轻量级模型。我们的结果表明，BioMistral相较于现有开源医学模型具有优越性能，并与专有对手具有竞争优势。最后，为了解决

    arXiv:2402.10373v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated remarkable versatility in recent years, offering potential applications across specialized domains such as healthcare and medicine. Despite the availability of various open-source LLMs tailored for health contexts, adapting general-purpose LLMs to the medical domain presents significant challenges. In this paper, we introduce BioMistral, an open-source LLM tailored for the biomedical domain, utilizing Mistral as its foundation model and further pre-trained on PubMed Central. We conduct a comprehensive evaluation of BioMistral on a benchmark comprising 10 established medical question-answering (QA) tasks in English. We also explore lightweight models obtained through quantization and model merging approaches. Our results demonstrate BioMistral's superior performance compared to existing open-source medical models and its competitive edge against proprietary counterparts. Finally, to address
    
[^38]: 选择性反射调节：LLM指令调节的学生选择数据回收

    Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning

    [https://arxiv.org/abs/2402.10110](https://arxiv.org/abs/2402.10110)

    本文介绍了一种名为选择性反射调节的新方法，该方法通过教师LLM的反射和自省与学生LLM的数据选择能力相结合，自动优化现有的指令调节数据，从而实现了高效的指令调节和卓越性能的LLM。

    

    指令调节对于大型语言模型（LLM）来说非常关键，以实现更好的指令跟踪和任务适应能力，但其成功在很大程度上取决于训练数据的质量。许多最近的方法都致力于改进数据质量，但往往忽视了数据与正在微调的学生模型的兼容性。本文介绍了一种新的范式——选择性反射调节，通过结合教师LLM的反射和自省，以自动优化现有的指令调节数据。这种师生合作产生了高质量且与学生LLM兼容的指令响应对，从而实现了高效的指令调节和卓越性能的LLM。选择性反射调节是一种数据增强和合成方法，通常能改善LLM微调和自我优化，而无需额外的计算资源。

    arXiv:2402.10110v1 Announce Type: cross  Abstract: Instruction tuning is critical to large language models (LLMs) for achieving better instruction following and task adaptation capabilities but its success heavily relies on the training data quality. Many recent methods focus on improving the data quality but often overlook the compatibility of the data with the student model being finetuned. This paper introduces Selective Reflection-Tuning, a novel paradigm that synergizes a teacher LLM's reflection and introspection for improving existing data quality with the data selection capability of the student LLM, to automatically refine existing instruction-tuning data. This teacher-student collaboration produces high-quality and student-compatible instruction-response pairs, resulting in sample-efficient instruction tuning and LLMs of superior performance. Selective Reflection-Tuning is a data augmentation and synthesis that generally improves LLM finetuning and self-improvement without co
    
[^39]: 排列、修复和改进：通过基于内容的控制实现可操控的长期音乐音频生成和编辑

    Arrange, Inpaint, and Refine: Steerable Long-term Music Audio Generation and Editing via Content-based Controls

    [https://arxiv.org/abs/2402.09508](https://arxiv.org/abs/2402.09508)

    通过引入参数高效微调（PEFT）方法，本研究实现了自回归语言模型在音乐修复和音乐排列任务中的应用。在多个音乐编辑任务中，该方法展示了有希望的结果，并为未来的AI驱动音乐编辑工具提供了更灵活的控制。

    

    可控音乐生成在人机音乐共创中起着重要作用。虽然大型语言模型（LLM）在生成高质量音乐方面表现出了潜力，但它们对自回归生成的依赖限制了它们在音乐编辑任务中的实用性。为了弥合这一差距，我们引入了一种新颖的参数高效微调（PEFT）方法。该方法使自回归语言模型能够无缝地解决音乐修复任务。此外，我们的PEFT方法集成了基于帧级内容的控制，促进了轨道条件音乐的精炼和分数条件音乐的排列。我们将该方法应用于MusicGen，一个领先的自回归音乐生成模型的微调。我们的实验在多个音乐编辑任务中展示了有希望的结果，为未来的AI驱动音乐编辑工具提供了更灵活的控制。

    arXiv:2402.09508v1 Announce Type: cross  Abstract: Controllable music generation plays a vital role in human-AI music co-creation. While Large Language Models (LLMs) have shown promise in generating high-quality music, their focus on autoregressive generation limits their utility in music editing tasks. To bridge this gap, we introduce a novel Parameter-Efficient Fine-Tuning (PEFT) method. This approach enables autoregressive language models to seamlessly address music inpainting tasks. Additionally, our PEFT method integrates frame-level content-based controls, facilitating track-conditioned music refinement and score-conditioned music arrangement. We apply this method to fine-tune MusicGen, a leading autoregressive music generation model. Our experiments demonstrate promising results across multiple music editing tasks, offering more flexible controls for future AI-driven music editing tools. A demo page\footnote{\url{https://kikyo-16.github.io/AIR/}.} showcasing our work and source 
    
[^40]: 通过期望最大化和Turbo Deep近似消息传递的贝叶斯联邦学习

    Bayesian Federated Learning Via Expectation Maximization and Turbo Deep Approximate Message Passing

    [https://arxiv.org/abs/2402.07366](https://arxiv.org/abs/2402.07366)

    本文提出了一种基于消息传递的贝叶斯联邦学习（BFL）框架，通过结合期望最大化和Turbo Deep近似消息传递（TDAMP）实现分布式学习和压缩。该框架在处理联邦学习算法的缺点上有着显著的改进。

    

    联邦学习是一种机器学习范 paradigm，在这种范式中，客户端拥有分散的训练数据，而中央服务器则负责聚合和调度。通常情况下，联邦学习算法涉及客户端使用随机梯度下降（SGD）来训练他们的本地模型，但这带来了收敛速度较慢和容易陷入次优解的问题。在这项工作中，我们提出了一种基于消息传递的贝叶斯联邦学习（BFL）框架来避免这些缺点。具体而言，我们将深度神经网络（DNN）的学习和压缩问题建模为稀疏贝叶斯推断问题，其中采用了分组稀疏先验以实现结构化模型压缩。然后，我们提出了一种高效的 BFL 算法，名为 EMTDAMP，其中将期望最大化（EM）和 Turbo Deep 近似消息传递（TDAMP）结合起来实现分布式学习和压缩。中央服务器聚合本地后验分布以实现更新。

    Federated learning (FL) is a machine learning paradigm where the clients possess decentralized training data and the central server handles aggregation and scheduling. Typically, FL algorithms involve clients training their local models using stochastic gradient descent (SGD), which carries drawbacks such as slow convergence and being prone to getting stuck in suboptimal solutions. In this work, we propose a message passing based Bayesian federated learning (BFL) framework to avoid these drawbacks.Specifically, we formulate the problem of deep neural network (DNN) learning and compression and as a sparse Bayesian inference problem, in which group sparse prior is employed to achieve structured model compression. Then, we propose an efficient BFL algorithm called EMTDAMP, where expectation maximization (EM) and turbo deep approximate message passing (TDAMP) are combined to achieve distributed learning and compression. The central server aggregates local posterior distributions to update 
    
[^41]: 自我纠正自我消耗循环用于生成模型训练

    Self-Correcting Self-Consuming Loops for Generative Model Training

    [https://arxiv.org/abs/2402.07087](https://arxiv.org/abs/2402.07087)

    本论文研究了使用合成数据进行生成模型训练时可能出现的自我消耗循环问题，并提出了一种通过引入理想的修正函数来稳定训练的方法。同时，我们还提出了自我修正函数来近似理想的修正函数，并通过实验证实了其有效性。

    

    随着合成数据在互联网上的质量越来越高以及数量不断增加，机器学习模型越来越多地在人工和机器生成的数据的混合上进行训练。尽管使用合成数据进行表征学习的成功案例有很多，但是在生成模型训练中使用合成数据会产生"自我消耗循环"，这可能导致训练不稳定甚至崩溃，除非满足某些条件。我们的论文旨在稳定自我消耗的生成模型训练。我们的理论结果表明，通过引入一个理想的修正函数，将数据点映射为更有可能来自真实数据分布的样本，可以使自我消耗循环的稳定性呈指数增加。然后，我们提出了自我修正函数，它依赖于专家知识（例如，编程在模拟器中的物理定律），并且旨在自动且大规模地近似理想的修正函数。我们通过实验证实了自我纠正自我消耗循环在生成模型训练中的有效性。

    As synthetic data becomes higher quality and proliferates on the internet, machine learning models are increasingly trained on a mix of human- and machine-generated data. Despite the successful stories of using synthetic data for representation learning, using synthetic data for generative model training creates "self-consuming loops" which may lead to training instability or even collapse, unless certain conditions are met. Our paper aims to stabilize self-consuming generative model training. Our theoretical results demonstrate that by introducing an idealized correction function, which maps a data point to be more likely under the true data distribution, self-consuming loops can be made exponentially more stable. We then propose self-correction functions, which rely on expert knowledge (e.g. the laws of physics programmed in a simulator), and aim to approximate the idealized corrector automatically and at scale. We empirically validate the effectiveness of self-correcting self-consum
    
[^42]: 进取的鲍勃通过提示对抗调整抵制越狱行为

    Studious Bob Fight Back Against Jailbreaking via Prompt Adversarial Tuning

    [https://arxiv.org/abs/2402.06255](https://arxiv.org/abs/2402.06255)

    本文提出了一种名为Prompt Adversarial Tuning (PAT)的方法，通过训练一个防御控制机制并将其作为前缀嵌入到用户提示中，实现对大型语言模型（LLMs）的越狱行为的防御。实验证明该方法在保护LLMs免受产生有害信息的影响方面效果显著。

    

    尽管大型语言模型（LLM）在各种应用中取得了巨大的成功，但它们也容易受到特定提示的影响，从而绕过内置的安全措施并提供危险或非法内容，这种现象被称为越狱行为。为了保护LLMs免受产生有害信息的影响，提出了各种防御策略，其中大多数集中在内容过滤或模型的对抗训练方面。在本文中，我们提出了一种名为Prompt Adversarial Tuning（PAT）的方法，通过训练一个防御控制机制并将其作为前缀嵌入到用户提示中来实现我们的防御策略。我们设计了一个类似对抗训练的训练过程，以实现我们的优化目标，交替更新攻击和防御控制机制。据我们所知，我们是第一个从提示调整的角度实施防御的人。一旦应用，我们的方法几乎不会影响LLMs的操作效率。实验表明我们的方法在抵御越狱行为方面具有良好的效果。

    Although Large Language Models (LLMs) have achieved tremendous success in various applications, they are also susceptible to certain prompts that can induce them to bypass built-in safety measures and provide dangerous or illegal content, a phenomenon known as jailbreak. To protect LLMs from producing harmful information, various defense strategies are proposed, with most focusing on content filtering or adversarial training of models. In this paper, we propose an approach named Prompt Adversarial Tuning (PAT) to train a defense control mechanism, which is then embedded as a prefix to user prompts to implement our defense strategy. We design a training process similar to adversarial training to achieve our optimized goal, alternating between updating attack and defense controls. To our knowledge, we are the first to implement defense from the perspective of prompt tuning. Once employed, our method will hardly impact the operational efficiency of LLMs. Experiments show that our method i
    
[^43]: 通过基于垄断对话的社交场景模拟实现大型语言模型的自对齐

    Self-Alignment of Large Language Models via Monopolylogue-based Social Scene Simulation

    [https://arxiv.org/abs/2402.05699](https://arxiv.org/abs/2402.05699)

    本文提出了一个通过社交场景模拟来自对齐大型语言模型的方法，以减轻其被滥用造成的潜在不良影响。通过一个名为MATRIX的虚拟排练空间，LLM可以在回答查询前考虑社交后果，并通过MATRIX-simulated数据的微调，保持对人类价值的遵从和推理速度的平衡。实验证明，在温和假设下，带有MATRIX的LLM胜过了宪法AI。

    

    将大型语言模型(LLMs)与人类价值对齐，以减轻其被滥用造成的潜在不良影响，具有重要意义。本文借鉴社会学的见解，即认识到所有各方的关切是塑造人类价值观的关键因素，提出了一种自对齐LLMs的新方向：社交场景模拟。为此，我们提出了一个名为MATRIX的创新社交场景模拟器，它可以模拟用户输入查询周围的现实场景，使LLM在回答前能够考虑社交后果。MATRIX类似于一个“垄断对话”下的虚拟排练空间，LLM在其中扮演与查询相关的多个角色并进行自我实践。为了引入这种对齐能力，我们使用MATRIX模拟数据对LLM进行微调，确保其在不影响推理速度的情况下符合人类价值观。理论上，我们证明了在温和假设下，带有MATRIX的LLM胜过了宪法AI。最后，大量实验证实了我们的方法在多个任务上都取得了最佳性能。

    Aligning large language models (LLMs) with human values is imperative to mitigate potential adverse effects resulting from their misuse. Drawing from the sociological insight that acknowledging all parties' concerns is a key factor in shaping human values, this paper proposes a novel direction to align LLMs by themselves: social scene simulation. To achieve this, we present MATRIX, a novel social scene simulator that emulates realistic scenes around a user's input query, enabling the LLM to take social consequences into account before responding. MATRIX serves as a virtual rehearsal space, akin to a Monopolylogue, where the LLM performs diverse roles related to the query and practice by itself. To inject this alignment, we fine-tune the LLM with MATRIX-simulated data, ensuring adherence to human values without compromising inference speed. We theoretically show that the LLM with MATRIX outperforms Constitutional AI under mild assumptions. Finally, extensive experiments validate that ou
    
[^44]: AttnLRP: 注意力感知的逐层相关传递用于Transformer

    AttnLRP: Attention-Aware Layer-wise Relevance Propagation for Transformers

    [https://arxiv.org/abs/2402.05602](https://arxiv.org/abs/2402.05602)

    AttnLRP是首个能够忠实且全面地归因Transformer模型的输入和潜在表示，并具有与单一反向传播相似的计算效率的方法。它通过扩展逐层相关传递归因方法以处理注意力层来解决了黑盒Transformer模型的归因问题，具有超越现有方法的准确性和理解潜在表示的能力。

    

    大型语言模型容易产生偏见的预测和幻象，这突显了理解其模型内部推理过程的重要性。然而，实现对整个黑盒Transformer模型的准确归因并保持计算效率是一个尚未解决的挑战。通过扩展逐层相关传递归因方法以处理注意力层，我们有效地解决了这些挑战。虽然存在部分解决方案，但我们的方法是首个能够忠实且全面地归因Transformer模型的输入和潜在表示，同时计算效率与单一反向传播相似。通过对Llama 2、Flan-T5和Vision Transformer架构上与现有方法的广泛评估，我们证明了我们提出的方法在准确性方面超过了其他方法，并能够理解潜在表示，为概念打开了大门。

    Large Language Models are prone to biased predictions and hallucinations, underlining the paramount importance of understanding their model-internal reasoning process. However, achieving faithful attributions for the entirety of a black-box transformer model and maintaining computational efficiency is an unsolved challenge. By extending the Layer-wise Relevance Propagation attribution method to handle attention layers, we address these challenges effectively. While partial solutions exist, our method is the first to faithfully and holistically attribute not only input but also latent representations of transformer models with the computational efficiency similar to a singular backward pass. Through extensive evaluations against existing methods on Llama 2, Flan-T5 and the Vision Transformer architecture, we demonstrate that our proposed approach surpasses alternative methods in terms of faithfulness and enables the understanding of latent representations, opening up the door for concep
    
[^45]: 在交流医疗辅导上对大型语言模型进行基准测试：一种新的系统和数据集

    Benchmarking Large Language Models on Communicative Medical Coaching: a Novel System and Dataset

    [https://arxiv.org/abs/2402.05547](https://arxiv.org/abs/2402.05547)

    本研究介绍了“ChatCoach”，一个集成人工智能与人类医生合作的框架，在交流医疗辅导中利用大型语言模型，提供模拟环境和实时反馈，以帮助医学学员提高沟通技巧。

    

    在医疗保健领域，自然语言处理（NLP）的传统应用主要集中在以患者为中心的服务上，增强患者互动和护理交付，例如医学对话系统。然而，NLP在帮助经验不丰富的医生，特别是在交流医疗辅导等领域的潜力仍然很少被探索。我们引入了“ChatCoach”，一个集成的人工智能合作框架。在这个框架内，一个患者代理和一个辅导代理共同支持医学学员在会诊过程中练习医学沟通技巧。与传统的对话系统不同，ChatCoach提供了一个模拟环境，医生可以在其中与患者代理进行医学对话。同时，辅导代理会提供实时反馈给医生。为了构建ChatCoach系统，我们开发了一个数据集，并集成了ChatGPT和Llama2等大型语言模型，旨在评估它们在交流医疗辅导方面的效果。

    Traditional applications of natural language processing (NLP) in healthcare have predominantly focused on patient-centered services, enhancing patient interactions and care delivery, such as through medical dialogue systems. However, the potential of NLP to benefit inexperienced doctors, particularly in areas such as communicative medical coaching, remains largely unexplored. We introduce ``ChatCoach,'' an integrated human-AI cooperative framework. Within this framework, both a patient agent and a coaching agent collaboratively support medical learners in practicing their medical communication skills during consultations. Unlike traditional dialogue systems, ChatCoach provides a simulated environment where a human doctor can engage in medical dialogue with a patient agent. Simultaneously, a coaching agent provides real-time feedback to the doctor. To construct the ChatCoach system, we developed a dataset and integrated Large Language Models such as ChatGPT and Llama2, aiming to assess 
    
[^46]: 量化近似正交循环神经网络

    Quantized Approximately Orthogonal Recurrent Neural Networks

    [https://arxiv.org/abs/2402.04012](https://arxiv.org/abs/2402.04012)

    本文提出了量化近似正交循环神经网络（QORNNs）来解决正交循环神经网络（ORNNs）中参数过多的问题，采用一种后训练量化策略和三种融入正交约束和量化权重的量化感知训练算法，取得了与s相似的结果。

    

    正交循环神经网络（ORNN）是一种吸引人的选择，用于学习涉及具有长期依赖性的时间序列的任务，由于其简单性和计算稳定性。然而，这些网络通常需要大量参数才能表现良好，这在功率受限的环境（如紧凑设备）中可能是阻碍因素。解决这个问题的一种方法是神经网络量化。构建这样的网络仍然是一个待解决的问题，其固有的不稳定性是被认可的。在本文中，我们探讨了ORNN中的循环和输入权重矩阵的量化，导致了量化近似正交RNN（QORNN）。我们研究了一种后训练量化（PTQ）策略和三种融入正交约束和量化权重的量化感知训练（QAT）算法。实证结果证明了使用QAT的优势。最高效的模型实现了与s类似的结果。

    Orthogonal recurrent neural networks (ORNNs) are an appealing option for learning tasks involving time series with long-term dependencies, thanks to their simplicity and computational stability. However, these networks often require a substantial number of parameters to perform well, which can be prohibitive in power-constrained environments, such as compact devices. One approach to address this issue is neural network quantization. The construction of such networks remains an open problem, acknowledged for its inherent instability.In this paper, we explore the quantization of the recurrent and input weight matrices in ORNNs, leading to Quantized approximately Orthogonal RNNs (QORNNs). We investigate one post-training quantization (PTQ) strategy and three quantization-aware training (QAT) algorithms that incorporate orthogonal constraints and quantized weights. Empirical results demonstrate the advantages of employing QAT over PTQ. The most efficient model achieves results similar to s
    
[^47]: BRAIn: Bayesian Reward-conditioned Amortized Inference for natural language generation from feedback

    BRAIn: Bayesian Reward-conditioned Amortized Inference for natural language generation from feedback

    [https://arxiv.org/abs/2402.02479](https://arxiv.org/abs/2402.02479)

    BRAIn是一种基于贝叶斯奖励条件化缩减推断的自然语言生成方法，通过反馈来改进RLHF，在LLM对齐中表现出较好的可扩展性和性能。

    

    在人类反馈的强化学习领域，继Proximal Policy Optimization (PPO)取得成功之后，提出了一种新的方法，如Sequence Likelihood Calibration (SLiC)和Direct Policy Optimization (DPO)，这些方法是离线的，并且以间接的方式使用奖励。这些技术，特别是DPO，由于其可扩展性和性能，最近已经成为LLM对齐的首选工具。然而，它们遗漏了PPO方法的重要特征。诸如SLiC或RRHF的方法仅利用奖励模型(RM)进行排序/偏好，丢失了细粒度信息，忽略了RM的参数形式(例如Bradley-Terry、Plackett-Luce)；而诸如DPO的方法甚至不使用单独的奖励模型。在这项工作中，我们提出了一种新颖的方法，命名为BRAIn，它将RM作为分布匹配方法的一部分重新引入。BRAIn考虑到了LLM分布在假设输出质量良好的条件下，并应用B...

    Following the success of Proximal Policy Optimization (PPO) for Reinforcement Learning from Human Feedback (RLHF), new techniques such as Sequence Likelihood Calibration (SLiC) and Direct Policy Optimization (DPO) have been proposed that are offline in nature and use rewards in an indirect manner. These techniques, in particular DPO, have recently become the tools of choice for LLM alignment due to their scalability and performance. However, they leave behind important features of the PPO approach. Methods such as SLiC or RRHF make use of the Reward Model (RM) only for ranking/preference, losing fine-grained information and ignoring the parametric form of the RM (eg., Bradley-Terry, Plackett-Luce), while methods such as DPO do not use even a separate reward model. In this work, we propose a novel approach, named BRAIn, that re-introduces the RM as part of a distribution matching approach.BRAIn considers the LLM distribution conditioned on the assumption of output goodness and applies B
    
[^48]: DeLLMa:一个用于大型语言模型下决策的框架

    DeLLMa: A Framework for Decision Making Under Uncertainty with Large Language Models

    [https://arxiv.org/abs/2402.02392](https://arxiv.org/abs/2402.02392)

    DeLLMa是一个旨在提高不确定环境下决策精度的框架，通过多步骤的脚手架程序，借鉴决策理论和效用理论的原则，可以显著提高大型语言模型的决策性能。

    

    大型语言模型（LLMs）在商业、工程和医学等领域被广泛应用，这些领域往往面临决策不确定性的问题，这是一个关键但具有挑战性的任务。本文表明，在决策问题上直接使用LLMs往往效果较差，尤其是在问题复杂性增加时。为了克服这个限制，我们提出了DeLLMa（Decision-making Large Language Model assistant）框架，旨在提高不确定环境下的决策精度。DeLLMa包括一个多步骤的脚手架程序，借鉴了决策理论和效用理论的原则，提供了一个最优的、可审计的决策过程。我们在涉及真实农业和金融数据的决策环境中验证了我们的框架。结果表明，DeLLMa可以显著提高LLMs的决策性能，准确性可提高高达40%以上。

    Large language models (LLMs) are increasingly used across society, including in domains like business, engineering, and medicine. These fields often grapple with decision-making under uncertainty, a critical yet challenging task. In this paper, we show that directly prompting LLMs on these types of decision-making problems yields poor results, especially as the problem complexity increases. To overcome this limitation, we propose DeLLMa (Decision-making Large Language Model assistant), a framework designed to enhance decision-making accuracy in uncertain environments. DeLLMa involves a multi-step scaffolding procedure, drawing upon principles from decision theory and utility theory, to provide an optimal and human-auditable decision-making process. We validate our framework on decision-making environments involving real agriculture and finance data. Our results show that DeLLMa can significantly improve LLM decision-making performance, achieving up to a 40% increase in accuracy over co
    
[^49]: Stereographic Spherical Sliced Wasserstein Distances - 应用于球形概率分布比较的立体投影球面切片瓦瑟斯坦距离

    Stereographic Spherical Sliced Wasserstein Distances

    [https://arxiv.org/abs/2402.02345](https://arxiv.org/abs/2402.02345)

    本文提出了一种快速且高度并行的用于比较球形测度的距离，使用了立体投影和广义Radon变换，称之为立体投影球面切片瓦瑟斯坦（S3W）距离。通过仔细处理立体投影引起的距离畸变，并进行了理论分析，证明了该方法在速度和效果上的优势。

    

    在地质学、医学领域、计算机视觉和深度表示学习等各个领域，比较球形概率分布是非常重要的。基于最优传输的距离，比如瓦瑟斯坦距离，对于比较概率测度已经引发了活跃的研究，以开发计算效率高的球形概率测度的变体。本文介绍了一种高速且高度并行化的用于比较球形测度的距离，使用了立体投影和广义Radon变换，我们称之为立体投影球面切片瓦瑟斯坦（S3W）距离。我们仔细处理了立体投影引起的距离畸变，并对我们提出的度量及其具有旋转不变性的变体进行了广泛的理论分析。最后，我们评估了所提出的度量的性能，并将其与最近的基线进行了比较，从遥感和处理效率两个方面进行了评估。

    Comparing spherical probability distributions is of great interest in various fields, including geology, medical domains, computer vision, and deep representation learning. The utility of optimal transport-based distances, such as the Wasserstein distance, for comparing probability measures has spurred active research in developing computationally efficient variations of these distances for spherical probability measures. This paper introduces a high-speed and highly parallelizable distance for comparing spherical measures using the stereographic projection and the generalized Radon transform, which we refer to as the Stereographic Spherical Sliced Wasserstein (S3W) distance. We carefully address the distance distortion caused by the stereographic projection and provide an extensive theoretical analysis of our proposed metric and its rotationally invariant variation. Finally, we evaluate the performance of the proposed metrics and compare them with recent baselines in terms of both spe
    
[^50]: 图上的神经缩放定律

    Neural Scaling Laws on Graphs

    [https://arxiv.org/abs/2402.02054](https://arxiv.org/abs/2402.02054)

    本论文在图上深入研究了神经缩放定律，从模型和数据两个角度进行了探索。对于模型缩放，发现了缩放定律崩溃和过拟合之间的关系，以及深度图模型的模型深度对缩放行为的影响。对于数据缩放，提出了图数量不适合作为衡量缩放定律中图数据量的指标。

    

    深度图模型（例如图神经网络和图变换器）已成为利用各种类型图的知识的重要技术。然而，深度图模型的缩放特性尚未得到系统研究，对通过扩大模型和数据集大小来实现大型图模型的可行性产生了疑问。在这项工作中，我们从模型和数据的角度深入探索了图上的神经缩放定律。我们首先验证了这些定律在图上的有效性，并建立了描述缩放行为的公式。对于模型缩放，我们研究了缩放定律崩溃现象，并确定了过拟合可能是原因。此外，我们揭示了深度图模型的模型深度可以影响模型缩放行为，这与其他领域（如计算机视觉和自然语言处理）的观察结果不同。对于数据缩放，我们建议图数量无法有效衡量图数据量的缩放定律，因为...

    Deep graph models (e.g., graph neural networks and graph transformers) have become important techniques for leveraging knowledge across various types of graphs. Yet, the scaling properties of deep graph models have not been systematically investigated, casting doubt on the feasibility of achieving large graph models through enlarging the model and dataset sizes. In this work, we delve into neural scaling laws on graphs from both model and data perspectives. We first verify the validity of such laws on graphs, establishing formulations to describe the scaling behaviors. For model scaling, we investigate the phenomenon of scaling law collapse and identify overfitting as the potential reason. Moreover, we reveal that the model depth of deep graph models can impact the model scaling behaviors, which differ from observations in other domains such as CV and NLP. For data scaling, we suggest that the number of graphs can not effectively metric the graph data volume in scaling law since the si
    
[^51]: BPDec: 揭示BERT预训练中掩码语言建模解码器的潜力

    BPDec: Unveiling the Potential of Masked Language Modeling Decoder in BERT pretraining

    [https://arxiv.org/abs/2401.15861](https://arxiv.org/abs/2401.15861)

    本文揭示了BPDec（BERT预训练解码器）的潜力，强调增强的掩码语言建模解码器设计及研究在BERT预训练中的重要性。

    

    BERT（来自Transformer的双向编码表示）通过其在许多任务上出色的性能彻底改变了自然语言处理领域。然而，大多数研究人员主要集中在与模型结构相关的增强，例如相对位置嵌入和更有效的注意机制。还有一些人深入研究了与掩码语言建模相关的预训练技巧，包括整词掩码。DeBERTa引入了一种针对BERT编码器模型进行预训练的增强解码器，证明效果非常显著。我们认为围绕增强掩码语言建模解码器的设计和研究并未得到应有的重视。在本文中，我们提出了几种增强解码器的设计，并介绍了BPDec（BERT预训练解码器），这是一种用于建模训练的新方法。通常，预训练的BERT模型会针对特定的自然语

    arXiv:2401.15861v2 Announce Type: replace-cross  Abstract: BERT (Bidirectional Encoder Representations from Transformers) has revolutionized the field of natural language processing through its exceptional performance on numerous tasks. Yet, the majority of researchers have mainly concentrated on enhancements related to the model structure, such as relative position embedding and more efficient attention mechanisms. Others have delved into pretraining tricks associated with Masked Language Modeling, including whole word masking. DeBERTa introduced an enhanced decoder adapted for BERT's encoder model for pretraining, proving to be highly effective. We argue that the design and research around enhanced masked language modeling decoders have been underappreciated. In this paper, we propose several designs of enhanced decoders and introduce BPDec (BERT Pretraining Decoder), a novel method for modeling training. Typically, a pretrained BERT model is fine-tuned for specific Natural Language 
    
[^52]: PRewrite: 使用强化学习的提示重写

    PRewrite: Prompt Rewriting with Reinforcement Learning

    [https://arxiv.org/abs/2401.08189](https://arxiv.org/abs/2401.08189)

    本文提出了一种基于强化学习的自动化工具PRewrite，用于重写提示草案并生成高效的新提示，以解决提示工程中的挑战。

    

    arXiv:2401.08189v2 公告类型: 替换 摘要: 提示工程对于基于LLM的应用程序的开发至关重要。然而，通常以“试错”的方式手动完成。这种手动程序可能耗时，效果不佳，并且在许多情况下生成的提示都是次优的。即使对那些看似运作良好的提示，始终存在一个悬而未决的问题：是否可以通过进一步修改使提示变得更好呢？为了解决这些问题，在本文中，我们研究了提示工程自动化。我们考虑了一个特定的使用情景，即开发者/用户已经起草了初始提示，但缺乏时间/专业知识来优化它们。我们提出了PRewrite，一个自动化工具，可重写这些草案，并生成高效的新提示。PRewrite基于强化学习（RL）框架，允许端到端优化，我们的设计允许RL搜索在大动作空间中进行。

    arXiv:2401.08189v2 Announce Type: replace  Abstract: Prompt engineering is critical for the development of LLM-based applications. However, it is usually done manually in a "trial and error" fashion. This manual procedure can be time consuming, ineffective, and the generated prompts are, in a lot of cases, sub-optimal. Even for the prompts which seemingly work well, there is always a lingering question: can the prompts be made better with further modifications?   To address these questions, in this paper, we investigate prompt engineering automation. We consider a specific use case scenario in which developers/users have drafted initial prompts, but lack the time/expertise to optimize them. We propose PRewrite, an automated tool to rewrite these drafts and to generate highly effective new prompts. PRewrite is based on the Reinforcement Learning (RL) framework which allows for end-to-end optimization and our design allows the RL search to happen in a large action space. The automated to
    
[^53]: 规模化模型编辑会导致渐进性和突发性遗忘

    Model Editing at Scale leads to Gradual and Catastrophic Forgetting

    [https://arxiv.org/abs/2401.07453](https://arxiv.org/abs/2401.07453)

    评估了当前模型编辑方法在规模化情况下的表现，发现随着模型被顺序编辑多个事实，它会逐渐遗忘先前的事实及执行下游任务的能力。

    

    在大型语言模型中编辑知识是一种具有吸引力的能力，它使我们能够在预训练期间纠正错误学习的事实，同时使用不断增长的新事实列表更新模型。我们认为，为了使模型编辑具有实际效用，我们必须能够对同一模型进行多次编辑。因此，我们评估了当前规模下的模型编辑方法，重点关注两种最先进的方法：ROME 和 MEMIT。我们发现，随着模型被顺序编辑多个事实，它不断地遗忘先前编辑过的事实以及执行下游任务的能力。这种遗忘分为两个阶段--初始的渐进性遗忘阶段，随后是突然或灾难性的遗忘。

    arXiv:2401.07453v2 Announce Type: replace-cross  Abstract: Editing knowledge in large language models is an attractive capability to have which allows us to correct incorrectly learnt facts during pre-training, as well as update the model with an ever-growing list of new facts. While existing model editing techniques have shown promise, they are usually evaluated using metrics for reliability, specificity and generalization over one or few edits. We argue that for model editing to have practical utility, we must be able to make multiple edits to the same model. With this in mind, we evaluate the current model editing methods at scale, focusing on two state of the art methods: ROME and MEMIT. We find that as the model is edited sequentially with multiple facts, it continually forgets previously edited facts and the ability to perform downstream tasks. This forgetting happens in two phases -- an initial gradual but progressive forgetting phase followed by abrupt or catastrophic forgettin
    
[^54]: 代理特定效应：多智能体MDPs中的因果效应传播分析

    Agent-Specific Effects: A Causal Effect Propagation Analysis in Multi-Agent MDPs

    [https://arxiv.org/abs/2310.11334](https://arxiv.org/abs/2310.11334)

    本文介绍了一种系统化的方法，用于将代理的行动对其他代理的影响归因到因果效应上，并提出了一种衡量代理特定效应（ASE）的新的因果数量。同时，我们还介绍了ASE的反事实对应物（cf-ASE）以及识别cf-ASE的条件，并提出了一种实用的基于采样的算法。

    

    在多智能体决策中建立行动与结果之间的因果关系对于负有责任的决策是至关重要的。然而，解释和量化代理对这种关系的贡献面临着重大挑战。在多智能体序贯决策的背景下，这些挑战尤为突出，因为代理的行动对结果的因果效应取决于其他代理如何对该行动作出响应。本文的目标是提出一个系统性的方法，将代理的行动对其他代理产生的因果效应归因到其所施加的影响上。针对多智能体马尔可夫决策过程，我们引入了一种新的因果数量——代理特定效应（ASE），用于衡量代理行动对通过其他代理传播的结果的影响。然后，我们转向ASE的反事实对应物（cf-ASE），提供了识别cf-ASE的一组充分条件，并提出了一种实用的基于采样的算法。

    Establishing causal relationships between actions and outcomes is fundamental for accountable multi-agent decision-making. However, interpreting and quantifying agents' contributions to such relationships pose significant challenges. These challenges are particularly prominent in the context of multi-agent sequential decision-making, where the causal effect of an agent's action on the outcome depends on how other agents respond to that action. In this paper, our objective is to present a systematic approach for attributing the causal effects of agents' actions to the influence they exert on other agents. Focusing on multi-agent Markov decision processes, we introduce agent-specific effects (ASE), a novel causal quantity that measures the effect of an agent's action on the outcome that propagates through other agents. We then turn to the counterfactual counterpart of ASE (cf-ASE), provide a sufficient set of conditions for identifying cf-ASE, and propose a practical sampling-based algor
    
[^55]: 图像到图像翻译的深度强化学习

    Deep Reinforcement Learning for Image-to-Image Translation

    [https://arxiv.org/abs/2309.13672](https://arxiv.org/abs/2309.13672)

    该论文提出了一种基于深度强化学习的图像到图像翻译方法，通过将翻译过程分解为小步骤并引入元策略和Plan概念，能够有效处理高维连续状态和动作空间的挑战。

    

    大多数现有的图像到图像翻译方法通过深度学习模型的一次运行生成图像。然而，设计这样的单步模型始终具有挑战性，需要大量的参数，并容易陷入坏的全局最小值和过拟合。在本工作中，我们将图像到图像翻译重新定义为逐步的决策问题，通过深度强化学习提出了一种新的框架，进行基于强化学习的图像到图像翻译（RL-I2IT）。RL-I2IT框架的关键特点是将一个单体学习过程分解为小的步骤，并引入一个轻量级模型，逐步将源图像转化为目标图像。考虑到在传统的强化学习框架下处理高维连续状态和动作空间的挑战，我们引入了元策略和一个新的概念Plan到标准的Actor-Critic模型中，该概念的维度较原始图像低，并且可以帮助演员生成可处理的高维表示。

    Most existing Image-to-Image Translation (I2IT) methods generate images in a single run of a deep learning (DL) model. However, designing such a single-step model is always challenging, requiring a huge number of parameters and easily falling into bad global minimums and overfitting. In this work, we reformulate I2IT as a step-wise decision-making problem via deep reinforcement learning (DRL) and propose a novel framework that performs RL-based I2IT (RL-I2IT). The key feature in the RL-I2IT framework is to decompose a monolithic learning process into small steps with a lightweight model to progressively transform a source image successively to a target image. Considering that it is challenging to handle high dimensional continuous state and action spaces in the conventional RL framework, we introduce meta policy with a new concept Plan to the standard Actor-Critic model, which is of a lower dimension than the original image and can facilitate the actor to generate a tractable high dime
    
[^56]: 一种可解释的三维框架揭示学习模式：变量脑沟识别的统一视角

    An explainable three dimension framework to uncover learning patterns: A unified look in variable sulci recognition

    [https://arxiv.org/abs/2309.00903](https://arxiv.org/abs/2309.00903)

    该论文提出了一个针对医学成像中的可解释AI的三维框架，旨在解决神经科学领域中识别大脑沟特征的复杂性问题。

    

    可解释的人工智能在医学成像中至关重要。在挑战性的神经科学领域里，视觉主题在三维空间内表现出高度复杂性。神经科学的应用涉及从MRI中识别大脑沟特征，由于专家之间的标注规程存在差异和大脑复杂的三维功能，我们面临着重大障碍。因此，传统的可解释性方法在有效验证和评估这些网络方面表现不佳。为了解决这个问题，我们首先提出了数学公式，细化了不同计算机视觉任务中解释需求的各种类别，分为自解释、半解释、非解释和基于验证协议可靠性的新模式学习应用。根据这个数学公式，我们提出了一个旨在解释三维的框架。

    arXiv:2309.00903v2 Announce Type: replace-cross  Abstract: Explainable AI is crucial in medical imaging. In the challenging field of neuroscience, visual topics present a high level of complexity, particularly within three-dimensional space. The application of neuroscience, which involves identifying brain sulcal features from MRI, faces significant hurdles due to varying annotation protocols among experts and the intricate three-dimension functionality of the brain. Consequently, traditional explainability approaches fall short in effectively validating and evaluating these networks. To address this, we first present a mathematical formulation delineating various categories of explanation needs across diverse computer vision tasks, categorized into self-explanatory, semi-explanatory, non-explanatory, and new-pattern learning applications based on the reliability of the validation protocol. With respect to this mathematical formulation, we propose a 3D explainability framework aimed at
    
[^57]: MLLMReID: 基于多模态大语言模型的人物再识别

    MLLMReID: Multimodal Large Language Model-based Person Re-identification. (arXiv:2401.13201v1 [cs.CV])

    [http://arxiv.org/abs/2401.13201](http://arxiv.org/abs/2401.13201)

    MLLMReID是一种基于多模态大语言模型的人物再识别方法，通过微调模型并将其视觉编码器作为主干进行优化，解决了MLLM在ReID任务中的设计指令和特征学习效果的问题。

    

    多模态大语言模型（MLLM）在许多任务中取得了令人满意的结果。然而，它们在人物再识别（ReID）任务中的表现尚未被研究。本文将研究如何将它们适应于ReID任务。一种直观的想法是使用ReID图像-文本数据集对MLLM进行微调，然后将它们的视觉编码器作为ReID的主干。然而，仍存在两个明显的问题：（1）为ReID设计指令时，MLLM可能过度拟合特定指令，而设计各种指令将导致更高的成本。（2）LLM的潜在图像特征向量没有参与损失计算。指令学习，对齐图像-文本特征，导致间接优化和学习目标不充分利用特征，限制了人物特征学习的效果。为了解决这些问题，本文提出了MLLMReID：基于多模态大语言模型的ReID。首先，我们提出了公共指令。

    Multimodal large language models (MLLM) have achieved satisfactory results in many tasks. However, their performance in the task of person re-identification (ReID) has not been explored to date. This paper will investigate how to adapt them for the task of ReID. An intuitive idea is to fine-tune MLLM with ReID image-text datasets, and then use their visual encoder as a backbone for ReID. However, there still exist two apparent issues: (1) Designing instructions for ReID, MLLMs may overfit specific instructions, and designing a variety of instructions will lead to higher costs. (2) Latent image feature vectors from LLMs are not involved in loss computation. Instructional learning, aligning image-text features, results in indirect optimization and a learning objective that inadequately utilizes features, limiting effectiveness in person feature learning. To address these problems, this paper proposes MLLMReID: Multimodal Large Language Model-based ReID. Firstly, we proposed Common Instru
    
[^58]: DeepEdit: 带有约束的解码式知识编辑

    DeepEdit: Knowledge Editing as Decoding with Constraints. (arXiv:2401.10471v1 [cs.CL])

    [http://arxiv.org/abs/2401.10471](http://arxiv.org/abs/2401.10471)

    DeepEdit是一种神经符号方法，通过更好的推理一致性和对更新知识的意识，提高了大型语言模型的知识编辑能力，对多跳问题数据集MQuaKE取得了显著的进展。

    

    我们将大型语言模型（LLMs）的知识编辑视为带有约束的解码过程。我们提出了DeepEdit（基于深度优先搜索的渐进式解码知识编辑），这是一种神经符号方法，通过更好的推理一致性、问题相关性和对更新知识的意识来改进知识编辑。DeepEdit可灵活应用于所有黑盒LLMs：不需要访问模型参数、表示或输出词汇分布。DeepEdit逐步产生高质量的推理步骤，以实现有效的知识编辑。它利用深度优先搜索来修改LLMs的输出，从而提高输出对问题的相关性和对更新知识的意识。在知识编辑方面，DeepEdit在控制LLMs产生更简洁的推理方面表现出色。在MQuaKE上，DeepEdit在定量上取得了显著的进展，这是一个具有挑战性的多跳问题数据集。

    We develop a new perspective of knowledge editing for large language models (LLMs) as decoding with constraints. We propose DeepEdit (Depth-first Search based Progressive Decoding for Knowledge Editing), a neuro-symbolic method that improves knowledge editing with better coherence of reasoning, relevance to the question, and awareness of updated knowledge. DeepEdit can be flexibly applied to all black-box LLMs: it does not require any access to the model parameters, representations, or output vocabulary distributions. DeepEdit progressively produces the high-quality reasoning steps towards effective knowledge editing. It utilizes a depth-first search to revise the LLMs' output, which improves the output's informativeness to the input question and awareness of the updated knowledge. Qualitatively, DeepEdit effectively controls LLMs to produce more succinct reasoning in accord with knowledge editing. Quantitatively, DeepEdit yields significant gains on MQuaKE, a challenging multi-hop que
    
[^59]: DiffDA:一种用于气象尺度数据同化的扩散模型

    DiffDA: a diffusion model for weather-scale data assimilation. (arXiv:2401.05932v1 [cs.CE])

    [http://arxiv.org/abs/2401.05932](http://arxiv.org/abs/2401.05932)

    DiffDA是一种用于气象尺度数据同化的扩散模型，通过机器学习的方法将预测状态和稀疏观测同化，生成与观测一致的初始条件，并能对预测进行后处理到未来。

    

    通过准确的数据同化生成初始条件对于可靠的天气预报和气候模拟至关重要。我们提出了DiffDA作为一种基于机器学习的数据同化方法，能够使用预测状态和稀疏观测来同化大气变量。我们将预训练的GraphCast天气预报模型作为去噪扩散模型。我们的方法应用了两阶段条件：在训练和推理过程中对预测状态进行条件化，在推理过程中只对稀疏观测进行条件化。作为副产品，这种策略还能将预测后处理到未来，在这种情况下没有可用的观测数据。通过基于再分析数据集的实验证明，我们的方法可以以0.25度分辨率生成与观测一致的同化全球大气数据。实验证明，通过我们的方法生成的初始条件可以用于具有较小损失的预报模型。

    The generation of initial conditions via accurate data assimilation is crucial for reliable weather forecasting and climate modeling. We propose the DiffDA as a machine learning based data assimilation method capable of assimilating atmospheric variables using predicted states and sparse observations. We adapt the pretrained GraphCast weather forecast model as a denoising diffusion model. Our method applies two-phase conditioning: on the predicted state during both training and inference, and on sparse observations during inference only. As a byproduct, this strategy also enables the post-processing of predictions into the future, for which no observations are available.Through experiments based on a reanalysis dataset, we have verified that our method can produce assimilated global atmospheric data consistent with observations at 0.25degree resolution. The experiments also show that the initial conditions that are generated via our approach can be used for forecast models with a loss 
    
[^60]: 基于移动网格PDE的移动采样物理信息神经网络

    Moving Sampling Physics-informed Neural Networks induced by Moving Mesh PDE. (arXiv:2311.16167v2 [math.NA] UPDATED)

    [http://arxiv.org/abs/2311.16167](http://arxiv.org/abs/2311.16167)

    这项工作提出了一种基于移动网格PDE的移动采样物理信息神经网络(MMPDE-Net)，通过解决移动网格PDE来自适应生成新的采样点，并且结合物理信息神经网络（PINN）提出了移动采样PINN（MS-PINN）的框架。数值实验验证了MS-PINN相对于PINN的性能改善。

    

    在这项工作中，我们提出了一种基于移动网格方法的端到端自适应采样神经网络（MMPDE-Net），通过求解移动网格PDE，可以自适应生成新的采样点。该模型旨在改善采样点生成的质量。此外，我们基于MMPDE-Net开发了一种迭代算法，使得采样点更加精确和可控。由于MMPDE-Net是独立于深度学习求解器的框架，我们将其与物理信息神经网络（PINN）相结合，提出了移动采样PINN（MS-PINN），并在一些假设下通过误差分析验证了其有效性。最后，我们通过四个典型实例的数值实验验证了MS-PINN相对于PINN的性能改善，从而数值上证明了我们方法的有效性。

    In this work, we propose an end-to-end adaptive sampling neural network (MMPDE-Net) based on the moving mesh method, which can adaptively generate new sampling points by solving the moving mesh PDE. This model focuses on improving the quality of sampling points generation. Moreover, we develop an iterative algorithm based on MMPDE-Net, which makes the sampling points more precise and controllable. Since MMPDE-Net is a framework independent of the deep learning solver, we combine it with physics-informed neural networks (PINN) to propose moving sampling PINN (MS-PINN) and demonstrate its effectiveness by error analysis under some assumptions. Finally, we demonstrate the performance improvement of MS-PINN compared to PINN through numerical experiments of four typical examples, which numerically verify the effectiveness of our method.
    
[^61]: 通过原始Wasserstein状态占用匹配实现的离线观察模仿

    Offline Imitation from Observation via Primal Wasserstein State Occupancy Matching. (arXiv:2311.01331v1 [cs.LG])

    [http://arxiv.org/abs/2311.01331](http://arxiv.org/abs/2311.01331)

    本论文提出了一种通过最小化原始Wasserstein距离来匹配专家和学习者状态占用的方法，以解决离线学习从观察中模仿任务的问题。

    

    在现实世界的情境中，与环境的任意交互往往是昂贵的，并且专家示范的行为并不总是可用的。为了减少这两者的需求，离线学习从观察（LfO）得到了广泛研究，其中代理通过只有专家状态和与任务无关的非专家状态-动作对来学习解决任务。最先进的分布校正估计（DICE）方法最小化了学习者和专家策略之间的状态占用差异。然而，它们仅限于$f$-divergences（KL和$\chi^2$）或带有Rubinstein对偶的Wasserstein距离，后者限制了对性能关键的基础距离度量的使用。为了解决这个问题，我们提出了原始Wasserstein DICE（PW-DICE），它通过悲观正则化器最小化专家和学习者状态占用之间的原始Wasserstein距离，并利用了对比学习的dis

    In real-world scenarios, arbitrary interactions with the environment can often be costly, and actions of expert demonstrations are not always available. To reduce the need for both, Offline Learning from Observations (LfO) is extensively studied, where the agent learns to solve a task with only expert states and \textit{task-agnostic} non-expert state-action pairs. The state-of-the-art DIstribution Correction Estimation (DICE) methods minimize the state occupancy divergence between the learner and expert policies. However, they are limited to either $f$-divergences (KL and $\chi^2$) or Wasserstein distance with Rubinstein duality, the latter of which constrains the underlying distance metric crucial to the performance of Wasserstein-based solutions. To address this problem, we propose Primal Wasserstein DICE (PW-DICE), which minimizes the primal Wasserstein distance between the expert and learner state occupancies with a pessimistic regularizer and leverages a contrastively learned dis
    
[^62]: 为目标条件智能体定义开放式学习问题

    A Definition of Open-Ended Learning Problems for Goal-Conditioned Agents. (arXiv:2311.00344v1 [cs.AI])

    [http://arxiv.org/abs/2311.00344](http://arxiv.org/abs/2311.00344)

    本文为开放式学习问题定义了一个关键的基本属性，即无限时间内不断产生新元素。在这基础上，提出了开放式学习问题的概念，并着重研究了开放式目标条件强化学习的子集。

    

    近期的许多机器学习研究论文中都提到了“开放式学习”，但很少有人尝试定义这个术语。更糟糕的是，当仔细研究时，似乎对于开放式学习与连续学习、终身学习或自为目的学习等相关概念的区别没有共识。在本文中，我们致力于解决这种情况。通过阐述这个概念的起源和最近的观点，我们说明了开放式学习通常被认为是一个包含多种属性的复合概念。与这些之前的方法不同，我们提出了将开放式过程的一个关键基本属性与时间无限制地产生新元素相分离的想法。基于此，我们建立了开放式学习问题的概念，并特别关注了开放式目标条件强化学习的子集。

    A lot of recent machine learning research papers have "Open-ended learning" in their title. But very few of them attempt to define what they mean when using the term. Even worse, when looking more closely there seems to be no consensus on what distinguishes open-ended learning from related concepts such as continual learning, lifelong learning or autotelic learning. In this paper, we contribute to fixing this situation. After illustrating the genealogy of the concept and more recent perspectives about what it truly means, we outline that open-ended learning is generally conceived as a composite notion encompassing a set of diverse properties. In contrast with these previous approaches, we propose to isolate a key elementary property of open-ended processes, which is to always produce novel elements from time to time over an infinite horizon. From there, we build the notion of open-ended learning problems and focus in particular on the subset of open-ended goal-conditioned reinforcement
    
[^63]: 通过非线性研究深度神经网络的理解

    Understanding deep neural networks through the lens of their non-linearity. (arXiv:2310.11439v1 [cs.LG])

    [http://arxiv.org/abs/2310.11439](http://arxiv.org/abs/2310.11439)

    本文提出了一个理论上有效的解决方案，通过亲和度评分追踪深度神经网络中的非线性传播，尤其关注计算机视觉应用。实验证实了所提出方法的实用性和对广泛应用的潜力。

    

    深度神经网络(DNN)的显著成功常常归因于它们的高表达能力和近似任意复杂函数的能力。事实上，DNN是高度非线性的模型，其中引入的激活函数在其中起到了重要作用。然而，尽管许多研究通过近似能力的视角研究了DNN的表达能力，但量化DNN或个别激活函数的非线性仍然是一个开放性问题。在本文中，我们提出了第一个在具体关注计算机视觉应用中追踪非线性传播的理论有效解决方案。我们提出的亲和度评分允许我们深入了解各种不同体系结构和学习范式的内部工作原理。我们提供了大量的实验结果，突出了所提出的亲和度评分的实际效用和潜在应用的可能性。

    The remarkable success of deep neural networks (DNN) is often attributed to their high expressive power and their ability to approximate functions of arbitrary complexity. Indeed, DNNs are highly non-linear models, and activation functions introduced into them are largely responsible for this. While many works studied the expressive power of DNNs through the lens of their approximation capabilities, quantifying the non-linearity of DNNs or of individual activation functions remains an open problem. In this paper, we propose the first theoretically sound solution to track non-linearity propagation in deep neural networks with a specific focus on computer vision applications. Our proposed affinity score allows us to gain insights into the inner workings of a wide range of different architectures and learning paradigms. We provide extensive experimental results that highlight the practical utility of the proposed affinity score and its potential for long-reaching applications.
    
[^64]: 演示就是你需要的一切：利用上下文学习推进攻击性内容改写

    Demonstrations Are All You Need: Advancing Offensive Content Paraphrasing using In-Context Learning. (arXiv:2310.10707v1 [cs.CL])

    [http://arxiv.org/abs/2310.10707](http://arxiv.org/abs/2310.10707)

    该论文在攻击性内容改写方面引入了上下文学习方法，并通过有限数量的输入-标签演示对来指导模型生成特定查询的所需输出，从而提高可用性和减少攻击性。

    

    改写攻击性内容是一种更好的替代内容删除的方法，有助于改善沟通环境的文明程度。然而，监督式的改写器在保留意义和意图的同时，对大量标记数据依赖性较高。它们也保留了原始内容的大部分攻击性，这引发了对它们整体可用性的疑问。在本文中，我们旨在通过探索上下文学习（ICL）与大型语言模型（LLM）相结合，帮助从业者开发可用的改写器，即使用有限数量的输入-标签演示对来引导模型生成特定查询的所需输出。我们的研究主要关注关键因素，如演示的数量和顺序，排除提示指令，以及降低测量毒性。我们在包括我们提出的上下文感知礼貌改写数据集在内的三个数据集上进行了原则性评估，其中包括对话式的粗鲁发言、礼貌改写等。

    Paraphrasing of offensive content is a better alternative to content removal and helps improve civility in a communication environment. Supervised paraphrasers; however, rely heavily on large quantities of labelled data to help preserve meaning and intent. They also retain a large portion of the offensiveness of the original content, which raises questions on their overall usability. In this paper we aim to assist practitioners in developing usable paraphrasers by exploring In-Context Learning (ICL) with large language models (LLMs), i.e., using a limited number of input-label demonstration pairs to guide the model in generating desired outputs for specific queries. Our study focuses on key factors such as -- number and order of demonstrations, exclusion of prompt instruction, and reduction in measured toxicity. We perform principled evaluation on three datasets, including our proposed Context-Aware Polite Paraphrase dataset, comprising of dialogue-style rude utterances, polite paraphr
    
[^65]: 通过深度强化学习将社区成员隐藏作为反事实图搜索

    Community Membership Hiding as Counterfactual Graph Search via Deep Reinforcement Learning. (arXiv:2310.08909v1 [cs.SI])

    [http://arxiv.org/abs/2310.08909](http://arxiv.org/abs/2310.08909)

    这项研究通过深度强化学习的方式解决了社区成员隐藏的挑战，通过战略地改变网络图的结构属性，防止节点被社区检测算法识别出来，并验证了方法的有效性。

    

    社区检测是社交媒体平台发现彼此紧密联系的用户群体的有用工具，他们共享共同的兴趣。然而，这种功能往往会以可能暴露个人隐私为代价，无意中透露他们的品味或偏好。因此，一些用户可能希望保护他们的匿名性，并出于各种原因选择退出社区检测，例如与政治或宗教组织的关联。在这项研究中，我们解决了社区成员隐藏的挑战，它涉及战略性地改变网络图的结构属性，以防止一个或多个节点被给定的社区检测算法识别出来。我们通过制定一个受限的反事实图目标，并通过深度强化学习来解决这个问题。我们通过两个不同的任务来验证我们方法的有效性：节点和社区欺骗。

    Community detection techniques are useful tools for social media platforms to discover tightly connected groups of users who share common interests. However, this functionality often comes at the expense of potentially exposing individuals to privacy breaches by inadvertently revealing their tastes or preferences. Therefore, some users may wish to safeguard their anonymity and opt out of community detection for various reasons, such as affiliation with political or religious organizations.  In this study, we address the challenge of community membership hiding, which involves strategically altering the structural properties of a network graph to prevent one or more nodes from being identified by a given community detection algorithm. We tackle this problem by formulating it as a constrained counterfactual graph objective, and we solve it via deep reinforcement learning. We validate the effectiveness of our method through two distinct tasks: node and community deception. Extensive exper
    
[^66]: 学习用户优先的电器调度奖励函数

    Learning a Reward Function for User-Preferred Appliance Scheduling. (arXiv:2310.07389v1 [cs.AI])

    [http://arxiv.org/abs/2310.07389](http://arxiv.org/abs/2310.07389)

    本文介绍了一种基于逆强化学习的模型，通过使用终端用户过去的消费数据，帮助创建用户每日的电器计划，从而鼓励终端用户参与需求响应服务的提供。

    

    居民部门加速发展需求响应服务对于降低电力部门的碳排放至关重要。随着基础设施的进步，鼓励终端用户参与至关重要。终端用户非常重视自己的隐私和控制权，并希望在创建每日电器操作计划时参与到服务设计和决策过程中。此外，除非他们有经济或环境动机，他们通常不会准备牺牲自己的舒适度来帮助平衡电力系统。本文提出了一种基于逆强化学习的模型，可以在不要求用户明确陈述需求和愿望的情况下帮助创建用户每日的电器计划。通过使用他们过去的消费数据，终端消费者将隐式参与这些决策的制定，并因此得到继续参与需求响应服务提供的动力。

    Accelerated development of demand response service provision by the residential sector is crucial for reducing carbon-emissions in the power sector. Along with the infrastructure advancement, encouraging the end users to participate is crucial. End users highly value their privacy and control, and want to be included in the service design and decision-making process when creating the daily appliance operation schedules. Furthermore, unless they are financially or environmentally motivated, they are generally not prepared to sacrifice their comfort to help balance the power system. In this paper, we present an inverse-reinforcement-learning-based model that helps create the end users' daily appliance schedules without asking them to explicitly state their needs and wishes. By using their past consumption data, the end consumers will implicitly participate in the creation of those decisions and will thus be motivated to continue participating in the provision of demand response services.
    
[^67]: 在线推测解码

    Online Speculative Decoding. (arXiv:2310.07177v1 [cs.AI])

    [http://arxiv.org/abs/2310.07177](http://arxiv.org/abs/2310.07177)

    在线推测解码是通过利用多余计算能力，在LLM服务集群中持续更新草稿模型，从而加速大型语言模型推理的一种方法。

    

    推测解码是通过利用较小的草稿模型来预测目标模型的输出，从而加速大型语言模型（LLM）推理的关键技术。然而，在面对多样的文本输入和草稿模型与目标模型之间的显著能力差距时，其有效性可能受到限制。我们引入了在线推测解码（OSD）来解决这一挑战。其主要思想是利用LLM服务集群中丰富的多余计算能力，根据观察到的用户查询数据持续更新（多个）草稿模型。由于LLM推理受内存限制，典型的LLM服务集群中的剩余计算能力可以用于在线重新训练草稿模型，从而使训练成本保持中性。由于LLM服务的查询分布相对简单，根据查询分布进行重新训练可以使草稿模型更准确地预测目标模型的输出。

    Speculative decoding is a pivotal technique to accelerate the inference of large language models (LLMs) by employing a smaller draft model to predict the target model's outputs. However, its efficacy can be limited due to the low predictive accuracy of the draft model, particularly when faced with diverse text inputs and a significant capability gap between the draft and target models. We introduce online speculative decoding (OSD) to address this challenge. The main idea is to continually update (multiple) draft model(s) on observed user query data using the abundant excess computational power in an LLM serving cluster. Given that LLM inference is memory-bounded, the surplus computational power in a typical LLM serving cluster can be repurposed for online retraining of draft models, thereby making the training cost-neutral. Since the query distribution of an LLM service is relatively simple, retraining on query distribution enables the draft model to more accurately predict the target
    
[^68]: Memoria: 用于类人顺序处理的海比安记忆体架构

    Memoria: Hebbian Memory Architecture for Human-Like Sequential Processing. (arXiv:2310.03052v1 [cs.LG])

    [http://arxiv.org/abs/2310.03052](http://arxiv.org/abs/2310.03052)

    Memoria 是一个通用记忆网络，应用海比安理论来增强神经网络中的长期依赖。通过存储和检索信息，并使用根据海布规则变化的连接权重，Memoria 在诸如 BERT 和 GPT 之类的流行 Transformer 模型上显著改进了考虑长期依赖的能力。

    

    Transformer 在多个领域和任务中取得了成功。然而，由于其有限的容量，Transformer 很难处理长输入序列。虽然增加输入长度是一个解决方案，但无止境地增加长度是不现实的。此外，与 Transformer 不同，人类有选择性地记住和使用仅与输入相关的信息，而不是从头到尾处理所有原始数据。我们引入了 Memoria，一个应用海比安记忆形成理论的通用记忆网络，用于增强神经网络中的长期依赖。Memoria 在工作记忆、短期记忆和长期记忆的多个记忆层级上存储和检索称为 engram 的信息，使用根据海布规则变化的连接权重。通过与诸如 BERT 和 GPT 等流行的基于 Transformer 的模型进行实验，我们提出 Memoria 显著提高了在各种任务中考虑长期依赖的能力。结果

    Transformers have demonstrated their success in various domains and tasks. However, Transformers struggle with long input sequences due to their limited capacity. While one solution is to increase input length, endlessly stretching the length is unrealistic. Furthermore, humans selectively remember and use only relevant information from inputs, unlike Transformers which process all raw data from start to end. We introduce Memoria, a general memory network that applies Hebbian theory which is a major theory explaining human memory formulation to enhance long-term dependencies in neural networks. Memoria stores and retrieves information called engram at multiple memory levels of working memory, short-term memory, and long-term memory, using connection weights that change according to Hebb's rule. Through experiments with popular Transformer-based models like BERT and GPT, we present that Memoria significantly improves the ability to consider long-term dependencies in various tasks. Resul
    
[^69]: 关于图神经网络中表达位置编码的稳定性

    On the Stability of Expressive Positional Encodings for Graph Neural Networks. (arXiv:2310.02579v1 [cs.LG])

    [http://arxiv.org/abs/2310.02579](http://arxiv.org/abs/2310.02579)

    本研究针对图神经网络中使用拉普拉斯特征向量作为位置编码面临的非唯一性和不稳定性问题，提出了稳定且表达丰富的位置编码方法（SPE），该方法通过利用特征值对特征空间进行"软分割"，在未见过的图结构上表现出良好的泛化能力。

    

    设计有效的图位置编码对构建强大的图转换器和增强消息传递图神经网络非常关键。尽管广泛使用，使用拉普拉斯特征向量作为位置编码面临两个根本性挑战：（1）\emph{非唯一性}：同一拉普拉斯矩阵存在许多不同的特征分解，以及（2）\emph{不稳定性}：对拉普拉斯矩阵的微小扰动可能导致完全不同的特征空间，从而导致位置编码的不可预测性变化。尽管有很多尝试解决非唯一性的方法，但大多数方法忽视了稳定性，导致在未见过的图结构上表现不佳。我们发现，不稳定性的原因是特征空间的"硬分割"。因此，我们引入了稳定且表达丰富的位置编码（SPE），这是一种用于处理特征向量的架构，利用特征值将特征空间进行"软分割"。SPE是首个（1）可证明稳定的架构，以及（2）普适地提升图结构泛化性能的架构。

    Designing effective positional encodings for graphs is key to building powerful graph transformers and enhancing message-passing graph neural networks. Although widespread, using Laplacian eigenvectors as positional encodings faces two fundamental challenges: (1) \emph{Non-uniqueness}: there are many different eigendecompositions of the same Laplacian, and (2) \emph{Instability}: small perturbations to the Laplacian could result in completely different eigenspaces, leading to unpredictable changes in positional encoding.  Despite many attempts to address non-uniqueness, most methods overlook stability, leading to poor generalization on unseen graph structures. We identify the cause of instability to be a "hard partition" of eigenspaces. Hence, we introduce Stable and Expressive Positional Encodings (SPE), an architecture for processing eigenvectors that uses eigenvalues to "softly partition" eigenspaces. SPE is the first architecture that is (1) provably stable, and (2) universally exp
    
[^70]: 通过随机化潜在表示来迷惑文本愚弄者

    Fooling the Textual Fooler via Randomizing Latent Representations. (arXiv:2310.01452v1 [cs.CL])

    [http://arxiv.org/abs/2310.01452](http://arxiv.org/abs/2310.01452)

    该论文提出了一种轻量级的攻击无关防御策略AdvFooler，通过随机化输入的潜在表示来困惑基于查询的黑盒攻击，从而迷惑文本愚弄者。

    

    尽管在各种自然语言处理任务中表现出色，但近期的研究表明，自然语言处理模型容易受到敌对攻击的影响，即微小地改变输入以导致模型的错误行为。其中，敌对词级扰动是一个被广泛研究和有效的攻击策略。这些攻击在黑盒设置中起作用，不需要访问模型结构或参数，因此可能对现有的自然语言处理应用产生不利影响。为了进行攻击，对手多次查询受害模型，以确定输入文本中最重要的单词，并用它们对应的同义词替换这些单词。在这项工作中，我们提出了一种轻量级和攻击无关的防御，其主要目标是困惑基于查询的黑盒攻击中产生敌对示例的过程；即愚弄文本愚弄者。这种防御名为AdvFooler，通过随机化输入的潜在表示来实现。

    Despite outstanding performance in a variety of NLP tasks, recent studies have revealed that NLP models are vulnerable to adversarial attacks that slightly perturb the input to cause the models to misbehave. Among these attacks, adversarial word-level perturbations are well-studied and effective attack strategies. Since these attacks work in black-box settings, they do not require access to the model architecture or model parameters and thus can be detrimental to existing NLP applications. To perform an attack, the adversary queries the victim model many times to determine the most important words in an input text and to replace these words with their corresponding synonyms. In this work, we propose a lightweight and attack-agnostic defense whose main goal is to perplex the process of generating an adversarial example in these query-based black-box attacks; that is to fool the textual fooler. This defense, named AdvFooler, works by randomizing the latent representation of the input at 
    
[^71]: 使用多元时间序列转换器获取风险投资和成长资本的投资目标

    Sourcing Investment Targets for Venture and Growth Capital Using Multivariate Time Series Transformer. (arXiv:2309.16888v1 [cs.LG])

    [http://arxiv.org/abs/2309.16888](http://arxiv.org/abs/2309.16888)

    这个论文介绍了一种新颖的方法，利用Transformer-based Multivariate Time Series Classifier (TMTSC)来预测风险投资和成长资本的候选公司的成功可能性，以优化投资目标的选择。通过对相关的方法进行了全面回顾和实验验证，证明了该方法的有效性。

    

    本文探讨了数据驱动方法在私募股权（PE）行业中的应用，特别是在为风险投资（VC）和成长资本（GC）寻找投资目标（即公司）方面。我们对相关方法进行了全面的回顾，并提出了一种新颖的方法，利用基于Transformer的多元时间序列分类器（TMTSC）来预测任何候选公司的成功可能性。我们的研究目标是通过将寻找投资问题正式定义为多元时间序列分类任务，优化VC和GC投资的寻找效果。我们依次介绍了我们实现的关键组成部分，这些部分共同 contribut 到了在VC/GC寻找中成功应用TMTSC：输入特征、模型架构、优化目标以及基于投资者的数据增强和划分。我们在四个数据集上进行了大量实验，并将其与三个流行的基准线进行了对比。

    This paper addresses the growing application of data-driven approaches within the Private Equity (PE) industry, particularly in sourcing investment targets (i.e., companies) for Venture Capital (VC) and Growth Capital (GC). We present a comprehensive review of the relevant approaches and propose a novel approach leveraging a Transformer-based Multivariate Time Series Classifier (TMTSC) for predicting the success likelihood of any candidate company. The objective of our research is to optimize sourcing performance for VC and GC investments by formally defining the sourcing problem as a multivariate time series classification task. We consecutively introduce the key components of our implementation which collectively contribute to the successful application of TMTSC in VC/GC sourcing: input features, model architecture, optimization target, and investor-centric data augmentation and split. Our extensive experiments on four datasets, benchmarked towards three popular baselines, demonstrat
    
[^72]: UniHead: 融合多感知的检测头

    UniHead: Unifying Multi-Perception for Detection Heads. (arXiv:2309.13242v1 [cs.CV])

    [http://arxiv.org/abs/2309.13242](http://arxiv.org/abs/2309.13242)

    UniHead是一种创新的检测头，它通过引入变形感知、双轴聚合变换器和跨任务交互变换器，实现了全感知能力的统一。

    

    检测头是目标检测器中一个关键组件，负责执行分类和定位功能。然而，常用的并行检测头常常缺乏全感知能力，如变形感知、全局感知和跨任务感知。尽管有很多方法试图从单个方面提高这些能力，但实现全面统一的解决方案仍然是一个重大挑战。针对这个挑战，我们开发了一种创新的检测头，称为UniHead，同时统一了三种感知能力。具体而言，我们的方法：（1）引入了变形感知，使模型能够自适应采样对象特征；（2）提出了双轴聚合变换器（DAT）来灵活地建模长距离依赖关系，从而实现全局感知；（3）设计了一种跨任务交互变换器（CIT），促进分类和定位之间的交互作用。

    The detection head constitutes a pivotal component within object detectors, tasked with executing both classification and localization functions. Regrettably, the commonly used parallel head often lacks omni perceptual capabilities, such as deformation perception, global perception and cross-task perception. Despite numerous methods attempt to enhance these abilities from a single aspect, achieving a comprehensive and unified solution remains a significant challenge. In response to this challenge, we have developed an innovative detection head, termed UniHead, to unify three perceptual abilities simultaneously. More precisely, our approach (1) introduces deformation perception, enabling the model to adaptively sample object features; (2) proposes a Dual-axial Aggregation Transformer (DAT) to adeptly model long-range dependencies, thereby achieving global perception; and (3) devises a Cross-task Interaction Transformer (CIT) that facilitates interaction between the classification and lo
    
[^73]: 对于ConvNets来说，遮盖（masking）能改善对比自监督学习，而显著性告诉你何处。（arXiv:2309.12757v1 [cs.CV]）

    Masking Improves Contrastive Self-Supervised Learning for ConvNets, and Saliency Tells You Where. (arXiv:2309.12757v1 [cs.CV])

    [http://arxiv.org/abs/2309.12757](http://arxiv.org/abs/2309.12757)

    该论文研究了如何将遮盖操作引入卷积神经网络的对比学习框架中，以提高自监督学习的效果。同时，研究还发现遮盖操作可能存在一些副作用，作者提出了解决方案来应对这些问题。

    

    图像数据开始受益于简单而有效的自监督学习方案，该方案建立在遮盖和自重构目标之上，这要归功于令牌化程序和视觉转换器骨干结构的引入。然而，作为图像数据的另一种重要且广泛采用的架构，卷积神经网络，尽管具有驱动自监督学习的对比学习技术，仍然面临将这种直接而通用的遮盖操作显著地利用于其学习过程中的困难。本研究旨在减轻将遮盖操作纳入对比学习框架的负担，作为一种额外的增强方法，以缓解ConvNets中因遮罩操作而产生的额外边缘（遮盖和未遮盖区域之间）以及其他不利影响的问题，这些问题已经在先前的研究中讨论过。

    While image data starts to enjoy the simple-but-effective self-supervised learning scheme built upon masking and self-reconstruction objective thanks to the introduction of tokenization procedure and vision transformer backbone, convolutional neural networks as another important and widely-adopted architecture for image data, though having contrastive-learning techniques to drive the self-supervised learning, still face the difficulty of leveraging such straightforward and general masking operation to benefit their learning process significantly. In this work, we aim to alleviate the burden of including masking operation into the contrastive-learning framework for convolutional neural networks as an extra augmentation method. In addition to the additive but unwanted edges (between masked and unmasked regions) as well as other adverse effects caused by the masking operations for ConvNets, which have been discussed by prior works, we particularly identify the potential problem where for 
    
[^74]: 从分层的弱偏好反馈中进行深度强化学习

    Deep Reinforcement Learning from Hierarchical Weak Preference Feedback. (arXiv:2309.02632v1 [cs.LG])

    [http://arxiv.org/abs/2309.02632](http://arxiv.org/abs/2309.02632)

    本研究探讨了如何利用分层的弱偏好反馈进行深度强化学习。通过学习奖励函数，与人类偏好非常一致的复杂奖励可以帮助强化学习解决日益困难的问题。

    

    奖励设计是实际强化学习中一个基本但具有挑战性的方面。对于简单任务，研究人员通常手工设计奖励函数，例如使用若干个奖励因子的线性组合。然而，这种奖励工程受到近似偏差的影响，需要大量的调优成本，并且通常无法提供复杂任务所需的细粒度。为了避免这些困难，研究人员开始转向从人类反馈中进行强化学习（RLHF），从轨迹序列对之间的人类偏好中学习奖励函数。通过利用基于偏好的奖励建模，RLHF学习到与人类偏好非常一致的复杂奖励，使得强化学习能够解决日益困难的问题。不幸的是，RLHF的适用性受到获得人类偏好数据的高成本和困难的限制。鉴于这个成本，我们研究了在复杂任务中使用更少人力投入的方式来学习奖励函数。

    Reward design is a fundamental, yet challenging aspect of practical reinforcement learning (RL). For simple tasks, researchers typically handcraft the reward function, e.g., using a linear combination of several reward factors. However, such reward engineering is subject to approximation bias, incurs large tuning cost, and often cannot provide the granularity required for complex tasks. To avoid these difficulties, researchers have turned to reinforcement learning from human feedback (RLHF), which learns a reward function from human preferences between pairs of trajectory sequences. By leveraging preference-based reward modeling, RLHF learns complex rewards that are well aligned with human preferences, allowing RL to tackle increasingly difficult problems. Unfortunately, the applicability of RLHF is limited due to the high cost and difficulty of obtaining human preference data. In light of this cost, we investigate learning reward functions for complex tasks with less human effort; sim
    
[^75]: 通过处理S参数模式对氧化铟锡电极进行现场故障诊断

    In situ Fault Diagnosis of Indium Tin Oxide Electrodes by Processing S-Parameter Patterns. (arXiv:2308.11639v1 [eess.SP])

    [http://arxiv.org/abs/2308.11639](http://arxiv.org/abs/2308.11639)

    本研究提出了一种利用散射参数（S参数）信号处理的现场故障诊断方法，对氧化铟锡（ITO）电极进行故障检测和诊断。这种方法具有早期检测、高诊断精度、噪声鲁棒性和根本原因分析的优势。

    

    在光电子领域，氧化铟锡（ITO）电极在显示器、传感器和太阳能电池等各种应用中起着关键作用。有效的故障检测和诊断是确保设备性能和可靠性的关键。然而，传统的视觉检查对于透明的ITO电极来说具有挑战性，而现有的故障检测方法在确定缺陷根本原因方面存在局限性，通常需要破坏性评估。本研究提出了一种利用散射参数（S参数）信号处理的现场故障诊断方法，提供了早期检测、高诊断精度、噪声鲁棒性和根本原因分析。根据缺陷状态获取了全面的S参数模式数据库。然后使用深度学习（DL）方法，包括多层感知器（MLP）、卷积神经网络（CNN）和Transformer，同时分析故障原因和严重性。

    In the field of optoelectronics, indium tin oxide (ITO) electrodes play a crucial role in various applications, such as displays, sensors, and solar cells. Effective fault detection and diagnosis of the ITO electrodes are essential to ensure the performance and reliability of the devices. However, traditional visual inspection is challenging with transparent ITO electrodes, and existing fault detection methods have limitations in determining the root causes of the defects, often requiring destructive evaluations. In this study, an in situ fault diagnosis method is proposed using scattering parameter (S-parameter) signal processing, offering early detection, high diagnostic accuracy, noise robustness, and root cause analysis. A comprehensive S-parameter pattern database is obtained according to defect states. Deep learning (DL) approaches, including multilayer perceptron (MLP), convolutional neural network (CNN), and transformer, are then used to simultaneously analyze the cause and sev
    
[^76]: 具有潜变量的因果结构估计的广义独立噪声条件

    Generalized Independent Noise Condition for Estimating Causal Structure with Latent Variables. (arXiv:2308.06718v1 [cs.LG])

    [http://arxiv.org/abs/2308.06718](http://arxiv.org/abs/2308.06718)

    这篇论文提出了具有潜变量的因果结构估计的广义独立噪声（GIN）条件，并给出了线性非高斯无环因果模型中满足GIN条件的图形判据。

    

    我们研究了在存在潜变量的情况下学习因果结构的挑战性任务，包括定位潜变量并确定它们的数量，以及识别潜变量和观测变量之间的因果关系。为了解决这个问题，我们提出了一种适用于包含潜变量的线性非高斯无环因果模型的广义独立噪声（GIN）条件，该条件建立了某些测量变量的线性组合与其他测量变量之间的独立性。具体而言，对于两个观测随机向量 $\bf{Y}$ 和 $\bf{Z}$，当且仅当 $\omega^{\intercal}\mathbf{Y}$ 和 $\mathbf{Z}$ 是独立的时，GIN 成立，其中 $\omega$ 是由 $\mathbf{Y}$ 和 $\mathbf{Z}$ 之间的交叉协方差确定的非零参数向量。然后，我们给出了线性非高斯无环因果模型中 GIN 条件的必要和充分图形判据。简言之，GIN 意味着存在一个外源的...

    We investigate the challenging task of learning causal structure in the presence of latent variables, including locating latent variables and determining their quantity, and identifying causal relationships among both latent and observed variables. To address this, we propose a Generalized Independent Noise (GIN) condition for linear non-Gaussian acyclic causal models that incorporate latent variables, which establishes the independence between a linear combination of certain measured variables and some other measured variables. Specifically, for two observed random vectors $\bf{Y}$ and $\bf{Z}$, GIN holds if and only if $\omega^{\intercal}\mathbf{Y}$ and $\mathbf{Z}$ are independent, where $\omega$ is a non-zero parameter vector determined by the cross-covariance between $\mathbf{Y}$ and $\mathbf{Z}$. We then give necessary and sufficient graphical criteria of the GIN condition in linear non-Gaussian acyclic causal models. Roughly speaking, GIN implies the existence of an exogenous se
    
[^77]: 在医疗领域的元学习：一项调查研究。

    Meta-learning in healthcare: A survey. (arXiv:2308.02877v1 [cs.LG])

    [http://arxiv.org/abs/2308.02877](http://arxiv.org/abs/2308.02877)

    元学习在医疗领域有广泛应用，可以解决医疗挑战，如样本不足和数据收集差异。主要包括多/单任务学习和多/少样本学习方法。

    

    作为机器学习的一个子集，元学习旨在通过利用先前的知识和经验来提高模型的能力。元学习范式可以适当地解决传统学习方法所面临的挑战，如样本数量不足、领域转移和泛化问题。这些独特的特点使元学习成为在各种医疗环境中开发有影响力的解决方案的合适选择，这些环境中可用数据通常不足，并且数据收集方法也不同。本调查讨论了元学习在医疗领域的广泛应用，以了解它如何以及在哪些方面可以解决关键的医疗挑战。我们首先描述了元学习的理论基础和关键方法。然后将在医疗领域应用的元学习方法分为多/单任务学习和多/少样本学习两大类。

    As a subset of machine learning, meta-learning, or learning to learn, aims at improving the model's capabilities by employing prior knowledge and experience. A meta-learning paradigm can appropriately tackle the conventional challenges of traditional learning approaches, such as insufficient number of samples, domain shifts, and generalization. These unique characteristics position meta-learning as a suitable choice for developing influential solutions in various healthcare contexts, where the available data is often insufficient, and the data collection methodologies are different. This survey discusses meta-learning broad applications in the healthcare domain to provide insight into how and where it can address critical healthcare challenges. We first describe the theoretical foundations and pivotal methods of meta-learning. We then divide the employed meta-learning approaches in the healthcare domain into two main categories of multi/single-task learning and many/few-shot learning a
    
[^78]: 零样本和少样本情况下应用于临床和生物医学任务的指导细调大型语言模型的研究

    A Zero-shot and Few-shot Study of Instruction-Finetuned Large Language Models Applied to Clinical and Biomedical Tasks. (arXiv:2307.12114v1 [cs.CL])

    [http://arxiv.org/abs/2307.12114](http://arxiv.org/abs/2307.12114)

    这项研究评估了四种指导细调大型语言模型在临床和生物医学任务上的表现，并发现它们在零样本和少样本情况下接近最先进模型的性能，尤其在问答任务上表现良好。然而，在分类和关系抽取任务上的表现稍逊于特定训练于医学领域的模型。没有一个模型在所有研究任务上胜过其他模型，有些模型更适合特定任务。

    

    我们评估了四种最先进的指导细调大型语言模型（LLM）——ChatGPT、Flan-T5 UL2、Tk-Instruct和Alpaca——在13个实际世界的临床和生物医学自然语言处理（NLP）任务中的表现，例如命名实体识别（NER）、问答（QA）、关系抽取（RE）等。我们的综合结果表明，在大多数任务的零样本和少样本情况下，评估的LLM开始接近最先进模型的性能，尤其对于QA任务表现得特别好，即使它们之前没有见过这些任务的示例。然而，我们观察到分类和关系抽取任务的表现低于特定训练于医学领域的模型（如PubMedBERT）可以达到的水平。最后，我们注意到没有一个LLM在所有研究任务上都胜过其他模型，有些模型更适合于特定的任务。

    We evaluate four state-of-the-art instruction-tuned large language models (LLMs) -- ChatGPT, Flan-T5 UL2, Tk-Instruct, and Alpaca -- on a set of 13 real-world clinical and biomedical natural language processing (NLP) tasks in English, such as named-entity recognition (NER), question-answering (QA), relation extraction (RE), etc. Our overall results demonstrate that the evaluated LLMs begin to approach performance of state-of-the-art models in zero- and few-shot scenarios for most tasks, and particularly well for the QA task, even though they have never seen examples from these tasks before. However, we observed that the classification and RE tasks perform below what can be achieved with a specifically trained model for the medical field, such as PubMedBERT. Finally, we noted that no LLM outperforms all the others on all the studied tasks, with some models being better suited for certain tasks than others.
    
[^79]: 梯度反击：如何滤除高频率提高解释性

    Gradient strikes back: How filtering out high frequencies improves explanations. (arXiv:2307.09591v1 [cs.AI])

    [http://arxiv.org/abs/2307.09591](http://arxiv.org/abs/2307.09591)

    本研究发现，基于预测的属性方法与基于梯度的方法产生的属性图具有不同的高频内容，滤除高频率可以提高解释性。

    

    近年来，新型基于预测的属性方法的发展迅猛，逐渐取代了旧的基于梯度的方法来解释深度神经网络的决策。然而，预测型方法为何优于梯度型方法仍不清楚。本文从经验观察开始：这两种方法产生的属性图具有非常不同的功率谱，梯度型方法揭示了比预测型方法更多的高频内容。这一观察引发了多个问题：这种高频信息的来源是什么，它是否真正反映了系统所作出的决策？最后，为什么在多个评价指标下，预测型方法中缺乏高频信息将产生更好的可解释性分数？我们分析了三个代表性的视觉分类模型的梯度，并观察到它包含来自高频的噪声信息。

    Recent years have witnessed an explosion in the development of novel prediction-based attribution methods, which have slowly been supplanting older gradient-based methods to explain the decisions of deep neural networks. However, it is still not clear why prediction-based methods outperform gradient-based ones. Here, we start with an empirical observation: these two approaches yield attribution maps with very different power spectra, with gradient-based methods revealing more high-frequency content than prediction-based methods. This observation raises multiple questions: What is the source of this high-frequency information, and does it truly reflect decisions made by the system? Lastly, why would the absence of high-frequency information in prediction-based methods yield better explainability scores along multiple metrics? We analyze the gradient of three representative visual classification models and observe that it contains noisy information emanating from high-frequencies. Furthe
    
[^80]: FedSelect: 个性化联邦学习中参数自定义选择的细调方法

    FedSelect: Customized Selection of Parameters for Fine-Tuning during Personalized Federated Learning. (arXiv:2306.13264v1 [cs.LG])

    [http://arxiv.org/abs/2306.13264](http://arxiv.org/abs/2306.13264)

    本文提出了一种名为FedSelect的新联邦学习框架，通过寻找最佳客户端子网络从而直接个性化客户端子网络结构和参数，同时保留了全局知识，提高了客户端性能。

    

    联邦学习旨在通过在本地数据上微调客户端参数或针对本地任务个性化架构来提高客户端性能。然而，现有的方法要么在牺牲重要的全局知识的情况下进行个性化，要么在预先确定网络层以进行微调的情况下导致客户端模型中全局知识储存的不足。本文提出了一种新的联邦学习框架FedSelect，通过同时搜索并获得个性化最佳参数和用于全局聚合的其余参数，从而直接个性化客户子网络结构和参数。

    Recent advancements in federated learning (FL) seek to increase client-level performance by fine-tuning client parameters on local data or personalizing architectures for the local task. Existing methods for such personalization either prune a global model or fine-tune a global model on a local client distribution. However, these existing methods either personalize at the expense of retaining important global knowledge, or predetermine network layers for fine-tuning, resulting in suboptimal storage of global knowledge within client models. Enlightened by the lottery ticket hypothesis, we first introduce a hypothesis for finding optimal client subnetworks to locally fine-tune while leaving the rest of the parameters frozen. We then propose a novel FL framework, FedSelect, using this procedure that directly personalizes both client subnetwork structure and parameters, via the simultaneous discovery of optimal parameters for personalization and the rest of parameters for global aggregatio
    
[^81]: CompanyKG:一种用于公司相似性量化的大规模异构图

    CompanyKG: A Large-Scale Heterogeneous Graph for Company Similarity Quantification. (arXiv:2306.10649v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.10649](http://arxiv.org/abs/2306.10649)

    本研究提出了CompanyKG，一种用于公司相似性量化的大规模异构图数据集。通过丰富的公司特征和关系表示，以及多个评估任务的基准测试，为公司相似性量化方法的综合评估提供了支持。

    

    在投资行业中，对于许多目的包括市场映射、竞争对手分析和并购，进行细粒度公司相似性量化通常是至关重要的。我们提出并发布了一个名为CompanyKG的知识图，用于表示和学习多样化的公司特征和关系。具体而言，1.17百万家公司被表示为节点，丰富了公司描述嵌入; 15种不同的公司间关系导致了5106百万个带权重的边。为了实现对公司相似性量化方法的全面评估，我们设计并编译了三个带有注释测试集的评估任务: 相似性预测、竞争对手检索和相似性排序。我们对11种可重现预测方法进行了广泛的基准测试，分为节点、边和节点+边三组。据我们所知，CompanyKG是第一个大规模的异构图数据集

    In the investment industry, it is often essential to carry out fine-grained company similarity quantification for a range of purposes, including market mapping, competitor analysis, and mergers and acquisitions. We propose and publish a knowledge graph, named CompanyKG, to represent and learn diverse company features and relations. Specifically, 1.17 million companies are represented as nodes enriched with company description embeddings; and 15 different inter-company relations result in 51.06 million weighted edges. To enable a comprehensive assessment of methods for company similarity quantification, we have devised and compiled three evaluation tasks with annotated test sets: similarity prediction, competitor retrieval and similarity ranking. We present extensive benchmarking results for 11 reproducible predictive methods categorized into three groups: node-only, edge-only, and node+edge. To the best of our knowledge, CompanyKG is the first large-scale heterogeneous graph dataset or
    
[^82]: Strokes2Surface：从四维建筑设计素描中恢复曲线网络

    Strokes2Surface: Recovering Curve Networks From 4D Architectural Design Sketches. (arXiv:2306.07220v2 [cs.GR] UPDATED)

    [http://arxiv.org/abs/2306.07220](http://arxiv.org/abs/2306.07220)

    本文介绍了Strokes2Surface，它可从建筑师的笔画中恢复出曲线网络，对于建筑设计中的概念设计和数字建模之间的桥梁具有重要意义。

    

    本文介绍了一个离线几何重建管道Strokes2Surface，它是基于4D Sketching Interface，MR.Sketch的目标是面向建筑设计的。该管道从设计师绘制的笔画中恢复曲线网络，因此在建筑设计的概念设计和数字建模阶段之间建立了桥梁。我们的管道的输入包括3D笔画的折线顶点及其相应的时间戳（作为第四个维度），以及额外的几何和笔触相关的记录属性。基于素描合并和基于素描建模方法的启发，我们的管道利用这些数据并组合三个机器学习（ML）模型；一个分类器和两个聚类模型。特别是，根据建筑设计素描中设计师通常采用的实践观察，我们解决了一个二元分类问题，以识别一笔画是描绘边界和边缘还是用于填充所需建筑物的封闭区域和表面。

    We present Strokes2Surface, an offline geometry-reconstruction pipeline built upon a 4D Sketching Interface, MR.Sketch, targeted at architectural design. The pipeline recovers a curve network from designer-drawn strokes, thus bridging between concept design and digital modeling stages in architectural design. The input to our pipeline consists of 3D strokes' polyline vertices and their corresponding timestamps (as of the fourth dimension), along with additional geometric and stylus-related recorded properties. Inspired by sketch consolidation and sketch-based modeling methods, our pipeline leverages such data and combines three Machine Learning (ML) models; a classifier and two clustering models. In particular, based on observations of practices designers typically employ in architectural design sketches, we solve a binary classification problem to recognize whether a stroke depicts a boundary and edge or is used to fill in the enclosing areas and faces of the intended architectural ob
    
[^83]: 基于参数的高效调整技术在医学图像分析中的应用：被忽视的机会

    Parameter-Efficient Fine-Tuning for Medical Image Analysis: The Missed Opportunity. (arXiv:2305.08252v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.08252](http://arxiv.org/abs/2305.08252)

    该论文综合评估了基于参数的高效调整技术（PEFT）在医学图像分析任务中的可能应用。通过超过600个控制测试，我们证明了PEFT的相对性能，并强调了PEFT在医学图像分析中实现参数高效转移学习的巨大潜力。

    

    我们对基于参数的高效调整技术（PEFT）在多样化的医学图像分析任务中进行了综合评估。PEFT越来越被用作知识转移的有价值方法，从自然语言处理、视觉、语音以及跨模态任务，例如视觉语言和文本到图像生成。然而，在医学图像分析中，它的应用仍相对未被探索。随着基础模型在医学领域越来越被利用，调查和比较评估各种知识转移策略可以增强各种下游任务至关重要。我们的研究是其类别中第一个（据我们所知），评估了16种卷积和基于转换器网络的PEFT方法，重点关注六个医学数据集上的图像分类和文本到图像生成任务，这些数据集在大小，模态和复杂性上有所不同。通过超过600个控制测试，我们证明了每种方法的相对性能，并确定了未来研究的途径，并强调了PEFT在医学图像分析中实现参数高效转移学习的潜力，并呼吁在未来研究中加以广泛探索。

    We present a comprehensive evaluation of Parameter-Efficient Fine-Tuning (PEFT) techniques for diverse medical image analysis tasks. PEFT is increasingly exploited as a valuable approach for knowledge transfer from pre-trained models in natural language processing, vision, speech, and cross-modal tasks, such as vision-language and text-to-image generation. However, its application in medical image analysis remains relatively unexplored. As foundation models are increasingly exploited in the medical domain, it is crucial to investigate and comparatively assess various strategies for knowledge transfer that can bolster a range of downstream tasks. Our study, the first of its kind (to the best of our knowledge), evaluates 16 distinct PEFT methodologies proposed for convolutional and transformer-based networks, focusing on image classification and text-to-image generation tasks across six medical datasets ranging in size, modality, and complexity. Through a battery of more than 600 control
    
[^84]: 知识图谱的结构和动态，以及其表层性质

    The Structure and Dynamics of Knowledge Graphs, with Superficiality. (arXiv:2305.08116v1 [cs.AI])

    [http://arxiv.org/abs/2305.08116](http://arxiv.org/abs/2305.08116)

    该论文提出了第一个知识图谱的结构和动态模型，并引入表层性来简单建模复杂特征，从而掌握全局知识分布的平衡。

    

    大型知识图谱综合了从学术机构和企业到大众集资等项目中获得的人类知识，每两个节点之间的关系代表这两个实体之间的基本事实。关系语义的多样性组成了知识图谱的丰富性，导致出现有时混乱的奇异拓扑结构。然而，这种复杂特征可以通过引入表层性的概念来简单建模，表层性控制着独立生成事实的关系之间的重叠情况，也通过确定错误描述实体的比例来控制全局知识分布的平衡。这是知识图谱结构和动态方面的首个模型，有助于更好地理解正式知识获取和组织。

    Large knowledge graphs combine human knowledge garnered from projects ranging from academia and institutions to enterprises and crowdsourcing. Within such graphs, each relationship between two nodes represents a basic fact involving these two entities. The diversity of the semantics of relationships constitutes the richness of knowledge graphs, leading to the emergence of singular topologies, sometimes chaotic in appearance. However, this complex characteristic can be modeled in a simple way by introducing the concept of superficiality, which controls the overlap between relationships whose facts are generated independently. Superficiality also regulates the balance of the global distribution of knowledge by determining the proportion of misdescribed entities. This is the first model for the structure and dynamics of knowledge graphs. It leads to a better understanding of formal knowledge acquisition and organization.
    
[^85]: 区分和回答：通过辨别器缓解检索增强模型中虚假信息的影响

    Discern and Answer: Mitigating the Impact of Misinformation in Retrieval-Augmented Models with Discriminators. (arXiv:2305.01579v1 [cs.CL])

    [http://arxiv.org/abs/2305.01579](http://arxiv.org/abs/2305.01579)

    本文研究了现有检索增强语言模型假设所有检索信息都是正确的假设的问题，在实际应用中可能存在虚假信息导致冲突的情况下，提出了通过精细调整鉴别器和提示鉴别能力引出鲁棒性的方法，这显著改善了模型在知识冲突下的效果；同时提供了关于交替精细调整模型和上下文学习的新的结论。

    

    大多数现有的检索增强语言模型（LM）假定所有检索到的信息都是事实上正确的。本文研究一个更加现实的场景，即检索到的文档可能包含虚假信息，从而导致它们之间存在冲突。我们观察到，现有模型在精调和上下文少样本学习设置中对这种信息高度脆弱。我们提出了一些方法，通过明确地对鉴别器进行精细调整或提示来引出GPT-3的鉴别能力，使检索增强LM对虚假信息具有鲁棒性。我们在开放域问答方面的实证结果表明，这些方法显著改善了LM对知识冲突的鲁棒性。我们还提供了关于交替精细调整模型的决策与上下文学习过程的发现，为利用两者的最佳方式铺平了新的道路。

    Most existing retrieval-augmented language models (LMs) for question answering assume all retrieved information is factually correct. In this work, we study a more realistic scenario in which retrieved documents may contain misinformation, causing conflicts among them. We observe that the existing models are highly brittle to such information in both fine-tuning and in-context few-shot learning settings. We propose approaches to make retrieval-augmented LMs robust to misinformation by explicitly fine-tuning a discriminator or prompting to elicit discrimination capability in GPT-3. Our empirical results on open-domain question answering show that these approaches significantly improve LMs' robustness to knowledge conflicts. We also provide our findings on interleaving the fine-tuned model's decision with the in-context learning process, paving a new path to leverage the best of both worlds.
    
[^86]: 可控的信任权衡下的合成数据审计与生成

    Auditing and Generating Synthetic Data with Controllable Trust Trade-offs. (arXiv:2304.10819v1 [cs.LG])

    [http://arxiv.org/abs/2304.10819](http://arxiv.org/abs/2304.10819)

    本论文提出了一个审计框架，能够以全面的方式评估合成数据和AI模型的具体效果，包括偏见和歧视预防、对真实数据的忠实程度、效用、鲁棒性和隐私保护。在多个用例中，审计框架平衡了信任和效用之间的权衡。

    

    现实中收集的数据往往存在偏差、不平衡，并且有泄露敏感和隐私信息的风险。这一事实引发了创建合成数据集的想法，以减轻真实数据中固有的风险、偏见、伤害和隐私问题。这个概念依赖于生成AI模型，以产生不偏执、保护隐私的合成数据，同时忠实于真实数据。在这种新范式中，我们如何知道这种方法是否兑现了其承诺？我们提出了一个审计框架，提供了对合成数据集和基于它们训练的AI模型的全面评估，围绕偏见和歧视的预防、对真实数据的忠实程度、效用、鲁棒性和隐私保护。我们通过审计多个生成模型在不同用例中展示了我们的框架，包括教育、医疗保健、银行、人力资源，以及从表格，时间序列到自然语言的不同模态。我们的用例展示了在合成数据生成中平衡信任和效用的权衡的重要性。

    Data collected from the real world tends to be biased, unbalanced, and at risk of exposing sensitive and private information. This reality has given rise to the idea of creating synthetic datasets to alleviate risk, bias, harm, and privacy concerns inherent in the real data. This concept relies on Generative AI models to produce unbiased, privacy-preserving synthetic data while being true to the real data. In this new paradigm, how can we tell if this approach delivers on its promises? We present an auditing framework that offers a holistic assessment of synthetic datasets and AI models trained on them, centered around bias and discrimination prevention, fidelity to the real data, utility, robustness, and privacy preservation. We showcase our framework by auditing multiple generative models on diverse use cases, including education, healthcare, banking, human resources, and across different modalities, from tabular, to time-series, to natural language. Our use cases demonstrate the imp
    
[^87]: 通过从光流信息中融合运动结构与模拟数据的绝对位置回归，解决室内环境定位的挑战性问题

    Fusing Structure from Motion and Simulation-Augmented Pose Regression from Optical Flow for Challenging Indoor Environments. (arXiv:2304.07250v1 [cs.CV])

    [http://arxiv.org/abs/2304.07250](http://arxiv.org/abs/2304.07250)

    本文探讨了如何在室内环境下进行运动目标的定位，使用了结构运动与模拟数据和深度学习技术。研究者整合光流和相对姿态回归方法帮助解决了因运动模糊、光照变化、重复图案和缺乏特征结构等问题而带来的瓶颈，为室内目标定位提供了更好的方案。

    

    目标的定位是各种应用中的重要任务，比如机器人、虚拟和增强现实、和在仓库中运送货物。深度学习的先进发展已经使得使用单目视觉相机进行定位成为可能。然而，所面临的挑战是由于环境本身引起的问题，例如运动模糊、光照变化、重复图案和缺乏特征的结构。本研究旨在通过融合附加信息和使用相对位置回归（RPR）方法来解决这些问题。使用Lucas-Kanade算法计算连续图像之间的光流，并使用辅助小型循环卷积网络来预测相对姿态。将绝对姿态和相对姿态进行融合。

    The localization of objects is a crucial task in various applications such as robotics, virtual and augmented reality, and the transportation of goods in warehouses. Recent advances in deep learning have enabled the localization using monocular visual cameras. While structure from motion (SfM) predicts the absolute pose from a point cloud, absolute pose regression (APR) methods learn a semantic understanding of the environment through neural networks. However, both fields face challenges caused by the environment such as motion blur, lighting changes, repetitive patterns, and feature-less structures. This study aims to address these challenges by incorporating additional information and regularizing the absolute pose using relative pose regression (RPR) methods. The optical flow between consecutive images is computed using the Lucas-Kanade algorithm, and the relative pose is predicted using an auxiliary small recurrent convolutional network. The fusion of absolute and relative poses is
    
[^88]: 基于权重滤波的多类可解释性卸载图像分类

    Multi-Class Explainable Unlearning for Image Classification via Weight Filtering. (arXiv:2304.02049v1 [cs.CV])

    [http://arxiv.org/abs/2304.02049](http://arxiv.org/abs/2304.02049)

    本论文提出一种基于权重滤波的多类可解释性卸载图像分类方法，可以在单个未训练轮中取消学习网络的所有类别，并且恢复可解释的类别表示。

    

    机器卸载是最近浮现的一种选择性地将训练数据点的影响从网络中删除的范式。尽管现有方法已经集中在卸载训练数据的小子集或单个类别，但在本文中，我们采取了不同的方法，设计了一个框架，可以在单个未训练轮中取消学习图像分类网络的所有类别。我们提出的方法通过内部组件的记忆矩阵来调节图像分类网络，以便在训练后，同一网络可以有选择地展示任何类别的未学习行为。通过发现每个类别特定的权重，我们的方法还通过设计可解释性机制来恢复类别的表示。我们在小规模和中规模图像分类数据集上使用CNN和Transformer-based骨架测试了提出的框架。我们的工作提供了一种多类可解释性卸载的解决方案。

    Machine Unlearning has recently been emerging as a paradigm for selectively removing the impact of training datapoints from a network. While existing approaches have focused on unlearning either a small subset of the training data or a single class, in this paper we take a different path and devise a framework that can unlearn all classes of an image classification network in a single untraining round. Our proposed technique learns to modulate the inner components of an image classification network through memory matrices so that, after training, the same network can selectively exhibit an unlearning behavior over any of the classes. By discovering weights which are specific to each of the classes, our approach also recovers a representation of the classes which is explainable by-design. We test the proposed framework, which we name Weight Filtering network (WF-Net), on small-scale and medium-scale image classification datasets, with both CNN and Transformer-based backbones. Our work p
    
[^89]: 基于可解释性和不平衡半监督的深度学习框架改善皮肤疾病不同诊断的研究

    An interpretable imbalanced semi-supervised deep learning framework for improving differential diagnosis of skin diseases. (arXiv:2211.10858v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.10858](http://arxiv.org/abs/2211.10858)

    本文提出了一种基于可解释性和不平衡半监督深度学习框架的研究，利用伪标签样本进行自我训练来解决皮肤疾病分类中的类别不平衡问题，并取得了令人满意的性能表现。

    

    皮肤疾病是世界上最常见的疾病之一。本文利用58,457张皮肤图像和10,857个未标记样本，对多类智能皮肤诊断框架（ISDL）的可解释性和不平衡的半监督学习进行了研究。通过在不平衡性类别的伪标签样本上自我训练，在每次迭代中使少数类别的伪标签样本具有更高的概率，从而促进了未标记样本的利用，解决了类别不平衡问题。我们的ISDL在多标签皮肤病分类中取得了令人满意的性能，准确率为0.979，灵敏度为0.975，特异度为0.973，宏F1分数为0.974，接收者操作特征曲线下面积（AUC）为0.999。我们还将Shapley Additive explanation (SHAP)方法与ISDL结合，解释了深度学习模型的预测方式。这一发现与临床诊断一致。我们还提出了一种采样分布最优化的方法。

    Dermatological diseases are among the most common disorders worldwide. This paper presents the first study of the interpretability and imbalanced semi-supervised learning of the multiclass intelligent skin diagnosis framework (ISDL) using 58,457 skin images with 10,857 unlabeled samples. Pseudo-labelled samples from minority classes have a higher probability at each iteration of class-rebalancing self-training, thereby promoting the utilization of unlabeled samples to solve the class imbalance problem. Our ISDL achieved a promising performance with an accuracy of 0.979, sensitivity of 0.975, specificity of 0.973, macro-F1 score of 0.974 and area under the receiver operating characteristic curve (AUC) of 0.999 for multi-label skin disease classification. The Shapley Additive explanation (SHAP) method is combined with our ISDL to explain how the deep learning model makes predictions. This finding is consistent with the clinical diagnosis. We also proposed a sampling distribution optimisa
    
[^90]: 缓解分层注意力多尺度算子学习中的光谱偏差问题

    Mitigating spectral bias for the multiscale operator learning with hierarchical attention. (arXiv:2210.10890v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.10890](http://arxiv.org/abs/2210.10890)

    本文提出了一种分层注意力神经算子（HANO），用于解决多尺度偏微分方程学习中存在的光谱偏差问题，并通过数值实验证明其优于现有方法。

    

    神经算子已经成为学习偏微分方程（PDE）的无限维参数和解空间之间映射的强大工具。本文关注于具有重要应用的多尺度PDE，如油藏建模和湍流预测。我们证明对于这种PDE，对低频分量存在光谱偏差是现有神经算子的一大挑战。为了解决这个挑战，我们提出了一种受层次矩阵方法启发的分层注意力神经算子（HANO）。HANO具有自适应尺度交互范围和层次结构上的自注意力机制，能够实现可控线性成本的嵌套特征计算和多尺度解空间的编码/解码。我们还采用经验H^1损失函数来增强对高频分量的学习。我们的数值实验表明，HANO优于现有的最先进方法（SOTA）。

    Neural operators have emerged as a powerful tool for learning the mapping between infinite-dimensional parameter and solution spaces of partial differential equations (PDEs). In this work, we focus on multiscale PDEs that have important applications such as reservoir modeling and turbulence prediction. We demonstrate that for such PDEs, the spectral bias towards low-frequency components presents a significant challenge for existing neural operators. To address this challenge, we propose a hierarchical attention neural operator (HANO) inspired by the hierarchical matrix approach. HANO features a scale-adaptive interaction range and self-attentions over a hierarchy of levels, enabling nested feature computation with controllable linear cost and encoding/decoding of multiscale solution space. We also incorporate an empirical $H^1$ loss function to enhance the learning of high-frequency components. Our numerical experiments demonstrate that HANO outperforms state-of-the-art (SOTA) methods 
    

