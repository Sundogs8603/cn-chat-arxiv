# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [InceptionNeXt: When Inception Meets ConvNeXt.](http://arxiv.org/abs/2303.16900) | 本论文提出了一种名为InceptionNeXt的新型神经网络，通过将大内核卷积沿通道维度分解为四个平行分支来提高模型效率，解决了保持性能的同时加快基于大内核的CNN模型的问题。 |
| [^2] | [ViewRefer: Grasp the Multi-view Knowledge for 3D Visual Grounding with GPT and Prototype Guidance.](http://arxiv.org/abs/2303.16894) | 本文提出了ViewRefer，这是一个多视角的三维视觉定位框架，利用大规模语言模型和多视角原型，从文本和3D模态中获取视角知识并增强框架的表现。 |
| [^3] | [Zero-shot Entailment of Leaderboards for Empirical AI Research.](http://arxiv.org/abs/2303.16835) | 本文探讨了自动挖掘 Empirical AI Research 领域排行榜这一任务类别中的零样本学习现象。实验测试了先前报告的最新技术模型在其未见过的排行榜标签上的泛化能力或 entailment 能力。本文创建了一个零样本标记的数据集。 |
| [^4] | [Decision Making for Autonomous Driving in Interactive Merge Scenarios via Learning-based Prediction.](http://arxiv.org/abs/2303.16821) | 本研究提出了在自动驾驶车辆与其他车辆交互合流的情况下，基于学习的预测的决策制定方法来解决高度挑战的决策问题和不确定性，并采用部分可观察的马尔可夫决策过程（POMDP）和蒙特卡罗树搜索算法来执行高级驾驶操作。 |
| [^5] | [Thistle: A Vector Database in Rust.](http://arxiv.org/abs/2303.16780) | Thistle是一个完全功能的向量数据库，旨在解决回答搜索查询中的潜在知识领域问题，已经在MS MARCO数据集上进行了基准测试，并且有助于推进Rust ML生态系统的发展。 |
| [^6] | [Assorted, Archetypal and Annotated Two Million (3A2M) Cooking Recipes Dataset based on Active Learning.](http://arxiv.org/abs/2303.16778) | 本研究利用领域专家的知识和主动学习技术呈现了一个两百万份烹饪食谱新数据集，通过将30万份食谱按照命名实体识别进行分类到9个类别中，然后使用混合方法对其余的1900K份食谱进行分类。 |
| [^7] | [A Novel Patent Similarity Measurement Methodology: Semantic Distance and Technological Distance.](http://arxiv.org/abs/2303.16767) | 该研究提出了一种混合方法，用于自动测量专利之间的相似性，同时考虑语义和技术相似性，并且实验证明该方法优于仅考虑语义相似性的方法。 |
| [^8] | [Computationally Efficient Labeling of Cancer Related Forum Posts by Non-Clinical Text Information Retrieval.](http://arxiv.org/abs/2303.16766) | 本研究基于非临床和免费可用的信息，结合分布式计算、文本检索、聚类和分类方法开发了一个能够检索、聚类和展示关于癌症病程信息的计算有效系统。 |
| [^9] | [Dialogue-to-Video Retrieval.](http://arxiv.org/abs/2303.16761) | 本研究提出了一种基于对话的视频检索系统，使用对话作为搜索描述符，有效地提高了视频检索的准确性。 |
| [^10] | [ACO-tagger: A Novel Method for Part-of-Speech Tagging using Ant Colony Optimization.](http://arxiv.org/abs/2303.16760) | 本研究提出了一种基于蚁群优化的高效词性标注方法ACO-tagger，实现了高达96.867％的准确率，优于几种最先进的方法。 |
| [^11] | [How can Deep Learning Retrieve the Write-Missing Additional Diagnosis from Chinese Electronic Medical Record For DRG.](http://arxiv.org/abs/2303.16757) | 该论文提出了一种使用深度学习的方法，从电子病历中检索漏诊的额外诊断，以适用于DRG分组，解决了漏诊问题导致医疗记录不完整、影响DRG招生正确率的问题。 |
| [^12] | [LLM for Patient-Trial Matching: Privacy-Aware Data Augmentation Towards Better Performance and Generalizability.](http://arxiv.org/abs/2303.16756) | 本文提出了一种隐私感知数据增强的LLM-PTM方法，有效地提高了患者-试验匹配的性能和泛化能力。 |
| [^13] | [Training Language Models with Language Feedback at Scale.](http://arxiv.org/abs/2303.16755) | 本文提出一种新方法，即利用更丰富的语言反馈进行模仿学习，通过三个迭代步骤对语言模型进行训练以生成更符合人类偏好的输出。 |
| [^14] | [Judicial Intelligent Assistant System: Extracting Events from Divorce Cases to Detect Disputes for the Judge.](http://arxiv.org/abs/2303.16751) | 本文提出了一种基于两轮标注事件提取技术的离婚案件争议检测方法，实现了司法智能助手（JIA）系统，以自动从离婚案件材料中提取重点事件，通过识别其中的共指来对事件进行对齐，并检测冲突。 |
| [^15] | [Improving Code Generation by Training with Natural Language Feedback.](http://arxiv.org/abs/2303.16749) | 该论文提出了一种新算法ILF，通过从自然语言反馈中进行学习来显著提高代码生成模型的性能，即使只有少量反馈，也可以获得很好的效果。 |
| [^16] | [Communication Load Balancing via Efficient Inverse Reinforcement Learning.](http://arxiv.org/abs/2303.16686) | 本文使用逆强化学习方法成功解决了通信负载均衡问题，首次将逆强化学习应用于该领域。 |
| [^17] | [Policy Reuse for Communication Load Balancing in Unseen Traffic Scenarios.](http://arxiv.org/abs/2303.16685) | 提出了一种策略重用框架，该框架通过选择最适合执行的预训练强化学习策略来解决通信负载平衡问题，其根据不同流量场景下的策略训练库进行选择，可以胜过传统的负载平衡算法。 |
| [^18] | [Preventing Object-centric Discovery of Unsound Process Models for Object Interactions with Loops in Collaborative Systems: Extended Version.](http://arxiv.org/abs/2303.16680) | OCPD范例转变了流程挖掘，可以处理与一系列对象相关联的事件，本文提出的扩展OCPD方法可以避免原方法中关于多对象交互循环的错误问题。 |
| [^19] | [Neuro-symbolic Rule Learning in Real-world Classification Tasks.](http://arxiv.org/abs/2303.16674) | 本研究通过将神经范式模块扩展到多类和多标签实际分类任务中，以及强制实现符号互斥属性，提高了神经符号规则学习模型的准确性和可解释性。 |
| [^20] | [A Byzantine-Resilient Aggregation Scheme for Federated Learning via Matrix Autoregression on Client Updates.](http://arxiv.org/abs/2303.16668) | 本文提出了FLANDERS，一种基于矩阵自回归的联邦学习聚合方案，可以识别恶意客户端，并提供了强大的拜占庭攻击防御。 |
| [^21] | [A Hierarchical Game-Theoretic Decision-Making for Cooperative Multi-Agent Systems Under the Presence of Adversarial Agents.](http://arxiv.org/abs/2303.16641) | 本文提出了一种名为GUT的新型分层式博弈论实用树模型，在多智能体决策中实现高低层次策略分解，使用代理需求作为新的收益度量，通过广泛的数值模拟表明可以帮助MAS以更低的成本和更高的获胜率实现具有挑战性的任务。 |
| [^22] | [GPTEval: NLG Evaluation using GPT-4 with Better Human Alignment.](http://arxiv.org/abs/2303.16634) | 本文介绍了GPTEval，一个利用链式思考和形式填充评价NLG生成的质量。实验表明，在文本摘要任务中，GPTEval结合GPT-4取得了0.514的斯皮尔曼相关系数，胜过其他方法。 |
| [^23] | [Fairlearn: Assessing and Improving Fairness of AI Systems.](http://arxiv.org/abs/2303.16626) | Fairlearn是一个有助于评估和提高人工智能系统公平性的开源项目，通过可视化地评估受影响人群的模型输出，并提供多种算法来缓解不公平问题，同时还在考虑系统的更广泛社会背景方面提供了学习资源。 |
| [^24] | [AraSpot: Arabic Spoken Command Spotting.](http://arxiv.org/abs/2303.16621) | AraSpot是一款使用ConformerGRU模型架构训练40个阿拉伯语关键词的口语命令识别工具，其通过在线数据增强和文本到语音模型的训练提高了性能，并以99.59%的准确率超出以往的方法。 |
| [^25] | [Personalised Language Modelling of Screen Characters Using Rich Metadata Annotations.](http://arxiv.org/abs/2303.16618) | 本篇论文研究了如何使用丰富的元数据注释的信息进行屏幕角色的个性化语言建模，测试表明这样可以有效地进行个性化语言模型的构建，即使对于零样本的演说家也可以应用。 |
| [^26] | [Implicit Visual Bias Mitigation by Posterior Estimate Sharpening of a Bayesian Neural Network.](http://arxiv.org/abs/2303.16564) | 该论文提出了一种隐式减轻视觉偏见的方法，使用贝叶斯神经网络，通过后验估计尖锐化，鼓励网络聚焦于不导致高不确定性的中心特征。 |
| [^27] | [Plan4MC: Skill Reinforcement Learning and Planning for Open-World Minecraft Tasks.](http://arxiv.org/abs/2303.16563) | 本论文提出了一种基于技能强化学习和规划的 Minecraft 开放式任务解决方案，通过学习基本技能和技能规划的方法有效提高了任务解决效率，实现了24个不同的任务并在大多数任务中优于基线算法。 |
| [^28] | [Self-accumulative Vision Transformer for Bone Age Assessment Using the Sauvegrain Method.](http://arxiv.org/abs/2303.16557) | 该研究提出了一种基于自累积视觉变换器的方法，应用于骨龄评估。通过应用标记重放和区域注意偏差，该方法有效地挖掘地标之间的关系并学习全局形态特征，使骨龄评估的平均绝对误差比之前的工作降低了0.11。 |
| [^29] | [Building a Knowledge Graph of Distributed Ledger Technologies.](http://arxiv.org/abs/2303.16528) | 本文建立了一个包括安全、应用领域、标准法规等方面的分布式分类账技术的知识图谱，有助于拓展人们对该技术的理解和寻找新的用例。 |
| [^30] | [Development of a deep learning-based tool to assist wound classification.](http://arxiv.org/abs/2303.16522) | 本文提出了一个基于深度学习的伤口分类工具，可以协助医务人员对五种关键伤口情况进行分类。使用了多任务深度学习框架，使用Cohen's kappa系数来评估模型的准确性，模型的表现优于或不劣于所有医务人员。 |
| [^31] | [Fair Federated Medical Image Segmentation via Client Contribution Estimation.](http://arxiv.org/abs/2303.16520) | 本论文提出了一种新方法，在客户贡献评估下同时优化协作公平性和性能公平性，以获得高质量的全局模型。 |
| [^32] | [From axioms over graphs to vectors, and back again: evaluating the properties of graph-based ontology embeddings.](http://arxiv.org/abs/2303.16519) | 本文研究了几种图形投影方法，并提供了选定适当图形投影的指导方针。 |
| [^33] | [Cascaded Local Implicit Transformer for Arbitrary-Scale Super-Resolution.](http://arxiv.org/abs/2303.16513) | 本文提出了局部隐式变换器（LIT）和级联LIT (CLIT) ，结合注意力机制和多尺度特征，实现任意尺度超分辨率，并在实验证明其有效性和优越性。 |
| [^34] | [Local Interpretability of Random Forests for Multi-Target Regression.](http://arxiv.org/abs/2303.16506) | 本文提出了一种针对随机森林模型在多目标回归中产生基于规则解释的技术，并在广泛实验评估中证明其具有竞争力。 |
| [^35] | [Distrust in (X)AI -- Measurement Artifact or Distinct Construct?.](http://arxiv.org/abs/2303.16495) | 这篇论文探讨了XAI中的信任与不信任之间的潜在区别，为探讨不同的信任概念化和缺乏验证的信任问卷提出了一种新的思考角度。 |
| [^36] | [GNNBuilder: An Automated Framework for Generic Graph Neural Network Accelerator Generation, Simulation, and Optimization.](http://arxiv.org/abs/2303.16459) | GNNBuilder是一个自动化的、通用的、端到端的GNN加速器生成框架，它可以为用户任意定义的广泛的GNN模型自动生成加速器，且运行速度比软件基准快多达12.95倍。 |
| [^37] | [ProtFIM: Fill-in-Middle Protein Sequence Design via Protein Language Models.](http://arxiv.org/abs/2303.16452) | 本论文介绍了一种基于蛋白质语言模型的填充中间蛋白序列设计方法，并设计了新的基准测试SEIFER，揭示了现有语言模型的弱点，证明了使用填充中间变换训练的语言模型(ProtFIM)，更适合于蛋白质工程。 |
| [^38] | [TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs.](http://arxiv.org/abs/2303.16434) | TaskMatrix.AI是一个任务完成系统，可以将基础模型与数百万个API连接，提高完成任务的效率和全面性。 |
| [^39] | [ProductAE: Toward Deep Learning Driven Error-Correction Codes of Large Dimensions.](http://arxiv.org/abs/2303.16424) | 本文提出了Product Autoencoder来通过可管理的训练复杂性实现相对较大的代码的训练。 |
| [^40] | [A Comprehensive and Versatile Multimodal Deep Learning Approach for Predicting Diverse Properties of Advanced Materials.](http://arxiv.org/abs/2303.16412) | 本文提出了一种多模态深度学习方法，利用物理属性和化学数据预测先进材料的特性，在处理高维信息空间方面具有很大优势，成功预测了114210种组成条件下的913680个属性数据点，该方法适用于不同材料和尺度。 |
| [^41] | [LMDA-Net:A lightweight multi-dimensional attention network for general EEG-based brain-computer interface paradigms and interpretability.](http://arxiv.org/abs/2303.16407) | 本论文提出了一种名为LMDA-Net的轻量级多维注意力网络，旨在提高通用EEG脑机接口范例的分类性能。该网络使用两个新型注意力模块——通道注意力模块和深度注意力模块，并在多个公开高影响力数据集上进行了评估。实验结果表明，LMDA-Net表现优于其他代表模型，实现了最先进的性能，并展示了其决策过程的高可解释性。 |
| [^42] | [Hierarchical Video-Moment Retrieval and Step-Captioning.](http://arxiv.org/abs/2303.16406) | 这篇论文提出了HiREST数据集和一个新的基准，将分层信息检索和视觉/文本逐步总结从教学视频语料库中推广，使得在一个端到端的设置下可以共同搜索视频语料库，并生成摘要。 |
| [^43] | [Language-Guided Audio-Visual Source Separation via Trimodal Consistency.](http://arxiv.org/abs/2303.16342) | 该论文提出了一种自监督学习的方法，通过使用自然语言查询来进行音频源分离，实现了语言、视觉和音频的一致性对齐，并在多个数据集上表现出比现有方法更好的效果。 |
| [^44] | [On the Local Cache Update Rules in Streaming Federated Learning.](http://arxiv.org/abs/2303.16340) | 本文提出了三种本地缓存更新规则来管理动态数据分布和有限的缓存容量，以应对流式联邦学习中本地训练数据集与长期数据分布之间的差异。我们还推导出了该算法的收敛界限。我们在两个数据集上进行了测试，结果表明我们的算法效果良好。 |
| [^45] | [FMAS: Fast Multi-Objective SuperNet Architecture Search for Semantic Segmentation.](http://arxiv.org/abs/2303.16322) | 本文提出了快速多目标神经架构搜索框架FMAS，搜索有效的语义分割模型，能够快速找到有竞争力的设计，并在边缘设备上找到更快的网络。 |
| [^46] | [Worst-Case Control and Learning Using Partial Observations Over an Infinite Time-Horizon.](http://arxiv.org/abs/2303.16321) | 本文提出了无限时间视角下部分观测系统的最坏情况控制和学习的框架，能够利用未知概率分布的有限值不确定变量，并能够通过定义信息状态来提高动态规划的计算可处理性，同时提出了可从观测数据中构建或学习的近似信息状态。 |
| [^47] | [Crime Prediction Using Machine Learning and Deep Learning: A Systematic Review and Future Directions.](http://arxiv.org/abs/2303.16310) | 该综述文章调查了超过150篇文章，探讨了各种机器学习和深度学习算法在预测犯罪方面的应用，为研究人员提供有价值的参考资料。 |
| [^48] | [Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels.](http://arxiv.org/abs/2303.16296) | 本文提出的Dice半度量损失函数可在软标签设置中使用，在医疗成像领域的分割方案中与使用软标签的研究相结合，可以获得更好的Dice分数和模型校准。 |
| [^49] | [XAIR: A Framework of Explainable AI in Augmented Reality.](http://arxiv.org/abs/2303.16292) | XAIR是一个解决AR中XAI输出解释的设计框架，可以为设计者提供指南和支持，实现有效的XAI设计。 |
| [^50] | [A Perspectival Mirror of the Elephant: Investigating Language Bias on Google, ChatGPT, Wikipedia, and YouTube.](http://arxiv.org/abs/2303.16281) | 研究发现在Google、ChatGPT、维基百科和YouTube上，搜索结果受限于语言，反映了与复杂主题相关的文化刻板印象，缺乏跨文化视角。 |
| [^51] | [Optimisation via encodings: a renormalisation group perspective.](http://arxiv.org/abs/2303.16258) | 本文提出了一种通过使用启发式算法构造覆盖编码映射，将大型搜索空间中的过程映射到原始搜索空间的子集中，并使用重整化群的视角来处理离散优化问题的方法。这种方法相对于单独的局部搜索方法具有更好的性能。 |
| [^52] | [On Codex Prompt Engineering for OCL Generation: An Empirical Study.](http://arxiv.org/abs/2303.16244) | 本文研究了使用Codex生成OCL约束，通过提高提示模板的领域特定信息和少量样本学习可以显著提高生成约束的质量。 |
| [^53] | [An EMO Joint Pruning with Multiple Sub-networks: Fast and Effect.](http://arxiv.org/abs/2303.16212) | 本文提出了一种基于多子网络的EMO联合剪枝算法，该算法可以减少空间和资源消耗。该算法采用分治的EMO网络剪枝框架，将整个网络上复杂的EMO剪枝任务分解为多个子网络上更简单的子任务。基于跨网络约束的子网络训练方法可以进一步提高性能。 |
| [^54] | [The Quality-Diversity Transformer: Generating Behavior-Conditioned Trajectories with Decision Transformers.](http://arxiv.org/abs/2303.16207) | 该论文提出了一种基于质量多样性算法和 Transformer 的方法，通过两种机制以实现质量一致的生成行为条件下的轨迹。 |
| [^55] | [Your Diffusion Model is Secretly a Zero-Shot Classifier.](http://arxiv.org/abs/2303.16203) | 扩散模型的密度估计可以被用作零样本分类，作者的生成式分类方法在各种基准测试中取得强大的结果，并具有更强的多模式关系推理能力。 |
| [^56] | [Reproducibility is Nothing without Correctness: The Importance of Testing Code in NLP.](http://arxiv.org/abs/2303.16166) | 在NLP研究中，我们不能仅凭感知质量假定代码正确性，应该推动采用编码最佳实践以提高实验结果的正确性和可靠性。 |
| [^57] | [The transformative potential of machine learning for experiments in fluid mechanics.](http://arxiv.org/abs/2303.15832) | 本文介绍了机器学习在实验流体力学中的三个方面的应用潜力：提高测量技术精度，改进实验设计和实现实时估计和控制。 |
| [^58] | [Foundation Models and Fair Use.](http://arxiv.org/abs/2303.15715) | 基础模型开发和部署需确保在合理使用的范围内，但这并不保证。在使用有版权内容时需要注意风险并可能需要进一步的工作。 |
| [^59] | [Diffusion Denoised Smoothing for Certified and Adversarial Robust Out-Of-Distribution Detection.](http://arxiv.org/abs/2303.14961) | 本研究提出了一个新的方法来证明$\ell_2$-norm下的样本外检测的鲁棒性，在不考虑网络架构和具体组件的情况下，改善了对抗攻击的检测技术。 |
| [^60] | [Learning Spatial-Temporal Implicit Neural Representations for Event-Guided Video Super-Resolution.](http://arxiv.org/abs/2303.13767) | 本文提出了一种新的框架，利用事件的时空插值来实现随机尺度下的视频超分辨率。方法包括从RGB帧和事件的查询空间-时间坐标和特征中学习隐式神经表示。 |
| [^61] | [DDT: A Diffusion-Driven Transformer-based Framework for Human Mesh Recovery from a Video.](http://arxiv.org/abs/2303.13397) | 提出了一种基于扩散驱动变压器的视频 HMR 框架（DDT），它旨在从输入序列中解码特定的运动模式，增强运动平滑性和时间一致性，并输出所有帧的人体网格，使得 DDT 更适用于时间效率至关重要的实际应用。 |
| [^62] | [Path Planning for Autonomous Driving: The State of the Art and Perspectives.](http://arxiv.org/abs/2303.09824) | 本文综述了现有的自动驾驶路径规划方法，包括管道规划和端到端规划方法。在挑战和潜在解决方案方面提供了讨论，有助于为智能汽车的发展提供更好的规划方法。 |
| [^63] | [Protecting Society from AI Misuse: When are Restrictions on Capabilities Warranted?.](http://arxiv.org/abs/2303.09377) | 随着人工智能系统能力不断提升，控制某些能力将有助于防止其滥用，这些限制可能包括控制访问、使用目的、输出与溯源以及开发资源，非AI能力限制也是必要的。尽管可能会降低使用率而增加滥用风险，但这些限制是当其他干预行不通、潜在危害性高、有有针对性方式干预时所必要的。 |
| [^64] | [Translating Radiology Reports into Plain Language using ChatGPT and GPT-4 with Prompt Learning: Promising Results, Limitations, and Potential.](http://arxiv.org/abs/2303.09038) | 本文研究探讨利用ChatGPT将放射学报告翻译成通俗易懂的语言，平均得分为5分制的4.1分，信息缺失率和信息错误率均较低，ChatGPT提供的建议大都与放射学报告相关。 |
| [^65] | [I$^2$-SDF: Intrinsic Indoor Scene Reconstruction and Editing via Raytracing in Neural SDFs.](http://arxiv.org/abs/2303.07634) | 本文提出了 I$^2$-SDF 方法，使用可微分的蒙特卡罗光线跟踪技术实现了室内场景的重建和编辑，采用气泡损失函数和错误引导的自适应采样方案提高了重建质量，同时分解神经辐射场为场景的空间变化材料实现了物理和逼真的场景编辑应用。 |
| [^66] | [GBMST: An Efficient Minimum Spanning Tree Clustering Based on Granular-Ball Computing.](http://arxiv.org/abs/2303.01082) | 该论文提出了一种基于多粒度颗粒球和最小生成树的聚类算法，通过实现基于“大规模优先级”的聚类方法，可以大大避免异常值的影响，并加速了MST的构建过程。 |
| [^67] | [On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective.](http://arxiv.org/abs/2302.12095) | 本研究评估了ChatGPT的鲁棒性，发现其在对抗性和超出分布任务上有一致的优势，但绝对表现仍有提高空间，鲁棒性仍是一个重要的挑战。 |
| [^68] | [Jaccard Metric Losses: Optimizing the Jaccard Index with Soft Labels.](http://arxiv.org/abs/2302.05666) | 本文提出了Jaccard度量损失（JMLs）来优化Jaccard指数，该损失在软标签下仍然有效。 |
| [^69] | [Automatic Network Adaptation for Ultra-Low Uniform-Precision Quantization.](http://arxiv.org/abs/2212.10878) | 本论文提出了一种名为神经通道扩展的神经架构搜索方法，该方法能够自适应多个流行网络，通过选择性扩展通道和满足硬件约束，实现了超低均匀精度量化对推理准确性的减轻和提升，其中2bit ResNet50准确率达到了目前最佳水平。 |
| [^70] | [Does CLIP Bind Concepts? Probing Compositionality in Large Image Models.](http://arxiv.org/abs/2212.10537) | 本文分析了大型神经网络模型CLIP的组合性能力以及以结构敏感的方式捆绑变量的能力，发现其能够在单一对象的情况下组合概念，但在需要概念捆绑的情况下性能显著下降。 |
| [^71] | [Large Language Models are reasoners with Self-Verification.](http://arxiv.org/abs/2212.09561) | 本文提出了一种新的自我验证方法，使用CoT的结论来构建新样本并要求LLM重新预测原始条件，以提高推理准确性。实验证明，LLMs可以对其自己的结论进行自我验证并实现竞争性的推理性能。 |
| [^72] | [Motif-aware temporal GCN for fraud detection in signed cryptocurrency trust networks.](http://arxiv.org/abs/2211.13123) | 本文提出了一种基于图卷积网络和平衡理论的加密货币信任网络欺诈检测方法，并使用模式矩阵捕捉局部拓扑信息。实验结果表明，该方法在真实数据和合成数据集上均优于现有方法。 |
| [^73] | [CRAFT: Concept Recursive Activation FacTorization for Explainability.](http://arxiv.org/abs/2211.10154) | CRAFT通过生成基于概念的解释来填补归因方法的局限性，实现了对图像“是什么”和“在哪里”的同时解释。 |
| [^74] | [VGFlow: Visibility guided Flow Network for Human Reposing.](http://arxiv.org/abs/2211.08540) | 提出了一种基于可见性引导流模块的流网络模型VGFlow，可以分离出目标的可见和不可见部分以实现纹理保留和风格操作，同时采用了多路径结构以在不同级别的细节上操作。在生成逼真人体姿势方面表现出有效性。 |
| [^75] | [Changing agents and ascribing beliefs in dynamic epistemic logic.](http://arxiv.org/abs/2211.02452) | 本文在动态认知逻辑中扩展了行动框架，提出了代理更新框架，可以有选择性地添加或删除代理，并进行代理更新。这个框架可以用于模拟一些有趣的例子，并在人工智能问题的建模中得到应用。 |
| [^76] | [Multi-Viewpoint and Multi-Evaluation with Felicitous Inductive Bias Boost Machine Abstract Reasoning Ability.](http://arxiv.org/abs/2210.14914) | 本文研究了机器在抽象推理方面的能力，证明了具有适宜的归纳偏差的神经网络可以优雅地解决RPM问题，并揭示了多视角和多评估是成功推理的关键学习策略。 |
| [^77] | [Instance-Aware Image Completion.](http://arxiv.org/abs/2210.12350) | 本文提出了一个实例感知图像修复模型ImComplete，相比现有方法，它可以幻象出与环境背景相协调的视觉实例，提供了基于语义和结构的像素级指导。 |
| [^78] | [The Interplay of AI and Digital Twin: Bridging the Gap between Data-Driven and Model-Driven Approaches.](http://arxiv.org/abs/2209.12423) | 本文全面回顾了AI和数字孪生之间的相互作用，重点介绍了数字孪生网络的各种用例和应用，以及其如何弥合数据驱动和模型驱动方法的差距。 |
| [^79] | [Deep Convolutional Pooling Transformer for Deepfake Detection.](http://arxiv.org/abs/2209.05299) | 本文提出了一种深度卷积池化变换器用于Deepfake检测，能够全面地融合局部和全局的图像特征，并采用注意力掩模丢失方法提高模型泛化能力，获得了多个基准数据集上的最优检测性能。 |
| [^80] | [What Does the Gradient Tell When Attacking the Graph Structure.](http://arxiv.org/abs/2208.12815) | 本文研究了图神经网络中针对图形结构的对抗攻击，发现攻击者更倾向于增加类间边缘，通过连接不同类的节点来更有效地破坏节点特征。然而，GNN 的固有平滑性会导致在前向过程中丢失关键信息。为此，我们提出了一个具有多级传播的新型代理模型来解决这个问题。 |
| [^81] | [A methodology to characterize bias and harmful stereotypes in natural language processing in Latin America.](http://arxiv.org/abs/2207.06591) | 本研究提出了一种自动检测和表征拉丁美洲自然语言处理系统中偏见和有害刻板印象的方法。该方法基于单词嵌入之间的相似性和数据源的分析，并在西班牙语、葡萄牙语和克丘亚语的有害刻板印象检测案例中进行测试。结果表明，不同的自然语言处理系统以不同甚至意想不到的方式存在偏见和放大有害的刻板印象。 |
| [^82] | [NovelCraft: A Dataset for Novelty Detection and Discovery in Open Worlds.](http://arxiv.org/abs/2206.11736) | NovelCraft数据集提供了开放世界中新颖性检测与发现任务的挑战。在复杂的场景中插入新颖物体的检测需要更好的基准，并发现了控制假阳性时更简单的方法可能比复杂的方法更出色。 |
| [^83] | [From {Solution Synthesis} to {Student Attempt Synthesis} for Block-Based Visual Programming Tasks.](http://arxiv.org/abs/2205.01265) | 研究自动推断学生误解的关键组成部分，引入了一个基准测试——StudentSyn，通过观察学生在一个任务上的尝试，合成他们对另一个任务的学习尝试，以提高人工智能驱动的编程导师的效果。 |
| [^84] | [IOP-FL: Inside-Outside Personalization for Federated Medical Image Segmentation.](http://arxiv.org/abs/2204.08467) | 该论文提出了IOP-FL，一种联邦学习的内外个性化方法，以增强医学成像任务中单个客户的预测准确性。 |
| [^85] | [The Prominence of Artificial Intelligence in COVID-19.](http://arxiv.org/abs/2111.09537) | 本论文研究人工智能在 COVID-19 中的应用，探讨了提出的方法，可帮助早期和廉价地诊断该病，有助于医生和研究人员对抗该病。 |
| [^86] | [HARPS: An Online POMDP Framework for Human-Assisted Robotic Planning and Sensing.](http://arxiv.org/abs/2110.10324) | 本文介绍了HARPS框架，该框架通过在线采样型POMDP策略、多模态语义交互和贝叶斯数据融合，实现了面向人-机器人团队的活动语义感知和规划，使机器人可以主动获取人类提供的语义数据。 |
| [^87] | [Compute and Energy Consumption Trends in Deep Learning Inference.](http://arxiv.org/abs/2109.05472) | 本篇论文研究了深度学习推理中的计算和能量消耗趋势，重点关注推理成本而非训练成本。结果显示，除了算法创新外，更具体和强大的硬件通常伴随着重要的能量效率优化，导致推理成本的提高呈现柔和的趋势。 |
| [^88] | [Systematic human learning and generalization from a brief tutorial with explanatory feedback.](http://arxiv.org/abs/2107.06994) | 本文研究了人类如何通过简要教程和解释性反馈从少量的训练示例中学习抽象推理任务，并能成功地将其推广到训练范围之外的情况。结果表明，实现人类学习机制对于人工智能的发展非常重要。 |

# 详细

[^1]: InceptionNeXt：当Inception遇到ConvNeXt

    InceptionNeXt: When Inception Meets ConvNeXt. (arXiv:2303.16900v1 [cs.CV])

    [http://arxiv.org/abs/2303.16900](http://arxiv.org/abs/2303.16900)

    本论文提出了一种名为InceptionNeXt的新型神经网络，通过将大内核卷积沿通道维度分解为四个平行分支来提高模型效率，解决了保持性能的同时加快基于大内核的CNN模型的问题。

    

    受ViTs长程建模能力的启发，近期广泛研究和采用了大内核卷积来扩大感受野和提高模型性能，例如ConvNeXt采用了7x7深度卷积。虽然这种深度操作仅消耗少量FLOPs，但由于高内存访问成本，这在功能强大的计算设备上大大损害了模型效率。尽管缩小ConvNeXt的内核大小能提高速度，但会导致性能显着下降。如何在保持性能的同时加快基于大内核的CNN模型仍不清楚。为了解决这个问题，受Inceptions的启发，我们提出将大内核深度卷积沿通道维度分解为四个平行分支，即小方内核、两个正交带内核和一个互补内核。

    Inspired by the long-range modeling ability of ViTs, large-kernel convolutions are widely studied and adopted recently to enlarge the receptive field and improve model performance, like the remarkable work ConvNeXt which employs 7x7 depthwise convolution. Although such depthwise operator only consumes a few FLOPs, it largely harms the model efficiency on powerful computing devices due to the high memory access costs. For example, ConvNeXt-T has similar FLOPs with ResNet-50 but only achieves 60% throughputs when trained on A100 GPUs with full precision. Although reducing the kernel size of ConvNeXt can improve speed, it results in significant performance degradation. It is still unclear how to speed up large-kernel-based CNN models while preserving their performance. To tackle this issue, inspired by Inceptions, we propose to decompose large-kernel depthwise convolution into four parallel branches along channel dimension, i.e. small square kernel, two orthogonal band kernels, and an ide
    
[^2]: ViewRefer: 基于GPT和样例引导的多视角知识处理的三维视觉定位

    ViewRefer: Grasp the Multi-view Knowledge for 3D Visual Grounding with GPT and Prototype Guidance. (arXiv:2303.16894v1 [cs.CV])

    [http://arxiv.org/abs/2303.16894](http://arxiv.org/abs/2303.16894)

    本文提出了ViewRefer，这是一个多视角的三维视觉定位框架，利用大规模语言模型和多视角原型，从文本和3D模态中获取视角知识并增强框架的表现。

    

    通过利用多视角输入的3D场景，可以缓解3D视觉定位中的视角差异问题。然而，现有方法通常忽略了嵌入在文本模态中的视角线索，并且未能权衡不同视图的相对重要性。本文提出了ViewRefer，这是一个多视角的三维视觉定位框架，探索如何从文本和3D模态中获取视角知识。其中，ViewRefer利用大规模语言模型（例如GPT）的多样化语言知识，将单一的定位文本扩展为多个几何一致的描述；同时，在3D模态中，引入了基于Transformer的融合模块和视图间注意力，以增强视图之间物体的交互。此外，还提出了一组可学习的多视角原型，用于记忆不同视角下的场景无关知识，从两个方面增强了框架。

    Understanding 3D scenes from multi-view inputs has been proven to alleviate the view discrepancy issue in 3D visual grounding. However, existing methods normally neglect the view cues embedded in the text modality and fail to weigh the relative importance of different views. In this paper, we propose ViewRefer, a multi-view framework for 3D visual grounding exploring how to grasp the view knowledge from both text and 3D modalities. For the text branch, ViewRefer leverages the diverse linguistic knowledge of large-scale language models, e.g., GPT, to expand a single grounding text to multiple geometry-consistent descriptions. Meanwhile, in the 3D modality, a transformer fusion module with inter-view attention is introduced to boost the interaction of objects across views. On top of that, we further present a set of learnable multi-view prototypes, which memorize scene-agnostic knowledge for different views, and enhance the framework from two perspectives: a view-guided attention module 
    
[^3]: 零样本 Entrailment 用于 Empirical AI Research 领域排行榜

    Zero-shot Entailment of Leaderboards for Empirical AI Research. (arXiv:2303.16835v1 [cs.CL])

    [http://arxiv.org/abs/2303.16835](http://arxiv.org/abs/2303.16835)

    本文探讨了自动挖掘 Empirical AI Research 领域排行榜这一任务类别中的零样本学习现象。实验测试了先前报告的最新技术模型在其未见过的排行榜标签上的泛化能力或 entailment 能力。本文创建了一个零样本标记的数据集。

    

    本文在一个特定的文本蕴含（RTE）任务类别中进行了零样本学习现象的大规模实证研究，即自动挖掘 Empirical AI Research 领域排行榜。该领域的排行榜提取先前报告的最新技术模型，在非零样本设置下表现良好，报告了高于90%的性能。然而，一个核心的研究问题仍未被检验：这些模型真的学习了 entailment 吗？因此，在本文的实验中，测试了两个先前报告的最新技术模型，在其训练过程中没有见过的排行榜标签上，测试它们的泛化能力或 entailment 能力。我们假设，如果模型学习了 entailment，它们的零样本性能也可能是中等的，或者具体来说，好于随机猜测。本文通过远程标注创建了零样本标记数据集。

    We present a large-scale empirical investigation of the zero-shot learning phenomena in a specific recognizing textual entailment (RTE) task category, i.e. the automated mining of leaderboards for Empirical AI Research. The prior reported state-of-the-art models for leaderboards extraction formulated as an RTE task, in a non-zero-shot setting, are promising with above 90% reported performances. However, a central research question remains unexamined: did the models actually learn entailment? Thus, for the experiments in this paper, two prior reported state-of-the-art models are tested out-of-the-box for their ability to generalize or their capacity for entailment, given leaderboard labels that were unseen during training. We hypothesize that if the models learned entailment, their zero-shot performances can be expected to be moderately high as well--perhaps, concretely, better than chance. As a result of this work, a zero-shot labeled dataset is created via distant labeling formulating
    
[^4]: 基于学习的预测的交互合流情况下自动驾驶决策制定

    Decision Making for Autonomous Driving in Interactive Merge Scenarios via Learning-based Prediction. (arXiv:2303.16821v1 [cs.RO])

    [http://arxiv.org/abs/2303.16821](http://arxiv.org/abs/2303.16821)

    本研究提出了在自动驾驶车辆与其他车辆交互合流的情况下，基于学习的预测的决策制定方法来解决高度挑战的决策问题和不确定性，并采用部分可观察的马尔可夫决策过程（POMDP）和蒙特卡罗树搜索算法来执行高级驾驶操作。

    

    在与人类驾驶员共享道路的自动代理方面，必须考虑交通参与者之间微妙的互动。这是一个非常具有挑战性的决策问题，因为人类行为受到难以建模的多种因素（例如人类意图和情绪）的影响。本文提出了一种自动驾驶的决策方法，重点关注复杂的合流交通任务，其中不确定性来自其他驾驶员的行为和不完美的传感器测量。我们将问题框架化为部分可观察的马尔可夫决策过程（POMDP），并使用蒙特卡罗树搜索在线求解。 POMDP的解决方案是执行高级驾驶操作的策略，例如让道给逼近的车辆，与前面的车辆保持安全距离或合并到交通中。我们的方法利用从数据中学习的模型来预测未来的交通状态，同时明确考虑交互作用。

    Autonomous agents that drive on roads shared with human drivers must reason about the nuanced interactions among traffic participants. This poses a highly challenging decision making problem since human behavior is influenced by a multitude of factors (e.g., human intentions and emotions) that are hard to model. This paper presents a decision making approach for autonomous driving, focusing on the complex task of merging into moving traffic where uncertainty emanates from the behavior of other drivers and imperfect sensor measurements. We frame the problem as a partially observable Markov decision process (POMDP) and solve it online with Monte Carlo tree search. The solution to the POMDP is a policy that performs high-level driving maneuvers, such as giving way to an approaching car, keeping a safe distance from the vehicle in front or merging into traffic. Our method leverages a model learned from data to predict the future states of traffic while explicitly accounting for interaction
    
[^5]: Thistle: Rust中的向量数据库

    Thistle: A Vector Database in Rust. (arXiv:2303.16780v1 [cs.IR])

    [http://arxiv.org/abs/2303.16780](http://arxiv.org/abs/2303.16780)

    Thistle是一个完全功能的向量数据库，旨在解决回答搜索查询中的潜在知识领域问题，已经在MS MARCO数据集上进行了基准测试，并且有助于推进Rust ML生态系统的发展。

    

    我们介绍了Thistle，一个完全功能的向量数据库。Thistle是Latent Knowledge Use在回答搜索查询方面的分支，这是初创公司和搜索引擎公司的持续研究课题。我们使用数个著名算法实现Thistle，并在MS MARCO数据集上进行基准测试。结果有助于澄清潜在知识领域以及不断增长的Rust ML生态系统。

    We present Thistle, a fully functional vector database. Thistle is an entry into the domain of latent knowledge use in answering search queries, an ongoing research topic at both start-ups and search engine companies. We implement Thistle with several well-known algorithms, and benchmark results on the MS MARCO dataset. Results help clarify the latent knowledge domain as well as the growing Rust ML ecosystem.
    
[^6]: 基于主动学习策略的两 百万份标记美食食谱数据集 - 3A2M

    Assorted, Archetypal and Annotated Two Million (3A2M) Cooking Recipes Dataset based on Active Learning. (arXiv:2303.16778v1 [cs.CL])

    [http://arxiv.org/abs/2303.16778](http://arxiv.org/abs/2303.16778)

    本研究利用领域专家的知识和主动学习技术呈现了一个两百万份烹饪食谱新数据集，通过将30万份食谱按照命名实体识别进行分类到9个类别中，然后使用混合方法对其余的1900K份食谱进行分类。

    

    烹饪食谱可以交换烹饪思想，并提供食品的制作说明。然而，在该领域内由于缺乏足够的标记数据，将在线找到的原始食谱分类到合适的食品类型是一项具有挑战性的任务。本研究利用领域专家的知识将食谱分类可能是一种解决方案。我们基于一个主动学习技术呈现了一个两百万份烹饪食谱的新数据集，通过利用领域专家的知识将其标记在各自的类别中。为了构建数据集，我们从RecipeNLG数据集中获取食谱。然后，我们使用三个可信度得分高于86.667％的人类专家按照其命名实体识别（NER）将30万份食谱分类到九个类别之一：烘焙、饮料、荤菜、蔬菜、快餐、麦片、餐点、配菜和融合。最后，我们使用Query-by-Committee和Human的混合方法，将剩余的1900K份食谱进行分类。

    Cooking recipes allow individuals to exchange culinary ideas and provide food preparation instructions. Due to a lack of adequate labeled data, categorizing raw recipes found online to the appropriate food genres is a challenging task in this domain. Utilizing the knowledge of domain experts to categorize recipes could be a solution. In this study, we present a novel dataset of two million culinary recipes labeled in respective categories leveraging the knowledge of food experts and an active learning technique. To construct the dataset, we collect the recipes from the RecipeNLG dataset. Then, we employ three human experts whose trustworthiness score is higher than 86.667% to categorize 300K recipe by their Named Entity Recognition (NER) and assign it to one of the nine categories: bakery, drinks, non-veg, vegetables, fast food, cereals, meals, sides and fusion. Finally, we categorize the remaining 1900K recipes using Active Learning method with a blend of Query-by-Committee and Human 
    
[^7]: 一种新的专利相似度测量方法：语义距离和技术距离

    A Novel Patent Similarity Measurement Methodology: Semantic Distance and Technological Distance. (arXiv:2303.16767v1 [cs.IR])

    [http://arxiv.org/abs/2303.16767](http://arxiv.org/abs/2303.16767)

    该研究提出了一种混合方法，用于自动测量专利之间的相似性，同时考虑语义和技术相似性，并且实验证明该方法优于仅考虑语义相似性的方法。

    

    测量专利之间的相似性是确保创新的新颖性的关键步骤。然而，目前大多数专利相似度测量方法仍然依赖于专家手动分类专利。另一方面，一些研究提出了自动化方法；然而，大部分自动化方法只关注专利的语义相似性。为了解决这些问题，我们提出了一种混合方法，用于自动测量专利之间的相似性，同时考虑语义和技术的相似性。我们基于专利文本使用BERT测量语义相似性，使用Jaccard相似性计算专利的技术相似性，并通过分配权重来实现混合。我们的评估结果表明，所提出的方法优于仅考虑语义相似度的基准方法。

    Measuring similarity between patents is an essential step to ensure novelty of innovation. However, a large number of methods of measuring the similarity between patents still rely on manual classification of patents by experts. Another body of research has proposed automated methods; nevertheless, most of it solely focuses on the semantic similarity of patents. In order to tackle these limitations, we propose a hybrid method for automatically measuring the similarity between patents, considering both semantic and technological similarities. We measure the semantic similarity based on patent texts using BERT, calculate the technological similarity with IPC codes using Jaccard similarity, and perform hybridization by assigning weights to the two similarity methods. Our evaluation result demonstrates that the proposed method outperforms the baseline that considers the semantic similarity only.
    
[^8]: 用非临床文本信息检索实现肿瘤相关论坛帖子的计算有效标记

    Computationally Efficient Labeling of Cancer Related Forum Posts by Non-Clinical Text Information Retrieval. (arXiv:2303.16766v1 [cs.IR])

    [http://arxiv.org/abs/2303.16766](http://arxiv.org/abs/2303.16766)

    本研究基于非临床和免费可用的信息，结合分布式计算、文本检索、聚类和分类方法开发了一个能够检索、聚类和展示关于癌症病程信息的计算有效系统。

    

    在线上存在着大量关于癌症的信息，但分类和提取有用信息很困难。几乎所有的医疗保健数据处理研究都涉及正式的临床数据，但非临床数据中也有有价值的信息。本研究将分布式计算、文本检索、聚类和分类方法结合成一个连贯、计算有效的系统，基于非临床和免费可用的信息，可以澄清癌症患者的病程。我们开发了一个完全功能的原型，可以从非临床论坛帖子中检索、聚类和展示关于癌症病程的信息。我们评估了三种聚类算法（MR-DBSCAN、DBSCAN和HDBSCAN），并比较了它们在调整后的兰德指数和总运行时间方面的表现，作为检索的帖子数量和邻域半径函数。聚类结果显示，邻域半径对聚类结果有最显著的影响。

    An abundance of information about cancer exists online, but categorizing and extracting useful information from it is difficult. Almost all research within healthcare data processing is concerned with formal clinical data, but there is valuable information in non-clinical data too. The present study combines methods within distributed computing, text retrieval, clustering, and classification into a coherent and computationally efficient system, that can clarify cancer patient trajectories based on non-clinical and freely available information. We produce a fully-functional prototype that can retrieve, cluster and present information about cancer trajectories from non-clinical forum posts. We evaluate three clustering algorithms (MR-DBSCAN, DBSCAN, and HDBSCAN) and compare them in terms of Adjusted Rand Index and total run time as a function of the number of posts retrieved and the neighborhood radius. Clustering results show that neighborhood radius has the most significant impact on c
    
[^9]: 基于对话的视频检索

    Dialogue-to-Video Retrieval. (arXiv:2303.16761v1 [cs.IR])

    [http://arxiv.org/abs/2303.16761](http://arxiv.org/abs/2303.16761)

    本研究提出了一种基于对话的视频检索系统，使用对话作为搜索描述符，有效地提高了视频检索的准确性。

    

    近年来，在社交媒体等网络平台上，人们进行着越来越多的对话。这启发了基于对话的检索的发展，其中基于对话的视频检索对于推荐系统具有越来越大的兴趣。不同于其他视频检索任务，对话到视频检索使用以用户生成的对话为搜索描述符的结构化查询。本文提出了一个新颖的基于对话的视频检索系统，融合了结构化的对话信息。在AVSD数据集上进行的实验表明，我们提出的使用纯文本查询的方法在R@1上比以前的模型提高了15.8%。此外，我们使用对话作为查询的方法，在R@1、R@5和R@10上分别提高了4.2%、6.2%和8.6%，在R@1、R@5和R@10上分别比基准模型提高了0.7%、3.6%和6.0%。

    Recent years have witnessed an increasing amount of dialogue/conversation on the web especially on social media. That inspires the development of dialogue-based retrieval, in which retrieving videos based on dialogue is of increasing interest for recommendation systems. Different from other video retrieval tasks, dialogue-to-video retrieval uses structured queries in the form of user-generated dialogue as the search descriptor. We present a novel dialogue-to-video retrieval system, incorporating structured conversational information. Experiments conducted on the AVSD dataset show that our proposed approach using plain-text queries improves over the previous counterpart model by 15.8% on R@1. Furthermore, our approach using dialogue as a query, improves retrieval performance by 4.2%, 6.2%, 8.6% on R@1, R@5 and R@10 and outperforms the state-of-the-art model by 0.7%, 3.6% and 6.0% on R@1, R@5 and R@10 respectively.
    
[^10]: 使用蚁群优化的新型词性标注方法ACO-tagger

    ACO-tagger: A Novel Method for Part-of-Speech Tagging using Ant Colony Optimization. (arXiv:2303.16760v1 [cs.CL])

    [http://arxiv.org/abs/2303.16760](http://arxiv.org/abs/2303.16760)

    本研究提出了一种基于蚁群优化的高效词性标注方法ACO-tagger，实现了高达96.867％的准确率，优于几种最先进的方法。

    

    近年来，群智能算法因其解决复杂和非确定性问题的能力而备受关注。这些算法受自然生物的集体行为启发，模拟这种行为以开发用于计算任务的智能 agent。其中一种算法是受到蚂蚁觅食行为及其信息素释放机制启发的蚁群优化（ACO）算法，用于解决离散和组合性的困难问题。词性标注是自然语言处理中的基础任务，旨在为句子中的每个单词分配一个词性角色。本研究提出了一种基于ACO的高性能词性标注方法ACO-tagger。该方法实现了高达96.867％的准确率，优于几种最先进的方法。该方法快速高效，是实际应用的可行选择。

    Swarm Intelligence algorithms have gained significant attention in recent years as a means of solving complex and non-deterministic problems. These algorithms are inspired by the collective behavior of natural creatures, and they simulate this behavior to develop intelligent agents for computational tasks. One such algorithm is Ant Colony Optimization (ACO), which is inspired by the foraging behavior of ants and their pheromone laying mechanism. ACO is used for solving difficult problems that are discrete and combinatorial in nature. Part-of-Speech (POS) tagging is a fundamental task in natural language processing that aims to assign a part-of-speech role to each word in a sentence. In this research paper, proposed a high-performance POS-tagging method based on ACO called ACO-tagger. This method achieved a high accuracy rate of 96.867%, outperforming several state-of-the-art methods. The proposed method is fast and efficient, making it a viable option for practical applications.
    
[^11]: 深度学习如何从电子病历中检测漏诊的额外诊断以适用于DRG

    How can Deep Learning Retrieve the Write-Missing Additional Diagnosis from Chinese Electronic Medical Record For DRG. (arXiv:2303.16757v1 [cs.CL])

    [http://arxiv.org/abs/2303.16757](http://arxiv.org/abs/2303.16757)

    该论文提出了一种使用深度学习的方法，从电子病历中检索漏诊的额外诊断，以适用于DRG分组，解决了漏诊问题导致医疗记录不完整、影响DRG招生正确率的问题。

    

    漏诊的检测的目的是找到已经在医疗记录中清晰诊断但被漏掉的疾病。不同于漏诊的定义，漏诊在医疗记录中明显表现，无须进一步推理。漏诊问题很常见，通常是由于医生疏忽造成的。漏诊会导致医疗记录的不完整性。在DRG的分组下，漏诊将错过重要的额外诊断（CC，MCC），从而影响DRG招生的正确率。在国家普遍开始采用DRG招生和支付的情况下，漏诊问题是普遍存在的严重问题。当前的基于手动方法由于全面医疗记录的复杂内容而昂贵。因此，我们认为自然语言处理可以用于解决这个问题。但据我所知，该论文提出了一种使用深度学习的方法，从中国电子病历中检索漏诊的额外诊断，以适用于DRG分组。

    The purpose of write-missing diagnosis detection is to find diseases that have been clearly diagnosed from medical records but are missed in the discharge diagnosis. Unlike the definition of missed diagnosis, the write-missing diagnosis is clearly manifested in the medical record without further reasoning. The write-missing diagnosis is a common problem, often caused by physician negligence. The write-missing diagnosis will result in an incomplete diagnosis of medical records. While under DRG grouping, the write-missing diagnoses will miss important additional diagnoses (CC, MCC), thus affecting the correct rate of DRG enrollment.  Under the circumstance that countries generally start to adopt DRG enrollment and payment, the problem of write-missing diagnosis is a common and serious problem. The current manual-based method is expensive due to the complex content of the full medical record. We think this problem is suitable to be solved as natural language processing. But to the best of
    
[^12]: LLM用于患者-试验匹配: 面向更好的性能和泛化能力的隐私感知数据增强

    LLM for Patient-Trial Matching: Privacy-Aware Data Augmentation Towards Better Performance and Generalizability. (arXiv:2303.16756v1 [cs.CL])

    [http://arxiv.org/abs/2303.16756](http://arxiv.org/abs/2303.16756)

    本文提出了一种隐私感知数据增强的LLM-PTM方法，有效地提高了患者-试验匹配的性能和泛化能力。

    

    将患者与适合的临床试验进行匹配是推进医学研究和提供最佳护理的关键。然而，现有方法面临数据标准化、伦理考虑和电子健康记录与临床试验标准之间互操作性缺乏等挑战。在本文中，我们探索利用大型语言模型（LLMs）解决这些挑战的潜力，通过利用其先进的自然语言生成能力来改善EHRs和临床试验描述之间的兼容性。我们提出了一种创新的基于LLM的患者-试验匹配（LLM-PTM）的隐私感知数据增强方法，平衡了LLMs的好处，同时确保敏感患者数据的安全和保密。我们的实验表明，使用所提出的LLM-PTM方法，性能平均提高了7.32％，新数据的泛化能力提高了12.12％。此外，我们还提供了案例研究。

    The process of matching patients with suitable clinical trials is essential for advancing medical research and providing optimal care. However, current approaches face challenges such as data standardization, ethical considerations, and a lack of interoperability between Electronic Health Records (EHRs) and clinical trial criteria. In this paper, we explore the potential of large language models (LLMs) to address these challenges by leveraging their advanced natural language generation capabilities to improve compatibility between EHRs and clinical trial descriptions. We propose an innovative privacy-aware data augmentation approach for LLM-based patient-trial matching (LLM-PTM), which balances the benefits of LLMs while ensuring the security and confidentiality of sensitive patient data. Our experiments demonstrate a 7.32% average improvement in performance using the proposed LLM-PTM method, and the generalizability to new data is improved by 12.12%. Additionally, we present case stud
    
[^13]: 使用语言反馈规模化训练语言模型

    Training Language Models with Language Feedback at Scale. (arXiv:2303.16755v1 [cs.CL])

    [http://arxiv.org/abs/2303.16755](http://arxiv.org/abs/2303.16755)

    本文提出一种新方法，即利用更丰富的语言反馈进行模仿学习，通过三个迭代步骤对语言模型进行训练以生成更符合人类偏好的输出。

    

    预训练的语言模型经常生成不符合人类偏好的输出，例如有害的文本或事实不正确的摘要。最近的研究尝试通过学习一种简单的人类反馈形式（即模型生成输出之间的比较）来解决这些问题。但是，比较反馈只能传达有限的关于人类偏好的信息。在本文中，我们介绍了一种新的方法——使用语言反馈进行模仿学习（ILF），它利用了更丰富的语言反馈。ILF由三个迭代步骤组成：第一步，根据输入，初始LM输出和反馈对语言模型进行调节以生成改进。第二步，选择最多反馈的改进。第三步，微调语言模型，以最大化在给定输入的情况下选择的改进的可能性。我们在理论上证明了ILF可以被看作是贝叶斯推断，类似于从人类反馈中进行强化学习。我们还评估了ILF在各种基准测试中的性能。

    Pretrained language models often generate outputs that are not in line with human preferences, such as harmful text or factually incorrect summaries. Recent work approaches the above issues by learning from a simple form of human feedback: comparisons between pairs of model-generated outputs. However, comparison feedback only conveys limited information about human preferences. In this paper, we introduce Imitation learning from Language Feedback (ILF), a new approach that utilizes more informative language feedback. ILF consists of three steps that are applied iteratively: first, conditioning the language model on the input, an initial LM output, and feedback to generate refinements. Second, selecting the refinement incorporating the most feedback. Third, finetuning the language model to maximize the likelihood of the chosen refinement given the input. We show theoretically that ILF can be viewed as Bayesian Inference, similar to Reinforcement Learning from human feedback. We evaluate
    
[^14]: 司法智能助手系统：从离婚案件中提取事件以检测裁判中的争议

    Judicial Intelligent Assistant System: Extracting Events from Divorce Cases to Detect Disputes for the Judge. (arXiv:2303.16751v1 [cs.CL])

    [http://arxiv.org/abs/2303.16751](http://arxiv.org/abs/2303.16751)

    本文提出了一种基于两轮标注事件提取技术的离婚案件争议检测方法，实现了司法智能助手（JIA）系统，以自动从离婚案件材料中提取重点事件，通过识别其中的共指来对事件进行对齐，并检测冲突。

    

    在民事案件的正式程序中，由不同当事人提供的文本资料描述了案件的发展过程。从这些文本材料中提取案件的关键信息并澄清相关当事人的争议焦点是一项困难而必要的任务。本文提出了一种基于两轮标注事件提取技术的离婚案件争议检测方法。我们按照所提出的方法实现了司法智能助手（JIA）系统，以自动从离婚案件材料中提取重点事件，通过识别其中的共指来对事件进行对齐，并检测冲突。

    In formal procedure of civil cases, the textual materials provided by different parties describe the development process of the cases. It is a difficult but necessary task to extract the key information for the cases from these textual materials and to clarify the dispute focus of related parties. Currently, officers read the materials manually and use methods, such as keyword searching and regular matching, to get the target information. These approaches are time-consuming and heavily depending on prior knowledge and carefulness of the officers. To assist the officers to enhance working efficiency and accuracy, we propose an approach to detect disputes from divorce cases based on a two-round-labeling event extracting technique in this paper. We implement the Judicial Intelligent Assistant (JIA) system according to the proposed approach to 1) automatically extract focus events from divorce case materials, 2) align events by identifying co-reference among them, and 3) detect conflicts a
    
[^15]: 利用自然语言反馈进行代码生成的改进

    Improving Code Generation by Training with Natural Language Feedback. (arXiv:2303.16749v1 [cs.SE])

    [http://arxiv.org/abs/2303.16749](http://arxiv.org/abs/2303.16749)

    该论文提出了一种新算法ILF，通过从自然语言反馈中进行学习来显著提高代码生成模型的性能，即使只有少量反馈，也可以获得很好的效果。

    

    预先训练好的大型语言模型（LLM）在推理时使用自然语言反馈的潜力是最近的一个令人兴奋的发展。我们在此基础上提出一种名为Language Feedback（ILF）的算法，用于从自然语言反馈中进行学习。ILF在训练期间仅需要少量的人工编写反馈，并且在测试时不需要相同的反馈，因此使用起来既方便又高效。此外，我们进一步证明ILF可以被视为最小化与基准分布的KL散度的一种形式，并在神经程序合成任务上进行了概念验证。我们使用ILF在Mostly Basic Python Problems(MBPP)基准测试上将Codegen-Mono 6.1B模型的pass @ 1覆盖率相对提高了38%（绝对提高了10%），胜过了在MBPP上微调和在人类修复的程序上微调的模型。总的来说，我们的结果表明，即使只有少量反馈，从人类编写的自然语言反馈中进行学习也可以显著改进代码生成模型。

    The potential for pre-trained large language models (LLMs) to use natural language feedback at inference time has been an exciting recent development. We build upon this observation by formalizing an algorithm for learning from natural language feedback at training time instead, which we call Imitation learning from Language Feedback (ILF). ILF requires only a small amount of human-written feedback during training and does not require the same feedback at test time, making it both user-friendly and sample-efficient. We further show that ILF can be seen as a form of minimizing the KL divergence to the ground truth distribution and demonstrate a proof-of-concept on a neural program synthesis task. We use ILF to improve a Codegen-Mono 6.1B model's pass@1 rate by 38% relative (and 10% absolute) on the Mostly Basic Python Problems (MBPP) benchmark, outperforming both fine-tuning on MBPP and fine-tuning on repaired programs written by humans. Overall, our results suggest that learning from h
    
[^16]: 通过高效的逆强化学习实现通信负载均衡

    Communication Load Balancing via Efficient Inverse Reinforcement Learning. (arXiv:2303.16686v1 [cs.NI])

    [http://arxiv.org/abs/2303.16686](http://arxiv.org/abs/2303.16686)

    本文使用逆强化学习方法成功解决了通信负载均衡问题，首次将逆强化学习应用于该领域。

    

    通信负载均衡旨在平衡不同可用资源之间的负载，从而提高网络系统的服务质量。本文将负载均衡问题描述为马尔可夫决策过程，并利用强化学习有效解决负载均衡问题。然而，为了利用经典强化学习解决负载均衡问题，我们需要明确的奖励定义。构建这种奖励函数是具有挑战性的，因为它涉及到专家知识的需求，而且对于最优奖励函数的形式缺乏共识。本文采用逆强化学习方法，从一组演示中推断奖励函数，成功地解决了通信负载均衡问题。据我们所知，这是第一次在通信负载均衡领域成功应用逆强化学习。具体而言，我们首先从一组演示中推断奖励函数，然后学习强化学习负载均衡策略。

    Communication load balancing aims to balance the load between different available resources, and thus improve the quality of service for network systems. After formulating the load balancing (LB) as a Markov decision process problem, reinforcement learning (RL) has recently proven effective in addressing the LB problem. To leverage the benefits of classical RL for load balancing, however, we need an explicit reward definition. Engineering this reward function is challenging, because it involves the need for expert knowledge and there lacks a general consensus on the form of an optimal reward function. In this work, we tackle the communication load balancing problem from an inverse reinforcement learning (IRL) approach. To the best of our knowledge, this is the first time IRL has been successfully applied in the field of communication load balancing. Specifically, first, we infer a reward function from a set of demonstrations, and then learn a reinforcement learning load balancing polic
    
[^17]: 未知流量场景下的通信负载均衡中的策略重用

    Policy Reuse for Communication Load Balancing in Unseen Traffic Scenarios. (arXiv:2303.16685v1 [cs.NI])

    [http://arxiv.org/abs/2303.16685](http://arxiv.org/abs/2303.16685)

    提出了一种策略重用框架，该框架通过选择最适合执行的预训练强化学习策略来解决通信负载平衡问题，其根据不同流量场景下的策略训练库进行选择，可以胜过传统的负载平衡算法。

    

    随着通信网络复杂性和流量增长的持续增加，通信负载平衡解决方案越来越受到关注。具体来说，基于强化学习（RL）的方法与传统的基于规则的方法相比，表现出了令人印象深刻的性能。然而，标准的RL方法通常需要大量的数据进行训练，并且对于在训练过程中未遇到的场景的泛化能力较差。我们提出了一个策略重用框架，其中策略选择器基于当前的流量状况选择最适合的预训练RL策略来执行。我们的方法依赖于一个策略库，其中包含在不同流量场景下训练的策略。在部署到未知的流量场景时，我们根据当前场景的前一天的流量与训练期间观察到的流量之间的相似度从策略库中选择策略。实验表明，该框架可以胜过传统的负载平衡算法。

    With the continuous growth in communication network complexity and traffic volume, communication load balancing solutions are receiving increasing attention. Specifically, reinforcement learning (RL)-based methods have shown impressive performance compared with traditional rule-based methods. However, standard RL methods generally require an enormous amount of data to train, and generalize poorly to scenarios that are not encountered during training. We propose a policy reuse framework in which a policy selector chooses the most suitable pre-trained RL policy to execute based on the current traffic condition. Our method hinges on a policy bank composed of policies trained on a diverse set of traffic scenarios. When deploying to an unknown traffic scenario, we select a policy from the policy bank based on the similarity between the previous-day traffic of the current scenario and the traffic observed during training. Experiments demonstrate that this framework can outperform classical a
    
[^18]: 针对循环协同系统中对象交互的不良过程模型的目标导向防止方法：扩展版

    Preventing Object-centric Discovery of Unsound Process Models for Object Interactions with Loops in Collaborative Systems: Extended Version. (arXiv:2303.16680v1 [cs.AI])

    [http://arxiv.org/abs/2303.16680](http://arxiv.org/abs/2303.16680)

    OCPD范例转变了流程挖掘，可以处理与一系列对象相关联的事件，本文提出的扩展OCPD方法可以避免原方法中关于多对象交互循环的错误问题。

    

    对象中心的过程发现（OCPD）是流程挖掘中的范式转变。 OCPD能够处理不具有单个案例概念但与具有特定类型的一系列对象相关联的事件。对象类型构成多个交互案例概念。 OCPD的输出是一个对象中心Petri网，即具有对象类型位置的Petri网，表示与对象类型对应的多个执行流的并行执行。本文提出了一种扩展OCPD方法，并证明其不会受到原始方法中出现的不良问题的影响。

    Object-centric process discovery (OCPD) constitutes a paradigm shift in process mining. Instead of assuming a single case notion present in the event log, OCPD can handle events without a single case notion, but that are instead related to a collection of objects each having a certain type. The object types constitute multiple, interacting case notions. The output of OCPD is an object-centric Petri net, i.e. a Petri net with object-typed places, that represents the parallel execution of multiple execution flows corresponding to object types. Similar to classical process discovery, where we aim for behaviorally sound process models as a result, in OCPD, we aim for soundness of the resulting object-centric Petri nets. However, the existing OCPD approach can result in violations of soundness. As we will show, one violation arises for multiple interacting object types with loops that arise in collaborative systems. This paper proposes an extended OCPD approach and proves that it does not s
    
[^19]: 实际分类任务中的神经符号规则学习

    Neuro-symbolic Rule Learning in Real-world Classification Tasks. (arXiv:2303.16674v1 [cs.LG])

    [http://arxiv.org/abs/2303.16674](http://arxiv.org/abs/2303.16674)

    本研究通过将神经范式模块扩展到多类和多标签实际分类任务中，以及强制实现符号互斥属性，提高了神经符号规则学习模型的准确性和可解释性。

    

    神经符号规则学习因其比纯神经模型具有更好的可解释性且比符号规则学习扩展性更好而受到关注。最近提出了一种名为 pix2rule 的方法，引入了一个神经范式模块来使用前向层学习符号规则。尽管在合成二分类方面证明了其有效性，但 pix2rule 尚未应用于更具挑战性的任务，如基于实际数据的多标签和多类分类。本文通过将神经范式模块扩展到以下三个方面来解决这一限制：(i) 支持实际多类和多标签分类任务的规则学习，(ii) 在多类分类中强制符号互斥属性(即预测恰好一个类)，以及(iii) 探索其在大输入输出方面的扩展性。我们使用类似于 pix2rule 的神经 DNF 模块训练了一个普通的神经 DNF 模型，用于多标签分类，同时提出了一种新方法来通过改进现有的神经 DNF 模块实现多类分类中的互斥性。在多个基准数据集上的实验结果表明，我们扩展的神经 DNF 模型在准确性和可解释性方面明显优于现有的神经符号规则学习模型以及纯神经模型和符号规则学习模型。

    Neuro-symbolic rule learning has attracted lots of attention as it offers better interpretability than pure neural models and scales better than symbolic rule learning. A recent approach named pix2rule proposes a neural Disjunctive Normal Form (neural DNF) module to learn symbolic rules with feed-forward layers. Although proved to be effective in synthetic binary classification, pix2rule has not been applied to more challenging tasks such as multi-label and multi-class classifications over real-world data. In this paper, we address this limitation by extending the neural DNF module to (i) support rule learning in real-world multi-class and multi-label classification tasks, (ii) enforce the symbolic property of mutual exclusivity (i.e. predicting exactly one class) in multi-class classification, and (iii) explore its scalability over large inputs and outputs. We train a vanilla neural DNF model similar to pix2rule's neural DNF module for multi-label classification, and we propose a nove
    
[^20]: 基于矩阵自回归的联邦学习拜占庭容错聚合方案

    A Byzantine-Resilient Aggregation Scheme for Federated Learning via Matrix Autoregression on Client Updates. (arXiv:2303.16668v1 [cs.LG])

    [http://arxiv.org/abs/2303.16668](http://arxiv.org/abs/2303.16668)

    本文提出了FLANDERS，一种基于矩阵自回归的联邦学习聚合方案，可以识别恶意客户端，并提供了强大的拜占庭攻击防御。

    

    本文提出了FLANDERS，一种新颖的联邦学习（FL）聚合方案，可以抵御拜占庭攻击。FLANDERS将每个FL轮次中由客户端发送的本地模型更新视为矩阵值时间序列。然后，通过将实际观测与由矩阵自回归预测模型估计的观测进行比较，识别恶意客户端作为这个时间序列的异常值。在不同FL设置下对多个数据集进行的实验证明，FLANDERS在抵御拜占庭攻击方面与最强大的基线相匹配。此外，与现有的防御策略相比， FLANDERS即使在极其严重的攻击场景下仍然非常有效。

    In this work, we propose FLANDERS, a novel federated learning (FL) aggregation scheme robust to Byzantine attacks. FLANDERS considers the local model updates sent by clients at each FL round as a matrix-valued time series. Then, it identifies malicious clients as outliers of this time series by comparing actual observations with those estimated by a matrix autoregressive forecasting model. Experiments conducted on several datasets under different FL settings demonstrate that FLANDERS matches the robustness of the most powerful baselines against Byzantine clients. Furthermore, FLANDERS remains highly effective even under extremely severe attack scenarios, as opposed to existing defense strategies.
    
[^21]: 多智能体系统中博弈论决策的分层式实用树模型

    A Hierarchical Game-Theoretic Decision-Making for Cooperative Multi-Agent Systems Under the Presence of Adversarial Agents. (arXiv:2303.16641v1 [cs.MA])

    [http://arxiv.org/abs/2303.16641](http://arxiv.org/abs/2303.16641)

    本文提出了一种名为GUT的新型分层式博弈论实用树模型，在多智能体决策中实现高低层次策略分解，使用代理需求作为新的收益度量，通过广泛的数值模拟表明可以帮助MAS以更低的成本和更高的获胜率实现具有挑战性的任务。

    

    在危险情境中的多智能体系统（MAS）中，基础的关系可以被表示成博弈论模型。本文提出了一种新的基于网络的分层模型，称为博弈论实用树（GUT），它将高层次策略分解为可执行的低层次动作，以实现合作MAS决策。它结合了一种基于代理需求的实时策略游戏的新收益度量。我们在Explore游戏领域中，从平衡成功概率和系统成本的角度衡量了MAS的绩效，评估了GUT方法相对于贪心地依赖于组合动作奖励的最新方法。广泛的数值模拟的确定结果表明GUT可以组织更复杂的MAS协作关系，帮助团队以更低的成本和更高的获胜率实现具有挑战性的任务。此外，我们演示了使用模拟应用GUT的可行性。

    Underlying relationships among Multi-Agent Systems (MAS) in hazardous scenarios can be represented as Game-theoretic models. This paper proposes a new hierarchical network-based model called Game-theoretic Utility Tree (GUT), which decomposes high-level strategies into executable low-level actions for cooperative MAS decisions. It combines with a new payoff measure based on agent needs for real-time strategy games. We present an Explore game domain, where we measure the performance of MAS achieving tasks from the perspective of balancing the success probability and system costs. We evaluate the GUT approach against state-of-the-art methods that greedily rely on rewards of the composite actions. Conclusive results on extensive numerical simulations indicate that GUT can organize more complex relationships among MAS cooperation, helping the group achieve challenging tasks with lower costs and higher winning rates. Furthermore, we demonstrated the applicability of the GUT using the simula
    
[^22]: GPTEval：使用GPT-4和更好的人类对齐来评估NLG

    GPTEval: NLG Evaluation using GPT-4 with Better Human Alignment. (arXiv:2303.16634v1 [cs.CL])

    [http://arxiv.org/abs/2303.16634](http://arxiv.org/abs/2303.16634)

    本文介绍了GPTEval，一个利用链式思考和形式填充评价NLG生成的质量。实验表明，在文本摘要任务中，GPTEval结合GPT-4取得了0.514的斯皮尔曼相关系数，胜过其他方法。

    

    自然语言生成（NLG）系统生成的文本质量很难进行自动测量。传统的基于参考的度量标准，如BLEU和ROUGE已被证明在需要创造性和多样性的任务中与人类判断的相关性相对较低。最近的研究建议使用大型语言模型（LLMs）作为无参考的NLG评估度量标准，这些模型适用于缺乏人类参考的新任务。然而，这些基于LLM的评估器仍然比中等规模的神经评估器的人类对应度低。在这项工作中，我们提出了GPTEval，一个使用链式思考（CoT）和形式填充范式来评估NLG输出质量的框架。我们针对两个生成任务，文本摘要和对话生成进行了实验。我们展示出，GPTEval结合GPT-4作为骨干模型，在摘要任务上实现了0.514的斯皮尔曼相关系数，胜过其他方法。

    The quality of texts generated by natural language generation (NLG) systems is hard to measure automatically. Conventional reference-based metrics, such as BLEU and ROUGE, have been shown to have relatively low correlation with human judgments, especially for tasks that require creativity and diversity. Recent studies suggest using large language models (LLMs) as reference-free metrics for NLG evaluation, which have the benefit of being applicable to new tasks that lack human references. However, these LLM-based evaluators still have lower human correspondence than medium-size neural evaluators. In this work, we present GPTEval, a framework of using large language models with chain-of-thoughts (CoT) and a form-filling paradigm, to assess the quality of NLG outputs. We experiment with two generation tasks, text summarization and dialogue generation. We show that GPTEval with GPT-4 as the backbone model achieves a Spearman correlation of 0.514 with human on summarization task, outperform
    
[^23]: Fairlearn: 评估和提升人工智能系统的公平性

    Fairlearn: Assessing and Improving Fairness of AI Systems. (arXiv:2303.16626v1 [cs.LG])

    [http://arxiv.org/abs/2303.16626](http://arxiv.org/abs/2303.16626)

    Fairlearn是一个有助于评估和提高人工智能系统公平性的开源项目，通过可视化地评估受影响人群的模型输出，并提供多种算法来缓解不公平问题，同时还在考虑系统的更广泛社会背景方面提供了学习资源。

    

    Fairlearn是一个开源项目，旨在帮助从业人员评估和提高人工智能（AI）系统的公平性。该相关的Python库，也名为Fairlearn，支持跨受影响的人口评估模型的输出，并包括几种算法以缓解公平性问题。基于公平是一个社会技术挑战的认识，该项目集成了学习资源，以帮助从业人员考虑一个系统的更广泛社会背景。

    Fairlearn is an open source project to help practitioners assess and improve fairness of artificial intelligence (AI) systems. The associated Python library, also named fairlearn, supports evaluation of a model's output across affected populations and includes several algorithms for mitigating fairness issues. Grounded in the understanding that fairness is a sociotechnical challenge, the project integrates learning resources that aid practitioners in considering a system's broader societal context.
    
[^24]: AraSpot：阿拉伯语口语命令识别

    AraSpot: Arabic Spoken Command Spotting. (arXiv:2303.16621v1 [cs.CL])

    [http://arxiv.org/abs/2303.16621](http://arxiv.org/abs/2303.16621)

    AraSpot是一款使用ConformerGRU模型架构训练40个阿拉伯语关键词的口语命令识别工具，其通过在线数据增强和文本到语音模型的训练提高了性能，并以99.59%的准确率超出以往的方法。

    

    口语关键识别（KWS）是指在音频流中识别关键词，广泛用于智能边缘设备上，以启动语音助手和进行免提任务。该任务面临着高精度和在低功率和可能的有限计算能力设备上保持系统运行效率的需求。本文介绍了使用不同的在线数据增强和引入ConformerGRU模型架构的AraSpot，用于训练40个阿拉伯语关键词的识别。最后，我们通过训练文本到语音模型进行合成数据生成，进一步提高了模型的性能。AraSpot以SOTA 99.59％超过以往的方法。

    Spoken keyword spotting (KWS) is the task of identifying a keyword in an audio stream and is widely used in smart devices at the edge in order to activate voice assistants and perform hands-free tasks. The task is daunting as there is a need, on the one hand, to achieve high accuracy while at the same time ensuring that such systems continue to run efficiently on low power and possibly limited computational capabilities devices. This work presents AraSpot for Arabic keyword spotting trained on 40 Arabic keywords, using different online data augmentation, and introducing ConformerGRU model architecture. Finally, we further improve the performance of the model by training a text-to-speech model for synthetic data generation. AraSpot achieved a State-of-the-Art SOTA 99.59% result outperforming previous approaches.
    
[^25]: 使用丰富的元数据注释的屏幕角色的个性化语言建模

    Personalised Language Modelling of Screen Characters Using Rich Metadata Annotations. (arXiv:2303.16618v1 [cs.CL])

    [http://arxiv.org/abs/2303.16618](http://arxiv.org/abs/2303.16618)

    本篇论文研究了如何使用丰富的元数据注释的信息进行屏幕角色的个性化语言建模，测试表明这样可以有效地进行个性化语言模型的构建，即使对于零样本的演说家也可以应用。

    

    语言模型的个性化为对话敏感，能更好地捕捉特定特征的人员和/或特定环境中的说话模式。然而，丰富的角色注释难以得到和成功利用。在此工作中，我们发布并描述了一组新颖的手动注释，涵盖了来自流行的 Cornell 电影对话语料库的 863 名演讲者，包括特征引用和角色描述，以及超过 95％ 的特色电影的一组自动提取的六个元数据。我们对两个语料库进行了广泛的实验，并表明可以有效地使用此类注释来个性化语言模型，将困惑减少高达 8.5％。我们的方法甚至可以应用于零样本的演讲者，即对于没有先前培训数据的演讲者，依赖于角色的人口特征的组合。由于收集此类元数据成本高昂，因此我们还贡献了一项成本效益分析，以突出显示

    Personalisation of language models for dialogue sensitises them to better capture the speaking patterns of people of specific characteristics, and/or in specific environments. However, rich character annotations are difficult to come by and to successfully leverage. In this work, we release and describe a novel set of manual annotations for 863 speakers from the popular Cornell Movie Dialog Corpus, including features like characteristic quotes and character descriptions, and a set of six automatically extracted metadata for over 95% of the featured films. We perform extensive experiments on two corpora and show that such annotations can be effectively used to personalise language models, reducing perplexity by up to 8.5%. Our method can be applied even zero-shot for speakers for whom no prior training data is available, by relying on combinations of characters' demographic characteristics. Since collecting such metadata is costly, we also contribute a cost-benefit analysis to highlight
    
[^26]: 通过后验估计尖锐化来隐式减轻视觉偏见：一种贝叶斯神经网络方法

    Implicit Visual Bias Mitigation by Posterior Estimate Sharpening of a Bayesian Neural Network. (arXiv:2303.16564v1 [cs.CV])

    [http://arxiv.org/abs/2303.16564](http://arxiv.org/abs/2303.16564)

    该论文提出了一种隐式减轻视觉偏见的方法，使用贝叶斯神经网络，通过后验估计尖锐化，鼓励网络聚焦于不导致高不确定性的中心特征。

    

    深度神经网络的公平性受到数据集偏见和虚假相关性的强烈影响，而这些对现代特征丰富和复杂的视觉数据集通常都是存在的。由于任务的难度和可变性，没有一种单一的去偏见方法是普遍成功的。特别是，在不需要显式知道偏差变量的情况下的隐式方法对于现实世界的应用尤为相关。我们提出了一种新颖的隐式减缓方法，使用贝叶斯神经网络，允许我们利用致性不确定性与样本中偏差或虚假相关性之间的关系。我们提出的后验估计尖锐化程序鼓励网络聚焦于不导致高不确定性的中心特征。在三个基准数据集上的实验结果表明，具有经过尖锐化后验估计的贝叶斯网络表现与现有方法相当，并显示出进一步研究的潜力。

    The fairness of a deep neural network is strongly affected by dataset bias and spurious correlations, both of which are usually present in modern feature-rich and complex visual datasets. Due to the difficulty and variability of the task, no single de-biasing method has been universally successful. In particular, implicit methods not requiring explicit knowledge of bias variables are especially relevant for real-world applications. We propose a novel implicit mitigation method using a Bayesian neural network, allowing us to leverage the relationship between epistemic uncertainties and the presence of bias or spurious correlations in a sample. Our proposed posterior estimate sharpening procedure encourages the network to focus on core features that do not contribute to high uncertainties. Experimental results on three benchmark datasets demonstrate that Bayesian networks with sharpened posterior estimates perform comparably to prior existing methods and show potential worthy of further 
    
[^27]: Plan4MC: 基于技能强化学习和规划的 Minecraft 开放式任务解决方案

    Plan4MC: Skill Reinforcement Learning and Planning for Open-World Minecraft Tasks. (arXiv:2303.16563v1 [cs.LG])

    [http://arxiv.org/abs/2303.16563](http://arxiv.org/abs/2303.16563)

    本论文提出了一种基于技能强化学习和规划的 Minecraft 开放式任务解决方案，通过学习基本技能和技能规划的方法有效提高了任务解决效率，实现了24个不同的任务并在大多数任务中优于基线算法。

    

    本论文研究在 Minecraft 中构建一个多任务智能体。在没有人工演示的情况下，用强化学习（RL）解决这个开放式环境中的长程任务是极其样本低效的。为了解决这个问题，我们将 Minecraft 任务的解决分解成学习基本技能和基于技能进行规划两个阶段。我们在 Minecraft 中提出了三种类型的细粒度基本技能，并使用具有内在奖励的 RL 方法来实现成功率高的基本技能学习。在技能规划方面，我们使用大型语言模型来发现技能之间的关系，预先构建技能图。当智能体解决任务时，我们的技能搜索算法在技能图上行走并生成适当的技能计划。在实验中，我们的方法解决了 24 个不同的 Minecraft 任务，其中许多任务需要连续执行超过 10 个技能。我们的方法在大多数任务中优于基线算法。项目的网址和代码可以在 https://www.rocwang.me/plan4mc.html 找到。

    We study building a multi-task agent in Minecraft. Without human demonstrations, solving long-horizon tasks in this open-ended environment with reinforcement learning (RL) is extremely sample inefficient. To tackle the challenge, we decompose solving Minecraft tasks into learning basic skills and planning over the skills. We propose three types of fine-grained basic skills in Minecraft, and use RL with intrinsic rewards to accomplish basic skills with high success rates. For skill planning, we use Large Language Models to find the relationships between skills and build a skill graph in advance. When the agent is solving a task, our skill search algorithm walks on the skill graph and generates the proper skill plans for the agent. In experiments, our method accomplishes 24 diverse Minecraft tasks, where many tasks require sequentially executing for more than 10 skills. Our method outperforms baselines in most tasks by a large margin. The project's website and code can be found at https:
    
[^28]: Bone Age Assessment的自累积视觉变换器，使用Sauvegrain方法

    Self-accumulative Vision Transformer for Bone Age Assessment Using the Sauvegrain Method. (arXiv:2303.16557v1 [cs.CV])

    [http://arxiv.org/abs/2303.16557](http://arxiv.org/abs/2303.16557)

    该研究提出了一种基于自累积视觉变换器的方法，应用于骨龄评估。通过应用标记重放和区域注意偏差，该方法有效地挖掘地标之间的关系并学习全局形态特征，使骨龄评估的平均绝对误差比之前的工作降低了0.11。

    

    本研究提出了一种新的方法，基于Sauvegrain方法，使用多视角、多任务分类模型进行骨龄评估（BAA）。该方法通过训练分类器来评分每个一点的成熟度并预测骨龄，但是这种方法局限于本地形态，并增加了计算成本。因此，本文提出了一种自累积视觉变换器（SAT），通过应用标记重放和区域注意偏差，消减了多视角、多任务问题中通常发生的各向异性行为，从而有效地挖掘地标之间的关系并学习全局形态特征。通过多次实验表明，SAT成功地将地标之间的关系和全局形态特征融合，使骨龄评估的平均绝对误差比之前的工作降低了0.11。

    This study presents a novel approach to bone age assessment (BAA) using a multi-view, multi-task classification model based on the Sauvegrain method. A straightforward solution to automating the Sauvegrain method, which assesses a maturity score for each landmark in the elbow and predicts the bone age, is to train classifiers independently to score each region of interest (RoI), but this approach limits the accessible information to local morphologies and increases computational costs. As a result, this work proposes a self-accumulative vision transformer (SAT) that mitigates anisotropic behavior, which usually occurs in multi-view, multi-task problems and limits the effectiveness of a vision transformer, by applying token replay and regional attention bias. A number of experiments show that SAT successfully exploits the relationships between landmarks and learns global morphological features, resulting in a mean absolute error of BAA that is 0.11 lower than that of the previous work. 
    
[^29]: 建立分布式分类账技术知识图谱

    Building a Knowledge Graph of Distributed Ledger Technologies. (arXiv:2303.16528v1 [cs.CL])

    [http://arxiv.org/abs/2303.16528](http://arxiv.org/abs/2303.16528)

    本文建立了一个包括安全、应用领域、标准法规等方面的分布式分类账技术的知识图谱，有助于拓展人们对该技术的理解和寻找新的用例。

    

    近年来，分布式分类账系统越来越受到关注和成功推广，尤其是区块链和加密货币方面。这导致了人们对该技术及其能力的各种误解，因为很多情况下，区块链和加密货币被视作同义词，其他用途也被经常忽视。因此，对分布式分类账技术的认识和应用被限制于区块链和加密货币领域。现有的词汇表和本体论往往只关注技术的某些方面，有时甚至只关注单个产品，这可能会忽略其他类型的分布式分类账及其潜在的用途。本文提出了一个分布式分类账技术的知识图谱和本体论，包括安全考虑、应用领域、相关标准和法规等，以改善对该技术的整体理解，并有助于发现区块链和加密货币以外的新用例。

    Distributed ledger systems have become more prominent and successful in recent years, with a focus on blockchains and cryptocurrency. This has led to various misunderstandings about both the technology itself and its capabilities, as in many cases blockchain and cryptocurrency is used synonymously and other applications are often overlooked. Therefore, as a whole, the view of distributed ledger technology beyond blockchains and cryptocurrencies is very limited. Existing vocabularies and ontologies often focus on single aspects of the technology, or in some cases even just on one product. This potentially leads to other types of distributed ledgers and their possible use cases being neglected. In this paper, we present a knowledge graph and an ontology for distributed ledger technologies, which includes security considerations to model aspects such as threats and vulnerabilities, application domains, as well as relevant standards and regulations. Such a knowledge graph improves the over
    
[^30]: 基于深度学习的伤口分类辅助工具开发

    Development of a deep learning-based tool to assist wound classification. (arXiv:2303.16522v1 [cs.CV])

    [http://arxiv.org/abs/2303.16522](http://arxiv.org/abs/2303.16522)

    本文提出了一个基于深度学习的伤口分类工具，可以协助医务人员对五种关键伤口情况进行分类。使用了多任务深度学习框架，使用Cohen's kappa系数来评估模型的准确性，模型的表现优于或不劣于所有医务人员。

    

    本文提出了一个基于深度学习的伤口分类工具，能够帮助非伤口护理专业的医务人员对五种关键伤口情况进行分类，包括深创口、感染性伤口、动脉性伤口、静脉性伤口和压力性伤口，使用易于获取的相机拍摄的彩色图像。分类的准确性对于适当的伤口管理至关重要。所提出的伤口分类方法采用了多任务深度学习框架，利用五种关键伤口情况之间的关系来实现统一的伤口分类架构。通过使用Cohen的kappa系数作为指标将我们的模型与人类进行比较，我们的模型的表现优于或不劣于所有医务人员。我们的卷积神经网络模型是第一个能够同时准确分类深创口、感染性伤口、动脉性伤口、静脉性伤口和压力性伤口的模型。所提出的模型是协助医护人员进行伤口分类的重要工具。

    This paper presents a deep learning-based wound classification tool that can assist medical personnel in non-wound care specialization to classify five key wound conditions, namely deep wound, infected wound, arterial wound, venous wound, and pressure wound, given color images captured using readily available cameras. The accuracy of the classification is vital for appropriate wound management. The proposed wound classification method adopts a multi-task deep learning framework that leverages the relationships among the five key wound conditions for a unified wound classification architecture. With differences in Cohen's kappa coefficients as the metrics to compare our proposed model with humans, the performance of our model was better or non-inferior to those of all human medical personnel. Our convolutional neural network-based model is the first to classify five tasks of deep, infected, arterial, venous, and pressure wounds simultaneously with good accuracy. The proposed model is co
    
[^31]: 客户贡献评估下的公平联邦医学图像分割

    Fair Federated Medical Image Segmentation via Client Contribution Estimation. (arXiv:2303.16520v1 [cs.LG])

    [http://arxiv.org/abs/2303.16520](http://arxiv.org/abs/2303.16520)

    本论文提出了一种新方法，在客户贡献评估下同时优化协作公平性和性能公平性，以获得高质量的全局模型。

    

    如何确保联邦学习中的公平性是一个重要的话题。最近的研究探讨了如何根据客户的贡献（协作公平性）来奖励客户，以及如何实现客户之间的性能均衡（性能公平性）。尽管已经在其中一个方面取得了进展，但我们认为将二者考虑在一起是至关重要的，以吸引和激励更多不同类型的客户加入联邦学习，以获得高质量的全局模型。在这项研究中，我们提出了一种同时优化两种公平性的新方法。具体而言，我们提出了一个梯度和数据空间中的客户贡献评估方法。在梯度空间中，我们监测每个客户相对于其他客户的梯度方向差异。在数据空间中，我们使用辅助模型来测量客户数据的预测误差。基于这种贡献评估，我们提出了一种联邦学习方法，即通过贡献评估进行的联邦训练（FedCE），即使用估计的方式作为全局模型聚合。

    How to ensure fairness is an important topic in federated learning (FL). Recent studies have investigated how to reward clients based on their contribution (collaboration fairness), and how to achieve uniformity of performance across clients (performance fairness). Despite achieving progress on either one, we argue that it is critical to consider them together, in order to engage and motivate more diverse clients joining FL to derive a high-quality global model. In this work, we propose a novel method to optimize both types of fairness simultaneously. Specifically, we propose to estimate client contribution in gradient and data space. In gradient space, we monitor the gradient direction differences of each client with respect to others. And in data space, we measure the prediction error on client data using an auxiliary model. Based on this contribution estimation, we propose a FL method, federated training via contribution estimation (FedCE), i.e., using estimation as global model agg
    
[^32]: 从图形公理回到向量：评估基于图形本体嵌入的属性

    From axioms over graphs to vectors, and back again: evaluating the properties of graph-based ontology embeddings. (arXiv:2303.16519v1 [cs.AI])

    [http://arxiv.org/abs/2303.16519](http://arxiv.org/abs/2303.16519)

    本文研究了几种图形投影方法，并提供了选定适当图形投影的指导方针。

    

    已经发展出多种方法生成描述逻辑本体嵌入，并在机器学习中使用这些嵌入。将本体嵌入到图形结构中，即引入一组节点和边缘用于命名实体和逻辑公理，然后应用图形嵌入将图形嵌入到$\mathbb{R}^n$中，是一种生成本体嵌入的方法。嵌入本体到图形中的方法（图形投影）具有不同的形式属性，涉及它们可以利用的公式类型、投影是否可逆以及是否可以应用于断言公式或其演绎闭包。我们定性地和定量地分析了已用于嵌入本体的几种图形投影方法，并展示了图形投影属性对从本体嵌入中预测公式的表现的影响。我们发现，不同的投影方法之间存在重大差异，并提供了选定适当图形投影的指导方针。

    Several approaches have been developed that generate embeddings for Description Logic ontologies and use these embeddings in machine learning. One approach of generating ontologies embeddings is by first embedding the ontologies into a graph structure, i.e., introducing a set of nodes and edges for named entities and logical axioms, and then applying a graph embedding to embed the graph in $\mathbb{R}^n$. Methods that embed ontologies in graphs (graph projections) have different formal properties related to the type of axioms they can utilize, whether the projections are invertible or not, and whether they can be applied to asserted axioms or their deductive closure. We analyze, qualitatively and quantitatively, several graph projection methods that have been used to embed ontologies, and we demonstrate the effect of the properties of graph projections on the performance of predicting axioms from ontology embeddings. We find that there are substantial differences between different proj
    
[^33]: 针对任意尺度超分辨率的级联局部隐式变换器

    Cascaded Local Implicit Transformer for Arbitrary-Scale Super-Resolution. (arXiv:2303.16513v1 [cs.CV])

    [http://arxiv.org/abs/2303.16513](http://arxiv.org/abs/2303.16513)

    本文提出了局部隐式变换器（LIT）和级联LIT (CLIT) ，结合注意力机制和多尺度特征，实现任意尺度超分辨率，并在实验证明其有效性和优越性。

    

    最近，隐式神经表示展示出在表示任意分辨率图像方面的有力能力。本文中，我们提出了一种局部隐式变换器（LIT），将注意力机制和频率编码技术融合到局部隐式图像函数中。我们设计了一个跨尺度的局部注意力块，以有效地聚合局部特征。为了进一步提高代表能力，我们提出了一种利用多尺度特征的级联LIT（CLIT），以及逐步增加上采样比例的累计训练策略。我们进行了大量实验证明了这些组件的有效性，并分析了各种训练策略。定性和定量结果表明，LIT和CLIT在任意超分辨率任务中取得了较好的结果，并超过了先前的工作。

    Implicit neural representation has recently shown a promising ability in representing images with arbitrary resolutions. In this paper, we present a Local Implicit Transformer (LIT), which integrates the attention mechanism and frequency encoding technique into a local implicit image function. We design a cross-scale local attention block to effectively aggregate local features. To further improve representative power, we propose a Cascaded LIT (CLIT) that exploits multi-scale features, along with a cumulative training strategy that gradually increases the upsampling scales during training. We have conducted extensive experiments to validate the effectiveness of these components and analyze various training strategies. The qualitative and quantitative results demonstrate that LIT and CLIT achieve favorable results and outperform the prior works in arbitrary super-resolution tasks.
    
[^34]: 随机森林在多目标回归中的局部可解释性

    Local Interpretability of Random Forests for Multi-Target Regression. (arXiv:2303.16506v1 [cs.LG])

    [http://arxiv.org/abs/2303.16506](http://arxiv.org/abs/2303.16506)

    本文提出了一种针对随机森林模型在多目标回归中产生基于规则解释的技术，并在广泛实验评估中证明其具有竞争力。

    

    多目标回归在众多应用中非常有用。虽然随机森林模型在这些任务中表现良好，但往往难以解释。可解释性在机器学习中非常重要，特别是当它能直接影响人类福祉时更为重要。虽然存在针对多目标回归的模型无关解释技术，但没有特定于随机森林模型的技术。为了解决这个问题，我们提出了一种技术，用于为随机森林模型在多目标回归中产生基于规则的解释，受最近用于随机森林解释性的模型特定技术的影响。通过广泛的实验评估，证明了所提出的技术在解释方面与最先进的技术相比具有竞争力。

    Multi-target regression is useful in a plethora of applications. Although random forest models perform well in these tasks, they are often difficult to interpret. Interpretability is crucial in machine learning, especially when it can directly impact human well-being. Although model-agnostic techniques exist for multi-target regression, specific techniques tailored to random forest models are not available. To address this issue, we propose a technique that provides rule-based interpretations for instances made by a random forest model for multi-target regression, influenced by a recent model-specific technique for random forest interpretability. The proposed technique was evaluated through extensive experiments and shown to offer competitive interpretations compared to state-of-the-art techniques.
    
[^35]: XAI中的不信任--测量工具还是不同的概念？

    Distrust in (X)AI -- Measurement Artifact or Distinct Construct?. (arXiv:2303.16495v1 [cs.HC])

    [http://arxiv.org/abs/2303.16495](http://arxiv.org/abs/2303.16495)

    这篇论文探讨了XAI中的信任与不信任之间的潜在区别，为探讨不同的信任概念化和缺乏验证的信任问卷提出了一种新的思考角度。

    

    信任是开发可解释人工智能（XAI）的关键动机，然而，研究人员面临许多挑战，例如不同的信任概念化和缺乏在AI上下文中经过验证的信任问卷。该篇位置论文着重于探讨distrust作为一个构建和独立于信任的第二个构建之间的潜在区别。

    Trust is a key motivation in developing explainable artificial intelligence (XAI). However, researchers attempting to measure trust in AI face numerous challenges, such as different trust conceptualizations, simplified experimental tasks that may not induce uncertainty as a prerequisite for trust, and the lack of validated trust questionnaires in the context of AI. While acknowledging these issues, we have identified a further challenge that currently seems underappreciated - the potential distinction between trust as one construct and \emph{distrust} as a second construct independent of trust. While there has been long-standing academic discourse for this distinction and arguments for both the one-dimensional and two-dimensional conceptualization of trust, distrust seems relatively understudied in XAI. In this position paper, we not only highlight the theoretical arguments for distrust as a distinct construct from trust but also contextualize psychometric evidence that likewise favors
    
[^36]: GNNBuilder：通用图神经网络加速器生成、模拟和优化的自动化框架

    GNNBuilder: An Automated Framework for Generic Graph Neural Network Accelerator Generation, Simulation, and Optimization. (arXiv:2303.16459v1 [cs.AR])

    [http://arxiv.org/abs/2303.16459](http://arxiv.org/abs/2303.16459)

    GNNBuilder是一个自动化的、通用的、端到端的GNN加速器生成框架，它可以为用户任意定义的广泛的GNN模型自动生成加速器，且运行速度比软件基准快多达12.95倍。

    

    目前有很多图神经网络（GNN）加速器被提出。然而，它们高度依赖于用户的硬件专业知识，并且通常针对一种特定的GNN模型进行优化，使它们难以实际使用。因此，在这项工作中，我们提出了GNNBuilder，这是第一个自动化的、通用的、端到端的GNN加速器生成框架。它具有四个优点：（1）GNNBuilder可以自动为用户任意定义的广泛的GNN模型生成GNN加速器；（2）GNNBuilder采用标准的PyTorch编程接口，为算法开发人员提供零开销；（3）GNNBuilder支持端到端的代码生成、模拟、加速器优化和硬件部署，实现了GNN加速器设计的一键式操作；（4）GNNBuilder配备了其所生成的加速器的准确性能模型，使得设计空间探索（DSE）快速而灵活。在实验中，首先我们展示了我们的加速器在6个基准数据集上与最先进的GNN加速器相比表现出色，运行速度比软件基准快了多达12.95倍。其次，对不规则图处理的案例研究展示了GNNBuilder的出色可扩展性和适应性。最后，在单个GPU的服务器上，我们对400个GNN模型进行了30分钟的DSE研究，验证了GNNBuilder的效率和有效性。

    There are plenty of graph neural network (GNN) accelerators being proposed. However, they highly rely on users' hardware expertise and are usually optimized for one specific GNN model, making them challenging for practical use . Therefore, in this work, we propose GNNBuilder, the first automated, generic, end-to-end GNN accelerator generation framework. It features four advantages: (1) GNNBuilder can automatically generate GNN accelerators for a wide range of GNN models arbitrarily defined by users; (2) GNNBuilder takes standard PyTorch programming interface, introducing zero overhead for algorithm developers; (3) GNNBuilder supports end-to-end code generation, simulation, accelerator optimization, and hardware deployment, realizing a push-button fashion for GNN accelerator design; (4) GNNBuilder is equipped with accurate performance models of its generated accelerator, enabling fast and flexible design space exploration (DSE). In the experiments, first, we show that our accelerator pe
    
[^37]: ProtFIM：基于蛋白质语言模型的填充中间蛋白序列设计

    ProtFIM: Fill-in-Middle Protein Sequence Design via Protein Language Models. (arXiv:2303.16452v1 [cs.LG])

    [http://arxiv.org/abs/2303.16452](http://arxiv.org/abs/2303.16452)

    本论文介绍了一种基于蛋白质语言模型的填充中间蛋白序列设计方法，并设计了新的基准测试SEIFER，揭示了现有语言模型的弱点，证明了使用填充中间变换训练的语言模型(ProtFIM)，更适合于蛋白质工程。

    

    基于蛋白质序列的因果语言建模，蛋白质语言模型(PLMs)已成为一种有前途的蛋白质序列设计工具。但是在实际的蛋白质工程中，有许多情况是在保持其它残基的情况下优化蛋白质中间的氨基酸。由于PLMs的从左到右的性质，现有的PLMs通过促使前缀残基来修改后缀残基，这对于考虑整个周围背景的填充任务是不足够的。为了找到更有效的PLMs用于蛋白质工程，我们设计了一个新的基准测试——二级结构中间填充——SEIFER，它近似于填充序列设计场景。通过对现有模型在基准测试中的评估，我们揭示了现有语言模型的弱点，证明了通过填充中间变换训练的语言模型(称为ProtFIM)，更适合于蛋白质工程。此外，我们证明了ProtFIM生成的蛋白质序列的中间部分，具有更准确的结构特征。

    Protein language models (pLMs), pre-trained via causal language modeling on protein sequences, have been a promising tool for protein sequence design. In real-world protein engineering, there are many cases where the amino acids in the middle of a protein sequence are optimized while maintaining other residues. Unfortunately, because of the left-to-right nature of pLMs, existing pLMs modify suffix residues by prompting prefix residues, which are insufficient for the infilling task that considers the whole surrounding context. To find the more effective pLMs for protein engineering, we design a new benchmark, Secondary structureE InFilling rEcoveRy, SEIFER, which approximates infilling sequence design scenarios. With the evaluation of existing models on the benchmark, we reveal the weakness of existing language models and show that language models trained via fill-in-middle transformation, called ProtFIM, are more appropriate for protein engineering. Also, we prove that ProtFIM generate
    
[^38]: TaskMatrix.AI：将基础模型与数百万个API连接以完成任务

    TaskMatrix.AI: Completing Tasks by Connecting Foundation Models with Millions of APIs. (arXiv:2303.16434v1 [cs.AI])

    [http://arxiv.org/abs/2303.16434](http://arxiv.org/abs/2303.16434)

    TaskMatrix.AI是一个任务完成系统，可以将基础模型与数百万个API连接，提高完成任务的效率和全面性。

    

    人工智能（AI）近年来取得了令人瞩目的进展。本文提出了一个任务完成系统TaskMatrix.AI，它可以自动将基础模型与数百万个API连接以完成不同的任务。具体而言，TaskMatrix.AI使用API数据集来将基础模型的输入与可用的API进行匹配，从而完成任务。我们在几个开放域和领域特定任务上进行实验，证明了TaskMatrix.AI的效果和效率。

    Artificial Intelligence (AI) has made incredible progress recently. On the one hand, advanced foundation models like ChatGPT can offer powerful conversation, in-context learning and code generation abilities on a broad range of open-domain tasks. They can also generate high-level solution outlines for domain-specific tasks based on the common sense knowledge they have acquired. However, they still face difficulties with some specialized tasks because they lack enough domain-specific data during pre-training or they often have errors in their neural network computations on those tasks that need accurate executions. On the other hand, there are also many existing models and systems (symbolic-based or neural-based) that can do some domain-specific tasks very well. However, due to the different implementation or working mechanisms, they are not easily accessible or compatible with foundation models. Therefore, there is a clear and pressing need for a mechanism that can leverage foundation 
    
[^39]: ProductAE：面向大维数的深度学习驱动纠错码设计

    ProductAE: Toward Deep Learning Driven Error-Correction Codes of Large Dimensions. (arXiv:2303.16424v1 [cs.IT])

    [http://arxiv.org/abs/2303.16424](http://arxiv.org/abs/2303.16424)

    本文提出了Product Autoencoder来通过可管理的训练复杂性实现相对较大的代码的训练。

    

    尽管几十年的理论研究已经发明了几个纠错码类别，但这些码的设计却是一项极具挑战性的任务，主要依靠人类智慧。最近的研究表明，这样的设计可以通过机器学习（ML）工具有效地自动化和加速，从而实现与经典设计相比具有良好性能增益的ML驱动的纠错码类别。然而，一个根本性的挑战是，对于大码维度来说，设计和训练完全的ML驱动的编码器和解码器对来说是非常复杂的，如果不是不可能的的话。在本文中，我们提出了Product Autoencoder（ProductAE）-一种计算效率高的深度学习驱动（编码器，解码器）对的系列-旨在通过可管理的训练复杂性实现相对较大的代码（编码器和解码器）的训练。我们借鉴了经典乘积码的思想，并提出了使用ProductAE构建大型神经网络的编码技术。

    While decades of theoretical research have led to the invention of several classes of error-correction codes, the design of such codes is an extremely challenging task, mostly driven by human ingenuity. Recent studies demonstrate that such designs can be effectively automated and accelerated via tools from machine learning (ML), thus enabling ML-driven classes of error-correction codes with promising performance gains compared to classical designs. A fundamental challenge, however, is that it is prohibitively complex, if not impossible, to design and train fully ML-driven encoder and decoder pairs for large code dimensions. In this paper, we propose Product Autoencoder (ProductAE) -- a computationally-efficient family of deep learning driven (encoder, decoder) pairs -- aimed at enabling the training of relatively large codes (both encoder and decoder) with a manageable training complexity. We build upon ideas from classical product codes and propose constructing large neural codes usin
    
[^40]: 一种用于预测先进材料多种特性的综合多模态深度学习方法

    A Comprehensive and Versatile Multimodal Deep Learning Approach for Predicting Diverse Properties of Advanced Materials. (arXiv:2303.16412v1 [cond-mat.soft])

    [http://arxiv.org/abs/2303.16412](http://arxiv.org/abs/2303.16412)

    本文提出了一种多模态深度学习方法，利用物理属性和化学数据预测先进材料的特性，在处理高维信息空间方面具有很大优势，成功预测了114210种组成条件下的913680个属性数据点，该方法适用于不同材料和尺度。

    

    我们提出了一种多模态深度学习（MDL）框架，通过合并物理属性和化学数据来预测10维丙烯酸聚合物复合材料的物理特性。我们的MDL模型包括四个模块，其中三个模块是用于材料结构表征的生成式深度学习模型，第四个模块用于属性预测。我们的方法处理了18维的复杂性，包括10个组成输入和8个属性输出，成功预测了114210种组成条件下的913680个属性数据点。对于计算材料科学特别是对于结构未定义的材料，这种复杂性是前所未有的。我们提出了一个框架来分析高维信息空间，以实现逆向材料设计，展示了对各种材料和尺度的灵活性和适应性，前提是有足够的数据。这项研究推动了未来研究不同材料和开发更复杂的MDL模型。

    We present a multimodal deep learning (MDL) framework for predicting physical properties of a 10-dimensional acrylic polymer composite material by merging physical attributes and chemical data. Our MDL model comprises four modules, including three generative deep learning models for material structure characterization and a fourth model for property prediction. Our approach handles an 18-dimensional complexity, with 10 compositional inputs and 8 property outputs, successfully predicting 913,680 property data points across 114,210 composition conditions. This level of complexity is unprecedented in computational materials science, particularly for materials with undefined structures. We propose a framework to analyze the high-dimensional information space for inverse material design, demonstrating flexibility and adaptability to various materials and scales, provided sufficient data is available. This study advances future research on different materials and the development of more soph
    
[^41]: LMDA-Net: 用于通用EEG脑机接口范例的轻量级多维注意力网络及其可解释性

    LMDA-Net:A lightweight multi-dimensional attention network for general EEG-based brain-computer interface paradigms and interpretability. (arXiv:2303.16407v1 [cs.LG])

    [http://arxiv.org/abs/2303.16407](http://arxiv.org/abs/2303.16407)

    本论文提出了一种名为LMDA-Net的轻量级多维注意力网络，旨在提高通用EEG脑机接口范例的分类性能。该网络使用两个新型注意力模块——通道注意力模块和深度注意力模块，并在多个公开高影响力数据集上进行了评估。实验结果表明，LMDA-Net表现优于其他代表模型，实现了最先进的性能，并展示了其决策过程的高可解释性。

    

    基于EEG的活动和状态识别需要使用神经科学先前知识生成定量EEG特征，这可能限制BCI的性能。虽然基于神经网络的方法可以有效地提取特征，但它们经常会遇到诸如跨数据集的通用性差、高预测波动性和低模型可解释性等问题。因此，我们提出了一种新的轻量级多维注意力网络，称为LMDA-Net。通过结合两个专为EEG信号设计的新型注意力模块——通道注意力模块和深度注意力模块，LMDA-Net可以有效地整合来自多个维度的特征，从而提高了在各种BCI任务上的分类性能。 LMDA-Net在包括运动想象（MI）和P300-Speller范例在内的四个公开高影响力数据集上进行了评估，并与其他代表模型进行了比较。实验结果表明，LMDA-Net表现优于其他代表模型，实现了最先进的性能，并展示了其决策过程的高可解释性。

    EEG-based recognition of activities and states involves the use of prior neuroscience knowledge to generate quantitative EEG features, which may limit BCI performance. Although neural network-based methods can effectively extract features, they often encounter issues such as poor generalization across datasets, high predicting volatility, and low model interpretability. Hence, we propose a novel lightweight multi-dimensional attention network, called LMDA-Net. By incorporating two novel attention modules designed specifically for EEG signals, the channel attention module and the depth attention module, LMDA-Net can effectively integrate features from multiple dimensions, resulting in improved classification performance across various BCI tasks. LMDA-Net was evaluated on four high-impact public datasets, including motor imagery (MI) and P300-Speller paradigms, and was compared with other representative models. The experimental results demonstrate that LMDA-Net outperforms other represen
    
[^42]: 层次化视频瞬间检索和分步字幕

    Hierarchical Video-Moment Retrieval and Step-Captioning. (arXiv:2303.16406v1 [cs.CV])

    [http://arxiv.org/abs/2303.16406](http://arxiv.org/abs/2303.16406)

    这篇论文提出了HiREST数据集和一个新的基准，将分层信息检索和视觉/文本逐步总结从教学视频语料库中推广，使得在一个端到端的设置下可以共同搜索视频语料库，并生成摘要。

    

    目前人们在寻找大型视频语料库中的信息方面越来越感兴趣。先前的工作独立研究了相关任务，如基于文本的视频检索、瞬间检索、视频摘要和视频字幕，没有一个端到端的设置可以共同搜索视频语料库，并生成摘要。这样的端到端设置将允许许多有趣的应用程序，例如基于文本的搜索，从视频语料库中找到相关的视频，提取最相关的瞬间，并将瞬间分成重要的步骤，并加上字幕。为了解决这个问题，我们提出了HiREST(Hierarchical REtrieval and STep-captioning)数据集，并提出了一个新的基准，涵盖了来自教学视频语料库的分层信息检索和视觉/文本分阶段总结。HiREST由来自教学视频数据集的3.4K个文本-视频对组成，其中1.1K个视频具有与文本查询相关的瞬间跨度注释和细分。

    There is growing interest in searching for information from large video corpora. Prior works have studied relevant tasks, such as text-based video retrieval, moment retrieval, video summarization, and video captioning in isolation, without an end-to-end setup that can jointly search from video corpora and generate summaries. Such an end-to-end setup would allow for many interesting applications, e.g., a text-based search that finds a relevant video from a video corpus, extracts the most relevant moment from that video, and segments the moment into important steps with captions. To address this, we present the HiREST (HIerarchical REtrieval and STep-captioning) dataset and propose a new benchmark that covers hierarchical information retrieval and visual/textual stepwise summarization from an instructional video corpus. HiREST consists of 3.4K text-video pairs from an instructional video dataset, where 1.1K videos have annotations of moment spans relevant to text query and breakdown of e
    
[^43]: 利用语言指导的三模态一致性进行音频-视频源分离

    Language-Guided Audio-Visual Source Separation via Trimodal Consistency. (arXiv:2303.16342v1 [cs.CV])

    [http://arxiv.org/abs/2303.16342](http://arxiv.org/abs/2303.16342)

    该论文提出了一种自监督学习的方法，通过使用自然语言查询来进行音频源分离，实现了语言、视觉和音频的一致性对齐，并在多个数据集上表现出比现有方法更好的效果。

    

    我们提出了一种自监督学习的方法，基于自然语言查询在视频中学习执行音频源分离，仅使用未标记的视频和音频对作为训练数据。这项任务的一个关键挑战是学习将发声物体的语言描述与其视觉特征和相应的音频波形组件联系起来，而在训练期间没有访问注释。为了克服这个挑战，我们改进了现成的视觉语言基础模型，通过两种新的损失函数提供伪目标监督，并促进音频、视觉和自然语言模态之间更强的对齐。在推理过程中，我们的方法可以在给定文本、视频和音频输入或仅给定文本和音频输入时分离声音。我们在三个音频-视频分离数据集（包括MUSIC、SOLOS和AudioSet）上展示了我们自监督方法的有效性，其中我们的模型胜过了现有强监督方法的最新成果。

    We propose a self-supervised approach for learning to perform audio source separation in videos based on natural language queries, using only unlabeled video and audio pairs as training data. A key challenge in this task is learning to associate the linguistic description of a sound-emitting object to its visual features and the corresponding components of the audio waveform, all without access to annotations during training. To overcome this challenge, we adapt off-the-shelf vision-language foundation models to provide pseudo-target supervision via two novel loss functions and encourage a stronger alignment between the audio, visual and natural language modalities. During inference, our approach can separate sounds given text, video and audio input, or given text and audio input alone. We demonstrate the effectiveness of our self-supervised approach on three audio-visual separation datasets, including MUSIC, SOLOS and AudioSet, where we outperform state-of-the-art strongly supervised 
    
[^44]: 关于流式联邦学习中本地缓存更新规则的研究

    On the Local Cache Update Rules in Streaming Federated Learning. (arXiv:2303.16340v1 [cs.LG])

    [http://arxiv.org/abs/2303.16340](http://arxiv.org/abs/2303.16340)

    本文提出了三种本地缓存更新规则来管理动态数据分布和有限的缓存容量，以应对流式联邦学习中本地训练数据集与长期数据分布之间的差异。我们还推导出了该算法的收敛界限。我们在两个数据集上进行了测试，结果表明我们的算法效果良好。

    

    本研究针对流式联邦学习（SFL）领域，提出了本地缓存更新规则，以管理动态数据分布和有限的缓存容量。传统的联邦学习依赖于固定的数据集，而在SFL中，数据是流式的，并且其分布随时间而变化，导致本地训练数据集与长期分布之间存在差异。为了解决这个问题，我们提出了三个本地缓存更新规则——先进先出（FIFO）、静态比例选择性替换（SRSR）和动态比例选择性替换（DRSR）——在考虑有限的缓存容量的同时更新每个客户端的本地缓存。此外，我们还推导出了基于长期数据分布和客户端本地训练数据集之间分布不一致度的收敛界限。然后，我们在两个数据集上评估了我们提出的算法：网络流量分类数据集和图像分类数据集。

    In this study, we address the emerging field of Streaming Federated Learning (SFL) and propose local cache update rules to manage dynamic data distributions and limited cache capacity. Traditional federated learning relies on fixed data sets, whereas in SFL, data is streamed, and its distribution changes over time, leading to discrepancies between the local training dataset and long-term distribution. To mitigate this problem, we propose three local cache update rules - First-In-First-Out (FIFO), Static Ratio Selective Replacement (SRSR), and Dynamic Ratio Selective Replacement (DRSR) - that update the local cache of each client while considering the limited cache capacity. Furthermore, we derive a convergence bound for our proposed SFL algorithm as a function of the distribution discrepancy between the long-term data distribution and the client's local training dataset. We then evaluate our proposed algorithm on two datasets: a network traffic classification dataset and an image class
    
[^45]: FMAS：用于语义分割的快速多目标超级网络架构搜索

    FMAS: Fast Multi-Objective SuperNet Architecture Search for Semantic Segmentation. (arXiv:2303.16322v1 [cs.CV])

    [http://arxiv.org/abs/2303.16322](http://arxiv.org/abs/2303.16322)

    本文提出了快速多目标神经架构搜索框架FMAS，搜索有效的语义分割模型，能够快速找到有竞争力的设计，并在边缘设备上找到更快的网络。

    

    本文提出了FMAS，一种针对语义分割的快速多目标神经架构搜索框架。FMAS对DeepLabV3+的结构和预训练参数进行子采样，无需微调，大大减少搜索期间的训练时间。为了进一步降低候选模型的评估时间，在搜索过程中仅使用验证集的子集。只有最终的 Pareto非支配 候选模型最终使用完整的训练集进行微调。我们在PASCAL VOC 2012数据集上搜索了有效的精度和计算成本交换模型，并评估了FMAS的性能。FMAS能够快速找到有竞争力的设计，例如只需0.5个GPU天即可发现DeepLabV3+变体，将FLOPs和参数分别减少10%和20%，误差仅增加不到3%。我们在一种名为GAP8的边缘设备上进行了搜索，并将其延迟作为度量标准，FMAS能够找到2.2倍更快的网络，丢失7.61% MIoU。

    We present FMAS, a fast multi-objective neural architecture search framework for semantic segmentation. FMAS subsamples the structure and pre-trained parameters of DeepLabV3+, without fine-tuning, dramatically reducing training time during search. To further reduce candidate evaluation time, we use a subset of the validation dataset during the search. Only the final, Pareto non-dominated, candidates are ultimately fine-tuned using the complete training set. We evaluate FMAS by searching for models that effectively trade accuracy and computational cost on the PASCAL VOC 2012 dataset. FMAS finds competitive designs quickly, e.g., taking just 0.5 GPU days to discover a DeepLabV3+ variant that reduces FLOPs and parameters by 10$\%$ and 20$\%$ respectively, for less than 3$\%$ increased error. We also search on an edge device called GAP8 and use its latency as the metric. FMAS is capable of finding 2.2$\times$ faster network with 7.61$\%$ MIoU loss.
    
[^46]: 无限时间视角下利用部分观测进行最坏情况控制与学习

    Worst-Case Control and Learning Using Partial Observations Over an Infinite Time-Horizon. (arXiv:2303.16321v1 [math.OC])

    [http://arxiv.org/abs/2303.16321](http://arxiv.org/abs/2303.16321)

    本文提出了无限时间视角下部分观测系统的最坏情况控制和学习的框架，能够利用未知概率分布的有限值不确定变量，并能够通过定义信息状态来提高动态规划的计算可处理性，同时提出了可从观测数据中构建或学习的近似信息状态。

    

    安全关键的网络物理系统需要良好的控制策略来应对敌对干扰和建模不确定性。本文提出了一个框架，利用部分观测系统进行近似控制和学习，以最小化无限时间视角下的最坏情况贴现成本。我们将对系统的干扰建模为具有未知概率分布的有限值不确定变量。对于已知系统动力学的问题，我们构建了一个动态规划（DP）分解来计算最优控制策略。我们的第一贡献是定义信息状态，提高了DP的计算可处理性，而不损失最优性。然后，我们描述了一类在每个时间点产生可观测成本的问题的简化。我们的第二个贡献是定义了可以从观测数据中直接构建或学习的近似信息状态。

    Safety-critical cyber-physical systems require control strategies whose worst-case performance is robust against adversarial disturbances and modeling uncertainties. In this paper, we present a framework for approximate control and learning in partially observed systems to minimize the worst-case discounted cost over an infinite time-horizon. We model disturbances to the system as finite-valued uncertain variables with unknown probability distributions. For problems with known system dynamics, we construct a dynamic programming (DP) decomposition to compute the optimal control strategy. Our first contribution is to define information states that improve the computational tractability of this DP without loss of optimality. Then, we describe a simplification for a class of problems where the incurred cost is observable at each time-instance. Our second contribution is a definition of approximate information states that can be constructed or learned directly from observed data for problem
    
[^47]: 机器学习和深度学习应用于犯罪预测：系统综述与未来方向

    Crime Prediction Using Machine Learning and Deep Learning: A Systematic Review and Future Directions. (arXiv:2303.16310v1 [cs.LG])

    [http://arxiv.org/abs/2303.16310](http://arxiv.org/abs/2303.16310)

    该综述文章调查了超过150篇文章，探讨了各种机器学习和深度学习算法在预测犯罪方面的应用，为研究人员提供有价值的参考资料。

    

    预测犯罪在最近几年引起了研究人员的相当关注，主要关注识别犯罪事件中的模式和趋势。本综述文章调查了超过150篇文章，探讨了各种机器学习和深度学习算法应用于预测犯罪的情况。该研究提供了研究人员用于犯罪预测的数据集，并分析了应用于预测犯罪的机器学习和深度学习算法的杰出方法，提供了有关犯罪活动相关不同趋势和因素的见解。此外，本文还强调了可能存在的差距和未来方向，以增强犯罪预测的准确性。最后，本文介绍的关于应用机器学习和深度学习方法预测犯罪的研究综述，为这一领域的研究人员提供了有价值的参考资料。

    Predicting crime using machine learning and deep learning techniques has gained considerable attention from researchers in recent years, focusing on identifying patterns and trends in crime occurrences. This review paper examines over 150 articles to explore the various machine learning and deep learning algorithms applied to predict crime. The study provides access to the datasets used for crime prediction by researchers and analyzes prominent approaches applied in machine learning and deep learning algorithms to predict crime, offering insights into different trends and factors related to criminal activities. Additionally, the paper highlights potential gaps and future directions that can enhance the accuracy of crime prediction. Finally, the comprehensive overview of research discussed in this paper on crime prediction using machine learning and deep learning approaches serves as a valuable reference for researchers in this field. By gaining a deeper understanding of crime predictio
    
[^48]: Dice半度量损失函数：用软标签优化Dice分数

    Dice Semimetric Losses: Optimizing the Dice Score with Soft Labels. (arXiv:2303.16296v1 [cs.CV])

    [http://arxiv.org/abs/2303.16296](http://arxiv.org/abs/2303.16296)

    本文提出的Dice半度量损失函数可在软标签设置中使用，在医疗成像领域的分割方案中与使用软标签的研究相结合，可以获得更好的Dice分数和模型校准。

    

    在医学成像领域的许多自动分割方案中，软Dice损失（SDL）发挥了关键作用。在过去几年中，人们已经揭示了其优越性能背后的一些原因并进一步探索了其优化。然而，目前还没有实现支持直接在软标签设置中使用它的方案。因此，在使用SDL和研究利用软标签的同时进行模型校准的协同作用仍然缺失。在本文中，我们介绍了Dice半度量损失函数（DMLs），它们（i）在硬标签的标准设置下与SDL相同，但（ii）也可在软标签设置中使用。我们在公共的QUBIQ、LiTS和KiTS基准测试上的实验证实了DMLs与软标签（如平均、标签平滑和知识蒸馏）的潜在协同作用，而DMLs与硬标签（如大多数投票和随机选择）相比，产生了更优秀的Dice分数和模型校准。

    The soft Dice loss (SDL) has taken a pivotal role in many automated segmentation pipelines in the medical imaging community. Over the last years, some reasons behind its superior functioning have been uncovered and further optimizations have been explored. However, there is currently no implementation that supports its direct use in settings with soft labels. Hence, a synergy between the use of SDL and research leveraging the use of soft labels, also in the context of model calibration, is still missing. In this work, we introduce Dice semimetric losses (DMLs), which (i) are by design identical to SDL in a standard setting with hard labels, but (ii) can be used in settings with soft labels. Our experiments on the public QUBIQ, LiTS and KiTS benchmarks confirm the potential synergy of DMLs with soft labels (e.g. averaging, label smoothing, and knowledge distillation) over hard labels (e.g. majority voting and random selection). As a result, we obtain superior Dice scores and model calib
    
[^49]: XAIR：增强现实中可解释AI框架

    XAIR: A Framework of Explainable AI in Augmented Reality. (arXiv:2303.16292v1 [cs.HC])

    [http://arxiv.org/abs/2303.16292](http://arxiv.org/abs/2303.16292)

    XAIR是一个解决AR中XAI输出解释的设计框架，可以为设计者提供指南和支持，实现有效的XAI设计。

    

    可解释的人工智能（XAI）已经成为AI驱动交互式系统的重要组成部分。随着增强现实（AR）越来越多地融入日常生活，XAI在AR中的作用也变得至关重要，因为最终用户将经常与智能服务互动。然而，如何设计有效的AR XAI体验尚不清楚。我们提出了XAIR，这是一个设计框架，解决了何时，什么和如何在AR中提供AI输出解释的问题。该框架是基于对XAI和HCI研究的跨学科文献综述、对500多名最终用户对基于AR的解释偏好的大规模调查以及对12位专家收集他们在AR XAI设计方面的见解的三个研讨会而构建的。通过与10名设计师和另外12名最终用户进行的研究验证了XAIR的效用和有效性。XAIR可以为设计师提供指南，激发他们发现新的设计机会，并在AR中实现有效的XAI设计。

    Explainable AI (XAI) has established itself as an important component of AI-driven interactive systems. With Augmented Reality (AR) becoming more integrated in daily lives, the role of XAI also becomes essential in AR because end-users will frequently interact with intelligent services. However, it is unclear how to design effective XAI experiences for AR. We propose XAIR, a design framework that addresses "when", "what", and "how" to provide explanations of AI output in AR. The framework was based on a multi-disciplinary literature review of XAI and HCI research, a large-scale survey probing 500+ end-users' preferences for AR-based explanations, and three workshops with 12 experts collecting their insights about XAI design in AR. XAIR's utility and effectiveness was verified via a study with 10 designers and another study with 12 end-users. XAIR can provide guidelines for designers, inspiring them to identify new design opportunities and achieve effective XAI designs in AR.
    
[^50]: 大象的透视镜：调查谷歌、ChatGPT、维基百科和YouTube上的语言偏见

    A Perspectival Mirror of the Elephant: Investigating Language Bias on Google, ChatGPT, Wikipedia, and YouTube. (arXiv:2303.16281v1 [cs.CY])

    [http://arxiv.org/abs/2303.16281](http://arxiv.org/abs/2303.16281)

    研究发现在Google、ChatGPT、维基百科和YouTube上，搜索结果受限于语言，反映了与复杂主题相关的文化刻板印象，缺乏跨文化视角。

    

    与谷歌搜索“从多个角度获取信息，以便你可以形成自己对世界的理解”的任务相反，我们发现谷歌及其最突出的搜索结果 - 维基百科和YouTube，仅反映与“佛教”、“自由主义”、“殖民化”、“伊朗”和“美国”等复杂主题相关的文化刻板印象。简单地说，在不同语言的相同搜索中，它们以不同程度呈现不同的信息（我们称之为“语言偏见”），而不是呈现复杂主题的全球图片。我们的在线搜索使我们成为谚语中的盲人，仅触摸小象的一小部分，不知道其他文化的视角的存在。我们用于搜索的语言最终成为促进本族中心主义观点的文化过滤器，其中一个人根据自己的文化评估其他人或思想。我们还发现ChatGPT中深深嵌入了语言偏见。

    Contrary to Google Search's mission of delivering information from "many angles so you can form your own understanding of the world," we find that Google and its most prominent returned results -- Wikipedia and YouTube, simply reflect the narrow set of cultural stereotypes tied to the search language for complex topics like "Buddhism," "Liberalism," "colonization," "Iran" and "America." Simply stated, they present, to varying degrees, distinct information across the same search in different languages (we call it 'language bias'). Instead of presenting a global picture of a complex topic, our online searches turn us into the proverbial blind person touching a small portion of an elephant, ignorant of the existence of other cultural perspectives. The language we use to search ends up as a cultural filter to promote ethnocentric views, where a person evaluates other people or ideas based on their own culture. We also find that language bias is deeply embedded in ChatGPT. As it is primaril
    
[^51]: 通过编码实现优化：重整化群的视角

    Optimisation via encodings: a renormalisation group perspective. (arXiv:2303.16258v1 [cs.AI])

    [http://arxiv.org/abs/2303.16258](http://arxiv.org/abs/2303.16258)

    本文提出了一种通过使用启发式算法构造覆盖编码映射，将大型搜索空间中的过程映射到原始搜索空间的子集中，并使用重整化群的视角来处理离散优化问题的方法。这种方法相对于单独的局部搜索方法具有更好的性能。

    

    解决离散优化问题的传统方法是使用适当定义的成本或适应性景观上的局部搜索。然而，这些方法受到典型崎岖景观中的局部最小值制约，令搜索过程变慢。另一种解决优化问题的方法是通过使用启发式逼近估计全局最小值。本文提出了这两种方法的组合，使用覆盖编码映射将大型搜索空间中的过程映射到原始搜索空间的子集中。关键思想是利用适当的启发式算法构造覆盖编码映射，在大型搜索空间上生成不再显示陷阱局部最小值的景观。通常采用的过程涉及某种形式的粗粒化，我们认为它们可以被视为统计力学中重整化群的化身。我们使用组合优化领域的测试问题来说明这种方法，发现覆盖编码映射与局部搜索的组合始终优于单独的局部搜索。

    The traditional way of tackling discrete optimization problems is by using local search on suitably defined cost or fitness landscapes. Such approaches are however limited by the slowing down that occurs when local minima, that are a feature of the typically rugged landscapes encountered, arrest the progress of the search process. Another way of tackling optimization problems is by the use of heuristic approximations to estimate a global cost minimum. Here we present a combination of these two approaches by using cover-encoding maps which map processes from a larger search space to subsets of the original search space. The key idea is to construct cover-encoding maps with the help of suitable heuristics that single out near-optimal solutions and result in landscapes on the larger search space that no longer exhibit trapping local minima. The processes that are typically employed involve some form of coarse-graining, and we suggest here that they can be viewed as avatars of renormalisat
    
[^52]: Codex提示工程用于OCL生成的实证研究

    On Codex Prompt Engineering for OCL Generation: An Empirical Study. (arXiv:2303.16244v1 [cs.SE])

    [http://arxiv.org/abs/2303.16244](http://arxiv.org/abs/2303.16244)

    本文研究了使用Codex生成OCL约束，通过提高提示模板的领域特定信息和少量样本学习可以显著提高生成约束的质量。

    

    对象约束语言（OCL）是一种声明性语言，它在MOF模型中添加了约束和对象查询表达式。尽管OCL有潜力为UML模型提供精度和简洁性，但其不熟悉的语法阻碍了其被采用。最近LLM（如GPT-3）的进展显示了它们在许多NLP任务（包括语义解析和文本生成）中的能力。Codex是GPT-3的后代，已经在GitHub上公开可用的代码上进行了微调，并且可以用许多编程语言生成代码。我们研究了从自然语言规范中由Codex生成的OCL约束的可靠性。为了实现这一目标，我们编制了一个包含插槽的提示模板，用UML信息和目标任务填充，使用零或少量样本学习方法。通过衡量OCL约束的语法有效性和执行准确性指标，我们发现丰富提示模板的领域特定信息以及使用少量样本学习可以显著提高生成的OCL约束的质量。

    The Object Constraint Language (OCL) is a declarative language that adds constraints and object query expressions to MOF models. Despite its potential to provide precision and conciseness to UML models, the unfamiliar syntax of OCL has hindered its adoption. Recent advancements in LLMs, such as GPT-3, have shown their capability in many NLP tasks, including semantic parsing and text generation. Codex, a GPT-3 descendant, has been fine-tuned on publicly available code from GitHub and can generate code in many programming languages. We investigate the reliability of OCL constraints generated by Codex from natural language specifications. To achieve this, we compiled a dataset of 15 UML models and 168 specifications and crafted a prompt template with slots to populate with UML information and the target task, using both zero- and few-shot learning methods. By measuring the syntactic validity and execution accuracy metrics of the generated OCL constraints, we found that enriching the promp
    
[^53]: 基于多子网络的EMO联合剪枝：高效快速

    An EMO Joint Pruning with Multiple Sub-networks: Fast and Effect. (arXiv:2303.16212v1 [cs.LG])

    [http://arxiv.org/abs/2303.16212](http://arxiv.org/abs/2303.16212)

    本文提出了一种基于多子网络的EMO联合剪枝算法，该算法可以减少空间和资源消耗。该算法采用分治的EMO网络剪枝框架，将整个网络上复杂的EMO剪枝任务分解为多个子网络上更简单的子任务。基于跨网络约束的子网络训练方法可以进一步提高性能。

    

    基于进化多目标（EMO）的网络剪枝算法可以平衡网络的剪枝率和性能。然而，由于基于种群的特性，它经常受到复杂的剪枝优化空间和高度资源消耗的剪枝结构验证过程的限制，从而限制了它的应用。为此，本文提出了一种基于多子网络的EMO联合剪枝（EMO-PMS），以减少空间复杂度和资源消耗。首先，提出了一种分治的EMO网络剪枝框架，将整个网络上复杂的EMO剪枝任务分解为多个子网络上更简单的子任务。一方面，这种分解减少了剪枝优化空间并降低了优化难度；另一方面，较小的网络结构收敛更快，因此所提出的算法的计算资源消耗较低。其次，基于跨网络约束的子网络训练方法。

    The network pruning algorithm based on evolutionary multi-objective (EMO) can balance the pruning rate and performance of the network. However, its population-based nature often suffers from the complex pruning optimization space and the highly resource-consuming pruning structure verification process, which limits its application. To this end, this paper proposes an EMO joint pruning with multiple sub-networks (EMO-PMS) to reduce space complexity and resource consumption. First, a divide-and-conquer EMO network pruning framework is proposed, which decomposes the complex EMO pruning task on the whole network into easier sub-tasks on multiple sub-networks. On the one hand, this decomposition reduces the pruning optimization space and decreases the optimization difficulty; on the other hand, the smaller network structure converges faster, so the computational resource consumption of the proposed algorithm is lower. Secondly, a sub-network training method based on cross-network constraint
    
[^54]: 质量多样性变形器：基于决策Transformer生成行为条件下的轨迹

    The Quality-Diversity Transformer: Generating Behavior-Conditioned Trajectories with Decision Transformers. (arXiv:2303.16207v1 [cs.NE])

    [http://arxiv.org/abs/2303.16207](http://arxiv.org/abs/2303.16207)

    该论文提出了一种基于质量多样性算法和 Transformer 的方法，通过两种机制以实现质量一致的生成行为条件下的轨迹。

    

    在神经进化计算的背景下，质量多样性算法通过依赖行为空间的定义来生成各种不同和高效的策略集合，取得了很好的效果。然而，在不确定的环境中，会有两个问题出现。第一，策略可能缺乏鲁棒性和可重复性，即在略微不同的情况下，多个 episodes 往往会导致非常不同的行为结果。第二，由于策略集的离散性，解决方案的变化是不连续的。本文提出了一种新的方法来实现基于行为条件下的轨迹生成，其基于两个机制：首先是 MAP-Elites Low-Spread (ME-LS)，它限制了选择那些在行为空间上最一致的解决方案。其次是质量多样性变形器 (QDT)，它是基于 Transformer 的。

    In the context of neuroevolution, Quality-Diversity algorithms have proven effective in generating repertoires of diverse and efficient policies by relying on the definition of a behavior space. A natural goal induced by the creation of such a repertoire is trying to achieve behaviors on demand, which can be done by running the corresponding policy from the repertoire. However, in uncertain environments, two problems arise. First, policies can lack robustness and repeatability, meaning that multiple episodes under slightly different conditions often result in very different behaviors. Second, due to the discrete nature of the repertoire, solutions vary discontinuously. Here we present a new approach to achieve behavior-conditioned trajectory generation based on two mechanisms: First, MAP-Elites Low-Spread (ME-LS), which constrains the selection of solutions to those that are the most consistent in the behavior space. Second, the Quality-Diversity Transformer (QDT), a Transformer-based 
    
[^55]: 您的扩散模型暗中是一种零样本分类器。

    Your Diffusion Model is Secretly a Zero-Shot Classifier. (arXiv:2303.16203v1 [cs.LG])

    [http://arxiv.org/abs/2303.16203](http://arxiv.org/abs/2303.16203)

    扩散模型的密度估计可以被用作零样本分类，作者的生成式分类方法在各种基准测试中取得强大的结果，并具有更强的多模式关系推理能力。

    

    最近大规模的文本到图像扩散模型极大地增强了我们的基于文本生成图像的能力。这些模型可以为大量提示生成逼真的图像，并展示出令人印象深刻的组合泛化能力。几乎所有的用例到目前为止都只关注抽样，然而，扩散模型还可以提供有用于图像生成之外的条件密度估计。在本文中，我们展示了类似于Stable Diffusion的大规模文本到图像扩散模型的密度估计可以被利用来执行零样本分类，而无需额外的训练。我们的生成式分类方法在各种基准测试中取得了强大的结果，并优于从扩散模型中提取知识的替代方法。我们还发现，我们基于扩散的方法比竞争性的对比方法具有更强的多模式关系推理能力。最后，我们评估了我们方法的可解释性，并呈现了定性结果，证明它学习了有意义的图像-文本对齐。

    The recent wave of large-scale text-to-image diffusion models has dramatically increased our text-based image generation abilities. These models can generate realistic images for a staggering variety of prompts and exhibit impressive compositional generalization abilities. Almost all use cases thus far have solely focused on sampling; however, diffusion models can also provide conditional density estimates, which are useful for tasks beyond image generation. In this paper, we show that the density estimates from large-scale text-to-image diffusion models like Stable Diffusion can be leveraged to perform zero-shot classification without any additional training. Our generative approach to classification attains strong results on a variety of benchmarks and outperforms alternative methods of extracting knowledge from diffusion models. We also find that our diffusion-based approach has stronger multimodal relational reasoning abilities than competing contrastive approaches. Finally, we eva
    
[^56]: 没有正确性的可重复性并不重要：在NLP领域中测试代码的重要性。

    Reproducibility is Nothing without Correctness: The Importance of Testing Code in NLP. (arXiv:2303.16166v1 [cs.CL])

    [http://arxiv.org/abs/2303.16166](http://arxiv.org/abs/2303.16166)

    在NLP研究中，我们不能仅凭感知质量假定代码正确性，应该推动采用编码最佳实践以提高实验结果的正确性和可靠性。

    

    尽管其在研究实验中发挥了关键作用，但代码正确性往往仅基于结果的感知质量而被假定。这带来了错误结果和潜在误导性发现的风险。为了解决这个问题，我们认为当前关注结果重现应该与强调编码最佳实践相辅相成。我们通过一个案例研究来支持我们向NLP社区发出的号召，在这个案例研究中，我们识别出并纠正了广泛使用的最先进Conformer架构的开源实现中的三个Bug。通过在各种语言环境下进行的自动语音识别和翻译的比较实验，我们证明了Bug的存在并不会妨碍获得良好的和可重复的结果，反而可能导致不正确的结论，为未来的研究可能提供错误的指导。为了应对这一问题，这项研究呼吁采用旨在促进NLP研究中正确性的编码最佳实践，并提高实验结果的可靠性。

    Despite its pivotal role in research experiments, code correctness is often presumed only on the basis of the perceived quality of the results. This comes with the risk of erroneous outcomes and potentially misleading findings. To address this issue, we posit that the current focus on result reproducibility should go hand in hand with the emphasis on coding best practices. We bolster our call to the NLP community by presenting a case study, in which we identify (and correct) three bugs in widely used open-source implementations of the state-of-the-art Conformer architecture. Through comparative experiments on automatic speech recognition and translation in various language settings, we demonstrate that the existence of bugs does not prevent the achievement of good and reproducible results and can lead to incorrect conclusions that potentially misguide future research. In response to this, this study is a call to action toward the adoption of coding best practices aimed at fostering cor
    
[^57]: 机器学习在流体力学实验中的变革性潜力

    The transformative potential of machine learning for experiments in fluid mechanics. (arXiv:2303.15832v1 [physics.flu-dyn])

    [http://arxiv.org/abs/2303.15832](http://arxiv.org/abs/2303.15832)

    本文介绍了机器学习在实验流体力学中的三个方面的应用潜力：提高测量技术精度，改进实验设计和实现实时估计和控制。

    

    机器学习领域在许多科学和工程领域取得了快速进展，其中包括实验流体力学，这是最初的大数据学科之一。本文将重点介绍实验流体力学中几个受益于机器学习进展的方面，包括：1）增强测量技术的精度和质量，2）改进实验设计和替代数值孪生模型和3）实现实时估计和控制。对于每个方面，我们讨论了最近的成功案例和正在进行的挑战，以及注意事项和限制，并概述了ML增强和ML能力的实验流体力学的新途径的潜力。

    The field of machine learning has rapidly advanced the state of the art in many fields of science and engineering, including experimental fluid dynamics, which is one of the original big-data disciplines. This perspective will highlight several aspects of experimental fluid mechanics that stand to benefit from progress advances in machine learning, including: 1) augmenting the fidelity and quality of measurement techniques, 2) improving experimental design and surrogate digital-twin models and 3) enabling real-time estimation and control. In each case, we discuss recent success stories and ongoing challenges, along with caveats and limitations, and outline the potential for new avenues of ML-augmented and ML-enabled experimental fluid mechanics.
    
[^58]: 基础模型与合理使用

    Foundation Models and Fair Use. (arXiv:2303.15715v1 [cs.CY] CROSS LISTED)

    [http://arxiv.org/abs/2303.15715](http://arxiv.org/abs/2303.15715)

    基础模型开发和部署需确保在合理使用的范围内，但这并不保证。在使用有版权内容时需要注意风险并可能需要进一步的工作。

    

    现有的基础模型是基于有版权的材料训练出来的。在数据创建者没有得到适当的归属或赔偿时部署这些模型可能带来法律和道德风险。在美国和其他几个国家，版权内容可能被用于构建基础模型而不会产生法律责任，这是因为合理使用原则的存在。但是需要注意的是，如果这些模型的输出产生了与版权数据相似的结果，尤其是在影响到这些数据市场的情况下，合理使用原则将不再适用于模型的输出。本文强调合理使用原则并不保证，可能需要进一步的工作才能确保模型的开发和部署在合理使用的范围内。首先，我们调查了基于有版权内容的开发和部署基础模型的潜在风险。我们回顾了相关的美国案例法，并类比生成文本、源代码和可视化等可能的应用。

    Existing foundation models are trained on copyrighted material. Deploying these models can pose both legal and ethical risks when data creators fail to receive appropriate attribution or compensation. In the United States and several other countries, copyrighted content may be used to build foundation models without incurring liability due to the fair use doctrine. However, there is a caveat: If the model produces output that is similar to copyrighted data, particularly in scenarios that affect the market of that data, fair use may no longer apply to the output of the model. In this work, we emphasize that fair use is not guaranteed, and additional work may be necessary to keep model development and deployment squarely in the realm of fair use. First, we survey the potential risks of developing and deploying foundation models based on copyrighted content. We review relevant U.S. case law, drawing parallels to existing and potential applications for generating text, source code, and vis
    
[^59]: 通过扩散去噪平滑进行认证和对抗性的鲁棒的样本外检测

    Diffusion Denoised Smoothing for Certified and Adversarial Robust Out-Of-Distribution Detection. (arXiv:2303.14961v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.14961](http://arxiv.org/abs/2303.14961)

    本研究提出了一个新的方法来证明$\ell_2$-norm下的样本外检测的鲁棒性，在不考虑网络架构和具体组件的情况下，改善了对抗攻击的检测技术。

    

    随着机器学习的应用不断扩展，确保其安全性变得尤为重要。其中一个主要关注点是识别给定样本是否来自训练分布，或者是一个“样本外”（OOD）样本。此外，对手可以以一种导致分类器做出自信预测的方式操纵OOD样本。本研究提出了一种新颖的方法，用于在输入的L2范围内证明在不考虑网络架构以及不需要特定组件或额外训练的情况下，对OOD检测的鲁棒性。此外，我们改进了检测OOD样本的对抗攻击的技术，同时提供了对于分布样本的高水平的认证和对抗的结果。在CIFAR10/100的所有OOD检测指标的平均值显示，与以前的方法相比提高了约13％/ 5％。

    As the use of machine learning continues to expand, the importance of ensuring its safety cannot be overstated. A key concern in this regard is the ability to identify whether a given sample is from the training distribution, or is an "Out-Of-Distribution" (OOD) sample. In addition, adversaries can manipulate OOD samples in ways that lead a classifier to make a confident prediction. In this study, we present a novel approach for certifying the robustness of OOD detection within a $\ell_2$-norm around the input, regardless of network architecture and without the need for specific components or additional training. Further, we improve current techniques for detecting adversarial attacks on OOD samples, while providing high levels of certified and adversarial robustness on in-distribution samples. The average of all OOD detection metrics on CIFAR10/100 shows an increase of $\sim 13 \% / 5\%$ relative to previous approaches.
    
[^60]: 学习时空隐式神经表示来实现事件引导的视频超分辨率

    Learning Spatial-Temporal Implicit Neural Representations for Event-Guided Video Super-Resolution. (arXiv:2303.13767v1 [cs.CV])

    [http://arxiv.org/abs/2303.13767](http://arxiv.org/abs/2303.13767)

    本文提出了一种新的框架，利用事件的时空插值来实现随机尺度下的视频超分辨率。方法包括从RGB帧和事件的查询空间-时间坐标和特征中学习隐式神经表示。

    

    事件相机异步感知强度变化，产生具有高动态范围和低延迟的事件流。这激发了利用事件引导具有挑战性的视频超分辨率（VSR）任务的研究。在本文中，我们首次尝试利用事件的高时序分辨率性质，通过利用事件的时空插值来实现随机尺度下的VSR。当引导VSR时，事件的时空信息的表示具有困难。为此，我们提出了一个新的框架，将事件的时空插值与VSR结合在一个统一的框架中。我们的关键思想是从RGB帧和事件的查询空间-时间坐标和特征中学习隐式神经表示。我们的方法分为三部分。具体而言，空时融合（STF）模块首先学习事件和RGB帧的3D特征。然后，时域滤波器（TF）模块解锁了更多特征并给出了精细的VSR结果。最后，我们提供了一个大规模的VSR数据集，以便深度学习的VSR研究人员可以评估其方法。

    Event cameras sense the intensity changes asynchronously and produce event streams with high dynamic range and low latency. This has inspired research endeavors utilizing events to guide the challenging video superresolution (VSR) task. In this paper, we make the first attempt to address a novel problem of achieving VSR at random scales by taking advantages of the high temporal resolution property of events. This is hampered by the difficulties of representing the spatial-temporal information of events when guiding VSR. To this end, we propose a novel framework that incorporates the spatial-temporal interpolation of events to VSR in a unified framework. Our key idea is to learn implicit neural representations from queried spatial-temporal coordinates and features from both RGB frames and events. Our method contains three parts. Specifically, the Spatial-Temporal Fusion (STF) module first learns the 3D features from events and RGB frames. Then, the Temporal Filter (TF) module unlocks mo
    
[^61]: DDT：一种基于扩散驱动变压器的从视频中恢复人体网格的框架

    DDT: A Diffusion-Driven Transformer-based Framework for Human Mesh Recovery from a Video. (arXiv:2303.13397v1 [cs.CV])

    [http://arxiv.org/abs/2303.13397](http://arxiv.org/abs/2303.13397)

    提出了一种基于扩散驱动变压器的视频 HMR 框架（DDT），它旨在从输入序列中解码特定的运动模式，增强运动平滑性和时间一致性，并输出所有帧的人体网格，使得 DDT 更适用于时间效率至关重要的实际应用。

    

    人体网格恢复（HMR）为各种实际应用提供了丰富的人体信息，例如游戏、人机交互和虚拟现实。与单一图像方法相比，基于视频的方法可以利用时间信息通过融合人体运动先验进一步提高性能。然而，像 VIBE 这样的多对多方法存在运动平滑性和时间一致性的挑战。而像 TCMR 和 MPS-Net 这样的多对一方法则依赖于未来帧，在推理过程中是非因果和时间效率低下的。为了解决这些挑战，提出了一种新的基于扩散驱动变压器的视频 HMR 框架（DDT）。DDT 旨在从输入序列中解码特定的运动模式，增强运动平滑性和时间一致性。作为一种多对多方法，DDT 的解码器输出所有帧的人体网格，使 DDT 更适用于时间效率至关重要的实际应用。

    Human mesh recovery (HMR) provides rich human body information for various real-world applications such as gaming, human-computer interaction, and virtual reality. Compared to single image-based methods, video-based methods can utilize temporal information to further improve performance by incorporating human body motion priors. However, many-to-many approaches such as VIBE suffer from motion smoothness and temporal inconsistency. While many-to-one approaches such as TCMR and MPS-Net rely on the future frames, which is non-causal and time inefficient during inference. To address these challenges, a novel Diffusion-Driven Transformer-based framework (DDT) for video-based HMR is presented. DDT is designed to decode specific motion patterns from the input sequence, enhancing motion smoothness and temporal consistency. As a many-to-many approach, the decoder of our DDT outputs the human mesh of all the frames, making DDT more viable for real-world applications where time efficiency is cruc
    
[^62]: 自动驾驶路径规划：现状与展望

    Path Planning for Autonomous Driving: The State of the Art and Perspectives. (arXiv:2303.09824v1 [cs.RO])

    [http://arxiv.org/abs/2303.09824](http://arxiv.org/abs/2303.09824)

    本文综述了现有的自动驾驶路径规划方法，包括管道规划和端到端规划方法。在挑战和潜在解决方案方面提供了讨论，有助于为智能汽车的发展提供更好的规划方法。

    

    智能汽车由于提高的便利性、安全性和潜在的商业价值而受到广泛关注。但由于各种问题，如安全性、可靠性和规划方法的泛化等限制，它们的部署仍局限于小规模验证阶段。本文旨在综述最先进的路径规划方法，包括管道规划和端到端规划方法。针对管道方法，本文提供了选取算法的概述，并讨论了扩展和优化机制；针对端到端方法，本文强调培训和验证方法。此外，本文还讨论了挑战和潜在解决方案，这有助于为智能汽车的发展提供更好的规划方法。

    Intelligent vehicles (IVs) have attracted wide attention thanks to the augmented convenience, safety advantages, and potential commercial value. Although a few of autonomous driving unicorns assert that IVs will be commercially deployable by 2025, their deployment is still restricted to small-scale validation due to various issues, among which safety, reliability, and generalization of planning methods are prominent concerns. Precise computation of control commands or trajectories by planning methods remains a prerequisite for IVs, owing to perceptual imperfections under complex environments, which pose an obstacle to the successful commercialization of IVs. This paper aims to review state-of-the-art planning methods, including pipeline planning and end-to-end planning methods. In terms of pipeline methods, a survey of selecting algorithms is provided along with a discussion of the expansion and optimization mechanisms, whereas in end-to-end methods, the training approaches and verific
    
[^63]: 保护社会免受AI滥用：何时限制AI能力是必要的？

    Protecting Society from AI Misuse: When are Restrictions on Capabilities Warranted?. (arXiv:2303.09377v1 [cs.AI])

    [http://arxiv.org/abs/2303.09377](http://arxiv.org/abs/2303.09377)

    随着人工智能系统能力不断提升，控制某些能力将有助于防止其滥用，这些限制可能包括控制访问、使用目的、输出与溯源以及开发资源，非AI能力限制也是必要的。尽管可能会降低使用率而增加滥用风险，但这些限制是当其他干预行不通、潜在危害性高、有有针对性方式干预时所必要的。

    

    随着人工智能（AI）系统不断提高能力，其被用于造成伤害的情况将会越来越多。事实上，AI系统已经开始用于自动化的欺诈活动、侵犯人权、创建有害的虚假图像以及识别危险毒素。为了防止AI的某些滥用，我们认为有必要对某些能力进行有针对性的干预。这些限制可能包括控制谁能访问某些类型的AI模型、它们可以用于什么、是否过滤输出或者可以追溯到使用者以及开发它们所需的资源。我们还认为，一些对滥用所需的非AI能力限制也是必要的。虽然能力限制可能会降低使用率而不是滥用率（存在不利的滥用-使用权衡），但我们认为当其他干预行不通、潜在滥用的危害性很高，并且有有针对性的方式来干预能力时，干预能力是必要的。

    Artificial intelligence (AI) systems will increasingly be used to cause harm as they grow more capable. In fact, AI systems are already starting to be used to automate fraudulent activities, violate human rights, create harmful fake images, and identify dangerous toxins. To prevent some misuses of AI, we argue that targeted interventions on certain capabilities will be warranted. These restrictions may include controlling who can access certain types of AI models, what they can be used for, whether outputs are filtered or can be traced back to their user, and the resources needed to develop them. We also contend that some restrictions on non-AI capabilities needed to cause harm will be required. Though capability restrictions risk reducing use more than misuse (facing an unfavorable Misuse-Use Tradeoff), we argue that interventions on capabilities are warranted when other interventions are insufficient, the potential harm from misuse is high, and there are targeted ways to intervene on
    
[^64]: 利用ChatGPT和Prompt Learning将放射学报告翻译成通俗易懂的语言：结果、限制和潜力。

    Translating Radiology Reports into Plain Language using ChatGPT and GPT-4 with Prompt Learning: Promising Results, Limitations, and Potential. (arXiv:2303.09038v1 [cs.CL])

    [http://arxiv.org/abs/2303.09038](http://arxiv.org/abs/2303.09038)

    本文研究探讨利用ChatGPT将放射学报告翻译成通俗易懂的语言，平均得分为5分制的4.1分，信息缺失率和信息错误率均较低，ChatGPT提供的建议大都与放射学报告相关。

    

    ChatGPT作为一种大型语言模型，以其类似人类表达和推理能力而备受关注。本研究探讨使用ChatGPT将放射学报告翻译成通俗易懂的语言的可行性，以便患者和医疗服务提供者得到更好的医疗教育。研究采集了62份低剂量胸部CT肺癌筛查扫描和76份脑MRI转移性筛查扫描的放射学报告。根据放射科医师的评价，ChatGPT可以成功将放射学报告翻译成通俗易懂的语言，平均得分为5分制的4.1分，信息缺失0.07处，信息错误0.11处。就ChatGPT提供的建议而言，它们是一般性的相关建议，例如保持与医生的随访和密切监测任何症状，对于共138个病例中的约37％，ChatGPT提供了与放射学报告有关的建议。

    The large language model called ChatGPT has drawn extensively attention because of its human-like expression and reasoning abilities. In this study, we investigate the feasibility of using ChatGPT in experiments on using ChatGPT to translate radiology reports into plain language for patients and healthcare providers so that they are educated for improved healthcare. Radiology reports from 62 low-dose chest CT lung cancer screening scans and 76 brain MRI metastases screening scans were collected in the first half of February for this study. According to the evaluation by radiologists, ChatGPT can successfully translate radiology reports into plain language with an average score of 4.1 in the five-point system with 0.07 places of information missing and 0.11 places of misinformation. In terms of the suggestions provided by ChatGPT, they are general relevant such as keeping following-up with doctors and closely monitoring any symptoms, and for about 37% of 138 cases in total ChatGPT offer
    
[^65]: I$^2$-SDF: 通过神经网络中的光线追踪实现内部场景重建和编辑

    I$^2$-SDF: Intrinsic Indoor Scene Reconstruction and Editing via Raytracing in Neural SDFs. (arXiv:2303.07634v1 [cs.CV])

    [http://arxiv.org/abs/2303.07634](http://arxiv.org/abs/2303.07634)

    本文提出了 I$^2$-SDF 方法，使用可微分的蒙特卡罗光线跟踪技术实现了室内场景的重建和编辑，采用气泡损失函数和错误引导的自适应采样方案提高了重建质量，同时分解神经辐射场为场景的空间变化材料实现了物理和逼真的场景编辑应用。

    

    本文提出了一种名为 I$^2$-SDF 的新方法，可使用可微分的蒙特卡罗光线追踪技术对神经网络有符号距离场中的多视图图像进行物体重建、辐射和材质恢复。针对小型物体，我们引入了新的气泡损失函数，以及误差引导自适应取样方案，大大提高了大规模室内场景的重建质量。此外，我们提出将神经辐射场分解为场景的空间变化材料，并通过基于表面的可微蒙特卡罗光线追踪和发射器语义分割来实现基于物理和逼真的场景重照和编辑应用。通过大量的定量和定性实验，我们展示了我们的方法在室内场景重建、新视角合成和场景编辑方面的卓越质量。

    In this work, we present I$^2$-SDF, a new method for intrinsic indoor scene reconstruction and editing using differentiable Monte Carlo raytracing on neural signed distance fields (SDFs). Our holistic neural SDF-based framework jointly recovers the underlying shapes, incident radiance and materials from multi-view images. We introduce a novel bubble loss for fine-grained small objects and error-guided adaptive sampling scheme to largely improve the reconstruction quality on large-scale indoor scenes. Further, we propose to decompose the neural radiance field into spatially-varying material of the scene as a neural field through surface-based, differentiable Monte Carlo raytracing and emitter semantic segmentations, which enables physically based and photorealistic scene relighting and editing applications. Through a number of qualitative and quantitative experiments, we demonstrate the superior quality of our method on indoor scene reconstruction, novel view synthesis, and scene editin
    
[^66]: 基于颗粒球计算的高效最小生成树聚类算法GBMST

    GBMST: An Efficient Minimum Spanning Tree Clustering Based on Granular-Ball Computing. (arXiv:2303.01082v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.01082](http://arxiv.org/abs/2303.01082)

    该论文提出了一种基于多粒度颗粒球和最小生成树的聚类算法，通过实现基于“大规模优先级”的聚类方法，可以大大避免异常值的影响，并加速了MST的构建过程。

    

    大多数现有的聚类方法都基于单一粒度的信息，如每个数据的距离和密度。这种最细粒度的方法通常效率低下且容易受到噪声的影响。因此，我们提出了一种聚类算法，它结合了多粒度颗粒球和最小生成树(MST)。我们构建了粗粒度颗粒球，然后使用颗粒球和MST实现基于“大规模优先级”的聚类方法，可以大大避免异常值的影响，并加快了MST的构建过程。在几个数据集上的实验结果证明了该算法的效果。所有代码已在https://github.com/xjnine/GBMST发布。

    Most of the existing clustering methods are based on a single granularity of information, such as the distance and density of each data. This most fine-grained based approach is usually inefficient and susceptible to noise. Therefore, we propose a clustering algorithm that combines multi-granularity Granular-Ball and minimum spanning tree (MST). We construct coarsegrained granular-balls, and then use granular-balls and MST to implement the clustering method based on "large-scale priority", which can greatly avoid the influence of outliers and accelerate the construction process of MST. Experimental results on several data sets demonstrate the power of the algorithm. All codes have been released at https://github.com/xjnine/GBMST.
    
[^67]: 论ChatGPT的鲁棒性：对抗性和超出分布的视角。

    On the Robustness of ChatGPT: An Adversarial and Out-of-distribution Perspective. (arXiv:2302.12095v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.12095](http://arxiv.org/abs/2302.12095)

    本研究评估了ChatGPT的鲁棒性，发现其在对抗性和超出分布任务上有一致的优势，但绝对表现仍有提高空间，鲁棒性仍是一个重要的挑战。

    

    ChatGPT是OpenAI最近发布的聊天机器人服务，并在过去几个月中受到越来越多的关注。虽然已对ChatGPT的各个方面进行了评估，但其鲁棒性，即对于未预期输入的表现，仍不清楚。鲁棒性在负责任的AI中特别受关注，特别是对于安全关键应用程序。在本文中，我们从对抗性和超出分布（OOD）的角度对ChatGPT的鲁棒性进行了彻底评估。为此，我们采用了AdvGLUE和ANLI基准来评估对抗性鲁棒性，采用Flipkart评论和DDXPlus医学诊断数据集进行OOD评估。我们选择了几个流行的基础模型作为基准。结果表明，ChatGPT在大多数对抗性和OOD分类和翻译任务上表现出一致的优势。但是，绝对的表现远非完美，这表明对抗性和OOD鲁棒性仍然是一个重要的威胁。

    ChatGPT is a recent chatbot service released by OpenAI and is receiving increasing attention over the past few months. While evaluations of various aspects of ChatGPT have been done, its robustness, i.e., the performance to unexpected inputs, is still unclear to the public. Robustness is of particular concern in responsible AI, especially for safety-critical applications. In this paper, we conduct a thorough evaluation of the robustness of ChatGPT from the adversarial and out-of-distribution (OOD) perspective. To do so, we employ the AdvGLUE and ANLI benchmarks to assess adversarial robustness and the Flipkart review and DDXPlus medical diagnosis datasets for OOD evaluation. We select several popular foundation models as baselines. Results show that ChatGPT shows consistent advantages on most adversarial and OOD classification and translation tasks. However, the absolute performance is far from perfection, which suggests that adversarial and OOD robustness remains a significant threat 
    
[^68]: Jaccard度量损失：使用软标签优化Jaccard指数

    Jaccard Metric Losses: Optimizing the Jaccard Index with Soft Labels. (arXiv:2302.05666v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.05666](http://arxiv.org/abs/2302.05666)

    本文提出了Jaccard度量损失（JMLs）来优化Jaccard指数，该损失在软标签下仍然有效。

    

    IoU损失是直接优化Jaccard指数的替代品。在语义分割中，将IoU损失作为损失函数的一部分，与仅优化像素损失（如交叉熵损失）相比，对于Jaccard指数测量表现更好。最显着的IoU损失是软Jaccard损失和Lovasz-Softmax损失。然而，这些损失与机器学习中普遍存在的软标签不兼容。在本文中，我们提出了Jaccard度量损失（JMLs），它们在标准设置下与软标签兼容，与软Jaccard损失相同。使用JMLs，我们研究了两种最流行的软标签用例：标签平滑和知识蒸馏。在三个语义分割数据集（Cityscapes、PASCAL VOC和DeepGlobe Land）上，我们的实验表明，与交叉熵损失相比，我们的简单方法显著提高了性能，并且在DeepGlobe Land数据集上超过了最先进的方法。

    IoU losses are surrogates that directly optimize the Jaccard index. In semantic segmentation, leveraging IoU losses as part of the loss function is shown to perform better with respect to the Jaccard index measure than optimizing pixel-wise losses such as the cross-entropy loss alone. The most notable IoU losses are the soft Jaccard loss and the Lovasz-Softmax loss. However, these losses are incompatible with soft labels which are ubiquitous in machine learning. In this paper, we propose Jaccard metric losses (JMLs), which are identical to the soft Jaccard loss in a standard setting with hard labels, but are compatible with soft labels. With JMLs, we study two of the most popular use cases of soft labels: label smoothing and knowledge distillation. With a variety of architectures, our experiments show significant improvements over the cross-entropy loss on three semantic segmentation datasets (Cityscapes, PASCAL VOC and DeepGlobe Land), and our simple approach outperforms state-of-the-
    
[^69]: 超低均匀精度量化的自动网络适应

    Automatic Network Adaptation for Ultra-Low Uniform-Precision Quantization. (arXiv:2212.10878v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.10878](http://arxiv.org/abs/2212.10878)

    本论文提出了一种名为神经通道扩展的神经架构搜索方法，该方法能够自适应多个流行网络，通过选择性扩展通道和满足硬件约束，实现了超低均匀精度量化对推理准确性的减轻和提升，其中2bit ResNet50准确率达到了目前最佳水平。

    

    均匀精度神经网络量化因其简化了高计算性能的紧密填充算术单元而变得流行。然而，它忽略了层间对量化误差的异构敏感性，导致推理准确性不佳。本文提出了一种名为神经通道扩展的神经架构搜索方法，调整网络结构以减轻超低均匀精度量化对推理准确性的影响。该方法优化了各层的通道扩展，同时满足硬件约束（例如FLOPs，PARAMs）。基于深入的分析和实验，我们证明了该方法可以调整多个流行网络，以在CIFAR10和ImageNet上实现更好的2位量化准确性。特别是，我们实现了具有更小的FLOPs和参数大小的2bit ResNet50最佳的Top-1/Top-5准确率。

    Uniform-precision neural network quantization has gained popularity since it simplifies densely packed arithmetic unit for high computing capability. However, it ignores heterogeneous sensitivity to the impact of quantization errors across the layers, resulting in sub-optimal inference accuracy. This work proposes a novel neural architecture search called neural channel expansion that adjusts the network structure to alleviate accuracy degradation from ultra-low uniform-precision quantization. The proposed method selectively expands channels for the quantization sensitive layers while satisfying hardware constraints (e.g., FLOPs, PARAMs). Based on in-depth analysis and experiments, we demonstrate that the proposed method can adapt several popular networks channels to achieve superior 2-bit quantization accuracy on CIFAR10 and ImageNet. In particular, we achieve the best-to-date Top-1/Top-5 accuracy for 2-bit ResNet50 with smaller FLOPs and the parameter size.
    
[^70]: CLIP是否捆绑概念？探索大型图像模型的组合性。

    Does CLIP Bind Concepts? Probing Compositionality in Large Image Models. (arXiv:2212.10537v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.10537](http://arxiv.org/abs/2212.10537)

    本文分析了大型神经网络模型CLIP的组合性能力以及以结构敏感的方式捆绑变量的能力，发现其能够在单一对象的情况下组合概念，但在需要概念捆绑的情况下性能显著下降。

    

    近年来，结合文本和图像的大型神经网络模型取得了令人瞩目的进展。然而，这些模型在多大程度上编码了它们操作的概念的组成性表示，如通过对“红色立方体”进行推理以正确识别“红色”和“立方体”这些成分，这仍然是一个开放性问题。本文关注一个大型预训练的视觉和语言模型（CLIP）编码组合概念的能力以及以结构敏感的方式捆绑变量的能力（例如区分“立方体在球体后面”和“球体在立方体后面”）。为了检查CLIP的性能，我们比较了许多来自组合分布语义模型（CDSMs）的架构，这是一种试图在嵌入空间中实现传统组合语言结构的研究方向。我们发现CLIP能够在单一对象的情况下组合概念，但在需要概念捆绑的情况下性能显著下降。我们的分析凸显了评估大型模型组合性的重要性，并为未来研究提出了方向。

    Large-scale neural network models combining text and images have made incredible progress in recent years. However, it remains an open question to what extent such models encode compositional representations of the concepts over which they operate, such as correctly identifying ''red cube'' by reasoning over the constituents ''red'' and ''cube''. In this work, we focus on the ability of a large pretrained vision and language model (CLIP) to encode compositional concepts and to bind variables in a structure-sensitive way (e.g., differentiating ''cube behind sphere'' from ''sphere behind cube''). In order to inspect the performance of CLIP, we compare several architectures from research on compositional distributional semantics models (CDSMs), a line of research that attempts to implement traditional compositional linguistic structures within embedding spaces. We find that CLIP can compose concepts in a single-object setting, but in situations where concept binding is needed, performance
    
[^71]: 大型语言模型是带有自我验证的推理器

    Large Language Models are reasoners with Self-Verification. (arXiv:2212.09561v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.09561](http://arxiv.org/abs/2212.09561)

    本文提出了一种新的自我验证方法，使用CoT的结论来构建新样本并要求LLM重新预测原始条件，以提高推理准确性。实验证明，LLMs可以对其自己的结论进行自我验证并实现竞争性的推理性能。

    

    当大型语言模型（LLM）通过思维链（CoT）进行复杂推理时，它非常敏感于个别错误。为了解决这个问题，我们必须训练验证器。我们提出一种称为自我验证的新方法，该方法使用CoT的结论作为条件来构建一个新样本，并要求LLM重新预测被掩盖的原始条件。我们基于准确性计算可解释的验证分数。该方法可以在使用少量样本学习时提高多个算术和逻辑推理数据集的准确性。我们已经证明LLM可以对其自己的结论进行可解释的自我验证并实现竞争性的推理性能。全面的实验表明，我们的方法可以帮助多种带有自我验证功能的大型语言模型避免混淆。

    When a large language model (LLM) performs complex reasoning by chain of thought (CoT), it can be highly sensitive to individual mistakes. We have had to train verifiers to address this issue. As we all know, after human inferring a conclusion, they often check it by re-verifying it, which can avoid some mistakes. We propose a new method called self-verification that uses the conclusion of the CoT as a condition to build a new sample and asks the LLM to re-predict the original conditions which be masked. We calculate an explainable verification score based on the accuracy. This method can improve the accuracy of multiple arithmetics and logical reasoning datasets when using few-shot learning. we have demonstrated that LLMs can conduct explainable self-verification of their own conclusions and achieve competitive reasoning performance. Extensive experimentals have demonstrated that our method can help multiple large language models with self-verification can avoid interference from inco
    
[^72]: 基于图卷积网络的密码货币信任网络中的欺诈检测方法

    Motif-aware temporal GCN for fraud detection in signed cryptocurrency trust networks. (arXiv:2211.13123v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.13123](http://arxiv.org/abs/2211.13123)

    本文提出了一种基于图卷积网络和平衡理论的加密货币信任网络欺诈检测方法，并使用模式矩阵捕捉局部拓扑信息。实验结果表明，该方法在真实数据和合成数据集上均优于现有方法。

    

    图卷积网络是一种处理可表示为图的数据的人工神经网络。由于金融交易可以自然地构造成图形，因此GCN在金融行业中得到了广泛应用，特别是在金融欺诈检测方面。本文重点研究加密货币信任网络中的欺诈检测。在现有文献中，大部分工作都集中在静态图上。而在本研究中，我们考虑了加密货币网络的演化特性，并利用本地结构和平衡理论来指导训练过程。具体而言，我们计算动态网络中的模式矩阵来捕捉局部拓扑信息，然后在GCN聚合过程中使用它们。每个快照生成的嵌入是时间窗口内嵌入的加权平均值，其中权重是可学习的参数。由于信任网络在每个边缘上都有签名，因此使用平衡理论来指导训练过程。实验结果表明，我们提出的基于模式感知的时态GCN在真实数据和合成数据集上均比现有的方法具有优异的性能。

    Graph convolutional networks (GCNs) is a class of artificial neural networks for processing data that can be represented as graphs. Since financial transactions can naturally be constructed as graphs, GCNs are widely applied in the financial industry, especially for financial fraud detection. In this paper, we focus on fraud detection on cryptocurrency truct networks. In the literature, most works focus on static networks. Whereas in this study, we consider the evolving nature of cryptocurrency networks, and use local structural as well as the balance theory to guide the training process. More specifically, we compute motif matrices to capture the local topological information, then use them in the GCN aggregation process. The generated embedding at each snapshot is a weighted average of embeddings within a time window, where the weights are learnable parameters. Since the trust networks is signed on each edge, balance theory is used to guide the training process. Experimental results 
    
[^73]: CRAFT: 概念递归激活分解用于可解释性

    CRAFT: Concept Recursive Activation FacTorization for Explainability. (arXiv:2211.10154v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.10154](http://arxiv.org/abs/2211.10154)

    CRAFT通过生成基于概念的解释来填补归因方法的局限性，实现了对图像“是什么”和“在哪里”的同时解释。

    

    归因方法通过热图识别影响模型决策的最具影响力区域，已成为一种普遍的可解释性方法。然而，最近的研究已经揭示了这些方法有限的实际价值，部分归因于它们对图像最显著区域的狭窄关注,揭示了模型“注视”哪里，但未能阐明模型在这些区域“看到”的内容。在本文中，我们通过生成基于概念的解释，尝试填补这一空白，来确定“是什么”和“在哪里”。我们引入了三个新要素来自动提取概念：（i）一种递归策略来检测和分解跨层的概念，（ii）用 Sobol 指数更准确地估计概念重要性的新方法，和（iii）使用隐式微分来解锁概念归因图。我们进行了人类和计算机视觉实验来证明该方法的可行性和有效性。

    Attribution methods, which employ heatmaps to identify the most influential regions of an image that impact model decisions, have gained widespread popularity as a type of explainability method. However, recent research has exposed the limited practical value of these methods, attributed in part to their narrow focus on the most prominent regions of an image -- revealing "where" the model looks, but failing to elucidate "what" the model sees in those areas. In this work, we try to fill in this gap with CRAFT -- a novel approach to identify both "what" and "where" by generating concept-based explanations. We introduce 3 new ingredients to the automatic concept extraction literature: (i) a recursive strategy to detect and decompose concepts across layers, (ii) a novel method for a more faithful estimation of concept importance using Sobol indices, and (iii) the use of implicit differentiation to unlock Concept Attribution Maps.  We conduct both human and computer vision experiments to de
    
[^74]: VGFlow: 针对人体重定位的可见性引导流网络

    VGFlow: Visibility guided Flow Network for Human Reposing. (arXiv:2211.08540v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.08540](http://arxiv.org/abs/2211.08540)

    提出了一种基于可见性引导流模块的流网络模型VGFlow，可以分离出目标的可见和不可见部分以实现纹理保留和风格操作，同时采用了多路径结构以在不同级别的细节上操作。在生成逼真人体姿势方面表现出有效性。

    

    人体重定位的任务涉及生成一个站立在任意构想姿势下的真实人物图像。生成感知准确图像存在多个困难，现有方法在保留纹理、维持图案一致性、考虑服装边界、处理遮挡、调整皮肤生成等方面存在局限性。这些困难还因可能的人体姿势方向空间巨大且多变、服装物品的本质高度非刚性、身体形状的多样性大大不同于人口中的多样性而进一步恶化。为了缓解这些困难并合成感知准确的图像，我们提出了VGFlow。我们的模型使用可见性引导流模块将流分离为目标的可见和不可见部分，以实现同时纹理保留和风格操作。此外，为了解决不同的身体形状和避免网络伪影，我们还采用了一个多路径结构，包括全局结构路径和多个局部细节路径，可以在不同级别的细节上进行操作。实验结果显示了所提出方法在生成具有精细细节和准确纹理的逼真人体姿势方面的有效性。

    The task of human reposing involves generating a realistic image of a person standing in an arbitrary conceivable pose. There are multiple difficulties in generating perceptually accurate images, and existing methods suffer from limitations in preserving texture, maintaining pattern coherence, respecting cloth boundaries, handling occlusions, manipulating skin generation, etc. These difficulties are further exacerbated by the fact that the possible space of pose orientation for humans is large and variable, the nature of clothing items is highly non-rigid, and the diversity in body shape differs largely among the population. To alleviate these difficulties and synthesize perceptually accurate images, we propose VGFlow. Our model uses a visibility-guided flow module to disentangle the flow into visible and invisible parts of the target for simultaneous texture preservation and style manipulation. Furthermore, to tackle distinct body shapes and avoid network artifacts, we also incorporat
    
[^75]: 动态认知逻辑中的代理更新与信念归属

    Changing agents and ascribing beliefs in dynamic epistemic logic. (arXiv:2211.02452v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.02452](http://arxiv.org/abs/2211.02452)

    本文在动态认知逻辑中扩展了行动框架，提出了代理更新框架，可以有选择性地添加或删除代理，并进行代理更新。这个框架可以用于模拟一些有趣的例子，并在人工智能问题的建模中得到应用。

    

    在动态认知逻辑中，通常使用行动框架来描述单个行动的不同视角。本文将行动框架扩展为添加或删除代理，称之为代理更新框架。可以有选择性地进行代理更新，只有某些指定的代理会获得更新的信息，这可用于模拟一些有趣的例子，如私有更新和欺骗。然后将一个Kripke模型通过代理更新框架的求和积更新进一步扩展，用于建模故事的问题。我们证明了动态认知逻辑对于人工智能问题的应用。

    In dynamic epistemic logic (Van Ditmarsch, Van Der Hoek, & Kooi, 2008) it is customary to use an action frame (Baltag & Moss, 2004; Baltag, Moss, & Solecki, 1998) to describe different views of a single action. In this article, action frames are extended to add or remove agents, we call these agent-update frames. This can be done selectively so that only some specified agents get information of the update, which can be used to model several interesting examples such as private update and deception, studied earlier by Baltag and Moss (2004); Sakama (2015); Van Ditmarsch, Van Eijck, Sietsma, and Wang (2012). The product update of a Kripke model by an action frame is an abbreviated way of describing the transformed Kripke model which is the result of performing the action. This is substantially extended to a sum-product update of a Kripke model by an agent-update frame in the new setting. These ideas are applied to an AI problem of modelling a story. We show that dynamic epistemic logics,
    
[^76]: 带有适宜的归纳偏差增强机器抽象推理能力的多视角和多评估方法

    Multi-Viewpoint and Multi-Evaluation with Felicitous Inductive Bias Boost Machine Abstract Reasoning Ability. (arXiv:2210.14914v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.14914](http://arxiv.org/abs/2210.14914)

    本文研究了机器在抽象推理方面的能力，证明了具有适宜的归纳偏差的神经网络可以优雅地解决RPM问题，并揭示了多视角和多评估是成功推理的关键学习策略。

    

    长期以来，人们一直致力于研究人工智能在抽象推理方面的能力，RAVEN渐进矩阵（RPM）的不同版本被提出作为基准测试。以往的工作表明，如果没有复杂的设计或包含语义信息的额外元数据，神经网络在训练后在RPM问题的决策方面仍可能犹豫不决。通过彻底的实验和消融研究，我们展示了具有适宜的归纳偏差的端到端神经网络可以优雅地解决RPM问题，而无需增加任何额外的元数据或特定骨干的偏好。我们的工作还揭示了多视角和多评估是成功推理的关键学习策略。最后，我们提供了关于连接模型在泛化方面失败的潜在解释。我们希望这些结果将作为人工智能能力检查的指标。

    Great endeavors have been made to study AI's ability in abstract reasoning, along with which different versions of RAVEN's progressive matrices (RPM) are proposed as benchmarks. Previous works give inkling that without sophisticated design or extra meta-data containing semantic information, neural networks may still be indecisive in making decisions regarding RPM problems, after relentless training. Evidenced by thorough experiments and ablation studies, we showcase that end-to-end neural networks embodied with felicitous inductive bias, intentionally design or serendipitously match, can solve RPM problems elegantly, without the augment of any extra meta-data or preferences of any specific backbone. Our work also reveals that multi-viewpoint with multi-evaluation is a key learning strategy for successful reasoning. Finally, potential explanations for the failure of connectionist models in generalization are provided. We hope that these results will serve as inspections of AI's ability 
    
[^77]: 实例感知图像修复

    Instance-Aware Image Completion. (arXiv:2210.12350v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.12350](http://arxiv.org/abs/2210.12350)

    本文提出了一个实例感知图像修复模型ImComplete，相比现有方法，它可以幻象出与环境背景相协调的视觉实例，提供了基于语义和结构的像素级指导。

    

    图像修复是一项旨在填补带有缺失区域的图像的任务，使它们具有合理的内容。然而，现有的图像修复方法往往通过填充周围纹理来填补缺失区域，而不是去幻象一个与环境背景相协调的视觉实例。在本研究中，我们提出了一种新的图像修复模型，名为ImComplete，该模型可以幻象缺失的实例，从而与原始背景协调。ImComplete首先采用了一个变压器架构，考虑到可见实例和缺失区域的位置。然后，ImComplete完成了缺失区域内的语义分割掩模，提供像素级的语义和结构指导。最后，图像合成块生成了逼真的内容。

    Image completion is a task that aims to fill in the missing region of a masked image with plausible contents. However, existing image completion methods tend to fill in the missing region with the surrounding texture instead of hallucinating a visual instance that is suitable in accordance with the context of the scene. In this work, we propose a novel image completion model, dubbed ImComplete, that hallucinates the missing instance that harmonizes well with - and thus preserves - the original context. ImComplete first adopts a transformer architecture that considers the visible instances and the location of the missing region. Then, ImComplete completes the semantic segmentation masks within the missing region, providing pixel-level semantic and structural guidance. Finally, the image synthesis blocks generate photo-realistic content. We perform a comprehensive evaluation of the results in terms of visual quality (LPIPS and FID) and contextual preservation scores (CLIPscore and object
    
[^78]: AI与数字孪生的相互作用：弥合数据驱动和模型驱动方法的差距

    The Interplay of AI and Digital Twin: Bridging the Gap between Data-Driven and Model-Driven Approaches. (arXiv:2209.12423v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.12423](http://arxiv.org/abs/2209.12423)

    本文全面回顾了AI和数字孪生之间的相互作用，重点介绍了数字孪生网络的各种用例和应用，以及其如何弥合数据驱动和模型驱动方法的差距。

    

    网络虚拟化和原生人工智能(AI)范例的发展已经构建了未来无线网络作为一个在数字平台上操作的综合实体的愿景，与物理领域智能互动，为数字孪生(DT)概念的蓬勃发展铺平了道路。DT网络的最新兴趣被新颖的无线技术和用例的出现所推动，这些技术和用例加剧了网络协调和资源管理的复杂度。由AI驱动，DT的关键原则是为物理实体和网络动力学创建虚拟孪生体，其中虚拟孪生体将被利用来生成合成数据并提供专为AI模型训练而设计的平台。尽管人们普遍认为AI是DT的种子，但我们预计DT和AI将互相促进，以一种克服彼此限制并相互补充优势的方式。在本文中，我们全面回顾了AI和数字孪生之间的相互作用，讨论了DT网络的各种用例和应用，并强调了这个领域的挑战和机遇。

    The evolution of network virtualization and native artificial intelligence (AI) paradigms have conceptualized the vision of future wireless networks as a comprehensive entity operating in whole over a digital platform, with smart interaction with the physical domain, paving the way for the blooming of the Digital Twin (DT) concept. The recent interest in the DT networks is fueled by the emergence of novel wireless technologies and use-cases, that exacerbate the level of complexity to orchestrate the network and to manage its resources. Driven by AI, the key principle of the DT is to create a virtual twin for the physical entities and network dynamics, where the virtual twin will be leveraged to generate synthetic data and offer an on-demand platform for AI model training. Despite the common understanding that AI is the seed for DT, we anticipate that the DT and AI will be enablers for each other, in a way that overcome their limitations and complement each other benefits. In this artic
    
[^79]: 深度卷积池化变换器用于Deepfake检测

    Deep Convolutional Pooling Transformer for Deepfake Detection. (arXiv:2209.05299v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.05299](http://arxiv.org/abs/2209.05299)

    本文提出了一种深度卷积池化变换器用于Deepfake检测，能够全面地融合局部和全局的图像特征，并采用注意力掩模丢失方法提高模型泛化能力，获得了多个基准数据集上的最优检测性能。

    

    最近，由于社交媒体数字取证中的安全和隐私问题，Deepfake引起了广泛的公众关注。随着互联网上越来越多逼真的Deepfake视频的传播，传统的检测技术已经无法区分真伪。大多数现有的深度学习方法主要集中在使用卷积神经网络作为骨干，以局部特征和脸部图像内关系为重点。然而，局部特征和关系对于模型训练学习足够的一般信息来进行Deepfake检测是不充分的。因此，现有的Deepfake检测方法已经达到了进一步提高检测性能的瓶颈。为了解决这个问题，我们提出了一种深度卷积变换器，以同时在局部和全局上合并关键的图像特征。具体来说，我们应用了卷积池化和重新注意力机制来丰富提取的特征和增强效能。此外，我们采用了鲜为人知的注意力掩模丢失方法来进一步提高模型的泛化能力。实验结果表明，我们提出的方法在多个基准数据集上实现了最先进的性能。

    Recently, Deepfake has drawn considerable public attention due to security and privacy concerns in social media digital forensics. As the wildly spreading Deepfake videos on the Internet become more realistic, traditional detection techniques have failed in distinguishing between real and fake. Most existing deep learning methods mainly focus on local features and relations within the face image using convolutional neural networks as a backbone. However, local features and relations are insufficient for model training to learn enough general information for Deepfake detection. Therefore, the existing Deepfake detection methods have reached a bottleneck to further improve the detection performance. To address this issue, we propose a deep convolutional Transformer to incorporate the decisive image features both locally and globally. Specifically, we apply convolutional pooling and re-attention to enrich the extracted features and enhance efficacy. Moreover, we employ the barely discusse
    
[^80]: 当攻击图形结构时，梯度告诉我们什么

    What Does the Gradient Tell When Attacking the Graph Structure. (arXiv:2208.12815v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.12815](http://arxiv.org/abs/2208.12815)

    本文研究了图神经网络中针对图形结构的对抗攻击，发现攻击者更倾向于增加类间边缘，通过连接不同类的节点来更有效地破坏节点特征。然而，GNN 的固有平滑性会导致在前向过程中丢失关键信息。为此，我们提出了一个具有多级传播的新型代理模型来解决这个问题。

    

    最近的研究表明，图神经网络 (GNNs) 容易受到针对图形结构的对抗攻击。一个恶意攻击者可以在有限的边缘范围内，通过给出的训练标签，来破坏受害模型的性能。之前的经验性研究表明，基于梯度的攻击者更倾向于添加边缘而不是删除。本文提出了一个理论证明，揭示了攻击者倾向于增加类间边缘，这是由于 GNN 的消息传递机制，这也解释了之前的一些经验观察。通过连接不同类的节点，攻击者可以更有效地破坏节点特征，从而使此类攻击更具优势。但是，我们证明了 GNN 消息传递的固有平滑性会将特征空间中的节点差异模糊化，导致在前向过程中丢失关键信息。为了解决这个问题，我们提出了一个具有多级传播的新型代理模型。

    Recent research has revealed that Graph Neural Networks (GNNs) are susceptible to adversarial attacks targeting the graph structure. A malicious attacker can manipulate a limited number of edges, given the training labels, to impair the victim model's performance. Previous empirical studies indicate that gradient-based attackers tend to add edges rather than remove them. In this paper, we present a theoretical demonstration revealing that attackers tend to increase inter-class edges due to the message passing mechanism of GNNs, which explains some previous empirical observations. By connecting dissimilar nodes, attackers can more effectively corrupt node features, making such attacks more advantageous. However, we demonstrate that the inherent smoothness of GNN's message passing tends to blur node dissimilarity in the feature space, leading to the loss of crucial information during the forward process. To address this issue, we propose a novel surrogate model with multi-level propagati
    
[^81]: 在拉丁美洲的自然语言处理中表现出的偏见和有害刻板印象的特征化方法

    A methodology to characterize bias and harmful stereotypes in natural language processing in Latin America. (arXiv:2207.06591v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.06591](http://arxiv.org/abs/2207.06591)

    本研究提出了一种自动检测和表征拉丁美洲自然语言处理系统中偏见和有害刻板印象的方法。该方法基于单词嵌入之间的相似性和数据源的分析，并在西班牙语、葡萄牙语和克丘亚语的有害刻板印象检测案例中进行测试。结果表明，不同的自然语言处理系统以不同甚至意想不到的方式存在偏见和放大有害的刻板印象。

    

    自动化决策系统，尤其是基于自然语言处理的系统在我们的生活中无处不在。它们不仅是我们每天使用的互联网搜索引擎的背后，还有更为关键的作用：筛选工作候选人，确定犯罪嫌疑人，诊断自闭症等。这些自动化系统会出现错误，这些错误可能在很多方面都是有害的，无论是因为后果的严重性（例如健康问题）还是因为所涉及的人数之多。当由自动化系统造成的错误对某个群体的影响超过其他群体时，我们称此系统存在偏见。大多数现代自然语言技术是基于使用机器学习从大量文本中获得的分析结果，即语言模型和单词嵌入。由于它们是通过应用子符号机器学习创建的，主要是人工神经网络，所以它们是不透明的，且无法通过直接检查来解释，因此很难理解这些系统何时存在偏见或何时放大有害的刻板印象。在本文中，我们提出了一种方法，用于自动检测和表征自然语言处理系统中的偏见和有害刻板印象，应用于拉丁美洲语言。我们的方法基于分析来自不同地区的单词嵌入之间的相似性，并分析用于训练自然语言处理模型的数据源。我们在一个针对西班牙语、葡萄牙语和克丘亚语的有害刻板印象检测案例研究中测试了我们的方法。我们的研究结果表明，不同的自然语言处理系统以不同甚至意想不到的方式存在偏见和放大有害的刻板印象，这凸显了测试和改善此类系统质量的重要性。

    Automated decision-making systems, especially those based on natural language processing, are pervasive in our lives. They are not only behind the internet search engines we use daily, but also take more critical roles: selecting candidates for a job, determining suspects of a crime, diagnosing autism and more. Such automated systems make errors, which may be harmful in many ways, be it because of the severity of the consequences (as in health issues) or because of the sheer number of people they affect. When errors made by an automated system affect a population more than others, we call the system \textit{biased}.  Most modern natural language technologies are based on artifacts obtained from enormous volumes of text using machine learning, namely language models and word embeddings. Since they are created by applying subsymbolic machine learning, mostly artificial neural networks, they are opaque and practically uninterpretable by direct inspection, thus making it very difficult to 
    
[^82]: NovelCraft：开放世界中的新颖性检测和发现数据集

    NovelCraft: A Dataset for Novelty Detection and Discovery in Open Worlds. (arXiv:2206.11736v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.11736](http://arxiv.org/abs/2206.11736)

    NovelCraft数据集提供了开放世界中新颖性检测与发现任务的挑战。在复杂的场景中插入新颖物体的检测需要更好的基准，并发现了控制假阳性时更简单的方法可能比复杂的方法更出色。

    

    为了让人工智能代理在不断变化的环境中成功执行任务，必须能够检测和适应新颖性。然而，视觉新颖性检测研究通常只评估旨在进行对象分类的重复利用数据集（如CIFAR-10），其中图像聚焦于一个明显、居中的对象。需要新的基准来代表在开放世界中导航复杂场景的挑战。我们的新NovelCraft数据集包含完成修改后的Minecraft环境中的跳跳球装配任务的代理所看到的图像和符号世界状态的多模式情节数据。在某些情节中，我们在复杂的3D场景中插入新颖物体，这些物体可能影响游戏玩法并出现在各种大小和位置中。我们的视觉新颖性检测基准发现，控制假阳性时，最好的面积下曲线度量的方法可能会被更简单的替代方法超过。

    In order for artificial agents to successfully perform tasks in changing environments, they must be able to both detect and adapt to novelty. However, visual novelty detection research often only evaluates on repurposed datasets such as CIFAR-10 originally intended for object classification, where images focus on one distinct, well-centered object. New benchmarks are needed to represent the challenges of navigating the complex scenes of an open world. Our new NovelCraft dataset contains multimodal episodic data of the images and symbolic world-states seen by an agent completing a pogo stick assembly task within a modified Minecraft environment. In some episodes, we insert novel objects within the complex 3D scene that may impact gameplay and appear in a variety of sizes and positions. Our visual novelty detection benchmark finds that methods that rank best on popular area-under-the-curve metrics may be outperformed by simpler alternatives when controlling false positives matters most. 
    
[^83]: 从“解决方案合成”到“学生尝试合成”：面向基于块的可视化编程任务的研究

    From {Solution Synthesis} to {Student Attempt Synthesis} for Block-Based Visual Programming Tasks. (arXiv:2205.01265v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2205.01265](http://arxiv.org/abs/2205.01265)

    研究自动推断学生误解的关键组成部分，引入了一个基准测试——StudentSyn，通过观察学生在一个任务上的尝试，合成他们对另一个任务的学习尝试，以提高人工智能驱动的编程导师的效果。

    

    基于块的可视化编程环境越来越被用来介绍计算概念给初学者。鉴于编程任务是开放式和概念性的，初学者在这些环境中学习时常常遇到困难。人工智能驱动的编程导师有着帮助挣扎的学生的巨大潜力，并且需要几个组成部分来实现这一潜力。我们研究了学生建模这一关键组成部分，特别是自动推断学生误解的能力，以便预测（合成）他们的行为。我们介绍了一个新颖的基准，StudentSyn，围绕以下挑战：为一个给定的学生，观察他们在一个固定的引用任务上的尝试后，合成他们对新目标任务的尝试。这个挑战类似于程序合成；但是，这里的目标不是合成一个“解决方案”（即专家编写的程序），而是合成一个“学生尝试”（即一个学生在学习过程中记录的程序）。我们提供了StudentSyn的详细说明，并描述了基准测试的几个潜在用例。我们还提出了一种模块化方法来解决这个挑战，并通过对初学者和有经验的参与者的实验分析了挑战的难度。

    Block-based visual programming environments are increasingly used to introduce computing concepts to beginners. Given that programming tasks are open-ended and conceptual, novice students often struggle when learning in these environments. AI-driven programming tutors hold great promise in automatically assisting struggling students, and need several components to realize this potential. We investigate the crucial component of student modeling, in particular, the ability to automatically infer students' misconceptions for predicting (synthesizing) their behavior. We introduce a novel benchmark, StudentSyn, centered around the following challenge: For a given student, synthesize the student's attempt on a new target task after observing the student's attempt on a fixed reference task. This challenge is akin to that of program synthesis; however, instead of synthesizing a {solution} (i.e., program an expert would write), the goal here is to synthesize a {student attempt} (i.e., program t
    
[^84]: IOP-FL: Inside-Outside Personalization for Federated Medical Image Segmentation（联邦医学图像分割的内外个性化方法）

    IOP-FL: Inside-Outside Personalization for Federated Medical Image Segmentation. (arXiv:2204.08467v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2204.08467](http://arxiv.org/abs/2204.08467)

    该论文提出了IOP-FL，一种联邦学习的内外个性化方法，以增强医学成像任务中单个客户的预测准确性。

    

    联邦学习（FL）允许多个医疗机构在未集中客户数据的情况下协同学习全局模型。由于来自各种扫描仪和患者人口统计学的医学图像的异质性，这种全局模型普遍实现每个客户的最佳性能是困难的，如果可能的话。当将全局模型部署到在FL期间未呈现的分布上看不见的客户时，这个问题变得更为重要。为了优化每个客户在医学成像任务中的预测准确性，我们提出了一个新的统一框架，用于FL中的“内部和外部模型个性化”（IOP-FL）。我们的内部个性化使用一种轻量级的基于梯度的方法，通过累积通用知识的全局梯度和客户特定优化的本地梯度，利用每个客户的本地适应模型。此外，我们还提出了一个外部个性化解决方案，通过一个客户自适应机制来应对来自未知客户的图像。实验结果表明，我们的方法可以大大提高单个客户的预测准确性，并且可以同时保持在不同客户之间的通用性。

    Federated learning (FL) allows multiple medical institutions to collaboratively learn a global model without centralizing client data. It is difficult, if possible at all, for such a global model to commonly achieve optimal performance for each individual client, due to the heterogeneity of medical images from various scanners and patient demographics. This problem becomes even more significant when deploying the global model to unseen clients outside the FL with unseen distributions not presented during federated training. To optimize the prediction accuracy of each individual client for medical imaging tasks, we propose a novel unified framework for both \textit{Inside and Outside model Personalization in FL} (IOP-FL). Our inside personalization uses a lightweight gradient-based approach that exploits the local adapted model for each client, by accumulating both the global gradients for common knowledge and the local gradients for client-specific optimization. Moreover, and important
    
[^85]: 新冠肺炎中的人工智能应用

    The Prominence of Artificial Intelligence in COVID-19. (arXiv:2111.09537v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2111.09537](http://arxiv.org/abs/2111.09537)

    本论文研究人工智能在 COVID-19 中的应用，探讨了提出的方法，可帮助早期和廉价地诊断该病，有助于医生和研究人员对抗该病。

    

    2019年12月，一种新型病毒，COVID-19已经导致了极多的死亡。与西班牙流感1918年相比，与这种新冠病毒的斗争令人困惑和恐惧。而在前线医生和医学研究人员在控制这种高度传染病毒的传播方面取得了重要进展的同时，技术在这场战斗中也证明了其重要性。此外，人工智能在许多医疗应用中得到了采用，可以诊断许多疾病，甚至使经验丰富的医生感到困惑。因此，本调查论文探讨了提出的方法，可帮助医生和研究人员早期和廉价地诊断该病。大多数发展中国家难以使用传统方式进行测试，但可以采用机器学习和深度学习的方法。另一方面，获得不同类型的医学图像也激发了研究人员的动力。因此，大量的技术创新被引入并应用于实践中。

    In December 2019, a novel virus called COVID-19 had caused an enormous number of causalities to date. The battle with the novel Coronavirus is baffling and horrifying after the Spanish Flu 2019. While the front-line doctors and medical researchers have made significant progress in controlling the spread of the highly contiguous virus, technology has also proved its significance in the battle. Moreover, Artificial Intelligence has been adopted in many medical applications to diagnose many diseases, even baffling experienced doctors. Therefore, this survey paper explores the methodologies proposed that can aid doctors and researchers in early and inexpensive methods of diagnosis of the disease. Most developing countries have difficulties carrying out tests using the conventional manner, but a significant way can be adopted with Machine and Deep Learning. On the other hand, the access to different types of medical images has motivated the researchers. As a result, a mammoth number of tech
    
[^86]: HARPS：面向人机协作的在线 POMDP 框架，用于机器人规划和感知

    HARPS: An Online POMDP Framework for Human-Assisted Robotic Planning and Sensing. (arXiv:2110.10324v4 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2110.10324](http://arxiv.org/abs/2110.10324)

    本文介绍了HARPS框架，该框架通过在线采样型POMDP策略、多模态语义交互和贝叶斯数据融合，实现了面向人-机器人团队的活动语义感知和规划，使机器人可以主动获取人类提供的语义数据。

    

    自主机器人可以从人类提供的不确定任务环境和状态的语义描述中获得巨大的好处。然而，让机器人对这种“软数据”建模、通信和采取行动的综合策略仍具有挑战性。本文介绍了面向人-机器人团队的活动语义感知和规划的HARPS框架，以通过形式化结合在线采样型 POMDP 策略、多模态语义交互和贝叶斯数据融合来解决这些差距。该方法允许人类通过在环境中勾画和标记任意地标，机会地施加模型结构并扩展不确定环境中的语义软数据范围。在搜索过程中动态更新环境模型，使机器人代理可以主动询问人类获取新颖和相关的语义数据，从而提高未知环境和状态的信念，以实现更好的在线规划。

    Autonomous robots can benefit greatly from human-provided semantic characterizations of uncertain task environments and states. However, the development of integrated strategies which let robots model, communicate, and act on such 'soft data' remains challenging. Here, the Human Assisted Robotic Planning and Sensing (HARPS) framework is presented for active semantic sensing and planning in human-robot teams to address these gaps by formally combining the benefits of online sampling-based POMDP policies, multimodal semantic interaction, and Bayesian data fusion. This approach lets humans opportunistically impose model structure and extend the range of semantic soft data in uncertain environments by sketching and labeling arbitrary landmarks across the environment. Dynamic updating of the environment model while during search allows robotic agents to actively query humans for novel and relevant semantic data, thereby improving beliefs of unknown environments and states for improved onlin
    
[^87]: 深度学习推理中的计算和能量消耗趋势

    Compute and Energy Consumption Trends in Deep Learning Inference. (arXiv:2109.05472v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2109.05472](http://arxiv.org/abs/2109.05472)

    本篇论文研究了深度学习推理中的计算和能量消耗趋势，重点关注推理成本而非训练成本。结果显示，除了算法创新外，更具体和强大的硬件通常伴随着重要的能量效率优化，导致推理成本的提高呈现柔和的趋势。

    

    一些人认为，深度学习等AI范式的进展与参数数量指数增长有关。有许多研究证实这些趋势，但这是否意味着能量消耗呈指数增长？为了回答这个问题，我们将重点放在推理成本上，而不是训练成本，因为前者占据了大部分的计算工作量，仅因为有乘法因素存在。此外，除了算法创新外，我们还考虑了更具体和强大的硬件（导致更高的FLOPS），这通常伴随着重要的能量效率优化。我们还将焦点从突破性论文的第一次实现转移到了一两年后的技术版本的巩固版本。在这个独特和全面的视角下，我们研究了计算机视觉和自然语言处理领域的相关模型：对于持续提高性能，我们看到一个更柔和的趋势。

    The progress of some AI paradigms such as deep learning is said to be linked to an exponential growth in the number of parameters. There are many studies corroborating these trends, but does this translate into an exponential increase in energy consumption? In order to answer this question we focus on inference costs rather than training costs, as the former account for most of the computing effort, solely because of the multiplicative factors. Also, apart from algorithmic innovations, we account for more specific and powerful hardware (leading to higher FLOPS) that is usually accompanied with important energy efficiency optimisations. We also move the focus from the first implementation of a breakthrough paper towards the consolidated version of the techniques one or two year later. Under this distinctive and comprehensive perspective, we study relevant models in the areas of computer vision and natural language processing: for a sustained increase in performance we see a much softer 
    
[^88]: 系统化的人类学习与推广：通过简要教程和解释性反馈实现

    Systematic human learning and generalization from a brief tutorial with explanatory feedback. (arXiv:2107.06994v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2107.06994](http://arxiv.org/abs/2107.06994)

    本文研究了人类如何通过简要教程和解释性反馈从少量的训练示例中学习抽象推理任务，并能成功地将其推广到训练范围之外的情况。结果表明，实现人类学习机制对于人工智能的发展非常重要。

    

    神经网络长期以来被用来模拟人类智能，捕捉行为和认知的元素及其神经基础。 深度学习的最新进展使得神经网络模型在许多方面达到甚至超过人类的智能水平，然而与人类不同的是，它们快速学习新任务的能力仍然是一个挑战。人们不仅可以在熟悉的领域进行推理，而且还可以快速学习推理新问题和情况，这就引发了一个问题：现代神经网络模型如何捕捉人类智能以及它们的哪些方面与人类不同。在这项工作中，我们通过研究成年人从一个基于数独的抽象推理任务的简要教学中学习的能力、通过解释性反馈纠正错误答案和狭窄范围的训练示例，来探讨这个差距。我们发现，掌握该任务的参与者可以在少数几次试验中实现，并可以推广到训练范围外的谜题。我们的结果突出了在人工智能系统中实现人类学习机制的重要性。

    Neural networks have long been used to model human intelligence, capturing elements of behavior and cognition, and their neural basis. Recent advancements in deep learning have enabled neural network models to reach and even surpass human levels of intelligence in many respects, yet unlike humans, their ability to learn new tasks quickly remains a challenge. People can reason not only in familiar domains, but can also rapidly learn to reason through novel problems and situations, raising the question of how well modern neural network models capture human intelligence and in which ways they diverge. In this work, we explore this gap by investigating human adults' ability to learn an abstract reasoning task based on Sudoku from a brief instructional tutorial with explanatory feedback for incorrect responses using a narrow range of training examples. We find that participants who master the task do so within a small number of trials and generalize well to puzzles outside of the training r
    

