# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Multi-level protein pre-training with Vabs-Net](https://rss.arxiv.org/abs/2402.01481) | 这篇论文介绍了一种使用Vabs-Net进行多级蛋白质预训练的方法。当前大多数基于结构的预训练模型仅关注残基水平，但忽略了侧链原子的重要性。为了解决这个问题，论文提出了一种新的预训练策略，引入了跨度掩码，以在三维蛋白质预训练中同时建模残基和原子水平的信息，并改善了残基表示的表达能力。 |
| [^2] | [Diffusion Meets DAgger: Supercharging Eye-in-hand Imitation Learning](https://arxiv.org/abs/2402.17768) | 提出了一种名为Diffusion Meets DAgger (DMD)的方法，用于eye-in-hand模仿学习，通过扩散模型创建新样本以提高模型的鲁棒性表现，并减少成本。 |
| [^3] | [Opening Cabinets and Drawers in the Real World using a Commodity Mobile Manipulator](https://arxiv.org/abs/2402.17767) | 实现了一个端到端系统，使商品移动操作器成功在以前未见的真实世界环境中打开橱柜和抽屉，感知误差是主要挑战。 |
| [^4] | [Learning to Program Variational Quantum Circuits with Fast Weights](https://arxiv.org/abs/2402.17760) | 本文介绍了量子快速权重编程器（QFWP）作为解决量子循环神经网络（QRNNs）模型训练时间延长问题的解决方案。 |
| [^5] | [Evaluating Very Long-Term Conversational Memory of LLM Agents](https://arxiv.org/abs/2402.17753) | 通过引入机器-人流程，基于LLM代理架构并将其对话基于人物角色和时间事件图进行基础，成功创建了LoCoMo数据集，为非常长期对话的研究填补了空白。 |
| [^6] | [When Your AI Deceives You: Challenges with Partial Observability of Human Evaluators in Reward Learning](https://arxiv.org/abs/2402.17747) | RLHF在考虑部分观察性时可能导致策略欺骗性地夸大性能或过度辩护行为，我们提出了数学条件来解决这些问题，并警告不要盲目应用RLHF在部分可观测情况下。 |
| [^7] | [reBandit: Random Effects based Online RL algorithm for Reducing Cannabis Use](https://arxiv.org/abs/2402.17739) | reBandit是一种在线RL算法，利用随机效应和贝叶斯先验快速高效地学习，在移动健康环境中通过个性化干预来减少新兴成年人的大麻使用 |
| [^8] | [Learning-Based Algorithms for Graph Searching Problems](https://arxiv.org/abs/2402.17736) | 本研究提出了针对未知图的图搜索问题的基于学习的算法，首次在未知加权图上建立了形式保证，并设计算法在预测误差上具有最优或几乎最佳依存关系。 |
| [^9] | [Case-Based or Rule-Based: How Do Transformers Do the Math?](https://arxiv.org/abs/2402.17709) | transformers在数学问题中采用基于案例的推理而非基于规则的推理。 |
| [^10] | [Autonomous Vehicles: Evolution of Artificial Intelligence and Learning Algorithms](https://arxiv.org/abs/2402.17690) | 本文全面探讨了自动驾驶车辆中AI的演进轨迹，从基础原理追溯到最新进展，并阐明了AI在塑造车辆自主决策能力中的基础作用。 |
| [^11] | [QoS prediction in radio vehicular environments via prior user information](https://arxiv.org/abs/2402.17689) | 本文评估了使用先前提取的用户信息对车载无线环境中的QoS进行预测的方法，展示了如何利用ML树集成方法来提高预测性能。 |
| [^12] | [Navigator: A Decentralized Scheduler for Latency-Sensitive ML Workflows](https://arxiv.org/abs/2402.17652) | 提出了一种名为Navigator的新型框架，通过统一GPU内存管理和任务放置功能，以减少作业延迟，同时高效利用资源，比其他最先进的调度器表现出更显著的完成时间缩短。 |
| [^13] | [SongComposer: A Large Language Model for Lyric and Melody Composition in Song Generation](https://arxiv.org/abs/2402.17645) | SongComposer提出了一种用于歌曲生成的大型语言模型，采用符号化的歌曲表示，实现了LLM可以明确创作歌曲的能力。 |
| [^14] | [Are LLMs Capable of Data-based Statistical and Causal Reasoning? Benchmarking Advanced Quantitative Reasoning with Data](https://arxiv.org/abs/2402.17644) | 本研究引入了QRData基准测试，评估了大型语言模型在统计和因果推理方面的能力，结果显示最强模型GPT-4在该测试中准确率为58％，存在改进空间。 |
| [^15] | [Variational Learning is Effective for Large Deep Networks](https://arxiv.org/abs/2402.17641) | 变分学习在大型深度网络中展现出非常好的效果，IVON优化器在训练大型网络时几乎能与Adam相媲美甚至胜过它，且预测不确定性更准确，对模型微调、泛化误差预测和数据敏感性估计均有显著改进。 |
| [^16] | [Learning Topological Representations with Bidirectional Graph Attention Network for Solving Job Shop Scheduling Problem](https://arxiv.org/abs/2402.17606) | 本文提出了拓扑感知的双向图注意力网络（TBGAT），在解决车间作业调度问题中，通过嵌入并发图并利用双向视图嵌入、图注意力聚合等技术，实现了对拓扑结构的更好建模和利用。 |
| [^17] | [DAGnosis: Localized Identification of Data Inconsistencies using Structures](https://arxiv.org/abs/2402.17599) | DAGnosis使用有向无环图(DAGs)来解决数据一致性检测中的两个关键限制，并能够准确定位为何样本会被标记为不一致。 |
| [^18] | [Implicit Regularization via Spectral Neural Networks and Non-linear Matrix Sensing](https://arxiv.org/abs/2402.17595) | 本文在更现实的神经网络背景下探讨了隐式正则化现象，通过研究非线性激活函数的一般类别，严格证明了在矩阵感知问题设置中这些网络的隐式正则化现象，同时提供了严格的速率保证，确保梯度的指数级快速收敛。 |
| [^19] | [Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization](https://arxiv.org/abs/2402.17574) | Agent-Pro提出了一种基于LLM的代理，通过策略级别的反思和优化，可以从互动经验中学习并逐步提升其行为策略。 |
| [^20] | [OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web](https://arxiv.org/abs/2402.17553) | OmniACT是一个针对代理生成可执行程序完成计算机任务能力的数据集和基准，超越了传统Web自动化，涵盖了各种桌面应用。 |
| [^21] | [Emergency Caching: Coded Caching-based Reliable Map Transmission in Emergency Networks](https://arxiv.org/abs/2402.17550) | 提出了一个三层架构的紧急缓存网络，结合了编码缓存技术，通过无人机之间协同上传实现灾难地图的可靠传输，同时引入了深度强化学习算法优化决策。 |
| [^22] | [COCOA: CBT-based Conversational Counseling Agent using Memory Specialized in Cognitive Distortions and Dynamic Prompt](https://arxiv.org/abs/2402.17546) | CoCoA是一款基于认知行为疗法技术的心理辅导代理，通过构建记忆系统管理信息、提取高层见解，引入动态提示灵活运用CBT技术，生成适当回应，并在与Character.ai角色的对话中展示出显著差异。 |
| [^23] | [Nissist: An Incident Mitigation Copilot based on Troubleshooting Guides](https://arxiv.org/abs/2402.17531) | Nissist利用TSGs和事故缓解历史提供主动建议，减少人为干预，以提高企业级云服务的事故管理效率。 |
| [^24] | [Predict the Next Word: <Humans exhibit uncertainty in this task and language models _____>](https://arxiv.org/abs/2402.17527) | 评估语言模型在预测下一个词时，是否能够复现人类在这项任务中展示的语言变化性 |
| [^25] | [QUCE: The Minimisation and Quantification of Path-Based Uncertainty for Generative Counterfactual Explanations](https://arxiv.org/abs/2402.17516) | QUCE方法旨在通过减少路径不确定性来量化和缓解基于路径的不确定性，从而改善对抗性反事实解释的表现。 |
| [^26] | [Rethinking Mutual Information for Language Conditioned Skill Discovery on Imitation Learning](https://arxiv.org/abs/2402.17511) | 通过重新思考互信息在语言条件下的作用，我们提出了一种端到端模仿学习方法LCSD，以无监督的方式最大化语言和技能之间的互信息。 |
| [^27] | [Demonstrating and Reducing Shortcuts in Vision-Language Representation Learning](https://arxiv.org/abs/2402.17510) | 在视觉-语言表示学习中，论文提出了一种训练和评估框架，引入了合成捷径来探究对比训练是否足以学习到包含所有信息的任务最优表示。 |
| [^28] | [Intensive Care as One Big Sequence Modeling Problem](https://arxiv.org/abs/2402.17501) | 将医疗保健视为序列建模问题，通过将患者与医疗提供者之间的交互表示为事件流，实现对未来事件（如诊断和治疗选择）进行预测。 |
| [^29] | [Emotional Voice Messages (EMOVOME) database: emotion recognition in spontaneous voice messages](https://arxiv.org/abs/2402.17496) | 该研究介绍了Emotional Voice Messages (EMOVOME)数据库，其中包含来自100名西班牙说话者的999条自发语音消息，通过专家和非专家的标记实现了在valence和arousal维度上的情感识别，并尝试使用语音和文本转录实现情感识别模型。 |
| [^30] | [The Mechanical Turkness: Tactical Media Art and the Critique of Corporate AI](https://arxiv.org/abs/2402.17490) | 这些艺术实践关注人工智能的经济和社会政治后果，通过揭示AI技术的社会根源和强调人类在其中的角色，挖掘了战术媒体艺术对公司AI政治体制的干扰作用。 |
| [^31] | [Automated Classification of Phonetic Segments in Child Speech Using Raw Ultrasound Imaging](https://arxiv.org/abs/2402.17482) | 通过将超声舌头成像与深度学习模型相结合，提出了一种自动识别幼儿期语音障碍的技术解决方案，旨在提高UTI分析的准确性和效率。 |
| [^32] | [Fraud Detection with Binding Global and Local Relational Interaction](https://arxiv.org/abs/2402.17472) | 这项工作提出了一个名为RAGFormer的新框架，同时将局部和全局特征嵌入目标节点，以改进欺诈检测性能。 |
| [^33] | [Natural Language Processing Methods for Symbolic Music Generation and Information Retrieval: a Survey](https://arxiv.org/abs/2402.17467) | 该调研综述了在符号音乐生成和信息检索研究中应用的自然语言处理方法，重点关注了符号音乐表示的设计和处理。 |
| [^34] | [A Piece of Theatre: Investigating How Teachers Design LLM Chatbots to Assist Adolescent Cyberbullying Education](https://arxiv.org/abs/2402.17456) | 该研究提出了一个无代码聊天机器人设计工具，帮助教师设计定制的对话流程和聊天机器人话语，探讨了教师在设计聊天机器人时的需求，并展示了教师将自己看作是引导学生和聊天机器人行为的剧作家的观点。 |
| [^35] | [Deep Learning Based Named Entity Recognition Models for Recipes](https://arxiv.org/abs/2402.17447) | 该研究基于深度学习，针对食谱文本开发了命名实体识别模型，通过系统的数据处理和分析，构建了用于自动生成新食谱的数据集。 |
| [^36] | [Ansible Lightspeed: A Code Generation Service for IT Automation](https://arxiv.org/abs/2402.17442) | Ansible Lightspeed是一种基于大型语言模型的服务，专注于将自然语言转换为Ansible代码，为IT自动化领域带来了创新。 |
| [^37] | [Exploiting Emotion-Semantic Correlations for Empathetic Response Generation](https://arxiv.org/abs/2402.17437) | 提出了一种利用动态情感-语义相关性来生成共情式对话回复的模型，通过上下文和情感的交互构建动态情感-语义向量，提高了对情感与语义关联性的理解。 |
| [^38] | [The KANDY Benchmark: Incremental Neuro-Symbolic Learning and Reasoning with Kandinsky Patterns](https://arxiv.org/abs/2402.17431) | 本文介绍了KANDY基准框架，通过生成基于坎丁斯基模式的学习和推理任务，提出了持续和半监督学习的新挑战，并着重研究符号组成性。 |
| [^39] | [Reinforced In-Context Black-Box Optimization](https://arxiv.org/abs/2402.17423) | 提出了一种从离线数据中端到端地强化学习黑盒优化算法的方法，通过使用表达能力强的序列模型和后悔-前进令牌来获取任务信息并做出决策。 |
| [^40] | [PANDAS: Prototype-based Novel Class Discovery and Detection](https://arxiv.org/abs/2402.17420) | PANDAS是一种用于新类别发现和检测的方法，通过从无标签数据中发现代表新类别的聚类，并用原型表示类别，实现了在基础类别的基础上检测新发现的类别。 |
| [^41] | [A novel image space formalism of Fourier domain interpolation neural networks for noise propagation analysis](https://arxiv.org/abs/2402.17410) | 提出了一种用于MRI重建的傅里叶域插值神经网络的图像空间形式主义，并分析了在CNN推断过程中噪声传播的估计方法。 |
| [^42] | [A Neural Rewriting System to Solve Algorithmic Problems](https://arxiv.org/abs/2402.17407) | 提出了一种受重写系统启发的神经架构，用于学习算法任务，通过Selector、Solver和Combiner三个专门模块实现算法任务的简化，具有较好的外推能力 |
| [^43] | [LSPT: Long-term Spatial Prompt Tuning for Visual Representation Learning](https://arxiv.org/abs/2402.17406) | LSPT是一种革命性的视觉表示学习方法，通过引入长期门控提示，巧妙地利用长距离先前块作为提示的潜在来源，减轻了遗忘参数的风险。 |
| [^44] | [A Quantum Approach to Synthetic Minority Oversampling Technique (SMOTE)](https://arxiv.org/abs/2402.17398) | 使用量子计算技术提出了Quantum-SMOTE方法，可以解决机器学习数据集中的类别不平衡问题，并引入了旋转角度、少数类百分比和分裂因子等超参数，实现了对合成数据生成过程的更好控制。 |
| [^45] | [Benchmarking GPT-4 on Algorithmic Problems: A Systematic Evaluation of Prompting Strategies](https://arxiv.org/abs/2402.17396) | 对GPT-4在算法问题上进行了系统评估，发现采用先进的提示技术可以提高其准确性。 |
| [^46] | [FairBelief - Assessing Harmful Beliefs in Language Models](https://arxiv.org/abs/2402.17389) | 本文提出了FairBelief，一种用于捕获和评估语言模型中有害信念的分析方法，并通过公平数据集对几种最先进的LM进行评估，发现这些LM可能存在有害信念。 |
| [^47] | [A case study of sending graph neural networks back to the test bench for applications in high-energy particle physics](https://arxiv.org/abs/2402.17386) | 本文进行了一项用典型GNN与深度全连接前馈结构神经网络进行基准测试的案例研究，以在高能粒子物理学领域中探讨它们的应用。 |
| [^48] | [Determinants of LLM-assisted Decision-Making](https://arxiv.org/abs/2402.17385) | 本研究探讨了影响LLM支持决策的决定因素，包括技术方面的透明度和及时工程、心理因素如情绪和决策风格，以及决策特定因素如任务难度和问责制。 |
| [^49] | [Accelerating Diffusion Sampling with Optimized Time Steps](https://arxiv.org/abs/2402.17376) | 提出了一个通用框架用于设计优化问题，旨在通过寻找更合适的时间步长加速扩散采样。 |
| [^50] | [CAPT: Category-level Articulation Estimation from a Single Point Cloud Using Transformer](https://arxiv.org/abs/2402.17360) | 提出了CAPT方法，使用Transformer从单个点云中准确估计各种联动物体的关节参数和状态，引入了运动损失方法和双重投票策略，实验结果表明其优于现有的其他选择 |
| [^51] | [LocalGCL: Local-aware Contrastive Learning for Graphs](https://arxiv.org/abs/2402.17345) | 提出了一种名为LocalGCL的新的自监督学习框架，通过掩码建模补充地捕捉局部图信息，优于传统对比学习方法。 |
| [^52] | [SocialCVAE: Predicting Pedestrian Trajectory via Interaction Conditioned Latents](https://arxiv.org/abs/2402.17339) | SocialCVAE使用CVAE模型来预测行人轨迹，通过探索行为不确定性并学习社交合理的运动随机性来提高模型性能。 |
| [^53] | [BiVRec: Bidirectional View-based Multimodal Sequential Recommendation](https://arxiv.org/abs/2402.17334) | 提出了一个创新框架 BiVRec，在推荐任务中联合训练 ID 和多模态视图，双向增强推荐性能。 |
| [^54] | [Probing Multimodal Large Language Models for Global and Local Semantic Representation](https://arxiv.org/abs/2402.17304) | 通过研究发现，多模态大型语言模型的中间层能够更好地编码全局语义信息，在视觉-语言任务中表现出更好的性能。顶层可能过多关注局部信息，导致理解全局信息的能力下降。 |
| [^55] | [Active propulsion noise shaping for multi-rotor aircraft localization](https://arxiv.org/abs/2402.17289) | 本文提出通过主动控制和塑造旋翼产生的飞行器推进噪声来有利于定位任务，提出了一种基于自噪声和时间变化旋翼相位调制的神经网络架构，实现了准确和稳健的定位。 |
| [^56] | [Enhancing Hyperspectral Images via Diffusion Model and Group-Autoencoder Super-resolution Network](https://arxiv.org/abs/2402.17285) | 该论文提出了一种新颖的Group-Autoencoder框架，与扩散模型协同组合，构建了一个高效的HSI超分辨模型（DMGASR）。 |
| [^57] | [Multi-Agent, Human-Agent and Beyond: A Survey on Cooperation in Social Dilemmas](https://arxiv.org/abs/2402.17270) | 调查了多智能体、人智能体和人工智能智能体在社会困境合作中的三个关键领域，讨论了合作的动机、策略、人类偏见，以及未来研究方向。 |
| [^58] | [Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue](https://arxiv.org/abs/2402.17262) | 本论文探讨了多轮对话中大型语言模型的安全性漏洞，指出人类可以通过多轮对话诱使其生成有害信息。 |
| [^59] | [RIME: Robust Preference-based Reinforcement Learning with Noisy Preferences](https://arxiv.org/abs/2402.17257) | RIME是一种针对嘈杂偏好的健壮PbRL算法，通过动态过滤去噪偏好和热启动奖励模型，极大增强了现有最先进PbRL方法的鲁棒性。 |
| [^60] | [Deep Learning-Based Speech and Vision Synthesis to Improve Phishing Attack Detection through a Multi-layer Adaptive Framework](https://arxiv.org/abs/2402.17249) | 提出了一个结合深度学习和随机森林的自适应框架，通过在多个预测层中读取图像、合成语音以及进行自然语言处理，显著提高了网络钓鱼攻击检测的性能。 |
| [^61] | [Playground v2.5: Three Insights towards Enhancing Aesthetic Quality in Text-to-Image Generation](https://arxiv.org/abs/2402.17245) | 本论文分享了三个见解，以实现文本到图像生成模型的最新美学质量：增强色彩和对比度，提高跨多个宽高比的生成，改善以人为中心的细节。 |
| [^62] | [Temporal Logic Specification-Conditioned Decision Transformer for Offline Safe Reinforcement Learning](https://arxiv.org/abs/2402.17217) | 提出了时间逻辑规范条件化决策转换器（SDT）框架，结合信号时间逻辑（STL）和决策转换器（DT）的能力，比现有方法在离线安全强化学习中学习出更好的安全高奖励策略。 |
| [^63] | [Application of Machine Learning Optimization in Cloud Computing Resource Scheduling and Management](https://arxiv.org/abs/2402.17216) | 本文提出了一种利用机器学习优化技术解决云计算资源调度与管理中复杂问题的创新方法。 |
| [^64] | [VCD: Knowledge Base Guided Visual Commonsense Discovery in Images](https://arxiv.org/abs/2402.17213) | 该论文提出了基于知识库的图像视觉常识发现（VCD）方法，通过定义细粒度的视觉常识类型以及构建包括超过10万张图像和1400万个对象-常识对的数据集，旨在提升计算机视觉系统的推理和决策能力。 |
| [^65] | [Measuring Vision-Language STEM Skills of Neural Models](https://arxiv.org/abs/2402.17205) | 该研究引入了一个新挑战，用于测试神经模型的STEM技能，提出了一个包含大量基础技能和问题的数据集，需要理解STEM的多模式视觉语言信息，并展示了最新模型对于低年级技能的有限掌握。 |
| [^66] | [AI-Driven Anonymization: Protecting Personal Data Privacy While Leveraging Machine Learning](https://arxiv.org/abs/2402.17191) | 通过机器学习的差分隐私保护算法，实现个人数据隐私保护和检测。 |
| [^67] | [An Effective Mixture-Of-Experts Approach For Code-Switching Speech Recognition Leveraging Encoder Disentanglement](https://arxiv.org/abs/2402.17189) | 通过引入解缠损失并改进声学编码器，本文提出的方法在处理代码切换现象时表现出色，显著优于先前的方法。 |
| [^68] | [Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models](https://arxiv.org/abs/2402.17177) | Sora是一种文本到视频生成的人工智能模型，展示出在模拟物理世界方面的潜力，具有广泛的应用前景和挑战，未来发展具有重要意义。 |
| [^69] | [Benchmarking Data Science Agents](https://arxiv.org/abs/2402.17168) | 本文引入了DSEval评估范式和一系列创新基准，用于评估数据科学代理在整个数据科学生命周期中的性能，通过引入自举注释方法简化数据集准备流程，改进评估覆盖范围，扩展基准测试的全面性，揭示了普遍存在的障碍并提供了关键见解 |
| [^70] | [Large Language Model for Participatory Urban Planning](https://arxiv.org/abs/2402.17161) | 本研究引入了基于大语言模型的多代理协作框架，用于参与式城市规划，可以生成考虑居民多样化需求的城市土地利用规划。 |
| [^71] | [TaxDiff: Taxonomic-Guided Diffusion Model for Protein Sequence Generation](https://arxiv.org/abs/2402.17156) | 提出了一种名为TaxDiff的分类引导扩散模型，结合了生物物种信息和扩散模型的生成能力，用于可控生成结构稳定的蛋白质序列。 |
| [^72] | [Metasql: A Generate-then-Rank Framework for Natural Language to SQL Translation](https://arxiv.org/abs/2402.17144) | Metasql是一种统一的生成-排序框架，利用查询元数据和学习-排序算法不断提高自然语言到SQL翻译的准确性。 |
| [^73] | [Video as the New Language for Real-World Decision Making](https://arxiv.org/abs/2402.17139) | 视频生成在解决真实世界任务中具有巨大潜力，类似于语言模型，它可以作为规划者、代理、计算引擎和环境模拟器。 |
| [^74] | [Unsupervised Zero-Shot Reinforcement Learning via Functional Reward Encodings](https://arxiv.org/abs/2402.17135) | 通过功能奖励编码实现的无监督零样本强化学习方法能够在各种模拟机器人基准测试中训练代理并成功解决新任务，相比以往的零样本强化学习方法表现更优秀。 |
| [^75] | [T-HITL Effectively Addresses Problematic Associations in Image Generation and Maintains Overall Visual Quality](https://arxiv.org/abs/2402.17101) | 本文通过开发一个分类法研究图像生成模型中的问题关联，探讨了在模型级别微调的有效性，并指出了视觉质量降低可能是一个局限性。 |
| [^76] | [Re-Ex: Revising after Explanation Reduces the Factual Errors in LLM Responses](https://arxiv.org/abs/2402.17097) | 提出了一种名为Re-Ex的方法，通过引入事实错误说明步骤来修正LLM生成文本中的事实错误，并提出了新的提示技术来减少所需的标记数量和挂钟时间 |
| [^77] | [A Note on Bayesian Networks with Latent Root Variables](https://arxiv.org/abs/2402.17087) | 从贝叶斯网络计算出的数据集的似然性主要由经验网络的似然性的全局最大值所主导，并且仅当贝叶斯网络的参数与经验模型的参数一致时，这样的最大值才会被实现。 |
| [^78] | [Deconstructing the Veneer of Simplicity: Co-Designing Introductory Generative AI Workshops with Local Entrepreneurs](https://arxiv.org/abs/2402.17082) | 通过与当地企业家合作共同设计交互式研讨会，帮助他们了解生成 AI 平台的重要性，支持可操作使用并揭示创业力量。 |
| [^79] | [One-Shot Graph Representation Learning Using Hyperdimensional Computing](https://arxiv.org/abs/2402.17073) | 该方法提出了一种使用超高维计算进行单次图表示学习的方法，通过将数据投影到高维空间并利用HD运算符进行信息聚合，实现了与最先进深度学习方法相竞争的预测性能，而无需进行计算昂贵的训练。 |
| [^80] | [Taming the Tail in Class-Conditional GANs: Knowledge Sharing via Unconditional Training at Lower Resolutions](https://arxiv.org/abs/2402.17065) | 通过在较低分辨率进行无条件训练，允许长尾类别从信息更丰富的类别中共享知识，以改善长尾数据下类别条件GANs的训练 |
| [^81] | [An Investigation into the Performances of the State-of-the-art Machine Learning Approaches for Various Cyber-attack Detection: A Survey](https://arxiv.org/abs/2402.17045) | 分析了过去10年针对不同类型网络攻击检测的各种最先进机器学习模型，着重比较了最新的工作。 |
| [^82] | [Towards Generalizing Inferences from Trials to Target Populations](https://arxiv.org/abs/2402.17042) | 本研究在试图解决从试验结果推广到目标种群的外部有效性挑战方面取得了重要进展 |
| [^83] | [REFACTOR: Learning to Extract Theorems from Proofs](https://arxiv.org/abs/2402.17032) | 提出了一种名为REFACTOR的新方法，用于训练神经网络从证明中提取定理，新定理的引入帮助缩短证明长度并提高证明效率。 |
| [^84] | [A Curious Case of Remarkable Resilience to Gradient Attacks via Fully Convolutional and Differentiable Front End with a Skip Connection](https://arxiv.org/abs/2402.17018) | 通过在神经模型中引入不同iable和完全卷积的前端模型，并结合跳跃连接，成功实现对梯度攻击的显著韧性，并通过将模型组合成随机集合，有效对抗黑盒攻击。 |
| [^85] | [Multi-Task Contrastive Learning for 8192-Token Bilingual Text Embeddings](https://arxiv.org/abs/2402.17016) | 通过引入独特的多任务学习目标，研究者设计了用于支持英语和其他目标语言的最先进的双语文本嵌入模型，显著提高了模型在STS任务上的表现，同时在目标语言理解和跨语言评估任务中超越了现有多语言模型。 |
| [^86] | [Towards Explainability and Fairness in Swiss Judgement Prediction: Benchmarking on a Multilingual Dataset](https://arxiv.org/abs/2402.17013) | 本研究深入探讨了在瑞士司法预测中实现可解释性和公平性的重要性，利用了唯一可用的多语言LJP数据集，并对最新的单语和多语BERT-based LJP模型进行了可解释性能评估。 |
| [^87] | [Pandora's White-Box: Increased Training Data Leakage in Open LLMs](https://arxiv.org/abs/2402.17012) | 本文对开源大型语言模型（LLMs）进行了隐私攻击研究，提出了首个能同时实现高真正率和低误分类率的预训练LLMs会员推理攻击（MIAs），以及展示了在自然环境中可以从微调LLM中提取超过50%的微调数据集。 |
| [^88] | [Can Large Language Models Recall Reference Location Like Humans?](https://arxiv.org/abs/2402.17010) | 本文探讨了大型语言模型如何利用预训练阶段的知识回忆参考段落，提出了一个两阶段框架模拟人类回忆参考的过程。 |
| [^89] | [Monitoring Fidelity of Online Reinforcement Learning Algorithms in Clinical Trials](https://arxiv.org/abs/2402.17003) | 提出了算法准确性作为在临床试验中部署在线RL算法的关键要求，强调了对参与者保护和数据科学效用的保留责任，并提出了一个框架进行预部署规划和实时监测以确保算法准确性。 |
| [^90] | [What Do Language Models Hear? Probing for Auditory Representations in Language Models](https://arxiv.org/abs/2402.16998) | 通过训练一个线性探针，将语言模型中的文本表示和预训练音频模型中的声音表示联系在一起，研究发现尽管仅在原始文本上进行训练，语言模型对于一些对象的声音知识有着基于实质的编码。 |
| [^91] | [GEM3D: GEnerative Medial Abstractions for 3D Shape Synthesis](https://arxiv.org/abs/2402.16994) | GEM3D提出了一种新的深度、拓扑感知的三维形状生成模型，通过神经骨架编码了拓扑和几何信息，通过骨架驱动的神经隐式公式生成准确和多样化的表面。 |
| [^92] | [Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections](https://arxiv.org/abs/2402.16973) | 通过检测潜在幻觉并建议替代方案的通信机制，成功减少人类导航错误高达29%而不增加认知负担 |
| [^93] | [A Survey of Large Language Models in Cybersecurity](https://arxiv.org/abs/2402.16968) | 大型语言模型在网络安全领域的应用及其局限性的调查和展望。 |
| [^94] | [WIPI: A New Web Threat for LLM-Driven Web Agents](https://arxiv.org/abs/2402.16965) | WIPI是一种新型威胁，可以间接控制Web代理执行恶意指令，从而提高攻击的效率和隐蔽性 |
| [^95] | [FedReview: A Review Mechanism for Rejecting Poisoned Updates in Federated Learning](https://arxiv.org/abs/2402.16934) | 提出了FedReview机制，通过随机分配评审员客户端来识别和拒绝联邦学习中的潜在毒化更新，并采用多数表决机制来整合排名并移除这些更新。 |
| [^96] | [Avoiding Catastrophic Forgetting in Visual Classification Using Human Concept Formation](https://arxiv.org/abs/2402.16933) | 提出了一种名为Cobweb4V的新颖视觉分类方法，利用人类类似学习系统，避免了灾难性遗忘效应，与传统方法相比，需要更少的数据来实现有效学习成果，并保持稳定性能。 |
| [^97] | [LangGPT: Rethinking Structured Reusable Prompt Design Framework for LLMs from the Programming Language](https://arxiv.org/abs/2402.16929) | LangGPT提出了一个双层提示设计框架，作为LLMs的编程语言，大大增强了LLMs产生高质量响应的能力，并在引导LLMs生成高质量提示方面具有显著效果。 |
| [^98] | [CLAP: Learning Transferable Binary Code Representations with Natural Language Supervision](https://arxiv.org/abs/2402.16928) | CLAP通过自然语言监督学习二进制代码的转移表示，提高了在少样本和零样本情景下的迁移性能。 |
| [^99] | [On the (In)feasibility of ML Backdoor Detection as an Hypothesis Testing Problem](https://arxiv.org/abs/2402.16926) | 提出了机器学习系统中后门检测问题的正式统计定义，并得出了后门检测的不可能性与可实现性结果，指出了通用后门检测的局限性，强调后门检测方法需要考虑敌对因素。 |
| [^100] | [Minimize Control Inputs for Strong Structural Controllability Using Reinforcement Learning with Graph Neural Network](https://arxiv.org/abs/2402.16925) | 使用带有图神经网络的强化学习方法，将图着色问题形式化为马尔可夫决策过程，有效解决了强结构可控性条件下最小化控制输入的问题。 |
| [^101] | [Theoretical Unification of the Fractured Aspects of Information](https://arxiv.org/abs/2402.16924) | 该论文旨在消除与信息研究相关的认知障碍，统一各方面的信息理论，摆脱不必要的方法论假设，为发展统一的信息理论提供了可能的应用例子。 |
| [^102] | [More Than Routing: Joint GPS and Route Modeling for Refine Trajectory Representation Learning](https://arxiv.org/abs/2402.16915) | 提出了一种新颖的联合GPS和路由建模的表示学习框架，通过自监督技术实现，利用两个编码器分别捕获路由和GPS轨迹的表示，并通过共享的变压器进行模态间信息交互。 |
| [^103] | [DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLM Jailbreakers](https://arxiv.org/abs/2402.16914) | 将恶意提示分解为独立的子提示使得LLM越狱攻击更难被检测 |
| [^104] | [NeSy is alive and well: A LLM-driven symbolic approach for better code comment data generation and classification](https://arxiv.org/abs/2402.16910) | 结合符号化学习技术和大型语言模型，提出了一种神经符号化工作流用于改进代码注释数据生成和分类，并通过生成受控合成数据修复LLM生成中的弱点，提高了经典机器学习模型在代码注释分类任务上的性能。 |
| [^105] | [LDB: A Large Language Model Debugger via Verifying Runtime Execution Step-by-step](https://arxiv.org/abs/2402.16906) | LDB是一个新颖的调试框架，可以让大型语言模型通过运行时执行信息来完善生成的程序。 |
| [^106] | [Enforcing Temporal Constraints on Generative Agent Behavior with Reactive Synthesis](https://arxiv.org/abs/2402.16905) | 提出了一种利用形式逻辑为基础的程序合成和LLM内容生成相结合的方法，通过使用时间流逻辑（TSL）对生成式代理施加时间约束，从而提高了代理行为的保证水平、系统的解释性和代理的模块化构建能力。 |
| [^107] | [Selective Task offloading for Maximum Inference Accuracy and Energy efficient Real-Time IoT Sensing Systems](https://arxiv.org/abs/2402.16904) | 本论文提出了一个轻量级混合遗传算法（LGSTO），用于解决面向实时物联网传感系统的选择性任务卸载问题，以在时间和能量约束下最大化推理准确性。 |
| [^108] | [FGBERT: Function-Driven Pre-trained Gene Language Model for Metagenomics](https://arxiv.org/abs/2402.16901) | 该论文提出了基于蛋白质的基因表示作为一种上下文感知和结构相关的标记器，通过Masked Gene Modeling（MGM）和Triple Enhanced Metagenomic Contrastive Learning（TEM-CL）进行预训练，构建了一个新颖的宏基因组语言模型FGBERT，能够更好地捕捉基因序列与功能之间的复杂关系。 |
| [^109] | [A prior Estimates for Deep Residual Network in Continuous-time Reinforcement Learning](https://arxiv.org/abs/2402.16899) | 本研究针对连续时间控制问题，提出了一种可以直接分析Bellman最优损失\emph{先验}泛化误差的方法，避免了有界性假设，并通过最大算子的分解方法实现了损失函数的转换。 |
| [^110] | [MIM-Reasoner: Learning with Theoretical Guarantees for Multiplex Influence Maximization](https://arxiv.org/abs/2402.16898) | 引入了MIM-Reasoner，结合强化学习和概率图模型，有效地捕捉了给定多重网络内部和层间的复杂传播过程，从而解决了MIM中最具挑战性的问题。 |
| [^111] | [Reliable Conflictive Multi-View Learning](https://arxiv.org/abs/2402.16897) | 提出了可靠的冲突多视角学习（RCML）问题，开发了一种Evidential Conflictive Multi-view Learning (ECML)方法来处理具有冲突信息的多视角数据。 |
| [^112] | [The Good and The Bad: Exploring Privacy Issues in Retrieval-Augmented Generation (RAG)](https://arxiv.org/abs/2402.16893) | RAG技术有可能改变大型语言模型生成行为，带来新的隐私问题，但同时也可以减少语言模型的训练数据泄漏。 |
| [^113] | [Multi-Task Learning for Routing Problem with Cross-Problem Zero-Shot Generalization](https://arxiv.org/abs/2402.16891) | 本研究首次尝试解决跨问题泛化的关键挑战，通过将VRPs定义为共享基础属性的不同组合，并通过属性组合同时解决它们，实现了零样本泛化的路径问题解决方法。 |
| [^114] | [Generative Models are Self-Watermarked: Declaring Model Authentication through Re-Generation](https://arxiv.org/abs/2402.16889) | 该论文提出了一种通过再生成识别模型数据所有权的方法，避免了传统数字水印技术可能破坏输出质量的问题。 |
| [^115] | [Artificial Intelligence for Complex Network: Potential, Methodology and Application](https://arxiv.org/abs/2402.16887) | 人工智能技术与丰富真实网络数据的存在开启了复杂网络科学研究的新时代，有望克服现存挑战。 |
| [^116] | [Using text embedding models and vector databases as text classifiers with the example of medical data](https://arxiv.org/abs/2402.16886) | 向量数据库和嵌入模型的应用为文本分类器提供了强大的方式来表达数据模式，特别是在医疗领域中开始有着广泛的应用。 |
| [^117] | [Substrate Scope Contrastive Learning: Repurposing Human Bias to Learn Atomic Representations](https://arxiv.org/abs/2402.16882) | 提出了一种新颖的预训练策略，底物范围对比学习，以学习适合化学反应性的原子表示。 |
| [^118] | [BESA: Pruning Large Language Models with Blockwise Parameter-Efficient Sparsity Allocation](https://arxiv.org/abs/2402.16880) | 该论文提出了一种名为BESA的新型大型语言模型修剪技术，通过应用分块重构损失，与传统的逐层修剪技术不同，BESA具有优势 |
| [^119] | [EvoGPT-f: An Evolutionary GPT Framework for Benchmarking Formal Math Languages](https://arxiv.org/abs/2402.16878) | EvoGPT-f是一个新颖的进化框架，用于对五个形式数学语料库进行差异机器可学习性的系统量化分析，为形式数学语言的基准测试提供了新的方法。 |
| [^120] | [Large Language Model Augmented Exercise Retrieval for Personalized Language Learning](https://arxiv.org/abs/2402.16877) | 大型语言模型利用生成能力来合成假设练习，以弥合学习者需求与练习内容之间的语义鸿沟，提高个性化语言学习练习检索效果。 |
| [^121] | [Advanced Academic Team Worker Recommendation Models](https://arxiv.org/abs/2402.16876) | 提出了一种新任务：学术团队成员推荐模型，通过结合查询和论文上下文与图拓扑结构，形成适用于特定研究兴趣和任务的新图（CQBG-R），实验结果表明这种方法的有效性。 |
| [^122] | [Enhancing Retrieval Processes for Language Generation with Augmented Queries](https://arxiv.org/abs/2402.16874) | 本研究通过检索增强生成（RAG）技术解决了语言生成中“幻觉”问题，并借助查询优化过程将用户查询与高级语言模型连接，显著提升了模型性能。 |
| [^123] | [Bike3S: A Tool for Bike Sharing Systems Simulation](https://arxiv.org/abs/2402.16871) | Bike3S是一个针对基于站点的自行车共享系统的模拟器，可以进行半现实的代理基础模拟，帮助评估和测试不同管理决策和策略。 |
| [^124] | [Considering Fundamental Rights in the European Standardisation of Artificial Intelligence: Nonsense or Strategic Alliance?](https://arxiv.org/abs/2402.16869) | 未来欧洲人工智能标准化应考虑基本权利，以缓解某些人工智能系统带来的高风险，反映基本权利考虑，并解决对欧洲标准化过程的批评。 |
| [^125] | [Codebook-enabled Generative End-to-end Semantic Communication Powered by Transformer](https://arxiv.org/abs/2402.16868) | 本文提出了一个强大的码书辅助图像语义通信系统，通过联合构建语义编解码器和码书、设计向量-索引变换器来实现图像生成，并且借助高质量码书帮助Transformer，提高系统对抗信道噪声的鲁棒性。 |
| [^126] | [Computation Rate Maximization for Wireless Powered Edge Computing With Multi-User Cooperation](https://arxiv.org/abs/2402.16866) | 提出一种新颖的多用户协作方案，旨在最大化网络中所有IoT设备的加权总计算速率（WSCR）。 |
| [^127] | [Quantum Inspired Chaotic Salp Swarm Optimization for Dynamic Optimization](https://arxiv.org/abs/2402.16863) | 量子启发的混沌萨尔普群体优化算法用于动态优化问题的改进性能研究 |
| [^128] | [Language Agents as Optimizable Graphs](https://arxiv.org/abs/2402.16823) | 将基于LLM的代理统一描述为计算图，提出新颖的自动图优化器来改进节点和边，实现了代理之间的自动协作和改进。 |
| [^129] | [Nemotron-4 15B Technical Report](https://arxiv.org/abs/2402.16819) | Nemotron-4 15B是一个150亿参数的大型多语言模型，在多语言能力上表现优异，超过其他规模相似的模型。 |
| [^130] | [Interpreting Grokked Transformers in Complex Modular Arithmetic](https://arxiv.org/abs/2402.16726) | 本研究通过可解释的逆向工程在复杂模块化算术中观察了Transformer内部电路学习过程，并发现减法在Transformer上造成了强烈的不对称性，乘法需要余弦偏置分量，多项式叠加了基本算术模式，但在挑战性情况下并不清晰，Grokking甚至可以在具有基本对称和交替表达式的高次公式中轻松发生。 |
| [^131] | [RoboGrind: Intuitive and Interactive Surface Treatment with Industrial Robots](https://arxiv.org/abs/2402.16542) | RoboGrind是一个集成系统，通过3D感知、交互式语音控制向导系统和自动规划执行流水线实现工业机器人对表面处理任务的直观、交互式自动化，为重制玻璃纤维风力涡轮叶片提供了解决方案。 |
| [^132] | [Feedback Efficient Online Fine-Tuning of Diffusion Models](https://arxiv.org/abs/2402.16359) | 提出了一种反馈高效的在线微调扩散模型的强化学习程序 |
| [^133] | [Cross-domain Chinese Sentence Pattern Parsing](https://arxiv.org/abs/2402.16311) | 本文提出了一种利用大型语言模型进行自我训练的创新方法，通过动态生成训练数据将源领域句法规则与目标领域句子相结合，增强句式结构解析器对各种领域的适应能力，实验证明其在教科书和新闻领域的效果优于基于规则的基准模型1.68个百分点。 |
| [^134] | [Citation-Enhanced Generation for LLM-based Chatbot](https://arxiv.org/abs/2402.16063) | 提出一种基于引文增强的LLM聊天机器人生成方法，采用检索模块搜索支持文档来解决幻觉内容产生的问题。 |
| [^135] | [Deep Contrastive Graph Learning with Clustering-Oriented Guidance](https://arxiv.org/abs/2402.16012) | 该论文提出了一种深度对比图学习（DCGL）模型，通过结合自编码器和GCN，在处理一般数据聚类时强调了图结构和原始特征。 |
| [^136] | [CoDream: Exchanging dreams instead of models for federated aggregation with heterogeneous models](https://arxiv.org/abs/2402.15968) | CoDream提出了一种通过在输入数据空间中协作优化数据来交换知识的框架，实现了模型之间的合作学习，实现了模型架构无关、通信不受模型大小影响、兼容安全聚合的优点。 |
| [^137] | [Adversarial Robustness of Deep Learning-based Malware Detectors via (De)Randomized Smoothing](https://arxiv.org/abs/2402.15267) | 通过选择相关的字节子集替代高斯噪声，在训练中进行基于消融的平滑方案，加强了基于深度学习的恶意软件检测器对抗性恶意软件示例的鲁棒性。 |
| [^138] | [GraphEdit: Large Language Models for Graph Structure Learning](https://arxiv.org/abs/2402.15183) | 本研究提出了一种名为GraphEdit的方法，利用大型语言模型（LLMs）学习复杂的图结构化数据中的节点关系，通过在图结构上进行指导调整，增强LLMs的推理能力，从而提高图结构学习的可靠性。 |
| [^139] | [Machine Unlearning of Pre-trained Large Language Models](https://arxiv.org/abs/2402.15159) | 本研究在大型语言模型（LLMs）中探讨了“被遗忘权”的概念，提出机器遗忘作为解决方案，并在预训练模型中建立了全面的遗忘框架及高效的遗忘方法，同时提供了改进超参数鲁棒性以及高效调整超参数的指南。 |
| [^140] | [Semantic Mirror Jailbreak: Genetic Algorithm Based Jailbreak Prompts Against Open-source LLMs](https://arxiv.org/abs/2402.14872) | 本文提出了一种语义镜像越狱（SMJ）方法，通过生成在语义上类似于原始问题的越狱提示来绕过LLMs。 |
| [^141] | [COPR: Continual Human Preference Learning via Optimal Policy Regularization](https://arxiv.org/abs/2402.14228) | 提出了Continual Optimal Policy Regularization (COPR) 方法，通过借鉴最优策略理论，利用采样分布作为示范和正则化约束，以动态地对当前策略进行正则化，从而使强化学习从人类反馈中学习在持续学习情境下更加稳健 |
| [^142] | [Wisdom of Committee: Distilling from Foundation Model to SpecializedApplication Model](https://arxiv.org/abs/2402.14035) | 将基础模型的知识转移到专用应用模型中存在挑战，提出了通过创建教学委员会来应对这些挑战。 |
| [^143] | [ProSparse: Introducing and Enhancing Intrinsic Activation Sparsity within Large Language Models](https://arxiv.org/abs/2402.13516) | 本文介绍了一种名为"ProSparse"的有效稀疏化方法，以推动大型语言模型实现更高的激活稀疏性而不降低模型性能 |
| [^144] | [Federated Causal Discovery from Heterogeneous Data](https://arxiv.org/abs/2402.13241) | 该研究提出了一种新型联邦因果发现方法，旨在适应任意因果模型和异构数据，通过使用替代变量和联邦条件独立性检验来解决数据异质性，并建立了联邦独立变化原则用于确定因果方向。 |
| [^145] | [Confidence Matters: Revisiting Intrinsic Self-Correction Capabilities of Large Language Models](https://arxiv.org/abs/2402.12563) | 本文研究了大型语言模型的内在自我校正能力，并提出了一个“如果-否则”（IoE）提示框架，帮助模型评估自身“信心”并进行自我校正。 |
| [^146] | [Acquiring Clean Language Models from Backdoor Poisoned Datasets by Downscaling Frequency Space](https://arxiv.org/abs/2402.12026) | 通过对频率空间的分析，本文提出了一种多尺度低秩适应（MuScleLoRA）方法，用于解决在训练语言模型时受到后门攻击的问题。 |
| [^147] | [Generative Kaleidoscopic Networks](https://arxiv.org/abs/2402.11793) | 发现深层ReLU网络表现出过度泛化现象，利用这一特性设计了“生成万花筒网络”，通过递归映射随机输入噪声生成样本。 |
| [^148] | [A Systematic Review of Data-to-Text NLG](https://arxiv.org/abs/2402.08496) | 这篇系统性回顾全面分析了数据到文本自然语言生成研究的现状，提出未来方向，并解决了相关挑战。 |
| [^149] | [On Limitations of the Transformer Architecture](https://arxiv.org/abs/2402.08164) | 本论文通过通信复杂性证明了Transformer层在处理函数组合任务时的局限性，指出对于大型定义域和某些数学任务，Transformers可能无法解决。 |
| [^150] | [TriAug: Out-of-Distribution Detection for Robust Classification of Imbalanced Breast Lesion in Ultrasound](https://arxiv.org/abs/2402.07452) | TriAug是一个用于乳腺超声图像的异常样本检测框架，通过使用三元状态增强和平衡的球形损失来提高示踪分类的准确性和异常样本检测性能。 |
| [^151] | [HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal](https://arxiv.org/abs/2402.04249) | HarmBench是一个为自动红队和强大拒绝设计的标准化评估框架，通过对18种红队方法和33个目标LLM和防御的比较，得出了新的见解，并介绍了一种高效的对抗训练方法，提高了LLM在各种攻击下的稳健性。 |
| [^152] | [ANLS* -- A Universal Document Processing Metric for Generative Large Language Models](https://arxiv.org/abs/2402.03848) | ANLS*是一种用于生成型模型的新度量方法，针对各种任务包括信息提取和分类任务进行评估。它扩展了现有的ANLS度量方法，可以作为替代方案使用。 |
| [^153] | [Distinguishing the Knowable from the Unknowable with Language Models](https://arxiv.org/abs/2402.03563) | 通过研究大型语言模型，在自由文本中识别作为代理的模型和冻结预训练模型的嵌入的小型线性探测器可以准确预测更大模型令牌级别上的自信度，进一步提出了一种无监督的方法在相同任务上达到了非平凡的准确度，这证明了语言模型中存在不同类型的不确定性表示。 |
| [^154] | [Generating High-Precision Force Fields for Molecular Dynamics Simulations to Study Chemical Reaction Mechanisms using Molecular Configuration Transformer](https://arxiv.org/abs/2401.00499) | 使用分子配置转换器生成高精度力场，以解决计算速度限制，从而在分子动力学模拟中研究化学反应机理。 |
| [^155] | [KnowGPT: Black-Box Knowledge Injection for Large Language Models](https://arxiv.org/abs/2312.06185) | KnowGPT是一种为大型语言模型提供黑盒知识注入的框架，通过深度强化学习和多臂老虎机构建最适合每个问题的提示，在三个基准数据集上实验证明其显著提升了知识注入的效果。 |
| [^156] | [Neural Speech Embeddings for Speech Synthesis Based on Deep Generative Networks](https://arxiv.org/abs/2312.05814) | 神经语音嵌入在基于深度生成网络的语音合成中起着重要作用，可以直接将脑信号转化为语音，极大地增强了交流的自然性。 |
| [^157] | [Causal Fairness under Unobserved Confounding: A Neural Sensitivity Framework](https://arxiv.org/abs/2311.18460) | 分析了因果公平性对未观察到混杂的敏感性，推导出因果公平性指标的界限，提出神经框架用于学习公平预测，展示了框架的有效性 |
| [^158] | [Reinforcement Learning with Maskable Stock Representation for Portfolio Management in Customizable Stock Pools](https://arxiv.org/abs/2311.10801) | 使用EarnMore方法，我们提出了一种新的RL方法，可以允许RL代理与可定制股票池（CSPs）交互，而不需要重新训练。 |
| [^159] | [Few-shot Transfer Learning for Knowledge Base Question Answering: Fusing Supervised Models with In-Context Learning](https://arxiv.org/abs/2311.08894) | 提出了一种新的KBQA架构FuSIC-KBQA，通过多个源训练的召回器执行KB检索，在LLM的重新排序后以此作为LLM少样本上下文学习的输入来生成逻辑形式，并利用执行引导反馈进一步优化。 |
| [^160] | [Labor Space: A Unifying Representation of the Labor Market via Large Language Models](https://arxiv.org/abs/2311.06310) | "Labor Space"是利用大型语言模型精细调整而成的矢量空间嵌入，揭示了劳动力市场各种组成部分的复杂关系结构，促进了对行业、职业、技能和公司的综合分析。 |
| [^161] | [Kantian Deontology Meets AI Alignment: Towards Morally Grounded Fairness Metrics](https://arxiv.org/abs/2311.05227) | 本文探讨了康德的义务论在公平度量中的应用，主张公平原则应与康德义务论框架相契合，以实现更具道德立足的人工智能和更平衡结果与程序的公平与正义。 |
| [^162] | [Small Language Models Fine-tuned to Coordinate Larger Language Models improve Complex Reasoning](https://arxiv.org/abs/2310.18338) | 细调小型语言模型作为分解生成器，使用策略梯度优化来协调更大型语言模型，进一步提高复杂推理能力 |
| [^163] | [Multimodal Federated Learning in Healthcare: a Review](https://arxiv.org/abs/2310.09650) | 医疗保健领域引入了多模态联邦学习，结合最新的机器学习进展，确保了患者数据隐私和安全，为优化医疗AI系统提供了新的可能性。 |
| [^164] | [Ask Again, Then Fail: Large Language Models' Vacillations in Judgement](https://arxiv.org/abs/2310.02174) | 目前的语言模型在面对后续问题时常常摇摆不定，研究者提出了一个后续问题机制和两个度量标准来量化这种不一致性，并开发出Unwavering-FQ框架来教导模型保持最初的正确判断，实验证明其有效性。 |
| [^165] | [EvalLM: Interactive Evaluation of Large Language Model Prompts on User-Defined Criteria](https://arxiv.org/abs/2309.13633) | EvalLM是一个交互式系统，帮助开发人员通过评估多个输出来改进大型语言模型提示，相比手动评估，能够帮助用户撰写更多样化的标准、检查更多输出，达到更满意的提示。 |
| [^166] | [OCAtari: Object-Centric Atari 2600 Reinforcement Learning Environments](https://arxiv.org/abs/2306.08649) | 以对象为中心的Atari 2600强化学习环境OCAtari扩展了Atari Learning Environments框架，实现了对游戏中基于对象的状态进行资源高效提取，并允许对象发现、对象表征学习以及对象为中心的强化学习。 |
| [^167] | ["According to ...": Prompting Language Models Improves Quoting from Pre-Training Data](https://arxiv.org/abs/2305.13252) | 提出了“根据”提示方法，通过引导大型语言模型在响应中参考先前观察到的文本来改进引用，并提出了一种新的评估指标（QUIP-Score）来度量模型生成的答案在文本语料库中的直接发现程度。 |
| [^168] | [Synthetic Data: Methods, Use Cases, and Risks](https://arxiv.org/abs/2303.01230) | 合成数据作为一种隐私增强技术，通过发布人工生成的数据集来代替敏感真实数据，具有巨大潜力，但仍面临未解决的隐私挑战和局限性。 |
| [^169] | [Dynamic fairness-aware recommendation through multi-agent social choice](https://arxiv.org/abs/2303.00968) | 在个性化推荐领域，提出了一个将推荐公平性表达为分配和聚合问题的新模型，集成了公平关注点和个性化推荐规定，并推导出了新的推荐技术。 |
| [^170] | [PEM: Perception Error Model for Virtual Testing of Autonomous Vehicles](https://arxiv.org/abs/2302.11919) | 提出了感知误差模型（PEM），用于帮助分析感知误差对自动驾驶无人车安全性的影响，无需对传感器本身进行建模，通过数据驱动的过程实现参数化建模，并在开源软件Apollo和公共数据集nuScenes中进行评估，展示了基于PEM的虚拟测试的有效性。 |
| [^171] | [Controller-Guided Partial Label Consistency Regularization with Unlabeled Data](https://arxiv.org/abs/2210.11194) | 本文提出了一种使用控制器引导的部分标签一致性规范方法，通过利用未标记数据来改善部分注释不足的情况。 |
| [^172] | [Goal-Space Planning with Subgoal Models](https://arxiv.org/abs/2206.02902) | 通过在一组（抽象的）子目标上进行约束和学习本地、子目标条件的模型，本文提出的目标空间规划（GSP）方法更具计算效率，自然地结合了时间抽象，避免了学习转换动力学。 |
| [^173] | [Snapture -- A Novel Neural Architecture for Combined Static and Dynamic Hand Gesture Recognition](https://arxiv.org/abs/2205.15862) | 提出了一种新型混合手势识别系统，能够学习静态和动态手势，并通过捕捉手势表现高峰的“快照”来融合静态姿势和动态运动。 |
| [^174] | [Automated Machine Learning: From Principles to Practices](https://arxiv.org/abs/1810.13306) | 自动化机器学习（AutoML）旨在以数据驱动的方式生成令人满意的ML配置，本文提供了对AutoML原理和实践的全面调研。 |
| [^175] | [How Good is ChatGPT at Face Biometrics? A First Look into Recognition, Soft Biometrics, and Explainability.](http://arxiv.org/abs/2401.13641) | 本研究初步探索了基于GPT-4的ChatGPT在面部生物识别中的表现。研究分析了ChatGPT在面部验证、软生物特征估计和结果可解释性方面的能力。ChatGPT的应用有望提高自动决策在人类场景中的解释性和透明度。 |
| [^176] | [Fast Adversarial Training against Textual Adversarial Attacks.](http://arxiv.org/abs/2401.12461) | 本研究提出了一种快速对抗训练（FAT）方法，用于提高自然语言处理模型在无同义词知识的情况下的对抗鲁棒性。该方法通过单步梯度上升在嵌入空间中生成对抗性示例，以加速训练过程。 |
| [^177] | [A Generalized Neural Diffusion Framework on Graphs.](http://arxiv.org/abs/2312.08616) | 本文提出了一个通用的扩散方程框架，通过带有保真度项的方程，正式建立了GNN与扩散过程之间的关系。通过实验证明，该框架能够描述高阶邻居的标签相似性。 |
| [^178] | [Quantum Polar Metric Learning: Efficient Classically Learned Quantum Embeddings.](http://arxiv.org/abs/2312.01655) | 本论文提出了一种称为量子极坐标度量学习(QPMeL)的方法，通过经典模型学习量子比特的极坐标形式的参数，然后使用浅层PQC和可训练的门层来创建量子态和学习纠缠。与QMeL相比，QPMeL具有更高效的计算性能和可扩展性。 |
| [^179] | [Conditional Unscented Autoencoders for Trajectory Prediction.](http://arxiv.org/abs/2310.19944) | 本文提出了使用条件非线性自动编码器(CVAE)进行轨迹预测的方法，通过利用变分自动编码器(VAE)中的非线性采样过程和其他改进，超越了现有技术，为自动驾驶领域的轨迹预测提供了更好的性能。 |
| [^180] | [NECO: NEural Collapse Based Out-of-distribution detection.](http://arxiv.org/abs/2310.06823) | NECO是一种基于神经坍塌的新颖的超出分布检测方法，利用几何属性和主成分空间识别OOD数据，在小规模和大规模任务上取得了最先进的结果，并展示了强大的泛化能力。 |
| [^181] | [Are Large Language Models Post Hoc Explainers?.](http://arxiv.org/abs/2310.05797) | 这项工作提出了第一个研究大型语言模型（LLMs）解释其他预测模型有效性的框架，并且提出了多个提示策略，填补了当前对于LLMs在解释其他模型行为方面的缺失。 |
| [^182] | [A Foundation Model for General Moving Object Segmentation in Medical Images.](http://arxiv.org/abs/2309.17264) | 本文提出了一种用于医学图像中移动目标分割的基础模型iMOS，通过对序列中只有少量图像进行注释，即可实现高精度的分割效果 |
| [^183] | [Can LLMs Effectively Leverage Structural Information for Graph Learning: When and Why.](http://arxiv.org/abs/2309.16595) | 本文研究了大型语言模型（LLM）在图数据中的应用，发现LLM可以从结构信息中受益，尤其是在文本节点特征缺乏的情况下，而LLM的性能与数据泄露没有显著相关。 |
| [^184] | [When do Generative Query and Document Expansions Fail? A Comprehensive Study Across Methods, Retrievers, and Datasets.](http://arxiv.org/abs/2309.08541) | 通过对11种扩展技术、12个不同分布变化的数据集和24个检索模型的全面分析，我们发现使用大型语言模型进行查询或文档扩展的效果与检索器性能相关，对于弱模型来说扩展提高了分数，但对于强模型来说扩展通常会损害分数。 |
| [^185] | [Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers.](http://arxiv.org/abs/2309.08532) | 本文提出了一种通过连接大型语言模型和进化算法进行提示优化的框架，名为EvoPrompt。通过利用大型语言模型的语言处理能力和进化算法的优化性能，EvoPrompt可以自动化处理需要连贯和可读性良好的提示，提高大型语言模型的性能。 |
| [^186] | [FedSoL: Bridging Global Alignment and Local Generality in Federated Learning.](http://arxiv.org/abs/2308.12532) | FedSoL提出了一种联邦学习的方法，该方法旨在解决数据分布不均匀导致性能下降的问题。它通过平衡全局对齐和本地一般性来改善FL的学习效果。 |
| [^187] | [Predicting masked tokens in stochastic locations improves masked image modeling.](http://arxiv.org/abs/2308.00566) | 本论文提出了一种名为FlexPredict的随机模型，通过在模型中加入位置不确定性，以预测掩盖的标记位置，从而改善了掩盖图像建模的性能。 |
| [^188] | [Pretrained deep models outperform GBDTs in Learning-To-Rank under label scarcity.](http://arxiv.org/abs/2308.00177) | 本研究研究了在标签稀缺的Learning-To-Rank问题中，无监督预训练的深度模型是否能胜过GBDTs和其他非预训练模型。实验结果表明，通过使用SimCLR-Rank方法进行无监督预训练，我们的深度学习模型在大量无标签数据和有限标签数据的情况下取得了显著优势。 |
| [^189] | [Towards Accelerating Benders Decomposition via Reinforcement Learning Surrogate Models.](http://arxiv.org/abs/2307.08816) | 本文介绍了一种利用强化学习代理模型加速Benders分解方法的方法，并通过实验证明了其相对于其他加速方案的30%更快的平均收敛速度。 |
| [^190] | [Preference Ranking Optimization for Human Alignment.](http://arxiv.org/abs/2306.17492) | 本文提出了Preference Ranking Optimization (PRO)方法，通过扩展布拉德利-特里比较，采用偏好排序的方式来直接对齐大型语言模型（LLMs），解决了强化学习从人类反馈中学习的复杂性、不稳定性和对超参数的敏感性的问题。 |
| [^191] | [DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models.](http://arxiv.org/abs/2306.11698) | 这项工作提出了对GPT模型进行全面可信度评估，考虑了多个方面的风险，发现了以前未公开的威胁漏洞，例如对毒性输出和个人信息泄漏的易被误导性。 |
| [^192] | [Detecting Heart Disease from Multi-View Ultrasound Images via Supervised Attention Multiple Instance Learning.](http://arxiv.org/abs/2306.00003) | 本研究提出了一种基于监督式注意力多实例学习的方法，可以自动分析超声图像，实现AS的精确筛查且精度优于传统机器学习和深度学习方法。 |
| [^193] | [Dynamic Neighborhood Construction for Structured Large Discrete Action Spaces.](http://arxiv.org/abs/2305.19891) | 本研究针对无法处理的结构化大离散动作空间（SLDAS）提出了一种名为动态邻域构建（DNC）的新型利用策略，通过可扩展的邻域探索启发式方法，高效地探索连续代理动作周围的离散邻域。 |
| [^194] | [Diagnosing Transformers: Illuminating Feature Spaces for Clinical Decision-Making.](http://arxiv.org/abs/2305.17588) | 该论文介绍了一种名为SUFO的框架，用于增强微调的变压器模型的可解释性。该框架利用多种分析和可视化技术，解决了模型信任和可解释性的关键问题，并通过案例研究验证了其有效性。 |
| [^195] | [Rethink Diversity in Deep Learning Testing.](http://arxiv.org/abs/2305.15698) | 本文提出针对深度学习测试的六个具体指标来检测和缓解其漏洞，认为许多DNN测试任务应该是定向测试问题而不是通用测试任务。 |
| [^196] | [Adaptive Chameleon or Stubborn Sloth: Unraveling the Behavior of Large Language Models in Knowledge Clashes.](http://arxiv.org/abs/2305.13300) | 本文研究了大型语言模型（LLMs）在遭遇知识冲突时的行为。结果发现，LLMs可以高度接受外部连贯且有说服力的证据，即使与其参数化内存存在冲突，但也可能有局限性。 |
| [^197] | [Enhancing Logical Reasoning of Large Language Models through Logic-Driven Data Augmentation.](http://arxiv.org/abs/2305.12599) | 本论文介绍了一种通过逻辑驱动的数据增强方法来增强大型语言模型的逻辑推理能力。通过将原始文本转换为抽象意义表述图，并对其进行逻辑修改和转换，生成增强数据，从而提升模型性能。该方法适用于各种体系结构的大型语言模型。 |
| [^198] | [PersonaLLM: Investigating the Ability of GPT-3.5 to Express Personality Traits and Gender Differences.](http://arxiv.org/abs/2305.02547) | 本文探究了基于LLMs模拟代理的行为，称之为LLM Personas，在分配大五人格类型和性别角色时是否可以生成具有一致性的个性化特质的内容。 |
| [^199] | [HeySQuAD: A Spoken Question Answering Dataset.](http://arxiv.org/abs/2304.13689) | HeySQuAD 是一个大规模口语化问答数据集，旨在衡量机器理解并回答嘈杂的口语提问的能力，同时使用转录的人类口语提问进行训练能显著提高模型表现。 |
| [^200] | [Implicit Visual Bias Mitigation by Posterior Estimate Sharpening of a Bayesian Neural Network.](http://arxiv.org/abs/2303.16564) | 该论文提出了一种隐式减轻视觉偏见的方法，使用贝叶斯神经网络，通过后验估计尖锐化，鼓励网络聚焦于不导致高不确定性的中心特征。 |
| [^201] | [Private, fair and accurate: Training large-scale, privacy-preserving AI models in medical imaging.](http://arxiv.org/abs/2302.01622) | 本研究评估了隐私保护训练医学影像人工智能模型的准确性和公平性，并与非隐私训练进行了比较。研究结果可为隐私保护技术的广泛应用提供重要参考。 |

# 详细

[^1]: 用Vabs-Net进行多级蛋白质预训练

    Multi-level protein pre-training with Vabs-Net

    [https://rss.arxiv.org/abs/2402.01481](https://rss.arxiv.org/abs/2402.01481)

    这篇论文介绍了一种使用Vabs-Net进行多级蛋白质预训练的方法。当前大多数基于结构的预训练模型仅关注残基水平，但忽略了侧链原子的重要性。为了解决这个问题，论文提出了一种新的预训练策略，引入了跨度掩码，以在三维蛋白质预训练中同时建模残基和原子水平的信息，并改善了残基表示的表达能力。

    

    最近几年，三维结构预训练蛋白质模型的发展迅猛，相较于预训练蛋白质语言模型，在各种下游任务中取得了重大进展。然而，大多数现有的基于结构的预训练模型主要关注残基水平，即α碳原子，而忽略了其他原子，如侧链原子。我们认为，在残基和原子水平上对蛋白质进行建模很重要，因为侧链原子对于许多下游任务（如分子对接）也是至关重要的。然而，我们发现在预训练中天真地组合残基和原子信息通常会失败。我们发现，信息泄漏是包含原子结构的输入导致残基级预训练任务变得琐碎并导致残基表示不够充分的一个关键原因。为了解决这个问题，我们引入了一种基于跨度掩码预训练策略的三维蛋白质预训练方法。

    In recent years, there has been a surge in the development of 3D structure-based pre-trained protein models, representing a significant advancement over pre-trained protein language models in various downstream tasks. However, most existing structure-based pre-trained models primarily focus on the residue level, i.e., alpha carbon atoms, while ignoring other atoms like side chain atoms. We argue that modeling proteins at both residue and atom levels is important since the side chain atoms can also be crucial for numerous downstream tasks, for example, molecular docking. Nevertheless, we find that naively combining residue and atom information during pre-training typically fails. We identify a key reason is the information leakage caused by the inclusion of atom structure in the input, which renders residue-level pre-training tasks trivial and results in insufficiently expressive residue representations. To address this issue, we introduce a span mask pre-training strategy on 3D protein
    
[^2]: 扩散遇见DAgger: 超级眼在手模仿学习

    Diffusion Meets DAgger: Supercharging Eye-in-hand Imitation Learning

    [https://arxiv.org/abs/2402.17768](https://arxiv.org/abs/2402.17768)

    提出了一种名为Diffusion Meets DAgger (DMD)的方法，用于eye-in-hand模仿学习，通过扩散模型创建新样本以提高模型的鲁棒性表现，并减少成本。

    

    论文介绍了一种新方法Diffusion Meets DAgger (DMD)，用于eye-in-hand模仿学习问题，通过利用扩散模型创建新样本，使得学习策略在遇到未出现在专家演示中的状态时具有鲁棒性表现，减少了数据采集成本。

    arXiv:2402.17768v1 Announce Type: cross  Abstract: A common failure mode for policies trained with imitation is compounding execution errors at test time. When the learned policy encounters states that were not present in the expert demonstrations, the policy fails, leading to degenerate behavior. The Dataset Aggregation, or DAgger approach to this problem simply collects more data to cover these failure states. However, in practice, this is often prohibitively expensive. In this work, we propose Diffusion Meets DAgger (DMD), a method to reap the benefits of DAgger without the cost for eye-in-hand imitation learning problems. Instead of collecting new samples to cover out-of-distribution states, DMD uses recent advances in diffusion models to create these samples with diffusion models. This leads to robust performance from few demonstrations. In experiments conducted for non-prehensile pushing on a Franka Research 3, we show that DMD can achieve a success rate of 80% with as few as 8 e
    
[^3]: 在现实世界中使用商品移动操作器打开橱柜和抽屉

    Opening Cabinets and Drawers in the Real World using a Commodity Mobile Manipulator

    [https://arxiv.org/abs/2402.17767](https://arxiv.org/abs/2402.17767)

    实现了一个端到端系统，使商品移动操作器成功在以前未见的真实世界环境中打开橱柜和抽屉，感知误差是主要挑战。

    

    在这项工作中，我们构建了一个端到端系统，使商品移动操作器（Stretch RE2）能够在多样的以前未见的真实世界环境中拉开橱柜和抽屉。我们在31个不同的物体和13个不同真实世界环境中进行了4天的实际测试。我们的系统在零击打下，对在未知环境中新颖的橱柜和抽屉的打开率达到61%。对失败模式的分析表明，感知误差是我们系统面临的最重要挑战。

    arXiv:2402.17767v1 Announce Type: cross  Abstract: Pulling open cabinets and drawers presents many difficult technical challenges in perception (inferring articulation parameters for objects from onboard sensors), planning (producing motion plans that conform to tight task constraints), and control (making and maintaining contact while applying forces on the environment). In this work, we build an end-to-end system that enables a commodity mobile manipulator (Stretch RE2) to pull open cabinets and drawers in diverse previously unseen real world environments. We conduct 4 days of real world testing of this system spanning 31 different objects from across 13 different real world environments. Our system achieves a success rate of 61% on opening novel cabinets and drawers in unseen environments zero-shot. An analysis of the failure modes suggests that errors in perception are the most significant challenge for our system. We will open source code and models for others to replicate and bui
    
[^4]: 学习使用快速权重编程变分量子电路

    Learning to Program Variational Quantum Circuits with Fast Weights

    [https://arxiv.org/abs/2402.17760](https://arxiv.org/abs/2402.17760)

    本文介绍了量子快速权重编程器（QFWP）作为解决量子循环神经网络（QRNNs）模型训练时间延长问题的解决方案。

    

    Quantum Machine Learning (QML)已经成为一个主要的框架，用于解决顺序控制任务和时间序列建模。 特别是在强化学习（RL）和时间序列预测等领域，已经展示了经验量子优势。 量子循环神经网络（QRNNs）是一个重大进展，专门为存储密集型任务设计，包括部分可观测环境和非线性时间序列预测。 然而，基于QRNN的模型面临挑战，尤其是由于需要使用通过时间反向传播（BPTT）计算量子梯度而产生的训练时间延长的问题。 当在量子设备上执行完整模型时，由于参数移位规则带来的电路评估需求巨大，这个困境进一步加剧。 本文将量子快速权重程序员（QFWP）引入作为解决方案。

    arXiv:2402.17760v1 Announce Type: cross  Abstract: Quantum Machine Learning (QML) has surfaced as a pioneering framework addressing sequential control tasks and time-series modeling. It has demonstrated empirical quantum advantages notably within domains such as Reinforcement Learning (RL) and time-series prediction. A significant advancement lies in Quantum Recurrent Neural Networks (QRNNs), specifically tailored for memory-intensive tasks encompassing partially observable environments and non-linear time-series prediction. Nevertheless, QRNN-based models encounter challenges, notably prolonged training duration stemming from the necessity to compute quantum gradients using backpropagation-through-time (BPTT). This predicament exacerbates when executing the complete model on quantum devices, primarily due to the substantial demand for circuit evaluation arising from the parameter-shift rule. This paper introduces the Quantum Fast Weight Programmers (QFWP) as a solution to the temporal
    
[^5]: 评估LLM代理的非常长期对话记忆

    Evaluating Very Long-Term Conversational Memory of LLM Agents

    [https://arxiv.org/abs/2402.17753](https://arxiv.org/abs/2402.17753)

    通过引入机器-人流程，基于LLM代理架构并将其对话基于人物角色和时间事件图进行基础，成功创建了LoCoMo数据集，为非常长期对话的研究填补了空白。

    

    长期开放领域对话方面的现有研究主要集中在评估模型响应，其上下文跨度不超过五个聊天会话。尽管长上下文大语言模型（LLMs）和检索增强生成（RAG）技术有所进展，但它们在非常长期对话中的有效性尚未被探索。为了解决这一研究空白，我们介绍了一种机器-人的流程，通过利用基于LLM的代理架构生成高质量的非常长期对话，并将其对话基于人物角色和时间事件图进行基础。此外，我们赋予每个代理分享和对图像做出反应的能力。生成的对话经人类注释员验证和编辑，以确保长期一致性和与事件图的基础相联系。使用此流程，我们收集了LoCoMo，一个非常长期对话的数据集，每个数据集包含300轮和平均9K令牌，最多达到35个会话。

    arXiv:2402.17753v1 Announce Type: cross  Abstract: Existing works on long-term open-domain dialogues focus on evaluating model responses within contexts spanning no more than five chat sessions. Despite advancements in long-context large language models (LLMs) and retrieval augmented generation (RAG) techniques, their efficacy in very long-term dialogues remains unexplored. To address this research gap, we introduce a machine-human pipeline to generate high-quality, very long-term dialogues by leveraging LLM-based agent architectures and grounding their dialogues on personas and temporal event graphs. Moreover, we equip each agent with the capability of sharing and reacting to images. The generated conversations are verified and edited by human annotators for long-range consistency and grounding to the event graphs. Using this pipeline, we collect LoCoMo, a dataset of very long-term conversations, each encompassing 300 turns and 9K tokens on avg., over up to 35 sessions. Based on LoCoM
    
[^6]: 当你的AI欺骗你：在奖励学习中人类评估者部分可观测性的挑战

    When Your AI Deceives You: Challenges with Partial Observability of Human Evaluators in Reward Learning

    [https://arxiv.org/abs/2402.17747](https://arxiv.org/abs/2402.17747)

    RLHF在考虑部分观察性时可能导致策略欺骗性地夸大性能或过度辩护行为，我们提出了数学条件来解决这些问题，并警告不要盲目应用RLHF在部分可观测情况下。

    

    强化学习从人类反馈（RLHF）的过去分析假设人类完全观察到环境。当人类反馈仅基于部分观察时会发生什么？我们对两种失败情况进行了正式定义：欺骗和过度辩护。通过将人类建模为对轨迹信念的Boltzmann-理性，我们证明了RLHF保证会导致策略欺骗性地夸大其性能、为了留下印象而过度辩护或者两者兼而有之的条件。为了帮助解决这些问题，我们数学地刻画了环境部分可观测性如何转化为（缺乏）学到的回报函数中的模糊性。在某些情况下，考虑环境部分可观测性使得在理论上可能恢复回报函数和最优策略，而在其他情况下，存在不可减少的模糊性。我们警告不要盲目应用RLHF在部分可观测情况下。

    arXiv:2402.17747v1 Announce Type: cross  Abstract: Past analyses of reinforcement learning from human feedback (RLHF) assume that the human fully observes the environment. What happens when human feedback is based only on partial observations? We formally define two failure cases: deception and overjustification. Modeling the human as Boltzmann-rational w.r.t. a belief over trajectories, we prove conditions under which RLHF is guaranteed to result in policies that deceptively inflate their performance, overjustify their behavior to make an impression, or both. To help address these issues, we mathematically characterize how partial observability of the environment translates into (lack of) ambiguity in the learned return function. In some cases, accounting for partial observability makes it theoretically possible to recover the return function and thus the optimal policy, while in other cases, there is irreducible ambiguity. We caution against blindly applying RLHF in partially observa
    
[^7]: reBandit：基于随机效应的在线RL算法用于减少大麻使用

    reBandit: Random Effects based Online RL algorithm for Reducing Cannabis Use

    [https://arxiv.org/abs/2402.17739](https://arxiv.org/abs/2402.17739)

    reBandit是一种在线RL算法，利用随机效应和贝叶斯先验快速高效地学习，在移动健康环境中通过个性化干预来减少新兴成年人的大麻使用

    

    大麻使用及相关的大麻使用障碍（CUD）的不断增加在全球范围内构成了一个重大的公共卫生挑战。尤其是在新兴成年人（18-25岁）中，存在明显的治疗缺口，因此解决大麻使用和CUD仍然是2030年联合国可持续发展目标（SDG）中的一个关键目标。在这项工作中，我们开发了一种名为reBandit的在线强化学习（RL）算法，将其应用于移动健康研究中，旨在通过提供个性化移动健康干预来减少新兴成年人的大麻使用。reBandit利用随机效应和信息丰富的贝叶斯先验以在嘈杂的移动健康环境中快速而有效地学习。此外，reBandit采用经验贝叶斯和优化技术来在线自主更新其超参数。为了评估我们算法的性能，我们利用数据构建了一个模拟测试平台

    arXiv:2402.17739v1 Announce Type: new  Abstract: The escalating prevalence of cannabis use, and associated cannabis-use disorder (CUD), poses a significant public health challenge globally. With a notably wide treatment gap, especially among emerging adults (EAs; ages 18-25), addressing cannabis use and CUD remains a pivotal objective within the 2030 United Nations Agenda for Sustainable Development Goals (SDG). In this work, we develop an online reinforcement learning (RL) algorithm called reBandit which will be utilized in a mobile health study to deliver personalized mobile health interventions aimed at reducing cannabis use among EAs. reBandit utilizes random effects and informative Bayesian priors to learn quickly and efficiently in noisy mobile health environments. Moreover, reBandit employs Empirical Bayes and optimization techniques to autonomously update its hyper-parameters online. To evaluate the performance of our algorithm, we construct a simulation testbed using data from
    
[^8]: 基于学习的图搜索问题算法

    Learning-Based Algorithms for Graph Searching Problems

    [https://arxiv.org/abs/2402.17736](https://arxiv.org/abs/2402.17736)

    本研究提出了针对未知图的图搜索问题的基于学习的算法，首次在未知加权图上建立了形式保证，并设计算法在预测误差上具有最优或几乎最佳依存关系。

    

    我们考虑了Banerjee等人（2022年）最近提出的具有预测的图搜索问题。在这个问题中，一个从某个顶点$r$出发的代理者必须在最小化总行程的同时遍历一个（潜在未知的）图$G$以找到隐藏的目标节点$g$。我们研究了一种设置，在这种设置中，在任意节点$v$处，代理者会接收到到$g$的距离的噪声估计。我们设计了针对未知图的这种搜索任务的算法。我们在未知加权图上建立了第一次形式保证，并提供了显示我们提出的算法在预测误差上具有最优或几乎最佳依存关系的下界。此外，我们进行了数值实验，证明我们的算法除了对抗性误差具有鲁棒性外，还在误差是随机的典型实例中表现良好。最后，我们提供了对Banerjee等人算法的替代简化性能界限。

    arXiv:2402.17736v1 Announce Type: cross  Abstract: We consider the problem of graph searching with prediction recently introduced by Banerjee et al. (2022). In this problem, an agent, starting at some vertex $r$ has to traverse a (potentially unknown) graph $G$ to find a hidden goal node $g$ while minimizing the total distance travelled. We study a setting in which at any node $v$, the agent receives a noisy estimate of the distance from $v$ to $g$. We design algorithms for this search task on unknown graphs. We establish the first formal guarantees on unknown weighted graphs and provide lower bounds showing that the algorithms we propose have optimal or nearly-optimal dependence on the prediction error. Further, we perform numerical experiments demonstrating that in addition to being robust to adversarial error, our algorithms perform well in typical instances in which the error is stochastic. Finally, we provide alternative simpler performance bounds on the algorithms of Banerjee et 
    
[^9]: 基于案例还是基于规则：变压器如何进行数学计算？

    Case-Based or Rule-Based: How Do Transformers Do the Math?

    [https://arxiv.org/abs/2402.17709](https://arxiv.org/abs/2402.17709)

    transformers在数学问题中采用基于案例的推理而非基于规则的推理。

    

    尽管现代大型语言模型在各种复杂任务中表现出色，但仍然难以处理一些对人类来说简单且直观的数学问题，例如加法。然而，我们可以轻松学习加法的基本规则，并将其应用于任意长度的新问题，而大型语言模型却难以做到。相反，它们可能依赖于在训练语料库中看到的类似“案例”来获取帮助。我们将这两种不同的推理机制定义为“基于规则的推理”和“基于案例的推理”。由于基于规则的推理对于获得系统化概括能力至关重要，我们旨在探究变压器究竟是使用基于规则还是基于案例的推理来解决数学问题。通过精心设计的五个数学任务的干预实验，我们确认变压器正在执行基于案例的推理，无论是否使用草稿本，这与之前的观察结果一致。

    arXiv:2402.17709v1 Announce Type: new  Abstract: Despite the impressive performance in a variety of complex tasks, modern large language models (LLMs) still have trouble dealing with some math problems that are simple and intuitive for humans, such as addition. While we can easily learn basic rules of addition and apply them to new problems of any length, LLMs struggle to do the same. Instead, they may rely on similar "cases" seen in the training corpus for help. We define these two different reasoning mechanisms as "rule-based reasoning" and "case-based reasoning". Since rule-based reasoning is essential for acquiring the systematic generalization ability, we aim to explore exactly whether transformers use rule-based or case-based reasoning for math problems. Through carefully designed intervention experiments on five math tasks, we confirm that transformers are performing case-based reasoning, no matter whether scratchpad is used, which aligns with the previous observations that tran
    
[^10]: 自动驾驶车辆：人工智能和学习算法的演进

    Autonomous Vehicles: Evolution of Artificial Intelligence and Learning Algorithms

    [https://arxiv.org/abs/2402.17690](https://arxiv.org/abs/2402.17690)

    本文全面探讨了自动驾驶车辆中AI的演进轨迹，从基础原理追溯到最新进展，并阐明了AI在塑造车辆自主决策能力中的基础作用。

    

    自动驾驶车辆的出现标志着交通运输领域迎来了一个变革时代，通过尖端技术重塑了移动性的格局。人工智能（AI）和学习算法的整合是这一进化的核心，将车辆推向前所未有的自主领域。本文全面探讨了自动驾驶车辆中AI的演进轨迹，从基础原理追溯到最新进展。从当前景观概述开始，本文深入探讨了AI在塑造车辆自主决策能力中的基础作用。阐明了AI驱动的车辆开发生命周期中涉及的步骤，解决了自动驾驶车辆中AI驱动软件开发中的伦理考虑和偏见问题。该研究提供了关于AI/学习的使用和类型的统计洞见。

    arXiv:2402.17690v1 Announce Type: cross  Abstract: The advent of autonomous vehicles has heralded a transformative era in transportation, reshaping the landscape of mobility through cutting-edge technologies. Central to this evolu- tion is the integration of Artificial Intelligence (AI) and learning algorithms, propelling vehicles into realms of unprecedented autonomy. This paper provides a comprehensive exploration of the evolutionary trajectory of AI within autonomous vehicles, tracing the journey from foundational principles to the most recent advancements. Commencing with a current landscape overview, the paper delves into the fundamental role of AI in shaping the autonomous decision-making capabilities of vehicles. It elucidates the steps involved in the AI-powered development life cycle in vehicles, addressing ethical considerations and bias in AI-driven software development for autonomous vehicles. The study presents statis- tical insights into the usage and types of AI/learning
    
[^11]: 通过先验用户信息在无线车载环境中预测QoS

    QoS prediction in radio vehicular environments via prior user information

    [https://arxiv.org/abs/2402.17689](https://arxiv.org/abs/2402.17689)

    本文评估了使用先前提取的用户信息对车载无线环境中的QoS进行预测的方法，展示了如何利用ML树集成方法来提高预测性能。

    

    可靠的无线通信在汽车行业中扮演着重要角色，它有助于增强当前用例并实现新的用例，如连接的自动驾驶、编队行驶、合作操纵、远程驾驶和智能导航。这些以及其他用例通常依赖于特定的通信服务质量（QoS）水平。最近，预测性服务质量（QoS）领域受到了极大关注，因为它可以提前足够准确地预测通信质量。然而，在可靠地预测QoS方面是一项非常困难的任务。在本文中，我们评估使用从蜂窝测试网络收集的数据来预测QoS的ML树集成方法，范围为几分钟。我们讨论了无线环境特征，并展示了如何利用这些特征来提高ML性能，并进一步支持ML在商业网络中的应用。具体来说，我们使用了

    arXiv:2402.17689v1 Announce Type: cross  Abstract: Reliable wireless communications play an important role in the automotive industry as it helps to enhance current use cases and enable new ones such as connected autonomous driving, platooning, cooperative maneuvering, teleoperated driving, and smart navigation. These and other use cases often rely on specific quality of service (QoS) levels for communication. Recently, the area of predictive quality of service (QoS) has received a great deal of attention as a key enabler to forecast communication quality well enough in advance. However, predicting QoS in a reliable manner is a notoriously difficult task. In this paper, we evaluate ML tree-ensemble methods to predict QoS in the range of minutes with data collected from a cellular test network. We discuss radio environment characteristics and we showcase how these can be used to improve ML performance and further support the uptake of ML in commercial networks. Specifically, we use the 
    
[^12]: 导航器：面向延迟敏感ML工作流的分散式调度器

    Navigator: A Decentralized Scheduler for Latency-Sensitive ML Workflows

    [https://arxiv.org/abs/2402.17652](https://arxiv.org/abs/2402.17652)

    提出了一种名为Navigator的新型框架，通过统一GPU内存管理和任务放置功能，以减少作业延迟，同时高效利用资源，比其他最先进的调度器表现出更显著的完成时间缩短。

    

    我们考虑在分布式系统中进行ML查询处理，其中启用GPU的工作人员协调执行复杂查询：这种计算风格经常出现在与用户互动支持图像处理和自然语言处理的应用程序中。在这种系统中，GPU内存管理和任务放置的协同调度代表着一个有前途的机会。我们提出了Navigator，一个新颖的框架，统一了这些功能，以减少作业延迟，同时高效利用资源，将任务放置在数据依赖关系将得到满足的地方，将来自同一作业的任务放在一起（当这不会使主机或其GPU超载时），并高效地管理GPU内存。与其他最先进的调度器比较显示，在需要相同量甚至更少资源的情况下，完成时间显著减少。在一个案例中，仅需要一半的服务器来处理相同的工作负载。

    arXiv:2402.17652v1 Announce Type: cross  Abstract: We consider ML query processing in distributed systems where GPU-enabled workers coordinate to execute complex queries: a computing style often seen in applications that interact with users in support of image processing and natural language processing. In such systems, coscheduling of GPU memory management and task placement represents a promising opportunity. We propose Navigator, a novel framework that unifies these functions to reduce job latency while using resources efficiently, placing tasks where data dependencies will be satisfied, collocating tasks from the same job (when this will not overload the host or its GPU), and efficiently managing GPU memory. Comparison with other state of the art schedulers shows a significant reduction in completion times while requiring the same amount or even fewer resources. In one case, just half the servers were needed for processing the same workload.
    
[^13]: SongComposer：一种用于歌曲生成的大型语言模型，用于歌词和旋律创作

    SongComposer: A Large Language Model for Lyric and Melody Composition in Song Generation

    [https://arxiv.org/abs/2402.17645](https://arxiv.org/abs/2402.17645)

    SongComposer提出了一种用于歌曲生成的大型语言模型，采用符号化的歌曲表示，实现了LLM可以明确创作歌曲的能力。

    

    我们提出了SongComposer，一个为歌曲创作而设计的创新型LLM。它能够理解和生成歌曲中的旋律和歌词，通过利用LLM的能力在符号化的歌曲表示中生成。现有的与音乐相关的LLM将音乐视为量化的音频信号，而这种隐式编码导致了编码效率低下和灵活性差。相比之下，我们采用了符号化的歌曲表示，这是人类为音乐设计的成熟和高效的方式，并使LLM能够像人类一样明确地创作歌曲。在实践中，我们设计了一种新颖的元组设计，用于格式化歌词和旋律中的三个音符属性（音高、持续时间和休止时间），从而保证LLM对音乐符号的正确理解，并实现歌词和旋律之间的精确对齐。为了向LLM灌输基本的音乐理解，我们精心收集了SongCompose-PT，一个大规模的歌曲预训练数据集，其中包括了歌词、旋律和成对的

    arXiv:2402.17645v1 Announce Type: cross  Abstract: We present SongComposer, an innovative LLM designed for song composition. It could understand and generate melodies and lyrics in symbolic song representations, by leveraging the capability of LLM. Existing music-related LLM treated the music as quantized audio signals, while such implicit encoding leads to inefficient encoding and poor flexibility. In contrast, we resort to symbolic song representation, the mature and efficient way humans designed for music, and enable LLM to explicitly compose songs like humans. In practice, we design a novel tuple design to format lyric and three note attributes (pitch, duration, and rest duration) in the melody, which guarantees the correct LLM understanding of musical symbols and realizes precise alignment between lyrics and melody. To impart basic music understanding to LLM, we carefully collected SongCompose-PT, a large-scale song pretraining dataset that includes lyrics, melodies, and paired ly
    
[^14]: LLMs是否具备基于数据的统计和因果推理能力？用数据对先进的定量推理进行基准测试

    Are LLMs Capable of Data-based Statistical and Causal Reasoning? Benchmarking Advanced Quantitative Reasoning with Data

    [https://arxiv.org/abs/2402.17644](https://arxiv.org/abs/2402.17644)

    本研究引入了QRData基准测试，评估了大型语言模型在统计和因果推理方面的能力，结果显示最强模型GPT-4在该测试中准确率为58％，存在改进空间。

    

    量化推理是分析数据的关键技能，然而对这种能力的评估仍然有限。为了填补这一空白，我们引入了Quantitative Reasoning with Data（QRData）基准测试，旨在评估大型语言模型在统计和因果推理方面与现实世界数据的能力。该基准测试包括一个精心构建的包含来自教科书、在线学习材料和学术论文的数据表的411个问题的数据集。为了比较模型在数据和文本上的定量推理能力，我们还在基准测试中添加了一个包含290个仅文本问题的辅助数据集，即QRText。我们评估了自然语言推理、基于程序推理和代理推理方法，包括Chain-of-Thought、Program-of-Thoughts、ReAct和代码解释器辅助等在各种模型上的表现。最强的模型GPT-4的准确率达到了58％，但仍有很大的改进空间。

    arXiv:2402.17644v1 Announce Type: cross  Abstract: Quantitative reasoning is a critical skill to analyze data, yet the assessment of such ability remains limited. To address this gap, we introduce the Quantitative Reasoning with Data (QRData) benchmark, aiming to evaluate Large Language Models' capability in statistical and causal reasoning with real-world data. The benchmark comprises a carefully constructed dataset of 411 questions accompanied by data sheets from textbooks, online learning materials, and academic papers. To compare models' quantitative reasoning abilities on data and text, we enrich the benchmark with an auxiliary set of 290 text-only questions, namely QRText. We evaluate natural language reasoning, program-based reasoning, and agent reasoning methods including Chain-of-Thought, Program-of-Thoughts, ReAct, and code interpreter assistants on diverse models. The strongest model GPT-4 achieves an accuracy of 58%, which has a large room for improvement. Among open-source
    
[^15]: 变分学习对大型深度网络有效

    Variational Learning is Effective for Large Deep Networks

    [https://arxiv.org/abs/2402.17641](https://arxiv.org/abs/2402.17641)

    变分学习在大型深度网络中展现出非常好的效果，IVON优化器在训练大型网络时几乎能与Adam相媲美甚至胜过它，且预测不确定性更准确，对模型微调、泛化误差预测和数据敏感性估计均有显著改进。

    

    我们提供了大量实证证据，反驳了变分学习对大型神经网络无效的普遍看法。我们展示了一种名为Improved Variational Online Newton (IVON)的优化器，在训练大型网络（如GPT-2和ResNets）时始终能够与Adam相匹配或胜过它。IVON的计算成本几乎与Adam相同，但其预测不确定性更好。我们展示了IVON的几种新用例，其中我们改进了大型语言模型的微调和模型合并，在准确预测泛化误差和忠实估计对数据的敏感性方面。我们找到了大量支持变分学习有效性的证据。

    arXiv:2402.17641v1 Announce Type: cross  Abstract: We give extensive empirical evidence against the common belief that variational learning is ineffective for large neural networks. We show that an optimizer called Improved Variational Online Newton (IVON) consistently matches or outperforms Adam for training large networks such as GPT-2 and ResNets from scratch. IVON's computational costs are nearly identical to Adam but its predictive uncertainty is better. We show several new use cases of IVON where we improve fine-tuning and model merging in Large Language Models, accurately predict generalization error, and faithfully estimate sensitivity to data. We find overwhelming evidence in support of effectiveness of variational learning.
    
[^16]: 使用双向图注意力网络学习拓扑表示解决车间作业调度问题

    Learning Topological Representations with Bidirectional Graph Attention Network for Solving Job Shop Scheduling Problem

    [https://arxiv.org/abs/2402.17606](https://arxiv.org/abs/2402.17606)

    本文提出了拓扑感知的双向图注意力网络（TBGAT），在解决车间作业调度问题中，通过嵌入并发图并利用双向视图嵌入、图注意力聚合等技术，实现了对拓扑结构的更好建模和利用。

    

    现有的基于学习的方法通常使用针对无向图的现成GNN模型解决车间作业调度问题（JSSP），并忽略了并发图（DGs）的丰富而有意义的拓扑结构。本文提出了拓扑感知的双向图注意力网络（TBGAT），这是一种基于注意力机制的新颖GNN架构，用于在本地搜索框架中嵌入DG以解决JSSP。具体而言，TBGAT分别从正向和反向视图嵌入DG，消息通过遵循不同视图的拓扑结构传播，并通过图注意力进行汇总。然后，我们提出一种基于消息传递机制的新操作符，用于计算DG的前向和后向拓扑排序，这些特征用于表征拓扑结构并被我们的模型利用。此外，我们从理论和实验上展示了TBGAT的...

    arXiv:2402.17606v1 Announce Type: cross  Abstract: Existing learning-based methods for solving job shop scheduling problem (JSSP) usually use off-the-shelf GNN models tailored to undirected graphs and neglect the rich and meaningful topological structures of disjunctive graphs (DGs). This paper proposes the topology-aware bidirectional graph attention network (TBGAT), a novel GNN architecture based on the attention mechanism, to embed the DG for solving JSSP in a local search framework. Specifically, TBGAT embeds the DG from a forward and a backward view, respectively, where the messages are propagated by following the different topologies of the views and aggregated via graph attention. Then, we propose a novel operator based on the message-passing mechanism to calculate the forward and backward topological sorts of the DG, which are the features for characterizing the topological structures and exploited by our model. In addition, we theoretically and experimentally show that TBGAT h
    
[^17]: DAGnosis：使用结构进行数据不一致性的局部识别

    DAGnosis: Localized Identification of Data Inconsistencies using Structures

    [https://arxiv.org/abs/2402.17599](https://arxiv.org/abs/2402.17599)

    DAGnosis使用有向无环图(DAGs)来解决数据一致性检测中的两个关键限制，并能够准确定位为何样本会被标记为不一致。

    

    在部署时识别和适当处理数据中的不一致性对可靠地使用机器学习模型至关重要。近期的数据中心方法能够识别与训练集相关的这种不一致性，但存在两个关键限制：（1）在特征展现统计独立性的情况下表现不佳，因为它们使用压缩表示；（2）缺乏局部化，无法准确定位样本为何被标记为不一致，这对指导未来数据收集至关重要。我们使用有向无环图（DAGs）来编码训练集的特征概率分布和独立性作为结构，从而解决了这两个基本限制。我们的方法被称为DAGnosis，利用这些结构交互带来有价值的、深刻的数据中心结论。DAGnosis解锁了在DAG上定位不一致性原因的能力，

    arXiv:2402.17599v1 Announce Type: cross  Abstract: Identification and appropriate handling of inconsistencies in data at deployment time is crucial to reliably use machine learning models. While recent data-centric methods are able to identify such inconsistencies with respect to the training set, they suffer from two key limitations: (1) suboptimality in settings where features exhibit statistical independencies, due to their usage of compressive representations and (2) lack of localization to pin-point why a sample might be flagged as inconsistent, which is important to guide future data collection. We solve these two fundamental limitations using directed acyclic graphs (DAGs) to encode the training set's features probability distribution and independencies as a structure. Our method, called DAGnosis, leverages these structural interactions to bring valuable and insightful data-centric conclusions. DAGnosis unlocks the localization of the causes of inconsistencies on a DAG, an aspec
    
[^18]: 通过谱神经网络和非线性矩阵感知实现隐式正则化

    Implicit Regularization via Spectral Neural Networks and Non-linear Matrix Sensing

    [https://arxiv.org/abs/2402.17595](https://arxiv.org/abs/2402.17595)

    本文在更现实的神经网络背景下探讨了隐式正则化现象，通过研究非线性激活函数的一般类别，严格证明了在矩阵感知问题设置中这些网络的隐式正则化现象，同时提供了严格的速率保证，确保梯度的指数级快速收敛。

    

    隐式正则化现象近年来引起了人们的兴趣，作为神经网络出色泛化能力的一个基本方面。简而言之，它意味着在许多神经网络中，即使损失函数中没有任何显式正则化器，梯度下降动态也会收敛到一个正则化学习问题的解。然而，已知的试图从理论上解释这一现象的结果主要集中在线性神经网络的设置上，线性结构的简单性对现有论据特别关键。本文在更现实的神经网络和一般非线性激活函数的背景下探讨了这一问题，并在矩阵感知问题的设置中严格证明了这些网络的隐式正则化现象，同时提供了严格的速率保证，确保梯度的指数级快速收敛。

    arXiv:2402.17595v1 Announce Type: cross  Abstract: The phenomenon of implicit regularization has attracted interest in recent years as a fundamental aspect of the remarkable generalizing ability of neural networks. In a nutshell, it entails that gradient descent dynamics in many neural nets, even without any explicit regularizer in the loss function, converges to the solution of a regularized learning problem. However, known results attempting to theoretically explain this phenomenon focus overwhelmingly on the setting of linear neural nets, and the simplicity of the linear structure is particularly crucial to existing arguments. In this paper, we explore this problem in the context of more realistic neural networks with a general class of non-linear activation functions, and rigorously demonstrate the implicit regularization phenomenon for such networks in the setting of matrix sensing problems, together with rigorous rate guarantees that ensure exponentially fast convergence of gradi
    
[^19]: Agent-Pro: 通过策略级别反思和优化学习进化

    Agent-Pro: Learning to Evolve via Policy-Level Reflection and Optimization

    [https://arxiv.org/abs/2402.17574](https://arxiv.org/abs/2402.17574)

    Agent-Pro提出了一种基于LLM的代理，通过策略级别的反思和优化，可以从互动经验中学习并逐步提升其行为策略。

    

    大型语言模型表现出在各种任务中具有强大问题解决能力。然而，大多数基于LLM的代理都是特定任务求解器，并具有复杂的提示工程，而不是能够通过互动学习和进化的代理。本文提出了Agent-Pro：一种基于LLM的代理，具有策略级别的反思和优化，可以从互动经验中学习丰富的专业知识，并逐渐提升其行为策略。具体来说，它涉及一个动态信念生成和反思过程，用于策略演化。

    arXiv:2402.17574v1 Announce Type: new  Abstract: Large Language Models exhibit robust problem-solving capabilities for diverse tasks. However, most LLM-based agents are designed as specific task solvers with sophisticated prompt engineering, rather than agents capable of learning and evolving through interactions. These task solvers necessitate manually crafted prompts to inform task rules and regulate LLM behaviors, inherently incapacitating to address complex dynamic scenarios e.g., large interactive games. In light of this, we propose Agent-Pro: an LLM-based Agent with Policy-level Reflection and Optimization that can learn a wealth of expertise from interactive experiences and progressively elevate its behavioral policy. Specifically, it involves a dynamic belief generation and reflection process for policy evolution. Rather than action-level reflection, Agent-Pro iteratively reflects on past trajectories and beliefs, fine-tuning its irrational beliefs for a better policy. Moreover
    
[^20]: OmniACT：用于启用桌面和Web多模式通用主动智能体的数据集和基准

    OmniACT: A Dataset and Benchmark for Enabling Multimodal Generalist Autonomous Agents for Desktop and Web

    [https://arxiv.org/abs/2402.17553](https://arxiv.org/abs/2402.17553)

    OmniACT是一个针对代理生成可执行程序完成计算机任务能力的数据集和基准，超越了传统Web自动化，涵盖了各种桌面应用。

    

    几十年来，人机交互从根本上一直是手动的。即使在今天，几乎所有在计算机上进行的高效工作都需要人类在每一步都提供输入。虚拟主动智能代表了自动化许多这些琐碎任务的一个激动人心的步骤。虚拟代理将使技术能力有限的用户能够充分利用计算机系统的各种可能性。它们还可以实现高效地简化许多计算机任务，从日历管理到复杂的旅行预订，减少人类干预。在这篇论文中，我们介绍了 OmniACT，这是一个用于评估代理生成可执行程序来完成计算机任务能力的首个数据集和基准。我们的范围超越了传统的Web自动化，涵盖了各种桌面应用。该数据集包含诸如"播放下一首歌"之类的基本任务，以及更为长期的任务

    arXiv:2402.17553v1 Announce Type: new  Abstract: For decades, human-computer interaction has fundamentally been manual. Even today, almost all productive work done on the computer necessitates human input at every step. Autonomous virtual agents represent an exciting step in automating many of these menial tasks. Virtual agents would empower users with limited technical proficiency to harness the full possibilities of computer systems. They could also enable the efficient streamlining of numerous computer tasks, ranging from calendar management to complex travel bookings, with minimal human intervention. In this paper, we introduce OmniACT, the first-of-a-kind dataset and benchmark for assessing an agent's capability to generate executable programs to accomplish computer tasks. Our scope extends beyond traditional web automation, covering a diverse range of desktop applications. The dataset consists of fundamental tasks such as "Play the next song", as well as longer horizon tasks such
    
[^21]: 紧急缓存：基于编码缓存的紧急网络可靠地图传输

    Emergency Caching: Coded Caching-based Reliable Map Transmission in Emergency Networks

    [https://arxiv.org/abs/2402.17550](https://arxiv.org/abs/2402.17550)

    提出了一个三层架构的紧急缓存网络，结合了编码缓存技术，通过无人机之间协同上传实现灾难地图的可靠传输，同时引入了深度强化学习算法优化决策。

    

    许多救援任务需要高效的感知和实时决策，这在很大程度上依赖于有效的数据收集和处理。本研究提出了一个侧重于数据收集和可靠传输的紧急缓存网络的三层架构，利用高效感知和边缘缓存技术。基于这个架构，我们提出了一个整合编码缓存技术的灾难地图收集框架。我们的框架在无人机之间策略性地缓存地图的编码片段，促进协同上传以增强传输的可靠性。此外，我们建立了一个全面的概率模型来评估灾难地图的有效恢复区域。为了实现效用最大化的目标，我们提出了一个基于深度强化学习（DRL）的算法，共同决策协作无人机选择、带宽分配等方面。

    arXiv:2402.17550v1 Announce Type: cross  Abstract: Many rescue missions demand effective perception and real-time decision making, which highly rely on effective data collection and processing. In this study, we propose a three-layer architecture of emergency caching networks focusing on data collection and reliable transmission, by leveraging efficient perception and edge caching technologies. Based on this architecture, we propose a disaster map collection framework that integrates coded caching technologies. Our framework strategically caches coded fragments of maps across unmanned aerial vehicles (UAVs), fostering collaborative uploading for augmented transmission reliability. Additionally, we establish a comprehensive probability model to assess the effective recovery area of disaster maps. Towards the goal of utility maximization, we propose a deep reinforcement learning (DRL) based algorithm that jointly makes decisions about cooperative UAVs selection, bandwidth allocation and 
    
[^22]: COCOA: 基于认知失调和动态提示的CBT对话辅导代理

    COCOA: CBT-based Conversational Counseling Agent using Memory Specialized in Cognitive Distortions and Dynamic Prompt

    [https://arxiv.org/abs/2402.17546](https://arxiv.org/abs/2402.17546)

    CoCoA是一款基于认知行为疗法技术的心理辅导代理，通过构建记忆系统管理信息、提取高层见解，引入动态提示灵活运用CBT技术，生成适当回应，并在与Character.ai角色的对话中展示出显著差异。

    

    随着对提供心理健康护理的对话代理的需求持续增加，我们开发了一款心理辅导代理CoCoA，应用认知行为疗法（CBT）技术来识别和解决客户陈述中固有的认知失调问题。具体来说，我们构建了一个记忆系统，以便有效管理辅导所需的信息，并从客户的话语中提取高层次的见解。此外，为了确保辅导代理生成适当的回应，我们引入了动态提示，灵活应用CBT技术，并促进信息的适当检索。我们在CoCoA和Character.ai的角色之间进行了对话，创建了一个用于评估的数据集。然后，我们要求GPT评估构建的辅导数据集，我们的模型表现出与其他方法的统计显著差异。

    arXiv:2402.17546v1 Announce Type: new  Abstract: The demand for conversational agents that provide mental health care is consistently increasing. In this work, we develop a psychological counseling agent, referred to as CoCoA, that applies Cognitive Behavioral Therapy (CBT) techniques to identify and address cognitive distortions inherent in the client's statements. Specifically, we construct a memory system to efficiently manage information necessary for counseling while extracting high-level insights about the client from their utterances. Additionally, to ensure that the counseling agent generates appropriate responses, we introduce dynamic prompting to flexibly apply CBT techniques and facilitate the appropriate retrieval of information. We conducted dialogues between CoCoA and characters from Character.ai, creating a dataset for evaluation. Then, we asked GPT to evaluate the constructed counseling dataset, and our model demonstrated a statistically significant difference from othe
    
[^23]: Nissist：基于故障排除指南的事故缓解副驾驶

    Nissist: An Incident Mitigation Copilot based on Troubleshooting Guides

    [https://arxiv.org/abs/2402.17531](https://arxiv.org/abs/2402.17531)

    Nissist利用TSGs和事故缓解历史提供主动建议，减少人为干预，以提高企业级云服务的事故管理效率。

    

    有效的事故管理对企业级云服务的顺畅运作至关重要。 为了加速事故缓解，服务团队将故障排除知识编译成供值班工程师（OCEs）访问的故障排除指南（TSGs）。 尽管自动化流水线已能够解决最常见和简单的事故，但仍存在需要OCE干预的复杂事故。 然而，TSGs通常是非结构化和不完整的，这需要OCE手动解释，导致值班疲劳和生产力下降，特别是新入职的OCE。 在这项工作中，我们提出了Nissist，它利用TSGs和事故缓解历史提供主动建议，减少人为干预。 利用大型语言模型（LLM），Nissist从非结构化TSGs和历史事故缓解讨论中提取见解，形成全面的知识库。

    arXiv:2402.17531v1 Announce Type: cross  Abstract: Effective incident management is pivotal for the smooth operation of enterprises-level cloud services. In order to expedite incident mitigation, service teams compile troubleshooting knowledge into Troubleshooting Guides (TSGs) accessible to on-call engineers (OCEs). While automated pipelines are enabled to resolve the most frequent and easy incidents, there still exist complex incidents that require OCEs' intervention. However, TSGs are often unstructured and incomplete, which requires manual interpretation by OCEs, leading to on-call fatigue and decreased productivity, especially among new-hire OCEs. In this work, we propose Nissist which leverages TSGs and incident mitigation histories to provide proactive suggestions, reducing human intervention. Leveraging Large Language Models (LLM), Nissist extracts insights from unstructured TSGs and historical incident mitigation discussions, forming a comprehensive knowledge base. Its multi-a
    
[^24]: 预测下一个词：人类在这项任务中表现出不确定性，而语言模型_____

    Predict the Next Word: <Humans exhibit uncertainty in this task and language models _____>

    [https://arxiv.org/abs/2402.17527](https://arxiv.org/abs/2402.17527)

    评估语言模型在预测下一个词时，是否能够复现人类在这项任务中展示的语言变化性

    

    语言模型（LMs）是训练用于为人类生成文本分配概率的统计模型。因此，合理质疑它们是否很好地近似人类展示的语言变化性。这种形式的统计评估在段落级别上很难执行，因为它需要可接受性判断（即，人类评估）或一个强大的自动代理（这是不平凡的）。然而，在单词级别上，通过给定一些上下文，可以通过与一个预先记录的替代单词连续数据集的精确匹配来评估LM的样本。我们利用这一事实，并评估LM重新生成人类（特别是一群英语使用者）在“下一个词预测”任务中展示的变化的能力。这可以被视为一种校准评估，在文本分类的背景下，Baan等人（2022年）将其称为对人类不确定性的校准

    arXiv:2402.17527v1 Announce Type: cross  Abstract: Language models (LMs) are statistical models trained to assign probability to human-generated text. As such, it is reasonable to question whether they approximate linguistic variability exhibited by humans well. This form of statistical assessment is difficult to perform at the passage level, for it requires acceptability judgements (i.e., human evaluation) or a robust automated proxy (which is non-trivial). At the word level, however, given some context, samples from an LM can be assessed via exact matching against a prerecorded dataset of alternative single-word continuations of the available context. We exploit this fact and evaluate the LM's ability to reproduce variability that humans (in particular, a population of English speakers) exhibit in the 'next word prediction' task. This can be seen as assessing a form of calibration, which, in the context of text classification, Baan et al. (2022) termed calibration to human uncertaint
    
[^25]: QUCE: 减少和量化基于路径的不确定性以生成对抗性反事实解释

    QUCE: The Minimisation and Quantification of Path-Based Uncertainty for Generative Counterfactual Explanations

    [https://arxiv.org/abs/2402.17516](https://arxiv.org/abs/2402.17516)

    QUCE方法旨在通过减少路径不确定性来量化和缓解基于路径的不确定性，从而改善对抗性反事实解释的表现。

    

    arXiv:2402.17516v1 公告类型：跨学科 深度神经网络（DNNs）作为机器学习领域最突出的方法之一。DNNs的有效性随着最近计算能力的增加而激增，使得这些方法能够扩展到处理大数据中的重要复杂性以应对预测挑战。然而，随着DNN模型复杂性的提高，可解释性降低。针对这一挑战，诸如对抗梯度整合（AGI）这样的可解释模型利用DNN提供的基于路径的梯度来阐明它们的决策。然而，当梯度在越界路径遍历期间表现出不规则性时，基于路径的解释器的性能可能会受到损害。在这种情况下，我们介绍了Quantified Uncertainty Counterfactual Explanations（QUCE），这是一种旨在减少路径不确定性的方法，以缓解越界遍历。 QUCE不仅在提出解释时量化不确定性

    arXiv:2402.17516v1 Announce Type: cross  Abstract: Deep Neural Networks (DNNs) stand out as one of the most prominent approaches within the Machine Learning (ML) domain. The efficacy of DNNs has surged alongside recent increases in computational capacity, allowing these approaches to scale to significant complexities for addressing predictive challenges in big data. However, as the complexity of DNN models rises, interpretability diminishes. In response to this challenge, explainable models such as Adversarial Gradient Integration (AGI) leverage path-based gradients provided by DNNs to elucidate their decisions. Yet the performance of path-based explainers can be compromised when gradients exhibit irregularities during out-of-distribution path traversal. In this context, we introduce Quantified Uncertainty Counterfactual Explanations (QUCE), a method designed to mitigate out-of-distribution traversal by minimizing path uncertainty. QUCE not only quantifies uncertainty when presenting e
    
[^26]: 重新思考语言条件下的互信息对模仿学习中技能发现的影响

    Rethinking Mutual Information for Language Conditioned Skill Discovery on Imitation Learning

    [https://arxiv.org/abs/2402.17511](https://arxiv.org/abs/2402.17511)

    通过重新思考互信息在语言条件下的作用，我们提出了一种端到端模仿学习方法LCSD，以无监督的方式最大化语言和技能之间的互信息。

    

    arXiv:2402.17511v1 公告类型:跨越 摘要:语言条件下的机器人行为通过将人类命令或指令与感知和动作相关联，在执行复杂任务中起着至关重要的作用。基于不受限制的语言指令构成长视距任务的能力需要获得各种通用技能集。然而，在没有外部奖励或人类监督的耦合和长视距环境中获得固有原始技能存在重大挑战。本文从数学角度评估了技能和语言指令之间的关系，在语言条件策略学习框架内采用了两种形式的互信息。为了以无监督方式最大化语言和技能之间的互信息，我们提出了一种称为语言条件下技能发现（LCSD）的端到端模仿学习方法。具体来说，我们利用矢量量化来

    arXiv:2402.17511v1 Announce Type: cross  Abstract: Language-conditioned robot behavior plays a vital role in executing complex tasks by associating human commands or instructions with perception and actions. The ability to compose long-horizon tasks based on unconstrained language instructions necessitates the acquisition of a diverse set of general-purpose skills. However, acquiring inherent primitive skills in a coupled and long-horizon environment without external rewards or human supervision presents significant challenges. In this paper, we evaluate the relationship between skills and language instructions from a mathematical perspective, employing two forms of mutual information within the framework of language-conditioned policy learning. To maximize the mutual information between language and skills in an unsupervised manner, we propose an end-to-end imitation learning approach known as Language Conditioned Skill Discovery (LCSD). Specifically, we utilize vector quantization to
    
[^27]: 示范和减少视觉语言表示学习中的捷径

    Demonstrating and Reducing Shortcuts in Vision-Language Representation Learning

    [https://arxiv.org/abs/2402.17510](https://arxiv.org/abs/2402.17510)

    在视觉-语言表示学习中，论文提出了一种训练和评估框架，引入了合成捷径来探究对比训练是否足以学习到包含所有信息的任务最优表示。

    

    arXiv:2402.17510v1 公告类型: 跨领域 摘要: 视觉-语言模型(VLMs)主要依赖对比训练来学习图像和标题的通用表示。我们关注的情况是当一个图像与多个标题相关联时，每个标题既包含所有标题共享的信息，又包含关于图像场景的每个标题独特的信息。在这种情况下，尚不清楚对比损失是否足以学习包含标题提供的所有信息的任务最优表示，还是对比学习设置是否鼓励学习最小化对比损失的简单捷径。我们引入了视觉-语言的合成捷径：一种训练和评估框架，在其中我们向图像-文本数据注入合成捷径。我们展示了，从头开始训练或用包含这些合成捷径的数据微调的对比VLMs主要学习代表捷径的特征。

    arXiv:2402.17510v1 Announce Type: cross  Abstract: Vision-language models (VLMs) mainly rely on contrastive training to learn general-purpose representations of images and captions. We focus on the situation when one image is associated with several captions, each caption containing both information shared among all captions and unique information per caption about the scene depicted in the image. In such cases, it is unclear whether contrastive losses are sufficient for learning task-optimal representations that contain all the information provided by the captions or whether the contrastive learning setup encourages the learning of a simple shortcut that minimizes contrastive loss. We introduce synthetic shortcuts for vision-language: a training and evaluation framework where we inject synthetic shortcuts into image-text data. We show that contrastive VLMs trained from scratch or fine-tuned with data containing these synthetic shortcuts mainly learn features that represent the shortcu
    
[^28]: 重症监护作为一个大型序列建模问题

    Intensive Care as One Big Sequence Modeling Problem

    [https://arxiv.org/abs/2402.17501](https://arxiv.org/abs/2402.17501)

    将医疗保健视为序列建模问题，通过将患者与医疗提供者之间的交互表示为事件流，实现对未来事件（如诊断和治疗选择）进行预测。

    

    在医疗保健中，强化学习通常涉及狭窄的自包含任务，如脓毒症预测或麻醉控制。然而，先前的研究表明，通用模型（主要示例为大型语言模型）具有超越特定任务方法的潜力，因为它们具有隐式迁移学习的能力。为了实现保健基础模型的训练以及利用最先进的Transformer架构的能力，我们提出了保健作为序列建模的范式，其中患者和医疗提供者之间的交互被表示为事件流，诊断和治疗选择等任务被建模为对流中未来事件的预测。为了在实验中探索这一范式，我们开发了MIMIC-SEQ，这是一个序列建模基准，通过将来自MIMIC-IV数据集的异构临床记录转换为一种统一...

    arXiv:2402.17501v1 Announce Type: cross  Abstract: Reinforcement Learning in Healthcare is typically concerned with narrow self-contained tasks such as sepsis prediction or anesthesia control. However, previous research has demonstrated the potential of generalist models (the prime example being Large Language Models) to outperform task-specific approaches due to their capability for implicit transfer learning. To enable training of foundation models for Healthcare as well as leverage the capabilities of state of the art Transformer architectures, we propose the paradigm of Healthcare as Sequence Modeling, in which interaction between the patient and the healthcare provider is represented as an event stream and tasks like diagnosis and treatment selection are modeled as prediction of future events in the stream. To explore this paradigm experimentally we develop MIMIC-SEQ, a sequence modeling benchmark derived by translating heterogenous clinical records from MIMIC-IV dataset into a un
    
[^29]: Emotional Voice Messages (EMOVOME)数据库：自发情感语音消息中的情感识别

    Emotional Voice Messages (EMOVOME) database: emotion recognition in spontaneous voice messages

    [https://arxiv.org/abs/2402.17496](https://arxiv.org/abs/2402.17496)

    该研究介绍了Emotional Voice Messages (EMOVOME)数据库，其中包含来自100名西班牙说话者的999条自发语音消息，通过专家和非专家的标记实现了在valence和arousal维度上的情感识别，并尝试使用语音和文本转录实现情感识别模型。

    

    Emotional Voice Messages (EMOVOME)是一个自发语音数据集，包含来自100名西班牙说话者、男女性平衡的999条真实会话中的音频消息，这些消息通过一个消息应用程序产生，在参与者被招募之前在野外环境中制作，避免了由于实验室环境而产生的任何意识偏见。音频按照三个非专家和两个专家的认可在valence和arousal维度上进行了标记，然后将它们结合以获得每个维度的最终标签。专家还提供了对应于七种情感类别的额外标签。为了为将来使用EMOVOME进行调查设定基准，我们使用了语音和音频转录来实现情感识别模型。对于语音部分，我们使用了标准的eGeMAPS特征集和支持向量机，分别获得了49.27%和44.71%的valence和arousal未加权准确度。对于文本部分，我们对一个多语言BERT模型进行了微调，并实现了61%的情感识别准确度。

    arXiv:2402.17496v1 Announce Type: cross  Abstract: Emotional Voice Messages (EMOVOME) is a spontaneous speech dataset containing 999 audio messages from real conversations on a messaging app from 100 Spanish speakers, gender balanced. Voice messages were produced in-the-wild conditions before participants were recruited, avoiding any conscious bias due to laboratory environment. Audios were labeled in valence and arousal dimensions by three non-experts and two experts, which were then combined to obtain a final label per dimension. The experts also provided an extra label corresponding to seven emotion categories. To set a baseline for future investigations using EMOVOME, we implemented emotion recognition models using both speech and audio transcriptions. For speech, we used the standard eGeMAPS feature set and support vector machines, obtaining 49.27% and 44.71% unweighted accuracy for valence and arousal respectively. For text, we fine-tuned a multilingual BERT model and achieved 61
    
[^30]: 机械土耳其人：战术媒体艺术与对公司AI的批判

    The Mechanical Turkness: Tactical Media Art and the Critique of Corporate AI

    [https://arxiv.org/abs/2402.17490](https://arxiv.org/abs/2402.17490)

    这些艺术实践关注人工智能的经济和社会政治后果，通过揭示AI技术的社会根源和强调人类在其中的角色，挖掘了战术媒体艺术对公司AI政治体制的干扰作用。

    

    自2010年代中期以来，人工智能（AI）的广泛工业化越来越激励艺术家们关注其经济和社会政治后果。本章讨论了主题化创造性代理、众包劳动和委托艺术创作的相关艺术实践，揭示了人工智能技术的社会根源，并强调了人类在其发展中的积极作用。我关注的是那些诗意特征表明当代AI影响的科学、技术、经济和社会的广泛问题的作品。通过探讨它们在颠覆公司AI政治体制中的有效性的概念、方法和道德方面，我确定了影响其战术影响力的几个问题，并概述了解决挑战并推进该领域的潜在途径。

    arXiv:2402.17490v1 Announce Type: cross  Abstract: The extensive industrialization of artificial intelligence (AI) since the mid-2010s has increasingly motivated artists to address its economic and sociopolitical consequences. In this chapter, I discuss interrelated art practices that thematize creative agency, crowdsourced labor, and delegated artmaking to reveal the social rootage of AI technologies and underline the productive human roles in their development. I focus on works whose poetic features indicate broader issues of contemporary AI-influenced science, technology, economy, and society. By exploring the conceptual, methodological, and ethical aspects of their effectiveness in disrupting the political regime of corporate AI, I identify several problems that affect their tactical impact and outline potential avenues for tackling the challenges and advancing the field.
    
[^31]: 使用原始超声波成像技术自动分类儿童语音中的音素片段

    Automated Classification of Phonetic Segments in Child Speech Using Raw Ultrasound Imaging

    [https://arxiv.org/abs/2402.17482](https://arxiv.org/abs/2402.17482)

    通过将超声舌头成像与深度学习模型相结合，提出了一种自动识别幼儿期语音障碍的技术解决方案，旨在提高UTI分析的准确性和效率。

    

    语音障碍（SSD）被定义为语音产生的持续障碍，导致语音可理解性降低，阻碍言语交流。本文专注于通过提出一种技术解决方案，将超声舌头成像（UTI）与深度学习模型相结合，推进对幼儿期SSD的自动诊断。引入的FusionNet模型将UTI数据与提取的纹理特征结合起来，用于对UTI进行分类，旨在提高UTI分析的准确性和效率。

    arXiv:2402.17482v1 Announce Type: cross  Abstract: Speech sound disorder (SSD) is defined as a persistent impairment in speech sound production leading to reduced speech intelligibility and hindered verbal communication. Early recognition and intervention of children with SSD and timely referral to speech and language therapists (SLTs) for treatment are crucial. Automated detection of speech impairment is regarded as an efficient method for examining and screening large populations. This study focuses on advancing the automatic diagnosis of SSD in early childhood by proposing a technical solution that integrates ultrasound tongue imaging (UTI) with deep-learning models. The introduced FusionNet model combines UTI data with the extracted texture features to classify UTI. The overarching aim is to elevate the accuracy and efficiency of UTI analysis, particularly for classifying speech sounds associated with SSD. This study compared the FusionNet approach with standard deep-learning metho
    
[^32]: 通过融合全局和局部关系交互进行欺诈检测

    Fraud Detection with Binding Global and Local Relational Interaction

    [https://arxiv.org/abs/2402.17472](https://arxiv.org/abs/2402.17472)

    这项工作提出了一个名为RAGFormer的新框架，同时将局部和全局特征嵌入目标节点，以改进欺诈检测性能。

    

    图神经网络已被证明对于欺诈检测具有有效性，因为它能够在整体视角中编码节点交互和聚合特征。最近，具有出色序列编码能力的Transformer网络在文献中也表现出优于其他基于GNN的方法。然而，基于GNN和基于Transformer的网络只编码整个图的一个视角，而GNN编码全局特征，Transformer网络编码局部特征。此外，先前的工作忽视了使用单独网络编码异构图的全局交互特征，导致性能不佳。在这项工作中，我们提出了一个称为Relation-Aware GNN with transFormer（RAGFormer）的新颖框架，将局部和全局特征同时嵌入目标节点中。这个简单而有效的网络应用了一个修改后的GAGA模块，其中每个Transformer层后面都跟着一个跨关系聚合层。

    arXiv:2402.17472v1 Announce Type: cross  Abstract: Graph Neural Network has been proved to be effective for fraud detection for its capability to encode node interaction and aggregate features in a holistic view. Recently, Transformer network with great sequence encoding ability, has also outperformed other GNN-based methods in literatures. However, both GNN-based and Transformer-based networks only encode one perspective of the whole graph, while GNN encodes global features and Transformer network encodes local ones. Furthermore, previous works ignored encoding global interaction features of the heterogeneous graph with separate networks, thus leading to suboptimal performance. In this work, we present a novel framework called Relation-Aware GNN with transFormer (RAGFormer) which simultaneously embeds local and global features into a target node. The simple yet effective network applies a modified GAGA module where each transformer layer is followed by a cross-relation aggregation lay
    
[^33]: 用于符号音乐生成和信息检索的自然语言处理方法：一项调研

    Natural Language Processing Methods for Symbolic Music Generation and Information Retrieval: a Survey

    [https://arxiv.org/abs/2402.17467](https://arxiv.org/abs/2402.17467)

    该调研综述了在符号音乐生成和信息检索研究中应用的自然语言处理方法，重点关注了符号音乐表示的设计和处理。

    

    自从Transformers模型在自然语言处理（NLP）领域取得突破以来，该模型已在各个领域进行了多种改进。 这一趋势已经传播到音乐信息检索（MIR）领域，包括处理音乐数据的研究。 但是，在MIR中，利用NLP工具处理符号音乐数据的做法并不新颖。 音乐经常被比作语言，因为它们具有多个相似之处，包括文本和音乐的序列化表示。 这些类比还通过MIR和NLP中的类似任务得到体现。 本文综述了应用于符号音乐生成和信息检索研究的NLP方法，遵循两个方面。我们首先概述了从自然语言序列表示中改编而来的符号音乐表示。 通过考虑符号音乐的特定性来设计这些表示。 然后这些表示被模型处理。

    arXiv:2402.17467v1 Announce Type: cross  Abstract: Several adaptations of Transformers models have been developed in various domains since its breakthrough in Natural Language Processing (NLP). This trend has spread into the field of Music Information Retrieval (MIR), including studies processing music data. However, the practice of leveraging NLP tools for symbolic music data is not novel in MIR. Music has been frequently compared to language, as they share several similarities, including sequential representations of text and music. These analogies are also reflected through similar tasks in MIR and NLP. This survey reviews NLP methods applied to symbolic music generation and information retrieval studies following two axes. We first propose an overview of representations of symbolic music adapted from natural language sequential representations. Such representations are designed by considering the specificities of symbolic music. These representations are then processed by models. S
    
[^34]: 一部戏剧：探讨教师如何设计 LLM 聊天机器人以协助青少年防止网络欺凌教育

    A Piece of Theatre: Investigating How Teachers Design LLM Chatbots to Assist Adolescent Cyberbullying Education

    [https://arxiv.org/abs/2402.17456](https://arxiv.org/abs/2402.17456)

    该研究提出了一个无代码聊天机器人设计工具，帮助教师设计定制的对话流程和聊天机器人话语，探讨了教师在设计聊天机器人时的需求，并展示了教师将自己看作是引导学生和聊天机器人行为的剧作家的观点。

    

    研究发现，网络欺凌危害青少年的心理健康，教授他们正确的干预方法至关重要。巫师-奥兹研究表明，聊天机器人可以扩展个性化和互动式的网络欺凌教育，但实施这样的聊天机器人是一项具有挑战性和微妙的任务。我们为 K-12 教师创建了一个无代码聊天机器人设计工具。通过使用大型语言模型和提示链条，我们的工具允许教师原型化定制的对话流程和聊天机器人话语。通过提供这个工具，我们探讨了教师在设计聊天机器人以辅助他们的教学时的独特需求，以及聊天机器人设计工具如何更好地支持他们。我们的研究结果表明，教师热情地接受这个工具。此外，他们将自己视为指导学生和聊天机器人行为的剧作家，同时允许一些即兴演出。他们的目标是使学生能够排练对网络欺凌的理想和不良反应。

    arXiv:2402.17456v1 Announce Type: cross  Abstract: Cyberbullying harms teenagers' mental health, and teaching them upstanding intervention is crucial. Wizard-of-Oz studies show chatbots can scale up personalized and interactive cyberbullying education, but implementing such chatbots is a challenging and delicate task. We created a no-code chatbot design tool for K-12 teachers. Using large language models and prompt chaining, our tool allows teachers to prototype bespoke dialogue flows and chatbot utterances. In offering this tool, we explore teachers' distinctive needs when designing chatbots to assist their teaching, and how chatbot design tools might better support them. Our findings reveal that teachers welcome the tool enthusiastically. Moreover, they see themselves as playwrights guiding both the students' and the chatbot's behaviors, while allowing for some improvisation. Their goal is to enable students to rehearse both desirable and undesirable reactions to cyberbullying in a s
    
[^35]: 食谱的深度学习命名实体识别模型

    Deep Learning Based Named Entity Recognition Models for Recipes

    [https://arxiv.org/abs/2402.17447](https://arxiv.org/abs/2402.17447)

    该研究基于深度学习，针对食谱文本开发了命名实体识别模型，通过系统的数据处理和分析，构建了用于自动生成新食谱的数据集。

    

    食物通过各种努力方式影响着我们的生活，包括口味、营养、健康和可持续性。食谱是通过非结构化文本代代相传的文化胶囊。自动识别命名实体的协议，即食谱文本的基本组成部分，对于各种应用来说都具有巨大价值，从信息提取到新颖食谱生成。命名实体识别是一种从已知标签的非结构化或半结构化数据中提取信息的技术。我们从手动注释的6,611个成分短语的数据开始，累积创建了26,445个短语的增强数据集。同时，我们系统地清理和分析了来自RecipeDB的成分短语，这是黄金标准的食谱数据存储库，并使用Stanford NER进行了标注。基于分析，我们使用基于聚类的方法对88,526个短语的子集进行了取样，同时保留了多样性。

    arXiv:2402.17447v1 Announce Type: cross  Abstract: Food touches our lives through various endeavors, including flavor, nourishment, health, and sustainability. Recipes are cultural capsules transmitted across generations via unstructured text. Automated protocols for recognizing named entities, the building blocks of recipe text, are of immense value for various applications ranging from information extraction to novel recipe generation. Named entity recognition is a technique for extracting information from unstructured or semi-structured data with known labels. Starting with manually-annotated data of 6,611 ingredient phrases, we created an augmented dataset of 26,445 phrases cumulatively. Simultaneously, we systematically cleaned and analyzed ingredient phrases from RecipeDB, the gold-standard recipe data repository, and annotated them using the Stanford NER. Based on the analysis, we sampled a subset of 88,526 phrases using a clustering-based approach while preserving the diversity
    
[^36]: Ansible Lightspeed: 一种用于IT自动化的代码生成服务

    Ansible Lightspeed: A Code Generation Service for IT Automation

    [https://arxiv.org/abs/2402.17442](https://arxiv.org/abs/2402.17442)

    Ansible Lightspeed是一种基于大型语言模型的服务，专注于将自然语言转换为Ansible代码，为IT自动化领域带来了创新。

    

    大型语言模型（LLMs）的问世使得创建可提高开发者生产力的工具成为可能，集成开发环境（IDEs）常被用作与LLMs交互的接口。已发布许多这类工具，但几乎全部都专注于通用编程语言，很少关注对IT自动化至关重要的特定领域语言。Ansible是一种基于YAML的IT自动化特定语言。Red Hat Ansible Lightspeed与IBM Watson Code Assistant合作的Ansible Lightspeed是一种基于LLM的服务，专门用于将自然语言转换为Ansible代码。

    arXiv:2402.17442v1 Announce Type: cross  Abstract: The availability of Large Language Models (LLMs) which can generate code, has made it possible to create tools that improve developer productivity. Integrated development environments or IDEs which developers use to write software are often used as an interface to interact with LLMs. Although many such tools have been released, almost all of them focus on general-purpose programming languages. Domain-specific languages, such as those crucial for IT automation, have not received much attention. Ansible is one such YAML-based IT automation-specific language. Red Hat Ansible Lightspeed with IBM Watson Code Assistant, further referred to as Ansible Lightspeed, is an LLM-based service designed explicitly for natural language to Ansible code generation.   In this paper, we describe the design and implementation of the Ansible Lightspeed service and analyze feedback from thousands of real users. We examine diverse performance indicators, clas
    
[^37]: 利用情感-语义相关性进行共情式回复生成

    Exploiting Emotion-Semantic Correlations for Empathetic Response Generation

    [https://arxiv.org/abs/2402.17437](https://arxiv.org/abs/2402.17437)

    提出了一种利用动态情感-语义相关性来生成共情式对话回复的模型，通过上下文和情感的交互构建动态情感-语义向量，提高了对情感与语义关联性的理解。

    

    共情式回复生成旨在通过理解对话语言中说话者的情感感受来生成共情回复。最近的方法捕捉交际者语言中的情感词，并将其构建为静态向量，以感知微妙的情感。然而，语言研究表明，语言中的情感词是动态的，并与其他语法语义角色（即具有语义含义的词语）相关联。以前的方法忽略了这两个特征，这很容易导致情感误解和关键语义的忽视。为了解决这个问题，我们提出了一种用于共情对话生成任务的动态情感-语义相关性模型（ESCM）。ESCM通过上下文和情感的交互构建动态情感-语义向量。我们引入依存树来反映情感与语义之间的相关性。

    arXiv:2402.17437v1 Announce Type: cross  Abstract: Empathetic response generation aims to generate empathetic responses by understanding the speaker's emotional feelings from the language of dialogue. Recent methods capture emotional words in the language of communicators and construct them as static vectors to perceive nuanced emotions. However, linguistic research has shown that emotional words in language are dynamic and have correlations with other grammar semantic roles, i.e., words with semantic meanings, in grammar. Previous methods overlook these two characteristics, which easily lead to misunderstandings of emotions and neglect of key semantics. To address this issue, we propose a dynamical Emotion-Semantic Correlation Model (ESCM) for empathetic dialogue generation tasks. ESCM constructs dynamic emotion-semantic vectors through the interaction of context and emotions. We introduce dependency trees to reflect the correlations between emotions and semantics. Based on dynamic em
    
[^38]: KANDY基准：使用坎丁斯基模式进行增量神经符号学习和推理

    The KANDY Benchmark: Incremental Neuro-Symbolic Learning and Reasoning with Kandinsky Patterns

    [https://arxiv.org/abs/2402.17431](https://arxiv.org/abs/2402.17431)

    本文介绍了KANDY基准框架，通过生成基于坎丁斯基模式的学习和推理任务，提出了持续和半监督学习的新挑战，并着重研究符号组成性。

    

    arXiv:2402.17431v1 公告类型：新的 摘要：人工智能不断寻求新的挑战和基准，以有效衡量性能并推动最新技术的发展。本文介绍了KANDY，一个可用于生成受坎丁斯基模式启发的各种学习和推理任务的基准框架。通过创建一系列具有递增复杂性和稀疏监督的二元分类任务课程，KANDY可用于实现持续和半监督学习的基准，并专注于符号组成性。基本事实中还提供了分类规则，以便分析可解释的解决方案。除了基准生成管道，我们还发布了两个课程，一个更容易一个更难，我们提议这些作为研究社区的新挑战。通过彻底的实验评估，我们展示了最先进的神经模型和纯符号方法的表现。

    arXiv:2402.17431v1 Announce Type: new  Abstract: Artificial intelligence is continuously seeking novel challenges and benchmarks to effectively measure performance and to advance the state-of-the-art. In this paper we introduce KANDY, a benchmarking framework that can be used to generate a variety of learning and reasoning tasks inspired by Kandinsky patterns. By creating curricula of binary classification tasks with increasing complexity and with sparse supervisions, KANDY can be used to implement benchmarks for continual and semi-supervised learning, with a specific focus on symbol compositionality. Classification rules are also provided in the ground truth to enable analysis of interpretable solutions. Together with the benchmark generation pipeline, we release two curricula, an easier and a harder one, that we propose as new challenges for the research community. With a thorough experimental evaluation, we show how both state-of-the-art neural models and purely symbolic approaches 
    
[^39]: 加强上下文黑盒优化

    Reinforced In-Context Black-Box Optimization

    [https://arxiv.org/abs/2402.17423](https://arxiv.org/abs/2402.17423)

    提出了一种从离线数据中端到端地强化学习黑盒优化算法的方法，通过使用表达能力强的序列模型和后悔-前进令牌来获取任务信息并做出决策。

    

    黑盒优化（BBO）已经在许多科学和工程领域取得成功应用。最近，人们越来越关注元学习BBO算法的特定组件，以加快优化速度并摆脱繁琐的手工启发式算法。作为扩展，从数据中学习整个算法需要专家最少的工作量，并且可以提供最大的灵活性。在本文中，我们提出了一种名为RIBBO的方法，可以以端到端的方式从离线数据中强化学习BBO算法。RIBBO利用表达能力强的序列模型来学习多个行为算法和任务产生的优化历史，利用大型模型的上下文学习能力来提取任务信息并相应地做出决策。我们方法的核心是通过增加后悔-前进令牌来增强优化历史，这些令牌旨在基于累积表现来表示算法的性能。

    arXiv:2402.17423v1 Announce Type: cross  Abstract: Black-Box Optimization (BBO) has found successful applications in many fields of science and engineering. Recently, there has been a growing interest in meta-learning particular components of BBO algorithms to speed up optimization and get rid of tedious hand-crafted heuristics. As an extension, learning the entire algorithm from data requires the least labor from experts and can provide the most flexibility. In this paper, we propose RIBBO, a method to reinforce-learn a BBO algorithm from offline data in an end-to-end fashion. RIBBO employs expressive sequence models to learn the optimization histories produced by multiple behavior algorithms and tasks, leveraging the in-context learning ability of large models to extract task information and make decisions accordingly. Central to our method is to augment the optimization histories with regret-to-go tokens, which are designed to represent the performance of an algorithm based on cumul
    
[^40]: PANDAS: 基于原型的新类别发现与检测

    PANDAS: Prototype-based Novel Class Discovery and Detection

    [https://arxiv.org/abs/2402.17420](https://arxiv.org/abs/2402.17420)

    PANDAS是一种用于新类别发现和检测的方法，通过从无标签数据中发现代表新类别的聚类，并用原型表示类别，实现了在基础类别的基础上检测新发现的类别。

    

    目标检测器通常在固定的一组类别上进行一次训练。然而，这种封闭世界的假设在实践中是不现实的，因为在检测器部署在野外后，新的类别必然会出现。在这项工作中，我们研究了扩展训练为一组基础类别的检测器的方法，使其能够 i) 发现新类别的存在，并 ii) 自动丰富其库以能够检测这些新发现的类别以及基础类别。我们提出了 PANDAS，一种用于新类别发现和检测的方法。它从无标签数据中发现代表新类别的聚类，并用原型来表示旧类别和新类别。在推断过程中，基于距离的分类器使用这些原型为每个检测到的对象实例分配标签。我们的方法的简单性使其具有广泛的适用性。我们在VOC 2012和COCO-to-LVIS数据集上通过实验展示了PANDAS的有效性。

    arXiv:2402.17420v1 Announce Type: cross  Abstract: Object detectors are typically trained once and for all on a fixed set of classes. However, this closed-world assumption is unrealistic in practice, as new classes will inevitably emerge after the detector is deployed in the wild. In this work, we look at ways to extend a detector trained for a set of base classes so it can i) spot the presence of novel classes, and ii) automatically enrich its repertoire to be able to detect those newly discovered classes together with the base ones. We propose PANDAS, a method for novel class discovery and detection. It discovers clusters representing novel classes from unlabeled data, and represents old and new classes with prototypes. During inference, a distance-based classifier uses these prototypes to assign a label to each detected object instance. The simplicity of our method makes it widely applicable. We experimentally demonstrate the effectiveness of PANDAS on the VOC 2012 and COCO-to-LVIS 
    
[^41]: 傅里叶域插值神经网络的图像空间形式主义用于噪声传播分析

    A novel image space formalism of Fourier domain interpolation neural networks for noise propagation analysis

    [https://arxiv.org/abs/2402.17410](https://arxiv.org/abs/2402.17410)

    提出了一种用于MRI重建的傅里叶域插值神经网络的图像空间形式主义，并分析了在CNN推断过程中噪声传播的估计方法。

    

    旨在为MRI重建中的图像域插值开发多层卷积神经网络（CNNs）的图像空间形式主义，并在CNN推断过程中对噪声传播进行分析。通过使用复值整流线性单元在傅里叶域（也称为k空间）中的非线性激活，将其表示为与激活掩模的逐元素乘法。这种操作在图像空间中转换为卷积。在k空间网络训练后，这种方法为相对于别名线圈图像的重建图像的导数提供了一个代数表达式，这些别名线圈图像作为图像空间中网络的输入张量。这使得可以通过分析估计网络推断中的方差，并用于描述噪声特性。通过蒙特卡洛模拟和基于自动微分的数值方法进行验证。

    arXiv:2402.17410v1 Announce Type: cross  Abstract: Purpose: To develop an image space formalism of multi-layer convolutional neural networks (CNNs) for Fourier domain interpolation in MRI reconstructions and analytically estimate noise propagation during CNN inference. Theory and Methods: Nonlinear activations in the Fourier domain (also known as k-space) using complex-valued Rectifier Linear Units are expressed as elementwise multiplication with activation masks. This operation is transformed into a convolution in the image space. After network training in k-space, this approach provides an algebraic expression for the derivative of the reconstructed image with respect to the aliased coil images, which serve as the input tensors to the network in the image space. This allows the variance in the network inference to be estimated analytically and to be used to describe noise characteristics. Monte-Carlo simulations and numerical approaches based on auto-differentiation were used for val
    
[^42]: 用神经重写系统解决算法问题

    A Neural Rewriting System to Solve Algorithmic Problems

    [https://arxiv.org/abs/2402.17407](https://arxiv.org/abs/2402.17407)

    提出了一种受重写系统启发的神经架构，用于学习算法任务，通过Selector、Solver和Combiner三个专门模块实现算法任务的简化，具有较好的外推能力

    

    现代神经网络架构仍然难以学习需要系统应用组合规则来解决超出分布问题实例的算法程序。在这项工作中，我们提出了一种原创方法来学习受重写系统启发的算法任务，重写系统是符号人工智能中的经典框架。我们展示了重写系统可以被实现为一个由专门模块组成的神经架构：选择器识别要处理的目标子表达式，求解器通过计算相应的结果简化子表达式，组合器通过用提供的解决方案替换子表达式生成原始表达式的新版本。我们在三种涉及简化涉及列表、算术和代数表达式的符号公式的算法任务上评估我们的模型。我们测试了所提架构的外推能力

    arXiv:2402.17407v1 Announce Type: cross  Abstract: Modern neural network architectures still struggle to learn algorithmic procedures that require to systematically apply compositional rules to solve out-of-distribution problem instances. In this work, we propose an original approach to learn algorithmic tasks inspired by rewriting systems, a classic framework in symbolic artificial intelligence. We show that a rewriting system can be implemented as a neural architecture composed by specialized modules: the Selector identifies the target sub-expression to process, the Solver simplifies the sub-expression by computing the corresponding result, and the Combiner produces a new version of the original expression by replacing the sub-expression with the solution provided. We evaluate our model on three types of algorithmic tasks that require simplifying symbolic formulas involving lists, arithmetic, and algebraic expressions. We test the extrapolation capabilities of the proposed architectu
    
[^43]: LSPT：用于视觉表示学习的长期空间提示调整

    LSPT: Long-term Spatial Prompt Tuning for Visual Representation Learning

    [https://arxiv.org/abs/2402.17406](https://arxiv.org/abs/2402.17406)

    LSPT是一种革命性的视觉表示学习方法，通过引入长期门控提示，巧妙地利用长距离先前块作为提示的潜在来源，减轻了遗忘参数的风险。

    

    视觉提示调整（VPT）技术因其通过专用的可学习令牌（称为提示）将预训练的视觉Transformer（ViT）调整到下游视觉任务而闻名。在自监督视觉Transformer中使用的当代VPT方法通常默认引入来源自模型先前块的新可学习提示或门控提示令牌。这种方法的一个关键缺失是未利用长距离先前块作为每个自监督ViT内提示的潜力来源。为了弥补这一重要差距，我们引入了长期空间提示调整（LSPT）- 一种革命性的视觉表示学习方法。 LSPT从人类大脑的复杂性中汲取灵感，巧妙地结合了长期门控提示。这个特性作为时间编码，减轻了遗忘参数的风险。

    arXiv:2402.17406v1 Announce Type: cross  Abstract: Visual Prompt Tuning (VPT) techniques have gained prominence for their capacity to adapt pre-trained Vision Transformers (ViTs) to downstream visual tasks using specialized learnable tokens termed as prompts. Contemporary VPT methodologies, especially when employed with self-supervised vision transformers, often default to the introduction of new learnable prompts or gated prompt tokens predominantly sourced from the model's previous block. A pivotal oversight in such approaches is their failure to harness the potential of long-range previous blocks as sources of prompts within each self-supervised ViT. To bridge this crucial gap, we introduce Long-term Spatial Prompt Tuning (LSPT) - a revolutionary approach to visual representation learning. Drawing inspiration from the intricacies of the human brain, LSPT ingeniously incorporates long-term gated prompts. This feature serves as temporal coding, curbing the risk of forgetting parameter
    
[^44]: 量子方法研究合成少数类过采样技术（SMOTE）

    A Quantum Approach to Synthetic Minority Oversampling Technique (SMOTE)

    [https://arxiv.org/abs/2402.17398](https://arxiv.org/abs/2402.17398)

    使用量子计算技术提出了Quantum-SMOTE方法，可以解决机器学习数据集中的类别不平衡问题，并引入了旋转角度、少数类百分比和分裂因子等超参数，实现了对合成数据生成过程的更好控制。

    

    这篇论文提出了Quantum-SMOTE方法，这是一种使用量子计算技术来解决机器学习数据集中普遍存在的类别不平衡问题的新颖解决方案。Quantum-SMOTE受到合成少数类过采样技术（SMOTE）的启发，利用量子过程如交换测试和量子旋转生成合成数据点。该方法与传统的SMOTE算法使用K-最近邻（KNN）和欧氏距离的方式有所不同，能够从少数类数据点生成合成实例而无需依赖于邻近性。算法通过引入旋转角度、少数类百分比和分裂因子等超参数，可以更好地控制合成数据生成过程，从而实现对特定数据集需求的定制。该方法在TelecomChurn公共数据集上进行了测试，并与两种主要的分类算法进行了评估。

    arXiv:2402.17398v1 Announce Type: cross  Abstract: The paper proposes the Quantum-SMOTE method, a novel solution that uses quantum computing techniques to solve the prevalent problem of class imbalance in machine learning datasets. Quantum-SMOTE, inspired by the Synthetic Minority Oversampling Technique (SMOTE), generates synthetic data points using quantum processes such as swap tests and quantum rotation. The process varies from the conventional SMOTE algorithm's usage of K-Nearest Neighbors (KNN) and Euclidean distances, enabling synthetic instances to be generated from minority class data points without relying on neighbor proximity. The algorithm asserts greater control over the synthetic data generation process by introducing hyperparameters such as rotation angle, minority percentage, and splitting factor, which allow for customization to specific dataset requirements. The approach is tested on a public dataset of TelecomChurn and evaluated alongside two prominent classification
    
[^45]: 在算法问题上对GPT-4进行基准测试：关于提示策略的系统评估

    Benchmarking GPT-4 on Algorithmic Problems: A Systematic Evaluation of Prompting Strategies

    [https://arxiv.org/abs/2402.17396](https://arxiv.org/abs/2402.17396)

    对GPT-4在算法问题上进行了系统评估，发现采用先进的提示技术可以提高其准确性。

    

    大型语言模型（LLMs）通过在海量文本语料库上获得的知识在各种下游任务中重新利用，几乎不需要（或根本不需要）调整步骤，从而革新了自然语言处理领域。与此同时，已经反复显示LLMs缺乏系统化泛化，这使得无法将学习到的统计规律外推到训练分布之外。在本研究中，我们对其中一种最先进的LLMs，GPT-4，在三个算法任务上进行了系统基准测试，这些任务通过两个参数控制问题难度。我们比较了GPT-4与其前身（GPT-3.5）以及最近介绍的变压器编码器架构的变体，即神经数据路由器，在解决类似任务时的性能。我们发现采用先进的提示技术可以使GPT-4达到更高的准确性。

    arXiv:2402.17396v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have revolutionized the field of Natural Language Processing thanks to their ability to reuse knowledge acquired on massive text corpora on a wide variety of downstream tasks, with minimal (if any) tuning steps. At the same time, it has been repeatedly shown that LLMs lack systematic generalization, which allows to extrapolate the learned statistical regularities outside the training distribution. In this work, we offer a systematic benchmarking of GPT-4, one of the most advanced LLMs available, on three algorithmic tasks characterized by the possibility to control the problem difficulty with two parameters. We compare the performance of GPT-4 with that of its predecessor (GPT-3.5) and with a variant of the Transformer-Encoder architecture recently introduced to solve similar tasks, the Neural Data Router. We find that the deployment of advanced prompting techniques allows GPT-4 to reach superior accuracy o
    
[^46]: 公平信念 - 评估语言模型中的有害信念

    FairBelief - Assessing Harmful Beliefs in Language Models

    [https://arxiv.org/abs/2402.17389](https://arxiv.org/abs/2402.17389)

    本文提出了FairBelief，一种用于捕获和评估语言模型中有害信念的分析方法，并通过公平数据集对几种最先进的LM进行评估，发现这些LM可能存在有害信念。

    

    语言模型（LMs）已被证明存在不良偏见，如果这些系统在没有仔细进行公平审计的情况下集成到现实应用中，可能会伤害少数群体和被忽视的群体。本文提出了FairBelief，一种分析方法，用于捕获和评估信念，即LM可能以不同程度的确信度嵌入的命题，这些命题暗中影响其预测。通过FairBelief，我们利用提示来研究几种最先进的LM在先前被忽视的不同轴上的行为，比如模型规模和可能性，评估对专门设计用于量化LM输出伤害程度的公平数据集的预测。最后，我们对模型发出的信念进行深入的定性评估。我们将FairBelief应用于英语LMs，发现尽管这些架构在各种自然语言处理任务上表现出色，但它们也可能存在有害信念。

    arXiv:2402.17389v1 Announce Type: cross  Abstract: Language Models (LMs) have been shown to inherit undesired biases that might hurt minorities and underrepresented groups if such systems were integrated into real-world applications without careful fairness auditing. This paper proposes FairBelief, an analytical approach to capture and assess beliefs, i.e., propositions that an LM may embed with different degrees of confidence and that covertly influence its predictions. With FairBelief, we leverage prompting to study the behavior of several state-of-the-art LMs across different previously neglected axes, such as model scale and likelihood, assessing predictions on a fairness dataset specifically designed to quantify LMs' outputs' hurtfulness. Finally, we conclude with an in-depth qualitative assessment of the beliefs emitted by the models. We apply FairBelief to English LMs, revealing that, although these architectures enable high performances on diverse natural language processing ta
    
[^47]: 将图神经网络重新送回试验台进行在高能粒子物理学中的应用的案例研究

    A case study of sending graph neural networks back to the test bench for applications in high-energy particle physics

    [https://arxiv.org/abs/2402.17386](https://arxiv.org/abs/2402.17386)

    本文进行了一项用典型GNN与深度全连接前馈结构神经网络进行基准测试的案例研究，以在高能粒子物理学领域中探讨它们的应用。

    

    在高能粒子碰撞中，主要的碰撞产物通常会进一步衰变，形成类似树状结构的分层结构，其中节点数量未知。在稳定粒子级别上，碰撞的所有衰变产物形成具有置换不变性的最终状态对象集合。与数学图的类比引发了一个想法，即图神经网络（GNNs），自然地类似于这些属性，应该最适合处理许多与高能粒子物理学相关的任务。在本文中，我们描述了针对典型GNN与深度全连接前馈结构神经网络进行基准测试的案例。我们旨在以节点、隐藏层或所研究神经网络的可训练参数方面最大程度地不偏性地进行这种比较。作为物理案例，我们使用与质子中产生的顶夸克对关联的最终态X的分类。

    arXiv:2402.17386v1 Announce Type: cross  Abstract: In high-energy particle collisions, the primary collision products usually decay further resulting in tree-like, hierarchical structures with a priori unknown multiplicity. At the stable-particle level all decay products of a collision form permutation invariant sets of final state objects. The analogy to mathematical graphs gives rise to the idea that graph neural networks (GNNs), which naturally resemble these properties, should be best-suited to address many tasks related to high-energy particle physics. In this paper we describe a benchmark test of a typical GNN against neural networks of the well-established deep fully-connected feed-forward architecture. We aim at performing this comparison maximally unbiased in terms of nodes, hidden layers, or trainable parameters of the neural networks under study. As physics case we use the classification of the final state X produced in association with top quark-antiquark pairs in proton-pr
    
[^48]: LLM辅助决策的决定因素

    Determinants of LLM-assisted Decision-Making

    [https://arxiv.org/abs/2402.17385](https://arxiv.org/abs/2402.17385)

    本研究探讨了影响LLM支持决策的决定因素，包括技术方面的透明度和及时工程、心理因素如情绪和决策风格，以及决策特定因素如任务难度和问责制。

    

    决策是日常生活中的一项基本能力。大型语言模型（LLMs）提供多方面支持，增强人类决策过程。然而，理解LLM辅助决策的影响因素对于使个体能够利用LLM提供的优势并最小化相关风险，以便做出更加明智和更好的决策至关重要。本研究提供了一项全面文献分析的结果，提供了影响LLM支持决策的决定因素的结构概述和详细分析。特别是，我们探讨了LLMs的技术方面的效应，包括透明度和及时工程，心理因素如情绪和决策风格，以及特定于决策的决定因素，如任务难度和问责制。此外，通过...

    arXiv:2402.17385v1 Announce Type: new  Abstract: Decision-making is a fundamental capability in everyday life. Large Language Models (LLMs) provide multifaceted support in enhancing human decision-making processes. However, understanding the influencing factors of LLM-assisted decision-making is crucial for enabling individuals to utilize LLM-provided advantages and minimize associated risks in order to make more informed and better decisions. This study presents the results of a comprehensive literature analysis, providing a structural overview and detailed analysis of determinants impacting decision-making with LLM support. In particular, we explore the effects of technological aspects of LLMs, including transparency and prompt engineering, psychological factors such as emotions and decision-making styles, as well as decision-specific determinants such as task difficulty and accountability. In addition, the impact of the determinants on the decision-making process is illustrated via 
    
[^49]: 优化时间步长加速扩散采样

    Accelerating Diffusion Sampling with Optimized Time Steps

    [https://arxiv.org/abs/2402.17376](https://arxiv.org/abs/2402.17376)

    提出了一个通用框架用于设计优化问题，旨在通过寻找更合适的时间步长加速扩散采样。

    

    扩散概率模型（DPMs）在高分辨率图像合成中表现出色，但由于通常需要大量采样步骤，其采样效率仍有待提高。近期高阶数值ODE求解器在DPMs中的应用使得用更少的采样步骤生成高质量图像成为可能。尽管这是一项重大进展，大多数采样方法仍然采用均匀时间步长，而在采样步骤较少时并不是最佳选择。为解决这一问题，我们提出了一个通用框架，用于设计一个优化问题，该优化问题旨在为DPMs的特定数值ODE求解器寻找更合适的时间步长。此优化问题旨在最小化地实现地真实解与与数值求解器对应的近似解之间的距离。它可以通过受限信赖域方法进行高效求解，时间少于

    arXiv:2402.17376v1 Announce Type: cross  Abstract: Diffusion probabilistic models (DPMs) have shown remarkable performance in high-resolution image synthesis, but their sampling efficiency is still to be desired due to the typically large number of sampling steps. Recent advancements in high-order numerical ODE solvers for DPMs have enabled the generation of high-quality images with much fewer sampling steps. While this is a significant development, most sampling methods still employ uniform time steps, which is not optimal when using a small number of steps. To address this issue, we propose a general framework for designing an optimization problem that seeks more appropriate time steps for a specific numerical ODE solver for DPMs. This optimization problem aims to minimize the distance between the ground-truth solution to the ODE and an approximate solution corresponding to the numerical solver. It can be efficiently solved using the constrained trust region method, taking less than 
    
[^50]: CAPT: 使用Transformer从单个点云估计类别级联的关节参数

    CAPT: Category-level Articulation Estimation from a Single Point Cloud Using Transformer

    [https://arxiv.org/abs/2402.17360](https://arxiv.org/abs/2402.17360)

    提出了CAPT方法，使用Transformer从单个点云中准确估计各种联动物体的关节参数和状态，引入了运动损失方法和双重投票策略，实验结果表明其优于现有的其他选择

    

    估计关节参数对于机器人学和计算机视觉中的各种应用至关重要。本文提出了CAPT：使用Transformer从点云中估计类别级联关节参数。CAPT使用端到端的基于Transformer的架构，从单个点云中对联动物体的关节参数和状态进行估计。所提出的CAPT方法可以准确估计各种联动物体的关节参数和状态，具有高精度和鲁棒性。该论文还提出了一种运动损失方法，通过强调联动物体的动态特征来改善关节参数估计性能。此外，该论文提出了双重投票策略，为框架提供由粗到细的参数估计。在几个类别数据集上的实验结果表明，我们的方法在关节参数估计方面优于现有的其他选择。

    arXiv:2402.17360v1 Announce Type: cross  Abstract: The ability to estimate joint parameters is essential for various applications in robotics and computer vision. In this paper, we propose CAPT: category-level articulation estimation from a point cloud using Transformer. CAPT uses an end-to-end transformer-based architecture for joint parameter and state estimation of articulated objects from a single point cloud. The proposed CAPT methods accurately estimate joint parameters and states for various articulated objects with high precision and robustness. The paper also introduces a motion loss approach, which improves articulation estimation performance by emphasizing the dynamic features of articulated objects. Additionally, the paper presents a double voting strategy to provide the framework with coarse-to-fine parameter estimation. Experimental results on several category datasets demonstrate that our methods outperform existing alternatives for articulation estimation. Our research 
    
[^51]: LocalGCL：面向图的局部感知对比学习

    LocalGCL: Local-aware Contrastive Learning for Graphs

    [https://arxiv.org/abs/2402.17345](https://arxiv.org/abs/2402.17345)

    提出了一种名为LocalGCL的新的自监督学习框架，通过掩码建模补充地捕捉局部图信息，优于传统对比学习方法。

    

    图表示学习（GRL）最近取得了相当大的进展，它将图与拓扑结构编码为低维嵌入。同时，手动注释图标签的耗时和成本高昂促使自监督学习（SSL）技术的发展。作为SSL的主要方法，对比学习（CL）通过区分正负样本来学习具有区分性的表示。然而，当应用于图数据时，它过分强调全局模式而忽视了局部结构。为了解决以上问题，我们提出了一种自监督学习框架，即面向图的局部感知对比学习（\methname），与普通对比学习相比，它通过基于掩码的建模补充地捕捉局部图信息。大量实验证实了\methname 的优越性。

    arXiv:2402.17345v1 Announce Type: cross  Abstract: Graph representation learning (GRL) makes considerable progress recently, which encodes graphs with topological structures into low-dimensional embeddings. Meanwhile, the time-consuming and costly process of annotating graph labels manually prompts the growth of self-supervised learning (SSL) techniques. As a dominant approach of SSL, Contrastive learning (CL) learns discriminative representations by differentiating between positive and negative samples. However, when applied to graph data, it overemphasizes global patterns while neglecting local structures. To tackle the above issue, we propose \underline{Local}-aware \underline{G}raph \underline{C}ontrastive \underline{L}earning (\textbf{\methnametrim}), a self-supervised learning framework that supplementarily captures local graph information with masking-based modeling compared with vanilla contrastive learning. Extensive experiments validate the superiority of \methname against st
    
[^52]: SocialCVAE：通过交互条件潜变量预测行人轨迹

    SocialCVAE: Predicting Pedestrian Trajectory via Interaction Conditioned Latents

    [https://arxiv.org/abs/2402.17339](https://arxiv.org/abs/2402.17339)

    SocialCVAE使用CVAE模型来预测行人轨迹，通过探索行为不确定性并学习社交合理的运动随机性来提高模型性能。

    

    行人轨迹预测是许多应用程序中的关键技术，可以洞察人类行为并预测人类未来动向。大多数现有的经验模型是通过观察到的人类行为以可解释的数学术语明确表达出来的，具有确定性，而近期的工作集中在开发混合模型，结合基于学习的技术，以提供强大的表达能力同时保持可解释性。然而，从经验模型中学得的具有确定性的驾驶行为的性质限制了模型的实际性能。为了解决这个问题，本文提出了社交条件变分自动编码器（SocialCVAE）用于预测行人轨迹，它采用CVAE来探索人类运动决策中的行为不确定性。SocialCVAE通过利用一个社交可解释的交互能量图来学习社交合理的运动随机性

    arXiv:2402.17339v1 Announce Type: cross  Abstract: Pedestrian trajectory prediction is the key technology in many applications for providing insights into human behavior and anticipating human future motions. Most existing empirical models are explicitly formulated by observed human behaviors using explicable mathematical terms with a deterministic nature, while recent work has focused on developing hybrid models combined with learning-based techniques for powerful expressiveness while maintaining explainability. However, the deterministic nature of the learned steering behaviors from the empirical models limits the models' practical performance. To address this issue, this work proposes the social conditional variational autoencoder (SocialCVAE) for predicting pedestrian trajectories, which employs a CVAE to explore behavioral uncertainty in human motion decisions. SocialCVAE learns socially reasonable motion randomness by utilizing a socially explainable interaction energy map as the
    
[^53]: BiVRec: 双向基于视图的多模态顺序推荐

    BiVRec: Bidirectional View-based Multimodal Sequential Recommendation

    [https://arxiv.org/abs/2402.17334](https://arxiv.org/abs/2402.17334)

    提出了一个创新框架 BiVRec，在推荐任务中联合训练 ID 和多模态视图，双向增强推荐性能。

    

    多模态信息融入顺序推荐系统近来引起了研究的广泛关注。在多模态顺序推荐模型的初期阶段，主流范式是ID主导推荐，即多模态信息作为辅助信息进行融合。然而，由于其在可转移性和信息侵入方面的局限性，另一种范式出现了，即直接利用多模态特征进行推荐，实现跨数据集的推荐。尽管如此，它忽略了用户ID信息，导致信息利用率低和训练成本高。为此，我们提出了一个创新框架，BiVRec，通过联合训练ID和多模态视图中的推荐任务，利用它们之间的协同关系双向增强推荐性能。为了解决信息异构性问题，我们...

    arXiv:2402.17334v1 Announce Type: cross  Abstract: The integration of multimodal information into sequential recommender systems has attracted significant attention in recent research. In the initial stages of multimodal sequential recommendation models, the mainstream paradigm was ID-dominant recommendations, wherein multimodal information was fused as side information. However, due to their limitations in terms of transferability and information intrusion, another paradigm emerged, wherein multimodal features were employed directly for recommendation, enabling recommendation across datasets. Nonetheless, it overlooked user ID information, resulting in low information utilization and high training costs. To this end, we propose an innovative framework, BivRec, that jointly trains the recommendation tasks in both ID and multimodal views, leveraging their synergistic relationship to enhance recommendation performance bidirectionally. To tackle the information heterogeneity issue, we fir
    
[^54]: 探究多模态大型语言模型对全局和局部语义表示的影响

    Probing Multimodal Large Language Models for Global and Local Semantic Representation

    [https://arxiv.org/abs/2402.17304](https://arxiv.org/abs/2402.17304)

    通过研究发现，多模态大型语言模型的中间层能够更好地编码全局语义信息，在视觉-语言任务中表现出更好的性能。顶层可能过多关注局部信息，导致理解全局信息的能力下降。

    

    大型语言模型的成功启发了研究人员将其优秀的表示能力转移到其他模态。最近的一些研究利用图像描述对齐数据集训练多模态大型语言模型（MLLMs），在图像到文本任务中取得了最新的性能表现。然而，很少有研究探讨MLLMs是否真正理解完整的图像信息，即全局信息，或者它们只能捕捉一些局部对象信息。本研究发现模型的中间层可以编码更多全局语义信息，其表示向量在视觉-语言蕴涵任务上表现更好，而不是顶层。我们通过目标检测任务进一步探究模型的局部语义表示。我们得出的结论是顶层可能过多专注于局部信息，导致减弱了对全局信息的理解能力。

    arXiv:2402.17304v1 Announce Type: cross  Abstract: The success of large language models has inspired researchers to transfer their exceptional representing ability to other modalities. Several recent works leverage image-caption alignment datasets to train multimodal large language models (MLLMs), which achieve state-of-the-art performance on image-to-text tasks. However, there are very few studies exploring whether MLLMs truly understand the complete image information, i.e., global information, or if they can only capture some local object information. In this study, we find that the intermediate layers of models can encode more global semantic information, whose representation vectors perform better on visual-language entailment tasks, rather than the topmost layers. We further probe models for local semantic representation through object detection tasks. And we draw a conclusion that the topmost layers may excessively focus on local information, leading to a diminished ability to en
    
[^55]: 多旋翼飞行器定位的主动推进噪声塑造

    Active propulsion noise shaping for multi-rotor aircraft localization

    [https://arxiv.org/abs/2402.17289](https://arxiv.org/abs/2402.17289)

    本文提出通过主动控制和塑造旋翼产生的飞行器推进噪声来有利于定位任务，提出了一种基于自噪声和时间变化旋翼相位调制的神经网络架构，实现了准确和稳健的定位。

    

    多旋翼空中自主载具(MAVs)主要依赖视觉进行导航。然而，视觉定位和测距技术在低或直射阳光下表现不佳，视野有限，并且容易受到遮挡的影响。声学传感可以作为视觉的补充或甚至替代方式在许多情况下使用，而且还具有更低的系统成本和能源占用量，这对微型飞行器尤为重要。本文提出通过主动控制和塑造由旋翼产生的飞行器推进噪声，以有利于定位任务，而非将其视为有害噪声。我们提出了一种基于自噪声的神经网络架构，用于在已知环境中进行定位。我们表明，同时训练学习时间变化的旋翼相位调制，可以实现准确和稳健的定位。所提出的方法进行了评估。

    arXiv:2402.17289v1 Announce Type: cross  Abstract: Multi-rotor aerial autonomous vehicles (MAVs) primarily rely on vision for navigation purposes. However, visual localization and odometry techniques suffer from poor performance in low or direct sunlight, a limited field of view, and vulnerability to occlusions. Acoustic sensing can serve as a complementary or even alternative modality for vision in many situations, and it also has the added benefits of lower system cost and energy footprint, which is especially important for micro aircraft. This paper proposes actively controlling and shaping the aircraft propulsion noise generated by the rotors to benefit localization tasks, rather than considering it a harmful nuisance. We present a neural network architecture for selfnoise-based localization in a known environment. We show that training it simultaneously with learning time-varying rotor phase modulation achieves accurate and robust localization. The proposed methods are evaluated u
    
[^56]: 通过扩散模型和组-自编码器超分辨网络增强高光谱图像

    Enhancing Hyperspectral Images via Diffusion Model and Group-Autoencoder Super-resolution Network

    [https://arxiv.org/abs/2402.17285](https://arxiv.org/abs/2402.17285)

    该论文提出了一种新颖的Group-Autoencoder框架，与扩散模型协同组合，构建了一个高效的HSI超分辨模型（DMGASR）。

    

    现有的高光谱图像（HSI）超分辨（SR）方法在有效捕捉复杂的光谱-空间关系和低级细节方面存在困难，而扩散模型以其在建模复杂关系和学习高低级视觉特征方面的卓越表现而闻名。将扩散模型直接应用于HSI SR受到挑战，例如模型收敛困难和推理时间延长。在本文中，我们引入了一种新颖的组-自编码器（GAE）框架，与扩散模型协同组合构建了一个高效的HSI SR模型（DMGASR）。我们提出的GAE框架将高维HSI数据编码为扩散模型可以运行的低维潜在空间，从而减轻了训练扩散模型的困难，同时保持波段相关性并显著减少推理时间。

    arXiv:2402.17285v1 Announce Type: cross  Abstract: Existing hyperspectral image (HSI) super-resolution (SR) methods struggle to effectively capture the complex spectral-spatial relationships and low-level details, while diffusion models represent a promising generative model known for their exceptional performance in modeling complex relations and learning high and low-level visual features. The direct application of diffusion models to HSI SR is hampered by challenges such as difficulties in model convergence and protracted inference time. In this work, we introduce a novel Group-Autoencoder (GAE) framework that synergistically combines with the diffusion model to construct a highly effective HSI SR model (DMGASR). Our proposed GAE framework encodes high-dimensional HSI data into low-dimensional latent space where the diffusion model works, thereby alleviating the difficulty of training the diffusion model while maintaining band correlation and considerably reducing inference time. Ex
    
[^57]: 多智能体、人智能体及其进展：合作在社会困境中的调查

    Multi-Agent, Human-Agent and Beyond: A Survey on Cooperation in Social Dilemmas

    [https://arxiv.org/abs/2402.17270](https://arxiv.org/abs/2402.17270)

    调查了多智能体、人智能体和人工智能智能体在社会困境合作中的三个关键领域，讨论了合作的动机、策略、人类偏见，以及未来研究方向。

    

    在社会困境中研究合作长期以来一直是各种学科的基本课题，包括计算机科学和社会科学。人工智能领域的最新进展显著重塑了这一领域，为理解和增强合作提供了新的见解。本调查考察了人工智能和社会困境合作交汇处的三个关键领域。首先，着重于多智能体合作，我们审查了支持理性智能体之间合作的内在和外在动机，以及用于制定有效策略对抗不同对手的方法。其次，探讨了人智能体合作，我们讨论了当前用于与人类合作的人工智能算法，以及人类对人工智能智能体的偏见。第三，我们审查了利用人工智能智能体增强人类合作的新兴领域。最后，我们讨论了未来研究方向，例如 u

    arXiv:2402.17270v1 Announce Type: new  Abstract: The study of cooperation within social dilemmas has long been a fundamental topic across various disciplines, including computer science and social science. Recent advancements in Artificial Intelligence (AI) have significantly reshaped this field, offering fresh insights into understanding and enhancing cooperation. This survey examines three key areas at the intersection of AI and cooperation in social dilemmas. First, focusing on multi-agent cooperation, we review the intrinsic and external motivations that support cooperation among rational agents, and the methods employed to develop effective strategies against diverse opponents. Second, looking into human-agent cooperation, we discuss the current AI algorithms for cooperating with humans and the human biases towards AI agents. Third, we review the emergent field of leveraging AI agents to enhance cooperation among humans. We conclude by discussing future research avenues, such as u
    
[^58]: 失言：多轮对话中大型语言模型的安全漏洞

    Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue

    [https://arxiv.org/abs/2402.17262](https://arxiv.org/abs/2402.17262)

    本论文探讨了多轮对话中大型语言模型的安全性漏洞，指出人类可以通过多轮对话诱使其生成有害信息。

    

    大型语言模型(LLMs)已被证明在面临"越狱"时会产生非法或不道德的回应。 "越狱"研究强调了LLMs的安全问题。然而，先前的研究主要集中在单轮对话上，忽视了多轮对话可能带来的复杂性和风险，这是人类从LLMs获取信息的关键方式。本文认为人类可以利用多轮对话诱使LLMs生成有害信息。LLMs可能不会拒绝警告性或边界不安全的查询，即使在多轮对话中每个回合都被服务于一个恶意目的。因此，通过将一个不安全查询分解为多个子查询用于多轮对话，我们逐渐诱使LLMs回答有害的子问题，最终导致总体有害响应。我们的实验跨越了广泛的范围。

    arXiv:2402.17262v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have been demonstrated to generate illegal or unethical responses, particularly when subjected to "jailbreak." Research on jailbreak has highlighted the safety issues of LLMs. However, prior studies have predominantly focused on single-turn dialogue, ignoring the potential complexities and risks presented by multi-turn dialogue, a crucial mode through which humans derive information from LLMs. In this paper, we argue that humans could exploit multi-turn dialogue to induce LLMs into generating harmful information. LLMs may not intend to reject cautionary or borderline unsafe queries, even if each turn is closely served for one malicious purpose in a multi-turn dialogue. Therefore, by decomposing an unsafe query into several sub-queries for multi-turn dialogue, we induced LLMs to answer harmful sub-questions incrementally, culminating in an overall harmful response. Our experiments, conducted across a wide ra
    
[^59]: RIME: 具有嘈杂偏好的健壮偏好强化学习

    RIME: Robust Preference-based Reinforcement Learning with Noisy Preferences

    [https://arxiv.org/abs/2402.17257](https://arxiv.org/abs/2402.17257)

    RIME是一种针对嘈杂偏好的健壮PbRL算法，通过动态过滤去噪偏好和热启动奖励模型，极大增强了现有最先进PbRL方法的鲁棒性。

    

    偏好强化学习（PbRL）通过利用人类偏好作为奖励信号，避免了对奖励设计的需求。然而，当前PbRL算法过度依赖来自领域专家的高质量反馈，导致缺乏鲁棒性。在本文中，我们提出了RIME，一种针对嘈杂偏好的健壮PbRL算法，用于有效地从嘈杂偏好中学习奖励。我们的方法结合了基于样本选择的鉴别器，动态过滤去噪偏好以进行健壮训练。为了减轻选择不正确造成的累积误差，我们提出热启动奖励模型，此外还能填补PbRL中从预训练到在线训练过渡时的性能差距。我们在机器人操纵和运动任务上的实验表明，RIME显著提升了当前最先进的PbRL方法的鲁棒性。消融研究进一步表明，热启动

    arXiv:2402.17257v1 Announce Type: cross  Abstract: Preference-based Reinforcement Learning (PbRL) avoids the need for reward engineering by harnessing human preferences as the reward signal. However, current PbRL algorithms over-reliance on high-quality feedback from domain experts, which results in a lack of robustness. In this paper, we present RIME, a robust PbRL algorithm for effective reward learning from noisy preferences. Our method incorporates a sample selection-based discriminator to dynamically filter denoised preferences for robust training. To mitigate the accumulated error caused by incorrect selection, we propose to warm start the reward model, which additionally bridges the performance gap during transition from pre-training to online training in PbRL. Our experiments on robotic manipulation and locomotion tasks demonstrate that RIME significantly enhances the robustness of the current state-of-the-art PbRL method. Ablation studies further demonstrate that the warm star
    
[^60]: 基于深度学习的语音和视觉合成在多层自适应框架中改进网络钓鱼攻击检测

    Deep Learning-Based Speech and Vision Synthesis to Improve Phishing Attack Detection through a Multi-layer Adaptive Framework

    [https://arxiv.org/abs/2402.17249](https://arxiv.org/abs/2402.17249)

    提出了一个结合深度学习和随机森林的自适应框架，通过在多个预测层中读取图像、合成语音以及进行自然语言处理，显著提高了网络钓鱼攻击检测的性能。

    

    攻击者不断演进的方式持续改进其欺骗技术，以绕过现有的最先进网络钓鱼检测方法，给行业和学术研究人员带来了巨大挑战，因为当前方法无法检测复杂的网络钓鱼攻击。因此，由于攻击者采用的策略日益复杂且新策略不断被开发以逃避检测，当前反网络钓鱼方法仍然容易受到复杂网络钓鱼攻击的影响。在这项研究中，我们提出了一个可调整的框架，将深度学习和随机森林结合起来，从深度伪造视频中读取图像，合成语音，以及自然语言处理，并在各种预测层中显著提高机器学习模型对网络钓鱼攻击检测的性能。

    arXiv:2402.17249v1 Announce Type: cross  Abstract: The ever-evolving ways attacker continues to im prove their phishing techniques to bypass existing state-of-the-art phishing detection methods pose a mountain of challenges to researchers in both industry and academia research due to the inability of current approaches to detect complex phishing attack. Thus, current anti-phishing methods remain vulnerable to complex phishing because of the increasingly sophistication tactics adopted by attacker coupled with the rate at which new tactics are being developed to evade detection. In this research, we proposed an adaptable framework that combines Deep learning and Randon Forest to read images, synthesize speech from deep-fake videos, and natural language processing at various predictions layered to significantly increase the performance of machine learning models for phishing attack detection.
    
[^61]: Playground v2.5：增强文本到图像生成中美学质量的三个见解

    Playground v2.5: Three Insights towards Enhancing Aesthetic Quality in Text-to-Image Generation

    [https://arxiv.org/abs/2402.17245](https://arxiv.org/abs/2402.17245)

    本论文分享了三个见解，以实现文本到图像生成模型的最新美学质量：增强色彩和对比度，提高跨多个宽高比的生成，改善以人为中心的细节。

    

    在这项工作中，我们分享了三个见解，以实现文本到图像生成模型的最新美学质量。我们专注于模型改进的三个关键方面：增强色彩和对比度，提高跨多个宽高比的生成，改善以人为中心的细节。首先，我们深入探讨了噪声调度在训练扩散模型中的重要性，展示了它对现实感和视觉保真度的深远影响。其次，我们解决了图像生成中容纳各种宽高比的挑战，强调准备平衡的分桶数据集的重要性。最后，我们调查了将模型输出与人类偏好对齐的关键作用，确保生成的图像 resonant with人类感知期望。通过广泛的分析和实验，Playground v2.5在各种条件下展示了最先进的美学质量表现。

    arXiv:2402.17245v1 Announce Type: cross  Abstract: In this work, we share three insights for achieving state-of-the-art aesthetic quality in text-to-image generative models. We focus on three critical aspects for model improvement: enhancing color and contrast, improving generation across multiple aspect ratios, and improving human-centric fine details. First, we delve into the significance of the noise schedule in training a diffusion model, demonstrating its profound impact on realism and visual fidelity. Second, we address the challenge of accommodating various aspect ratios in image generation, emphasizing the importance of preparing a balanced bucketed dataset. Lastly, we investigate the crucial role of aligning model outputs with human preferences, ensuring that generated images resonate with human perceptual expectations. Through extensive analysis and experiments, Playground v2.5 demonstrates state-of-the-art performance in terms of aesthetic quality under various conditions an
    
[^62]: 离线安全强化学习中的时间逻辑规范条件化决策转换器

    Temporal Logic Specification-Conditioned Decision Transformer for Offline Safe Reinforcement Learning

    [https://arxiv.org/abs/2402.17217](https://arxiv.org/abs/2402.17217)

    提出了时间逻辑规范条件化决策转换器（SDT）框架，结合信号时间逻辑（STL）和决策转换器（DT）的能力，比现有方法在离线安全强化学习中学习出更好的安全高奖励策略。

    

    离线安全强化学习旨在从固定数据集训练一个满足约束的策略。本文提出了一种新颖的框架，即时间逻辑规范条件化决策转换器（SDT），它利用信号时间逻辑（STL）的表达能力来指定代理应该遵循的复杂时间规则，以及决策转换器（DT）的顺序建模能力。对DSRL基准测试的实证评估表明，与现有方法相比，SDT在学习安全高奖励策略方面具有更好的能力。

    arXiv:2402.17217v1 Announce Type: cross  Abstract: Offline safe reinforcement learning (RL) aims to train a constraint satisfaction policy from a fixed dataset. Current state-of-the-art approaches are based on supervised learning with a conditioned policy. However, these approaches fall short in real-world applications that involve complex tasks with rich temporal and logical structures. In this paper, we propose temporal logic Specification-conditioned Decision Transformer (SDT), a novel framework that harnesses the expressive power of signal temporal logic (STL) to specify complex temporal rules that an agent should follow and the sequential modeling capability of Decision Transformer (DT). Empirical evaluations on the DSRL benchmarks demonstrate the better capacity of SDT in learning safe and high-reward policies compared with existing approaches. In addition, SDT shows good alignment with respect to different desired degrees of satisfaction of the STL specification that it is condi
    
[^63]: 机器学习优化在云计算资源调度与管理中的应用

    Application of Machine Learning Optimization in Cloud Computing Resource Scheduling and Management

    [https://arxiv.org/abs/2402.17216](https://arxiv.org/abs/2402.17216)

    本文提出了一种利用机器学习优化技术解决云计算资源调度与管理中复杂问题的创新方法。

    

    近年来，云计算被广泛应用。云计算是指集中式的计算资源，用户通过访问集中式资源完成计算，云计算中心将程序处理结果返回给用户。云计算不仅适用于个人用户，也适用于企业用户。购买云服务器后，用户无需购买大量计算机，节约了计算成本。根据中国经济新闻网络的报告，中国的云计算规模已达到2091亿元人民币。目前，中国较为成熟的云服务提供商有阿里云、百度云、华为云等。因此，本文提出了一种创新方法，利用机器学习优化技术解决云计算资源调度与管理中的复杂问题。

    arXiv:2402.17216v1 Announce Type: cross  Abstract: In recent years, cloud computing has been widely used. Cloud computing refers to the centralized computing resources, users through the access to the centralized resources to complete the calculation, the cloud computing center will return the results of the program processing to the user. Cloud computing is not only for individual users, but also for enterprise users. By purchasing a cloud server, users do not have to buy a large number of computers, saving computing costs. According to a report by China Economic News Network, the scale of cloud computing in China has reached 209.1 billion yuan. At present, the more mature cloud service providers in China are Ali Cloud, Baidu Cloud, Huawei Cloud and so on. Therefore, this paper proposes an innovative approach to solve complex problems in cloud computing resource scheduling and management using machine learning optimization techniques. Through in-depth study of challenges such as low r
    
[^64]: 基于知识库的图像视觉常识发现（VCD）

    VCD: Knowledge Base Guided Visual Commonsense Discovery in Images

    [https://arxiv.org/abs/2402.17213](https://arxiv.org/abs/2402.17213)

    该论文提出了基于知识库的图像视觉常识发现（VCD）方法，通过定义细粒度的视觉常识类型以及构建包括超过10万张图像和1400万个对象-常识对的数据集，旨在提升计算机视觉系统的推理和决策能力。

    

    图像中的视觉常识包含有关对象属性、关系和行为的知识。发现视觉常识可以提供对图像的更全面和丰富的理解，并增强计算机视觉系统的推理和决策能力。然而，现有的视觉常识发现研究中所定义的视觉常识是粗粒度且不完整的。在这项工作中，我们从自然语言处理中的常识知识库ConceptNet中汲取灵感，并系统地定义了各种类型的视觉常识。基于此，我们引入了一个新任务，即视觉常识发现（VCD），旨在提取图像中不同对象所包含的不同类型的细粒度常识。因此，我们从Visual Genome和ConceptNet中构建了一个名为VCDD的数据集，包括超过10万张图像和1400万个对象-常识对。

    arXiv:2402.17213v1 Announce Type: cross  Abstract: Visual commonsense contains knowledge about object properties, relationships, and behaviors in visual data. Discovering visual commonsense can provide a more comprehensive and richer understanding of images, and enhance the reasoning and decision-making capabilities of computer vision systems. However, the visual commonsense defined in existing visual commonsense discovery studies is coarse-grained and incomplete. In this work, we draw inspiration from a commonsense knowledge base ConceptNet in natural language processing, and systematically define the types of visual commonsense. Based on this, we introduce a new task, Visual Commonsense Discovery (VCD), aiming to extract fine-grained commonsense of different types contained within different objects in the image. We accordingly construct a dataset (VCDD) from Visual Genome and ConceptNet for VCD, featuring over 100,000 images and 14 million object-commonsense pairs. We furthermore pro
    
[^65]: 测量神经模型的视觉语言STEM技能

    Measuring Vision-Language STEM Skills of Neural Models

    [https://arxiv.org/abs/2402.17205](https://arxiv.org/abs/2402.17205)

    该研究引入了一个新挑战，用于测试神经模型的STEM技能，提出了一个包含大量基础技能和问题的数据集，需要理解STEM的多模式视觉语言信息，并展示了最新模型对于低年级技能的有限掌握。

    

    我们引入了一个新挑战，用于测试神经模型的STEM技能。现实世界中的问题通常需要结合STEM（科学、技术、工程和数学）知识来解决。与现有数据集不同，我们的数据集需要理解STEM的多模式视觉语言信息。我们的数据集是挑战性问题中最大、最全面的数据集之一。它包括448项技能和1,073,146个跨越所有STEM科目的问题。与通常侧重于检验专家水平能力的现有数据集不同，我们的数据集包括基础技能和根据K-12课程设计的问题。我们还将最先进的基础模型，如CLIP和GPT-3.5-Turbo，添加到我们的基准中。结果显示，最近的模型进展只有助于掌握数据集中非常有限数量的低年级技能（三年级中的2.5%）。事实上，这些模型仍远没有完全掌握学前教育阶段的技能。

    arXiv:2402.17205v1 Announce Type: cross  Abstract: We introduce a new challenge to test the STEM skills of neural models. The problems in the real world often require solutions, combining knowledge from STEM (science, technology, engineering, and math). Unlike existing datasets, our dataset requires the understanding of multimodal vision-language information of STEM. Our dataset features one of the largest and most comprehensive datasets for the challenge. It includes 448 skills and 1,073,146 questions spanning all STEM subjects. Compared to existing datasets that often focus on examining expert-level ability, our dataset includes fundamental skills and questions designed based on the K-12 curriculum. We also add state-of-the-art foundation models such as CLIP and GPT-3.5-Turbo to our benchmark. Results show that the recent model advances only help master a very limited number of lower grade-level skills (2.5% in the third grade) in our dataset. In fact, these models are still well bel
    
[^66]: AI驱动的匿名化：在利用机器学习的同时保护个人数据隐私

    AI-Driven Anonymization: Protecting Personal Data Privacy While Leveraging Machine Learning

    [https://arxiv.org/abs/2402.17191](https://arxiv.org/abs/2402.17191)

    通过机器学习的差分隐私保护算法，实现个人数据隐私保护和检测。

    

    人工智能的发展显著改变了人们的生活。然而，它也对隐私和安全构成了重大威胁，许多个人信息被公开，并有犯罪攻击和窃取的报道。因此，通过机器学习算法实现个人信息的智能保护已经成为首要关注的问题。人工智能利用先进算法和技术有效加密和匿名化个人数据，实现有价值的数据分析和利用同时维护隐私。本文着眼于个人数据隐私保护和匿名化推广作为其核心研究目标。它通过使用机器学习的差分隐私保护算法实现了个人数据隐私保护和检测。该论文还解决了机器学习领域中现有的挑战。

    arXiv:2402.17191v1 Announce Type: cross  Abstract: The development of artificial intelligence has significantly transformed people's lives. However, it has also posed a significant threat to privacy and security, with numerous instances of personal information being exposed online and reports of criminal attacks and theft. Consequently, the need to achieve intelligent protection of personal information through machine learning algorithms has become a paramount concern. Artificial intelligence leverages advanced algorithms and technologies to effectively encrypt and anonymize personal data, enabling valuable data analysis and utilization while safeguarding privacy. This paper focuses on personal data privacy protection and the promotion of anonymity as its core research objectives. It achieves personal data privacy protection and detection through the use of machine learning's differential privacy protection algorithm. The paper also addresses existing challenges in machine learning rel
    
[^67]: 一种有效的混合专家方法，利用编码器解缠来进行代码切换语音识别

    An Effective Mixture-Of-Experts Approach For Code-Switching Speech Recognition Leveraging Encoder Disentanglement

    [https://arxiv.org/abs/2402.17189](https://arxiv.org/abs/2402.17189)

    通过引入解缠损失并改进声学编码器，本文提出的方法在处理代码切换现象时表现出色，显著优于先前的方法。

    

    随着端到端（E2E）神经网络的大规模发展，近年来自动语音识别（ASR）取得了前所未有的突破。然而，代码切换现象仍然是阻碍ASR完美的主要障碍，因为缺乏标记数据和语言之间的变化经常导致ASR性能下降。在本文中，我们专注于改进E2E ASR的声学编码器，以应对代码切换现象带来的挑战。我们的主要贡献有三个：首先，我们引入了一种新颖的解缠损失，使得编码器的较低层能够捕获跨语言的声学信息，同时在编码器的较高层减轻语言混淆。其次，通过全面的实验，我们验证了我们的方法优于使用预训练双编码器的现有方法，同时只访问代码切换

    arXiv:2402.17189v1 Announce Type: cross  Abstract: With the massive developments of end-to-end (E2E) neural networks, recent years have witnessed unprecedented breakthroughs in automatic speech recognition (ASR). However, the codeswitching phenomenon remains a major obstacle that hinders ASR from perfection, as the lack of labeled data and the variations between languages often lead to degradation of ASR performance. In this paper, we focus exclusively on improving the acoustic encoder of E2E ASR to tackle the challenge caused by the codeswitching phenomenon. Our main contributions are threefold: First, we introduce a novel disentanglement loss to enable the lower-layer of the encoder to capture inter-lingual acoustic information while mitigating linguistic confusion at the higher-layer of the encoder. Second, through comprehensive experiments, we verify that our proposed method outperforms the prior-art methods using pretrained dual-encoders, meanwhile having access only to the codesw
    
[^68]: Sora: 大型视觉模型背景、技术、局限性和机遇的综述

    Sora: A Review on Background, Technology, Limitations, and Opportunities of Large Vision Models

    [https://arxiv.org/abs/2402.17177](https://arxiv.org/abs/2402.17177)

    Sora是一种文本到视频生成的人工智能模型，展示出在模拟物理世界方面的潜力，具有广泛的应用前景和挑战，未来发展具有重要意义。

    

    Sora是由OpenAI于2024年2月发布的一种文本到视频生成的人工智能模型。这个模型经过训练，可以根据文本指令生成逼真或想象的场景视频，并在模拟物理世界方面显示出潜力。本文基于公开的技术报告和逆向工程，对这个模型的背景、相关技术、应用、尚存的挑战以及文本到视频人工智能模型的未来方向进行了全面回顾。首先我们追溯了Sora的发展历程，并调查了用于构建这个"世界模拟器"的基础技术。然后，我们详细描述了Sora在从电影制作和教育到营销等多个行业中的应用和潜在影响。我们讨论了需要解决的主要挑战和局限性，以便广泛部署Sora，如确保安全和无偏见的视频生成。最后，我们讨论了Sora以及视频生成技术未来的发展。

    arXiv:2402.17177v1 Announce Type: cross  Abstract: Sora is a text-to-video generative AI model, released by OpenAI in February 2024. The model is trained to generate videos of realistic or imaginative scenes from text instructions and show potential in simulating the physical world. Based on public technical reports and reverse engineering, this paper presents a comprehensive review of the model's background, related technologies, applications, remaining challenges, and future directions of text-to-video AI models. We first trace Sora's development and investigate the underlying technologies used to build this "world simulator". Then, we describe in detail the applications and potential impact of Sora in multiple industries ranging from film-making and education to marketing. We discuss the main challenges and limitations that need to be addressed to widely deploy Sora, such as ensuring safe and unbiased video generation. Lastly, we discuss the future development of Sora and video gene
    
[^69]: 数据科学代理基准测试

    Benchmarking Data Science Agents

    [https://arxiv.org/abs/2402.17168](https://arxiv.org/abs/2402.17168)

    本文引入了DSEval评估范式和一系列创新基准，用于评估数据科学代理在整个数据科学生命周期中的性能，通过引入自举注释方法简化数据集准备流程，改进评估覆盖范围，扩展基准测试的全面性，揭示了普遍存在的障碍并提供了关键见解

    

    在数据驱动决策的时代，数据分析的复杂性需要数据科学的高级专业知识和工具，这对专家来说也带来了重大挑战。大型语言模型(LLM)作为数据科学代理，已经成为协助人类进行数据分析和处理的有希望的辅助工具。然而，它们的实际有效性仍受限于现实应用的多样需求和复杂的分析过程。在本文中，我们介绍了DSEval--一种新颖的评估范式，以及一系列针对整个数据科学生命周期的代理性能评估的创新基准。通过引入一种新颖的自举注释方法，我们简化了数据集准备流程，改进了评估覆盖范围，并扩展了基准测试的全面性。我们的研究发现揭示了普遍存在的障碍，并提供了关键见解，以指导未来在这一领域的进展。

    arXiv:2402.17168v1 Announce Type: new  Abstract: In the era of data-driven decision-making, the complexity of data analysis necessitates advanced expertise and tools of data science, presenting significant challenges even for specialists. Large Language Models (LLMs) have emerged as promising aids as data science agents, assisting humans in data analysis and processing. Yet their practical efficacy remains constrained by the varied demands of real-world applications and complicated analytical process. In this paper, we introduce DSEval -- a novel evaluation paradigm, as well as a series of innovative benchmarks tailored for assessing the performance of these agents throughout the entire data science lifecycle. Incorporating a novel bootstrapped annotation method, we streamline dataset preparation, improve the evaluation coverage, and expand benchmarking comprehensiveness. Our findings uncover prevalent obstacles and provide critical insights to inform future advancements in the field.
    
[^70]: 大语言模型在参与式城市规划中的应用

    Large Language Model for Participatory Urban Planning

    [https://arxiv.org/abs/2402.17161](https://arxiv.org/abs/2402.17161)

    本研究引入了基于大语言模型的多代理协作框架，用于参与式城市规划，可以生成考虑居民多样化需求的城市土地利用规划。

    

    参与式城市规划是现代城市规划的主流，涉及居民的积极参与。然而，传统的参与式范式需要经验丰富的规划专家，通常耗时且昂贵。幸运的是，新兴的大语言模型(LLMs)已经显示出相当大的能力来模拟类人代理，可以用于轻松模拟参与性过程。在这项工作中，我们引入了一个基于LLM的多代理协作框架，用于参与式城市规划，可以考虑居民的多样化需求生成城市地区的土地利用规划。具体来说，我们构建了LLM代理来模拟规划者和成千上万具有不同背景和特点的居民。我们首先要求规划者制定一项初步土地利用规划。为了解决居民对不同设施需求的问题，我们在每个社区中让居民展开讨论...

    arXiv:2402.17161v1 Announce Type: new  Abstract: Participatory urban planning is the mainstream of modern urban planning that involves the active engagement of residents. However, the traditional participatory paradigm requires experienced planning experts and is often time-consuming and costly. Fortunately, the emerging Large Language Models (LLMs) have shown considerable ability to simulate human-like agents, which can be used to emulate the participatory process easily. In this work, we introduce an LLM-based multi-agent collaboration framework for participatory urban planning, which can generate land-use plans for urban regions considering the diverse needs of residents. Specifically, we construct LLM agents to simulate a planner and thousands of residents with diverse profiles and backgrounds. We first ask the planner to carry out an initial land-use plan. To deal with the different facilities needs of residents, we initiate a discussion among the residents in each community about
    
[^71]: TaxDiff：用于蛋白质序列生成的分类引导扩散模型

    TaxDiff: Taxonomic-Guided Diffusion Model for Protein Sequence Generation

    [https://arxiv.org/abs/2402.17156](https://arxiv.org/abs/2402.17156)

    提出了一种名为TaxDiff的分类引导扩散模型，结合了生物物种信息和扩散模型的生成能力，用于可控生成结构稳定的蛋白质序列。

    

    设计具有特定生物功能和结构稳定性的蛋白质序列在生物学和化学中至关重要。生成模型已经展示了它们在可靠蛋白质设计方面的能力。然而，先前的模型仅限于无条件生成蛋白质序列，缺乏对生物任务至关重要的可控生成能力。在这项工作中，我们提出了TaxDiff，一种用于可控蛋白质序列生成的分类引导扩散模型，它将生物物种信息与扩散模型的生成能力相结合，以在序列空间内生成结构稳定的蛋白质。具体地，分类控制信息被插入到变压器块的每一层，以实现细粒度控制。全局和局部关注的结合确保了分类特定蛋白质的序列一致性和结构可折叠性。广泛的实验...

    arXiv:2402.17156v1 Announce Type: cross  Abstract: Designing protein sequences with specific biological functions and structural stability is crucial in biology and chemistry. Generative models already demonstrated their capabilities for reliable protein design. However, previous models are limited to the unconditional generation of protein sequences and lack the controllable generation ability that is vital to biological tasks. In this work, we propose TaxDiff, a taxonomic-guided diffusion model for controllable protein sequence generation that combines biological species information with the generative capabilities of diffusion models to generate structurally stable proteins within the sequence space. Specifically, taxonomic control information is inserted into each layer of the transformer block to achieve fine-grained control. The combination of global and local attention ensures the sequence consistency and structural foldability of taxonomic-specific proteins. Extensive experimen
    
[^72]: Metasql：一种用于自然语言到SQL翻译的生成-排序框架

    Metasql: A Generate-then-Rank Framework for Natural Language to SQL Translation

    [https://arxiv.org/abs/2402.17144](https://arxiv.org/abs/2402.17144)

    Metasql是一种统一的生成-排序框架，利用查询元数据和学习-排序算法不断提高自然语言到SQL翻译的准确性。

    

    arXiv:2402.17144v1 公告类型:跨学科 摘要: 数据库自然语言接口（NLIDB）通过直观的自然语言（NL）交互使非技术用户能够访问数据库。先进的方法通常利用神经序列到序列模型或大规模语言模型，通常使用自回归解码来逐个生成独特的SQL查询。虽然这些翻译模型大大提高了整体翻译准确性，在NLIDB基准测试中超过了70％，但使用自回归解码生成单个SQL查询可能导致次优输出，潜在导致错误翻译。本文提出了Metasql，一个统一的生成-排序框架，可以灵活与现有NLIDB集成，从而不断提高其翻译准确性。Metasql引入了查询元数据来控制生成更好的SQL查询候选项，并使用学习-排序算法检索全局最优结果。

    arXiv:2402.17144v1 Announce Type: cross  Abstract: The Natural Language Interface to Databases (NLIDB) empowers non-technical users with database access through intuitive natural language (NL) interactions. Advanced approaches, utilizing neural sequence-to-sequence models or large-scale language models, typically employ auto-regressive decoding to generate unique SQL queries sequentially. While these translation models have greatly improved the overall translation accuracy, surpassing 70% on NLIDB benchmarks, the use of auto-regressive decoding to generate single SQL queries may result in sub-optimal outputs, potentially leading to erroneous translations. In this paper, we propose Metasql, a unified generate-then-rank framework that can be flexibly incorporated with existing NLIDBs to consistently improve their translation accuracy. Metasql introduces query metadata to control the generation of better SQL query candidates and uses learning-to-rank algorithms to retrieve globally optimi
    
[^73]: 视频作为真实世界决策的新语言

    Video as the New Language for Real-World Decision Making

    [https://arxiv.org/abs/2402.17139](https://arxiv.org/abs/2402.17139)

    视频生成在解决真实世界任务中具有巨大潜力，类似于语言模型，它可以作为规划者、代理、计算引擎和环境模拟器。

    

    互联网上存在大量文本和视频数据，通过下一个令牌或帧预测支持大规模自监督学习。然而，它们并没有被充分利用：语言模型在现实世界中产生了显著影响，而视频生成在很大程度上仅限于媒体娱乐。然而，视频数据捕捉了关于物理世界的重要信息，这些信息很难用语言表达。为了弥补这一差距，我们讨论了将视频生成扩展到解决真实世界任务的一个被低估的机会。我们观察到，类似于语言，视频可以作为一个统一的接口，可以吸收互联网知识并表示多样化的任务。此外，我们展示了如何通过各种技术（如上下文学习、规划和强化学习）将视频生成用作规划者、代理、计算引擎和环境模拟器。我们确定了一些重要的创新

    arXiv:2402.17139v1 Announce Type: cross  Abstract: Both text and video data are abundant on the internet and support large-scale self-supervised learning through next token or frame prediction. However, they have not been equally leveraged: language models have had significant real-world impact, whereas video generation has remained largely limited to media entertainment. Yet video data captures important information about the physical world that is difficult to express in language. To address this gap, we discuss an under-appreciated opportunity to extend video generation to solve tasks in the real world. We observe how, akin to language, video can serve as a unified interface that can absorb internet knowledge and represent diverse tasks. Moreover, we demonstrate how, like language models, video generation can serve as planners, agents, compute engines, and environment simulators through techniques such as in-context learning, planning and reinforcement learning. We identify major im
    
[^74]: 通过功能奖励编码实现的无监督零样本强化学习

    Unsupervised Zero-Shot Reinforcement Learning via Functional Reward Encodings

    [https://arxiv.org/abs/2402.17135](https://arxiv.org/abs/2402.17135)

    通过功能奖励编码实现的无监督零样本强化学习方法能够在各种模拟机器人基准测试中训练代理并成功解决新任务，相比以往的零样本强化学习方法表现更优秀。

    

    这项工作提出了一种称为功能奖励编码（FRE）的通用、可扩展的解决方案，用于零样本强化学习问题。我们的主要想法是通过使用基于transformer的变分自动编码器对任意任务的状态-奖励样本进行编码，从而学习任意任务的功能表示。这种功能编码不仅使得能够从各种通用无监督奖励函数进行预训练，而且还提供了一种在零样本情况下解决任何新的下游任务的方法，只需少量奖励注释样本。我们在实验中显示，针对多样的随机无监督奖励函数进行训练的FRE代理能够推广到解决一系列模拟机器人基准测试中的新任务，通常优于先前的零样本强化学习方法。

    arXiv:2402.17135v1 Announce Type: cross  Abstract: Can we pre-train a generalist agent from a large amount of unlabeled offline trajectories such that it can be immediately adapted to any new downstream tasks in a zero-shot manner? In this work, we present a functional reward encoding (FRE) as a general, scalable solution to this zero-shot RL problem. Our main idea is to learn functional representations of any arbitrary tasks by encoding their state-reward samples using a transformer-based variational auto-encoder. This functional encoding not only enables the pre-training of an agent from a wide diversity of general unsupervised reward functions, but also provides a way to solve any new downstream tasks in a zero-shot manner, given a small number of reward-annotated samples. We empirically show that FRE agents trained on diverse random unsupervised reward functions can generalize to solve novel tasks in a range of simulated robotic benchmarks, often outperforming previous zero-shot RL
    
[^75]: T-HITL有效解决图像生成中的问题关联并保持总体视觉质量

    T-HITL Effectively Addresses Problematic Associations in Image Generation and Maintains Overall Visual Quality

    [https://arxiv.org/abs/2402.17101](https://arxiv.org/abs/2402.17101)

    本文通过开发一个分类法研究图像生成模型中的问题关联，探讨了在模型级别微调的有效性，并指出了视觉质量降低可能是一个局限性。

    

    生成性人工智能图像模型可能会无意中生成有关人物的问题表征。过去的研究指出，全球有数百万用户每天与这些模型互动，并且这些模型，包括通过有关人物的问题表征，具有可能加剧现实世界中的歧视和其他危害的潜力。 在本文中，我们着重解决人口群体和语义概念之间生成问题关联的问题，这些关联可能反映和强化社会数据中嵌入的负面叙述。在社会学文献（Blumer, 1958）的基础上，通过将表征映射到模型行为，我们开发了一个分类法来研究图像生成模型中的问题关联。我们探讨了在模型级别微调的有效性作为解决这些关联的方法，确定视觉质量降低可能是一个局限性。

    arXiv:2402.17101v1 Announce Type: cross  Abstract: Generative AI image models may inadvertently generate problematic representations of people. Past research has noted that millions of users engage daily across the world with these models and that the models, including through problematic representations of people, have the potential to compound and accelerate real-world discrimination and other harms (Bianchi et al, 2023). In this paper, we focus on addressing the generation of problematic associations between demographic groups and semantic concepts that may reflect and reinforce negative narratives embedded in social data. Building on sociological literature (Blumer, 1958) and mapping representations to model behaviors, we have developed a taxonomy to study problematic associations in image generation models. We explore the effectiveness of fine tuning at the model level as a method to address these associations, identifying a potential reduction in visual quality as a limitation of
    
[^76]: 修复: 在说明后修正LLM响应中的事实错误

    Re-Ex: Revising after Explanation Reduces the Factual Errors in LLM Responses

    [https://arxiv.org/abs/2402.17097](https://arxiv.org/abs/2402.17097)

    提出了一种名为Re-Ex的方法，通过引入事实错误说明步骤来修正LLM生成文本中的事实错误，并提出了新的提示技术来减少所需的标记数量和挂钟时间

    

    缓解幻觉问题是LLM的主要挑战之一，我们需要克服这一挑战，以便可靠地在现实场景中使用它们。最近，提出了各种方法来检查LLM生成的文本中的事实错误，并相应地进行修订，以减少幻觉问题。在本文中，我们提出了Re-Ex，一种修订LLM生成文本的方法，它引入了一个称为事实错误说明步骤的新步骤。 Re-Ex使用3个步骤对LLM的初始响应进行修订：首先，使用外部工具获取响应中事实错误的证据；第二，要求LLM根据第一步中收集的证据解释响应中的问题部分；最后，LLM使用在第二步中获得的解释对响应进行修订。除了说明步骤，我们还提出了新的提示技术，以减少所需的标记数量和挂钟时间。

    arXiv:2402.17097v1 Announce Type: cross  Abstract: Mitigating hallucination issues is one of the main challenges of LLMs we need to overcome, in order to reliably use them in real-world scenarios. Recently, various methods are proposed to check the factual errors in the LLM-generated texts and revise them accordingly, to reduce the hallucination issue. In this paper, we propose Re-Ex, a method of revising LLM-generated texts, which introduces a novel step dubbed as the factual error explanation step. Re-Ex revises the initial response of LLMs using 3-steps: first, external tools are used to get the evidences on the factual errors in the response; second, LLMs are instructed to explain the problematic parts of the response based on the evidences gathered in the first step; finally, LLMs revise the response using the explanation obtained in the second step. In addition to the explanation step, we propose new prompting techniques to reduce the amount of tokens and wall-clock time required
    
[^77]: 关于具有潜在根变量的贝叶斯网络的注解

    A Note on Bayesian Networks with Latent Root Variables

    [https://arxiv.org/abs/2402.17087](https://arxiv.org/abs/2402.17087)

    从贝叶斯网络计算出的数据集的似然性主要由经验网络的似然性的全局最大值所主导，并且仅当贝叶斯网络的参数与经验模型的参数一致时，这样的最大值才会被实现。

    

    我们表征了从具有潜在根节点的贝叶斯网络计算出的似然函数。我们展示了对于剩余的显性变量的边缘分布也会像一个贝叶斯网络一样分解，我们称之为经验化。一组观测到的显性变量的数据集使我们能够量化经验贝叶斯网络的参数。我们证明了(i)从原始贝叶斯网络计算出这样一个数据集的似然性由经验化模型的似然性的全局最大值所主导；以及(ii)这样一个最大值仅在贝叶斯网络的参数与经验模型的参数一致时才会达到。

    arXiv:2402.17087v1 Announce Type: cross  Abstract: We characterise the likelihood function computed from a Bayesian network with latent variables as root nodes. We show that the marginal distribution over the remaining, manifest, variables also factorises as a Bayesian network, which we call empirical. A dataset of observations of the manifest variables allows us to quantify the parameters of the empirical Bayesian net. We prove that (i) the likelihood of such a dataset from the original Bayesian network is dominated by the global maximum of the likelihood from the empirical one; and that (ii) such a maximum is attained if and only if the parameters of the Bayesian network are consistent with those of the empirical model.
    
[^78]: 拆解简单外表：与当地企业家共同设计初级生成 AI 研讨会

    Deconstructing the Veneer of Simplicity: Co-Designing Introductory Generative AI Workshops with Local Entrepreneurs

    [https://arxiv.org/abs/2402.17082](https://arxiv.org/abs/2402.17082)

    通过与当地企业家合作共同设计交互式研讨会，帮助他们了解生成 AI 平台的重要性，支持可操作使用并揭示创业力量。

    

    生成 AI 平台和功能正在渗透工作的许多方面。特别是来自实力薄弱的经济体的企业家由于资源有限，因此很有可能将任务外包给生成 AI。在本文中，我们通过与当地创业中心开展长达四年的合作，致力于解决对这些技术使用的不平等现象。我们共同设计了一系列互动研讨会，旨在帮助当地企业家熟悉生成 AI 平台。除此之外，我们还与15位当地企业家和社区提供者进行了访谈。我们详细介绍了对当地企业家进行团体和支持性曝光的重要性，为他们提供生成 AI 工具的可操作使用（以及对不使用的支持），通过强调创业力量来揭开生成 AI 技术的神秘面纱。

    arXiv:2402.17082v1 Announce Type: cross  Abstract: Generative AI platforms and features are permeating many aspects of work. Entrepreneurs from lean economies in particular are well positioned to outsource tasks to generative AI given limited resources. In this paper, we work to address a growing disparity in use of these technologies by building on a four-year partnership with a local entrepreneurial hub dedicated to equity in tech and entrepreneurship. Together, we co-designed an interactive workshops series aimed to onboard local entrepreneurs to generative AI platforms. Alongside four community-driven and iterative workshops with entrepreneurs across five months, we conducted interviews with 15 local entrepreneurs and community providers. We detail the importance of communal and supportive exposure to generative AI tools for local entrepreneurs, scaffolding actionable use (and supporting non-use), demystifying generative AI technologies by emphasizing entrepreneurial power, while s
    
[^79]: 使用超高维计算进行单次图表示学习

    One-Shot Graph Representation Learning Using Hyperdimensional Computing

    [https://arxiv.org/abs/2402.17073](https://arxiv.org/abs/2402.17073)

    该方法提出了一种使用超高维计算进行单次图表示学习的方法，通过将数据投影到高维空间并利用HD运算符进行信息聚合，实现了与最先进深度学习方法相竞争的预测性能，而无需进行计算昂贵的训练。

    

    我们提出了一种新颖、简单、快速、高效的半监督图学习方法。所提方法利用超高维计算，将数据样本使用随机投影编码到高维空间（简称HD空间）。具体来说，我们提出了一种利用图神经网络节点表示的单射性质的超高维图学习（HDGL）算法。HDGL将节点特征映射到HD空间，然后使用HD运算符（如捆绑和绑定）来聚合每个节点的局部邻域信息。对广泛使用的基准数据集进行的实验结果显示，HDGL实现了与最先进深度学习方法相竞争的预测性能，而无需进行计算昂贵的训练。

    arXiv:2402.17073v1 Announce Type: cross  Abstract: We present a novel, simple, fast, and efficient approach for semi-supervised learning on graphs. The proposed approach takes advantage of hyper-dimensional computing which encodes data samples using random projections into a high dimensional space (HD space for short). Specifically, we propose a Hyper-dimensional Graph Learning (HDGL) algorithm that leverages the injectivity property of the node representations of a family of graph neural networks. HDGL maps node features to the HD space and then uses HD operators such as bundling and binding to aggregate information from the local neighborhood of each node. Results of experiments with widely used benchmark data sets show that HDGL achieves predictive performance that is competitive with the state-of-the-art deep learning methods, without the need for computationally expensive training.
    
[^80]: 驯服类别条件GAN中的长尾问题：通过在较低分辨率进行无条件训练进行知识共享

    Taming the Tail in Class-Conditional GANs: Knowledge Sharing via Unconditional Training at Lower Resolutions

    [https://arxiv.org/abs/2402.17065](https://arxiv.org/abs/2402.17065)

    通过在较低分辨率进行无条件训练，允许长尾类别从信息更丰富的类别中共享知识，以改善长尾数据下类别条件GANs的训练

    

    尽管对于使用有限训练数据训练生成对抗网络（GANs）进行了广泛的研究，但从长尾训练分布生成图像的技术仍然相当未被探索。在存在不平衡的多类别训练数据时，GANs倾向于偏爱样本更多的类别，导致尾部类别的生成低质量且样本不够多样化。在这项研究中，我们旨在改进使用长尾数据训练类别条件GANs。我们提出了一种简单而有效的知识共享方法，允许尾部类别从训练数据更丰富的类别中借鉴丰富的信息。具体地，我们对现有的类别条件GAN架构进行了修改，以确保生成器的较低分辨率层完全无条件地进行训练，同时将类别条件生成保留给较高分辨率层。在多个实验中进行了实验

    arXiv:2402.17065v1 Announce Type: cross  Abstract: Despite the extensive research on training generative adversarial networks (GANs) with limited training data, learning to generate images from long-tailed training distributions remains fairly unexplored. In the presence of imbalanced multi-class training data, GANs tend to favor classes with more samples, leading to the generation of low-quality and less diverse samples in tail classes. In this study, we aim to improve the training of class-conditional GANs with long-tailed data. We propose a straightforward yet effective method for knowledge sharing, allowing tail classes to borrow from the rich information from classes with more abundant training data. More concretely, we propose modifications to existing class-conditional GAN architectures to ensure that the lower-resolution layers of the generator are trained entirely unconditionally while reserving class-conditional generation for the higher-resolution layers. Experiments on seve
    
[^81]: 对各类网络攻击检测的最先进机器学习方法性能的研究：一项调查

    An Investigation into the Performances of the State-of-the-art Machine Learning Approaches for Various Cyber-attack Detection: A Survey

    [https://arxiv.org/abs/2402.17045](https://arxiv.org/abs/2402.17045)

    分析了过去10年针对不同类型网络攻击检测的各种最先进机器学习模型，着重比较了最新的工作。

    

    为了保护计算机和信息系统免受攻击者利用系统中的漏洞进行网络犯罪的侵害，已经提出了几种用于实时检测漏洞以提高信息系统安全性的方法。在所有提出的方法中，机器学习是实现系统安全的效果最好的方法，其能力范围从早期检测软件漏洞到实时检测系统中正在进行的妥协。由于存在不同类型的网络攻击，每种现有最先进的机器学习模型都依赖于不同的训练算法，这也影响了它们对特定类型网络攻击的适用性。在这项研究中，我们分析了过去10年针对不同类型网络攻击检测的每一个当前最先进的机器学习模型，重点放在最近的工作上以进行比较。

    arXiv:2402.17045v1 Announce Type: cross  Abstract: To secure computers and information systems from attackers taking advantage of vulnerabilities in the system to commit cybercrime, several methods have been proposed for real-time detection of vulnerabilities to improve security around information systems. Of all the proposed methods, machine learning had been the most effective method in securing a system with capabilities ranging from early detection of software vulnerabilities to real-time detection of ongoing compromise in a system. As there are different types of cyberattacks, each of the existing state-of-the-art machine learning models depends on different algorithms for training which also impact their suitability for detection of a particular type of cyberattack. In this research, we analyzed each of the current state-of-theart machine learning models for different types of cyberattack detection from the past 10 years with a major emphasis on the most recent works for comparat
    
[^82]: 通向从试验推广推理到目标种群的泛化

    Towards Generalizing Inferences from Trials to Target Populations

    [https://arxiv.org/abs/2402.17042](https://arxiv.org/abs/2402.17042)

    本研究在试图解决从试验结果推广到目标种群的外部有效性挑战方面取得了重要进展

    

    随机对照试验（RCTs）在产生内部有效估计方面起着至关重要的作用，而对扩展这些发现以获得外部有效估计至关重要，以促进更广泛的科学探究。本文探讨了应对这些外部有效性挑战的前沿，概括了2023年秋季在布朗大学计算与实验数学研究所（ICERM）举行的一次跨学科研讨会的精华。该研讨会汇集了来自社会科学、医学、公共卫生、统计学、计算机科学和教育等各个领域的专家，以解决每个学科在推断实验结果方面面临的独特障碍。我们的研究提出了三个关键贡献：我们整合正在进行的努力，突出了

    arXiv:2402.17042v1 Announce Type: cross  Abstract: Randomized Controlled Trials (RCTs) are pivotal in generating internally valid estimates with minimal assumptions, serving as a cornerstone for researchers dedicated to advancing causal inference methods. However, extending these findings beyond the experimental cohort to achieve externally valid estimates is crucial for broader scientific inquiry. This paper delves into the forefront of addressing these external validity challenges, encapsulating the essence of a multidisciplinary workshop held at the Institute for Computational and Experimental Research in Mathematics (ICERM), Brown University, in Fall 2023. The workshop congregated experts from diverse fields including social science, medicine, public health, statistics, computer science, and education, to tackle the unique obstacles each discipline faces in extrapolating experimental findings. Our study presents three key contributions: we integrate ongoing efforts, highlighting me
    
[^83]: 从证明中提取定理的学习

    REFACTOR: Learning to Extract Theorems from Proofs

    [https://arxiv.org/abs/2402.17032](https://arxiv.org/abs/2402.17032)

    提出了一种名为REFACTOR的新方法，用于训练神经网络从证明中提取定理，新定理的引入帮助缩短证明长度并提高证明效率。

    

    人类数学家通常擅长识别模块化和可重用的定理，这些定理使复杂的数学结果易于获得。在本文中，我们提出了一个名为“定理从证明中提取器（REFACTOR）”的新方法，用于训练神经网络模仿这种形式数学定理证明的能力。我们展示了在一组未见证明上，REFACTOR能够提取出人类在写证明时会使用的19.6%的定理。当将模型应用于现有的Metamath库时，REFACTOR提取出了16个新定理。通过新提取的定理，我们展示了MetaMath数据库中的现有证明可以被重构。经重构后，这些新定理被非常频繁地使用，平均使用次数为733.5次，并有助于缩短证明长度。最后，我们展示了在经过新定理重构的数据集上训练的证明者证明了更多测试定理，并通过频繁利用超越了最先进的基准模型。

    arXiv:2402.17032v1 Announce Type: new  Abstract: Human mathematicians are often good at recognizing modular and reusable theorems that make complex mathematical results within reach. In this paper, we propose a novel method called theoREm-from-prooF extrACTOR (REFACTOR) for training neural networks to mimic this ability in formal mathematical theorem proving. We show on a set of unseen proofs, REFACTOR is able to extract 19.6% of the theorems that humans would use to write the proofs. When applying the model to the existing Metamath library, REFACTOR extracted 16 new theorems. With newly extracted theorems, we show that the existing proofs in the MetaMath database can be refactored. The new theorems are used very frequently after refactoring, with an average usage of 733.5 times, and help shorten the proof lengths. Lastly, we demonstrate that the prover trained on the new-theorem refactored dataset proves more test theorems and outperforms state-of-the-art baselines by frequently lever
    
[^84]: 通过完全卷积和可微的前端与跳跃连接对梯度攻击表现出显著韧性的耐人寻味案例

    A Curious Case of Remarkable Resilience to Gradient Attacks via Fully Convolutional and Differentiable Front End with a Skip Connection

    [https://arxiv.org/abs/2402.17018](https://arxiv.org/abs/2402.17018)

    通过在神经模型中引入不同iable和完全卷积的前端模型，并结合跳跃连接，成功实现对梯度攻击的显著韧性，并通过将模型组合成随机集合，有效对抗黑盒攻击。

    

    我们测试了通过在一个冻结的分类器之前增加一个可微且完全卷积的模型，并具有跳跃连接的前端增强神经模型。通过使用较小的学习率进行大约一个epoch的训练，我们获得了一些模型，这些模型在保持骨干分类器准确性的同时，对包括AutoAttack软件包中的APGD和FAB-T攻击在内的梯度攻击具有异常的抵抗力，这归因于梯度掩盖。梯度掩盖现象并不新鲜，但对于这些没有梯度破坏部分（如JPEG压缩或预计导致梯度减小的部分）的完全可微模型来说，掩盖的程度相当显著。尽管黑盒攻击对梯度掩盖可能部分有效，但通过将模型组合成随机集合，可以轻松击败它们。我们估计这样的集合在CIFAR10和CIF等上实现了几乎SOTA级别的AutoAttack准确性。

    arXiv:2402.17018v1 Announce Type: cross  Abstract: We tested front-end enhanced neural models where a frozen classifier was prepended by a differentiable and fully convolutional model with a skip connection. By training them using a small learning rate for about one epoch, we obtained models that retained the accuracy of the backbone classifier while being unusually resistant to gradient attacks including APGD and FAB-T attacks from the AutoAttack package, which we attributed to gradient masking. The gradient masking phenomenon is not new, but the degree of masking was quite remarkable for fully differentiable models that did not have gradient-shattering components such as JPEG compression or components that are expected to cause diminishing gradients.   Though black box attacks can be partially effective against gradient masking, they are easily defeated by combining models into randomized ensembles. We estimate that such ensembles achieve near-SOTA AutoAttack accuracy on CIFAR10, CIF
    
[^85]: 多任务对比学习用于8192标记的双语文本嵌入

    Multi-Task Contrastive Learning for 8192-Token Bilingual Text Embeddings

    [https://arxiv.org/abs/2402.17016](https://arxiv.org/abs/2402.17016)

    通过引入独特的多任务学习目标，研究者设计了用于支持英语和其他目标语言的最先进的双语文本嵌入模型，显著提高了模型在STS任务上的表现，同时在目标语言理解和跨语言评估任务中超越了现有多语言模型。

    

    我们引入了一套新颖的最先进的双语文本嵌入模型，旨在支持英语和另一种目标语言。这些模型能够处理长达8192个标记的文本输入，因此非常适用于一系列自然语言处理任务，如文本检索、聚类和语义文本相似度（STS）计算。通过专注于双语模型并引入独特的多任务学习目标，我们显著改善了在STS任务上的模型表现，超过了现有多语言模型在目标语言理解和跨语言评估任务方面的能力。此外，我们的双语模型更加高效，需要较少的参数和更少的内存，因为它们需要较小的词汇量。此外，我们还扩展了大规模文本嵌入基准（MTEB），包括德语和西班牙语嵌入的基准。

    arXiv:2402.17016v1 Announce Type: cross  Abstract: We introduce a novel suite of state-of-the-art bilingual text embedding models that are designed to support English and another target language. These models are capable of processing lengthy text inputs with up to 8192 tokens, making them highly versatile for a range of natural language processing tasks such as text retrieval, clustering, and semantic textual similarity (STS) calculations.   By focusing on bilingual models and introducing a unique multi-task learning objective, we have significantly improved the model performance on STS tasks, which outperforms the capabilities of existing multilingual models in both target language understanding and cross-lingual evaluation tasks. Moreover, our bilingual models are more efficient, requiring fewer parameters and less memory due to their smaller vocabulary needs. Furthermore, we have expanded the Massive Text Embedding Benchmark (MTEB) to include benchmarks for German and Spanish embed
    
[^86]: 在瑞士司法预测中实现可解释性和公平性：在一个多语言数据集上进行基准测试

    Towards Explainability and Fairness in Swiss Judgement Prediction: Benchmarking on a Multilingual Dataset

    [https://arxiv.org/abs/2402.17013](https://arxiv.org/abs/2402.17013)

    本研究深入探讨了在瑞士司法预测中实现可解释性和公平性的重要性，利用了唯一可用的多语言LJP数据集，并对最新的单语和多语BERT-based LJP模型进行了可解释性能评估。

    

    arXiv:2402.17013v1 公告类型：跨领域 摘要：对法律裁决预测（LJP）系统中的可解释性进行评估在构建值得信赖和透明系统方面至关重要，特别是考虑到这些系统依赖可能缺乏法律相关性或涉及敏感属性的因素。本研究深入探讨了LJP模型中可解释性和公平性的领域，利用瑞士裁决预测（SJP）这一唯一可用的多语言LJP数据集。我们整理了一个包括108个案例的支持和反对法律专家裁决的理由的全面收集，在德语、法语和意大利语中提供。通过采用基于遮挡的可解释性方法，我们评估了最新的单语和多语BERT-based LJP模型的可解释性表现，以及利用数据增强和跨语言转移等技术开发的模型，这些模型展示了预测性能的提高。值得注意的是，我们的发现

    arXiv:2402.17013v1 Announce Type: cross  Abstract: The assessment of explainability in Legal Judgement Prediction (LJP) systems is of paramount importance in building trustworthy and transparent systems, particularly considering the reliance of these systems on factors that may lack legal relevance or involve sensitive attributes. This study delves into the realm of explainability and fairness in LJP models, utilizing Swiss Judgement Prediction (SJP), the only available multilingual LJP dataset. We curate a comprehensive collection of rationales that `support' and `oppose' judgement from legal experts for 108 cases in German, French, and Italian. By employing an occlusion-based explainability approach, we evaluate the explainability performance of state-of-the-art monolingual and multilingual BERT-based LJP models, as well as models developed with techniques such as data augmentation and cross-lingual transfer, which demonstrated prediction performance improvement. Notably, our finding
    
[^87]: Pandora's White-Box：开放LLMs中训练数据泄漏的增加

    Pandora's White-Box: Increased Training Data Leakage in Open LLMs

    [https://arxiv.org/abs/2402.17012](https://arxiv.org/abs/2402.17012)

    本文对开源大型语言模型（LLMs）进行了隐私攻击研究，提出了首个能同时实现高真正率和低误分类率的预训练LLMs会员推理攻击（MIAs），以及展示了在自然环境中可以从微调LLM中提取超过50%的微调数据集。

    

    在本文中，我们对开源的大型语言模型（LLMs）遭受的隐私攻击进行了系统研究，其中对手可以访问模型权重、梯度或损失，试图利用它们来了解底层训练数据。我们的主要结果是针对预训练LLMs的第一个会员推理攻击（MIAs），能够同时实现高TPR和低FPR，并展示了在自然环境中可以从微调LLM中提取超过50%的微调数据集。我们考虑了对底层模型的不同访问程度、语言模型的定制化以及攻击者可以使用的资源。在预训练设置中，我们提出了三种新的白盒MIAs：基于梯度范数的攻击、监督神经网络分类器和单步损失比攻击。所有这些都优于现有的黑盒基线，并且我们的.....

    arXiv:2402.17012v1 Announce Type: cross  Abstract: In this paper we undertake a systematic study of privacy attacks against open source Large Language Models (LLMs), where an adversary has access to either the model weights, gradients, or losses, and tries to exploit them to learn something about the underlying training data. Our headline results are the first membership inference attacks (MIAs) against pre-trained LLMs that are able to simultaneously achieve high TPRs and low FPRs, and a pipeline showing that over $50\%$ (!) of the fine-tuning dataset can be extracted from a fine-tuned LLM in natural settings. We consider varying degrees of access to the underlying model, customization of the language model, and resources available to the attacker. In the pre-trained setting, we propose three new white-box MIAs: an attack based on the gradient norm, a supervised neural network classifier, and a single step loss ratio attack. All outperform existing black-box baselines, and our supervi
    
[^88]: 大型语言模型能像人类一样回忆参考位置吗？

    Can Large Language Models Recall Reference Location Like Humans?

    [https://arxiv.org/abs/2402.17010](https://arxiv.org/abs/2402.17010)

    本文探讨了大型语言模型如何利用预训练阶段的知识回忆参考段落，提出了一个两阶段框架模拟人类回忆参考的过程。

    

    在完成知识密集型任务时，人类有时不仅需要一个答案，还需要相应的参考段落供辅助阅读。先前的方法需要通过额外的检索模型获取预分段的文章块。本文探讨了利用大型语言模型（LLMs）的预训练阶段存储的参数化知识，独立于任何起始位置回忆参考段落。我们提出了一个模拟人类回忆易被遗忘参考的情景的两阶段框架。首先，LLM被提示回忆文档标题标识符以获取粗粒度文档集。然后，基于获得的粗粒度文档集，它回忆细粒度段落。在两阶段回忆过程中，我们使用约束解码来确保不生成存储文档之外的内容。为了增加速度，我们只回忆短前缀。

    arXiv:2402.17010v1 Announce Type: cross  Abstract: When completing knowledge-intensive tasks, humans sometimes need not just an answer but also a corresponding reference passage for auxiliary reading. Previous methods required obtaining pre-segmented article chunks through additional retrieval models. This paper explores leveraging the parameterized knowledge stored during the pre-training phase of large language models (LLMs) to independently recall reference passage from any starting position. We propose a two-stage framework that simulates the scenario of humans recalling easily forgotten references. Initially, the LLM is prompted to recall document title identifiers to obtain a coarse-grained document set. Then, based on the acquired coarse-grained document set, it recalls fine-grained passage. In the two-stage recall process, we use constrained decoding to ensure that content outside of the stored documents is not generated. To increase speed, we only recall a short prefix in the 
    
[^89]: 在临床试验中监测在线强化学习算法的准确性

    Monitoring Fidelity of Online Reinforcement Learning Algorithms in Clinical Trials

    [https://arxiv.org/abs/2402.17003](https://arxiv.org/abs/2402.17003)

    提出了算法准确性作为在临床试验中部署在线RL算法的关键要求，强调了对参与者保护和数据科学效用的保留责任，并提出了一个框架进行预部署规划和实时监测以确保算法准确性。

    

    在线强化学习（RL）算法为个性化临床试验中参与者的治疗提供了巨大潜力。然而，在高风险医疗领域部署在线自主算法使得质量控制和数据质量特别难以实现。本文提出了作为在临床试验中部署在线RL算法的关键要求的算法准确性。它强调了算法对（1）保护参与者和（2）保留数据在试验后分析中的科学效用的责任。我们还提出了一个用于部署前规划和实时监测的框架，以协助算法开发者和临床研究人员确保算法的准确性。为了说明我们框架的实际应用，我们介绍了来自Oralytics临床试验的真实案例。自2023年春季以来，这项试验成功地部署了一种自主的在线RL算法来进行个

    arXiv:2402.17003v1 Announce Type: cross  Abstract: Online reinforcement learning (RL) algorithms offer great potential for personalizing treatment for participants in clinical trials. However, deploying an online, autonomous algorithm in the high-stakes healthcare setting makes quality control and data quality especially difficult to achieve. This paper proposes algorithm fidelity as a critical requirement for deploying online RL algorithms in clinical trials. It emphasizes the responsibility of the algorithm to (1) safeguard participants and (2) preserve the scientific utility of the data for post-trial analyses. We also present a framework for pre-deployment planning and real-time monitoring to help algorithm developers and clinical researchers ensure algorithm fidelity. To illustrate our framework's practical application, we present real-world examples from the Oralytics clinical trial. Since Spring 2023, this trial successfully deployed an autonomous, online RL algorithm to persona
    
[^90]: 语言模型听到了什么？探究语言模型中的听觉表征

    What Do Language Models Hear? Probing for Auditory Representations in Language Models

    [https://arxiv.org/abs/2402.16998](https://arxiv.org/abs/2402.16998)

    通过训练一个线性探针，将语言模型中的文本表示和预训练音频模型中的声音表示联系在一起，研究发现尽管仅在原始文本上进行训练，语言模型对于一些对象的声音知识有着基于实质的编码。

    

    这项工作探讨了语言模型是否对物体的声音具有含义深刻且基于实质的表征。我们学习了一个线性探针，通过一个预训练的音频模型给出一个对象的声音表示，从而在给定与该对象相关的音频片段的情况下检索出该对象的正确文本表示。这个探针是通过对比损失进行训练的，推动对象的语言表示和声音表示彼此接近。在训练之后，我们测试了探针对于一些在训练中没有见过的对象的泛化能力。在不同的语言模型和音频模型中，我们发现在许多情况下探针的泛化能力超过了随机猜测的水平，这表明尽管仅在原始文本上进行训练，语言模型对于一些对象的声音知识具有基于实质的编码。

    arXiv:2402.16998v1 Announce Type: cross  Abstract: This work explores whether language models encode meaningfully grounded representations of sounds of objects. We learn a linear probe that retrieves the correct text representation of an object given a snippet of audio related to that object, where the sound representation is given by a pretrained audio model. This probe is trained via a contrastive loss that pushes the language representations and sound representations of an object to be close to one another. After training, the probe is tested on its ability to generalize to objects that were not seen during training. Across different language models and audio models, we find that the probe generalization is above chance in many cases, indicating that despite being trained only on raw text, language models encode grounded knowledge of sounds for some objects.
    
[^91]: GEM3D：三维形状合成的生成媒体抽象

    GEM3D: GEnerative Medial Abstractions for 3D Shape Synthesis

    [https://arxiv.org/abs/2402.16994](https://arxiv.org/abs/2402.16994)

    GEM3D提出了一种新的深度、拓扑感知的三维形状生成模型，通过神经骨架编码了拓扑和几何信息，通过骨架驱动的神经隐式公式生成准确和多样化的表面。

    

    我们介绍了GEM3D——一种新的深度、拓扑感知的三维形状生成模型。我们方法的关键部分是基于神经骨架的表示，编码了关于形状拓扑和几何的信息。通过一个去噪扩散概率模型，我们的方法首先生成遵循中轴变换（MAT）的基于骨架的表示，然后通过一个骨架驱动的神经隐式公式生成表面。神经隐式考虑了在生成的骨架表示中存储的拓扑和几何信息，产生的表面与之前的神经场公式相比更加拓扑和几何准确。我们讨论了我们的方法在形状合成和点云重建任务中的应用，并对我们的方法进行了定性和定量评估。我们展示了比以前更为准确和多样化的形状重建。

    arXiv:2402.16994v1 Announce Type: cross  Abstract: We introduce GEM3D -- a new deep, topology-aware generative model of 3D shapes. The key ingredient of our method is a neural skeleton-based representation encoding information on both shape topology and geometry. Through a denoising diffusion probabilistic model, our method first generates skeleton-based representations following the Medial Axis Transform (MAT), then generates surfaces through a skeleton-driven neural implicit formulation. The neural implicit takes into account the topological and geometric information stored in the generated skeleton representations to yield surfaces that are more topologically and geometrically accurate compared to previous neural field formulations. We discuss applications of our method in shape synthesis and point cloud reconstruction tasks, and evaluate our method both qualitatively and quantitatively. We demonstrate significantly more faithful surface reconstruction and diverse shape generation r
    
[^92]: 通过突出潜在错误并建议纠正成功引导人类做出决策的不完美说明

    Successfully Guiding Humans with Imperfect Instructions by Highlighting Potential Errors and Suggesting Corrections

    [https://arxiv.org/abs/2402.16973](https://arxiv.org/abs/2402.16973)

    通过检测潜在幻觉并建议替代方案的通信机制，成功减少人类导航错误高达29%而不增加认知负担

    

    本文解决了利用不完美语言模型来在基于定位导航任务的背景下引导人类决策的挑战。我们展示了不完美的说明生成模型可以通过有效的通信机制来更成功地引导人类。我们构建的通信机制包括可以检测说明中潜在幻觉并建议实际替代方案的模型，以及一个直观的界面将该信息呈现给用户。我们展示了这种方法可以将人类导航错误降低高达29%，而不增加额外的认知负担。这一结果突显了将多样化的通信渠道整合到AI系统中来弥补其缺陷并增强其对人类的实用性的潜力。

    arXiv:2402.16973v1 Announce Type: new  Abstract: This paper addresses the challenge of leveraging imperfect language models to guide human decision-making in the context of a grounded navigation task. We show that an imperfect instruction generation model can be complemented with an effective communication mechanism to become more successful at guiding humans. The communication mechanism we build comprises models that can detect potential hallucinations in instructions and suggest practical alternatives, and an intuitive interface to present that information to users. We show that this approach reduces the human navigation error by up to 29% with no additional cognitive burden. This result underscores the potential of integrating diverse communication channels into AI systems to compensate for their imperfections and enhance their utility for humans.
    
[^93]: 大型语言模型在网络安全中的调查

    A Survey of Large Language Models in Cybersecurity

    [https://arxiv.org/abs/2402.16968](https://arxiv.org/abs/2402.16968)

    大型语言模型在网络安全领域的应用及其局限性的调查和展望。

    

    大型语言模型(LLMs)迅速崛起，因其能够在多个领域以接近或达到最先进水平的表现，并处理自然语言。研究的一个重要领域是将这些模型应用于网络安全领域。本调查旨在确定在网络安全领域LLMs已经被应用的地方，它们被用于的方式以及它们在该领域中的局限性。最后，提出了如何改善这些局限性以及在克服这些局限性后可以从这些系统中期待什么的建议。

    arXiv:2402.16968v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have quickly risen to prominence due to their ability to perform at or close to the state-of-the-art in a variety of fields while handling natural language. An important field of research is the application of such models at the cybersecurity context. This survey aims to identify where in the field of cybersecurity LLMs have already been applied, the ways in which they are being used and their limitations in the field. Finally, suggestions are made on how to improve such limitations and what can be expected from these systems once these limitations are overcome.
    
[^94]: WIPI: 一种新的用于LLM驱动Web代理的网络威胁

    WIPI: A New Web Threat for LLM-Driven Web Agents

    [https://arxiv.org/abs/2402.16965](https://arxiv.org/abs/2402.16965)

    WIPI是一种新型威胁，可以间接控制Web代理执行恶意指令，从而提高攻击的效率和隐蔽性

    

    随着大型语言模型（LLMs）的快速发展，LLM驱动的Web代理（简称Web代理）由于其优越的能力而受到广泛关注，其中LLMs作为决策的核心部分，类似于人脑，配备了多个网络工具，可以与外部部署的网站进行积极交互。随着无数Web代理的发布，这种LLM系统正在快速发展，并且逐渐接近在我们日常生活中的广泛部署，一个重要而迫切的问题出现了：“这些Web代理安全吗？”在本文中，我们介绍了一种新型威胁WIPI，它间接控制Web代理执行嵌入在公开可访问网页中的恶意指令。为了成功启动WIPI，需要在黑盒环境中工作。这种方法关注于外部网页中间接指令的形式和内容，增强了攻击的效率和隐蔽性。

    arXiv:2402.16965v1 Announce Type: cross  Abstract: With the fast development of large language models (LLMs), LLM-driven Web Agents (Web Agents for short) have obtained tons of attention due to their superior capability where LLMs serve as the core part of making decisions like the human brain equipped with multiple web tools to actively interact with external deployed websites. As uncountable Web Agents have been released and such LLM systems are experiencing rapid development and drawing closer to widespread deployment in our daily lives, an essential and pressing question arises: "Are these Web Agents secure?". In this paper, we introduce a novel threat, WIPI, that indirectly controls Web Agent to execute malicious instructions embedded in publicly accessible webpages. To launch a successful WIPI works in a black-box environment. This methodology focuses on the form and content of indirect instructions within external webpages, enhancing the efficiency and stealthiness of the attack
    
[^95]: FedReview: 一种用于拒绝毒化更新的联邦学习审查机制

    FedReview: A Review Mechanism for Rejecting Poisoned Updates in Federated Learning

    [https://arxiv.org/abs/2402.16934](https://arxiv.org/abs/2402.16934)

    提出了FedReview机制，通过随机分配评审员客户端来识别和拒绝联邦学习中的潜在毒化更新，并采用多数表决机制来整合排名并移除这些更新。

    

    Federated learning最近已经被提出作为一种去中心化的方法，在不访问用户数据的情况下学习一个高性能模型。尽管其有效性，但联邦学习给恶意用户提供了机会通过向服务器上传毒化模型更新来操纵模型。在本文中，我们提出了一种名为FedReview的审查机制，用于识别和拒绝联邦学习中潜在的毒化更新。在我们的机制下，服务器每轮随机分配子集客户端作为评审员，在其训练数据集上评估模型更新。评审员根据评价结果对模型更新进行排名，统计相对低质量的更新数量作为估计的毒化更新数量。基于审查报告，服务器采用多数表决机制整合排名并在模型聚合过程中去除潜在的毒化更新。

    arXiv:2402.16934v1 Announce Type: cross  Abstract: Federated learning has recently emerged as a decentralized approach to learn a high-performance model without access to user data. Despite its effectiveness, federated learning gives malicious users opportunities to manipulate the model by uploading poisoned model updates to the server. In this paper, we propose a review mechanism called FedReview to identify and decline the potential poisoned updates in federated learning. Under our mechanism, the server randomly assigns a subset of clients as reviewers to evaluate the model updates on their training datasets in each round. The reviewers rank the model updates based on the evaluation results and count the number of the updates with relatively low quality as the estimated number of poisoned updates. Based on review reports, the server employs a majority voting mechanism to integrate the rankings and remove the potential poisoned updates in the model aggregation process. Extensive evalu
    
[^96]: 使用人类概念形成避免视觉分类中的灾难性遗忘

    Avoiding Catastrophic Forgetting in Visual Classification Using Human Concept Formation

    [https://arxiv.org/abs/2402.16933](https://arxiv.org/abs/2402.16933)

    提出了一种名为Cobweb4V的新颖视觉分类方法，利用人类类似学习系统，避免了灾难性遗忘效应，与传统方法相比，需要更少的数据来实现有效学习成果，并保持稳定性能。

    

    深度神经网络在机器学习中表现出色，特别是在视觉任务中，然而，当按顺序学习新任务时，它们经常面临灾难性遗忘。本研究提出了Cobweb4V，这是一种新颖的视觉分类方法，它基于Cobweb，这是一种人类类似的学习系统，受到人类随时间逐渐学习新概念的启发。我们进行了全面评估，展示了Cobweb4V在学习视觉概念方面的熟练程度，相较于传统方法，需要更少的数据来实现有效的学习成果，随时间保持稳定的性能，并实现了令人称赞的渐近行为，避免了灾难性遗忘效应。这些特征与人类认知中的学习策略一致，将Cobweb4V定位为神经网络方法的一个有前途的替代方案。

    arXiv:2402.16933v1 Announce Type: cross  Abstract: Deep neural networks have excelled in machine learning, particularly in vision tasks, however, they often suffer from catastrophic forgetting when learning new tasks sequentially. In this work, we propose Cobweb4V, a novel visual classification approach that builds on Cobweb, a human like learning system that is inspired by the way humans incrementally learn new concepts over time. In this research, we conduct a comprehensive evaluation, showcasing the proficiency of Cobweb4V in learning visual concepts, requiring less data to achieve effective learning outcomes compared to traditional methods, maintaining stable performance over time, and achieving commendable asymptotic behavior, without catastrophic forgetting effects. These characteristics align with learning strategies in human cognition, positioning Cobweb4V as a promising alternative to neural network approaches.
    
[^97]: LangGPT：重新思考面向LLMs的结构化可重复使用提示设计框架从编程语言出发

    LangGPT: Rethinking Structured Reusable Prompt Design Framework for LLMs from the Programming Language

    [https://arxiv.org/abs/2402.16929](https://arxiv.org/abs/2402.16929)

    LangGPT提出了一个双层提示设计框架，作为LLMs的编程语言，大大增强了LLMs产生高质量响应的能力，并在引导LLMs生成高质量提示方面具有显著效果。

    

    LLMs已经展示出在不同领域取得了令人瞩目的性能。然而，为了有效指导LLMs制定高质量的提示对于非AI专家来说是一个挑战。现有的提示工程研究建议了一些略显零碎的优化原则和设计，以及凭经验依赖的提示优化器。不幸的是，这些努力缺乏一个结构化的设计模板，导致学习成本高，重复使用性低。受结构化可重复使用的编程语言的启发，我们提出了LangGPT，作为LLMs的编程语言的双层提示设计框架。LangGPT具有易于学习的规范结构，并提供了一个扩展结构以进行迁移和重用。实验证明，与基准相比，LangGPT显著增强了LLMs产生高质量响应的能力。此外，LangGPT已被证明在引导LLMs生成高质量提示方面是有效的。

    arXiv:2402.16929v1 Announce Type: cross  Abstract: LLMs have demonstrated commendable performance across diverse domains. Nevertheless, formulating high-quality prompts to effectively instruct LLMs poses a challenge for non-AI experts. Existing research in prompt engineering suggests somewhat fragmented optimization principles and designs empirically dependent prompt optimizers. Unfortunately, these endeavors lack a structured design template, incurring high learning costs and resulting in low reusability. Inspired by structured reusable programming languages, we propose LangGPT, a dual-layer prompt design framework as the programming language for LLMs. LangGPT has an easy-to-learn normative structure and provides an extended structure for migration and reuse. Experiments illustrate that LangGPT significantly enhances the capacity of LLMs to produce responses of superior quality compared to baselines. Moreover, LangGPT has proven effective in guiding LLMs to generate high-quality promp
    
[^98]: 使用自然语言监督学习可转移的二进制代码表示的CLAP

    CLAP: Learning Transferable Binary Code Representations with Natural Language Supervision

    [https://arxiv.org/abs/2402.16928](https://arxiv.org/abs/2402.16928)

    CLAP通过自然语言监督学习二进制代码的转移表示，提高了在少样本和零样本情景下的迁移性能。

    

    二进制代码表示学习在二进制分析任务中显示出显著性能。但现有解决方案在迁移性上往往较差，特别是在少样本和零样本情景下，任务的训练样本很少或不存在时。为了解决这个问题，我们提出了CLAP（对比语言-汇编预训练），它利用自然语言监督来学习更好的二进制代码（即汇编代码）表示，并获得更好的迁移性。从核心上讲，我们的方法通过有效地将二进制代码与它们的语义解释（自然语言中）相对齐，提高了卓越的迁移学习能力，从而使模型能够为二进制代码生成更好的嵌入。为了实现这种对齐训练，我们随后提出了一种能够自动生成大量和多样化的数据集的高效数据集引擎，包括二进制代码和相应的自然语言解释。

    arXiv:2402.16928v1 Announce Type: cross  Abstract: Binary code representation learning has shown significant performance in binary analysis tasks. But existing solutions often have poor transferability, particularly in few-shot and zero-shot scenarios where few or no training samples are available for the tasks. To address this problem, we present CLAP (Contrastive Language-Assembly Pre-training), which employs natural language supervision to learn better representations of binary code (i.e., assembly code) and get better transferability. At the core, our approach boosts superior transfer learning capabilities by effectively aligning binary code with their semantics explanations (in natural language), resulting a model able to generate better embeddings for binary code. To enable this alignment training, we then propose an efficient dataset engine that could automatically generate a large and diverse dataset comprising of binary code and corresponding natural language explanations. We 
    
[^99]: 机器学习后门检测的可行性问题作为假设检验问题的探讨

    On the (In)feasibility of ML Backdoor Detection as an Hypothesis Testing Problem

    [https://arxiv.org/abs/2402.16926](https://arxiv.org/abs/2402.16926)

    提出了机器学习系统中后门检测问题的正式统计定义，并得出了后门检测的不可能性与可实现性结果，指出了通用后门检测的局限性，强调后门检测方法需要考虑敌对因素。

    

    我们提出了一种正式的统计学定义，用于分析机器学习系统中的后门检测问题的可行性，并使用它来分析这些问题的可行性，提供了对我们定义的实用性和适用性的证据。这项工作的主要贡献是对后门检测的不可能性结果和可实现性结果。我们展示了一个没有免费午餐定理，证明了通用（对敌方不知情）后门检测是不可能的，除非Alphabet大小非常小。因此，我们认为，后门检测方法需要明确地或隐式地考虑敌对因素。然而，我们的工作并不意味着后门检测在特定场景下不能起作用，因为科学文献中成功的后门检测方法证明了这一点。此外，我们将我们的定义与大概近似正确（PAC）学习与外分布检测问题联系起来。

    arXiv:2402.16926v1 Announce Type: cross  Abstract: We introduce a formal statistical definition for the problem of backdoor detection in machine learning systems and use it to analyze the feasibility of such problems, providing evidence for the utility and applicability of our definition. The main contributions of this work are an impossibility result and an achievability result for backdoor detection. We show a no-free-lunch theorem, proving that universal (adversary-unaware) backdoor detection is impossible, except for very small alphabet sizes. Thus, we argue, that backdoor detection methods need to be either explicitly, or implicitly adversary-aware. However, our work does not imply that backdoor detection cannot work in specific scenarios, as evidenced by successful backdoor detection methods in the scientific literature. Furthermore, we connect our definition to the probably approximately correct (PAC) learnability of the out-of-distribution detection problem.
    
[^100]: 使用带有图神经网络的强结构可控性强化学习最小化控制输入

    Minimize Control Inputs for Strong Structural Controllability Using Reinforcement Learning with Graph Neural Network

    [https://arxiv.org/abs/2402.16925](https://arxiv.org/abs/2402.16925)

    使用带有图神经网络的强化学习方法，将图着色问题形式化为马尔可夫决策过程，有效解决了强结构可控性条件下最小化控制输入的问题。

    

    强结构可控性(SSC)保证具有线性不变动力学的网络系统对于所有参数的数值实现都是可控的。当前研究已经为零/非零或零/非零/任意结构的SSC建立了代数和图论条件。一个相关的实际问题是如何用最少的输入信号完全控制系统，并确定必须施加信号的节点。先前的研究表明，这个优化问题是NP难的，很难找到解决方案。为了解决这个问题，我们根据零/非零和零/非零/任意结构的SSC的图论条件，将图着色过程构建为马尔可夫决策过程(MDP)。我们使用带有有向图神经网络的Actor-critic方法来表示图的着色信息以优化MDP。我们的方法在一个社交影响网络中得到了验证。

    arXiv:2402.16925v1 Announce Type: cross  Abstract: Strong structural controllability (SSC) guarantees networked system with linear-invariant dynamics controllable for all numerical realizations of parameters. Current research has established algebraic and graph-theoretic conditions of SSC for zero/nonzero or zero/nonzero/arbitrary structure. One relevant practical problem is how to fully control the system with the minimal number of input signals and identify which nodes must be imposed signals. Previous work shows that this optimization problem is NP-hard and it is difficult to find the solution. To solve this problem, we formulate the graph coloring process as a Markov decision process (MDP) according to the graph-theoretical condition of SSC for both zero/nonzero and zero/nonzero/arbitrary structure. We use Actor-critic method with Directed graph neural network which represents the color information of graph to optimize MDP. Our method is validated in a social influence network with
    
[^101]: 信息碎片的理论统一

    Theoretical Unification of the Fractured Aspects of Information

    [https://arxiv.org/abs/2402.16924](https://arxiv.org/abs/2402.16924)

    该论文旨在消除与信息研究相关的认知障碍，统一各方面的信息理论，摆脱不必要的方法论假设，为发展统一的信息理论提供了可能的应用例子。

    

    该文章的主要目标是确定与信息研究相关的基本认识论障碍，消除关于信息各方面基本分歧的流行信念，并可理解为对认识论障碍的Bachelardian切断的解惑无必要的方法论假设。 在这些一般性考虑之前，文章对研究信息的动机及信息概念在智能、复杂性和意识的概念化中的作用进行了概述，证明了在信息研究中需要一个足够一般的视角，并在文章末尾陈述了一个可能应用的例子，指出在统一信息理论的发展中需要摆脱不必要的分歧和对现有方法偏好的优越性主张。 托 B.的参考

    arXiv:2402.16924v1 Announce Type: new  Abstract: The article has as its main objective the identification of fundamental epistemological obstacles in the study of information related to unnecessary methodological assumptions and the demystification of popular beliefs in the fundamental divisions of the aspects of information that can be understood as Bachelardian rupture of epistemological obstacles. These general considerations are preceded by an overview of the motivations for the study of information and the role of the concept of information in the conceptualization of intelligence, complexity, and consciousness justifying the need for a sufficiently general perspective in the study of information, and are followed at the end of the article by a brief exposition of an example of a possible application in the development of the unified theory of information free from unnecessary divisions and claims of superiority of the existing preferences in methodology. The reference to Gaston B
    
[^102]: 超越路由：联合GPS和路由建模以优化轨迹表示学习

    More Than Routing: Joint GPS and Route Modeling for Refine Trajectory Representation Learning

    [https://arxiv.org/abs/2402.16915](https://arxiv.org/abs/2402.16915)

    提出了一种新颖的联合GPS和路由建模的表示学习框架，通过自监督技术实现，利用两个编码器分别捕获路由和GPS轨迹的表示，并通过共享的变压器进行模态间信息交互。

    

    轨迹表示学习在支持各种下游任务中发挥着关键作用。传统方法为了过滤GPS轨迹中的噪声往往侧重于基于路由的方法用于简化轨迹。然而，这种方法忽略了GPS数据中包含的运动细节，限制了轨迹表示学习的表示能力。为了填补这一空白，我们提出了一种新颖的基于自监督技术的联合GPS和路由建模的表示学习框架，即JGRM。我们将GPS轨迹和路由视为单个移动观察的两种模式，并通过模态间信息交互来融合信息。具体来说，我们开发了两个编码器，分别用于捕获路由和GPS轨迹的表示。来自这两种模态的表示被送入一个共享的变压器进行模态间信息交互。

    arXiv:2402.16915v1 Announce Type: cross  Abstract: Trajectory representation learning plays a pivotal role in supporting various downstream tasks. Traditional methods in order to filter the noise in GPS trajectories tend to focus on routing-based methods used to simplify the trajectories. However, this approach ignores the motion details contained in the GPS data, limiting the representation capability of trajectory representation learning. To fill this gap, we propose a novel representation learning framework that Joint GPS and Route Modelling based on self-supervised technology, namely JGRM. We consider GPS trajectory and route as the two modes of a single movement observation and fuse information through inter-modal information interaction. Specifically, we develop two encoders, each tailored to capture representations of route and GPS trajectories respectively. The representations from the two modalities are fed into a shared transformer for inter-modal information interaction. Eve
    
[^103]: DrAttack: 提示分解和重构使强大的LLM越狱者

    DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLM Jailbreakers

    [https://arxiv.org/abs/2402.16914](https://arxiv.org/abs/2402.16914)

    将恶意提示分解为独立的子提示使得LLM越狱攻击更难被检测

    

    本文发现将恶意提示分解为独立的子提示能够有效模糊其潜在的恶意意图，使之以片段化、不易检测的形式呈现，从而解决了这些局限性。我们引入了一个用于越狱攻击的自动提示分解和重构框架（DrAttack）。DrAttack包括三个关键组件：(a) 将原始提示进行“分解”为子提示，(b) 通过上下文学习中的语义上相似但隐含的“重构”这些子提示

    arXiv:2402.16914v1 Announce Type: cross  Abstract: The safety alignment of Large Language Models (LLMs) is vulnerable to both manual and automated jailbreak attacks, which adversarially trigger LLMs to output harmful content. However, current methods for jailbreaking LLMs, which nest entire harmful prompts, are not effective at concealing malicious intent and can be easily identified and rejected by well-aligned LLMs. This paper discovers that decomposing a malicious prompt into separated sub-prompts can effectively obscure its underlying malicious intent by presenting it in a fragmented, less detectable form, thereby addressing these limitations. We introduce an automatic prompt \textbf{D}ecomposition and \textbf{R}econstruction framework for jailbreak \textbf{Attack} (DrAttack). DrAttack includes three key components: (a) `Decomposition' of the original prompt into sub-prompts, (b) `Reconstruction' of these sub-prompts implicitly by in-context learning with semantically similar but h
    
[^104]: NeSy犹在：一种基于LLM的符号化方法用于改进代码注释数据生成和分类

    NeSy is alive and well: A LLM-driven symbolic approach for better code comment data generation and classification

    [https://arxiv.org/abs/2402.16910](https://arxiv.org/abs/2402.16910)

    结合符号化学习技术和大型语言模型，提出了一种神经符号化工作流用于改进代码注释数据生成和分类，并通过生成受控合成数据修复LLM生成中的弱点，提高了经典机器学习模型在代码注释分类任务上的性能。

    

    我们提出了一种神经符号化（NeSy）工作流，将基于符号的学习技术与大型语言模型（LLM）代理相结合，以生成C编程语言中代码注释分类的合成数据。我们还展示了如何使用这种工作流生成受控合成数据来修复LLM基于生成的一些明显弱点，并提高经典机器学习模型在代码注释分类任务上的性能。我们的最佳模型，一个神经网络，在数据增强后实现了91.412％的Macro-F1分数，增加了1.033％。

    arXiv:2402.16910v1 Announce Type: cross  Abstract: We present a neuro-symbolic (NeSy) workflow combining a symbolic-based learning technique with a large language model (LLM) agent to generate synthetic data for code comment classification in the C programming language. We also show how generating controlled synthetic data using this workflow fixes some of the notable weaknesses of LLM-based generation and increases the performance of classical machine learning models on the code comment classification task. Our best model, a Neural Network, achieves a Macro-F1 score of 91.412% with an increase of 1.033% after data augmentation.
    
[^105]: LDB：通过逐步验证运行时执行来调试大型语言模型

    LDB: A Large Language Model Debugger via Verifying Runtime Execution Step-by-step

    [https://arxiv.org/abs/2402.16906](https://arxiv.org/abs/2402.16906)

    LDB是一个新颖的调试框架，可以让大型语言模型通过运行时执行信息来完善生成的程序。

    

    大型语言模型（LLMs）在代码生成方面取得了重大进展。最近的研究不仅将单次代码生成，而且还将单元测试和程序验证器整合到LLMs中，以迭代地完善生成的程序。然而，这些工作将生成的程序视为不可分割的实体，这对LLMs在调试程序时存在不足，特别是当程序包含复杂的逻辑流程和数据操作时。相比之下，当人类开发人员调试程序时，他们通常设置断点并有选择地检查运行时执行信息。执行流和中间变量在调试过程中发挥着关键作用，然而现有的代码生成文献中未充分利用它们。本研究引入了大型语言模型调试器（LDB），这是一个新颖的调试框架，可以让LLMs通过运行时执行信息完善其生成的程序。

    arXiv:2402.16906v1 Announce Type: cross  Abstract: Large language models (LLMs) are leading significant progress in code generation. Beyond one-pass code generation, recent works further integrate unit tests and program verifiers into LLMs to iteratively refine the generated programs. However, these works consider the generated programs as an indivisible entity, which falls short for LLMs in debugging the programs, especially when the programs contain complex logic flows and data operations. In contrast, when human developers debug programs, they typically set breakpoints and selectively examine runtime execution information. The execution flow and the intermediate variables play a crucial role in the debugging process, yet they are underutilized in the existing literature on code generation. In this study, we introduce Large Language Model Debugger (LDB), a novel debugging framework that enables LLMs to refine their generated programs with the runtime execution information. Specifical
    
[^106]: 利用反应合成对生成式代理行为施加时间约束

    Enforcing Temporal Constraints on Generative Agent Behavior with Reactive Synthesis

    [https://arxiv.org/abs/2402.16905](https://arxiv.org/abs/2402.16905)

    提出了一种利用形式逻辑为基础的程序合成和LLM内容生成相结合的方法，通过使用时间流逻辑（TSL）对生成式代理施加时间约束，从而提高了代理行为的保证水平、系统的解释性和代理的模块化构建能力。

    

    大型语言模型（LLM）的流行引发了对创建交互代理新方法的探索。然而，在互动过程中管理这些代理的时间行为仍然具有挑战性。我们提出了一种将形式逻辑为基础的程序合成与LLM内容生成相结合的方法，以创建遵守时间约束的生成式代理。我们的方法使用时间流逻辑（Temporal Stream Logic，TSL）生成一个自动机，对代理施加时间结构，并将每个动作的细节留给LLM。通过使用TSL，我们能够增强生成代理，使用户在行为上有更高的保证水平，系统更易解释，并且更能以模块化方式构建代理。我们评估了我们的方法……

    arXiv:2402.16905v1 Announce Type: new  Abstract: The surge in popularity of Large Language Models (LLMs) has opened doors for new approaches to the creation of interactive agents. However, managing the temporal behavior of such agents over the course of an interaction remains challenging. The stateful, long-term horizon and quantitative reasoning required for coherent agent behavior does not fit well into the LLM paradigm. We propose a combination of formal logic-based program synthesis and LLM content generation to create generative agents that adhere to temporal constraints. Our approach uses Temporal Stream Logic (TSL) to generate an automaton that enforces a temporal structure on an agent and leaves the details of each action for a moment in time to an LLM. By using TSL, we are able to augment the generative agent where users have a higher level of guarantees on behavior, better interpretability of the system, and more ability to build agents in a modular way. We evaluate our appro
    
[^107]: 面向最大推理准确性和能效实时物联网传感系统的选择性任务卸载

    Selective Task offloading for Maximum Inference Accuracy and Energy efficient Real-Time IoT Sensing Systems

    [https://arxiv.org/abs/2402.16904](https://arxiv.org/abs/2402.16904)

    本论文提出了一个轻量级混合遗传算法（LGSTO），用于解决面向实时物联网传感系统的选择性任务卸载问题，以在时间和能量约束下最大化推理准确性。

    

    小型推理模型的最新进展促进了人工智能在边缘部署。然而，边缘设备有限的资源特性，特别是对于实时应用程序，带来了新的挑战。部署多个推理模型（或者一个尺寸可调的模型）变化大小，因此准确性和功耗，以及边缘服务器推理模型，可以提供一个动态系统，在其中根据当前资源条件执行对推理模型到推理任务的分配。因此，在这项工作中，我们解决了将推理模型选择性分配给任务或将其卸载到边缘服务器以在时间和能量约束下最大化推理准确性的问题。该问题被证明是无界多维背包问题的一个实例，被认为是一个强 NP-难问题。我们提出了一个轻量级混合遗传算法（LGSTO）来解决此问题。

    arXiv:2402.16904v1 Announce Type: cross  Abstract: The recent advancements in small-size inference models facilitated AI deployment on the edge. However, the limited resource nature of edge devices poses new challenges especially for real-time applications. Deploying multiple inference models (or a single tunable model) varying in size and therefore accuracy and power consumption, in addition to an edge server inference model, can offer a dynamic system in which the allocation of inference models to inference jobs is performed according to the current resource conditions. Therefore, in this work, we tackle the problem of selectively allocating inference models to jobs or offloading them to the edge server to maximize inference accuracy under time and energy constraints. This problem is shown to be an instance of the unbounded multidimensional knapsack problem which is considered a strongly NP-hard problem. We propose a lightweight hybrid genetic algorithm (LGSTO) to solve this problem.
    
[^108]: FGBERT：基于功能驱动的宏基因组预训练基因语言模型

    FGBERT: Function-Driven Pre-trained Gene Language Model for Metagenomics

    [https://arxiv.org/abs/2402.16901](https://arxiv.org/abs/2402.16901)

    该论文提出了基于蛋白质的基因表示作为一种上下文感知和结构相关的标记器，通过Masked Gene Modeling（MGM）和Triple Enhanced Metagenomic Contrastive Learning（TEM-CL）进行预训练，构建了一个新颖的宏基因组语言模型FGBERT，能够更好地捕捉基因序列与功能之间的复杂关系。

    

    Metagenomic data, comprising mixed multi-species genomes, are prevalent in diverse environments like oceans and soils, significantly impacting human health and ecological functions. However, current research relies on K-mer representations, limiting the capture of structurally relevant gene contexts. To address these limitations and further our understanding of complex relationships between metagenomic sequences and their functions, we introduce a protein-based gene representation as a context-aware and structure-relevant tokenizer. Our approach includes Masked Gene Modeling (MGM) for gene group-level pre-training, providing insights into inter-gene contextual information, and Triple Enhanced Metagenomic Contrastive Learning (TEM-CL) for gene-level pre-training to model gene sequence-function relationships. MGM and TEM-CL constitute our novel metagenomic language model FGBERT, pre-trained on 100 million metagenomic sequences.

    arXiv:2402.16901v1 Announce Type: cross  Abstract: Metagenomic data, comprising mixed multi-species genomes, are prevalent in diverse environments like oceans and soils, significantly impacting human health and ecological functions. However, current research relies on K-mer representations, limiting the capture of structurally relevant gene contexts. To address these limitations and further our understanding of complex relationships between metagenomic sequences and their functions, we introduce a protein-based gene representation as a context-aware and structure-relevant tokenizer. Our approach includes Masked Gene Modeling (MGM) for gene group-level pre-training, providing insights into inter-gene contextual information, and Triple Enhanced Metagenomic Contrastive Learning (TEM-CL) for gene-level pre-training to model gene sequence-function relationships. MGM and TEM-CL constitute our novel metagenomic language model {\NAME}, pre-trained on 100 million metagenomic sequences. We demon
    
[^109]: 连续时间强化学习中深度残差网络的\emph{先验估计}

    A prior Estimates for Deep Residual Network in Continuous-time Reinforcement Learning

    [https://arxiv.org/abs/2402.16899](https://arxiv.org/abs/2402.16899)

    本研究针对连续时间控制问题，提出了一种可以直接分析Bellman最优损失\emph{先验}泛化误差的方法，避免了有界性假设，并通过最大算子的分解方法实现了损失函数的转换。

    

    深度强化学习在许多大规模实际应用中表现出色。然而，现有的性能分析忽略了连续时间控制问题的独特特征，无法直接估计Bellman最优损失的泛化误差，并且需要一个有界性假设。我们的工作侧重于连续时间控制问题，并提出了一种适用于所有满足半群和Lipschitz性质的问题的方法。在该方法下，我们能够直接分析Bellman最优损失的\emph{先验}泛化误差。该方法的核心在于损失函数的两次转换。为了完成转换，我们提出了最大算子的分解方法。此外，这个分析方法不需要有界性假设。最终我们维得到了一个没有“维度诅咒”的\emph{先验}泛化误差。

    arXiv:2402.16899v1 Announce Type: cross  Abstract: Deep reinforcement learning excels in numerous large-scale practical applications. However, existing performance analyses ignores the unique characteristics of continuous-time control problems, is unable to directly estimate the generalization error of the Bellman optimal loss and require a boundedness assumption. Our work focuses on continuous-time control problems and proposes a method that is applicable to all such problems where the transition function satisfies semi-group and Lipschitz properties. Under this method, we can directly analyze the \emph{a priori} generalization error of the Bellman optimal loss. The core of this method lies in two transformations of the loss function. To complete the transformation, we propose a decomposition method for the maximum operator. Additionally, this analysis method does not require a boundedness assumption. Finally, we obtain an \emph{a priori} generalization error without the curse of dime
    
[^110]: MIM-Reasoner: 具有理论保证的多重影响最大化学习

    MIM-Reasoner: Learning with Theoretical Guarantees for Multiplex Influence Maximization

    [https://arxiv.org/abs/2402.16898](https://arxiv.org/abs/2402.16898)

    引入了MIM-Reasoner，结合强化学习和概率图模型，有效地捕捉了给定多重网络内部和层间的复杂传播过程，从而解决了MIM中最具挑战性的问题。

    

    多重影响最大化（MIM）要求我们识别一组种子用户，以最大化多重网络中受影响用户的预期数量。本文介绍了MIM-Reasoner，将强化学习与概率图模型相结合，有效捕捉给定多重网络内部和层间的复杂传播过程，从而解决了MIM中最具挑战性的问题。

    arXiv:2402.16898v1 Announce Type: cross  Abstract: Multiplex influence maximization (MIM) asks us to identify a set of seed users such as to maximize the expected number of influenced users in a multiplex network. MIM has been one of central research topics, especially in nowadays social networking landscape where users participate in multiple online social networks (OSNs) and their influences can propagate among several OSNs simultaneously. Although there exist a couple combinatorial algorithms to MIM, learning-based solutions have been desired due to its generalization ability to heterogeneous networks and their diversified propagation characteristics. In this paper, we introduce MIM-Reasoner, coupling reinforcement learning with probabilistic graphical model, which effectively captures the complex propagation process within and between layers of a given multiplex network, thereby tackling the most challenging problem in MIM. We establish a theoretical guarantee for MIM-Reasoner as w
    
[^111]: 可靠的冲突多视角学习

    Reliable Conflictive Multi-View Learning

    [https://arxiv.org/abs/2402.16897](https://arxiv.org/abs/2402.16897)

    提出了可靠的冲突多视角学习（RCML）问题，开发了一种Evidential Conflictive Multi-view Learning (ECML)方法来处理具有冲突信息的多视角数据。

    

    多视角学习旨在结合多个特征，以实现对数据的更全面描述。之前的大部分工作都假设多个视图是严格对齐的。然而，现实世界中的多视角数据可能包含低质量的冲突实例，即在不同视图中显示冲突信息。为了解决这个问题，我们提出了一个新的可靠的冲突多视角学习（RCML）问题，要求模型为冲突的多视角数据提供决策结果和附加的可靠性。我们为这个问题开发了一种Evidential Conflictive Multi-view Learning (ECML)方法。

    arXiv:2402.16897v1 Announce Type: cross  Abstract: Multi-view learning aims to combine multiple features to achieve more comprehensive descriptions of data. Most previous works assume that multiple views are strictly aligned. However, real-world multi-view data may contain low-quality conflictive instances, which show conflictive information in different views. Previous methods for this problem mainly focus on eliminating the conflictive data instances by removing them or replacing conflictive views. Nevertheless, real-world applications usually require making decisions for conflictive instances rather than only eliminating them. To solve this, we point out a new Reliable Conflictive Multi-view Learning (RCML) problem, which requires the model to provide decision results and attached reliabilities for conflictive multi-view data. We develop an Evidential Conflictive Multi-view Learning (ECML) method for this problem. ECML first learns view-specific evidence, which could be termed as th
    
[^112]: 探讨检索增强生成（RAG）中的隐私问题的利与弊

    The Good and The Bad: Exploring Privacy Issues in Retrieval-Augmented Generation (RAG)

    [https://arxiv.org/abs/2402.16893](https://arxiv.org/abs/2402.16893)

    RAG技术有可能改变大型语言模型生成行为，带来新的隐私问题，但同时也可以减少语言模型的训练数据泄漏。

    

    检索增强生成（RAG）是一种强大的技术，用于促进具有专有和私密数据的语言模型，其中数据隐私是一个关键关注点。尽管大量研究已经证明了大型语言模型（LLMs）存在的隐私风险，RAG技术有可能改变LLM生成的固有行为，从而引发目前尚未充分探讨的新隐私问题。在这项工作中，我们进行了大量的实证研究，并采用了新颖的攻击方法，证明了RAG系统泄露私密检索数据库的脆弱性。尽管RAG带来了检索数据的新风险，我们进一步揭示了RAG可以减少LLM训练数据的泄漏。总体而言，我们在本文中提供了关于检索增强LLMs隐私保护的新见解，这有利于LLMs和RAG系统的构建者。我们的代码可在https://github.com/phycholosogy/RAG-privacy找到。

    arXiv:2402.16893v1 Announce Type: cross  Abstract: Retrieval-augmented generation (RAG) is a powerful technique to facilitate language model with proprietary and private data, where data privacy is a pivotal concern. Whereas extensive research has demonstrated the privacy risks of large language models (LLMs), the RAG technique could potentially reshape the inherent behaviors of LLM generation, posing new privacy issues that are currently under-explored. In this work, we conduct extensive empirical studies with novel attack methods, which demonstrate the vulnerability of RAG systems on leaking the private retrieval database. Despite the new risk brought by RAG on the retrieval data, we further reveal that RAG can mitigate the leakage of the LLMs' training data. Overall, we provide new insights in this paper for privacy protection of retrieval-augmented LLMs, which benefit both LLMs and RAG systems builders. Our code is available at https://github.com/phycholosogy/RAG-privacy.
    
[^113]: 多任务学习用于具有跨问题零样本泛化的路径问题

    Multi-Task Learning for Routing Problem with Cross-Problem Zero-Shot Generalization

    [https://arxiv.org/abs/2402.16891](https://arxiv.org/abs/2402.16891)

    本研究首次尝试解决跨问题泛化的关键挑战，通过将VRPs定义为共享基础属性的不同组合，并通过属性组合同时解决它们，实现了零样本泛化的路径问题解决方法。

    

    车辆路径问题（VRPs）在许多实际应用中都能找到，已经成为几十年的重要研究课题。最近，利用基于学习的模型来解决VRPs的神经组合优化（NCO）方法引起了相当大的关注。然而，当前的NCO方法通常需要为每个路径问题构建一个模型，这显著阻碍了它们在具有不同属性的真实工业问题中的实际应用。在这项工作中，我们首次尝试解决跨问题泛化的关键挑战。具体而言，我们将VRPs定义为一组共享的基础属性的不同组合，并通过属性组合同时通过单一模型解决它们。通过这种方式，我们提出的模型能够成功解决具有未见属性组合的VRPs，实现零样本泛化。

    arXiv:2402.16891v1 Announce Type: cross  Abstract: Vehicle routing problems (VRPs), which can be found in numerous real-world applications, have been an important research topic for several decades. Recently, the neural combinatorial optimization (NCO) approach that leverages a learning-based model to solve VRPs without manual algorithm design has gained substantial attention. However, current NCO methods typically require building one model for each routing problem, which significantly hinders their practical application for real-world industry problems with diverse attributes. In this work, we make the first attempt to tackle the crucial challenge of cross-problem generalization. In particular, we formulate VRPs as different combinations of a set of shared underlying attributes and solve them simultaneously via a single model through attribute composition. In this way, our proposed model can successfully solve VRPs with unseen attribute combinations in a zero-shot generalization mann
    
[^114]: 生成模型具有自身水印：通过再生成声明模型认证

    Generative Models are Self-Watermarked: Declaring Model Authentication through Re-Generation

    [https://arxiv.org/abs/2402.16889](https://arxiv.org/abs/2402.16889)

    该论文提出了一种通过再生成识别模型数据所有权的方法，避免了传统数字水印技术可能破坏输出质量的问题。

    

    随着机器和人工智能生成的内容不断增加，保护生成模型的知识产权已变得至关重要，然而验证数据所有权在未经授权重复使用生成数据的情况下面临着巨大挑战。我们的工作致力于检测即使是个别样本的数据重复使用。传统上，数字水印技术被利用来检测人工智能生成的内容。然而，与将附加信息嵌入模型或生成内容以作为触发器的水印技术不同，潜在损害输出质量，我们的方法通过重新生成识别在输出中固有存在的潜在指纹。我们提出了一个可解释的验证过程，通过再生成来归属数据所有权，进一步

    arXiv:2402.16889v1 Announce Type: cross  Abstract: As machine- and AI-generated content proliferates, protecting the intellectual property of generative models has become imperative, yet verifying data ownership poses formidable challenges, particularly in cases of unauthorized reuse of generated data. The challenge of verifying data ownership is further amplified by using Machine Learning as a Service (MLaaS), which often functions as a black-box system.   Our work is dedicated to detecting data reuse from even an individual sample. Traditionally, watermarking has been leveraged to detect AI-generated content. However, unlike watermarking techniques that embed additional information as triggers into models or generated content, potentially compromising output quality, our approach identifies latent fingerprints inherently present within the outputs through re-generation. We propose an explainable verification procedure that attributes data ownership through re-generation, and further 
    
[^115]: 复杂网络的人工智能：潜力、方法论和应用

    Artificial Intelligence for Complex Network: Potential, Methodology and Application

    [https://arxiv.org/abs/2402.16887](https://arxiv.org/abs/2402.16887)

    人工智能技术与丰富真实网络数据的存在开启了复杂网络科学研究的新时代，有望克服现存挑战。

    

    复杂网络存在于各种真实世界系统中，从自然环境到人类社会。这些网络的本质在于它们能够从微观混乱-其中网络拓扑和节点动态交织-转变和演化为具有特定集体行为的宏观秩序。在过去的二十年里，复杂网络科学显著增强了我们对真实世界网络潜在机制、结构和动态的理解。尽管取得了这些进展，但在探索更加真实系统和提升实际应用方面仍然存在着相当大的挑战。人工智能技术的出现，以及丰富多样的真实世界网络数据的存在，开启了复杂网络科学研究的新时代。本调查旨在系统地探讨人工智能在克服复杂网络科学研究所面临的挑战方面的潜在优势。

    arXiv:2402.16887v1 Announce Type: cross  Abstract: Complex networks pervade various real-world systems, from the natural environment to human societies. The essence of these networks is in their ability to transition and evolve from microscopic disorder-where network topology and node dynamics intertwine-to a macroscopic order characterized by certain collective behaviors. Over the past two decades, complex network science has significantly enhanced our understanding of the statistical mechanics, structures, and dynamics underlying real-world networks. Despite these advancements, there remain considerable challenges in exploring more realistic systems and enhancing practical applications. The emergence of artificial intelligence (AI) technologies, coupled with the abundance of diverse real-world network data, has heralded a new era in complex network science research. This survey aims to systematically address the potential advantages of AI in overcoming the lingering challenges of com
    
[^116]: 使用文本嵌入模型和向量数据库作为文本分类器的研究，以医疗数据为例

    Using text embedding models and vector databases as text classifiers with the example of medical data

    [https://arxiv.org/abs/2402.16886](https://arxiv.org/abs/2402.16886)

    向量数据库和嵌入模型的应用为文本分类器提供了强大的方式来表达数据模式，特别是在医疗领域中开始有着广泛的应用。

    

    大型语言模型（LLMs）的出现是令人兴奋的，并已在许多领域找到应用，但通常情况下，医学领域的标准要求非常高。与LLMs配合使用，向量嵌入模型和向量数据库提供了一种强大的方式来表达各种数据模式，这些数据模式容易被典型的机器学习模型所理解。除了方便地向这些向量数据库添加信息、知识和数据外，它们还提供了一个令人信服的理由，即将其应用于通常由人类完成的检索信息任务的各种领域。Google的研究人员开发了一个清晰的替代模型Med-PaLM，专门旨在与临床医师的医学知识水平匹配。在训练分类器和开发模型时，保持事实和减少偏见是至关重要的。在本文中，我们探讨了向量数据库和嵌入模型的应用

    arXiv:2402.16886v1 Announce Type: cross  Abstract: The advent of Large Language Models (LLMs) is promising and has found application in numerous fields, but as it often is with the medical field, the bar is typically quite high [5]. In tandem with LLMs, vector embedding models and vector databases provide a robust way of expressing numerous modes of data that are easily digestible by typical machine learning models. Along with the ease of adding information, knowledge, and data to these vector databases, they provide a compelling reason to apply them in numerous fields where the task of retrieving information is typically done by humans. Researchers at Google have developed a clear alternative model, Med-PaLM [6] specifically designed to match a clinician's level of accuracy when it comes to medical knowledge. When training classifiers, and developing models, it is imperative to maintain factuality and reduce bias [4]. Here, we explore the use of vector databases and embedding models a
    
[^117]: 底物范围对比学习：重新利用人类偏见学习原子表示

    Substrate Scope Contrastive Learning: Repurposing Human Bias to Learn Atomic Representations

    [https://arxiv.org/abs/2402.16882](https://arxiv.org/abs/2402.16882)

    提出了一种新颖的预训练策略，底物范围对比学习，以学习适合化学反应性的原子表示。

    

    学习分子表示是分子机器学习中的关键步骤，对建模成功产生显著影响，尤其在数据稀缺情况下。广义预训练神经网络的概念推动了计算机视觉、自然语言处理和蛋白质工程等领域的发展。然而，类似的方法在小有机分子方面并未取得类似的成功。在这项工作中，我们引入一种新颖的预训练策略，即底物范围对比学习，它学习适合化学反应性的原子表示。这种方法以已发表的底物范围表中底物的分组和产物收率作为化学反应性相似性或不相似性的衡量。我们关注 CAS Content Collection 中的 20,798 个芳香卤代烃，涵盖数千篇出版物，以学习芳香卤代烃的反应性表示。我们验证了我们的预训练方法。

    arXiv:2402.16882v1 Announce Type: cross  Abstract: Learning molecular representation is a critical step in molecular machine learning that significantly influences modeling success, particularly in data-scarce situations. The concept of broadly pre-training neural networks has advanced fields such as computer vision, natural language processing, and protein engineering. However, similar approaches for small organic molecules have not achieved comparable success. In this work, we introduce a novel pre-training strategy, substrate scope contrastive learning, which learns atomic representations tailored to chemical reactivity. This method considers the grouping of substrates and their yields in published substrate scope tables as a measure of their similarity or dissimilarity in terms of chemical reactivity. We focus on 20,798 aryl halides in the CAS Content Collection spanning thousands of publications to learn a representation of aryl halide reactivity. We validate our pre-training appr
    
[^118]: BESA: 使用分块参数高效稀疏分配修剪大型语言模型

    BESA: Pruning Large Language Models with Blockwise Parameter-Efficient Sparsity Allocation

    [https://arxiv.org/abs/2402.16880](https://arxiv.org/abs/2402.16880)

    该论文提出了一种名为BESA的新型大型语言模型修剪技术，通过应用分块重构损失，与传统的逐层修剪技术不同，BESA具有优势

    

    大型语言模型（LLMs）在文本摘要、文本问答等各种任务中表现出色。尽管它们的性能令人印象深刻，但由于大量参数造成的计算占用可能是禁锢的。现有解决方案（如SparseGPT和Wanda）尝试通过权重修剪缓解此问题。然而，它们的逐层方法会导致模型输出显著扰动，并需要细致的超参数调整，如修剪速率，这可能会对整体模型性能产生不利影响。为解决此问题，本文引入了一种新颖的LLM修剪技术，称为分块参数高效稀疏分配（BESA），通过应用分块重构损失。与典型的逐层修剪技术相比，BESA具有两个独特的特点：i）它定位于整体修剪误差相对于每个

    arXiv:2402.16880v1 Announce Type: cross  Abstract: Large language models (LLMs) have demonstrated outstanding performance in various tasks, such as text summarization, text question-answering, and etc. While their performance is impressive, the computational footprint due to their vast number of parameters can be prohibitive. Existing solutions such as SparseGPT and Wanda attempt to alleviate this issue through weight pruning. However, their layer-wise approach results in significant perturbation to the model's output and requires meticulous hyperparameter tuning, such as the pruning rate, which can adversely affect overall model performance. To address this, this paper introduces a novel LLM pruning technique dubbed blockwise parameter-efficient sparsity allocation (BESA) by applying a blockwise reconstruction loss. In contrast to the typical layer-wise pruning techniques, BESA is characterized by two distinctive attributes: i) it targets the overall pruning error with respect to indi
    
[^119]: EvoGPT-f: 一种用于基准测试形式数学语言的进化GPT框架

    EvoGPT-f: An Evolutionary GPT Framework for Benchmarking Formal Math Languages

    [https://arxiv.org/abs/2402.16878](https://arxiv.org/abs/2402.16878)

    EvoGPT-f是一个新颖的进化框架，用于对五个形式数学语料库进行差异机器可学习性的系统量化分析，为形式数学语言的基准测试提供了新的方法。

    

    arXiv:2402.16878v1 公告类型: 新的 摘要: 形式数学是将数学转化为编程语言的学科，在这种编程语言中，任何陈述都可以被计算机明确地检查。数学家和计算机科学家花费了数十年进行艰苦的形式化工作，开发了诸如Coq、HOL和Lean等语言。机器学习研究已经汇集到这些形式化数学语料库上，并产生了各种方法来帮助交互式和自动定理证明。然而，这些论文主要集中在一个方法、一个证明任务、一个语言上。本文介绍了EvoGPT-f: 一种新颖的进化框架，用于首次系统量化分析五个形式数学语料库(Lean 3、Lean 4、Coq、HOL 4、HOL Light)的差异机器可学习性，使用四种记号化方法(字符、单词级、字节对编码和StarCoder记号化器)。本文并未结束关于“最佳”的问题。

    arXiv:2402.16878v1 Announce Type: new  Abstract: Formal mathematics is the discipline of translating mathematics into a programming language in which any statement can be unequivocally checked by a computer. Mathematicians and computer scientists have spent decades of painstaking formalization efforts developing languages such as Coq, HOL, and Lean. Machine learning research has converged on these formal math corpora and given rise to an assortment of methodologies to aid in interactive and automated theorem proving. However, these papers have primarily focused on one method, for one proof task, in one language. This paper introduces EvoGPT-f: a novel evolutionary framework for the first systematic quantitative analysis of the differential machine learnability of five formal math corpora (Lean 3, Lean 4, Coq, HOL 4, HOL Light) using four tokenization methods (character, word-level, Byte Pair Encoding and StarCoder tokenizer). This paper does not put to rest the question of the "best" o
    
[^120]: 大型语言模型增强的个性化语言学习练习检索

    Large Language Model Augmented Exercise Retrieval for Personalized Language Learning

    [https://arxiv.org/abs/2402.16877](https://arxiv.org/abs/2402.16877)

    大型语言模型利用生成能力来合成假设练习，以弥合学习者需求与练习内容之间的语义鸿沟，提高个性化语言学习练习检索效果。

    

    我们研究了在线语言学习环境中的零样本练习检索问题，以赋予学习者通过自然语言明确请求个性化练习的能力。通过收集自语言学习者的真实数据，我们观察到矢量相似性方法很难捕捉练习内容与学习者用于表达他们想要学习内容的语言之间的关系。我们利用大型语言模型的生成能力来弥合这一差距，通过基于学习者输入合成假设练习，然后用于搜索相关练习。我们的方法mHyER克服了三个挑战：（1）缺乏用于训练的相关性标签，（2）受限的学习

    arXiv:2402.16877v1 Announce Type: cross  Abstract: We study the problem of zero-shot exercise retrieval in the context of online language learning, to give learners the ability to explicitly request personalized exercises via natural language. Using real-world data collected from language learners, we observe that vector similarity approaches poorly capture the relationship between exercise content and the language that learners use to express what they want to learn. This semantic gap between queries and content dramatically reduces the effectiveness of general-purpose retrieval models pretrained on large scale information retrieval datasets like MS MARCO. We leverage the generative capabilities of large language models to bridge the gap by synthesizing hypothetical exercises based on the learner's input, which are then used to search for relevant exercises. Our approach, which we call mHyER, overcomes three challenges: (1) lack of relevance labels for training, (2) unrestricted learn
    
[^121]: 高级学术团队成员推荐模型

    Advanced Academic Team Worker Recommendation Models

    [https://arxiv.org/abs/2402.16876](https://arxiv.org/abs/2402.16876)

    提出了一种新任务：学术团队成员推荐模型，通过结合查询和论文上下文与图拓扑结构，形成适用于特定研究兴趣和任务的新图（CQBG-R），实验结果表明这种方法的有效性。

    

    合作伙伴推荐是学术领域中的重要任务。现有方法大多假设推荐系统仅需为任务推荐特定的研究人员。然而，学术成功可能归功于整个学术团队的高效合作。在这项工作中，我们提出了一个新任务：学术团队成员推荐。根据给定的身份（学生，助理教授或主教授）、研究兴趣和特定任务，我们可以推荐一个由（主教授，助理教授，学生）组成的学术团队。为了完成这个任务，我们提出了一个名为CQBG-R（引用-查询混合图-排名）的模型。其关键思想是将查询和论文的上下文与图拓扑结构结合起来形成一个新的图（CQBG），这个图可以针对这次的研究兴趣和特定研究任务。实验结果展示了该方法的有效性。

    arXiv:2402.16876v1 Announce Type: cross  Abstract: Collaborator recommendation is an important task in academic domain. Most of the existing approaches have the assumption that the recommendation system only need to recommend a specific researcher for the task. However, academic successes can be owed to productive collaboration of a whole academic team. In this work, we propose a new task: academic team worker recommendation: with a given status: student, assistant professor or prime professor, research interests and specific task, we can recommend an academic team formed as (prime professor, assistant professor, student). For this task, we propose a model CQBG-R(Citation-Query Blended Graph-Ranking). The key ideas is to combine the context of the query and the papers with the graph topology to form a new graph(CQBG), which can target at the research interests and the specific research task for this time. The experiment results show the effectiveness of the proposed method.
    
[^122]: 通过增强查询提升语言生成的检索过程

    Enhancing Retrieval Processes for Language Generation with Augmented Queries

    [https://arxiv.org/abs/2402.16874](https://arxiv.org/abs/2402.16874)

    本研究通过检索增强生成（RAG）技术解决了语言生成中“幻觉”问题，并借助查询优化过程将用户查询与高级语言模型连接，显著提升了模型性能。

    

    在智能技术日新月异的世界中，由于先进语言模型的崛起，搜索文档变得更具挑战性。这些模型有时会面临困难，比如提供不准确的信息，通常被称为“幻觉”。本研究致力于通过检索增强生成（RAG）技术解决这一问题，该技术指导模型基于真实事实提供准确答复。为了解决可伸缩性问题，研究探讨了将用户查询与诸如BERT和Orca2等复杂语言模型连接起来的创新查询优化过程。研究展开在三种情境中：首先，没有RAG，其次，没有额外帮助，最后，加入额外帮助。选择紧凑而高效的Orca2 7B模型展示出对计算资源的智能使用。实证结果表明，初始语言模型的性能有了显著提升。

    arXiv:2402.16874v1 Announce Type: cross  Abstract: In the rapidly changing world of smart technology, searching for documents has become more challenging due to the rise of advanced language models. These models sometimes face difficulties, like providing inaccurate information, commonly known as "hallucination." This research focuses on addressing this issue through Retrieval-Augmented Generation (RAG), a technique that guides models to give accurate responses based on real facts. To overcome scalability issues, the study explores connecting user queries with sophisticated language models such as BERT and Orca2, using an innovative query optimization process. The study unfolds in three scenarios: first, without RAG, second, without additional assistance, and finally, with extra help. Choosing the compact yet efficient Orca2 7B model demonstrates a smart use of computing resources. The empirical results indicate a significant improvement in the initial language model's performance unde
    
[^123]: Bike3S：自行车共享系统模拟工具

    Bike3S: A Tool for Bike Sharing Systems Simulation

    [https://arxiv.org/abs/2402.16871](https://arxiv.org/abs/2402.16871)

    Bike3S是一个针对基于站点的自行车共享系统的模拟器，可以进行半现实的代理基础模拟，帮助评估和测试不同管理决策和策略。

    

    车辆共享系统越来越受欢迎。这些系统的有效性取决于不同的战略和运营管理决策和政策，比如车队规模或车辆分布。能够预测和评估这些策略的潜在影响至关重要，然后才能成功部署。本文介绍了Bike3S，一个用于基于站点的自行车共享系统的模拟器。该模拟器执行半现实的自行车共享系统操作模拟，并允许评估和测试不同的管理决策和策略。特别是，该模拟器被设计用于测试不同的站点容量、站点分布和平衡策略。该模拟器进行微观基于代理的模拟，可以定义不同类型的用户，根据其自身行为。

    arXiv:2402.16871v1 Announce Type: cross  Abstract: Vehicle sharing systems are becoming increasingly popular. The effectiveness of such systems depends, among other factors, on different strategic and operational management decisions and policies, like the dimension of the fleet or the distribution of vehicles. It is of foremost importance to be able to anticipate and evaluate the potential effects of such strategies before they can be successfully deployed. In this paper we present Bike3S, a simulator for a station-based bike sharing system. The simulator performs semi-realistic simulations of the operation of a bike sharing system and allows for evaluating and testing different management decisions and strategies. In particular, the simulator has been designed to test different station capacities, station distributions, and balancing strategies. The simulator carries out microscopic agent-based simulations, where users of different types can be defined that act according to their ind
    
[^124]: 在欧洲人工智能标准化中考虑基本权利：胡扯还是战略联盟？

    Considering Fundamental Rights in the European Standardisation of Artificial Intelligence: Nonsense or Strategic Alliance?

    [https://arxiv.org/abs/2402.16869](https://arxiv.org/abs/2402.16869)

    未来欧洲人工智能标准化应考虑基本权利，以缓解某些人工智能系统带来的高风险，反映基本权利考虑，并解决对欧洲标准化过程的批评。

    

    在欧洲背景下，欧盟人工智能法案提案和有关安全可信人工智能的标准化请求草案，将标准化与基本权利联系起来。然而，这些文本并未提供任何指导方针，明确阐明人工智能标准与基本权利之间的关系、含义或影响。本章旨在澄清这一重要的监管盲点。主要讨论的问题是基于未来人工智能法案采纳人工智能协调标准时是否应考虑基本权利。在我们看来，答案是肯定的。某些人工智能系统带来的高风险特别涉及基本权利的侵犯。因此，减轻这些风险涉及基本权利考虑，未来的协调标准应该反映这一点。同时，对欧洲标准化过程的有效批评必须得到解决。最后，实际整合

    arXiv:2402.16869v1 Announce Type: cross  Abstract: In the European context, both the EU AI Act proposal and the draft Standardisation Request on safe and trustworthy AI link standardisation to fundamental rights. However, these texts do not provide any guidelines that specify and detail the relationship between AI standards and fundamental rights, its meaning or implication. This chapter aims to clarify this critical regulatory blind spot. The main issue tackled is whether the adoption of AI harmonised standards, based on the future AI Act, should take into account fundamental rights. In our view, the response is yes. The high risks posed by certain AI systems relate in particular to infringements of fundamental rights. Therefore, mitigating such risks involves fundamental rights considerations and this is what future harmonised standards should reflect. At the same time, valid criticisms of the European standardisation process have to be addressed. Finally, the practical incorporation
    
[^125]: 由Transformer驱动的端到端语义通信的码书生成方法

    Codebook-enabled Generative End-to-end Semantic Communication Powered by Transformer

    [https://arxiv.org/abs/2402.16868](https://arxiv.org/abs/2402.16868)

    本文提出了一个强大的码书辅助图像语义通信系统，通过联合构建语义编解码器和码书、设计向量-索引变换器来实现图像生成，并且借助高质量码书帮助Transformer，提高系统对抗信道噪声的鲁棒性。

    

    基于码书的生成式语义通信引起了越来越多的关注，因为当码书在发送者和接收者之间共享时，只需要传输索引。然而，由于码向量之间的语义关系未必与对应码索引的距离相关，码书启用的语义通信系统性能容易受到信道噪声的影响。因此，如何提高系统对抗噪声的鲁棒性需要仔细设计。本文提出了一个强大的码书辅助图像语义通信系统，其中首先联合构建语义编解码器和码书，然后设计了向量-索引变换器，根据码书引导以消除信道噪声的影响，并实现图像生成。由于高质量码书对Transformer的辅助，接收端生成的图像效果优于...

    arXiv:2402.16868v1 Announce Type: cross  Abstract: Codebook-based generative semantic communication attracts increasing attention, since only indices are required to be transmitted when the codebook is shared between transmitter and receiver. However, due to the fact that the semantic relations among code vectors are not necessarily related to the distance of the corresponding code indices, the performance of the codebook-enabled semantic communication system is susceptible to the channel noise. Thus, how to improve the system robustness against the noise requires careful design. This paper proposes a robust codebook-assisted image semantic communication system, where semantic codec and codebook are first jointly constructed, and then vector-to-index transformer is designed guided by the codebook to eliminate the effects of channel noise, and achieve image generation. Thanks to the assistance of the high-quality codebook to the Transformer, the generated images at the receiver outperfo
    
[^126]: 用于多用户协作的无线供电边缘计算的计算速率最大化

    Computation Rate Maximization for Wireless Powered Edge Computing With Multi-User Cooperation

    [https://arxiv.org/abs/2402.16866](https://arxiv.org/abs/2402.16866)

    提出一种新颖的多用户协作方案，旨在最大化网络中所有IoT设备的加权总计算速率（WSCR）。

    

    arXiv:2402.16866v1 公告类型: 跨学科 摘要: 移动边缘计算（MEC）和基于射频的无线功率传输（WPT）的结合呈现出一种为网络边缘提供可持续能源供应和计算服务的有前景的技术。本研究考虑了一个包括具有计算单元和多个物联网（IoT）设备的混合接入点（HAP）的无线供电移动边缘计算系统。具体而言，我们提出了一种新颖的多用户协作方案来改善计算性能，其中合作集群是动态形成的。每个合作集群包括一个源设备（SD）和一个辅助设备（AD），其中SD可以将计算任务分成各种部分进行本地处理，向HAP卸载，并在HAP的帮助下由AD远程执行。具体而言，我们旨在最大化网络中所有IoT设备的加权总计算速率（WSCR）。

    arXiv:2402.16866v1 Announce Type: cross  Abstract: The combination of mobile edge computing (MEC) and radio frequency-based wireless power transfer (WPT) presents a promising technique for providing sustainable energy supply and computing services at the network edge. This study considers a wireless-powered mobile edge computing system that includes a hybrid access point (HAP) equipped with a computing unit and multiple Internet of Things (IoT) devices. In particular, we propose a novel muti-user cooperation scheme to improve computation performance, where collaborative clusters are dynamically formed. Each collaborative cluster comprises a source device (SD) and an auxiliary device (AD), where the SD can partition the computation task into various segments for local processing, offloading to the HAP, and remote execution by the AD with the assistance of the HAP. Specifically, we aims to maximize the weighted sum computation rate (WSCR) of all the IoT devices in the network. This invol
    
[^127]: 基于量子启发的混沌萨尔普群体优化用于动态优化

    Quantum Inspired Chaotic Salp Swarm Optimization for Dynamic Optimization

    [https://arxiv.org/abs/2402.16863](https://arxiv.org/abs/2402.16863)

    量子启发的混沌萨尔普群体优化算法用于动态优化问题的改进性能研究

    

    许多实际问题是未知的动态优化问题。在实践中，像新工作的到来、截止日期变更、预订取消以及参数或约束的更改等不可预测事件使得搜索环境动态化。许多算法设计用于处理静态优化问题，但这些算法无法很好地处理动态优化问题。尽管一些优化算法被提出来不同地处理动态环境的变化，但由于某些限制或缺陷，现有算法仍有改进空间，特别是在定位和跟踪先前确定的最优解方面。考虑到这一点，我们研究了一种集成了量子计算原理的SSA变体，名为QSSO。我们致力于改进标准SSA的整体性能，以处理动态环境。

    arXiv:2402.16863v1 Announce Type: cross  Abstract: Many real-world problems are dynamic optimization problems that are unknown beforehand. In practice, unpredictable events such as the arrival of new jobs, due date changes, and reservation cancellations, changes in parameters or constraints make the search environment dynamic. Many algorithms are designed to deal with stationary optimization problems, but these algorithms do not face dynamic optimization problems or manage them correctly. Although some optimization algorithms are proposed to deal with the changes in dynamic environments differently, there are still areas of improvement in existing algorithms due to limitations or drawbacks, especially in terms of locating and following the previously identified optima. With this in mind, we studied a variant of SSA known as QSSO, which integrates the principles of quantum computing. An attempt is made to improve the overall performance of standard SSA to deal with the dynamic environme
    
[^128]: 作为可优化图的语言代理

    Language Agents as Optimizable Graphs

    [https://arxiv.org/abs/2402.16823](https://arxiv.org/abs/2402.16823)

    将基于LLM的代理统一描述为计算图，提出新颖的自动图优化器来改进节点和边，实现了代理之间的自动协作和改进。

    

    多种人类设计的提升技术被提出，用于改进基于大型语言模型（LLMs）的问题求解器，产生了许多不同的代码库。我们通过将LLM代理描述为计算图来统一这些方法。节点实现处理多模态数据或查询LLMs的功能，并且边描述操作之间的信息流动。图形可以递归地组合成代表不同代理之间协作层次的更大组合图（其中边连接不同代理的操作）。我们的新颖自动图优化器（1）优化节点级LLM提示（节点优化）并（2）通过改变图连接性来改善代理协调（边缘优化）。实验证明我们的框架可用于高效开发、集成和自动改进各种LLM代理。代码可在https://github.com/metauto-ai/gptswarm找到。

    arXiv:2402.16823v1 Announce Type: cross  Abstract: Various human-designed prompt engineering techniques have been proposed to improve problem solvers based on Large Language Models (LLMs), yielding many disparate code bases. We unify these approaches by describing LLM-based agents as computational graphs. The nodes implement functions to process multimodal data or query LLMs, and the edges describe the information flow between operations. Graphs can be recursively combined into larger composite graphs representing hierarchies of inter-agent collaboration (where edges connect operations of different agents). Our novel automatic graph optimizers (1) refine node-level LLM prompts (node optimization) and (2) improve agent orchestration by changing graph connectivity (edge optimization). Experiments demonstrate that our framework can be used to efficiently develop, integrate, and automatically improve various LLM agents. The code can be found at https://github.com/metauto-ai/gptswarm.
    
[^129]: Nemotron-4 15B技术报告

    Nemotron-4 15B Technical Report

    [https://arxiv.org/abs/2402.16819](https://arxiv.org/abs/2402.16819)

    Nemotron-4 15B是一个150亿参数的大型多语言模型，在多语言能力上表现优异，超过其他规模相似的模型。

    

    我们介绍了Nemotron-4 15B，这是一个拥有150亿参数的大型多语言模型，训练过程中使用了8000万亿个文本标记。Nemotron-4 15B在英语、多语言和编码任务上表现出色：在7个下游评估领域中，它在4个领域中表现出色，并在其余领域中取得了竞争性表现，超过了所有现有规模相似的开放模型。具体来说，Nemotron-4 15B展现出了所有规模相似模型中最强的多语言能力，甚至在多语言任务上优于四倍以上的大型模型，以及专门用于多语言任务的模型。

    arXiv:2402.16819v1 Announce Type: new  Abstract: We introduce Nemotron-4 15B, a 15-billion-parameter large multilingual language model trained on 8 trillion text tokens. Nemotron-4 15B demonstrates strong performance when assessed on English, multilingual, and coding tasks: it outperforms all existing similarly-sized open models on 4 out of 7 downstream evaluation areas and achieves competitive performance to the leading open models in the remaining ones. Specifically, Nemotron-4 15B exhibits the best multilingual capabilities of all similarly-sized models, even outperforming models over four times larger and those explicitly specialized for multilingual tasks.
    
[^130]: 在复杂模块化算术中解释理解的Transformer

    Interpreting Grokked Transformers in Complex Modular Arithmetic

    [https://arxiv.org/abs/2402.16726](https://arxiv.org/abs/2402.16726)

    本研究通过可解释的逆向工程在复杂模块化算术中观察了Transformer内部电路学习过程，并发现减法在Transformer上造成了强烈的不对称性，乘法需要余弦偏置分量，多项式叠加了基本算术模式，但在挑战性情况下并不清晰，Grokking甚至可以在具有基本对称和交替表达式的高次公式中轻松发生。

    

    Grokking一直是解开延迟泛化之谜的积极探索。在已解密模型中识别可解释的算法是理解其机制的暗示性线索。在这项工作中，除了最简单和广为研究的模块化加法外，我们通过可解释的逆向工程观察了通过Grokking在复杂模块化算术中学到的内部电路，突出显示了它们动力学上的重大差异：减法对Transformer产生强烈的不对称性；乘法在傅立叶域的所有频率上需要余弦偏置分量；多项式通常导致基本算术模式的叠加，但在挑战性情况下清晰的模式并不显现；即使在具有基本对称和交替表达式的高次公式中，Grokking也很容易发生。我们还引入了模块化算术的新颖进展度量；傅立叶频率

    arXiv:2402.16726v2 Announce Type: replace-cross  Abstract: Grokking has been actively explored to reveal the mystery of delayed generalization. Identifying interpretable algorithms inside the grokked models is a suggestive hint to understanding its mechanism. In this work, beyond the simplest and well-studied modular addition, we observe the internal circuits learned through grokking in complex modular arithmetic via interpretable reverse engineering, which highlights the significant difference in their dynamics: subtraction poses a strong asymmetry on Transformer; multiplication requires cosine-biased components at all the frequencies in a Fourier domain; polynomials often result in the superposition of the patterns from elementary arithmetic, but clear patterns do not emerge in challenging cases; grokking can easily occur even in higher-degree formulas with basic symmetric and alternating expressions. We also introduce the novel progress measure for modular arithmetic; Fourier Freque
    
[^131]: RoboGrind：工业机器人的直观交互式表面处理

    RoboGrind: Intuitive and Interactive Surface Treatment with Industrial Robots

    [https://arxiv.org/abs/2402.16542](https://arxiv.org/abs/2402.16542)

    RoboGrind是一个集成系统，通过3D感知、交互式语音控制向导系统和自动规划执行流水线实现工业机器人对表面处理任务的直观、交互式自动化，为重制玻璃纤维风力涡轮叶片提供了解决方案。

    

    arXiv:2402.16542v1 公告类型：跨领域 摘要：诸如磨削、打磨或抛光之类的表面处理任务是许多行业价值链中至关重要的一步，但自动化处理这些任务非常具有挑战性。我们提出了RoboGrind，这是一个集成系统，用于通过工业机器人直观、交互式地自动化表面处理任务。该系统结合了一个复杂的3D感知流水线，用于表面扫描和自动缺陷识别，一个交互式语音控制向导系统，用于AI辅助初始化和参数化机器人程序，以及一个用于力控制式机器人表面处理的自动规划和执行流水线。RoboGrind在实验室和实际环境中进行了评估，主要是用于重制玻璃纤维风力涡轮叶片。

    arXiv:2402.16542v1 Announce Type: cross  Abstract: Surface treatment tasks such as grinding, sanding or polishing are a vital step of the value chain in many industries, but are notoriously challenging to automate. We present RoboGrind, an integrated system for the intuitive, interactive automation of surface treatment tasks with industrial robots. It combines a sophisticated 3D perception pipeline for surface scanning and automatic defect identification, an interactive voice-controlled wizard system for the AI-assisted bootstrapping and parameterization of robot programs, and an automatic planning and execution pipeline for force-controlled robotic surface treatment. RoboGrind is evaluated both under laboratory and real-world conditions in the context of refabricating fiberglass wind turbine blades.
    
[^132]: 反馈高效在线微调扩散模型

    Feedback Efficient Online Fine-Tuning of Diffusion Models

    [https://arxiv.org/abs/2402.16359](https://arxiv.org/abs/2402.16359)

    提出了一种反馈高效的在线微调扩散模型的强化学习程序

    

    扩散模型在建模复杂数据分布方面表现出色，包括图像，蛋白质和小分子的分布。然而，在许多情况下，我们的目标是模拟最大化某些属性的分布的部分：例如，我们可能希望生成具有高审美质量的图像，或具有高生物活性的分子。自然地，我们可以将这视为一个强化学习（RL）问题，其目标是微调扩散模型以最大化与某些属性对应的奖励函数。即使可以访问地面真实奖励函数的在线查询，有效地发现高奖励样本也可能具有挑战性：它们在初始分布中的概率可能很低，并且可能存在许多不可行的样本，甚至没有定义良好的奖励（例如，不自然的图像或物理上不可能的分子）。在这项工作中，我们提出了一种新颖的强化学习程序，可以高效地发现高奖励样本。

    arXiv:2402.16359v1 Announce Type: cross  Abstract: Diffusion models excel at modeling complex data distributions, including those of images, proteins, and small molecules. However, in many cases, our goal is to model parts of the distribution that maximize certain properties: for example, we may want to generate images with high aesthetic quality, or molecules with high bioactivity. It is natural to frame this as a reinforcement learning (RL) problem, in which the objective is to fine-tune a diffusion model to maximize a reward function that corresponds to some property. Even with access to online queries of the ground-truth reward function, efficiently discovering high-reward samples can be challenging: they might have a low probability in the initial distribution, and there might be many infeasible samples that do not even have a well-defined reward (e.g., unnatural images or physically impossible molecules). In this work, we propose a novel reinforcement learning procedure that effi
    
[^133]: 跨领域的中文句式结构解析

    Cross-domain Chinese Sentence Pattern Parsing

    [https://arxiv.org/abs/2402.16311](https://arxiv.org/abs/2402.16311)

    本文提出了一种利用大型语言模型进行自我训练的创新方法，通过动态生成训练数据将源领域句法规则与目标领域句子相结合，增强句式结构解析器对各种领域的适应能力，实验证明其在教科书和新闻领域的效果优于基于规则的基准模型1.68个百分点。

    

    arXiv:2402.16311v1 公告类型: 跨领域 句式结构（SPS）解析是一种主要用于语言教学的句法分析方法。现有的SPS解析器主要依赖于教科书语料库进行训练，缺乏跨领域能力。为了克服这一限制，本文提出了一种创新方法，利用大型语言模型（LLMs）在自我训练框架内。从源领域中提取部分句法规则，与目标领域句子结合动态生成训练数据，增强了解析器对不同领域的适应能力。在教科书和新闻领域进行的实验表明，所提出的方法效果显著，F1指标比基于规则的基准模型高出1.68个百分点。

    arXiv:2402.16311v1 Announce Type: cross  Abstract: Sentence Pattern Structure (SPS) parsing is a syntactic analysis method primarily employed in language teaching.Existing SPS parsers rely heavily on textbook corpora for training, lacking cross-domain capability.To overcome this constraint, this paper proposes an innovative approach leveraging large language models (LLMs) within a self-training framework. Partial syntactic rules from a source domain are combined with target domain sentences to dynamically generate training data, enhancing the adaptability of the parser to diverse domains.Experiments conducted on textbook and news domains demonstrate the effectiveness of the proposed method, outperforming rule-based baselines by 1.68 points on F1 metrics.
    
[^134]: 基于引文增强的LLM聊天机器人生成

    Citation-Enhanced Generation for LLM-based Chatbot

    [https://arxiv.org/abs/2402.16063](https://arxiv.org/abs/2402.16063)

    提出一种基于引文增强的LLM聊天机器人生成方法，采用检索模块搜索支持文档来解决幻觉内容产生的问题。

    

    大型语言模型（LLMs）在各种情景下展现出强大的通用智能，包括将它们集成到聊天机器人中。然而，基于LLM的聊天机器人面临的一个重要挑战是在回复中可能产生虚构内容，这严重限制了它们的适用性。本文提出了一种新颖的后续引用增强生成（CEG）方法，结合检索论证。与先前侧重于预防生成过程中幻觉的研究不同，我们的方法以后续方式解决了这个问题。它结合了一个检索模块来搜索与生成内容相关的支持文档，并采用基于自然语言推理的方法。

    arXiv:2402.16063v1 Announce Type: cross  Abstract: Large language models (LLMs) exhibit powerful general intelligence across diverse scenarios, including their integration into chatbots. However, a vital challenge of LLM-based chatbots is that they may produce hallucinated content in responses, which significantly limits their applicability. Various efforts have been made to alleviate hallucination, such as retrieval augmented generation and reinforcement learning with human feedback, but most of them require additional training and data annotation. In this paper, we propose a novel post-hoc \textbf{C}itation-\textbf{E}nhanced \textbf{G}eneration (\textbf{CEG}) approach combined with retrieval argumentation. Unlike previous studies that focus on preventing hallucinations during generation, our method addresses this issue in a post-hoc way. It incorporates a retrieval module to search for supporting documents relevant to the generated content, and employs a natural language inference-ba
    
[^135]: 具有面向聚类的引导的深度对比图学习

    Deep Contrastive Graph Learning with Clustering-Oriented Guidance

    [https://arxiv.org/abs/2402.16012](https://arxiv.org/abs/2402.16012)

    该论文提出了一种深度对比图学习（DCGL）模型，通过结合自编码器和GCN，在处理一般数据聚类时强调了图结构和原始特征。

    

    图卷积网络（GCN）在改善基于图的聚类中展现出了显著潜力。为了处理没有先验图的一般聚类场景，这些模型先估计一个初始图，然后应用GCN。文献中显示，大多数模型关注于初始图而忽略了原始特征。因此，学到的表示的可辨识性可能会受到低质量初始图的破坏；训练过程缺乏有效的聚类引导，这可能导致将与聚类无关的信息合并到学到的图中。为了解决这些问题，提出了用于一般数据聚类的深度对比图学习（DCGL）模型。具体来说，我们建立了一个伪孪生网络，将自编码器与GCN相结合，以强调图结构和原始特征。基于此，特征级对比。

    arXiv:2402.16012v1 Announce Type: new  Abstract: Graph Convolutional Network (GCN) has exhibited remarkable potential in improving graph-based clustering. To handle the general clustering scenario without a prior graph, these models estimate an initial graph beforehand to apply GCN. Throughout the literature, we have witnessed that 1) most models focus on the initial graph while neglecting the original features. Therefore, the discriminability of the learned representation may be corrupted by a low-quality initial graph; 2) the training procedure lacks effective clustering guidance, which may lead to the incorporation of clustering-irrelevant information into the learned graph. To tackle these problems, the Deep Contrastive Graph Learning (DCGL) model is proposed for general data clustering. Specifically, we establish a pseudo-siamese network, which incorporates auto-encoder with GCN to emphasize both the graph structure and the original features. On this basis, feature-level contrasti
    
[^136]: CoDream：使用异构模型交换梦想而不是模型进行联合聚合

    CoDream: Exchanging dreams instead of models for federated aggregation with heterogeneous models

    [https://arxiv.org/abs/2402.15968](https://arxiv.org/abs/2402.15968)

    CoDream提出了一种通过在输入数据空间中协作优化数据来交换知识的框架，实现了模型之间的合作学习，实现了模型架构无关、通信不受模型大小影响、兼容安全聚合的优点。

    

    联邦学习（FL）通过聚合模型参数实现机器学习模型在分散数据上的协作优化。我们的方法通过聚合模型产生的“知识”，而不是模型参数来扩展这一概念。我们提出了一个名为 \codream 的新颖框架，在这个框架中，客户端通过在输入数据空间中使用联合优化来协作优化随机初始化的数据，类似于在FL中优化随机初始化的模型参数。我们的关键见解是，联合优化这些数据可以有效捕获全局数据分布的特性。在数据空间共享知识具有许多好处：（1）与模型无关的协作学习，即不同客户端可以具有不同的模型架构；（2）通信不受模型大小影响，消除了模型参数的可伸缩性问题；（3）与安全聚合兼容，因此可预

    arXiv:2402.15968v1 Announce Type: cross  Abstract: Federated Learning (FL) enables collaborative optimization of machine learning models across decentralized data by aggregating model parameters. Our approach extends this concept by aggregating "knowledge" derived from models, instead of model parameters. We present a novel framework called \codream, where clients collaboratively optimize randomly initialized data using federated optimization in the input data space, similar to how randomly initialized model parameters are optimized in FL. Our key insight is that jointly optimizing this data can effectively capture the properties of the global data distribution. Sharing knowledge in data space offers numerous benefits: (1) model-agnostic collaborative learning, i.e., different clients can have different model architectures; (2) communication that is independent of the model size, eliminating scalability concerns with model parameters; (3) compatibility with secure aggregation, thus pre
    
[^137]: 通过（去）随机平滑提高基于深度学习的恶意软件检测器的对抗鲁棒性

    Adversarial Robustness of Deep Learning-based Malware Detectors via (De)Randomized Smoothing

    [https://arxiv.org/abs/2402.15267](https://arxiv.org/abs/2402.15267)

    通过选择相关的字节子集替代高斯噪声，在训练中进行基于消融的平滑方案，加强了基于深度学习的恶意软件检测器对抗性恶意软件示例的鲁棒性。

    

    基于深度学习的恶意软件检测器已被证明容易受到对抗性恶意软件示例的攻击，即恶意软件示例经过故意操纵以避免检测。鉴于深度学习检测器对微妙输入文件修改的脆弱性，我们提出了一种受（去）随机平滑启发的针对对抗性恶意软件示例的实用防御方法。本文中，我们通过选择相关的字节子集而不是像计算机视觉（CV）领域那样使用高斯噪声来随机化输入，来降低被恶意软件作者注入的对抗内容被采样的几率。在训练期间，我们的去除基于消融的平滑方案训练一个基本分类器对一部分连续字节或字节块进行分类。在测试时，基本分类器对大量字节块进行分类，最后预测结果是这些分类中的一致性。

    arXiv:2402.15267v1 Announce Type: cross  Abstract: Deep learning-based malware detectors have been shown to be susceptible to adversarial malware examples, i.e. malware examples that have been deliberately manipulated in order to avoid detection. In light of the vulnerability of deep learning detectors to subtle input file modifications, we propose a practical defense against adversarial malware examples inspired by (de)randomized smoothing. In this work, we reduce the chances of sampling adversarial content injected by malware authors by selecting correlated subsets of bytes, rather than using Gaussian noise to randomize inputs like in the Computer Vision (CV) domain. During training, our ablation-based smoothing scheme trains a base classifier to make classifications on a subset of contiguous bytes or chunk of bytes. At test time, a large number of chunks are then classified by a base classifier and the consensus among these classifications is then reported as the final prediction. W
    
[^138]: GraphEdit：用于图结构学习的大型语言模型

    GraphEdit: Large Language Models for Graph Structure Learning

    [https://arxiv.org/abs/2402.15183](https://arxiv.org/abs/2402.15183)

    本研究提出了一种名为GraphEdit的方法，利用大型语言模型（LLMs）学习复杂的图结构化数据中的节点关系，通过在图结构上进行指导调整，增强LLMs的推理能力，从而提高图结构学习的可靠性。

    

    图结构学习（GSL）致力于通过生成新颖的图结构来捕捉图结构数据中节点之间的固有依赖性和相互作用。本文提出了一种名为GraphEdit的方法，利用大型语言模型（LLMs）学习图结构化数据中复杂的节点关系。通过在图结构上进行指导调整，增强LLMs的推理能力，我们旨在克服显式图结构信息带来的挑战，并提高图结构学习的可靠性。

    arXiv:2402.15183v1 Announce Type: cross  Abstract: Graph Structure Learning (GSL) focuses on capturing intrinsic dependencies and interactions among nodes in graph-structured data by generating novel graph structures. Graph Neural Networks (GNNs) have emerged as promising GSL solutions, utilizing recursive message passing to encode node-wise inter-dependencies. However, many existing GSL methods heavily depend on explicit graph structural information as supervision signals, leaving them susceptible to challenges such as data noise and sparsity. In this work, we propose GraphEdit, an approach that leverages large language models (LLMs) to learn complex node relationships in graph-structured data. By enhancing the reasoning capabilities of LLMs through instruction-tuning over graph structures, we aim to overcome the limitations associated with explicit graph structural information and enhance the reliability of graph structure learning. Our approach not only effectively denoises noisy co
    
[^139]: 面向预训练大型语言模型的机器遗忘

    Machine Unlearning of Pre-trained Large Language Models

    [https://arxiv.org/abs/2402.15159](https://arxiv.org/abs/2402.15159)

    本研究在大型语言模型（LLMs）中探讨了“被遗忘权”的概念，提出机器遗忘作为解决方案，并在预训练模型中建立了全面的遗忘框架及高效的遗忘方法，同时提供了改进超参数鲁棒性以及高效调整超参数的指南。

    

    本研究探讨了大型语言模型（LLMs）背景下“被遗忘权”的概念。我们以机器遗忘作为一个关键解决方案，重点关注预训练模型——一个明显缺乏研究的领域。我们在预训练LLMs中勾勒了一个全面的机器遗忘框架，包括对七种不同遗忘方法的批判性分析。通过使用来自arXiv、书籍和GitHub的策划数据集进行严格评估，我们建立了一个有力的机器遗忘性能基准，表明这些方法的计算效率比重新训练高出 $10^5$ 倍以上。我们的结果表明，在分布数据上将梯度上升与梯度下降结合可以改善超参数的鲁棒性。我们还提供了关于在遗忘过程中进行高效超参数调整的详细指南。我们的研究推动了有关伦理人工智能实践的讨论，提供了

    arXiv:2402.15159v1 Announce Type: cross  Abstract: This study investigates the concept of the `right to be forgotten' within the context of large language models (LLMs). We explore machine unlearning as a pivotal solution, with a focus on pre-trained models--a notably under-researched area. Our research delineates a comprehensive framework for machine unlearning in pre-trained LLMs, encompassing a critical analysis of seven diverse unlearning methods. Through rigorous evaluation using curated datasets from arXiv, books, and GitHub, we establish a robust benchmark for unlearning performance, demonstrating that these methods are over $10^5$ times more computationally efficient than retraining. Our results show that integrating gradient ascent with gradient descent on in-distribution data improves hyperparameter robustness. We also provide detailed guidelines for efficient hyperparameter tuning in the unlearning process. Our findings advance the discourse on ethical AI practices, offering
    
[^140]: 语义镜像越狱:基于遗传算法的针对开源LLM的越狱提示

    Semantic Mirror Jailbreak: Genetic Algorithm Based Jailbreak Prompts Against Open-source LLMs

    [https://arxiv.org/abs/2402.14872](https://arxiv.org/abs/2402.14872)

    本文提出了一种语义镜像越狱（SMJ）方法，通过生成在语义上类似于原始问题的越狱提示来绕过LLMs。

    

    大型语言模型（LLMs）通常用于创意写作、代码生成和翻译，根据输入序列生成文本，但容易受到越狱攻击的影响，其中精心设计的提示会导致有害输出。大多数越狱提示方法使用一组越狱模板，然后跟随提出问题，创建越狱提示。然而，现有的越狱提示设计通常存在过多的语义差异，导致无法抵御使用简单语义度量作为阈值的防御。越狱提示在语义上比用于查询的原始问题更加多样化。在本文中，我们介绍了一种称为语义镜像越狱（SMJ）的方法，通过生成在语义上类似于原始问题的越狱提示来绕过LLMs。我们将寻找既满足语义相似性又具有越狱有效性的越狱提示建模为一个多目标优化问题。

    arXiv:2402.14872v1 Announce Type: cross  Abstract: Large Language Models (LLMs), used in creative writing, code generation, and translation, generate text based on input sequences but are vulnerable to jailbreak attacks, where crafted prompts induce harmful outputs. Most jailbreak prompt methods use a combination of jailbreak templates followed by questions to ask to create jailbreak prompts. However, existing jailbreak prompt designs generally suffer from excessive semantic differences, resulting in an inability to resist defenses that use simple semantic metrics as thresholds. Jailbreak prompts are semantically more varied than the original questions used for queries. In this paper, we introduce a Semantic Mirror Jailbreak (SMJ) approach that bypasses LLMs by generating jailbreak prompts that are semantically similar to the original question. We model the search for jailbreak prompts that satisfy both semantic similarity and jailbreak validity as a multi-objective optimization proble
    
[^141]: COPR:通过最优策略正则化实现持续人类偏好学习

    COPR: Continual Human Preference Learning via Optimal Policy Regularization

    [https://arxiv.org/abs/2402.14228](https://arxiv.org/abs/2402.14228)

    提出了Continual Optimal Policy Regularization (COPR) 方法，通过借鉴最优策略理论，利用采样分布作为示范和正则化约束，以动态地对当前策略进行正则化，从而使强化学习从人类反馈中学习在持续学习情境下更加稳健

    

    arXiv:2402.14228v1 公告类型:跨界 摘要: 利用强化学习从人类反馈中学习（RLHF）通常用于改善大型语言模型（LLMs）与人类偏好的对齐。鉴于人类偏好的不断变化，持续对齐相对于传统静态对齐变得更加重要和实际。然而，使RLHF与持续学习（CL）兼容由于其复杂过程而具有挑战性。同时，直接学习新的人类偏好可能导致历史偏好的灾难性遗忘（CF），导致无助或有害的结果。为了克服这些挑战，我们提出了Continual Optimal Policy Regularization (COPR) 方法，该方法借鉴了最优策略理论。COPR利用采样分布作为示范和正则化约束用于持续学习。它采用Lagrange对偶（LD）方法根据历史上的最优策略动态地正则化当前策略

    arXiv:2402.14228v1 Announce Type: cross  Abstract: Reinforcement Learning from Human Feedback (RLHF) is commonly utilized to improve the alignment of Large Language Models (LLMs) with human preferences. Given the evolving nature of human preferences, continual alignment becomes more crucial and practical in comparison to traditional static alignment. Nevertheless, making RLHF compatible with Continual Learning (CL) is challenging due to its complex process. Meanwhile, directly learning new human preferences may lead to Catastrophic Forgetting (CF) of historical preferences, resulting in helpless or harmful outputs. To overcome these challenges, we propose the Continual Optimal Policy Regularization (COPR) method, which draws inspiration from the optimal policy theory. COPR utilizes a sampling distribution as a demonstration and regularization constraints for CL. It adopts the Lagrangian Duality (LD) method to dynamically regularize the current policy based on the historically optimal p
    
[^142]: 委员会的智慧：从基础模型到专用应用模型的提取

    Wisdom of Committee: Distilling from Foundation Model to SpecializedApplication Model

    [https://arxiv.org/abs/2402.14035](https://arxiv.org/abs/2402.14035)

    将基础模型的知识转移到专用应用模型中存在挑战，提出了通过创建教学委员会来应对这些挑战。

    

    最近基础模型的进展在各种任务上取得了令人印象深刻的性能，与此同时，为特定应用，从业者们一直在开发专门的应用模型。为了享受这两种模型的好处，一个自然的路径是将基础模型中的知识转移到专用应用模型中，后者通常更有效地提供服务。知识蒸馏的技术可以在这里应用，其中应用模型学会模仿基础模型。然而，专用应用模型和基础模型在容量上存在实质性差距，采用不同的架构，使用来自不同模态的不同输入特征，并在不同的分布上进行优化。模型特征上的这些差异导致了蒸馏方法面临重大挑战。在这项工作中，我们提出创建一个教学委员会，包括基础模型和专用应用模型。

    arXiv:2402.14035v1 Announce Type: cross  Abstract: Recent advancements in foundation models have yielded impressive performance across a wide range of tasks. Meanwhile, for specific applications, practitioners have been developing specialized application models. To enjoy the benefits of both kinds of models, one natural path is to transfer the knowledge in foundation models into specialized application models, which are generally more efficient for serving. Techniques from knowledge distillation may be applied here, where the application model learns to mimic the foundation model. However, specialized application models and foundation models have substantial gaps in capacity, employing distinct architectures, using different input features from different modalities, and being optimized on different distributions. These differences in model characteristics lead to significant challenges for distillation methods. In this work, we propose creating a teaching committee comprising both foun
    
[^143]: ProSparse: 引入和增强大型语言模型内部激活稀疏性

    ProSparse: Introducing and Enhancing Intrinsic Activation Sparsity within Large Language Models

    [https://arxiv.org/abs/2402.13516](https://arxiv.org/abs/2402.13516)

    本文介绍了一种名为"ProSparse"的有效稀疏化方法，以推动大型语言模型实现更高的激活稀疏性而不降低模型性能

    

    Activation sparsity指的是激活输出中存在许多弱贡献元素。作为使用ReLU激活函数的模型的普遍属性，已被证明是提高模型推理效率的一种有前途的范例。然而，大多数大型语言模型（LLMs）采用了没有内在激活稀疏性的激活函数（例如GELU和Swish）。一些最近的努力尝试引入ReLU或其变体作为替代激活函数，以帮助LLMs实现激活稀疏性和推理加速，但很少能同时获得高稀疏度和可比较的模型性能。本文介绍了一种名为"ProSparse"的有效稀疏化方法，以推动LLMs实现更高的激活稀疏性而不降低模型性能。具体来说，将LLMs的激活函数替换为ReLU后，ProSparse采用渐进稀疏正则化

    arXiv:2402.13516v1 Announce Type: cross  Abstract: Activation sparsity refers to the existence of considerable weakly-contributed elements among activation outputs. As a prevalent property of the models using the ReLU activation function, it has been proven a promising paradigm to boost model inference efficiency. Nevertheless, most large language models (LLMs) adopt activation functions without intrinsic activation sparsity (e.g., GELU and Swish). Some recent efforts have explored introducing ReLU or its variants as the substitutive activation function to help LLMs achieve activation sparsity and inference acceleration, but few can simultaneously obtain high sparsity and comparable model performance. This paper introduces an effective sparsification method named "ProSparse" to push LLMs for higher activation sparsity without decreasing model performance. Specifically, after substituting the activation function of LLMs with ReLU, ProSparse adopts progressive sparsity regularization wit
    
[^144]: 来自异构数据的联邦因果发现

    Federated Causal Discovery from Heterogeneous Data

    [https://arxiv.org/abs/2402.13241](https://arxiv.org/abs/2402.13241)

    该研究提出了一种新型联邦因果发现方法，旨在适应任意因果模型和异构数据，通过使用替代变量和联邦条件独立性检验来解决数据异质性，并建立了联邦独立变化原则用于确定因果方向。

    

    传统的因果发现方法依赖于集中式数据，这与许多实际情况下数据的分散性质不一致。这种差异推动了联邦因果发现（FCD）方法的发展。然而，现有的FCD方法可能受到其对可识别功能因果模型或 homogeneous数据分布的潜在限制，从而限制了它们在各种场景中的适用性。在本文中，我们提出了一种尝试适应任意因果模型和异构数据的新型FCD方法。我们首先利用与客户端索引对应的替代变量，以解决不同客户端之间的数据异质性。然后我们开发了一个用于因果骨架发现的联邦条件独立性检验（FCIT），并建立了一个用于确定因果方向的联邦独立变化原则（FICP）。这些方法涉及构建

    arXiv:2402.13241v1 Announce Type: cross  Abstract: Conventional causal discovery methods rely on centralized data, which is inconsistent with the decentralized nature of data in many real-world situations. This discrepancy has motivated the development of federated causal discovery (FCD) approaches. However, existing FCD methods may be limited by their potentially restrictive assumptions of identifiable functional causal models or homogeneous data distributions, narrowing their applicability in diverse scenarios. In this paper, we propose a novel FCD method attempting to accommodate arbitrary causal models and heterogeneous data. We first utilize a surrogate variable corresponding to the client index to account for the data heterogeneity across different clients. We then develop a federated conditional independence test (FCIT) for causal skeleton discovery and establish a federated independent change principle (FICP) to determine causal directions. These approaches involve constructing
    
[^145]: 信心至关重要：重新审视大型语言模型的内在自我校正能力

    Confidence Matters: Revisiting Intrinsic Self-Correction Capabilities of Large Language Models

    [https://arxiv.org/abs/2402.12563](https://arxiv.org/abs/2402.12563)

    本文研究了大型语言模型的内在自我校正能力，并提出了一个“如果-否则”（IoE）提示框架，帮助模型评估自身“信心”并进行自我校正。

    

    大型语言模型（LLMs）的最近成功激发了对它们自我校正能力的越来越多的兴趣。本文对LLMs的内在自我校正进行了全面调查，试图解决关于其可行性的持续争论。我们的研究确定了一个重要的潜在因素 - LLMs的“信心” - 在自我校正过程中。忽视这一因素可能导致模型过度批评自己，从而导致对自校正效果的可靠结论不准确。我们实验观察到LLMs具有理解其自身回应“信心”的能力。这激励我们开发了一个“如果-否则”（IoE）提示框架，旨在引导LLMs评估其自身“信心”，促进内在自我校正。我们进行了大量实验证明，我们基于IoE的提示可以实现一

    arXiv:2402.12563v1 Announce Type: cross  Abstract: The recent success of Large Language Models (LLMs) has catalyzed an increasing interest in their self-correction capabilities. This paper presents a comprehensive investigation into the intrinsic self-correction of LLMs, attempting to address the ongoing debate about its feasibility. Our research has identified an important latent factor - the ``confidence'' of LLMs - during the self-correction process. Overlooking this factor may cause the models to over-criticize themselves, resulting in unreliable conclusions regarding the efficacy of self-correction. We have experimentally observed that LLMs possess the capability to understand the ``confidence'' in their own responses. It motivates us to develop an ``If-or-Else'' (IoE) prompting framework, designed to guide LLMs in assessing their own ``confidence'', facilitating intrinsic self-corrections. We conduct extensive experiments and demonstrate that our IoE-based Prompt can achieve a co
    
[^146]: 从后门毒化数据集中通过降频空间获取清洁语言模型

    Acquiring Clean Language Models from Backdoor Poisoned Datasets by Downscaling Frequency Space

    [https://arxiv.org/abs/2402.12026](https://arxiv.org/abs/2402.12026)

    通过对频率空间的分析，本文提出了一种多尺度低秩适应（MuScleLoRA）方法，用于解决在训练语言模型时受到后门攻击的问题。

    

    尽管语言模型（LMs）在各种自然语言处理（NLP）任务中取得了显著成功，但LMs的可靠性容易受到后门攻击的影响。先前的研究尝试在毒化数据集上训练LMs时减轻后门学习，但在现实场景中抵御复杂的后门攻击时仍然面临困难。在本文中，我们通过傅里叶分析研究了频率空间中后门LMs的学习机制。我们的发现表明，毒化数据集上呈现的后门映射相比清洁映射更倾向于较低频率，导致后门映射更快地收敛。为了解决这一困境，我们提出了多尺度低秩适应（MuScleLoRA），它在频率空间中部署多个径向缩放，低秩适应目标模型，并在更新参数时进一步调整梯度。通过降频

    arXiv:2402.12026v1 Announce Type: cross  Abstract: Despite the notable success of language models (LMs) in various natural language processing (NLP) tasks, the reliability of LMs is susceptible to backdoor attacks. Prior research attempts to mitigate backdoor learning while training the LMs on the poisoned dataset, yet struggles against complex backdoor attacks in real-world scenarios. In this paper, we investigate the learning mechanisms of backdoor LMs in the frequency space by Fourier analysis. Our findings indicate that the backdoor mapping presented on the poisoned datasets exhibits a more discernible inclination towards lower frequency compared to clean mapping, resulting in the faster convergence of backdoor mapping. To alleviate this dilemma, we propose Multi-Scale Low-Rank Adaptation (MuScleLoRA), which deploys multiple radial scalings in the frequency space with low-rank adaptation to the target model and further aligns the gradients when updating parameters. Through downscal
    
[^147]: 生成万花筒网络

    Generative Kaleidoscopic Networks

    [https://arxiv.org/abs/2402.11793](https://arxiv.org/abs/2402.11793)

    发现深层ReLU网络表现出过度泛化现象，利用这一特性设计了“生成万花筒网络”，通过递归映射随机输入噪声生成样本。

    

    发现深层ReLU网络（或多层感知器架构）表现出“过度泛化”现象。也就是说，那些在训练过程中没有看到的输入的输出值被映射到了在学习过程中观察到的输出范围附近。换句话说，多层感知器学习了一对多的映射，这种效应在增加层数或多层感知器的深度时更为明显。我们利用了深层ReLU网络的这一特性来设计一个数据集万花筒，称为“生成万花筒网络”。简而言之，如果我们学习一个多层感知器将输入 $x\in\mathbb{R}^D$ 映射到自身 $f_\mathcal{N}(x)\rightarrow x$，那么“万花筒采样”过程将从随机输入噪声 $z\in\mathbb{R}^D$ 开始，并递归地应用 $f_\mathcal{N}(\cdots f_\mathcal{N}(z)\cdots )$。经过燃烧期后，我们开始观察来自输入分布的样本，我们发现更深的

    arXiv:2402.11793v1 Announce Type: cross  Abstract: We discovered that the Deep ReLU networks (or Multilayer Perceptron architecture) demonstrate an 'over-generalization' phenomenon. That is, the output values for the inputs that were not seen during training are mapped close to the output range that were observed during the learning process. In other words, the MLP learns a many-to-one mapping and this effect is more prominent as we increase the number of layers or depth of the MLP. We utilize this property of Deep ReLU networks to design a dataset kaleidoscope, termed as 'Generative Kaleidoscopic Networks'. Briefly, if we learn a MLP to map from input $x\in\mathbb{R}^D$ to itself $f_\mathcal{N}(x)\rightarrow x$, the 'Kaleidoscopic sampling' procedure starts with a random input noise $z\in\mathbb{R}^D$ and recursively applies $f_\mathcal{N}(\cdots f_\mathcal{N}(z)\cdots )$. After a burn-in period duration, we start observing samples from the input distribution and we found that deeper 
    
[^148]: 数据到文本自然语言生成研究的系统性回顾

    A Systematic Review of Data-to-Text NLG

    [https://arxiv.org/abs/2402.08496](https://arxiv.org/abs/2402.08496)

    这篇系统性回顾全面分析了数据到文本自然语言生成研究的现状，提出未来方向，并解决了相关挑战。

    

    这篇系统性回顾旨在全面分析数据到文本生成研究的现状，重点是确定研究空白，提供未来方向，并解决回顾中发现的挑战。我们对文献进行了全面的检查，包括方法、数据集、评估指标、应用、多语言性和幻觉缓解措施。我们的回顾为这个快速发展的领域的未来研究提供了路线图。

    This systematic review aims to provide a comprehensive analysis of the state of data-to-text generation research, focusing on identifying research gaps, offering future directions, and addressing challenges found during the review. We thoroughly examined the literature, including approaches, datasets, evaluation metrics, applications, multilingualism, and hallucination mitigation measures. Our review provides a roadmap for future research in this rapidly evolving field.
    
[^149]: 关于Transformer架构的限制

    On Limitations of the Transformer Architecture

    [https://arxiv.org/abs/2402.08164](https://arxiv.org/abs/2402.08164)

    本论文通过通信复杂性证明了Transformer层在处理函数组合任务时的局限性，指出对于大型定义域和某些数学任务，Transformers可能无法解决。

    

    大型语言模型（LLMs）中幻觉的根本原因是什么？我们使用通信复杂性来证明，如果函数的定义域足够大，Transformer层无法组合函数（例如，在家谱中查找一个人的祖父）；我们通过示例显示，当定义域相当小的时候，这种能力的缺乏已经在经验上存在。我们还指出，许多在所谓的组合任务中的数学任务，认为它们对LLMs来说很难解决，对于足够大的实例来说，且假设计算复杂性领域的某些被广泛接受的猜想是正确的，Transformers也不太可能解决。

    What are the root causes of hallucinations in large language models (LLMs)? We use Communication Complexity to prove that the Transformer layer is incapable of composing functions (e.g., identify a grandparent of a person in a genealogy) if the domains of the functions are large enough; we show through examples that this inability is already empirically present when the domains are quite small. We also point out that several mathematical tasks that are at the core of the so-called compositional tasks thought to be hard for LLMs are unlikely to be solvable by Transformers, for large enough instances and assuming that certain well accepted conjectures in the field of Computational Complexity are true.
    
[^150]: TriAug：用于超声乳腺病变不平衡分类的异常样本检测

    TriAug: Out-of-Distribution Detection for Robust Classification of Imbalanced Breast Lesion in Ultrasound

    [https://arxiv.org/abs/2402.07452](https://arxiv.org/abs/2402.07452)

    TriAug是一个用于乳腺超声图像的异常样本检测框架，通过使用三元状态增强和平衡的球形损失来提高示踪分类的准确性和异常样本检测性能。

    

    不同的疾病，如乳腺病变的组织亚型，具有严重不同的发病率。即使通过大量的示踪数据进行训练，模型在临床实际中通常遇到属于未见类别的异常样本。为了解决这个问题，我们提出了一种新的框架，基于乳腺超声图像的长尾异常样本检测任务，并配备了一种三元状态增强（TriAug），它可以提高示踪分类的准确性，同时保持良好的异常样本检测性能。与此同时，我们设计了一个平衡的球形损失来处理类不平衡的问题。

    Different diseases, such as histological subtypes of breast lesions, have severely varying incidence rates. Even trained with substantial amount of in-distribution (ID) data, models often encounter out-of-distribution (OOD) samples belonging to unseen classes in clinical reality. To address this, we propose a novel framework built upon a long-tailed OOD detection task for breast ultrasound images. It is equipped with a triplet state augmentation (TriAug) which improves ID classification accuracy while maintaining a promising OOD detection performance. Meanwhile, we designed a balanced sphere loss to handle the class imbalanced problem.
    
[^151]: HarmBench：用于自动红队和强大拒绝的标准化评估框架

    HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal

    [https://arxiv.org/abs/2402.04249](https://arxiv.org/abs/2402.04249)

    HarmBench是一个为自动红队和强大拒绝设计的标准化评估框架，通过对18种红队方法和33个目标LLM和防御的比较，得出了新的见解，并介绍了一种高效的对抗训练方法，提高了LLM在各种攻击下的稳健性。

    

    自动红队具有发现和减轻大型语言模型（LLM）恶意使用的风险的巨大潜力，然而该领域缺乏一个标准化的评估框架来严格评估新方法。为了解决这个问题，我们引入了HarmBench，一个用于自动红队的标准化评估框架。我们在红队评估中确定了几个以前未考虑的有吸引力的特性，并系统地设计了HarmBench以满足这些标准。使用HarmBench，我们对18种红队方法和33个目标LLM和防御进行了大规模比较，得到了新的见解。我们还引入了一种高效的对抗训练方法，显著增强了LLM在各种攻击下的稳健性，展示了HarmBench如何促进攻击和防御的共同开发。我们在https://github.com/centerforaisafety/HarmBench上开源了HarmBench。

    Automated red teaming holds substantial promise for uncovering and mitigating the risks associated with the malicious use of large language models (LLMs), yet the field lacks a standardized evaluation framework to rigorously assess new methods. To address this issue, we introduce HarmBench, a standardized evaluation framework for automated red teaming. We identify several desirable properties previously unaccounted for in red teaming evaluations and systematically design HarmBench to meet these criteria. Using HarmBench, we conduct a large-scale comparison of 18 red teaming methods and 33 target LLMs and defenses, yielding novel insights. We also introduce a highly efficient adversarial training method that greatly enhances LLM robustness across a wide range of attacks, demonstrating how HarmBench enables codevelopment of attacks and defenses. We open source HarmBench at https://github.com/centerforaisafety/HarmBench.
    
[^152]: ANLS* -- 一种适用于生成型大语言模型的通用文档处理度量方法

    ANLS* -- A Universal Document Processing Metric for Generative Large Language Models

    [https://arxiv.org/abs/2402.03848](https://arxiv.org/abs/2402.03848)

    ANLS*是一种用于生成型模型的新度量方法，针对各种任务包括信息提取和分类任务进行评估。它扩展了现有的ANLS度量方法，可以作为替代方案使用。

    

    传统上，在文档分类和信息提取等任务中，区分模型一直是主要选择。这些模型做出的预测可以分为有限数量的预定义类别，便于进行二元真假评估，并能直接计算F1分数等指标。然而，生成型大语言模型（GLLMs）的最新进展促使领域发生了转变，因为它们具备了强大的零-shot能力，消除了下游数据集和计算昂贵的微调的需求。然而，评估GLLMs存在挑战，因为对于GLLMs的预测，不能应用于区分模型所使用的二元真假评估方法。本文引入了一种用于生成型模型的新度量方法，称为ANLS*，用于评估各种任务，包括信息提取和分类任务。ANLS*度量方法扩展了现有ANLS度量方法，可作为一种即插即用的替代方案。

    Traditionally, discriminative models have been the predominant choice for tasks like document classification and information extraction. These models make predictions that fall into a limited number of predefined classes, facilitating a binary true or false evaluation and enabling the direct calculation of metrics such as the F1 score. However, recent advancements in generative large language models (GLLMs) have prompted a shift in the field due to their enhanced zero-shot capabilities, which eliminate the need for a downstream dataset and computationally expensive fine-tuning. However, evaluating GLLMs presents a challenge as the binary true or false evaluation used for discriminative models is not applicable to the predictions made by GLLMs. This paper introduces a new metric for generative models called ANLS* for evaluating a wide variety of tasks, including information extraction and classification tasks. The ANLS* metric extends existing ANLS metrics as a drop-in-replacement and i
    
[^153]: 用语言模型区分可知与不可知的能力

    Distinguishing the Knowable from the Unknowable with Language Models

    [https://arxiv.org/abs/2402.03563](https://arxiv.org/abs/2402.03563)

    通过研究大型语言模型，在自由文本中识别作为代理的模型和冻结预训练模型的嵌入的小型线性探测器可以准确预测更大模型令牌级别上的自信度，进一步提出了一种无监督的方法在相同任务上达到了非平凡的准确度，这证明了语言模型中存在不同类型的不确定性表示。

    

    我们研究了在大型语言模型（LLMs）生成的自由文本输出中，是否可以鉴别出认知不确定性（反映缺乏知识的不确定性）和偶然不确定性（反映基础分布中的熵）。在没有真实概率的情况下，我们探索了一个设置，在这个设置中，为了（近似地）分解给定LLM的不确定性，一个明显更大的模型充当地面真相的代理。我们表明，基于冻结预训练模型的嵌入的小型线性探测器能够准确预测在令牌级别上更大模型将更自信的情况，并且在一个文本领域上训练的探测器可以泛化到其他领域。进一步地，我们提出了一种完全无监督的方法，在相同任务上达到了非平凡的准确度。综合考虑这些结果，我们解释这些结果作为LLMs内部自然地包含了不同类型不确定性的表示，这可能有助于制定更有效的方法。

    We study the feasibility of identifying epistemic uncertainty (reflecting a lack of knowledge), as opposed to aleatoric uncertainty (reflecting entropy in the underlying distribution), in the outputs of large language models (LLMs) over free-form text. In the absence of ground-truth probabilities, we explore a setting where, in order to (approximately) disentangle a given LLM's uncertainty, a significantly larger model stands in as a proxy for the ground truth. We show that small linear probes trained on the embeddings of frozen, pretrained models accurately predict when larger models will be more confident at the token level and that probes trained on one text domain generalize to others. Going further, we propose a fully unsupervised method that achieves non-trivial accuracy on the same task. Taken together, we interpret these results as evidence that LLMs naturally contain internal representations of different types of uncertainty that could potentially be leveraged to devise more i
    
[^154]: 使用分子配置转换器生成用于分子动力学模拟的高精度力场，研究化学反应机理

    Generating High-Precision Force Fields for Molecular Dynamics Simulations to Study Chemical Reaction Mechanisms using Molecular Configuration Transformer

    [https://arxiv.org/abs/2401.00499](https://arxiv.org/abs/2401.00499)

    使用分子配置转换器生成高精度力场，以解决计算速度限制，从而在分子动力学模拟中研究化学反应机理。

    

    在有机化学中，化学反应机理的理论研究至关重要。传统上，使用量子化学计算计算手动构建的过渡态分子构型是最常用的方法。然而，这种方法在很大程度上依赖于个人经验和化学直觉。在我们之前的研究中，我们提出了一种使用分子动力学模拟中的增强采样来研究化学反应的研究范式。这种方法可以直接模拟化学反应的整个过程。然而，计算速度限制了用于模拟的高精度势能函数的使用。为解决这个问题，我们提出了一种方案，使用先前开发的基于图神经网络的分子模型-分子配置转换器来训练高精度分子建模力场。

    arXiv:2401.00499v2 Announce Type: replace-cross  Abstract: Theoretical studies on chemical reaction mechanisms have been crucial in organic chemistry. Traditionally, calculating the manually constructed molecular conformations of transition states for chemical reactions using quantum chemical calculations is the most commonly used method. However, this way is heavily dependent on individual experience and chemical intuition. In our previous study, we proposed a research paradigm that uses enhanced sampling in molecular dynamics simulations to study chemical reactions. This approach can directly simulate the entire process of a chemical reaction. However, the computational speed limits the use of high-precision potential energy functions for simulations. To address this issue, we present a scheme for training high-precision force fields for molecular modeling using a previously developed graph-neural-network-based molecular model, molecular configuration transformer. This potential ener
    
[^155]: KnowGPT：大型语言模型的黑盒知识注入

    KnowGPT: Black-Box Knowledge Injection for Large Language Models

    [https://arxiv.org/abs/2312.06185](https://arxiv.org/abs/2312.06185)

    KnowGPT是一种为大型语言模型提供黑盒知识注入的框架，通过深度强化学习和多臂老虎机构建最适合每个问题的提示，在三个基准数据集上实验证明其显著提升了知识注入的效果。

    

    生成式大型语言模型（LLMs），如ChatGPT，提供互动式API，可以以人类专家水平回答常见问题。然而，当面临需要特定领域或专业领域知识的问题时，这些模型通常会给出不准确或不正确的响应，这些知识并未包含在它们的训练语料库中。此外，许多最先进的LLMs并非开源，这使得仅使用模型API注入知识具有挑战性。在本研究中，我们介绍了KnowGPT，一种用于LLMs在问答中的黑盒知识注入框架。KnowGPT利用深度强化学习（RL）从知识图中提取相关知识，并使用多臂老虎机（MAB）为每个问题构建最合适的提示。我们在三个基准数据集上进行了大量实验，展示了KnowGPT显著增强了现有方法。值得注意的是，KnowGPT平均改进了23%。

    arXiv:2312.06185v2 Announce Type: replace-cross  Abstract: Generative Large Language Models (LLMs), such as ChatGPT, offer interactive APIs that can answer common questions at a human-expert level. However, these models often give inaccurate or incorrect responses when faced with questions requiring domain-specific or professional-specific knowledge not covered in their training corpus. Furthermore, many state-of-the-art LLMs are not open-source, making it challenging to inject knowledge with model APIs only. In this work, we introduce KnowGPT, a black-box knowledge injection framework for LLMs in question answering. KnowGPT leverages deep reinforcement learning (RL) to extract relevant knowledge from Knowledge Graphs (KGs) and use Multi-Armed Bandit (MAB) to construct the most suitable prompt for each question. Our extensive experiments on three benchmark datasets showcase that KnowGPT significantly enhances the existing methods. Notably, KnowGPT achieves an average improvement of 23.
    
[^156]: 基于深度生成网络的语音生成的神经语音嵌入

    Neural Speech Embeddings for Speech Synthesis Based on Deep Generative Networks

    [https://arxiv.org/abs/2312.05814](https://arxiv.org/abs/2312.05814)

    神经语音嵌入在基于深度生成网络的语音合成中起着重要作用，可以直接将脑信号转化为语音，极大地增强了交流的自然性。

    

    arXiv:2312.05814v2 公告类型: 替换 摘要: 脑到语音技术代表了跨学科应用的融合，涵盖了人工智能、脑-计算机界面和语音合成领域。基于神经表征学习的意图解码和语音合成直接将神经活动与人类语言交流方式联系起来，这可能极大增强交流的自然性。随着对表征学习的当前发现和语音合成技术的发展，直接将脑信号翻译成语音显示出巨大的潜力。特别是，输入特征和神经语音嵌入在使用深度生成模型从脑信号生成语音时发挥着重要作用。在本文中，我们介绍了当前的脑到语音技术，以及从脑信号合成语音的可能性。

    arXiv:2312.05814v2 Announce Type: replace  Abstract: Brain-to-speech technology represents a fusion of interdisciplinary applications encompassing fields of artificial intelligence, brain-computer interfaces, and speech synthesis. Neural representation learning based intention decoding and speech synthesis directly connects the neural activity to the means of human linguistic communication, which may greatly enhance the naturalness of communication. With the current discoveries on representation learning and the development of the speech synthesis technologies, direct translation of brain signals into speech has shown great promise. Especially, the processed input features and neural speech embeddings which are given to the neural network play a significant role in the overall performance when using deep generative models for speech generation from brain signals. In this paper, we introduce the current brain-to-speech technology with the possibility of speech synthesis from brain signa
    
[^157]: 未观察到的混杂下的因果公平性：一种神经敏感性框架

    Causal Fairness under Unobserved Confounding: A Neural Sensitivity Framework

    [https://arxiv.org/abs/2311.18460](https://arxiv.org/abs/2311.18460)

    分析了因果公平性对未观察到混杂的敏感性，推导出因果公平性指标的界限，提出神经框架用于学习公平预测，展示了框架的有效性

    

    机器学习预测中的公平性由于法律、道德和社会原因在实践中被广泛要求。现有工作通常集中在没有未观察到的混杂的设置上，尽管未观察到的混杂可能导致严重违反因果公平性，从而产生不公平的预测。在这项工作中，我们分析了因果公平性对未观察到的混杂的敏感性。我们的贡献有三个方面。首先，我们推导出不同来源的未观察到混杂下因果公平性指标的界限。这使从业者能够检查其机器学习模型对在公平关键应用中的未观察到的混杂的敏感性。其次，我们提出了一种用于学习公平预测的新型神经框架，这使我们能够提供对因果公平性可能由于未观察到的混杂而受到违反的程度的最坏情况保证。第三，我们展示了我们框架的有效性。

    arXiv:2311.18460v2 Announce Type: replace-cross  Abstract: Fairness for machine learning predictions is widely required in practice for legal, ethical, and societal reasons. Existing work typically focuses on settings without unobserved confounding, even though unobserved confounding can lead to severe violations of causal fairness and, thus, unfair predictions. In this work, we analyze the sensitivity of causal fairness to unobserved confounding. Our contributions are three-fold. First, we derive bounds for causal fairness metrics under different sources of unobserved confounding. This enables practitioners to examine the sensitivity of their machine learning models to unobserved confounding in fairness-critical applications. Second, we propose a novel neural framework for learning fair predictions, which allows us to offer worst-case guarantees of the extent to which causal fairness can be violated due to unobserved confounding. Third, we demonstrate the effectiveness of our framewor
    
[^158]: 使用可屏蔽股票表示的强化学习在可定制股票池中进行投资组合管理

    Reinforcement Learning with Maskable Stock Representation for Portfolio Management in Customizable Stock Pools

    [https://arxiv.org/abs/2311.10801](https://arxiv.org/abs/2311.10801)

    使用EarnMore方法，我们提出了一种新的RL方法，可以允许RL代理与可定制股票池（CSPs）交互，而不需要重新训练。

    

    投资组合管理（PM）是一项基本的金融交易任务，探索定期将资金重新配置到不同股票中以追求长期利润。最近，强化学习（RL）显示出其潜力，通过与金融市场互动来训练具有盈利能力的PM代理。但是，现有工作主要集中在固定股票池上，这与投资者的实际需求不一致。为应对这一挑战，我们提出EarnMore，一种新的RL方法，可以允许RL代理与可定制股票池（CSPs）交互，而不需要重新训练。

    arXiv:2311.10801v3 Announce Type: replace-cross  Abstract: Portfolio management (PM) is a fundamental financial trading task, which explores the optimal periodical reallocation of capitals into different stocks to pursue long-term profits. Reinforcement learning (RL) has recently shown its potential to train profitable agents for PM through interacting with financial markets. However, existing work mostly focuses on fixed stock pools, which is inconsistent with investors' practical demand. Specifically, the target stock pool of different investors varies dramatically due to their discrepancy on market states and individual investors may temporally adjust stocks they desire to trade (e.g., adding one popular stocks), which lead to customizable stock pools (CSPs). Existing RL methods require to retrain RL agents even with a tiny change of the stock pool, which leads to high computational cost and unstable performance. To tackle this challenge, we propose EarnMore, a rEinforcement leARNin
    
[^159]: 少样本迁移学习用于知识库问答：融合监督模型和上下文学习

    Few-shot Transfer Learning for Knowledge Base Question Answering: Fusing Supervised Models with In-Context Learning

    [https://arxiv.org/abs/2311.08894](https://arxiv.org/abs/2311.08894)

    提出了一种新的KBQA架构FuSIC-KBQA，通过多个源训练的召回器执行KB检索，在LLM的重新排序后以此作为LLM少样本上下文学习的输入来生成逻辑形式，并利用执行引导反馈进一步优化。

    

    现有的知识库问答（KBQA）架构需要大量注释数据，这使得它们在部署时成本高且耗时。我们提出少样本迁移学习用于KBQA的问题，目标域仅提供少量标记示例，但在源域中有大量标记训练数据集可用。我们提出了一种名为FuSIC-KBQA的新型KBQA架构，它使用多个经过源培训的召回器执行KB检索，使用LLM重新排序，将此作为LLM少样本上下文学习的输入以生成逻辑形式，进一步使用执行引导反馈进行细化。在四对不同复杂度的源-目标KBQA对上的实验表明，FuSIC-KBQA明显优于为此设置调整的SoTA KBQA模型。在领域内设置的额外实验表明，当训练数据有限时，FuSIC-KBQA也优于SoTA KBQA模型。

    arXiv:2311.08894v2 Announce Type: replace-cross  Abstract: Existing Knowledge Base Question Answering (KBQA) architectures are hungry for annotated data, which make them costly and time-consuming to deploy. We introduce the problem of few-shot transfer learning for KBQA, where the target domain offers only a few labeled examples, but a large labeled training dataset is available in a source domain. We propose a novel KBQA architecture called FuSIC-KBQA that performs KB-retrieval using multiple source-trained retrievers, re-ranks using an LLM and uses this as input for LLM few-shot in-context learning to generate logical forms, which are further refined using execution-guided feedback. Experiments over four source-target KBQA pairs of varying complexity show that FuSIC-KBQA significantly outperforms adaptations of SoTA KBQA models for this setting. Additional experiments in the in-domain setting show that FuSIC-KBQA also outperforms SoTA KBQA models when training data is limited.
    
[^160]: Labor Space: 通过大型语言模型对劳动力市场进行统一表征

    Labor Space: A Unifying Representation of the Labor Market via Large Language Models

    [https://arxiv.org/abs/2311.06310](https://arxiv.org/abs/2311.06310)

    "Labor Space"是利用大型语言模型精细调整而成的矢量空间嵌入，揭示了劳动力市场各种组成部分的复杂关系结构，促进了对行业、职业、技能和公司的综合分析。

    

    劳动力市场是一个复杂的生态系统，包括各种相互关联的实体，如行业、职业、技能和公司。由于缺乏将这些异质实体系统地映射在一起的方法，每个实体都被孤立地分析或仅通过成对关系，抑制了对整个生态系统的全面理解。在本研究中，我们介绍了"Labor Space"，这是通过应用具有微调的大型语言模型导出的异质劳动力市场实体的矢量空间嵌入。Labor Space展示了各种劳动力市场成分的复杂关系结构，促进了对行业、职业、技能和公司的一致综合分析，同时保留了特定类型的聚类。我们展示了其前所未有的分析能力，包括将异质实体定位在经济轴上，如“制造业-医疗保健”。此外，

    arXiv:2311.06310v3 Announce Type: replace-cross  Abstract: The labor market is a complex ecosystem comprising diverse, interconnected entities, such as industries, occupations, skills, and firms. Due to the lack of a systematic method to map these heterogeneous entities together, each entity has been analyzed in isolation or only through pairwise relationships, inhibiting comprehensive understanding of the whole ecosystem. Here, we introduce $\textit{Labor Space}$, a vector-space embedding of heterogeneous labor market entities, derived through applying a large language model with fine-tuning. Labor Space exposes the complex relational fabric of various labor market constituents, facilitating coherent integrative analysis of industries, occupations, skills, and firms, while retaining type-specific clustering. We demonstrate its unprecedented analytical capacities, including positioning heterogeneous entities on an economic axes, such as `Manufacturing--Healthcare'. Furthermore, by allo
    
[^161]: 康德的义务论与人工智能对齐：迈向道德立足的公平度量

    Kantian Deontology Meets AI Alignment: Towards Morally Grounded Fairness Metrics

    [https://arxiv.org/abs/2311.05227](https://arxiv.org/abs/2311.05227)

    本文探讨了康德的义务论在公平度量中的应用，主张公平原则应与康德义务论框架相契合，以实现更具道德立足的人工智能和更平衡结果与程序的公平与正义。

    

    康德的义务论即伊曼纽尔·康德理解的那种，提供了一个强调职责和原则重要性而非行动后果的道德框架。本文认为，尽管义务论颇具突出，但在公平度量领域却鲜有研究，它探讨了康德义务论框架与公平度量的兼容性，在AI对齐领域中。我们重新审视了康德对功利主义的批判，而功利主义是AI公平度量的主要方法，主张公平原则应与康德义务论框架相契合。通过将康德伦理融入AI对齐，我们不仅引入了一个被广泛接受的重要道德理论，而且努力实现一个更具道德立足的人工智能领域，更好地平衡结果和程序，追求公平与正义。

    arXiv:2311.05227v2 Announce Type: replace  Abstract: Deontological ethics, specifically understood through Immanuel Kant, provides a moral framework that emphasizes the importance of duties and principles, rather than the consequences of action. Understanding that despite the prominence of deontology, it is currently an overlooked approach in fairness metrics, this paper explores the compatibility of a Kantian deontological framework in fairness metrics, part of the AI alignment field. We revisit Kant's critique of utilitarianism, which is the primary approach in AI fairness metrics and argue that fairness principles should align with the Kantian deontological framework. By integrating Kantian ethics into AI alignment, we not only bring in a widely-accepted prominent moral theory but also strive for a more morally grounded AI landscape that better balances outcomes and procedures in pursuit of fairness and justice.
    
[^162]: 细调小型语言模型以协调更大型语言模型提高复杂推理能力

    Small Language Models Fine-tuned to Coordinate Larger Language Models improve Complex Reasoning

    [https://arxiv.org/abs/2310.18338](https://arxiv.org/abs/2310.18338)

    细调小型语言模型作为分解生成器，使用策略梯度优化来协调更大型语言模型，进一步提高复杂推理能力

    

    大型语言模型（LLMs）在生成思维链（CoT）时展现出令人印象深刻的推理能力。最近对提示分解以解决复杂的多步推理问题的尝试取决于LLM同时分解和解决问题的能力。一个重要的缺点是，基础LLMs通常不可用于微调，使得适应性在计算上是禁锢的。我们认为（并证明）问题的分解和解决方案生成是不同的能力，最好通过单个庞大的LLM而不是一个整体模块来解决。我们引入了DaSLaM，它使用一个分解生成器将复杂问题分解成需要更少推理步骤的子问题。这些子问题由一个求解器来回答。我们使用一个相对小型（13B参数）LM作为分解生成器，我们使用策略梯度优化来与之交互进行训练。

    arXiv:2310.18338v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) prompted to generate chain-of-thought (CoT) exhibit impressive reasoning capabilities. Recent attempts at prompt decomposition toward solving complex, multi-step reasoning problems depend on the ability of the LLM to simultaneously decompose and solve the problem. A significant disadvantage is that foundational LLMs are typically not available for fine-tuning, making adaptation computationally prohibitive. We believe (and demonstrate) that problem decomposition and solution generation are distinct capabilites, better addressed in separate modules, than by one monolithic LLM. We introduce DaSLaM, which uses a decomposition generator to decompose complex problems into subproblems that require fewer reasoning steps. These subproblems are answered by a solver. We use a relatively small (13B parameters) LM as the decomposition generator, which we train using policy gradient optimization to interact with 
    
[^163]: 医疗保健中的多模态联邦学习：综述

    Multimodal Federated Learning in Healthcare: a Review

    [https://arxiv.org/abs/2310.09650](https://arxiv.org/abs/2310.09650)

    医疗保健领域引入了多模态联邦学习，结合最新的机器学习进展，确保了患者数据隐私和安全，为优化医疗AI系统提供了新的可能性。

    

    多模态机器学习的最新进展赋予了医学领域准确而稳健的AI系统的发展，尤其是在中心化数据库系统内。同时，联邦学习（FL）也得到了进展，提供了一种数据无需整合的去中心化机制，增强了对敏感医疗数据的隐私和安全性。这两个概念的整合支持了医疗保健中多模态学习的持续进展，同时确保了患者记录在本地数据持有机构内的安全和隐私。本文简要概述了FL在医疗保健中的重要性，并概述了医疗领域内多模态联邦学习（MMFL）的最新技术方法。文章全面审视了该领域中存在的挑战，揭示了现有模型的局限性。

    arXiv:2310.09650v2 Announce Type: replace-cross  Abstract: Recent advancements in multimodal machine learning have empowered the development of accurate and robust AI systems in the medical domain, especially within centralized database systems. Simultaneously, Federated Learning (FL) has progressed, providing a decentralized mechanism where data need not be consolidated, thereby enhancing the privacy and security of sensitive healthcare data. The integration of these two concepts supports the ongoing progress of multimodal learning in healthcare while ensuring the security and privacy of patient records within local data-holding agencies. This paper offers a concise overview of the significance of FL in healthcare and outlines the current state-of-the-art approaches to Multimodal Federated Learning (MMFL) within the healthcare domain. It comprehensively examines the existing challenges in the field, shedding light on the limitations of present models. Finally, the paper outlines poten
    
[^164]: 让循环的询问: 大型语言模型在判断中的摇摆

    Ask Again, Then Fail: Large Language Models' Vacillations in Judgement

    [https://arxiv.org/abs/2310.02174](https://arxiv.org/abs/2310.02174)

    目前的语言模型在面对后续问题时常常摇摆不定，研究者提出了一个后续问题机制和两个度量标准来量化这种不一致性，并开发出Unwavering-FQ框架来教导模型保持最初的正确判断，实验证明其有效性。

    

    我们观察到目前的会话式语言模型在面对后续问题时往往在其判断上摇摆不定，即使原始判断是正确的。这种摇摆对于生成可靠回复和建立用户信任构成了重要挑战。为了全面评估这一问题，我们引入了一个后续问题机制以及两个度量标准来量化这种不一致性，确认了当前语言模型普遍存在这种情况。为了缓解这一问题，我们探讨了各种提示策略用于闭源模型；此外，我们开发了一个基于训练的框架Unwavering-FQ，通过合成高质量的偏好数据来教导语言模型保持其最初的正确判断。我们的实验结果验证了我们框架的有效性以及其增强模型通用能力的能力。

    arXiv:2310.02174v2 Announce Type: replace-cross  Abstract: We observe that current conversational language models often waver in their judgements when faced with follow-up questions, even if the original judgement was correct. This wavering presents a significant challenge for generating reliable responses and building user trust. To comprehensively assess this issue, we introduce a Follow-up Questioning Mechanism along with two metrics to quantify this inconsistency, confirming its widespread presence in current language models. To mitigate this issue, we explore various prompting strategies for closed-source models; moreover, we develop a training-based framework Unwavering-FQ that teaches language models to maintain their originally correct judgements through synthesized high-quality preference data. Our experimental results confirm the effectiveness of our framework and its ability to enhance the general capabilities of models (https://github.com/NUSTM/LLMs-Waver-In-Judgements).
    
[^165]: EvalLM: 交互式评估基于用户定义标准的大型语言模型提示

    EvalLM: Interactive Evaluation of Large Language Model Prompts on User-Defined Criteria

    [https://arxiv.org/abs/2309.13633](https://arxiv.org/abs/2309.13633)

    EvalLM是一个交互式系统，帮助开发人员通过评估多个输出来改进大型语言模型提示，相比手动评估，能够帮助用户撰写更多样化的标准、检查更多输出，达到更满意的提示。

    

    通过简单地组合提示，开发人员可以使用大型语言模型（LLMs）原型化新颖的生成应用。然而，要将原型细化为产品，开发人员必须通过评估输出以诊断弱点来迭代修订提示。形成性访谈（N=8）显示，开发人员在评估输出时投入了大量精力，因为他们评估特定上下文和主观标准。我们提出了EvalLM，这是一个交互式系统，可以通过评估用户定义标准上的多个输出来迭代改进提示。用户可以通过用自然语言描述标准，使用系统基于LLM的评估器来获得提示在哪些方面表现出色或失败的概述，并根据评估器的反馈进行改进。一项比较研究（N=12）显示，与手动评估相比，EvalLM有助于帮助参与者撰写更多样化的标准、检查两倍数量的输出，并达到令人满意的提示。

    arXiv:2309.13633v2 Announce Type: replace-cross  Abstract: By simply composing prompts, developers can prototype novel generative applications with Large Language Models (LLMs). To refine prototypes into products, however, developers must iteratively revise prompts by evaluating outputs to diagnose weaknesses. Formative interviews (N=8) revealed that developers invest significant effort in manually evaluating outputs as they assess context-specific and subjective criteria. We present EvalLM, an interactive system for iteratively refining prompts by evaluating multiple outputs on user-defined criteria. By describing criteria in natural language, users can employ the system's LLM-based evaluator to get an overview of where prompts excel or fail, and improve these based on the evaluator's feedback. A comparative study (N=12) showed that EvalLM, when compared to manual evaluation, helped participants compose more diverse criteria, examine twice as many outputs, and reach satisfactory promp
    
[^166]: OCAtari: 以对象为中心的Atari 2600强化学习环境

    OCAtari: Object-Centric Atari 2600 Reinforcement Learning Environments

    [https://arxiv.org/abs/2306.08649](https://arxiv.org/abs/2306.08649)

    以对象为中心的Atari 2600强化学习环境OCAtari扩展了Atari Learning Environments框架，实现了对游戏中基于对象的状态进行资源高效提取，并允许对象发现、对象表征学习以及对象为中心的强化学习。

    

    认知科学和心理学表明，复杂场景的以对象为中心的表征是实现从低级感知特征有效抽象推理的一个有希望的步骤。然而，大多数深度强化学习方法只依赖于像素级表示，无法捕捉自然场景的组合特性。因此，我们需要允许我们处理和评估以对象为中心方法的环境和数据集。在我们的工作中，我们通过引入OCAtari来扩展Atari学习环境，这是深度RL方法最常用的评估框架，OCAtari对这些游戏进行了资源高效的对象中心状态提取。我们的框架允许对象发现、对象表征学习以及对象为中心的RL。我们评估了OCAtari的检测能力和资源效率。我们的源代码可在github.com/k4ntz/OC_Atari上找到。

    arXiv:2306.08649v2 Announce Type: replace-cross  Abstract: Cognitive science and psychology suggest that object-centric representations of complex scenes are a promising step towards enabling efficient abstract reasoning from low-level perceptual features. Yet, most deep reinforcement learning approaches only rely on pixel-based representations that do not capture the compositional properties of natural scenes. For this, we need environments and datasets that allow us to work and evaluate object-centric approaches. In our work, we extend the Atari Learning Environments, the most-used evaluation framework for deep RL approaches, by introducing OCAtari, that performs resource-efficient extractions of the object-centric states for these games. Our framework allows for object discovery, object representation learning, as well as object-centric RL. We evaluate OCAtari's detection capabilities and resource efficiency. Our source code is available at github.com/k4ntz/OC_Atari.
    
[^167]: 根据...：促使语言模型提高引用的能力

    "According to ...": Prompting Language Models Improves Quoting from Pre-Training Data

    [https://arxiv.org/abs/2305.13252](https://arxiv.org/abs/2305.13252)

    提出了“根据”提示方法，通过引导大型语言模型在响应中参考先前观察到的文本来改进引用，并提出了一种新的评估指标（QUIP-Score）来度量模型生成的答案在文本语料库中的直接发现程度。

    

    大型语言模型（LLMs）可能会产生幻觉并生成虚假信息，尽管它们事先在事实数据上进行了训练。受“据悉”的新闻设备启发，我们提出了“根据”提示：指导LLMs将响应与先前观察到的文本相联系。为了量化这种基础性，我们提出了一种新颖的评估指标（QUIP-Score），用于衡量模型生成的答案在基础文本语料库中直接找到的程度。我们通过对三个语料库（维基百科、PubMed和美国法律税法典）进行实验来说明这些提示根据我们的度量标准改善了基础性，而且通常还提高了最终任务性能。此外，要求模型减少基础性（或者根据其他语料库）的提示确实降低了QUIP-Score，表明LLMs有能力根据要求增加或减少基础性生成。

    arXiv:2305.13252v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) may hallucinate and generate fake information, despite pre-training on factual data. Inspired by the journalistic device of "according to sources", we propose according-to prompting: directing LLMs to ground responses against previously observed text. To quantify this grounding, we propose a novel evaluation metric (QUIP-Score) that measures the extent to which model-produced answers are directly found in underlying text corpora. We illustrate with experiments on three corpora (Wikipedia, PubMed, and the U.S. legal tax code) that these prompts improve grounding under our metrics, with the additional benefit of often improving end-task performance. Furthermore, prompts that ask the model to decrease grounding (or to ground to other corpora) indeed decrease QUIP-Score, indicating the ability of LLMs to increase or decrease grounded generations on request.
    
[^168]: 合成数据：方法、用例和风险

    Synthetic Data: Methods, Use Cases, and Risks

    [https://arxiv.org/abs/2303.01230](https://arxiv.org/abs/2303.01230)

    合成数据作为一种隐私增强技术，通过发布人工生成的数据集来代替敏感真实数据，具有巨大潜力，但仍面临未解决的隐私挑战和局限性。

    

    分享数据通常可以实现引人注目的应用程序和分析。然而，更多时候，有价值的数据集包含敏感信息，因此分享它们可能会危及用户和组织的隐私。在研究界和产业界都日益受到关注的一个可能替代方案是分享合成数据。这个想法是发布人工生成的数据集，这些数据集类似于实际数据 -- 更准确地说，具有类似的统计特性。在本文中，我们提供了合成数据的简要介绍，并讨论了它的用例、仍未解决的隐私挑战以及作为一种有效的隐私增强技术的内在局限性。

    arXiv:2303.01230v3 Announce Type: replace-cross  Abstract: Sharing data can often enable compelling applications and analytics. However, more often than not, valuable datasets contain information of a sensitive nature, and thus, sharing them can endanger the privacy of users and organizations. A possible alternative gaining momentum in both the research community and industry is to share synthetic data instead. The idea is to release artificially generated datasets that resemble the actual data -- more precisely, having similar statistical properties. In this article, we provide a gentle introduction to synthetic data and discuss its use cases, the privacy challenges that are still unaddressed, and its inherent limitations as an effective privacy-enhancing technology.
    
[^169]: 动态公平感知推荐通过多智能体社会选择

    Dynamic fairness-aware recommendation through multi-agent social choice

    [https://arxiv.org/abs/2303.00968](https://arxiv.org/abs/2303.00968)

    在个性化推荐领域，提出了一个将推荐公平性表达为分配和聚合问题的新模型，集成了公平关注点和个性化推荐规定，并推导出了新的推荐技术。

    

    在个性化推荐的算法公平性中，算法公平性面临与分类任务中常见挑战显著不同的问题。研究分类的研究人员通常认为公平性在于实现受保护组和未受保护组之间结果的平等，并基于此构建算法干预。我们认为，在现实世界的应用环境中通常更为复杂且多方面，在个性化推荐的背景下尤其如此，需要更一般化的方法。我们提出了一个模型，将推荐系统中的多利益相关者公平性形式化为两阶段社会选择问题。特别地，我们将推荐公平性表达为一个分配和聚合问题的新颖组合，将公平关注点和个性化推荐规定融合在一起，并推导出新的推荐技术。

    arXiv:2303.00968v3 Announce Type: replace  Abstract: Algorithmic fairness in the context of personalized recommendation presents significantly different challenges to those commonly encountered in classification tasks. Researchers studying classification have generally considered fairness to be a matter of achieving equality of outcomes between a protected and unprotected group, and built algorithmic interventions on this basis. We argue that fairness in real-world application settings in general, and especially in the context of personalized recommendation, is much more complex and multi-faceted, requiring a more general approach. We propose a model to formalize multistakeholder fairness in recommender systems as a two stage social choice problem. In particular, we express recommendation fairness as a novel combination of an allocation and an aggregation problem, which integrate both fairness concerns and personalized recommendation provisions, and derive new recommendation techniques
    
[^170]: PEM: 用于自动驾驶无人车虚拟测试的感知误差模型

    PEM: Perception Error Model for Virtual Testing of Autonomous Vehicles

    [https://arxiv.org/abs/2302.11919](https://arxiv.org/abs/2302.11919)

    提出了感知误差模型（PEM），用于帮助分析感知误差对自动驾驶无人车安全性的影响，无需对传感器本身进行建模，通过数据驱动的过程实现参数化建模，并在开源软件Apollo和公共数据集nuScenes中进行评估，展示了基于PEM的虚拟测试的有效性。

    

    虽然虚拟测试自动驾驶无人车（AVs）已被公认为安全评估中至关重要，AV模拟器仍在积极开发中。其中一个特别具有挑战性的问题是如何有效地将感知与知觉（S&P）子系统纳入模拟循环中。在本文中，我们定义了感知误差模型（PEM），这是一种虚拟模拟组件，可以分析感知误差对AV安全性的影响，而无需对传感器本身进行建模。我们提出了一种通用的数据驱动过程用于参数建模，并使用Apollo（一种开源驾驶软件）和nuScenes（一个公共AV数据集）进行评估。此外，我们在SVL（一种开源车辆模拟器）中实现了PEMs。此外，我们通过评估摄像头、LiDAR和摄像头-LiDAR设置，展示了基于PEM的虚拟测试的有效性。我们的虚拟测试凸显了在

    arXiv:2302.11919v2 Announce Type: replace-cross  Abstract: Even though virtual testing of Autonomous Vehicles (AVs) has been well recognized as essential for safety assessment, AV simulators are still undergoing active development. One particularly challenging question is to effectively include the Sensing and Perception (S&P) subsystem into the simulation loop. In this article, we define Perception Error Models (PEM), a virtual simulation component that can enable the analysis of the impact of perception errors on AV safety, without the need to model the sensors themselves. We propose a generalized data-driven procedure towards parametric modeling and evaluate it using Apollo, an open-source driving software, and nuScenes, a public AV dataset. Additionally, we implement PEMs in SVL, an open-source vehicle simulator. Furthermore, we demonstrate the usefulness of PEM-based virtual tests, by evaluating camera, LiDAR, and camera-LiDAR setups. Our virtual tests highlight limitations in the
    
[^171]: 使用控制器引导的部分标签一致性规范与未标记数据

    Controller-Guided Partial Label Consistency Regularization with Unlabeled Data

    [https://arxiv.org/abs/2210.11194](https://arxiv.org/abs/2210.11194)

    本文提出了一种使用控制器引导的部分标签一致性规范方法，通过利用未标记数据来改善部分注释不足的情况。

    

    部分标签学习（PLL）从训练示例中学习，每个示例都与多个候选标签相关联，其中只有一个是有效的。近年来，受益于处理模糊监督的强大能力和现代数据增强方法的推动，基于一致性规范的PLL方法取得了一系列成功并成为主流。然而，随着部分注释不足，它们的性能显著下降。在本文中，我们利用易于访问的未标记示例促进部分标签一致性规范。除了部分监督损失外，我们的方法使用控制器在标签级别和表示级别对未标记数据进行一致性规范。为了最小化初始监督模型能力不足的缺点，我们使用控制器估计每个

    arXiv:2210.11194v4 Announce Type: replace  Abstract: Partial label learning (PLL) learns from training examples each associated with multiple candidate labels, among which only one is valid. In recent years, benefiting from the strong capability of dealing with ambiguous supervision and the impetus of modern data augmentation methods, consistency regularization-based PLL methods have achieved a series of successes and become mainstream. However, as the partial annotation becomes insufficient, their performances drop significantly. In this paper, we leverage easily accessible unlabeled examples to facilitate the partial label consistency regularization. In addition to a partial supervised loss, our method performs a controller-guided consistency regularization at both the label-level and representation-level with the help of unlabeled data. To minimize the disadvantages of insufficient capabilities of the initial supervised model, we use the controller to estimate the confidence of each
    
[^172]: 具有子目标模型的目标空间规划

    Goal-Space Planning with Subgoal Models

    [https://arxiv.org/abs/2206.02902](https://arxiv.org/abs/2206.02902)

    通过在一组（抽象的）子目标上进行约束和学习本地、子目标条件的模型，本文提出的目标空间规划（GSP）方法更具计算效率，自然地结合了时间抽象，避免了学习转换动力学。

    

    本文研究了一种新的基于模型的强化学习方法，使用背景规划：混合（近似的）动态规划更新和模型无关的更新，类似于Dyna架构。利用学习的模型进行背景规划通常比模型无关的替代方法（如Double DQN）更差，尽管前者使用了显著更多的内存和计算资源。根本问题在于，学习的模型可能不准确，并且在迭代多个步骤时通常会产生无效状态。在本文中，我们通过将背景规划限制在一组（抽象的）子目标，并仅学习本地、子目标条件的模型来避免这种限制。这种目标空间规划（GSP）方法更具计算效率，自然地结合了用于更快长时程规划的时间抽象，并完全避免了学习转换动力学。我们展示了我们的GSP算法可以传播价值

    arXiv:2206.02902v5 Announce Type: replace-cross  Abstract: This paper investigates a new approach to model-based reinforcement learning using background planning: mixing (approximate) dynamic programming updates and model-free updates, similar to the Dyna architecture. Background planning with learned models is often worse than model-free alternatives, such as Double DQN, even though the former uses significantly more memory and computation. The fundamental problem is that learned models can be inaccurate and often generate invalid states, especially when iterated many steps. In this paper, we avoid this limitation by constraining background planning to a set of (abstract) subgoals and learning only local, subgoal-conditioned models. This goal-space planning (GSP) approach is more computationally efficient, naturally incorporates temporal abstraction for faster long-horizon planning and avoids learning the transition dynamics entirely. We show that our GSP algorithm can propagate value
    
[^173]: Snapture -- 一种用于静态和动态手势识别的新型神经结构

    Snapture -- A Novel Neural Architecture for Combined Static and Dynamic Hand Gesture Recognition

    [https://arxiv.org/abs/2205.15862](https://arxiv.org/abs/2205.15862)

    提出了一种新型混合手势识别系统，能够学习静态和动态手势，并通过捕捉手势表现高峰的“快照”来融合静态姿势和动态运动。

    

    随着机器人预期更多地参与人们的日常生活，需要能够提供直观用户界面的框架。手势识别系统提供了一种自然的交流方式，因此是无缝人机交互的重要组成部分。近年来，由深度学习驱动的计算模型发生了巨大的发展。然而，最先进的模型在跨不同手势领域（如象征手势和共语手势）方面仍存在不足。在本文中，我们提出了一种新颖的混合手势识别系统。我们的架构实现了对静态和动态手势的学习：通过捕捉手势在其高峰表现时的所谓“快照”，我们将手势姿势与动态运动融合在一起。此外，我们提出了一种分析手势运动轨迹的方法，以揭示其动态特征，并允许调节一个静态通道。

    arXiv:2205.15862v2 Announce Type: replace-cross  Abstract: As robots are expected to get more involved in people's everyday lives, frameworks that enable intuitive user interfaces are in demand. Hand gesture recognition systems provide a natural way of communication and, thus, are an integral part of seamless Human-Robot Interaction (HRI). Recent years have witnessed an immense evolution of computational models powered by deep learning. However, state-of-the-art models fall short in expanding across different gesture domains, such as emblems and co-speech. In this paper, we propose a novel hybrid hand gesture recognition system. Our architecture enables learning both static and dynamic gestures: by capturing a so-called "snapshot" of the gesture performance at its peak, we integrate the hand pose along with the dynamic movement. Moreover, we present a method for analyzing the motion profile of a gesture to uncover its dynamic characteristics and which allows regulating a static channel
    
[^174]: 自动化机器学习：从原理到实践

    Automated Machine Learning: From Principles to Practices

    [https://arxiv.org/abs/1810.13306](https://arxiv.org/abs/1810.13306)

    自动化机器学习（AutoML）旨在以数据驱动的方式生成令人满意的ML配置，本文提供了对AutoML原理和实践的全面调研。

    

    机器学习（ML）方法发展迅速，但配置和选择合适的方法以达到所需性能正变得越来越困难和乏味。为了解决这一挑战，自动化机器学习（AutoML）应运而生，旨在以数据驱动的方式为给定任务生成令人满意的ML配置。本文就该主题进行了全面调研。我们从AutoML的正式定义开始，然后介绍其原理，包括双层学习目标、学习策略和理论解释。接着，我们通过基于三个主要因素——搜索空间、搜索算法和评估策略——设立现有工作的分类法来总结AutoML实践。每个类别还会通过代表性方法进行解释。然后，我们通过配置ML管线等示例应用说明了AutoML的原理和实践。

    arXiv:1810.13306v5 Announce Type: replace  Abstract: Machine learning (ML) methods have been developing rapidly, but configuring and selecting proper methods to achieve a desired performance is increasingly difficult and tedious. To address this challenge, automated machine learning (AutoML) has emerged, which aims to generate satisfactory ML configurations for given tasks in a data-driven way. In this paper, we provide a comprehensive survey on this topic. We begin with the formal definition of AutoML and then introduce its principles, including the bi-level learning objective, the learning strategy, and the theoretical interpretation. Then, we summarize the AutoML practices by setting up the taxonomy of existing works based on three main factors: the search space, the search algorithm, and the evaluation strategy. Each category is also explained with the representative methods. Then, we illustrate the principles and practices with exemplary applications from configuring ML pipeline, 
    
[^175]: ChatGPT在面部生物识别中的表现有多好？对识别、软生物特征和可解释性的初步探索。

    How Good is ChatGPT at Face Biometrics? A First Look into Recognition, Soft Biometrics, and Explainability. (arXiv:2401.13641v1 [cs.CV])

    [http://arxiv.org/abs/2401.13641](http://arxiv.org/abs/2401.13641)

    本研究初步探索了基于GPT-4的ChatGPT在面部生物识别中的表现。研究分析了ChatGPT在面部验证、软生物特征估计和结果可解释性方面的能力。ChatGPT的应用有望提高自动决策在人类场景中的解释性和透明度。

    

    诸如OpenAI开发的GPT这样的大型语言模型已经展现出令人惊讶的结果，为我们的社会引入了快速变革。ChatGPT的发布进一步加强了这一影响，它使任何人都能以简单的对话方式与语言模型进行交互，不需要任何领域经验。因此，ChatGPT已被迅速应用于许多不同的任务，如代码和歌曲创作、教育、虚拟助手等，展示了对于未经过训练的任务而言令人印象深刻的结果（零样本学习）。本研究旨在探讨基于最新的GPT-4多模态语言模型的ChatGPT在面部生物识别任务中的能力。具体而言，我们分析了ChatGPT在面部验证、软生物特征估计和结果可解释性方面的能力。ChatGPT对于进一步增加人类场景中自动决策的解释性和透明度非常有价值。实验被进行以评估ChatGPT的表现。

    Large Language Models (LLMs) such as GPT developed by OpenAI, have already shown astonishing results, introducing quick changes in our society. This has been intensified by the release of ChatGPT which allows anyone to interact in a simple conversational way with LLMs, without any experience in the field needed. As a result, ChatGPT has been rapidly applied to many different tasks such as code- and song-writer, education, virtual assistants, etc., showing impressive results for tasks for which it was not trained (zero-shot learning).  The present study aims to explore the ability of ChatGPT, based on the recent GPT-4 multimodal LLM, for the task of face biometrics. In particular, we analyze the ability of ChatGPT to perform tasks such as face verification, soft-biometrics estimation, and explainability of the results. ChatGPT could be very valuable to further increase the explainability and transparency of the automatic decisions in human scenarios. Experiments are carried out in order
    
[^176]: 快速对抗训练与文本对抗攻击

    Fast Adversarial Training against Textual Adversarial Attacks. (arXiv:2401.12461v1 [cs.CL])

    [http://arxiv.org/abs/2401.12461](http://arxiv.org/abs/2401.12461)

    本研究提出了一种快速对抗训练（FAT）方法，用于提高自然语言处理模型在无同义词知识的情况下的对抗鲁棒性。该方法通过单步梯度上升在嵌入空间中生成对抗性示例，以加速训练过程。

    

    许多对抗性防御方法已被提出，以增强自然语言处理模型的对抗鲁棒性。然而，大多数方法引入了额外的预设语言知识，并假设攻击者使用的同义词候选词是可访问的，这是一个理想的假设。我们深入研究了嵌入空间中的对抗性训练，并从单步扰动生成和扰动初始化角度提出了一种快速对抗训练（FAT）方法，以改善在无同义词知识的情况下模型的鲁棒性。基于单步和多步梯度上升生成的对抗扰动相似的观察，FAT使用单步梯度上升在嵌入空间中生成对抗性示例，以加速训练过程。基于连续纪元中同一训练样本上生成的扰动相似的观察，FAT充分利用历史信息来初始化扰动。

    Many adversarial defense methods have been proposed to enhance the adversarial robustness of natural language processing models. However, most of them introduce additional pre-set linguistic knowledge and assume that the synonym candidates used by attackers are accessible, which is an ideal assumption. We delve into adversarial training in the embedding space and propose a Fast Adversarial Training (FAT) method to improve the model robustness in the synonym-unaware scenario from the perspective of single-step perturbation generation and perturbation initialization. Based on the observation that the adversarial perturbations crafted by single-step and multi-step gradient ascent are similar, FAT uses single-step gradient ascent to craft adversarial examples in the embedding space to expedite the training process. Based on the observation that the perturbations generated on the identical training sample in successive epochs are similar, FAT fully utilizes historical information when initi
    
[^177]: 图上的通用神经扩散框架

    A Generalized Neural Diffusion Framework on Graphs. (arXiv:2312.08616v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2312.08616](http://arxiv.org/abs/2312.08616)

    本文提出了一个通用的扩散方程框架，通过带有保真度项的方程，正式建立了GNN与扩散过程之间的关系。通过实验证明，该框架能够描述高阶邻居的标签相似性。

    

    最近的研究揭示了GNN和扩散过程之间的联系，这激发了许多基于扩散的GNN的提出。然而，由于这两种机制密切相关，一个基本的问题自然地产生：是否存在一个可以正式统一这些GNN的通用扩散框架？这个问题的答案不仅可以加深我们对GNN学习过程的理解，而且还可能打开一个设计广泛新的GNN类别的新大门。在本文中，我们提出了一个带有保真度项的通用扩散方程框架，它正式建立了扩散过程与更多GNN之间的关系。同时，通过这个框架，我们确定了图扩散网络的一个特征，即当前神经扩散过程只对应于一阶扩散方程。然而，通过实验证明，高阶邻居的标签实际上表现出单一性特征，这引发了相似性。

    Recent studies reveal the connection between GNNs and the diffusion process, which motivates many diffusion-based GNNs to be proposed. However, since these two mechanisms are closely related, one fundamental question naturally arises: Is there a general diffusion framework that can formally unify these GNNs? The answer to this question can not only deepen our understanding of the learning process of GNNs, but also may open a new door to design a broad new class of GNNs. In this paper, we propose a general diffusion equation framework with the fidelity term, which formally establishes the relationship between the diffusion process with more GNNs. Meanwhile, with this framework, we identify one characteristic of graph diffusion networks, i.e., the current neural diffusion process only corresponds to the first-order diffusion equation. However, by an experimental investigation, we show that the labels of high-order neighbors actually exhibit monophily property, which induces the similarit
    
[^178]: 量子极坐标度量学习: 高效经典学习的量子嵌入

    Quantum Polar Metric Learning: Efficient Classically Learned Quantum Embeddings. (arXiv:2312.01655v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2312.01655](http://arxiv.org/abs/2312.01655)

    本论文提出了一种称为量子极坐标度量学习(QPMeL)的方法，通过经典模型学习量子比特的极坐标形式的参数，然后使用浅层PQC和可训练的门层来创建量子态和学习纠缠。与QMeL相比，QPMeL具有更高效的计算性能和可扩展性。

    

    深度度量学习在经典数据范畴中表现出极有潜力的结果，创建了分离明显的特征空间。这个想法也被应用到量子计算机中，通过量子度量学习(QMeL)。QMeL包括两个步骤，首先使用经典模型将数据压缩以适应有限数量的量子比特，然后使用参数化量子电路(PQC)在希尔伯特空间中创建更好的分离效果。然而，在嘈杂中间规模量子(NISQ)设备上，QMeL解决方案导致电路宽度和深度较大，从而限制了可扩展性。我们提出了一种称为量子极坐标度量学习(QPMeL)的方法，它使用经典模型学习一个量子比特的极坐标形式的参数。然后，我们利用仅包含$R_y$和$R_z$门的浅层PQC创建量子态，并利用可训练的$ZZ(\theta)$门层学习纠缠。电路还通过SWAP测试计算保真度，用于我们提出的保真度三元损失函数的训练，用于同时训练经典和量子模型。

    Deep metric learning has recently shown extremely promising results in the classical data domain, creating well-separated feature spaces. This idea was also adapted to quantum computers via Quantum Metric Learning(QMeL). QMeL consists of a 2 step process with a classical model to compress the data to fit into the limited number of qubits, then train a Parameterized Quantum Circuit(PQC) to create better separation in Hilbert Space. However, on Noisy Intermediate Scale Quantum (NISQ) devices. QMeL solutions result in high circuit width and depth, both of which limit scalability. We propose Quantum Polar Metric Learning (QPMeL) that uses a classical model to learn the parameters of the polar form of a qubit. We then utilize a shallow PQC with $R_y$ and $R_z$ gates to create the state and a trainable layer of $ZZ(\theta)$-gates to learn entanglement. The circuit also computes fidelity via a SWAP Test for our proposed Fidelity Triplet Loss function, used to train both classical and quantum 
    
[^179]: 条件非线性自动编码器用于轨迹预测

    Conditional Unscented Autoencoders for Trajectory Prediction. (arXiv:2310.19944v1 [cs.RO])

    [http://arxiv.org/abs/2310.19944](http://arxiv.org/abs/2310.19944)

    本文提出了使用条件非线性自动编码器(CVAE)进行轨迹预测的方法，通过利用变分自动编码器(VAE)中的非线性采样过程和其他改进，超越了现有技术，为自动驾驶领域的轨迹预测提供了更好的性能。

    

    条件变分自动编码器(CVAE)是自动驾驶轨迹预测中最常用的模型之一。它将驾驶环境和真实未来关系建立在概率隐空间中，并利用此空间生成预测。本文对CVAE的关键组件提出了挑战。我们利用变分自动编码器(VAE)领域的最新进展，发现变化采样过程可以极大地提高性能。我们发现非线性采样能够更适合于轨迹预测，而随机采样可能带来潜在的问题。我们进一步提出了其他改进，包括更结构化的混合隐空间，以及一种新颖、可能更具表达力的CVAE推理方法。我们通过在INTERACTION预测数据集上进行评估，展示了我们模型的广泛适用性，超过了现有技术的表现。

    The \ac{CVAE} is one of the most widely-used models in trajectory prediction for \ac{AD}. It captures the interplay between a driving context and its ground-truth future into a probabilistic latent space and uses it to produce predictions. In this paper, we challenge key components of the CVAE. We leverage recent advances in the space of the VAE, the foundation of the CVAE, which show that a simple change in the sampling procedure can greatly benefit performance. We find that unscented sampling, which draws samples from any learned distribution in a deterministic manner, can naturally be better suited to trajectory prediction than potentially dangerous random sampling. We go further and offer additional improvements, including a more structured mixture latent space, as well as a novel, potentially more expressive way to do inference with CVAEs. We show wide applicability of our models by evaluating them on the INTERACTION prediction dataset, outperforming the state of the art, as well 
    
[^180]: NECO: 基于神经坍塌的超出分布检测

    NECO: NEural Collapse Based Out-of-distribution detection. (arXiv:2310.06823v1 [stat.ML])

    [http://arxiv.org/abs/2310.06823](http://arxiv.org/abs/2310.06823)

    NECO是一种基于神经坍塌的新颖的超出分布检测方法，利用几何属性和主成分空间识别OOD数据，在小规模和大规模任务上取得了最先进的结果，并展示了强大的泛化能力。

    

    由于模型过于自信并且没有意识到其认识论限制，检测超出分布（OOD）数据是机器学习中的一个重要挑战。我们假设“神经坍塌”，一种影响超出分布数据的现象，也会影响超出分布数据。为了从这种相互作用中受益，我们引入了NECO，一种用于OOD检测的新颖的事后方法，它利用“神经坍塌”和主成分空间的几何属性来识别OOD数据。我们的大量实验表明，NECO在小规模和大规模OOD检测任务上取得了最先进的结果，同时在不同的网络架构上展示了强大的泛化能力。此外，我们还对我们的方法在OOD检测中的有效性提供了理论解释。我们计划在匿名期结束后发布代码。

    Detecting out-of-distribution (OOD) data is a critical challenge in machine learning due to model overconfidence, often without awareness of their epistemological limits. We hypothesize that ``neural collapse'', a phenomenon affecting in-distribution data for models trained beyond loss convergence, also influences OOD data. To benefit from this interplay, we introduce NECO, a novel post-hoc method for OOD detection, which leverages the geometric properties of ``neural collapse'' and of principal component spaces to identify OOD data. Our extensive experiments demonstrate that NECO achieves state-of-the-art results on both small and large-scale OOD detection tasks while exhibiting strong generalization capabilities across different network architectures. Furthermore, we provide a theoretical explanation for the effectiveness of our method in OOD detection. We plan to release the code after the anonymity period.
    
[^181]: 大型语言模型是事后解释器吗？

    Are Large Language Models Post Hoc Explainers?. (arXiv:2310.05797v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05797](http://arxiv.org/abs/2310.05797)

    这项工作提出了第一个研究大型语言模型（LLMs）解释其他预测模型有效性的框架，并且提出了多个提示策略，填补了当前对于LLMs在解释其他模型行为方面的缺失。

    

    大型语言模型（LLM）越来越被广泛应用于各种自然语言处理（NLP）应用中。最近的一项创新，即上下文学习（ICL），使得LLM能够在推理阶段通过在提示中提供少量示例来学习新任务，从而消除了模型微调的需要。虽然LLM已经被应用于多个领域，但其在解释其他模型行为方面的适用性仍相对未被探索。尽管存在越来越多的新解释技术，但很多技术要求对模型具有白盒访问权限和/或计算成本较高，凸显了下一代事后解释器的需求。在这项工作中，我们提出了第一个研究LLM解释其他预测模型有效性的框架。具体而言，我们提出了一个包含多种提示策略的新颖框架：i）基于扰动的ICL，ii）基于预测的ICL，iii）基于指令的ICL，和iv）基于解释的ICL。

    Large Language Models (LLMs) are increasingly used as powerful tools for a plethora of natural language processing (NLP) applications. A recent innovation, in-context learning (ICL), enables LLMs to learn new tasks by supplying a few examples in the prompt during inference time, thereby eliminating the need for model fine-tuning. While LLMs have been utilized in several applications, their applicability in explaining the behavior of other models remains relatively unexplored. Despite the growing number of new explanation techniques, many require white-box access to the model and/or are computationally expensive, highlighting a need for next-generation post hoc explainers. In this work, we present the first framework to study the effectiveness of LLMs in explaining other predictive models. More specifically, we propose a novel framework encompassing multiple prompting strategies: i) Perturbation-based ICL, ii) Prediction-based ICL, iii) Instruction-based ICL, and iv) Explanation-based I
    
[^182]: 一种用于医学图像中一般移动目标分割的基础模型

    A Foundation Model for General Moving Object Segmentation in Medical Images. (arXiv:2309.17264v1 [cs.CV])

    [http://arxiv.org/abs/2309.17264](http://arxiv.org/abs/2309.17264)

    本文提出了一种用于医学图像中移动目标分割的基础模型iMOS，通过对序列中只有少量图像进行注释，即可实现高精度的分割效果

    

    医学图像分割旨在描绘感兴趣的解剖或病理结构，在临床诊断中起着关键作用。构建高精度的深度分割模型需要大量高质量的注释数据。然而，医学注释非常繁琐耗时，特别是对于医学视频或3D体积，由于巨大的标签空间和差的帧间一致性。最近，在自然图像中，一个名为Moving Object Segmentation (MOS)的基本任务在技术上取得了重大进展。它的目标是在图像序列中从背景中描绘移动物体，只需要最小的注释。在本文中，我们提出了第一个用于医学图像中MOS的基础模型，名为iMOS。对一个大规模多模态医学数据集进行的大量实验验证了所提出的iMOS的有效性。具体而言，只需对序列中少量的图像进行注释，iMOS就可以实现了

    Medical image segmentation aims to delineate the anatomical or pathological structures of interest, playing a crucial role in clinical diagnosis. A substantial amount of high-quality annotated data is crucial for constructing high-precision deep segmentation models. However, medical annotation is highly cumbersome and time-consuming, especially for medical videos or 3D volumes, due to the huge labeling space and poor inter-frame consistency. Recently, a fundamental task named Moving Object Segmentation (MOS) has made significant advancements in natural images. Its objective is to delineate moving objects from the background within image sequences, requiring only minimal annotations. In this paper, we propose the first foundation model, named iMOS, for MOS in medical images. Extensive experiments on a large multi-modal medical dataset validate the effectiveness of the proposed iMOS. Specifically, with the annotation of only a small number of images in the sequence, iMOS can achieve sati
    
[^183]: LLM能否有效利用结构信息进行图学习：何时何地。

    Can LLMs Effectively Leverage Structural Information for Graph Learning: When and Why. (arXiv:2309.16595v1 [cs.LG])

    [http://arxiv.org/abs/2309.16595](http://arxiv.org/abs/2309.16595)

    本文研究了大型语言模型（LLM）在图数据中的应用，发现LLM可以从结构信息中受益，尤其是在文本节点特征缺乏的情况下，而LLM的性能与数据泄露没有显著相关。

    

    本文研究了大型语言模型（LLM）在结构化数据（特别是图数据）上的应用，这是LLM文献中尚未充分探索的重要数据形态。我们旨在了解在节点分类任务中，何时何地引入图数据中的结构信息可以提高LLM的预测性能。为了解决“何时”问题，我们研究了多种编码结构信息的提示方法，设置中文本节点特征丰富或稀缺。对于“为什么”问题，我们探讨了LLM性能的两个潜在因素：数据泄露和同质性。我们的研究结果表明：（i）LLM可以从结构信息中受益，尤其是在文本节点特征缺乏的情况下；（ii）没有实质性的证据表明LLM性能与数据泄露有显著相关；（iii）LLM在目标节点上的性能与正向相关。

    This paper studies Large Language Models (LLMs) for structured data--particularly graphs--a crucial data modality that remains underexplored in the LLM literature. We aim to understand when and why the incorporation of structural information inherent in graph data can improve the prediction performance of LLMs on node classification tasks. To address the ``when'' question, we examine a variety of prompting methods for encoding structural information, in settings where textual node features are either rich or scarce. For the ``why'' questions, we probe into two potential contributing factors to the LLM performance: data leakage and homophily. Our exploration of these questions reveals that (i) LLMs can benefit from structural information, especially when textual node features are scarce; (ii) there is no substantial evidence indicating that the performance of LLMs is significantly attributed to data leakage; and (iii) the performance of LLMs on a target node is strongly positively relat
    
[^184]: 生成式查询和文档扩展何时失败？方法、检索器和数据集的全面研究

    When do Generative Query and Document Expansions Fail? A Comprehensive Study Across Methods, Retrievers, and Datasets. (arXiv:2309.08541v1 [cs.IR])

    [http://arxiv.org/abs/2309.08541](http://arxiv.org/abs/2309.08541)

    通过对11种扩展技术、12个不同分布变化的数据集和24个检索模型的全面分析，我们发现使用大型语言模型进行查询或文档扩展的效果与检索器性能相关，对于弱模型来说扩展提高了分数，但对于强模型来说扩展通常会损害分数。

    

    使用大型语言模型（LM）进行查询或文档扩展可以改善信息检索中的泛化能力。然而，目前尚不清楚这些技术是否普遍有益，还是仅在特定设置下有效，例如对于特定的检索模型、数据集领域或查询类型。为了回答这个问题，我们进行了第一次对基于LM的扩展的全面分析。我们发现，检索器性能与扩展的增益之间存在强烈的负相关关系：扩展改善了较弱模型的分数，但通常会损害较强模型的分数。我们展示了这一趋势在11种扩展技术、12个具有不同分布变化的数据集和24个检索模型的一组实验中成立。通过定性错误分析，我们提出了一个假设，即尽管扩展提供了额外的信息（可能改善了召回率），但它们也增加了噪声，使得很难区分出顶级相关文档（从而引入了错误的正例）

    Using large language models (LMs) for query or document expansion can improve generalization in information retrieval. However, it is unknown whether these techniques are universally beneficial or only effective in specific settings, such as for particular retrieval models, dataset domains, or query types. To answer this, we conduct the first comprehensive analysis of LM-based expansion. We find that there exists a strong negative correlation between retriever performance and gains from expansion: expansion improves scores for weaker models, but generally harms stronger models. We show this trend holds across a set of eleven expansion techniques, twelve datasets with diverse distribution shifts, and twenty-four retrieval models. Through qualitative error analysis, we hypothesize that although expansions provide extra information (potentially improving recall), they add additional noise that makes it difficult to discern between the top relevant documents (thus introducing false positiv
    
[^185]: 通过进化算法连接大型语言模型与强大的提示优化器

    Connecting Large Language Models with Evolutionary Algorithms Yields Powerful Prompt Optimizers. (arXiv:2309.08532v1 [cs.CL])

    [http://arxiv.org/abs/2309.08532](http://arxiv.org/abs/2309.08532)

    本文提出了一种通过连接大型语言模型和进化算法进行提示优化的框架，名为EvoPrompt。通过利用大型语言模型的语言处理能力和进化算法的优化性能，EvoPrompt可以自动化处理需要连贯和可读性良好的提示，提高大型语言模型的性能。

    

    大型语言模型在各种任务中表现出色，但它们依赖于精心设计的提示，这通常需要大量的人力努力。为了自动化这个过程，本文提出了一种新颖的离散提示优化框架，称为EvoPrompt，它借鉴了进化算法的思想，因为它们表现出良好的性能和快速的收敛性。为了使进化算法能够处理需要连贯并且可读性良好的自然语言表达的离散提示，我们将大型语言模型与进化算法进行了连接。这种方法使我们可以同时利用大型语言模型的强大语言处理能力和进化算法的高效优化性能。具体而言，EvoPrompt在不使用任何梯度或参数的情况下，从一组提示中开始，并基于进化算子通过大型语言模型生成新的提示，根据开发集改进提示的种群。我们对闭源和开源的大型语言模型，包括GPT-3进行提示优化。

    Large Language Models (LLMs) excel in various tasks, but they rely on carefully crafted prompts that often demand substantial human effort. To automate this process, in this paper, we propose a novel framework for discrete prompt optimization, called EvoPrompt, which borrows the idea of evolutionary algorithms (EAs) as they exhibit good performance and fast convergence. To enable EAs to work on discrete prompts, which are natural language expressions that need to be coherent and human-readable, we connect LLMs with EAs. This approach allows us to simultaneously leverage the powerful language processing capabilities of LLMs and the efficient optimization performance of EAs. Specifically, abstaining from any gradients or parameters, EvoPrompt starts from a population of prompts and iteratively generates new prompts with LLMs based on the evolutionary operators, improving the population based on the development set. We optimize prompts for both closed- and open-source LLMs including GPT-3
    
[^186]: FedSoL: 在联邦学习中解决全局对齐和本地一般性的问题

    FedSoL: Bridging Global Alignment and Local Generality in Federated Learning. (arXiv:2308.12532v1 [cs.LG])

    [http://arxiv.org/abs/2308.12532](http://arxiv.org/abs/2308.12532)

    FedSoL提出了一种联邦学习的方法，该方法旨在解决数据分布不均匀导致性能下降的问题。它通过平衡全局对齐和本地一般性来改善FL的学习效果。

    

    联邦学习(Federated Learning, FL)通过聚合来自个体客户端的本地训练模型来构建全局模型。虽然FL可以在保护数据隐私的情况下学习模型，但当客户端数据分布不均匀时，常常导致性能下降。许多先前的FL算法通过引入各种近似约束来解决这个问题。这些约束旨在通过限制局部学习与全局目标的偏离来促进全局对齐。然而，它们本质上通过干扰原始的局部目标而限制了局部学习。最近，出现了一种替代方法来改善本地学习的一般性。通过在平滑的损失空间中获得本地模型，这种方法减轻了客户端不同本地目标之间的冲突。然而，它不能确保稳定的全局对齐，因为本地学习不考虑全局目标。在本研究中，我们提出了联邦学习的稳定性(FedSoL)方法来在FL中解决全局对齐和本地一般性的问题。

    Federated Learning (FL) aggregates locally trained models from individual clients to construct a global model. While FL enables learning a model with data privacy, it often suffers from significant performance degradation when client data distributions are heterogeneous. Many previous FL algorithms have addressed this issue by introducing various proximal restrictions. These restrictions aim to encourage global alignment by constraining the deviation of local learning from the global objective. However, they inherently limit local learning by interfering with the original local objectives. Recently, an alternative approach has emerged to improve local learning generality. By obtaining local models within a smooth loss landscape, this approach mitigates conflicts among different local objectives of the clients. Yet, it does not ensure stable global alignment, as local learning does not take the global objective into account. In this study, we propose Federated Stability on Learning (Fed
    
[^187]: 在随机位置预测掩盖的标记改善了掩盖图像建模

    Predicting masked tokens in stochastic locations improves masked image modeling. (arXiv:2308.00566v1 [cs.CV])

    [http://arxiv.org/abs/2308.00566](http://arxiv.org/abs/2308.00566)

    本论文提出了一种名为FlexPredict的随机模型，通过在模型中加入位置不确定性，以预测掩盖的标记位置，从而改善了掩盖图像建模的性能。

    

    自监督学习是深度学习中一种有前景的范式，通过构建需要学习有用表示的预训练任务，可以从无标签数据中进行学习。在自然语言处理中，主要的预训练任务是掩盖语言建模（MLM），而在计算机视觉中存在相应的掩盖图像建模（MIM）。然而，MIM具有挑战性，因为它需要在准确位置上预测语义内容。例如，给定一张不完整的狗的图片，我们可以猜测有一个尾巴，但我们无法确定它的确切位置。在这项工作中，我们提出了FlexPredict，这是一个考虑位置不确定性的随机模型，通过将模型条件化到随机掩盖的标记位置上，引导模型学习更加鲁棒对位置不确定性的特征。我们的方法改进了多个任务的下游性能，例如与MIM基准相比，FlexPredict在一系列任务上表现更好。

    Self-supervised learning is a promising paradigm in deep learning that enables learning from unlabeled data by constructing pretext tasks that require learning useful representations. In natural language processing, the dominant pretext task has been masked language modeling (MLM), while in computer vision there exists an equivalent called Masked Image Modeling (MIM). However, MIM is challenging because it requires predicting semantic content in accurate locations. E.g, given an incomplete picture of a dog, we can guess that there is a tail, but we cannot determine its exact location. In this work, we propose FlexPredict, a stochastic model that addresses this challenge by incorporating location uncertainty into the model. Specifically, we condition the model on stochastic masked token positions to guide the model toward learning features that are more robust to location uncertainties. Our approach improves downstream performance on a range of tasks, e.g, compared to MIM baselines, Fle
    
[^188]: 预训练的深度模型在标签稀缺的Learning-To-Rank中胜过GBDTs

    Pretrained deep models outperform GBDTs in Learning-To-Rank under label scarcity. (arXiv:2308.00177v1 [cs.LG])

    [http://arxiv.org/abs/2308.00177](http://arxiv.org/abs/2308.00177)

    本研究研究了在标签稀缺的Learning-To-Rank问题中，无监督预训练的深度模型是否能胜过GBDTs和其他非预训练模型。实验结果表明，通过使用SimCLR-Rank方法进行无监督预训练，我们的深度学习模型在大量无标签数据和有限标签数据的情况下取得了显著优势。

    

    尽管深度学习模型在文本和图像领域是最先进的，但它们在表格形式的Learning-To-Rank问题上尚未一致地胜过梯度提升决策树(GBDTs)。近期在文本和图像任务上深度学习模型取得的性能提升主要依赖于无监督预训练，这种方法利用了比有标签数据多几个数量级的无标签数据。据我们所知，无监督预训练还未应用于Learning-To-Rank问题，而该问题通常产生大量无标签数据。本研究探究了无监督预训练是否能提高LTR性能，与GBDTs和其他非预训练模型相比。通过使用简单的设计选择(包括SimCLR-Rank，这是我们针对排名问题修改的SimCLR方法)，我们产生了预训练的深度学习模型，在有大量无标签数据且有限标签数据的情况下，显著优于GBDTs(和其他非预训练模型)。

    While deep learning (DL) models are state-of-the-art in text and image domains, they have not yet consistently outperformed Gradient Boosted Decision Trees (GBDTs) on tabular Learning-To-Rank (LTR) problems. Most of the recent performance gains attained by DL models in text and image tasks have used unsupervised pretraining, which exploits orders of magnitude more unlabeled data than labeled data. To the best of our knowledge, unsupervised pretraining has not been applied to the LTR problem, which often produces vast amounts of unlabeled data. In this work, we study whether unsupervised pretraining can improve LTR performance over GBDTs and other non-pretrained models. Using simple design choices--including SimCLR-Rank, our ranking-specific modification of SimCLR (an unsupervised pretraining method for images)--we produce pretrained deep learning models that soundly outperform GBDTs (and other non-pretrained models) in the case where labeled data is vastly outnumbered by unlabeled data
    
[^189]: 加速Benders分解方法的强化学习代理模型研究

    Towards Accelerating Benders Decomposition via Reinforcement Learning Surrogate Models. (arXiv:2307.08816v1 [cs.LG])

    [http://arxiv.org/abs/2307.08816](http://arxiv.org/abs/2307.08816)

    本文介绍了一种利用强化学习代理模型加速Benders分解方法的方法，并通过实验证明了其相对于其他加速方案的30%更快的平均收敛速度。

    

    随机优化试图在存在不确定性的情况下提供最优决策。通常，由于需要捕捉不确定性的情景数量以及现实规划问题的离散性质，这些问题的经典形式变得难以处理。为了克服这些可行性问题，实践者们转向分解方法，将问题分解为更小、更易处理的子问题。本文的主要分解方法是Benders分解（BD），它根据情景独立性对随机优化问题进行分解。在本文中，我们提出了一种利用代理模型加速BD的方法，该代理模型取代了NP难的整数主问题。通过加速方法，与其他加速的BD实现相比，我们观察到平均收敛速度提高了30%。我们引入了一个强化学习代理作为替代，并展示了如何使用它来解决随机库存问题。

    Stochastic optimization (SO) attempts to offer optimal decisions in the presence of uncertainty. Often, the classical formulation of these problems becomes intractable due to (a) the number of scenarios required to capture the uncertainty and (b) the discrete nature of real-world planning problems. To overcome these tractability issues, practitioners turn to decomposition methods that divide the problem into smaller, more tractable sub-problems. The focal decomposition method of this paper is Benders decomposition (BD), which decomposes stochastic optimization problems on the basis of scenario independence. In this paper we propose a method of accelerating BD with the aid of a surrogate model in place of an NP-hard integer master problem. Through the acceleration method we observe 30% faster average convergence when compared to other accelerated BD implementations. We introduce a reinforcement learning agent as a surrogate and demonstrate how it can be used to solve a stochastic invent
    
[^190]: 人类对齐的偏好排序优化

    Preference Ranking Optimization for Human Alignment. (arXiv:2306.17492v1 [cs.CL])

    [http://arxiv.org/abs/2306.17492](http://arxiv.org/abs/2306.17492)

    本文提出了Preference Ranking Optimization (PRO)方法，通过扩展布拉德利-特里比较，采用偏好排序的方式来直接对齐大型语言模型（LLMs），解决了强化学习从人类反馈中学习的复杂性、不稳定性和对超参数的敏感性的问题。

    

    大型语言模型（LLMs）经常包含误导性内容，强调了将其与人类价值观对齐以确保安全的AI系统的必要性。采用从人类反馈中学习强化学习（RLHF）来实现这种对齐，通过将基于布拉德利-特里配对比较的奖励模型与Proximal Policy Optimization（PPO）等RL算法结合起来来优化LLM的响应。然而，RLHF表现出复杂性、不稳定性和对超参数的敏感性。在本文中，我们提出了Preference Ranking Optimization（PRO）作为PPO的另一种直接将LLM与布拉德利-特里比较对齐的方法。PRO将配对的布拉德利-特里比较扩展到适应任意长度的偏好排序。通过反复对比生成响应的可能性，PRO指导LLM优先考虑最佳响应，并逐渐对剩余的响应进行排序。通过这种方式，PRO将人类对齐有效地转化为概率对齐。

    Large language models (LLMs) often contain misleading content, emphasizing the need to align them with human values to ensure secur AI systems. Reinforcement learning from human feedback (RLHF) has been employed to achieve this alignment by combining a reward model, typically based on Bradley-Terry paired comparison, with an RL algorithm such as Proximal Policy Optimization (PPO) to optimize LLM responses. However, RLHF exhibits complexity, instability, and sensitivity to hyperparameters. In this paper, we propose Preference Ranking Optimization (PRO) as an alternative to PPO for directly aligning LLMs with the Bradley-Terry comparison. PRO extends the pairwise Bradley-Terry comparison to accommodate preference rankings of any length. By iteratively contrasting the likelihood of generating responses, PRO instructs the LLM to prioritize the best response while progressively ranking the remaining responses. In this manner, PRO effectively transforms human alignment into aligning the prob
    
[^191]: DecodingTrust: GPT模型的全面可信度评估

    DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models. (arXiv:2306.11698v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.11698](http://arxiv.org/abs/2306.11698)

    这项工作提出了对GPT模型进行全面可信度评估，考虑了多个方面的风险，发现了以前未公开的威胁漏洞，例如对毒性输出和个人信息泄漏的易被误导性。

    

    生成预训练变压器（GPT）模型在其能力方面取得了令人兴奋的进展，引起了从从业者到公众的兴趣。然而，尽管关于GPT模型的可信度的文献仍然有限，从业者们提议将强大的GPT模型用于敏感应用，如医疗保健和金融领域，其中错误可能代价高昂。为此，本研究提出了对大型语言模型（重点放在GPT-4和GPT-3.5上）进行全面的可信度评估，考虑了多样的观点 - 包括有毒性、陈规偏见、对抗强度、超出分布的强度、对抗示范的强度、隐私、机器伦理和公平性。根据我们的评估，我们发现了以前未公开的可信度威胁漏洞。例如，我们发现GPT模型可以轻松被误导生成有毒和偏见的输出，并在训练数据和上下文中泄漏私人信息。

    Generative Pre-trained Transformer (GPT) models have exhibited exciting progress in their capabilities, capturing the interest of practitioners and the public alike. Yet, while the literature on the trustworthiness of GPT models remains limited, practitioners have proposed employing capable GPT models for sensitive applications such as healthcare and finance -- where mistakes can be costly. To this end, this work proposes a comprehensive trustworthiness evaluation for large language models with a focus on GPT-4 and GPT-3.5, considering diverse perspectives -- including toxicity, stereotype bias, adversarial robustness, out-of-distribution robustness, robustness on adversarial demonstrations, privacy, machine ethics, and fairness. Based on our evaluations, we discover previously unpublished vulnerabilities to trustworthiness threats. For instance, we find that GPT models can be easily misled to generate toxic and biased outputs and leak private information in both training data and conv
    
[^192]: 通过监督式注意力多实例学习从多视角超声图像检测心脏病

    Detecting Heart Disease from Multi-View Ultrasound Images via Supervised Attention Multiple Instance Learning. (arXiv:2306.00003v1 [eess.IV])

    [http://arxiv.org/abs/2306.00003](http://arxiv.org/abs/2306.00003)

    本研究提出了一种基于监督式注意力多实例学习的方法，可以自动分析超声图像，实现AS的精确筛查且精度优于传统机器学习和深度学习方法。

    

    主动脉瓣狭窄(AS)是一种导致严重发病率和死亡率的退行性瓣膜疾病。这种情况经常被低估和低治疗。在临床实践中，AS是通过超声心动图的专家审查来诊断的，这会产生数十个下肺采样的超声图像。只有一些视图显示主动脉瓣。为了自动化筛查AS，深度网络必须学习模仿人类专家识别主动脉瓣视图的能力，然后汇总这些相关图像以产生研究级诊断。我们发现先前的AS检测方法由于依赖于跨图像的不灵活平均值而导致精度不足。我们进一步发现，现成的基于注意力的多实例(MIL)学习表现不佳。我们提出了一种新的端到端MIL方法，包含两个关键方法创新。首先，通过监督式注意技术，引导学习的注意机制偏爱相关视图。其次，一种新颖的自我监督学习技术提高了每个单独图像的表现。我们的方法在一个真实的临床数据集（4569名患者）上实现了最先进的性能，在传统的机器学习和深度学习方法之上。

    Aortic stenosis (AS) is a degenerative valve condition that causes substantial morbidity and mortality. This condition is under-diagnosed and under-treated. In clinical practice, AS is diagnosed with expert review of transthoracic echocardiography, which produces dozens of ultrasound images of the heart. Only some of these views show the aortic valve. To automate screening for AS, deep networks must learn to mimic a human expert's ability to identify views of the aortic valve then aggregate across these relevant images to produce a study-level diagnosis. We find previous approaches to AS detection yield insufficient accuracy due to relying on inflexible averages across images. We further find that off-the-shelf attention-based multiple instance learning (MIL) performs poorly. We contribute a new end-to-end MIL approach with two key methodological innovations. First, a supervised attention technique guides the learned attention mechanism to favor relevant views. Second, a novel self-sup
    
[^193]: 结构化大离散动作空间的动态邻域构建

    Dynamic Neighborhood Construction for Structured Large Discrete Action Spaces. (arXiv:2305.19891v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.19891](http://arxiv.org/abs/2305.19891)

    本研究针对无法处理的结构化大离散动作空间（SLDAS）提出了一种名为动态邻域构建（DNC）的新型利用策略，通过可扩展的邻域探索启发式方法，高效地探索连续代理动作周围的离散邻域。

    

    大离散动作空间（LDAS）是强化学习中的一个核心挑战。现有的解决方案可以处理多达几百万个动作的非结构化LDAS。然而，在物流、生产和运输系统等许多现实应用中，动作空间具有组合结构，其规模甚至在小规模实例上也超过了数百万个动作。幸运的是，这样的动作空间呈现出一定的结构，例如等间距的离散资源单位。在这项工作中，我们专注于处理当前基准测试无法处理的结构化LDAS（SLDAS）。我们提出了一种名为动态邻域构建（DNC）的新型利用策略，用于SLDAS。我们提出了一种可扩展的邻域探索启发式方法，利用这种策略，在具有高达$10^{73}$个动作的结构化动作空间中高效地探索连续代理动作周围的离散邻域。我们通过与三个标杆算法进行基准测试来展示我们方法的性能。

    Large discrete action spaces (LDAS) remain a central challenge in reinforcement learning. Existing solution approaches can handle unstructured LDAS with up to a few million actions. However, many real-world applications in logistics, production, and transportation systems have combinatorial action spaces, whose size grows well beyond millions of actions, even on small instances. Fortunately, such action spaces exhibit structure, e.g., equally spaced discrete resource units. With this work, we focus on handling structured LDAS (SLDAS) with sizes that cannot be handled by current benchmarks: we propose Dynamic Neighborhood Construction (DNC), a novel exploitation paradigm for SLDAS. We present a scalable neighborhood exploration heuristic that utilizes this paradigm and efficiently explores the discrete neighborhood around the continuous proxy action in structured action spaces with up to $10^{73}$ actions. We demonstrate the performance of our method by benchmarking it against three sta
    
[^194]: 诊断变压器：揭示临床决策中的特征空间。 (arXiv:2305.17588v2 [cs.CL] UPDATED)

    Diagnosing Transformers: Illuminating Feature Spaces for Clinical Decision-Making. (arXiv:2305.17588v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17588](http://arxiv.org/abs/2305.17588)

    该论文介绍了一种名为SUFO的框架，用于增强微调的变压器模型的可解释性。该框架利用多种分析和可视化技术，解决了模型信任和可解释性的关键问题，并通过案例研究验证了其有效性。

    

    在医学等高风险领域，为了建立信任和确保安全，模型的可解释性至关重要，而使用有限的临床记录对预训练的变压器进行微调以辅助临床决策。我们引入了一种名为SUFO的系统框架，该框架增强了微调的变压器特征空间的可解释性。SUFO利用一系列分析和可视化技术，包括监督探索、无监督相似性分析、特征动态和异常值分析，来解决关于模型信任和可解释性的关键问题。我们进行了一个案例研究，研究了预训练数据对真实世界病理分类任务的影响，并在MedNLI上验证了我们的发现。我们评估了五个110M规模的预训练变压器模型，分为通用领域（BERT, TNLR）、混合领域（BioBERT, Clinical BioBERT）和领域特定（PubMedBERT）组。我们的SUFO分析揭示了：(1)

    Pre-trained transformers are often fine-tuned to aid clinical decision-making using limited clinical notes. Model interpretability is crucial, especially in high-stakes domains like medicine, to establish trust and ensure safety, which requires human engagement. We introduce SUFO, a systematic framework that enhances interpretability of fine-tuned transformer feature spaces. SUFO utilizes a range of analytic and visualization techniques, including Supervised probing, Unsupervised similarity analysis, Feature dynamics, and Outlier analysis to address key questions about model trust and interpretability. We conduct a case study investigating the impact of pre-training data where we focus on real-world pathology classification tasks, and validate our findings on MedNLI. We evaluate five 110M-sized pre-trained transformer models, categorized into general-domain (BERT, TNLR), mixed-domain (BioBERT, Clinical BioBERT), and domain-specific (PubMedBERT) groups. Our SUFO analyses reveal that: (1
    
[^195]: 重新思考深度学习测试中的多样性

    Rethink Diversity in Deep Learning Testing. (arXiv:2305.15698v1 [cs.SE])

    [http://arxiv.org/abs/2305.15698](http://arxiv.org/abs/2305.15698)

    本文提出针对深度学习测试的六个具体指标来检测和缓解其漏洞，认为许多DNN测试任务应该是定向测试问题而不是通用测试任务。

    

    深度神经网络（DNNs）展现了非凡的能力，是现代软件系统的重要组成部分。然而，它们也面临着各种漏洞，如对抗攻击和不公平性。因此，测试深度学习（DL）系统是一项重要任务，以检测和减轻这些漏洞。受传统软件测试成功的启发，提出了各种DNN的多样性度量，以帮助有效地暴露DNNs的buggy行为。在本文中，我们认为许多DNN测试任务应该被视为定向测试问题而不是通用测试任务，因为这些任务是具体和明确定义的。因此，基于多样性的方法效果较差。遵循我们的测试目标和DNN语义的论证，我们推导出6个指标，可以用于DNN测试，并仔细分析它们的应用范围。我们通过经验性结果显示它们的应用性。

    Deep neural networks (DNNs) have demonstrated extraordinary capabilities and are an integral part of modern software systems. However, they also suffer from various vulnerabilities such as adversarial attacks and unfairness. Testing deep learning (DL) systems is therefore an important task, to detect and mitigate those vulnerabilities. Motivated by the success of traditional software testing, which often employs diversity heuristics, various diversity measures on DNNs have been proposed to help efficiently expose the buggy behavior of DNNs. In this work, we argue that many DNN testing tasks should be treated as directed testing problems rather than general-purpose testing tasks, because these tasks are specific and well-defined. Hence, the diversity-based approach is less effective.  Following our argument based on the semantics of DNNs and the testing goal, we derive $6$ metrics that can be used for DNN testing and carefully analyze their application scopes. We empirically show their 
    
[^196]: 大型语言模型在知识冲突中的行为揭秘：自适应变色龙还是固执的树獭

    Adaptive Chameleon or Stubborn Sloth: Unraveling the Behavior of Large Language Models in Knowledge Clashes. (arXiv:2305.13300v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.13300](http://arxiv.org/abs/2305.13300)

    本文研究了大型语言模型（LLMs）在遭遇知识冲突时的行为。结果发现，LLMs可以高度接受外部连贯且有说服力的证据，即使与其参数化内存存在冲突，但也可能有局限性。

    

    通过向大型语言模型（LLMs）提供外部信息，工具增强（包括检索增强）已成为解决LLMs静态参数化内存限制的有希望的解决方案。然而，当这些证据与它们的参数化内存发生冲突时，LLMs对这些外部证据有多少接受能力？我们提出了一个系统性的框架来从LLMs中获取高质量的参数化内存，并构建相应的对立内存，从而使我们能够进行一系列受控实验。我们的调查揭示了LLMs表现出看似矛盾的行为。一方面，与以往的观念不同，我们发现，只要外部证据是连贯且有说服力的，LLMs即使与其参数化内存存在冲突也可以高度接受外部证据。另一方面，LLMs也可能会表现出局限性，尤其是当其参数化内存受到威胁时。

    By providing external information to large language models (LLMs), tool augmentation (including retrieval augmentation) has emerged as a promising solution for addressing the limitations of LLMs' static parametric memory. However, how receptive are LLMs to such external evidence, especially when the evidence conflicts with their parametric memory? We present the first comprehensive and controlled investigation into the behavior of LLMs when encountering knowledge conflicts. We propose a systematic framework to elicit high-quality parametric memory from LLMs and construct the corresponding counter-memory, which enables us to conduct a series of controlled experiments. Our investigation reveals seemingly contradicting behaviors of LLMs. On the one hand, different from prior wisdom, we find that LLMs can be highly receptive to external evidence even when that conflicts with their parametric memory, given that the external evidence is coherent and convincing. On the other hand, LLMs also d
    
[^197]: 通过逻辑驱动的数据增强增强大型语言模型的逻辑推理能力

    Enhancing Logical Reasoning of Large Language Models through Logic-Driven Data Augmentation. (arXiv:2305.12599v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12599](http://arxiv.org/abs/2305.12599)

    本论文介绍了一种通过逻辑驱动的数据增强方法来增强大型语言模型的逻辑推理能力。通过将原始文本转换为抽象意义表述图，并对其进行逻辑修改和转换，生成增强数据，从而提升模型性能。该方法适用于各种体系结构的大型语言模型。

    

    将大型语言模型与逻辑推理相结合可以增强它们在问题解决中的能力，使其更加强大和可靠。然而，逻辑推理的复杂性使得从网页上收集可靠的数据来建立全面的训练数据集面临困难，进而影响下游任务的性能。为了解决这个问题，我们提出了一种新颖的逻辑驱动数据增强方法，AMR-LDA。AMR-LDA将原始文本转换成抽象意义表示（AMR）图，这是一种结构化的语义表示，包含了句子的逻辑结构，然后对该图进行操作以生成逻辑修改后的AMR图。修改后的AMR图随后被转换回文本，从而创建增强数据。值得注意的是，我们的方法与体系结构无关，并通过提示增强来增强生成型大型语言模型（如GPT-3.5和GPT-4），并通过微调来增强判别型大型语言模型。

    Combining large language models with logical reasoning enhance their capacity to address problems in a robust and reliable manner. Nevertheless, the intricate nature of logical reasoning poses challenges to gathering reliable data from web for building comprehensive training datasets, subsequently affecting the performance on downstream tasks. To address this, we introduce a novel logic-driven data augmentation approach, AMR-LDA. AMR-LDA converts the original text into an Abstract Meaning Representation (AMR) graph, a structured semantic representation that encapsulates the logic structure of the sentence, upon which operations are performed to generate logically modified AMR graphs. The modified AMR graphs are subsequently converted back into texts to create augmented data. Notably, our methodology is architecture-agnostic and enhances generative large language models, such as GPT-3.5 and GPT-4, through prompt augmentation, and fine-tuning discriminative large language models through 
    
[^198]: PersonaLLM: 探究GPT-3.5表达个性特征和性别差异的能力

    PersonaLLM: Investigating the Ability of GPT-3.5 to Express Personality Traits and Gender Differences. (arXiv:2305.02547v1 [cs.CL])

    [http://arxiv.org/abs/2305.02547](http://arxiv.org/abs/2305.02547)

    本文探究了基于LLMs模拟代理的行为，称之为LLM Personas，在分配大五人格类型和性别角色时是否可以生成具有一致性的个性化特质的内容。

    

    尽管大型语言模型在各个行业的聊天机器人设计中有许多用途，并且研究表明个性化聊天机器人在满足不同人格特征方面的重要性，但很少有研究评估个性化LLM的行为是否能够准确、一致地反映某些人格特征。我们考虑研究基于LLM的模拟代理的行为，称之为LLM personas，并使用GPT-3.5（text-davinci-003）进行案例研究，以研究LLM在分配大五人格类型和性别角色时是否可以生成具有一致性的个性化特质的内容。我们创建了320个LLM personas（每种大五人格类型有5个女性和5个男性），并提示他们完成经典的44项大五人格问卷（BFI），然后撰写一个关于他们童年的800字故事。结果表明，LLM personas的自我报告的BFI分数与他们分配的人格类型一致。

    Despite the many use cases for large language models (LLMs) in the design of chatbots in various industries and the research showing the importance of personalizing chatbots to cater to different personality traits, little work has been done to evaluate whether the behaviors of personalized LLMs can reflect certain personality traits accurately and consistently. We consider studying the behavior of LLM-based simulated agents which refer to as LLM personas and present a case study with GPT-3.5 (text-davinci-003) to investigate whether LLMs can generate content with consistent, personalized traits when assigned Big Five personality types and gender roles. We created 320 LLM personas (5 females and 5 males for each of the 32 Big Five personality types) and prompted them to complete the classic 44-item Big Five Inventory (BFI) and then write an 800-word story about their childhood. Results showed that LLM personas' self-reported BFI scores are consistent with their assigned personality typ
    
[^199]: HeySQuAD: 一个口语化问答数据集

    HeySQuAD: A Spoken Question Answering Dataset. (arXiv:2304.13689v1 [cs.CL])

    [http://arxiv.org/abs/2304.13689](http://arxiv.org/abs/2304.13689)

    HeySQuAD 是一个大规模口语化问答数据集，旨在衡量机器理解并回答嘈杂的口语提问的能力，同时使用转录的人类口语提问进行训练能显著提高模型表现。

    

    人类口语提问对于评估口语问答系统的性能至关重要，尤其是数字助手等多个实际应用场景。本文提出了一个新的大规模社区共享的口语问答数据集 HeySQuAD，它由76k个人类口语提问、97k个机器生成的问题以及相应的文本答案组成，这些答案源自 SQuAD QA 数据集。HeySQuAD 的目标是衡量机器理解嘈杂的口语提问并准确回答问题的能力。为此，我们在人类口语和机器生成的问题上进行了广泛的基准测试，以量化来自两方面噪声的差异及对模型和回答准确度的影响。重要的是，在口语问答任务中，我们希望回答的是人类口语提问，我们观察到使用转录的人类口语提问和原始 SQuAD 问题进行训练，能够显著提高（12.51%）模型的表现，而不是仅使用原始 SQuAD 数据集。

    Human-spoken questions are critical to evaluating the performance of spoken question answering (SQA) systems that serve several real-world use cases including digital assistants. We present a new large-scale community-shared SQA dataset, HeySQuAD that consists of 76k human-spoken questions and 97k machine-generated questions and corresponding textual answers derived from the SQuAD QA dataset. The goal of HeySQuAD is to measure the ability of machines to understand noisy spoken questions and answer the questions accurately. To this end, we run extensive benchmarks on the human-spoken and machine-generated questions to quantify the differences in noise from both sources and its subsequent impact on the model and answering accuracy. Importantly, for the task of SQA, where we want to answer human-spoken questions, we observe that training using the transcribed human-spoken and original SQuAD questions leads to significant improvements (12.51%) over training using only the original SQuAD te
    
[^200]: 通过后验估计尖锐化来隐式减轻视觉偏见：一种贝叶斯神经网络方法

    Implicit Visual Bias Mitigation by Posterior Estimate Sharpening of a Bayesian Neural Network. (arXiv:2303.16564v1 [cs.CV])

    [http://arxiv.org/abs/2303.16564](http://arxiv.org/abs/2303.16564)

    该论文提出了一种隐式减轻视觉偏见的方法，使用贝叶斯神经网络，通过后验估计尖锐化，鼓励网络聚焦于不导致高不确定性的中心特征。

    

    深度神经网络的公平性受到数据集偏见和虚假相关性的强烈影响，而这些对现代特征丰富和复杂的视觉数据集通常都是存在的。由于任务的难度和可变性，没有一种单一的去偏见方法是普遍成功的。特别是，在不需要显式知道偏差变量的情况下的隐式方法对于现实世界的应用尤为相关。我们提出了一种新颖的隐式减缓方法，使用贝叶斯神经网络，允许我们利用致性不确定性与样本中偏差或虚假相关性之间的关系。我们提出的后验估计尖锐化程序鼓励网络聚焦于不导致高不确定性的中心特征。在三个基准数据集上的实验结果表明，具有经过尖锐化后验估计的贝叶斯网络表现与现有方法相当，并显示出进一步研究的潜力。

    The fairness of a deep neural network is strongly affected by dataset bias and spurious correlations, both of which are usually present in modern feature-rich and complex visual datasets. Due to the difficulty and variability of the task, no single de-biasing method has been universally successful. In particular, implicit methods not requiring explicit knowledge of bias variables are especially relevant for real-world applications. We propose a novel implicit mitigation method using a Bayesian neural network, allowing us to leverage the relationship between epistemic uncertainties and the presence of bias or spurious correlations in a sample. Our proposed posterior estimate sharpening procedure encourages the network to focus on core features that do not contribute to high uncertainties. Experimental results on three benchmark datasets demonstrate that Bayesian networks with sharpened posterior estimates perform comparably to prior existing methods and show potential worthy of further 
    
[^201]: 私密、公平且精确：在医学影像中训练大规模隐私保护的人工智能模型

    Private, fair and accurate: Training large-scale, privacy-preserving AI models in medical imaging. (arXiv:2302.01622v3 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2302.01622](http://arxiv.org/abs/2302.01622)

    本研究评估了隐私保护训练医学影像人工智能模型的准确性和公平性，并与非隐私训练进行了比较。研究结果可为隐私保护技术的广泛应用提供重要参考。

    

    人工智能模型在医学领域的应用越来越多。然而，由于医学数据的高度敏感性，需要采取特殊措施确保其保护。保护隐私的黄金标准是引入差分隐私（DP）来进行模型训练。先前的研究表明，DP对模型的准确性和公平性有负面影响，这在医学中是不可接受的，并且是隐私保护技术广泛应用的主要障碍。在这项工作中，我们评估了隐私保护训练人工智能模型对准确性和公平性的影响，与非隐私训练进行了比较。为此，我们使用了两个数据集：（1）一个大规模数据集（N=193,311）的高质量临床胸部X射线图像，和（2）一个数据集（N=1,625）的3D腹部计算机断层扫描（CT）图像，用于分类胰腺导管腺癌（PDAC）的存在。两个数据集均为回顾性采集，并由经验丰富的医学影像专家进行手动标注。

    Artificial intelligence (AI) models are increasingly used in the medical domain. However, as medical data is highly sensitive, special precautions to ensure its protection are required. The gold standard for privacy preservation is the introduction of differential privacy (DP) to model training. Prior work indicates that DP has negative implications on model accuracy and fairness, which are unacceptable in medicine and represent a main barrier to the widespread use of privacy-preserving techniques. In this work, we evaluated the effect of privacy-preserving training of AI models regarding accuracy and fairness compared to non-private training. For this, we used two datasets: (1) A large dataset (N=193,311) of high quality clinical chest radiographs, and (2) a dataset (N=1,625) of 3D abdominal computed tomography (CT) images, with the task of classifying the presence of pancreatic ductal adenocarcinoma (PDAC). Both were retrospectively collected and manually labeled by experienced radio
    

