# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [When does the ID algorithm fail?.](http://arxiv.org/abs/2307.03750) | ID算法解决了图形因果模型中干预分布的识别问题，但当输入分布无法识别时，所谓的"hedge准则"无效。 |
| [^2] | [Frontier AI Regulation: Managing Emerging Risks to Public Safety.](http://arxiv.org/abs/2307.03718) | 对于边缘人工智能模型的监管需要标准制定、注册报告和安全合规机制。 |
| [^3] | [Intelligent Robotic Sonographer: Mutual Information-based Disentangled Reward Learning from Few Demonstrations.](http://arxiv.org/abs/2307.03705) | 本研究提出了一种智能机器人超声医生，通过学习专家的经验，自主地控制超声探头来进行生物测量和内部器官诊断。使用互信息来提取任务相关和领域特征，并通过神经奖励函数推断出专家的生理知识。 |
| [^4] | [Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media.](http://arxiv.org/abs/2307.03699) | 这项研究首次系统地利用大型语言模型(ChatGPT)检测社交媒体上的非法毒品贩运活动。通过利用知识驱动的提示，该方法能够解决传统监督学习方法在数据获取和识别欺骗性语言方面的限制。 |
| [^5] | [Scalable Membership Inference Attacks via Quantile Regression.](http://arxiv.org/abs/2307.03694) | 通过分位数回归进行成员推断攻击的方法，与现有的影子模型攻击相比，计算量更小但效果相当。 |
| [^6] | [Becoming self-instruct: introducing early stopping criteria for minimal instruct tuning.](http://arxiv.org/abs/2307.03692) | 该论文引入了一个用于检测语言模型遵循指令能力的度量标准，并将其用作早停标准进行指令调整。实验证明模型能够相对早期地学会遵循指令，并且进一步微调可能导致语义变化。 |
| [^7] | [Comparing Apples to Apples: Generating Aspect-Aware Comparative Sentences from User Review.](http://arxiv.org/abs/2307.03691) | 该论文提出了一个模型，利用用户评论和相关项目特征生成对比评价句子，以帮助用户找到最适合的产品。该模型包括项目编码模块、比较生成模块和个性化解码方法，并通过人类评估验证了生成句子的相关性和真实性。 |
| [^8] | [Guideline for Trustworthy Artificial Intelligence -- AI Assessment Catalog.](http://arxiv.org/abs/2307.03681) | 上述论文提出了一个可信人工智能准则--AI评估目录，旨在确保AI应用按照高质量标准开发，并有效防范新的AI风险，从而使AI发挥其潜力，减少不公平对待个体的风险。 |
| [^9] | [Evaluating the Effectiveness of Large Language Models in Representing Textual Descriptions of Geometry and Spatial Relations.](http://arxiv.org/abs/2307.03678) | 本研究评估了大型语言模型在表示几何和空间关系文本描述中的有效性，发现虽然这些模型能够捕捉一些空间关系，但在估计数值和检索相关对象方面仍存在挑战。 |
| [^10] | [Decomposing the Generalization Gap in Imitation Learning for Visual Robotic Manipulation.](http://arxiv.org/abs/2307.03659) | 本研究通过研究模仿学习策略在仿真和实际机器人操作任务中的表现，量化了不同因素的泛化困难程度，并设计了一个新的仿真基准来评估泛化控制。根据研究结果，我们确定了泛化困难度的因素排序。 |
| [^11] | [Discovering Variable Binding Circuitry with Desiderata.](http://arxiv.org/abs/2307.03637) | 该论文介绍了一种使用愿望清单自动识别语言模型中的变量绑定电路的方法。该方法通过指定特定子任务的因果属性，成功地将变量绑定定位在模型的部分组件中。 |
| [^12] | [GEANN: Scalable Graph Augmentations for Multi-Horizon Time Series Forecasting.](http://arxiv.org/abs/2307.03595) | 本研究介绍了一种使用图神经网络 (GNNs) 作为数据增强来解决多视角时间序列预测中的“冷启动”问题的方法。这些GNN-based特征能够捕捉复杂的跨序列关系，并且可以与预测任务进行端到端的优化。 |
| [^13] | [VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis.](http://arxiv.org/abs/2307.03592) | VesselVAE是一个递归变分自编码器，用于生成血管的3D几何形状，通过利用血管的层次组织结构和几何特征的低维流形编码，在合成数据和真实数据的半径、长度和扭曲度方面取得了相似性。 |
| [^14] | [Structure Guided Multi-modal Pre-trained Transformer for Knowledge Graph Reasoning.](http://arxiv.org/abs/2307.03591) | 本研究提出了一种图结构引导的多模态预训练Transformer用于知识图谱推理。当前的多模态预训练Transformer模型未能充分利用知识图谱的结构信息，限制了其推理性能。 |
| [^15] | [Multimodal Deep Learning for Personalized Renal Cell Carcinoma Prognosis: Integrating CT Imaging and Clinical Data.](http://arxiv.org/abs/2307.03575) | 本研究通过综合CT成像和临床数据，设计了一个深度学习模型，可以预测肾细胞癌患者的生存概率，并辅助识别需要紧急治疗的患者。 |
| [^16] | [Large Language Models as Batteries-Included Zero-Shot ESCO Skills Matchers.](http://arxiv.org/abs/2307.03539) | 这项工作提出了一个基于大型语言模型的零-shot技能提取系统，通过生成ESCO技能的合成训练数据和使用相似性检索器，实现了从职位描述中提取技能的目标。 |
| [^17] | [Tranfer Learning of Semantic Segmentation Methods for Identifying Buried Archaeological Structures on LiDAR Data.](http://arxiv.org/abs/2307.03512) | 本文研究了利用传输学习方法在LiDAR数据上识别埋藏的考古结构的语义分割。实验结果表明，传输学习的应用可以提高性能，为未来工作提供基准。 |
| [^18] | [Derivative Free Weight-space Ensembling.](http://arxiv.org/abs/2307.03506) | 本文引入了一种新的无导数权重空间集成方法（DFWE），用于开放域对话的少样本任务传递。通过在几个不同的知识库的角度上对专家模型进行微调，并使用无梯度优化算法进行线性插值，我们有效地找到了一个好的模型权重插值，从而在FETA-Friends上超过了标准的预训练-微调方法。 |
| [^19] | [RCDN -- Robust X-Corner Detection Algorithm based on Advanced CNN Model.](http://arxiv.org/abs/2307.03505) | 本研究提出了一种新颖的鲁棒X角点检测算法，能够在多种干扰下保持高亚像素精度，并采用了粗到细的策略和多种后处理技术来提高检测性能和准确度。 |
| [^20] | [Large AI Model-Based Semantic Communications.](http://arxiv.org/abs/2307.03492) | 本文提出了一种基于大型AI模型的语义通信框架（LAM-SC），利用该框架可以克服知识库构建过程中面临的问题，并在图像数据领域实现了语义分割、语义集成和自适应语义压缩。 |
| [^21] | [Discovering Hierarchical Achievements in Reinforcement Learning via Contrastive Learning.](http://arxiv.org/abs/2307.03486) | 通过对比学习方法，我们在强化学习中提出了新的成就蒸馏方法，可以加强代理对下一个解锁成就的预测能力，并优于先前的模型驱动和层次化方法。 |
| [^22] | [TBGC: Task-level Backbone-Oriented Gradient Clip for Multi-Task Foundation Model Learning.](http://arxiv.org/abs/2307.03465) | 提出了任务级骨干导向梯度截断范式，通过独立的梯度截断和统一的范数缩放，有效缓解了多任务学习中的梯度偏向问题。 |
| [^23] | [Towards Deep Network Steganography: From Networks to Networks.](http://arxiv.org/abs/2307.03444) | 本论文提出了一种新的深度网络隐写术，通过将秘密DNN模型伪装成另一个普通学习任务的隐写DNN模型，实现了DNN模型的秘密传输。 |
| [^24] | [Non-iterative Coarse-to-fine Transformer Networks for Joint Affine and Deformable Image Registration.](http://arxiv.org/abs/2307.03421) | 本论文提出了一种非迭代的粗到细变换网络，用于联合仿射和可变形图像配准。与现有方法相比，该方法能够在单个网络中实现粗到细配准，并在配准精度和运行时间方面具有优势。 |
| [^25] | [QI2 -- an Interactive Tool for Data Quality Assurance.](http://arxiv.org/abs/2307.03419) | 本文介绍了一种用于数据质量保证的交互工具QI2，该工具支持对多个数据质量方面的验证和定量数据质量要求的验证。通过在MNIST数据集上进行演示，展示了该方法的应用和优势。 |
| [^26] | [Goal-Conditioned Predictive Coding as an Implicit Planner for Offline Reinforcement Learning.](http://arxiv.org/abs/2307.03406) | 本论文研究了将决策制定视为离线收集的轨迹的监督学习问题，并探究了序列建模在轨迹压缩和策略学习中的作用。通过引入目标条件预测编码（GCPC），本文提出了一种能够产生强大轨迹表示并实现高性能策略的方法。 |
| [^27] | [Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs.](http://arxiv.org/abs/2307.03393) | 本文探索了大规模语言模型（LLMs）在图学习中的潜力，并尝试了两种不同的流程：将LLMs作为增强器通过海量知识来增强节点的文本属性，并使用图神经网络（GNNs）生成预测，以及直接使用LLMs作为独立的预测器。 |
| [^28] | [On Formal Feature Attribution and Its Approximation.](http://arxiv.org/abs/2307.03380) | 这篇论文研究了解释性人工智能（XAI）中的形式特征归因方法及其近似方法。现有的特征选择和归因方法存在一些问题，而形式化的XAI方法虽然是一个有希望的解决方案，但仍存在一些限制。 |
| [^29] | [Efficient Ground Vehicle Path Following in Game AI.](http://arxiv.org/abs/2307.03379) | 本文介绍了一种专为游戏AI设计的高效路径跟随解决方案，通过调整已有技术，设计出具有可调参数的简单解决方案，并通过测试场景验证了其在不同类型路径和车辆上的效果和稳健性，在总卡住事件数量上取得了70%的减少。 |
| [^30] | [All in One: Exploring Unified Vision-Language Tracking with Multi-Modal Alignment.](http://arxiv.org/abs/2307.03373) | 本文提出了一种一体化视觉-语言跟踪框架，采用统一的Transformer主干网络，实现联合特征提取和交互，提高了在复杂场景下的目标感知能力。 |
| [^31] | [Adaptation and Communication in Human-Robot Teaming to Handle Discrepancies in Agents' Beliefs about Plans.](http://arxiv.org/abs/2307.03362) | 本文研究人机合作中的适应性和沟通，以处理代理之间关于计划的信念差异，通过利用认知逻辑来理解和解决这些差异。 |
| [^32] | [Evaluating Biased Attitude Associations of Language Models in an Intersectional Context.](http://arxiv.org/abs/2307.03360) | 这篇论文以已建立的文献为基础，量化了英语语言模型中社会群体的情绪关联，并发现语言模型对性别认同、社会阶级和性取向的信号表现出最大的偏见态度。 |
| [^33] | [Assisting Clinical Decisions for Scarcely Available Treatment via Disentangled Latent Representation.](http://arxiv.org/abs/2307.03315) | 通过解决体外膜肺氧合(ECMO)治疗选择偏差和稀缺治疗案例的挑战，我们提出了一种名为Treatment Variational AutoEncoder (TVAE)的方法，用于个体化治疗分析，以支持临床决策。 |
| [^34] | [On Invariance, Equivariance, Correlation and Convolution of Spherical Harmonic Representations for Scalar and Vectorial Data.](http://arxiv.org/abs/2307.03311) | 这篇论文介绍了球面谐波表示的理论基础和实际应用，包括旋转不变和等变特征，以及球面上信号的卷积和精确相关性。此外，还将这些方法推广到了矢量谐波表示。 |
| [^35] | [A Vulnerability of Attribution Methods Using Pre-Softmax Scores.](http://arxiv.org/abs/2307.03305) | 这篇论文讨论了使用前softmax分数的归属方法的一个漏洞，该方法用于解释卷积神经网络分类器输出。与对抗性攻击不同，作者关注的是对归属方法进行小修改可能导致的影响，而不会改变模型的输出。 |
| [^36] | [It is not Sexually Suggestive, It is Educative. Separating Sex Education from Suggestive Content on TikTok Videos.](http://arxiv.org/abs/2307.03274) | 在TikTok视频中，我们引入了一个名为SexTok的数据集，用于区分性暗示内容和虚拟性教育视频。我们发现这是一个具有挑战性但可学习的任务。 |
| [^37] | [Vision Language Transformers: A Survey.](http://arxiv.org/abs/2307.03254) | 视觉语言转换器是将预训练的transformer架构应用于视觉语言建模的研究领域，通过迁移学习，在同时进行视觉和语言任务中取得了显著改进。 |
| [^38] | [Region-Wise Attentive Multi-View Representation Learning for Urban Region Embeddings.](http://arxiv.org/abs/2307.03212) | 提出了一种区域关注的多视角表示学习（ROMER）的算法，用于捕捉多视角之间的依赖关系，学习城市区域的表达能力，并在多源城市数据中优于现有方法。 |
| [^39] | [Scaling Laws Do Not Scale.](http://arxiv.org/abs/2307.03201) | 本文讨论了缩放定律与人工智能模型性能之间的关系，并指出数据集规模的增加会引发不同社群的价值观和偏见风险。 |
| [^40] | [Transcribing Educational Videos Using Whisper: A preliminary study on using AI for transcribing educational videos.](http://arxiv.org/abs/2307.03200) | 本文研究了使用AI进行教育视频转录的初步研究，发现自动语音识别系统可以降低生成转录的成本和延迟，并提出了一些未来的研究方向。 |
| [^41] | [A multilevel framework for AI governance.](http://arxiv.org/abs/2307.03198) | 本文提出了一个多层级的AI治理框架，涉及政府、企业和公民三个相互依赖的利益相关者群体。通过信任的不同维度来研究它们之间的关系，并为进一步提升用户体验和制定AI相关公共政策提供实用见解。 |
| [^42] | [Analyzing the vulnerabilities in SplitFed Learning: Assessing the robustness against Data Poisoning Attacks.](http://arxiv.org/abs/2307.03197) | 本研究对SplitFed Learning中的数据污染攻击进行了研究和分析，并提出了三种新的攻击策略。实验结果表明这些攻击策略可以降低基于DCML的分类器的性能。 |
| [^43] | [A Comprehensive Survey of Artificial Intelligence Techniques for Talent Analytics.](http://arxiv.org/abs/2307.03195) | 这篇论文综述了人工智能技术在人才分析中的应用。通过使用大数据和人工智能技术，组织可以从数据科学的角度理解组织行为并实时做出决策，为有效的人才管理提供智能支持。 |
| [^44] | [Finding differences in perspectives between designers and engineers to develop trustworthy AI for autonomous cars.](http://arxiv.org/abs/2307.03193) | 本研究通过探索设计师和工程师的观点差异，为自动驾驶汽车的可信任AI开发提供了实用建议，旨在提高技术进步和道德原则的优先性。 |
| [^45] | [Hybrid Knowledge-Data Driven Channel Semantic Acquisition and Beamforming for Cell-Free Massive MIMO.](http://arxiv.org/abs/2307.03070) | 本文提出了一种混合知识数据驱动的方法，用于无小区大规模MIMO系统中的通道语义获取和多用户波束赋形，可提高室外无线系统的性能，支持扩展现实应用。 |
| [^46] | [What Should Data Science Education Do with Large Language Models?.](http://arxiv.org/abs/2307.02792) | 大型语言模型（LLM）正在改变数据科学家的责任和数据科学教育模式，从动手编码和标准分析转变为评估和管理自动化AI执行的分析。这种转变要求数据科学教育注重培养学生的多样化技能，如创造力、批判性思维和AI引导的编程。 |
| [^47] | [Elastic Decision Transformer.](http://arxiv.org/abs/2307.02484) | 弹性决策变压器（EDT）通过在测试时间进行动作推断时调整历史长度来实现轨迹拼接，填补了决策变压器（DT）在这一方面的性能差距，并且在多任务情况下胜过基于Q-Learning的方法。 |
| [^48] | [FOCUS: Object-Centric World Models for Robotics Manipulation.](http://arxiv.org/abs/2307.02427) | FOCUS是一个基于模型的代理机器人，学习了以物体为中心的世界模型，并通过新颖的探索奖励来更轻松地探索物体间的相互作用。这种以物体为中心的世界模型可以更高效地解决机器人操纵任务，并实现一致性的机器人-物体交互探索。 |
| [^49] | [Suffering Toasters.](http://arxiv.org/abs/2306.17258) | 本文旨在为人工智能、自我意识和代理问题提供更清晰的定义，我们提出了一种新的启发式方法来测试人工自我意识，并讨论了这种方法引发的一些问题。 |
| [^50] | [Enhancing Adversarial Training via Reweighting Optimization Trajectory.](http://arxiv.org/abs/2306.14275) | 本文提出了一种名为“加权优化轨迹（WOT）”的新方法，通过优化历史轨迹，解决了对抗训练中的鲁棒泛化问题。 |
| [^51] | [FedSelect: Customized Selection of Parameters for Fine-Tuning during Personalized Federated Learning.](http://arxiv.org/abs/2306.13264) | 本文提出了一种名为FedSelect的新联邦学习框架，通过寻找最佳客户端子网络从而直接个性化客户端子网络结构和参数，同时保留了全局知识，提高了客户端性能。 |
| [^52] | [An Interleaving Semantics of the Timed Concurrent Language for Argumentation to Model Debates and Dialogue Games.](http://arxiv.org/abs/2306.07675) | 本文提出了一种基于定时抽象论证框架的定时并发语言，用于模拟代理之间的交互，并将代理的可接受性与给定时间间隔进行推理和通信，特别适用于模拟辩论和对话游戏的情境。 |
| [^53] | [$E(2)$-Equivariant Vision Transformer.](http://arxiv.org/abs/2306.06722) | 本文设计了一个群等变视觉Transformer，通过一种新颖有效的位置编码操作解决了视觉Transformer中的等变性学习难题，并通过实验证明了其明显优于非等变的自注意力网络。 |
| [^54] | [Offline Prioritized Experience Replay.](http://arxiv.org/abs/2306.05412) | 本文提出了离线优先经验重放（OPER）方法来解决离线强化学习中的分布偏移问题。通过设计一类优先级函数来对高回报的转换进行优先处理，从而改善行为策略，并在此改进的策略约束下优化离线强化学习算法的解决方案。对于离线强化学习，OPER方法是一种有效的解决方案。 |
| [^55] | [Don't trust your eyes: on the (un)reliability of feature visualizations.](http://arxiv.org/abs/2306.04719) | 本文探讨了神经网络如何从像素中提取模式的问题，并研究了特征可视化的可靠性。实验证据表明，由于优化过程中固有的限制，特征可视化能够可靠理解的功能集非常有限，对于解释神经网络如何处理自然图像的解释能力产生怀疑。 |
| [^56] | [Code-Switched Text Synthesis in Unseen Language Pairs.](http://arxiv.org/abs/2305.16724) | 本文介绍了GLOSS模型，旨在解决在缺乏训练数据的情况下合成混合代码文本的问题，并且可以推广到更广泛的语言对。该模型在四个未见过的语言对上的实验中优于其他基线模型和在单语文本上运行的生成模型。 |
| [^57] | [Summarizing Strategy Card Game AI Competition.](http://arxiv.org/abs/2305.11814) | 本文总结了基于《魔法与代码英雄》（LOCM）的五年人工智能比赛，介绍了游戏规则以及比赛历史，给出了组织AI比赛的建议。LOCM已被用于许多与游戏树搜索算法、神经网络、评估函数和CCG卡组构建等相关领域的出版物中。 |
| [^58] | [SocNavGym: A Reinforcement Learning Gym for Social Navigation.](http://arxiv.org/abs/2304.14102) | 本文提出了SocNavGym，对于社交导航领域的研究提供了一个轻便、快速、易用的仿真环境，可生成各种各样的社交导航场景，并促进了智能社交机器人的发展。 |
| [^59] | [Innovation Slowdown: Decelerating Concept Creation and Declining Originality in New Technological Concepts.](http://arxiv.org/abs/2303.13300) | 人类智力的局限性导致技术概念创造放缓和原创性下降，因此建议开发和实施创造性人工智能增强创新过程。 |
| [^60] | [Revisiting Modality Imbalance In Multimodal Pedestrian Detection.](http://arxiv.org/abs/2302.12589) | 本文探讨了多模态行人检测中模态不平衡问题，并提出了一种新的训练设置，通过正则化器解决了模态之间的不平衡，使得特征融合更加鲁棒。 |
| [^61] | [Automatic Intrinsic Reward Shaping for Exploration in Deep Reinforcement Learning.](http://arxiv.org/abs/2301.10886) | 本文提出了一种名为AIRS的自动内在奖励塑造探索方法，可以提供高质量的内在激励以增强强化学习中的探索性能；并开发了高效可靠的内在奖励工具包。实验表明，AIRS性能卓越，能够胜过基准方案。 |
| [^62] | [Scalable Multi-Agent Reinforcement Learning for Warehouse Logistics with Robotic and Human Co-Workers.](http://arxiv.org/abs/2212.11498) | 该论文提出了一种可扩展的多智能体强化学习方法，用于仓库物流中的机器人和人类同事合作。他们通过分层的MARL算法，让经理和工人代理根据全局目标进行协同训练，以最大化拣货速率。 |
| [^63] | [A Memetic Algorithm with Reinforcement Learning for Sociotechnical Production Scheduling.](http://arxiv.org/abs/2212.10936) | 本文提出了一种基于深度强化学习的模因算法，用于解决具有实际约束的灵活生产调度问题，并弥补元启发式研究中的缺陷。 |
| [^64] | [Memory-efficient NLLB-200: Language-specific Expert Pruning of a Massively Multilingual Machine Translation Model.](http://arxiv.org/abs/2212.09811) | 本研究提出了一种节约内存的NLLB-200模型修剪方法，可在保持翻译质量的同时移除多达80％的专家，使得在单个32GB的GPU上运行模型成为可能。这对于大规模多语言机器翻译具有重要的意义。 |
| [^65] | [Equivariance with Learned Canonicalization Functions.](http://arxiv.org/abs/2211.06489) | 本文提出了一种使用学习的规范化函数来实现等变性的方法，避免了对神经网络架构的限制。实验结果表明，学习规范化函数可以在多个任务中与现有技术相比具有竞争力，并且速度更快。 |
| [^66] | [Breadth-First Pipeline Parallelism.](http://arxiv.org/abs/2211.05953) | 宽度优先的流水线并行计算方法结合了流水线和数据并行计算，通过在每个GPU上使用小批量大小和完全分片的数据并行计算，以提高训练吞吐量。在实验中，与Megatron-LM相比，在一个520亿参数的模型上，使用小批量大小每个GPU的训练吞吐量增加了高达43%。 |
| [^67] | [Topical: Learning Repository Embeddings from Source Code using Attention.](http://arxiv.org/abs/2208.09495) | 这篇论文介绍了Topical，一种使用深度神经网络从源代码中学习存储库级嵌入的方法，以实现代码自动生成、代码推荐和代码自动标记等功能。 |
| [^68] | [GRAPHSHAP: Explaining Identity-Aware Graph Classifiers Through the Language of Motifs.](http://arxiv.org/abs/2202.08815) | GRAPHSHAP是一种基于Shapley值的方法，可以提供基于模样式的解释，用于解释基于身份感知的图分类器，而无需对模型或其训练数据有任何先验知识。 |
| [^69] | [Reward-Respecting Subtasks for Model-Based Reinforcement Learning.](http://arxiv.org/abs/2202.03466) | 论文提出了一种基于模型的强化学习的方法，通过添加奖励加成的子任务来发现选项，从而解决了以前方法中忽略原始奖励的问题。 |
| [^70] | [Deep Optimal Transport for Domain Adaptation on SPD Manifolds.](http://arxiv.org/abs/2201.05745) | 这项研究介绍了一种基于深度最优传输的方法，用于解决在SPD流形上的领域自适应问题。通过利用最优传输理论和SPD流形的对数欧几里得几何，我们克服了协方差矩阵操作的复杂性挑战。 |
| [^71] | [Creativity of AI: Hierarchical Planning Model Learning for Facilitating Deep Reinforcement Learning.](http://arxiv.org/abs/2112.09836) | 该论文提出了一种新颖的深度强化学习框架，通过在DRL中嵌入符号知识，解决了数据效率、解释性缺乏和可迁移性等关键问题。该框架通过循环训练过程，并利用学习的规划模型和符号选项来引导策略的改进。学到的符号选项减轻了对专家领域知识的要求，并提供了策略的内在可解释性，同时通过与符号规划模型的规划进一步提高了可迁移性和数据效率。 |
| [^72] | [F2A2: Flexible Fully-decentralized Approximate Actor-critic for Cooperative Multi-agent Reinforcement Learning.](http://arxiv.org/abs/2004.11145) | 本文提出了一个灵活完全分散化的演员-评论家多智能体强化学习框架，在大规模合作多智能体环境中，通过设计一个基于原始-对偶混合梯度下降的算法框架，可以分别学习每个智能体，并实现策略改进和价值评价。 |

# 详细

[^1]: ID算法在什么情况下失效？

    When does the ID algorithm fail?. (arXiv:2307.03750v1 [stat.ME])

    [http://arxiv.org/abs/2307.03750](http://arxiv.org/abs/2307.03750)

    ID算法解决了图形因果模型中干预分布的识别问题，但当输入分布无法识别时，所谓的"hedge准则"无效。

    

    ID算法解决了图形因果模型中形式为p(Y | do(a))的干预分布的识别问题，并且已经以多种方式进行了公式化。ID算法是正确的（在输入图所代表的因果模型中，输出观测数据分布的正确功能），并且是完整的（当输入的p(Y | do(a))在输入图所代表的因果模型中无法识别时，明确标记为失败）。参考文献[9]提供了一个结果，即所谓的"hedge准则"（Corollary 3），旨在以输入图中的一个称为"hedge"的结构来给出ID算法无法识别其输入的情况的图形特征。虽然ID算法确实是一个正确和完整的算法，并且只要输入分布无法识别，"hedge"结构就会出现，但是在[9]中提出的Corollary 3是不正确的。

    The ID algorithm solves the problem of identification of interventional distributions of the form p(Y | do(a)) in graphical causal models, and has been formulated in a number of ways [12, 9, 6]. The ID algorithm is sound (outputs the correct functional of the observed data distribution whenever p(Y | do(a)) is identified in the causal model represented by the input graph), and complete (explicitly flags as a failure any input p(Y | do(a)) whenever this distribution is not identified in the causal model represented by the input graph).  The reference [9] provides a result, the so called "hedge criterion" (Corollary 3), which aims to give a graphical characterization of situations when the ID algorithm fails to identify its input in terms of a structure in the input graph called the hedge. While the ID algorithm is, indeed, a sound and complete algorithm, and the hedge structure does arise whenever the input distribution is not identified, Corollary 3 presented in [9] is incorrect as sta
    
[^2]: 边缘人工智能监管：管理对公共安全的新兴风险

    Frontier AI Regulation: Managing Emerging Risks to Public Safety. (arXiv:2307.03718v1 [cs.CY])

    [http://arxiv.org/abs/2307.03718](http://arxiv.org/abs/2307.03718)

    对于边缘人工智能模型的监管需要标准制定、注册报告和安全合规机制。

    

    先进的人工智能模型为人类带来巨大的好处，但社会需要主动管理相关的风险。本文关注我们所称的“边缘人工智能”模型：高度能力的基础模型，可能具备足以对公共安全造成严重风险的危险能力。边缘人工智能模型带来了独特的监管挑战：危险能力可能出乎意料；很难有效防止部署模型被滥用；并且很难阻止模型的能力广泛扩散。为了应对这些挑战，边缘模型的监管需要至少三个基本要素：(1) 设定标准的过程，以确定边缘人工智能开发者的适当要求；(2) 注册和报告要求，为监管机构提供对边缘人工智能开发过程的可见性；(3) 保证开发和部署的安全标准的机制。

    Advanced AI models hold the promise of tremendous benefits for humanity, but society needs to proactively manage the accompanying risks. In this paper, we focus on what we term "frontier AI" models: highly capable foundation models that could possess dangerous capabilities sufficient to pose severe risks to public safety. Frontier AI models pose a distinct regulatory challenge: dangerous capabilities can arise unexpectedly; it is difficult to robustly prevent a deployed model from being misused; and, it is difficult to stop a model's capabilities from proliferating broadly. To address these challenges, at least three building blocks for the regulation of frontier models are needed: (1) standard-setting processes to identify appropriate requirements for frontier AI developers, (2) registration and reporting requirements to provide regulators with visibility into frontier AI development processes, and (3) mechanisms to ensure compliance with safety standards for the development and deplo
    
[^3]: 智能机器人超声医生：基于互信息的少示范解耦奖励学习

    Intelligent Robotic Sonographer: Mutual Information-based Disentangled Reward Learning from Few Demonstrations. (arXiv:2307.03705v1 [cs.RO])

    [http://arxiv.org/abs/2307.03705](http://arxiv.org/abs/2307.03705)

    本研究提出了一种智能机器人超声医生，通过学习专家的经验，自主地控制超声探头来进行生物测量和内部器官诊断。使用互信息来提取任务相关和领域特征，并通过神经奖励函数推断出专家的生理知识。

    

    超声（US）成像由于实时性和无辐射的优势而广泛用于生物测量和内部器官诊断。然而，由于高水平的操作者可变性，结果图像很大程度上取决于操作者的经验。本文提出了一种智能机器人超声医生，通过从专家那里学习，自主地“探索”目标解剖学并将超声探头导航到相关的2D平面。专家的底层高级生理知识通过神经奖励函数推断出来，使用自监督方式进行排名对比图像。这个过程可以称为理解 “声学语言”。考虑到克服患者间变异性的泛化能力，网络通过估计互信息来显式提取潜在空间中与任务相关和领域特征。此外，开发了基于高斯分布的滤波器，用于自动评估和采取措施。

    Ultrasound (US) imaging is widely used for biometric measurement and diagnosis of internal organs due to the advantages of being real-time and radiation-free. However, due to high inter-operator variability, resulting images highly depend on operators' experience. In this work, an intelligent robotic sonographer is proposed to autonomously "explore" target anatomies and navigate a US probe to a relevant 2D plane by learning from expert. The underlying high-level physiological knowledge from experts is inferred by a neural reward function, using a ranked pairwise image comparisons approach in a self-supervised fashion. This process can be referred to as understanding the "language of sonography". Considering the generalization capability to overcome inter-patient variations, mutual information is estimated by a network to explicitly extract the task-related and domain features in latent space. Besides, a Gaussian distribution-based filter is developed to automatically evaluate and take 
    
[^4]: 揭示知识激发的ChatGPT在增强社交媒体上的毒品贩运检测中的潜力

    Unveiling the Potential of Knowledge-Prompted ChatGPT for Enhancing Drug Trafficking Detection on Social Media. (arXiv:2307.03699v1 [cs.CL])

    [http://arxiv.org/abs/2307.03699](http://arxiv.org/abs/2307.03699)

    这项研究首次系统地利用大型语言模型(ChatGPT)检测社交媒体上的非法毒品贩运活动。通过利用知识驱动的提示，该方法能够解决传统监督学习方法在数据获取和识别欺骗性语言方面的限制。

    

    社交媒体平台如Instagram和Twitter已经成为毒品营销和非法销售的关键渠道。检测和标记在线非法毒品贩运活动对解决这个问题至关重要。然而，传统的监督学习方法在检测毒品贩运方面的有效性在很大程度上依赖于获得大量标记数据，而数据注释是耗时且资源密集的过程。此外，当毒贩使用欺骗性语言和委婉语避免被检测时，这些模型通常面临着准确识别贩运活动的挑战。为了克服这个限制，我们进行了第一次系统研究，利用ChatGPT等大型语言模型(LLMs)来检测社交媒体上的非法毒品贩运活动。我们提出了一个分析框架，用于组成知识驱动的提示，这些提示作为人类与LLMs交互的接口来执行检测任务。

    Social media platforms such as Instagram and Twitter have emerged as critical channels for drug marketing and illegal sale. Detecting and labeling online illicit drug trafficking activities becomes important in addressing this issue. However, the effectiveness of conventional supervised learning methods in detecting drug trafficking heavily relies on having access to substantial amounts of labeled data, while data annotation is time-consuming and resource-intensive. Furthermore, these models often face challenges in accurately identifying trafficking activities when drug dealers use deceptive language and euphemisms to avoid detection. To overcome this limitation, we conduct the first systematic study on leveraging large language models (LLMs), such as ChatGPT, to detect illicit drug trafficking activities on social media. We propose an analytical framework to compose \emph{knowledge-informed prompts}, which serve as the interface that humans can interact with and use LLMs to perform t
    
[^5]: 可伸缩的通过分位数回归进行成员推断攻击

    Scalable Membership Inference Attacks via Quantile Regression. (arXiv:2307.03694v1 [cs.LG])

    [http://arxiv.org/abs/2307.03694](http://arxiv.org/abs/2307.03694)

    通过分位数回归进行成员推断攻击的方法，与现有的影子模型攻击相比，计算量更小但效果相当。

    

    成员推断攻击旨在通过对训练模型进行黑盒访问，确定特定示例是否在训练中使用。成员推断可以形式化为一个假设检验问题。现有最有效的攻击是通过训练许多与被攻击模型相同架构的“影子模型”（在随机数据子样本上训练）来估计某些测试统计量（通常是模型对真实标签的置信度）的分布。虽然有效，但这些攻击非常计算密集，特别是当被攻击的模型很大时。我们引入了一种新的攻击方式，通过对未在训练中使用的点上的被攻击模型产生的置信度分布进行分位数回归。我们证明了我们的方法与最先进的影子模型攻击相竞争，同时需要更少的计算量。

    Membership inference attacks are designed to determine, using black box access to trained models, whether a particular example was used in training or not. Membership inference can be formalized as a hypothesis testing problem. The most effective existing attacks estimate the distribution of some test statistic (usually the model's confidence on the true label) on points that were (and were not) used in training by training many \emph{shadow models} -i.e. models of the same architecture as the model being attacked, trained on a random subsample of data. While effective, these attacks are extremely computationally expensive, especially when the model under attack is large.  We introduce a new class of attacks based on performing quantile regression on the distribution of confidence scores induced by the model under attack on points that are not used in training. We show that our method is competitive with state-of-the-art shadow model attacks, while requiring substantially less comput
    
[^6]: 成为自学者：引入最小指令调整的早停标准

    Becoming self-instruct: introducing early stopping criteria for minimal instruct tuning. (arXiv:2307.03692v1 [cs.CL])

    [http://arxiv.org/abs/2307.03692](http://arxiv.org/abs/2307.03692)

    该论文引入了一个用于检测语言模型遵循指令能力的度量标准，并将其用作早停标准进行指令调整。实验证明模型能够相对早期地学会遵循指令，并且进一步微调可能导致语义变化。

    

    在本文中，我们引入了指令跟随得分（IFS），一种检测语言模型遵循指令能力的度量标准。该度量标准具有双重目的。首先，IFS可以用于区分基础模型和指令模型。我们对公开可用的基础模型和指令模型进行了基准测试，并显示出良好格式化响应与部分和完整句子的比例可以作为这两种模型类别之间的有效衡量指标。其次，该度量标准可以用作指令调整的早停标准。我们计算了7B和13B LLaMA模型的有监督微调的IFS，显示模型在训练过程中相对早期就学会了遵循指令，并且进一步微调可能导致基础模型语义的变化。作为语义变化的示例，我们展示了由辅助度量标准ObjecQA定义的模型预测的客观性。我们表明在这种特定情况下，当IFS倾向于p时，语义变化最为剧烈。

    In this paper, we introduce the Instruction Following Score (IFS), a metric that detects language models' ability to follow instructions. The metric has a dual purpose. First, IFS can be used to distinguish between base and instruct models. We benchmark publicly available base and instruct models, and show that the ratio of well formatted responses to partial and full sentences can be an effective measure between those two model classes. Secondly, the metric can be used as an early stopping criteria for instruct tuning. We compute IFS for Supervised Fine-Tuning (SFT) of 7B and 13B LLaMA models, showing that models learn to follow instructions relatively early in the training process, and the further finetuning can result in changes in the underlying base model semantics. As an example of semantics change we show the objectivity of model predictions, as defined by an auxiliary metric ObjecQA. We show that in this particular case, semantic changes are the steepest when the IFS tends to p
    
[^7]: 将苹果与苹果进行比较：从用户评论生成纵向感知的比较句子

    Comparing Apples to Apples: Generating Aspect-Aware Comparative Sentences from User Review. (arXiv:2307.03691v1 [cs.CL])

    [http://arxiv.org/abs/2307.03691](http://arxiv.org/abs/2307.03691)

    该论文提出了一个模型，利用用户评论和相关项目特征生成对比评价句子，以帮助用户找到最适合的产品。该模型包括项目编码模块、比较生成模块和个性化解码方法，并通过人类评估验证了生成句子的相关性和真实性。

    

    在众多相似的选择中找到最佳产品是非常耗时的。比较句子可以帮助我们以突出的方式对比一个项目与其他项目，在此过程中强调出重要特征。基于用户对一个或多个项目的评论及相关项目特征，我们生成比较评论句子来帮助用户找到最适合的产品。具体来说，我们的模型包括三个连续组件：（i）一个项目编码模块用于对项目进行编码比较，（ii）一个比较生成模块以自回归的方式生成比较句子，（iii）一种用于用户个性化的新型解码方法。我们展示了我们的流程能够生成流畅且多样的比较句子。我们进行了人类评估研究来验证我们生成的句子的相关性和真实性，结果表明我们的算法能够生成相关且真实的比较评论句子。

    It is time-consuming to find the best product among many similar alternatives. Comparative sentences can help to contrast one item from others in a way that highlights important features of an item that stand out. Given reviews of one or multiple items and relevant item features, we generate comparative review sentences to aid users to find the best fit. Specifically, our model consists of three successive components in a transformer: (i) an item encoding module to encode an item for comparison, (ii) a comparison generation module that generates comparative sentences in an autoregressive manner, (iii) a novel decoding method for user personalization. We show that our pipeline generates fluent and diverse comparative sentences. We run experiments on the relevance and fidelity of our generated sentences in a human evaluation study and find that our algorithm creates comparative review sentences that are relevant and truthful.
    
[^8]: 可信人工智能准则--AI评估目录

    Guideline for Trustworthy Artificial Intelligence -- AI Assessment Catalog. (arXiv:2307.03681v1 [cs.CY])

    [http://arxiv.org/abs/2307.03681](http://arxiv.org/abs/2307.03681)

    上述论文提出了一个可信人工智能准则--AI评估目录，旨在确保AI应用按照高质量标准开发，并有效防范新的AI风险，从而使AI发挥其潜力，减少不公平对待个体的风险。

    

    人工智能（AI）近年来取得了令人瞩目的进展，并代表着一项对经济和社会具有重要影响的关键技术。然而，很明显，只有按照高质量标准开发AI应用并有效防范新的AI风险，AI和基于其的商业模式才能充分发挥其潜力。例如，当处理个人数据（例如，支持信贷借款或员工招聘决策）时，AI存在不公平对待个体的风险。这些新风险的出现与AI应用的行为密切相关，尤其是基于机器学习（ML）的应用，其行为基本上是从大量数据中学习而来，而不是由固定编程规则预先确定的。因此，AI应用的可信度问题至关重要，是政治、商业和社会利益相关者众多重要出版物的主题。

    Artificial Intelligence (AI) has made impressive progress in recent years and represents a key technology that has a crucial impact on the economy and society. However, it is clear that AI and business models based on it can only reach their full potential if AI applications are developed according to high quality standards and are effectively protected against new AI risks. For instance, AI bears the risk of unfair treatment of individuals when processing personal data e.g., to support credit lending or staff recruitment decisions. The emergence of these new risks is closely linked to the fact that the behavior of AI applications, particularly those based on Machine Learning (ML), is essentially learned from large volumes of data and is not predetermined by fixed programmed rules.  Thus, the issue of the trustworthiness of AI applications is crucial and is the subject of numerous major publications by stakeholders in politics, business and society. In addition, there is mutual agreeme
    
[^9]: 评估大型语言模型在表示几何和空间关系的文本描述中的有效性

    Evaluating the Effectiveness of Large Language Models in Representing Textual Descriptions of Geometry and Spatial Relations. (arXiv:2307.03678v1 [cs.CL])

    [http://arxiv.org/abs/2307.03678](http://arxiv.org/abs/2307.03678)

    本研究评估了大型语言模型在表示几何和空间关系文本描述中的有效性，发现虽然这些模型能够捕捉一些空间关系，但在估计数值和检索相关对象方面仍存在挑战。

    

    本研究旨在评估大型语言模型（LLMs）在表示几何和空间关系方面的能力。我们利用包括GPT-2和BERT在内的LLMs对几何的文本格式进行编码，然后将它们的嵌入输入分类器和回归器，以评估LLMs生成的嵌入在几何属性方面的有效性。实验表明，尽管LLMs生成的嵌入能够保留几何类型并捕捉一些空间关系（准确度高达73%），但在估计数值和检索空间相关对象方面仍存在挑战。本研究凸显了在捕捉底层地理空间数据的细微差别和复杂性以及整合领域知识以支持使用基础模型的各种GeoAI应用方面的改进需求。

    This research focuses on assessing the ability of large language models (LLMs) in representing geometries and their spatial relations. We utilize LLMs including GPT-2 and BERT to encode the well-known text (WKT) format of geometries and then feed their embeddings into classifiers and regressors to evaluate the effectiveness of the LLMs-generated embeddings for geometric attributes. The experiments demonstrate that while the LLMs-generated embeddings can preserve geometry types and capture some spatial relations (up to 73% accuracy), challenges remain in estimating numeric values and retrieving spatially related objects. This research highlights the need for improvement in terms of capturing the nuances and complexities of the underlying geospatial data and integrating domain knowledge to support various GeoAI applications using foundation models.
    
[^10]: 分解视觉机器人操作中模仿学习的泛化差距

    Decomposing the Generalization Gap in Imitation Learning for Visual Robotic Manipulation. (arXiv:2307.03659v1 [cs.RO])

    [http://arxiv.org/abs/2307.03659](http://arxiv.org/abs/2307.03659)

    本研究通过研究模仿学习策略在仿真和实际机器人操作任务中的表现，量化了不同因素的泛化困难程度，并设计了一个新的仿真基准来评估泛化控制。根据研究结果，我们确定了泛化困难度的因素排序。

    

    模仿学习在视觉机器人操作中为何难以泛化？这个问题并不容易解决，但从机器人的视角来看，环境通常可以分解为可以枚举的变化因素，例如光照条件或摄像机的摆放位置。在实证上，对于这些因素的泛化比其他因素更具挑战性，但现有的工作很少涉及到每个因素对泛化差距的贡献有多大。为了回答这个问题，我们在仿真环境和实际机器人语言条件下的操作任务中研究模仿学习策略，以量化不同（集合）因素的泛化困难程度。我们还设计了一个新的仿真基准，包含19个任务和11个变化因素，以便更好地进行泛化的控制性评估。通过我们的研究，我们确定了基于泛化困难度的因素排序，这是一致的。

    What makes generalization hard for imitation learning in visual robotic manipulation? This question is difficult to approach at face value, but the environment from the perspective of a robot can often be decomposed into enumerable factors of variation, such as the lighting conditions or the placement of the camera. Empirically, generalization to some of these factors have presented a greater obstacle than others, but existing work sheds little light on precisely how much each factor contributes to the generalization gap. Towards an answer to this question, we study imitation learning policies in simulation and on a real robot language-conditioned manipulation task to quantify the difficulty of generalization to different (sets of) factors. We also design a new simulated benchmark of 19 tasks with 11 factors of variation to facilitate more controlled evaluations of generalization. From our study, we determine an ordering of factors based on generalization difficulty, that is consistent
    
[^11]: 使用愿望清单发现变量绑定电路

    Discovering Variable Binding Circuitry with Desiderata. (arXiv:2307.03637v1 [cs.AI])

    [http://arxiv.org/abs/2307.03637](http://arxiv.org/abs/2307.03637)

    该论文介绍了一种使用愿望清单自动识别语言模型中的变量绑定电路的方法。该方法通过指定特定子任务的因果属性，成功地将变量绑定定位在模型的部分组件中。

    

    最近的研究表明，语言模型中的计算可能是可理解的，通过成功地局部化和干预单元特征和输入输出电路。在这里，我们引入了一种方法，通过仅指定执行特定子任务的模型组件的一组"愿望清单"或因果属性，来扩展因果中介实验，以自动识别负责执行该子任务的模型组件。作为概念验证，我们将我们的方法应用于自动发现LLaMA-13B中分享的"变量绑定电路"，该电路为多个算术任务检索变量值。我们的方法成功地将变量绑定定位为仅有9个注意头（1600个中）和最终令牌的残余流中的一个MLP。

    Recent work has shown that computation in language models may be human-understandable, with successful efforts to localize and intervene on both single-unit features and input-output circuits. Here, we introduce an approach which extends causal mediation experiments to automatically identify model components responsible for performing a specific subtask by solely specifying a set of \textit{desiderata}, or causal attributes of the model components executing that subtask. As a proof of concept, we apply our method to automatically discover shared \textit{variable binding circuitry} in LLaMA-13B, which retrieves variable values for multiple arithmetic tasks. Our method successfully localizes variable binding to only 9 attention heads (of the 1.6k) and one MLP in the final token's residual stream.
    
[^12]: GEANN: 多视角时间序列预测的可扩展图增强

    GEANN: Scalable Graph Augmentations for Multi-Horizon Time Series Forecasting. (arXiv:2307.03595v1 [cs.LG])

    [http://arxiv.org/abs/2307.03595](http://arxiv.org/abs/2307.03595)

    本研究介绍了一种使用图神经网络 (GNNs) 作为数据增强来解决多视角时间序列预测中的“冷启动”问题的方法。这些GNN-based特征能够捕捉复杂的跨序列关系，并且可以与预测任务进行端到端的优化。

    

    编码器-解码器深度神经网络在多视角时间序列预测中得到了越来越多的研究，尤其是在实际应用中。然而，为了准确预测，这些复杂模型通常依赖于大量的具有丰富历史数据的时间序列示例。一个越来越受关注的研究主题是预测缺乏足够历史数据的时间序列，通常被称为“冷启动”问题。在本文中，我们引入了一种新颖而简单的方法来解决这个问题，通过利用图神经网络 (GNNs) 作为数据增强来增强这些预测器使用的编码器。这些基于GNN的特征能够捕捉复杂的跨序列关系，并且它们的生成过程可以与预测任务进行端到端的优化。我们展示了我们的架构可以使用数据驱动或基于领域知识定义的图，能够扩展到包含数百万节点的多个非常大的图的信息。

    Encoder-decoder deep neural networks have been increasingly studied for multi-horizon time series forecasting, especially in real-world applications. However, to forecast accurately, these sophisticated models typically rely on a large number of time series examples with substantial history. A rapidly growing topic of interest is forecasting time series which lack sufficient historical data -- often referred to as the ``cold start'' problem. In this paper, we introduce a novel yet simple method to address this problem by leveraging graph neural networks (GNNs) as a data augmentation for enhancing the encoder used by such forecasters. These GNN-based features can capture complex inter-series relationships, and their generation process can be optimized end-to-end with the forecasting task. We show that our architecture can use either data-driven or domain knowledge-defined graphs, scaling to incorporate information from multiple very large graphs with millions of nodes. In our target app
    
[^13]: VesselVAE: 递归变分自编码器用于3D血管合成

    VesselVAE: Recursive Variational Autoencoders for 3D Blood Vessel Synthesis. (arXiv:2307.03592v1 [cs.CV])

    [http://arxiv.org/abs/2307.03592](http://arxiv.org/abs/2307.03592)

    VesselVAE是一个递归变分自编码器，用于生成血管的3D几何形状，通过利用血管的层次组织结构和几何特征的低维流形编码，在合成数据和真实数据的半径、长度和扭曲度方面取得了相似性。

    

    我们提出了一个数据驱动的生成框架用于合成血管的3D几何形状。由于血管系统的形状、大小和结构高度变化，这是一项具有挑战性的任务。现有的基于模型的方法在生成的结构中提供了一定程度的控制和变化，但未能捕捉到实际解剖数据的多样性。我们开发了VesselVAE，一种递归变分神经网络，完全利用了血管的层次组织结构，并学习了描述目标表面的分支连接性以及几何特征的低维流形编码。经过训练，VesselVAE的潜在空间可以进行采样来生成新的血管几何形状。据我们所知，这项工作是首次利用这种技术来合成血管。我们实现了半径（.97）、长度（.95）和扭曲度（.96）的合成和真实数据的相似性。通过充分利用深度神经网络的能力，我们能够生成逼真的3D血管合成图像。

    We present a data-driven generative framework for synthesizing blood vessel 3D geometry. This is a challenging task due to the complexity of vascular systems, which are highly variating in shape, size, and structure. Existing model-based methods provide some degree of control and variation in the structures produced, but fail to capture the diversity of actual anatomical data. We developed VesselVAE, a recursive variational Neural Network that fully exploits the hierarchical organization of the vessel and learns a low-dimensional manifold encoding branch connectivity along with geometry features describing the target surface. After training, the VesselVAE latent space can be sampled to generate new vessel geometries. To the best of our knowledge, this work is the first to utilize this technique for synthesizing blood vessels. We achieve similarities of synthetic and real data for radius (.97), length (.95), and tortuosity (.96). By leveraging the power of deep neural networks, we gener
    
[^14]: 结构引导的多模态预训练Transformer用于知识图谱推理

    Structure Guided Multi-modal Pre-trained Transformer for Knowledge Graph Reasoning. (arXiv:2307.03591v1 [cs.AI])

    [http://arxiv.org/abs/2307.03591](http://arxiv.org/abs/2307.03591)

    本研究提出了一种图结构引导的多模态预训练Transformer用于知识图谱推理。当前的多模态预训练Transformer模型未能充分利用知识图谱的结构信息，限制了其推理性能。

    

    多模态知识图谱(MKGs)直观地组织了各种模式的信息，可以惠及多个实际的下游任务，如推荐系统和视觉问答。然而，大多数MKGs仍然远离完整，这促使了MKG推理模型的兴起。最近，随着通用人工架构的发展，预训练transformer模型引起了越来越多的关注，特别是对于多模态场景。然而，多模态预训练transformer (MPT)用于知识图推理 (KGR) 的研究仍处于早期阶段。作为MKG和其他多模态数据的最大区别，MKG中丰富的结构信息仍然无法在现有的MPT模型中充分利用。大多数模型只将图结构用作匹配与同一实体相连的图像和文本的检索映射。这种方式阻碍了它们的推理性能。为此，我们提出了图结构引导的多模态预训练Transformer用于知识图谱推理的方法。

    Multimodal knowledge graphs (MKGs), which intuitively organize information in various modalities, can benefit multiple practical downstream tasks, such as recommendation systems, and visual question answering. However, most MKGs are still far from complete, which motivates the flourishing of MKG reasoning models. Recently, with the development of general artificial architectures, the pretrained transformer models have drawn increasing attention, especially for multimodal scenarios. However, the research of multimodal pretrained transformer (MPT) for knowledge graph reasoning (KGR) is still at an early stage. As the biggest difference between MKG and other multimodal data, the rich structural information underlying the MKG still cannot be fully leveraged in existing MPT models. Most of them only utilize the graph structure as a retrieval map for matching images and texts connected with the same entity. This manner hinders their reasoning performances. To this end, we propose the graph S
    
[^15]: 多模态深度学习用于个性化肾细胞癌预后：整合CT成像和临床数据

    Multimodal Deep Learning for Personalized Renal Cell Carcinoma Prognosis: Integrating CT Imaging and Clinical Data. (arXiv:2307.03575v1 [cs.CV])

    [http://arxiv.org/abs/2307.03575](http://arxiv.org/abs/2307.03575)

    本研究通过综合CT成像和临床数据，设计了一个深度学习模型，可以预测肾细胞癌患者的生存概率，并辅助识别需要紧急治疗的患者。

    

    肾细胞癌是一个低生存率的重要全球健康挑战。本研究旨在设计一个综合的深度学习模型，通过整合CT成像和临床数据，解决以往研究中存在的限制，能够预测肾细胞癌患者的生存概率，以便辅助识别需要紧急治疗的患者。所提出的框架包括三个模块：3D图像特征提取器、临床变量选择和生存预测。基于3D CNN架构的特征提取器模块，通过CT图像预测与肾细胞癌病灶相关的死亡率的ISUP分级。通过使用Spearman分数和随机森林重要性分数作为标准，系统地选择一些临床变量。使用离散的LogisticHazard-based损失训练的基于深度学习的网络进行生存预测。进行了九个不同的实验。

    Renal cell carcinoma represents a significant global health challenge with a low survival rate. This research aimed to devise a comprehensive deep-learning model capable of predicting survival probabilities in patients with renal cell carcinoma by integrating CT imaging and clinical data and addressing the limitations observed in prior studies. The aim is to facilitate the identification of patients requiring urgent treatment. The proposed framework comprises three modules: a 3D image feature extractor, clinical variable selection, and survival prediction. The feature extractor module, based on the 3D CNN architecture, predicts the ISUP grade of renal cell carcinoma tumors linked to mortality rates from CT images. A selection of clinical variables is systematically chosen using the Spearman score and random forest importance score as criteria. A deep learning-based network, trained with discrete LogisticHazard-based loss, performs the survival prediction. Nine distinct experiments are 
    
[^16]: 大型语言模型作为一体化零-shot ESCO技能匹配器

    Large Language Models as Batteries-Included Zero-Shot ESCO Skills Matchers. (arXiv:2307.03539v1 [cs.CL])

    [http://arxiv.org/abs/2307.03539](http://arxiv.org/abs/2307.03539)

    这项工作提出了一个基于大型语言模型的零-shot技能提取系统，通过生成ESCO技能的合成训练数据和使用相似性检索器，实现了从职位描述中提取技能的目标。

    

    理解劳动力市场动态需要准确地识别劳动力所需的技能。越来越多的自动化技术被开发出来支持这个工作。然而，由于现有技能的数量庞大，从职位发布中自动提取技能是具有挑战性的。ESCO（欧洲技能、能力、资格和职业）框架提供了一个有用的参考，列出了超过13,000个独立的技能。然而，技能提取仍然困难，并且准确地将工作岗位与ESCO分类进行匹配是一个悬而未决的问题。在这项工作中，我们提出了一个基于大型语言模型（LLM）的零-shot技能提取系统。我们生成ESCO技能的合成训练数据，并训练一个分类器从职位发布中提取技能提及。我们还使用相似性检索器生成技能候选项，然后使用第二个LLM进行重新排序。使用合成数据实现了技能提取的良好效果。

    Understanding labour market dynamics requires accurately identifying the skills required for and possessed by the workforce. Automation techniques are increasingly being developed to support this effort. However, automatically extracting skills from job postings is challenging due to the vast number of existing skills. The ESCO (European Skills, Competences, Qualifications and Occupations) framework provides a useful reference, listing over 13,000 individual skills. However, skills extraction remains difficult and accurately matching job posts to the ESCO taxonomy is an open problem. In this work, we propose an end-to-end zero-shot system for skills extraction from job descriptions based on large language models (LLMs). We generate synthetic training data for the entirety of ESCO skills and train a classifier to extract skill mentions from job posts. We also employ a similarity retriever to generate skill candidates which are then re-ranked using a second LLM. Using synthetic data achi
    
[^17]: 利用传输学习方法在LiDAR数据上识别埋藏的考古结构的语义分割研究

    Tranfer Learning of Semantic Segmentation Methods for Identifying Buried Archaeological Structures on LiDAR Data. (arXiv:2307.03512v1 [cs.CV])

    [http://arxiv.org/abs/2307.03512](http://arxiv.org/abs/2307.03512)

    本文研究了利用传输学习方法在LiDAR数据上识别埋藏的考古结构的语义分割。实验结果表明，传输学习的应用可以提高性能，为未来工作提供基准。

    

    当将深度学习应用于考古研究中的遥感数据时，一个显著的障碍是适用于模型训练的合适数据集的有限可用性。传输学习的应用经常被用来减轻这个缺点。然而，仍有必要探索在不同考古数据集上应用传输学习的有效性。本文比较了使用两个语义分割深度神经网络在两个LiDAR数据集上的各种传输学习配置的性能。实验结果表明，基于传输学习的方法在考古学中可以提高性能，尽管尚未观察到系统性的改进。我们提供了关于此类技术有效性的具体见解，可作为未来工作的基准。

    When applying deep learning to remote sensing data in archaeological research, a notable obstacle is the limited availability of suitable datasets for training models. The application of transfer learning is frequently employed to mitigate this drawback. However, there is still a need to explore its effectiveness when applied across different archaeological datasets. This paper compares the performance of various transfer learning configurations using two semantic segmentation deep neural networks on two LiDAR datasets. The experimental results indicate that transfer learning-based approaches in archaeology can lead to performance improvements, although a systematic enhancement has not yet been observed. We provide specific insights about the validity of such techniques that can serve as a baseline for future works.
    
[^18]: 无导数的权重空间集成

    Derivative Free Weight-space Ensembling. (arXiv:2307.03506v1 [cs.CL])

    [http://arxiv.org/abs/2307.03506](http://arxiv.org/abs/2307.03506)

    本文引入了一种新的无导数权重空间集成方法（DFWE），用于开放域对话的少样本任务传递。通过在几个不同的知识库的角度上对专家模型进行微调，并使用无梯度优化算法进行线性插值，我们有效地找到了一个好的模型权重插值，从而在FETA-Friends上超过了标准的预训练-微调方法。

    

    最近的研究表明，在两个专门的语言模型的权重之间插值可以在任务之间传递知识，但很少有人探索在两个以上模型之间插值，每个模型都有一个不同的知识库。在本文中，我们引入了一种新的无导数权重空间集成方法（DFWE），用于开放域对话的少样本任务传递。我们的框架创建了一组多样化的专家语言模型，这些模型是使用预定义的一组源任务进行训练的。接下来，我们对每个专家模型在目标任务上进行微调，从几个不同的知识库的角度来处理目标任务。最后，我们使用无梯度优化算法在模型权重之间进行线性插值，以高效地找到一个好的插值权重。我们在FETA-Friends上展示了该方法的有效性，优于标准的预训练-微调方法。

    Recent work suggests that interpolating between the weights of two specialized language models can transfer knowledge between tasks in a way that multi-task learning cannot. However, very few have explored interpolation between more than two models, where each has a distinct knowledge base. In this paper, we introduce Derivative Free Weight-space Ensembling (DFWE), a new few-sample task transfer approach for open-domain dialogue. Our framework creates a set of diverse expert language models trained using a predefined set of source tasks. Next, we finetune each of the expert models on the target task, approaching the target task from several distinct knowledge bases. Finally, we linearly interpolate between the model weights using a gradient-free-optimization algorithm, to efficiently find a good interpolation weighting. We demonstrate the effectiveness of the method on FETA-Friends outperforming the standard pretrain-finetune approach.
    
[^19]: RCDN -- 基于先进CNN模型的鲁棒X角点检测算法

    RCDN -- Robust X-Corner Detection Algorithm based on Advanced CNN Model. (arXiv:2307.03505v1 [cs.CV])

    [http://arxiv.org/abs/2307.03505](http://arxiv.org/abs/2307.03505)

    本研究提出了一种新颖的鲁棒X角点检测算法，能够在多种干扰下保持高亚像素精度，并采用了粗到细的策略和多种后处理技术来提高检测性能和准确度。

    

    准确检测和定位平面和非平面模式上的X角点是机器人和机器视觉中的核心步骤。然而，先前的工作在准确性和鲁棒性之间无法达到良好的平衡，这两个标准都是评估检测器性能的关键要素。为了解决这个问题，本文提出了一种新颖的检测算法，可以在多种干扰下保持对输入的高亚像素精度，例如镜头畸变、极端姿态和噪声。整个算法采用从粗到细的策略，包括X角点检测网络和三个后处理技术来区分正确的角点候选，以及混合亚像素细化技术和改进的区域增长策略来自动恢复部分可见或遮挡的棋盘格纹样。对真实和合成图像的评估结果表明，所提出的算法具有比先前方法更高的检测率、亚像素精度和鲁棒性。

    Accurate detection and localization of X-corner on both planar and non-planar patterns is a core step in robotics and machine vision. However, previous works could not make a good balance between accuracy and robustness, which are both crucial criteria to evaluate the detectors performance. To address this problem, in this paper we present a novel detection algorithm which can maintain high sub-pixel precision on inputs under multiple interference, such as lens distortion, extreme poses and noise. The whole algorithm, adopting a coarse-to-fine strategy, contains a X-corner detection network and three post-processing techniques to distinguish the correct corner candidates, as well as a mixed sub-pixel refinement technique and an improved region growth strategy to recover the checkerboard pattern partially visible or occluded automatically. Evaluations on real and synthetic images indicate that the presented algorithm has the higher detection rate, sub-pixel accuracy and robustness than 
    
[^20]: 基于大型AI模型的语义通信

    Large AI Model-Based Semantic Communications. (arXiv:2307.03492v1 [cs.AI])

    [http://arxiv.org/abs/2307.03492](http://arxiv.org/abs/2307.03492)

    本文提出了一种基于大型AI模型的语义通信框架（LAM-SC），利用该框架可以克服知识库构建过程中面临的问题，并在图像数据领域实现了语义分割、语义集成和自适应语义压缩。

    

    语义通信（SC）是一种新兴的智能范式，为元宇宙、混合现实和万物互联等未来应用提供解决方案。然而，在目前的SC系统中，知识库（KB）的构建面临着一些问题，包括知识表示有限、频繁的知识更新和不安全的知识共享。幸运的是，大型AI模型的发展提供了解决上述问题的新方案。在这里，我们提出了一种基于大型AI模型的SC框架（LAM-SC），专门用于图像数据，我们首先设计了基于段落模型（SAM）的知识库（SKB），它可以通过通用语义知识将原始图像划分为不同的语义段落。然后，我们提出了一种基于注意力的语义集成（ASI），通过权衡由SKB生成的语义段落，无需人工参与并将它们集成为具有语义感知的图像。此外，我们还提出了一种自适应语义压缩（ASC）方法。

    Semantic communication (SC) is an emerging intelligent paradigm, offering solutions for various future applications like metaverse, mixed-reality, and the Internet of everything. However, in current SC systems, the construction of the knowledge base (KB) faces several issues, including limited knowledge representation, frequent knowledge updates, and insecure knowledge sharing. Fortunately, the development of the large AI model provides new solutions to overcome above issues. Here, we propose a large AI model-based SC framework (LAM-SC) specifically designed for image data, where we first design the segment anything model (SAM)-based KB (SKB) that can split the original image into different semantic segments by universal semantic knowledge. Then, we present an attention-based semantic integration (ASI) to weigh the semantic segments generated by SKB without human participation and integrate them as the semantic-aware image. Additionally, we propose an adaptive semantic compression (ASC
    
[^21]: 通过对比学习在强化学习中发现层次化成就

    Discovering Hierarchical Achievements in Reinforcement Learning via Contrastive Learning. (arXiv:2307.03486v1 [cs.LG])

    [http://arxiv.org/abs/2307.03486](http://arxiv.org/abs/2307.03486)

    通过对比学习方法，我们在强化学习中提出了新的成就蒸馏方法，可以加强代理对下一个解锁成就的预测能力，并优于先前的模型驱动和层次化方法。

    

    在生成环境中发现具有层次结构的成就是一个重大挑战。这需要智能体具备广泛的能力，包括泛化和长期推理。许多先前的方法基于模型驱动或层次化方法，认为显式的长期规划模块对于学习层次化成就是有益的。然而，这些方法需要大量的环境交互或大型模型，限制了它们的实用性。在这项工作中，我们发现近期实施实践中的近端策略优化（PPO）算法优于先前的方法。此外，我们发现PPO智能体可以在一定程度上预测下一个要解锁的成就，尽管预测的置信度较低。基于这一观察，我们提出了一种新颖的对比学习方法，称为成就蒸馏，可以加强PPO智能体对下一个解锁成就的预测能力。

    Discovering achievements with a hierarchical structure on procedurally generated environments poses a significant challenge. This requires agents to possess a broad range of abilities, including generalization and long-term reasoning. Many prior methods are built upon model-based or hierarchical approaches, with the belief that an explicit module for long-term planning would be beneficial for learning hierarchical achievements. However, these methods require an excessive amount of environment interactions or large model sizes, limiting their practicality. In this work, we identify that proximal policy optimization (PPO), a simple and versatile model-free algorithm, outperforms the prior methods with recent implementation practices. Moreover, we find that the PPO agent can predict the next achievement to be unlocked to some extent, though with low confidence. Based on this observation, we propose a novel contrastive learning method, called achievement distillation, that strengthens the 
    
[^22]: TBGC: 多任务基础模型学习的任务级骨干导向梯度截断

    TBGC: Task-level Backbone-Oriented Gradient Clip for Multi-Task Foundation Model Learning. (arXiv:2307.03465v1 [cs.CV])

    [http://arxiv.org/abs/2307.03465](http://arxiv.org/abs/2307.03465)

    提出了任务级骨干导向梯度截断范式，通过独立的梯度截断和统一的范数缩放，有效缓解了多任务学习中的梯度偏向问题。

    

    AllInOne训练范式以多任务学习方式将各种任务集中到统一模型中。然而，多任务学习中的优化比单任务学习更具挑战性，因为不同任务的梯度范数可能差异很大，使得骨干过分偏向某个特定任务。为了解决这个问题，我们提出了任务级骨干导向梯度截断范式，与普通的梯度截断方法相比，它有两个重点：1）对每个任务独立进行梯度截断；2）从每个任务生成的骨干梯度重新缩放到相同的范数尺度。根据实验结果，我们认为任务级骨干导向梯度截断范式在一定程度上可以缓解梯度偏向问题。我们还提出了一种新颖的多分支数据增强策略，在不同分支中放置冲突增强。我们的方法被证明是有效的，并最终在比赛中获得第一名。

    The AllInOne training paradigm squeezes a wide range of tasks into a unified model in a multi-task learning manner. However, optimization in multi-task learning is more challenge than single-task learning, as the gradient norm from different tasks may vary greatly, making the backbone overly biased towards one specific task. To address this issue, we propose the task-level backbone-oriented gradient clip paradigm, compared with the vanilla gradient clip method, it has two points of emphasis:1) gradient clip is performed independently for each task. 2) backbone gradients generated from each task are rescaled to the same norm scale. Based on the experimental results, we argue that the task-level backbone-oriented gradient clip paradigm can relieve the gradient bias problem to some extent. We also propose a novel multi-branch data augmentation strategy where conflict augmentations are placed in different branches. Our approach has been shown to be effective and finally achieve 1st place i
    
[^23]: 从网络到网络的深度网络隐写术

    Towards Deep Network Steganography: From Networks to Networks. (arXiv:2307.03444v1 [cs.CR])

    [http://arxiv.org/abs/2307.03444](http://arxiv.org/abs/2307.03444)

    本论文提出了一种新的深度网络隐写术，通过将秘密DNN模型伪装成另一个普通学习任务的隐写DNN模型，实现了DNN模型的秘密传输。

    

    随着深度神经网络(DNN)的广泛应用，如何在公共信道中秘密传输DNN模型引起了我们的关注，特别是针对那些用于秘密学习任务的模型。本文提出了一种用于DNN模型秘密传输的深度网络隐写术。与现有的隐写方案不同，其重点是通过对封面数据进行细微修改以适应秘密，我们的方案是以学习任务为导向的，将秘密DNN模型(称为秘密学习任务)伪装成另一个在隐写DNN模型(称为隐写学习任务)中进行的普通学习任务。为此，我们提出了一种基于梯度的滤波器插入方案，将干扰滤波器插入到秘密DNN模型的重要位置，形成一个隐写DNN模型。然后，我们使用密钥和附加信息隐藏将这些位置嵌入到隐写DNN模型中。最后，通过部分优化激活干扰滤波器。

    With the widespread applications of the deep neural network (DNN), how to covertly transmit the DNN models in public channels brings us the attention, especially for those trained for secret-learning tasks. In this paper, we propose deep network steganography for the covert communication of DNN models. Unlike the existing steganography schemes which focus on the subtle modification of the cover data to accommodate the secrets, our scheme is learning task oriented, where the learning task of the secret DNN model (termed as secret-learning task) is disguised into another ordinary learning task conducted in a stego DNN model (termed as stego-learning task). To this end, we propose a gradient-based filter insertion scheme to insert interference filters into the important positions in the secret DNN model to form a stego DNN model. These positions are then embedded into the stego DNN model using a key by side information hiding. Finally, we activate the interference filters by a partial opt
    
[^24]: 非迭代的粗到细变换网络用于联合仿射和可变形图像配准

    Non-iterative Coarse-to-fine Transformer Networks for Joint Affine and Deformable Image Registration. (arXiv:2307.03421v1 [cs.CV])

    [http://arxiv.org/abs/2307.03421](http://arxiv.org/abs/2307.03421)

    本论文提出了一种非迭代的粗到细变换网络，用于联合仿射和可变形图像配准。与现有方法相比，该方法能够在单个网络中实现粗到细配准，并在配准精度和运行时间方面具有优势。

    

    图像配准是医学图像分析的基本要求。基于深度学习的深度配准方法因其能够进行快速的端到端配准而被广泛认可。许多深度配准方法通过迭代多个具有级联网络的配准步骤来实现粗到细配准，已实现了最先进的性能。最近，提出了非迭代的粗到细配准（NICE）方法，能够在单个网络中进行粗到细配准，并显示出配准精度和运行时间的优势。然而，现有的NICE配准方法主要侧重于可变形配准，而仿射配准作为常见的前提条件仍然依赖耗时的传统基于优化的方法或额外的仿射配准网络。此外，现有的NICE配准方法受到卷积操作本地性的局限性。表示可能解决这个问题。

    Image registration is a fundamental requirement for medical image analysis. Deep registration methods based on deep learning have been widely recognized for their capabilities to perform fast end-to-end registration. Many deep registration methods achieved state-of-the-art performance by performing coarse-to-fine registration, where multiple registration steps were iterated with cascaded networks. Recently, Non-Iterative Coarse-to-finE (NICE) registration methods have been proposed to perform coarse-to-fine registration in a single network and showed advantages in both registration accuracy and runtime. However, existing NICE registration methods mainly focus on deformable registration, while affine registration, a common prerequisite, is still reliant on time-consuming traditional optimization-based methods or extra affine registration networks. In addition, existing NICE registration methods are limited by the intrinsic locality of convolution operations. Transformers may address thi
    
[^25]: QI2 -- 一个用于数据质量保证的交互工具

    QI2 -- an Interactive Tool for Data Quality Assurance. (arXiv:2307.03419v1 [cs.CY])

    [http://arxiv.org/abs/2307.03419](http://arxiv.org/abs/2307.03419)

    本文介绍了一种用于数据质量保证的交互工具QI2，该工具支持对多个数据质量方面的验证和定量数据质量要求的验证。通过在MNIST数据集上进行演示，展示了该方法的应用和优势。

    

    高数据质量的重要性随着机器学习系统和大数据的增长影响和分布而增加。此外，欧洲委员会计划的AI法案为数据质量定义了具有挑战性的法律要求，特别是对于市场推出与安全相关的机器学习系统。本文介绍了一种支持多个数据质量方面的数据质量保证过程的新方法。这种方法可以验证定量数据质量要求。通过小例子数据集介绍和解释了该概念和优势。如何应用该方法在基于手写数字的知名MNIST数据集上进行了演示。

    The importance of high data quality is increasing with the growing impact and distribution of ML systems and big data. Also the planned AI Act from the European commission defines challenging legal requirements for data quality especially for the market introduction of safety relevant ML systems. In this paper we introduce a novel approach that supports the data quality assurance process of multiple data quality aspects. This approach enables the verification of quantitative data quality requirements. The concept and benefits are introduced and explained on small example data sets. How the method is applied is demonstrated on the well known MNIST data set based an handwritten digits.
    
[^26]: 使用目标条件预测编码作为离线强化学习的隐式规划器

    Goal-Conditioned Predictive Coding as an Implicit Planner for Offline Reinforcement Learning. (arXiv:2307.03406v1 [cs.LG])

    [http://arxiv.org/abs/2307.03406](http://arxiv.org/abs/2307.03406)

    本论文研究了将决策制定视为离线收集的轨迹的监督学习问题，并探究了序列建模在轨迹压缩和策略学习中的作用。通过引入目标条件预测编码（GCPC），本文提出了一种能够产生强大轨迹表示并实现高性能策略的方法。

    

    最近的研究已经证明了将决策制定视为离线收集的轨迹的监督学习问题的有效性。然而，在轨迹数据上进行序列建模的好处尚不清楚。在这项工作中，我们研究了序列建模是否具备将轨迹压缩为有用表示并对策略学习有所贡献的能力。为了实现这一目标，我们采用了一个两阶段的框架，首先使用序列建模技术总结轨迹，然后利用这些表示学习策略以及一个期望的目标。这个设计使得许多现有的监督式离线强化学习方法可以被看作是我们框架的特例。在这个框架内，我们引入了目标条件预测编码（GCPC），这是一种带来强大轨迹表示并导致高性能策略的方法。我们在AntMaze，FrankaKitchen和Locomotion环境上进行了广泛的实证评估，并观察到...

    Recent work has demonstrated the effectiveness of formulating decision making as a supervised learning problem on offline-collected trajectories. However, the benefits of performing sequence modeling on trajectory data is not yet clear. In this work we investigate if sequence modeling has the capability to condense trajectories into useful representations that can contribute to policy learning. To achieve this, we adopt a two-stage framework that first summarizes trajectories with sequence modeling techniques, and then employs these representations to learn a policy along with a desired goal. This design allows many existing supervised offline RL methods to be considered as specific instances of our framework. Within this framework, we introduce Goal-Conditioned Predicitve Coding (GCPC), an approach that brings powerful trajectory representations and leads to performant policies. We conduct extensive empirical evaluations on AntMaze, FrankaKitchen and Locomotion environments, and obser
    
[^27]: 探索大规模语言模型（LLMs）在图学习中的潜力

    Exploring the Potential of Large Language Models (LLMs) in Learning on Graphs. (arXiv:2307.03393v1 [cs.LG])

    [http://arxiv.org/abs/2307.03393](http://arxiv.org/abs/2307.03393)

    本文探索了大规模语言模型（LLMs）在图学习中的潜力，并尝试了两种不同的流程：将LLMs作为增强器通过海量知识来增强节点的文本属性，并使用图神经网络（GNNs）生成预测，以及直接使用LLMs作为独立的预测器。

    

    图学习因其广泛的现实世界应用而引起了极大的关注。以文本节点属性为主的图学习最流行的流程主要依赖于图神经网络（GNN），并利用浅层文本嵌入作为初始节点表示，但存在通用知识和深刻语义理解方面的限制。近年来，大规模语言模型（LLMs）被证明具有广泛的常识和强大的语义理解能力，已经颠覆了现有的处理文本数据的工作流程。在本文中，我们旨在探索LLMs在图机器学习中的潜力，特别是节点分类任务，并研究两种可能的流程：LLMs作为增强器和LLMs作为预测器。前者利用LLMs通过其海量知识增强节点的文本属性，然后通过GNNs生成预测。后者试图直接使用LLMs作为独立的预测器。

    Learning on Graphs has attracted immense attention due to its wide real-world applications. The most popular pipeline for learning on graphs with textual node attributes primarily relies on Graph Neural Networks (GNNs), and utilizes shallow text embedding as initial node representations, which has limitations in general knowledge and profound semantic understanding. In recent years, Large Language Models (LLMs) have been proven to possess extensive common knowledge and powerful semantic comprehension abilities that have revolutionized existing workflows to handle text data. In this paper, we aim to explore the potential of LLMs in graph machine learning, especially the node classification task, and investigate two possible pipelines: LLMs-as-Enhancers and LLMs-as-Predictors. The former leverages LLMs to enhance nodes' text attributes with their massive knowledge and then generate predictions through GNNs. The latter attempts to directly employ LLMs as standalone predictors. We conduct 
    
[^28]: 关于形式特征归因及其近似方法

    On Formal Feature Attribution and Its Approximation. (arXiv:2307.03380v1 [cs.AI])

    [http://arxiv.org/abs/2307.03380](http://arxiv.org/abs/2307.03380)

    这篇论文研究了解释性人工智能（XAI）中的形式特征归因方法及其近似方法。现有的特征选择和归因方法存在一些问题，而形式化的XAI方法虽然是一个有希望的解决方案，但仍存在一些限制。

    

    近年来，人工智能（AI）算法和机器学习（ML）模型得到了广泛应用。尽管取得了巨大成功，但ML模型脆弱性，公平性以及解释性的缺乏等重要问题需要积极发展可解释的人工智能（XAI）和形式化的ML模型验证。XAI的两个主要研究方向包括特征选择方法（例如，Anchors）和特征归因技术（例如，LIME和SHAP）。尽管有希望，但大多数现有的特征选择和归因方法都容易出现一系列关键问题，包括解释不正确和超出分布采样。近期一种形式化的XAI方法（FXAI）虽然作为以上方法的替代品并避免了这些问题，但仍存在一些限制。例如，除了可扩展性限制外，这种形式化方法无法解决特征归因问题。

    Recent years have witnessed the widespread use of artificial intelligence (AI) algorithms and machine learning (ML) models. Despite their tremendous success, a number of vital problems like ML model brittleness, their fairness, and the lack of interpretability warrant the need for the active developments in explainable artificial intelligence (XAI) and formal ML model verification. The two major lines of work in XAI include feature selection methods, e.g. Anchors, and feature attribution techniques, e.g. LIME and SHAP. Despite their promise, most of the existing feature selection and attribution approaches are susceptible to a range of critical issues, including explanation unsoundness and out-of-distribution sampling. A recent formal approach to XAI (FXAI) although serving as an alternative to the above and free of these issues suffers from a few other limitations. For instance and besides the scalability limitation, the formal approach is unable to tackle the feature attribution prob
    
[^29]: 游戏AI中高效的地面车辆路径跟随方案

    Efficient Ground Vehicle Path Following in Game AI. (arXiv:2307.03379v1 [cs.AI])

    [http://arxiv.org/abs/2307.03379](http://arxiv.org/abs/2307.03379)

    本文介绍了一种专为游戏AI设计的高效路径跟随解决方案，通过调整已有技术，设计出具有可调参数的简单解决方案，并通过测试场景验证了其在不同类型路径和车辆上的效果和稳健性，在总卡住事件数量上取得了70%的减少。

    

    本文介绍了一种专为游戏AI设计的高效路径跟随解决方案。我们重点是通过调整已建立的技术，设计出具有可调参数、高效的基准路径跟随器的简单解决方案。我们的解决方案特别关注计算目标速度，使用二次贝塞尔曲线来估计路径曲率。通过在第一人称射击游戏中进行各种测试场景，评估了所提出的路径跟随器的性能，展示了其在处理不同类型的路径和车辆时的效果和稳健性。与现有路径跟随解决方案相比，我们实现了总卡住事件数量减少70%的效果。

    This short paper presents an efficient path following solution for ground vehicles tailored to game AI. Our focus is on adapting established techniques to design simple solutions with parameters that are easily tunable for an efficient benchmark path follower. Our solution pays particular attention to computing a target speed which uses quadratic Bezier curves to estimate the path curvature. The performance of the proposed path follower is evaluated through a variety of test scenarios in a first-person shooter game, demonstrating its effectiveness and robustness in handling different types of paths and vehicles. We achieved a 70% decrease in the total number of stuck events compared to an existing path following solution.
    
[^30]: 一体化视觉-语言跟踪的探索：多模态对齐

    All in One: Exploring Unified Vision-Language Tracking with Multi-Modal Alignment. (arXiv:2307.03373v1 [cs.CV])

    [http://arxiv.org/abs/2307.03373](http://arxiv.org/abs/2307.03373)

    本文提出了一种一体化视觉-语言跟踪框架，采用统一的Transformer主干网络，实现联合特征提取和交互，提高了在复杂场景下的目标感知能力。

    

    当前主流的视觉-语言跟踪框架包括三个部分，即视觉特征提取器、语言特征提取器和融合模型。为了追求更好的性能，视觉-语言跟踪常常使用定制和更重的单模态编码器和多模态融合模型。尽管有效，现有的视觉-语言跟踪器将特征提取和特征集成分开，导致提取的特征缺乏语义引导，在复杂场景下具有有限的目标感知能力，例如相似的干扰物和极端光照。在这项研究中，受到近期在自然语言和计算机视觉任务中统一架构探索的成功启发，我们提出了一种一体化框架，通过采用统一的Transformer主干网络来学习联合特征提取和交互。具体而言，我们混合原始的视觉和语言信号来生成注入语言的视觉单元，然后将它们连接起来。

    Current mainstream vision-language (VL) tracking framework consists of three parts, \ie a visual feature extractor, a language feature extractor, and a fusion model. To pursue better performance, a natural modus operandi for VL tracking is employing customized and heavier unimodal encoders, and multi-modal fusion models. Albeit effective, existing VL trackers separate feature extraction and feature integration, resulting in extracted features that lack semantic guidance and have limited target-aware capability in complex scenarios, \eg similar distractors and extreme illumination. In this work, inspired by the recent success of exploring foundation models with unified architecture for both natural language and computer vision tasks, we propose an All-in-One framework, which learns joint feature extraction and interaction by adopting a unified transformer backbone. Specifically, we mix raw vision and language signals to generate language-injected vision tokens, which we then concatenate
    
[^31]: 人机合作中的适应性和沟通：处理代理关于计划的信念差异

    Adaptation and Communication in Human-Robot Teaming to Handle Discrepancies in Agents' Beliefs about Plans. (arXiv:2307.03362v1 [cs.AI])

    [http://arxiv.org/abs/2307.03362](http://arxiv.org/abs/2307.03362)

    本文研究人机合作中的适应性和沟通，以处理代理之间关于计划的信念差异，通过利用认知逻辑来理解和解决这些差异。

    

    当代理共同合作完成任务时，拥有一些共享的任务流程的心理模型非常重要，这些流程是实现目标的可行计划的集合。然而，实际情况经常出现这样的情况，即无法保证存在这样的共享心理模型，比如在临时团队中代理可能遵循不同的约定，或者当出现只有部分代理知晓的临时约束时。以前关于人机合作的研究假设团队拥有一组共享的流程，而在这些情况下这种假设不成立。在这项工作中，我们利用认知逻辑使代理能够理解彼此关于可行计划的信念差异，并动态规划他们的行动来适应或沟通以解决差异。我们提出了一个扩展了条件信念逻辑的形式，以描述知识库，从而明确表示代理对可行计划和执行状态的嵌套信念。我们提供了一个在线执行算法。

    When agents collaborate on a task, it is important that they have some shared mental model of the task routines -- the set of feasible plans towards achieving the goals. However, in reality, situations often arise that such a shared mental model cannot be guaranteed, such as in ad-hoc teams where agents may follow different conventions or when contingent constraints arise that only some agents are aware of. Previous work on human-robot teaming has assumed that the team has a set of shared routines, which breaks down in these situations. In this work, we leverage epistemic logic to enable agents to understand the discrepancy in each other's beliefs about feasible plans and dynamically plan their actions to adapt or communicate to resolve the discrepancy. We propose a formalism that extends conditional doxastic logic to describe knowledge bases in order to explicitly represent agents' nested beliefs on the feasible plans and state of execution. We provide an online execution algorithm ba
    
[^32]: 在交叉问答背景下评估语言模型中的偏见态度关联

    Evaluating Biased Attitude Associations of Language Models in an Intersectional Context. (arXiv:2307.03360v1 [cs.CY])

    [http://arxiv.org/abs/2307.03360](http://arxiv.org/abs/2307.03360)

    这篇论文以已建立的文献为基础，量化了英语语言模型中社会群体的情绪关联，并发现语言模型对性别认同、社会阶级和性取向的信号表现出最大的偏见态度。

    

    语言模型是在大规模语料库上训练的，这些语料库中嵌入了心理学中已经记录的隐含偏见。社会群体的情绪关联（愉快/不愉快）决定了社会认知中对群体和概念的偏见态度。在此基础上，我们通过提供一个交叉问答背景的句子模板，量化了英语语言模型中社会群体的情绪关联。我们研究了与年龄、教育、性别、身高、智力、文化素养、种族、宗教、性别、性取向、社会阶级和体重有关的偏见。我们采用概念投影方法通过语言模型的上下文化词向量捕捉情绪关联的子空间。将基于投影的方法调整为量化偏见的嵌入关联测试，我们发现语言模型对性别认同、社会阶级和性取向的信号表现出最大的偏见态度。我们发现最大和表现最好的模型是...

    Language models are trained on large-scale corpora that embed implicit biases documented in psychology. Valence associations (pleasantness/unpleasantness) of social groups determine the biased attitudes towards groups and concepts in social cognition. Building on this established literature, we quantify how social groups are valenced in English language models using a sentence template that provides an intersectional context. We study biases related to age, education, gender, height, intelligence, literacy, race, religion, sex, sexual orientation, social class, and weight. We present a concept projection approach to capture the valence subspace through contextualized word embeddings of language models. Adapting the projection-based approach to embedding association tests that quantify bias, we find that language models exhibit the most biased attitudes against gender identity, social class, and sexual orientation signals in language. We find that the largest and better-performing model
    
[^33]: 通过解缠的潜在表示辅助临床决策以获取可用治疗

    Assisting Clinical Decisions for Scarcely Available Treatment via Disentangled Latent Representation. (arXiv:2307.03315v1 [cs.LG])

    [http://arxiv.org/abs/2307.03315](http://arxiv.org/abs/2307.03315)

    通过解决体外膜肺氧合(ECMO)治疗选择偏差和稀缺治疗案例的挑战，我们提出了一种名为Treatment Variational AutoEncoder (TVAE)的方法，用于个体化治疗分析，以支持临床决策。

    

    体外膜肺氧合(ECMO)是对于COVID-19患者的重要的生命支持方式，这些患者对传统治疗方法无效。然而，对于这种稀缺且技术复杂的治疗选择，适当的治疗决策一直备受争议，对于谁会从中受益仍然存在争议。为了支持临床决策，预测治疗需求和潜在的治疗与非治疗反应是至关重要的。针对这一临床挑战，我们提出了Treatment Variational AutoEncoder (TVAE)，一种用于个体化治疗分析的新方法。TVAE专门设计来解决像ECMO这样具有强烈治疗选择偏差和治疗案例稀缺的建模挑战。TVAE将治疗决策视为一个多尺度问题。我们将患者的潜在治疗分配以及事实和反事实结果作为他们固有特征的一部分进行建模，这些特征可以被表征，

    Extracorporeal membrane oxygenation (ECMO) is an essential life-supporting modality for COVID-19 patients who are refractory to conventional therapies. However, the proper treatment decision has been the subject of significant debate and it remains controversial about who benefits from this scarcely available and technically complex treatment option. To support clinical decisions, it is a critical need to predict the treatment need and the potential treatment and no-treatment responses. Targeting this clinical challenge, we propose Treatment Variational AutoEncoder (TVAE), a novel approach for individualized treatment analysis. TVAE is specifically designed to address the modeling challenges like ECMO with strong treatment selection bias and scarce treatment cases. TVAE conceptualizes the treatment decision as a multi-scale problem. We model a patient's potential treatment assignment and the factual and counterfactual outcomes as part of their intrinsic characteristics that can be repr
    
[^34]: 关于球面谐波表示的不变性、等变性、相关性和卷积的标量和矢量数据论文

    On Invariance, Equivariance, Correlation and Convolution of Spherical Harmonic Representations for Scalar and Vectorial Data. (arXiv:2307.03311v1 [cs.LG])

    [http://arxiv.org/abs/2307.03311](http://arxiv.org/abs/2307.03311)

    这篇论文介绍了球面谐波表示的理论基础和实际应用，包括旋转不变和等变特征，以及球面上信号的卷积和精确相关性。此外，还将这些方法推广到了矢量谐波表示。

    

    最近，球面谐波（SH）域中的数据数学表示方法在机器学习界重新引起了越来越多的关注。本技术报告对SH表示的理论基础和实际实现进行了深入介绍，总结了关于旋转不变和等变特征以及球面上信号的卷积和精确相关性的工作。此外，这些方法从标量SH表示扩展到矢量谐波（VH），为球面上的3D矢量场提供相同的功能

    The mathematical representations of data in the Spherical Harmonic (SH) domain has recently regained increasing interest in the machine learning community. This technical report gives an in-depth introduction to the theoretical foundation and practical implementation of SH representations, summarizing works on rotation invariant and equivariant features, as well as convolutions and exact correlations of signals on spheres. In extension, these methods are then generalized from scalar SH representations to Vectorial Harmonics (VH), providing the same capabilities for 3d vector fields on spheres
    
[^35]: 使用前softmax分数的归属方法的一个漏洞

    A Vulnerability of Attribution Methods Using Pre-Softmax Scores. (arXiv:2307.03305v1 [cs.LG])

    [http://arxiv.org/abs/2307.03305](http://arxiv.org/abs/2307.03305)

    这篇论文讨论了使用前softmax分数的归属方法的一个漏洞，该方法用于解释卷积神经网络分类器输出。与对抗性攻击不同，作者关注的是对归属方法进行小修改可能导致的影响，而不会改变模型的输出。

    

    我们讨论了一类用于解释卷积神经网络分类器输出的归属方法的一个漏洞。已知这种类型的网络容易受到对抗性攻击的影响，即输入的微小扰动可能会改变模型的输出。与此不同的是，我们关注的是对归属方法进行小修改可能导致的影响，而不会改变模型的输出。

    We discuss a vulnerability involving a category of attribution methods used to provide explanations for the outputs of convolutional neural networks working as classifiers. It is known that this type of networks are vulnerable to adversarial attacks, in which imperceptible perturbations of the input may alter the outputs of the model. In contrast, here we focus on effects that small modifications in the model may cause on the attribution method without altering the model outputs.
    
[^36]: 不是性暗示，是教育。在TikTok视频中分离性教育和暗示性内容。

    It is not Sexually Suggestive, It is Educative. Separating Sex Education from Suggestive Content on TikTok Videos. (arXiv:2307.03274v1 [cs.CV])

    [http://arxiv.org/abs/2307.03274](http://arxiv.org/abs/2307.03274)

    在TikTok视频中，我们引入了一个名为SexTok的数据集，用于区分性暗示内容和虚拟性教育视频。我们发现这是一个具有挑战性但可学习的任务。

    

    我们引入了一个名为SexTok的多模式数据集，其中包含被标记为性暗示（从注释者的角度来看），性教育内容或两者都不是的TikTok视频。这样的数据集是为了解决在TikTok上区分性暗示内容和虚拟性教育视频的挑战。儿童接触性暗示的视频已被证明对他们的发展有不利影响。与此同时，对于LGBTQIA+社区更相关的虚拟性教育非常有价值。平台的当前系统删除或惩罚这两种类型的视频，尽管它们有不同的目的。我们的数据集包含视频URL，并且还有音频转录。为了验证其重要性，我们探索了两个基于转换器的模型来对视频进行分类。我们的初步结果表明区分这些类型的视频是可学习但具有挑战性的任务。这些实验表明...

    We introduce SexTok, a multi-modal dataset composed of TikTok videos labeled as sexually suggestive (from the annotator's point of view), sex-educational content, or neither. Such a dataset is necessary to address the challenge of distinguishing between sexually suggestive content and virtual sex education videos on TikTok. Children's exposure to sexually suggestive videos has been shown to have adversarial effects on their development. Meanwhile, virtual sex education, especially on subjects that are more relevant to the LGBTQIA+ community, is very valuable. The platform's current system removes or penalizes some of both types of videos, even though they serve different purposes. Our dataset contains video URLs, and it is also audio transcribed. To validate its importance, we explore two transformer-based models for classifying the videos. Our preliminary results suggest that the task of distinguishing between these types of videos is learnable but challenging. These experiments sugge
    
[^37]: 视觉语言转换器：一项调查

    Vision Language Transformers: A Survey. (arXiv:2307.03254v1 [cs.CV])

    [http://arxiv.org/abs/2307.03254](http://arxiv.org/abs/2307.03254)

    视觉语言转换器是将预训练的transformer架构应用于视觉语言建模的研究领域，通过迁移学习，在同时进行视觉和语言任务中取得了显著改进。

    

    视觉语言任务，如回答关于图像的问题或生成描述图像的标题，是计算机难以完成的任务。最近的研究将预训练的transformer架构应用于视觉语言建模。相比以前的视觉语言模型，transformer模型在性能和多功能性方面有很大提高。它们通过在大型通用数据集上进行预训练，并在架构和参数值上进行微小改变后，将学习转移到新任务中。这种迁移学习已成为自然语言处理和计算机视觉中的标准建模实践。视觉语言转换器承诺在需要同时进行视觉和语言的任务中产生类似的进展。本文对目前可用的视觉语言转换器模型的研究进行了广泛综合，并对其优势进行了分析。

    Vision language tasks, such as answering questions about or generating captions that describe an image, are difficult tasks for computers to perform. A relatively recent body of research has adapted the pretrained transformer architecture introduced in \citet{vaswani2017attention} to vision language modeling. Transformer models have greatly improved performance and versatility over previous vision language models. They do so by pretraining models on a large generic datasets and transferring their learning to new tasks with minor changes in architecture and parameter values. This type of transfer learning has become the standard modeling practice in both natural language processing and computer vision. Vision language transformers offer the promise of producing similar advancements in tasks which require both vision and language. In this paper, we provide a broad synthesis of the currently available research on vision language transformer models and offer some analysis of their strength
    
[^38]: 基于区域关注的多视角表示学习用于城市区域嵌入

    Region-Wise Attentive Multi-View Representation Learning for Urban Region Embeddings. (arXiv:2307.03212v1 [cs.CV])

    [http://arxiv.org/abs/2307.03212](http://arxiv.org/abs/2307.03212)

    提出了一种区域关注的多视角表示学习（ROMER）的算法，用于捕捉多视角之间的依赖关系，学习城市区域的表达能力，并在多源城市数据中优于现有方法。

    

    城市区域嵌入是一个重要且具有高度挑战性的问题，由于城市数据的复杂性和不断变化的性质。为了解决这些挑战，我们提出了一种区域关注的多视角表示学习（ROMER），以捕捉多视角之间的依赖关系，并学习城市区域的表达能力，而不受刚性邻域条件的限制。我们的模型专注于从多源城市数据中学习城市区域表示。首先，我们从移动流模式、POI语义和签到动态中捕捉多视角的相关性。然后，我们采用全局图注意网络来学习图中任意两个顶点的相似性。为了全面考虑和共享多个视角的特征，我们进一步提出了一个两阶段的融合模块，利用外部注意力学习权重来融合多视角嵌入。在真实世界数据集上进行的两个下游任务的大量实验证明，我们的模型优于现有的方法。

    Urban region embedding is an important and yet highly challenging issue due to the complexity and constantly changing nature of urban data. To address the challenges, we propose a Region-Wise Multi-View Representation Learning (ROMER) to capture multi-view dependencies and learn expressive representations of urban regions without the constraints of rigid neighbourhood region conditions. Our model focus on learn urban region representation from multi-source urban data. First, we capture the multi-view correlations from mobility flow patterns, POI semantics and check-in dynamics. Then, we adopt global graph attention networks to learn similarity of any two vertices in graphs. To comprehensively consider and share features of multiple views, a two-stage fusion module is further proposed to learn weights with external attention to fuse multi-view embeddings. Extensive experiments for two downstream tasks on real-world datasets demonstrate that our model outperforms state-of-the-art methods
    
[^39]: 缩放定律不具备可扩展性

    Scaling Laws Do Not Scale. (arXiv:2307.03201v1 [cs.LG])

    [http://arxiv.org/abs/2307.03201](http://arxiv.org/abs/2307.03201)

    本文讨论了缩放定律与人工智能模型性能之间的关系，并指出数据集规模的增加会引发不同社群的价值观和偏见风险。

    

    最近的研究提出了一种称为“缩放定律”的幂律关系，它描述了人工智能（AI）模型的性能与模型设计的各个方面（如数据集大小）之间的关系。换句话说，随着数据集（或模型参数等）的增加，基于该数据集训练的模型的性能将相应增加。然而，在总体上具有吸引力的同时，这种缩放定律关系忽视了用于衡量性能的指标可能是不稳定和有争议的，或者可能不符合不同人群对模型输出质量的感知。本文提出，随着用于训练大型AI模型的数据集规模增长，数据集中包含的不同社群（包括人口统计学群体）的数量可能会增加，每个社群可能具有不同的价值观。因此，数据集中所代表的社群可能存在价值观或偏见的风险。

    Recent work has proposed a power law relationship, referred to as ``scaling laws,'' between the performance of artificial intelligence (AI) models and aspects of those models' design (e.g., dataset size). In other words, as the size of a dataset (or model parameters, etc) increases, the performance of a given model trained on that dataset will correspondingly increase. However, while compelling in the aggregate, this scaling law relationship overlooks the ways that metrics used to measure performance may be precarious and contested, or may not correspond with how different groups of people may perceive the quality of models' output. In this paper, we argue that as the size of datasets used to train large AI models grows, the number of distinct communities (including demographic groups) whose data is included in a given dataset is likely to grow, each of whom may have different values. As a result, there is an increased risk that communities represented in a dataset may have values or p
    
[^40]: 使用Whisper进行教育视频转录：关于使用AI进行教育视频转录的初步研究

    Transcribing Educational Videos Using Whisper: A preliminary study on using AI for transcribing educational videos. (arXiv:2307.03200v1 [cs.CY])

    [http://arxiv.org/abs/2307.03200](http://arxiv.org/abs/2307.03200)

    本文研究了使用AI进行教育视频转录的初步研究，发现自动语音识别系统可以降低生成转录的成本和延迟，并提出了一些未来的研究方向。

    

    视频在远程学习中的应用越来越广泛，生成文本转录以增强学习体验十分重要。自动语音识别(ASR)系统可以减少生成转录的成本和延迟。本文通过对25个教育视频使用Whisper生成的转录进行量化，并在使用ASR进行教育视频转录时识别出一些开放性研究方向。

    Videos are increasingly being used for e-learning, and transcripts are vital to enhance the learning experience. The costs and delays of generating transcripts can be alleviated by automatic speech recognition (ASR) systems. In this article, we quantify the transcripts generated by whisper for 25 educational videos and identify some open avenues of research when leveraging ASR for transcribing educational videos.
    
[^41]: 一个多层级的AI治理框架

    A multilevel framework for AI governance. (arXiv:2307.03198v1 [cs.CY])

    [http://arxiv.org/abs/2307.03198](http://arxiv.org/abs/2307.03198)

    本文提出了一个多层级的AI治理框架，涉及政府、企业和公民三个相互依赖的利益相关者群体。通过信任的不同维度来研究它们之间的关系，并为进一步提升用户体验和制定AI相关公共政策提供实用见解。

    

    为了实现人工智能的潜在益处并减轻可能的风险，有必要开发一个符合伦理和基本人类价值观的治理框架。尽管一些组织已经发布了可信AI的指南和伦理框架，但如果没有一个调节的治理结构，这些伦理原则将无法转化为实践。在本文中，我们提出了一个多层级治理方法，涉及三个相互依赖的利益相关者群体：政府、企业和公民。我们通过信任的维度（如能力、诚信和善意）来研究它们之间的相互关系。结合AI的治理水平和信任维度，提供了可用于进一步增强用户体验并为与AI相关的公共政策提供信息的实用见解。

    To realize the potential benefits and mitigate potential risks of AI, it is necessary to develop a framework of governance that conforms to ethics and fundamental human values. Although several organizations have issued guidelines and ethical frameworks for trustworthy AI, without a mediating governance structure, these ethical principles will not translate into practice. In this paper, we propose a multilevel governance approach that involves three groups of interdependent stakeholders: governments, corporations, and citizens. We examine their interrelationships through dimensions of trust, such as competence, integrity, and benevolence. The levels of governance combined with the dimensions of trust in AI provide practical insights that can be used to further enhance user experiences and inform public policy related to AI.
    
[^42]: 分析SplitFed Learning中的漏洞：评估其对数据污染攻击的鲁棒性

    Analyzing the vulnerabilities in SplitFed Learning: Assessing the robustness against Data Poisoning Attacks. (arXiv:2307.03197v1 [cs.LG])

    [http://arxiv.org/abs/2307.03197](http://arxiv.org/abs/2307.03197)

    本研究对SplitFed Learning中的数据污染攻击进行了研究和分析，并提出了三种新的攻击策略。实验结果表明这些攻击策略可以降低基于DCML的分类器的性能。

    

    分布式协作机器学习（DCML）是解决集中式机器学习中的隐私问题的一种潜在替代方案。Split learning（SL）和联邦学习（FL）是DCML中两种有效的学习方法。最近人们对FL和SL的混合形式SplitFed Learning（SFL）产生了较大兴趣。本研究是对SFL中数据污染攻击进行研究、分析和影响评估的最早尝试。我们提出了三种新的攻击策略，分别是非目标攻击、有目标攻击和基于距离的攻击，用于SFL。所有攻击策略旨在降低基于DCML的分类器的性能。我们对心电图信号分类和手写数字识别这两个不同案例进行了攻击实验，在恶意客户端的百分比和模型拆分层的选择方面进行了变化。

    Distributed Collaborative Machine Learning (DCML) is a potential alternative to address the privacy concerns associated with centralized machine learning. The Split learning (SL) and Federated Learning (FL) are the two effective learning approaches in DCML. Recently there have been an increased interest on the hybrid of FL and SL known as the SplitFed Learning (SFL). This research is the earliest attempt to study, analyze and present the impact of data poisoning attacks in SFL. We propose three kinds of novel attack strategies namely untargeted, targeted and distance-based attacks for SFL. All the attacks strategies aim to degrade the performance of the DCML-based classifier. We test the proposed attack strategies for two different case studies on Electrocardiogram signal classification and automatic handwritten digit recognition. A series of attack experiments were conducted by varying the percentage of malicious clients and the choice of the model split layer between the clients and 
    
[^43]: 人才分析的人工智能技术综述

    A Comprehensive Survey of Artificial Intelligence Techniques for Talent Analytics. (arXiv:2307.03195v1 [cs.CY])

    [http://arxiv.org/abs/2307.03195](http://arxiv.org/abs/2307.03195)

    这篇论文综述了人工智能技术在人才分析中的应用。通过使用大数据和人工智能技术，组织可以从数据科学的角度理解组织行为并实时做出决策，为有效的人才管理提供智能支持。

    

    在当今竞争激烈且快速发展的商业环境下，组织需要重新思考以量化方式做出人才相关决策的重要性。事实上，大数据和人工智能技术的最新发展已经彻底改变了人力资源管理。大规模人才和管理相关数据的可用性为企业领导者提供了从数据科学角度理解组织行为和获取实际知识的无与伦比机会，进而为实时决策和有效的人才管理提供智能支持。在过去的十年中，人才分析已经成为应用数据科学在人力资源管理方面的有希望的领域，引起了人工智能社区的广泛关注并激发了许多研究工作。为此，我们提供了一个最新、全面的关于人工智能技术在人才分析中的应用的综述。

    In today's competitive and fast-evolving business environment, it is a critical time for organizations to rethink how to make talent-related decisions in a quantitative manner. Indeed, the recent development of Big Data and Artificial Intelligence (AI) techniques have revolutionized human resource management. The availability of large-scale talent and management-related data provides unparalleled opportunities for business leaders to comprehend organizational behaviors and gain tangible knowledge from a data science perspective, which in turn delivers intelligence for real-time decision-making and effective talent management at work for their organizations. In the last decade, talent analytics has emerged as a promising field in applied data science for human resource management, garnering significant attention from AI communities and inspiring numerous research efforts. To this end, we present an up-to-date and comprehensive survey on AI technologies used for talent analytics in the f
    
[^44]: 探索设计师和工程师在开发可信任的自动驾驶AI方面的观点差异

    Finding differences in perspectives between designers and engineers to develop trustworthy AI for autonomous cars. (arXiv:2307.03193v1 [cs.CY])

    [http://arxiv.org/abs/2307.03193](http://arxiv.org/abs/2307.03193)

    本研究通过探索设计师和工程师的观点差异，为自动驾驶汽车的可信任AI开发提供了实用建议，旨在提高技术进步和道德原则的优先性。

    

    在设计和实施道德人工智能（AI）的背景下，关于为自动驾驶汽车开发可信赖的AI存在不同的观点。本研究揭示了这些观点差异，并提出了建议以减少这种分歧。通过探索不同的观点，我们确定了导致差异的关键因素，并提出了弥合差距的策略。本研究超越了道德困境，可视化了可信赖和道德AI的复杂挑战。可信赖AI的三个支柱已被定义为透明度、可靠性和安全性。本研究为自动驾驶汽车的可信任AI领域做出了贡献，提供了实际建议，以增强将技术进步和道德原则优先考虑的AI系统的开发。

    In the context of designing and implementing ethical Artificial Intelligence (AI), varying perspectives exist regarding developing trustworthy AI for autonomous cars. This study sheds light on the differences in perspectives and provides recommendations to minimize such divergences. By exploring the diverse viewpoints, we identify key factors contributing to the differences and propose strategies to bridge the gaps. This study goes beyond the trolley problem to visualize the complex challenges of trustworthy and ethical AI. Three pillars of trustworthy AI have been defined: transparency, reliability, and safety. This research contributes to the field of trustworthy AI for autonomous cars, providing practical recommendations to enhance the development of AI systems that prioritize both technological advancement and ethical principles.
    
[^45]: 混合知识数据驱动的通道语义获取和波束赋形用于无小区大规模MIMO系统

    Hybrid Knowledge-Data Driven Channel Semantic Acquisition and Beamforming for Cell-Free Massive MIMO. (arXiv:2307.03070v1 [eess.SP] CROSS LISTED)

    [http://arxiv.org/abs/2307.03070](http://arxiv.org/abs/2307.03070)

    本文提出了一种混合知识数据驱动的方法，用于无小区大规模MIMO系统中的通道语义获取和多用户波束赋形，可提高室外无线系统的性能，支持扩展现实应用。

    

    本文旨在推动室外无线系统的发展，以更好地支持普遍存在的扩展现实（XR）应用，并缩小与当前室内无线传输能力之间的差距。我们提出了一种混合知识数据驱动的方法，用于无小区大规模多输入多输出（MIMO）系统中的通道语义获取和多用户波束赋形。具体而言，我们首先提出了一种基于数据驱动的多层感知机（MLP）-Mixer自编码器，用于通道语义获取，在此过程中联合优化了导频信号、信道语义嵌入的CSI量化器以及信道语义提取的CSI重构。此外，基于获取的通道语义，我们进一步提出了一种知识驱动的深度展开多用户波束赋形器，在室外XR场景中能够实现良好的频谱效率，并对不完美的CSI具有鲁棒性。通过展开传统的迭代超松弛（SOR）线性波束赋形

    This paper focuses on advancing outdoor wireless systems to better support ubiquitous extended reality (XR) applications, and close the gap with current indoor wireless transmission capabilities. We propose a hybrid knowledge-data driven method for channel semantic acquisition and multi-user beamforming in cell-free massive multiple-input multiple-output (MIMO) systems. Specifically, we firstly propose a data-driven multiple layer perceptron (MLP)-Mixer-based auto-encoder for channel semantic acquisition, where the pilot signals, CSI quantizer for channel semantic embedding, and CSI reconstruction for channel semantic extraction are jointly optimized in an end-to-end manner. Moreover, based on the acquired channel semantic, we further propose a knowledge-driven deep-unfolding multi-user beamformer, which is capable of achieving good spectral efficiency with robustness to imperfect CSI in outdoor XR scenarios. By unfolding conventional successive over-relaxation (SOR)-based linear beamf
    
[^46]: 大规模语言模型对数据科学教育应该做什么？

    What Should Data Science Education Do with Large Language Models?. (arXiv:2307.02792v1 [cs.CY])

    [http://arxiv.org/abs/2307.02792](http://arxiv.org/abs/2307.02792)

    大型语言模型（LLM）正在改变数据科学家的责任和数据科学教育模式，从动手编码和标准分析转变为评估和管理自动化AI执行的分析。这种转变要求数据科学教育注重培养学生的多样化技能，如创造力、批判性思维和AI引导的编程。

    

    大型语言模型（LLM），如ChatGPT等的快速发展正在改变数据科学和统计学。这些最先进的工具可以简化复杂的流程，从而重塑了数据科学家的角色。我们认为LLM正在转变数据科学家的责任，将他们的重点从动手编码、数据整理和进行标准分析转变为评估和管理这些自动化AI执行的分析。这种角色的演变类似于从软件工程师转变为产品经理。我们在本文中使用LLM在数据科学案例研究中说明了这种转变。这些发展要求数据科学教育有意义地发展。教育方法现在必须更加注重培养学生的多样化技能，如LLM启发的创造力、批判性思维、AI引导的编程。LLM还可以在课堂上起到重要的作用，作为互动式教学和...

    The rapid advances of large language models (LLMs), such as ChatGPT, are revolutionizing data science and statistics. These state-of-the-art tools can streamline complex processes. As a result, it reshapes the role of data scientists. We argue that LLMs are transforming the responsibilities of data scientists, shifting their focus from hands-on coding, data-wrangling and conducting standard analyses to assessing and managing analyses performed by these automated AIs. This evolution of roles is reminiscent of the transition from a software engineer to a product manager. We illustrate this transition with concrete data science case studies using LLMs in this paper. These developments necessitate a meaningful evolution in data science education. Pedagogy must now place greater emphasis on cultivating diverse skillsets among students, such as LLM-informed creativity, critical thinking, AI-guided programming. LLMs can also play a significant role in the classroom as interactive teaching and
    
[^47]: 弹性决策变压器

    Elastic Decision Transformer. (arXiv:2307.02484v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.02484](http://arxiv.org/abs/2307.02484)

    弹性决策变压器（EDT）通过在测试时间进行动作推断时调整历史长度来实现轨迹拼接，填补了决策变压器（DT）在这一方面的性能差距，并且在多任务情况下胜过基于Q-Learning的方法。

    

    本文介绍了弹性决策变压器（EDT），它是现有决策变压器（DT）及其变体的重大进展。尽管DT声称能够生成最佳轨迹，但实证证据表明它在轨迹拼接方面存在困难，轨迹拼接是指从一组次优轨迹中生成最优或接近最优轨迹的过程。提出的EDT通过在测试时间进行动作推断时调整DT中维护的历史长度来实现轨迹拼接，从而使自己与众不同。此外，当前轨迹是最优的时候，EDT通过保持较长的历史，当当前轨迹是次优的时候，EDT通过保持较短的历史来优化轨迹，使其能够与更优的轨迹进行“拼接”。广泛的实验表明，EDT能够填补基于DT和基于Q-Learning方法之间的性能差距。特别是，EDT在多任务情况下胜过基于Q-Learning的方法。

    This paper introduces Elastic Decision Transformer (EDT), a significant advancement over the existing Decision Transformer (DT) and its variants. Although DT purports to generate an optimal trajectory, empirical evidence suggests it struggles with trajectory stitching, a process involving the generation of an optimal or near-optimal trajectory from the best parts of a set of sub-optimal trajectories. The proposed EDT differentiates itself by facilitating trajectory stitching during action inference at test time, achieved by adjusting the history length maintained in DT. Further, the EDT optimizes the trajectory by retaining a longer history when the previous trajectory is optimal and a shorter one when it is sub-optimal, enabling it to "stitch" with a more optimal trajectory. Extensive experimentation demonstrates EDT's ability to bridge the performance gap between DT-based and Q Learning-based approaches. In particular, the EDT outperforms Q Learning-based methods in a multi-task regi
    
[^48]: FOCUS:机器人操纵的以物体为中心的世界模型

    FOCUS: Object-Centric World Models for Robotics Manipulation. (arXiv:2307.02427v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2307.02427](http://arxiv.org/abs/2307.02427)

    FOCUS是一个基于模型的代理机器人，学习了以物体为中心的世界模型，并通过新颖的探索奖励来更轻松地探索物体间的相互作用。这种以物体为中心的世界模型可以更高效地解决机器人操纵任务，并实现一致性的机器人-物体交互探索。

    

    在机器人操纵中，以物体为中心的世界模型是理解物体及其可能的相互作用的重要认知能力。然而，学习这样一个特定捕捉实体和关系的结构化世界模型仍然是一个具有挑战性且尚未深入探索的问题。为了解决这个问题，我们提出了FOCUS，这是一个基于模型的代理机器人，可以学习以物体为中心的世界模型。通过来自以物体为中心的表示的新颖探索奖励，FOCUS可以在机器人操纵任务中更轻松地探索物体间的相互作用。在不同环境中对我们的方法进行评估，我们展示了以物体为中心的世界模型可以使代理机器人更高效地解决任务，并实现对机器人-物体交互的一致性探索。通过使用Franka Emika机器人臂，我们还展示了FOCUS如何在实际环境中进行应用。

    Understanding the world in terms of objects and the possible interplays with them is an important cognition ability, especially in robotics manipulation, where many tasks require robot-object interactions. However, learning such a structured world model, which specifically captures entities and relationships, remains a challenging and underexplored problem. To address this, we propose FOCUS, a model-based agent that learns an object-centric world model. Thanks to a novel exploration bonus that stems from the object-centric representation, FOCUS can be deployed on robotics manipulation tasks to explore object interactions more easily. Evaluating our approach on manipulation tasks across different settings, we show that object-centric world models allow the agent to solve tasks more efficiently and enable consistent exploration of robot-object interactions. Using a Franka Emika robot arm, we also showcase how FOCUS could be adopted in real-world settings.
    
[^49]: 遭受苦难的烤面包机

    Suffering Toasters. (arXiv:2306.17258v1 [cs.AI])

    [http://arxiv.org/abs/2306.17258](http://arxiv.org/abs/2306.17258)

    本文旨在为人工智能、自我意识和代理问题提供更清晰的定义，我们提出了一种新的启发式方法来测试人工自我意识，并讨论了这种方法引发的一些问题。

    

    在人工智能（AI）领域，智能的广泛接受的定义仍然难以找到。由于我们对AI范式、架构和工具的快速发展，人们普遍认为自然产生的AI意识比以往更有可能。在本文中，我们声称所有当前的智能测试都不足以指出存在或缺乏象人类直觉感知的智能。我们借鉴科学哲学、心理学和其他领域的思想，提供了对人工智能、自我意识和代理问题的更清晰定义。我们进一步提出了一种测试人工自我意识的新启发式方法，并概述了可能的实现。最后，我们讨论了这种新启发式方法引发的一些问题，无论是哲学问题还是实现问题。

    A widely accepted definition of intelligence in the context of Artificial Intelligence (AI) still eludes us. Due to our exceedingly rapid development of AI paradigms, architectures, and tools, the prospect of naturally arising AI consciousness seems more likely than ever. In this paper, we claim that all current intelligence tests are insufficient to point to the existence or lack of intelligence \textbf{as humans intuitively perceive it}. We draw from ideas in the philosophy of science, psychology, and other areas of research to provide a clearer definition of the problems of artificial intelligence, self-awareness, and agency. We furthermore propose a new heuristic approach to test for artificial self-awareness and outline a possible implementation. Finally, we discuss some of the questions that arise from this new heuristic, be they philosophical or implementation-oriented.
    
[^50]: 通过重新加权优化轨迹增强对抗训练

    Enhancing Adversarial Training via Reweighting Optimization Trajectory. (arXiv:2306.14275v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.14275](http://arxiv.org/abs/2306.14275)

    本文提出了一种名为“加权优化轨迹（WOT）”的新方法，通过优化历史轨迹，解决了对抗训练中的鲁棒泛化问题。

    

    尽管对抗训练已成为提高深度神经网络鲁棒性的事实上的方法，但众所周知，简单的对抗训练遭受了令人畏缩的鲁棒过拟合问题，导致鲁棒泛化效果不佳。近年来已经提出了一些方法来解决这些缺点，如额外的规范化、对抗权重扰动和更多数据训练。然而，鲁棒泛化的改进仍然远不理想。在本文中，我们从全新的角度解决这一挑战--优化历史轨迹的精细化。我们提出了一种名为“加权优化轨迹（WOT）”的新方法，利用对抗训练的优化轨迹在时间上的特点。我们进行了大量实验证明了WOT在各种最新对抗攻击下的有效性。结果显示，WOT与现有方法完美融合。

    Despite the fact that adversarial training has become the de facto method for improving the robustness of deep neural networks, it is well-known that vanilla adversarial training suffers from daunting robust overfitting, resulting in unsatisfactory robust generalization. A number of approaches have been proposed to address these drawbacks such as extra regularization, adversarial weights perturbation, and training with more data over the last few years. However, the robust generalization improvement is yet far from satisfactory. In this paper, we approach this challenge with a brand new perspective -- refining historical optimization trajectories. We propose a new method named \textbf{Weighted Optimization Trajectories (WOT)} that leverages the optimization trajectories of adversarial training in time. We have conducted extensive experiments to demonstrate the effectiveness of WOT under various state-of-the-art adversarial attacks. Our results show that WOT integrates seamlessly with t
    
[^51]: FedSelect: 个性化联邦学习中参数自定义选择的细调方法

    FedSelect: Customized Selection of Parameters for Fine-Tuning during Personalized Federated Learning. (arXiv:2306.13264v1 [cs.LG])

    [http://arxiv.org/abs/2306.13264](http://arxiv.org/abs/2306.13264)

    本文提出了一种名为FedSelect的新联邦学习框架，通过寻找最佳客户端子网络从而直接个性化客户端子网络结构和参数，同时保留了全局知识，提高了客户端性能。

    

    联邦学习旨在通过在本地数据上微调客户端参数或针对本地任务个性化架构来提高客户端性能。然而，现有的方法要么在牺牲重要的全局知识的情况下进行个性化，要么在预先确定网络层以进行微调的情况下导致客户端模型中全局知识储存的不足。本文提出了一种新的联邦学习框架FedSelect，通过同时搜索并获得个性化最佳参数和用于全局聚合的其余参数，从而直接个性化客户子网络结构和参数。

    Recent advancements in federated learning (FL) seek to increase client-level performance by fine-tuning client parameters on local data or personalizing architectures for the local task. Existing methods for such personalization either prune a global model or fine-tune a global model on a local client distribution. However, these existing methods either personalize at the expense of retaining important global knowledge, or predetermine network layers for fine-tuning, resulting in suboptimal storage of global knowledge within client models. Enlightened by the lottery ticket hypothesis, we first introduce a hypothesis for finding optimal client subnetworks to locally fine-tune while leaving the rest of the parameters frozen. We then propose a novel FL framework, FedSelect, using this procedure that directly personalizes both client subnetwork structure and parameters, via the simultaneous discovery of optimal parameters for personalization and the rest of parameters for global aggregatio
    
[^52]: 论述模型与对话游戏的定时并发语言的交错语义

    An Interleaving Semantics of the Timed Concurrent Language for Argumentation to Model Debates and Dialogue Games. (arXiv:2306.07675v1 [cs.AI])

    [http://arxiv.org/abs/2306.07675](http://arxiv.org/abs/2306.07675)

    本文提出了一种基于定时抽象论证框架的定时并发语言，用于模拟代理之间的交互，并将代理的可接受性与给定时间间隔进行推理和通信，特别适用于模拟辩论和对话游戏的情境。

    

    时间是建模智能体动态行为的关键因素：活动在真实环境中具有确定的时间长度，并且先前的行为会影响智能体的行为。本文提出了一种语言，用于建模代理之间的并发交互，同时允许指定特定行为发生的时间间隔。这种语言利用定时的抽象论证框架实现代理使用的共享内存，以在给定时间间隔内通信和推理关于他们的信念的可接受性。在单个处理器上使用交错模型进行基本计算步骤，时隔最大并行性。按照这种方法，只有一个可用的代理在每个时刻被执行。为了展示这种语言的能力，我们还展示了如何使用它来模拟发生在智能代理之间的辩论和对话游戏等互动。

    Time is a crucial factor in modelling dynamic behaviours of intelligent agents: activities have a determined temporal duration in a real-world environment, and previous actions influence agents' behaviour. In this paper, we propose a language for modelling concurrent interaction between agents that also allows the specification of temporal intervals in which particular actions occur. Such a language exploits a timed version of Abstract Argumentation Frameworks to realise a shared memory used by the agents to communicate and reason on the acceptability of their beliefs with respect to a given time interval. An interleaving model on a single processor is used for basic computation steps, with maximum parallelism for time elapsing. Following this approach, only one of the enabled agents is executed at each moment. To demonstrate the capabilities of language, we also show how it can be used to model interactions such as debates and dialogue games taking place between intelligent agents. La
    
[^53]: $E(2)$-等变视觉Transformer

    $E(2)$-Equivariant Vision Transformer. (arXiv:2306.06722v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.06722](http://arxiv.org/abs/2306.06722)

    本文设计了一个群等变视觉Transformer，通过一种新颖有效的位置编码操作解决了视觉Transformer中的等变性学习难题，并通过实验证明了其明显优于非等变的自注意力网络。

    

    视觉Transformer（ViT）在计算机视觉领域取得了显著的性能。然而，ViT中的位置编码使得学习数据的内在等变性变得非常困难。本文对设计的等变ViT进行了初步尝试，但证明在某些情况下存在缺陷。为了解决这个问题，我们通过一种新颖有效的位置编码操作设计了一个群等变视觉Transformer（GE-ViT）。我们证明了GE-ViT满足等变神经网络的所有理论要求。在标准基准数据集上进行了全面的实验证明，GE-ViT明显优于非等变的自注意力网络。代码可在https://github.com/ZJUCDSYangKaifan/GEVit中获得。

    Vision Transformer (ViT) has achieved remarkable performance in computer vision. However, positional encoding in ViT makes it substantially difficult to learn the intrinsic equivariance in data. Initial attempts have been made on designing equivariant ViT but are proved defective in some cases in this paper. To address this issue, we design a Group Equivariant Vision Transformer (GE-ViT) via a novel, effective positional encoding operator. We prove that GE-ViT meets all the theoretical requirements of an equivariant neural network. Comprehensive experiments are conducted on standard benchmark datasets, demonstrating that GE-ViT significantly outperforms non-equivariant self-attention networks. The code is available at https://github.com/ZJUCDSYangKaifan/GEVit.
    
[^54]: 离线优先经验重放

    Offline Prioritized Experience Replay. (arXiv:2306.05412v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.05412](http://arxiv.org/abs/2306.05412)

    本文提出了离线优先经验重放（OPER）方法来解决离线强化学习中的分布偏移问题。通过设计一类优先级函数来对高回报的转换进行优先处理，从而改善行为策略，并在此改进的策略约束下优化离线强化学习算法的解决方案。对于离线强化学习，OPER方法是一种有效的解决方案。

    

    离线强化学习面临着分布偏移问题。为了解决这个问题，现有的工作主要集中在设计学习策略和行为策略之间的复杂约束。然而，这些约束通过均匀采样等方式被应用到表现良好和表现差的行动上，这可能会对学习策略产生负面影响。为了缓解这个问题，我们提出了离线优先经验重放（OPER），其中包括一类优先级函数，用于将高回报的转换置于更频繁的访问中。通过理论分析，我们证明了这类优先级函数能够引起行为策略的改善，当策略约束到这个改进的策略上时，离线强化学习算法很可能得到更好的解决方案。我们开发了两种实用策略来获得基于拟合值网络的优先权重（OPER-A）或者u

    Offline reinforcement learning (RL) is challenged by the distributional shift problem. To address this problem, existing works mainly focus on designing sophisticated policy constraints between the learned policy and the behavior policy. However, these constraints are applied equally to well-performing and inferior actions through uniform sampling, which might negatively affect the learned policy. To alleviate this issue, we propose Offline Prioritized Experience Replay (OPER), featuring a class of priority functions designed to prioritize highly-rewarding transitions, making them more frequently visited during training. Through theoretical analysis, we show that this class of priority functions induce an improved behavior policy, and when constrained to this improved policy, a policy-constrained offline RL algorithm is likely to yield a better solution. We develop two practical strategies to obtain priority weights by estimating advantages based on a fitted value network (OPER-A) or u
    
[^55]: 不要相信你的眼睛：关于特征可视化的（不）可靠性。

    Don't trust your eyes: on the (un)reliability of feature visualizations. (arXiv:2306.04719v1 [cs.CV])

    [http://arxiv.org/abs/2306.04719](http://arxiv.org/abs/2306.04719)

    本文探讨了神经网络如何从像素中提取模式的问题，并研究了特征可视化的可靠性。实验证据表明，由于优化过程中固有的限制，特征可视化能够可靠理解的功能集非常有限，对于解释神经网络如何处理自然图像的解释能力产生怀疑。

    

    神经网络是如何从像素中提取模式的？特征可视化通过优化来可视化高激活的模式，试图回答这个重要问题。如今，可视化方法构成了我们对神经网络内部工作的了解的基础，作为一种机械式的可解释性。在这里，我们问：特征可视化有多可靠？我们通过开发网络电路来诈骗特征可视化，使其显示完全与自然输入的正常网络行为毫无联系的任意模式。然后，我们提供证据表明在标准，未操纵网络中发生了类似的现象：特征可视化与标准输入处理非常不同，对神经网络如何处理自然图像的解释能力产生怀疑。我们通过理论证明支撑这一经验发现，由于优化过程中固有的限制，可以通过特征可视化可靠理解的功能集极其有限。

    How do neural networks extract patterns from pixels? Feature visualizations attempt to answer this important question by visualizing highly activating patterns through optimization. Today, visualization methods form the foundation of our knowledge about the internal workings of neural networks, as a type of mechanistic interpretability. Here we ask: How reliable are feature visualizations? We start our investigation by developing network circuits that trick feature visualizations into showing arbitrary patterns that are completely disconnected from normal network behavior on natural input. We then provide evidence for a similar phenomenon occurring in standard, unmanipulated networks: feature visualizations are processed very differently from standard input, casting doubt on their ability to "explain" how neural networks process natural images. We underpin this empirical finding by theory proving that the set of functions that can be reliably understood by feature visualization is extr
    
[^56]: 未见过的语言对中的混合代码文本合成

    Code-Switched Text Synthesis in Unseen Language Pairs. (arXiv:2305.16724v1 [cs.CL])

    [http://arxiv.org/abs/2305.16724](http://arxiv.org/abs/2305.16724)

    本文介绍了GLOSS模型，旨在解决在缺乏训练数据的情况下合成混合代码文本的问题，并且可以推广到更广泛的语言对。该模型在四个未见过的语言对上的实验中优于其他基线模型和在单语文本上运行的生成模型。

    

    现有的针对混合代码文本合成的研究大多需要在目标语言对中的混合代码文本上进行训练，这限制了模型在缺乏混合代码数据的情况下的部署。在本文中，我们研究了在缺乏训练数据的情况下合成混合代码文本的问题。我们介绍了GLOSS，这是一个建立在预训练多语言机器翻译模型（PMMTM）之上，并带有额外的代码切换模块的模型。这个模块，无论是适配器还是额外的前缀，在训练过程中从混合代码数据中学习代码切换模式，而GLOSS的主要组成部分PMMTM被冻结。我们只调整代码切换模块的设计，防止模型过度拟合针对混合代码训练数据的约束。因此，GLOSS表现出了跨更广泛的语言对进行归纳和合成混合代码文本的能力。此外，我们还开发了一种基于目标语言单语文本的自训练算法，以提高模型性能。我们对四个未见过的语言对进行的实验证明，GLOSS优于其他从具有混合代码数据的语言对中调整的模型和在单语文本上运行的生成模型等多个基线模型。

    Existing efforts on text synthesis for code-switching mostly require training on code-switched texts in the target language pairs, limiting the deployment of the models to cases lacking code-switched data. In this work, we study the problem of synthesizing code-switched texts for language pairs absent from the training data. We introduce GLOSS, a model built on top of a pre-trained multilingual machine translation model (PMMTM) with an additional code-switching module. This module, either an adapter or extra prefixes, learns code-switching patterns from code-switched data during training, while the primary component of GLOSS, i.e., the PMMTM, is frozen. The design of only adjusting the code-switching module prevents our model from overfitting to the constrained training data for code-switching. Hence, GLOSS exhibits the ability to generalize and synthesize code-switched texts across a broader spectrum of language pairs. Additionally, we develop a self-training algorithm on target langu
    
[^57]: 战略卡牌游戏人工智能比赛总结

    Summarizing Strategy Card Game AI Competition. (arXiv:2305.11814v1 [cs.AI])

    [http://arxiv.org/abs/2305.11814](http://arxiv.org/abs/2305.11814)

    本文总结了基于《魔法与代码英雄》（LOCM）的五年人工智能比赛，介绍了游戏规则以及比赛历史，给出了组织AI比赛的建议。LOCM已被用于许多与游戏树搜索算法、神经网络、评估函数和CCG卡组构建等相关领域的出版物中。

    

    本文总结了基于《魔法与代码英雄》（LOCM）的五年人工智能比赛，这是一个旨在支持研究和算法开发的小型收集卡牌游戏（CCG）。该游戏被用于多个事件中，包括CodinGame平台上的社区比赛，以及IEEE进化计算大会和IEEE游戏会议上的战略卡牌游戏人工智能比赛。LOCM已被用于许多与游戏树搜索算法、神经网络、评估函数和CCG卡组构建等相关领域的出版物中。本文介绍了游戏规则、组织比赛的历史以及参赛者和他们的方法，并提供了有关为研究社区组织人工智能比赛的一些常规建议。尽管COG 2022版宣布是最后一版，但游戏仍然可用，并可在在线排行榜竞技场上进行游玩。

    This paper concludes five years of AI competitions based on Legends of Code and Magic (LOCM), a small Collectible Card Game (CCG), designed with the goal of supporting research and algorithm development. The game was used in a number of events, including Community Contests on the CodinGame platform, and Strategy Card Game AI Competition at the IEEE Congress on Evolutionary Computation and IEEE Conference on Games. LOCM has been used in a number of publications related to areas such as game tree search algorithms, neural networks, evaluation functions, and CCG deckbuilding. We present the rules of the game, the history of organized competitions, and a listing of the participant and their approaches, as well as some general advice on organizing AI competitions for the research community. Although the COG 2022 edition was announced to be the last one, the game remains available and can be played using an online leaderboard arena.
    
[^58]: SocNavGym：一个针对社交导航的强化学习仿真环境

    SocNavGym: A Reinforcement Learning Gym for Social Navigation. (arXiv:2304.14102v1 [cs.RO])

    [http://arxiv.org/abs/2304.14102](http://arxiv.org/abs/2304.14102)

    本文提出了SocNavGym，对于社交导航领域的研究提供了一个轻便、快速、易用的仿真环境，可生成各种各样的社交导航场景，并促进了智能社交机器人的发展。

    

    在人口密集的环境下，自主机器人在导航时需要遵守社交规范。机器学习，尤其是深度强化学习，最近在社交导航领域中取得了显著进展。这可以部分归因于生成的策略不受代码复杂性或处理的变量数量等人类限制。不幸的是，DRL算法缺乏安全保障，需要大量数据需求，导致在现实环境中的应用不太切实际。为了缩小这一差距，仿真环境被广泛使用。本文提出了SocNavGym，一个专门针对社交导航的先进仿真环境，可以生成各种各样的社交导航场景，并促进智能社交机器人的发展。SocNavGym轻便、快速、易于使用，并可轻松配置以生成不同类型的社交导航场景。此外，它还可以配置为使用不同的传感器，并支持无障碍环境的仿真。

    It is essential for autonomous robots to be socially compliant while navigating in human-populated environments. Machine Learning and, especially, Deep Reinforcement Learning have recently gained considerable traction in the field of Social Navigation. This can be partially attributed to the resulting policies not being bound by human limitations in terms of code complexity or the number of variables that are handled. Unfortunately, the lack of safety guarantees and the large data requirements by DRL algorithms make learning in the real world unfeasible. To bridge this gap, simulation environments are frequently used. We propose SocNavGym, an advanced simulation environment for social navigation that can generate a wide variety of social navigation scenarios and facilitates the development of intelligent social agents. SocNavGym is light-weight, fast, easy-to-use, and can be effortlessly configured to generate different types of social navigation scenarios. It can also be configured to
    
[^59]: 创新放缓：技术概念创造的减速及新技术概念原创性的下降

    Innovation Slowdown: Decelerating Concept Creation and Declining Originality in New Technological Concepts. (arXiv:2303.13300v1 [cs.SI])

    [http://arxiv.org/abs/2303.13300](http://arxiv.org/abs/2303.13300)

    人类智力的局限性导致技术概念创造放缓和原创性下降，因此建议开发和实施创造性人工智能增强创新过程。

    

    通过对之前的概念重用、重组和合成进行新技术概念的创造可能会导致概念空间的指数增长。然而，我们对由专利文本中超过400万个概念组成的大规模技术语义网络进行的统计分析发现，概念创造的步伐在持续减缓，并且新创造出的概念的原创性有所下降。这些趋势可以归因于人类智力在创新超出现有技术的拓展空间方面的局限。为了保持创新，我们建议开发和实施创造性人工智能，以增强创新过程的多个方面，包括学习、创造和评估。

    The creation of new technological concepts through design reuses, recombination, and synthesis of prior concepts to create new ones may lead to exponential growth of the concept space over time. However, our statistical analysis of a large-scale technology semantic network consisting of over four million concepts from patent texts found evidence of a persistent deceleration in the pace of concept creation and a decline in the originality of newly created concepts. These trends may be attributed to the limitations of human intelligence in innovating beyond an expanding space of prior art. To sustain innovation, we recommend the development and implementation of creative artificial intelligence that can augment various aspects of the innovation process, including learning, creation, and evaluation.
    
[^60]: 重新审视多模态行人检测中的模态不平衡问题

    Revisiting Modality Imbalance In Multimodal Pedestrian Detection. (arXiv:2302.12589v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.12589](http://arxiv.org/abs/2302.12589)

    本文探讨了多模态行人检测中模态不平衡问题，并提出了一种新的训练设置，通过正则化器解决了模态之间的不平衡，使得特征融合更加鲁棒。

    

    多模态学习，特别是对于行人检测而言，近来受到关注，因为它能够在关键的自动驾驶场景中同样良好地运行，如弱光、夜间和恶劣天气条件。然而，在大多数情况下，训练分布极大地强调了某个特定输入的贡献，使网络对某种模态偏向。因此，这种模型的泛化成为一个重要问题，在推断过程中，在训练过程中非主导输入模态可能对推理过程做出更多贡献。在这里，我们引入了一种新的训练设置与多模态架构中的正则化器，以解决模态之间的这种不平衡问题。具体来说，我们的正则化项通过在训练过程中将特征提取器同等重要地考虑在内，使特征融合方法更具鲁棒性，从而提取多模态分布，这被称为移除不平衡性。

    Multimodal learning, particularly for pedestrian detection, has recently received emphasis due to its capability to function equally well in several critical autonomous driving scenarios such as low-light, night-time, and adverse weather conditions. However, in most cases, the training distribution largely emphasizes the contribution of one specific input that makes the network biased towards one modality. Hence, the generalization of such models becomes a significant problem where the non-dominant input modality during training could be contributing more to the course of inference. Here, we introduce a novel training setup with regularizer in the multimodal architecture to resolve the problem of this disparity between the modalities. Specifically, our regularizer term helps to make the feature fusion method more robust by considering both the feature extractors equivalently important during the training to extract the multimodal distribution which is referred to as removing the imbala
    
[^61]: 深度强化学习中的自动内在奖励塑造探索方法研究

    Automatic Intrinsic Reward Shaping for Exploration in Deep Reinforcement Learning. (arXiv:2301.10886v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.10886](http://arxiv.org/abs/2301.10886)

    本文提出了一种名为AIRS的自动内在奖励塑造探索方法，可以提供高质量的内在激励以增强强化学习中的探索性能；并开发了高效可靠的内在奖励工具包。实验表明，AIRS性能卓越，能够胜过基准方案。

    

    本文提出了一种名为AIRS的自动内在奖励塑造方法，通过智能和适应性的塑造函数，提供高质量的内在激励以增强强化学习中的探索性能。AIRS可以根据实时估计的任务回报从预定义的函数集中选择塑造函数，提供可靠的探索激励并解决偏置目标问题。此外，我们开发了一个内在奖励工具包，提供多种内在奖励方法的高效可靠实现方式。我们将AIRS应用在MiniGrid、Procgen和DeepMind控制套件的多项任务中进行测试。大量仿真结果表明，AIRS可以胜过基准方案，并具有简单的架构和卓越的性能。

    We present AIRS: Automatic Intrinsic Reward Shaping that intelligently and adaptively provides high-quality intrinsic rewards to enhance exploration in reinforcement learning (RL). More specifically, AIRS selects shaping function from a predefined set based on the estimated task return in real-time, providing reliable exploration incentives and alleviating the biased objective problem. Moreover, we develop an intrinsic reward toolkit to provide efficient and reliable implementations of diverse intrinsic reward approaches. We test AIRS on various tasks of MiniGrid, Procgen, and DeepMind Control Suite. Extensive simulation demonstrates that AIRS can outperform the benchmarking schemes and achieve superior performance with simple architecture.
    
[^62]: 可扩展的多智能体强化学习在仓库物流中与机器人和人类同事合作

    Scalable Multi-Agent Reinforcement Learning for Warehouse Logistics with Robotic and Human Co-Workers. (arXiv:2212.11498v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.11498](http://arxiv.org/abs/2212.11498)

    该论文提出了一种可扩展的多智能体强化学习方法，用于仓库物流中的机器人和人类同事合作。他们通过分层的MARL算法，让经理和工人代理根据全局目标进行协同训练，以最大化拣货速率。

    

    我们设想一个仓库里有数十个移动机器人和人类分拣员一起工作，收集和交付仓库内的物品。我们要解决的基本问题是称为拣货问题，即这些工作代理人如何在仓库中协调他们的移动和行为以最大化性能（例如订单吞吐量）。传统的行业方法使用启发式方法需要大量的工程努力来为固有可变的仓库配置进行优化。相比之下，多智能体强化学习（MARL）可以灵活地应用于不同的仓库配置（例如大小，布局，工人数量/类型，物品补充频率），因为代理人通过经验学习如何最优地相互合作。我们开发了分层MARL算法，其中一个管理者为工人代理分配目标，并且管理者和工人的策略被共同训练以最大化全局目标（例如拣货速率）。

    We envision a warehouse in which dozens of mobile robots and human pickers work together to collect and deliver items within the warehouse. The fundamental problem we tackle, called the order-picking problem, is how these worker agents must coordinate their movement and actions in the warehouse to maximise performance (e.g. order throughput). Established industry methods using heuristic approaches require large engineering efforts to optimise for innately variable warehouse configurations. In contrast, multi-agent reinforcement learning (MARL) can be flexibly applied to diverse warehouse configurations (e.g. size, layout, number/types of workers, item replenishment frequency), as the agents learn through experience how to optimally cooperate with one another. We develop hierarchical MARL algorithms in which a manager assigns goals to worker agents, and the policies of the manager and workers are co-trained toward maximising a global objective (e.g. pick rate). Our hierarchical algorith
    
[^63]: 一种基于强化学习的模因算法用于社会技术生产调度

    A Memetic Algorithm with Reinforcement Learning for Sociotechnical Production Scheduling. (arXiv:2212.10936v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.10936](http://arxiv.org/abs/2212.10936)

    本文提出了一种基于深度强化学习的模因算法，用于解决具有实际约束的灵活生产调度问题，并弥补元启发式研究中的缺陷。

    

    本文提出了一个应用深度强化学习的模因算法，用于解决实际双资源约束柔性作业车间调度问题（DRC-FJSSP）。近年来，对于DRL技术已经进行了广泛的研究，但是没有考虑到现实、灵活和以人为中心的车间。本文发现，在以订单为导向的间歇性制造中存在一个研究空白，它经常在具有高服务水平的中小型公司中表示。从这一领域的实际工业项目中，我们认识到需要描述灵活的机器、人工工作者和能力、设置和处理操作、物料到达时间、具有并行任务的复杂作业路径以进行物料清单（BOM）制造、顺序相关设置时间和（部分）自动化任务。另一方面，在DRC-FJSSP的背景下，已经进行了大量的元启发式研究。然而，缺乏适当的方法来解决生产过程的复杂性和不确定性，这是现实工业世界中面临的主要挑战。因此，提出了一种新的算法，以弥补相关领域的缺陷。

    The following article presents a memetic algorithm with applying deep reinforcement learning (DRL) for solving practically oriented dual resource constrained flexible job shop scheduling problems (DRC-FJSSP). In recent years, there has been extensive research on DRL techniques, but without considering realistic, flexible and human-centered shopfloors. A research gap can be identified in the context of make-to-order oriented discontinuous manufacturing as it is often represented in medium-size companies with high service levels. From practical industry projects in this domain, we recognize requirements to depict flexible machines, human workers and capabilities, setup and processing operations, material arrival times, complex job paths with parallel tasks for bill of material (BOM) manufacturing, sequence-depended setup times and (partially) automated tasks. On the other hand, intensive research has been done on metaheuristics in the context of DRC-FJSSP. However, there is a lack of sui
    
[^64]: 高效节约内存的NLLB-200：针对大规模多语言机器翻译模型的语言特定专家删减

    Memory-efficient NLLB-200: Language-specific Expert Pruning of a Massively Multilingual Machine Translation Model. (arXiv:2212.09811v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09811](http://arxiv.org/abs/2212.09811)

    本研究提出了一种节约内存的NLLB-200模型修剪方法，可在保持翻译质量的同时移除多达80％的专家，使得在单个32GB的GPU上运行模型成为可能。这对于大规模多语言机器翻译具有重要的意义。

    

    与传统的双语翻译系统相比，大规模多语言机器翻译具有吸引力，因为一个单一模型可以翻译成多种语言，并从知识转移中获益，尤其是对于低资源语言。然而，大规模多语言模型受到多语言性的限制，除非进行大规模扩展，否则会增加训练和推理成本。稀疏的专家混合模型是一种在不需要大量计算的情况下大幅增加模型容量的方法。最近发布的NLLB-200是这样一个模型的例子。它涵盖了202种语言，但仅推理就需要至少四个32GB的GPU。在这项工作中，我们提出了一种修剪方法，允许删除多达80％的专家，但翻译质量几乎没有损失，这使得在单个32GB的GPU上运行该模型成为可能。进一步分析表明，我们的修剪度量指标可以识别出语言特定的专家

    Compared to conventional bilingual translation systems, massively multilingual machine translation is appealing because a single model can translate into multiple languages and benefit from knowledge transfer for low resource languages. On the other hand, massively multilingual models suffer from the curse of multilinguality, unless scaling their size massively, which increases their training and inference costs. Sparse Mixture-of-Experts models are a way to drastically increase model capacity without the need for a proportional amount of computing. The recently released NLLB-200 is an example of such a model. It covers 202 languages but requires at least four 32GB GPUs just for inference. In this work, we propose a pruning method that allows the removal of up to 80\% of experts with a negligible loss in translation quality, which makes it feasible to run the model on a single 32GB GPU. Further analysis suggests that our pruning metrics allow to identify language-specific experts and p
    
[^65]: 使用学习的规范化函数实现等变性

    Equivariance with Learned Canonicalization Functions. (arXiv:2211.06489v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.06489](http://arxiv.org/abs/2211.06489)

    本文提出了一种使用学习的规范化函数来实现等变性的方法，避免了对神经网络架构的限制。实验结果表明，学习规范化函数可以在多个任务中与现有技术相比具有竞争力，并且速度更快。

    

    基于对称性的神经网络通常通过限制架构来实现对一组变换的不变性或等变性。在本文中，我们提出了一种替代方法，通过学习产生数据的规范表示来避免这种架构约束。这些规范化函数可以直接插入非等变主干架构中。我们提供了一些感兴趣的群组的明确实现方法。我们表明，这种方法具有普适性，同时提供可解释的洞察力。我们的主要假设得到了我们的实证结果的支持，即学习一个小的神经网络来执行规范化优于使用预定义的启发式。我们的实验结果表明，学习规范化函数在许多任务中，包括图像分类、$N$体动力学预测、点云分类和部分分割等学习等变函数的现有技术相比具有竞争力，同时速度更快。

    Symmetry-based neural networks often constrain the architecture in order to achieve invariance or equivariance to a group of transformations. In this paper, we propose an alternative that avoids this architectural constraint by learning to produce canonical representations of the data. These canonicalization functions can readily be plugged into non-equivariant backbone architectures. We offer explicit ways to implement them for some groups of interest. We show that this approach enjoys universality while providing interpretable insights. Our main hypothesis, supported by our empirical results, is that learning a small neural network to perform canonicalization is better than using predefined heuristics. Our experiments show that learning the canonicalization function is competitive with existing techniques for learning equivariant functions across many tasks, including image classification, $N$-body dynamics prediction, point cloud classification and part segmentation, while being fas
    
[^66]: 宽度优先的流水线并行计算方法

    Breadth-First Pipeline Parallelism. (arXiv:2211.05953v2 [cs.DC] UPDATED)

    [http://arxiv.org/abs/2211.05953](http://arxiv.org/abs/2211.05953)

    宽度优先的流水线并行计算方法结合了流水线和数据并行计算，通过在每个GPU上使用小批量大小和完全分片的数据并行计算，以提高训练吞吐量。在实验中，与Megatron-LM相比，在一个520亿参数的模型上，使用小批量大小每个GPU的训练吞吐量增加了高达43%。

    

    我们引入了一种新的训练调度方法——宽度优先的流水线并行计算，该方法优化了流水线和数据并行计算的结合。宽度优先的流水线并行计算通过在每个GPU上使用较小的批量大小并结合完全分片的数据并行计算，实现了高GPU利用率、降低训练时间、成本和内存使用。实验证明，相对于Megatron-LM，对于一个520亿参数的模型，使用较小的批量大小每个GPU的训练吞吐量增加了高达43%，从而在大型GPU集群上将训练时间和成本同样降低了。

    We introduce Breadth-First Pipeline Parallelism, a novel training schedule which optimizes the combination of pipeline and data parallelism. Breadth-First Pipeline Parallelism lowers training time, cost and memory usage by combining a high GPU utilization with a small batch size per GPU, and by making use of fully sharded data parallelism. Experimentally, we observed an increase of up to 43% in training throughput for a 52 billion-parameter model using a small batch size per GPU compared to Megatron-LM, which would reduce the training time and cost by the same amount on a large GPU cluster.
    
[^67]: Topical: 使用Attention从源代码中学习存储库嵌入

    Topical: Learning Repository Embeddings from Source Code using Attention. (arXiv:2208.09495v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2208.09495](http://arxiv.org/abs/2208.09495)

    这篇论文介绍了Topical，一种使用深度神经网络从源代码中学习存储库级嵌入的方法，以实现代码自动生成、代码推荐和代码自动标记等功能。

    

    源代码的机器学习(MLOnCode)承诺改变软件交付的方式。通过挖掘软件工件之间的上下文和关系，MLOnCode通过代码自动生成、代码推荐、代码自动标记和其他数据驱动增强来增强软件开发人员的能力。对于许多任务来说，代码的脚本级表示已经足够，然而，在许多情况下，考虑到各种依赖关系和存储库结构的存储库级表示是必要的，例如，为存储库自动标记主题或自动记录存储库代码等。现有的计算存储库级表示的方法存在以下问题：(a) 依赖于代码的自然语言文档(例如README文件)；(b) 通过串联或平均等方法对方法/脚本级表示进行简单聚合。本文介绍了Topical，一种用于生成公共存储库级嵌入的深度神经网络。

    Machine learning on source code (MLOnCode) promises to transform how software is delivered. By mining the context and relationship between software artefacts, MLOnCode augments the software developers capabilities with code auto-generation, code recommendation, code auto-tagging and other data-driven enhancements. For many of these tasks a script level representation of code is sufficient, however, in many cases a repository level representation that takes into account various dependencies and repository structure is imperative, for example, auto-tagging repositories with topics or auto-documentation of repository code etc. Existing methods for computing repository level representations suffer from (a) reliance on natural language documentation of code (for example, README files) (b) naive aggregation of method/script-level representation, for example, by concatenation or averaging. This paper introduces Topical a deep neural network to generate repository level embeddings of publicly 
    
[^68]: GRAPHSHAP：通过模样式的语言解释基于身份感知的图分类器

    GRAPHSHAP: Explaining Identity-Aware Graph Classifiers Through the Language of Motifs. (arXiv:2202.08815v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.08815](http://arxiv.org/abs/2202.08815)

    GRAPHSHAP是一种基于Shapley值的方法，可以提供基于模样式的解释，用于解释基于身份感知的图分类器，而无需对模型或其训练数据有任何先验知识。

    

    大多数解释黑盒分类器的方法（例如在表格数据、图像或时间序列上）依赖于衡量删除/扰动特征对模型输出的影响。这要求解释语言与分类器的特征空间匹配。然而，在处理图数据时，基本特征对应于描述图结构的边，特征空间与解释语言之间的匹配可能不合适。为了为图分类任务开发可行的解释，将特征空间（边）与所需的高级解释语言（如模样式）解耦是一个重大挑战。在本文中，我们引入了一种基于Shapley值的方法GRAPHSHAP，能够为身份感知的图分类器提供基于模样式的解释，不需要对模型或其训练数据有任何先验知识：唯一的要求是可以任意查询黑盒分类器。

    Most methods for explaining black-box classifiers (e.g. on tabular data, images, or time series) rely on measuring the impact that removing/perturbing features has on the model output. This forces the explanation language to match the classifier's feature space. However, when dealing with graph data, in which the basic features correspond to the edges describing the graph structure, this matching between features space and explanation language might not be appropriate. Decoupling the feature space (edges) from a desired high-level explanation language (such as motifs) is thus a major challenge towards developing actionable explanations for graph classification tasks. In this paper we introduce GRAPHSHAP, a Shapley-based approach able to provide motif-based explanations for identity-aware graph classifiers, assuming no knowledge whatsoever about the model or its training data: the only requirement is that the classifier can be queried as a black-box at will. For the sake of computationa
    
[^69]: 基于模型的强化学习中遵循奖励的子任务

    Reward-Respecting Subtasks for Model-Based Reinforcement Learning. (arXiv:2202.03466v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.03466](http://arxiv.org/abs/2202.03466)

    论文提出了一种基于模型的强化学习的方法，通过添加奖励加成的子任务来发现选项，从而解决了以前方法中忽略原始奖励的问题。

    

    为了实现人工智能的远大目标，强化学习必须包括对抽象状态和时间的世界模型的规划。深度学习在状态抽象方面取得了进展，但时间抽象却很少被使用，尽管基于选项框架已经广泛发展了理论。其中一个原因是可能的选项空间很大，以前提出的选项发现方法没有考虑到选项模型在规划中的使用方式。通常通过提出子任务（例如达到瓶颈状态或最大化除奖励外的感知信号的累积和）来发现选项。解决每个子任务以生成一个选项，然后学习选项的模型并使其可用于规划过程。在大多数以前的研究中，子任务忽略了原始问题上的奖励，而我们提出的子任务使用原始奖励加上基于某个特征的奖励加成。

    To achieve the ambitious goals of artificial intelligence, reinforcement learning must include planning with a model of the world that is abstract in state and time. Deep learning has made progress with state abstraction, but temporal abstraction has rarely been used, despite extensively developed theory based on the options framework. One reason for this is that the space of possible options is immense, and the methods previously proposed for option discovery do not take into account how the option models will be used in planning. Options are typically discovered by posing subsidiary tasks, such as reaching a bottleneck state or maximizing the cumulative sum of a sensory signal other than reward. Each subtask is solved to produce an option, and then a model of the option is learned and made available to the planning process. In most previous work, the subtasks ignore the reward on the original problem, whereas we propose subtasks that use the original reward plus a bonus based on a fe
    
[^70]: 基于SPD流形的深度最优传输领域自适应

    Deep Optimal Transport for Domain Adaptation on SPD Manifolds. (arXiv:2201.05745v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.05745](http://arxiv.org/abs/2201.05745)

    这项研究介绍了一种基于深度最优传输的方法，用于解决在SPD流形上的领域自适应问题。通过利用最优传输理论和SPD流形的对数欧几里得几何，我们克服了协方差矩阵操作的复杂性挑战。

    

    近年来，机器学习界对于在对称正定（SPD）流形上解决领域自适应（DA）问题表现出了很大兴趣。这种兴趣源于医疗设备产生的复杂神经物理数据（如脑电图、脑磁图和扩散张量成像）在不同领域之间存在数据分布的偏移。这些数据表示以信号协方差矩阵的形式表示，并具有对称性和正定性的属性。然而，由于协方差矩阵的复杂操作特性，直接将先前的经验和解决方案应用于DA问题存在挑战。为了解决这个问题，我们的研究引入了一类基于深度学习的迁移学习方法，称为深度最优传输。这一类方法利用最优传输理论，并利用SPD流形的对数欧几里得几何。此外，我们还展示了...

    In recent years, there has been significant interest in solving the domain adaptation (DA) problem on symmetric positive definite (SPD) manifolds within the machine learning community. This interest stems from the fact that complex neurophysiological data generated by medical equipment, such as electroencephalograms, magnetoencephalograms, and diffusion tensor imaging, often exhibit a shift in data distribution across different domains. These data representations, represented by signal covariance matrices, possess properties of symmetry and positive definiteness. However, directly applying previous experiences and solutions to the DA problem poses challenges due to the manipulation complexities of covariance matrices.To address this, our research introduces a category of deep learning-based transfer learning approaches called deep optimal transport. This category utilizes optimal transport theory and leverages the Log-Euclidean geometry for SPD manifolds. Additionally, we present a com
    
[^71]: AI的创造力：用于促进深度强化学习的分层规划模型学习

    Creativity of AI: Hierarchical Planning Model Learning for Facilitating Deep Reinforcement Learning. (arXiv:2112.09836v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2112.09836](http://arxiv.org/abs/2112.09836)

    该论文提出了一种新颖的深度强化学习框架，通过在DRL中嵌入符号知识，解决了数据效率、解释性缺乏和可迁移性等关键问题。该框架通过循环训练过程，并利用学习的规划模型和符号选项来引导策略的改进。学到的符号选项减轻了对专家领域知识的要求，并提供了策略的内在可解释性，同时通过与符号规划模型的规划进一步提高了可迁移性和数据效率。

    

    尽管在实际应用中取得了巨大成功，但深度强化学习(DRL)仍然面临三个关键问题，即数据效率、解释性的缺乏和可迁移性。最近的研究显示，在DRL中嵌入符号知识有望解决这些挑战。受此启发，我们引入了一种新颖的具有符号选项的深度强化学习框架。我们的框架具有一个循环训练过程，通过与交互轨迹学习的规划模型（包括动作模型和分层任务网络模型）和符号选项来引导策略的改进。学到的符号选项减轻了对专家领域知识的要求，并提供了策略的内在可解释性。此外，通过与符号规划模型的规划，可进一步提高可迁移性和数据效率。

    Despite of achieving great success in real-world applications, Deep Reinforcement Learning (DRL) is still suffering from three critical issues, i.e., data efficiency, lack of the interpretability and transferability. Recent research shows that embedding symbolic knowledge into DRL is promising in addressing those challenges. Inspired by this, we introduce a novel deep reinforcement learning framework with symbolic options. Our framework features a loop training procedure, which enables guiding the improvement of policy by planning with planning models (including action models and hierarchical task network models) and symbolic options learned from interactive trajectories automatically. The learned symbolic options alleviate the dense requirement of expert domain knowledge and provide inherent interpretability of policies. Moreover, the transferability and data efficiency can be further improved by planning with the symbolic planning models. To validate the effectiveness of our framewor
    
[^72]: F2A2: 灵活完全去中心化的合作多智能体强化学习的近似演员-评论家算法

    F2A2: Flexible Fully-decentralized Approximate Actor-critic for Cooperative Multi-agent Reinforcement Learning. (arXiv:2004.11145v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2004.11145](http://arxiv.org/abs/2004.11145)

    本文提出了一个灵活完全分散化的演员-评论家多智能体强化学习框架，在大规模合作多智能体环境中，通过设计一个基于原始-对偶混合梯度下降的算法框架，可以分别学习每个智能体，并实现策略改进和价值评价。

    

    传统的中央集权的多智能体强化学习算法在复杂应用中有时不实用，因为智能体之间缺乏互动，存在维度灾难和计算复杂性。因此，出现了一些分散化的多智能体强化学习算法。然而，现有的分散化方法只能处理完全合作的设置，在训练过程中需要传输大量信息。传统的块坐标梯度下降方法可以简化计算，但会引起严重的偏差。本文提出了一个灵活的完全分散化的演员-评论家多智能体强化学习框架，可以组合大多数演员-评论家方法，并处理大规模一般合作多智能体环境。设计了一种基于原始-对偶混合梯度下降的算法框架，分别学习每个智能体来实现分散化。从每个智能体的角度来看，实现了策略改进和价值评价。

    Traditional centralized multi-agent reinforcement learning (MARL) algorithms are sometimes unpractical in complicated applications, due to non-interactivity between agents, curse of dimensionality and computation complexity. Hence, several decentralized MARL algorithms are motivated. However, existing decentralized methods only handle the fully cooperative setting where massive information needs to be transmitted in training. The block coordinate gradient descent scheme they used for successive independent actor and critic steps can simplify the calculation, but it causes serious bias. In this paper, we propose a flexible fully decentralized actor-critic MARL framework, which can combine most of actor-critic methods, and handle large-scale general cooperative multi-agent setting. A primal-dual hybrid gradient descent type algorithm framework is designed to learn individual agents separately for decentralization. From the perspective of each agent, policy improvement and value evaluatio
    

