# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes.](http://arxiv.org/abs/2308.12967) | NeO 360是一种用于稀疏视角合成户外场景的通用方法，通过捕获复杂的真实世界场景分布，使用混合的图像条件式三平面表示，实现了从单个或少数几个图像重建360度场景，并具有更好的效果和表达能力。 |
| [^2] | [DLIP: Distilling Language-Image Pre-training.](http://arxiv.org/abs/2308.12956) | 本文提出了DLIP，提取语言-图像预训练的方法，通过对不同模块的架构特性和不同模态的信息传递进行深入研究，探索了如何提取轻量级但性能优越的视觉-语言预训练模型。实验结果显示DLIP能达到最先进的准确性和效率平衡。 |
| [^3] | [Low-count Time Series Anomaly Detection.](http://arxiv.org/abs/2308.12925) | 本论文提出了一种解决低计数时间序列异常检测的方法。通过引入新的生成过程来创建包含异常片段的基准数据集，并通过理论和实证分析解释了常用算法在正常和异常片段之间的分布重叠问题。 |
| [^4] | [Evaluating the Vulnerabilities in ML systems in terms of adversarial attacks.](http://arxiv.org/abs/2308.12918) | 本研究评估了机器学习系统在面对对抗攻击时的漏洞，并讨论了漏洞可能的原因、对抗攻击与随机化示例的差异以及相关的道德问题。 |
| [^5] | [Language as Reality: A Co-Creative Storytelling Game Experience in 1001 Nights using Generative AI.](http://arxiv.org/abs/2308.12915) | 本文介绍了一款以生成AI为基础的合作性故事游戏《一千零一夜》，玩家通过与语言模型驱动的角色共同创作故事来引导游戏中的现实，挑战游戏世界与现实之间的传统边界。 |
| [^6] | [CDAN: Convolutional Dense Attention-guided Network for Low-light Image Enhancement.](http://arxiv.org/abs/2308.12902) | 本研究提出了一种名为CDAN的卷积稠密注意力引导网络，用于低光图像增强。该网络结合了自编码器架构、卷积和稠密块、注意力机制和跳跃连接，通过专门的后处理阶段进一步改善色彩平衡和对比度。与现有方法相比，在低光图像增强方面取得了显著的进展，展示了在各种具有挑战性的场景中的稳健性。 |
| [^7] | [Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language Pretraining?.](http://arxiv.org/abs/2308.12898) | 本论文研究了语言知识在多模态对齐中的作用，设计并发布了一个多模态对齐探测基准来检测关键的语言组成部分。 |
| [^8] | [Large Language Models Vote: Prompting for Rare Disease Identification.](http://arxiv.org/abs/2308.12890) | 本文提出了一种名为模型投票提示(MVP)的方法，用于改善在少样本学习(FSL)环境下大型语言模型(LLMs)的查询性能。MVP通过提示多个LLMs执行相同的任务，并对生成的输出进行多数投票，从而实现了对罕见病的识别和分类任务的改进。 |
| [^9] | [Inducing Causal Structure for Abstractive Text Summarization.](http://arxiv.org/abs/2308.12888) | 该论文提出了一种使用结构性因果模型来诱导抽象文本摘要中的因果结构的方法。通过引入因果关系，可以缓解训练数据中语言先验的干扰，进而提高摘要模型的效果。研究者还设计了一个因果启发式的序列到序列模型来学习因果表示，以指导摘要生成过程。 |
| [^10] | [FaceTouch: Detecting hand-to-face touch with supervised contrastive learning to assist in tracing infectious disease.](http://arxiv.org/abs/2308.12840) | 该论文提出了一个名为FaceTouch的计算机视觉框架，利用深度学习方法检测复杂场景下的手与脸接触，以帮助追踪传染病。FaceTouch通过学习人体动作和场景的RGB表示来检测面部接触，对于解决只能识别手的移动和与脸的接近的问题具有实用性。 |
| [^11] | [Short Run Transit Route Planning Decision Support System Using a Deep Learning-Based Weighted Graph.](http://arxiv.org/abs/2308.12828) | 提出了一种基于深度学习的短途公交线路规划决策支持系统，通过调整路线的特定部分，减少时间并提升公共交通服务。利用多样化的数据源，通过预测道路段的延迟值作为边权重，实现了快速路径规划决策。 |
| [^12] | [ICU Mortality Prediction Using Long Short-Term Memory Networks.](http://arxiv.org/abs/2308.12800) | 该论文通过使用长短期记忆网络分析床边监测产生的时间数据，成功构建了用于预测ICU患者死亡率和住院时间的系统。 |
| [^13] | [Job Shop Scheduling Benchmark: Environments and Instances for Learning and Non-learning Methods.](http://arxiv.org/abs/2308.12794) | 这个开源的GitHub仓库为机器调度问题提供了综合基准，包括多种环境和实例，为研究人员和从业者提供了一个集中的中心。 |
| [^14] | [Acquiring Qualitative Explainable Graphs for Automated Driving Scene Interpretation.](http://arxiv.org/abs/2308.12755) | 本文提出了一种定性可解释图(QXG)的表示方法，用于自动驾驶场景的解释。该方法通过定性时空推理构建图，能够实时计算，占用空间较少，并在实验中展示了良好的性能。 |
| [^15] | [Motion In-Betweening with Phase Manifolds.](http://arxiv.org/abs/2308.12751) | 本论文介绍了一种使用相位流形的动作插帧系统，通过学习相位变量和混合专家神经网络模型来生成目标姿势之间的连续姿势序列，同时可以满足动画师手动修改的姿势和末端效应器作为约束的要求。 |
| [^16] | [Separating the Human Touch from AI-Generated Text using Higher Criticism: An Information-Theoretic Approach.](http://arxiv.org/abs/2308.12747) | 本文提出了一种使用更高的批评力量将人类触摸与AI生成的文本分离的方法，通过多个困惑度测试和统计模型的结合，能够有效识别出可能被编辑的部分，并探讨了方法的有效性及相关挑战。 |
| [^17] | [Human Comprehensible Active Learning of Genome-Scale Metabolic Networks.](http://arxiv.org/abs/2308.12740) | 这项研究介绍了一种人类可理解的基因组规模代谢网络的主动学习方法，基于归纳逻辑编程(ILP)框架进行逻辑推理，并通过从实验中学习新的逻辑结构，以有效探索假设空间和指导实验设计。 |
| [^18] | [Asymmetric Co-Training with Explainable Cell Graph Ensembling for Histopathological Image Classification.](http://arxiv.org/abs/2308.12737) | 该论文提出了一个非对称协同训练框架，结合深度图卷积网络和卷积神经网络，用于多类别组织病理图像分类。通过嵌入细胞的形态和拓扑分布，这个框架提出了一种可以解释的方法，用于提高整个系统的可解释性。 |
| [^19] | [DeepLOC: Deep Learning-based Bone Pathology Localization and Classification in Wrist X-ray Images.](http://arxiv.org/abs/2308.12727) | 本文提出了一种基于深度学习的方法，利用YOLO和Swin模型实现手腕X射线图像中骨病理的定位和分类。该方法解决了准确定位和精确分类的两个关键挑战。 |
| [^20] | [Continuous Reinforcement Learning-based Dynamic Difficulty Adjustment in a Visual Working Memory Game.](http://arxiv.org/abs/2308.12726) | 本文提出了一种基于连续强化学习的动态难度调整方法，用于处理视觉工作记忆游戏中的复杂难度记忆问题。通过根据玩家的得分和上一轮游戏的难度量度来调整游戏难度，该方法在52位受试者的实验中得到了评估和比较。 |
| [^21] | [VIGC: Visual Instruction Generation and Correction.](http://arxiv.org/abs/2308.12714) | 本文提出了VIGC框架，使多模态大型语言模型能够生成和纠正视觉指令数据，解决了缺乏高质量调整数据的挑战。 |
| [^22] | [SayCanPay: Heuristic Planning with Large Language Models using Learnable Domain Knowledge.](http://arxiv.org/abs/2308.12682) | SayCanPay是一种结合了大型语言模型(LLMs)和启发式规划的方法，通过利用LLMs的世界知识和启发式搜索的原则，生成可行的最优计划。 |
| [^23] | [LR-XFL: Logical Reasoning-based Explainable Federated Learning.](http://arxiv.org/abs/2308.12681) | LR-XFL是一种基于逻辑推理的可解释联邦学习方法，通过将逻辑规则和模型更新结合起来，实现了对FL模型的解释性提升和加权聚合，并在相关基准测试中取得了较好的效果。 |
| [^24] | [Improving Translation Faithfulness of Large Language Models via Augmenting Instructions.](http://arxiv.org/abs/2308.12674) | 通过增强指令来提高大型语言模型的翻译真实性，我们提出了SWIE（分段加权指令嵌入）和一个指令遵循数据集OVERMISS，用于改善模型对指令的理解和提高模型的真实性。 |
| [^25] | [Don't Look into the Sun: Adversarial Solarization Attacks on Image Classifiers.](http://arxiv.org/abs/2308.12661) | 通过对图像进行曝光攻击，我们引入了一种简单而有效的方法来评估图像分类器的鲁棒性，并证明该攻击能够显著降低准确性。 |
| [^26] | [kTrans: Knowledge-Aware Transformer for Binary Code Embedding.](http://arxiv.org/abs/2308.12659) | kTrans是一种知识感知的二进制代码嵌入方法，通过将显式知识和隐式知识与Transformer模型结合，提供了一种将领域知识融入Transformer框架的新视角。它在二进制代码相似性检测、函数类型恢复和间接调用识别等任务中具有优异的表现。 |
| [^27] | [APART: Diverse Skill Discovery using All Pairs with Ascending Reward and DropouT.](http://arxiv.org/abs/2308.12649) | 本文提出了一个名为APART的方法，使用全组对判别器、新颖的内在奖励函数和丢弃技术，在无奖励环境中实现了多样化技能的发现。该方法具有更高的效率，并在简单的网格世界环境中发现了所有可能的技能。 |
| [^28] | [Advancing Hungarian Text Processing with HuSpaCy: Efficient and Accurate NLP Pipelines.](http://arxiv.org/abs/2308.12635) | 本文介绍了一套工业级匈牙利文本处理模型，利用HuSpaCy框架实现，通过多项改进在资源效率和准确性之间取得了接近最先进的性能。这些模型具备高准确性和吞吐量，并在所有基本文本处理步骤中展示了竞争性能。 |
| [^29] | [Towards Hierarchical Regional Transformer-based Multiple Instance Learning.](http://arxiv.org/abs/2308.12634) | 本文提出了一种基于变压器的多实例学习方法，通过使用区域自注意力机制，融合区域补丁信息以得出滑片级别预测，并通过堆叠区域聚合来分层处理特征。此外，引入了一种方法来聚焦于高关注区域，从而提高预测准确性。这种方法在组织病理学图像分类任务上表现出了显著的性能改进，并为进一步研究提供了有希望的方向。 |
| [^30] | [A Greedy Approach for Offering to Telecom Subscribers.](http://arxiv.org/abs/2308.12606) | 本论文提出了一个用于解决套餐优化问题的新颖组合算法，该算法针对电信运营商在选择激励套餐和目标用户时面临的困难进行了解决。 |
| [^31] | [APLA: Additional Perturbation for Latent Noise with Adversarial Training Enables Consistency.](http://arxiv.org/abs/2308.12605) | APLA是一种基于扩散模型的文本到视频生成网络结构，通过引入附加摄动的层噪声与对抗训练，解决了视频生成中一致性细节丢失的问题。 |
| [^32] | [SICNN: Soft Interference Cancellation Inspired Neural Network Equalizers.](http://arxiv.org/abs/2308.12591) | SICNN是基于神经网络的均衡方法，通过深度展开基于模型的迭代SIC方法来设计，消除了基于模型方法的缺点。 |
| [^33] | [A Huber Loss Minimization Approach to Byzantine Robust Federated Learning.](http://arxiv.org/abs/2308.12581) | 本文介绍了一种基于Huber损失最小化的新型聚合器用于拜占庭鲁棒的联邦学习。在独立同分布假设下，该方法具有与现有方法相比的优势，并对非i.i.d数据进行了扩展分析。 |
| [^34] | [Mind vs. Mouth: On Measuring Re-judge Inconsistency of Social Bias in Large Language Models.](http://arxiv.org/abs/2308.12578) | 本文研究了大型语言模型中的社会偏见，并发现了一种名为“重新判断不一致性”的现象，即在完成陈述和重新评判过程中存在矛盾。这对于理解语言模型的认知和隐含偏见具有重要意义。 |
| [^35] | [REB: Reducing Biases in Representation for Industrial Anomaly Detection.](http://arxiv.org/abs/2308.12577) | 本文提出了一种名为REB的方法，通过考虑领域偏差和构建自监督学习任务，以及使用本地密度K最近邻方法，从而降低工业异常检测中的表示偏差，并取得了显著的改进。 |
| [^36] | [Exploring the Integration Strategies of Retriever and Large Language Models.](http://arxiv.org/abs/2308.12574) | 本文通过探索不同的检索器和大型语言模型整合方法来增强答案生成，并发现常用的连接方法存在局限性。为了解决这个问题，本文提出了四种替代策略，包括两种单轮方法和两种多轮策略。 |
| [^37] | [Conditional Kernel Imitation Learning for Continuous State Environments.](http://arxiv.org/abs/2308.12573) | 本研究以连续状态空间环境为基础，仅凭观察到的行为进行仿真学习，无需访问转移动力学信息、奖励结构，或者任何额外的交互。 |
| [^38] | [A Co-training Approach for Noisy Time Series Learning.](http://arxiv.org/abs/2308.12551) | 本研究提出了一种用于嘈杂时间序列学习的协同训练方法，通过多视图学习来减轻数据噪声和损坏的影响，并在多个时间序列基准上超越现有方法。 |
| [^39] | [Synchronize Feature Extracting and Matching: A Single Branch Framework for 3D Object Tracking.](http://arxiv.org/abs/2308.12549) | 这个论文提出了一种单支架构SyncTrack，通过同步特征提取和匹配来简化3D物体跟踪中的Siamese网络，避免了多次转发编码器和引入额外参数。研究结果表明，在Transformer层中引入了一个新的Attention Points-Sampling策略（APST）进行特征采样。 |
| [^40] | [CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias.](http://arxiv.org/abs/2308.12539) | CALM是一个用于量化语言模型偏见的多任务基准数据集，相比先前数据集更加多样和可靠，能更好地捕捉评估模型偏见所需的语言变化的广度。 |
| [^41] | [FedSoL: Bridging Global Alignment and Local Generality in Federated Learning.](http://arxiv.org/abs/2308.12532) | FedSoL提出了一种联邦学习的方法，该方法旨在解决数据分布不均匀导致性能下降的问题。它通过平衡全局对齐和本地一般性来改善FL的学习效果。 |
| [^42] | [Not Only Rewards But Also Constraints: Applications on Legged Robot Locomotion.](http://arxiv.org/abs/2308.12517) | 本文提出了一种新的强化学习框架，为复杂机器人系统训练神经网络控制器。该框架引入了奖励和约束的概念，通过设计高效的策略优化算法来处理约束，以减少计算开销。通过应用于不同腿式机器人的运动控制器训练中，展示了该框架的有效性。 |
| [^43] | [I3DOD: Towards Incremental 3D Object Detection via Prompting.](http://arxiv.org/abs/2308.12512) | I3DOD是一种基于引导的增量式三维物体检测方法，通过引导机制学习对象定位信息和类别语义信息之间的匹配关系，解决了旧类的遗忘问题。 |
| [^44] | [Masked Autoencoders are Efficient Class Incremental Learners.](http://arxiv.org/abs/2308.12510) | 本论文提出了使用掩蔽自编码器(MAEs)作为高效的分类增量学习器，通过重建原始输入图像和学习图像级和嵌入级融合来存储和学习过去任务的表示。实验证实，在CIFAR-100，ImageNet-Subset和ImageNet-Full上，该方法优于现有最先进的方法。 |
| [^45] | [CGMI: Configurable General Multi-Agent Interaction Framework.](http://arxiv.org/abs/2308.12503) | 本研究提出了一个名为CGMI的框架，旨在模拟真实世界场景中的人际交往。该框架采用了树状结构方法来管理智能体的个性，并设计了一个基于ACT*模型的认知架构。通过使用CGMI框架，我们成功模拟了教师和学生之间的课堂互动。 |
| [^46] | [Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis.](http://arxiv.org/abs/2308.12495) | 通过无需源数据，使用多角度特征增强的方法提出了一种无源协作领域适应（SCDA）框架，用于静息态功能磁共振成像（rs-fMRI）分析。该方法能够减少不同扫描仪/协议导致的跨站点/领域数据异质性。 |
| [^47] | [GPTEval: A Survey on Assessments of ChatGPT and GPT-4.](http://arxiv.org/abs/2308.12488) | 本文对ChatGPT和GPT-4的先前评估进行了综合分析，关注其语言和推理能力、科学知识和伦理考虑，提出了几个评估大型语言模型的建议。 |
| [^48] | [A Model of Sequential Learning based on Non-Axiomatic Logic.](http://arxiv.org/abs/2308.12486) | 这个论文提出了一个基于非公理逻辑的顺序学习模型，用于智能代理的学习功能。它包含假设、修正和循环三个步骤，并在知识和资源不足的情况下工作。尽管有一些限制，但该模型已在一些简单案例中证明有效。 |
| [^49] | [Attention-Based Acoustic Feature Fusion Network for Depression Detection.](http://arxiv.org/abs/2308.12478) | 提出了一种新颖的基于注意力的声学特征融合网络（ABAFnet）用于抑郁症检测，能够有效整合和融合多种语音特征，提高检测性能。 |
| [^50] | [Are ChatGPT and GPT-4 Good Poker Players? -- A Pre-Flop Analysis.](http://arxiv.org/abs/2308.12466) | ChatGPT和GPT-4在扑克中显示出高级理解，但不是游戏论理最优的扑克玩家。对模型参数和提示的优化可以提高它们在扑克中的表现。 |
| [^51] | [PFL-GAN: When Client Heterogeneity Meets Generative Models in Personalized Federated Learning.](http://arxiv.org/abs/2308.12454) | PFL-GAN是一种在个性化联合学习中解决客户异质性的新型GAN共享和聚合策略，通过学习客户间的相似度并采用加权协同数据聚合方法来实现。 |
| [^52] | [Augmenting medical image classifiers with synthetic data from latent diffusion models.](http://arxiv.org/abs/2308.12453) | 使用潜在扩散模型生成的合成数据可提高医学图像分类器的性能，在数据受限的情况下表现出饱和效果，比添加真实图像获得的性能提升要小得多。 |
| [^53] | [An Intentional Forgetting-Driven Self-Healing Method For Deep Reinforcement Learning Systems.](http://arxiv.org/abs/2308.12445) | 本文提出了一种名为 Dr. DRL 的自愈方法，用于解决深度强化学习系统中的一些效率问题，该方法通过在连续学习中引入有意遗忘的机制来应对环境漂移引起的困扰。 |
| [^54] | [BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection.](http://arxiv.org/abs/2308.12439) | BaDExpert是一种防御后门攻击的新方法，通过逆向工程提取给定后门模型的后门功能，并生成一个专家模型，该模型只能识别后门输入。可以进一步使用该模型设计高度准确的后门输入检测器。 |
| [^55] | [Deploying Deep Reinforcement Learning Systems: A Taxonomy of Challenges.](http://arxiv.org/abs/2308.12438) | 本文通过对开发者问答论坛Stack Overflow上的帖子进行实证研究，总结了部署深度强化学习系统所面临的挑战，并针对不同的部署平台进行了分类。 |
| [^56] | [Reframing the Brain Age Prediction Problem to a More Interpretable and Quantitative Approach.](http://arxiv.org/abs/2308.12416) | 本论文提出了一种重塑脑龄预测问题的方法，将其转化为图像到图像的回归问题，通过估计每个脑部体素的脑龄来提供更可解释的结果。与全局年龄预测模型相比，逐体素年龄预测模型提供了更可解释的空间信息。 |
| [^57] | [Benchmarking Causal Study to Interpret Large Language Models for Source Code.](http://arxiv.org/abs/2308.12415) | 这项研究提出了一种用于源代码的大型语言模型的因果研究基准评估，以解决包括因果推断在内的模型性能可解释性的问题。 |
| [^58] | [A Theory of Intelligences: Concepts, Models, Implications.](http://arxiv.org/abs/2308.12411) | 这篇论文提出了一种智能的理论，讨论了智能的核心要素和挑战，并提出了基于第一原理的理论。研究重点是人类智能，并与机器进行比较，目的是为更广泛的生命、集合体和非设计的物理化学系统提供描述。 |
| [^59] | [Self-Supervised Learning for Endoscopic Video Analysis.](http://arxiv.org/abs/2308.12394) | 本研究研究了自监督学习在内窥镜视频分析中的应用，使用Masked Siamese Networks（MSNs）框架进行训练，并通过创建大规模未标记的视频数据集来充分利用自监督学习的能力。在有限标记数据的二次训练下，实现了内窥镜基准测试的最先进性能。 |
| [^60] | [Handling the inconsistency of systems of $\min\rightarrow$ fuzzy relational equations.](http://arxiv.org/abs/2308.12385) | 本文研究了$\min-\rightarrow$模糊关系方程组的不一致性，并给出了计算与该方程组相关的Chebyshev距离的分析公式。最终证明，在某些情况下，该距离可能为下确界，而在任何情况下都为最小值。 |
| [^61] | [With a Little Help from your own Past: Prototypical Memory Networks for Image Captioning.](http://arxiv.org/abs/2308.12383) | 本文提出了一种典型记忆网络，用于提取图像的语义并生成语义连贯的描述。通过在处理其他训练样本时执行注意力操作，该网络能够利用先前激活的信息。实验证明，该模型在COCO数据集上的性能优于其他基准模型和最先进方法。 |
| [^62] | [Inferring gender from name: a large scale performance evaluation study.](http://arxiv.org/abs/2308.12381) | 本研究评估了从姓名中推断性别的性能，该方法在没有性别信息的情况下是一种可行且广泛应用的方法。其重要性在于研究各种科学学科中对性别差异的模式和决定因素进行分析。 |
| [^63] | [Open-set Face Recognition with Neural Ensemble, Maximal Entropy Loss and Feature Augmentation.](http://arxiv.org/abs/2308.12371) | 本文介绍了一种新颖的方法，将一组紧凑的神经网络与基于边缘的成本函数相结合，通过探索附加样本来提高开放集人脸识别的准确性。该方法利用外部数据库获取辅助负样本或通过混合特征增强方法在训练过程中合成建立负样本。实验结果表明，该方法能够提升封闭集的准确性。 |
| [^64] | [SafeAR: Towards Safer Algorithmic Recourse by Risk-Aware Policies.](http://arxiv.org/abs/2308.12367) | 本文提出了一种更安全的算法补救方法（SafeAR），该方法通过考虑风险因素在计算和评估补救措施时，为那些受到机器学习模型决策不利影响的个体提供更可靠的建议。 |
| [^65] | [RemovalNet: DNN Fingerprint Removal Attacks.](http://arxiv.org/abs/2308.12319) | 本论文对DNN指纹去除攻击进行了全面的调查，并提出了一种名为RemovalNet的攻击方法，通过min-max双层优化来逃避模型所有权验证。攻击方法旨在去除指纹特定知识，并提取受害模型的通用语义知识来维持替代模型性能。 |
| [^66] | [Trustworthy Representation Learning Across Domains.](http://arxiv.org/abs/2308.12315) | 本论文首次提出了跨领域的可信表示学习框架，通过包括鲁棒性、隐私、公平性和可解释性等概念，对该研究方向进行了全面的文献综述。 |
| [^67] | [Physics informed Neural Networks applied to the description of wave-particle resonance in kinetic simulations of fusion plasmas.](http://arxiv.org/abs/2308.12312) | 本论文测试了物理信息神经网络（PINN）在描述等离子体融合动力学模拟中的波粒共振问题方面的适用性，提出了一种名为I-PINN的PINN变体，该方法基于自动微分和自动积分解决偏微分方程和积分方程。 |
| [^68] | [Modeling Bends in Popular Music Guitar Tablatures.](http://arxiv.org/abs/2308.12307) | 本文研究了流行音乐吉他谱中的弯音现象，并提出了一种通过分析弯音的过去和未来短期上下文来预测弯音发生的方法。实验证明这种方法具有良好的预测性能和应用前景。 |
| [^69] | [FedDAT: An Approach for Foundation Model Finetuning in Multi-Modal Heterogeneous Federated Learning.](http://arxiv.org/abs/2308.12305) | FedDAT是一种在多模态异构联邦学习中进行基础模型微调的方法，通过采用参数高效微调（PEFT）方法来减轻客户端计算负担和通信开销，并解决了数据异构性的问题。 |
| [^70] | [CLIPN for Zero-Shot OOD Detection: Teaching CLIP to Say No.](http://arxiv.org/abs/2308.12213) | 本文提出了一种名为CLIPN的方法，通过积极的语义提示和否定的语义提示，为CLIP赋予了区分OOD和ID样本的能力。 |
| [^71] | [A multiobjective continuation method to compute the regularization path of deep neural networks.](http://arxiv.org/abs/2308.12044) | 本文提出了一种多目标延续方法，用于计算深度神经网络的正则化路径，以解决DNNs中稀疏性和数值效率之间的冲突。 |
| [^72] | [Integrated Image and Location Analysis for Wound Classification: A Deep Learning Approach.](http://arxiv.org/abs/2308.11877) | 本研究提出了一种基于深度学习的多模态网络，结合图像和位置信息进行创伤分类，通过引入体部图谱系统提供精确的创伤位置标记，并在新颖的架构中整合多个模型以提高分类效果。 |
| [^73] | [Halo: Estimation and Reduction of Hallucinations in Open-Source Weak Large Language Models.](http://arxiv.org/abs/2308.11764) | 本文介绍了一种用于评估和减少开源弱大语言模型中幻觉问题的框架，并探索了知识注入和师生方法等技术来减轻低参数模型中的幻觉问题，实验结果表明，在挑战性领域中，这些模型的幻觉问题得到了减少。 |
| [^74] | [Dynamic Open Vocabulary Enhanced Safe-landing with Intelligence (DOVESEI).](http://arxiv.org/abs/2308.11471) | 本文提出了一种动态开放词汇增强的智能安全着陆系统，通过利用开放词汇图像分割的能力实现无人机的视觉伺服，适应不同场景且无需大量数据积累进行模型改进，可以处理100米高度的操作。 |
| [^75] | [Federated Learning in Big Model Era: Domain-Specific Multimodal Large Models.](http://arxiv.org/abs/2308.11217) | 本论文提出了一种多模态联邦学习框架，利用私有领域数据协同训练大型模型，以实现跨场景的智能服务。在大模型时代，该框架解决了异构数据、模型聚合、性能和成本权衡、数据隐私以及激励机制等方面的挑战。 |
| [^76] | [Visual Crowd Analysis: Open Research Problems.](http://arxiv.org/abs/2308.10677) | 本文深入探讨了可视化人群分析的六个主要领域，并概述了在未来工作中需要解决的关键问题，以确保自动人群监测领域的进展和繁荣。 |
| [^77] | [Metaverse: A Vision, Architectural Elements, and Future Directions for Scalable and Realtime Virtual Worlds.](http://arxiv.org/abs/2308.10559) | 元宇宙是一种可伸缩且实时的虚拟世界，它通过虚拟和增强现实技术拓展物理世界，使用户能够与真实和虚拟世界无缝交互。它对社交媒体、合作工作、市场营销、教学和个性化医疗等方面具有潜在影响。实现元宇宙在实时和大规模上的要求尚需进一步研究，以实现其可用性。 |
| [^78] | [MoCLIM: Towards Accurate Cancer Subtyping via Multi-Omics Contrastive Learning with Omics-Inference Modeling.](http://arxiv.org/abs/2308.09725) | 本论文介绍了一种名为MoCLIM的多组学对比学习框架，能够在癌症亚型划分中利用多组学数据的潜力，显著提高了数据的拟合度和亚型划分性能。 |
| [^79] | [DiagGPT: An LLM-based Chatbot with Automatic Topic Management for Task-Oriented Dialogue.](http://arxiv.org/abs/2308.08043) | DiagGPT将大型语言模型(LLMs)扩展到任务导向的对话场景，提供了在复杂诊断场景中主动提问和引导用户完成任务的能力。 |
| [^80] | [Open-set Face Recognition using Ensembles trained on Clustered Data.](http://arxiv.org/abs/2308.07445) | 本研究提出了一种使用在聚类数据上训练的集成模型进行开放集合人脸识别的方法，能够准确识别感兴趣的个体，同时有效处理陌生的面孔。实验结果表明即使在大规模图库中也能取得竞争性的性能。 |
| [^81] | [Natural Language is All a Graph Needs.](http://arxiv.org/abs/2308.07134) | 本论文提出了一种名为InstructGLM的结构化语言模型算法，该算法将大型语言模型与图表学习问题相结合，旨在探索是否可以用语言模型取代图神经网络作为图表的基础模型。 |
| [^82] | [Dealing with Small Annotated Datasets for Deep Learning in Medical Imaging: An Evaluation of Self-Supervised Pre-Training on CT Scans Comparing Contrastive and Masked Autoencoder Methods for Convolutional Models.](http://arxiv.org/abs/2308.06534) | 本研究评估了在医学影像领域使用自监督预训练方法的可行性，比较了共同对比学习和掩码自编码器方法在CT扫描卷积模型中的性能。 |
| [^83] | [Face Encryption via Frequency-Restricted Identity-Agnostic Attacks.](http://arxiv.org/abs/2308.05983) | 通过受限频率的身份不可知攻击进行人脸加密，解决了使用外部扰动加密人脸图像的隐私保护问题，并提出了一种弱黑盒场景下可行的解决方案。 |
| [^84] | [Developmental Bootstrapping of AIs.](http://arxiv.org/abs/2308.04586) | 传统的符号AI方法和深度学习AI方法无法满足创建强大和可信赖的AI的挑战，然而，发展脱靴法通过模仿人类儿童的能力发展过程，为创建稳健可靠的AI提供了希望。 |
| [^85] | [GridMM: Grid Memory Map for Vision-and-Language Navigation.](http://arxiv.org/abs/2307.12907) | 本文提出了GridMM，一种用于视觉与语言导航的自顶向下网格记忆图，从全局和局部视角有效地表示和结构化先前访问的环境。在多个数据集上进行的实验证明了该方法的优越性。 |
| [^86] | [A Video-based Detector for Suspicious Activity in Examination with OpenPose.](http://arxiv.org/abs/2307.11413) | 本研究提出了一种利用OpenPose框架和卷积神经网络(CNN)分析考试视频并高效有效地检测可疑活动的框架。 |
| [^87] | [Video-FocalNets: Spatio-Temporal Focal Modulation for Video Action Recognition.](http://arxiv.org/abs/2307.06947) | 本论文提出了一种名为视频焦点网络的视频识别架构，通过时空焦点调制来模拟局部和全局上下文，结合了Transformer和卷积设计的优点，既有效又高效。 |
| [^88] | [DoReMi: Grounding Language Model by Detecting and Recovering from Plan-Execution Misalignment.](http://arxiv.org/abs/2307.00329) | DoReMi是一种新颖的语言模型基础架构，通过检测和修复计划与执行之间的不一致性来实现语言模型的基础。该架构利用视觉问答模型检查约束条件以发现不一致，并调用语言模型进行重新规划以实现恢复。 |
| [^89] | [Multi-modal Pre-training for Medical Vision-language Understanding and Generation: An Empirical Study with A New Benchmark.](http://arxiv.org/abs/2306.06494) | 本文通过研究关键因素，提供了医疗视觉语言预训练的全面实证分析，并提出了一个新的医学图像-文本数据集作为预训练数据或新的基准，为医学报告生成和图像-文本检索任务提供了强有力的支持。 |
| [^90] | [LANISTR: Multimodal Learning from Structured and Unstructured Data.](http://arxiv.org/abs/2305.16556) | LANISTR是一个新颖的基于注意力机制的框架，可从结构化和非结构化数据中进行学习，在挑战性数据集上表现优异。 |
| [^91] | [PruMUX: Augmenting Data Multiplexing with Model Compression.](http://arxiv.org/abs/2305.14706) | PruMUX是一种结合了结构化剪枝和数据复用的方法，可在保持准确性的情况下提高BERT-base模型的吞吐量。Auto-PruMUX可以预测修剪和复用的高性能参数，从而提供了一个实用的自动化工具。 |
| [^92] | [Structure-CLIP: Enhance Multi-modal Language Representations with Structure Knowledge.](http://arxiv.org/abs/2305.06152) | Structure-CLIP使用文本中的结构化知识，使用场景图强化多模态语言表示，从而在图像-文本匹配任务中展现了更好的性能。 |
| [^93] | [Positive AI: Key Challenges for Designing Wellbeing-aligned Artificial Intelligence.](http://arxiv.org/abs/2304.12241) | 设计以幸福为导向的人工智能系统面临着知识和动机两方面的挑战，包括概念化、测量和优化幸福，设计适当的AI行动，以及激励措施、财务和宣传风险的不一致以及数据获取的缺乏。针对这些挑战，需要在科学理解AI系统对幸福影响方面进行研究，并指导设计行动。 |
| [^94] | [HyperTab: Hypernetwork Approach for Deep Learning on Small Tabular Datasets.](http://arxiv.org/abs/2304.03543) | HyperTab是一种基于超网络结合了随机森林和神经网络优点的小型表格数据深度学习方法，使用每个特定低维视图处理数据，虚拟增加训练样本数量，避免过度拟合。 |
| [^95] | [Synthesize Extremely High-dimensional Longitudinal Electronic Health Records via Hierarchical Autoregressive Language Model.](http://arxiv.org/abs/2304.02169) | 此论文提出了一种名为HALO的方法，它是一个层级自回归模型，可以生成高保真、细粒度电子健康记录数据，而这些数据可以用于训练准确的ML模型，且无需涉及隐私问题。 |
| [^96] | [Pluralistic Aging Diffusion Autoencoder.](http://arxiv.org/abs/2303.11086) | 本文提出了一种多元化老化扩散自编码器（PADA），通过扩散模型生成多样的低层老化细节，并使用概率老化嵌入（PAE）捕捉多样的高层老化模式。实验证明该方法能够产生更多样和高质量的老化效果。 |
| [^97] | [Anderson Acceleration For Bioinformatics-Based Machine Learning.](http://arxiv.org/abs/2302.00347) | 这项研究在经典机器学习分类器中探索了Anderson加速的有效性，并通过使用AA，达到了显著提高收敛速度和减小训练误差的效果。 |
| [^98] | [BallGAN: 3D-aware Image Synthesis with a Spherical Background.](http://arxiv.org/abs/2301.09091) | BallGAN是一个新颖的3D感知GAN框架，通过将背景近似为球形表面，并使用特定约束来减少背景自由度，可以产生更合理的3D几何。 |
| [^99] | [Efficient data transport over multimode light-pipes with Megapixel images using differentiable ray tracing and Machine-learning.](http://arxiv.org/abs/2301.06496) | 本研究利用可微分光线追踪和机器学习的方法，在多模光导管中实现了对Megapixel图像的高效传输，通过使用数字孪生和U-Net结合，减少了解码的计算复杂度，并比较了不同模式的性能差异。最终实现了对大规模数字图像的解码和检索，为光学存储应用提供了重要的技术支持。 |
| [^100] | [DexBERT: Effective, Task-Agnostic and Fine-grained Representation Learning of Android Bytecode.](http://arxiv.org/abs/2212.05976) | DexBERT是一项研究Android字节码的有效、任务无关和精细化表示学习的工作，旨在捕捉信息以适用于各种低级下游任务。 |
| [^101] | [Regulating Gatekeeper AI and Data: Transparency, Access, and Fairness under the DMA, the GDPR, and beyond.](http://arxiv.org/abs/2212.04997) | 数字市场法规定了对人工智能应用的欧盟规则，其对披露要求、人工智能训练数据的管理、访问规则和公平排名制度具有广泛而有效的影响。 |
| [^102] | [Neural Fourier Filter Bank.](http://arxiv.org/abs/2212.01735) | 该论文提出了一个新的神经傅里叶滤波器组方法，该方法既在空间上又在频率上分解信号，通过使用傅里叶编码特定频率来存储每个网格，这一方法在2D图像拟合、3D形状重建和神经辐射场等多个任务上，表现出优于现有技术的模型紧凑性和收敛速度。 |
| [^103] | [Farm-wide virtual load monitoring for offshore wind structures via Bayesian neural networks.](http://arxiv.org/abs/2211.00642) | 该论文介绍了一种基于贝叶斯神经网络的全场虚拟负载监测方案，以解决离岸风电结构监测的不确定性和实际限制问题。 |
| [^104] | [Improving Semantic Matching through Dependency-Enhanced Pre-trained Model with Adaptive Fusion.](http://arxiv.org/abs/2210.08471) | 本文提出了一种依赖增强的自适应融合注意力模型，它将依赖信息与原始语义信号自适应融合，以更好地模拟复杂的语义匹配关系。 |
| [^105] | [Improving Sample Quality of Diffusion Models Using Self-Attention Guidance.](http://arxiv.org/abs/2210.00939) | 该论文提出了一种利用自注意力指导的策略来提升扩散模型生成图像的稳定性和质量，具有较高的实用价值。 |
| [^106] | [Augmenting Reinforcement Learning with Transformer-based Scene Representation Learning for Decision-making of Autonomous Driving.](http://arxiv.org/abs/2208.12263) | 本研究提出了Scene-Rep Transformer来提升强化学习决策能力，通过改进场景表示编码和顺序预测潜在蒸馏。采用多阶段Transformer编码器建模交互意识和意图意识，并使用顺序潜在Transformer进行自监督学习，加速训练和减少探索空间。 |
| [^107] | [Test-Time Adaptation for Visual Document Understanding.](http://arxiv.org/abs/2206.07240) | 该论文提出了一种测试时间自适应方法，用于将自监督预训练得到的表示适应到测试时的分布转移。通过利用跨模态自监督学习和伪标签方法，该方法在文档理解任务中实现了显著的改进，并在实体识别、键值提取和文档视觉问答上分别提高了1.89%、3.43%和17.68%。 |
| [^108] | [Leveraging Global Binary Masks for Structure Segmentation in Medical Images.](http://arxiv.org/abs/2205.09107) | 这篇论文提出了利用全局二进制掩码来进行医学图像中结构分割的方法，通过利用器官的解剖形状和位置信息的一致性来进行分割。研究了两种情况下的应用，并在脑部和心脏CT图像数据集上进行了验证。 |
| [^109] | [MonoDETR: Depth-guided Transformer for Monocular 3D Object Detection.](http://arxiv.org/abs/2203.13310) | 本文介绍了一种名为MonoDETR的深度引导Transformer框架，用于单目3D目标检测。相比于传统的方法，MonoDETR通过引入深度信息来指导整个检测过程，提高了对场景的理解和目标的准确性。 |
| [^110] | [The Interpretability of LSTM Models for Predicting Oil Company Stocks: impacts of correlated features.](http://arxiv.org/abs/2201.00350) | 研究探究了相关特征对用于预测石油公司股票的LSTM模型的可解释性的影响。结果表明，添加与石油股票相关的特征并不会提高LSTM模型的可解释性，因此应谨慎依靠LSTM模型进行股票市场决策。 |

# 详细

[^1]: NeO 360: 用于稀疏视角合成户外场景的神经场

    NeO 360: Neural Fields for Sparse View Synthesis of Outdoor Scenes. (arXiv:2308.12967v1 [cs.CV])

    [http://arxiv.org/abs/2308.12967](http://arxiv.org/abs/2308.12967)

    NeO 360是一种用于稀疏视角合成户外场景的通用方法，通过捕获复杂的真实世界场景分布，使用混合的图像条件式三平面表示，实现了从单个或少数几个图像重建360度场景，并具有更好的效果和表达能力。

    

    最近的隐式神经表示方法在新视角合成方面取得了很好的结果。然而，现有方法需要在许多视角下进行昂贵的场景优化，从而限制了它们在真实世界无限制的城市环境中的应用，其中感兴趣的对象或背景只从很少的视角观察到。为了解决这个挑战，我们引入了一种名为NeO 360的新方法，用于稀疏视角合成户外场景。NeO 360是一种通用的方法，可以从单个或少数几个位置的RGB图像重建360度场景。我们方法的核心在于捕获复杂的真实世界户外三维场景的分布，并使用一种混合的图像条件式三平面表示，可以从任何世界点查询。我们的表示方法结合了体素和鸟瞰图表示的优点，比每种表示方法更有效和表达能力更强。NeO 360的表示方法允许我们从一个庞大的无限制的三维数据集中进行学习。

    Recent implicit neural representations have shown great results for novel view synthesis. However, existing methods require expensive per-scene optimization from many views hence limiting their application to real-world unbounded urban settings where the objects of interest or backgrounds are observed from very few views. To mitigate this challenge, we introduce a new approach called NeO 360, Neural fields for sparse view synthesis of outdoor scenes. NeO 360 is a generalizable method that reconstructs 360{\deg} scenes from a single or a few posed RGB images. The essence of our approach is in capturing the distribution of complex real-world outdoor 3D scenes and using a hybrid image-conditional triplanar representation that can be queried from any world point. Our representation combines the best of both voxel-based and bird's-eye-view (BEV) representations and is more effective and expressive than each. NeO 360's representation allows us to learn from a large collection of unbounded 3D
    
[^2]: DLIP: 提取语言-图像预训练的方法

    DLIP: Distilling Language-Image Pre-training. (arXiv:2308.12956v1 [cs.CV])

    [http://arxiv.org/abs/2308.12956](http://arxiv.org/abs/2308.12956)

    本文提出了DLIP，提取语言-图像预训练的方法，通过对不同模块的架构特性和不同模态的信息传递进行深入研究，探索了如何提取轻量级但性能优越的视觉-语言预训练模型。实验结果显示DLIP能达到最先进的准确性和效率平衡。

    

    视觉-语言预训练 (VLP) 在极重的参数辅助下取得了显著进展，但这也给其在实际应用中的部署带来了挑战。知识提取作为模型压缩中的重要过程被广泛认可。然而，现有的知识提取技术对于VLP的深入调查和分析还不够，并且VLP导向的提取实践指南尚未被探索。在本文中，我们提出了DLIP，一个简单而高效的提取语言-图像预训练框架，通过它我们研究如何提取一个轻量级的VLP模型。具体地，我们从多个维度剖析了模型提取，如不同模块的架构特性和不同模态的信息传递。我们进行了全面的实验，并对如何提取轻量级但性能优越的VLP模型提供了深刻的见解。实验结果表明，DLIP在准确性和效率的权衡上达到了最先进水平。

    Vision-Language Pre-training (VLP) shows remarkable progress with the assistance of extremely heavy parameters, which challenges deployment in real applications. Knowledge distillation is well recognized as the essential procedure in model compression. However, existing knowledge distillation techniques lack an in-depth investigation and analysis of VLP, and practical guidelines for VLP-oriented distillation are still not yet explored. In this paper, we present DLIP, a simple yet efficient Distilling Language-Image Pre-training framework, through which we investigate how to distill a light VLP model. Specifically, we dissect the model distillation from multiple dimensions, such as the architecture characteristics of different modules and the information transfer of different modalities. We conduct comprehensive experiments and provide insights on distilling a light but performant VLP model. Experimental results reveal that DLIP can achieve a state-of-the-art accuracy/efficiency trade-o
    
[^3]: 低计数时间序列异常检测

    Low-count Time Series Anomaly Detection. (arXiv:2308.12925v1 [cs.LG])

    [http://arxiv.org/abs/2308.12925](http://arxiv.org/abs/2308.12925)

    本论文提出了一种解决低计数时间序列异常检测的方法。通过引入新的生成过程来创建包含异常片段的基准数据集，并通过理论和实证分析解释了常用算法在正常和异常片段之间的分布重叠问题。

    

    低计数时间序列描述稀疏或间断事件，这在捕获和监控不同数据类型的大规模在线平台中很常见。建模低计数时间序列面临几个挑战，特别是低信噪比（当异常签名无法检测时）和非均匀性能（平均度量指标不能代表局部行为）。当前的时间序列异常检测领域缺乏明确的工具和流程来建模和可靠地检测这些情况下的异常。为了解决这个问题，我们引入了一种新的生成过程，用于创建包含有异常片段的低计数时间序列的基准数据集。通过理论和实证分析的混合，我们的工作解释了常用算法在正常和异常片段之间的分布重叠中遇到的困难。为了减轻这个缺点，我们利用我们的发现来展示如何进行异常检测。

    Low-count time series describe sparse or intermittent events, which are prevalent in large-scale online platforms that capture and monitor diverse data types. Several distinct challenges surface when modelling low-count time series, particularly low signal-to-noise ratios (when anomaly signatures are provably undetectable), and non-uniform performance (when average metrics are not representative of local behaviour). The time series anomaly detection community currently lacks explicit tooling and processes to model and reliably detect anomalies in these settings. We address this gap by introducing a novel generative procedure for creating benchmark datasets comprising of low-count time series with anomalous segments. Via a mixture of theoretical and empirical analysis, our work explains how widely-used algorithms struggle with the distribution overlap between normal and anomalous segments. In order to mitigate this shortcoming, we then leverage our findings to demonstrate how anomaly sc
    
[^4]: 评估机器学习系统在对抗攻击方面的漏洞

    Evaluating the Vulnerabilities in ML systems in terms of adversarial attacks. (arXiv:2308.12918v1 [cs.LG])

    [http://arxiv.org/abs/2308.12918](http://arxiv.org/abs/2308.12918)

    本研究评估了机器学习系统在面对对抗攻击时的漏洞，并讨论了漏洞可能的原因、对抗攻击与随机化示例的差异以及相关的道德问题。

    

    最近出现了一些难以发现的对抗攻击。这些新的对抗攻击方法可能对当前的深度学习网络防御系统构成挑战，并可能影响未来网络攻击的防御。本研究论文作者专注于这个领域。他们探讨了AI系统的漏洞带来的后果。这包括讨论漏洞可能发生的原因，随机化和对抗性示例之间的差异，以及漏洞可能引发的道德问题。此外，当AI系统处于测试阶段并准备进行更广泛的使用时，适当进行针对性的训练是至关重要的。

    There have been recent adversarial attacks that are difficult to find. These new adversarial attacks methods may pose challenges to current deep learning cyber defense systems and could influence the future defense of cyberattacks. The authors focus on this domain in this research paper. They explore the consequences of vulnerabilities in AI systems. This includes discussing how they might arise, differences between randomized and adversarial examples and also potential ethical implications of vulnerabilities. Moreover, it is important to train the AI systems appropriately when they are in testing phase and getting them ready for broader use.
    
[^5]: 以生成AI为基础的合作性故事游戏体验：在《一千零一夜》中的语言作为现实

    Language as Reality: A Co-Creative Storytelling Game Experience in 1001 Nights using Generative AI. (arXiv:2308.12915v1 [cs.HC])

    [http://arxiv.org/abs/2308.12915](http://arxiv.org/abs/2308.12915)

    本文介绍了一款以生成AI为基础的合作性故事游戏《一千零一夜》，玩家通过与语言模型驱动的角色共同创作故事来引导游戏中的现实，挑战游戏世界与现实之间的传统边界。

    

    本文介绍了一款名为《一千零一夜》的AI本地化游戏，通过与由大型语言模型驱动的角色共同创作故事，玩家可以引导游戏中的现实。该概念受到维特根斯坦关于语言界限决定一个人世界界限的思想的启发。使用GPT-4和稳定扩散等先进的AI工具，游戏的第二次迭代使得主角沙赫拉萨德能够在她的世界中实现文字和故事。玩家可以与AI国王进行对话，引导对特定关键词的讨论，这些关键词随后成为游戏中的战斗装备。这种互动叙事和文本到图像转换的结合通过双重视角挑战了游戏世界与现实之间的传统边界。我们关注的是试图改变自己命运的沙赫拉萨德，以及与AI合作创作故事并塑造游戏世界的玩家。我们探索了实现这一概念的技术和设计要素。

    In this paper, we present "1001 Nights", an AI-native game that allows players lead in-game reality through co-created storytelling with the character driven by large language model. The concept is inspired by Wittgenstein's idea of the limits of one's world being determined by the bounds of their language. Using advanced AI tools like GPT-4 and Stable Diffusion, the second iteration of the game enables the protagonist, Shahrzad, to realize words and stories in her world. The player can steer the conversation with the AI King towards specific keywords, which then become battle equipment in the game. This blend of interactive narrative and text-to-image transformation challenges the conventional border between the game world and reality through a dual perspective. We focus on Shahrzad, who seeks to alter her fate compared to the original folklore, and the player, who collaborates with AI to craft narratives and shape the game world. We explore the technical and design elements of implem
    
[^6]: CDAN: 用于低光图像增强的卷积稠密注意力引导网络

    CDAN: Convolutional Dense Attention-guided Network for Low-light Image Enhancement. (arXiv:2308.12902v1 [cs.CV])

    [http://arxiv.org/abs/2308.12902](http://arxiv.org/abs/2308.12902)

    本研究提出了一种名为CDAN的卷积稠密注意力引导网络，用于低光图像增强。该网络结合了自编码器架构、卷积和稠密块、注意力机制和跳跃连接，通过专门的后处理阶段进一步改善色彩平衡和对比度。与现有方法相比，在低光图像增强方面取得了显著的进展，展示了在各种具有挑战性的场景中的稳健性。

    

    低光图像以不足的照明为特征，面临清晰度减弱、颜色暗淡和细节减少的挑战。低光图像增强是计算机视觉中的一个重要任务，旨在通过改善亮度、对比度和整体感知质量来纠正这些问题，从而促进准确的分析和解释。本文介绍了一种新颖的解决方案：卷积稠密注意力引导网络（CDAN），用于增强低光图像。CDAN将自编码器架构与卷积和稠密块相结合，配合注意力机制和跳跃连接。该架构确保了有效的信息传递和特征学习。此外，专门的后处理阶段可以进一步改善色彩平衡和对比度。与低光图像增强领域的最新成果相比，我们的方法取得了显著的进展，并展示了在各种具有挑战性的场景中的稳健性。

    Low-light images, characterized by inadequate illumination, pose challenges of diminished clarity, muted colors, and reduced details. Low-light image enhancement, an essential task in computer vision, aims to rectify these issues by improving brightness, contrast, and overall perceptual quality, thereby facilitating accurate analysis and interpretation. This paper introduces the Convolutional Dense Attention-guided Network (CDAN), a novel solution for enhancing low-light images. CDAN integrates an autoencoder-based architecture with convolutional and dense blocks, complemented by an attention mechanism and skip connections. This architecture ensures efficient information propagation and feature learning. Furthermore, a dedicated post-processing phase refines color balance and contrast. Our approach demonstrates notable progress compared to state-of-the-art results in low-light image enhancement, showcasing its robustness across a wide range of challenging scenarios. Our model performs 
    
[^7]: 语言知识能改进视觉-语言预训练中的多模态对齐吗？

    Can Linguistic Knowledge Improve Multimodal Alignment in Vision-Language Pretraining?. (arXiv:2308.12898v1 [cs.MM])

    [http://arxiv.org/abs/2308.12898](http://arxiv.org/abs/2308.12898)

    本论文研究了语言知识在多模态对齐中的作用，设计并发布了一个多模态对齐探测基准来检测关键的语言组成部分。

    

    多媒体领域对通过多模态预训练神经网络模型感知和表达物理世界展现出了强烈的兴趣，其中视觉-语言相关的研究是当前最吸引人的话题之一。然而，目前对以下两个问题的探索非常有限：1）在视觉-语言预训练中是否可以提取关键的语言知识（如语义和句法），2）这种语言知识如何影响或增强多模态对齐。因此，本文旨在阐明全面的语言知识，包括语义表达和句法结构，对多模态对齐的影响。具体而言，我们设计并发布了SNARE，第一个大规模的多模态对齐探测基准，来检测关键的语言组成部分，如词汇、语义和句法知识，包含了四个任务：语义结构、否定逻辑、属性归属和关系组合。基于我们的实验结果，我们证明了.....

    The multimedia community has shown a significant interest in perceiving and representing the physical world with multimodal pretrained neural network models, and among them, the visual-language pertaining (VLP) is, currently, the most captivating topic. However, there have been few endeavors dedicated to the exploration of 1) whether essential linguistic knowledge (e.g., semantics and syntax) can be extracted during VLP, and 2) how such linguistic knowledge impact or enhance the multimodal alignment. In response, here we aim to elucidate the impact of comprehensive linguistic knowledge, including semantic expression and syntactic structure, on multimodal alignment. Specifically, we design and release the SNARE, the first large-scale multimodal alignment probing benchmark, to detect the vital linguistic components, e.g., lexical, semantic, and syntax knowledge, containing four tasks: Semantic structure, Negation logic, Attribute ownership, and Relationship composition. Based on our prop
    
[^8]: 大型语言模型的投票：用于罕见病识别的提示

    Large Language Models Vote: Prompting for Rare Disease Identification. (arXiv:2308.12890v1 [cs.CL])

    [http://arxiv.org/abs/2308.12890](http://arxiv.org/abs/2308.12890)

    本文提出了一种名为模型投票提示(MVP)的方法，用于改善在少样本学习(FSL)环境下大型语言模型(LLMs)的查询性能。MVP通过提示多个LLMs执行相同的任务，并对生成的输出进行多数投票，从而实现了对罕见病的识别和分类任务的改进。

    

    生成式大型语言模型(LLMs)的出现强调了准确和高效的提示方法的需求。LLMs经常应用于少样本学习(FSL)的情境中，这里任务只使用很少的训练数据执行。FSL在许多人工智能(AI)子领域中变得流行，包括用于健康的AI。罕见病影响人口的一小部分，在数据可用性受限的情况下 inherently 需要FSL技术，尽管人工数据收集和标注费时费力。在本文中，我们提出了模型投票提示(MVP)，这是一种用于改善FSL环境中LLM查询性能的灵活提示方法。MVP通过提示多个LLMs执行相同的任务，然后对生成的输出进行多数投票来实现。该方法在单次罕见病识别和分类任务中相对于任何单个模型在集成模型中实现了改进的结果。我们还发布了一个新颖的罕见病数据集用于FSL。

    The emergence of generative Large Language Models (LLMs) emphasizes the need for accurate and efficient prompting approaches. LLMs are often applied in Few-Shot Learning (FSL) contexts, where tasks are executed with minimal training data. FSL has become popular in many Artificial Intelligence (AI) subdomains, including AI for health. Rare diseases, affecting a small fraction of the population, inherently require FSL techniques due to limited data availability, though manual data collection and annotation is costly and time-consuming. In this paper, we propose Models-Vote Prompting (MVP), a flexible prompting approach for improving the performance of LLM queries in FSL settings. MVP works by prompting numerous LLMs to perform the same tasks and then conducting a majority vote on the resulting outputs. This method achieves improved results to any one model in the ensemble on one-shot rare disease identification and classification tasks. We also release a novel rare disease dataset for FS
    
[^9]: 诱导因果结构进行抽象文本摘要

    Inducing Causal Structure for Abstractive Text Summarization. (arXiv:2308.12888v1 [cs.CL])

    [http://arxiv.org/abs/2308.12888](http://arxiv.org/abs/2308.12888)

    该论文提出了一种使用结构性因果模型来诱导抽象文本摘要中的因果结构的方法。通过引入因果关系，可以缓解训练数据中语言先验的干扰，进而提高摘要模型的效果。研究者还设计了一个因果启发式的序列到序列模型来学习因果表示，以指导摘要生成过程。

    

    数据驱动的抽象摘要模型主要探索相关性而非因果关系。在这些相关性中，可能存在受训练语料库中的语言先验干扰的伪相关性，从而削弱了学习模型的整体效果。为解决这个问题，我们引入了一个结构性因果模型（SCM）来诱导摘要数据的潜在因果结构。我们假设存在几个潜在的因果因素和非因果因素，分别表示文档和摘要的内容和风格。理论上，我们证明了在某些条件下，我们的SCM中的潜在因素可以通过拟合观察到的训练数据来识别出来。基于此，我们提出了一个因果启发式的序列到序列模型（CI-Seq2Seq），用于学习能够模拟因果因素的因果表示，指导我们获取用于生成摘要的因果信息。关键思想是重新构造Va模型，以引入因果关系。

    The mainstream of data-driven abstractive summarization models tends to explore the correlations rather than the causal relationships. Among such correlations, there can be spurious ones which suffer from the language prior learned from the training corpus and therefore undermine the overall effectiveness of the learned model. To tackle this issue, we introduce a Structural Causal Model (SCM) to induce the underlying causal structure of the summarization data. We assume several latent causal factors and non-causal factors, representing the content and style of the document and summary. Theoretically, we prove that the latent factors in our SCM can be identified by fitting the observed training data under certain conditions. On the basis of this, we propose a Causality Inspired Sequence-to-Sequence model (CI-Seq2Seq) to learn the causal representations that can mimic the causal factors, guiding us to pursue causal information for summary generation. The key idea is to reformulate the Va
    
[^10]: FaceTouch: 利用监督对比学习检测手与脸接触，以帮助追踪传染病

    FaceTouch: Detecting hand-to-face touch with supervised contrastive learning to assist in tracing infectious disease. (arXiv:2308.12840v1 [cs.CV])

    [http://arxiv.org/abs/2308.12840](http://arxiv.org/abs/2308.12840)

    该论文提出了一个名为FaceTouch的计算机视觉框架，利用深度学习方法检测复杂场景下的手与脸接触，以帮助追踪传染病。FaceTouch通过学习人体动作和场景的RGB表示来检测面部接触，对于解决只能识别手的移动和与脸的接近的问题具有实用性。

    

    通过我们的呼吸系统，许多病毒和疾病经常在人与人之间传播。COVID-19是一个示例，展示了追踪和减少接触以阻止病毒传播的重要性。在寻找能够在复杂的城市场景或室内检测手与脸接触的自动方法方面存在明显的差距。在本文中，我们引入了一个基于深度学习的计算机视觉框架，名为FaceTouch。它包括了用于检测人体和分析其动作的深度子模型。FaceTouch旨在检测野外环境中的手与脸接触，例如视频聊天、公交车摄像头或闭路电视。尽管面部部分遮挡，该系统通过利用场景的RGB表示以及身体手势（如手臂运动）的表示学习检测面部接触。这已经在复杂的城市场景中证明了对于仅仅识别手的移动和其与脸的接近之外的实用性。在监督对比学习的基础上。

    Through our respiratory system, many viruses and diseases frequently spread and pass from one person to another. Covid-19 served as an example of how crucial it is to track down and cut back on contacts to stop its spread. There is a clear gap in finding automatic methods that can detect hand-to-face contact in complex urban scenes or indoors. In this paper, we introduce a computer vision framework, called FaceTouch, based on deep learning. It comprises deep sub-models to detect humans and analyse their actions. FaceTouch seeks to detect hand-to-face touches in the wild, such as through video chats, bus footage, or CCTV feeds. Despite partial occlusion of faces, the introduced system learns to detect face touches from the RGB representation of a given scene by utilising the representation of the body gestures such as arm movement. This has been demonstrated to be useful in complex urban scenarios beyond simply identifying hand movement and its closeness to faces. Relying on Supervised 
    
[^11]: 使用基于深度学习的加权图的短途公交线路规划决策支持系统

    Short Run Transit Route Planning Decision Support System Using a Deep Learning-Based Weighted Graph. (arXiv:2308.12828v1 [cs.AI])

    [http://arxiv.org/abs/2308.12828](http://arxiv.org/abs/2308.12828)

    提出了一种基于深度学习的短途公交线路规划决策支持系统，通过调整路线的特定部分，减少时间并提升公共交通服务。利用多样化的数据源，通过预测道路段的延迟值作为边权重，实现了快速路径规划决策。

    

    公共交通路线规划在交通网络设计中起着至关重要的作用，确保乘客获得满意的服务水平。然而，当前的路线规划解决方案依赖于传统的运营研究启发式算法，实施起来耗时，并且缺乏提供快速解决方案的能力。在这里，我们提出了一种新颖的基于深度学习的方法，用于决策支持系统，使公共交通规划者能够快速确定短期路线改进。通过在特定时间段内无缝调整两个站点之间特定路段的路线，我们的方法有效地减少时间并提升公共交通服务。利用GTFS和智能卡数据等多样化的数据源，我们提取特征并将交通网络建模为有向图。通过自监督学习，我们训练了一个深度学习模型，用于预测道路段的延迟值。然后，这些延迟值被用作交通图中的边权重，实现了快速路径规划决策。

    Public transport routing plays a crucial role in transit network design, ensuring a satisfactory level of service for passengers. However, current routing solutions rely on traditional operational research heuristics, which can be time-consuming to implement and lack the ability to provide quick solutions. Here, we propose a novel deep learning-based methodology for a decision support system that enables public transport (PT) planners to identify short-term route improvements rapidly. By seamlessly adjusting specific sections of routes between two stops during specific times of the day, our method effectively reduces times and enhances PT services. Leveraging diverse data sources such as GTFS and smart card data, we extract features and model the transportation network as a directed graph. Using self-supervision, we train a deep learning model for predicting lateness values for road segments.  These lateness values are then utilized as edge weights in the transportation graph, enabling
    
[^12]: ICU使用长短期记忆网络进行死亡率预测

    ICU Mortality Prediction Using Long Short-Term Memory Networks. (arXiv:2308.12800v1 [cs.LG])

    [http://arxiv.org/abs/2308.12800](http://arxiv.org/abs/2308.12800)

    该论文通过使用长短期记忆网络分析床边监测产生的时间数据，成功构建了用于预测ICU患者死亡率和住院时间的系统。

    

    在重症监护病房 (ICU) 进行的大量床边监测产生了与患者生理相关的复杂时间数据，这为临床数据分析提供了一个复杂的背景。另一方面，识别出这些数据中的时间序列模式可能会提供高度能力来预测临床事件。因此，在这项工作中，我们研究了实施一个自动数据驱动的系统，该系统分析来自电子健康记录 (EHRs) 的大量多变量时间数据，并提取高级信息以早期预测住院死亡率和住院时间。在实践中，我们通过将时间窗口缩短到6小时来研究LSTM网络的适用性，以增强临床任务。实验结果突出了LSTM模型的效率，通过严格的多变量时间序列测量来构建真实世界的预测引擎。

    Extensive bedside monitoring in Intensive Care Units (ICUs) has resulted in complex temporal data regarding patient physiology, which presents an upscale context for clinical data analysis. In the other hand, identifying the time-series patterns within these data may provide a high aptitude to predict clinical events. Hence, we investigate, during this work, the implementation of an automatic data-driven system, which analyzes large amounts of multivariate temporal data derived from Electronic Health Records (EHRs), and extracts high-level information so as to predict in-hospital mortality and Length of Stay (LOS) early. Practically, we investigate the applicability of LSTM network by reducing the time-frame to 6-hour so as to enhance clinical tasks. The experimental results highlight the efficiency of LSTM model with rigorous multivariate time-series measurements for building real-world prediction engines.
    
[^13]: 工作车间调度基准：用于学习和非学习方法的环境和实例

    Job Shop Scheduling Benchmark: Environments and Instances for Learning and Non-learning Methods. (arXiv:2308.12794v1 [cs.AI])

    [http://arxiv.org/abs/2308.12794](http://arxiv.org/abs/2308.12794)

    这个开源的GitHub仓库为机器调度问题提供了综合基准，包括多种环境和实例，为研究人员和从业者提供了一个集中的中心。

    

    我们介绍了一个开源的GitHub仓库，其中包含了广泛的机器调度问题的综合基准，包括工作车间调度（JSP），流水车间调度（FSP），灵活工作车间调度（FJSP），具有装配约束的FJSP（FAJSP），具有序列依赖设置时间的FJSP（FJSP-SDST）和在线FJSP（在线作业到达）。我们的主要目标是为对机器调度挑战感兴趣的研究人员，从业者和爱好者提供一个集中的中心。

    We introduce an open-source GitHub repository containing comprehensive benchmarks for a wide range of machine scheduling problems, including Job Shop Scheduling (JSP), Flow Shop Scheduling (FSP), Flexible Job Shop Scheduling (FJSP), FJSP with Assembly constraints (FAJSP), FJSP with Sequence-Dependent Setup Times (FJSP-SDST), and the online FJSP (with online job arrivals). Our primary goal is to provide a centralized hub for researchers, practitioners, and enthusiasts interested in tackling machine scheduling challenges.
    
[^14]: 获取用于自动驾驶场景解释的定性可解释图

    Acquiring Qualitative Explainable Graphs for Automated Driving Scene Interpretation. (arXiv:2308.12755v1 [cs.AI])

    [http://arxiv.org/abs/2308.12755](http://arxiv.org/abs/2308.12755)

    本文提出了一种定性可解释图(QXG)的表示方法，用于自动驾驶场景的解释。该方法通过定性时空推理构建图，能够实时计算，占用空间较少，并在实验中展示了良好的性能。

    

    自动驾驶（AD）未来的发展依赖于强大、公平和可解释的人工智能方法。根据要求，自动驾驶车辆必须能够向驾驶员和车上乘客、行人以及其他容易受伤的道路使用者解释其决策，可能还要向外部审计人员解释事故情况。然而，目前大多数可解释方法仍依赖于对多个传感器捕捉的AD场景表示进行定量分析。本文提出了一种新的AD场景表示方法，称为定性可解释图（QXG），专用于长期场景的定性时空推理。该图的构建利用了最近的定性约束获取范式。我们在NuScenes，一个开放的真实多模态数据集上的实验结果显示，一个由40帧组成的AD场景的定性可解释图可以实时计算，并且占用空间较少，具有很高的实用性。

    The future of automated driving (AD) is rooted in the development of robust, fair and explainable artificial intelligence methods. Upon request, automated vehicles must be able to explain their decisions to the driver and the car passengers, to the pedestrians and other vulnerable road users and potentially to external auditors in case of accidents. However, nowadays, most explainable methods still rely on quantitative analysis of the AD scene representations captured by multiple sensors. This paper proposes a novel representation of AD scenes, called Qualitative eXplainable Graph (QXG), dedicated to qualitative spatiotemporal reasoning of long-term scenes. The construction of this graph exploits the recent Qualitative Constraint Acquisition paradigm. Our experimental results on NuScenes, an open real-world multi-modal dataset, show that the qualitative eXplainable graph of an AD scene composed of 40 frames can be computed in real-time and light in space storage which makes it a potent
    
[^15]: 使用相位流形的动作插帧

    Motion In-Betweening with Phase Manifolds. (arXiv:2308.12751v1 [cs.GR])

    [http://arxiv.org/abs/2308.12751](http://arxiv.org/abs/2308.12751)

    本论文介绍了一种使用相位流形的动作插帧系统，通过学习相位变量和混合专家神经网络模型来生成目标姿势之间的连续姿势序列，同时可以满足动画师手动修改的姿势和末端效应器作为约束的要求。

    

    本论文介绍了一种新颖的数据驱动动作插帧系统，通过使用周期自编码器学习的相位变量来达到角色的目标姿势。我们的方法利用混合专家神经网络模型，其中相位以不同的专家权重将动作在空间和时间上进行聚类。每组生成的权重以自回归的方式在当前状态和目标状态之间产生一系列姿势。此外，为了满足动画师手动修改的姿势或某些末端效应器作为动画要达到的约束，实施了一种学习的双向控制方案来满足这些约束。结果表明，使用相位进行动作插帧可以提高插值动作的锐度，并进一步稳定学习过程。此外，使用相位进行动作插帧还可以合成更具挑战性的运动，超越了行走等基本运动。

    This paper introduces a novel data-driven motion in-betweening system to reach target poses of characters by making use of phases variables learned by a Periodic Autoencoder. Our approach utilizes a mixture-of-experts neural network model, in which the phases cluster movements in both space and time with different expert weights. Each generated set of weights then produces a sequence of poses in an autoregressive manner between the current and target state of the character. In addition, to satisfy poses which are manually modified by the animators or where certain end effectors serve as constraints to be reached by the animation, a learned bi-directional control scheme is implemented to satisfy such constraints. The results demonstrate that using phases for motion in-betweening tasks sharpen the interpolated movements, and furthermore stabilizes the learning process. Moreover, using phases for motion in-betweening tasks can also synthesize more challenging movements beyond locomotion b
    
[^16]: 使用更高的批评力量将人类触摸与AI生成的文本分离：一种信息论方法

    Separating the Human Touch from AI-Generated Text using Higher Criticism: An Information-Theoretic Approach. (arXiv:2308.12747v1 [cs.IT])

    [http://arxiv.org/abs/2308.12747](http://arxiv.org/abs/2308.12747)

    本文提出了一种使用更高的批评力量将人类触摸与AI生成的文本分离的方法，通过多个困惑度测试和统计模型的结合，能够有效识别出可能被编辑的部分，并探讨了方法的有效性及相关挑战。

    

    我们提出了一种方法，用于确定一篇给定文章是完全由生成性语言模型编写的，还是包含了一些由其他作者（可能是人类）进行了重要编辑的替代情况。我们的过程涉及对个别句子或其他文本单位起源进行的多个困惑度测试，将这些多个测试结合起来使用更高的批评力量（HC）。作为副产品，该方法还能够识别出可能被编辑的部分。该方法受到了对数困惑度收敛到交叉熵率的启发，以及一个统计模型来描述被编辑的文本，即句子主要由语言模型生成，但可能有少数句子是通过其他机制产生的。我们使用真实数据证明了我们方法的有效性，并分析了影响其成功的因素。这个分析提出了一些有趣的开放挑战，解决这些挑战可能会改善该方法的有效性。

    We propose a method to determine whether a given article was entirely written by a generative language model versus an alternative situation in which the article includes some significant edits by a different author, possibly a human. Our process involves many perplexity tests for the origin of individual sentences or other text atoms, combining these multiple tests using Higher Criticism (HC). As a by-product, the method identifies parts suspected to be edited. The method is motivated by the convergence of the log-perplexity to the cross-entropy rate and by a statistical model for edited text saying that sentences are mostly generated by the language model, except perhaps for a few sentences that might have originated via a different mechanism. We demonstrate the effectiveness of our method using real data and analyze the factors affecting its success. This analysis raises several interesting open challenges whose resolution may improve the method's effectiveness.
    
[^17]: 人类可理解的基因组规模代谢网络的主动学习

    Human Comprehensible Active Learning of Genome-Scale Metabolic Networks. (arXiv:2308.12740v1 [cs.AI])

    [http://arxiv.org/abs/2308.12740](http://arxiv.org/abs/2308.12740)

    这项研究介绍了一种人类可理解的基因组规模代谢网络的主动学习方法，基于归纳逻辑编程(ILP)框架进行逻辑推理，并通过从实验中学习新的逻辑结构，以有效探索假设空间和指导实验设计。

    

    合成生物学的一个重要应用是将宿主细胞系统工程化以产生有用的产品。然而，宿主系统规模的增加导致设计空间巨大，并需要大量高昂的验证试验。为了宿主细胞系统的设计-构建-测试-学习（Design-Build-Test-Learn，DBTL）周期，迫切需要一种能有效探索假设空间并指导实验设计的可理解的机器学习方法。我们引入了一种基于归纳逻辑编程（ILP）的新型机器学习框架ILP-iML1515，它通过诱导逻辑推理和从训练实例中积极学习来执行说明性的逻辑推理。与数值模型不同，ILP-iML1515建立在对基因组规模代谢模型的可理解的逻辑表示上，并可以通过从缺乏营养的突变体试验中学习新的逻辑结构来更新模型。ILP-iML1515框架具有高通量模拟能力，并能主动选择实验。

    An important application of Synthetic Biology is the engineering of the host cell system to yield useful products. However, an increase in the scale of the host system leads to huge design space and requires a large number of validation trials with high experimental costs. A comprehensible machine learning approach that efficiently explores the hypothesis space and guides experimental design is urgently needed for the Design-Build-Test-Learn (DBTL) cycle of the host cell system. We introduce a novel machine learning framework ILP-iML1515 based on Inductive Logic Programming (ILP) that performs abductive logical reasoning and actively learns from training examples. In contrast to numerical models, ILP-iML1515 is built on comprehensible logical representations of a genome-scale metabolic model and can update the model by learning new logical structures from auxotrophic mutant trials. The ILP-iML1515 framework 1) allows high-throughput simulations and 2) actively selects experiments that 
    
[^18]: 使用可解释的细胞图集成的非对称协同训练用于组织病理图像分类

    Asymmetric Co-Training with Explainable Cell Graph Ensembling for Histopathological Image Classification. (arXiv:2308.12737v1 [cs.CV])

    [http://arxiv.org/abs/2308.12737](http://arxiv.org/abs/2308.12737)

    该论文提出了一个非对称协同训练框架，结合深度图卷积网络和卷积神经网络，用于多类别组织病理图像分类。通过嵌入细胞的形态和拓扑分布，这个框架提出了一种可以解释的方法，用于提高整个系统的可解释性。

    

    卷积神经网络在组织病理图像分类方面表现出色，但由于其像素级的关注，限制了可解释性。相反，新兴的图卷积网络聚焦于细胞级特征和医学意义。然而，由于浅层网络和高维像素数据使用不充分，图卷积网络在多类别组织病理图像分类中表现不佳。为了充分利用像素级和细胞级特征，我们提出了一个非对称协同训练框架，结合深度图卷积网络和卷积神经网络进行多类别组织病理图像分类。为了提高整个框架的可解释性，我们构建了一个14层的深度图卷积网络来处理细胞图数据的形态和拓扑分布。为了进一步利用像素级和细胞级信息之间的动态互作，我们还设计了一种协同训练策略来整合这两者之间的信息。

    Convolutional neural networks excel in histopathological image classification, yet their pixel-level focus hampers explainability. Conversely, emerging graph convolutional networks spotlight cell-level features and medical implications. However, limited by their shallowness and suboptimal use of high-dimensional pixel data, GCNs underperform in multi-class histopathological image classification. To make full use of pixel-level and cell-level features dynamically, we propose an asymmetric co-training framework combining a deep graph convolutional network and a convolutional neural network for multi-class histopathological image classification. To improve the explainability of the entire framework by embedding morphological and topological distribution of cells, we build a 14-layer deep graph convolutional network to handle cell graph data. For the further utilization and dynamic interactions between pixel-level and cell-level information, we also design a co-training strategy to integra
    
[^19]: DeepLOC: 基于深度学习的手腕X射线图像中骨病理定位和分类

    DeepLOC: Deep Learning-based Bone Pathology Localization and Classification in Wrist X-ray Images. (arXiv:2308.12727v1 [cs.CV])

    [http://arxiv.org/abs/2308.12727](http://arxiv.org/abs/2308.12727)

    本文提出了一种基于深度学习的方法，利用YOLO和Swin模型实现手腕X射线图像中骨病理的定位和分类。该方法解决了准确定位和精确分类的两个关键挑战。

    

    近年来，计算机辅助诊断系统在辅助放射科医生进行准确和高效的医学图像分析方面展现了巨大潜力。本文提出了一种创新方法，使用YOLO (You Only Look Once) 和 Shifted Window Transformer (Swin) 的组合，并配合一个新提出的模块，对手腕X射线图像中的骨病理进行定位和分类。所提出的方法解决了手腕X射线分析中的两个关键挑战：骨病理的准确定位和异常的精确分类。利用YOLO框架进行骨病理的检测和定位，充分发挥其实时目标检测能力。此外，利用Swin模块从感兴趣区域(ROI)中提取上下文信息，实现准确分类。

    In recent years, computer-aided diagnosis systems have shown great potential in assisting radiologists with accurate and efficient medical image analysis. This paper presents a novel approach for bone pathology localization and classification in wrist X-ray images using a combination of YOLO (You Only Look Once) and the Shifted Window Transformer (Swin) with a newly proposed block. The proposed methodology addresses two critical challenges in wrist X-ray analysis: accurate localization of bone pathologies and precise classification of abnormalities. The YOLO framework is employed to detect and localize bone pathologies, leveraging its real-time object detection capabilities. Additionally, the Swin, a transformer-based module, is utilized to extract contextual information from the localized regions of interest (ROIs) for accurate classification.
    
[^20]: 基于连续强化学习的视觉工作记忆游戏动态难度调整

    Continuous Reinforcement Learning-based Dynamic Difficulty Adjustment in a Visual Working Memory Game. (arXiv:2308.12726v1 [cs.HC])

    [http://arxiv.org/abs/2308.12726](http://arxiv.org/abs/2308.12726)

    本文提出了一种基于连续强化学习的动态难度调整方法，用于处理视觉工作记忆游戏中的复杂难度记忆问题。通过根据玩家的得分和上一轮游戏的难度量度来调整游戏难度，该方法在52位受试者的实验中得到了评估和比较。

    

    动态难度调整（DDA）是提升玩家在视频游戏中体验的一种有效方法。最近，强化学习（RL）方法已被应用于非竞争性游戏的DDA；尽管如此，它们仅依赖于具有小的搜索空间的离散状态-动作空间。在本文中，我们提出了一种基于连续强化学习的DDA方法，用于处理视觉工作记忆（VWM）游戏中难度记忆的复杂搜索空间。该提出的基于RL的DDA根据玩家的得分和上一轮游戏的难度量度来调整游戏难度。我们定义了一种连续的难度记忆度量。然后，我们将任务难度和难度-得分向量分别作为RL的动作和状态。我们通过一个涉及52位受试者的被试内实验来评估所提出的方法。在玩家的得分和游戏体验度量方面，将所提出的方法与两种基于规则的难度调整方法进行了比较。

    Dynamic Difficulty Adjustment (DDA) is a viable approach to enhance a player's experience in video games. Recently, Reinforcement Learning (RL) methods have been employed for DDA in non-competitive games; nevertheless, they rely solely on discrete state-action space with a small search space. In this paper, we propose a continuous RL-based DDA methodology for a visual working memory (VWM) game to handle the complex search space for the difficulty of memorization. The proposed RL-based DDA tailors game difficulty based on the player's score and game difficulty in the last trial. We defined a continuous metric for the difficulty of memorization. Then, we consider the task difficulty and the vector of difficulty-score as the RL's action and state, respectively. We evaluated the proposed method through a within-subject experiment involving 52 subjects. The proposed approach was compared with two rule-based difficulty adjustment methods in terms of player's score and game experience measure
    
[^21]: VIGC: 视觉指令生成与纠正

    VIGC: Visual Instruction Generation and Correction. (arXiv:2308.12714v1 [cs.CV])

    [http://arxiv.org/abs/2308.12714](http://arxiv.org/abs/2308.12714)

    本文提出了VIGC框架，使多模态大型语言模型能够生成和纠正视觉指令数据，解决了缺乏高质量调整数据的挑战。

    

    视觉编码器和大型语言模型（LLMs）的整合推动了多模态大型语言模型（MLLMs）的最新进展。然而，针对视觉语言任务的高质量指令调整数据的稀缺仍然是一个挑战。当前的主导范式，如LLaVA，依赖于仅使用语言的GPT-4生成数据，这需要预注释的图像标题和检测包围框，导致对图像细节的理解不足。解决这个问题的一个实际方案是利用可用的多模态大型语言模型（MLLMs）生成视觉语言任务的指令数据。然而，值得注意的是，当前可访问的MLLMs不像它们的LLM对应物那样强大，因为它们往往产生不适当的回应和生成错误信息。作为解决当前问题的方案，本文提出了Visual Instruction Generation and Correction（VIGC）框架，使多模态大型语言模型能够生成视觉指令数据并纠正错误。

    The integration of visual encoders and large language models (LLMs) has driven recent progress in multimodal large language models (MLLMs). However, the scarcity of high-quality instruction-tuning data for vision-language tasks remains a challenge. The current leading paradigm, such as LLaVA, relies on language-only GPT-4 to generate data, which requires pre-annotated image captions and detection bounding boxes, suffering from understanding image details. A practical solution to this problem would be to utilize the available multimodal large language models (MLLMs) to generate instruction data for vision-language tasks. However, it's worth noting that the currently accessible MLLMs are not as powerful as their LLM counterparts, as they tend to produce inadequate responses and generate false information. As a solution for addressing the current issue, this paper proposes the Visual Instruction Generation and Correction (VIGC) framework that enables multimodal large language models to ge
    
[^22]: SayCanPay: 使用可学习的领域知识，基于大型语言模型的启发式规划。

    SayCanPay: Heuristic Planning with Large Language Models using Learnable Domain Knowledge. (arXiv:2308.12682v1 [cs.AI])

    [http://arxiv.org/abs/2308.12682](http://arxiv.org/abs/2308.12682)

    SayCanPay是一种结合了大型语言模型(LLMs)和启发式规划的方法，通过利用LLMs的世界知识和启发式搜索的原则，生成可行的最优计划。

    

    大型语言模型(LLMs)通过其庞大的"世界知识"展示了令人印象深刻的规划能力。然而，尽管最近取得了一些进展，但获得既可行（基于可用性）又具有成本效益（计划长度方面）的计划仍然是一个挑战。这与启发式规划方法形成反差，启发式规划方法利用领域知识(在动作模型如PDDL中形式化)和启发式搜索来生成可行的最优计划。受此启发，我们提出了将LLMs的强大能力和启发式规划相结合的方法，利用LLMs的世界知识和启发式搜索的原则。我们的方法SayCanPay利用LLMs来生成由可学习的领域知识引导的动作(Say)，评估动作的可行性(Can)和长期回报/收益(Pay)，利用启发式搜索来选择最佳的动作序列。我们的贡献有(1)在启发式规划的背景下，对LLM规划问题进行了新颖的构建，(2)整合了可用性和成本效益。

    Large Language Models (LLMs) have demonstrated impressive planning abilities due to their vast "world knowledge". Yet, obtaining plans that are both feasible (grounded in affordances) and cost-effective (in plan length), remains a challenge, despite recent progress. This contrasts with heuristic planning methods that employ domain knowledge (formalized in action models such as PDDL) and heuristic search to generate feasible, optimal plans. Inspired by this, we propose to combine the power of LLMs and heuristic planning by leveraging the world knowledge of LLMs and the principles of heuristic search. Our approach, SayCanPay, employs LLMs to generate actions (Say) guided by learnable domain knowledge, that evaluates actions' feasibility (Can) and long-term reward/payoff (Pay), and heuristic search to select the best sequence of actions. Our contributions are (1) a novel framing of the LLM planning problem in the context of heuristic planning, (2) integrating grounding and cost-effective 
    
[^23]: LR-XFL: 基于逻辑推理的可解释联邦学习

    LR-XFL: Logical Reasoning-based Explainable Federated Learning. (arXiv:2308.12681v1 [cs.AI])

    [http://arxiv.org/abs/2308.12681](http://arxiv.org/abs/2308.12681)

    LR-XFL是一种基于逻辑推理的可解释联邦学习方法，通过将逻辑规则和模型更新结合起来，实现了对FL模型的解释性提升和加权聚合，并在相关基准测试中取得了较好的效果。

    

    联邦学习 (FL) 是一种新兴的机器学习模型协作训练方法，能够保护数据隐私。隐私保护的需求使得FL模型很难实现全局透明度和可解释性。为了解决这个限制，我们提出了基于逻辑推理的可解释联邦学习 (LR-XFL) 方法，将逻辑推理融入FL中。在LR-XFL中，FL客户端根据其本地数据创建本地逻辑规则，并将其与模型更新一起发送到FL服务器。FL服务器通过适当的逻辑连接符将本地逻辑规则连接起来，该连接符基于客户端数据的属性进行推导，而无需访问原始数据。此外，服务器还根据客户端上传的逻辑规则反映的本地数据的质量，使用权重值对本地模型更新进行聚合。结果显示，LR-XFL在最相关的基准测试中超过1.19％，5.81％和5.41％。

    Federated learning (FL) is an emerging approach for training machine learning models collaboratively while preserving data privacy. The need for privacy protection makes it difficult for FL models to achieve global transparency and explainability. To address this limitation, we incorporate logic-based explanations into FL by proposing the Logical Reasoning-based eXplainable Federated Learning (LR-XFL) approach. Under LR-XFL, FL clients create local logic rules based on their local data and send them, along with model updates, to the FL server. The FL server connects the local logic rules through a proper logical connector that is derived based on properties of client data, without requiring access to the raw data. In addition, the server also aggregates the local model updates with weight values determined by the quality of the clients' local data as reflected by their uploaded logic rules. The results show that LR-XFL outperforms the most relevant baseline by 1.19%, 5.81% and 5.41% in
    
[^24]: 通过增强指令来提高大型语言模型的翻译真实性

    Improving Translation Faithfulness of Large Language Models via Augmenting Instructions. (arXiv:2308.12674v1 [cs.CL])

    [http://arxiv.org/abs/2308.12674](http://arxiv.org/abs/2308.12674)

    通过增强指令来提高大型语言模型的翻译真实性，我们提出了SWIE（分段加权指令嵌入）和一个指令遵循数据集OVERMISS，用于改善模型对指令的理解和提高模型的真实性。

    

    大型语言模型(LLMs)具有很强的通用能力，目前一个引人注目的挑战是通过低成本的指令调整来激发它们的专门能力，如机器翻译。标准的指令遵循数据是按顺序组织的，包括指令、输入和响应的连接。由于LLMs的注意机制在局部关注上存在局限性，LLMs倾向于在每个位置更多地关注附近的单词或句子。这导致在解码过程中遗忘指令的风险很高。为了缓解上述问题，我们提出了SWIE（分段加权指令嵌入）和一个指令遵循数据集OVERMISS。SWIE通过在后续的输入和响应表示上添加全局指令表示来改善模型对指令的理解。OVERMISS通过将过度翻译和遗漏翻译结果与正确翻译进行比较来提高模型的真实性。我们将我们的方法应用到两个主要的翻译任务中。

    Large Language Models (LLMs) present strong general capabilities, and a current compelling challenge is stimulating their specialized capabilities, such as machine translation, through low-cost instruction tuning. The standard instruction-following data is sequentially organized as the concatenation of an instruction, an input, and a response. As the attention mechanism of LLMs has limitations on local focus, LLMs tend to focus more on the words or sentences nearby at each position. This leads to a high risk of instruction forgetting during decoding. To alleviate the above issues, We propose SWIE (Segment-Weighted Instruction Embedding) and an instruction-following dataset OVERMISS. SWIE improves the model instruction understanding by adding a global instruction representation on the following input and response representations. OVERMISS improves model faithfulness by comparing over-translation and miss-translation results with the correct translation. We apply our methods to two main-
    
[^25]: 不要望向太阳：对图像分类器的对抗性曝光攻击

    Don't Look into the Sun: Adversarial Solarization Attacks on Image Classifiers. (arXiv:2308.12661v1 [cs.CV])

    [http://arxiv.org/abs/2308.12661](http://arxiv.org/abs/2308.12661)

    通过对图像进行曝光攻击，我们引入了一种简单而有效的方法来评估图像分类器的鲁棒性，并证明该攻击能够显著降低准确性。

    

    评估深度神经网络对于超出分布范围的输入的鲁棒性是至关重要的，特别是在像自动驾驶这样的安全关键领域，但也适用于恶意攻击者可以数字地修改输入以绕过安全保护的安全系统中。然而，设计有效的超出分布测试，在保持准确的标签信息的同时涵盖所有可能的场景，是一项具有挑战性的任务。现有的方法往往需要在攻击的多样性和限制水平之间做出妥协，有时甚至两者兼而有之。作为对图像分类模型更全面的鲁棒性评估的第一步，我们引入了一种基于图像曝光的攻击方法，该方法在概念上简单明了，但又能避免局部范围内的自然图像的全局结构受到损害。通过对多个ImageNet模型进行全面评估，我们证明该攻击能够显著降低准确性，前提是它没有集成到

    Assessing the robustness of deep neural networks against out-of-distribution inputs is crucial, especially in safety-critical domains like autonomous driving, but also in safety systems where malicious actors can digitally alter inputs to circumvent safety guards. However, designing effective out-of-distribution tests that encompass all possible scenarios while preserving accurate label information is a challenging task. Existing methodologies often entail a compromise between variety and constraint levels for attacks and sometimes even both. In a first step towards a more holistic robustness evaluation of image classification models, we introduce an attack method based on image solarization that is conceptually straightforward yet avoids jeopardizing the global structure of natural images independent of the intensity. Through comprehensive evaluations of multiple ImageNet models, we demonstrate the attack's capacity to degrade accuracy significantly, provided it is not integrated into
    
[^26]: kTrans:知识感知的二进制代码嵌入

    kTrans: Knowledge-Aware Transformer for Binary Code Embedding. (arXiv:2308.12659v1 [cs.SE])

    [http://arxiv.org/abs/2308.12659](http://arxiv.org/abs/2308.12659)

    kTrans是一种知识感知的二进制代码嵌入方法，通过将显式知识和隐式知识与Transformer模型结合，提供了一种将领域知识融入Transformer框架的新视角。它在二进制代码相似性检测、函数类型恢复和间接调用识别等任务中具有优异的表现。

    

    二进制代码嵌入(BCE)在各种逆向工程任务中有重要应用，如二进制代码相似性检测、类型恢复、控制流恢复和数据流分析。最近的研究表明，Transformer模型可以理解二进制代码的语义以支持下游任务。然而，现有模型忽视了汇编语言的先验知识。在本文中，我们提出了一种新颖的基于Transformer的方法，即kTrans，用于生成知识感知的二进制代码嵌入。通过将显式知识作为额外的输入馈送给Transformer，并将隐式知识与新颖的预训练任务融合，kTrans为将领域知识合并到Transformer框架中提供了新的视角。我们用离群值检测和可视化来检查生成的嵌入，并将kTrans应用于3个下游任务：二进制代码相似性检测(BCSD)、函数类型恢复(FTR)和间接调用识别(ICR)。

    Binary Code Embedding (BCE) has important applications in various reverse engineering tasks such as binary code similarity detection, type recovery, control-flow recovery and data-flow analysis. Recent studies have shown that the Transformer model can comprehend the semantics of binary code to support downstream tasks. However, existing models overlooked the prior knowledge of assembly language. In this paper, we propose a novel Transformer-based approach, namely kTrans, to generate knowledge-aware binary code embedding. By feeding explicit knowledge as additional inputs to the Transformer, and fusing implicit knowledge with a novel pre-training task, kTrans provides a new perspective to incorporating domain knowledge into a Transformer framework. We inspect the generated embeddings with outlier detection and visualization, and also apply kTrans to 3 downstream tasks: Binary Code Similarity Detection (BCSD), Function Type Recovery (FTR) and Indirect Call Recognition (ICR). Evaluation r
    
[^27]: APART: 使用有升序奖励和丢弃技术的全组对多样化技能发现

    APART: Diverse Skill Discovery using All Pairs with Ascending Reward and DropouT. (arXiv:2308.12649v1 [cs.LG])

    [http://arxiv.org/abs/2308.12649](http://arxiv.org/abs/2308.12649)

    本文提出了一个名为APART的方法，使用全组对判别器、新颖的内在奖励函数和丢弃技术，在无奖励环境中实现了多样化技能的发现。该方法具有更高的效率，并在简单的网格世界环境中发现了所有可能的技能。

    

    我们研究了在无奖励环境中的多样化技能发现，在简单的网格世界环境中发现所有可能的技能，先前的方法很难成功。这个问题被制定为使用内在奖励和一个经过训练的判别器来相互训练技能以预测给定轨迹的技能。我们的初始解决方案用全组对（all pairs）判别器替换了标准的一对多（softmax）判别器，并结合了一种新颖的内在奖励函数和丢弃（dropout）正则化技术。这种综合方法被命名为APART: 使用有升序奖励和丢弃技术的全组对多样化技能发现。我们证明APART比先前的方法更少样本就能发现网格世界中所有可能的技能。受到APART的实证成功的启发，我们进一步研究了一个更简单的算法，通过改变VIC，重新调整其内在奖励，并调节其softmax温度来实现最大化技能的目标。

    We study diverse skill discovery in reward-free environments, aiming to discover all possible skills in simple grid-world environments where prior methods have struggled to succeed. This problem is formulated as mutual training of skills using an intrinsic reward and a discriminator trained to predict a skill given its trajectory. Our initial solution replaces the standard one-vs-all (softmax) discriminator with a one-vs-one (all pairs) discriminator and combines it with a novel intrinsic reward function and a dropout regularization technique. The combined approach is named APART: Diverse Skill Discovery using All Pairs with Ascending Reward and Dropout. We demonstrate that APART discovers all the possible skills in grid worlds with remarkably fewer samples than previous works. Motivated by the empirical success of APART, we further investigate an even simpler algorithm that achieves maximum skills by altering VIC, rescaling its intrinsic reward, and tuning the temperature of its softm
    
[^28]: 使用HuSpaCy推进匈牙利文本处理：高效准确的自然语言处理管道

    Advancing Hungarian Text Processing with HuSpaCy: Efficient and Accurate NLP Pipelines. (arXiv:2308.12635v1 [cs.CL])

    [http://arxiv.org/abs/2308.12635](http://arxiv.org/abs/2308.12635)

    本文介绍了一套工业级匈牙利文本处理模型，利用HuSpaCy框架实现，通过多项改进在资源效率和准确性之间取得了接近最先进的性能。这些模型具备高准确性和吞吐量，并在所有基本文本处理步骤中展示了竞争性能。

    

    本文介绍了一套用于匈牙利文本处理的工业级模型，这些模型在资源效率和准确性之间取得了接近最先进的性能。这些模型是基于spaCy框架实现的，在HuSpaCy工具包的架构上进行了多个改进。与现有的匈牙利语自然语言处理工具相比，我们所有的管道都具备包括标记化、句子边界检测、词性标注、词形特征标注、词形还原、依存句法分析和命名实体识别在内的所有基本文本处理步骤，并且具有高准确性和高吞吐量。我们对提出的改进进行了全面评估，将管道与最先进的工具进行了比较，并在所有文本预处理步骤中展示了新模型的竞争性能。所有实验都可以重现，并且这些管道可以免费使用并采用宽松的许可证。

    This paper presents a set of industrial-grade text processing models for Hungarian that achieve near state-of-the-art performance while balancing resource efficiency and accuracy. Models have been implemented in the spaCy framework, extending the HuSpaCy toolkit with several improvements to its architecture. Compared to existing NLP tools for Hungarian, all of our pipelines feature all basic text processing steps including tokenization, sentence-boundary detection, part-of-speech tagging, morphological feature tagging, lemmatization, dependency parsing and named entity recognition with high accuracy and throughput. We thoroughly evaluated the proposed enhancements, compared the pipelines with state-of-the-art tools and demonstrated the competitive performance of the new models in all text preprocessing steps. All experiments are reproducible and the pipelines are freely available under a permissive license.
    
[^29]: 面向分层区域变压器的多实例学习

    Towards Hierarchical Regional Transformer-based Multiple Instance Learning. (arXiv:2308.12634v1 [cs.CV])

    [http://arxiv.org/abs/2308.12634](http://arxiv.org/abs/2308.12634)

    本文提出了一种基于变压器的多实例学习方法，通过使用区域自注意力机制，融合区域补丁信息以得出滑片级别预测，并通过堆叠区域聚合来分层处理特征。此外，引入了一种方法来聚焦于高关注区域，从而提高预测准确性。这种方法在组织病理学图像分类任务上表现出了显著的性能改进，并为进一步研究提供了有希望的方向。

    

    在数字病理学和精确医学中，使用深度多实例学习模型对巨像素组织病理学图像进行分类已成为一项关键任务。本文提出了一种基于变压器的多实例学习方法，该方法用区域性的、受到视觉变压器启发的自注意力机制替代了传统的学习注意力机制。我们提出了一种融合区域补丁信息以得出滑片级别预测的方法，并展示了如何堆叠这种区域聚合以分层地处理不同距离水平上的特征。为了提高预测准确性，特别是对于具有小的局部形态特征的数据集，我们引入了一种方法，在推理期间将图像处理集中在高关注区域。我们的方法能够显著改善两个组织病理学数据集的性能，并指向进一步研究的有希望的方向。

    The classification of gigapixel histopathology images with deep multiple instance learning models has become a critical task in digital pathology and precision medicine. In this work, we propose a Transformer-based multiple instance learning approach that replaces the traditional learned attention mechanism with a regional, Vision Transformer inspired self-attention mechanism. We present a method that fuses regional patch information to derive slide-level predictions and show how this regional aggregation can be stacked to hierarchically process features on different distance levels. To increase predictive accuracy, especially for datasets with small, local morphological features, we introduce a method to focus the image processing on high attention regions during inference. Our approach is able to significantly improve performance over the baseline on two histopathology datasets and points towards promising directions for further research.
    
[^30]: 一个用于向电信用户提供的贪心方法

    A Greedy Approach for Offering to Telecom Subscribers. (arXiv:2308.12606v1 [stat.ML])

    [http://arxiv.org/abs/2308.12606](http://arxiv.org/abs/2308.12606)

    本论文提出了一个用于解决套餐优化问题的新颖组合算法，该算法针对电信运营商在选择激励套餐和目标用户时面临的困难进行了解决。

    

    客户保留或减少流失是电信运营商面临的一项具有挑战性的任务。其中一个有效的方法是向用户提供一些有吸引力的激励措施或附加服务或金钱，以保持他们的参与并确保他们在运营商的网络中停留更长时间。通常，运营商会分配一定金额的预算来进行推广活动。这项活动的困难之处在于从庞大的订户群体中选择一组客户，并决定应该向个体提供多少金额，以实现运营商的目标。选择订户和选择提供给被选定订户的套餐可能有多个目标（例如，最大化收入，最小化流失数量）。除了金钱利益，套餐还可以包括额外的数据、短信、手机热点共享等等。这个问题被称为套餐优化。在这篇论文中，我们提出了一种新颖的组合算法来解决套餐优化问题。

    Customer retention or churn prevention is a challenging task of a telecom operator. One of the effective approaches is to offer some attractive incentive or additional services or money to the subscribers for keeping them engaged and make sure they stay in the operator's network for longer time. Often, operators allocate certain amount of monetary budget to carry out the offer campaign. The difficult part of this campaign is the selection of a set of customers from a large subscriber-base and deciding the amount that should be offered to an individual so that operator's objective is achieved. There may be multiple objectives (e.g., maximizing revenue, minimizing number of churns) for selection of subscriber and selection of an offer to the selected subscriber. Apart from monetary benefit, offers may include additional data, SMS, hots-spot tethering, and many more. This problem is known as offer optimization. In this paper, we propose a novel combinatorial algorithm for solving offer op
    
[^31]: APLA: 附加摄动的层噪声与对抗训练使一致性成为可能

    APLA: Additional Perturbation for Latent Noise with Adversarial Training Enables Consistency. (arXiv:2308.12605v1 [cs.CV])

    [http://arxiv.org/abs/2308.12605](http://arxiv.org/abs/2308.12605)

    APLA是一种基于扩散模型的文本到视频生成网络结构，通过引入附加摄动的层噪声与对抗训练，解决了视频生成中一致性细节丢失的问题。

    

    扩散模型在视频生成方面取得了令人期待的进展。然而，它们经常难以在帧之间保留局部区域的一致细节。其中一个潜在原因是传统扩散模型在逼近高斯噪声分布时利用了预测噪声，没有充分考虑输入本身的内在信息的影响。此外，这些模型强调预测和参考之间的区别，忽视了视频本身固有的信息。为了解决这个限制，受到自注意机制的启发，我们提出了一种基于扩散模型的文本到视频（T2V）生成网络结构，名为附加摄动的层噪声与对抗训练（APLA）。我们的方法只需要一个视频作为输入，并建立在预训练稳定的扩散网络上。值得注意的是，我们引入了一个额外的紧凑网络，称为视频生成变换器（VGT）。

    Diffusion models have exhibited promising progress in video generation. However, they often struggle to retain consistent details within local regions across frames. One underlying cause is that traditional diffusion models approximate Gaussian noise distribution by utilizing predictive noise, without fully accounting for the impact of inherent information within the input itself. Additionally, these models emphasize the distinction between predictions and references, neglecting information intrinsic to the videos. To address this limitation, inspired by the self-attention mechanism, we propose a novel text-to-video (T2V) generation network structure based on diffusion models, dubbed Additional Perturbation for Latent noise with Adversarial training (APLA). Our approach only necessitates a single video as input and builds upon pre-trained stable diffusion networks. Notably, we introduce an additional compact network, known as the Video Generation Transformer (VGT). This auxiliary compo
    
[^32]: SICNN: 受软干扰抵消启发的神经网络均衡器

    SICNN: Soft Interference Cancellation Inspired Neural Network Equalizers. (arXiv:2308.12591v1 [eess.SP])

    [http://arxiv.org/abs/2308.12591](http://arxiv.org/abs/2308.12591)

    SICNN是基于神经网络的均衡方法，通过深度展开基于模型的迭代SIC方法来设计，消除了基于模型方法的缺点。

    

    均衡是数字无线通信系统接收端的一项重要任务，传统上使用基于模型的估计方法来进行。在众多选项中，迭代软干扰抵消（SIC）是一种表现良好的方法，因为它避免了迭代估计过程中由硬决策数据符号估计引起的错误传播。然而，基于模型的方法存在高计算复杂度和性能降低的问题，因为需要进行逼近。在这项工作中，我们提出了一种新颖的基于神经网络（NN）的均衡方法，称为SICNN，通过对基于模型的迭代SIC方法进行深度展开来设计，消除了其基于模型的对应方法的主要缺点。我们提出了不同版本的SICNN。SICNNv1非常类似于基于模型的方法，专门为单载波频域均衡系统设计

    Equalization is an important task at the receiver side of a digital wireless communication system, which is traditionally conducted with model-based estimation methods. Among the numerous options for model-based equalization, iterative soft interference cancellation (SIC) is a well-performing approach since error propagation caused by hard decision data symbol estimation during the iterative estimation procedure is avoided. However, the model-based method suffers from high computational complexity and performance degradation due to required approximations. In this work, we propose a novel neural network (NN-)based equalization approach, referred to as SICNN, which is designed by deep unfolding of a model-based iterative SIC method, eliminating the main disadvantages of its model-based counterpart. We present different variants of SICNN. SICNNv1 is very similar to the model-based method, and is specifically tailored for single carrier frequency domain equalization systems, which is the 
    
[^33]: 一种Huber损失最小化方法用于拜占庭鲁棒的联邦学习

    A Huber Loss Minimization Approach to Byzantine Robust Federated Learning. (arXiv:2308.12581v1 [cs.LG])

    [http://arxiv.org/abs/2308.12581](http://arxiv.org/abs/2308.12581)

    本文介绍了一种基于Huber损失最小化的新型聚合器用于拜占庭鲁棒的联邦学习。在独立同分布假设下，该方法具有与现有方法相比的优势，并对非i.i.d数据进行了扩展分析。

    

    联邦学习系统容易受到对抗攻击。为了应对这个问题，我们引入了一种基于Huber损失最小化的新型聚合器，并提供了全面的理论分析。在独立同分布（i.i.d）假设下，与现有方法相比，我们的方法具有几个优势。首先，它对于被攻击客户端比率$\epsilon$具有最优的依赖关系。其次，我们的方法不需要对$\epsilon$有精确的知识。第三，它允许不同的客户端具有不均等的数据大小。然后，我们将分析扩展到包括非i.i.d数据，这意味着客户端具有略有不同的分布。

    Federated learning systems are susceptible to adversarial attacks. To combat this, we introduce a novel aggregator based on Huber loss minimization, and provide a comprehensive theoretical analysis. Under independent and identically distributed (i.i.d) assumption, our approach has several advantages compared to existing methods. Firstly, it has optimal dependence on $\epsilon$, which stands for the ratio of attacked clients. Secondly, our approach does not need precise knowledge of $\epsilon$. Thirdly, it allows different clients to have unequal data sizes. We then broaden our analysis to include non-i.i.d data, such that clients have slightly different distributions.
    
[^34]: 理智对话声音：关于在大型语言模型中测量社会偏见的重新判断不一致性的论文

    Mind vs. Mouth: On Measuring Re-judge Inconsistency of Social Bias in Large Language Models. (arXiv:2308.12578v1 [cs.CL])

    [http://arxiv.org/abs/2308.12578](http://arxiv.org/abs/2308.12578)

    本文研究了大型语言模型中的社会偏见，并发现了一种名为“重新判断不一致性”的现象，即在完成陈述和重新评判过程中存在矛盾。这对于理解语言模型的认知和隐含偏见具有重要意义。

    

    最近的研究表明，预训练的大型语言模型(LLMs)具有与人类观察到的认知结构相似的特点，促使研究人员调查LLMs的认知方面。本文着重研究了明确和隐含的社会偏见，这是心理学中一种独特的两级认知结构。文中提出，个体的明确社会偏见，即其在陈述中表达的有意识偏见，可能与其隐含的社会偏见不同，后者代表其无意识偏见。我们提出了一个两阶段的方法，并发现LLMs中的一种并行现象，即社会偏见中的“重新判断不一致性”。在初始阶段，LLM负责自动完成陈述，可能会包含隐含的社会偏见。然而，在随后的阶段，同样的LLM重新评判了其自动生成的有偏见的陈述，但却与之相矛盾。我们提出，这种重新判断的不一致性可能类似于人类不知道其偏见的一致性。

    Recent researches indicate that Pre-trained Large Language Models (LLMs) possess cognitive constructs similar to those observed in humans, prompting researchers to investigate the cognitive aspects of LLMs. This paper focuses on explicit and implicit social bias, a distinctive two-level cognitive construct in psychology. It posits that individuals' explicit social bias, which is their conscious expression of bias in the statements, may differ from their implicit social bias, which represents their unconscious bias. We propose a two-stage approach and discover a parallel phenomenon in LLMs known as "re-judge inconsistency" in social bias. In the initial stage, the LLM is tasked with automatically completing statements, potentially incorporating implicit social bias. However, in the subsequent stage, the same LLM re-judges the biased statement generated by itself but contradicts it. We propose that this re-judge inconsistency can be similar to the inconsistency between human's unaware im
    
[^35]: REB：降低工业异常检测中的表示偏差

    REB: Reducing Biases in Representation for Industrial Anomaly Detection. (arXiv:2308.12577v1 [cs.CV])

    [http://arxiv.org/abs/2308.12577](http://arxiv.org/abs/2308.12577)

    本文提出了一种名为REB的方法，通过考虑领域偏差和构建自监督学习任务，以及使用本地密度K最近邻方法，从而降低工业异常检测中的表示偏差，并取得了显著的改进。

    

    现有的K最近邻（KNN）检索方法通常分为两个阶段进行工业异常检测：使用预训练的CNN模型获取特征表示，并执行距离度量进行缺陷检测。然而，由于忽略了领域偏差和特征空间中的局部密度差异，这些特征没有被充分利用，限制了检测性能。本文提出了一种通过考虑预训练模型的领域偏差和构建自监督学习任务以实现更好的领域适应性的方法——Reducing Biases（REB）。同时，通过模仿自然缺陷的缺陷生成策略（DefectMaker），提出了一种本地密度K最近邻（LDKNN）方法来减少局部密度偏差并实现有效的异常检测。我们在广泛使用的MVTec AD基准上实现了99.5％的AUROC，并在具有挑战性的MVTec LOCO AD数据集上实现了88.0％的AUROC，并将AUROC提高了4.7％。

    Existing K-nearest neighbor (KNN) retrieval-based methods usually conduct industrial anomaly detection in two stages: obtain feature representations with a pre-trained CNN model and perform distance measures for defect detection. However, the features are not fully exploited as they ignore domain bias and the difference of local density in feature space, which limits the detection performance. In this paper, we propose Reducing Biases (REB) in representation by considering the domain bias of the pre-trained model and building a self-supervised learning task for better domain adaption with a defect generation strategy (DefectMaker) imitating the natural defects. Additionally, we propose a local density KNN (LDKNN) to reduce the local density bias and obtain effective anomaly detection. We achieve a promising result of 99.5\% AUROC on the widely used MVTec AD benchmark. We also achieve 88.0\% AUROC on the challenging MVTec LOCO AD dataset and bring an improvement of 4.7\% AUROC to the st
    
[^36]: 探索检索器和大型语言模型的整合策略

    Exploring the Integration Strategies of Retriever and Large Language Models. (arXiv:2308.12574v1 [cs.IR])

    [http://arxiv.org/abs/2308.12574](http://arxiv.org/abs/2308.12574)

    本文通过探索不同的检索器和大型语言模型整合方法来增强答案生成，并发现常用的连接方法存在局限性。为了解决这个问题，本文提出了四种替代策略，包括两种单轮方法和两种多轮策略。

    

    检索到的段落和大型语言模型（如ChatGPT）的整合为提高开放领域问答作出了显著贡献。然而，如何将检索到的段落融入答案生成过程中的最佳方法仍然缺乏探索。本文旨在通过研究不同的方法来结合检索到的段落和大型语言模型以增强答案生成。我们首先研究了常用的连接方法的局限性。令人惊讶的是，即使正确的文档在前k个检索到的段落中，这种方法经常会生成“未知”输出。为了解决这个问题，我们探索了四种将检索到的段落与大型语言模型整合的替代策略。这些策略包括两种利用思维链推理的单轮方法和两种利用反馈循环的多轮策略。通过全面的分析和实验，我们发现...

    The integration of retrieved passages and large language models (LLMs), such as ChatGPTs, has significantly contributed to improving open-domain question answering. However, there is still a lack of exploration regarding the optimal approach for incorporating retrieved passages into the answer generation process. This paper aims to fill this gap by investigating different methods of combining retrieved passages with LLMs to enhance answer generation. We begin by examining the limitations of a commonly-used concatenation approach. Surprisingly, this approach often results in generating "unknown" outputs, even when the correct document is among the top-k retrieved passages. To address this issue, we explore four alternative strategies for integrating the retrieved passages with the LLMs. These strategies include two single-round methods that utilize chain-of-thought reasoning and two multi-round strategies that incorporate feedback loops. Through comprehensive analyses and experiments, w
    
[^37]: 条件核模仿学习在连续状态环境中的应用

    Conditional Kernel Imitation Learning for Continuous State Environments. (arXiv:2308.12573v1 [cs.LG])

    [http://arxiv.org/abs/2308.12573](http://arxiv.org/abs/2308.12573)

    本研究以连续状态空间环境为基础，仅凭观察到的行为进行仿真学习，无需访问转移动力学信息、奖励结构，或者任何额外的交互。

    

    仿真学习（IL）是在更广泛的强化学习（RL）方法中的重要范例。与大多数RL不同，它不假设回馈奖励的可用性。奖励推断和塑形已知是困难且容易出错的方法，特别是当演示数据来自人类专家时。传统方法如行为克隆和逆向强化学习对估计误差非常敏感，这在连续状态空间问题中尤为严重。与此同时，最先进的IL算法将行为策略学习问题转换为分布匹配问题，通常需要额外的在线交互数据才能发挥作用。本文考虑了在连续状态空间环境中仅基于观察到的行为进行仿真学习的问题，不需要访问转移动力学信息、奖励结构，或者最重要的是不需要与环境进行任何额外交互。

    Imitation Learning (IL) is an important paradigm within the broader reinforcement learning (RL) methodology. Unlike most of RL, it does not assume availability of reward-feedback. Reward inference and shaping are known to be difficult and error-prone methods particularly when the demonstration data comes from human experts. Classical methods such as behavioral cloning and inverse reinforcement learning are highly sensitive to estimation errors, a problem that is particularly acute in continuous state space problems. Meanwhile, state-of-the-art IL algorithms convert behavioral policy learning problems into distribution-matching problems which often require additional online interaction data to be effective. In this paper, we consider the problem of imitation learning in continuous state space environments based solely on observed behavior, without access to transition dynamics information, reward structure, or, most importantly, any additional interactions with the environment. Our appr
    
[^38]: 一种用于嘈杂时间序列学习的协同训练方法

    A Co-training Approach for Noisy Time Series Learning. (arXiv:2308.12551v1 [cs.LG])

    [http://arxiv.org/abs/2308.12551](http://arxiv.org/abs/2308.12551)

    本研究提出了一种用于嘈杂时间序列学习的协同训练方法，通过多视图学习来减轻数据噪声和损坏的影响，并在多个时间序列基准上超越现有方法。

    

    本文致力于鲁棒的时间序列表示学习。我们的假设是现实世界的时间序列是嘈杂的，并且来自同一时间序列的不同观点的互补信息在分析嘈杂输入时发挥着重要作用。基于此，我们通过两个不同的编码器为输入时间序列创建了两个视图。我们通过协同训练基于对比学习的方式来迭代学习编码器。我们的实验表明，这种协同训练方法可以显著提高性能。特别是，通过利用来自不同视图的互补信息，我们提出的TS-CoT方法可以减轻数据噪声和损坏的影响。在无监督和半监督设置下对四个时间序列基准进行的实证评估表明，TS-CoT优于现有方法。此外，通过微调，TS-CoT学习到的表示可以很好地适用于下游任务。

    In this work, we focus on robust time series representation learning. Our assumption is that real-world time series is noisy and complementary information from different views of the same time series plays an important role while analyzing noisy input. Based on this, we create two views for the input time series through two different encoders. We conduct co-training based contrastive learning iteratively to learn the encoders. Our experiments demonstrate that this co-training approach leads to a significant improvement in performance. Especially, by leveraging the complementary information from different views, our proposed TS-CoT method can mitigate the impact of data noise and corruption. Empirical evaluations on four time series benchmarks in unsupervised and semi-supervised settings reveal that TS-CoT outperforms existing methods. Furthermore, the representations learned by TS-CoT can transfer well to downstream tasks through fine-tuning.
    
[^39]: 同步特征提取和匹配：一种用于3D物体跟踪的单支架构框架

    Synchronize Feature Extracting and Matching: A Single Branch Framework for 3D Object Tracking. (arXiv:2308.12549v1 [cs.CV])

    [http://arxiv.org/abs/2308.12549](http://arxiv.org/abs/2308.12549)

    这个论文提出了一种单支架构SyncTrack，通过同步特征提取和匹配来简化3D物体跟踪中的Siamese网络，避免了多次转发编码器和引入额外参数。研究结果表明，在Transformer层中引入了一个新的Attention Points-Sampling策略（APST）进行特征采样。

    

    与3D LiDAR物体跟踪中共享参数的编码器从模板和搜索区域分别提取特征的Siamese网络已成为事实上的基准框架。这个范式严重依赖于额外的匹配网络来建模模板和搜索区域的交叉相关性/相似性。本文不再使用传统的Siamese范式，提出了一种新颖的单支架构SyncTrack，通过同步特征提取和匹配，避免了为模板和搜索区域分别转发编码器两次，也避免了引入额外的匹配网络参数。同步机制基于Transformer的动态亲和力，并提供了理论上的相关性深入分析。此外，基于同步，我们引入了一种新颖的Transformer层中的Attention Points-Sampling策略（APST），用采样代替了随机/最远点采样（FPS）方法，并在采样过程中有监督地进行。

    Siamese network has been a de facto benchmark framework for 3D LiDAR object tracking with a shared-parametric encoder extracting features from template and search region, respectively. This paradigm relies heavily on an additional matching network to model the cross-correlation/similarity of the template and search region. In this paper, we forsake the conventional Siamese paradigm and propose a novel single-branch framework, SyncTrack, synchronizing the feature extracting and matching to avoid forwarding encoder twice for template and search region as well as introducing extra parameters of matching network. The synchronization mechanism is based on the dynamic affinity of the Transformer, and an in-depth analysis of the relevance is provided theoretically. Moreover, based on the synchronization, we introduce a novel Attentive Points-Sampling strategy into the Transformer layers (APST), replacing the random/Farthest Points Sampling (FPS) method with sampling under the supervision of a
    
[^40]: CALM: 一种用于全面评估语言模型偏见的多任务基准数据集

    CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias. (arXiv:2308.12539v1 [cs.CL])

    [http://arxiv.org/abs/2308.12539](http://arxiv.org/abs/2308.12539)

    CALM是一个用于量化语言模型偏见的多任务基准数据集，相比先前数据集更加多样和可靠，能更好地捕捉评估模型偏见所需的语言变化的广度。

    

    随着语言模型（LMs）的不断增强，量化和比较它们在社会和人口学偏见方面的能力以及潜在的危害变得越来越重要。先前的偏见测量数据集对于人工设计模板的扰动敏感，因此不可靠。为了保证可靠性，我们引入了全面评估语言模型偏见（CALM）的基准数据集，用于量化LMs在三个任务上的偏见。我们整合了来自不同领域（如维基百科和新闻文章）的16个现有数据集，过滤出224个模板，并构建了一个包含78,400个示例的数据集。我们通过平均语义相似性和模板长度的变异程度等指标，比较CALM与先前数据集的多样性，并测试其对细微扰动的敏感性。我们展示了我们的数据集相对于先前数据集更加多样和可靠，因此能更好地捕捉评估模型偏见所需的语言变化的广度。我们评估了20个大型语言模型的偏见。

    As language models (LMs) become increasingly powerful, it is important to quantify and compare them for sociodemographic bias with potential for harm. Prior bias measurement datasets are sensitive to perturbations in their manually designed templates, therefore unreliable. To achieve reliability, we introduce the Comprehensive Assessment of Language Model bias (CALM), a benchmark dataset to quantify bias in LMs across three tasks. We integrate 16 existing datasets across different domains, such as Wikipedia and news articles, to filter 224 templates from which we construct a dataset of 78,400 examples. We compare the diversity of CALM with prior datasets on metrics such as average semantic similarity, and variation in template length, and test the sensitivity to small perturbations. We show that our dataset is more diverse and reliable than previous datasets, thus better capture the breadth of linguistic variation required to reliably evaluate model bias. We evaluate 20 large language 
    
[^41]: FedSoL: 在联邦学习中解决全局对齐和本地一般性的问题

    FedSoL: Bridging Global Alignment and Local Generality in Federated Learning. (arXiv:2308.12532v1 [cs.LG])

    [http://arxiv.org/abs/2308.12532](http://arxiv.org/abs/2308.12532)

    FedSoL提出了一种联邦学习的方法，该方法旨在解决数据分布不均匀导致性能下降的问题。它通过平衡全局对齐和本地一般性来改善FL的学习效果。

    

    联邦学习(Federated Learning, FL)通过聚合来自个体客户端的本地训练模型来构建全局模型。虽然FL可以在保护数据隐私的情况下学习模型，但当客户端数据分布不均匀时，常常导致性能下降。许多先前的FL算法通过引入各种近似约束来解决这个问题。这些约束旨在通过限制局部学习与全局目标的偏离来促进全局对齐。然而，它们本质上通过干扰原始的局部目标而限制了局部学习。最近，出现了一种替代方法来改善本地学习的一般性。通过在平滑的损失空间中获得本地模型，这种方法减轻了客户端不同本地目标之间的冲突。然而，它不能确保稳定的全局对齐，因为本地学习不考虑全局目标。在本研究中，我们提出了联邦学习的稳定性(FedSoL)方法来在FL中解决全局对齐和本地一般性的问题。

    Federated Learning (FL) aggregates locally trained models from individual clients to construct a global model. While FL enables learning a model with data privacy, it often suffers from significant performance degradation when client data distributions are heterogeneous. Many previous FL algorithms have addressed this issue by introducing various proximal restrictions. These restrictions aim to encourage global alignment by constraining the deviation of local learning from the global objective. However, they inherently limit local learning by interfering with the original local objectives. Recently, an alternative approach has emerged to improve local learning generality. By obtaining local models within a smooth loss landscape, this approach mitigates conflicts among different local objectives of the clients. Yet, it does not ensure stable global alignment, as local learning does not take the global objective into account. In this study, we propose Federated Stability on Learning (Fed
    
[^42]: 不仅仅奖励，还有约束：用于腿式机器人运动的应用

    Not Only Rewards But Also Constraints: Applications on Legged Robot Locomotion. (arXiv:2308.12517v1 [cs.RO])

    [http://arxiv.org/abs/2308.12517](http://arxiv.org/abs/2308.12517)

    本文提出了一种新的强化学习框架，为复杂机器人系统训练神经网络控制器。该框架引入了奖励和约束的概念，通过设计高效的策略优化算法来处理约束，以减少计算开销。通过应用于不同腿式机器人的运动控制器训练中，展示了该框架的有效性。

    

    早期的一些研究通过设计神经网络控制器并使用无模型强化学习来训练，展示了复杂机器人系统中令人印象深刻的控制性能。然而，这些具有自然动作风格和高任务性能的出色控制器是通过进行大量奖励工程而开发的，该过程非常费时费力，需要设计大量奖励项并确定合适的奖励系数。在这项工作中，我们提出了一种新的强化学习框架，用于训练同时包含奖励和约束的神经网络控制器。为了让工程师能够适当地反映他们对约束的意图并以最小的计算开销处理它们，我们提出了两种约束类型和一种高效的策略优化算法。该学习框架被应用于训练不同形态和物理属性的几个腿式机器人的运动控制器。

    Several earlier studies have shown impressive control performance in complex robotic systems by designing the controller using a neural network and training it with model-free reinforcement learning. However, these outstanding controllers with natural motion style and high task performance are developed through extensive reward engineering, which is a highly laborious and time-consuming process of designing numerous reward terms and determining suitable reward coefficients. In this work, we propose a novel reinforcement learning framework for training neural network controllers for complex robotic systems consisting of both rewards and constraints. To let the engineers appropriately reflect their intent to constraints and handle them with minimal computation overhead, two constraint types and an efficient policy optimization algorithm are suggested. The learning framework is applied to train locomotion controllers for several legged robots with different morphology and physical attribu
    
[^43]: I3DOD: 基于引导的增量式三维物体检测方法

    I3DOD: Towards Incremental 3D Object Detection via Prompting. (arXiv:2308.12512v1 [cs.CV])

    [http://arxiv.org/abs/2308.12512](http://arxiv.org/abs/2308.12512)

    I3DOD是一种基于引导的增量式三维物体检测方法，通过引导机制学习对象定位信息和类别语义信息之间的匹配关系，解决了旧类的遗忘问题。

    

    三维物体检测在许多领域，如机器人系统、自动驾驶和增强现实中取得了显著的性能。然而，大多数现有方法在处理类增量型场景时可能导致旧类的灾难性遗忘。同时，当前的类增量型三维物体检测方法忽视了对象定位信息和类别语义信息之间的关系，并假设旧模型的全部知识是可靠的。为了解决上述挑战，我们提出了一种新颖的增量式三维物体检测框架，即I3DOD。具体而言，我们提出了一种任务共享的引导机制，用于学习对象定位信息和类别语义信息之间的匹配关系。训练完成后，这些引导将被存储在我们的引导池中，并在下一个任务中处理旧类的关系。此外，我们设计了一种可靠的蒸馏方法

    3D object detection has achieved significant performance in many fields, e.g., robotics system, autonomous driving, and augmented reality. However, most existing methods could cause catastrophic forgetting of old classes when performing on the class-incremental scenarios. Meanwhile, the current class-incremental 3D object detection methods neglect the relationships between the object localization information and category semantic information and assume all the knowledge of old model is reliable. To address the above challenge, we present a novel Incremental 3D Object Detection framework with the guidance of prompting, i.e., I3DOD. Specifically, we propose a task-shared prompts mechanism to learn the matching relationships between the object localization information and category semantic information. After training on the current task, these prompts will be stored in our prompt pool, and perform the relationship of old classes in the next task. Moreover, we design a reliable distillatio
    
[^44]: Masked Autoencoders是高效的分类增量学习器

    Masked Autoencoders are Efficient Class Incremental Learners. (arXiv:2308.12510v1 [cs.CV])

    [http://arxiv.org/abs/2308.12510](http://arxiv.org/abs/2308.12510)

    本论文提出了使用掩蔽自编码器(MAEs)作为高效的分类增量学习器，通过重建原始输入图像和学习图像级和嵌入级融合来存储和学习过去任务的表示。实验证实，在CIFAR-100，ImageNet-Subset和ImageNet-Full上，该方法优于现有最先进的方法。

    

    分类增量学习(CIL)旨在在学习新类别的同时避免对之前知识的灾难性遗忘。我们提出使用掩蔽自编码器(MAEs)作为CIL的高效学习器。MAEs最初是为了通过重建无监督学习来学习有用的表示，并且它们可以轻松地与监督损失结合以用于分类。此外，MAEs可以可靠地从随机选择的图像补丁中重建原始输入图像，我们使用这种方法更高效地存储过去任务的范例用于CIL。我们还提出了双边MAE框架来学习图像级和嵌入级融合，它可以产生更高质量的重建图像和更稳定的表示。我们的实验证实，我们的方法在CIFAR-100，ImageNet-Subset和ImageNet-Full上优于现有最先进的方法。代码可在https://github.com/scok30/MAE-CIL上获取。

    Class Incremental Learning (CIL) aims to sequentially learn new classes while avoiding catastrophic forgetting of previous knowledge. We propose to use Masked Autoencoders (MAEs) as efficient learners for CIL. MAEs were originally designed to learn useful representations through reconstructive unsupervised learning, and they can be easily integrated with a supervised loss for classification. Moreover, MAEs can reliably reconstruct original input images from randomly selected patches, which we use to store exemplars from past tasks more efficiently for CIL. We also propose a bilateral MAE framework to learn from image-level and embedding-level fusion, which produces better-quality reconstructed images and more stable representations. Our experiments confirm that our approach performs better than the state-of-the-art on CIFAR-100, ImageNet-Subset, and ImageNet-Full. The code is available at https://github.com/scok30/MAE-CIL .
    
[^45]: CGMI: 可配置的通用多智能体交互框架。

    CGMI: Configurable General Multi-Agent Interaction Framework. (arXiv:2308.12503v1 [cs.AI])

    [http://arxiv.org/abs/2308.12503](http://arxiv.org/abs/2308.12503)

    本研究提出了一个名为CGMI的框架，旨在模拟真实世界场景中的人际交往。该框架采用了树状结构方法来管理智能体的个性，并设计了一个基于ACT*模型的认知架构。通过使用CGMI框架，我们成功模拟了教师和学生之间的课堂互动。

    

    由于大型语言模型（LLM）的强大能力，基于LLM的智能体已经展现出解决特定领域任务和模仿人类行为的潜力。然而，由于其有限的领域专业知识以及缺乏有效的认知架构，这些智能体生成的内容仍然相对表面。为解决这个问题，我们提出了一个可配置的通用多智能体交互（CGMI）框架，旨在模拟真实世界场景中的人际交往。具体而言，我们提出了一种树状结构的方法论，用于智能体的个性分配、检测和维护。此外，我们设计了一个基于ACT*模型的技能库的认知架构，其中包含记忆、反思和规划模块。我们还整合了通用智能体来增强虚拟环境的真实感。利用CGMI框架，我们模拟了多个教师和学生之间的课堂互动。

    Benefiting from the powerful capabilities of large language models (LLMs), agents based on LLMs have shown the potential to address domain-specific tasks and emulate human behaviors. However, the content generated by these agents remains somewhat superficial, owing to their limited domain expertise and the absence of an effective cognitive architecture. To address this, we present the Configurable General Multi-Agent Interaction (CGMI) framework, designed to replicate human interactions in real-world scenarios. Specifically, we propose a tree-structured methodology for the assignment, detection, and maintenance of agent personality. Additionally, we designed a cognitive architecture equipped with a skill library based on the ACT* model, which contains memory, reflection, and planning modules. We have also integrated general agents to augment the virtual environment's realism. Using the CGMI framework, we simulated numerous classroom interactions between teacher and students. The experi
    
[^46]: 无源协作领域适应：多角度特征增强在功能磁共振成像分析中的应用

    Source-Free Collaborative Domain Adaptation via Multi-Perspective Feature Enrichment for Functional MRI Analysis. (arXiv:2308.12495v1 [cs.CV])

    [http://arxiv.org/abs/2308.12495](http://arxiv.org/abs/2308.12495)

    通过无需源数据，使用多角度特征增强的方法提出了一种无源协作领域适应（SCDA）框架，用于静息态功能磁共振成像（rs-fMRI）分析。该方法能够减少不同扫描仪/协议导致的跨站点/领域数据异质性。

    

    静息态功能磁共振成像（rs-fMRI）在多地点研究中越来越常用于辅助神经学疾病分析。现有研究通常受到跨站点/领域数据异质性的影响，这是由于不同的扫描仪/协议导致的。许多方法已被提出以减少源域和目标域之间的fMRI异质性，但这往往需要源数据的可用性。然而，在多地点研究中由于隐私和/或数据存储负担的问题，获取源数据很具挑战性。为此，我们设计了一种无源协作领域适应（SCDA）框架用于fMRI分析，其中仅能访问预先训练的源模型和无标签的目标数据。具体地，我们开发了一种多角度特征增强方法（MFE）用于目标fMRI分析，由多个协作分支组成，动态地捕捉来自多个视角的无标签目标数据的fMRI特征。每个分支都具有一个数据进给模块，

    Resting-state functional MRI (rs-fMRI) is increasingly employed in multi-site research to aid neurological disorder analysis. Existing studies usually suffer from significant cross-site/domain data heterogeneity caused by site effects such as differences in scanners/protocols. Many methods have been proposed to reduce fMRI heterogeneity between source and target domains, heavily relying on the availability of source data. But acquiring source data is challenging due to privacy concerns and/or data storage burdens in multi-site studies. To this end, we design a source-free collaborative domain adaptation (SCDA) framework for fMRI analysis, where only a pretrained source model and unlabeled target data are accessible. Specifically, a multi-perspective feature enrichment method (MFE) is developed for target fMRI analysis, consisting of multiple collaborative branches to dynamically capture fMRI features of unlabeled target data from multiple views. Each branch has a data-feeding module, a
    
[^47]: GPTEval: 对ChatGPT和GPT-4评估的调查

    GPTEval: A Survey on Assessments of ChatGPT and GPT-4. (arXiv:2308.12488v1 [cs.AI])

    [http://arxiv.org/abs/2308.12488](http://arxiv.org/abs/2308.12488)

    本文对ChatGPT和GPT-4的先前评估进行了综合分析，关注其语言和推理能力、科学知识和伦理考虑，提出了几个评估大型语言模型的建议。

    

    ChatGPT的出现引发了媒体对其扰乱社会和经济系统潜力的许多猜测。其惊人的语言能力激起学者们对其在不同领域表现的浓厚兴趣。已经有许多研究评估了ChatGPT和GPT-4在不同任务和学科中的能力。然而，缺乏一项综合性的综述总结集体评估结果。本调查的目标是对ChatGPT和GPT-4的先前评估进行深入分析，重点关注其语言和推理能力、科学知识和伦理考虑。此外，对现有评估方法进行了检查，并提出了几个未来研究评估大型语言模型的建议。

    The emergence of ChatGPT has generated much speculation in the press about its potential to disrupt social and economic systems. Its astonishing language ability has aroused strong curiosity among scholars about its performance in different domains. There have been many studies evaluating the ability of ChatGPT and GPT-4 in different tasks and disciplines. However, a comprehensive review summarizing the collective assessment findings is lacking. The objective of this survey is to thoroughly analyze prior assessments of ChatGPT and GPT-4, focusing on its language and reasoning abilities, scientific knowledge, and ethical considerations. Furthermore, an examination of the existing evaluation methods is conducted, offering several recommendations for future research in evaluating large language models.
    
[^48]: 基于非公理逻辑的顺序学习模型

    A Model of Sequential Learning based on Non-Axiomatic Logic. (arXiv:2308.12486v1 [cs.AI])

    [http://arxiv.org/abs/2308.12486](http://arxiv.org/abs/2308.12486)

    这个论文提出了一个基于非公理逻辑的顺序学习模型，用于智能代理的学习功能。它包含假设、修正和循环三个步骤，并在知识和资源不足的情况下工作。尽管有一些限制，但该模型已在一些简单案例中证明有效。

    

    顺序学习是智能代理的基本功能。本技术报告介绍了一个基于非公理逻辑的顺序学习模型。学习过程包括假设、修正和循环三个步骤，并可以适用于知识和资源不足的情况。虽然当前设计存在一定限制，但该模型已在一些简单案例中证明有效。

    Sequential learning is a fundamental function of an intelligent agent. This technical report introduces a model of sequential learning, which is interpretable through Non-Axiomatic Logic. The learning procedure includes three steps, hypothesizing, revising, and recycling, and can work under the Assumption of Insufficient Knowledge and Resources. Although there are limitations for the current design, the model has been proven effective in some simple cases.
    
[^49]: 基于注意力的声学特征融合网络用于抑郁症检测

    Attention-Based Acoustic Feature Fusion Network for Depression Detection. (arXiv:2308.12478v1 [cs.SD])

    [http://arxiv.org/abs/2308.12478](http://arxiv.org/abs/2308.12478)

    提出了一种新颖的基于注意力的声学特征融合网络（ABAFnet）用于抑郁症检测，能够有效整合和融合多种语音特征，提高检测性能。

    

    抑郁症是一种常见的心理障碍，对个体产生重大影响并对社会造成巨大冲击。由于该疾病的复杂性和异质性，迫切需要及时有效的检测方法，但这也带来了巨大的挑战。利用先进的机器学习模型，通过利用听觉数据进行研究，展示了有希望的研究方向。然而，现有技术主要依赖于单一维度的特征模型，可能忽略了多种语音特征中隐藏的丰富信息。为了解决这个问题，我们提出了一种新颖的基于注意力的声学特征融合网络（ABAFnet）用于抑郁症检测。ABAFnet将四种不同的声学特征结合到一个综合的深度学习模型中，有效地整合和融合了多层次的特征。

    Depression, a common mental disorder, significantly influences individuals and imposes considerable societal impacts. The complexity and heterogeneity of the disorder necessitate prompt and effective detection, which nonetheless, poses a difficult challenge. This situation highlights an urgent requirement for improved detection methods. Exploiting auditory data through advanced machine learning paradigms presents promising research directions. Yet, existing techniques mainly rely on single-dimensional feature models, potentially neglecting the abundance of information hidden in various speech characteristics. To rectify this, we present the novel Attention-Based Acoustic Feature Fusion Network (ABAFnet) for depression detection. ABAFnet combines four different acoustic features into a comprehensive deep learning model, thereby effectively integrating and blending multi-tiered features. We present a novel weight adjustment module for late fusion that boosts performance by efficaciously 
    
[^50]: ChatGPT和GPT-4是优秀的扑克玩家吗？——一项Pre-Flop分析。

    Are ChatGPT and GPT-4 Good Poker Players? -- A Pre-Flop Analysis. (arXiv:2308.12466v1 [cs.CL])

    [http://arxiv.org/abs/2308.12466](http://arxiv.org/abs/2308.12466)

    ChatGPT和GPT-4在扑克中显示出高级理解，但不是游戏论理最优的扑克玩家。对模型参数和提示的优化可以提高它们在扑克中的表现。

    

    自ChatGPT和GPT-4问世以来，这些模型已在许多任务中进行了测试。它们在各个领域的熟练程度是显而易见的，但它们在游戏中的能力，特别是在扑克领域的能力，还未被探索。扑克是一种需要在不确定性和不完全信息下做出决策的游戏。在本文中，我们对ChatGPT和GPT-4进行了扑克测试，并评估了它们的扑克技能。我们的研究结果显示，虽然这两个模型都展示了对扑克的高级理解，包括起始手牌的估值、打牌位置以及游戏论理最优(GTO)扑克的其他复杂性，但ChatGPT和GPT-4并不是游戏论理最优的扑克玩家。通过一系列实验，我们首先发现了与使用这些模型玩扑克相关的最佳提示和模型参数的特征。接着，我们观察到了这两个模型具有不同的打牌风格。最终，我们得出结论：GPT-4是

    Since the introduction of ChatGPT and GPT-4, these models have been tested across a large number of tasks. Their adeptness across domains is evident, but their aptitude in playing games and specifically their aptitude in the realm of poker has remained unexplored. Poker is a game that requires decision making under uncertainty and incomplete information. In this paper, we put ChatGPT and GPT-4 through the poker test and evaluate their poker skills. Our findings reveal that while both models display an advanced understanding of poker, encompassing concepts like the valuation of starting hands, playing positions and other intricacies of game theory optimal (GTO) poker, both ChatGPT and GPT-4 are NOT game theory optimal poker players.  Through a series of experiments, we first discover the characteristics of optimal prompts and model parameters for playing poker with these models. Our observations then unveil the distinct playing personas of the two models. We first conclude that GPT-4 is
    
[^51]: PFL-GAN：当客户异质性与生成模型相遇在个性化联合学习中

    PFL-GAN: When Client Heterogeneity Meets Generative Models in Personalized Federated Learning. (arXiv:2308.12454v1 [cs.LG])

    [http://arxiv.org/abs/2308.12454](http://arxiv.org/abs/2308.12454)

    PFL-GAN是一种在个性化联合学习中解决客户异质性的新型GAN共享和聚合策略，通过学习客户间的相似度并采用加权协同数据聚合方法来实现。

    

    近期生成学习模型的进展伴随着对基于生成对抗网络（GAN）模型的联合学习（FL）的日益关注。在FL的背景下，GAN可以捕捉底层客户数据结构，并重新生成类似于原始数据分布的样本，而不损害私有原始数据。虽然大多数现有基于GAN的FL工作集中在训练全局模型上，但在客户数据异质性方面，个性化FL（PFL）有时可能更加有效，因为它涉及到不同数据样本分布、特征空间和标签。为了应对GAN-based FL中的客户异质性，我们提出了一种针对PFL的新型GAN共享和聚合策略。所提出的PFL-GAN解决了不同场景下的客户异质性问题。具体而言，我们首先学习客户之间的相似度，然后开发一个加权的协同数据聚合方法。通过在几个知名数据集上进行严格的实验来验证此方法的实际效果。

    Recent advances of generative learning models are accompanied by the growing interest in federated learning (FL) based on generative adversarial network (GAN) models. In the context of FL, GAN can capture the underlying client data structure, and regenerate samples resembling the original data distribution without compromising the private raw data. Although most existing GAN-based FL works focus on training a global model, Personalized FL (PFL) sometimes can be more effective in view of client data heterogeneity in terms of distinct data sample distributions, feature spaces, and labels. To cope with client heterogeneity in GAN-based FL, we propose a novel GAN sharing and aggregation strategy for PFL. The proposed PFL-GAN addresses the client heterogeneity in different scenarios. More specially, we first learn the similarity among clients and then develop an weighted collaborative data aggregation. The empirical results through the rigorous experimentation on several well-known datasets
    
[^52]: 利用潜在扩散模型的合成数据增强医学图像分类器

    Augmenting medical image classifiers with synthetic data from latent diffusion models. (arXiv:2308.12453v1 [cs.CV])

    [http://arxiv.org/abs/2308.12453](http://arxiv.org/abs/2308.12453)

    使用潜在扩散模型生成的合成数据可提高医学图像分类器的性能，在数据受限的情况下表现出饱和效果，比添加真实图像获得的性能提升要小得多。

    

    虽然现在有数百种人工智能算法已获得美国食品和药物管理局的批准或清除，但许多研究显示其一致性泛化或潜在偏差存在不一致，特别是对于少数群体。有人提出生成式人工智能可以减少对真实数据的需求，但其在模型开发中的效用尚不清楚。皮肤疾病是合成图像生成的有用案例研究，因为疾病外观具有多样性，特别是在皮肤色调这一保护属性上。我们展示了潜在扩散模型可以可扩展地生成皮肤疾病图像，并且在数据受限情况下，将这些数据用于模型训练可以提高性能。这种性能提升在合成到真实图像比例超过10：1后达到饱和，并且比添加真实图像所获得的提升要小得多。作为我们分析的一部分，我们生成并分析了一个新的数据集，其中包括458,920个合成图像。

    While hundreds of artificial intelligence (AI) algorithms are now approved or cleared by the US Food and Drugs Administration (FDA), many studies have shown inconsistent generalization or latent bias, particularly for underrepresented populations. Some have proposed that generative AI could reduce the need for real data, but its utility in model development remains unclear. Skin disease serves as a useful case study in synthetic image generation due to the diversity of disease appearance, particularly across the protected attribute of skin tone. Here we show that latent diffusion models can scalably generate images of skin disease and that augmenting model training with these data improves performance in data-limited settings. These performance gains saturate at synthetic-to-real image ratios above 10:1 and are substantially smaller than the gains obtained from adding real images. As part of our analysis, we generate and analyze a new dataset of 458,920 synthetic images produced using 
    
[^53]: 一种基于有意遗忘驱动的自愈深度强化学习系统的方法

    An Intentional Forgetting-Driven Self-Healing Method For Deep Reinforcement Learning Systems. (arXiv:2308.12445v1 [cs.LG])

    [http://arxiv.org/abs/2308.12445](http://arxiv.org/abs/2308.12445)

    本文提出了一种名为 Dr. DRL 的自愈方法，用于解决深度强化学习系统中的一些效率问题，该方法通过在连续学习中引入有意遗忘的机制来应对环境漂移引起的困扰。

    

    深度强化学习 (DRL) 在像 Netflix 和 Facebook 这样的大规模应用中越来越多。和大多数数据驱动系统一样，DRL 系统可能由于环境漂移导致不良行为，而这种漂移经常发生在不断变化的生产环境中。连续学习 (CL) 是自愈方法，用于根据环境条件的变化调整 DRL 代理。然而，大规模的连续变化可能导致生产环境从原始状态偏离。最近的研究表明，这些环境漂移往往导致连续学习进入长时间的自愈周期，甚至无法成功，这是由于灾难性遗忘、温和起始失败和收敛缓慢等效率低下问题引起的。在本文中，我们提出 Dr. DRL，一种对 DRL 系统的有效自愈方法，它将有意遗忘的新颖机制整合到原始的连续学习中以解决其主要问题。Dr. DRL 有意地擦除...

    Deep reinforcement learning (DRL) is increasingly applied in large-scale productions like Netflix and Facebook. As with most data-driven systems, DRL systems can exhibit undesirable behaviors due to environmental drifts, which often occur in constantly-changing production settings. Continual Learning (CL) is the inherent self-healing approach for adapting the DRL agent in response to the environment's conditions shifts. However, successive shifts of considerable magnitude may cause the production environment to drift from its original state. Recent studies have shown that these environmental drifts tend to drive CL into long, or even unsuccessful, healing cycles, which arise from inefficiencies such as catastrophic forgetting, warm-starting failure, and slow convergence. In this paper, we propose Dr. DRL, an effective self-healing approach for DRL systems that integrates a novel mechanism of intentional forgetting into vanilla CL to overcome its main issues. Dr. DRL deliberately erases
    
[^54]: BaDExpert: 提取后门功能以实现准确的后门输入检测

    BaDExpert: Extracting Backdoor Functionality for Accurate Backdoor Input Detection. (arXiv:2308.12439v1 [cs.CR])

    [http://arxiv.org/abs/2308.12439](http://arxiv.org/abs/2308.12439)

    BaDExpert是一种防御后门攻击的新方法，通过逆向工程提取给定后门模型的后门功能，并生成一个专家模型，该模型只能识别后门输入。可以进一步使用该模型设计高度准确的后门输入检测器。

    

    我们提出了一种新颖的防御方法，用于对抗深度神经网络（DNN）上的后门攻击，其中对手将恶意行为（后门）秘密地植入DNN中。我们的防御属于后期开发的防御范畴，独立于模型生成的方式。所提出的防御方法基于一种新颖的逆向工程方法，可以直接提取给定后门模型的后门功能并生成一个专家模型。该方法很简单 - 在一小组有意义的错误标记的干净样本上微调后门模型，从而使其忘记正常功能但仍保留后门功能，从而生成一个只能识别后门输入的模型（称为后门专家模型）。基于提取的后门专家模型，我们展示了设计高度准确的后门输入检测器的可行性，在模型推理过程中过滤掉后门输入。进一步通过...

    We present a novel defense, against backdoor attacks on Deep Neural Networks (DNNs), wherein adversaries covertly implant malicious behaviors (backdoors) into DNNs. Our defense falls within the category of post-development defenses that operate independently of how the model was generated. The proposed defense is built upon a novel reverse engineering approach that can directly extract backdoor functionality of a given backdoored model to a backdoor expert model. The approach is straightforward -- finetuning the backdoored model over a small set of intentionally mislabeled clean samples, such that it unlearns the normal functionality while still preserving the backdoor functionality, and thus resulting in a model (dubbed a backdoor expert model) that can only recognize backdoor inputs. Based on the extracted backdoor expert model, we show the feasibility of devising highly accurate backdoor input detectors that filter out the backdoor inputs during model inference. Further augmented by
    
[^55]: 部署深度强化学习系统：挑战分类

    Deploying Deep Reinforcement Learning Systems: A Taxonomy of Challenges. (arXiv:2308.12438v1 [cs.LG])

    [http://arxiv.org/abs/2308.12438](http://arxiv.org/abs/2308.12438)

    本文通过对开发者问答论坛Stack Overflow上的帖子进行实证研究，总结了部署深度强化学习系统所面临的挑战，并针对不同的部署平台进行了分类。

    

    深度强化学习（DRL）利用深度学习（DL）在强化学习中，已经在包括机器人、计算机视觉和电脑游戏等领域显示出显著潜力，以实现人类水平的自主能力。这种潜力引起了学术界和工业界对DRL的热情和日益增长的兴趣。然而，目前社区主要集中在DRL系统开发阶段，对DRL部署关注较少。在本文中，我们对开发者最流行的问答论坛Stack Overflow（SO）进行了一项实证研究，以揭示和了解从业人员在部署DRL系统时遇到的挑战。具体而言，我们按部署平台对相关SO帖子进行了分类：服务器/云、移动/嵌入式系统、浏览器和游戏引擎。经过过滤和手动分析，我们研究了357个有关DRL部署的SO帖子，调查了当前状况，并确定了与部署DRL系统相关的挑战。

    Deep reinforcement learning (DRL), leveraging Deep Learning (DL) in reinforcement learning, has shown significant potential in achieving human-level autonomy in a wide range of domains, including robotics, computer vision, and computer games. This potential justifies the enthusiasm and growing interest in DRL in both academia and industry. However, the community currently focuses mostly on the development phase of DRL systems, with little attention devoted to DRL deployment. In this paper, we propose an empirical study on Stack Overflow (SO), the most popular Q&A forum for developers, to uncover and understand the challenges practitioners faced when deploying DRL systems. Specifically, we categorized relevant SO posts by deployment platforms: server/cloud, mobile/embedded system, browser, and game engine. After filtering and manual analysis, we examined 357 SO posts about DRL deployment, investigated the current state, and identified the challenges related to deploying DRL systems. The
    
[^56]: 重塑脑龄预测问题为更可解释和量化的方法

    Reframing the Brain Age Prediction Problem to a More Interpretable and Quantitative Approach. (arXiv:2308.12416v1 [eess.IV])

    [http://arxiv.org/abs/2308.12416](http://arxiv.org/abs/2308.12416)

    本论文提出了一种重塑脑龄预测问题的方法，将其转化为图像到图像的回归问题，通过估计每个脑部体素的脑龄来提供更可解释的结果。与全局年龄预测模型相比，逐体素年龄预测模型提供了更可解释的空间信息。

    

    深度学习模型已经在估计磁共振图像中的脑龄（一个重要的脑健康生物标志）方面取得了最先进的结果。然而，大多数模型只提供全局的年龄预测，并依赖于像显著性图这样的技术来解释结果。这些显著性图突出显示了对模型预测有重要意义的输入图像区域，但很难解释，并且显著性图的值在不同样本之间无法直接比较。在本研究中，我们将脑龄预测问题从磁共振图像转换为图像到图像的回归问题，其中我们估计每个脑部体素的脑龄。我们将逐体素年龄预测模型与全局年龄预测模型及其对应的显著性图进行对比。结果表明，逐体素年龄预测模型更易解释，因为它们提供了关于脑衰老过程的空间信息，并且它们从中受益。

    Deep learning models have achieved state-of-the-art results in estimating brain age, which is an important brain health biomarker, from magnetic resonance (MR) images. However, most of these models only provide a global age prediction, and rely on techniques, such as saliency maps to interpret their results. These saliency maps highlight regions in the input image that were significant for the model's predictions, but they are hard to be interpreted, and saliency map values are not directly comparable across different samples. In this work, we reframe the age prediction problem from MR images to an image-to-image regression problem where we estimate the brain age for each brain voxel in MR images. We compare voxel-wise age prediction models against global age prediction models and their corresponding saliency maps. The results indicate that voxel-wise age prediction models are more interpretable, since they provide spatial information about the brain aging process, and they benefit fro
    
[^57]: 用于源代码的大型语言模型的因果研究基准评估

    Benchmarking Causal Study to Interpret Large Language Models for Source Code. (arXiv:2308.12415v1 [cs.SE])

    [http://arxiv.org/abs/2308.12415](http://arxiv.org/abs/2308.12415)

    这项研究提出了一种用于源代码的大型语言模型的因果研究基准评估，以解决包括因果推断在内的模型性能可解释性的问题。

    

    软件研究人员常采用的解决代码生成的常见方法是通过对大量源代码进行大型语言模型（LLM）的训练。尽管许多研究已经表明LLM在流行的精确度指标（例如BLEU，CodeBleu）上已经得到了有效评估，但以前的研究在LLM性能的可解释性的根本组成部分——因果推断的作用方面主要被忽视了。现有的基准和数据集旨在突出预期结果与生成结果之间的差异，但没有考虑同样影响精确度指标的混淆变量（例如代码行数，提示大小）。事实上，在处理LLM的生成软件任务时，没有基准可以告诉研究人员如何量化基于软件工程的处理的因果效应以及混淆变量与模型性能的相关性。为了在评估LLM时引入统计严谨性。

    One of the most common solutions adopted by software researchers to address code generation is by training Large Language Models (LLMs) on massive amounts of source code. Although a number of studies have shown that LLMs have been effectively evaluated on popular accuracy metrics (e.g., BLEU, CodeBleu), previous research has largely overlooked the role of Causal Inference as a fundamental component of the interpretability of LLMs' performance. Existing benchmarks and datasets are meant to highlight the difference between the expected and the generated outcome, but do not take into account confounding variables (e.g., lines of code, prompt size) that equally influence the accuracy metrics. The fact remains that, when dealing with generative software tasks by LLMs, no benchmark is available to tell researchers how to quantify neither the causal effect of SE-based treatments nor the correlation of confounders to the model's performance. In an effort to bring statistical rigor to the evalu
    
[^58]: 智能的一种理论：概念、模型和意义

    A Theory of Intelligences: Concepts, Models, Implications. (arXiv:2308.12411v1 [cs.AI])

    [http://arxiv.org/abs/2308.12411](http://arxiv.org/abs/2308.12411)

    这篇论文提出了一种智能的理论，讨论了智能的核心要素和挑战，并提出了基于第一原理的理论。研究重点是人类智能，并与机器进行比较，目的是为更广泛的生命、集合体和非设计的物理化学系统提供描述。

    

    智能是人类用来表示实现目标能力的概念。给予这个广泛的范畴，智能已经被无数次定义，以各种方式进行研究，并使用多种测量方法进行量化。理解智能最终需要理论和量化，但这两者都很难捉摸。我的主要目标是确定智能的一些核心要素，讨论其中的一些挑战，并提出一种基于第一原理的理论。我主要关注以人类为定义和参照对象的智能，常常与机器进行比较，意图为生命、集合体、人工智能等非设计的物理和化学系统提供更一般化的描述。我讨论了智能的关键特征，包括路径效率和目标准确性、智能作为黑盒、环境影响、处理意外情况的灵活性、智能的回归和相对论性质。

    Intelligence is a human construct to represent the ability to achieve goals. Given this wide berth, intelligence has been defined countless times, studied in a variety of ways and quantified using numerous measures. Understanding intelligence ultimately requires theory and quantification, both of which are elusive. My main objectives are to identify some of the central elements in and surrounding intelligence, discuss some of its challenges and propose a theory based on first principles. I focus on intelligence as defined by and for humans, frequently in comparison to machines, with the intention of setting the stage for more general characterizations in life, collectives, human designs such as AI and in non-designed physical and chemical systems. I discuss key features of intelligence, including path efficiency and goal accuracy, intelligence as a Black Box, environmental influences, flexibility to deal with surprisal, the regress of intelligence, the relativistic nature of intelligen
    
[^59]: 自监督学习用于内窥镜视频分析

    Self-Supervised Learning for Endoscopic Video Analysis. (arXiv:2308.12394v1 [cs.CV])

    [http://arxiv.org/abs/2308.12394](http://arxiv.org/abs/2308.12394)

    本研究研究了自监督学习在内窥镜视频分析中的应用，使用Masked Siamese Networks（MSNs）框架进行训练，并通过创建大规模未标记的视频数据集来充分利用自监督学习的能力。在有限标记数据的二次训练下，实现了内窥镜基准测试的最先进性能。

    

    自监督学习（SSL）通过允许从大量未标记数据中学习，已经在计算机视觉领域取得了重要突破。因此，在需要高度专门化专业知识来注释数据的生物医学领域中，SSL可能发挥关键作用。然而，在许多医疗领域中，SSL的应用尚未广泛探索，其中之一就是内窥镜检查，这种微创手术常用于检测和治疗感染、慢性炎症性疾病或癌症。本研究中，我们研究了一种领先的SSL框架，即Masked Siamese Networks（MSNs），用于内窥镜视频分析，例如结肠镜检查和腹腔镜检查。为了充分利用SSL的能力，我们创建了大规模的未标记内窥镜视频数据集来训练MSN。这些强大的图像表示作为有限标记数据集的二次训练的基础，使得在内窥镜基准测试中获得了最先进的性能，如手术阶段识别等。

    Self-supervised learning (SSL) has led to important breakthroughs in computer vision by allowing learning from large amounts of unlabeled data. As such, it might have a pivotal role to play in biomedicine where annotating data requires a highly specialized expertise. Yet, there are many healthcare domains for which SSL has not been extensively explored. One such domain is endoscopy, minimally invasive procedures which are commonly used to detect and treat infections, chronic inflammatory diseases or cancer. In this work, we study the use of a leading SSL framework, namely Masked Siamese Networks (MSNs), for endoscopic video analysis such as colonoscopy and laparoscopy. To fully exploit the power of SSL, we create sizable unlabeled endoscopic video datasets for training MSNs. These strong image representations serve as a foundation for secondary training with limited annotated datasets, resulting in state-of-the-art performance in endoscopic benchmarks like surgical phase recognition du
    
[^60]: 处理$\min\rightarrow$模糊关系方程组的不一致性

    Handling the inconsistency of systems of $\min\rightarrow$ fuzzy relational equations. (arXiv:2308.12385v1 [cs.AI])

    [http://arxiv.org/abs/2308.12385](http://arxiv.org/abs/2308.12385)

    本文研究了$\min-\rightarrow$模糊关系方程组的不一致性，并给出了计算与该方程组相关的Chebyshev距离的分析公式。最终证明，在某些情况下，该距离可能为下确界，而在任何情况下都为最小值。

    

    本文研究了$\min-\rightarrow$模糊关系方程组的不一致性。我们给出了计算与形式为$\Gamma \Box_{\rightarrow}^{\min} x = \beta$的$\min-\rightarrow$模糊关系方程组相关的Chebyshev距离$\nabla = \inf_{d \in \mathcal{D}} \Vert \beta - d \Vert$的分析公式，其中$\rightarrow$是G\"odel蕴含、Goguen蕴含或Lukasiewicz蕴含之一，$\mathcal{D}$是通过相同矩阵$\Gamma$定义的一致方程组的第二成员的集合。允许我们得到这些公式的主要初步结果是，无论使用哪种残差蕴含，Chebyshev距离$\nabla$都是一个向量不等式解的下界。最后，我们证明，在$\min-\rightarrow_{G}$系统的情况下，Chebyshev距离$\nabla$可能是一个下确界，而在任何情况下它都是一个最小值。

    In this article, we study the inconsistency of systems of $\min-\rightarrow$ fuzzy relational equations. We give analytical formulas for computing the Chebyshev distances $\nabla = \inf_{d \in \mathcal{D}} \Vert \beta - d \Vert$ associated to systems of $\min-\rightarrow$ fuzzy relational equations of the form $\Gamma \Box_{\rightarrow}^{\min} x = \beta$, where $\rightarrow$ is a residual implicator among the G\"odel implication $\rightarrow_G$, the Goguen implication $\rightarrow_{GG}$ or Lukasiewicz's implication $\rightarrow_L$ and $\mathcal{D}$ is the set of second members of consistent systems defined with the same matrix $\Gamma$. The main preliminary result that allows us to obtain these formulas is that the Chebyshev distance $\nabla$ is the lower bound of the solutions of a vector inequality, whatever the residual implicator used. Finally, we show that, in the case of the $\min-\rightarrow_{G}$ system, the Chebyshev distance $\nabla$ may be an infimum, while it is always a min
    
[^61]: 通过过去的记忆：用于图像字幕生成的典型记忆网络

    With a Little Help from your own Past: Prototypical Memory Networks for Image Captioning. (arXiv:2308.12383v1 [cs.CV])

    [http://arxiv.org/abs/2308.12383](http://arxiv.org/abs/2308.12383)

    本文提出了一种典型记忆网络，用于提取图像的语义并生成语义连贯的描述。通过在处理其他训练样本时执行注意力操作，该网络能够利用先前激活的信息。实验证明，该模型在COCO数据集上的性能优于其他基准模型和最先进方法。

    

    图像字幕生成是一个涉及视觉和语言的任务，目前依赖于基于Transformer的架构来提取图像的语义并将其转化为语义连贯的描述。尽管成功，但注意力机制只考虑当前输入样本的投影加权求和，因此忽略了来自其他样本的相关语义信息。在本文中，我们设计了一个网络，该网络可以通过典型记忆模型在处理其他训练样本时执行注意力操作。我们的记忆通过原型向量的定义来建模过去的键和值的分布，这些原型向量既具有区分性又紧凑。在实验中，我们将所提出模型与精心设计的基准模型和最先进方法进行比较，并研究每个提出的组件的作用。

    Image captioning, like many tasks involving vision and language, currently relies on Transformer-based architectures for extracting the semantics in an image and translating it into linguistically coherent descriptions. Although successful, the attention operator only considers a weighted summation of projections of the current input sample, therefore ignoring the relevant semantic information which can come from the joint observation of other samples. In this paper, we devise a network which can perform attention over activations obtained while processing other training samples, through a prototypical memory model. Our memory models the distribution of past keys and values through the definition of prototype vectors which are both discriminative and compact. Experimentally, we assess the performance of the proposed model on the COCO dataset, in comparison with carefully designed baselines and state-of-the-art approaches, and by investigating the role of each of the proposed components
    
[^62]: 从姓名中推断性别：一个大规模的性能评估研究

    Inferring gender from name: a large scale performance evaluation study. (arXiv:2308.12381v1 [cs.CL])

    [http://arxiv.org/abs/2308.12381](http://arxiv.org/abs/2308.12381)

    本研究评估了从姓名中推断性别的性能，该方法在没有性别信息的情况下是一种可行且广泛应用的方法。其重要性在于研究各种科学学科中对性别差异的模式和决定因素进行分析。

    

    一个人的性别是在进行医学、社会学、政治学和经济学等各种科学学科的研究时一个至关重要的信息。然而，随着大数据的激增，性别信息的获取变得越来越困难。在这种情况下，研究人员需要从可获得的信息中，主要是从人名中推断性别。尽管通过姓名来推断性别可能引发一些伦理问题，但缺乏可行的替代方法意味着研究人员不得不使用这种方法，当目标使手段合理时-在大多数这类研究中，目标是研究性别差异的模式和决定因素。姓名到性别推断的必要性产生了一个越来越多的算法方法和软件产品的领域。这些方法已经在世界各地的学术界、工业界、政府和非政府组织中使用。

    A person's gender is a crucial piece of information when performing research across a wide range of scientific disciplines, such as medicine, sociology, political science, and economics, to name a few. However, in increasing instances, especially given the proliferation of big data, gender information is not readily available. In such cases researchers need to infer gender from readily available information, primarily from persons' names. While inferring gender from name may raise some ethical questions, the lack of viable alternatives means that researchers have to resort to such approaches when the goal justifies the means - in the majority of such studies the goal is to examine patterns and determinants of gender disparities. The necessity of name-to-gender inference has generated an ever-growing domain of algorithmic approaches and software products. These approaches have been used throughout the world in academia, industry, governmental and non-governmental organizations. Neverthe
    
[^63]: 带有神经集合、最大熵损失和特征增强的开放集人脸识别

    Open-set Face Recognition with Neural Ensemble, Maximal Entropy Loss and Feature Augmentation. (arXiv:2308.12371v1 [cs.CV])

    [http://arxiv.org/abs/2308.12371](http://arxiv.org/abs/2308.12371)

    本文介绍了一种新颖的方法，将一组紧凑的神经网络与基于边缘的成本函数相结合，通过探索附加样本来提高开放集人脸识别的准确性。该方法利用外部数据库获取辅助负样本或通过混合特征增强方法在训练过程中合成建立负样本。实验结果表明，该方法能够提升封闭集的准确性。

    

    开放集人脸识别是指生物识别系统对所有已存在主体的知识不完整的情况。因此，人们期望它们能够防止将未注册主体的人脸样本识别为先前注册的身份。这种监视列表的背景增加了一个艰巨的要求，要求主要关注感兴趣的主体，从而排除不相关的人脸。为此，本文引入了一种新的方法，该方法将一组紧凑的神经网络与基于边缘的成本函数相结合，该函数探索附加样本。辅助负样本可以从外部数据库中获得，或者在训练时通过新的混合特征增强方法在表示层次上进行合成构建。预先在大型人脸数据集上训练的深度神经网络作为初步特征提取模块。我们在知名的LFW和IJB-C数据集上进行了实验证明，该方法能够提升封闭集的

    Open-set face recognition refers to a scenario in which biometric systems have incomplete knowledge of all existing subjects. Therefore, they are expected to prevent face samples of unregistered subjects from being identified as previously enrolled identities. This watchlist context adds an arduous requirement that calls for the dismissal of irrelevant faces by focusing mainly on subjects of interest. As a response, this work introduces a novel method that associates an ensemble of compact neural networks with a margin-based cost function that explores additional samples. Supplementary negative samples can be obtained from external databases or synthetically built at the representation level in training time with a new mix-up feature augmentation approach. Deep neural networks pre-trained on large face datasets serve as the preliminary feature extraction module. We carry out experiments on well-known LFW and IJB-C datasets where results show that the approach is able to boost closed an
    
[^64]: SafeAR: 通过风险感知策略实现更安全的算法补偿

    SafeAR: Towards Safer Algorithmic Recourse by Risk-Aware Policies. (arXiv:2308.12367v1 [cs.LG])

    [http://arxiv.org/abs/2308.12367](http://arxiv.org/abs/2308.12367)

    本文提出了一种更安全的算法补救方法（SafeAR），该方法通过考虑风险因素在计算和评估补救措施时，为那些受到机器学习模型决策不利影响的个体提供更可靠的建议。

    

    随着机器学习模型在金融和医疗等关键领域的广泛使用，为那些受到机器学习模型决策不利影响的个体提供补救措施的需求变得更加重要；个体应该获得改善自身情况和获得有利决策的建议。之前关于顺序算法补救的工作——推荐一系列变化——主要关注行动的可行性，并使用特征变化的接近程度确定行动成本。然而，未考虑特征变化的不确定性和补救中高于平均成本的风险。如果补救措施可能（以一定概率）导致更糟糕的情况，而恢复需要付出非常高的代价，那将是不可取的。在计算和评估补救措施时，必须考虑风险。我们将考虑了这种风险因素计算出的补救措施称为更安全的算法补救（SafeAR）。

    With the growing use of machine learning (ML) models in critical domains such as finance and healthcare, the need to offer recourse for those adversely affected by the decisions of ML models has become more important; individuals ought to be provided with recommendations on actions to take for improving their situation and thus receive a favorable decision. Prior work on sequential algorithmic recourse -- which recommends a series of changes -- focuses on action feasibility and uses the proximity of feature changes to determine action costs. However, the uncertainties of feature changes and the risk of higher than average costs in recourse have not been considered. It is undesirable if a recourse could (with some probability) result in a worse situation from which recovery requires an extremely high cost. It is essential to incorporate risks when computing and evaluating recourse. We call the recourse computed with such risk considerations as Safer Algorithmic Recourse (SafeAR). The ob
    
[^65]: RemovalNet: DNN指纹去除攻击

    RemovalNet: DNN Fingerprint Removal Attacks. (arXiv:2308.12319v1 [cs.CV])

    [http://arxiv.org/abs/2308.12319](http://arxiv.org/abs/2308.12319)

    本论文对DNN指纹去除攻击进行了全面的调查，并提出了一种名为RemovalNet的攻击方法，通过min-max双层优化来逃避模型所有权验证。攻击方法旨在去除指纹特定知识，并提取受害模型的通用语义知识来维持替代模型性能。

    

    随着深度神经网络(DNNs)性能的显著提升，DNNs在许多领域得到了广泛应用。因此，DNN模型已经成为一项宝贵的资产，其知识产权通过所有权验证技术（如DNN指纹）得到保护。然而，DNN指纹去除攻击的可行性及其潜在影响仍然是一个未解决的问题。本文首次对DNN指纹去除攻击进行了全面的调查。一般而言，DNN模型中包含的知识可以分为通用语义知识和指纹特定知识。为此，我们提出了一种基于min-max双层优化的DNN指纹去除攻击——RemovalNet，以逃避模型所有权验证。下层优化旨在去除指纹特定知识，而上层优化则在维持替代模型性能的同时提取受害模型的通用语义知识。

    With the performance of deep neural networks (DNNs) remarkably improving, DNNs have been widely used in many areas. Consequently, the DNN model has become a valuable asset, and its intellectual property is safeguarded by ownership verification techniques (e.g., DNN fingerprinting). However, the feasibility of the DNN fingerprint removal attack and its potential influence remains an open problem. In this paper, we perform the first comprehensive investigation of DNN fingerprint removal attacks. Generally, the knowledge contained in a DNN model can be categorized into general semantic and fingerprint-specific knowledge. To this end, we propose a min-max bilevel optimization-based DNN fingerprint removal attack named RemovalNet, to evade model ownership verification. The lower-level optimization is designed to remove fingerprint-specific knowledge. While in the upper-level optimization, we distill the victim model's general semantic knowledge to maintain the surrogate model's performance.
    
[^66]: 跨领域的可信表示学习

    Trustworthy Representation Learning Across Domains. (arXiv:2308.12315v1 [cs.LG])

    [http://arxiv.org/abs/2308.12315](http://arxiv.org/abs/2308.12315)

    本论文首次提出了跨领域的可信表示学习框架，通过包括鲁棒性、隐私、公平性和可解释性等概念，对该研究方向进行了全面的文献综述。

    

    随着人工智能系统在我们日常生活和人类社会中取得显著的性能，人们既享受到了这些技术带来的好处，也面临因这些系统而引发的许多社会问题。为了使人工智能系统足够好并且可信，已经进行了大量研究，建立了可信人工智能系统的指南。机器学习是人工智能系统中最重要的部分之一，而表示学习是机器学习中的基础技术。如何使表示学习在现实世界的应用中具有可信度，例如跨领域场景，对于机器学习和人工智能系统领域都是非常有价值和必要的。在可信人工智能的概念启发下，我们提出了第一个跨领域的可信表示学习框架，包括了鲁棒性、隐私、公平性和可解释性这四个概念，对这个研究方向进行了全面的文献综述。

    As AI systems have obtained significant performance to be deployed widely in our daily live and human society, people both enjoy the benefits brought by these technologies and suffer many social issues induced by these systems. To make AI systems good enough and trustworthy, plenty of researches have been done to build guidelines for trustworthy AI systems. Machine learning is one of the most important parts for AI systems and representation learning is the fundamental technology in machine learning. How to make the representation learning trustworthy in real-world application, e.g., cross domain scenarios, is very valuable and necessary for both machine learning and AI system fields. Inspired by the concepts in trustworthy AI, we proposed the first trustworthy representation learning across domains framework which includes four concepts, i.e, robustness, privacy, fairness, and explainability, to give a comprehensive literature review on this research direction. Specifically, we first 
    
[^67]: 应用物理信息神经网络描述等离子体融合动力学模拟中的波粒共振

    Physics informed Neural Networks applied to the description of wave-particle resonance in kinetic simulations of fusion plasmas. (arXiv:2308.12312v1 [physics.comp-ph])

    [http://arxiv.org/abs/2308.12312](http://arxiv.org/abs/2308.12312)

    本论文测试了物理信息神经网络（PINN）在描述等离子体融合动力学模拟中的波粒共振问题方面的适用性，提出了一种名为I-PINN的PINN变体，该方法基于自动微分和自动积分解决偏微分方程和积分方程。

    

    通过将Vlasov-Poisson系统的简化形式（1D1V）应用于物理信息神经网络（PINN）对波粒共振的适用性进行了测试。研究了两个例子：Landau衰减和尾巴上的颠簸不稳定性。首先，将PINN作为Vlasov-Poisson系统解的压缩方法进行测试，并与标准神经网络进行了比较。其次，还介绍了将PINN应用于解决Vlasov-Poisson系统的方法，特别强调了积分部分，并提出了一种基于自动微分解决偏微分方程和自动积分解决积分方程的PINN变体，称为可积PINN（I-PINN）。

    The Vlasov-Poisson system is employed in its reduced form version (1D1V) as a test bed for the applicability of Physics Informed Neural Network (PINN) to the wave-particle resonance. Two examples are explored: the Landau damping and the bump-on-tail instability. PINN is first tested as a compression method for the solution of the Vlasov-Poisson system and compared to the standard neural networks. Second, the application of PINN to solving the Vlasov-Poisson system is also presented with the special emphasis on the integral part, which motivates the implementation of a PINN variant, called Integrable PINN (I-PINN), based on the automatic-differentiation to solve the partial differential equation and on the automatic-integration to solve the integral equation.
    
[^68]: 模拟流行音乐吉他谱中的弯音

    Modeling Bends in Popular Music Guitar Tablatures. (arXiv:2308.12307v1 [cs.SD])

    [http://arxiv.org/abs/2308.12307](http://arxiv.org/abs/2308.12307)

    本文研究了流行音乐吉他谱中的弯音现象，并提出了一种通过分析弯音的过去和未来短期上下文来预测弯音发生的方法。实验证明这种方法具有良好的预测性能和应用前景。

    

    弹奏谱标记广泛应用于流行音乐中，用于转录和分享吉他的音乐内容。作为标准音符标记的补充，弹奏谱可以转录演奏动作信息，包括手指位置和各种吉他特定的演奏技巧，如滑音，拉弦和弯音。本文专注于弯音，在谱中逐渐改变音高从而避免离散的按弦限制。我们提出了一组高级特征，针对谱中的每个音符进行计算，研究如何通过过去和未来的短期上下文来预测弯音的发生。在932个流行音乐的主吉他谱样本上进行实验，结果显示决策树可以成功预测弯音的发生，F1分数为0.71，并且有可接受的误报率，展示了将非吉他音乐适应的有希望的应用。

    Tablature notation is widely used in popular music to transcribe and share guitar musical content. As a complement to standard score notation, tablatures transcribe performance gesture information including finger positions and a variety of guitar-specific playing techniques such as slides, hammer-on/pull-off or bends.This paper focuses on bends, which enable to progressively shift the pitch of a note, therefore circumventing physical limitations of the discrete fretted fingerboard. In this paper, we propose a set of 25 high-level features, computed for each note of the tablature, to study how bend occurrences can be predicted from their past and future short-term context. Experiments are performed on a corpus of 932 lead guitar tablatures of popular music and show that a decision tree successfully predicts bend occurrences with an F1 score of 0.71 anda limited amount of false positive predictions, demonstrating promising applications to assist the arrangement of non-guitar music into 
    
[^69]: FedDAT: 一种多模态异构联邦学习中基础模型微调的方法

    FedDAT: An Approach for Foundation Model Finetuning in Multi-Modal Heterogeneous Federated Learning. (arXiv:2308.12305v1 [cs.LG])

    [http://arxiv.org/abs/2308.12305](http://arxiv.org/abs/2308.12305)

    FedDAT是一种在多模态异构联邦学习中进行基础模型微调的方法，通过采用参数高效微调（PEFT）方法来减轻客户端计算负担和通信开销，并解决了数据异构性的问题。

    

    近年来，在多模态学习中，基础模型取得了显著的进展。这些模型通常配备了数百万（或数十亿）个参数，需要大量数据进行微调。然而，由于不同的隐私法规，从不同领域收集和集中训练数据变得具有挑战性。联邦学习（FL）作为一种有前途的解决方案出现，可以让多个客户端在不集中其本地数据的情况下共同训练神经网络。为了减轻客户端的计算负担和通信开销，之前的工作已经采用了参数高效微调（PEFT）方法用于FL。在此过程中，只有少量模型参数在联邦通信期间进行优化和传输。然而，大多数之前的工作都专注于单一形态，并忽略了一种常见现象，即客户端之间存在数据异构性。因此，在本文中，我们提出了一个微调框架，用于解决多模态异构联邦学习中的问题。

    Recently, foundation models have exhibited remarkable advancements in multi-modal learning. These models, equipped with millions (or billions) of parameters, typically require a substantial amount of data for finetuning. However, collecting and centralizing training data from diverse sectors becomes challenging due to distinct privacy regulations. Federated Learning (FL) emerges as a promising solution, enabling multiple clients to collaboratively train neural networks without centralizing their local data. To alleviate client computation burdens and communication overheads, previous works have adapted Parameter-efficient Finetuning (PEFT) methods for FL. Hereby, only a small fraction of the model parameters are optimized and communicated during federated communications. Nevertheless, most previous works have focused on a single modality and neglected one common phenomenon, i.e., the presence of data heterogeneity across the clients. Therefore, in this work, we propose a finetuning fra
    
[^70]: CLIPN用于零样本OOD检测：教CLIP说“不”。

    CLIPN for Zero-Shot OOD Detection: Teaching CLIP to Say No. (arXiv:2308.12213v1 [cs.CV])

    [http://arxiv.org/abs/2308.12213](http://arxiv.org/abs/2308.12213)

    本文提出了一种名为CLIPN的方法，通过积极的语义提示和否定的语义提示，为CLIP赋予了区分OOD和ID样本的能力。

    

    OOD检测是指在内部分布（ID）数据集上训练模型，以分类输入图像来自未知类别。设计基于卷积神经网络或Transformer的各种OOD检测方法已经付出了相当多的努力。然而，仅需要ID的类名的CLIP驱动的零样本OOD检测方法却受到较少关注。本文提出了一种新方法，即CLIP说“不”（CLIPN），它赋予了CLIP在逻辑上说“不”的能力。我们的主要动机是通过积极的语义提示和否定的语义提示，为CLIP提供区分OOD样本和ID样本的能力。具体而言，我们设计了一种新的可学习的“不”提示符和一个“不”文本编码器，以捕获图像中的否定语义。随后，我们引入了两种损失函数：图像-文本二元相反损失和文本语义相反损失，用于教授CLIPN关联OOD和ID样本。

    Out-of-distribution (OOD) detection refers to training the model on an in-distribution (ID) dataset to classify whether the input images come from unknown classes. Considerable effort has been invested in designing various OOD detection methods based on either convolutional neural networks or transformers. However, zero-shot OOD detection methods driven by CLIP, which only require class names for ID, have received less attention. This paper presents a novel method, namely CLIP saying "no" (\textbf{CLIPN}), which empowers the logic of saying "no" within CLIP. Our key motivation is to equip CLIP with the capability of distinguishing OOD and ID samples using positive-semantic prompts and negation-semantic prompts. Specifically, we design a novel learnable "no" prompt and a "no" text encoder to capture negation semantics within images. Subsequently, we introduce two loss functions: the image-text binary-opposite loss and the text semantic-opposite loss, which we use to teach CLIPN to assoc
    
[^71]: 用于计算深度神经网络正则化路径的多目标延续方法

    A multiobjective continuation method to compute the regularization path of deep neural networks. (arXiv:2308.12044v1 [cs.LG])

    [http://arxiv.org/abs/2308.12044](http://arxiv.org/abs/2308.12044)

    本文提出了一种多目标延续方法，用于计算深度神经网络的正则化路径，以解决DNNs中稀疏性和数值效率之间的冲突。

    

    稀疏性是深度神经网络(DNNs)中非常理想的特征，因为它确保了数值效率，提高了模型的可解释性(由于相关特征的数量较少)和鲁棒性。在基于线性模型的机器学习方法中，众所周知在$\ell^1$范数(即零权重)的最稀疏解和非正则化解之间存在一条连接路径，这条路径被称为正则化路径。最近，通过将经验损失和稀疏性($\ell^1$范数)作为两个冲突的标准，并解决由此产生的多目标优化问题，首次尝试将正则化路径的概念扩展到DNNs。然而，由于$\ell^1$范数的不光滑性和参数数量的高度，从计算的角度来看，这种方法并不是很有效。为了克服这个限制，我们提出了一种算法，可以近似计算整个帕累托曲线

    Sparsity is a highly desired feature in deep neural networks (DNNs) since it ensures numerical efficiency, improves the interpretability of models (due to the smaller number of relevant features), and robustness. In machine learning approaches based on linear models, it is well known that there exists a connecting path between the sparsest solution in terms of the $\ell^1$ norm (i.e., zero weights) and the non-regularized solution, which is called the regularization path. Very recently, there was a first attempt to extend the concept of regularization paths to DNNs by means of treating the empirical loss and sparsity ($\ell^1$ norm) as two conflicting criteria and solving the resulting multiobjective optimization problem. However, due to the non-smoothness of the $\ell^1$ norm and the high number of parameters, this approach is not very efficient from a computational perspective. To overcome this limitation, we present an algorithm that allows for the approximation of the entire Pareto
    
[^72]: 综合图像和位置分析用于创伤分类：基于深度学习的方法

    Integrated Image and Location Analysis for Wound Classification: A Deep Learning Approach. (arXiv:2308.11877v1 [cs.CV])

    [http://arxiv.org/abs/2308.11877](http://arxiv.org/abs/2308.11877)

    本研究提出了一种基于深度学习的多模态网络，结合图像和位置信息进行创伤分类，通过引入体部图谱系统提供精确的创伤位置标记，并在新颖的架构中整合多个模型以提高分类效果。

    

    急性和慢性创伤的全球负担为增强创伤分类方法提供了强有力的案例，这是诊断和确定最佳治疗的关键步骤。认识到这一需求，我们介绍了一种创新的多模态网络，基于深度卷积神经网络，将创伤分类为四类：糖尿病性、压力性、外科性和静脉溃疡。我们的多模态网络使用创伤图像及其相应的位置信息进行更精确的分类。我们方法的一个独特之处在于引入了一个体部图谱系统，提供了准确的创伤位置标记，改进了传统的创伤图像分类技术。我们方法的一个独特特点是在一个新颖的架构中整合了VGG16、ResNet152和EfficientNet等模型。该架构包括了空间和通道级的Squeeze-and-Excitation模块、Axial Attention和自适应门控多层感知机等元素，提供了更好的性能。

    The global burden of acute and chronic wounds presents a compelling case for enhancing wound classification methods, a vital step in diagnosing and determining optimal treatments. Recognizing this need, we introduce an innovative multi-modal network based on a deep convolutional neural network for categorizing wounds into four categories: diabetic, pressure, surgical, and venous ulcers. Our multi-modal network uses wound images and their corresponding body locations for more precise classification. A unique aspect of our methodology is incorporating a body map system that facilitates accurate wound location tagging, improving upon traditional wound image classification techniques. A distinctive feature of our approach is the integration of models such as VGG16, ResNet152, and EfficientNet within a novel architecture. This architecture includes elements like spatial and channel-wise Squeeze-and-Excitation modules, Axial Attention, and an Adaptive Gated Multi-Layer Perceptron, providing 
    
[^73]: Halo：评估和降低开源弱大语言模型中的幻觉

    Halo: Estimation and Reduction of Hallucinations in Open-Source Weak Large Language Models. (arXiv:2308.11764v1 [cs.CL])

    [http://arxiv.org/abs/2308.11764](http://arxiv.org/abs/2308.11764)

    本文介绍了一种用于评估和减少开源弱大语言模型中幻觉问题的框架，并探索了知识注入和师生方法等技术来减轻低参数模型中的幻觉问题，实验结果表明，在挑战性领域中，这些模型的幻觉问题得到了减少。

    

    大型语言模型(LLMs)已经彻底改变了自然语言处理(NLP)领域。虽然对于研究和实际应用来说方便，但是与其更大规模的对应模型相比，开源的参数较少的LLMs经常出现严重幻觉问题。本文着重于测量和减少BLOOM 7B中的幻觉问题，该模型是公开提供给研究和商业应用的弱开源LLMs的代表。我们引入了HaloCheck，一种轻量级的无需知识的黑盒子框架，用于量化LLMs中幻觉问题的严重程度。此外，我们探索了知识注入和师生方法等技术，以减轻低参数LLMs中的幻觉问题。我们的实验证明了在这些LLMs的挑战性领域中幻觉问题的减少。

    Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP). Although convenient for research and practical applications, open-source LLMs with fewer parameters often suffer from severe hallucinations compared to their larger counterparts. This paper focuses on measuring and reducing hallucinations in BLOOM 7B, a representative of such weaker open-source LLMs that are publicly available for research and commercial applications. We introduce HaloCheck, a lightweight BlackBox knowledge-free framework designed to quantify the severity of hallucinations in LLMs. Additionally, we explore techniques like knowledge injection and teacher-student approaches to alleviate hallucinations in low-parameter LLMs. Our experiments effectively demonstrate the reduction of hallucinations in challenging domains for these LLMs.
    
[^74]: 动态开放词汇增强的智能安全着陆（DOVESEI）

    Dynamic Open Vocabulary Enhanced Safe-landing with Intelligence (DOVESEI). (arXiv:2308.11471v1 [cs.RO])

    [http://arxiv.org/abs/2308.11471](http://arxiv.org/abs/2308.11471)

    本文提出了一种动态开放词汇增强的智能安全着陆系统，通过利用开放词汇图像分割的能力实现无人机的视觉伺服，适应不同场景且无需大量数据积累进行模型改进，可以处理100米高度的操作。

    

    本研究针对城市空中机器人的基础步骤之一，即安全着陆。我们关注安全着陆感知堆栈中最关键的方面之一，即分割。我们提出了一种简化的反应式无人机系统，利用开放词汇图像分割的能力实现视觉伺服。这种方法可以适应各种场景，并通过其开放词汇方法，最小化调整需求，绕过对内部模型进行大量数据积累以进行改进的必要性。考虑到当地当局的限制，我们的主要关注点是从100米高度起飞的操作。这个选择是有意的，因为许多之前的工作处理的高度仅限于30米，与小型立体相机的能力相吻合。因此，我们采用传统的三维路径规划方法来导航剩下的20米。利用单目相机和图像

    This work targets what we consider to be the foundational step for urban airborne robots, a safe landing. Our attention is directed toward what we deem the most crucial aspect of the safe landing perception stack: segmentation. We present a streamlined reactive UAV system that employs visual servoing by harnessing the capabilities of open vocabulary image segmentation. This approach can adapt to various scenarios with minimal adjustments, bypassing the necessity for extensive data accumulation for refining internal models, thanks to its open vocabulary methodology. Given the limitations imposed by local authorities, our primary focus centers on operations originating from altitudes of 100 meters. This choice is deliberate, as numerous preceding works have dealt with altitudes up to 30 meters, aligning with the capabilities of small stereo cameras. Consequently, we leave the remaining 20m to be navigated using conventional 3D path planning methods. Utilizing monocular cameras and image 
    
[^75]: 大模型时代中的联邦学习：针对特定领域的多模态大模型

    Federated Learning in Big Model Era: Domain-Specific Multimodal Large Models. (arXiv:2308.11217v1 [cs.LG])

    [http://arxiv.org/abs/2308.11217](http://arxiv.org/abs/2308.11217)

    本论文提出了一种多模态联邦学习框架，利用私有领域数据协同训练大型模型，以实现跨场景的智能服务。在大模型时代，该框架解决了异构数据、模型聚合、性能和成本权衡、数据隐私以及激励机制等方面的挑战。

    

    多模态数据能够全面感知和识别物理世界，已成为通往通用人工智能的重要路径。然而，在公共数据集上训练的多模态大模型在特定工业领域的性能往往不理想。本文提出了一种多模态联邦学习框架，可以使多个企业利用私有领域数据协同训练大型模型，实现跨场景的智能服务。作者深入探讨了大模型时代联邦学习的智能基础和目标的战略转变，以及在异构数据、模型聚合、性能和成本权衡、数据隐私和激励机制方面面临的新挑战。本文详细介绍了领先企业在城市安全运营管理方面贡献多模态数据和专家知识的案例研究，包括分布式部署和高效性能的实现。

    Multimodal data, which can comprehensively perceive and recognize the physical world, has become an essential path towards general artificial intelligence. However, multimodal large models trained on public datasets often underperform in specific industrial domains. This paper proposes a multimodal federated learning framework that enables multiple enterprises to utilize private domain data to collaboratively train large models for vertical domains, achieving intelligent services across scenarios. The authors discuss in-depth the strategic transformation of federated learning in terms of intelligence foundation and objectives in the era of big model, as well as the new challenges faced in heterogeneous data, model aggregation, performance and cost trade-off, data privacy, and incentive mechanism. The paper elaborates a case study of leading enterprises contributing multimodal data and expert knowledge to city safety operation management , including distributed deployment and efficient 
    
[^76]: 可视化人群分析：开放的研究问题

    Visual Crowd Analysis: Open Research Problems. (arXiv:2308.10677v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2308.10677](http://arxiv.org/abs/2308.10677)

    本文深入探讨了可视化人群分析的六个主要领域，并概述了在未来工作中需要解决的关键问题，以确保自动人群监测领域的进展和繁荣。

    

    在过去的十年中，计算机视觉领域对自动化人群监测的兴趣迅猛增长。现代深度学习方法使得开发全自动基于视觉的人群监测应用成为可能。然而，尽管问题的规模庞大，技术的显著进步以及研究界的持续关注，仍然存在许多需要解决的挑战。在本文中，我们深入探讨了可视化人群分析的六个主要领域，强调了每个领域的关键发展。我们概述了必须在未来的工作中解决的重大未解决问题，以确保自动人群监测领域继续取得进展和繁荣。过去已经进行了一些相关主题的调查。尽管如此，本文全面考察并呈现了更直观的作品分类，同时描述了最新的突破。

    Over the last decade, there has been a remarkable surge in interest in automated crowd monitoring within the computer vision community. Modern deep-learning approaches have made it possible to develop fully-automated vision-based crowd-monitoring applications. However, despite the magnitude of the issue at hand, the significant technological advancements, and the consistent interest of the research community, there are still numerous challenges that need to be overcome. In this article, we delve into six major areas of visual crowd analysis, emphasizing the key developments in each of these areas. We outline the crucial unresolved issues that must be tackled in future works, in order to ensure that the field of automated crowd monitoring continues to progress and thrive. Several surveys related to this topic have been conducted in the past. Nonetheless, this article thoroughly examines and presents a more intuitive categorization of works, while also depicting the latest breakthroughs 
    
[^77]: Metaverse：可伸缩和实时虚拟世界的愿景、架构要素和未来发展方向

    Metaverse: A Vision, Architectural Elements, and Future Directions for Scalable and Realtime Virtual Worlds. (arXiv:2308.10559v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2308.10559](http://arxiv.org/abs/2308.10559)

    元宇宙是一种可伸缩且实时的虚拟世界，它通过虚拟和增强现实技术拓展物理世界，使用户能够与真实和虚拟世界无缝交互。它对社交媒体、合作工作、市场营销、教学和个性化医疗等方面具有潜在影响。实现元宇宙在实时和大规模上的要求尚需进一步研究，以实现其可用性。

    

    随着云计算、物联网技术启用的人机界面、生成式人工智能以及高精度的机器和深度学习识别和预测模型的出现，再加上后COVID-19时代社交网络和远程通信的广泛普及，元宇宙变得非常受欢迎。元宇宙有潜力通过虚拟和增强现实来扩展物理世界，使用户可以使用虚拟形象和全息影像与现实和虚拟世界无缝交互。它有可能影响人们在社交媒体上的互动方式，工作中的协作，市场营销和商业活动，教学，学习，甚至个性化医疗护理的获取。文献中的几项研究从可穿戴硬件设备和虚拟现实游戏应用的角度探讨了元宇宙。然而，实时实现并在大规模上实现元宇宙的要求还有待研究，以便使该技术能够被应用。

    With the emergence of Cloud computing, Internet of Things-enabled Human-Computer Interfaces, Generative Artificial Intelligence, and high-accurate Machine and Deep-learning recognition and predictive models, along with the Post Covid-19 proliferation of social networking, and remote communications, the Metaverse gained a lot of popularity. Metaverse has the prospective to extend the physical world using virtual and augmented reality so the users can interact seamlessly with the real and virtual worlds using avatars and holograms. It has the potential to impact people in the way they interact on social media, collaborate in their work, perform marketing and business, teach, learn, and even access personalized healthcare. Several works in the literature examine Metaverse in terms of hardware wearable devices, and virtual reality gaming applications. However, the requirements of realizing the Metaverse in realtime and at a large-scale need yet to be examined for the technology to be usabl
    
[^78]: MoCLIM: 用多组学对比学习和组学推理建模实现准确的癌症亚型划分

    MoCLIM: Towards Accurate Cancer Subtyping via Multi-Omics Contrastive Learning with Omics-Inference Modeling. (arXiv:2308.09725v1 [q-bio.GN])

    [http://arxiv.org/abs/2308.09725](http://arxiv.org/abs/2308.09725)

    本论文介绍了一种名为MoCLIM的多组学对比学习框架，能够在癌症亚型划分中利用多组学数据的潜力，显著提高了数据的拟合度和亚型划分性能。

    

    精准医学的目标是建立癌症亚型的生化机制与疾病之间的因果关系。基于组学的癌症亚型划分已经成为一种革命性的方法，因为不同级别的组学记录了癌症中多步骤过程的生化产物。本文旨在充分利用多组学数据的潜力来改善癌症亚型划分结果，因此开发了MoCLIM，一种表示学习框架。MoCLIM独立地从不同的组学模式中提取有信息量的特征。通过对不同组学模式之间的对比学习所得到的统一表示，在给定癌症情况下，我们能够将亚型很好地聚类到较低的潜空间中。这种对比可以被解释为在生物网络中观察到的组际推理的投影。在六个癌症数据集上的实验结果表明，我们的方法在较少的高维癌症数据拟合和亚型划分性能方面显著改善。

    Precision medicine fundamentally aims to establish causality between dysregulated biochemical mechanisms and cancer subtypes. Omics-based cancer subtyping has emerged as a revolutionary approach, as different level of omics records the biochemical products of multistep processes in cancers. This paper focuses on fully exploiting the potential of multi-omics data to improve cancer subtyping outcomes, and hence developed MoCLIM, a representation learning framework. MoCLIM independently extracts the informative features from distinct omics modalities. Using a unified representation informed by contrastive learning of different omics modalities, we can well-cluster the subtypes, given cancer, into a lower latent space. This contrast can be interpreted as a projection of inter-omics inference observed in biological networks. Experimental results on six cancer datasets demonstrate that our approach significantly improves data fit and subtyping performance in fewer high-dimensional cancer ins
    
[^79]: DiagGPT:一种基于LLM的任务导向对话的聊天机器人

    DiagGPT: An LLM-based Chatbot with Automatic Topic Management for Task-Oriented Dialogue. (arXiv:2308.08043v1 [cs.CL])

    [http://arxiv.org/abs/2308.08043](http://arxiv.org/abs/2308.08043)

    DiagGPT将大型语言模型(LLMs)扩展到任务导向的对话场景，提供了在复杂诊断场景中主动提问和引导用户完成任务的能力。

    

    大型语言模型(LLMs)如ChatGPT正变得越来越复杂，展示出与人类相似的能力。这些AI模型在日常生活中辅助人类完成各种任务方面发挥着重要作用。AI作为聊天代理人的重要应用是回答人类在各个领域的问题。目前的LLMs在回答一般问题方面已经显示出熟练的能力。然而，在复杂的诊断场景(如法律或医疗咨询)中，基本的问答对话往往表现不佳。这些场景通常需要任务导向对话(TOD)，其中AI聊天代理需要主动提问并引导用户完成特定任务。以前的微调模型在TOD方面表现不佳，而当前的LLMs并未固有这种能力。在本文中，我们介绍了一种名为DiagGPT (Diagnosis GPT)的创新方法，它将LLMs推广到TOD场景中。

    Large Language Models (LLMs), such as ChatGPT, are becoming increasingly sophisticated, demonstrating capabilities that closely resemble those of humans. These AI models are playing an essential role in assisting humans with a wide array of tasks in daily life. A significant application of AI is its use as a chat agent, responding to human inquiries across various domains. Current LLMs have shown proficiency in answering general questions. However, basic question-answering dialogue often falls short in complex diagnostic scenarios, such as legal or medical consultations. These scenarios typically necessitate Task-Oriented Dialogue (TOD), wherein an AI chat agent needs to proactively pose questions and guide users towards specific task completion. Previous fine-tuning models have underperformed in TOD, and current LLMs do not inherently possess this capability. In this paper, we introduce DiagGPT (Dialogue in Diagnosis GPT), an innovative method that extends LLMs to TOD scenarios. Our e
    
[^80]: 使用在聚类数据上训练的集成模型进行开放集合人脸识别

    Open-set Face Recognition using Ensembles trained on Clustered Data. (arXiv:2308.07445v1 [cs.CV])

    [http://arxiv.org/abs/2308.07445](http://arxiv.org/abs/2308.07445)

    本研究提出了一种使用在聚类数据上训练的集成模型进行开放集合人脸识别的方法，能够准确识别感兴趣的个体，同时有效处理陌生的面孔。实验结果表明即使在大规模图库中也能取得竞争性的性能。

    

    开放集合人脸识别描述了在测试时出现未知的主题，而在训练阶段未见过。它不仅需要准确识别感兴趣的个体的方法，还需要有效处理陌生的面孔的方法。本文详细介绍了一个可扩展的开放集合人脸识别方法，适用于包含数百和数千个主题的图库。它由聚类和一组二进制学习算法组成，用于估计查询人脸样本是否属于人脸图库，并检索其正确的身份。该方法选择最合适的图库主题，并使用集成模型改善预测性能。我们在知名的LFW和YTF基准测试上进行实验。结果表明，即使针对可扩展性，也可以达到竞争性的性能。

    Open-set face recognition describes a scenario where unknown subjects, unseen during the training stage, appear on test time. Not only it requires methods that accurately identify individuals of interest, but also demands approaches that effectively deal with unfamiliar faces. This work details a scalable open-set face identification approach to galleries composed of hundreds and thousands of subjects. It is composed of clustering and an ensemble of binary learning algorithms that estimates when query face samples belong to the face gallery and then retrieves their correct identity. The approach selects the most suitable gallery subjects and uses the ensemble to improve prediction performance. We carry out experiments on well-known LFW and YTF benchmarks. Results show that competitive performance can be achieved even when targeting scalability.
    
[^81]: 自然语言是图表所需要的全部内容

    Natural Language is All a Graph Needs. (arXiv:2308.07134v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.07134](http://arxiv.org/abs/2308.07134)

    本论文提出了一种名为InstructGLM的结构化语言模型算法，该算法将大型语言模型与图表学习问题相结合，旨在探索是否可以用语言模型取代图神经网络作为图表的基础模型。

    

    大规模预训练语言模型的出现，如ChatGPT，已经在人工智能的各个研究领域中引起了革命。基于Transformer的大型语言模型（LLMs）逐渐取代了CNN和RNN，将计算机视觉和自然语言处理领域统一起来。与相对独立存在的数据（如图像、视频或文本）相比，图表是一种包含丰富结构和关系信息的数据类型。同时，作为最具表现力的媒介之一，自然语言在描述复杂结构方面表现出色。然而，将图表学习问题纳入生成式语言建模框架的现有工作仍然非常有限。随着大型语言模型的重要性不断增长，探索LLMs是否也可以替代GNNs成为图表的基础模型变得至关重要。在本文中，我们提出了InstructGLM（结构化语言模型）算法，系统地设计高度可扩展的模型来处理图表学习问题。

    The emergence of large-scale pre-trained language models, such as ChatGPT, has revolutionized various research fields in artificial intelligence. Transformers-based large language models (LLMs) have gradually replaced CNNs and RNNs to unify fields of computer vision and natural language processing. Compared with the data that exists relatively independently such as images, videos or texts, graph is a type of data that contains rich structural and relational information. Meanwhile, natural language, as one of the most expressive mediums, excels in describing complex structures. However, existing work on incorporating graph learning problems into the generative language modeling framework remains very limited. As the importance of large language models continues to grow, it becomes essential to explore whether LLMs can also replace GNNs as the foundation model for graphs. In this paper, we propose InstructGLM (Instruction-finetuned Graph Language Model), systematically design highly scal
    
[^82]: 解决医学影像深度学习中的小型注释数据集问题：对比共同对比学习和掩码自编码器方法在CT扫描卷积模型中的自监督预训练的评估

    Dealing with Small Annotated Datasets for Deep Learning in Medical Imaging: An Evaluation of Self-Supervised Pre-Training on CT Scans Comparing Contrastive and Masked Autoencoder Methods for Convolutional Models. (arXiv:2308.06534v1 [cs.CV])

    [http://arxiv.org/abs/2308.06534](http://arxiv.org/abs/2308.06534)

    本研究评估了在医学影像领域使用自监督预训练方法的可行性，比较了共同对比学习和掩码自编码器方法在CT扫描卷积模型中的性能。

    

    医学影像中的深度学习有潜力减少诊断错误的风险、减轻放射科医生的工作负担并加速确诊。训练这样的深度学习模型需要大型且准确的数据集，并且需要为所有训练样本提供注释。然而，在医学影像领域，由于注释的高复杂性、受限的获取方式或疾病的罕见性，特定任务的注释数据集通常很小。为了应对这一挑战，深度学习模型可以使用自监督学习领域的方法，在没有注释的大型图像数据集上进行预训练。在预训练之后，小型的已注释数据集就足以对模型进行特定任务的微调，即所谓的“下游任务”。医学影像中最流行的自监督预训练方法基于共同对比学习。然而，最近的自然图像处理研究表明掩码自编码器方法具有很大的潜力。本研究比较了二者在CT扫描卷积模型中的性能。

    Deep learning in medical imaging has the potential to minimize the risk of diagnostic errors, reduce radiologist workload, and accelerate diagnosis. Training such deep learning models requires large and accurate datasets, with annotations for all training samples. However, in the medical imaging domain, annotated datasets for specific tasks are often small due to the high complexity of annotations, limited access, or the rarity of diseases. To address this challenge, deep learning models can be pre-trained on large image datasets without annotations using methods from the field of self-supervised learning. After pre-training, small annotated datasets are sufficient to fine-tune the models for a specific task, the so-called ``downstream task". The most popular self-supervised pre-training approaches in medical imaging are based on contrastive learning. However, recent studies in natural image processing indicate a strong potential for masked autoencoder approaches. Our work compares sta
    
[^83]: 通过受限频率的身份不可知攻击进行人脸加密

    Face Encryption via Frequency-Restricted Identity-Agnostic Attacks. (arXiv:2308.05983v1 [cs.CV])

    [http://arxiv.org/abs/2308.05983](http://arxiv.org/abs/2308.05983)

    通过受限频率的身份不可知攻击进行人脸加密，解决了使用外部扰动加密人脸图像的隐私保护问题，并提出了一种弱黑盒场景下可行的解决方案。

    

    每天有数十亿人在社交媒体上分享他们的日常照片。然而，恶意采集者利用深度人脸识别系统轻松地从这些图片中窃取他们的生物特征信息（例如人脸）。一些研究正在进行中，通过引入难以察觉的扰动来生成加密人脸照片，以减少人脸信息泄漏。然而，现有的研究需要更强的黑盒场景可行性和更自然的视觉外观，这对隐私保护的可行性构成了挑战。为了解决这些问题，我们提出了一种受限频率的身份不可知（FRIA）框架，以从未经授权的人脸识别中加密人脸图像，而无需访问个人信息。对于弱黑盒场景的可行性，我们观察到多个人脸识别模型中的平均特征表示相似，因此我们提出利用通过互联网爬取的数据集中的平均特征作为t

    Billions of people are sharing their daily live images on social media everyday. However, malicious collectors use deep face recognition systems to easily steal their biometric information (e.g., faces) from these images. Some studies are being conducted to generate encrypted face photos using adversarial attacks by introducing imperceptible perturbations to reduce face information leakage. However, existing studies need stronger black-box scenario feasibility and more natural visual appearances, which challenge the feasibility of privacy protection. To address these problems, we propose a frequency-restricted identity-agnostic (FRIA) framework to encrypt face images from unauthorized face recognition without access to personal information. As for the weak black-box scenario feasibility, we obverse that representations of the average feature in multiple face recognition models are similar, thus we propose to utilize the average feature via the crawled dataset from the Internet as the t
    
[^84]: AIs的发展脱靴法

    Developmental Bootstrapping of AIs. (arXiv:2308.04586v1 [cs.AI])

    [http://arxiv.org/abs/2308.04586](http://arxiv.org/abs/2308.04586)

    传统的符号AI方法和深度学习AI方法无法满足创建强大和可信赖的AI的挑战，然而，发展脱靴法通过模仿人类儿童的能力发展过程，为创建稳健可靠的AI提供了希望。

    

    尽管当前一些AI在封闭的世界，如棋盘游戏中超越了人类能力，但它们在混乱的现实世界中的表现有限。它们会犯奇怪的错误而且没有意识到。它们很难受到指导，不能运用常识，缺乏好奇心。它们不能成为良好的合作者。传统手动构建的符号AI方法构建的系统和使用生成和深度学习AI方法(包括大规模语言模型)构建的系统都无法应对这些挑战。它们不适合创建强大和可信赖的AI。尽管此方法不属于主流的AI方法，但发展脱靴法显示出希望。在发展脱靴法中，AI像人类儿童一样发展能力。它们从先天能力开始。像人类一样，它们与环境互动，并从互动中学习。它们通过自我发展的能力逐步扩展先天能力。它们互动并逐渐将所学应用于实际操作。

    Although some current AIs surpass human abilities especially in closed worlds such as board games, their performance in the messy real world is limited. They make strange mistakes and do not notice them. They cannot be instructed easily, fail to use common sense, and lack curiosity. They do not make good collaborators. Neither systems built using the traditional manually-constructed symbolic AI approach nor systems built using generative and deep learning AI approaches including large language models (LLMs) can meet the challenges. They are not well suited for creating robust and trustworthy AIs. Although it is outside of mainstream AI approaches, developmental bootstrapping shows promise. In developmental bootstrapping, AIs develop competences like human children do. They start with innate competences. Like humans, they interact with the environment and learn from their interactions. They incrementally extend their innate competences with self-developed competences. They interact and 
    
[^85]: GridMM:视觉与语言导航的网格记忆图

    GridMM: Grid Memory Map for Vision-and-Language Navigation. (arXiv:2307.12907v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2307.12907](http://arxiv.org/abs/2307.12907)

    本文提出了GridMM，一种用于视觉与语言导航的自顶向下网格记忆图，从全局和局部视角有效地表示和结构化先前访问的环境。在多个数据集上进行的实验证明了该方法的优越性。

    

    视觉与语言导航（VLN）使代理能够根据自然语言指令在3D环境中导航到远程位置。为了表示先前访问的环境，VLN的大多数方法使用经常性状态、拓扑地图或自顶向下的语义地图来实现记忆。与这些方法相比，我们构建了自顶向下的以自我为中心并动态增长的网格记忆图（即GridMM）来结构化访问的环境。从全局视角来看，历史观察结果在自上而下的视图中被投影到统一的网格地图中，这可以更好地表示环境的空间关系。从局部视角来看，我们进一步提出了一种指令相关性聚合方法，以捕捉每个网格区域中细粒度的视觉线索。在离散环境中对REVERIE、R2R、SOON数据集以及连续环境中的R2R-CE数据集进行了大量实验证明了我们提出的方法的优越性。

    Vision-and-language navigation (VLN) enables the agent to navigate to a remote location following the natural language instruction in 3D environments. To represent the previously visited environment, most approaches for VLN implement memory using recurrent states, topological maps, or top-down semantic maps. In contrast to these approaches, we build the top-down egocentric and dynamically growing Grid Memory Map (i.e., GridMM) to structure the visited environment. From a global perspective, historical observations are projected into a unified grid map in a top-down view, which can better represent the spatial relations of the environment. From a local perspective, we further propose an instruction relevance aggregation method to capture fine-grained visual clues in each grid region. Extensive experiments are conducted on both the REVERIE, R2R, SOON datasets in the discrete environments, and the R2R-CE dataset in the continuous environments, showing the superiority of our proposed metho
    
[^86]: 采用OpenPose的基于视频的考试可疑活动检测器

    A Video-based Detector for Suspicious Activity in Examination with OpenPose. (arXiv:2307.11413v1 [cs.CV])

    [http://arxiv.org/abs/2307.11413](http://arxiv.org/abs/2307.11413)

    本研究提出了一种利用OpenPose框架和卷积神经网络(CNN)分析考试视频并高效有效地检测可疑活动的框架。

    

    考试是学习过程中至关重要的一部分，学术机构投入大量资源维护其完整性，防止学生或监考员作弊。然而，作弊在考试中变得猖獗，这损害了考试的完整性。依靠监考员监视每个学生的传统方法不切实际且无效。为解决这个问题，需要连续记录考试过程以监控学生的可疑活动。然而，这些录像通常过长以至于监考员无法有效分析，疲劳可能导致他们错过重要细节。为扩大监控范围，监考员可以使用固定架设在高处或佩戴的摄像头。本文介绍了一个利用自动化分析视频并有效高效地检测考试中可疑活动的框架。我们利用OpenPose框架和卷积神经网络(CNN)识别学生交换的

    Examinations are a crucial part of the learning process, and academic institutions invest significant resources into maintaining their integrity by preventing cheating from students or facilitators. However, cheating has become rampant in examination setups, compromising their integrity. The traditional method of relying on invigilators to monitor every student is impractical and ineffective. To address this issue, there is a need to continuously record exam sessions to monitor students for suspicious activities. However, these recordings are often too lengthy for invigilators to analyze effectively, and fatigue may cause them to miss significant details. To widen the coverage, invigilators could use fixed overhead or wearable cameras. This paper introduces a framework that uses automation to analyze videos and detect suspicious activities during examinations efficiently and effectively. We utilized the OpenPose framework and Convolutional Neural Network (CNN) to identify students exch
    
[^87]: 视频焦点网络：用于视频动作识别的时空焦点调制

    Video-FocalNets: Spatio-Temporal Focal Modulation for Video Action Recognition. (arXiv:2307.06947v1 [cs.CV])

    [http://arxiv.org/abs/2307.06947](http://arxiv.org/abs/2307.06947)

    本论文提出了一种名为视频焦点网络的视频识别架构，通过时空焦点调制来模拟局部和全局上下文，结合了Transformer和卷积设计的优点，既有效又高效。

    

    最近的视频识别模型利用Transformer模型进行长距离时空上下文建模。视频Transformer设计基于自注意力，可以以高计算成本模拟全局上下文。相比之下，用于视频的卷积设计提供了一种高效的替代方法，但缺乏长距离依赖建模。为了实现这两种设计的最佳效果，本研究提出了视频焦点网络（Video-FocalNet），这是一种既有效又高效的视频识别架构，可以模拟局部和全局上下文。视频焦点网络基于时空焦点调制架构，对自注意力的交互和聚合步骤进行了颠倒，以提高效率。此外，聚合步骤和交互步骤都使用了高效的卷积和逐元素乘法操作来实现，其计算成本比视频表达中的自注意力对应部分要低得多。我们广泛探索了焦点调制的设计空间。

    Recent video recognition models utilize Transformer models for long-range spatio-temporal context modeling. Video transformer designs are based on self-attention that can model global context at a high computational cost. In comparison, convolutional designs for videos offer an efficient alternative but lack long-range dependency modeling. Towards achieving the best of both designs, this work proposes Video-FocalNet, an effective and efficient architecture for video recognition that models both local and global contexts. Video-FocalNet is based on a spatio-temporal focal modulation architecture that reverses the interaction and aggregation steps of self-attention for better efficiency. Further, the aggregation step and the interaction step are both implemented using efficient convolution and element-wise multiplication operations that are computationally less expensive than their self-attention counterparts on video representations. We extensively explore the design space of focal modu
    
[^88]: DoReMi: 通过检测和修复计划执行不一致来实现语言模型的基础

    DoReMi: Grounding Language Model by Detecting and Recovering from Plan-Execution Misalignment. (arXiv:2307.00329v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2307.00329](http://arxiv.org/abs/2307.00329)

    DoReMi是一种新颖的语言模型基础架构，通过检测和修复计划与执行之间的不一致性来实现语言模型的基础。该架构利用视觉问答模型检查约束条件以发现不一致，并调用语言模型进行重新规划以实现恢复。

    

    大型语言模型包含大量的语义知识，并具备出色的理解和推理能力。先前的研究已经探索了如何将语言模型与机器人任务相结合，以确保语言模型生成的序列在逻辑上正确且可执行。然而，由于环境扰动或控制器设计的不完善，底层执行可能会偏离高级计划。在本文中，我们提出了一种名为DoReMi的新型语言模型基础架构，该架构能够及时检测和修复计划与执行之间的不一致性。具体而言，我们利用LLM进行规划，并生成计划步骤的约束条件。这些约束条件可以指示计划与执行之间的不一致性，并且我们使用视觉问答（VQA）模型在低层技能执行过程中检查约束条件。如果发生特定的不一致，我们的方法将调用语言模型重新规划以从中恢复。

    Large language models encode a vast amount of semantic knowledge and possess remarkable understanding and reasoning capabilities. Previous research has explored how to ground language models in robotic tasks to ensure that the sequences generated by the language model are both logically correct and practically executable. However, low-level execution may deviate from the high-level plan due to environmental perturbations or imperfect controller design. In this paper, we propose DoReMi, a novel language model grounding framework that enables immediate Detection and Recovery from Misalignments between plan and execution. Specifically, LLMs are leveraged for both planning and generating constraints for planned steps. These constraints can indicate plan-execution misalignments and we use a vision question answering (VQA) model to check constraints during low-level skill execution. If certain misalignment occurs, our method will call the language model to re-plan in order to recover from mi
    
[^89]: 医疗视觉语言理解与生成的多模态预训练：一项新基准的实证研究

    Multi-modal Pre-training for Medical Vision-language Understanding and Generation: An Empirical Study with A New Benchmark. (arXiv:2306.06494v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.06494](http://arxiv.org/abs/2306.06494)

    本文通过研究关键因素，提供了医疗视觉语言预训练的全面实证分析，并提出了一个新的医学图像-文本数据集作为预训练数据或新的基准，为医学报告生成和图像-文本检索任务提供了强有力的支持。

    

    随着大规模、全面和通用的视觉语言（VL）数据集（如MSCOCO）的可用性，视觉语言预训练（VLP）已成为一个活跃的研究领域，并被证明在各种VL任务（如视觉问答）中非常有效。然而，目前在医疗领域对VLP的研究还很少。为了为医疗VL任务提供全面的视角，我们进行了一项全面的实证分析，研究可能影响统一视觉语言Transformer性能的关键因素。为了能够进行明智和快速的预训练决策，我们提出了RadioGraphy Captions（RGC），一个高质量的多模态放射图像数据集，其中包含18,434个来自开放获取在线数据库MedPix的图像-标题对。RGC可以用作预训练数据集，也可以作为医学报告生成和医学图像-文本检索的新基准。通过利用RGC和其他可用数据集进行预训练，我们开发了新的医疗VL模型。

    With the availability of large-scale, comprehensive, and general-purpose vision-language (VL) datasets such as MSCOCO, vision-language pre-training (VLP) has become an active area of research and proven to be effective for various VL tasks such as visual-question answering. However, studies on VLP in the medical domain have so far been scanty. To provide a comprehensive perspective on VLP for medical VL tasks, we conduct a thorough experimental analysis to study key factors that may affect the performance of VLP with a unified vision-language Transformer. To allow making sound and quick pre-training decisions, we propose RadioGraphy Captions (RGC), a high-quality, multi-modality radiographic dataset containing 18,434 image-caption pairs collected from an open-access online database MedPix. RGC can be used as a pre-training dataset or a new benchmark for medical report generation and medical image-text retrieval. By utilizing RGC and other available datasets for pre-training, we develop
    
[^90]: LANISTR：从结构化和非结构化数据中进行多模态学习

    LANISTR: Multimodal Learning from Structured and Unstructured Data. (arXiv:2305.16556v1 [cs.LG])

    [http://arxiv.org/abs/2305.16556](http://arxiv.org/abs/2305.16556)

    LANISTR是一个新颖的基于注意力机制的框架，可从结构化和非结构化数据中进行学习，在挑战性数据集上表现优异。

    

    多模态的大规模预训练已经在处理非结构化数据（包括文本、图像、音频和视频）方面展现了令人瞩目的性能提升。但是，现实世界中最常见的情况是结构化（包括表格和时间序列）和非结构化数据的结合，但这一领域尚未得到充分的研究。为此，我们提出了LANISTR，这是一个新颖的基于注意力机制的框架，用于从语言、图像和结构化数据中进行学习。我们引入了一个新的多模态融合模块，并采用基于相似性的多模态遮罩损失，使得LANISTR能够在大规模多模态数据中学习跨模态关系，并在训练和测试时处理缺失的模态。在两个公开可用的具有挑战性的数据集MIMIC-IV和Amazon Product Review上，与最先进的多模态模型相比，LANISTR分别达到了6.47%（AUROC）和高达17.69%（准确度）的绝对提升，并显示出更强的泛化能力。

    Multimodal large-scale pretraining has shown impressive performance gains for unstructured data including language, image, audio, and video. Yet, the scenario most prominent in real-world applications is the existence of combination of structured (including tabular and time-series) and unstructured data, and this has so far been understudied. Towards this end, we propose LANISTR, a novel attention-based framework to learn from LANguage, Image, and STRuctured data. We introduce a new multimodal fusion module with a similarity-based multimodal masking loss that enables LANISTR to learn cross-modal relations from large-scale multimodal data with missing modalities during training and test time. On two publicly available challenging datasets, MIMIC-IV and Amazon Product Review, LANISTR achieves absolute improvements of 6.47% (AUROC) and up to 17.69% (accuracy), respectively, compared to the state-of-the-art multimodal models while showing superior generalization capabilities.
    
[^91]: PruMUX：利用模型压缩增强数据复用

    PruMUX: Augmenting Data Multiplexing with Model Compression. (arXiv:2305.14706v1 [cs.LG])

    [http://arxiv.org/abs/2305.14706](http://arxiv.org/abs/2305.14706)

    PruMUX是一种结合了结构化剪枝和数据复用的方法，可在保持准确性的情况下提高BERT-base模型的吞吐量。Auto-PruMUX可以预测修剪和复用的高性能参数，从而提供了一个实用的自动化工具。

    

    随着语言模型的不断扩大，提高其推理效率变得至关重要。 先前的研究调查了模型修剪，知识蒸馏和数据复用等技术，以增加模型的吞吐量而不损失准确性。 在本文中，我们将结构化剪枝和数据复用两种方法结合起来，以增强两种方法获得的加速优势。 我们的方法PruMUX在保持准确性阈值为80％到74％的情况下，与BERT-base模型相比，可获得7.5-29.5倍的吞吐量提高。 我们进一步研究了两种技术中不同参数（例如稀疏性和复用因子）的各种组合，以提供有关准确性和吞吐量之间权衡的综合分析。 然后，我们提出了Auto-PruMUX，这是一种元模型，可以在给定期望的精度损失预算的情况下，预测修剪和复用的高性能参数，从而提供了一个实用的自动化工具。

    As language models increase in size by the day, methods for efficient inference are critical to leveraging their capabilities for various applications. Prior work has investigated techniques like model pruning, knowledge distillation, and data multiplexing to increase model throughput without sacrificing accuracy. In this paper, we combine two such methods -structured pruning and data multiplexing -- to compound the speedup gains obtained by either method. Our approach, PruMUX, obtains up to 7.5-29.5X throughput improvement over BERT-base model with accuracy threshold from 80% to 74%. We further study various combinations of parameters (such as sparsity and multiplexing factor) in the two techniques to provide a comprehensive analysis of the tradeoff between accuracy and throughput in the resulting models. We then propose Auto-PruMUX, a meta-level model that can predict the high-performance parameters for pruning and multiplexing given a desired accuracy loss budget, providing a prac
    
[^92]: Structure-CLIP: 结合结构知识优化多模态语言表示

    Structure-CLIP: Enhance Multi-modal Language Representations with Structure Knowledge. (arXiv:2305.06152v1 [cs.CL])

    [http://arxiv.org/abs/2305.06152](http://arxiv.org/abs/2305.06152)

    Structure-CLIP使用文本中的结构化知识，使用场景图强化多模态语言表示，从而在图像-文本匹配任务中展现了更好的性能。

    

    大规模的视觉-语言预训练在各种下游任务中展现出了很好的性能，并在多模态理解和生成任务中取得了显著的进展。然而，现有方法在需要对文本进行详细语义理解的图像-文本匹配任务上通常表现较差。尽管已经有一些研究在解决这个问题，但它们没有充分利用句子中存在的结构化知识来增强多模态语言表示，导致性能较差。本文提出了一个端到端的框架Structure-CLIP，该框架结合了从文本中提取的隐式详细语义，以增强精细的语义表示。具体而言，(1)我们使用场景图来更加关注文本中的详细语义学习，并充分探索细粒度语义之间的结构化知识，(2)我们结合场景图的知识强化框架来充分利用这些信息。

    Large-scale vision-language pre-training has shown promising advances on various downstream tasks and achieved significant performance in multi-modal understanding and generation tasks. However, existing methods often perform poorly on image-text matching tasks that require a detailed semantics understanding of the text. Although there have been some works on this problem, they do not sufficiently exploit the structural knowledge present in sentences to enhance multi-modal language representations, which leads to poor performance. In this paper, we present an end-to-end framework Structure-CLIP, which integrates latent detailed semantics from the text to enhance fine-grained semantic representations. Specifically, (1) we use scene graphs in order to pay more attention to the detailed semantic learning in the text and fully explore structured knowledge between fine-grained semantics, and (2) we utilize the knowledge-enhanced framework with the help of the scene graph to make full use of
    
[^93]: 正向人工智能：设计以幸福为导向的人工智能的关键挑战

    Positive AI: Key Challenges for Designing Wellbeing-aligned Artificial Intelligence. (arXiv:2304.12241v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2304.12241](http://arxiv.org/abs/2304.12241)

    设计以幸福为导向的人工智能系统面临着知识和动机两方面的挑战，包括概念化、测量和优化幸福，设计适当的AI行动，以及激励措施、财务和宣传风险的不一致以及数据获取的缺乏。针对这些挑战，需要在科学理解AI系统对幸福影响方面进行研究，并指导设计行动。

    

    人工智能（AI）正迅速改变社会，迫切需要确保其积极影响。本文采用积极设计方法来解决这个问题，将其视为设计主动支持人类幸福的AI系统的问题。然而，设计以幸福为导向的AI系统是困难的。本文采用控制论的视角，识别了两个类别中的十二个关键挑战：知识缺乏和动机缺乏。知识障碍包括概念化、测量和优化幸福，并设计适当的AI行动方面的挑战。动机障碍包括不一致的激励措施、财务和宣传风险，以及缺乏数据获取阻止了（第三方）对幸福进行研究。为了应对这些挑战，我们提出了一个研究议程，包括推进对AI系统对幸福影响的科学理解，并指导如何进行AI系统的设计行动。

    Artificial Intelligence (AI) is rapidly transforming society, creating an urgent need to ensure its positive impact. In this article, we take a positive design approach towards this issue, viewing it as a matter of designing AI systems that actively support human wellbeing. However, designing wellbeing-aligned AI systems is difficult. This article adopts a cybernetic perspective to identify twelve key challenges across two categories: lack of knowledge and lack of motivation. Knowledge barriers include challenges in conceptualizing, measuring, and optimizing for wellbeing, then designing appropriate AI actions. Motivation barriers include misaligned incentives, financial and publicity risks, and a lack of data access preventing (third-party) research on wellbeing. To address these challenges we have captured our key takeaways in a research agenda related to 1) advancing the scientific understanding of the impact of AI systems on wellbeing, and 2) guiding design actions on how AI system
    
[^94]: HyperTab: 基于超网络的小型表格数据深度学习方法

    HyperTab: Hypernetwork Approach for Deep Learning on Small Tabular Datasets. (arXiv:2304.03543v1 [cs.LG])

    [http://arxiv.org/abs/2304.03543](http://arxiv.org/abs/2304.03543)

    HyperTab是一种基于超网络结合了随机森林和神经网络优点的小型表格数据深度学习方法，使用每个特定低维视图处理数据，虚拟增加训练样本数量，避免过度拟合。

    

    深度学习在许多领域取得了惊人的表现，例如计算机视觉和自然语言处理，但它在表格数据集上相对传统浅层方法的优势仍然值得商榷。在小型数据集（小于1k个样本）上超过树状集成（如XGBoost或随机森林）的表现尤其具有挑战性。为了解决这个问题，我们引入了HyperTab，这是一种基于超网络解决表格数据集小样本问题的方法。通过将随机森林和神经网络的优点结合起来，HyperTab生成了一个神经网络集合，其中每个目标模型专门处理数据的特定低维视图。由于每个视图扮演数据增强的角色，我们在保持可训练参数数量不变的情况下，虚拟增加了训练样本数量，从而避免了过度拟合。我们对40多个大小不同的表格数据集对HyperTab进行了评估。

    Deep learning has achieved impressive performance in many domains, such as computer vision and natural language processing, but its advantage over classical shallow methods on tabular datasets remains questionable. It is especially challenging to surpass the performance of tree-like ensembles, such as XGBoost or Random Forests, on small-sized datasets (less than 1k samples). To tackle this challenge, we introduce HyperTab, a hypernetwork-based approach to solving small sample problems on tabular datasets. By combining the advantages of Random Forests and neural networks, HyperTab generates an ensemble of neural networks, where each target model is specialized to process a specific lower-dimensional view of the data. Since each view plays the role of data augmentation, we virtually increase the number of training samples while keeping the number of trainable parameters unchanged, which prevents model overfitting. We evaluated HyperTab on more than 40 tabular datasets of a varying number
    
[^95]: 基于层级自回归语言模型合成极高维长期电子健康记录

    Synthesize Extremely High-dimensional Longitudinal Electronic Health Records via Hierarchical Autoregressive Language Model. (arXiv:2304.02169v1 [cs.LG])

    [http://arxiv.org/abs/2304.02169](http://arxiv.org/abs/2304.02169)

    此论文提出了一种名为HALO的方法，它是一个层级自回归模型，可以生成高保真、细粒度电子健康记录数据，而这些数据可以用于训练准确的ML模型，且无需涉及隐私问题。

    

    合成的电子健康记录(EHRs)能够在机器学习(ML)和统计分析中作为真实EHRs的替代品，既真实又保护隐私。然而，由于高维数据的内在复杂性，以其原始高度维形式生成高保真、细粒度电子健康记录(EHR)数据对现有方法构成了挑战。本文提出了一种名为“Hierarchical Autoregressive Language mOdel (HALO)”的方法，用于生成纵向高维EHR数据，该方法保留了真实EHR的统计特性，可以用于训练准确的ML模型而不涉及隐私问题。我们的HALO方法被设计为一个层级自回归模型，生成一组针对医学代码、临床就诊和病人记录的概率密度函数，可以在其原始未聚合形式下生成真实的EHR数据，无需进行变量选择或聚合。此外，我们的模型还产生大量的随机样本，以提供复杂度较低但仍有意义的EHR数据。

    Synthetic electronic health records (EHRs) that are both realistic and preserve privacy can serve as an alternative to real EHRs for machine learning (ML) modeling and statistical analysis. However, generating high-fidelity and granular electronic health record (EHR) data in its original, highly-dimensional form poses challenges for existing methods due to the complexities inherent in high-dimensional data. In this paper, we propose Hierarchical Autoregressive Language mOdel (HALO) for generating longitudinal high-dimensional EHR, which preserve the statistical properties of real EHR and can be used to train accurate ML models without privacy concerns. Our HALO method, designed as a hierarchical autoregressive model, generates a probability density function of medical codes, clinical visits, and patient records, allowing for the generation of realistic EHR data in its original, unaggregated form without the need for variable selection or aggregation. Additionally, our model also produc
    
[^96]: 多元化老化扩散自编码器

    Pluralistic Aging Diffusion Autoencoder. (arXiv:2303.11086v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.11086](http://arxiv.org/abs/2303.11086)

    本文提出了一种多元化老化扩散自编码器（PADA），通过扩散模型生成多样的低层老化细节，并使用概率老化嵌入（PAE）捕捉多样的高层老化模式。实验证明该方法能够产生更多样和高质量的老化效果。

    

    人脸老化是一个模糊的问题，因为一个给定的输入可能对应着多种合理的老化模式。现有的大多数方法通常只能产生一个确定性的估计。本文提出了一种新颖的基于CLIP驱动的多元化老化扩散自编码器（PADA），以增强老化模式的多样性。首先，我们使用扩散模型通过一个顺序去噪逆过程生成多样的低层老化细节。其次，我们提出了概率老化嵌入（PAE），以在常见的CLIP潜在空间中将年龄信息表示为概率分布，从而捕捉多样的高层老化模式。我们设计了一个文本引导的KL散度损失来指导这个学习过程。我们的方法可以根据面向开放世界的老化文本和任意未见的面部图像实现多元化的人脸老化。定性和定量实验证明我们的方法可以生成更多样和高质量的老化结果。

    Face aging is an ill-posed problem because multiple plausible aging patterns may correspond to a given input. Most existing methods often produce one deterministic estimation. This paper proposes a novel CLIP-driven Pluralistic Aging Diffusion Autoencoder (PADA) to enhance the diversity of aging patterns. First, we employ diffusion models to generate diverse low-level aging details via a sequential denoising reverse process. Second, we present Probabilistic Aging Embedding (PAE) to capture diverse high-level aging patterns, which represents age information as probabilistic distributions in the common CLIP latent space. A text-guided KL-divergence loss is designed to guide this learning. Our method can achieve pluralistic face aging conditioned on open-world aging texts and arbitrary unseen face images. Qualitative and quantitative experiments demonstrate that our method can generate more diverse and high-quality plausible aging results.
    
[^97]: 基于生物信息学的机器学习中的Anderson加速

    Anderson Acceleration For Bioinformatics-Based Machine Learning. (arXiv:2302.00347v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00347](http://arxiv.org/abs/2302.00347)

    这项研究在经典机器学习分类器中探索了Anderson加速的有效性，并通过使用AA，达到了显著提高收敛速度和减小训练误差的效果。

    

    Anderson加速（AA）是一种用于加快迭代算法收敛速度的著名方法，应用于深度学习和优化等各个领域。尽管在这些领域中AA很受欢迎，但其在经典机器学习分类器中的有效性尚未得到彻底研究。尤其是对于表格数据，深度学习模型面临着独特的挑战，而经典机器学习模型在这些场景中表现更好。然而，这些模型的收敛性分析受到了有限的关注。为了填补这一研究空白，我们实现了一种支持向量机（SVM）分类器变种，结合了AA以加速收敛。我们评估了在多个生物学领域的数据集上使用和不使用Anderson加速的SVM的性能，并证明在迭代次数增加时，使用AA显著提高了收敛速度，并减小了训练误差。我们的研究结果提供了一个。

    Anderson acceleration (AA) is a well-known method for accelerating the convergence of iterative algorithms, with applications in various fields including deep learning and optimization. Despite its popularity in these areas, the effectiveness of AA in classical machine learning classifiers has not been thoroughly studied. Tabular data, in particular, presents a unique challenge for deep learning models, and classical machine learning models are known to perform better in these scenarios. However, the convergence analysis of these models has received limited attention. To address this gap in research, we implement a support vector machine (SVM) classifier variant that incorporates AA to speed up convergence. We evaluate the performance of our SVM with and without Anderson acceleration on several datasets from the biology domain and demonstrate that the use of AA significantly improves convergence and reduces the training loss as the number of iterations increases. Our findings provide a
    
[^98]: BallGAN: 带有球形背景的3D感知图像合成

    BallGAN: 3D-aware Image Synthesis with a Spherical Background. (arXiv:2301.09091v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.09091](http://arxiv.org/abs/2301.09091)

    BallGAN是一个新颖的3D感知GAN框架，通过将背景近似为球形表面，并使用特定约束来减少背景自由度，可以产生更合理的3D几何。

    

    3D感知的生成对抗网络（GAN）旨在合成逼真的3D场景，以便可以以任意角度进行渲染以产生图像。尽管以前的方法可以产生逼真的图像，但它们在训练不稳定或存在不自然的3D几何解决方案方面存在问题。我们假设3D几何在约束不足的情况下是不确定的，即仅将其分类为真实图像对于鉴别器来说是不够的。为了解决这个问题，我们提出将背景近似为球形表面，并将场景表示为放置在球体中的前景和薄球形背景的联合。这样可以减少背景场的自由度。因此，我们修改了体渲染方程，并加入了专用的约束，设计了一种名为BallGAN的新型3D感知GAN框架。 BallGAN具有以下多个优点。1）它产生了更合理的3D几何；场景在不同视角下的图像具有更好的光度。

    3D-aware GANs aim to synthesize realistic 3D scenes such that they can be rendered in arbitrary perspectives to produce images. Although previous methods produce realistic images, they suffer from unstable training or degenerate solutions where the 3D geometry is unnatural. We hypothesize that the 3D geometry is underdetermined due to the insufficient constraint, i.e., being classified as real image to the discriminator is not enough. To solve this problem, we propose to approximate the background as a spherical surface and represent a scene as a union of the foreground placed in the sphere and the thin spherical background. It reduces the degree of freedom in the background field. Accordingly, we modify the volume rendering equation and incorporate dedicated constraints to design a novel 3D-aware GAN framework named BallGAN. BallGAN has multiple advantages as follows. 1) It produces more reasonable 3D geometry; the images of a scene across different viewpoints have better photometric 
    
[^99]: 使用可微分光线追踪和机器学习在多模光导管中高效传输Megapixel图像的研究

    Efficient data transport over multimode light-pipes with Megapixel images using differentiable ray tracing and Machine-learning. (arXiv:2301.06496v3 [physics.optics] UPDATED)

    [http://arxiv.org/abs/2301.06496](http://arxiv.org/abs/2301.06496)

    本研究利用可微分光线追踪和机器学习的方法，在多模光导管中实现了对Megapixel图像的高效传输，通过使用数字孪生和U-Net结合，减少了解码的计算复杂度，并比较了不同模式的性能差异。最终实现了对大规模数字图像的解码和检索，为光学存储应用提供了重要的技术支持。

    

    由于多模光纤能够有效地约束和传输光线，在传输通过多模光纤的图像方面的研究越来越受到关注。在本研究中，我们使用基于机器学习的方法解码大规模数字图像，以最大化光学存储应用的页面容量。通过使用毫米级方形横截面波导，我们可以将8位空间光调制器成像，将数据表示为符号矩阵。通过将系统的数字孪生与U-Net相结合，我们可以仅使用高效的卷积操作来检索高达66 kB的数据，而通常的解码器在处理空间混乱的数据时会导致计算复杂度的O(n^2)。通过比较基于可训练光线追踪和基于本征模的数字孪生，我们发现前者具有优越性，因为它能够通过调整光学缺陷来弥补模拟与实验之间的差距。我们使用可微分互信息方法对整个流程进行端到端的训练。

    Retrieving images transmitted through multi-mode fibers is of growing interest, thanks to their ability to confine and transport light efficiently in a compact system. Here, we demonstrate machine-learning-based decoding of large-scale digital images (pages), maximizing page capacity for optical storage applications. Using a millimeter-sized square cross-section waveguide, we image an 8-bit spatial light modulator, presenting data as a matrix of symbols. Normally, decoders will incur a prohibitive O(n^2) computational scaling to decode n symbols in spatially scrambled data. However, by combining a digital twin of the setup with a U-Net, we can retrieve up to 66 kB using efficient convolutional operations only. We compare trainable ray-tracing-based with eigenmode-based twins and show the former to be superior thanks to its ability to overcome the simulation-to-experiment gap by adjusting to optical imperfections. We train the pipeline end-to-end using a differentiable mutual-informatio
    
[^100]: DexBERT：Android字节码的有效、任务无关和精细化表示学习

    DexBERT: Effective, Task-Agnostic and Fine-grained Representation Learning of Android Bytecode. (arXiv:2212.05976v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2212.05976](http://arxiv.org/abs/2212.05976)

    DexBERT是一项研究Android字节码的有效、任务无关和精细化表示学习的工作，旨在捕捉信息以适用于各种低级下游任务。

    

    由于机器学习的进展，大量软件工程任务的自动化成为可能。在将机器学习应用于软件工件（如源代码或可执行代码）时，关键是将它们转化为适合学习的形式。传统上，研究人员依赖于基于专家知识的手动选择特征，但有时这种方法可能不准确或不完全。表示学习使得机器学习能自动选择合适的表示和相关特征。然而，对于与Android相关的任务，现有模型如apk2vec聚焦于整个应用程序级别，或者专注于特定任务如smali2vec，这限制了它们的适用性。我们的研究是一项新的研究方向，旨在调查Android字节码的有效、任务无关和精细化的通用表示，以减轻这两个限制。这些表示旨在捕捉与各种低级下游任务（例如类级别）相关的信息。

    The automation of a large number of software engineering tasks is becoming possible thanks to Machine Learning (ML). Central to applying ML to software artifacts (like source or executable code) is converting them into forms suitable for learning. Traditionally, researchers have relied on manually selected features, based on expert knowledge which is sometimes imprecise and generally incomplete. Representation learning has allowed ML to automatically choose suitable representations and relevant features. Yet, for Android-related tasks, existing models like apk2vec focus on whole-app levels, or target specific tasks like smali2vec, which limits their applicability. Our work is part of a new line of research that investigates effective, task-agnostic, and fine-grained universal representations of bytecode to mitigate both of these two limitations. Such representations aim to capture information relevant to various low-level downstream tasks (e.g., at the class-level). We are inspired by 
    
[^101]: 管理AI和数据的守门员：在DMA、GDPR及更多法规下的透明度、访问和公平性

    Regulating Gatekeeper AI and Data: Transparency, Access, and Fairness under the DMA, the GDPR, and beyond. (arXiv:2212.04997v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2212.04997](http://arxiv.org/abs/2212.04997)

    数字市场法规定了对人工智能应用的欧盟规则，其对披露要求、人工智能训练数据的管理、访问规则和公平排名制度具有广泛而有效的影响。

    

    人工智能不仅在商业和行政领域的应用越来越普遍，对其规范的竞赛也正在进行中，欧盟在这方面处于前沿。但与现有文献不同，本文认为，在数字市场法议案中所包含的对数字经济中人工智能应用的欧盟规则不仅具有最广泛的影响力，而且是最有效的。我们分析了DMA及相关欧盟法案对人工智能模型及其基础数据的四个关键领域的影响：披露要求；人工智能训练数据的管理；访问规则；公平排名制度。本文证明，DMA中的公平性超越了目前人工智能与法律交叉学科中主要关注的传统非歧视法律所保护的类别。相反，我们借鉴了竞争法和知识产权法中的FRAND准则来解释和评价。

    Artificial intelligence is not only increasingly used in business and administration contexts, but a race for its regulation is also underway, with the EU spearheading the efforts. Contrary to existing literature, this article suggests, however, that the most far-reaching and effective EU rules for AI applications in the digital economy will not be contained in the proposed AI Act - but have just been enacted in the Digital Markets Act. We analyze the impact of the DMA and related EU acts on AI models and their underlying data across four key areas: disclosure requirements; the regulation of AI training data; access rules; and the regime for fair rankings. The paper demonstrates that fairness, in the sense of the DMA, goes beyond traditionally protected categories of non-discrimination law on which scholarship at the intersection of AI and law has so far largely focused on. Rather, we draw on competition law and the FRAND criteria known from intellectual property law to interpret and r
    
[^102]: 神经傅里叶滤波器组

    Neural Fourier Filter Bank. (arXiv:2212.01735v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.01735](http://arxiv.org/abs/2212.01735)

    该论文提出了一个新的神经傅里叶滤波器组方法，该方法既在空间上又在频率上分解信号，通过使用傅里叶编码特定频率来存储每个网格，这一方法在2D图像拟合、3D形状重建和神经辐射场等多个任务上，表现出优于现有技术的模型紧凑性和收敛速度。

    

    我们提出了一种新的方法，以提供高效且高度详细的重构。受小波启发，我们学习了一个神经场，既在空间上又在频率上分解信号。我们遵循最近的基于网格的空间分解范例，但与现有的工作不同，通过傅里叶特征编码鼓励在每个网格中存储特定的频率。然后，我们应用带正弦激活函数的多层感知器，以在适当的层次上接受这些傅里叶编码的特征，以使高频组件依次累积在低频组件之上，最后将它们相加以形成最终输出。我们证明了我们的方法在多个任务上（2D图像拟合，3D形状重建和神经辐射场）优于现有技术，包括模型紧凑性和收敛速度。我们的代码可以在https://github.com/ubc-vision/NFFB获得。

    We present a novel method to provide efficient and highly detailed reconstructions. Inspired by wavelets, we learn a neural field that decompose the signal both spatially and frequency-wise. We follow the recent grid-based paradigm for spatial decomposition, but unlike existing work, encourage specific frequencies to be stored in each grid via Fourier features encodings. We then apply a multi-layer perceptron with sine activations, taking these Fourier encoded features in at appropriate layers so that higher-frequency components are accumulated on top of lower-frequency components sequentially, which we sum up to form the final output. We demonstrate that our method outperforms the state of the art regarding model compactness and convergence speed on multiple tasks: 2D image fitting, 3D shape reconstruction, and neural radiance fields. Our code is available at https://github.com/ubc-vision/NFFB.
    
[^103]: 基于贝叶斯神经网络的离岸风电结构全场虚拟负载监测

    Farm-wide virtual load monitoring for offshore wind structures via Bayesian neural networks. (arXiv:2211.00642v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.00642](http://arxiv.org/abs/2211.00642)

    该论文介绍了一种基于贝叶斯神经网络的全场虚拟负载监测方案，以解决离岸风电结构监测的不确定性和实际限制问题。

    

    离岸风电结构在运行寿命内会受到退化机制的影响。即使通过基于物理的退化模型可以估计结构元件的退化演变，但过程中涉及的不确定性阻碍了生命周期管理决策的选择。在这种情况下，通过高效的监测系统收集相关信息，可以减少不确定性，最终推动更优化的生命周期决策。然而，在整个风电场的所有风力涡轮上实施完整的监测仪器可能由于实际和经济限制而变得不可行。此外，某些负载监测系统在海洋环境暴露几年后经常发生故障。为解决上述问题，由一个领导型风力涡轮指导的全场虚拟负载监测方案提供了一种有吸引力的解决方案。

    Offshore wind structures are subject to deterioration mechanisms throughout their operational lifetime. Even if the deterioration evolution of structural elements can be estimated through physics-based deterioration models, the uncertainties involved in the process hurdle the selection of lifecycle management decisions. In this scenario, the collection of relevant information through an efficient monitoring system enables the reduction of uncertainties, ultimately driving more optimal lifecycle decisions. However, a full monitoring instrumentation implemented on all wind turbines in a farm might become unfeasible due to practical and economical constraints. Besides, certain load monitoring systems often become defective after a few years of marine environment exposure. Addressing the aforementioned concerns, a farm-wide virtual load monitoring scheme directed by a fleet-leader wind turbine offers an attractive solution. Fetched with data retrieved from a fully-instrumented wind turbine
    
[^104]: 通过结构增强的预训练模型和自适应融合提高语义匹配

    Improving Semantic Matching through Dependency-Enhanced Pre-trained Model with Adaptive Fusion. (arXiv:2210.08471v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.08471](http://arxiv.org/abs/2210.08471)

    本文提出了一种依赖增强的自适应融合注意力模型，它将依赖信息与原始语义信号自适应融合，以更好地模拟复杂的语义匹配关系。

    

    基于Transformer的预训练模型，如BERT，在语义句子匹配方面取得了很大的进展。同时，依赖性先验知识在多个NLP任务中也显示出普遍的益处。然而，如何将依赖性先验结构有效地集成到预训练模型中，以更好地模拟复杂的语义匹配关系，仍未确定。在本文中，我们提出了一种名为DAFA的依赖增强自适应融合注意力模型，这将依赖结构明确地引入预训练模型，并将其自适应地融合到语义信息中。具体地，DAFA首先提出了一个结构敏感范式来构建一个依赖矩阵，以校准注意力权重。它采用自适应融合模块来集成获取的依赖信息和原始语义信号。此外，DAFA重构了注意力计算流程，并提供了更好的可解释性。

    Transformer-based pre-trained models like BERT have achieved great progress on Semantic Sentence Matching. Meanwhile, dependency prior knowledge has also shown general benefits in multiple NLP tasks. However, how to efficiently integrate dependency prior structure into pre-trained models to better model complex semantic matching relations is still unsettled. In this paper, we propose the \textbf{D}ependency-Enhanced \textbf{A}daptive \textbf{F}usion \textbf{A}ttention (\textbf{DAFA}), which explicitly introduces dependency structure into pre-trained models and adaptively fuses it with semantic information. Specifically, \textbf{\emph{(i)}} DAFA first proposes a structure-sensitive paradigm to construct a dependency matrix for calibrating attention weights. It adopts an adaptive fusion module to integrate the obtained dependency information and the original semantic signals. Moreover, DAFA reconstructs the attention calculation flow and provides better interpretability. By applying it o
    
[^105]: 利用自注意力指导提高扩散模型的样本质量

    Improving Sample Quality of Diffusion Models Using Self-Attention Guidance. (arXiv:2210.00939v5 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.00939](http://arxiv.org/abs/2210.00939)

    该论文提出了一种利用自注意力指导的策略来提升扩散模型生成图像的稳定性和质量，具有较高的实用价值。

    

    去噪扩散模型以其出色的生成质量和多样性受到关注。这种成功很大程度上归因于使用分类或文本条件的扩散指导方法，如分类器和无分类器指导。在本文中，我们提出了一个更全面的视角，超越了传统的指导方法。从这个广义的视角出发，我们引入了新的无条件和无监督的策略来提高生成图像的质量。作为一种简单的解决方案，模糊指导改善了中间样本的适用性，使得扩散模型能够以适度的指导尺度生成更高质量的样本。在此基础上，自注意力指导（SAG）利用了扩散模型的中间自注意力映射来增强它们的稳定性和效果。具体而言，SAG在每次迭代中仅对扩散模型关注的区域进行对抗性模糊处理。

    Denoising diffusion models (DDMs) have attracted attention for their exceptional generation quality and diversity. This success is largely attributed to the use of class- or text-conditional diffusion guidance methods, such as classifier and classifier-free guidance. In this paper, we present a more comprehensive perspective that goes beyond the traditional guidance methods. From this generalized perspective, we introduce novel condition- and training-free strategies to enhance the quality of generated images. As a simple solution, blur guidance improves the suitability of intermediate samples for their fine-scale information and structures, enabling diffusion models to generate higher quality samples with a moderate guidance scale. Improving upon this, Self-Attention Guidance (SAG) uses the intermediate self-attention maps of diffusion models to enhance their stability and efficacy. Specifically, SAG adversarially blurs only the regions that diffusion models attend to at each iteratio
    
[^106]: 使用基于Transformer的场景表示学习增强强化学习用于自动驾驶决策

    Augmenting Reinforcement Learning with Transformer-based Scene Representation Learning for Decision-making of Autonomous Driving. (arXiv:2208.12263v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.12263](http://arxiv.org/abs/2208.12263)

    本研究提出了Scene-Rep Transformer来提升强化学习决策能力，通过改进场景表示编码和顺序预测潜在蒸馏。采用多阶段Transformer编码器建模交互意识和意图意识，并使用顺序潜在Transformer进行自监督学习，加速训练和减少探索空间。

    

    城市自动驾驶的决策是具有挑战性的，由于交通参与者的随机性和道路结构的复杂性。尽管基于强化学习（RL）的决策方案在处理城市驾驶场景方面很有前景，但它的采样效率低且适应性差。在本文中，我们提出了Scene-Rep Transformer来改善RL决策能力，通过更好的场景表示编码和顺序预测潜在蒸馏。具体而言，我们构建了一个多阶段Transformer（MST）编码器，用于建模自车与其邻居之间的交互意识以及代理者与候选路径之间的意图意识。我们采用了一个具有自监督学习目标的顺序潜在Transformer（SLT），将未来的预测信息蒸馏到潜在的场景表示中，以减少探索空间并加快训练。

    Decision-making for urban autonomous driving is challenging due to the stochastic nature of interactive traffic participants and the complexity of road structures. Although reinforcement learning (RL)-based decision-making scheme is promising to handle urban driving scenarios, it suffers from low sample efficiency and poor adaptability. In this paper, we propose Scene-Rep Transformer to improve the RL decision-making capabilities with better scene representation encoding and sequential predictive latent distillation. Specifically, a multi-stage Transformer (MST) encoder is constructed to model not only the interaction awareness between the ego vehicle and its neighbors but also intention awareness between the agents and their candidate routes. A sequential latent Transformer (SLT) with self-supervised learning objectives is employed to distill the future predictive information into the latent scene representation, in order to reduce the exploration space and speed up training. The fina
    
[^107]: 测试时间自适应视觉文档理解

    Test-Time Adaptation for Visual Document Understanding. (arXiv:2206.07240v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.07240](http://arxiv.org/abs/2206.07240)

    该论文提出了一种测试时间自适应方法，用于将自监督预训练得到的表示适应到测试时的分布转移。通过利用跨模态自监督学习和伪标签方法，该方法在文档理解任务中实现了显著的改进，并在实体识别、键值提取和文档视觉问答上分别提高了1.89%、3.43%和17.68%。

    

    对于视觉文档理解（VDU），自监督预训练已被证明能够成功生成具有可传递性的表示，然而，在测试时间对这种表示进行有效的适应仍然是一个未被探索的领域。我们提出了DocTTA，一种用于文档的新型测试时间适应方法，该方法使用无标签的目标文档数据进行无源域适应。DocTTA利用跨模态自监督学习和伪标签方法，将在“源”域上学到的模型适应到未标记的“目标”域。我们使用现有的公共数据集为各种VDU任务引入了新的基准，包括实体识别、键值提取和文档视觉问答。相比于源模型性能，DocTTA在这些任务上表现出了显著的改进，分别提高了1.89%（F1分数）、3.43%（F1分数）和17.68%（ANLS分数）。

    For visual document understanding (VDU), self-supervised pretraining has been shown to successfully generate transferable representations, yet, effective adaptation of such representations to distribution shifts at test-time remains to be an unexplored area. We propose DocTTA, a novel test-time adaptation method for documents, that does source-free domain adaptation using unlabeled target document data. DocTTA leverages cross-modality self-supervised learning via masked visual language modeling, as well as pseudo labeling to adapt models learned on a \textit{source} domain to an unlabeled \textit{target} domain at test time. We introduce new benchmarks using existing public datasets for various VDU tasks, including entity recognition, key-value extraction, and document visual question answering. DocTTA shows significant improvements on these compared to the source model performance, up to 1.89\% in (F1 score), 3.43\% (F1 score), and 17.68\% (ANLS score), respectively. Our benchmark dat
    
[^108]: 在医学图像中利用全局二进制掩码进行结构分割

    Leveraging Global Binary Masks for Structure Segmentation in Medical Images. (arXiv:2205.09107v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2205.09107](http://arxiv.org/abs/2205.09107)

    这篇论文提出了利用全局二进制掩码来进行医学图像中结构分割的方法，通过利用器官的解剖形状和位置信息的一致性来进行分割。研究了两种情况下的应用，并在脑部和心脏CT图像数据集上进行了验证。

    

    对于医学图像分割的深度学习模型受到输入图像强度变化的影响很大，并且由于主要利用像素强度信息进行推理，缺乏泛化能力。获取足够的训练数据是限制模型应用的另一个挑战。我们提出利用医学图像中器官的解剖形状和位置信息的一致性。我们引入了一个框架，通过全局二进制掩码来利用重复出现的解剖模式进行器官分割。研究了两种情况：1）全局二进制掩码是模型(U-Net)的唯一输入，强制进行器官的定位和形状信息编码进行分割。2）将全局二进制掩码作为附加通道，并用作位置和形状线索以减少训练数据的稀缺性。将两个包含脑部和心脏CT图像及其地面实况的数据集分为(26:10:10)和(12:3:5)进行训练、验证和测试。

    Deep learning (DL) models for medical image segmentation are highly influenced by intensity variations of input images and lack generalization due to primarily utilizing pixels' intensity information for inference. Acquiring sufficient training data is another challenge limiting models' applications. We proposed to leverage the consistency of organs' anatomical shape and position information in medical images. We introduced a framework leveraging recurring anatomical patterns through global binary masks for organ segmentation. Two scenarios were studied.1) Global binary masks were the only model's (i.e. U-Net) input, forcing exclusively encoding organs' position and shape information for segmentation/localization.2) Global binary masks were incorporated as an additional channel functioning as position/shape clues to mitigate training data scarcity. Two datasets of the brain and heart CT images with their ground-truth were split into (26:10:10) and (12:3:5) for training, validation, and
    
[^109]: MonoDETR：深度引导的单目3D目标检测的Transformer

    MonoDETR: Depth-guided Transformer for Monocular 3D Object Detection. (arXiv:2203.13310v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2203.13310](http://arxiv.org/abs/2203.13310)

    本文介绍了一种名为MonoDETR的深度引导Transformer框架，用于单目3D目标检测。相比于传统的方法，MonoDETR通过引入深度信息来指导整个检测过程，提高了对场景的理解和目标的准确性。

    

    单目三维目标检测一直是自动驾驶中一项具有挑战性的任务。大多数现有方法是根据传统的二维检测器首先定位目标中心，然后通过邻近特征预测三维属性。然而，仅仅使用局部视觉特征是不足以理解场景级别的三维空间结构并忽略了远距离的目标深度关系。在本文中，我们引入了第一个采用深度引导Transformer的单目检测框架，称为MonoDETR。我们将基本的Transformer进行了修改，使其具有深度感知，并通过上下文深度线索来指导整个检测过程。具体而言，在捕捉物体外观的视觉编码器的同时，我们引入了预测前景深度图，并专门设计了一个深度编码器来提取非局部深度嵌入。然后，我们将三维目标候选物形式化为可学习的查询，并提出了一个深度引导的解码器来进行目标-场景深度交互。通过这种方式，每个目标都可以得到更全面的深度感知和更准确的三维检测结果。

    Monocular 3D object detection has long been a challenging task in autonomous driving. Most existing methods follow conventional 2D detectors to first localize object centers, and then predict 3D attributes by neighboring features. However, only using local visual features is insufficient to understand the scene-level 3D spatial structures and ignores the long-range inter-object depth relations. In this paper, we introduce the first DETR framework for Monocular DEtection with a depth-guided TRansformer, named MonoDETR. We modify the vanilla transformer to be depth-aware and guide the whole detection process by contextual depth cues. Specifically, concurrent to the visual encoder that captures object appearances, we introduce to predict a foreground depth map, and specialize a depth encoder to extract non-local depth embeddings. Then, we formulate 3D object candidates as learnable queries and propose a depth-guided decoder to conduct object-scene depth interactions. In this way, each obj
    
[^110]: LSTM模型用于预测石油公司股票的可解释性：相关特征的影响

    The Interpretability of LSTM Models for Predicting Oil Company Stocks: impacts of correlated features. (arXiv:2201.00350v3 [q-fin.ST] UPDATED)

    [http://arxiv.org/abs/2201.00350](http://arxiv.org/abs/2201.00350)

    研究探究了相关特征对用于预测石油公司股票的LSTM模型的可解释性的影响。结果表明，添加与石油股票相关的特征并不会提高LSTM模型的可解释性，因此应谨慎依靠LSTM模型进行股票市场决策。

    

    石油公司是全球最大的公司之一，由于与黄金、原油和美元相关，其经济指标对全球经济和市场有着巨大的影响。本研究调查了相关特征对用于预测石油公司股票的长短期记忆(LSTM)模型的可解释性的影响。为了实现这一目标，我们设计了标准的LSTM网络，并使用各种相关数据集进行了训练。我们的方法旨在通过考虑影响市场的多个因素，如原油价格、黄金价格和美元，来提高股票价格预测的准确性。结果表明，添加与石油股票相关的特征并不会提高LSTM模型的可解释性。这些发现表明，虽然LSTM模型在预测股票价格方面可能是有效的，但其可解释性可能有限。在仅依靠LSTM模型进行股票市场决策时应格外谨慎。

    Oil companies are among the largest companies in the world whose economic indicators in the global stock market have a great impact on the world economy and market due to their relation to gold, crude oil, and the dollar. This study investigates the impact of correlated features on the interpretability of Long Short-Term Memory (LSTM) models for predicting oil company stocks. To achieve this, we designed a Standard Long Short-Term Memory (LSTM) network and trained it using various correlated datasets. Our approach aims to improve the accuracy of stock price prediction by considering the multiple factors affecting the market, such as crude oil prices, gold prices, and the US dollar. The results demonstrate that adding a feature correlated with oil stocks does not improve the interpretability of LSTM models. These findings suggest that while LSTM models may be effective in predicting stock prices, their interpretability may be limited. Caution should be exercised when relying solely on L
    

