# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection for Conversational AI.](http://arxiv.org/abs/2307.10172) | DialogStudio是迄今为止最大且最多样化的对话数据集合，包含从开放领域对话到任务导向对话、自然语言理解、会话推荐、对话摘要和知识驱动对话的数据。它为对话研究和模型训练提供了丰富而多样化的资源。 |
| [^2] | [LightPath: Lightweight and Scalable Path Representation Learning.](http://arxiv.org/abs/2307.10171) | LightPath是一个轻量级和可伸缩的路径表示学习框架，旨在实现在资源受限的环境下降低资源消耗和实现可伸缩性，同时保持高准确性，从而实现更广泛的适用性。 |
| [^3] | [Challenges and Applications of Large Language Models.](http://arxiv.org/abs/2307.10169) | 本文旨在总结大型语言模型领域的挑战和应用成功案例，帮助机器学习研究人员快速了解该领域的当前状态并提高效率。 |
| [^4] | [Robust Driving Policy Learning with Guided Meta Reinforcement Learning.](http://arxiv.org/abs/2307.10160) | 本文提出了一种通过引导元元策略学习方法来实现社交车辆多样驾驶策略的有效方法，并使用训练策略增强自主驾驶策略的鲁棒性。 |
| [^5] | [Benchmarking Potential Based Rewards for Learning Humanoid Locomotion.](http://arxiv.org/abs/2307.10142) | 本文对人形机器人使用标准形式的奖励塑造和潜在基于奖励的塑造进行了基准测试。在高维系统中，潜在基于奖励的塑造（PBRS）对于收敛速度的提升效果较小。 |
| [^6] | [Extended Graph Assessment Metrics for Graph Neural Networks.](http://arxiv.org/abs/2307.10112) | 本论文提出了扩展的图评估指标（GAMs），适用于回归任务和连续邻接矩阵。主要关注的两个GAMs是同质性和跨类邻域相似度（CCNS）。这些扩展的指标能够在图神经网络中评估图结构，提高模型性能。 |
| [^7] | [A decision making framework for recommended maintenance of road segments.](http://arxiv.org/abs/2307.10085) | 这项研究提出了一个决策框架，通过整合多种人工智能决策技术和历史数据，为道路管理部门提供科学决策工具和证据，以解决道路维护的问题。 |
| [^8] | [Accurate deep learning sub-grid scale models for large eddy simulations.](http://arxiv.org/abs/2307.10060) | 本文提出了两个用于大涡模拟的子网格尺度模型，采用深度学习算法并与分析模型相比能够处理更复杂的非线性关系。其中一个模型融入了多个不变性，另一个只融入了伽利略不变性。 |
| [^9] | [Ethics in the Age of AI: An Analysis of AI Practitioners' Awareness and Challenges.](http://arxiv.org/abs/2307.10057) | 这项研究调查了100名人工智能从业者对人工智能伦理的认识和纳入伦理方面所面临的挑战。结果显示，大多数人工智能从业者对人工智能伦理有一定的了解，主要归因于工作场所规则和政策，并且隐私保护和安全是他们熟悉的伦理原则。教育和培训被认为在帮助人工智能从业者纳入伦理方面有所帮助。挑战包括缺乏共识、缺乏明确的指导和困惑的领导力。 |
| [^10] | [Convergence Guarantees for Stochastic Subgradient Methods in Nonsmooth Nonconvex Optimization.](http://arxiv.org/abs/2307.10053) | 本文研究了非平滑非凸优化中随机次梯度方法的收敛性质，并提出了一种新的框架，证明了其在单时间尺度和双时间尺度情况下的全局收敛性，包括了多种已知的SGD类型方法。对于有限和形式的目标函数，证明了这些方法能够在随机选择的步长和初始点上找到Clarke稳定点。 |
| [^11] | [Automatic Conversion of MiniZinc Programs to QUBO.](http://arxiv.org/abs/2307.10032) | 该论文介绍了一个自动将MiniZinc程序转换为QUBO的工具，能够高效地处理约束优化和约束满足问题，大大简化了从优化问题到QUBO模型的过程。 |
| [^12] | [An Empirical Study on Fertility Proposals Using Multi-Grined Topic Analysis Methods.](http://arxiv.org/abs/2307.10025) | 本研究通过采用多粒度主题分析方法，对微博评论进行语义分析，发现关于取消婚姻登记的生育限制的提案涉及个人、社会和国家三个维度，详细讨论了个人行为、社会伦理和法律以及国家政策等社会问题。 |
| [^13] | [Rob\^oCIn Small Size League Extended Team Description Paper for RoboCup 2023.](http://arxiv.org/abs/2307.10018) | Rob\^oCIn团队是RoboCup小规模联赛的强队，本论文介绍了他们为保卫B组冠军所做的改进工作，包括新架构实施、软件和人工智能重构以及机械系统整合等。他们还分享了团队在相关会议上发表的两篇文章以及他们为比赛做的准备工作。 |
| [^14] | [6G Network Business Support System.](http://arxiv.org/abs/2307.10004) | 6G网络业务支持系统是下一代智能和集成的数字信息基础设施，将引领经济和社会的数字化、智能化和绿色转型，并通过加强集成，提高客户的运营效率和效益。 |
| [^15] | [TbExplain: A Text-based Explanation Method for Scene Classification Models with the Statistical Prediction Correction.](http://arxiv.org/abs/2307.10003) | 本文提出了一种名为TbExplain的框架，它利用XAI技术和预训练的对象检测器，通过文本形式解释场景分类模型，并引入了一种新的方法来纠正预测和进行文本解释。 |
| [^16] | [Our Model Achieves Excellent Performance on MovieLens: What Does it Mean?.](http://arxiv.org/abs/2307.09985) | 该论文通过对MovieLens数据集的分析，发现用户与该平台的交互在不同阶段存在显著差异，并且用户交互受到平台推荐算法推荐的候选电影的影响。 |
| [^17] | [XSkill: Cross Embodiment Skill Discovery.](http://arxiv.org/abs/2307.09955) | 本研究提出了XSkill，一种跨体现的技能发现框架，能够从无标签的人类和机器人操纵视频中纯粹地发现跨体现技能原型，并通过条件扩散策略将这些技能转移到机器人动作中，在未见任务中完成学习到的技能的组合。仿真和真实环境中的实验结果表明，这些发现的技能原型能够有效地促进技能转移和组合，从而构建出更通用和可扩展的模仿学习框架。 |
| [^18] | [U-CE: Uncertainty-aware Cross-Entropy for Semantic Segmentation.](http://arxiv.org/abs/2307.09947) | 本文提出了一种新的不确定性感知型交叉熵损失函数（U-CE），通过像素级加权将动态预测不确定性纳入训练过程中的著名交叉熵损失函数，通过实验证明了U-CE对于语义分割在性能和提供有意义的不确定性方面的改进。 |
| [^19] | [TREEMENT: Interpretable Patient-Trial Matching via Personalized Dynamic Tree-Based Memory Network.](http://arxiv.org/abs/2307.09942) | TREEMENT是一种采用个性化动态树状记忆网络的可解释患者-试验匹配模型，利用层次化临床本体知识和合格标准嵌入学习，提供准确而有解释性的患者-试验匹配。 |
| [^20] | [Spuriosity Didn't Kill the Classifier: Using Invariant Predictions to Harness Spurious Features.](http://arxiv.org/abs/2307.09933) | 本研究通过理论证明和算法提出，展示了在没有标签的情况下如何利用不稳定特征来提高分类器的性能。 |
| [^21] | [Exploring Non-Regular Extensions of Propositional Dynamic Logic with Description-Logics Features.](http://arxiv.org/abs/2307.09913) | 研究了非正则路径表达式对于扩展ALC描述逻辑中可满足性检查和查询的可决定性的影响，并提供了一系列不可决定性结果。 |
| [^22] | [Chit-Chat or Deep Talk: Prompt Engineering for Process Mining.](http://arxiv.org/abs/2307.09909) | 这项研究通过应用大型语言模型(LLM)来增强对话代理在过程挖掘中的应用，改善了现有解决方案中的问题，并提出了未来的研究建议。 |
| [^23] | [Implicit Identity Representation Conditioned Memory Compensation Network for Talking Head video Generation.](http://arxiv.org/abs/2307.09906) | 提出了一种隐式身份表示条件化记忆补偿网络，用于高保真度的自然头部视频生成。 |
| [^24] | [PyTAG: Challenges and Opportunities for Reinforcement Learning in Tabletop Games.](http://arxiv.org/abs/2307.09905) | PyTAG是一个用于在桌面游戏中进行强化学习研究的Python API。它提供了与Tabletop Games framework (TAG)进行交互的功能，并介绍了在现代桌面游戏中训练强化学习代理的技术和基准结果。 |
| [^25] | [An analysis on the effects of speaker embedding choice in non auto-regressive TTS.](http://arxiv.org/abs/2307.09898) | 本文分析了非自回归TTS中选择不同说话者嵌入的效果。研究发现，无论使用何种嵌入集和学习策略，网络都可以同样良好地处理各种说话者身份，并且训练过程中存在不可避免的说话者泄漏。 |
| [^26] | [Amortised Design Optimization for Item Response Theory.](http://arxiv.org/abs/2307.09891) | 本文在物品反应理论中提出了摊销实验设计方法，利用深度强化学习代理在预处理阶段选择对于学生分布最具信息价值的测试项目，并在部署过程中进行摊销推断。 |
| [^27] | [A reinforcement learning approach for VQA validation: an application to diabetic macular edema grading.](http://arxiv.org/abs/2307.09886) | 本论文提出了一种基于强化学习的方法，用于验证VQA算法在医学图像分析中的应用，旨在提供更丰富和更适当的验证方法，以揭示算法的推理行为。 |
| [^28] | [Test-takers have a say: understanding the implications of the use of AI in language tests.](http://arxiv.org/abs/2307.09885) | 深入了解在语言测试中使用人工智能的影响和担忧，有助于利益相关者做出明智决策，确保社区福祉和测试完整性。 |
| [^29] | [Adversarial Likelihood Estimation with One-way Flows.](http://arxiv.org/abs/2307.09882) | 本文提出了一种通过单向流进行对抗性似然估计的方法，并使用重要性采样解决了Wasserstein GAN中分区函数有偏估计的问题。同时，通过最大化生成器的熵，提高了模式覆盖效果。这种方法通过计算生成样本的密度来实现对分区函数的无偏估计和生成器熵的计算。 |
| [^30] | [Amortised Experimental Design and Parameter Estimation for User Models of Pointing.](http://arxiv.org/abs/2307.09878) | 本研究研究了一种通过训练策略选择实验设计，用模拟数据代替大量人类数据来分摊实验设计成本的方法，在交互设计中估计用户模型的参数，并且在三个不同的指向模型上进行了演示。 |
| [^31] | [Detecting Vulnerable Nodes in Urban Infrastructure Interdependent Network.](http://arxiv.org/abs/2307.09866) | 该论文使用图神经网络和强化学习对城市基础设施相互依赖网络中的脆弱节点进行了准确建模和分析。 |
| [^32] | [Towards a population-informed approach to the definition of data-driven models for structural dynamics.](http://arxiv.org/abs/2307.09862) | 本论文提出了一种基于人群信息的方法，用于定义结构动力学的数据驱动模型，以解决数据稀缺问题。这种方法结合了物理基础方法和机器学习算法，通过从相似物理现象的人群中学习关系，构建可转移、可解释、值得信赖的模型。 |
| [^33] | [Towards Reliable Rare Category Analysis on Graphs via Individual Calibration.](http://arxiv.org/abs/2307.09858) | 该论文研究了稀有类别分析中的不正确校准问题，发现现有的方法在预测少数类别时过于自信且不够自信。 |
| [^34] | [A Fast and Map-Free Model for Trajectory Prediction in Traffics.](http://arxiv.org/abs/2307.09831) | 本文提出了一种高效的无地图轨迹预测模型，通过综合运用多种技术，学习到所有代理的动态和交互信息，达到了最高性能水平。 |
| [^35] | [Online Continual Learning for Robust Indoor Object Recognition.](http://arxiv.org/abs/2307.09827) | 本论文提出了RobOCLe方法，针对室内物体识别中的在线持续学习问题，通过构建丰富的特征空间和计算样本之间的相似性来提高模型的鲁棒性。 |
| [^36] | [Probabilistic Forecasting with Coherent Aggregation.](http://arxiv.org/abs/2307.09797) | 该论文提出了一种新的模型，利用因子模型结构来产生遵守层次结构的概率预测。模型利用卷积神经网络生成参数，并通过优化样本损失函数实现预测优化。 |
| [^37] | [ZeroQuant-FP: A Leap Forward in LLMs Post-Training W4A8 Quantization Using Floating-Point Formats.](http://arxiv.org/abs/2307.09782) | ZeroQuant-FP通过使用浮点格式进行LLMs训练后量化，解决了在大型语言模型中平衡计算效率和保持模型质量的挑战，并发现FP8激活优于INT8，并且FP4权重表现与INT4相当甚至更优。 |
| [^38] | [Text2Layer: Layered Image Generation using Latent Diffusion Model.](http://arxiv.org/abs/2307.09781) | 该论文提出了一种使用潜在扩散模型进行分层图像生成的方法，使得在生成高质量图像的同时，实现更好的合成工作流程和更高质量的图层遮罩生成。 |
| [^39] | [Beyond Single-Feature Importance with ICECREAM.](http://arxiv.org/abs/2307.09779) | 提出了一种名为ICECREAM的新方法，超越了单一特征重要性的统计方法。该方法利用信息论量化衡量了变量联合对目标变量分布的影响，能够确定一个特定结果所需的关键因素集合。 |
| [^40] | [Generating Redstone Style Cities in Minecraft.](http://arxiv.org/abs/2307.09777) | 本文提出了一个在Minecraft中生成城市的方法，并通过使用不同算法来生成建筑布局，实验结果表明基于启发式的算法对于平坦地图更快找到可接受的布局，而演化布局算法在其他情况下表现更好。 |
| [^41] | [Perturbing a Neural Network to Infer Effective Connectivity: Evidence from Synthetic EEG Data.](http://arxiv.org/abs/2307.09770) | 该研究提出了一种通过扰动神经网络推断脑内有效连接性的方法。研究使用数据驱动的框架，在经过训练的神经网络中，通过扰动输入信号来计算扰动之后对其他脑区的因果影响，从而揭示了脑区之间的非线性因果关系。测试结果在合成的脑电数据上表现出良好的性能。 |
| [^42] | [Sig-Splines: universal approximation and convex calibration of time series generative models.](http://arxiv.org/abs/2307.09767) | 该论文提出了一种新颖的时间序列生成模型，通过将线性变换和签名变换作为传统神经网络的替代，既实现了神经网络的通用性，又引入了模型参数的凸性。 |
| [^43] | [Towards Building More Robust Models with Frequency Bias.](http://arxiv.org/abs/2307.09763) | 该论文提出了一种频率偏好控制模块，通过自适应地重新配置中间特征表示的低频和高频成分，提高了模型在鲁棒性学习中对频率的利用。 |
| [^44] | [Reinforcing POD based model reduction techniques in reaction-diffusion complex networks using stochastic filtering and pattern recognition.](http://arxiv.org/abs/2307.09762) | 该论文提出了一种算法框架，通过将模式识别和随机滤波理论的技术结合起来，强化了基于POD的反应扩散复杂网络模型简化技术，在受扰动输入的情况下提高了代理模型的准确性。 |
| [^45] | [Space Engage: Collaborative Space Supervision for Contrastive-based Semi-Supervised Semantic Segmentation.](http://arxiv.org/abs/2307.09755) | 基于对比的半监督语义分割方法通常仅依赖于logit空间中的监督，而我们提出了一种协同空间监督方法，利用logit空间和表示空间的输出来提高模型性能和减少过拟合风险。 |
| [^46] | [Information Retrieval Meets Large Language Models: A Strategic Report from Chinese IR Community.](http://arxiv.org/abs/2307.09751) | 本论文总结了中国信息检索界关于信息检索与大型语言模型相结合的战略报告。大型语言模型在文本理解、生成和知识推理方面具有出色能力，为信息检索研究开辟了新的方向。此外，IR模型、LLM和人类之间的协同关系形成了一种更强大的信息寻求技术范式。然而，该领域仍面临计算成本、可信度、领域特定限制和伦理考虑等挑战。 |
| [^47] | [Enhancing conversational quality in language learning chatbots: An evaluation of GPT4 for ASR error correction.](http://arxiv.org/abs/2307.09744) | 本文研究了在语言学习聊天机器人中使用GPT4进行ASR错误纠正的方法，发现GPT4纠正的转录导致更高的对话质量，尽管WER有所增加。 |
| [^48] | [Multi-Grained Multimodal Interaction Network for Entity Linking.](http://arxiv.org/abs/2307.09721) | 这篇论文提出了一个名为MIMIC的多粒度多模态交互网络框架，用于解决多模态实体链接任务。该框架解决了多模态之间信息互补不充分和噪声数据导致的性能下降问题。 |
| [^49] | [Two Tales of Platoon Intelligence for Autonomous Mobility Control: Enabling Deep Learning Recipes.](http://arxiv.org/abs/2307.09711) | 本文介绍了基于深度学习的解决自主移动控制和资源管理问题的两个方法：多智能体强化学习和神经迈尔逊拍卖。其中，通信网络是最流行的多智能体强化学习算法之一，将多个智能体的状态和动作训练在一个单一的神经网络中。神经迈尔逊拍卖保证了多个智能体之间的诚信度并实现了最优收益。整合多智能体强化学习和神经迈尔逊拍卖对于实现高效和可靠的自主移动服务至关重要。 |
| [^50] | [STRAPPER: Preference-based Reinforcement Learning via Self-training Augmentation and Peer Regularization.](http://arxiv.org/abs/2307.09692) | 本文提出了STRAPPER方法，通过自训练增强和同伴正则化实现基于偏好的强化学习。与其他方法不同的是，作者发现基于偏好的强化学习中存在相似性陷阱现象，即相似的片段对可能会存在截然相反的偏好，对一致性正则化造成影响。 |
| [^51] | [Amazon-M2: A Multilingual Multi-locale Shopping Session Dataset for Recommendation and Text Generation.](http://arxiv.org/abs/2307.09688) | Amazon-M2是一个多语言多区域购物会话数据集，可以增强个性化推荐和理解用户偏好能力。 |
| [^52] | [PubMed and Beyond: Recent Advances and Best Practices in Biomedical Literature Search.](http://arxiv.org/abs/2307.09683) | 本论文总结了生物医学文献检索领域的最新进展和最佳实践，介绍了针对不同生物医学信息需求的文献检索工具，并旨在帮助读者高效满足其信息需求。 |
| [^53] | [What's meant by explainable model: A Scoping Review.](http://arxiv.org/abs/2307.09673) | 这项研究通过范围审查方法调查了应用人工智能模型并采用事后解释方法的论文，探讨了可解释模型这一术语的含义。 |
| [^54] | [Towards A Unified Agent with Foundation Models.](http://arxiv.org/abs/2307.09668) | 本文研究如何在强化学习智能体中嵌入和利用语言模型和视觉语言模型的能力，设计了一个以语言为核心推理工具的框架，并在稀疏奖励的机器人操作环境中测试了该方法。结果显示，该方法在探索效率和数据复用方面具有显著性能提升，并展示了如何通过复用学到的技能解决新任务。 |
| [^55] | [Anticipating Technical Expertise and Capability Evolution in Research Communities using Dynamic Graph Transformers.](http://arxiv.org/abs/2307.09665) | 这项研究通过使用动态图转换器预测研究社区中的技术专长和能力演进，从而提高了全球安全和核不扩散等领域的预测能力。 |
| [^56] | [HAT-CL: A Hard-Attention-to-the-Task PyTorch Library for Continual Learning.](http://arxiv.org/abs/2307.09653) | HAT-CL是一个基于任务的硬注意力PyTorch库，以提供对连续学习中的灾难性遗忘现象的解决方案。它通过改善HAT的可用性和兼容性问题，并提供对现有网络复用的支持，实现了对PyTorch模块的自动化梯度操作和转换。此外，HAT-CL还引入了新颖的掩码操作技术。 |
| [^57] | [VISER: A Tractable Solution Concept for Games with Information Asymmetry.](http://arxiv.org/abs/2307.09652) | 该论文提出了一种名为VISER的解决方案概念，用于处理信息不对称博弈。VISER使得外部观察者能够预测博弈的结果，并允许受害者更好地自卫以及确定攻击者可使用的最具破坏性的攻击方法。通过线性规划，每个玩家的VISER策略可以在多项式时间内计算。论文还将VISER扩展到马尔可夫博弈的马尔可夫完美对应规则，并提出了高效求解方法。 |
| [^58] | [With Flying Colors: Predicting Community Success in Large-scale Collaborative Campaigns.](http://arxiv.org/abs/2307.09650) | 本研究通过对Reddit的r/place在线社区进行分析，以预测在线社区在大规模协作活动中的成功水平，以及分析社区成员之间的底层动态对成功的影响。 |
| [^59] | [Promoting Exploration in Memory-Augmented Adam using Critical Momenta.](http://arxiv.org/abs/2307.09638) | 本研究提出了一种记忆增强型Adam方法，通过使用关键动量项的缓冲区来促进对更平坦最小值的探索。实验证明，该方法在标准的监督语言建模和图像分类任务中提高了几种Adam变体的性能。 |
| [^60] | [Traffic-Domain Video Question Answering with Automatic Captioning.](http://arxiv.org/abs/2307.09636) | 本文提出了一种带有自动字幕的交通领域视频问答(TRIVIA)方法，通过将交通领域知识注入到视频语言模型中，实现了显著的准确率提升，对推动该领域的进步具有重要意义。 |
| [^61] | [Looking deeper into interpretable deep learning in neuroimaging: a comprehensive survey.](http://arxiv.org/abs/2307.09615) | 本文对可解释的深度学习在神经影像学中的应用进行了全面调查，深度学习模型的易解释性仍然存在挑战，近年来的研究主要集中在如何理解模型决策的直觉，还需探索如何验证解释性方法的可靠性。 |
| [^62] | [Sequential Monte Carlo Learning for Time Series Structure Discovery.](http://arxiv.org/abs/2307.09607) | 本文提出了一种顺序蒙特卡洛学习的方法，用于自动发现复杂时间序列数据的准确模型。在实验中显示，该方法相对于之前的方法，具有较快的运行速度并能够发现合理的模型结构。 |
| [^63] | [A max-affine spline approximation of neural networks using the Legendre transform of a convex-concave representation.](http://arxiv.org/abs/2307.09602) | 这项工作提出了一种将神经网络转化为样条表示的新算法，它不再需要凸多边形和分段线性网络操作符的限制，并且可以在整个网络上执行。这项工作不仅填补了神经网络和逼近理论之间的差距，还使得网络特征图的可视化成为可能。 |
| [^64] | [Gradient strikes back: How filtering out high frequencies improves explanations.](http://arxiv.org/abs/2307.09591) | 本研究发现，基于预测的属性方法与基于梯度的方法产生的属性图具有不同的高频内容，滤除高频率可以提高解释性。 |
| [^65] | [Automating Wood Species Detection and Classification in Microscopic Images of Fibrous Materials with Deep Learning.](http://arxiv.org/abs/2307.09588) | 本研究通过深度学习实现了对纤维材料显微图像中硬木种类的自动检测和分类。该方法在性能上与人类专家类似，未来将有助于保护森林资源。 |
| [^66] | [Understanding Multi-Turn Toxic Behaviors in Open-Domain Chatbots.](http://arxiv.org/abs/2307.09579) | 本研究针对开放域聊天机器人中的多轮有害行为问题进行了研究，发现现有工具无法检测出82%导致有害行为的单句都被认为是安全的。通过设计新的攻击方法\toxicbot，我们发现开放域聊天机器人模型可以在多轮对话中触发生成有害回应。 |
| [^67] | [Reinforcement Learning for Syntax-Guided Synthesis.](http://arxiv.org/abs/2307.09564) | 本论文提出了一种基于树搜索和强化学习的语法引导综合算法，解决了搜索问题复杂性和数据集较小的挑战。 |
| [^68] | [Enhancing Evacuation Planning through Multi-Agent Simulation and Artificial Intelligence: Understanding Human Behavior in Hazardous Environments.](http://arxiv.org/abs/2307.09485) | 本文通过使用多智能体模拟和人工智能技术，构建了一个能够捕捉危险环境中个体行为的疏散模型，旨在提高我们对疏散过程的理解并为决策者提供更有效的疏散策略。 |
| [^69] | [Llama 2: Open Foundation and Fine-Tuned Chat Models.](http://arxiv.org/abs/2307.09288) | Llama 2是一个优化的聊天模型，通过fine-tuned技术和安全改进，表现优于开源模型，并可作为闭源模型的替代选择。 |
| [^70] | [M-FLAG: Medical Vision-Language Pre-training with Frozen Language Models and Latent Space Geometry Optimization.](http://arxiv.org/abs/2307.08347) | M-FLAG是一种新颖的医学视觉语言预训练方法，通过利用冻结语言模型和引入正交损失函数来优化潜空间几何关系。在医学影像分类、分割和目标检测任务上，M-FLAG在性能上显著优于现有方法，并且减少了78%的参数量。 |
| [^71] | [IntelliGraphs: Datasets for Benchmarking Knowledge Graph Generation.](http://arxiv.org/abs/2307.06698) | IntelliGraphs是一组新的知识图谱数据集，用于评估知识图谱生成。其中包含具有逻辑规则表达的语义的子图，用于评估子图推断的模型。 |
| [^72] | [Introducing Foundation Models as Surrogate Models: Advancing Towards More Practical Adversarial Attacks.](http://arxiv.org/abs/2307.06608) | 本文将对抗攻击重新设定为下游任务，通过生成图像噪声来满足新兴趋势，并将基础模型引入作为代理模型。虽然基础模型的表现不佳，但通过在特征空间中进行分析，我们发现缺乏对应的特征。 |
| [^73] | [Diagnosis, Feedback, Adaptation: A Human-in-the-Loop Framework for Test-Time Policy Adaptation.](http://arxiv.org/abs/2307.06333) | 提出了一种交互式框架，通过从用户那里直接获取反馈来识别个性化的无关紧要的概念，从而进行数据增强并获得适应个性化用户目标的政策。 |
| [^74] | [Distilling Large Vision-Language Model with Out-of-Distribution Generalizability.](http://arxiv.org/abs/2307.03135) | 本文研究了针对大型视觉语言模型的模型压缩方法，将教师模型的视觉表示压缩到学生模型中。研究重点在于超出分布可泛化的问题，并提出了两个原则来增强学生模型的性能。 |
| [^75] | [SwinGNN: Rethinking Permutation Invariance in Diffusion Models for Graph Generation.](http://arxiv.org/abs/2307.01646) | 本文提出了一种新的图生成扩散模型SwinGNN，通过使用高效的2-WL消息传递网络和移动窗口自注意力，以及结合关键的训练和采样技术，显著提高了图生成样本的质量，并引入了随机置换的后处理技巧转换生成的图形统计量。 |
| [^76] | [Theory of Mind as Intrinsic Motivation for Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2307.01158) | 本论文提出了一种方法来建立语义有意义、人类可解释的信念，并将其应用于多智能体强化学习中。研究发现，通过预测其他智能体的信念来作为内在奖励信号，可以在多智能体环境中产生良好的效果。 |
| [^77] | [From $O(\sqrt n)$ to $O(\log n)$ in Quadratic Programming.](http://arxiv.org/abs/2306.15079) | 这篇论文提出了一种迭代复杂度为$O(\log(n))$的二次规划优化算法，并通过严格的理论证明验证了该算法的可行性。这一重大突破使得我们从$O(\sqrt{n})$的优化算法过渡到$O(\log(n))$的优化算法，其在大数据和人工智能时代具有重要应用价值。 |
| [^78] | [Pre or Post-Softmax Scores in Gradient-based Attribution Methods, What is Best?.](http://arxiv.org/abs/2306.13197) | 在Gradient-based Attribution Methods中，使用Pre Softmax分数或Post Softmax分数的梯度的选择有各自的优缺点，需要根据具体情况进行权衡。 |
| [^79] | [Who Needs to Know? Minimal Knowledge for Optimal Coordination.](http://arxiv.org/abs/2306.09309) | 该论文研究了在合作游戏中最佳协调所需的最小知识。通过提出一个关于战略相关和不相关信息的二分法以及通过Bellman备份运算符的计算方法，作者证明了在动态游戏中可以有效地确定战略相关信息。在实验中，他们应用该算法分析了标准和部分可观察的Overcooked环境中任务的战略相关信息，并且证明了该算法相较于基线方法具有显著的效率提升。 |
| [^80] | [Mining Negative Temporal Contexts For False Positive Suppression In Real-Time Ultrasound Lesion Detection.](http://arxiv.org/abs/2305.18060) | 该论文提出了一种在超声视频中实时进行病变检测的方法，通过挖掘之前帧中的负面时间背景来抑制假阳性，取得了显著的性能改进。 |
| [^81] | [Off-Policy Average Reward Actor-Critic with Deterministic Policy Search.](http://arxiv.org/abs/2305.12239) | 本文介绍了带有确定性策略搜索的离策略平均回报行动者-评论家算法，并提出了基于策略和离策略的确定性策略梯度定理。使用这些定理，本文还提出了一种平均回报离策略深度确定性策略梯度算法（ARO-DDPG）。该算法在渐近收敛性分析和有限时间分析中展示了较好的性能，并获得了$\epsilon$-最优稳定策略。 |
| [^82] | [Capturing Emerging Complexity in Lenia.](http://arxiv.org/abs/2305.09378) | 研究人工生命平台Lenia，通过识别复杂新兴行为的度量标准和使用遗传算法产生不同行为的结果，以进化出更好的Lenia行为。 |
| [^83] | [Outline, Then Details: Syntactically Guided Coarse-To-Fine Code Generation.](http://arxiv.org/abs/2305.00909) | 提出一种基于语法引导的粗-细代码生成模型，支持从粗到细的多次迭代，实现了更加符合人脑思维方式的代码编写方式。 |
| [^84] | [A Preliminary Evaluation of ChatGPT in Requirements Information Retrieval.](http://arxiv.org/abs/2304.12562) | ChatGPT具备在需求信息检索任务中执行的能力，并且在零-shot设置下获得了可比较或更好的结果。 |
| [^85] | [RoCOCO: Robust Benchmark MS-COCO to Stress-test Robustness of Image-Text Matching Models.](http://arxiv.org/abs/2304.10727) | 本文提出了一个新的评估基准来测试ITM模型的鲁棒性，通过将一些“愚弄”的图片和标题添加到检索池中，在MS COCO数据集上为各种最先进的模型进行鲁棒性测试，揭示了它们的不足之处。 |
| [^86] | [Leveraging triplet loss for unsupervised action segmentation.](http://arxiv.org/abs/2304.06403) | 本文提出了一种无监督的框架，可以在不需要任何训练数据的情况下，从单个输入视频中学习适用于动作分割任务的动作表示，并使用三元组选择策略和三元组损失来在新的表示空间中发现动作，相对于现有无监督方法实现了更好的时间边界恢复质量。 |
| [^87] | [MagicFusion: Boosting Text-to-Image Generation Performance by Fusing Diffusion Models.](http://arxiv.org/abs/2303.13126) | 本论文提出了一种名为SNB的方法，该方法集成了两个文本指导扩散模型的噪声预测，以实现更可控的图像生成，同时不需要额外的训练或注释。 |
| [^88] | [Sionna RT: Differentiable Ray Tracing for Radio Propagation Modeling.](http://arxiv.org/abs/2303.11103) | Sionna RT是一个GPU加速的开源库，它集成了可微分的光线追踪器，可以用于模拟无线电波传播。这个功能使得可以计算与多个系统和环境参数有关的量的梯度，对于诸如学习无线电材料和优化发射机方向等应用具有重要价值。同时，可微分光线追踪对于新颖的研究方向如数字孪生也是一个关键的推动者。 |
| [^89] | [Schema Inference for Interpretable Image Classification.](http://arxiv.org/abs/2303.06635) | 本论文提出了一种名为模式推理的新型推理范式，利用先前的深度神经网络(DNN)前向方案学习演绎地推断可解释的预测。通过图匹配策略将图像的视觉概念与场景印象相关联，并设计了一种专用架构称为SchemaNet，以建模输入实例的视觉语义和目标类别的学习抽象想象。还引入了一个通用的Feat2Graph方案以捕捉和利用视觉语义的组合贡献。 |
| [^90] | [CO-BED: Information-Theoretic Contextual Optimization via Bayesian Experimental Design.](http://arxiv.org/abs/2302.14015) | CO-BED是一个通用的、与模型无关的框架，用于通过贝叶斯实验设计的信息理论来进行上下文优化。它采用黑箱变分方法同时估计和优化设计，可以适应离散动作，并在多个实验中展示出竞争性能。 |
| [^91] | [The Meta-Evaluation Problem in Explainable AI: Identifying Reliable Estimators with MetaQuantus.](http://arxiv.org/abs/2302.07265) | 这项研究解决了可解释人工智能领域中关于在缺乏真实解释标签的情况下如何可靠估算解释方法质量的问题。通过对不同质量估计器进行元评估，利用MetaQuantus框架分析了估计器的韧性和反应特征，从而帮助实践者选择最佳的解释方法。 |
| [^92] | [CIPER: Combining Invariant and Equivariant Representations Using Contrastive and Predictive Learning.](http://arxiv.org/abs/2302.02330) | CIPER是一个自监督表示学习方法，通过结合不变和等变学习目标来提高性能，适用于具有特定数据增强要求的计算机视觉任务 |
| [^93] | [Hierarchically Composing Level Generators for the Creation of Complex Structures.](http://arxiv.org/abs/2302.01561) | 提出了一种层级组合生成器的方法，通过递归组合简单的低级生成器来构建大型和复杂的创作，从而优化目标并设计复杂结构。 |
| [^94] | [ThoughtSource: A central hub for large language model reasoning data.](http://arxiv.org/abs/2301.11596) | ThoughtSource是一个用于连续思考推理的元数据集和软件库，旨在通过促进对连续思考的定性理解、实证评估和提供训练数据，改进未来的人工智能系统。 |
| [^95] | [Lego-MT: Towards Detachable Models in Massively Multilingual Machine Translation.](http://arxiv.org/abs/2212.10551) | 本文提出了一种可拆卸的多语言机器翻译模型，Lego-MT，以解决现有多语言单体模型在参数干扰和低效推导方面的挑战。进行实验评估表明，该模型具有较高的性能，相比具有10倍规模的模型，在效率和表现方面都更具优势。 |
| [^96] | [API-Miner: an API-to-API Specification Recommendation Engine.](http://arxiv.org/abs/2212.07253) | API-Miner是一种API到API规范推荐引擎，具有从OpenAPI规范中提取关键信息的新方法、优化的特征提取技术以及结合多种信号的对数线性概率模型等重要贡献。 |
| [^97] | [Can In-context Learners Learn a Reasoning Concept from Demonstrations?.](http://arxiv.org/abs/2212.01692) | 本文介绍了一种概念性少样本学习方法，以帮助在场学习者学习新技能。通过选择与预测示例共享可能信息的演示，这个方法可以在模型记忆独立的情况下区分模型的在场学习能力。 |
| [^98] | [SurCo: Learning Linear Surrogates For Combinatorial Nonlinear Optimization Problems.](http://arxiv.org/abs/2210.12547) | 该论文介绍了一种名为SurCo的方法，通过学习线性代理成本，将组合非线性优化问题转化为线性问题，并通过结合梯度方法和线性组合优化的结构提供了高效解决方案。 |
| [^99] | [The Value of Out-of-Distribution Data.](http://arxiv.org/abs/2208.10967) | 不同分布的数据可以对任务的泛化误差产生非单调的影响，使用少量不同分布的数据进行训练是有价值的。 |
| [^100] | [Data Augmentation is a Hyperparameter: Cherry-picked Self-Supervision for Unsupervised Anomaly Detection is Creating the Illusion of Success.](http://arxiv.org/abs/2208.07734) | 这项研究通过广泛的实验，证明数据增强与异常生成机制之间的对齐是自监督学习在无监督异常检测中取得成功的关键，并且在缺乏对齐时，自监督学习甚至可能降低准确性。 |
| [^101] | [Planning with Dynamically Estimated Action Costs.](http://arxiv.org/abs/2206.04166) | 本文介绍了一种使用动态估计的行动成本进行规划的方法，通过选择多个估计器来平衡计算时间和有界估计不确定性，提高了规划的可靠性和可扩展性。 |
| [^102] | [Meta-Learning Parameterized Skills.](http://arxiv.org/abs/2206.03597) | 提出了一种元学习参数化技能的算法，通过学习可转移的参数化技能并将其综合到新的动作空间中，实现了长期任务的高效学习。实证研究表明，该算法能够使智能体在难以解决的长期任务中取得成功。 |
| [^103] | [Planning to Fairly Allocate: Probabilistic Fairness in the Restless Bandit Setting.](http://arxiv.org/abs/2106.07677) | 本研究引入了一种概率公平策略ProbFair，如何在不确定性贪婪赌博问题中进行资源分配，并在满足预算约束的同时最大化总期望奖励。实验证明ProbFair在保持效用的同时提供公平性保证。 |
| [^104] | [Declarative Mechanism Design.](http://arxiv.org/abs/1912.13122) | 本文介绍了声明性机制设计的研究，提出了机构神经网络作为一种受管制的人工神经网络，引起人们对人工教学的关注，并提供了初步的答案。 |

# 详细

[^1]: DialogStudio：面向会话 AI 的最丰富和最多样化的统一数据集集合

    DialogStudio: Towards Richest and Most Diverse Unified Dataset Collection for Conversational AI. (arXiv:2307.10172v1 [cs.CL])

    [http://arxiv.org/abs/2307.10172](http://arxiv.org/abs/2307.10172)

    DialogStudio是迄今为止最大且最多样化的对话数据集合，包含从开放领域对话到任务导向对话、自然语言理解、会话推荐、对话摘要和知识驱动对话的数据。它为对话研究和模型训练提供了丰富而多样化的资源。

    

    尽管会话 AI 取得了进展，但语言模型在处理多样化的对话任务时面临挑战，现有的对话数据集往往缺乏多样性和全面性。为解决这些问题，我们介绍了 DialogStudio：最大、最多样化的对话数据集集合，以一致的格式统一，同时保留其原始信息。我们的集合包括来自开放领域对话、任务导向对话、自然语言理解、会话推荐、对话摘要和知识驱动对话的数据，为对话研究和模型训练提供了非常丰富和多样化的资源。为了进一步增强 DialogStudio 的实用性，我们为每个数据集确定了许可证，并为选定对话设计了领域感知提示，以便促进指导感知微调。此外，我们使用数据集集合开发了会话 AI 模型，并在零摘要生成和分布式文字基准对话任务上进行了实验。

    Despite advancements in conversational AI, language models encounter challenges to handle diverse conversational tasks, and existing dialogue dataset collections often lack diversity and comprehensiveness. To tackle these issues, we introduce DialogStudio: the largest and most diverse collection of dialogue datasets, unified under a consistent format while preserving their original information. Our collection encompasses data from open-domain dialogues, task-oriented dialogues, natural language understanding, conversational recommendation, dialogue summarization, and knowledge-grounded dialogues, making it an incredibly rich and diverse resource for dialogue research and model training. To further enhance the utility of DialogStudio, we identify the licenses for each dataset and design domain-aware prompts for selected dialogues to facilitate instruction-aware fine-tuning. Furthermore, we develop conversational AI models using the dataset collection, and our experiments in both zero-sh
    
[^2]: LightPath: 轻量级和可伸缩的路径表示学习

    LightPath: Lightweight and Scalable Path Representation Learning. (arXiv:2307.10171v1 [cs.LG])

    [http://arxiv.org/abs/2307.10171](http://arxiv.org/abs/2307.10171)

    LightPath是一个轻量级和可伸缩的路径表示学习框架，旨在实现在资源受限的环境下降低资源消耗和实现可伸缩性，同时保持高准确性，从而实现更广泛的适用性。

    

    移动路径广泛应用于智能交通和智能城市应用中。为了服务这些应用，路径表示学习旨在提供路径的紧凑表示，以在不同的下游任务（如路径排序和旅行成本估计）中实现高效准确的操作。在资源受限的环境下和绿色计算限制下，路径表示学习的轻量级和可伸缩性非常重要。然而，现有的路径表示学习研究主要关注准确性，对资源消耗和可伸缩性次要关注。我们提出了一个轻量级和可伸缩的路径表示学习框架，命名为LightPath，旨在降低资源消耗，实现可伸缩性，同时不影响准确性，从而实现更广泛的适用性。

    Movement paths are used widely in intelligent transportation and smart city applications. To serve such applications, path representation learning aims to provide compact representations of paths that enable efficient and accurate operations when used for different downstream tasks such as path ranking and travel cost estimation. In many cases, it is attractive that the path representation learning is lightweight and scalable; in resource-limited environments and under green computing limitations, it is essential. Yet, existing path representation learning studies focus on accuracy and pay at most secondary attention to resource consumption and scalability.  We propose a lightweight and scalable path representation learning framework, termed LightPath, that aims to reduce resource consumption and achieve scalability without affecting accuracy, thus enabling broader applicability. More specifically, we first propose a sparse auto-encoder that ensures that the framework achieves good sca
    
[^3]: 大型语言模型的挑战与应用

    Challenges and Applications of Large Language Models. (arXiv:2307.10169v1 [cs.CL])

    [http://arxiv.org/abs/2307.10169](http://arxiv.org/abs/2307.10169)

    本文旨在总结大型语言模型领域的挑战和应用成功案例，帮助机器学习研究人员快速了解该领域的当前状态并提高效率。

    

    大型语言模型在机器学习领域的讨论中从不存在到无处不在只用了几年的时间。由于领域的快速发展，很难确定剩余的挑战和已经取得的应用成功。本文旨在建立一个系统的一组未解决问题和应用成功案例，以便机器学习研究人员能够更快地了解该领域的当前状态并提高效率。

    Large Language Models (LLMs) went from non-existent to ubiquitous in the machine learning discourse within a few years. Due to the fast pace of the field, it is difficult to identify the remaining challenges and already fruitful application areas. In this paper, we aim to establish a systematic set of open problems and application successes so that ML researchers can comprehend the field's current state more quickly and become productive.
    
[^4]: 通过引导元元强化学习实现鲁棒的驾驶策略学习

    Robust Driving Policy Learning with Guided Meta Reinforcement Learning. (arXiv:2307.10160v1 [cs.RO])

    [http://arxiv.org/abs/2307.10160](http://arxiv.org/abs/2307.10160)

    本文提出了一种通过引导元元策略学习方法来实现社交车辆多样驾驶策略的有效方法，并使用训练策略增强自主驾驶策略的鲁棒性。

    

    尽管深度强化学习(DRL)在交互式交通场景中的自主导航方面取得了可喜的成果，但现有研究通常采用固定的行为策略来控制训练环境中的社交车辆。这可能导致学习到的驾驶策略过拟合环境，使其难以与具有不同、未见过行为的车辆良好交互。在这项工作中，我们引入了一种有效的方法，将多样的驾驶策略作为一个单一的元元策略进行训练。通过随机化社交车辆的基于交互的奖励函数，我们可以生成多样化的目标，并通过实现特定目标的引导策略有效地训练元元策略。我们进一步提出了一种训练策略，使用社交车辆由学习到的元元策略控制的环境，来增强自主车辆的驾驶策略的鲁棒性。我们的方法成功地学习了一种能够很好地适应未见过的情况的自主驾驶策略。

    Although deep reinforcement learning (DRL) has shown promising results for autonomous navigation in interactive traffic scenarios, existing work typically adopts a fixed behavior policy to control social vehicles in the training environment. This may cause the learned driving policy to overfit the environment, making it difficult to interact well with vehicles with different, unseen behaviors. In this work, we introduce an efficient method to train diverse driving policies for social vehicles as a single meta-policy. By randomizing the interaction-based reward functions of social vehicles, we can generate diverse objectives and efficiently train the meta-policy through guiding policies that achieve specific objectives. We further propose a training strategy to enhance the robustness of the ego vehicle's driving policy using the environment where social vehicles are controlled by the learned meta-policy. Our method successfully learns an ego driving policy that generalizes well to unsee
    
[^5]: 对于学习人形机械行走的潜在基于奖励的基准测试

    Benchmarking Potential Based Rewards for Learning Humanoid Locomotion. (arXiv:2307.10142v1 [cs.RO])

    [http://arxiv.org/abs/2307.10142](http://arxiv.org/abs/2307.10142)

    本文对人形机器人使用标准形式的奖励塑造和潜在基于奖励的塑造进行了基准测试。在高维系统中，潜在基于奖励的塑造（PBRS）对于收敛速度的提升效果较小。

    

    在开发有效的强化学习(RL)流程中，主要挑战往往是设计和调整奖励函数。良好设计的塑形奖励可以加快学习速度。然而，简单地制定奖励可能与期望的行为相冲突，如果没有适当调整，可能导致过度拟合甚至不稳定的性能。从理论上讲，潜在基于奖励的塑形(PBRS)可以在不影响最优策略的情况下指导学习过程。尽管有几项研究探索了使用潜在基于奖励的塑形来加快学习收敛的方法，但大多数研究局限于网格世界和低维系统，而在机器人强化学习中，主要依赖于标准形式的奖励塑造。在本文中，我们对使用PBRS的标准形式和塑形进行了人形机器人的基准测试。我们发现，在这个高维系统中，PBRS的收敛速度只有微小的好处。然而，PBRS奖励项具有重大的意义。

    The main challenge in developing effective reinforcement learning (RL) pipelines is often the design and tuning the reward functions. Well-designed shaping reward can lead to significantly faster learning. Naively formulated rewards, however, can conflict with the desired behavior and result in overfitting or even erratic performance if not properly tuned. In theory, the broad class of potential based reward shaping (PBRS) can help guide the learning process without affecting the optimal policy. Although several studies have explored the use of potential based reward shaping to accelerate learning convergence, most have been limited to grid-worlds and low-dimensional systems, and RL in robotics has predominantly relied on standard forms of reward shaping. In this paper, we benchmark standard forms of shaping with PBRS for a humanoid robot. We find that in this high-dimensional system, PBRS has only marginal benefits in convergence speed. However, the PBRS reward terms are significantly
    
[^6]: 扩展图神经网络的图评估指标

    Extended Graph Assessment Metrics for Graph Neural Networks. (arXiv:2307.10112v1 [cs.SI])

    [http://arxiv.org/abs/2307.10112](http://arxiv.org/abs/2307.10112)

    本论文提出了扩展的图评估指标（GAMs），适用于回归任务和连续邻接矩阵。主要关注的两个GAMs是同质性和跨类邻域相似度（CCNS）。这些扩展的指标能够在图神经网络中评估图结构，提高模型性能。

    

    当将患者队列重组为所谓的人口图时，最初独立的数据点可以合并成一个相互连接的图结构。利用图神经网络（GNNs），可以使用这种人口图进行医学的下游任务。适合的图结构的构建是学习过程中的一个具有挑战性的步骤，它对模型的性能有着重要的影响。为此，已经引入了不同的图评估指标来评估图结构。然而，这些指标仅适用于分类任务和离散的邻接矩阵，只覆盖了一小部分实际应用。在这项工作中，我们引入了针对回归任务和连续邻接矩阵的扩展图评估指标（GAMs）。我们重点关注两个具体的GAMs：同质性和跨类邻域相似度（CCNS）。我们将GAMs的概念扩展到多个跳跃，并为回归任务定义了同质性。

    When re-structuring patient cohorts into so-called population graphs, initially independent data points can be incorporated into one interconnected graph structure. This population graph can then be used for medical downstream tasks using graph neural networks (GNNs). The construction of a suitable graph structure is a challenging step in the learning pipeline that can have severe impact on model performance. To this end, different graph assessment metrics have been introduced to evaluate graph structures. However, these metrics are limited to classification tasks and discrete adjacency matrices, only covering a small subset of real-world applications. In this work, we introduce extended graph assessment metrics (GAMs) for regression tasks and continuous adjacency matrices. We focus on two GAMs in specific: \textit{homophily} and \textit{cross-class neighbourhood similarity} (CCNS). We extend the notion of GAMs to more than one hop, define homophily for regression tasks, as well as con
    
[^7]: 一个用于道路段推荐维护的决策框架

    A decision making framework for recommended maintenance of road segments. (arXiv:2307.10085v1 [cs.AI])

    [http://arxiv.org/abs/2307.10085](http://arxiv.org/abs/2307.10085)

    这项研究提出了一个决策框架，通过整合多种人工智能决策技术和历史数据，为道路管理部门提供科学决策工具和证据，以解决道路维护的问题。

    

    随着全球道路交通的快速发展，各国已完成了道路网络的建设。然而，随之而来的挑战在于现有道路的维护。众所周知，各国在道路维护项目上的预算有限，道路管理部门在进行科学决策方面面临困难。因此，将各种人工智能决策技术与历史维护数据相结合，以适应道路维护科学决策的背景，成为一个迫切的问题。这种整合旨在为道路管理部门提供更科学的工具和证据，以进行决策。本文提出的框架主要解决以下四个问题：1）预测各路线的路面性能，2）确定维护路线的优先级，3）基于评估标准制定维护决策。

    With the rapid development of global road transportation, countries worldwide have completed the construction of road networks. However, the ensuing challenge lies in the maintenance of existing roads. It is well-known that countries allocate limited budgets to road maintenance projects, and road management departments face difficulties in making scientifically informed maintenance decisions. Therefore, integrating various artificial intelligence decision-making techniques to thoroughly explore historical maintenance data and adapt them to the context of road maintenance scientific decision-making has become an urgent issue. This integration aims to provide road management departments with more scientific tools and evidence for decision-making. The framework proposed in this paper primarily addresses the following four issues: 1) predicting the pavement performance of various routes, 2) determining the prioritization of maintenance routes, 3) making maintenance decisions based on the e
    
[^8]: 准确的深度学习子网格尺度模型用于大涡模拟

    Accurate deep learning sub-grid scale models for large eddy simulations. (arXiv:2307.10060v1 [physics.flu-dyn])

    [http://arxiv.org/abs/2307.10060](http://arxiv.org/abs/2307.10060)

    本文提出了两个用于大涡模拟的子网格尺度模型，采用深度学习算法并与分析模型相比能够处理更复杂的非线性关系。其中一个模型融入了多个不变性，另一个只融入了伽利略不变性。

    

    我们提出了两个用于大涡模拟的子网格尺度（SGS）湍流模型系列。它们的开发需要制定经过物理验证的强大而高效的深度学习（DL）算法，与最先进的分析建模技术不同，这些算法可以产生输入和输出之间的高阶复杂非线性关系。通过从两个摩擦雷诺数约为395和590的典型通道流的直接模拟数据进行显式滤波，提供了用于训练和测试的准确数据。这两组模型使用不同的网络架构。其中一种架构使用张量基神经网络（TBNN），嵌入了简化的分析模型形式的一般有效粘性假设，从而融入了伽利略、旋转和反射不变性。而另一种架构是一个相对简单的网络，它只能融入伽利略不变性。

    We present two families of sub-grid scale (SGS) turbulence models developed for large-eddy simulation (LES) purposes. Their development required the formulation of physics-informed robust and efficient Deep Learning (DL) algorithms which, unlike state-of-the-art analytical modeling techniques can produce high-order complex non-linear relations between inputs and outputs. Explicit filtering of data from direct simulations of the canonical channel flow at two friction Reynolds numbers $Re_\tau\approx 395$ and 590 provided accurate data for training and testing. The two sets of models use different network architectures. One of the architectures uses tensor basis neural networks (TBNN) and embeds the simplified analytical model form of the general effective-viscosity hypothesis, thus incorporating the Galilean, rotational and reflectional invariances. The other architecture is that of a relatively simple network, that is able to incorporate the Galilean invariance only. However, this simp
    
[^9]: 在人工智能时代的伦理学：对人工智能从业者意识和挑战的分析

    Ethics in the Age of AI: An Analysis of AI Practitioners' Awareness and Challenges. (arXiv:2307.10057v1 [cs.CY])

    [http://arxiv.org/abs/2307.10057](http://arxiv.org/abs/2307.10057)

    这项研究调查了100名人工智能从业者对人工智能伦理的认识和纳入伦理方面所面临的挑战。结果显示，大多数人工智能从业者对人工智能伦理有一定的了解，主要归因于工作场所规则和政策，并且隐私保护和安全是他们熟悉的伦理原则。教育和培训被认为在帮助人工智能从业者纳入伦理方面有所帮助。挑战包括缺乏共识、缺乏明确的指导和困惑的领导力。

    

    在最近几年，人工智能伦理已成为公众和专家讨论的热议话题。但是，那些构建人工智能的人 - 人工智能从业者对他们对人工智能伦理的理解以及将其纳入他们开发的基于人工智能系统中的挑战有何说法呢？了解人工智能从业者对人工智能伦理的看法很重要，因为他们是最接近人工智能系统并能够带来变革和改进的人。我们进行了一项调查，旨在了解人工智能从业者对人工智能伦理的认识和纳入伦理方面所面临的挑战。根据100名人工智能从业者的回答，我们的调查结果表明，大多数人工智能从业者对人工智能伦理有一定的了解，这主要归因于工作场所的规则和政策。隐私保护和安全是他们中大多数人熟悉的伦理原则。正规教育/培训在帮助人工智能从业者纳入人工智能伦理方面被认为是有所帮助的。挑战方面，他们认为缺乏共识、缺乏明确的指导和困惑的领导力是最主要的问题。

    Ethics in AI has become a debated topic of public and expert discourse in recent years. But what do people who build AI - AI practitioners - have to say about their understanding of AI ethics and the challenges associated with incorporating it in the AI-based systems they develop? Understanding AI practitioners' views on AI ethics is important as they are the ones closest to the AI systems and can bring about changes and improvements. We conducted a survey aimed at understanding AI practitioners' awareness of AI ethics and their challenges in incorporating ethics. Based on 100 AI practitioners' responses, our findings indicate that majority of AI practitioners had a reasonable familiarity with the concept of AI ethics, primarily due to workplace rules and policies. Privacy protection and security was the ethical principle that majority of them were aware of. Formal education/training was considered somewhat helpful in preparing practitioners to incorporate AI ethics. The challenges tha
    
[^10]: 非平滑非凸优化中随机次梯度方法的收敛性保证

    Convergence Guarantees for Stochastic Subgradient Methods in Nonsmooth Nonconvex Optimization. (arXiv:2307.10053v1 [math.OC])

    [http://arxiv.org/abs/2307.10053](http://arxiv.org/abs/2307.10053)

    本文研究了非平滑非凸优化中随机次梯度方法的收敛性质，并提出了一种新的框架，证明了其在单时间尺度和双时间尺度情况下的全局收敛性，包括了多种已知的SGD类型方法。对于有限和形式的目标函数，证明了这些方法能够在随机选择的步长和初始点上找到Clarke稳定点。

    

    本文研究了随机梯度下降（SGD）方法及其变种在训练由非平滑激活函数构建的神经网络中的收敛性质。我们提出了一种新颖的框架，为更新动量项和变量的步长分配了不同的时间尺度。在一些温和的条件下，我们证明了我们提出的框架在单时间尺度和双时间尺度情况下的全局收敛性。我们还证明了我们提出的框架包含了很多已知的SGD类型方法，包括heavy-ball SGD、SignSGD、Lion、normalized SGD和clipped SGD。此外，当目标函数采用有限和形式时，我们基于我们提出的框架证明了这些SGD类型方法的收敛性质。特别地，在温和的假设下，我们证明了这些SGD类型方法在随机选择的步长和初始点上能够找到目标函数的Clarke稳定点。

    In this paper, we investigate the convergence properties of the stochastic gradient descent (SGD) method and its variants, especially in training neural networks built from nonsmooth activation functions. We develop a novel framework that assigns different timescales to stepsizes for updating the momentum terms and variables, respectively. Under mild conditions, we prove the global convergence of our proposed framework in both single-timescale and two-timescale cases. We show that our proposed framework encompasses a wide range of well-known SGD-type methods, including heavy-ball SGD, SignSGD, Lion, normalized SGD and clipped SGD. Furthermore, when the objective function adopts a finite-sum formulation, we prove the convergence properties for these SGD-type methods based on our proposed framework. In particular, we prove that these SGD-type methods find the Clarke stationary points of the objective function with randomly chosen stepsizes and initial points under mild assumptions. Preli
    
[^11]: MiniZinc程序自动转换为QUBO

    Automatic Conversion of MiniZinc Programs to QUBO. (arXiv:2307.10032v1 [cs.MS])

    [http://arxiv.org/abs/2307.10032](http://arxiv.org/abs/2307.10032)

    该论文介绍了一个自动将MiniZinc程序转换为QUBO的工具，能够高效地处理约束优化和约束满足问题，大大简化了从优化问题到QUBO模型的过程。

    

    获取用于各种优化问题的二次无约束二进制优化模型，以便在物理量子计算机（如DWave退火器）上解决这些问题，现如今是一个冗长而繁琐的过程，需要将所有问题变量重新建模为二进制变量，并将目标函数和约束压缩为一个二次多项式。我们在这里报告了我们从MiniZinc到QUBO的自动转换器的基础，该转换器能够处理大量的约束优化和约束满足问题，并将它们转换为等效的QUBOs，有效地优化整个过程。

    Obtaining Quadratic Unconstrained Binary Optimisation models for various optimisation problems, in order to solve those on physical quantum computers (such as the the DWave annealers) is nowadays a lengthy and tedious process that requires one to remodel all problem variables as binary variables and squeeze the target function and the constraints into a single quadratic polynomial into these new variables.  We report here on the basis of our automatic converter from MiniZinc to QUBO, which is able to process a large set of constraint optimisation and constraint satisfaction problems and turn them into equivalent QUBOs, effectively optimising the whole process.
    
[^12]: 通过使用多粒度主题分析方法的实证研究：生育政策提案

    An Empirical Study on Fertility Proposals Using Multi-Grined Topic Analysis Methods. (arXiv:2307.10025v1 [cs.HC])

    [http://arxiv.org/abs/2307.10025](http://arxiv.org/abs/2307.10025)

    本研究通过采用多粒度主题分析方法，对微博评论进行语义分析，发现关于取消婚姻登记的生育限制的提案涉及个人、社会和国家三个维度，详细讨论了个人行为、社会伦理和法律以及国家政策等社会问题。

    

    生育问题与人口安全密切相关，中国60年来首次出现人口负增长趋势，生育政策的变化引起了社会的极大关注。本文采用共现语义分析、主题分析和情感分析等方法，对微博评论进行多粒度的语义分析。发现关于“取消婚姻登记的生育限制”的提案讨论涉及个人、社会和国家三个维度，并详细探讨了个人行为、社会伦理和法律以及国家政策等社会问题。

    Fertility issues are closely related to population security, in 60 years China's population for the first time in a negative growth trend, the change of fertility policy is of great concern to the community. 2023 ``two sessions" proposal ``suggests that the country in the form of legislation, the birth of the registration of the cancellation of the marriage restriction" This topic was once a hot topic on the Internet, and ``unbundling" the relationship between birth registration and marriage has become the focus of social debate. In this paper, we adopt co-occurrence semantic analysis, topic analysis and sentiment analysis to conduct multi-granularity semantic analysis of microblog comments. It is found that the discussion on the proposal of ``removing marriage restrictions from birth registration" involves the individual, society and the state at three dimensions, and is detailed into social issues such as personal behaviour, social ethics and law, and national policy, with people's s
    
[^13]: Rob\^oCIn大规模联赛扩展团队论文描述——RoboCup 2023 （arXiv:2307.10018v1 [cs.RO]）

    Rob\^oCIn Small Size League Extended Team Description Paper for RoboCup 2023. (arXiv:2307.10018v1 [cs.RO])

    [http://arxiv.org/abs/2307.10018](http://arxiv.org/abs/2307.10018)

    Rob\^oCIn团队是RoboCup小规模联赛的强队，本论文介绍了他们为保卫B组冠军所做的改进工作，包括新架构实施、软件和人工智能重构以及机械系统整合等。他们还分享了团队在相关会议上发表的两篇文章以及他们为比赛做的准备工作。

    

    Rob\^oCIn自2019年起参加RoboCup小规模联赛，在2022年获得了首个世界冠军（B组），并连续三次成为拉丁美洲冠军。本论文介绍了我们为保卫RoboCup 2023小规模联赛（SSL）B组冠军所做的改进工作，比赛将在法国波尔多举行。本文旨在分享我们团队在过去一年中开展的一些学术研究。我们团队已成功在两个高影响力会议上发表了与SSL相关的两篇文章：第25届RoboCup国际研讨会和第19届IEEE拉丁美洲机器人研讨会（LARS 2022）。在过去一年中，我们一直在将过去的代码库迁移到Unification上。我们将描述新实施的架构以及软件和人工智能重构的一些要点。此外，我们还讨论了将机械组件整合到机械系统中的过程，以及去年参加视力遮挡挑战赛的开发情况以及我们正在为之准备的内容。

    Rob\^oCIn has participated in RoboCup Small Size League since 2019, won its first world title in 2022 (Division B), and is currently a three-times Latin-American champion. This paper presents our improvements to defend the Small Size League (SSL) division B title in RoboCup 2023 in Bordeaux, France. This paper aims to share some of the academic research that our team developed over the past year. Our team has successfully published 2 articles related to SSL at two high-impact conferences: the 25th RoboCup International Symposium and the 19th IEEE Latin American Robotics Symposium (LARS 2022). Over the last year, we have been continuously migrating from our past codebase to Unification. We will describe the new architecture implemented and some points of software and AI refactoring. In addition, we discuss the process of integrating machined components into the mechanical system, our development for participating in the vision blackout challenge last year and what we are preparing for t
    
[^14]: 6G网络业务支持系统

    6G Network Business Support System. (arXiv:2307.10004v1 [cs.AI])

    [http://arxiv.org/abs/2307.10004](http://arxiv.org/abs/2307.10004)

    6G网络业务支持系统是下一代智能和集成的数字信息基础设施，将引领经济和社会的数字化、智能化和绿色转型，并通过加强集成，提高客户的运营效率和效益。

    

    6G是下一代智能和集成的数字信息基础设施，具有普遍互联、本地智能、多维感知、全球覆盖、绿色低碳、本地网络安全等特点。6G将实现从为人和人物通信服务转向支持智能代理的高效连接，并全面引领经济和社会的数字化、智能化和绿色转型。作为移动通信网络的核心支持系统，6G BSS需要与下一代互联网和信息技术发展带来的新业务模式集成，从“网络为中心”升级为“以业务和服务为中心”和“以客户为中心”。6G OSS和BSS系统需要加强集成，通过连接供需两侧的数字智能支持能力，提高客户的运营效率和效益。

    6G is the next-generation intelligent and integrated digital information infrastructure, characterized by ubiquitous interconnection, native intelligence, multi-dimensional perception, global coverage, green and low-carbon, native network security, etc. 6G will realize the transition from serving people and people-things communication to supporting the efficient connection of intelligent agents, and comprehensively leading the digital, intelligent and green transformation of the economy and the society. As the core support system for mobile communication network, 6 6G BSS need to integrate with new business models brought about by the development of the next-generation Internet and IT, upgrade from "network-centric" to "business and service centric" and "customer-centric". 6G OSS and BSS systems need to strengthen their integration to improve the operational efficiency and benefits of customers by connecting the digital intelligence support capabilities on both sides of supply and dema
    
[^15]: TbExplain: 一种场景分类模型的基于文本的解释方法与统计预测校正

    TbExplain: A Text-based Explanation Method for Scene Classification Models with the Statistical Prediction Correction. (arXiv:2307.10003v1 [cs.CV])

    [http://arxiv.org/abs/2307.10003](http://arxiv.org/abs/2307.10003)

    本文提出了一种名为TbExplain的框架，它利用XAI技术和预训练的对象检测器，通过文本形式解释场景分类模型，并引入了一种新的方法来纠正预测和进行文本解释。

    

    可解释性人工智能(XAI)的领域旨在提高黑盒机器学习模型的可解释性。建立基于输入特征重要性值的热图是解释这些模型产生预测的基本方法之一。热图在人类中几乎可以理解，但并非没有缺陷。例如，非专业用户可能不完全理解热图的逻辑（即使用不同强度或颜色突出显示与模型预测相关的像素的逻辑）。此外，与模型预测相关的输入图像的对象和区域通常无法完全通过热图区分。本文提出了一种称为TbExplain的框架，采用XAI技术和预训练的对象检测器，以文本形式解释场景分类模型。此外，TbExplain还采用了一种新的方法来纠正预测和进行文本解释。

    The field of Explainable Artificial Intelligence (XAI) aims to improve the interpretability of black-box machine learning models. Building a heatmap based on the importance value of input features is a popular method for explaining the underlying functions of such models in producing their predictions. Heatmaps are almost understandable to humans, yet they are not without flaws. Non-expert users, for example, may not fully understand the logic of heatmaps (the logic in which relevant pixels to the model's prediction are highlighted with different intensities or colors). Additionally, objects and regions of the input image that are relevant to the model prediction are frequently not entirely differentiated by heatmaps. In this paper, we propose a framework called TbExplain that employs XAI techniques and a pre-trained object detector to present text-based explanations of scene classification models. Moreover, TbExplain incorporates a novel method to correct predictions and textually exp
    
[^16]: 我们的模型在MovieLens上取得了出色的表现：这意味着什么？

    Our Model Achieves Excellent Performance on MovieLens: What Does it Mean?. (arXiv:2307.09985v1 [cs.IR])

    [http://arxiv.org/abs/2307.09985](http://arxiv.org/abs/2307.09985)

    该论文通过对MovieLens数据集的分析，发现用户与该平台的交互在不同阶段存在显著差异，并且用户交互受到平台推荐算法推荐的候选电影的影响。

    

    推荐系统评估的典型基准数据集是在某一时间段内在平台上生成的用户-物品交互数据。交互生成机制部分解释了为什么用户与物品进行交互（如喜欢、购买、评分）以及特定交互发生的背景。在本研究中，我们对MovieLens数据集进行了细致的分析，并解释了使用该数据集进行评估推荐算法时可能的影响。我们从分析中得出了一些主要发现。首先，在用户与MovieLens平台交互的不同阶段存在显著差异。早期交互在很大程度上定义了用户画像，影响了后续的交互。其次，用户交互受到平台内部推荐算法推荐的候选电影的很大影响。删除靠近最后几次交互的交互会对结果产生较大影响。

    A typical benchmark dataset for recommender system (RecSys) evaluation consists of user-item interactions generated on a platform within a time period. The interaction generation mechanism partially explains why a user interacts with (e.g.,like, purchase, rate) an item, and the context of when a particular interaction happened. In this study, we conduct a meticulous analysis on the MovieLens dataset and explain the potential impact on using the dataset for evaluating recommendation algorithms. We make a few main findings from our analysis. First, there are significant differences in user interactions at the different stages when a user interacts with the MovieLens platform. The early interactions largely define the user portrait which affect the subsequent interactions. Second, user interactions are highly affected by the candidate movies that are recommended by the platform's internal recommendation algorithm(s). Removal of interactions that happen nearer to the last few interactions 
    
[^17]: XSkill：跨体现技能发现

    XSkill: Cross Embodiment Skill Discovery. (arXiv:2307.09955v1 [cs.RO])

    [http://arxiv.org/abs/2307.09955](http://arxiv.org/abs/2307.09955)

    本研究提出了XSkill，一种跨体现的技能发现框架，能够从无标签的人类和机器人操纵视频中纯粹地发现跨体现技能原型，并通过条件扩散策略将这些技能转移到机器人动作中，在未见任务中完成学习到的技能的组合。仿真和真实环境中的实验结果表明，这些发现的技能原型能够有效地促进技能转移和组合，从而构建出更通用和可扩展的模仿学习框架。

    

    人类示范视频是机器人学习的广泛数据源，并且是表达所需行为的直观用户界面。然而，直接从非结构化的人类视频中提取可重用的机器人操纵技能面临着体现差异和未观察到的行动参数的挑战。为了弥合这种体现差距，本文介绍了XSkill，一种模仿学习框架，它从无标签的人类和机器人操纵视频中纯粹地发现名为技能原型的跨体现表示，使用条件扩散策略将技能表示转移到机器人动作，并最终使用人类提示视频完成学习到的技能来完成未见任务。我们在仿真和真实环境中的实验表明，发现的技能原型促进了未见任务的技能转移和组合，从而实现了更通用和可扩展的模仿学习框架。

    Human demonstration videos are a widely available data source for robot learning and an intuitive user interface for expressing desired behavior. However, directly extracting reusable robot manipulation skills from unstructured human videos is challenging due to the big embodiment difference and unobserved action parameters. To bridge this embodiment gap, this paper introduces XSkill, an imitation learning framework that 1) discovers a cross-embodiment representation called skill prototypes purely from unlabeled human and robot manipulation videos, 2) transfers the skill representation to robot actions using conditional diffusion policy, and finally, 3) composes the learned skill to accomplish unseen tasks specified by a human prompt video. Our experiments in simulation and real-world environments show that the discovered skill prototypes facilitate both skill transfer and composition for unseen tasks, resulting in a more general and scalable imitation learning framework. The performan
    
[^18]: U-CE: 不确定性感知的语义分割交叉熵

    U-CE: Uncertainty-aware Cross-Entropy for Semantic Segmentation. (arXiv:2307.09947v1 [cs.CV])

    [http://arxiv.org/abs/2307.09947](http://arxiv.org/abs/2307.09947)

    本文提出了一种新的不确定性感知型交叉熵损失函数（U-CE），通过像素级加权将动态预测不确定性纳入训练过程中的著名交叉熵损失函数，通过实验证明了U-CE对于语义分割在性能和提供有意义的不确定性方面的改进。

    

    深度神经网络在各种任务中表现出色，但它们的鲁棒性、可靠性和过度自信的倾向为在自动驾驶等安全关键应用中部署提出了挑战。因此，量化模型预测中固有的不确定性是解决这些缺点的一种有前途的努力。在这项工作中，我们提出了一种新颖的不确定性感知型交叉熵损失函数（U-CE），通过像素级加权将动态预测不确定性纳入训练过程中的著名交叉熵损失函数（CE）。通过广泛的实验，我们证明了U-CE在两个基准数据集Cityscapes和ACDC上与常见的ResNet-18和ResNet-101两种主干架构相比，具有优势。通过使用U-CE，我们能够训练出不仅在分割性能上有所提升，而且在训练后提供有意义的不确定性的模型。因此，我们对不确定性感知的语义分割交叉熵的研究做出了贡献。

    Deep neural networks have shown exceptional performance in various tasks, but their lack of robustness, reliability, and tendency to be overconfident pose challenges for their deployment in safety-critical applications like autonomous driving. In this regard, quantifying the uncertainty inherent to a model's prediction is a promising endeavour to address these shortcomings. In this work, we present a novel Uncertainty-aware Cross-Entropy loss (U-CE) that incorporates dynamic predictive uncertainties into the training process by pixel-wise weighting of the well-known cross-entropy loss (CE). Through extensive experimentation, we demonstrate the superiority of U-CE over regular CE training on two benchmark datasets, Cityscapes and ACDC, using two common backbone architectures, ResNet-18 and ResNet-101. With U-CE, we manage to train models that not only improve their segmentation performance but also provide meaningful uncertainties after training. Consequently, we contribute to the devel
    
[^19]: TREEMENT: 可解释的患者-试验匹配模型通过个性化动态树状记忆网络

    TREEMENT: Interpretable Patient-Trial Matching via Personalized Dynamic Tree-Based Memory Network. (arXiv:2307.09942v1 [cs.LG])

    [http://arxiv.org/abs/2307.09942](http://arxiv.org/abs/2307.09942)

    TREEMENT是一种采用个性化动态树状记忆网络的可解释患者-试验匹配模型，利用层次化临床本体知识和合格标准嵌入学习，提供准确而有解释性的患者-试验匹配。

    

    临床试验对于药物开发至关重要，但往往面临昂贵而低效的患者招募问题。近年来，提出了机器学习模型，通过基于纵向患者电子健康记录（EHR）数据和临床试验的合格标准自动匹配患者与临床试验，以加速患者招募。然而，它们要么依赖于无法扩展到其他试验的专家规则，要么以黑箱模型进行非常通用的匹配，缺乏可解释性会导致模型结果难以采用。为了提供准确且可解释的患者-试验匹配，我们引入了一种名为TREEMENT的个性化动态树状记忆网络模型。它利用层次化临床本体知识扩展了从序列EHR数据中学到的个性化患者表示，然后使用基于合格标准嵌入学习的注意力束搜索查询。

    Clinical trials are critical for drug development but often suffer from expensive and inefficient patient recruitment. In recent years, machine learning models have been proposed for speeding up patient recruitment via automatically matching patients with clinical trials based on longitudinal patient electronic health records (EHR) data and eligibility criteria of clinical trials. However, they either depend on trial-specific expert rules that cannot expand to other trials or perform matching at a very general level with a black-box model where the lack of interpretability makes the model results difficult to be adopted.  To provide accurate and interpretable patient trial matching, we introduce a personalized dynamic tree-based memory network model named TREEMENT. It utilizes hierarchical clinical ontologies to expand the personalized patient representation learned from sequential EHR data, and then uses an attentional beam-search query learned from eligibility criteria embedding to o
    
[^20]: Spuriosity并没有导致分类器失败：利用不变的预测来利用虚假特征

    Spuriosity Didn't Kill the Classifier: Using Invariant Predictions to Harness Spurious Features. (arXiv:2307.09933v1 [cs.LG])

    [http://arxiv.org/abs/2307.09933](http://arxiv.org/abs/2307.09933)

    本研究通过理论证明和算法提出，展示了在没有标签的情况下如何利用不稳定特征来提高分类器的性能。

    

    为了避免在域外数据上的失败，最近的研究试图提取具有与标签在不同域之间稳定或不变关系的特征，舍弃与标签在不同域之间关系变化的"虚假"或不稳定特征。然而，不稳定特征常常携带关于标签的补充信息，如果在测试域中正确使用，可以提高性能。我们的主要贡献是显示在没有标签的情况下学习如何在测试域中使用这些不稳定特征是可能的。特别是，我们证明基于稳定特征的伪标签提供了足够的指导来做到这一点，前提是在给定标签的条件下，稳定特征和不稳定特征是条件独立的。基于这个理论洞见，我们提出了稳定特征增强（SFB）算法：(i)学习一个能够分离稳定特征和条件独立不稳定特征的预测器；(ii)使用稳定特征预测来适应测试域

    To avoid failures on out-of-distribution data, recent works have sought to extract features that have a stable or invariant relationship with the label across domains, discarding the "spurious" or unstable features whose relationship with the label changes across domains. However, unstable features often carry complementary information about the label that could boost performance if used correctly in the test domain. Our main contribution is to show that it is possible to learn how to use these unstable features in the test domain without labels. In particular, we prove that pseudo-labels based on stable features provide sufficient guidance for doing so, provided that stable and unstable features are conditionally independent given the label. Based on this theoretical insight, we propose Stable Feature Boosting (SFB), an algorithm for: (i) learning a predictor that separates stable and conditionally-independent unstable features; and (ii) using the stable-feature predictions to adapt t
    
[^21]: 探索具有描述逻辑特征的命题动态逻辑的非正则扩展

    Exploring Non-Regular Extensions of Propositional Dynamic Logic with Description-Logics Features. (arXiv:2307.09913v1 [cs.LO])

    [http://arxiv.org/abs/2307.09913](http://arxiv.org/abs/2307.09913)

    研究了非正则路径表达式对于扩展ALC描述逻辑中可满足性检查和查询的可决定性的影响，并提供了一系列不可决定性结果。

    

    我们研究了非正则路径表达式对于扩展ALC描述逻辑中可满足性检查和查询的可决定性的影响。我们主要关注的对象是ALCreg和ALCvpl，分别是使用正则和可见推下语言的路径表达式的扩展。第一个ALCreg是Fischer和Ladner所熟知的命题动态逻辑的一种变种。第二个ALCvpl是由Loding和Serre在2007年引入和研究的。ALCvpl逻辑广义上推广了许多已知的可决定性非正则扩展的ALCreg。我们提供了一系列不可决定性结果。首先，我们展示了在添加看似无害的Self操作符后，对于ALCvpl中的概念可满足性问题的可决定性丧失。其次，我们建立了对于在ALCvpl中添加个体词的概念可满足性问题的不可决定性。有趣的是，我们的不可决定性证明只依赖于一个单一的非正则（可见推下）语言。

    We investigate the impact of non-regular path expressions on the decidability of satisfiability checking and querying in description logics extending ALC. Our primary objects of interest are ALCreg and ALCvpl, the extensions of with path expressions employing, respectively, regular and visibly-pushdown languages. The first one, ALCreg, is a notational variant of the well-known Propositional Dynamic Logic of Fischer and Ladner. The second one, ALCvpl, was introduced and investigated by Loding and Serre in 2007. The logic ALCvpl generalises many known decidable non-regular extensions of ALCreg.  We provide a series of undecidability results. First, we show that decidability of the concept satisfiability problem for ALCvpl is lost upon adding the seemingly innocent Self operator. Second, we establish undecidability for the concept satisfiability problem for ALCvpl extended with nominals. Interestingly, our undecidability proof relies only on one single non-regular (visibly-pushdown) langu
    
[^22]: Chit-Chat或者Deep Talk：用于过程挖掘的提示工程

    Chit-Chat or Deep Talk: Prompt Engineering for Process Mining. (arXiv:2307.09909v1 [cs.AI])

    [http://arxiv.org/abs/2307.09909](http://arxiv.org/abs/2307.09909)

    这项研究通过应用大型语言模型(LLM)来增强对话代理在过程挖掘中的应用，改善了现有解决方案中的问题，并提出了未来的研究建议。

    

    该研究探讨了大型语言模型(LLM)在过程挖掘中增强对话代理的应用，旨在应对其固有的复杂性和多样化的技能要求。虽然LLM的进展为对话式过程挖掘提供了新的机遇，但生成高效的输出仍然是一个障碍。我们提出了一种创新的方法，通过对自然语言处理(NLP)为对话代理进行的先前研究的了解，改善了现有解决方案中的许多问题。利用LLM，我们的框架改善了可访问性和代理性能，通过对公共问题和数据集的实验进行验证。我们的研究为进一步探索LLM在过程挖掘中的作用奠定了基础，并提出了增强LLM记忆、实施实时用户测试以及检查多样化数据集的建议。

    This research investigates the application of Large Language Models (LLMs) to augment conversational agents in process mining, aiming to tackle its inherent complexity and diverse skill requirements. While LLM advancements present novel opportunities for conversational process mining, generating efficient outputs is still a hurdle. We propose an innovative approach that amend many issues in existing solutions, informed by prior research on Natural Language Processing (NLP) for conversational agents. Leveraging LLMs, our framework improves both accessibility and agent performance, as demonstrated by experiments on public question and data sets. Our research sets the stage for future explorations into LLMs' role in process mining and concludes with propositions for enhancing LLM memory, implementing real-time user testing, and examining diverse data sets.
    
[^23]: 隐式身份表示条件化记忆补偿网络用于生成自然头部视频

    Implicit Identity Representation Conditioned Memory Compensation Network for Talking Head video Generation. (arXiv:2307.09906v1 [cs.CV])

    [http://arxiv.org/abs/2307.09906](http://arxiv.org/abs/2307.09906)

    提出了一种隐式身份表示条件化记忆补偿网络，用于高保真度的自然头部视频生成。

    

    头部视频生成旨在通过从目标驱动视频中提取的动态姿势和表情来给静态图像中的人脸添加动画效果，同时保持源图像中的个人身份。然而，驱动视频中戏剧性和复杂的运动会导致生成模糊不清，因为静态源图像无法提供足够的外观信息来处理被遮挡区域或微妙的表情变化，这会产生严重的伪影并严重降低生成质量。为了解决这个问题，我们提出了学习全局人脸表示空间的方法，并设计了一种新颖的隐式身份表示条件化记忆补偿网络，称为MCNet，用于高保真度的头部视频生成。

    Talking head video generation aims to animate a human face in a still image with dynamic poses and expressions using motion information derived from a target-driving video, while maintaining the person's identity in the source image. However, dramatic and complex motions in the driving video cause ambiguous generation, because the still source image cannot provide sufficient appearance information for occluded regions or delicate expression variations, which produces severe artifacts and significantly degrades the generation quality. To tackle this problem, we propose to learn a global facial representation space, and design a novel implicit identity representation conditioned memory compensation network, coined as MCNet, for high-fidelity talking head generation.~Specifically, we devise a network module to learn a unified spatial facial meta-memory bank from all training samples, which can provide rich facial structure and appearance priors to compensate warped source facial features 
    
[^24]: PyTAG：强化学习在桌面游戏中的挑战与机遇

    PyTAG: Challenges and Opportunities for Reinforcement Learning in Tabletop Games. (arXiv:2307.09905v1 [cs.AI])

    [http://arxiv.org/abs/2307.09905](http://arxiv.org/abs/2307.09905)

    PyTAG是一个用于在桌面游戏中进行强化学习研究的Python API。它提供了与Tabletop Games framework (TAG)进行交互的功能，并介绍了在现代桌面游戏中训练强化学习代理的技术和基准结果。

    

    近年来，游戏人工智能研究使用强化学习取得了重要突破。然而，相比视频游戏，现代桌面游戏在强化学习方面鲜有关注，尽管它们提供了一系列与众不同的挑战。为了弥补这一差距，我们介绍了PyTAG，该Python API用于与Tabletop Games framework (TAG)进行交互。TAG包含了超过20个现代桌面游戏，并提供了一个公共API供AI代理使用。我们介绍了在这些游戏中训练强化学习代理的技术，并在部分游戏上使用Proximal Policy Optimisation算法进行基准结果的训练。最后，我们讨论了复杂现代桌面游戏提供的独特挑战，并介绍了通过PyTAG进行强化学习研究的机会。

    In recent years, Game AI research has made important breakthroughs using Reinforcement Learning (RL). Despite this, RL for modern tabletop games has gained little to no attention, even when they offer a range of unique challenges compared to video games. To bridge this gap, we introduce PyTAG, a Python API for interacting with the Tabletop Games framework (TAG). TAG contains a growing set of more than 20 modern tabletop games, with a common API for AI agents. We present techniques for training RL agents in these games and introduce baseline results after training Proximal Policy Optimisation algorithms on a subset of games. Finally, we discuss the unique challenges complex modern tabletop games provide, now open to RL research through PyTAG.
    
[^25]: 非自回归TTS中说话者嵌入选择的效果分析

    An analysis on the effects of speaker embedding choice in non auto-regressive TTS. (arXiv:2307.09898v1 [eess.AS])

    [http://arxiv.org/abs/2307.09898](http://arxiv.org/abs/2307.09898)

    本文分析了非自回归TTS中选择不同说话者嵌入的效果。研究发现，无论使用何种嵌入集和学习策略，网络都可以同样良好地处理各种说话者身份，并且训练过程中存在不可避免的说话者泄漏。

    

    本文首次尝试理解非自回归的分解多说话者语音合成架构如何利用不同说话者嵌入集中的信息。我们分析了联合学习表示和从预训练模型初始化它们是否能提高目标说话者身份的质量。在另一个分析中，我们调查了不同嵌入集对网络的核心语音抽象（即零条件）在说话者身份和表示学习方面的影响。我们展示出，无论使用哪种嵌入集和学习策略，网络都可以同样良好地处理各种说话者身份，语音输出质量几乎没有明显的变化，并且在迄今为止采用的标准训练过程中，合成系统的核心结构不可避免地存在说话者泄漏。

    In this paper we introduce a first attempt on understanding how a non-autoregressive factorised multi-speaker speech synthesis architecture exploits the information present in different speaker embedding sets. We analyse if jointly learning the representations, and initialising them from pretrained models determine any quality improvements for target speaker identities. In a separate analysis, we investigate how the different sets of embeddings impact the network's core speech abstraction (i.e. zero conditioned) in terms of speaker identity and representation learning. We show that, regardless of the used set of embeddings and learning strategy, the network can handle various speaker identities equally well, with barely noticeable variations in speech output quality, and that speaker leakage within the core structure of the synthesis system is inevitable in the standard training procedures adopted thus far.
    
[^26]: 物品反应理论的摊销设计优化

    Amortised Design Optimization for Item Response Theory. (arXiv:2307.09891v1 [cs.AI])

    [http://arxiv.org/abs/2307.09891](http://arxiv.org/abs/2307.09891)

    本文在物品反应理论中提出了摊销实验设计方法，利用深度强化学习代理在预处理阶段选择对于学生分布最具信息价值的测试项目，并在部署过程中进行摊销推断。

    

    物品反应理论（IRT）是一种用于评估教育和心理学中人类回答的方法。在教育领域，IRT被用来推断学生能力和测试项目的特点，通过学生的回答。与学生的互动是昂贵的，需要高效地收集推断学生能力的信息。基于最佳实验设计（OED）的方法在计算上代价高昂，使其不适用于交互式应用。为此，我们提出将摊销实验设计纳入IRT中。在这里，计算成本被转移到预计算阶段，通过使用合成数据训练深度强化学习（DRL）代理。该代理被训练为选择对于学生分布最具信息价值的测试项目，并根据实验结果进行摊销推断。在部署过程中，代理根据数据估计参数，并为学生建议下一个测试项目。

    Item Response Theory (IRT) is a well known method for assessing responses from humans in education and psychology. In education, IRT is used to infer student abilities and characteristics of test items from student responses. Interactions with students are expensive, calling for methods that efficiently gather information for inferring student abilities. Methods based on Optimal Experimental Design (OED) are computationally costly, making them inapplicable for interactive applications. In response, we propose incorporating amortised experimental design into IRT. Here, the computational cost is shifted to a precomputing phase by training a Deep Reinforcement Learning (DRL) agent with synthetic data. The agent is trained to select optimally informative test items for the distribution of students, and to conduct amortised inference conditioned on the experiment outcomes. During deployment the agent estimates parameters from data, and suggests the next test item for the student, in close t
    
[^27]: VQA验证的强化学习方法：应用于糖尿病黄斑水肿分级

    A reinforcement learning approach for VQA validation: an application to diabetic macular edema grading. (arXiv:2307.09886v1 [cs.CV])

    [http://arxiv.org/abs/2307.09886](http://arxiv.org/abs/2307.09886)

    本论文提出了一种基于强化学习的方法，用于验证VQA算法在医学图像分析中的应用，旨在提供更丰富和更适当的验证方法，以揭示算法的推理行为。

    

    最近的机器学习模型的进展极大地提高了医学图像分析自动化方法的性能。然而，这些模型的内部功能很大程度上是隐藏的，这妨碍了它们在临床实践中的整合。可解释性和信任被视为现代方法的重要方面，以便在临床社区中广泛应用。因此，机器学习模型的验证代表了一个重要方面，然而大多数方法仅在有限的方式下进行验证。在这项工作中，我们专注于为功能强大的视觉问答（VQA）算法提供更丰富和更适当的验证方法。为了更好地了解这些方法的性能，这项工作关注于自动视觉图灵测试（VTT）。也就是说，我们提出了一种自适应问答方法，旨在暴露VQA算法的推理行为。具体而言，我们引入了一种强化学习方法。

    Recent advances in machine learning models have greatly increased the performance of automated methods in medical image analysis. However, the internal functioning of such models is largely hidden, which hinders their integration in clinical practice. Explainability and trust are viewed as important aspects of modern methods, for the latter's widespread use in clinical communities. As such, validation of machine learning models represents an important aspect and yet, most methods are only validated in a limited way. In this work, we focus on providing a richer and more appropriate validation approach for highly powerful Visual Question Answering (VQA) algorithms. To better understand the performance of these methods, which answer arbitrary questions related to images, this work focuses on an automatic visual Turing test (VTT). That is, we propose an automatic adaptive questioning method, that aims to expose the reasoning behavior of a VQA algorithm. Specifically, we introduce a reinfor
    
[^28]: 考试者有话说：理解在语言测试中使用人工智能的影响

    Test-takers have a say: understanding the implications of the use of AI in language tests. (arXiv:2307.09885v1 [cs.CY])

    [http://arxiv.org/abs/2307.09885](http://arxiv.org/abs/2307.09885)

    深入了解在语言测试中使用人工智能的影响和担忧，有助于利益相关者做出明智决策，确保社区福祉和测试完整性。

    

    语言测试衡量一个人在听、说、读、写方面使用某种语言的能力。这类测试在学术、职业和移民领域发挥着重要作用，教育机构、专业认证机构和政府等实体机构使用它们来评估候选人的语言熟练程度。人工智能和自然语言处理学科的最新进展促使语言测试提供者探索将人工智能应用于语言测试的潜在可能性，从而引发了围绕语言教学和学习的变革性活动模式。然而，在对人工智能信任性存在担忧的情况下，必须了解将人工智能整合到语言测试中的影响。这样的知识将使利益相关者能够做出明智的决策，从而保护社区的福祉和测试的完整性。为了了解在语言测试中使用人工智能的关切和影响，我们进行了...

    Language tests measure a person's ability to use a language in terms of listening, speaking, reading, or writing. Such tests play an integral role in academic, professional, and immigration domains, with entities such as educational institutions, professional accreditation bodies, and governments using them to assess candidate language proficiency. Recent advances in Artificial Intelligence (AI) and the discipline of Natural Language Processing have prompted language test providers to explore AI's potential applicability within language testing, leading to transformative activity patterns surrounding language instruction and learning. However, with concerns over AI's trustworthiness, it is imperative to understand the implications of integrating AI into language testing. This knowledge will enable stakeholders to make well-informed decisions, thus safeguarding community well-being and testing integrity. To understand the concerns and effects of AI usage in language tests, we conducted 
    
[^29]: 通过单向流进行对抗性似然估计

    Adversarial Likelihood Estimation with One-way Flows. (arXiv:2307.09882v1 [cs.LG])

    [http://arxiv.org/abs/2307.09882](http://arxiv.org/abs/2307.09882)

    本文提出了一种通过单向流进行对抗性似然估计的方法，并使用重要性采样解决了Wasserstein GAN中分区函数有偏估计的问题。同时，通过最大化生成器的熵，提高了模式覆盖效果。这种方法通过计算生成样本的密度来实现对分区函数的无偏估计和生成器熵的计算。

    

    生成对抗网络（GAN）能够产生高质量的样本，但无法提供样本周围的概率密度估计。然而，已经注意到在能量模型的设置中，最大化对数似然可以导致判别器提供非归一化的密度（通常称为能量）的对抗性框架。我们进一步发展了这一观点，结合重要性采样，并展示了以下内容：1）Wasserstein GAN对分区函数进行了有偏估计，我们提出使用无偏估计方法；2）在最优化似然时，必须最大化生成器的熵。这被假设会提供更好的模式覆盖。与以前的工作不同，我们明确计算了生成样本的密度。这是设计无偏估计分区函数以及计算生成器熵的关键因素。生成密度是通过一种新型的流网络来获得的，称为单向流网络。

    Generative Adversarial Networks (GANs) can produce high-quality samples, but do not provide an estimate of the probability density around the samples. However, it has been noted that maximizing the log-likelihood within an energy-based setting can lead to an adversarial framework where the discriminator provides unnormalized density (often called energy). We further develop this perspective, incorporate importance sampling, and show that 1) Wasserstein GAN performs a biased estimate of the partition function, and we propose instead to use an unbiased estimator; 2) when optimizing for likelihood, one must maximize generator entropy. This is hypothesized to provide a better mode coverage. Different from previous works, we explicitly compute the density of the generated samples. This is the key enabler to designing an unbiased estimator of the partition function and computation of the generator entropy term. The generator density is obtained via a new type of flow network, called one-way 
    
[^30]: 《用户指向的摊销实验设计和参数估计》

    Amortised Experimental Design and Parameter Estimation for User Models of Pointing. (arXiv:2307.09878v1 [cs.AI])

    [http://arxiv.org/abs/2307.09878](http://arxiv.org/abs/2307.09878)

    本研究研究了一种通过训练策略选择实验设计，用模拟数据代替大量人类数据来分摊实验设计成本的方法，在交互设计中估计用户模型的参数，并且在三个不同的指向模型上进行了演示。

    

    用户模型在交互设计中起着重要的作用，支持自动化交互设计选择。为了实现这一目标，必须从用户数据中估计模型参数。虽然有时需要大量的用户数据，但最近的研究表明可以设计实验来尽可能高效地收集数据并推断参数，从而最小化数据需求。在本文中，我们研究了这些方法的一种变体，通过训练一个选择实验设计的策略来分摊实验设计的计算成本，使用模拟参与者来收集实验数据。我们的解决方案通过与模型空间中的模拟代理相互作用来学习哪些实验对参数估计提供最有用的数据，从而使用合成数据而不是大量的人类数据。该方法在三个日益复杂的指向模型上进行了演示。

    User models play an important role in interaction design, supporting automation of interaction design choices. In order to do so, model parameters must be estimated from user data. While very large amounts of user data are sometimes required, recent research has shown how experiments can be designed so as to gather data and infer parameters as efficiently as possible, thereby minimising the data requirement. In the current article, we investigate a variant of these methods that amortises the computational cost of designing experiments by training a policy for choosing experimental designs with simulated participants. Our solution learns which experiments provide the most useful data for parameter estimation by interacting with in-silico agents sampled from the model space thereby using synthetic data rather than vast amounts of human data. The approach is demonstrated for three progressively complex models of pointing.
    
[^31]: 检测城市基础设施相互依赖网络中的脆弱节点

    Detecting Vulnerable Nodes in Urban Infrastructure Interdependent Network. (arXiv:2307.09866v1 [cs.LG])

    [http://arxiv.org/abs/2307.09866](http://arxiv.org/abs/2307.09866)

    该论文使用图神经网络和强化学习对城市基础设施相互依赖网络中的脆弱节点进行了准确建模和分析。

    

    理解和描述城市基础设施的脆弱性对我们具有重要价值，这些基础设施是城市正常运行所必需的工程设施，以网络的形式自然存在。潜在的应用包括保护脆弱设施和设计稳健的拓扑结构等。由于不同拓扑特性和基础设施脆弱性以及其复杂的演化机制之间的强关联，一些启发式分析和机器辅助分析在解决这种场景时存在局限性。在本文中，我们将相互依赖网络建模为异构图，并提出了一种基于图神经网络和强化学习的系统，可以在实际数据上进行训练，准确地描述城市系统的脆弱性。所提出的系统利用深度学习技术来理解和分析异构图，从而能够捕捉级联失败风险。

    Understanding and characterizing the vulnerability of urban infrastructures, which refers to the engineering facilities essential for the regular running of cities and that exist naturally in the form of networks, is of great value to us. Potential applications include protecting fragile facilities and designing robust topologies, etc. Due to the strong correlation between different topological characteristics and infrastructure vulnerability and their complicated evolution mechanisms, some heuristic and machine-assisted analysis fall short in addressing such a scenario. In this paper, we model the interdependent network as a heterogeneous graph and propose a system based on graph neural network with reinforcement learning, which can be trained on real-world data, to characterize the vulnerability of the city system accurately. The presented system leverages deep learning techniques to understand and analyze the heterogeneous graph, which enables us to capture the risk of cascade failu
    
[^32]: 迈向基于人群信息的结构动力学数据驱动模型定义方法

    Towards a population-informed approach to the definition of data-driven models for structural dynamics. (arXiv:2307.09862v1 [cs.LG])

    [http://arxiv.org/abs/2307.09862](http://arxiv.org/abs/2307.09862)

    本论文提出了一种基于人群信息的方法，用于定义结构动力学的数据驱动模型，以解决数据稀缺问题。这种方法结合了物理基础方法和机器学习算法，通过从相似物理现象的人群中学习关系，构建可转移、可解释、值得信赖的模型。

    

    机器学习已经影响了许多领域中多种现象的建模方式，其中之一就是结构动力学领域。然而，由于机器学习算法是问题特定的，他们在数据稀缺的情况下往往效果不佳。为了解决这些问题，结合物理基础方法和机器学习算法的方法被开发出来。虽然这些方法是有效的，但也需要分析者对问题的物理基础有所了解。本研究旨在推动使用从相似物理现象的人群中学习这种关系的模型。这些模型的开发受到物理模型，特别是有限元模型的启发。这些模型被认为是可转移的、可解释的和值得信赖的，而对于机器学习模型来说，这些属性并不是轻松可行的。

    Machine learning has affected the way in which many phenomena for various domains are modelled, one of these domains being that of structural dynamics. However, because machine-learning algorithms are problem-specific, they often fail to perform efficiently in cases of data scarcity. To deal with such issues, combination of physics-based approaches and machine learning algorithms have been developed. Although such methods are effective, they also require the analyser's understanding of the underlying physics of the problem. The current work is aimed at motivating the use of models which learn such relationships from a population of phenomena, whose underlying physics are similar. The development of such models is motivated by the way that physics-based models, and more specifically finite element models, work. Such models are considered transferrable, explainable and trustworthy, attributes which are not trivially imposed or achieved for machine-learning models. For this reason, machin
    
[^33]: 通过个体校准实现图上可靠的稀有类别分析

    Towards Reliable Rare Category Analysis on Graphs via Individual Calibration. (arXiv:2307.09858v1 [cs.AI])

    [http://arxiv.org/abs/2307.09858](http://arxiv.org/abs/2307.09858)

    该论文研究了稀有类别分析中的不正确校准问题，发现现有的方法在预测少数类别时过于自信且不够自信。

    

    稀有类别在许多现实世界的网络中广泛存在，并在各种高风险应用中起着重要作用，包括金融欺诈检测，网络入侵检测和罕见疾病诊断。稀有类别分析(RCA)是指在高度不平衡的数据分布中检测、表征和理解少数类别行为的任务。虽然现有的RCA研究大多集中在提高预测性能上，但少数几个基础性的研究问题迄今为止受到较少关注和较少探索：在稀有类别分析中，预测模型有多自信或不确定？我们如何量化学习过程中的不确定性，并实现可靠的稀有类别分析？为了回答这些问题，我们首先调查了现有RCA方法中的不正确校准问题。实证结果表明，当前最先进的RCA方法主要在预测少数类别时过于自信且不够自信。

    Rare categories abound in a number of real-world networks and play a pivotal role in a variety of high-stakes applications, including financial fraud detection, network intrusion detection, and rare disease diagnosis. Rare category analysis (RCA) refers to the task of detecting, characterizing, and comprehending the behaviors of minority classes in a highly-imbalanced data distribution. While the vast majority of existing work on RCA has focused on improving the prediction performance, a few fundamental research questions heretofore have received little attention and are less explored: How confident or uncertain is a prediction model in rare category analysis? How can we quantify the uncertainty in the learning process and enable reliable rare category analysis?  To answer these questions, we start by investigating miscalibration in existing RCA methods. Empirical results reveal that state-of-the-art RCA methods are mainly over-confident in predicting minority classes and under-confide
    
[^34]: 在交通中的轨迹预测中的快速和无地图模型

    A Fast and Map-Free Model for Trajectory Prediction in Traffics. (arXiv:2307.09831v1 [cs.AI])

    [http://arxiv.org/abs/2307.09831](http://arxiv.org/abs/2307.09831)

    本文提出了一种高效的无地图轨迹预测模型，通过综合运用多种技术，学习到所有代理的动态和交互信息，达到了最高性能水平。

    

    为了解决现有方法的两个缺点，（i）几乎所有模型都依赖于高清地图，然而地图信息在实际交通场景中并不总是可用的，而且建立高清地图也是昂贵且耗时的；（ii）现有模型通常注重提高预测准确性，而忽视了计算效率，然而效率对于各种实际应用非常关键。本文提出了一种高效的轨迹预测模型，不依赖于交通地图。我们模型的核心思想是在第一阶段中对单个代理的时空信息进行编码，并在第二阶段中探索多个代理的时空交互。通过综合运用注意力机制、LSTM、图卷积网络和时序转换器等技术，我们的模型能够学习到所有代理的丰富动态和交互信息。与现有的无地图方法相比，我们的模型在性能上达到了最高水平。

    To handle the two shortcomings of existing methods, (i)nearly all models rely on high-definition (HD) maps, yet the map information is not always available in real traffic scenes and HD map-building is expensive and time-consuming and (ii) existing models usually focus on improving prediction accuracy at the expense of reducing computing efficiency, yet the efficiency is crucial for various real applications, this paper proposes an efficient trajectory prediction model that is not dependent on traffic maps. The core idea of our model is encoding single-agent's spatial-temporal information in the first stage and exploring multi-agents' spatial-temporal interactions in the second stage. By comprehensively utilizing attention mechanism, LSTM, graph convolution network and temporal transformer in the two stages, our model is able to learn rich dynamic and interaction information of all agents. Our model achieves the highest performance when comparing with existing map-free methods and also
    
[^35]: 在室内物体识别中的在线持续学习

    Online Continual Learning for Robust Indoor Object Recognition. (arXiv:2307.09827v1 [cs.RO])

    [http://arxiv.org/abs/2307.09827](http://arxiv.org/abs/2307.09827)

    本论文提出了RobOCLe方法，针对室内物体识别中的在线持续学习问题，通过构建丰富的特征空间和计算样本之间的相似性来提高模型的鲁棒性。

    

    家庭机器人上的视觉系统需要在不断变化的环境中与未见过的类别进行交互。机器人具有有限的计算资源、标记数据和存储能力。这些要求带来了一些独特的挑战：模型应该以数据和参数高效的方式适应并不会忘记过去的知识。我们将问题定义为少样本（FS）的在线持续学习（OCL），其中机器人代理从一系列非重复的少样本数据中学习，只更新少量的模型参数。此外，这些模型在测试时会遇到不同的条件，物体可能以不同的姿势（例如，水平或垂直）和环境（例如，白天或黑夜）出现，为了提高持续学习代理的鲁棒性，我们提出了RobOCLe方法：1）通过计算样本的嵌入特征的高阶统计量来构建丰富的特征空间；2）计算丰富特征空间中样本的高阶统计量之间的相似性，并预测样本的标签。

    Vision systems mounted on home robots need to interact with unseen classes in changing environments. Robots have limited computational resources, labelled data and storage capability. These requirements pose some unique challenges: models should adapt without forgetting past knowledge in a data- and parameter-efficient way. We characterize the problem as few-shot (FS) online continual learning (OCL), where robotic agents learn from a non-repeated stream of few-shot data updating only a few model parameters. Additionally, such models experience variable conditions at test time, where objects may appear in different poses (e.g., horizontal or vertical) and environments (e.g., day or night). To improve robustness of CL agents, we propose RobOCLe, which; 1) constructs an enriched feature space computing high order statistical moments from the embedded features of samples; and 2) computes similarity between high order statistics of the samples on the enriched feature space, and predicts the
    
[^36]: 具有一致聚合的概率预测

    Probabilistic Forecasting with Coherent Aggregation. (arXiv:2307.09797v1 [cs.LG])

    [http://arxiv.org/abs/2307.09797](http://arxiv.org/abs/2307.09797)

    该论文提出了一种新的模型，利用因子模型结构来产生遵守层次结构的概率预测。模型利用卷积神经网络生成参数，并通过优化样本损失函数实现预测优化。

    

    在许多应用中，准确获得遵守层次结构的概率预测是一项重要的运营挑战，特别是在能源管理、供应链规划和资源配置等领域。对于多变量预测，基本挑战在于预测通常需要与层次结构保持一致。在本文中，我们提出了一种新的模型，利用因子模型结构通过构建来产生一致的预测。这是一个简单的观察结果（可交换性）：置换层次结构中的基本级别序列不会改变它们的聚合。我们的模型使用卷积神经网络来生成因子、它们的加载和基本级别分布的参数；它产生可以根据模型参数进行微分的样本；因此它可以对任何基于样本的损失函数进行优化，包括连续排名概率损失函数。

    Obtaining accurate probabilistic forecasts while respecting hierarchical information is an important operational challenge in many applications, perhaps most obviously in energy management, supply chain planning, and resource allocation. The basic challenge, especially for multivariate forecasting, is that forecasts are often required to be coherent with respect to the hierarchical structure. In this paper, we propose a new model which leverages a factor model structure to produce coherent forecasts by construction. This is a consequence of a simple (exchangeability) observation: permuting \textit{}base-level series in the hierarchy does not change their aggregates. Our model uses a convolutional neural network to produce parameters for the factors, their loadings and base-level distributions; it produces samples which can be differentiated with respect to the model's parameters; and it can therefore optimize for any sample-based loss function, including the Continuous Ranked Probabili
    
[^37]: ZeroQuant-FP: 使用浮点格式进行LLMs训练后量化的一项飞跃

    ZeroQuant-FP: A Leap Forward in LLMs Post-Training W4A8 Quantization Using Floating-Point Formats. (arXiv:2307.09782v1 [cs.LG])

    [http://arxiv.org/abs/2307.09782](http://arxiv.org/abs/2307.09782)

    ZeroQuant-FP通过使用浮点格式进行LLMs训练后量化，解决了在大型语言模型中平衡计算效率和保持模型质量的挑战，并发现FP8激活优于INT8，并且FP4权重表现与INT4相当甚至更优。

    

    在大型语言模型（LLMs）的复杂领域中，平衡计算效率和保持模型质量是一个巨大的挑战。本研究通过探讨浮点（FP）量化的可行性，特别关注FP8和FP4，以应对均匀量化的固有限制，尤其是处理离群值，并受到NVIDIA H100硬件的启发。我们的全面调查发现，在LLMs中，FP8激活始终优于其整数（INT8）等效，性能优势在包含超过十亿参数的模型中更为明显。对于权重量化，我们的研究结果表明，FP4的性能与INT4相当，甚至更优，简化了在像H100这样支持FP的硬件上的部署。为了减少由权重和激活之间差异引起的精度对齐开销，我们提出了两个缩放约束。

    In the complex domain of large language models (LLMs), striking a balance between computational efficiency and maintaining model quality is a formidable challenge. Navigating the inherent limitations of uniform quantization, particularly when dealing with outliers, and motivated by the launch of NVIDIA's H100 hardware, this study delves into the viability of floating-point (FP) quantization, particularly focusing on FP8 and FP4, as a potential solution. Our comprehensive investigation reveals that for LLMs, FP8 activation consistently outshines its integer (INT8) equivalent, with the performance edge becoming more noticeable in models possessing parameters beyond one billion. For weight quantization, our findings indicate that FP4 exhibits comparable, if not superior, performance to INT4, simplifying deployment on FP-supported hardware like H100. To mitigate the overhead from precision alignment caused by the disparity between weights and activations, we propose two scaling constraints
    
[^38]: Text2Layer: 使用潜在扩散模型进行分层图像生成

    Text2Layer: Layered Image Generation using Latent Diffusion Model. (arXiv:2307.09781v1 [cs.CV])

    [http://arxiv.org/abs/2307.09781](http://arxiv.org/abs/2307.09781)

    该论文提出了一种使用潜在扩散模型进行分层图像生成的方法，使得在生成高质量图像的同时，实现更好的合成工作流程和更高质量的图层遮罩生成。

    

    图层合成是业余爱好者和专业人士中最受欢迎的图像编辑工作流之一。受到扩散模型的成功启发，我们从分层图像生成的角度探索图层合成问题。我们提出了一种同时生成背景、前景、图层遮罩和合成图像的方法，而不仅仅是生成一幅图像。为了实现分层图像生成，我们训练了一个自动编码器来重建分层图像，并在潜在表示上训练了扩散模型。该方法的一个好处是在高质量图像输出之外，可以实现更好的合成工作流程。另一个好处是生成比通过图像分割的独立步骤产生的图层遮罩更高质量的图层遮罩。实验结果表明，所提出的方法能够生成高质量的分层图像，并为未来的工作奠定了基准。

    Layer compositing is one of the most popular image editing workflows among both amateurs and professionals. Motivated by the success of diffusion models, we explore layer compositing from a layered image generation perspective. Instead of generating an image, we propose to generate background, foreground, layer mask, and the composed image simultaneously. To achieve layered image generation, we train an autoencoder that is able to reconstruct layered images and train diffusion models on the latent representation. One benefit of the proposed problem is to enable better compositing workflows in addition to the high-quality image output. Another benefit is producing higher-quality layer masks compared to masks produced by a separate step of image segmentation. Experimental results show that the proposed method is able to generate high-quality layered images and initiates a benchmark for future work.
    
[^39]: 超越单一特征重要性的新方法ICECREAM

    Beyond Single-Feature Importance with ICECREAM. (arXiv:2307.09779v1 [cs.LG])

    [http://arxiv.org/abs/2307.09779](http://arxiv.org/abs/2307.09779)

    提出了一种名为ICECREAM的新方法，超越了单一特征重要性的统计方法。该方法利用信息论量化衡量了变量联合对目标变量分布的影响，能够确定一个特定结果所需的关键因素集合。

    

    机器学习模型输出的确定特征集合是哪些？云计算应用失败的原因是哪些组件？本研究通过一种基于联合的可解释性方法ICECREAM，解答了这两个问题。具体来说，我们提出了一种信息论量化方法，用于衡量变量联合对目标变量分布的影响。相比于现有的解释性和因果贡献分析方法，该方法能够确定一个特定结果所需的关键因素集合，而不仅仅是对个体因素进行重要性排序。在合成数据和真实数据的实验中，我们展示了ICECREAM在解释性和根本原因分析方面超越了现有方法，并在两个任务上取得了令人印象深刻的准确性。

    Which set of features was responsible for a certain output of a machine learning model? Which components caused the failure of a cloud computing application? These are just two examples of questions we are addressing in this work by Identifying Coalition-based Explanations for Common and Rare Events in Any Model (ICECREAM). Specifically, we propose an information-theoretic quantitative measure for the influence of a coalition of variables on the distribution of a target variable. This allows us to identify which set of factors is essential to obtain a certain outcome, as opposed to well-established explainability and causal contribution analysis methods which can assign contributions only to individual factors and rank them by their importance. In experiments with synthetic and real-world data, we show that ICECREAM outperforms state-of-the-art methods for explainability and root cause analysis, and achieves impressive accuracy in both tasks.
    
[^40]: 在Minecraft中生成类似红石风格的城市

    Generating Redstone Style Cities in Minecraft. (arXiv:2307.09777v1 [cs.AI])

    [http://arxiv.org/abs/2307.09777](http://arxiv.org/abs/2307.09777)

    本文提出了一个在Minecraft中生成城市的方法，并通过使用不同算法来生成建筑布局，实验结果表明基于启发式的算法对于平坦地图更快找到可接受的布局，而演化布局算法在其他情况下表现更好。

    

    在Minecraft中程序化生成城市为玩家提供了更多多样化场景的可能，也有助于理解和改进其他数字世界和现实世界中的城市设计。本文提出了一个城市生成器，作为参加Minecraft定居生成比赛的参赛作品。生成过程包括植被清理、地形整形、建筑布局生成、路径规划、路灯布置和围墙建设等六个主要步骤。使用了基于启发式的算法、演化布局算法和随机算法来生成建筑布局，并通过在有限时间内在随机地图上生成城市进行测试。实验结果显示，对于平坦地图，基于启发式的算法能更快地找到可接受的建筑布局，而演化布局算法在其他情况下表现更好。

    Procedurally generating cities in Minecraft provides players more diverse scenarios and could help understand and improve the design of cities in other digital worlds and the real world. This paper presents a city generator that was submitted as an entry to the 2023 Edition of Minecraft Settlement Generation Competition for Minecraft. The generation procedure is composed of six main steps, namely vegetation clearing, terrain reshaping, building layout generation, route planning, streetlight placement, and wall construction. Three algorithms, including a heuristic-based algorithm, an evolving layout algorithm, and a random one are applied to generate the building layout, thus determining where to place different redstone style buildings, and tested by generating cities on random maps in limited time. Experimental results show that the heuristic-based algorithm is capable of finding an acceptable building layout faster for flat maps, while the evolving layout algorithm performs better in
    
[^41]: 通过扰动神经网络推断有效连接性：来自合成脑电数据的证据

    Perturbing a Neural Network to Infer Effective Connectivity: Evidence from Synthetic EEG Data. (arXiv:2307.09770v1 [eess.SP])

    [http://arxiv.org/abs/2307.09770](http://arxiv.org/abs/2307.09770)

    该研究提出了一种通过扰动神经网络推断脑内有效连接性的方法。研究使用数据驱动的框架，在经过训练的神经网络中，通过扰动输入信号来计算扰动之后对其他脑区的因果影响，从而揭示了脑区之间的非线性因果关系。测试结果在合成的脑电数据上表现出良好的性能。

    

    识别大脑不同区域之间的因果关系，即有效连接性，对于了解大脑的信息处理和认知功能具有重要洞见。脑电图（EEG）信号显示出脑内复杂的动力学和区域间相互作用。然而，对于表征多个脑区之间非线性因果关系的方法仍相对不够发展。在本研究中，我们提出了一个数据驱动的框架，通过扰动经过训练的神经网络来推断有效连接性。具体而言，我们训练了神经网络（如CNN、vanilla RNN、GRU、LSTM和Transformer），根据历史数据预测未来的EEG信号，然后扰动网络的输入以获取扰动的EEG通道与其他通道之间的有效连接性（EC）。EC反映了扰动一个节点对其他节点的因果影响。性能测试是在由生物合理的Jansen-Rit模型生成的合成EEG上进行的。

    Identifying causal relationships among distinct brain areas, known as effective connectivity, holds key insights into the brain's information processing and cognitive functions. Electroencephalogram (EEG) signals exhibit intricate dynamics and inter-areal interactions within the brain. However, methods for characterizing nonlinear causal interactions among multiple brain regions remain relatively underdeveloped. In this study, we proposed a data-driven framework to infer effective connectivity by perturbing the trained neural networks. Specifically, we trained neural networks (i.e., CNN, vanilla RNN, GRU, LSTM, and Transformer) to predict future EEG signals according to historical data and perturbed the networks' input to obtain effective connectivity (EC) between the perturbed EEG channel and the rest of the channels. The EC reflects the causal impact of perturbing one node on others. The performance was tested on the synthetic EEG generated by a biological-plausible Jansen-Rit model.
    
[^42]: Sig-Splines：时间序列生成模型的通用逼近和凸校准

    Sig-Splines: universal approximation and convex calibration of time series generative models. (arXiv:2307.09767v1 [cs.LG])

    [http://arxiv.org/abs/2307.09767](http://arxiv.org/abs/2307.09767)

    该论文提出了一种新颖的时间序列生成模型，通过将线性变换和签名变换作为传统神经网络的替代，既实现了神经网络的通用性，又引入了模型参数的凸性。

    

    我们提出了一种新颖的多变量离散时间序列数据生成模型。受神经样条流构造的启发，我们的算法将线性变换和签名变换作为传统神经网络的无缝替代。这种方法不仅实现了神经网络固有的通用性，还引入了模型参数的凸性。

    We propose a novel generative model for multivariate discrete-time time series data. Drawing inspiration from the construction of neural spline flows, our algorithm incorporates linear transformations and the signature transform as a seamless substitution for traditional neural networks. This approach enables us to achieve not only the universality property inherent in neural networks but also introduces convexity in the model's parameters.
    
[^43]: 用频率偏差构建更强大的模型

    Towards Building More Robust Models with Frequency Bias. (arXiv:2307.09763v1 [cs.CV])

    [http://arxiv.org/abs/2307.09763](http://arxiv.org/abs/2307.09763)

    该论文提出了一种频率偏好控制模块，通过自适应地重新配置中间特征表示的低频和高频成分，提高了模型在鲁棒性学习中对频率的利用。

    

    尽管深度神经网络在各个领域取得了成功，但对于对抗样本的脆弱性仍然是它们应用广泛的一个主要障碍。最近的一些研究表明，对抗训练的模型强调低频信息的重要性，以达到更高的鲁棒性。虽然已经有一些尝试利用这种频率特性，但直接将低通滤波器应用于输入图像会导致不可逆的信息丢失和对具有不同频率特征的数据集的泛化能力差的问题。本文提出了一种名为频率偏好控制模块的插拔式模块，可以自适应地重新配置中间特征表示的低频和高频成分，更好地利用频率进行鲁棒学习。实证研究表明，我们提出的模块可以轻松地集成到任何对抗训练框架中，并进一步改善其性能。

    The vulnerability of deep neural networks to adversarial samples has been a major impediment to their broad applications, despite their success in various fields. Recently, some works suggested that adversarially-trained models emphasize the importance of low-frequency information to achieve higher robustness. While several attempts have been made to leverage this frequency characteristic, they have all faced the issue that applying low-pass filters directly to input images leads to irreversible loss of discriminative information and poor generalizability to datasets with distinct frequency features. This paper presents a plug-and-play module called the Frequency Preference Control Module that adaptively reconfigures the low- and high-frequency components of intermediate feature representations, providing better utilization of frequency in robust learning. Empirical studies show that our proposed module can be easily incorporated into any adversarial training framework, further improvi
    
[^44]: 通过随机滤波和模式识别强化基于POD的反应扩散复杂网络模型简化技术

    Reinforcing POD based model reduction techniques in reaction-diffusion complex networks using stochastic filtering and pattern recognition. (arXiv:2307.09762v1 [cs.CE])

    [http://arxiv.org/abs/2307.09762](http://arxiv.org/abs/2307.09762)

    该论文提出了一种算法框架，通过将模式识别和随机滤波理论的技术结合起来，强化了基于POD的反应扩散复杂网络模型简化技术，在受扰动输入的情况下提高了代理模型的准确性。

    

    复杂网络被用于建模许多现实世界系统，然而这些系统的维度使得其分析变得困难。在这种情况下，可以使用POD等降维技术。然而，这些模型容易受输入数据扰动的影响。我们提出了一种算法框架，将模式识别和随机滤波理论的技术结合起来，以增强这些模型的输出。研究结果表明，我们的方法可以在受扰动输入的情况下提高代理模型的准确性。深度神经网络(DNNs)容易受到对抗性攻击，然而最近的研究发现，神经常微分方程(ODEs)在特定应用中表现出鲁棒性。我们将我们的算法框架与基于神经ODE的方法进行了基准比较。

    Complex networks are used to model many real-world systems. However, the dimensionality of these systems can make them challenging to analyze. Dimensionality reduction techniques like POD can be used in such cases. However, these models are susceptible to perturbations in the input data. We propose an algorithmic framework that combines techniques from pattern recognition (PR) and stochastic filtering theory to enhance the output of such models. The results of our study show that our method can improve the accuracy of the surrogate model under perturbed inputs. Deep Neural Networks (DNNs) are susceptible to adversarial attacks. However, recent research has revealed that neural Ordinary Differential Equations (ODEs) exhibit robustness in specific applications. We benchmark our algorithmic framework with a Neural ODE-based approach as a reference.
    
[^45]: Space Engage: 基于对比的半监督语义分割的协同空间监督

    Space Engage: Collaborative Space Supervision for Contrastive-based Semi-Supervised Semantic Segmentation. (arXiv:2307.09755v1 [cs.CV])

    [http://arxiv.org/abs/2307.09755](http://arxiv.org/abs/2307.09755)

    基于对比的半监督语义分割方法通常仅依赖于logit空间中的监督，而我们提出了一种协同空间监督方法，利用logit空间和表示空间的输出来提高模型性能和减少过拟合风险。

    

    半监督语义分割旨在利用有限的标记图像和大量的未标记图像训练分割模型。为了提高表示的鲁棒性，强大的方法在潜在空间（即表示空间）中引入了像素级的对比学习方法，以全监督的方式将表示聚合到其原型中。然而，先前基于对比的半监督方法仅依赖于未标记训练中模型输出（logits）在logit空间中的监督。相反，我们利用logit空间和表示空间中的输出来协同获得监督。两个空间的监督发挥两个作用：1）借助表示减少在logits中过度拟合错误的语义信息的风险；2）增强两个空间之间的知识交流。此外，与先前的方法不同，我们使用表示与原型之间的相似性来衡量对比学习的能力，从而提高模型的性能。

    Semi-Supervised Semantic Segmentation (S4) aims to train a segmentation model with limited labeled images and a substantial volume of unlabeled images. To improve the robustness of representations, powerful methods introduce a pixel-wise contrastive learning approach in latent space (i.e., representation space) that aggregates the representations to their prototypes in a fully supervised manner. However, previous contrastive-based S4 methods merely rely on the supervision from the model's output (logits) in logit space during unlabeled training. In contrast, we utilize the outputs in both logit space and representation space to obtain supervision in a collaborative way. The supervision from two spaces plays two roles: 1) reduces the risk of over-fitting to incorrect semantic information in logits with the help of representations; 2) enhances the knowledge exchange between the two spaces. Furthermore, unlike previous approaches, we use the similarity between representations and prototyp
    
[^46]: 信息检索遇上大型语言模型：中国信息检索界的战略报告

    Information Retrieval Meets Large Language Models: A Strategic Report from Chinese IR Community. (arXiv:2307.09751v1 [cs.IR])

    [http://arxiv.org/abs/2307.09751](http://arxiv.org/abs/2307.09751)

    本论文总结了中国信息检索界关于信息检索与大型语言模型相结合的战略报告。大型语言模型在文本理解、生成和知识推理方面具有出色能力，为信息检索研究开辟了新的方向。此外，IR模型、LLM和人类之间的协同关系形成了一种更强大的信息寻求技术范式。然而，该领域仍面临计算成本、可信度、领域特定限制和伦理考虑等挑战。

    

    信息检索（IR）领域已经取得了显著的发展，超越了传统搜索，以满足多样化的用户信息需求。最近，大型语言模型（LLM）在文本理解、生成和知识推理方面展示了出色的能力，为IR研究开辟了新的契机。LLM不仅能够促进生成式检索，还提供了改进的用户理解、模型评估和用户系统交互方案。更重要的是，IR模型、LLM和人类之间的协同关系构成了一种更强大的信息寻求技术范式。IR模型提供实时和相关的信息，LLM贡献内部知识，而人类在信息服务的可靠性方面起着需求者和评估者的中心作用。然而，仍然存在着一些重要挑战，包括计算成本、可信度问题、领域特定限制和伦理考虑。

    The research field of Information Retrieval (IR) has evolved significantly, expanding beyond traditional search to meet diverse user information needs. Recently, Large Language Models (LLMs) have demonstrated exceptional capabilities in text understanding, generation, and knowledge inference, opening up exciting avenues for IR research. LLMs not only facilitate generative retrieval but also offer improved solutions for user understanding, model evaluation, and user-system interactions. More importantly, the synergistic relationship among IR models, LLMs, and humans forms a new technical paradigm that is more powerful for information seeking. IR models provide real-time and relevant information, LLMs contribute internal knowledge, and humans play a central role of demanders and evaluators to the reliability of information services. Nevertheless, significant challenges exist, including computational costs, credibility concerns, domain-specific limitations, and ethical considerations. To 
    
[^47]: 提高语言学习聊天机器人对话质量：对GPT4在ASR错误纠正中的评估

    Enhancing conversational quality in language learning chatbots: An evaluation of GPT4 for ASR error correction. (arXiv:2307.09744v1 [cs.CL])

    [http://arxiv.org/abs/2307.09744](http://arxiv.org/abs/2307.09744)

    本文研究了在语言学习聊天机器人中使用GPT4进行ASR错误纠正的方法，发现GPT4纠正的转录导致更高的对话质量，尽管WER有所增加。

    

    自然语言处理技术（NLP）在教育应用中的整合已经显示出有希望的结果，特别是在语言学习领域。最近，许多口语开放领域的聊天机器人被用作口语伙伴，帮助语言学习者提升语言技能。然而，其中一个重要的挑战是在识别非母语/非流利语音时的高字错误率（WER），这会打断对话流程并令学习者感到失望。本文探讨了在对话环境中使用GPT4进行ASR错误纠正的方法。除了WER，我们还提出使用语义文本相似度（STS）和下一个回复的合理性（NRS）指标来评估错误纠正模型对对话质量的影响。我们发现，由GPT4纠正的转录导致更高的对话质量，尽管WER有所增加。GPT4还优于标准的错误纠正方法，而无需领域专属数据。

    The integration of natural language processing (NLP) technologies into educational applications has shown promising results, particularly in the language learning domain. Recently, many spoken open-domain chatbots have been used as speaking partners, helping language learners improve their language skills. However, one of the significant challenges is the high word-error-rate (WER) when recognizing non-native/non-fluent speech, which interrupts conversation flow and leads to disappointment for learners. This paper explores the use of GPT4 for ASR error correction in conversational settings. In addition to WER, we propose to use semantic textual similarity (STS) and next response sensibility (NRS) metrics to evaluate the impact of error correction models on the quality of the conversation. We find that transcriptions corrected by GPT4 lead to higher conversation quality, despite an increase in WER. GPT4 also outperforms standard error correction methods without the need for in-domain tr
    
[^48]: 多粒度多模态交互网络用于实体链接

    Multi-Grained Multimodal Interaction Network for Entity Linking. (arXiv:2307.09721v1 [cs.AI])

    [http://arxiv.org/abs/2307.09721](http://arxiv.org/abs/2307.09721)

    这篇论文提出了一个名为MIMIC的多粒度多模态交互网络框架，用于解决多模态实体链接任务。该框架解决了多模态之间信息互补不充分和噪声数据导致的性能下降问题。

    

    近年来，多模态实体链接（MEL）任务在解决多模态知识图谱中的含糊提及方面吸引了广泛关注。尽管已经做出了大量努力来探索多个模态之间的互补效应，但它们可能未能充分吸收简写文本上下文和隐含视觉指示的综合表达。更糟糕的是，不可避免的噪声数据可能导致学习过程中不同模态的一致性不足，严重降低性能。为了解决以上问题，本文提出了一个新颖的多粒度多模态交互网络(MIMIC)框架用于解决MEL任务。具体而言，首先将提及和实体的统一输入由文本/视觉编码器分别进行编码，以提取全局描述特征和局部详细特征。然后，为每个提及-实体对派生相似性匹配分数，我们设计了三种交互方法。

    Multimodal entity linking (MEL) task, which aims at resolving ambiguous mentions to a multimodal knowledge graph, has attracted wide attention in recent years. Though large efforts have been made to explore the complementary effect among multiple modalities, however, they may fail to fully absorb the comprehensive expression of abbreviated textual context and implicit visual indication. Even worse, the inevitable noisy data may cause inconsistency of different modalities during the learning process, which severely degenerates the performance. To address the above issues, in this paper, we propose a novel Multi-GraIned Multimodal InteraCtion Network $\textbf{(MIMIC)}$ framework for solving the MEL task. Specifically, the unified inputs of mentions and entities are first encoded by textual/visual encoders separately, to extract global descriptive features and local detailed features. Then, to derive the similarity matching score for each mention-entity pair, we device three interaction u
    
[^49]: 两种故事介绍了用于自主移动控制的连队情报:实现深度学习配方

    Two Tales of Platoon Intelligence for Autonomous Mobility Control: Enabling Deep Learning Recipes. (arXiv:2307.09711v1 [cs.AI])

    [http://arxiv.org/abs/2307.09711](http://arxiv.org/abs/2307.09711)

    本文介绍了基于深度学习的解决自主移动控制和资源管理问题的两个方法：多智能体强化学习和神经迈尔逊拍卖。其中，通信网络是最流行的多智能体强化学习算法之一，将多个智能体的状态和动作训练在一个单一的神经网络中。神经迈尔逊拍卖保证了多个智能体之间的诚信度并实现了最优收益。整合多智能体强化学习和神经迈尔逊拍卖对于实现高效和可靠的自主移动服务至关重要。

    

    本文介绍了基于深度学习的最新成果，以解决自主移动控制和自动驾驶车辆和无人机的高效资源管理问题，即(i)多智能体强化学习（MARL），和(ii)神经迈尔逊拍卖。作为代表，引入了通信网络（CommNet），这是最流行的MARL算法之一，通过训练所有智能体的状态和动作在一个单一的神经网络中，使多个智能体能够以分布式方式采取行动来实现共享目标。此外，神经迈尔逊拍卖保证了多个智能体之间的诚信度，并实现了高度动态系统的最优收益。因此，我们对基于MARL和神经迈尔逊拍卖的自主移动控制的最近研究进行了调查。此外，我们强调，MARL和神经迈尔逊拍卖的整合对于实现高效和可靠的自主移动服务至关重要。

    This paper presents the deep learning-based recent achievements to resolve the problem of autonomous mobility control and efficient resource management of autonomous vehicles and UAVs, i.e., (i) multi-agent reinforcement learning (MARL), and (ii) neural Myerson auction. Representatively, communication network (CommNet), which is one of the most popular MARL algorithms, is introduced to enable multiple agents to take actions in a distributed manner for their shared goals by training all agents' states and actions in a single neural network. Moreover, the neural Myerson auction guarantees trustfulness among multiple agents as well as achieves the optimal revenue of highly dynamic systems. Therefore, we survey the recent studies on autonomous mobility control based on MARL and neural Myerson auction. Furthermore, we emphasize that integration of MARL and neural Myerson auction is expected to be critical for efficient and trustful autonomous mobility services.
    
[^50]: STRAPPER：通过自训练增强和同伴正则化实现基于偏好的强化学习

    STRAPPER: Preference-based Reinforcement Learning via Self-training Augmentation and Peer Regularization. (arXiv:2307.09692v1 [cs.LG])

    [http://arxiv.org/abs/2307.09692](http://arxiv.org/abs/2307.09692)

    本文提出了STRAPPER方法，通过自训练增强和同伴正则化实现基于偏好的强化学习。与其他方法不同的是，作者发现基于偏好的强化学习中存在相似性陷阱现象，即相似的片段对可能会存在截然相反的偏好，对一致性正则化造成影响。

    

    基于偏好的强化学习（PbRL）承诺通过二进制人类偏好学习复杂的奖励函数。然而，这种人类参与的形式需要大量的人力来为片段对分配偏好标签，从而阻碍了其大规模应用。最近的方法尝试重复使用未标记的片段，隐含地阐明了片段的分布，从而减轻了人们的努力。并且进一步考虑了一致性正则化来提高半监督学习的性能。然而，我们注意到，与普通的分类任务不同，PbRL中存在一个我们在本文中定义为相似性陷阱的独特现象。直观地说，人类对于相似的片段对可能会存在截然相反的偏好，但这种相似性可能会导致一致性正则化在PbRL中失败。由于相似性陷阱的存在，这样的一致性正则化不适当地增强了模型预测的一致性可能性。

    Preference-based reinforcement learning (PbRL) promises to learn a complex reward function with binary human preference. However, such human-in-the-loop formulation requires considerable human effort to assign preference labels to segment pairs, hindering its large-scale applications. Recent approache has tried to reuse unlabeled segments, which implicitly elucidates the distribution of segments and thereby alleviates the human effort. And consistency regularization is further considered to improve the performance of semi-supervised learning. However, we notice that, unlike general classification tasks, in PbRL there exits a unique phenomenon that we defined as similarity trap in this paper. Intuitively, human can have diametrically opposite preferredness for similar segment pairs, but such similarity may trap consistency regularization fail in PbRL. Due to the existence of similarity trap, such consistency regularization improperly enhances the consistency possiblity of the model's pr
    
[^51]: Amazon-M2: 一个用于推荐和文本生成的多语言多区域购物会话数据集

    Amazon-M2: A Multilingual Multi-locale Shopping Session Dataset for Recommendation and Text Generation. (arXiv:2307.09688v1 [cs.IR])

    [http://arxiv.org/abs/2307.09688](http://arxiv.org/abs/2307.09688)

    Amazon-M2是一个多语言多区域购物会话数据集，可以增强个性化推荐和理解用户偏好能力。

    

    对于电子商务来说，建模客户购物意图是一个重要的任务，因为它直接影响用户体验和参与度。因此，准确理解客户的偏好对于提供个性化推荐至关重要。基于会话的推荐技术利用客户会话数据来预测他们的下一次互动，已经越来越受到欢迎。然而，现有的会话数据集在项目属性、用户多样性和数据集规模方面存在局限性。因此，它们不能全面地捕捉用户行为和偏好的谱系。为了弥补这一差距，我们提出了Amazon Multilingual Multi-locale Shopping Session Dataset，即Amazon-M2。它是第一个由来自六个不同区域的数百万用户会话组成的多语言数据集，其中产品的主要语言是英语、德语、日语、法语、意大利语和西班牙语。值得注意的是，这个数据集可以帮助我们增强个性化和理解用户偏好能力。

    Modeling customer shopping intentions is a crucial task for e-commerce, as it directly impacts user experience and engagement. Thus, accurately understanding customer preferences is essential for providing personalized recommendations. Session-based recommendation, which utilizes customer session data to predict their next interaction, has become increasingly popular. However, existing session datasets have limitations in terms of item attributes, user diversity, and dataset scale. As a result, they cannot comprehensively capture the spectrum of user behaviors and preferences. To bridge this gap, we present the Amazon Multilingual Multi-locale Shopping Session Dataset, namely Amazon-M2. It is the first multilingual dataset consisting of millions of user sessions from six different locales, where the major languages of products are English, German, Japanese, French, Italian, and Spanish. Remarkably, the dataset can help us enhance personalization and understanding of user preferences, w
    
[^52]: PubMed及其他：生物医学文献检索的最新进展和最佳实践

    PubMed and Beyond: Recent Advances and Best Practices in Biomedical Literature Search. (arXiv:2307.09683v1 [cs.IR])

    [http://arxiv.org/abs/2307.09683](http://arxiv.org/abs/2307.09683)

    本论文总结了生物医学文献检索领域的最新进展和最佳实践，介绍了针对不同生物医学信息需求的文献检索工具，并旨在帮助读者高效满足其信息需求。

    

    生物医学研究产生了丰富的信息，其中很多只能通过文献获取。因此，文献检索是临床和生物医学研究中建立在先前知识基础上的重要工具。尽管人工智能的最新进展已经将功能扩展到了超越基于关键字的搜索，但这些进展可能对临床医生和研究人员来说还比较陌生。为了解决这个问题，本文介绍了一些特定于生物医学领域信息需求的文献检索工具，旨在帮助读者高效地满足他们的信息需求。我们首先对广泛使用的PubMed搜索引擎进行了讨论，包括最新的改进和仍然存在的挑战。然后，我们描述了五种特定信息需求的文献检索工具：1.为循证医学寻找高质量临床研究。2.为精准医学和基因组学检索基因相关信息。3.根据意义搜索。

    Biomedical research yields a wealth of information, much of which is only accessible through the literature. Consequently, literature search is an essential tool for building on prior knowledge in clinical and biomedical research. Although recent improvements in artificial intelligence have expanded functionality beyond keyword-based search, these advances may be unfamiliar to clinicians and researchers. In response, we present a survey of literature search tools tailored to both general and specific information needs in biomedicine, with the objective of helping readers efficiently fulfill their information needs. We first examine the widely used PubMed search engine, discussing recent improvements and continued challenges. We then describe literature search tools catering to five specific information needs: 1. Identifying high-quality clinical research for evidence-based medicine. 2. Retrieving gene-related information for precision medicine and genomics. 3. Searching by meaning, inc
    
[^53]: 什么是可解释模型：一项范围审查

    What's meant by explainable model: A Scoping Review. (arXiv:2307.09673v1 [cs.AI])

    [http://arxiv.org/abs/2307.09673](http://arxiv.org/abs/2307.09673)

    这项研究通过范围审查方法调查了应用人工智能模型并采用事后解释方法的论文，探讨了可解释模型这一术语的含义。

    

    我们经常在描述基于人工智能（AI）的应用的论文标题中看到可解释这个术语。然而，可解释人工智能（XAI）的文献表明，XAI中的解释是特定应用和领域的，因此在用于解释特定应用问题的模型时需要进行评估。此外，文献揭示了事后方法，特别是特征归因方法的性能存在很大差异，暗示它们并不能成为AI可解释性的解决方案。因此，在使用XAI方法时，应在特定应用中评估其信息输出的质量和适用性。基于这些原因，我们使用了范围审查方法来研究应用AI模型和采用事后解释方法的论文，同时将这些模型称为可解释。

    We often see the term explainable in the titles of papers that describe applications based on artificial intelligence (AI). However, the literature in explainable artificial intelligence (XAI) indicates that explanations in XAI are application- and domain-specific, hence requiring evaluation whenever they are employed to explain a model that makes decisions for a specific application problem. Additionally, the literature reveals that the performance of post-hoc methods, particularly feature attribution methods, varies substantially hinting that they do not represent a solution to AI explainability. Therefore, when using XAI methods, the quality and suitability of their information outputs should be evaluated within the specific application. For these reasons, we used a scoping review methodology to investigate papers that apply AI models and adopt methods to generate post-hoc explanations while referring to said models as explainable. This paper investigates whether the term explainabl
    
[^54]: 迈向具有基础模型的统一智能体

    Towards A Unified Agent with Foundation Models. (arXiv:2307.09668v1 [cs.RO])

    [http://arxiv.org/abs/2307.09668](http://arxiv.org/abs/2307.09668)

    本文研究如何在强化学习智能体中嵌入和利用语言模型和视觉语言模型的能力，设计了一个以语言为核心推理工具的框架，并在稀疏奖励的机器人操作环境中测试了该方法。结果显示，该方法在探索效率和数据复用方面具有显著性能提升，并展示了如何通过复用学到的技能解决新任务。

    

    最近，语言模型和视觉语言模型在理解人类意图、推理、场景理解和规划行为等方面展示了前所未有的能力。在这项工作中，我们探讨了如何将这些能力嵌入和利用在强化学习（RL）智能体中。我们设计了一个以语言作为核心推理工具的框架，探索了这如何使智能体能够应对一系列基础RL挑战，如高效探索、复用经验数据、调度技能和从观察中学习，这些传统上需要单独设计的垂直算法。我们在稀疏奖励的模拟机器人操作环境中测试了我们的方法，其中机器人需要堆叠一组物体。我们展示了在探索效率和能够从离线数据集中复用数据方面与基线方法相比的显著性能提升，并且展示了如何通过复用学到的技能解决新任务。

    Language Models and Vision Language Models have recently demonstrated unprecedented capabilities in terms of understanding human intentions, reasoning, scene understanding, and planning-like behaviour, in text form, among many others. In this work, we investigate how to embed and leverage such abilities in Reinforcement Learning (RL) agents. We design a framework that uses language as the core reasoning tool, exploring how this enables an agent to tackle a series of fundamental RL challenges, such as efficient exploration, reusing experience data, scheduling skills, and learning from observations, which traditionally require separate, vertically designed algorithms. We test our method on a sparse-reward simulated robotic manipulation environment, where a robot needs to stack a set of objects. We demonstrate substantial performance improvements over baselines in exploration efficiency and ability to reuse data from offline datasets, and illustrate how to reuse learned skills to solve no
    
[^55]: 使用动态图转换器预测研究社区中的技术专长和能力演进

    Anticipating Technical Expertise and Capability Evolution in Research Communities using Dynamic Graph Transformers. (arXiv:2307.09665v1 [cs.LG])

    [http://arxiv.org/abs/2307.09665](http://arxiv.org/abs/2307.09665)

    这项研究通过使用动态图转换器预测研究社区中的技术专长和能力演进，从而提高了全球安全和核不扩散等领域的预测能力。

    

    能够预测全球技术专长和能力演进趋势对国家和全球安全非常重要，特别是在核不扩散（NN）等安全关键领域和人工智能（AI）等快速兴起的领域。本研究扩展了传统的统计关系学习方法（例如，协作网络中的链接预测），并制定了使用动态异构图表示来预测技术专长和能力演进的问题。我们开发了新的能力来预测不同粒度（例如科学家和机构级别）的协作模式，作者行为和技术能力演进。我们实现了一种动态图转换器（DGT）神经架构，通过（a）预测异构（而不是同构）节点和边缘，并（b）依赖于离散和连续特征，推动了最先进的图神经网络模型的发展。

    The ability to anticipate technical expertise and capability evolution trends globally is essential for national and global security, especially in safety-critical domains like nuclear nonproliferation (NN) and rapidly emerging fields like artificial intelligence (AI). In this work, we extend traditional statistical relational learning approaches (e.g., link prediction in collaboration networks) and formulate a problem of anticipating technical expertise and capability evolution using dynamic heterogeneous graph representations. We develop novel capabilities to forecast collaboration patterns, authorship behavior, and technical capability evolution at different granularities (e.g., scientist and institution levels) in two distinct research fields. We implement a dynamic graph transformer (DGT) neural architecture, which pushes the state-of-the-art graph neural network models by (a) forecasting heterogeneous (rather than homogeneous) nodes and edges, and (b) relying on both discrete -- 
    
[^56]: HAT-CL: 用于连续学习的基于任务的硬注意力PyTorch库

    HAT-CL: A Hard-Attention-to-the-Task PyTorch Library for Continual Learning. (arXiv:2307.09653v1 [cs.LG])

    [http://arxiv.org/abs/2307.09653](http://arxiv.org/abs/2307.09653)

    HAT-CL是一个基于任务的硬注意力PyTorch库，以提供对连续学习中的灾难性遗忘现象的解决方案。它通过改善HAT的可用性和兼容性问题，并提供对现有网络复用的支持，实现了对PyTorch模块的自动化梯度操作和转换。此外，HAT-CL还引入了新颖的掩码操作技术。

    

    连续学习中的灾难性遗忘现象，即神经网络在学习新任务时丧失先前获得的知识，给人们带来了重大挑战。硬注意力任务(HAT)机制在减轻这个问题方面已经显示出潜力，但其实际实现受到了可用性和兼容性问题的影响，并且缺乏对现有网络复用的支持。在本文中，我们介绍了HAT-CL，这是HAT机制的用户友好、与PyTorch兼容的重新设计。HAT-CL不仅自动化了梯度操作，还简化了PyTorch模块转化为HAT模块的过程。它通过提供一套全面的模块，可以无缝地集成到现有的架构中。此外，HAT-CL还提供了与TIMM库平滑集成的可用的HAT网络。除了对HAT的重新设计和重新实现之外，我们还介绍了用于HAT的新颖的掩码操作技术。

    Catastrophic forgetting, the phenomenon in which a neural network loses previously obtained knowledge during the learning of new tasks, poses a significant challenge in continual learning. The Hard-Attention-to-the-Task (HAT) mechanism has shown potential in mitigating this problem, but its practical implementation has been complicated by issues of usability and compatibility, and a lack of support for existing network reuse. In this paper, we introduce HAT-CL, a user-friendly, PyTorch-compatible redesign of the HAT mechanism. HAT-CL not only automates gradient manipulation but also streamlines the transformation of PyTorch modules into HAT modules. It achieves this by providing a comprehensive suite of modules that can be seamlessly integrated into existing architectures. Additionally, HAT-CL offers ready-to-use HAT networks that are smoothly integrated with the TIMM library. Beyond the redesign and reimplementation of HAT, we also introduce novel mask manipulation techniques for HAT,
    
[^57]: VISER: 一种处理信息不对称博弈的可行解决方案概念

    VISER: A Tractable Solution Concept for Games with Information Asymmetry. (arXiv:2307.09652v1 [cs.GT])

    [http://arxiv.org/abs/2307.09652](http://arxiv.org/abs/2307.09652)

    该论文提出了一种名为VISER的解决方案概念，用于处理信息不对称博弈。VISER使得外部观察者能够预测博弈的结果，并允许受害者更好地自卫以及确定攻击者可使用的最具破坏性的攻击方法。通过线性规划，每个玩家的VISER策略可以在多项式时间内计算。论文还将VISER扩展到马尔可夫博弈的马尔可夫完美对应规则，并提出了高效求解方法。

    

    许多现实世界的博弈存在信息不对称问题：一个玩家只知道自己的收益，而另一个玩家拥有完整的游戏信息。例如安全博弈和对抗式多智能体强化学习等关键领域。信息不对称使得传统的解决方案概念如强势斯塔克贝格均衡（SSE）和鲁棒优化均衡（ROE）失效。我们提出了一种新的解决方案概念，称为VISER（受害者安全，剥削者最佳回应）。VISER使得外部观察者能够预测这类博弈的结果。特别地，在安全应用中，VISER允许受害者更好地自卫，并确定攻击者可使用的最具破坏性的攻击方法。我们表明，每个玩家的VISER策略可以通过线性规划在多项式时间内独立计算。我们还将VISER扩展到马尔可夫博弈的马尔可夫完美对应规则，通过一系列的计算可以高效求解。

    Many real-world games suffer from information asymmetry: one player is only aware of their own payoffs while the other player has the full game information. Examples include the critical domain of security games and adversarial multi-agent reinforcement learning. Information asymmetry renders traditional solution concepts such as Strong Stackelberg Equilibrium (SSE) and Robust-Optimization Equilibrium (ROE) inoperative. We propose a novel solution concept called VISER (Victim Is Secure, Exploiter best-Responds). VISER enables an external observer to predict the outcome of such games. In particular, for security applications, VISER allows the victim to better defend itself while characterizing the most damaging attacks available to the attacker. We show that each player's VISER strategy can be computed independently in polynomial time using linear programming (LP). We also extend VISER to its Markov-perfect counterpart for Markov games, which can be solved efficiently using a series of 
    
[^58]: 以骄人战绩：预测大规模协作活动中社区的成功

    With Flying Colors: Predicting Community Success in Large-scale Collaborative Campaigns. (arXiv:2307.09650v1 [cs.SI])

    [http://arxiv.org/abs/2307.09650](http://arxiv.org/abs/2307.09650)

    本研究通过对Reddit的r/place在线社区进行分析，以预测在线社区在大规模协作活动中的成功水平，以及分析社区成员之间的底层动态对成功的影响。

    

    网络社区具有独特的特征，建立社会规范，并在其成员之间展现着不同的动态。在线社区的活动往往导致具体的“离线”行动，对社会产生广泛影响（例如政治街头抗议和与性行为不当有关的规范）。尽管过去二十年中对社区动态、信息传播和在线协作进行了广泛研究，但对衡量在线社区在推动其议程方面有效性的定量研究很少。在这项工作中，我们研究了社区的效果（通过其在竞争性在线活动中的成功水平来衡量）和其成员之间的底层动态之间的对应关系。为此，我们定义了一个新任务：预测Reddit的r/place在线社区的成功水平--这是一个需要社区成员之间协作的大规模分布式实验。我们考虑了一系列成功水平的定义；每个定义表示社区在活动中的不同层面获取成功的能力。

    Online communities develop unique characteristics, establish social norms, and exhibit distinct dynamics among their members. Activity in online communities often results in concrete ``off-line'' actions with a broad societal impact (e.g., political street protests and norms related to sexual misconduct). While community dynamics, information diffusion, and online collaborations have been widely studied in the past two decades, quantitative studies that measure the effectiveness of online communities in promoting their agenda are scarce. In this work, we study the correspondence between the effectiveness of a community, measured by its success level in a competitive online campaign, and the underlying dynamics between its members. To this end, we define a novel task: predicting the success level of online communities in Reddit's r/place - a large-scale distributed experiment that required collaboration between community members. We consider an array of definitions for success level; ea
    
[^59]: 通过关键阶段促进记忆增强型Adam的探索

    Promoting Exploration in Memory-Augmented Adam using Critical Momenta. (arXiv:2307.09638v1 [cs.LG])

    [http://arxiv.org/abs/2307.09638](http://arxiv.org/abs/2307.09638)

    本研究提出了一种记忆增强型Adam方法，通过使用关键动量项的缓冲区来促进对更平坦最小值的探索。实验证明，该方法在标准的监督语言建模和图像分类任务中提高了几种Adam变体的性能。

    

    自适应梯度优化器，特别是Adam，在训练大规模深度学习模型中发挥了重要作用。这种优化器的优势在于其快速收敛性，同时对超参数的选择更加鲁棒。然而，它们通常比非自适应方法泛化效果更差。最近的研究将这种性能差距归因于选择平坦最小值：自适应方法倾向于在损失函数曲面中更尖锐的盆地中寻找解决方案，从而损害了泛化能力。为了克服这个问题，我们提出了一种新的记忆增强型Adam方法，在训练过程中使用关键动量项的缓冲区来促进对更平坦最小值的探索。直观地说，缓冲区的使用使得优化器如果盆地的吸引范围不够宽，就会超出其范围。我们经验性地证明了我们的方法在标准的监督语言建模和图像分类任务上提高了几种Adam变体的性能。

    Adaptive gradient-based optimizers, particularly Adam, have left their mark in training large-scale deep learning models. The strength of such optimizers is that they exhibit fast convergence while being more robust to hyperparameter choice. However, they often generalize worse than non-adaptive methods. Recent studies have tied this performance gap to flat minima selection: adaptive methods tend to find solutions in sharper basins of the loss landscape, which in turn hurts generalization. To overcome this issue, we propose a new memory-augmented version of Adam that promotes exploration towards flatter minima by using a buffer of critical momentum terms during training. Intuitively, the use of the buffer makes the optimizer overshoot outside the basin of attraction if it is not wide enough. We empirically show that our method improves the performance of several variants of Adam on standard supervised language modelling and image classification tasks.
    
[^60]: 带有自动字幕的交通领域视频问答

    Traffic-Domain Video Question Answering with Automatic Captioning. (arXiv:2307.09636v1 [cs.CV])

    [http://arxiv.org/abs/2307.09636](http://arxiv.org/abs/2307.09636)

    本文提出了一种带有自动字幕的交通领域视频问答(TRIVIA)方法，通过将交通领域知识注入到视频语言模型中，实现了显著的准确率提升，对推动该领域的进步具有重要意义。

    

    视频问答(VidQA)在智能交通监控和智能交通系统领域有着显著的潜力，可以促进先进的机器推理能力。然而，在先前的研究中，将城市交通场景知识整合到VidQA系统中的注意力有限。在这项工作中，我们提出了一种新颖的方法，称为带有自动字幕的交通领域视频问答(TRIVIA)，它作为一种弱监督技术，将交通领域知识注入到大型视频语言模型中。从SUTD-TrafficQA任务中获得的实证结果凸显了TRIVIA所取得的显著改进，将代表性视频语言模型的准确率提高了6.5个点(19.88%)，相比于基线设置。这种开创性的方法对推动该领域的进步充满了潜力，激励着研究人员和实践者们发掘其全部潜能。

    Video Question Answering (VidQA) exhibits remarkable potential in facilitating advanced machine reasoning capabilities within the domains of Intelligent Traffic Monitoring and Intelligent Transportation Systems. Nevertheless, the integration of urban traffic scene knowledge into VidQA systems has received limited attention in previous research endeavors. In this work, we present a novel approach termed Traffic-domain Video Question Answering with Automatic Captioning (TRIVIA), which serves as a weak-supervision technique for infusing traffic-domain knowledge into large video-language models. Empirical findings obtained from the SUTD-TrafficQA task highlight the substantial enhancements achieved by TRIVIA, elevating the accuracy of representative video-language models by a remarkable 6.5 points (19.88%) compared to baseline settings. This pioneering methodology holds great promise for driving advancements in the field, inspiring researchers and practitioners alike to unlock the full pot
    
[^61]: 深入探究可解释性深度学习在神经影像学中的应用：一项全面调查

    Looking deeper into interpretable deep learning in neuroimaging: a comprehensive survey. (arXiv:2307.09615v1 [cs.LG])

    [http://arxiv.org/abs/2307.09615](http://arxiv.org/abs/2307.09615)

    本文对可解释的深度学习在神经影像学中的应用进行了全面调查，深度学习模型的易解释性仍然存在挑战，近年来的研究主要集中在如何理解模型决策的直觉，还需探索如何验证解释性方法的可靠性。

    

    深度学习（DL）模型因其能够直接从原始数据中进行端到端学习，减轻了对错误易发特征提取阶段的担忧而备受青睐。最近的DL基于神经影像学的研究也在传统机器学习算法上取得了显著的性能提升。然而，深度学习模型的挑战仍然存在，因为这些模型缺乏透明度，无法成功应用于现实世界的应用中。最近几年，可解释的人工智能（XAI）经历了快速发展，主要用于揭示模型如何作出决策的直觉，这对于安全关键领域如医疗保健、金融和执法机构至关重要。尽管解释性领域取得了显著的进展，但研究人员仍不清楚后期方法揭示了模型学习的哪个方面以及如何验证其可靠性。本文综合评述了可解释的深度学习方法在神经影像学中的应用。

    Deep learning (DL) models have been popular due to their ability to learn directly from the raw data in an end-to-end paradigm, alleviating the concern of a separate error-prone feature extraction phase. Recent DL-based neuroimaging studies have also witnessed a noticeable performance advancement over traditional machine learning algorithms. But the challenges of deep learning models still exist because of the lack of transparency in these models for their successful deployment in real-world applications. In recent years, Explainable AI (XAI) has undergone a surge of developments mainly to get intuitions of how the models reached the decisions, which is essential for safety-critical domains such as healthcare, finance, and law enforcement agencies. While the interpretability domain is advancing noticeably, researchers are still unclear about what aspect of model learning a post hoc method reveals and how to validate its reliability. This paper comprehensively reviews interpretable deep
    
[^62]: 顺序蒙特卡洛学习用于时间序列结构发现

    Sequential Monte Carlo Learning for Time Series Structure Discovery. (arXiv:2307.09607v1 [cs.LG])

    [http://arxiv.org/abs/2307.09607](http://arxiv.org/abs/2307.09607)

    本文提出了一种顺序蒙特卡洛学习的方法，用于自动发现复杂时间序列数据的准确模型。在实验中显示，该方法相对于之前的方法，具有较快的运行速度并能够发现合理的模型结构。

    

    本文提出了一种自动发现复杂时间序列数据准确模型的新方法。在高斯过程时间序列模型的符号空间上工作的贝叶斯非参数先验中，我们提出了一种集成顺序蒙特卡洛（SMC）和旋换MCMC的新型结构学习算法，以实现高效的后验推断。我们的方法可以在“在线”设置中使用，其中新数据顺序地合并在时间中，并且可以在“离线”设置中使用，通过使用历史数据的嵌套子集对后验进行退火。对真实世界的时间序列进行的实验测量结果显示，我们的方法相比之前针对相同模型族的MCMC和贪心搜索结构学习算法可以提供10倍至100倍的运行时间加速。我们使用我们的方法对1,428个计量经济数据集的知名基准进行了首次大规模的高斯过程时间序列结构学习评估。结果表明我们的方法可以发现合理的模型结构。

    This paper presents a new approach to automatically discovering accurate models of complex time series data. Working within a Bayesian nonparametric prior over a symbolic space of Gaussian process time series models, we present a novel structure learning algorithm that integrates sequential Monte Carlo (SMC) and involutive MCMC for highly effective posterior inference. Our method can be used both in "online" settings, where new data is incorporated sequentially in time, and in "offline" settings, by using nested subsets of historical data to anneal the posterior. Empirical measurements on real-world time series show that our method can deliver 10x--100x runtime speedups over previous MCMC and greedy-search structure learning algorithms targeting the same model family. We use our method to perform the first large-scale evaluation of Gaussian process time series structure learning on a prominent benchmark of 1,428 econometric datasets. The results show that our method discovers sensible 
    
[^63]: 使用凸凹表示的Legendre变换将神经网络转化为max-affine样条近似

    A max-affine spline approximation of neural networks using the Legendre transform of a convex-concave representation. (arXiv:2307.09602v1 [cs.LG])

    [http://arxiv.org/abs/2307.09602](http://arxiv.org/abs/2307.09602)

    这项工作提出了一种将神经网络转化为样条表示的新算法，它不再需要凸多边形和分段线性网络操作符的限制，并且可以在整个网络上执行。这项工作不仅填补了神经网络和逼近理论之间的差距，还使得网络特征图的可视化成为可能。

    

    本文提出了一种将神经网络转化为样条表示的新算法。与以前需要凸多边形和分段线性网络操作符来创建max-affine样条形式的方法不同，本文放宽了这个约束。唯一的约束是函数应该是有界的，并且具有明确定义的二阶导数，尽管通过实验表明这并不是严格必需的。这种方法也可以在整个网络上执行，而不是在每个层上独立执行。与以前的工作一样，这填补了神经网络和逼近理论之间的差距，同时也实现了网络特征图的可视化。通过从一系列架构中提取逼近误差和特征图进行数学证明和实验研究。

    This work presents a novel algorithm for transforming a neural network into a spline representation. Unlike previous work that required convex and piecewise-affine network operators to create a max-affine spline alternate form, this work relaxes this constraint. The only constraint is that the function be bounded and possess a well-define second derivative, although this was shown experimentally to not be strictly necessary. It can also be performed over the whole network rather than on each layer independently. As in previous work, this bridges the gap between neural networks and approximation theory but also enables the visualisation of network feature maps. Mathematical proof and experimental investigation of the technique is performed with approximation error and feature maps being extracted from a range of architectures, including convolutional neural networks.
    
[^64]: 梯度反击：如何滤除高频率提高解释性

    Gradient strikes back: How filtering out high frequencies improves explanations. (arXiv:2307.09591v1 [cs.AI])

    [http://arxiv.org/abs/2307.09591](http://arxiv.org/abs/2307.09591)

    本研究发现，基于预测的属性方法与基于梯度的方法产生的属性图具有不同的高频内容，滤除高频率可以提高解释性。

    

    近年来，新型基于预测的属性方法的发展迅猛，逐渐取代了旧的基于梯度的方法来解释深度神经网络的决策。然而，预测型方法为何优于梯度型方法仍不清楚。本文从经验观察开始：这两种方法产生的属性图具有非常不同的功率谱，梯度型方法揭示了比预测型方法更多的高频内容。这一观察引发了多个问题：这种高频信息的来源是什么，它是否真正反映了系统所作出的决策？最后，为什么在多个评价指标下，预测型方法中缺乏高频信息将产生更好的可解释性分数？我们分析了三个代表性的视觉分类模型的梯度，并观察到它包含来自高频的噪声信息。

    Recent years have witnessed an explosion in the development of novel prediction-based attribution methods, which have slowly been supplanting older gradient-based methods to explain the decisions of deep neural networks. However, it is still not clear why prediction-based methods outperform gradient-based ones. Here, we start with an empirical observation: these two approaches yield attribution maps with very different power spectra, with gradient-based methods revealing more high-frequency content than prediction-based methods. This observation raises multiple questions: What is the source of this high-frequency information, and does it truly reflect decisions made by the system? Lastly, why would the absence of high-frequency information in prediction-based methods yield better explainability scores along multiple metrics? We analyze the gradient of three representative visual classification models and observe that it contains noisy information emanating from high-frequencies. Furthe
    
[^65]: 使用深度学习自动化进行纤维材料显微图像中的木材种类检测与分类

    Automating Wood Species Detection and Classification in Microscopic Images of Fibrous Materials with Deep Learning. (arXiv:2307.09588v1 [cs.CV])

    [http://arxiv.org/abs/2307.09588](http://arxiv.org/abs/2307.09588)

    本研究通过深度学习实现了对纤维材料显微图像中硬木种类的自动检测和分类。该方法在性能上与人类专家类似，未来将有助于保护森林资源。

    

    我们开发了一种方法，用于系统地生成大量的破解木材参考图像数据集，并利用此数据生成了九个硬木种属的图像数据。这是通过深度学习，首次自动化识别纤维材料显微图像中硬木种类的基础。我们的方法包括一个灵活的管道，便于对导管元素进行注释。我们比较了不同神经网络架构和超参数的性能。我们提出的方法表现与人类专家相似。将来，这将改善对全球木质纤维产品流的控制，以保护森林。

    We have developed a methodology for the systematic generation of a large image dataset of macerated wood references, which we used to generate image data for nine hardwood genera. This is the basis for a substantial approach to automate, for the first time, the identification of hardwood species in microscopic images of fibrous materials by deep learning. Our methodology includes a flexible pipeline for easy annotation of vessel elements. We compare the performance of different neural network architectures and hyperparameters. Our proposed method performs similarly well to human experts. In the future, this will improve controls on global wood fiber product flows to protect forests.
    
[^66]: 理解开放域聊天机器人中的多轮有害行为

    Understanding Multi-Turn Toxic Behaviors in Open-Domain Chatbots. (arXiv:2307.09579v1 [cs.CR])

    [http://arxiv.org/abs/2307.09579](http://arxiv.org/abs/2307.09579)

    本研究针对开放域聊天机器人中的多轮有害行为问题进行了研究，发现现有工具无法检测出82%导致有害行为的单句都被认为是安全的。通过设计新的攻击方法\toxicbot，我们发现开放域聊天机器人模型可以在多轮对话中触发生成有害回应。

    

    最近自然语言处理和机器学习的进展使得聊天机器人模型如ChatGPT可以与人类用户进行对话。然而，这些模型在非有害的多轮对话中生成有害或有碍的回应能力仍然是一个开放性的研究问题。现有研究关注于单句测试，而我们发现82％因为单一句子而在对话中诱发有害行为的句子被现有工具认为是安全的。在本文中，我们设计了一种新的攻击方法\toxicbot，通过对聊天机器人进行微调与目标开放域聊天机器人进行对话。聊天机器人被微调为受控的会话序列。特别是，每个对话的起始都来自精心设计的提示句子数据集。我们的广泛评估表明，开放域聊天机器人模型可以在多轮对话中触发生成有害回应。

    Recent advances in natural language processing and machine learning have led to the development of chatbot models, such as ChatGPT, that can engage in conversational dialogue with human users. However, the ability of these models to generate toxic or harmful responses during a non-toxic multi-turn conversation remains an open research question. Existing research focuses on single-turn sentence testing, while we find that 82\% of the individual non-toxic sentences that elicit toxic behaviors in a conversation are considered safe by existing tools. In this paper, we design a new attack, \toxicbot, by fine-tuning a chatbot to engage in conversation with a target open-domain chatbot. The chatbot is fine-tuned with a collection of crafted conversation sequences. Particularly, each conversation begins with a sentence from a crafted prompt sentences dataset. Our extensive evaluation shows that open-domain chatbot models can be triggered to generate toxic responses in a multi-turn conversation
    
[^67]: 语法引导综合的强化学习

    Reinforcement Learning for Syntax-Guided Synthesis. (arXiv:2307.09564v1 [cs.AI])

    [http://arxiv.org/abs/2307.09564](http://arxiv.org/abs/2307.09564)

    本论文提出了一种基于树搜索和强化学习的语法引导综合算法，解决了搜索问题复杂性和数据集较小的挑战。

    

    程序综合是根据规范自动生成代码的任务。在语法引导综合（SyGuS）中，规范是一个语法模板和一个逻辑公式的组合，生成的代码被证明满足规范。像SyGuS这样的技术对于确保正确的综合结果至关重要。尽管机器学习在其他类型的程序综合中已经得到广泛应用，但在SyGuS中目前的技术仍然主要依赖自动推理工具和简单的枚举方法。我们假设这是由于搜索问题的复杂性和可用数据集相对较小的原因。在这项工作中，我们通过将通用SyGuS问题构建为树搜索，并基于Monte-Carlo Tree Search (MCTS)提出了一种强化学习引导的SyGuS综合算法。我们的算法结合了学习的策略和值函数与用于平衡探索和利用的树的上限置信度。

    Program synthesis is the task of automatically generating code based on a specification. In Syntax-Guided Synthesis(SyGuS) this specification is a combination of a syntactic template and a logical formula, and any generated code is proven to satisfy both. Techniques like SyGuS are critical to guaranteeing correct synthesis results. Despite the proliferation of machine learning in other types of program synthesis, state-of-the-art techniques in SyGuS are still driven by automated reasoning tools and simple enumeration. We hypothesize this is for two reasons: first the complexity of the search problem, and second the relatively small data sets available. In this work, we tackle these challenges by framing general SyGuS problems as a tree-search, and present a reinforcement learning guided synthesis algorithm for SyGuS based on Monte-Carlo Tree Search (MCTS). Our algorithm incorporates learned policy and value functions combined with the upper confidence bound for trees to balance explora
    
[^68]: 通过多智能体模拟和人工智能提升疏散规划：理解危险环境中的人类行为

    Enhancing Evacuation Planning through Multi-Agent Simulation and Artificial Intelligence: Understanding Human Behavior in Hazardous Environments. (arXiv:2307.09485v1 [cs.MA])

    [http://arxiv.org/abs/2307.09485](http://arxiv.org/abs/2307.09485)

    本文通过使用多智能体模拟和人工智能技术，构建了一个能够捕捉危险环境中个体行为的疏散模型，旨在提高我们对疏散过程的理解并为决策者提供更有效的疏散策略。

    

    本文关注解决危险场所疏散的关键任务，对协调员、活动主办方和管理机构具有重要意义。为了促进有效解决方案的开发，本文运用人工智能技术，特别是多智能体系统，构建了一个疏散模拟模型。由于NetLogo能够全面了解危险环境中压迫情况下人类行为，因此被选为首选模拟工具。本文的主要目标是增进我们对个体在这种压迫情况下的反应和响应的理解。通过利用人工智能和多智能体系统，模拟模型旨在捕捉疏散情景的复杂动态，使决策者和应急规划者能够做出明智决策，实施更高效、更有效的疏散策略。本文致力于促进疏散规划的进展。

    This paper focuses on the crucial task of addressing the evacuation of hazardous places, which holds great importance for coordinators, event hosts, and authorities. To facilitate the development of effective solutions, the paper employs Artificial Intelligence (AI) techniques, specifically Multi-Agent Systems (MAS), to construct a simulation model for evacuation. NetLogo is selected as the simulation tool of choice due to its ability to provide a comprehensive understanding of human behaviour in distressing situations within hazardous environments. The primary objective of this paper is to enhance our comprehension of how individuals react and respond during such distressing situations. By leveraging AI and MAS, the simulation model aims to capture the complex dynamics of evacuation scenarios, enabling policymakers and emergency planners to make informed decisions and implement more efficient and effective evacuation strategies. This paper endeavours to contribute to the advancement o
    
[^69]: Llama 2: 开放基础和优化聊天模型

    Llama 2: Open Foundation and Fine-Tuned Chat Models. (arXiv:2307.09288v1 [cs.CL])

    [http://arxiv.org/abs/2307.09288](http://arxiv.org/abs/2307.09288)

    Llama 2是一个优化的聊天模型，通过fine-tuned技术和安全改进，表现优于开源模型，并可作为闭源模型的替代选择。

    

    在这项工作中，我们开发并发布了Llama 2，一个包含预训练和优化的大型语言模型（LLM），其规模从70亿到700亿参数不等。我们的优化LLM，称为Llama 2-Chat，在对话使用案例中表现优于开源聊天模型。根据我们对有用性和安全性的人工评估结果，它们可能是闭源模型的合适替代品。我们详细描述了我们在Llama 2-Chat的优化和安全性改进方面的方法，以便让社区能够在我们的工作基础上构建并为LLM的负责任发展做出贡献。

    In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closed-source models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.
    
[^70]: M-FLAG：使用冻结语言模型和潜空间几何优化的医学视觉语言预训练

    M-FLAG: Medical Vision-Language Pre-training with Frozen Language Models and Latent Space Geometry Optimization. (arXiv:2307.08347v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2307.08347](http://arxiv.org/abs/2307.08347)

    M-FLAG是一种新颖的医学视觉语言预训练方法，通过利用冻结语言模型和引入正交损失函数来优化潜空间几何关系。在医学影像分类、分割和目标检测任务上，M-FLAG在性能上显著优于现有方法，并且减少了78%的参数量。

    

    医学视觉语言模型可以实现医学影像和临床文本的特征共学习和集成。然而，这些模型训练起来并不容易，并且潜空间表示可以非常复杂。本文提出了一种新颖的医学视觉语言模型预训练和正则化方法。该方法命名为医学视觉语言预训练与冻结语言模型和潜空间几何优化（M-FLAG），利用冻结语言模型来稳定和高效地进行训练，并引入了一种新颖的正交损失函数来协调潜空间几何关系。我们在三个下游任务上展示了预训练模型的潜力：医学影像分类、分割和目标检测。通过对五个公开数据集进行广泛的实验证明，M-FLAG在减少78％的参数的同时，明显优于现有的医学视觉语言预训练方法。值得注意的是，M-FLAG表现出了出色的性能。

    Medical vision-language models enable co-learning and integrating features from medical imaging and clinical text. However, these models are not easy to train and the latent representation space can be complex. Here we propose a novel way for pre-training and regularising medical vision-language models. The proposed method, named Medical vision-language pre-training with Frozen language models and Latent spAce Geometry optimization (M-FLAG), leverages a frozen language model for training stability and efficiency and introduces a novel orthogonality loss to harmonize the latent space geometry. We demonstrate the potential of the pre-trained model on three downstream tasks: medical image classification, segmentation, and object detection. Extensive experiments across five public datasets demonstrate that M-FLAG significantly outperforms existing medical vision-language pre-training approaches and reduces the number of parameters by 78\%. Notably, M-FLAG achieves outstanding performance o
    
[^71]: IntelliGraphs: 用于评估知识图谱生成的数据集

    IntelliGraphs: Datasets for Benchmarking Knowledge Graph Generation. (arXiv:2307.06698v1 [cs.AI])

    [http://arxiv.org/abs/2307.06698](http://arxiv.org/abs/2307.06698)

    IntelliGraphs是一组新的知识图谱数据集，用于评估知识图谱生成。其中包含具有逻辑规则表达的语义的子图，用于评估子图推断的模型。

    

    知识图谱嵌入（KGE）模型用于学习实体和关系的连续表示。文献中一个关键的任务是预测实体之间的缺失链接。然而，知识图谱不仅仅是链接的集合，还具有其结构中的语义。语义在多个下游任务中至关重要，例如查询回答或推理。我们引入了子图推断任务，其中一个模型必须生成可能的并且语义上有效的子图。我们提出了IntelliGraphs，一个包含五个新的知识图谱数据集的集合。IntelliGraphs数据集包含具有逻辑规则表达的语义的子图，用于评估子图推断。我们还设计了产生合成数据集的数据集生成器。我们设计了四个新的基准模型，其中包括基于传统KGE的三个模型。我们评估了它们的表达能力，并展示了这些模型无法捕捉到语义。我们相信这一基准将促进该领域的发展。

    Knowledge Graph Embedding (KGE) models are used to learn continuous representations of entities and relations. A key task in the literature is predicting missing links between entities. However, Knowledge Graphs are not just sets of links but also have semantics underlying their structure. Semantics is crucial in several downstream tasks, such as query answering or reasoning. We introduce the subgraph inference task, where a model has to generate likely and semantically valid subgraphs. We propose IntelliGraphs, a set of five new Knowledge Graph datasets. The IntelliGraphs datasets contain subgraphs with semantics expressed in logical rules for evaluating subgraph inference. We also present the dataset generator that produced the synthetic datasets. We designed four novel baseline models, which include three models based on traditional KGEs. We evaluate their expressiveness and show that these models cannot capture the semantics. We believe this benchmark will encourage the development
    
[^72]: 将基础模型作为代理模型引入：朝着更实用的对抗攻击迈进

    Introducing Foundation Models as Surrogate Models: Advancing Towards More Practical Adversarial Attacks. (arXiv:2307.06608v1 [cs.LG])

    [http://arxiv.org/abs/2307.06608](http://arxiv.org/abs/2307.06608)

    本文将对抗攻击重新设定为下游任务，通过生成图像噪声来满足新兴趋势，并将基础模型引入作为代理模型。虽然基础模型的表现不佳，但通过在特征空间中进行分析，我们发现缺乏对应的特征。

    

    最近，无盒对抗攻击成为了最实用且具有挑战性的攻击方式，攻击者无法访问模型的架构、权重和训练数据。然而，在无盒设置中，对于代理模型选择过程的潜力和灵活性缺乏认识。受到利用基础模型解决下游任务的兴趣的启发，本文采用了1）将对抗攻击重新设定为下游任务，具体而言，是生成图像噪声以满足新兴趋势；2）将基础模型引入作为代理模型的创新思想。通过利用非鲁棒特征的概念，我们阐述了选择代理模型的两个指导原则，以解释为什么基础模型是这一角色的最佳选择。然而，矛盾地的是，我们观察到这些基础模型表现不佳。通过在特征空间中分析这种意外行为，我们归因于缺乏上述指导原则所需的特征。

    Recently, the no-box adversarial attack, in which the attacker lacks access to the model's architecture, weights, and training data, become the most practical and challenging attack setup. However, there is an unawareness of the potential and flexibility inherent in the surrogate model selection process on no-box setting. Inspired by the burgeoning interest in utilizing foundational models to address downstream tasks, this paper adopts an innovative idea that 1) recasting adversarial attack as a downstream task. Specifically, image noise generation to meet the emerging trend and 2) introducing foundational models as surrogate models. Harnessing the concept of non-robust features, we elaborate on two guiding principles for surrogate model selection to explain why the foundational model is an optimal choice for this role. However, paradoxically, we observe that these foundational models underperform. Analyzing this unexpected behavior within the feature space, we attribute the lackluster
    
[^73]: 诊断、反馈、适应性: 用于测试时政策调整的人-机环路框架

    Diagnosis, Feedback, Adaptation: A Human-in-the-Loop Framework for Test-Time Policy Adaptation. (arXiv:2307.06333v1 [cs.LG])

    [http://arxiv.org/abs/2307.06333](http://arxiv.org/abs/2307.06333)

    提出了一种交互式框架，通过从用户那里直接获取反馈来识别个性化的无关紧要的概念，从而进行数据增强并获得适应个性化用户目标的政策。

    

    政策常常由于分布偏移而失效——即当政策在新环境中部署时，状态和奖励发生变化。数据增强可以通过使模型对与任务无关的变化具有不变性来增加鲁棒性。然而，设计者在事先往往不知道哪些概念是无关紧要的，尤其是当不同的最终用户对任务执行方式有不同的偏好时。我们提出了一个互动框架，通过直接从用户那里获得反馈来识别个性化的无关紧要的概念。我们的核心思想是生成反事实演示，使用户能够快速确定可能与任务相关和无关的概念。然后利用无关紧要的概念的知识进行数据增强，从而获得适应于个性化用户目标的政策。我们在离散和连续控制任务上进行实验证实了我们的框架。我们的方法(1)使用户能够……

    Policies often fail due to distribution shift -- changes in the state and reward that occur when a policy is deployed in new environments. Data augmentation can increase robustness by making the model invariant to task-irrelevant changes in the agent's observation. However, designers don't know which concepts are irrelevant a priori, especially when different end users have different preferences about how the task is performed. We propose an interactive framework to leverage feedback directly from the user to identify personalized task-irrelevant concepts. Our key idea is to generate counterfactual demonstrations that allow users to quickly identify possible task-relevant and irrelevant concepts. The knowledge of task-irrelevant concepts is then used to perform data augmentation and thus obtain a policy adapted to personalized user objectives. We present experiments validating our framework on discrete and continuous control tasks with real human users. Our method (1) enables users to 
    
[^74]: 用于超出分布可泛化性的大型视觉语言模型压缩

    Distilling Large Vision-Language Model with Out-of-Distribution Generalizability. (arXiv:2307.03135v1 [cs.CV])

    [http://arxiv.org/abs/2307.03135](http://arxiv.org/abs/2307.03135)

    本文研究了针对大型视觉语言模型的模型压缩方法，将教师模型的视觉表示压缩到学生模型中。研究重点在于超出分布可泛化的问题，并提出了两个原则来增强学生模型的性能。

    

    大型视觉语言模型取得了出色的性能，但其规模和计算要求使它们在资源受限设备和时间敏感任务上的部署变得不切实际。模型压缩是创建更小、更快的模型以保持较大模型性能的有希望的方法。本文研究了将大型视觉语言模型中的视觉表示压缩到轻量级学生模型中的过程，使用小型或中型数据集。值得注意的是，本研究关注的是超出分布（OOD）可泛化的开放词汇问题，这在以往的模型压缩研究中被忽视了。我们从视觉和语言的角度提出了两个原则来增强学生模型的OOD可泛化性：（1）更好地模仿教师的视觉表示空间，并在视觉语言对齐方面谨慎地促进更好的一致性；（2）通过丰富学生模型的自举学习和数据扩充来提高OOD可泛化性。

    Large vision-language models have achieved outstanding performance, but their size and computational requirements make their deployment on resource-constrained devices and time-sensitive tasks impractical. Model distillation, the process of creating smaller, faster models that maintain the performance of larger models, is a promising direction towards the solution. This paper investigates the distillation of visual representations in large teacher vision-language models into lightweight student models using a smallor mid-scale dataset. Notably, this study focuses on open-vocabulary out-of-distribution (OOD) generalization, a challenging problem that has been overlooked in previous model distillation literature. We propose two principles from vision and language modality perspectives to enhance student's OOD generalization: (1) by better imitating teacher's visual representation space, and carefully promoting better coherence in vision-language alignment with the teacher; (2) by enric
    
[^75]: SwinGNN:重新思考在图生成的扩散模型中的置换不变性

    SwinGNN: Rethinking Permutation Invariance in Diffusion Models for Graph Generation. (arXiv:2307.01646v1 [cs.LG])

    [http://arxiv.org/abs/2307.01646](http://arxiv.org/abs/2307.01646)

    本文提出了一种新的图生成扩散模型SwinGNN，通过使用高效的2-WL消息传递网络和移动窗口自注意力，以及结合关键的训练和采样技术，显著提高了图生成样本的质量，并引入了随机置换的后处理技巧转换生成的图形统计量。

    

    基于置换等变网络的扩散模型可以学习图数据的置换不变分布。然而，相对于非不变模型，我们发现这些不变模型遇到了更大的学习挑战，因为1）它们的目标分布更具模态性；2）它们的最优一步去噪得分是具有更多成分的高斯混合物的得分函数。受到这个分析的启发，我们提出了一种非不变的扩散模型，称为“SwinGNN”，它采用了一种高效的边到边的2-WL消息传递网络，并利用SwinTransformers中的移动窗口自注意力。此外，通过系统性的实验和剖析，我们确定了几种关键的训练和采样技术，显著提高了图生成样本的质量。最后，我们引入了一种简单的后处理技巧，即随机置换生成的图，可以证明将任何图转换成图形统计量。

    Diffusion models based on permutation-equivariant networks can learn permutation-invariant distributions for graph data. However, in comparison to their non-invariant counterparts, we have found that these invariant models encounter greater learning challenges since 1) their effective target distributions exhibit more modes; 2) their optimal one-step denoising scores are the score functions of Gaussian mixtures with more components. Motivated by this analysis, we propose a non-invariant diffusion model, called $\textit{SwinGNN}$, which employs an efficient edge-to-edge 2-WL message passing network and utilizes shifted window based self-attention inspired by SwinTransformers. Further, through systematic ablations, we identify several critical training and sampling techniques that significantly improve the sample quality of graph generation. At last, we introduce a simple post-processing trick, $\textit{i.e.}$, randomly permuting the generated graphs, which provably converts any graph ge
    
[^76]: 多智能体强化学习中心理推理作为内在动机的理论

    Theory of Mind as Intrinsic Motivation for Multi-Agent Reinforcement Learning. (arXiv:2307.01158v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.01158](http://arxiv.org/abs/2307.01158)

    本论文提出了一种方法来建立语义有意义、人类可解释的信念，并将其应用于多智能体强化学习中。研究发现，通过预测其他智能体的信念来作为内在奖励信号，可以在多智能体环境中产生良好的效果。

    

    模拟他人内心状态对于人类的社会智能至关重要，并且对于人工智能代理来说，在多智能体环境中也可以提供类似的好处。我们提出了一种通过深度网络模型来建立语义有意义、人类可解释的信念的方法。然后，我们考虑了二阶信念预测的任务。我们认为，每个智能体能够预测其他智能体的信念的能力可以作为多智能体强化学习的内在奖励信号。最后，我们在一个混合的合作竞争环境中呈现了初步的实证结果。

    The ability to model the mental states of others is crucial to human social intelligence, and can offer similar benefits to artificial agents with respect to the social dynamics induced in multi-agent settings. We present a method of grounding semantically meaningful, human-interpretable beliefs within policies modeled by deep networks. We then consider the task of 2nd-order belief prediction. We propose that ability of each agent to predict the beliefs of the other agents can be used as an intrinsic reward signal for multi-agent reinforcement learning. Finally, we present preliminary empirical results in a mixed cooperative-competitive environment.
    
[^77]: 从$O(\sqrt{n})$到$O(\log(n))$的二次规划问题

    From $O(\sqrt n)$ to $O(\log n)$ in Quadratic Programming. (arXiv:2306.15079v1 [math.OC])

    [http://arxiv.org/abs/2306.15079](http://arxiv.org/abs/2306.15079)

    这篇论文提出了一种迭代复杂度为$O(\log(n))$的二次规划优化算法，并通过严格的理论证明验证了该算法的可行性。这一重大突破使得我们从$O(\sqrt{n})$的优化算法过渡到$O(\log(n))$的优化算法，其在大数据和人工智能时代具有重要应用价值。

    

    多年来，数值优化理论一直存在一个困扰，即是否存在一个迭代复杂度为$O(\log(n))$的优化算法。本文通过引入一种全新的优化算法和严格的理论证明来回答这个问题。该算法以有界盒二次规划问题（Box-QP）为起点，许多实际优化问题可以通过对偶理论转化为Box-QP问题。本文首次提出了一个迭代复杂度为$O(\log(n))$的QP算法，尤其是其表现类似于“直接”方法：所需迭代次数是确定性的，精确值为$\left\lceil\log\left(\frac{3.125n}{\epsilon}\right)/\log(1.5625)\right\rceil$。这一重大突破使得我们能够从$O(\sqrt{n})$的优化算法过渡到$O(\log(n))$的优化算法，其出色的可扩展性在当今的大数据和人工智能时代尤为重要。

    A "dark cloud" hangs over numerical optimization theory for decades, namely, whether an optimization algorithm $O(\log(n))$ iteration complexity exists. "Yes", this paper answers, with a new optimization algorithm and strict theory proof. It starts with box-constrained quadratic programming (Box-QP), and many practical optimization problems fall into Box-QP. Smooth quadratic programming (QP) and nonsmooth Lasso can be reformulated as Box-QP via duality theory. It is the first time to present an $O(\log(n))$ iteration complexity QP algorithm, in particular, which behaves like a "direct" method: the required number of iterations is deterministic with exact value $\left\lceil\log\left(\frac{3.125n}{\epsilon}\right)/\log(1.5625)\right\rceil$. This significant breakthrough enables us to transition from the $O(\sqrt{n})$ to the $O(\log(n))$ optimization algorithm, whose amazing scalability is particularly relevant in today's era of big data and artificial intelligence.
    
[^78]: Gradient-based Attribution Methods中Pre或Post-Softmax Scores，哪个更好？

    Pre or Post-Softmax Scores in Gradient-based Attribution Methods, What is Best?. (arXiv:2306.13197v1 [cs.LG])

    [http://arxiv.org/abs/2306.13197](http://arxiv.org/abs/2306.13197)

    在Gradient-based Attribution Methods中，使用Pre Softmax分数或Post Softmax分数的梯度的选择有各自的优缺点，需要根据具体情况进行权衡。

    

    对于工作作为分类器的神经网络的基于梯度的归因方法使用网络分数的梯度。在这里，我们讨论使用Pre Softmax分数和Post Softmax分数的梯度之间的实际差异以及它们各自的优缺点。

    Gradient based attribution methods for neural networks working as classifiers use gradients of network scores. Here we discuss the practical differences between using gradients of pre-softmax scores versus post-softmax scores, and their respective advantages and disadvantages.
    
[^79]: 谁需要知道？最小知识用于最佳协调

    Who Needs to Know? Minimal Knowledge for Optimal Coordination. (arXiv:2306.09309v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.09309](http://arxiv.org/abs/2306.09309)

    该论文研究了在合作游戏中最佳协调所需的最小知识。通过提出一个关于战略相关和不相关信息的二分法以及通过Bellman备份运算符的计算方法，作者证明了在动态游戏中可以有效地确定战略相关信息。在实验中，他们应用该算法分析了标准和部分可观察的Overcooked环境中任务的战略相关信息，并且证明了该算法相较于基线方法具有显著的效率提升。

    

    在合作游戏中与他人进行最佳协调时，了解合作伙伴的信息通常是至关重要的：成功驾驶要求了解在哪一侧驾驶。然而，并非合作伙伴的每个特征在战略上都是相关的：在保持最佳协调的同时，可以忽略驾驶者的精细加速度。我们展示了战略相关和不相关信息之间存在明确定义的二分法。此外，我们还展示，在动态游戏中，这种二分法具有可通过Bellman备份运算符高效计算的紧凑表示。我们将此算法应用于分析标准和部分可观察的Overcooked环境中任务的战略相关信息。理论和实证结果表明，我们的算法比基线方法显著更高效。视频可在https://minknowledge.github.io上获得。

    To optimally coordinate with others in cooperative games, it is often crucial to have information about one's collaborators: successful driving requires understanding which side of the road to drive on. However, not every feature of collaborators is strategically relevant: the fine-grained acceleration of drivers may be ignored while maintaining optimal coordination. We show that there is a well-defined dichotomy between strategically relevant and irrelevant information. Moreover, we show that, in dynamic games, this dichotomy has a compact representation that can be efficiently computed via a Bellman backup operator. We apply this algorithm to analyze the strategically relevant information for tasks in both a standard and a partially observable version of the Overcooked environment. Theoretical and empirical results show that our algorithms are significantly more efficient than baselines. Videos are available at https://minknowledge.github.io.
    
[^80]: 在实时超声病变检测中挖掘负面时间背景以抑制假阳性

    Mining Negative Temporal Contexts For False Positive Suppression In Real-Time Ultrasound Lesion Detection. (arXiv:2305.18060v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.18060](http://arxiv.org/abs/2305.18060)

    该论文提出了一种在超声视频中实时进行病变检测的方法，通过挖掘之前帧中的负面时间背景来抑制假阳性，取得了显著的性能改进。

    

    在超声扫描过程中，实时病变检测可以帮助放射科医生准确诊断癌症。然而，这一关键任务仍然具有挑战性且未被充分探索。当应用于超声视频时，通用实时目标检测模型可能错误地报告明显的假阳性(FPs)，可能误导初级放射科医生。其中一个关键问题是它们未能利用之前帧中的负面症状，即负面时间背景(NTC)。为了解决这个问题，我们提出利用逆光流指导，从之前的帧中提取上下文，包括NTC。通过聚合提取的上下文，我们赋予模型利用NTC抑制FP的能力。我们将结果模型称为UltraDet。所提出的UltraDet在超过之前最先进的模型上取得了显著改进，并实现了实时推理速度。我们在https://github上发布了CVA-BUS数据集的代码、检查点和高质量标签。

    During ultrasonic scanning processes, real-time lesion detection can assist radiologists in accurate cancer diagnosis. However, this essential task remains challenging and underexplored. General-purpose real-time object detection models can mistakenly report obvious false positives (FPs) when applied to ultrasound videos, potentially misleading junior radiologists. One key issue is their failure to utilize negative symptoms in previous frames, denoted as negative temporal contexts (NTC). To address this issue, we propose to extract contexts from previous frames, including NTC, with the guidance of inverse optical flow. By aggregating extracted contexts, we endow the model with the ability to suppress FPs by leveraging NTC. We call the resulting model UltraDet. The proposed UltraDet demonstrates significant improvement over previous state-of-the-arts and achieves real-time inference speed. We release the code, checkpoints, and high-quality labels of the CVA-BUS dataset in https://github
    
[^81]: 带有确定性策略搜索的离策略平均回报行动者-评论家算法

    Off-Policy Average Reward Actor-Critic with Deterministic Policy Search. (arXiv:2305.12239v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.12239](http://arxiv.org/abs/2305.12239)

    本文介绍了带有确定性策略搜索的离策略平均回报行动者-评论家算法，并提出了基于策略和离策略的确定性策略梯度定理。使用这些定理，本文还提出了一种平均回报离策略深度确定性策略梯度算法（ARO-DDPG）。该算法在渐近收敛性分析和有限时间分析中展示了较好的性能，并获得了$\epsilon$-最优稳定策略。

    

    平均回报准则相对较少被研究，因为强化学习文献中的大多数现有工作考虑了贴现回报准则。近期有一些关于基于策略的平均回报行动者-评论家算法的工作，但离策略平均回报行动者-评论家算法相对较少探索。本文提出了关于平均回报性能准则的基于策略和离策略确定性策略梯度定理。利用这些定理，我们还提出了一种平均回报离策略深度确定性策略梯度算法（ARO-DDPG）。我们首先使用基于ODE的方法展示了渐近收敛性分析。随后，我们提供了结果随机逼近方案的有限时间分析，使用线性函数逼近器获得了一个$\epsilon$-最优稳定策略，其样本复杂度为$\Omega(\epsilon^{-2.5})$。我们比较了我们提出的ARO-DDPG算法的平均回报性能，并观察到更好的经验表现。

    The average reward criterion is relatively less studied as most existing works in the Reinforcement Learning literature consider the discounted reward criterion. There are few recent works that present on-policy average reward actor-critic algorithms, but average reward off-policy actor-critic is relatively less explored. In this work, we present both on-policy and off-policy deterministic policy gradient theorems for the average reward performance criterion. Using these theorems, we also present an Average Reward Off-Policy Deep Deterministic Policy Gradient (ARO-DDPG) Algorithm. We first show asymptotic convergence analysis using the ODE-based method. Subsequently, we provide a finite time analysis of the resulting stochastic approximation scheme with linear function approximator and obtain an $\epsilon$-optimal stationary policy with a sample complexity of $\Omega(\epsilon^{-2.5})$. We compare the average reward performance of our proposed ARO-DDPG algorithm and observe better empir
    
[^82]: 在Lenia中捕获新兴复杂性

    Capturing Emerging Complexity in Lenia. (arXiv:2305.09378v1 [cs.NE])

    [http://arxiv.org/abs/2305.09378](http://arxiv.org/abs/2305.09378)

    研究人工生命平台Lenia，通过识别复杂新兴行为的度量标准和使用遗传算法产生不同行为的结果，以进化出更好的Lenia行为。

    

    本研究项目探讨了Lenia，这是一个模拟数字生物系统的人工生命平台。Lenia的生态系统由简单的人工生物组成，它们可以移动、消耗、生长和繁殖。该平台是一个研究人工生命和进化的重要工具，因为它提供了一个可扩展和灵活的环境，用于创建具有不同能力和行为的多样化生物。该研究的关键是在Lenia中测量复杂性，识别测量规则的长期复杂性新兴行为的度量标准，旨在进化出尚未发现的更好的Lenia行为。遗传算法使用相邻区域或核作为基因型，同时保持Lenia的其他参数（例如生长函数）不变，以产生不同人口行为的结果，然后测量适应度值以决定所得行为的复杂性。首先，我们使用时间变化作为适应度函数，

    This research project investigates Lenia, an artificial life platform that simulates ecosystems of digital creatures. Lenia's ecosystem consists of simple, artificial organisms that can move, consume, grow, and reproduce. The platform is important as a tool for studying artificial life and evolution, as it provides a scalable and flexible environment for creating a diverse range of organisms with varying abilities and behaviors. Measuring complexity in Lenia is a key aspect of the study, which identifies the metrics for measuring long-term complex emerging behavior of rules, with the aim of evolving better Lenia behaviors which are yet not discovered. The Genetic Algorithm uses neighborhoods or kernels as genotype while keeping the rest of the parameters of Lenia as fixed, for example growth function, to produce different behaviors respective to the population and then measures fitness value to decide the complexity of the resulting behavior. First, we use Variation over Time as a fitn
    
[^83]: 大纲先行，细节后至：基于语法引导的粗-细代码生成

    Outline, Then Details: Syntactically Guided Coarse-To-Fine Code Generation. (arXiv:2305.00909v2 [cs.PL] UPDATED)

    [http://arxiv.org/abs/2305.00909](http://arxiv.org/abs/2305.00909)

    提出一种基于语法引导的粗-细代码生成模型，支持从粗到细的多次迭代，实现了更加符合人脑思维方式的代码编写方式。

    

    对于一个复杂算法的实现，人类程序员的做法通常是先概述一下控制流程，然后迭代进行丰富，最终生成一些精心加工的语法结构和层次变量。然而，现有的大型语言模型一次性生成代码，没有中间环节，以反映"大纲先行，细节后至"的结构化思维过程。受到思维链提示的最新成功启发，我们提出了ChainCoder，这是一种程序综合语言模型，它逐步生成Python代码，即从粗到细进行多次迭代。我们首先通过抽象语法树解析将源代码分解为布局框架组件和附件组件，以构建层次表示。然后我们将预测目标重新启动，形成多次通过目标，每次生成一个子序列，这些子序列在层次结构中串联起来。最后，我们利用量身定制的Transformer体系结构来实现模型的优化。

    For a complicated algorithm, its implementation by a human programmer usually starts with outlining a rough control flow followed by iterative enrichments, eventually yielding carefully generated syntactic structures and variables in a hierarchy. However, state-of-the-art large language models generate codes in a single pass, without intermediate warm-ups to reflect the structured thought process of "outline-then-detail". Inspired by the recent success of chain-of-thought prompting, we propose ChainCoder, a program synthesis language model that generates Python code progressively, i.e. from coarse to fine in multiple passes. We first decompose source code into layout frame components and accessory components via abstract syntax tree parsing to construct a hierarchical representation. We then reform our prediction target into a multi-pass objective, each pass generates a subsequence, which is concatenated in the hierarchy. Finally, a tailored transformer architecture is leveraged to joi
    
[^84]: 对ChatGPT在需求信息检索中的初步评估

    A Preliminary Evaluation of ChatGPT in Requirements Information Retrieval. (arXiv:2304.12562v1 [cs.SE])

    [http://arxiv.org/abs/2304.12562](http://arxiv.org/abs/2304.12562)

    ChatGPT具备在需求信息检索任务中执行的能力，并且在零-shot设置下获得了可比较或更好的结果。

    

    近期，许多说明性实例显示了ChatGPT在执行编程任务和回答一般领域问题方面的出色能力。本研究目的在于实证评价ChatGPT在需求分析任务中的表现，以此洞察由ChatGPT代表的生成式大语言模型对自然语言处理在需求工程领域的影响。方法是设计了一个评估流程，包括两个常见的需求信息检索任务、包含两种典型需求工件的四个公共数据集、固定任务提示查询ChatGPT，以及定量和定性结果分析。结果显示，ChatGPT在所有数据集中都达到了零-shot设置下可比较或更好的$F\beta$值。定性分析进一步说明了ChatGPT强大的自然语言处理能力和有限的需求工程领域知识。结论是评估了ChatGPT在需求信息检索任务中的表现，并获得了令人满意的结果，突显了其提高需求工程中自然语言处理的潜力。

    Context: Recently, many illustrative examples have shown ChatGPT's impressive ability to perform programming tasks and answer general domain questions.  Objective: We empirically evaluate how ChatGPT performs on requirements analysis tasks to derive insights into how generative large language model, represented by ChatGPT, influence the research and practice of natural language processing for requirements engineering.  Method: We design an evaluation pipeline including two common requirements information retrieval tasks, four public datasets involving two typical requirements artifacts, querying ChatGPT with fixed task prompts, and quantitative and qualitative results analysis.  Results: Quantitative results show that ChatGPT achieves comparable or better $F\beta$ values in all datasets under a zero-shot setting. Qualitative analysis further illustrates ChatGPT's powerful natural language processing ability and limited requirements engineering domain knowledge.  Conclusion: The evaluat
    
[^85]: RoCOCO：稳健的基准MS-COCO评估图文匹配模型的鲁棒性

    RoCOCO: Robust Benchmark MS-COCO to Stress-test Robustness of Image-Text Matching Models. (arXiv:2304.10727v1 [cs.CV])

    [http://arxiv.org/abs/2304.10727](http://arxiv.org/abs/2304.10727)

    本文提出了一个新的评估基准来测试ITM模型的鲁棒性，通过将一些“愚弄”的图片和标题添加到检索池中，在MS COCO数据集上为各种最先进的模型进行鲁棒性测试，揭示了它们的不足之处。

    

    近年来，大规模的视觉语言预训练模型和视觉语义嵌入方法显著提高了MS COCO 5K测试集上图文匹配（ITM）的准确性。然而，当将这些最先进的模型用于实际应用时，它们的鲁棒性仍不清楚。本文提出了一个新的评估基准来测试ITM模型的鲁棒性。为此，我们将各种“愚弄”的图片和标题添加到检索池中。具体而言，我们通过插入不相关的图像来更改图像，并通过替换名词来更改标题，从而改变句子的含义。我们发现，仅仅将这些新创建的图像和标题添加到测试集中就可以降低各种最先进模型的性能（例如，在BLIP中从81.9％降至64.5％，在VSE∞中从66.1％降至37.5％）。我们希望我们的发现能为提高视觉语言模型的鲁棒性和设计更多样化的压力测试提供启示。

    Recently, large-scale vision-language pre-training models and visual semantic embedding methods have significantly improved image-text matching (ITM) accuracy on MS COCO 5K test set. However, it is unclear how robust these state-of-the-art (SOTA) models are when using them in the wild. In this paper, we propose a novel evaluation benchmark to stress-test the robustness of ITM models. To this end, we add various fooling images and captions to a retrieval pool. Specifically, we change images by inserting unrelated images, and change captions by substituting a noun, which can change the meaning of a sentence. We discover that just adding these newly created images and captions to the test set can degrade performances (i.e., Recall@1) of a wide range of SOTA models (e.g., 81.9% $\rightarrow$ 64.5% in BLIP, 66.1% $\rightarrow$ 37.5% in VSE$\infty$). We expect that our findings can provide insights for improving the robustness of the vision-language models and devising more diverse stress-te
    
[^86]: 利用三元组损失进行无监督的动作分割

    Leveraging triplet loss for unsupervised action segmentation. (arXiv:2304.06403v1 [cs.CV])

    [http://arxiv.org/abs/2304.06403](http://arxiv.org/abs/2304.06403)

    本文提出了一种无监督的框架，可以在不需要任何训练数据的情况下，从单个输入视频中学习适用于动作分割任务的动作表示，并使用三元组选择策略和三元组损失来在新的表示空间中发现动作，相对于现有无监督方法实现了更好的时间边界恢复质量。

    

    本文提出了一种全新的无监督框架，可以从单个输入视频中学习适用于动作分割任务的动作表示，而无需任何训练数据。我们的方法是一种深度度量学习方法，基于操作相似度分布的三元组损失和一种有效建模时间和语义先验以在新的表示空间中发现动作的三元组选择策略。在这些条件下，与现有的无监督方法相比，我们成功地恢复了学习到的动作表示中的时间边界，质量更高。我们在两个广泛使用的动作分割任务的基准数据集上评估了所提出的方法，通过在学习的表示上应用通用聚类算法，实现了竞争性能。

    In this paper, we propose a novel fully unsupervised framework that learns action representations suitable for the action segmentation task from the single input video itself, without requiring any training data. Our method is a deep metric learning approach rooted in a shallow network with a triplet loss operating on similarity distributions and a novel triplet selection strategy that effectively models temporal and semantic priors to discover actions in the new representational space. Under these circumstances, we successfully recover temporal boundaries in the learned action representations with higher quality compared with existing unsupervised approaches. The proposed method is evaluated on two widely used benchmark datasets for the action segmentation task and it achieves competitive performance by applying a generic clustering algorithm on the learned representations.
    
[^87]: MagicFusion：通过融合扩散模型提高文本到图像生成的性能

    MagicFusion: Boosting Text-to-Image Generation Performance by Fusing Diffusion Models. (arXiv:2303.13126v1 [cs.CV])

    [http://arxiv.org/abs/2303.13126](http://arxiv.org/abs/2303.13126)

    本论文提出了一种名为SNB的方法，该方法集成了两个文本指导扩散模型的噪声预测，以实现更可控的图像生成，同时不需要额外的训练或注释。

    

    开源AI社区的出现产生了一系列强大的基于文本的扩散模型，这些模型训练在各种数据集上。本文提出了一种名为“Saliency-aware Noise Blending (SNB)” 的简单且有效的方法，可以使融合的文本指导扩散模型实现更可控的生成。实验证明分类器自由指导的响应与生成图像的显着性高度相关，因此我们提出了一种在显着性感知的情况下混合两个扩散模型的预测噪声来信任其专业领域的不同模型的方法。SNB是无需训练即可完成的，并且可以在DDIM采样过程中自动对齐两个噪声空间的语义，而无需额外的注释，例如掩模。大量的实验展示了SNB的显着有效性

    The advent of open-source AI communities has produced a cornucopia of powerful text-guided diffusion models that are trained on various datasets. While few explorations have been conducted on ensembling such models to combine their strengths. In this work, we propose a simple yet effective method called Saliency-aware Noise Blending (SNB) that can empower the fused text-guided diffusion models to achieve more controllable generation. Specifically, we experimentally find that the responses of classifier-free guidance are highly related to the saliency of generated images. Thus we propose to trust different models in their areas of expertise by blending the predicted noises of two diffusion models in a saliency-aware manner. SNB is training-free and can be completed within a DDIM sampling process. Additionally, it can automatically align the semantics of two noise spaces without requiring additional annotations such as masks. Extensive experiments show the impressive effectiveness of SNB
    
[^88]: Sionna RT：无线电传播建模的可微分光线追踪技术

    Sionna RT: Differentiable Ray Tracing for Radio Propagation Modeling. (arXiv:2303.11103v2 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2303.11103](http://arxiv.org/abs/2303.11103)

    Sionna RT是一个GPU加速的开源库，它集成了可微分的光线追踪器，可以用于模拟无线电波传播。这个功能使得可以计算与多个系统和环境参数有关的量的梯度，对于诸如学习无线电材料和优化发射机方向等应用具有重要价值。同时，可微分光线追踪对于新颖的研究方向如数字孪生也是一个关键的推动者。

    

    Sionna是一个基于TensorFlow的GPU加速开源库，用于链路级模拟。自v0.14版本以来，它集成了一个可微分的光线追踪器（RT），用于模拟无线电波传播。这个独特功能允许计算与许多系统和环境参数有关的信道冲激响应和其他相关量的梯度，例如材料特性、天线图案、阵列几何、发射机和接收机的方向和位置。在本文中，我们概述了Sionna RT的关键组成部分，并展示了学习无线电材料和通过梯度下降优化发射机方向等示例应用。虽然经典的光线追踪对于6G研究课题如可重构智能表面、集成感知与通信以及用户定位是一个重要工具，但可微分光线追踪是许多新颖和令人兴奋的研究方向的关键推动者，例如数字孪生。

    Sionna is a GPU-accelerated open-source library for link-level simulations based on TensorFlow. Since release v0.14 it integrates a differentiable ray tracer (RT) for the simulation of radio wave propagation. This unique feature allows for the computation of gradients of the channel impulse response and other related quantities with respect to many system and environment parameters, such as material properties, antenna patterns, array geometries, as well as transmitter and receiver orientations and positions. In this paper, we outline the key components of Sionna RT and showcase example applications such as learning radio materials and optimizing transmitter orientations by gradient descent. While classic ray tracing is a crucial tool for 6G research topics like reconfigurable intelligent surfaces, integrated sensing and communications, as well as user localization, differentiable ray tracing is a key enabler for many novel and exciting research directions, for example, digital twins.
    
[^89]: 可解释图像分类的模式推理

    Schema Inference for Interpretable Image Classification. (arXiv:2303.06635v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.06635](http://arxiv.org/abs/2303.06635)

    本论文提出了一种名为模式推理的新型推理范式，利用先前的深度神经网络(DNN)前向方案学习演绎地推断可解释的预测。通过图匹配策略将图像的视觉概念与场景印象相关联，并设计了一种专用架构称为SchemaNet，以建模输入实例的视觉语义和目标类别的学习抽象想象。还引入了一个通用的Feat2Graph方案以捕捉和利用视觉语义的组合贡献。

    

    在本文中，我们研究了一种称为模式推理的新型推理范式，它通过重建先前的深度神经网络(DNN)前向方案来学习演绎地推断可解释的预测，以模式的哲学认知概念为指导。我们致力于将传统的模型推理流程重新定义为一种图匹配策略，通过类比人类推理机制中的印象匹配，将图像的提取视觉概念与预先计算的场景印象相关联。为此，我们设计了一种精心构建的架构，称为SchemaNet，作为所提出的模式推理概念的专用实例，它将输入实例的视觉语义和目标类别的学习抽象想象都建模为拓扑关系图。同时，为了全局视图中捕捉和利用视觉语义的组合贡献，我们还在SchemaNet中引入了一个通用的Feat2Graph方案。

    In this paper, we study a novel inference paradigm, termed as schema inference, that learns to deductively infer the explainable predictions by rebuilding the prior deep neural network (DNN) forwarding scheme, guided by the prevalent philosophical cognitive concept of schema. We strive to reformulate the conventional model inference pipeline into a graph matching policy that associates the extracted visual concepts of an image with the pre-computed scene impression, by analogy with human reasoning mechanism via impression matching. To this end, we devise an elaborated architecture, termed as SchemaNet, as a dedicated instantiation of the proposed schema inference concept, that models both the visual semantics of input instances and the learned abstract imaginations of target categories as topological relational graphs. Meanwhile, to capture and leverage the compositional contributions of visual semantics in a global view, we also introduce a universal Feat2Graph scheme in SchemaNet to 
    
[^90]: CO-BED：通过贝叶斯实验设计的信息理论上下文优化

    CO-BED: Information-Theoretic Contextual Optimization via Bayesian Experimental Design. (arXiv:2302.14015v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2302.14015](http://arxiv.org/abs/2302.14015)

    CO-BED是一个通用的、与模型无关的框架，用于通过贝叶斯实验设计的信息理论来进行上下文优化。它采用黑箱变分方法同时估计和优化设计，可以适应离散动作，并在多个实验中展示出竞争性能。

    

    我们通过贝叶斯实验设计的视角对上下文优化问题进行了形式化，并提出了CO-BED - 一个通用的、与模型无关的框架，用于使用信息理论原则设计上下文实验。在制定合适的基于信息的目标后，我们采用黑箱变分方法在单一随机梯度方案中同时估计和优化设计。此外，为了适应我们框架中的离散动作，我们提议利用连续松弛方案，这可以自然地集成到我们变分目标中。因此，CO-BED为各种上下文优化问题提供了通用的自动化解决方案。我们在许多实验中演示了其有效性，即使与定制的、特定于模型的替代方法相比，CO-BED也表现出了竞争性能。

    We formalize the problem of contextual optimization through the lens of Bayesian experimental design and propose CO-BED -- a general, model-agnostic framework for designing contextual experiments using information-theoretic principles. After formulating a suitable information-based objective, we employ black-box variational methods to simultaneously estimate it and optimize the designs in a single stochastic gradient scheme. In addition, to accommodate discrete actions within our framework, we propose leveraging continuous relaxation schemes, which can naturally be integrated into our variational objective. As a result, CO-BED provides a general and automated solution to a wide range of contextual optimization problems. We illustrate its effectiveness in a number of experiments, where CO-BED demonstrates competitive performance even when compared to bespoke, model-specific alternatives.
    
[^91]: 在可解释人工智能中的元评估问题：使用MetaQuantus识别可靠的估计器

    The Meta-Evaluation Problem in Explainable AI: Identifying Reliable Estimators with MetaQuantus. (arXiv:2302.07265v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.07265](http://arxiv.org/abs/2302.07265)

    这项研究解决了可解释人工智能领域中关于在缺乏真实解释标签的情况下如何可靠估算解释方法质量的问题。通过对不同质量估计器进行元评估，利用MetaQuantus框架分析了估计器的韧性和反应特征，从而帮助实践者选择最佳的解释方法。

    

    在可解释人工智能（XAI）领域中，确定在没有真实解释标签的情况下最可靠地估算解释方法的质量是一个尚未解决的挑战。解决这个问题至关重要，因为竞争评估方法（或“质量估计器”）生成的评估结果，旨在衡量解释方法的相同性质，经常呈现出不一致的排名。这样的分歧对于实践者来说很难解释，从而使他们难以选择表现最好的解释方法。我们通过对XAI中的不同质量估计器进行元评估（"评估评估方法的过程"）来解决这个问题。我们的新框架MetaQuantus分析了质量估计器的两个互补性性能特征：对噪声的韧性和对随机性的反应，从而避免了对真实标签的需求。

    One of the unsolved challenges in the field of Explainable AI (XAI) is determining how to most reliably estimate the quality of an explanation method in the absence of ground truth explanation labels. Resolving this issue is of utmost importance as the evaluation outcomes generated by competing evaluation methods (or ''quality estimators''), which aim at measuring the same property of an explanation method, frequently present conflicting rankings. Such disagreements can be challenging for practitioners to interpret, thereby complicating their ability to select the best-performing explanation method. We address this problem through a meta-evaluation of different quality estimators in XAI, which we define as ''the process of evaluating the evaluation method''. Our novel framework, MetaQuantus, analyses two complementary performance characteristics of a quality estimator: its resilience to noise and reactivity to randomness, thus circumventing the need for ground truth labels. We demonstr
    
[^92]: CIPER: 使用对比学习和预测学习结合不变和等变表示

    CIPER: Combining Invariant and Equivariant Representations Using Contrastive and Predictive Learning. (arXiv:2302.02330v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.02330](http://arxiv.org/abs/2302.02330)

    CIPER是一个自监督表示学习方法，通过结合不变和等变学习目标来提高性能，适用于具有特定数据增强要求的计算机视觉任务

    

    自监督表示学习方法在计算机视觉领域取得了巨大的成功。最近的研究中，基于增强对比学习方法已经被提出用于学习对预定义的数据增强操作具有不变性或等变性的表示。然而，具有不变或等变特征仅适用于特定的下游任务，取决于所选择的增强方式。当学到的表示不符合任务要求时，可能会导致性能较差。在这里，我们考虑一个能够操作对象视图并知道生成每个视图的动作的主动观察者。我们引入了对比不变和预测等变表示学习（CIPER）。CIPER包括使用一个共享编码器和两个不同的输出头部的不变和等变学习目标。一个输出头部是一个具有最先进对比目标的投影头部，以鼓励不变性

    Self-supervised representation learning (SSRL) methods have shown great success in computer vision. In recent studies, augmentation-based contrastive learning methods have been proposed for learning representations that are invariant or equivariant to pre-defined data augmentation operations. However, invariant or equivariant features favor only specific downstream tasks depending on the augmentations chosen. They may result in poor performance when the learned representation does not match task requirements. Here, we consider an active observer that can manipulate views of an object and has knowledge of the action(s) that generated each view. We introduce Contrastive Invariant and Predictive Equivariant Representation learning (CIPER). CIPER comprises both invariant and equivariant learning objectives using one shared encoder and two different output heads on top of the encoder. One output head is a projection head with a state-of-the-art contrastive objective to encourage invariance 
    
[^93]: 构建复杂结构的层级组成生成器

    Hierarchically Composing Level Generators for the Creation of Complex Structures. (arXiv:2302.01561v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.01561](http://arxiv.org/abs/2302.01561)

    提出了一种层级组合生成器的方法，通过递归组合简单的低级生成器来构建大型和复杂的创作，从而优化目标并设计复杂结构。

    

    过程生成内容（PCG）是一个不断发展的领域，具有在视频游戏行业中的广泛应用和以较低成本创建更好游戏的巨大潜力。然而，PCG的大部分工作集中在生成相对简单的游戏中的关卡，因为设计可优化的目标函数对于复杂环境来说具有挑战性。这限制了PCG在更复杂和现代化的游戏中的适用性，阻碍了其在工业界的应用。我们的工作旨在通过引入一个组成层级生成方法来解决这个限制，该方法递归地组成简单的低级生成器以构建大型和复杂的创造物。这种方法可以轻松优化目标，并通过引用较低级别组件来以可解释的方式设计复杂结构。我们经验性地证明我们的方法优于非组合基准线，更准确地满足设计师的功能需求。

    Procedural content generation (PCG) is a growing field, with numerous applications in the video game industry and great potential to help create better games at a fraction of the cost of manual creation. However, much of the work in PCG is focused on generating relatively straightforward levels in simple games, as it is challenging to design an optimisable objective function for complex settings. This limits the applicability of PCG to more complex and modern titles, hindering its adoption in industry. Our work aims to address this limitation by introducing a compositional level generation method that recursively composes simple low-level generators to construct large and complex creations. This approach allows for easily-optimisable objectives and the ability to design a complex structure in an interpretable way by referencing lower-level components. We empirically demonstrate that our method outperforms a non-compositional baseline by more accurately satisfying a designer's functiona
    
[^94]: ThoughtSource:一个用于大型语言模型推理数据的中央枢纽。

    ThoughtSource: A central hub for large language model reasoning data. (arXiv:2301.11596v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.11596](http://arxiv.org/abs/2301.11596)

    ThoughtSource是一个用于连续思考推理的元数据集和软件库，旨在通过促进对连续思考的定性理解、实证评估和提供训练数据，改进未来的人工智能系统。

    

    最近，像GPT-4这样的大型语言模型在多个任务上展示了令人印象深刻的结果。然而，这些语言模型在复杂推理上仍存在限制，它们的推理过程不透明，容易产生“幻觉”事实，并且存在其潜在偏见的担忧。最近提出了一种称为连续思考提示的技术，让模型以自然语言形式表达推理步骤，以解决这些问题。在这里，我们介绍了ThoughtSource，一个用于连续思考推理的元数据集和软件库。ThoughtSource的目标是通过促进对连续思考的定性理解、实证评估和提供训练数据来改进未来的人工智能系统。ThoughtSource的首次发布集成了六个科学/医学、三个通用领域和五个数学题答案数据集。

    Large language models (LLMs) such as GPT-4 have recently demonstrated impressive results across a wide range of tasks. LLMs are still limited, however, in that they frequently fail at complex reasoning, their reasoning processes are opaque, they are prone to 'hallucinate' facts, and there are concerns about their underlying biases. Letting models verbalize reasoning steps as natural language, a technique known as chain-of-thought prompting, has recently been proposed as a way to address some of these issues. Here we present ThoughtSource, a meta-dataset and software library for chain-of-thought (CoT) reasoning. The goal of ThoughtSource is to improve future artificial intelligence systems by facilitating qualitative understanding of CoTs, enabling empirical evaluations, and providing training data. This first release of ThoughtSource integrates six scientific/medical, three general-domain and five math word question answering datasets.
    
[^95]: Lego-MT: 走向可拆卸的高度多语言机器翻译模型

    Lego-MT: Towards Detachable Models in Massively Multilingual Machine Translation. (arXiv:2212.10551v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10551](http://arxiv.org/abs/2212.10551)

    本文提出了一种可拆卸的多语言机器翻译模型，Lego-MT，以解决现有多语言单体模型在参数干扰和低效推导方面的挑战。进行实验评估表明，该模型具有较高的性能，相比具有10倍规模的模型，在效率和表现方面都更具优势。

    

    多语言神经机器翻译(MNMT)旨在构建一个适用于多个语言方向的统一模型。现有的MNMT单体模型面临两个挑战:语言之间的参数干扰和大型模型的低效推理。本文重新审视了经典的多路径结构，通过将每种语言(或语言组)分配给支持即插即用训练和推理的单独分支，开发出可拆卸模型。为了满足在统一空间中为所有语言学习表示的需要，我们提出了一种新颖的高效训练配方，以此构建一个有效的可拆卸模型，Lego-MT。为了进行公正的比较，我们从OPUS收集数据，构建了一个包括433种语言和13亿个平行数据的翻译基准。实验表明，参数为12亿的Lego-MT带来了3.2个spBLEU的平均增益。它甚至胜过了参数为120亿的M2M-100。所提出的训练配方比并行训练提速了28.2倍。

    Multilingual neural machine translation (MNMT) aims to build a unified model for many language directions. Existing monolithic models for MNMT encounter two challenges: parameter interference among languages and inefficient inference for large models. In this paper, we revisit the classic multi-way structures and develop a detachable model by assigning each language (or group of languages) to an individual branch that supports plug-and-play training and inference. To address the needs of learning representations for all languages in a unified space, we propose a novel efficient training recipe, upon which we build an effective detachable model, Lego-MT. For a fair comparison, we collect data from OPUS and build a translation benchmark covering 433 languages and 1.3B parallel data. Experiments show that Lego-MT with 1.2B parameters brings an average gain of 3.2 spBLEU. It even outperforms M2M-100 with 12B parameters. The proposed training recipe brings a 28.2$\times$ speedup over the co
    
[^96]: API-Miner: 一种API到API规范推荐引擎

    API-Miner: an API-to-API Specification Recommendation Engine. (arXiv:2212.07253v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2212.07253](http://arxiv.org/abs/2212.07253)

    API-Miner是一种API到API规范推荐引擎，具有从OpenAPI规范中提取关键信息的新方法、优化的特征提取技术以及结合多种信号的对数线性概率模型等重要贡献。

    

    在设计大型项目的新API时，开发人员需要做出明智的设计选择，以确保代码库能够可持续增长。为了确保新的API组件设计良好，开发人员可以借鉴现有的API组件。然而，由于缺乏标准化的API设计比较方法，这个学习过程变得耗时且困难。为了填补这一空白，我们开发了API-Miner，根据我们的了解，这是首个API到API规范推荐引擎之一。API-Miner检索与OpenAPI（一种广泛采用的用于描述Web API的语言）编写的相关规范组件。API-Miner提出了几个重要的贡献，包括：（1）从OpenAPI规范中处理和提取关键信息的新方法，（2）为高度技术的API规范领域优化的创新特征提取技术，以及（3）一种结合多种信号以检索相关内容的新型对数线性概率模型。

    When designing a new API for a large project, developers need to make smart design choices so that their code base can grow sustainably. To ensure that new API components are well designed, developers can learn from existing API components. However, the lack of standardized methods for comparing API designs makes this learning process time-consuming and difficult. To address this gap we developed API-Miner, to the best of our knowledge, one of the first API-to-API specification recommendation engines. API-Miner retrieves relevant specification components written in OpenAPI (a widely adopted language used to describe web APIs). API-miner presents several significant contributions, including: (1) novel methods of processing and extracting key information from OpenAPI specifications, (2) innovative feature extraction techniques that are optimized for the highly technical API specification domain, and (3) a novel log-linear probabilistic model that combines multiple signals to retrieve rel
    
[^97]: 在场学习者能否从演示中学习推理概念？

    Can In-context Learners Learn a Reasoning Concept from Demonstrations?. (arXiv:2212.01692v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.01692](http://arxiv.org/abs/2212.01692)

    本文介绍了一种概念性少样本学习方法，以帮助在场学习者学习新技能。通过选择与预测示例共享可能信息的演示，这个方法可以在模型记忆独立的情况下区分模型的在场学习能力。

    

    大型语言模型展示了从少量输入-输出演示中学习新任务的新能力。然而，最近的研究表明，在场学习者大部分依赖于他们的预训练知识，如标签的情感，而不是在输入中找到新的关联性。然而，常用的少样本评估设置使用随机选择的在场演示无法区分模型从演示中学习新技能的能力，因为大部分随机选择的演示并不呈现超越暴露于新任务分布的预测的关系。为了在模型记忆独立的情况下区分模型的在场学习能力，我们引入了一个概念性少样本学习方法，选择与预测示例共享可能信息的演示。我们从注释解释中提取了一组这样的概念，并测量了模型展示这些概念可以获得多少好处。

    Large language models show an emergent ability to learn a new task from a small number of input-output demonstrations. However, recent work shows that in-context learners largely rely on their pre-trained knowledge, such as the sentiment of the labels, instead of finding new associations in the input. However, the commonly-used few-shot evaluation settings using a random selection of in-context demonstrations can not disentangle models' ability to learn a new skill from demonstrations, as most of the randomly-selected demonstrations do not present relations informative for prediction beyond exposing the new task distribution.  To disentangle models' in-context learning ability independent of models' memory, we introduce a Conceptual few-shot learning method selecting the demonstrations sharing a possibly-informative concept with the predicted sample. We extract a set of such concepts from annotated explanations and measure how much can models benefit from presenting these concepts in f
    
[^98]: SurCo：学习用于组合非线性优化问题的线性代理

    SurCo: Learning Linear Surrogates For Combinatorial Nonlinear Optimization Problems. (arXiv:2210.12547v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.12547](http://arxiv.org/abs/2210.12547)

    该论文介绍了一种名为SurCo的方法，通过学习线性代理成本，将组合非线性优化问题转化为线性问题，并通过结合梯度方法和线性组合优化的结构提供了高效解决方案。

    

    在许多实际应用中，具有非线性代价函数和组合约束的优化问题与其线性对应物相比，仍然具有挑战性，难以高效求解。为了弥合这一差距，我们提出了SurCo，它学习线性代理成本，可用于现有的组合求解器，以输出原始非线性组合优化问题的良好解决方案。通过对线性代理求解器进行端到端的学习，通过非线性损失函数微分，将基于梯度的方法的灵活性与线性组合优化的结构相结合。我们提出了三个SurCo变体：SurCo-zero用于单个非线性问题，SurCo-prior用于问题分布，SurCo-hybrid用于结合分布和问题特定信息。我们给出了理论上的直觉动机

    Optimization problems with nonlinear cost functions and combinatorial constraints appear in many real-world applications but remain challenging to solve efficiently compared to their linear counterparts. To bridge this gap, we propose $\textbf{SurCo}$ that learns linear $\underline{\text{Sur}}$rogate costs which can be used in existing $\underline{\text{Co}}$mbinatorial solvers to output good solutions to the original nonlinear combinatorial optimization problem. The surrogate costs are learned end-to-end with nonlinear loss by differentiating through the linear surrogate solver, combining the flexibility of gradient-based methods with the structure of linear combinatorial optimization. We propose three $\texttt{SurCo}$ variants: $\texttt{SurCo}-\texttt{zero}$ for individual nonlinear problems, $\texttt{SurCo}-\texttt{prior}$ for problem distributions, and $\texttt{SurCo}-\texttt{hybrid}$ to combine both distribution and problem-specific information. We give theoretical intuition motiv
    
[^99]: 不同分布的数据价值

    The Value of Out-of-Distribution Data. (arXiv:2208.10967v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.10967](http://arxiv.org/abs/2208.10967)

    不同分布的数据可以对任务的泛化误差产生非单调的影响，使用少量不同分布的数据进行训练是有价值的。

    

    我们期望随着类似任务样本的增加，泛化误差会减小；而随着来自不同分布（OOD）任务样本的增加，泛化误差会增大。在这项工作中，我们展示了一个反直觉的现象：任务的泛化误差可以是样本从OOD任务中的数量的非单调函数。随着OOD样本数量的增加，目标任务的泛化误差在超过一个阈值之前会先减小后增大。换句话说，使用少量OOD数据进行训练是有价值的。我们在合成数据集上使用Fisher线性判别和计算机视觉基准数据集（如MNIST、CIFAR-10、CINIC-10、PACS和DomainNet）上的深度网络来展示和分析这一现象。在我们知道哪些样本属于OOD的理想情况下，我们展示了可以利用目标和OOD经验风险的适当加权目标来利用这些非单调趋势。尽管实际应用有限，但这表明如果我们能够检测到OOD样本，这种方法可能是有价值的。

    We expect the generalization error to improve with more samples from a similar task, and to deteriorate with more samples from an out-of-distribution (OOD) task. In this work, we show a counter-intuitive phenomenon: the generalization error of a task can be a non-monotonic function of the number of OOD samples. As the number of OOD samples increases, the generalization error on the target task improves before deteriorating beyond a threshold. In other words, there is value in training on small amounts of OOD data. We use Fisher's Linear Discriminant on synthetic datasets and deep networks on computer vision benchmarks such as MNIST, CIFAR-10, CINIC-10, PACS and DomainNet to demonstrate and analyze this phenomenon. In the idealistic setting where we know which samples are OOD, we show that these non-monotonic trends can be exploited using an appropriately weighted objective of the target and OOD empirical risk. While its practical utility is limited, this does suggest that if we can det
    
[^100]: 数据增强是一个超参数：精心筛选的自监督对于无监督异常检测的成功产生了幻象。

    Data Augmentation is a Hyperparameter: Cherry-picked Self-Supervision for Unsupervised Anomaly Detection is Creating the Illusion of Success. (arXiv:2208.07734v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.07734](http://arxiv.org/abs/2208.07734)

    这项研究通过广泛的实验，证明数据增强与异常生成机制之间的对齐是自监督学习在无监督异常检测中取得成功的关键，并且在缺乏对齐时，自监督学习甚至可能降低准确性。

    

    自监督学习（SSL）已经成为一种有希望的替代方法，用于为现实世界的问题创建监督信号，避免了手动标注的巨大成本。对于标记异常稀缺或几乎不存在的无监督任务（如异常检测），SSL特别有吸引力。过去已经使用了大量的数据增强函数来进行基于SSL的异常检测（SSAD）的图像数据，并且最近的研究表明数据增强的类型对准确性有着重要影响。受此启发，本研究通过对三种不同检测模型和420个异常检测任务的广泛实验，提供了全面的数字和可视证据，证明数据增强与异常生成机制之间的对齐是SSAD成功的关键，而在缺乏对齐的情况下，SSL甚至可能降低准确性。据我们所知，这是关于图像型SSAD的首次深入研究。

    Self-supervised learning (SSL) has emerged as a promising alternative to create supervisory signals to real-world problems, avoiding the extensive cost of manual labeling. SSL is particularly attractive for unsupervised tasks such as anomaly detection (AD), where labeled anomalies are rare or often nonexistent. A large catalog of augmentation functions has been used for SSL-based AD (SSAD) on image data, and recent works have reported that the type of augmentation has a significant impact on accuracy. Motivated by those, this work sets out to put image-based SSAD under a larger lens and investigate the role of data augmentation in SSAD. Through extensive experiments on 3 different detector models and across 420 AD tasks, we provide comprehensive numerical and visual evidences that the alignment between data augmentation and anomaly-generating mechanism is the key to the success of SSAD, and in the lack thereof, SSL may even impair accuracy. To the best of our knowledge, this is the fir
    
[^101]: 使用动态估计的行动成本进行规划

    Planning with Dynamically Estimated Action Costs. (arXiv:2206.04166v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2206.04166](http://arxiv.org/abs/2206.04166)

    本文介绍了一种使用动态估计的行动成本进行规划的方法，通过选择多个估计器来平衡计算时间和有界估计不确定性，提高了规划的可靠性和可扩展性。

    

    行动成本的信息对于真实世界的人工智能规划应用至关重要。最近的方法不仅依赖于声明性行动模型，还使用黑盒外部行动成本估计器，通常从数据中学习，这些估计器在规划阶段应用。然而，这些估计器可能计算成本高昂，并且产生不确定的值。在本文中，我们提出了一种对行动成本进行广义化的确定性规划方法，该方法可以在多个估计器之间选择行动成本，以在计算时间与有界估计不确定性之间取得平衡。这样可以实现更丰富和更现实的问题表示。重要的是，它允许规划器限制规划的准确性，从而提高可靠性，同时减少不必要的计算负担，这对于处理大规模问题至关重要。我们引入了一种搜索算法，对$A^*$进行泛化，用于解决这样的规划问题，并提出了其他算法扩展。

    Information about action costs is critical for real-world AI planning applications. Rather than rely solely on declarative action models, recent approaches also use black-box external action cost estimators, often learned from data, that are applied during the planning phase. These, however, can be computationally expensive, and produce uncertain values. In this paper we suggest a generalization of deterministic planning with action costs that allows selecting between multiple estimators for action cost, to balance computation time against bounded estimation uncertainty. This enables a much richer -- and correspondingly more realistic -- problem representation. Importantly, it allows planners to bound plan accuracy, thereby increasing reliability, while reducing unnecessary computational burden, which is critical for scaling to large problems. We introduce a search algorithm, generalizing $A^*$, that solves such planning problems, and additional algorithmic extensions. In addition to t
    
[^102]: 元学习参数化技能

    Meta-Learning Parameterized Skills. (arXiv:2206.03597v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.03597](http://arxiv.org/abs/2206.03597)

    提出了一种元学习参数化技能的算法，通过学习可转移的参数化技能并将其综合到新的动作空间中，实现了长期任务的高效学习。实证研究表明，该算法能够使智能体在难以解决的长期任务中取得成功。

    

    我们提出了一种新颖的参数化技能学习算法，旨在学习可转移的参数化技能并将它们综合到支持长期任务高效学习的新动作空间中。我们提出利用离策略元强化学习与以轨迹为中心的平滑项相结合，学习一组参数化技能。我们的智能体可以使用这些学习到的技能构建一个三级层次结构框架，模拟时间扩展参数化动作马尔可夫决策过程。我们进行实证研究表明，所提出的算法使智能体能够解决一组困难的长期任务（障碍课程和机器人操纵）。

    We propose a novel parameterized skill-learning algorithm that aims to learn transferable parameterized skills and synthesize them into a new action space that supports efficient learning in long-horizon tasks. We propose to leverage off-policy Meta-RL combined with a trajectory-centric smoothness term to learn a set of parameterized skills. Our agent can use these learned skills to construct a three-level hierarchical framework that models a Temporally-extended Parameterized Action Markov Decision Process. We empirically demonstrate that the proposed algorithms enable an agent to solve a set of difficult long-horizon (obstacle-course and robot manipulation) tasks.
    
[^103]: 在不确定性贪婪赌博问题中的公平分配规划：概率公平性

    Planning to Fairly Allocate: Probabilistic Fairness in the Restless Bandit Setting. (arXiv:2106.07677v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2106.07677](http://arxiv.org/abs/2106.07677)

    本研究引入了一种概率公平策略ProbFair，如何在不确定性贪婪赌博问题中进行资源分配，并在满足预算约束的同时最大化总期望奖励。实验证明ProbFair在保持效用的同时提供公平性保证。

    

    在预算受限的资源分配中，常常使用不确定性和崩溃赌博模型来描述具有动作相关转移概率的情境，例如在患者之间分配健康干预措施。然而，针对这个规划问题的最先进的Whittle指数方法要么不考虑赌博之间的公平性，要么在保证公平性时激励公平性。因此，我们引入ProbFair，一种概率公平策略，该策略在满足预算约束的同时，最大化总期望奖励，并确保在每个时间步上被选择的概率具有严格的正下界。我们在实际应用中评估了我们的算法，在这个应用中，介入措施支持患者间持续的正压通气（CPAP）疗法的依从性，以及在更广泛的合成转移矩阵类上进行了评估。我们发现ProbFair在提供公平性保证的同时保持了效用。

    Restless and collapsing bandits are often used to model budget-constrained resource allocation in settings where arms have action-dependent transition probabilities, such as the allocation of health interventions among patients. However, state-of-the-art Whittle-index-based approaches to this planning problem either do not consider fairness among arms, or incentivize fairness without guaranteeing it. We thus introduce ProbFair, a probabilistically fair policy that maximizes total expected reward and satisfies the budget constraint while ensuring a strictly positive lower bound on the probability of being pulled at each timestep. We evaluate our algorithm on a real-world application, where interventions support continuous positive airway pressure (CPAP) therapy adherence among patients, as well as on a broader class of synthetic transition matrices. We find that ProbFair preserves utility while providing fairness guarantees.
    
[^104]: 声明性机制设计

    Declarative Mechanism Design. (arXiv:1912.13122v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/1912.13122](http://arxiv.org/abs/1912.13122)

    本文介绍了声明性机制设计的研究，提出了机构神经网络作为一种受管制的人工神经网络，引起人们对人工教学的关注，并提供了初步的答案。

    

    多智能体系统（MAS）和声明性电子机构（DEIs）的调控是过去十年涉及物理和软件智能体以及法律的多学科研究课题，但近年来逐渐演变为2016年起被称为新闻的机器律师。其中一种首次提出限制软件智能体行为的方案是电子机构。然而，随着人工神经网络（ANNs）被重新定义为深度学习（DL），有关DL使用的安全、隐私、伦理和法律问题引起了人工智能（AI）社区的关注。现在，MAS的规范几乎得到正确处理，我们提出将人工神经网络的规范作为一种特殊类型的受管制的人工神经网络，称之为机构神经网络（INN）。本文的主旨是引起人们对人工教学（AT）的关注，并给出一个初步的答案，展示了一种证明性的方法。

    Regulation of Multi-Agent Systems (MAS) and Declarative Electronic Institutions (DEIs) was a multidisciplinary research topic of the past decade involving (Physical and Software) Agents and Law since the beginning, but recently evolved towards News-claimed Robot Lawyer since 2016. One of these first proposals of restricting the behaviour of Software Agentswas Electronic Institutions.However, with the recent reformulation of Artificial Neural Networks (ANNs) as Deep Learning (DL), Security, Privacy,Ethical and Legal issues regarding the use of DL has raised concerns in the Artificial Intelligence (AI) Community. Now that the Regulation of MAS is almost correctly addressed, we propose the Regulation of Artificial Neural Networks as Agent-based Training of a special type of regulated Artificial Neural Network that we call Institutional Neural Network (INN).The main purpose of this paper is to bring attention to Artificial Teaching (AT) and to give a tentative answer showing a proof-of-con
    

