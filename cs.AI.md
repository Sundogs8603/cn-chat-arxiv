# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Forget-Me-Not: Learning to Forget in Text-to-Image Diffusion Models.](http://arxiv.org/abs/2303.17591) | 不忘我是一种高效、低成本的解决文本到图像模型中删除指定的身份、对象或样式的方法。我们还介绍了记忆分数 (M-Score) 和概念基准 (ConceptBench) 来衡量模型生成通用概念的能力。在三个最先进的文本到图像模型上进行的广泛评估显示出了不忘我的有前途结果。 |
| [^2] | [HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace.](http://arxiv.org/abs/2303.17580) | 用ChatGPT作为任务规划工具，利用大型语言模型（LLM）作为控制器来整合现有的AI模型，解决复杂的AI任务。 |
| [^3] | [Multimodal Image-Text Matching Improves Retrieval-based Chest X-Ray Report Generation.](http://arxiv.org/abs/2303.17579) | 本研究提出了一种基于检索的放射性医学报告生成模块 X-REM，它使用图像文本匹配分数来衡量胸部 X 光图像和放射学报告之间的相似度，以进行报告检索，其在多个先前的放射学报告生成模块中表现优异，可有效提高放射学报告的自动生成精度。 |
| [^4] | [Elastic Weight Removal for Faithful and Abstractive Dialogue Generation.](http://arxiv.org/abs/2303.17574) | EWR方法通过费舍尔信息矩阵权衡语音生成模型中个体参数的重要性，提高对话回复的忠实性，取得了很好的效果。 |
| [^5] | [Using AI to Measure Parkinson's Disease Severity at Home.](http://arxiv.org/abs/2303.17573) | 该论文提出了一种使用人工智能系统远程评估帕金森病患者运动表现的方法，该方法可重复用于类似的运动任务，拥有较高的可靠性和准确性。 |
| [^6] | [CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X.](http://arxiv.org/abs/2303.17568) | CodeGeeX是一个多语言模型，具有130亿参数，用于代码生成。经过广泛的实验证明，CodeGeeX在HumanEval-X上的代码生成和翻译任务中表现优异。此外，CodeGeeX可以将程序员的生产力提高22%。 |
| [^7] | [BloombergGPT: A Large Language Model for Finance.](http://arxiv.org/abs/2303.17564) | 本文提出了BloombergGPT，一个500亿参数的金融领域的大型语言模型，其基于Bloomberg的广泛数据来源和通用数据集进行训练。通过混合数据集训练，该模型在金融任务上表现出色，并且不会牺牲在普通任务上的性能。 |
| [^8] | [SoftCLIP: Softer Cross-modal Alignment Makes CLIP Stronger.](http://arxiv.org/abs/2303.17561) | 本文提出了一种柔性跨模态对齐的方法 SoftCLIP，在配对任务中取得了很好的效果。 |
| [^9] | [The AI Act proposal: a new right to technical interpretability?.](http://arxiv.org/abs/2303.17558) | 本文探讨了欧盟的AI法案是否足以表明在其法律框架中存在技术可解释性权利，并进一步探讨了是否需要将其纳入现行立法中。 |
| [^10] | [Factoring the Matrix of Domination: A Critical Review and Reimagination of Intersectionality in AI Fairness.](http://arxiv.org/abs/2303.17555) | 本文通过批判性回顾AI公平性文献中30篇交织性讨论，揭示研究人员普遍缺乏对交织性的整体理解，其一方面将其缩小为在群体子组上进行公平度量的优化，另一方面则在社会背景和权力结构的讨论方面存在欠缺。 |
| [^11] | [Whose Opinions Do Language Models Reflect?.](http://arxiv.org/abs/2303.17548) | 本文通过调查高质量的公共民意调查来创建一个新的数据集OpinionsQA，评估语言模型反映的观点与60个不同人口统计组的观点之间的一致性，发现当前语言模型反映的观点与美国人群组的观点存在巨大差异，甚至通过明确调整LM反映出的观点，仍然无法消除。 |
| [^12] | [PAIR-Diffusion: Object-Level Image Editing with Structure-and-Appearance Paired Diffusion Models.](http://arxiv.org/abs/2303.17546) | 本论文提出了一种采用结构和外观配对扩散模型进行对象级图像编辑的方法，使用户能够精细控制图像中的不同对象属性，同时自动传播注入的外观到具有相似结构的对象。 |
| [^13] | [Quantum Circuit Fidelity Improvement with Long Short-Term Memory Networks.](http://arxiv.org/abs/2303.17523) | 本文提出使用长短期记忆网络解决量子计算中的保真度问题，利用时间序列预测方法预测量子电路的保真度。 |
| [^14] | [On pitfalls (and advantages) of sophisticated large language models.](http://arxiv.org/abs/2303.17511) | 大型语言模型能够超越人类表现，但过度依赖可能会导致严重后果，包括难以区分的机器生成文本和各种形式的欺诈，进而产生新的伦理挑战。 |
| [^15] | [The Full Rights Dilemma for A.I. Systems of Debatable Personhood.](http://arxiv.org/abs/2303.17509) | AI可能具有可争议的人格，因此，将它们看作道德上的人存在严重风险，不将它们视为道德上的人又会有道德错误，这是一个严重的道德困境 |
| [^16] | [Learning in Factored Domains with Information-Constrained Visual Representations.](http://arxiv.org/abs/2303.17508) | 本文提出了一种基于信息约束的视觉表示的因子领域学习模型，该模型能够促进在因子领域中RL任务的学习速度。 |
| [^17] | [Pgx: Hardware-accelerated parallel game simulation for reinforcement learning.](http://arxiv.org/abs/2303.17503) | Pgx是一个用JAX编写的游戏模拟器集合，具有强化学习硬件加速能力，支持并行执行，速度比现有的强化学习库快10倍。 它实现了Backgammon，Shogi和Go等基准测试游戏。 |
| [^18] | [Intention-Aware Decision-Making for Mixed Intersection Scenarios.](http://arxiv.org/abs/2303.17493) | 本文提出了一种适用于城市交通的混合路口的白盒意图感知决策制定框架，用于处理行人和自动驾驶车辆之间的交互，以提高AV的接受度。 |
| [^19] | [Language Models can Solve Computer Tasks.](http://arxiv.org/abs/2303.17491) | 本文研究表明，预训练的大型语言模型代理可以通过一个简单的提示方案使用自然语言执行计算机任务，该方法取得了很好的效果并在MiniWoB++基准测试中超越了监督学习和强化学习方法。 |
| [^20] | [Cost Sensitive GNN-based Imbalanced Learning for Mobile Social Network Fraud Detection.](http://arxiv.org/abs/2303.17486) | 本论文提出了代价敏感图神经网络（CSGNN），用于解决移动社交网络欺诈检测中的图像平衡问题，并在两个开源数据集上实现了显着的改进。 |
| [^21] | [Edge Ranking of Graphs in Transportation Networks using a Graph Neural Network (GNN).](http://arxiv.org/abs/2303.17485) | 本文提出了一种使用图神经网络对交通网络中边缘进行评级的新方法，可以快速准确地确定网络中的重要边缘，而无需计算每个边缘对的边缘介数中心度。 |
| [^22] | [Three-way causal attribute partial order structure analysis.](http://arxiv.org/abs/2303.17482) | 本文提出了一种名为三向因果属性偏序结构（3WCAPOS）的方法，将偏序正式结构分析（POFSA）演变为因果覆盖，从而增强模型的可解释性和分类性能，同时提出了因果因子（CF）概念评估属性和决策属性之间的因果相关性，并结合三向决策构建3WCAPOS，使得结构中节点的纯度更清晰，级别之间的变化更明显。 |
| [^23] | [Seeing What You Said: Talking Face Generation Guided by a Lip Reading Expert.](http://arxiv.org/abs/2303.17480) | 本文提出了一种使用口读专家引导的说话人脸生成方法，通过惩罚不正确的生成结果来提高生成唇部区域的明晰度，使用对比学习方法增强唇语同步性，并使用变压器来同步编码音频和视频。实验证明此方法在视觉质量和明晰度方面具有优势。 |
| [^24] | [All You Need Is Sex for Diversity.](http://arxiv.org/abs/2303.17441) | 研究人员成功地采用理想伴侣表示法来建模遗传规划中的交配偏好，通过自适应进化产生多样化的种群来获得更好的结果。 |
| [^25] | [Robust Multi-Agent Pickup and Delivery with Delays.](http://arxiv.org/abs/2303.17422) | 研究了具有实际应用中常见的不完美执行的多智能体接送问题，并提出了两种通过规划路径来限制不完美执行效果的解决方案，提供了鲁棒性保证。 |
| [^26] | [Explainable Intrusion Detection Systems Using Competitive Learning Techniques.](http://arxiv.org/abs/2303.17387) | 本文提出一种基于竞争学习算法的白盒可解释入侵检测系统，与黑匣子方法相比，能够提供更为可解释的模型，且资源消耗较小。 |
| [^27] | [Complementary Random Masking for RGB-Thermal Semantic Segmentation.](http://arxiv.org/abs/2303.17386) | 本文提出了一种RGB-T图像互补随机蒙版策略和自蒸馏损失，通过防止对单一模式过度依赖，强制网络在一个模态部分可用时进行分割和分类，从而提高了神经网络的准确性和鲁棒性，同时鼓励网络提取互补且有意义的表示。 |
| [^28] | [A Study of Autoregressive Decoders for Multi-Tasking in Computer Vision.](http://arxiv.org/abs/2303.17376) | 本研究着重研究了计算机视觉中的多任务自回归解码器，通过广泛的系统试验分析了任务和数据混合、训练和正则化超参数、条件类型和特异性、模态组合等因素，发现通过冻结预训练编码器，采用小型解码器可接近于单任务基线。 |
| [^29] | [GAT-COBO: Cost-Sensitive Graph Neural Network for Telecom Fraud Detection.](http://arxiv.org/abs/2303.17334) | 本文提出了一种针对电信欺诈检测而设计的图神经网络，名为GAT-COBO。该方法通过设计基于GAT的基本分类器和成本敏感学习器来解决图不平衡问题，实验结果证明其优于现有竞争方法。 |
| [^30] | [The impact of training dataset size and ensemble inference strategies on head and neck auto-segmentation.](http://arxiv.org/abs/2303.17318) | 本文研究了头颈部自动分割模型所需的训练数据集大小和集成方法对其性能的影响，发现250个扫描是训练最准确和最健壮的模型所需的最小数据量，并且集成方法可以在小数据集上发挥作用。 |
| [^31] | [Humans in Humans Out: On GPT Converging Toward Common Sense in both Success and Failure.](http://arxiv.org/abs/2303.17276) | 本文研究了GPT-3、GPT-3.5和GPT-4模型在人类思维模式中的表现, 运用认识论理论提供了符号生成模型，通过实验证实的人类判断数据点以及ETR预测数据点的数量级对模型进行了检验。 |
| [^32] | [Ontology in Hybrid Intelligence: a concise literature review.](http://arxiv.org/abs/2303.17262) | 本文综述了本体论在混合智能中的应用，并探讨了它在缩小人工智能与人类智能差距方面的潜在作用。研究发现，本体论能够提高系统的质量和准确性，并通过启用扩展互操作性、系统工程和可解释、透明系统等方面来发挥更加具体的作用。 |
| [^33] | [Demystifying Misconceptions in Social Bots Research.](http://arxiv.org/abs/2303.17251) | 这篇文章揭示了关于社交机器人研究的普遍误解，强调需要以严谨、公正和负责任的方式讨论虚假信息研究。 |
| [^34] | [Model-agnostic explainable artificial intelligence for object detection in image data.](http://arxiv.org/abs/2303.17249) | 本文设计并实现了一种新的黑盒解释方法——BODEM，它采用了局部和远程掩蔽生成多个版本的输入图像，从而比目前用于解释对象检测的其他三种最先进的方法提供更详细和有用的解释。 |
| [^35] | [Milestones in Autonomous Driving and Intelligent Vehicles: Survey of Surveys.](http://arxiv.org/abs/2303.17220) | 这篇论文提出了一份自动驾驶和智能汽车的总技术调查综述（SoS），总结了其历史，总结了里程碑，并提供了展望、伦理和未来的研究方向。 |
| [^36] | [SynthVSR: Scaling Up Visual Speech Recognition With Synthetic Supervision.](http://arxiv.org/abs/2303.17200) | 本文首次探讨利用合成视觉数据进行可视语音识别（VSR）的潜力，提出的方法SynthVSR通过利用语音驱动的唇部动画模型合成大规模数据，极大地提高了VSR系统的性能。 |
| [^37] | [The Nordic Pile: A 1.2TB Nordic Dataset for Language Modeling.](http://arxiv.org/abs/2303.17183) | 本论文描述了一个包含1.2TB文本的北欧语言数据集，为预训练大型语言模型提供了重要资源，促进了北欧语言的LLMs的开发。 |
| [^38] | [Matrix diagonalization and singular value decomposition: Static SageMath and dynamic ChatGPT juxtaposed.](http://arxiv.org/abs/2303.17163) | 本文通过对SageMath和ChatGPT的调查和比较，旨在为学生提供更深入的矩阵分解理解。 |
| [^39] | [TreePiece: Faster Semantic Parsing via Tree Tokenization.](http://arxiv.org/abs/2303.17161) | 本文提出的TreePiece技术将解析树分割成子树，以加速自回归模型用于语义分析的过程，相比标准自回归提高了4.6倍的解码速度，并在速度相当的情况下准确性更高于非自回归方法。 |
| [^40] | [Discriminative Class Tokens for Text-to-Image Diffusion Models.](http://arxiv.org/abs/2303.17155) | 本文提出了一种基于判别性信息和自由文本的非侵入式微调技术，以实现多样性和高准确率的文本到图像生成模型。 |
| [^41] | [DAMO-StreamNet: Optimizing Streaming Perception in Autonomous Driving.](http://arxiv.org/abs/2303.17144) | DAMO-StreamNet是一个优化自动驾驶中流式感知的框架，它融合了YOLO系列的最新进展，并通过颈部结构、双分支结构、蒸馏机制和实时预测机制等关键创新点，提供了尖端的解决方案。 |
| [^42] | [Understanding the Usability of AI Programming Assistants.](http://arxiv.org/abs/2303.17125) | 人工智能编程助手在快速完成编程任务方面有用，但输出的代码不适合开发者，导致他们不高频接受AI编程助手的初始建议。 |
| [^43] | [Deep Generative Model and Its Applications in Efficient Wireless Network Management: A Tutorial and Case Study.](http://arxiv.org/abs/2303.17114) | 本文探讨了深度生成模型在提高无线网络管理效率方面的应用，提出了一种基于DGMs的管理框架，并进行了一项DGM模型的案例研究。 |
| [^44] | [Contextual Combinatorial Bandits with Probabilistically Triggered Arms.](http://arxiv.org/abs/2303.17110) | 本文研究了带有概率触发臂的情境组合赌博机，在不同条件下设计了C$^2$-UCB-T算法和VAC$^2$-UCB算法，并分别导出了对应的遗憾值上限，为相关应用提供了理论支持。 |
| [^45] | [OpenMix: Exploring Outlier Samples for Misclassification Detection.](http://arxiv.org/abs/2303.17093) | 该论文介绍了一种名为OpenMix的新方法，通过学习拒绝异常样本生成的伪样本来提高深度神经分类器的可靠性，从而检测已知类别的分类错误和未知类别的OOD样本。 |
| [^46] | [Viewpoint: A Theoretical Computer Science Perspective on Consciousness and Artificial General Intelligence.](http://arxiv.org/abs/2303.17075) | 该论文提出了“有意识的图灵机”（CTM）模型，旨在探究意识的理论计算机科学方法。该模型从神经科学和心理学中获益良多，并可作为创建人工通用智能的指导方针。 |
| [^47] | [DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents.](http://arxiv.org/abs/2303.17071) | 本文介绍了一种名为DERA的对话型解决代理，该代理利用LLM的对话能力提高了模型的补全能力。DERA框架化为两个代理类型之间的讨论，可以在医疗对话摘要和护理计划生成方面实现显著改进。 |
| [^48] | [Ideal Abstractions for Decision-Focused Learning.](http://arxiv.org/abs/2303.17062) | 本论文提出了一种通过自动配置输出空间以最小化与决策相关信息的损失来制定简化抽象的机器学习系统的方法。 |
| [^49] | [System Predictor: Grounding Size Estimator for Logic Programs under Answer Set Semantics.](http://arxiv.org/abs/2303.17018) | 系统预测器可以通过估计程序实例化大小来影响系统性能，为答案集编程提供潜在改进。 |
| [^50] | [Advances in apparent conceptual physics reasoning in ChatGPT-4.](http://arxiv.org/abs/2303.17012) | ChatGPT-4是一个基于大规模语言模型训练的对话机器人，能达到接近于物理专家水平的力概念测试成绩，对未来的物理教育和教学有重要意义。 |
| [^51] | [Evaluating GPT-3.5 and GPT-4 Models on Brazilian University Admission Exams.](http://arxiv.org/abs/2303.17003) | 本研究在巴西大学入学考试中评估了GPT-3.5和GPT-4模型，分析了不同提示策略，最终发现GPT-4与Chain-of-Thought提示结合表现最好，在2022年考试中准确率达到了87％。 |
| [^52] | [Does Sparsity Help in Learning Misspecified Linear Bandits?.](http://arxiv.org/abs/2303.16998) | 本文研究了稀疏性在解决不正确线性赌博机问题中的作用，证明了算法可以通过查询$ O(\varepsilon^{-s}d^s) $个操作来获得$O(\varepsilon)$-最优行动，其中$s$是稀疏性参数。 |
| [^53] | [Adapting to the Low-Resource Double-Bind: Investigating Low-Compute Methods on Low-Resource African Languages.](http://arxiv.org/abs/2303.16985) | 本文探讨了在低资源条件下，采用语言适配器等低计算方法在非洲语言上进行NLP研究的有效性，并通过微调实验得出了实现可比性能的结论。 |
| [^54] | [Queer In AI: A Case Study in Community-Led Participatory AI.](http://arxiv.org/abs/2303.16972) | Queer in AI是一个基于社区参与的AI设计案例研究，通过拒绝等级制度而选择去中心化，在酷儿社群内部建立了援助和项目，同时努力改变酷儿社群外的参与者和机构。通过培育AI参与文化，欢迎和赋权边缘化参与者，为AI的参与式设计做出了更广泛的贡献。 |
| [^55] | [Heuristic Search For Physics-Based Problems: Angry Birds in PDDL+.](http://arxiv.org/abs/2303.16967) | 本文探讨了使用PDDL+建模愤怒的小鸟游戏并运用启发式和类似于首选运算符的搜索技术来缓解组合搜索复杂性的方法，并取得了和专门领域的方法相当的表现。 |
| [^56] | [Meta-Learning Parameterized First-Order Optimizers using Differentiable Convex Optimization.](http://arxiv.org/abs/2303.16952) | 该研究提出了使用可微凸优化的元学习框架，将现有的一阶更新规则推广到更广的家族，证明在元学习者有足够类似任务的经验下，可以一步优化一系列线性最小二乘问题。 |
| [^57] | [Concise QBF Encodings for Games on a Grid (extended version).](http://arxiv.org/abs/2303.16949) | 该论文介绍了一种名为BDDL的领域定义语言以进行网格棋盘游戏（如井字游戏，连四，占领游戏，追逐者-逃避者和突破）的统一和简洁的QBF编码方法，通过使用QBF求解器在有限深度上决定胜者。 |
| [^58] | [Are Neural Architecture Search Benchmarks Well Designed? A Deeper Look Into Operation Importance.](http://arxiv.org/abs/2303.16938) | 本论文对当前广泛使用的NAS基准测试进行了经验研究，发现只需一小部分的操作即可生成接近最高性能的架构，同时这些基准测试存在缺点可能影响公平比较并提供不可靠结果。 |
| [^59] | [A New Deep Learning and XAI-Based Algorithm for Features Selection in Genomics.](http://arxiv.org/abs/2303.16914) | 本文提出了一种基于深度学习和可解释人工智能的新算法来选择基因组数据中最有信息的特征，为诊断、预后和精准医学提供支持，并在慢性淋巴细胞白血病数据集上取得了有效结果。 |
| [^60] | [RetClean: Retrieval-Based Data Cleaning Using Foundation Models and Data Lakes.](http://arxiv.org/abs/2303.16909) | 本研究展示了使用ChatGPT对数据进行清洗的可能性，并提出了结合用户提供的数据湖的基于检索的清洗方法，同时还开发了一种在本地部署的RoBERTa模型来解决隐私问题。 |
| [^61] | [Hybrid ACO-CI Algorithm for Beam Design problems.](http://arxiv.org/abs/2303.16908) | 本文介绍了一种基于蚁群算法和Cohort Intelligence算法的混合算法，旨在解决梁设计问题。该算法通过比较已有算法，优化了计算时间，并成功解决了两个机械设计问题。 |
| [^62] | [Deep Learning-Assisted Localisation of Nanoparticles in synthetically generated two-photon microscopy images.](http://arxiv.org/abs/2303.16903) | 本论文提出了一种用于纳米颗粒定位的数据驱动方法，在合成的2PM图像中测试效果良好，可以解释基于强度的方法的失败原因。 |
| [^63] | [Implicit Visual Bias Mitigation by Posterior Estimate Sharpening of a Bayesian Neural Network.](http://arxiv.org/abs/2303.16564) | 该论文提出了一种隐式减轻视觉偏见的方法，使用贝叶斯神经网络，通过后验估计尖锐化，鼓励网络聚焦于不导致高不确定性的中心特征。 |
| [^64] | [Self-accumulative Vision Transformer for Bone Age Assessment Using the Sauvegrain Method.](http://arxiv.org/abs/2303.16557) | 该研究提出了一种基于自累积视觉变换器的方法，应用于骨龄评估。通过应用标记重放和区域注意偏差，该方法有效地挖掘地标之间的关系并学习全局形态特征，使骨龄评估的平均绝对误差比之前的工作降低了0.11。 |
| [^65] | [TraffNet: Learning Causality of Traffic Generation for Road Network Digital Twins.](http://arxiv.org/abs/2303.15954) | TraffNet是一个学习交通量生成原因的深度学习框架，将车辆轨迹数据表示为异构图，利用递归神经网络结构实现了对交通生成原因的预测。 |
| [^66] | [Supervised Masked Knowledge Distillation for Few-Shot Transformers.](http://arxiv.org/abs/2303.15466) | 本文提出了一种新型的有监督的掩蔽知识蒸馏模型（SMKD），在少量标注数据的情况下，将标签信息融入到自蒸馏框架中，有效解决了Transformer在少样本学习中的过拟合和性能下降问题，实验结果在基准数据集上表现出最先进的性能。 |
| [^67] | [Sigmoid Loss for Language Image Pre-Training.](http://arxiv.org/abs/2303.15343) | 本论文提出了适用于语言图像预训练的成对Sigmoid损失函数，可以有效地提高训练批量大小，同时不需要全局查看配对相似性进行归一化，其训练出来的模型在ImageNet上表现良好。 |
| [^68] | [Towards Outcome-Driven Patient Subgroups: A Machine Learning Analysis Across Six Depression Treatment Studies.](http://arxiv.org/abs/2303.15202) | 这项研究使用机器学习分析了六项抑郁症药物治疗研究的数据，并生成了结果导向的患者亚组，为患者的个性化治疗提供了指导。 |
| [^69] | [LONGNN: Spectral GNNs with Learnable Orthonormal Basis.](http://arxiv.org/abs/2303.13750) | 本研究提出了一种谱图神经网络LONGNN，它采用可学习正交标准基，并解决了固定多项式基和非归一化基础所带来的缺陷，经实验证明其在各种图数据集上具有优异的表现。 |
| [^70] | [Data Association Aware POMDP Planning with Hypothesis Pruning Performance Guarantees.](http://arxiv.org/abs/2303.02139) | 提出了一种用于处理具有不确定数据关联的POMDP规划的剪枝算法，通过导出完整假设集与减枝假设子集之间的价值函数边界，建立了使用减枝假设子集造成的最大损失的紧密上界，实验证明此方法在具有挑战性的自主驾驶场景中能够显著节省计算时间并保持合理的性能保证。 |
| [^71] | [Vagueness in Predicates and Objects.](http://arxiv.org/abs/2302.13189) | 本文提出了一种称为变量参考语义学的语义框架，用于建模在谓词和物体中的模糊性和因诸多因素导致的变异性。 |
| [^72] | [On The Coherence of Quantitative Evaluation of Visual Explanations.](http://arxiv.org/abs/2302.10764) | 本研究针对常用神经网络解释方法，探究不同评估度量下的表现以及评估方法之间的比较，发现方法的表现经常不一致且选择评估度量至关重要。 |
| [^73] | [A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT.](http://arxiv.org/abs/2302.09419) | 本文全面回顾了预训练基础模型的最新研究进展和发展历程，包括它们的架构、培训目标、预培训任务、微调策略和评估。同时，讨论了其局限性和未来研究方向。 |
| [^74] | [AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving.](http://arxiv.org/abs/2302.08646) | AutoFed 是一种支持异构感知联邦学习的框架，旨在充分利用自动驾驶车辆上的多模态传感数据，并以此实现稳健的自动驾驶。它通过伪标签和自编码器预训练的方法，在解决分布式AVs上具有异构数据的挑战方面表现良好。 |
| [^75] | ["Correct answers" from the psychology of artificial intelligence.](http://arxiv.org/abs/2302.07267) | 本文使用OpenAI的GPT3.5模型重新复制了Many Labs 2复制项目中的14项研究，其中8项研究的结果被成功复制。然而，对于剩下的6项研究，GPT3.5以极其预定的方式回答了调查问题，导致无法分析这些研究。 |
| [^76] | [LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models.](http://arxiv.org/abs/2212.04088) | 本研究提出了一种新颖的方法LLM-Planner，利用大型语言模型为实体代理进行少样本规划，以实体代理目前所在的环境为基础，增强LLMs生成和更新计划，实验表明其在多任务和快速学习新任务的通用代理的开发中具有很好的表现。 |
| [^77] | [MHCCL: Masked Hierarchical Cluster-Wise Contrastive Learning for Multivariate Time Series.](http://arxiv.org/abs/2212.01141) | 本文提出了一种名为MHCCL的对比学习模型，可以从多元时间序列数据中学习语义丰富的表示，并利用层次聚类结构中的多粒度信息来滤除虚假负样本和补充正样本。 |
| [^78] | [CODA-Prompt: COntinual Decomposed Attention-based Prompting for Rehearsal-Free Continual Learning.](http://arxiv.org/abs/2211.13218) | CODA-Prompt是一种基于分解注意力提示，无需重复训练即可连续学习的方法，相比于其他提示方法具有更好的性能和效率。 |
| [^79] | [ConStruct-VL: Data-Free Continual Structured VL Concepts Learning.](http://arxiv.org/abs/2211.09790) | 该论文介绍了第一个持续的无数据结构化VL概念学习（ConStruct-VL）基准，旨在解决VL模型在结构化VL概念推理方面的瓶颈问题，并提出了一种数据-free的方法。 |
| [^80] | [Effective Audio Classification Network Based on Paired Inverse Pyramid Structure and Dense MLP Block.](http://arxiv.org/abs/2211.02940) | 该论文通过提出基于轻量级音频的配对逆金字塔结构网络和密集多层感知机块网络，实现了在不进行数据增强或模型迁移情况下，对UrbanSound8K数据集和GTAZN数据集的高准确度分类任务。 |
| [^81] | [LongShortNet: Exploring Temporal and Semantic Features Fusion in Streaming Perception.](http://arxiv.org/abs/2210.15518) | LongShortNet是一种基于双路径网络的流式感知方法，它结合了长期时间运动和短期空间语义，实现了时空特征融合。在Argoverse-HD数据集上，LongShortNet表现出优异的检测性能，并且几乎不需要额外的计算成本。 |
| [^82] | [ProContEXT: Exploring Progressive Context Transformer for Tracking.](http://arxiv.org/abs/2210.15511) | 本文提出了基于递进的上下文变换机制的目标跟踪方法 ProContEXT，采用上下文感知的自注意力模块对空间和时间上下文进行编码，逐步利用静态和动态多尺度模板进行准确跟踪。它探索了空间和时间上下文之间的互补性，为基于 transformer 的跟踪器的多上下文建模提供了新的途径。 |
| [^83] | [Decoding Visual Neural Representations by Multimodal Learning of Brain-Visual-Linguistic Features.](http://arxiv.org/abs/2210.06756) | 本文提出了一种通用神经解码方法 BraVL，它利用了脑视觉语言特征的多模态学习，通过产品混合模型推断潜在代码，实现三种模态的协同生成，在解码视觉神经表征方面表现优于现有的最先进方法。 |
| [^84] | [Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset Copyright Protection.](http://arxiv.org/abs/2210.00875) | 本文提出了一种针对数据集版权保护的无害和隐蔽的无目标后门水印方案，可以达到与最先进方案相当或更好的水印效果，并证明对模型性能无害且隐蔽。 |
| [^85] | [Alignment-based conformance checking over probabilistic events.](http://arxiv.org/abs/2209.04309) | 本文介绍了一种基于对齐的概率事件符合性检查算法，该算法考虑到具有较低但足够高概率的活动，以更好地与过程模型对齐。 |
| [^86] | [Improving Small Molecule Generation using Mutual Information Machine.](http://arxiv.org/abs/2208.09016) | MolMIM是用于小分子药物发现的概率自编码器，其学习了一种信息丰富且聚类的潜在空间，并通过促进致密的潜在空间来采样有效的分子。通过与其他模型的比较，证明了MolMIM的更好的生成能力，并展示了其出色的分子优化性能。 |
| [^87] | [Multi-scale Attentive Image De-raining Networks via Neural Architecture Search.](http://arxiv.org/abs/2207.00728) | 本文提出了一种高性能的多尺度注意神经体系结构搜索（MANAS）框架，可用于图像去雨。 该方法自动搜索去雨网络的内部多尺度注意力结构，并采用有效的多尺度训练策略确保模型的鲁棒性。 |
| [^88] | [Segmentation in large-scale cellular electron microscopy with deep learning: A literature survey.](http://arxiv.org/abs/2206.07171) | 本文综述了如何使用深度学习算法来处理大规模的电子显微镜数据集。重点讨论了算法如何应用于细胞和亚细胞结构的分割，并介绍了某些网络体系结构如何克服这些图像所产生的特殊挑战。此外，本文还提供了有关在EM中推动深度学习发展的显著数据集的全面概述，并展望了EM分割的当前趋势和未来前景，特别是在标签-free的EM中。 |
| [^89] | [Fine-grained Image Captioning with CLIP Reward.](http://arxiv.org/abs/2205.13115) | 本研究提出使用CLIP作为奖励函数, 生成更细致、独特的图像标题。通过FineCapEval测试，该方法在客观指标和人类评估方面均优于最先进的模型。 |
| [^90] | [Enhancing Continual Learning with Global Prototypes: Counteracting Negative Representation Drift.](http://arxiv.org/abs/2205.12186) | 该论文提出了一种基于全局原型的持续学习方法，在自监督信息的正则化下学习数据表示，以缓解负面表示漂移问题，并减少持续学习中的灾难性遗忘。 |
| [^91] | [The HaMSE Ontology: Using Semantic Technologies to support Music Representation Interoperability and Musicological Analysis.](http://arxiv.org/abs/2202.05817) | 本论文提出了HaMSE本体论，它可以描述音乐特征并有助于音乐学研究。它通过允许不同音乐表现系统之间的对齐，并描述了一组音乐学特征，可以解决音乐表示和定量和定性数据之间的关系。 |
| [^92] | [CATRO: Channel Pruning via Class-Aware Trace Ratio Optimization.](http://arxiv.org/abs/2110.10921) | 本文提出了基于类感知迹比优化的通道剪枝方法（CATRO），通过特征空间判别度量多通道的联合影响并合并保留通道的层次影响，有效降低计算负担并加速模型推理。 |
| [^93] | [On the Complexity of SHAP-Score-Based Explanations: Tractability via Knowledge Compilation and Non-Approximability Results.](http://arxiv.org/abs/2104.08015) | 该论文证明了对于确定性和可分解的布尔电路，可以在多项式时间内计算$\mathsf{SHAP}$-score，但计算大多数机器学习模型的$\mathsf{SHAP}$-scores是计算上困难的。 |
| [^94] | [Learning in a Small/Big World.](http://arxiv.org/abs/2009.11917) | 这篇论文研究了在小/大世界中最优学习行为的特征，发现随着环境变得更复杂和决策者的认知能力变弱，最优行为逐渐不同。在大世界中，最优学习行为可能表现出多种非贝叶斯学习行为。 |

# 详细

[^1]: “不忘我”：文本到图像扩散模型中的遗忘学习

    Forget-Me-Not: Learning to Forget in Text-to-Image Diffusion Models. (arXiv:2303.17591v1 [cs.CV])

    [http://arxiv.org/abs/2303.17591](http://arxiv.org/abs/2303.17591)

    不忘我是一种高效、低成本的解决文本到图像模型中删除指定的身份、对象或样式的方法。我们还介绍了记忆分数 (M-Score) 和概念基准 (ConceptBench) 来衡量模型生成通用概念的能力。在三个最先进的文本到图像模型上进行的广泛评估显示出了不忘我的有前途结果。

    

    深度学习模型的遗忘问题曾一度是学术界的主要关注点，但如今已成为产业界的普遍问题。文本到图像生成技术的重大进展引发了全球对隐私、版权和安全的讨论，因为这些模型学习了大量未授权的个人身份、内容、艺术创作和潜在的有害物质，随后用于生成和分发无控制的内容。为了解决这一挑战，我们提出了“不忘我”，这是一种高效、低成本的解决方案，旨在安全地从文本到图像模型中删除指定的身份、对象或样式，只需不到30秒的时间，而不会影响其生成其他内容的能力。在我们的方法之外，我们引入了“记忆分数 (M-Score)”和“概念基准 (ConceptBench)”来衡量模型生成通用概念的能力，分为三个主要类别：ID、对象和样式。使用M-Score和ConceptBench，我们对三种最先进的文本到图像模型的忘记我进行了广泛的评估，并展示了在记忆保留率、图像质量和推理速度等方面的有前途的结果。

    The unlearning problem of deep learning models, once primarily an academic concern, has become a prevalent issue in the industry. The significant advances in text-to-image generation techniques have prompted global discussions on privacy, copyright, and safety, as numerous unauthorized personal IDs, content, artistic creations, and potentially harmful materials have been learned by these models and later utilized to generate and distribute uncontrolled content. To address this challenge, we propose \textbf{Forget-Me-Not}, an efficient and low-cost solution designed to safely remove specified IDs, objects, or styles from a well-configured text-to-image model in as little as 30 seconds, without impairing its ability to generate other content. Alongside our method, we introduce the \textbf{Memorization Score (M-Score)} and \textbf{ConceptBench} to measure the models' capacity to generate general concepts, grouped into three primary categories: ID, object, and style. Using M-Score and Conc
    
[^2]: HuggingGPT: 在HugingFace中使用ChatGPT及其伙伴解决AI任务

    HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace. (arXiv:2303.17580v1 [cs.CL])

    [http://arxiv.org/abs/2303.17580](http://arxiv.org/abs/2303.17580)

    用ChatGPT作为任务规划工具，利用大型语言模型（LLM）作为控制器来整合现有的AI模型，解决复杂的AI任务。

    

    解决不同领域和模态的复杂AI任务是通向人工智能的关键步骤。本文提出了一个系统，利用大型语言模型（LLMs）作为控制器来管理现有的AI模型以解决AI任务，语言成为通用接口来赋能它。具体来说，我们使用ChatGPT作为任务规划工具，根据HuggingFace中可用的模型功能描述来选择模型，在选定AI模型的情况下执行每个子任务，并总结响应。

    Solving complicated AI tasks with different domains and modalities is a key step toward artificial general intelligence (AGI). While there are abundant AI models available for different domains and modalities, they cannot handle complicated AI tasks. Considering large language models (LLMs) have exhibited exceptional ability in language understanding, generation, interaction, and reasoning, we advocate that LLMs could act as a controller to manage existing AI models to solve complicated AI tasks and language could be a generic interface to empower this. Based on this philosophy, we present HuggingGPT, a system that leverages LLMs (e.g., ChatGPT) to connect various AI models in machine learning communities (e.g., HuggingFace) to solve AI tasks. Specifically, we use ChatGPT to conduct task planning when receiving a user request, select models according to their function descriptions available in HuggingFace, execute each subtask with the selected AI model, and summarize the response acco
    
[^3]: 多模态图像文本匹配优化基于检索的胸部 X 射线报告生成

    Multimodal Image-Text Matching Improves Retrieval-based Chest X-Ray Report Generation. (arXiv:2303.17579v1 [cs.CL])

    [http://arxiv.org/abs/2303.17579](http://arxiv.org/abs/2303.17579)

    本研究提出了一种基于检索的放射性医学报告生成模块 X-REM，它使用图像文本匹配分数来衡量胸部 X 光图像和放射学报告之间的相似度，以进行报告检索，其在多个先前的放射学报告生成模块中表现优异，可有效提高放射学报告的自动生成精度。

    

    自动化生成临床准确的放射学报告可以改善患者护理。以前依赖图像字幕模型的报告生成方法由于缺乏相关领域知识而经常生成不连贯和不正确的文本，而基于检索的尝试经常检索到与输入图像不相关的报告。在这项工作中，我们提出了一种名为 Contrastive X-Ray REport Match（X-REM）的新型基于检索的放射性医学报告生成模块，该模块使用图像文本匹配分数来衡量胸部 X 光图像和放射学报告之间的相似度以进行报告检索。我们观察到，使用语言图像模型计算图像文本匹配分数可以有效地捕捉到在使用余弦相似性时经常丢失的图像和文本之间的细粒度交互。在自然语言和临床度量方面，X-REM在多个先前的放射学报告生成模块中表现优异。通过对生成的报告进行人类评估，表明 X-R...

    Automated generation of clinically accurate radiology reports can improve patient care. Previous report generation methods that rely on image captioning models often generate incoherent and incorrect text due to their lack of relevant domain knowledge, while retrieval-based attempts frequently retrieve reports that are irrelevant to the input image. In this work, we propose Contrastive X-Ray REport Match (X-REM), a novel retrieval-based radiology report generation module that uses an image-text matching score to measure the similarity of a chest X-ray image and radiology report for report retrieval. We observe that computing the image-text matching score with a language-image model can effectively capture the fine-grained interaction between image and text that is often lost when using cosine similarity. X-REM outperforms multiple prior radiology report generation modules in terms of both natural language and clinical metrics. Human evaluation of the generated reports suggests that X-R
    
[^4]: 适用于忠实和抽象化对话生成的弹性权重去除

    Elastic Weight Removal for Faithful and Abstractive Dialogue Generation. (arXiv:2303.17574v1 [cs.CL])

    [http://arxiv.org/abs/2303.17574](http://arxiv.org/abs/2303.17574)

    EWR方法通过费舍尔信息矩阵权衡语音生成模型中个体参数的重要性，提高对话回复的忠实性，取得了很好的效果。

    

    理想情况下，对话系统应该生成忠实于相关文档中包含的知识的回复。然而，许多模型生成了幻想的响应，其中包含与其相矛盾的信息或不可验证的信息。为了减轻这种不良行为，已经提出了在负面示例上微调“负面专家”，并从预训练模型的参数中减去它的参数。然而，直觉上，这并没有考虑到某些参数比其他参数更负责导致幻觉。因此，我们提出通过（近似）费舍尔信息矩阵来权衡它们的个体重要性，该矩阵衡量其估计的不确定性。我们将此方法称为弹性权重去除（EWR）。我们使用Flan-T5不同变体作为骨干语言模型评估我们的方法，并在多个信息寻求对话生成数据集上比较我们的方法与忠实性的最新技术。

    Ideally, dialogue systems should generate responses that are faithful to the knowledge contained in relevant documents. However, many models generate hallucinated responses instead that contradict it or contain unverifiable information. To mitigate such undesirable behaviour, it has been proposed to fine-tune a `negative expert' on negative examples and subtract its parameters from those of a pre-trained model. However, intuitively, this does not take into account that some parameters are more responsible than others in causing hallucinations. Thus, we propose to weigh their individual importance via (an approximation of) the Fisher Information matrix, which measures the uncertainty of their estimate. We call this method Elastic Weight Removal (EWR). We evaluate our method -- using different variants of Flan-T5 as a backbone language model -- on multiple datasets for information-seeking dialogue generation and compare our method with state-of-the-art techniques for faithfulness, such a
    
[^5]: 使用人工智能在家中测量帕金森病的严重程度

    Using AI to Measure Parkinson's Disease Severity at Home. (arXiv:2303.17573v1 [cs.LG])

    [http://arxiv.org/abs/2303.17573](http://arxiv.org/abs/2303.17573)

    该论文提出了一种使用人工智能系统远程评估帕金森病患者运动表现的方法，该方法可重复用于类似的运动任务，拥有较高的可靠性和准确性。

    

    我们提出了一种使用人工智能系统远程评估帕金森病患者运动表现的方法。参与者在网络摄像头前完成了运动任务（即点击手指），250名全球参与者的数据按照运动障碍协会统一帕金森病评分量表 (MDS-UPDRS) 的标准由三名专家神经学家进行了评估。神经学家的评估具有高度的可靠性，内部一致性系数（ICC）为0.88。我们开发了计算机算法来获得与MDS-UPDRS指南一致且与神经学家的评估高度相关的客观测量结果。我们的机器学习模型在这些指标的训练下表现优于一个MDS-UPDRS认证的评分者，平均绝对误差（MAE）为0.59，而评分者的MAE为0.79。然而，该模型的表现略逊于专家神经学家（0.53 MAE）。该方法可重复用于类似的运动任务，提供了可能性。

    We present an artificial intelligence system to remotely assess the motor performance of individuals with Parkinson's disease (PD). Participants performed a motor task (i.e., tapping fingers) in front of a webcam, and data from 250 global participants were rated by three expert neurologists following the Movement Disorder Society Unified Parkinson's Disease Rating Scale (MDS-UPDRS). The neurologists' ratings were highly reliable, with an intra-class correlation coefficient (ICC) of 0.88. We developed computer algorithms to obtain objective measurements that align with the MDS-UPDRS guideline and are strongly correlated with the neurologists' ratings. Our machine learning model trained on these measures outperformed an MDS-UPDRS certified rater, with a mean absolute error (MAE) of 0.59 compared to the rater's MAE of 0.79. However, the model performed slightly worse than the expert neurologists (0.53 MAE). The methodology can be replicated for similar motor tasks, providing the possibili
    
[^6]: CodeGeeX：多语言评估下的预训练代码生成模型

    CodeGeeX: A Pre-Trained Model for Code Generation with Multilingual Evaluations on HumanEval-X. (arXiv:2303.17568v1 [cs.LG])

    [http://arxiv.org/abs/2303.17568](http://arxiv.org/abs/2303.17568)

    CodeGeeX是一个多语言模型，具有130亿参数，用于代码生成。经过广泛的实验证明，CodeGeeX在HumanEval-X上的代码生成和翻译任务中表现优异。此外，CodeGeeX可以将程序员的生产力提高22%。

    

    大型预训练代码生成模型（如OpenAI Codex）可以生成正确语法和功能的代码，使程序员的编码更加高效，使我们对人工智能的追求更加贴近现实。本文介绍了CodeGeeX，一个具有130亿参数的多语言模型，用于代码生成。CodeGeeX在2022年6月时基于23种编程语言的8500亿令牌进行了预训练。我们的广泛实验表明，CodeGeeX在HumanEval-X上的代码生成和翻译任务中均优于规模相似的多语言代码模型。在HumanEval（仅限Python）的基础上，我们开发了HumanEval-X基准测试，通过手写C ++、Java、JavaScript和Go的解决方案来评估多语言模型。此外，我们在Visual Studio Code、JetBrains和Cloud Studio上构建了基于CodeGeeX的扩展，每周为数以万计的活跃用户生成47亿令牌。我们的用户研究表明，CodeGeeX可以将程序员的生产力提高22%。

    Large pre-trained code generation models, such as OpenAI Codex, can generate syntax- and function-correct code, making the coding of programmers more productive and our pursuit of artificial general intelligence closer. In this paper, we introduce CodeGeeX, a multilingual model with 13 billion parameters for code generation. CodeGeeX is pre-trained on 850 billion tokens of 23 programming languages as of June 2022. Our extensive experiments suggest that CodeGeeX outperforms multilingual code models of similar scale for both the tasks of code generation and translation on HumanEval-X. Building upon HumanEval (Python only), we develop the HumanEval-X benchmark for evaluating multilingual models by hand-writing the solutions in C++, Java, JavaScript, and Go. In addition, we build CodeGeeX-based extensions on Visual Studio Code, JetBrains, and Cloud Studio, generating 4.7 billion tokens for tens of thousands of active users per week. Our user study demonstrates that CodeGeeX can help to inc
    
[^7]: BloombergGPT：金融领域的大型语言模型

    BloombergGPT: A Large Language Model for Finance. (arXiv:2303.17564v1 [cs.LG])

    [http://arxiv.org/abs/2303.17564](http://arxiv.org/abs/2303.17564)

    本文提出了BloombergGPT，一个500亿参数的金融领域的大型语言模型，其基于Bloomberg的广泛数据来源和通用数据集进行训练。通过混合数据集训练，该模型在金融任务上表现出色，并且不会牺牲在普通任务上的性能。

    

    自然语言处理在金融技术领域有着广泛而复杂的应用，从情感分析和命名实体识别到问答。大型语言模型（LLM）已被证明在各种任务上非常有效；然而，专为金融领域设计的LLM尚未在文献中报告。在本文中，我们提出了BloombergGPT，一个拥有500亿个参数的语言模型，它是基于广泛的金融数据进行训练的。我们构建了一种3630亿个标记的数据集，该数据集基于彭博社的广泛数据来源，可能是迄今最大的领域特定数据集，同时又增加了来自通用数据集的3450亿个标记。我们在标准LLM基准、开放式金融基准和一套最能准确反映我们预期用途的内部基准上验证了BloombergGPT。我们的混合数据集训练产生了一个在金融任务上明显优于现有模型的模型，同时不会牺牲普通任务的性能。

    The use of NLP in the realm of financial technology is broad and complex, with applications ranging from sentiment analysis and named entity recognition to question answering. Large Language Models (LLMs) have been shown to be effective on a variety of tasks; however, no LLM specialized for the financial domain has been reported in literature. In this work, we present BloombergGPT, a 50 billion parameter language model that is trained on a wide range of financial data. We construct a 363 billion token dataset based on Bloomberg's extensive data sources, perhaps the largest domain-specific dataset yet, augmented with 345 billion tokens from general purpose datasets. We validate BloombergGPT on standard LLM benchmarks, open financial benchmarks, and a suite of internal benchmarks that most accurately reflect our intended usage. Our mixed dataset training leads to a model that outperforms existing models on financial tasks by significant margins without sacrificing performance on general 
    
[^8]: SoftCLIP: 更柔和的跨模态对齐使 CLIP 更强大

    SoftCLIP: Softer Cross-modal Alignment Makes CLIP Stronger. (arXiv:2303.17561v1 [cs.CV])

    [http://arxiv.org/abs/2303.17561](http://arxiv.org/abs/2303.17561)

    本文提出了一种柔性跨模态对齐的方法 SoftCLIP，在配对任务中取得了很好的效果。

    

    在过去两年中，视觉-语言预训练在多个下游任务上取得了令人瞩目的成功。然而，获取高质量的图像-文本配对，其中配对完全互不干扰，仍然是一项具有挑战性的任务，并且常用数据集中存在噪声。为了解决这个问题，我们提出了 SoftCLIP，这是一种新颖的方法，通过引入来自细粒度内模态自相似性生成的“柔性目标”，实现了柔性跨模态对齐。内模态引导能够使得两个配对之间存在一些局部相似性，并且模型之间存在多对多的关系。此外，由于正样本在柔性目标分布中仍然占主导地位，我们通过分离分布中的负样本来进一步提高跨模态学习中的关系对齐性。大量实验表明 SoftCLIP 的有效性。

    During the preceding biennium, vision-language pre-training has achieved noteworthy success on several downstream tasks. Nevertheless, acquiring high-quality image-text pairs, where the pairs are entirely exclusive of each other, remains a challenging task, and noise exists in the commonly used datasets. To address this issue, we propose SoftCLIP, a novel approach that relaxes the strict one-to-one constraint and achieves a soft cross-modal alignment by introducing a softened target, which is generated from the fine-grained intra-modal self-similarity. The intra-modal guidance is indicative to enable two pairs have some local similarities and model many-to-many relationships between the two modalities. Besides, since the positive still dominates in the softened target distribution, we disentangle the negatives in the distribution to further boost the relation alignment with the negatives in the cross-modal learning. Extensive experiments demonstrate the effectiveness of SoftCLIP. In pa
    
[^9]: 《AI法案提案：一项新的技术可解释性权利？》

    The AI Act proposal: a new right to technical interpretability?. (arXiv:2303.17558v1 [cs.CY])

    [http://arxiv.org/abs/2303.17558](http://arxiv.org/abs/2303.17558)

    本文探讨了欧盟的AI法案是否足以表明在其法律框架中存在技术可解释性权利，并进一步探讨了是否需要将其纳入现行立法中。

    

    AI的解释权问题涉及大量文献的讨论。在法律学者中，集中于《通用数据保护条例》中的第22条；在技术学者中，集中于能够帮助解释某个模型输出的技术（XAI）上。本文旨在调查《AI法案》中引入的新规定与《108公约》和《通用数据保护条例》相结合是否足以表明在欧盟的法律框架中存在技术可解释性权利，如果不是，则欧盟是否应将其包含在其现行立法中。

    The debate about the concept of the so called right to explanation in AI is the subject of a wealth of literature. It has focused, in the legal scholarship, on art. 22 GDPR and, in the technical scholarship, on techniques that help explain the output of a certain model (XAI). The purpose of this work is to investigate if the new provisions introduced by the proposal for a Regulation laying down harmonised rules on artificial intelligence (AI Act), in combination with Convention 108 plus and GDPR, are enough to indicate the existence of a right to technical explainability in the EU legal framework and, if not, whether the EU should include it in its current legislation. This is a preliminary work submitted to the online event organised by the Information Society Law Center and it will be later developed into a full paper.
    
[^10]: 对压迫矩阵的分解:揭示交织性在AI公平性中的作用的批判性回顾与再想象

    Factoring the Matrix of Domination: A Critical Review and Reimagination of Intersectionality in AI Fairness. (arXiv:2303.17555v1 [cs.CY])

    [http://arxiv.org/abs/2303.17555](http://arxiv.org/abs/2303.17555)

    本文通过批判性回顾AI公平性文献中30篇交织性讨论，揭示研究人员普遍缺乏对交织性的整体理解，其一方面将其缩小为在群体子组上进行公平度量的优化，另一方面则在社会背景和权力结构的讨论方面存在欠缺。

    

    交织性是一个关键框架，通过调查和实践，它使我们能够检查社会不平等如何通过结构和纪律领域持续存在。在AI公平的理念中，“公平性”是至关重要的，我们认为采用交织性作为分析框架对于有效地实现公平至关重要。通过对AI公平文献中30篇关于交织性的讨论进行批判性回顾，我们归纳和演绎出:1)交织性指导如何在AI公平范例中操作，2)揭示交织性的概念化和实现之间的差距。我们发现，研究人员普遍将交织性缩减为针对人口亚组的公平指标进行优化。他们也未能讨论它们的社会背景，当提到权力时，他们主要将其置于AI流程中。我们将进一步阐述并评估这些差距对于临床研究和实践的影响。

    Intersectionality is a critical framework that, through inquiry and praxis, allows us to examine how social inequalities persist through domains of structure and discipline. Given AI fairness' raison d'\^etre of ``fairness,'' we argue that adopting intersectionality as an analytical framework is pivotal to effectively operationalizing fairness. Through a critical review of how intersectionality is discussed in 30 papers from the AI fairness literature, we deductively and inductively: 1) map how intersectionality tenets operate within the AI fairness paradigm and 2) uncover gaps between the conceptualization and operationalization of intersectionality. We find that researchers overwhelmingly reduce intersectionality to optimizing for fairness metrics over demographic subgroups. They also fail to discuss their social context and when mentioning power, they mostly situate it only within the AI pipeline. We: 3) outline and assess the implications of these gaps for critical inquiry and prax
    
[^11]: 语言模型反映了谁的观点？

    Whose Opinions Do Language Models Reflect?. (arXiv:2303.17548v1 [cs.CL])

    [http://arxiv.org/abs/2303.17548](http://arxiv.org/abs/2303.17548)

    本文通过调查高质量的公共民意调查来创建一个新的数据集OpinionsQA，评估语言模型反映的观点与60个不同人口统计组的观点之间的一致性，发现当前语言模型反映的观点与美国人群组的观点存在巨大差异，甚至通过明确调整LM反映出的观点，仍然无法消除。

    

    语言模型（LM）在越来越多的开放环境中被使用，在针对主观查询的响应中反映的观点可能会对用户满意度产生深远影响，同时也可能塑造整个社会的观点。本文提出了一个定量框架，以调查LM反映的观点。我们利用高质量的公共民意调查和相关的人类反应来创建OpinionsQA，并对60个美国人口统计组的意见进行评估，并涉及从堕胎到自动化的各种话题。在各个话题上，我们发现当前LM反映的观点与美国人群组之间存在重大差异，这与民主党和共和党在气候变化问题上的分歧差不多。值得注意的是，即使明确将LM定向于特定的人口统计组，这种差异仍然存在。我们的分析不仅确认了先前对左倾倾向的观察结果，同时提出了这种差异的一个全新的理论解释。

    Language models (LMs) are increasingly being used in open-ended contexts, where the opinions reflected by LMs in response to subjective queries can have a profound impact, both on user satisfaction, as well as shaping the views of society at large. In this work, we put forth a quantitative framework to investigate the opinions reflected by LMs -- by leveraging high-quality public opinion polls and their associated human responses. Using this framework, we create OpinionsQA, a new dataset for evaluating the alignment of LM opinions with those of 60 US demographic groups over topics ranging from abortion to automation. Across topics, we find substantial misalignment between the views reflected by current LMs and those of US demographic groups: on par with the Democrat-Republican divide on climate change. Notably, this misalignment persists even after explicitly steering the LMs towards particular demographic groups. Our analysis not only confirms prior observations about the left-leaning
    
[^12]: PAIR-Diffusion: 采用结构和外观配对扩散模型进行对象级图像编辑

    PAIR-Diffusion: Object-Level Image Editing with Structure-and-Appearance Paired Diffusion Models. (arXiv:2303.17546v1 [cs.CV])

    [http://arxiv.org/abs/2303.17546](http://arxiv.org/abs/2303.17546)

    本论文提出了一种采用结构和外观配对扩散模型进行对象级图像编辑的方法，使用户能够精细控制图像中的不同对象属性，同时自动传播注入的外观到具有相似结构的对象。

    

    最近，使用扩散模型进行图像编辑发展迅速。以前的作品可以通过各种方式进行控制和编辑图像，某些作品使用高级条件（例如文本），而其他作品使用低级条件。然而，大多数作品缺乏对图像中不同对象的属性进行精细化控制，即对象级图像编辑。本文将图像视为由多个对象组成，每个对象由不同属性定义。我们发现结构和外观是最直观且最有用于编辑的属性。我们提出了结构和外观配对扩散模型（PAIR-Diffusion），该模型使用从图像中明确提取的结构和外观信息进行训练。所提出的模型使用户能够在对象和全局级别将参考图像的外观注入输入图像中。此外，PAIR-Diffusion自动将注入的外观传播到输入图像中具有类似结构的对象。

    Image editing using diffusion models has witnessed extremely fast-paced growth recently. There are various ways in which previous works enable controlling and editing images. Some works use high-level conditioning such as text, while others use low-level conditioning. Nevertheless, most of them lack fine-grained control over the properties of the different objects present in the image, i.e. object-level image editing. In this work, we consider an image as a composition of multiple objects, each defined by various properties. Out of these properties, we identify structure and appearance as the most intuitive to understand and useful for editing purposes. We propose Structure-and-Appearance Paired Diffusion model (PAIR-Diffusion), which is trained using structure and appearance information explicitly extracted from the images. The proposed model enables users to inject a reference image's appearance into the input image at both the object and global levels. Additionally, PAIR-Diffusion a
    
[^13]: 利用长短期记忆网络提高量子电路保真度

    Quantum Circuit Fidelity Improvement with Long Short-Term Memory Networks. (arXiv:2303.17523v1 [quant-ph])

    [http://arxiv.org/abs/2303.17523](http://arxiv.org/abs/2303.17523)

    本文提出使用长短期记忆网络解决量子计算中的保真度问题，利用时间序列预测方法预测量子电路的保真度。

    

    量子计算已进入噪声中间规模量子（NISQ）时代，目前我们拥有的量子处理器对辐射和温度等环境变量敏感，因此会产生嘈杂的输出。虽然已经有许多算法和应用程序用于NISQ处理器，但我们仍面临着解释其嘈杂结果的不确定性。具体来说，我们对所选择的量子态有多少信心？这种信心很重要，因为NISQ计算机将输出其量子位测量的概率分布，有时很难区分分布是否表示有意义的计算或只是随机噪声。本文提出了一种新方法来解决这个问题，将量子电路保真度预测框架为时间序列预测问题，因此可以利用长短期记忆（LSTM）神经网络的强大能力。一个完整的工作流程来构建训练电路

    Quantum computing has entered the Noisy Intermediate-Scale Quantum (NISQ) era. Currently, the quantum processors we have are sensitive to environmental variables like radiation and temperature, thus producing noisy outputs. Although many proposed algorithms and applications exist for NISQ processors, we still face uncertainties when interpreting their noisy results. Specifically, how much confidence do we have in the quantum states we are picking as the output? This confidence is important since a NISQ computer will output a probability distribution of its qubit measurements, and it is sometimes hard to distinguish whether the distribution represents meaningful computation or just random noise. This paper presents a novel approach to attack this problem by framing quantum circuit fidelity prediction as a Time Series Forecasting problem, therefore making it possible to utilize the power of Long Short-Term Memory (LSTM) neural networks. A complete workflow to build the training circuit d
    
[^14]: 关于复杂大型语言模型的优劣（坑）。

    On pitfalls (and advantages) of sophisticated large language models. (arXiv:2303.17511v1 [cs.CY])

    [http://arxiv.org/abs/2303.17511](http://arxiv.org/abs/2303.17511)

    大型语言模型能够超越人类表现，但过度依赖可能会导致严重后果，包括难以区分的机器生成文本和各种形式的欺诈，进而产生新的伦理挑战。

    

    基于大型语言模型（LLMs）的自然语言处理是人工智能研究的一个蓬勃发展的领域。在神经网络已经在基于模式识别的游戏和实际领域中证明超越人类表现后，我们现在可能处于一个人工实体最终进入人类交流领域的十字路口。然而，这也带来了严重的风险。由于神经网络可靠性固有的限制，过度依赖LLMs可能带来破坏性后果。由于区分人类书写和机器生成的文本将变得越来越困难，人们面临着新的伦理挑战。从不再明确可验证的人类作者身份开始，继续涉及各种类型的欺诈，例如新形式的剽窃。这还涉及侵犯隐私权，可能传播人类伪造品，最后但同样重要的是，它使大规模传播错误信息成为可能。

    Natural language processing based on large language models (LLMs) is a booming field of AI research. After neural networks have proven to outperform humans in games and practical domains based on pattern recognition, we might stand now at a road junction where artificial entities might eventually enter the realm of human communication. However, this comes with serious risks. Due to the inherent limitations regarding the reliability of neural networks, overreliance on LLMs can have disruptive consequences. Since it will be increasingly difficult to distinguish between human-written and machine-generated text, one is confronted with new ethical challenges. This begins with the no longer undoubtedly verifiable human authorship and continues with various types of fraud, such as a new form of plagiarism. This also concerns the violation of privacy rights, the possibility of circulating counterfeits of humans, and, last but not least, it makes a massive spread of misinformation possible.
    
[^15]: 论可争议人格的人工智能系统中的全部权利困境

    The Full Rights Dilemma for A.I. Systems of Debatable Personhood. (arXiv:2303.17509v1 [cs.CY])

    [http://arxiv.org/abs/2303.17509](http://arxiv.org/abs/2303.17509)

    AI可能具有可争议的人格，因此，将它们看作道德上的人存在严重风险，不将它们视为道德上的人又会有道德错误，这是一个严重的道德困境

    

    如果存在一种认知上的可能性，即人工智能系统（AI）可以是人，也可以远远不及人类，那么AI具有可争议的人格。AI存在争议性人格是AI发展的可能结果，可能很快就会出现。存在争议性的AI人格将我们置于严重的道德困境中：要么将系统视为道德上的人，冒着为了不值得牺牲的实体而牺牲真正的人类利益的风险，要么不将系统视为道德上的人，冒着对它们进行严重的道德错误。如果考虑具有可能有意识、亚人类、超人类或在其道德相关属性上高度差异化的情况，道德问题将变得更加棘手。

    An Artificially Intelligent system (an AI) has debatable personhood if it's epistemically possible either that the AI is a person or that it falls far short of personhood. Debatable personhood is a likely outcome of AI development and might arise soon. Debatable AI personhood throws us into a catastrophic moral dilemma: Either treat the systems as moral persons and risk sacrificing real human interests for the sake of entities without interests worth the sacrifice, or don't treat the systems as moral persons and risk perpetrating grievous moral wrongs against them. The moral issues become even more perplexing if we consider cases of possibly conscious AI that are subhuman, superhuman, or highly divergent from us in their morally relevant properties.
    
[^16]: 基于信息受限视觉表示的因子领域学习

    Learning in Factored Domains with Information-Constrained Visual Representations. (arXiv:2303.17508v1 [cs.AI])

    [http://arxiv.org/abs/2303.17508](http://arxiv.org/abs/2303.17508)

    本文提出了一种基于信息约束的视觉表示的因子领域学习模型，该模型能够促进在因子领域中RL任务的学习速度。

    

    人类即使在包含复杂视觉信息的任务中也能够快速学习。这部分是由于视觉信息的高效压缩形成，从而可以更好地推广和鲁棒性。然而，仅有压缩表示是无法解释人类学习高速度的原因的。寻求复制这种印象的效率的强化学习（RL）模型可能通过使用任务的因子表示来实现。这些信息简单的任务表示与视觉信息的压缩表示的使用类似。最近的研究将生物视觉感知与分离的压缩表示联系起来。这引出了一个问题，即人类如何学习有效地表达有助于学习任务的视觉信息。在本文中，我们提出了一种基于$\beta$-变分自动编码器（VAE）的改变形式的人类因子表示学习模型，该模型允许视觉信息的表示按照任务相关信息进行塑造。我们展示了这个模型能够学习以一种促进在因子领域中RL任务更快学习的方式有效地表示视觉信息。

    Humans learn quickly even in tasks that contain complex visual information. This is due in part to the efficient formation of compressed representations of visual information, allowing for better generalization and robustness. However, compressed representations alone are insufficient for explaining the high speed of human learning. Reinforcement learning (RL) models that seek to replicate this impressive efficiency may do so through the use of factored representations of tasks. These informationally simplistic representations of tasks are similarly motivated as the use of compressed representations of visual information. Recent studies have connected biological visual perception to disentangled and compressed representations. This raises the question of how humans learn to efficiently represent visual information in a manner useful for learning tasks. In this paper we present a model of human factored representation learning based on an altered form of a $\beta$-Variational Auto-encod
    
[^17]: Pgx:强化学习硬件加速的并行游戏模拟器

    Pgx: Hardware-accelerated parallel game simulation for reinforcement learning. (arXiv:2303.17503v1 [cs.AI])

    [http://arxiv.org/abs/2303.17503](http://arxiv.org/abs/2303.17503)

    Pgx是一个用JAX编写的游戏模拟器集合，具有强化学习硬件加速能力，支持并行执行，速度比现有的强化学习库快10倍。 它实现了Backgammon，Shogi和Go等基准测试游戏。

    

    我们提出了Pgx，这是一个用JAX编写的棋盘游戏模拟器集合。由于JAX的自动向量化和即时编译功能，Pgx易于在GPU/TPU加速器上进行大规模并行执行。我们发现，在单个A100 GPU上的Pgx模拟比现有的强化学习库快10倍。Pgx实现了被认为是人工智能研究中至关重要的基准测试的游戏，如Backgammon，Shogi和Go。 Pgx可在https://github.com/sotetsuk/pgx获得。

    We propose Pgx, a collection of board game simulators written in JAX. Thanks to auto-vectorization and Just-In-Time compilation of JAX, Pgx scales easily to thousands of parallel execution on GPU/TPU accelerators. We found that the simulation of Pgx on a single A100 GPU is 10x faster than that of existing reinforcement learning libraries. Pgx implements games considered vital benchmarks in artificial intelligence research, such as Backgammon, Shogi, and Go. Pgx is available at https://github.com/sotetsuk/pgx.
    
[^18]: 混合路口场景中的意图感知决策制定

    Intention-Aware Decision-Making for Mixed Intersection Scenarios. (arXiv:2303.17493v1 [cs.AI])

    [http://arxiv.org/abs/2303.17493](http://arxiv.org/abs/2303.17493)

    本文提出了一种适用于城市交通的混合路口的白盒意图感知决策制定框架，用于处理行人和自动驾驶车辆之间的交互，以提高AV的接受度。

    

    本文提出了面向白盒的意图感知决策制定，用于处理未信号化的道路交叉口场景下的行人和自动驾驶车辆（AV）之间的交互。此外，还开发了一个设计框架，可以自动参数化决策制定。该决策制定被设计为能够理解城市交通中的行人，并能根据他们的意图做出反应。这样可以确保对行人动作的类人反应，从而提高AV的接受度。本文的核心概念是将行人的意图预测和决策制定划分为两个子系统。一方面，意图检测是一个基于数据驱动的黑盒模型，因此它可以模拟行人的复杂行为。另一方面，决策制定是一个白盒模型，以确保可追踪性，并启用AV的快速验证和验证。

    This paper presents a white-box intention-aware decision-making for the handling of interactions between a pedestrian and an automated vehicle (AV) in an unsignalized street crossing scenario. Moreover, a design framework has been developed, which enables automated parameterization of the decision-making. This decision-making is designed in such a manner that it can understand pedestrians in urban traffic and can react accordingly to their intentions. That way, a human-like response to the actions of the pedestrian is ensured, leading to a higher acceptance of AVs. The core notion of this paper is that the intention prediction of the pedestrian to cross the street and decision-making are divided into two subsystems. On the one hand, the intention detection is a data-driven, black-box model. Thus, it can model the complex behavior of the pedestrians. On the other hand, the decision-making is a white-box model to ensure traceability and to enable a rapid verification and validation of AV
    
[^19]: 语言模型能够解决计算机任务

    Language Models can Solve Computer Tasks. (arXiv:2303.17491v1 [cs.CL])

    [http://arxiv.org/abs/2303.17491](http://arxiv.org/abs/2303.17491)

    本文研究表明，预训练的大型语言模型代理可以通过一个简单的提示方案使用自然语言执行计算机任务，该方法取得了很好的效果并在MiniWoB++基准测试中超越了监督学习和强化学习方法。

    

    能够在计算机上执行通用任务的代理可以通过自动化重复任务和协助复杂问题的解决来提高效率和生产力。理想情况下，这些代理应该能够通过自然语言命令解决新的计算机任务。然而，先前解决这个问题的方法需要大量专家示范和任务特定的奖励函数，这两者对于新任务来说都不切实际。在这项工作中，我们展示了一个预先训练的大型语言模型（LLM）代理可以使用一个简单的提示方案（RCI），通过自然语言指导执行计算机任务，并在批评和改进输出的过程中取得很好的效果。RCI方法在自动化计算机任务方面明显优于现有的LLM方法，并在MiniWoB++基准测试中超越了监督学习（SL）和强化学习（RL）方法。RCI方法使用每个任务仅有的少数示范，与最新的SL+RL方法相竞争。

    Agents capable of carrying out general tasks on a computer can improve efficiency and productivity by automating repetitive tasks and assisting in complex problem-solving. Ideally, such agents should be able to solve new computer tasks presented to them through natural language commands. However, previous approaches to this problem require large amounts of expert demonstrations and task-specific reward functions, both of which are impractical for new tasks. In this work, we show that a pre-trained large language model (LLM) agent can execute computer tasks guided by natural language using a simple prompting scheme where the agent recursively criticizes and improves its output (RCI). The RCI approach significantly outperforms existing LLM methods for automating computer tasks and surpasses supervised learning (SL) and reinforcement learning (RL) approaches on the MiniWoB++ benchmark. RCI is competitive with the state-of-the-art SL+RL method, using only a handful of demonstrations per ta
    
[^20]: 基于代价敏感图神经网络的移动社交网络欺诈检测

    Cost Sensitive GNN-based Imbalanced Learning for Mobile Social Network Fraud Detection. (arXiv:2303.17486v1 [cs.SI])

    [http://arxiv.org/abs/2303.17486](http://arxiv.org/abs/2303.17486)

    本论文提出了代价敏感图神经网络（CSGNN），用于解决移动社交网络欺诈检测中的图像平衡问题，并在两个开源数据集上实现了显着的改进。

    

    随着移动网络的快速发展，人们的社交联系得到了极大的便利。然而，移动社交网络欺诈的兴起给人们带来了巨大困扰，可能造成个人和社会财富的损失，并潜在地对经济造成重大损害。为了检测欺诈用户，广泛使用反映用户移动网络中社交行为的通话详单记录（CDR）数据。但是，上述数据中的不平衡问题可能严重阻碍基于图神经网络（GNN）的欺诈检测器的有效性，在先前的工作中几乎没有得到解决。本文将创造性地结合代价敏感学习和图神经网络，提出了一种新颖的代价敏感图神经网络（CSGNN）。我们在两个开源实际移动网络欺诈数据集上进行了广泛的实验。结果表明，CSGNN可以有效解决移动社交网络欺诈检测中的图像平衡问题，并在几个最先进的基线模型上实现了显着的改进。

    With the rapid development of mobile networks, the people's social contacts have been considerably facilitated. However, the rise of mobile social network fraud upon those networks, has caused a great deal of distress, in case of depleting personal and social wealth, then potentially doing significant economic harm. To detect fraudulent users, call detail record (CDR) data, which portrays the social behavior of users in mobile networks, has been widely utilized. But the imbalance problem in the aforementioned data, which could severely hinder the effectiveness of fraud detectors based on graph neural networks(GNN), has hardly been addressed in previous work. In this paper, we are going to present a novel Cost-Sensitive Graph Neural Network (CSGNN) by creatively combining cost-sensitive learning and graph neural networks. We conduct extensive experiments on two open-source realworld mobile network fraud datasets. The results show that CSGNN can effectively solve the graph imbalance prob
    
[^21]: 利用图神经网络对交通网络中的图进行边缘评级

    Edge Ranking of Graphs in Transportation Networks using a Graph Neural Network (GNN). (arXiv:2303.17485v1 [cs.SI])

    [http://arxiv.org/abs/2303.17485](http://arxiv.org/abs/2303.17485)

    本文提出了一种使用图神经网络对交通网络中边缘进行评级的新方法，可以快速准确地确定网络中的重要边缘，而无需计算每个边缘对的边缘介数中心度。

    

    许多网络，例如交通、电力和供水分布，都可以表示为图形。在图形表示中的一个关键挑战是确定图形边缘的重要性及其对整体网络效率和信息流性能的影响。例如，交通网络中的重要边缘是受影响时会显著改变网络整体效率的道路。找到这样重要的边缘的常用方法是“边缘介数中心度”（EBC），一种基于连通性和信息传播确定图的有影响力边缘的边缘排序度量。使用常见的Brandes算法计算EBC涉及计算每个节点对的最短路径，这可能会在计算和限制大型图形时耗费大量计算资源。图形参数的更改，例如边缘权重或节点或边缘的添加和删除，需要重新计算EBC。作为本文的主要贡献，我们提出了一种使用图神经网络（GNN）对交通网络的边缘进行评分的新方法。我们的方法能够快速准确地识别网络中的边缘重要性，并且不必为每个边缘对计算EBC。在实验中，我们的方法在真实和合成数据集上的表现均优于EBC方法，无论是在精度还是效率上。

    Many networks, such as transportation, power, and water distribution, can be represented as graphs. Crucial challenge in graph representations is identifying the importance of graph edges and their influence on overall network efficiency and information flow performance. For example, important edges in a transportation network are those roads that, when affected, will significantly alter the network's overall efficiency. Commonly used approach to finding such important edges is ``edge betweenness centrality'' (EBC), an edge ranking measure to determine the influential edges of the graph based on connectivity and information spread. Computing the EBC utilizing the common Brandes algorithm involves calculating the shortest paths for every node pair, which can be computationally expensive and restrictive, especially for large graphs. Changes in the graph parameters, e.g., in the edge weight or the addition and deletion of nodes or edges, require the recalculation of the EBC. As the main c
    
[^22]: 三向因果属性偏序结构分析

    Three-way causal attribute partial order structure analysis. (arXiv:2303.17482v1 [cs.AI])

    [http://arxiv.org/abs/2303.17482](http://arxiv.org/abs/2303.17482)

    本文提出了一种名为三向因果属性偏序结构（3WCAPOS）的方法，将偏序正式结构分析（POFSA）演变为因果覆盖，从而增强模型的可解释性和分类性能，同时提出了因果因子（CF）概念评估属性和决策属性之间的因果相关性，并结合三向决策构建3WCAPOS，使得结构中节点的纯度更清晰，级别之间的变化更明显。

    

    偏序正式结构分析（POFSA）作为一种新兴的认知学习模型，在知识处理领域得到了广泛的应用。本文提出了一种名为三向因果属性偏序结构（3WCAPOS）的方法，以从集合覆盖向因果覆盖演变，以增加模型的可解释性和分类性能。首先，提出了因果因子（CF）的概念，用于评估形式决策环境中属性和决策属性之间的因果相关性。然后，将CF与属性偏序结构相结合，定义了因果属性偏序结构的概念，使得集合覆盖演变成因果覆盖。最后，结合三向决策的思想，形成了3WCAPOS，使结构中节点的纯度更清晰，级别之间的变化更明显。除此之外，从分类能力出发进行了实验。

    As an emerging concept cognitive learning model, partial order formal structure analysis (POFSA) has been widely used in the field of knowledge processing. In this paper, we propose the method named three-way causal attribute partial order structure (3WCAPOS) to evolve the POFSA from set coverage to causal coverage in order to increase the interpretability and classification performance of the model. First, the concept of causal factor (CF) is proposed to evaluate the causal correlation between attributes and decision attributes in the formal decision context. Then, combining CF with attribute partial order structure, the concept of causal attribute partial order structure is defined and makes set coverage evolve into causal coverage. Finally, combined with the idea of three-way decision, 3WCAPOS is formed, which makes the purity of nodes in the structure clearer and the changes between levels more obviously. In addition, the experiments are carried out from the classification ability 
    
[^23]: 看着你说话：由口读专家引导的说话人脸生成

    Seeing What You Said: Talking Face Generation Guided by a Lip Reading Expert. (arXiv:2303.17480v1 [cs.CV])

    [http://arxiv.org/abs/2303.17480](http://arxiv.org/abs/2303.17480)

    本文提出了一种使用口读专家引导的说话人脸生成方法，通过惩罚不正确的生成结果来提高生成唇部区域的明晰度，使用对比学习方法增强唇语同步性，并使用变压器来同步编码音频和视频。实验证明此方法在视觉质量和明晰度方面具有优势。

    

    说话人脸生成，也称为语音到唇部生成，是 reconstructs 面部动作，特别是唇部运动，给定一致的语音输入。之前的研究揭示了唇语同步性和视觉质量的重要性。尽管取得了很多进展，但他们很难集中于唇部运动的内容，即所说单词的视觉明晰度，这是生成质量的重要方面。为了解决这个问题，我们提出使用口读专家通过惩罚不正确的生成结果来提高生成唇部区域的清晰度。此外，为了弥补数据稀缺性，我们在音频 - 视觉自我监督的方式下训练口读专家。使用口读专家，我们提出了一种新颖的对比学习方法来增强唇语同步性，并使用变压器来同步编码音频和视频，同时考虑到音频的全局时序依赖关系。为了评估，我们提出了一种新的策略，使用两个不同的口读专家来评估生成的唇部运动的视觉明晰度。实验结果表明，我们的方法提高了生成面孔的视觉质量和明晰度，在主观和客观评估中均优于现有技术。

    Talking face generation, also known as speech-to-lip generation, reconstructs facial motions concerning lips given coherent speech input. The previous studies revealed the importance of lip-speech synchronization and visual quality. Despite much progress, they hardly focus on the content of lip movements i.e., the visual intelligibility of the spoken words, which is an important aspect of generation quality. To address the problem, we propose using a lip-reading expert to improve the intelligibility of the generated lip regions by penalizing the incorrect generation results. Moreover, to compensate for data scarcity, we train the lip-reading expert in an audio-visual self-supervised manner. With a lip-reading expert, we propose a novel contrastive learning to enhance lip-speech synchronization, and a transformer to encode audio synchronically with video, while considering global temporal dependency of audio. For evaluation, we propose a new strategy with two different lip-reading exper
    
[^24]: 多样性的关键在于性交配：基于自适应选择机制的遗传规划中的繁殖优选方法

    All You Need Is Sex for Diversity. (arXiv:2303.17441v1 [cs.NE])

    [http://arxiv.org/abs/2303.17441](http://arxiv.org/abs/2303.17441)

    研究人员成功地采用理想伴侣表示法来建模遗传规划中的交配偏好，通过自适应进化产生多样化的种群来获得更好的结果。

    

    在遗传规划中，保持基因多样性以避免过早收敛是至关重要的。多种方法已被提出来实现这一点，其中一些方法集中于交配阶段，通过耦合不同的解决方案到一些形式的自适应选择机制来实现。在自然中，基因多样性可以是许多不同因素的结果，但当考虑繁殖时，性选择对于在一个物种内促进变异具有影响。具体来说，异性选择往往导致不同的选择压力，进而可能在它们之间引发进化差异。虽然一些性选择机制曾经被应用于遗传规划中，但当涉及到交配选择时，相关文献较少。最近，通过理想伴侣表示法建模交配偏好的方法被提出，与标准方法相比，取得了良好的结果。这些交配偏好按照自适应方式自由进化，并能产生多样化的种群，从而得到更好的结果。

    Maintaining genetic diversity as a means to avoid premature convergence is critical in Genetic Programming. Several approaches have been proposed to achieve this, with some focusing on the mating phase from coupling dissimilar solutions to some form of self-adaptive selection mechanism. In nature, genetic diversity can be the consequence of many different factors, but when considering reproduction Sexual Selection can have an impact on promoting variety within a species. Specifically, Mate Choice often results in different selective pressures between sexes, which in turn may trigger evolutionary differences among them. Although some mechanisms of Sexual Selection have been applied to Genetic Programming in the past, the literature is scarce when it comes to mate choice. Recently, a way of modelling mating preferences by ideal mate representations was proposed, achieving good results when compared to a standard approach. These mating preferences evolve freely in a self-adaptive fashion,
    
[^25]: 具有延迟的强鲁棒性多智能体接送问题

    Robust Multi-Agent Pickup and Delivery with Delays. (arXiv:2303.17422v1 [cs.AI])

    [http://arxiv.org/abs/2303.17422](http://arxiv.org/abs/2303.17422)

    研究了具有实际应用中常见的不完美执行的多智能体接送问题，并提出了两种通过规划路径来限制不完美执行效果的解决方案，提供了鲁棒性保证。

    

    多智能体接送(MAPD)的问题在于计算一组代理的无碰撞路径，以便它们能够安全地从提取位置到达传递位置。这些位置在运行时提供，使得MAPD成为经典多智能体路径规划(MAPF)和在线任务分配的组合。目前的MAPD算法没有考虑到实际应用中遇到的许多实际问题：真实的代理通常不完全按计划路径行驶，可能会受到延迟和故障的影响。在本文中，我们研究了具有延迟的MAPD问题，并提出了两种解决方案，通过规划路径来限制不完美执行的效果，从而提供了鲁棒性保证。具体来说，我们引入了两种算法，k-TP和p-TP，都基于分布式算法Token Passing(TP)，它通常用于解决MAPD，分别提供确定性和概率保证。在实验上，我们将我们的算法与现有的算法进行比较。

    Multi-Agent Pickup and Delivery (MAPD) is the problem of computing collision-free paths for a group of agents such that they can safely reach delivery locations from pickup ones. These locations are provided at runtime, making MAPD a combination between classical Multi-Agent Path Finding (MAPF) and online task assignment. Current algorithms for MAPD do not consider many of the practical issues encountered in real applications: real agents often do not follow the planned paths perfectly, and may be subject to delays and failures. In this paper, we study the problem of MAPD with delays, and we present two solution approaches that provide robustness guarantees by planning paths that limit the effects of imperfect execution. In particular, we introduce two algorithms, k-TP and p-TP, both based on a decentralized algorithm typically used to solve MAPD, Token Passing (TP), which offer deterministic and probabilistic guarantees, respectively. Experimentally, we compare our algorithms against 
    
[^26]: 使用竞争学习技术的可解释入侵检测系统

    Explainable Intrusion Detection Systems Using Competitive Learning Techniques. (arXiv:2303.17387v1 [cs.CR])

    [http://arxiv.org/abs/2303.17387](http://arxiv.org/abs/2303.17387)

    本文提出一种基于竞争学习算法的白盒可解释入侵检测系统，与黑匣子方法相比，能够提供更为可解释的模型，且资源消耗较小。

    

    当前，人工智能（AI）启用的入侵检测系统采用各种黑匣子方法。这些黑匣子方法通常使用基于错误学习（EBL）技术进行训练，并专注于创建准确的模型。这些模型具有高性能成本且不易解释。基于竞争学习（CL）的白盒可解释入侵检测系统（X-IDS）为这些问题提供了潜在解决方案。CL模型利用与EBL方法完全不同的学习范式。这种不同的学习过程使得CL算法族固有地可解释且资源消耗较小。在本文中，我们创建了一个基于DARPA对可解释系统的建议的X-IDS架构。在我们的架构中，我们利用像自组织映射（SOM）、增长式自组织映射（GSOM）和增长式分层自组织映射（GHSOM）等CL算法。生成的模型可以进行数据挖掘以创建可解释的规则。

    The current state of the art systems in Artificial Intelligence (AI) enabled intrusion detection use a variety of black box methods. These black box methods are generally trained using Error Based Learning (EBL) techniques with a focus on creating accurate models. These models have high performative costs and are not easily explainable. A white box Competitive Learning (CL) based eXplainable Intrusion Detection System (X-IDS) offers a potential solution to these problem. CL models utilize an entirely different learning paradigm than EBL approaches. This different learning process makes the CL family of algorithms innately explainable and less resource intensive. In this paper, we create an X-IDS architecture that is based on DARPA's recommendation for explainable systems. In our architecture we leverage CL algorithms like, Self Organizing Maps (SOM), Growing Self Organizing Maps (GSOM), and Growing Hierarchical Self Organizing Map (GHSOM). The resulting models can be data-mined to crea
    
[^27]: RGB-热红外语义分割的互补随机蒙版策略

    Complementary Random Masking for RGB-Thermal Semantic Segmentation. (arXiv:2303.17386v1 [cs.CV])

    [http://arxiv.org/abs/2303.17386](http://arxiv.org/abs/2303.17386)

    本文提出了一种RGB-T图像互补随机蒙版策略和自蒸馏损失，通过防止对单一模式过度依赖，强制网络在一个模态部分可用时进行分割和分类，从而提高了神经网络的准确性和鲁棒性，同时鼓励网络提取互补且有意义的表示。

    

    在恶劣的气象和照明条件下，RGB-热红外语义分割是实现可靠的场景理解的潜在解决方案。然而，先前的研究大多集中在设计多模态融合模块，而忽略了多模态输入的本质。因此，网络容易过度依赖单一模态，难以为每个模态学习互补且有意义的表示。本文提出了一种RGB-T图像互补随机蒙版策略和自蒸馏损失。所提出的蒙版策略防止对单一模式的过度依赖，强制网络在一个模态部分可用时进行对象分割和分类，从而提高了神经网络的准确性和鲁棒性。同时，所提出的自蒸馏损失鼓励网络从单一模态中提取互补且有意义的表示。

    RGB-thermal semantic segmentation is one potential solution to achieve reliable semantic scene understanding in adverse weather and lighting conditions. However, the previous studies mostly focus on designing a multi-modal fusion module without consideration of the nature of multi-modality inputs. Therefore, the networks easily become over-reliant on a single modality, making it difficult to learn complementary and meaningful representations for each modality. This paper proposes 1) a complementary random masking strategy of RGB-T images and 2) self-distillation loss between clean and masked input modalities. The proposed masking strategy prevents over-reliance on a single modality. It also improves the accuracy and robustness of the neural network by forcing the network to segment and classify objects even when one modality is partially available. Also, the proposed self-distillation loss encourages the network to extract complementary and meaningful representations from a single moda
    
[^28]: 计算机视觉多任务自回归解码器研究

    A Study of Autoregressive Decoders for Multi-Tasking in Computer Vision. (arXiv:2303.17376v1 [cs.CV])

    [http://arxiv.org/abs/2303.17376](http://arxiv.org/abs/2303.17376)

    本研究着重研究了计算机视觉中的多任务自回归解码器，通过广泛的系统试验分析了任务和数据混合、训练和正则化超参数、条件类型和特异性、模态组合等因素，发现通过冻结预训练编码器，采用小型解码器可接近于单任务基线。

    

    最近出现了许多计算机视觉模型，能够执行多项任务，由图像编码器（通常是 ViT）和自回归解码器（通常是 Transformer）组成。然而，大部分工作仅呈现一个系统及其结果，对这些系统的设计决策和权衡方面留下了许多疑问。在这项工作中，我们旨在提供这些答案。我们仔细研究了自回归解码器在多模态计算机视觉多任务学习中的应用，包括分类、字幕、视觉问答和光学字符识别等。通过广泛的系统试验，我们研究了任务和数据混合、训练和正则化超参数、条件类型和特异性、模态组合等因素的影响。重要的是，我们将这些结果与经过充分调试的单任务基线进行了比较，以凸显多任务学习所带来的成本。一个关键的发现是，对于冻结预训练编码器上学习的小型解码器，性能接近于单任务基线。

    There has been a recent explosion of computer vision models which perform many tasks and are composed of an image encoder (usually a ViT) and an autoregressive decoder (usually a Transformer). However, most of this work simply presents one system and its results, leaving many questions regarding design decisions and trade-offs of such systems unanswered. In this work, we aim to provide such answers. We take a close look at autoregressive decoders for multi-task learning in multimodal computer vision, including classification, captioning, visual question answering, and optical character recognition. Through extensive systematic experiments, we study the effects of task and data mixture, training and regularization hyperparameters, conditioning type and specificity, modality combination, and more. Importantly, we compare these to well-tuned single-task baselines to highlight the cost incurred by multi-tasking. A key finding is that a small decoder learned on top of a frozen pretrained en
    
[^29]: GAT-COBO：一种针对电信欺诈检测的成本敏感图神经网络

    GAT-COBO: Cost-Sensitive Graph Neural Network for Telecom Fraud Detection. (arXiv:2303.17334v1 [cs.LG])

    [http://arxiv.org/abs/2303.17334](http://arxiv.org/abs/2303.17334)

    本文提出了一种针对电信欺诈检测而设计的图神经网络，名为GAT-COBO。该方法通过设计基于GAT的基本分类器和成本敏感学习器来解决图不平衡问题，实验结果证明其优于现有竞争方法。

    

    随着移动通信技术（如5G）的快速发展，电信欺诈得到了显著增加，影响了个人财富和社会财富的损失。最近，图挖掘技术逐渐成为检测电信欺诈的主流解决方案。然而，由于帕累托原因引起的图不平衡问题给图数据挖掘带来了严重的挑战。这是一个新的和具有挑战性的问题，但之前很少有研究关注。本文提出了一种针对图不平衡问题的图注意力网络和成本敏感增强（GAT-COBO）方法。首先，我们设计了基于GAT的基本分类器来学习图中所有节点的嵌入。然后，将嵌入馈送到经过良好设计的成本敏感学习器中进行不平衡学习。接下来，根据分类错误成本更新权重，使模型更多地关注少数类。最终，我们将基于分类器和成本敏感学习器获得的节点嵌入相加，得出最终预测。实验结果表明，我们提出的GAT-COBO方法在与最先进的基准线相比时取得了令人满意的性能。

    Along with the rapid evolution of mobile communication technologies, such as 5G, there has been a drastically increase in telecom fraud, which significantly dissipates individual fortune and social wealth. In recent years, graph mining techniques are gradually becoming a mainstream solution for detecting telecom fraud. However, the graph imbalance problem, caused by the Pareto principle, brings severe challenges to graph data mining. This is a new and challenging problem, but little previous work has been noticed. In this paper, we propose a Graph ATtention network with COst-sensitive BOosting (GAT-COBO) for the graph imbalance problem. First, we design a GAT-based base classifier to learn the embeddings of all nodes in the graph. Then, we feed the embeddings into a well-designed cost-sensitive learner for imbalanced learning. Next, we update the weights according to the misclassification cost to make the model focus more on the minority class. Finally, we sum the node embeddings obtai
    
[^30]: 训练数据集大小和集成推理策略对头颈部自动分割的影响

    The impact of training dataset size and ensemble inference strategies on head and neck auto-segmentation. (arXiv:2303.17318v1 [cs.CV])

    [http://arxiv.org/abs/2303.17318](http://arxiv.org/abs/2303.17318)

    本文研究了头颈部自动分割模型所需的训练数据集大小和集成方法对其性能的影响，发现250个扫描是训练最准确和最健壮的模型所需的最小数据量，并且集成方法可以在小数据集上发挥作用。

    

    卷积神经网络(CNNs)越来越被用于放疗中自动分割危机器官。由于高质量的大数据集很少，因此我们研究了多少数据是训练精准和健壮的头颈部自动分割模型所需的。为此，我们使用不同大小的数据集(25-1000个扫描)来训练一个简单的3D CNN模型，以分割CT中的脑干、腮腺和脊髓。此外，我们评估了多种集成技术来改善这些模型的性能。随着训练集大小达到250个扫描，分割效果得到了改善，而集成方法显著提高了所有器官的性能。集成方法对最小的数据集的影响最为明显，这表明它们在难以获得大型训练数据集的情况下的潜力。

    Convolutional neural networks (CNNs) are increasingly being used to automate segmentation of organs-at-risk in radiotherapy. Since large sets of highly curated data are scarce, we investigated how much data is required to train accurate and robust head and neck auto-segmentation models. For this, an established 3D CNN was trained from scratch with different sized datasets (25-1000 scans) to segment the brainstem, parotid glands and spinal cord in CTs. Additionally, we evaluated multiple ensemble techniques to improve the performance of these models. The segmentations improved with training set size up to 250 scans and the ensemble methods significantly improved performance for all organs. The impact of the ensemble methods was most notable in the smallest datasets, demonstrating their potential for use in cases where large training datasets are difficult to obtain.
    
[^31]: 在GPT成功和失败的情况下，人类输入人类输出：论GPT朝向常识的趋同性

    Humans in Humans Out: On GPT Converging Toward Common Sense in both Success and Failure. (arXiv:2303.17276v1 [cs.AI])

    [http://arxiv.org/abs/2303.17276](http://arxiv.org/abs/2303.17276)

    本文研究了GPT-3、GPT-3.5和GPT-4模型在人类思维模式中的表现, 运用认识论理论提供了符号生成模型，通过实验证实的人类判断数据点以及ETR预测数据点的数量级对模型进行了检验。

    

    计算规模和微调的增加使得大语言模型（LLM）例如GPT的输出质量得到了显著提高。鉴于GPT-3和GPT-4都是使用大量由人类生成的文本进行训练的，我们可以问他们的输出在多大程度上反映了人类思维的模式，无论是正确还是错误的情况。认识论理论提供了关于人类成功和失败的符号生成模型，包括命题、量化、概率推理和决策。本文将ETR的最近一个书本的61个核心推理和判断问题提供给了GPT-3、GPT-3.5和GPT-4，这些问题包括经过实验证实的人类判断数据点和ETR预测的数据点，同时包含正确的推理模式和谬误和框架效应（ETR61基准测试）。 ETR61包括了Wason的卡牌任务、错觉推理、诱饵效应等经典案例。

    Increase in computational scale and fine-tuning has seen a dramatic improvement in the quality of outputs of large language models (LLMs) like GPT. Given that both GPT-3 and GPT-4 were trained on large quantities of human-generated text, we might ask to what extent their outputs reflect patterns of human thinking, both for correct and incorrect cases. The Erotetic Theory of Reason (ETR) provides a symbolic generative model of both human success and failure in thinking, across propositional, quantified, and probabilistic reasoning, as well as decision-making. We presented GPT-3, GPT-3.5, and GPT-4 with 61 central inference and judgment problems from a recent book-length presentation of ETR, consisting of experimentally verified data-points on human judgment and extrapolated data-points predicted by ETR, with correct inference patterns as well as fallacies and framing effects (the ETR61 benchmark). ETR61 includes classics like Wason's card task, illusory inferences, the decoy effect, and
    
[^32]: 混合智能中的本体论：一篇简明的文献综述

    Ontology in Hybrid Intelligence: a concise literature review. (arXiv:2303.17262v1 [cs.AI])

    [http://arxiv.org/abs/2303.17262](http://arxiv.org/abs/2303.17262)

    本文综述了本体论在混合智能中的应用，并探讨了它在缩小人工智能与人类智能差距方面的潜在作用。研究发现，本体论能够提高系统的质量和准确性，并通过启用扩展互操作性、系统工程和可解释、透明系统等方面来发挥更加具体的作用。

    

    在人工智能技术不断演进和增多的背景下，混合智能正在流行，以实现人工智能和人类之间的平衡共存。本文旨在提供一个简洁而重点突出的概述，介绍本体论在广泛背景的混合智能中的应用，无论其定义如何，并对本体论在减少混合智能系统中人工智能与人类智能之间差距的可能作用进行了批判性讨论。除了有效使用本体论提供的典型好处外，在概念层面，所进行的分析指出，在质量和准确性方面做出了显着贡献，同时在启用扩展互操作性、系统工程和可解释、透明系统方面发挥了更具体的作用。

    In a context of constant evolution and proliferation of AI technology, Hybrid Intelligence is gaining popularity to refer a balanced coexistence between human and artificial intelligence. On the other side, the concept has been extensively used in the past two decades to define models of intelligence involving more than one technology. This paper aims to provide (i) a concise and focused overview of the adoption of Ontology in the broad context of Hybrid Intelligence regardless of its definition and (ii) a critical discussion on the possible role of Ontology to reduce the gap between human and artificial intelligence within hybrid intelligent systems. Beside the typical benefits provided by an effective use of ontologies, at a conceptual level, the analysis conducted has pointed out a significant contribution to quality and accuracy, as well as a more specific role to enable extended interoperability, system engineering and explainable/transparent systems. On the other side, an applica
    
[^33]: 揭开对社交机器人研究的误解

    Demystifying Misconceptions in Social Bots Research. (arXiv:2303.17251v1 [cs.SI])

    [http://arxiv.org/abs/2303.17251](http://arxiv.org/abs/2303.17251)

    这篇文章揭示了关于社交机器人研究的普遍误解，强调需要以严谨、公正和负责任的方式讨论虚假信息研究。

    

    社交机器人科学寻求解决网络虚假信息最受争议的形式之一的知识和解决方案。然而，社交机器人研究受到普遍的偏见、夸大的结果和误解的困扰，这些都为歧义、不切实际的期望和看似无法调和的发现打下了基础。克服这些问题对于确保可靠的解决方案和重申科学方法的有效性至关重要。在这篇文章中，我们修订了社交机器人研究中的一些最新结果，强调和纠正了事实错误以及方法论和概念问题。更重要的是，我们揭开了普遍的误解，解决了有关如何讨论社交机器人研究的基本问题。我们的分析揭示了以严谨、公正和负责任的方式讨论虚假信息研究的必要性。本文通过确定并驳斥社交机器人研究的支持者和反对者常用的谬误论证，支持这种努力。

    The science of social bots seeks knowledge and solutions to one of the most debated forms of online misinformation. Yet, social bots research is plagued by widespread biases, hyped results, and misconceptions that set the stage for ambiguities, unrealistic expectations, and seemingly irreconcilable findings. Overcoming such issues is instrumental towards ensuring reliable solutions and reaffirming the validity of the scientific method. In this contribution we revise some recent results in social bots research, highlighting and correcting factual errors as well as methodological and conceptual issues. More importantly, we demystify common misconceptions, addressing fundamental points on how social bots research is discussed. Our analysis surfaces the need to discuss misinformation research in a rigorous, unbiased, and responsible way. This article bolsters such effort by identifying and refuting common fallacious arguments used by both proponents and opponents of social bots research as
    
[^34]: 面向对象检测的模型无关可解释人工智能

    Model-agnostic explainable artificial intelligence for object detection in image data. (arXiv:2303.17249v1 [cs.CV])

    [http://arxiv.org/abs/2303.17249](http://arxiv.org/abs/2303.17249)

    本文设计并实现了一种新的黑盒解释方法——BODEM，它采用了局部和远程掩蔽生成多个版本的输入图像，从而比目前用于解释对象检测的其他三种最先进的方法提供更详细和有用的解释。

    

    对象检测是计算机视觉中的基本任务之一，通过开发大型复杂的深度学习模型已经取得了很大进展。然而，缺乏透明度是一个重要的挑战，可能妨碍这些模型的广泛应用。可解释的人工智能是一个研究领域，其中开发方法来帮助用户理解基于人工智能的系统的行为、决策逻辑和漏洞。本文为了解释基于人工智能的对象检测系统设计和实现了一种名为Black-box Object Detection Explanation by Masking（BODEM）的黑盒说明方法，采用新的掩蔽方法。我们提出了局部和远程掩蔽来生成输入图像的多个版本。局部掩蔽用于干扰目标对象内的像素，以了解对象检测器对这些变化的反应，而远程掩蔽则用于研究对象检测器在图像背景上的行为。我们在三个基准数据集上的实验表明，与用于解释对象检测的其他三种最先进的方法相比，BODEM提供了更详细和有用的说明。

    Object detection is a fundamental task in computer vision, which has been greatly progressed through developing large and intricate deep learning models. However, the lack of transparency is a big challenge that may not allow the widespread adoption of these models. Explainable artificial intelligence is a field of research where methods are developed to help users understand the behavior, decision logics, and vulnerabilities of AI-based systems. Black-box explanation refers to explaining decisions of an AI system without having access to its internals. In this paper, we design and implement a black-box explanation method named Black-box Object Detection Explanation by Masking (BODEM) through adopting a new masking approach for AI-based object detection systems. We propose local and distant masking to generate multiple versions of an input image. Local masks are used to disturb pixels within a target object to figure out how the object detector reacts to these changes, while distant ma
    
[^35]: 自动驾驶与智能汽车的里程碑：调查综述

    Milestones in Autonomous Driving and Intelligent Vehicles: Survey of Surveys. (arXiv:2303.17220v1 [cs.RO])

    [http://arxiv.org/abs/2303.17220](http://arxiv.org/abs/2303.17220)

    这篇论文提出了一份自动驾驶和智能汽车的总技术调查综述（SoS），总结了其历史，总结了里程碑，并提供了展望、伦理和未来的研究方向。

    

    由于方便、安全和经济效益的原因，对自动驾驶（AD）和智能汽车（IV）的兴趣正在迅速增长。虽然一些调查已经回顾了该领域的研究成果，但它们仍然局限于特定任务，缺乏系统性的总结和未来的研究方向。在这里，我们提出了一份对AD和IV的总技术的调查综述（SoS），回顾了历史，总结了里程碑，并提供了展望、伦理和未来的研究方向。据我们所知，本文是第一篇关于AD和IV里程碑的SoS，与其他两篇技术调查一起构成了我们的完整研究工作。我们预计这篇文章将为研究人员和初学者带来新颖而多样的见解，并作为过去和未来之间的桥梁。

    Interest in autonomous driving (AD) and intelligent vehicles (IVs) is growing at a rapid pace due to the convenience, safety, and economic benefits. Although a number of surveys have reviewed research achievements in this field, they are still limited in specific tasks, lack of systematic summary and research directions in the future. Here we propose a Survey of Surveys (SoS) for total technologies of AD and IVs that reviews the history, summarizes the milestones, and provides the perspectives, ethics, and future research directions. To our knowledge, this article is the first SoS with milestones in AD and IVs, which constitutes our complete research work together with two other technical surveys. We anticipate that this article will bring novel and diverse insights to researchers and abecedarians, and serve as a bridge between past and future.
    
[^36]: SynthVSR：使用合成监督实现可视语音识别的规模化提升

    SynthVSR: Scaling Up Visual Speech Recognition With Synthetic Supervision. (arXiv:2303.17200v1 [cs.CV])

    [http://arxiv.org/abs/2303.17200](http://arxiv.org/abs/2303.17200)

    本文首次探讨利用合成视觉数据进行可视语音识别（VSR）的潜力，提出的方法SynthVSR通过利用语音驱动的唇部动画模型合成大规模数据，极大地提高了VSR系统的性能。

    

    最近在可视语音识别（VSR）领域中报道的最新成果通常依赖于越来越多的视频数据，而公开可用的转录视频数据集大小有限。本文首次研究了利用合成视觉数据进行VSR的潜力。我们的方法“SynthVSR”通过合成嘴唇动作显著提高了VSR系统的性能。SynthVSR背后的关键思想是利用一个基于语音驱动的唇部动画模型，该模型根据输入语音生成唇部动作。该语音驱动的唇部动画模型是在未标记的音视频数据集上训练的，并且可以在有标记的视频可用时进一步优化为预训练的VSR模型。由于存在大量的转录声学数据和面部图像，我们能够使用所提出的唇部动画模型生成大规模的合成数据用于半监督VSR训练。我们在“Lip Reading in the Wild”（Lrw）评测基准上评估了我们方法的性能。

    Recently reported state-of-the-art results in visual speech recognition (VSR) often rely on increasingly large amounts of video data, while the publicly available transcribed video datasets are limited in size. In this paper, for the first time, we study the potential of leveraging synthetic visual data for VSR. Our method, termed SynthVSR, substantially improves the performance of VSR systems with synthetic lip movements. The key idea behind SynthVSR is to leverage a speech-driven lip animation model that generates lip movements conditioned on the input speech. The speech-driven lip animation model is trained on an unlabeled audio-visual dataset and could be further optimized towards a pre-trained VSR model when labeled videos are available. As plenty of transcribed acoustic data and face images are available, we are able to generate large-scale synthetic data using the proposed lip animation model for semi-supervised VSR training. We evaluate the performance of our approach on the la
    
[^37]: 《北欧根桩:一个1.2TB的北欧语言建模数据集》

    The Nordic Pile: A 1.2TB Nordic Dataset for Language Modeling. (arXiv:2303.17183v1 [cs.CL])

    [http://arxiv.org/abs/2303.17183](http://arxiv.org/abs/2303.17183)

    本论文描述了一个包含1.2TB文本的北欧语言数据集，为预训练大型语言模型提供了重要资源，促进了北欧语言的LLMs的开发。

    

    预训练大型语言模型( LLMs )需要海量的文本数据，LLMs的性能通常与数据集的规模和质量相关。这意味着在北欧等语种中建立LLMs可能是具有挑战性的，因为其文本语料库的可用性有限。为了促进北欧语言的LLMs开发，我们策划了一个高质量的数据集，其中包括了1.2TB的文本，涵盖了所有重要的北日耳曼语言（丹麦语、冰岛语、挪威语和瑞典语），以及一些高质量的英文数据。本文详细介绍了我们收集、清理和过滤该数据集的考虑和流程。

    Pre-training Large Language Models (LLMs) require massive amounts of text data, and the performance of the LLMs typically correlates with the scale and quality of the datasets. This means that it may be challenging to build LLMs for smaller languages such as Nordic ones, where the availability of text corpora is limited. In order to facilitate the development of the LLMS in the Nordic languages, we curate a high-quality dataset consisting of 1.2TB of text, in all of the major North Germanic languages (Danish, Icelandic, Norwegian, and Swedish), as well as some high-quality English data. This paper details our considerations and processes for collecting, cleaning, and filtering the dataset.
    
[^38]: 矩阵对角化与奇异值分解：静态SageMath与动态ChatGPT并置

    Matrix diagonalization and singular value decomposition: Static SageMath and dynamic ChatGPT juxtaposed. (arXiv:2303.17163v1 [math.HO])

    [http://arxiv.org/abs/2303.17163](http://arxiv.org/abs/2303.17163)

    本文通过对SageMath和ChatGPT的调查和比较，旨在为学生提供更深入的矩阵分解理解。

    

    我们研究了本科线性代数教学中学生经常面临的一些困难，并确定了他们在处理需要算法思维技能的话题时经常遇到的一些常见错误和困难，如矩阵分解。我们特别关注（正交）对角化和奇异值分解（SVD）。我们还提供了使用SageMath探索这些主题的可能性，它是一种基于Python的免费开源软件计算机代数系统（CAS），尽管其输出本质上是静态的，但已被确定为在计算过程中帮助许多学生的有用工具。然后，我们通过向聊天机器人询问有关该主题的示例或解决问题来探索动态ChatGPT，即通过从特定矩阵构造（正交）对角化或SVD来完成任务。通过在线性代数中巩固基本概念并通过有效实践提高计算技能，我们旨在为学生提供更深入的矩阵分解理解，并为各个领域的应用做好准备。

    We investigated some difficulties that students often face when studying linear algebra at the undergraduate level, and identified some common mistakes and difficulties they often encountered when dealing with topics that require algorithmic thinking skills such as matrix factorization. In particular, we focused on (orthogonal) diagonalization and singular value decomposition (SVD). We also offered the possibility of exploring these topics using SageMath, a Python-based free open software computer algebra system (CAS) that has been identified to be useful for assisting many students in the computational process even though its output is static by nature. We then explored dynamic ChatGPT by inquiring the chatbot about the topic, either by asking to provide an example or to solve a problem, that is by constructing an (orthogonal) diagonalization or SVD from a particular matrix. By consolidating essential concepts in linear algebra and improving computational skills through effective prac
    
[^39]: TreePiece：通过树状分割提高语义解析速度

    TreePiece: Faster Semantic Parsing via Tree Tokenization. (arXiv:2303.17161v1 [cs.CL])

    [http://arxiv.org/abs/2303.17161](http://arxiv.org/abs/2303.17161)

    本文提出的TreePiece技术将解析树分割成子树，以加速自回归模型用于语义分析的过程，相比标准自回归提高了4.6倍的解码速度，并在速度相当的情况下准确性更高于非自回归方法。

    

    自回归编码器-解码器神经网络已经在许多自然语言处理问题中取得了成功，包括语义解析（一种将自然语言转换为机器可读的解析树的任务）。然而，自回归模型的顺序预测过程可能会很慢。为了加速用于语义分析的自回归模型，我们引入了一种新技术，称为TreePiece，它将解析树分割成子树，并在每个解码步骤中生成一个子树。在TopV2基准测试中，TreePiece的解码速度比标准自回归快4.6倍，比非自回归方法（NAR）的速度相当但准确性显着更高。

    Autoregressive (AR) encoder-decoder neural networks have proved successful in many NLP problems, including Semantic Parsing -- a task that translates natural language to machine-readable parse trees. However, the sequential prediction process of AR models can be slow. To accelerate AR for semantic parsing, we introduce a new technique called TreePiece that tokenizes a parse tree into subtrees and generates one subtree per decoding step. On TopV2 benchmark, TreePiece shows 4.6 times faster decoding speed than standard AR, and comparable speed but significantly higher accuracy compared to Non-Autoregressive (NAR).
    
[^40]: 基于判别性类标的文本图片扩散模型

    Discriminative Class Tokens for Text-to-Image Diffusion Models. (arXiv:2303.17155v1 [cs.CV])

    [http://arxiv.org/abs/2303.17155](http://arxiv.org/abs/2303.17155)

    本文提出了一种基于判别性信息和自由文本的非侵入式微调技术，以实现多样性和高准确率的文本到图像生成模型。

    

    最近文本到图像扩散模型的进展使得生成多样且高质量图片成为可能。然而，由于输入文本的歧义，生成的图片常常无法描绘出微妙的细节且易于出错。缓解这些问题的方法之一是在有类标注的数据集上训练扩散模型。这种方法的缺点在于：（i）与用于训练文本到图像模型的大规模爬取的文本-图像数据集相比，有类标注的数据集通常较小，因此生成的图片质量和多样性会严重受影响，或（ii）输入是硬编码的标签，而不是自由文本，这限制了对生成的图像的控制。在这项工作中，我们提出了一种非侵入式的微调技术，利用预训练分类器的判别性信号引导生成过程，既发挥了自由文本的表达潜力，又能够实现高准确率。

    Recent advances in text-to-image diffusion models have enabled the generation of diverse and high-quality images. However, generated images often fall short of depicting subtle details and are susceptible to errors due to ambiguity in the input text. One way of alleviating these issues is to train diffusion models on class-labeled datasets. This comes with a downside, doing so limits their expressive power: (i) supervised datasets are generally small compared to large-scale scraped text-image datasets on which text-to-image models are trained, and so the quality and diversity of generated images are severely affected, or (ii) the input is a hard-coded label, as opposed to free-form text, which limits the control over the generated images.  In this work, we propose a non-invasive fine-tuning technique that capitalizes on the expressive potential of free-form text while achieving high accuracy through discriminative signals from a pretrained classifier, which guides the generation. This 
    
[^41]: DAMO-StreamNet：自动驾驶中流式感知的优化

    DAMO-StreamNet: Optimizing Streaming Perception in Autonomous Driving. (arXiv:2303.17144v1 [cs.CV])

    [http://arxiv.org/abs/2303.17144](http://arxiv.org/abs/2303.17144)

    DAMO-StreamNet是一个优化自动驾驶中流式感知的框架，它融合了YOLO系列的最新进展，并通过颈部结构、双分支结构、蒸馏机制和实时预测机制等关键创新点，提供了尖端的解决方案。

    

    实时感知，或者说流式感知，是自动驾驶中一个至关重要但尚未得到充分研究的方面。为了填补这一空白，我们提出了DAMO-StreamNet，它将YOLO系列的最新进展与空间和时间感知机制的全面分析相结合，提供了一个尖端的解决方案。DAMO-StreamNet的关键创新点包括：(1)一个鲁棒的颈部结构，融合了可变形卷积，增强了感受野和特征对齐能力。(2)一个双分支结构，整合了短通道语义特征和长通道时序特征，提高了运动状态预测的精度。(3)一个在logits级别上进行的蒸馏机制，对齐教师网络和学生网络的语义空间。(4)一个实时预测机制，更新支持帧的特征与当前帧，确保推理过程中的无缝流式感知。

    Real-time perception, or streaming perception, is a crucial aspect of autonomous driving that has yet to be thoroughly explored in existing research. To address this gap, we present DAMO-StreamNet, an optimized framework that combines recent advances from the YOLO series with a comprehensive analysis of spatial and temporal perception mechanisms, delivering a cutting-edge solution. The key innovations of DAMO-StreamNet are: (1) A robust neck structure incorporating deformable convolution, enhancing the receptive field and feature alignment capabilities. (2) A dual-branch structure that integrates short-path semantic features and long-path temporal features, improving motion state prediction accuracy. (3) Logits-level distillation for efficient optimization, aligning the logits of teacher and student networks in semantic space. (4) A real-time forecasting mechanism that updates support frame features with the current frame, ensuring seamless streaming perception during inference. Our ex
    
[^42]: 理解人工智能编程助手的可用性

    Understanding the Usability of AI Programming Assistants. (arXiv:2303.17125v1 [cs.SE])

    [http://arxiv.org/abs/2303.17125](http://arxiv.org/abs/2303.17125)

    人工智能编程助手在快速完成编程任务方面有用，但输出的代码不适合开发者，导致他们不高频接受AI编程助手的初始建议。

    

    软件工程社区近年来广泛使用人工智能编程助手（例如GitHub Copilot）。然而在实践中，开发者并不高频接受AI编程助手的初始建议。这引发了与这些工具可用性相关的许多问题。为了了解开发者在使用这些工具时的实践情况和他们面临的重要的可用性挑战，我们向大量开发者进行了调查，并从410名开发者中获得了回复。通过定性和定量分析，我们发现，开发者最有动力使用AI编程助手的原因是它们可以帮助开发者减少按键次数，快速完成编程任务并调用语法，但它对帮助开发者思考潜在解决方案的支持度较低。我们还发现，开发者不使用这些工具的最重要原因是这些工具不能输出适合他们的代码。

    The software engineering community recently has witnessed widespread deployment of AI programming assistants, such as GitHub Copilot. However, in practice, developers do not accept AI programming assistants' initial suggestions at a high frequency. This leaves a number of open questions related to the usability of these tools. To understand developers' practices while using these tools and the important usability challenges they face, we administered a survey to a large population of developers and received responses from a diverse set of 410 developers. Through a mix of qualitative and quantitative analyses, we found that developers are most motivated to use AI programming assistants because they help developers reduce key-strokes, finish programming tasks quickly, and recall syntax, but resonate less with using them to help brainstorm potential solutions. We also found the most important reasons why developers do not use these tools are because these tools do not output code that add
    
[^43]: 深度生成模型及其在高效无线网络管理中的应用: 教程和案例研究

    Deep Generative Model and Its Applications in Efficient Wireless Network Management: A Tutorial and Case Study. (arXiv:2303.17114v1 [cs.NI])

    [http://arxiv.org/abs/2303.17114](http://arxiv.org/abs/2303.17114)

    本文探讨了深度生成模型在提高无线网络管理效率方面的应用，提出了一种基于DGMs的管理框架，并进行了一项DGM模型的案例研究。

    

    随着扩散模型和ChatGPT的惊人成功，深度生成模型(DGMs)正在经历2022年的爆炸式增长。不限于内容生成，由于其出色的复杂模式表示能力和生成出可信样本的能力，DGMs也被广泛应用于物联网、元宇宙和数字孪生等领域。在本文中，我们探讨了DGMs在重要任务中的应用，即提高无线网络管理的效率。具体来说，我们首先概述了生成AI，以及三种代表性的DGMs。然后，我们提出了一种基于DGMs增强的无线网络管理框架，在框架中详细说明了传统网络管理方法的问题，以及为什么DGMs能够高效地解决这些问题，并阐述了在管理无线网络中应用DGMs的逐步工作流程。此外，我们还使用最先进的DGM模型——扩散模型，在网络经济学上进行了一项案例研究，以生成有效的内容。

    With the phenomenal success of diffusion models and ChatGPT, deep generation models (DGMs) have been experiencing explosive growth from 2022. Not limited to content generation, DGMs are also widely adopted in Internet of Things, Metaverse, and digital twin, due to their outstanding ability to represent complex patterns and generate plausible samples. In this article, we explore the applications of DGMs in a crucial task, i.e., improving the efficiency of wireless network management. Specifically, we firstly overview the generative AI, as well as three representative DGMs. Then, a DGM-empowered framework for wireless network management is proposed, in which we elaborate the issues of the conventional network management approaches, why DGMs can address them efficiently, and the step-by-step workflow for applying DGMs in managing wireless networks. Moreover, we conduct a case study on network economics, using the state-of-the-art DGM model, i.e., diffusion model, to generate effective con
    
[^44]: 带有概率触发臂的情境组合赌博机

    Contextual Combinatorial Bandits with Probabilistically Triggered Arms. (arXiv:2303.17110v1 [cs.LG])

    [http://arxiv.org/abs/2303.17110](http://arxiv.org/abs/2303.17110)

    本文研究了带有概率触发臂的情境组合赌博机，在不同条件下设计了C$^2$-UCB-T算法和VAC$^2$-UCB算法，并分别导出了对应的遗憾值上限，为相关应用提供了理论支持。

    

    本研究探讨了在捕捉广泛应用范围的一系列平滑条件下的带有概率触发臂的情境组合赌博机(C$^2$MAB-T)，例如情境级联赌博机和情境最大化赌博机。在模拟触发概率(TPM)的条件下，我们设计了C$^2$-UCB-T算法，并提出了一种新的分析方法，实现了一个$\tilde{O}(d\sqrt{KT})$的遗憾值上限，消除了一个可能指数级增长的因子$O(1/p_{\min})$，其中$d$是情境的维数，$p_{\min}$是能被触发的任何臂的最小正概率，批大小$K$是每轮能被触发的臂的最大数量。在方差调制(VM)或触发概率和方差调制(TPVM)条件下，我们提出了一种新的方差自适应算法VAC$^2$-UCB，并导出了一个$\tilde{O}(d\sqrt{T})$的遗憾值上限，该上限与批大小$K$无关。作为一个有价值的副产品，我们发现我们的一个...

    We study contextual combinatorial bandits with probabilistically triggered arms (C$^2$MAB-T) under a variety of smoothness conditions that capture a wide range of applications, such as contextual cascading bandits and contextual influence maximization bandits. Under the triggering probability modulated (TPM) condition, we devise the C$^2$-UCB-T algorithm and propose a novel analysis that achieves an $\tilde{O}(d\sqrt{KT})$ regret bound, removing a potentially exponentially large factor $O(1/p_{\min})$, where $d$ is the dimension of contexts, $p_{\min}$ is the minimum positive probability that any arm can be triggered, and batch-size $K$ is the maximum number of arms that can be triggered per round. Under the variance modulated (VM) or triggering probability and variance modulated (TPVM) conditions, we propose a new variance-adaptive algorithm VAC$^2$-UCB and derive a regret bound $\tilde{O}(d\sqrt{T})$, which is independent of the batch-size $K$. As a valuable by-product, we find our a
    
[^45]: OpenMix: 探索异常样本以检测分类错误

    OpenMix: Exploring Outlier Samples for Misclassification Detection. (arXiv:2303.17093v1 [cs.LG])

    [http://arxiv.org/abs/2303.17093](http://arxiv.org/abs/2303.17093)

    该论文介绍了一种名为OpenMix的新方法，通过学习拒绝异常样本生成的伪样本来提高深度神经分类器的可靠性，从而检测已知类别的分类错误和未知类别的OOD样本。

    

    在高风险应用中，可靠的深度神经分类器置信度估计是一个具有挑战性但基本要求。然而，现代深度神经网络通常对其错误预测过于自信。在这项工作中，我们利用易于获取的异常样本，即来自非目标类的未标记样本，帮助检测分类错误。特别地，我们发现出名的Outlier Exposure在检测未知类别的样本中非常强大，但在识别分类错误方面并没有提供任何帮助。基于这些观察，我们提出了一种名为OpenMix的新方法，通过学习拒绝通过异常转换生成的不确定伪样本来融合开放世界的知识。OpenMix在各种情境下显著提高了可靠性，建立了一个强大而统一的框架，用于检测已知类别的分类错误和未知类别的OOD样本。

    Reliable confidence estimation for deep neural classifiers is a challenging yet fundamental requirement in high-stakes applications. Unfortunately, modern deep neural networks are often overconfident for their erroneous predictions. In this work, we exploit the easily available outlier samples, i.e., unlabeled samples coming from non-target classes, for helping detect misclassification errors. Particularly, we find that the well-known Outlier Exposure, which is powerful in detecting out-of-distribution (OOD) samples from unknown classes, does not provide any gain in identifying misclassification errors. Based on these observations, we propose a novel method called OpenMix, which incorporates open-world knowledge by learning to reject uncertain pseudo-samples generated via outlier transformation. OpenMix significantly improves confidence reliability under various scenarios, establishing a strong and unified framework for detecting both misclassified samples from known classes and OOD sa
    
[^46]: 观点：意识和人工通用智能的理论计算机科学视角

    Viewpoint: A Theoretical Computer Science Perspective on Consciousness and Artificial General Intelligence. (arXiv:2303.17075v1 [cs.AI])

    [http://arxiv.org/abs/2303.17075](http://arxiv.org/abs/2303.17075)

    该论文提出了“有意识的图灵机”（CTM）模型，旨在探究意识的理论计算机科学方法。该模型从神经科学和心理学中获益良多，并可作为创建人工通用智能的指导方针。

    

    我们定义了“有意识的图灵机”（CTM），旨在探究意识的理论计算机科学（TCS）方法。为此，我们遵循了TCS对简单易懂的要求。CTM是一个意图简单的机器，而不是大脑的模型，但其设计从神经科学和心理学中获益良多。尽管其开发是为了理解意识，但CTM也提供了一个独到的指导方针，用于创建人工通用智能（AGI）。

    We have defined the Conscious Turing Machine (CTM) for the purpose of investigating a Theoretical Computer Science (TCS) approach to consciousness. For this, we have hewn to the TCS demand for simplicity and understandability. The CTM is consequently and intentionally a simple machine. It is not a model of the brain, though its design has greatly benefited - and continues to benefit - from neuroscience and psychology. The CTM is a model of and for consciousness.  Although it is developed to understand consciousness, the CTM offers a thoughtful and novel guide to the creation of an Artificial General Intelligence (AGI). For example, the CTM has an enormous number of powerful processors, some with specialized expertise, others unspecialized but poised to develop an expertise. For whatever problem must be dealt with, the CTM has an excellent way to utilize those processors that have the required knowledge, ability, and time to work on the problem, even if it is not aware of which ones the
    
[^47]: DERA: 使用对话型解决代理提高大型语言模型的补全能力

    DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents. (arXiv:2303.17071v1 [cs.CL])

    [http://arxiv.org/abs/2303.17071](http://arxiv.org/abs/2303.17071)

    本文介绍了一种名为DERA的对话型解决代理，该代理利用LLM的对话能力提高了模型的补全能力。DERA框架化为两个代理类型之间的讨论，可以在医疗对话摘要和护理计划生成方面实现显著改进。

    

    大型语言模型已成为许多自然语言理解任务的有价值工具。在医疗等关乎安全性的应用中，这些模型的实用性取决于它们生成的输出是否具备事实准确和完整性。本文介绍了对话型解决代理（DERA）。DERA是一种由LLM（特别是GPT-4）的对话能力提供支持的模式，它为模型提供了一个简单且易于理解的论坛，用于沟通反馈并迭代改进输出。我们将对话框架化为两个代理类型之间的讨论：一个研究人员，负责处理信息并识别关键问题组件；以及一个决策者，具有将研究人员的信息集成并对最终输出做出判定的自主权。我们将DERA用于三个临床相关任务的测试。在医疗对话摘要和护理计划生成方面，DERA显示出比基础GPT-4性能显著提高的效果。

    Large language models (LLMs) have emerged as valuable tools for many natural language understanding tasks. In safety-critical applications such as healthcare, the utility of these models is governed by their ability to generate outputs that are factually accurate and complete. In this work, we present dialog-enabled resolving agents (DERA). DERA is a paradigm made possible by the increased conversational abilities of LLMs, namely GPT-4. It provides a simple, interpretable forum for models to communicate feedback and iteratively improve output. We frame our dialog as a discussion between two agent types - a Researcher, who processes information and identifies crucial problem components, and a Decider, who has the autonomy to integrate the Researcher's information and makes judgments on the final output.  We test DERA against three clinically-focused tasks. For medical conversation summarization and care plan generation, DERA shows significant improvement over the base GPT-4 performance 
    
[^48]: 决策导向学习中的理想抽象

    Ideal Abstractions for Decision-Focused Learning. (arXiv:2303.17062v1 [cs.LG])

    [http://arxiv.org/abs/2303.17062](http://arxiv.org/abs/2303.17062)

    本论文提出了一种通过自动配置输出空间以最小化与决策相关信息的损失来制定简化抽象的机器学习系统的方法。

    

    我们提出了一种通过识别和利用决策的效用结构来制定简化抽象的机器学习系统的方法。机器学习任务通常涉及高维输出空间（例如图像中每个像素或图中节点的预测），尽管对于下游的决策制定来说，粗略的输出空间通常已经足够了（例如图像中的区域而不是像素）。开发者常常手工制定输出空间的抽象，但存在着众多的抽象形式，而且选择模型输出空间的影响对其在下游决策制定方面的实用性尚不清楚。我们提出了一种方法，自动配置输出空间以最小化与决策相关信息的损失。采用几何角度，我们将算法的一步作为概率单纯形的投影，称之为fold，以最小化决策相关信息在H-熵意义下的总损失。关键是，L…

    We present a methodology for formulating simplifying abstractions in machine learning systems by identifying and harnessing the utility structure of decisions. Machine learning tasks commonly involve high-dimensional output spaces (e.g., predictions for every pixel in an image or node in a graph), even though a coarser output would often suffice for downstream decision-making (e.g., regions of an image instead of pixels). Developers often hand-engineer abstractions of the output space, but numerous abstractions are possible and it is unclear how the choice of output space for a model impacts its usefulness in downstream decision-making. We propose a method that configures the output space automatically in order to minimize the loss of decision-relevant information. Taking a geometric perspective, we formulate a step of the algorithm as a projection of the probability simplex, termed fold, that minimizes the total loss of decision-related information in the H-entropy sense. Crucially, l
    
[^49]: 系统预测器：面向答案集语义下逻辑程序的规模估计器

    System Predictor: Grounding Size Estimator for Logic Programs under Answer Set Semantics. (arXiv:2303.17018v1 [cs.AI])

    [http://arxiv.org/abs/2303.17018](http://arxiv.org/abs/2303.17018)

    系统预测器可以通过估计程序实例化大小来影响系统性能，为答案集编程提供潜在改进。

    

    答案集编程是一种面向解决困难组合搜索问题的声明式逻辑编程范式。虽然不同的逻辑程序可以编码同一问题，但它们的性能可能会有很大差异。很难确定哪个版本的程序表现最佳。我们提出了系统Predictor及其算法后端，用于估计程序的实例化大小，这是一个可以影响处理程序的系统性能的度量标准。我们评估了当Predictor用作答案集编程重写工具Projector和Lpopt生成的重写的指南时的影响。结果表明这种方法具有潜力。

    Answer set programming is a declarative logic programming paradigm geared towards solving difficult combinatorial search problems. While different logic programs can encode the same problem, their performance may vary significantly. It is not always easy to identify which version of the program performs the best. We present the system Predictor (and its algorithmic backend) for estimating the grounding size of programs, a metric that can influence a performance of a system processing a program. We evaluate the impact of Predictor when used as a guide for rewritings produced by the answer set programming rewriting tools Projector and Lpopt. The results demonstrate potential to this approach.
    
[^50]: ChatGPT-4中显著概念物理推理的进展

    Advances in apparent conceptual physics reasoning in ChatGPT-4. (arXiv:2303.17012v1 [physics.ed-ph])

    [http://arxiv.org/abs/2303.17012](http://arxiv.org/abs/2303.17012)

    ChatGPT-4是一个基于大规模语言模型训练的对话机器人，能达到接近于物理专家水平的力概念测试成绩，对未来的物理教育和教学有重要意义。

    

    ChatGPT是建立在一个巨大的人类文本信息库上的大型语言模型，以模拟人类对话。最近Kortemeyer（2023）的研究表明，尽管没有任何关于物理定律的明确编程指导，ChatGPT-3.5可以通过一些名义水平的入门物理课程，并在力学的力概念测试中得到接近最小理解的成绩。本研究复制了这些结果，并证明了最新版本ChatGPT-4在该环境下的成绩远高于前版本，在一些非常值得注意的例外和限制条件下，其回答非常接近于完美地展示专家水平的能力。我们简要评述了这对于未来物理教育和教学的含义。

    ChatGPT is built on a large language model trained on an enormous corpus of human text to emulate human conversation. Despite lacking any explicit programming regarding the laws of physics, recent work by Kortemeyer (2023) has demonstrated that ChatGPT-3.5 could pass an introductory physics course at some nominal level and register something close to a minimal understanding of Newtonian Mechanics on the Force Concept Inventory. This work replicates those results and also demonstrates that the latest version, ChatGPT-4, has reached a much higher mark in the latter context. Indeed, its responses come quite close to perfectly demonstrating expert-level competence, with a few very notable exceptions and limitations. We briefly comment on the implications of this for the future of physics education and pedagogy.
    
[^51]: 在巴西大学入学考试中评估GPT-3.5和GPT-4模型

    Evaluating GPT-3.5 and GPT-4 Models on Brazilian University Admission Exams. (arXiv:2303.17003v1 [cs.CL])

    [http://arxiv.org/abs/2303.17003](http://arxiv.org/abs/2303.17003)

    本研究在巴西大学入学考试中评估了GPT-3.5和GPT-4模型，分析了不同提示策略，最终发现GPT-4与Chain-of-Thought提示结合表现最好，在2022年考试中准确率达到了87％。

    

    本研究旨在探索语言模型（LMs）在应对高风险的多项选择测试中的能力，这里以巴西大学广泛采用的多学科入学考试Exame Nacional do Ensino Médio（ENEM）为例。该考试对LMs提出了挑战，因为其问题可能涉及多个知识领域，需要理解来自不同领域的信息。例如，一个问题可能需要理解统计学和生物学才能解决。本研究分析了GPT-3.5和GPT-4模型对2009年至2017年考试以及2022年公开的考试问题的响应。此外，还测试了不同的提示策略，包括使用Chain-of-Thought（CoT）提示生成答案的解释。在2022年的考试中，表现最佳的模型是GPT-4并使用了CoT，在准确率方面达到了87％。

    The present study aims to explore the capabilities of Language Models (LMs) in tackling high-stakes multiple-choice tests, represented here by the Exame Nacional do Ensino M\'edio (ENEM), a multidisciplinary entrance examination widely adopted by Brazilian universities. This exam poses challenging tasks for LMs, since its questions may span into multiple fields of knowledge, requiring understanding of information from diverse domains. For instance, a question may require comprehension of both statistics and biology to be solved. This work analyzed responses generated by GPT-3.5 and GPT-4 models for questions presented in the 2009-2017 exams, as well as for questions of the 2022 exam, which were made public after the training of the models was completed. Furthermore, different prompt strategies were tested, including the use of Chain-of-Thought (CoT) prompts to generate explanations for answers. On the 2022 edition, the best-performing model, GPT-4 with CoT, achieved an accuracy of 87%,
    
[^52]: 稀疏性是否有助于学习不正确的线性赌博机？

    Does Sparsity Help in Learning Misspecified Linear Bandits?. (arXiv:2303.16998v1 [cs.LG])

    [http://arxiv.org/abs/2303.16998](http://arxiv.org/abs/2303.16998)

    本文研究了稀疏性在解决不正确线性赌博机问题中的作用，证明了算法可以通过查询$ O(\varepsilon^{-s}d^s) $个操作来获得$O(\varepsilon)$-最优行动，其中$s$是稀疏性参数。

    

    最近，学习线性不正确赌博机已经产生了对学习赌博机和强化学习（RL）的难度的有趣影响。具体而言，Du等人（2020）表明，即使学习者被赋予在$ \mathbb{R}^d$ 中近似赌博机或RL奖励的线性特征，且误差在$\varepsilon$的范围内，寻找一个$ O（\varepsilon）$ -最优行动需要至少拉出$ \Omega(\exp(d)) $的查询。此外，Lattimore等人（2020）展示了如何在$\operatorname{poly}(d/\varepsilon)$的查询中学习得到退化的$O(\varepsilon\sqrt{d})$ -最优解决方案。然而，关于实际参数的结构假设，如稀疏性，是否能打破$\varepsilon\sqrt{d}$的障碍仍不清楚。本文通过展示算法可以通过查询$ O(\varepsilon^{-s}d^s) $个操作来获得$O(\varepsilon)$-最优行动，其中$s$是稀疏性参数，以消除$ \exp(d)$-依赖性解决了这个问题。

    Recently, the study of linear misspecified bandits has generated intriguing implications of the hardness of learning in bandits and reinforcement learning (RL). In particular, Du et al. (2020) show that even if a learner is given linear features in $\mathbb{R}^d$ that approximate the rewards in a bandit or RL with a uniform error of $\varepsilon$, searching for an $O(\varepsilon)$-optimal action requires pulling at least $\Omega(\exp(d))$ queries. Furthermore, Lattimore et al. (2020) show that a degraded $O(\varepsilon\sqrt{d})$-optimal solution can be learned within $\operatorname{poly}(d/\varepsilon)$ queries. Yet it is unknown whether a structural assumption on the ground-truth parameter, such as sparsity, could break the $\varepsilon\sqrt{d}$ barrier. In this paper, we address this question by showing that algorithms can obtain $O(\varepsilon)$-optimal actions by querying $O(\varepsilon^{-s}d^s)$ actions, where $s$ is the sparsity parameter, removing the $\exp(d)$-dependence. We th
    
[^53]: 适应低资源双连通性: 探究对非洲低资源语言采用低计算方法的有效性

    Adapting to the Low-Resource Double-Bind: Investigating Low-Compute Methods on Low-Resource African Languages. (arXiv:2303.16985v1 [cs.CL])

    [http://arxiv.org/abs/2303.16985](http://arxiv.org/abs/2303.16985)

    本文探讨了在低资源条件下，采用语言适配器等低计算方法在非洲语言上进行NLP研究的有效性，并通过微调实验得出了实现可比性能的结论。

    

    自然语言处理(NLP)的许多任务都使用大规模的预训练语言模型，但这些模型计算成本高昂。然而，非洲语言数据的稀缺性和高计算资源的获取限制了对这些语言进行研究的可能性。本文探讨了在这种低资源双连通性背景下，语言适配器等低计算方法的适用性。我们试图回答以下问题：语言适配器是否允许那些在数据和计算方面双重受限的人实际上构建有用的模型？通过在非洲语言上进行微调实验，我们评估了它们作为低资源非洲NLP的成本效益方法的有效性。使用全部免费计算资源，我们的结果显示，与计算资源损耗大的大规模预训练语言模型相比，语言适配器实现了可比的性能。这为进一步的实验和探索打开了大门。

    Many natural language processing (NLP) tasks make use of massively pre-trained language models, which are computationally expensive. However, access to high computational resources added to the issue of data scarcity of African languages constitutes a real barrier to research experiments on these languages. In this work, we explore the applicability of low-compute approaches such as language adapters in the context of this low-resource double-bind. We intend to answer the following question: do language adapters allow those who are doubly bound by data and compute to practically build useful models? Through fine-tuning experiments on African languages, we evaluate their effectiveness as cost-effective approaches to low-resource African NLP. Using solely free compute resources, our results show that language adapters achieve comparable performances to massive pre-trained language models which are heavy on computational resources. This opens the door to further experimentation and explor
    
[^54]: Queer In AI:基于社区参与的AI案例研究

    Queer In AI: A Case Study in Community-Led Participatory AI. (arXiv:2303.16972v1 [cs.CY])

    [http://arxiv.org/abs/2303.16972](http://arxiv.org/abs/2303.16972)

    Queer in AI是一个基于社区参与的AI设计案例研究，通过拒绝等级制度而选择去中心化，在酷儿社群内部建立了援助和项目，同时努力改变酷儿社群外的参与者和机构。通过培育AI参与文化，欢迎和赋权边缘化参与者，为AI的参与式设计做出了更广泛的贡献。

    

    本文以Queer in AI为案例研究，探讨社区参与式AI设计的实践。我们分析了社区参与设计和交叉性原则如何在多年里在这个社群中萌芽和塑造了其项目。本文探讨了该组织在此过程中面临的不同挑战，审视了该组织在实现参与性与交叉性原则方面的不足，并评估了该组织的影响。Queer in AI通过拒绝等级制度而选择去中心化，通过将援助和项目建设建立在酷儿社群内部、由酷儿社群内成员来负责的方式，以及努力改变酷儿社群外的参与者和机构，为参与式方法的从业者和理论家提供了重要的经验和见解。最后，我们推测像Queer in AI这样的社区如何通过培育AI的参与文化，欢迎和赋权边缘化的参与者，批评贫瘠和剥削性表述等方面，为AI的参与式设计做出了更广泛的贡献。

    We present Queer in AI as a case study for community-led participatory design in AI. We examine how participatory design and intersectional tenets started and shaped this community's programs over the years. We discuss different challenges that emerged in the process, look at ways this organization has fallen short of operationalizing participatory and intersectional principles, and then assess the organization's impact. Queer in AI provides important lessons and insights for practitioners and theorists of participatory methods broadly through its rejection of hierarchy in favor of decentralization, success at building aid and programs by and for the queer community, and effort to change actors and institutions outside of the queer community. Finally, we theorize how communities like Queer in AI contribute to the participatory design in AI more broadly by fostering cultures of participation in AI, welcoming and empowering marginalized participants, critiquing poor or exploitative parti
    
[^55]: 物理问题的启发式搜索：用PDDL+玩愤怒的小鸟

    Heuristic Search For Physics-Based Problems: Angry Birds in PDDL+. (arXiv:2303.16967v1 [cs.AI])

    [http://arxiv.org/abs/2303.16967](http://arxiv.org/abs/2303.16967)

    本文探讨了使用PDDL+建模愤怒的小鸟游戏并运用启发式和类似于首选运算符的搜索技术来缓解组合搜索复杂性的方法，并取得了和专门领域的方法相当的表现。

    

    本文研究如何使用通用型规划器与组合搜索来玩愤怒的小鸟——一个已经成为AI挑战问题的游戏。我们使用PDDL+来建模游戏，这是一种支持持续过程和外生事件的混合离散/连续域计划语言。本文描述了模型，并确定了降低问题复杂性的关键设计决策。此外，我们提出了一些特定于域的增强措施，包括启发式和类似于首选运算符的搜索技术。它们共同缓解了组合搜索的复杂性。我们通过将其与专门的特定领域解算器在一系列愤怒的小鸟水平上的表现进行比较来评估我们的方法。结果表明，在大多数水平上，我们的表现与这些特定领域的方法相当，即使不使用我们的特定领域搜索增强措施。

    This paper studies how a domain-independent planner and combinatorial search can be employed to play Angry Birds, a well established AI challenge problem. To model the game, we use PDDL+, a planning language for mixed discrete/continuous domains that supports durative processes and exogenous events. The paper describes the model and identifies key design decisions that reduce the problem complexity. In addition, we propose several domain-specific enhancements including heuristics and a search technique similar to preferred operators. Together, they alleviate the complexity of combinatorial search. We evaluate our approach by comparing its performance with dedicated domain-specific solvers on a range of Angry Birds levels. The results show that our performance is on par with these domain-specific approaches in most levels, even without using our domain-specific search enhancements.
    
[^56]: 使用可微凸优化元学习参数化的一阶优化器

    Meta-Learning Parameterized First-Order Optimizers using Differentiable Convex Optimization. (arXiv:2303.16952v1 [cs.LG])

    [http://arxiv.org/abs/2303.16952](http://arxiv.org/abs/2303.16952)

    该研究提出了使用可微凸优化的元学习框架，将现有的一阶更新规则推广到更广的家族，证明在元学习者有足够类似任务的经验下，可以一步优化一系列线性最小二乘问题。

    

    机器学习和控制中的传统优化方法主要依赖于一阶更新规则。针对某个任务选择合适方法和超参数常常需要试错或从业者直觉，这促进了元学习领域的发展。我们通过提出内循环优化步骤涉及可微凸优化(DCO)的元学习框架，推广了一个广泛的现有更新规则家族。我们通过展示此方法的理论吸引力，证明了在元学习者有足够的类似任务经验的情况下，它可以一步优化一系列线性最小二乘问题。在一系列说明性实验设置中，将DCO更新规则的各种实例与传统优化器进行了比较。

    Conventional optimization methods in machine learning and controls rely heavily on first-order update rules. Selecting the right method and hyperparameters for a particular task often involves trial-and-error or practitioner intuition, motivating the field of meta-learning. We generalize a broad family of preexisting update rules by proposing a meta-learning framework in which the inner loop optimization step involves solving a differentiable convex optimization (DCO). We illustrate the theoretical appeal of this approach by showing that it enables one-step optimization of a family of linear least squares problems, given that the meta-learner has sufficient exposure to similar tasks. Various instantiations of the DCO update rule are compared to conventional optimizers on a range of illustrative experimental settings.
    
[^57]: 网格游戏的简洁QBF编码（扩展版本）

    Concise QBF Encodings for Games on a Grid (extended version). (arXiv:2303.16949v1 [cs.AI])

    [http://arxiv.org/abs/2303.16949](http://arxiv.org/abs/2303.16949)

    该论文介绍了一种名为BDDL的领域定义语言以进行网格棋盘游戏（如井字游戏，连四，占领游戏，追逐者-逃避者和突破）的统一和简洁的QBF编码方法，通过使用QBF求解器在有限深度上决定胜者。

    

    编码2人游戏QBF的正确性和效率是具有挑战性和容易出错的。为了实现在网格棋盘上进行游戏（如井字游戏，连四，占领比赛，追逐者-逃避者和突破）的简洁规格和统一编码，我们引入了他人领域定义语言（BDDL），它受到了在计划领域中PDDL的成功启发。我们提供了从BDDL到QBF的有效转换，将有限深度的获胜策略的存在进行编码。我们的提升编码符号地处理棋盘位置，并允许相对于符号棋盘位置简洁定义条件、效果和获胜配置。编码的大小在输入模型和考虑的深度中呈线性增长。为了展示这种通用方法的可行性，我们使用QBF求解器计算了几个已知游戏实例的获胜策略的关键深度。对于几个游戏，我们的工作提供了第一个QBF编码。与SAT中的计划验证不同，

    Encoding 2-player games in QBF correctly and efficiently is challenging and error-prone. To enable concise specifications and uniform encodings of games played on grid boards, like Tic-Tac-Toe, Connect-4, Domineering, Pursuer-Evader and Breakthrough, we introduce Board-game Domain Definition Language (BDDL), inspired by the success of PDDL in the planning domain.  We provide an efficient translation from BDDL into QBF, encoding the existence of a winning strategy of bounded depth. Our lifted encoding treats board positions symbolically and allows concise definitions of conditions, effects and winning configurations, relative to symbolic board positions. The size of the encoding grows linearly in the input model and the considered depth.  To show the feasibility of such a generic approach, we use QBF solvers to compute the critical depths of winning strategies for instances of several known games. For several games, our work provides the first QBF encoding. Unlike plan validation in SAT
    
[^58]: 神经架构搜索基准测试是否设计良好？对操作重要性的深入研究

    Are Neural Architecture Search Benchmarks Well Designed? A Deeper Look Into Operation Importance. (arXiv:2303.16938v1 [cs.LG])

    [http://arxiv.org/abs/2303.16938](http://arxiv.org/abs/2303.16938)

    本论文对当前广泛使用的NAS基准测试进行了经验研究，发现只需一小部分的操作即可生成接近最高性能的架构，同时这些基准测试存在缺点可能影响公平比较并提供不可靠结果。

    

    神经架构搜索（NAS）基准测试显著提高了开发和比较NAS方法的能力，同时通过提供关于数千个训练过的神经网络的元信息，大幅减少了计算开销。然而，表格基准测试具有几个缺点，可能会阻碍公平比较并提供不可靠的结果。在这项工作中，我们对广泛使用的NAS-Bench-101、NAS-Bench-201和TransNAS-Bench-101基准测试进行了经验性分析，重点关注它们的通用性以及不同操作如何影响所生成架构的性能。我们发现，仅需要操作池的一部分即可生成接近最高性能范围的架构。此外，性能分布具有负偏斜。

    Neural Architecture Search (NAS) benchmarks significantly improved the capability of developing and comparing NAS methods while at the same time drastically reduced the computational overhead by providing meta-information about thousands of trained neural networks. However, tabular benchmarks have several drawbacks that can hinder fair comparisons and provide unreliable results. These usually focus on providing a small pool of operations in heavily constrained search spaces -- usually cell-based neural networks with pre-defined outer-skeletons. In this work, we conducted an empirical analysis of the widely used NAS-Bench-101, NAS-Bench-201 and TransNAS-Bench-101 benchmarks in terms of their generability and how different operations influence the performance of the generated architectures. We found that only a subset of the operation pool is required to generate architectures close to the upper-bound of the performance range. Also, the performance distribution is negatively skewed, havi
    
[^59]: 基于深度学习和XAI的基因组学特征选择新算法

    A New Deep Learning and XAI-Based Algorithm for Features Selection in Genomics. (arXiv:2303.16914v1 [q-bio.GN])

    [http://arxiv.org/abs/2303.16914](http://arxiv.org/abs/2303.16914)

    本文提出了一种基于深度学习和可解释人工智能的新算法来选择基因组数据中最有信息的特征，为诊断、预后和精准医学提供支持，并在慢性淋巴细胞白血病数据集上取得了有效结果。

    

    在功能基因组学领域，机器学习和深度学习对基因表达谱的分析越来越能够提供有意义的洞察力，特别是对于多种疾病的分析。本文提出了一种新的算法，利用自编码器的重构能力和一种专门定义的可解释人工智能基础分数，以选择作为诊断、预后和精准医学最具信息量的基因组数据特征。在慢性淋巴细胞白血病数据集上的应用结果表明，该算法的有效性，通过确定并提供一组具有意义的基因组数据特征，有助于进行进一步的医学调查。

    In the field of functional genomics, the analysis of gene expression profiles through Machine and Deep Learning is increasingly providing meaningful insight into a number of diseases. The paper proposes a novel algorithm to perform Feature Selection on genomic-scale data, which exploits the reconstruction capabilities of autoencoders and an ad-hoc defined Explainable Artificial Intelligence-based score in order to select the most informative genes for diagnosis, prognosis, and precision medicine. Results of the application on a Chronic Lymphocytic Leukemia dataset evidence the effectiveness of the algorithm, by identifying and suggesting a set of meaningful genes for further medical investigation.
    
[^60]: RetClean: 基于基础模型与数据湖的检索式数据清洗

    RetClean: Retrieval-Based Data Cleaning Using Foundation Models and Data Lakes. (arXiv:2303.16909v1 [cs.DB])

    [http://arxiv.org/abs/2303.16909](http://arxiv.org/abs/2303.16909)

    本研究展示了使用ChatGPT对数据进行清洗的可能性，并提出了结合用户提供的数据湖的基于检索的清洗方法，同时还开发了一种在本地部署的RoBERTa模型来解决隐私问题。

    

    本研究展示了使用基础模型ChatGPT来提供数据清洗建议的可能性。但在处理企业数据或需要解释建议来源时，ChatGPT可能无法胜任。为解决这些问题，我们开发了一种基于检索的方法，该方法配合用户提供的数据湖，将数据湖的数据与ChatGPT的能力结合使用。此外，我们还开发了一种基于RoBERTa的定制化模型，用户可以在本地进行部署使用。

    Can foundation models (such as ChatGPT) clean your data? In this proposal, we demonstrate that indeed ChatGPT can assist in data cleaning by suggesting corrections for specific cells in a data table (scenario 1). However, ChatGPT may struggle with datasets it has never encountered before (e.g., local enterprise data) or when the user requires an explanation of the source of the suggested clean values. To address these issues, we developed a retrieval-based method that complements ChatGPT's power with a user-provided data lake. The data lake is first indexed, we then retrieve the top-k relevant tuples to the user's query tuple and finally leverage ChatGPT to infer the correct value (scenario 2). Nevertheless, sharing enterprise data with ChatGPT, an externally hosted model, might not be feasible for privacy reasons. To assist with this scenario, we developed a custom RoBERTa-based foundation model that can be locally deployed. By fine-tuning it on a small number of examples, it can effe
    
[^61]: 基于混合蚁群算法和Cohort Intelligence算法的梁设计问题

    Hybrid ACO-CI Algorithm for Beam Design problems. (arXiv:2303.16908v1 [cs.NE])

    [http://arxiv.org/abs/2303.16908](http://arxiv.org/abs/2303.16908)

    本文介绍了一种基于蚁群算法和Cohort Intelligence算法的混合算法，旨在解决梁设计问题。该算法通过比较已有算法，优化了计算时间，并成功解决了两个机械设计问题。

    

    复杂的现实世界问题推动了多种优化方法的发展。本文开发了一种新型的混合Ant colony optimization (ACO)方法，使用Cohort Intelligence (CI)算法的样本空间缩减技术。通过解决35个标准基准测试函数来开发和测试算法的准确性。此外，使用算法的约束版本来解决涉及台阶悬臂梁和I型梁的两个机械设计问题。将所提出的解决方案技术的有效性与已经使用的现代算法方法进行评估。结果显示，所提出的混合ACO-CI算法将需要更少的迭代次数来产生所需的输出，这意味着需要更少的计算时间。对于最小化台阶悬臂梁的重量和I型梁中的挠度，所提出的混合ACO-CI算法产生了最佳结果。

    A range of complicated real-world problems have inspired the development of several optimization methods. Here, a novel hybrid version of the Ant colony optimization (ACO) method is developed using the sample space reduction technique of the Cohort Intelligence (CI) Algorithm. The algorithm is developed, and accuracy is tested by solving 35 standard benchmark test functions. Furthermore, the constrained version of the algorithm is used to solve two mechanical design problems involving stepped cantilever beams and I-section beams. The effectiveness of the proposed technique of solution is evaluated relative to contemporary algorithmic approaches that are already in use. The results show that our proposed hybrid ACO-CI algorithm will take lesser number of iterations to produce the desired output which means lesser computational time. For the minimization of weight of stepped cantilever beam and deflection in I-section beam a proposed hybrid ACO-CI algorithm yielded best results when comp
    
[^62]: 深度学习辅助合成的双光子显微镜图像中的纳米颗粒定位

    Deep Learning-Assisted Localisation of Nanoparticles in synthetically generated two-photon microscopy images. (arXiv:2303.16903v1 [q-bio.QM])

    [http://arxiv.org/abs/2303.16903](http://arxiv.org/abs/2303.16903)

    本论文提出了一种用于纳米颗粒定位的数据驱动方法，在合成的2PM图像中测试效果良好，可以解释基于强度的方法的失败原因。

    

    追踪单个分子对于量化药物在生物样本中的输送至关重要，例如在大脑药物输送研究中。既有的基于强度的定位方法不适用于扫描显微镜成像，通常用于体内成像。扫描双光子显微镜（Two-photon microscopy，2PM）成像的低信噪比、分子离开焦平面的运动和高运动模糊对于分子的准确定位构成了挑战。基于数据驱动的模型的应用由于体内实验的数据量通常很少而具有挑战性。为了补充稀缺的训练数据，我们开发了一个2PM图像模拟器。该模拟器模仿了体内成像中观察到的运动模糊、背景荧光和光子噪声。用合成数据训练数据驱动模型可以提高合成图像的定位质量，并解释为什么基于强度的方法失败。

    Tracking single molecules is instrumental for quantifying the transport of molecules and nanoparticles in biological samples, e.g., in brain drug delivery studies. Existing intensity-based localisation methods are not developed for imaging with a scanning microscope, typically used for in vivo imaging. Low signal-to-noise ratios, movement of molecules out-of-focus, and high motion blur on images recorded with scanning two-photon microscopy (2PM) in vivo pose a challenge to the accurate localisation of molecules. Using data-driven models is challenging due to low data volumes, typical for in vivo experiments. We developed a 2PM image simulator to supplement scarce training data. The simulator mimics realistic motion blur, background fluorescence, and shot noise observed in vivo imaging. Training a data-driven model with simulated data improves localisation quality in simulated images and shows why intensity-based methods fail.
    
[^63]: 通过后验估计尖锐化来隐式减轻视觉偏见：一种贝叶斯神经网络方法

    Implicit Visual Bias Mitigation by Posterior Estimate Sharpening of a Bayesian Neural Network. (arXiv:2303.16564v1 [cs.CV])

    [http://arxiv.org/abs/2303.16564](http://arxiv.org/abs/2303.16564)

    该论文提出了一种隐式减轻视觉偏见的方法，使用贝叶斯神经网络，通过后验估计尖锐化，鼓励网络聚焦于不导致高不确定性的中心特征。

    

    深度神经网络的公平性受到数据集偏见和虚假相关性的强烈影响，而这些对现代特征丰富和复杂的视觉数据集通常都是存在的。由于任务的难度和可变性，没有一种单一的去偏见方法是普遍成功的。特别是，在不需要显式知道偏差变量的情况下的隐式方法对于现实世界的应用尤为相关。我们提出了一种新颖的隐式减缓方法，使用贝叶斯神经网络，允许我们利用致性不确定性与样本中偏差或虚假相关性之间的关系。我们提出的后验估计尖锐化程序鼓励网络聚焦于不导致高不确定性的中心特征。在三个基准数据集上的实验结果表明，具有经过尖锐化后验估计的贝叶斯网络表现与现有方法相当，并显示出进一步研究的潜力。

    The fairness of a deep neural network is strongly affected by dataset bias and spurious correlations, both of which are usually present in modern feature-rich and complex visual datasets. Due to the difficulty and variability of the task, no single de-biasing method has been universally successful. In particular, implicit methods not requiring explicit knowledge of bias variables are especially relevant for real-world applications. We propose a novel implicit mitigation method using a Bayesian neural network, allowing us to leverage the relationship between epistemic uncertainties and the presence of bias or spurious correlations in a sample. Our proposed posterior estimate sharpening procedure encourages the network to focus on core features that do not contribute to high uncertainties. Experimental results on three benchmark datasets demonstrate that Bayesian networks with sharpened posterior estimates perform comparably to prior existing methods and show potential worthy of further 
    
[^64]: Bone Age Assessment的自累积视觉变换器，使用Sauvegrain方法

    Self-accumulative Vision Transformer for Bone Age Assessment Using the Sauvegrain Method. (arXiv:2303.16557v1 [cs.CV])

    [http://arxiv.org/abs/2303.16557](http://arxiv.org/abs/2303.16557)

    该研究提出了一种基于自累积视觉变换器的方法，应用于骨龄评估。通过应用标记重放和区域注意偏差，该方法有效地挖掘地标之间的关系并学习全局形态特征，使骨龄评估的平均绝对误差比之前的工作降低了0.11。

    

    本研究提出了一种新的方法，基于Sauvegrain方法，使用多视角、多任务分类模型进行骨龄评估（BAA）。该方法通过训练分类器来评分每个一点的成熟度并预测骨龄，但是这种方法局限于本地形态，并增加了计算成本。因此，本文提出了一种自累积视觉变换器（SAT），通过应用标记重放和区域注意偏差，消减了多视角、多任务问题中通常发生的各向异性行为，从而有效地挖掘地标之间的关系并学习全局形态特征。通过多次实验表明，SAT成功地将地标之间的关系和全局形态特征融合，使骨龄评估的平均绝对误差比之前的工作降低了0.11。

    This study presents a novel approach to bone age assessment (BAA) using a multi-view, multi-task classification model based on the Sauvegrain method. A straightforward solution to automating the Sauvegrain method, which assesses a maturity score for each landmark in the elbow and predicts the bone age, is to train classifiers independently to score each region of interest (RoI), but this approach limits the accessible information to local morphologies and increases computational costs. As a result, this work proposes a self-accumulative vision transformer (SAT) that mitigates anisotropic behavior, which usually occurs in multi-view, multi-task problems and limits the effectiveness of a vision transformer, by applying token replay and regional attention bias. A number of experiments show that SAT successfully exploits the relationships between landmarks and learns global morphological features, resulting in a mean absolute error of BAA that is 0.11 lower than that of the previous work. 
    
[^65]: TraffNet：学习道路网络数字孪生交通生成因果关系

    TraffNet: Learning Causality of Traffic Generation for Road Network Digital Twins. (arXiv:2303.15954v1 [cs.LG])

    [http://arxiv.org/abs/2303.15954](http://arxiv.org/abs/2303.15954)

    TraffNet是一个学习交通量生成原因的深度学习框架，将车辆轨迹数据表示为异构图，利用递归神经网络结构实现了对交通生成原因的预测。

    

    道路网络数字孪生（RNDT）在开发下一代智能交通系统中发挥着关键作用，可以实现更精确的交通规划和控制。为了支持实时决策，RNDT需要一个模型，从在线传感器数据中动态学习交通模式并生成高保真模拟结果。尽管基于图神经网络的当前交通预测技术已经实现了最先进的性能，但是这些技术仅通过挖掘历史交通数据中的相关性来预测未来交通，而忽略了交通生成的原因，例如交通需求和路径选择。因此，它们的性能对于实时决策是不可靠的。为了填补这一差距，我们引入了一个新的深度学习框架称为 TraffNet，该框架从车辆轨迹数据中学习交通量的因果性。首先，我们使用异构图来表示道路网络，使模型能够并入预测所需的其他数据，然后我们提出了一种新颖的递归神经网络结构，从而能够预测交通量的因果联系。

    Road network digital twins (RNDTs) play a critical role in the development of next-generation intelligent transportation systems, enabling more precise traffic planning and control. To support just-in-time (JIT) decision making, RNDTs require a model that dynamically learns the traffic patterns from online sensor data and generates high-fidelity simulation results. Although current traffic prediction techniques based on graph neural networks have achieved state-of-the-art performance, these techniques only predict future traffic by mining correlations in historical traffic data, disregarding the causes of traffic generation, such as traffic demands and route selection. Therefore, their performance is unreliable for JIT decision making. To fill this gap, we introduce a novel deep learning framework called TraffNet that learns the causality of traffic volume from vehicle trajectory data. First, we use a heterogeneous graph to represent the road network, allowing the model to incorporate 
    
[^66]: 有监督的掩蔽知识蒸馏用于少样本Transformer

    Supervised Masked Knowledge Distillation for Few-Shot Transformers. (arXiv:2303.15466v1 [cs.CV])

    [http://arxiv.org/abs/2303.15466](http://arxiv.org/abs/2303.15466)

    本文提出了一种新型的有监督的掩蔽知识蒸馏模型（SMKD），在少量标注数据的情况下，将标签信息融入到自蒸馏框架中，有效解决了Transformer在少样本学习中的过拟合和性能下降问题，实验结果在基准数据集上表现出最先进的性能。

    

    视觉Transformer利用局部特征捕捉远距离依赖关系，针对对少样本学习进行优化。然而，对于只有极少标注样本的数据集来说，由于缺少CNN式的归纳偏差，ViT容易过拟合并且性能严重下降。以前在少样本学习中的工作，要么通过辅助自监督损失来避免这种问题，要么通过监督学习的标签信息来避免。但是自监督和有监督的少样本Transformer之间的差距仍未填补。我们受到最近自监督知识蒸馏和掩蔽图像建模的进展启发，提出了一种新型的Supervised Masked Knowledge Distillation模型（SMKD）用于Transformer的少样本学习，将标签信息融入到自蒸馏框架中。与以前的自监督方法相比，我们允许类内知识流动，并有效利用监督信号对模型输出进行自然约束。在基准数据集上的实验表明，我们的方法在少样本分类任务上实现了最先进的性能，超过了以前自监督和有监督的方法。

    Vision Transformers (ViTs) emerge to achieve impressive performance on many data-abundant computer vision tasks by capturing long-range dependencies among local features. However, under few-shot learning (FSL) settings on small datasets with only a few labeled data, ViT tends to overfit and suffers from severe performance degradation due to its absence of CNN-alike inductive bias. Previous works in FSL avoid such problem either through the help of self-supervised auxiliary losses, or through the dextile uses of label information under supervised settings. But the gap between self-supervised and supervised few-shot Transformers is still unfilled. Inspired by recent advances in self-supervised knowledge distillation and masked image modeling (MIM), we propose a novel Supervised Masked Knowledge Distillation model (SMKD) for few-shot Transformers which incorporates label information into self-distillation frameworks. Compared with previous self-supervised methods, we allow intra-class kno
    
[^67]: Sigmoid Loss用于语言图像预训练

    Sigmoid Loss for Language Image Pre-Training. (arXiv:2303.15343v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.15343](http://arxiv.org/abs/2303.15343)

    本论文提出了适用于语言图像预训练的成对Sigmoid损失函数，可以有效地提高训练批量大小，同时不需要全局查看配对相似性进行归一化，其训练出来的模型在ImageNet上表现良好。

    

    我们提出了一种简单的成对Sigmoid损失函数，用于图像-文本预训练。与标准的具有softmax归一化的对比学习不同，Sigmoid损失只操作图像-文本对，不需要全局查看配对相似性以进行归一化。Sigmoid损失同时使批量大小进一步增加，并可在较小的批量大小下表现更好。仅使用四个TPUv4芯片，我们就能在4k批量大小下训练出一个Base CLIP模型和在20k批量大小下训练出一个大规模LiT模型，后者在两天内实现了84.5%的ImageNet零样本准确率。这种损失函数将批量大小与损失函数分离，使我们能够研究示例与对之间、负-正例比率的影响。最后，我们将批量大小推到极限，高达一百万，发现扩大批量大小的好处很快就会减弱，32k批量大小已经足够。我们希望我们的研究能够激发进一步探索如何提高质量的研究。

    We propose a simple pairwise sigmoid loss for image-text pre-training. Unlike standard contrastive learning with softmax normalization, the sigmoid loss operates solely on image-text pairs and does not require a global view of the pairwise similarities for normalization. The sigmoid loss simultaneously allows further scaling up the batch size, while also performing better at smaller batch sizes. With only four TPUv4 chips, we can train a Base CLIP model at 4k batch size and a Large LiT model at 20k batch size, the latter achieves 84.5% ImageNet zero-shot accuracy in two days. This disentanglement of the batch size from the loss further allows us to study the impact of examples vs pairs and negative to positive ratio. Finally, we push the batch size to the extreme, up to one million, and find that the benefits of growing batch size quickly diminish, with a more reasonable batch size of 32k being sufficient. We hope our research motivates further explorations in improving the quality and
    
[^68]: 旨在实现结果导向的患者亚组：六项抑郁症治疗研究的机器学习分析

    Towards Outcome-Driven Patient Subgroups: A Machine Learning Analysis Across Six Depression Treatment Studies. (arXiv:2303.15202v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.15202](http://arxiv.org/abs/2303.15202)

    这项研究使用机器学习分析了六项抑郁症药物治疗研究的数据，并生成了结果导向的患者亚组，为患者的个性化治疗提供了指导。

    

    重度抑郁障碍(MDD) 是一种多样性疾病，大量的神经生物学基础可能与治疗反应的变异性有关。理解这种变异性的根源并预测结果一直是难以实现的。机器学习已经在预测MDD的治疗反应方面显示出潜力，但其中一项限制是机器学习模型的临床可解释性不足。我们使用差异原型神经网络(DPNN)分析了六个药物治疗抑郁症临床试验的数据(总数n = 5438)。DPNN可以派生出可用于生成患者亚组的病人原型，同时学习生成差异性治疗反应的概率。使用临床和人口统计数据训练了一个模型，用于分类缓解并输出五种一线单药疗法和三种联合治疗的个体缓解概率。模型使用留一研究法交叉验证、置换测试和特征重要性分析进行验证和临床解释性评估。DPNN模型准确预测了所有六个研究的缓解状况，通过鉴定与特定治疗反应更好相关的患者亚组来展示高的临床可解释性。这些研究结果有可能为MDD患者的个性化治疗建议提供信息。

    Major depressive disorder (MDD) is a heterogeneous condition; multiple underlying neurobiological substrates could be associated with treatment response variability. Understanding the sources of this variability and predicting outcomes has been elusive. Machine learning has shown promise in predicting treatment response in MDD, but one limitation has been the lack of clinical interpretability of machine learning models. We analyzed data from six clinical trials of pharmacological treatment for depression (total n = 5438) using the Differential Prototypes Neural Network (DPNN), a neural network model that derives patient prototypes which can be used to derive treatment-relevant patient clusters while learning to generate probabilities for differential treatment response. A model classifying remission and outputting individual remission probabilities for five first-line monotherapies and three combination treatments was trained using clinical and demographic data. Model validity and clin
    
[^69]: LONGNN: 具有可学习正交标准基的谱图神经网络

    LONGNN: Spectral GNNs with Learnable Orthonormal Basis. (arXiv:2303.13750v1 [cs.LG])

    [http://arxiv.org/abs/2303.13750](http://arxiv.org/abs/2303.13750)

    本研究提出了一种谱图神经网络LONGNN，它采用可学习正交标准基，并解决了固定多项式基和非归一化基础所带来的缺陷，经实验证明其在各种图数据集上具有优异的表现。

    

    近年来，大量的谱图神经网络（GNN）方法利用可学习系数的多项式基在许多节点级任务上实现了顶级性能。虽然已经探索了各种多项式基，但是每种方法都采用了固定的多项式基，可能不是给定图形的最佳选择。此外，我们确定了这些方法所谓的越界问题，并表明这在它们不太系统化的正则化策略和非归一化基础上有所根源。在本文中，我们首次尝试解决这两个问题。利用雅各比多项式，我们设计了一种新的具有可学习正交标准基的谱GNN，LON-GNN，并证明了正则化系数现在等效于正则化所学滤波函数的范数。我们在多样的图数据集上进行了广泛的实验，以评估LON-GNN的拟合和泛化能力，结果表明其优于几种最先进的方法。

    In recent years, a plethora of spectral graph neural networks (GNN) methods have utilized polynomial basis with learnable coefficients to achieve top-tier performances on many node-level tasks. Although various kinds of polynomial bases have been explored, each such method adopts a fixed polynomial basis which might not be the optimal choice for the given graph. Besides, we identify the so-called over-passing issue of these methods and show that it is somewhat rooted in their less-principled regularization strategy and unnormalized basis. In this paper, we make the first attempts to address these two issues. Leveraging Jacobi polynomials, we design a novel spectral GNN, LON-GNN, with Learnable OrthoNormal bases and prove that regularizing coefficients becomes equivalent to regularizing the norm of learned filter function now. We conduct extensive experiments on diverse graph datasets to evaluate the fitting and generalization capability of LON-GNN, where the results imply its superiori
    
[^70]: 数据关联感知的POMDP规划与假设剪枝性能保证

    Data Association Aware POMDP Planning with Hypothesis Pruning Performance Guarantees. (arXiv:2303.02139v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.02139](http://arxiv.org/abs/2303.02139)

    提出了一种用于处理具有不确定数据关联的POMDP规划的剪枝算法，通过导出完整假设集与减枝假设子集之间的价值函数边界，建立了使用减枝假设子集造成的最大损失的紧密上界，实验证明此方法在具有挑战性的自主驾驶场景中能够显著节省计算时间并保持合理的性能保证。

    

    在现实世界中运作的自主代理通常要处理部分可观测性，而这通常被建模为部分可观测马尔可夫决策过程（POMDP）。然而，传统的 POMDP 模型依赖于完全知识观测源的假设，即完全可观测数据关联。为了解决这个限制，我们提出了一种规划算法，它维护多个数据关联假设，表示为信念混合，其中每个组件对应于不同的数据关联假设。然而，这种方法可能导致假设数量呈指数增长，从而导致显著的计算开销。为了克服这一挑战，我们引入了一种基于剪枝的方法来处理具有不确定数据关联的规划。我们的主要贡献在于基于完整假设集与基于假设剪枝子集的价值函数之间导出界限，从而使我们能够建立使用修剪的假设子集所造成的最大损失的紧密上界。我们的方法在具有挑战性的自主驾驶场景中进行评估，并展示了显著的计算节省，同时保持合理的性能保证。

    Autonomous agents that operate in the real world must often deal with partial observability, which is commonly modeled as partially observable Markov decision processes (POMDPs). However, traditional POMDP models rely on the assumption of complete knowledge of the observation source, known as fully observable data association. To address this limitation, we propose a planning algorithm that maintains multiple data association hypotheses, represented as a belief mixture, where each component corresponds to a different data association hypothesis. However, this method can lead to an exponential growth in the number of hypotheses, resulting in significant computational overhead. To overcome this challenge, we introduce a pruning-based approach for planning with ambiguous data associations. Our key contribution is to derive bounds between the value function based on the complete set of hypotheses and the value function based on a pruned-subset of the hypotheses, enabling us to establish a 
    
[^71]: 谓词和物体的模糊性

    Vagueness in Predicates and Objects. (arXiv:2302.13189v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.13189](http://arxiv.org/abs/2302.13189)

    本文提出了一种称为变量参考语义学的语义框架，用于建模在谓词和物体中的模糊性和因诸多因素导致的变异性。

    

    经典语义学认为，我们可以将参考、谓词和量词建模为固定域内精确参考对象的集合。非逻辑术语和量词可以通过该域中元素和子集的直接解释来解释。但我们探讨了如何将精确谓词和对象的经典观点概括为考虑诸如模糊性、语境和定义或观点多样性等因素的含义的可变性，并提出了一种称为变量参考语义学的语义框架，该框架可以适应涉及谓词和对象的多种变异模式。

    Classical semantics assumes that one can model reference, predication and quantification with respect to a fixed domain of precise referent objects. Non-logical terms and quantification are then interpreted directly in terms of elements and subsets of this domain. We explore ways to generalise this classical picture of precise predicates and objects to account for variability of meaning due to factors such as vagueness, context and diversity of definitions or opinions. Both names and predicative expressions can be given either multiple semantic referents or be associated with semantic referents that incorporate some model of variability. We present a semantic framework, Variable Reference Semantics, that can accommodate several modes of variability in relation to both predicates and objects.
    
[^72]: 关于视觉解释定量评估的一致性

    On The Coherence of Quantitative Evaluation of Visual Explanations. (arXiv:2302.10764v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.10764](http://arxiv.org/abs/2302.10764)

    本研究针对常用神经网络解释方法，探究不同评估度量下的表现以及评估方法之间的比较，发现方法的表现经常不一致且选择评估度量至关重要。

    

    近年来，通过视觉解释来证明神经网络预测的方法得到了增强发展。这些解释通常采用热图的形式，为输入图像的每个像素分配一个显著性值，表示像素对标签预测的相关性。为了评估这种解释的质量，已经提出了评估方法。一些这样的评估方法依赖于合成数据集，但这样会引入在更现实的情景下适用性的有限保证。另一些方法依赖于客观评估的度量。但是有关这些评估方法的执行水平的不确定性很大。因此，我们对ImageNet-1k验证集的一个子集进行了全面研究，使用多个评估度量来评估不同的常用神经网络解释方法。我们的研究旨在确定不同的评估设置下各个方法的表现如何，以及不同的评估方法之间的比较如何。我们发现，在所使用的评估度量上，这些方法的表现经常是不一致的，而且在观察的表现中，选择评估度量是至关重要的。

    Recent years have shown an increased development of methods for justifying the predictions of neural networks through visual explanations. These explanations usually take the form of heatmaps which assign a saliency (or relevance) value to each pixel of the input image that expresses how relevant the pixel is for the prediction of a label.  Complementing this development, evaluation methods have been proposed to assess the "goodness" of such explanations. On the one hand, some of these methods rely on synthetic datasets. However, this introduces the weakness of having limited guarantees regarding their applicability on more realistic settings. On the other hand, some methods rely on metrics for objective evaluation. However the level to which some of these evaluation methods perform with respect to each other is uncertain.  Taking this into account, we conduct a comprehensive study on a subset of the ImageNet-1k validation set where we evaluate a number of different commonly-used expla
    
[^73]: 预训练基础模型综述：从BERT到ChatGPT的历程

    A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT. (arXiv:2302.09419v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.09419](http://arxiv.org/abs/2302.09419)

    本文全面回顾了预训练基础模型的最新研究进展和发展历程，包括它们的架构、培训目标、预培训任务、微调策略和评估。同时，讨论了其局限性和未来研究方向。

    

    预训练基础模型(PFMs)被认为是各种不同数据模态下游任务的基础。PFM(例如BERT、ChatGPT和GPT-4)在大规模数据上进行训练，为各种下游应用提供了合理的参数初始化。BERT从转换器中学习双向编码器表示，这些模型作为上下文语言模型在大型数据集上进行训练。类似地，生成式预训练变压器(GPT)方法采用转换器作为特征提取器，并采用自回归范式在大型数据集上进行训练。最近，ChatGPT在大语言模型中展现了令人兴奋的成功，它采用自回归式语言模型，可以进行零射击或少射击提示。PFM的卓越成就为各种AI领域带来了重大突破。许多研究提出了不同的方法，提高了对更新调查的需求。本研究全面回顾了PFMs的最新进展，包括它们的架构、培训目标、预培训任务、微调策略和评估。此外，我们还讨论了PFMs的局限性和未来潜在的研究方向。

    Pretrained Foundation Models (PFMs) are regarded as the foundation for various downstream tasks with different data modalities. A PFM (e.g., BERT, ChatGPT, and GPT-4) is trained on large-scale data which provides a reasonable parameter initialization for a wide range of downstream applications. BERT learns bidirectional encoder representations from Transformers, which are trained on large datasets as contextual language models. Similarly, the generative pretrained transformer (GPT) method employs Transformers as the feature extractor and is trained using an autoregressive paradigm on large datasets. Recently, ChatGPT shows promising success on large language models, which applies an autoregressive language model with zero shot or few shot prompting. The remarkable achievements of PFM have brought significant breakthroughs to various fields of AI. Numerous studies have proposed different methods, raising the demand for an updated survey. This study provides a comprehensive review of rec
    
[^74]: AutoFed：用于稳健自动驾驶的异构感知联邦多模态学习

    AutoFed: Heterogeneity-Aware Federated Multimodal Learning for Robust Autonomous Driving. (arXiv:2302.08646v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.08646](http://arxiv.org/abs/2302.08646)

    AutoFed 是一种支持异构感知联邦学习的框架，旨在充分利用自动驾驶车辆上的多模态传感数据，并以此实现稳健的自动驾驶。它通过伪标签和自编码器预训练的方法，在解决分布式AVs上具有异构数据的挑战方面表现良好。

    

    自动驾驶中，基于车载传感器（如激光雷达、雷达和摄像头）的目标检测起着至关重要的作用，而这些传感器在模态上互为补充。尽管众感知技术可能潜在地利用这些传感器（数量巨大）来得出更全面的知识，但是，\textit{联邦学习}（FL）似乎是达到这个潜力的必要工具：它使得自动驾驶车辆（AVs）能够在不显式共享原始传感数据的情况下训练机器学习模型。然而，多模态传感器引入了分布式AVs（如标签数量偏差和不同形式）的各种数据异质性，给有效FL带来了重大挑战。为此，我们提出了AutoFed作为一种异构感知FL框架，充分利用AVs上的多模态传感数据，从而实现稳健的自动驾驶。具体而言，我们首先提出了一种新颖的模型，利用伪标签来避免错误地将未标记的对象视为背景。我们还提出了一种基于自编码器的预训练方法，用于学习多模态数据的通用特征表示。借助这些技术，AutoFed可以成功地聚合来自具有各种数据异质性的分布式AVs的多模态数据，并比传统FL和非FL方法实现更好的物体检测结果。

    Object detection with on-board sensors (e.g., lidar, radar, and camera) play a crucial role in autonomous driving (AD), and these sensors complement each other in modalities. While crowdsensing may potentially exploit these sensors (of huge quantity) to derive more comprehensive knowledge, \textit{federated learning} (FL) appears to be the necessary tool to reach this potential: it enables autonomous vehicles (AVs) to train machine learning models without explicitly sharing raw sensory data. However, the multimodal sensors introduce various data heterogeneity across distributed AVs (e.g., label quantity skews and varied modalities), posing critical challenges to effective FL. To this end, we present AutoFed as a heterogeneity-aware FL framework to fully exploit multimodal sensory data on AVs and thus enable robust AD. Specifically, we first propose a novel model leveraging pseudo-labeling to avoid mistakenly treating unlabeled objects as the background. We also propose an autoencoder-b
    
[^75]: 人工智能心理学中的“正确答案”

    "Correct answers" from the psychology of artificial intelligence. (arXiv:2302.07267v3 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2302.07267](http://arxiv.org/abs/2302.07267)

    本文使用OpenAI的GPT3.5模型重新复制了Many Labs 2复制项目中的14项研究，其中8项研究的结果被成功复制。然而，对于剩下的6项研究，GPT3.5以极其预定的方式回答了调查问题，导致无法分析这些研究。

    This paper replicates 14 studies from the Many Labs 2 replication project with OpenAI's text-davinci-003 model, and successfully replicates the results of 8 studies. However, for the remaining 6 studies, GPT3.5 answered survey questions in an extremely predetermined way, making it impossible to analyze these studies.

    大型语言模型的能力已经大大增强。这种AI系统的一个提出的应用是支持社会和认知科学中的数据收集，目前完美的实验控制是不可行的，而大规模、代表性数据集的收集通常是昂贵的。在本文中，我们使用OpenAI的text-davinci-003模型（俗称GPT3.5）重新复制了Many Labs 2复制项目中的14项研究。我们通过将每项研究的调查作为文本输入，从GPT3.5的默认设置中收集了响应。在我们可以分析的八项研究中，我们的GPT样本复制了原始结果的37.5%以及Many Labs 2结果的37.5%。出乎意料的是，我们无法像预先注册的计划那样分析剩下的六项研究。这是因为对于这六项研究中的每一项，GPT3.5以极其预定的方式回答了调查问题（无论是因变量还是条件变量）：一个未知的

    Large Language Models have vastly grown in capabilities. One proposed application of such AI systems is to support data collection in the social and cognitive sciences, where perfect experimental control is currently unfeasible and the collection of large, representative datasets is generally expensive. In this paper, we re-replicate 14 studies from the Many Labs 2 replication project with OpenAI's text-davinci-003 model, colloquially known as GPT3.5. We collected responses from the default setting of GPT3.5 by inputting each study's survey as text. Among the eight studies we could analyse, our GPT sample replicated 37.5% of the original results as well as 37.5% of the Many Labs 2 results. Unexpectedly, we could not analyse the remaining six studies as we had planned in our pre-registration. This was because for each of these six studies, GPT3.5 answered at least one of the survey questions (either a dependent variable or a condition variable) in an extremely predetermined way: an unex
    
[^76]: LLM-Planner: 利用大型语言模型进行少样本实体代理规划

    LLM-Planner: Few-Shot Grounded Planning for Embodied Agents with Large Language Models. (arXiv:2212.04088v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.04088](http://arxiv.org/abs/2212.04088)

    本研究提出了一种新颖的方法LLM-Planner，利用大型语言模型为实体代理进行少样本规划，以实体代理目前所在的环境为基础，增强LLMs生成和更新计划，实验表明其在多任务和快速学习新任务的通用代理的开发中具有很好的表现。

    

    本研究关注利用大型语言模型（LLMs）作为规划器，让实体代理可以按照自然语言指令完成在视觉感知环境中的复杂任务。现有方法的高数据成本和低样本效率阻碍了多任务和快速学习新任务的通用代理的开发。本文提出了一种新颖的方法LLM-Planner，利用大型语言模型为实体代理进行少样本规划。我们进一步提出了一种简单但有效的方法，以实体代理目前所在的环境为基础，增强LLMs生成和更新计划。在ALFRED数据集上的实验表明，我们的方法可以取得非常有竞争力的少样本性能：尽管使用的配对训练数据不到0.5％，LLM-Planner的表现与使用完整训练数据训练的最新基线相当。现有方法几乎无法完成任何任务。

    This study focuses on using large language models (LLMs) as a planner for embodied agents that can follow natural language instructions to complete complex tasks in a visually-perceived environment. The high data cost and poor sample efficiency of existing methods hinders the development of versatile agents that are capable of many tasks and can learn new tasks quickly. In this work, we propose a novel method, LLM-Planner, that harnesses the power of large language models to do few-shot planning for embodied agents. We further propose a simple but effective way to enhance LLMs with physical grounding to generate and update plans that are grounded in the current environment. Experiments on the ALFRED dataset show that our method can achieve very competitive few-shot performance: Despite using less than 0.5% of paired training data, LLM-Planner achieves competitive performance with recent baselines that are trained using the full training data. Existing methods can barely complete any ta
    
[^77]: MHCCL：用于多元时间序列的层次掩蔽聚类对比学习

    MHCCL: Masked Hierarchical Cluster-Wise Contrastive Learning for Multivariate Time Series. (arXiv:2212.01141v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.01141](http://arxiv.org/abs/2212.01141)

    本文提出了一种名为MHCCL的对比学习模型，可以从多元时间序列数据中学习语义丰富的表示，并利用层次聚类结构中的多粒度信息来滤除虚假负样本和补充正样本。

    

    从原始无标签时间序列数据中学习语义丰富的表示对于分类和预测等下游任务至关重要。对比学习最近展示了在缺乏专家注释的情况下具有良好的表示学习能力。然而，现有的对比学习方法通常独立处理每个实例，导致共享相同语义的假负样本。为了解决这个问题，我们提出了MHCCL，一种层次掩蔽聚类对比学习模型，它利用由多个潜在分区组成的层次结构获得的语义信息来为多元时间序列建模。受到细粒度聚类保留更高纯度，而粗粒度聚类反映更高级别语义的观察的启发，我们提出了一种新颖的向下掩蔽策略，通过结合聚类层次结构中的多粒度信息，过滤掉虚假负面实例并补充正面实例。

    Learning semantic-rich representations from raw unlabeled time series data is critical for downstream tasks such as classification and forecasting. Contrastive learning has recently shown its promising representation learning capability in the absence of expert annotations. However, existing contrastive approaches generally treat each instance independently, which leads to false negative pairs that share the same semantics. To tackle this problem, we propose MHCCL, a Masked Hierarchical Cluster-wise Contrastive Learning model, which exploits semantic information obtained from the hierarchical structure consisting of multiple latent partitions for multivariate time series. Motivated by the observation that fine-grained clustering preserves higher purity while coarse-grained one reflects higher-level semantics, we propose a novel downward masking strategy to filter out fake negatives and supplement positives by incorporating the multi-granularity information from the clustering hierarchy
    
[^78]: CODA-Prompt：基于分解注意力提示的无重训练连续学习方法

    CODA-Prompt: COntinual Decomposed Attention-based Prompting for Rehearsal-Free Continual Learning. (arXiv:2211.13218v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.13218](http://arxiv.org/abs/2211.13218)

    CODA-Prompt是一种基于分解注意力提示，无需重复训练即可连续学习的方法，相比于其他提示方法具有更好的性能和效率。

    

    计算机视觉模型在学习不断变化的训练数据中的新概念时容易产生所谓的灾难性遗忘现象。解决这个连续学习问题的典型方法需要对先前已经见过的数据进行大量的重复训练，这增加了内存成本并可能违反数据隐私。最近，大规模预训练视觉变换器模型的出现使提示方法成为一种替代数据重复训练的方法。这些方法依靠关键查询机制生成提示，并已被发现在已经建立的无重训练连续学习设置中高度抵抗灾难性遗忘。然而，这些方法的关键机制没有与任务序列一起进行端到端训练。我们的实验表明，这会导致它们的可塑性降低，从而牺牲新任务准确性，并无法从扩展的参数容量中受益。我们提出了一种新的连续学习方法CODA-Prompt，它使用分解注意力提示机制结合蒸馏损失来训练提示组件，从而实现与任务序列的端到端训练。我们在一系列视觉数据集上的实验表明，CODA-Prompt优于最近的提示方法，而不需要重复训练或额外的资源。

    Computer vision models suffer from a phenomenon known as catastrophic forgetting when learning novel concepts from continuously shifting training data. Typical solutions for this continual learning problem require extensive rehearsal of previously seen data, which increases memory costs and may violate data privacy. Recently, the emergence of large-scale pre-trained vision transformer models has enabled prompting approaches as an alternative to data-rehearsal. These approaches rely on a key-query mechanism to generate prompts and have been found to be highly resistant to catastrophic forgetting in the well-established rehearsal-free continual learning setting. However, the key mechanism of these methods is not trained end-to-end with the task sequence. Our experiments show that this leads to a reduction in their plasticity, hence sacrificing new task accuracy, and inability to benefit from expanded parameter capacity. We instead propose to learn a set of prompt components which are ass
    
[^79]: ConStruct-VL: 无需数据的持续结构化视觉语言概念学习

    ConStruct-VL: Data-Free Continual Structured VL Concepts Learning. (arXiv:2211.09790v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.09790](http://arxiv.org/abs/2211.09790)

    该论文介绍了第一个持续的无数据结构化VL概念学习（ConStruct-VL）基准，旨在解决VL模型在结构化VL概念推理方面的瓶颈问题，并提出了一种数据-free的方法。

    

    最近，大规模预先训练的视觉语言基础模型在许多零样本下游任务中展示出了非凡的能力，能够通过仅包含短文本提示的定义来识别物体，并取得了竞争性的结果。然而，也已经表明，VL模型在结构化VL概念推理方面仍然很脆弱，例如识别物体属性、状态和物体间关系的能力。这导致推理错误，需要通过教授VL模型缺失的SVLC技能来进行更正；通常必须使用发现问题的私有数据来完成这一点，这自然而然地导致了一个无需任务ID的无数据持续VL学习设置。在这项工作中，我们介绍了第一个持续的无数据结构化VL概念学习（ConStruct-VL）基准，并表明它对许多现有的无数据CL策略都很具有挑战性。

    Recently, large-scale pre-trained Vision-and-Language (VL) foundation models have demonstrated remarkable capabilities in many zero-shot downstream tasks, achieving competitive results for recognizing objects defined by as little as short text prompts. However, it has also been shown that VL models are still brittle in Structured VL Concept (SVLC) reasoning, such as the ability to recognize object attributes, states, and inter-object relations. This leads to reasoning mistakes, which need to be corrected as they occur by teaching VL models the missing SVLC skills; often this must be done using private data where the issue was found, which naturally leads to a data-free continual (no task-id) VL learning setting. In this work, we introduce the first Continual Data-Free Structured VL Concepts Learning (ConStruct-VL) benchmark and show it is challenging for many existing data-free CL strategies. We, therefore, propose a data-free method comprised of a new approach of Adversarial Pseudo-Re
    
[^80]: 基于配对逆金字塔结构和密集多层感知机块的有效音频分类网络

    Effective Audio Classification Network Based on Paired Inverse Pyramid Structure and Dense MLP Block. (arXiv:2211.02940v3 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2211.02940](http://arxiv.org/abs/2211.02940)

    该论文通过提出基于轻量级音频的配对逆金字塔结构网络和密集多层感知机块网络，实现了在不进行数据增强或模型迁移情况下，对UrbanSound8K数据集和GTAZN数据集的高准确度分类任务。

    

    最近，基于卷积神经网络（CNN）和自注意机制的大规模架构已经成为音频分类领域的必要技术。虽然这些技术是最先进的，但只有通过巨大的计算成本和参数、大量的数据增强、来自大型数据集的迁移以及一些其他技巧才能保证有效性。通过利用音频的轻量级特性，我们提出了一种高效的网络结构——配对逆金字塔结构（PIP），以及一种称为配对逆金字塔结构MLP网络（PIPMN）的网络。PIP网络在UrbanSound8K数据集上达到96%的环境声音分类准确度，在GTAZN数据集上达到93.2%的音乐流派分类准确度，仅使用100万个参数即可实现这两个结果，而不需要进行数据增强或模型迁移。公共代码可在以下网址获取：https://github.com/JNAIC/PIPMN

    Recently, massive architectures based on Convolutional Neural Network (CNN) and self-attention mechanisms have become necessary for audio classification. While these techniques are state-of-the-art, these works' effectiveness can only be guaranteed with huge computational costs and parameters, large amounts of data augmentation, transfer from large datasets and some other tricks. By utilizing the lightweight nature of audio, we propose an efficient network structure called Paired Inverse Pyramid Structure (PIP) and a network called Paired Inverse Pyramid Structure MLP Network (PIPMN). The PIPMN reaches 96\% of Environmental Sound Classification (ESC) accuracy on the UrbanSound8K dataset and 93.2\% of Music Genre Classification (MGC) on the GTAZN dataset, with only 1 million parameters. Both of the results are achieved without data augmentation or model transfer. Public code is available at: https://github.com/JNAIC/PIPMN
    
[^81]: LongShortNet：探索时间和语义特征融合在流式感知中

    LongShortNet: Exploring Temporal and Semantic Features Fusion in Streaming Perception. (arXiv:2210.15518v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.15518](http://arxiv.org/abs/2210.15518)

    LongShortNet是一种基于双路径网络的流式感知方法，它结合了长期时间运动和短期空间语义，实现了时空特征融合。在Argoverse-HD数据集上，LongShortNet表现出优异的检测性能，并且几乎不需要额外的计算成本。

    

    流式感知是自动驾驶中的基本任务，需要在自动驾驶系统的延迟和准确性之间进行仔细的平衡。然而，当前的流式感知方法存在局限性，因为它们仅仅依赖于当前帧及其相邻的两帧来学习运动模式，从而限制了它们对复杂场景的建模能力，往往导致检测结果不佳。为了解决这一限制，我们提出了LongShortNet，一种新颖的双路径网络，它捕捉长期的时间运动，并将其与短期的空间语义集成到实时感知中。我们提出的LongShortNet值得注意，因为它是第一个将长期时间建模扩展到流式感知的工作，从而实现了时空特征融合。我们在具有挑战性的Argoverse-HD数据集上评估了LongShortNet，并证明了它在几乎没有额外计算成本的情况下优于现有的最先进方法。

    Streaming perception is a fundamental task in autonomous driving that requires a careful balance between the latency and accuracy of the autopilot system. However, current methods for streaming perception are limited as they rely only on the current and adjacent two frames to learn movement patterns, which restricts their ability to model complex scenes, often leading to poor detection results. To address this limitation, we propose LongShortNet, a novel dual-path network that captures long-term temporal motion and integrates it with short-term spatial semantics for real-time perception. Our proposed LongShortNet is notable as it is the first work to extend long-term temporal modeling to streaming perception, enabling spatiotemporal feature fusion. We evaluate LongShortNet on the challenging Argoverse-HD dataset and demonstrate that it outperforms existing state-of-the-art methods with almost no additional computational cost.
    
[^82]: ProContEXT：基于递进的上下文变换机制的目标跟踪方法研究

    ProContEXT: Exploring Progressive Context Transformer for Tracking. (arXiv:2210.15511v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.15511](http://arxiv.org/abs/2210.15511)

    本文提出了基于递进的上下文变换机制的目标跟踪方法 ProContEXT，采用上下文感知的自注意力模块对空间和时间上下文进行编码，逐步利用静态和动态多尺度模板进行准确跟踪。它探索了空间和时间上下文之间的互补性，为基于 transformer 的跟踪器的多上下文建模提供了新的途径。

    

    传统的视觉目标跟踪仅将第一个帧中的目标区域作为模板，无法适应快速变化和拥挤场景中的物体外观变化，导致跟踪失败。本文提出了一种基于递进式上下文编码变换机制的跟踪方法 ProContEXT，使用上下文感知的自注意力模块对空间和时间上下文进行编码，逐步利用静态和动态多尺度模板进行准确跟踪。它探索了空间和时间上下文之间的互补性，为基于 transformer 的跟踪器的多上下文建模提供了新的途径。另外，ProContEXT 修订了标记修剪技术以减少计算复杂度。

    Existing Visual Object Tracking (VOT) only takes the target area in the first frame as a template. This causes tracking to inevitably fail in fast-changing and crowded scenes, as it cannot account for changes in object appearance between frames. To this end, we revamped the tracking framework with Progressive Context Encoding Transformer Tracker (ProContEXT), which coherently exploits spatial and temporal contexts to predict object motion trajectories. Specifically, ProContEXT leverages a context-aware self-attention module to encode the spatial and temporal context, refining and updating the multi-scale static and dynamic templates to progressively perform accurate tracking. It explores the complementary between spatial and temporal context, raising a new pathway to multi-context modeling for transformer-based trackers. In addition, ProContEXT revised the token pruning technique to reduce computational complexity. Extensive experiments on popular benchmark datasets such as GOT-10k and
    
[^83]: 通过多模态学习脑视觉语言特征解码视觉神经表征

    Decoding Visual Neural Representations by Multimodal Learning of Brain-Visual-Linguistic Features. (arXiv:2210.06756v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.06756](http://arxiv.org/abs/2210.06756)

    本文提出了一种通用神经解码方法 BraVL，它利用了脑视觉语言特征的多模态学习，通过产品混合模型推断潜在代码，实现三种模态的协同生成，在解码视觉神经表征方面表现优于现有的最先进方法。

    

    解码人类视觉神经表征是一个充满挑战的任务，在揭示视觉处理机制和开发类似大脑的智能机器方面具有重要的科学意义。本文提出了一种名为 BraVL 的通用神经解码方法，它利用了脑视觉语言特征的多模态学习。我们通过多模态深度生成模型建模脑、视觉和语言特征之间的关系，具体地说，我们利用产品混合模型的形式来推断潜在代码，从而实现三种模态的协同生成。为了学习更一致的联合表示并促进跨模态泛化，我们引入了一种称为模态丢失正则化的新的训练策略。在两个不同的人类 fMRI 数据集上的实验结果表明 BraVL 在对多个类别的视觉神经表征进行解码方面优于现有的最先进方法，包括新颖和未见过的。

    Decoding human visual neural representations is a challenging task with great scientific significance in revealing vision-processing mechanisms and developing brain-like intelligent machines. Most existing methods are difficult to generalize to novel categories that have no corresponding neural data for training. The two main reasons are 1) the under-exploitation of the multimodal semantic knowledge underlying the neural data and 2) the small number of paired (stimuli-responses) training data. To overcome these limitations, this paper presents a generic neural decoding method called BraVL that uses multimodal learning of brain-visual-linguistic features. We focus on modeling the relationships between brain, visual and linguistic features via multimodal deep generative models. Specifically, we leverage the mixture-of-product-of-experts formulation to infer a latent code that enables a coherent joint generation of all three modalities. To learn a more consistent joint representation and 
    
[^84]: 无目标后门水印：朝着无害和隐蔽的数据集版权保护迈进

    Untargeted Backdoor Watermark: Towards Harmless and Stealthy Dataset Copyright Protection. (arXiv:2210.00875v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2210.00875](http://arxiv.org/abs/2210.00875)

    本文提出了一种针对数据集版权保护的无害和隐蔽的无目标后门水印方案，可以达到与最先进方案相当或更好的水印效果，并证明对模型性能无害且隐蔽。

    

    深度神经网络已在实践中展现出了其优越性。可以说，深度神经网络的快速发展在很大程度上得益于高质量（开源）数据集，研究人员和开发人员可以在此基础上轻松地评估和改进他们的学习方法。由于数据收集通常是耗时甚至昂贵的，如何保护其版权具有重要意义并值得进一步探索。本文重新审视了数据集的所有权验证。我们发现，现有的验证方法由于有目标的后门水印的特性，会在受保护的数据集上训练的深度神经网络中引入新的安全风险。为了解决这个问题，在本文中，我们探讨了无目标后门水印方案，其中异常的模型行为不是确定性的。具体而言，我们介绍了两个分散度，并证明了它们的相关性，基于此我们在受污染标签和干净标签攻击设置下设计了无目标后门水印。实验结果表明，我们提出的方法在水印提取的准确性和模型性能上都能够达到甚至超过现有最先进的方案。此外，我们提出的方法还被证明对模型性能无害且隐蔽，不会引入任何可检测的扭曲或故障。

    Deep neural networks (DNNs) have demonstrated their superiority in practice. Arguably, the rapid development of DNNs is largely benefited from high-quality (open-sourced) datasets, based on which researchers and developers can easily evaluate and improve their learning methods. Since the data collection is usually time-consuming or even expensive, how to protect their copyrights is of great significance and worth further exploration. In this paper, we revisit dataset ownership verification. We find that existing verification methods introduced new security risks in DNNs trained on the protected dataset, due to the targeted nature of poison-only backdoor watermarks. To alleviate this problem, in this work, we explore the untargeted backdoor watermarking scheme, where the abnormal model behaviors are not deterministic. Specifically, we introduce two dispersibilities and prove their correlation, based on which we design the untargeted backdoor watermark under both poisoned-label and clean
    
[^85]: 基于对齐的概率事件符合性检查

    Alignment-based conformance checking over probabilistic events. (arXiv:2209.04309v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.04309](http://arxiv.org/abs/2209.04309)

    本文介绍了一种基于对齐的概率事件符合性检查算法，该算法考虑到具有较低但足够高概率的活动，以更好地与过程模型对齐。

    

    符合性检查技术允许我们评估特定过程模型的展示行为，由监测事件的跟踪表示。现代监测和活动识别技术，如传感器、物联网、统计学和人工智能等技术，可以产生大量相关事件数据。然而，该数据通常具有噪声和不确定性，与符合性检查算法所需的确定性事件日志的假设相反。本文将基于对齐的符合性检查扩展到概率事件日志。我们介绍了加权跟踪模型和加权对齐成本函数，以及自定义阈值参数，用于控制对事件数据与过程模型的置信度水平。最终的算法考虑到具有较低但足够高概率的活动，以更好地与过程模型对齐。我们从正式和非正式的角度解释了算法及其动机，并通过合成和实际案例研究验证了其效用和效率。

    Conformance checking techniques allow us to evaluate how well some exhibited behaviour, represented by a trace of monitored events, conforms to a specified process model. Modern monitoring and activity recognition technologies, such as those relying on sensors, the IoT, statistics and AI, can produce a wealth of relevant event data. However, this data is typically characterised by noise and uncertainty, in contrast to the assumption of a deterministic event log required by conformance checking algorithms. In this paper, we extend alignment-based conformance checking to function under a probabilistic event log. We introduce a weighted trace model and weighted alignment cost function, and a custom threshold parameter that controls the level of confidence on the event data vs. the process model. The resulting algorithm considers activities of lower but sufficiently high probability that better align with the process model. We explain the algorithm and its motivation both from formal and i
    
[^86]: 使用互信息机器提高小分子生成

    Improving Small Molecule Generation using Mutual Information Machine. (arXiv:2208.09016v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.09016](http://arxiv.org/abs/2208.09016)

    MolMIM是用于小分子药物发现的概率自编码器，其学习了一种信息丰富且聚类的潜在空间，并通过促进致密的潜在空间来采样有效的分子。通过与其他模型的比较，证明了MolMIM的更好的生成能力，并展示了其出色的分子优化性能。

    

    本文研究了控制小分子生成的任务，即在一定限制条件下（如与参考分子的相似度），寻找具有所需属性的新型分子。我们介绍了MolMIM，一种用于小分子药物发现的概率自编码器，它学习了一种信息丰富且聚类的潜在空间。 MolMIM是用互信息机器（MIM）学习训练的，并提供了变长SMILES字符串的固定长度表示。由于编码器-解码器模型可以学习具有无效样本的“空洞”的表示，因此我们在训练过程中提出了一种新颖的扩展，促进了致密的潜在空间，并允许模型从潜在代码的随机扰动中采样有效的分子。我们对MolMIM与几种可变大小和固定大小的编码器-解码器模型进行了全面比较，通过有效性、独特性和新颖性等指标证明了MolMIM的更好的生成能力。然后，我们利用CMA-ES（一种朴素演化算法）来优化分子性质的组合目标函数，并展示了MolMIM在分子优化方面的表现优于现有最先进的方法。

    We address the task of controlled generation of small molecules, which entails finding novel molecules with desired properties under certain constraints (e.g., similarity to a reference molecule). Here we introduce MolMIM, a probabilistic auto-encoder for small molecule drug discovery that learns an informative and clustered latent space. MolMIM is trained with Mutual Information Machine (MIM) learning, and provides a fixed length representation of variable length SMILES strings. Since encoder-decoder models can learn representations with ``holes'' of invalid samples, here we propose a novel extension to the training procedure which promotes a dense latent space, and allows the model to sample valid molecules from random perturbations of latent codes. We provide a thorough comparison of MolMIM to several variable-size and fixed-size encoder-decoder models, demonstrating MolMIM's superior generation as measured in terms of validity, uniqueness, and novelty. We then utilize CMA-ES, a nai
    
[^87]: 多尺度注意力图像去雨神经体系结构搜索

    Multi-scale Attentive Image De-raining Networks via Neural Architecture Search. (arXiv:2207.00728v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2207.00728](http://arxiv.org/abs/2207.00728)

    本文提出了一种高性能的多尺度注意神经体系结构搜索（MANAS）框架，可用于图像去雨。 该方法自动搜索去雨网络的内部多尺度注意力结构，并采用有效的多尺度训练策略确保模型的鲁棒性。

    

    多尺度架构和注意模块已经证明在许多基于深度学习的图像去雨方法中很有效。然而，手动设计和集成这两个组件到神经网络中需要大量的劳动和广泛的专业知识。在本文中，为图像去雨技术开发了一种高性能的多尺度注意神经体系结构搜索（MANAS）框架。该方法利用多个灵活的模块构建了一个新的多尺度关注搜索空间，这些模块非常适合于图像去雨任务。在该搜索空间下，构建了多尺度注意力单元，进一步用于构建一个强大的图像去雨网络。去雨网络的内部多尺度注意力结构通过基于梯度的搜索算法自动搜索，从某种程度上避免了手动设计的繁琐过程。此外，为了获得鲁棒的图像去雨模型，进一步采用了实用且有效的多尺度训练策略，确保了模型的泛化能力。

    Multi-scale architectures and attention modules have shown effectiveness in many deep learning-based image de-raining methods. However, manually designing and integrating these two components into a neural network requires a bulk of labor and extensive expertise. In this article, a high-performance multi-scale attentive neural architecture search (MANAS) framework is technically developed for image deraining. The proposed method formulates a new multi-scale attention search space with multiple flexible modules that are favorite to the image de-raining task. Under the search space, multi-scale attentive cells are built, which are further used to construct a powerful image de-raining network. The internal multiscale attentive architecture of the de-raining network is searched automatically through a gradient-based search algorithm, which avoids the daunting procedure of the manual design to some extent. Moreover, in order to obtain a robust image de-raining model, a practical and effecti
    
[^88]: 深度学习在大规模细胞电子显微镜中的分割：文献综述

    Segmentation in large-scale cellular electron microscopy with deep learning: A literature survey. (arXiv:2206.07171v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.07171](http://arxiv.org/abs/2206.07171)

    本文综述了如何使用深度学习算法来处理大规模的电子显微镜数据集。重点讨论了算法如何应用于细胞和亚细胞结构的分割，并介绍了某些网络体系结构如何克服这些图像所产生的特殊挑战。此外，本文还提供了有关在EM中推动深度学习发展的显著数据集的全面概述，并展望了EM分割的当前趋势和未来前景，特别是在标签-free的EM中。

    

    生物医学电子显微镜中的自动化和半自动化技术使得高速获取大数据集成为了可能。因此，分割方法对于分析和解释这些大量的数据是至关重要的。近年来，深度学习算法在像素级标注（语义分割）和同一类别的不同实例的标注（实例分割）方面取得了令人瞩目的结果。本综述研究了这些算法如何被应用于细胞和亚细胞结构的分割。文章描述了这些图像所产生的特殊挑战以及克服某些挑战的网络体系结构。此外，文章还提供了有关在EM中推动深度学习发展的显著数据集的全面概述。最后，给出了当前趋势和EM分割未来前景的展望，特别是在标签-free的EM中。

    Automated and semi-automated techniques in biomedical electron microscopy (EM) enable the acquisition of large datasets at a high rate. Segmentation methods are therefore essential to analyze and interpret these large volumes of data, which can no longer completely be labeled manually. In recent years, deep learning algorithms achieved impressive results in both pixel-level labeling (semantic segmentation) and the labeling of separate instances of the same class (instance segmentation). In this review, we examine how these algorithms were adapted to the task of segmenting cellular and sub-cellular structures in EM images. The special challenges posed by such images and the network architectures that overcame some of them are described. Moreover, a thorough overview is also provided on the notable datasets that contributed to the proliferation of deep learning in EM. Finally, an outlook of current trends and future prospects of EM segmentation is given, especially in the area of label-f
    
[^89]: 带有CLIP奖励的细粒度图像描述

    Fine-grained Image Captioning with CLIP Reward. (arXiv:2205.13115v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.13115](http://arxiv.org/abs/2205.13115)

    本研究提出使用CLIP作为奖励函数, 生成更细致、独特的图像标题。通过FineCapEval测试，该方法在客观指标和人类评估方面均优于最先进的模型。

    

    现代图像描述模型通常使用文本相似性目标进行训练。然而，由于公共数据集中的参考描述通常描述最显著的共同对象，使用文本相似性目标进行训练的模型往往忽略了区分图像与其他图像的特定和详细方面。为了更详细和独特地生成标题，我们建议使用CLIP作为奖励函数，计算从网络中巨大的图像-文本对中训练的多模式编码器的多模式相似性。我们还提出了一个简单的fine-tuning策略，改进了CLIP文本编码器的语法，不需要额外的文本注释。这完全消除了在奖励计算期间参考标题的需要。为了全面评估描述性标题，我们引入了FineCapEval，这是一个具有细粒度标准（整体、背景、对象、关系）的新标注数据集。在我们的文本-图像检索和FineCapEval实验中，我们展示了我们的方法在客观指标和人类评估方面都优于最先进的模型。

    Modern image captioning models are usually trained with text similarity objectives. However, since reference captions in public datasets often describe the most salient common objects, models trained with text similarity objectives tend to ignore specific and detailed aspects of an image that distinguish it from others. Toward more descriptive and distinctive caption generation, we propose using CLIP, a multimodal encoder trained on huge image-text pairs from web, to calculate multimodal similarity and use it as a reward function. We also propose a simple finetuning strategy of the CLIP text encoder to improve grammar that does not require extra text annotation. This completely eliminates the need for reference captions during the reward computation. To comprehensively evaluate descriptive captions, we introduce FineCapEval, a new dataset for caption evaluation with fine-grained criteria: overall, background, object, relations. In our experiments on text-to-image retrieval and FineCapE
    
[^90]: 基于全局原型的增强持续学习: 对抗负表示漂移

    Enhancing Continual Learning with Global Prototypes: Counteracting Negative Representation Drift. (arXiv:2205.12186v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.12186](http://arxiv.org/abs/2205.12186)

    该论文提出了一种基于全局原型的持续学习方法，在自监督信息的正则化下学习数据表示，以缓解负面表示漂移问题，并减少持续学习中的灾难性遗忘。

    

    持续学习旨在学习一系列任务，其中数据分布从一个任务转移到另一个任务。在训练新任务数据时，旧任务的数据表示可能会漂移。一些负面的表示漂移可能会导致灾难性遗忘，因为会导致从本地学习的类别原型和数据表示在任务之间的相关性较差。为了缓解这种表示漂移，我们提出一种方法，通过全局原型指导学习，用自监督信息的正则化来学习数据表示。具体来说，对于NLP任务，我们将每个任务以屏蔽语言建模的方式进行公式化，并通过预训练的语言模型进行相邻注意机制学习任务。实验结果表明，我们提出的方法可以学习出具有较少表示漂移的相当一致的表示，并在不重新采样过去任务的数据的情况下显著减少持续学习中的灾难性遗忘。

    Continual learning (CL) aims to learn a sequence of tasks over time, with data distributions shifting from one task to another. When training on new task data, data representations from old tasks may drift. Some negative representation drift can result in catastrophic forgetting, by causing the locally learned class prototypes and data representations to correlate poorly across tasks. To mitigate such representation drift, we propose a method that finds global prototypes to guide the learning, and learns data representations with the regularization of the self-supervised information. Specifically, for NLP tasks, we formulate each task in a masked language modeling style, and learn the task via a neighbor attention mechanism over a pre-trained language model. Experimental results show that our proposed method can learn fairly consistent representations with less representation drift, and significantly reduce catastrophic forgetting in CL without resampling data from past tasks.
    
[^91]: HaMSE本体论：利用语义技术支持音乐表现互操作性和音乐学分析

    The HaMSE Ontology: Using Semantic Technologies to support Music Representation Interoperability and Musicological Analysis. (arXiv:2202.05817v1 [cs.SD] CROSS LISTED)

    [http://arxiv.org/abs/2202.05817](http://arxiv.org/abs/2202.05817)

    本论文提出了HaMSE本体论，它可以描述音乐特征并有助于音乐学研究。它通过允许不同音乐表现系统之间的对齐，并描述了一组音乐学特征，可以解决音乐表示和定量和定性数据之间的关系。

    

    使用语义技术 - 特别是语义Web - 已经成为描述文化遗产领域和艺术实践的伟大工具。 然而，音乐学应用本体的景观似乎是有限的，并且仅限于特定的应用程序。在这项研究中，我们提出了HaMSE，一种能够描述音乐特征并有助于音乐学研究的本体论。更具体而言，HaMSE旨在解决困扰音乐学研究几十年的问题：音乐的表示和定量和定性数据之间的关系。为此，HaMSE允许不同音乐表现系统之间的对齐，并描述了一组音乐学特征，可以允许以不同的粒度级别进行音乐分析。

    The use of Semantic Technologies - in particular the Semantic Web - has revealed to be a great tool for describing the cultural heritage domain and artistic practices. However, the panorama of ontologies for musicological applications seems to be limited and restricted to specific applications. In this research, we propose HaMSE, an ontology capable of describing musical features that can assist musicological research. More specifically, HaMSE proposes to address sues that have been affecting musicological research for decades: the representation of music and the relationship between quantitative and qualitative data. To do this, HaMSE allows the alignment between different music representation systems and describes a set of musicological features that can allow the music analysis at different granularity levels.
    
[^92]: CATRO：基于类感知的迹比优化的通道剪枝

    CATRO: Channel Pruning via Class-Aware Trace Ratio Optimization. (arXiv:2110.10921v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.10921](http://arxiv.org/abs/2110.10921)

    本文提出了基于类感知迹比优化的通道剪枝方法（CATRO），通过特征空间判别度量多通道的联合影响并合并保留通道的层次影响，有效降低计算负担并加速模型推理。

    

    深度卷积神经网络在许多应用场景中存在高参数和计算冗余，必要时需要进行模型剪枝以获得轻量级和高效的网络。然而，大多数现有的剪枝方法是由经验启发式的，很少考虑通道的联合影响，导致性能不确定和次优。本文提出了一种新颖的基于类感知迹比优化的通道剪枝方法（CATRO），以减少计算负担并加速模型推理。利用少量样本的类别信息，CATRO通过特征空间判别度量多通道的联合影响，并合并保留通道的层次影响。通过将通道剪枝形式化为子模函数最大化问题，CATRO通过两阶段贪心迭代优化过程有效地解决了这个问题。更重要的是，我们提出了理论分析证明了我们所提出的CATRO方法的有效性和优越性。

    Deep convolutional neural networks are shown to be overkill with high parametric and computational redundancy in many application scenarios, and an increasing number of works have explored model pruning to obtain lightweight and efficient networks. However, most existing pruning approaches are driven by empirical heuristic and rarely consider the joint impact of channels, leading to unguaranteed and suboptimal performance. In this paper, we propose a novel channel pruning method via Class-Aware Trace Ratio Optimization (CATRO) to reduce the computational burden and accelerate the model inference. Utilizing class information from a few samples, CATRO measures the joint impact of multiple channels by feature space discriminations and consolidates the layer-wise impact of preserved channels. By formulating channel pruning as a submodular set function maximization problem, CATRO solves it efficiently via a two-stage greedy iterative optimization procedure. More importantly, we present theo
    
[^93]: 基于SHAP-Score的解释的复杂性研究：通过知识编译和不可近似性结果实现可处理性

    On the Complexity of SHAP-Score-Based Explanations: Tractability via Knowledge Compilation and Non-Approximability Results. (arXiv:2104.08015v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2104.08015](http://arxiv.org/abs/2104.08015)

    该论文证明了对于确定性和可分解的布尔电路，可以在多项式时间内计算$\mathsf{SHAP}$-score，但计算大多数机器学习模型的$\mathsf{SHAP}$-scores是计算上困难的。

    

    在机器学习中，$\mathsf{SHAP}$-score是Shapley值的一个版本，用于通过给每个特征分配一个得分来解释学习模型在特定实体上的结果。虽然计算Shapley值通常是一个难以处理的问题，但我们证明了一项强有力的正面结果，即对于确定性和可分解的布尔电路，可以在多项式时间内计算$\mathsf{SHAP}$-score。这些电路在知识编译领域中得到研究，广泛推广了各种布尔电路和二进制决策图类，包括二进制决策树和有序二进制决策图（OBDD）。我们还通过观察发现，在一个布尔模型类上计算$\mathsf{SHAP}$-score总是和该类的模型计数问题一样困难的多项式问题。这意味着我们考虑的电路的确定性和可分解性都是必要的属性。这还意味着，除非NP=#P，否则计算大多数机器学习模型的$\mathsf{SHAP}$-scores是计算上困难的。

    In Machine Learning, the $\mathsf{SHAP}$-score is a version of the Shapley value that is used to explain the result of a learned model on a specific entity by assigning a score to every feature. While in general computing Shapley values is an intractable problem, we prove a strong positive result stating that the $\mathsf{SHAP}$-score can be computed in polynomial time over deterministic and decomposable Boolean circuits. Such circuits are studied in the field of Knowledge Compilation and generalize a wide range of Boolean circuits and binary decision diagrams classes, including binary decision trees and Ordered Binary Decision Diagrams (OBDDs).  We also establish the computational limits of the SHAP-score by observing that computing it over a class of Boolean models is always polynomially as hard as the model counting problem for that class. This implies that both determinism and decomposability are essential properties for the circuits that we consider. It also implies that computing
    
[^94]: 小/大世界中的学习

    Learning in a Small/Big World. (arXiv:2009.11917v8 [econ.TH] UPDATED)

    [http://arxiv.org/abs/2009.11917](http://arxiv.org/abs/2009.11917)

    这篇论文研究了在小/大世界中最优学习行为的特征，发现随着环境变得更复杂和决策者的认知能力变弱，最优行为逐渐不同。在大世界中，最优学习行为可能表现出多种非贝叶斯学习行为。

    

    复杂性和有限能力对我们在不确定性下的学习和决策有深刻的影响。本文使用有限自动机理论来模拟信念形成过程，研究了在小世界和大世界中，即环境复杂度相对于决策者的认知能力较低或较高的情况下，最优学习行为的特征。在非常小的世界中，最优行为非常接近贝叶斯基准，但随着世界的变大，最优行为则越来越不同。此外，在大世界中，最优学习行为可能表现出多种已有文献报道过的非贝叶斯学习行为，包括启发式的使用、相关忽视、持续的过度自信、不注意学习以及模型简化或误设等行为。这些结果建立了非贝叶斯学习行为、复杂度和认知能力之间明确可验证的关系。

    Complexity and limited ability have profound effect on how we learn and make decisions under uncertainty. Using the theory of finite automaton to model belief formation, this paper studies the characteristics of optimal learning behavior in small and big worlds, where the complexity of the environment is low and high, respectively, relative to the cognitive ability of the decision maker. Optimal behavior is well approximated by the Bayesian benchmark in very small world but is more different as the world gets bigger. In addition, in big worlds, the optimal learning behavior could exhibit a wide range of well-documented non-Bayesian learning behavior, including the use of heuristics, correlation neglect, persistent over-confidence, inattentive learning, and other behaviors of model simplification or misspecification. These results establish a clear and testable relationship among the prominence of non-Bayesian learning behavior, complexity, and cognitive ability.
    

