# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Preserving Knowledge Invariance: Rethinking Robustness Evaluation of Open Information Extraction.](http://arxiv.org/abs/2305.13981) | 本文提出了第一个模拟评估开放式信息提取模型在真实世界中的基准测试，并通过判断模型在整个团体上的表现是否始终准确来评估模型的鲁棒性。 |
| [^2] | [Flexible Grammar-Based Constrained Decoding for Language Models.](http://arxiv.org/abs/2305.13971) | 本文提出了一种使用形式语法约束丰富解码步骤的方法，有效生成符合特定语法的复杂输出结构，同时允许任何上下文无关语法集成。实验证明该方法在四个信息提取任务上实现了最先进的性能表现。 |
| [^3] | [REGARD: Rules of EngaGement for Automated cybeR Defense to aid in Intrusion Response.](http://arxiv.org/abs/2305.13967) | 本文介绍了REGARD框架，该框架提供了系统化和纪律性的方法，用于设计和实现自适应自主计算系统下自动网络防御代理的行动规则，特别侧重于攻击响应方面。 |
| [^4] | [CPNet: Exploiting CLIP-based Attention Condenser and Probability Map Guidance for High-fidelity Talking Face Generation.](http://arxiv.org/abs/2305.13962) | 本文提出了一种名为CPNet的网络，利用基于CLIP的关注凝聚器和概率映射指导实现高保真度的说话人脸生成。 |
| [^5] | [A Comparative Analysis of Techniques and Algorithms for Recognising Sign Language.](http://arxiv.org/abs/2305.13941) | 本研究比较了卷积神经网络、长短期记忆网络和混合模型等各种深度学习技术，用公共的中国手语识别数据集进行了测试。结果表明，一种融合了CNN和LSTM的混合模型表现最好。 |
| [^6] | [Algorithmic Unfairness through the Lens of EU Non-Discrimination Law: Or Why the Law is not a Decision Tree.](http://arxiv.org/abs/2305.13938) | 本文分析了算法不公平性的示例，并从欧盟非歧视法的角度讲述了其中涉及的不公正。同时，本文建立了框架以帮助决策者确定算法公平性指标以符合欧盟非歧视法理。 |
| [^7] | [Optimizing National Security Strategies through LLM-Driven Artificial Intelligence Integration.](http://arxiv.org/abs/2305.13927) | 本文探讨了在国家安全中人工智能的战略重要性，从军事角度审视了美国在人工智能和机器学习方面的进展，并强调了需要保护这些技术免受敌方入侵的重要性。 |
| [^8] | [Generating Data for Symbolic Language with Large Language Models.](http://arxiv.org/abs/2305.13917) | 符号语言任务中，利用大型语言模型（LLMs）生成数据的方法被提出。SymGen由信息提示和基于协议的验证器组成，可以生成各种注释昂贵的符号语言数据。相对于LLMs，使用1%大小的任务模型性能相当或更好，大幅削减了推理和部署成本。使用SymGen生成数据可以提高符号语言任务的性能和通用性。 |
| [^9] | [Deep Transductive Transfer Learning for Automatic Target Recognition.](http://arxiv.org/abs/2305.13886) | 提出了一种无配对传递迁移学习框架，使用CycleGAN模型将中波红外（MWIR）图像转换为可见（VIS）域图像（或可见图像到MWIR域），实验结果表明该方法在各种目标识别场景中都取得了最佳性能。 |
| [^10] | [Multi-Granularity Detector for Vulnerability Fixes.](http://arxiv.org/abs/2305.13884) | 针对软件漏洞修复的挑战，提出了一种名为MiDas的多粒度检测器，它利用不同级别的代码更改构建多个神经网络来识别漏洞修复提交。 |
| [^11] | [Generalized Expectation Maximization Framework for Blind Image Super Resolution.](http://arxiv.org/abs/2305.13880) | 本文提出了用于盲图像超分辨率的广义期望极大化框架，集成了学习技术，可以在统一的贝叶斯框架内进行图像恢复，包括全监督和半监督。所提出的SREMN方法在现有工作中表现卓越，并具有半监督学习的新颖性。 |
| [^12] | [Narrative XL: A Large-scale Dataset For Long-Term Memory Models.](http://arxiv.org/abs/2305.13877) | 本研究提出了一个新的用于长期记忆模型的大规模自然数据集，以帮助改进现有的大型语言模型。数据集由 GPT 3.5 生成，摘要包括来自 Project Gutenberg 的 1500 本书中每个场景的总结，以及配套的阅读理解问题。 |
| [^13] | [Fair Oversampling Technique using Heterogeneous Clusters.](http://arxiv.org/abs/2305.13875) | 本文提出了一种使用异质性聚类的公平过采样技术，可以同时解决类别不平衡和组不平衡问题，且能够抵抗过拟合。 |
| [^14] | [Variational Bayesian Framework for Advanced Image Generation with Domain-Related Variables.](http://arxiv.org/abs/2305.13872) | 本文提出一种统一的贝叶斯框架，利用变分推断技术实现高级条件生成问题，并提出了一种变分贝叶斯图像翻译网络（VBITN），可以实现无监督图像到图像转换、语义编辑和混合域翻译等任务。 |
| [^15] | [Trend-Based SAC Beam Control Method with Zero-Shot in Superconducting Linear Accelerator.](http://arxiv.org/abs/2305.13869) | 本文提出了一种基于趋势的零-shot束流控制方法，在 CAFe II 和 LPI 中取得了良好的效果，可以将校正时间缩短到人类专家所需时间的十分之一。 |
| [^16] | [Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study.](http://arxiv.org/abs/2305.13860) | 本研究探索了通过提示工程破解ChatGPT的有效性，发现破解提示可以在40种用例情况下一致地规避限制，强调了提示结构在破解ChatGPT中的重要性。 |
| [^17] | [Producing a Standard Dataset of Speed Climbing Training Videos Using Deep Learning Techniques.](http://arxiv.org/abs/2305.13858) | 本文介绍了一种使用深度学习技术创建标准速度攀爬训练视频数据集的方法，并展示了它在改进速度攀爬训练和研究方面的潜力。 |
| [^18] | [Global Structure Knowledge-Guided Relation Extraction Method for Visually-Rich Document.](http://arxiv.org/abs/2305.13850) | 这篇论文提出了一种结合全局结构知识的连续迭代的方式去捕获实体之间的依赖关系，以提高视觉丰富文档中关系抽取的准确性。 |
| [^19] | [Constrained Reinforcement Learning for Dynamic Material Handling.](http://arxiv.org/abs/2305.13824) | 本文提出了一种自适应约束强化学习算法RCPOM，用于解决动态物料搬运中的自动引导车调度问题。该算法结合了Lagrangian松弛和无效动作屏蔽，能够高效处理动态事件和提高系统性能。 |
| [^20] | [XRoute Environment: A Novel Reinforcement Learning Environment for Routing.](http://arxiv.org/abs/2305.13823) | XRoute环境是一种基于强化学习的新型路由环境，允许代理在端到端路由框架中选择和路由网络，具有挑战性且易于使用，并支持分布式部署和多实例实验。 |
| [^21] | [NORM: Knowledge Distillation via N-to-One Representation Matching.](http://arxiv.org/abs/2305.13803) | 本文提出了一种新的基于N到一的表示匹配的知识蒸馏方法NORM，通过一种特征变换模块，该模块能保留教师网络的全部信息，使得学生网络能够更好地逼近教师网络的表现。 |
| [^22] | [SE-Bridge: Speech Enhancement with Consistent Brownian Bridge.](http://arxiv.org/abs/2305.13796) | 提出了一种基于一致布朗桥的语音增强方法，该方法在节省采样时间的同时，在多个指标上实现最先进的结果。 |
| [^23] | [Proximal Policy Gradient Arborescence for Quality Diversity Reinforcement Learning.](http://arxiv.org/abs/2305.13795) | 本论文提出了一种将近端策略优化(PPO)方法与质量多样性(QD)相结合的新型QD-RL方法，用于在高吞吐量、大规模并行化机器人模拟器环境下训练能够在未知动态环境中表现出色的机器人学习智能体。 |
| [^24] | [Can Large Language Models Infer and Disagree Like Humans?.](http://arxiv.org/abs/2305.13788) | 本文研究了大型语言模型在自然语言推断方面的性能和与人类分歧分布的对齐情况。结果表明LLM的推断能力有限，无法捕捉到人类分歧分布，引发了对其NLU和代表人类用户性质的担忧。 |
| [^25] | [Perception Test: A Diagnostic Benchmark for Multimodal Video Models.](http://arxiv.org/abs/2305.13786) | 该论文提出了一个名为“感知测试”的多模态视频基准测试，可以评估预训练模型的感知和推理能力，测试涵盖了记忆、抽象、物理、语义等技能和描述性、解释性、预测性、反事实性等推理类型。 |
| [^26] | [Deep Reinforcement Learning-based Multi-objective Path Planning on the Off-road Terrain Environment for Ground Vehicles.](http://arxiv.org/abs/2305.13783) | 本文提出了一种基于深度强化学习的2.5D多目标路径规划方法，可以高效地找到距离和能耗达到良好权衡的路径。 |
| [^27] | [Counterspeeches up my sleeve! Intent Distribution Learning and Persistent Fusion for Intent-Conditioned Counterspeech Generation.](http://arxiv.org/abs/2305.13776) | 这篇论文提出了一个意图条件下的反话语生成方法QUARC，基于IntentCONAN数据集，利用向量量化表示和PerFuMe融合模块实现特定意图的反话语输出。 |
| [^28] | [Concept-aware Training Improves In-context Learning Ability of Language Models.](http://arxiv.org/abs/2305.13775) | 本研究提出了一种概念感知训练的方法，用于训练能够更好利用上下文信息的语言模型。该方法能够显著提高模型的推理能力，在多个基准测试中表现出良好的效果。 |
| [^29] | [Human Body Pose Estimation for Gait Identification: A Comprehensive Survey of Datasets and Models.](http://arxiv.org/abs/2305.13765) | 本文对人体姿态估计和步态分析进行了综述，探讨了骨架为基础的步态辨识方法。详细介绍了相关数据集、工具、方法和评估指标，并提出了未来研究的建议。 |
| [^30] | [Topic-driven Distant Supervision Framework for Macro-level Discourse Parsing.](http://arxiv.org/abs/2305.13755) | 本研究提出了一种基于主题驱动的远程监督框架，通过远程监督方法利用领域内数据生成高质量的篇章训练数据，进一步提高篇章分析性能，在使用更少的训练数据的情况下实现最先进的结果。 |
| [^31] | [L-SA: Learning Under-Explored Targets in Multi-Target Reinforcement Learning.](http://arxiv.org/abs/2305.13741) | 提出了一个用于解决多目标强化学习中探索困难目标学习问题的L-SA框架，其中包括自适应采样和主动查询。实验结果表明L-SA可以提高样本效率和成功率。 |
| [^32] | [i-Code Studio: A Configurable and Composable Framework for Integrative AI.](http://arxiv.org/abs/2305.13738) | i-Code Studio提供了一个综合、灵活和可组合的设置，可以使开发人员快速轻松地组合最先进的服务和技术，以解决复杂的多模态任务，是实现人工通用智能（AGI）的一种重要方法。 |
| [^33] | [Aligning Large Language Models through Synthetic Feedback.](http://arxiv.org/abs/2305.13735) | 该论文提出了一种使用合成反馈对齐大型语言模型的新框架，几乎不需要人力成本，也不依赖于预先对齐的LLMs。其中，通过对尺寸和提示等不同因素的普通 LLMS的响应进行奖励建模，来模拟高质量的示范来训练监督策略，并进一步使用强化学习优化模型。 |
| [^34] | [Discrete Prompt Optimization via Constrained Generation for Zero-shot Re-ranker.](http://arxiv.org/abs/2305.13729) | 本文提出了一种新的离散提示优化方法，称为受约束提示生成（Co-Prompt），通过估算最佳排序来引导 PLM 生成的文本朝向最优提示。实验结果表明，Co-Prompt 相对于基线方法表现出卓越的重排性能。 |
| [^35] | [Continual Dialogue State Tracking via Example-Guided Question Answering.](http://arxiv.org/abs/2305.13721) | 本文建议将对话状态跟踪重构为由例子引导的粒度问题回答任务，以最小化服务之间的任务转移，获得持续的学习效益。通过结合简单的持续学习策略，可以在基准数据集上获得最先进的性能。 |
| [^36] | [Knowledge of Knowledge: Exploring Known-Unknowns Uncertainty with Large Language Models.](http://arxiv.org/abs/2305.13712) | 本文探索了大型语言模型对其自身知识的理解和测量不确定性的能力。该研究聚焦于解决“已知-未知”问题，提出了新的分类方案，并使用语义评估方法量化了模型表达不确定性的准确性。 |
| [^37] | [LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models.](http://arxiv.org/abs/2305.13711) | LLM-Eval是一种针对大型语言模型的开放领域对话的多维自动评估方法，其在一个模型调用中涵盖了多个对话质量维度，并提供了有效性、高效性和适应性，是评估开放领域对话系统的多功能强大解决方案。 |
| [^38] | [Semantic-aware Transmission Scheduling: a Monotonicity-driven Deep Reinforcement Learning Approach.](http://arxiv.org/abs/2305.13706) | 这篇论文提出了一种基于单调性驱动的深度强化学习算法，用于处理在6G时代物联网系统中的大规模语义感知传输调度问题。数值结果显示所提出的算法相比基准算法可以大大减少训练时间并提高训练性能。 |
| [^39] | [Know Your Self-supervised Learning: A Survey on Image-based Generative and Discriminative Training.](http://arxiv.org/abs/2305.13689) | 自监督学习在图像计算机视觉领域中正在快速成为主要训练深度神经网络的方法。本文综述了文献中提出的用于图像生成和判别式训练的各种自监督学习方法。 |
| [^40] | [GUARD: A Safe Reinforcement Learning Benchmark.](http://arxiv.org/abs/2305.13681) | GUARD是一个广义统一安全强化学习开发基准测试平台，是目前广泛遍布且包含各种RL代理、任务和安全约束规范的一站式基准测试，能够全面涵盖最先进的安全RL算法，并具有高度的可自定义性。 |
| [^41] | [Physics of Language Models: Part 1, Context-Free Grammar.](http://arxiv.org/abs/2305.13673) | 本研究探究了生成式语言模型如何学习上下文无关文法（CFG），并通过构造人造数据证明了预训练transformers可以学会生成具有接近完美准确度和显着多样性的句子。研究发现transformer内部的隐藏状态隐含而精确地编码了CFG结构，学会形成类似动态规划的“边界到边界”的注意力。此外，还研究了标准CFG的扩展，例如概率CFG和线性CFG，并证明transformers也可以学会这些扩展语法结构。 |
| [^42] | [Mitigating Language Model Hallucination with Interactive Question-Knowledge Alignment.](http://arxiv.org/abs/2305.13669) | 本文提出了MixAlign框架，通过与用户和知识库交互，实现自动的问题-知识对齐，从而解决了语言模型因无法正确理解问题和知识而导致的幻觉问题。 |
| [^43] | [Dual Focal Loss for Calibration.](http://arxiv.org/abs/2305.13665) | 本文提出了一种新的损失函数——双聚焦损失，可以在过度自信和低自信之间达到更好的平衡，实现了最先进的校准性能。 |
| [^44] | [On the Risk of Misinformation Pollution with Large Language Models.](http://arxiv.org/abs/2305.13661) | 本文探讨了大型语言模型（LLM）可能误用的潜在风险，指出LLM可以作为有效的误导性信息生成器，导致开放域问答（ODQA）系统性能显著降低，并尝试提出三种防御策略：提示，误报检测和大多数投票。 |
| [^45] | [Non-parametric, Nearest-neighbor-assisted Fine-tuning for Neural Machine Translation.](http://arxiv.org/abs/2305.13648) | 本文探究了如何利用kNN预测的统计信息来改善fine-tuning阶段的机器翻译模型表现，通过不同的方法整合kNN统计信息，成功地提高了BLEU分数。 |
| [^46] | [Detecting and Mitigating Hallucinations in Multilingual Summarisation.](http://arxiv.org/abs/2305.13632) | 本文提出一种新的度量方法mFACT，可以在非英语摘要中评估其忠实性。本文还提出了一种简单有效的加权方法，可以通过跨语言转移减少摘要的幻觉问题。 |
| [^47] | [Instruct-Align: Teaching Novel Languages with to LLMs through Alignment-based Cross-Lingual Instruction.](http://arxiv.org/abs/2305.13627) | Instruct-Align提出了基于对齐的跨语言教学调整框架，使得教学调整的LLMs能够学习新语言，且不会发生灾难性遗忘。 |
| [^48] | [Validating Multimedia Content Moderation Software via Semantic Fusion.](http://arxiv.org/abs/2305.13623) | 该论文提出了一种名为“Semantic Fusion”的通用有效方法，通过融合两个或多个不同模态的内容审核模型来提高多媒体内容审核软件的验证效果。该方法经过大规模多媒体内容审核数据集的评估，相比现有方法显著提高了验证结果。 |
| [^49] | [SPEECH: Structured Prediction with Energy-Based Event-Centric Hyperspheres.](http://arxiv.org/abs/2305.13617) | 这篇论文提出了一种称为SPEECH的模型，它使用能量建模来表示复杂的事件结构，并使用超球来表示事件类别。实验结果表明，SPEECH在事件检测和事件关系抽取任务中表现出卓越的性能。 |
| [^50] | [Understanding Programs by Exploiting (Fuzzing) Test Cases.](http://arxiv.org/abs/2305.13592) | 本文提出了通过模糊测试获取代表性输入来帮助语义理解程序的方法。 |
| [^51] | [Model Stealing Attack against Multi-Exit Networks.](http://arxiv.org/abs/2305.13584) | 该论文介绍了第一个能同时窃取多出口网络模型函数和输出策略的攻击方法，并使用贝叶斯变点检测和性能损失、策略损失指导替代模型的训练。开发了一种新的输出策略搜索方法。 |
| [^52] | [Efficient Multi-Scale Attention Module with Cross-Spatial Learning.](http://arxiv.org/abs/2305.13563) | 本文提出了一种高效的多尺度注意力模块，重塑部分通道为批处理维度并将通道分组，以增加空间语义分布性，同时通过交叉维度交互聚合两个并行分支的输出特征。实验表明EMA可以高效地优化性能，比之前的最新方法更好。 |
| [^53] | [EntRED: Benchmarking Relation Extraction with Fewer Shortcuts.](http://arxiv.org/abs/2305.13551) | 本研究提出了一个名称更为多样、没有捷径、具有挑战性的关系提取基准测试EntRed，并解决了标准基准测试数据集存在的实体注释错误、实体名称多样性较低、从实体名称到基本事实关系的捷径等问题。 |
| [^54] | [Neural Functional Transformers.](http://arxiv.org/abs/2305.13546) | 本文提出了一种称为神经功能转换器的模型，它可以通过直接操作其权重空间处理其他神经网络作为输入，使用注意力机制来定义置换等变的权重空间层。在处理前馈MLPs和CNNs的权重的实验中，NFTs的性能与或优于先前的权重空间方法，并且开发了一种计算置换不变潜变量的新方法。 |
| [^55] | [ConvBoost: Boosting ConvNets for Sensor-based Activity Recognition.](http://arxiv.org/abs/2305.13541) | 本论文提出了ConvBoost，一种基于卷积神经网络的三层结构模型和增强框架，旨在改善传感器活动识别的效果，缓解标记训练数据不足的问题。 |
| [^56] | [The Grammar and Syntax Based Corpus Analysis Tool For The Ukrainian Language.](http://arxiv.org/abs/2305.13530) | StyloMetrix是一种基于语法和句法的文本挖掘工具，可分析乌克兰语的语法、文体和句法模式，适用于文本分类任务。 |
| [^57] | [Communication-minimizing Asynchronous Tensor Parallelism.](http://arxiv.org/abs/2305.13525) | 本文提出了Tensor3D，一种最小化通信消耗的三维张量计算并行化方法。它利用智能分布神经网络参数、新颖超分解方法以及通信模型，使训练速度提高了约3倍，GPU空闲时间降低了50％以上。 |
| [^58] | [Tied-Augment: Controlling Representation Similarity Improves Data Augmentation.](http://arxiv.org/abs/2305.13520) | Tied-Augment可以通过控制表示相似性提高数据增强的效果，可以应用于很多任务中，例如半监督学习、自监督学习等。 |
| [^59] | [Can ChatGPT Detect Intent? Evaluating Large Language Models for Spoken Language Understanding.](http://arxiv.org/abs/2305.13512) | 本文评估了几个大型预训练语言模型在口语理解任务中的表现，发现最大模型可以在零-shot学习和上下文学习中达到与监督模型相近的意图分类准确度，但在槽填充方面表现不佳，且对ASR错误敏感。 |
| [^60] | [ColMix -- A Simple Data Augmentation Framework to Improve Object Detector Performance and Robustness in Aerial Images.](http://arxiv.org/abs/2305.13509) | 本论文提出了一种新的数据增强方法——拼贴拼贴（collage pasting），用于增加目标密度，提高航空图像中的目标检测器性能和鲁棒性，并与其他方法相比证明了它的优越性。 |
| [^61] | [Multimodal Automated Fact-Checking: A Survey.](http://arxiv.org/abs/2305.13507) | 本调查提出了一个多模态自动事实核查的框架，并包括了独特的子任务，重点关注了文本，图像，音频和视频这四种模态的现实应用。纪录了相关的基准模型，讨论了未来研究的局限性和前景。 |
| [^62] | [Flover: A Temporal Fusion Framework for Efficient Autoregressive Model Parallel Inference.](http://arxiv.org/abs/2305.13484) | Flover是一种用于自回归模型并行推断的时间融合框架，解决了并行性不足和灵活性差的问题，可以实现更加高效的推断性能。 |
| [^63] | [MAILEX: Email Event and Argument Extraction.](http://arxiv.org/abs/2305.13469) | 本文提出了针对邮件领域的事件抽取数据集\dataset，比较了序列标记和生成式端到端抽取的方法，结果表明该任务存在非连续共享触发器跨度、非命名实体参数和邮件会话历史等难点，未来需要更多研究。 |
| [^64] | [The First Proven Performance Guarantees for the Non-Dominated Sorting Genetic Algorithm II (NSGA-II) on a Combinatorial Optimization Problem.](http://arxiv.org/abs/2305.13459) | 本论文对遗传算法在经典优化问题中的应用进行了研究，首次提供了经过验证的NSGA-II性能保证。 |
| [^65] | [A Meta-learning based Generalizable Indoor Localization Model using Channel State Information.](http://arxiv.org/abs/2305.13453) | 本文提出了一种基于元学习和信道状态信息的室内定位模型，以解决深度学习定位模型中持续存在的通用性缺失问题。 |
| [^66] | [Measuring and Modeling Physical Intrinsic Motivation.](http://arxiv.org/abs/2305.13452) | 本文对身体内在动机进行了量化建模，发现对抗性奖励模型可以最好地预测人类对物理情境的趣味反应，还发现简单场景特征模型无法在所有情境中预测人类反应，将对抗模型和场景中碰撞数量进行线性组合，能够显著提高对人类反应的预测能力，表明人类追求高信息增益和身体活动的情况。 |
| [^67] | [Developmental Curiosity and Social Interaction in Virtual Agents.](http://arxiv.org/abs/2305.13396) | 本文研究了以发展性好奇心为基础的内在动机如何促进代理人进行探究，并发现代表新奇性和不确定性的奖励函数最成功地产生了多样的体验，并激活了环境中的应变。 |
| [^68] | [Further Decimating the Inductive Programming Search Space with Instruction Digrams.](http://arxiv.org/abs/2305.13347) | 本文通过研究大量开源代码中指令二元组的频率分布，证明可以利用指令二元组限制指令选择从而减小搜索空间，从而提高归纳编程的效率。 |
| [^69] | [Discovering Causal Relations and Equations from Data.](http://arxiv.org/abs/2305.13341) | 物理学利用科学方法回答自然现象，发现因果关系丶物理定律和方程式是其基础。随着大数据发展，从数据中发现因果关系和方程式逐渐成为研究的核心，但仍面临多项挑战。 |
| [^70] | [Gene Set Summarization using Large Language Models.](http://arxiv.org/abs/2305.13338) | 该论文介绍了一种使用大型语言模型来对基因集进行函数概括的方法，名为SPINDOCTOR，可以提供比传统方法更好的性能和可解释性。 |
| [^71] | [3D Molecular Geometry Analysis with 2D Graphs.](http://arxiv.org/abs/2305.13315) | 本论文提出了一种使用2D图形并借助平衡信息传递神经网络（EMPNN）预测分子基态三维结构的方法。该方法可以更高效地预测准确的基态三维结构，优于RDKit和其他深度学习方法，并在属性预测任务上优于自监督学习方法。 |
| [^72] | [Training Diffusion Models with Reinforcement Learning.](http://arxiv.org/abs/2305.13301) | 本文研究了利用强化学习方法直接优化扩散模型以实现下游对象的问题，并提出一种称之为去噪扩散策略优化（DDPO）的有效策略梯度算法，能够适应难以通过提示表达的图像压缩等目标，以及通过人类反馈得出的美学质量等目标。 |
| [^73] | [GPT-SW3: An Autoregressive Language Model for the Nordic Languages.](http://arxiv.org/abs/2305.12987) | GPT-SW3是面向北欧语言的第一个本地化大型生成语言模型，本文介绍了其开发过程，可作为其他研究人员开发面向较小语言的大型生成模型的指南和参考。 |
| [^74] | [Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations.](http://arxiv.org/abs/2305.12715) | 本文提出了不精确标签学习（ILL）框架，利用期望最大化算法对不精确标签信息进行最大似然估计，为各种不精确标签配置问题提供了统一的解决方案。 |
| [^75] | [Evaluating the Performance of Large Language Models on GAOKAO Benchmark.](http://arxiv.org/abs/2305.12474) | 本文介绍了一个基于高考考试问题的基准测试GAOKAO-Benchmark，用于评估大型语言模型在客观和主观问题方面的表现。通过对ChatGPT模型的评估，研究发现其在客观问题方面表现出色，同时也揭示了其不足之处和改进的方向。 |
| [^76] | [PhotoMat: A Material Generator Learned from Single Flash Photos.](http://arxiv.org/abs/2305.12296) | PhotoMat是第一个仅基于真实物料照片进行训练的材质生成器，能够产生高质量的数字材料，超过其他依赖于合成数据和/或材质地图监督的生成模型。 |
| [^77] | [Challenges and Trends in User Trust Discourse in AI.](http://arxiv.org/abs/2305.11876) | 本文阐述在人工智能话语中用户信任面临的挑战和趋势，呼吁澄清概念以避免可能的信任差距和误解现象。 |
| [^78] | [Regularization of Soft Actor-Critic Algorithms with Automatic Temperature Adjustment.](http://arxiv.org/abs/2305.11831) | 本文提出了正则化自动温度调整的软性演员评论算法，增加了对原理的明确性。 |
| [^79] | [Evaluating task understanding through multilingual consistency: A ChatGPT case study.](http://arxiv.org/abs/2305.11662) | 本文提出了一种新的评估大型语言模型理解能力的范例，通过评估模型自身生成的不同意义之间的一致性，探讨了多语言自我一致性作为模型理解的检验方法，同时证明了ChatGPT在多语言一致性方面的优秀性能。 |
| [^80] | [Instruct2Act: Mapping Multi-modality Instructions to Robotic Actions with Large Language Model.](http://arxiv.org/abs/2305.11176) | 本文提出了Instruct2Act，利用大型语言模型将多模态指令映射到机器人操作。通过使用基础模型的专业知识和机器人的能力，将复杂的高级指令转换为精确的策略代码，该方法可调整和灵活适应各种指令模态和输入类型，并满足特定的任务需求。 |
| [^81] | [Lightweight Online Learning for Sets of Related Problems in Automated Reasoning.](http://arxiv.org/abs/2305.11087) | 本文提出了一种自动推理中解决一组相关问题的轻量级在线学习方法，它能够自动收集信息并拟合机器学习模型来调整解决策略。在实验中证明该方法能证明更大的边界和发现更多反例。 |
| [^82] | [Parameter-Efficient Fine-Tuning for Medical Image Analysis: The Missed Opportunity.](http://arxiv.org/abs/2305.08252) | 该论文综合评估了基于参数的高效调整技术（PEFT）在医学图像分析任务中的可能应用。通过超过600个控制测试，我们证明了PEFT的相对性能，并强调了PEFT在医学图像分析中实现参数高效转移学习的巨大潜力。 |
| [^83] | [When the Majority is Wrong: Leveraging Annotator Disagreement for Subjective Tasks.](http://arxiv.org/abs/2305.06626) | 本文通过预测单个标注者的打分，并结合文本目标群体的预测，模拟了目标群体成员的意见，通过使用他们的人口统计学数据和在线意见预测标注者的打分，在仇恨言论检测等主观任务中提高了模型性能。 |
| [^84] | [Putting Natural in Natural Language Processing.](http://arxiv.org/abs/2305.04572) | 自然语言处理领域过于重视书面语言，应该将口语作为主要交流方式纳入考虑，真正的自然语言处理可以超越文本，与其他语言科学更好地整合，实现更高效、更像人类的系统。 |
| [^85] | [Latest Trends in Artificial Intelligence Technology: A Scoping Review.](http://arxiv.org/abs/2305.04532) | 本文对当前最先进的人工智能技术进行了范围评估，并要求对技术解决方案进行测试、使用公认数据集以及确保结果可复制。 |
| [^86] | [AADiff: Audio-Aligned Video Synthesis with Text-to-Image Diffusion.](http://arxiv.org/abs/2305.04001) | 本文提出了一种新颖的文本到视频合成框架AADiff，它使用音频信号控制时间动态，通过音频对齐生成视频。本文的方法通过音频区域编辑和信号平滑，在时间灵活性和一致性之间取得良好的平衡。该方法的有效性已通过实验验证，并可用于内容创建。 |
| [^87] | [Vera: A General-Purpose Plausibility Estimation Model for Commonsense Statements.](http://arxiv.org/abs/2305.03695) | 本文提出了Vera模型，它是一个通用模型，可以基于常识知识估计陈述性语句的可信度。在解决验证格式的常识问题时，Vera明显优于现有的模型，并展现了对未见任务的泛化能力和良好的标定输出。 |
| [^88] | [Automated Code generation for Information Technology Tasks in YAML through Large Language Models.](http://arxiv.org/abs/2305.02783) | 这项研究提出了一种名为Ansible Wisdom的自然语言转Ansible-YAML代码的工具，可自动化生成Ansible脚本，提高IT自动化生产力，并相比现有技术达到或更好的性能水平。 |
| [^89] | [Answering Questions by Meta-Reasoning over Multiple Chains of Thought.](http://arxiv.org/abs/2304.13007) | 本论文提出了基于元推理的Multi-Chain Reasoning (MCR)方法，该方法检查多个推理链，混合它们之间的信息并选择最相关的事实，从而超越多链思维，解决多跳QA问题。 实验结果表明MCR胜过多个强基线，解释质量高。 |
| [^90] | [Towards Responsible AI in the Era of ChatGPT: A Reference Architecture for Designing Foundation Model-based AI Systems.](http://arxiv.org/abs/2304.11090) | 本文提出了一个以模式为导向的负责任AI-by-design参考架构，用于设计基于基础模型的AI系统，重点关注可解释性、公平性、安全性和鲁棒性等关键设计元素。 |
| [^91] | [Fooling Thermal Infrared Detectors in Physical World.](http://arxiv.org/abs/2304.10712) | 本论文提出一种新颖的物理攻击方法——对抗性红外块（AdvIB），可以从多个角度对热成像系统执行隐蔽的黑盒攻击，成功诱导目标红外检测器在物理场景中对对象或人类进行误分类，并且不被人类察觉。 |
| [^92] | [NeRFVS: Neural Radiance Fields for Free View Synthesis via Geometry Scaffolds.](http://arxiv.org/abs/2304.06287) | NeRFVS是一种利用神经重建的“全局信息”，包括伪深度图和视角覆盖信息，基于几何支撑的神经辐射场方法。该方法在实现室内自由导航方面表现出色且可减少可见的伪影。 |
| [^93] | [On Context Distribution Shift in Task Representation Learning for Offline Meta RL.](http://arxiv.org/abs/2304.00354) | 该论文探讨了离线元强化学习中任务表示学习中遇到的上下文分布偏移问题，并提出了一种硬采样的策略用于解决该问题，实验结果表明该方法能够得到更强健的任务表示和更好的测试性能。 |
| [^94] | [A Perspectival Mirror of the Elephant: Investigating Language Bias on Google, ChatGPT, Wikipedia, and YouTube.](http://arxiv.org/abs/2303.16281) | 研究发现在Google、ChatGPT、维基百科和YouTube上，搜索结果受限于语言，反映了与复杂主题相关的文化刻板印象，缺乏跨文化视角。 |
| [^95] | [AC2C: Adaptively Controlled Two-Hop Communication for Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2302.12515) | 本文提出了一种自适应控制的两跳通信(AC2C)协议，用于协同多智能体强化学习任务。该协议在初始的局部通信后采用自适应的两跳通信策略，以实现智能体之间的长距离信息交流，从而显著提高性能。 |
| [^96] | [ChatGPT: Jack of all trades, master of none.](http://arxiv.org/abs/2302.10724) | 本研究检验了 ChatGPT 在 25 个不同的 NLP 任务上的性能，它是一个万能的 AI 模型，但无关紧要的表现可能会对某些任务的表现产生负面影响。 |
| [^97] | [Anti-unification and Generalization: A Survey.](http://arxiv.org/abs/2302.00277) | 反升级或概括是归纳推理中使用的基本操作，是定理证明的双重操作之一。该调查报告对反升级的研究和应用进行了系统归纳和总结。 |
| [^98] | [Simulating the Integration of Urban Air Mobility into Existing Transportation Systems: A Survey.](http://arxiv.org/abs/2301.12901) | 本文调查了城市空中出行（UAM）在大都市交通中的研究现状，确定了将UAM融入城市交通系统的关键挑战和机遇，包括对现有交通模式和拥堵的影响；安全分析和风险评估；潜在的经济和环境效益；以及为UAM和地面交通开发共享基础设施和路线。同时，我们讨论了UAM的潜在好处，如缩短旅行时间和改善服务不足地区的可达性。 |
| [^99] | [Diffusion Models as Artists: Are we Closing the Gap between Humans and Machines?.](http://arxiv.org/abs/2301.11722) | 本文研究表明，扩散模型已经在拉近人与机器之间的鸿沟方面取得了进展，但机器生成作品的原创性和可识别性仍然存在差距。 |
| [^100] | [Semi-Structured Object Sequence Encoders.](http://arxiv.org/abs/2301.01015) | 本文提出了一种半结构化物体序列编码器，通过编码键的值的表示并自我关注这些键以完成下游任务来解决长对象序列的问题。 |
| [^101] | [Large Language Models are reasoners with Self-Verification.](http://arxiv.org/abs/2212.09561) | 本文提出了一种新的自我验证方法，使用CoT的结论来构建新样本并要求LLM重新预测原始条件，以提高推理准确性。实验证明，LLMs可以对其自己的结论进行自我验证并实现竞争性的推理性能。 |
| [^102] | [QEBVerif: Quantization Error Bound Verification of Neural Networks.](http://arxiv.org/abs/2212.02781) | 本文提出了一种名为QEBVerif的方法，通过量化误差边界验证神经网络的权重和激活张量，以解决在量化后关键验证属性变得无效的问题。 |
| [^103] | [Formal Controller Synthesis for Markov Jump Linear Systems with Uncertain Dynamics.](http://arxiv.org/abs/2212.00679) | 本文介绍了一种方法，用于合成马尔可夫跳变线性系统（MJLS）的控制器，以确保满足概率计算树逻辑（PCTL）公式，对于转移概率未知或已知但存在一定的区间的问题提出了解决方案。 |
| [^104] | [What's the Situation with Intelligent Mesh Generation: A Survey and Perspectives.](http://arxiv.org/abs/2211.06009) | 本文综述了智能网格生成（IMG）现状，概括了113种IMG方法的核心技术、应用范围、代理学习目标、数据类型、目标挑战、优势和局限性，并提出了三个不同的分类法。 |
| [^105] | [Sensor Control for Information Gain in Dynamic, Sparse and Partially Observed Environments.](http://arxiv.org/abs/2211.01527) | 本文提出了一种自主传感器控制方法，用于在动态、稀疏和部分可观测的环境中最大化收集有关实体信息。采用深度先行网络强化学习框架，扩展控制空间并使用混合卷积递归神经层来监测复杂的动态活动模式。 |
| [^106] | [SAM-RL: Sensing-Aware Model-Based Reinforcement Learning via Differentiable Physics-Based Simulation and Rendering.](http://arxiv.org/abs/2210.15185) | SAM-RL使用不可导物理仿真和渲染，通过比较渲染图像和真实原始图像自动更新模型，并高效产生策略。感知感知的学习管道允许机器人选择信息丰富的视角监控任务过程。 用于完成机器人组装，工具操作和变形物体操作任务。 |
| [^107] | [ASDOT: Any-Shot Data-to-Text Generation with Pretrained Language Models.](http://arxiv.org/abs/2210.04325) | 该论文提出了一种名为ASDOT的新方法，可以通过利用任何给定或没有样本进行数据到文本的生成。该方法由两个步骤组成，其使用预训练语言模型进行解决，并可适用于各种不同的场景。 |
| [^108] | [Hierarchical Adversarial Inverse Reinforcement Learning.](http://arxiv.org/abs/2210.01969) | 本文提出了一种分层对抗逆强化学习算法，能够在复杂任务中学习到具有层次结构的最优策略，比现有的方法更加有效。 |
| [^109] | [L2XGNN: Learning to Explain Graph Neural Networks.](http://arxiv.org/abs/2209.14402) | L2XGNN提出了一个框架来解释图神经网络，通过选择解释子图（模体）实现忠实的解释。该框架能够识别负责预测图属性的模体，并实现与基线方法相同的分类精度。 |
| [^110] | [A Survey of Explainable Graph Neural Networks: Taxonomy and Evaluation Metrics.](http://arxiv.org/abs/2207.12599) | 本综述全面评述了为图神经网络开发的可解释技术，着重关注可解释的图神经网络并根据使用的可解释方法进行分类。同时，提供了GNN解释的常见性能指标，并指出了几个未来的研究方向。 |
| [^111] | [Latent Combinational Game Design.](http://arxiv.org/abs/2206.14203) | 本文提出了一种名为潜在组合游戏设计的方法，使用深度生成潜变量模型将给定的一组游戏混合到所需组合中以生成可玩游戏，并且通过这种方法能够控制每个游戏在混合游戏中的比例。 |
| [^112] | [Adversarial Zoom Lens: A Novel Physical-World Attack to DNNs.](http://arxiv.org/abs/2206.12251) | 本文提出了一种名为AdvZL的新型物理敌对攻击技术，利用敌对变焦镜头对物理世界的图像进行放大和缩小，从而欺骗DNNs，同时不改变目标对象的特征。在数字和物理环境中的实验结果表明，该方法的有效性，是唯一一种不添加物理敌对扰动攻击DNNs的敌对攻击技术。 |
| [^113] | [Adversarial Laser Spot: Robust and Covert Physical-World Attack to DNNs.](http://arxiv.org/abs/2206.01034) | 这篇论文提出了一种名为对抗性激光点（AdvLS）的光学物理攻击，通过遗传算法优化激光点的物理参数进行物理攻击，实现了对DNNs的健壮和隐蔽的物理攻击。 |
| [^114] | [A Case of Exponential Convergence Rates for SVM.](http://arxiv.org/abs/2205.10055) | 本文研究了SVM的指数级收敛速度，提出了一种简单的方法来获得快速收敛速度，并在没有假设硬Tsybakov边际条件的情况下展示了SVM的指数级收敛速度现象。 |
| [^115] | [PFGE: Parsimonious Fast Geometric Ensembling of DNNs.](http://arxiv.org/abs/2202.06658) | 本论文提出了一种简洁快速几何集成深度神经网络（PFGE）的方法，该方法通过连续的随机权重平均过程生成一个轻量级的高性能DNN集合，相比之前的方法，内存效率提高了5倍，而不会影响泛化性能。 |
| [^116] | [Consequences of Slow Neural Dynamics for Incremental Learning.](http://arxiv.org/abs/2012.06694) | 本文研究了内部状态的时间平滑性如何影响神经网络的学习和表示，发现使用时间平滑的数据进行训练时，具有“慢”神经网络的网络比前馈网络更有效地学习分类，同时具有线性循环和多时间尺度门控机制的网络能够更好地表示输入的时间结构，具有更强大的泛化能力。 |

# 详细

[^1]: 保持知识不变性：重新思考开放信息抽取的鲁棒性评估

    Preserving Knowledge Invariance: Rethinking Robustness Evaluation of Open Information Extraction. (arXiv:2305.13981v1 [cs.CL])

    [http://arxiv.org/abs/2305.13981](http://arxiv.org/abs/2305.13981)

    本文提出了第一个模拟评估开放式信息提取模型在真实世界中的基准测试，并通过判断模型在整个团体上的表现是否始终准确来评估模型的鲁棒性。

    

    鲁棒性是确保自然语言处理模型能够成功应用于现实世界中的关键因素，特别是对于信息抽取任务而言。然而，大多数先前的评估基准都专注于验证配对匹配的正确性，忽略了关键的鲁棒性测量。在本文中，我们提出了第一个基准测试，模拟在真实世界中评估开放式信息提取模型的情况，其中同一知识含义的句法和表达分布会各不相同。我们设计和注释了一个大规模的测试平台，其中每个示例都是一个知识不变的团体，由具有相同含义但结构不同的句子组成。通过进一步阐述鲁棒性指标，当模型在整个团体上的表现始终准确时，被判定为鲁棒性强。我们对过去十年中发表的几种典型模型进行了实验。

    The robustness to distribution changes ensures that NLP models can be successfully applied in the realistic world, especially for information extraction tasks. However, most prior evaluation benchmarks have been devoted to validating pairwise matching correctness, ignoring the crucial measurement of robustness. In this paper, we present the first benchmark that simulates the evaluation of open information extraction models in the real world, where the syntactic and expressive distributions under the same knowledge meaning may drift variously. We design and annotate a large-scale testbed in which each example is a knowledge-invariant clique that consists of sentences with structured knowledge of the same meaning but with different syntactic and expressive forms. By further elaborating the robustness metric, a model is judged to be robust if its performance is consistently accurate on the overall cliques. We perform experiments on typical models published in the last decade as well as a 
    
[^2]: 基于语法约束的语言模型灵活解码技术

    Flexible Grammar-Based Constrained Decoding for Language Models. (arXiv:2305.13971v1 [cs.CL])

    [http://arxiv.org/abs/2305.13971](http://arxiv.org/abs/2305.13971)

    本文提出了一种使用形式语法约束丰富解码步骤的方法，有效生成符合特定语法的复杂输出结构，同时允许任何上下文无关语法集成。实验证明该方法在四个信息提取任务上实现了最先进的性能表现。

    

    LLM在许多任务中展现出了惊人的少量样本表现，但在生成信息提取所需的复杂输出结构时仍存在困难。这个限制源于LLM在没有微调的情况下倾向于生成自由文本而不是遵循特定语法的精确结构。在本文中，我们提出在解码步骤中使用形式语法约束来丰富模型。在搜索过程中，只有符合语法产生规则的有效令牌能被考虑到。这样就强制只产生有效的序列。我们的框架非常通用和灵活，允许任何上下文无关语法(CFG)集成到我们的自定义约束beam搜索实现中。我们展示了许多NLP任务的输出可以被表示为形式语言，使它们适合在我们的框架中直接使用。对于输出空间取决于输入的任务，我们提出了基于输入的CFG，根据特定于输入的特征更新产生规则。实验证明了我们的方法在生成复杂输出结构方面的有效性，并在四个信息提取任务上实现了最先进的性能。

    LLMs have shown impressive few-shot performance across many tasks. However, they still struggle when it comes to generating complex output structures, such as those required for Information Extraction. This limitation stems from the fact that LLMs, without finetuning, tend to generate free text rather than precise structures that follow a specific grammar. In this work, we propose to enrich the decoding step with formal grammar constraints. During beam search, only valid token continuations compliant with the grammar production rules are considered. This enforces the generation of valid sequences exclusively. Our framework is highly general and flexible, allowing any Context-Free Grammar (CFG) to be integrated into our custom constrained beam search implementation. We demonstrate that the outputs of many NLP tasks can be represented as formal languages, making them suitable for direct use in our framework. For task where the output space is dependent on the input, we propose input-depe
    
[^3]: REGARD：自适应自主计算系统框架下的自动化网络防御指导规则

    REGARD: Rules of EngaGement for Automated cybeR Defense to aid in Intrusion Response. (arXiv:2305.13967v1 [cs.CR])

    [http://arxiv.org/abs/2305.13967](http://arxiv.org/abs/2305.13967)

    本文介绍了REGARD框架，该框架提供了系统化和纪律性的方法，用于设计和实现自适应自主计算系统下自动网络防御代理的行动规则，特别侧重于攻击响应方面。

    

    该论文提出了一个名为“REGARD”的框架，旨在提供一个系统化和纪律性的方法来设计和实现自适应自主计算系统下自动网络防御代理的行动规则，重点关注攻击响应方面。

    Automated Intelligent Cyberdefense Agents (AICAs) that are part Intrusion Detection Systems (IDS) and part Intrusion Response Systems (IRS) are being designed to protect against sophisticated and automated cyber-attacks. An AICA based on the ideas of Self-Adaptive Autonomic Computing Systems (SA-ACS) can be considered as a managing system that protects a managed system like a personal computer, web application, critical infrastructure, etc. An AICA, specifically the IRS components, can compute a wide range of potential responses to meet its security goals and objectives, such as taking actions to prevent the attack from completing, restoring the system to comply with the organizational security policy, containing or confining an attack, attack eradication, deploying forensics measures to enable future attack analysis, counterattack, and so on. To restrict its activities in order to minimize collateral/organizational damage, such an automated system must have set Rules of Engagement (Ro
    
[^4]: CPNet：利用基于CLIP的关注凝聚器和概率映射指导实现高保真度的说话人脸生成

    CPNet: Exploiting CLIP-based Attention Condenser and Probability Map Guidance for High-fidelity Talking Face Generation. (arXiv:2305.13962v1 [cs.MM])

    [http://arxiv.org/abs/2305.13962](http://arxiv.org/abs/2305.13962)

    本文提出了一种名为CPNet的网络，利用基于CLIP的关注凝聚器和概率映射指导实现高保真度的说话人脸生成。

    

    最近，由于其艰巨的挑战和广泛的应用场景例如电影动画和虚拟主播，说话人脸生成引起了计算机视觉研究界的越来越多的关注。尽管已经进行了不断的努力来提高生成的说话人脸视频的保真度和口型同步质量，但是合成质量和效率仍有很大的提升空间。为了缓解这些困境，本文精心设计了一种全新的基于CLIP的关注和概率地图引导网络（CPNet）来推断高保真度的说话人脸视频。

    Recently, talking face generation has drawn ever-increasing attention from the research community in computer vision due to its arduous challenges and widespread application scenarios, e.g. movie animation and virtual anchor. Although persevering efforts have been undertaken to enhance the fidelity and lip-sync quality of generated talking face videos, there is still large room for further improvements of synthesis quality and efficiency. Actually, these attempts somewhat ignore the explorations of fine-granularity feature extraction/integration and the consistency between probability distributions of landmarks, thereby recurring the issues of local details blurring and degraded fidelity. To mitigate these dilemmas, in this paper, a novel CLIP-based Attention and Probability Map Guided Network (CPNet) is delicately designed for inferring high-fidelity talking face videos. Specifically, considering the demands of fine-grained feature recalibration, a clip-based attention condenser is ex
    
[^5]: 手语识别技术和算法的比较分析

    A Comparative Analysis of Techniques and Algorithms for Recognising Sign Language. (arXiv:2305.13941v1 [cs.CV])

    [http://arxiv.org/abs/2305.13941](http://arxiv.org/abs/2305.13941)

    本研究比较了卷积神经网络、长短期记忆网络和混合模型等各种深度学习技术，用公共的中国手语识别数据集进行了测试。结果表明，一种融合了CNN和LSTM的混合模型表现最好。

    

    手语是一种视觉语言，增强人与人之间的沟通，并且经常作为先天性听力丧失者主要的交流方式。尽管如此，使用手语的先天性听力丧失者并不多，他们经常面临社交孤立。因此，有必要创建人机界面系统，为听力障碍人士提供社交平台。市场上大多数商用手语翻译系统是基于传感器的，价格昂贵，使用起来也很困难。尽管迫切需要基于视觉的系统，但首先必须克服几个挑战。早期连续手语识别技术使用隐马尔可夫模型，但它们很难包含时间信息。为了克服这些限制，现在正在应用多种机器学习方法来将手部和手语动作转化为口语或书面语言。本研究比较了各种深度学习技术，包括卷积神经网络（CNN）、长短期记忆网络（LSTM）和混合模型，用公共的中国手语识别数据集进行了测试。结果表明，一种融合了CNN和LSTM的混合模型表现最好。

    Sign language is a visual language that enhances communication between people and is frequently used as the primary form of communication by people with hearing loss. Even so, not many people with hearing loss use sign language, and they frequently experience social isolation. Therefore, it is necessary to create human-computer interface systems that can offer hearing-impaired people a social platform. Most commercial sign language translation systems now on the market are sensor-based, pricey, and challenging to use. Although vision-based systems are desperately needed, they must first overcome several challenges. Earlier continuous sign language recognition techniques used hidden Markov models, which have a limited ability to include temporal information. To get over these restrictions, several machine learning approaches are being applied to transform hand and sign language motions into spoken or written language. In this study, we compare various deep learning techniques for recogn
    
[^6]: 通过欧盟非歧视法的视角讲述算法不公平性：或谓法律非决策树。

    Algorithmic Unfairness through the Lens of EU Non-Discrimination Law: Or Why the Law is not a Decision Tree. (arXiv:2305.13938v1 [cs.CY])

    [http://arxiv.org/abs/2305.13938](http://arxiv.org/abs/2305.13938)

    本文分析了算法不公平性的示例，并从欧盟非歧视法的角度讲述了其中涉及的不公正。同时，本文建立了框架以帮助决策者确定算法公平性指标以符合欧盟非歧视法理。

    

    人工智能系统中美感到不公平和歧视的问题最近引起了法律和计算机科学学者的越来越多的关注。然而，算法偏见和公平性以及法律上的歧视和平等概念之间的重叠程度通常不清楚，导致计算机科学和法律之间的误解。本文旨在阐明欧盟非歧视法与计算机科学文献中提出的算法公平性概念在多大程度上重合以及它们的区别。本文的贡献如下：首先，我们通过欧盟案例法的角度来分析算法不公平的典型例子，找出与欧盟案例法的类比之处。其次，我们建立了一个框架，以帮助决策者确定算法和AI系统的公平性指标，以确保它们符合欧盟的非歧视法理。

    Concerns regarding unfairness and discrimination in the context of artificial intelligence (AI) systems have recently received increased attention from both legal and computer science scholars. Yet, the degree of overlap between notions of algorithmic bias and fairness on the one hand, and legal notions of discrimination and equality on the other, is often unclear, leading to misunderstandings between computer science and law. What types of bias and unfairness does the law address when it prohibits discrimination? What role can fairness metrics play in establishing legal compliance? In this paper, we aim to illustrate to what extent European Union (EU) non-discrimination law coincides with notions of algorithmic fairness proposed in computer science literature and where they differ. The contributions of this paper are as follows. First, we analyse seminal examples of algorithmic unfairness through the lens of EU non-discrimination law, drawing parallels with EU case law. Second, we set
    
[^7]: 通过LLM驱动的人工智能集成优化国家安全战略

    Optimizing National Security Strategies through LLM-Driven Artificial Intelligence Integration. (arXiv:2305.13927v1 [cs.CY])

    [http://arxiv.org/abs/2305.13927](http://arxiv.org/abs/2305.13927)

    本文探讨了在国家安全中人工智能的战略重要性，从军事角度审视了美国在人工智能和机器学习方面的进展，并强调了需要保护这些技术免受敌方入侵的重要性。

    

    随着人工智能和机器学习的不断发展，我们必须了解它们在国家安全中的战略重要性。本文聚焦于军事中独特的AI应用，强调成功的战略要求，并旨在重新点燃AI在国家安全中的角色的激情。我们将从军事角度审视美国在人工智能和机器学习方面的进展，讨论保护这些技术免受敌方入侵的重要性，并探讨其集成所面临的挑战和风险。最后，我们将强调人工智能对国家安全的战略意义以及一系列军事领袖和政策制定者的战略要求。

    As artificial intelligence and machine learning continue to advance, we must understand their strategic importance in national security. This paper focuses on unique AI applications in the military, emphasizes strategic imperatives for success, and aims to rekindle excitement about AI's role in national security. We will examine the United States progress in AI and ML from a military standpoint, discuss the importance of securing these technologies from adversaries, and explore the challenges and risks associated with their integration. Finally, we will highlight the strategic significance of AI to national security and a set of strategic imperatives for military leaders and policymakers
    
[^8]: 利用大型语言模型生成符号语言数据

    Generating Data for Symbolic Language with Large Language Models. (arXiv:2305.13917v1 [cs.CL])

    [http://arxiv.org/abs/2305.13917](http://arxiv.org/abs/2305.13917)

    符号语言任务中，利用大型语言模型（LLMs）生成数据的方法被提出。SymGen由信息提示和基于协议的验证器组成，可以生成各种注释昂贵的符号语言数据。相对于LLMs，使用1%大小的任务模型性能相当或更好，大幅削减了推理和部署成本。使用SymGen生成数据可以提高符号语言任务的性能和通用性。

    

    尽管大型语言模型（LLMs）带来了性能提升，但也增加了复杂性。最近的研究开始将LLMs转换为数据生成器而不是任务推理器，通过训练另一个可负担的任务模型以实现高效部署和推理。然而，这种方法主要被应用于自然语言任务，并且尚未探索用于具有复杂结构输出（例如语义解析和代码生成）的符号语言任务。本文提出了SymGen，利用LLMs生成各种注释昂贵的符号语言数据。SymGen由信息提示和基于协议的验证器组成，以提高数据的正确性。我们在各种设置下对六个符号语言任务进行了大量实验。与LLMs相比，我们证明1\%大小的任务模型可以实现相当或更好的性能，大大降低了推理和部署成本。我们还展示了使用SymGen生成数据可以提高符号语言任务的性能和通用性。

    While large language models (LLMs) bring not only performance but also complexity, recent work has started to turn LLMs into data generators rather than task inferencers, where another affordable task model is trained for efficient deployment and inference. However, such an approach has primarily been applied to natural language tasks and has not yet been explored for symbolic language tasks with complex structured outputs (e.g., semantic parsing and code generation). In this paper, we propose SymGen which utilizes LLMs for generating various annotation-expensive symbolic language data. SymGen consists of an informative prompt to steer generation and an agreement-based verifier to improve data correctness. We conduct extensive experiments on six symbolic language tasks across various settings. Compared with the LLMs, we demonstrate the 1\%-sized task model can achieve comparable or better performance, largely cutting inference and deployment costs. We also show that generated data with
    
[^9]: 深度传递迁移学习用于自动目标识别

    Deep Transductive Transfer Learning for Automatic Target Recognition. (arXiv:2305.13886v1 [cs.CV])

    [http://arxiv.org/abs/2305.13886](http://arxiv.org/abs/2305.13886)

    提出了一种无配对传递迁移学习框架，使用CycleGAN模型将中波红外（MWIR）图像转换为可见（VIS）域图像（或可见图像到MWIR域），实验结果表明该方法在各种目标识别场景中都取得了最佳性能。

    

    自动目标识别算法的一个主要障碍是通常存在一个领域（红外源领域）中有标记的图像，但在其他目标领域（如可见、SAR、LIDAR）中没有注释的图像。因此，自动注释这些图像对于基于源领域标记图像构建目标领域的强大分类器至关重要。传递迁移学习是一种有效的方法，通过利用在源域中预训练的自动目标识别网络来使网络适应一个新的目标领域。我们提出了一种无配对传递迁移学习框架，其中使用CycleGAN模型和源域中训练良好的ATR分类器来构建目标域的ATR分类器，而不需要目标域中的任何标记数据。我们使用CycleGAN模型将中波红外（MWIR）图像转换为可见（VIS）域图像（或可见图像到MWIR域）。为了训练传递迁移学习，我们使用相位一致性损失和感知损失。实验结果表明，我们的方法在各种目标识别场景中都取得了最佳性能。

    One of the major obstacles in designing an automatic target recognition (ATR) algorithm, is that there are often labeled images in one domain (i.e., infrared source domain) but no annotated images in the other target domains (i.e., visible, SAR, LIDAR). Therefore, automatically annotating these images is essential to build a robust classifier in the target domain based on the labeled images of the source domain. Transductive transfer learning is an effective way to adapt a network to a new target domain by utilizing a pretrained ATR network in the source domain. We propose an unpaired transductive transfer learning framework where a CycleGAN model and a well-trained ATR classifier in the source domain are used to construct an ATR classifier in the target domain without having any labeled data in the target domain. We employ a CycleGAN model to transfer the mid-wave infrared (MWIR) images to visible (VIS) domain images (or visible to MWIR domain). To train the transductive CycleGAN, we 
    
[^10]: 漏洞修复的多粒度检测器

    Multi-Granularity Detector for Vulnerability Fixes. (arXiv:2305.13884v1 [cs.CR])

    [http://arxiv.org/abs/2305.13884](http://arxiv.org/abs/2305.13884)

    针对软件漏洞修复的挑战，提出了一种名为MiDas的多粒度检测器，它利用不同级别的代码更改构建多个神经网络来识别漏洞修复提交。

    

    随着对开源软件的日益依赖，用户暴露于第三方库漏洞之中。为了提醒用户此类漏洞，已经开发了软件组成分析（SCA）工具。SCA需要确定漏洞修复提交。以前的工作已经提出了可以自动识别这样的漏洞修复提交的方法。然而，鉴定这样的提交是极具挑战性的，因为只有极少数提交是漏洞修复。此外，代码更改可能是嘈杂且难以分析的。我们观察到，噪声可以出现在不同层次的细节中，使得准确检测漏洞修复变得极具挑战性。为了应对这些挑战并提高以前工作的有效性，我们提出了MiDas（漏洞修复的多粒度检测器）。MiDas与以前的工作不同，它为每个代码更改粒度级别构建不同的神经网络，分别对应于提交级别、文件级别、碎片级别。

    With the increasing reliance on Open Source Software, users are exposed to third-party library vulnerabilities. Software Composition Analysis (SCA) tools have been created to alert users of such vulnerabilities. SCA requires the identification of vulnerability-fixing commits. Prior works have proposed methods that can automatically identify such vulnerability-fixing commits. However, identifying such commits is highly challenging, as only a very small minority of commits are vulnerability fixing. Moreover, code changes can be noisy and difficult to analyze. We observe that noise can occur at different levels of detail, making it challenging to detect vulnerability fixes accurately.  To address these challenges and boost the effectiveness of prior works, we propose MiDas (Multi-Granularity Detector for Vulnerability Fixes). Unique from prior works, Midas constructs different neural networks for each level of code change granularity, corresponding to commit-level, file-level, hunk-level,
    
[^11]: 盲图像超分辨率的广义期望极大化框架

    Generalized Expectation Maximization Framework for Blind Image Super Resolution. (arXiv:2305.13880v1 [cs.CV])

    [http://arxiv.org/abs/2305.13880](http://arxiv.org/abs/2305.13880)

    本文提出了用于盲图像超分辨率的广义期望极大化框架，集成了学习技术，可以在统一的贝叶斯框架内进行图像恢复，包括全监督和半监督。所提出的SREMN方法在现有工作中表现卓越，并具有半监督学习的新颖性。

    

    基于学习的盲单张图像超分辨率（SISR）方法通过高分辨率（HR）图像和它们的低分辨率（LR）对应物间的学习映射进行恢复，这些对应物用任意模糊核降级。然而，这些方法大多需要一个独立的步骤来估计模糊核，导致步骤之间的误差累积。我们提出了一个用于盲SISR问题的端到端学习框架，可以在统一的贝叶斯框架内进行图像恢复，包括全监督和半监督。所提出的方法称为SREMN，将学习技术整合到广义期望最大化算法中，并从最大似然估计（MLE）中推断HR图像。广泛的实验表明，与现有工作相比，所提出的方法具有卓越性能和半监督学习的新颖性。

    Learning-based methods for blind single image super resolution (SISR) conduct the restoration by a learned mapping between high-resolution (HR) images and their low-resolution (LR) counterparts degraded with arbitrary blur kernels. However, these methods mostly require an independent step to estimate the blur kernel, leading to error accumulation between steps. We propose an end-to-end learning framework for the blind SISR problem, which enables image restoration within a unified Bayesian framework with either full- or semi-supervision. The proposed method, namely SREMN, integrates learning techniques into the generalized expectation-maximization (GEM) algorithm and infers HR images from the maximum likelihood estimation (MLE). Extensive experiments show the superiority of the proposed method with comparison to existing work and novelty in semi-supervised learning.
    
[^12]: Narrative XL: 一个用于长期记忆模型的大规模数据集

    Narrative XL: A Large-scale Dataset For Long-Term Memory Models. (arXiv:2305.13877v1 [cs.CL])

    [http://arxiv.org/abs/2305.13877](http://arxiv.org/abs/2305.13877)

    本研究提出了一个新的用于长期记忆模型的大规模自然数据集，以帮助改进现有的大型语言模型。数据集由 GPT 3.5 生成，摘要包括来自 Project Gutenberg 的 1500 本书中每个场景的总结，以及配套的阅读理解问题。

    

    虽然大多数大型语言模型取得了巨大的成功，但它们缺乏任何长期记忆机制，这限制了它们的应用。要克服这一限制，不仅需要对典型的变压器架构或训练程序进行更改，还需要一个可以训练和评估这些新模型的数据集。我们认为现有的资源缺少一些关键属性，目前没有足够规模的自然数据集来训练（而不仅仅是评估）长期记忆语言模型。然后，我们提出了利用短期记忆语言模型的进展来创建这样一个数据集的解决方案。使用 GPT 3.5，我们总结了 Project Gutenberg 中 1500 本手工筛选的书籍中的每个场景，每本书得到大约 150 个场景级别的摘要。然后，我们创建了一些阅读理解问题，包括三种类型的多项选择场景识别问题，以及...

    Despite their tremendous successes, most large language models do not have any long-term memory mechanisms, which restricts their applications. Overcoming this limitation would not only require changes to the typical transformer architectures or training procedures, but also a dataset on which these new models could be trained and evaluated. We argue that existing resources lack a few key properties, and that at present, there are no naturalistic datasets of sufficient scale to train (and not only evaluate) long-term memory language models. We then present our solution that capitalizes on the advances in short-term memory language models to create such a dataset. Using GPT 3.5, we summarized each scene in 1500 hand-curated books from Project Gutenberg, which resulted in approximately 150 scene-level summaries per book. We then created a number of reading comprehension questions based on these summaries, including three types of multiple-choice scene recognition questions, as well as fr
    
[^13]: 使用异质性聚类的公平过采样技术

    Fair Oversampling Technique using Heterogeneous Clusters. (arXiv:2305.13875v1 [cs.LG])

    [http://arxiv.org/abs/2305.13875](http://arxiv.org/abs/2305.13875)

    本文提出了一种使用异质性聚类的公平过采样技术，可以同时解决类别不平衡和组不平衡问题，且能够抵抗过拟合。

    

    数据中的类别不平衡和组不平衡被认为是妨碍机器学习分类器公平性和效用之间权衡的两个原因。现有技术通过提出公平过采样技术来共同解决类别不平衡和组不平衡问题。我们提出了一种使用异质性群集数据的公平过采样技术，产生的合成数据具有混合类特征或混合组特征，使分类器能够抵抗过拟合。此外，我们开发了一种插值方法，可以提高生成的合成数据的有效性。

    Class imbalance and group (e.g., race, gender, and age) imbalance are acknowledged as two reasons in data that hinder the trade-off between fairness and utility of machine learning classifiers. Existing techniques have jointly addressed issues regarding class imbalance and group imbalance by proposing fair over-sampling techniques. Unlike the common oversampling techniques, which only address class imbalance, fair oversampling techniques significantly improve the abovementioned trade-off, as they can also address group imbalance. However, if the size of the original clusters is too small, these techniques may cause classifier overfitting. To address this problem, we herein develop a fair oversampling technique using data from heterogeneous clusters. The proposed technique generates synthetic data that have class-mix features or group-mix features to make classifiers robust to overfitting. Moreover, we develop an interpolation method that can enhance the validity of generated synthetic 
    
[^14]: 具有领域相关变量的高级图像生成的变分贝叶斯框架

    Variational Bayesian Framework for Advanced Image Generation with Domain-Related Variables. (arXiv:2305.13872v1 [cs.CV])

    [http://arxiv.org/abs/2305.13872](http://arxiv.org/abs/2305.13872)

    本文提出一种统一的贝叶斯框架，利用变分推断技术实现高级条件生成问题，并提出了一种变分贝叶斯图像翻译网络（VBITN），可以实现无监督图像到图像转换、语义编辑和混合域翻译等任务。

    

    深度生成模型（DGM）以及它们的条件表征为数据分布提供了强大的通用生成建模能力。然而，缺乏注释的情况下，现有方法仍然难以解决高级条件生成问题，而这种方法能够实现多种应用，如图像到图像的转换和图像编辑。我们提出了一个统一的贝叶斯框架，引入了学习过程中潜在变量的推断阶段，特别是我们提出了一个变分贝叶斯图像翻译网络（VBITN），它可以实现多种图像翻译和编辑任务。全面的实验展示了我们方法在无监督图像到图像转换上的有效性，并展示了语义编辑和混合域翻译的创新高级能力。

    Deep generative models (DGMs) and their conditional counterparts provide a powerful ability for general-purpose generative modeling of data distributions. However, it remains challenging for existing methods to address advanced conditional generative problems without annotations, which can enable multiple applications like image-to-image translation and image editing. We present a unified Bayesian framework for such problems, which introduces an inference stage on latent variables within the learning process. In particular, we propose a variational Bayesian image translation network (VBITN) that enables multiple image translation and editing tasks. Comprehensive experiments show the effectiveness of our method on unsupervised image-to-image translation, and demonstrate the novel advanced capabilities for semantic editing and mixed domain translation.
    
[^15]: 一种基于趋势的超导线性加速器零-shot束流控制方法

    Trend-Based SAC Beam Control Method with Zero-Shot in Superconducting Linear Accelerator. (arXiv:2305.13869v1 [physics.acc-ph])

    [http://arxiv.org/abs/2305.13869](http://arxiv.org/abs/2305.13869)

    本文提出了一种基于趋势的零-shot束流控制方法，在 CAFe II 和 LPI 中取得了良好的效果，可以将校正时间缩短到人类专家所需时间的十分之一。

    

    超导线性加速器是现代科学研究的高度灵活的设施，需要每周重新配置和调整。因此，最小化设置时间对于提供充足的实验时间至关重要。我们提出了一种基于趋势的软 actor-critic(TBSAC)束流控制方法，具有强大的鲁棒性，允许代理在模拟环境中进行训练，并直接应用于真正的加速器中，实现了零-shot控制。为了验证我们的方法的有效性，分别在中国超重元素加速器设施(CAFe II)和一个轻质粒子注入器(LPI)中执行了两个不同的典型束流控制任务。在CAFe II的三个低温模块中分别执行了轨道校正任务，调谐所需时间已经减少到人类专家所需时间的十分之一，校正后的RMS值都小于1毫米。另一个传输效率优化任务在CAFe II的加速器段LPI中进行了

    The superconducting linear accelerator is a highly flexiable facility for modern scientific discoveries, necessitating weekly reconfiguration and tuning. Accordingly, minimizing setup time proves essential in affording users with ample experimental time. We propose a trend-based soft actor-critic(TBSAC) beam control method with strong robustness, allowing the agents to be trained in a simulated environment and applied to the real accelerator directly with zero-shot. To validate the effectiveness of our method, two different typical beam control tasks were performed on China Accelerator Facility for Superheavy Elements (CAFe II) and a light particle injector(LPI) respectively. The orbit correction tasks were performed in three cryomodules in CAFe II seperately, the time required for tuning has been reduced to one-tenth of that needed by human experts, and the RMS values of the corrected orbit were all less than 1mm. The other transmission efficiency optimization task was conducted in th
    
[^16]: 通过提示工程破解ChatGPT：一项实证研究

    Jailbreaking ChatGPT via Prompt Engineering: An Empirical Study. (arXiv:2305.13860v1 [cs.SE])

    [http://arxiv.org/abs/2305.13860](http://arxiv.org/abs/2305.13860)

    本研究探索了通过提示工程破解ChatGPT的有效性，发现破解提示可以在40种用例情况下一致地规避限制，强调了提示结构在破解ChatGPT中的重要性。

    

    大型语言模型（LLMs）如ChatGPT已经展示了强大的潜力，但同时也引发了与内容约束和潜在滥用相关的挑战。我们的研究探究了三个关键问题：（1）可以用多少种不同的提示类型破解LLMs，（2）破解提示在规避LLM限制方面的有效性以及（3）ChatGPT对这些破解提示的韧性。首先，我们开发了一个分类模型来分析现有提示的分布，识别出十个不同模式和三个破解提示类别。随后，我们使用3,120个禁止情景下的狱中问题数据集评估ChatGPT 3.5和4.0版本的破解能力。最后，我们评估了ChatGPT对破解提示的抵抗力，发现提示可以在40种用例情景下一致地规避限制。该研究强调了提示结构在破解ChatGPT中的重要性，并突出了LLMs对意外滥用的敏感性。

    Large Language Models (LLMs), like ChatGPT, have demonstrated vast potential but also introduce challenges related to content constraints and potential misuse. Our study investigates three key research questions: (1) the number of different prompt types that can jailbreak LLMs, (2) the effectiveness of jailbreak prompts in circumventing LLM constraints, and (3) the resilience of ChatGPT against these jailbreak prompts. Initially, we develop a classification model to analyze the distribution of existing prompts, identifying ten distinct patterns and three categories of jailbreak prompts. Subsequently, we assess the jailbreak capability of prompts with ChatGPT versions 3.5 and 4.0, utilizing a dataset of 3,120 jailbreak questions across eight prohibited scenarios. Finally, we evaluate the resistance of ChatGPT against jailbreak prompts, finding that the prompts can consistently evade the restrictions in 40 use-case scenarios. The study underscores the importance of prompt structures in j
    
[^17]: 使用深度学习技术生成标准的速度攀爬训练视频数据集

    Producing a Standard Dataset of Speed Climbing Training Videos Using Deep Learning Techniques. (arXiv:2305.13858v1 [cs.CV])

    [http://arxiv.org/abs/2305.13858](http://arxiv.org/abs/2305.13858)

    本文介绍了一种使用深度学习技术创建标准速度攀爬训练视频数据集的方法，并展示了它在改进速度攀爬训练和研究方面的潜力。

    

    本文介绍了一种使用多摄像头记录速度攀爬训练课程和注释视频相关数据的方法，其中包括身体姿势、手和脚的位置和时间等信息。然后利用深度学习技术分析注释数据，创建了标准的速度攀爬训练视频数据集。结果展示了这个新数据集在改进速度攀爬训练和研究方面的潜力，包括寻找改进的领域、创建个性化的训练计划以及分析不同训练方法的影响。这些发现还将通过进一步的经验研究应用于江西攀爬队的培训过程中，以测试这些发现并进一步探索这项研究的可行性。

    This dissertation presents a methodology for recording speed climbing training sessions with multiple cameras and annotating the videos with relevant data, including body position, hand and foot placement, and timing. The annotated data is then analyzed using deep learning techniques to create a standard dataset of speed climbing training videos. The results demonstrate the potential of the new dataset for improving speed climbing training and research, including identifying areas for improvement, creating personalized training plans, and analyzing the effects of different training methods.The findings will also be applied to the training process of the Jiangxi climbing team through further empirical research to test the findings and further explore the feasibility of this study.
    
[^18]: 结合全局结构知识的视觉丰富文档关系抽取方法

    Global Structure Knowledge-Guided Relation Extraction Method for Visually-Rich Document. (arXiv:2305.13850v1 [cs.CL])

    [http://arxiv.org/abs/2305.13850](http://arxiv.org/abs/2305.13850)

    这篇论文提出了一种结合全局结构知识的连续迭代的方式去捕获实体之间的依赖关系，以提高视觉丰富文档中关系抽取的准确性。

    

    视觉关系提取（VRE）旨在从视觉丰富的文档中提取实体之间的关系。现有方法通常基于实体特征单独预测每对实体之间的关系，但忽略了全局结构信息，即实体对之间的依赖关系。缺乏全局结构信息可能使模型难以学习长程关系，并容易产生冲突的预测结果。为了缓解这些限制，我们提出了一种GOSE框架，该框架以迭代的方式捕获实体对之间的依赖关系。给定文档的扫描图像，GOSE首先对实体对生成初步的关系预测。第二，在先前迭代的预测结果基础上，GOSE利用全局结构知识进一步整合实体表示。这种“生成-捕获-整合”模式被多次执行，以便实体之间的依赖关系能够被很好地捕获和利用。

    Visual relation extraction (VRE) aims to extract relations between entities from visuallyrich documents. Existing methods usually predict relations for each entity pair independently based on entity features but ignore the global structure information, i.e., dependencies between entity pairs. The absence of global structure information may make the model struggle to learn long-range relations and easily predict conflicted results. To alleviate such limitations, we propose a GlObal Structure knowledgeguided relation Extraction (GOSE) framework, which captures dependencies between entity pairs in an iterative manner. Given a scanned image of the document, GOSE firstly generates preliminary relation predictions on entity pairs. Secondly, it mines global structure knowledge based on prediction results of the previous iteration and further incorporates global structure knowledge into entity representations. This "generate-capture-incorporate" schema is performed multiple times so that entit
    
[^19]: 动态物料搬运的约束强化学习

    Constrained Reinforcement Learning for Dynamic Material Handling. (arXiv:2305.13824v1 [cs.LG])

    [http://arxiv.org/abs/2305.13824](http://arxiv.org/abs/2305.13824)

    本文提出了一种自适应约束强化学习算法RCPOM，用于解决动态物料搬运中的自动引导车调度问题。该算法结合了Lagrangian松弛和无效动作屏蔽，能够高效处理动态事件和提高系统性能。

    

    物料搬运是柔性制造系统的核心部分之一，涉及自动化车辆在工作站之间的物料存储和搬运。物料搬运的改善可以促进制造系统的整体效率。然而，在任务安排的优化过程中发生的动态事件对适应性和效率构成了挑战。本文旨在对动态物料搬运中的自动引导车进行调度。在一些真实场景的启发下，我们将未知的新任务和意外的车辆故障视为我们问题中的动态事件。我们将问题表述为考虑到迟到和可用车辆作为累积约束和瞬时约束的约束马尔可夫决策过程。提出了一种自适应约束强化学习算法RCPOM，它结合了Lagrangian松弛和无效动作屏蔽，用于解决这个问题。实验结果表明它在处理动态事件和提高系统性能方面的有效性和效率。

    As one of the core parts of flexible manufacturing systems, material handling involves storage and transportation of materials between workstations with automated vehicles. The improvement in material handling can impulse the overall efficiency of the manufacturing system. However, the occurrence of dynamic events during the optimisation of task arrangements poses a challenge that requires adaptability and effectiveness. In this paper, we aim at the scheduling of automated guided vehicles for dynamic material handling. Motivated by some real-world scenarios, unknown new tasks and unexpected vehicle breakdowns are regarded as dynamic events in our problem. We formulate the problem as a constrained Markov decision process which takes into account tardiness and available vehicles as cumulative and instantaneous constraints, respectively. An adaptive constrained reinforcement learning algorithm that combines Lagrangian relaxation and invalid action masking, named RCPOM, is proposed to addr
    
[^20]: XRoute环境：一种基于强化学习的新型路由环境

    XRoute Environment: A Novel Reinforcement Learning Environment for Routing. (arXiv:2305.13823v1 [cs.AI])

    [http://arxiv.org/abs/2305.13823](http://arxiv.org/abs/2305.13823)

    XRoute环境是一种基于强化学习的新型路由环境，允许代理在端到端路由框架中选择和路由网络，具有挑战性且易于使用，并支持分布式部署和多实例实验。

    

    路由是现代设计自动化流程中至关重要且耗时的阶段，强化学习领域的巨大进展使得可以利用这些方法来改善路由质量和效率。然而，最近研究中基于强化学习的方法解决的路由问题规模太小，无法在商业EDA工具中使用。我们介绍了XRoute环境，这是一种新的强化学习环境，其中代理被训练在先进的端到端路由框架中选择和路由网络。这个环境可以快速安全且可重复地测试新算法和想法，并且具有挑战性，易于使用，定制和添加其他场景，并且在一个宽松的开源许可下提供支持分布式部署和多实例实验。我们提出了两个学习任务并构建了一个完整芯片测试。

    Routing is a crucial and time-consuming stage in modern design automation flow for advanced technology nodes. Great progress in the field of reinforcement learning makes it possible to use those approaches to improve the routing quality and efficiency. However, the scale of the routing problems solved by reinforcement learning-based methods in recent studies is too small for these methods to be used in commercial EDA tools. We introduce the XRoute Environment, a new reinforcement learning environment where agents are trained to select and route nets in an advanced, end-to-end routing framework. Novel algorithms and ideas can be quickly tested in a safe and reproducible manner in it. The resulting environment is challenging, easy to use, customize and add additional scenarios, and it is available under a permissive open-source license. In addition, it provides support for distributed deployment and multi-instance experiments. We propose two tasks for learning and build a full-chip test 
    
[^21]: 基于N到一的表示匹配的知识蒸馏

    NORM: Knowledge Distillation via N-to-One Representation Matching. (arXiv:2305.13803v1 [cs.CV])

    [http://arxiv.org/abs/2305.13803](http://arxiv.org/abs/2305.13803)

    本文提出了一种新的基于N到一的表示匹配的知识蒸馏方法NORM，通过一种特征变换模块，该模块能保留教师网络的全部信息，使得学生网络能够更好地逼近教师网络的表现。

    

    现有的特征蒸馏方法通常采用预选的师生层对之间的一对一表示匹配。在本文中，我们提出了一种新的双阶段知识蒸馏方法N到一表示（NORM），它依赖于一个由两个线性层组成的简单特征变换（FT）模块。为了保留由教师网络学习的完整信息，在训练期间，我们的FT模块仅插入在学生网络的最后一个卷积层之后。第一层线性层将学生表示投射到一个特征空间中，该特征空间的特征通道数是最后一个卷积层中教师表示的N倍，第二个线性层将扩展的输出收缩回原始特征空间。通过将扩展的学生表示顺序分成N个不重叠的特征段，每个段具有与教师的相同数量的特征通道，它们可以很容易地强制近似于教师的表示.

    Existing feature distillation methods commonly adopt the One-to-one Representation Matching between any pre-selected teacher-student layer pair. In this paper, we present N-to-One Representation (NORM), a new two-stage knowledge distillation method, which relies on a simple Feature Transform (FT) module consisting of two linear layers. In view of preserving the intact information learnt by the teacher network, during training, our FT module is merely inserted after the last convolutional layer of the student network. The first linear layer projects the student representation to a feature space having N times feature channels than the teacher representation from the last convolutional layer, and the second linear layer contracts the expanded output back to the original feature space. By sequentially splitting the expanded student representation into N non-overlapping feature segments having the same number of feature channels as the teacher's, they can be readily forced to approximate t
    
[^22]: SE-Bridge: 一种基于一致布朗桥的语音增强方法

    SE-Bridge: Speech Enhancement with Consistent Brownian Bridge. (arXiv:2305.13796v1 [cs.SD])

    [http://arxiv.org/abs/2305.13796](http://arxiv.org/abs/2305.13796)

    提出了一种基于一致布朗桥的语音增强方法，该方法在节省采样时间的同时，在多个指标上实现最先进的结果。

    

    我们提出了一种名为SE-Bridge的新型语音增强方法。在最近将扩散模型应用于语音增强之后，我们可以通过解决随机微分方程（SDE）来实现语音增强。每个SDE对应一个概率流普通微分方程（PF-ODE），PF-ODE解的轨迹由不同时刻的语音状态组成。我们的方法基于一致性模型，该模型确保同一PF-ODE轨迹上的任何语音状态对应于同一初始状态。通过集成布朗桥过程，该模型能够生成高可懂性的语音样本，无需敌对训练。这是第一次将一致性模型应用于SE任务，在多个指标上实现了最先进的结果，同时相对于基于扩散的基线，节省了15倍的采样时间。我们在多个数据集上的实验证明了SE-Bridge在SE中的有效性。此外，我们还展示了我们提出的方法在看护机器人任务中的应用。

    We propose SE-Bridge, a novel method for speech enhancement (SE). After recently applying the diffusion models to speech enhancement, we can achieve speech enhancement by solving a stochastic differential equation (SDE). Each SDE corresponds to a probabilistic flow ordinary differential equation (PF-ODE), and the trajectory of the PF-ODE solution consists of the speech states at different moments. Our approach is based on consistency model that ensure any speech states on the same PF-ODE trajectory, correspond to the same initial state. By integrating the Brownian Bridge process, the model is able to generate high-intelligibility speech samples without adversarial training. This is the first attempt that applies the consistency models to SE task, achieving state-of-the-art results in several metrics while saving 15 x the time required for sampling compared to the diffusion-based baseline. Our experiments on multiple datasets demonstrate the effectiveness of SE-Bridge in SE. Furthermore
    
[^23]: 质量多样性强化学习中的近端策略梯度树枝方法

    Proximal Policy Gradient Arborescence for Quality Diversity Reinforcement Learning. (arXiv:2305.13795v1 [cs.LG])

    [http://arxiv.org/abs/2305.13795](http://arxiv.org/abs/2305.13795)

    本论文提出了一种将近端策略优化(PPO)方法与质量多样性(QD)相结合的新型QD-RL方法，用于在高吞吐量、大规模并行化机器人模拟器环境下训练能够在未知动态环境中表现出色的机器人学习智能体。

    

    培训通常能够在未知动态环境中表现良好的机器人学习智能体是一个长期目标。质量多样性强化学习(QD-RL)是一类新兴的强化学习算法，它将质量多样性(QD)和RL的见解相结合，产生一系列关于行为嵌入的高性能和行为多样性的策略集。然而，现有的QD-RL方法迄今为止利用了样本有效的离策略RL算法。然而，最近高吞吐量、大规模并行化的机器人模拟器的进步已经打开了能够利用这种并行性的算法的大门，而将现有的离策略QD-RL方法扩展到这些新的数据丰富的环境还不清楚。在这项工作中，我们首次采用了能够利用大规模并行性的近端策略优化(PPO)等策略方法与QD相结合，提出了一种新的QD-RL方法。

    Training generally capable agents that perform well in unseen dynamic environments is a long-term goal of robot learning. Quality Diversity Reinforcement Learning (QD-RL) is an emerging class of reinforcement learning (RL) algorithms that blend insights from Quality Diversity (QD) and RL to produce a collection of high performing and behaviorally diverse policies with respect to a behavioral embedding. Existing QD-RL approaches have thus far taken advantage of sample-efficient off-policy RL algorithms. However, recent advances in high-throughput, massively parallelized robotic simulators have opened the door for algorithms that can take advantage of such parallelism, and it is unclear how to scale existing off-policy QD-RL methods to these new data-rich regimes. In this work, we take the first steps to combine on-policy RL methods, specifically Proximal Policy Optimization (PPO), that can leverage massive parallelism, with QD, and propose a new QD-RL method with these high-throughput s
    
[^24]: 大型语言模型能像人类一样推理和产生分歧吗？

    Can Large Language Models Infer and Disagree Like Humans?. (arXiv:2305.13788v1 [cs.CL])

    [http://arxiv.org/abs/2305.13788](http://arxiv.org/abs/2305.13788)

    本文研究了大型语言模型在自然语言推断方面的性能和与人类分歧分布的对齐情况。结果表明LLM的推断能力有限，无法捕捉到人类分歧分布，引发了对其NLU和代表人类用户性质的担忧。

    

    大型语言模型在解决广泛任务方面已经表现出非常好的成绩。在生成文本时，从这些模型中采样标记是一种常见的策略。但是，LLM很难与人类的分歧分布高度对齐，特别是在自然语言推断方面。本文使用 Monte Carlo Reconstruction（MCR）和 Log Probability Reconstruction（LPR）两种不同的技术评估了LLM分布的性能和与人类的对齐情况。结果表明，LLM在解决NLI任务方面能力有限，同时无法捕捉到人类的分歧分布，这对其自然语言理解（NLU）能力和代表人类用户的特性提出了关注。

    Large Language Models (LLMs) have shown stellar achievements in solving a broad range of tasks. When generating text, it is common to sample tokens from these models: whether LLMs closely align with the human disagreement distribution has not been well-studied, especially within the scope of Natural Language Inference (NLI). In this paper, we evaluate the performance and alignment of LLM distribution with humans using two different techniques: Monte Carlo Reconstruction (MCR) and Log Probability Reconstruction (LPR). As a result, we show LLMs exhibit limited ability in solving NLI tasks and simultaneously fail to capture human disagreement distribution, raising concerns about their natural language understanding (NLU) ability and their representativeness of human users.
    
[^25]: 论文标题：《感知测试：多模态视频模型的诊断基准》

    Perception Test: A Diagnostic Benchmark for Multimodal Video Models. (arXiv:2305.13786v1 [cs.CV])

    [http://arxiv.org/abs/2305.13786](http://arxiv.org/abs/2305.13786)

    该论文提出了一个名为“感知测试”的多模态视频基准测试，可以评估预训练模型的感知和推理能力，测试涵盖了记忆、抽象、物理、语义等技能和描述性、解释性、预测性、反事实性等推理类型。

    

    我们提出了一种新颖的多模态视频基准——感知测试，用于评估预训练的多模态模型（例如 Flamingo、BEiT-3 或 GPT-4）的感知和推理技能。与现有的基准侧重于计算任务（例如分类、检测或跟踪）不同，感知测试侧重于视频、音频和文本模态跨越记忆、抽象、物理、语义等技能和推理类型（描述性、解释性、预测性、反事实性），以提供全面而高效的评估工具。该基准测试通过零样本/少样本或有限微调下挑选预训练模型的转移能力。为实现这些目的，感知测试介绍了11.6k种真实世界视频，平均长度为23秒，旨在展示感知上有趣的情境，由全球约100名参与者拍摄。这些视频密集地带有六种标签（多项选择和基于视频问题回答，对象a）

    We propose a novel multimodal video benchmark - the Perception Test - to evaluate the perception and reasoning skills of pre-trained multimodal models (e.g. Flamingo, BEiT-3, or GPT-4). Compared to existing benchmarks that focus on computational tasks (e.g. classification, detection or tracking), the Perception Test focuses on skills (Memory, Abstraction, Physics, Semantics) and types of reasoning (descriptive, explanatory, predictive, counterfactual) across video, audio, and text modalities, to provide a comprehensive and efficient evaluation tool. The benchmark probes pre-trained models for their transfer capabilities, in a zero-shot / few-shot or limited finetuning regime. For these purposes, the Perception Test introduces 11.6k real-world videos, 23s average length, designed to show perceptually interesting situations, filmed by around 100 participants worldwide. The videos are densely annotated with six types of labels (multiple-choice and grounded video question-answers, object a
    
[^26]: 基于深度强化学习的地面车辆在越野地形环境下的多目标路径规划

    Deep Reinforcement Learning-based Multi-objective Path Planning on the Off-road Terrain Environment for Ground Vehicles. (arXiv:2305.13783v1 [cs.RO])

    [http://arxiv.org/abs/2305.13783](http://arxiv.org/abs/2305.13783)

    本文提出了一种基于深度强化学习的2.5D多目标路径规划方法，可以高效地找到距离和能耗达到良好权衡的路径。

    

    由于上坡和下坡之间的能耗效率差异巨大，在复杂的越野地形环境（2.5D地图）上，最短路径不一定是能耗最少的路径。对于任何能源敏感的车辆来说，实现距离和能耗在2.5D路径规划上良好的权衡具有重要意义。本文提出了一种基于深度强化学习的2.5D多目标路径规划方法（DMOP）。DMOP可以通过三个步骤高效地找到所需路径：(1)将高分辨率的2.5D地图转换为小尺寸地图。(2)使用训练好的深度Q网络（DQN）在小尺寸地图上找到所需路径。(3)使用路径增强方法将计划路径构建到原始高分辨率地图上。此外，还应用了模仿学习方法和奖励塑造理论来训练DQN。奖励函数结合了地形、距离和边界的信息。

    Due to the energy-consumption efficiency between up-slope and down-slope is hugely different, a path with the shortest length on a complex off-road terrain environment (2.5D map) is not always the path with the least energy consumption. For any energy-sensitive vehicles, realizing a good trade-off between distance and energy consumption on 2.5D path planning is significantly meaningful. In this paper, a deep reinforcement learning-based 2.5D multi-objective path planning method (DMOP) is proposed. The DMOP can efficiently find the desired path with three steps: (1) Transform the high-resolution 2.5D map into a small-size map. (2) Use a trained deep Q network (DQN) to find the desired path on the small-size map. (3) Build the planned path to the original high-resolution map using a path enhanced method. In addition, the imitation learning method and reward shaping theory are applied to train the DQN. The reward function is constructed with the information of terrain, distance, border. S
    
[^27]: 持续融合意图分布学习的反话语生成方法

    Counterspeeches up my sleeve! Intent Distribution Learning and Persistent Fusion for Intent-Conditioned Counterspeech Generation. (arXiv:2305.13776v1 [cs.CL])

    [http://arxiv.org/abs/2305.13776](http://arxiv.org/abs/2305.13776)

    这篇论文提出了一个意图条件下的反话语生成方法QUARC，基于IntentCONAN数据集，利用向量量化表示和PerFuMe融合模块实现特定意图的反话语输出。

    

    反话语已被证明是对抗仇恨言论的一种有效方法。然而，对于每种场景，具有特定意图的反话语可能并不足够。本文探讨了意图条件下的反话语生成。首先，我们创建了IntentCONAN数据集，其中包含6831个反话语，分为五种意图：信息、谴责、问题、积极和幽默。随后，我们提出QUARC框架，该框架有两个阶段，用于意图条件下的反话语生成。QUARC利用学习每种意图类别的向量量化表示，以及PerFuMe，一种用于整合特定意图的信息的新型融合模块。

    Counterspeech has been demonstrated to be an efficacious approach for combating hate speech. While various conventional and controlled approaches have been studied in recent years to generate counterspeech, a counterspeech with a certain intent may not be sufficient in every scenario. Due to the complex and multifaceted nature of hate speech, utilizing multiple forms of counter-narratives with varying intents may be advantageous in different circumstances. In this paper, we explore intent-conditioned counterspeech generation. At first, we develop IntentCONAN, a diversified intent-specific counterspeech dataset with 6831 counterspeeches conditioned on five intents, i.e., informative, denouncing, question, positive, and humour. Subsequently, we propose QUARC, a two-stage framework for intent-conditioned counterspeech generation. QUARC leverages vector-quantized representations learned for each intent category along with PerFuMe, a novel fusion module to incorporate intent-specific inform
    
[^28]: 概念感知训练提高了语言模型在上下文学习中的能力

    Concept-aware Training Improves In-context Learning Ability of Language Models. (arXiv:2305.13775v1 [cs.CL])

    [http://arxiv.org/abs/2305.13775](http://arxiv.org/abs/2305.13775)

    本研究提出了一种概念感知训练的方法，用于训练能够更好利用上下文信息的语言模型。该方法能够显著提高模型的推理能力，在多个基准测试中表现出良好的效果。

    

    近期的多个Transformer系列语言模型展现了所谓的上下文学习能力(ICL)，表现为这些语言模型可以通过对自然语言输入任务进行调节来改变自身的功能。之前的一些研究认为，ICL的出现是由于过度参数化或多任务训练规模。然而，最近一些理论研究认为，ICL的出现是由具体的训练数据属性引起的，并在小规模的仿真环境中创建了功能性的上下文学习器。借鉴数据属性驱动ICL的最新发现，我们提出了一种方法来创建能够更好地利用上下文信息的语言模型。通过构建训练场景，使得模型捕捉到类比思维的概念，我们的概念感知训练 (CoAT) 方法可以显著提高模型的推理能力。结果，使用CoAT训练得到的具有上下文学习能力的语言模型在多个基准测试中得到了提升。

    Many recent language models (LMs) of Transformers family exhibit so-called in-context learning (ICL) ability, manifested in the LMs' ability to modulate their function by a task described in a natural language input. Previous work curating these models assumes that ICL emerges from vast over-parametrization or the scale of multi-task training. However, a complementary branch of recent theoretical work attributes ICL emergence to specific properties of training data and creates functional in-context learners in small-scale, synthetic settings.  Inspired by recent findings on data properties driving the emergence of ICL, we propose a method to create LMs able to better utilize the in-context information, by constructing training scenarios where it is beneficial for the LM to capture the analogical reasoning concepts. We measure that data sampling of Concept-aware Training (CoAT) consistently improves models' reasoning ability. As a result, the in-context learners trained with CoAT on onl
    
[^29]: 人体姿态估计用于步态辨识：数据集与模型综述

    Human Body Pose Estimation for Gait Identification: A Comprehensive Survey of Datasets and Models. (arXiv:2305.13765v1 [cs.CV])

    [http://arxiv.org/abs/2305.13765](http://arxiv.org/abs/2305.13765)

    本文对人体姿态估计和步态分析进行了综述，探讨了骨架为基础的步态辨识方法。详细介绍了相关数据集、工具、方法和评估指标，并提出了未来研究的建议。

    

    个人辨识是一个受到广泛关注的问题，尤其是在安全领域。步态识别是最方便的方法之一，可以在远距离识别个人而无需高质量的图像。虽然骨架为基础的人物识别正越来越受欢迎，而且能够克服传统方法所面临的挑战，但现有的综述研究缺乏对骨架为基础的步态辨识方法的综合评估。我们对人体姿态估计和步态分析进行了详细的综述，阐述了骨架为基础的步态辨识的方法。该研究涵盖相关数据集、工具、方法论和评估指标的各种类型，以及相关挑战、限制和应用领域。针对每个方面都进行了详细的比较，并提出了未来研究的建议。

    Person identification is a problem that has received substantial attention, particularly in security domains. Gait recognition is one of the most convenient approaches enabling person identification at a distance without the need of high-quality images. There are several review studies addressing person identification such as the utilization of facial images, silhouette images, and wearable sensor. Despite skeleton-based person identification gaining popularity while overcoming the challenges of traditional approaches, existing survey studies lack the comprehensive review of skeleton-based approaches to gait identification. We present a detailed review of the human pose estimation and gait analysis that make the skeleton-based approaches possible. The study covers various types of related datasets, tools, methodologies, and evaluation metrics with associated challenges, limitations, and application domains. Detailed comparisons are presented for each of these aspects with recommendatio
    
[^30]: 基于主题驱动的远程监督框架实现宏观层面的篇章分析

    Topic-driven Distant Supervision Framework for Macro-level Discourse Parsing. (arXiv:2305.13755v1 [cs.CL])

    [http://arxiv.org/abs/2305.13755](http://arxiv.org/abs/2305.13755)

    本研究提出了一种基于主题驱动的远程监督框架，通过远程监督方法利用领域内数据生成高质量的篇章训练数据，进一步提高篇章分析性能，在使用更少的训练数据的情况下实现最先进的结果。

    

    篇章分析是自然语言处理中一个具有挑战性的任务，其目的是分析文本的内部修辞结构。尽管神经模型存在近期的进展，但缺乏大规模、高质量的语料库用于训练仍然是一个重要的障碍。最近的研究尝试通过远程监督来克服此限制，该方法利用其他自然语言处理任务（例如情感极性、注意力矩阵和分割概率）的结果来解析篇章树。然而，这些方法没有考虑领域内外任务的差异，导致效果较差并且不能利用高质量的领域内数据进一步提高效果。为了解决这些问题，我们提出了一种远程监督框架，将主题结构和修辞结构之间的关系利用起来。具体来说，我们提出了两种基于远程监督的方法，基于转移学习和师生模型，用于重复生成高质量的领域内篇章训练数据。我们在基准数据集上的评估结果表明，我们的提议框架在要求更少的训练数据的同时实现了最先进的性能。

    Discourse parsing, the task of analyzing the internal rhetorical structure of texts, is a challenging problem in natural language processing. Despite the recent advances in neural models, the lack of large-scale, high-quality corpora for training remains a major obstacle. Recent studies have attempted to overcome this limitation by using distant supervision, which utilizes results from other NLP tasks (e.g., sentiment polarity, attention matrix, and segmentation probability) to parse discourse trees. However, these methods do not take into account the differences between in-domain and out-of-domain tasks, resulting in lower performance and inability to leverage the high-quality in-domain data for further improvement. To address these issues, we propose a distant supervision framework that leverages the relations between topic structure and rhetorical structure. Specifically, we propose two distantly supervised methods, based on transfer learning and the teacher-student model, that narr
    
[^31]: L-SA：多目标强化学习中的探索困难目标学习

    L-SA: Learning Under-Explored Targets in Multi-Target Reinforcement Learning. (arXiv:2305.13741v1 [cs.LG])

    [http://arxiv.org/abs/2305.13741](http://arxiv.org/abs/2305.13741)

    提出了一个用于解决多目标强化学习中探索困难目标学习问题的L-SA框架，其中包括自适应采样和主动查询。实验结果表明L-SA可以提高样本效率和成功率。

    

    与多个目标进行交互的任务被称为多目标任务。当应用通用的强化学习方法处理这样的任务时，某些难以访问或交互的目标可能会在训练过程中被忽视-这种困境称为探索困难目标问题（UTP）。为了解决这个问题，我们提出了一个包括自适应采样和主动查询的学习框架L-SA（通过自适应采样和主动查询进行学习）。在L-SA框架中，自适应采样动态地从最高成功率目标中采样，使得学习从容易到困难的目标，主动查询则促使代理与需要更多经验或探索的探索困难目标更频繁地交互。我们在视觉导航任务上的实验结果表明，L-SA框架提高了多个UTP多目标任务的样本效率和成功率。另外，预计该提出的L-SA框架能够应用到其他涉及多个存在UTP的目标的强化学习任务中。

    Tasks that involve interaction with various targets are called multi-target tasks. When applying general reinforcement learning approaches for such tasks, certain targets that are difficult to access or interact with may be neglected throughout the course of training - a predicament we call Under-explored Target Problem (UTP). To address this problem, we propose L-SA (Learning by adaptive Sampling and Active querying) framework that includes adaptive sampling and active querying. In the L-SA framework, adaptive sampling dynamically samples targets with the highest increase of success rates at a high proportion, resulting in curricular learning from easy to hard targets. Active querying prompts the agent to interact more frequently with under-explored targets that need more experience or exploration. Our experimental results on visual navigation tasks show that the L-SA framework improves sample efficiency as well as success rates on various multi-target tasks with UTP. Also, it is expe
    
[^32]: i-Code Studio：一种可配置和可组合的综合AI框架

    i-Code Studio: A Configurable and Composable Framework for Integrative AI. (arXiv:2305.13738v1 [cs.CL])

    [http://arxiv.org/abs/2305.13738](http://arxiv.org/abs/2305.13738)

    i-Code Studio提供了一个综合、灵活和可组合的设置，可以使开发人员快速轻松地组合最先进的服务和技术，以解决复杂的多模态任务，是实现人工通用智能（AGI）的一种重要方法。

    

    人工通用智能（AGI）需要全面的理解和生成能力，可以涵盖不同的模态和功能。综合AI是实现AGI的一种重要方法，通过组合多个模型来解决复杂的多模态任务。然而，缺乏一种灵活和可组合的平台来促进模型的高效和有效的组合和协调。本文提出了i-Code Studio，这是一个可配置和可组合的综合AI框架。 i-Code Studio以无fine-tuning方式协调多个预训练模型，以执行复杂的多模态任务。 i-Code Studio不仅提供简单的模型组合，还提供了一个综合、灵活和可组合的设置，使开发人员能够快速轻松地组合最先进的服务和技术，以满足他们的特定要求。i-Code Studio在多种零-shot多模态任务上取得了惊人的结果。

    Artificial General Intelligence (AGI) requires comprehensive understanding and generation capabilities for a variety of tasks spanning different modalities and functionalities. Integrative AI is one important direction to approach AGI, through combining multiple models to tackle complex multimodal tasks. However, there is a lack of a flexible and composable platform to facilitate efficient and effective model composition and coordination. In this paper, we propose the i-Code Studio, a configurable and composable framework for Integrative AI. The i-Code Studio orchestrates multiple pre-trained models in a finetuning-free fashion to conduct complex multimodal tasks. Instead of simple model composition, the i-Code Studio provides an integrative, flexible, and composable setting for developers to quickly and easily compose cutting-edge services and technologies tailored to their specific requirements. The i-Code Studio achieves impressive results on a variety of zero-shot multimodal tasks,
    
[^33]: 通过合成反馈对齐大型语言模型

    Aligning Large Language Models through Synthetic Feedback. (arXiv:2305.13735v1 [cs.CL])

    [http://arxiv.org/abs/2305.13735](http://arxiv.org/abs/2305.13735)

    该论文提出了一种使用合成反馈对齐大型语言模型的新框架，几乎不需要人力成本，也不依赖于预先对齐的LLMs。其中，通过对尺寸和提示等不同因素的普通 LLMS的响应进行奖励建模，来模拟高质量的示范来训练监督策略，并进一步使用强化学习优化模型。

    

    将大型语言模型(LLMs)与人类价值观对齐变得越来越重要，因为它能够提供复杂的LLMs控制，例如使它们按照特定的指令操作而不会产生有害反应。然而，这需要大量的人类示范和反馈。最近，开源模型试图通过提炼来自已对齐的LLMs（如InstructGPT或ChatGPT）的数据来复制对齐学习过程。虽然这个过程减少了人力成本，但是构建这些数据集对教师模型的依赖性很高。在这项工作中，我们提出了一个新的对齐学习框架，几乎不需要人类劳动，也不依赖于预先对齐的LLMs。首先，我们使用大小和提示等不同因素的普通LLMs的响应进行合成反馈的奖励建模(RM)。然后，我们使用RM模拟高质量的示范来训练监督策略，并进一步使用强化学习优化模型。

    Aligning large language models (LLMs) to human values has become increasingly important as it enables sophisticated steering of LLMs, e.g., making them follow given instructions while keeping them less toxic. However, it requires a significant amount of human demonstrations and feedback. Recently, open-sourced models have attempted to replicate the alignment learning process by distilling data from already aligned LLMs like InstructGPT or ChatGPT. While this process reduces human efforts, constructing these datasets has a heavy dependency on the teacher models. In this work, we propose a novel framework for alignment learning with almost no human labor and no dependency on pre-aligned LLMs. First, we perform reward modeling (RM) with synthetic feedback by contrasting responses from vanilla LLMs with various sizes and prompts. Then, we use the RM for simulating high-quality demonstrations to train a supervised policy and for further optimizing the model with reinforcement learning. Our 
    
[^34]: 基于约束生成的离散提示优化在零样本重排器中的应用

    Discrete Prompt Optimization via Constrained Generation for Zero-shot Re-ranker. (arXiv:2305.13729v1 [cs.IR])

    [http://arxiv.org/abs/2305.13729](http://arxiv.org/abs/2305.13729)

    本文提出了一种新的离散提示优化方法，称为受约束提示生成（Co-Prompt），通过估算最佳排序来引导 PLM 生成的文本朝向最优提示。实验结果表明，Co-Prompt 相对于基线方法表现出卓越的重排性能。

    

    重排器是在给定查询的相关性评分下对检索的文档进行排序的方法，在信息检索（IR）任务中得到了关注。与微调预训练语言模型（PLM）不同，利用大规模语言模型（LLM）作为具有优异结果的零样本重排器。虽然 LLM 在很大程度上依赖于提示语，但零样本重排器提示语的影响和优化尚未得到探究。除了强调优化对零样本重排器的影响外，我们还提出了一种新的离散提示优化方法，称为受约束提示生成（Co-Prompt），通过估算最佳排序来引导 PLM 生成的文本朝向最优提示。实验结果表明，Co-Prompt 相对于基线方法表现出卓越的重排性能。此外，Co-Prompt 生成的提示更易于人类理解。

    Re-rankers, which order retrieved documents with respect to the relevance score on the given query, have gained attention for the information retrieval (IR) task. Rather than fine-tuning the pre-trained language model (PLM), the large-scale language model (LLM) is utilized as a zero-shot re-ranker with excellent results. While LLM is highly dependent on the prompts, the impact and the optimization of the prompts for the zero-shot re-ranker are not explored yet. Along with highlighting the impact of optimization on the zero-shot re-ranker, we propose a novel discrete prompt optimization method, Constrained Prompt generation (Co-Prompt), with the metric estimating the optimum for re-ranking. Co-Prompt guides the generated texts from PLM toward optimal prompts based on the metric without parameter update. The experimental results demonstrate that Co-Prompt leads to outstanding re-ranking performance against the baselines. Also, Co-Prompt generates more interpretable prompts for humans aga
    
[^35]: 基于示例引导问答的持续对话状态跟踪

    Continual Dialogue State Tracking via Example-Guided Question Answering. (arXiv:2305.13721v1 [cs.CL])

    [http://arxiv.org/abs/2305.13721](http://arxiv.org/abs/2305.13721)

    本文建议将对话状态跟踪重构为由例子引导的粒度问题回答任务，以最小化服务之间的任务转移，获得持续的学习效益。通过结合简单的持续学习策略，可以在基准数据集上获得最先进的性能。

    

    对话系统需要不断更新以适应新服务，但是简单地使用新服务的数据进行训练会降低先前学习的服务的性能。本文发现，对话状态跟踪(DST)是一个简单的自然语言理解任务，我们建议将其重构为一组由例子引导的粒度问题回答任务，以最小化服务之间的任务转移，从而获得持续的学习效益。我们的方法可以减轻特定服务的记忆负担，并教会模型将所给问题和示例用于从对话中提取必要信息。我们发现，一个只有6000万个参数的模型可以通过学习从检索器获取的上下文示例获得巨大的提升。将我们的方法与简单的持续学习策略相结合，可以在基准数据集上获得最先进的性能，证明了我们方法的有效性。

    Dialogue systems are frequently updated to accommodate new services, but naively updating them by continually training with data for new services in diminishing performance on previously learnt services. Motivated by the insight that dialogue state tracking (DST), a crucial component of dialogue systems that estimates the user's goal as a conversation proceeds, is a simple natural language understanding task, we propose reformulating it as a bundle of granular example-guided question answering tasks to minimize the task shift between services and thus benefit continual learning. Our approach alleviates service-specific memorization and teaches a model to contextualize the given question and example to extract the necessary information from the conversation. We find that a model with just 60M parameters can achieve a significant boost by learning to learn from in-context examples retrieved by a retriever trained to identify turns with similar dialogue state changes. Combining our method
    
[^36]: 知识的知识：探索大型语言模型对未知-已知不确定性的理解

    Knowledge of Knowledge: Exploring Known-Unknowns Uncertainty with Large Language Models. (arXiv:2305.13712v1 [cs.CL])

    [http://arxiv.org/abs/2305.13712](http://arxiv.org/abs/2305.13712)

    本文探索了大型语言模型对其自身知识的理解和测量不确定性的能力。该研究聚焦于解决“已知-未知”问题，提出了新的分类方案，并使用语义评估方法量化了模型表达不确定性的准确性。

    

    本文研究了大型语言模型（LLM）在理解自身知识和测量不确定性方面的能力，以缓解虚构现象。我们专门关注解决“已知-未知”问题，这种问题由于缺乏确定的答案而具有高度不确定性。为了促进我们的研究，我们收集了一个新的已知-未知问题（KUQ）数据集，并提出了一个新的分类方案来阐明不确定性的来源。随后，我们评估LLM区分已知和未知问题以及相应分类的能力。此外，我们在开放式QA环境中评估LLM的答案质量。为了量化答案中表达的不确定性，我们创建了一种语义评估方法，用于测量模型在表达已知vs未知问题的不确定性方面的准确性。

    This paper investigates the capabilities of Large Language Models (LLMs) in the context of understanding their own knowledge and measuring their uncertainty. We argue this is an important feature for mitigating hallucinations. Specifically, we focus on addressing \textit{known-unknown} questions, characterized by high uncertainty due to the absence of definitive answers. To facilitate our study, we collect a dataset with new Known-Unknown Questions (KUQ) and propose a novel categorization scheme to elucidate the sources of uncertainty. Subsequently, we assess the LLMs' ability to differentiate between known and unknown questions and classify them accordingly. Moreover, we evaluate the quality of their answers in an Open-Ended QA setting. To quantify the uncertainty expressed in the answers, we create a semantic evaluation method that measures the model's accuracy in expressing uncertainty between known vs unknown questions.
    
[^37]: LLM-Eval：开放领域对话中基于大语言模型的统一多维自动评估方法

    LLM-Eval: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models. (arXiv:2305.13711v1 [cs.CL])

    [http://arxiv.org/abs/2305.13711](http://arxiv.org/abs/2305.13711)

    LLM-Eval是一种针对大型语言模型的开放领域对话的多维自动评估方法，其在一个模型调用中涵盖了多个对话质量维度，并提供了有效性、高效性和适应性，是评估开放领域对话系统的多功能强大解决方案。

    

    我们提出了LLM-Eval，一种针对基于大语言模型的开放领域对话的统一多维自动评估方法。现有的评估方法常常依赖于人工注释、基本事实回复或多个LLM提示，这些方法可能需要付出昂贵的代价并消耗大量时间。为了解决这些问题，我们设计了一个单提示评估方法，利用统一的评估模式，在单个模型调用中涵盖了对话质量的多个维度。我们在各种基准数据集上广泛评估了LLM-Eval的性能，并证明了它相对于最先进的评估方法而言具有的有效性、高效性和适应性。我们的分析还强调了为获得准确的评估结果，选择合适的LLM和解码策略的重要性。LLM-Eval提供了一种多功能且强大的解决方案，用于评估开放领域对话系统，简化了评估过程，并提供了在各种情景下的一致性表现。

    We propose LLM-Eval, a unified multi-dimensional automatic evaluation method for open-domain conversations with large language models (LLMs). Existing evaluation methods often rely on human annotations, ground-truth responses, or multiple LLM prompts, which can be expensive and time-consuming. To address these issues, we design a single prompt-based evaluation method that leverages a unified evaluation schema to cover multiple dimensions of conversation quality in a single model call. We extensively evaluate the performance of LLM-Eval on various benchmark datasets, demonstrating its effectiveness, efficiency, and adaptability compared to state-of-the-art evaluation methods. Our analysis also highlights the importance of choosing suitable LLMs and decoding strategies for accurate evaluation results. LLM-Eval offers a versatile and robust solution for evaluating open-domain conversation systems, streamlining the evaluation process and providing consistent performance across diverse scen
    
[^38]: 语义感知的传输调度：一种基于单调性驱动的深度强化学习方法

    Semantic-aware Transmission Scheduling: a Monotonicity-driven Deep Reinforcement Learning Approach. (arXiv:2305.13706v1 [cs.LG])

    [http://arxiv.org/abs/2305.13706](http://arxiv.org/abs/2305.13706)

    这篇论文提出了一种基于单调性驱动的深度强化学习算法，用于处理在6G时代物联网系统中的大规模语义感知传输调度问题。数值结果显示所提出的算法相比基准算法可以大大减少训练时间并提高训练性能。

    

    在6G时代的物联网系统中，需要语义传输来连接分布式设备，以保证应用层性能，不仅仅是集中于通信层性能。语义在这里是信息传输有用性的衡量。大规模系统的语义感知传输调度常常涉及庞大的决策空间，现有算法无法有效地获得最优策略。本文首先研究最优语义感知调度策略的基本属性，然后根据理论指导原则开发了先进的深度强化学习算法。我们的数值结果显示，相比基准算法，所提出的算法可以大大减少训练时间并提高训练性能。

    For cyber-physical systems in the 6G era, semantic communications connecting distributed devices for dynamic control and remote state estimation are required to guarantee application-level performance, not merely focus on communication-centric performance. Semantics here is a measure of the usefulness of information transmissions. Semantic-aware transmission scheduling of a large system often involves a large decision-making space, and the optimal policy cannot be obtained by existing algorithms effectively. In this paper, we first investigate the fundamental properties of the optimal semantic-aware scheduling policy and then develop advanced deep reinforcement learning (DRL) algorithms by leveraging the theoretical guidelines. Our numerical results show that the proposed algorithms can substantially reduce training time and enhance training performance compared to benchmark algorithms.
    
[^39]: 认识你的自监督学习：图像生成和判别式训练综述

    Know Your Self-supervised Learning: A Survey on Image-based Generative and Discriminative Training. (arXiv:2305.13689v1 [cs.CV])

    [http://arxiv.org/abs/2305.13689](http://arxiv.org/abs/2305.13689)

    自监督学习在图像计算机视觉领域中正在快速成为主要训练深度神经网络的方法。本文综述了文献中提出的用于图像生成和判别式训练的各种自监督学习方法。

    

    虽然在过去，监督式学习在图像计算机视觉领域中取得了很高的成功，但近年来，其改进的幅度已经显著减小，这表明一个瓶颈已经出现。与此同时，在自然语言处理（NLP）领域中使用自监督学习（SSL）取得了巨大的成功，这种新的学习范式产生了强大的语言模型。启发自NLP领域取得的优异结果，基于聚类、对比学习、蒸馏和信息最大化的分类式SSL等自监督方法迅速在计算机视觉领域得到了广泛应用。不久之后，基于遮蔽图像建模的生成式SSL框架在弥补和超越了判别式SSL所取得的结果。因此，自监督学习已经成为训练图像计算机视觉深度神经网络的主流方法。本文全面综述了文献中提出的用于图像生成和判别式训练的各种自监督学习方法。

    Although supervised learning has been highly successful in improving the state-of-the-art in the domain of image-based computer vision in the past, the margin of improvement has diminished significantly in recent years, indicating that a plateau is in sight. Meanwhile, the use of self-supervised learning (SSL) for the purpose of natural language processing (NLP) has seen tremendous successes during the past couple of years, with this new learning paradigm yielding powerful language models. Inspired by the excellent results obtained in the field of NLP, self-supervised methods that rely on clustering, contrastive learning, distillation, and information-maximization, which all fall under the banner of discriminative SSL, have experienced a swift uptake in the area of computer vision. Shortly afterwards, generative SSL frameworks that are mostly based on masked image modeling, complemented and surpassed the results obtained with discriminative SSL. Consequently, within a span of three yea
    
[^40]: GUARD: 一个安全强化学习基准测试平台

    GUARD: A Safe Reinforcement Learning Benchmark. (arXiv:2305.13681v1 [cs.LG])

    [http://arxiv.org/abs/2305.13681](http://arxiv.org/abs/2305.13681)

    GUARD是一个广义统一安全强化学习开发基准测试平台，是目前广泛遍布且包含各种RL代理、任务和安全约束规范的一站式基准测试，能够全面涵盖最先进的安全RL算法，并具有高度的可自定义性。

    

    由于试错的性质，将RL算法应用于安全关键的现实应用（例如自动驾驶、人机交互、机器人操作等）通常是具有挑战性的，因为这些错误是不可容忍的。最近，安全RL（即约束RL）已经在文献中迅速出现，其中代理在满足约束条件的同时，探索环境。由于算法和任务的多样性，比较现有的安全RL算法仍然很困难。为了填补这一空白，我们介绍了GUARD，一个广义统一安全强化学习开发基准测试平台。与现有基准相比，GUARD具有几个优点。首先，GUARD是一个广义基准测试平台，具有各种RL代理、任务和安全约束规范。其次，GUARD全面涵盖了最先进的安全RL算法，并具有自包含的实现。第三，GUARD在任务和算法方面具有高度的可自定义性。我们提供了状态下现有方法在GUARD上的基准测试结果。

    Due to the trial-and-error nature, it is typically challenging to apply RL algorithms to safety-critical real-world applications, such as autonomous driving, human-robot interaction, robot manipulation, etc, where such errors are not tolerable. Recently, safe RL (i.e. constrained RL) has emerged rapidly in the literature, in which the agents explore the environment while satisfying constraints. Due to the diversity of algorithms and tasks, it remains difficult to compare existing safe RL algorithms. To fill that gap, we introduce GUARD, a Generalized Unified SAfe Reinforcement Learning Development Benchmark. GUARD has several advantages compared to existing benchmarks. First, GUARD is a generalized benchmark with a wide variety of RL agents, tasks, and safety constraint specifications. Second, GUARD comprehensively covers state-of-the-art safe RL algorithms with self-contained implementations. Third, GUARD is highly customizable in tasks and algorithms. We present a comparison of state
    
[^41]: 语言模型的物理学：第一部分，上下文无关文法。

    Physics of Language Models: Part 1, Context-Free Grammar. (arXiv:2305.13673v1 [cs.CL])

    [http://arxiv.org/abs/2305.13673](http://arxiv.org/abs/2305.13673)

    本研究探究了生成式语言模型如何学习上下文无关文法（CFG），并通过构造人造数据证明了预训练transformers可以学会生成具有接近完美准确度和显着多样性的句子。研究发现transformer内部的隐藏状态隐含而精确地编码了CFG结构，学会形成类似动态规划的“边界到边界”的注意力。此外，还研究了标准CFG的扩展，例如概率CFG和线性CFG，并证明transformers也可以学会这些扩展语法结构。

    

    我们设计了实验来研究生成式语言模型（例如GPT）如何学习上下文无关文法（CFG）-具有树状结构的多样化语言系统，可捕捉许多自然语言，程序和人类逻辑的方面。CFG与下推自动机一样困难，可能是模棱两可的，因此验证字符串是否满足规则需要动态规划。我们构造了人造数据，并证明即使对于非常具有挑战性的CFG，预训练transformers也可以学会生成具有接近完美准确度和显着多样性的句子。更重要的是，我们深入探讨了transformers学习CFG背后的物理原理。我们发现transformer内部的隐藏状态隐含而精确地编码了CFG结构（如在子树边界上精确定位树节点信息），并学会形成类似动态规划的“边界到边界”的注意力。我们还涵盖了一些标准CFG的扩展，例如概率CFG和线性CFG，并展示transformers也可以学会这些扩展语法结构。我们的工作揭示了语言模型的内部工作原理，并为未来的模型设计和分析提供了启示。

    We design experiments to study $\textit{how}$ generative language models, like GPT, learn context-free grammars (CFGs) -- diverse language systems with a tree-like structure capturing many aspects of natural languages, programs, and human logics. CFGs are as hard as pushdown automata, and can be ambiguous so that verifying if a string satisfies the rules requires dynamic programming. We construct synthetic data and demonstrate that even for very challenging CFGs, pre-trained transformers can learn to generate sentences with near-perfect accuracy and remarkable $\textit{diversity}$.  More importantly, we delve into the $\textit{physical principles}$ behind how transformers learns CFGs. We discover that the hidden states within the transformer implicitly and $\textit{precisely}$ encode the CFG structure (such as putting tree node information exactly on the subtree boundary), and learn to form "boundary to boundary" attentions that resemble dynamic programming. We also cover some extensio
    
[^42]: 通过交互式问题-知识对齐解决语言模型幻觉问题

    Mitigating Language Model Hallucination with Interactive Question-Knowledge Alignment. (arXiv:2305.13669v1 [cs.CL])

    [http://arxiv.org/abs/2305.13669](http://arxiv.org/abs/2305.13669)

    本文提出了MixAlign框架，通过与用户和知识库交互，实现自动的问题-知识对齐，从而解决了语言模型因无法正确理解问题和知识而导致的幻觉问题。

    

    尽管语言模型近期进展显著，但仍面临幻觉问题，可能会生成误导性和不支持的回答。一种缓解幻觉问题的常见方法是从知识库中检索和整合支持证据。然而，用户的问题通常与存储的知识不太对齐，因为他们在提问前不知道可用的信息。这种不对齐可能限制语言模型定位和利用知识的能力，可能迫使其通过忽略或覆盖检索到的证据而产生幻觉。为了解决这个问题，我们介绍了 MixAlign，一个框架，它与用户和知识库交互以获得并整合关于用户问题与存储信息相关性的澄清信息。 MixAlign 采用语言模型实现自动问题-知识对齐，并在需要时通过人工用户澄清进一步增强这种对齐。

    Despite the remarkable recent advances in language models, they still struggle with the hallucination problem and can generate misleading and unsupported responses. A common approach to mitigate the hallucination issue is retrieving and incorporating supporting evidence from a knowledge base. However, user questions usually do not align well with the stored knowledge, as they are unaware of the information available before asking questions. This misalignment can limit the language model's ability to locate and utilize the knowledge, potentially forcing it to hallucinate by ignoring or overriding the retrieved evidence. To address this issue, we introduce MixAlign, a framework that interacts with both the user and the knowledge base to obtain and integrate clarifications on how the user question relates to the stored information. MixAlign employs a language model to achieve automatic question-knowledge alignment and, if necessary, further enhances this alignment through human user clari
    
[^43]: 双聚焦损失用于置信度校准

    Dual Focal Loss for Calibration. (arXiv:2305.13665v1 [cs.CV])

    [http://arxiv.org/abs/2305.13665](http://arxiv.org/abs/2305.13665)

    本文提出了一种新的损失函数——双聚焦损失，可以在过度自信和低自信之间达到更好的平衡，实现了最先进的校准性能。

    

    在现实世界的深度神经网络应用中，需要具有良好校准的网络，其置信度分数能够准确反映实际概率。然而，这些网络通常提供过度自信的预测，从而导致校准不佳。最近的研究努力解决这个问题通过焦点损失来降低过度自信，但这种方法也可能导致低自信的预测。虽然已经探索了焦点损失的不同变体，但很难找到过度自信和低自信之间的平衡点。在我们的工作中，我们提出了一种新的损失函数，专注于双重逻辑。我们的方法不仅考虑基于实际情况的logit，而且还考虑在基于实际情况之后评级最高的logit。通过最大化这两个logit之间的差距，我们提出的双聚焦损失可以在过度自信和低自信之间达到更好的平衡。我们提供理论证据来支持我们的方法，并描述在图像分类和语义分割任务上的实验结果，这表明我们的方法实现了最先进的校准性能。

    The use of deep neural networks in real-world applications require well-calibrated networks with confidence scores that accurately reflect the actual probability. However, it has been found that these networks often provide over-confident predictions, which leads to poor calibration. Recent efforts have sought to address this issue by focal loss to reduce over-confidence, but this approach can also lead to under-confident predictions. While different variants of focal loss have been explored, it is difficult to find a balance between over-confidence and under-confidence. In our work, we propose a new loss function by focusing on dual logits. Our method not only considers the ground truth logit, but also take into account the highest logit ranked after the ground truth logit. By maximizing the gap between these two logits, our proposed dual focal loss can achieve a better balance between over-confidence and under-confidence. We provide theoretical evidence to support our approach and de
    
[^44]: 论大型语言模型的错误信息污染风险

    On the Risk of Misinformation Pollution with Large Language Models. (arXiv:2305.13661v1 [cs.CL])

    [http://arxiv.org/abs/2305.13661](http://arxiv.org/abs/2305.13661)

    本文探讨了大型语言模型（LLM）可能误用的潜在风险，指出LLM可以作为有效的误导性信息生成器，导致开放域问答（ODQA）系统性能显著降低，并尝试提出三种防御策略：提示，误报检测和大多数投票。

    

    本文全面调查了现代大型语言模型（LLM）的潜在误用，探讨了其生成可信并具有误导性的信息并对信息密集型应用程序，尤其是开放域问答（ODQA）系统的影响。我们建立了一个威胁模型，并对无意和故意的潜在误用场景进行模拟，以评估LLM可以用于生成信息不实的程度。研究发现，LLM可以作为有效的误导性信息生成器，导致ODQA系统性能显著降低。为了减轻由LLM生成的错误信息带来的危害，我们探讨了三种防御策略：提示，误报检测和大多数投票。虽然初步结果显示这些防御性策略有希望产生明显效果，但还需要做大量工作来应对错误信息污染的挑战。本研究强调了需要进一步进行跨学科研究。

    In this paper, we comprehensively investigate the potential misuse of modern Large Language Models (LLMs) for generating credible-sounding misinformation and its subsequent impact on information-intensive applications, particularly Open-Domain Question Answering (ODQA) systems. We establish a threat model and simulate potential misuse scenarios, both unintentional and intentional, to assess the extent to which LLMs can be utilized to produce misinformation. Our study reveals that LLMs can act as effective misinformation generators, leading to a significant degradation in the performance of ODQA systems. To mitigate the harm caused by LLM-generated misinformation, we explore three defense strategies: prompting, misinformation detection, and majority voting. While initial results show promising trends for these defensive strategies, much more work needs to be done to address the challenge of misinformation pollution. Our work highlights the need for further research and interdisciplinary
    
[^45]: 无参数，最近邻辅助微调神经机器翻译

    Non-parametric, Nearest-neighbor-assisted Fine-tuning for Neural Machine Translation. (arXiv:2305.13648v1 [cs.CL])

    [http://arxiv.org/abs/2305.13648](http://arxiv.org/abs/2305.13648)

    本文探究了如何利用kNN预测的统计信息来改善fine-tuning阶段的机器翻译模型表现，通过不同的方法整合kNN统计信息，成功地提高了BLEU分数。

    

    最近邻算法已经被用于辅助语言模型和机器翻译解码器等生成模型。本文研究了这种非参数模型如何通过kNN预测的统计信息来改进机器翻译模型在fine-tuning阶段的表现。我们探究了不同的方法，如通过门控机制进行渐变缩放、使用kNN的真实概率以及强化学习等方法来整合kNN统计信息。对于四个标准领域的机器翻译数据集，与经典的微调方法相比，我们报道了三种方法的一致改进，对于德英和英德翻译，BLEU分别提高了1.45和1.28分。通过定性分析，我们发现在翻译语法关系或函数词时，有着特别的改进。

    Non-parametric, k-nearest-neighbor algorithms have recently made inroads to assist generative models such as language models and machine translation decoders. We explore whether such non-parametric models can improve machine translation models at the fine-tuning stage by incorporating statistics from the kNN predictions to inform the gradient updates for a baseline translation model. There are multiple methods which could be used to incorporate kNN statistics and we investigate gradient scaling by a gating mechanism, the kNN's ground truth probability, and reinforcement learning. For four standard in-domain machine translation datasets, compared with classic fine-tuning, we report consistent improvements of all of the three methods by as much as 1.45 BLEU and 1.28 BLEU for German-English and English-German translations respectively. Through qualitative analysis, we found particular improvements when it comes to translating grammatical relations or function words, which results in incre
    
[^46]: 多语言摘要中的幻觉检测和缓解

    Detecting and Mitigating Hallucinations in Multilingual Summarisation. (arXiv:2305.13632v1 [cs.CL])

    [http://arxiv.org/abs/2305.13632](http://arxiv.org/abs/2305.13632)

    本文提出一种新的度量方法mFACT，可以在非英语摘要中评估其忠实性。本文还提出了一种简单有效的加权方法，可以通过跨语言转移减少摘要的幻觉问题。

    

    幻觉对于抽象摘要的神经模型的可靠性构成了重大挑战。虽然自动产生的摘要可能流畅，但通常缺乏对原始文档的忠实性。在低资源环境下，如跨语言转移，这个问题变得更加突出。由于现有的忠实性测量方法主要集中于英语，因此在跨语言环境中甚至衡量这种现象的程度也很困难。为了解决这个问题，作者首先提出了一种新的度量方法mFACT，通过从多个英语的忠实性测量结果中借鉴翻译基础知识为非英语摘要评估其忠实性。然后，他们提出了一种简单而有效的方法来通过跨语言转移减少幻觉，该方法将每个训练样本的损失乘以其忠实性得分。通过多种语言的广泛实验，作者证明了mFACT是最适合检测幻觉的度量方法。此外，他们发现他们的提出的加权方法可以缓解幻觉问题。

    Hallucinations pose a significant challenge to the reliability of neural models for abstractive summarisation. While automatically generated summaries may be fluent, they often lack faithfulness to the original document. This issue becomes even more pronounced in low-resource settings, such as cross-lingual transfer. With the existing faithful metrics focusing on English, even measuring the extent of this phenomenon in cross-lingual settings is hard. To address this, we first develop a novel metric, mFACT, evaluating the faithfulness of non-English summaries, leveraging translation-based transfer from multiple English faithfulness metrics. We then propose a simple but effective method to reduce hallucinations with a cross-lingual transfer, which weighs the loss of each training example by its faithfulness score. Through extensive experiments in multiple languages, we demonstrate that mFACT is the metric that is most suited to detect hallucinations. Moreover, we find that our proposed l
    
[^47]: Instruct-Align：通过基于对齐的跨语言教学将新语言教给LLM

    Instruct-Align: Teaching Novel Languages with to LLMs through Alignment-based Cross-Lingual Instruction. (arXiv:2305.13627v1 [cs.CL])

    [http://arxiv.org/abs/2305.13627](http://arxiv.org/abs/2305.13627)

    Instruct-Align提出了基于对齐的跨语言教学调整框架，使得教学调整的LLMs能够学习新语言，且不会发生灾难性遗忘。

    

    教学调整的大型语言模型（LLM）已经展示了在多种语言和多种任务上的卓越泛化能力。然而，它们对不同语言的泛化能力会有所不同，尤其是对于少数语言或者是未知语言。先前的工作发现，简单地将新语言适应到经过教学调整的LLM中会导致灾难性遗忘，从而导致这些LLM失去多任务能力。为了解决这个问题，我们提出了称为Instruct-Align的框架，通过基于对齐的跨语言教学调整，使得经过教学调整的LLM能够学习到看不见的和之前学习的语言之间的跨语言对齐。我们在BLOOMZ-560M数据集上的初步结果显示，Instruct-Align能够在仅使用有限量的平行语料的情况下有效地学习新语言，并且通过持续的教学调整，防止了灾难性遗忘。

    Instruction-tuned large language models (LLMs) have shown remarkable generalization capability over multiple tasks in multiple languages. Nevertheless, their generalization towards different languages varies especially to underrepresented languages or even to unseen languages. Prior works on adapting new languages to LLMs find that naively adapting new languages to instruction-tuned LLMs will result in catastrophic forgetting, which in turn causes the loss of multitasking ability in these LLMs. To tackle this, we propose the Instruct-Align a.k.a (IA)$^1$ framework, which enables instruction-tuned LLMs to learn cross-lingual alignment between unseen and previously learned languages via alignment-based cross-lingual instruction-tuning. Our preliminary result on BLOOMZ-560M shows that (IA)$^1$ is able to learn a new language effectively with only a limited amount of parallel data and at the same time prevent catastrophic forgetting by applying continual instruction-tuning through experien
    
[^48]: 通过语义融合验证多媒体内容审核软件

    Validating Multimedia Content Moderation Software via Semantic Fusion. (arXiv:2305.13623v1 [cs.SE])

    [http://arxiv.org/abs/2305.13623](http://arxiv.org/abs/2305.13623)

    该论文提出了一种名为“Semantic Fusion”的通用有效方法，通过融合两个或多个不同模态的内容审核模型来提高多媒体内容审核软件的验证效果。该方法经过大规模多媒体内容审核数据集的评估，相比现有方法显著提高了验证结果。

    

    社交媒体平台，如Facebook和TikTok的指数级增长，已经改变了人类社会的交流和内容发布方式。在这些平台上，用户可以发布结合文本，音频，图像和视频传递信息的多媒体内容。与此同时，多媒体内容发布设施日益被利用来传播有害内容，如仇恨言论，恶意广告和色情内容。为此，内容审核软件已经广泛部署在这些平台上，以检测和屏蔽有害内容。然而，由于内容审核模型的复杂性以及跨多种模式理解信息的困难，现有的内容审核软件可能会失败，导致极为负面的影响。我们引入Semantic Fusion，这是一种通用而有效的验证多媒体内容审核软件的方法。我们的关键思想是融合两个或更多基于不同模态（如文本，音频，图像和视频）的现有内容审核模型，并利用多模态的互补性和一致性来提高内容审核软件的验证性能。我们在一个大规模的多媒体内容审核数据集上评估了Semantic Fusion，并显示它相比现有方法显著提高了验证结果。

    The exponential growth of social media platforms, such as Facebook and TikTok, has revolutionized communication and content publication in human society. Users on these platforms can publish multimedia content that delivers information via the combination of text, audio, images, and video. Meanwhile, the multimedia content release facility has been increasingly exploited to propagate toxic content, such as hate speech, malicious advertisements, and pornography. To this end, content moderation software has been widely deployed on these platforms to detect and blocks toxic content. However, due to the complexity of content moderation models and the difficulty of understanding information across multiple modalities, existing content moderation software can fail to detect toxic content, which often leads to extremely negative impacts.  We introduce Semantic Fusion, a general, effective methodology for validating multimedia content moderation software. Our key idea is to fuse two or more ex
    
[^49]: SPEECH: 基于能量的事件中心超球的结构化预测

    SPEECH: Structured Prediction with Energy-Based Event-Centric Hyperspheres. (arXiv:2305.13617v1 [cs.CL])

    [http://arxiv.org/abs/2305.13617](http://arxiv.org/abs/2305.13617)

    这篇论文提出了一种称为SPEECH的模型，它使用能量建模来表示复杂的事件结构，并使用超球来表示事件类别。实验结果表明，SPEECH在事件检测和事件关系抽取任务中表现出卓越的性能。

    

    事件中心的结构化预测涉及预测事件的结构化输出。在大多数自然语言处理情况下，事件结构都具有复杂的依赖关系，因此有效地表示这些复杂的事件结构是具有挑战性的。为了解决这些问题，我们提出了基于能量的事件中心超球的结构化预测 (SPEECH)。 SPEECH 使用基于能量的建模来模拟事件结构组件之间的复杂依赖关系，并使用简单但有效的超球来表示事件类别。在两个统一标注的事件数据集的实验中，结果表明SPEECH在事件检测和事件关系抽取任务中占优势。

    Event-centric structured prediction involves predicting structured outputs of events. In most NLP cases, event structures are complex with manifold dependency, and it is challenging to effectively represent these complicated structured events. To address these issues, we propose Structured Prediction with Energy-based Event-Centric Hyperspheres (SPEECH). SPEECH models complex dependency among event structured components with energy-based modeling, and represents event classes with simple but effective hyperspheres. Experiments on two unified-annotated event datasets indicate that SPEECH is predominant in event detection and event-relation extraction tasks.
    
[^50]: 利用（模糊测试）测试用例来理解程序

    Understanding Programs by Exploiting (Fuzzing) Test Cases. (arXiv:2305.13592v1 [cs.LG])

    [http://arxiv.org/abs/2305.13592](http://arxiv.org/abs/2305.13592)

    本文提出了通过模糊测试获取代表性输入来帮助语义理解程序的方法。

    

    程序的语义理解引起了社区的极大关注。受到自然语言理解中大型语言模型（LLM）的最近成功启发，通过将编程语言视为另一种自然语言，并在程序代码语料库上训练LLM，取得了巨大进展。然而，程序毕竟与文本有本质的区别，因为它们通常具有严格的结构和语法。特别是，程序及其基本单元（即函数和子程序）旨在展示各种行为和/或提供可能的输出，给定不同的输入。输入和可能的输出/行为之间的关系表示函数/子程序，并概述了整个程序。因此，我们提出将这种关系纳入学习中，以实现对程序的更深入语义理解。为了获得足够代表性的输入以触发大量执行，可以使用模糊测试。

    Semantic understanding of programs has attracted great attention in the community. Inspired by recent successes of large language models (LLMs) in natural language understanding, tremendous progress has been made by treating programming language as another sort of natural language and training LLMs on corpora of program code. However, programs are essentially different from texts after all, in a sense that they are normally heavily structured and syntax-strict. In particular, programs and their basic units (i.e., functions and subroutines) are designed to demonstrate a variety of behaviors and/or provide possible outputs, given different inputs. The relationship between inputs and possible outputs/behaviors represents the functions/subroutines and profiles the program as a whole. Therefore, we propose to incorporate such a relationship into learning, for achieving a deeper semantic understanding of programs. To obtain inputs that are representative enough to trigger the execution of mo
    
[^51]: 针对多出口网络的模型窃取攻击

    Model Stealing Attack against Multi-Exit Networks. (arXiv:2305.13584v1 [cs.CR])

    [http://arxiv.org/abs/2305.13584](http://arxiv.org/abs/2305.13584)

    该论文介绍了第一个能同时窃取多出口网络模型函数和输出策略的攻击方法，并使用贝叶斯变点检测和性能损失、策略损失指导替代模型的训练。开发了一种新的输出策略搜索方法。

    

    与具有单个出口的传统神经网络相比，多出口网络具有多个出口，这些出口允许从模型的中间层早期输出，从而在保持类似识别精度的情况下提高计算效率。当使用传统的模型窃取攻击方法尝试窃取这些有价值的模型时，我们发现传统方法只能窃取模型的分类函数，而不能捕捉其输出策略。这导致窃取的替代模型的计算效率显著降低，失去多出口网络的优点。在本文中，我们提出了第一个窃取模型攻击，可以提取模型函数和输出策略。我们采用贝叶斯变点检测来分析目标模型的输出策略，并使用性能损失和策略损失来指导替代模型的训练。此外，我们设计了一种新颖的输出策略搜索方法，以使替代模型还原窃取目标模型的输出策略。

    Compared to traditional neural networks with a single exit, a multi-exit network has multiple exits that allow for early output from intermediate layers of the model, thus bringing significant improvement in computational efficiency while maintaining similar recognition accuracy. When attempting to steal such valuable models using traditional model stealing attacks, we found that conventional methods can only steal the model's classification function while failing to capture its output strategy. This results in a significant decrease in computational efficiency for the stolen substitute model, thereby losing the advantages of multi-exit networks.In this paper, we propose the first model stealing attack to extract both the model function and output strategy. We employ bayesian changepoint detection to analyze the target model's output strategy and use performance loss and strategy loss to guide the training of the substitute model. Furthermore, we designed a novel output strategy search
    
[^52]: 多尺度高效交叉空间学习的注意力模块

    Efficient Multi-Scale Attention Module with Cross-Spatial Learning. (arXiv:2305.13563v1 [cs.CV])

    [http://arxiv.org/abs/2305.13563](http://arxiv.org/abs/2305.13563)

    本文提出了一种高效的多尺度注意力模块，重塑部分通道为批处理维度并将通道分组，以增加空间语义分布性，同时通过交叉维度交互聚合两个并行分支的输出特征。实验表明EMA可以高效地优化性能，比之前的最新方法更好。

    

    本文提出了一种新颖的高效多尺度注意力（EMA）模块，旨在保留每个通道的信息和减少计算开销。该模块将部分通道重塑为批处理维度，并将通道分组成多个子特征，从而使空间语义特征在每个特征组中分布良好。此外，该模块通过交叉维度交互进一步聚合了两个并行分支的输出特征，以捕捉像素级别的成对关系。实验表明，EMA可以在多个计算机视觉任务中比之前的最新方法更高效地优化性能。

    Remarkable effectiveness of the channel or spatial attention mechanisms for producing more discernible feature representation are illustrated in various computer vision tasks. However, modeling the cross-channel relationships with channel dimensionality reduction may bring side effect in extracting deep visual representations. In this paper, a novel efficient multi-scale attention (EMA) module is proposed. Focusing on retaining the information on per channel and decreasing the computational overhead, we reshape the partly channels into the batch dimensions and group the channel dimensions into multiple sub-features which make the spatial semantic features well-distributed inside each feature group. Specifically, apart from encoding the global information to re-calibrate the channel-wise weight in each parallel branch, the output features of the two parallel branches are further aggregated by a cross-dimension interaction for capturing pixel-level pairwise relationship. We conduct exten
    
[^53]: EntRED: 用更少的捷径进行关系抽取基准测试

    EntRED: Benchmarking Relation Extraction with Fewer Shortcuts. (arXiv:2305.13551v1 [cs.CL])

    [http://arxiv.org/abs/2305.13551](http://arxiv.org/abs/2305.13551)

    本研究提出了一个名称更为多样、没有捷径、具有挑战性的关系提取基准测试EntRed，并解决了标准基准测试数据集存在的实体注释错误、实体名称多样性较低、从实体名称到基本事实关系的捷径等问题。

    

    实体名称在关系抽取中起着有效的作用，并常常影响模型性能。因此，基准测试中测试集中的实体名称显著影响了关系提取模型的评估。本研究发现，标准的关系抽取基准测试数据集存在大量错误的实体注释，实体名称多样性较低，并且容易出现从实体名称到基本事实关系的捷径。这些问题使得标准基准测试与现实世界场景相距甚远。因此，在本研究中，我们提出了EntRED，这是一个具有较少捷径和更高实体多样性的具有挑战性的关系提取基准测试。为构建EntRED，我们提出了一种基于因果推理（CI）的端到端实体替换管道：ERIC。ERIC对实体进行类型约束替换，以减少从实体偏差到基本事实关系的捷径。ERIC在两个方面应用CI：1）针对需要实体替换的实例，2）确定候选实体。

    Entity names play an effective role in relation extraction (RE) and often influence model performance. As a result, the entity names in the benchmarks' test sets significantly influence the evaluation of RE models. In this work, we find that the standard RE benchmarks' datasets have a large portion of incorrect entity annotations, low entity name diversity, and are prone to have shortcuts from entity names to ground-truth relations. These issues make the standard benchmarks far from reflecting the real-world scenarios. Hence, in this work, we present EntRED, a challenging RE benchmark with reduced shortcuts and higher diversity of entities. To build EntRED, we propose an end-to-end entity replacement pipeline based on causal inference (CI): ERIC. ERIC performs type-constrained replacements on entities to reduce the shortcuts from entity bias to ground-truth relations. ERIC applies CI in two aspects: 1) targeting the instances that need entity replacements, and 2) determining the candid
    
[^54]: 神经功能转换器

    Neural Functional Transformers. (arXiv:2305.13546v1 [cs.LG])

    [http://arxiv.org/abs/2305.13546](http://arxiv.org/abs/2305.13546)

    本文提出了一种称为神经功能转换器的模型，它可以通过直接操作其权重空间处理其他神经网络作为输入，使用注意力机制来定义置换等变的权重空间层。在处理前馈MLPs和CNNs的权重的实验中，NFTs的性能与或优于先前的权重空间方法，并且开发了一种计算置换不变潜变量的新方法。

    

    神经网络作为数据的隐式表示方式的成功，推动了对神经功能的增长兴趣：一种可以通过直接操作其权重空间处理其他神经网络作为输入的模型。然而，构建能够处理高维权重空间对象的具有表现力和高效性的神经功能体系结构仍然具有挑战性。本文使用注意力机制来定义一种新的置换等变的权重空间层，并将它们组合成深度等变模型，称为神经功能转换器(NFTs)。NFTs尊重权重空间置换对称性，同时结合注意力的优势，这一方法在多个领域中表现出了显著的成功。在处理前馈MLPs和CNNs的权重的实验中，我们发现NFTs的性能与或优于先前的权重空间方法。我们还利用NFTs开发了Inr2Array，一种计算置换不变潜变量的新方法。

    The recent success of neural networks as implicit representation of data has driven growing interest in neural functionals: models that can process other neural networks as input by operating directly over their weight spaces. Nevertheless, constructing expressive and efficient neural functional architectures that can handle high-dimensional weight-space objects remains challenging. This paper uses the attention mechanism to define a novel set of permutation equivariant weight-space layers and composes them into deep equivariant models called neural functional Transformers (NFTs). NFTs respect weight-space permutation symmetries while incorporating the advantages of attention, which have exhibited remarkable success across multiple domains. In experiments processing the weights of feedforward MLPs and CNNs, we find that NFTs match or exceed the performance of prior weight-space methods. We also leverage NFTs to develop Inr2Array, a novel method for computing permutation invariant laten
    
[^55]: 基于卷积神经网络的传感器活动识别中的ConvBoost增强技术

    ConvBoost: Boosting ConvNets for Sensor-based Activity Recognition. (arXiv:2305.13541v1 [cs.LG])

    [http://arxiv.org/abs/2305.13541](http://arxiv.org/abs/2305.13541)

    本论文提出了ConvBoost，一种基于卷积神经网络的三层结构模型和增强框架，旨在改善传感器活动识别的效果，缓解标记训练数据不足的问题。

    

    人类活动识别（HAR）是普及和可穿戴计算的核心研究主题之一。随着深度学习（DL）分析方法的流行，可以以端到端的方式提取高级特征和进行分类。但由于典型HAR应用程序中可用的标记样本数据数量往往非常少，从而导致过拟合，这使得DL-Based HAR可能会受到影响。为应对这些挑战，我们提出了ConvBoost-一种基于卷积网络的HAR的新型、三层、结构化的模型架构和增强框架。我们的框架从三个不同的角度生成额外的训练数据，从而改善HAR，旨在缓解领域内标记训练数据的数量不足的问题。

    Human activity recognition (HAR) is one of the core research themes in ubiquitous and wearable computing. With the shift to deep learning (DL) based analysis approaches, it has become possible to extract high-level features and perform classification in an end-to-end manner. Despite their promising overall capabilities, DL-based HAR may suffer from overfitting due to the notoriously small, often inadequate, amounts of labeled sample data that are available for typical HAR applications. In response to such challenges, we propose ConvBoost -- a novel, three-layer, structured model architecture and boosting framework for convolutional network based HAR. Our framework generates additional training data from three different perspectives for improved HAR, aiming to alleviate the shortness of labeled training data in the field. Specifically, with the introduction of three conceptual layers--Sampling Layer, Data Augmentation Layer, and Resilient Layer -- we develop three "boosters" -R-Frame,
    
[^56]: 面向乌克兰语的基于语法和句法的语料库分析工具

    The Grammar and Syntax Based Corpus Analysis Tool For The Ukrainian Language. (arXiv:2305.13530v1 [cs.CL])

    [http://arxiv.org/abs/2305.13530](http://arxiv.org/abs/2305.13530)

    StyloMetrix是一种基于语法和句法的文本挖掘工具，可分析乌克兰语的语法、文体和句法模式，适用于文本分类任务。

    

    本文介绍了一种文本挖掘工具StyloMetrix，最初用于波兰语，后来扩展到英语和乌克兰语。它基于计算语言学家和文学研究人员手工制作的各种指标，分析语法、文体和句法模式。我们描述了StyloMetrix管道，并针对文本分类任务进行了一些实验。我们还描述了我们软件包的主要限制和指标的评估过程。

    This paper provides an overview of a text mining tool the StyloMetrix developed initially for the Polish language and further extended for English and recently for Ukrainian. The StyloMetrix is built upon various metrics crafted manually by computational linguists and researchers from literary studies to analyze grammatical, stylistic, and syntactic patterns. The idea of constructing the statistical evaluation of syntactic and grammar features is straightforward and familiar for the languages like English, Spanish, German, and others; it is yet to be developed for low-resource languages like Ukrainian. We describe the StyloMetrix pipeline and provide some experiments with this tool for the text classification task. We also describe our package's main limitations and the metrics' evaluation procedure.
    
[^57]: 最小化通信的异步张量并行性

    Communication-minimizing Asynchronous Tensor Parallelism. (arXiv:2305.13525v1 [cs.LG])

    [http://arxiv.org/abs/2305.13525](http://arxiv.org/abs/2305.13525)

    本文提出了Tensor3D，一种最小化通信消耗的三维张量计算并行化方法。它利用智能分布神经网络参数、新颖超分解方法以及通信模型，使训练速度提高了约3倍，GPU空闲时间降低了50％以上。

    

    随着现代神经网络规模扩大到数十亿个参数，设计能够在多GPU集群上高效训练这些网络的并行算法变得至关重要。本文提出了Tensor3D，一种全新的三维（3D）张量计算并行化方法，旨在最小化大型多十亿参数模型的并行训练中由通信引起的空闲时间。首先，我们引入了一种智能的神经网络参数分布方式，消除了为满足各层数据依赖而需要的通信。然后，我们提出了一种新颖的并行训练过程超分解方法，利用它可以显著提高通信与计算的重叠度，从而减少GPU空闲时间。最后，我们提出了一种通信模型，帮助用户为给定的神经网络识别通信最优的可用硬件资源分解。 对于256 A100 GPU上的28B参数CNN，在本文的 Tensor3D 方法下，训练速度提高了约3倍，与以前的方法相比 GPU 空闲时间也降低了约50％以上。

    As state-of-the-art neural networks scale to billions of parameters, designing parallel algorithms that can train these networks efficiently on multi-GPU clusters has become critical. This paper presents Tensor3D, a novel three-dimensional (3D) approach to parallelize tensor computations, that strives to minimize the idle time incurred due to communication in parallel training of large multi-billion parameter models. First, we introduce an intelligent distribution of neural network parameters across GPUs that eliminates communication required for satisfying data dependencies of individual layers. Then, we propose a novel overdecomposition of the parallel training process, using which we achieve significant overlap of communication with computation, thereby reducing GPU idle time. Finally, we present a communication model, which helps users identify communication optimal decompositions of available hardware resources for a given neural network. For a 28B parameter CNN on 256 A100 GPUs, 
    
[^58]: Tied-Augment：控制表示相似性以提高数据增强

    Tied-Augment: Controlling Representation Similarity Improves Data Augmentation. (arXiv:2305.13520v1 [cs.CV])

    [http://arxiv.org/abs/2305.13520](http://arxiv.org/abs/2305.13520)

    Tied-Augment可以通过控制表示相似性提高数据增强的效果，可以应用于很多任务中，例如半监督学习、自监督学习等。

    

    数据增强是深度学习模型的重要组成部分，已成为半监督、自监督和监督训练中最先进模型不可或缺的组成部分。我们提出了一种名为Tied-Augment的通用框架，它通过将一个简单的项添加到损失函数中来控制扭曲下的表示相似性，从而在广泛的应用中提高数据增强的有效性。Tied-Augment可以改善来自数据增强，优化和半监督学习的最先进方法（例如RandAugment，mixup和SAM）。例如，Tied-RandAugment可以优于...

    Data augmentation methods have played an important role in the recent advance of deep learning models, and have become an indispensable component of state-of-the-art models in semi-supervised, self-supervised, and supervised training for vision. Despite incurring no additional latency at test time, data augmentation often requires more epochs of training to be effective. For example, even the simple flips-and-crops augmentation requires training for more than 5 epochs to improve performance, whereas RandAugment requires more than 90 epochs. We propose a general framework called Tied-Augment, which improves the efficacy of data augmentation in a wide range of applications by adding a simple term to the loss that can control the similarity of representations under distortions. Tied-Augment can improve state-of-the-art methods from data augmentation (e.g. RandAugment, mixup), optimization (e.g. SAM), and semi-supervised learning (e.g. FixMatch). For example, Tied-RandAugment can outperfor
    
[^59]: 能ChatGPT检测出意图吗？评估用于口语理解的大型语言模型。

    Can ChatGPT Detect Intent? Evaluating Large Language Models for Spoken Language Understanding. (arXiv:2305.13512v1 [cs.CL])

    [http://arxiv.org/abs/2305.13512](http://arxiv.org/abs/2305.13512)

    本文评估了几个大型预训练语言模型在口语理解任务中的表现，发现最大模型可以在零-shot学习和上下文学习中达到与监督模型相近的意图分类准确度，但在槽填充方面表现不佳，且对ASR错误敏感。

    

    最近，大型预训练语言模型展示了强大的语言理解能力，特别体现在通过提示在下游任务中的零-shot和上下文学习能力。为了评估它们对口语理解（SLU）的影响，我们评估了几个不同大小的ChatGPT和OPT模型在多个基准测试中的表现。我们验证了最大模型特有的新兴能力，即在给定Oracle转录的各种语言上，其可以接近于监督模型的意图分类准确度。相比之下，适合单个GPU的较小模型的结果远远落后。我们注意到错误案例通常来自数据集的注释方案；ChatGPT的响应仍然是合理的。但是我们发现，该模型在槽填充方面表现不佳，而且对ASR错误非常敏感，因此表明了将这些文本模型应用于口语理解的严峻挑战。

    Recently, large pretrained language models have demonstrated strong language understanding capabilities. This is particularly reflected in their zero-shot and in-context learning abilities on downstream tasks through prompting. To assess their impact on spoken language understanding (SLU), we evaluate several such models like ChatGPT and OPT of different sizes on multiple benchmarks. We verify the emergent ability unique to the largest models as they can reach intent classification accuracy close to that of supervised models with zero or few shots on various languages given oracle transcripts. By contrast, the results for smaller models fitting a single GPU fall far behind. We note that the error cases often arise from the annotation scheme of the dataset; responses from ChatGPT are still reasonable. We show, however, that the model is worse at slot filling, and its performance is sensitive to ASR errors, suggesting serious challenges for the application of those textual models on SLU.
    
[^60]: ColMix -- 一种简单的数据增强框架，可提高航空图像中的目标检测器性能和鲁棒性

    ColMix -- A Simple Data Augmentation Framework to Improve Object Detector Performance and Robustness in Aerial Images. (arXiv:2305.13509v1 [cs.CV])

    [http://arxiv.org/abs/2305.13509](http://arxiv.org/abs/2305.13509)

    本论文提出了一种新的数据增强方法——拼贴拼贴（collage pasting），用于增加目标密度，提高航空图像中的目标检测器性能和鲁棒性，并与其他方法相比证明了它的优越性。

    

    在过去的十年中，卷积神经网络（CNN）和基于Transformer的目标检测器在各种数据集上取得了高性能。尽管大多数检测文献是在MS COCO等数据集上发展这种能力，但这些检测器已被证明在遥感应用中也很有效。而这个特定领域的挑战，如标注对象数量少和低目标密度，阻碍了总体性能。在这项工作中，我们提出了一种新的增强方法——拼贴拼贴（collage pasting），用于增加目标密度，无需分割掩模，从而提高检测器性能。我们证明，与类似的方法（如马赛克增强）相比，拼贴拼贴（collage pasting）可以提高精度和召回，并实现更大的目标密度控制。然而，我们发现，拼贴拼贴（collage pasting）容易受到某些分布外移位（如图像损坏）的影响。为了解决这个问题，我们引入了两种简单的方法

    In the last decade, Convolutional Neural Network (CNN) and transformer based object detectors have achieved high performance on a large variety of datasets. Though the majority of detection literature has developed this capability on datasets such as MS COCO, these detectors have still proven effective for remote sensing applications. Challenges in this particular domain, such as small numbers of annotated objects and low object density, hinder overall performance. In this work, we present a novel augmentation method, called collage pasting, for increasing the object density without a need for segmentation masks, thereby improving the detector performance. We demonstrate that collage pasting improves precision and recall beyond related methods, such as mosaic augmentation, and enables greater control of object density. However, we find that collage pasting is vulnerable to certain out-of-distribution shifts, such as image corruptions. To address this, we introduce two simple approaches
    
[^61]: 多模态自动事实核查：一份调查

    Multimodal Automated Fact-Checking: A Survey. (arXiv:2305.13507v1 [cs.CL])

    [http://arxiv.org/abs/2305.13507](http://arxiv.org/abs/2305.13507)

    本调查提出了一个多模态自动事实核查的框架，并包括了独特的子任务，重点关注了文本，图像，音频和视频这四种模态的现实应用。纪录了相关的基准模型，讨论了未来研究的局限性和前景。

    

    错误信息，即事实上不正确的信息，通常以多种形式传达，例如带有标题的图像。 它被人们视为更可信，比其仅限于文本的对应物扩散速度更快，范围更广。 尽管越来越多的研究涉及自动事实核查（AFC），但以往的调查主要集中在文本误导方面。 在本调查中，我们构建了一个包括多模态误导独特子任务在内的AFC框架。此外，我们在我们的框架上讨论了不同社区所发展的相关术语。 我们重点关注现实世界事实核查中存在的四种模态：文本，图像，音频和视频。 我们调查了基准和模型，并讨论了未来研究的局限性和有前途的方向。

    Misinformation, i.e. factually incorrect information, is often conveyed in multiple modalities, e.g. an image accompanied by a caption. It is perceived as more credible by humans, and spreads faster and wider than its text-only counterparts. While an increasing body of research investigates automated fact-checking (AFC), previous surveys mostly focus on textual misinformation. In this survey, we conceptualise a framework for AFC including subtasks unique to multimodal misinformation. Furthermore, we discuss related terminological developed in different communities in the context of our framework. We focus on four modalities prevalent in real-world fact-checking: text, image, audio, and video. We survey benchmarks and models, and discuss limitations and promising directions for future research.
    
[^62]: Flover：一种用于高效自回归模型并行推断的时间融合框架

    Flover: A Temporal Fusion Framework for Efficient Autoregressive Model Parallel Inference. (arXiv:2305.13484v1 [cs.DC])

    [http://arxiv.org/abs/2305.13484](http://arxiv.org/abs/2305.13484)

    Flover是一种用于自回归模型并行推断的时间融合框架，解决了并行性不足和灵活性差的问题，可以实现更加高效的推断性能。

    

    在深度学习领域快速发展的背景下，模型推断性能成为一个关键因素，尤其是在模型变得更加复杂并被部署在多个应用场景中的情况下。自回归模型由于在众多生成任务中表现优异，因此备受关注。这些模型设计上采用了一种时间依赖结构，其中当前token的概率分布受到前面token的影响。然而，这种本质上的序列特性遵循马尔可夫链假设，缺乏时间并行性，因此存在独特的挑战。特别是在工业背景下，推断请求遵循泊松时间分布，需要不同的响应长度，这种并行性的缺失更加明显。现有的解决方案如动态批处理和并发模型实例，然而，这些粗粒度的方法存在严重的开销和缺乏灵活性，无法实现最优化。

    In the rapidly evolving field of deep learning, the performance of model inference has become a pivotal aspect as models become more complex and are deployed in diverse applications. Among these, autoregressive models stand out due to their state-of-the-art performance in numerous generative tasks. These models, by design, harness a temporal dependency structure, where the current token's probability distribution is conditioned on preceding tokens. This inherently sequential characteristic, however, adheres to the Markov Chain assumption and lacks temporal parallelism, which poses unique challenges. Particularly in industrial contexts where inference requests, following a Poisson time distribution, necessitate diverse response lengths, this absence of parallelism is more profound. Existing solutions, such as dynamic batching and concurrent model instances, nevertheless, come with severe overheads and a lack of flexibility, these coarse-grained methods fall short of achieving optimal la
    
[^63]: MAILEX: 邮件事件与参数抽取

    MAILEX: Email Event and Argument Extraction. (arXiv:2305.13469v1 [cs.CL])

    [http://arxiv.org/abs/2305.13469](http://arxiv.org/abs/2305.13469)

    本文提出了针对邮件领域的事件抽取数据集\dataset，比较了序列标记和生成式端到端抽取的方法，结果表明该任务存在非连续共享触发器跨度、非命名实体参数和邮件会话历史等难点，未来需要更多研究。

    

    本文提出了第一个数据集 \dataset，用于从邮件串中执行事件抽取。为此，我们首先提出了一个新的分类法，涵盖了邮件领域中的 10 种事件类型和 76 个参数。我们的最终数据集包括约 4K 封标记有约 9K 个事件实例的邮件。为了了解任务的挑战，我们进行了一系列实验，比较了两种常见的事件抽取方法，即序列标记和生成式端到端抽取（包括几率 GPT-3.5）。我们的结果表明，邮件事件抽取任务远未得到解决，因为存在诸多难点，例如提取非连续共享触发器跨度、提取非命名实体参数和建模邮件会话历史等。因此，我们的工作提出了未来在这个特定领域的事件抽取任务中需要进行更多研究的建议。

    In this work, we present the first dataset, \dataset, for performing event extraction from conversational email threads. To this end, we first proposed a new taxonomy covering 10 event types and 76 arguments in the email domain. Our final dataset includes $\sim$4K emails annotated with $\sim$9K event instances. To understand the task challenges, we conducted a series of experiments comparing two commonly-seen lines of approaches for event extraction, i.e., sequence labeling and generative end-to-end extraction (including few-shot GPT-3.5). Our results showed that the task of email event extraction is far from being addressed, due to challenges lying in, e.g., extracting non-continuous, shared trigger spans, extracting non-named entity arguments, and modeling the email conversational history. Our work thus suggests more investigations in this domain-specific event extraction task in the future.\footnote{The source code and dataset can be obtained from \url{https://github.com/salokr/Emai
    
[^64]: 遗传算法在组合优化问题中的应用

    The First Proven Performance Guarantees for the Non-Dominated Sorting Genetic Algorithm II (NSGA-II) on a Combinatorial Optimization Problem. (arXiv:2305.13459v1 [cs.AI])

    [http://arxiv.org/abs/2305.13459](http://arxiv.org/abs/2305.13459)

    本论文对遗传算法在经典优化问题中的应用进行了研究，首次提供了经过验证的NSGA-II性能保证。

    

    非支配排序遗传算法II（NSGA-II）是解决多目标优化问题的最突出算法之一。最近，该算法的第一个数学运行时间保证已被证明，但仅适用于合成基准问题。在本研究中，我们针对NP完全的双目最小生成树问题提供了首个经过验证的NSGA-II性能保证。具体而言，我们展示NSGA-II使用种群大小$N \ge 4((n-1) w_\max + 1)$，能够在望在$O(m^2 n w_\max \log(n w_\max))$次迭代中，计算出帕累托前沿的所有极端点，其中$n$是顶点数，$m$是边数，$w_\max$是问题实例中的最大边权。该结果通过数学手段证实了NSGA-II的良好效果并且表明可以将此算法用于解决经典优化问题。

    The Non-dominated Sorting Genetic Algorithm-II (NSGA-II) is one of the most prominent algorithms to solve multi-objective optimization problems. Recently, the first mathematical runtime guarantees have been obtained for this algorithm, however only for synthetic benchmark problems.  In this work, we give the first proven performance guarantees for a classic optimization problem, the NP-complete bi-objective minimum spanning tree problem. More specifically, we show that the NSGA-II with population size $N \ge 4((n-1) w_{\max} + 1)$ computes all extremal points of the Pareto front in an expected number of $O(m^2 n w_{\max} \log(n w_{\max}))$ iterations, where $n$ is the number of vertices, $m$ the number of edges, and $w_{\max}$ is the maximum edge weight in the problem instance. This result confirms, via mathematical means, the good performance of the NSGA-II observed empirically. It also shows that mathematical analyses of this algorithm are not only possible for synthetic benchmark pr
    
[^65]: 一种基于元学习和信道状态信息的可推广室内定位模型

    A Meta-learning based Generalizable Indoor Localization Model using Channel State Information. (arXiv:2305.13453v1 [cs.LG])

    [http://arxiv.org/abs/2305.13453](http://arxiv.org/abs/2305.13453)

    本文提出了一种基于元学习和信道状态信息的室内定位模型，以解决深度学习定位模型中持续存在的通用性缺失问题。

    

    近年来，室内定位因其在智能家居、工业自动化和医疗保健等领域的广泛应用而受到了重视，特别是随着越来越多的人依赖其无线设备进行基于位置的服务。基于深度学习的解决方案利用无线参数（如信道状态信息（CSI）和接收信号强度指示器（RSSI））在室内环境中准确估计无线设备的位置已经取得了很好的效果。然而，尽管深度学习模型在实现高准确度的定位方面取得了成功，但这些模型缺乏通用性，在不重新训练的情况下无法轻松部署到新环境或在动态环境中运行。本文提出了基于元学习的定位模型来解决传统深度学习定位模型中持续存在的通用性缺失问题。此外，由于元学习算法需要多元化数据。

    Indoor localization has gained significant attention in recent years due to its various applications in smart homes, industrial automation, and healthcare, especially since more people rely on their wireless devices for location-based services. Deep learning-based solutions have shown promising results in accurately estimating the position of wireless devices in indoor environments using wireless parameters such as Channel State Information (CSI) and Received Signal Strength Indicator (RSSI). However, despite the success of deep learning-based approaches in achieving high localization accuracy, these models suffer from a lack of generalizability and can not be readily-deployed to new environments or operate in dynamic environments without retraining. In this paper, we propose meta-learning-based localization models to address the lack of generalizability that persists in conventionally trained DL-based localization models. Furthermore, since meta-learning algorithms require diverse dat
    
[^66]: 测量和建模身体内在动机

    Measuring and Modeling Physical Intrinsic Motivation. (arXiv:2305.13452v1 [cs.AI])

    [http://arxiv.org/abs/2305.13452](http://arxiv.org/abs/2305.13452)

    本文对身体内在动机进行了量化建模，发现对抗性奖励模型可以最好地预测人类对物理情境的趣味反应，还发现简单场景特征模型无法在所有情境中预测人类反应，将对抗模型和场景中碰撞数量进行线性组合，能够显著提高对人类反应的预测能力，表明人类追求高信息增益和身体活动的情况。

    

    人类是有驱动力的互动性代理，他们追求有趣的物理动力学情境。本文探讨了形式化的物理内在动机形式。我们首先收集了人类对多种物理情境的评分。接着，我们通过实现依赖于简单场景特征的模型到依赖于前向物理预测的模型的各种内在动机假设来建模人类的趣味反应。我们发现，对于人类反应的单一最佳预测器是针对物理预测损失推导出的对抗性奖励模型。我们还发现，简单的场景特征模型不能在所有情境中推广他们对人类反应的预测。最后，将对抗模型与场景中碰撞数量进行线性组合，可显著提高对人类反应的预测能力，表明人类倾向于追求高信息增益和身体活动的情况。

    Humans are interactive agents driven to seek out situations with interesting physical dynamics. Here we formalize the functional form of physical intrinsic motivation. We first collect ratings of how interesting humans find a variety of physics scenarios. We then model human interestingness responses by implementing various hypotheses of intrinsic motivation including models that rely on simple scene features to models that depend on forward physics prediction. We find that the single best predictor of human responses is adversarial reward, a model derived from physical prediction loss. We also find that simple scene feature models do not generalize their prediction of human responses across all scenarios. Finally, linearly combining the adversarial model with the number of collisions in a scene leads to the greatest improvement in predictivity of human responses, suggesting humans are driven towards scenarios that result in high information gain and physical activity.
    
[^67]: 虚拟代理人中的发展好奇心和社交互动

    Developmental Curiosity and Social Interaction in Virtual Agents. (arXiv:2305.13396v1 [cs.LG])

    [http://arxiv.org/abs/2305.13396](http://arxiv.org/abs/2305.13396)

    本文研究了以发展性好奇心为基础的内在动机如何促进代理人进行探究，并发现代表新奇性和不确定性的奖励函数最成功地产生了多样的体验，并激活了环境中的应变。

    

    婴儿会有意识地探究复杂的物理和社会环境。为了探寻内在动机如何帮助组织探究，我们创建了虚拟婴儿代理人并将其置于受启发的3D环境中，没有外部奖励。该环境有一个虚拟的照看代理人，能够与婴儿代理交互并以类似游戏的方式互动。我们测试了类似于推动人类探索的动机的内在奖励函数：惊奇，不确定性，新奇性和学习进度。这些通用的奖励函数引导婴儿代理人探索其环境，并发现内嵌在照看代理中的应变。代表新奇性和不确定性的奖励函数最成功地产生了多样的体验，并激活了环境中的应变。我们还发现，在存在一个关注且反应迅速的照看代理人的情况下学习世界模型可以更加高效和有效。

    Infants explore their complex physical and social environment in an organized way. To gain insight into what intrinsic motivations may help structure this exploration, we create a virtual infant agent and place it in a developmentally-inspired 3D environment with no external rewards. The environment has a virtual caregiver agent with the capability to interact contingently with the infant agent in ways that resemble play. We test intrinsic reward functions that are similar to motivations that have been proposed to drive exploration in humans: surprise, uncertainty, novelty, and learning progress. These generic reward functions lead the infant agent to explore its environment and discover the contingencies that are embedded into the caregiver agent. The reward functions that are proxies for novelty and uncertainty are the most successful in generating diverse experiences and activating the environment contingencies. We also find that learning a world model in the presence of an attentiv
    
[^68]: 基于指令二元组的归纳程序搜索空间再压缩

    Further Decimating the Inductive Programming Search Space with Instruction Digrams. (arXiv:2305.13347v1 [cs.PL])

    [http://arxiv.org/abs/2305.13347](http://arxiv.org/abs/2305.13347)

    本文通过研究大量开源代码中指令二元组的频率分布，证明可以利用指令二元组限制指令选择从而减小搜索空间，从而提高归纳编程的效率。

    

    先前研究表明，从人类原创的代码中导出的重叠指令子集能够极大地缩小归纳编程的搜索空间，通常缩小几个数量级。本文将指令子集方法扩展到考虑指令-指令应用（或指令二元组）作为归纳编程的另一种搜索启发式。本研究分析了大量开源代码中指令二元组的频率分布，表明指令二元组分布极度偏斜，超过93%的指令二元组在代码样本中并未出现。我们演示了如何利用指令二元组在搜索过程中限制指令选择，进一步减小搜索空间的规模，在某些情况下减小了几个数量级。这大大增加了使用基于搜索的归纳编程技术生成程序的规模。我们讨论了结果和相关工作。

    Overlapping instruction subsets derived from human originated code have previously been shown to dramatically shrink the inductive programming search space, often by many orders of magnitude. Here we extend the instruction subset approach to consider direct instruction-instruction applications (or instruction digrams) as an additional search heuristic for inductive programming. In this study we analyse the frequency distribution of instruction digrams in a large sample of open source code. This indicates that the instruction digram distribution is highly skewed with over 93% of possible instruction digrams not represnted in the code sample. We demonstrate that instruction digrams can be used to constrain instruction selection during search, further reducing size of the the search space, in some cases by several orders of magnitude. This significantly increases the size of programs that can be generated using search based inductive programming techniques. We discuss the results and prov
    
[^69]: 从数据中发现因果关系和方程式

    Discovering Causal Relations and Equations from Data. (arXiv:2305.13341v1 [physics.data-an])

    [http://arxiv.org/abs/2305.13341](http://arxiv.org/abs/2305.13341)

    物理学利用科学方法回答自然现象，发现因果关系丶物理定律和方程式是其基础。随着大数据发展，从数据中发现因果关系和方程式逐渐成为研究的核心，但仍面临多项挑战。

    

    物理学是一门利用科学方法回答自然现象产生原因并建立可验证模型来解释这些现象的学科。几个世纪以来，发现不变、强健和因果解释世界的方程、法则和原则一直是物理学中的基础。这些发现源于对世界的观察，并在可能的情况下在所研究的系统中进行干预研究。随着大数据的出现和数据驱动方法的使用，因果和方程式发现领域在计算机科学、物理学、统计学、哲学以及许多应用领域取得了进展。所有这些领域都交织在一起，并可用于在观察数据中发现因果关系、物理定律和方程式。本文回顾了物理学广泛领域中的因果和方程式发现的概念、方法和相关作品，并概述了最重要的挑战。

    Physics is a field of science that has traditionally used the scientific method to answer questions about why natural phenomena occur and to make testable models that explain the phenomena. Discovering equations, laws and principles that are invariant, robust and causal explanations of the world has been fundamental in physical sciences throughout the centuries. Discoveries emerge from observing the world and, when possible, performing interventional studies in the system under study. With the advent of big data and the use of data-driven methods, causal and equation discovery fields have grown and made progress in computer science, physics, statistics, philosophy, and many applied fields. All these domains are intertwined and can be used to discover causal relations, physical laws, and equations from observational data. This paper reviews the concepts, methods, and relevant works on causal and equation discovery in the broad field of Physics and outlines the most important challenges 
    
[^70]: 使用大型语言模型进行基因集概括

    Gene Set Summarization using Large Language Models. (arXiv:2305.13338v1 [q-bio.GN])

    [http://arxiv.org/abs/2305.13338](http://arxiv.org/abs/2305.13338)

    该论文介绍了一种使用大型语言模型来对基因集进行函数概括的方法，名为SPINDOCTOR，可以提供比传统方法更好的性能和可解释性。

    

    分子生物学家经常解释从高通量实验和计算分析中获得的基因列表。这通常是通过统计富集分析来完成的，该分析测量与基因或其属性相关的生物功能术语的过度或欠表示程度，基于知识库（KB）（例如Gene Ontology（GO））中的编译断言。解释基因列表也可以被构建为一个文本概括任务，利用大型语言模型（LLMs）进行，可能直接利用科学文本并避免依赖KB。我们开发了SPINDOCTOR（稳定的提示插值的受控术语的自然语言描述的结构化报告模板），一种使用GPT模型执行基因集函数概括的方法，作为标准富集分析的补充。该方法可以使用不同的基因功能信息来源：（1）从鉴定的本体KB注释中获得的结构化文本，（2）从文本挖掘中推断的本体术语，以及（3）直接从非结构化文本中获得的术语。我们在一个1813个基因集的基准数据集上评估了SPINDOCTOR，并展示了使用GPT模型显著改善了现有方法的性能，同时也提高了可解释性，因为它能够生成人类可读的基因功能摘要。

    Molecular biologists frequently interpret gene lists derived from high-throughput experiments and computational analysis. This is typically done as a statistical enrichment analysis that measures the over- or under-representation of biological function terms associated with genes or their properties, based on curated assertions from a knowledge base (KB) such as the Gene Ontology (GO). Interpreting gene lists can also be framed as a textual summarization task, enabling the use of Large Language Models (LLMs), potentially utilizing scientific texts directly and avoiding reliance on a KB.  We developed SPINDOCTOR (Structured Prompt Interpolation of Natural Language Descriptions of Controlled Terms for Ontology Reporting), a method that uses GPT models to perform gene set function summarization as a complement to standard enrichment analysis. This method can use different sources of gene functional information: (1) structured text derived from curated ontological KB annotations, (2) ontol
    
[^71]: 使用2D图形进行三维分子几何分析

    3D Molecular Geometry Analysis with 2D Graphs. (arXiv:2305.13315v1 [physics.chem-ph])

    [http://arxiv.org/abs/2305.13315](http://arxiv.org/abs/2305.13315)

    本论文提出了一种使用2D图形并借助平衡信息传递神经网络（EMPNN）预测分子基态三维结构的方法。该方法可以更高效地预测准确的基态三维结构，优于RDKit和其他深度学习方法，并在属性预测任务上优于自监督学习方法。

    

    分子的基态三维结构对于许多分子分析任务至关重要。现代量子力学方法可以计算准确的三维结构，但计算复杂度很高。目前，缺乏从2D图形计算基态三维分子几何形状的有效替代方法。在这里，我们提出了一个新颖的深度学习框架，从分子图形预测三维几何形状。为此，我们开发了一个平衡信息传递神经网络（EMPNN），以更好地从分子图形中捕捉基态几何形状。为了提供一个三维分子几何分析的测试平台，我们开发了一个基准测试，包括一个大规模的分子几何数据集、数据分割和评估协议。实验结果表明，EMPNN可以比RDKit和其他深度学习方法更高效地预测更准确的基态三维结构。结果还表明，所提出的框架在属性预测任务上优于自监督学习方法。

    Ground-state 3D geometries of molecules are essential for many molecular analysis tasks. Modern quantum mechanical methods can compute accurate 3D geometries but are computationally prohibitive. Currently, an efficient alternative to computing ground-state 3D molecular geometries from 2D graphs is lacking. Here, we propose a novel deep learning framework to predict 3D geometries from molecular graphs. To this end, we develop an equilibrium message passing neural network (EMPNN) to better capture ground-state geometries from molecular graphs. To provide a testbed for 3D molecular geometry analysis, we develop a benchmark that includes a large-scale molecular geometry dataset, data splits, and evaluation protocols. Experimental results show that EMPNN can efficiently predict more accurate ground-state 3D geometries than RDKit and other deep learning methods. Results also show that the proposed framework outperforms self-supervised learning methods on property prediction tasks.
    
[^72]: 利用强化学习训练扩散模型

    Training Diffusion Models with Reinforcement Learning. (arXiv:2305.13301v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.13301](http://arxiv.org/abs/2305.13301)

    本文研究了利用强化学习方法直接优化扩散模型以实现下游对象的问题，并提出一种称之为去噪扩散策略优化（DDPO）的有效策略梯度算法，能够适应难以通过提示表达的图像压缩等目标，以及通过人类反馈得出的美学质量等目标。

    

    扩散模型是一类灵活的生成模型，采用对数似然目标的近似训练。然而，大多数扩散模型的使用案例并不关注似然，而是关注人类感知的图像质量或药物效力等下游目标。本文研究利用强化学习方法直接优化扩散模型以实现此类目标。我们描述了将去噪视为多步决策问题的方法，并提出称之为去噪扩散策略优化（DDPO）的一类策略梯度算法，相对于替代的奖励加权似然方法更为有效。在实证研究中，DDPO能够适应难以通过提示表达的图像压缩等目标，以及通过人类反馈得出的美学质量等目标。最后，我们展示DDPO可以利用来自反馈的提示-图像对齐方式来进行优化。

    Diffusion models are a class of flexible generative models trained with an approximation to the log-likelihood objective. However, most use cases of diffusion models are not concerned with likelihoods, but instead with downstream objectives such as human-perceived image quality or drug effectiveness. In this paper, we investigate reinforcement learning methods for directly optimizing diffusion models for such objectives. We describe how posing denoising as a multi-step decision-making problem enables a class of policy gradient algorithms, which we refer to as denoising diffusion policy optimization (DDPO), that are more effective than alternative reward-weighted likelihood approaches. Empirically, DDPO is able to adapt text-to-image diffusion models to objectives that are difficult to express via prompting, such as image compressibility, and those derived from human feedback, such as aesthetic quality. Finally, we show that DDPO can improve prompt-image alignment using feedback from a 
    
[^73]: GPT-SW3：一种面向北欧语言的自回归语言模型

    GPT-SW3: An Autoregressive Language Model for the Nordic Languages. (arXiv:2305.12987v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12987](http://arxiv.org/abs/2305.12987)

    GPT-SW3是面向北欧语言的第一个本地化大型生成语言模型，本文介绍了其开发过程，可作为其他研究人员开发面向较小语言的大型生成模型的指南和参考。

    

    本文详细介绍了开发面向北欧语言的第一个本地化大型生成语言模型GPT-SW3的过程。我们涵盖了开发过程的所有部分，从数据收集和处理，训练配置和指令微调，到评估和发布策略的考虑。我们希望本文能够作为指南和参考，帮助其他研究人员开发面向较小语言的大型生成模型。

    This paper details the process of developing the first native large generative language model for the Nordic languages, GPT-SW3. We cover all parts of the development process, from data collection and processing, training configuration and instruction finetuning, to evaluation and considerations for release strategies. We hope that this paper can serve as a guide and reference for other researchers that undertake the development of large generative models for smaller languages.
    
[^74]: 不精确标签学习：学习各种不精确标签配置的统一框架

    Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations. (arXiv:2305.12715v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.12715](http://arxiv.org/abs/2305.12715)

    本文提出了不精确标签学习（ILL）框架，利用期望最大化算法对不精确标签信息进行最大似然估计，为各种不精确标签配置问题提供了统一的解决方案。

    

    本文介绍了不精确标签学习（ILL）框架，这是一种处理机器学习任务中普遍存在的各种不精确标签配置的统一方法。ILL利用期望最大化（EM）算法对不精确标签信息进行最大似然估计（MLE），将精确标签视为潜在变量。与以前试图从不精确标签信息中推断正确标签的多功能方法相比，我们的ILL框架考虑了不精确标签信息强加的所有可能标签，允许对任何不精确标签的统一解决方案。通过全面的实验结果，我们展示了ILL可以无缝地适应各种情况，包括部分标签学习、半监督学习、噪声标签学习以及这些配置的混合。值得注意的是，我们的简单方法超过了现有的处理不精确标签的技术，标志着第一个统一解决这个问题的方法。

    In this paper, we introduce the imprecise label learning (ILL) framework, a unified approach to handle various imprecise label configurations, which are commonplace challenges in machine learning tasks. ILL leverages an expectation-maximization (EM) algorithm for the maximum likelihood estimation (MLE) of the imprecise label information, treating the precise labels as latent variables. Compared to previous versatile methods attempting to infer correct labels from the imprecise label information, our ILL framework considers all possible labeling imposed by the imprecise label information, allowing a unified solution to deal with any imprecise labels. With comprehensive experimental results, we demonstrate that ILL can seamlessly adapt to various situations, including partial label learning, semi-supervised learning, noisy label learning, and a mixture of these settings. Notably, our simple method surpasses the existing techniques for handling imprecise labels, marking the first unified 
    
[^75]: 在高考基准测试上评估大型语言模型的性能

    Evaluating the Performance of Large Language Models on GAOKAO Benchmark. (arXiv:2305.12474v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12474](http://arxiv.org/abs/2305.12474)

    本文介绍了一个基于高考考试问题的基准测试GAOKAO-Benchmark，用于评估大型语言模型在客观和主观问题方面的表现。通过对ChatGPT模型的评估，研究发现其在客观问题方面表现出色，同时也揭示了其不足之处和改进的方向。

    

    大型语言模型已经在各种自然语言处理任务中展示了出色的性能；然而它们在更具挑战性和领域特定的任务中的功效仍然不太清楚。本文介绍了GAOKAO-Benchmark（GAOKAO-Bench），这是一个直观的基准测试，它使用中国高考考试的题目作为测试样本，评估大型语言模型。为了尽可能地使评估结果与人类一致，我们设计了一种基于零-shot提示的方法，通过将问题分为主观和客观类型来分析模型的准确性和评分率。我们评估了ChatGPT模型在GAOKAO-Benchmark性能上的表现。我们的研究发现，ChatGPT模型在解决客观问题方面表现出色，同时也揭示了其不足之处和改进的方向。为了进一步审查模型的响应，我们加入了人类评估。总之，本研究为创建一个稳健的评估GAOKAO基准测试提供了贡献。

    Large language models have demonstrated remarkable performance across various natural language processing tasks; however, their efficacy in more challenging and domain-specific tasks remains less explored. This paper introduces the GAOKAO-Benchmark (GAOKAO-Bench), an intuitive benchmark that employs questions from the Chinese Gaokao examination as test samples for evaluating large language models.In order to align the evaluation results with humans as much as possible, we designed a method based on zero-shot prompts to analyze the accuracy and scoring rate of the model by dividing the questions into subjective and objective types. We evaluated the ChatGPT model on GAOKAO-Benchmark performance.Our findings reveal that the ChatGPT model excels in tackling objective questions, while also shedding light on its shortcomings and areas for improvement. To further scrutinize the model's responses, we incorporate human evaluations.In conclusion, this research contributes a robust evaluation ben
    
[^76]: PhotoMat：从单闪光照片中学习的材质生成器

    PhotoMat: A Material Generator Learned from Single Flash Photos. (arXiv:2305.12296v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.12296](http://arxiv.org/abs/2305.12296)

    PhotoMat是第一个仅基于真实物料照片进行训练的材质生成器，能够产生高质量的数字材料，超过其他依赖于合成数据和/或材质地图监督的生成模型。

    

    高质量数字材质的制作对于3D渲染的逼真非常关键。以前的材质生成模型都是仅在合成数据上进行训练的，这种数据有现实世界中材质的视觉差距，而且还很难获得。我们提出了PhotoMat来解决这个问题，它是第一个仅基于手机闪光灯拍摄的真实物料照片进行训练的材质生成器。由于在这种情况下，无法获得单独材质地图的监督，因此我们训练了一个神经材质表示生成器，它使用学习的重照明模块渲染成任意光照下的RGB图像，与真实照片使用鉴别器进行比较。然后，我们通过训练材质地图估计器来从神经材质表示中解码材料的反射属性。我们用一个新的数据集训练了PhotoMat，其中包含了手持手机相机在闪光灯照明下捕获的12,000张物料照片。我们证明了我们生成的材料与真实照片相比具有高度的视觉保真度，并且优于依赖合成数据和/或材质地图监督的最先进的生成模型。我们的方法为基于学习的材料创作提供了一个大而多样的真实世界照片集。

    Authoring high-quality digital materials is key to realism in 3D rendering. Previous generative models for materials have been trained exclusively on synthetic data; such data is limited in availability and has a visual gap to real materials. We circumvent this limitation by proposing PhotoMat: the first material generator trained exclusively on real photos of material samples captured using a cell phone camera with flash. Supervision on individual material maps is not available in this setting. Instead, we train a generator for a neural material representation that is rendered with a learned relighting module to create arbitrarily lit RGB images; these are compared against real photos using a discriminator. We then train a material maps estimator to decode material reflectance properties from the neural material representation. We train PhotoMat with a new dataset of 12,000 material photos captured with handheld phone cameras under flash lighting. We demonstrate that our generated mat
    
[^77]: 人工智能中用户信任话语的挑战与趋势。

    Challenges and Trends in User Trust Discourse in AI. (arXiv:2305.11876v1 [cs.HC])

    [http://arxiv.org/abs/2305.11876](http://arxiv.org/abs/2305.11876)

    本文阐述在人工智能话语中用户信任面临的挑战和趋势，呼吁澄清概念以避免可能的信任差距和误解现象。

    

    1990年的互联网革命和数据驱动的信息革命改变了我们所知道的世界。现在，曾经被视为科幻想法（即机器统治世界）的事情被认为是可能的。这场革命也引发了对新的监管实践的需求，其中用户信任和人工智能（AI）话语发挥了核心作用。本研究旨在澄清关于人工智能话语中用户信任的一些误解，反对倾向于设计容易引起信任破裂的交互的趋势，包括真实和感知上的。研究结果表明，人们对于用户信任理解不清晰，并已经影响到计算机科学，尤其是在测量用户信任特征方面。研究呼吁澄清这些概念，以避免在人工智能采用与适用中出现潜在的信任差距和误解现象。

    The Internet revolution in 1990, followed by the data-driven and information revolution, has transformed the world as we know it. Nowadays, what seam to be 10 to 20 years ago, a science fiction idea (i.e., machines dominating the world) is seen as possible. This revolution also brought a need for new regulatory practices where user trust and artificial Intelligence (AI) discourse has a central role. This work aims to clarify some misconceptions about user trust in AI discourse and fight the tendency to design vulnerable interactions that lead to further breaches of trust, both real and perceived. Findings illustrate the lack of clarity in understanding user trust and its effects on computer science, especially in measuring user trust characteristics. It argues for clarifying those notions to avoid possible trust gaps and misinterpretations in AI adoption and appropriation.
    
[^78]: 自动温度调整的软性演员评论算法的正则化

    Regularization of Soft Actor-Critic Algorithms with Automatic Temperature Adjustment. (arXiv:2305.11831v1 [cs.LG])

    [http://arxiv.org/abs/2305.11831](http://arxiv.org/abs/2305.11831)

    本文提出了正则化自动温度调整的软性演员评论算法，增加了对原理的明确性。

    

    本文提出了一种使用自动温度调整的软性演员评论（SAC）算法的正则化方法，并对策略评估、策略改进和温度调整进行重新定义和修改，以更加明确地阐述原理。

    This work presents a comprehensive analysis to regularize the Soft Actor-Critic (SAC) algorithm with automatic temperature adjustment. The the policy evaluation, the policy improvement and the temperature adjustment are reformulated, addressing certain modification and enhancing the clarity of the original theory in a more explicit manner.
    
[^79]: 通过多语言一致性评估任务理解：ChatGPT案例研究

    Evaluating task understanding through multilingual consistency: A ChatGPT case study. (arXiv:2305.11662v1 [cs.CL])

    [http://arxiv.org/abs/2305.11662](http://arxiv.org/abs/2305.11662)

    本文提出了一种新的评估大型语言模型理解能力的范例，通过评估模型自身生成的不同意义之间的一致性，探讨了多语言自我一致性作为模型理解的检验方法，同时证明了ChatGPT在多语言一致性方面的优秀性能。

    

    随着大型语言模型（LLM）功能的惊人提升，创建未来可持续的评估集以评估它们的理解变得越来越具有挑战性。本文提出了一种新的评估LLM的范例，该范例利用了正确的世界理解应该在相同含义的不同（弗雷格）意义上保持一致的思想。因此，我们不是通过正确性来衡量理解，而是通过评估模型自身生成的多个意义之间的一致性来衡量。我们通过实例化一个测试展示了我们的方法，其中不同的意义是不同的语言，因此将多语言自我一致性作为模型理解的检验并同时解决多语言的重要主题。我们以最新版本的ChatGPT为我们的研究对象，在三种不同语言中评估两个不同任务的多语言一致性。我们证明了ChatGPT在多语言一致性方面的优秀性能。

    At the staggering pace with which the capabilities of large language models (LLMs) are increasing, creating future-proof evaluation sets to assess their understanding becomes more and more challenging. In this paper, we propose a novel paradigm for evaluating LLMs which leverages the idea that correct world understanding should be consistent across different (Fregean) senses of the same meaning. Accordingly, we measure understanding not in terms of correctness but by evaluating consistency across multiple senses that are generated by the model itself. We showcase our approach by instantiating a test where the different senses are different languages, hence using multilingual self-consistency as a litmus test for the model's understanding and simultaneously addressing the important topic of multilingualism. Taking one of the latest versions of ChatGPT as our object of study, we evaluate multilingual consistency for two different tasks across three different languages. We show that its m
    
[^80]: Instruct2Act：利用大型语言模型将多模态指令映射到机器人动作

    Instruct2Act: Mapping Multi-modality Instructions to Robotic Actions with Large Language Model. (arXiv:2305.11176v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2305.11176](http://arxiv.org/abs/2305.11176)

    本文提出了Instruct2Act，利用大型语言模型将多模态指令映射到机器人操作。通过使用基础模型的专业知识和机器人的能力，将复杂的高级指令转换为精确的策略代码，该方法可调整和灵活适应各种指令模态和输入类型，并满足特定的任务需求。

    

    基础模型在各种应用中取得了重大进展，包括文本到图像生成、全景分割和自然语言处理。本文介绍了Instruct2Act，这是一个利用大型语言模型将多模态指令映射到机器人操作的框架。具体地，Instruct2Act利用LLM模型生成Python程序，构成机器人任务的全面感知、规划和动作循环。该框架利用基础模型的专业知识和机器人的能力，将复杂的高级指令转换为精确的策略代码。我们的方法可以调整和灵活适应各种指令模态和输入类型，并满足特定的任务需求。

    Foundation models have made significant strides in various applications, including text-to-image generation, panoptic segmentation, and natural language processing. This paper presents Instruct2Act, a framework that utilizes Large Language Models to map multi-modal instructions to sequential actions for robotic manipulation tasks. Specifically, Instruct2Act employs the LLM model to generate Python programs that constitute a comprehensive perception, planning, and action loop for robotic tasks. In the perception section, pre-defined APIs are used to access multiple foundation models where the Segment Anything Model (SAM) accurately locates candidate objects, and CLIP classifies them. In this way, the framework leverages the expertise of foundation models and robotic abilities to convert complex high-level instructions into precise policy codes. Our approach is adjustable and flexible in accommodating various instruction modalities and input types and catering to specific task demands. W
    
[^81]: 自动推理领域相关问题的轻量级在线学习方法

    Lightweight Online Learning for Sets of Related Problems in Automated Reasoning. (arXiv:2305.11087v1 [cs.AI])

    [http://arxiv.org/abs/2305.11087](http://arxiv.org/abs/2305.11087)

    本文提出了一种自动推理中解决一组相关问题的轻量级在线学习方法，它能够自动收集信息并拟合机器学习模型来调整解决策略。在实验中证明该方法能证明更大的边界和发现更多反例。

    

    本文提出一种名为Self-Driven Strategy Learning (sdsl)的轻量级在线学习方法。该方法适用于自动推理中需要解决一组相关问题的任务。sdsl会在解决早期问题时自动收集信息来生成数据集。它利用这些学习到的数据来调整后续问题的解决策略，通过在线拟合机器学习模型。我们将这种方法形式化为一组抽象的转换规则。本文还描述了一个具体的sdsl计算实例，其中使用条件采样来生成数据，采用随机森林作为底层机器学习模型。我们在Kissat求解器上实现了该方法，并展示了Kissat+sdsl在最新的硬件模型检查竞赛中比其他最先进的有限模型检查方法证明了更大的边界和发现了更多的反例。

    We present Self-Driven Strategy Learning (sdsl), a lightweight online learning methodology for automated reasoning tasks that involve solving a set of related problems. sdsl automatically gathers information, in form of a dataset, while solving earlier problems. It utilizes the learned data to adjust the solving strategy for later problems by fitting a machine learning model to the obtained data on the fly. We formally define the approach as a set of abstract transition rules. We describe a concrete instance of the sdsl calculus which uses conditional sampling for generating data and random forests as the underlying machine learning model. We implement the approach on top of the Kissat solver and show that the combination of Kissat+sdsl certifies larger bounds and finds more counter-examples than other state-of-the-art bounded model checking approaches on benchmarks obtained from the latest Hardware Model Checking Competition.
    
[^82]: 基于参数的高效调整技术在医学图像分析中的应用：被忽视的机会

    Parameter-Efficient Fine-Tuning for Medical Image Analysis: The Missed Opportunity. (arXiv:2305.08252v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.08252](http://arxiv.org/abs/2305.08252)

    该论文综合评估了基于参数的高效调整技术（PEFT）在医学图像分析任务中的可能应用。通过超过600个控制测试，我们证明了PEFT的相对性能，并强调了PEFT在医学图像分析中实现参数高效转移学习的巨大潜力。

    

    我们对基于参数的高效调整技术（PEFT）在多样化的医学图像分析任务中进行了综合评估。PEFT越来越被用作知识转移的有价值方法，从自然语言处理、视觉、语音以及跨模态任务，例如视觉语言和文本到图像生成。然而，在医学图像分析中，它的应用仍相对未被探索。随着基础模型在医学领域越来越被利用，调查和比较评估各种知识转移策略可以增强各种下游任务至关重要。我们的研究是其类别中第一个（据我们所知），评估了16种卷积和基于转换器网络的PEFT方法，重点关注六个医学数据集上的图像分类和文本到图像生成任务，这些数据集在大小，模态和复杂性上有所不同。通过超过600个控制测试，我们证明了每种方法的相对性能，并确定了未来研究的途径，并强调了PEFT在医学图像分析中实现参数高效转移学习的潜力，并呼吁在未来研究中加以广泛探索。

    We present a comprehensive evaluation of Parameter-Efficient Fine-Tuning (PEFT) techniques for diverse medical image analysis tasks. PEFT is increasingly exploited as a valuable approach for knowledge transfer from pre-trained models in natural language processing, vision, speech, and cross-modal tasks, such as vision-language and text-to-image generation. However, its application in medical image analysis remains relatively unexplored. As foundation models are increasingly exploited in the medical domain, it is crucial to investigate and comparatively assess various strategies for knowledge transfer that can bolster a range of downstream tasks. Our study, the first of its kind (to the best of our knowledge), evaluates 16 distinct PEFT methodologies proposed for convolutional and transformer-based networks, focusing on image classification and text-to-image generation tasks across six medical datasets ranging in size, modality, and complexity. Through a battery of more than 600 control
    
[^83]: 当多数人是错误的：利用标注者不一致性进行主观任务

    When the Majority is Wrong: Leveraging Annotator Disagreement for Subjective Tasks. (arXiv:2305.06626v1 [cs.CL])

    [http://arxiv.org/abs/2305.06626](http://arxiv.org/abs/2305.06626)

    本文通过预测单个标注者的打分，并结合文本目标群体的预测，模拟了目标群体成员的意见，通过使用他们的人口统计学数据和在线意见预测标注者的打分，在仇恨言论检测等主观任务中提高了模型性能。

    

    在自然语言处理中，虽然通常使用标注者的多数投票来确定标签，但在仇恨言论检测等主观任务中，标注者之间存在不一致性可能反映出群体观点的差异，而不是噪声。因此，仇恨言论检测的一个关键问题是一个语句是否冒犯了它所针对的人群，而这可能只占标注者池的一小部分。本文构建了一个模型，预测可能具有冒犯性文本上每个标注者的打分，并结合文本的预测目标群体来模拟目标群体成员的意见。我们展示了一系列的评估指标，包括提高了22％在预测每个标注者的打分上的性能，提高了33％在预测标注者之间方差上的性能，这提供了下游用来衡量模型不确定性的方法。我们发现可以使用标注者的人口统计信息和其在线意见来预测标注者的打分。

    Though majority vote among annotators is typically used for ground truth labels in natural language processing, annotator disagreement in tasks such as hate speech detection may reflect differences among group opinions, not noise. Thus, a crucial problem in hate speech detection is whether a statement is offensive to the demographic group that it targets, which may constitute a small fraction of the annotator pool. We construct a model that predicts individual annotator ratings on potentially offensive text and combines this information with the predicted target group of the text to model the opinions of target group members. We show gains across a range of metrics, including raising performance over the baseline by 22% at predicting individual annotators' ratings and 33% at predicting variance among annotators, which provides a method of measuring model uncertainty downstream. We find that annotators' ratings can be predicted using their demographic information and opinions on online 
    
[^84]: 让自然成为自然语言处理的一部分

    Putting Natural in Natural Language Processing. (arXiv:2305.04572v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.04572](http://arxiv.org/abs/2305.04572)

    自然语言处理领域过于重视书面语言，应该将口语作为主要交流方式纳入考虑，真正的自然语言处理可以超越文本，与其他语言科学更好地整合，实现更高效、更像人类的系统。

    

    人类语言首先是口语，其次才是书写语言。然而，文本是语言的一种非常方便和有效的表示方式，现代文明已将其普及。因此，NLP领域主要关注处理书面语言，很少关注口语。与此同时，口语处理则主要集中于独立的语音处理社区，在将语音转录为文本方面一直极为占优势。然而，深度学习的最新进展导致了语音处理和主流NLP方法之间的有利趋同。有人认为，现在是将这两个领域统一起来，认真对待口语作为人类主要交流方式的时候了。真正的自然语言处理可以带来与其他语言科学更好的整合，可以实现更高效、更像人类的系统，从而可以超越文本模式进行沟通。

    Human language is firstly spoken and only secondarily written. Text, however, is a very convenient and efficient representation of language, and modern civilization has made it ubiquitous. Thus the field of NLP has overwhelmingly focused on processing written rather than spoken language. Work on spoken language, on the other hand, has been siloed off within the largely separate speech processing community which has been inordinately preoccupied with transcribing speech into text. Recent advances in deep learning have led to a fortuitous convergence in methods between speech processing and mainstream NLP. Arguably, the time is ripe for a unification of these two fields, and for starting to take spoken language seriously as the primary mode of human communication. Truly natural language processing could lead to better integration with the rest of language science and could lead to systems which are more data-efficient and more human-like, and which can communicate beyond the textual moda
    
[^85]: 人工智能技术的最新趋势：一个范围评估研究

    Latest Trends in Artificial Intelligence Technology: A Scoping Review. (arXiv:2305.04532v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2305.04532](http://arxiv.org/abs/2305.04532)

    本文对当前最先进的人工智能技术进行了范围评估，并要求对技术解决方案进行测试、使用公认数据集以及确保结果可复制。

    

    人工智能技术已经广泛应用于多个领域。智能手机、社交媒体平台、搜索引擎和自主驾驶车辆等应用程序都利用了人工智能技术以提高其性能。本研究按照 PRISMA 框架对当前最先进的人工智能技术进行了范围评估。目标是寻找应用于不同领域人工智能技术研究的最先进技术。从人工智能和机器学习领域选取了三个知名期刊：《人工智能研究杂志》、《机器学习研究杂志》和《机器学习》，并观察了2022年发表的文章。对技术解决方案进行了一定的资格要求：技术必须针对可比较的解决方案进行测试，必须使用公认或其他充分证明的数据集进行应用，并确保结果可复制。

    Artificial intelligence is more ubiquitous in multiple domains. Smartphones, social media platforms, search engines, and autonomous vehicles are just a few examples of applications that utilize artificial intelligence technologies to enhance their performance. This study carries out a scoping review of the current state-of-the-art artificial intelligence technologies following the PRISMA framework. The goal was to find the most advanced technologies used in different domains of artificial intelligence technology research. Three recognized journals were used from artificial intelligence and machine learning domain: Journal of Artificial Intelligence Research, Journal of Machine Learning Research, and Machine Learning, and articles published in 2022 were observed. Certain qualifications were laid for the technological solutions: the technology must be tested against comparable solutions, commonly approved or otherwise well justified datasets must be used while applying, and results must 
    
[^86]: AADiff: 基于文本到图像扩散的音频对齐视频合成

    AADiff: Audio-Aligned Video Synthesis with Text-to-Image Diffusion. (arXiv:2305.04001v1 [cs.CV])

    [http://arxiv.org/abs/2305.04001](http://arxiv.org/abs/2305.04001)

    本文提出了一种新颖的文本到视频合成框架AADiff，它使用音频信号控制时间动态，通过音频对齐生成视频。本文的方法通过音频区域编辑和信号平滑，在时间灵活性和一致性之间取得良好的平衡。该方法的有效性已通过实验验证，并可用于内容创建。

    

    最近扩散模型的进展在文本到视频（T2V）合成任务中展示了有前途的结果。然而，由于这些T2V模型仅使用文本作为引导，它们往往在建模详细的时间动态方面遇到困难。本文介绍了一种新颖的T2V框架，该框架另外使用音频信号来控制时间动态，使得一个现成的T2I扩散模型可以生成音频对齐的视频。我们提出基于音频的区域编辑和信号平滑来在视频合成的两个相互矛盾的愿望，即时间灵活性和一致性之间取得良好的平衡。我们通过实验来经验证明了我们方法的有效性，并进一步展示了内容创建的实际应用。

    Recent advances in diffusion models have showcased promising results in the text-to-video (T2V) synthesis task. However, as these T2V models solely employ text as the guidance, they tend to struggle in modeling detailed temporal dynamics. In this paper, we introduce a novel T2V framework that additionally employ audio signals to control the temporal dynamics, empowering an off-the-shelf T2I diffusion to generate audio-aligned videos. We propose audio-based regional editing and signal smoothing to strike a good balance between the two contradicting desiderata of video synthesis, i.e., temporal flexibility and coherence. We empirically demonstrate the effectiveness of our method through experiments, and further present practical applications for contents creation.
    
[^87]: Vera：一个用于通用常识语句可信度评估的模型

    Vera: A General-Purpose Plausibility Estimation Model for Commonsense Statements. (arXiv:2305.03695v1 [cs.CL])

    [http://arxiv.org/abs/2305.03695](http://arxiv.org/abs/2305.03695)

    本文提出了Vera模型，它是一个通用模型，可以基于常识知识估计陈述性语句的可信度。在解决验证格式的常识问题时，Vera明显优于现有的模型，并展现了对未见任务的泛化能力和良好的标定输出。

    

    尽管当今的语言模型在许多方面表现出色，但它们仍然容易出现荒谬和意外的常识失败。本文提出了一种回顾性验证方法，反思LM输出的正确性，并引入了Vera，一个通用模型，它基于常识知识估计陈述性语句的可信度。通过使用19个QA数据集和两个大规模知识库创建的约700万条常识语句以及三个训练目标的组合进行训练，Vera是一个多功能模型，可以有效地区分各种常识领域中的正确和错误语句。当应用于解决验证格式的常识问题时，Vera明显优于现有的可重用于常识验证的模型，并且它进一步展示了对未见任务的泛化能力并提供了良好的标定输出。我们发现Vera在过滤LM生成的常识知识方面表现突出，可以潜在地增强它们的可信度和实际应用。

    Despite the much discussed capabilities of today's language models, they are still prone to silly and unexpected commonsense failures. We consider a retrospective verification approach that reflects on the correctness of LM outputs, and introduce Vera, a general-purpose model that estimates the plausibility of declarative statements based on commonsense knowledge. Trained on ~7M commonsense statements created from 19 QA datasets and two large-scale knowledge bases, and with a combination of three training objectives, Vera is a versatile model that effectively separates correct from incorrect statements across diverse commonsense domains. When applied to solving commonsense problems in the verification format, Vera substantially outperforms existing models that can be repurposed for commonsense verification, and it further exhibits generalization capabilities to unseen tasks and provides well-calibrated outputs. We find that Vera excels at filtering LM-generated commonsense knowledge an
    
[^88]: 大语言模型在信息技术任务中自动生成YAML代码

    Automated Code generation for Information Technology Tasks in YAML through Large Language Models. (arXiv:2305.02783v1 [cs.SE])

    [http://arxiv.org/abs/2305.02783](http://arxiv.org/abs/2305.02783)

    这项研究提出了一种名为Ansible Wisdom的自然语言转Ansible-YAML代码的工具，可自动化生成Ansible脚本，提高IT自动化生产力，并相比现有技术达到或更好的性能水平。

    

    由于大语言模型在代码生成方面的不断提升，在通用编程语言方面的受益最大，而针对IT自动化等领域特定语言的研究较少。本研究聚焦于Ansible-YAML的生成，提出了一种名为Ansible Wisdom的自然语言转Ansible-YAML代码的工具，旨在提高IT自动化生产力。研究采用基于Transformer的模型，并通过新的包含Ansible-YAML的数据集进行扩展训练。同时，还开发了两个用于捕捉此领域特征的YAML和Ansible性能指标。结果表明，Ansible Wisdom可以精确地从自然语言提示中生成Ansible脚本，并且其性能可与现有技术的状态相媲美或更好。

    The recent improvement in code generation capabilities due to the use of large language models has mainly benefited general purpose programming languages. Domain specific languages, such as the ones used for IT Automation, have received far less attention, despite involving many active developers and being an essential component of modern cloud platforms. This work focuses on the generation of Ansible-YAML, a widely used markup language for IT Automation. We present Ansible Wisdom, a natural-language to Ansible-YAML code generation tool, aimed at improving IT automation productivity. Ansible Wisdom is a transformer-based model, extended by training with a new dataset containing Ansible-YAML. We also develop two novel performance metrics for YAML and Ansible to capture the specific characteristics of this domain. Results show that Ansible Wisdom can accurately generate Ansible script from natural language prompts with performance comparable or better than existing state of the art code 
    
[^89]: 超越多链思维：基于元推理的问题解答方法

    Answering Questions by Meta-Reasoning over Multiple Chains of Thought. (arXiv:2304.13007v1 [cs.CL])

    [http://arxiv.org/abs/2304.13007](http://arxiv.org/abs/2304.13007)

    本论文提出了基于元推理的Multi-Chain Reasoning (MCR)方法，该方法检查多个推理链，混合它们之间的信息并选择最相关的事实，从而超越多链思维，解决多跳QA问题。 实验结果表明MCR胜过多个强基线，解释质量高。

    

    现代多跳问题解答（QA）系统通常将问题分解为一系列思考步骤（CoT），然后才得出最终答案。通常来说，多个链条被抽样并通过最终答案的投票机制进行聚合，但中间步骤本身被丢弃。虽然这种方法提高了性能，但它们并不考虑链之间的中间步骤之间的关系，并且不提供预测答案的统一解释。我们引入了基于元推理的 Multi-Chain Reasoning (MCR) 方法，该方法利用大型语言模型来超越多个思考链，而不是聚合回答。MCR检查不同的推理链，混合它们之间的信息并选择在生成解释和预测答案时最相关的事实。MCR在7个多跳QA数据集上胜过强基线。此外，我们的分析表明MCR的解释具有高质量。

    Modern systems for multi-hop question answering (QA) typically break questions into a sequence of reasoning steps, termed chain-of-thought (CoT), before arriving at a final answer. Often, multiple chains are sampled and aggregated through a voting mechanism over the final answers, but the intermediate steps themselves are discarded. While such approaches improve performance, they do not consider the relations between intermediate steps across chains and do not provide a unified explanation for the predicted answer. We introduce Multi-Chain Reasoning (MCR), an approach which prompts large language models to meta-reason over multiple chains of thought, rather than aggregating their answers. MCR examines different reasoning chains, mixes information between them and selects the most relevant facts in generating an explanation and predicting the answer. MCR outperforms strong baselines on 7 multi-hop QA datasets. Moreover, our analysis reveals that MCR explanations exhibit high quality, en
    
[^90]: 在ChatGPT时代迈向负责任的人工智能：用于设计基于基础模型的AI系统的参考架构

    Towards Responsible AI in the Era of ChatGPT: A Reference Architecture for Designing Foundation Model-based AI Systems. (arXiv:2304.11090v1 [cs.CL])

    [http://arxiv.org/abs/2304.11090](http://arxiv.org/abs/2304.11090)

    本文提出了一个以模式为导向的负责任AI-by-design参考架构，用于设计基于基础模型的AI系统，重点关注可解释性、公平性、安全性和鲁棒性等关键设计元素。

    

    ChatGPT、Bard和其他大型语言模型(LLM)聊天机器人的推出在全球范围内引起了巨大关注。基础模型将成为未来大多数AI系统的基础构建块的趋势正在增长。然而，将基础模型纳入AI系统引发了对负责任AI的重大关注，这是由于其黑匣子性质和快速发展的超级智能引起的。此外，基础模型的增长能力最终可能会吞噬AI系统的其他组件，引入架构设计中的运动边界和接口演变挑战。为了应对这些挑战，本文提出了一种以模式为导向的负责任AI-by-design参考架构，用于设计基于基础模型的AI系统。特别地，本文首先呈现了基于基础模型的AI系统在架构演进方面的发展，从"基础模型作为连接器"到"基础模型作为单片机核"。然后，它提出了一个参考架构，包括五个类别的模式，重点关注关键设计元素，例如可解释性、公平性、安全性和鲁棒性。所提出的参考架构为设计负责任的基础模型的AI系统提供了系统化和透明的方法。

    The release of ChatGPT, Bard, and other large language model (LLM)-based chatbots has drawn huge attention on foundations models worldwide. There is a growing trend that foundation models will serve as the fundamental building blocks for most of the future AI systems. However, incorporating foundation models in AI systems raises significant concerns about responsible AI due to their black box nature and rapidly advancing super-intelligence. Additionally, the foundation model's growing capabilities can eventually absorb the other components of AI systems, introducing the moving boundary and interface evolution challenges in architecture design. To address these challenges, this paper proposes a pattern-oriented responsible-AI-by-design reference architecture for designing foundation model-based AI systems. Specially, the paper first presents an architecture evolution of AI systems in the era of foundation models, from "foundation-model-as-a-connector" to "foundation-model-as-a-monolithi
    
[^91]: 物理世界中愚弄热红外探测器

    Fooling Thermal Infrared Detectors in Physical World. (arXiv:2304.10712v1 [cs.CV])

    [http://arxiv.org/abs/2304.10712](http://arxiv.org/abs/2304.10712)

    本论文提出一种新颖的物理攻击方法——对抗性红外块（AdvIB），可以从多个角度对热成像系统执行隐蔽的黑盒攻击，成功诱导目标红外检测器在物理场景中对对象或人类进行误分类，并且不被人类察觉。

    

    红外成像系统在行人检测和自动驾驶等方面有着广泛的应用前景，并且它们的安全性能备受关注。然而，很少有研究探索了红外成像系统在真实世界环境下的安全性。过去的研究使用物理干扰，如小灯泡和热“QR代码”来攻击红外成像探测器，但这种方法很容易被察觉，缺乏隐秘性。其他研究人员使用热和冷块来欺骗红外成像探测器，但这种方法在从多个角度执行攻击方面的能力有限。为了解决这些缺点，我们提出了一种新颖的物理攻击方法，称为对抗性红外块（AdvIB）。通过优化对抗性红外块的物理参数，这种方法可以从多个角度对热成像系统执行隐蔽的黑盒攻击。我们根据其有效性、隐秘性和稳健性评估了所提出的方法。结果表明，AdvIB可以成功诱导目标红外检测器在物理场景中对对象或人类进行误分类，并且不被人类察觉。我们的工作强调了在红外成像系统中提高安全措施的必要性，特别是在真实世界环境中。

    Infrared imaging systems have a vast array of potential applications in pedestrian detection and autonomous driving, and their safety performance is of great concern. However, few studies have explored the safety of infrared imaging systems in real-world settings. Previous research has used physical perturbations such as small bulbs and thermal "QR codes" to attack infrared imaging detectors, but such methods are highly visible and lack stealthiness. Other researchers have used hot and cold blocks to deceive infrared imaging detectors, but this method is limited in its ability to execute attacks from various angles. To address these shortcomings, we propose a novel physical attack called adversarial infrared blocks (AdvIB). By optimizing the physical parameters of the adversarial infrared blocks, this method can execute a stealthy black-box attack on thermal imaging system from various angles. We evaluate the proposed method based on its effectiveness, stealthiness, and robustness. Our
    
[^92]: NeRFVS:基于几何支撑的神经辐射场实现自由视角合成

    NeRFVS: Neural Radiance Fields for Free View Synthesis via Geometry Scaffolds. (arXiv:2304.06287v1 [cs.CV])

    [http://arxiv.org/abs/2304.06287](http://arxiv.org/abs/2304.06287)

    NeRFVS是一种利用神经重建的“全局信息”，包括伪深度图和视角覆盖信息，基于几何支撑的神经辐射场方法。该方法在实现室内自由导航方面表现出色且可减少可见的伪影。

    

    本文提出了一种名为NeRFVS的新型神经辐射场（NeRF）方法，以实现在室内自由导航的功能。该方法利用神经重建的“全局信息”，包括伪深度图和视角覆盖信息，从而指导3D室内场景的隐式神经表示的学习。实验表明，我们的方法在定量指标和视觉质量方面均优于现有方法。

    We present NeRFVS, a novel neural radiance fields (NeRF) based method to enable free navigation in a room. NeRF achieves impressive performance in rendering images for novel views similar to the input views while suffering for novel views that are significantly different from the training views. To address this issue, we utilize the holistic priors, including pseudo depth maps and view coverage information, from neural reconstruction to guide the learning of implicit neural representations of 3D indoor scenes. Concretely, an off-the-shelf neural reconstruction method is leveraged to generate a geometry scaffold. Then, two loss functions based on the holistic priors are proposed to improve the learning of NeRF: 1) A robust depth loss that can tolerate the error of the pseudo depth map to guide the geometry learning of NeRF; 2) A variance loss to regularize the variance of implicit neural representations to reduce the geometry and color ambiguity in the learning procedure. These two loss
    
[^93]: 离线元强化学习中任务表示学习中的上下文分布偏移问题

    On Context Distribution Shift in Task Representation Learning for Offline Meta RL. (arXiv:2304.00354v1 [cs.LG])

    [http://arxiv.org/abs/2304.00354](http://arxiv.org/abs/2304.00354)

    该论文探讨了离线元强化学习中任务表示学习中遇到的上下文分布偏移问题，并提出了一种硬采样的策略用于解决该问题，实验结果表明该方法能够得到更强健的任务表示和更好的测试性能。

    

    离线元强化学习（OMRL）旨在从离线数据集中学习可转移知识，以促进新目标任务的学习过程。基于上下文的RL采用上下文编码器，通过推断任务表示来快速适应新任务，然后根据推断出的任务表示调整行动策略。在这里，我们考虑基于上下文的OMRL，特别是OMRL中的任务表示学习问题。我们经验性地证明，基于离线数据集训练的上下文编码器可能会遭受训练和测试时使用上下文之间的分布偏移。为了解决这个问题，我们提出了一种基于硬采样的策略，用于学习一个强健的任务上下文编码器。基于不同的连续控制任务的实验结果表明，我们的技术的利用导致更强健的任务表示和更好的测试性能，累积回报比基准方法好。

    Offline meta reinforcement learning (OMRL) aims to learn transferrable knowledge from offline datasets to facilitate the learning process for new target tasks. Context-based RL employs a context encoder to rapidly adapt the agent to new tasks by inferring about the task representation, and then adjusting the acting policy based on the inferred task representation. Here we consider context-based OMRL, in particular, the issue of task representation learning for OMRL. We empirically demonstrate that the context encoder trained on offline datasets could suffer from distribution shift between the contexts used for training and testing. To tackle this issue, we propose a hard sampling based strategy for learning a robust task context encoder. Experimental results, based on distinct continuous control tasks, demonstrate that the utilization of our technique results in more robust task representations and better testing performance in terms of accumulated returns, compared with baseline metho
    
[^94]: 大象的透视镜：调查谷歌、ChatGPT、维基百科和YouTube上的语言偏见

    A Perspectival Mirror of the Elephant: Investigating Language Bias on Google, ChatGPT, Wikipedia, and YouTube. (arXiv:2303.16281v1 [cs.CY])

    [http://arxiv.org/abs/2303.16281](http://arxiv.org/abs/2303.16281)

    研究发现在Google、ChatGPT、维基百科和YouTube上，搜索结果受限于语言，反映了与复杂主题相关的文化刻板印象，缺乏跨文化视角。

    

    与谷歌搜索“从多个角度获取信息，以便你可以形成自己对世界的理解”的任务相反，我们发现谷歌及其最突出的搜索结果 - 维基百科和YouTube，仅反映与“佛教”、“自由主义”、“殖民化”、“伊朗”和“美国”等复杂主题相关的文化刻板印象。简单地说，在不同语言的相同搜索中，它们以不同程度呈现不同的信息（我们称之为“语言偏见”），而不是呈现复杂主题的全球图片。我们的在线搜索使我们成为谚语中的盲人，仅触摸小象的一小部分，不知道其他文化的视角的存在。我们用于搜索的语言最终成为促进本族中心主义观点的文化过滤器，其中一个人根据自己的文化评估其他人或思想。我们还发现ChatGPT中深深嵌入了语言偏见。

    Contrary to Google Search's mission of delivering information from "many angles so you can form your own understanding of the world," we find that Google and its most prominent returned results -- Wikipedia and YouTube, simply reflect the narrow set of cultural stereotypes tied to the search language for complex topics like "Buddhism," "Liberalism," "colonization," "Iran" and "America." Simply stated, they present, to varying degrees, distinct information across the same search in different languages (we call it 'language bias'). Instead of presenting a global picture of a complex topic, our online searches turn us into the proverbial blind person touching a small portion of an elephant, ignorant of the existence of other cultural perspectives. The language we use to search ends up as a cultural filter to promote ethnocentric views, where a person evaluates other people or ideas based on their own culture. We also find that language bias is deeply embedded in ChatGPT. As it is primaril
    
[^95]: 自适应控制的两跳通信用于多智能体强化学习

    AC2C: Adaptively Controlled Two-Hop Communication for Multi-Agent Reinforcement Learning. (arXiv:2302.12515v2 [cs.MA] UPDATED)

    [http://arxiv.org/abs/2302.12515](http://arxiv.org/abs/2302.12515)

    本文提出了一种自适应控制的两跳通信(AC2C)协议，用于协同多智能体强化学习任务。该协议在初始的局部通信后采用自适应的两跳通信策略，以实现智能体之间的长距离信息交流，从而显著提高性能。

    

    最近，学习协同多智能体强化学习中的通信策略引起了广泛关注。早期的研究通常假设智能体之间有完全连接的通信拓扑结构，导致高昂的通信成本并且不切实际。近期的一些工作已经发展出了自适应通信策略以减少通信开销，但这些方法无法有效地获取超出通信范围之外的智能体宝贵的信息。在本文中，我们考虑到每个智能体具有有限的通信范围以及通信拓扑实时动态变化的情况。为了有效地实现智能体之间的通信，我们提出了一种新的通信协议，称为自适应控制的两跳通信(AC2C)。在初始的局部通信之后，AC2C采用自适应的两跳通信策略，以实现智能体之间的长距离信息交流，以提高性能，而这是仅通过局部通信难以实现的。我们在各种任务环境中验证了所提出方法的有效性，并表明AC2C在学习效率和可扩展性方面优于现有的通信方法。

    Learning communication strategies in cooperative multi-agent reinforcement learning (MARL) has recently attracted intensive attention. Early studies typically assumed a fully-connected communication topology among agents, which induces high communication costs and may not be feasible. Some recent works have developed adaptive communication strategies to reduce communication overhead, but these methods cannot effectively obtain valuable information from agents that are beyond the communication range. In this paper, we consider a realistic communication model where each agent has a limited communication range, and the communication topology dynamically changes. To facilitate effective agent communication, we propose a novel communication protocol called Adaptively Controlled Two-Hop Communication (AC2C). After an initial local communication round, AC2C employs an adaptive two-hop communication strategy to enable long-range information exchange among agents to boost performance, which is 
    
[^96]: ChatGPT：应付千事的万能型 AI，但无所专精

    ChatGPT: Jack of all trades, master of none. (arXiv:2302.10724v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.10724](http://arxiv.org/abs/2302.10724)

    本研究检验了 ChatGPT 在 25 个不同的 NLP 任务上的性能，它是一个万能的 AI 模型，但无关紧要的表现可能会对某些任务的表现产生负面影响。

    

    OpenAI 推出了聊天生成预训练 Transformer（ChatGPT），革新了人工智能与人类互动的方法。许多研究通过测试 ChatGPT 在众所周知的自然语言处理（NLP）任务中的效果，来评估该模型的效能。然而，现有的研究大多非自动化，并且规模非常有限。本研究在 25 个不同的 NLP 任务上检验了 ChatGPT 的性能，其中大多数任务甚至对人类而言都是主观的，例如情感分析、情绪识别、攻击性和立场检测。另一些任务则需要更客观的推理，如词义消歧、语言可接受性和问答。我们还对 GPT-4 模型在五个选定的 NLP 任务子集上进行了评估。我们自动化了 ChatGPT 和 GPT-4 的引导过程，并分析了超过 49k 个响应。与现有最先进的解决方案（SOTA）进行比较，我们的结果显示，在一些任务上 ChatGPT 的性能存在一定的缺陷。

    OpenAI has released the Chat Generative Pre-trained Transformer (ChatGPT) and revolutionized the approach in artificial intelligence to human-model interaction. Several publications on ChatGPT evaluation test its effectiveness on well-known natural language processing (NLP) tasks. However, the existing studies are mostly non-automated and tested on a very limited scale. In this work, we examined ChatGPT's capabilities on 25 diverse analytical NLP tasks, most of them subjective even to humans, such as sentiment analysis, emotion recognition, offensiveness, and stance detection. In contrast, the other tasks require more objective reasoning like word sense disambiguation, linguistic acceptability, and question answering. We also evaluated GPT-4 model on five selected subsets of NLP tasks. We automated ChatGPT and GPT-4 prompting process and analyzed more than 49k responses. Our comparison of its results with available State-of-the-Art (SOTA) solutions showed that the average loss in quali
    
[^97]: 反升级与概括：一份调查报告

    Anti-unification and Generalization: A Survey. (arXiv:2302.00277v3 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2302.00277](http://arxiv.org/abs/2302.00277)

    反升级或概括是归纳推理中使用的基本操作，是定理证明的双重操作之一。该调查报告对反升级的研究和应用进行了系统归纳和总结。

    

    反升级（AU）又称概括，是归纳推理中使用的基本操作，是定理证明基础上的双重操作之一。 AI和相关社区对AU的兴趣日益增长，但没有系统研究该概念，也没有现有工作的调查，调查往往会采用特定于应用的方法，而这些方法可能已经被现有方法覆盖。我们提供了第一份有关AU研究及其应用的调查报告，以及一种将现有和未来发展分类的通用框架。

    Anti-unification (AU), also known as generalization, is a fundamental operation used for inductive inference and is the dual operation to unification, an operation at the foundation of theorem proving. Interest in AU from the AI and related communities is growing, but without a systematic study of the concept, nor surveys of existing work, investigations7 often resort to developing application-specific methods that may be covered by existing approaches. We provide the first survey of AU research and its applications, together with a general framework for categorizing existing and future developments.
    
[^98]: 模拟城市空中出行融入现有交通系统：一项调查

    Simulating the Integration of Urban Air Mobility into Existing Transportation Systems: A Survey. (arXiv:2301.12901v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2301.12901](http://arxiv.org/abs/2301.12901)

    本文调查了城市空中出行（UAM）在大都市交通中的研究现状，确定了将UAM融入城市交通系统的关键挑战和机遇，包括对现有交通模式和拥堵的影响；安全分析和风险评估；潜在的经济和环境效益；以及为UAM和地面交通开发共享基础设施和路线。同时，我们讨论了UAM的潜在好处，如缩短旅行时间和改善服务不足地区的可达性。

    This paper surveys the current state of research on urban air mobility (UAM) in metropolitan-scale traffic using simulation techniques, identifying key challenges and opportunities for integrating UAM into urban transportation systems, including impacts on existing traffic patterns and congestion, safety analysis and risk assessment, potential economic and environmental benefits, and the development of shared infrastructure and routes for UAM and ground-based transportation. The potential benefits of UAM, such as reduced travel times and improved accessibility for underserved areas, are also discussed.

    城市空中出行（UAM）有可能彻底改变大都市地区的交通方式，提供一种新的交通方式，缓解拥堵，提高可达性。然而，将UAM融入现有交通系统是一项复杂的任务，需要深入了解其对交通流量和容量的影响。在本文中，我们进行了一项调查，使用模拟技术调查了UAM在大都市交通中的研究现状。我们确定了将UAM融入城市交通系统的关键挑战和机遇，包括对现有交通模式和拥堵的影响；安全分析和风险评估；潜在的经济和环境效益；以及为UAM和地面交通开发共享基础设施和路线。我们还讨论了UAM的潜在好处，如缩短旅行时间和改善服务不足地区的可达性。我们的调查

    Urban air mobility (UAM) has the potential to revolutionize transportation in metropolitan areas, providing a new mode of transportation that could alleviate congestion and improve accessibility. However, the integration of UAM into existing transportation systems is a complex task that requires a thorough understanding of its impact on traffic flow and capacity. In this paper, we conduct a survey to investigate the current state of research on UAM in metropolitan-scale traffic using simulation techniques. We identify key challenges and opportunities for the integration of UAM into urban transportation systems, including impacts on existing traffic patterns and congestion; safety analysis and risk assessment; potential economic and environmental benefits; and the development of shared infrastructure and routes for UAM and ground-based transportation. We also discuss the potential benefits of UAM, such as reduced travel times and improved accessibility for underserved areas. Our survey 
    
[^99]: 扩散模型作为艺术家：我们正在拉近人与机器之间的鸿沟吗？

    Diffusion Models as Artists: Are we Closing the Gap between Humans and Machines?. (arXiv:2301.11722v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.11722](http://arxiv.org/abs/2301.11722)

    本文研究表明，扩散模型已经在拉近人与机器之间的鸿沟方面取得了进展，但机器生成作品的原创性和可识别性仍然存在差距。

    

    人工智能的一个重要里程碑是开发能够生成和人类无异的绘画作品的算法。在本文中，我们采用 Boutin 等人 2022 年提出的“多样性 vs. 可识别性”评分框架，发现一发即中的扩散模型确实已经开始拉近人类和机器之间的鸿沟。然而，用更细粒度的样本独创性度量，我们发现强化扩散模型的指导有助于提高它们的绘画人性化程度，但它们仍然无法接近人类绘画作品的原创性和可识别性。通过在线心理物理实验收集人类类别诊断特征并将其与从扩散模型中导出的特征进行比较，我们发现人类依赖于更少且更局部的特征。总体而言，我们的研究表明扩散模型在显著提高机器生成绘画作品的质量方面发挥着重要作用，但人与机器之间的差距仍然存在。

    An important milestone for AI is the development of algorithms that can produce drawings that are indistinguishable from those of humans. Here, we adapt the 'diversity vs. recognizability' scoring framework from Boutin et al, 2022 and find that one-shot diffusion models have indeed started to close the gap between humans and machines. However, using a finer-grained measure of the originality of individual samples, we show that strengthening the guidance of diffusion models helps improve the humanness of their drawings, but they still fall short of approximating the originality and recognizability of human drawings. Comparing human category diagnostic features, collected through an online psychophysics experiment, against those derived from diffusion models reveals that humans rely on fewer and more localized features. Overall, our study suggests that diffusion models have significantly helped improve the quality of machine-generated drawings; however, a gap between humans and machines 
    
[^100]: 半结构化物体序列编码器

    Semi-Structured Object Sequence Encoders. (arXiv:2301.01015v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.01015](http://arxiv.org/abs/2301.01015)

    本文提出了一种半结构化物体序列编码器，通过编码键的值的表示并自我关注这些键以完成下游任务来解决长对象序列的问题。

    

    本文探讨了建模半结构化对象序列的任务，特别关注开发这些序列的结构感知输入表示的问题。这种数据的例子包括用户在网站上的活动、机器日志等。由于序列长度的不断增加，这种数据经常被表示为一系列的键值对集合。我们提出了一个两部分方法，首先独立考虑每个键并编码其值的表示，然后自我关注这些具有值感知的键表示以完成下游任务。这样，我们可以操作比现有方法更长的对象序列。我们介绍了两个模块之间的新型共享注意力头结构，并提出了一种创新的训练计划，交替训练两个模块，某些注意力头使用共享权重。我们对我们的方法在多个数据集上进行了实验，发现它在几个基准上取得了显着改进。

    In this paper we explore the task of modeling semi-structured object sequences; in particular, we focus our attention on the problem of developing a structure-aware input representation for such sequences. Examples of such data include user activity on websites, machine logs, and many others. This type of data is often represented as a sequence of sets of key-value pairs over time and can present modeling challenges due to an ever-increasing sequence length. We propose a two-part approach, which first considers each key independently and encodes a representation of its values over time; we then self-attend over these value-aware key representations to accomplish a downstream task. This allows us to operate on longer object sequences than existing methods. We introduce a novel shared-attention-head architecture between the two modules and present an innovative training schedule that interleaves the training of both modules with shared weights for some attention heads. Our experiments on
    
[^101]: 大型语言模型是带有自我验证的推理器

    Large Language Models are reasoners with Self-Verification. (arXiv:2212.09561v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.09561](http://arxiv.org/abs/2212.09561)

    本文提出了一种新的自我验证方法，使用CoT的结论来构建新样本并要求LLM重新预测原始条件，以提高推理准确性。实验证明，LLMs可以对其自己的结论进行自我验证并实现竞争性的推理性能。

    

    当大型语言模型（LLM）通过思维链（CoT）进行复杂推理时，它非常敏感于个别错误。为了解决这个问题，我们必须训练验证器。我们提出一种称为自我验证的新方法，该方法使用CoT的结论作为条件来构建一个新样本，并要求LLM重新预测被掩盖的原始条件。我们基于准确性计算可解释的验证分数。该方法可以在使用少量样本学习时提高多个算术和逻辑推理数据集的准确性。我们已经证明LLM可以对其自己的结论进行可解释的自我验证并实现竞争性的推理性能。全面的实验表明，我们的方法可以帮助多种带有自我验证功能的大型语言模型避免混淆。

    When a large language model (LLM) performs complex reasoning by chain of thought (CoT), it can be highly sensitive to individual mistakes. We have had to train verifiers to address this issue. As we all know, after human inferring a conclusion, they often check it by re-verifying it, which can avoid some mistakes. We propose a new method called self-verification that uses the conclusion of the CoT as a condition to build a new sample and asks the LLM to re-predict the original conditions which be masked. We calculate an explainable verification score based on the accuracy. This method can improve the accuracy of multiple arithmetics and logical reasoning datasets when using few-shot learning. we have demonstrated that LLMs can conduct explainable self-verification of their own conclusions and achieve competitive reasoning performance. Extensive experimentals have demonstrated that our method can help multiple large language models with self-verification can avoid interference from inco
    
[^102]: QEBVerif：神经网络量化误差边界的验证

    QEBVerif: Quantization Error Bound Verification of Neural Networks. (arXiv:2212.02781v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.02781](http://arxiv.org/abs/2212.02781)

    本文提出了一种名为QEBVerif的方法，通过量化误差边界验证神经网络的权重和激活张量，以解决在量化后关键验证属性变得无效的问题。

    

    为了缓解在边缘设备上部署深度神经网络（DNN）的实际限制，量化被广泛认为是一种有前途的技术。通过将DNN的权重和/或激活张量量化为较低位宽的定点数，从而得到量化神经网络（QNN），降低了对计算能力和存储空间的资源要求，尽管已经经验证明它会引入轻微的准确性损失，但是在量化后，DNN的关键验证属性可能变得无效。现有的验证方法专注于单个神经网络（DNN或QNN）或部分量化的量化误差界限。在本文中，我们提出了一种名为QEBVerif的量化误差边界验证方法，其中权重和激活张量都被量化了。QEBVerif由两部分组成，即不同的可达性分析（DRA）和基于混合整数线性规划（MILP）的验证方法。

    To alleviate the practical constraints for deploying deep neural networks (DNNs) on edge devices, quantization is widely regarded as one promising technique. It reduces the resource requirements for computational power and storage space by quantizing the weights and/or activation tensors of a DNN into lower bit-width fixed-point numbers, resulting in quantized neural networks (QNNs). While it has been empirically shown to introduce minor accuracy loss, critical verified properties of a DNN might become invalid once quantized. Existing verification methods focus on either individual neural networks (DNNs or QNNs) or quantization error bound for partial quantization. In this work, we propose a quantization error bound verification method, named QEBVerif, where both weights and activation tensors are quantized. QEBVerif consists of two parts, i.e., a differential reachability analysis (DRA) and a mixed-integer linear programming (MILP) based verification method. DRA performs difference an
    
[^103]: 未知动态马尔可夫跳变线性系统的形式化控制器合成

    Formal Controller Synthesis for Markov Jump Linear Systems with Uncertain Dynamics. (arXiv:2212.00679v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2212.00679](http://arxiv.org/abs/2212.00679)

    本文介绍了一种方法，用于合成马尔可夫跳变线性系统（MJLS）的控制器，以确保满足概率计算树逻辑（PCTL）公式，对于转移概率未知或已知但存在一定的区间的问题提出了解决方案。

    

    在安全关键场景中，对于控制器的自动化合成可以确保系统的正确性至关重要。然而，混合特性和随机或未知的行为使得合成控制器的问题变得具有挑战性。本论文提出了一种方法，用于合成马尔可夫跳变线性系统（MJLS）的控制器，这是一类离散时钟模型的控制器，用于解决这些系统的安全问题，以确保满足概率计算树逻辑（PCTL）公式。一个MJLS由一组有限的随机线性动态和这些动态之间的离散跳变组成，这些跳变由一个马尔可夫决策过程（MDP）来管理。我们考虑了这个MDP的转移概率未知或已知但存在一定的区间。我们的方法基于一个有限状态抽象，捕捉了MJLS的离散（模式跳跃）和连续（随机线性）行为。我们将这个抽象形式化为一个区间MDP（iMDP），然后计算了状态转移区间。

    Automated synthesis of provably correct controllers for cyber-physical systems is crucial for deployment in safety-critical scenarios. However, hybrid features and stochastic or unknown behaviours make this problem challenging. We propose a method for synthesising controllers for Markov jump linear systems (MJLSs), a class of discrete-time models for cyber-physical systems, so that they certifiably satisfy probabilistic computation tree logic (PCTL) formulae. An MJLS consists of a finite set of stochastic linear dynamics and discrete jumps between these dynamics that are governed by a Markov decision process (MDP). We consider the cases where the transition probabilities of this MDP are either known up to an interval or completely unknown. Our approach is based on a finite-state abstraction that captures both the discrete (mode-jumping) and continuous (stochastic linear) behaviour of the MJLS. We formalise this abstraction as an interval MDP (iMDP) for which we compute intervals of tra
    
[^104]: 智能网格生成的现状：综述与前景展望

    What's the Situation with Intelligent Mesh Generation: A Survey and Perspectives. (arXiv:2211.06009v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.06009](http://arxiv.org/abs/2211.06009)

    本文综述了智能网格生成（IMG）现状，概括了113种IMG方法的核心技术、应用范围、代理学习目标、数据类型、目标挑战、优势和局限性，并提出了三个不同的分类法。

    

    智能网格生成（IMG）是一种机器学习生成网格的技术，是一个相对较新和有前途的研究领域。在短暂的历史中，IMG极大地拓展了网格生成技术的通用性和实用性，取得了许多突破，并为网格生成创造了潜在可能性。然而，关于IMG的综述研究还不够。本文致力于系统综述和描述当下IMG的研究现状。我们搜集了113种IMG方法，从多个角度（包括算法的核心技术和应用范围、代理学习目标、数据类型、目标挑战、优势和局限性）进行了深入分析。基于内容提取，我们提出了三个不同的分类法：关键技术、输出网格单元元素、所针对的问题，以进行文献收集和分类整理。

    Intelligent mesh generation (IMG) refers to a technique for generating mesh by machine learning, which is a relatively new and promising research field. Within its short lifespan, IMG has greatly expanded the generalizability and practicality of mesh generation techniques, achieved many breakthroughs and created potential possibilities for mesh generation. However, there is a lack of surveys that focus on IMG methods in recent works. In this paper, we are committed to a systematic and comprehensive survey that describes the contemporary IMG landscape. Focusing on 113 preliminary IMG methods, we conducted an in-depth analysis from multiple perspectives, including the core technique and application scope of the algorithm, agent learning goals, data types, targeting challenges, advantages, and limitations. With the aim of literature collection and classification based on content extraction, we propose three different taxonomies from three views: key techniques, output mesh unit elements, 
    
[^105]: 动态、稀疏和部分观测环境下的信息收集的传感器控制方法

    Sensor Control for Information Gain in Dynamic, Sparse and Partially Observed Environments. (arXiv:2211.01527v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.01527](http://arxiv.org/abs/2211.01527)

    本文提出了一种自主传感器控制方法，用于在动态、稀疏和部分可观测的环境中最大化收集有关实体信息。采用深度先行网络强化学习框架，扩展控制空间并使用混合卷积递归神经层来监测复杂的动态活动模式。

    

    我们提出了一种自主传感器控制方法，用于在部分可观测、动态和稀疏采样的环境下最大化有关该空间中存在的实体的信息收集。我们描述了我们针对无线电频谱监测任务的方法，其中目标是搜索和跟踪环境中的未知动态信号。为此，我们通过（1）改进探索稀疏、非平稳环境的新型信息收益奖励和（2）扩展控制空间并使用混合卷积-递归神经层来监测复杂动态活动模式来扩展了深度先行网络(DAN)强化学习（RL）框架。我们还将这个问题扩展到采样预期的无线电频谱/场有限的情况，并提出了原始RL算法的基于模型的版本，通过从限制中不断提高的模型来微调控制器。

    We present an approach for autonomous sensor control for information gathering under partially observable, dynamic and sparsely sampled environments that maximizes information about entities present in that space. We describe our approach for the task of Radio-Frequency (RF) spectrum monitoring, where the goal is to search for and track unknown, dynamic signals in the environment. To this end, we extend the Deep Anticipatory Network (DAN) Reinforcement Learning (RL) framework by (1) improving exploration in sparse, non-stationary environments using a novel information gain reward, and (2) scaling up the control space and enabling the monitoring of complex, dynamic activity patterns using hybrid convolutional-recurrent neural layers. We also extend this problem to situations in which sampling from the intended RF spectrum/field is limited and propose a model-based version of the original RL algorithm that fine-tunes the controller via a model that is iteratively improved from the limite
    
[^106]: 基于不可导物理仿真渲染的感知感知模型强化学习

    SAM-RL: Sensing-Aware Model-Based Reinforcement Learning via Differentiable Physics-Based Simulation and Rendering. (arXiv:2210.15185v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2210.15185](http://arxiv.org/abs/2210.15185)

    SAM-RL使用不可导物理仿真和渲染，通过比较渲染图像和真实原始图像自动更新模型，并高效产生策略。感知感知的学习管道允许机器人选择信息丰富的视角监控任务过程。 用于完成机器人组装，工具操作和变形物体操作任务。

    

    模型为基础的强化学习（MBRL）具有比基于模型的强化学习更高的样本效率。如何从原始感官输入（如图像）自动有效地开发准确的模型，特别是针对复杂的环境和任务，是限制MBRL在现实世界中广泛应用的挑战性问题。本文提出了一种称为SAM-RL的感知感知模型强化学习系统。利用不可导物理仿真和渲染，SAM-RL通过比较渲染图像和真实原始图像自动更新模型并高效产生策略。通过感知感知学习管道，SAM-RL允许机器人选择一个信息丰富的视角来监控任务过程。我们将我们的框架应用于实际的三个操作任务：机器人装配，工具操纵和可变形物体操纵。我们证明了其有效性。

    Model-based reinforcement learning (MBRL) is recognized with the potential to be significantly more sample-efficient than model-free RL. How an accurate model can be developed automatically and efficiently from raw sensory inputs (such as images), especially for complex environments and tasks, is a challenging problem that hinders the broad application of MBRL in the real world. In this work, we propose a sensing-aware model-based reinforcement learning system called SAM-RL. Leveraging the differentiable physics-based simulation and rendering, SAM-RL automatically updates the model by comparing rendered images with real raw images and produces the policy efficiently. With the sensing-aware learning pipeline, SAM-RL allows a robot to select an informative viewpoint to monitor the task process. We apply our framework to real world experiments for accomplishing three manipulation tasks: robotic assembly, tool manipulation, and deformable object manipulation. We demonstrate the effectivene
    
[^107]: ASDOT：预训练语言模型实现数据到文本的零样本生成

    ASDOT: Any-Shot Data-to-Text Generation with Pretrained Language Models. (arXiv:2210.04325v3 [cs.CL] CROSS LISTED)

    [http://arxiv.org/abs/2210.04325](http://arxiv.org/abs/2210.04325)

    该论文提出了一种名为ASDOT的新方法，可以通过利用任何给定或没有样本进行数据到文本的生成。该方法由两个步骤组成，其使用预训练语言模型进行解决，并可适用于各种不同的场景。

    

    数据到文本的生成在输入数据的领域（如金融 vs 运动）或架构（例如，不同的谓词）方面存在巨大的差异，这使得最近的端到端神经方法需要足够多的训练样本才能学习到消除歧义和描述数据的方法。然而，现实中的数据到文本问题往往面临着各种不足样本的问题：可能只有极少量的训练样本或根本没有训练样本，或需要依赖于不同领域或架构的样例。为了填补这一空白，我们提出了 Any-Shot Data-to-Text (ASDOT)，一种新的方法，通过有效利用任何给定（或没有）样本，可以灵活适用于各种不同的场景。ASDOT由两个步骤组成，数据消歧和句子融合，这两个步骤都可以使用现成的预训练语言模型（LMs）进行解决。在数据消歧阶段，我们使用提示式GPT-3模型来理解输入数据中可能存在的模糊三元组，然后将其与可用样本中的信息融合以生成文本。

    Data-to-text generation is challenging due to the great variety of the input data in terms of domains (e.g., finance vs sports) or schemata (e.g., diverse predicates). Recent end-to-end neural methods thus require substantial training examples to learn to disambiguate and describe the data. Yet, real-world data-to-text problems often suffer from various data-scarce issues: one may have access to only a handful of or no training examples, and/or have to rely on examples in a different domain or schema. To fill this gap, we propose Any-Shot Data-to-Text (ASDOT), a new approach flexibly applicable to diverse settings by making efficient use of any given (or no) examples. ASDOT consists of two steps, data disambiguation and sentence fusion, both of which are amenable to be solved with off-the-shelf pretrained language models (LMs) with optional finetuning. In the data disambiguation stage, we employ the prompted GPT-3 model to understand possibly ambiguous triples from the input data and c
    
[^108]: 分层对抗逆强化学习

    Hierarchical Adversarial Inverse Reinforcement Learning. (arXiv:2210.01969v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.01969](http://arxiv.org/abs/2210.01969)

    本文提出了一种分层对抗逆强化学习算法，能够在复杂任务中学习到具有层次结构的最优策略，比现有的方法更加有效。

    

    模仿学习（IL）一般用于从演示中恢复专家策略。然而，对于高度复杂的、长时程任务，恢复单一整体策略是困难的，而专家策略通常包含子任务层次结构。因此，研究者开发了分层模仿学习（HIL）方法，通过在选项框架中显式地建模任务中的活动结构来学习分层策略。现有的HIL方法要么忽视了子任务结构与学习策略之间的因果关系，要么无法同时在分层框架中学习高级别和低级别策略，导致亚最优。本文提出了一种新的HIL算法——分层对抗逆强化学习（H-AIRL），它在最新的IL算法AIRL上扩展了一步选项框架，重新定义了AIRL目标。

    Imitation Learning (IL) has been proposed to recover the expert policy from demonstrations. However, it would be difficult to learn a single monolithic policy for highly-complex long-horizon tasks of which the expert policy usually contains subtask hierarchies. Therefore, Hierarchical Imitation Learning (HIL) has been developed to learn a hierarchical policy from expert demonstrations through explicitly modelling the activity structure in a task with the option framework. Existing HIL methods either overlook the causal relationship between the subtask structure and the learned policy, or fail to learn the high-level and low-level policy in the hierarchical framework in conjuncture, which leads to suboptimality. In this work, we propose a novel HIL algorithm -Hierarchical Adversarial Inverse Reinforcement Learning (H-AIRL), which extends a state-of-the-art (SOTA) IL algorithm -- AIRL, with the one-step option framework. Specifically, we redefine the AIRL objectives on the extended sta
    
[^109]: L2XGNN：学习解释图神经网络

    L2XGNN: Learning to Explain Graph Neural Networks. (arXiv:2209.14402v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.14402](http://arxiv.org/abs/2209.14402)

    L2XGNN提出了一个框架来解释图神经网络，通过选择解释子图（模体）实现忠实的解释。该框架能够识别负责预测图属性的模体，并实现与基线方法相同的分类精度。

    

    图神经网络（GNNs）是一类流行的机器学习模型。在学习解释（L2X）范式的启发下，我们提出了L2XGNN，这是一个可解释的GNN框架，通过设计提供忠实的解释。L2XGNN学习一种机制，用于选择解释子图（模体），这些子图仅用于GNN的信息传递操作中。对模体施加这样的限制通常会导致更易解释和更有效的解释。在几种数据集上的实验表明，L2XGNN实现了与基线方法相同的分类精度，同时确保仅使用提供的解释来进行预测。此外，我们还表明L2XGNN能够识别负责预测图属性的模体。

    Graph Neural Networks (GNNs) are a popular class of machine learning models. Inspired by the learning to explain (L2X) paradigm, we propose L2XGNN, a framework for explainable GNNs which provides faithful explanations by design. L2XGNN learns a mechanism for selecting explanatory subgraphs (motifs) which are exclusively used in the GNNs message-passing operations. L2XGNN is able to select, for each input graph, a subgraph with specific properties such as being sparse and connected. Imposing such constraints on the motifs often leads to more interpretable and effective explanations. Experiments on several datasets suggest that L2XGNN achieves the same classification accuracy as baseline methods using the entire input graph while ensuring that only the provided explanations are used to make predictions. Moreover, we show that L2XGNN is able to identify motifs responsible for the graph's properties it is intended to predict.
    
[^110]: 可解释图神经网络的综述：分类和评估指标

    A Survey of Explainable Graph Neural Networks: Taxonomy and Evaluation Metrics. (arXiv:2207.12599v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2207.12599](http://arxiv.org/abs/2207.12599)

    本综述全面评述了为图神经网络开发的可解释技术，着重关注可解释的图神经网络并根据使用的可解释方法进行分类。同时，提供了GNN解释的常见性能指标，并指出了几个未来的研究方向。

    

    图神经网络已经在图数据的预测性能上取得了显著的提高。与此同时，这些模型所做的预测往往难以解释。因此，许多工作都致力于从GNNExplainer、XGNN和PGExplainer等方面解释这些模型的预测机制。虽然这些工作提供了系统性的解释GNN的框架，但对于可解释图神经网络的全面评述尚不可用。在本综述中，我们提供了对为GNN开发的可解释技术的全面评述。我们重点关注可解释的图神经网络，并根据使用可解释方法进行分类。我们进一步提供了GNN解释的常见性能指标，并指出几个未来的研究方向。

    Graph neural networks (GNNs) have demonstrated a significant boost in prediction performance on graph data. At the same time, the predictions made by these models are often hard to interpret. In that regard, many efforts have been made to explain the prediction mechanisms of these models from perspectives such as GNNExplainer, XGNN and PGExplainer. Although such works present systematic frameworks to interpret GNNs, a holistic review for explainable GNNs is unavailable. In this survey, we present a comprehensive review of explainability techniques developed for GNNs. We focus on explainable graph neural networks and categorize them based on the use of explainable methods. We further provide the common performance metrics for GNNs explanations and point out several future research directions.
    
[^111]: 潜在组合游戏设计

    Latent Combinational Game Design. (arXiv:2206.14203v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.14203](http://arxiv.org/abs/2206.14203)

    本文提出了一种名为潜在组合游戏设计的方法，使用深度生成潜变量模型将给定的一组游戏混合到所需组合中以生成可玩游戏，并且通过这种方法能够控制每个游戏在混合游戏中的比例。

    

    我们提出了一种名为“潜在组合游戏设计”的方法，使用深度生成潜变量模型将给定的一组游戏混合到所需组合中以生成可玩游戏。我们使用高斯混合变分自编码器 (GMVAEs) 对 VAE 潜在空间进行建模，通过监督式训练，每个组件对应一个游戏的水平，并使我们能够将混合游戏定义为这些组件的线性组合，这使得能够生成新游戏，并控制混合中每个游戏的比例。我们还使用有条件变分自编码器扩展以前的混合工作，并与 GMVAE 进行比较，同时引入了混合条件 GMVAE (CGMVAE) 结构，使我们能够生成整个混合水平和布局。结果表明，上述方法可以生成按指定组合混合的可玩游戏。我们使用平台游戏和地下城类游戏来展示我们方法的可行性和灵活性。

    We present latent combinational game design -- an approach for generating playable games that blend a given set of games in a desired combination using deep generative latent variable models. We use Gaussian Mixture Variational Autoencoders (GMVAEs) which model the VAE latent space via a mixture of Gaussian components. Through supervised training, each component encodes levels from one game and lets us define blended games as linear combinations of these components. This enables generating new games that blend the input games and controlling the relative proportions of each game in the blend. We also extend prior blending work using conditional VAEs and compare against the GMVAE and additionally introduce a hybrid conditional GMVAE (CGMVAE) architecture which lets us generate whole blended levels and layouts. Results show that the above approaches can generate playable games that blend the input games in specified combinations. We use both platformers and dungeon-based games to demonst
    
[^112]: 对深度神经网络的一种新型物理攻击：敌对变焦镜头

    Adversarial Zoom Lens: A Novel Physical-World Attack to DNNs. (arXiv:2206.12251v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2206.12251](http://arxiv.org/abs/2206.12251)

    本文提出了一种名为AdvZL的新型物理敌对攻击技术，利用敌对变焦镜头对物理世界的图像进行放大和缩小，从而欺骗DNNs，同时不改变目标对象的特征。在数字和物理环境中的实验结果表明，该方法的有效性，是唯一一种不添加物理敌对扰动攻击DNNs的敌对攻击技术。

    

    尽管人们知道深度神经网络（DNNs）很脆弱，但还没有人研究过在物理世界中对图像进行放大或缩小对DNNs性能的影响。本文提出了一种名为Adversarial Zoom Lens（AdvZL）的新型物理敌对攻击技术，该技术使用敌对变焦镜头对物理世界中的图像进行放大和缩小，从而欺骗DNNs，同时不改变目标对象的特征。该方法是迄今为止唯一一种不添加物理敌对扰动攻击DNNs的敌对攻击技术。在数字环境中，我们构建了一个基于AdvZL的数据集，以验证等比例放大图像对DNNs的敌对性。在物理环境中，我们用变焦镜头对目标对象进行缩放，并生成敌对样本。实验结果证明了AdvZL在数字环境和物理环境中的有效性。我们进一步分析了所提出的数据集的敌对性质。

    Although deep neural networks (DNNs) are known to be fragile, no one has studied the effects of zooming-in and zooming-out of images in the physical world on DNNs performance. In this paper, we demonstrate a novel physical adversarial attack technique called Adversarial Zoom Lens (AdvZL), which uses a zoom lens to zoom in and out of pictures of the physical world, fooling DNNs without changing the characteristics of the target object. The proposed method is so far the only adversarial attack technique that does not add physical adversarial perturbation attack DNNs. In a digital environment, we construct a data set based on AdvZL to verify the antagonism of equal-scale enlarged images to DNNs. In the physical environment, we manipulate the zoom lens to zoom in and out of the target object, and generate adversarial samples. The experimental results demonstrate the effectiveness of AdvZL in both digital and physical environments. We further analyze the antagonism of the proposed data set 
    
[^113]: 对DNNs的健壮和隐蔽的物理攻击: 对抗性激光点攻击

    Adversarial Laser Spot: Robust and Covert Physical-World Attack to DNNs. (arXiv:2206.01034v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.01034](http://arxiv.org/abs/2206.01034)

    这篇论文提出了一种名为对抗性激光点（AdvLS）的光学物理攻击，通过遗传算法优化激光点的物理参数进行物理攻击，实现了对DNNs的健壮和隐蔽的物理攻击。

    

    大多数现有的深度神经网络（DNN）都容易受到微小噪声的干扰。然而，关于使用照明设备进行物理攻击的研究很少。基于光的物理攻击具有出色的隐蔽性，这给许多基于视觉的应用（如自动驾驶）带来了巨大的安全风险。因此，我们提出了一种名为对抗性激光点（AdvLS）的光学物理攻击，通过遗传算法优化激光点的物理参数进行物理攻击。它利用低成本的激光设备实现了强健和隐蔽的物理攻击。据我们所知，AdvLS是第一个在白天进行物理攻击的基于光的攻击方式。在数字和物理环境中进行了大量的实验，结果表明AdvLS具有出色的健壮性和隐蔽性。此外，通过对实验数据的深入分析，我们发现AdvLS生成的对抗性扰动具有优秀的对抗攻击能力。

    Most existing deep neural networks (DNNs) are easily disturbed by slight noise. However, there are few researches on physical attacks by deploying lighting equipment. The light-based physical attacks has excellent covertness, which brings great security risks to many vision-based applications (such as self-driving). Therefore, we propose a light-based physical attack, called adversarial laser spot (AdvLS), which optimizes the physical parameters of laser spots through genetic algorithm to perform physical attacks. It realizes robust and covert physical attack by using low-cost laser equipment. As far as we know, AdvLS is the first light-based physical attack that perform physical attacks in the daytime. A large number of experiments in the digital and physical environments show that AdvLS has excellent robustness and covertness. In addition, through in-depth analysis of the experimental data, we find that the adversarial perturbations generated by AdvLS have superior adversarial attack
    
[^114]: SVM指数级收敛速度的案例

    A Case of Exponential Convergence Rates for SVM. (arXiv:2205.10055v2 [stat.ML] UPDATED)

    [http://arxiv.org/abs/2205.10055](http://arxiv.org/abs/2205.10055)

    本文研究了SVM的指数级收敛速度，提出了一种简单的方法来获得快速收敛速度，并在没有假设硬Tsybakov边际条件的情况下展示了SVM的指数级收敛速度现象。

    

    分类问题通常是介绍机器学习课程中描述的第一个问题。历史上，瓦普尼克-切尔沃年科理论提供了分类的泛化保证。然而，这些保证基于难以处理的算法，这导致了分类中代理方法的理论。代理方法提供的保证基于校准不等式，已被证明在某些边际条件下非常次优，不能捕捉到指数级收敛现象。这些"超"快速率现在已经对于光滑的代理得到了很好的理解，但对于与著名的支持向量机相关的非光滑损失（如铰链损失），画面仍然模糊不清。本文介绍了一种简单的机制来获得快速收敛速度，并研究其用于SVM的情况。特别地，我们展示了SVM可以展现出指数级的收敛速度，即使没有假设硬Tsybakov边际条件。

    Classification is often the first problem described in introductory machine learning classes. Generalization guarantees of classification have historically been offered by Vapnik-Chervonenkis theory. Yet those guarantees are based on intractable algorithms, which has led to the theory of surrogate methods in classification. Guarantees offered by surrogate methods are based on calibration inequalities, which have been shown to be highly sub-optimal under some margin conditions, failing short to capture exponential convergence phenomena. Those "super" fast rates are becoming to be well understood for smooth surrogates, but the picture remains blurry for non-smooth losses such as the hinge loss, associated with the renowned support vector machines. In this paper, we present a simple mechanism to obtain fast convergence rates and we investigate its usage for SVM. In particular, we show that SVM can exhibit exponential convergence rates even without assuming the hard Tsybakov margin conditi
    
[^115]: PFGE: 简洁快速几何集成深度神经网络

    PFGE: Parsimonious Fast Geometric Ensembling of DNNs. (arXiv:2202.06658v8 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.06658](http://arxiv.org/abs/2202.06658)

    本论文提出了一种简洁快速几何集成深度神经网络（PFGE）的方法，该方法通过连续的随机权重平均过程生成一个轻量级的高性能DNN集合，相比之前的方法，内存效率提高了5倍，而不会影响泛化性能。

    

    集成方法通常用于增强机器学习模型的泛化性能，但是在深度学习系统中，由于训练深度神经网络（DNNs）的集成需要高计算开销，因此集成方法面临挑战。最近的进展，如快速几何集成（FGE）和快照集成，通过在与单个模型相同的时间内训练模型集成来解决了这个问题。然而，与单一模型的基于方法相比，这些技术仍需要额外的内存进行测试时间推断。在本文中，我们提出了一种称为简洁FGE（PFGE）的新方法，它使用由连续的随机权重平均过程生成的高性能DNN的轻量级集成。我们在各种现代DNN架构的CIFAR-{10,100}和ImageNet数据集上的实验结果表明，PFGE实现了与以前方法相比5倍的内存效率，而不会影响泛化性能。

    Ensemble methods are commonly used to enhance the generalization performance of machine learning models. However, they present a challenge in deep learning systems due to the high computational overhead required to train an ensemble of deep neural networks (DNNs). Recent advancements such as fast geometric ensembling (FGE) and snapshot ensembles have addressed this issue by training model ensembles in the same time as a single model. Nonetheless, these techniques still require additional memory for test-time inference compared to single-model-based methods. In this paper, we propose a new method called parsimonious FGE (PFGE), which employs a lightweight ensemble of higher-performing DNNs generated through successive stochastic weight averaging procedures. Our experimental results on CIFAR-{10,100} and ImageNet datasets across various modern DNN architectures demonstrate that PFGE achieves 5x memory efficiency compared to previous methods, without compromising on generalization perform
    
[^116]: 慢神经动力学对增量学习的后果

    Consequences of Slow Neural Dynamics for Incremental Learning. (arXiv:2012.06694v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2012.06694](http://arxiv.org/abs/2012.06694)

    本文研究了内部状态的时间平滑性如何影响神经网络的学习和表示，发现使用时间平滑的数据进行训练时，具有“慢”神经网络的网络比前馈网络更有效地学习分类，同时具有线性循环和多时间尺度门控机制的网络能够更好地表示输入的时间结构，具有更强大的泛化能力。

    

    在人脑中，内部状态通常会随时间相互关联（由于局部循环和其他内在电路特性），并由突然转换断断续续地呈现。乍一看，内部状态的时间平滑性会对学习输入输出映射（例如图像的类别标签）产生问题，因为输入的内部表示将包含当前输入和先前输入的混合。然而，当使用自然数据（例如电影）进行训练时，输入也存在时间自相关性。当训练数据也是时间平滑的时，内部状态的时间平滑性如何影响学习的效率？它如何影响所学的表示类型？我们发现，当使用时间平滑的数据进行训练时，具有“慢”神经网络（配备线性循环和门控机制）的网络比前馈网络更有效地学习了分类。此外，具有线性循环和多时间尺度门控机制的网络学会了表示输入的时间结构，从而实现了更强大的泛化能力。

    In the human brain, internal states are often correlated over time (due to local recurrence and other intrinsic circuit properties), punctuated by abrupt transitions. At first glance, temporal smoothness of internal states presents a problem for learning input-output mappings (e.g. category labels for images), because the internal representation of the input will contain a mixture of current input and prior inputs. However, when training with naturalistic data (e.g. movies) there is also temporal autocorrelation in the input. How does the temporal "smoothness" of internal states affect the efficiency of learning when the training data are also temporally smooth? How does it affect the kinds of representations that are learned? We found that, when trained with temporally smooth data, "slow" neural networks (equipped with linear recurrence and gating mechanisms) learned to categorize more efficiently than feedforward networks. Furthermore, networks with linear recurrence and multi-timesc
    

