# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Hierarchical Randomized Smoothing.](http://arxiv.org/abs/2310.16221) | 分层随机平滑是一种在复杂数据上进行鲁棒性认证的解决方案，通过只在一个对象的子集上添加随机噪声，以更有针对性的方式提供了更强的鲁棒性保证和高准确性。 |
| [^2] | [Predicting Transcription Factor Binding Sites using Transformer based Capsule Network.](http://arxiv.org/abs/2310.15202) | 本文提出了一种基于Transformer的胶囊网络DNABERT-Cap，用于预测转录因子结合位点。该模型在预测中利用了双向编码器、胶囊层、卷积和双向长短时记忆层的特征，并通过对这些特征的联合优化构建了转录因子结合位点的预测器。 |
| [^3] | [Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis.](http://arxiv.org/abs/2310.10477) | 该论文介绍了一种基于错误分析的对齐策略，通过暴露大型语言模型的错误输出并进行评估，以理解内部原因。通过这种方法，有毒回应可以转化为模型对齐的指导调谐语料，从而提高模型的安全性并训练其进行自我批评。 |
| [^4] | [Can We Edit Multimodal Large Language Models?.](http://arxiv.org/abs/2310.08475) | 本文提出了编辑多模式大型语言模型（MLLMs）的挑战，并构建了一个新的基准用于评估和比较不同编辑方法的效果。实验结果表明，编辑多模式LLMs仍然存在困难，但这项工作为NLP社区提供了宝贵的见解。 |
| [^5] | [Attributing Learned Concepts in Neural Networks to Training Data.](http://arxiv.org/abs/2310.03149) | 通过将数据归因方法与概念探测方法相结合，研究了神经网络中学习到的概念与训练数据的关系，并发现概念的位置和稀疏性并不完全依赖于少量特定示例。 |
| [^6] | [Mini-BEHAVIOR: A Procedurally Generated Benchmark for Long-horizon Decision-Making in Embodied AI.](http://arxiv.org/abs/2310.01824) | Mini-BEHAVIOR是一个面向具身人工智能的基准，旨在挑战智能体解决类似于日常挑战的复杂活动，并通过过程生成实现了无限的任务变化和对开放式学习的支持。 |
| [^7] | [AskIt: Unified Programming Interface for Programming with Large Language Models.](http://arxiv.org/abs/2308.15645) | AskIt是一个专为大型语言模型设计的领域特定语言，通过简化LLM的集成和提供统一的接口，解决了LLM嵌入应用程序和代码生成的挑战。 |
| [^8] | [Serving MoE Models on Resource-constrained Edge Devices via Dynamic Expert Swapping.](http://arxiv.org/abs/2308.15030) | 本文提出了一种在资源受限的边缘设备上通过动态专家交换为MoE模型提供服务的推理框架，该框架通过分析MoE模型的行为模式，引入了新的数据结构来减少资源消耗，并通过性能分析优化参数配置。 |
| [^9] | [Traffic Flow Optimisation for Lifelong Multi-Agent Path Finding.](http://arxiv.org/abs/2308.11234) | 本文提出了一种新的终身多智能体路径规划方法，通过引导智能体避开拥堵路径来优化交通流量，显著提高解决方案质量和总体吞吐量。 |
| [^10] | [Developmental Bootstrapping of AIs.](http://arxiv.org/abs/2308.04586) | 传统的符号AI方法和深度学习AI方法无法满足创建强大和可信赖的AI的挑战，然而，发展脱靴法通过模仿人类儿童的能力发展过程，为创建稳健可靠的AI提供了希望。 |
| [^11] | [EnrichEvent: Enriching Social Data with Contextual Information for Emerging Event Extraction.](http://arxiv.org/abs/2307.16082) | 本文提出了一个利用词汇、语义和上下文表示的框架，旨在解决现有事件检测方法在识别新兴社交事件方面的局限性，并提供了对社交数据进行丰富的上下文化处理的方法。 |
| [^12] | [Investigating the Robustness of Sequential Recommender Systems Against Training Data Perturbations: an Empirical Study.](http://arxiv.org/abs/2307.13165) | 本研究通过对多个数据集进行评估发现，顺序推荐系统中删除序列末尾的项目显著降低了性能，而删除序列开头或中间的项目则没有明显影响。这一发现强调了考虑训练数据中扰动项目位置的重要性，并能指导更具鲁棒性的顺序推荐系统的设计。 |
| [^13] | [PreDiff: Precipitation Nowcasting with Latent Diffusion Models.](http://arxiv.org/abs/2307.10422) | 本论文提出了PreDiff方法，使用条件隐式扩散模型进行降水近期预测。同时，引入显式知识控制机制以满足特定领域的物理约束。 |
| [^14] | [Safe Model-Based Multi-Agent Mean-Field Reinforcement Learning.](http://arxiv.org/abs/2306.17052) | 本文提出了Safe-$\text{M}^3$-UCRL算法，通过使用模型中的认知不确定性和对数障碍方法，实现了在未知转移动态情况下达到安全策略的优化，成功解决了大规模多智能体协调问题。 |
| [^15] | [Integrating Geometric Control into Text-to-Image Diffusion Models for High-Quality Detection Data Generation via Text Prompt.](http://arxiv.org/abs/2306.04607) | GeoDiffusion使用文本提示将各种几何条件转化为图像，生成高质量的检测数据，性能优于现有方法。 |
| [^16] | [Active Sparse Conversations for Improved Audio-Visual Embodied Navigation.](http://arxiv.org/abs/2306.04047) | 本文提出了CAVEN - 一种具有对话功能的音频视觉导航代理，能够向人类/神谕提出导航问题并处理神谕回答以协助自主导航。该系统基于多模态分层强化学习方法，并使用三个低级策略进行引导。 |
| [^17] | [Russo-Ukrainian War: Prediction and explanation of Twitter suspension.](http://arxiv.org/abs/2306.03502) | 本研究分析了Twitter封禁机制，揭示了存在的政策违规、宣传、垃圾邮件等问题，并发现拥有更多粉丝的账户更可能被封禁。这些发现可以让Twitter和其他社交网络改进其内容过滤机制。 |
| [^18] | [What indeed can GPT models do in chemistry? A comprehensive benchmark on eight tasks.](http://arxiv.org/abs/2305.18365) | 本文建立了包括 8 个实际化学任务的综合基准测试，有力地证明了 LLM 在实际化学中的能力。 |
| [^19] | [Protein Complex Invariant Embedding with Cross-Gate MLP is A One-Shot Antibody Designer.](http://arxiv.org/abs/2305.09480) | 本文提出了一种深度生成模型，可以一次性地共同设计抗体CDR的1D序列和3D结构，解决几何建模和低效推断的问题。 |
| [^20] | [A Survey on Out-of-Distribution Detection in NLP.](http://arxiv.org/abs/2305.03236) | 这篇论文首次综述了最新的OOD检测方法在自然语言处理中的应用。根据算法使用的数据，将方法分成三类，并介绍了相关数据集、应用和度量方法。 |
| [^21] | [Space reduction techniques for the $3$-wise Kemeny problem.](http://arxiv.org/abs/2305.00140) | 本文研究了三元Kemeny问题，提出了空间缩减技术，可以在多项式时间内高效确定备选方案的相对顺序，实现了计算优化。 |
| [^22] | [Heterogeneous-Agent Reinforcement Learning.](http://arxiv.org/abs/2304.09870) | 提出了一种异构智能体强化学习（HARL）算法，解决了协作多智能体强化学习中的参数共享限制，同时通过引入多智能体优势分解引理和序列更新方案，建立了异构智能体信任区域学习（HATRL）算法及其易处理的逼近方式 HATRPO 和 HAPPO。此外，发现了一种名为异构智能体镜像学习（HAML）的新型框架，加强了对HATRPO和HAPPO的理论保证。 |
| [^23] | [Identification of Negative Transfers in Multitask Learning Using Surrogate Models.](http://arxiv.org/abs/2303.14582) | 本文提出了一种通过代理建模来解决多任务学习中负迁移问题的方法，能够识别哪些源任务的子集会对目标任务有帮助。 |
| [^24] | [Roots and Requirements for Collaborative AI.](http://arxiv.org/abs/2303.12040) | 论文探讨了AI协同合作的历史和要求，是协同AI研究的动机和背景。 |
| [^25] | [EvHandPose: Event-based 3D Hand Pose Estimation with Sparse Supervision.](http://arxiv.org/abs/2303.02862) | 本文提出了EvHandPose，该方法利用稀疏监督下的新型手部流表示进行基于事件的3D手势姿势估计，解决了运动模糊的问题，并通过构建大规模真实世界数据集来填补真实合成领域间的差距。 |
| [^26] | [A Pathway Towards Responsible AI Generated Content.](http://arxiv.org/abs/2303.01325) | 本文探讨了AI生成内容的合理使用所面临的风险，包括隐私、偏见、毒性、错误信息和知识产权等，并提供有希望的解决方向。 |
| [^27] | [Editing Language Model-based Knowledge Graph Embeddings.](http://arxiv.org/abs/2301.10405) | 本文提出了一种新的任务——编辑基于语言模型的知识图谱嵌入，旨在实现对KG嵌入的数据高效和快速更新。针对这一任务，提出了一个简单而强大的方案——KGEditor，可以更好地更新特定事实而不影响其余部分的性能。 |
| [^28] | [Generalisation Through Negation and Predicate Invention.](http://arxiv.org/abs/2301.07629) | 这篇论文介绍了一种结合了否定和谓词创造的归纳逻辑编程方法，通过学习仅具有全量化身体变量的规则来改善泛化能力，并实现在NOPI中。实验结果表明，这种方法可以提高预测准确性和学习效率。 |
| [^29] | [gRoMA: a Tool for Measuring Deep Neural Networks Global Robustness.](http://arxiv.org/abs/2301.02288) | gRoMA是一种衡量DNN全局鲁棒性的创新工具，采用概率验证方法评估特定输出类别遭受到对抗性输入的概率。该工具可运行于预训练的黑盒分类模型上，并对整个模型和每个输入样本产生鲁棒性测量结果。 |
| [^30] | [Improving Speech Emotion Recognition with Unsupervised Speaking Style Transfer.](http://arxiv.org/abs/2211.08843) | 本文介绍了EmoAug，一种通过无监督说话风格转换来提升语音情感识别的模型。EmoAug利用语义编码器和语调编码器表示语言和非语言信息，并通过无监督方式重建语音信号。训练完成后，EmoAug通过引入不同风格丰富了情感语音的表达，并解决了数据不平衡问题。 |
| [^31] | [Augmentation-Aware Self-Supervision for Data-Efficient GAN Training.](http://arxiv.org/abs/2205.15677) | 本文提出一种增强感知的自监督判别器用于对生成数据及其增强参数的预测，从而提高判别器的表现和生成模型的性能，实现了数据有效的 GAN 训练。 |

# 详细

[^1]: 分层随机平滑

    Hierarchical Randomized Smoothing. (arXiv:2310.16221v1 [cs.LG])

    [http://arxiv.org/abs/2310.16221](http://arxiv.org/abs/2310.16221)

    分层随机平滑是一种在复杂数据上进行鲁棒性认证的解决方案，通过只在一个对象的子集上添加随机噪声，以更有针对性的方式提供了更强的鲁棒性保证和高准确性。

    

    真实世界的数据是复杂的，通常由可分解为多个实体的对象组成（例如，将图像分解为像素，将图形分解为相互连接的节点）。随机平滑是一种强大的框架，可以使模型在其输入的微小变化上具有证明的鲁棒性-通过在分类之前随机添加噪声来保证多数投票的鲁棒性。然而，当对手不是任意干扰整个对象（例如图像），而是对象的某个实体的子集（例如像素）时，通过随机平滑对这种复杂数据进行鲁棒性认证是具有挑战性的。作为解决方案，我们引入了分层随机平滑：我们通过仅在随机选择的实体子集上添加随机噪声来部分平滑对象。通过以比现有方法更有针对性的方式添加噪声，我们获得更强的鲁棒性保证，同时保持高准确性。我们使用不同的噪声分布初始化分层平滑，得到了新的鲁棒性保证。

    Real-world data is complex and often consists of objects that can be decomposed into multiple entities (e.g. images into pixels, graphs into interconnected nodes). Randomized smoothing is a powerful framework for making models provably robust against small changes to their inputs - by guaranteeing robustness of the majority vote when randomly adding noise before classification. Yet, certifying robustness on such complex data via randomized smoothing is challenging when adversaries do not arbitrarily perturb entire objects (e.g. images) but only a subset of their entities (e.g. pixels). As a solution, we introduce hierarchical randomized smoothing: We partially smooth objects by adding random noise only on a randomly selected subset of their entities. By adding noise in a more targeted manner than existing methods we obtain stronger robustness guarantees while maintaining high accuracy. We initialize hierarchical smoothing using different noising distributions, yielding novel robustness
    
[^2]: 基于Transformer的胶囊网络预测转录因子结合位点

    Predicting Transcription Factor Binding Sites using Transformer based Capsule Network. (arXiv:2310.15202v1 [q-bio.GN])

    [http://arxiv.org/abs/2310.15202](http://arxiv.org/abs/2310.15202)

    本文提出了一种基于Transformer的胶囊网络DNABERT-Cap，用于预测转录因子结合位点。该模型在预测中利用了双向编码器、胶囊层、卷积和双向长短时记忆层的特征，并通过对这些特征的联合优化构建了转录因子结合位点的预测器。

    

    预测转录因子的结合位点对于理解它们如何调控基因表达以及如何通过治疗手段进行调节非常重要。尽管在过去几年里已经有相当多的工作针对这个问题进行了研究，但仍然有改进的空间。在这方面，本文提出了一种基于Transformer的胶囊网络DNABERT-Cap，用于利用ChIP-seq数据集挖掘预测转录因子结合位点。DNABERT-Cap是一个双向编码器，经过大量基因组DNA序列的预训练，并通过胶囊层进行最终预测。所提出的模型通过对包含双向编码器、胶囊层、卷积和双向长短时记忆层特征的联合优化，构建了转录因子结合位点的预测器。为了评估所提方法的效率，我们使用了五个细胞系的基准ChIP-seq数据集，包括A54。

    Prediction of binding sites for transcription factors is important to understand how they regulate gene expression and how this regulation can be modulated for therapeutic purposes. Although in the past few years there are significant works addressing this issue, there is still space for improvement. In this regard, a transformer based capsule network viz. DNABERT-Cap is proposed in this work to predict transcription factor binding sites mining ChIP-seq datasets. DNABERT-Cap is a bidirectional encoder pre-trained with large number of genomic DNA sequences, empowered with a capsule layer responsible for the final prediction. The proposed model builds a predictor for transcription factor binding sites using the joint optimisation of features encompassing both bidirectional encoder and capsule layer, along with convolutional and bidirectional long-short term memory layers. To evaluate the efficiency of the proposed approach, we use a benchmark ChIP-seq datasets of five cell lines viz. A54
    
[^3]: 从挫折中获得智慧：通过错误分析对齐大型语言模型

    Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis. (arXiv:2310.10477v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.10477](http://arxiv.org/abs/2310.10477)

    该论文介绍了一种基于错误分析的对齐策略，通过暴露大型语言模型的错误输出并进行评估，以理解内部原因。通过这种方法，有毒回应可以转化为模型对齐的指导调谐语料，从而提高模型的安全性并训练其进行自我批评。

    

    大型语言模型（LLMs）的快速发展既带来了机遇，也带来了挑战，特别是在意外生成有害和有毒回应方面。传统的对齐方法致力于引导LLMs朝着期望的性能发展并保护它们免受恶意内容的侵害，而本研究提出了一种基于错误分析的全新对齐策略，通过有意暴露LLMs的缺陷输出并进行深入评估，以完全理解内部原因，通过自然语言分析。因此，有毒回应可以转化为模型对齐的指导调谐语料，LLMs不仅可以避免生成有缺陷的回应，还可以训练其进行自我批评，发挥其辨别有毒内容的内在能力。实验结果表明，所提出的方法在安全指令遵循方面优于传统的对齐技术，同时还保持了卓越的效率。

    The rapid advancement of large language models (LLMs) presents both opportunities and challenges, particularly concerning unintentional generation of harmful and toxic responses. While the traditional alignment methods strive to steer LLMs towards desired performance and shield them from malicious content, this study proposes a novel alignment strategy rooted in mistake analysis by exposing LLMs to flawed outputs purposefully and then conducting a thorough assessment to fully comprehend internal reasons via natural language analysis. Thus, toxic responses can be transformed into instruction tuning corpus for model alignment, and LLMs can not only be deterred from generating flawed responses but also trained to self-criticize, leveraging its innate ability to discriminate toxic content. Experimental results demonstrate that the proposed method outperforms conventional alignment techniques for safety instruction following, while maintaining superior efficiency.
    
[^4]: 我们能编辑多模式大型语言模型吗？

    Can We Edit Multimodal Large Language Models?. (arXiv:2310.08475v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.08475](http://arxiv.org/abs/2310.08475)

    本文提出了编辑多模式大型语言模型（MLLMs）的挑战，并构建了一个新的基准用于评估和比较不同编辑方法的效果。实验结果表明，编辑多模式LLMs仍然存在困难，但这项工作为NLP社区提供了宝贵的见解。

    

    本文关注编辑多模式大型语言模型（MLLMs）。与编辑单模式LLMs相比，多模式模型的编辑更具挑战性，需要更高级别的审查和慎重考虑。为了促进这一领域的研究，我们构建了一个新的基准，称为MMEdit，用于编辑多模式LLMs，并建立了一套创新的度量标准进行评估。我们进行了包括各种模型编辑基线的综合实验，并分析了编辑多模式LLMs的不同组件的影响。根据经验，我们发现之前的基线在某种程度上可以实现编辑多模式LLMs，但效果仍然不理想，表明这个任务可能存在的困难。我们希望我们的工作能为NLP社区提供见解。代码和数据集可在https://github.com/zjunlp/EasyEdit获取。

    In this paper, we focus on editing Multimodal Large Language Models (MLLMs). Compared to editing single-modal LLMs, multimodal model editing is more challenging, which demands a higher level of scrutiny and careful consideration in the editing process. To facilitate research in this area, we construct a new benchmark, dubbed MMEdit, for editing multimodal LLMs and establishing a suite of innovative metrics for evaluation. We conduct comprehensive experiments involving various model editing baselines and analyze the impact of editing different components for multimodal LLMs. Empirically, we notice that previous baselines can implement editing multimodal LLMs to some extent, but the effect is still barely satisfactory, indicating the potential difficulty of this task. We hope that our work can provide the NLP community with insights. Code and dataset are available in https://github.com/zjunlp/EasyEdit.
    
[^5]: 将神经网络中学习到的概念归因于训练数据

    Attributing Learned Concepts in Neural Networks to Training Data. (arXiv:2310.03149v1 [cs.LG])

    [http://arxiv.org/abs/2310.03149](http://arxiv.org/abs/2310.03149)

    通过将数据归因方法与概念探测方法相结合，研究了神经网络中学习到的概念与训练数据的关系，并发现概念的位置和稀疏性并不完全依赖于少量特定示例。

    

    现在有大量的证据表明，深度学习模型学习到了某些可解释的人类特征，作为其对数据的内部表示的一部分。由于拥有正确（或错误）的概念对于可信赖的机器学习系统至关重要，自然而然地我们想要知道在给定层次上，模型原始训练集中的哪些输入对于学习一个概念最为重要。为了回答这个问题，我们将数据归因方法与探测模型学习到的概念的方法相结合。通过在一系列网络层次上训练网络和探测模型，并使用最近开发的用于大规模数据归因的TRAK方法，我们对两个概念数据集进行训练网络和探测模型的集合。我们发现一些证据表明，通过移除对一个概念具有最高归因的前10000张图像并重新训练模型，概念在网络中的位置以及概念的探测稀疏性并没有发生改变。这表明，与依赖于少量特定示例不同，用于确定概念的特征具有较高的独立性。

    By now there is substantial evidence that deep learning models learn certain human-interpretable features as part of their internal representations of data. As having the right (or wrong) concepts is critical to trustworthy machine learning systems, it is natural to ask which inputs from the model's original training set were most important for learning a concept at a given layer. To answer this, we combine data attribution methods with methods for probing the concepts learned by a model. Training network and probe ensembles for two concept datasets on a range of network layers, we use the recently developed TRAK method for large-scale data attribution. We find some evidence for convergence, where removing the 10,000 top attributing images for a concept and retraining the model does not change the location of the concept in the network nor the probing sparsity of the concept. This suggests that rather than being highly dependent on a few specific examples, the features that inform the 
    
[^6]: Mini-BEHAVIOR：面向具身人工智能的长期决策制定的过程生成基准

    Mini-BEHAVIOR: A Procedurally Generated Benchmark for Long-horizon Decision-Making in Embodied AI. (arXiv:2310.01824v1 [cs.AI])

    [http://arxiv.org/abs/2310.01824](http://arxiv.org/abs/2310.01824)

    Mini-BEHAVIOR是一个面向具身人工智能的基准，旨在挑战智能体解决类似于日常挑战的复杂活动，并通过过程生成实现了无限的任务变化和对开放式学习的支持。

    

    我们提出了Mini-BEHAVIOR，一种新颖的面向具身人工智能的基准，挑战智能体利用推理和决策技能解决类似于日常人类挑战的复杂活动。Mini-BEHAVIOR环境是一个快速，现实的Gridworld环境，既具有快速原型设计和易用性的优点，同时也保留了复杂具身人工智能基准中符号级的物理现实感和复杂性。我们引入了关键特性，如过程生成，以实现无限的任务变化和对开放式学习的支持。Mini-BEHAVIOR提供了原始BEHAVIOR基准中各种家务任务的实现，以及用于数据收集和强化学习代理训练的入门代码。总之，Mini-BEHAVIOR为评估具身人工智能中的决策制定和规划解决方案提供了一个快速、开放式的基准。它作为研究的用户友好的入口点，促进了评估和发展过程。

    We present Mini-BEHAVIOR, a novel benchmark for embodied AI that challenges agents to use reasoning and decision-making skills to solve complex activities that resemble everyday human challenges. The Mini-BEHAVIOR environment is a fast, realistic Gridworld environment that offers the benefits of rapid prototyping and ease of use while preserving a symbolic level of physical realism and complexity found in complex embodied AI benchmarks. We introduce key features such as procedural generation, to enable the creation of countless task variations and support open-ended learning. Mini-BEHAVIOR provides implementations of various household tasks from the original BEHAVIOR benchmark, along with starter code for data collection and reinforcement learning agent training. In essence, Mini-BEHAVIOR offers a fast, open-ended benchmark for evaluating decision-making and planning solutions in embodied AI. It serves as a user-friendly entry point for research and facilitates the evaluation and devel
    
[^7]: AskIt: 大型语言模型的统一编程接口

    AskIt: Unified Programming Interface for Programming with Large Language Models. (arXiv:2308.15645v1 [cs.PL])

    [http://arxiv.org/abs/2308.15645](http://arxiv.org/abs/2308.15645)

    AskIt是一个专为大型语言模型设计的领域特定语言，通过简化LLM的集成和提供统一的接口，解决了LLM嵌入应用程序和代码生成的挑战。

    

    在软件开发的不断发展中，大型语言模型 (LLMs) 展示了一种独特的现象，即 emergent abilities，展示了在多个任务中的熟练能力，从文本摘要到代码生成。虽然这些能力在软件设计和开发方面开辟了新的途径，但它们的整合也带来了重大挑战。开发者面临着将LLMs直接嵌入应用程序或将其用于代码生成的决策。此外，有效的提示设计成为一个关键问题，考虑到从自然语言输出中提取数据的必要性。为了解决这些复杂性，本文介绍了AskIt，一种专为LLMs设计的领域特定语言 (DSL)。AskIt简化了LLM的集成，提供了类型指导的输出控制，基于模板的函数定义以及统一的接口，减少了LLM的基于代码生成和应用程序集成之间的区别。

    In the evolving landscape of software development, Large Language Models (LLMs) exhibit a unique phenomenon known as emergent abilities, demonstrating adeptness across numerous tasks, from text summarization to code generation. While these abilities open up novel avenues in software design and crafting, their incorporation presents substantial challenges. Developers grapple with decisions surrounding the direct embedding of LLMs within applications versus employing them for code generation. Moreover, effective prompt design becomes a critical concern, given the necessity of data extraction from natural language outputs. To address these intricacies, this paper introduces AskIt, a domain-specific language (DSL) specifically designed for LLMs. AskIt simplifies LLM integration, offering type-guided output control, template-based function definitions, and a unified interface that diminishes the distinction between LLM-based code generation and application integration. Furthermore, through 
    
[^8]: 在资源受限的边缘设备上通过动态专家交换为MoE模型提供服务

    Serving MoE Models on Resource-constrained Edge Devices via Dynamic Expert Swapping. (arXiv:2308.15030v1 [cs.AI])

    [http://arxiv.org/abs/2308.15030](http://arxiv.org/abs/2308.15030)

    本文提出了一种在资源受限的边缘设备上通过动态专家交换为MoE模型提供服务的推理框架，该框架通过分析MoE模型的行为模式，引入了新的数据结构来减少资源消耗，并通过性能分析优化参数配置。

    

    混合专家(MoE)是深度学习中一种流行的技术，通过有条件激活的并行神经网络模块(专家)提升了模型的容量。然而，在资源受限的延迟关键的边缘场景中提供MoE模型的服务是一项具有挑战性的任务，因为模型的大小和复杂性显著增加。本文首先分析了MoE模型在连续推理场景中的行为模式，得出了关于专家激活的三个关键观察结果，包括时间局部性、可交换性和可跳过计算。基于这些观察，我们引入了PC-MoE，一种适用于资源受限的连续MoE模型服务的推理框架。PC-MoE的核心是一种新的数据结构，称为“参数委员会”，它智能地维护一部分重要的正在使用的专家，以减少资源消耗。通过基于性能分析的委员会规划器，在线找到参数委员会的最佳配置，并进行专家交换和请求处理。

    Mixture of experts (MoE) is a popular technique in deep learning that improves model capacity with conditionally-activated parallel neural network modules (experts). However, serving MoE models in resource-constrained latency-critical edge scenarios is challenging due to the significantly increased model size and complexity. In this paper, we first analyze the behavior pattern of MoE models in continuous inference scenarios, which leads to three key observations about the expert activations, including temporal locality, exchangeability, and skippable computation. Based on these observations, we introduce PC-MoE, an inference framework for resource-constrained continuous MoE model serving. The core of PC-MoE is a new data structure, Parameter Committee, that intelligently maintains a subset of important experts in use to reduce resource consumption. The optimal configuration of Parameter Committee is found offline by a profiling-guided committee planner, and expert swapping and request 
    
[^9]: 交通流量优化的终身多智能体路径规划

    Traffic Flow Optimisation for Lifelong Multi-Agent Path Finding. (arXiv:2308.11234v1 [cs.AI])

    [http://arxiv.org/abs/2308.11234](http://arxiv.org/abs/2308.11234)

    本文提出了一种新的终身多智能体路径规划方法，通过引导智能体避开拥堵路径来优化交通流量，显著提高解决方案质量和总体吞吐量。

    

    多智能体路径规划(MAPF)是机器人领域的一个基本问题，要求为一个团队的智能体计算无碰撞路径，所有智能体都在共享地图上移动。尽管有许多相关研究，但当前的算法在智能体数量增加时都会遇到困难。主要原因是现有方法通常规划自由流动的最优路径，这会导致拥堵。为了解决这个问题，我们提出了一种新的MAPF方法，通过跟随避免拥堵的路径来引导智能体到达目的地。我们在两个大规模场景中评估了这个想法：一次性MAPF，每个智能体只有一个目的地，以及终身MAPF，智能体不断被分配新任务。对于一次性MAPF，我们展示了我们的方法大大提高了解决方案的质量。对于终身MAPF，我们报告了总体吞吐量的大幅提升。

    Multi-Agent Path Finding (MAPF) is a fundamental problem in robotics that asks us to compute collision-free paths for a team of agents, all moving across a shared map. Although many works appear on this topic, all current algorithms struggle as the number of agents grows. The principal reason is that existing approaches typically plan free-flow optimal paths, which creates congestion. To tackle this issue we propose a new approach for MAPF where agents are guided to their destination by following congestion-avoiding paths. We evaluate the idea in two large-scale settings: one-shot MAPF, where each agent has a single destination, and lifelong MAPF, where agents are continuously assigned new tasks. For one-shot MAPF we show that our approach substantially improves solution quality. For Lifelong MAPF we report large improvements in overall throughput.
    
[^10]: AIs的发展脱靴法

    Developmental Bootstrapping of AIs. (arXiv:2308.04586v1 [cs.AI])

    [http://arxiv.org/abs/2308.04586](http://arxiv.org/abs/2308.04586)

    传统的符号AI方法和深度学习AI方法无法满足创建强大和可信赖的AI的挑战，然而，发展脱靴法通过模仿人类儿童的能力发展过程，为创建稳健可靠的AI提供了希望。

    

    尽管当前一些AI在封闭的世界，如棋盘游戏中超越了人类能力，但它们在混乱的现实世界中的表现有限。它们会犯奇怪的错误而且没有意识到。它们很难受到指导，不能运用常识，缺乏好奇心。它们不能成为良好的合作者。传统手动构建的符号AI方法构建的系统和使用生成和深度学习AI方法(包括大规模语言模型)构建的系统都无法应对这些挑战。它们不适合创建强大和可信赖的AI。尽管此方法不属于主流的AI方法，但发展脱靴法显示出希望。在发展脱靴法中，AI像人类儿童一样发展能力。它们从先天能力开始。像人类一样，它们与环境互动，并从互动中学习。它们通过自我发展的能力逐步扩展先天能力。它们互动并逐渐将所学应用于实际操作。

    Although some current AIs surpass human abilities especially in closed worlds such as board games, their performance in the messy real world is limited. They make strange mistakes and do not notice them. They cannot be instructed easily, fail to use common sense, and lack curiosity. They do not make good collaborators. Neither systems built using the traditional manually-constructed symbolic AI approach nor systems built using generative and deep learning AI approaches including large language models (LLMs) can meet the challenges. They are not well suited for creating robust and trustworthy AIs. Although it is outside of mainstream AI approaches, developmental bootstrapping shows promise. In developmental bootstrapping, AIs develop competences like human children do. They start with innate competences. Like humans, they interact with the environment and learn from their interactions. They incrementally extend their innate competences with self-developed competences. They interact and 
    
[^11]: EnrichEvent: 使用上下文信息为新出现的事件提供丰富的社交数据

    EnrichEvent: Enriching Social Data with Contextual Information for Emerging Event Extraction. (arXiv:2307.16082v1 [cs.CL])

    [http://arxiv.org/abs/2307.16082](http://arxiv.org/abs/2307.16082)

    本文提出了一个利用词汇、语义和上下文表示的框架，旨在解决现有事件检测方法在识别新兴社交事件方面的局限性，并提供了对社交数据进行丰富的上下文化处理的方法。

    

    社交平台已成为传播和讨论真实事件信息的关键平台，为及早发现有新闻价值的事件提供了良好的机会。然而，现有的大多数事件检测方法仅利用关键词突发性或网络结构来检测热点事件。因此，对于事件和社交数据的复杂性而言，它们往往无法在达到趋势状态之前识别出新出现的社交事件。社交数据，例如推文，具有拼写错误、不完整性、歧义性和语言不规范性，以及意见方面的变化。此外，利用有限的上下文知识来学习事件的演变特征对于机器学习模型几乎是不可行的。为了解决这些问题，本文提出了一个利用流式社交数据的词汇、语义和上下文表示的框架。

    Social platforms have emerged as a crucial platform for disseminating and discussing information about real-life events, which offers an excellent opportunity for early detection of newsworthy events. However, most existing approaches for event detection solely exploit keyword burstiness or network structures to detect hot events. Thus, they often fail to identify emerging social events before reaching a trending state regarding the challenging nature of events and social data. Social data, e.g., tweets, is characterized by misspellings, incompleteness, ambiguity, and irregular language, as well as variation in aspects of opinions. Moreover, learning the evolving characteristics of the events utilizing limited contextual knowledge is almost infeasible for machine learning models. To address these problems, in this paper, we propose a framework that exploits the lexical, semantic, and contextual representations of streaming social data. In particular, we leverage contextual knowledge to
    
[^12]: 研究顺序推荐系统对训练数据扰动的鲁棒性：一项经验研究

    Investigating the Robustness of Sequential Recommender Systems Against Training Data Perturbations: an Empirical Study. (arXiv:2307.13165v1 [cs.IR])

    [http://arxiv.org/abs/2307.13165](http://arxiv.org/abs/2307.13165)

    本研究通过对多个数据集进行评估发现，顺序推荐系统中删除序列末尾的项目显著降低了性能，而删除序列开头或中间的项目则没有明显影响。这一发现强调了考虑训练数据中扰动项目位置的重要性，并能指导更具鲁棒性的顺序推荐系统的设计。

    

    顺序推荐系统被广泛用于建模用户随时间变化的行为，然而其在面对训练数据扰动时的鲁棒性是一个关键问题。本文进行了一项经验研究，探究了在时间顺序序列中不同位置上删除项目的效果。我们评估了两种不同的顺序推荐系统模型在多个数据集上的表现，使用归一化折现累积增益（NDCG）指标和排名敏感度列表（Rank Sensitivity List）指标来衡量其性能。我们的结果显示，删除序列末尾的项目显著影响性能，NDCG下降高达60％，而删除序列开头或中间的项目没有显著影响。这些发现凸显了考虑训练数据中扰动项目位置的重要性，并可指导更具鲁棒性的顺序推荐系统的设计。

    Sequential Recommender Systems (SRSs) have been widely used to model user behavior over time, but their robustness in the face of perturbations to training data is a critical issue. In this paper, we conduct an empirical study to investigate the effects of removing items at different positions within a temporally ordered sequence. We evaluate two different SRS models on multiple datasets, measuring their performance using Normalized Discounted Cumulative Gain (NDCG) and Rank Sensitivity List metrics. Our results demonstrate that removing items at the end of the sequence significantly impacts performance, with NDCG decreasing up to 60\%, while removing items from the beginning or middle has no significant effect. These findings highlight the importance of considering the position of the perturbed items in the training data and shall inform the design of more robust SRSs.
    
[^13]: PreDiff: 使用隐式扩散模型进行降水近期预测

    PreDiff: Precipitation Nowcasting with Latent Diffusion Models. (arXiv:2307.10422v1 [cs.LG])

    [http://arxiv.org/abs/2307.10422](http://arxiv.org/abs/2307.10422)

    本论文提出了PreDiff方法，使用条件隐式扩散模型进行降水近期预测。同时，引入显式知识控制机制以满足特定领域的物理约束。

    

    传统上，地球系统预测主要依赖于复杂的物理模型，这些模型计算量大且需要领域专业知识。在过去的十年中，时空地球观测数据的空前增加使得使用深度学习技术的数据驱动预测模型成为可能。这些模型在不同的地球系统预测任务中显示出有希望的效果，但是它们要么难以处理不确定性，要么忽视特定领域的先验知识，导致预测结果模糊或产生物理上不合理的预测。为了解决这些限制，我们提出了一种概率时空预测的两阶段流程：1）我们开发了一种名为PreDiff的条件隐式扩散模型，能够进行概率预测；2）我们融入了一种显式知识控制机制，以使预测符合特定领域的物理约束。这是通过在每个去噪步骤中估计与所施加约束的偏差来实现的。

    Earth system forecasting has traditionally relied on complex physical models that are computationally expensive and require significant domain expertise. In the past decade, the unprecedented increase in spatiotemporal Earth observation data has enabled data-driven forecasting models using deep learning techniques. These models have shown promise for diverse Earth system forecasting tasks but either struggle with handling uncertainty or neglect domain-specific prior knowledge, resulting in averaging possible futures to blurred forecasts or generating physically implausible predictions. To address these limitations, we propose a two-stage pipeline for probabilistic spatiotemporal forecasting: 1) We develop PreDiff, a conditional latent diffusion model capable of probabilistic forecasts. 2) We incorporate an explicit knowledge control mechanism to align forecasts with domain-specific physical constraints. This is achieved by estimating the deviation from imposed constraints at each denoi
    
[^14]: 安全的基于模型的多智能体均场强化学习

    Safe Model-Based Multi-Agent Mean-Field Reinforcement Learning. (arXiv:2306.17052v1 [cs.LG])

    [http://arxiv.org/abs/2306.17052](http://arxiv.org/abs/2306.17052)

    本文提出了Safe-$\text{M}^3$-UCRL算法，通过使用模型中的认知不确定性和对数障碍方法，实现了在未知转移动态情况下达到安全策略的优化，成功解决了大规模多智能体协调问题。

    

    许多应用，比如共享交通，需要协调大量的智能体。均场强化学习通过优化代表性智能体的策略来应对由此带来的可扩展性挑战。在本文中，我们解决了一个重要的泛化问题，即智能体分布存在全局约束的情况（例如需要满足容量约束或最小覆盖要求）。我们提出了Safe-$\text{M}^3$-UCRL，这是第一个能够在未知转移动态的情况下实现安全策略的基于模型的算法。作为一个关键因素，它在保证悲观约束满足的同时，利用转移模型中的认知不确定性来使用对数障碍方法确保高概率。我们在许多共享交通运营商面临的车辆重定位问题上展示了Safe-$\text{M}^3$-UCRL，并通过基于深圳出租车轨迹数据的仿真评估其性能。我们的算法能够有效满足关键需求。

    Many applications, e.g., in shared mobility, require coordinating a large number of agents. Mean-field reinforcement learning addresses the resulting scalability challenge by optimizing the policy of a representative agent. In this paper, we address an important generalization where there exist global constraints on the distribution of agents (e.g., requiring capacity constraints or minimum coverage requirements to be met). We propose Safe-$\text{M}^3$-UCRL, the first model-based algorithm that attains safe policies even in the case of unknown transition dynamics. As a key ingredient, it uses epistemic uncertainty in the transition model within a log-barrier approach to ensure pessimistic constraints satisfaction with high probability. We showcase Safe-$\text{M}^3$-UCRL on the vehicle repositioning problem faced by many shared mobility operators and evaluate its performance through simulations built on Shenzhen taxi trajectory data. Our algorithm effectively meets the demand in critica
    
[^15]: 将几何控制集成到文本到图像扩散模型中以通过文本提示生成高质量的检测数据

    Integrating Geometric Control into Text-to-Image Diffusion Models for High-Quality Detection Data Generation via Text Prompt. (arXiv:2306.04607v1 [cs.CV])

    [http://arxiv.org/abs/2306.04607](http://arxiv.org/abs/2306.04607)

    GeoDiffusion使用文本提示将各种几何条件转化为图像，生成高质量的检测数据，性能优于现有方法。

    

    扩散模型因其在创建内容和生成数据方面的显着能力而受到重视，例如图像分类。然而，使用扩散模型生成高质量的物体检测数据仍然是一个不被充分探索的领域，其中不仅图像水平的感知质量，而且边界框和相机视图等几何条件也是至关重要的。前期研究使用模块编码语义布局来实现复制粘贴合成或布局到图像(L2I)生成。本文提出了GeoDiffusion，一种简单的框架，可以灵活地将各种几何条件转化为文本提示，并使用预训练的文本到图像(T2I)扩散模型生成高质量的检测数据。与以往的L2I方法不同，我们的GeoDiffusion不仅能够编码边界框，还能够编码自驾场景中的额外几何条件，如摄像头视图。广泛的实验结果表明，GeoDiffusion在物体检测准确性方面优于最先进的方法，并针对各种几何条件生成具有更高感知质量的图像。

    Diffusion models have attracted significant attention due to their remarkable ability to create content and generate data for tasks such as image classification. However, the usage of diffusion models to generate high-quality object detection data remains an underexplored area, where not only the image-level perceptual quality but also geometric conditions such as bounding boxes and camera views are essential. Previous studies have utilized either copy-paste synthesis or layout-to-image (L2I) generation with specifically designed modules to encode semantic layouts. In this paper, we propose GeoDiffusion, a simple framework that can flexibly translate various geometric conditions into text prompts and empower the pre-trained text-to-image (T2I) diffusion models for high-quality detection data generation. Unlike previous L2I methods, our GeoDiffusion is able to encode not only bounding boxes but also extra geometric conditions such as camera views in self-driving scenes. Extensive experi
    
[^16]: 用于改进视听融合导航的主动稀疏对话

    Active Sparse Conversations for Improved Audio-Visual Embodied Navigation. (arXiv:2306.04047v1 [cs.CV])

    [http://arxiv.org/abs/2306.04047](http://arxiv.org/abs/2306.04047)

    本文提出了CAVEN - 一种具有对话功能的音频视觉导航代理，能够向人类/神谕提出导航问题并处理神谕回答以协助自主导航。该系统基于多模态分层强化学习方法，并使用三个低级策略进行引导。

    

    为了高效地导航到一个听觉目标，一个具有固定自主权的实体必须不仅要有能力有效地使用视听线索, 而且还要有能力在不牺牲自主性的情况下主动寻求人类/神谕的帮助，例如，当不确定导航到哪里寻找嘈杂或间歇性听觉目标时。因此，我们提出了CAVEN-一种具有对话功能的音频视觉导航代理，能够向人类/神谕提出导航问题并处理神谕的自由形式自然语言回答。在CAVEN的核心是一个多模态分层强化学习(RL)设置，它配备了一个高级策略，该策略经过训练，可以在每一步从三个低级策略中选择一个，即：(i)使用视听线索进行导航，或(ii)向神谕提出问题并接收短或详细的回答，或(iii)提问普遍问题(当不确定该问什么时)并获得指导

    Efficient navigation towards an audio-goal necessitates an embodied agent to not only possess the ability to use audio-visual cues effectively, but also be equipped to actively (but occasionally) seek human/oracle assistance without sacrificing autonomy, e.g., when it is uncertain of where to navigate towards locating a noisy or sporadic audio goal. To this end, we present CAVEN -- a conversational audio-visual embodied navigation agent that is capable of posing navigation questions to a human/oracle and processing the oracle responses; both in free-form natural language. At the core of CAVEN is a multimodal hierarchical reinforcement learning (RL) setup that is equipped with a high-level policy that is trained to choose from one of three low-level policies (at every step), namely: (i) to navigate using audio-visual cues, or (ii) to frame a question to the oracle and receive a short or detailed response, or (iii) ask generic questions (when unsure of what to ask) and receive instructio
    
[^17]: 俄乌战争：预测和解释Twitter的封禁

    Russo-Ukrainian War: Prediction and explanation of Twitter suspension. (arXiv:2306.03502v1 [cs.SI])

    [http://arxiv.org/abs/2306.03502](http://arxiv.org/abs/2306.03502)

    本研究分析了Twitter封禁机制，揭示了存在的政策违规、宣传、垃圾邮件等问题，并发现拥有更多粉丝的账户更可能被封禁。这些发现可以让Twitter和其他社交网络改进其内容过滤机制。

    

    2022年2月24日，俄罗斯入侵乌克兰，开始了现在已知的俄乌战争，并在社交媒体上引发了在线话语。Twitter作为最受欢迎的社交网络之一，以其开放和民主的特点，在其庞大的用户群中实现了透明的讨论。不幸的是，这往往会导致Twitter的政策违规、宣传、滥用行为、侵犯公民权利，因此导致用户账户被封禁和删除。本研究着重探讨了Twitter的封禁机制，并分析了可能导致账户被封禁的共享内容和用户账户的特征。为此，我们利用Twitter API获得了包含107.7M条推文的数据集，来自980万用户。我们提取了被封禁账户的共享内容类别，并通过提取文本嵌入和余弦相似性聚类来解释其特征。我们的研究结果揭示了一些滥用Twitter政策标准的骗子活动、垃圾邮件和宣传活动。此外，我们发现相对于粉丝数较少的账户，拥有更多粉丝的账户更有可能被封禁。这些发现可以为Twitter和其他社交网络改进其内容过滤机制，最小化有害内容的传播提供有用的参考。

    On 24 February 2022, Russia invaded Ukraine, starting what is now known as the Russo-Ukrainian War, initiating an online discourse on social media. Twitter as one of the most popular SNs, with an open and democratic character, enables a transparent discussion among its large user base. Unfortunately, this often leads to Twitter's policy violations, propaganda, abusive actions, civil integrity violation, and consequently to user accounts' suspension and deletion. This study focuses on the Twitter suspension mechanism and the analysis of shared content and features of the user accounts that may lead to this. Toward this goal, we have obtained a dataset containing 107.7M tweets, originating from 9.8 million users, using Twitter API. We extract the categories of shared content of the suspended accounts and explain their characteristics, through the extraction of text embeddings in junction with cosine similarity clustering. Our results reveal scam campaigns taking advantage of trending top
    
[^18]: GPT 模型在化学领域到底有怎样的应用？八个任务的综合基准测试。

    What indeed can GPT models do in chemistry? A comprehensive benchmark on eight tasks. (arXiv:2305.18365v1 [cs.CL])

    [http://arxiv.org/abs/2305.18365](http://arxiv.org/abs/2305.18365)

    本文建立了包括 8 个实际化学任务的综合基准测试，有力地证明了 LLM 在实际化学中的能力。

    

    具有强大自然语言处理能力的大型语言模型已被广泛应用于科学、金融和软件工程等领域。但是，LLM 是否有能力推动化学领域的进展仍不清楚。本文建立了包含 8 个实际化学任务的综合基准测试，包括名称预测、属性预测、产量预测、反应预测、反合成（从产物预测反应物）、基于文本的分子设计、分子字幕和试剂选择。我们使用广泛认可的数据集，包括 BBBP、Tox21、PubChem、USPTO 和 ChEBI，有力地证明了 LLM 在实际化学中的能力。在精心选择的示例中，对三种 GPT 模型（GPT-4、GPT-3.5 和 DaVinci-003）在零样本和少样本有上下文学习的设置中进行了评估。

    Large Language Models (LLMs) with strong abilities in natural language processing tasks have emerged and have been rapidly applied in various kinds of areas such as science, finance and software engineering. However, the capability of LLMs to advance the field of chemistry remains unclear. In this paper,we establish a comprehensive benchmark containing 8 practical chemistry tasks, including 1) name prediction, 2) property prediction, 3) yield prediction, 4) reaction prediction, 5) retrosynthesis (prediction of reactants from products), 6)text-based molecule design, 7) molecule captioning, and 8) reagent selection. Our analysis draws on widely recognized datasets including BBBP, Tox21, PubChem, USPTO, and ChEBI, facilitating a broad exploration of the capacities of LLMs within the context of practical chemistry. Three GPT models (GPT-4, GPT-3.5,and Davinci-003) are evaluated for each chemistry task in zero-shot and few-shot in-context learning settings with carefully selected demonstrat
    
[^19]: 交叉门控多层感知机下的蛋白质复合物不变嵌入是一种一次性抗体设计器

    Protein Complex Invariant Embedding with Cross-Gate MLP is A One-Shot Antibody Designer. (arXiv:2305.09480v1 [q-bio.BM])

    [http://arxiv.org/abs/2305.09480](http://arxiv.org/abs/2305.09480)

    本文提出了一种深度生成模型，可以一次性地共同设计抗体CDR的1D序列和3D结构，解决几何建模和低效推断的问题。

    

    抗体是由免疫系统产生的针对外来物质或抗原的重要蛋白质。抗体的特异性由其互补决定区（CDR）决定，CDR位于抗体链的可变区域中，形成与抗原结合的位点。以往的研究利用复杂的技术生成CDR，但它们遭受了几何建模不足的问题。此外，常见的迭代精化策略导致了低效的推断。本文提出了一种深度生成模型，可以一次性地共同设计CDR的1D序列和3D结构。为了实现这一目标，我们将抗体CDR设计分为两个阶段：（i）蛋白质结构的几何建模和（ii）序列结构共学习。我们开发了一种蛋白质复合物不变嵌入，可捕捉蛋白质骨架原子（包括Cα、N、C和O原子）之间的内部和外部组分相互作用，以实现全面的几何建模。

    Antibodies are crucial proteins produced by the immune system in response to foreign substances or antigens. The specificity of an antibody is determined by its complementarity-determining regions (CDRs), which are located in the variable domains of the antibody chains and form the antigen-binding site. Previous studies have utilized complex techniques to generate CDRs, but they suffer from inadequate geometric modeling. Moreover, the common iterative refinement strategies lead to an inefficient inference. In this paper, we propose a deep generative model that can co-design 1D sequences and 3D structures of CDRs in a one-shot manner. To achieve this, we decouple the antibody CDR design into two stages: (i) geometric modeling of protein structures and (ii) sequence-structure co-learning. We develop a protein complex invariant embedding that captures both intra- and inter-component interactions among the backbone atoms including C$\alpha$, N, C, and O atoms to achieve comprehensive geome
    
[^20]: 自然语言处理中基于外部分布检测的综述

    A Survey on Out-of-Distribution Detection in NLP. (arXiv:2305.03236v1 [cs.CL])

    [http://arxiv.org/abs/2305.03236](http://arxiv.org/abs/2305.03236)

    这篇论文首次综述了最新的OOD检测方法在自然语言处理中的应用。根据算法使用的数据，将方法分成三类，并介绍了相关数据集、应用和度量方法。

    

    在现实世界中，基于外部分布（OOD）的检测对于机器学习系统的可靠和安全的部署至关重要。过去几年取得了极大进展。本文重点关注自然语言处理方法，并首次综述了OOD检测方面的最新进展。首先，我们给出OOD检测的正式定义，并讨论了几个相关领域。然后，根据算法使用的数据，将最近的算法分成三类：（1）可用OOD数据，（2）OOD数据不可用+内部分布（ID）标签可用，（3）OOD数据不可用+ID标签不可用。第三，介绍数据集、应用和度量方法。最后，总结现有工作并提出潜在的未来研究课题。

    Out-of-distribution (OOD) detection is essential for the reliable and safe deployment of machine learning systems in the real world. Great progress has been made over the past years. This paper presents the first review of recent advances in OOD detection with a particular focus on natural language processing approaches. First, we provide a formal definition of OOD detection and discuss several related fields. We then categorize recent algorithms into three classes according to the data they used: (1) OOD data available, (2) OOD data unavailable + in-distribution (ID) label available, and (3) OOD data unavailable + ID label unavailable. Third, we introduce datasets, applications, and metrics. Finally, we summarize existing work and present potential future research topics.
    
[^21]: 三元Kemeny问题的空间缩减技术

    Space reduction techniques for the $3$-wise Kemeny problem. (arXiv:2305.00140v1 [cs.DM])

    [http://arxiv.org/abs/2305.00140](http://arxiv.org/abs/2305.00140)

    本文研究了三元Kemeny问题，提出了空间缩减技术，可以在多项式时间内高效确定备选方案的相对顺序，实现了计算优化。

    

    Kemeny规则是最广泛研究和知名度很高的选举方案之一，具有计算社会选择和生物学等多种重要应用。最近，Gilbert等人通过集合方法推广了Kemeny规则。重塑该模式，我们已经证明了在与古典Kemeny规则相比下，由三元Kendall-tau距离引出的三元Kemeny投票方案具有有趣的优势。虽然三元Kemeny问题（计算投票配置的三元共识排名集合）是NP难的，但我们在本文中建立了几个主序定理的推广，如同经典Kemeny规则中在\cite{Milosz-Hamel-2020}中所得到的，为了实现大幅地减少搜索空间，通过在多项式时间内高效地确定成对备选方案的相对顺序。实质上，我们的定理精确量化了非平凡属性，即当存在任意数量的投票者时，Kemeny评分的计算具有渐进最优性。

    Kemeny's rule is one of the most studied and well-known voting schemes with various important applications in computational social choice and biology. Recently, Kemeny's rule was generalized via a set-wise approach by Gilbert et. al. Following this paradigm, we have shown in \cite{Phung-Hamel-2023} that the $3$-wise Kemeny voting scheme induced by the $3$-wise Kendall-tau distance presents interesting advantages in comparison with the classical Kemeny rule. While the $3$-wise Kemeny problem, which consists of computing the set of $3$-wise consensus rankings of a voting profile, is NP-hard, we establish in this paper several generalizations of the Major Order Theorems, as obtained in \cite{Milosz-Hamel-2020} for the classical Kemeny rule, for the $3$-wise Kemeny voting scheme to achieve a substantial search space reduction by efficiently determining in polynomial time the relative orders of pairs of alternatives. Essentially, our theorems quantify precisely the non-trivial property that
    
[^22]: 异构智能体强化学习

    Heterogeneous-Agent Reinforcement Learning. (arXiv:2304.09870v1 [cs.LG])

    [http://arxiv.org/abs/2304.09870](http://arxiv.org/abs/2304.09870)

    提出了一种异构智能体强化学习（HARL）算法，解决了协作多智能体强化学习中的参数共享限制，同时通过引入多智能体优势分解引理和序列更新方案，建立了异构智能体信任区域学习（HATRL）算法及其易处理的逼近方式 HATRPO 和 HAPPO。此外，发现了一种名为异构智能体镜像学习（HAML）的新型框架，加强了对HATRPO和HAPPO的理论保证。

    

    协作多智能体强化学习（MARL）在人工智能研究中越来越受欢迎，然而，许多研究仍然严重依赖于智能体之间的参数共享，这将它们限制在同质异构智能体设置下，从而导致训练不稳定和缺乏收敛保证。为了在一般的异构智能体设置下实现有效的协作，我们提出了解决上述问题的异构智能体强化学习（HARL）算法。我们的发现核心是多智能体优势分解引理和序列更新方案。基于这些，我们开发了经过验证的无参数共享约束的异构智能体信任区域学习（HATRL）算法，并通过易处理的逼近方式得出了HATRPO和HAPPO。此外，我们发现了一种名为异构智能体镜像学习（HAML）的新型框架，它加强了对HATRPO和HAPPO的理论保证。

    The necessity for cooperation among intelligent machines has popularised cooperative multi-agent reinforcement learning (MARL) in AI research. However, many research endeavours heavily rely on parameter sharing among agents, which confines them to only homogeneous-agent setting and leads to training instability and lack of convergence guarantees. To achieve effective cooperation in the general heterogeneous-agent setting, we propose Heterogeneous-Agent Reinforcement Learning (HARL) algorithms that resolve the aforementioned issues. Central to our findings are the multi-agent advantage decomposition lemma and the sequential update scheme. Based on these, we develop the provably correct Heterogeneous-Agent Trust Region Learning (HATRL) that is free of parameter-sharing constraint, and derive HATRPO and HAPPO by tractable approximations. Furthermore, we discover a novel framework named Heterogeneous-Agent Mirror Learning (HAML), which strengthens theoretical guarantees for HATRPO and HAPP
    
[^23]: 利用代理模型识别多任务学习中的负迁移

    Identification of Negative Transfers in Multitask Learning Using Surrogate Models. (arXiv:2303.14582v1 [cs.LG])

    [http://arxiv.org/abs/2303.14582](http://arxiv.org/abs/2303.14582)

    本文提出了一种通过代理建模来解决多任务学习中负迁移问题的方法，能够识别哪些源任务的子集会对目标任务有帮助。

    

    多任务学习广泛应用于通过增加多个相关源任务来训练低资源目标任务。然而，将所有源任务与目标任务简单组合并不总是能提高目标任务的预测性能，因为会存在负迁移。因此，多任务学习的一个关键问题是识别哪些源任务的子集会对目标任务有益。这个问题在计算上很具有挑战性，因为子集的数量随着源任务的数量呈指数级增长。在本文中，我们介绍了一种通过代理建模来解决此问题的有效方法。在代理建模中，我们对源任务进行采样（随机），并预先计算它们的多任务学习表现；然后，我们用线性回归模型来逼近预先计算的表现，该模型也可用于预测未采样的子集的表现。我们在几个合成示例和一个现实世界的多语言情感分析任务上证明了我们方法的有效性。

    Multitask learning is widely used in practice to train a low-resource target task by augmenting it with multiple related source tasks. Yet, naively combining all the source tasks with a target task does not always improve the prediction performance for the target task due to negative transfers. Thus, a critical problem in multitask learning is identifying subsets of source tasks that would benefit the target task. This problem is computationally challenging since the number of subsets grows exponentially with the number of source tasks; efficient heuristics for subset selection does not always capture the relationship between task subsets and multitask learning performances. In this paper, we introduce an efficient procedure to address this problem via surrogate modeling. In surrogate modeling, we sample (random) subsets of source tasks and precompute their multitask learning performances; Then, we approximate the precomputed performances with a linear regression model that can also be
    
[^24]: 协同人工智能的根源和要求

    Roots and Requirements for Collaborative AI. (arXiv:2303.12040v1 [cs.AI])

    [http://arxiv.org/abs/2303.12040](http://arxiv.org/abs/2303.12040)

    论文探讨了AI协同合作的历史和要求，是协同AI研究的动机和背景。

    

    AI协作者的愿景长期以来一直是科幻小说的经典素材，其中人工智能代理理解协作和人类沟通的微妙差别。它们通过贡献特殊的才能给他们的人类合作者和团队带来优势。多年来，政府咨询团体和人工智能领域的领袖一直倡导AIs应该具有人类兼容性和有效协作的能力。然而，具备像才华横溢的人那样协作能力的强大的AI仍然遥不可及。这篇论文依据对人工智能和人类代理有效和强大协作所需认知的分析，概述了公众和AI愿景中关于人工协作者的历史，开始于早期智能增强(IA)和人工智能(AI)的愿景。这篇论文旨在成为协同AI的第二个立场文件(Stefik & Price, 2023)的动机和背景。第二篇论文回顾了多学科的现状，并提出了一个AI协作研究的路线图。

    The vision of AI collaborators has long been a staple of science fiction, where artificial agents understand nuances of collaboration and human communication. They bring advantages to their human collaborators and teams by contributing their special talents. Government advisory groups and leaders in AI have advocated for years that AIs should be human compatible and be capable of effective collaboration. Nonetheless, robust AIs that can collaborate like talented people remain out of reach. This position paper draws on a cognitive analysis of what effective and robust collaboration requires of human and artificial agents. It sketches a history of public and AI visions for artificial collaborators, starting with early visions of intelligence augmentation (IA) and artificial intelligence (AI). It is intended as motivation and context for a second position paper on collaborative AI (Stefik & Price, 2023). The second paper reviews the multi-disciplinary state-of-the-art and proposes a roadm
    
[^25]: EvHandPose: 使用稀疏监督进行基于事件的3D手势姿势估计

    EvHandPose: Event-based 3D Hand Pose Estimation with Sparse Supervision. (arXiv:2303.02862v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.02862](http://arxiv.org/abs/2303.02862)

    本文提出了EvHandPose，该方法利用稀疏监督下的新型手部流表示进行基于事件的3D手势姿势估计，解决了运动模糊的问题，并通过构建大规模真实世界数据集来填补真实合成领域间的差距。

    

    事件相机在3D手势姿势估计中显示出了巨大的潜力，尤其在解决快速运动和高动态范围的挑战以低功耗方式处理时。然而，由于异步差分成像机制，设计事件表示来编码手部运动信息尤其是当手部不动时（导致运动模糊）是具有挑战性的，并且不可能对时间密集的事件流进行完全注释。在本文中，我们提出了EvHandPose，用于准确的手势姿势估计和减轻运动模糊问题的新型手部流表示。为了解决稀疏注释下的问题，我们在Pose-to-IWE（具有扭曲事件的图像）模块中设计了对比度最大化和手边缘约束，并将EvHandPose构建为弱监督框架。我们还构建了EvRealHands，首个针对几个具有挑战性场景的大规模真实世界事件驱动手势姿势数据集，以填补真实合成领域间的差距。

    Event camera shows great potential in 3D hand pose estimation, especially addressing the challenges of fast motion and high dynamic range in a low-power way. However, due to the asynchronous differential imaging mechanism, it is challenging to design event representation to encode hand motion information especially when the hands are not moving (causing motion ambiguity), and it is infeasible to fully annotate the temporally dense event stream. In this paper, we propose EvHandPose with novel hand flow representations in Event-to-Pose module for accurate hand pose estimation and alleviating the motion ambiguity issue. To solve the problem under sparse annotation, we design contrast maximization and hand-edge constraints in Pose-to-IWE (Image with Warped Events) module and formulate EvHandPose in a weakly-supervision framework. We further build EvRealHands, the first large-scale real-world event-based hand pose dataset on several challenging scenes to bridge the real-synthetic domain gap
    
[^26]: 前往负责任的AI生成内容之路

    A Pathway Towards Responsible AI Generated Content. (arXiv:2303.01325v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.01325](http://arxiv.org/abs/2303.01325)

    本文探讨了AI生成内容的合理使用所面临的风险，包括隐私、偏见、毒性、错误信息和知识产权等，并提供有希望的解决方向。

    

    近年来，AI生成内容（AIGC）受到了极大的关注，其内容涵盖了图像、文本、音频、视频等。与此同时，AIGC已经成为一把双刃剑，并最近在其负责任使用方面受到了许多批评。在本视野论文中，我们关注可能阻碍AIGC在实践中健康发展和部署的三个主要问题，包括来自隐私、偏见、毒性、错误信息和知识产权（IP）的风险。通过记录已知和潜在的风险，以及AIGC的任何可能的滥用情况，旨在引起对潜在风险和滥用的注意，帮助社会消除障碍，并促进更加道德和安全的AIGC部署。此外，我们提供了对应对这些风险的有希望的方向的见解，同时构建生成模型，使AIGC能够负责任地为社会带来益处。

    AI Generated Content (AIGC) has received tremendous attention within the past few years, with content ranging from image, text, to audio, video, etc. Meanwhile, AIGC has become a double-edged sword and recently received much criticism regarding its responsible usage. In this vision paper, we focus on three main concerns that may hinder the healthy development and deployment of AIGC in practice, including risks from privacy, bias, toxicity, misinformation, and intellectual property (IP). By documenting known and potential risks, as well as any possible misuse scenarios of AIGC, the aim is to draw attention to potential risks and misuse, help society to eliminate obstacles, and promote the more ethical and secure deployment of AIGC. Additionally, we provide insights into the promising directions for tackling these risks while constructing generative models, enabling AIGC to be used responsibly to benefit society.
    
[^27]: 基于语言模型的知识图谱嵌入编辑

    Editing Language Model-based Knowledge Graph Embeddings. (arXiv:2301.10405v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.10405](http://arxiv.org/abs/2301.10405)

    本文提出了一种新的任务——编辑基于语言模型的知识图谱嵌入，旨在实现对KG嵌入的数据高效和快速更新。针对这一任务，提出了一个简单而强大的方案——KGEditor，可以更好地更新特定事实而不影响其余部分的性能。

    

    近几十年来，使用语言模型进行知识图谱（KG）嵌入已经取得了实证成功。但是，基于语言模型的KG嵌入通常作为静态工件部署，修改起来具有挑战性，需要重新训练。为了解决这个问题，本文提出了一种新的任务，即编辑基于语言模型的KG嵌入。该任务旨在实现对KG嵌入的数据高效和快速更新，而不影响其余部分的性能。我们构建了四个新数据集：E-FB15k237、A-FB15k237、E-WN18RR 和 A-WN18RR，并评估了几种知识编辑基线，证明了之前的模型处理该任务的能力有限。我们进一步提出了一个简单但强大的基线——KGEditor，它利用超网络的附加参数层来编辑/添加事实。全面的实验结果表明，当更新特定事实而不影响其余部分的性能时，KGEditor 的表现更好。

    Recently decades have witnessed the empirical success of framing Knowledge Graph (KG) embeddings via language models. However, language model-based KG embeddings are usually deployed as static artifacts, which are challenging to modify without re-training after deployment. To address this issue, we propose a new task of editing language model-based KG embeddings in this paper. The proposed task aims to enable data-efficient and fast updates to KG embeddings without damaging the performance of the rest. We build four new datasets: E-FB15k237, A-FB15k237, E-WN18RR, and A-WN18RR, and evaluate several knowledge editing baselines demonstrating the limited ability of previous models to handle the proposed challenging task. We further propose a simple yet strong baseline dubbed KGEditor, which utilizes additional parametric layers of the hyper network to edit/add facts. Comprehensive experimental results demonstrate that KGEditor can perform better when updating specific facts while not affec
    
[^28]: 通过否定和谓词创造实现一般化

    Generalisation Through Negation and Predicate Invention. (arXiv:2301.07629v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.07629](http://arxiv.org/abs/2301.07629)

    这篇论文介绍了一种结合了否定和谓词创造的归纳逻辑编程方法，通过学习仅具有全量化身体变量的规则来改善泛化能力，并实现在NOPI中。实验结果表明，这种方法可以提高预测准确性和学习效率。

    

    在机器学习中，从少量的示例中进行泛化是一个基本挑战。为了解决这个挑战，我们引入了一种归纳逻辑编程（ILP）方法，结合了否定和谓词创造。结合这两个特性可以使ILP系统通过学习仅具有全量化身体变量的规则来更好地泛化。我们将这个想法实现在NOPI中，它可以学习具有谓词创造的正常逻辑程序，包括具有分层否定的Datalog程序。我们在多个领域上的实验结果表明，我们的方法可以提高预测准确性和学习时间。

    The ability to generalise from a small number of examples is a fundamental challenge in machine learning. To tackle this challenge, we introduce an inductive logic programming (ILP) approach that combines negation and predicate invention. Combining these two features allows an ILP system to generalise better by learning rules with universally quantified body-only variables. We implement our idea in NOPI, which can learn normal logic programs with predicate invention, including Datalog programs with stratified negation. Our experimental results on multiple domains show that our approach can improve predictive accuracies and learning times.
    
[^29]: gRoMA: 一种衡量深度神经网络全局鲁棒性的工具

    gRoMA: a Tool for Measuring Deep Neural Networks Global Robustness. (arXiv:2301.02288v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.02288](http://arxiv.org/abs/2301.02288)

    gRoMA是一种衡量DNN全局鲁棒性的创新工具，采用概率验证方法评估特定输出类别遭受到对抗性输入的概率。该工具可运行于预训练的黑盒分类模型上，并对整个模型和每个输入样本产生鲁棒性测量结果。

    

    深度神经网络（DNN）是前沿技术的代表，在各种复杂任务中取得了显著的表现。然而，将它们应用于安全关键系统（如航空或汽车领域）时，由于对抗性输入（即可能导致DNN犯错的输入扰动）的威胁，存在重大挑战。多项研究表明即便是现代DNN也容易受到对抗性输入的影响，因此必须测量并降低这种风险才能在安全关键系统中部署DNN。在这里，我们提出了一种创新且可扩展的工具gRoMA（全局鲁棒性测量和评估），它实现了一种概率验证方法来测量DNN的全局分类鲁棒性。具体而言，gRoMA测量特定输出类别遇到对抗性输入的概率。我们的工具基于预训练的黑盒分类模型，产生整个模型和每个输入样本的鲁棒性测量结果。我们通过测量多个最先进的DNN在热门图像数据集上的鲁棒性并分析结果，证明了我们的工具的有效性。

    Deep neural networks (DNNs) are at the forefront of cutting-edge technology, and have been achieving remarkable performance in a variety of complex tasks. Nevertheless, their integration into safety-critical systems, such as in the aerospace or automotive domains, poses a significant challenge due to the threat of adversarial inputs: perturbations in inputs that might cause the DNN to make grievous mistakes. Multiple studies have demonstrated that even modern DNNs are susceptible to adversarial inputs; and this risk must thus be measured and mitigated to allow the deployment of DNNs in safety-critical systems.  Here, we present gRoMA (global Robustness Measurement and Assessment), an innovative and scalable tool that implements a probabilistic verification approach to measure the global categorial robustness of a DNN. Specifically, gRoMA measures the probability of encountering adversarial inputs for a specific output category. Our tool operates on pre-trained, black-box classification
    
[^30]: 通过无监督说话风格转换提升语音情感识别

    Improving Speech Emotion Recognition with Unsupervised Speaking Style Transfer. (arXiv:2211.08843v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2211.08843](http://arxiv.org/abs/2211.08843)

    本文介绍了EmoAug，一种通过无监督说话风格转换来提升语音情感识别的模型。EmoAug利用语义编码器和语调编码器表示语言和非语言信息，并通过无监督方式重建语音信号。训练完成后，EmoAug通过引入不同风格丰富了情感语音的表达，并解决了数据不平衡问题。

    

    人类可以轻松修改各种韵律属性，例如重音位置和情感强度，以传达特定的情感，同时保持一致的语言内容。受到这种能力的启发，我们提出了EmoAug，这是一种新颖的风格转换模型，旨在增强情感表达并解决语音情感识别任务中的数据稀缺问题。EmoAug由一个语义编码器和一个语调编码器组成，分别表示语言和非语言信息。此外，解码器以无监督的方式在上述两个信息流的条件下重建语音信号。训练完成后，EmoAug通过将不同风格输入到语调编码器中，丰富了情感语音的表达，包括重音、节奏和强度等不同的韵律属性。同时，EmoAug能够生成每个类别相似数量的样本，以解决数据不平衡问题。

    Humans can effortlessly modify various prosodic attributes, such as the placement of stress and the intensity of sentiment, to convey a specific emotion while maintaining consistent linguistic content. Motivated by this capability, we propose EmoAug, a novel style transfer model designed to enhance emotional expression and tackle the data scarcity issue in speech emotion recognition tasks. EmoAug consists of a semantic encoder and a paralinguistic encoder that represent verbal and non-verbal information respectively. Additionally, a decoder reconstructs speech signals by conditioning on the aforementioned two information flows in an unsupervised fashion. Once training is completed, EmoAug enriches expressions of emotional speech with different prosodic attributes, such as stress, rhythm and intensity, by feeding different styles into the paralinguistic encoder. EmoAug enables us to generate similar numbers of samples for each class to tackle the data imbalance issue as well. Experiment
    
[^31]: 数据有效的 GAN 训练中的自我监督增强技术

    Augmentation-Aware Self-Supervision for Data-Efficient GAN Training. (arXiv:2205.15677v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.15677](http://arxiv.org/abs/2205.15677)

    本文提出一种增强感知的自监督判别器用于对生成数据及其增强参数的预测，从而提高判别器的表现和生成模型的性能，实现了数据有效的 GAN 训练。

    

    有限数据情况下训练生成式对抗网络（GAN）是具有挑战性的，因为判别器容易过拟合。先前提出的可微增强技术改善了GAN训练的数据效率。但是，增强技术隐式地引入了不良不变性因素，因为它忽略了由数据转换引起的标签空间语义变化，这可能限制了判别器的表示学习能力，并最终影响生成模型的表现。为了减轻不变性的负面影响，同时继承数据增强的好处，我们提出了一种新的增强感知的自监督判别器，该判别器可以预测增强数据的参数。特别地，真实数据和生成数据的预测目标在训练过程中需要区别开来。我们还鼓励生成器对抗地生成其增强参数可以被判别器准确预测的数据，从而获得更多信息量和更高效的判别器，提高生成模型的性能。多个数据集上的实验表明，我们的方法在数据有效的 GAN 训练中实现了最先进的性能。

    Training generative adversarial networks (GANs) with limited data is challenging because discriminator is prone to overfitting. Previously proposed differentiable augmentation demonstrates improved data efficiency of training GANs. However, the augmentation implicitly introduces undesired invariance to augmentation for the discriminator since it ignores the change of semantics in the label space caused by data transformation, which may limit the representation learning ability of the discriminator and ultimately affect the generative modeling performance of the generator. To mitigate the negative impact of invariance while inheriting the benefits of data augmentation, we propose a novel augmentation-aware self-supervised discriminator that predicts the augmentation parameter of the augmented data. Particularly, the prediction targets of real data and generated data are required to be distinguished since they are different during training. We further encourage the generator to adversari
    

