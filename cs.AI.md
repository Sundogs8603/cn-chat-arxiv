# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Matching Patients to Clinical Trials with Large Language Models.](http://arxiv.org/abs/2307.15051) | 本研究调查了使用大型语言模型（LLMs）来帮助患者和转诊医生识别合适的临床试验的潜力，并引入了TrialGPT架构，该架构能够准确预测合格性并提供解释，实验证明其有效性。 |
| [^2] | [Universal and Transferable Adversarial Attacks on Aligned Language Models.](http://arxiv.org/abs/2307.15043) | 这项研究提出了一种简单而有效的攻击方法，能够使对齐的语言模型生成不良行为，而不依赖于人工设计，通过自动化方法产生对抗性后缀，并在实践中取得改进。 |
| [^3] | [SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark.](http://arxiv.org/abs/2307.15020) | 提出了一个全面的中文大型语言模型基准测试SuperCLUE，包括实际用户的查询和评级、开放性问题以及封闭性问题，该基准测试填补了目前对模型在实际应用中能力理解的空白。 |
| [^4] | [How Good is Google Bard's Visual Understanding? An Empirical Study on Open Challenges.](http://arxiv.org/abs/2307.15016) | 本研究探索了Google Bard在理解和解释文本问题条件下的视觉数据方面的能力，并发现Bard在各种视觉场景中仍然存在困境，这凸显出在视觉理解方面存在重要的差距。 |
| [^5] | [A LLM Assisted Exploitation of AI-Guardian.](http://arxiv.org/abs/2307.15008) | 本文研究了LLM是否能辅助进行对抗性机器学习研究，以AI-Guardian为案例评估了其鲁棒性。研究发现，我们成功破解了AI-Guardian的防御机制，并且通过指示和引导GPT-4实施攻击算法的方法非常有效和高效。 |
| [^6] | [Thinker: Learning to Plan and Act.](http://arxiv.org/abs/2307.14993) | Thinker算法通过引入世界模型和模型交互动作使强化学习代理实现自主规划，消除了手工设计规划算法的需求，并且在Sokoban游戏和Atari 2600基准测试中取得了state-of-the-art的性能。 |
| [^7] | [Multilingual Code Co-Evolution Using Large Language Models.](http://arxiv.org/abs/2307.14991) | 本文介绍了使用大型语言模型（LLMs）将代码更改从一种编程语言翻译到另一种编程语言的方法。通过设计和实现第一个LLM，Codeditor，以将代码更改建模为编辑序列，并学习不同编程语言之间的关联性，我们为多语言代码共同演进提供了一种新的解决方法。 |
| [^8] | [Take-A-Photo: 3D-to-2D Generative Pre-training of Point Cloud Models.](http://arxiv.org/abs/2307.14971) | 本文提出了一种新的三维到二维的生成式预训练方法，通过生成视图图像作为预训练方案，帮助三维模型更好地理解点云的几何结构和立体关系，并在实验证明了其优越性。 |
| [^9] | [Multi-Source Domain Adaptation through Dataset Dictionary Learning in Wasserstein Space.](http://arxiv.org/abs/2307.14953) | 本文提出了一种基于字典学习和最优传输的MSDA框架，通过将每个域表示为字典原子的Wasserstein重心来缓解数据分布偏移。根据该字典，提出了两种新的MSDA方法，分别基于目标域标记样本的重构和在原子分布上学习的分类器的集成。在多个基准测试集上进行的实验证明，这些方法在分类任务上取得了显著的改进效果。 |
| [^10] | [PanGu-Coder2: Boosting Large Language Models for Code with Ranking Feedback.](http://arxiv.org/abs/2307.14936) | 本文提出了一种新的框架RRTF，以增强预训练的大型语言模型在代码生成方面的能力。PanGu-Coder2是该框架的实现，在多个基准测试中均表现出色，优于其他先前的Code LLMs。 |
| [^11] | [Solving Data Quality Problems with Desbordante: a Demo.](http://arxiv.org/abs/2307.14935) | Desbordante是一个旨在解决数据质量问题的工具，通过发现和验证复杂统计信息来帮助现代数据科学家进行数据概要分析。它提供了与现有工具的适当集成，同时考虑到工业级工作负载，并提供描述性的解释来解释模式缺失的原因。 |
| [^12] | [Scaling Session-Based Transformer Recommendations using Optimized Negative Sampling and Loss Functions.](http://arxiv.org/abs/2307.14906) | 本文介绍了一种使用优化的负采样和损失函数扩展基于会话的Transformer推荐系统，该系统在大规模电商数据集上通过集成负采样和列表损失函数实现了较高的推荐准确性，并在实践中表现出潜力。 |
| [^13] | [CodeLens: An Interactive Tool for Visualizing Code Representations.](http://arxiv.org/abs/2307.14902) | CodeLens是一种可视化代码表示的交互式工具，支持多种表示方法和编程语言，开发人员能够快速理解和探索代码。 |
| [^14] | [Base-based Model Checking for Multi-Agent Only Believing (long version).](http://arxiv.org/abs/2307.14893) | 该论文提出了一种基于信念基扩展的多智能体仅信任模型验证方法，包括自动检查公式的PSPACE算法和探索状态空间的专用算法。 |
| [^15] | [Weakly Supervised Multi-Modal 3D Human Body Pose Estimation for Autonomous Driving.](http://arxiv.org/abs/2307.14889) | 通过强大的弱监督方法，在自动驾驶领域中，我们提出了一种简单且高效的多模态3D人体姿势估计方法，通过相机和激光雷达数据之间的高级传感器融合，无需2D/3D关键点标签，在目标数据集上进行训练，实现准确的3D姿势估计。 |
| [^16] | [Exploiting the Potential of Seq2Seq Models as Robust Few-Shot Learners.](http://arxiv.org/abs/2307.14856) | Seq2Seq模型作为少样本学习器的潜力在解码器和编码-解码模型中进行了广泛研究，提出了两种能有效提升Seq2Seq模型上下文学习能力的方法，并在各种任务中显示出显著的性能改进。 |
| [^17] | [Counterfactual Explanations for Graph Classification Through the Lenses of Density.](http://arxiv.org/abs/2307.14849) | 本文提出了一种基于密度的反事实搜索框架，利用图的主要特征生成图分类器的实例级反事实解释。 |
| [^18] | [Hybrid ASP-based multi-objective scheduling of semiconductor manufacturing processes (Extended version).](http://arxiv.org/abs/2307.14799) | 本研究通过混合ASP方法解决了实际半导体制造过程的调度问题，将其具体要求建模，并且实现了灵活的机器加工、设置、批处理和维护操作。 |
| [^19] | [Emotion4MIDI: a Lyrics-based Emotion-Labeled Symbolic Music Dataset.](http://arxiv.org/abs/2307.14783) | Emotion4MIDI是一个包含12k个带情感标签的符号音乐数据集，通过在GoEmotions数据集上训练情感分类模型，并应用于两个大规模的MIDI数据集的歌词，提供了一个宝贵的资源来探索音乐和情感之间的联系，并开发可以根据特定情感生成音乐的模型。 |
| [^20] | [Fair Machine Unlearning: Data Removal while Mitigating Disparities.](http://arxiv.org/abs/2307.14754) | 本研究提出了第一个能够可靠而高效地遗忘数据实例并保持公平性的机器学习方法。 |
| [^21] | [Exploring Annotation-free Image Captioning with Retrieval-augmented Pseudo Sentence Generation.](http://arxiv.org/abs/2307.14750) | 本文提出了一种新的无注释图像字幕生成的策略，利用大规模预训练模型的先验知识作为监督，并整合检索过程以进一步增强其效力。该方法能够从不匹配的语料库中检索相关的短区域描述，并利用其生成多样的句子。 |
| [^22] | [New Interaction Paradigm for Complex EDA Software Leveraging GPT.](http://arxiv.org/abs/2307.14740) | 本研究通过开发SmartonAI插件，基于GPT和BERT等大型语言模型，提供一种新的交互范式来解决EDA软件中初学者面临的复杂命令结构和高学习曲线问题。 |
| [^23] | [Evaluating Generative Models for Graph-to-Text Generation.](http://arxiv.org/abs/2307.14712) | 本文评估了生成模型在图文生成中的应用，并发现生成模型能够生成流畅并连贯的文本。然而，生成模型仍然困难理解实体之间的语义关系，并且容易生成带有幻觉或无关信息的文本。 |
| [^24] | [Prediction of wind turbines power with physics-informed neural networks and evidential uncertainty quantification.](http://arxiv.org/abs/2307.14675) | 本研究使用物理信息神经网络对风力涡轮机的历史数据进行建模，通过施加物理约束，成功地预测了涡轮机的功率、转矩和功率系数。这对于优化涡轮机运行和早期故障检测具有重要的实际应用价值。 |
| [^25] | [Fuzzy order-sorted feature logic.](http://arxiv.org/abs/2307.14669) | 本文将有序特征逻辑推广到模糊设置中，并给出了模糊的OSF逻辑语义。通过扩展包含关系到OSF术语，我们构成了一个模糊偏序。 |
| [^26] | [Multi-Valued Partial Order Plans in Numeric Planning.](http://arxiv.org/abs/2307.14660) | 本文研究了数值规划中的多值偏序计划，在分析可能导致不可判定性的原因时，通过研究动作发生次数的不同情况。通过重新定义限制任务为搜索问题，并使用启发式方法找到数值规划的一个NP完全片段。通过开发多值偏序计划的想法，实现了最小承诺的紧凑表示方法。该表示方法的优化技术能够纳入软先决条件。 |
| [^27] | [Fact-Checking of AI-Generated Reports.](http://arxiv.org/abs/2307.14634) | 本文提出了一种使用相关联的图像对AI生成报告进行事实核查的新方法，以区分报告中的真假句子。这对加快临床工作流程，提高准确性并降低总体成本具有重要意义。 |
| [^28] | [Metric-Based In-context Learning: A Case Study in Text Simplification.](http://arxiv.org/abs/2307.14632) | 本文针对文本简化进行了一个案例研究，提出了一种基于度量的上下文学习（MBL）方法，通过选择具有顶级SARI得分的示例，可以在较大型的GPT模型上获得最佳表现。而在较小型的模型上，通过选择具有较高压缩比例的示例表现更好。 |
| [^29] | [BubbleML: A Multi-Physics Dataset and Benchmarks for Machine Learning.](http://arxiv.org/abs/2307.14623) | BubbleML是一个用于机器学习的多物理数据集，通过物理驱动模拟获得准确的地面真实信息，并在各种沸腾场景中验证了其可靠性和潜力。 |
| [^30] | [Self-Contrastive Graph Diffusion Network.](http://arxiv.org/abs/2307.14613) | 提出了一种名为自对比图扩散网络（SCGDN）的新型框架，通过注意力模块和扩散模块实现对高阶结构和特征信息的优秀嵌入。与现有的方法不同，SCGDN是一种无增强的方法，避免了“采样偏差”和语义漂移问题。 |
| [^31] | [Clustering based Point Cloud Representation Learning for 3D Analysis.](http://arxiv.org/abs/2307.14605) | 这篇论文提出了一种基于聚类的点云表示学习方法，用于3D分析。通过在点嵌入空间进行类内聚类，自动发现跨场景的子类模式，然后利用这些模式重新绘制嵌入空间，以提高点云分析性能。 |
| [^32] | [The detection and rectification for identity-switch based on unfalsified control.](http://arxiv.org/abs/2307.14591) | 本文提出了一种基于未被伪造的控制的多目标跟踪方法，针对身份交换问题设计了检测和修正模块，以及解决外观信息模糊匹配的策略，并在实验中展示了其出色的效果和鲁棒性。 |
| [^33] | [Explainable Techniques for Analyzing Flow Cytometry Cell Transformers.](http://arxiv.org/abs/2307.14581) | 本文针对流式细胞术数据提出了一种基于ReluFormer的transformer架构，以及针对FCM量身定制的基于梯度和注意力的可视化技术。通过对儿童急性淋巴白血病（ALL）FCM样本的实验，我们展示了模型的决策过程，并演示了如何利用这些技术来检查训练后的模型。 |
| [^34] | [A Memory-Augmented Multi-Task Collaborative Framework for Unsupervised Traffic Accident Detection in Driving Videos.](http://arxiv.org/abs/2307.14575) | 在本论文中，我们提出了一种记忆增强的多任务协作框架，用于无监督驾驶视频交通事故检测，以解决驾驶场景中长尾分布的驾驶事件可能带来的潜在危险。该方法不仅能够克服相机移动和光照变化对外观方法的干扰，还能够捕捉视频帧中的外观变化，实现对与自身相关的事故的检测。 |
| [^35] | [Evaluation of Safety Constraints in Autonomous Navigation with Deep Reinforcement Learning.](http://arxiv.org/abs/2307.14568) | 本研究评估了在深度强化学习中考虑安全约束的自主导航，在比较了安全和不安全两种学习策略后发现，安全策略能够生成更安全的轨迹，避免碰撞，而不影响整体性能。 |
| [^36] | [Reinforcement learning guided fuzz testing for a browser's HTML rendering engine.](http://arxiv.org/abs/2307.14556) | 本文提出了一种基于强化学习的方法，将训练好的测试用例生成模型与双深度Q网络结合，用于模糊测试浏览器的HTML渲染引擎，提高了代码覆盖性能。基于基础语法模糊器相比，代码覆盖率提高了18.5%。 |
| [^37] | [Adversarial Sleeping Bandit Problems with Multiple Plays: Algorithm and Ranking Application.](http://arxiv.org/abs/2307.14549) | 本论文提出了解决在线推荐系统中具有多个游戏的睡眠赌博问题的高效算法，该算法能够保证理论性能，并且后悔上界为$\bigO(kN^2\sqrt{T\log T})$。 |
| [^38] | [Speed Reading Tool Powered by Artificial Intelligence for Students with ADHD, Dyslexia, or Short Attention Span.](http://arxiv.org/abs/2307.14544) | 这项研究提出了一种基于人工智能的速读工具，用于帮助患有ADHD、诵读困难或注意力不集中的学生更高效地消化文本信息。该工具利用多层感知机算法和T5模型，通过文本处理和摘要任务实现。同时，该工具还应用了仿生阅读原则来增强可读性。 |
| [^39] | [Open Problems in Computer Vision for Wilderness SAR and The Search for Patricia Wu-Murad.](http://arxiv.org/abs/2307.14527) | 该论文介绍了在荒野搜救中应用计算机视觉系统的挑战，提出了使用EfficientDET模型和无监督RX光谱分类器的方法，但在真实世界中存在假阳性的问题。 |
| [^40] | [Patterns of Vehicle Lights: Addressing Complexities in Curation and Annotation of Camera-Based Vehicle Light Datasets and Metrics.](http://arxiv.org/abs/2307.14521) | 本论文探讨了计算机视觉中车辆灯光的表示及其在自动驾驶中的应用。提出了三个重要任务：夜间车辆检测、3D车辆方向估计和动态轨迹线索。介绍了LISA车辆灯光数据集和相关的灯光可见性模型，可用于车辆检测、意图和轨迹预测以及安全路径规划。进行了比较分析。 |
| [^41] | [The Co-12 Recipe for Evaluating Interpretable Part-Prototype Image Classifiers.](http://arxiv.org/abs/2307.14517) | 本文提出了一种用于评估可解释的部件原型图像分类器的Co-12配方，并回顾了现有工作，揭示了研究的空白，并概述了评估部件原型模型解释质量的未来方法。这对于这个相对较新的研究领域的进展和成熟具有重要意义。 |
| [^42] | [Words That Stick: Predicting Decision Making and Synonym Engagement Using Cognitive Biases and Computational Linguistics.](http://arxiv.org/abs/2307.14511) | 这项研究使用认知偏差和计算语言学预测用户参与度和决策过程，发现准确代表核心思想、易于理解、能够引发情感反应并且常见的同义词能够促进更高的用户参与度。 |
| [^43] | [Attention of Robot Touch: Tactile Saliency Prediction for Robust Sim-to-Real Tactile Control.](http://arxiv.org/abs/2307.14510) | 这篇论文提出了一种新的概念——机器人触觉的“触觉显著性”，通过借鉴人类触觉注意机制和计算机视觉中的视觉显著性预测问题，提高了非结构化环境下触觉机器人控制的鲁棒性。 |
| [^44] | [Improving Reliable Navigation under Uncertainty via Predictions Informed by Non-Local Information.](http://arxiv.org/abs/2307.14501) | 通过使用非本地信息进行预测，我们改进了在不确定环境下的可靠导航方法，并进行了实验证明在大规模大学建筑环境中可以减少9.3％的成本。 |
| [^45] | [Technical note: ShinyAnimalCV: open-source cloud-based web application for object detection, segmentation, and three-dimensional visualization of animals using computer vision.](http://arxiv.org/abs/2307.14487) | ShinyAnimalCV是一个开源的云平台网络应用，用于动物的物体检测、分割和三维可视化，解决了将计算机视觉工具应用于动物数据的挑战，同时也满足了动物科学教育的需求。 |
| [^46] | [Single Channel Speech Enhancement Using U-Net Spiking Neural Networks.](http://arxiv.org/abs/2307.14464) | 本文提出了一种基于U-Net脉冲神经网络的单通道语音增强方法，该方法在提供可靠增强效果的同时，具有较低的计算能力和能耗需求。 |
| [^47] | [VISPUR: Visual Aids for Identifying and Interpreting Spurious Associations in Data-Driven Decisions.](http://arxiv.org/abs/2307.14448) | VISPUR是一个提供视觉分析和人本工作流程的系统，用于识别和解释数据驱动决策中的虚假关联。它包括混淆因素仪表盘和子群浏览器，可以帮助人们定位、推理和预防虚假关联。 |
| [^48] | [Unsupervised Deep Learning-based Pansharpening with Jointly-Enhanced Spectral and Spatial Fidelity.](http://arxiv.org/abs/2307.14403) | 这篇论文提出了一个基于无监督深度学习的Pansharpening模型，通过全分辨率训练和特定损失函数的使用，充分利用了这种方法的潜力，具有优秀的性能。 |
| [^49] | [Non-Linear Self Augmentation Deep Pipeline for Cancer Treatment outcome Prediction.](http://arxiv.org/abs/2307.14398) | 该论文提出了一种在癌症治疗结果预测中应用非线性自我增强深度管道的创新策略，通过选择和增强CT图像中的2D特征，提高了预测能力。 |
| [^50] | [Learning to simulate partially known spatio-temporal dynamics with trainable difference operators.](http://arxiv.org/abs/2307.14395) | 本文提出了一种新的混合架构PDE-Net++，通过结合可训练差分算子和黑盒模型，明确嵌入了底层PDE的部分先验知识。数值实验证明，PDE-Net++具有比黑盒模型更高的预测准确性和更好的外推性能。 |
| [^51] | [Dual-Space Attacks against Random-Walk-based Anomaly Detection.](http://arxiv.org/abs/2307.14387) | 本文考察了随机游走异常检测(RWAD)面临的图空间攻击和特征空间攻击，证明了攻击RWAD的复杂度是NP难的，并提出了两种攻击策略，进一步通过图引导攻击设计了更强大的特征空间攻击。 |
| [^52] | [HyperFed: Hyperbolic Prototypes Exploration with Consistent Aggregation for Non-IID Data in Federated Learning.](http://arxiv.org/abs/2307.14384) | 提出了HyperFed，用于解决联邦学习中非相同和独立数据分布造成的性能问题。该方法通过超球面原型探索、超球面原型学习和一致聚合等模块的结合，来解决类别统计的变化、层级信息利用不足和客户端聚合的不一致性问题。 |
| [^53] | [When Multi-Task Learning Meets Partial Supervision: A Computer Vision Review.](http://arxiv.org/abs/2307.14382) | 本综述讨论了多任务学习如何在部分监督设置下应用，以解决由于复杂的优化方案和高标签需求而引入的挑战。 |
| [^54] | [EdgeConvEns: Convolutional Ensemble Learning for Edge Intelligence.](http://arxiv.org/abs/2307.14381) | EdgeConvEns是一种卷积集成学习方法，用于在边缘网络上训练和集成异构的弱模型，以满足计算能力有限和分布式数据处理的需求。 |
| [^55] | [How Can Large Language Models Help Humans in Design and Manufacturing?.](http://arxiv.org/abs/2307.14377) | 大型语言模型在设计和制造中的应用潜力以及其限制 |
| [^56] | [Synthesis of Procedural Models for Deterministic Transition Systems.](http://arxiv.org/abs/2307.14368) | 本文介绍了一种通用方法，用于综合离散系统的状态过渡的过程化模型，并采用归纳式综合方法。该方法可以接受不同目标语言并应用于不同模型获取任务，从而实现了结构化程序的综合。 |
| [^57] | [Federated Distributionally Robust Optimization with Non-Convex Objectives: Algorithm and Analysis.](http://arxiv.org/abs/2307.14364) | 本文提出了一个名为ASPIRE算法的异步分布式算法，用于解决联邦分布鲁棒优化问题，并引入了约束的D-范数不确定性集合，以灵活控制鲁棒性的程度。 |
| [^58] | [A Hybrid Machine Learning Model for Classifying Gene Mutations in Cancer using LSTM, BiLSTM, CNN, GRU, and GloVe.](http://arxiv.org/abs/2307.14361) | 本研究提出了一个基于多种机器学习算法和嵌入模型的集成模型，用于基因突变在癌症中的分类。实验结果表明，该模型在准确率、精确率、召回率等指标上优于其他传统和最新的转换器模型，并且具有更高的训练效率。 |
| [^59] | [Framing Relevance for Safety-Critical Autonomous Systems.](http://arxiv.org/abs/2307.14355) | 该论文旨在开发一种形式化方法来确定安全关键的自主系统在当前任务下的相关信息，以构建适当的世界观以实现其目标。 |
| [^60] | [Copilot for Xcode: Exploring AI-Assisted Programming by Prompting Cloud-based Large Language Models.](http://arxiv.org/abs/2307.14349) | Copilot for Xcode是一种AI辅助编程工具，通过集成基于云的大型语言模型与Apple的本地开发环境Xcode，提高了软件开发人员的生产力和创造力。它利用NLP技术处理源代码标记和模式，并提供代码生成、自动补全、文档编写和错误检测等功能。用户还可以在聊天界面中进行查询和"小"决策的制定。该工具在Xcode中使用NLP激励编程已经证明有效。 |
| [^61] | [Multi-objective Deep Reinforcement Learning for Mobile Edge Computing.](http://arxiv.org/abs/2307.14346) | 本研究提出了一种多目标深度强化学习方法，以解决移动边缘计算中的离线问题。该方法通过考虑未知偏好参数，最小化能耗和传输延迟，并采用近端策略优化算法进行资源调度。引入了一种特征构建方法，用于处理MEC系统中的多个边缘。 |
| [^62] | [Pruning Distorted Images in MNIST Handwritten Digits.](http://arxiv.org/abs/2307.14343) | 本论文提出了一个两阶段的深度学习方法，通过识别和剔除扭曲和模糊图像，从而提高了MNIST数据集中手写数字的分类准确性和置信度。 |
| [^63] | [How to Scale Your EMA.](http://arxiv.org/abs/2307.13813) | 本研究提供了在存在模型EMA的情况下进行优化的缩放规则，以保持训练动态的一致性。这对于实际机器学习中的权衡批量大小和墙钟时间非常重要。模型EMA能够提高模型的性能以及稳定训练过程，并为自监督学习提供学习信号。 |
| [^64] | [Deep Bradley-Terry Rating: Estimate Properties Without Metric of Unseen Items.](http://arxiv.org/abs/2307.13709) | 本论文提出了深度布拉德利-特里评分（DBTR）方法，用于评估不一定存在于数据集中的未知物品的属性。该方法通过将传统的布拉德利-特里模型与神经网络结构无缝结合，成功地学习了这些属性的预期量化。 |
| [^65] | [Duet: efficient and scalable hybriD neUral rElation undersTanding.](http://arxiv.org/abs/2307.13494) | Duet是一种高效且可扩展的混合神经关系理解方法，旨在解决基数估计问题中高成本和难以区分的采样方法，并通过可微分的预测过程改进模型的准确性。 |
| [^66] | [Empower Your Model with Longer and Better Context Comprehension.](http://arxiv.org/abs/2307.13365) | 本文研究了大语言模型（LLMs）内的信息传递，并提出了一种名为注意力转移的技术，该技术能够使模型在不增加训练或对生成流畅性的影响的情况下实现更长更好的上下文理解。 |
| [^67] | [On the Vulnerability of Fairness Constrained Learning to Malicious Noise.](http://arxiv.org/abs/2307.11892) | 这项研究考虑了公正约束学习对恶意噪声的脆弱性，发现使用随机分类器可以在精度上只损失$\Theta(\alpha)$和$O(\sqrt{\alpha})$，对应不同的公正约束要求。 |
| [^68] | [Deep Directly-Trained Spiking Neural Networks for Object Detection.](http://arxiv.org/abs/2307.11411) | EMS-YOLO是一种直接训练的脉冲神经网络框架，通过使用替代梯度而不是ANN-SNN转换策略，成功解决了深度SNN的目标检测问题。 |
| [^69] | [Information Retrieval Meets Large Language Models: A Strategic Report from Chinese IR Community.](http://arxiv.org/abs/2307.09751) | 本论文总结了中国信息检索界关于信息检索与大型语言模型相结合的战略报告。大型语言模型在文本理解、生成和知识推理方面具有出色能力，为信息检索研究开辟了新的方向。此外，IR模型、LLM和人类之间的协同关系形成了一种更强大的信息寻求技术范式。然而，该领域仍面临计算成本、可信度、领域特定限制和伦理考虑等挑战。 |
| [^70] | [Artificial intelligence is algorithmic mimicry: why artificial "agents" are not (and won't be) proper agents.](http://arxiv.org/abs/2307.07515) | 本研究通过对比生物系统和算法系统，指出了生物系统具有自我制造自主能力、符号和物理方面没有区分以及体验到模糊问题的大世界等特点，而算法系统则与此相反。 |
| [^71] | [GP-guided MPPI for Efficient Navigation in Complex Unknown Cluttered Environments.](http://arxiv.org/abs/2307.04019) | 本研究提出了一种GP引导的MPPI方法用于在复杂未知杂乱环境中进行高效导航。该方法利用局部感知模型和在线学习技术，通过构建不确定性表面，识别并推荐最优子目标给局部的MPPI规划器。最终实现了满足要求的最优控制序列。 |
| [^72] | [Mining Clues from Incomplete Utterance: A Query-enhanced Network for Incomplete Utterance Rewriting.](http://arxiv.org/abs/2307.00866) | 这篇论文提出了一种增强查询的网络用于不完整话语重写，通过引入查询模板来明确语义结构知识，并采用有效的编辑操作评分网络来建模两个标记之间的关系。在多个公共数据集上，该模型取得了最先进的性能。 |
| [^73] | [Identifiability of direct effects from summary causal graphs.](http://arxiv.org/abs/2306.16958) | 该论文研究了在缺乏完整时间因果图的情况下，直接因果效应如何从总结因果图中进行可辨识，并提出了一个完整的可辨识性结果。 |
| [^74] | [Fine-Tuned but Zero-Shot 3D Shape Sketch View Similarity and Retrieval.](http://arxiv.org/abs/2306.08541) | 这项研究关注个体3D实例的多模态2D投影，发现在零-shot环境中，草图越抽象，错误图像匹配的可能性越高。另外，细调一个形状类别的3D模型可以提高其他形状类别的性能。 |
| [^75] | [Automating Model Comparison in Factor Graphs.](http://arxiv.org/abs/2306.05965) | 本文基于自定义混合节点 Forney 样式的因子图消息传递，实现了高效自动化贝叶斯模型平均、选择和组合，并缩短了模型设计周期。 |
| [^76] | [AI Art Curation: Re-imagining the city of Helsinki in occasion of its Biennial.](http://arxiv.org/abs/2306.03753) | 本研究通过AI策展和观众互动，利用机器学习模型重新构想了赫尔辛基市艺术双年展，使用视觉-文本模型将室内艺术品放置在公共空间中，生成合成的360艺术全景图，以创造出艺术品与城市空间的新视角。 |
| [^77] | [Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse Engineering of Language at Scale.](http://arxiv.org/abs/2306.00017) | 本文提出结合符号表示和自下而上的逆向工程的方法，解决大规模语言模型在真正语言理解上的局限性，实现可解释的、语言无关的LLMs。 |
| [^78] | [PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning.](http://arxiv.org/abs/2305.19472) | PlaSma提出了一种使用小型语言模型进行过程知识和计划能力的新方法， |
| [^79] | [Science in the Era of ChatGPT, Large Language Models and Generative AI: Challenges for Research Ethics and How to Respond.](http://arxiv.org/abs/2305.15299) | 这篇论文回顾了生成AI对科学研究所带来的认识论挑战、伦理和诚信风险，并提出了十项建议，以在AI时代促进更负责任的研究进行。 |
| [^80] | [A Confidence-based Partial Label Learning Model for Crowd-Annotated Named Entity Recognition.](http://arxiv.org/abs/2305.12485) | 本论文提出了一种基于置信度的部分标签学习方法（CPLL）用于群体注释的命名实体识别。该模型通过迭代更新真实后验和置信度，通过最小化经验风险学习一个基于标记和内容的置信度，实验结果表明该方法能够提高NER的性能。 |
| [^81] | [SUG: Single-dataset Unified Generalization for 3D Point Cloud Classification.](http://arxiv.org/abs/2305.09160) | 本文提出了一种单数据集统一泛化（SUG）框架，通过多细粒度子域对齐和样本级域感知注意力策略，解决了三维点云领域泛化问题。 |
| [^82] | [Differential Convolutional Fuzzy Time Series Forecasting.](http://arxiv.org/abs/2305.08890) | 本文提出了一种新的预测模型DFCNN，利用卷积神经网络实现具有可学习能力的FTSF，并能够处理非平稳时间序列。 |
| [^83] | [Introducing Tales of Tribute AI Competition.](http://arxiv.org/abs/2305.08234) | 这项论文介绍了一项新的人工智能挑战——致敬神话人工智能竞赛(TOTAIC)，该竞赛基于《上古卷轴在线》中的一款卡牌游戏。除了应对通常与CCG相关的挑战外，该挑战还需要长期规划和适应性。竞赛采用多种方法解决游戏，如对抗搜索、单人计划和神经网络算法。第一届TOTAIC将在2023年的IEEE游戏会议上举行。 |
| [^84] | [Synergies Between Federated Learning and O-RAN: Towards an Elastic Virtualized Architecture for Multiple Distributed Machine Learning Services.](http://arxiv.org/abs/2305.02109) | 本文研究了联邦学习在现代无线网络下的挑战，提出了一种方法称为动态多服务联邦学习（DMS-FL）来解决这个问题。同时，还提出了一种名为弹性虚拟化联邦学习（EV-FL）的分布式机器学习架构，来支持DMS-FL中的设计要求。 |
| [^85] | [CAR-DESPOT: Causally-Informed Online POMDP Planning for Robots in Confounded Environments.](http://arxiv.org/abs/2304.06848) | 本文提出了一种新的因果关系在线POMDP规划方法CAR-DESPOT，使用因果建模和推理来消除未测量混淆变量引起的错误，并在混杂环境中表现优异。 |
| [^86] | [Empirical analysis of Different Dimensionality Reduction and classification Techniques for Epileptic Seizure detection.](http://arxiv.org/abs/2302.12012) | 本研究对使用不同降维和分类技术进行癫痫发作检测进行了实证分析，通过离散小波变换和机器学习分类器，结合主成分分析、独立成分分析和线性判别分析等降维算法，选择特征来提高检测准确性。 |
| [^87] | [Algorithmic Hallucinations of Near-Surface Winds: Statistical Downscaling with Generative Adversarial Networks to Convection-Permitting Scales.](http://arxiv.org/abs/2302.08720) | 本论文将新兴的图像超分辨率技术应用于统计降尺度任务，具体探索了基于生成对抗网络的算法在模拟北美地区地表风中的应用。通过使用非理想化的低分辨率和高分辨率输入数据，该方法克服了共享尺度不匹配的问题，并通过评估空间功率谱等指标来评估模型的技能。 |
| [^88] | [Causal Lifting and Link Prediction.](http://arxiv.org/abs/2302.01198) | 本文开发了第一个能够处理链路预测中路径依赖的因果模型，并介绍了因果提升的概念，通过有限的干预数据识别因果链路预测查询。 |
| [^89] | [ThoughtSource: A central hub for large language model reasoning data.](http://arxiv.org/abs/2301.11596) | ThoughtSource是一个用于连续思考推理的元数据集和软件库，旨在通过促进对连续思考的定性理解、实证评估和提供训练数据，改进未来的人工智能系统。 |
| [^90] | [Towards Better Generalization with Flexible Representation of Multi-Module Graph Neural Networks.](http://arxiv.org/abs/2209.06589) | 本研究探讨了图神经网络在推广到更大的图和从未见过的数据方面的局限，并提出了多模块GNN框架，通过推广单个规范非线性变换来适应新图。结果表明，多模块GNN在合成和实际数据集上均显著提高了GNN的泛化能力，并在几项具有挑战性的任务上实现了最先进的性能。 |
| [^91] | [Learning Task Automata for Reinforcement Learning using Hidden Markov Models.](http://arxiv.org/abs/2208.11838) | 本文提出了一种学习非马尔可夫任务规范的新方法，通过从代理经验中学习，将其表示为有限状态的任务自动机。利用隐马尔可夫模型和新的提炼方法，使得代理能够解决稀疏和非马尔可夫奖励的强化学习任务。 |
| [^92] | [On the non-efficient PAC learnability of conjunctive queries.](http://arxiv.org/abs/2208.10255) | 这篇论文阐述了连词查询在PAC模型中的非高效可学习性，针对不同变种的连词查询提出了负面可学习性结果，并展示了通过成员查询可以高效学习连词查询和UCQs。 |
| [^93] | [Runtime Analysis for Permutation-based Evolutionary Algorithms.](http://arxiv.org/abs/2207.04045) | 本文对基于排列的进化算法进行了运行时分析，并提出了一种通用方法将经典的伪布尔基准转化为基于排列集合定义的基准。研究发现，与位串不同，排列变异的困难程度不仅取决于汉明距离，还与排列的精确循环结构有关。 |
| [^94] | [Visual Pre-training for Navigation: What Can We Learn from Noise?.](http://arxiv.org/abs/2207.00052) | 本论文提出了一种使用随机裁剪预测进行自监督训练的视觉预训练方法，可以学习到对导航任务有用的表示，并通过自举学习有效地学习导航策略，减少对交互数据的需求。 |
| [^95] | [Trace Recovery from Stochastically Known Logs.](http://arxiv.org/abs/2206.12672) | 本文提出了一种从随机已知日志中恢复轨迹的算法，在两个公开数据集上平均恢复准确度达到90-97%。这一方法通过计算流程模型和随机已知轨迹的合规性，并恢复在该随机轨迹中的最佳对齐作为真实轨迹。对比其他轨迹恢复选项，使用了产品多图来分析成本模型对恢复准确性的影响。这一算法对于预测模型开发、错误排查和系统性能改进具有重要意义。 |
| [^96] | [Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning.](http://arxiv.org/abs/2205.14704) | 本论文提出了一种检索增强的提示学习方法，通过将知识从记忆中解耦，帮助模型在泛化和记忆之间取得平衡。 |
| [^97] | [Graph-Based Recommendation System Enhanced with Community Detection.](http://arxiv.org/abs/2201.03622) | 本文提出了一个基于图的推荐系统，利用数学和统计方法确定标签的相似性，包括词汇相似性和共现解决方案，并考虑了标签分配的时间，以提高推荐的准确性。 |
| [^98] | [Machine Learning with a Reject Option: A survey.](http://arxiv.org/abs/2107.11277) | 这项调查综述了机器学习中的拒绝选项。通过机器学习模型避免在可能犯错误时做出预测，可以在决策支持应用中避免严重后果。调查介绍了拒绝选项的条件、评估策略以及相关应用领域，并探讨了它与其他机器学习方法的关系。 |
| [^99] | [Dynamics of specialization in neural modules under resource constraints.](http://arxiv.org/abs/2106.02626) | 本研究使用人工神经网络模拟实验，发现结构模块化并不一定能够确保功能专业化，在特定环境和资源限制下，才能够出现专业化现象。 |
| [^100] | [DanceFormer: Music Conditioned 3D Dance Generation with Parametric Motion Transformer.](http://arxiv.org/abs/2103.10206) | 本文提出了一种名为DanceFormer的方法，通过两个级联的动力学增强的变换器引导网络来生成基于音乐的3D舞蹈。方法首先生成关键姿势，然后预测参数化运动曲线，使得舞蹈与音乐节奏对齐，并且提出了一个准确标记的大规模音乐条件下的3D舞蹈数据集PhantomDance。 |
| [^101] | [Deep Serial Number: Computational Watermarking for DNN Intellectual Property Protection.](http://arxiv.org/abs/2011.08960) | 本文提出了一种名为 Deep Serial Number (DSN) 的水印算法用于深度神经网络的知识产权保护。该算法在DNN中实现序列号嵌入，只有输入有效序列号的情况下，DNN才能正确工作。 |
| [^102] | [On the Generalization Effects of Linear Transformations in Data Augmentation.](http://arxiv.org/abs/2005.00695) | 这项研究考虑了一类线性转换，并研究了其在过参数化线性回归设置中对岭估计量的影响。研究发现，能够保持数据标签的转换可以通过扩大训练数据的张量来改善估计结果；而混合数据的转换则通过起到正则化作用来改善估计结果。此外，通过在MNIST数据集上进行验证，研究者提出了一个增强方案，该方案通过模型对转换后数据的不确定性进行搜索转换空间，并在图像和文本数据集上验证了其有效性。 |
| [^103] | [Declarative Mechanism Design.](http://arxiv.org/abs/1912.13122) | 本文介绍了声明性机制设计的研究，提出了机构神经网络作为一种受管制的人工神经网络，引起人们对人工教学的关注，并提供了初步的答案。 |

# 详细

[^1]: 使用大型语言模型将患者与临床试验匹配

    Matching Patients to Clinical Trials with Large Language Models. (arXiv:2307.15051v1 [cs.CL])

    [http://arxiv.org/abs/2307.15051](http://arxiv.org/abs/2307.15051)

    本研究调查了使用大型语言模型（LLMs）来帮助患者和转诊医生识别合适的临床试验的潜力，并引入了TrialGPT架构，该架构能够准确预测合格性并提供解释，实验证明其有效性。

    

    临床试验在推动药物研发和基于证据的医学方面非常重要，但患者招募常常受到限制。在这项工作中，我们调查了使用大型语言模型（LLMs）来帮助患者和转诊医生识别合适的临床试验的潜力。具体而言，我们引入了一种新颖的架构TrialGPT，采用LLMs预测基于标准的合格性，并提供详细的解释，并根据患者病历中的自由文本来对候选临床试验进行排名和排除。我们在三个公开可用的184名患者和18,238个注释的临床试验的队列上评估了TrialGPT。实验结果表明几个关键发现：第一，TrialGPT在标准级别的预测准确性上表现出很高的准确率，并提供准确的解释。第二，TrialGPT的综合试验级别评分与专家标注的合格性高度相关。第三，这些评分

    Clinical trials are vital in advancing drug development and evidence-based medicine, but their success is often hindered by challenges in patient recruitment. In this work, we investigate the potential of large language models (LLMs) to assist individual patients and referral physicians in identifying suitable clinical trials from an extensive selection. Specifically, we introduce TrialGPT, a novel architecture employing LLMs to predict criterion-level eligibility with detailed explanations, which are then aggregated for ranking and excluding candidate clinical trials based on free-text patient notes. We evaluate TrialGPT on three publicly available cohorts of 184 patients and 18,238 annotated clinical trials. The experimental results demonstrate several key findings: First, TrialGPT achieves high criterion-level prediction accuracy with faithful explanations. Second, the aggregated trial-level TrialGPT scores are highly correlated with expert eligibility annotations. Third, these scor
    
[^2]: 对齐语言模型上的通用和可迁移对抗攻击

    Universal and Transferable Adversarial Attacks on Aligned Language Models. (arXiv:2307.15043v1 [cs.CL])

    [http://arxiv.org/abs/2307.15043](http://arxiv.org/abs/2307.15043)

    这项研究提出了一种简单而有效的攻击方法，能够使对齐的语言模型生成不良行为，而不依赖于人工设计，通过自动化方法产生对抗性后缀，并在实践中取得改进。

    

    由于“开箱即用”的大型语言模型能够生成大量引起反感的内容，最新的研究专注于对齐这些模型，以防止产生不良生成。尽管在规避这些措施上取得了一些成功，所谓的对LLMs的“越狱”攻击，但这些攻击需要人为的巧思，实际上并不稳定。在本文中，我们提出了一种简单而有效的攻击方法，使对齐的语言模型生成不良行为。具体而言，我们的方法找到一个后缀，当附加到各种查询上，供LLM生成不良内容时，旨在最大化模型产生肯定回答（而不是拒绝回答）的概率。然而，与其依赖手工设计，我们的方法通过贪婪和基于梯度的搜索技术自动产生这些对抗性后缀，并且在过去的自动化方法上进行了改进。

    Because "out-of-the-box" large language models are capable of generating a great deal of objectionable content, recent work has focused on aligning these models in an attempt to prevent undesirable generation. While there has been some success at circumventing these measures -- so-called "jailbreaks" against LLMs -- these attacks have required significant human ingenuity and are brittle in practice. In this paper, we propose a simple and effective attack method that causes aligned language models to generate objectionable behaviors. Specifically, our approach finds a suffix that, when attached to a wide range of queries for an LLM to produce objectionable content, aims to maximize the probability that the model produces an affirmative response (rather than refusing to answer). However, instead of relying on manual engineering, our approach automatically produces these adversarial suffixes by a combination of greedy and gradient-based search techniques, and also improves over past autom
    
[^3]: SuperCLUE:一个全面的中文大型语言模型基准测试

    SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark. (arXiv:2307.15020v1 [cs.CL])

    [http://arxiv.org/abs/2307.15020](http://arxiv.org/abs/2307.15020)

    提出了一个全面的中文大型语言模型基准测试SuperCLUE，包括实际用户的查询和评级、开放性问题以及封闭性问题，该基准测试填补了目前对模型在实际应用中能力理解的空白。

    

    大型语言模型(LLMs)已经显示出将其整合到人们日常生活中的潜力。因此，用户偏好是评估LLMs在实际场景中表现的最关键标准。然而，现有的基准主要集中在使用多选题来衡量模型的准确性，这限制了对它们在实际应用中能力的理解。我们通过提出一个全面的中文基准测试SuperCLUE来填补这个空白，该基准测试以另一个流行的中文LLM基准测试CLUE命名。SuperCLUE包括三个子任务：来自一个LLM对战平台(CArena)的实际用户查询和评级，有单个和多轮对话的开放性问题(OPEN)，以及与开放性单轮问题相同茎的封闭性问题(CLOSE)。我们的研究表明，封闭性问题上的准确性不足以反映在开放性问题上实现的人类偏好。同时，它们可以互补地预测实际用户偏好。

    Large language models (LLMs) have shown the potential to be integrated into human daily lives. Therefore, user preference is the most critical criterion for assessing LLMs' performance in real-world scenarios. However, existing benchmarks mainly focus on measuring models' accuracy using multi-choice questions, which limits the understanding of their capabilities in real applications. We fill this gap by proposing a comprehensive Chinese benchmark SuperCLUE, named after another popular Chinese LLM benchmark CLUE. SuperCLUE encompasses three sub-tasks: actual users' queries and ratings derived from an LLM battle platform (CArena), open-ended questions with single and multiple-turn dialogues (OPEN), and closed-ended questions with the same stems as open-ended single-turn ones (CLOSE). Our study shows that accuracy on closed-ended questions is insufficient to reflect human preferences achieved on open-ended ones. At the same time, they can complement each other to predict actual user prefe
    
[^4]: Google Bard的视觉理解能力如何？开放挑战的实证研究。

    How Good is Google Bard's Visual Understanding? An Empirical Study on Open Challenges. (arXiv:2307.15016v1 [cs.CV])

    [http://arxiv.org/abs/2307.15016](http://arxiv.org/abs/2307.15016)

    本研究探索了Google Bard在理解和解释文本问题条件下的视觉数据方面的能力，并发现Bard在各种视觉场景中仍然存在困境，这凸显出在视觉理解方面存在重要的差距。

    

    Google的Bard在对话型人工智能领域与OpenAI的ChatGPT成为了强大的竞争对手。值得注意的是，Bard最近已经更新，可以在对话过程中处理文本提示和视觉输入。鉴于Bard在处理文本输入方面的出色表现，我们探索了其在理解和解释由文本问题条件下的视觉数据（图像）方面的能力。这种探索有潜力揭示Bard和其他即将发布的多模式生成模型在解决需要准确的视觉和语言理解的复杂计算机视觉问题时的新见解和挑战。具体而言，在这项研究中，我们专注于15个不同的任务场景，包括常规、伪装、医学、水下和遥感数据，全面评估了Bard的性能。我们的主要发现表明，Bard在这些视觉场景中仍然存在困境，突显了在基于视觉的理解方面存在的重要差距。

    Google's Bard has emerged as a formidable competitor to OpenAI's ChatGPT in the field of conversational AI. Notably, Bard has recently been updated to handle visual inputs alongside text prompts during conversations. Given Bard's impressive track record in handling textual inputs, we explore its capabilities in understanding and interpreting visual data (images) conditioned by text questions. This exploration holds the potential to unveil new insights and challenges for Bard and other forthcoming multi-modal Generative models, especially in addressing complex computer vision problems that demand accurate visual and language understanding. Specifically, in this study, we focus on 15 diverse task scenarios encompassing regular, camouflaged, medical, under-water and remote sensing data to comprehensively evaluate Bard's performance. Our primary finding indicates that Bard still struggles in these vision scenarios, highlighting the significant gap in vision-based understanding that needs t
    
[^5]: 通过LLM辅助，对AI-Guardian的攻击研究

    A LLM Assisted Exploitation of AI-Guardian. (arXiv:2307.15008v1 [cs.CR])

    [http://arxiv.org/abs/2307.15008](http://arxiv.org/abs/2307.15008)

    本文研究了LLM是否能辅助进行对抗性机器学习研究，以AI-Guardian为案例评估了其鲁棒性。研究发现，我们成功破解了AI-Guardian的防御机制，并且通过指示和引导GPT-4实施攻击算法的方法非常有效和高效。

    

    如今，大型语言模型（LLMs）在各种任务上都能够表现出很高的能力。本文研究了一种名为GPT-4的LLM是否能够辅助进行对抗性机器学习研究。以AI-Guardian为案例，我们评估了这个最近在IEEE S&P 2023上发表的针对对抗样本的防御机制的鲁棒性。我们完全破解了这个防御机制：与未防御的基线相比，所提出的方案并没有增加鲁棒性。我们并没有编写攻击该模型的代码，而是指示和引导GPT-4按照我们的指令实施所有攻击算法。这个过程出奇地有效和高效，有时候语言模型在不明确的指令下产生的代码比本文作者还要快。最后，我们讨论了（1）评估中出现的警示信号表明AI-Guardian将被攻破，以及（2）我们在设计和实施攻击方案时的经验。

    Large language models (LLMs) are now highly capable at a diverse range of tasks. This paper studies whether or not GPT-4, one such LLM, is capable of assisting researchers in the field of adversarial machine learning. As a case study, we evaluate the robustness of AI-Guardian, a recent defense to adversarial examples published at IEEE S&P 2023, a top computer security conference. We completely break this defense: the proposed scheme does not increase robustness compared to an undefended baseline.  We write none of the code to attack this model, and instead prompt GPT-4 to implement all attack algorithms following our instructions and guidance. This process was surprisingly effective and efficient, with the language model at times producing code from ambiguous instructions faster than the author of this paper could have done. We conclude by discussing (1) the warning signs present in the evaluation that suggested to us AI-Guardian would be broken, and (2) our experience with designing a
    
[^6]: Thinker: 学习规划和行动

    Thinker: Learning to Plan and Act. (arXiv:2307.14993v1 [cs.AI])

    [http://arxiv.org/abs/2307.14993](http://arxiv.org/abs/2307.14993)

    Thinker算法通过引入世界模型和模型交互动作使强化学习代理实现自主规划，消除了手工设计规划算法的需求，并且在Sokoban游戏和Atari 2600基准测试中取得了state-of-the-art的性能。

    

    我们提出了Thinker算法，一种新颖的方法，使强化学习代理能够自主地与学习的世界模型进行交互并利用其。 Thinker算法通过给环境添加世界模型来改变环境，并引入了用于与世界模型交互的新动作。这些模型交互动作使代理能够通过在选择最终的环境动作之前向世界模型提出备选计划来进行规划。该方法通过使代理自主学习如何进行规划来消除了手工设计的规划算法的需求，并且允许对代理的计划进行易于解释的可视化。我们通过Sokoban游戏和Atari 2600基准测试的实验结果证明了该算法的有效性，其中Thinker算法分别实现了最先进的性能和有竞争力的结果。使用Thinker算法训练的代理的可视化结果表明，它们已经学到了优秀的规划策略。

    We propose the Thinker algorithm, a novel approach that enables reinforcement learning agents to autonomously interact with and utilize a learned world model. The Thinker algorithm wraps the environment with a world model and introduces new actions designed for interacting with the world model. These model-interaction actions enable agents to perform planning by proposing alternative plans to the world model before selecting a final action to execute in the environment. This approach eliminates the need for hand-crafted planning algorithms by enabling the agent to learn how to plan autonomously and allows for easy interpretation of the agent's plan with visualization. We demonstrate the algorithm's effectiveness through experimental results in the game of Sokoban and the Atari 2600 benchmark, where the Thinker algorithm achieves state-of-the-art performance and competitive results, respectively. Visualizations of agents trained with the Thinker algorithm demonstrate that they have lear
    
[^7]: 使用大型语言模型的多语言代码共同演进

    Multilingual Code Co-Evolution Using Large Language Models. (arXiv:2307.14991v1 [cs.SE])

    [http://arxiv.org/abs/2307.14991](http://arxiv.org/abs/2307.14991)

    本文介绍了使用大型语言模型（LLMs）将代码更改从一种编程语言翻译到另一种编程语言的方法。通过设计和实现第一个LLM，Codeditor，以将代码更改建模为编辑序列，并学习不同编程语言之间的关联性，我们为多语言代码共同演进提供了一种新的解决方法。

    

    许多软件项目在多种编程语言中实现API和算法。维护这样的项目很繁琐，因为开发人员必须确保任何变化（例如错误修复或新功能）能够及时且无误地传播到其他编程语言的实现中。在不断变化的软件世界中，使用基于规则的翻译工具（例如转译器）或用于将代码从一种语言翻译成另一种语言的机器学习模型提供有限的价值。每次将整个代码库从一种语言翻译到另一种语言的方式并不符合开发人员的工作方式。在本文中，我们针对一个新颖的任务：使用大型语言模型（LLMs）将代码更改从一种编程语言翻译到另一种编程语言。我们设计并实现了第一个LLM，名为Codeditor，来处理这个任务。Codeditor明确地将代码更改建模为编辑序列，并学习在编程语言之间建立更改的关联性。为了评估Codeditor，我们收集了一个包含6,613个示例的语料库。

    Many software projects implement APIs and algorithms in multiple programming languages. Maintaining such projects is tiresome, as developers have to ensure that any change (e.g., a bug fix or a new feature) is being propagated, timely and without errors, to implementations in other programming languages. In the world of ever-changing software, using rule-based translation tools (i.e., transpilers) or machine learning models for translating code from one language to another provides limited value. Translating each time the entire codebase from one language to another is not the way developers work. In this paper, we target a novel task: translating code changes from one programming language to another using large language models (LLMs). We design and implement the first LLM, dubbed Codeditor, to tackle this task. Codeditor explicitly models code changes as edit sequences and learns to correlate changes across programming languages. To evaluate Codeditor, we collect a corpus of 6,613 ali
    
[^8]: Take-A-Photo: 三维到二维的点云模型生成预训练

    Take-A-Photo: 3D-to-2D Generative Pre-training of Point Cloud Models. (arXiv:2307.14971v1 [cs.CV])

    [http://arxiv.org/abs/2307.14971](http://arxiv.org/abs/2307.14971)

    本文提出了一种新的三维到二维的生成式预训练方法，通过生成视图图像作为预训练方案，帮助三维模型更好地理解点云的几何结构和立体关系，并在实验证明了其优越性。

    

    在MAE带领下，生成式预训练在2D视觉领域已经显示出显著的潜力来提升基本模型的性能。然而，在3D视觉领域，对Transformer为基础的骨干网络的过度依赖以及点云的无序性限制了生成式预训练的进一步发展。本文提出了一种新颖的适用于任何点云模型的三维到二维的生成式预训练方法。我们通过交叉注意机制从不同的姿势生成视图图像作为预训练方案。相比于其点云对应物，生成视图图像具有更精确的监督，从而帮助3D背骨更好地理解点云的几何结构和立体关系。实验结果证明了我们提出的三维到二维的生成式预训练方法优于先前的预训练方法。我们的方法还能有效地提升...

    With the overwhelming trend of mask image modeling led by MAE, generative pre-training has shown a remarkable potential to boost the performance of fundamental models in 2D vision. However, in 3D vision, the over-reliance on Transformer-based backbones and the unordered nature of point clouds have restricted the further development of generative pre-training. In this paper, we propose a novel 3D-to-2D generative pre-training method that is adaptable to any point cloud model. We propose to generate view images from different instructed poses via the cross-attention mechanism as the pre-training scheme. Generating view images has more precise supervision than its point cloud counterpart, thus assisting 3D backbones to have a finer comprehension of the geometrical structure and stereoscopic relations of the point cloud. Experimental results have proved the superiority of our proposed 3D-to-2D generative pre-training over previous pre-training methods. Our method is also effective in boost
    
[^9]: 在Wasserstein空间中通过数据集字典学习进行多源域自适应

    Multi-Source Domain Adaptation through Dataset Dictionary Learning in Wasserstein Space. (arXiv:2307.14953v1 [cs.LG])

    [http://arxiv.org/abs/2307.14953](http://arxiv.org/abs/2307.14953)

    本文提出了一种基于字典学习和最优传输的MSDA框架，通过将每个域表示为字典原子的Wasserstein重心来缓解数据分布偏移。根据该字典，提出了两种新的MSDA方法，分别基于目标域标记样本的重构和在原子分布上学习的分类器的集成。在多个基准测试集上进行的实验证明，这些方法在分类任务上取得了显著的改进效果。

    

    本文旨在解决多源域自适应（MSDA）问题，该问题旨在在从多个标记的源域转移知识到未标记的目标域时缓解数据分布偏移。我们提出了一种基于字典学习和最优传输的新型MSDA框架。我们将MSDA中的每个域解释为经验分布。因此，我们将每个域表达为字典原子的Wasserstein重心，这些原子是经验分布。我们提出了一种新的通过小批量学习的算法DaDiL：（i）原子分布；（ii）重心坐标矩阵。根据我们的字典，我们提出了两种新的MSDA方法：DaDiL-R，基于目标域标记样本的重构；DaDiL-E，基于在原子分布上学习的分类器的集成。我们在3个基准测试集中评估了我们的方法：Caltech-Office、Office 31和CRWU，在分类上改进了以前的最先进技术3.15％、2.29％和7.71％。

    This paper seeks to solve Multi-Source Domain Adaptation (MSDA), which aims to mitigate data distribution shifts when transferring knowledge from multiple labeled source domains to an unlabeled target domain. We propose a novel MSDA framework based on dictionary learning and optimal transport. We interpret each domain in MSDA as an empirical distribution. As such, we express each domain as a Wasserstein barycenter of dictionary atoms, which are empirical distributions. We propose a novel algorithm, DaDiL, for learning via mini-batches: (i) atom distributions; (ii) a matrix of barycentric coordinates. Based on our dictionary, we propose two novel methods for MSDA: DaDil-R, based on the reconstruction of labeled samples in the target domain, and DaDiL-E, based on the ensembling of classifiers learned on atom distributions. We evaluate our methods in 3 benchmarks: Caltech-Office, Office 31, and CRWU, where we improved previous state-of-the-art by 3.15%, 2.29%, and 7.71% in classification 
    
[^10]: PanGu-Coder2：利用排名反馈增强大型语言模型在代码生成方面的能力

    PanGu-Coder2: Boosting Large Language Models for Code with Ranking Feedback. (arXiv:2307.14936v1 [cs.CL])

    [http://arxiv.org/abs/2307.14936](http://arxiv.org/abs/2307.14936)

    本文提出了一种新的框架RRTF，以增强预训练的大型语言模型在代码生成方面的能力。PanGu-Coder2是该框架的实现，在多个基准测试中均表现出色，优于其他先前的Code LLMs。

    

    大型语言模型（Code LLM）在代码生成任务上展现出了卓越的性能，每周都有新的强大模型发布。为了提高预训练的Code LLM的代码生成性能，提出了各种方法，如有监督的微调、指令微调、强化学习等。本文提出了一种新颖的RRTF（Rank Responses to align Test&Teacher Feedback）框架，可以有效、高效地提升预训练的大型语言模型在代码生成方面的能力。在该框架下，我们提出了PanGu-Coder2，在OpenAI HumanEval基准上取得了62.20%的一级通过率。此外，通过对CoderEval和LeetCode基准的广泛评估，我们展示了PanGu-Coder2始终优于所有先前的Code LLMs。

    Large Language Models for Code (Code LLM) are flourishing. New and powerful models are released on a weekly basis, demonstrating remarkable performance on the code generation task. Various approaches have been proposed to boost the code generation performance of pre-trained Code LLMs, such as supervised fine-tuning, instruction tuning, reinforcement learning, etc. In this paper, we propose a novel RRTF (Rank Responses to align Test&Teacher Feedback) framework, which can effectively and efficiently boost pre-trained large language models for code generation. Under this framework, we present PanGu-Coder2, which achieves 62.20% pass@1 on the OpenAI HumanEval benchmark. Furthermore, through an extensive evaluation on CoderEval and LeetCode benchmarks, we show that PanGu-Coder2 consistently outperforms all previous Code LLMs.
    
[^11]: 使用Desbordante解决数据质量问题：一项演示

    Solving Data Quality Problems with Desbordante: a Demo. (arXiv:2307.14935v1 [cs.DB])

    [http://arxiv.org/abs/2307.14935](http://arxiv.org/abs/2307.14935)

    Desbordante是一个旨在解决数据质量问题的工具，通过发现和验证复杂统计信息来帮助现代数据科学家进行数据概要分析。它提供了与现有工具的适当集成，同时考虑到工业级工作负载，并提供描述性的解释来解释模式缺失的原因。

    

    数据概要分析是现代数据驱动行业中的重要过程。其中一个关键组成部分是发现和验证复杂统计信息，包括函数依赖、数据约束、关联规则等。然而，大多数现有的专注于复杂统计的数据概要分析系统在与现代数据科学家使用的工具进行适当集成方面存在问题。这在行业中对这些工具采用造成了重大障碍。此外，现有系统并不考虑工业级工作负载。最后，它们不旨在提供描述性的解释，即为什么找不到给定的模式。这是一个重要问题，因为了解特定模式缺失的根本原因对基于数据的明智决策至关重要。因此，这些模式实际上是消失在空中中：它们的应用范围相对有限，很少被广大公众使用。

    Data profiling is an essential process in modern data-driven industries. One of its critical components is the discovery and validation of complex statistics, including functional dependencies, data constraints, association rules, and others.  However, most existing data profiling systems that focus on complex statistics do not provide proper integration with the tools used by contemporary data scientists. This creates a significant barrier to the adoption of these tools in the industry. Moreover, existing systems were not created with industrial-grade workloads in mind. Finally, they do not aim to provide descriptive explanations, i.e. why a given pattern is not found. It is a significant issue as it is essential to understand the underlying reasons for a specific pattern's absence to make informed decisions based on the data.  Because of that, these patterns are effectively rest in thin air: their application scope is rather limited, they are rarely used by the broader public. At the
    
[^12]: 使用优化的负采样和损失函数扩展基于会话的Transformer推荐系统

    Scaling Session-Based Transformer Recommendations using Optimized Negative Sampling and Loss Functions. (arXiv:2307.14906v1 [cs.IR])

    [http://arxiv.org/abs/2307.14906](http://arxiv.org/abs/2307.14906)

    本文介绍了一种使用优化的负采样和损失函数扩展基于会话的Transformer推荐系统，该系统在大规模电商数据集上通过集成负采样和列表损失函数实现了较高的推荐准确性，并在实践中表现出潜力。

    

    本文介绍了TRON，一种使用优化的负采样的可扩展的基于会话的Transformer推荐系统。受到SASRec和GRU4Rec+等现有模型在可扩展性和性能方面的限制，TRON集成了top-k负采样和列表损失函数，以提高其推荐准确性。在相关的大规模电子商务数据集上的评估结果表明，TRON在保持与SASRec类似的训练速度的同时，改进了当前方法的推荐质量。一项实时的A/B测试显示，相对于SASRec，TRON的点击率增加了18.14%，突显了其在实际环境中的潜力。

    This work introduces TRON, a scalable session-based Transformer Recommender using Optimized Negative-sampling. Motivated by the scalability and performance limitations of prevailing models such as SASRec and GRU4Rec+, TRON integrates top-k negative sampling and listwise loss functions to enhance its recommendation accuracy. Evaluations on relevant large-scale e-commerce datasets show that TRON improves upon the recommendation quality of current methods while maintaining training speeds similar to SASRec. A live A/B test yielded an 18.14% increase in click-through rate over SASRec, highlighting the potential of TRON in practical settings. For further research, we provide access to our source code at https://github.com/otto-de/TRON and an anonymized dataset at https://github.com/otto-de/recsys-dataset.
    
[^13]: CodeLens: 一种用于可视化代码表示的交互式工具

    CodeLens: An Interactive Tool for Visualizing Code Representations. (arXiv:2307.14902v1 [cs.SE])

    [http://arxiv.org/abs/2307.14902](http://arxiv.org/abs/2307.14902)

    CodeLens是一种可视化代码表示的交互式工具，支持多种表示方法和编程语言，开发人员能够快速理解和探索代码。

    

    将源代码以通用输入格式表示对于自动化软件工程任务至关重要，例如应用机器学习算法来提取信息。可视化代码表示可以进一步使人类专家直观地理解代码。然而，到目前为止，还没有一种通用工具能够同时可视化不同类型的代码表示。在本文中，我们介绍了一种名为CodeLens的工具，它提供了一个可视化交互环境，支持各种表示方法，并帮助开发人员理解和探索它们。CodeLens被设计成支持多种编程语言，如Java、Python和JavaScript，以及四种代码表示类型，包括标记序列、抽象语法树（AST）、数据流图（DFG）和控制流图（CFG）。通过使用CodeLens，开发人员可以快速可视化特定的代码表示，并获取代码模型的表示输入。

    Representing source code in a generic input format is crucial to automate software engineering tasks, e.g., applying machine learning algorithms to extract information. Visualizing code representations can further enable human experts to gain an intuitive insight into the code. Unfortunately, as of today, there is no universal tool that can simultaneously visualise different types of code representations. In this paper, we introduce a tool, CodeLens, which provides a visual interaction environment that supports various representation methods and helps developers understand and explore them. CodeLens is designed to support multiple programming languages, such as Java, Python, and JavaScript, and four types of code representations, including sequence of tokens, abstract syntax tree (AST), data flow graph (DFG), and control flow graph (CFG). By using CodeLens, developers can quickly visualize the specific code representation and also obtain the represented inputs for models of code. The W
    
[^14]: 基于基扩展的多智能体仅信任模型验证

    Base-based Model Checking for Multi-Agent Only Believing (long version). (arXiv:2307.14893v1 [cs.AI])

    [http://arxiv.org/abs/2307.14893](http://arxiv.org/abs/2307.14893)

    该论文提出了一种基于信念基扩展的多智能体仅信任模型验证方法，包括自动检查公式的PSPACE算法和探索状态空间的专用算法。

    

    我们提出了一种新颖的语义方法，利用信念基扩展，为多智能体仅信任语言以及其带有私有信念扩展运算符的动态扩展提供了自动检查公式的方法。我们提供了一个基于PSPACE算法的模型检查，依赖于对QBF的约简以及对状态空间的探索的另一种专用算法。我们展示了基于QBF算法的实现及在具体示例中的计算时间的一些实验结果。

    We present a novel semantics for the language of multi-agent only believing exploiting belief bases, and show how to use it for automatically checking formulas of this language and of its dynamic extension with private belief expansion operators. We provide a PSPACE algorithm for model checking relying on a reduction to QBF and alternative dedicated algorithm relying on the exploration of the state space. We present an implementation of the QBF-based algorithm and some experimental results on computation time in a concrete example.
    
[^15]: 弱监督的多模态3D人体姿势估计在自动驾驶中的应用

    Weakly Supervised Multi-Modal 3D Human Body Pose Estimation for Autonomous Driving. (arXiv:2307.14889v1 [cs.CV])

    [http://arxiv.org/abs/2307.14889](http://arxiv.org/abs/2307.14889)

    通过强大的弱监督方法，在自动驾驶领域中，我们提出了一种简单且高效的多模态3D人体姿势估计方法，通过相机和激光雷达数据之间的高级传感器融合，无需2D/3D关键点标签，在目标数据集上进行训练，实现准确的3D姿势估计。

    

    准确的3D人体姿势估计对于自动驾驶车辆做出明智决策和在关键道路场景中积极应对非常重要。在多个领域，如人机交互、机器人技术、体育和医学分析等，3D人体姿势估计取得了令人满意的结果，通常基于在良好控制的实验室环境中收集的数据。然而，由于获取准确的3D姿势标注的挑战以及其他领域数据的有限适用性，将3D人体姿势估计方法转移到自动驾驶车辆中的研究受到了限制。我们提出了一种简单而高效的弱监督方法，通过将相机和激光雷达数据进行高级传感器融合，实现了自动驾驶场景下的3D人体姿势估计。弱监督的设置使得在目标数据集上进行训练时不需要任何2D/3D关键点标签，而是利用现成的2D关节点提取器和由激光雷达到图像的投影生成伪标签。我们的方法表现优于其他方法。

    Accurate 3D human pose estimation (3D HPE) is crucial for enabling autonomous vehicles (AVs) to make informed decisions and respond proactively in critical road scenarios. Promising results of 3D HPE have been gained in several domains such as human-computer interaction, robotics, sports and medical analytics, often based on data collected in well-controlled laboratory environments. Nevertheless, the transfer of 3D HPE methods to AVs has received limited research attention, due to the challenges posed by obtaining accurate 3D pose annotations and the limited suitability of data from other domains.  We present a simple yet efficient weakly supervised approach for 3D HPE in the AV context by employing a high-level sensor fusion between camera and LiDAR data. The weakly supervised setting enables training on the target datasets without any 2D/3D keypoint labels by using an off-the-shelf 2D joint extractor and pseudo labels generated from LiDAR to image projections. Our approach outperform
    
[^16]: 发挥Seq2Seq模型作为稳健少样本学习器的潜力

    Exploiting the Potential of Seq2Seq Models as Robust Few-Shot Learners. (arXiv:2307.14856v1 [cs.CL])

    [http://arxiv.org/abs/2307.14856](http://arxiv.org/abs/2307.14856)

    Seq2Seq模型作为少样本学习器的潜力在解码器和编码-解码模型中进行了广泛研究，提出了两种能有效提升Seq2Seq模型上下文学习能力的方法，并在各种任务中显示出显著的性能改进。

    

    在上下文学习中，只有解码器模型具有明显优势，而编码-解码（即Seq2Seq）模型在依赖于权重更新的方法中表现出色。最近，一些研究表明Seq2Seq模型可以进行少样本学习，但这仅限于与Seq2Seq体系结构相匹配的任务，如摘要和翻译。受到这些初始研究的启发，我们首次进行了广泛的实验，比较了解码器和编码-解码模型在各种任务的上下文少样本学习能力。此外，我们提出了两种能更有效地引发Seq2Seq模型上下文学习能力的方法：目标对齐提示和基于融合的方法。值得注意的是，我们的方法在性能上超过了一个体积是其六倍的解码器模型，并且相较于常规Seq2Seq模型显示出显著的性能改进。

    In-context learning, which offers substantial advantages over fine-tuning, is predominantly observed in decoder-only models, while encoder-decoder (i.e., seq2seq) models excel in methods that rely on weight updates. Recently, a few studies have demonstrated the feasibility of few-shot learning with seq2seq models; however, this has been limited to tasks that align well with the seq2seq architecture, such as summarization and translation. Inspired by these initial studies, we provide a first-ever extensive experiment comparing the in-context few-shot learning capabilities of decoder-only and encoder-decoder models on a broad range of tasks. Furthermore, we propose two methods to more effectively elicit in-context learning ability in seq2seq models: objective-aligned prompting and a fusion-based approach. Remarkably, our approach outperforms a decoder-only model that is six times larger and exhibits significant performance improvements compared to conventional seq2seq models across a var
    
[^17]: 通过密度视角进行图分类的反事实解释

    Counterfactual Explanations for Graph Classification Through the Lenses of Density. (arXiv:2307.14849v1 [cs.LG])

    [http://arxiv.org/abs/2307.14849](http://arxiv.org/abs/2307.14849)

    本文提出了一种基于密度的反事实搜索框架，利用图的主要特征生成图分类器的实例级反事实解释。

    

    反事实例子已经成为一种产生简单易懂的事后解释的有效方法。在图分类的背景下，先前的工作主要集中在通过改变图的最基本单元（即删除现有边或添加不存在的边）来生成反事实解释。本文认为这种解释方式可能太细致，转而关注真实世界复杂网络的一些主要特征，如闭合三角形的趋势、重复的模式以及组织成密集模块。因此，我们提出了一种基于密度的反事实搜索框架，用于为图分类器生成实例级反事实解释，该框架可以用不同的密集子结构概念实例化。特别地，我们展示了该通用框架的两个具体实例化方法：一种通过搜索反事实图来匹配密集子结构测度的方法和一种通过搜索反事实子图来匹配密集子图的方法。

    Counterfactual examples have emerged as an effective approach to produce simple and understandable post-hoc explanations. In the context of graph classification, previous work has focused on generating counterfactual explanations by manipulating the most elementary units of a graph, i.e., removing an existing edge, or adding a non-existing one. In this paper, we claim that such language of explanation might be too fine-grained, and turn our attention to some of the main characterizing features of real-world complex networks, such as the tendency to close triangles, the existence of recurring motifs, and the organization into dense modules. We thus define a general density-based counterfactual search framework to generate instance-level counterfactual explanations for graph classifiers, which can be instantiated with different notions of dense substructures. In particular, we show two specific instantiations of this general framework: a method that searches for counterfactual graphs by 
    
[^18]: 混合ASP方法用于半导体制造过程的多目标调度（扩展版本）

    Hybrid ASP-based multi-objective scheduling of semiconductor manufacturing processes (Extended version). (arXiv:2307.14799v1 [cs.AI])

    [http://arxiv.org/abs/2307.14799](http://arxiv.org/abs/2307.14799)

    本研究通过混合ASP方法解决了实际半导体制造过程的调度问题，将其具体要求建模，并且实现了灵活的机器加工、设置、批处理和维护操作。

    

    现代半导体制造涉及复杂的生产过程，包括数百个操作，从批次发布到完成可能需要数月时间。这些过程中使用的高科技设备多样化，可以在多个阶段上对单个晶圆、批次或批次进行操作，并需要产品特定的设置和专门的维护程序。这种情况与传统的车间调度场景不同，后者具有较不复杂的生产过程和设备，主要关注解决高度组合但抽象的调度问题。在这项工作中，我们通过使用具有差异逻辑的混合ASP模型来对实际的半导体制造过程的调度进行建模，这包括灵活的机器加工、设置、批处理和维护操作。与现有的使用贪婪启发式算法或独立进行调度半导体制造过程的方法不同，

    Modern semiconductor manufacturing involves intricate production processes consisting of hundreds of operations, which can take several months from lot release to completion. The high-tech machines used in these processes are diverse, operate on individual wafers, lots, or batches in multiple stages, and necessitate product-specific setups and specialized maintenance procedures. This situation is different from traditional job-shop scheduling scenarios, which have less complex production processes and machines, and mainly focus on solving highly combinatorial but abstract scheduling problems. In this work, we address the scheduling of realistic semiconductor manufacturing processes by modeling their specific requirements using hybrid Answer Set Programming with difference logic, incorporating flexible machine processing, setup, batching and maintenance operations. Unlike existing methods that schedule semiconductor manufacturing processes locally with greedy heuristics or by independen
    
[^19]: Emotion4MIDI：基于歌词的带情感标签的符号音乐数据集

    Emotion4MIDI: a Lyrics-based Emotion-Labeled Symbolic Music Dataset. (arXiv:2307.14783v1 [eess.AS])

    [http://arxiv.org/abs/2307.14783](http://arxiv.org/abs/2307.14783)

    Emotion4MIDI是一个包含12k个带情感标签的符号音乐数据集，通过在GoEmotions数据集上训练情感分类模型，并应用于两个大规模的MIDI数据集的歌词，提供了一个宝贵的资源来探索音乐和情感之间的联系，并开发可以根据特定情感生成音乐的模型。

    

    我们提出了一个新的大规模带情感标签的符号音乐数据集，包含12k个MIDI歌曲。为了创建这个数据集，我们首先在GoEmotions数据集上训练情感分类模型，使用一半大小的模型实现了最先进的结果。然后，我们将这些模型应用于两个大规模的MIDI数据集的歌词。我们的数据集涵盖了广泛的细粒度情感，为探索音乐和情感之间的联系，尤其是开发可以根据特定情感生成音乐的模型提供了宝贵的资源。我们的推断代码、训练模型和数据集都可以在线获取。

    We present a new large-scale emotion-labeled symbolic music dataset consisting of 12k MIDI songs. To create this dataset, we first trained emotion classification models on the GoEmotions dataset, achieving state-of-the-art results with a model half the size of the baseline. We then applied these models to lyrics from two large-scale MIDI datasets. Our dataset covers a wide range of fine-grained emotions, providing a valuable resource to explore the connection between music and emotions and, especially, to develop models that can generate music based on specific emotions. Our code for inference, trained models, and datasets are available online.
    
[^20]: 公平机器遗忘：在减少差异的同时删除数据

    Fair Machine Unlearning: Data Removal while Mitigating Disparities. (arXiv:2307.14754v1 [cs.LG])

    [http://arxiv.org/abs/2307.14754](http://arxiv.org/abs/2307.14754)

    本研究提出了第一个能够可靠而高效地遗忘数据实例并保持公平性的机器学习方法。

    

    随着公众对企业收集和使用个人信息的意识增强，消费者积极参与企业数据集的管理变得越来越重要。为此，数据管理框架（如欧洲通用数据保护条例）已经提出了被遗忘的权利，允许个人请求将其个人数据从组织使用的数据库和模型中删除。为了实现遗忘，已经提出了几种机器学习遗忘方法，以解决每个遗忘请求重新训练模型的计算效率问题。虽然这些在线替代方案可以高效地进行遗忘，但它们对于其他关键的实际应用属性（如公平性）的影响尚不清楚。在这项工作中，我们提出了第一个能够可靠而高效地遗忘数据实例并保持公平性的方法。

    As public consciousness regarding the collection and use of personal information by corporations grows, it is of increasing importance that consumers be active participants in the curation of corporate datasets. In light of this, data governance frameworks such as the General Data Protection Regulation (GDPR) have outlined the right to be forgotten as a key principle allowing individuals to request that their personal data be deleted from the databases and models used by organizations. To achieve forgetting in practice, several machine unlearning methods have been proposed to address the computational inefficiencies of retraining a model from scratch with each unlearning request. While efficient online alternatives to retraining, it is unclear how these methods impact other properties critical to real-world applications, such as fairness. In this work, we propose the first fair machine unlearning method that can provably and efficiently unlearn data instances while preserving group fai
    
[^21]: 无注释图像字幕生成的研究：基于检索增强的伪句子生成

    Exploring Annotation-free Image Captioning with Retrieval-augmented Pseudo Sentence Generation. (arXiv:2307.14750v1 [cs.CV])

    [http://arxiv.org/abs/2307.14750](http://arxiv.org/abs/2307.14750)

    本文提出了一种新的无注释图像字幕生成的策略，利用大规模预训练模型的先验知识作为监督，并整合检索过程以进一步增强其效力。该方法能够从不匹配的语料库中检索相关的短区域描述，并利用其生成多样的句子。

    

    近年来，训练无注释图像字幕生成器取得了进展。先前的方法可以分为两种策略：从不匹配的语料库中获取句子，并将其与给定的图像对齐作为伪注释，或者使用外部的图像-文本对对生成器进行预训练。然而，由于对齐的设置存在质量问题，其性能似乎已经达到了极限，而预训练需要大量的计算资源。为了解决这些挑战，我们提出了一种新的策略“LPM + 检索增强学习”，利用来自大规模预训练模型（LPM）的先验知识作为监督，并整合检索过程以进一步增强其效力。具体而言，我们引入了检索增强的伪句子生成（RaPSG），采用高效的方法从不匹配的语料库中检索出高相关的短区域描述，并将其用于生成多样的句子。

    Training an image captioner without annotated image-sentence pairs has gained traction in recent years. Previous approaches can be categorized into two strategies: crawling sentences from mismatching corpora and aligning them with the given images as pseudo annotations, or pre-training the captioner using external image-text pairs. However, the aligning setting seems to reach its performance limit due to the quality problem of pairs, and pre-training requires significant computational resources. To address these challenges, we propose a new strategy ``LPM + retrieval-augmented learning" where the prior knowledge from large pre-trained models (LPMs) is leveraged as supervision, and a retrieval process is integrated to further reinforce its effectiveness. Specifically, we introduce Retrieval-augmented Pseudo Sentence Generation (RaPSG), which adopts an efficient approach to retrieve highly relevant short region descriptions from the mismatching corpora and use them to generate a variety 
    
[^22]: 基于GPT的复杂EDA软件新交互范式

    New Interaction Paradigm for Complex EDA Software Leveraging GPT. (arXiv:2307.14740v1 [cs.SE])

    [http://arxiv.org/abs/2307.14740](http://arxiv.org/abs/2307.14740)

    本研究通过开发SmartonAI插件，基于GPT和BERT等大型语言模型，提供一种新的交互范式来解决EDA软件中初学者面临的复杂命令结构和高学习曲线问题。

    

    在电子设计自动化（EDA）领域中，专业软件如KiCad、Cadence和Altium Designer提供越来越广泛的设计功能。然而，复杂的命令结构和较高的学习曲线对于初学者的印刷电路板（PCB）设计师来说造成了障碍。这导致难以选择适合不同设计目的的功能或插件，并且传统文档、视频和在线论坛之外缺乏直观的学习方法。为解决这一挑战，本研究开发了一个名为SmartonAI的EDA软件人工智能交互辅助插件，其中以KiCad作为第一个示例。SmartonAI受到HuggingGPT框架的启发，采用了GPT和BERT等大型语言模型，以促进任务规划和执行。当接收到设计师的请求时，SmartonAI会进行任务分解并高效执行相关的子任务，

    In the rapidly growing field of electronic design automation (EDA), professional software such as KiCad, Cadence , and Altium Designer provide increasingly extensive design functionalities. However, the intricate command structure and high learning curve create a barrier, particularly for novice printed circuit board (PCB) designers. This results in difficulties in selecting appropriate functions or plugins for varying design purposes, compounded by the lack of intuitive learning methods beyond traditional documentation, videos, and online forums. To address this challenge, an artificial intelligence (AI) interaction assist plugin for EDA software named SmartonAl is developed here, also KiCad is taken as the first example. SmartonAI is inspired by the HuggingGPT framework and employs large language models, such as GPT and BERT, to facilitate task planning and execution. On receiving a designer request, SmartonAI conducts a task breakdown and efficiently executes relevant subtasks, such
    
[^23]: 评估生成模型在图文生成中的应用

    Evaluating Generative Models for Graph-to-Text Generation. (arXiv:2307.14712v1 [cs.CL])

    [http://arxiv.org/abs/2307.14712](http://arxiv.org/abs/2307.14712)

    本文评估了生成模型在图文生成中的应用，并发现生成模型能够生成流畅并连贯的文本。然而，生成模型仍然困难理解实体之间的语义关系，并且容易生成带有幻觉或无关信息的文本。

    

    大型语言模型（LLM）已广泛应用于图文生成任务。然而，微调LLM的过程需要大量的训练资源和注释工作。本文中，我们探索了生成模型在无需微调的情况下，从图数据中生成描述性文本的能力。具体而言，我们评估了GPT-3和ChatGPT在两个图文数据集上的性能，并将其与微调的LLM模型（如T5和BART）进行了比较。我们的结果表明，生成模型能够生成流畅并连贯的文本，在AGENDA和WebNLG数据集上分别实现了10.57和11.08的BLEU分数。然而，我们的错误分析揭示了生成模型仍然难以理解实体之间的语义关系，而且它们还倾向于生成具有幻觉或无关信息的文本。作为错误分析的一部分，我们利用BERT检测机器生成的文本，并取得了较高的宏F1分数。

    Large language models (LLMs) have been widely employed for graph-to-text generation tasks. However, the process of finetuning LLMs requires significant training resources and annotation work. In this paper, we explore the capability of generative models to generate descriptive text from graph data in a zero-shot setting. Specifically, we evaluate GPT-3 and ChatGPT on two graph-to-text datasets and compare their performance with that of finetuned LLM models such as T5 and BART. Our results demonstrate that generative models are capable of generating fluent and coherent text, achieving BLEU scores of 10.57 and 11.08 for the AGENDA and WebNLG datasets, respectively. However, our error analysis reveals that generative models still struggle with understanding the semantic relations between entities, and they also tend to generate text with hallucinations or irrelevant information. As a part of error analysis, we utilize BERT to detect machine-generated text and achieve high macro-F1 scores.
    
[^24]: 使用物理信息神经网络和证据不确定性量化预测风力发电机功率

    Prediction of wind turbines power with physics-informed neural networks and evidential uncertainty quantification. (arXiv:2307.14675v1 [cs.LG])

    [http://arxiv.org/abs/2307.14675](http://arxiv.org/abs/2307.14675)

    本研究使用物理信息神经网络对风力涡轮机的历史数据进行建模，通过施加物理约束，成功地预测了涡轮机的功率、转矩和功率系数。这对于优化涡轮机运行和早期故障检测具有重要的实际应用价值。

    

    风能的不断增长使通过偏航角控制器来优化涡轮机运行，并通过早期故障检测来进行维护变得必要。准确而稳健的模型来模拟风力涡轮机的行为尤其关键，特别是预测生成的功率与风速的关系。现有的经验和基于物理的模型在捕捉输入变量和功率之间的复杂关系方面存在局限性，尤其是受风变性的加剧。数据驱动方法为通过提高准确性和效率来增强大数据集上的风力涡轮机建模提供了新的机会。在本研究中，我们使用物理信息神经网络以模拟来自一个风场的4台涡轮机的历史数据，同时对模型施加了一定的物理约束。开发的用于回归功率、转矩和功率系数的模型在真实数据和控制方程方面都展现了很好的准确性。

    The ever-growing use of wind energy makes necessary the optimization of turbine operations through pitch angle controllers and their maintenance with early fault detection. It is crucial to have accurate and robust models imitating the behavior of wind turbines, especially to predict the generated power as a function of the wind speed. Existing empirical and physics-based models have limitations in capturing the complex relations between the input variables and the power, aggravated by wind variability. Data-driven methods offer new opportunities to enhance wind turbine modeling of large datasets by improving accuracy and efficiency. In this study, we used physics-informed neural networks to reproduce historical data coming from 4 turbines in a wind farm, while imposing certain physical constraints to the model. The developed models for regression of the power, torque, and power coefficient as output variables showed great accuracy for both real data and physical equations governing th
    
[^25]: 模糊有序特征逻辑

    Fuzzy order-sorted feature logic. (arXiv:2307.14669v1 [cs.AI])

    [http://arxiv.org/abs/2307.14669](http://arxiv.org/abs/2307.14669)

    本文将有序特征逻辑推广到模糊设置中，并给出了模糊的OSF逻辑语义。通过扩展包含关系到OSF术语，我们构成了一个模糊偏序。

    

    有序特征（OSF）逻辑是一种基于函数表示特征符号和集合表示排序符号的知识表示和推理语言，这些符号在一个包含关系格中排列。 OSF逻辑允许构建类似记录的术语，表示实体类别，并且这些术语本身也按照包含关系排序。这种结构的一致性算法提供了一种高效的类型包含演算，已经应用于计算语言学，并在约束逻辑编程语言（如LOGIN和LIFE）和自动推理器（如CEDAR）中实现。本文将OSF逻辑推广到模糊设置中。我们给出了一个灵活的模糊包含关系的定义，它推广了Zadeh的模糊集包含关系。基于这个定义，我们定义了一个模糊的OSF逻辑语义，其中排序符号和OSF术语表示模糊集合。我们将包含关系扩展到OSF术语，并证明它构成了一个模糊偏序。

    Order-Sorted Feature (OSF) logic is a knowledge representation and reasoning language based on function-denoting feature symbols and set-denoting sort symbols ordered in a subsumption lattice. OSF logic allows the construction of record-like terms that represent classes of entities and that are themselves ordered in a subsumption relation. The unification algorithm for such structures provides an efficient calculus of type subsumption, which has been applied in computational linguistics and implemented in constraint logic programming languages such as LOGIN and LIFE and automated reasoners such as CEDAR. This work generalizes OSF logic to a fuzzy setting. We give a flexible definition of a fuzzy subsumption relation which generalizes Zadeh's inclusion between fuzzy sets. Based on this definition we define a fuzzy semantics of OSF logic where sort symbols and OSF terms denote fuzzy sets. We extend the subsumption relation to OSF terms and prove that it constitutes a fuzzy partial order 
    
[^26]: 数值规划中的多值偏序计划

    Multi-Valued Partial Order Plans in Numeric Planning. (arXiv:2307.14660v1 [cs.AI])

    [http://arxiv.org/abs/2307.14660](http://arxiv.org/abs/2307.14660)

    本文研究了数值规划中的多值偏序计划，在分析可能导致不可判定性的原因时，通过研究动作发生次数的不同情况。通过重新定义限制任务为搜索问题，并使用启发式方法找到数值规划的一个NP完全片段。通过开发多值偏序计划的想法，实现了最小承诺的紧凑表示方法。该表示方法的优化技术能够纳入软先决条件。

    

    许多规划形式允许将数字与布尔效应混合使用，但大多数形式是不可判定的。本文将通过研究动作发生次数的不同情况来分析导致不可判定性的可能原因，这种方法在度量谓词之前已被证明是有用的。我们将从重新定义限制任务这个已知的数值规划问题为搜索问题开始。然后，我们将展示如何使用启发式方法找到数值规划的一个NP完全片段。为了实现这一点，我们将开发多值偏序计划的想法，这是一种最小承诺的紧凑表示方法（逐步和并行计划）。最后，我们将研究这种表示方法的优化技术，以纳入软先决条件。

    Many planning formalisms allow for mixing numeric with Boolean effects. However, most of these formalisms are undecidable. In this paper, we will analyze possible causes for this undecidability by studying the number of different occurrences of actions, an approach that proved useful for metric fluents before. We will start by reformulating a numeric planning problem known as restricted tasks as a search problem. We will then show how an NP-complete fragment of numeric planning can be found by using heuristics. To achieve this, we will develop the idea of multi-valued partial order plans, a least committing compact representation for (sequential and parallel) plans. Finally, we will study optimization techniques for this representation to incorporate soft preconditions.
    
[^27]: AI生成报告的事实核查

    Fact-Checking of AI-Generated Reports. (arXiv:2307.14634v1 [cs.AI])

    [http://arxiv.org/abs/2307.14634](http://arxiv.org/abs/2307.14634)

    本文提出了一种使用相关联的图像对AI生成报告进行事实核查的新方法，以区分报告中的真假句子。这对加快临床工作流程，提高准确性并降低总体成本具有重要意义。

    

    随着生成人工智能（AI）的进步，现在可以生成逼真的自动报告来对放射学图像进行初步阅读。这可以加快临床工作流程，提高准确性并降低总体成本。然而，众所周知，这种模型往往会产生幻觉，导致生成报告中出现错误的发现。在本文中，我们提出了一种使用相关联的图像对AI生成报告进行事实核查的新方法。具体而言，通过学习图像与描述真实或潜在虚假发现的句子之间的关联，开发的核查者区分报告中的真假句子。为了训练这样的核查者，我们首先通过扰动原始与图像相关的放射学报告中的发现，创建了一个新的伪造报告数据集。然后将来自这些报告的真假句子的文本编码与图像编码配对，学习映射到真/假标签的关系。

    With advances in generative artificial intelligence (AI), it is now possible to produce realistic-looking automated reports for preliminary reads of radiology images. This can expedite clinical workflows, improve accuracy and reduce overall costs. However, it is also well-known that such models often hallucinate, leading to false findings in the generated reports. In this paper, we propose a new method of fact-checking of AI-generated reports using their associated images. Specifically, the developed examiner differentiates real and fake sentences in reports by learning the association between an image and sentences describing real or potentially fake findings. To train such an examiner, we first created a new dataset of fake reports by perturbing the findings in the original ground truth radiology reports associated with images. Text encodings of real and fake sentences drawn from these reports are then paired with image encodings to learn the mapping to real/fake labels. The utility 
    
[^28]: 基于度量的上下文学习：文本简化案例研究

    Metric-Based In-context Learning: A Case Study in Text Simplification. (arXiv:2307.14632v1 [cs.CL])

    [http://arxiv.org/abs/2307.14632](http://arxiv.org/abs/2307.14632)

    本文针对文本简化进行了一个案例研究，提出了一种基于度量的上下文学习（MBL）方法，通过选择具有顶级SARI得分的示例，可以在较大型的GPT模型上获得最佳表现。而在较小型的模型上，通过选择具有较高压缩比例的示例表现更好。

    

    对大型语言模型进行上下文学习（ICL）在许多自然语言处理任务中已被证明是一种强大的方法。然而，确定选择ICL示例的最佳方法并不容易，因为结果可以因使用的示例的质量、数量和顺序而变化很大。在本文中，我们进行了一个关于文本简化（TS）的案例研究，以探讨如何选择最佳和最健壮的ICL示例。我们提出了一种基于常用的TS度量（如SARI、压缩比例和BERT-Precision）进行选择的基于度量的上下文学习（MBL）方法。通过在标准的TS基准（如TurkCorpus和ASSET）上使用各种规模的GPT模型进行广泛的实验，我们表明在较大的模型（如GPT-175B）上选择的示例通过顶级SARI得分表现最佳，而压缩比例通常在较小的模型（如GPT-13B和GPT-6.7B）上表现更好。此外，我们证明MBL通常具有良好的鲁棒性。

    In-context learning (ICL) for large language models has proven to be a powerful approach for many natural language processing tasks. However, determining the best method to select examples for ICL is nontrivial as the results can vary greatly depending on the quality, quantity, and order of examples used. In this paper, we conduct a case study on text simplification (TS) to investigate how to select the best and most robust examples for ICL. We propose Metric-Based in-context Learning (MBL) method that utilizes commonly used TS metrics such as SARI, compression ratio, and BERT-Precision for selection. Through an extensive set of experiments with various-sized GPT models on standard TS benchmarks such as TurkCorpus and ASSET, we show that examples selected by the top SARI scores perform the best on larger models such as GPT-175B, while the compression ratio generally performs better on smaller models such as GPT-13B and GPT-6.7B. Furthermore, we demonstrate that MBL is generally robust 
    
[^29]: BubbleML: 用于机器学习的多物理数据集和基准

    BubbleML: A Multi-Physics Dataset and Benchmarks for Machine Learning. (arXiv:2307.14623v1 [cs.LG])

    [http://arxiv.org/abs/2307.14623](http://arxiv.org/abs/2307.14623)

    BubbleML是一个用于机器学习的多物理数据集，通过物理驱动模拟获得准确的地面真实信息，并在各种沸腾场景中验证了其可靠性和潜力。

    

    在相变现象领域，缺乏适用于机器学习训练的可访问和多样化的数据集是一个重要挑战。现有的实验数据集通常受限，可用性有限且地面真实数据稀缺，阻碍了我们对这种复杂多物理现象的理解。为了弥补这一差距，我们提出了BubbleML数据集（https://github.com/HPCForge/BubbleML），它利用物理驱动的模拟为各种沸腾场景提供准确的地面真实信息，包括核泡池沸腾、流动沸腾和亚冷沸腾。这个广泛的数据集涵盖了各种参数，包括不同的重力条件、流量、亚冷水平和壁面过热，总共有51个模拟。BubbleML已经通过实验观察和趋势进行了验证，被确认为机器学习研究的宝贵资源。此外，我们展示了它促进多样化降低温度沸腾研究的潜力。

    In the field of phase change phenomena, the lack of accessible and diverse datasets suitable for machine learning (ML) training poses a significant challenge. Existing experimental datasets are often restricted, with limited availability and sparse ground truth data, impeding our understanding of this complex multi-physics phenomena. To bridge this gap, we present the BubbleML Dataset(https://github.com/HPCForge/BubbleML) which leverages physics-driven simulations to provide accurate ground truth information for various boiling scenarios, encompassing nucleate pool boiling, flow boiling, and sub-cooled boiling. This extensive dataset covers a wide range of parameters, including varying gravity conditions, flow rates, sub-cooling levels, and wall superheat, comprising 51 simulations. BubbleML is validated against experimental observations and trends, establishing it as an invaluable resource for ML research. Furthermore, we showcase its potential to facilitate exploration of diverse dow
    
[^30]: 自对比图扩散网络

    Self-Contrastive Graph Diffusion Network. (arXiv:2307.14613v1 [cs.LG])

    [http://arxiv.org/abs/2307.14613](http://arxiv.org/abs/2307.14613)

    提出了一种名为自对比图扩散网络（SCGDN）的新型框架，通过注意力模块和扩散模块实现对高阶结构和特征信息的优秀嵌入。与现有的方法不同，SCGDN是一种无增强的方法，避免了“采样偏差”和语义漂移问题。

    

    在对比学习中，增强技术和采样策略非常重要，但在大多数现有工作中，增强技术需要精心设计，而他们的采样策略只能捕捉到一小部分内在的监督信息。此外，现有的方法需要复杂的设计来获得数据的两个不同表示。为了克服这些限制，我们提出了一个新颖的框架，称为自对比图扩散网络（SCGDN）。我们的框架由两个主要组件组成：注意力模块（AttM）和扩散模块（DiFM）。AttM通过汇集高阶结构和特征信息来获得优秀的嵌入，而DiFM通过Laplacian扩散学习平衡图中每个节点的状态，并允许图中邻接和特征信息的协同演化。与现有的方法不同，SCGDN是一种无增强的方法，避免了“采样偏差”和语义漂移问题。

    Augmentation techniques and sampling strategies are crucial in contrastive learning, but in most existing works, augmentation techniques require careful design, and their sampling strategies can only capture a small amount of intrinsic supervision information. Additionally, the existing methods require complex designs to obtain two different representations of the data. To overcome these limitations, we propose a novel framework called the Self-Contrastive Graph Diffusion Network (SCGDN). Our framework consists of two main components: the Attentional Module (AttM) and the Diffusion Module (DiFM). AttM aggregates higher-order structure and feature information to get an excellent embedding, while DiFM balances the state of each node in the graph through Laplacian diffusion learning and allows the cooperative evolution of adjacency and feature information in the graph. Unlike existing methodologies, SCGDN is an augmentation-free approach that avoids "sampling bias" and semantic drift, wit
    
[^31]: 基于聚类的点云表示学习用于3D分析

    Clustering based Point Cloud Representation Learning for 3D Analysis. (arXiv:2307.14605v1 [cs.CV])

    [http://arxiv.org/abs/2307.14605](http://arxiv.org/abs/2307.14605)

    这篇论文提出了一种基于聚类的点云表示学习方法，用于3D分析。通过在点嵌入空间进行类内聚类，自动发现跨场景的子类模式，然后利用这些模式重新绘制嵌入空间，以提高点云分析性能。

    

    点云分析（如3D分割和检测）是一项具有挑战性的任务，因为不仅有数百万个无序点的不规则几何形状，还有由深度、视点、遮挡等引起的巨大变化。当前的研究主要关注神经网络对点云复杂几何形状的适应性，但忽视了一个基本问题：如何学习一个既具有辨别语义又能应对挑战性变化的适当点嵌入空间？作为回应，我们提出了一种基于聚类的点云分析有监督学习方案。与当前的基于场景的训练范式不同，我们的算法在点嵌入空间上进行类内聚类，自动发现跨场景潜在而代表性的子类模式。随后，利用发现的模式重新绘制嵌入空间，以尊重整个训练数据集的潜在分布并改进点云分析性能。

    Point cloud analysis (such as 3D segmentation and detection) is a challenging task, because of not only the irregular geometries of many millions of unordered points, but also the great variations caused by depth, viewpoint, occlusion, etc. Current studies put much focus on the adaption of neural networks to the complex geometries of point clouds, but are blind to a fundamental question: how to learn an appropriate point embedding space that is aware of both discriminative semantics and challenging variations? As a response, we propose a clustering based supervised learning scheme for point cloud analysis. Unlike current de-facto, scene-wise training paradigm, our algorithm conducts within-class clustering on the point embedding space for automatically discovering subclass patterns which are latent yet representative across scenes. The mined patterns are, in turn, used to repaint the embedding space, so as to respect the underlying distribution of the entire training dataset and improv
    
[^32]: 基于未被伪造的控制的身份交换检测与修正

    The detection and rectification for identity-switch based on unfalsified control. (arXiv:2307.14591v1 [cs.CV])

    [http://arxiv.org/abs/2307.14591](http://arxiv.org/abs/2307.14591)

    本文提出了一种基于未被伪造的控制的多目标跟踪方法，针对身份交换问题设计了检测和修正模块，以及解决外观信息模糊匹配的策略，并在实验中展示了其出色的效果和鲁棒性。

    

    多目标跟踪的目的是持续跟踪和识别视频中检测到的物体。目前，大多数多目标跟踪方法都是通过建模运动信息并将其与外观信息相结合，来确定和跟踪物体。本文采用了未被伪造的控制方法来解决多目标跟踪中的身份交换问题。我们在跟踪过程中建立了外观信息变化的序列，针对身份交换检测和恢复设计了一个检测和修正模块。我们还提出了一种简单而有效的策略来解决数据关联过程中外观信息模糊匹配的问题。公开可用的多目标跟踪数据集上的实验结果表明，该跟踪器在处理由遮挡和快速运动引起的跟踪错误方面具有出色的效果和鲁棒性。

    The purpose of multi-object tracking (MOT) is to continuously track and identify objects detected in videos. Currently, most methods for multi-object tracking model the motion information and combine it with appearance information to determine and track objects. In this paper, unfalsified control is employed to address the ID-switch problem in multi-object tracking. We establish sequences of appearance information variations for the trajectories during the tracking process and design a detection and rectification module specifically for ID-switch detection and recovery. We also propose a simple and effective strategy to address the issue of ambiguous matching of appearance information during the data association process. Experimental results on publicly available MOT datasets demonstrate that the tracker exhibits excellent effectiveness and robustness in handling tracking errors caused by occlusions and rapid movements.
    
[^33]: 可解释的技术用于分析流式细胞术细胞变换器

    Explainable Techniques for Analyzing Flow Cytometry Cell Transformers. (arXiv:2307.14581v1 [q-bio.QM])

    [http://arxiv.org/abs/2307.14581](http://arxiv.org/abs/2307.14581)

    本文针对流式细胞术数据提出了一种基于ReluFormer的transformer架构，以及针对FCM量身定制的基于梯度和注意力的可视化技术。通过对儿童急性淋巴白血病（ALL）FCM样本的实验，我们展示了模型的决策过程，并演示了如何利用这些技术来检查训练后的模型。

    

    对于临床应用来说，对于深度学习模型的可解释性尤为重要，因为自动系统的决策具有深远影响。虽然已经存在各种后期解释方法，例如注意力可视化和显著性图，适用于常见的数据模态，包括自然语言和图像，但在流式细胞术（FCM）数据这一模态上的工作尚少。在这项工作中，我们评估了一种称为ReluFormer的transformer架构的使用，该架构可以简化注意力可视化，并提出了一种针对FCM量身定制的基于梯度和注意力的可视化技术。我们对儿童急性淋巴白血病（ALL）FCM样本的细胞分类和多边形回归进行了定性评估。结果展示了模型的决策过程，并演示了如何利用所提出的技术来检查训练后的模型。基于梯度的可视化不仅可以标识细胞.

    Explainability for Deep Learning Models is especially important for clinical applications, where decisions of automated systems have far-reaching consequences.  While various post-hoc explainable methods, such as attention visualization and saliency maps, already exist for common data modalities, including natural language and images, little work has been done to adapt them to the modality of Flow CytoMetry (FCM) data.  In this work, we evaluate the usage of a transformer architecture called ReluFormer that ease attention visualization as well as we propose a gradientand an attention-based visualization technique tailored for FCM. We qualitatively evaluate the visualization techniques for cell classification and polygon regression on pediatric Acute Lymphoblastic Leukemia (ALL) FCM samples. The results outline the model's decision process and demonstrate how to utilize the proposed techniques to inspect the trained model. The gradient-based visualization not only identifies cells tha
    
[^34]: 用于无监督驾驶视频交通事故检测的记忆增强多任务协作框架

    A Memory-Augmented Multi-Task Collaborative Framework for Unsupervised Traffic Accident Detection in Driving Videos. (arXiv:2307.14575v1 [cs.CV])

    [http://arxiv.org/abs/2307.14575](http://arxiv.org/abs/2307.14575)

    在本论文中，我们提出了一种记忆增强的多任务协作框架，用于无监督驾驶视频交通事故检测，以解决驾驶场景中长尾分布的驾驶事件可能带来的潜在危险。该方法不仅能够克服相机移动和光照变化对外观方法的干扰，还能够捕捉视频帧中的外观变化，实现对与自身相关的事故的检测。

    

    在自动驾驶和驾驶员辅助系统中，识别驾驶视频中的交通事故对确保安全至关重要。为了解决驾驶事件长尾分布可能带来的潜在危险，现有的交通事故检测方法主要依赖于无监督学习。然而，由于驾驶场景中相机的快速移动和动态场景，交通事故检测仍然具有挑战性。现有的无监督交通事故检测方法主要依赖于单一的预训练任务，即基于外观或未来物体定位任务来检测事故。然而，基于外观的方法容易受到相机快速移动和光照变化的干扰，显著降低了交通事故检测的性能。基于未来物体定位的方法可能无法捕捉视频帧中的外观变化，使得难以检测到车辆失控等与自身相关的事故。在本文中，我们提出了一种记忆增强的多任务协作框架

    Identifying traffic accidents in driving videos is crucial to ensuring the safety of autonomous driving and driver assistance systems. To address the potential danger caused by the long-tailed distribution of driving events, existing traffic accident detection (TAD) methods mainly rely on unsupervised learning. However, TAD is still challenging due to the rapid movement of cameras and dynamic scenes in driving scenarios. Existing unsupervised TAD methods mainly rely on a single pretext task, i.e., an appearance-based or future object localization task, to detect accidents. However, appearance-based approaches are easily disturbed by the rapid movement of the camera and changes in illumination, which significantly reduce the performance of traffic accident detection. Methods based on future object localization may fail to capture appearance changes in video frames, making it difficult to detect ego-involved accidents (e.g., out of control of the ego-vehicle). In this paper, we propose a
    
[^35]: 深度强化学习在自主导航中对安全约束的评估

    Evaluation of Safety Constraints in Autonomous Navigation with Deep Reinforcement Learning. (arXiv:2307.14568v1 [cs.RO])

    [http://arxiv.org/abs/2307.14568](http://arxiv.org/abs/2307.14568)

    本研究评估了在深度强化学习中考虑安全约束的自主导航，在比较了安全和不安全两种学习策略后发现，安全策略能够生成更安全的轨迹，避免碰撞，而不影响整体性能。

    

    尽管强化学习算法在自主导航领域取得了巨大的成功，但在考虑到安全限制的情况下，它们不能直接应用于真实的自主系统中。这些限制对于避免自动驾驶车辆在道路上出现不安全行为至关重要。为了凸显这些限制的重要性，在本研究中，我们比较了两种可学习的导航策略：安全策略和不安全策略。安全策略考虑到了约束条件，而另一种策略则没有。我们展示了在训练过程中，安全策略能够生成具有更大安全间隙（与障碍物的距离）并且发生更少碰撞的轨迹，而不损害整体性能。

    While reinforcement learning algorithms have had great success in the field of autonomous navigation, they cannot be straightforwardly applied to the real autonomous systems without considering the safety constraints. The later are crucial to avoid unsafe behaviors of the autonomous vehicle on the road. To highlight the importance of these constraints, in this study, we compare two learnable navigation policies: safe and unsafe. The safe policy takes the constraints into account, while the other does not. We show that the safe policy is able to generate trajectories with more clearance (distance to the obstacles) and makes less collisions while training without sacrificing the overall performance.
    
[^36]: 基于强化学习的模糊测试浏览器HTML渲染引擎

    Reinforcement learning guided fuzz testing for a browser's HTML rendering engine. (arXiv:2307.14556v1 [cs.AI])

    [http://arxiv.org/abs/2307.14556](http://arxiv.org/abs/2307.14556)

    本文提出了一种基于强化学习的方法，将训练好的测试用例生成模型与双深度Q网络结合，用于模糊测试浏览器的HTML渲染引擎，提高了代码覆盖性能。基于基础语法模糊器相比，代码覆盖率提高了18.5%。

    

    基于生成的模糊测试可以发现各种错误和安全漏洞。然而，与基于变异的模糊测试相比，开发一个能产生良好测试用例并决定在何处打破底层结构以执行新的代码路径的平衡生成器需要更长的时间。我们提出了一种新颖的方法，首次将训练好的测试用例生成深度学习模型与双深度Q网络（DDQN）结合起来。DDQN根据代码覆盖信号指导测试用例的创建。与基于基础语法模糊器相比，我们的方法将Firefox HTML渲染引擎的代码覆盖性能提高了高达18.5％。

    Generation-based fuzz testing can uncover various bugs and security vulnerabilities. However, compared to mutation-based fuzz testing, it takes much longer to develop a well-balanced generator that produces good test cases and decides where to break the underlying structure to exercise new code paths. We propose a novel approach to combine a trained test case generator deep learning model with a double deep Q-network (DDQN) for the first time. The DDQN guides test case creation based on a code coverage signal. Our approach improves the code coverage performance of the underlying generator model by up to 18.5\% for the Firefox HTML rendering engine compared to the baseline grammar based fuzzer.
    
[^37]: 带有多个游戏的对抗睡眠赌博问题：算法和排名应用

    Adversarial Sleeping Bandit Problems with Multiple Plays: Algorithm and Ranking Application. (arXiv:2307.14549v1 [cs.LG])

    [http://arxiv.org/abs/2307.14549](http://arxiv.org/abs/2307.14549)

    本论文提出了解决在线推荐系统中具有多个游戏的睡眠赌博问题的高效算法，该算法能够保证理论性能，并且后悔上界为$\bigO(kN^2\sqrt{T\log T})$。

    

    本论文介绍了在在线推荐系统中解决具有多个游戏的睡眠赌博问题的高效算法。该问题涉及有界的对抗性损失和未知的i.i.d.分布的武器可用性。该算法扩展了单武器选择的睡眠赌博算法，并保证达到理论性能，后悔上界为$\bigO(kN^2\sqrt{T\log T})$，其中$k$是每个时间步选择的武器数量，$N$是总武器数量，$T$是时间范围。

    This paper presents an efficient algorithm to solve the sleeping bandit with multiple plays problem in the context of an online recommendation system. The problem involves bounded, adversarial loss and unknown i.i.d. distributions for arm availability. The proposed algorithm extends the sleeping bandit algorithm for single arm selection and is guaranteed to achieve theoretical performance with regret upper bounded by $\bigO(kN^2\sqrt{T\log T})$, where $k$ is the number of arms selected per time step, $N$ is the total number of arms, and $T$ is the time horizon.
    
[^38]: 基于人工智能的速读工具，用于辅助患有ADHD、诵读困难或注意力不集中的学生

    Speed Reading Tool Powered by Artificial Intelligence for Students with ADHD, Dyslexia, or Short Attention Span. (arXiv:2307.14544v1 [cs.CL])

    [http://arxiv.org/abs/2307.14544](http://arxiv.org/abs/2307.14544)

    这项研究提出了一种基于人工智能的速读工具，用于帮助患有ADHD、诵读困难或注意力不集中的学生更高效地消化文本信息。该工具利用多层感知机算法和T5模型，通过文本处理和摘要任务实现。同时，该工具还应用了仿生阅读原则来增强可读性。

    

    本文提出了一种新颖的方法，用于帮助患有诵读困难、ADHD和注意力不集中的学生更高效地消化任何基于文本的信息。所提出的解决方案利用了多层感知机（MLP）算法进行复杂文本处理和摘要任务。该工具利用了Hugging Face的T5（文本到文本转换器）模型，将每个自然语言处理任务视为文本生成任务。模型使用较小的数据集对特定任务进行微调。NLTK的Punkt句子分词器用于将文本分割为句子列表。应用程序使用轻量级Web服务器和框架Flask提供。该工具还应用了仿生阅读的原则来增强可读性，包括加粗功能和对行、单词和字符间距的调整。本文讨论了基于人工智能的速读工具的方法、实现和结果。

    This paper presents a novel approach to assist students with dyslexia, ADHD, and short attention span in digesting any text-based information more efficiently. The proposed solution utilizes the Multilayer Perceptron (MLP) algorithm for complex text processing and summarization tasks. The tool leverages the T5 (Text-to-Text Transfer Transformer) model from Hugging Face, which treats every NLP task as a text generation task. The model is fine-tuned on specific tasks using a smaller dataset. The NLTK's Punkt Sentence Tokenizer is used to divide a text into a list of sentences. The application is served using Flask, a lightweight web server and framework. The tool also applies principles from Bionic Reading to enhance readability, which includes a bolding function and adjustments to line, word, and character spacing. The paper discusses the methodology, implementation, and results of the AI-based speed reading tool.
    
[^39]: 用于荒野SAR和寻找Patricia Wu-Murad的计算机视觉的开放问题

    Open Problems in Computer Vision for Wilderness SAR and The Search for Patricia Wu-Murad. (arXiv:2307.14527v1 [cs.CV])

    [http://arxiv.org/abs/2307.14527](http://arxiv.org/abs/2307.14527)

    该论文介绍了在荒野搜救中应用计算机视觉系统的挑战，提出了使用EfficientDET模型和无监督RX光谱分类器的方法，但在真实世界中存在假阳性的问题。

    

    本论文详细介绍了将两种计算机视觉系统，EfficientDET监督学习模型和无监督RX光谱分类器应用于来自日本Wu-Murad野外搜救（WSAR）努力的98.9 GB无人机图像的挑战，并确定了未来研究的3个方向。已经提出了至少19种方法和3个数据集，旨在在无人机图像中定位失踪人员，但只有3种方法（2种无监督和1种未知结构）在文献中被引用为实际WSAR操作中使用过。在这些提出的方法中，EfficientDET架构和无监督的RX光谱分类器被选择为最适合此情景的方法。EfficientDET模型应用于HERIDAL数据集，尽管在性能上达到了与最新技术相当的水平，但模型在假阳性方面无法在现实世界中有效识别（例如，识别树枝和岩石）

    This paper details the challenges in applying two computer vision systems, an EfficientDET supervised learning model and the unsupervised RX spectral classifier, to 98.9 GB of drone imagery from the Wu-Murad wilderness search and rescue (WSAR) effort in Japan and identifies 3 directions for future research. There have been at least 19 proposed approaches and 3 datasets aimed at locating missing persons in drone imagery, but only 3 approaches (2 unsupervised and 1 of an unknown structure) are referenced in the literature as having been used in an actual WSAR operation. Of these proposed approaches, the EfficientDET architecture and the unsupervised spectral RX classifier were selected as the most appropriate for this setting. The EfficientDET model was applied to the HERIDAL dataset and despite achieving performance that is statistically equivalent to the state-of-the-art, the model fails to translate to the real world in terms of false positives (e.g., identifying tree limbs and rocks 
    
[^40]: 车辆灯光模式：应对基于摄像头的车辆灯光数据集和指标的复杂性

    Patterns of Vehicle Lights: Addressing Complexities in Curation and Annotation of Camera-Based Vehicle Light Datasets and Metrics. (arXiv:2307.14521v1 [cs.CV])

    [http://arxiv.org/abs/2307.14521](http://arxiv.org/abs/2307.14521)

    本论文探讨了计算机视觉中车辆灯光的表示及其在自动驾驶中的应用。提出了三个重要任务：夜间车辆检测、3D车辆方向估计和动态轨迹线索。介绍了LISA车辆灯光数据集和相关的灯光可见性模型，可用于车辆检测、意图和轨迹预测以及安全路径规划。进行了比较分析。

    

    本论文探讨了计算机视觉中车辆灯光的表示及其对自动驾驶领域中各种任务的影响。讨论了表示车辆灯光的不同规范，包括边界框、中心点、角点和分割掩模，并从其优点和缺点的角度进行了讨论。确定了自动驾驶中可以从车辆灯光检测中受益的三个重要任务：夜间车辆检测、3D车辆方向估计和动态轨迹线索。每个任务可能需要不同的灯光表示。还讨论了收集和注释大规模数据集以供数据驱动模型训练的挑战，并引入了LISA车辆灯光数据集和相关的灯光可见性模型，该模型专门为车辆检测、意图和轨迹预测以及安全路径规划的下游应用提供灯光注释。对现有方法进行了比较分析。

    This paper explores the representation of vehicle lights in computer vision and its implications for various tasks in the field of autonomous driving. Different specifications for representing vehicle lights, including bounding boxes, center points, corner points, and segmentation masks, are discussed in terms of their strengths and weaknesses. Three important tasks in autonomous driving that can benefit from vehicle light detection are identified: nighttime vehicle detection, 3D vehicle orientation estimation, and dynamic trajectory cues. Each task may require a different representation of the light. The challenges of collecting and annotating large datasets for training data-driven models are also addressed, leading to introduction of the LISA Vehicle Lights Dataset and associated Light Visibility Model, which provides light annotations specifically designed for downstream applications in vehicle detection, intent and trajectory prediction, and safe path planning. A comparison of exi
    
[^41]: 用于评估可解释的部件原型图像分类器的Co-12配方

    The Co-12 Recipe for Evaluating Interpretable Part-Prototype Image Classifiers. (arXiv:2307.14517v1 [cs.CV])

    [http://arxiv.org/abs/2307.14517](http://arxiv.org/abs/2307.14517)

    本文提出了一种用于评估可解释的部件原型图像分类器的Co-12配方，并回顾了现有工作，揭示了研究的空白，并概述了评估部件原型模型解释质量的未来方法。这对于这个相对较新的研究领域的进展和成熟具有重要意义。

    

    可解释的部件原型模型是设计上可以解释的计算机视觉模型。这些模型学习原型部件，并识别图像中的这些组件，从而结合分类和解释。尽管近年来可解释模型受到了关注，但对可解释的部件原型模型的解释质量评估缺乏全面的概述。基于在arXiv:2201.08164中引入的Co-12解释质量属性（例如正确性、完整性、紧凑性），我们回顾了评估部件原型模型的现有工作，揭示了研究的空白，并概述了评估部件原型模型解释质量的未来方法。因此，本文对可解释的部件原型模型这个相对较新的研究领域的进展和成熟做出了贡献。我们还提供了一个“Co-12备忘单”，它作为对评估部件原型模型结果的简明总结。

    Interpretable part-prototype models are computer vision models that are explainable by design. The models learn prototypical parts and recognise these components in an image, thereby combining classification and explanation. Despite the recent attention for intrinsically interpretable models, there is no comprehensive overview on evaluating the explanation quality of interpretable part-prototype models. Based on the Co-12 properties for explanation quality as introduced in arXiv:2201.08164 (e.g., correctness, completeness, compactness), we review existing work that evaluates part-prototype models, reveal research gaps and outline future approaches for evaluation of the explanation quality of part-prototype models. This paper, therefore, contributes to the progression and maturity of this relatively new research field on interpretable part-prototype models. We additionally provide a ``Co-12 cheat sheet'' that acts as a concise summary of our findings on evaluating part-prototype models.
    
[^42]: 词语的留存：使用认知偏差和计算语言学预测决策和同义词吸引力。

    Words That Stick: Predicting Decision Making and Synonym Engagement Using Cognitive Biases and Computational Linguistics. (arXiv:2307.14511v1 [cs.HC])

    [http://arxiv.org/abs/2307.14511](http://arxiv.org/abs/2307.14511)

    这项研究使用认知偏差和计算语言学预测用户参与度和决策过程，发现准确代表核心思想、易于理解、能够引发情感反应并且常见的同义词能够促进更高的用户参与度。

    

    这项研究借鉴了认知心理学和信息系统研究的成果，旨在预测数字平台上的用户参与和决策过程。通过运用自然语言处理技术和认知偏差研究的见解，我们深入探讨了用户与数字内容中的同义词的交互。我们的方法将代表性、易用性、情感和分布这四种认知偏差融合到了READ模型中。通过进行综合性的用户调查，我们评估了该模型预测用户参与的能力，发现准确代表核心思想、易于理解、能够引发情感反应并且常见的同义词能够促进更高的用户参与度。至关重要的是，我们的工作为人机交互、数字行为和决策过程提供了全新的视角。我们的结果突显了认知偏差作为用户参与度的有力指标的潜力，凸显了它们在设计有效的数字平台中的重要性。

    This research draws upon cognitive psychology and information systems studies to anticipate user engagement and decision-making on digital platforms. By employing natural language processing (NLP) techniques and insights from cognitive bias research, we delve into user interactions with synonyms within digital content. Our methodology synthesizes four cognitive biasesRepresentativeness, Ease-of-use, Affect, and Distributioninto the READ model. Through a comprehensive user survey, we assess the model's ability to predict user engagement, discovering that synonyms that accurately represent core ideas, are easy to understand, elicit emotional responses, and are commonly encountered, promote greater user engagement. Crucially, our work offers a fresh lens on human-computer interaction, digital behaviors, and decision-making processes. Our results highlight the promise of cognitive biases as potent indicators of user engagement, underscoring their significance in designing effective digital
    
[^43]: 机器人触觉的注意力: 用于强健的模拟-真实触觉控制的触觉显著性预测

    Attention of Robot Touch: Tactile Saliency Prediction for Robust Sim-to-Real Tactile Control. (arXiv:2307.14510v1 [cs.RO])

    [http://arxiv.org/abs/2307.14510](http://arxiv.org/abs/2307.14510)

    这篇论文提出了一种新的概念——机器人触觉的“触觉显著性”，通过借鉴人类触觉注意机制和计算机视觉中的视觉显著性预测问题，提高了非结构化环境下触觉机器人控制的鲁棒性。

    

    高分辨率的触觉传感可以提供关于接触丰富的机器人任务中局部接触的准确信息。然而，在非结构化环境中部署这样的任务仍然未被充分研究。为了提高在非结构化环境中触觉机器人控制的鲁棒性，我们提出并研究了一个新的概念：机器人触觉的“触觉显著性”，灵感来源于神经科学中的人类触觉注意机制和计算机视觉中视觉显著性预测问题。类似于视觉显著性，这个概念涉及到通过触觉传感器捕捉到的触觉图像中识别关键信息。虽然视觉显著性数据集通常由人类进行注释，但由于触觉图像的反直觉模式，手动标记触觉图像具有挑战性。为了解决这个挑战，我们提出了一个由三个相互关联的网络组成的新方法: 1) 接触深度网络（ConDepNet），它生成一个接触深度地图以定位真实触觉中的变形。

    High-resolution tactile sensing can provide accurate information about local contact in contact-rich robotic tasks. However, the deployment of such tasks in unstructured environments remains under-investigated. To improve the robustness of tactile robot control in unstructured environments, we propose and study a new concept: \textit{tactile saliency} for robot touch, inspired by the human touch attention mechanism from neuroscience and the visual saliency prediction problem from computer vision. In analogy to visual saliency, this concept involves identifying key information in tactile images captured by a tactile sensor. While visual saliency datasets are commonly annotated by humans, manually labelling tactile images is challenging due to their counterintuitive patterns. To address this challenge, we propose a novel approach comprised of three interrelated networks: 1) a Contact Depth Network (ConDepNet), which generates a contact depth map to localize deformation in a real tactile 
    
[^44]: 通过非本地信息指导的预测方法改进不确定环境下的可靠导航

    Improving Reliable Navigation under Uncertainty via Predictions Informed by Non-Local Information. (arXiv:2307.14501v1 [cs.RO])

    [http://arxiv.org/abs/2307.14501](http://arxiv.org/abs/2307.14501)

    通过使用非本地信息进行预测，我们改进了在不确定环境下的可靠导航方法，并进行了实验证明在大规模大学建筑环境中可以减少9.3％的成本。

    

    我们通过使用非本地可用信息来预测进入未知空间的行为的好坏，改进了在部分映射环境中的可靠、长期目标导向的导航。一般情况下，预测导航的位置需要非本地信息：机器人迄今所见到的任何观察可能提供有关特定行进方向的好坏的信息。基于最近在不确定性下增强学习模型的计划方面的工作，我们提出了一种既能依靠非本地信息进行预测（通过图神经网络），又能设计可靠的方法：即使学习不能提供准确的预测，它也能始终达到目标。我们在三个需要非本地信息的模拟环境中进行了实验。在我们的大规模大学建筑环境中，根据真实地板图生成，我们证明了成本减少了9.3％。

    We improve reliable, long-horizon, goal-directed navigation in partially-mapped environments by using non-locally available information to predict the goodness of temporally-extended actions that enter unseen space. Making predictions about where to navigate in general requires non-local information: any observations the robot has seen so far may provide information about the goodness of a particular direction of travel. Building on recent work in learning-augmented model-based planning under uncertainty, we present an approach that can both rely on non-local information to make predictions (via a graph neural network) and is reliable by design: it will always reach its goal, even when learning does not provide accurate predictions. We conduct experiments in three simulated environments in which non-local information is needed to perform well. In our large scale university building environment, generated from real-world floorplans to the scale, we demonstrate a 9.3\% reduction in cost-
    
[^45]: 技术注释：ShinyAnimalCV: 基于云平台的开源网络应用，用于动物的物体检测、分割和三维可视化

    Technical note: ShinyAnimalCV: open-source cloud-based web application for object detection, segmentation, and three-dimensional visualization of animals using computer vision. (arXiv:2307.14487v1 [cs.CV])

    [http://arxiv.org/abs/2307.14487](http://arxiv.org/abs/2307.14487)

    ShinyAnimalCV是一个开源的云平台网络应用，用于动物的物体检测、分割和三维可视化，解决了将计算机视觉工具应用于动物数据的挑战，同时也满足了动物科学教育的需求。

    

    计算机视觉（CV）作为一种非侵入性且成本效益高的技术，通过实时和个性化的动物护理，进一步推动了精确畜牧业的发展。廉价的二维和三维相机传感器与各种机器学习和深度学习算法的结合，为改善畜牧生产系统提供了宝贵的机会。然而，尽管公开领域中存在各种CV工具，但将这些工具应用于动物数据可能具有挑战性，通常需要用户具备编程和数据分析技能，以及计算资源。此外，精确畜牧业的快速扩张正在在CV方面培养和教育动物科学学生，教育工作者面临着有效展示CV中复杂算法的挑战。因此，本研究的目标是开发ShinyAnimalCV，一个开源基于云平台的网络应用，用于动物的物体检测、分割和三维可视化。

    Computer vision (CV), a non-intrusive and cost-effective technology, has furthered the development of precision livestock farming by enabling optimized decision-making through timely and individualized animal care. The availability of affordable two- and three-dimensional camera sensors, combined with various machine learning and deep learning algorithms, has provided a valuable opportunity to improve livestock production systems. However, despite the availability of various CV tools in the public domain, applying these tools to animal data can be challenging, often requiring users to have programming and data analysis skills, as well as access to computing resources. Moreover, the rapid expansion of precision livestock farming is creating a growing need to educate and train animal science students in CV. This presents educators with the challenge of efficiently demonstrating the complex algorithms involved in CV. Thus, the objective of this study was to develop ShinyAnimalCV, an open-
    
[^46]: 使用 U-Net 脉冲神经网络的单通道语音增强

    Single Channel Speech Enhancement Using U-Net Spiking Neural Networks. (arXiv:2307.14464v1 [cs.SD])

    [http://arxiv.org/abs/2307.14464](http://arxiv.org/abs/2307.14464)

    本文提出了一种基于U-Net脉冲神经网络的单通道语音增强方法，该方法在提供可靠增强效果的同时，具有较低的计算能力和能耗需求。

    

    语音增强（SE）对于可靠的通信设备或稳健的语音识别系统至关重要。虽然常规的人工神经网络（ANN）在SE方面表现出色，但它们需要大量的计算能力和高能耗。在本文中，我们提出了一种基于U-Net结构的脉冲神经网络（SNN）来进行SE的新方法。SNN适用于处理具有时间维度的数据，如语音，并以其在神经形态硬件上的低能耗实现而闻名。因此，SNN是在资源有限的设备上进行实时应用的有趣候选。本工作的主要目标是开发一种基于SNN的模型，其性能可以与最先进的ANN模型相媲美。我们使用基于代理梯度的优化方法训练了一个深层SNN，并在不同信噪比和真实世界环境下使用感知客观测试来评估其性能。

    Speech enhancement (SE) is crucial for reliable communication devices or robust speech recognition systems. Although conventional artificial neural networks (ANN) have demonstrated remarkable performance in SE, they require significant computational power, along with high energy costs. In this paper, we propose a novel approach to SE using a spiking neural network (SNN) based on a U-Net architecture. SNNs are suitable for processing data with a temporal dimension, such as speech, and are known for their energy-efficient implementation on neuromorphic hardware. As such, SNNs are thus interesting candidates for real-time applications on devices with limited resources. The primary objective of the current work is to develop an SNN-based model with comparable performance to a state-of-the-art ANN model for SE. We train a deep SNN using surrogate-gradient-based optimization and evaluate its performance using perceptual objective tests under different signal-to-noise ratios and real-world no
    
[^47]: VISPUR: 用于识别和解释数据驱动决策中虚假关联的视觉辅助工具

    VISPUR: Visual Aids for Identifying and Interpreting Spurious Associations in Data-Driven Decisions. (arXiv:2307.14448v1 [cs.HC])

    [http://arxiv.org/abs/2307.14448](http://arxiv.org/abs/2307.14448)

    VISPUR是一个提供视觉分析和人本工作流程的系统，用于识别和解释数据驱动决策中的虚假关联。它包括混淆因素仪表盘和子群浏览器，可以帮助人们定位、推理和预防虚假关联。

    

    大数据和机器学习工具共同赋予人类在数据驱动决策方面的能力。然而，这些工具捕捉到的经验关联可能由于混淆因素和子群异质性而是虚假的。著名的辛普森悖论就是这样一个现象，聚合和子群级别的关联相互矛盾，给人类带来认知困惑和决策困难。现有的工具对于人类在实践中定位、推理和预防虚假关联提供的见解很少。我们提出VISPUR，一个提供因果分析框架和人本工作流程以应对虚假关联的可视化分析系统。其中包括一个混淆因素仪表盘，可以自动识别可能的混淆因素，以及一个子群浏览器，允许对可能导致对因果关系解释错误的多样子群模式进行可视化和比较。

    Big data and machine learning tools have jointly empowered humans in making data-driven decisions. However, many of them capture empirical associations that might be spurious due to confounding factors and subgroup heterogeneity. The famous Simpson's paradox is such a phenomenon where aggregated and subgroup-level associations contradict with each other, causing cognitive confusions and difficulty in making adequate interpretations and decisions. Existing tools provide little insights for humans to locate, reason about, and prevent pitfalls of spurious association in practice. We propose VISPUR, a visual analytic system that provides a causal analysis framework and a human-centric workflow for tackling spurious associations. These include a CONFOUNDER DASHBOARD, which can automatically identify possible confounding factors, and a SUBGROUP VIEWER, which allows for the visualization and comparison of diverse subgroup patterns that likely or potentially result in a misinterpretation of ca
    
[^48]: 基于无监督深度学习的联合增强光谱和空间保真度的Pansharpening方法

    Unsupervised Deep Learning-based Pansharpening with Jointly-Enhanced Spectral and Spatial Fidelity. (arXiv:2307.14403v1 [eess.IV])

    [http://arxiv.org/abs/2307.14403](http://arxiv.org/abs/2307.14403)

    这篇论文提出了一个基于无监督深度学习的Pansharpening模型，通过全分辨率训练和特定损失函数的使用，充分利用了这种方法的潜力，具有优秀的性能。

    

    近年来，深度学习在多分辨率图像的Pansharpening中发挥重要作用。由于缺乏地面真实数据，大多数基于深度学习的方法在降低分辨率领域进行监督训练。然而，对于高分辨率目标图像，训练在降低分辨率图像上的模型往往表现不佳。因此，一些研究团队现在转向在全分辨率领域进行无监督训练，通过定义合适的损失函数和训练范例。在这个背景下，我们最近提出了一个可以应用于许多现有架构的全分辨率训练框架。在这里，我们提出了一个新的基于深度学习的Pansharpening模型，充分利用了这种方法的潜力并提供了前沿的性能。除了与先前工作相比的架构改进，如使用残余注意力模块，所提出的模型还具有一个新的损失函数，可以同时促进光谱和空间保真度。

    In latest years, deep learning has gained a leading role in the pansharpening of multiresolution images. Given the lack of ground truth data, most deep learning-based methods carry out supervised training in a reduced-resolution domain. However, models trained on downsized images tend to perform poorly on high-resolution target images. For this reason, several research groups are now turning to unsupervised training in the full-resolution domain, through the definition of appropriate loss functions and training paradigms. In this context, we have recently proposed a full-resolution training framework which can be applied to many existing architectures.  Here, we propose a new deep learning-based pansharpening model that fully exploits the potential of this approach and provides cutting-edge performance. Besides architectural improvements with respect to previous work, such as the use of residual attention modules, the proposed model features a novel loss function that jointly promotes 
    
[^49]: 非线性自我增强深度管道在癌症治疗结果预测中的应用

    Non-Linear Self Augmentation Deep Pipeline for Cancer Treatment outcome Prediction. (arXiv:2307.14398v1 [eess.IV])

    [http://arxiv.org/abs/2307.14398](http://arxiv.org/abs/2307.14398)

    该论文提出了一种在癌症治疗结果预测中应用非线性自我增强深度管道的创新策略，通过选择和增强CT图像中的2D特征，提高了预测能力。

    

    免疫疗法作为治疗癌症的一种有希望的方法出现。鼓舞人心的发现验证了免疫疗法药物在处理肿瘤方面的疗效，导致了较长的生存率和对比传统化疗方法相比的显著毒性降低。然而，适合免疫疗法的患者群体仍然相对较小，这表明对于某些个体中有利的治疗反应的生理机制缺乏全面的理解，而其他患者则受益有限。为了解决这个问题，作者提出了一种创新的策略，结合非线性细胞结构和深度下游分类器。该方法旨在精选和增强从胸腹部CT图像中提取的2D特征，从而提高对治疗结果的预测能力。所提出的管道经过精心设计，可以与先进的嵌入式Point进行无缝集成。

    Immunotherapy emerges as promising approach for treating cancer. Encouraging findings have validated the efficacy of immunotherapy medications in addressing tumors, resulting in prolonged survival rates and notable reductions in toxicity compared to conventional chemotherapy methods. However, the pool of eligible patients for immunotherapy remains relatively small, indicating a lack of comprehensive understanding regarding the physiological mechanisms responsible for favorable treatment response in certain individuals while others experience limited benefits. To tackle this issue, the authors present an innovative strategy that harnesses a non-linear cellular architecture in conjunction with a deep downstream classifier. This approach aims to carefully select and enhance 2D features extracted from chest-abdomen CT images, thereby improving the prediction of treatment outcomes. The proposed pipeline has been meticulously designed to seamlessly integrate with an advanced embedded Point o
    
[^50]: 学习使用可训练差分算子模拟部分已知的时空动态

    Learning to simulate partially known spatio-temporal dynamics with trainable difference operators. (arXiv:2307.14395v1 [cs.LG])

    [http://arxiv.org/abs/2307.14395](http://arxiv.org/abs/2307.14395)

    本文提出了一种新的混合架构PDE-Net++，通过结合可训练差分算子和黑盒模型，明确嵌入了底层PDE的部分先验知识。数值实验证明，PDE-Net++具有比黑盒模型更高的预测准确性和更好的外推性能。

    

    最近，使用神经网络来模拟时空动态引起了很大的关注。然而，大多数现有的方法采用纯数据驱动的黑盒模型，其准确性和可解释性有限。通过将可训练的差分算子与黑盒模型相结合，我们提出了一种新的混合架构，将底层PDE的部分先验知识明确嵌入到PDE-Net++中。此外，我们引入了两种不同的选择，称为可训练翻转差分层（TFDL）和可训练动态差分层（TDDL），用于差分算子。大量的数值实验证明，PDE-Net++具有比黑盒模型更高的预测准确性和更好的外推性能。

    Recently, using neural networks to simulate spatio-temporal dynamics has received a lot of attention. However, most existing methods adopt pure data-driven black-box models, which have limited accuracy and interpretability. By combining trainable difference operators with black-box models, we propose a new hybrid architecture explicitly embedded with partial prior knowledge of the underlying PDEs named PDE-Net++. Furthermore, we introduce two distinct options called the trainable flipping difference layer (TFDL) and the trainable dynamic difference layer (TDDL) for the difference operators. Numerous numerical experiments have demonstrated that PDE-Net++ has superior prediction accuracy and better extrapolation performance than black-box models.
    
[^51]: 基于随机游走的异常检测的双重空间攻击

    Dual-Space Attacks against Random-Walk-based Anomaly Detection. (arXiv:2307.14387v1 [cs.CR])

    [http://arxiv.org/abs/2307.14387](http://arxiv.org/abs/2307.14387)

    本文考察了随机游走异常检测(RWAD)面临的图空间攻击和特征空间攻击，证明了攻击RWAD的复杂度是NP难的，并提出了两种攻击策略，进一步通过图引导攻击设计了更强大的特征空间攻击。

    

    随机游走异常检测(RWAD)通常用于在各种应用中识别异常模式。RWAD的一个有趣特点是输入图可以是预先存在的，也可以由原始特征构建而来。因此，对于RWAD有两种潜在的攻击方式：图空间攻击和特征空间攻击。本文通过设计实际的双重空间攻击，探究了图空间攻击和特征空间攻击之间的相互作用。为此，我们进行了深入的复杂性分析，证明了攻击RWAD是NP难的。然后，我们将图空间攻击形式化为双层优化问题，并提出了两种解决策略：交替迭代攻击(alterI-attack)或利用随机游走模型的闭合解(cf-attack)。最后，我们利用图空间攻击的结果来指导设计更强大的特征空间攻击(即，图引导攻击)。

    Random Walks-based Anomaly Detection (RWAD) is commonly used to identify anomalous patterns in various applications. An intriguing characteristic of RWAD is that the input graph can either be pre-existing or constructed from raw features. Consequently, there are two potential attack surfaces against RWAD: graph-space attacks and feature-space attacks. In this paper, we explore this vulnerability by designing practical dual-space attacks, investigating the interplay between graph-space and feature-space attacks. To this end, we conduct a thorough complexity analysis, proving that attacking RWAD is NP-hard. Then, we proceed to formulate the graph-space attack as a bi-level optimization problem and propose two strategies to solve it: alternative iteration (alterI-attack) or utilizing the closed-form solution of the random walk model (cf-attack). Finally, we utilize the results from the graph-space attacks as guidance to design more powerful feature-space attacks (i.e., graph-guided attack
    
[^52]: HyperFed: 非IID数据联邦学习中的超球面原型探索与一致聚合

    HyperFed: Hyperbolic Prototypes Exploration with Consistent Aggregation for Non-IID Data in Federated Learning. (arXiv:2307.14384v1 [cs.LG])

    [http://arxiv.org/abs/2307.14384](http://arxiv.org/abs/2307.14384)

    提出了HyperFed，用于解决联邦学习中非相同和独立数据分布造成的性能问题。该方法通过超球面原型探索、超球面原型学习和一致聚合等模块的结合，来解决类别统计的变化、层级信息利用不足和客户端聚合的不一致性问题。

    

    联邦学习（FL）以分散化的方式协同对用户数据建模。然而，在现实世界中，客户端之间的非相同和独立数据分布（非IID）阻碍了FL的性能，原因有三点，即（1）类别统计的变化，（2）层级信息利用不足和（3）客户端聚合的不一致性。为了解决上述问题，我们提出了HyperFed，其中包含三个主要模块，即超球面原型Tammes初始化（HPTI），超球面原型学习（HPL）和一致聚合（CA）。首先，服务器中的HPTI构造均匀分布且固定的类别原型，并与客户端分享以匹配类别统计，进一步指导本地客户端的一致特征表示。其次，每个客户端中的HPL在超球面模型空间中以共享的类别原型为监督，捕获本地数据中的层级信息。此外，在服务器中的CA进行一致聚合。

    Federated learning (FL) collaboratively models user data in a decentralized way. However, in the real world, non-identical and independent data distributions (non-IID) among clients hinder the performance of FL due to three issues, i.e., (1) the class statistics shifting, (2) the insufficient hierarchical information utilization, and (3) the inconsistency in aggregating clients. To address the above issues, we propose HyperFed which contains three main modules, i.e., hyperbolic prototype Tammes initialization (HPTI), hyperbolic prototype learning (HPL), and consistent aggregation (CA). Firstly, HPTI in the server constructs uniformly distributed and fixed class prototypes, and shares them with clients to match class statistics, further guiding consistent feature representation for local clients. Secondly, HPL in each client captures the hierarchical information in local data with the supervision of shared class prototypes in the hyperbolic model space. Additionally, CA in the server mi
    
[^53]: 当多任务学习遇到部分监督：计算机视觉综述

    When Multi-Task Learning Meets Partial Supervision: A Computer Vision Review. (arXiv:2307.14382v1 [cs.LG])

    [http://arxiv.org/abs/2307.14382](http://arxiv.org/abs/2307.14382)

    本综述讨论了多任务学习如何在部分监督设置下应用，以解决由于复杂的优化方案和高标签需求而引入的挑战。

    

    多任务学习(MTL)旨在同时学习多个任务，并利用它们之间的相互关系。通过使用共享资源同时计算多个输出，这种学习范式有潜力比传统方法在内存需求和推理时间方面更低。以往的MTL研究主要集中在完全监督方法上，因为任务之间的关系可以降低这些方法对数据的依赖性，并且可以提高性能。然而，MTL引入了一系列挑战，由于复杂的优化方案和更高的标签需求。本综述着重于MTL如何在不同的部分监督设置下应用，以解决这些挑战。首先，本综述分析了MTL传统上如何使用不同的参数共享技术在任务之间进行知识转移。其次，它介绍了不同的挑战。

    Multi-Task Learning (MTL) aims to learn multiple tasks simultaneously while exploiting their mutual relationships. By using shared resources to simultaneously calculate multiple outputs, this learning paradigm has the potential to have lower memory requirements and inference times compared to the traditional approach of using separate methods for each task. Previous work in MTL has mainly focused on fully-supervised methods, as task relationships can not only be leveraged to lower the level of data-dependency of those methods but they can also improve performance. However, MTL introduces a set of challenges due to a complex optimisation scheme and a higher labeling requirement. This review focuses on how MTL could be utilised under different partial supervision settings to address these challenges. First, this review analyses how MTL traditionally uses different parameter sharing techniques to transfer knowledge in between tasks. Second, it presents the different challenges arising fro
    
[^54]: EdgeConvEns: 基于卷积集成学习的边缘智能

    EdgeConvEns: Convolutional Ensemble Learning for Edge Intelligence. (arXiv:2307.14381v1 [cs.LG])

    [http://arxiv.org/abs/2307.14381](http://arxiv.org/abs/2307.14381)

    EdgeConvEns是一种卷积集成学习方法，用于在边缘网络上训练和集成异构的弱模型，以满足计算能力有限和分布式数据处理的需求。

    

    深度边缘智能旨在在计算能力有限的边缘网络上部署需要消耗计算资源的深度学习模型。此外，许多深度边缘智能应用程序需要处理分布式数据，由于隐私问题无法将其传输到中央服务器。分散式学习方法，如联邦学习，可以通过交换学到的权重来以集体方式学习模型。然而，它们通常需要复杂的模型，边缘设备可能无法处理，并且需要多轮网络通信才能达到最先进的性能。本研究提出了一种卷积集成学习方法，命名为EdgeConvEns，它可以在边缘上训练异构的弱模型，并学会将它们集成起来，在边缘上数据分布呈异质性。边缘模型采用不同计算能力的现场可编程门阵列（FPGA）设备进行独立实现和训练。

    Deep edge intelligence aims to deploy deep learning models that demand computationally expensive training in the edge network with limited computational power. Moreover, many deep edge intelligence applications require handling distributed data that cannot be transferred to a central server due to privacy concerns. Decentralized learning methods, such as federated learning, offer solutions where models are learned collectively by exchanging learned weights. However, they often require complex models that edge devices may not handle and multiple rounds of network communication to achieve state-of-the-art performances. This study proposes a convolutional ensemble learning approach, coined EdgeConvEns, that facilitates training heterogeneous weak models on edge and learning to ensemble them where data on edge are heterogeneously distributed. Edge models are implemented and trained independently on Field-Programmable Gate Array (FPGA) devices with various computational capacities. Learned 
    
[^55]: 大型语言模型如何帮助人们在设计和制造中?

    How Can Large Language Models Help Humans in Design and Manufacturing?. (arXiv:2307.14377v1 [cs.CL])

    [http://arxiv.org/abs/2307.14377](http://arxiv.org/abs/2307.14377)

    大型语言模型在设计和制造中的应用潜力以及其限制

    

    大型语言模型（LLMs）的发展，包括GPT-4，为生成设计提供了令人兴奋的新机会。我们研究了在整个设计和制造流程中应用该工具的可行性。具体而言，我们审查了LLMs在诸如将基于文本的提示转化为设计规范、将设计转化为制造指导、生成设计空间和设计变体、计算设计性能以及基于性能搜索设计等任务中的实用性。通过一系列例子，我们突出了当前LLMs的优点和局限性。通过揭示这些局限性，我们希望促进这些模型的持续改进和发展。

    The advancement of Large Language Models (LLMs), including GPT-4, provides exciting new opportunities for generative design. We investigate the application of this tool across the entire design and manufacturing workflow. Specifically, we scrutinize the utility of LLMs in tasks such as: converting a text-based prompt into a design specification, transforming a design into manufacturing instructions, producing a design space and design variations, computing the performance of a design, and searching for designs predicated on performance. Through a series of examples, we highlight both the benefits and the limitations of the current LLMs. By exposing these limitations, we aspire to catalyze the continued improvement and progression of these models.
    
[^56]: 指定过渡系统的过程化模型综合

    Synthesis of Procedural Models for Deterministic Transition Systems. (arXiv:2307.14368v1 [cs.FL])

    [http://arxiv.org/abs/2307.14368](http://arxiv.org/abs/2307.14368)

    本文介绍了一种通用方法，用于综合离散系统的状态过渡的过程化模型，并采用归纳式综合方法。该方法可以接受不同目标语言并应用于不同模型获取任务，从而实现了结构化程序的综合。

    

    本文介绍了一种通用的方法，用于综合给定离散系统的状态过渡的过程化模型。该方法是通用的，因为它接受不同的目标语言来对离散系统的状态过渡进行建模；不同的目标语言与不同的模型获取任务，例如STRIPS动作模型的综合，或细胞自动机的更新规则，都适用于我们的通用方法。我们采用归纳式综合方法，即将状态过渡的示例集合（表示为（前状态，动作，后状态）元组）作为输入。目标是综合出一个结构化程序，该程序在给定前状态上执行时输出其关联的后状态。我们的综合方法在一个具有极简指令集和有限内存的随机访问机器（RAM）的良构终止程序空间中实现组合搜索。

    This paper introduces a general approach for synthesizing procedural models of the state-transitions of a given discrete system. The approach is general in that it accepts different target languages for modeling the state-transitions of a discrete system; different model acquisition tasks with different target languages, such as the synthesis of STRIPS action models, or the update rule of a cellular automaton, fit as particular instances of our general approach. We follow an inductive approach to synthesis meaning that a set of examples of state-transitions, represented as (pre-state, action, post-state) tuples, are given as input. The goal is to synthesize a structured program that, when executed on a given pre-state, outputs its associated post-state. Our synthesis method implements a combinatorial search in the space of well-structured terminating programs that can be built using a Random-Access Machine (RAM), with a minimalist instruction set, and a finite amount of memory. The com
    
[^57]: 具有非凸目标函数的联邦分布鲁棒优化：算法与分析

    Federated Distributionally Robust Optimization with Non-Convex Objectives: Algorithm and Analysis. (arXiv:2307.14364v1 [math.OC])

    [http://arxiv.org/abs/2307.14364](http://arxiv.org/abs/2307.14364)

    本文提出了一个名为ASPIRE算法的异步分布式算法，用于解决联邦分布鲁棒优化问题，并引入了约束的D-范数不确定性集合，以灵活控制鲁棒性的程度。

    

    分布鲁棒优化 (DRO) 旨在找到一个最优决策，以在概率分布的模糊集合中最小化最坏情况成本，已在各种应用中广泛应用，例如网络行为分析、风险管理等。然而，现有的DRO技术面临三个关键挑战：1）如何处理分布环境中的异步更新；2）如何有效利用先验分布；3）如何根据不同场景适当调整鲁棒性的程度。为此，我们提出了一种名为Asynchronous Single-looP alternatIve gRadient projEction (ASPIRE)算法的异步分布式算法，以处理联邦分布鲁棒优化 (FDRO) 问题。此外，我们还开发了一种新的不确定性集合，即约束的D-范数不确定性集合，以有效利用先验分布并灵活控制鲁棒性的程度。

    Distributionally Robust Optimization (DRO), which aims to find an optimal decision that minimizes the worst case cost over the ambiguity set of probability distribution, has been widely applied in diverse applications, e.g., network behavior analysis, risk management, etc. However, existing DRO techniques face three key challenges: 1) how to deal with the asynchronous updating in a distributed environment; 2) how to leverage the prior distribution effectively; 3) how to properly adjust the degree of robustness according to different scenarios. To this end, we propose an asynchronous distributed algorithm, named Asynchronous Single-looP alternatIve gRadient projEction (ASPIRE) algorithm with the itErative Active SEt method (EASE) to tackle the federated distributionally robust optimization (FDRO) problem. Furthermore, a new uncertainty set, i.e., constrained D-norm uncertainty set, is developed to effectively leverage the prior distribution and flexibly control the degree of robustness.
    
[^58]: 一种基于LSTM、BiLSTM、CNN、GRU和GloVe的混合机器学习模型用于基因突变在癌症中的分类

    A Hybrid Machine Learning Model for Classifying Gene Mutations in Cancer using LSTM, BiLSTM, CNN, GRU, and GloVe. (arXiv:2307.14361v1 [q-bio.QM])

    [http://arxiv.org/abs/2307.14361](http://arxiv.org/abs/2307.14361)

    本研究提出了一个基于多种机器学习算法和嵌入模型的集成模型，用于基因突变在癌症中的分类。实验结果表明，该模型在准确率、精确率、召回率等指标上优于其他传统和最新的转换器模型，并且具有更高的训练效率。

    

    本研究提出了一个集成模型，将LSTM、BiLSTM、CNN、GRU和GloVe结合起来，用于在Kaggle的“个性化医学：重新定义癌症治疗”数据集中对基因突变进行分类。通过与BERT、Electra、Roberta、XLNet、Distilbert以及它们的LSTM集成等知名转换器进行比较，结果显示我们的模型在准确率、精确率、召回率、F1分数和均方误差方面都优于其他模型。令人惊讶的是，它还需要较少的训练时间，实现了性能和效率的完美结合。该研究证明了集成模型在基因突变分类等困难任务中的实用性。

    This study presents an ensemble model combining LSTM, BiLSTM, CNN, GRU, and GloVe to classify gene mutations using Kaggle's Personalized Medicine: Redefining Cancer Treatment dataset. The results were compared against well-known transformers like as BERT, Electra, Roberta, XLNet, Distilbert, and their LSTM ensembles. Our model outperformed all other models in terms of accuracy, precision, recall, F1 score, and Mean Squared Error. Surprisingly, it also needed less training time, resulting in a perfect combination of performance and efficiency. This study demonstrates the utility of ensemble models for difficult tasks such as gene mutation classification.
    
[^59]: 为安全关键的自主系统构建相关性框架

    Framing Relevance for Safety-Critical Autonomous Systems. (arXiv:2307.14355v1 [cs.AI])

    [http://arxiv.org/abs/2307.14355](http://arxiv.org/abs/2307.14355)

    该论文旨在开发一种形式化方法来确定安全关键的自主系统在当前任务下的相关信息，以构建适当的世界观以实现其目标。

    

    我们正在构建复杂的高度自主的系统，这些系统具有内部信念、感知环境并交换信息的能力。这些系统构建了它们各自的世界观，并基于此规划了未来的操作，即它们根据可能的未来预测选择行动来实现目标。通常，这些系统面临着来自各种来源的大量信息，其中并不是所有信息都是相关的。我们的工作目标是开发一种形式化方法来确定在当前任务下对于安全关键的自主系统来说什么是相关的，即什么信息足以构建适当的世界观以实现其任务目标。

    We are in the process of building complex highly autonomous systems that have build-in beliefs, perceive their environment and exchange information. These systems construct their respective world view and based on it they plan their future manoeuvres, i.e., they choose their actions in order to establish their goals based on their prediction of the possible futures. Usually these systems face an overwhelming flood of information provided by a variety of sources where by far not everything is relevant. The goal of our work is to develop a formal approach to determine what is relevant for a safety critical autonomous system at its current mission, i.e., what information suffices to build an appropriate world view to accomplish its mission goals.
    
[^60]: Copilot for Xcode: 探索AI辅助编程通过激励基于云的大型语言模型

    Copilot for Xcode: Exploring AI-Assisted Programming by Prompting Cloud-based Large Language Models. (arXiv:2307.14349v1 [cs.SE])

    [http://arxiv.org/abs/2307.14349](http://arxiv.org/abs/2307.14349)

    Copilot for Xcode是一种AI辅助编程工具，通过集成基于云的大型语言模型与Apple的本地开发环境Xcode，提高了软件开发人员的生产力和创造力。它利用NLP技术处理源代码标记和模式，并提供代码生成、自动补全、文档编写和错误检测等功能。用户还可以在聊天界面中进行查询和"小"决策的制定。该工具在Xcode中使用NLP激励编程已经证明有效。

    

    本文介绍了一种名为Copilot for Xcode的AI辅助编程工具，用于支持人类软件开发人员进行程序组合和设计。通过将基于云的大型语言模型（LLM）与Apple的本地开发环境Xcode无缝集成，该工具提高了生产力，释放了苹果软件生态系统（例如iOS应用和macOS）中的软件开发创造力。利用先进的自然语言处理（NLP）技术，Copilot for Xcode能够有效处理代码库中的源代码标记和模式，实现代码生成、自动补全、文档编写和错误检测等特性。软件开发人员还可以通过Copilot for Xcode的聊天界面进行查询和"小"决策的制定，其中一些决策可以同时进行。最后，我们通过简单的案例研究提供了在Xcode中利用NLP激励流行的编程实证效果。

    This paper presents an AI-assisted programming tool called Copilot for Xcode for program composition and design to support human software developers. By seamlessly integrating cloud-based Large Language Models (LLM) with Apple's local development environment, Xcode, this tool enhances productivity and unleashes creativity for software development in Apple software ecosystem (e.g., iOS apps, macOS). Leveraging advanced natural language processing (NLP) techniques, Copilot for Xcode effectively processes source code tokens and patterns within code repositories, enabling features such as code generation, autocompletion, documentation, and error detection. Software developers can also query and make "small" decisions for program composition, some of which can be made simultaneously, and this is facilitated through prompt engineering in a chat interface of Copilot for Xcode. Finally, we present simple case studies as evidence of the effectiveness of utilizing NLP in Xcode to prompt popular 
    
[^61]: 多目标深度强化学习用于移动边缘计算

    Multi-objective Deep Reinforcement Learning for Mobile Edge Computing. (arXiv:2307.14346v1 [cs.NI])

    [http://arxiv.org/abs/2307.14346](http://arxiv.org/abs/2307.14346)

    本研究提出了一种多目标深度强化学习方法，以解决移动边缘计算中的离线问题。该方法通过考虑未知偏好参数，最小化能耗和传输延迟，并采用近端策略优化算法进行资源调度。引入了一种特征构建方法，用于处理MEC系统中的多个边缘。

    

    移动边缘计算（MEC）对于下一代移动网络应用至关重要，这些应用优先考虑各种性能指标，包括延迟和能耗。然而，传统的单目标调度解决方案不能直接应用于实际系统，因为这些应用的偏好（即不同目标的权重）通常是未知的或难以事先指定。在这项研究中，我们通过制定一个多目标离线问题来解决这个问题，针对MEC中的多个边缘来最小化预期的长期能耗和传输延迟，同时考虑未知的偏好作为参数。为了解决未知偏好的挑战，我们设计了一种基于深度强化学习（MORL）和近端策略优化（PPO）的多目标资源调度方案。此外，我们还引入了一种精心设计的状态编码方法，用于构建MEC系统中多个边缘的特征。

    Mobile edge computing (MEC) is essential for next-generation mobile network applications that prioritize various performance metrics, including delays and energy consumption. However, conventional single-objective scheduling solutions cannot be directly applied to practical systems in which the preferences of these applications (i.e., the weights of different objectives) are often unknown or challenging to specify in advance. In this study, we address this issue by formulating a multi-objective offloading problem for MEC with multiple edges to minimize expected long-term energy consumption and transmission delay while considering unknown preferences as parameters. To address the challenge of unknown preferences, we design a multi-objective (deep) reinforcement learning (MORL)-based resource scheduling scheme with proximal policy optimization (PPO). In addition, we introduce a well-designed state encoding method for constructing features for multiple edges in MEC systems, a sophisticate
    
[^62]: MNIST手写数字中的扭曲图像剪枝

    Pruning Distorted Images in MNIST Handwritten Digits. (arXiv:2307.14343v1 [cs.CV])

    [http://arxiv.org/abs/2307.14343](http://arxiv.org/abs/2307.14343)

    本论文提出了一个两阶段的深度学习方法，通过识别和剔除扭曲和模糊图像，从而提高了MNIST数据集中手写数字的分类准确性和置信度。

    

    由于书写风格的多样性和噪声图像的存在，识别手写数字是一项具有挑战性的任务。广泛使用的MNIST数据集，作为这个任务的基准，包含具有不规则形状、不完整笔画和变异倾斜度的扭曲数字，同时存在于训练和测试数据集中。因此，这些因素导致了数字识别准确度的降低。为了克服这个挑战，我们提出了一个两阶段的深度学习方法。在第一阶段，我们使用一个简单的神经网络来识别训练集中的扭曲数字。这个模型用于检测和过滤出这些扭曲和模糊的图像。在第二阶段，我们将这些被识别出的图像从训练数据集中排除，并使用过滤后的数据集重新训练模型。这个过程旨在提高分类准确性和置信度，同时减轻欠拟合和过拟合的问题。我们的实验结果证明了这个方法的有效性。

    Recognizing handwritten digits is a challenging task primarily due to the diversity of writing styles and the presence of noisy images. The widely used MNIST dataset, which is commonly employed as a benchmark for this task, includes distorted digits with irregular shapes, incomplete strokes, and varying skew in both the training and testing datasets. Consequently, these factors contribute to reduced accuracy in digit recognition. To overcome this challenge, we propose a two-stage deep learning approach. In the first stage, we create a simple neural network to identify distorted digits within the training set. This model serves to detect and filter out such distorted and ambiguous images. In the second stage, we exclude these identified images from the training dataset and proceed to retrain the model using the filtered dataset. This process aims to improve the classification accuracy and confidence levels while mitigating issues of underfitting and overfitting. Our experimental results
    
[^63]: 如何扩展您的EMA（arXiv:2307.13813v1 [stat.ML]）

    How to Scale Your EMA. (arXiv:2307.13813v1 [stat.ML])

    [http://arxiv.org/abs/2307.13813](http://arxiv.org/abs/2307.13813)

    本研究提供了在存在模型EMA的情况下进行优化的缩放规则，以保持训练动态的一致性。这对于实际机器学习中的权衡批量大小和墙钟时间非常重要。模型EMA能够提高模型的性能以及稳定训练过程，并为自监督学习提供学习信号。

    

    在实际机器学习中，保持训练动态在批量大小之间的一致性是一种重要工具，它能够在批量大小和墙钟时间之间进行权衡。这种权衡通常通过一个缩放规则来实现，例如，在随机梯度下降中，应该将学习率与批量大小呈线性关系。另一个实际机器学习的重要工具是模型指数移动平均（EMA），它是一个不接收梯度信息的模型副本，而是以一定的动量跟随其目标模型。这个模型EMA可以提高监督学习的稳健性和泛化性能，稳定伪标记，为自监督学习提供学习信号。之前的研究将模型EMA与优化分开处理，导致批量大小之间存在不同的训练动态和较低的模型性能。在这项工作中，我们提供了在存在模型EMA的情况下进行优化的缩放规则，并展示了其效果。

    Preserving training dynamics across batch sizes is an important tool for practical machine learning as it enables the trade-off between batch size and wall-clock time. This trade-off is typically enabled by a scaling rule, for example, in stochastic gradient descent, one should scale the learning rate linearly with the batch size. Another important tool for practical machine learning is the model Exponential Moving Average (EMA), which is a model copy that does not receive gradient information, but instead follows its target model with some momentum. This model EMA can improve the robustness and generalization properties of supervised learning, stabilize pseudo-labeling, and provide a learning signal for Self-Supervised Learning (SSL). Prior works have treated the model EMA separately from optimization, leading to different training dynamics across batch sizes and lower model performance. In this work, we provide a scaling rule for optimization in the presence of model EMAs and demonst
    
[^64]: 深度布拉德利-特里评分：在没有具体评价标准的情况下估计物品的属性

    Deep Bradley-Terry Rating: Estimate Properties Without Metric of Unseen Items. (arXiv:2307.13709v1 [cs.LG])

    [http://arxiv.org/abs/2307.13709](http://arxiv.org/abs/2307.13709)

    本论文提出了深度布拉德利-特里评分（DBTR）方法，用于评估不一定存在于数据集中的未知物品的属性。该方法通过将传统的布拉德利-特里模型与神经网络结构无缝结合，成功地学习了这些属性的预期量化。

    

    在现实世界中，许多属性，如竞争环境中的可取性或强度，无法直接观测，这使得它们难以评估。为了解决这个具有挑战性的问题，先前的研究主要集中在估计已知物品的这些属性，特别是出现在配对比较数据集中的运动员的实力。在本文中，我们介绍了深度布拉德利-特里评分（DBTR），这是一个新颖的机器学习框架，用于评估不一定存在于数据集中的未知物品的任何属性。我们的方法无缝地将传统的布拉德利-特里模型与神经网络结构相结合。我们还进一步推广了这个架构，用于具有不公平性的非对称环境，这在现实世界中更为常见。在我们的实验分析中，DBTR成功地学习了这些属性的预期量化。

    Many properties in real world, such as desirability or strength in competitive environment, can't be directly observed, which makes them difficult to evaluate. To deal with this challenging problem, prior work has primarily focused on estimating those properties of known items, especially the strength of sports players, only of those who appears in paired comparison dataset. In this paper, we introduce Deep Bradley-Terry Rating (DBTR), a novel ML framework to evaluate any properties of unknown items, not necessarily present in dataset. Our method seamlessly integrates traditional Bradley-Terry model with a neural network structure. We also generalizes this architecture further for asymmetric environment with unfairness, which is much more common in real world settings. In our experimental analysis, DBTR successfully learned desired quantification of those properties.
    
[^65]: Duet: 高效且可扩展的混合神经关系理解

    Duet: efficient and scalable hybriD neUral rElation undersTanding. (arXiv:2307.13494v1 [cs.DB])

    [http://arxiv.org/abs/2307.13494](http://arxiv.org/abs/2307.13494)

    Duet是一种高效且可扩展的混合神经关系理解方法，旨在解决基数估计问题中高成本和难以区分的采样方法，并通过可微分的预测过程改进模型的准确性。

    

    基于概率分布估计的基数估计方法相较于传统方法取得了高精度的估计结果。然而，最先进的方法由于在处理范围查询时使用的采样方法而导致估计成本较高。此外，这种采样方法也使得它们难以区分，因此来自查询工作负载的监督信号很难训练模型以提高基数估计的准确性。在本文中，我们提出了一种新的混合确定性建模方法（Duet）用于基数估计问题，与以前的方法相比，具有更好的效率和可扩展性。Duet可以以更低的时间和内存成本直接估计范围查询的基数，并且以可区分的形式呈现。由于此方法的预测过程是可微分的，我们可以将估计误差较大的查询纳入训练过程以进行改进。

    Cardinality estimation methods based on probability distribution estimation have achieved high-precision estimation results compared to traditional methods. However, the most advanced methods suffer from high estimation costs due to the sampling method they use when dealing with range queries. Also, such a sampling method makes them difficult to differentiate, so the supervision signal from the query workload is difficult to train the model to improve the accuracy of cardinality estimation. In this paper, we propose a new hybrid and deterministic modeling approach (Duet) for the cardinality estimation problem which has better efficiency and scalability compared to previous approaches. Duet allows for direct cardinality estimation of range queries with significantly lower time and memory costs, as well as in a differentiable form. As the prediction process of this approach is differentiable, we can incorporate queries with larger model estimation errors into the training process to addr
    
[^66]: 用更长更好的上下文理解将模型赋能

    Empower Your Model with Longer and Better Context Comprehension. (arXiv:2307.13365v1 [cs.CL])

    [http://arxiv.org/abs/2307.13365](http://arxiv.org/abs/2307.13365)

    本文研究了大语言模型（LLMs）内的信息传递，并提出了一种名为注意力转移的技术，该技术能够使模型在不增加训练或对生成流畅性的影响的情况下实现更长更好的上下文理解。

    

    最近，随着大量的大语言模型（LLMs）的出现，人工智能的实现进入了一个新的时代。无论这些模型自身的容量和结构如何，都存在对LLMs具有更长更复杂上下文的增强理解的需求，而模型通常在处理超出其理解能力范围的句子序列时会遇到上限，导致产生离题或混乱的回答。虽然最近有几项工作试图以不同的方式解决这个问题，但它们很少关注“为什么模型无法自行弥补或增强自己的能力”。在本文中，我们对LLMs内的信息传递性质进行了深入研究，并提出了一种名为注意力转移的新技术。这种技术能够使模型在最小化额外训练或对生成流利性的影响的情况下实现更长更好的上下文理解。我们的实验证明了这一点。

    Recently, with the emergence of numerous Large Language Models (LLMs), the implementation of AI has entered a new era. Irrespective of these models' own capacity and structure, there is a growing demand for LLMs to possess enhanced comprehension of longer and more complex contexts with relatively smaller sizes. Models often encounter an upper limit when processing sequences of sentences that extend beyond their comprehension capacity and result in off-topic or even chaotic responses. While several recent works attempt to address this issue in various ways, they rarely focus on "why models are unable to compensate or strengthen their capabilities on their own". In this paper, we thoroughly investigate the nature of information transfer within LLMs and propose a novel technique called Attention Transition. This technique empowers models to achieve longer and better context comprehension with minimal additional training or impact on generation fluency. Our experiments are conducted in XSu
    
[^67]: 关于受恶意噪声影响的公正约束学习的脆弱性

    On the Vulnerability of Fairness Constrained Learning to Malicious Noise. (arXiv:2307.11892v1 [cs.LG])

    [http://arxiv.org/abs/2307.11892](http://arxiv.org/abs/2307.11892)

    这项研究考虑了公正约束学习对恶意噪声的脆弱性，发现使用随机分类器可以在精度上只损失$\Theta(\alpha)$和$O(\sqrt{\alpha})$，对应不同的公正约束要求。

    

    我们考虑了公正约束学习对训练数据中微小恶意噪声的脆弱性。Konstantinov和Lampert (2021)在这个问题上进行了研究，并展示了负面结果，表明在不平衡的群组大小下存在一些数据分布，任何适当的学习器都会表现出较高的脆弱性。在这里，我们展示了更乐观的观点，如果允许随机分类器，则情况更加细致。例如，对于人口统计学平等性，我们显示只会产生$\Theta(\alpha)$的精度损失，其中$\alpha$是恶意噪声率，甚至可以与没有公正约束的情况完全匹配。对于机会均等性，我们显示只会产生$O(\sqrt{\alpha})$的损失，并给出一个匹配的$\Omega(\sqrt{\alpha})$的下界。相比之下，Konstantinov和Lampert (2021)示范了对于适当的学习器，这两个概念的精度损失都是$\Omega(1)$。关键的技术创新是

    We consider the vulnerability of fairness-constrained learning to small amounts of malicious noise in the training data. Konstantinov and Lampert (2021) initiated the study of this question and presented negative results showing there exist data distributions where for several fairness constraints, any proper learner will exhibit high vulnerability when group sizes are imbalanced. Here, we present a more optimistic view, showing that if we allow randomized classifiers, then the landscape is much more nuanced. For example, for Demographic Parity we show we can incur only a $\Theta(\alpha)$ loss in accuracy, where $\alpha$ is the malicious noise rate, matching the best possible even without fairness constraints. For Equal Opportunity, we show we can incur an $O(\sqrt{\alpha})$ loss, and give a matching $\Omega(\sqrt{\alpha})$lower bound. In contrast, Konstantinov and Lampert (2021) showed for proper learners the loss in accuracy for both notions is $\Omega(1)$. The key technical novelty 
    
[^68]: 深度直接训练的脉冲神经网络用于目标检测

    Deep Directly-Trained Spiking Neural Networks for Object Detection. (arXiv:2307.11411v1 [cs.CV])

    [http://arxiv.org/abs/2307.11411](http://arxiv.org/abs/2307.11411)

    EMS-YOLO是一种直接训练的脉冲神经网络框架，通过使用替代梯度而不是ANN-SNN转换策略，成功解决了深度SNN的目标检测问题。

    

    脉冲神经网络（SNN）是一种受大脑启发的高能效模型，它通过时空动态来编码信息。最近，直接训练的深度SNN在少数时间步骤上的分类任务中表现出了很高的性能。然而，如何设计一个直接训练的SNN来解决目标检测回归任务仍然是一个具有挑战性的问题。为了解决这个问题，我们提出了EMS-YOLO，一种用于目标检测的新型直接训练的SNN框架，它是第一个使用替代梯度而不是ANN-SNN转换策略来训练深度SNN的尝试。具体地，我们设计了一个全脉冲残差块EMS-ResNet，它可以有效地扩展直接训练的SNN的深度，并且能够具有低功耗。此外，我们在理论上分析并证明了EMS-ResNet可以避免梯度消失或梯度爆炸的问题。实验结果表明，我们的方法优于最先进的ANN-SNN转换方法。

    Spiking neural networks (SNNs) are brain-inspired energy-efficient models that encode information in spatiotemporal dynamics. Recently, deep SNNs trained directly have shown great success in achieving high performance on classification tasks with very few time steps. However, how to design a directly-trained SNN for the regression task of object detection still remains a challenging problem. To address this problem, we propose EMS-YOLO, a novel directly-trained SNN framework for object detection, which is the first trial to train a deep SNN with surrogate gradients for object detection rather than ANN-SNN conversion strategies. Specifically, we design a full-spike residual block, EMS-ResNet, which can effectively extend the depth of the directly-trained SNN with low power consumption. Furthermore, we theoretically analyze and prove the EMS-ResNet could avoid gradient vanishing or exploding. The results demonstrate that our approach outperforms the state-of-the-art ANN-SNN conversion me
    
[^69]: 信息检索遇上大型语言模型：中国信息检索界的战略报告

    Information Retrieval Meets Large Language Models: A Strategic Report from Chinese IR Community. (arXiv:2307.09751v1 [cs.IR])

    [http://arxiv.org/abs/2307.09751](http://arxiv.org/abs/2307.09751)

    本论文总结了中国信息检索界关于信息检索与大型语言模型相结合的战略报告。大型语言模型在文本理解、生成和知识推理方面具有出色能力，为信息检索研究开辟了新的方向。此外，IR模型、LLM和人类之间的协同关系形成了一种更强大的信息寻求技术范式。然而，该领域仍面临计算成本、可信度、领域特定限制和伦理考虑等挑战。

    

    信息检索（IR）领域已经取得了显著的发展，超越了传统搜索，以满足多样化的用户信息需求。最近，大型语言模型（LLM）在文本理解、生成和知识推理方面展示了出色的能力，为IR研究开辟了新的契机。LLM不仅能够促进生成式检索，还提供了改进的用户理解、模型评估和用户系统交互方案。更重要的是，IR模型、LLM和人类之间的协同关系构成了一种更强大的信息寻求技术范式。IR模型提供实时和相关的信息，LLM贡献内部知识，而人类在信息服务的可靠性方面起着需求者和评估者的中心作用。然而，仍然存在着一些重要挑战，包括计算成本、可信度问题、领域特定限制和伦理考虑。

    The research field of Information Retrieval (IR) has evolved significantly, expanding beyond traditional search to meet diverse user information needs. Recently, Large Language Models (LLMs) have demonstrated exceptional capabilities in text understanding, generation, and knowledge inference, opening up exciting avenues for IR research. LLMs not only facilitate generative retrieval but also offer improved solutions for user understanding, model evaluation, and user-system interactions. More importantly, the synergistic relationship among IR models, LLMs, and humans forms a new technical paradigm that is more powerful for information seeking. IR models provide real-time and relevant information, LLMs contribute internal knowledge, and humans play a central role of demanders and evaluators to the reliability of information services. Nevertheless, significant challenges exist, including computational costs, credibility concerns, domain-specific limitations, and ethical considerations. To 
    
[^70]: 人工智能是算法模仿：为什么人工“代理”不是（也不会成为）真正的代理

    Artificial intelligence is algorithmic mimicry: why artificial "agents" are not (and won't be) proper agents. (arXiv:2307.07515v1 [cs.AI])

    [http://arxiv.org/abs/2307.07515](http://arxiv.org/abs/2307.07515)

    本研究通过对比生物系统和算法系统，指出了生物系统具有自我制造自主能力、符号和物理方面没有区分以及体验到模糊问题的大世界等特点，而算法系统则与此相反。

    

    这篇论文通过对比生物系统和算法系统，重点探讨“代理”概念，来探讨人工通用智能（AGI）的发展前景。作者指出了三个基本的差异：（1）生物系统具有自我制造的自主能力，能够设定自身的内在目标，而算法系统存在于一个由外部代理提供目标函数的计算环境中。（2）生物系统是具体体现的，即其符号和物理方面没有区分，而算法运行在计算结构上，最大限度地将软件与硬件隔离。（3）生物系统体验到一个庞大的世界，其中大多数问题是模糊的（并非全部可定义），而算法系统存在于一个小世界中，其中所有问题都是明确的。这三个差异说明了生物和算法系统具有非常不同的能力。

    What is the prospect of developing artificial general intelligence (AGI)? I investigate this question by systematically comparing living and algorithmic systems, with a special focus on the notion of "agency." There are three fundamental differences to consider: (1) Living systems are autopoietic, that is, self-manufacturing, and therefore able to set their own intrinsic goals, while algorithms exist in a computational environment with target functions that are both provided by an external agent. (2) Living systems are embodied in the sense that there is no separation between their symbolic and physical aspects, while algorithms run on computational architectures that maximally isolate software from hardware. (3) Living systems experience a large world, in which most problems are ill-defined (and not all definable), while algorithms exist in a small world, in which all problems are well-defined. These three differences imply that living and algorithmic systems have very different capab
    
[^71]: GP引导的MPPI在复杂未知杂乱环境中的高效导航

    GP-guided MPPI for Efficient Navigation in Complex Unknown Cluttered Environments. (arXiv:2307.04019v1 [cs.RO])

    [http://arxiv.org/abs/2307.04019](http://arxiv.org/abs/2307.04019)

    本研究提出了一种GP引导的MPPI方法用于在复杂未知杂乱环境中进行高效导航。该方法利用局部感知模型和在线学习技术，通过构建不确定性表面，识别并推荐最优子目标给局部的MPPI规划器。最终实现了满足要求的最优控制序列。

    

    在具有有限感知能力的未知杂乱环境中进行机器人导航对机器人学来说是一个重大挑战。局部轨迹优化方法，如模型预测路径积分（MPPI），是解决这一挑战的一种有希望的方法。然而，在遇到具有挑战性的环境条件或在计划范围之外导航时，需要全局引导来确保有效的导航。本研究提出了GP-MPPI，一种基于在线学习的控制策略，它将MPPI与基于稀疏高斯过程（SGP）的局部感知模型相结合。关键思想是利用SGP的学习能力构建一个方差（不确定性）表面，使机器人能够了解周围的可导航空间，识别一组建议的子目标，并最终推荐最小化预定义成本函数的最优子目标给局部的MPPI规划器。之后，MPPI计算出满足要求的最优控制序列。

    Robotic navigation in unknown, cluttered environments with limited sensing capabilities poses significant challenges in robotics. Local trajectory optimization methods, such as Model Predictive Path Intergal (MPPI), are a promising solution to this challenge. However, global guidance is required to ensure effective navigation, especially when encountering challenging environmental conditions or navigating beyond the planning horizon. This study presents the GP-MPPI, an online learning-based control strategy that integrates MPPI with a local perception model based on Sparse Gaussian Process (SGP). The key idea is to leverage the learning capability of SGP to construct a variance (uncertainty) surface, which enables the robot to learn about the navigable space surrounding it, identify a set of suggested subgoals, and ultimately recommend the optimal subgoal that minimizes a predefined cost function to the local MPPI planner. Afterward, MPPI computes the optimal control sequence that sati
    
[^72]: 从不完整话语中挖掘线索：一种增强查询的网络用于不完整话语重写

    Mining Clues from Incomplete Utterance: A Query-enhanced Network for Incomplete Utterance Rewriting. (arXiv:2307.00866v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.00866](http://arxiv.org/abs/2307.00866)

    这篇论文提出了一种增强查询的网络用于不完整话语重写，通过引入查询模板来明确语义结构知识，并采用有效的编辑操作评分网络来建模两个标记之间的关系。在多个公共数据集上，该模型取得了最先进的性能。

    

    最近，不完整话语重写引起了广泛关注。然而，先前的工作没有考虑不完整话语和重写话语之间的语义结构信息，也没有隐式和不充分地建模语义结构。为解决这个问题，我们提出了一种增强查询网络（QUEEN）。首先，我们提出的查询模板明确地引入了不完整话语和重写话语之间的指导性语义结构知识，使模型能够理解在哪里进行参考或恢复被省略的标记。然后，我们采用一种快速有效的编辑操作评分网络来建模两个标记之间的关系。由于提出的查询模板和精心设计的编辑操作评分网络的好处，QUEEN在多个公共数据集上实现了最先进的性能。

    Incomplete utterance rewriting has recently raised wide attention. However, previous works do not consider the semantic structural information between incomplete utterance and rewritten utterance or model the semantic structure implicitly and insufficiently. To address this problem, we propose a QUEry-Enhanced Network (QUEEN). Firstly, our proposed query template explicitly brings guided semantic structural knowledge between the incomplete utterance and the rewritten utterance making model perceive where to refer back to or recover omitted tokens. Then, we adopt a fast and effective edit operation scoring network to model the relation between two tokens. Benefiting from proposed query template and the well-designed edit operation scoring network, QUEEN achieves state-of-the-art performance on several public datasets.
    
[^73]: 直接效应在总结因果图中的可辨识性

    Identifiability of direct effects from summary causal graphs. (arXiv:2306.16958v1 [cs.AI])

    [http://arxiv.org/abs/2306.16958](http://arxiv.org/abs/2306.16958)

    该论文研究了在缺乏完整时间因果图的情况下，直接因果效应如何从总结因果图中进行可辨识，并提出了一个完整的可辨识性结果。

    

    动态结构因果模型（SCMs）是一个强大的框架，用于推理动态系统中的直接效应，即衡量一个变量的变化如何影响另一个变量，同时保持其他变量不变。动态结构因果模型中的因果关系可以用完全时间因果图来进行定性表示。假设线性和因果充分性，并给定完全时间因果图，直接因果效应总是可辨识的，并可以通过调整由所谓的单门准则给出的任何变量集合来从数据中估计。然而，在许多应用中，由于各种原因没有此类图形可用，但专家仍然可以访问完全时间因果图的一个抽象，该抽象表示了时间序列之间的因果关系，同时省略了时间信息。本文提出了一个完整的可辨识性结果，其中详细描述了所有直接效应在总结因果图中可辨识的情况。

    Dynamic structural causal models (SCMs) are a powerful framework for reasoning in dynamic systems about direct effects which measure how a change in one variable affects another variable while holding all other variables constant. The causal relations in a dynamic structural causal model can be qualitatively represented with a full-time causal graph. Assuming linearity and causal sufficiency and given the full-time causal graph, the direct causal effect is always identifiable and can be estimated from data by adjusting on any set of variables given by the so-called single-door criterion. However, in many application such a graph is not available for various reasons but nevertheless experts have access to an abstraction of the full-time causal graph which represents causal relations between time series while omitting temporal information. This paper presents a complete identifiability result which characterizes all cases for which the direct effect is graphically identifiable from summa
    
[^74]: 细调但零-shot 3D形状草图视图相似性和检索

    Fine-Tuned but Zero-Shot 3D Shape Sketch View Similarity and Retrieval. (arXiv:2306.08541v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.08541](http://arxiv.org/abs/2306.08541)

    这项研究关注个体3D实例的多模态2D投影，发现在零-shot环境中，草图越抽象，错误图像匹配的可能性越高。另外，细调一个形状类别的3D模型可以提高其他形状类别的性能。

    

    最近，像ViT（视觉变换器）和ResNet这样的编码器已经在大规模数据集上进行训练，并且被用作比较草图和图像的知觉度量，以及零-shot环境中的多域编码器。然而，关于这些编码器的细粒度量化工作尚有有限的努力。我们的工作通过关注个体3D实例的多模态2D投影来填补这一空白。这个任务对于检索和基于草图建模具有重要的影响。我们发现，在零-shot环境中，草图越抽象，错误图像匹配的可能性越高。即使在同一个草图领域中，以不同的风格绘制的同一物体的草图，例如由不同的个体绘制，也可能无法准确匹配。我们研究的一个关键发现是，在一类3D形状上进行细致的微调可以提高其他形状类别的性能，达到或超过监督方法的准确性。我们进行了比较和讨论。

    Recently, encoders like ViT (vision transformer) and ResNet have been trained on vast datasets and utilized as perceptual metrics for comparing sketches and images, as well as multi-domain encoders in a zero-shot setting. However, there has been limited effort to quantify the granularity of these encoders. Our work addresses this gap by focusing on multi-modal 2D projections of individual 3D instances. This task holds crucial implications for retrieval and sketch-based modeling. We show that in a zero-shot setting, the more abstract the sketch, the higher the likelihood of incorrect image matches. Even within the same sketch domain, sketches of the same object drawn in different styles, for example by distinct individuals, might not be accurately matched. One of the key findings of our research is that meticulous fine-tuning on one class of 3D shapes can lead to improved performance on other shape classes, reaching or surpassing the accuracy of supervised methods. We compare and discus
    
[^75]: 在因子图中自动进行模型比较

    Automating Model Comparison in Factor Graphs. (arXiv:2306.05965v1 [cs.LG])

    [http://arxiv.org/abs/2306.05965](http://arxiv.org/abs/2306.05965)

    本文基于自定义混合节点 Forney 样式的因子图消息传递，实现了高效自动化贝叶斯模型平均、选择和组合，并缩短了模型设计周期。

    

    在文献中，贝叶斯状态和参数估计已经被有效自动化，但对于模型比较尚未如此，因此仍需要容易出错和耗时的手动推导。因此，模型比较经常被忽视和忽略，尽管它很重要。本文通过在Forney样式的因子图上使用自定义混合节点上的消息传递来高效地自动化贝叶斯模型平均、选择和组合。进而可使用缩放因子同时执行参数和状态推断以及模型比较。这种方法缩短了模型设计周期，同时允许简单地扩展到分层和时间模型先验，以适应建模复杂的时变过程。

    Bayesian state and parameter estimation have been automated effectively in the literature, however, this has not yet been the case for model comparison, which therefore still requires error-prone and time-consuming manual derivations. As a result, model comparison is often overlooked and ignored, despite its importance. This paper efficiently automates Bayesian model averaging, selection, and combination by message passing on a Forney-style factor graph with a custom mixture node. Parameter and state inference, and model comparison can then be executed simultaneously using message passing with scale factors. This approach shortens the model design cycle and allows for the straightforward extension to hierarchical and temporal model priors to accommodate for modeling complicated time-varying processes.
    
[^76]: AI艺术策展：重新构想赫尔辛基市艺术双年展

    AI Art Curation: Re-imagining the city of Helsinki in occasion of its Biennial. (arXiv:2306.03753v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.03753](http://arxiv.org/abs/2306.03753)

    本研究通过AI策展和观众互动，利用机器学习模型重新构想了赫尔辛基市艺术双年展，使用视觉-文本模型将室内艺术品放置在公共空间中，生成合成的360艺术全景图，以创造出艺术品与城市空间的新视角。

    

    艺术策展实践的特点是以知识的方式展示艺术收藏品。机器过程的特点是它们能够处理和分析大量数据。本文设想了AI策展和观众互动，以探索当代机器学习模型对策展界的影响。该项目是为2023年赫尔辛基艺术双年展的场合而开发的，题为“可能出现新的方向”。我们使用赫尔辛基艺术博物馆（HAM）的藏品，通过机器感知的视角重新构想了赫尔辛基市。我们使用视觉-文本模型在公共空间中展示室内艺术品，根据相似性评分分配虚构的坐标。我们通过生成合成的360艺术全景图来改变每件艺术品在城市中的所处空间。我们通过估计每件艺术品位置的360全景图的深度值和机器生成的艺术品提示来指导生成过程。这个项目的结果就是...

    Art curatorial practice is characterized by the presentation of an art collection in a knowledgeable way. Machine processes are characterized by their capacity to manage and analyze large amounts of data. This paper envisages AI curation and audience interaction to explore the implications of contemporary machine learning models for the curatorial world. This project was developed for the occasion of the 2023 Helsinki Art Biennial, entitled New Directions May Emerge. We use the Helsinki Art Museum (HAM) collection to re-imagine the city of Helsinki through the lens of machine perception. We use visual-textual models to place indoor artworks in public spaces, assigning fictional coordinates based on similarity scores. We transform the space that each artwork inhabits in the city by generating synthetic 360 art panoramas. We guide the generation estimating depth values from 360 panoramas at each artwork location, and machine-generated prompts of the artworks. The result of this project i
    
[^77]: 向可解释的、语言无关的LLMs迈进：大规模语言符号逆向工程

    Towards Explainable and Language-Agnostic LLMs: Symbolic Reverse Engineering of Language at Scale. (arXiv:2306.00017v1 [cs.CL])

    [http://arxiv.org/abs/2306.00017](http://arxiv.org/abs/2306.00017)

    本文提出结合符号表示和自下而上的逆向工程的方法，解决大规模语言模型在真正语言理解上的局限性，实现可解释的、语言无关的LLMs。

    

    大型语言模型（LLMs）取得了一个里程碑，无可否认地改变了人工智能（AI）中许多信仰。然而，当涉及真正的语言理解时，这些LLM的许多限制仍然存在，这些限制是深度神经网络底层架构的副产品。此外，由于它们的亚符号性质，这些模型获得有关语言如何运作的任何知识都将被埋在数十亿个微特征（权重）中，其中没有一个单独的特征有意义，使得这些模型无法解释。为了解决这些限制，我们建议将符号表示的强度与我们认为是LLMs成功的关键结合起来，即在规模上成功地进行自下而上的语言逆向工程。因此，我们主张在符号设置下对语言进行自下而上的逆向工程。一些作者提出了这个项目的提示，我们将进行详细讨论。

    Large language models (LLMs) have achieved a milestone that undenia-bly changed many held beliefs in artificial intelligence (AI). However, there remains many limitations of these LLMs when it comes to true language understanding, limitations that are a byproduct of the under-lying architecture of deep neural networks. Moreover, and due to their subsymbolic nature, whatever knowledge these models acquire about how language works will always be buried in billions of microfeatures (weights), none of which is meaningful on its own, making such models hopelessly unexplainable. To address these limitations, we suggest com-bining the strength of symbolic representations with what we believe to be the key to the success of LLMs, namely a successful bottom-up re-verse engineering of language at scale. As such we argue for a bottom-up reverse engineering of language in a symbolic setting. Hints on what this project amounts to have been suggested by several authors, and we discuss in some detail
    
[^78]: PlaSma: 为 (反事实) 计划制定增强过程知识模型的小型语言模型

    PlaSma: Making Small Language Models Better Procedural Knowledge Models for (Counterfactual) Planning. (arXiv:2305.19472v1 [cs.CL])

    [http://arxiv.org/abs/2305.19472](http://arxiv.org/abs/2305.19472)

    PlaSma提出了一种使用小型语言模型进行过程知识和计划能力的新方法，

    

    过程规划是机器的一项重要而又复杂的任务，它将一个高级目标分解为一系列时间顺序的步骤。它需要整合常识知识以推理出常常是反事实的复杂情境，例如 "没有电话时安排医生的约会"。当前的方法使用大型语言模型 (LLM) 取得了令人鼓舞的结果，但受到昂贵的 API 调用和可复现性问题的限制。本文提出使用更小的语言模型来进行规划，我们介绍了 PlaSma，这是一种新的双重方法，使小型语言模型具有过程知识和 (反事实) 计划能力。更具体地说，我们开发了符号过程知识蒸馏来增强小型语言模型中的隐含知识，以及一种推理算法来促进更结构化和准确的推理。此外，我们还引入了一个新的任务，反事实规划。

    Procedural planning, which entails decomposing a high-level goal into a sequence of temporally ordered steps, is an important yet intricate task for machines. It involves integrating common-sense knowledge to reason about complex contextualized situations that are often counterfactual, e.g. "scheduling a doctor's appointment without a phone". While current approaches show encouraging results using large language models (LLMs), they are hindered by drawbacks such as costly API calls and reproducibility issues. In this paper, we advocate planning using smaller language models. We present PlaSma, a novel two-pronged approach to endow small language models with procedural knowledge and (counterfactual) planning capabilities. More concretely, we develop symbolic procedural knowledge distillation to enhance the implicit knowledge in small language models and an inference-time algorithm to facilitate more structured and accurate reasoning. In addition, we introduce a novel task, Counterfactua
    
[^79]: 在ChatGPT、大型语言模型和生成AI时代的科学：研究伦理的挑战及应对方法

    Science in the Era of ChatGPT, Large Language Models and Generative AI: Challenges for Research Ethics and How to Respond. (arXiv:2305.15299v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2305.15299](http://arxiv.org/abs/2305.15299)

    这篇论文回顾了生成AI对科学研究所带来的认识论挑战、伦理和诚信风险，并提出了十项建议，以在AI时代促进更负责任的研究进行。

    

    人工智能的大型语言模型（如ChatGPT）在科学研究中具有显著但有争议的应用。本文回顾了生成AI时代科学研究的认识论挑战、伦理和诚信风险，并旨在为高质量的研究伦理审查奠定新的及时基础。对AI语言模型作为研究工具和研究对象的角色进行了详细审查，并讨论了对科学家、参与者和评审人员的伦理影响。讨论了研究伦理审查的新兴实践，并给出了十项建议，为在AI时代更负责任的研究进行回应。

    Large language models of artificial intelligence (AI), such as ChatGPT, find remarkable but controversial applicability in science and research. This paper reviews epistemological challenges, ethical and integrity risks in science conduct in the advent of generative AI. This is with the aim to lay new timely foundations for a high-quality research ethics review. The role of AI language models as a research instrument and subject is scrutinized along with ethical implications for scientists, participants and reviewers. New emerging practices for research ethics review are discussed, concluding with ten recommendations that shape a response for a more responsible research conduct in the era of AI.
    
[^80]: 基于置信度的部分标签学习模型用于群体注释的命名实体识别

    A Confidence-based Partial Label Learning Model for Crowd-Annotated Named Entity Recognition. (arXiv:2305.12485v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.12485](http://arxiv.org/abs/2305.12485)

    本论文提出了一种基于置信度的部分标签学习方法（CPLL）用于群体注释的命名实体识别。该模型通过迭代更新真实后验和置信度，通过最小化经验风险学习一个基于标记和内容的置信度，实验结果表明该方法能够提高NER的性能。

    

    现有的命名实体识别（NER）模型主要基于大规模标记数据集，这些数据集通常是通过众包获得的。然而，由于标注空间的广泛性和任务的复杂性，很难通过多个标注者的多数表决获得统一且正确的标签。为了解决这个问题，我们旨在直接利用原始的多标注者标签。具体而言，我们提出了一种基于置信度的部分标签学习（CPLL）方法，用于集成注释者提供的先验置信度和模型学习的后验置信度，用于群体注释的NER。该模型通过最小化经验风险，通过期望最大化（EM）算法学习一个基于标记和内容的置信度。真实后验估计器和置信度估计器通过迭代更新真实后验和置信度。我们在真实和合成数据集上进行了大量实验，结果表明我们的模型可以提高命名实体识别的性能。

    Existing models for named entity recognition (NER) are mainly based on large-scale labeled datasets, which always obtain using crowdsourcing. However, it is hard to obtain a unified and correct label via majority voting from multiple annotators for NER due to the large labeling space and complexity of this task. To address this problem, we aim to utilize the original multi-annotator labels directly. Particularly, we propose a Confidence-based Partial Label Learning (CPLL) method to integrate the prior confidence (given by annotators) and posterior confidences (learned by models) for crowd-annotated NER. This model learns a token- and content-dependent confidence via an Expectation-Maximization (EM) algorithm by minimizing empirical risk. The true posterior estimator and confidence estimator perform iteratively to update the true posterior and confidence respectively. We conduct extensive experimental results on both real-world and synthetic datasets, which show that our model can impro
    
[^81]: SUG：单数据集统一泛化用于 3D 点云分类

    SUG: Single-dataset Unified Generalization for 3D Point Cloud Classification. (arXiv:2305.09160v1 [cs.CV])

    [http://arxiv.org/abs/2305.09160](http://arxiv.org/abs/2305.09160)

    本文提出了一种单数据集统一泛化（SUG）框架，通过多细粒度子域对齐和样本级域感知注意力策略，解决了三维点云领域泛化问题。

    

    虽然领域泛化（DG）问题在二维图像任务中增长迅速，但其在三维点云数据上的探索仍然不足，并且受到更复杂和不确定的跨域差异以及不均匀的跨类模态分布的挑战。与之前的二维 DG 工作不同，本文关注三维 DG 问题，并提出了一种 Single-dataset Unified Generalization（SUG）框架，该框架仅利用单个源数据集来缓解经过充分训练的源模型面临的未知域差异。具体来说，首先设计了一种多细粒度子域对齐（MSA）方法，通过在来自单个源数据集的分裂子域之间执行多细粒度特征对齐过程来约束学习表示为域不可知和有区别性。然后，提出了一种样本级域感知注意力（SDA）策略，该策略可以根据每个样本所属的不同子域选择性地增强易于适应的样本。

    Although Domain Generalization (DG) problem has been fast-growing in the 2D image tasks, its exploration on 3D point cloud data is still insufficient and challenged by more complex and uncertain cross-domain variances with uneven inter-class modality distribution. In this paper, different from previous 2D DG works, we focus on the 3D DG problem and propose a Single-dataset Unified Generalization (SUG) framework that only leverages a single source dataset to alleviate the unforeseen domain differences faced by a well-trained source model. Specifically, we first design a Multi-grained Sub-domain Alignment (MSA) method, which can constrain the learned representations to be domain-agnostic and discriminative, by performing a multi-grained feature alignment process between the splitted sub-domains from the single source dataset. Then, a Sample-level Domain-aware Attention (SDA) strategy is presented, which can selectively enhance easy-to-adapt samples from different sub-domains according to
    
[^82]: 差分卷积模糊时间序列预测

    Differential Convolutional Fuzzy Time Series Forecasting. (arXiv:2305.08890v1 [cs.LG])

    [http://arxiv.org/abs/2305.08890](http://arxiv.org/abs/2305.08890)

    本文提出了一种新的预测模型DFCNN，利用卷积神经网络实现具有可学习能力的FTSF，并能够处理非平稳时间序列。

    

    模糊时间序列预测（FTSF）是一种具有广泛应用的典型预测方法。传统的FTSF被认为是一种专家系统，导致失去了识别未定义特征的能力，这是FTSF预测不准确的主要原因。为了解决这个问题，提出了差分模糊卷积神经网络（DFCNN）模型，利用卷积神经网络实现具有可学习能力的FTSF。DFCNN能够识别潜在信息并改善预测精度。由于神经网络的可学习能力，FTSF建立的模糊规则的长度可以任意扩展，这是专家系统所无法处理的。同时，由于非平稳时间序列的趋势，FTSF通常无法实现令人满意的性能。非平稳时间序列的趋势会导致FTSF建立的模糊集失效，并导致预测失败。DFCNN利用卷积神经网络的学习能力，可以处理非平稳时间序列。

    Fuzzy time series forecasting (FTSF) is a typical forecasting method with wide application. Traditional FTSF is regarded as an expert system which leads to lose the ability to recognize undefined feature. The mentioned is main reason of poor forecasting with FTSF. To solve the problem, the proposed model Differential Fuzzy Convolutional Neural Network (DFCNN) utilizes convolution neural network to re-implement FTSF with learnable ability. DFCNN is capable of recognizing the potential information and improve the forecasting accuracy. Thanks to learnable ability of neural network, length of fuzzy rules established in FTSF is expended to arbitrary length which expert is not able to be handle by expert system. At the same time, FTSF usually cannot achieve satisfactory performance of non-stationary time series due to trend of non-stationary time series. The trend of non-stationary time series causes the fuzzy set established by FTSF to invalid and cause the forecasting to fail. DFCNN utiliz
    
[^83]: 引入致敬神话人工智能竞赛

    Introducing Tales of Tribute AI Competition. (arXiv:2305.08234v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.08234](http://arxiv.org/abs/2305.08234)

    这项论文介绍了一项新的人工智能挑战——致敬神话人工智能竞赛(TOTAIC)，该竞赛基于《上古卷轴在线》中的一款卡牌游戏。除了应对通常与CCG相关的挑战外，该挑战还需要长期规划和适应性。竞赛采用多种方法解决游戏，如对抗搜索、单人计划和神经网络算法。第一届TOTAIC将在2023年的IEEE游戏会议上举行。

    

    本文介绍了一项新的人工智能挑战，即致敬神话人工智能竞赛(TOTAIC)，该竞赛基于《上古卷轴在线》海之岛章节发布的一款双人卡牌建设类游戏。目前还没有其他涵盖收集卡牌游戏(CCG)类型的人工智能竞赛，也从未有过针对建设卡牌游戏的竞赛。因此，成功的方法除了要克服通常与CCG相关的障碍，如随机性、隐藏信息和大的分支因素外，还需要长期规划和适应性。该游戏可以采用多种方法进行解决，包括经典的对抗搜索、单人计划和基于神经网络的算法。本文介绍了竞赛框架，描述了游戏规则，并呈现了示例AI代理之间的锦标赛结果。TOTAIC的第一届将在2023年IEEE游戏会议上举行。

    This paper presents a new AI challenge, the Tales of Tribute AI Competition (TOTAIC), based on a two-player deck-building card game released with the High Isle chapter of The Elder Scrolls Online. Currently, there is no other AI competition covering Collectible Card Games (CCG) genre, and there has never been one that targets a deck-building game. Thus, apart from usual CCG-related obstacles to overcome, like randomness, hidden information, and large branching factor, the successful approach additionally requires long-term planning and versatility. The game can be tackled with multiple approaches, including classic adversarial search, single-player planning, and Neural Networks-based algorithms. This paper introduces the competition framework, describes the rules of the game, and presents the results of a tournament between sample AI agents. The first edition of TOTAIC is hosted at the IEEE Conference on Games 2023.
    
[^84]: 联邦学习与O-RAN的协同：面向多个分布式机器学习服务的弹性虚拟化架构

    Synergies Between Federated Learning and O-RAN: Towards an Elastic Virtualized Architecture for Multiple Distributed Machine Learning Services. (arXiv:2305.02109v1 [cs.NI])

    [http://arxiv.org/abs/2305.02109](http://arxiv.org/abs/2305.02109)

    本文研究了联邦学习在现代无线网络下的挑战，提出了一种方法称为动态多服务联邦学习（DMS-FL）来解决这个问题。同时，还提出了一种名为弹性虚拟化联邦学习（EV-FL）的分布式机器学习架构，来支持DMS-FL中的设计要求。

    

    联邦学习是最流行的分布式机器学习技术，但是在现代无线网络中实现联邦学习面临着许多挑战，主要包括网络条件的动态性、系统中多个联邦学习服务/任务的并存以及联邦学习服务与其他网络服务的并行执行等。针对这些挑战，本文提出了一种名为动态多服务联邦学习（DMS-FL）的联邦学习泛型架构，并通过提出一种新的分布式机器学习架构——弹性虚拟化联邦学习（EV-FL）来解决DMS-FL中的三个未探索的设计问题。

    Federated learning (FL) is the most popular distributed machine learning technique. However, implementation of FL over modern wireless networks faces key challenges caused by (i) dynamics of the network conditions, (ii) coexistence of multiple FL services/tasks in the system, and (iii) concurrent execution of FL services with other network services, which are not jointly considered in prior works. Motivated by these challenges, we introduce a generic FL paradigm over next-generation (NextG) networks, called dynamic multi-service FL (DMS-FL). We identify three unexplored design considerations in DMS-FL: (i) FL service operator accumulation, (ii) wireless resource fragmentation, and (iii) signal strength fluctuations. We take the first steps towards addressing these design considerations through proposing a novel distributed ML architecture called elastic virtualized FL (EV-FL). EV-FL unleashes the full potential of Open RAN (O-RAN) systems and introduces an elastic resource provisioning
    
[^85]: CAR-DESPOT: 针对混杂环境下的机器人的因果关系在线POMDP规划

    CAR-DESPOT: Causally-Informed Online POMDP Planning for Robots in Confounded Environments. (arXiv:2304.06848v1 [cs.RO])

    [http://arxiv.org/abs/2304.06848](http://arxiv.org/abs/2304.06848)

    本文提出了一种新的因果关系在线POMDP规划方法CAR-DESPOT，使用因果建模和推理来消除未测量混淆变量引起的错误，并在混杂环境中表现优异。

    

    在现实环境中工作的机器人必须考虑随机行为的可能结果，并根据真实的世界状态的部分观察进行决策。因果混淆的问题是进行准确和强健的行为预测的主要挑战。部分可观察的马尔可夫决策过程(POMDP)是一种广泛使用的框架，用于模拟这些随机和部分可观测的决策问题。然而，由于缺乏明确的因果语义，POMDP规划方法容易受到混淆偏差的影响，在未观察到混杂变量的情况下，可能会产生表现不佳的策略。本文提出了一种新的因果关系在线POMDP规划方法，使用因果建模和推理来消除未测量混淆变量引起的错误。我们进一步提出了一种从观测数据中学习因果模型的方法，以在我们的方法中使用。实验结果表明，我们的方法CAR-DESPOT在混杂环境中比现有的最先进的POMDP规划程序表现显著更好。

    Robots operating in real-world environments must reason about possible outcomes of stochastic actions and make decisions based on partial observations of the true world state. A major challenge for making accurate and robust action predictions is the problem of confounding, which if left untreated can lead to prediction errors. The partially observable Markov decision process (POMDP) is a widely-used framework to model these stochastic and partially-observable decision-making problems. However, due to a lack of explicit causal semantics, POMDP planning methods are prone to confounding bias and thus in the presence of unobserved confounders may produce underperforming policies. This paper presents a novel causally-informed extension of "anytime regularized determinized sparse partially observable tree" (AR-DESPOT), a modern anytime online POMDP planner, using causal modelling and inference to eliminate errors caused by unmeasured confounder variables. We further propose a method to lear
    
[^86]: 使用不同降维和分类技术的癫痫发作检测的经验分析

    Empirical analysis of Different Dimensionality Reduction and classification Techniques for Epileptic Seizure detection. (arXiv:2302.12012v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.12012](http://arxiv.org/abs/2302.12012)

    本研究对使用不同降维和分类技术进行癫痫发作检测进行了实证分析，通过离散小波变换和机器学习分类器，结合主成分分析、独立成分分析和线性判别分析等降维算法，选择特征来提高检测准确性。

    

    脑电图（EEG）是一种非侵入性检查，记录大脑的电活动。该检查用于帮助诊断各种脑问题。通过离散小波变换（DWT）和机器学习分类器，可以进行癫痫检测。在癫痫发作检测中，主要使用机器学习分类器和统计特征。EEG信号中的隐藏信息对于检测影响大脑的疾病很有用。有时，在时间和频率域内识别EEG的最小变化是非常困难的。DWT可以在不同频带进行信号良好的分解和特征提取。我们使用三个降维算法：主成分分析（PCA）、独立成分分析（ICA）和线性判别分析（LDA）。最后，通过融合规则选择特征。

    An Electroencephalogram (EEG) is a non-invasive exam that records the electrical activity of the brain. This exam is used to help diagnose conditions such as different brain problems. EEG signals are taken for the purpose of epilepsy detection and with Discrete Wavelet Transform (DWT) and machine learning classifier, they perform epilepsy detection. In Epilepsy seizure detection, mainly machine learning classifiers and statistical features are used. The hidden information in the EEG signal is useful for detecting diseases affecting the brain. Sometimes it is very difficult to identify the minimum changes in the EEG in the time and frequency domains purpose. The DWT can give a good decomposition of the signals in different frequency bands and feature extraction. We use the tri-dimensionality reduction algorithm.; Principal Component Analysis (PCA), Independent Component Analysis (ICA), and Linear Discriminant Analysis (LDA). Finally, features are selected by using a fusion rule and at t
    
[^87]: 近地表风的算法幻觉：使用生成对抗网络进行统计降尺度的研究

    Algorithmic Hallucinations of Near-Surface Winds: Statistical Downscaling with Generative Adversarial Networks to Convection-Permitting Scales. (arXiv:2302.08720v2 [physics.ao-ph] UPDATED)

    [http://arxiv.org/abs/2302.08720](http://arxiv.org/abs/2302.08720)

    本论文将新兴的图像超分辨率技术应用于统计降尺度任务，具体探索了基于生成对抗网络的算法在模拟北美地区地表风中的应用。通过使用非理想化的低分辨率和高分辨率输入数据，该方法克服了共享尺度不匹配的问题，并通过评估空间功率谱等指标来评估模型的技能。

    

    本论文探讨了将图像超分辨率（SR）中新兴的机器学习方法应用于统计降尺度任务。我们特别关注卷积神经网络的生成对抗网络（GANs）。我们的GANs是通过对低分辨率（LR）输入进行条件训练来生成模拟北美地区 Weather Research and Forecasting（WRF）模型的高分辨率（HR）地表风。与传统的SR模型不同，LR输入在WRF模拟中使用了非理想化的LR和HR配对，导致由于内部变异引起的共享尺度不匹配。我们的研究基于当前基于SR的统计降尺度，并尝试了计算机视觉领域的新颖频率分离（FS）方法。为了评估SR模型的技能，我们精选评估指标，并关注基于空间功率谱的性能度量。我们的分析揭示了GAN配置如何影响模型的性能。

    This paper explores the application of emerging machine learning methods from image super-resolution (SR) to the task of statistical downscaling. We specifically focus on convolutional neural network-based Generative Adversarial Networks (GANs). Our GANs are conditioned on low-resolution (LR) inputs to generate high-resolution (HR) surface winds emulating Weather Research and Forecasting (WRF) model simulations over North America. Unlike traditional SR models, where LR inputs are idealized coarsened versions of the HR images, WRF emulation involves using non-idealized LR and HR pairs resulting in shared-scale mismatches due to internal variability. Our study builds upon current SR-based statistical downscaling by experimenting with a novel frequency-separation (FS) approach from the computer vision field. To assess the skill of SR models, we carefully select evaluation metrics, and focus on performance measures based on spatial power spectra. Our analyses reveal how GAN configurations 
    
[^88]: 因果提升与链路预测

    Causal Lifting and Link Prediction. (arXiv:2302.01198v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.01198](http://arxiv.org/abs/2302.01198)

    本文开发了第一个能够处理链路预测中路径依赖的因果模型，并介绍了因果提升的概念，通过有限的干预数据识别因果链路预测查询。

    

    现有的链路预测因果模型假设存在一组固有的节点因子，即在节点出生时就定义的固有特征，它们控制着图中链路的因果演化。然而，在某些因果任务中，链路形成是路径依赖的：链路干预的结果取决于现有的链路。不幸的是，这些现有的因果方法并不适用于路径依赖的链路形成，因为链路之间的级联功能依赖（由路径依赖性产生）要么无法识别，要么需要大量不切实际的控制变量。为了克服这个问题，我们开发了第一个能够处理链路预测中路径依赖的因果模型。在这项工作中，我们引入了因果提升的概念，这是一种独立于图的因果模型的不变性，可以利用有限的干预数据来识别因果链路预测查询。此外，我们展示了结构对两个节点之间嵌入的低维表示的方式。

    Existing causal models for link prediction assume an underlying set of inherent node factors -- an innate characteristic defined at the node's birth -- that governs the causal evolution of links in the graph. In some causal tasks, however, link formation is path-dependent: The outcome of link interventions depends on existing links. Unfortunately, these existing causal methods are not designed for path-dependent link formation, as the cascading functional dependencies between links (arising from path dependence) are either unidentifiable or require an impractical number of control variables. To overcome this, we develop the first causal model capable of dealing with path dependencies in link prediction. In this work we introduce the concept of causal lifting, an invariance in causal models of independent interest that, on graphs, allows the identification of causal link prediction queries using limited interventional data. Further, we show how structural pairwise embeddings exhibit low
    
[^89]: ThoughtSource:一个用于大型语言模型推理数据的中央枢纽。

    ThoughtSource: A central hub for large language model reasoning data. (arXiv:2301.11596v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.11596](http://arxiv.org/abs/2301.11596)

    ThoughtSource是一个用于连续思考推理的元数据集和软件库，旨在通过促进对连续思考的定性理解、实证评估和提供训练数据，改进未来的人工智能系统。

    

    最近，像GPT-4这样的大型语言模型在多个任务上展示了令人印象深刻的结果。然而，这些语言模型在复杂推理上仍存在限制，它们的推理过程不透明，容易产生“幻觉”事实，并且存在其潜在偏见的担忧。最近提出了一种称为连续思考提示的技术，让模型以自然语言形式表达推理步骤，以解决这些问题。在这里，我们介绍了ThoughtSource，一个用于连续思考推理的元数据集和软件库。ThoughtSource的目标是通过促进对连续思考的定性理解、实证评估和提供训练数据来改进未来的人工智能系统。ThoughtSource的首次发布集成了六个科学/医学、三个通用领域和五个数学题答案数据集。

    Large language models (LLMs) such as GPT-4 have recently demonstrated impressive results across a wide range of tasks. LLMs are still limited, however, in that they frequently fail at complex reasoning, their reasoning processes are opaque, they are prone to 'hallucinate' facts, and there are concerns about their underlying biases. Letting models verbalize reasoning steps as natural language, a technique known as chain-of-thought prompting, has recently been proposed as a way to address some of these issues. Here we present ThoughtSource, a meta-dataset and software library for chain-of-thought (CoT) reasoning. The goal of ThoughtSource is to improve future artificial intelligence systems by facilitating qualitative understanding of CoTs, enabling empirical evaluations, and providing training data. This first release of ThoughtSource integrates six scientific/medical, three general-domain and five math word question answering datasets.
    
[^90]: 多模块图神经网络的灵活表征促进更好的泛化能力

    Towards Better Generalization with Flexible Representation of Multi-Module Graph Neural Networks. (arXiv:2209.06589v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.06589](http://arxiv.org/abs/2209.06589)

    本研究探讨了图神经网络在推广到更大的图和从未见过的数据方面的局限，并提出了多模块GNN框架，通过推广单个规范非线性变换来适应新图。结果表明，多模块GNN在合成和实际数据集上均显著提高了GNN的泛化能力，并在几项具有挑战性的任务上实现了最先进的性能。

    

    图神经网络（GNN）已成为处理图结构数据的学习与推断的强大模型，但对于扩展到更大的图以及推广到从未见过的数据的基本限制的了解还不足。本文使用随机图生成器系统地研究了图的大小和结构属性如何影响GNN的预测性能，并提出多模块GNN框架，通过推广单个规范非线性变换来适应新图。结果表明，多模块GNN在合成和实际数据集上均显著提高了GNN的泛化能力，并在几项具有挑战性的任务上实现了最先进的性能。

    Graph neural networks (GNNs) have become compelling models designed to perform learning and inference on graph-structured data. However, little work has been done to understand the fundamental limitations of GNNs for scaling to larger graphs and generalizing to out-of-distribution (OOD) inputs. In this paper, we use a random graph generator to systematically investigate how the graph size and structural properties affect the predictive performance of GNNs. We present specific evidence that the average node degree is a key feature in determining whether GNNs can generalize to unseen graphs, and that the use of multiple node update functions can improve the generalization performance of GNNs when dealing with graphs of multimodal degree distributions. Accordingly, we propose a multi-module GNN framework that allows the network to adapt flexibly to new graphs by generalizing a single canonical nonlinear transformation over aggregated inputs. Our results show that the multi-module GNNs imp
    
[^91]: 使用隐马尔可夫模型学习强化学习任务自动机

    Learning Task Automata for Reinforcement Learning using Hidden Markov Models. (arXiv:2208.11838v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.11838](http://arxiv.org/abs/2208.11838)

    本文提出了一种学习非马尔可夫任务规范的新方法，通过从代理经验中学习，将其表示为有限状态的任务自动机。利用隐马尔可夫模型和新的提炼方法，使得代理能够解决稀疏和非马尔可夫奖励的强化学习任务。

    

    在环境具有稀疏和非马尔可夫奖励的情况下，使用标量奖励信号训练强化学习代理通常是不可行的。此外，在训练之前手工创建这些奖励函数往往容易出错，特别是当环境的动力学只有部分已知时。本文提出了一种新颖的流程，通过对未知环境中代理经验的 episodes 进行学习，从而学习非马尔可夫任务规范的简洁有限状态“任务自动机”。我们利用了两个关键算法的见解。首先，我们通过将产品 MDP 视为部分可观测 MDP 并使用众所周知的 Baum-Welch 算法来学习隐马尔可夫模型，从而学习到了规范自动机和环境的 MDP（初始都未知）所组成的模型。其次，我们提出了一种新颖的方法，从学到的产品 MDP 中提炼任务自动机（假设为确定性有限自动机）。我们学到的任务自动机使得代理可以解决非马尔可夫任务规范。

    Training reinforcement learning (RL) agents using scalar reward signals is often infeasible when an environment has sparse and non-Markovian rewards. Moreover, handcrafting these reward functions before training is prone to misspecification, especially when the environment's dynamics are only partially known. This paper proposes a novel pipeline for learning non-Markovian task specifications as succinct finite-state `task automata' from episodes of agent experience within unknown environments. We leverage two key algorithmic insights. First, we learn a product MDP, a model composed of the specification's automaton and the environment's MDP (both initially unknown), by treating the product MDP as a partially observable MDP and using the well-known Baum-Welch algorithm for learning hidden Markov models. Second, we propose a novel method for distilling the task automaton (assumed to be a deterministic finite automaton) from the learnt product MDP. Our learnt task automaton enables the dec
    
[^92]: 论连词查询的非高效PAC可学习性

    On the non-efficient PAC learnability of conjunctive queries. (arXiv:2208.10255v2 [cs.DB] UPDATED)

    [http://arxiv.org/abs/2208.10255](http://arxiv.org/abs/2208.10255)

    这篇论文阐述了连词查询在PAC模型中的非高效可学习性，针对不同变种的连词查询提出了负面可学习性结果，并展示了通过成员查询可以高效学习连词查询和UCQs。

    

    这篇论文有三个目的：(i)我们提供了一个自包含的阐述，证明了连词查询在可能-近似正确(PAC)模型中没有高效可学习性，清楚地注意到这个概念类在很多计算学习理论文献中暗含的多项式规模适应性缺失；(ii)我们建立了一个强大的负面PAC可学习性结果，适用于许多限制类别的连词查询(CQs)，包括广义的“无环性”；(iii)我们展示了连词查询和UCQs通过成员查询是可以高效PAC可学习的。

    This note serves three purposes: (i) we provide a self-contained exposition of the fact that conjunctive queries are not efficiently learnable in the Probably-Approximately-Correct (PAC) model, paying clear attention to the complicating fact that this concept class lacks the polynomial-size fitting property, a property that is tacitly assumed in much of the computational learning theory literature; (ii) we establish a strong negative PAC learnability result that applies to many restricted classes of conjunctive queries (CQs), including acyclic CQs for a wide range of notions of "acyclicity"; (iii) we show that CQs (and UCQs) are efficiently PAC learnable with membership queries.
    
[^93]: 基于排列的进化算法的运行时分析

    Runtime Analysis for Permutation-based Evolutionary Algorithms. (arXiv:2207.04045v3 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2207.04045](http://arxiv.org/abs/2207.04045)

    本文对基于排列的进化算法进行了运行时分析，并提出了一种通用方法将经典的伪布尔基准转化为基于排列集合定义的基准。研究发现，与位串不同，排列变异的困难程度不仅取决于汉明距离，还与排列的精确循环结构有关。

    

    尽管在过去25年针对伪布尔优化问题的进化算法（EAs）的理论分析取得了重大进展，但在如何解决基于排列的问题的理论结果方面只存在零星的结果。为了克服基于排列的基准问题的不足，我们提出了一种将经典的伪布尔基准转化为基于排列集合定义的基准的通用方法。然后，我们对Scharnow，Tinnefeld和Wegener（2004）提出的基于排列的（1+1）EA在LeadingOnes和Jump基准的类似物上进行了严格的运行时分析。后者表明，与位串不同，不仅汉明距离决定了将一个排列$\sigma$变异为另一个排列$\tau$的困难程度，还有$\sigma\tau^{-1}$的精确循环结构。因此，我们还考虑了更对称的混淆变异算子。我们观察到，这不仅导致了更简单的证明，还导致了更好的效果。

    While the theoretical analysis of evolutionary algorithms (EAs) has made significant progress for pseudo-Boolean optimization problems in the last 25 years, only sporadic theoretical results exist on how EAs solve permutation-based problems.  To overcome the lack of permutation-based benchmark problems, we propose a general way to transfer the classic pseudo-Boolean benchmarks into benchmarks defined on sets of permutations. We then conduct a rigorous runtime analysis of the permutation-based $(1+1)$ EA proposed by Scharnow, Tinnefeld, and Wegener (2004) on the analogues of the LeadingOnes and Jump benchmarks. The latter shows that, different from bit-strings, it is not only the Hamming distance that determines how difficult it is to mutate a permutation $\sigma$ into another one $\tau$, but also the precise cycle structure of $\sigma \tau^{-1}$. For this reason, we also regard the more symmetric scramble mutation operator. We observe that it not only leads to simpler proofs, but also 
    
[^94]: 视觉预训练用于导航：从噪声中我们能学到什么？

    Visual Pre-training for Navigation: What Can We Learn from Noise?. (arXiv:2207.00052v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2207.00052](http://arxiv.org/abs/2207.00052)

    本论文提出了一种使用随机裁剪预测进行自监督训练的视觉预训练方法，可以学习到对导航任务有用的表示，并通过自举学习有效地学习导航策略，减少对交互数据的需求。

    

    在视觉导航中，一种强大的范式是从观察中直接预测行为。训练这样一个端到端的系统可以自动产生对下游任务有用的表示。然而，缺乏归纳偏差使得该系统数据效率低下。我们假设通过预测与目标对应的当前视图裁剪的位置和大小，可以学习到导航策略所需的当前视图和目标视图的充分表示。我们进一步展示，在自监督的方式下，仅使用合成噪声图像进行随机裁剪预测的训练可以很好地迁移到自然家庭图像。然后，可以利用学到的表示有效地自举学习导航策略，减少交互数据的需求。

    One powerful paradigm in visual navigation is to predict actions from observations directly. Training such an end-to-end system allows representations useful for downstream tasks to emerge automatically. However, the lack of inductive bias makes this system data inefficient. We hypothesize a sufficient representation of the current view and the goal view for a navigation policy can be learned by predicting the location and size of a crop of the current view that corresponds to the goal. We further show that training such random crop prediction in a self-supervised fashion purely on synthetic noise images transfers well to natural home images. The learned representation can then be bootstrapped to learn a navigation policy efficiently with little interaction data. The code is available at https://yanweiw.github.io/noise2ptz
    
[^95]: 从随机已知日志中恢复轨迹

    Trace Recovery from Stochastically Known Logs. (arXiv:2206.12672v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.12672](http://arxiv.org/abs/2206.12672)

    本文提出了一种从随机已知日志中恢复轨迹的算法，在两个公开数据集上平均恢复准确度达到90-97%。这一方法通过计算流程模型和随机已知轨迹的合规性，并恢复在该随机轨迹中的最佳对齐作为真实轨迹。对比其他轨迹恢复选项，使用了产品多图来分析成本模型对恢复准确性的影响。这一算法对于预测模型开发、错误排查和系统性能改进具有重要意义。

    

    在这项工作中，我们提出了一种用于从随机已知日志中恢复轨迹的算法。随着传感器数量的增加和生成不确定数据的预测模型的增加，这种设置越来越常见。所提出的方法计算流程模型与随机已知轨迹之间的合规性，并在这个随机轨迹中恢复最佳对齐作为真实轨迹。论文对不同成本模型对轨迹恢复准确性的影响进行了分析，并利用产品多图来比较替代轨迹恢复选项。通过使用两个公开可用的数据集进行评估，我们的方法的平均准确性令人印象深刻，平均恢复准确度达到90-97%，显著改善了常见的启发式算法，该算法选择每个不确定活动的最可能值。我们相信，所提出的算法在从随机已知日志中恢复正确轨迹方面的有效性可能是开发预测模型、错误排查和改进系统性能的有力帮助。

    In this work we propose an algorithm for trace recovery from stochastically known logs, a setting that is becoming more common with the increasing number of sensors and predictive models that generate uncertain data. The suggested approach calculates the conformance between a process model and a stochastically known trace and recovers the best alignment within this stochastic trace as the true trace. The paper offers an analysis of the impact of various cost models on trace recovery accuracy and makes use of a product multi-graph to compare alternative trace recovery options. The average accuracy of our approach, evaluated using two publicly available datasets, is impressive, with an average recovery accuracy score of 90-97%, significantly improving a common heuristic that chooses the most likely value for each uncertain activity. We believe that the effectiveness of the proposed algorithm in recovering correct traces from stochastically known logs may be a powerful aid for developing 
    
[^96]: 将知识从记忆中解耦：检索增强的提示学习

    Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning. (arXiv:2205.14704v4 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2205.14704](http://arxiv.org/abs/2205.14704)

    本论文提出了一种检索增强的提示学习方法，通过将知识从记忆中解耦，帮助模型在泛化和记忆之间取得平衡。

    

    提示学习方法在自然语言处理领域取得了显著的突破，提高了少样本学习的性能，但仍然遵循参数化学习范式；在学习过程中，遗忘和机械记忆问题可能导致不稳定的泛化问题。为了缓解这些限制，我们开发了RetroPrompt，旨在从记忆中将知识解耦，帮助模型在泛化和记忆之间取得平衡。与传统的提示学习方法相比，RetroPrompt从训练实例构建了一个开放式知识库，并在输入、训练和推断过程中实施检索机制，使模型具备了从训练语料库中检索相关上下文用于增强的能力。大量实验证明了RetroPrompt的效果。

    Prompt learning approaches have made waves in natural language processing by inducing better few-shot performance while they still follow a parametric-based learning paradigm; the oblivion and rote memorization problems in learning may encounter unstable generalization issues. Specifically, vanilla prompt learning may struggle to utilize atypical instances by rote during fully-supervised training or overfit shallow patterns with low-shot data. To alleviate such limitations, we develop RetroPrompt with the motivation of decoupling knowledge from memorization to help the model strike a balance between generalization and memorization. In contrast with vanilla prompt learning, RetroPrompt constructs an open-book knowledge-store from training instances and implements a retrieval mechanism during the process of input, training and inference, thus equipping the model with the ability to retrieve related contexts from the training corpus as cues for enhancement. Extensive experiments demonstra
    
[^97]: 基于图的推荐系统在社区检测中的增强

    Graph-Based Recommendation System Enhanced with Community Detection. (arXiv:2201.03622v3 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2201.03622](http://arxiv.org/abs/2201.03622)

    本文提出了一个基于图的推荐系统，利用数学和统计方法确定标签的相似性，包括词汇相似性和共现解决方案，并考虑了标签分配的时间，以提高推荐的准确性。

    

    许多研究者已经利用标签信息来改善推荐系统中推荐技术的性能。通过研究用户的标签，可以了解他们的兴趣，从而提高推荐的准确性。然而，由于用户自定义标签的任意性和缺乏限制，确定其确切含义和标签之间的相似性存在问题。本文利用数学和统计方法确定标签的词汇相似性和共现解决方案，以分配语义相似性。另外，考虑到用户兴趣随时间变化，本文还在共现标签中考虑了标签分配的时间以确定标签的相似性。然后，基于标签的相似性创建图形模型来建模用户的兴趣。

    Many researchers have used tag information to improve the performance of recommendation techniques in recommender systems. Examining the tags of users will help to get their interests and leads to more accuracy in the recommendations. Since user-defined tags are chosen freely and without any restrictions, problems arise in determining their exact meaning and the similarity of tags. However, using thesaurus and ontologies to find the meaning of tags is not very efficient due to their free definition by users and the use of different languages in many data sets. Therefore, this article uses mathematical and statistical methods to determine lexical similarity and co-occurrence tags solution to assign semantic similarity. On the other hand, due to the change of users' interests over time this article has considered the time of tag assignments in co-occurrence tags for determining similarity of tags. Then the graph is created based on similarity of tags. For modeling the interests of the us
    
[^98]: 机器学习中的拒绝选项：一项调查

    Machine Learning with a Reject Option: A survey. (arXiv:2107.11277v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2107.11277](http://arxiv.org/abs/2107.11277)

    这项调查综述了机器学习中的拒绝选项。通过机器学习模型避免在可能犯错误时做出预测，可以在决策支持应用中避免严重后果。调查介绍了拒绝选项的条件、评估策略以及相关应用领域，并探讨了它与其他机器学习方法的关系。

    

    机器学习模型总是做出预测，即使可能是不准确的。在许多决策支持应用中，应避免这种行为，因为错误可能带来严重后果。尽管在1970年已经研究过，但近年来机器学习中的拒绝选项引起了人们的关注。这个机器学习子领域使得机器学习模型能够在可能犯错误时避免做出预测。本调查旨在提供机器学习中拒绝选项的概述。我们介绍了导致两种拒绝情况（模糊和新奇拒绝）的条件，并对其进行了仔细的形式化。此外，我们还回顾和分类了评估模型预测和拒绝质量的策略。此外，我们定义了现有的带有拒绝选项的模型架构，并描述了学习这些模型的标准技术。最后，我们提供了相关应用领域的示例，并展示了机器学习中的拒绝选项与其他机器学习方法之间的关系。

    Machine learning models always make a prediction, even when it is likely to be inaccurate. This behavior should be avoided in many decision support applications, where mistakes can have severe consequences. Albeit already studied in 1970, machine learning with rejection recently gained interest. This machine learning subfield enables machine learning models to abstain from making a prediction when likely to make a mistake.  This survey aims to provide an overview on machine learning with rejection. We introduce the conditions leading to two types of rejection, ambiguity and novelty rejection, which we carefully formalize. Moreover, we review and categorize strategies to evaluate a model's predictive and rejective quality. Additionally, we define the existing architectures for models with rejection and describe the standard techniques for learning such models. Finally, we provide examples of relevant application domains and show how machine learning with rejection relates to other machi
    
[^99]: 约束资源下神经模块专业化的动力学研究

    Dynamics of specialization in neural modules under resource constraints. (arXiv:2106.02626v2 [q-bio.NC] UPDATED)

    [http://arxiv.org/abs/2106.02626](http://arxiv.org/abs/2106.02626)

    本研究使用人工神经网络模拟实验，发现结构模块化并不一定能够确保功能专业化，在特定环境和资源限制下，才能够出现专业化现象。

    

    长期以来，人们一直认为大脑在结构和功能上高度模块化，但最近的证据使一些人对两种模块化的程度产生了怀疑。我们使用人工神经网络来测试结构模块化是否足以保证功能专业化，并发现一般情况下，并不一定成立，除非在极端水平上。然后，我们系统地测试了环境和网络的哪些特征会导致专业化的出现。我们使用了一个简单的玩具环境、任务和网络，以精确控制条件，并表明在这个设置中，几个不同的专业化度量指标给出了类似的结果。我们进一步发现，（1）专业化只能在环境中那些可以明确分离的特征存在的情况下出现，（2）专业化更容易在网络资源受到强烈限制的情况下出现，（3）这些发现在 qualitatively 上相似。

    It has long been believed that the brain is highly modular both in terms of structure and function, although recent evidence has led some to question the extent of both types of modularity. We used artificial neural networks to test the hypothesis that structural modularity is sufficient to guarantee functional specialization, and find that in general, this doesn't necessarily hold except at extreme levels. We then systematically tested which features of the environment and network do lead to the emergence of specialization. We used a simple toy environment, task and network, allowing us precise control, and show that in this setup, several distinct measures of specialization give qualitatively similar results. We further find that (1) specialization can only emerge in environments where features of that environment are meaningfully separable, (2) specialization preferentially emerges when the network is strongly resource-constrained, and (3) these findings are qualitatively similar ac
    
[^100]: DanceFormer: 基于音乐的参数化运动变换器生成的3D舞蹈生成

    DanceFormer: Music Conditioned 3D Dance Generation with Parametric Motion Transformer. (arXiv:2103.10206v5 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2103.10206](http://arxiv.org/abs/2103.10206)

    本文提出了一种名为DanceFormer的方法，通过两个级联的动力学增强的变换器引导网络来生成基于音乐的3D舞蹈。方法首先生成关键姿势，然后预测参数化运动曲线，使得舞蹈与音乐节奏对齐，并且提出了一个准确标记的大规模音乐条件下的3D舞蹈数据集PhantomDance。

    

    从音乐中生成3D舞蹈是一项新兴的研究任务，对视觉和图形领域有很多应用。以往的工作将这个任务视为序列生成，然而，要渲染一段与音乐对齐的、具有高动力学复杂性和连贯运动的长期序列是具有挑战性的。本文通过一个两阶段的过程进行重构，即先生成关键姿势，然后预测参数化运动曲线，其中关键姿势更容易与音乐节拍同步，参数化曲线可以有效地回归以渲染平滑的节奏对齐运动。我们将提出的方法命名为DanceFormer，其中包括两个级联的增强动力学变换器引导网络（称为DanTrans），分别解决每个阶段的问题。此外，我们提出了一个大规模的基于音乐的3D舞蹈数据集PhantomDance，该数据集由经验丰富的动画师准确标记，而不是重建或动作捕捉。

    Generating 3D dances from music is an emerged research task that benefits a lot of applications in vision and graphics. Previous works treat this task as sequence generation, however, it is challenging to render a music-aligned long-term sequence with high kinematic complexity and coherent movements. In this paper, we reformulate it by a two-stage process, ie, a key pose generation and then an in-between parametric motion curve prediction, where the key poses are easier to be synchronized with the music beats and the parametric curves can be efficiently regressed to render fluent rhythm-aligned movements. We named the proposed method as DanceFormer, which includes two cascading kinematics-enhanced transformer-guided networks (called DanTrans) that tackle each stage, respectively. Furthermore, we propose a large-scale music conditioned 3D dance dataset, called PhantomDance, that is accurately labeled by experienced animators rather than reconstruction or motion capture. This dataset als
    
[^101]: 深度序列号：用于 DNN 知识产权保护的计算水印

    Deep Serial Number: Computational Watermarking for DNN Intellectual Property Protection. (arXiv:2011.08960v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2011.08960](http://arxiv.org/abs/2011.08960)

    本文提出了一种名为 Deep Serial Number (DSN) 的水印算法用于深度神经网络的知识产权保护。该算法在DNN中实现序列号嵌入，只有输入有效序列号的情况下，DNN才能正确工作。

    

    本文提出了一种特别为深度神经网络（DNN）设计的简单而有效的水印算法 Deep Serial Number（DSN）。与传统方法在DNN中引入标识信号不同，我们的方法探索了一种新的DNN知识产权保护机制，有效地阻止了攻击者使用窃取的网络。借鉴序列号在保护传统软件知识产权方面的成功，我们提出了在DNN中实现序列号嵌入的第一个实现。为此，DSN被集成到知识蒸馏框架中，其中首先训练了一个私有的教师DNN。随后，其知识被提炼并传授给一系列定制的学生DNN。每个客户DNN仅在输入有效序列号的情况下才能正确工作。在各种应用中的实验结果证明了DSN在防止未经授权的使用的同时不会损害原始DNN性能的有效性。

    In this paper, we present DSN (Deep Serial Number), a simple yet effective watermarking algorithm designed specifically for deep neural networks (DNNs). Unlike traditional methods that incorporate identification signals into DNNs, our approach explores a novel Intellectual Property (IP) protection mechanism for DNNs, effectively thwarting adversaries from using stolen networks. Inspired by the success of serial numbers in safeguarding conventional software IP, we propose the first implementation of serial number embedding within DNNs. To achieve this, DSN is integrated into a knowledge distillation framework, in which a private teacher DNN is initially trained. Subsequently, its knowledge is distilled and imparted to a series of customized student DNNs. Each customer DNN functions correctly only upon input of a valid serial number. Experimental results across various applications demonstrate DSN's efficacy in preventing unauthorized usage without compromising the original DNN performan
    
[^102]: 关于数据增强中线性转换的泛化效果的研究

    On the Generalization Effects of Linear Transformations in Data Augmentation. (arXiv:2005.00695v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2005.00695](http://arxiv.org/abs/2005.00695)

    这项研究考虑了一类线性转换，并研究了其在过参数化线性回归设置中对岭估计量的影响。研究发现，能够保持数据标签的转换可以通过扩大训练数据的张量来改善估计结果；而混合数据的转换则通过起到正则化作用来改善估计结果。此外，通过在MNIST数据集上进行验证，研究者提出了一个增强方案，该方案通过模型对转换后数据的不确定性进行搜索转换空间，并在图像和文本数据集上验证了其有效性。

    

    数据增强是一种在图像和文本分类任务等应用中提高性能的强大技术。然而，对于各种增强方法为何有效以及其工作原理的严格理解还很有限。在本研究中，我们考虑了一类线性转换，并研究了其在过参数化线性回归设置中对岭估计量的影响。首先，我们通过扩大训练数据的张量来展示了能够保持数据标签的转换会改善估计结果。其次，我们通过混合数据的转换展示了对估计量起到了正则化的作用。最后，我们通过MNIST数据集验证了我们的理论洞见。基于这些洞见，我们提出了一个通过模型对转换后的数据的不确定性来搜索转换空间的增强方案。我们在图像和文本数据集上验证了我们提出的方案。例如，我们的方法在使用Wide-ResNet对CIFAR-100数据集上优于随机采样方法1.24%。

    Data augmentation is a powerful technique to improve performance in applications such as image and text classification tasks. Yet, there is little rigorous understanding of why and how various augmentations work. In this work, we consider a family of linear transformations and study their effects on the ridge estimator in an over-parametrized linear regression setting. First, we show that transformations that preserve the labels of the data can improve estimation by enlarging the span of the training data. Second, we show that transformations that mix data can improve estimation by playing a regularization effect. Finally, we validate our theoretical insights on MNIST. Based on the insights, we propose an augmentation scheme that searches over the space of transformations by how uncertain the model is about the transformed data. We validate our proposed scheme on image and text datasets. For example, our method outperforms random sampling methods by 1.24% on CIFAR-100 using Wide-ResNet
    
[^103]: 声明性机制设计

    Declarative Mechanism Design. (arXiv:1912.13122v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/1912.13122](http://arxiv.org/abs/1912.13122)

    本文介绍了声明性机制设计的研究，提出了机构神经网络作为一种受管制的人工神经网络，引起人们对人工教学的关注，并提供了初步的答案。

    

    多智能体系统（MAS）和声明性电子机构（DEIs）的调控是过去十年涉及物理和软件智能体以及法律的多学科研究课题，但近年来逐渐演变为2016年起被称为新闻的机器律师。其中一种首次提出限制软件智能体行为的方案是电子机构。然而，随着人工神经网络（ANNs）被重新定义为深度学习（DL），有关DL使用的安全、隐私、伦理和法律问题引起了人工智能（AI）社区的关注。现在，MAS的规范几乎得到正确处理，我们提出将人工神经网络的规范作为一种特殊类型的受管制的人工神经网络，称之为机构神经网络（INN）。本文的主旨是引起人们对人工教学（AT）的关注，并给出一个初步的答案，展示了一种证明性的方法。

    Regulation of Multi-Agent Systems (MAS) and Declarative Electronic Institutions (DEIs) was a multidisciplinary research topic of the past decade involving (Physical and Software) Agents and Law since the beginning, but recently evolved towards News-claimed Robot Lawyer since 2016. One of these first proposals of restricting the behaviour of Software Agentswas Electronic Institutions.However, with the recent reformulation of Artificial Neural Networks (ANNs) as Deep Learning (DL), Security, Privacy,Ethical and Legal issues regarding the use of DL has raised concerns in the Artificial Intelligence (AI) Community. Now that the Regulation of MAS is almost correctly addressed, we propose the Regulation of Artificial Neural Networks as Agent-based Training of a special type of regulated Artificial Neural Network that we call Institutional Neural Network (INN).The main purpose of this paper is to bring attention to Artificial Teaching (AT) and to give a tentative answer showing a proof-of-con
    

