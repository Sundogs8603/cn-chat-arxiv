# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [DOST -- Domain Obedient Self-supervised Training for Multi Label Classification with Noisy Labels.](http://arxiv.org/abs/2308.05101) | 本文提出了一种名为"DOST"的方法，通过领域规则的纳入，利用领域遵从自监督训练的范式，解决了多标签分类任务中标签噪声的问题，并改善了学习性能和关键指标，减小了注释噪声的影响。 |
| [^2] | [LayoutLLM-T2I: Eliciting Layout Guidance from LLM for Text-to-Image Generation.](http://arxiv.org/abs/2308.05095) | 本论文提出了LayoutLLM-T2I的方法，用于从LLM中获取布局指导以用于文本到图像生成。该方法采用由粗到细的范例，通过基于大型语言模型的上下文学习，在给定文本提示的条件下合成与文本语义对齐的高保真度图像。 |
| [^3] | [Organizational Bulk Email Systems: Their Role and Performance in Remote Work.](http://arxiv.org/abs/2308.05085) | 这篇论文讨论了在远程工作环境中组织大规模邮件系统的作用和性能。研究发现，该系统存在问题，包括接收者无法保留消息、接收者和发送者对重要消息有不同看法以及沟通者缺乏技术支持。研究提出了进一步研究该系统的议程，并提出了一些关键问题和潜在的研究方向。 |
| [^4] | [Drones4Good: Supporting Disaster Relief Through Remote Sensing and AI.](http://arxiv.org/abs/2308.05074) | 通过结合无人机数据和深度学习方法，本研究展示了如何实现自动化和大规模情况评估，同时演示了机载图像处理技术在无人机救援投送中的集成，以实现快速、大规模图像分析和提高救援投送的安全性。 |
| [^5] | [Competitions in AI -- Robustly Ranking Solvers Using Statistical Resampling.](http://arxiv.org/abs/2308.05062) | 该论文研究了在AI领域中的求解器竞赛结果的泛化问题，通过使用统计重采样技术发现，竞赛结果的排名对基准实例集的微小变化非常敏感，因此不能期望这些排名能够适用于其他样本。因此引入了一种新的统计分析方法来解决这个问题。 |
| [^6] | [Separate Anything You Describe.](http://arxiv.org/abs/2308.05037) | 这项工作介绍了一种用于开放领域音频源分离的基础模型AudioSep，该模型使用自然语言查询，具有强大的分离性能和优秀的泛化能力。 |
| [^7] | [Expert load matters: operating networks at high accuracy and low manual effort.](http://arxiv.org/abs/2308.05035) | 在关键应用领域的人机协同系统中，为了确保最小错误，需要根据模型置信度设定操作点进行决策委托给专家。为了提高系统效用，需要考虑模型仅对准确样本具有自信的特点以及尽量减少委托给专家的样本数量。我们提出了置信度操作特性（COC）曲线来表示模型准确性与专家处理样本数量的权衡关系。这对于医疗保健等可用专家时间有限且昂贵的领域尤为关键。 |
| [^8] | [MetRoBERTa: Leveraging Traditional Customer Relationship Management Data to Develop a Transit-Topic-Aware Language Model.](http://arxiv.org/abs/2308.05012) | 本文提出了一种利用传统交通CRM反馈开发和应用交通主题感知的大型语言模型，能够将开放性文本反馈分类到相关交通主题中。通过半监督学习方法构建训练数据集，并使用RoBERTa架构训练和评估语言模型。 |
| [^9] | [AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities.](http://arxiv.org/abs/2308.04992) | AspectMMKG是一个具有方面意识的多模态知识图谱，通过匹配图像和不同实体方面，它提供了从多个角度理解实体的能力，并在实体方面链接任务中取得了最先进的性能。 |
| [^10] | [Exploring Multilingual Text Data Distillation.](http://arxiv.org/abs/2308.04982) | 本论文提出了基于语言模型的学习方法，用于多语言文本分类数据集的数据提炼。通过实验分析，我们发现这些方法在分类强度和跨架构泛化方面的性能良好，并考虑了数据摘要的语言特定公平性。 |
| [^11] | [Improving Autonomous Separation Assurance through Distributed Reinforcement Learning with Attention Networks.](http://arxiv.org/abs/2308.04958) | 本文提出了一个分布式强化学习框架，利用速度和垂直机动手段，在高密度环境中实现了自主的自我分离能力，从而改进了自主分离保障技术。 |
| [^12] | [Wirelessly Powered Federated Learning Networks: Joint Power Transfer, Data Sensing, Model Training, and Resource Allocation.](http://arxiv.org/abs/2308.04953) | 本论文研究了无线供电联合学习网络中的资源分配问题，提出了一种实用的采集-感知-训练-传输协议，并通过联合优化功率传输、传输功率分配、数据感知和模型训练参数等方式来最小化总完成时间。 |
| [^13] | [Prototypical Kernel Learning and Open-set Foreground Perception for Generalized Few-shot Semantic Segmentation.](http://arxiv.org/abs/2308.04952) | 本研究通过典型核学习和开放集前景感知，解决泛化少样本语义分割中的表示分割和嵌入偏见问题，并且在分割过程中使用了可学习的核以及典型学习和前景上下文感知模块来提高性能。 |
| [^14] | [Methods for Acquiring and Incorporating Knowledge into Stock Price Prediction: A Survey.](http://arxiv.org/abs/2308.04947) | 这项调查论文系统而全面地描述了从不同来源获得外部知识的方法，以应用于股票价格预测，帮助理解股票市场的复杂性。 |
| [^15] | [LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking.](http://arxiv.org/abs/2308.04945) | LLMeBench是一个灵活的框架，用于加速LLMs基准测试。它可以定制任何NLP任务和模型，无论语言，支持零和少样本学习设置，并允许用户添加新的自定义数据集。已经在31个独特的NLP任务上进行了测试，并计划将框架开源。 |
| [^16] | [Gaussian Image Anomaly Detection with Greedy Eigencomponent Selection.](http://arxiv.org/abs/2308.04944) | 本文提出了一种使用预训练的卷积神经网络进行图像异常检测的新方法，通过贪婪策略的特征值分量选择，寻找最优子集以提高性能得分。 |
| [^17] | [Semantic Communications for Artificial Intelligence Generated Content (AIGC) Toward Effective Content Creation.](http://arxiv.org/abs/2308.04942) | 本论文提出了一个综合概念模型，用于集成人工智能生成内容（AIGC）和语义沟通（SemCom），以产生有意义和效果的内容。同时，提出了一个采用AIGC技术作为编码器和解码器的框架，优化了语义提取和评估指标。实验验证了该方法的有效性。 |
| [^18] | [An In-Depth Analysis of Discretization Methods for Communication Learning using Backpropagation with Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2308.04938) | 本文深入分析了使用基于多智能体强化学习的反向传播方法进行通信学习的离散化方法。研究比较了几种先进的离散化方法，并提出了一种新的方法。 |
| [^19] | [Service Reservation and Pricing for Green Metaverses: A Stackelberg Game Approach.](http://arxiv.org/abs/2308.04914) | 本文研究了绿色Metaverse中的服务预订和定价问题，通过Stackelberg博弈方法解决了MSP和用户之间的经济冲突，实现了能效的服务提供。 |
| [^20] | [LLaMA-E: Empowering E-commerce Authoring with Multi-Aspect Instruction Following.](http://arxiv.org/abs/2308.04913) | LLaMA-E是一种统一且定制的指导语言模型，旨在解决电子商务创作过程中遇到的各种任务，包括广告生成、查询增强的产品标题改写、产品分类、购买意图推测和常规问答。 |
| [^21] | [SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation.](http://arxiv.org/abs/2308.04911) | 在有限标注数据的医学图像分析中存在困难，我们提出了一个新的框架SLPT，将选择性标注和提示调整相结合，以提高性能并减少标注成本。 |
| [^22] | [Adversarial Deep Reinforcement Learning for Cyber Security in Software Defined Networks.](http://arxiv.org/abs/2308.04909) | 本文研究了在软件定义网络中利用对抗性学习来训练更加鲁棒的深度强化学习智能体，探讨了两种算法的差异。攻击者利用因果攻击试图破坏学习过程。游戏中进行了有序的因果攻击。 |
| [^23] | [GraphCC: A Practical Graph Learning-based Approach to Congestion Control in Datacenters.](http://arxiv.org/abs/2308.04905) | 本论文提出了一种名为GraphCC的实用图学习方法，用于优化数据中心的拥塞控制。通过结合多智能体强化学习（MARL）和图神经网络，该方法能够适应快速和突然的网络状态变化，并提高网络的性能。 |
| [^24] | [NLLG Quarterly arXiv Report 06/23: What are the most influential current AI Papers?.](http://arxiv.org/abs/2308.04889) | 该报告关注当前最具影响力的AI论文，并以标准化引用计数为依据编制了40篇最受欢迎的论文列表。观察到在2023年上半年，大型语言模型（LLMs）和具体而言的ChatGPT相关的论文占主导地位，ChatGPT表现出下降的趋势。 |
| [^25] | [Learning Type-Generalized Actions for Symbolic Planning.](http://arxiv.org/abs/2308.04867) | 本文提出了一种学习通用型符号规划动作的新方法，通过给定实体层次结构和观察到的相似行为来实现通用化。在模拟的厨房环境中验证了该方法的有效性。 |
| [^26] | [Scalability of Message Encoding Techniques for Continuous Communication Learned with Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2308.04844) | 本论文使用多智能体强化学习研究了在增加消息中包含的信息量和智能体数量增加的情况下，采用不同的消息编码方法对系统性能的影响。结果表明，均值消息编码器比注意力消息编码器更优，在智能体之间的通信协议中起到关键作用。 |
| [^27] | [Neuro-Symbolic RDF and Description Logic Reasoners: The State-Of-The-Art and Challenges.](http://arxiv.org/abs/2308.04814) | 本文概述了神经符号化RDF和描述逻辑推理机的现状和挑战，并介绍了神经符号化推理在RDF(S)、EL和ALC描述逻辑以及OWL 2 RL领域的已有研究文献。 |
| [^28] | [A Fast and Optimal Learning-based Path Planning Method for Planetary Rovers.](http://arxiv.org/abs/2308.04792) | 本文提出了一种基于学习的快速路径规划方法，通过学习最优路径示范中的语义信息和地图表示，生成概率分布来搜索最优路径。实验结果表明，该方法能够提高行星探测车的探索效率。 |
| [^29] | [Multi-View Fusion and Distillation for Subgrade Distresses Detection based on 3D-GPR.](http://arxiv.org/abs/2308.04779) | 该论文提出了一种基于多视角融合和蒸馏的方法，用于基于3D地下雷达的路基损坏检测任务。通过利用多视角信息和构建真实多视角图像数据集，提高了检测效率和准确性，同时降低了计算复杂性。 |
| [^30] | [Multi-modal Multi-view Clustering based on Non-negative Matrix Factorization.](http://arxiv.org/abs/2308.04778) | 本文提出了一种基于非负矩阵分解的多模态多视图聚类方法，通过协作多个本地NMF模型，揭示了数据集中的潜在模式，并在多个应用领域取得了良好的实验结果。 |
| [^31] | [E3-UAV: An Edge-based Energy-Efficient Object Detection System for Unmanned Aerial Vehicles.](http://arxiv.org/abs/2308.04774) | E3-UAV是一种面向边缘的能量高效无人机目标检测系统，通过动态调整飞行参数和检测算法，最大程度地减少能量消耗。 |
| [^32] | [Induction Network: Audio-Visual Modality Gap-Bridging for Self-Supervised Sound Source Localization.](http://arxiv.org/abs/2308.04767) | 本研究提出了一种Induction Network来解决自监督音源定位中的视听模态差距问题。通过解耦梯度并引入自举学习，使声源的判别性视觉表示能够与音频模态保持一致。还引入了自适应阈值选择策略来增强其引导能力的鲁棒性。 |
| [^33] | [Feature Matching Data Synthesis for Non-IID Federated Learning.](http://arxiv.org/abs/2308.04761) | 本文提出了一种用于非独立同分布联邦学习的特征匹配数据合成方法，通过生成合成数据来解决联邦学习中的非独立同分布问题，并提出了一种隐私保护的特征增强方法。这种方法能够改善模型的泛化能力并抹去真实特征的信息。 |
| [^34] | [Automated Driving Without Ethics: Meaning, Design and Real-World Implementation.](http://arxiv.org/abs/2308.04760) | 本研究提出了一种自动驾驶决策制定策略，使用预定义参数来评估可能发生事故的风险，并集成伦理倾向理论，以适应不同环境和决策背景。该方法旨在提供一种灵活的计算方法，而不是定义车辆行为的道德要求。 |
| [^35] | [Bird's-Eye-View Scene Graph for Vision-Language Navigation.](http://arxiv.org/abs/2308.04758) | 这项研究提出了一种鸟瞰场景图（BSG）用于视觉语言导航，通过使用多步鸟瞰表示来编码场景布局和几何线索，从而改进了当前全景观察的导航代理的能力，并提供了更准确的动作预测。 |
| [^36] | [Enhancing Efficient Continual Learning with Dynamic Structure Development of Spiking Neural Networks.](http://arxiv.org/abs/2308.04749) | 使用动态结构发展的脉冲神经网络来实现高效连续学习，通过动态增长和修剪神经元来提高记忆容量和减少计算开销，同时利用重叠的共享结构快速应用已获得的知识到新任务上。 |
| [^37] | [Case Study: Using AI-Assisted Code Generation In Mobile Teams.](http://arxiv.org/abs/2308.04736) | 本研究通过案例研究评估了在专注于移动开发的团队中使用AI辅助代码生成的性能。通过对参与者进行技术入职和技术堆栈切换阶段的问题求解，评估了使用和不使用AI-Code生成器的影响。研究结合了时间、正确性和技术集成等度量指标，并分析了参与者的反馈，以确定使用AI辅助编程工具是否对开发人员产生影响。 |
| [^38] | [JEN-1: Text-Guided Universal Music Generation with Omnidirectional Diffusion Models.](http://arxiv.org/abs/2308.04729) | JEN-1是一个高保真度通用音乐生成模型，通过结合自回归和非自回归训练，实现了文本引导的音乐生成、音乐修补和延续等生成任务，在文本音乐对齐和音乐质量方面表现出优越性，同时保持计算效率。 |
| [^39] | [JiangJun: Mastering Xiangqi by Tackling Non-Transitivity in Two-Player Zero-Sum Games.](http://arxiv.org/abs/2308.04719) | 本文通过研究非传递性问题，开发了江俊算法，结合蒙特卡洛树搜索和策略空间响应神谕，以逼近纳什均衡，成功提高了象棋对弈中的胜率。 |
| [^40] | [Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution.](http://arxiv.org/abs/2308.04708) | 本文提出了一种新颖的概率异常归因框架，通过生成扰动来计算每个输入变量的归因得分的概率分布，并量化这些得分的不确定性。 |
| [^41] | [Explainable AI in Orthopedics: Challenges, Opportunities, and Prospects.](http://arxiv.org/abs/2308.04696) | 解释性人工智能在骨科中的应用面临挑战，但也带来机遇。为了实现透明度和可解释性，需要开发注重人工智能模型的透明性和可解释性的算法，并促进跨学科合作。 |
| [^42] | [Finite Element Operator Network for Solving Parametric PDEs.](http://arxiv.org/abs/2308.04690) | 本文提出了一种新方法，通过有限元算子网络（FEONet）解决参数PDE。它结合了深度学习和传统数值方法，展示了在没有输入-输出训练数据的情况下解决参数PDE的有效性，并在准确度、泛化性和计算灵活性方面优于现有方法。 |
| [^43] | [web crawler strategies for web pages under robot.txt restriction.](http://arxiv.org/abs/2308.04689) | 本文研究了在robot.txt限制下的网络爬虫策略，讨论了搜索引擎如何确定网页排名以及如何获取数据库中的网页。并介绍了机器人排除协议规则和robot.txt文件的基本格式。 |
| [^44] | [Rapid Training Data Creation by Synthesizing Medical Images for Classification and Localization.](http://arxiv.org/abs/2308.04687) | 该论文提出了一种通过合成医学图像快速创建训练数据的方法，以解决医学领域中生成注释数据的专业知识、时间和成本高的问题。该方法在弱监督和强监督目标定位模型上均取得了良好的效果。 |
| [^45] | [Sci-CoT: Leveraging Large Language Models for Enhanced Knowledge Distillation in Small Models for Scientific QA.](http://arxiv.org/abs/2308.04679) | 本论文研究了通过知识蒸馏将大型语言模型(LLMs)的推理能力转移到较小模型的可能性，提出了Sci-CoT框架，分离了生成理由和推理的过程。 |
| [^46] | [Addressing Racial Bias in Facial Emotion Recognition.](http://arxiv.org/abs/2308.04674) | 本研究通过分析不同种族分布的子采样训练集，并评估模拟中的测试性能，解决了面部情绪识别中的种族偏见问题。实验结果表明，具有姿势面部的较小数据集可以提高公平性和性能指标，但在具有更大面部变异的较大数据集中，种族平衡仍然无法实现不同种族群体之间的测试性能的公平性。 |
| [^47] | [SSL-Auth: An Authentication Framework by Fragile Watermarking for Pre-trained Encoders in Self-supervised Learning.](http://arxiv.org/abs/2308.04673) | 本文提出了SSL-Auth，这是一种用于自监督学习中预训练的编码器的易碎水印身份验证框架。该方法利用选择的关键样本作为水印信息，并训练一个验证网络来重构水印信息，从而进行验证。 |
| [^48] | [Resource Constrained Model Compression via Minimax Optimization for Spiking Neural Networks.](http://arxiv.org/abs/2308.04672) | 提出了一种资源受限下通过极小化最大化优化对脉冲神经网络进行模型压缩的方法，以平衡模型性能和计算效率。 |
| [^49] | [A Hierarchical Destroy and Repair Approach for Solving Very Large-Scale Travelling Salesman Problem.](http://arxiv.org/abs/2308.04639) | 提出了一种层次化的破坏和修复方法用于解决极大规模的旅行推销员问题。该方法采用了递归修复和压缩输入实例的层次化搜索框架，能够在合理的时间内提供高竞争力的解决方案。 |
| [^50] | [Sparse Binary Transformers for Multivariate Time Series Modeling.](http://arxiv.org/abs/2308.04637) | 本研究将稀疏二值变压器应用于多元时间序列问题，并展示了该轻量级模型在分类、异常检测和单步预测任务中取得了与密集浮点变压器相当的准确度。同时，通过两个修改降低了注意机制的计算复杂性。 |
| [^51] | [Where's the Liability in Harmful AI Speech?.](http://arxiv.org/abs/2308.04635) | AI生成式模型可能会产生具有潜在责任风险的有害言论。解决模型创建者和部署者的法律责任问题的关键在于算法设计的技术细节。需要进行深入的Section 230免责分析以及下游责任分析。 |
| [^52] | [A Comparative Study of Sentence Embedding Models for Assessing Semantic Variation.](http://arxiv.org/abs/2308.04625) | 本研究比较了几种最近的句子嵌入方法在分析语义变化方面的一致性和有效性，并通过真实世界文本进行了评估。 |
| [^53] | [Benchmarking LLM powered Chatbots: Methods and Metrics.](http://arxiv.org/abs/2308.04624) | 本文提出了一种新型的E2E基准测试，用于评估由LLM驱动的聊天机器人的准确性和实用性，相比其他指标，该基准测试展现出更好的结果。 |
| [^54] | [Accelerating LLM Inference with Staged Speculative Decoding.](http://arxiv.org/abs/2308.04623) | 本文提出了一种新算法，分阶段推测解码，用于加速在小批量、设备上进行LLM推理。通过使用树形结构的批次重组和增加第二阶段的推测解码，将单批解码延迟降低了3.16倍，而输出质量保持完美。 |
| [^55] | [Model of models -- Part 1.](http://arxiv.org/abs/2308.04600) | 本文提出了一种新的认知模型，该模型在成熟智能状态下操作累积的知识，并依赖适当的意愿进行指导。 |
| [^56] | [Shepherd: A Critic for Language Model Generation.](http://arxiv.org/abs/2308.04592) | Shepherd是一种专门用于评论和提出改进建议的语言模型，通过使用高质量的反馈数据集，它可以识别和修复不同的错误。与其他模型相比，在评估和人工评估中，Shepherd的性能表现更佳。 |
| [^57] | [Temporal DINO: A Self-supervised Video Strategy to Enhance Action Prediction.](http://arxiv.org/abs/2308.04589) | Temporal DINO是一种自监督视频策略，通过引入一个学生模型和一个教师模型，使得学生模型能够通过观察过去帧来学习未来帧的上下文，以增强动作预测。这种方法在行动预测任务上在ROAD数据集上进行了评估。 |
| [^58] | [Developmental Bootstrapping of AIs.](http://arxiv.org/abs/2308.04586) | 传统的符号AI方法和深度学习AI方法无法满足创建强大和可信赖的AI的挑战，然而，发展脱靴法通过模仿人类儿童的能力发展过程，为创建稳健可靠的AI提供了希望。 |
| [^59] | [Improving Performance in Continual Learning Tasks using Bio-Inspired Architectures.](http://arxiv.org/abs/2308.04539) | 本研究提出了一种受生物启发的轻量级神经网络架构，通过本地误差信号实现在线连续学习，克服了传统方法的局限性，在多个数据集上展现出优秀的表现。 |
| [^60] | [Generating Modern Persian Carpet Map by Style-transfer.](http://arxiv.org/abs/2308.04529) | 本研究旨在利用深度神经网络(DNN)生成现代波斯地毯地图，并提出了三种不同的DNN风格迁移方法。通过使用Style-Swap方法创建初始地图，并使用Clip-Styler、Gatys和Style-Swap方法生成更多样化的设计，同时还考虑了对地图进行着色的方法。 |
| [^61] | [Deep Learning for Diverse Data Types Steganalysis: A Review.](http://arxiv.org/abs/2308.04522) | 本综述论文详细综述了基于深度学习的隐写分析技术在数字媒体中检测隐藏信息的最新研究进展。 |
| [^62] | [DisCoCat for Donkey Sentences.](http://arxiv.org/abs/2308.04519) | 这篇论文展示了如何在一个组合分布式意义模型中解析Donkey句子，并提出了一种类型逻辑语法和关系向量空间语义。 |
| [^63] | [MT-IceNet -- A Spatial and Multi-Temporal Deep Learning Model for Arctic Sea Ice Forecasting.](http://arxiv.org/abs/2308.04511) | 提出了一种名为MT-IceNet的深度学习模型，用于预测北极海冰浓度。该模型采用了空间和多时序结构，利用编码器-解码器架构和跳跃连接处理多时序输入流，并可生成未来时间步骤的空间地图。 |
| [^64] | [ChatGPT for Arabic Grammatical Error Correction.](http://arxiv.org/abs/2308.04492) | 本研究针对阿拉伯语语法错误修正任务，探究了指令调校的大型语言模型（LLMs）的能力。通过结合多种提示方法和少样本学习，我们的研究发现，在阿拉伯语语法错误修正中，GPT-4能够达到65.49的F1得分，比我们已有的基准提高了大约5个点。这表明LLMs在资源匮乏环境中具有潜力，并为模型训练提供了生成合成数据的可行方法。 |
| [^65] | [A Comparative Study of Code Generation using ChatGPT 3.5 across 10 Programming Languages.](http://arxiv.org/abs/2308.04477) | 本研究比较了使用ChatGPT 3.5在10种编程语言中生成代码的能力，并发现了模型的意外行为和限制。 |
| [^66] | [Correlating Medi- Claim Service by Deep Learning Neural Networks.](http://arxiv.org/abs/2308.04469) | 本论文通过使用深度学习神经网络，结合回归模型的相关性研究，利用卷积神经网络架构来检测医疗保险索赔中的欺诈行为，并使用有监督和无监督分类器来区分欺诈和非欺诈索赔。 |
| [^67] | [Anonymizing Speech: Evaluating and Designing Speaker Anonymization Techniques.](http://arxiv.org/abs/2308.04455) | 本研究提出了匿名化语音的解决方案，并评估了匿名化的程度，以应对语音数据收集中的隐私问题和恶意使用的风险。 |
| [^68] | [Vulnerabilities in AI Code Generators: Exploring Targeted Data Poisoning Attacks.](http://arxiv.org/abs/2308.04451) | 本文评估了AI代码生成器的安全性，发现它们容易受到数据毒化攻击，即注入恶意样本来生成易受攻击的代码。攻击可以成功即使只有少量数据被毒化，而且不影响预训练模型生成的代码的正确性，使其难以被检测。 |
| [^69] | [Dual Governance: The intersection of centralized regulation and crowdsourced safety mechanisms for Generative AI.](http://arxiv.org/abs/2308.04448) | 本文讨论了生成AI领域的治理问题，提出了将集中监管与众包安全机制相结合的双重治理方式。集中监管存在缺乏明确性和统一性等问题，而众包安全机制则存在缺乏统一性和合规性的不足。该研究旨在促进生成AI领域的负责任和道德发展。 |
| [^70] | [Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc.](http://arxiv.org/abs/2308.04445) | 对于未来的AI，需要从生成式AI转向可信赖的AI。通过培养基于明确知识和经验规则的AI，可以解决当前方法的限制并实现推理过程的可信赖和可解释性。 |
| [^71] | [Blockchain-based Optimized Client Selection and Privacy Preserved Framework for Federated Learning.](http://arxiv.org/abs/2308.04442) | 本论文提出了基于区块链的优化客户选择和隐私保护框架，用于解决联邦学习中的单点故障攻击和模型准确性问题，并采用完全同态加密保护隐私。 |
| [^72] | [Nature and the Machines.](http://arxiv.org/abs/2308.04440) | 《自然》杂志在一篇社论中呼吁我们“停止谈论明天的AI末日，而AI今天就存在风险。”这被认为是一个严重的判断失误，特别是对于有影响力的行动者来说，因为我们期望他们能够考虑到错误的后果。 |
| [^73] | [The Two Faces of AI in Green Mobile Computing: A Literature Review.](http://arxiv.org/abs/2308.04436) | 这篇论文综述了在绿色移动计算领域使用人工智能的研究，并指出人工智能在移动设备中既是关键的功能实现者，又是能源消耗的主要来源。 |
| [^74] | [Event Abstraction for Enterprise Collaboration Systems to Support Social Process Mining.](http://arxiv.org/abs/2308.04396) | 本论文提出了一种定制的企业协作系统的事件抽象方法，通过比较实际用户活动和系统生成的低级别跟踪来训练模型，并将低级别跟踪转换为抽象的高级别日志，以支持社会流程挖掘。 |
| [^75] | [Cumulative Reasoning With Large Language Models.](http://arxiv.org/abs/2308.04371) | 本文提出了一种名为累积推理（CR）的新方法，利用语言模型以累积和迭代的方式模拟人类思维过程，通过将任务分解为较小的组件，简化问题解决过程，取得了优于现有方法的性能，并在逻辑推理和24点游戏中实现了显著提升。 |
| [^76] | [Apple Vision Pro for Healthcare: "The Ultimate Display"?.](http://arxiv.org/abs/2308.04313) | 苹果推出了Vision Pro，一款具有混合现实和增强现实功能的虚拟现实设备，拥有独特的特点，例如内部屏幕展示佩戴者的眼睛以及数字皇冠按钮的融合功能。这款无线设备可能实现了“终极显示器”的潜力。 |
| [^77] | [Understanding CNN Hidden Neuron Activations using Structured Background Knowledge and Deductive Reasoning.](http://arxiv.org/abs/2308.03999) | 本文提供了一种使用结构化背景知识和演绎推理的方法，用于解释CNN隐藏神经元的激活。该方法能够提供有意义的解释，解决了深度学习系统黑盒特性的问题。 |
| [^78] | [ALFA -- Leveraging All Levels of Feature Abstraction for Enhancing the Generalization of Histopathology Image Classification Across Unseen Hospitals.](http://arxiv.org/abs/2308.03936) | ALFA使用各个层次的特征抽象来增强组织病理学图像分类在未知医院中的泛化能力，并通过自监督学习和域对齐实现了对不变特征的提取，以及对参与医院的高度特定特征的表示与分类。 |
| [^79] | [Mobile Supply: The Last Piece of Jigsaw of Recommender System.](http://arxiv.org/abs/2308.03855) | 本研究提出了一种新的推荐系统模块，称为移动供应，旨在解决分页机制问题。通过在用户设备上部署推荐算法，可以有效减少数据传输延迟和提升用户的沉浸式体验。 |
| [^80] | [Doubly Robust Estimator for Off-Policy Evaluation with Large Action Spaces.](http://arxiv.org/abs/2308.03443) | 本文提出了一种用于具有大动作空间的离策略评估的双重稳健估计器（MDR）。与现有的基准估计器相比，MDR能够在减小方差的同时保持无偏性，从而提高了估计的准确性。实验结果证实了MDR相对于现有估计器的优越性。 |
| [^81] | [Anomaly Detection in Global Financial Markets with Graph Neural Networks and Nonextensive Entropy.](http://arxiv.org/abs/2308.02914) | 通过使用图神经网络和非极端熵，在全球金融市场中成功检测出了异常情况，发现了在危机期间高度相关的资产的复杂结构减少，并且不同的非极端熵参数在危机前、期间和后的异常数量存在统计上的差异 |
| [^82] | [Adapt and Decompose: Efficient Generalization of Text-to-SQL via Domain Adapted Least-To-Most Prompting.](http://arxiv.org/abs/2308.02582) | 该论文介绍了一种通过领域适应和最少到最多提示的方式实现文本到SQL的高效泛化的方法。通过离线抽样获取少量样本，并合成一个通用提示，避免了昂贵的测试时间样本检索，并通过自适应和分解的方法更好地处理跨领域和跨组合式的泛化。 |
| [^83] | [AutoML4ETC: Automated Neural Architecture Search for Real-World Encrypted Traffic Classification.](http://arxiv.org/abs/2308.02182) | AutoML4ETC是一个自动设计高效且高性能神经架构的工具，用于加密流量分类。其通过定义新颖的搜索空间和使用不同的搜索策略，在多个数据集上优于当前最先进的加密流量分类器。 |
| [^84] | [Enhancing Representation Learning for Periodic Time Series with Floss: A Frequency Domain Regularization Approach.](http://arxiv.org/abs/2308.01011) | 本文提出了一种叫做Floss的无监督方法，通过在频域上对学到的表示进行正则化来增强周期性时间序列的表示学习。Floss方法可以自动检测时间序列中的周期性并学习具有周期一致性的有意义的表示。 |
| [^85] | [ESP: Exploiting Symmetry Prior for Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2307.16186) | 本文提出了一种利用对称性先验知识的框架来解决多Agent强化学习中的数据效率问题，通过将数据增强和一致性损失集成到现有方法中，能够提高模型训练效率，并且泛化性能良好。 |
| [^86] | [Tackling the Curse of Dimensionality with Physics-Informed Neural Networks.](http://arxiv.org/abs/2307.12306) | 本文提出了一种新方法，利用物理信知的神经网络(PINNs)解决高维度的偏微分方程(PDEs)问题，并证明了收敛性和其他期望属性。 |
| [^87] | [Towards Automatic Boundary Detection for Human-AI Collaborative Hybrid Essay in Education.](http://arxiv.org/abs/2307.12267) | 本研究探索了在教育领域中，由人类和生成性语言模型协作编写的混合文本的AI内容检测方法，将其形式化为识别转换点的任务，以区分人类编写和AI生成的部分。 |
| [^88] | [MSQNet: Actor-agnostic Action Recognition with Multi-modal Query.](http://arxiv.org/abs/2307.10763) | MSQNet是一种无关演员的多模态多标签动作识别方法，通过使用视觉和文本模态来更好地表示动作类别，克服了现有方法中针对特定演员的限制。 |
| [^89] | [RL-ViGen: A Reinforcement Learning Benchmark for Visual Generalization.](http://arxiv.org/abs/2307.10224) | RL-ViGen是一种用于视觉泛化的强化学习基准，包含多样的任务和广泛的泛化类型，旨在推动对代理人视觉泛化能力的全面评估。 |
| [^90] | [An Alternative to Variance: Gini Deviation for Risk-averse Policy Gradient.](http://arxiv.org/abs/2307.08873) | 本研究提出了一种风险厌恶策略梯度的替代方法，通过使用基尼离差来替代方差，缓解了方差方法的局限性，并在实证评估中取得了高回报和低风险的成果。 |
| [^91] | [INFLECT-DGNN: Influencer Prediction with Dynamic Graph Neural Networks.](http://arxiv.org/abs/2307.08131) | INFLECT-DGNN是一个结合了图神经网络和递归神经网络的框架，使用加权损失函数、针对图数据适应的合成少数过采样技术和滚动窗口策略，用于影响者预测。实验结果显示，使用RNN来编码时间属性和GNN显著提高了预测性能。 |
| [^92] | [AutoHint: Automatic Prompt Optimization with Hint Generation.](http://arxiv.org/abs/2307.07415) | 本文介绍了AutoHint，一种用于大型语言模型的自动提示生成和优化的新框架。该方法通过从输入-输出演示中生成提示，并利用上下文学习和零样本学习的优点，优化原始提示，从而提高了大型语言模型在特定任务上的表现。 |
| [^93] | [A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media.](http://arxiv.org/abs/2307.06775) | 本研究创建了一个多模态深度学习模型，将文本和视觉数据相结合，能够准确识别社交媒体上的促进饮食紊乱的内容。最有效的模型是RoBERTa自然语言处理模型和MaxViT图像分类模型的融合模型，准确率和F1分数分别达到95.9%和0.959。 |
| [^94] | [A Survey on Graph Neural Networks for Time Series: Forecasting, Classification, Imputation, and Anomaly Detection.](http://arxiv.org/abs/2307.03759) | 这项综述介绍了图神经网络在时间序列分析中的应用，包括预测、分类、异常检测和插值。图神经网络能够显式地建模时间序列和变量之间的关系，为时间序列数据分析带来了新的方法和技术。 |
| [^95] | [The False Dawn: Reevaluating Google's Reinforcement Learning for Chip Macro Placement.](http://arxiv.org/abs/2306.09633) | 谷歌2021年在《自然》杂志上发表的一篇论文声称其使用强化学习在芯片设计领域进行了创新，但两项独立的评估表明，谷歌的方法不如人类设计师、不如一个众所周知的算法（模拟退火），并且也不如普遍可用的商业软件，文章的完整性也遭到了严重的损害。 |
| [^96] | [Diff-TTSG: Denoising probabilistic integrated speech and gesture synthesis.](http://arxiv.org/abs/2306.09417) | Diff-TTSG是第一个基于扩散的概率模型，用于联合学习合成语音和手势，相比于先前最新技术的非概率方法，它可以更好地捕捉人类讲话和运动的变化，产生更逼真和多样化的集成语音和手势合成。 |
| [^97] | [Temporally Layered Architecture for Efficient Continuous Control.](http://arxiv.org/abs/2305.18701) | 这项研究提出了一种时间分层架构，利用时间抽象实现了高效的连续控制，具有节能、持续探索、减少决策、减少抖动和增加动作重复等优势。 |
| [^98] | [Adapt and Align to Improve Zero-Shot Sketch-Based Image Retrieval.](http://arxiv.org/abs/2305.05144) | 本文针对零样本基于草图图像检索的跨域和语义问题，提出了一种自适应和对齐的方法，通过插入简单且轻量的域适配器重新学习草图领域的新抽象概念，并通过明确对齐学习到的图像嵌入以提高跨域表示能力。 |
| [^99] | [Can Feature Engineering Help Quantum Machine Learning for Malware Detection?.](http://arxiv.org/abs/2305.02396) | 本文通过量子机器学习与特征选择策略相结合的混合框架，以降低恶意软件分类器培训时间，初步结果表明在模拟器上可以达到78.91％的测试准确性。 |
| [^100] | [DiverseVul: A New Vulnerable Source Code Dataset for Deep Learning Based Vulnerability Detection.](http://arxiv.org/abs/2304.00409) | 这个论文提供了一个包含150个CWE的新的漏洞源代码数据集，覆盖比以前所有数据集加起来多305个项目。作者通过增加训练数据的多样性和数量改进了深度学习模型在漏洞检测方面的表现。通过结合已有数据集，作者还研究了使用深度学习检测软件漏洞的挑战和前途的分析，结果表明目前深度学习检测漏洞仍存在高误报率，低F1分数和难以检测严重CWE的问题。 |
| [^101] | [Quantifying Causes of Arctic Amplification via Deep Learning based Time-series Causal Inference.](http://arxiv.org/abs/2303.07122) | 该研究提出了一种基于循环神经网络的时间序列因果推断模型TCINet，用于推断大气过程对海冰融化的因果效应。通过实验证明，该模型能够显著提高量化北极海冰融化的主要原因的能力。 |
| [^102] | [Inducing Neural Collapse to a Fixed Hierarchy-Aware Frame for Reducing Mistake Severity.](http://arxiv.org/abs/2303.05689) | 本文提出了一种将神经衰竭引入到固定的层次感知框架中的方法，通过学习层次感知的倒数第二特征，并将其坍缩到框架上，来减少模型预测的错误严重程度。 |
| [^103] | [Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference.](http://arxiv.org/abs/2303.04673) | 本文研究了优化大规模语言模型生成推理的成本效益超参数，通过经济的超参数优化和基于成本的修剪，提出了EcoOptiGen框架，该框架在使用GPT-3.5/GPT-4模型的任务中表现出有效性。 |
| [^104] | [A Universal Question-Answering Platform for Knowledge Graphs.](http://arxiv.org/abs/2303.00595) | 本文提出了KGQAn，一个通用的问答系统，它无需针对每个目标知识图谱进行定制。通过新颖的形式化方法，将问题转换为中间的抽象表示，从而实现了将自然语言问题转换为SPARQL查询的目标。 |
| [^105] | [A Survey of Deep Learning: From Activations to Transformers.](http://arxiv.org/abs/2302.00722) | 这篇综述调查了深度学习领域的重要进展，包括各种架构、层、目标和优化技术的发展，以及关注机制、归一化、跳跃连接、Transformer和自监督学习等方法的变体。总结了成功创新的关键策略，并讨论了最近的商业闭源模型。 |
| [^106] | [Model Ratatouille: Recycling Diverse Models for Out-of-Distribution Generalization.](http://arxiv.org/abs/2212.10445) | 本论文提出了一种名为模型美食的新策略，通过回收基于同一基础模型在多样辅助任务上的多次微调，实现了在目标任务上的超出分布的泛化能力。通过利用辅助任务的多样性，这种策略旨在最大限度地提高模型权重的多样性。 |
| [^107] | [RaLiBEV: Radar and LiDAR BEV Fusion Learning for Anchor Box Free Object Detection System.](http://arxiv.org/abs/2211.06108) | 本论文提出了一种基于鸟瞰视角的引导框自由物体检测系统，通过雷达和激光雷达的特征融合学习，解决了在恶劣天气下物体检测的问题。 |
| [^108] | [Rickrolling the Artist: Injecting Backdoors into Text Encoders for Text-to-Image Synthesis.](http://arxiv.org/abs/2211.02408) | 本文证明了文本生成图像模型中使用的文本编码器存在重大的篡改风险，并提出了一种基于反向门攻击的方法，可以插入一个单一字符触发器进提示中，从而触发模型生成具有预定义属性的图像或遵循隐藏的、潜在的恶意描述的图像。 |
| [^109] | [One-Shot Neural Fields for 3D Object Understanding.](http://arxiv.org/abs/2210.12126) | 本文提出了一种一次性神经场方法，用于机器人学中的3D对象理解。这种方法利用单个RGB图像构建统一而紧凑的场景表示，可以用于多个任务，如新视角渲染、3D重建、碰撞检查和稳定抓取预测。研究结果表明，这种方法能够从新视角进行渲染并预测成功的抓取。 |
| [^110] | [A first-order logic characterization of safety and co-safety languages.](http://arxiv.org/abs/2209.02307) | 本论文提出了一些新的语言类型和算法，可以降低模型检测和反应合成等问题的复杂度。 |
| [^111] | [BoMD: Bag of Multi-label Descriptors for Noisy Chest X-ray Classification.](http://arxiv.org/abs/2203.01937) | 本文提出了一种适用于多标签、嘈杂CXR学习的方法，使用基于袋的多标签描述符平滑地重新标记数据集中的样本，并进行训练以提高模型性能。 |

# 详细

[^1]: DOST - 无噪声标签的多标签分类的领域遵从自监督训练

    DOST -- Domain Obedient Self-supervised Training for Multi Label Classification with Noisy Labels. (arXiv:2308.05101v1 [cs.LG])

    [http://arxiv.org/abs/2308.05101](http://arxiv.org/abs/2308.05101)

    本文提出了一种名为"DOST"的方法，通过领域规则的纳入，利用领域遵从自监督训练的范式，解决了多标签分类任务中标签噪声的问题，并改善了学习性能和关键指标，减小了注释噪声的影响。

    

    深度学习技术对标注数据的巨大需求引发了注释噪声的问题。尽管这个问题在机器学习文献中广泛讨论，但在"多标签分类"（MLC）任务的复杂噪声情况下，却相对未经探索。此外，当所涉及的领域具有某些逻辑约束时，噪声标注常常加剧违规情况，使得该系统被专家认为是不可接受的。本文研究了标签噪声对MLC任务中领域规则违规事件的影响，并将领域规则纳入我们的学习算法，以减轻噪声的影响。我们提出了"Domain Obedient Self-supervised Training"（DOST）范式，不仅可以使深度学习模型更符合领域规则，还可以在关键指标上提高学习性能，并最小化注释噪声的影响。这种新颖的方法使用领域指导训练技术。

    The enormous demand for annotated data brought forth by deep learning techniques has been accompanied by the problem of annotation noise. Although this issue has been widely discussed in machine learning literature, it has been relatively unexplored in the context of "multi-label classification" (MLC) tasks which feature more complicated kinds of noise. Additionally, when the domain in question has certain logical constraints, noisy annotations often exacerbate their violations, making such a system unacceptable to an expert. This paper studies the effect of label noise on domain rule violation incidents in the MLC task, and incorporates domain rules into our learning algorithm to mitigate the effect of noise. We propose the Domain Obedient Self-supervised Training (DOST) paradigm which not only makes deep learning models more aligned to domain rules, but also improves learning performance in key metrics and minimizes the effect of annotation noise. This novel approach uses domain guid
    
[^2]: LayoutLLM-T2I：从LLM中获取布局指导以用于文本到图像生成

    LayoutLLM-T2I: Eliciting Layout Guidance from LLM for Text-to-Image Generation. (arXiv:2308.05095v1 [cs.CV])

    [http://arxiv.org/abs/2308.05095](http://arxiv.org/abs/2308.05095)

    本论文提出了LayoutLLM-T2I的方法，用于从LLM中获取布局指导以用于文本到图像生成。该方法采用由粗到细的范例，通过基于大型语言模型的上下文学习，在给定文本提示的条件下合成与文本语义对齐的高保真度图像。

    

    在文本到图像生成领域，近期稳定扩散技术的显著进展使得生成各种新颖的逼真图像成为可能。然而，当前的模型在复杂自然场景中仍然面临着错位问题（例如，空间关系理解和数字化失败），这阻碍了高保真度的文本到图像生成。尽管最近已经进行了一些改进，通过提供细粒度的指导（例如，草图和涂鸦）来改善可控性，但是由于用户必须手动提供这些指导信息，因此这个问题尚未根本解决。在这项工作中，我们努力合成与给定文本提示语义对齐且不需要任何指导的高保真度图像。为了达到这个目标，我们提出了一个由粗到细的范例，用于布局规划和图像生成。具体而言，我们首先通过基于大型语言模型的上下文学习，在给定的文本提示条件下生成粗粒度的布局。

    In the text-to-image generation field, recent remarkable progress in Stable Diffusion makes it possible to generate rich kinds of novel photorealistic images. However, current models still face misalignment issues (e.g., problematic spatial relation understanding and numeration failure) in complex natural scenes, which impedes the high-faithfulness text-to-image generation. Although recent efforts have been made to improve controllability by giving fine-grained guidance (e.g., sketch and scribbles), this issue has not been fundamentally tackled since users have to provide such guidance information manually. In this work, we strive to synthesize high-fidelity images that are semantically aligned with a given textual prompt without any guidance. Toward this end, we propose a coarse-to-fine paradigm to achieve layout planning and image generation. Concretely, we first generate the coarse-grained layout conditioned on a given textual prompt via in-context learning based on Large Language M
    
[^3]: 组织大规模邮件系统：在远程工作中的作用和性能

    Organizational Bulk Email Systems: Their Role and Performance in Remote Work. (arXiv:2308.05085v1 [cs.HC])

    [http://arxiv.org/abs/2308.05085](http://arxiv.org/abs/2308.05085)

    这篇论文讨论了在远程工作环境中组织大规模邮件系统的作用和性能。研究发现，该系统存在问题，包括接收者无法保留消息、接收者和发送者对重要消息有不同看法以及沟通者缺乏技术支持。研究提出了进一步研究该系统的议程，并提出了一些关键问题和潜在的研究方向。

    

    COVID-19疫情迫使许多员工在家工作。组织大规模邮件现在在这种远程工作环境中起着关键的作用，以便向员工传达中央信息。然而，根据我们最近的研究，我们知道组织大规模邮件存在问题：接收者无法保留他们从组织接收到的大规模消息；接收者和发送者对哪些大规模消息重要有不同的意见；以及沟通者缺乏技术支持来更好地定位和设计消息。在这篇论文中，首先我们回顾了评估、设计和原型化组织沟通系统的先前工作。其次，我们回顾了我们最近的发现和一些我们发现对研究组织沟通有用的研究技术。最后，我们提出了一个研究议程，研究远程工作环境中的组织沟通，并提出了一些关键问题和潜在的研究方向。

    The COVID-19 pandemic has forced many employees to work from home. Organizational bulk emails now play a critical role to reach employees with central information in this work-from-home environment. However, we know from our own recent work that organizational bulk email has problems: recipients fail to retain the bulk messages they received from the organization; recipients and senders have different opinions on which bulk messages were important; and communicators lack technology support to better target and design messages. In this position paper, first we review the prior work on evaluating, designing, and prototyping organizational communication systems. Second we review our recent findings and some research techniques we found useful in studying organizational communication. Last we propose a research agenda to study organizational communications in remote work environment and suggest some key questions and potential study directions.
    
[^4]: Drones4Good：通过遥感和人工智能支持救灾工作

    Drones4Good: Supporting Disaster Relief Through Remote Sensing and AI. (arXiv:2308.05074v1 [cs.CY])

    [http://arxiv.org/abs/2308.05074](http://arxiv.org/abs/2308.05074)

    通过结合无人机数据和深度学习方法，本研究展示了如何实现自动化和大规模情况评估，同时演示了机载图像处理技术在无人机救援投送中的集成，以实现快速、大规模图像分析和提高救援投送的安全性。

    

    为了能够有效地应对灾后情况，紧急服务和救援组织需要及时准确地获取受灾区域的信息。遥感技术有望通过快速勘察大范围区域来显著减少收集此类信息所需的时间和工作量。实现这一目标的主要挑战是从遥感数据中自动提取相关信息。在本研究中，我们展示了无人机数据与深度学习方法的结合如何实现自动化和大规模情况评估。此外，我们还展示了通过机载图像处理技术实现无人机自主投送救援物资的集成。结果显示，在现场进行快速和大规模图像分析是可行的，而机载图像处理可以提高无人机救援投送的安全性。

    In order to respond effectively in the aftermath of a disaster, emergency services and relief organizations rely on timely and accurate information about the affected areas. Remote sensing has the potential to significantly reduce the time and effort required to collect such information by enabling a rapid survey of large areas. To achieve this, the main challenge is the automatic extraction of relevant information from remotely sensed data. In this work, we show how the combination of drone-based data with deep learning methods enables automated and large-scale situation assessment. In addition, we demonstrate the integration of onboard image processing techniques for the deployment of autonomous drone-based aid delivery. The results show the feasibility of a rapid and large-scale image analysis in the field, and that onboard image processing can increase the safety of drone-based aid deliveries.
    
[^5]: AI中的竞赛--使用统计重采样稳定地排名求解器

    Competitions in AI -- Robustly Ranking Solvers Using Statistical Resampling. (arXiv:2308.05062v1 [cs.AI])

    [http://arxiv.org/abs/2308.05062](http://arxiv.org/abs/2308.05062)

    该论文研究了在AI领域中的求解器竞赛结果的泛化问题，通过使用统计重采样技术发现，竞赛结果的排名对基准实例集的微小变化非常敏感，因此不能期望这些排名能够适用于其他样本。因此引入了一种新的统计分析方法来解决这个问题。

    

    求解器竞赛在评估和推进解决AI和其他问题的最新技术方面起着重要作用。然而，我们在特定竞赛中观察到的结果能够推广到与基准实例集不同的问题集合吗？本研究使用统计重采样技术来探讨这个问题。我们发现，基于竞赛结果的标准解释所产生的排名对基准实例集的微小变化非常敏感，因此不能期望这些排名能够适用于同一基础实例分布的其他样本。为了解决这个问题，我们引入了一种新颖的统计分析竞赛结果的方法。

    Solver competitions play a prominent role in assessing and advancing the state of the art for solving many problems in AI and beyond. Notably, in many areas of AI, competitions have had substantial impact in guiding research and applications for many years, and for a solver to be ranked highly in a competition carries considerable weight. But to which extent can we expect competition results to generalise to sets of problem instances different from those used in a particular competition? This is the question we investigate here, using statistical resampling techniques. We show that the rankings resulting from the standard interpretation of competition results can be very sensitive to even minor changes in the benchmark instance set used as the basis for assessment and can therefore not be expected to carry over to other samples from the same underlying instance distribution. To address this problem, we introduce a novel approach to statistically meaningful analysis of competition resul
    
[^6]: 将任何你描述的事物分离

    Separate Anything You Describe. (arXiv:2308.05037v1 [eess.AS])

    [http://arxiv.org/abs/2308.05037](http://arxiv.org/abs/2308.05037)

    这项工作介绍了一种用于开放领域音频源分离的基础模型AudioSep，该模型使用自然语言查询，具有强大的分离性能和优秀的泛化能力。

    

    语言查询音频源分离（LASS）是计算听觉场景分析（CASA）中的一种新范 Paradigm。LASS旨在根据自然语言查询从音频混合物中分离目标声音，为数字音频应用提供了一种自然且可扩展的界面。尽管最近在LASS上取得了有希望的分离性能（例如，乐器，有限类别的音频事件），但仍然无法在开放域中分离音频概念。在这项工作中，我们引入了AudioSep，这是一种针对自然语言查询的开放领域音频源分离的基础模型。我们使用大规模多模态数据集训练AudioSep，并对其在许多任务上进行了广泛评估，包括音频事件分离，乐器分离和语音增强。AudioSep表现出强大的分离性能和令人印象深刻的零-shot泛化能力，使用音频标题或文字标签作为查询，明显优于其他方法。

    Language-queried audio source separation (LASS) is a new paradigm for computational auditory scene analysis (CASA). LASS aims to separate a target sound from an audio mixture given a natural language query, which provides a natural and scalable interface for digital audio applications. Recent works on LASS, despite attaining promising separation performance on specific sources (e.g., musical instruments, limited classes of audio events), are unable to separate audio concepts in the open domain. In this work, we introduce AudioSep, a foundation model for open-domain audio source separation with natural language queries. We train AudioSep on large-scale multimodal datasets and extensively evaluate its capabilities on numerous tasks including audio event separation, musical instrument separation, and speech enhancement. AudioSep demonstrates strong separation performance and impressive zero-shot generalization ability using audio captions or text labels as queries, substantially outperfor
    
[^7]: 专家负载很重要：以高准确性和低人工工作量运行网络

    Expert load matters: operating networks at high accuracy and low manual effort. (arXiv:2308.05035v1 [cs.AI])

    [http://arxiv.org/abs/2308.05035](http://arxiv.org/abs/2308.05035)

    在关键应用领域的人机协同系统中，为了确保最小错误，需要根据模型置信度设定操作点进行决策委托给专家。为了提高系统效用，需要考虑模型仅对准确样本具有自信的特点以及尽量减少委托给专家的样本数量。我们提出了置信度操作特性（COC）曲线来表示模型准确性与专家处理样本数量的权衡关系。这对于医疗保健等可用专家时间有限且昂贵的领域尤为关键。

    

    在人工智能与人类协同系统的关键应用中，为了确保最小错误，用户应根据模型的置信度设定操作点，确定何时将决策委托给人类专家。模型置信度低于操作点的样本将由专家手动分析，以避免错误。只有在考虑到两个方面的情况下，这样的系统才能真正有用：模型只对准确的样本具有自信，并且尽量减少委托给专家的样本数量。后者对于可用专家时间有限且昂贵的应用，如医疗保健，尤为关键。模型准确性与委托给专家样本数量之间的权衡可以用类似ROC曲线的曲线表示，我们称之为置信度操作特性（COC）曲线。在本文中，我们认为应该通过考虑到模型的置信度和专家处理的样本数量来训练深度神经网络。

    In human-AI collaboration systems for critical applications, in order to ensure minimal error, users should set an operating point based on model confidence to determine when the decision should be delegated to human experts. Samples for which model confidence is lower than the operating point would be manually analysed by experts to avoid mistakes. Such systems can become truly useful only if they consider two aspects: models should be confident only for samples for which they are accurate, and the number of samples delegated to experts should be minimized. The latter aspect is especially crucial for applications where available expert time is limited and expensive, such as healthcare. The trade-off between the model accuracy and the number of samples delegated to experts can be represented by a curve that is similar to an ROC curve, which we refer to as confidence operating characteristic (COC) curve. In this paper, we argue that deep neural networks should be trained by taking into 
    
[^8]: MetRoBERTa：利用传统的客户关系管理数据开发交通主题感知语言模型

    MetRoBERTa: Leveraging Traditional Customer Relationship Management Data to Develop a Transit-Topic-Aware Language Model. (arXiv:2308.05012v1 [cs.AI])

    [http://arxiv.org/abs/2308.05012](http://arxiv.org/abs/2308.05012)

    本文提出了一种利用传统交通CRM反馈开发和应用交通主题感知的大型语言模型，能够将开放性文本反馈分类到相关交通主题中。通过半监督学习方法构建训练数据集，并使用RoBERTa架构训练和评估语言模型。

    

    乘客在乘车调查、客户关系管理（CRM）渠道以及最近的社交媒体上提供的反馈是交通机构更好地评估其服务和计划有效性的关键。通过这些工具共享的反馈来获得对乘客体验的整体理解常常具有挑战性，主要是由于文本反馈的开放性和非结构化性质。在本文中，我们提出利用传统的交通CRM反馈来开发和应用能够将开放性文本反馈分类到相关的交通特定主题中的交通主题感知大语言模型（LLM）。首先，我们利用半监督学习在华盛顿都会区交通局（WMATA）的6年顾客反馈语料库中检测到的11个广泛交通主题构建一个训练数据集。然后，我们使用该数据集来训练并全面评估基于RoBERTa架构的语言模型。

    Transit riders' feedback provided in ridership surveys, customer relationship management (CRM) channels, and in more recent times, through social media is key for transit agencies to better gauge the efficacy of their services and initiatives. Getting a holistic understanding of riders' experience through the feedback shared in those instruments is often challenging, mostly due to the open-ended, unstructured nature of text feedback. In this paper, we propose leveraging traditional transit CRM feedback to develop and deploy a transit-topic-aware large language model (LLM) capable of classifying open-ended text feedback to relevant transit-specific topics. First, we utilize semi-supervised learning to engineer a training dataset of 11 broad transit topics detected in a corpus of 6 years of customer feedback provided to the Washington Metropolitan Area Transit Authority (WMATA). We then use this dataset to train and thoroughly evaluate a language model based on the RoBERTa architecture. 
    
[^9]: AspectMMKG: 一个具有方面意识的多模态知识图谱

    AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities. (arXiv:2308.04992v1 [cs.CL])

    [http://arxiv.org/abs/2308.04992](http://arxiv.org/abs/2308.04992)

    AspectMMKG是一个具有方面意识的多模态知识图谱，通过匹配图像和不同实体方面，它提供了从多个角度理解实体的能力，并在实体方面链接任务中取得了最先进的性能。

    

    多模态知识图谱（MMKG）结合不同的模态数据（例如文本和图像），以全面理解实体。尽管大规模MMKG的最近进展，但现有的MMKG忽视了实体的多方面性质，限制了从各种角度理解实体的能力。在本文中，我们构建了AspectMMKG，这是第一个具有与方面相关的图像的MMKG，通过将图像与不同的实体方面进行匹配。具体而言，我们从知识库中收集与方面相关的图像，并通过在线图像搜索引擎提取知识库中与方面相关的句子作为查询，以检索大量与方面相关的图像。最后，AspectMMKG包含2380个实体，18139个实体方面和645383个与方面相关的图像。我们展示了AspectMMKG在实体方面链接（EAL）下游任务中的可用性，并证明在AspectMMKG的帮助下，先前的EAL模型实现了新的最先进性能。

    Multi-modal knowledge graphs (MMKGs) combine different modal data (e.g., text and image) for a comprehensive understanding of entities. Despite the recent progress of large-scale MMKGs, existing MMKGs neglect the multi-aspect nature of entities, limiting the ability to comprehend entities from various perspectives. In this paper, we construct AspectMMKG, the first MMKG with aspect-related images by matching images to different entity aspects. Specifically, we collect aspect-related images from a knowledge base, and further extract aspect-related sentences from the knowledge base as queries to retrieve a large number of aspect-related images via an online image search engine. Finally, AspectMMKG contains 2,380 entities, 18,139 entity aspects, and 645,383 aspect-related images. We demonstrate the usability of AspectMMKG in entity aspect linking (EAL) downstream task and show that previous EAL models achieve a new state-of-the-art performance with the help of AspectMMKG. To facilitate the
    
[^10]: 探索多语言文本数据提炼

    Exploring Multilingual Text Data Distillation. (arXiv:2308.04982v1 [cs.CL])

    [http://arxiv.org/abs/2308.04982](http://arxiv.org/abs/2308.04982)

    本论文提出了基于语言模型的学习方法，用于多语言文本分类数据集的数据提炼。通过实验分析，我们发现这些方法在分类强度和跨架构泛化方面的性能良好，并考虑了数据摘要的语言特定公平性。

    

    随着深度学习的兴起，大规模数据集和复杂模型已经成为常见的需求，需要大量的计算资源。为了解决这个问题，数据提炼技术应运而生，能够用更低的内存和时间要求快速训练模型。然而，在文本数据集上进行数据提炼并没有得到很好的研究，因为其离散性带来了挑战。此外，现有的数据集提炼方法通常难以泛化到新的架构上。在这篇论文中，我们提出了几种基于语言模型的学习方法，用于多语言文本分类数据集的数据提炼。我们进行了实验，分析了其在分类强度和跨架构泛化方面的性能。此外，我们还研究了这些方法生成的数据摘要的语言特定公平性。我们的方法建立在现有技术的基础上，增强了文本数据提炼中的跨架构泛化能力。

    With the rise of deep learning, large datasets and complex models have become common, requiring significant computing power. To address this, data distillation has emerged as a technique to quickly train models with lower memory and time requirements. However, data distillation on text-based datasets hasn't been explored much because of the challenges rising due to its discrete nature. Additionally, existing dataset distillation methods often struggle to generalize to new architectures. In the paper, we propose several data distillation techniques for multilingual text classification datasets using language-model-based learning methods. We conduct experiments to analyze their performance in terms of classification strength, and cross-architecture generalization. Furthermore, we investigate the language-specific fairness of the data summaries generated by these methods. Our approach builds upon existing techniques, enhancing cross-architecture generalization in the text data distillatio
    
[^11]: 通过具有注意力网络的分布式强化学习改进自主分离保障

    Improving Autonomous Separation Assurance through Distributed Reinforcement Learning with Attention Networks. (arXiv:2308.04958v1 [cs.AI])

    [http://arxiv.org/abs/2308.04958](http://arxiv.org/abs/2308.04958)

    本文提出了一个分布式强化学习框架，利用速度和垂直机动手段，在高密度环境中实现了自主的自我分离能力，从而改进了自主分离保障技术。

    

    先进的空中移动（AAM）介绍了一种新的、高效的交通方式，利用车辆自主性和电动飞机，在之前未得到充分服务的市场之间提供越来越自主的交通。通过高密度环境中低空飞行器的安全和高效导航，需要整合大量复杂观测数据，如监视，车辆动力学知识和天气。在处理和推理这些观测数据时，面临着信息不确定性的多个来源的挑战，同时要确保与空域中可变数量的飞机合作。这些挑战加上需要实时做出安全关键决策的要求，使得传统的分离保障技术无法使用。我们提出了一个分布式强化学习框架，在AAM走廊内使用速度和垂直机动手段提供自主的自我分离能力。

    Advanced Air Mobility (AAM) introduces a new, efficient mode of transportation with the use of vehicle autonomy and electrified aircraft to provide increasingly autonomous transportation between previously underserved markets. Safe and efficient navigation of low altitude aircraft through highly dense environments requires the integration of a multitude of complex observations, such as surveillance, knowledge of vehicle dynamics, and weather. The processing and reasoning on these observations pose challenges due to the various sources of uncertainty in the information while ensuring cooperation with a variable number of aircraft in the airspace. These challenges coupled with the requirement to make safety-critical decisions in real-time rule out the use of conventional separation assurance techniques. We present a decentralized reinforcement learning framework to provide autonomous self-separation capabilities within AAM corridors with the use of speed and vertical maneuvers. The probl
    
[^12]: 无线供电联合学习网络：联合功率传输、数据感知、模型训练和资源分配

    Wirelessly Powered Federated Learning Networks: Joint Power Transfer, Data Sensing, Model Training, and Resource Allocation. (arXiv:2308.04953v1 [cs.NI])

    [http://arxiv.org/abs/2308.04953](http://arxiv.org/abs/2308.04953)

    本论文研究了无线供电联合学习网络中的资源分配问题，提出了一种实用的采集-感知-训练-传输协议，并通过联合优化功率传输、传输功率分配、数据感知和模型训练参数等方式来最小化总完成时间。

    

    联合学习（FL）在无线网络中取得了许多成功，然而，FL的实施受到移动设备（MDs）的能源限制和MDs上训练数据的可用性的限制。如何将无线能量传输和移动众包感知整合到可持续的FL解决方案中，是开放文献中完全缺失的研究课题。本文首次研究了协作感知辅助可持续FL（S2FL）网络中的资源分配问题，旨在最小化总完成时间。我们研究了一种实用的采集-感知-训练-传输协议，在这个协议中，能量有限的MDs首先从射频信号中收集能量，用来奖励用户参与，从环境中感知训练数据，在MDs上训练本地模型，并将模型更新传输给服务器。我们通过联合优化功率传输、传输功率分配、数据感知，以及模型训练参数等方式来最小化总完成时间。

    Federated learning (FL) has found many successes in wireless networks; however, the implementation of FL has been hindered by the energy limitation of mobile devices (MDs) and the availability of training data at MDs. How to integrate wireless power transfer and mobile crowdsensing towards sustainable FL solutions is a research topic entirely missing from the open literature. This work for the first time investigates a resource allocation problem in collaborative sensing-assisted sustainable FL (S2FL) networks with the goal of minimizing the total completion time. We investigate a practical harvesting-sensing-training-transmitting protocol in which energy-limited MDs first harvest energy from RF signals, use it to gain a reward for user participation, sense the training data from the environment, train the local models at MDs, and transmit the model updates to the server. The total completion time minimization problem of jointly optimizing power transfer, transmit power allocation, dat
    
[^13]: 泛化少样本语义分割中的典型核学习与开放集前景感知

    Prototypical Kernel Learning and Open-set Foreground Perception for Generalized Few-shot Semantic Segmentation. (arXiv:2308.04952v1 [cs.CV])

    [http://arxiv.org/abs/2308.04952](http://arxiv.org/abs/2308.04952)

    本研究通过典型核学习和开放集前景感知，解决泛化少样本语义分割中的表示分割和嵌入偏见问题，并且在分割过程中使用了可学习的核以及典型学习和前景上下文感知模块来提高性能。

    

    泛化少样本语义分割（GFSS）将少样本语义分割（FSS）扩展到评估过程中同时分割未见过的类别和已见过的类别。先前的研究利用额外的分支或典型聚合来消除FSS的约束设置。然而，表示分割和嵌入偏见，严重影响GFSS的性能，尚未综合考虑。我们通过联合典型核学习和开放集前景感知来解决上述问题。具体而言，我们提出了一组可学习的核来对每个类别进行分割。然后，我们将典型学习与基类核的更新相结合，这与少样本新类别的原型知识聚合相一致。此外，采用与条件偏差基于推理的前景上下文感知模块，用于执行与类别无关的分割。

    Generalized Few-shot Semantic Segmentation (GFSS) extends Few-shot Semantic Segmentation (FSS) to simultaneously segment unseen classes and seen classes during evaluation. Previous works leverage additional branch or prototypical aggregation to eliminate the constrained setting of FSS. However, representation division and embedding prejudice, which heavily results in poor performance of GFSS, have not been synthetical considered. We address the aforementioned problems by jointing the prototypical kernel learning and open-set foreground perception. Specifically, a group of learnable kernels is proposed to perform segmentation with each kernel in charge of a stuff class. Then, we explore to merge the prototypical learning to the update of base-class kernels, which is consistent with the prototype knowledge aggregation of few-shot novel classes. In addition, a foreground contextual perception module cooperating with conditional bias based inference is adopted to perform class-agnostic as 
    
[^14]: 获得和整合知识用于股票价格预测的方法：一项调查

    Methods for Acquiring and Incorporating Knowledge into Stock Price Prediction: A Survey. (arXiv:2308.04947v1 [q-fin.ST])

    [http://arxiv.org/abs/2308.04947](http://arxiv.org/abs/2308.04947)

    这项调查论文系统而全面地描述了从不同来源获得外部知识的方法，以应用于股票价格预测，帮助理解股票市场的复杂性。

    

    预测股票价格是一个具有挑战性的研究问题，因为股票市场的固有波动性和非线性性质。近年来，利用外部知识来理解股票市场的知识增强型股票价格预测方法表现出突破性的成果。尽管这些方法的重要性，但在从外部知识类型的角度系统地综合以往研究方面，学术作品的稀缺性存在一定问题。具体而言，外部知识可以以不同的数据结构建模，我们将其分为非图形化格式和图形化格式两类：1) 非图形化知识捕获与个别股票密切相关的上下文信息和多媒体描述；2) 图形化知识捕获股票市场中相互关联和相互依赖的信息。本调查论文旨在系统而全面地描述从不同来源获取外部知识的方法。

    Predicting stock prices presents a challenging research problem due to the inherent volatility and non-linear nature of the stock market. In recent years, knowledge-enhanced stock price prediction methods have shown groundbreaking results by utilizing external knowledge to understand the stock market. Despite the importance of these methods, there is a scarcity of scholarly works that systematically synthesize previous studies from the perspective of external knowledge types. Specifically, the external knowledge can be modeled in different data structures, which we group into non-graph-based formats and graph-based formats: 1) non-graph-based knowledge captures contextual information and multimedia descriptions specifically associated with an individual stock; 2) graph-based knowledge captures interconnected and interdependent information in the stock market. This survey paper aims to provide a systematic and comprehensive description of methods for acquiring external knowledge from va
    
[^15]: LLMeBench：用于加速LLMs基准测试的灵活框架

    LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking. (arXiv:2308.04945v1 [cs.CL])

    [http://arxiv.org/abs/2308.04945](http://arxiv.org/abs/2308.04945)

    LLMeBench是一个灵活的框架，用于加速LLMs基准测试。它可以定制任何NLP任务和模型，无论语言，支持零和少样本学习设置，并允许用户添加新的自定义数据集。已经在31个独特的NLP任务上进行了测试，并计划将框架开源。

    

    最近大型语言模型（LLMs）的发展和成功使得需要评估它们在不同语言的各种NLP任务中的性能。尽管已经开发并公开了几个框架，但对于不同用户来说，它们对特定任务和数据集的定制能力通常很复杂。在这项研究中，我们引入了LLMeBench框架。最初是为了使用OpenAI的GPT和BLOOM模型评估阿拉伯语NLP任务而开发的；它可以无缝定制任何NLP任务和模型，无论语言如何。该框架还具有零和少样本学习设置。可以在不到10分钟内添加新的自定义数据集，并且用户可以使用自己的模型API密钥来评估当前任务。该框架已经在90个实验设置中使用53个公开可用数据集对31个独特的NLP任务进行了测试，涉及大约296K个数据点。我们计划将该框架开源供社区使用。

    The recent development and success of Large Language Models (LLMs) necessitate an evaluation of their performance across diverse NLP tasks in different languages. Although several frameworks have been developed and made publicly available, their customization capabilities for specific tasks and datasets are often complex for different users. In this study, we introduce the LLMeBench framework. Initially developed to evaluate Arabic NLP tasks using OpenAI's GPT and BLOOM models; it can be seamlessly customized for any NLP task and model, regardless of language. The framework also features zero- and few-shot learning settings. A new custom dataset can be added in less than 10 minutes, and users can use their own model API keys to evaluate the task at hand. The developed framework has been already tested on 31 unique NLP tasks using 53 publicly available datasets within 90 experimental setups, involving approximately 296K data points. We plan to open-source the framework for the community
    
[^16]: 使用贪婪特征值分量选择的高斯图像异常检测

    Gaussian Image Anomaly Detection with Greedy Eigencomponent Selection. (arXiv:2308.04944v1 [cs.CV])

    [http://arxiv.org/abs/2308.04944](http://arxiv.org/abs/2308.04944)

    本文提出了一种使用预训练的卷积神经网络进行图像异常检测的新方法，通过贪婪策略的特征值分量选择，寻找最优子集以提高性能得分。

    

    图像中的异常检测是计算机视觉中的关键问题，可以识别与正常情况明显偏离的地方。本文介绍了一种新的降维方法，用于采用EfficientNet模型的预训练卷积神经网络（CNN）来进行异常检测。我们研究了特征值分量选择的重要性，并提出了两种采用贪婪策略的树搜索方法，用于选择最优的特征值分量。我们的研究通过三个主要的实验来评估我们方法的有效性。第一个实验探索了测试集性能对特征值分量选择的影响，第二个实验研究了当我们在一个异常类型上进行训练并在所有其他类型上进行评估时的性能，第三个实验调查了使用最少数量的图像进行训练并根据异常类型选择这些图像的影响。我们的方法旨在找到最优的分量子集，以实现最高的性能得分。

    Anomaly detection (AD) in images, identifying significant deviations from normality, is a critical issue in computer vision. This paper introduces a novel approach to dimensionality reduction for AD using pre-trained convolutional neural network (CNN) that incorporate EfficientNet models. We investigate the importance of component selection and propose two types of tree search approaches, both employing a greedy strategy, for optimal eigencomponent selection. Our study conducts three main experiments to evaluate the effectiveness of our approach. The first experiment explores the influence of test set performance on component choice, the second experiment examines the performance when we train on one anomaly type and evaluate on all other types, and the third experiment investigates the impact of using a minimum number of images for training and selecting them based on anomaly types. Our approach aims to find the optimal subset of components that deliver the highest performance score, 
    
[^17]: 人工智能生成内容的语义沟通对于有效的内容创造的影响

    Semantic Communications for Artificial Intelligence Generated Content (AIGC) Toward Effective Content Creation. (arXiv:2308.04942v1 [cs.NI])

    [http://arxiv.org/abs/2308.04942](http://arxiv.org/abs/2308.04942)

    本论文提出了一个综合概念模型，用于集成人工智能生成内容（AIGC）和语义沟通（SemCom），以产生有意义和效果的内容。同时，提出了一个采用AIGC技术作为编码器和解码器的框架，优化了语义提取和评估指标。实验验证了该方法的有效性。

    

    人工智能生成内容（AIGC）服务在数字内容创造领域有着巨大的潜力。AIGC的独特能力，如基于最小输入的内容生成，特别是在与语义沟通（SemCom）相结合时，具有巨大的潜力。本文提出了一个新的综合概念模型，用于AIGC和SemCom的集成。特别地，在语义层之上引入了一个内容生成层，清晰地概述了AIGC和SemCom如何相互作用以产生有意义和有效的内容。此外，提出了一个采用AIGC技术作为语义信息编码器和解码器的新框架，考虑到针对AIGC服务定制的语义提取和评估指标的联合优化。该框架可以适应不同类型的生成内容、所需的质量和所利用的语义信息。通过采用深度Q网络（DQN），对具体案例进行了实验验证。

    Artificial Intelligence Generated Content (AIGC) Services have significant potential in digital content creation. The distinctive abilities of AIGC, such as content generation based on minimal input, hold huge potential, especially when integrating with semantic communication (SemCom). In this paper, a novel comprehensive conceptual model for the integration of AIGC and SemCom is developed. Particularly, a content generation level is introduced on top of the semantic level that provides a clear outline of how AIGC and SemCom interact with each other to produce meaningful and effective content. Moreover, a novel framework that employs AIGC technology is proposed as an encoder and decoder for semantic information, considering the joint optimization of semantic extraction and evaluation metrics tailored to AIGC services. The framework can adapt to different types of content generated, the required quality, and the semantic information utilized. By employing a Deep Q Network (DQN), a case 
    
[^18]: 使用基于多智能体强化学习的反向传播方法进行通信学习的离散化方法的深入分析

    An In-Depth Analysis of Discretization Methods for Communication Learning using Backpropagation with Multi-Agent Reinforcement Learning. (arXiv:2308.04938v1 [cs.LG])

    [http://arxiv.org/abs/2308.04938](http://arxiv.org/abs/2308.04938)

    本文深入分析了使用基于多智能体强化学习的反向传播方法进行通信学习的离散化方法。研究比较了几种先进的离散化方法，并提出了一种新的方法。

    

    当智能体无法观察到完整的环境状态时，通信在多智能体强化学习中至关重要。允许智能体之间学习通信的常见方法是使用可微分的通信通道，以便梯度能够作为反馈流动。然而，当我们想要使用离散消息来减小消息的大小时，这会带来挑战，因为梯度不能通过离散的通信通道传播。以前的研究提出了处理这个问题的方法。然而，这些方法在不同的通信学习架构和环境中进行了测试，使得很难进行比较。在本文中，我们比较了几种最先进的离散化方法以及一种新的方法。我们在使用来自其他智能体的梯度进行通信学习的背景下进行了比较，并在多个环境中进行了测试。另外，我们介绍了COMA-DIAL，这是一种基于通信学习的方法。

    Communication is crucial in multi-agent reinforcement learning when agents are not able to observe the full state of the environment. The most common approach to allow learned communication between agents is the use of a differentiable communication channel that allows gradients to flow between agents as a form of feedback. However, this is challenging when we want to use discrete messages to reduce the message size, since gradients cannot flow through a discrete communication channel. Previous work proposed methods to deal with this problem. However, these methods are tested in different communication learning architectures and environments, making it hard to compare them. In this paper, we compare several state-of-the-art discretization methods as well as a novel approach. We do this comparison in the context of communication learning using gradients from other agents and perform tests on several environments. In addition, we present COMA-DIAL, a communication learning approach based
    
[^19]: 绿色Metaverses的服务预订和定价：一种Stackelberg博弈方法

    Service Reservation and Pricing for Green Metaverses: A Stackelberg Game Approach. (arXiv:2308.04914v1 [cs.AI])

    [http://arxiv.org/abs/2308.04914](http://arxiv.org/abs/2308.04914)

    本文研究了绿色Metaverse中的服务预订和定价问题，通过Stackelberg博弈方法解决了MSP和用户之间的经济冲突，实现了能效的服务提供。

    

    Metaverse通过数字化的虚拟角色使用户能够相互交流、合作和社交。由于时空特性，通过协同方式执行软件组件可以为共同定位的用户提供良好的服务，从而减少冗余的数据传输和处理，最终减少总能耗。能效的服务提供对于实现绿色和可持续的Metaverse至关重要。本文以增强现实（AR）应用程序为例来实现这个目标。此外，我们研究了一个经济问题，即用户如何预订MSP的卸载服务，以及MSP如何确定最优收费价格，因为每个用户都会根据货币成本来决定是否接受卸载服务。在MSP和用户之间建立了单主导多从属的Stackelberg博弈，而每个用户都在优化卸载服务时同时进行决策。

    Metaverse enables users to communicate, collaborate and socialize with each other through their digital avatars. Due to the spatio-temporal characteristics, co-located users are served well by performing their software components in a collaborative manner such that a Metaverse service provider (MSP) eliminates redundant data transmission and processing, ultimately reducing the total energy consumption. The energyefficient service provision is crucial for enabling the green and sustainable Metaverse. In this article, we take an augmented reality (AR) application as an example to achieve this goal. Moreover, we study an economic issue on how the users reserve offloading services from the MSP and how the MSP determines an optimal charging price since each user is rational to decide whether to accept the offloading service by taking into account the monetary cost. A single-leader multi-follower Stackelberg game is formulated between the MSP and users while each user optimizes an offloading
    
[^20]: LLaMA-E：多方面指导下的电子商务创作增强系统

    LLaMA-E: Empowering E-commerce Authoring with Multi-Aspect Instruction Following. (arXiv:2308.04913v1 [cs.CL])

    [http://arxiv.org/abs/2308.04913](http://arxiv.org/abs/2308.04913)

    LLaMA-E是一种统一且定制的指导语言模型，旨在解决电子商务创作过程中遇到的各种任务，包括广告生成、查询增强的产品标题改写、产品分类、购买意图推测和常规问答。

    

    电子商务创作涉及创建吸引人、丰富且有针对性的促销内容，以推动产品销售。大型语言模型（LLM）的出现引入了一种创新的范例，为解决这种情景中的各种创作任务提供了统一的解决方案。然而，基于通用语料库和常识知识训练的主流LLM在适应电子商务产品和客户独特的复杂和个性化特征方面存在局限性。此外，像GPT-3.5这样的LLM需要进行远程访问，引发了在传输过程中保护大量客户隐私数据的担忧。本文提出了LLaMA-E，针对多样化的电子商务创作任务的统一且定制的指导语言模型。具体而言，领域专家从广告生成、查询增强的产品标题改写、产品分类、购买意图推测和常规问答等任务中创建了种子指导集合。这些任务能够...

    E-commerce authoring involves creating attractive, abundant, and targeted promotional content to drive product sales. The emergence of large language models (LLMs) introduces an innovative paradigm, offering a unified solution to address various authoring tasks within this scenario. However, mainstream LLMs trained on general corpora with common sense knowledge reveal limitations in fitting complex and personalized features unique to e-commerce products and customers. Furthermore, LLMs like GPT-3.5 necessitate remote accessibility, raising concerns about safeguarding voluminous customer privacy data during transmission. This paper proposes the LLaMA-E, the unified and customized instruction-following language models focusing on diverse e-commerce authoring tasks. Specifically, the domain experts create the seed instruction set from the tasks of ads generation, query-enhanced product title rewriting, product classification, purchase intent speculation, and general Q&A. These tasks enabl
    
[^21]: SLPT：选择性标注与提示调整在有限标注的病变分割中的应用

    SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation. (arXiv:2308.04911v1 [cs.CV])

    [http://arxiv.org/abs/2308.04911](http://arxiv.org/abs/2308.04911)

    在有限标注数据的医学图像分析中存在困难，我们提出了一个新的框架SLPT，将选择性标注和提示调整相结合，以提高性能并减少标注成本。

    

    使用深度学习进行医学图像分析常常面临有限标注数据和高昂的标注成本的挑战。在有限标注的情况下对整个网络进行微调可能导致过拟合和性能不佳。最近，提示调整作为一种更有前景的技术出现，它向独立于任务的预训练模型引入了一些额外的可调参数作为提示，并仅使用有限的标注数据来更新这些参数，而保持预训练模型不变。然而，以前的研究忽视了选择性标注在下游任务中的重要性，它旨在选择最有价值的下游样本以实现最佳性能和最小的标注成本。为了解决这个问题，我们提出了一个将选择性标注与提示调整相结合的框架(SLPT)，以提升有限标签下的性能。具体地，我们引入了一个基于特征的提示更新器来引导提示调整，并使用TandEm Selective LAbeling方法。

    Medical image analysis using deep learning is often challenged by limited labeled data and high annotation costs. Fine-tuning the entire network in label-limited scenarios can lead to overfitting and suboptimal performance. Recently, prompt tuning has emerged as a more promising technique that introduces a few additional tunable parameters as prompts to a task-agnostic pre-trained model, and updates only these parameters using supervision from limited labeled data while keeping the pre-trained model unchanged. However, previous work has overlooked the importance of selective labeling in downstream tasks, which aims to select the most valuable downstream samples for annotation to achieve the best performance with minimum annotation cost. To address this, we propose a framework that combines selective labeling with prompt tuning (SLPT) to boost performance in limited labels. Specifically, we introduce a feature-aware prompt updater to guide prompt tuning and a TandEm Selective LAbeling (
    
[^22]: 软件定义网络中对抗性深度强化学习在网络安全中的应用

    Adversarial Deep Reinforcement Learning for Cyber Security in Software Defined Networks. (arXiv:2308.04909v1 [cs.CR])

    [http://arxiv.org/abs/2308.04909](http://arxiv.org/abs/2308.04909)

    本文研究了在软件定义网络中利用对抗性学习来训练更加鲁棒的深度强化学习智能体，探讨了两种算法的差异。攻击者利用因果攻击试图破坏学习过程。游戏中进行了有序的因果攻击。

    

    本文研究了在软件定义网络（Software Defined Networks，SDN）中，利用自主攻击方法在深度强化学习（Deep Reinforcement Learning，DRL）中训练更加鲁棒的智能体的影响，探讨了将对抗性学习应用于DRL的自主安全性。比较了两种算法：Double Deep Q-Networks（DDQN）和Neural Episodic Control to Deep Q-Network（NEC2DQN或N2D）。攻击者对环境具有完全的可见性，并且可以利用状态操作进行因果攻击，试图破坏学习过程。攻击实施在白盒环境中进行，攻击者可以访问防御者的模型和经验。进行了两轮游戏：第一轮游戏中，DDQN是防御者，N2D是攻击者；第二轮游戏中，角色互换。两轮游戏分别进行了两次，第一次没有主动的因果攻击，第二次进行了有序的因果攻击。

    This paper focuses on the impact of leveraging autonomous offensive approaches in Deep Reinforcement Learning (DRL) to train more robust agents by exploring the impact of applying adversarial learning to DRL for autonomous security in Software Defined Networks (SDN). Two algorithms, Double Deep Q-Networks (DDQN) and Neural Episodic Control to Deep Q-Network (NEC2DQN or N2D), are compared. NEC2DQN was proposed in 2018 and is a new member of the deep q-network (DQN) family of algorithms. The attacker has full observability of the environment and access to a causative attack that uses state manipulation in an attempt to poison the learning process. The implementation of the attack is done under a white-box setting, in which the attacker has access to the defender's model and experiences. Two games are played; in the first game, DDQN is a defender and N2D is an attacker, and in second game, the roles are reversed. The games are played twice; first, without an active causative attack and se
    
[^23]: GraphCC: 数据中心拥塞控制的实用图学习方法

    GraphCC: A Practical Graph Learning-based Approach to Congestion Control in Datacenters. (arXiv:2308.04905v1 [cs.NI])

    [http://arxiv.org/abs/2308.04905](http://arxiv.org/abs/2308.04905)

    本论文提出了一种名为GraphCC的实用图学习方法，用于优化数据中心的拥塞控制。通过结合多智能体强化学习（MARL）和图神经网络，该方法能够适应快速和突然的网络状态变化，并提高网络的性能。

    

    拥塞控制（CC）在优化数据中心网络（DCN）中的流量方面起着基础作用。目前，DCN主要实现了两种主要的CC协议：DCTCP和DCQCN。这两个协议及其主要变体都基于显式拥塞通知（ECN），其中中间交换机在检测到拥塞时标记数据包。ECN配置因此成为CC协议性能的关键因素。现在，网络专家设定静态ECN参数，精心选择以优化网络的平均性能。然而，现今的高速DCN经历快速和突然的变化，严重改变了网络状态（例如，动态流量工作负载，incast事件，故障）。这导致了低效利用和次优性能。本文提出了一种名为GraphCC的新颖的基于机器学习的网络内CC优化框架。我们的分布式解决方案依赖于多智能体强化学习（MARL）和图神经网络。

    Congestion Control (CC) plays a fundamental role in optimizing traffic in Data Center Networks (DCN). Currently, DCNs mainly implement two main CC protocols: DCTCP and DCQCN. Both protocols -- and their main variants -- are based on Explicit Congestion Notification (ECN), where intermediate switches mark packets when they detect congestion. The ECN configuration is thus a crucial aspect on the performance of CC protocols. Nowadays, network experts set static ECN parameters carefully selected to optimize the average network performance. However, today's high-speed DCNs experience quick and abrupt changes that severely change the network state (e.g., dynamic traffic workloads, incast events, failures). This leads to under-utilization and sub-optimal performance. This paper presents GraphCC, a novel Machine Learning-based framework for in-network CC optimization. Our distributed solution relies on a novel combination of Multi-agent Reinforcement Learning (MARL) and Graph Neural Networks (
    
[^24]: NLLG季度arXiv报告 06/23：当前最具影响力的AI论文是什么？（arXiv:2308.04889v1 [cs.CY]）

    NLLG Quarterly arXiv Report 06/23: What are the most influential current AI Papers?. (arXiv:2308.04889v1 [cs.CY])

    [http://arxiv.org/abs/2308.04889](http://arxiv.org/abs/2308.04889)

    该报告关注当前最具影响力的AI论文，并以标准化引用计数为依据编制了40篇最受欢迎的论文列表。观察到在2023年上半年，大型语言模型（LLMs）和具体而言的ChatGPT相关的论文占主导地位，ChatGPT表现出下降的趋势。

    

    人工智能（AI）领域中的生成式人工智能（Generative Artificial Intelligence，特别是自然语言处理（Natural Language Processing，NLP）和机器学习（Machine Learning，ML））信息的快速增长给研究人员和从业者带来了巨大的挑战，使得他们难以跟上最新的发展。为了解决信息过载的问题，Bielefeld大学的自然语言学习组在本报告中专注于识别arXiv上最受欢迎的论文，特别关注NLP和ML。其目标是为最相关且被广泛讨论的研究提供快速指南，以帮助新来者和已有研究人员跟上当前趋势。具体而言，我们根据2023年上半年的标准化引用计数编制了一个由40篇最受欢迎的论文组成的列表。我们观察到在2023年上半年，与大型语言模型（Large Language Models，LLMs）和具体而言的ChatGPT相关的论文占主导地位，而ChatGPT显示出下降的趋势。

    The rapid growth of information in the field of Generative Artificial Intelligence (AI), particularly in the subfields of Natural Language Processing (NLP) and Machine Learning (ML), presents a significant challenge for researchers and practitioners to keep pace with the latest developments. To address the problem of information overload, this report by the Natural Language Learning Group at Bielefeld University focuses on identifying the most popular papers on arXiv, with a specific emphasis on NLP and ML. The objective is to offer a quick guide to the most relevant and widely discussed research, aiding both newcomers and established researchers in staying abreast of current trends. In particular, we compile a list of the 40 most popular papers based on normalized citation counts from the first half of 2023. We observe the dominance of papers related to Large Language Models (LLMs) and specifically ChatGPT during the first half of 2023, with the latter showing signs of declining popul
    
[^25]: 学习通用型符号规划的动作

    Learning Type-Generalized Actions for Symbolic Planning. (arXiv:2308.04867v1 [cs.AI])

    [http://arxiv.org/abs/2308.04867](http://arxiv.org/abs/2308.04867)

    本文提出了一种学习通用型符号规划动作的新方法，通过给定实体层次结构和观察到的相似行为来实现通用化。在模拟的厨房环境中验证了该方法的有效性。

    

    符号规划是一种强大的技术，用于解决需要长序列动作并装备智能体具有复杂行为的复杂任务。这种方法的缺点是需要合适的符号表示来描述环境的状态以及能够改变状态的动作。传统上，这些表示是由专家为不同的问题域精心设计的，这限制了它们在不同问题和环境复杂性上的可转移性。在这篇论文中，我们提出了一种新的概念，使用给定的实体层次结构和观察到的相似行为来通用化符号动作。在一个模拟的基于网格的厨房环境中，我们展示了从少量观察中学习到的通用型动作能够泛化到新的情况。在规划过程中引入额外的即时通用化机制，可以处理未见过的任务组合、较长序列、新实体和意外环境行为。

    Symbolic planning is a powerful technique to solve complex tasks that require long sequences of actions and can equip an intelligent agent with complex behavior. The downside of this approach is the necessity for suitable symbolic representations describing the state of the environment as well as the actions that can change it. Traditionally such representations are carefully hand-designed by experts for distinct problem domains, which limits their transferability to different problems and environment complexities. In this paper, we propose a novel concept to generalize symbolic actions using a given entity hierarchy and observed similar behavior. In a simulated grid-based kitchen environment, we show that type-generalized actions can be learned from few observations and generalize to novel situations. Incorporating an additional on-the-fly generalization mechanism during planning, unseen task combinations, involving longer sequences, novel entities and unexpected environment behavior,
    
[^26]: 使用多智能体强化学习学习连续通信的消息编码技术的可扩展性

    Scalability of Message Encoding Techniques for Continuous Communication Learned with Multi-Agent Reinforcement Learning. (arXiv:2308.04844v1 [cs.LG])

    [http://arxiv.org/abs/2308.04844](http://arxiv.org/abs/2308.04844)

    本论文使用多智能体强化学习研究了在增加消息中包含的信息量和智能体数量增加的情况下，采用不同的消息编码方法对系统性能的影响。结果表明，均值消息编码器比注意力消息编码器更优，在智能体之间的通信协议中起到关键作用。

    

    许多多智能体系统需要智能体之间的通信以确保正确实现其目标。通过使用多智能体强化学习技术学习通信协议和动作协议，智能体可以灵活决定应该共享哪些信息。然而，当智能体数量增加时，我们需要创建包含在这些消息中的信息的编码方式。在本文中，我们研究了增加消息中应包含的信息量和增加智能体数量对两种不同消息编码方法（均值消息编码器和注意力消息编码器）的影响，并在一个矩阵环境中对这些影响进行了评估。令人惊讶的是，我们的结果表明，均值消息编码器始终优于注意力消息编码器。因此，我们分析了使用均值消息编码器的智能体使用的通信协议，并得出以下结论：

    Many multi-agent systems require inter-agent communication to properly achieve their goal. By learning the communication protocol alongside the action protocol using multi-agent reinforcement learning techniques, the agents gain the flexibility to determine which information should be shared. However, when the number of agents increases we need to create an encoding of the information contained in these messages. In this paper, we investigate the effect of increasing the amount of information that should be contained in a message and increasing the number of agents. We evaluate these effects on two different message encoding methods, the mean message encoder and the attention message encoder. We perform our experiments on a matrix environment. Surprisingly, our results show that the mean message encoder consistently outperforms the attention message encoder. Therefore, we analyse the communication protocol used by the agents that use the mean message encoder and can conclude that the a
    
[^27]: 神经符号化RDF和描述逻辑推理机：现状与挑战

    Neuro-Symbolic RDF and Description Logic Reasoners: The State-Of-The-Art and Challenges. (arXiv:2308.04814v1 [cs.AI])

    [http://arxiv.org/abs/2308.04814](http://arxiv.org/abs/2308.04814)

    本文概述了神经符号化RDF和描述逻辑推理机的现状和挑战，并介绍了神经符号化推理在RDF(S)、EL和ALC描述逻辑以及OWL 2 RL领域的已有研究文献。

    

    本文介绍了神经符号化RDF和描述逻辑推理机的现状和挑战。随着本体论的不断发展，RDF和OWL成为本体开发的重要标准。虽然RDF简单灵活，OWL能够详细表示领域知识，但随着本体的扩大和表达的增加，推理复杂度增加，传统推理机的效率受到挑战。针对这些挑战，研究人员提出了神经符号化方法，结合神经网络的学习能力和符号系统的推理能力。本文概述了神经符号化推理在RDF(S)、EL和ALC描述逻辑以及OWL 2 RL领域的已有研究文献。

    Ontologies are used in various domains, with RDF and OWL being prominent standards for ontology development. RDF is favored for its simplicity and flexibility, while OWL enables detailed domain knowledge representation. However, as ontologies grow larger and more expressive, reasoning complexity increases, and traditional reasoners struggle to perform efficiently. Despite optimization efforts, scalability remains an issue. Additionally, advancements in automated knowledge base construction have created large and expressive ontologies that are often noisy and inconsistent, posing further challenges for conventional reasoners. To address these challenges, researchers have explored neuro-symbolic approaches that combine neural networks' learning capabilities with symbolic systems' reasoning abilities. In this chapter,we provide an overview of the existing literature in the field of neuro-symbolic deductive reasoning supported by RDF(S), the description logics EL and ALC, and OWL 2 RL, dis
    
[^28]: 快速和最优的基于学习的行星探测车路径规划方法

    A Fast and Optimal Learning-based Path Planning Method for Planetary Rovers. (arXiv:2308.04792v1 [cs.RO])

    [http://arxiv.org/abs/2308.04792](http://arxiv.org/abs/2308.04792)

    本文提出了一种基于学习的快速路径规划方法，通过学习最优路径示范中的语义信息和地图表示，生成概率分布来搜索最优路径。实验结果表明，该方法能够提高行星探测车的探索效率。

    

    智能自主路径规划对于提高行星探测车的探索效率至关重要。在本文中，我们提出了一种基于学习的方法，在高程图中快速搜索最优路径，称为NNPP。NNPP模型从大量预注释的最优路径示范中学习起始和目标位置的语义信息，以及地图表示，并生成每个像素的概率分布，表示其属于地图上最优路径的可能性。具体而言，本文从DEM获取的坡度、粗糙度和高度差计算每个网格单元的遍历成本。随后，使用高斯分布对起始和目标位置进行编码，并分析不同位置编码参数对模型性能的影响。经过训练，NNPP模型能够在新的地图上执行路径规划。实验证明，NNPP生成的引导场能够准确指导行星探测车的运动。

    Intelligent autonomous path planning is crucial to improve the exploration efficiency of planetary rovers. In this paper, we propose a learning-based method to quickly search for optimal paths in an elevation map, which is called NNPP. The NNPP model learns semantic information about start and goal locations, as well as map representations, from numerous pre-annotated optimal path demonstrations, and produces a probabilistic distribution over each pixel representing the likelihood of it belonging to an optimal path on the map. More specifically, the paper computes the traversal cost for each grid cell from the slope, roughness and elevation difference obtained from the DEM. Subsequently, the start and goal locations are encoded using a Gaussian distribution and different location encoding parameters are analyzed for their effect on model performance. After training, the NNPP model is able to perform path planning on novel maps. Experiments show that the guidance field generated by the 
    
[^29]: 基于3D地下雷达的路基损坏检测的多视角融合与蒸馏

    Multi-View Fusion and Distillation for Subgrade Distresses Detection based on 3D-GPR. (arXiv:2308.04779v1 [cs.CV])

    [http://arxiv.org/abs/2308.04779](http://arxiv.org/abs/2308.04779)

    该论文提出了一种基于多视角融合和蒸馏的方法，用于基于3D地下雷达的路基损坏检测任务。通过利用多视角信息和构建真实多视角图像数据集，提高了检测效率和准确性，同时降低了计算复杂性。

    

    3D地下雷达（3D-GPR）在路基损坏检测中的应用已经广泛流行起来。为了提高检测的效率和准确性，先导性研究尝试采用自动检测技术，特别是深度学习。然而，现有的工作通常依赖于传统的1D A扫描、2D B扫描或3D C扫描数据，导致空间信息不足或计算复杂度高。为了解决这些挑战，我们引入了一种新的方法来处理3D-GPR数据的路基损坏检测任务，利用多视角信息。此外，我们还构建了一个由原始3D-GPR数据导出的真实多视角图像数据集，用于检测任务，相比A扫描和B扫描数据，该数据集提供了更丰富的空间信息，同时降低了与C扫描数据相比的计算复杂性。随后，我们开发了一种新的多视角融合和蒸馏框架

    The application of 3D ground-penetrating radar (3D-GPR) for subgrade distress detection has gained widespread popularity. To enhance the efficiency and accuracy of detection, pioneering studies have attempted to adopt automatic detection techniques, particularly deep learning. However, existing works typically rely on traditional 1D A-scan, 2D B-scan or 3D C-scan data of the GPR, resulting in either insufficient spatial information or high computational complexity. To address these challenges, we introduce a novel methodology for the subgrade distress detection task by leveraging the multi-view information from 3D-GPR data. Moreover, we construct a real multi-view image dataset derived from the original 3D-GPR data for the detection task, which provides richer spatial information compared to A-scan and B-scan data, while reducing computational complexity compared to C-scan data. Subsequently, we develop a novel \textbf{M}ulti-\textbf{V}iew \textbf{V}usion and \textbf{D}istillation fram
    
[^30]: 基于非负矩阵分解的多模态多视图聚类

    Multi-modal Multi-view Clustering based on Non-negative Matrix Factorization. (arXiv:2308.04778v1 [cs.AI])

    [http://arxiv.org/abs/2308.04778](http://arxiv.org/abs/2308.04778)

    本文提出了一种基于非负矩阵分解的多模态多视图聚类方法，通过协作多个本地NMF模型，揭示了数据集中的潜在模式，并在多个应用领域取得了良好的实验结果。

    

    通过将相关对象组合起来，无监督的机器学习技术旨在揭示数据集中的潜在模式。非负矩阵分解（NMF）是一种数据挖掘技术，通过对元素非负性施加限制，将数据矩阵分解为两个矩阵：一个表示数据分区，另一个表示数据集的聚类原型。该方法受到了广泛关注，并在文本挖掘、聚类、语言建模、音乐转录和神经科学（基因分离）等多个应用领域中得到了应用。生成矩阵的解释由于不存在负值而变得更简单。在本文中，我们提出了一项关于多模态聚类算法的研究，并提出了一种新颖的方法，称为多模态多视图非负矩阵分解，其中我们分析了多个本地NMF模型的协作。实验结果显示了所提方法的价值。

    By combining related objects, unsupervised machine learning techniques aim to reveal the underlying patterns in a data set. Non-negative Matrix Factorization (NMF) is a data mining technique that splits data matrices by imposing restrictions on the elements' non-negativity into two matrices: one representing the data partitions and the other to represent the cluster prototypes of the data set. This method has attracted a lot of attention and is used in a wide range of applications, including text mining, clustering, language modeling, music transcription, and neuroscience (gene separation). The interpretation of the generated matrices is made simpler by the absence of negative values. In this article, we propose a study on multi-modal clustering algorithms and present a novel method called multi-modal multi-view non-negative matrix factorization, in which we analyze the collaboration of several local NMF models. The experimental results show the value of the proposed approach, which wa
    
[^31]: E3-UAV:一种面向边缘的能量高效无人机目标检测系统

    E3-UAV: An Edge-based Energy-Efficient Object Detection System for Unmanned Aerial Vehicles. (arXiv:2308.04774v1 [cs.RO])

    [http://arxiv.org/abs/2308.04774](http://arxiv.org/abs/2308.04774)

    E3-UAV是一种面向边缘的能量高效无人机目标检测系统，通过动态调整飞行参数和检测算法，最大程度地减少能量消耗。

    

    随着深度学习技术的进步，基于无人机的目标检测在车辆计数、火灾检测和城市监测等领域得到了广泛应用。然而，现有研究大多只关注无人机目标检测中某些挑战的子集，缺乏在各个方面平衡来设计一个实际能量消耗降低的系统。为解决这个问题，本文提出了一种面向边缘的能量高效无人机目标检测系统E3-UAV。该系统通过决定满足任务检测要求的最节能飞行参数（包括飞行高度、飞行速度、检测算法和采样率），从而动态支持各种无人机设备、边缘设备和检测算法，以最大程度地减少能量消耗。我们首先提出了一个有效的评估指标来评估实际任务，并构建了一个透明的...

    Motivated by the advances in deep learning techniques, the application of Unmanned Aerial Vehicle (UAV)-based object detection has proliferated across a range of fields, including vehicle counting, fire detection, and city monitoring. While most existing research studies only a subset of the challenges inherent to UAV-based object detection, there are few studies that balance various aspects to design a practical system for energy consumption reduction. In response, we present the E3-UAV, an edge-based energy-efficient object detection system for UAVs. The system is designed to dynamically support various UAV devices, edge devices, and detection algorithms, with the aim of minimizing energy consumption by deciding the most energy-efficient flight parameters (including flight altitude, flight speed, detection algorithm, and sampling rate) required to fulfill the detection requirements of the task. We first present an effective evaluation metric for actual tasks and construct a transpare
    
[^32]: Induction Network:自监督音源定位的视听模态差距补偿

    Induction Network: Audio-Visual Modality Gap-Bridging for Self-Supervised Sound Source Localization. (arXiv:2308.04767v1 [cs.CV])

    [http://arxiv.org/abs/2308.04767](http://arxiv.org/abs/2308.04767)

    本研究提出了一种Induction Network来解决自监督音源定位中的视听模态差距问题。通过解耦梯度并引入自举学习，使声源的判别性视觉表示能够与音频模态保持一致。还引入了自适应阈值选择策略来增强其引导能力的鲁棒性。

    

    自监督音源定位通常受到模态不一致的挑战。在最近的研究中，基于对比学习的策略已经显示出在视觉场景中建立音频和声源之间一致对应的良好前景。然而，对于不同模态特征中的异质性影响，这个方案的关注度不足仍然限制了进一步的改进，这也成为我们工作的动机。在这项研究中，提出了一种Induction Network来更有效地弥合模态差距。通过解耦视觉和音频模态的梯度，可以以引导向量设计的自举方式学习声源的判别性视觉表示，这也使音频模态能够与视觉模态保持一致。除了视觉加权对比损失外，还引入了自适应阈值选择策略来增强引导能力的鲁棒性。

    Self-supervised sound source localization is usually challenged by the modality inconsistency. In recent studies, contrastive learning based strategies have shown promising to establish such a consistent correspondence between audio and sound sources in visual scenarios. Unfortunately, the insufficient attention to the heterogeneity influence in the different modality features still limits this scheme to be further improved, which also becomes the motivation of our work. In this study, an Induction Network is proposed to bridge the modality gap more effectively. By decoupling the gradients of visual and audio modalities, the discriminative visual representations of sound sources can be learned with the designed Induction Vector in a bootstrap manner, which also enables the audio modality to be aligned with the visual modality consistently. In addition to a visual weighted contrastive loss, an adaptive threshold selection strategy is introduced to enhance the robustness of the Induction
    
[^33]: 非独立同分布联邦学习的特征匹配数据合成

    Feature Matching Data Synthesis for Non-IID Federated Learning. (arXiv:2308.04761v1 [cs.LG])

    [http://arxiv.org/abs/2308.04761](http://arxiv.org/abs/2308.04761)

    本文提出了一种用于非独立同分布联邦学习的特征匹配数据合成方法，通过生成合成数据来解决联邦学习中的非独立同分布问题，并提出了一种隐私保护的特征增强方法。这种方法能够改善模型的泛化能力并抹去真实特征的信息。

    

    联邦学习是一种隐私保护的范式，它在边缘设备上训练神经网络而不在中央服务器上收集数据。然而，联邦学习在处理设备之间的非独立同分布（non-IID）数据方面面临着固有的挑战。为了解决这个挑战，本文提出了一种硬特征匹配数据合成（HFMDS）方法，除了本地模型外，还共享辅助数据。具体而言，通过学习真实样本的基本类相关特征并丢弃多余的特征，生成了合成数据，这有助于有效处理非独立同分布问题。为了更好地保护隐私，我们提出了一种硬特征增强方法，将真实特征转移到决策边界附近，从而合成数据不仅改善了模型的泛化能力，而且抹去了真实特征的信息。通过将提出的HFMDS方法与联邦学习相结合，我们提出了一种新的联邦学习框架，其中包含数据增强的方法。

    Federated learning (FL) has emerged as a privacy-preserving paradigm that trains neural networks on edge devices without collecting data at a central server. However, FL encounters an inherent challenge in dealing with non-independent and identically distributed (non-IID) data among devices. To address this challenge, this paper proposes a hard feature matching data synthesis (HFMDS) method to share auxiliary data besides local models. Specifically, synthetic data are generated by learning the essential class-relevant features of real samples and discarding the redundant features, which helps to effectively tackle the non-IID issue. For better privacy preservation, we propose a hard feature augmentation method to transfer real features towards the decision boundary, with which the synthetic data not only improve the model generalization but also erase the information of real features. By integrating the proposed HFMDS method with FL, we present a novel FL framework with data augmentati
    
[^34]: 无伦理的自动驾驶：意义、设计和现实世界应用

    Automated Driving Without Ethics: Meaning, Design and Real-World Implementation. (arXiv:2308.04760v1 [cs.AI])

    [http://arxiv.org/abs/2308.04760](http://arxiv.org/abs/2308.04760)

    本研究提出了一种自动驾驶决策制定策略，使用预定义参数来评估可能发生事故的风险，并集成伦理倾向理论，以适应不同环境和决策背景。该方法旨在提供一种灵活的计算方法，而不是定义车辆行为的道德要求。

    

    自动驾驶车辆（AV）的道德问题近年来受到了很多关注，特别是在涉及到人类伤害的事故情况下的决策政策方面。在讨论“人工道德代理”一词是否适用于描述能够做出这些决策的AV之后，并基于一种假设，即在某些情况下无法避免人类伤害，提出了一种AV决策制定策略，只使用预定义的参数来表征可能发生事故的风险，并将伦理倾向理论纳入多种可能的决策规则中，以确定在特定环境和决策背景下最合适的行动。这种方法的目标不是定义道德理论要求车辆如何行为，而是提供一种灵活的计算方法，能够适应各种情况。

    The ethics of automated vehicles (AV) has received a great amount of attention in recent years, specifically in regard to their decisional policies in accident situations in which human harm is a likely consequence. After a discussion about the pertinence and cogency of the term 'artificial moral agent' to describe AVs that would accomplish these sorts of decisions, and starting from the assumption that human harm is unavoidable in some situations, a strategy for AV decision making is proposed using only pre-defined parameters to characterize the risk of possible accidents and also integrating the Ethical Valence Theory, which paints AV decision-making as a type of claim mitigation, into multiple possible decision rules to determine the most suitable action given the specific environment and decision context. The goal of this approach is not to define how moral theory requires vehicles to behave, but rather to provide a computational approach that is flexible enough to accommodate a nu
    
[^35]: 鸟瞰场景图用于视觉语言导航

    Bird's-Eye-View Scene Graph for Vision-Language Navigation. (arXiv:2308.04758v1 [cs.CV])

    [http://arxiv.org/abs/2308.04758](http://arxiv.org/abs/2308.04758)

    这项研究提出了一种鸟瞰场景图（BSG）用于视觉语言导航，通过使用多步鸟瞰表示来编码场景布局和几何线索，从而改进了当前全景观察的导航代理的能力，并提供了更准确的动作预测。

    

    视觉语言导航（VLN）需要一个代理根据人类指示在3D环境中导航，已经取得了显著的进展。然而，当前的代理基于全景观察构建，这限制了它们感知3D场景几何和容易导致全景视图的模糊选择能力。为了解决这些限制，我们提出了一种鸟瞰场景图（BSG），它利用多步鸟瞰表示来编码室内环境的场景布局和几何线索，在3D检测的监督下。在导航过程中，BSG在每个步骤构建一个本地鸟瞰表示，并维护一个基于鸟瞰的全局场景地图，根据它们的拓扑关系存储和组织所有在线收集的本地鸟瞰表示。基于BSG，代理预测本地鸟瞰网格级决策得分和全局图形级决策得分，结合全景视图的子视图选择得分，以实现更准确的动作预测。我们的方法

    Vision-language navigation (VLN), which entails an agent to navigate 3D environments following human instructions, has shown great advances. However, current agents are built upon panoramic observations, which hinders their ability to perceive 3D scene geometry and easily leads to ambiguous selection of panoramic view. To address these limitations, we present a BEV Scene Graph (BSG), which leverages multi-step BEV representations to encode scene layouts and geometric cues of indoor environment under the supervision of 3D detection. During navigation, BSG builds a local BEV representation at each step and maintains a BEV-based global scene map, which stores and organizes all the online collected local BEV representations according to their topological relations. Based on BSG, the agent predicts a local BEV grid-level decision score and a global graph-level decision score, combined with a sub-view selection score on panoramic views, for more accurate action prediction. Our approach signi
    
[^36]: 提升带有动态结构发展的脉冲神经网络的高效连续学习

    Enhancing Efficient Continual Learning with Dynamic Structure Development of Spiking Neural Networks. (arXiv:2308.04749v1 [cs.AI])

    [http://arxiv.org/abs/2308.04749](http://arxiv.org/abs/2308.04749)

    使用动态结构发展的脉冲神经网络来实现高效连续学习，通过动态增长和修剪神经元来提高记忆容量和减少计算开销，同时利用重叠的共享结构快速应用已获得的知识到新任务上。

    

    孩童具备顺序学习多个认知任务的能力，这对于实现人工通用智能的长远目标是一个重要挑战。现有的连续学习框架通常适用于深度神经网络（DNNs），但对更加脑启发、能效更高的脉冲神经网络（SNNs）缺乏探索。借鉴孩童成长和发展过程中的连续学习机制，我们提出了动态结构发展的脉冲神经网络（DSD-SNN），用于高效和自适应的连续学习。在学习一系列任务时，DSD-SNN会动态地分配并增长新的神经元来处理新任务，并修剪多余的神经元，从而增加记忆容量并减少计算开销。此外，重叠的共享结构有助于快速将所有已获得的知识应用到新任务上，使单个网络能够支持多个增量任务（而无需为每个任务单独创建子网络的掩码）。

    Children possess the ability to learn multiple cognitive tasks sequentially, which is a major challenge toward the long-term goal of artificial general intelligence. Existing continual learning frameworks are usually applicable to Deep Neural Networks (DNNs) and lack the exploration on more brain-inspired, energy-efficient Spiking Neural Networks (SNNs). Drawing on continual learning mechanisms during child growth and development, we propose Dynamic Structure Development of Spiking Neural Networks (DSD-SNN) for efficient and adaptive continual learning. When learning a sequence of tasks, the DSD-SNN dynamically assigns and grows new neurons to new tasks and prunes redundant neurons, thereby increasing memory capacity and reducing computational overhead. In addition, the overlapping shared structure helps to quickly leverage all acquired knowledge to new tasks, empowering a single network capable of supporting multiple incremental tasks (without the separate sub-network mask for each ta
    
[^37]: 案例研究：在移动团队中使用AI辅助代码生成

    Case Study: Using AI-Assisted Code Generation In Mobile Teams. (arXiv:2308.04736v1 [cs.SE])

    [http://arxiv.org/abs/2308.04736](http://arxiv.org/abs/2308.04736)

    本研究通过案例研究评估了在专注于移动开发的团队中使用AI辅助代码生成的性能。通过对参与者进行技术入职和技术堆栈切换阶段的问题求解，评估了使用和不使用AI-Code生成器的影响。研究结合了时间、正确性和技术集成等度量指标，并分析了参与者的反馈，以确定使用AI辅助编程工具是否对开发人员产生影响。

    

    本研究旨在评估在专注于Kotlin和Swift等原生移动语言的实际移动开发团队中使用AI辅助编程的性能。这个广泛的案例研究涉及16名参与者和2名技术评审人员，来自一个软件开发部门，旨在了解在团队的特定阶段中使用针对代码生成进行训练的LLMs的影响，更具体地说是技术入职和技术堆栈切换。研究使用针对每个阶段的技术问题，并要求参与者使用和不使用AI-Code生成器提供解决方案。它通过ReviewerScore这一特定于本论文的度量标准，以及从实际行业标准（合并请求的代码评审人员）中提取的度量时间、正确性和技术集成。输出与参与者的反馈一起转换和分析，以确定使用AI辅助编程工具是否对获得开发人员有影响。

    The aim of this study is to evaluate the performance of AI-assisted programming in actual mobile development teams that are focused on native mobile languages like Kotlin and Swift. The extensive case study involves 16 participants and 2 technical reviewers, from a software development department designed to understand the impact of using LLMs trained for code generation in specific phases of the team, more specifically, technical onboarding and technical stack switch. The study uses technical problems dedicated to each phase and requests solutions from the participants with and without using AI-Code generators. It measures time, correctness, and technical integration using ReviewerScore, a metric specific to the paper and extracted from actual industry standards, the code reviewers of merge requests. The output is converted and analyzed together with feedback from the participants in an attempt to determine if using AI-assisted programming tools will have an impact on getting develope
    
[^38]: JEN-1：具有全向扩散模型的文本引导通用音乐生成

    JEN-1: Text-Guided Universal Music Generation with Omnidirectional Diffusion Models. (arXiv:2308.04729v1 [cs.SD])

    [http://arxiv.org/abs/2308.04729](http://arxiv.org/abs/2308.04729)

    JEN-1是一个高保真度通用音乐生成模型，通过结合自回归和非自回归训练，实现了文本引导的音乐生成、音乐修补和延续等生成任务，在文本音乐对齐和音乐质量方面表现出优越性，同时保持计算效率。

    

    随着深度生成模型的进步，音乐生成引起了越来越多的关注。然而，基于文本描述生成音乐（即文本到音乐）仍然具有挑战性，原因是音乐结构的复杂性和高采样率的要求。尽管任务的重要性，当前的生成模型在音乐质量、计算效率和泛化能力方面存在局限性。本文介绍了JEN-1，这是一个用于文本到音乐生成的通用高保真模型。JEN-1是一个结合了自回归和非自回归训练的扩散模型。通过上下文学习，JEN-1可以执行各种生成任务，包括文本引导的音乐生成、音乐修补以及延续。评估结果表明，JEN-1在文本音乐对齐和音乐质量方面表现出优越性，同时保持计算效率。我们的演示可在此网址获取：http://URL

    Music generation has attracted growing interest with the advancement of deep generative models. However, generating music conditioned on textual descriptions, known as text-to-music, remains challenging due to the complexity of musical structures and high sampling rate requirements. Despite the task's significance, prevailing generative models exhibit limitations in music quality, computational efficiency, and generalization. This paper introduces JEN-1, a universal high-fidelity model for text-to-music generation. JEN-1 is a diffusion model incorporating both autoregressive and non-autoregressive training. Through in-context learning, JEN-1 performs various generation tasks including text-guided music generation, music inpainting, and continuation. Evaluations demonstrate JEN-1's superior performance over state-of-the-art methods in text-music alignment and music quality while maintaining computational efficiency. Our demos are available at this http URL
    
[^39]: JiangJun：通过应对二人零和博弈中的非传递性来掌握象棋

    JiangJun: Mastering Xiangqi by Tackling Non-Transitivity in Two-Player Zero-Sum Games. (arXiv:2308.04719v1 [cs.AI])

    [http://arxiv.org/abs/2308.04719](http://arxiv.org/abs/2308.04719)

    本文通过研究非传递性问题，开发了江俊算法，结合蒙特卡洛树搜索和策略空间响应神谕，以逼近纳什均衡，成功提高了象棋对弈中的胜率。

    

    本文通过对象棋等完全信息游戏中的非传递性进行经验性探索，分析了超过10,000个人类象棋对局记录，发现了游戏战略结构中存在传递性和非传递性元素。为了解决非传递性问题，我们引入了江俊算法，这是蒙特卡洛树搜索（MCTS）和策略空间响应神谕（PSRO）的创新组合，旨在逼近纳什均衡。我们使用微信小程序对算法进行了实证评估，并在与人类玩家对战中达到了大师级别，胜率达到99.41％。大量指标，如相对人口表现和可视化结果，证实了该算法克服非传递性问题的有效性。我们的项目网站可在\url{https://sites.google.com/view/jiangjun-site/}访问。

    This paper presents an empirical exploration of non-transitivity in perfect-information games, specifically focusing on Xiangqi, a traditional Chinese board game comparable in game-tree complexity to chess and shogi. By analyzing over 10,000 records of human Xiangqi play, we highlight the existence of both transitive and non-transitive elements within the game's strategic structure. To address non-transitivity, we introduce the JiangJun algorithm, an innovative combination of Monte-Carlo Tree Search (MCTS) and Policy Space Response Oracles (PSRO) designed to approximate a Nash equilibrium. We evaluate the algorithm empirically using a WeChat mini program and achieve a Master level with a 99.41\% win rate against human players. The algorithm's effectiveness in overcoming non-transitivity is confirmed by a plethora of metrics, such as relative population performance and visualization results. Our project site is available at \url{https://sites.google.com/view/jiangjun-site/}.
    
[^40]: 生成扰动分析用于概率黑盒异常归因

    Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution. (arXiv:2308.04708v1 [cs.LG])

    [http://arxiv.org/abs/2308.04708](http://arxiv.org/abs/2308.04708)

    本文提出了一种新颖的概率异常归因框架，通过生成扰动来计算每个输入变量的归因得分的概率分布，并量化这些得分的不确定性。

    

    我们针对黑盒回归模型设置中的概率异常归因任务，旨在计算每个输入变量的归因得分的概率分布，给定一个观察到的异常。假设训练数据集不可用。与标准的可解释人工智能（XAI）情景不同，这个任务希望解释与黑盒预测的异常偏差，而不是解释黑盒模型本身。我们首先证明了主流的模型无关解释方法，如Shapley值，对于这个任务不适用，因为它们具有“偏差无关属性”。然后，我们提出了一种新颖的概率异常归因框架，不仅可以计算归因得分作为预测均值，还可以量化这些得分的不确定性。这是通过考虑一个生成过程来实现的，该过程对扰动进行反事实地将观测到的异常观察恢复到正常状态。

    We address the task of probabilistic anomaly attribution in the black-box regression setting, where the goal is to compute the probability distribution of the attribution score of each input variable, given an observed anomaly. The training dataset is assumed to be unavailable. This task differs from the standard XAI (explainable AI) scenario, since we wish to explain the anomalous deviation from a black-box prediction rather than the black-box model itself.  We begin by showing that mainstream model-agnostic explanation methods, such as the Shapley values, are not suitable for this task because of their ``deviation-agnostic property.'' We then propose a novel framework for probabilistic anomaly attribution that allows us to not only compute attribution scores as the predictive mean but also quantify the uncertainty of those scores. This is done by considering a generative process for perturbations that counter-factually bring the observed anomalous observation back to normalcy. We int
    
[^41]: 解释性人工智能在骨科中的应用: 挑战、机遇和前景

    Explainable AI in Orthopedics: Challenges, Opportunities, and Prospects. (arXiv:2308.04696v1 [cs.AI])

    [http://arxiv.org/abs/2308.04696](http://arxiv.org/abs/2308.04696)

    解释性人工智能在骨科中的应用面临挑战，但也带来机遇。为了实现透明度和可解释性，需要开发注重人工智能模型的透明性和可解释性的算法，并促进跨学科合作。

    

    虽然人工智能在各个领域取得了许多成功应用，但在医疗保健领域的应用却略显滞后。其中一些因素包括监管框架、患者隐私问题和数据异质性等影响了人工智能在医疗保健中的推广。然而，在骨科领域，特别是解释性和可解释性方面的挑战阻碍了人工智能的实施。解决解释性人工智能（XAI）在骨科中的问题需要开发注重透明度和可解释性的人工智能模型和算法，使临床医生、外科医生和患者能够理解任何依赖人工智能预测或描述模型的因素。本文概述了解释性人工智能在骨科实践中的几个关键挑战和机遇，并强调了人工智能从业者之间的跨学科合作的需求。

    While artificial intelligence (AI) has made many successful applications in various domains, its adoption in healthcare lags a little bit behind other high-stakes settings. Several factors contribute to this slower uptake, including regulatory frameworks, patient privacy concerns, and data heterogeneity. However, one significant challenge that impedes the implementation of AI in healthcare, particularly in orthopedics, is the lack of explainability and interpretability around AI models. Addressing the challenge of explainable AI (XAI) in orthopedics requires developing AI models and algorithms that prioritize transparency and interpretability, allowing clinicians, surgeons, and patients to understand the contributing factors behind any AI-powered predictive or descriptive models. The current contribution outlines several key challenges and opportunities that manifest in XAI in orthopedic practice. This work emphasizes the need for interdisciplinary collaborations between AI practitione
    
[^42]: 用于解决参数PDE的有限元算子网络

    Finite Element Operator Network for Solving Parametric PDEs. (arXiv:2308.04690v1 [math.NA])

    [http://arxiv.org/abs/2308.04690](http://arxiv.org/abs/2308.04690)

    本文提出了一种新方法，通过有限元算子网络（FEONet）解决参数PDE。它结合了深度学习和传统数值方法，展示了在没有输入-输出训练数据的情况下解决参数PDE的有效性，并在准确度、泛化性和计算灵活性方面优于现有方法。

    

    偏微分方程（PDE）是我们理解和预测物理、工程和金融等众多领域自然现象的基础。然而，解决参数PDE是一项复杂的任务，需要高效的数值方法。在本文中，我们提出了一种通过有限元算子网络（FEONet）解决参数PDE的新方法。我们的方法结合了深度学习和传统数值方法，特别是有限元法，以在没有任何配对的输入-输出训练数据的情况下解决参数PDE。我们在几个基准问题上展示了我们方法的效果，并且表明它在准确度、泛化性和计算灵活性方面优于现有的最先进方法。我们的FEONet框架在模拟具有不同边界条件和复杂域的各种领域中显示出潜力。

    Partial differential equations (PDEs) underlie our understanding and prediction of natural phenomena across numerous fields, including physics, engineering, and finance. However, solving parametric PDEs is a complex task that necessitates efficient numerical methods. In this paper, we propose a novel approach for solving parametric PDEs using a Finite Element Operator Network (FEONet). Our proposed method leverages the power of deep learning in conjunction with traditional numerical methods, specifically the finite element method, to solve parametric PDEs in the absence of any paired input-output training data. We demonstrate the effectiveness of our approach on several benchmark problems and show that it outperforms existing state-of-the-art methods in terms of accuracy, generalization, and computational flexibility. Our FEONet framework shows potential for application in various fields where PDEs play a crucial role in modeling complex domains with diverse boundary conditions and sin
    
[^43]: 网络爬虫在robot.txt限制下的策略研究

    web crawler strategies for web pages under robot.txt restriction. (arXiv:2308.04689v1 [cs.AI])

    [http://arxiv.org/abs/2308.04689](http://arxiv.org/abs/2308.04689)

    本文研究了在robot.txt限制下的网络爬虫策略，讨论了搜索引擎如何确定网页排名以及如何获取数据库中的网页。并介绍了机器人排除协议规则和robot.txt文件的基本格式。

    

    当今，所有人都了解互联网并每天在互联网上工作。本文介绍了为用户输入的关键字进行搜索的搜索引擎。搜索引擎使用不同的搜索算法，为上网者提供方便的结果。上网者选择排名靠前的搜索结果，但是网页的排名是如何由搜索引擎确定的？搜索引擎如何获取数据库中的所有网页？本文给出了所有这些基本问题的答案。本研究论文还讨论了为搜索引擎工作的网络爬虫和网络爬虫的机器人排除协议规则。网站管理员使用robot.txt文件中的不同限制规则指导网络爬虫，本文还提到了一些基本的robot.txt格式。

    In the present time, all know about World Wide Web and work over the Internet daily. In this paper, we introduce the search engines working for keywords that are entered by users to find something. The search engine uses different search algorithms for convenient results for providing to the net surfer. Net surfers go with the top search results but how did the results of web pages get higher ranks over search engines? how the search engine got that all the web pages in the database? This paper gives the answers to all these kinds of basic questions. Web crawlers working for search engines and robot exclusion protocol rules for web crawlers are also addressed in this research paper. Webmaster uses different restriction facts in robot.txt file to instruct web crawler, some basic formats of robot.txt are also mentioned in this paper.
    
[^44]: 通过合成医学图像快速创建训练数据以进行分类和定位

    Rapid Training Data Creation by Synthesizing Medical Images for Classification and Localization. (arXiv:2308.04687v1 [cs.CV])

    [http://arxiv.org/abs/2308.04687](http://arxiv.org/abs/2308.04687)

    该论文提出了一种通过合成医学图像快速创建训练数据的方法，以解决医学领域中生成注释数据的专业知识、时间和成本高的问题。该方法在弱监督和强监督目标定位模型上均取得了良好的效果。

    

    虽然人工智能在医学图像分析中的应用获得了广泛的认可，但由于数据和专家注释的有限可用性，医学领域生成注释数据所需的专业知识、时间和成本显著高。强监督目标定位模型需要详尽注释的数据，这意味着需要识别图像中所有感兴趣的对象。对于医学图像而言，这是难以实现和验证的。我们提出了一种将真实数据转化为训练任何深度神经网络解决上述问题的方法。我们展示了这种方法在弱监督定位模型和强监督定位模型上的有效性。对于弱监督模型，我们展示了使用生成的数据明显提高了定位准确性。对于强监督模型，这种方法克服了对真实图像的详尽注释的需求。在后者模型中，我们展示了...

    While the use of artificial intelligence (AI) for medical image analysis is gaining wide acceptance, the expertise, time and cost required to generate annotated data in the medical field are significantly high, due to limited availability of both data and expert annotation. Strongly supervised object localization models require data that is exhaustively annotated, meaning all objects of interest in an image are identified. This is difficult to achieve and verify for medical images. We present a method for the transformation of real data to train any Deep Neural Network to solve the above problems. We show the efficacy of this approach on both a weakly supervised localization model and a strongly supervised localization model. For the weakly supervised model, we show that the localization accuracy increases significantly using the generated data. For the strongly supervised model, this approach overcomes the need for exhaustive annotation on real images. In the latter model, we show tha
    
[^45]: Sci-CoT: 利用大型语言模型改进小型科学问答中的知识蒸馏

    Sci-CoT: Leveraging Large Language Models for Enhanced Knowledge Distillation in Small Models for Scientific QA. (arXiv:2308.04679v1 [cs.CL])

    [http://arxiv.org/abs/2308.04679](http://arxiv.org/abs/2308.04679)

    本论文研究了通过知识蒸馏将大型语言模型(LLMs)的推理能力转移到较小模型的可能性，提出了Sci-CoT框架，分离了生成理由和推理的过程。

    

    大型语言模型(LLMs)在广泛的下游任务中展现出了出色的性能。这种能力归功于它们庞大的参数规模和对大量语料库的预训练。此外，LLMs展现出增强的推理能力，能够应对复杂的推理任务，这归功于一种名为"思维链 (CoT)提示"的方法。该方法旨在生成引导最终答案推理的中间推理步骤。然而，需要强调的是，这些先进的推理能力似乎只在具有至少100亿参数的模型中出现，从而限制了其在计算资源有限的情况下的有效性。在本文中，我们探讨了通过知识蒸馏将LLMs的推理能力转移到较小模型的可能性。具体来说，我们提出了Sci-CoT，一个两阶段的框架，分离了生成理由和推理的过程。

    Large Language Models (LLMs) have shown outstanding performance across wide range of downstream tasks. This competency is attributed to their substantial parameter size and pre-training on extensive corpus. Moreover, LLMs have exhibited enhanced reasoning capabilities in tackling complex reasoning tasks, owing to the utilization of a method named ``Chain-of-Thought (CoT) prompting''. This method is designed to generate intermediate reasoning steps that guide the inference of the final answer. However, it is essential to highlight that these advanced reasoning abilities appear to emerge in models with a minimum of 10 billion parameters, thereby limiting its efficacy in situations where computational resources are constrained. In this paper, we investigate the possibility of transferring the reasoning capabilities of LLMs to smaller models via knowledge distillation. Specifically, we propose Sci-CoT, a two-stage framework that separates the processes of generating rationales and inferrin
    
[^46]: 解决面部情绪识别中的种族偏见问题

    Addressing Racial Bias in Facial Emotion Recognition. (arXiv:2308.04674v1 [cs.CV])

    [http://arxiv.org/abs/2308.04674](http://arxiv.org/abs/2308.04674)

    本研究通过分析不同种族分布的子采样训练集，并评估模拟中的测试性能，解决了面部情绪识别中的种族偏见问题。实验结果表明，具有姿势面部的较小数据集可以提高公平性和性能指标，但在具有更大面部变异的较大数据集中，种族平衡仍然无法实现不同种族群体之间的测试性能的公平性。

    

    在深度学习模型中，训练集具有高维度输入和主观标签的公平性仍然是一个复杂且研究不足的领域。面部情绪识别是一个数据集常常存在种族不平衡的领域，可能导致模型在不同种族群体之间产生不同的结果。本研究重点分析通过对具有不同种族分布的训练集进行子采样，并评估这些模拟中的测试性能来解决种族偏见问题。我们的研究结果表明，随着模拟接近种族平衡，采用较小的具有姿势面部的数据集可以在公平性和性能指标上取得改善。值得注意的是，F1得分平均提高了27.2个百分点，并且人口统计学平等性平均提高了15.7个百分点。然而，在具有更大面部变异的较大数据集中，公平性指标通常保持不变，这表明仅仅种族平衡是无法实现在不同种族群体之间测试性能的公平性。

    Fairness in deep learning models trained with high-dimensional inputs and subjective labels remains a complex and understudied area. Facial emotion recognition, a domain where datasets are often racially imbalanced, can lead to models that yield disparate outcomes across racial groups. This study focuses on analyzing racial bias by sub-sampling training sets with varied racial distributions and assessing test performance across these simulations. Our findings indicate that smaller datasets with posed faces improve on both fairness and performance metrics as the simulations approach racial balance. Notably, the F1-score increases by $27.2\%$ points, and demographic parity increases by $15.7\%$ points on average across the simulations. However, in larger datasets with greater facial variation, fairness metrics generally remain constant, suggesting that racial balance by itself is insufficient to achieve parity in test performance across different racial groups.
    
[^47]: SSL-Auth:一种用于自监督学习中预训练的编码器的易碎水印身份验证框架

    SSL-Auth: An Authentication Framework by Fragile Watermarking for Pre-trained Encoders in Self-supervised Learning. (arXiv:2308.04673v1 [cs.CR])

    [http://arxiv.org/abs/2308.04673](http://arxiv.org/abs/2308.04673)

    本文提出了SSL-Auth，这是一种用于自监督学习中预训练的编码器的易碎水印身份验证框架。该方法利用选择的关键样本作为水印信息，并训练一个验证网络来重构水印信息，从而进行验证。

    

    自监督学习（SSL）利用无标签数据集为预训练的强大编码器取得了显著的成功。这些编码器常被用作各种下游任务的特征提取器，其训练过程需要大量的数据和计算资源。随着预训练编码器在商业应用中的部署，保护模型所有者的知识产权并确保模型的可信性变得至关重要。最近的研究表明，编码器受到后门攻击、对抗攻击等威胁。因此，需要一种验证预训练编码器完整性的方案来保护用户。在本文中，我们提出了SSL-Auth，这是一种无损害模型性能的易碎水印身份验证方案。我们的方法利用选择的关键样本作为水印信息，并训练一个验证网络来重构水印信息，从而进行验证。

    Self-supervised learning (SSL) which leverages unlabeled datasets for pre-training powerful encoders has achieved significant success in recent years. These encoders are commonly used as feature extractors for various downstream tasks, requiring substantial data and computing resources for their training process. With the deployment of pre-trained encoders in commercial use, protecting the intellectual property of model owners and ensuring the trustworthiness of the models becomes crucial. Recent research has shown that encoders are threatened by backdoor attacks, adversarial attacks, etc. Therefore, a scheme to verify the integrity of pre-trained encoders is needed to protect users. In this paper, we propose SSL-Auth, the first fragile watermarking scheme for verifying the integrity of encoders without compromising model performance. Our method utilizes selected key samples as watermark information and trains a verification network to reconstruct the watermark information, thereby ver
    
[^48]: 资源受限下通过极小化最大化优化对脉冲神经网络进行模型压缩

    Resource Constrained Model Compression via Minimax Optimization for Spiking Neural Networks. (arXiv:2308.04672v1 [cs.CV])

    [http://arxiv.org/abs/2308.04672](http://arxiv.org/abs/2308.04672)

    提出了一种资源受限下通过极小化最大化优化对脉冲神经网络进行模型压缩的方法，以平衡模型性能和计算效率。

    

    脑部启发的脉冲神经网络（SNNs）具有事件驱动和高能效的特点，与传统的人工神经网络（ANNs）在神经元仿真芯片等边缘设备上部署时有所不同。大部分之前的研究集中于SNNs训练策略以提高模型性能并引入更大更深的网络架构。但是在资源受限的边缘设备上直接部署这些复杂网络是困难的。为了满足这种需求，人们通过谨慎地对SNNs进行压缩，以平衡性能和计算效率。现有的压缩方法要么通过权重范数大小迭代地剪枝SNNs，要么将问题形式化为稀疏学习优化。我们提出了一种改进的端到端极小化最大化优化方法来更好地平衡模型性能和计算效率。我们还证明了在SNNs上联合应用压缩和微调优于顺序应用它们。

    Brain-inspired Spiking Neural Networks (SNNs) have the characteristics of event-driven and high energy-efficient, which are different from traditional Artificial Neural Networks (ANNs) when deployed on edge devices such as neuromorphic chips. Most previous work focuses on SNNs training strategies to improve model performance and brings larger and deeper network architectures. It is difficult to deploy these complex networks on resource-limited edge devices directly. To meet such demand, people compress SNNs very cautiously to balance the performance and the computation efficiency. Existing compression methods either iteratively pruned SNNs using weights norm magnitude or formulated the problem as a sparse learning optimization. We propose an improved end-to-end Minimax optimization method for this sparse learning problem to better balance the model performance and the computation efficiency. We also demonstrate that jointly applying compression and finetuning on SNNs is better than seq
    
[^49]: 一种层次化的破坏和修复方法用于解决极大规模的旅行推销员问题

    A Hierarchical Destroy and Repair Approach for Solving Very Large-Scale Travelling Salesman Problem. (arXiv:2308.04639v1 [cs.AI])

    [http://arxiv.org/abs/2308.04639](http://arxiv.org/abs/2308.04639)

    提出了一种层次化的破坏和修复方法用于解决极大规模的旅行推销员问题。该方法采用了递归修复和压缩输入实例的层次化搜索框架，能够在合理的时间内提供高竞争力的解决方案。

    

    对于规模庞大的旅行推销员问题(TSP)，现有算法在计算效率和解决方案质量方面面临巨大挑战。为解决这个问题，我们提出了一种层次化的破坏和修复(HDR)方法，该方法通过一系列精心设计的破坏和修复操作来改进初始解决方案。一个关键的创新概念是层次化搜索框架，它递归修复部分边，并将输入实例压缩为具有某种等价保证的小规模TSP。这个简单明了的搜索框架能够在合理的时间内提供高竞争力的解决方案。基于十九个著名的大规模实例(包含10,000到10,000,000个城市)的公平比较表明，HDR在计算效率和解决方案质量方面与现有最先进的TSP算法具有很高的竞争力。值得注意的是，在具有3,162,278和10,000,000个城市的两个大规模实例上，HDR打破了世界纪录。

    For prohibitively large-scale Travelling Salesman Problems (TSPs), existing algorithms face big challenges in terms of both computational efficiency and solution quality. To address this issue, we propose a hierarchical destroy-and-repair (HDR) approach, which attempts to improve an initial solution by applying a series of carefully designed destroy-and-repair operations. A key innovative concept is the hierarchical search framework, which recursively fixes partial edges and compresses the input instance into a small-scale TSP under some equivalence guarantee. This neat search framework is able to deliver highly competitive solutions within a reasonable time. Fair comparisons based on nineteen famous large-scale instances (with 10,000 to 10,000,000 cities) show that HDR is highly competitive against existing state-of-the-art TSP algorithms, in terms of both efficiency and solution quality. Notably, on two large instances with 3,162,278 and 10,000,000 cities, HDR breaks the world record
    
[^50]: 稀疏二值变压器用于多元时间序列建模

    Sparse Binary Transformers for Multivariate Time Series Modeling. (arXiv:2308.04637v1 [cs.LG])

    [http://arxiv.org/abs/2308.04637](http://arxiv.org/abs/2308.04637)

    本研究将稀疏二值变压器应用于多元时间序列问题，并展示了该轻量级模型在分类、异常检测和单步预测任务中取得了与密集浮点变压器相当的准确度。同时，通过两个修改降低了注意机制的计算复杂性。

    

    压缩神经网络有可能实现在新应用和较小的计算环境中进行深度学习。然而，目前对于这种模型在哪些学习任务中能够成功的了解不多。在这项工作中，我们将稀疏和二值权重的变压器应用于多元时间序列问题，结果显示这种轻量级模型的准确度与相同结构的密集浮点变压器相当。我们的模型在三个时间序列学习任务中取得了好的结果：分类、异常检测和单步预测。此外，为了降低注意机制的计算复杂性，我们进行了两个修改，这两个修改在模型性能上几乎没有下降：1) 在分类任务中，我们对查询、键和值激活应用了一个固定的掩码；2) 对于预测和异常检测，这些任务都依赖于对单个时间点的输出进行预测，我们提出了一种注意力机制的变体。

    Compressed Neural Networks have the potential to enable deep learning across new applications and smaller computational environments. However, understanding the range of learning tasks in which such models can succeed is not well studied. In this work, we apply sparse and binary-weighted Transformers to multivariate time series problems, showing that the lightweight models achieve accuracy comparable to that of dense floating-point Transformers of the same structure. Our model achieves favorable results across three time series learning tasks: classification, anomaly detection, and single-step forecasting. Additionally, to reduce the computational complexity of the attention mechanism, we apply two modifications, which show little to no decline in model performance: 1) in the classification task, we apply a fixed mask to the query, key, and value activations, and 2) for forecasting and anomaly detection, which rely on predicting outputs at a single point in time, we propose an attentio
    
[^51]: AI有害言论的责任在哪里？

    Where's the Liability in Harmful AI Speech?. (arXiv:2308.04635v1 [cs.CY])

    [http://arxiv.org/abs/2308.04635](http://arxiv.org/abs/2308.04635)

    AI生成式模型可能会产生具有潜在责任风险的有害言论。解决模型创建者和部署者的法律责任问题的关键在于算法设计的技术细节。需要进行深入的Section 230免责分析以及下游责任分析。

    

    生成式人工智能（特别是基于文本的“基础模型”）可以生成可能在广泛的责任制度下引发问题的言论。机器学习从业者经常对模型进行“红队”测试，以识别和减轻此类问题言论，从错误指责严重不端行为的“幻觉”到构造原子弹的食谱。一个关键问题是这些红队测试行为是否真的对模型创建者和部署者构成任何法律责任风险，从而激励投资于安全机制。我们研究了三种责任制度，并将其与红队测试模型行为的常见例子联系起来：诽谤、构成犯罪行为的言论和错误致死。我们发现，任何Section 230免责分析或下游责任分析都与算法设计的技术细节密切相关。而要真正找到解决这些问题的方法有很多障碍。

    Generative AI, in particular text-based "foundation models" (large models trained on a huge variety of information including the internet), can generate speech that could be problematic under a wide range of liability regimes. Machine learning practitioners regularly "red team" models to identify and mitigate such problematic speech: from "hallucinations" falsely accusing people of serious misconduct to recipes for constructing an atomic bomb. A key question is whether these red-teamed behaviors actually present any liability risk for model creators and deployers under U.S. law, incentivizing investments in safety mechanisms. We examine three liability regimes, tying them to common examples of red-teamed model behaviors: defamation, speech integral to criminal conduct, and wrongful death. We find that any Section 230 immunity analysis or downstream liability analysis is intimately wrapped up in the technical details of algorithm design. And there are many roadblocks to truly finding mo
    
[^52]: 句子嵌入模型在评估语义变化中的比较研究

    A Comparative Study of Sentence Embedding Models for Assessing Semantic Variation. (arXiv:2308.04625v1 [cs.CL])

    [http://arxiv.org/abs/2308.04625](http://arxiv.org/abs/2308.04625)

    本研究比较了几种最近的句子嵌入方法在分析语义变化方面的一致性和有效性，并通过真实世界文本进行了评估。

    

    分析长篇真实世界文本（如书籍或记录）中语义变化的模式在文体、认知和语言学的角度上很有趣。它也有助于诸如文本分段、文档摘要和语义新颖性检测等应用。最近出现的几种句子嵌入方法使得这种分析成为可能。然而，这引发了不同方法产生的语义表示在自身上是否一致和有意义的问题。在本文中，我们通过时间序列的连续句子语义相似度和多本文学作品的句子对语义相似度矩阵来比较几种最近的句子嵌入方法。与以前使用目标任务和策划数据集来比较句子嵌入方法的工作相比，我们的方法在"野外"提供了对方法的评估。我们发现，大多数考虑的句子嵌入方法确实可以获得良好的效果。

    Analyzing the pattern of semantic variation in long real-world texts such as books or transcripts is interesting from the stylistic, cognitive, and linguistic perspectives. It is also useful for applications such as text segmentation, document summarization, and detection of semantic novelty. The recent emergence of several vector-space methods for sentence embedding has made such analysis feasible. However, this raises the issue of how consistent and meaningful the semantic representations produced by various methods are in themselves. In this paper, we compare several recent sentence embedding methods via time-series of semantic similarity between successive sentences and matrices of pairwise sentence similarity for multiple books of literature. In contrast to previous work using target tasks and curated datasets to compare sentence embedding methods, our approach provides an evaluation of the methods 'in the wild'. We find that most of the sentence embedding methods considered do in
    
[^53]: 基于LLM技术的聊天机器人的基准测试：方法和指标

    Benchmarking LLM powered Chatbots: Methods and Metrics. (arXiv:2308.04624v1 [cs.CL])

    [http://arxiv.org/abs/2308.04624](http://arxiv.org/abs/2308.04624)

    本文提出了一种新型的E2E基准测试，用于评估由LLM驱动的聊天机器人的准确性和实用性，相比其他指标，该基准测试展现出更好的结果。

    

    自主对话代理，即聊天机器人，正成为企业为客户和合作伙伴提供支持的越来越常见的机制。为了评估特别是由大型语言模型（LLM）驱动的聊天机器人的表现，我们需要能够准确评估其性能。这就是聊天机器人基准测试的重要性所在。在本文中，我们提出了一种称为E2E（端到端）基准测试的新型基准测试，并展示了如何使用E2E基准测试来评估由LLM驱动的聊天机器人提供的答案的准确性和实用性。我们根据我们的E2E基准测试以及其他常用的现有指标评估了一个示例聊天机器人的不同复杂程度，并观察到所提出的基准测试相比其他指标展现出更好的结果。此外，一些指标被证明是不可预测的，而与E2E基准测试相关的指标使用了余弦相似度。

    Autonomous conversational agents, i.e. chatbots, are becoming an increasingly common mechanism for enterprises to provide support to customers and partners. In order to rate chatbots, especially ones powered by Generative AI tools like Large Language Models (LLMs) we need to be able to accurately assess their performance. This is where chatbot benchmarking becomes important. In this paper, we propose the use of a novel benchmark that we call the E2E (End to End) benchmark, and show how the E2E benchmark can be used to evaluate accuracy and usefulness of the answers provided by chatbots, especially ones powered by LLMs. We evaluate an example chatbot at different levels of sophistication based on both our E2E benchmark, as well as other available metrics commonly used in the state of art, and observe that the proposed benchmark show better results compared to others. In addition, while some metrics proved to be unpredictable, the metric associated with the E2E benchmark, which uses cosi
    
[^54]: 采用分阶段推测解码加速LLM推理

    Accelerating LLM Inference with Staged Speculative Decoding. (arXiv:2308.04623v1 [cs.AI])

    [http://arxiv.org/abs/2308.04623](http://arxiv.org/abs/2308.04623)

    本文提出了一种新算法，分阶段推测解码，用于加速在小批量、设备上进行LLM推理。通过使用树形结构的批次重组和增加第二阶段的推测解码，将单批解码延迟降低了3.16倍，而输出质量保持完美。

    

    最近LLM的大规模语言模型的进展展示了它们的多样化能力。我们提出了一种新颖的算法，即分阶段推测解码，来加速在小批量、设备上进行LLM推理。通过改进先前的推测解码工作，我们解决了小批量推理的低算术强度问题。首先，我们将推测批次重新组织成树形结构，从而降低了生成成本，并增加了每批预期的标记数。其次，我们增加了第二阶段的推测解码。综合而言，我们在保持输出质量完美的情况下，将单批解码延迟降低了3.16倍，使用了762M参数的GPT-2-L模型。

    Recent advances with large language models (LLM) illustrate their diverse capabilities. We propose a novel algorithm, staged speculative decoding, to accelerate LLM inference in small-batch, on-device scenarios. We address the low arithmetic intensity of small-batch inference by improving upon previous work in speculative decoding. First, we restructure the speculative batch as a tree, which reduces generation costs and increases the expected tokens per batch. Second, we add a second stage of speculative decoding. Taken together, we reduce single-batch decoding latency by 3.16x with a 762M parameter GPT-2-L model while perfectly preserving output quality.
    
[^55]: 模型的模型--第一部分

    Model of models -- Part 1. (arXiv:2308.04600v1 [cs.AI])

    [http://arxiv.org/abs/2308.04600](http://arxiv.org/abs/2308.04600)

    本文提出了一种新的认知模型，该模型在成熟智能状态下操作累积的知识，并依赖适当的意愿进行指导。

    

    本文提出了一种新的认知模型，作为AGI代理的主要组成部分。该模型是在其成熟的智能状态下引入的，是DENN和特别是AKREM之前模型的延伸，包括操作模型（框架/类别）和意愿。该模型的核心假设是认知是在适当的意愿引导下对累积的知识进行操作。此外，我们假设在成熟的智能状态之前的演化阶段，行为（知识的一部分）是学习与意愿对齐的。此外，该模型主要基于每个已知智能方面的二元性原则，例如上下学习模型，泛化与特化，等等。此外，倡导一种整体的AGI设计方法，并提出了在约束条件下的认知或效率问题，以可重用性和简洁性的形式。最后，通过实现知识和规则之间的双重叠加方式来描述达到这种成熟状态。

    This paper proposes a new cognitive model, acting as the main component of an AGI agent. The model is introduced in its mature intelligence state, and as an extension of previous models, DENN, and especially AKREM, by including operational models (frames/classes) and will. This model's core assumption is that cognition is about operating on accumulated knowledge, with the guidance of an appropriate will. Also, we assume that the actions, part of knowledge, are learning to be aligned with will, during the evolution phase that precedes the mature intelligence state. In addition, this model is mainly based on the duality principle in every known intelligent aspect, such as exhibiting both top-down and bottom-up model learning, generalization verse specialization, and more. Furthermore, a holistic approach is advocated for AGI designing, and cognition under constraints or efficiency is proposed, in the form of reusability and simplicity. Finally, reaching this mature state is described via
    
[^56]: "Shepherd: 一种用于语言模型生成的评论者"

    Shepherd: A Critic for Language Model Generation. (arXiv:2308.04592v1 [cs.CL])

    [http://arxiv.org/abs/2308.04592](http://arxiv.org/abs/2308.04592)

    Shepherd是一种专门用于评论和提出改进建议的语言模型，通过使用高质量的反馈数据集，它可以识别和修复不同的错误。与其他模型相比，在评估和人工评估中，Shepherd的性能表现更佳。

    

    随着大型语言模型的改进，越来越多的技术开始利用这些模型的能力来优化其输出。本研究介绍了Shepherd，一种特定调整的语言模型，用于评论回复并提出改进建议，超越了未调整模型的能力，可以识别不同的错误并提供建议来修复它们。我们的方法的核心是一个高质量的反馈数据集，我们从社区反馈和人工注释中策划整理而成。尽管Shepherd规模较小（7B个参数），但其评论要么与ChatGPT等已建立的模型等效，要么更优。通过使用GPT-4进行评估，Shepherd相对于竞争对手平均具有53-87%的胜率。在人工评估中，Shepherd明显优于其他模型，并且平均与ChatGPT持平。

    As large language models improve, there is increasing interest in techniques that leverage these models' capabilities to refine their own outputs. In this work, we introduce Shepherd, a language model specifically tuned to critique responses and suggest refinements, extending beyond the capabilities of an untuned model to identify diverse errors and provide suggestions to remedy them. At the core of our approach is a high quality feedback dataset, which we curate from community feedback and human annotations. Even though Shepherd is small (7B parameters), its critiques are either equivalent or preferred to those from established models including ChatGPT. Using GPT-4 for evaluation, Shepherd reaches an average win-rate of 53-87% compared to competitive alternatives. In human evaluation, Shepherd strictly outperforms other models and on average closely ties with ChatGPT.
    
[^57]: Temporal DINO:一种增强动作预测的自监督视频策略

    Temporal DINO: A Self-supervised Video Strategy to Enhance Action Prediction. (arXiv:2308.04589v1 [cs.CV])

    [http://arxiv.org/abs/2308.04589](http://arxiv.org/abs/2308.04589)

    Temporal DINO是一种自监督视频策略，通过引入一个学生模型和一个教师模型，使得学生模型能够通过观察过去帧来学习未来帧的上下文，以增强动作预测。这种方法在行动预测任务上在ROAD数据集上进行了评估。

    

    行动预测的新兴领域在各种计算机视觉应用中起着重要作用，如自动驾驶、活动分析和人机交互。尽管有重大进展，但由于视频数据中固有的高维度、复杂动态和不确定性，准确预测未来动作仍然是一个具有挑战性的问题。传统的监督方法需要大量的标记数据，而获取这些数据既昂贵又耗时。本文介绍了一种受DINO（无标签的自蒸馏）启发的增强动作预测的新型自监督视频策略，称为Temporal-DINO。该策略使用两个模型：一个“学生”处理过去的帧，一个“教师”同时处理过去和未来的帧，从而实现更广泛的时间上下文。在训练过程中，教师通过仅观察过去的帧来指导学生学习未来的上下文。该策略在ROAD数据集上进行了行动预测下游任务的评估。

    The emerging field of action prediction plays a vital role in various computer vision applications such as autonomous driving, activity analysis and human-computer interaction. Despite significant advancements, accurately predicting future actions remains a challenging problem due to high dimensionality, complex dynamics and uncertainties inherent in video data. Traditional supervised approaches require large amounts of labelled data, which is expensive and time-consuming to obtain. This paper introduces a novel self-supervised video strategy for enhancing action prediction inspired by DINO (self-distillation with no labels). The Temporal-DINO approach employs two models; a 'student' processing past frames; and a 'teacher' processing both past and future frames, enabling a broader temporal context. During training, the teacher guides the student to learn future context by only observing past frames. The strategy is evaluated on ROAD dataset for the action prediction downstream task usi
    
[^58]: AIs的发展脱靴法

    Developmental Bootstrapping of AIs. (arXiv:2308.04586v1 [cs.AI])

    [http://arxiv.org/abs/2308.04586](http://arxiv.org/abs/2308.04586)

    传统的符号AI方法和深度学习AI方法无法满足创建强大和可信赖的AI的挑战，然而，发展脱靴法通过模仿人类儿童的能力发展过程，为创建稳健可靠的AI提供了希望。

    

    尽管当前一些AI在封闭的世界，如棋盘游戏中超越了人类能力，但它们在混乱的现实世界中的表现有限。它们会犯奇怪的错误而且没有意识到。它们很难受到指导，不能运用常识，缺乏好奇心。它们不能成为良好的合作者。传统手动构建的符号AI方法构建的系统和使用生成和深度学习AI方法(包括大规模语言模型)构建的系统都无法应对这些挑战。它们不适合创建强大和可信赖的AI。尽管此方法不属于主流的AI方法，但发展脱靴法显示出希望。在发展脱靴法中，AI像人类儿童一样发展能力。它们从先天能力开始。像人类一样，它们与环境互动，并从互动中学习。它们通过自我发展的能力逐步扩展先天能力。它们互动并逐渐将所学应用于实际操作。

    Although some current AIs surpass human abilities especially in closed worlds such as board games, their performance in the messy real world is limited. They make strange mistakes and do not notice them. They cannot be instructed easily, fail to use common sense, and lack curiosity. They do not make good collaborators. Neither systems built using the traditional manually-constructed symbolic AI approach nor systems built using generative and deep learning AI approaches including large language models (LLMs) can meet the challenges. They are not well suited for creating robust and trustworthy AIs. Although it is outside of mainstream AI approaches, developmental bootstrapping shows promise. In developmental bootstrapping, AIs develop competences like human children do. They start with innate competences. Like humans, they interact with the environment and learn from their interactions. They incrementally extend their innate competences with self-developed competences. They interact and 
    
[^59]: 利用生物启发的架构提高连续学习任务的性能

    Improving Performance in Continual Learning Tasks using Bio-Inspired Architectures. (arXiv:2308.04539v1 [cs.LG])

    [http://arxiv.org/abs/2308.04539](http://arxiv.org/abs/2308.04539)

    本研究提出了一种受生物启发的轻量级神经网络架构，通过本地误差信号实现在线连续学习，克服了传统方法的局限性，在多个数据集上展现出优秀的表现。

    

    在设计智能系统中，从连续的数据流中无间断地学习而不会发生灾难性遗忘的能力至关重要。许多连续学习方法依赖于随机梯度下降及其变体，这些方法采用全局误差更新，因此需要采取策略，如内存缓冲区或回放，以规避其稳定性、贪婪和短期记忆的限制。为了解决这个问题，我们开发了一种受生物启发的轻量级神经网络架构，它包括突触可塑性机制和神经调节，并通过本地误差信号进行学习，以实现在线连续学习而无需随机梯度下降。我们的方法在Split-MNIST、Split-CIFAR-10和Split-CIFAR-100数据集上比其他内存受限的学习方法表现出更好的在线连续学习性能，并且与最先进的内存密集型回放方法相匹配。

    The ability to learn continuously from an incoming data stream without catastrophic forgetting is critical to designing intelligent systems. Many approaches to continual learning rely on stochastic gradient descent and its variants that employ global error updates, and hence need to adopt strategies such as memory buffers or replay to circumvent its stability, greed, and short-term memory limitations. To address this limitation, we have developed a biologically inspired lightweight neural network architecture that incorporates synaptic plasticity mechanisms and neuromodulation and hence learns through local error signals to enable online continual learning without stochastic gradient descent.  Our approach leads to superior online continual learning performance on Split-MNIST, Split-CIFAR-10, and Split-CIFAR-100 datasets compared to other memory-constrained learning approaches and matches that of the state-of-the-art memory-intensive replay-based approaches. We further demonstrate the 
    
[^60]: 通过风格迁移生成现代波斯地毯地图

    Generating Modern Persian Carpet Map by Style-transfer. (arXiv:2308.04529v1 [cs.CV])

    [http://arxiv.org/abs/2308.04529](http://arxiv.org/abs/2308.04529)

    本研究旨在利用深度神经网络(DNN)生成现代波斯地毯地图，并提出了三种不同的DNN风格迁移方法。通过使用Style-Swap方法创建初始地图，并使用Clip-Styler、Gatys和Style-Swap方法生成更多样化的设计，同时还考虑了对地图进行着色的方法。

    

    如今，深度神经网络(DNN)在各个领域中都展现出了出色的性能。其中最有吸引力的应用之一是生成艺术设计。作为一种被认为是艺术品的地毯是房子中最重要的物品之一，拥有全球各地的众多爱好者。生成地毯的第一步是准备它的地图，这是一项困难、耗时且昂贵的任务。在这项研究中，我们的目的是使用DNN来生成现代波斯地毯地图。为了实现这个目标，提出并比较了三种不同的DNN风格迁移方法。在提出的方法中，使用Style-Swap方法创建初始地毯地图，并在接下来使用Clip-Styler、Gatys和Style-Swap方法分别生成更多样化的设计。此外，还对一些着色方法进行了研究和介绍，以给生成的地毯地图上色。通过填写问卷的结果来评估设计的地图。

    Today, the great performance of Deep Neural Networks(DNN) has been proven in various fields. One of its most attractive applications is to produce artistic designs. A carpet that is known as a piece of art is one of the most important items in a house, which has many enthusiasts all over the world. The first stage of producing a carpet is to prepare its map, which is a difficult, time-consuming, and expensive task. In this research work, our purpose is to use DNN for generating a Modern Persian Carpet Map. To reach this aim, three different DNN style transfer methods are proposed and compared against each other. In the proposed methods, the Style-Swap method is utilized to create the initial carpet map, and in the following, to generate more diverse designs, methods Clip-Styler, Gatys, and Style-Swap are used separately. In addition, some methods are examined and introduced for coloring the produced carpet maps. The designed maps are evaluated via the results of filled questionnaires w
    
[^61]: 深度学习在不同数据类型隐写分析中的应用：综述

    Deep Learning for Diverse Data Types Steganalysis: A Review. (arXiv:2308.04522v1 [cs.CR])

    [http://arxiv.org/abs/2308.04522](http://arxiv.org/abs/2308.04522)

    本综述论文详细综述了基于深度学习的隐写分析技术在数字媒体中检测隐藏信息的最新研究进展。

    

    隐写术和隐写分析是信息安全领域的两个相关方面。隐写术旨在隐藏通信，而隐写分析则旨在找到这些隐藏信息，甚至尝试恢复其所包含的数据。隐写术和隐写分析引起了广泛的关注，特别受到执法部门的关注。隐写术常被网络犯罪分子甚至恐怖分子用来避免在拥有证据时被捕，即使加密也一样，因为在许多国家禁止或限制使用密码学。因此，了解揭示隐藏信息的尖端技术对揭露非法行为至关重要。在过去几年中，文献中引入了许多强大可靠的隐写术和隐写分析技术。本综述论文提供了基于深度学习的隐写分析技术在数字媒体中检测隐藏信息的全面概述。

    Steganography and steganalysis are two interrelated aspects of the field of information security. Steganography seeks to conceal communications, whereas steganalysis is aimed to either find them or even, if possible, recover the data they contain. Steganography and steganalysis have attracted a great deal of interest, particularly from law enforcement. Steganography is often used by cybercriminals and even terrorists to avoid being captured while in possession of incriminating evidence, even encrypted, since cryptography is prohibited or restricted in many countries. Therefore, knowledge of cutting-edge techniques to uncover concealed information is crucial in exposing illegal acts. Over the last few years, a number of strong and reliable steganography and steganalysis techniques have been introduced in the literature. This review paper provides a comprehensive overview of deep learning-based steganalysis techniques used to detect hidden information within digital media. The paper cove
    
[^62]: DisCoCat用于Donkey句子

    DisCoCat for Donkey Sentences. (arXiv:2308.04519v1 [cs.CL])

    [http://arxiv.org/abs/2308.04519](http://arxiv.org/abs/2308.04519)

    这篇论文展示了如何在一个组合分布式意义模型中解析Donkey句子，并提出了一种类型逻辑语法和关系向量空间语义。

    

    我们展示了如何在一个组合分布式意义模型中解析Geach的Donkey句子。我们在之前关于DisCoCat（分布式组合范畴）框架的工作基础上进行扩展，包括对话语、限定词和关系代词的建模。我们提出了一种类型逻辑语法来解析donkey句子，同时定义了关系和向量空间语义。

    We demonstrate how to parse Geach's Donkey sentences in a compositional distributional model of meaning. We build on previous work on the DisCoCat (Distributional Compositional Categorical) framework, including extensions that model discourse, determiners, and relative pronouns. We present a type-logical syntax for parsing donkey sentences, for which we define both relational and vector space semantics.
    
[^63]: MT-IceNet - 一种用于北极海冰预测的空间和多时序深度学习模型

    MT-IceNet -- A Spatial and Multi-Temporal Deep Learning Model for Arctic Sea Ice Forecasting. (arXiv:2308.04511v1 [physics.ao-ph])

    [http://arxiv.org/abs/2308.04511](http://arxiv.org/abs/2308.04511)

    提出了一种名为MT-IceNet的深度学习模型，用于预测北极海冰浓度。该模型采用了空间和多时序结构，利用编码器-解码器架构和跳跃连接处理多时序输入流，并可生成未来时间步骤的空间地图。

    

    北极放大已经改变了区域和全球的气候模式，导致过去几十年中更频繁和更强烈的极端天气事件。北极放大的关键部分是卫星观测所证实的前所未有的海冰消失。准确地从次季节到季节性尺度预测北极海冰一直是一个重要的研究问题，存在根本性挑战。除了基于物理学的地球系统模型，研究者一直应用多种统计和机器学习模型进行海冰预测。回顾数据驱动方法研究海冰变化的潜力，我们提出了MT-IceNet - 一种基于UNet的空间和多时序深度学习模型，用于预测北极海冰浓度（SIC）。该模型采用编码器-解码器架构，具有跳跃连接，并处理多时序输入流以在未来的时间步骤中重新生成空间地图。

    Arctic amplification has altered the climate patterns both regionally and globally, resulting in more frequent and more intense extreme weather events in the past few decades. The essential part of Arctic amplification is the unprecedented sea ice loss as demonstrated by satellite observations. Accurately forecasting Arctic sea ice from sub-seasonal to seasonal scales has been a major research question with fundamental challenges at play. In addition to physics-based Earth system models, researchers have been applying multiple statistical and machine learning models for sea ice forecasting. Looking at the potential of data-driven approaches to study sea ice variations, we propose MT-IceNet - a UNet based spatial and multi-temporal (MT) deep learning model for forecasting Arctic sea ice concentration (SIC). The model uses an encoder-decoder architecture with skip connections and processes multi-temporal input streams to regenerate spatial maps at future timesteps. Using bi-monthly and m
    
[^64]: 用于阿拉伯语语法错误修正的ChatGPT

    ChatGPT for Arabic Grammatical Error Correction. (arXiv:2308.04492v1 [cs.AI])

    [http://arxiv.org/abs/2308.04492](http://arxiv.org/abs/2308.04492)

    本研究针对阿拉伯语语法错误修正任务，探究了指令调校的大型语言模型（LLMs）的能力。通过结合多种提示方法和少样本学习，我们的研究发现，在阿拉伯语语法错误修正中，GPT-4能够达到65.49的F1得分，比我们已有的基准提高了大约5个点。这表明LLMs在资源匮乏环境中具有潜力，并为模型训练提供了生成合成数据的可行方法。

    

    最近，被调整以遵循人类指令的大型语言模型（LLM）在各种英文NLP任务中展示出了显著的能力。然而，在语法错误修正（GEC）任务中，特别是在非英文语言中，它们的表现仍然相当未被探索。在本文中，我们研究了指令调校的LLM在阿拉伯语GEC中的能力，这是由于阿拉伯语的丰富形态而变得复杂的任务。我们的研究结果表明，结合不同的提示方法，并结合（上下文）少样本学习，展示出了相当大的效果，GPT-4在专家提示下达到了65.49的F1得分（比我们已有的基准提高了大约5个点）。这突显了LLM在资源匮乏环境中的潜力，为模型训练生成有用的合成数据提供了可行的方法。尽管取得了积极的结果，我们发现，不论规模如何，指令调校模型的性能显著低于比较基准。

    Recently, large language models (LLMs) fine-tuned to follow human instruction have exhibited significant capabilities in various English NLP tasks. However, their performance in grammatical error correction (GEC) tasks, particularly in non-English languages, remains significantly unexplored. In this paper, we delve into abilities of instruction fine-tuned LLMs in Arabic GEC, a task made complex due to Arabic's rich morphology. Our findings suggest that various prompting methods, coupled with (in-context) few-shot learning, demonstrate considerable effectiveness, with GPT-4 achieving up to $65.49$ F\textsubscript{1} score under expert prompting (approximately $5$ points higher than our established baseline). This highlights the potential of LLMs in low-resource settings, offering a viable approach for generating useful synthetic data for model training. Despite these positive results, we find that instruction fine-tuned models, regardless of their size, significantly underperform compar
    
[^65]: 使用ChatGPT 3.5生成代码在10种编程语言之间的比较研究

    A Comparative Study of Code Generation using ChatGPT 3.5 across 10 Programming Languages. (arXiv:2308.04477v1 [cs.SE])

    [http://arxiv.org/abs/2308.04477](http://arxiv.org/abs/2308.04477)

    本研究比较了使用ChatGPT 3.5在10种编程语言中生成代码的能力，并发现了模型的意外行为和限制。

    

    大型语言模型（LLMs）是先进的人工智能系统，经过大数据集的广泛训练，以理解和产生与人类语言相似的内容。这些模型已经具备一定的能力，能够成功完成多个学科的大学考试，并且能够生成处理新问题的功能代码。本研究调查了由OpenAI于2022年11月发布的ChatGPT 3.5的编码能力，该模型因其出色的文本生成和代码创建能力而获得了广泛的认可。该模型在10种不同的编程语言和4个不同的软件领域中的代码片段生成能力进行了评估。根据研究结果，本研究发现了模型的重要意外行为和限制。本研究旨在确定发展的潜在领域，并研究自动生成代码的影响。

    Large Language Models (LLMs) are advanced Artificial Intelligence (AI) systems that have undergone extensive training using large datasets in order to understand and produce language that closely resembles that of humans. These models have reached a level of proficiency where they are capable of successfully completing university exams across several disciplines and generating functional code to handle novel problems. This research investigates the coding proficiency of ChatGPT 3.5, a LLM released by OpenAI in November 2022, which has gained significant recognition for its impressive text generating and code creation capabilities. The skill of the model in creating code snippets is evaluated across 10 various programming languages and 4 different software domains. Based on the findings derived from this research, major unexpected behaviors and limitations of the model have been identified. This study aims to identify potential areas for development and examine the ramifications of auto
    
[^66]: 通过深度学习神经网络相关医疗保险索赔服务

    Correlating Medi- Claim Service by Deep Learning Neural Networks. (arXiv:2308.04469v1 [cs.LG])

    [http://arxiv.org/abs/2308.04469](http://arxiv.org/abs/2308.04469)

    本论文通过使用深度学习神经网络，结合回归模型的相关性研究，利用卷积神经网络架构来检测医疗保险索赔中的欺诈行为，并使用有监督和无监督分类器来区分欺诈和非欺诈索赔。

    

    医疗保险索赔中存在与患者、医生、诊断中心和保险提供商相关的有组织犯罪，形成了必须不断监测的连锁反应。这些欺诈行为影响被保险人和健康保险公司的财务增长。通过对回归模型的相关性研究，利用卷积神经网络架构来检测欺诈索赔，从而有助于检测来自不同提供商的不同索赔的洗钱行为。使用了有监督和无监督分类器来检测欺诈和非欺诈索赔。

    Medical insurance claims are of organized crimes related to patients, physicians, diagnostic centers, and insurance providers, forming a chain reaction that must be monitored constantly. These kinds of frauds affect the financial growth of both insured people and health insurance companies. The Convolution Neural Network architecture is used to detect fraudulent claims through a correlation study of regression models, which helps to detect money laundering on different claims given by different providers. Supervised and unsupervised classifiers are used to detect fraud and non-fraud claims.
    
[^67]: 匿名化语音：评估和设计说话人匿名化技术

    Anonymizing Speech: Evaluating and Designing Speaker Anonymization Techniques. (arXiv:2308.04455v1 [cs.CR])

    [http://arxiv.org/abs/2308.04455](http://arxiv.org/abs/2308.04455)

    本研究提出了匿名化语音的解决方案，并评估了匿名化的程度，以应对语音数据收集中的隐私问题和恶意使用的风险。

    

    随着语音用户界面的广泛使用，语音数据的收集和存储也大大增加。虽然数据收集可以为大多数语音服务提供高效的工具，但它也给用户的隐私造成严重的问题，因为集中存储使个人的语音数据容易受到网络威胁的侵害。随着亚马逊的Alexa，谷歌的Home和苹果的Siri等基于语音的数字助手的使用增加，以及个人语音数据收集变得越来越容易，声音克隆和说话人/性别/病理等识别的恶意使用的风险也增加了。本文提出了匿名化语音的解决方案，并评估匿名化的程度。在这项工作中，匿名化是指使个人语音数据与身份无法关联，同时保持语音信号的实用性（例如，访问语言内容）。我们首先确定了几个评估协议的挑战。

    The growing use of voice user interfaces has led to a surge in the collection and storage of speech data. While data collection allows for the development of efficient tools powering most speech services, it also poses serious privacy issues for users as centralized storage makes private personal speech data vulnerable to cyber threats. With the increasing use of voice-based digital assistants like Amazon's Alexa, Google's Home, and Apple's Siri, and with the increasing ease with which personal speech data can be collected, the risk of malicious use of voice-cloning and speaker/gender/pathological/etc. recognition has increased.  This thesis proposes solutions for anonymizing speech and evaluating the degree of the anonymization. In this work, anonymization refers to making personal speech data unlinkable to an identity while maintaining the usefulness (utility) of the speech signal (e.g., access to linguistic content). We start by identifying several challenges that evaluation protoco
    
[^68]: AI代码生成器的漏洞：探索针对数据毒化攻击的方法

    Vulnerabilities in AI Code Generators: Exploring Targeted Data Poisoning Attacks. (arXiv:2308.04451v1 [cs.CR])

    [http://arxiv.org/abs/2308.04451](http://arxiv.org/abs/2308.04451)

    本文评估了AI代码生成器的安全性，发现它们容易受到数据毒化攻击，即注入恶意样本来生成易受攻击的代码。攻击可以成功即使只有少量数据被毒化，而且不影响预训练模型生成的代码的正确性，使其难以被检测。

    

    在这项工作中，我们通过数据毒化评估AI代码生成器的安全性，即通过将恶意样本注入训练数据来生成易受攻击的代码。我们通过注入包含安全漏洞的代码来毒化训练数据，并评估不同最先进的代码生成模型对攻击的成功程度。我们的分析表明，即使只有少量的数据毒化，AI代码生成器也容易受到攻击。此外，该攻击不会影响预训练模型生成的代码的正确性，使其难以检测。

    In this work, we assess the security of AI code generators via data poisoning, i.e., an attack that injects malicious samples into the training data to generate vulnerable code. We poison the training data by injecting increasing amounts of code containing security vulnerabilities and assess the attack's success on different state-of-the-art models for code generation. Our analysis shows that AI code generators are vulnerable to even a small amount of data poisoning. Moreover, the attack does not impact the correctness of code generated by pre-trained models, making it hard to detect.
    
[^69]: 双重治理：集中监管与众包安全机制在生成AI中的交集

    Dual Governance: The intersection of centralized regulation and crowdsourced safety mechanisms for Generative AI. (arXiv:2308.04448v1 [cs.CY])

    [http://arxiv.org/abs/2308.04448](http://arxiv.org/abs/2308.04448)

    本文讨论了生成AI领域的治理问题，提出了将集中监管与众包安全机制相结合的双重治理方式。集中监管存在缺乏明确性和统一性等问题，而众包安全机制则存在缺乏统一性和合规性的不足。该研究旨在促进生成AI领域的负责任和道德发展。

    

    生成人工智能（AI）最近在消费者面向的、开放式的文本和图像生成模型方面得到了广泛应用。然而，使用这样的系统引发了重要的伦理和安全问题，包括隐私侵犯、虚假信息和知识产权盗窃。生成AI可能取代人类的创造力和谋生方式也受到了严格审查。为了缓解这些风险，在生成AI领域需要一种负责任和道德的发展政策和监管机制。现有和提议的政府集中监管AI的规定面临诸多批评，例如缺乏足够的明确性和统一性，在不同司法辖区之间缺乏互操作性，限制创新，阻碍自由市场竞争。分散的众包安全工具和机制是一个潜在的替代方案。然而，它们在缺乏统一性、合规性和透明性方面存在明显的不足。

    Generative Artificial Intelligence (AI) has seen mainstream adoption lately, especially in the form of consumer-facing, open-ended, text and image generating models. However, the use of such systems raises significant ethical and safety concerns, including privacy violations, misinformation and intellectual property theft. The potential for generative AI to displace human creativity and livelihoods has also been under intense scrutiny. To mitigate these risks, there is an urgent need of policies and regulations responsible and ethical development in the field of generative AI. Existing and proposed centralized regulations by governments to rein in AI face criticisms such as not having sufficient clarity or uniformity, lack of interoperability across lines of jurisdictions, restricting innovation, and hindering free market competition. Decentralized protections via crowdsourced safety tools and mechanisms are a potential alternative. However, they have clear deficiencies in terms of lac
    
[^70]: 从生成式AI走向可信赖的AI：LLM可以从Cyc中学到什么

    Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc. (arXiv:2308.04445v1 [cs.LG])

    [http://arxiv.org/abs/2308.04445](http://arxiv.org/abs/2308.04445)

    对于未来的AI，需要从生成式AI转向可信赖的AI。通过培养基于明确知识和经验规则的AI，可以解决当前方法的限制并实现推理过程的可信赖和可解释性。

    

    生成式AI是目前最流行的人工智能方法，由训练出的大型语言模型（LLMs）组成，用于生成可信，但不一定正确的输出。尽管它们的能力常常令人惊叹，但在推理方面它们存在缺陷，导致LLMs不完全可信赖。此外，它们的结果往往不可预测和不可解释。我们提出了未来人工智能的16个期望，并讨论了AI的另一种可能解决当前方法所面临的许多限制的方法：培养基于明确知识和经验规则的AI，使推理引擎能够自动推导出所有知识的逻辑蕴含。即使是通过这种方式产生的长论证也可以是可信且可解释的，因为完整的逐步推理过程始终可以获得，并且可以记录和审计每个步骤使用的知识的来源。

    Generative AI, the most popular current approach to AI, consists of large language models (LLMs) that are trained to produce outputs that are plausible, but not necessarily correct. Although their abilities are often uncanny, they are lacking in aspects of reasoning, leading LLMs to be less than completely trustworthy. Furthermore, their results tend to be both unpredictable and uninterpretable.  We lay out 16 desiderata for future AI, and discuss an alternative approach to AI which could theoretically address many of the limitations associated with current approaches: AI educated with curated pieces of explicit knowledge and rules of thumb, enabling an inference engine to automatically deduce the logical entailments of all that knowledge. Even long arguments produced this way can be both trustworthy and interpretable, since the full step-by-step line of reasoning is always available, and for each step the provenance of the knowledge used can be documented and audited. There is however
    
[^71]: 基于区块链的优化客户选择和隐私保护框架用于联邦学习

    Blockchain-based Optimized Client Selection and Privacy Preserved Framework for Federated Learning. (arXiv:2308.04442v1 [cs.CR])

    [http://arxiv.org/abs/2308.04442](http://arxiv.org/abs/2308.04442)

    本论文提出了基于区块链的优化客户选择和隐私保护框架，用于解决联邦学习中的单点故障攻击和模型准确性问题，并采用完全同态加密保护隐私。

    

    联邦学习是一种分布式机制，通过多个客户端的参与训练大规模神经网络模型，数据仍然保留在其设备上，只分享本地模型更新。这个特点使得联邦学习被认为是解决数据隐私问题的安全解决方案。然而，传统的联邦学习结构依赖于客户端-服务器，这导致了单点故障攻击，随机选择客户端进行模型训练也会影响模型的准确性。此外，对手还试图进行推理攻击，即对隐私的攻击会导致梯度泄露攻击。我们在这一背景下提出了基于区块链的优化客户选择和隐私保护框架。我们设计了三种智能合约，包括1) 客户端注册，2) 正向竞价选择优化客户进行联邦学习模型训练，3) 付款结算和奖励智能合约。此外，我们还使用Cheon, Kim, Kim和Son的完全同态加密方法。

    Federated learning is a distributed mechanism that trained large-scale neural network models with the participation of multiple clients and data remains on their devices, only sharing the local model updates. With this feature, federated learning is considered a secure solution for data privacy issues. However, the typical FL structure relies on the client-server, which leads to the single-point-of-failure (SPoF) attack, and the random selection of clients for model training compromised the model accuracy. Furthermore, adversaries try for inference attacks i.e., attack on privacy leads to gradient leakage attacks. We proposed the blockchain-based optimized client selection and privacy-preserved framework in this context. We designed the three kinds of smart contracts such as 1) registration of clients 2) forward bidding to select optimized clients for FL model training 3) payment settlement and reward smart contracts. Moreover, fully homomorphic encryption with Cheon, Kim, Kim, and Son
    
[^72]: 自然和机器

    Nature and the Machines. (arXiv:2308.04440v1 [cs.CY])

    [http://arxiv.org/abs/2308.04440](http://arxiv.org/abs/2308.04440)

    《自然》杂志在一篇社论中呼吁我们“停止谈论明天的AI末日，而AI今天就存在风险。”这被认为是一个严重的判断失误，特别是对于有影响力的行动者来说，因为我们期望他们能够考虑到错误的后果。

    

    人工智能(AI)是否对人类构成存在危险？一些批评家认为这个问题正在受到过多的关注，他们希望将其推到一边，转而讨论AI的即时风险。这些批评家现在包括《自然》杂志，在最近的一篇社论中敦促我们“停止谈论明天的AI末日，而AI今天就存在风险。”我们认为这是一种严重的判断失误，对于《自然》杂志来说。在科学领域，就像在日常生活中一样，我们希望有影响力的行为者能够考虑错误的后果。作为世界领先的科学期刊，《自然》杂志无疑是一个有影响力的行为者，特别是在缺乏健全全球AI监管的情况下。然而，它在这个案例中明显未能考虑到错误的代价。

    Does artificial intelligence (AI) pose existential risks to humanity? Some critics feel this question is getting too much attention, and want to push it aside in favour of conversations about the immediate risks of AI. These critics now include the journal Nature, where a recent editorial urges us to 'stop talking about tomorrow's AI doomsday when AI poses risks today.' We argue that this is a serious failure of judgement, on Nature's part. In science, as in everyday life, we expect influential actors to consider the consequences of error. As the world's leading scientific journal, Nature is certainly an influential actor, especially so in the absence of robust global regulation of AI. Yet it has manifestly failed to consider the cost of error in this case.
    
[^73]: AI在绿色移动计算中的两面性: 文献综述

    The Two Faces of AI in Green Mobile Computing: A Literature Review. (arXiv:2308.04436v1 [cs.AI])

    [http://arxiv.org/abs/2308.04436](http://arxiv.org/abs/2308.04436)

    这篇论文综述了在绿色移动计算领域使用人工智能的研究，并指出人工智能在移动设备中既是关键的功能实现者，又是能源消耗的主要来源。

    

    人工智能为移动设备带来了越来越多的功能，如相机和语音助手、推荐系统等，被认为是不可或缺的。然而，运行人工智能需要消耗大量能源。然而，人工智能也被用于实现更节能的移动系统解决方案。因此，从这个角度来看，人工智能有两个面向，它既是实现理想（高效）移动功能的关键，也是这些设备的主要能源消耗者，既是问题的一部分，也是解决方案的一部分。在本文中，我们对过去十年在绿色移动计算领域使用人工智能的文献进行了综述。通过分析34篇论文，我们总结出13个主要主题，并展示了该领域近年来的发展情况。

    Artificial intelligence is bringing ever new functionalities to the realm of mobile devices that are now considered essential (e.g., camera and voice assistants, recommender systems). Yet, operating artificial intelligence takes up a substantial amount of energy. However, artificial intelligence is also being used to enable more energy-efficient solutions for mobile systems. Hence, artificial intelligence has two faces in that regard, it is both a key enabler of desired (efficient) mobile functionalities and a major power draw on these devices, playing a part in both the solution and the problem. In this paper, we present a review of the literature of the past decade on the usage of artificial intelligence within the realm of green mobile computing. From the analysis of 34 papers, we highlight the emerging patterns and map the field into 13 main topics that are summarized in details.  Our results showcase that the field is slowly increasing in the past years, more specifically, since 2
    
[^74]: 企业协作系统的事件抽象以支持社会流程挖掘

    Event Abstraction for Enterprise Collaboration Systems to Support Social Process Mining. (arXiv:2308.04396v1 [cs.LG])

    [http://arxiv.org/abs/2308.04396](http://arxiv.org/abs/2308.04396)

    本论文提出了一种定制的企业协作系统的事件抽象方法，通过比较实际用户活动和系统生成的低级别跟踪来训练模型，并将低级别跟踪转换为抽象的高级别日志，以支持社会流程挖掘。

    

    流程挖掘的一个目标是从信息系统的事件日志中发现流程模型。流程挖掘已成功应用于面向流程的企业系统，但对于面向通信和文档的企业协作系统（ECS）来说不太适用。ECS事件日志非常细粒度，对其日志应用流程挖掘会导致混乱的模型。一个常见的解决方案是事件抽象，即在运行发现算法之前将低级别日志转换为更抽象的高级别日志。迄今为止，既有的事件抽象方法尚未完全解决ECS日志的特殊特征。我们旨在通过定制的ECS事件抽象（ECSEA）方法来弥补这一差距，该方法通过比较记录的实际用户活动（高级别跟踪）与系统生成的低级别跟踪（从ECS中提取）来训练模型。该模型使我们能够自动将未来的低级别跟踪转换为抽象的高级别日志。

    One aim of Process Mining (PM) is the discovery of process models from event logs of information systems. PM has been successfully applied to process-oriented enterprise systems but is less suited for communication- and document-oriented Enterprise Collaboration Systems (ECS). ECS event logs are very fine-granular and PM applied to their logs results in spaghetti models. A common solution for this is event abstraction, i.e., converting low-level logs into more abstract high-level logs before running discovery algorithms. ECS logs come with special characteristics that have so far not been fully addressed by existing event abstraction approaches. We aim to close this gap with a tailored ECS event abstraction (ECSEA) approach that trains a model by comparing recorded actual user activities (high-level traces) with the system-generated low-level traces (extracted from the ECS). The model allows us to automatically convert future low-level traces into an abstracted high-level log that can 
    
[^75]: 用大型语言模型进行累积推理的论文

    Cumulative Reasoning With Large Language Models. (arXiv:2308.04371v1 [cs.AI])

    [http://arxiv.org/abs/2308.04371](http://arxiv.org/abs/2308.04371)

    本文提出了一种名为累积推理（CR）的新方法，利用语言模型以累积和迭代的方式模拟人类思维过程，通过将任务分解为较小的组件，简化问题解决过程，取得了优于现有方法的性能，并在逻辑推理和24点游戏中实现了显著提升。

    

    虽然语言模型强大且多功能，但它们通常无法解决高度复杂的问题。这是因为解决复杂问题需要深思熟虑，而在训练过程中对此只有最小程度的指导。在本文中，我们提出了一种新方法，称为累积推理（CR），它以累积和迭代的方式利用语言模型来模拟人类的思维过程。通过将任务分解为较小的组件，我们的方法简化了问题解决过程，使其更易管理和更有效。对于逻辑推理任务，CR在性能上始终超过现有方法，提高了多达9.3％，并在经过策划的FOLIO维基数据集上实现了惊人的98.04％的准确率。在24点游戏的背景下，CR实现了94％的准确率，相比先前最先进的方法，提升了20％。

    While language models are powerful and versatile, they often fail to address highly complex problems. This is because solving complex problems requires deliberate thinking, which has been only minimally guided during training. In this paper, we propose a new method called Cumulative Reasoning (CR), which employs language models in a cumulative and iterative manner to emulate human thought processes. By decomposing tasks into smaller components, \ournameb streamlines the problem-solving process, rendering it both more manageable and effective. For logical inference tasks, CR consistently outperforms existing methods with an improvement up to 9.3\%, and achieves the astonishing accuracy of 98.04\% on the curated FOLIO wiki dataset. In the context of the Game of 24, CR achieves an accuracy of 94\%, which signifies a substantial enhancement of 20\% over the previous state-of-the-art method.
    
[^76]: Apple Vision Pro for Healthcare: “终极显示器”？（arXiv:2308.04313v1 [cs.AI]）

    Apple Vision Pro for Healthcare: "The Ultimate Display"?. (arXiv:2308.04313v1 [cs.AI])

    [http://arxiv.org/abs/2308.04313](http://arxiv.org/abs/2308.04313)

    苹果推出了Vision Pro，一款具有混合现实和增强现实功能的虚拟现实设备，拥有独特的特点，例如内部屏幕展示佩戴者的眼睛以及数字皇冠按钮的融合功能。这款无线设备可能实现了“终极显示器”的潜力。

    

    在2023年6月的全球开发者大会（WWDC）上，苹果推出了Vision Pro。Vision Pro是一款混合现实（MR）头盔，更具体地说，它是一款具有额外视频透视（VST）能力的虚拟现实（VR）设备。通过将真实世界通过摄像头传输到用户眼前的（VR）屏幕，使得Vision Pro也成为了增强现实（AR）设备。当然，这并不独特，与Varjo XR-3等其他设备类似。尽管如此，Vision Pro具有一些有趣的特点，例如内部屏幕可以向“外界”显示佩戴头盔者的眼睛，或者顶部的一个按钮称为“数字皇冠”，可以通过旋转无缝地融合数字内容与物理空间。此外，Vision Pro是无线的，只有电池的电缆连接，这使得头盔比Varjo XR-3更加灵活。这可能更接近“终极显示器”。

    At the Worldwide Developers Conference (WWDC) in June 2023, Apple introduced the Vision Pro. The Vision Pro is a Mixed Reality (MR) headset, more specifically it is a Virtual Reality (VR) device with an additional Video See-Through (VST) capability. The VST capability turns the Vision Pro also into an Augmented Reality (AR) device. The AR feature is enabled by streaming the real world via cameras to the (VR) screens in front of the user's eyes. This is of course not unique and similar to other devices, like the Varjo XR-3. Nevertheless, the Vision Pro has some interesting features, like an inside-out screen that can show the headset wearers' eyes to "outsiders" or a button on the top, called "Digital Crown", that allows you to seamlessly blend digital content with your physical space by turning it. In addition, it is untethered, except for the cable to the battery, which makes the headset more agile, compared to the Varjo XR-3. This could actually come closer to the "Ultimate Display",
    
[^77]: 使用结构化背景知识和演绎推理理解CNN隐藏神经元激活

    Understanding CNN Hidden Neuron Activations using Structured Background Knowledge and Deductive Reasoning. (arXiv:2308.03999v1 [cs.LG])

    [http://arxiv.org/abs/2308.03999](http://arxiv.org/abs/2308.03999)

    本文提供了一种使用结构化背景知识和演绎推理的方法，用于解释CNN隐藏神经元的激活。该方法能够提供有意义的解释，解决了深度学习系统黑盒特性的问题。

    

    Explainable AI中的一个主要挑战是准确解释隐藏神经元的激活：准确的解释将为深度学习系统内部检测到的输入相关内容提供洞察力，揭示深度学习系统的黑盒特性。现有技术表明，在某些情况下，隐藏节点的激活可以被人类理解，但是对隐藏神经元激活的解释进行假设和验证的系统化自动化方法尚未充分研究。在本文中，我们提供了这样一种方法，并证明它提供了有意义的解释。我们的方法基于使用大规模的背景知识，从维基百科概念层次结构中筛选出的约200万个类别，以及一个称为概念归纳的符号推理方法，这种方法最初是为语义Web领域的应用而开发的。

    A major challenge in Explainable AI is in correctly interpreting activations of hidden neurons: accurate interpretations would provide insights into the question of what a deep learning system has internally detected as relevant on the input, de-mystifying the otherwise black-box character of deep learning systems. The state of the art indicates that hidden node activations can, in some cases, be interpretable in a way that makes sense to humans, but systematic automated methods that would be able to hypothesize and verify interpretations of hidden neuron activations are underexplored. In this paper, we provide such a method and demonstrate that it provides meaningful interpretations. Our approach is based on using large-scale background knowledge approximately 2 million classes curated from the Wikipedia concept hierarchy together with a symbolic reasoning approach called Concept Induction based on description logics, originally developed for applications in the Semantic Web field. Ou
    
[^78]: ALFA - 利用各个层次的特征抽象来增强组织病理学图像分类在未知医院中的泛化能力

    ALFA -- Leveraging All Levels of Feature Abstraction for Enhancing the Generalization of Histopathology Image Classification Across Unseen Hospitals. (arXiv:2308.03936v1 [cs.CV])

    [http://arxiv.org/abs/2308.03936](http://arxiv.org/abs/2308.03936)

    ALFA使用各个层次的特征抽象来增强组织病理学图像分类在未知医院中的泛化能力，并通过自监督学习和域对齐实现了对不变特征的提取，以及对参与医院的高度特定特征的表示与分类。

    

    我们提出了一种全面的方法，利用各个层次的特征抽象，旨在提高图像分类在未知医院中的泛化能力。我们的方法结合了基于增强的自监督学习和病理学场景中的常见分布偏移作为前提任务。这使我们能够从训练图像中提取不变特征，而不依赖于训练标签，从而涵盖不同的抽象层次。在进一步的抽象层次上，我们利用域对齐模块来进一步提取在不同训练医院中的不变特征。为了表示参与医院的高度特定特征，我们训练了一个编码器来对医院标签进行分类，而不考虑诊断标签。然后，我们对来自每个编码器的特征进行解缠以最小化冗余并分离特征。这种表示涵盖了广泛的语义特征。

    We propose an exhaustive methodology that leverages all levels of feature abstraction, targeting an enhancement in the generalizability of image classification to unobserved hospitals. Our approach incorporates augmentation-based self-supervision with common distribution shifts in histopathology scenarios serving as the pretext task. This enables us to derive invariant features from training images without relying on training labels, thereby covering different abstraction levels. Moving onto the subsequent abstraction level, we employ a domain alignment module to facilitate further extraction of invariant features across varying training hospitals. To represent the highly specific features of participating hospitals, an encoder is trained to classify hospital labels, independent of their diagnostic labels. The features from each of these encoders are subsequently disentangled to minimize redundancy and segregate the features. This representation, which spans a broad spectrum of semanti
    
[^79]: 移动供应：推荐系统的最后一块拼图

    Mobile Supply: The Last Piece of Jigsaw of Recommender System. (arXiv:2308.03855v1 [cs.IR])

    [http://arxiv.org/abs/2308.03855](http://arxiv.org/abs/2308.03855)

    本研究提出了一种新的推荐系统模块，称为移动供应，旨在解决分页机制问题。通过在用户设备上部署推荐算法，可以有效减少数据传输延迟和提升用户的沉浸式体验。

    

    推荐系统是在线平台的基本功能。随着手机计算能力的发展，一些研究人员已经将推荐算法部署在用户设备上，以解决数据传输延迟和分页机制等问题。然而，现有的边缘端移动排名不能完全解决分页机制问题。移动排名只能对当前页面上的项目进行排序，所以如果只调用一两次是不起作用的。此外，在用户查看了当前页面上的感兴趣的项目后，用户会刷新页面获取新的项目。这会使移动排名模型做很多无用功，影响用户的沉浸式体验。为了解决分页机制问题，我们在推荐系统的流水线中提出了一个全新的模块，称为移动供应。

    Recommendation system is a fundamental functionality of online platforms. With the development of computing power of mobile phones, some researchers have deployed recommendation algorithms on users' devices to solve the problems of data transmission delay and pagination mechanism. However, the existing edge-side mobile rankings cannot completely solve the problem of pagination mechanism. The mobile rankings can only sort the items on the current page, so it will not work if it is called once or twice. Besides, after the user has viewed the items of interest to the user on the current page, the user refresh to get a new page of items. This will make the mobile ranking model do a lot of useless work and affect the user's immersive experience. In order to solve the pagination mechanism problem, we propose a completely new module in the pipeline of recommender named Mobile Supply. The pipeline of recommender system is extended to "retrival->pre-ranking->ranking->re-ranking->Mobile Supply->
    
[^80]: 用于具有大动作空间的离策略评估的双重稳健估计器

    Doubly Robust Estimator for Off-Policy Evaluation with Large Action Spaces. (arXiv:2308.03443v1 [stat.ML])

    [http://arxiv.org/abs/2308.03443](http://arxiv.org/abs/2308.03443)

    本文提出了一种用于具有大动作空间的离策略评估的双重稳健估计器（MDR）。与现有的基准估计器相比，MDR能够在减小方差的同时保持无偏性，从而提高了估计的准确性。实验结果证实了MDR相对于现有估计器的优越性。

    

    本文研究了在具有大动作空间的背景下的离策略评估（OPE）。现有的基准估计器存在严重的偏差和方差折衷问题。参数化方法由于很难确定正确的模型而导致偏差，而重要性加权方法由于方差而产生问题。为了克服这些限制，本文提出了基于判别式的不良行为抑制器（MIPS）来通过对动作的嵌入来减小估计器的方差。为了使估计器更准确，我们提出了MIPS的双重稳健估计器——边际化双重稳健（MDR）估计器。理论分析表明，所提出的估计器在比MIPS更弱的假设下是无偏的，同时保持了对IPS的方差减小，这是MIPS的主要优势。经验实验证实了MDR相对于现有估计器的优越性。

    We study Off-Policy Evaluation (OPE) in contextual bandit settings with large action spaces. The benchmark estimators suffer from severe bias and variance tradeoffs. Parametric approaches suffer from bias due to difficulty specifying the correct model, whereas ones with importance weight suffer from variance. To overcome these limitations, Marginalized Inverse Propensity Scoring (MIPS) was proposed to mitigate the estimator's variance via embeddings of an action. To make the estimator more accurate, we propose the doubly robust estimator of MIPS called the Marginalized Doubly Robust (MDR) estimator. Theoretical analysis shows that the proposed estimator is unbiased under weaker assumptions than MIPS while maintaining variance reduction against IPS, which was the main advantage of MIPS. The empirical experiment verifies the supremacy of MDR against existing estimators.
    
[^81]: 使用图神经网络和非极端熵在全球金融市场中进行异常检测

    Anomaly Detection in Global Financial Markets with Graph Neural Networks and Nonextensive Entropy. (arXiv:2308.02914v1 [cs.AI])

    [http://arxiv.org/abs/2308.02914](http://arxiv.org/abs/2308.02914)

    通过使用图神经网络和非极端熵，在全球金融市场中成功检测出了异常情况，发现了在危机期间高度相关的资产的复杂结构减少，并且不同的非极端熵参数在危机前、期间和后的异常数量存在统计上的差异

    

    异常检测是一个具有许多变量的系统中的一项具有挑战性的任务。异常是与分析数据在统计上不同的离群值，可能来自罕见事件、设备故障或系统滥用。本研究通过考虑由非极端熵衡量的不确定性场景，研究了使用图神经网络(GNN)在全球金融市场中检测异常的能力。主要发现表明，在危机期间高度相关的资产的复杂结构减少，不同的非极端熵参数在危机前、期间和后的异常数量在统计上存在差异。

    Anomaly detection is a challenging task, particularly in systems with many variables. Anomalies are outliers that statistically differ from the analyzed data and can arise from rare events, malfunctions, or system misuse. This study investigated the ability to detect anomalies in global financial markets through Graph Neural Networks (GNN) considering an uncertainty scenario measured by a nonextensive entropy. The main findings show that the complex structure of highly correlated assets decreases in a crisis, and the number of anomalies is statistically different for nonextensive entropy parameters considering before, during, and after crisis.
    
[^82]: 通过领域适应的最少到最多提示的方式实现文本到SQL的高效泛化

    Adapt and Decompose: Efficient Generalization of Text-to-SQL via Domain Adapted Least-To-Most Prompting. (arXiv:2308.02582v1 [cs.CL])

    [http://arxiv.org/abs/2308.02582](http://arxiv.org/abs/2308.02582)

    该论文介绍了一种通过领域适应和最少到最多提示的方式实现文本到SQL的高效泛化的方法。通过离线抽样获取少量样本，并合成一个通用提示，避免了昂贵的测试时间样本检索，并通过自适应和分解的方法更好地处理跨领域和跨组合式的泛化。

    

    跨领域和跨组合式的文本到SQL语义解析的泛化是一项具有挑战性的任务。现有的基于大型语言模型（LLM）的解决方案依赖于从训练集中推理出少量样本，以合成每个自然语言（NL）测试查询的运行时提示。与此相反，我们设计了一种算法，该算法通过离线抽样从训练数据中获取少量样本，完全覆盖SQL子句、运算符和函数，并在允许的令牌长度范围内实现最大领域覆盖。这样可以合成一个固定的通用提示（GP），其中包含NL测试查询之间共用的多样化样本集，避免了昂贵的测试时间样本检索。我们还将GP自适应到目标数据库领域（DA-GP），以更好地处理跨领域泛化；然后采用分解的最少到最多提示（LTMP-DA-GP）来处理跨组合泛化。LTMP-DA-GP的合成是离线任务，

    Cross-domain and cross-compositional generalization of Text-to-SQL semantic parsing is a challenging task. Existing Large Language Model (LLM) based solutions rely on inference-time retrieval of few-shot exemplars from the training set to synthesize a run-time prompt for each Natural Language (NL) test query. In contrast, we devise an algorithm which performs offline sampling of a minimal set-of few-shots from the training data, with complete coverage of SQL clauses, operators and functions, and maximal domain coverage within the allowed token length. This allows for synthesis of a fixed Generic Prompt (GP), with a diverse set-of exemplars common across NL test queries, avoiding expensive test time exemplar retrieval. We further auto-adapt the GP to the target database domain (DA-GP), to better handle cross-domain generalization; followed by a decomposed Least-To-Most-Prompting (LTMP-DA-GP) to handle cross-compositional generalization. The synthesis of LTMP-DA-GP is an offline task, to
    
[^83]: AutoML4ETC: 自动化神经架构搜索实现现实世界加密流量分类

    AutoML4ETC: Automated Neural Architecture Search for Real-World Encrypted Traffic Classification. (arXiv:2308.02182v1 [cs.NI])

    [http://arxiv.org/abs/2308.02182](http://arxiv.org/abs/2308.02182)

    AutoML4ETC是一个自动设计高效且高性能神经架构的工具，用于加密流量分类。其通过定义新颖的搜索空间和使用不同的搜索策略，在多个数据集上优于当前最先进的加密流量分类器。

    

    在实验环境中，深度学习（DL）已成功应用于加密网络流量分类。然而，在实际应用中，DL分类器的性能随时间不可避免地下降。仅仅对新数据集进行模型重新训练只能部分提高其性能。手动调整模型架构以满足新数据集上的性能期望耗时且需要领域专业知识。本文提出了一种新颖的工具AutoML4ETC，用于自动设计高效且高性能的神经架构以进行加密流量分类。我们定义了一个新颖而强大的搜索空间，专门针对使用数据包头字节进行近实时加密流量分类。通过在搜索空间上使用不同的搜索策略，我们展示了AutoML4ETC生成的神经架构在多个数据集上均优于当前最先进的加密流量分类器，包括公共基准数据集。

    Deep learning (DL) has been successfully applied to encrypted network traffic classification in experimental settings. However, in production use, it has been shown that a DL classifier's performance inevitably decays over time. Re-training the model on newer datasets has been shown to only partially improve its performance. Manually re-tuning the model architecture to meet the performance expectations on newer datasets is time-consuming and requires domain expertise. We propose AutoML4ETC, a novel tool to automatically design efficient and high-performing neural architectures for encrypted traffic classification. We define a novel, powerful search space tailored specifically for the near real-time classification of encrypted traffic using packet header bytes. We show that with different search strategies over our search space, AutoML4ETC generates neural architectures that outperform the state-of-the-art encrypted traffic classifiers on several datasets, including public benchmark dat
    
[^84]: 使用Floss增强周期性时间序列的表示学习：一种频域正则化方法

    Enhancing Representation Learning for Periodic Time Series with Floss: A Frequency Domain Regularization Approach. (arXiv:2308.01011v1 [cs.LG])

    [http://arxiv.org/abs/2308.01011](http://arxiv.org/abs/2308.01011)

    本文提出了一种叫做Floss的无监督方法，通过在频域上对学到的表示进行正则化来增强周期性时间序列的表示学习。Floss方法可以自动检测时间序列中的周期性并学习具有周期一致性的有意义的表示。

    

    时间序列分析是各个应用领域的基础任务，深度学习方法在这个领域表现出了非凡的性能。然而，许多现实世界的时间序列数据展现出重要的周期性或准周期性动态，这些动态往往不能被现有的基于深度学习的解决方案充分捕捉到。这导致对感兴趣的基础动态行为的表示不完整。为了解决这个问题，我们提出了一种无监督的方法叫做Floss，它通过自动化地在频域上调整学到的表示来进行正则化。Floss方法首先自动检测时间序列中的主要周期性。然后，它利用周期移位和谱密度相似度度量来学习具有周期一致性的有意义的表示。此外，Floss可以轻松地整合到有监督、半监督和无监督的学习框架中。

    Time series analysis is a fundamental task in various application domains, and deep learning approaches have demonstrated remarkable performance in this area. However, many real-world time series data exhibit significant periodic or quasi-periodic dynamics that are often not adequately captured by existing deep learning-based solutions. This results in an incomplete representation of the underlying dynamic behaviors of interest. To address this gap, we propose an unsupervised method called Floss that automatically regularizes learned representations in the frequency domain. The Floss method first automatically detects major periodicities from the time series. It then employs periodic shift and spectral density similarity measures to learn meaningful representations with periodic consistency. In addition, Floss can be easily incorporated into both supervised, semi-supervised, and unsupervised learning frameworks. We conduct extensive experiments on common time series classification, for
    
[^85]: ESP:利用对称性先验知识进行多Agent强化学习

    ESP: Exploiting Symmetry Prior for Multi-Agent Reinforcement Learning. (arXiv:2307.16186v1 [cs.MA])

    [http://arxiv.org/abs/2307.16186](http://arxiv.org/abs/2307.16186)

    本文提出了一种利用对称性先验知识的框架来解决多Agent强化学习中的数据效率问题，通过将数据增强和一致性损失集成到现有方法中，能够提高模型训练效率，并且泛化性能良好。

    

    近年来，多Agent强化学习（MARL）取得了令人期待的成果。然而，大多数现有的强化学习方法需要大量的数据进行模型训练。此外，数据高效的强化学习要求构建强大的归纳偏差，在当前的MARL方法中被忽视了。受多Agent系统中对称现象的启发，本文提出了一种框架，通过将数据增强和精心设计的一致性损失集成到现有的MARL方法中，来利用先验知识。此外，所提出的框架是模型无关的，可以应用于大多数当前的MARL算法。对多个具有挑战性的任务进行了实验测试，证明了所提出的框架的有效性。此外，将所提出的框架应用于一个物理多机器人实验平台，展示了它的优越性。

    Multi-agent reinforcement learning (MARL) has achieved promising results in recent years. However, most existing reinforcement learning methods require a large amount of data for model training. In addition, data-efficient reinforcement learning requires the construction of strong inductive biases, which are ignored in the current MARL approaches. Inspired by the symmetry phenomenon in multi-agent systems, this paper proposes a framework for exploiting prior knowledge by integrating data augmentation and a well-designed consistency loss into the existing MARL methods. In addition, the proposed framework is model-agnostic and can be applied to most of the current MARL algorithms. Experimental tests on multiple challenging tasks demonstrate the effectiveness of the proposed framework. Moreover, the proposed framework is applied to a physical multi-robot testbed to show its superiority.
    
[^86]: 用物理信知的神经网络解决维度诅咒问题

    Tackling the Curse of Dimensionality with Physics-Informed Neural Networks. (arXiv:2307.12306v1 [cs.LG])

    [http://arxiv.org/abs/2307.12306](http://arxiv.org/abs/2307.12306)

    本文提出了一种新方法，利用物理信知的神经网络(PINNs)解决高维度的偏微分方程(PDEs)问题，并证明了收敛性和其他期望属性。

    

    维度诅咒(CoD)随着维度的增加，以指数级增长的计算成本来极度税费计算资源。这在解决高维偏微分方程(PDEs)中面临极大挑战，正如Richard Bellman在60年前首次指出的那样。尽管近年来在高维度上数值解决偏微分方程(PDEs)取得了一些成功，但这样的计算代价过高，而将一般非线性PDEs扩展到高维度从未实现过。本文提出了一种新方法，将物理信知的神经网络(PINNs)扩展到解决任意高维PDEs。该新方法称为随机维度梯度下降(SDGD)，将PDE的梯度分解为与不同维度对应的部分，并在训练PINNs的每次迭代中随机选择这些维度部分的子集进行采样。我们在理论上证明了所提出方法的收敛保证和其他期望属性。

    The curse-of-dimensionality (CoD) taxes computational resources heavily with exponentially increasing computational cost as the dimension increases. This poses great challenges in solving high-dimensional PDEs as Richard Bellman first pointed out over 60 years ago. While there has been some recent success in solving numerically partial differential equations (PDEs) in high dimensions, such computations are prohibitively expensive, and true scaling of general nonlinear PDEs to high dimensions has never been achieved. In this paper, we develop a new method of scaling up physics-informed neural networks (PINNs) to solve arbitrary high-dimensional PDEs. The new method, called Stochastic Dimension Gradient Descent (SDGD), decomposes a gradient of PDEs into pieces corresponding to different dimensions and samples randomly a subset of these dimensional pieces in each iteration of training PINNs. We theoretically prove the convergence guarantee and other desired properties of the proposed meth
    
[^87]: 面向教育中人工智能协作混合论文的自动边界检测

    Towards Automatic Boundary Detection for Human-AI Collaborative Hybrid Essay in Education. (arXiv:2307.12267v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.12267](http://arxiv.org/abs/2307.12267)

    本研究探索了在教育领域中，由人类和生成性语言模型协作编写的混合文本的AI内容检测方法，将其形式化为识别转换点的任务，以区分人类编写和AI生成的部分。

    

    最近的大型语言模型（如ChatGPT）能够在提供具体指导的情况下生成类似于人类的流畅回答。尽管承认技术进步带来的便利，教育者也担心学生可能利用语言模型来完成写作任务并将其假冒为自己的原创作品。虽然有很多AI内容检测研究是基于这些担忧进行的，但大多数之前的研究将AI内容检测建模为一个分类问题，假设一个文本要么完全由人类编写，要么完全由AI生成。在本研究中，我们研究了AI内容检测在一个少有探索但却现实的情况下，即检测的文本由人类和生成性语言模型（即混合文本）协作编写。我们首先将检测任务形式化为从给定的混合文本中识别人类编写内容和AI生成内容之间的转换点（边界检测）。

    The recent large language models (LLMs), e.g., ChatGPT, have been able to generate human-like and fluent responses when provided with specific instructions. While admitting the convenience brought by technological advancement, educators also have concerns that students might leverage LLMs to complete their writing assignments and pass them off as their original work. Although many AI content detection studies have been conducted as a result of such concerns, most of these prior studies modeled AI content detection as a classification problem, assuming that a text is either entirely human-written or entirely AI-generated. In this study, we investigated AI content detection in a rarely explored yet realistic setting where the text to be detected is collaboratively written by human and generative LLMs (i.e., hybrid text). We first formalized the detection task as identifying the transition points between human-written content and AI-generated content from a given hybrid text (boundary det
    
[^88]: MSQNet: 无关演员的多模态动作识别

    MSQNet: Actor-agnostic Action Recognition with Multi-modal Query. (arXiv:2307.10763v1 [cs.CV])

    [http://arxiv.org/abs/2307.10763](http://arxiv.org/abs/2307.10763)

    MSQNet是一种无关演员的多模态多标签动作识别方法，通过使用视觉和文本模态来更好地表示动作类别，克服了现有方法中针对特定演员的限制。

    

    现有的动作识别方法通常是针对特定演员的，因为演员之间具有固有的拓扑和显着差异。这就需要特定演员的姿态估计（例如人类与动物），导致模型设计复杂性和高维护成本。此外，它们通常只关注学习视觉模态和单标签分类，忽视了其他可用信息源（例如类名文本）和多个动作的同时发生。为了克服这些限制，我们提出了一种新的方法，称为“无关演员的多模态多标签动作识别”，为包括人类和动物在内的各种类型的演员提供了统一的解决方案。我们进一步在基于Transformer的目标检测框架（例如DETR）中提出了一种新颖的多模态语义查询网络（MSQNet）模型，通过利用视觉和文本模态更好地表示动作类别。消除了演员特定性的限制。

    Existing action recognition methods are typically actor-specific due to the intrinsic topological and apparent differences among the actors. This requires actor-specific pose estimation (e.g., humans vs. animals), leading to cumbersome model design complexity and high maintenance costs. Moreover, they often focus on learning the visual modality alone and single-label classification whilst neglecting other available information sources (e.g., class name text) and the concurrent occurrence of multiple actions. To overcome these limitations, we propose a new approach called 'actor-agnostic multi-modal multi-label action recognition,' which offers a unified solution for various types of actors, including humans and animals. We further formulate a novel Multi-modal Semantic Query Network (MSQNet) model in a transformer-based object detection framework (e.g., DETR), characterized by leveraging visual and textual modalities to represent the action classes better. The elimination of actor-spec
    
[^89]: RL-ViGen: 一种用于视觉泛化的强化学习基准

    RL-ViGen: A Reinforcement Learning Benchmark for Visual Generalization. (arXiv:2307.10224v1 [cs.AI])

    [http://arxiv.org/abs/2307.10224](http://arxiv.org/abs/2307.10224)

    RL-ViGen是一种用于视觉泛化的强化学习基准，包含多样的任务和广泛的泛化类型，旨在推动对代理人视觉泛化能力的全面评估。

    

    视觉强化学习（Visual RL）与高维观察相结合，一直面临着长期存在的泛化挑战。尽管有重点研究用于解决视觉泛化问题的算法，但我们认为现有的基准存在问题，因为它们局限于孤立的任务和泛化类别，从而削弱了对代理人视觉泛化能力的全面评估。为了弥合这一差距，我们引入了RL-ViGen：一种新型的用于视觉泛化的强化学习基准，其中包含多样的任务和广泛的泛化类型，从而促进得出更可靠的结论。此外，RL-ViGen将最新的泛化视觉强化学习算法融入到一个统一的框架中，实验结果表明，没有单一的现有算法在所有任务上普遍占优势。我们的愿景是RL-ViGen将在这个领域起到催化剂的作用。

    Visual Reinforcement Learning (Visual RL), coupled with high-dimensional observations, has consistently confronted the long-standing challenge of generalization. Despite the focus on algorithms aimed at resolving visual generalization problems, we argue that the devil is in the existing benchmarks as they are restricted to isolated tasks and generalization categories, undermining a comprehensive evaluation of agents' visual generalization capabilities. To bridge this gap, we introduce RL-ViGen: a novel Reinforcement Learning Benchmark for Visual Generalization, which contains diverse tasks and a wide spectrum of generalization types, thereby facilitating the derivation of more reliable conclusions. Furthermore, RL-ViGen incorporates the latest generalization visual RL algorithms into a unified framework, under which the experiment results indicate that no single existing algorithm has prevailed universally across tasks. Our aspiration is that RL-ViGen will serve as a catalyst in this a
    
[^90]: 一种风险厌恶策略梯度的方差替代：基尼离差

    An Alternative to Variance: Gini Deviation for Risk-averse Policy Gradient. (arXiv:2307.08873v1 [cs.LG])

    [http://arxiv.org/abs/2307.08873](http://arxiv.org/abs/2307.08873)

    本研究提出了一种风险厌恶策略梯度的替代方法，通过使用基尼离差来替代方差，缓解了方差方法的局限性，并在实证评估中取得了高回报和低风险的成果。

    

    在风险厌恶的强化学习中，限制策略回报的方差是一种常见选择，因为它具有明确的数学定义和易于解释。传统方法直接限制总回报方差，而最近的方法通过限制每步奖励方差作为代理。本文彻底研究了这些基于方差的方法的局限性，如数字尺度的敏感性和阻碍策略学习，并提出使用替代风险衡量标准——基尼离差。我们研究了这种新风险衡量标准的各种属性，并导出了一种用于最小化基尼离差的策略梯度算法。在风险厌恶可以明确定义的领域进行实证评估时，我们的算法可以缓解基于方差的风险衡量标准的局限性，并在其他策略无法学到合理策略时实现高回报和低风险，以方差和基尼离差度量。

    Restricting the variance of a policy's return is a popular choice in risk-averse Reinforcement Learning (RL) due to its clear mathematical definition and easy interpretability. Traditional methods directly restrict the total return variance. Recent methods restrict the per-step reward variance as a proxy. We thoroughly examine the limitations of these variance-based methods, such as sensitivity to numerical scale and hindering of policy learning, and propose to use an alternative risk measure, Gini deviation, as a substitute. We study various properties of this new risk measure and derive a policy gradient algorithm to minimize it. Empirical evaluation in domains where risk-aversion can be clearly defined, shows that our algorithm can mitigate the limitations of variance-based risk measures and achieves high return with low risk in terms of variance and Gini deviation when others fail to learn a reasonable policy.
    
[^91]: INFLECT-DGNN: 动态图神经网络进行影响者预测

    INFLECT-DGNN: Influencer Prediction with Dynamic Graph Neural Networks. (arXiv:2307.08131v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2307.08131](http://arxiv.org/abs/2307.08131)

    INFLECT-DGNN是一个结合了图神经网络和递归神经网络的框架，使用加权损失函数、针对图数据适应的合成少数过采样技术和滚动窗口策略，用于影响者预测。实验结果显示，使用RNN来编码时间属性和GNN显著提高了预测性能。

    

    在许多领域中，利用网络信息进行预测建模已经变得非常普遍。在推荐和定向营销领域中，影响者检测是一个可以通过动态网络表示大大受益的领域，原因是不断发展的客户-品牌关系。为了阐述这一思想，我们引入了INFLECT-DGNN，这是一个使用加权损失函数的图神经网络（GNN）和递归神经网络（RNN），针对图数据适应的合成少数过采样技术（SMOTE）以及精心设计的滚动窗口策略的新框架。为了评估预测性能，我们利用一个包含三个城市网络的独特企业数据集，并制定了一个以利润为驱动的影响者预测评估方法。我们的结果表明，使用RNN来编码时间属性以及GNN显著改善了预测性能。

    Leveraging network information for predictive modeling has become widespread in many domains. Within the realm of referral and targeted marketing, influencer detection stands out as an area that could greatly benefit from the incorporation of dynamic network representation due to the ongoing development of customer-brand relationships. To elaborate this idea, we introduce INFLECT-DGNN, a new framework for INFLuencer prEdiCTion with Dynamic Graph Neural Networks that combines Graph Neural Networks (GNN) and Recurrent Neural Networks (RNN) with weighted loss functions, the Synthetic Minority Oversampling TEchnique (SMOTE) adapted for graph data, and a carefully crafted rolling-window strategy. To evaluate predictive performance, we utilize a unique corporate data set with networks of three cities and derive a profit-driven evaluation methodology for influencer prediction. Our results show how using RNN to encode temporal attributes alongside GNNs significantly improves predictive perform
    
[^92]: AutoHint: 自动提示生成与优化的新框架

    AutoHint: Automatic Prompt Optimization with Hint Generation. (arXiv:2307.07415v1 [cs.CL])

    [http://arxiv.org/abs/2307.07415](http://arxiv.org/abs/2307.07415)

    本文介绍了AutoHint，一种用于大型语言模型的自动提示生成和优化的新框架。该方法通过从输入-输出演示中生成提示，并利用上下文学习和零样本学习的优点，优化原始提示，从而提高了大型语言模型在特定任务上的表现。

    

    本文提出了AutoHint，一种用于大型语言模型（LLM）的自动提示工程和优化的新框架。虽然LLM在各种任务中展示了出色的注释能力，但将此能力应用于特定任务的关键在于开发高质量的提示。因此，我们提出了一种框架，通过将从输入-输出演示中派生的丰富指导纳入原始提示，以继承上下文学习和零样本学习的优点。我们将这种丰富称为“提示”，并提出了一种从标记数据中自动生成提示的框架。具体而言，从一个初始提示开始，我们的方法首先指导LLM从错误预测中推断出选定样本的新提示，然后从每个样本的提示中进行总结，并将结果添加回初始提示，形成一个新的丰富指导。该方法在BIG-Bench指令推导任务上进行了评估。

    This paper presents AutoHint, a novel framework for automatic prompt engineering and optimization for Large Language Models (LLM). While LLMs have demonstrated remarkable ability in achieving high-quality annotation in various tasks, the key to applying this ability to specific tasks lies in developing high-quality prompts. Thus we propose a framework to inherit the merits of both in-context learning and zero-shot learning by incorporating enriched instructions derived from input-output demonstrations to optimize original prompt. We refer to the enrichment as the hint and propose a framework to automatically generate the hint from labeled data. More concretely, starting from an initial prompt, our method first instructs a LLM to deduce new hints for selected samples from incorrect predictions, and then summarizes from per-sample hints and adds the results back to the initial prompt to form a new, enriched instruction. The proposed method is evaluated on the BIG-Bench Instruction Induct
    
[^93]: 一种新型的与平台无关的多模态深度学习模型，用于识别社交媒体上的促进饮食紊乱内容

    A Novel Site-Agnostic Multimodal Deep Learning Model to Identify Pro-Eating Disorder Content on Social Media. (arXiv:2307.06775v1 [cs.LG])

    [http://arxiv.org/abs/2307.06775](http://arxiv.org/abs/2307.06775)

    本研究创建了一个多模态深度学习模型，将文本和视觉数据相结合，能够准确识别社交媒体上的促进饮食紊乱的内容。最有效的模型是RoBERTa自然语言处理模型和MaxViT图像分类模型的融合模型，准确率和F1分数分别达到95.9%和0.959。

    

    在过去的十年中，饮食紊乱的诊断和与之相关的死亡数量大幅增加，尤其是在新冠疫情期间。这种巨大增长部分来源于疫情的压力，但也与社交媒体的暴露增加有关，社交媒体上充斥着促进饮食紊乱的内容。这些内容可以诱发观看者的饮食紊乱。本研究旨在创建一个多模态深度学习模型，能够基于视觉和文本数据的组合判断给定的社交媒体帖子是否促进饮食紊乱。从Twitter收集了一个带有标签的推文数据集，对其进行了十二个深度学习模型的训练和测试。根据模型的性能，最有效的深度学习模型是RoBERTa自然语言处理模型和MaxViT图像分类模型的多模态融合模型，准确率和F1分数分别达到95.9%和0.959。RoBERTa和MaxViT融合模型可以有效地识别社交媒体上的促进饮食紊乱的内容。

    Over the last decade, there has been a vast increase in eating disorder diagnoses and eating disorder-attributed deaths, reaching their zenith during the Covid-19 pandemic. This immense growth derived in part from the stressors of the pandemic but also from increased exposure to social media, which is rife with content that promotes eating disorders. Such content can induce eating disorders in viewers. This study aimed to create a multimodal deep learning model capable of determining whether a given social media post promotes eating disorders based on a combination of visual and textual data. A labeled dataset of Tweets was collected from Twitter, upon which twelve deep learning models were trained and tested. Based on model performance, the most effective deep learning model was the multimodal fusion of the RoBERTa natural language processing model and the MaxViT image classification model, attaining accuracy and F1 scores of 95.9% and 0.959 respectively. The RoBERTa and MaxViT fusion
    
[^94]: 一项关于时间序列的图神经网络综述：预测、分类、插值和异常检测

    A Survey on Graph Neural Networks for Time Series: Forecasting, Classification, Imputation, and Anomaly Detection. (arXiv:2307.03759v1 [cs.LG])

    [http://arxiv.org/abs/2307.03759](http://arxiv.org/abs/2307.03759)

    这项综述介绍了图神经网络在时间序列分析中的应用，包括预测、分类、异常检测和插值。图神经网络能够显式地建模时间序列和变量之间的关系，为时间序列数据分析带来了新的方法和技术。

    

    时间序列是记录动态系统测量结果的主要数据类型，通过物理传感器和在线过程（虚拟传感器）生成大量数据。时间序列分析对于揭示可用数据中所蕴含的丰富信息至关重要。随着图神经网络（GNN）的最新进展，基于GNN的时间序列分析方法也大幅增加。这些方法能够显式地建模时间序列和变量之间的关系，而传统和其他深度神经网络方法则面临困难。在本综述中，我们提供了一份全面的基于图神经网络的时间序列分析综述（GNN4TS），包括四个基本维度：预测、分类、异常检测和插值。我们旨在指导设计师和实践者了解、构建应用和推动GNN4TS的研究。首先，我们提供了一个全面的面向任务的GNN4TS分类体系。接下来，我们展示了...

    Time series are the primary data type used to record dynamic system measurements and generated in great volume by both physical sensors and online processes (virtual sensors). Time series analytics is therefore crucial to unlocking the wealth of information implicit in available data. With the recent advancements in graph neural networks (GNNs), there has been a surge in GNN-based approaches for time series analysis. Approaches can explicitly model inter-temporal and inter-variable relationships, which traditional and other deep neural network-based methods struggle to do. In this survey, we provide a comprehensive review of graph neural networks for time series analysis (GNN4TS), encompassing four fundamental dimensions: Forecasting, classification, anomaly detection, and imputation. Our aim is to guide designers and practitioners to understand, build applications, and advance research of GNN4TS. At first, we provide a comprehensive task-oriented taxonomy of GNN4TS. Then, we present a
    
[^95]: 虚假黎明：重新评估谷歌强化学习在芯片宏观布局中的应用

    The False Dawn: Reevaluating Google's Reinforcement Learning for Chip Macro Placement. (arXiv:2306.09633v1 [cs.LG])

    [http://arxiv.org/abs/2306.09633](http://arxiv.org/abs/2306.09633)

    谷歌2021年在《自然》杂志上发表的一篇论文声称其使用强化学习在芯片设计领域进行了创新，但两项独立的评估表明，谷歌的方法不如人类设计师、不如一个众所周知的算法（模拟退火），并且也不如普遍可用的商业软件，文章的完整性也遭到了严重的损害。

    

    谷歌2021年在《自然》杂志上发表的有关使用强化学习设计芯片的论文，因为所声称的结果缺乏充分的文件记录和关键步骤的说明，引发争议并受到媒体的批评报道。 而两项独立的评估填补了空白，证明谷歌强化学习落后于人类设计师、落后于一种众所周知的算法（模拟退火），并且还落后于普遍可用的商业软件。交叉检查的数据表明，由于行为、分析和报告中的错误，该《自然》文章的完整性受到了严重的损害。

    Reinforcement learning (RL) for physical design of silicon chips in a Google 2021 Nature paper stirred controversy due to poorly documented claims that raised eyebrows and attracted critical media coverage. The Nature paper withheld most inputs needed to produce reported results and some critical steps in the methodology. But two independent evaluations filled in the gaps and demonstrated that Google RL lags behind human designers, behind a well-known algorithm (Simulated Annealing), and also behind generally-available commercial software. Crosschecked data indicate that the integrity of the Nature paper is substantially undermined owing to errors in the conduct, analysis and reporting.
    
[^96]: Diff-TTSG: 去噪概率集成语音和手势合成

    Diff-TTSG: Denoising probabilistic integrated speech and gesture synthesis. (arXiv:2306.09417v1 [eess.AS])

    [http://arxiv.org/abs/2306.09417](http://arxiv.org/abs/2306.09417)

    Diff-TTSG是第一个基于扩散的概率模型，用于联合学习合成语音和手势，相比于先前最新技术的非概率方法，它可以更好地捕捉人类讲话和运动的变化，产生更逼真和多样化的集成语音和手势合成。

    

    随着朗读语音合成实现高自然度评分，越来越多的研究开始关注合成自然言语。然而，人类面对面的自发对话既有口头的，也有非语言的（例如，共同言语手势）。最近才开始研究联合合成这两种模态在一个单一的系统中的好处。先前的最新技术使用非概率方法，无法捕捉人类讲话和运动的变化，并可能产生过度平滑的伪影和次优的合成质量。我们提出了第一个基于扩散的概率模型，称为 Diff-TTSG，共同学习合成语音和手势。我们的方法可以从头开始使用小型数据集进行训练。此外，我们描述了一组小心的单模态和多模态主观测试，用于评估集成语音和手势合成系统，并用它们来验证我们提出的方法。对于合成的样例而言，Diff-TTSG优于先前的最新技术，产生更逼真和多样化的集成语音和手势合成。

    With read-aloud speech synthesis achieving high naturalness scores, there is a growing research interest in synthesising spontaneous speech. However, human spontaneous face-to-face conversation has both spoken and non-verbal aspects (here, co-speech gestures). Only recently has research begun to explore the benefits of jointly synthesising these two modalities in a single system. The previous state of the art used non-probabilistic methods, which fail to capture the variability of human speech and motion, and risk producing oversmoothing artefacts and sub-optimal synthesis quality. We present the first diffusion-based probabilistic model, called Diff-TTSG, that jointly learns to synthesise speech and gestures together. Our method can be trained on small datasets from scratch. Furthermore, we describe a set of careful uni- and multi-modal subjective tests for evaluating integrated speech and gesture synthesis systems, and use them to validate our proposed approach. For synthesised examp
    
[^97]: 高效连续控制的时间分层架构

    Temporally Layered Architecture for Efficient Continuous Control. (arXiv:2305.18701v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2305.18701](http://arxiv.org/abs/2305.18701)

    这项研究提出了一种时间分层架构，利用时间抽象实现了高效的连续控制，具有节能、持续探索、减少决策、减少抖动和增加动作重复等优势。

    

    我们提出了一种时间分层架构（TLA），用于具有最小能量消耗的时间自适应控制。TLA将快速策略和慢速策略层叠在一起，实现时间抽象，使每个层可以专注于不同的时间尺度。我们的设计借鉴了人脑的节能机制，根据环境需求在不同的时间尺度上执行动作。我们证明了TLA除了节能之外，还提供了许多额外的优势，包括持续探索、减少需求决策、减少抖动和增加动作重复。我们在一系列连续控制任务上评估了我们的方法，并展示了TLA在多个重要指标上相对于现有方法的显著优势。我们还引入了多目标评分来定性评估连续控制策略，并展示了TLA具有显著更好的评分。我们的训练算法在慢速策略和

    We present a temporally layered architecture (TLA) for temporally adaptive control with minimal energy expenditure. The TLA layers a fast and a slow policy together to achieve temporal abstraction that allows each layer to focus on a different time scale. Our design draws on the energy-saving mechanism of the human brain, which executes actions at different timescales depending on the environment's demands. We demonstrate that beyond energy saving, TLA provides many additional advantages, including persistent exploration, fewer required decisions, reduced jerk, and increased action repetition. We evaluate our method on a suite of continuous control tasks and demonstrate the significant advantages of TLA over existing methods when measured over multiple important metrics. We also introduce a multi-objective score to qualitatively assess continuous control policies and demonstrate a significantly better score for TLA. Our training algorithm uses minimal communication between the slow and
    
[^98]: 改进零样本基于草图的图像检索的自适应和对齐方法

    Adapt and Align to Improve Zero-Shot Sketch-Based Image Retrieval. (arXiv:2305.05144v1 [cs.CV])

    [http://arxiv.org/abs/2305.05144](http://arxiv.org/abs/2305.05144)

    本文针对零样本基于草图图像检索的跨域和语义问题，提出了一种自适应和对齐的方法，通过插入简单且轻量的域适配器重新学习草图领域的新抽象概念，并通过明确对齐学习到的图像嵌入以提高跨域表示能力。

    

    零样本基于草图的图像检索(ZS-SBIR)由于草图和照片之间的跨域本质以及已知和未知图像分布之间的语义差距而具有挑战性。先前的方法使用各种辅助信息和学习策略微调预训练模型，以学习一个紧凑的特征空间，该空间 (\romannumeral 1)在草图和照片领域之间共享，(\romannumeral 2) 桥接已知和未知类别。然而，这些努力在适应领域和从已知类别传递知识方面不足。本文提出了一种有效的“自适应和对齐”方法来解决关键问题。具体而言，我们插入简单且轻量的域适配器，以学习草图领域的新的抽象概念，并提高跨域表示能力。受到最近在零样本场景下图像-文本基础模型(CLIP)的进展启发，我们明确地将学习到的图像嵌入与模型明确对齐。

    Zero-shot sketch-based image retrieval (ZS-SBIR) is challenging due to the cross-domain nature of sketches and photos, as well as the semantic gap between seen and unseen image distributions. Previous methods fine-tune pre-trained models with various side information and learning strategies to learn a compact feature space that (\romannumeral1) is shared between the sketch and photo domains and (\romannumeral2) bridges seen and unseen classes. However, these efforts are inadequate in adapting domains and transferring knowledge from seen to unseen classes. In this paper, we present an effective \emph{``Adapt and Align''} approach to address the key challenges. Specifically, we insert simple and lightweight domain adapters to learn new abstract concepts of the sketch domain and improve cross-domain representation capabilities. Inspired by recent advances in image-text foundation models (\textit{e.g.}, CLIP) on zero-shot scenarios, we explicitly align the learned image embedding with a mo
    
[^99]: 特征工程能帮助量子机器学习进行恶意软件检测吗？

    Can Feature Engineering Help Quantum Machine Learning for Malware Detection?. (arXiv:2305.02396v1 [cs.LG])

    [http://arxiv.org/abs/2305.02396](http://arxiv.org/abs/2305.02396)

    本文通过量子机器学习与特征选择策略相结合的混合框架，以降低恶意软件分类器培训时间，初步结果表明在模拟器上可以达到78.91％的测试准确性。

    

    随着恶意软件攻击数量和复杂度的增加，基于机器学习（ML）的恶意软件检测系统变得越来越重要。同时，许多用于恶意软件分类的流行ML模型都是有监督学习。这些有监督分类器通常对新型恶意软件的推广效果不好。因此，需要经常重新训练它们以检测新的恶意软件样本，这可能非常耗时。本文通过理论量子ML与特征选择策略相结合的混合框架来解决这个问题，以降低数据大小和恶意软件分类器培训时间。初步结果表明，使用XGBoost选择的特征的VQC在模拟器上可以获得78.91％的测试准确性。使用XGBoost选择的特征训练的模型在IBM 5 qubits机器上的平均准确性为74％（+-11.35％）。

    With the increasing number and sophistication of malware attacks, malware detection systems based on machine learning (ML) grow in importance. At the same time, many popular ML models used in malware classification are supervised solutions. These supervised classifiers often do not generalize well to novel malware. Therefore, they need to be re-trained frequently to detect new malware specimens, which can be time-consuming. Our work addresses this problem in a hybrid framework of theoretical Quantum ML, combined with feature selection strategies to reduce the data size and malware classifier training time. The preliminary results show that VQC with XGBoost selected features can get a 78.91% test accuracy on the simulator. The average accuracy for the model trained using the features selected with XGBoost was 74% (+- 11.35%) on the IBM 5 qubits machines.
    
[^100]: DiverseVul: 基于深度学习漏洞检测的新漏洞源代码数据集

    DiverseVul: A New Vulnerable Source Code Dataset for Deep Learning Based Vulnerability Detection. (arXiv:2304.00409v1 [cs.CR])

    [http://arxiv.org/abs/2304.00409](http://arxiv.org/abs/2304.00409)

    这个论文提供了一个包含150个CWE的新的漏洞源代码数据集，覆盖比以前所有数据集加起来多305个项目。作者通过增加训练数据的多样性和数量改进了深度学习模型在漏洞检测方面的表现。通过结合已有数据集，作者还研究了使用深度学习检测软件漏洞的挑战和前途的分析，结果表明目前深度学习检测漏洞仍存在高误报率，低F1分数和难以检测严重CWE的问题。

    

    我们提出并发布了一个新的漏洞源代码数据集。我们通过爬取安全问题网站，提取相应项目的漏洞修复提交和源代码，筛选出了这个数据集。我们的新数据集包含了150个CWE，26,635个易受攻击的函数和352,606个不易受攻击的函数，提取自7,861个提交。我们的数据集覆盖了比以前所有数据集加起来多305个项目。我们展示了增加训练数据的多样性和数量可以提高深度学习模型在漏洞检测方面的表现。结合我们的新数据集和以前的数据集，我们提出了使用深度学习检测软件漏洞的挑战和有前途的研究方向的分析。我们研究了11个模型架构，属于4个家族。我们的结果表明，由于高误报率，低F1分数和难以检测严重CWE，深度学习仍未准备好用于漏洞检测。特别是，我们展示了......

    We propose and release a new vulnerable source code dataset. We curate the dataset by crawling security issue websites, extracting vulnerability-fixing commits and source codes from the corresponding projects. Our new dataset contains 150 CWEs, 26,635 vulnerable functions, and 352,606 non-vulnerable functions extracted from 7,861 commits. Our dataset covers 305 more projects than all previous datasets combined. We show that increasing the diversity and volume of training data improves the performance of deep learning models for vulnerability detection.  Combining our new dataset with previous datasets, we present an analysis of the challenges and promising research directions of using deep learning for detecting software vulnerabilities. We study 11 model architectures belonging to 4 families. Our results show that deep learning is still not ready for vulnerability detection, due to high false positive rate, low F1 score, and difficulty of detecting hard CWEs. In particular, we demonst
    
[^101]: 基于深度学习的时间序列因果推断量化北极放大的原因

    Quantifying Causes of Arctic Amplification via Deep Learning based Time-series Causal Inference. (arXiv:2303.07122v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.07122](http://arxiv.org/abs/2303.07122)

    该研究提出了一种基于循环神经网络的时间序列因果推断模型TCINet，用于推断大气过程对海冰融化的因果效应。通过实验证明，该模型能够显著提高量化北极海冰融化的主要原因的能力。

    

    北极变暖，也称北极放大，由多种大气和海洋因素导致，但其基础热力因素的详细情况仍不清楚。使用固定治疗效应策略推断大气过程对海冰融化的因果效应会导致不现实的反事实估计。这样的模型也容易受到时间变化的混淆的影响而引起偏差。为了解决这些挑战，我们提出了TCINet - 一种基于循环神经网络的时间序列因果推断模型，以连续治疗方式推断因果关系。通过对合成和观测数据的实验，我们展示了我们的研究如何大大提高量化北极海冰融化的主要原因的能力。

    The warming of the Arctic, also known as Arctic amplification, is led by several atmospheric and oceanic drivers, however, the details of its underlying thermodynamic causes are still unknown. Inferring the causal effects of atmospheric processes on sea ice melt using fixed treatment effect strategies leads to unrealistic counterfactual estimations. Such models are also prone to bias due to time-varying confoundedness. In order to tackle these challenges, we propose TCINet - time-series causal inference model to infer causation under continuous treatment using recurrent neural networks. Through experiments on synthetic and observational data, we show how our research can substantially improve the ability to quantify the leading causes of Arctic sea ice melt.
    
[^102]: 将神经衰竭引入到固定的等角紧框架中，以减少错误严重程度

    Inducing Neural Collapse to a Fixed Hierarchy-Aware Frame for Reducing Mistake Severity. (arXiv:2303.05689v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.05689](http://arxiv.org/abs/2303.05689)

    本文提出了一种将神经衰竭引入到固定的层次感知框架中的方法，通过学习层次感知的倒数第二特征，并将其坍缩到框架上，来减少模型预测的错误严重程度。

    

    最近发现了一种有趣的现象，称为神经衰竭：在训练深度神经网络进行分类的末期阶段，所有平坦类的倒数第二特征均值和相关的分类器向量都会坍缩到一个简单的等角紧框架（ETF）的顶点上。近期的研究尝试利用这一现象，通过将相关的分类器权重固定为预先计算得到的ETF来引发神经衰竭，并在使用不平衡数据进行训练时最大化所学特征之间的分离度。在本文中，我们提出将深度神经网络的线性分类器固定为按层次结构设计的框架（HAFrame），而不是ETF，并使用基于余弦相似度的辅助损失来学习坍缩到HAFrame的层次感知的倒数第二特征。我们证明了我们的方法在保持模型在多个具有层次结构的数据集上的top-1准确率的同时，降低了模型预测的错误严重程度。

    There is a recently discovered and intriguing phenomenon called Neural Collapse: at the terminal phase of training a deep neural network for classification, the within-class penultimate feature means and the associated classifier vectors of all flat classes collapse to the vertices of a simplex Equiangular Tight Frame (ETF). Recent work has tried to exploit this phenomenon by fixing the related classifier weights to a pre-computed ETF to induce neural collapse and maximize the separation of the learned features when training with imbalanced data. In this work, we propose to fix the linear classifier of a deep neural network to a Hierarchy-Aware Frame (HAFrame), instead of an ETF, and use a cosine similarity-based auxiliary loss to learn hierarchy-aware penultimate features that collapse to the HAFrame. We demonstrate that our approach reduces the mistake severity of the model's predictions while maintaining its top-1 accuracy on several datasets of varying scales with hierarchies of he
    
[^103]: 大规模语言模型生成推理的成本效益超参数优化

    Cost-Effective Hyperparameter Optimization for Large Language Model Generation Inference. (arXiv:2303.04673v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.04673](http://arxiv.org/abs/2303.04673)

    本文研究了优化大规模语言模型生成推理的成本效益超参数，通过经济的超参数优化和基于成本的修剪，提出了EcoOptiGen框架，该框架在使用GPT-3.5/GPT-4模型的任务中表现出有效性。

    

    大规模语言模型（LLM）在其生成能力方面引起了广泛关注，从而推动了各种商业应用的发展。使用这些模型的高成本驱使应用程序构建者在有限的推理预算下最大化生成价值。本文提出了一项关于优化推理超参数（如回复数量、温度和最大token数）的研究，这显著影响了文本生成的效用/成本。我们设计了一个名为EcoOptiGen的框架，它利用经济的超参数优化和基于成本的修剪。通过在各种任务上使用GPT-3.5/GPT-4模型进行实验，验证了其有效性。EcoOptiGen已在FLAML库的`autogen'包中实现：\url{https://aka.ms/autogen}。

    Large Language Models (LLMs) have sparked significant interest in their generative capabilities, leading to the development of various commercial applications. The high cost of using the models drives application builders to maximize the value of generation under a limited inference budget. This paper presents a study of optimizing inference hyperparameters such as the number of responses, temperature and max tokens, which significantly affects the utility/cost of text generation. We design a framework named EcoOptiGen which leverages economical hyperparameter optimization and cost-based pruning. Experiments with the GPT-3.5/GPT-4 models on a variety of tasks verify its effectiveness. EcoOptiGen is implemented in the `autogen' package of the FLAML library: \url{https://aka.ms/autogen}.
    
[^104]: 一个适用于知识图谱的通用问答平台

    A Universal Question-Answering Platform for Knowledge Graphs. (arXiv:2303.00595v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.00595](http://arxiv.org/abs/2303.00595)

    本文提出了KGQAn，一个通用的问答系统，它无需针对每个目标知识图谱进行定制。通过新颖的形式化方法，将问题转换为中间的抽象表示，从而实现了将自然语言问题转换为SPARQL查询的目标。

    

    知识图谱是以RDF引擎存储的来自不同应用领域的知识。通过SPARQL端点可以在Web上访问知识图谱。为了正确表达一个符合规范的SPARQL查询，需要了解图结构和其组成部分的确切URI，这对于普通用户来说是不现实的。问答系统通过将自然语言问题转换为SPARQL来提供帮助。现有的问答系统通常基于应用特定的人工策略，或者需要先验信息、昂贵的预处理和模型调整来适配每个目标知识图谱。因此，它们很难推广到广泛的应用和知识图谱。本文提出了KGQAn，一个不需要针对每个目标知识图谱进行定制的通用问答系统。KGQAn不使用人工策略，而是将问题理解作为一个文本生成问题来进行新颖的形式化，通过神经序列到序列模型将问题转换为中间的抽象表示。

    Knowledge from diverse application domains is organized as knowledge graphs (KGs) that are stored in RDF engines accessible in the web via SPARQL endpoints. Expressing a well-formed SPARQL query requires information about the graph structure and the exact URIs of its components, which is impractical for the average user. Question answering (QA) systems assist by translating natural language questions to SPARQL. Existing QA systems are typically based on application-specific human-curated rules, or require prior information, expensive pre-processing and model adaptation for each targeted KG. Therefore, they are hard to generalize to a broad set of applications and KGs.  In this paper, we propose KGQAn, a universal QA system that does not need to be tailored to each target KG. Instead of curated rules, KGQAn introduces a novel formalization of question understanding as a text generation problem to convert a question into an intermediate abstract representation via a neural sequence-to-se
    
[^105]: 深度学习综述：从激活函数到Transformer

    A Survey of Deep Learning: From Activations to Transformers. (arXiv:2302.00722v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.00722](http://arxiv.org/abs/2302.00722)

    这篇综述调查了深度学习领域的重要进展，包括各种架构、层、目标和优化技术的发展，以及关注机制、归一化、跳跃连接、Transformer和自监督学习等方法的变体。总结了成功创新的关键策略，并讨论了最近的商业闭源模型。

    

    过去十年中，深度学习取得了显著的进展，得益于各种架构、层、目标和优化技术的涌现。这些包括关注机制、归一化、跳跃连接、Transformer和自监督学习等多种变体方法。我们的目标是向具有深度学习基本理解的人提供对这些领域中最新重要贡献的全面调查。我们的期望是通过对重要最新作品的综合和全面的探讨，促进不同深度学习领域之间形成新的联系。在我们的讨论中，我们总结了过去十年中许多成功创新的关键策略。我们还对最近一些商业闭源模型进行了讨论，例如OpenAI的GPT-4和Google的PaLM 2。

    The past decade has witnessed remarkable advancements in deep learning, owing to the emergence of various architectures, layers, objectives, and optimization techniques. These consist of a multitude of variations of attention, normalization, skip connections, transformer, and self-supervised learning methods, among others. Our goal is to furnish a comprehensive survey of significant recent contributions in these domains to individuals with a fundamental grasp of deep learning. Our aspiration is that an integrated and comprehensive approach of influential recent works will facilitate the formation of new connections between different areas of deep learning. In our discussion, we discuss multiple patterns that summarize the key strategies for many of the successful innovations over the last decade. We also include a discussion on recent commercially built, closed-source models such as OpenAI's GPT-4 and Google's PaLM 2.
    
[^106]: 模型美食：多样模型的回收利用以实现超出分布的泛化

    Model Ratatouille: Recycling Diverse Models for Out-of-Distribution Generalization. (arXiv:2212.10445v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.10445](http://arxiv.org/abs/2212.10445)

    本论文提出了一种名为模型美食的新策略，通过回收基于同一基础模型在多样辅助任务上的多次微调，实现了在目标任务上的超出分布的泛化能力。通过利用辅助任务的多样性，这种策略旨在最大限度地提高模型权重的多样性。

    

    基础模型正在重新定义AI系统的构建方式。从一个预训练的基础模型开始，从业者现在都遵循一个标准的流程来构建他们的机器学习解决方案：在目标任务上微调权重。因此，互联网上充斥着许多在不同任务上微调的基础模型：这些单独的微调过程存在孤立，没有相互受益。在我们看来，这是一个被忽视的机会，因为这些专门的模型包含丰富多样的特征。因此，在本文中，我们提出了模型美食，这是一种在不同辅助任务上回收相同基础模型的多个微调的新策略。具体而言，我们将这些辅助权重重新用于目标任务上的多个并行微调的初始化；然后，我们对所有微调后的权重取平均值，得到最终模型。这种回收策略旨在通过利用辅助任务的多样性来最大化权重的多样性。

    Foundation models are redefining how AI systems are built. Practitioners now follow a standard procedure to build their machine learning solutions: from a pre-trained foundation model, they fine-tune the weights on the target task of interest. So, the Internet is swarmed by a handful of foundation models fine-tuned on many diverse tasks: these individual fine-tunings exist in isolation without benefiting from each other. In our opinion, this is a missed opportunity, as these specialized models contain rich and diverse features. In this paper, we thus propose model ratatouille, a new strategy to recycle the multiple fine-tunings of the same foundation model on diverse auxiliary tasks. Specifically, we repurpose these auxiliary weights as initializations for multiple parallel fine-tunings on the target task; then, we average all fine-tuned weights to obtain the final model. This recycling strategy aims at maximizing the diversity in weights by leveraging the diversity in auxiliary tasks.
    
[^107]: RaLiBEV: 雷达和激光雷达的引导框自由物体检测系统的融合学习

    RaLiBEV: Radar and LiDAR BEV Fusion Learning for Anchor Box Free Object Detection System. (arXiv:2211.06108v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.06108](http://arxiv.org/abs/2211.06108)

    本论文提出了一种基于鸟瞰视角的引导框自由物体检测系统，通过雷达和激光雷达的特征融合学习，解决了在恶劣天气下物体检测的问题。

    

    在自动驾驶系统中，激光雷达和雷达在感知周围环境中起着重要作用。激光雷达提供精确的三维空间感知信息，但在雾等恶劣天气下无法工作。另一方面，雷达信号由于波长的特性在遇到雨滴或雾粒时会发生衍射，但它受到大噪声的干扰。最近的最新研究表明，雷达和激光雷达的融合可以在恶劣天气下实现强健的检测。现有的方法采用卷积神经网络架构从每个传感器数据流中提取特征，然后对齐和汇聚两个分支的特征以预测物体检测结果。然而，由于标签分配和融合策略的简单设计，这些方法对边界框估计的准确性较低。在本文中，我们提出了一种基于鸟瞰视角融合学习的引导框自由物体检测系统，该系统将来自雷达的距离-方位特征融合起来

    In autonomous driving systems, LiDAR and radar play important roles in the perception of the surrounding environment. LiDAR provides accurate 3D spatial sensing information but cannot work in adverse weather like fog. On the other hand, the radar signal can be diffracted when encountering raindrops or mist particles thanks to its wavelength, but it suffers from large noise. Recent state-of-the-art works reveal that fusion of radar and LiDAR can lead to robust detection in adverse weather. The existing works adopt convolutional neural network architecture to extract features from each sensor data stream, then align and aggregate the two branch features to predict object detection results. However, these methods have low accuracy of bounding box estimations due to a simple design of label assignment and fusion strategies. In this paper, we propose a bird's-eye view fusion learning-based anchor box-free object detection system, which fuses the feature derived from the radar range-azimuth 
    
[^108]: 插入后门元素的文本编码器对文本生成图像的影响

    Rickrolling the Artist: Injecting Backdoors into Text Encoders for Text-to-Image Synthesis. (arXiv:2211.02408v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.02408](http://arxiv.org/abs/2211.02408)

    本文证明了文本生成图像模型中使用的文本编码器存在重大的篡改风险，并提出了一种基于反向门攻击的方法，可以插入一个单一字符触发器进提示中，从而触发模型生成具有预定义属性的图像或遵循隐藏的、潜在的恶意描述的图像。

    

    尽管文本生成图像技术在研究者和公众中越来越受欢迎，但这些模型的安全性一直被忽视。许多文本生成图像模型依赖于外部来源的预训练文本编码器，并且它们的用户相信检索到的模型会像承诺的那样运行。不幸的是，这可能不是这种情况。我们引入了反向门攻击文本引导的生成模型，并证明它们的文本编码器构成了重大的篡改风险。我们的攻击只是轻微地改变了编码器，使得对于带有干净提示的图像生成没有可疑的模型行为。然后，通过将一个单一字符触发器插入提示中，例如一个非拉丁字符或表情符号，攻击者就可以触发模型生成具有预定义属性的图像或遵循隐藏的、潜在的恶意描述的图像。我们在Stable Diffusion和highligh上经验性地证明了我们攻击的高效性。

    While text-to-image synthesis currently enjoys great popularity among researchers and the general public, the security of these models has been neglected so far. Many text-guided image generation models rely on pre-trained text encoders from external sources, and their users trust that the retrieved models will behave as promised. Unfortunately, this might not be the case. We introduce backdoor attacks against text-guided generative models and demonstrate that their text encoders pose a major tampering risk. Our attacks only slightly alter an encoder so that no suspicious model behavior is apparent for image generations with clean prompts. By then inserting a single character trigger into the prompt, e.g., a non-Latin character or emoji, the adversary can trigger the model to either generate images with pre-defined attributes or images following a hidden, potentially malicious description. We empirically demonstrate the high effectiveness of our attacks on Stable Diffusion and highligh
    
[^109]: 一次性神经场用于3D对象理解

    One-Shot Neural Fields for 3D Object Understanding. (arXiv:2210.12126v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2210.12126](http://arxiv.org/abs/2210.12126)

    本文提出了一种一次性神经场方法，用于机器人学中的3D对象理解。这种方法利用单个RGB图像构建统一而紧凑的场景表示，可以用于多个任务，如新视角渲染、3D重建、碰撞检查和稳定抓取预测。研究结果表明，这种方法能够从新视角进行渲染并预测成功的抓取。

    

    我们提出了一种用于机器人学的统一且紧凑的场景表示方法，其中场景中的每个对象由捕捉几何和外观的潜在代码来描述。这种表示方法可以解码用于各种任务，例如新视角渲染，3D重建（例如恢复深度，点云或体素图），碰撞检查和稳定抓取预测。我们利用最新的神经辐射场（NeRF）在测试时从单个RGB输入图像构建我们的表示方法，该方法在大型多视图数据集上学习类别级先验知识，然后在少数或仅一个视图的新对象上进行微调。我们扩展了NeRF模型以获得额外的抓取输出，并探索了利用这种表示方法用于机器人学的方法。在测试时，我们从仅一个视点观察到的单个RGB输入图像构建表示方法。我们发现恢复的表示方法允许从新视角进行渲染，包括遮挡的物体部分，并且可以预测成功的抓取。

    We present a unified and compact scene representation for robotics, where each object in the scene is depicted by a latent code capturing geometry and appearance. This representation can be decoded for various tasks such as novel view rendering, 3D reconstruction (e.g. recovering depth, point clouds, or voxel maps), collision checking, and stable grasp prediction. We build our representation from a single RGB input image at test time by leveraging recent advances in Neural Radiance Fields (NeRF) that learn category-level priors on large multiview datasets, then fine-tune on novel objects from one or few views. We expand the NeRF model for additional grasp outputs and explore ways to leverage this representation for robotics. At test-time, we build the representation from a single RGB input image observing the scene from only one viewpoint. We find that the recovered representation allows rendering from novel views, including of occluded object parts, and also for predicting successful 
    
[^110]: 安全和协安全语言的一阶逻辑特征

    A first-order logic characterization of safety and co-safety languages. (arXiv:2209.02307v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.02307](http://arxiv.org/abs/2209.02307)

    本论文提出了一些新的语言类型和算法，可以降低模型检测和反应合成等问题的复杂度。

    

    线性时间逻辑（LTL）是最受欢迎的时间逻辑之一，广泛应用于计算机科学的各个领域。LTL的强大基础性质之一是其等价于无计数ω-自动机、星自由ω-正则表达式以及（通过Kamp定理）线性序的一阶理论（FO-TLO）。安全语言和协安全语言分别指只需有限前缀便可确定该单词属于或不属于该语言的语言类型。SafetyLTL（和coSafetyLTL）是LTL的一个片段，其中仅允许使用全局（存在）时间修饰词来识别安全（协安全）语言。本文的主要贡献是引入FO-TLO的片段SafetyFO以及其对偶的coSafetyFO，它们在表达能力上都是完备的（except一些边界情况）。

    Linear Temporal Logic (LTL) is one of the most popular temporal logics, that comes into play in a variety of branches of computer science. Among the various reasons of its widespread use there are its strong foundational properties: LTL is equivalent to counter-free omega-automata, to star-free omega-regular expressions, and (by Kamp's theorem) to the First-Order Theory of Linear Orders (FO-TLO). Safety and co-safety languages, where a finite prefix suffices to establish whether a word does not belong or belongs to the language, respectively, play a crucial role in lowering the complexity of problems like model checking and reactive synthesis for LTL. SafetyLTL (resp., coSafetyLTL) is a fragment of LTL where only universal (resp., existential) temporal modalities are allowed, that recognises safety (resp., co-safety) languages only. The main contribution of this paper is the introduction of a fragment of FO-TLO, called SafetyFO, and of its dual coSafetyFO, which are expressively comple
    
[^111]: BoMD：适用于嘈杂X光分类的多标签描述符包

    BoMD: Bag of Multi-label Descriptors for Noisy Chest X-ray Classification. (arXiv:2203.01937v3 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2203.01937](http://arxiv.org/abs/2203.01937)

    本文提出了一种适用于多标签、嘈杂CXR学习的方法，使用基于袋的多标签描述符平滑地重新标记数据集中的样本，并进行训练以提高模型性能。

    

    深度学习方法在医学图像问题的分类精度方面表现出色，这在很大程度上归功于具有清洁标签的大规模数据集的可用性。然而，考虑到这种手动注释的高成本，新的医学图像分类问题可能需要依赖于从放射学报告中提取的机器生成的嘈杂标签。事实上，许多胸部X光分类器已经从带有嘈杂标签的数据集中建模，但它们的训练过程通常不具有噪声标签样本的鲁棒性，导致次优模型。此外，CXR数据集大多是多标记的，因此当前设计用于多类问题的嘈杂标签学习方法不能轻松地进行调整。本文提出了一种新方法，用于嘈杂多标签CXR学习，其中检测并平滑地重新标记数据集中的样本，然后用于训练常见的多标签分类器。该方法优化了一个基于袋的多标签表示方法，以便有效地使用从放射学报告中提取的信息。

    Deep learning methods have shown outstanding classification accuracy in medical imaging problems, which is largely attributed to the availability of large-scale datasets manually annotated with clean labels. However, given the high cost of such manual annotation, new medical imaging classification problems may need to rely on machine-generated noisy labels extracted from radiology reports. Indeed, many Chest X-ray (CXR) classifiers have already been modelled from datasets with noisy labels, but their training procedure is in general not robust to noisy-label samples, leading to sub-optimal models. Furthermore, CXR datasets are mostly multi-label, so current noisy-label learning methods designed for multi-class problems cannot be easily adapted. In this paper, we propose a new method designed for the noisy multi-label CXR learning, which detects and smoothly re-labels samples from the dataset, which is then used to train common multi-label classifiers. The proposed method optimises a ba
    

