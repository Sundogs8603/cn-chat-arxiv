# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [LipsFormer: Introducing Lipschitz Continuity to Vision Transformers.](http://arxiv.org/abs/2304.09856) | 本文介绍了一种Lipschitz连续的Transformer模型LipsFormer，其中引入了多项Lipschitz连续的组件来保证训练的稳定性，并在实验证明其可以让深度Transformer架构稳定进行训练，无需过多调整学习率等参数。 |
| [^2] | [Learning and Adapting Agile Locomotion Skills by Transferring Experience.](http://arxiv.org/abs/2304.09834) | 通过经验迁移和强化学习，该论文提出一种训练复杂机器人运动技能的框架，并克服了在高度欠驱动系统中进行探索的障碍。 |
| [^3] | [Fairness in AI and Its Long-Term Implications on Society.](http://arxiv.org/abs/2304.09826) | 本文探讨了AI的公平性问题，指出缺乏AI公平性会加深偏见成为社会压力因素，可能对社会产生长期影响，因此需要寻求潜在解决方案。 |
| [^4] | [Using Offline Data to Speed-up Reinforcement Learning in Procedurally Generated Environments.](http://arxiv.org/abs/2304.09825) | 本研究旨在提高程序生成环境中强化学习的样本效率。研究证明，使用模仿学习进行预训练和同时进行模仿学习和在线强化学习的方法可以提高效率。 |
| [^5] | [The Future of ChatGPT-enabled Labor Market: A Preliminary Study.](http://arxiv.org/abs/2304.09823) | 本研究从人工智能协作的角度，通过分析大规模职位发布数据及基于职业知识图谱开发的协同过滤算法，预测了ChatGPT对未来劳动力市场的影响，发现目前约28％的职业需要ChatGPT相关技能。 |
| [^6] | [Leveraging Deep Reinforcement Learning for Metacognitive Interventions across Intelligent Tutoring Systems.](http://arxiv.org/abs/2304.09821) | 本研究比较了两种方法来提供元认知干预，并发现基于深度强化学习的自适应干预能够缩小学生之间的元认知技能差距。 |
| [^7] | [A Two-Stage Framework with Self-Supervised Distillation For Cross-Domain Text Classification.](http://arxiv.org/abs/2304.09820) | 本文提出了一种双阶段框架，使用自监督蒸馏和来自不同但相关源领域的标记数据完成跨领域文本分类，取得在单源领域适应性和多源领域适应性上的新的最先进结果。 |
| [^8] | [On the Perception of Difficulty: Differences between Humans and AI.](http://arxiv.org/abs/2304.09803) | 有效的人机交互系统需要准确反映人类和人工智能代理在实现有价值的结果时的知觉难度，目前研究尚未充分探讨两者之间的差异。 |
| [^9] | [End-to-End Policy Gradient Method for POMDPs and Explainable Agents.](http://arxiv.org/abs/2304.09769) | 本文提出了一种使用端到端训练估计POMDP中隐藏状态并可视化为状态转移图的RL算法，实验结果表明该算法可以解决简单问题并且代理的行为可解释。 |
| [^10] | [An innovative Deep Learning Based Approach for Accurate Agricultural Crop Price Prediction.](http://arxiv.org/abs/2304.09761) | 本文提出了一种基于深度学习的方法，利用历史价格信息、气候条件、土壤类型、地理位置和其他关键决策因素，精确预测农产品价格。该方法使用图神经网络和卷积神经网络相结合，适用于有噪声的历史数据，并且表现至少比现有文献中的结果好20%。 |
| [^11] | [Skeleton-based action analysis for ADHD diagnosis.](http://arxiv.org/abs/2304.09751) | 提出一种基于骨架的动作识别框架用于注意力缺陷多动障碍的诊断，其显示出成本效益和显著的性能改进，是一种低成本的初始ADHD诊断方法。 |
| [^12] | [Reference-based Image Composition with Sketch via Structure-aware Diffusion Model.](http://arxiv.org/abs/2304.09748) | 该论文提出了一种利用素描进行图像合成的方法，允许用户通过所需的结构和内容对图像的子部分进行编辑或完成。该方法采用预训练的扩散模型来完成缺失的区域并维持素描的引导，为图像操作提供了独特的用例。 |
| [^13] | [Rehabilitation Exercise Repetition Segmentation and Counting using Skeletal Body Joints.](http://arxiv.org/abs/2304.09735) | 本研究提出了一种通过骨架身体关节点实现患者康复运动重复分割和计数的方法，可克服传感器难以使用和隐私问题的困境。 |
| [^14] | [Sample-efficient Model-based Reinforcement Learning for Quantum Control.](http://arxiv.org/abs/2304.09718) | 本论文提出了一种基于模型的强化学习方法，通过受到神经常微分方程进展的启发，这个方法采用自动微分的ODE表达由可学习的汉密尔顿安排参数化的模型来近似环境，在门控制和汉密尔顿参数的学习中通过系统交互解决问题。该方法在样本复杂度方面比标准基于模型自由的强化学习方法具有一个数量级的优势，适用于噪声时变门优化。 |
| [^15] | [Autonomous Agent for Beyond Visual Range Air Combat: A Deep Reinforcement Learning Approach.](http://arxiv.org/abs/2304.09669) | 本论文基于深度强化学习理论，致力于开发一款能够在超视距空战中执行任务的智能代理人,通过计算奖励，不断学习和提高自身在空战中的表现，并期望生成以前从未出现过的空战策略，最终测试真正的飞行员与训练代理人在相同环境下的表现差异，为空中防御任务提高飞行员的表现做出贡献。 |
| [^16] | [GeneGPT: Teaching Large Language Models to Use NCBI Web APIs.](http://arxiv.org/abs/2304.09667) | GeneGPT通过少量NCBI API调用URL请求作为演示，教授大型语言模型使用NCBI Web API回答基因组问题，并在GeneTuring测试中达到了优异的结果。 |
| [^17] | [ReelFramer: Co-creating News Reels on Social Media with Generative AI.](http://arxiv.org/abs/2304.09653) | ReelFramer使用生成式人工智能与社交媒体共同创作新闻片段。它可以帮助记者探索一个故事的多种叙事框架，并生成脚本、角色板和故事板。用户研究发现该系统大大减轻了将一篇书面报道转化为新闻片段的负担。 |
| [^18] | [Quantum deep Q learning with distributed prioritized experience replay.](http://arxiv.org/abs/2304.09648) | 本论文提出了 QDQN-DPER 框架，它将分布式优先经验回放和异步训练纳入算法，以提高量子强化学习在解决顺序决策任务中的效率。 |
| [^19] | [The Krohn-Rhodes Logics.](http://arxiv.org/abs/2304.09639) | 本篇论文提出了一组新的时间逻辑，通过使用Krohn和Rhodes的级联理论，扩展了过去的LTL表达能力，其中包括可以捕获其他prime automata的新的时间运算符。 |
| [^20] | [StyleDEM: a Versatile Model for Authoring Terrains.](http://arxiv.org/abs/2304.09626) | StyleDEM是一种通用的地形创作模型，它具有多种风格的工具箱，可以通过交互式笔刷进行创作和增强，使其非常适合娱乐行业的设计师。 |
| [^21] | [MMDR: A Result Feature Fusion Object Detection Approach for Autonomous System.](http://arxiv.org/abs/2304.09609) | MMDR是一种新的多模态融合方法，利用了来自单模态源的结果特征，能够更好地表示深层特征。同时，MMDR模型结合了单模态源的浅层和深层特征，从而进一步提高了检测精度。 |
| [^22] | [LEA: Beyond Evolutionary Algorithms via Learned Optimization Strategy.](http://arxiv.org/abs/2304.09599) | LEA是一种适应性强且能够有效利用目标任务低保真度信息的学习进化算法，从而比传统进化算法在更少的计算成本下获得更好的解决方案。 |
| [^23] | [An Ecosystem for Personal Knowledge Graphs: A Survey and Research Roadmap.](http://arxiv.org/abs/2304.09572) | 本论文提出了一个个人知识图谱（PKG）的生态系统，PKG的主要目的是数据管理和个性化服务。要解锁PKG的全部潜力，需要一个统一的框架，并提出了一个关于PKG的综合视图。 |
| [^24] | [SemEval 2023 Task 6: LegalEval -- Understanding Legal Texts.](http://arxiv.org/abs/2304.09548) | SemEval 2023举办了LegalEval共享任务，即理解法律文本，包括 自动结构化和语义连贯化的法律文件（Task-A），法律命名实体识别（Task-B）以及自动预测法律案件结果和提供预测解释（Task-C）。26个团队提交了系统论文并在所有子任务中优于基准线，但仍有改进空间。 |
| [^25] | [SelfAct: Personalized Activity Recognition based on Self-Supervised and Active Learning.](http://arxiv.org/abs/2304.09530) | SelfAct是一种基于自我监督和主动学习的人体活动识别框架，可以用大量未标记数据进行预训练，并通过新的无监督主动学习策略进行微调，从而实现对每个用户的个性化活动识别。 |
| [^26] | [NetGPT: Generative Pretrained Transformer for Network Traffic.](http://arxiv.org/abs/2304.09513) | 本文提出了首个网络流量生成预训练变压器模型NetGPT，该模型可以优化网络任务的训练效率和有效性。 |
| [^27] | [Biologically inspired structure learning with reverse knowledge distillation for spiking neural networks.](http://arxiv.org/abs/2304.09500) | 本文提出了一种基于进化的结构构建方法用于构建更合理的脉冲神经网络。通过结合知识蒸馏和连接剪枝方法，动态优化突触连接可以达到最优状态。 |
| [^28] | [Emotion fusion for mental illness detection from social media: A survey.](http://arxiv.org/abs/2304.09493) | 本文为全面综述通过分析社交媒体上用户生成的文章来使用情感信息进行心理疾病检测的方法。文章回顾了不同的融合策略及其优缺点，并讨论了该领域研究人员所面临的挑战和未来的研究方向。 |
| [^29] | [Rank-Based Learning and Local Model Based Evolutionary Algorithm for High-Dimensional Expensive Multi-Objective Problems.](http://arxiv.org/abs/2304.09444) | 本文提出了一种基于排名学习和局部模型的多目标进化算法，该算法使用分类器进行排名，以解决高维昂贵多目标优化问题。 |
| [^30] | [Local object crop collision network for efficient simulation of non-convex objects in GPU-based simulators.](http://arxiv.org/abs/2304.09439) | 提出了一种数据驱动的碰撞检测方法，用于高效模拟非凸物体，不需要在计算速度和准确性之间进行权衡，具有较小的在线计算时间和更好的GPU利用率。 |
| [^31] | [Martingale Posterior Neural Processes.](http://arxiv.org/abs/2304.09431) | 本文提出了一种基于鞅后验的神经过程方法，用于估计使用神经网络隐式定义的随机过程，并在 benchmark 数据集上表现出更高的精度和样本效率。 |
| [^32] | [Loss minimization yields multicalibration for large neural networks.](http://arxiv.org/abs/2304.09424) | 本文展示了对于大型神经网络大小，最优地最小化损失会导致多校准，以提供公平的预测结果。 |
| [^33] | [Pointerformer: Deep Reinforced Multi-Pointer Transformer for the Traveling Salesman Problem.](http://arxiv.org/abs/2304.09407) | Pointerformer是一种端到端DRL算法，采用多指针Transformer算法来解决旅行商问题。它使用可逆残差网络和多指针网络来控制内存消耗，使用深度Q网络来指导解码器，是目前在大规模TSP实例上取得最先进效果的方法。 |
| [^34] | [H-TSP: Hierarchically Solving the Large-Scale Travelling Salesman Problem.](http://arxiv.org/abs/2304.09395) | 我们提出了一种称为H-TSP的基于层次强化学习的端到端学习框架，它通过联合训练上下层策略，直接生成给定TSP实例的解决方案，而不需要依赖于任何耗时的搜索过程。我们在随机生成的TSP实例上进行的实验表明，H-TSP可以获得可比较的结果（与其他最先进方法之间的间隙为3.42% vs. 7.3%），而在具有2000个以上节点的实例上则胜过其他方法。 |
| [^35] | [Inferring High-level Geographical Concepts via Knowledge Graph and Multi-scale Data Integration: A Case Study of C-shaped Building Pattern Recognition.](http://arxiv.org/abs/2304.09391) | 本文提出了一种通过知识图谱和多尺度数据集成识别C型建筑模式的方法，提高了模式识别的效率和有效性。 |
| [^36] | [An Empirical Study of Leveraging Knowledge Distillation for Compressing Multilingual Neural Machine Translation Models.](http://arxiv.org/abs/2304.09388) | 本文研究了利用知识蒸馏方法压缩多语言神经机器翻译模型的实证效果，并以印地语到英语的翻译为案例展示了蒸馏方法对模型大小和性能的影响。研究发现，深层紧凑模型往往与浅层非紧凑模型一样好，将蒸馏模型在高质量子集上微调可以提高翻译质量。 |
| [^37] | [Investigating the Nature of 3D Generalization in Deep Neural Networks.](http://arxiv.org/abs/2304.09358) | 本论文研究了深度学习架构对新视图推广的能力，发现深度模型具有很好的推广能力，但它们的方式与所有现有模型不同。 |
| [^38] | [Optimizing Carbon Storage Operations for Long-Term Safety.](http://arxiv.org/abs/2304.09352) | 本文提出使用信念状态规划来优化注入器和监测井位置，在确保安全的情况下最大化CO2储存效果。实验结果表明该方法有效，同时还引入了神经网络代理模型来处理决策过程的复杂动态。 |
| [^39] | [LLM as A Robotic Brain: Unifying Egocentric Memory and Control.](http://arxiv.org/abs/2304.09349) | 本文提出了一个统一自我中心记忆和控制的框架LLM-Brain，使用大规模语言模型作为机器人大脑进行零-shot学习。该框架包括封闭式多轮对话，覆盖了感知、规划、控制和记忆，具有很好的泛化性能，适用于多个机器人任务。 |
| [^40] | [Promptify: Text-to-Image Generation through Interactive Prompt Exploration with Large Language Models.](http://arxiv.org/abs/2304.09337) | Promptify是一种基于大型语言模型的互动系统，用于优化文本到图像生成模型的提示探索和优化。该系统通过建议引擎快速探索和创作样式多样的提示，而用户可以通过反馈循环迭代地优化他们的提示，以增强所期望的特征并避免不需要的特征。 |
| [^41] | [Towards Spatio-temporal Sea Surface Temperature Forecasting via Static and Dynamic Learnable Personalized Graph Convolution Network.](http://arxiv.org/abs/2304.09290) | 该论文提出了基于静态和动态可学习个性化图卷积网络的时空海表温度预测方法，其中利用两个图学习层分别模型化了SST数据的固定网络和动态网络，并设计了个性化的图卷积网络层以精确预测时空变化。实验结果显示，该方法在预测准确度方面优于目前最先进的方法。 |
| [^42] | [Integrity and Junkiness Failure Handling for Embedding-based Retrieval: A Case Study in Social Network Search.](http://arxiv.org/abs/2304.09287) | 本文提出了解决基于嵌入式检索的社交网络搜索中完整性和垃圾性问题的有效方法，其中包括索引处理和针对性用户分组处理等。这些方法表现出了良好的结果。 |
| [^43] | [Pelphix: Surgical Phase Recognition from X-ray Images in Percutaneous Pelvic Fixation.](http://arxiv.org/abs/2304.09285) | 本文提出了一种名为Pelphix的X光引导下的经皮盆骨折修复手术阶段识别方法，使用马尔科夫过程模拟过程并提供完全注释的训练数据，在四个粒度级别上回归手术阶段，并取得了很好的准确率。 |
| [^44] | [A Data Driven Sequential Learning Framework to Accelerate and Optimize Multi-Objective Manufacturing Decisions.](http://arxiv.org/abs/2304.09278) | 本文提出了一种利用序列学习来高效优化多个相互冲突目标的复杂系统的数据驱动贝叶斯优化框架。 |
| [^45] | [A Neural Lambda Calculus: Neurosymbolic AI meets the foundations of computing and functional programming.](http://arxiv.org/abs/2304.09276) | 本文提出了一种神经λ演算法，使用λ语言编程，研究神经网络在执行整个程序的能力，旨在拓展神经网络在符号人工智能领域的应用。 |
| [^46] | [The Metaverse: Survey, Trends, Novel Pipeline Ecosystem & Future Directions.](http://arxiv.org/abs/2304.09240) | 本文介绍了元宇宙的概述、趋势和未来发展方向。通过适当的指导和方向，元宇宙的发展将会给技术、游戏、教育、艺术和文化领域带来更多的益处。本文提出了一个多层次的流程生态系统，旨在提供关于元宇宙的全面、跨学科、深入的研究。 |
| [^47] | [A Deep Learning Framework for Traffic Data Imputation Considering Spatiotemporal Dependencies.](http://arxiv.org/abs/2304.09182) | 该论文提出了一种考虑时空依赖关系的交通数据填补深度学习框架，可用于解决缺失或不完整数据问题，以进一步应用该数据。 |
| [^48] | [Pretrained Language Models as Visual Planners for Human Assistance.](http://arxiv.org/abs/2304.09179) | 本研究提出了视觉辅助计划（VPA）的任务，利用预训练语言模型作为序列模型，在视频行动分割和预测方面优于现有的方法，来实现多模态AI助手指导用户完成复杂多步骤目标的进展。 |
| [^49] | [Alzheimers Disease Diagnosis using Machine Learning: A Review.](http://arxiv.org/abs/2304.09178) | 本综述分析了机器学习在阿尔茨海默病诊断中的应用，深度学习和强化学习是研究热点，可用于早期病变检测和诊断。 |
| [^50] | [Enhancing Personalized Ranking With Differentiable Group AUC Optimization.](http://arxiv.org/abs/2304.09176) | 本文提出了一种个性化和可微分的AUC优化方法（PDAOM），可用于训练二元分类器并向其提供在独立用户组中紧密相关的正负样本对，以促进分类器关注不易区分的样本之间的关系，这些方法不仅提高了AUC和GAUC指标，还减少了训练目标的计算复杂度。 |
| [^51] | [Memento: Facilitating Effortless, Efficient, and Reliable ML Experiments.](http://arxiv.org/abs/2304.09175) | Memento是一个Python包，旨在协助研究人员高效地管理和执行计算密集型机器学习实验。它提供了简单明了的配置矩阵和并发运行实验的能力。 |
| [^52] | [Speaker Profiling in Multiparty Conversations.](http://arxiv.org/abs/2304.08801) | 本文提出了一个名为SPC的任务，旨在为对话中每个发言者生成个人特征摘要。任务被分为三个子任务：个人特征发现、个人特征类型识别和个人特征价值提取。任务对于银行、酒店预订和航空预订等行业中的聊天机器人非常重要，可以使聊天机器人更好地了解和回应每个发言人的需求。 |
| [^53] | [Self-Supervised 3D Action Representation Learning with Skeleton Cloud Colorization.](http://arxiv.org/abs/2304.08799) | 本文提出了一种基于自监督学习和骨架云着色技术的无监督三维动作表示学习方法，可以在未标注数据上进行空间和时间表示学习，实验结果表明，在三个基准数据集上实现了最先进的无监督骨架动作识别性能。 |
| [^54] | [Masked Language Model Based Textual Adversarial Example Detection.](http://arxiv.org/abs/2304.08767) | 通过探索掩码语言模型引起的流形变化，我们提出了一种插即用的文本对抗例子检测方法，可以在保持对分类任务、模型结构和数据集无依赖的前提下，有效地检测到对抗例子。 |
| [^55] | [Sabi\'a: Portuguese Large Language Models.](http://arxiv.org/abs/2304.07880) | 针对葡萄牙语进行单语言预训练，可以显著提高大规模合成语言模型的质量，并能够在一系列葡萄牙语数据集上优于以英语为中心和多语言的对手，最好的模型的表现与GPT-3.5-turbo持平。 |
| [^56] | [EEGSN: Towards Efficient Low-latency Decoding of EEG with Graph Spiking Neural Networks.](http://arxiv.org/abs/2304.07655) | 该论文提出了一种名为 EEGSN 的图形脉冲神经网络（SNN）架构，面向多通道 EEG 分类任务，在学习分布式 EEG 传感器中的动态关系信息的同时，将推断计算复杂度降低了20倍，为低延迟和功耗效率的脑计算机接口的开发提供了一个可行的框架。 |
| [^57] | [A Comprehensive Survey on Deep Graph Representation Learning.](http://arxiv.org/abs/2304.05055) | 本文综述了深度图表示学习的研究现状和存在的问题，并指出利用深度学习已经显示出巨大的优势和潜力。 |
| [^58] | [Bayesian optimization for sparse neural networks with trainable activation functions.](http://arxiv.org/abs/2304.04455) | 本文提出了一种可训练的激活函数以提高神经网络性能，在此基础上开发了一个基于贝叶斯优化和MCMC采样的模型，能通过有效的采样和全局优化来解决过拟合并提高收敛速度。 |
| [^59] | [GPT detectors are biased against non-native English writers.](http://arxiv.org/abs/2304.02819) | 该研究发现，GPT检测器对非英语母语作者存在偏见，容易将其内容错误地分类为AI生成的内容。此外，简单的提示策略可以缓解这种偏见，同时规避GPT检测器，这表明GPT检测器可能会惩罚具有受限语言表达能力的作者。 |
| [^60] | [Inductive Relation Prediction from Relational Paths and Context with Hierarchical Transformers.](http://arxiv.org/abs/2304.00215) | 本文提出了一种基于分层Transformer的方法，即REPORT，能够同时聚合关系路径和上下文，捕捉实体之间的联系和内在特性。它完全依赖于关系语义，并能自然地推广到完全归纳的设置中。在基准数据集上实现了最先进的性能。 |
| [^61] | [From Private to Public: Benchmarking GANs in the Context of Private Time Series Classification.](http://arxiv.org/abs/2303.15916) | 本论文在时间序列领域对两种GAN架构进行了评估，结果以GSWGAN表现最佳，可以私密地生成保护数据隐私的公共数据。 |
| [^62] | [Unknown Sniffer for Object Detection: Don't Turn a Blind Eye to Unknown Objects.](http://arxiv.org/abs/2303.13769) | 本文提出了未知嗅探器(UnSniffer)，用于同时寻找未知和已知的目标。通过引入广义物体置信度(GOC)分数和负能量抑制损失来提高未知对象在背景中的检测准确率，并解决了在推断过程中难以获得每个未知目标最佳框的问题。 |
| [^63] | [TempT: Temporal consistency for Test-time adaptation.](http://arxiv.org/abs/2303.10536) | 本文提出一种新颖的方法TempT，通过确保连续帧之间的预测具有时间上的一致性，实现了对视频的测试时自适应。其仅利用视觉单模态特征，并在面部表情识别等计算机视觉任务中具有广泛应用，并在实验中取得了有竞争力的表现，为其在各种实际应用中提供了令人信服的概念证明。 |
| [^64] | [Highly Personalized Text Embedding for Image Manipulation by Stable Diffusion.](http://arxiv.org/abs/2303.08767) | 本论文提出了一种简单但高效的个性化方法——使用高度个性化文本嵌入来进行图像操作，可以运用于图像的背景、纹理和动作的编辑，不需要多个参考图像或复杂训练，能实现复杂语义图像编辑。 |
| [^65] | [TSMixer: An all-MLP Architecture for Time Series Forecasting.](http://arxiv.org/abs/2303.06053) | TSMixer是一种通过堆叠多层感知器（MLP）设计的新型结构，基于沿时间和特征维度的混合操作，能够在时间序列预测中表现出极好的性能。 |
| [^66] | [Ensemble Reinforcement Learning: A Survey.](http://arxiv.org/abs/2303.02618) | 集成强化学习（ERL）是一种将强化学习（RL）与集成学习（EL）相结合的有前途的方法，旨在利用多个模型或培训算法全面探索问题空间，并具有强大的泛化能力。 |
| [^67] | [The In-Sample Softmax for Offline Reinforcement Learning.](http://arxiv.org/abs/2302.14372) | 本文研究离线强化学习中的In-Sample Softmax，通过使用只由数据集中的操作组成的In-Sample softmax来解决操作覆盖不足问题，并且In-Sample Actor-Critic与该方法相比在稳定性或性能上表现更好。 |
| [^68] | [Understanding the Spectral Bias of Coordinate Based MLPs Via Training Dynamics.](http://arxiv.org/abs/2301.05816) | 该论文研究了基于坐标的MLPs的谱偏置对高频组件收敛的阻碍，并提出使用高频正弦波编码输入来克服这一限制。 |
| [^69] | [Multi-Level Firing with Spiking DS-ResNet: Enabling Better and Deeper Directly-Trained Spiking Neural Networks.](http://arxiv.org/abs/2210.06386) | 本文提出了一种多层射击（MLF）方法和尖峰沉默禁制残差网络（spiking DS-ResNet），通过 MLF 方法，可以更高效地传播梯度，增加神经元的增量表达能力；DS-ResNet 可以有效地执行离散尖峰的恒等映射，提高网络的表达能力。 |
| [^70] | [Embedding-Assisted Attentional Deep Learning for Real-World RF Fingerprinting of Bluetooth.](http://arxiv.org/abs/2210.02897) | 本研究提出了一种嵌入式注意力深度学习框架，用于提取实际蓝牙设备的指纹。该模型具有较高的分类准确率，并在内存使用方面有所改进。 |
| [^71] | [Constraining Representations Yields Models That Know What They Don't Know.](http://arxiv.org/abs/2208.14488) | 通过对模型内部激活模式施加类感知约束的方法，本文提出总激活分类器（TAC）可以让模型更加安全、可靠，并具有广泛的应用前景。 |
| [^72] | [EC-KitY: Evolutionary Computation Tool Kit in Python with Seamless Machine Learning Integration.](http://arxiv.org/abs/2207.10367) | EC-KitY是一款基于Python的全面进化计算工具包，采用BSD 3-Clause许可证，兼容scikit-learn，支持多种流行的EC范例，能够无缝集成机器学习，并提供简便的EC实验设置和具有竞争力的模型性能。 |
| [^73] | [Discourse-Aware Graph Networks for Textual Logical Reasoning.](http://arxiv.org/abs/2207.01450) | 本论文提出了逻辑结构约束建模和话语感知图网络（DAGNs）用于解决文本逻辑推理问答问题。DAGNs可以构建逻辑图并通过边缘推理机制和图特征更新来学习逻辑表示。该方法在实验中取得了良好的效果。 |
| [^74] | [BATFormer: Towards Boundary-Aware Lightweight Transformer for Efficient Medical Image Segmentation.](http://arxiv.org/abs/2206.14409) | 本文提出了一种名为BATFormer的方法，以较低的计算复杂度实现跨尺度全局交互，即建立长距离依赖。同时，指导下灵活地生成窗口，增强了在医学图像分割中的形状建模。 |
| [^75] | [Toward multi-target self-organizing pursuit in a partially observable Markov game.](http://arxiv.org/abs/2206.12330) | 本文提出了一个基于部分可观察马尔可夫博弈（POMG）的多智能体自主组织追捕（SOP）框架，并使用模糊自组织协作共同演化（FSC2）分布式算法来解决SOP中的三大挑战：分布式自组织搜索（SOS）、分布式任务分配和分布式单目标追踪。实验结果表明，所提出的FSC2算法有效提高了多目标SOP任务的准确性和效率。 |
| [^76] | [Fast Vision Transformers with HiLo Attention.](http://arxiv.org/abs/2205.13213) | 摘要：本文提出了一种名为HiLo注意力的自注意机制，使用分而治之的策略在注意力转换器中分解高/低频模式，可以更加高效地运行视觉Transformer，并在不同模型大小的范围内胜过现有的最先进方法。 |
| [^77] | [Successes and critical failures of neural networks in capturing human-like speech recognition.](http://arxiv.org/abs/2204.03740) | 本文综合了语音识别实验，评估了最先进的神经网络作为可计算、优化的观察器。实验结果展示了机器在带有噪声的语音识别能力的时间范围上表现出来的鲁棒性特征。 |
| [^78] | [A Survey on Offline Reinforcement Learning: Taxonomy, Review, and Open Problems.](http://arxiv.org/abs/2203.01387) | 本文综述了离线强化学习中的分类与最新算法突破，离线RL算法具有更广泛的应用，尤其适用于教育、医疗保健和机器人等实际应用。 |
| [^79] | [CADRE: A Cascade Deep Reinforcement Learning Framework for Vision-based Autonomous Urban Driving.](http://arxiv.org/abs/2202.08557) | 本论文提出了一种基于级联深度强化学习框架 CADRE，通过 CoPM 离线训练，采用联合注意机制从预收集的驾驶数据集中学习视觉和控制信息之间的相互关系，在此基础上采用特别设计的奖励函数指导下，通过高效分布式 PPO 实现在线学习驾驶策略。 |
| [^80] | [Continuous Time Bandits With Sampling Costs.](http://arxiv.org/abs/2107.05289) | 本文研究了带采样成本的连续时间多臂赌博机问题，在连续时间里，学习者要在获得更高奖励和承担采样成本之间进行有效平衡。本文提出了一个达到下界的算法，并揭示了与传统多臂赌博机问题不同的特殊现象，具有广泛应用价值。 |
| [^81] | [Over-Fit: Noisy-Label Detection based on the Overfitted Model Property.](http://arxiv.org/abs/2106.07217) | 本文提出一种基于模型过拟合特性的后训练学习方法，能够识别错误标记的样本，并逐步删除对决策边界有较高影响的样本，从而提高模型的泛化性能。 |
| [^82] | [On the uniform one-dimensional fragment.](http://arxiv.org/abs/1604.01673) | 统一一维分片是一种形式化语言，可将二元逻辑扩展到具有任意元数关系的上下文中。其描述逻辑版本具有表达能力的新结果，与能够容纳更高元数关系的描述逻辑紧密相关。 |

# 详细

[^1]: LipsFormer：向Vision Transformer引入Lipschitz连续性

    LipsFormer: Introducing Lipschitz Continuity to Vision Transformers. (arXiv:2304.09856v1 [cs.CV])

    [http://arxiv.org/abs/2304.09856](http://arxiv.org/abs/2304.09856)

    本文介绍了一种Lipschitz连续的Transformer模型LipsFormer，其中引入了多项Lipschitz连续的组件来保证训练的稳定性，并在实验证明其可以让深度Transformer架构稳定进行训练，无需过多调整学习率等参数。

    

    我们提出了一个名为LipsFormer的Lipschitz连续Transformer，旨在从理论上和实践上追求Transformer-based模型的训练稳定性。相比于以前通过学习率warmup、层归一化、attention公式、权重初始化等方法解决训练不稳定性的实际技巧，我们证明了Lipschitz连续性是确保训练稳定性的更重要的属性。在LipsFormer中，我们用Lipschitz连续的中心归一化代替不稳定的Transformer组件模块：中心归一化代替层归一化，谱初始化代替Xavier初始化，缩放余弦相似度注意代替点积注意，并使用加权残差快捷方式。我们证明了这些引入的模块是Lipschitz连续的，并推导出LipsFormer的Lipschitz常数的上界。我们的实验表明，LipsFormer允许深度Transformer架构的稳定训练，无需仔细调整学习率。

    We present a Lipschitz continuous Transformer, called LipsFormer, to pursue training stability both theoretically and empirically for Transformer-based models. In contrast to previous practical tricks that address training instability by learning rate warmup, layer normalization, attention formulation, and weight initialization, we show that Lipschitz continuity is a more essential property to ensure training stability. In LipsFormer, we replace unstable Transformer component modules with Lipschitz continuous counterparts: CenterNorm instead of LayerNorm, spectral initialization instead of Xavier initialization, scaled cosine similarity attention instead of dot-product attention, and weighted residual shortcut. We prove that these introduced modules are Lipschitz continuous and derive an upper bound on the Lipschitz constant of LipsFormer. Our experiments show that LipsFormer allows stable training of deep Transformer architectures without the need of careful learning rate tuning such 
    
[^2]: 学习和适应敏捷运动技能的方法：经验迁移

    Learning and Adapting Agile Locomotion Skills by Transferring Experience. (arXiv:2304.09834v1 [cs.RO])

    [http://arxiv.org/abs/2304.09834](http://arxiv.org/abs/2304.09834)

    通过经验迁移和强化学习，该论文提出一种训练复杂机器人运动技能的框架，并克服了在高度欠驱动系统中进行探索的障碍。

    

    从在不平整地形中导航到高速奔跑，有腿机器人的能力潜力巨大。然而，为高度敏捷的动态运动设计稳健的控制器仍然是机器人技术人员面临的重大挑战。强化学习（RL）提供了一种有前途的数据驱动方法，可以自动训练这种控制器。然而，在这些高维度、欠驱动系统中进行探索仍然是使有腿机器人学习表现良好、自然而多才多艺的敏捷技能的重要障碍。我们提出了一个框架，通过从现有的控制器中转移经验来训练复杂的机器人技能，从而启动学习新任务。为了利用我们在实践中可以获得的控制器，我们设计了这个框架，使其在源上具有灵活性--也就是说，这些控制器可能已针对不同的动态而针对不同的目标进行了优化，或者可能需要更多的环境知识--因此可能非常高。

    Legged robots have enormous potential in their range of capabilities, from navigating unstructured terrains to high-speed running. However, designing robust controllers for highly agile dynamic motions remains a substantial challenge for roboticists. Reinforcement learning (RL) offers a promising data-driven approach for automatically training such controllers. However, exploration in these high-dimensional, underactuated systems remains a significant hurdle for enabling legged robots to learn performant, naturalistic, and versatile agility skills. We propose a framework for training complex robotic skills by transferring experience from existing controllers to jumpstart learning new tasks. To leverage controllers we can acquire in practice, we design this framework to be flexible in terms of their source -that is, the controllers may have been optimized for a different objective under different dynamics, or may require different knowledge of the surroundings -- and thus may be highl
    
[^3]: AI的公平性及其对社会的长期影响

    Fairness in AI and Its Long-Term Implications on Society. (arXiv:2304.09826v1 [cs.CY])

    [http://arxiv.org/abs/2304.09826](http://arxiv.org/abs/2304.09826)

    本文探讨了AI的公平性问题，指出缺乏AI公平性会加深偏见成为社会压力因素，可能对社会产生长期影响，因此需要寻求潜在解决方案。

    

    人工智能（AI）在各种设置中的成功部署已经为个人和社会带来了许多积极的成果。然而，由于预测的偏见，AI系统也被证明对部分人口造成了伤害。我们着眼于AI的公平性，分析了缺乏AI公平性时如何导致偏见随着时间的加深而成为社会压力因素。如果问题持续存在，可能会对社会产生不良的长期影响，并通过与其他风险的交互来加强。我们检查了提高AI公平性的当前策略，并评估它们在实际部署方面的限制，并探讨了确保我们在不损害社会重要部分的情况下获得AI的好处的潜在路径。

    Successful deployment of artificial intelligence (AI) in various settings has led to numerous positive outcomes for individuals and society. However, AI systems have also been shown to harm parts of the population due to biased predictions. We take a closer look at AI fairness and analyse how lack of AI fairness can lead to deepening of biases over time and act as a social stressor. If the issues persist, it could have undesirable long-term implications on society, reinforced by interactions with other risks. We examine current strategies for improving AI fairness, assess their limitations in terms of real-world deployment, and explore potential paths forward to ensure we reap AI's benefits without harming significant parts of the society.
    
[^4]: 利用离线数据加速程序生成环境中的强化学习

    Using Offline Data to Speed-up Reinforcement Learning in Procedurally Generated Environments. (arXiv:2304.09825v1 [cs.LG])

    [http://arxiv.org/abs/2304.09825](http://arxiv.org/abs/2304.09825)

    本研究旨在提高程序生成环境中强化学习的样本效率。研究证明，使用模仿学习进行预训练和同时进行模仿学习和在线强化学习的方法可以提高效率。

    

    强化学习面临的主要挑战之一是代理能够将其学习策略推广到未见过的环境中。此外，训练强化学习代理需要与环境进行大量交互。受离线强化学习和模仿学习的最近成功启发，我们进行了一项研究，以调查代理是否可以利用轨迹的离线数据来提高程序生成环境中的样本效率。我们考虑了两种使用离线数据的模仿学习方法：（1）在在线强化学习训练之前预训练策略和（2）同时训练在线强化学习和来自离线数据的模仿学习。我们分析了可用的离线轨迹的质量（轨迹的最佳性）和多样性（轨迹数量和覆盖级别）对两种方法有效性的影响。在MiniGrid环境中的四个知名稀疏奖励任务中，我们发现使用模仿学习进行预训练和同时进行模仿学习和在线强化学习的方法可以提供更高的样本效率。

    One of the key challenges of Reinforcement Learning (RL) is the ability of agents to generalise their learned policy to unseen settings. Moreover, training RL agents requires large numbers of interactions with the environment. Motivated by the recent success of Offline RL and Imitation Learning (IL), we conduct a study to investigate whether agents can leverage offline data in the form of trajectories to improve the sample-efficiency in procedurally generated environments. We consider two settings of using IL from offline data for RL: (1) pre-training a policy before online RL training and (2) concurrently training a policy with online RL and IL from offline data. We analyse the impact of the quality (optimality of trajectories) and diversity (number of trajectories and covered level) of available offline trajectories on the effectiveness of both approaches. Across four well-known sparse reward tasks in the MiniGrid environment, we find that using IL for pre-training and concurrently d
    
[^5]: ChatGPT启用的劳动力市场的未来：初步研究

    The Future of ChatGPT-enabled Labor Market: A Preliminary Study. (arXiv:2304.09823v1 [cs.CY])

    [http://arxiv.org/abs/2304.09823](http://arxiv.org/abs/2304.09823)

    本研究从人工智能协作的角度，通过分析大规模职位发布数据及基于职业知识图谱开发的协同过滤算法，预测了ChatGPT对未来劳动力市场的影响，发现目前约28％的职业需要ChatGPT相关技能。

    

    作为一个非凡的大型语言模型，ChatGPT在各种现实任务中取得了无与伦比的成功并越来越在我们的日常生活和工作中扮演重要角色。然而，人们也提出了广泛的担忧，特别是关于ChatGPT样的人工通用智能（AGI）是否会取代人类工作。因此，在本文中，我们从人工智能协作而不是对立的角度介绍了ChatGPT启用的劳动力市场的未来的初步数据驱动研究。具体来说，我们首先对中国最大的在线招聘平台BOSS直聘中的大规模职位发布数据进行深入分析。结果表明，当前劳动力市场约有28％的职业需要ChatGPT相关技能。此外，基于大规模基于职业的知识图谱，我们开发了一个语义信息增强的协同过滤算法，以预测未来职业技能。

    As a phenomenal large language model, ChatGPT has achieved unparalleled success in various real-world tasks and increasingly plays an important role in our daily lives and work. However, extensive concerns are also raised about the potential ethical issues, especially about whether ChatGPT-like artificial general intelligence (AGI) will replace human jobs. To this end, in this paper, we introduce a preliminary data-driven study on the future of ChatGPT-enabled labor market from the view of Human-AI Symbiosis instead of Human-AI Confrontation. To be specific, we first conduct an in-depth analysis of large-scale job posting data in BOSS Zhipin, the largest online recruitment platform in China. The results indicate that about 28% of occupations in the current labor market require ChatGPT-related skills. Furthermore, based on a large-scale occupation-centered knowledge graph, we develop a semantic information enhanced collaborative filtering algorithm to predict the future occupation-skill
    
[^6]: 利用深度强化学习在智能辅导系统中提供元认知干预

    Leveraging Deep Reinforcement Learning for Metacognitive Interventions across Intelligent Tutoring Systems. (arXiv:2304.09821v1 [cs.CY])

    [http://arxiv.org/abs/2304.09821](http://arxiv.org/abs/2304.09821)

    本研究比较了两种方法来提供元认知干预，并发现基于深度强化学习的自适应干预能够缩小学生之间的元认知技能差距。

    

    本研究比较了两种不同方法来提供元认知干预，以及它们对智能辅导系统（ITSs）中学生未来学习准备的影响。我们在两个连续的学期中进行了两个课堂实验：实验1使用经典的人工智能方法将学生分类为不同的元认知组，并根据他们的分类组提供静态的干预。在实验2中，我们利用了深度强化学习（DRL）来提供自适应干预，考虑到学生元认知水平的动态变化。在两个实验中，学生接受了这些干预，学习如何和何时在逻辑辅导程序上使用向后链接（BC）策略，该程序支持默认的向前链接策略。六周后，我们在一个只支持BC而没有干预的概率辅导程序上对学生进行了培训。我们的结果表明，自适应的基于DRL的干预缩小了学生之间的元认知技能差距。

    This work compares two approaches to provide metacognitive interventions and their impact on preparing students for future learning across Intelligent Tutoring Systems (ITSs). In two consecutive semesters, we conducted two classroom experiments: Exp. 1 used a classic artificial intelligence approach to classify students into different metacognitive groups and provide static interventions based on their classified groups. In Exp. 2, we leveraged Deep Reinforcement Learning (DRL) to provide adaptive interventions that consider the dynamic changes in the student's metacognitive levels. In both experiments, students received these interventions that taught how and when to use a backward-chaining (BC) strategy on a logic tutor that supports a default forward-chaining strategy. Six weeks later, we trained students on a probability tutor that only supports BC without interventions. Our results show that adaptive DRL-based interventions closed the metacognitive skills gap between students. In 
    
[^7]: 一种自监督蒸馏的双阶段框架用于跨领域文本分类

    A Two-Stage Framework with Self-Supervised Distillation For Cross-Domain Text Classification. (arXiv:2304.09820v1 [cs.CL])

    [http://arxiv.org/abs/2304.09820](http://arxiv.org/abs/2304.09820)

    本文提出了一种双阶段框架，使用自监督蒸馏和来自不同但相关源领域的标记数据完成跨领域文本分类，取得在单源领域适应性和多源领域适应性上的新的最先进结果。

    

    跨领域文本分类旨在将模型适应于缺少标记数据的目标领域。它利用或重用不同但相关源领域的丰富标记数据和目标领域的未标记数据。为此，先前的工作要么专注于提取领域不变特征，要么忽略可能存在于目标领域中并对下游任务有用的领域感知特征的任务不可知特征。本文提出了一种双阶段框架，用于跨领域文本分类。在第一阶段，我们使用掩蔽语言建模（MLM）和来自源域的标记数据微调模型。在第二阶段，我们进一步使用自监督蒸馏（SSD）和来自目标域的未标记数据微调模型。我们基于公共的跨领域文本分类基准测试其性能，并实验结果表明，我们的方法在单源领域适应性和多源领域适应性上均取得了新的最先进结果。

    Cross-domain text classification aims to adapt models to a target domain that lacks labeled data. It leverages or reuses rich labeled data from the different but related source domain(s) and unlabeled data from the target domain. To this end, previous work focuses on either extracting domain-invariant features or task-agnostic features, ignoring domain-aware features that may be present in the target domain and could be useful for the downstream task. In this paper, we propose a two-stage framework for cross-domain text classification. In the first stage, we finetune the model with mask language modeling (MLM) and labeled data from the source domain. In the second stage, we further fine-tune the model with self-supervised distillation (SSD) and unlabeled data from the target domain. We evaluate its performance on a public cross-domain text classification benchmark and the experiment results show that our method achieves new state-of-the-art results for both single-source domain adaptat
    
[^8]: 关于难度知觉: 人类和人工智能之间的差异

    On the Perception of Difficulty: Differences between Humans and AI. (arXiv:2304.09803v1 [cs.HC])

    [http://arxiv.org/abs/2304.09803](http://arxiv.org/abs/2304.09803)

    有效的人机交互系统需要准确反映人类和人工智能代理在实现有价值的结果时的知觉难度，目前研究尚未充分探讨两者之间的差异。

    

    随着人工智能在工业和社会中的应用日益增多，有效的人机交互系统变得越来越重要。人与人工智能交互的一个重要挑战是估计针对单个任务实例人类和人工智能代理的难度。这些估计对于评估每个代理的能力至关重要，因此有助于实现有效的协作。迄今为止，人机交互领域的研究独立地估计了人类和人工智能的知觉难度。然而，人工智能代理和人类代理之间的有效交互取决于准确反映每个代理在实现有价值的结果时的知觉难度的度量标准。迄今为止，研究尚未充分探讨人类和人工智能的知觉难度差异。因此，本研究回顾了人机交互中关于知觉难度的最新研究以及对每个代理的难度估计的贡献因素进行了一致的比较。

    With the increased adoption of artificial intelligence (AI) in industry and society, effective human-AI interaction systems are becoming increasingly important. A central challenge in the interaction of humans with AI is the estimation of difficulty for human and AI agents for single task instances.These estimations are crucial to evaluate each agent's capabilities and, thus, required to facilitate effective collaboration. So far, research in the field of human-AI interaction estimates the perceived difficulty of humans and AI independently from each other. However, the effective interaction of human and AI agents depends on metrics that accurately reflect each agent's perceived difficulty in achieving valuable outcomes. Research to date has not yet adequately examined the differences in the perceived difficulty of humans and AI. Thus, this work reviews recent research on the perceived difficulty in human-AI interaction and contributing factors to consistently compare each agent's perc
    
[^9]: POMDPs和可解释智能体的端到端策略梯度方法

    End-to-End Policy Gradient Method for POMDPs and Explainable Agents. (arXiv:2304.09769v1 [cs.AI])

    [http://arxiv.org/abs/2304.09769](http://arxiv.org/abs/2304.09769)

    本文提出了一种使用端到端训练估计POMDP中隐藏状态并可视化为状态转移图的RL算法，实验结果表明该算法可以解决简单问题并且代理的行为可解释。

    

    真实世界的决策问题通常是部分可观测的，并且有许多可以被归结为部分可观测马尔可夫决策过程（POMDP）。当我们将强化学习算法应用于POMDP时，合理的隐藏状态估计可以帮助解决问题。此外，可解释的决策是首选，考虑到它们在自主驾驶汽车等真实世界任务中的应用。我们提出了一种通过端到端训练估计隐藏状态并将估计可视化为状态转移图的RL算法。实验结果表明，所提出的算法可以解决简单的POMDP问题，并且可视化使代理的行为对人类具有可解释性。

    Real-world decision-making problems are often partially observable, and many can be formulated as a Partially Observable Markov Decision Process (POMDP). When we apply reinforcement learning (RL) algorithms to the POMDP, reasonable estimation of the hidden states can help solve the problems. Furthermore, explainable decision-making is preferable, considering their application to real-world tasks such as autonomous driving cars. We proposed an RL algorithm that estimates the hidden states by end-to-end training, and visualize the estimation as a state-transition graph. Experimental results demonstrated that the proposed algorithm can solve simple POMDP problems and that the visualization makes the agent's behavior interpretable to humans.
    
[^10]: 一种基于深度学习的创新方法用于准确的农产品价格预测

    An innovative Deep Learning Based Approach for Accurate Agricultural Crop Price Prediction. (arXiv:2304.09761v1 [cs.LG])

    [http://arxiv.org/abs/2304.09761](http://arxiv.org/abs/2304.09761)

    本文提出了一种基于深度学习的方法，利用历史价格信息、气候条件、土壤类型、地理位置和其他关键决策因素，精确预测农产品价格。该方法使用图神经网络和卷积神经网络相结合，适用于有噪声的历史数据，并且表现至少比现有文献中的结果好20%。

    

    农产品价格的准确预测对于农业各利益相关者（农民、消费者、零售商、批发商和政府）的决策至关重要，特别是对农民的经济福祉产生重要影响。本文的目标是利用历史价格信息、气候条件、土壤类型、地理位置和其他关键决策因素，精确预测农产品价格。这是一个技术挑战，以前也曾被尝试过。本文提出了一种创新的基于深度学习的方法，以实现在价格预测中的提高准确性。所提出的方法使用图神经网络（GNNs）与标准卷积神经网络（CNN）模型相结合，利用价格的地理空间相关性。我们的方法适用于有噪声的历史数据，并且表现至少比现有文献中的结果好20%。

    Accurate prediction of agricultural crop prices is a crucial input for decision-making by various stakeholders in agriculture: farmers, consumers, retailers, wholesalers, and the Government. These decisions have significant implications including, most importantly, the economic well-being of the farmers. In this paper, our objective is to accurately predict crop prices using historical price information, climate conditions, soil type, location, and other key determinants of crop prices. This is a technically challenging problem, which has been attempted before. In this paper, we propose an innovative deep learning based approach to achieve increased accuracy in price prediction. The proposed approach uses graph neural networks (GNNs) in conjunction with a standard convolutional neural network (CNN) model to exploit geospatial dependencies in prices. Our approach works well with noisy legacy data and produces a performance that is at least 20% better than the results available in the li
    
[^11]: 基于骨架的行为分析用于注意力缺陷多动障碍的诊断

    Skeleton-based action analysis for ADHD diagnosis. (arXiv:2304.09751v1 [cs.CV])

    [http://arxiv.org/abs/2304.09751](http://arxiv.org/abs/2304.09751)

    提出一种基于骨架的动作识别框架用于注意力缺陷多动障碍的诊断，其显示出成本效益和显著的性能改进，是一种低成本的初始ADHD诊断方法。

    

    注意力缺陷多动障碍 (ADHD)是世界范围内常见的神经行为障碍。尽管对于机器学习方法在ADHD诊断上的研究非常广泛，但大多数研究都依赖于高成本设备，例如MRI机器和EEG贴片。因此，基于ADHD行为特征的低成本诊断方法备受期待。基于骨架的动作识别由于其聚焦于动作和鲁棒性而受到关注。在本文中，我们提出了一个新颖的ADHD诊断系统，其中包含基于骨架的动作识别框架，利用真实的多模态ADHD数据集和最先进的检测算法。与传统方法相比，所提出的方法显示出成本效益和显著的性能改进，使其更易于进行广泛的初始ADHD诊断。通过实验结果，所提出的方法在准确性和AUC方面优于传统方法。同时，我们的方法可广泛应用于大规模诊断和预测。

    Attention Deficit Hyperactivity Disorder (ADHD) is a common neurobehavioral disorder worldwide. While extensive research has focused on machine learning methods for ADHD diagnosis, most research relies on high-cost equipment, e.g., MRI machine and EEG patch. Therefore, low-cost diagnostic methods based on the action characteristics of ADHD are desired. Skeleton-based action recognition has gained attention due to the action-focused nature and robustness. In this work, we propose a novel ADHD diagnosis system with a skeleton-based action recognition framework, utilizing a real multi-modal ADHD dataset and state-of-the-art detection algorithms. Compared to conventional methods, the proposed method shows cost-efficiency and significant performance improvement, making it more accessible for a broad range of initial ADHD diagnoses. Through the experiment results, the proposed method outperforms the conventional methods in accuracy and AUC. Meanwhile, our method is widely applicable for mass
    
[^12]: 通过结构感知扩散模型利用素描进行参考图像合成

    Reference-based Image Composition with Sketch via Structure-aware Diffusion Model. (arXiv:2304.09748v1 [cs.CV])

    [http://arxiv.org/abs/2304.09748](http://arxiv.org/abs/2304.09748)

    该论文提出了一种利用素描进行图像合成的方法，允许用户通过所需的结构和内容对图像的子部分进行编辑或完成。该方法采用预训练的扩散模型来完成缺失的区域并维持素描的引导，为图像操作提供了独特的用例。

    

    最近在大规模文本与图像生成模型方面的显著改进已经显示出在生成高保真图像方面的良好结果。为了进一步增强可编辑性并使细粒度生成成为可能，我们引入了一种多输入条件的图像合成模型，其中包含素描作为一种新的模式，以及参考图像。由于使用素描对边界进行控制，我们的方法使用户能够使用所需的结构（即素描）和内容（即参考图像）来编辑或完成图像的子部分。我们的框架通过微调预先训练的扩散模型来使用参考图像来完成缺失的区域，同时保持素描引导。虽然简单，但这将带来广泛的机会，以满足用户需要获取所需图像。通过大量实验证明，我们提出的方法为图像操作提供了独特的用例，使用户驱动任意场景的修改成为可能。

    Recent remarkable improvements in large-scale text-to-image generative models have shown promising results in generating high-fidelity images. To further enhance editability and enable fine-grained generation, we introduce a multi-input-conditioned image composition model that incorporates a sketch as a novel modal, alongside a reference image. Thanks to the edge-level controllability using sketches, our method enables a user to edit or complete an image sub-part with a desired structure (i.e., sketch) and content (i.e., reference image). Our framework fine-tunes a pre-trained diffusion model to complete missing regions using the reference image while maintaining sketch guidance. Albeit simple, this leads to wide opportunities to fulfill user needs for obtaining the in-demand images. Through extensive experiments, we demonstrate that our proposed method offers unique use cases for image manipulation, enabling user-driven modifications of arbitrary scenes.
    
[^13]: 基于骨架身体关节点的康复运动重复分割和计数

    Rehabilitation Exercise Repetition Segmentation and Counting using Skeletal Body Joints. (arXiv:2304.09735v1 [cs.CV])

    [http://arxiv.org/abs/2304.09735](http://arxiv.org/abs/2304.09735)

    本研究提出了一种通过骨架身体关节点实现患者康复运动重复分割和计数的方法，可克服传感器难以使用和隐私问题的困境。

    

    体育锻炼是提高生活质量、降低死亡率和再住院率的康复计划的重要组成部分。在AI驱动的虚拟康复计划中，患者独立在家完成运动，而AI算法分析运动数据，向患者提供反馈，并向临床医生报告他们的进展情况。分析运动数据的第一步是将其分割成连续的重复动作。之前已经有大量关于使用原始视频数据对健康人进行重复活动分割和计数的研究，这引发了隐私问题，并且计算复杂度较高。以前关于患者的康复运动分割的研究依赖于多个可穿戴传感器收集的数据，这些传感器在康复患者家中使用起来很困难。与健康人相比，在患者中分割和计数运动重复更具挑战性，这是因为康复过程中涉及到疾病和身体损伤的各种因素。

    Physical exercise is an essential component of rehabilitation programs that improve quality of life and reduce mortality and re-hospitalization rates. In AI-driven virtual rehabilitation programs, patients complete their exercises independently at home, while AI algorithms analyze the exercise data to provide feedback to patients and report their progress to clinicians. To analyze exercise data, the first step is to segment it into consecutive repetitions. There has been a significant amount of research performed on segmenting and counting the repetitive activities of healthy individuals using raw video data, which raises concerns regarding privacy and is computationally intensive. Previous research on patients' rehabilitation exercise segmentation relied on data collected by multiple wearable sensors, which are difficult to use at home by rehabilitation patients. Compared to healthy individuals, segmenting and counting exercise repetitions in patients is more challenging because of th
    
[^14]: 基于样本效率的模型驱动量子控制强化学习

    Sample-efficient Model-based Reinforcement Learning for Quantum Control. (arXiv:2304.09718v1 [quant-ph])

    [http://arxiv.org/abs/2304.09718](http://arxiv.org/abs/2304.09718)

    本论文提出了一种基于模型的强化学习方法，通过受到神经常微分方程进展的启发，这个方法采用自动微分的ODE表达由可学习的汉密尔顿安排参数化的模型来近似环境，在门控制和汉密尔顿参数的学习中通过系统交互解决问题。该方法在样本复杂度方面比标准基于模型自由的强化学习方法具有一个数量级的优势，适用于噪声时变门优化。

    

    我们提出了一种基于模型的强化学习方法，用于噪声时变门优化，其样本复杂度优于基于模型自由的强化学习。样本复杂度是控制器与物理系统交互的次数。借助一个归纳偏置，受最近神经常微分方程的进展启发，我们使用可微的ODE，其由可学习的汉密尔顿安排参数化，以表示模型近似环境，其时变部分（包括控制）完全已知。控制器和连续时域独立参数的汉密尔顿学习是通过与系统的交互来解决的。在真实数值实验中，我们展示了使用我们方法在准备一些标准单量子门的闭合和开放系统动态时，在样本复杂度方面与标准模型自由强化学习相比，具有一个数量级的优势，这包括单次测量、任意希尔伯特空间截断和不确定性等。

    We propose a model-based reinforcement learning (RL) approach for noisy time-dependent gate optimization with improved sample complexity over model-free RL. Sample complexity is the number of controller interactions with the physical system. Leveraging an inductive bias, inspired by recent advances in neural ordinary differential equations (ODEs), we use an auto-differentiable ODE parametrised by a learnable Hamiltonian ansatz to represent the model approximating the environment whose time-dependent part, including the control, is fully known. Control alongside Hamiltonian learning of continuous time-independent parameters is addressed through interactions with the system. We demonstrate an order of magnitude advantage in the sample complexity of our method over standard model-free RL in preparing some standard unitary gates with closed and open system dynamics, in realistic numerical experiments incorporating single shot measurements, arbitrary Hilbert space truncations and uncertaint
    
[^15]: 基于深度强化学习的超视距空战自主代理人

    Autonomous Agent for Beyond Visual Range Air Combat: A Deep Reinforcement Learning Approach. (arXiv:2304.09669v1 [cs.RO])

    [http://arxiv.org/abs/2304.09669](http://arxiv.org/abs/2304.09669)

    本论文基于深度强化学习理论，致力于开发一款能够在超视距空战中执行任务的智能代理人,通过计算奖励，不断学习和提高自身在空战中的表现，并期望生成以前从未出现过的空战策略，最终测试真正的飞行员与训练代理人在相同环境下的表现差异，为空中防御任务提高飞行员的表现做出贡献。

    

    本论文旨在开发一个基于深度强化学习的代理人，能够在超视距空战模拟环境中执行任务。本文提出了构建代表高性能战斗飞机的代理人，并根据操作指标计算奖励，使其能够学习并提高其在超视距空战中的表现。此外，通过自我对弈实验，期望生成以前从未出现过的空战策略。最后，我们希望能够测试真正的飞行员使用虚拟模拟与经过训练的代理人在相同环境中交互的能力，并比较他们的表现。这项研究将通过开发能够与真正的飞行员交互的代理人，在空中防御任务中提高飞行员的表现。

    This work contributes to developing an agent based on deep reinforcement learning capable of acting in a beyond visual range (BVR) air combat simulation environment. The paper presents an overview of building an agent representing a high-performance fighter aircraft that can learn and improve its role in BVR combat over time based on rewards calculated using operational metrics. Also, through self-play experiments, it expects to generate new air combat tactics never seen before. Finally, we hope to examine a real pilot's ability, using virtual simulation, to interact in the same environment with the trained agent and compare their performances. This research will contribute to the air combat training context by developing agents that can interact with real pilots to improve their performances in air defense missions.
    
[^16]: GeneGPT: 教授大型语言模型使用NCBI Web API

    GeneGPT: Teaching Large Language Models to Use NCBI Web APIs. (arXiv:2304.09667v1 [cs.CL])

    [http://arxiv.org/abs/2304.09667](http://arxiv.org/abs/2304.09667)

    GeneGPT通过少量NCBI API调用URL请求作为演示，教授大型语言模型使用NCBI Web API回答基因组问题，并在GeneTuring测试中达到了优异的结果。

    

    本文介绍了GeneGPT，一种新颖的方法，用于教授大型语言模型（LLM）使用国家生物技术信息中心（NCBI）的Web应用程序编程接口（API），并回答基因组问题。具体而言，我们通过少量的NCBI API调用URL请求作为上下文学习的演示，启发Codex（code-davinci-002）解决GeneTuring测试。在推理过程中，一旦检测到调用请求，我们就停止解码并使用生成的URL进行API调用。我们然后将NCBI API返回的原始执行结果附加到生成的文本中，并继续生成直到找到答案或检测到另一个API调用。初步结果表明，GeneGPT在GeneTuring数据集的四个One-shot任务中取得了三个最先进的结果，在五个Zero-shot任务中取得了四个最先进的结果。总体而言，GeneGPT的宏平均分数为0.76，远高于检索增强LLM，如New Bin。

    In this paper, we present GeneGPT, a novel method for teaching large language models (LLMs) to use the Web Application Programming Interfaces (APIs) of the National Center for Biotechnology Information (NCBI) and answer genomics questions. Specifically, we prompt Codex (code-davinci-002) to solve the GeneTuring tests with few-shot URL requests of NCBI API calls as demonstrations for in-context learning. During inference, we stop the decoding once a call request is detected and make the API call with the generated URL. We then append the raw execution results returned by NCBI APIs to the generated texts and continue the generation until the answer is found or another API call is detected. Our preliminary results show that GeneGPT achieves state-of-the-art results on three out of four one-shot tasks and four out of five zero-shot tasks in the GeneTuring dataset. Overall, GeneGPT achieves a macro-average score of 0.76, which is much higher than retrieval-augmented LLMs such as the New Bin
    
[^17]: ReelFramer：使用生成式人工智能与社交媒体共同创作新闻片段

    ReelFramer: Co-creating News Reels on Social Media with Generative AI. (arXiv:2304.09653v1 [cs.HC])

    [http://arxiv.org/abs/2304.09653](http://arxiv.org/abs/2304.09653)

    ReelFramer使用生成式人工智能与社交媒体共同创作新闻片段。它可以帮助记者探索一个故事的多种叙事框架，并生成脚本、角色板和故事板。用户研究发现该系统大大减轻了将一篇书面报道转化为新闻片段的负担。

    

    社交媒体上的短视频是许多年轻人发现和消费内容的主要方式。新闻机构希望通过新闻片段接触受众，但目前难以将传统的新闻报道格式转化为与平台风格相匹配的短小有趣视频。有多种方法可以围绕新闻事件构建片段式叙事，而选定其中一种则是具有挑战性的。不同的新闻故事需要不同的叙述框架，并需要在娱乐性和信息量之间达到不同的平衡。本文提出了一种名为ReelFramer的系统，利用文本和图像生成来帮助记者探索一个故事的多种叙事框架，然后生成他们可以编辑和迭代的脚本、角色板和故事板。在一项由五名新闻相关领域的研究生参与的用户研究中，我们发现该系统大大减轻了将一篇书面报道转化为新闻片段的负担，并探索叙事框架以找到正确的框架过程是非常有意义的。

    Short videos on social media are a prime way many young people find and consume content. News outlets would like to reach audiences through news reels, but currently struggle to translate traditional journalistic formats into the short, entertaining videos that match the style of the platform. There are many ways to frame a reel-style narrative around a news story, and selecting one is a challenge. Different news stories call for different framings, and require a different trade-off between entertainment and information. We present a system called ReelFramer that uses text and image generation to help journalists explore multiple narrative framings for a story, then generate scripts, character boards and storyboards they can edit and iterate on. A user study of five graduate students in journalism-related fields found the system greatly eased the burden of transforming a written story into a reel, and that exploring framings to find the right one was a rewarding process.
    
[^18]: 基于分布式优先经验回放的量子深度 Q 学习

    Quantum deep Q learning with distributed prioritized experience replay. (arXiv:2304.09648v1 [quant-ph])

    [http://arxiv.org/abs/2304.09648](http://arxiv.org/abs/2304.09648)

    本论文提出了 QDQN-DPER 框架，它将分布式优先经验回放和异步训练纳入算法，以提高量子强化学习在解决顺序决策任务中的效率。

    

    本研究介绍了 QDQN-DPER 框架，以提高量子强化学习 (QRL) 在解决顺序决策任务中的效率。该框架将优先经验回放和异步训练纳入训练算法，以减少高采样复杂性。数值模拟表明，QDQN-DPER 在具有相同模型架构的分布式量子 Q 学习的基础上表现更好。该框架可以在保持训练效率的同时适用于更复杂的任务。

    This paper introduces the QDQN-DPER framework to enhance the efficiency of quantum reinforcement learning (QRL) in solving sequential decision tasks. The framework incorporates prioritized experience replay and asynchronous training into the training algorithm to reduce the high sampling complexities. Numerical simulations demonstrate that QDQN-DPER outperforms the baseline distributed quantum Q learning with the same model architecture. The proposed framework holds potential for more complex tasks while maintaining training efficiency.
    
[^19]: Krohn-Rhodes逻辑

    The Krohn-Rhodes Logics. (arXiv:2304.09639v1 [cs.LO])

    [http://arxiv.org/abs/2304.09639](http://arxiv.org/abs/2304.09639)

    本篇论文提出了一组新的时间逻辑，通过使用Krohn和Rhodes的级联理论，扩展了过去的LTL表达能力，其中包括可以捕获其他prime automata的新的时间运算符。

    

    我们提出了一组新的过去的模态时间逻辑，通过使用Krohn和Rhodes的自动机级联理论，基于Past LTL扩展一组丰富的时间运算符而获得。该理论指出，每个自动机都可以表示为一些称为prime automata的基本自动机的级联。他们是所有自动机的构建块，类似于质数是所有自然数的构建块。我们展示了过去的LTL对应于称为flip-flops的一种prime automata的级联。特别地，Past LTL的时间运算符由flip-flops捕获，并且它们不能捕获任何其他prime automata，将表达能力限制在星号自由正则语言内。我们提出了新的时间运算符，可以捕获其他prime automata，从而扩展了Past LTL的表达能力。这些运算符是无穷多的，并且它们产生了无限数量的逻辑，捕获了正则语言的无限数量的不同片段。

    We present a new family of modal temporal logics of the past, obtained by extending Past LTL with a rich set of temporal operators based on the theory by Krohn and Rhodes for automata cascades. The theory says that every automaton can be expressed as a cascade of some basic automata called prime automata. They are the building blocks of all automata, analogously to prime numbers being the building blocks of all natural numbers. We show that Past LTL corresponds to cascades of one kind of prime automata called flip-flops. In particular, the temporal operators of Past LTL are captured by flip-flops, and they cannot capture any other prime automaton, confining the expressivity within the star-free regular languages. We propose novel temporal operators that can capture other prime automata, and hence extend the expressivity of Past LTL. Such operators are infinitely-many, and they yield an infinite number of logics capturing an infinite number of distinct fragments of the regular languages
    
[^20]: StyleDEM：一种通用的地形创作模型

    StyleDEM: a Versatile Model for Authoring Terrains. (arXiv:2304.09626v1 [cs.GR])

    [http://arxiv.org/abs/2304.09626](http://arxiv.org/abs/2304.09626)

    StyleDEM是一种通用的地形创作模型，它具有多种风格的工具箱，可以通过交互式笔刷进行创作和增强，使其非常适合娱乐行业的设计师。

    

    在过去的几十年里，已经提出了许多地形建模方法，提供高效且通常是交互式的创作工具。然而，它们通常不包括任何风格的概念，而这对于娱乐行业的设计师来说是一个至关重要的方面。我们介绍了一种名为StyleDEM的新型生成对抗网络方法，用于地形合成和创作，并具有风格的多功能工具箱。这种方法可以从输入的草图或现有地形开始。它输出的地形具有通过交互式笔刷进行创作并通过其他工具进行增强的特征，如风格操作或超分辨率。我们方法的优点在于工具箱的多功能性和互操作性。

    Many terrain modelling methods have been proposed for the past decades, providing efficient and often interactive authoring tools. However, they generally do not include any notion of style, which is a critical aspect for designers in the entertainment industry. We introduce StyleDEM, a new generative adversarial network method for terrain synthesis and authoring, with a versatile toolbox of authoring methods with style. This method starts from an input sketch or an existing terrain. It outputs a terrain with features that can be authored using interactive brushes and enhanced with additional tools such as style manipulation or super-resolution. The strength of our approach resides in the versatility and interoperability of the toolbox.
    
[^21]: MMDR：自主系统中的结果特征融合物体检测方法

    MMDR: A Result Feature Fusion Object Detection Approach for Autonomous System. (arXiv:2304.09609v1 [cs.CV])

    [http://arxiv.org/abs/2304.09609](http://arxiv.org/abs/2304.09609)

    MMDR是一种新的多模态融合方法，利用了来自单模态源的结果特征，能够更好地表示深层特征。同时，MMDR模型结合了单模态源的浅层和深层特征，从而进一步提高了检测精度。

    

    近年来，物体检测在自主系统中得到了广泛应用，包括2D和3D物体检测。该领域的最新研究主要集中在多模态方法上。本文提出了一种基于结果特征级融合的多模态融合方法。该方法利用从单模态源产生的结果特征，并将它们融合用于下游任务。基于此方法，提出了一种新的后融合网络，用于多模态物体检测，利用单模态结果作为特征。提出的方法称为基于结果特征的多模态检测器(MMDR)，旨在应用于2D和3D物体检测任务。与以往的多模态模型相比，本文提出的方法在较晚的阶段执行特征融合，有助于更好地表示单模态源的深层特征。此外，MMDR模型结合了单模态源的浅层和深层特征，从而进一步提高了检测精度。

    Object detection has been extensively utilized in autonomous systems in recent years, encompassing both 2D and 3D object detection. Recent research in this field has primarily centered around multimodal approaches for addressing this issue.In this paper, a multimodal fusion approach based on result feature-level fusion is proposed. This method utilizes the outcome features generated from single modality sources, and fuses them for downstream tasks.Based on this method, a new post-fusing network is proposed for multimodal object detection, which leverages the single modality outcomes as features. The proposed approach, called Multi-Modal Detector based on Result features (MMDR), is designed to work for both 2D and 3D object detection tasks. Compared to previous multimodal models, the proposed approach in this paper performs feature fusion at a later stage, enabling better representation of the deep-level features of single modality sources. Additionally, the MMDR model incorporates shal
    
[^22]: LEA: 学习优化策略的超越进化算法

    LEA: Beyond Evolutionary Algorithms via Learned Optimization Strategy. (arXiv:2304.09599v1 [cs.NE])

    [http://arxiv.org/abs/2304.09599](http://arxiv.org/abs/2304.09599)

    LEA是一种适应性强且能够有效利用目标任务低保真度信息的学习进化算法，从而比传统进化算法在更少的计算成本下获得更好的解决方案。

    

    进化算法已成为昂贵黑盒优化的强大框架。在更少的计算成本下获得更好的解决方案对于黑盒优化至关重要且具有挑战性。最关键的障碍是找出如何有效利用目标任务信息来形成高效的优化策略。然而，当前的方法由于优化策略的表征不足以及优化策略与目标任务之间的低效交互而显得薄弱。为了克服上述限制，我们设计了一种学习进化算法（LEA），以实现从手动设计的优化策略到学习优化策略的转换，其中包括超参数和更新规则。与传统进化算法不同，LEA对目标任务具有高适应性，并且可以在更少的计算成本下获得更好的解决方案。LEA还能够有效地利用目标任务的低保真度信息来形成高效的优化策略。

    Evolutionary algorithms (EAs) have emerged as a powerful framework for expensive black-box optimization. Obtaining better solutions with less computational cost is essential and challenging for black-box optimization. The most critical obstacle is figuring out how to effectively use the target task information to form an efficient optimization strategy. However, current methods are weak due to the poor representation of the optimization strategy and the inefficient interaction between the optimization strategy and the target task. To overcome the above limitations, we design a learned EA (LEA) to realize the move from hand-designed optimization strategies to learned optimization strategies, including not only hyperparameters but also update rules. Unlike traditional EAs, LEA has high adaptability to the target task and can obtain better solutions with less computational cost. LEA is also able to effectively utilize the low-fidelity information of the target task to form an efficient op
    
[^23]: 个人知识图谱生态系统：调查与研究路线图

    An Ecosystem for Personal Knowledge Graphs: A Survey and Research Roadmap. (arXiv:2304.09572v1 [cs.AI])

    [http://arxiv.org/abs/2304.09572](http://arxiv.org/abs/2304.09572)

    本论文提出了一个个人知识图谱（PKG）的生态系统，PKG的主要目的是数据管理和个性化服务。要解锁PKG的全部潜力，需要一个统一的框架，并提出了一个关于PKG的综合视图。

    

    本论文提出了一个个人知识图谱（PKG）的生态系统，通常定义为有关个人相关实体、其属性和它们之间关系的结构化信息资源。PKG是安全、精密的个人数据管理和个性化服务的关键支持。然而，在PKG能够广泛应用之前需要解决一些挑战。其中一个基本挑战是关于PKG的定义，因为术语有多种解释。我们提出了自己的PKG定义，强调了（1）单个个体拥有数据和（2）提供个性化服务作为主要目的的方面。我们进一步提出了一个综合的PKG视图，需要解锁它们的全部潜力，并提出了一个统一的框架，其中PKG是更大的生态系统的一部分，具有明确的与数据服务和数据源的接口。本文还展示了对当前PKG研究的全面调查和研究路线图。

    This paper presents an ecosystem for personal knowledge graphs (PKG), commonly defined as resources of structured information about entities related to an individual, their attributes, and the relations between them. PKGs are a key enabler of secure and sophisticated personal data management and personalized services. However, there are challenges that need to be addressed before PKGs can achieve widespread adoption. One of the fundamental challenges is the very definition of what constitutes a PKG, as there are multiple interpretations of the term. We propose our own definition of a PKG, emphasizing the aspects of (1) data ownership by a single individual and (2) the delivery of personalized services as the primary purpose. We further argue that a holistic view of PKGs is needed to unlock their full potential, and propose a unified framework for PKGs, where the PKG is a part of a larger ecosystem with clear interfaces towards data services and data sources. A comprehensive survey and 
    
[^24]: SemEval 2023 任务6: LegalEval -- 理解法律文本

    SemEval 2023 Task 6: LegalEval -- Understanding Legal Texts. (arXiv:2304.09548v1 [cs.CL])

    [http://arxiv.org/abs/2304.09548](http://arxiv.org/abs/2304.09548)

    SemEval 2023举办了LegalEval共享任务，即理解法律文本，包括 自动结构化和语义连贯化的法律文件（Task-A），法律命名实体识别（Task-B）以及自动预测法律案件结果和提供预测解释（Task-C）。26个团队提交了系统论文并在所有子任务中优于基准线，但仍有改进空间。

    

    在人口众多的国家，待处理的法律案件呈指数增长。有必要开发基于自然语言处理的技术，对法律文件进行处理和自动理解。为了促进在法律自然语言处理领域的研究，我们在 SemEval 2023 上组织了共享任务 LegalEval - 理解法律文本。LegalEval 任务有三个子任务：Task-A（修辞角色标记）是自动将法律文件结构化为语义连贯的单元，Task-B（法律命名实体识别）处理在法律文件中识别相关实体，而 Task-C（法院判决预测与解释）探索了自动预测法律案件结果以及提供预测解释的可能性。共有26个团队（分布在全球的约100名参与者）提交了系统论文。在每个子任务中，所提出的系统都优于基准线；但是，仍然有很大的改进空间。本文介绍了 LegalEval 任务的组织和细节，并概述了参与系统及其性能。

    In populous countries, pending legal cases have been growing exponentially. There is a need for developing NLP-based techniques for processing and automatically understanding legal documents. To promote research in the area of Legal NLP we organized the shared task LegalEval - Understanding Legal Texts at SemEval 2023. LegalEval task has three sub-tasks: Task-A (Rhetorical Roles Labeling) is about automatically structuring legal documents into semantically coherent units, Task-B (Legal Named Entity Recognition) deals with identifying relevant entities in a legal document and Task-C (Court Judgement Prediction with Explanation) explores the possibility of automatically predicting the outcome of a legal case along with providing an explanation for the prediction. In total 26 teams (approx. 100 participants spread across the world) submitted systems paper. In each of the sub-tasks, the proposed systems outperformed the baselines; however, there is a lot of scope for improvement. This pape
    
[^25]: SelfAct: 基于自监督和主动学习的个性化活动识别

    SelfAct: Personalized Activity Recognition based on Self-Supervised and Active Learning. (arXiv:2304.09530v1 [cs.LG])

    [http://arxiv.org/abs/2304.09530](http://arxiv.org/abs/2304.09530)

    SelfAct是一种基于自我监督和主动学习的人体活动识别框架，可以用大量未标记数据进行预训练，并通过新的无监督主动学习策略进行微调，从而实现对每个用户的个性化活动识别。

    

    目前，基于传感器的人体活动识别已经成为了穿戴设备和移动设备上应用广泛的方法，监督深度学习模型是目前领先的方法。然而，训练这些模型需要大量标记数据，采集这些数据通常是耗时、昂贵且容易出错的。与此同时，由于活动执行的内部和外部可变性，活动模型应该为每个用户个性化设计。本文提出了SelfAct：一种新的用于缓解这些问题的人体活动识别框架，它结合自监督和主动学习。SelfAct利用从许多用户收集的大量未标记数据进行自我监督预训练深度学习模型，以学习有意义、高效的传感器数据的潜在表示。由此得出的预训练模型可以被新用户当地使用，他们将通过一种新的无监督主动学习策略来微调这个模型。我们在两个公开可用的人体活动识别数据集上的实验表明，SelfAct在准确性和模型效率方面都取得了优异的表现。

    Supervised Deep Learning (DL) models are currently the leading approach for sensor-based Human Activity Recognition (HAR) on wearable and mobile devices. However, training them requires large amounts of labeled data whose collection is often time-consuming, expensive, and error-prone. At the same time, due to the intra- and inter-variability of activity execution, activity models should be personalized for each user. In this work, we propose SelfAct: a novel framework for HAR combining self-supervised and active learning to mitigate these problems. SelfAct leverages a large pool of unlabeled data collected from many users to pre-train through self-supervision a DL model, with the goal of learning a meaningful and efficient latent representation of sensor data. The resulting pre-trained model can be locally used by new users, which will fine-tune it thanks to a novel unsupervised active learning strategy. Our experiments on two publicly available HAR datasets demonstrate that SelfAct ac
    
[^26]: NetGPT：网络流量生成预训练变压器模型

    NetGPT: Generative Pretrained Transformer for Network Traffic. (arXiv:2304.09513v1 [cs.NI])

    [http://arxiv.org/abs/2304.09513](http://arxiv.org/abs/2304.09513)

    本文提出了首个网络流量生成预训练变压器模型NetGPT，该模型可以优化网络任务的训练效率和有效性。

    

    预训练模型可以利用大规模的原始数据学习网络流量的基本特征，并为输入流量生成可区分的结果，而不考虑特定的下游任务。有效的预训练模型可以显著优化下游任务的训练效率和有效性，例如流量分类、攻击检测、资源调度、协议分析和流量生成。本文提出了NetGPT，旨在为网络流量构建预训练模型并解决多样的挑战。

    Pretrained models for network traffic can utilize large-scale raw data to learn the essential characteristics of network traffic, and generate distinguishable results for input traffic without considering specific downstream tasks. Effective pretrained models can significantly optimize the training efficiency and effectiveness of downstream tasks, such as traffic classification, attack detection, resource scheduling, protocol analysis, and traffic generation. Despite the great success of pretraining in natural language processing, there is no work in the network field. Considering the diverse demands and characteristics of network traffic and network tasks, it is non-trivial to build a pretrained model for network traffic and we face various challenges, especially the heterogeneous headers and payloads in the multi-pattern network traffic and the different dependencies for contexts of diverse downstream network tasks.  To tackle these challenges, in this paper, we make the first attemp
    
[^27]: 反向知识蒸馏结合仿生结构学习用于脉冲神经网络的构建

    Biologically inspired structure learning with reverse knowledge distillation for spiking neural networks. (arXiv:2304.09500v1 [cs.NE])

    [http://arxiv.org/abs/2304.09500](http://arxiv.org/abs/2304.09500)

    本文提出了一种基于进化的结构构建方法用于构建更合理的脉冲神经网络。通过结合知识蒸馏和连接剪枝方法，动态优化突触连接可以达到最优状态。

    

    由于生物学本源，脉冲神经网络(SNNs)在感知信息识别任务方面具有独特的特点。然而，一些当前基于脉冲的模型的性能受到结构的限制，这意味着全连接或过深的结构会带来过多的冗余，这是阻碍SNNs实际应用的关键因素之一。针对这个问题，本文提出了一种基于进化的结构构建方法来构建更合理的SNNs。通过集成知识蒸馏和连接剪枝方法，SNNs的突触连接可以动态优化以达到最佳状态。因此，SNNs的结构不仅可以吸收来自教师模型的知识，还可以进行迭代搜索以优化结构。

    Spiking neural networks (SNNs) have superb characteristics in sensory information recognition tasks due to their biological plausibility. However, the performance of some current spiking-based models is limited by their structures which means either fully connected or too-deep structures bring too much redundancy. This redundancy from both connection and neurons is one of the key factors hindering the practical application of SNNs. Although Some pruning methods were proposed to tackle this problem, they normally ignored the fact the neural topology in the human brain could be adjusted dynamically. Inspired by this, this paper proposed an evolutionary-based structure construction method for constructing more reasonable SNNs. By integrating the knowledge distillation and connection pruning method, the synaptic connections in SNNs can be optimized dynamically to reach an optimal state. As a result, the structure of SNNs could not only absorb knowledge from the teacher model but also searc
    
[^28]: 情感融合在社交媒体上的应用：用于心理疾病检测的综述

    Emotion fusion for mental illness detection from social media: A survey. (arXiv:2304.09493v1 [cs.CL])

    [http://arxiv.org/abs/2304.09493](http://arxiv.org/abs/2304.09493)

    本文为全面综述通过分析社交媒体上用户生成的文章来使用情感信息进行心理疾病检测的方法。文章回顾了不同的融合策略及其优缺点，并讨论了该领域研究人员所面临的挑战和未来的研究方向。

    

    心理疾病是全球最普遍的公共卫生问题之一，对人们的生活和社会健康产生负面影响。随着社交媒体的普及，对于通过分析社交媒体上用户生成的文章来早期发现心理疾病的研究越来越受到关注。根据情绪和心理疾病之间的相关性，利用和融合情感信息已成为一个有价值的研究主题。本文全面综述了在社交媒体上结合情感融合的方法用于心理疾病检测。我们首先回顾了不同的融合策略及其优缺点。随后，我们讨论了该领域研究人员面临的主要挑战，包括有关数据集可用性和质量、算法性能和可解释性的问题。我们还提出了一些未来研究的潜在方向。

    Mental illnesses are one of the most prevalent public health problems worldwide, which negatively influence people's lives and society's health. With the increasing popularity of social media, there has been a growing research interest in the early detection of mental illness by analysing user-generated posts on social media. According to the correlation between emotions and mental illness, leveraging and fusing emotion information has developed into a valuable research topic. In this article, we provide a comprehensive survey of approaches to mental illness detection in social media that incorporate emotion fusion. We begin by reviewing different fusion strategies, along with their advantages and disadvantages. Subsequently, we discuss the major challenges faced by researchers working in this area, including issues surrounding the availability and quality of datasets, the performance of algorithms and interpretability. We additionally suggest some potential directions for future resea
    
[^29]: 基于排名学习和局部模型的多目标高维昂贵问题的进化算法

    Rank-Based Learning and Local Model Based Evolutionary Algorithm for High-Dimensional Expensive Multi-Objective Problems. (arXiv:2304.09444v1 [cs.NE])

    [http://arxiv.org/abs/2304.09444](http://arxiv.org/abs/2304.09444)

    本文提出了一种基于排名学习和局部模型的多目标进化算法，该算法使用分类器进行排名，以解决高维昂贵多目标优化问题。

    

    近年来，辅以代理模型的进化算法广泛应用于解决复杂而计算代价昂贵的多目标优化问题。但是在处理高维优化问题时，这些辅以代理模型的多目标进化算法的性能会急剧恶化。本文提出了一种新颖的基于分类器辅助的排名学习和局部模型的多目标进化算法 (CLMEA)，用于解决高维昂贵的多目标优化问题。该算法由三部分组成：分类器辅助的排名学习、超体积非支配搜索和相对稀疏目标空间的局部搜索。具体来说，该算法建立了一个概率神经网络作为分类器，将后代划分为几个等级。不同等级的后代使用排名学习策略生成更具有前景性和信息性的候选解用于实际优化函数。

    Surrogate-assisted evolutionary algorithms have been widely developed to solve complex and computationally expensive multi-objective optimization problems in recent years. However, when dealing with high-dimensional optimization problems, the performance of these surrogate-assisted multi-objective evolutionary algorithms deteriorate drastically. In this work, a novel Classifier-assisted rank-based learning and Local Model based multi-objective Evolutionary Algorithm (CLMEA) is proposed for high-dimensional expensive multi-objective optimization problems. The proposed algorithm consists of three parts: classifier-assisted rank-based learning, hypervolume-based non-dominated search, and local search in the relatively sparse objective space. Specifically, a probabilistic neural network is built as classifier to divide the offspring into a number of ranks. The offspring in different ranks uses rank-based learning strategy to generate more promising and informative candidates for real funct
    
[^30]: 用于GPU模拟非凸物体的本地物体裁剪碰撞网络的高效碰撞检测算法

    Local object crop collision network for efficient simulation of non-convex objects in GPU-based simulators. (arXiv:2304.09439v1 [cs.RO])

    [http://arxiv.org/abs/2304.09439](http://arxiv.org/abs/2304.09439)

    提出了一种数据驱动的碰撞检测方法，用于高效模拟非凸物体，不需要在计算速度和准确性之间进行权衡，具有较小的在线计算时间和更好的GPU利用率。

    

    本文旨在开发一种用于GPU模拟非凸物体的高效碰撞检测算法。目前GPU模拟器在模拟非凸物体时需要在速度、通用性和精度之间做出权衡，主要问题在于现有的碰撞检测算法需要在计算速度和准确性之间进行权衡。我们提出了一种数据驱动的碰撞检测方法，其中精度仅取决于离线数据集的质量和数量，而不是在线计算时间。

    Our goal is to develop an efficient contact detection algorithm for large-scale GPU-based simulation of non-convex objects. Current GPU-based simulators such as IsaacGym and Brax must trade-off speed with fidelity, generality, or both when simulating non-convex objects. Their main issue lies in contact detection (CD): existing CD algorithms, such as Gilbert-Johnson-Keerthi (GJK), must trade off their computational speed with accuracy which becomes expensive as the number of collisions among non-convex objects increases. We propose a data-driven approach for CD, whose accuracy depends only on the quality and quantity of offline dataset rather than online computation time. Unlike GJK, our method inherently has a uniform computational flow, which facilitates efficient GPU usage based on advanced compilers such as XLA (Accelerated Linear Algebra). Further, we offer a data-efficient solution by learning the patterns of colliding local crop object shapes, rather than global object shapes whi
    
[^31]: 鞅后验神经过程

    Martingale Posterior Neural Processes. (arXiv:2304.09431v1 [cs.LG])

    [http://arxiv.org/abs/2304.09431](http://arxiv.org/abs/2304.09431)

    本文提出了一种基于鞅后验的神经过程方法，用于估计使用神经网络隐式定义的随机过程，并在 benchmark 数据集上表现出更高的精度和样本效率。

    

    神经过程(NP)可用于估计使用神经网络隐式定义的随机过程，而不是预先规定已知先验的过程，例如高斯过程。理想的NP将从数据中学习一切而没有任何归纳偏差，但在实践中，我们常常为了方便估计而限制了随机过程的类别。本文提出了一种基于鞅后验的方法，为未来数据指定了一种预测分布，从而减小了生成函数时的不确定性，并提出一个新的MPNP框架，表现出比现有NP方法更高的精度和样本效率。

    A Neural Process (NP) estimates a stochastic process implicitly defined with neural networks given a stream of data, rather than pre-specifying priors already known, such as Gaussian processes. An ideal NP would learn everything from data without any inductive biases, but in practice, we often restrict the class of stochastic processes for the ease of estimation. One such restriction is the use of a finite-dimensional latent variable accounting for the uncertainty in the functions drawn from NPs. Some recent works show that this can be improved with more "data-driven" source of uncertainty such as bootstrapping. In this work, we take a different approach based on the martingale posterior, a recently developed alternative to Bayesian inference. For the martingale posterior, instead of specifying prior-likelihood pairs, a predictive distribution for future data is specified. Under specific conditions on the predictive distribution, it can be shown that the uncertainty in the generated fu
    
[^32]: 大型神经网络的多校准可最小化损失

    Loss minimization yields multicalibration for large neural networks. (arXiv:2304.09424v1 [cs.LG])

    [http://arxiv.org/abs/2304.09424](http://arxiv.org/abs/2304.09424)

    本文展示了对于大型神经网络大小，最优地最小化损失会导致多校准，以提供公平的预测结果。

    

    多校准是一种公平性概念，旨在提供跨大量团体的准确预测。即使对于简单的预测器，如线性函数，多校准也被认为是与最小化损失不同的目标。在本文中，我们展示了对于（几乎所有的）大型神经网络大小，最优地最小化平方误差会导致多校准。我们的结果关于神经网络的表征方面，而不是关于算法或样本复杂性考虑。以前的这样的结果仅适用于几乎贝叶斯最优的预测器，因此是表征无关的。我们强调，我们的结果不适用于优化神经网络的特定算法，如 SGD，并且不应解释为“公平性从优化神经网络中获得免费的好处”。

    Multicalibration is a notion of fairness that aims to provide accurate predictions across a large set of groups. Multicalibration is known to be a different goal than loss minimization, even for simple predictors such as linear functions. In this note, we show that for (almost all) large neural network sizes, optimally minimizing squared error leads to multicalibration. Our results are about representational aspects of neural networks, and not about algorithmic or sample complexity considerations. Previous such results were known only for predictors that were nearly Bayes-optimal and were therefore representation independent. We emphasize that our results do not apply to specific algorithms for optimizing neural networks, such as SGD, and they should not be interpreted as "fairness comes for free from optimizing neural networks".
    
[^33]: Pointerformer: 多指针深度强化Transformer算法解决旅行商问题

    Pointerformer: Deep Reinforced Multi-Pointer Transformer for the Traveling Salesman Problem. (arXiv:2304.09407v1 [cs.AI])

    [http://arxiv.org/abs/2304.09407](http://arxiv.org/abs/2304.09407)

    Pointerformer是一种端到端DRL算法，采用多指针Transformer算法来解决旅行商问题。它使用可逆残差网络和多指针网络来控制内存消耗，使用深度Q网络来指导解码器，是目前在大规模TSP实例上取得最先进效果的方法。

    

    旅行商问题(TSP)最初起源于交通和物流行业的经典路线优化问题，现已成为制造和生物等更广泛领域的重要任务。近年来，深度强化学习(DRL)因其高推理效率而越来越多地被采用来解决TSP问题。然而，大多数现有的端到端DRL算法仅在小规模TSP实例上表现良好，并且随着问题规模的扩大，内存消耗和计算时间急剧增加，很难推广到大规模问题上。本文提出了一种新颖的端到端DRL方法，称为Pointerformer，基于多指针Transformer。特别地，Pointerformer在编码器中采用了可逆残差网络，在解码器中采用了多指针网络，以有效控制编码器-解码器体系结构的内存消耗。为了进一步提高TSP解决方案的性能，Pointerformer还使用了深度Q网络(DQN)来指导解码器。实验结果表明，Pointerformer在大规模TSP实例上取得了最先进的效果。

    Traveling Salesman Problem (TSP), as a classic routing optimization problem originally arising in the domain of transportation and logistics, has become a critical task in broader domains, such as manufacturing and biology. Recently, Deep Reinforcement Learning (DRL) has been increasingly employed to solve TSP due to its high inference efficiency. Nevertheless, most of existing end-to-end DRL algorithms only perform well on small TSP instances and can hardly generalize to large scale because of the drastically soaring memory consumption and computation time along with the enlarging problem scale. In this paper, we propose a novel end-to-end DRL approach, referred to as Pointerformer, based on multi-pointer Transformer. Particularly, Pointerformer adopts both reversible residual network in the encoder and multi-pointer network in the decoder to effectively contain memory consumption of the encoder-decoder architecture. To further improve the performance of TSP solutions, Pointerformer e
    
[^34]: H-TSP：基于层次强化学习的大规模旅行商问题求解

    H-TSP: Hierarchically Solving the Large-Scale Travelling Salesman Problem. (arXiv:2304.09395v1 [cs.AI])

    [http://arxiv.org/abs/2304.09395](http://arxiv.org/abs/2304.09395)

    我们提出了一种称为H-TSP的基于层次强化学习的端到端学习框架，它通过联合训练上下层策略，直接生成给定TSP实例的解决方案，而不需要依赖于任何耗时的搜索过程。我们在随机生成的TSP实例上进行的实验表明，H-TSP可以获得可比较的结果（与其他最先进方法之间的间隙为3.42% vs. 7.3%），而在具有2000个以上节点的实例上则胜过其他方法。

    

    我们提出了一种基于层次强化学习的端到端学习框架，称为H-TSP，用于解决大规模旅行商问题（TSP）。H-TSP从头开始构建TSP实例的解决方案，依赖于两个组件：上层策略从要遍历的所有节点中选择一小部分节点（在我们的实验中最多为200个），而下层策略将所选节点作为输入，并输出连接它们与现有部分路径（最初仅包含车站）相连的路径。在联合训练上下层策略之后，我们的方法可以直接生成给定TSP实例的解决方案，而不需要依赖于任何耗时的搜索过程。为了展示所提出方法的有效性，我们在具有不同节点数的随机生成TSP实例上进行了广泛的实验。我们表明，在具有1000个节点的实例上，H-TSP可以获得可比较的结果（与其他最先进方法之间的间隙为3.42% vs. 7.3%），而在具有2000个以上节点的实例上则胜过其他方法。

    We propose an end-to-end learning framework based on hierarchical reinforcement learning, called H-TSP, for addressing the large-scale Travelling Salesman Problem (TSP). The proposed H-TSP constructs a solution of a TSP instance starting from the scratch relying on two components: the upper-level policy chooses a small subset of nodes (up to 200 in our experiment) from all nodes that are to be traversed, while the lower-level policy takes the chosen nodes as input and outputs a tour connecting them to the existing partial route (initially only containing the depot). After jointly training the upper-level and lower-level policies, our approach can directly generate solutions for the given TSP instances without relying on any time-consuming search procedures. To demonstrate effectiveness of the proposed approach, we have conducted extensive experiments on randomly generated TSP instances with different numbers of nodes. We show that H-TSP can achieve comparable results (gap 3.42% vs. 7.3
    
[^35]: 通过知识图谱和多尺度数据集成推断高层地理概念：C型建筑模式识别案例研究

    Inferring High-level Geographical Concepts via Knowledge Graph and Multi-scale Data Integration: A Case Study of C-shaped Building Pattern Recognition. (arXiv:2304.09391v1 [cs.CV])

    [http://arxiv.org/abs/2304.09391](http://arxiv.org/abs/2304.09391)

    本文提出了一种通过知识图谱和多尺度数据集成识别C型建筑模式的方法，提高了模式识别的效率和有效性。

    

    有效的建筑模式识别对于了解城市形态、自动化地图概括和可视化3D城市模型至关重要。大多数现有研究使用基于视觉感知规则和邻近图模型的独立于对象的方法来提取模式。然而，由于人类视觉是一个基于部件的系统，模式识别可能需要将形状分解为部件或将其分组为簇。现有方法可能无法识别所有视觉感知模式，并且邻近图模型可能效率低下。为了提高效率和效果，我们使用知识图谱集成多尺度数据，重点关注C型建筑模式识别。首先，我们使用属性图表示参与C型建筑模式识别的不同尺度内和跨尺度之间的建筑之间的关系。接下来，我们将这个知识图谱存储在图形数据库中，并将C型模式识别和丰富的规则转换为查询。

    Effective building pattern recognition is critical for understanding urban form, automating map generalization, and visualizing 3D city models. Most existing studies use object-independent methods based on visual perception rules and proximity graph models to extract patterns. However, because human vision is a part-based system, pattern recognition may require decomposing shapes into parts or grouping them into clusters. Existing methods may not recognize all visually aware patterns, and the proximity graph model can be inefficient. To improve efficiency and effectiveness, we integrate multi-scale data using a knowledge graph, focusing on the recognition of C-shaped building patterns. First, we use a property graph to represent the relationships between buildings within and across different scales involved in C-shaped building pattern recognition. Next, we store this knowledge graph in a graph database and convert the rules for C-shaped pattern recognition and enrichment into query co
    
[^36]: 利用知识蒸馏压缩多语言神经机器翻译模型的实证研究

    An Empirical Study of Leveraging Knowledge Distillation for Compressing Multilingual Neural Machine Translation Models. (arXiv:2304.09388v1 [cs.CL])

    [http://arxiv.org/abs/2304.09388](http://arxiv.org/abs/2304.09388)

    本文研究了利用知识蒸馏方法压缩多语言神经机器翻译模型的实证效果，并以印地语到英语的翻译为案例展示了蒸馏方法对模型大小和性能的影响。研究发现，深层紧凑模型往往与浅层非紧凑模型一样好，将蒸馏模型在高质量子集上微调可以提高翻译质量。

    

    知识蒸馏是一种压缩神经模型的方法。然而，尽管MNMT（多语言神经机器翻译）的普及和优越性，但从大型MNMT模型中提取知识的研究实际上并不存在。本文填补了这一空白，提出了一种利用知识蒸馏压缩MNMT模型的实证研究。我们以印地语到英语的翻译为案例研究，并证明了常用的语言无关和语言感知的蒸馏方法可以使模型压缩4-5倍，但性能下降多达3.5 BLEU。为了缓解这一问题，我们进行了多个设计上的实验，包括深层模型和浅层模型、参数共享、多阶段训练和适配器等。我们观察到，深层紧凑模型往往与浅层非紧凑模型一样好，将蒸馏模型在高质量子集上微调可以稍微提高翻译质量。

    Knowledge distillation (KD) is a well-known method for compressing neural models. However, works focusing on distilling knowledge from large multilingual neural machine translation (MNMT) models into smaller ones are practically nonexistent, despite the popularity and superiority of MNMT. This paper bridges this gap by presenting an empirical investigation of knowledge distillation for compressing MNMT models. We take Indic to English translation as a case study and demonstrate that commonly used language-agnostic and language-aware KD approaches yield models that are 4-5x smaller but also suffer from performance drops of up to 3.5 BLEU. To mitigate this, we then experiment with design considerations such as shallower versus deeper models, heavy parameter sharing, multi-stage training, and adapters. We observe that deeper compact models tend to be as good as shallower non-compact ones, and that fine-tuning a distilled model on a High-Quality subset slightly boosts translation quality. 
    
[^37]: 探究深度神经网络中三维泛化的本质。

    Investigating the Nature of 3D Generalization in Deep Neural Networks. (arXiv:2304.09358v1 [cs.CV])

    [http://arxiv.org/abs/2304.09358](http://arxiv.org/abs/2304.09358)

    本论文研究了深度学习架构对新视图推广的能力，发现深度模型具有很好的推广能力，但它们的方式与所有现有模型不同。

    

    视觉对象识别系统需要从一组二维训练视图推广到新视图。如何使人类视觉系统可以推广到新视图的问题已经在心理学、计算机视觉和神经科学中进行了研究和建模。现代深度学习架构用于对象识别对新视图具有很好的推广能力，但机制尚未得到很好的理解。在本文中，我们表征了常见深度学习架构对新视图推广的能力。我们将其制定为一个监督分类任务，其中标签对应于唯一的三维物体，示例对应于物体在不同三维方向上的二维视图。我们考虑了三种常见的推广到新视图的模型：(i)完全的三维泛化，(ii)纯二维匹配，(iii)基于视图的线性组合匹配。我们发现，深度模型具有很好的推广能力，但它们的方式与所有这些现有模型不同。外推到vi

    Visual object recognition systems need to generalize from a set of 2D training views to novel views. The question of how the human visual system can generalize to novel views has been studied and modeled in psychology, computer vision, and neuroscience. Modern deep learning architectures for object recognition generalize well to novel views, but the mechanisms are not well understood. In this paper, we characterize the ability of common deep learning architectures to generalize to novel views. We formulate this as a supervised classification task where labels correspond to unique 3D objects and examples correspond to 2D views of the objects at different 3D orientations. We consider three common models of generalization to novel views: (i) full 3D generalization, (ii) pure 2D matching, and (iii) matching based on a linear combination of views. We find that deep models generalize well to novel views, but they do so in a way that differs from all these existing models. Extrapolation to vi
    
[^38]: 长期安全优化碳储存操作

    Optimizing Carbon Storage Operations for Long-Term Safety. (arXiv:2304.09352v1 [cs.AI])

    [http://arxiv.org/abs/2304.09352](http://arxiv.org/abs/2304.09352)

    本文提出使用信念状态规划来优化注入器和监测井位置，在确保安全的情况下最大化CO2储存效果。实验结果表明该方法有效，同时还引入了神经网络代理模型来处理决策过程的复杂动态。

    

    为了应对全球变暖和减缓与气候变化相关的风险，碳捕集和封存技术（CCS）已经成为一项关键技术。然而，将CO2安全地封存在地质层中长期储存存在着一些挑战。在这项研究中，我们将碳储存操作的决策过程建模为部分可观察的马尔可夫决策过程（POMDP），并使用信念状态规划来优化注入器和监测井的位置，以最大程度地储存CO2，同时保持安全。仿真实验的实证结果表明，我们的方法有效地确保了安全的长期碳储存操作。我们展示了我们的方法的灵活性，通过引入三种不同的监测策略，并研究它们对决策质量的影响。此外，我们引入了一个用于处理POMDP决策过程复杂动态的神经网络代理模型。

    To combat global warming and mitigate the risks associated with climate change, carbon capture and storage (CCS) has emerged as a crucial technology. However, safely sequestering CO2 in geological formations for long-term storage presents several challenges. In this study, we address these issues by modeling the decision-making process for carbon storage operations as a partially observable Markov decision process (POMDP). We solve the POMDP using belief state planning to optimize injector and monitoring well locations, with the goal of maximizing stored CO2 while maintaining safety. Empirical results in simulation demonstrate that our approach is effective in ensuring safe long-term carbon storage operations. We showcase the flexibility of our approach by introducing three different monitoring strategies and examining their impact on decision quality. Additionally, we introduce a neural network surrogate model for the POMDP decision-making process to handle the complex dynamics of the
    
[^39]: LLM作为机器人的大脑：统一自我中心记忆与控制

    LLM as A Robotic Brain: Unifying Egocentric Memory and Control. (arXiv:2304.09349v1 [cs.AI])

    [http://arxiv.org/abs/2304.09349](http://arxiv.org/abs/2304.09349)

    本文提出了一个统一自我中心记忆和控制的框架LLM-Brain，使用大规模语言模型作为机器人大脑进行零-shot学习。该框架包括封闭式多轮对话，覆盖了感知、规划、控制和记忆，具有很好的泛化性能，适用于多个机器人任务。

    

    体感人工智能研究和开发具备物理或虚拟实体（即机器人）并能够与环境动态交互的智能系统。记忆和控制是体感系统的两个基本部分，通常需要分别使用框架进行建模。本文提出了一个新的、可推广的框架，称为LLM-Brain：使用大规模语言模型作为机器人大脑，统一自我中心记忆和控制。LLM-Brain框架集成了多个多模态语言模型用于机器人任务，利用零-shot学习方法。LLM-Brain中的所有组件使用自然语言进行封闭式多轮对话，包括感知、规划、控制和记忆。系统的核心是一个具备自我中心记忆和控制机器人的实体LLM。我们通过研究两个下游任务：主动探索和实体问答来演示LLM-Brain。

    Embodied AI focuses on the study and development of intelligent systems that possess a physical or virtual embodiment (i.e. robots) and are able to dynamically interact with their environment. Memory and control are the two essential parts of an embodied system and usually require separate frameworks to model each of them. In this paper, we propose a novel and generalizable framework called LLM-Brain: using Large-scale Language Model as a robotic brain to unify egocentric memory and control. The LLM-Brain framework integrates multiple multimodal language models for robotic tasks, utilizing a zero-shot learning approach. All components within LLM-Brain communicate using natural language in closed-loop multi-round dialogues that encompass perception, planning, control, and memory. The core of the system is an embodied LLM to maintain egocentric memory and control the robot. We demonstrate LLM-Brain by examining two downstream tasks: active exploration and embodied question answering. The
    
[^40]: Promptify: 利用大型语言模型的互动提示探索对文本到图像生成进行优化

    Promptify: Text-to-Image Generation through Interactive Prompt Exploration with Large Language Models. (arXiv:2304.09337v1 [cs.HC])

    [http://arxiv.org/abs/2304.09337](http://arxiv.org/abs/2304.09337)

    Promptify是一种基于大型语言模型的互动系统，用于优化文本到图像生成模型的提示探索和优化。该系统通过建议引擎快速探索和创作样式多样的提示，而用户可以通过反馈循环迭代地优化他们的提示，以增强所期望的特征并避免不需要的特征。

    

    文本到图像生成模型根据文本提示生成高质量图像已经展示出卓越的性能。但是，精确捕捉用户创意意图的提示仍然具有挑战性。通常需要耗费大量时间进行试错性的操作，确保模型能够准确识别提示和用户意图的差异。为了解决这些问题，我们提出了 Promptify，一种支持文本到图像生成模型提示探索和优化的互动系统。Promptify 利用大型语言模型的建议引擎，帮助用户快速探索和创作多样化的提示。我们的界面允许用户灵活地组织生成的图像，并根据他们的偏好，Promptify 提供对原始提示的建议更改。这种反馈循环使用户能够迭代地优化他们的提示，并增强所期望的特征，同时避免不需要的特征。我们的用户研究表明，Promptify 能够有效地改善用户的文本提示生成体验。

    Text-to-image generative models have demonstrated remarkable capabilities in generating high-quality images based on textual prompts. However, crafting prompts that accurately capture the user's creative intent remains challenging. It often involves laborious trial-and-error procedures to ensure that the model interprets the prompts in alignment with the user's intention. To address the challenges, we present Promptify, an interactive system that supports prompt exploration and refinement for text-to-image generative models. Promptify utilizes a suggestion engine powered by large language models to help users quickly explore and craft diverse prompts. Our interface allows users to organize the generated images flexibly, and based on their preferences, Promptify suggests potential changes to the original prompt. This feedback loop enables users to iteratively refine their prompts and enhance desired features while avoiding unwanted ones. Our user study shows that Promptify effectively f
    
[^41]: 基于静态和动态可学习个性化图卷积网络的时空海表温度预测研究

    Towards Spatio-temporal Sea Surface Temperature Forecasting via Static and Dynamic Learnable Personalized Graph Convolution Network. (arXiv:2304.09290v1 [cs.LG])

    [http://arxiv.org/abs/2304.09290](http://arxiv.org/abs/2304.09290)

    该论文提出了基于静态和动态可学习个性化图卷积网络的时空海表温度预测方法，其中利用两个图学习层分别模型化了SST数据的固定网络和动态网络，并设计了个性化的图卷积网络层以精确预测时空变化。实验结果显示，该方法在预测准确度方面优于目前最先进的方法。

    

    海表温度对于地球大气非常重要，因为其动力学对于塑造本地和全球气候有很大的作用，并且深刻地影响着我们的生态系统。准确预测海表温度能够带来重大的经济和社会影响，例如提前数月更好地准备极端天气，如严重干旱或热带气旋。然而，由于海洋系统的内在复杂性和不确定性，这项任务面临着独特的挑战。为了解决这个问题，本文提出了一个新颖的基于静态和动态可学习个性化图卷积网络 (SD-LPGC)。实验结果表明，SD-LPGC方法在预测精度方面优于目前最先进的方法。

    Sea surface temperature (SST) is uniquely important to the Earth's atmosphere since its dynamics are a major force in shaping local and global climate and profoundly affect our ecosystems. Accurate forecasting of SST brings significant economic and social implications, for example, better preparation for extreme weather such as severe droughts or tropical cyclones months ahead. However, such a task faces unique challenges due to the intrinsic complexity and uncertainty of ocean systems. Recently, deep learning techniques, such as graphical neural networks (GNN), have been applied to address this task. Even though these methods have some success, they frequently have serious drawbacks when it comes to investigating dynamic spatiotemporal dependencies between signals. To solve this problem, this paper proposes a novel static and dynamic learnable personalized graph convolution network (SD-LPGC). Specifically, two graph learning layers are first constructed to respectively model the stabl
    
[^42]: 基于嵌入式检索的完整性和垃圾处理方法：社交网络搜索案例研究

    Integrity and Junkiness Failure Handling for Embedding-based Retrieval: A Case Study in Social Network Search. (arXiv:2304.09287v1 [cs.IR])

    [http://arxiv.org/abs/2304.09287](http://arxiv.org/abs/2304.09287)

    本文提出了解决基于嵌入式检索的社交网络搜索中完整性和垃圾性问题的有效方法，其中包括索引处理和针对性用户分组处理等。这些方法表现出了良好的结果。

    

    基于嵌入式检索已经被广泛应用于电子商务、社交网络搜索等各种搜索应用中。尽管该方法在语义匹配和上下文搜索等任务中表现出了良好的效果，但它仍受到无法控制的关联性问题的困扰。本文在对早期应用于我们的社交网络搜索引擎的嵌入式检索进行分析的基础上，定义了引入的两种主要的故障类型，完整性和垃圾性。前者是指可以严重危害用户体验的仇恨言论和攻击性内容等问题，而后者包括类似模糊文本匹配或语言不匹配的无关结果。进一步提出了有效的模型推断方法来解决这个问题，包括索引处理和针对性用户分组处理等。尽管方法简单，但我们证明了这些方法在离线NDCG和在线A/B测试指标增益方面具有良好的表现。我们分析了这些故障的原因并提出了有效的解决方案来解决在基于嵌入式检索的社交网络搜索中的完整性和垃圾性问题。

    Embedding based retrieval has seen its usage in a variety of search applications like e-commerce, social networking search etc. While the approach has demonstrated its efficacy in tasks like semantic matching and contextual search, it is plagued by the problem of uncontrollable relevance. In this paper, we conduct an analysis of embedding-based retrieval launched in early 2021 on our social network search engine, and define two main categories of failures introduced by it, integrity and junkiness. The former refers to issues such as hate speech and offensive content that can severely harm user experience, while the latter includes irrelevant results like fuzzy text matching or language mismatches. Efficient methods during model inference are further proposed to resolve the issue, including indexing treatments and targeted user cohort treatments, etc. Though being simple, we show the methods have good offline NDCG and online A/B tests metrics gain in practice. We analyze the reasons for
    
[^43]: Pelphix：经皮盆骨固定术中基于X光图像的手术阶段识别

    Pelphix: Surgical Phase Recognition from X-ray Images in Percutaneous Pelvic Fixation. (arXiv:2304.09285v1 [cs.LG])

    [http://arxiv.org/abs/2304.09285](http://arxiv.org/abs/2304.09285)

    本文提出了一种名为Pelphix的X光引导下的经皮盆骨折修复手术阶段识别方法，使用马尔科夫过程模拟过程并提供完全注释的训练数据，在四个粒度级别上回归手术阶段，并取得了很好的准确率。

    

    手术阶段识别(SPR)是现代手术室数字化转型中至关重要的元素。虽然基于视频源的SPR已经很成熟，但插管X光序列的整合尚未被探索。本文提出了Pelphix，这是一种针对X光引导下的经皮盆骨折修复的SPR方法，该方法将该过程建模为四个粒度水平——走廊、活动、视图和帧值——将盆骨折修复工作流程模拟为马尔科夫过程，从而提供完全注释的训练数据。 使用从骨走廊、工具和解剖学检测中添加的监督学习，我们学习图像表示，并将其馈送到Transformer模型中，以在四个粒度级别上回归手术阶段。我们的方法展示了基于X光的SPR的可行性，在模拟序列中实现了93.8％的平均准确率，在尸体中实现了67.57％的所有粒度级别，并针对目标走廊的准确率高达88％。

    Surgical phase recognition (SPR) is a crucial element in the digital transformation of the modern operating theater. While SPR based on video sources is well-established, incorporation of interventional X-ray sequences has not yet been explored. This paper presents Pelphix, a first approach to SPR for X-ray-guided percutaneous pelvic fracture fixation, which models the procedure at four levels of granularity -- corridor, activity, view, and frame value -- simulating the pelvic fracture fixation workflow as a Markov process to provide fully annotated training data. Using added supervision from detection of bony corridors, tools, and anatomy, we learn image representations that are fed into a transformer model to regress surgical phases at the four granularity levels. Our approach demonstrates the feasibility of X-ray-based SPR, achieving an average accuracy of 93.8% on simulated sequences and 67.57% in cadaver across all granularity levels, with up to 88% accuracy for the target corrido
    
[^44]: 一种数据驱动的序列学习框架，用于加速和优化多目标制造决策

    A Data Driven Sequential Learning Framework to Accelerate and Optimize Multi-Objective Manufacturing Decisions. (arXiv:2304.09278v1 [cs.LG])

    [http://arxiv.org/abs/2304.09278](http://arxiv.org/abs/2304.09278)

    本文提出了一种利用序列学习来高效优化多个相互冲突目标的复杂系统的数据驱动贝叶斯优化框架。

    

    制造具有特定性质或性质组合的先进材料和产品通常是必要的。为了实现这一点，找到能够生成这些性质理想组合的最佳配方或处理条件至关重要。大多数时候，需要进行足够数量的实验才能生成Pareto前沿。然而，制造实验通常很昂贵，甚至进行一次实验也可能是一个耗时的过程。因此，确定最佳数据收集位置以获得对过程的最全面理解非常关键。序列学习是一种有前途的方法，可以从进行中的实验中主动学习，迭代更新基础优化例程，并随时调整数据收集过程。本文提出了一种新颖的基于数据驱动的贝叶斯优化框架，利用序列学习来高效优化具有多个相互冲突目标的复杂系统。

    Manufacturing advanced materials and products with a specific property or combination of properties is often warranted. To achieve that it is crucial to find out the optimum recipe or processing conditions that can generate the ideal combination of these properties. Most of the time, a sufficient number of experiments are needed to generate a Pareto front. However, manufacturing experiments are usually costly and even conducting a single experiment can be a time-consuming process. So, it's critical to determine the optimal location for data collection to gain the most comprehensive understanding of the process. Sequential learning is a promising approach to actively learn from the ongoing experiments, iteratively update the underlying optimization routine, and adapt the data collection process on the go. This paper presents a novel data-driven Bayesian optimization framework that utilizes sequential learning to efficiently optimize complex systems with multiple conflicting objectives. 
    
[^45]: 一种神经λ演算法：神经符号人工智能遇见计算和函数式编程的基础。

    A Neural Lambda Calculus: Neurosymbolic AI meets the foundations of computing and functional programming. (arXiv:2304.09276v1 [cs.LG])

    [http://arxiv.org/abs/2304.09276](http://arxiv.org/abs/2304.09276)

    本文提出了一种神经λ演算法，使用λ语言编程，研究神经网络在执行整个程序的能力，旨在拓展神经网络在符号人工智能领域的应用。

    

    在过去几十年中，基于深度神经网络的模型成为了机器学习中的主导范式。最近，人们越来越认为在符号学习中使用人工神经网络是越来越相关的。为了研究神经网络在符号人工智能领域的能力，研究人员已经探索了深度神经网络学习数学构造（如加法和乘法）、逻辑推理（如定理证明器）甚至执行计算机程序的能力。然而，后者对于神经网络来说是太复杂的任务，结果并不总是成功的，并且往往需要在学习过程中引入有偏见的元素，以限制可能要执行的程序的范围。在这项工作中，我们将分析神经网络学习如何执行整个程序的能力。为此，我们提出了一种不同的方法。我们不使用命令式编程语言，而是采用λ语言进行编程。

    Over the last decades, deep neural networks based-models became the dominant paradigm in machine learning. Further, the use of artificial neural networks in symbolic learning has been seen as increasingly relevant recently. To study the capabilities of neural networks in the symbolic AI domain, researchers have explored the ability of deep neural networks to learn mathematical constructions, such as addition and multiplication, logic inference, such as theorem provers, and even the execution of computer programs. The latter is known to be too complex a task for neural networks. Therefore, the results were not always successful, and often required the introduction of biased elements in the learning process, in addition to restricting the scope of possible programs to be executed. In this work, we will analyze the ability of neural networks to learn how to execute programs as a whole. To do so, we propose a different approach. Instead of using an imperative programming language, with com
    
[^46]: 《元宇宙：概述、趋势、新型生态系统和未来方向》

    The Metaverse: Survey, Trends, Novel Pipeline Ecosystem & Future Directions. (arXiv:2304.09240v1 [cs.CY])

    [http://arxiv.org/abs/2304.09240](http://arxiv.org/abs/2304.09240)

    本文介绍了元宇宙的概述、趋势和未来发展方向。通过适当的指导和方向，元宇宙的发展将会给技术、游戏、教育、艺术和文化领域带来更多的益处。本文提出了一个多层次的流程生态系统，旨在提供关于元宇宙的全面、跨学科、深入的研究。

    

    元宇宙通过虚拟现实 (VR) 技术提供了一个超现实的第二个世界，其中不存在任何边界，通过参与和沉浸式体验，提供了无限可能的发展。许多领域可以受益于元宇宙的发展，包括技术、游戏、教育、艺术和文化。然而，将元宇宙环境开发到其完整潜力是一项模糊的任务，需要适当的指导和方向。现有的关于元宇宙的调查仅关注元宇宙的特定方面和学科，并缺乏对整个过程的全面视角。为此，需要进行更全面、跨学科、深入和学术和行业导向的研究，以提供元宇宙开发流程的彻底研究。本文提出了一个新的多层次流程生态系统，包括元宇宙计算、网络、通信和...

    The Metaverse offers a second world beyond reality, where boundaries are non-existent, and possibilities are endless through engagement and immersive experiences using the virtual reality (VR) technology. Many disciplines can benefit from the advancement of the Metaverse when accurately developed, including the fields of technology, gaming, education, art, and culture. Nevertheless, developing the Metaverse environment to its full potential is an ambiguous task that needs proper guidance and directions. Existing surveys on the Metaverse focus only on a specific aspect and discipline of the Metaverse and lack a holistic view of the entire process. To this end, a more holistic, multi-disciplinary, in-depth, and academic and industry-oriented review is required to provide a thorough study of the Metaverse development pipeline. To address these issues, we present in this survey a novel multi-layered pipeline ecosystem composed of (1) the Metaverse computing, networking, communications and 
    
[^47]: 考虑时空依赖关系的交通数据填补的深度学习框架

    A Deep Learning Framework for Traffic Data Imputation Considering Spatiotemporal Dependencies. (arXiv:2304.09182v1 [cs.LG])

    [http://arxiv.org/abs/2304.09182](http://arxiv.org/abs/2304.09182)

    该论文提出了一种考虑时空依赖关系的交通数据填补深度学习框架，可用于解决缺失或不完整数据问题，以进一步应用该数据。

    

    传感器收集的时空（ST）数据可以表示为多变量时间序列，这是按时间顺序列出的数据点序列。尽管存在大量有用信息，但ST数据通常存在缺失或不完整数据的问题，这也限制了它的应用。数据填补是一个可行的解决方案，经常用于预处理数据以进行进一步的应用。然而，在实践中，由于交通网络中时空依赖关系变化的复杂性，时空数据填补非常困难，是进一步应用的关键前提任务。现有的方法大多只捕捉时间序列中的时间依赖性或静态空间依赖性。他们无法直接建模时空依赖关系，并且模型的表示能力相对有限。

    Spatiotemporal (ST) data collected by sensors can be represented as multi-variate time series, which is a sequence of data points listed in an order of time. Despite the vast amount of useful information, the ST data usually suffer from the issue of missing or incomplete data, which also limits its applications. Imputation is one viable solution and is often used to prepossess the data for further applications. However, in practice, n practice, spatiotemporal data imputation is quite difficult due to the complexity of spatiotemporal dependencies with dynamic changes in the traffic network and is a crucial prepossessing task for further applications. Existing approaches mostly only capture the temporal dependencies in time series or static spatial dependencies. They fail to directly model the spatiotemporal dependencies, and the representation ability of the models is relatively limited.
    
[^48]: 预训练语言模型作为人类辅助视觉计划者

    Pretrained Language Models as Visual Planners for Human Assistance. (arXiv:2304.09179v1 [cs.CV])

    [http://arxiv.org/abs/2304.09179](http://arxiv.org/abs/2304.09179)

    本研究提出了视觉辅助计划（VPA）的任务，利用预训练语言模型作为序列模型，在视频行动分割和预测方面优于现有的方法，来实现多模态AI助手指导用户完成复杂多步骤目标的进展。

    

    为了实现多模态AI助手指导用户完成复杂多步骤目标的进展，本研究提出了视觉辅助计划（VPA）的任务。给定自然语言简要描述的目标，例如“制作书架”，以及用户迄今为止的视频进展，VPA的目标是获得一个计划，即一系列行动，如“砂光书架”、“涂漆书架”等，以实现目标。这需要评估用户在未经修剪的视频中的进展，并与底层目标的要求相关联，即行动的相关性和其中的排序依赖关系。因此，这需要处理长时间的视频历史记录和任意复杂的行动依赖性。为了解决这些问题，我们将VPA分解为视频行动分割和预测。我们将预测步骤公式化为多模态序列建模问题，并提出了基于视觉语言模型的计划者（VLaMP），其中利用预训练的LMs作为序列模型。我们在两个数据集（Epic Kitchen和Charades-Ego）上展示了VLaMP的有效性。我们的实验结果表明，VLaMP在准确性、效率和泛化方面优于现有的方法。

    To make progress towards multi-modal AI assistants which can guide users to achieve complex multi-step goals, we propose the task of Visual Planning for Assistance (VPA). Given a goal briefly described in natural language, e.g., "make a shelf", and a video of the user's progress so far, the aim of VPA is to obtain a plan, i.e., a sequence of actions such as "sand shelf", "paint shelf", etc., to achieve the goal. This requires assessing the user's progress from the untrimmed video, and relating it to the requirements of underlying goal, i.e., relevance of actions and ordering dependencies amongst them. Consequently, this requires handling long video history, and arbitrarily complex action dependencies. To address these challenges, we decompose VPA into video action segmentation and forecasting. We formulate the forecasting step as a multi-modal sequence modeling problem and present Visual Language Model based Planner (VLaMP), which leverages pre-trained LMs as the sequence model. We dem
    
[^49]: 机器学习在阿尔茨海默病诊断中的应用：一篇综述

    Alzheimers Disease Diagnosis using Machine Learning: A Review. (arXiv:2304.09178v1 [cs.LG])

    [http://arxiv.org/abs/2304.09178](http://arxiv.org/abs/2304.09178)

    本综述分析了机器学习在阿尔茨海默病诊断中的应用，深度学习和强化学习是研究热点，可用于早期病变检测和诊断。

    

    阿尔茨海默病是一种严重的神经退行性疾病，会逐渐导致记忆力丧失。这种致命性脑病主要影响老年人，导致认知和生物学功能衰退并逐渐引起脑萎缩。为了准确诊断阿尔茨海默病，需要采用先进的机器学习方法。近年来，机器学习在医疗行业中受到了广泛关注和应用。通过机器学习方法可以判断一个人是否有早期阿尔茨海默病的可能性。本文综述了2008年至2023年间通过谷歌学术发现的基于深度学习技术和强化学习的阿尔茨海默病诊断论文。

    Alzheimers Disease AD is an acute neuro disease that degenerates the brain cells and thus leads to memory loss progressively. It is a fatal brain disease that mostly affects the elderly. It steers the decline of cognitive and biological functions of the brain and shrinks the brain successively, which in turn is known as Atrophy. For an accurate diagnosis of Alzheimers disease, cutting edge methods like machine learning are essential. Recently, machine learning has gained a lot of attention and popularity in the medical industry. As the illness progresses, those with Alzheimers have a far more difficult time doing even the most basic tasks, and in the worst case, their brain completely stops functioning. A persons likelihood of having early-stage Alzheimers disease may be determined using the ML method. In this analysis, papers on Alzheimers disease diagnosis based on deep learning techniques and reinforcement learning between 2008 and 2023 found in google scholar were studied. Sixty re
    
[^50]: 利用不可微分的群组 AUC 优化提升个性化排序

    Enhancing Personalized Ranking With Differentiable Group AUC Optimization. (arXiv:2304.09176v1 [cs.LG])

    [http://arxiv.org/abs/2304.09176](http://arxiv.org/abs/2304.09176)

    本文提出了一种个性化和可微分的AUC优化方法（PDAOM），可用于训练二元分类器并向其提供在独立用户组中紧密相关的正负样本对，以促进分类器关注不易区分的样本之间的关系，这些方法不仅提高了AUC和GAUC指标，还减少了训练目标的计算复杂度。

    

    AUC是评估分类器性能的常见指标。然而，大多数分类器是使用交叉熵训练的，它并不直接优化AUC指标，这在训练和评估阶段之间存在差距。本文提出了PDAOM损失，一种具有最大违规规定的个性化和可微分AUC优化方法，可直接应用于训练二元分类器并用梯度优化。具体地，我们构造了成对指数损失函数，将用户ID分组的子批次中的难分辨正负样本对拆分出来，旨在指导分类器从独立用户的角度关注相反样本之间的难以区分的关系。与成对指数损失函数的原始形式相比，所提出的PDAOM损失函数不仅在离线评估中提高了AUC和GAUC指标，而且减少了训练目标的计算复杂度。

    AUC is a common metric for evaluating the performance of a classifier. However, most classifiers are trained with cross entropy, and it does not optimize the AUC metric directly, which leaves a gap between the training and evaluation stage. In this paper, we propose the PDAOM loss, a Personalized and Differentiable AUC Optimization method with Maximum violation, which can be directly applied when training a binary classifier and optimized with gradient-based methods. Specifically, we construct the pairwise exponential loss with difficult pair of positive and negative samples within sub-batches grouped by user ID, aiming to guide the classifier to pay attention to the relation between hard-distinguished pairs of opposite samples from the perspective of independent users. Compared to the origin form of pairwise exponential loss, the proposed PDAOM loss not only improves the AUC and GAUC metrics in the offline evaluation, but also reduces the computation complexity of the training objecti
    
[^51]: Memento: 实现机器学习实验的轻松、高效和可靠的框架

    Memento: Facilitating Effortless, Efficient, and Reliable ML Experiments. (arXiv:2304.09175v1 [cs.LG])

    [http://arxiv.org/abs/2304.09175](http://arxiv.org/abs/2304.09175)

    Memento是一个Python包，旨在协助研究人员高效地管理和执行计算密集型机器学习实验。它提供了简单明了的配置矩阵和并发运行实验的能力。

    

    由于缺乏统一框架，运行复杂的机器学习实验集非常具挑战性和耗时。这迫使研究人员自己花费时间实现必要的功能，如并行化、缓存和检查点，而不是集中精力于他们的项目。为了简化这个过程，本文介绍了 Memento，一个旨在帮助研究人员和数据科学家高效管理和执行计算密集型实验的 Python 包。Memento 通过提供一个简单明了的配置矩阵和能够同时运行多个线程的实验来优化任何实验流程。Memento 的演示可在以下网站查看：https://wickerlab.org/publication/memento。

    Running complex sets of machine learning experiments is challenging and time-consuming due to the lack of a unified framework. This leaves researchers forced to spend time implementing necessary features such as parallelization, caching, and checkpointing themselves instead of focussing on their project. To simplify the process, in this paper, we introduce Memento, a Python package that is designed to aid researchers and data scientists in the efficient management and execution of computationally intensive experiments. Memento has the capacity to streamline any experimental pipeline by providing a straightforward configuration matrix and the ability to concurrently run experiments across multiple threads. A demonstration of Memento is available at: https://wickerlab.org/publication/memento.
    
[^52]: 多方会话中的发言人个人特征分析

    Speaker Profiling in Multiparty Conversations. (arXiv:2304.08801v1 [cs.CL])

    [http://arxiv.org/abs/2304.08801](http://arxiv.org/abs/2304.08801)

    本文提出了一个名为SPC的任务，旨在为对话中每个发言者生成个人特征摘要。任务被分为三个子任务：个人特征发现、个人特征类型识别和个人特征价值提取。任务对于银行、酒店预订和航空预订等行业中的聊天机器人非常重要，可以使聊天机器人更好地了解和回应每个发言人的需求。

    

    在对话环境中，个体展现出独特的行为，使得“一刀切”的方法不足以为对话代理生成回应。虽然过去的研究旨在使用发言人个人信息创建个性化对话代理，但它们依赖于前提，即发言人个人特征已经被提供。然而，在像银行、酒店预订和航空预订等行业中使用的聊天机器人方面，这一假设并不总是正确的。本文旨在通过探索对话中的发言人个人特征分析 (SPC)任务来填补这个空白。SPC的主要目标是为对话中每个发言人产生个人特征摘要。为了实现这一目标，我们将任务分为三个子任务：个人特征发现、个人特征类型识别和个人特征价值提取。在给定对话的情况下，第一个子任务旨在识别包含个人信息的所有话语。

    In conversational settings, individuals exhibit unique behaviors, rendering a one-size-fits-all approach insufficient for generating responses by dialogue agents. Although past studies have aimed to create personalized dialogue agents using speaker persona information, they have relied on the assumption that the speaker's persona is already provided. However, this assumption is not always valid, especially when it comes to chatbots utilized in industries like banking, hotel reservations, and airline bookings. This research paper aims to fill this gap by exploring the task of Speaker Profiling in Conversations (SPC). The primary objective of SPC is to produce a summary of persona characteristics for each individual speaker present in a dialogue. To accomplish this, we have divided the task into three subtasks: persona discovery, persona-type identification, and persona-value extraction. Given a dialogue, the first subtask aims to identify all utterances that contain persona information.
    
[^53]: 无监督三维动作表示学习：基于骨架云着色的自监督学习方法

    Self-Supervised 3D Action Representation Learning with Skeleton Cloud Colorization. (arXiv:2304.08799v1 [cs.CV])

    [http://arxiv.org/abs/2304.08799](http://arxiv.org/abs/2304.08799)

    本文提出了一种基于自监督学习和骨架云着色技术的无监督三维动作表示学习方法，可以在未标注数据上进行空间和时间表示学习，实验结果表明，在三个基准数据集上实现了最先进的无监督骨架动作识别性能。

    

    近年来，基于三维骨架的人体动作识别逐渐受到人们的关注。然而，现有的方法往往需要大量的标注数据，标注成本高且耗时。本文提出了一种基于自监督学习的方法进行三维动作表示学习，利用骨架云着色技术对未标注的骨架数据进行空间和时间表示学习。实验结果表明，该方法在三个基准数据集上实现了最先进的无监督骨架动作识别性能。

    3D Skeleton-based human action recognition has attracted increasing attention in recent years. Most of the existing work focuses on supervised learning which requires a large number of labeled action sequences that are often expensive and time-consuming to annotate. In this paper, we address self-supervised 3D action representation learning for skeleton-based action recognition. We investigate self-supervised representation learning and design a novel skeleton cloud colorization technique that is capable of learning spatial and temporal skeleton representations from unlabeled skeleton sequence data. We represent a skeleton action sequence as a 3D skeleton cloud and colorize each point in the cloud according to its temporal and spatial orders in the original (unannotated) skeleton sequence. Leveraging the colorized skeleton point cloud, we design an auto-encoder framework that can learn spatial-temporal features from the artificial color labels of skeleton joints effectively. Specifical
    
[^54]: 基于掩码语言模型的文本对抗样本检测

    Masked Language Model Based Textual Adversarial Example Detection. (arXiv:2304.08767v1 [cs.CR])

    [http://arxiv.org/abs/2304.08767](http://arxiv.org/abs/2304.08767)

    通过探索掩码语言模型引起的流形变化，我们提出了一种插即用的文本对抗例子检测方法，可以在保持对分类任务、模型结构和数据集无依赖的前提下，有效地检测到对抗例子。

    

    对抗攻击是机器学习模型在关键安全应用中可靠部署的严重威胁，稍微修改输入即可误导当前模型进行错误预测。最近，大量研究表明，对抗样本往往偏离正常样本的基础数据流形，而预训练的掩码语言模型可以适应正常的NLP数据流形。为了探索如何将掩码语言模型用于对抗性检测，我们提出了一种新颖的文本对抗例子检测方法，即基于掩码语言模型的检测（MLMD），它可以通过探索掩码语言模型引起的流形变化，在正常样本和对抗样本之间产生明显可区分的信号。MLMD具有即插即用的使用方法（即无需重新训练受害模型）用于对抗性防御，而且不受分类任务、受害模型结构和待防御的数据集的影响。

    Adversarial attacks are a serious threat to the reliable deployment of machine learning models in safety-critical applications. They can misguide current models to predict incorrectly by slightly modifying the inputs. Recently, substantial work has shown that adversarial examples tend to deviate from the underlying data manifold of normal examples, whereas pre-trained masked language models can fit the manifold of normal NLP data. To explore how to use the masked language model in adversarial detection, we propose a novel textual adversarial example detection method, namely Masked Language Model-based Detection (MLMD), which can produce clearly distinguishable signals between normal examples and adversarial examples by exploring the changes in manifolds induced by the masked language model. MLMD features a plug and play usage (i.e., no need to retrain the victim model) for adversarial defense and it is agnostic to classification tasks, victim model's architectures, and to-be-defended a
    
[^55]: Sabiá: 葡萄牙的大型语言模型

    Sabi\'a: Portuguese Large Language Models. (arXiv:2304.07880v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.07880](http://arxiv.org/abs/2304.07880)

    针对葡萄牙语进行单语言预训练，可以显著提高大规模合成语言模型的质量，并能够在一系列葡萄牙语数据集上优于以英语为中心和多语言的对手，最好的模型的表现与GPT-3.5-turbo持平。

    

    随着语言模型能力的不断提高，”一刀切“的模型仍然是主流。尤其是考虑到全球使用的语言数量非常庞大，并且其中很多语言都是低资源语言，主要的做法是对多种语言进行预训练。本文对这种做法提出了质疑，证明了针对目标语言进行单语言预训练可以显著提高大规模合成语言模型的质量。我们在本文中进一步介绍了用3%或更少的原始预训练预算在葡萄牙语文本上进一步预训练GPT-J和LLaMA模型。我们在Poeta（一套由14个葡萄牙语数据集组成的套件）上进行了少样本评估，结果显示我们的模型在表现上远优于以英语为中心的和多语言的对手。我们的最佳模型Sabiá-65B的表现与GPT-3.5-turbo持平。我们在目标语言中已经设想了数据集，以及经过翻译的数据集上都进行了评估。

    As the capabilities of language models continue to advance, it is conceivable that "one-size-fits-all" model will remain as the main paradigm. For instance, given the vast number of languages worldwide, many of which are low-resource, the prevalent practice is to pretrain a single model on multiple languages. In this paper, we add to the growing body of evidence that challenges this practice, demonstrating that monolingual pretraining on the target language significantly improves models already extensively trained on diverse corpora. More specifically, we further pretrain GPT-J and LLaMA models on Portuguese texts using 3% or less of their original pretraining budget. Few-shot evaluations on Poeta, a suite of 14 Portuguese datasets, reveal that our models outperform English-centric and multilingual counterparts by a significant margin. Our best model, Sabi\'a-65B, performs on par with GPT-3.5-turbo. By evaluating on datasets originally conceived in the target language as well as transl
    
[^56]: EEG SN：面向 EEG 的图形脉冲神经网络的高效低延迟解码

    EEGSN: Towards Efficient Low-latency Decoding of EEG with Graph Spiking Neural Networks. (arXiv:2304.07655v1 [cs.NE])

    [http://arxiv.org/abs/2304.07655](http://arxiv.org/abs/2304.07655)

    该论文提出了一种名为 EEGSN 的图形脉冲神经网络（SNN）架构，面向多通道 EEG 分类任务，在学习分布式 EEG 传感器中的动态关系信息的同时，将推断计算复杂度降低了20倍，为低延迟和功耗效率的脑计算机接口的开发提供了一个可行的框架。

    

    目前大多数脉冲神经网络（SNN）的训练依赖于归纳偏差，这并不一定适用于多个需要低延迟和功耗效率的关键任务。 基于相关的脑电图（EEG）信号推断大脑行为就是一个这样的例子，学习时空依赖关系会严重影响网络的训练和推断效率。目前，SNN仅仅依靠一般归纳偏差来模拟不同数据流之间的动态关系。在这里，我们提出了一种用于多通道 EEG 分类的图形脉冲神经网络架构（EEGSN），它能够学习分布在 EEG 传感器中的动态关系信息。与现有技术相比，我们的方法将推断计算复杂度降低了20倍，同时在运动执行分类任务上达到了可比较的准确性。总体而言，我们的工作为可解释和高效训练 EEG 数据的图形SNN提供了一个框架，从而实现了低延迟和功耗效率的脑-计算机界面的开发。

    A vast majority of spiking neural networks (SNNs) are trained based on inductive biases that are not necessarily a good fit for several critical tasks that require low-latency and power efficiency. Inferring brain behavior based on the associated electroenchephalography (EEG) signals is an example of how networks training and inference efficiency can be heavily impacted by learning spatio-temporal dependencies. Up to now, SNNs rely solely on general inductive biases to model the dynamic relations between different data streams. Here, we propose a graph spiking neural network architecture for multi-channel EEG classification (EEGSN) that learns the dynamic relational information present in the distributed EEG sensors. Our method reduced the inference computational complexity by $\times 20$ compared to the state-of-the-art SNNs, while achieved comparable accuracy on motor execution classification tasks. Overall, our work provides a framework for interpretable and efficient training of gr
    
[^57]: 深度图表示学习综述

    A Comprehensive Survey on Deep Graph Representation Learning. (arXiv:2304.05055v1 [cs.LG])

    [http://arxiv.org/abs/2304.05055](http://arxiv.org/abs/2304.05055)

    本文综述了深度图表示学习的研究现状和存在的问题，并指出利用深度学习已经显示出巨大的优势和潜力。

    

    图表示学习旨在将高维稀疏的图结构数据有效地编码成低维密集向量，这是一个基本任务，在包括机器学习和数据挖掘在内的一系列领域都得到了广泛的研究。传统图嵌入方法遵循这样一种基本思想，即图中相互连接的节点的嵌入矢量仍然能够保持相对接近的距离，从而保留了图中节点之间的结构信息。然而，这种方法存在以下问题：（i）传统方法的模型容量受限，限制了学习性能; （ii）现有技术通常依赖于无监督学习策略，无法与最新的学习范式相结合；（iii）表示学习和下游任务相互依存，应共同加强。随着深度学习的显着成功，深度图表示学习已经显示出巨大的潜力和优势。

    Graph representation learning aims to effectively encode high-dimensional sparse graph-structured data into low-dimensional dense vectors, which is a fundamental task that has been widely studied in a range of fields, including machine learning and data mining. Classic graph embedding methods follow the basic idea that the embedding vectors of interconnected nodes in the graph can still maintain a relatively close distance, thereby preserving the structural information between the nodes in the graph. However, this is sub-optimal due to: (i) traditional methods have limited model capacity which limits the learning performance; (ii) existing techniques typically rely on unsupervised learning strategies and fail to couple with the latest learning paradigms; (iii) representation learning and downstream tasks are dependent on each other which should be jointly enhanced. With the remarkable success of deep learning, deep graph representation learning has shown great potential and advantages 
    
[^58]: 可训练激活函数的稀疏神经网络贝叶斯优化

    Bayesian optimization for sparse neural networks with trainable activation functions. (arXiv:2304.04455v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2304.04455](http://arxiv.org/abs/2304.04455)

    本文提出了一种可训练的激活函数以提高神经网络性能，在此基础上开发了一个基于贝叶斯优化和MCMC采样的模型，能通过有效的采样和全局优化来解决过拟合并提高收敛速度。

    

    在深度神经网络的文献中，人们对开发能增强神经网络性能的激活函数非常感兴趣。最近，科学界提出了可以在学习过程中进行训练的激活函数，因为它们似乎可以提高网络性能，特别是通过减少过拟合。本文提出了一种可训练的激活函数，需要估计其参数。开发了一个完全贝叶斯模型，自动从学习数据中估计出模型权重和激活函数参数。开发了一个基于MCMC的优化方案来构建推理。提出的方法旨在通过使用有效的采样方案来保证收敛到全局最大值，从而解决上述问题并改善收敛时间。在三个不同CNN数据集上测试了所提出的方案。有希望的结果证明了它的有效性。

    In the literature on deep neural networks, there is considerable interest in developing activation functions that can enhance neural network performance. In recent years, there has been renewed scientific interest in proposing activation functions that can be trained throughout the learning process, as they appear to improve network performance, especially by reducing overfitting. In this paper, we propose a trainable activation function whose parameters need to be estimated. A fully Bayesian model is developed to automatically estimate from the learning data both the model weights and activation function parameters. An MCMC-based optimization scheme is developed to build the inference. The proposed method aims to solve the aforementioned problems and improve convergence time by using an efficient sampling scheme that guarantees convergence to the global maximum. The proposed scheme is tested on three datasets with three different CNNs. Promising results demonstrate the usefulness of o
    
[^59]: GPT检测器对非英语母语的作者存在偏见。

    GPT detectors are biased against non-native English writers. (arXiv:2304.02819v1 [cs.CL])

    [http://arxiv.org/abs/2304.02819](http://arxiv.org/abs/2304.02819)

    该研究发现，GPT检测器对非英语母语作者存在偏见，容易将其内容错误地分类为AI生成的内容。此外，简单的提示策略可以缓解这种偏见，同时规避GPT检测器，这表明GPT检测器可能会惩罚具有受限语言表达能力的作者。

    

    生成语言模型的快速推广带来了数字通信方面的实质性进展，同时也引发了AI生成内容潜在误用的担忧。虽然已经提出了许多检测方法来区分AI和人类生成的内容，但这些检测器的公平性和鲁棒性仍未得到充分探讨。在这项研究中，我们使用来自英语母语和非英语母语作者的写作样本评估了几种广泛使用的GPT检测器的性能表现。我们的研究发现，这些检测器持续将非英语母语的写作样本错误地分类为AI生成的内容，而原生写作样本则能够被准确识别。此外，我们证明了简单的提示策略不仅可以缓解这种偏见，而且还可以有效地规避GPT检测器，这表明GPT检测器可能无意中惩罚具有受限语言表达能力的作者。我们的研究结果呼吁进行更广泛的讨论。

    The rapid adoption of generative language models has brought about substantial advancements in digital communication, while simultaneously raising concerns regarding the potential misuse of AI-generated content. Although numerous detection methods have been proposed to differentiate between AI and human-generated content, the fairness and robustness of these detectors remain underexplored. In this study, we evaluate the performance of several widely-used GPT detectors using writing samples from native and non-native English writers. Our findings reveal that these detectors consistently misclassify non-native English writing samples as AI-generated, whereas native writing samples are accurately identified. Furthermore, we demonstrate that simple prompting strategies can not only mitigate this bias but also effectively bypass GPT detectors, suggesting that GPT detectors may unintentionally penalize writers with constrained linguistic expressions. Our results call for a broader conversati
    
[^60]: 基于分层Transformer的关系路径和上下文归纳关系预测方法

    Inductive Relation Prediction from Relational Paths and Context with Hierarchical Transformers. (arXiv:2304.00215v1 [cs.CL])

    [http://arxiv.org/abs/2304.00215](http://arxiv.org/abs/2304.00215)

    本文提出了一种基于分层Transformer的方法，即REPORT，能够同时聚合关系路径和上下文，捕捉实体之间的联系和内在特性。它完全依赖于关系语义，并能自然地推广到完全归纳的设置中。在基准数据集上实现了最先进的性能。

    

    在知识图谱中进行关系预测是一个重要的研究课题。现有的嵌入式方法主要依赖于转导设置，缺乏归纳能力，无法推广到新的实体上进行推理。本文提出了一种新方法，通过使用统一的分层Transformer框架，即REPORT，同时聚合关系路径和上下文，捕捉实体之间的联系和内在特性，这种方法完全依赖于关系语义，并能自然地推广到完全归纳的设置中。在实验中，REPORT表现优于所有基线方法，甚至在两个完全归纳的数据集的八个版本子集上也是如此。此外，REPORT能够将推理推广到训练和推理中没有公共实体的新实体上，并在基准数据集上实现了最先进的性能。

    Relation prediction on knowledge graphs (KGs) is a key research topic. Dominant embedding-based methods mainly focus on the transductive setting and lack the inductive ability to generalize to new entities for inference. Existing methods for inductive reasoning mostly mine the connections between entities, i.e., relational paths, without considering the nature of head and tail entities contained in the relational context. This paper proposes a novel method that captures both connections between entities and the intrinsic nature of entities, by simultaneously aggregating RElational Paths and cOntext with a unified hieRarchical Transformer framework, namely REPORT. REPORT relies solely on relation semantics and can naturally generalize to the fully-inductive setting, where KGs for training and inference have no common entities. In the experiments, REPORT performs consistently better than all baselines on almost all the eight version subsets of two fully-inductive datasets. Moreover. REPO
    
[^61]: 从私有到公有：在私有时间序列分类情境下对GAN进行基准测试

    From Private to Public: Benchmarking GANs in the Context of Private Time Series Classification. (arXiv:2303.15916v1 [cs.LG])

    [http://arxiv.org/abs/2303.15916](http://arxiv.org/abs/2303.15916)

    本论文在时间序列领域对两种GAN架构进行了评估，结果以GSWGAN表现最佳，可以私密地生成保护数据隐私的公共数据。

    

    深度学习已被证明在各个领域和任务中都很成功。然而，当涉及到私人数据时，几个限制使得难以在这些应用领域中使用深度学习方法。最近的方法尝试私密地生成数据，而不是在分类器之上直接应用隐私保护机制。解决方案是以一种保护数据隐私的方式从私有数据创建公共数据。在这项工作中，针对私有时间序列分类情境，评估了两种非常突出的基于GAN的架构。与先前主要局限于图像领域的工作相比，这个基准测试的范围是时间序列领域。实验表明，尤其是GSWGAN在多种公共数据集上表现良好，优于竞争对手DPWGAN。生成数据集的分析进一步验证了GSWGAN在时间序列生成的情境下的优越性。

    Deep learning has proven to be successful in various domains and for different tasks. However, when it comes to private data several restrictions are making it difficult to use deep learning approaches in these application fields. Recent approaches try to generate data privately instead of applying a privacy-preserving mechanism directly, on top of the classifier. The solution is to create public data from private data in a manner that preserves the privacy of the data. In this work, two very prominent GAN-based architectures were evaluated in the context of private time series classification. In contrast to previous work, mostly limited to the image domain, the scope of this benchmark was the time series domain. The experiments show that especially GSWGAN performs well across a variety of public datasets outperforming the competitor DPWGAN. An analysis of the generated datasets further validates the superiority of GSWGAN in the context of time series generation.
    
[^62]: 未知嗅探器用于目标检测：不要对未知对象视而不见

    Unknown Sniffer for Object Detection: Don't Turn a Blind Eye to Unknown Objects. (arXiv:2303.13769v1 [cs.CV])

    [http://arxiv.org/abs/2303.13769](http://arxiv.org/abs/2303.13769)

    本文提出了未知嗅探器(UnSniffer)，用于同时寻找未知和已知的目标。通过引入广义物体置信度(GOC)分数和负能量抑制损失来提高未知对象在背景中的检测准确率，并解决了在推断过程中难以获得每个未知目标最佳框的问题。

    

    近期提出的开放世界目标和开放集检测在寻找从未见过的物体并将其与已知类别区分开方面取得了突破。然而，他们对从已知类别向未知类别的知识传递的研究需要更深入，从而导致探测隐藏在背景中的未知物体的能力不足。本文中，我们提出了未知嗅探器(UnSniffer)来寻找未知和已知的目标。首先，引入广义物体置信度(GOC)分数，仅使用已知类别样本进行监督和避免在背景中不适当地压制未知物体。值得注意的是，从已知物体学习到的这种置信度分数可以推广到未知物体。此外，我们提出了负能量抑制损失来进一步限制背景中非物体样本。接下来，在推断过程中由于缺乏它们在训练中的语义信息，难以获得每个未知目标的最佳框。为了解决这个问题，

    The recently proposed open-world object and open-set detection achieve a breakthrough in finding never-seen-before objects and distinguishing them from class-known ones. However, their studies on knowledge transfer from known classes to unknown ones need to be deeper, leading to the scanty capability for detecting unknowns hidden in the background. In this paper, we propose the unknown sniffer (UnSniffer) to find both unknown and known objects. Firstly, the generalized object confidence (GOC) score is introduced, which only uses class-known samples for supervision and avoids improper suppression of unknowns in the background. Significantly, such confidence score learned from class-known objects can be generalized to unknown ones. Additionally, we propose a negative energy suppression loss to further limit the non-object samples in the background. Next, the best box of each unknown is hard to obtain during inference due to lacking their semantic information in training. To solve this is
    
[^63]: TempT：测试时间自适应的时间一致性方法

    TempT: Temporal consistency for Test-time adaptation. (arXiv:2303.10536v1 [cs.CV])

    [http://arxiv.org/abs/2303.10536](http://arxiv.org/abs/2303.10536)

    本文提出一种新颖的方法TempT，通过确保连续帧之间的预测具有时间上的一致性，实现了对视频的测试时自适应。其仅利用视觉单模态特征，并在面部表情识别等计算机视觉任务中具有广泛应用，并在实验中取得了有竞争力的表现，为其在各种实际应用中提供了令人信服的概念证明。

    

    本技术报告介绍了TempT，一种新颖的方法，通过确保连续帧之间的预测具有时间上的一致性，实现对视频的测试时自适应。TempT是一种强大的工具，在计算机视觉任务中具有广泛应用，包括视频中的面部表情识别（FER）。我们将TempT在AffWild2数据集上作为情感行为分析比赛（ABAW）第五届研讨会和竞赛中的表情分类挑战的一部分进行了评估。我们的方法仅专注于数据的视觉单模态特征，并利用了流行的二维卷积神经网络骨干，而不是较大的序列或基于注意力的模型。我们的实验结果表明，TempT与往年报告的表现相比具有竞争力，其有效性为其在各种实际应用中的使用提供了令人信服的概念证明。

    In this technical report, we introduce TempT, a novel method for test time adaptation on videos by ensuring temporal coherence of predictions across sequential frames. TempT is a powerful tool with broad applications in computer vision tasks, including facial expression recognition (FER) in videos. We evaluate TempT's performance on the AffWild2 dataset as part of the Expression Classification Challenge at the 5th Workshop and Competition on Affective Behavior Analysis in the wild (ABAW). Our approach focuses solely on the unimodal visual aspect of the data and utilizes a popular 2D CNN backbone, in contrast to larger sequential or attention based models. Our experimental results demonstrate that TempT has competitive performance in comparison to previous years reported performances, and its efficacy provides a compelling proof of concept for its use in various real world applications.
    
[^64]: 基于稳定扩散的高度个性化文本嵌入图像操作

    Highly Personalized Text Embedding for Image Manipulation by Stable Diffusion. (arXiv:2303.08767v1 [cs.CV])

    [http://arxiv.org/abs/2303.08767](http://arxiv.org/abs/2303.08767)

    本论文提出了一种简单但高效的个性化方法——使用高度个性化文本嵌入来进行图像操作，可以运用于图像的背景、纹理和动作的编辑，不需要多个参考图像或复杂训练，能实现复杂语义图像编辑。

    

    稳定扩散模型已经展现出在图像生成和操作方面的卓越性能，但内部随机性带来的挑战在于如何保留和操作图像内容和身份。虽然之前的方法如“梦境相机”和“文本反转”提出了使用模型或潜在表示个性化来保持内容，但它们对多个参考图像和复杂训练的依赖限制了它们的实用性。本文提出了一种简单而又非常有效的个性化方法，使用高度个性化（HiPer）文本嵌入通过分解CLIP嵌入空间实现个性化和内容操作。我们的方法不需要模型微调或识别符，但仍可以仅通过单个图像和目标文本来实现背景、纹理和动作的操作。通过对多样化的目标文本的实验，我们证明了我们的方法在各种任务中都能产生高度个性化和复杂的语义图像编辑。

    Diffusion models have shown superior performance in image generation and manipulation, but the inherent stochasticity presents challenges in preserving and manipulating image content and identity. While previous approaches like DreamBooth and Textual Inversion have proposed model or latent representation personalization to maintain the content, their reliance on multiple reference images and complex training limits their practicality. In this paper, we present a simple yet highly effective approach to personalization using highly personalized (HiPer) text embedding by decomposing the CLIP embedding space for personalization and content manipulation. Our method does not require model fine-tuning or identifiers, yet still enables manipulation of background, texture, and motion with just a single image and target text. Through experiments on diverse target texts, we demonstrate that our approach produces highly personalized and complex semantic image edits across a wide range of tasks. We
    
[^65]: TSMixer：一种全MLP架构用于时间序列预测

    TSMixer: An all-MLP Architecture for Time Series Forecasting. (arXiv:2303.06053v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.06053](http://arxiv.org/abs/2303.06053)

    TSMixer是一种通过堆叠多层感知器（MLP）设计的新型结构，基于沿时间和特征维度的混合操作，能够在时间序列预测中表现出极好的性能。

    

    实际时间序列数据集通常是多变量且具有复杂的动态。为了捕获这种复杂性，像循环或基于注意力的顺序深度学习模型这样的高容量结构变得受欢迎。然而，最近的研究表明，简单的单变量线性模型可以在几个常用的学术基准测试中胜过这样的深度学习模型。扩展它们，本文研究线性模型在时间序列预测中的能力，并提出了时序混合器（TSMixer），这是一种通过堆叠多层感知器（MLP）设计的新型结构。 TSMixer基于沿时间和特征维度的混合操作，以有效地提取信息。在流行的学术基准测试上，简单易行的TSMixer与利用特定基准的归纳偏差的专业先进模型相媲美。在具有挑战性和大规模的M5基准测试中，即一个实际的零售数据集上，TSMixer表现出非常出色的性能。

    Real-world time-series datasets are often multivariate with complex dynamics. To capture this complexity, high capacity architectures like recurrent- or attention-based sequential deep learning models have become popular. However, recent work demonstrates that simple univariate linear models can outperform such deep learning models on several commonly used academic benchmarks. Extending them, in this paper, we investigate the capabilities of linear models for time-series forecasting and present Time-Series Mixer (TSMixer), a novel architecture designed by stacking multi-layer perceptrons (MLPs). TSMixer is based on mixing operations along both the time and feature dimensions to extract information efficiently. On popular academic benchmarks, the simple-to-implement TSMixer is comparable to specialized state-of-the-art models that leverage the inductive biases of specific benchmarks. On the challenging and large scale M5 benchmark, a real-world retail dataset, TSMixer demonstrates super
    
[^66]: 集成强化学习综述

    Ensemble Reinforcement Learning: A Survey. (arXiv:2303.02618v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.02618](http://arxiv.org/abs/2303.02618)

    集成强化学习（ERL）是一种将强化学习（RL）与集成学习（EL）相结合的有前途的方法，旨在利用多个模型或培训算法全面探索问题空间，并具有强大的泛化能力。

    

    强化学习（RL）已成为解决各种科学和应用问题的高效技术。尽管其取得了成功，但某些复杂任务仍难以仅使用单个模型和算法解决。作为响应，集成强化学习（ERL）作为一种有前途的方法，结合了RL和集成学习（EL）的优点，已经广泛受到欢迎。ERL利用多个模型或培训算法全面探索问题空间，并具有强大的泛化能力。本研究旨在提供ERL的综合调查，以便为读者提供该领域的最新进展和挑战概述。首先，我们介绍ERL的背景和动机。其次，我们详细分析了成功应用于ERL中的策略，包括模型平均、模型选择和模型组合。随后，我们总结了相关数据集并分析了所使用的算法。

    Reinforcement Learning (RL) has emerged as a highly effective technique for addressing various scientific and applied problems. Despite its success, certain complex tasks remain challenging to be addressed solely with a single model and algorithm. In response, ensemble reinforcement learning (ERL), a promising approach that combines the benefits of both RL and ensemble learning (EL), has gained widespread popularity. ERL leverages multiple models or training algorithms to comprehensively explore the problem space and possesses strong generalization capabilities. In this study, we present a comprehensive survey on ERL to provide readers with an overview of recent advances and challenges in the field. First, we introduce the background and motivation for ERL. Second, we analyze in detail the strategies that have been successfully applied in ERL, including model averaging, model selection, and model combination. Subsequently, we summarize the datasets and analyze algorithms used in releva
    
[^67]: 离线强化学习中的In-Sample Softmax

    The In-Sample Softmax for Offline Reinforcement Learning. (arXiv:2302.14372v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.14372](http://arxiv.org/abs/2302.14372)

    本文研究离线强化学习中的In-Sample Softmax，通过使用只由数据集中的操作组成的In-Sample softmax来解决操作覆盖不足问题，并且In-Sample Actor-Critic与该方法相比在稳定性或性能上表现更好。

    

    强化学习RL代理可以利用以前收集的数据的批次来提取合理的控制策略。然而，在这种离线RL设置中，一个不断出现的问题是，许多方法下的bootstrapping更新受到行动覆盖不足的影响：标准max运算符可能会选择在数据集中没有出现过的最大动作。从这些不准确的值进行bootstrapping更新会导致高估甚至发散。有越来越多的方法尝试近似一个仅使用数据集中涵盖良好的操作的in-sample max。本文强调一个简单的事实：使用仅由数据集中的动作近似In-Sample softmax更加直观。我们展示了在In-Sample softmax基础上的策略迭代的收敛性，并且对于温度的下降，它会接近In-Sample max。我们使用这种In-Sample softmax推导出一个In-Sample Actor-Critic（AC），并且证明其在稳定性或性能上更好。

    Reinforcement learning (RL) agents can leverage batches of previously collected data to extract a reasonable control policy. An emerging issue in this offline RL setting, however, is that the bootstrapping update underlying many of our methods suffers from insufficient action-coverage: standard max operator may select a maximal action that has not been seen in the dataset. Bootstrapping from these inaccurate values can lead to overestimation and even divergence. There are a growing number of methods that attempt to approximate an \emph{in-sample} max, that only uses actions well-covered by the dataset. We highlight a simple fact: it is more straightforward to approximate an in-sample \emph{softmax} using only actions in the dataset. We show that policy iteration based on the in-sample softmax converges, and that for decreasing temperatures it approaches the in-sample max. We derive an In-Sample Actor-Critic (AC), using this in-sample softmax, and show that it is consistently better or 
    
[^68]: 通过训练动态理解基于坐标的MLPs的谱偏置

    Understanding the Spectral Bias of Coordinate Based MLPs Via Training Dynamics. (arXiv:2301.05816v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.05816](http://arxiv.org/abs/2301.05816)

    该论文研究了基于坐标的MLPs的谱偏置对高频组件收敛的阻碍，并提出使用高频正弦波编码输入来克服这一限制。

    

    谱偏置是神经网络训练的重要观察结果，它表示网络在收敛到更高频率组件前，会学习目标函数的低频表示。这一属性与超参数网络的良好泛化能力有关，但在应用于场景渲染时，采用具有ReLU激活的多层感知器(MLPs)利用密集的低维坐标输入会导致严重的谱偏差，完全阻碍了收敛到高频组件。为了克服这个限制，可以使用高频正弦波编码输入。以前的研究试图使用神经切向核(NTK)和傅里叶分析来解释坐标系中的谱偏差及其严重性。然而，这种方法存在各种限制，因为NTK不能捕捉到真正的网络动态，而傅里叶分析只能提供对频率组件的全局视角。

    Spectral bias is an important observation of neural network training, stating that the network will learn a low frequency representation of the target function before converging to higher frequency components. This property is interesting due to its link to good generalization in over-parameterized networks. However, in applications to scene rendering, where multi-layer perceptrons (MLPs) with ReLU activations utilize dense, low dimensional coordinate based inputs, a severe spectral bias occurs that obstructs convergence to high freqeuncy components entirely. In order to overcome this limitation, one can encode the inputs using high frequency sinusoids. Previous works attempted to explain both spectral bias and its severity in the coordinate based regime using Neural Tangent Kernel (NTK) and Fourier analysis. However, such methods come with various limitations, since NTK does not capture real network dynamics, and Fourier analysis only offers a global perspective on the frequency compo
    
[^69]: 多层射击和沉默禁制残差网络：实现更好和更深的直接训练尖峰神经网络

    Multi-Level Firing with Spiking DS-ResNet: Enabling Better and Deeper Directly-Trained Spiking Neural Networks. (arXiv:2210.06386v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2210.06386](http://arxiv.org/abs/2210.06386)

    本文提出了一种多层射击（MLF）方法和尖峰沉默禁制残差网络（spiking DS-ResNet），通过 MLF 方法，可以更高效地传播梯度，增加神经元的增量表达能力；DS-ResNet 可以有效地执行离散尖峰的恒等映射，提高网络的表达能力。

    

    尖峰神经网络（SNN）具有异步离散和稀疏特性，是一种生物启发的神经网络，它们在低能耗方面越来越表现出优越性。最近的研究致力于利用时空信息通过反向传播直接训练SNN。然而，尖峰活动的二进制和不可微的特性迫使直接训练的SNN遭受严重的梯度消失和网络退化，这极大地限制了直接训练的SNN的性能并阻止它们变得更深。本文提出了一种基于现有时空反向传播（STBP）方法的多层射击（MLF）方法和尖峰沉默禁制残差网络（spiking DS-ResNet）。MLF使梯度传播更加高效，并增量表达神经元的能力。尖峰DS-ResNet可以有效地执行离散尖峰的恒等映射，同时提供更合适的连接方式。

    Spiking neural networks (SNNs) are bio-inspired neural networks with asynchronous discrete and sparse characteristics, which have increasingly manifested their superiority in low energy consumption. Recent research is devoted to utilizing spatio-temporal information to directly train SNNs by backpropagation. However, the binary and non-differentiable properties of spike activities force directly trained SNNs to suffer from serious gradient vanishing and network degradation, which greatly limits the performance of directly trained SNNs and prevents them from going deeper. In this paper, we propose a multi-level firing (MLF) method based on the existing spatio-temporal back propagation (STBP) method, and spiking dormant-suppressed residual network (spiking DS-ResNet). MLF enables more efficient gradient propagation and the incremental expression ability of the neurons. Spiking DS-ResNet can efficiently perform identity mapping of discrete spikes, as well as provide a more suitable connec
    
[^70]: 嵌入式注意力深度学习用于实际蓝牙射频指纹的提取

    Embedding-Assisted Attentional Deep Learning for Real-World RF Fingerprinting of Bluetooth. (arXiv:2210.02897v2 [cs.NI] UPDATED)

    [http://arxiv.org/abs/2210.02897](http://arxiv.org/abs/2210.02897)

    本研究提出了一种嵌入式注意力深度学习框架，用于提取实际蓝牙设备的指纹。该模型具有较高的分类准确率，并在内存使用方面有所改进。

    

    本研究设计了一个可扩展且计算效率高的框架，用于提取实际蓝牙设备的指纹。我们提出了一种嵌入式注意力框架（Mbed-ATN），适用于获取实际蓝牙设备的指纹。我们分析了其在不同环境中的泛化能力，并演示了样本长度和抗混叠抽取的效果。嵌入式模块作为降维单元，将高维的三维输入张量映射为一维特征向量，供ATN模块进一步处理。此外，我们对该模型的复杂性进行了密切评估，并在训练后使用另一个在不同时段和实验设置下收集的真实蓝牙数据集测试了其指纹能力，这是该领域先前研究所没有做过的。研究表明，在样本长度为100 kS时，与基准——GRU和Oracle模型相比，我们的模型内存使用量分别降低了9.17倍和65.2倍。此外，所提出的Mbed-ATN在室内和室外环境中均实现了较高的分类准确率，分别为99.4％和97.4％。

    A scalable and computationally efficient framework is designed to fingerprint real-world Bluetooth devices. We propose an embedding-assisted attentional framework (Mbed-ATN) suitable for fingerprinting actual Bluetooth devices. Its generalization capability is analyzed in different settings and the effect of sample length and anti-aliasing decimation is demonstrated. The embedding module serves as a dimensionality reduction unit that maps the high dimensional 3D input tensor to a 1D feature vector for further processing by the ATN module. Furthermore, unlike the prior research in this field, we closely evaluate the complexity of the model and test its fingerprinting capability with real-world Bluetooth dataset collected under a different time frame and experimental setting while being trained on another. Our study reveals a 9.17x and 65.2x lesser memory usage at a sample length of 100 kS when compared to the benchmark - GRU and Oracle models respectively. Further, the proposed Mbed-ATN
    
[^71]: 限制网络表示，让模型知道自己的不足

    Constraining Representations Yields Models That Know What They Don't Know. (arXiv:2208.14488v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.14488](http://arxiv.org/abs/2208.14488)

    通过对模型内部激活模式施加类感知约束的方法，本文提出总激活分类器（TAC）可以让模型更加安全、可靠，并具有广泛的应用前景。

    

    神经网络的一个已知失败模式是它们可能自信地返回错误的预测。这种不安全的行为在使用案例略有不同的情况下特别频繁，或者在面对敌手时。本文介绍了一种新的方法来以一种广泛且一般的方式解决这些问题：对模型内部的激活模式施加类感知约束。具体而言，我们为每个类分配一个独特的、固定的、随机生成的二进制向量（后文称为类编码），并训练模型，使其通过交叉深度的激活模式根据输入样本的类别预测相应的类编码。结果预测器被称为总激活分类器（TAC），TAC可以从头开始训练，也可以在冻结的预训练神经网络顶部用极小的代价作为薄层附加使用。TAC的激活模式与最接近的有效编码之间的距离作为额外的置信度评分。

    A well-known failure mode of neural networks is that they may confidently return erroneous predictions. Such unsafe behaviour is particularly frequent when the use case slightly differs from the training context, and/or in the presence of an adversary. This work presents a novel direction to address these issues in a broad, general manner: imposing class-aware constraints on a model's internal activation patterns. Specifically, we assign to each class a unique, fixed, randomly-generated binary vector - hereafter called class code and train the model so that its cross-depths activation patterns predict the appropriate class code according to the input sample's class. The resulting predictors are dubbed Total Activation Classifiers (TAC), and TACs may either be trained from scratch, or used with negligible cost as a thin add-on on top of a frozen, pre-trained neural network. The distance between a TAC's activation pattern and the closest valid code acts as an additional confidence scor
    
[^72]: EC-KitY：无缝机器学习集成的Python进化计算工具包

    EC-KitY: Evolutionary Computation Tool Kit in Python with Seamless Machine Learning Integration. (arXiv:2207.10367v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2207.10367](http://arxiv.org/abs/2207.10367)

    EC-KitY是一款基于Python的全面进化计算工具包，采用BSD 3-Clause许可证，兼容scikit-learn，支持多种流行的EC范例，能够无缝集成机器学习，并提供简便的EC实验设置和具有竞争力的模型性能。

    

    EC-KitY是一个全面的Python库，用于进行进化计算(EC)，采用BSD 3-Clause许可证，并兼容scikit-learn。设计时考虑了现代软件工程和机器学习集成，EC-KitY可以支持所有流行的EC范例，包括遗传算法，遗传编程，协同进化，进化多目标优化等。本文概述了该软件包的概况，包括设置EC实验的简便性、架构、主要特点以及与其他库的比较。

    EC-KitY is a comprehensive Python library for doing evolutionary computation (EC), licensed under the BSD 3-Clause License, and compatible with scikit-learn. Designed with modern software engineering and machine learning integration in mind, EC-KitY can support all popular EC paradigms, including genetic algorithms, genetic programming, coevolution, evolutionary multi-objective optimization, and more. This paper provides an overview of the package, including the ease of setting up an EC experiment, the architecture, the main features, and a comparison with other libraries.
    
[^73]: 面向文本逻辑推理的话语感知图网络

    Discourse-Aware Graph Networks for Textual Logical Reasoning. (arXiv:2207.01450v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2207.01450](http://arxiv.org/abs/2207.01450)

    本论文提出了逻辑结构约束建模和话语感知图网络（DAGNs）用于解决文本逻辑推理问答问题。DAGNs可以构建逻辑图并通过边缘推理机制和图特征更新来学习逻辑表示。该方法在实验中取得了良好的效果。

    

    文本逻辑推理，尤其是涉及到逻辑推理的问答任务，需要意识到特定的逻辑结构。段落级逻辑关系代表了命题单元之间的蕴涵或矛盾关系（例如，结论句），然而，由于当前的问答系统侧重于基于实体的关系，这种结构尚未被探索。本文提出了逻辑结构约束建模来解决逻辑推理问答问题，并引入了话语感知图网络（DAGNs）。该网络首先利用行间话语连接词和通用逻辑理论构建逻辑图，然后通过端到端的边缘推理机制和图特征更新来学习逻辑表示。这个流程应用于一个通用的编码器，其基本特征与高层逻辑特征相结合，用于答案预测。在三个文本逻辑推理数据集上的实验证明了该方法的合理性。

    Textual logical reasoning, especially question-answering (QA) tasks with logical reasoning, requires awareness of particular logical structures. The passage-level logical relations represent entailment or contradiction between propositional units (e.g., a concluding sentence). However, such structures are unexplored as current QA systems focus on entity-based relations. In this work, we propose logic structural-constraint modeling to solve the logical reasoning QA and introduce discourse-aware graph networks (DAGNs). The networks first construct logic graphs leveraging in-line discourse connectives and generic logic theories, then learn logic representations by end-to-end evolving the logic relations with an edge-reasoning mechanism and updating the graph features. This pipeline is applied to a general encoder, whose fundamental features are joined with the high-level logic features for answer prediction. Experiments on three textual logical reasoning datasets demonstrate the reasonabi
    
[^74]: BATFormer: 用于高效医学图像分割的边界感知轻量级Transformer

    BATFormer: Towards Boundary-Aware Lightweight Transformer for Efficient Medical Image Segmentation. (arXiv:2206.14409v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.14409](http://arxiv.org/abs/2206.14409)

    本文提出了一种名为BATFormer的方法，以较低的计算复杂度实现跨尺度全局交互，即建立长距离依赖。同时，指导下灵活地生成窗口，增强了在医学图像分割中的形状建模。

    

    摘要：Transformer近来因其弥补了CNN不足的感受野而备受关注。但全局表示学习的高计算复杂度，以及刚性的窗口分割，阻碍了它们在医学图像分割中的应用。本文旨在解决Transformer在医学图像分割中的这两个问题。我们提出了一种名为边界感知轻量级Transformer（BATFormer）的方法，它可以以较低的计算复杂度建立跨尺度全局交互，并在熵的指导下灵活地生成窗口。具体而言，为了充分发挥Transformer在建立长距离依赖方面的优势，我们引入了一个跨尺度全局Transformer（CGT）模块，以联合利用多个小尺度特征图，生成更丰富的全局特征，同时计算复杂度更低。鉴于形状建模在医学图像分割中的重要性，我们还引入了一种边界感知本地Transformer。

    Objective: Transformers, born to remedy the inadequate receptive fields of CNNs, have drawn explosive attention recently. However, the daunting computational complexity of global representation learning, together with rigid window partitioning, hinders their deployment in medical image segmentation. This work aims to address the above two issues in transformers for better medical image segmentation. Methods: We propose a boundary-aware lightweight transformer (BATFormer) that can build cross-scale global interaction with lower computational complexity and generate windows flexibly under the guidance of entropy. Specifically, to fully explore the benefits of transformers in long-range dependency establishment, a cross-scale global transformer (CGT) module is introduced to jointly utilize multiple small-scale feature maps for richer global features with lower computational complexity. Given the importance of shape modeling in medical image segmentation, a boundary-aware local transformer
    
[^75]: 面向部分可观察马尔可夫博弈的多目标自主组织追捕

    Toward multi-target self-organizing pursuit in a partially observable Markov game. (arXiv:2206.12330v3 [cs.MA] UPDATED)

    [http://arxiv.org/abs/2206.12330](http://arxiv.org/abs/2206.12330)

    本文提出了一个基于部分可观察马尔可夫博弈（POMG）的多智能体自主组织追捕（SOP）框架，并使用模糊自组织协作共同演化（FSC2）分布式算法来解决SOP中的三大挑战：分布式自组织搜索（SOS）、分布式任务分配和分布式单目标追踪。实验结果表明，所提出的FSC2算法有效提高了多目标SOP任务的准确性和效率。

    

    多目标自主组织追捕（SOP）问题具有广泛应用，并被认为是分布式系统的具有挑战性的自组织游戏，在该游戏中，智能代理协作地追踪多个动态目标，其中又存在部分可观察。本文提出了一个分散多智能体系统的框架，以改善搜索和追逐中的隐式协调能力。我们将自组织系统建模为一个部分可观察马尔可夫博弈（POMG），该模型具有大规模性、去中心化、部分可观察和非通信等特点。随后，利用模糊自组织协作共同演化（FSC2）分布式算法来解决多目标SOP中的三大挑战：分布式自组织搜索（SOS）、分布式任务分配和分布式单目标追踪。FSC2包括一种协调的多智能体深度强化学习（MARL）方法，使同质智能体学习自然的SOS模式。此外，提出了一种基于模糊推理的分散式任务分配机制，以将搜索任务分配给代理。最后，提出了一种分布式单目标追踪策略，该策略结合了SOS和任务分配的结果，使得追踪目标更加有效率。实验结果表明，所提出的FSC2算法有效提高了多目标SOP任务的准确性和效率。

    The multiple-target self-organizing pursuit (SOP) problem has wide applications and has been considered a challenging self-organization game for distributed systems, in which intelligent agents cooperatively pursue multiple dynamic targets with partial observations. This work proposes a framework for decentralized multi-agent systems to improve the implicit coordination capabilities in search and pursuit. We model a self-organizing system as a partially observable Markov game (POMG) featured by large-scale, decentralization, partial observation, and noncommunication. The proposed distributed algorithm: fuzzy self-organizing cooperative coevolution (FSC2) is then leveraged to resolve the three challenges in multi-target SOP: distributed self-organizing search (SOS), distributed task allocation, and distributed single-target pursuit. FSC2 includes a coordinated multi-agent deep reinforcement learning (MARL) method that enables homogeneous agents to learn natural SOS patterns. Additionall
    
[^76]: 高低注意力的快速视觉Transformer

    Fast Vision Transformers with HiLo Attention. (arXiv:2205.13213v5 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2205.13213](http://arxiv.org/abs/2205.13213)

    摘要：本文提出了一种名为HiLo注意力的自注意机制，使用分而治之的策略在注意力转换器中分解高/低频模式，可以更加高效地运行视觉Transformer，并在不同模型大小的范围内胜过现有的最先进方法。

    

    视觉Transformer (ViT) 已经在计算机视觉领域引起了重大突破。它们的高效设计大多由计算复杂性之间的间接指标（即 FLOP）指导，而与直接指标（如吞吐量）存在明显差距。因此，我们提出使用目标平台上的直接速度评估作为高效ViTs的设计原则。特别是，我们引入了LITv2，这是一个简单而有效的ViT，它在不同模型大小的范围内与现有的最先进方法相比表现优异，速度更快。LITv2的核心是一种新颖的自注意机制，我们称之为“高低注意力”。高低注意力的灵感来自于图像中的高频捕捉局部细节，低频专注于全局结构，而多头自注意层忽略了不同频率的特征。因此，我们提出使用分而治之的策略在注意力转换器中分解高/低频模式，其中自注意层分为两个分支，每个分支专门捕捉局部或全局信息。

    Vision Transformers (ViTs) have triggered the most recent and significant breakthroughs in computer vision. Their efficient designs are mostly guided by the indirect metric of computational complexity, i.e., FLOPs, which however has a clear gap with the direct metric such as throughput. Thus, we propose to use the direct speed evaluation on the target platform as the design principle for efficient ViTs. Particularly, we introduce LITv2, a simple and effective ViT which performs favourably against the existing state-of-the-art methods across a spectrum of different model sizes with faster speed. At the core of LITv2 is a novel self-attention mechanism, which we dub HiLo. HiLo is inspired by the insight that high frequencies in an image capture local fine details and low frequencies focus on global structures, whereas a multi-head self-attention layer neglects the characteristic of different frequencies. Therefore, we propose to disentangle the high/low frequency patterns in an attention
    
[^77]: 神经网络在模拟人类语音识别方面的成功和关键失败

    Successes and critical failures of neural networks in capturing human-like speech recognition. (arXiv:2204.03740v4 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2204.03740](http://arxiv.org/abs/2204.03740)

    本文综合了语音识别实验，评估了最先进的神经网络作为可计算、优化的观察器。实验结果展示了机器在带有噪声的语音识别能力的时间范围上表现出来的鲁棒性特征。

    

    自然与人工听觉原则上可以获得不同的给定问题的解决方案。然而，任务的约束可以促使听觉认知科学和工程定性收敛，表明更紧密的相互审查有可能丰富人工听觉系统和大脑的处理模型。语音识别是一个值得探索的领域，它在人类中天生对于各种光谱时间尺度的转换具有鲁棒性。到目前为止，高性能神经网络系统是否完全考虑了这些鲁棒性特征仍有待确定。我们将语音识别实验集成到一个综合框架中，以评估最先进的神经网络作为可计算、优化的观察器。通过一系列实验，我们（1）澄清了文献中有影响力的语音处理与自然语音之间的关系，（2）展示了机器表现出带有噪声的语音识别能力的时间范围。

    Natural and artificial audition can in principle acquire different solutions to a given problem. The constraints of the task, however, can nudge the cognitive science and engineering of audition to qualitatively converge, suggesting that a closer mutual examination would potentially enrich artificial hearing systems and process models of the mind and brain. Speech recognition an area ripe for such exploration - is inherently robust in humans to a number transformations at various spectrotemporal granularities. To what extent are these robustness profiles accounted for by high-performing neural network systems? We bring together experiments in speech recognition under a single synthesis framework to evaluate state-of-the-art neural networks as stimulus-computable, optimized observers. In a series of experiments, we (1) clarify how influential speech manipulations in the literature relate to each other and to natural speech, (2) show the granularities at which machines exhibit out-of-d
    
[^78]: 离线强化学习综述：分类、回顾和未解决问题

    A Survey on Offline Reinforcement Learning: Taxonomy, Review, and Open Problems. (arXiv:2203.01387v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2203.01387](http://arxiv.org/abs/2203.01387)

    本文综述了离线强化学习中的分类与最新算法突破，离线RL算法具有更广泛的应用，尤其适用于教育、医疗保健和机器人等实际应用。

    

    随着深度学习的广泛应用，强化学习（RL）在解决以往无法处理的问题方面取得了显著进展，如从像素观察中玩复杂游戏、与人类进行对话以及控制机器人智能体。然而，仍有许多领域由于与环境互动的高成本和危险而无法用RL解决。离线RL是一种范式，它仅从以前收集的交互的静态数据集中学习，因此可以从大型和多样化的培训数据集中提取策略。有效的离线RL算法比在线RL算法具有更广泛的应用，尤其适用于教育、医疗保健和机器人等实际应用。在本文中，我们提出了一个统一的分类法，对离线RL方法进行分类。此外，我们还对该领域最新的算法突破进行了全面回顾。

    With the widespread adoption of deep learning, reinforcement learning (RL) has experienced a dramatic increase in popularity, scaling to previously intractable problems, such as playing complex games from pixel observations, sustaining conversations with humans, and controlling robotic agents. However, there is still a wide range of domains inaccessible to RL due to the high cost and danger of interacting with the environment. Offline RL is a paradigm that learns exclusively from static datasets of previously collected interactions, making it feasible to extract policies from large and diverse training datasets. Effective offline RL algorithms have a much wider range of applications than online RL, being particularly appealing for real-world applications, such as education, healthcare, and robotics. In this work, we contribute with a unifying taxonomy to classify offline RL methods. Furthermore, we provide a comprehensive review of the latest algorithmic breakthroughs in the field usin
    
[^79]: CADRE:基于级联深度强化学习的基于视觉的自主城市驾驶框架

    CADRE: A Cascade Deep Reinforcement Learning Framework for Vision-based Autonomous Urban Driving. (arXiv:2202.08557v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2202.08557](http://arxiv.org/abs/2202.08557)

    本论文提出了一种基于级联深度强化学习框架 CADRE，通过 CoPM 离线训练，采用联合注意机制从预收集的驾驶数据集中学习视觉和控制信息之间的相互关系，在此基础上采用特别设计的奖励函数指导下，通过高效分布式 PPO 实现在线学习驾驶策略。

    

    在复杂的城市环境和驾驶行为动态的挑战下，基于视觉的自主城市驾驶是非常困难的。现有的方法要么严重依赖于手工规则，要么学习来自于有限人类经验，这使得它们难以推广到罕见但关键的情景。在本文中，我们提出了一种新颖的级联深度强化学习框架 CADRE，以实现无模型的基于视觉的自主城市驾驶。

    Vision-based autonomous urban driving in dense traffic is quite challenging due to the complicated urban environment and the dynamics of the driving behaviors. Widely-applied methods either heavily rely on hand-crafted rules or learn from limited human experience, which makes them hard to generalize to rare but critical scenarios. In this paper, we present a novel CAscade Deep REinforcement learning framework, CADRE, to achieve model-free vision-based autonomous urban driving. In CADRE, to derive representative latent features from raw observations, we first offline train a Co-attention Perception Module (CoPM) that leverages the co-attention mechanism to learn the inter-relationships between the visual and control information from a pre-collected driving dataset. Cascaded by the frozen CoPM, we then present an efficient distributed proximal policy optimization framework to online learn the driving policy under the guidance of particularly designed reward functions. We perform a compre
    
[^80]: 带采样成本的连续时间多臂赌博机问题研究

    Continuous Time Bandits With Sampling Costs. (arXiv:2107.05289v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2107.05289](http://arxiv.org/abs/2107.05289)

    本文研究了带采样成本的连续时间多臂赌博机问题，在连续时间里，学习者要在获得更高奖励和承担采样成本之间进行有效平衡。本文提出了一个达到下界的算法，并揭示了与传统多臂赌博机问题不同的特殊现象，具有广泛应用价值。

    

    本文研究了连续时间下的多臂赌博机问题(Continuous Time Multi-arm Bandit Problem，CTMAB)。在给定时间段内，学习者可以对臂进行任意次采样，每次采样都能获得随机奖励，但采样频率的提高会带来额外的惩罚/成本。因此，存在获得更高奖励与承担采样成本之间的平衡。本文旨在设计一种学习算法，使遗憾（regret，定义为学习算法与理论最优策略收益之间的差值）达到最小。CTMAB与通常的多臂赌博机问题(Multi-armed Bandit Problem，MAB)有根本的区别，例如，在CTMAB中，单臂情况都不是微不足道的，因为最优采样频率取决于臂的均值，而该均值需要被估计。本文首先建立了所有算法可达到的遗憾下界，然后提出了一种在对数因子上达到下界的算法。对于单臂情况，我们证明了下限和上限大致符合，并提出了一个计算效率高的算法。我们的结果揭示了在经典MAB问题中不存在的令人惊讶的现象，并在各个领域的顺序决策问题中具有广泛的应用。

    We consider a continuous-time multi-arm bandit problem (CTMAB), where the learner can sample arms any number of times in a given interval and obtain a random reward from each sample, however, increasing the frequency of sampling incurs an additive penalty/cost. Thus, there is a tradeoff between obtaining large reward and incurring sampling cost as a function of the sampling frequency. The goal is to design a learning algorithm that minimizes regret, that is defined as the difference of the payoff of the oracle policy and that of the learning algorithm. CTMAB is fundamentally different than the usual multi-arm bandit problem (MAB), e.g., even the single-arm case is non-trivial in CTMAB, since the optimal sampling frequency depends on the mean of the arm, which needs to be estimated. We first establish lower bounds on the regret achievable with any algorithm and then propose algorithms that achieve the lower bound up to logarithmic factors. For the single-arm case, we show that the lower
    
[^81]: 基于过拟合模型特性的噪声标签检测方法

    Over-Fit: Noisy-Label Detection based on the Overfitted Model Property. (arXiv:2106.07217v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2106.07217](http://arxiv.org/abs/2106.07217)

    本文提出一种基于模型过拟合特性的后训练学习方法，能够识别错误标记的样本，并逐步删除对决策边界有较高影响的样本，从而提高模型的泛化性能。

    

    由于深度神经网络具有高容量特性，即使是噪声标签，也容易过度拟合，从而降低模型的泛化性能。为了解决这个问题，我们提出了一种新的后训练学习方法，用于从含噪声标签的数据中显著提高任何预训练模型的泛化性能。具体而言，我们利用训练模型的过拟合特性来识别错误标记的样本，逐步删除对决策边界有较高影响的样本，并改善决策边界来提高泛化性能。我们的后训练方法与现有的噪声标签学习方法相结合具有很好的协同效果。在多种真实世界和合成基准数据集上的实验证明了我们方法在各种实际情况下的有效性。

    Deep neural network can easily overfit to even noisy labels due to its high capacity, which degrades the generalization performance of a model. To overcome this issue, we propose a new approach for learning from noisy labels (LNL) via post-training, which can significantly improve the generalization performance of any pre-trained model on noisy label data. To this end, we rather exploit the overfitting property of a trained model to identify mislabeled samples. Specifically, our post-training approach gradually removes samples with high influence on the decision boundary and refines the decision boundary to improve generalization performance. Our post-training approach creates great synergies when combined with the existing LNL methods. Experimental results on various real-world and synthetic benchmark datasets demonstrate the validity of our approach in diverse realistic scenarios.
    
[^82]: 关于统一一维分片

    On the uniform one-dimensional fragment. (arXiv:1604.01673v3 [cs.LO] UPDATED)

    [http://arxiv.org/abs/1604.01673](http://arxiv.org/abs/1604.01673)

    统一一维分片是一种形式化语言，可将二元逻辑扩展到具有任意元数关系的上下文中。其描述逻辑版本具有表达能力的新结果，与能够容纳更高元数关系的描述逻辑紧密相关。

    

    统一一维分片（U1）是一种形式化语言，以一种自然的方式将二元逻辑扩展到具有任意元数关系的上下文中。我们调查了U1的属性并研究了它与旨在容纳更高元数关系的描述逻辑的关系，特别关注DLR_reg。我们还定义了U1的一个变体的描述逻辑版本，并证明了有关U1及其相关逻辑的表达能力的一系列新结果。

    The uniform one-dimensional fragment of first-order logic, U1, is a formalism that extends two-variable logic in a natural way to contexts with relations of all arities. We survey properties of U1 and investigate its relationship to description logics designed to accommodate higher arity relations, with particular attention given to DLR_reg. We also define a description logic version of a variant of U1 and prove a range of new results concerning the expressivity of U1 and related logics.
    

