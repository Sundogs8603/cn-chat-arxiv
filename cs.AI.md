# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Synthetically Generating Human-like Data for Sequential Decision Making Tasks via Reward-Shaped Imitation Learning.](http://arxiv.org/abs/2304.07280) | 本文提出了一种从少量人类数据开始，通过奖励塑形和模仿学习算法合成类似人类决策的数据的方法，并通过应用到电脑游戏的连续决策任务中证明其有效性。 |
| [^2] | [Fusing Structure from Motion and Simulation-Augmented Pose Regression from Optical Flow for Challenging Indoor Environments.](http://arxiv.org/abs/2304.07250) | 本文探讨了如何在室内环境下进行运动目标的定位，使用了结构运动与模拟数据和深度学习技术。研究者整合光流和相对姿态回归方法帮助解决了因运动模糊、光照变化、重复图案和缺乏特征结构等问题而带来的瓶颈，为室内目标定位提供了更好的方案。 |
| [^3] | [Evaluation of ChatGPT Model for Vulnerability Detection.](http://arxiv.org/abs/2304.07232) | 本文评估了ChatGPT模型在真实世界的CWE漏洞数据集上对代码漏洞检测的性能，结果发现该模型在此任务中表现不好。 |
| [^4] | [Model Predictive Control with Self-supervised Representation Learning.](http://arxiv.org/abs/2304.07219) | 该论文提出了在TD-MPC框架内使用重构函数进行自监督表示学习的方法，在机器人控制任务中实现更好的性能表现。 |
| [^5] | [Just Tell Me: Prompt Engineering in Business Process Management.](http://arxiv.org/abs/2304.07183) | 该论文探讨了提示工程方法在业务流程管理中的应用。这种方法可以利用预训练的语言模型解决微调需要大量数据的问题，并为BPM研究带来诸多潜力。 |
| [^6] | [Bandit-Based Policy Invariant Explicit Shaping for Incorporating External Advice in Reinforcement Learning.](http://arxiv.org/abs/2304.07163) | 本文研究了如何基于Bandit方法将外部建议融入到强化学习中，并提出了三种不同的塑形算法：UCB-PIES（UPIES）， Racing-PIES（RPIES）和Lazy PIES（LPIES）。实验结果表明这些算法在样本复杂度、学习速度和形状质量方面都取得了良好的效果。 |
| [^7] | [A Review on Longitudinal Car-Following Model.](http://arxiv.org/abs/2304.07143) | 这篇论文综述了逐车跟驰模型的不同原则和分类，以及面临的挑战和局限性。 |
| [^8] | [On Data Sampling Strategies for Training Neural Network Speech Separation Models.](http://arxiv.org/abs/2304.07142) | 本文研究了训练神经网络语音分离模型的数据采样策略对模型性能的影响。研究表明，对于特定的信号长度分布，采用特定的训练信号长度限制可以获得更好的性能。 |
| [^9] | [TUM-FA\c{C}ADE: Reviewing and enriching point cloud benchmarks for fa\c{c}ade segmentation.](http://arxiv.org/abs/2304.07140) | 本文介绍了一种用于增强现有点云数据集的方法，以便进行表面分割测试，并利用该方法创建了TUM-FA\c{C}ADE数据集。这个数据集可以促进基于点云的表面分割任务的开发，并且该方法也可以用于其他基准类型，创建更多样化的评估数据集。 |
| [^10] | [Task-oriented Document-Grounded Dialog Systems by HLTPR@RWTH for DSTC9 and DSTC10.](http://arxiv.org/abs/2304.07101) | 本论文总结了HLTPR@RWTH团队在DSTC9和DSTC10中为任务导向型文档对话系统所做的贡献，包括提出了不同的方法来使选择任务更有效率，在DSTC10中提出了数据增强技术来提高模型的鲁棒性并适应生成回答的风格，以及提出了一个嘈杂的通道模型来直接建模语音识别错误。实验结果表明，该团队的方法显著优于基线模型。 |
| [^11] | [The role of object-centric representations, guided attention, and external memory on generalizing visual relations.](http://arxiv.org/abs/2304.07091) | 研究对几种DNN进行了系统评估，发现DNN尚无法很好地在特定类型的图像中推广抽象的视觉关系，因此抽象的视觉推理仍然是DNN无法解决的挑战。 |
| [^12] | [BCE-Net: Reliable Building Footprints Change Extraction based on Historical Map and Up-to-Date Images using Contrastive Learning.](http://arxiv.org/abs/2304.07076) | 本研究通过对比学习方法，将历史地图和最新卫星影像中建筑物轮廓进行对比，将建筑物语义信息融入变化检测流程，提高建筑物与非建筑物特征的可分辨性。 |
| [^13] | [CornerFormer: Boosting Corner Representation for Fine-Grained Structured Reconstruction.](http://arxiv.org/abs/2304.07072) | CornerFormer是一种新的方法，它利用不同建模策略于单个模型中融合角点检测和边缘预测来提升精细结构重建的表现，并在挑战性的基准测试中取得了最好的结果。 |
| [^14] | [SEA: A Scalable Entity Alignment System.](http://arxiv.org/abs/2304.07065) | 提出了一个可扩展的实体对齐系统SEA，它包括了六个最先进的EA模型并能够使用户轻松建立、评估自己的模型，提高了基于GNN的EA模型在实际应用中的可用性和效率。 |
| [^15] | [On Existential First Order Queries Inference on Knowledge Graphs.](http://arxiv.org/abs/2304.07063) | 本文阐述了关于知识图谱中存在性一阶查询推理的新方法，提出了一个新数据集，并开发了一种来自模糊逻辑理论的新搜索算法，该算法能够解决新公式，并在现有公式中超过以前的方法。 |
| [^16] | [DroidBot-GPT: GPT-powered UI Automation for Android.](http://arxiv.org/abs/2304.07061) | DroidBot-GPT是一款利用GPT模型自动化Android应用程序的工具，可以根据任务的自然语言描述自动生成并执行操作，有望提高移动应用程序的测试和开发效率。 |
| [^17] | [Perceptual Quality Assessment of Face Video Compression: A Benchmark and An Effective Method.](http://arxiv.org/abs/2304.07056) | 本文介绍了大规模压缩面部视频质量评估（CFVQA）数据库，用于系统地了解面部视频感知质量和多样化压缩失真。生成式编码方法被确定为具有合理的感知码率失真折衷的有前途的替代方法，利用面部视频的统计先验知识。 |
| [^18] | [The Second Monocular Depth Estimation Challenge.](http://arxiv.org/abs/2304.07051) | 本文介绍了单目深度估计挑战赛的第二届比赛结果，高质量的SYNS-Patches数据集提高了比赛难度，所有提交作品都超过了基准水平。 |
| [^19] | [Lossy Compression of Large-Scale Radio Interferometric Data.](http://arxiv.org/abs/2304.07050) | 本文提出了一种通过基线相关的有损压缩技术来降低射电干涉可见度数据体积的方法，将整个可见度数据表示为基线的数据矩阵集合，从而实现数据的压缩，同时保留视场边缘的模糊效应。 |
| [^20] | [FairRec: Fairness Testing for Deep Recommender Systems.](http://arxiv.org/abs/2304.07030) | 本文提出了一种名为FairRec的统一框架，支持对深度推荐系统进行公平性测试。同时，提供了一组新的公平性概念针对推荐系统的特征，可以有效地发现DRS中独特的公平性问题。 |
| [^21] | [SimpLex: a lexical text simplification architecture.](http://arxiv.org/abs/2304.07002) | SimpLex是一种用于生成简化英文句子的新型简化架构，它使用词嵌入或句子转换器来生成简化句子并集成到易用的软件中。实验结果中发现，变压器模型在SARI得分方面表现优异，而基于词嵌入的模型则在困惑度方面表现更好。 |
| [^22] | [H2TNE: Temporal Heterogeneous Information Network Embedding in Hyperbolic Spaces.](http://arxiv.org/abs/2304.06970) | 该论文提出了 H2TNE 模型，用于将时态异构信息网络嵌入到双曲空间中。通过时间和异质性双重约束的随机游走策略，该模型能够捕捉结构与语义信息。 |
| [^23] | [Self-Supervised Learning based Depth Estimation from Monocular Images.](http://arxiv.org/abs/2304.06966) | 本论文研究了基于自监督学习的单目图像深度估计，探索了多种扩展深度估计模型的方法，并计划实现姿态估计和语义分割等技术来提供更准确的深度图预测。 |
| [^24] | [Prompt Engineering and Calibration for Zero-Shot Commonsense Reasoning.](http://arxiv.org/abs/2304.06962) | 本文研究并评估提示工程和校准策略对于小型语言模型在五个常识推理基准上的表现，发现每种策略倾向于某些模型，但联合效果为负。 |
| [^25] | [AUTOSPARSE: Towards Automated Sparse Training of Deep Neural Networks.](http://arxiv.org/abs/2304.06941) | 本文提出了一种叫做AutoSparse的自动稀疏训练算法，其中包含梯度退火法来权衡稀疏和准确性，在ResNet50和MobileNetV1上表现出更好的准确性和较少的计算资源需求。 |
| [^26] | [CiPR: An Efficient Framework with Cross-instance Positive Relations for Generalized Category Discovery.](http://arxiv.org/abs/2304.06928) | 该论文提出了一个名为CiPR的框架，通过利用部分标记数据中的跨实例正关系进行对比学习，解决了广义类别发现(GCD)的问题。选择邻居聚类(SNC)算法在此过程中发挥了重要作用。 |
| [^27] | [YOLO-Drone:Airborne real-time detection of dense small objects from high-altitude perspective.](http://arxiv.org/abs/2304.06925) | YOLO-Drone是一种能够高效检测小尺度物体的实时物体检测算法，并在无人机平台上得到了应用，以广义交集联盟(GIOU)作为损失函数，取得了最佳的检测效果。 |
| [^28] | [Sampling-based Reactive Synthesis for Nondeterministic Hybrid Systems.](http://arxiv.org/abs/2304.06876) | 本文提出了一种基于采样的策略综合算法，用于具有复杂连续动力学和时间和可达性约束的非确定性混合系统。算法基于在混合空间中生长（搜索）游戏树，以合成一种反应（鲁棒）策略，以满足目标并在可扩展性和效率方面优于最新技术水平。 |
| [^29] | [CAR-DESPOT: Causally-Informed Online POMDP Planning for Robots in Confounded Environments.](http://arxiv.org/abs/2304.06848) | 本文提出了一种新的因果关系在线POMDP规划方法CAR-DESPOT，使用因果建模和推理来消除未测量混淆变量引起的错误，并在混杂环境中表现优异。 |
| [^30] | [Structured Pruning for Multi-Task Deep Neural Networks.](http://arxiv.org/abs/2304.06840) | 本研究探索了在多任务模型上应用结构化剪枝的有效性，通过实验发现，在参数数量相似的情况下，来自不同剪枝方法的架构在任务性能上没有显着差异，迭代结构剪枝可能不是实现最优结构的最佳方法。 |
| [^31] | [Modeling Dense Multimodal Interactions Between Biological Pathways and Histology for Survival Prediction.](http://arxiv.org/abs/2304.06819) | 本论文提出了一种解决整合全切片图像和批量转录组学预测患者生存率的多模态任务的方案，旨在解决标记化转录组学和捕获这两种模态之间的交互的问题。 |
| [^32] | [Unified Out-Of-Distribution Detection: A Model-Specific Perspective.](http://arxiv.org/abs/2304.06813) | 本文提出一种新颖的统一框架，用于将机器学习模型中的外部分布检测扩展到更广泛的范围，该框架旨在检测模型无法正确预测的测试示例，而不是特定的外部分布原因。 |
| [^33] | [Designing Nonlinear Photonic Crystals for High-Dimensional Quantum State Engineering.](http://arxiv.org/abs/2304.06810) | 该论文提出了一种通过设计非线性光子晶体和泵浦光束生成高维量子态的方法，同时基于所提出的物理约束和可微分的方法，理论和实验上演示了如何生成最大纠缠态。这为控制任意量子态提供了新途径，并在全光学相干控制成为可能。 |
| [^34] | [On the Opportunities and Challenges of Foundation Models for Geospatial Artificial Intelligence.](http://arxiv.org/abs/2304.06798) | 本文研究了在地理空间AI中开发基础模型的机遇和挑战，测试了多种FMs在地理子领域中的表现，发现在文本任务上的表现优于任务特定的定制模型，但在发展中也面临着缺少数据集和需要专业技术微调的挑战。 |
| [^35] | [ChatGPT cites the most-cited articles and journals, relying solely on Google Scholar's citation counts. As a result, AI may amplify the Matthew Effect in environmental science.](http://arxiv.org/abs/2304.06794) | ChatGPT使用谷歌学术的引用计数来引述环境科学中的最具影响力的文章和期刊，但这可能会放大马太效应。 |
| [^36] | [RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment.](http://arxiv.org/abs/2304.06767) | RAFT框架引入了奖励排名微调方法，用于对齐生成型基础模型，以解决强化学习带来的低效和不稳定性问题。 |
| [^37] | [A Study of Biologically Plausible Neural Network: The Role and Interactions of Brain-Inspired Mechanisms in Continual Learning.](http://arxiv.org/abs/2304.06738) | 本论文提出了一种基于脑启发机制的生物可行的神经网络框架，并研究了其中包括稀疏不重叠表示、赫布学习、突触巩固和重播等机制在持续学习中的相互作用，实现了基于序列的持续学习基准测试的最先进性能。 |
| [^38] | [Meta-Learned Models of Cognition.](http://arxiv.org/abs/2304.06729) | 元学习模型是构建人类认知模型的有前途的工具，可以用于构建贝叶斯最优学习算法，并且比传统的贝叶斯方法有几个优势。 |
| [^39] | [Late Breaking Results: Scalable and Efficient Hyperdimensional Computing for Network Intrusion Detection.](http://arxiv.org/abs/2304.06728) | 本文提出了一种名为CyberHD的超维计算学习框架，该框架可以以显著更低的维度捕捉网络威胁的复杂模式，并具有显著的硬件错误容错能力。 |
| [^40] | [Diagnostic Benchmark and Iterative Inpainting for Layout-Guided Image Generation.](http://arxiv.org/abs/2304.06671) | 本文提出了布局引导下图像生成的诊断基准LayoutBench，对数量、位置、大小和形状四种空间控制技能进行了研究，发现好的ID布局控制在任意布局的野外环境下可能不具有良好的推广性。接着，我们提出了一种新的基准方法IterInpaint通过修复逐步生成前景和背景区域，显现出在OOD布局方面更强的通用性。 |
| [^41] | [Analyzing ChatGPT's Aptitude in an Introductory Computer Engineering Course.](http://arxiv.org/abs/2304.06122) | 本文研究探讨了ChatGPT在计算机工程入门课程中的应用，发现它可以回答普通概念的问题，但无法处理带有图表或图形的问题，也无法进行实验室的现场操作。 |
| [^42] | [Reinforcement Learning Tutor Better Supported Lower Performers in a Math Task.](http://arxiv.org/abs/2304.04933) | 本文证明了深度强化学习可用于提供自适应的教育支持，尤其对于最初成绩较低的学生具有最大的益处。 |
| [^43] | [Improving Performance Insensitivity of Large-scale Multiobjective Optimization via Monte Carlo Tree Search.](http://arxiv.org/abs/2304.04071) | 本论文提出了一种能同时提高大规模多目标优化算法性能和不敏感性的方法，该方法利用蒙特卡罗树搜索。 |
| [^44] | [REDf: A Renewable Energy Demand Forecasting Model for Smart Grids using Long Short Term Memory Network.](http://arxiv.org/abs/2304.03997) | 本文提出了一种基于长短期记忆网络的智能电网可再生能源需求预测模型REDf，可以提供准确的能量需求预测，改善可再生能源的集成，实验结果表明其准确度优于其他模型。 |
| [^45] | [InstructBio: A Large-scale Semi-supervised Learning Paradigm for Biochemical Problems.](http://arxiv.org/abs/2304.03906) | InstructBio是一种针对生物化学问题的大规模半监督学习算法，引入教练模型提供有效的置信度比率来指导目标模型对不同数据点给予明显关注，避免依赖有限的标记数据和不正确的伪注释，提高了分子模型的泛化能力。 |
| [^46] | [Subject-driven Text-to-Image Generation via Apprenticeship Learning.](http://arxiv.org/abs/2304.00186) | 该论文提出了一种基于徒弟学习的面向主题的文本到图像生成器SuTI，能够通过将大量基于主题的专家模型的数据输入徒弟模型，学习并推断出新主题的最佳专家模型，从而生成高品质的自定义图像，且速度比传统方法更快。 |
| [^47] | [Superhuman Artificial Intelligence Can Improve Human Decision Making by Increasing Novelty.](http://arxiv.org/abs/2303.07462) | 该研究通过分析职业围棋选手的移动决策发现，在超人工智能问世后，人类开始做出显著更好的决策，并且新颖的决策更频繁地发生，可能意味着超人工智能的发展可以改变人类的决策能力。 |
| [^48] | [MCTS-GEB: Monte Carlo Tree Search is a Good E-graph Builder.](http://arxiv.org/abs/2303.04651) | MCTS-GEB是一个通用的重写系统，使用强化学习和蒙特卡洛树搜索来构建最优的E图，有效消除了E图构建中的顺序问题，并在评估中表现出很好的性能。 |
| [^49] | [Inseq: An Interpretability Toolkit for Sequence Generation Models.](http://arxiv.org/abs/2302.13942) | 本文介绍了Inseq，这是一个Python工具包，旨在推广可解释性序列生成模型的分析。它为常见的解码器和编码器-解码器Transformers架构提供了提取模型内部信息和特征重要性得分的直观优化方法。作者还在机器翻译模型和GPT-2中展示了Inseq的潜力，证明其有助于推动可解释性自然语言生成的未来发展。 |
| [^50] | [Is Distance Matrix Enough for Geometric Deep Learning?.](http://arxiv.org/abs/2302.05743) | 本文证明了消息传递神经网络（MPNNs）不能学习几何信息，提出了$k$-DisGNNs可以利用距离矩阵中的信息，并建立了几何深度学习和传统图表示学习之间的联系。 |
| [^51] | [Bayesian Weapon System Reliability Modeling with Cox-Weibull Neural Network.](http://arxiv.org/abs/2301.01850) | 该论文提出了一种带有Cox-Weibull神经网络的贝叶斯武器系统可靠性建模方法，可以通过整合武器系统特征来改善预测性维修，相较于传统模型的表现更优。 |
| [^52] | [Berlin V2X: A Machine Learning Dataset from Multiple Vehicles and Radio Access Technologies.](http://arxiv.org/abs/2212.10343) | 这篇论文介绍了一个详细的测量活动，提供了一个多车辆和无线电访问技术的机器学习数据集，该数据集通过各种V2X研究为车辆和工业通信领域开辟了新的可能性。 |
| [^53] | [Low Variance Off-policy Evaluation with State-based Importance Sampling.](http://arxiv.org/abs/2212.03932) | 本文提出了一种基于状态的重要性抽样（SIS）方法，通过检测“忽略状态”的子轨迹来实现低方差的离线评估。 |
| [^54] | [CLIP-Sculptor: Zero-Shot Generation of High-Fidelity and Diverse Shapes from Natural Language.](http://arxiv.org/abs/2211.01427) | 这篇论文提出了一种名为 CLIP-Sculptor 的方法，可以通过自然语言来生成和编辑高保真度和多样性的三维形状，且不需要 (文本，形状) 对训练，通过不同的潜在空间和改进的指导方法来实现更好的效果。 |
| [^55] | [Improving Semantic Matching through Dependency-Enhanced Pre-trained Model with Adaptive Fusion.](http://arxiv.org/abs/2210.08471) | 本文提出了一种依赖增强的自适应融合注意力模型，它将依赖信息与原始语义信号自适应融合，以更好地模拟复杂的语义匹配关系。 |
| [^56] | [Finite-rate sparse quantum codes aplenty.](http://arxiv.org/abs/2207.03562) | 本研究提供了一种生成有限速稀疏量子码的方法，通过解决随机二部图上的约束满足问题同时强制执行多个约束限制。在满足阶段中找到的稀疏码能实现涂抹噪声的通道容量，且中等大小的有限速稀疏量子码很容易找到。 |
| [^57] | [Generalized Policy Improvement Algorithms with Theoretically Supported Sample Reuse.](http://arxiv.org/abs/2206.13714) | 研究提出了一种广义策略提升算法，结合了在线方法的策略提升保证和离线策略算法通过样本重用有效利用数据的效率。 |
| [^58] | [Sources of Irreproducibility in Machine Learning: A Review.](http://arxiv.org/abs/2204.07610) | 本文提出了一个理解机器学习中不可重复性来源的框架，并指出实验设置问题和未能正确考虑数据变异是机器学习研究中最常见的不可重复性来源。 |
| [^59] | [Concise Logarithmic Loss Function for Robust Training of Anomaly Detection Model.](http://arxiv.org/abs/2201.05748) | 本研究提出了一种新的对数均方误差（LMSE）损失函数，相比于现有的均方误差（MSE）函数，在神经网络训练中更稳定、具有更强的收敛性和更好的异常检测性能。 |
| [^60] | [Artificial Intelligence-Driven Customized Manufacturing Factory: Key Technologies, Applications, and Challenges.](http://arxiv.org/abs/2108.03383) | 人工智能技术在定制化制造中起到关键作用，实现了定制化智能工厂的特点，包括自我感知、运营优化、动态重构和智能决策，并可实现智能生产、联网协作和扩展服务模型等业务模型。 |
| [^61] | [Learning Geometric Combinatorial Optimization Problems using Self-attention and Domain Knowledge.](http://arxiv.org/abs/2107.01759) | 使用自注意力和领域知识，提出了一种新颖的神经网络模型来解决涉及几何的组合优化问题，可应用于各种涉及几何的COP，并在实验中取得了显著的解决质量和可扩展性方面的提高。 |

# 详细

[^1]: 使用基于奖励塑形的模仿学习合成类似人类数据，来解决连续决策问题

    Synthetically Generating Human-like Data for Sequential Decision Making Tasks via Reward-Shaped Imitation Learning. (arXiv:2304.07280v1 [cs.LG])

    [http://arxiv.org/abs/2304.07280](http://arxiv.org/abs/2304.07280)

    本文提出了一种从少量人类数据开始，通过奖励塑形和模仿学习算法合成类似人类决策的数据的方法，并通过应用到电脑游戏的连续决策任务中证明其有效性。

    

    本文针对在与AI系统进行交互的情况下，例如与电脑游戏交互，如何合成类似于人类决策的数据进行研究。本文提出一种新的算法，能够从少量的人类决策数据入手，将奖励塑形的概念与模仿学习算法相结合，生成合成的、类似于人类决策的数据。作者使用这种技术在一个小型的电脑游戏中完成了三个不同难度的连续决策任务，并对实验结果进行了多方面的经验性和统计性分析，证明了合成的数据可以代替人类数据，实现与人类类似的决策和任务表现。

    We consider the problem of synthetically generating data that can closely resemble human decisions made in the context of an interactive human-AI system like a computer game. We propose a novel algorithm that can generate synthetic, human-like, decision making data while starting from a very small set of decision making data collected from humans. Our proposed algorithm integrates the concept of reward shaping with an imitation learning algorithm to generate the synthetic data. We have validated our synthetic data generation technique by using the synthetically generated data as a surrogate for human interaction data to solve three sequential decision making tasks of increasing complexity within a small computer game-like setup. Different empirical and statistical analyses of our results show that the synthetically generated data can substitute the human data and perform the game-playing tasks almost indistinguishably, with very low divergence, from a human performing the same tasks.
    
[^2]: 通过从光流信息中融合运动结构与模拟数据的绝对位置回归，解决室内环境定位的挑战性问题

    Fusing Structure from Motion and Simulation-Augmented Pose Regression from Optical Flow for Challenging Indoor Environments. (arXiv:2304.07250v1 [cs.CV])

    [http://arxiv.org/abs/2304.07250](http://arxiv.org/abs/2304.07250)

    本文探讨了如何在室内环境下进行运动目标的定位，使用了结构运动与模拟数据和深度学习技术。研究者整合光流和相对姿态回归方法帮助解决了因运动模糊、光照变化、重复图案和缺乏特征结构等问题而带来的瓶颈，为室内目标定位提供了更好的方案。

    

    目标的定位是各种应用中的重要任务，比如机器人、虚拟和增强现实、和在仓库中运送货物。深度学习的先进发展已经使得使用单目视觉相机进行定位成为可能。然而，所面临的挑战是由于环境本身引起的问题，例如运动模糊、光照变化、重复图案和缺乏特征的结构。本研究旨在通过融合附加信息和使用相对位置回归（RPR）方法来解决这些问题。使用Lucas-Kanade算法计算连续图像之间的光流，并使用辅助小型循环卷积网络来预测相对姿态。将绝对姿态和相对姿态进行融合。

    The localization of objects is a crucial task in various applications such as robotics, virtual and augmented reality, and the transportation of goods in warehouses. Recent advances in deep learning have enabled the localization using monocular visual cameras. While structure from motion (SfM) predicts the absolute pose from a point cloud, absolute pose regression (APR) methods learn a semantic understanding of the environment through neural networks. However, both fields face challenges caused by the environment such as motion blur, lighting changes, repetitive patterns, and feature-less structures. This study aims to address these challenges by incorporating additional information and regularizing the absolute pose using relative pose regression (RPR) methods. The optical flow between consecutive images is computed using the Lucas-Kanade algorithm, and the relative pose is predicted using an auxiliary small recurrent convolutional network. The fusion of absolute and relative poses is
    
[^3]: 基于ChatGPT的漏洞检测模型的评估

    Evaluation of ChatGPT Model for Vulnerability Detection. (arXiv:2304.07232v1 [cs.CR])

    [http://arxiv.org/abs/2304.07232](http://arxiv.org/abs/2304.07232)

    本文评估了ChatGPT模型在真实世界的CWE漏洞数据集上对代码漏洞检测的性能，结果发现该模型在此任务中表现不好。

    

    在这篇技术报告中，我们评估了ChatGPT和GPT-3模型在代码漏洞检测任务中的性能。我们使用二进制和多标签分类任务对CWE漏洞进行了真实世界数据集的评估。我们决定对该模型进行评估，因为它在其他基于代码的任务上表现良好，比如解决编程挑战和理解高水平的代码。然而，我们发现ChatGPT模型在代码漏洞检测的二进制和多标签分类任务中表现不如虚拟分类器。

    In this technical report, we evaluated the performance of the ChatGPT and GPT-3 models for the task of vulnerability detection in code. Our evaluation was conducted on our real-world dataset, using binary and multi-label classification tasks on CWE vulnerabilities. We decided to evaluate the model because it has shown good performance on other code-based tasks, such as solving programming challenges and understanding code at a high level. However, we found that the ChatGPT model performed no better than a dummy classifier for both binary and multi-label classification tasks for code vulnerability detection.
    
[^4]: 具有自监督表示学习的模型预测控制

    Model Predictive Control with Self-supervised Representation Learning. (arXiv:2304.07219v1 [cs.LG])

    [http://arxiv.org/abs/2304.07219](http://arxiv.org/abs/2304.07219)

    该论文提出了在TD-MPC框架内使用重构函数进行自监督表示学习的方法，在机器人控制任务中实现更好的性能表现。

    

    在过去的几年中，我们没有看到模型无关或模型基础学习方法有任何重大进展，使得其中一个相对于另一个过时。在大多数情况下，所使用的技术严重依赖于用例场景或其他属性，例如环境。两种方法都有自己的优点，例如样本效率或计算效率。然而，当将两种方法结合起来时，可以结合各自的优点，从而实现更好的性能。TD-MPC框架就是这种方法的一个例子。一方面，结合模型预测控制的世界模型用于获得良好的值函数初始估计。另一方面，Q函数用于提供良好的长期估计。与MuZero等算法类似，使用潜在状态表示，其中仅对任务相关信息进行编码以减少复杂性。本文提出了在TD-MPC框架内使用重构函数进行自监督表示学习。这可以创建更具信息性和鲁棒性的潜在状态表示，从而提高了一系列机器人控制任务的性能。

    Over the last few years, we have not seen any major developments in model-free or model-based learning methods that would make one obsolete relative to the other. In most cases, the used technique is heavily dependent on the use case scenario or other attributes, e.g. the environment. Both approaches have their own advantages, for example, sample efficiency or computational efficiency. However, when combining the two, the advantages of each can be combined and hence achieve better performance. The TD-MPC framework is an example of this approach. On the one hand, a world model in combination with model predictive control is used to get a good initial estimate of the value function. On the other hand, a Q function is used to provide a good long-term estimate. Similar to algorithms like MuZero a latent state representation is used, where only task-relevant information is encoded to reduce the complexity. In this paper, we propose the use of a reconstruction function within the TD-MPC fram
    
[^5]: Just Tell Me: 业务流程管理中的提示工程

    Just Tell Me: Prompt Engineering in Business Process Management. (arXiv:2304.07183v1 [cs.AI])

    [http://arxiv.org/abs/2304.07183](http://arxiv.org/abs/2304.07183)

    该论文探讨了提示工程方法在业务流程管理中的应用。这种方法可以利用预训练的语言模型解决微调需要大量数据的问题，并为BPM研究带来诸多潜力。

    

    GPT-3和其他几个语言模型可以有效地处理各种自然语言处理任务，包括机器翻译和文本摘要。最近，它们也在业务流程管理（BPM）领域成功应用，例如用于预测过程监控和从文本中提取过程。然而，这通常需要对所用语言模型进行微调，其中包括大量合适的训练数据。解决这个问题的一种可能解决方案是使用提示工程，它利用预训练的语言模型，而无需进行微调。认识到这一点，我们认为提示工程可以帮助将语言模型的能力引入BPM研究。本篇文章利用这一观点，通过确定相关的潜力和挑战，为BPM研究的提示工程使用制定研究议程。

    GPT-3 and several other language models (LMs) can effectively address various natural language processing (NLP) tasks, including machine translation and text summarization. Recently, they have also been successfully employed in the business process management (BPM) domain, e.g., for predictive process monitoring and process extraction from text. This, however, typically requires fine-tuning the employed LM, which, among others, necessitates large amounts of suitable training data. A possible solution to this problem is the use of prompt engineering, which leverages pre-trained LMs without fine-tuning them. Recognizing this, we argue that prompt engineering can help bring the capabilities of LMs to BPM research. We use this position paper to develop a research agenda for the use of prompt engineering for BPM research by identifying the associated potentials and challenges.
    
[^6]: 强化学习中基于Bandit方法的显式塑形外部建议算法的研究

    Bandit-Based Policy Invariant Explicit Shaping for Incorporating External Advice in Reinforcement Learning. (arXiv:2304.07163v1 [cs.AI])

    [http://arxiv.org/abs/2304.07163](http://arxiv.org/abs/2304.07163)

    本文研究了如何基于Bandit方法将外部建议融入到强化学习中，并提出了三种不同的塑形算法：UCB-PIES（UPIES）， Racing-PIES（RPIES）和Lazy PIES（LPIES）。实验结果表明这些算法在样本复杂度、学习速度和形状质量方面都取得了良好的效果。

    

    强化学习（RL）算法中的一个关键问题是如何将外部或专家的建议融入到学习当中。本文将将将此问题表述为一种多臂赌博机称为塑形赌博机（shaping-bandits）。我们提出了三种不同的塑形算法：UCB-PIES（UPIES）， Racing-PIES（RPIES）和Lazy PIES（LPIES）。通过在模拟环境和LQR和Atari环境中的实验，我们证明了这三种算法在样本复杂度、学习速度和形状质量方面的有效性。

    A key challenge for a reinforcement learning (RL) agent is to incorporate external/expert1 advice in its learning. The desired goals of an algorithm that can shape the learning of an RL agent with external advice include (a) maintaining policy invariance; (b) accelerating the learning of the agent; and (c) learning from arbitrary advice [3]. To address this challenge this paper formulates the problem of incorporating external advice in RL as a multi-armed bandit called shaping-bandits. The reward of each arm of shaping bandits corresponds to the return obtained by following the expert or by following a default RL algorithm learning on the true environment reward.We show that directly applying existing bandit and shaping algorithms that do not reason about the non-stationary nature of the underlying returns can lead to poor results. Thus we propose UCB-PIES (UPIES), Racing-PIES (RPIES), and Lazy PIES (LPIES) three different shaping algorithms built on different assumptions that reason a
    
[^7]: 逐车跟驰模型综述

    A Review on Longitudinal Car-Following Model. (arXiv:2304.07143v1 [eess.SY])

    [http://arxiv.org/abs/2304.07143](http://arxiv.org/abs/2304.07143)

    这篇论文综述了逐车跟驰模型的不同原则和分类，以及面临的挑战和局限性。

    

    车跟车模型是交通仿真的核心组成部分，已经内置于许多配备ADAS的汽车中。对车跟车行为的研究使我们能够确定由基本的车辆交互过程引起的不同宏观现象的根源。本文提供了一份详尽的调查，重点介绍了各种车跟车模型之间的区别、互补性和重叠之处。该审查将在不同原则中概念化的车跟车模型进行分类。

    The car-following (CF) model is the core component for traffic simulations and has been built-in in many production vehicles with Advanced Driving Assistance Systems (ADAS). Research of CF behavior allows us to identify the sources of different macro phenomena induced by the basic process of pairwise vehicle interaction. The CF behavior and control model encompasses various fields, such as traffic engineering, physics, cognitive science, machine learning, and reinforcement learning. This paper provides a comprehensive survey highlighting differences, complementarities, and overlaps among various CF models according to their underlying logic and principles. We reviewed representative algorithms, ranging from the theory-based kinematic models, stimulus-response models, and cruise control models to data-driven Behavior Cloning (BC) and Imitation Learning (IL) and outlined their strengths and limitations. This review categorizes CF models that are conceptualized in varying principles and s
    
[^8]: 训练神经网络语音分离模型的数据采样策略研究

    On Data Sampling Strategies for Training Neural Network Speech Separation Models. (arXiv:2304.07142v1 [cs.SD])

    [http://arxiv.org/abs/2304.07142](http://arxiv.org/abs/2304.07142)

    本文研究了训练神经网络语音分离模型的数据采样策略对模型性能的影响。研究表明，对于特定的信号长度分布，采用特定的训练信号长度限制可以获得更好的性能。

    

    语音分离仍然是多说话信号处理的重要领域。深度神经网络（DNN）模型在许多语音分离基准上取得了最佳性能。一些模型需要较长的训练时间和较高的内存需求。以前的研究提出了缩短训练示例以解决这些问题，但这对模型性能的影响尚不清楚。本文分析了应用这些训练信号长度（TSL）限制对两个语音分离模型（SepFormer，一个变换器模型，和Conv-TasNet，一个卷积模型）的影响。使用WJS0-2Mix，WHAMR和Libri2Mix数据集来分析信号长度分布及其对训练效率的影响。研究表明，对于特定的分布，应用特定的TSL限制可以获得更好的性能。这主要是由于对波形起始索引进行随机采样导致更多独特的示例用于训练。

    Speech separation remains an important area of multi-speaker signal processing. Deep neural network (DNN) models have attained the best performance on many speech separation benchmarks. Some of these models can take significant time to train and have high memory requirements. Previous work has proposed shortening training examples to address these issues but the impact of this on model performance is not yet well understood. In this work, the impact of applying these training signal length (TSL) limits is analysed for two speech separation models: SepFormer, a transformer model, and Conv-TasNet, a convolutional model. The WJS0-2Mix, WHAMR and Libri2Mix datasets are analysed in terms of signal length distribution and its impact on training efficiency. It is demonstrated that, for specific distributions, applying specific TSL limits results in better performance. This is shown to be mainly due to randomly sampling the start index of the waveforms resulting in more unique examples for tra
    
[^9]: TUM-FA\c{C}ADE：用于表面分割的点云基准的评估和增强

    TUM-FA\c{C}ADE: Reviewing and enriching point cloud benchmarks for fa\c{c}ade segmentation. (arXiv:2304.07140v1 [cs.CV])

    [http://arxiv.org/abs/2304.07140](http://arxiv.org/abs/2304.07140)

    本文介绍了一种用于增强现有点云数据集的方法，以便进行表面分割测试，并利用该方法创建了TUM-FA\c{C}ADE数据集。这个数据集可以促进基于点云的表面分割任务的开发，并且该方法也可以用于其他基准类型，创建更多样化的评估数据集。

    

    点云数据被广泛认为是城市制图最佳数据类型之一。因此，点云数据集通常被用于各种城市解释方法的基准类型。然而，很少有研究者探究使用点云基准来进行表面分割。稳健的表面分割已经成为各种应用的关键因素，范围从模拟自动驾驶功能到文化遗产保护。在本文中，我们提出了一种丰富现有点云数据集的方法，其中新增了面相关类别，以便于进行表面分割测试。我们提出了如何高效地扩展现有数据集，并全面评估它们在表面分割方面的潜力。我们使用该方法创建了TUM-FA\c{C}ADE数据集，用于扩展TUM-MLS-2016的功能。TUM-FA\c{C}ADE不仅可以促进基于点云的表面分割任务的开发，而且我们丰富点云数据集的方法也可以应用于其他基准类型，为城市解释方法创建更多样化的评估数据集。

    Point clouds are widely regarded as one of the best dataset types for urban mapping purposes. Hence, point cloud datasets are commonly investigated as benchmark types for various urban interpretation methods. Yet, few researchers have addressed the use of point cloud benchmarks for fa\c{c}ade segmentation. Robust fa\c{c}ade segmentation is becoming a key factor in various applications ranging from simulating autonomous driving functions to preserving cultural heritage. In this work, we present a method of enriching existing point cloud datasets with fa\c{c}ade-related classes that have been designed to facilitate fa\c{c}ade segmentation testing. We propose how to efficiently extend existing datasets and comprehensively assess their potential for fa\c{c}ade segmentation. We use the method to create the TUM-FA\c{C}ADE dataset, which extends the capabilities of TUM-MLS-2016. Not only can TUM-FA\c{C}ADE facilitate the development of point-cloud-based fa\c{c}ade segmentation tasks, but our 
    
[^10]: HLTPR@RWTH在DSTC9和DSTC10中的任务导向型文档对话系统

    Task-oriented Document-Grounded Dialog Systems by HLTPR@RWTH for DSTC9 and DSTC10. (arXiv:2304.07101v1 [cs.CL])

    [http://arxiv.org/abs/2304.07101](http://arxiv.org/abs/2304.07101)

    本论文总结了HLTPR@RWTH团队在DSTC9和DSTC10中为任务导向型文档对话系统所做的贡献，包括提出了不同的方法来使选择任务更有效率，在DSTC10中提出了数据增强技术来提高模型的鲁棒性并适应生成回答的风格，以及提出了一个嘈杂的通道模型来直接建模语音识别错误。实验结果表明，该团队的方法显著优于基线模型。

    

    本文总结了我们在第9和第10次Dialog System Technology Challenges（DSTC9和DSTC10）中为对话基于文档的任务作出的贡献。在两次迭代中，任务由三个子任务组成：首先检测当前回合是否需要知识，其次选择相关的知识文档，第三生成基于所选文档的回答。对于DSTC9，我们提出了不同的方法来使选择任务更有效率。其中最好的方法——分层选择，实际上比原始基线改进了结果，并提高了24倍速度。在DSTC10迭代中，挑战是要使经过书面对话训练的系统能够在嘈杂的自动语音识别转录中表现良好。因此，我们提出了数据增强技术来提高模型的鲁棒性，以及适应生成回答的风格，使其与前期对话相匹配的方法。此外，我们提出了一个嘈杂的通道模型来直接建模语音识别错误。实验结果表明，我们的方法在所有子任务上显著优于基线模型。

    This paper summarizes our contributions to the document-grounded dialog tasks at the 9th and 10th Dialog System Technology Challenges (DSTC9 and DSTC10). In both iterations the task consists of three subtasks: first detect whether the current turn is knowledge seeking, second select a relevant knowledge document, and third generate a response grounded on the selected document. For DSTC9 we proposed different approaches to make the selection task more efficient. The best method, Hierarchical Selection, actually improves the results compared to the original baseline and gives a speedup of 24x. In the DSTC10 iteration of the task, the challenge was to adapt systems trained on written dialogs to perform well on noisy automatic speech recognition transcripts. Therefore, we proposed data augmentation techniques to increase the robustness of the models as well as methods to adapt the style of generated responses to fit well into the proceeding dialog. Additionally, we proposed a noisy channel
    
[^11]: 物体为中心的表征、引导注意力和外部记忆对于推广视觉关系的作用。

    The role of object-centric representations, guided attention, and external memory on generalizing visual relations. (arXiv:2304.07091v1 [cs.CV])

    [http://arxiv.org/abs/2304.07091](http://arxiv.org/abs/2304.07091)

    研究对几种DNN进行了系统评估，发现DNN尚无法很好地在特定类型的图像中推广抽象的视觉关系，因此抽象的视觉推理仍然是DNN无法解决的挑战。

    

    视觉推理是视觉研究的长期目标。在过去的十年中，有几项工作试图将深度神经网络（DNNs）应用于从图像学习视觉关系的任务，但在学习关系的推广方面效果不佳。最近，为了使DNN能够从图像中学习抽象的关系，出现了几种创新的DNN机制。在本文中，我们系统地评估了一系列DNN，其中包括诸如插槽注意力、循环引导注意力和外部记忆等机制，用于最简单的视觉推理任务：决定两个物体是否相同或不同。我们发现，尽管某些模型在将相同-不同关系推广到特定类型的图像方面表现更好，但没有模型能够在全面范围内推广此关系。我们得出结论，抽象的视觉推理仍然是DNN的一个尚未解决的挑战。

    Visual reasoning is a long-term goal of vision research. In the last decade, several works have attempted to apply deep neural networks (DNNs) to the task of learning visual relations from images, with modest results in terms of the generalization of the relations learned. In recent years, several innovations in DNNs have been developed in order to enable learning abstract relation from images. In this work, we systematically evaluate a series of DNNs that integrate mechanism such as slot attention, recurrently guided attention, and external memory, in the simplest possible visual reasoning task: deciding whether two objects are the same or different. We found that, although some models performed better than others in generalizing the same-different relation to specific types of images, no model was able to generalize this relation across the board. We conclude that abstract visual reasoning remains largely an unresolved challenge for DNNs.
    
[^12]: 基于对比学习的历史地图和最新影像可靠建筑物轮廓变化提取

    BCE-Net: Reliable Building Footprints Change Extraction based on Historical Map and Up-to-Date Images using Contrastive Learning. (arXiv:2304.07076v1 [cs.CV])

    [http://arxiv.org/abs/2304.07076](http://arxiv.org/abs/2304.07076)

    本研究通过对比学习方法，将历史地图和最新卫星影像中建筑物轮廓进行对比，将建筑物语义信息融入变化检测流程，提高建筑物与非建筑物特征的可分辨性。

    

    针对城市环境快速发展和建筑物数据库需求的紧迫性，本文提出了一种对比学习方法，通过对比历史地图和单一最新卫星影像建筑物轮廓，将建筑物语义信息融入变化检测流程，从而提高建筑物与非建筑物特征的可分辨性。

    Automatic and periodic recompiling of building databases with up-to-date high-resolution images has become a critical requirement for rapidly developing urban environments. However, the architecture of most existing approaches for change extraction attempts to learn features related to changes but ignores objectives related to buildings. This inevitably leads to the generation of significant pseudo-changes, due to factors such as seasonal changes in images and the inclination of building fa\c{c}ades. To alleviate the above-mentioned problems, we developed a contrastive learning approach by validating historical building footprints against single up-to-date remotely sensed images. This contrastive learning strategy allowed us to inject the semantics of buildings into a pipeline for the detection of changes, which is achieved by increasing the distinguishability of features of buildings from those of non-buildings. In addition, to reduce the effects of inconsistencies between historical 
    
[^13]: CornerFormer: 提升角点表征以进行精细结构重建

    CornerFormer: Boosting Corner Representation for Fine-Grained Structured Reconstruction. (arXiv:2304.07072v1 [cs.CV])

    [http://arxiv.org/abs/2304.07072](http://arxiv.org/abs/2304.07072)

    CornerFormer是一种新的方法，它利用不同建模策略于单个模型中融合角点检测和边缘预测来提升精细结构重建的表现，并在挑战性的基准测试中取得了最好的结果。

    

    结构化重建是一种非平凡的密集预测问题，它从栅格图像中提取结构信息（例如，建筑角点和边缘），然后相应地重建为二维平面图。与常见的分割或检测问题相比，它显著依赖于利用整体几何信息进行结构推理的能力。目前，基于transformer的方法采用两阶段方式解决这个具有挑战性的问题，在第一个模型中检测角点，并在第二个模型中分类拟议边缘（角对）。然而，它们将两个阶段分开成不同的模型，并且只共享主干编码器。与现有的建模策略不同，我们提出了增强的角点表示方法：1）通过在不同的粒度中共享特征，它在角点检测和边缘预测之间融合知识；2）角点候选者根据其方向作为四个热图通道提出。定性和定量评估均表明，我们的CornerFormer明显优于以前的transformer-based模型，在具有挑战性的基准测试中取得了最先进的结果。

    Structured reconstruction is a non-trivial dense prediction problem, which extracts structural information (\eg, building corners and edges) from a raster image, then reconstructs it to a 2D planar graph accordingly. Compared with common segmentation or detection problems, it significantly relays on the capability that leveraging holistic geometric information for structural reasoning. Current transformer-based approaches tackle this challenging problem in a two-stage manner, which detect corners in the first model and classify the proposed edges (corner-pairs) in the second model. However, they separate two-stage into different models and only share the backbone encoder. Unlike the existing modeling strategies, we present an enhanced corner representation method: 1) It fuses knowledge between the corner detection and edge prediction by sharing feature in different granularity; 2) Corner candidates are proposed in four heatmap channels w.r.t its direction. Both qualitative and quantita
    
[^14]: SEA: 一个可扩展实体对齐系统

    SEA: A Scalable Entity Alignment System. (arXiv:2304.07065v1 [cs.CL])

    [http://arxiv.org/abs/2304.07065](http://arxiv.org/abs/2304.07065)

    提出了一个可扩展的实体对齐系统SEA，它包括了六个最先进的EA模型并能够使用户轻松建立、评估自己的模型，提高了基于GNN的EA模型在实际应用中的可用性和效率。

    

    实体对齐旨在在不同知识图谱中找到相应的实体。现有的实体对齐方法通常使用图神经网络来编码实体。然而，大多数方法都是在全批量模式下训练模型和评估结果，这使得实体对齐在大规模数据集上无法扩展。为了增强基于图神经网络的实体对齐模型在实际应用中的可用性，我们提出了一个可扩展的实体对齐系统SEA。它能够(i)训练大规模的图神经网络用于实体对齐，(ii)加速归一化和评估过程，(iii)为用户提供清晰的结果以估计不同的模型和参数设置。SEA只需要一个图形卡就可以运行。此外，SEA包括六个最先进的实体对齐模型，并为用户提供快速建立和评估自己模型的方法。因此，SEA允许用户在不涉及复杂实现的情况下执行实体对齐，如负抽样和GPU加速。

    Entity alignment (EA) aims to find equivalent entities in different knowledge graphs (KGs). State-of-the-art EA approaches generally use Graph Neural Networks (GNNs) to encode entities. However, most of them train the models and evaluate the results in a fullbatch fashion, which prohibits EA from being scalable on largescale datasets. To enhance the usability of GNN-based EA models in real-world applications, we present SEA, a scalable entity alignment system that enables to (i) train large-scale GNNs for EA, (ii) speed up the normalization and the evaluation process, and (iii) report clear results for users to estimate different models and parameter settings. SEA can be run on a computer with merely one graphic card. Moreover, SEA encompasses six state-of-the-art EA models and provides access for users to quickly establish and evaluate their own models. Thus, SEA allows users to perform EA without being involved in tedious implementations, such as negative sampling and GPU-accelerated
    
[^15]: 关于知识图谱中存在性一阶查询推理的研究

    On Existential First Order Queries Inference on Knowledge Graphs. (arXiv:2304.07063v1 [cs.AI])

    [http://arxiv.org/abs/2304.07063](http://arxiv.org/abs/2304.07063)

    本文阐述了关于知识图谱中存在性一阶查询推理的新方法，提出了一个新数据集，并开发了一种来自模糊逻辑理论的新搜索算法，该算法能够解决新公式，并在现有公式中超过以前的方法。

    

    知识图谱推理是一项具有挑战性的任务，因为它利用观察到的信息来预测缺失的信息。特别地，回答一阶逻辑公式是特别感兴趣的，因为它具有清晰的语法和语义。最近，提出了查询嵌入方法，该方法学习了一组实体的嵌入，并将逻辑运算视为集合运算。尽管有很多研究遵循相同的方法，但它缺乏从逻辑角度进行系统检查的方法。在本文中，我们描述了先前研究调查的查询范围，并准确地确定了它与整个存在性公式家族之间的差距。此外，我们还开发了一个包含十个新公式的新数据集，并讨论了同时出现的新挑战。最后，我们提出了一种来自模糊逻辑理论的新搜索算法，该算法能够解决新公式，并在现有公式中超过以前的方法。

    Reasoning on knowledge graphs is a challenging task because it utilizes observed information to predict the missing one. Specifically, answering first-order logic formulas is of particular interest because of its clear syntax and semantics. Recently, the query embedding method has been proposed which learns the embedding of a set of entities and treats logic operations as set operations. Though there has been much research following the same methodology, it lacks a systematic inspection from the standpoint of logic. In this paper, we characterize the scope of queries investigated previously and precisely identify the gap between it and the whole family of existential formulas. Moreover, we develop a new dataset containing ten new formulas and discuss the new challenges coming simultaneously. Finally, we propose a new search algorithm from fuzzy logic theory which is capable of solving new formulas and outperforming the previous methods in existing formulas.
    
[^16]: DroidBot-GPT：基于GPT的Android UI自动化

    DroidBot-GPT: GPT-powered UI Automation for Android. (arXiv:2304.07061v1 [cs.SE])

    [http://arxiv.org/abs/2304.07061](http://arxiv.org/abs/2304.07061)

    DroidBot-GPT是一款利用GPT模型自动化Android应用程序的工具，可以根据任务的自然语言描述自动生成并执行操作，有望提高移动应用程序的测试和开发效率。

    

    本文介绍了DroidBot-GPT，这是一种利用类似GPT的大型语言模型（LLM）自动化与Android移动应用程序交互的工具。给定所需任务的自然语言描述，DroidBot-GPT可以自动生成并执行操作，导航应用程序以完成任务。它通过将应用程序GUI状态信息和智能手机屏幕上可用的操作转换为自然语言提示，并要求LLM选择动作来实现。由于LLM通常受过大量数据的训练，包括各种软件应用程序的操作指南，因此它具有根据提供的信息作出合理动作选择的能力。我们使用了一个自创建的数据集对DroidBot-GPT进行评估，该数据集包含来自10个类别的17个Android应用程序的33个任务。它可以成功完成39.39%的任务，并且平均部分完成进度约为66.76%。鉴于我们的方法是完全自动的，并且用于训练LLM的数据是广泛可用的，我们认为DroidBot-GPT在改善移动应用程序的测试和开发效率方面具有巨大潜力。

    This paper introduces DroidBot-GPT, a tool that utilizes GPT-like large language models (LLMs) to automate the interactions with Android mobile applications. Given a natural language description of a desired task, DroidBot-GPT can automatically generate and execute actions that navigate the app to complete the task. It works by translating the app GUI state information and the available actions on the smartphone screen to natural language prompts and asking the LLM to make a choice of actions. Since the LLM is typically trained on a large amount of data including the how-to manuals of diverse software applications, it has the ability to make reasonable choices of actions based on the provided information. We evaluate DroidBot-GPT with a self-created dataset that contains 33 tasks collected from 17 Android applications spanning 10 categories. It can successfully complete 39.39% of the tasks, and the average partial completion progress is about 66.76%. Given the fact that our method is f
    
[^17]: 面部视频压缩的感知质量评估：基准和有效方法

    Perceptual Quality Assessment of Face Video Compression: A Benchmark and An Effective Method. (arXiv:2304.07056v1 [eess.IV])

    [http://arxiv.org/abs/2304.07056](http://arxiv.org/abs/2304.07056)

    本文介绍了大规模压缩面部视频质量评估（CFVQA）数据库，用于系统地了解面部视频感知质量和多样化压缩失真。生成式编码方法被确定为具有合理的感知码率失真折衷的有前途的替代方法，利用面部视频的统计先验知识。

    

    近年来，对面部视频压缩的需求呈指数级增长，人工智能的成功使得超出了传统的混合视频编码范围。生成式编码方法被确定为具有合理的感知码率失真折衷的有前途的替代方法，利用面部视频的统计先验知识。然而，空间和时间域中扭曲类型的极大多样性，从传统的混合编码框架到生成模型，给压缩面部视频质量评估（VQA）带来了巨大挑战。在本文中，我们介绍了大规模压缩面部视频质量评估（CFVQA）数据库，这是系统地了解面部视频感知质量和多样化压缩失真的第一次尝试。该数据库包含 3,240 个压缩的面部视频片段，涵盖多个压缩级别，这些片段来自 135 个源视频，具有多样性。

    Recent years have witnessed an exponential increase in the demand for face video compression, and the success of artificial intelligence has expanded the boundaries beyond traditional hybrid video coding. Generative coding approaches have been identified as promising alternatives with reasonable perceptual rate-distortion trade-offs, leveraging the statistical priors of face videos. However, the great diversity of distortion types in spatial and temporal domains, ranging from the traditional hybrid coding frameworks to generative models, present grand challenges in compressed face video quality assessment (VQA). In this paper, we introduce the large-scale Compressed Face Video Quality Assessment (CFVQA) database, which is the first attempt to systematically understand the perceptual quality and diversified compression distortions in face videos. The database contains 3,240 compressed face video clips in multiple compression levels, which are derived from 135 source videos with diversif
    
[^18]: 第二届单目深度估计挑战赛

    The Second Monocular Depth Estimation Challenge. (arXiv:2304.07051v1 [cs.CV])

    [http://arxiv.org/abs/2304.07051](http://arxiv.org/abs/2304.07051)

    本文介绍了单目深度估计挑战赛的第二届比赛结果，高质量的SYNS-Patches数据集提高了比赛难度，所有提交作品都超过了基准水平。

    

    本文介绍了单目深度估计挑战赛（MDEC）的第二届比赛结果。本次比赛接受任何形式方式的监督，包括全监督、自监督、多任务或代理深度。比赛的数据集基于SYNS-Patches，其中包含高质量的密集真实数据，并具有广泛的环境多样性。比赛收到了8个独特的提交作品，所有基于点云或基于图像的指标表现都超过了基准水平。最佳监督提交作品的相对F-分数提高了27.62％，而最佳自监督提交作品提高了16.61％，这些结果代表了真正的进步。

    This paper discusses the results for the second edition of the Monocular Depth Estimation Challenge (MDEC). This edition was open to methods using any form of supervision, including fully-supervised, self-supervised, multi-task or proxy depth. The challenge was based around the SYNS-Patches dataset, which features a wide diversity of environments with high-quality dense ground-truth. This includes complex natural environments, e.g. forests or fields, which are greatly underrepresented in current benchmarks.  The challenge received eight unique submissions that outperformed the provided SotA baseline on any of the pointcloud- or image-based metrics. The top supervised submission improved relative F-Score by 27.62%, while the top self-supervised improved it by 16.61%. Supervised submissions generally leveraged large collections of datasets to improve data diversity. Self-supervised submissions instead updated the network architecture and pretrained backbones. These results represent a si
    
[^19]: 大规模射电干涉数据的有损压缩

    Lossy Compression of Large-Scale Radio Interferometric Data. (arXiv:2304.07050v1 [astro-ph.IM])

    [http://arxiv.org/abs/2304.07050](http://arxiv.org/abs/2304.07050)

    本文提出了一种通过基线相关的有损压缩技术来降低射电干涉可见度数据体积的方法，将整个可见度数据表示为基线的数据矩阵集合，从而实现数据的压缩，同时保留视场边缘的模糊效应。

    

    本文提出使用一种基线相关的有损压缩技术来减少可见度数据的体积，同时保留视场边缘的模糊效果。我们利用矩阵秩和低秩近似描述原始可见度数据的基本分量和具体的天空分布矩阵。因此，整个可见度数据被表示为基线的数据矩阵集合，而不是单个张量。我们提出了两种压缩算法，分别是简单的$SVD$和命名为$BDSVD$的算法。

    This work proposes to reduce visibility data volume using a baseline-dependent lossy compression technique that preserves smearing at the edges of the field-of-view. We exploit the relation of the rank of a matrix and the fact that a low-rank approximation can describe the raw visibility data as a sum of basic components where each basic component corresponds to a specific Fourier component of the sky distribution. As such, the entire visibility data is represented as a collection of data matrices from baselines, instead of a single tensor. The proposed methods are formulated as follows: provided a large dataset of the entire visibility data; the first algorithm, named $simple~SVD$ projects the data into a regular sampling space of rank$-r$ data matrices. In this space, the data for all the baselines has the same rank, which makes the compression factor equal across all baselines. The second algorithm, named $BDSVD$ projects the data into an irregular sampling space of rank$-r_{pq}$ da
    
[^20]: FairRec：用于深度推荐系统的公平性测试。

    FairRec: Fairness Testing for Deep Recommender Systems. (arXiv:2304.07030v1 [cs.AI])

    [http://arxiv.org/abs/2304.07030](http://arxiv.org/abs/2304.07030)

    本文提出了一种名为FairRec的统一框架，支持对深度推荐系统进行公平性测试。同时，提供了一组新的公平性概念针对推荐系统的特征，可以有效地发现DRS中独特的公平性问题。

    

    基于深度学习的推荐系统（DRS）在工业界的部署越来越广泛，为人们的日常生活带来了显著的便利，但同时也存在多重问题，例如“回声室”和“马修效应”，其中“公平性”的概念起着核心作用。然而，尽管已经为传统的深度分类模型开发了许多公平性概念和相应的公平性测试方法，但它们对于DRS来说几乎无法应用。主要困难在于目前仍缺乏对现有公平性概念与深度推荐系统的多元化测试要求之间的系统理解和映射，更不用说进一步的测试或调试活动。为了解决这个问题，我们提出了FairRec，一个统一的框架，支持从多个自定义角度对DRS进行公平性测试，例如模型效用、项目多样性、项目受欢迎程度等。我们还提供了一组新的公平性概念，针对DRS具体特征，可以有效地发现推荐系统独特的公平性问题。在真实世界数据集上的实验表明，我们的方法在检测和减轻DRS中各种类型的公平性问题方面具有有效性和效率。

    Deep learning-based recommender systems (DRSs) are increasingly and widely deployed in the industry, which brings significant convenience to people's daily life in different ways. However, recommender systems are also shown to suffer from multiple issues,e.g., the echo chamber and the Matthew effect, of which the notation of "fairness" plays a core role.While many fairness notations and corresponding fairness testing approaches have been developed for traditional deep classification models, they are essentially hardly applicable to DRSs. One major difficulty is that there still lacks a systematic understanding and mapping between the existing fairness notations and the diverse testing requirements for deep recommender systems, not to mention further testing or debugging activities. To address the gap, we propose FairRec, a unified framework that supports fairness testing of DRSs from multiple customized perspectives, e.g., model utility, item diversity, item popularity, etc. We also pr
    
[^21]: SimpLex：一种词汇文本简化架构

    SimpLex: a lexical text simplification architecture. (arXiv:2304.07002v1 [cs.CL])

    [http://arxiv.org/abs/2304.07002](http://arxiv.org/abs/2304.07002)

    SimpLex是一种用于生成简化英文句子的新型简化架构，它使用词嵌入或句子转换器来生成简化句子并集成到易用的软件中。实验结果中发现，变压器模型在SARI得分方面表现优异，而基于词嵌入的模型则在困惑度方面表现更好。

    

    文本简化是将给定句子或文本生成易于理解的句子的过程。简化的目的是在不损失含义或细微差别的情况下减少给定文本或句子的词汇和语法复杂性。在本文中，我们介绍了SimpLex，一种用于生成简化英文句子的新型简化架构。为了生成简化句子，所提出的架构使用词嵌入（即Word2Vec）和困惑度或句子转换器（即BERT、RoBERTa和GPT2）和余弦相似度之一。该解决方案集成到一个用户友好的、易于使用的软件中。我们使用两个指标（即SARI和困惑度降低）评估了我们的系统。从实验角度来看，我们观察到变压器模型在SARI得分方面优于其他模型。然而，从困惑度方面来看，基于词嵌入的模型表现更好。

    Text simplification (TS) is the process of generating easy-to-understand sentences from a given sentence or piece of text. The aim of TS is to reduce both the lexical (which refers to vocabulary complexity and meaning) and syntactic (which refers to the sentence structure) complexity of a given text or sentence without the loss of meaning or nuance. In this paper, we present \textsc{SimpLex}, a novel simplification architecture for generating simplified English sentences. To generate a simplified sentence, the proposed architecture uses either word embeddings (i.e., Word2Vec) and perplexity, or sentence transformers (i.e., BERT, RoBERTa, and GPT2) and cosine similarity. The solution is incorporated into a user-friendly and simple-to-use software. We evaluate our system using two metrics, i.e., SARI, and Perplexity Decrease. Experimentally, we observe that the transformer models outperform the other models in terms of the SARI score. However, in terms of Perplexity, the Word-Embeddings-
    
[^22]: H2TNE：时态异构信息网络在双曲空间中的嵌入

    H2TNE: Temporal Heterogeneous Information Network Embedding in Hyperbolic Spaces. (arXiv:2304.06970v1 [cs.SI])

    [http://arxiv.org/abs/2304.06970](http://arxiv.org/abs/2304.06970)

    该论文提出了 H2TNE 模型，用于将时态异构信息网络嵌入到双曲空间中。通过时间和异质性双重约束的随机游走策略，该模型能够捕捉结构与语义信息。

    

    时间异构信息网络（temporal HIN）嵌入，旨在将不同时间戳的各种类型节点表示为低维空间，并同时保留结构和语义信息，在各种实际任务中至关重要。研究人员在欧几里得空间中进行了许多关于时间HIN嵌入的努力，并取得了一些可观的成果。然而，在现实世界中，许多网络都显示出分层属性和幂律分布，并不是欧几里得空间的等距的。最近，双曲空间中的表示学习已被证明对具有分层和幂律结构的数据是有效的。受这个特性的启发，我们提出了一个双曲异构时间网络嵌入（H2TNE）模型，用于时态HIN。具体而言，我们利用一个时间和异质性双重约束的随机游走策略来捕捉结构和语义信息，然后计算

    Temporal heterogeneous information network (temporal HIN) embedding, aiming to represent various types of nodes of different timestamps into low dimensional spaces while preserving structural and semantic information, is of vital importance in diverse real-life tasks. Researchers have made great efforts on temporal HIN embedding in Euclidean spaces and got some considerable achievements. However, there is always a fundamental conflict that many real-world networks show hierarchical property and power-law distribution, and are not isometric of Euclidean spaces. Recently, representation learning in hyperbolic spaces has been proved to be valid for data with hierarchical and power-law structure. Inspired by this character, we propose a hyperbolic heterogeneous temporal network embedding (H2TNE) model for temporal HINs. Specifically, we leverage a temporally and heterogeneously double-constrained random walk strategy to capture the structural and semantic information, and then calculate th
    
[^23]: 基于自监督学习的单目图像深度估计

    Self-Supervised Learning based Depth Estimation from Monocular Images. (arXiv:2304.06966v1 [cs.CV])

    [http://arxiv.org/abs/2304.06966](http://arxiv.org/abs/2304.06966)

    本论文研究了基于自监督学习的单目图像深度估计，探索了多种扩展深度估计模型的方法，并计划实现姿态估计和语义分割等技术来提供更准确的深度图预测。

    

    深度估计在计算机视觉中有广泛的应用，如目标跟踪、增强现实和自动驾驶汽车。单目深度估计的目标是预测深度图，给定一个二维单目 RGB 图像作为输入。传统的深度估计方法基于深度线索，使用了诸如极线几何等概念。随着卷积神经网络的发展，深度估计已经取得了巨大的进展。在这个项目中，我们的目标是探索可能的深度估计模型的扩展，以及是否可以进一步提高性能度量。在更广泛的意义上，我们正在考虑实现姿态估计、高效亚像素卷积插值、语义分割估计技术，以进一步增强我们的提出的架构，并提供细粒度和更全局一致的深度图预测。我们还计划放弃相机内参数，并调查基于自监督学习的深度估计，其中训练数据是从单目 RGB 图像自动生成的，无需地面真实深度图。

    Depth Estimation has wide reaching applications in the field of Computer vision such as target tracking, augmented reality, and self-driving cars. The goal of Monocular Depth Estimation is to predict the depth map, given a 2D monocular RGB image as input. The traditional depth estimation methods are based on depth cues and used concepts like epipolar geometry. With the evolution of Convolutional Neural Networks, depth estimation has undergone tremendous strides. In this project, our aim is to explore possible extensions to existing SoTA Deep Learning based Depth Estimation Models and to see whether performance metrics could be further improved. In a broader sense, we are looking at the possibility of implementing Pose Estimation, Efficient Sub-Pixel Convolution Interpolation, Semantic Segmentation Estimation techniques to further enhance our proposed architecture and to provide fine-grained and more globally coherent depth map predictions. We also plan to do away with camera intrinsic 
    
[^24]: 用于零样本常识推理的提示工程和校准

    Prompt Engineering and Calibration for Zero-Shot Commonsense Reasoning. (arXiv:2304.06962v1 [cs.CL])

    [http://arxiv.org/abs/2304.06962](http://arxiv.org/abs/2304.06962)

    本文研究并评估提示工程和校准策略对于小型语言模型在五个常识推理基准上的表现，发现每种策略倾向于某些模型，但联合效果为负。

    

    提示工程和校准使得大型语言模型在推理任务，包括多项选择常识推理中表现出色。从实际角度出发，我们在较小的语言模型上研究并评估了这些策略。通过对五个常识推理基准的实验，我们发现每种策略都倾向于某些模型，但它们的联合效果大多为负。

    Prompt engineering and calibration make large language models excel at reasoning tasks, including multiple choice commonsense reasoning. From a practical perspective, we investigate and evaluate these strategies on smaller language models. Through experiments on five commonsense reasoning benchmarks, we find that each strategy favors certain models, but their joint effects are mostly negative.
    
[^25]: AUTOSPARSE:实现神经网络自动稀疏训练的方法研究

    AUTOSPARSE: Towards Automated Sparse Training of Deep Neural Networks. (arXiv:2304.06941v1 [cs.LG])

    [http://arxiv.org/abs/2304.06941](http://arxiv.org/abs/2304.06941)

    本文提出了一种叫做AutoSparse的自动稀疏训练算法，其中包含梯度退火法来权衡稀疏和准确性，在ResNet50和MobileNetV1上表现出更好的准确性和较少的计算资源需求。

    

    稀疏训练是减少训练神经网络计算成本的一个有前途的途径。最近的研究提出了使用可学习阈值的修剪方法，以有效地探索模型中内在稀疏性的不均匀分布。本文提出了梯度退火法（GA），其中掩码权重的梯度按非线性方式缩小。 GA在不需要额外稀疏诱导正则化的情况下提供了一种优美的权衡稀疏性和准确性的方法。我们将GA与最新的可学习修剪方法相结合，创建了一种称为AutoSparse的自动稀疏训练算法，它在ImageNet-1K上的稀疏ResNet50和MobileNetV1上实现了更好的准确性和/或训练/推理FLOPS减少，例如AutoSparse在80％的稀疏下，ResNet50在ImageNet上实现了（2倍，7倍）的（训练，推理）FLOPS减少。最后，AutoSparse在创新性稀疏领域表现优异。

    Sparse training is emerging as a promising avenue for reducing the computational cost of training neural networks. Several recent studies have proposed pruning methods using learnable thresholds to efficiently explore the non-uniform distribution of sparsity inherent within the models. In this paper, we propose Gradient Annealing (GA), where gradients of masked weights are scaled down in a non-linear manner. GA provides an elegant trade-off between sparsity and accuracy without the need for additional sparsity-inducing regularization. We integrated GA with the latest learnable pruning methods to create an automated sparse training algorithm called AutoSparse, which achieves better accuracy and/or training/inference FLOPS reduction than existing learnable pruning methods for sparse ResNet50 and MobileNetV1 on ImageNet-1K: AutoSparse achieves (2x, 7x) reduction in (training,inference) FLOPS for ResNet50 on ImageNet at 80% sparsity. Finally, AutoSparse outperforms sparse-to-sparse SotA me
    
[^26]: CiPR:一种具有跨实例正关系的高效框架，用于广义类别发现.

    CiPR: An Efficient Framework with Cross-instance Positive Relations for Generalized Category Discovery. (arXiv:2304.06928v1 [cs.CV])

    [http://arxiv.org/abs/2304.06928](http://arxiv.org/abs/2304.06928)

    该论文提出了一个名为CiPR的框架，通过利用部分标记数据中的跨实例正关系进行对比学习，解决了广义类别发现(GCD)的问题。选择邻居聚类(SNC)算法在此过程中发挥了重要作用。

    

    本文解决了广义类别发现（GCD）的问题。GCD考虑了自动聚类部分标记数据集的开放世界问题，在该数据集中，未标记数据包含来自新类别和已标记类别的实例。本文解决了在未标记数据中没有已知类别数的GCD问题。我们提出了一个名为CiPR的框架，通过利用部分标记数据中被现有方法忽视的跨实例正关系进行对比学习来引导表示。为了获得可靠的跨实例关系以促进表示学习，我们首先引入了一种半监督的分层聚类算法，称为选择邻居聚类（SNC），它可以直接从由选择邻居构造的图中的连通分量中生成聚类层次结构。我们还扩展了SNC以便对具有给定类的未标记实例进行标签分配。

    We tackle the issue of generalized category discovery (GCD). GCD considers the open-world problem of automatically clustering a partially labelled dataset, in which the unlabelled data contain instances from novel categories and also the labelled classes. In this paper, we address the GCD problem without a known category number in the unlabelled data. We propose a framework, named CiPR, to bootstrap the representation by exploiting Cross-instance Positive Relations for contrastive learning in the partially labelled data which are neglected in existing methods. First, to obtain reliable cross-instance relations to facilitate the representation learning, we introduce a semi-supervised hierarchical clustering algorithm, named selective neighbor clustering (SNC), which can produce a clustering hierarchy directly from the connected components in the graph constructed by selective neighbors. We also extend SNC to be capable of label assignment for the unlabelled instances with the given clas
    
[^27]: YOLO-Drone: 高空即时检测密集小物体的无人机技术

    YOLO-Drone:Airborne real-time detection of dense small objects from high-altitude perspective. (arXiv:2304.06925v1 [cs.CV])

    [http://arxiv.org/abs/2304.06925](http://arxiv.org/abs/2304.06925)

    YOLO-Drone是一种能够高效检测小尺度物体的实时物体检测算法，并在无人机平台上得到了应用，以广义交集联盟(GIOU)作为损失函数，取得了最佳的检测效果。

    

    无人机远程感应目标探测技术已广泛应用于许多领域，并成为计算机视觉领域的主要研究方向。然而，由于物体大小、图像降噪和实时性等因素的挑战，小尺度物体的可靠检测一直是具有挑战性的。为解决这些问题，提出了一种实时物体检测算法(YOLO-Drone)，并将其应用于两种新的无人机平台以及一种特定的光源(硅基金LED)。YOLO-Drone提出了几个创新：1)包括一个新的骨干Darknet59；2)一个新的复杂特征聚合模块MSPP-FPN，它包括一个空间金字塔池化和三个扩张空间金字塔池化模块；3)使用广义交集联盟(Generalized Intersection over Union，GIOU)作为损失函数。为了评估性能，使用了两个基准数据集，结果表明YOLO-Drone在小物体检测方面实现了最优结果。

    Unmanned Aerial Vehicles (UAVs), specifically drones equipped with remote sensing object detection technology, have rapidly gained a broad spectrum of applications and emerged as one of the primary research focuses in the field of computer vision. Although UAV remote sensing systems have the ability to detect various objects, small-scale objects can be challenging to detect reliably due to factors such as object size, image degradation, and real-time limitations. To tackle these issues, a real-time object detection algorithm (YOLO-Drone) is proposed and applied to two new UAV platforms as well as a specific light source (silicon-based golden LED). YOLO-Drone presents several novelties: 1) including a new backbone Darknet59; 2) a new complex feature aggregation module MSPP-FPN that incorporated one spatial pyramid pooling and three atrous spatial pyramid pooling modules; 3) and the use of Generalized Intersection over Union (GIoU) as the loss function. To evaluate performance, two bench
    
[^28]: 基于采样的反应综合算法应用于非确定性混合系统

    Sampling-based Reactive Synthesis for Nondeterministic Hybrid Systems. (arXiv:2304.06876v1 [eess.SY])

    [http://arxiv.org/abs/2304.06876](http://arxiv.org/abs/2304.06876)

    本文提出了一种基于采样的策略综合算法，用于具有复杂连续动力学和时间和可达性约束的非确定性混合系统。算法基于在混合空间中生长（搜索）游戏树，以合成一种反应（鲁棒）策略，以满足目标并在可扩展性和效率方面优于最新技术水平。

    

    本文提出了一种基于采样的策略综合算法，用于具有复杂连续动力学和时间和可达性约束的非确定性混合系统。我们将混合系统的演化视为一个双人游戏，其中非确定性是一个对手玩家，其目标是阻止实现时间和可达性目标。旨在合成一种获胜策略——一种反应（鲁棒）策略，它保证在对手玩家的所有可能移动下满足目标。该方法基于在混合空间中生长（搜索）游戏树，通过将基于采样的规划方法与一种用于选择和改进部分策略的新型乘客舱机技术相结合。我们提供的条件下，算法是概率上完备的，即，如果存在获胜策略，该算法几乎肯定会找到它。案例研究和基准结果表明，该算法具有广泛的适用性，并在可扩展性和效率方面始终优于最新技术水平。

    This paper introduces a sampling-based strategy synthesis algorithm for nondeterministic hybrid systems with complex continuous dynamics under temporal and reachability constraints. We view the evolution of the hybrid system as a two-player game, where the nondeterminism is an adversarial player whose objective is to prevent achieving temporal and reachability goals. The aim is to synthesize a winning strategy -- a reactive (robust) strategy that guarantees the satisfaction of the goals under all possible moves of the adversarial player. The approach is based on growing a (search) game-tree in the hybrid space by combining a sampling-based planning method with a novel bandit-based technique to select and improve on partial strategies. We provide conditions under which the algorithm is probabilistically complete, i.e., if a winning strategy exists, the algorithm will almost surely find it. The case studies and benchmark results show that the algorithm is general and consistently outperf
    
[^29]: CAR-DESPOT: 针对混杂环境下的机器人的因果关系在线POMDP规划

    CAR-DESPOT: Causally-Informed Online POMDP Planning for Robots in Confounded Environments. (arXiv:2304.06848v1 [cs.RO])

    [http://arxiv.org/abs/2304.06848](http://arxiv.org/abs/2304.06848)

    本文提出了一种新的因果关系在线POMDP规划方法CAR-DESPOT，使用因果建模和推理来消除未测量混淆变量引起的错误，并在混杂环境中表现优异。

    

    在现实环境中工作的机器人必须考虑随机行为的可能结果，并根据真实的世界状态的部分观察进行决策。因果混淆的问题是进行准确和强健的行为预测的主要挑战。部分可观察的马尔可夫决策过程(POMDP)是一种广泛使用的框架，用于模拟这些随机和部分可观测的决策问题。然而，由于缺乏明确的因果语义，POMDP规划方法容易受到混淆偏差的影响，在未观察到混杂变量的情况下，可能会产生表现不佳的策略。本文提出了一种新的因果关系在线POMDP规划方法，使用因果建模和推理来消除未测量混淆变量引起的错误。我们进一步提出了一种从观测数据中学习因果模型的方法，以在我们的方法中使用。实验结果表明，我们的方法CAR-DESPOT在混杂环境中比现有的最先进的POMDP规划程序表现显著更好。

    Robots operating in real-world environments must reason about possible outcomes of stochastic actions and make decisions based on partial observations of the true world state. A major challenge for making accurate and robust action predictions is the problem of confounding, which if left untreated can lead to prediction errors. The partially observable Markov decision process (POMDP) is a widely-used framework to model these stochastic and partially-observable decision-making problems. However, due to a lack of explicit causal semantics, POMDP planning methods are prone to confounding bias and thus in the presence of unobserved confounders may produce underperforming policies. This paper presents a novel causally-informed extension of "anytime regularized determinized sparse partially observable tree" (AR-DESPOT), a modern anytime online POMDP planner, using causal modelling and inference to eliminate errors caused by unmeasured confounder variables. We further propose a method to lear
    
[^30]: 多任务深度神经网络的结构化剪枝

    Structured Pruning for Multi-Task Deep Neural Networks. (arXiv:2304.06840v1 [cs.LG])

    [http://arxiv.org/abs/2304.06840](http://arxiv.org/abs/2304.06840)

    本研究探索了在多任务模型上应用结构化剪枝的有效性，通过实验发现，在参数数量相似的情况下，来自不同剪枝方法的架构在任务性能上没有显着差异，迭代结构剪枝可能不是实现最优结构的最佳方法。

    

    虽然相对于单个单任务DNN模型，多任务深度神经网络模型具有计算和存储优势，但是它们可以通过模型压缩进一步优化。许多结构化剪枝方法已经被开发出来，可以轻松地实现单任务模型的加速，但是对于多任务网络的剪枝尚未得到广泛研究。在这项工作中，我们研究了结构化剪枝在多任务模型上的有效性。我们使用现有的单任务滤波器剪枝准则，并引入了一个基于MTL的滤波器剪枝准则来估计滤波器重要性分数。我们使用迭代剪枝策略使用两种剪枝方法来剪枝模型。我们展示了，在仔细的超参数调整下，当参数数量相似时，来自不同剪枝方法的架构在任务之间的性能上没有显着差异。我们还展示了迭代结构剪枝可能不是实现多任务网络最优结构的最佳方法。

    Although multi-task deep neural network (DNN) models have computation and storage benefits over individual single-task DNN models, they can be further optimized via model compression. Numerous structured pruning methods are already developed that can readily achieve speedups in single-task models, but the pruning of multi-task networks has not yet been extensively studied. In this work, we investigate the effectiveness of structured pruning on multi-task models. We use an existing single-task filter pruning criterion and also introduce an MTL-based filter pruning criterion for estimating the filter importance scores. We prune the model using an iterative pruning strategy with both pruning methods. We show that, with careful hyper-parameter tuning, architectures obtained from different pruning methods do not have significant differences in their performances across tasks when the number of parameters is similar. We also show that iterative structure pruning may not be the best way to ac
    
[^31]: 建模生物通路和组织学之间的稠密多模态交互以预测存活率

    Modeling Dense Multimodal Interactions Between Biological Pathways and Histology for Survival Prediction. (arXiv:2304.06819v1 [cs.CV])

    [http://arxiv.org/abs/2304.06819](http://arxiv.org/abs/2304.06819)

    本论文提出了一种解决整合全切片图像和批量转录组学预测患者生存率的多模态任务的方案，旨在解决标记化转录组学和捕获这两种模态之间的交互的问题。

    

    整合全切片图像（WSIs）和批量转录组学（bulk transcriptomics）以预测患者生存率可以提高我们对患者预后的理解。然而，由于这些数据的不同性质，这个多模态任务特别具有挑战性：WSIs代表肿瘤的高维空间描述，而批量转录组学则代表该肿瘤内的基因表达水平的全局描述。在这种情况下，我们的工作旨在解决两个关键问题：（1）如何以语义上有意义和可解释的方式对转录组学进行标记化？（2）如何捕捉这两种模态之间的密集多模态交互？具体来说，我们提出从转录组学中学习生物通路标记，以编码特定的细胞功能。结合编码WSI中不同形态模式的组织学块标记，我们认为它们构成了下游可解释性分析的适当推理单元。我们提出融合...

    Integrating whole-slide images (WSIs) and bulk transcriptomics for predicting patient survival can improve our understanding of patient prognosis. However, this multimodal task is particularly challenging due to the different nature of these data: WSIs represent a very high-dimensional spatial description of a tumor, while bulk transcriptomics represent a global description of gene expression levels within that tumor. In this context, our work aims to address two key challenges: (1) how can we tokenize transcriptomics in a semantically meaningful and interpretable way?, and (2) how can we capture dense multimodal interactions between these two modalities? Specifically, we propose to learn biological pathway tokens from transcriptomics that can encode specific cellular functions. Together with histology patch tokens that encode the different morphological patterns in the WSI, we argue that they form appropriate reasoning units for downstream interpretability analyses. We propose fusing 
    
[^32]: 模型特定视角下的统一外部分布检测

    Unified Out-Of-Distribution Detection: A Model-Specific Perspective. (arXiv:2304.06813v1 [cs.LG])

    [http://arxiv.org/abs/2304.06813](http://arxiv.org/abs/2304.06813)

    本文提出一种新颖的统一框架，用于将机器学习模型中的外部分布检测扩展到更广泛的范围，该框架旨在检测模型无法正确预测的测试示例，而不是特定的外部分布原因。

    

    外部分布检测旨在识别不属于训练分布并不可靠预测的测试样例。虽然已有大量相关工作，但其中大多数只关注来自语义转换（如未见过的类别）的OOD例子，而忽略了其他可能的原因（如协变量转换）。本文提出了一种新颖的统一框架，以更广泛的范围研究OOD检测。我们建议不是检测特定原因导致的OOD例子，而是检测已部署机器学习模型（例如图像分类器）无法正确预测的例子。也就是说，是否应该检测和拒绝测试例子是“模型特定”的。我们展示了该框架统一了由语义变化和协变量变化引起的OOD例子的检测，并密切关注将机器学习模型应用于不受控制的环境的问题。我们对该框架进行了广泛的分析和实验。

    Out-of-distribution (OOD) detection aims to identify test examples that do not belong to the training distribution and are thus unlikely to be predicted reliably. Despite a plethora of existing works, most of them focused only on the scenario where OOD examples come from semantic shift (e.g., unseen categories), ignoring other possible causes (e.g., covariate shift). In this paper, we present a novel, unifying framework to study OOD detection in a broader scope. Instead of detecting OOD examples from a particular cause, we propose to detect examples that a deployed machine learning model (e.g., an image classifier) is unable to predict correctly. That is, whether a test example should be detected and rejected or not is ``model-specific''. We show that this framework unifies the detection of OOD examples caused by semantic shift and covariate shift, and closely addresses the concern of applying a machine learning model to uncontrolled environments. We provide an extensive analysis that 
    
[^33]: 高维量子态工程的非线性光子晶体设计

    Designing Nonlinear Photonic Crystals for High-Dimensional Quantum State Engineering. (arXiv:2304.06810v1 [quant-ph])

    [http://arxiv.org/abs/2304.06810](http://arxiv.org/abs/2304.06810)

    该论文提出了一种通过设计非线性光子晶体和泵浦光束生成高维量子态的方法，同时基于所提出的物理约束和可微分的方法，理论和实验上演示了如何生成最大纠缠态。这为控制任意量子态提供了新途径，并在全光学相干控制成为可能。

    

    我们提出了一种新颖、受物理约束和可微分的方法，通过量子光学中的自发参量下转换 (SPDC)，生成 D 维 qudit 状态。我们规避了物理过程固有的随机性所带来的任何限制，并并入了一组随机动力学方程，控制其在 SPDC 哈密顿下的演化。我们通过设计结构化的非线性光子晶体 (NLPCs) 和形状化的泵浦光束，展示了我们模型的有效性；理论上和实验上展示了如何在空间自由度中生成最大纠缠态。学习 NLPC 结构为塑造和控制任意量子态提供了有前途的新途径，并且使得生成态的全光学相干控制成为可能。我们相信这种方法可以很容易地从庞大的晶体扩展到薄型元表面，并且可能应用于其他共享类似哈密顿量的量子系统。

    We propose a novel, physically-constrained and differentiable approach for the generation of D-dimensional qudit states via spontaneous parametric down-conversion (SPDC) in quantum optics. We circumvent any limitations imposed by the inherently stochastic nature of the physical process and incorporate a set of stochastic dynamical equations governing its evolution under the SPDC Hamiltonian. We demonstrate the effectiveness of our model through the design of structured nonlinear photonic crystals (NLPCs) and shaped pump beams; and show, theoretically and experimentally, how to generate maximally entangled states in the spatial degree of freedom. The learning of NLPC structures offers a promising new avenue for shaping and controlling arbitrary quantum states and enables all-optical coherent control of the generated states. We believe that this approach can readily be extended from bulky crystals to thin Metasurfaces and potentially applied to other quantum systems sharing a similar Ham
    
[^34]: 论基础模型在地理空间AI中的机遇与挑战

    On the Opportunities and Challenges of Foundation Models for Geospatial Artificial Intelligence. (arXiv:2304.06798v1 [cs.AI])

    [http://arxiv.org/abs/2304.06798](http://arxiv.org/abs/2304.06798)

    本文研究了在地理空间AI中开发基础模型的机遇和挑战，测试了多种FMs在地理子领域中的表现，发现在文本任务上的表现优于任务特定的定制模型，但在发展中也面临着缺少数据集和需要专业技术微调的挑战。

    

    基础模型（FMs）是指在大规模数据上以任务无关的方式进行训练，并通过微调、少样本甚至零样本学习适用于广泛下游任务的大型预训练模型。虽然在语言和视觉任务中大获成功，但我们尚未见到为地理空间人工智能（GeoAI）开发基础模型的尝试。本文探讨开发多模态基础模型以应对GeoAI的潜力和挑战。我们首先通过在多个地理空间子域中进行七项任务的测试，包括地理语义、健康地理学、城市地理学和遥感等，研究了现有许多FMs的潜力。结果表明，在仅涉及文本模态的一些地理空间任务（例如地名识别、位置描述识别以及美国州级/县级痴呆症时间序列预测）中，这些任务无关的LLM也可以胜任任务特定的完全定制模型。我们进一步讨论了为地理空间AI开发FMs的挑战，包括缺乏大规模地理空间数据集和需要专门的地理空间微调技术。最后，我们确定了多模态FMs的潜在研究方向和应用，以惠及地理空间AI社区。

    Large pre-trained models, also known as foundation models (FMs), are trained in a task-agnostic manner on large-scale data and can be adapted to a wide range of downstream tasks by fine-tuning, few-shot, or even zero-shot learning. Despite their successes in language and vision tasks, we have yet seen an attempt to develop foundation models for geospatial artificial intelligence (GeoAI). In this work, we explore the promises and challenges of developing multimodal foundation models for GeoAI. We first investigate the potential of many existing FMs by testing their performances on seven tasks across multiple geospatial subdomains including Geospatial Semantics, Health Geography, Urban Geography, and Remote Sensing. Our results indicate that on several geospatial tasks that only involve text modality such as toponym recognition, location description recognition, and US state-level/county-level dementia time series forecasting, these task-agnostic LLMs can outperform task-specific fully-s
    
[^35]: ChatGPT依靠谷歌学术的引用计数来引述最经典的文章和期刊，导致人工智能可能会放大环境科学中的马太效应

    ChatGPT cites the most-cited articles and journals, relying solely on Google Scholar's citation counts. As a result, AI may amplify the Matthew Effect in environmental science. (arXiv:2304.06794v1 [cs.DL])

    [http://arxiv.org/abs/2304.06794](http://arxiv.org/abs/2304.06794)

    ChatGPT使用谷歌学术的引用计数来引述环境科学中的最具影响力的文章和期刊，但这可能会放大马太效应。

    

    ChatGPT（GPT）已成为近年来最受瞩目的创新之一，全球拥有超过1亿用户。然而，关于GPT的信息来源仍知之甚少。因此，我们进行了一项研究，重点关注环境科学领域内的信息来源。在研究中，我们要求GPT识别环境科学领域内最重要的10个子学科。然后，我们要求其撰写每个子学科的科学综述文章，每篇文章包括25个参考文献。然后，我们对这些参考文献进行了分析，重点关注了引用次数、出版日期和文章所发表的期刊。我们的发现表明，GPT倾向于引用环境科学中引用次数较高的出版物，其中引用次数的中位数为1184.5。它还对较旧的出版物表现出偏好，出版年份中位数为2010年，并且主要参考备受尊重的期刊。

    ChatGPT (GPT) has become one of the most talked-about innovations in recent years, with over 100 million users worldwide. However, there is still limited knowledge about the sources of information GPT utilizes. As a result, we carried out a study focusing on the sources of information within the field of environmental science. In our study, we asked GPT to identify the ten most significant subdisciplines within the field of environmental science. We then asked it to compose a scientific review article on each subdiscipline, including 25 references. We proceeded to analyze these references, focusing on factors such as the number of citations, publication date, and the journal in which the work was published. Our findings indicate that GPT tends to cite highly-cited publications in environmental science, with a median citation count of 1184.5. It also exhibits a preference for older publications, with a median publication year of 2010, and predominantly refers to well-respected journals 
    
[^36]: RAFT: 奖励排名微调用于生成型基础模型对齐

    RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment. (arXiv:2304.06767v1 [cs.LG])

    [http://arxiv.org/abs/2304.06767](http://arxiv.org/abs/2304.06767)

    RAFT框架引入了奖励排名微调方法，用于对齐生成型基础模型，以解决强化学习带来的低效和不稳定性问题。

    

    生成型基础模型容易受到广泛的无监督训练数据带来的隐式偏见的影响。这些偏见可能导致子优样本、扭曲的结果和不公平，可能产生重大影响。因此，将这些模型与人的伦理和偏好对齐是确保它们在真实应用中负责任和有效的部署的关键步骤。以往的研究主要采用人类反馈的强化学习（ RLHF）作为解决这个问题的手段。在 RL 算法的指导下，用人类反馈指导的奖励模型对生成模型进行微调。然而， RL 算法的低效性和不稳定性常常会对生成模型的成功对齐产生重大障碍，因此需要开发一种更为强大和简化的方法。为此，我们引入了一个新的框架，即奖励排名微调（ RAFT ），旨在对齐生成基础模型。

    Generative foundation models are susceptible to implicit biases that can arise from extensive unsupervised training data. Such biases can produce suboptimal samples, skewed outcomes, and unfairness, with potentially significant repercussions. Consequently, aligning these models with human ethics and preferences is an essential step toward ensuring their responsible and effective deployment in real-world applications. Prior research has primarily employed Reinforcement Learning from Human Feedback (RLHF) as a means of addressing this problem, wherein generative models are fine-tuned using RL algorithms guided by a human-feedback-informed reward model. However, the inefficiencies and instabilities associated with RL algorithms frequently present substantial obstacles to the successful alignment of generative models, necessitating the development of a more robust and streamlined approach. To this end, we introduce a new framework, Reward rAnked FineTuning (RAFT), designed to align generat
    
[^37]: 一项生物可行的神经网络研究：脑启发机制在持续学习中的作用和相互作用

    A Study of Biologically Plausible Neural Network: The Role and Interactions of Brain-Inspired Mechanisms in Continual Learning. (arXiv:2304.06738v1 [cs.NE])

    [http://arxiv.org/abs/2304.06738](http://arxiv.org/abs/2304.06738)

    本论文提出了一种基于脑启发机制的生物可行的神经网络框架，并研究了其中包括稀疏不重叠表示、赫布学习、突触巩固和重播等机制在持续学习中的相互作用，实现了基于序列的持续学习基准测试的最先进性能。

    

    人类擅长不断从不断变化的环境中获取、巩固和保留信息，而人工神经网络则表现出灾难性遗忘。生物神经网络和它们的人工对应物在突触复杂性、信息处理和学习机制方面存在显著差异，这可能解释了性能上的不匹配。我们考虑一个生物可行的框架，其中包括完全兴奋和抑制神经元的单独种群，遵循戴尔原则，并为兴奋的锥体神经元增加了类似树突的结构，用于上下文相关的刺激处理。然后我们对受脑启发的不同机制进行了全面研究，包括稀疏不重叠表示、赫布学习、突触巩固和重播伴随学习事件的过去激活。我们的解决方案在基于序列的持续学习基准测试中实现了最先进的性能，并展示了考虑这些机制在生物可行的框架中相互作用的重要性。

    Humans excel at continually acquiring, consolidating, and retaining information from an ever-changing environment, whereas artificial neural networks (ANNs) exhibit catastrophic forgetting. There are considerable differences in the complexity of synapses, the processing of information, and the learning mechanisms in biological neural networks and their artificial counterparts, which may explain the mismatch in performance. We consider a biologically plausible framework that constitutes separate populations of exclusively excitatory and inhibitory neurons that adhere to Dale's principle, and the excitatory pyramidal neurons are augmented with dendritic-like structures for context-dependent processing of stimuli. We then conduct a comprehensive study on the role and interactions of different mechanisms inspired by the brain, including sparse non-overlapping representations, Hebbian learning, synaptic consolidation, and replay of past activations that accompanied the learning event. Our s
    
[^38]: 认知的元学习模型

    Meta-Learned Models of Cognition. (arXiv:2304.06729v1 [cs.AI])

    [http://arxiv.org/abs/2304.06729](http://arxiv.org/abs/2304.06729)

    元学习模型是构建人类认知模型的有前途的工具，可以用于构建贝叶斯最优学习算法，并且比传统的贝叶斯方法有几个优势。

    

    元学习是通过与环境的反复交互而学习学习算法的框架，而不是手动设计它们。近年来，这个框架已经成为构建人类认知模型的有前途的工具。然而，还缺乏一个关于元学习认知模型的连贯的研究计划。本文的目的是综合先前的工作，在这个领域建立这样的研究计划。我们依靠三个关键支柱来实现这个目标。首先，我们指出元学习可以用于构建贝叶斯最优学习算法。这个结果不仅意味着任何可以通过贝叶斯模型解释的行为现象也可以通过元学习模型解释，而且还允许我们与认知的理性分析建立强连接。然后，我们讨论了元学习框架相对于传统的贝叶斯方法的几个优势。特别是，我们认为元学习可以

    Meta-learning is a framework for learning learning algorithms through repeated interactions with an environment as opposed to designing them by hand. In recent years, this framework has established itself as a promising tool for building models of human cognition. Yet, a coherent research program around meta-learned models of cognition is still missing. The purpose of this article is to synthesize previous work in this field and establish such a research program. We rely on three key pillars to accomplish this goal. We first point out that meta-learning can be used to construct Bayes-optimal learning algorithms. This result not only implies that any behavioral phenomenon that can be explained by a Bayesian model can also be explained by a meta-learned model but also allows us to draw strong connections to the rational analysis of cognition. We then discuss several advantages of the meta-learning framework over traditional Bayesian methods. In particular, we argue that meta-learning can
    
[^39]: 最新进展：网络入侵检测的可扩展高效的超维计算

    Late Breaking Results: Scalable and Efficient Hyperdimensional Computing for Network Intrusion Detection. (arXiv:2304.06728v1 [cs.CR])

    [http://arxiv.org/abs/2304.06728](http://arxiv.org/abs/2304.06728)

    本文提出了一种名为CyberHD的超维计算学习框架，该框架可以以显著更低的维度捕捉网络威胁的复杂模式，并具有显著的硬件错误容错能力。

    

    网络安全已经成为工业界面临的重大挑战。由于安全领域的复杂性，成本高昂的深度学习模型在边缘设备上往往无法及时检测到网络威胁。受脑启发的超维计算已被引入作为解决这个问题的一个很有前途的解决方案。但是，现有的超维计算方法使用静态编码器，需要极高的维度和数百次训练迭代才能达到合理的准确性。这导致了严重的学习效率损失，以及检测攻击时出现巨大的延迟。本文提出了一种创新的超维计算学习框架CyberHD，通过识别和再生不重要的维度，可以以显著更低的维度捕捉网络威胁的复杂模式。此外，高维空间中的全息分布为CyberHD提供了显著的硬件错误容错能力。

    Cybersecurity has emerged as a critical challenge for the industry. With the large complexity of the security landscape, sophisticated and costly deep learning models often fail to provide timely detection of cyber threats on edge devices. Brain-inspired hyperdimensional computing (HDC) has been introduced as a promising solution to address this issue. However, existing HDC approaches use static encoders and require very high dimensionality and hundreds of training iterations to achieve reasonable accuracy. This results in a serious loss of learning efficiency and causes huge latency for detecting attacks. In this paper, we propose CyberHD, an innovative HDC learning framework that identifies and regenerates insignificant dimensions to capture complicated patterns of cyber threats with remarkably lower dimensionality. Additionally, the holographic distribution of patterns in high dimensional space provides CyberHD with notably high robustness against hardware errors.
    
[^40]: 布局引导下的图像生成的诊断基准和迭代修复

    Diagnostic Benchmark and Iterative Inpainting for Layout-Guided Image Generation. (arXiv:2304.06671v1 [cs.CV])

    [http://arxiv.org/abs/2304.06671](http://arxiv.org/abs/2304.06671)

    本文提出了布局引导下图像生成的诊断基准LayoutBench，对数量、位置、大小和形状四种空间控制技能进行了研究，发现好的ID布局控制在任意布局的野外环境下可能不具有良好的推广性。接着，我们提出了一种新的基准方法IterInpaint通过修复逐步生成前景和背景区域，显现出在OOD布局方面更强的通用性。

    

    空间控制是可控图像生成的核心能力。在布局引导下的图像生成方面的进展已经显示出在具有类似空间配置的内分布（ID）数据集上有良好的结果。然而，当面对任意不确定的布局的离线分布样本时，这些模型的表现还不清楚。在本文中，我们提出了LayoutBench，这是一种对布局引导下的图像生成进行诊断的基准，它检查了四种空间控制技能：数量，位置，大小和形状。我们对两种最近代表性的布局引导下的图像生成方法进行了基准测试，并观察到良好的ID布局控制可能无法很好地推广到任意布局的野外环境（例如，边界上的对象）。接下来，我们提出了一个新的基准方法IterInpaint，它通过修复逐步生成前景和背景区域，展示出在LayoutBench的OOD布局上更强的通用性。我们进行了数量和定性评估，表明IterInpaint相对于现有方法具有更好的生成多样和视觉上令人愉悦的图像和可控的空间布局。

    Spatial control is a core capability in controllable image generation. Advancements in layout-guided image generation have shown promising results on in-distribution (ID) datasets with similar spatial configurations. However, it is unclear how these models perform when facing out-of-distribution (OOD) samples with arbitrary, unseen layouts. In this paper, we propose LayoutBench, a diagnostic benchmark for layout-guided image generation that examines four categories of spatial control skills: number, position, size, and shape. We benchmark two recent representative layout-guided image generation methods and observe that the good ID layout control may not generalize well to arbitrary layouts in the wild (e.g., objects at the boundary). Next, we propose IterInpaint, a new baseline that generates foreground and background regions in a step-by-step manner via inpainting, demonstrating stronger generalizability than existing models on OOD layouts in LayoutBench. We perform quantitative and q
    
[^41]: 分析ChatGPT在计算机工程入门课程中的适应能力

    Analyzing ChatGPT's Aptitude in an Introductory Computer Engineering Course. (arXiv:2304.06122v1 [cs.CY])

    [http://arxiv.org/abs/2304.06122](http://arxiv.org/abs/2304.06122)

    本文研究探讨了ChatGPT在计算机工程入门课程中的应用，发现它可以回答普通概念的问题，但无法处理带有图表或图形的问题，也无法进行实验室的现场操作。

    

    ChatGPT最近受到了公众和学术界的关注，因为它能够生成合理且听起来像人类回答的各种问题的文本答案。 ChatGPT在学术或课堂环境中回答各种问题甚至生成整篇论文的潜在用途或滥用受到了关注。尽管最近的研究探讨了ChatGPT在人文学科、商学院或医学院的应用，但本研究探讨了ChatGPT在计算机工程入门课程中的表现。本研究评估了ChatGPT在入门级计算机工程课程中回答测验、作业、考试和实验室问题的适应能力。本研究发现，ChatGPT在询问普通概念的问题上表现良好。然而，显然，作为一个仅限于文本的工具，它无法处理具有图表或图形的问题，也无法生成图表和图形。同时，这个工具也无法进行实验室的现场操作。

    ChatGPT has recently gathered attention from the general public and academia as a tool that is able to generate plausible and human-sounding text answers to various questions. One potential use, or abuse, of ChatGPT is in answering various questions or even generating whole essays and research papers in an academic or classroom setting. While recent works have explored the use of ChatGPT in the context of humanities, business school, or medical school, this work explores how ChatGPT performs in the context of an introductory computer engineering course. This work assesses ChatGPT's aptitude in answering quizzes, homework, exam, and laboratory questions in an introductory-level computer engineering course. This work finds that ChatGPT can do well on questions asking about generic concepts. However, predictably, as a text-only tool, it cannot handle questions with diagrams or figures, nor can it generate diagrams and figures. Further, also clearly, the tool cannot do hands-on lab experim
    
[^42]: 强化学习辅导员在数学任务中更好地支持了低成绩学生

    Reinforcement Learning Tutor Better Supported Lower Performers in a Math Task. (arXiv:2304.04933v1 [cs.AI])

    [http://arxiv.org/abs/2304.04933](http://arxiv.org/abs/2304.04933)

    本文证明了深度强化学习可用于提供自适应的教育支持，尤其对于最初成绩较低的学生具有最大的益处。

    

    资源限制使得为所有学生提供个性化教学变得困难。强化学习可以成为减少发展成本、提高智能辅导软件效果的关键工具，旨在为学生提供正确的支持。在这里，我们展示了深度强化学习如何在叙述故事线软件中为学习“容积”概念的学生提供自适应教育支持。通过解释性人工智能工具，我们也提取了有关学习的可解释洞见，证明了所得政策在不同的学生群体中具有类似的表现。最重要的是，在这两项研究中，强化学习故事系统对最初的预测分数最低的学生有最大的益处，这表明了AI适应并为低成绩学生提供支持的机会。

    Resource limitations make it hard to provide all students with one of the most effective educational interventions: personalized instruction. Reinforcement learning could be a key tool to reduce the development cost and improve the effectiveness of, intelligent tutoring software that aims to provide the right support, at the right time, to a student. Here we illustrate that deep reinforcement learning can be used to provide adaptive pedagogical support to students learning about the concept of volume in a narrative storyline software. Using explainable artificial intelligence tools, we also extracted interpretable insights about the pedagogical policy learned, and we demonstrate that the resulting policy had similar performance in a different student population. Most importantly, in both studies the reinforcement-learning narrative system had the largest benefit for those students with the lowest initial pretest scores, suggesting the opportunity for AI to adapt and provide support for
    
[^43]: 通过蒙特卡罗树搜索改进大规模多目标优化的性能不敏感性

    Improving Performance Insensitivity of Large-scale Multiobjective Optimization via Monte Carlo Tree Search. (arXiv:2304.04071v1 [cs.NE])

    [http://arxiv.org/abs/2304.04071](http://arxiv.org/abs/2304.04071)

    本论文提出了一种能同时提高大规模多目标优化算法性能和不敏感性的方法，该方法利用蒙特卡罗树搜索。

    

    大规模多目标优化问题(LSMOP)的特点是同时优化多个冲突目标并涉及数百个决策变量。 许多工程领域的实际应用可以建模为LSMOP。同时，工程应用要求性能不敏感。这通常意味着算法运行的结果不仅在性能方面对每次运行都很好，而且多次运行的性能不应波动太大，即算法呈现良好的不敏感性。考虑到每次运行需要大量计算资源，因此改进大规模多目标优化算法的性能和算法的不敏感性至关重要。然而，现有的大规模多目标优化算法只关注于提高算法的性能，而不是考虑不敏感性。

    The large-scale multiobjective optimization problem (LSMOP) is characterized by simultaneously optimizing multiple conflicting objectives and involving hundreds of decision variables. {Many real-world applications in engineering fields can be modeled as LSMOPs; simultaneously, engineering applications require insensitivity in performance.} This requirement usually means that the results from the algorithm runs should not only be good for every run in terms of performance but also that the performance of multiple runs should not fluctuate too much, i.e., the algorithm shows good insensitivity. Considering that substantial computational resources are requested for each run, it is essential to improve upon the performance of the large-scale multiobjective optimization algorithm, as well as the insensitivity of the algorithm. However, existing large-scale multiobjective optimization algorithms solely focus on improving the performance of the algorithms, leaving the insensitivity characteri
    
[^44]: REDf：基于长短期记忆网络的智能电网可再生能源需求预测模型

    REDf: A Renewable Energy Demand Forecasting Model for Smart Grids using Long Short Term Memory Network. (arXiv:2304.03997v1 [cs.LG])

    [http://arxiv.org/abs/2304.03997](http://arxiv.org/abs/2304.03997)

    本文提出了一种基于长短期记忆网络的智能电网可再生能源需求预测模型REDf，可以提供准确的能量需求预测，改善可再生能源的集成，实验结果表明其准确度优于其他模型。

    

    随着世界向更可持续的能源未来发展，将可再生能源源纳入电网的集成变得越来越重要。然而，可再生能源的间歇性使电网管理和确保稳定的电力供应变得具有挑战性。本文提出了一种基于深度学习的方法来预测智能电网中的能量需求，可以通过提供准确的能量需求预测来改善可再生能源的集成。我们使用长短期记忆网络来捕捉能럟需求数据中的复杂模式和依赖关系，这些网络特别适用于时间序列数据。所提出的方法使用了四个历史能量需求数据集，这些数据集来自不同的能源分配公司，包括美国电力、Commonwealth Edison、Dayton Power and Light以及宾夕法尼亚-新泽西-马里兰互联网。该方法还将REDf模型与其他两个深度学习模型和基准模型进行比较。实验结果表明，我们提出的REDf模型在平均绝对误差、均方根误差和决定系数等准确度指标方面优于其他模型。因此，REDf可以作为可再生能源需求预测的可靠工具，并提高可再生能源纳入智能电网的能力。

    The integration of renewable energy sources into the power grid is becoming increasingly important as the world moves towards a more sustainable energy future. However, the intermittent nature of renewable energy sources can make it challenging to manage the power grid and ensure a stable supply of electricity. In this paper, we propose a deep learning-based approach for predicting energy demand in a smart power grid, which can improve the integration of renewable energy sources by providing accurate predictions of energy demand. We use long short-term memory networks, which are well-suited for time series data, to capture complex patterns and dependencies in energy demand data. The proposed approach is evaluated using four datasets of historical energy demand data from different energy distribution companies including American Electric Power, Commonwealth Edison, Dayton Power and Light, and Pennsylvania-New Jersey-Maryland Interconnection. The proposed model is also compared with two 
    
[^45]: InstructBio：一种针对生物化学问题的大规模半监督学习范式。

    InstructBio: A Large-scale Semi-supervised Learning Paradigm for Biochemical Problems. (arXiv:2304.03906v1 [cs.LG])

    [http://arxiv.org/abs/2304.03906](http://arxiv.org/abs/2304.03906)

    InstructBio是一种针对生物化学问题的大规模半监督学习算法，引入教练模型提供有效的置信度比率来指导目标模型对不同数据点给予明显关注，避免依赖有限的标记数据和不正确的伪注释，提高了分子模型的泛化能力。

    

    在科学人工智能领域，面对真实世界问题中的有限标记数据始终是一个重要的挑战。目前的方法是在大型未标记语料库上预训练强力的任务无关模型，但在向下游任务转移知识方面可能存在困难。在本研究中，我们提出了InstructBio，一种半监督学习算法，更好地利用未标记的样例。它引入教练模型来提供伪标签可靠性的置信度比率。这些置信度分数然后指导目标模型对不同的数据点给予明显的关注，避免对标记数据的过度依赖以及不正确的伪注释的负面影响。全面的实验表明，InstructBio显著提高了分子模型的泛化能力，不仅在分子属性预测方面，在活性悬崖估计方面也表现出优越性。

    In the field of artificial intelligence for science, it is consistently an essential challenge to face a limited amount of labeled data for real-world problems. The prevailing approach is to pretrain a powerful task-agnostic model on a large unlabeled corpus but may struggle to transfer knowledge to downstream tasks. In this study, we propose InstructMol, a semi-supervised learning algorithm, to take better advantage of unlabeled examples. It introduces an instructor model to provide the confidence ratios as the measurement of pseudo-labels' reliability. These confidence scores then guide the target model to pay distinct attention to different data points, avoiding the over-reliance on labeled data and the negative influence of incorrect pseudo-annotations. Comprehensive experiments show that InstructBio substantially improves the generalization ability of molecular models, in not only molecular property predictions but also activity cliff estimations, demonstrating the superiority of 
    
[^46]: 基于徒弟学习的面向主题的文本到图像生成器

    Subject-driven Text-to-Image Generation via Apprenticeship Learning. (arXiv:2304.00186v1 [cs.CV])

    [http://arxiv.org/abs/2304.00186](http://arxiv.org/abs/2304.00186)

    该论文提出了一种基于徒弟学习的面向主题的文本到图像生成器SuTI，能够通过将大量基于主题的专家模型的数据输入徒弟模型，学习并推断出新主题的最佳专家模型，从而生成高品质的自定义图像，且速度比传统方法更快。

    

    最近的文本到图像生成模型（如DreamBooth）在通过针对目标主题微调“专家模型”，生成高度自定义的图像方面取得了显著进展。然而，这个过程很昂贵，因为每个主题都必须学习一个新的专家模型。在本文中，我们提出了一个替代主题特定微调的面向主题的文本到图像生成器SuTI。给定一个新主题的少量演示，SuTI可以即时生成不同场景中主题的新版本，而无需进行任何主题特定的优化。SuTI由“徒弟学习”驱动，其中从大量基于主题的专家模型生成的数据中学习单个的徒弟模型。具体而言，我们从互联网挖掘了数百万个图像簇，每个图像簇都聚焦于一个特定的视觉主题。我们采用这些簇来训练大量专门针对不同视觉主题的专家模型。徒弟模型通过推断基于其文本描述的新主题的最佳专家模型并生成图像来学习。我们在各种基准数据集上展示了SuTI的有效性，表明它可以生成高品质的不同主题的图像，同时比基于微调的方法快得多。

    Recent text-to-image generation models like DreamBooth have made remarkable progress in generating highly customized images of a target subject, by fine-tuning an ``expert model'' for a given subject from a few examples. However, this process is expensive, since a new expert model must be learned for each subject. In this paper, we present SuTI, a Subject-driven Text-to-Image generator that replaces subject-specific fine tuning with \emph{in-context} learning. Given a few demonstrations of a new subject, SuTI can instantly generate novel renditions of the subject in different scenes, without any subject-specific optimization. SuTI is powered by {\em apprenticeship learning}, where a single apprentice model is learned from data generated by massive amount of subject-specific expert models. Specifically, we mine millions of image clusters from the Internet, each centered around a specific visual subject. We adopt these clusters to train massive amount of expert models specialized on diff
    
[^47]: 超人工智能可以通过增加新奇性来改进人类决策的能力

    Superhuman Artificial Intelligence Can Improve Human Decision Making by Increasing Novelty. (arXiv:2303.07462v1 [cs.AI])

    [http://arxiv.org/abs/2303.07462](http://arxiv.org/abs/2303.07462)

    该研究通过分析职业围棋选手的移动决策发现，在超人工智能问世后，人类开始做出显著更好的决策，并且新颖的决策更频繁地发生，可能意味着超人工智能的发展可以改变人类的决策能力。

    

    超人工智能（AI）将如何影响人类决策，并且有哪些机制可用于支持这种影响？我们在一个领域中回答了这些问题，该领域的AI已经超过了人类的表现，分析了过去71年（1950-2021）职业围棋选手所做的超过580万个移动决策。为了回答第一个问题，我们使用了一个超人工智能程序来估计随时间变化的人类决策质量，生成了580亿个反事实的游戏模式，并将实际人类决策的胜率与反事实的AI决策的胜率进行比较。我们发现，在超人工智能问世后，人类开始做出显著更好的决策。然后，我们在时间上检查了人类玩家的策略，并发现在超人工智能问世后，新颖的决策（即以前未观察到的移动）更频繁地发生，并与更高的决策质量相关联。我们的研究结果表明，超人工智能程序的发展可能会改变人类的决策能力。

    How will superhuman artificial intelligence (AI) affect human decision making? And what will be the mechanisms behind this effect? We address these questions in a domain where AI already exceeds human performance, analyzing more than 5.8 million move decisions made by professional Go players over the past 71 years (1950-2021). To address the first question, we use a superhuman AI program to estimate the quality of human decisions across time, generating 58 billion counterfactual game patterns and comparing the win rates of actual human decisions with those of counterfactual AI decisions. We find that humans began to make significantly better decisions following the advent of superhuman AI. We then examine human players' strategies across time and find that novel decisions (i.e., previously unobserved moves) occurred more frequently and became associated with higher decision quality after the advent of superhuman AI. Our findings suggest that the development of superhuman AI programs ma
    
[^48]: MCTS-GEB：蒙特卡洛树搜索是一个好的E图构建器

    MCTS-GEB: Monte Carlo Tree Search is a Good E-graph Builder. (arXiv:2303.04651v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.04651](http://arxiv.org/abs/2303.04651)

    MCTS-GEB是一个通用的重写系统，使用强化学习和蒙特卡洛树搜索来构建最优的E图，有效消除了E图构建中的顺序问题，并在评估中表现出很好的性能。

    

    重写系统广泛使用等式饱和技术来优化重写顺序，但是当E图没有饱和时，无法代表所有可能的重写机会，会重新引入问题。为了解决这个问题，我们提出了MCTS-GEB，一个应用强化学习于E图构建的通用重写系统。MCTS-GEB使用蒙特卡洛树搜索（MCTS）高效规划最优的E图构建，有效地消除了E图构建阶段的顺序问题，并且在合理时间内取得了更好的性能。在两个不同领域的评估中，MCTS-GEB都表现出很好的性能。

    Rewrite systems [6, 10, 12] have been widely employing equality saturation [9], which is an optimisation methodology that uses a saturated e-graph to represent all possible sequences of rewrite simultaneously, and then extracts the optimal one. As such, optimal results can be achieved by avoiding the phase-ordering problem. However, we observe that when the e-graph is not saturated, it cannot represent all possible rewrite opportunities and therefore the phase-ordering problem is re-introduced during the construction phase of the e-graph. To address this problem, we propose MCTS-GEB, a domain-general rewrite system that applies reinforcement learning (RL) to e-graph construction. At its core, MCTS-GEB uses a Monte Carlo Tree Search (MCTS) [3] to efficiently plan for the optimal e-graph construction, and therefore it can effectively eliminate the phase-ordering problem at the construction phase and achieve better performance within a reasonable time. Evaluation in two different domains 
    
[^49]: Inseq：一个用于序列生成模型的可解释性工具包

    Inseq: An Interpretability Toolkit for Sequence Generation Models. (arXiv:2302.13942v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.13942](http://arxiv.org/abs/2302.13942)

    本文介绍了Inseq，这是一个Python工具包，旨在推广可解释性序列生成模型的分析。它为常见的解码器和编码器-解码器Transformers架构提供了提取模型内部信息和特征重要性得分的直观优化方法。作者还在机器翻译模型和GPT-2中展示了Inseq的潜力，证明其有助于推动可解释性自然语言生成的未来发展。

    

    自然语言处理领域的过去的可解释性研究主要集中在流行的分类任务上，而在生成任务中往往被忽视，部分原因是缺乏专门的工具。在本文中，我们介绍了Inseq，一个Python库，用于使序列生成模型的可解释性分析普及化。Inseq能够直观且优化地提取流行的仅解码器和编码器解码器Transformers架构的模型内部信息和特征重要性分数。我们还展示了它的潜力，通过使用它来突出机器翻译模型中的性别偏见并在GPT-2中定位事实知识。由于其支持对比特征归因等前沿技术的可扩展接口，因此Inseq可以推动可解释性自然语言生成的未来发展，集中优良实践，并实现公正和可重复的模型评估。

    Past work in natural language processing interpretability focused mainly on popular classification tasks while largely overlooking generation settings, partly due to a lack of dedicated tools. In this work, we introduce Inseq, a Python library to democratize access to interpretability analyses of sequence generation models. Inseq enables intuitive and optimized extraction of models' internal information and feature importance scores for popular decoder-only and encoder-decoder Transformers architectures. We showcase its potential by adopting it to highlight gender biases in machine translation models and locate factual knowledge inside GPT-2. Thanks to its extensible interface supporting cutting-edge techniques such as contrastive feature attribution, Inseq can drive future advances in explainable natural language generation, centralizing good practices and enabling fair and reproducible model evaluations.
    
[^50]: 几何深度学习仅依靠距离矩阵足够吗？

    Is Distance Matrix Enough for Geometric Deep Learning?. (arXiv:2302.05743v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.05743](http://arxiv.org/abs/2302.05743)

    本文证明了消息传递神经网络（MPNNs）不能学习几何信息，提出了$k$-DisGNNs可以利用距离矩阵中的信息，并建立了几何深度学习和传统图表示学习之间的联系。

    

    图神经网络（GNN）常用于涉及图形几何的任务，例如分子动力学模拟。虽然几何图的距离矩阵包含完整的几何信息，但已经证明消息传递神经网络（MPNNs）无法学习这种几何信息。本文通过构造新颖的对称几何图的家族，扩展了MPNN无法区分其距离矩阵的反例家族，并提出$k$-DisGNNs，可以有效地利用距离矩阵中丰富的几何结构。我们证明了模型的高表达能力，并证明了一些现有的精心设计的几何模型可以作为$k$-DisGNNs的特殊情况统一起来。最重要的是，我们建立了几何深度学习和传统图表示学习之间的联系，展示了那些最初为低度表达能力的GNN模型设计的高度表达力的GNN模型。

    Graph Neural Networks (GNNs) are often used for tasks involving the geometry of a given graph, such as molecular dynamics simulation. Although the distance matrix of a geometric graph contains complete geometric information, it has been demonstrated that Message Passing Neural Networks (MPNNs) are insufficient for learning this geometry. In this work, we expand on the families of counterexamples that MPNNs are unable to distinguish from their distance matrices, by constructing families of novel and symmetric geometric graphs. We then propose $k$-DisGNNs, which can effectively exploit the rich geometry contained in the distance matrix. We demonstrate the high expressive power of our models and prove that some existing well-designed geometric models can be unified by $k$-DisGNNs as special cases. Most importantly, we establish a connection between geometric deep learning and traditional graph representation learning, showing that those highly expressive GNN models originally designed for
    
[^51]: 带有Cox-Weibull神经网络的贝叶斯武器系统可靠性建模

    Bayesian Weapon System Reliability Modeling with Cox-Weibull Neural Network. (arXiv:2301.01850v5 [stat.AP] UPDATED)

    [http://arxiv.org/abs/2301.01850](http://arxiv.org/abs/2301.01850)

    该论文提出了一种带有Cox-Weibull神经网络的贝叶斯武器系统可靠性建模方法，可以通过整合武器系统特征来改善预测性维修，相较于传统模型的表现更优。

    

    我们提出通过神经网络（例如DeepSurv）将武器系统特征（如武器系统制造商、部署时间和地点、存储时间和地点等）整合到参数化的Cox-Weibull可靠性模型中，以改善预测性维修。同时，我们通过使用MC-dropout等退火方法来将Weibull参数参数化并开发了另一种贝叶斯模型，以进行比较目的。因为武器系统测试中的数据收集程序，我们采用了一个新颖的区间被审查对数似然函数，它在梯度下降优化期间合并了Weibull参数的MCMC取样。我们比较了分类指标，如接收器工作特性（ROC）曲线下面积（AUC）、精度-召回（PR）AUC和F分数，以展示我们的模型通常优于传统的强大模型，如XGBoost和当前标准的条件Weibull概率模型。

    We propose to integrate weapon system features (such as weapon system manufacturer, deployment time and location, storage time and location, etc.) into a parameterized Cox-Weibull [1] reliability model via a neural network, like DeepSurv [2], to improve predictive maintenance. In parallel, we develop an alternative Bayesian model by parameterizing the Weibull parameters with a neural network and employing dropout methods such as Monte-Carlo (MC)-dropout for comparative purposes. Due to data collection procedures in weapon system testing we employ a novel interval-censored log-likelihood which incorporates Monte-Carlo Markov Chain (MCMC) [3] sampling of the Weibull parameters during gradient descent optimization. We compare classification metrics such as receiver operator curve (ROC) area under the curve (AUC), precision-recall (PR) AUC, and F scores to show our model generally outperforms traditional powerful models such as XGBoost and the current standard conditional Weibull probabili
    
[^52]: Berlin V2X：多车辆和无线电访问技术的机器学习数据集

    Berlin V2X: A Machine Learning Dataset from Multiple Vehicles and Radio Access Technologies. (arXiv:2212.10343v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.10343](http://arxiv.org/abs/2212.10343)

    这篇论文介绍了一个详细的测量活动，提供了一个多车辆和无线电访问技术的机器学习数据集，该数据集通过各种V2X研究为车辆和工业通信领域开辟了新的可能性。

    

    无线通信的发展已被预期依靠新的基于机器学习（ML）的能力。这可以使无线网络组件采取主动决策和行动，以维持服务质量（QoS）和用户体验。此外，将出现在车辆和工业通信领域的新用例。具体在车辆通信领域，车辆对一切（V2X）方案将会从这些进展中受益匪浅。考虑到此，我们进行了详细的测量活动，为各种多样的基于ML的研究铺平了道路。所得到的数据集提供了在不同城市环境下基站（使用两个不同运营商）和邻近链路无线电访问技术的GPS定位无线测量，因此可以进行各种不同的V2X研究。数据集标有标签，并以高时间分辨率采样。此外，我们将数据公开发布，并附有所需的信息。

    The evolution of wireless communications into 6G and beyond is expected to rely on new machine learning (ML)-based capabilities. These can enable proactive decisions and actions from wireless-network components to sustain quality-of-service (QoS) and user experience. Moreover, new use cases in the area of vehicular and industrial communications will emerge. Specifically in the area of vehicle communication, vehicle-to-everything (V2X) schemes will benefit strongly from such advances. With this in mind, we have conducted a detailed measurement campaign that paves the way to a plethora of diverse ML-based studies. The resulting datasets offer GPS-located wireless measurements across diverse urban environments for both cellular (with two different operators) and sidelink radio access technologies, thus enabling a variety of different studies towards V2X. The datasets are labeled and sampled with a high time resolution. Furthermore, we make the data publicly available with all the necessar
    
[^53]: 基于状态的重要性抽样方法实现低方差的行为策略离线评估

    Low Variance Off-policy Evaluation with State-based Importance Sampling. (arXiv:2212.03932v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.03932](http://arxiv.org/abs/2212.03932)

    本文提出了一种基于状态的重要性抽样（SIS）方法，通过检测“忽略状态”的子轨迹来实现低方差的离线评估。

    

    在强化学习的离线评估中，需要评估目标策略的性能，而这需要使用由行为策略采集的样本数据。传统的重要性抽样方法由于计算动作概率比值的乘积而导致方差增加，从而在涉及长期规划的任务中出现估计不准确的问题。本文提出了一种基于状态的重要性抽样（SIS）方法，通过检测“忽略状态”的子轨迹来实现低方差的离线评估。

    In off-policy reinforcement learning, a behaviour policy performs exploratory interactions with the environment to obtain state-action-reward samples which are then used to learn a target policy that optimises the expected return. This leads to a problem of off-policy evaluation, where one needs to evaluate the target policy from samples collected by the often unrelated behaviour policy. Importance sampling is a traditional statistical technique that is often applied to off-policy evaluation. While importance sampling estimators are unbiased, their variance increases exponentially with the horizon of the decision process due to computing the importance weight as a product of action probability ratios, yielding estimates with low accuracy for domains involving long-term planning. This paper proposes state-based importance sampling (SIS), which drops the action probability ratios of sub-trajectories with "negligible states" -- roughly speaking, those for which the chosen actions have no 
    
[^54]: CLIP-Sculptor: 自然语言零样本生成高保真度和多样性的三维形状

    CLIP-Sculptor: Zero-Shot Generation of High-Fidelity and Diverse Shapes from Natural Language. (arXiv:2211.01427v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.01427](http://arxiv.org/abs/2211.01427)

    这篇论文提出了一种名为 CLIP-Sculptor 的方法，可以通过自然语言来生成和编辑高保真度和多样性的三维形状，且不需要 (文本，形状) 对训练，通过不同的潜在空间和改进的指导方法来实现更好的效果。

    

    最近的研究表明，自然语言可以用于生成和编辑三维形状。然而，这些方法生成的形状保真度和多样性有限。我们介绍了 CLIP-Sculptor，一种方法，通过在训练期间不需要（文本，形状）对，就可以产生高保真度和多样性的三维形状，它采用多分辨率方法，首先在低维潜在空间中生成，然后提升分辨率以获得更好的形状保真度，而离散潜在空间使用了 transformer 来建模，并通过 CLIP 的图像-文本嵌入空间进行条件化。我们还提出了一种新颖的不需要分类器的指导方法，提高了准确性-多样性的平衡。最后，我们进行了大量实验，证明了 CLIP-Sculptor 优于现有的基准方法。代码可在 https://ivl.cs.brown.edu/#/projects/clip-sculptor 下载。

    Recent works have demonstrated that natural language can be used to generate and edit 3D shapes. However, these methods generate shapes with limited fidelity and diversity. We introduce CLIP-Sculptor, a method to address these constraints by producing high-fidelity and diverse 3D shapes without the need for (text, shape) pairs during training. CLIP-Sculptor achieves this in a multi-resolution approach that first generates in a low-dimensional latent space and then upscales to a higher resolution for improved shape fidelity. For improved shape diversity, we use a discrete latent space which is modeled using a transformer conditioned on CLIP's image-text embedding space. We also present a novel variant of classifier-free guidance, which improves the accuracy-diversity trade-off. Finally, we perform extensive experiments demonstrating that CLIP-Sculptor outperforms state-of-the-art baselines. The code is available at https://ivl.cs.brown.edu/#/projects/clip-sculptor.
    
[^55]: 通过结构增强的预训练模型和自适应融合提高语义匹配

    Improving Semantic Matching through Dependency-Enhanced Pre-trained Model with Adaptive Fusion. (arXiv:2210.08471v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.08471](http://arxiv.org/abs/2210.08471)

    本文提出了一种依赖增强的自适应融合注意力模型，它将依赖信息与原始语义信号自适应融合，以更好地模拟复杂的语义匹配关系。

    

    基于Transformer的预训练模型，如BERT，在语义句子匹配方面取得了很大的进展。同时，依赖性先验知识在多个NLP任务中也显示出普遍的益处。然而，如何将依赖性先验结构有效地集成到预训练模型中，以更好地模拟复杂的语义匹配关系，仍未确定。在本文中，我们提出了一种名为DAFA的依赖增强自适应融合注意力模型，这将依赖结构明确地引入预训练模型，并将其自适应地融合到语义信息中。具体地，DAFA首先提出了一个结构敏感范式来构建一个依赖矩阵，以校准注意力权重。它采用自适应融合模块来集成获取的依赖信息和原始语义信号。此外，DAFA重构了注意力计算流程，并提供了更好的可解释性。

    Transformer-based pre-trained models like BERT have achieved great progress on Semantic Sentence Matching. Meanwhile, dependency prior knowledge has also shown general benefits in multiple NLP tasks. However, how to efficiently integrate dependency prior structure into pre-trained models to better model complex semantic matching relations is still unsettled. In this paper, we propose the \textbf{D}ependency-Enhanced \textbf{A}daptive \textbf{F}usion \textbf{A}ttention (\textbf{DAFA}), which explicitly introduces dependency structure into pre-trained models and adaptively fuses it with semantic information. Specifically, \textbf{\emph{(i)}} DAFA first proposes a structure-sensitive paradigm to construct a dependency matrix for calibrating attention weights. It adopts an adaptive fusion module to integrate the obtained dependency information and the original semantic signals. Moreover, DAFA reconstructs the attention calculation flow and provides better interpretability. By applying it o
    
[^56]: “有限速稀疏量子码多如牛毛”

    Finite-rate sparse quantum codes aplenty. (arXiv:2207.03562v3 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2207.03562](http://arxiv.org/abs/2207.03562)

    本研究提供了一种生成有限速稀疏量子码的方法，通过解决随机二部图上的约束满足问题同时强制执行多个约束限制。在满足阶段中找到的稀疏码能实现涂抹噪声的通道容量，且中等大小的有限速稀疏量子码很容易找到。

    

    本文介绍了一种生成随机多量子比特稳定器码的方法，基于求解随机二部图上的约束满足问题（CSP）。这个框架允许我们同时强制执行稳定器交换，$X/Z$ 平衡，有限速度，稀疏度和最大度数约束。通过使用最先进的 CSP 求解器，我们得到了存在满足阈值的有力证据。此外，满足阶段的范围随着量子比特数量的增加而增加。在这个阶段中，找到稀疏的码变得很容易。此外，我们观察到，在满足阶段中找到的稀疏码实际上实现了涂抹噪声的通道容量。我们的结果表明，中等大小的有限速稀疏量子码很容易找到，同时还展示了一种生成具有自定义属性的好码的灵活方法。因此，我们建立了一个完整和可定制的管道，用于生成有限速度稀疏量子码。

    We introduce a methodology for generating random multi-qubit stabilizer codes based on solving a constraint satisfaction problem (CSP) on random bipartite graphs. This framework allows us to enforce stabilizer commutation, $X/Z$ balancing, finite rate, sparsity, and maximum-degree constraints simultaneously in a CSP that we can then solve numerically. Using a state-of-the-art CSP solver, we obtain convincing evidence for the existence of a satisfiability threshold. Furthermore, the extent of the satisfiable phase increases with the number of qubits. In that phase, finding sparse codes becomes an easy problem. Moreover, we observe that the sparse codes found in the satisfiable phase practically achieve the channel capacity for erasure noise. Our results show that intermediate-size finite-rate sparse quantum codes are easy to find, while also demonstrating a flexible methodology for generating good codes with custom properties. We therefore establish a complete and customizable pipeline 
    
[^57]: 带理论支持的样本重用的广义策略提升算法

    Generalized Policy Improvement Algorithms with Theoretically Supported Sample Reuse. (arXiv:2206.13714v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.13714](http://arxiv.org/abs/2206.13714)

    研究提出了一种广义策略提升算法，结合了在线方法的策略提升保证和离线策略算法通过样本重用有效利用数据的效率。

    

    数据驱动的学习控制方法具有改善复杂系统运行的潜力，而基于模型的深度强化学习代表了一种流行的数据驱动控制方法。然而，现有的算法类别在实际控制部署的两个重要要求之间存在权衡：（i）实际性能保证和（ii）数据效率。离线策略算法通过样本重用有效利用数据，但缺乏理论保证，而在线策略算法保证了训练期间的近似策略改进，但受到高样本复杂度的影响。为了平衡这些竞争目标，我们开发了一类广义策略提升算法，它结合了在线方法的策略提升保证和样本重用的效率。通过对来自DeepMind C的多种连续控制任务进行 extensive 的实验分析，我们证明了这种新类算法的益处。

    Data-driven, learning-based control methods offer the potential to improve operations in complex systems, and model-free deep reinforcement learning represents a popular approach to data-driven control. However, existing classes of algorithms present a trade-off between two important deployment requirements for real-world control: (i) practical performance guarantees and (ii) data efficiency. Off-policy algorithms make efficient use of data through sample reuse but lack theoretical guarantees, while on-policy algorithms guarantee approximate policy improvement throughout training but suffer from high sample complexity. In order to balance these competing goals, we develop a class of Generalized Policy Improvement algorithms that combines the policy improvement guarantees of on-policy methods with the efficiency of sample reuse. We demonstrate the benefits of this new class of algorithms through extensive experimental analysis on a variety of continuous control tasks from the DeepMind C
    
[^58]: 机器学习中的不可重复性来源：一篇综述

    Sources of Irreproducibility in Machine Learning: A Review. (arXiv:2204.07610v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2204.07610](http://arxiv.org/abs/2204.07610)

    本文提出了一个理解机器学习中不可重复性来源的框架，并指出实验设置问题和未能正确考虑数据变异是机器学习研究中最常见的不可重复性来源。

    

    背景：许多发布的机器学习研究是不可重复的。方法论问题以及未能正确考虑算法本身或其实现引入的变异被认为是不可重复性的主要贡献因素。问题：不存在将实验设计选择与其对结论的潜在影响联系起来的理论框架。缺乏这样的框架，从业者和研究人员评估实验结果和描述实验的限制会更加困难。缺乏这样的框架也使得独立研究人员难以系统地归因于失败的可重复性实验的原因。目标：本文的目的是开发一个框架，使应用数据科学从业者和研究人员能够理解哪些实验设计选择可能导致误导性的发现，并通过此理解如何分析可重复性实验的结论，从而帮助分析结论。方法：我们提出了一个理解机器学习中不可重复性来源的框架，包括算法选择、数据变异、实验设置和实现细节。我们回顾了关于可重复性的最近文献，确定了常见问题，并提供了如何解决这些问题对机器学习研究可重复性的影响的例子。结果：我们发现实验设置问题和未能正确考虑数据变异是机器学习研究中最常见的不可重复性来源。结论：更好地理解这些不可重复性来源可以提高机器学习研究的可重复性，并增加结果的信心。

    Background: Many published machine learning studies are irreproducible. Issues with methodology and not properly accounting for variation introduced by the algorithm themselves or their implementations are attributed as the main contributors to the irreproducibility.Problem: There exist no theoretical framework that relates experiment design choices to potential effects on the conclusions. Without such a framework, it is much harder for practitioners and researchers to evaluate experiment results and describe the limitations of experiments. The lack of such a framework also makes it harder for independent researchers to systematically attribute the causes of failed reproducibility experiments. Objective: The objective of this paper is to develop a framework that enable applied data science practitioners and researchers to understand which experiment design choices can lead to false findings and how and by this help in analyzing the conclusions of reproducibility experiments. Method: We
    
[^59]: 稳健训练异常检测模型的简明对数损失函数

    Concise Logarithmic Loss Function for Robust Training of Anomaly Detection Model. (arXiv:2201.05748v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.05748](http://arxiv.org/abs/2201.05748)

    本研究提出了一种新的对数均方误差（LMSE）损失函数，相比于现有的均方误差（MSE）函数，在神经网络训练中更稳定、具有更强的收敛性和更好的异常检测性能。

    

    近年来，由于能够在没有或最少领域知识情况下建立异常检测模型的优势，基于深度学习的算法被广泛采用。然而，为了更稳定地训练人工神经网络，应该定义适当的神经网络结构或损失函数。对于异常检测模型的训练，均方误差（MSE）函数被广泛采用。另一方面，本文提出了一种新的损失函数，对数均方误差（LMSE），以更稳定地训练神经网络。本研究涵盖了数学比较，反向传播的差分域可视化，训练过程中的损失收敛和异常检测性能等各个方面的比较。在总体上，LMSE在损失收敛强度、异常检测性能方面优于现有的MSE函数。LMSE函数预计可适用于训练各种类型的异常检测模型。

    Recently, deep learning-based algorithms are widely adopted due to the advantage of being able to establish anomaly detection models without or with minimal domain knowledge of the task. Instead, to train the artificial neural network more stable, it should be better to define the appropriate neural network structure or the loss function. For the training anomaly detection model, the mean squared error (MSE) function is adopted widely. On the other hand, the novel loss function, logarithmic mean squared error (LMSE), is proposed in this paper to train the neural network more stable. This study covers a variety of comparisons from mathematical comparisons, visualization in the differential domain for backpropagation, loss convergence in the training process, and anomaly detection performance. In an overall view, LMSE is superior to the existing MSE function in terms of strongness of loss convergence, anomaly detection performance. The LMSE function is expected to be applicable for train
    
[^60]: 基于人工智能的定制化制造工厂：关键技术、应用和挑战

    Artificial Intelligence-Driven Customized Manufacturing Factory: Key Technologies, Applications, and Challenges. (arXiv:2108.03383v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2108.03383](http://arxiv.org/abs/2108.03383)

    人工智能技术在定制化制造中起到关键作用，实现了定制化智能工厂的特点，包括自我感知、运营优化、动态重构和智能决策，并可实现智能生产、联网协作和扩展服务模型等业务模型。

    

    传统的大批量生产范式无法灵活满足个性化客户需求。新一代智能工厂预计支持新的多品种和小批量定制生产模式。为此，人工智能（AI）正在通过加速制造和信息通信技术的整合（包括计算、通信和控制），实现更高附加值的制造。定制化智能工厂的特点是自我感知、运营优化、动态重构和智能决策。AI技术将使制造系统能够感知环境、适应外部需求，并提取包括智能生产、联网协作和扩展服务模型在内的加工知识和业务模型。本文重点讨论了AI在定制化制造（CM）中的实现。

    The traditional production paradigm of large batch production does not offer flexibility towards satisfying the requirements of individual customers. A new generation of smart factories is expected to support new multi-variety and small-batch customized production modes. For that, Artificial Intelligence (AI) is enabling higher value-added manufacturing by accelerating the integration of manufacturing and information communication technologies, including computing, communication, and control. The characteristics of a customized smart factory are to include self-perception, operations optimization, dynamic reconfiguration, and intelligent decision-making. The AI technologies will allow manufacturing systems to perceive the environment, adapt to external needs, and extract the processed knowledge, including business models, such as intelligent production, networked collaboration, and extended service models.  This paper focuses on the implementation of AI in customized manufacturing (CM)
    
[^61]: 使用自注意力和领域知识学习几何组合优化问题

    Learning Geometric Combinatorial Optimization Problems using Self-attention and Domain Knowledge. (arXiv:2107.01759v2 [cs.CG] UPDATED)

    [http://arxiv.org/abs/2107.01759](http://arxiv.org/abs/2107.01759)

    使用自注意力和领域知识，提出了一种新颖的神经网络模型来解决涉及几何的组合优化问题，可应用于各种涉及几何的COP，并在实验中取得了显著的解决质量和可扩展性方面的提高。

    

    组合优化问题（COP）是各个领域的重要研究课题。近年来，有许多尝试使用基于深度学习的方法来解决COP。我们提出了一种新颖的神经网络模型，基于自注意力和新的注意机制来解决基于几何的COP。该模型的设计使得其能够高效地使用编码器中的自注意力来学习几何COP中的点对点关系。我们提出了有效的输入和输出序列排序方法，从而减少了歧义，使模型更加规律和有效地学习序列。几何COP涉及需要满足的几何要求。在解码器中，我们提出了一种使用领域知识的新的掩蔽方案，以在问题的几何要求未被满足时提供高代价。所提出的神经网络是一个灵活的框架，可以应用于各种涉及几何的COP。我们在各种几何COP和基准数据集上进行实验，所提出的模型在解决质量和可扩展性方面相比现有模型表现出显著的提高。

    Combinatorial optimization problems (COPs) are an important research topic in various fields. In recent times, there have been many attempts to solve COPs using deep learning-based approaches. We propose a novel neural network model that solves COPs involving geometry based on self-attention and a new attention mechanism. The proposed model is designed such that the model efficiently learns point-to-point relationships in COPs involving geometry using self-attention in the encoder. We propose efficient input and output sequence ordering methods that reduce ambiguities such that the model learns the sequences more regularly and effectively. Geometric COPs involve geometric requirements that need to be satisfied. In the decoder, a new masking scheme using domain knowledge is proposed to provide a high penalty when the geometric requirement of the problem is not satisfied. The proposed neural net is a flexible framework that can be applied to various COPs involving geometry. We conduct ex
    

