# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Learning Vision-based Pursuit-Evasion Robot Policies.](http://arxiv.org/abs/2308.16185) | 本文提出了一种学习基于视觉的追逐-逃避机器人策略的方法。通过将问题转化为监督学习问题，利用完全可观测机器人策略为部分可观测策略生成监督信号。实验结果表明，部分可观测策略的监督信号质量取决于逃避者行为的多样性和最优性的平衡，以及完全可观测策略中建模假设的强度。我们在一台具有RGB-D相机的四足机器人上进行了实际应用，证明了该方法的有效性和创新性。 |
| [^2] | [Quantifying Uncertainty in Answers from any Language Model via Intrinsic and Extrinsic Confidence Assessment.](http://arxiv.org/abs/2308.16175) | 本文引入了BSDetector，一种用于检测预训练大型语言模型生成的错误和推测性回答的方法。该方法通过估计置信度量化了回答的不确定性，并在闭合型和开放型问答基准实验中表现出更准确的识别能力。 |
| [^3] | [Algebraic, Topological, and Mereological Foundations of Existential Granules.](http://arxiv.org/abs/2308.16157) | 本研究从代数、拓扑和细部学的角度创造了新的存在性颗粒概念，并刻画了其特征。这些颗粒首先确定自己，然后与环境互动，并且适用于多种颗粒计算理论框架。研究结果对算法开发、分类问题应用和方法推广的数学基础具有重要意义。 |
| [^4] | [Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models.](http://arxiv.org/abs/2308.16149) | Jais和Jais-chat是新的以阿拉伯语为中心的开放式生成式大型语言模型，具有13亿参数，在阿拉伯语方面表现出优异的知识和推理能力，并且在英语方面也具有竞争力。这些模型的发布旨在促进阿拉伯语LLMs的研究。 |
| [^5] | [LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models.](http://arxiv.org/abs/2308.16137) | LM-Infinite研究了大规模语言模型在长序列上的长度推广失败问题，并提出了一种简单的即时推广方法，以更高效地利用现有模型的生成能力。 |
| [^6] | [CorrEmbed: Evaluating Pre-trained Model Image Similarity Efficacy with a Novel Metric.](http://arxiv.org/abs/2308.16126) | 本论文提出了一种新的方法，名为CorrEmbed，用于评估预训练模型生成的图像嵌入的效果。通过计算图像嵌入中的距离与人工标注向量中的距离之间的相关性，揭示了ImageNet1k准确度得分和标签相关性之间的直线关系。 |
| [^7] | [Response: Emergent analogical reasoning in large language models.](http://arxiv.org/abs/2308.16118) | 该论文回应了关于大型语言模型中紧急类比推理的主张，并通过提供字符串类比的反例来反驳。在测试中，GPT-3无法解决最简单的类比问题。为了加强零点推理等人类推理的主张，需要发展出排除数据记忆的方法。 |
| [^8] | [survex: an R package for explaining machine learning survival models.](http://arxiv.org/abs/2308.16113) | survex是一个R软件包，通过应用可解释的人工智能技术，提供了一个连贯的框架来解释任何生存模型，可以改进模型，提高透明度和责任感。 |
| [^9] | [Grandma Karl is 27 years old -- research agenda for pseudonymization of research data.](http://arxiv.org/abs/2308.16109) | 研究数据的共享面临个人和敏感信息保护的问题，该论文提出了一个关于假名化的研究议程，包括对假名化对无结构化数据的影响，假名化作为保护作者身份的有效性，以及开发上下文敏感算法用于处理个人信息。 |
| [^10] | [Application of Zone Method based Machine Learning and Physics-Informed Neural Networks in Reheating Furnaces.](http://arxiv.org/abs/2308.16089) | 本文将经典的Hottel区域方法与机器学习和深度学习相结合，利用生成的数据进行加热炉控制系统的训练，为基础产业的可持续制造和能耗降低目标做出贡献。 |
| [^11] | [Impact of Visual Context on Noisy Multimodal NMT: An Empirical Study for English to Indian Languages.](http://arxiv.org/abs/2308.16075) | 该研究实证研究了神经机器翻译中利用多模态信息的有效性，发现在大规模预训练的单模态系统中添加图像特征可能是多余的。此外，该研究还引入了合成噪声来评估图像对处理文本噪声的帮助。实验结果表明，多模态模型在嘈杂的环境中略优于文本模型，即使是随机图像。研究在英语翻译为印地语、孟加拉语和马拉雅拉姆语时表现出色，且视觉背景对翻译效果的影响与源文本噪声有所不同。 |
| [^12] | [Semantic Image Synthesis via Class-Adaptive Cross-Attention.](http://arxiv.org/abs/2308.16071) | 本文提出了一种基于类自适应交叉注意力的语义图像合成方法，通过使用交叉注意力层来调节图像生成，实现了优秀的视觉生成质量和编辑灵活性，并解决了全局样式不一致和局部样式编辑不真实的问题。 |
| [^13] | [Consensus of state of the art mortality prediction models: From all-cause mortality to sudden death prediction.](http://arxiv.org/abs/2308.16067) | 本研究共识了最新的死亡预测模型，从全因死亡到突发死亡预测，展示了结合医疗历史、血液检查、药物处方和住院治疗可以预测突发死亡的风险增加的有效性。 |
| [^14] | [Text-to-OverpassQL: A Natural Language Interface for Complex Geodata Querying of OpenStreetMap.](http://arxiv.org/abs/2308.16060) | Text-to-OverpassQL是一个使用自然语言查询OpenStreetMap中地理数据的界面，能够帮助用户制定复杂的数据库查询，并为序列生成模型提供一个基准。 |
| [^15] | [AsyncET: Asynchronous Learning for Knowledge Graph Entity Typing with Auxiliary Relations.](http://arxiv.org/abs/2308.16055) | 本文介绍了一种采用异步学习方法并引入多个辅助关系的知识图谱实体类型推断方法。实验结果表明，该方法在不同粒度的实体类型模式建模方面具有更强的表达能力。 |
| [^16] | [EnsembleFollower: A Hybrid Car-Following Framework Based On Reinforcement Learning and Hierarchical Planning.](http://arxiv.org/abs/2308.16008) | EnsembleFollower是一个采用分层规划和强化学习的混合车辆跟驰框架，能够实现先进的类人车辆跟驰。 |
| [^17] | [DRL-Based Trajectory Tracking for Motion-Related Modules in Autonomous Driving.](http://arxiv.org/abs/2308.15991) | 本文提出了一种基于深度强化学习的轨迹跟踪方法，适用于自主驾驶系统中的运动相关模块。该方法通过DL的表示学习能力和RL的探索性质，提高了轨迹跟踪的准确性和稳健性，在真实系统中具有较好的适应性和效果。 |
| [^18] | [FPTQ: Fine-grained Post-Training Quantization for Large Language Models.](http://arxiv.org/abs/2308.15987) | 本研究提出了一种面向大型语言模型的细粒度训练后量化方法，结合了W4A8和W8A8两种方案的优点，通过逐层激活量化和细粒度权重量化来解决性能下降的问题。 |
| [^19] | [Vision-Based Traffic Accident Detection and Anticipation: A Survey.](http://arxiv.org/abs/2308.15985) | 本综述是关于基于视觉的交通事故检测和预测的第一篇在深度学习时代的综述，它探讨了交通事故检测和预测中的分布外特征以及当前的人工智能发展方向。 |
| [^20] | [RoboTAP: Tracking Arbitrary Points for Few-Shot Visual Imitation.](http://arxiv.org/abs/2308.15975) | RoboTAP通过利用稠密追踪技术实现了快速、普适的学习，可以从短时间内收集的演示中解决复杂的物体排列任务。 |
| [^21] | [Iterative Reward Shaping using Human Feedback for Correcting Reward Misspecification.](http://arxiv.org/abs/2308.15969) | 这项工作提出了ITERS，一种使用人机反馈的迭代奖励塑造方法，用于纠正奖励函数规格化错误。通过让用户提供基于轨迹的反馈，并结合用户的解释，我们实现了自动化的奖励调整过程，并在多种环境中对该方法进行了评估。 |
| [^22] | [Review of Parameter Tuning Methods for Nature-Inspired Algorithms.](http://arxiv.org/abs/2308.15965) | 本文综述了自然启发算法参数调整的主要方法，并强调了参数调整最新发展中的重要问题。 |
| [^23] | [WALL-E: Embodied Robotic WAiter Load Lifting with Large Language Model.](http://arxiv.org/abs/2308.15962) | 本文研究了将大型语言模型与视觉定位和机器人抓取系统集成，通过使用WALL-E实现了在餐厅场景中提高人机交互准确性和效率的目标。通过实验和评估，证明了这种集成可以使WALL-E成为一位更有能力和智能的机器人服务员。 |
| [^24] | [Cyclophobic Reinforcement Learning.](http://arxiv.org/abs/2308.15911) | 本文提出一种新的周期性排斥增强学习方法，通过避免循环来惩罚冗余而不奖励新颖性，在奖励稀疏的环境中能取得优异的结果。 |
| [^25] | [Is the U.S. Legal System Ready for AI's Challenges to Human Values?.](http://arxiv.org/abs/2308.15906) | 美国法律需要加强应对生成式人工智能对人类价值观挑战的能力，并提供积极、可审计的指导，以填补现有法律框架在保护基本价值观方面的空白和不确定性。 |
| [^26] | [Thermodynamic Computing via Autonomous Quantum Thermal Machines.](http://arxiv.org/abs/2308.15905) | 通过自主量子热机实现了热力学计算模型。通过热流进行计算，可实现任何线性可分离函数，并可扩展到神经元网络执行任何 needed功能。 |
| [^27] | [Explainable Answer-set Programming.](http://arxiv.org/abs/2308.15901) | 这篇论文研究了可解释性答案集编程，该编程方法在许多领域中广泛应用，并提出了对ASP解决方案的解释方法。 |
| [^28] | [Beyond Traditional Neural Networks: Toward adding Reasoning and Learning Capabilities through Computational Logic Techniques.](http://arxiv.org/abs/2308.15899) | 通过计算逻辑技术，本研究提出了一种超越传统神经网络的方法，将神经网络和符号推理相结合，解决了深度学习模型在高质量训练数据、透明性和鲁棒性方面的限制。同时，通过改进知识注入过程，将机器学习和逻辑元素融入多主体系统。 |
| [^29] | [An xAI Approach for Data-to-Text Processing with ASP.](http://arxiv.org/abs/2308.15898) | 本文提出了一个基于ASP的框架，用于从数据生成自然语言文本，具备明确控制准确性错误和合成量的能力，采用逻辑规则逐步丰富文本描述。 |
| [^30] | [Nemo: First Glimpse of a New Rule Engine.](http://arxiv.org/abs/2308.15897) | Nemo是一个全新的、注重可靠性和性能的逻辑编程引擎，通过数据中心的分析计算，使用了完全声明式的Datalog方言，具有出色的可扩展性。 |
| [^31] | [Assessing Drivers' Situation Awareness in Semi-Autonomous Vehicles: ASP based Characterisations of Driving Dynamics for Modelling Scene Interpretation and Projection.](http://arxiv.org/abs/2308.15895) | 构建了一个软硬件框架来评估驾驶员对情况的感知，并提供以人为中心的辅助，以帮助建立情境感知。 |
| [^32] | [A Logic Programming Approach to Global Logistics in a Co-Design Environment.](http://arxiv.org/abs/2308.15892) | 本文提出了一种利用逻辑编程方法解决共同设计环境中全球物流问题的方法，旨在通过与产品同时开发工业系统，提高其韧性并降低供应链瓶颈的风险。 |
| [^33] | [Understanding ProbLog as Probabilistic Argumentation.](http://arxiv.org/abs/2308.15891) | 在这篇论文中，我们研究了ProbLog和概率论证之间的关系，发现了ProbLog是Probabilistic Abstract Argumentation (PAA)的一种形式的实例，并为ProbLog提供了使用PAA/PABA的替代语义的可能性，以及为PAA/PABA获得新的论证语义的可能性。这些结果还为ProbLog的输出提供了新形式的论证性解释的可能性。 |
| [^34] | [Natlog: Embedding Logic Programming into the Python Deep-Learning Ecosystem.](http://arxiv.org/abs/2308.15890) | Natlog通过高级交互模式和多种功能的连接，将逻辑编程嵌入到Python深度学习生态系统中，实现了逻辑语言结构对Python生态系统的完全访问能力。 |
| [^35] | [Generalizing Level Ranking Constraints for Monotone and Convex Aggregates.](http://arxiv.org/abs/2308.15888) | 这项工作通过将级别排名约束重写为保持单调和凸聚合结构的一般形式，提供了一种统一的解决方案，以覆盖ASP的聚合扩展。 |
| [^36] | [On the Potential of CLIP for Compositional Logical Reasoning.](http://arxiv.org/abs/2308.15887) | 本文研究了使用CLIP进行组合逻辑推理的潜力，并发现通常配置的CLIP无法进行这种推理。 |
| [^37] | ["Would life be more interesting if I were in AI?" Answering Counterfactuals based on Probabilistic Inductive Logic Programming.](http://arxiv.org/abs/2308.15883) | 该论文提出了一种使用概率归纳逻辑编程回答反事实问题的方法，在学习程序结构时考虑了因果机制，使得可以进行反事实推理。 |
| [^38] | [Explanations for Answer Set Programming.](http://arxiv.org/abs/2308.15879) | 本文介绍了对Answer Set Programming (ASP)进行解释的系统xASP的改进版本xASP2，它支持了更多的clingo构造并能够以有向无环图的形式呈现解释。 |
| [^39] | [ABA Learning via ASP.](http://arxiv.org/abs/2308.15877) | 该论文通过使用ASP实现ABA学习的方法提出了一种新颖的符号机器学习方法，用于从背景知识和正负例中绘制基于假设的论证框架。 |
| [^40] | [Deontic Paradoxes in ASP with Weak Constraints.](http://arxiv.org/abs/2308.15870) | 本文通过使用Answer Set Programming（ASP）和弱约束，解决了道义逻辑面临的悖论问题，并提出了一种方法来翻译带有弱约束的ASP中的道义系统，应用于"道德"版本的Pac-man取得了较好的结果。 |
| [^41] | [On the Independencies Hidden in the Structure of a Probabilistic Logic Program.](http://arxiv.org/abs/2308.15865) | 该论文推广了基于贝叶斯网络的条件独立性推理方法，并提出了一种用于判断非ground情况下的条件独立性陈述的方法。实验评估证明了该方法的有效性。 |
| [^42] | [Inductive Learning of Declarative Domain-Specific Heuristics for ASP.](http://arxiv.org/abs/2308.15863) | 本文介绍了一种用于自动学习声明性领域特定启发式算法的新方法。实验结果表明，学习到的启发式算法可以提高求解性能和解的质量。 |
| [^43] | [Zero-shot Inversion Process for Image Attribute Editing with Diffusion Models.](http://arxiv.org/abs/2308.15854) | 提出了一种零样本反演过程（ZIP）框架，用于图像属性编辑。该方法利用生成的视觉参考和文本引导注入扩散模型的语义潜空间，可以在文本提示的直观控制下产生多样的内容和属性，并展现出对不同属性操作的鲁棒性。 |
| [^44] | [MSGNN: Multi-scale Spatio-temporal Graph Neural Network for Epidemic Forecasting.](http://arxiv.org/abs/2308.15840) | MSGNN是一种多尺度时空图神经网络，通过创新的多尺度视图和图学习模块，有效地解决了现有GNN模型在保留远距离连接和多尺度流行病模式上的局限性。它在传染病预测中具有重要的应用价值。 |
| [^45] | [Depth analysis of battery performance based on a data-driven approach.](http://arxiv.org/abs/2308.15833) | 本论文利用机器学习技术研究了电池容量衰减问题，提出了WOA-ELM模型来解析电池性能关键因素，并克服了机器学习黑盒的缺陷。研究结果揭示了电极材料的结构损伤与电池故障之间的联系，对于电池研究和改进具有重要意义。 |
| [^46] | [Early Detection of Red Palm Weevil Infestations using Deep Learning Classification of Acoustic Signals.](http://arxiv.org/abs/2308.15829) | 本文提出了一种基于深度学习分类声学信号的红棕象侵染早期检测方法，可以解决栽培枣椰树中最具挑战性的问题之一。 |
| [^47] | [Federated Two Stage Decoupling With Adaptive Personalization Layers.](http://arxiv.org/abs/2308.15821) | 该论文提出了一种具有自适应个性化层的联邦化两阶段解耦方法，通过将同质客户端聚类到同一组的方式来提高联邦学习的性能，并解决了数据异质性和聚类时间选择的问题。 |
| [^48] | [SharpSAT-TD in Model Counting Competitions 2021-2023.](http://arxiv.org/abs/2308.15819) | SharpSAT-TD是基于SharpSAT的改进版本，在模型计数竞赛中获得了多个第一名，并引入了树分解的变量选择启发式算法。 |
| [^49] | [Peering Through Preferences: Unraveling Feedback Acquisition for Aligning Large Language Models.](http://arxiv.org/abs/2308.15812) | 本研究分析了对于对齐和评估大型语言模型而言，设计反馈选择是评分还是排名对结果的影响。研究发现评分和排名所推断出的偏好存在不一致问题，并且注释者的偏见也会影响结果。同时，研究还发现反馈协议的选择也对评估结果有显著影响。 |
| [^50] | [Benchmarking Robustness and Generalization in Multi-Agent Systems: A Case Study on Neural MMO.](http://arxiv.org/abs/2308.15802) | 这篇论文介绍了第二届神经MMO挑战赛的研究结果，表明通过使用标准的强化学习方法和领域特定的工程技术，成功解决了多代理系统中的鲁棒性和泛化性能问题，并提出比赛作为解决困难问题和建立算法标准的有效方法。 |
| [^51] | [FedCiR: Client-Invariant Representation Learning for Federated Non-IID Features.](http://arxiv.org/abs/2308.15786) | FedCiR是一种客户端不变表示学习框架，用于解决联邦学习中的特征偏移问题，通过改进表示和标签之间的互信息项来提取信息且与客户无关的特征。 |
| [^52] | [ASTER: Automatic Speech Recognition System Accessibility Testing for Stutterers.](http://arxiv.org/abs/2308.15742) | ASTER是一种面向口吃患者的自动语音识别系统可访问性测试框架，提出了一种生成模拟口吃语音并用于测试和分析ASR系统性能的方法。 |
| [^53] | [Efficient and Explainable Graph Neural Architecture Search via Monte-Carlo Tree Search.](http://arxiv.org/abs/2308.15734) | 该论文提出了一种高效且可解释的图神经网络架构搜索方法，名为ExGNAS。它包括适应各种图形的简单搜索空间和能解释决策过程的搜索算法。通过蒙特卡洛树搜索高效地搜索最佳GNN架构。 |
| [^54] | [AGS: An Dataset and Taxonomy for Domestic Scene Sound Event Recognition.](http://arxiv.org/abs/2308.15726) | 本文提出了一个用于家庭环境声音事件识别的数据集（AGS），对于室内环境声音场景的声音事件识别研究领域来说具有重要意义。该数据集考虑了重叠音频和背景噪声，并通过比较和分析先进的方法来验证其可靠性和研究新数据集带来的挑战。 |
| [^55] | [Surrogate-based Autotuning for Randomized Sketching Algorithms in Regression Problems.](http://arxiv.org/abs/2308.15720) | 本文介绍了如何使用基于替代模型的自动调优方法解决随机化草图算法中的参数选择问题，在随机数值线性代数中取得了接近最优性能的实证结果。 |
| [^56] | [Optimizing Factual Accuracy in Text Generation through Dynamic Knowledge Selection.](http://arxiv.org/abs/2308.15711) | 本文提出了DKGen系统，通过动态选择知识参考，消除了文本生成过程中的非关联参考，从而提高了生成文本的事实准确性。 |
| [^57] | [Speech Wikimedia: A 77 Language Multilingual Speech Dataset.](http://arxiv.org/abs/2308.15710) | Speech Wikimedia是一个包含来自77种语言的大量音频和转录的数据集，适用于训练语音识别、语音翻译和机器翻译模型。 |
| [^58] | [Towards a Rigorous Analysis of Mutual Information in Contrastive Learning.](http://arxiv.org/abs/2308.15704) | 本研究探索了对比学习中互信息的严格分析，引入了三种新方法和相关定理，提升了互信息分析的严谨性与实用性。 |
| [^59] | [Training Towards Critical Use: Learning to Situate AI Predictions Relative to Human Knowledge.](http://arxiv.org/abs/2308.15700) | 本文介绍了一种过程导向的适当依赖概念，称为批判使用，旨在帮助人们更好地利用基于人工智能的决策支持。研究通过在儿童虐待筛查领域进行在线实验，发现通过提供特定培训可以支持人们的批判使用能力。 |
| [^60] | [CongNaMul: A Dataset for Advanced Image Processing of Soybean Sprouts.](http://arxiv.org/abs/2308.15690) | 提出了一个用于大豆芽图像处理的名为CongNaMul的数据集，旨在支持图像分类、语义分割、分解和测量等任务。提供了质量分类、语义分割和图像分解的标记，以及5个芽的物理特征供测量使用。 |
| [^61] | [Interactively Robot Action Planning with Uncertainty Analysis and Active Questioning by Large Language Model.](http://arxiv.org/abs/2308.15684) | 本文提出了一种交互式机器人行动规划方法，利用大型语言模型（LLM）通过向人类提问来分析并收集缺失信息，最大程度地减少生成精确机器人指令的设计成本。揭示了在机器人行动规划中使用LLM面临的挑战，并为未来研究提供了有价值的见解。 |
| [^62] | [Multimodal Foundation Models For Echocardiogram Interpretation.](http://arxiv.org/abs/2308.15670) | 该论文提出了一个名为EchoCLIP的多模式基础模型，用于心脏超声解读。该模型利用大量的心脏超声视频和专家解读来实现强大的零样本性能，并在心脏功能评估和植入心脏内器件识别方面表现出良好的性能。 |
| [^63] | [Deep Reinforcement Learning Based Framework for Mobile Energy Disseminator Dispatching to Charge On-the-Road Electric Vehicles.](http://arxiv.org/abs/2308.15656) | 本论文提出了一个基于深度强化学习的移动能量传播器调度框架，用于在道路上为电动车充电，解决了充电期间车辆排队导致的行车效率低的问题，并提出了一种有效的调度策略来确定最佳时间和位置。 |
| [^64] | [A General Recipe for Automated Machine Learning in Practice.](http://arxiv.org/abs/2308.15647) | 本文提出了一个构建通用AutoML系统的参考框架，通过叙事性回顾主要方法，将基本概念提炼出来以支持在单一设计中的应用。 |
| [^65] | [AskIt: Unified Programming Interface for Programming with Large Language Models.](http://arxiv.org/abs/2308.15645) | AskIt是一个专为大型语言模型设计的领域特定语言，通过简化LLM的集成和提供统一的接口，解决了LLM嵌入应用程序和代码生成的挑战。 |
| [^66] | [Hyperbolic Convolutional Neural Networks.](http://arxiv.org/abs/2308.15639) | 双曲卷积神经网络利用双曲空间进行数据嵌入，具有更强大和可解释的模型特性。浅层嵌入构建了层次化嵌入。 |
| [^67] | [Intelligent System for Assessing University Student Personality Development and Career Readiness.](http://arxiv.org/abs/2308.15620) | 本论文研究使用一个智能系统来评估大学生的个性发展和就业准备情况。该系统通过设计基于“平衡轮”理论的调查问卷来收集学生的情感数据，并使用机器学习模型和模糊集进行处理，从而评估毕业生对未来职业的准备程度。 |
| [^68] | [InstaTune: Instantaneous Neural Architecture Search During Fine-Tuning.](http://arxiv.org/abs/2308.15609) | InstaTune是一种在微调阶段即时生成超级网络的方法，可以最小化神经架构搜索所需的时间和计算资源。 |
| [^69] | [Can transformers learn the greatest common divisor?.](http://arxiv.org/abs/2308.15594) | 本文研究了小型变形金刚模型计算最大公约数的能力。通过选择合适的训练分布和表示基准，模型可以达到高准确率，并在预测中表现出明确的模式。 |
| [^70] | [Over-Squashing in Graph Neural Networks: A Comprehensive survey.](http://arxiv.org/abs/2308.15568) | 过度压缩是图神经网络面临的关键挑战，它限制了节点之间的长程信息传递，影响了在需要广泛上下文洞察力的情况下的准确预测。 |
| [^71] | [WeatherBench 2: A benchmark for the next generation of data-driven global weather models.](http://arxiv.org/abs/2308.15560) | WeatherBench 2更新了全球中期天气预测基准测试，旨在加速数据驱动天气建模的进展，提供了开源评估框架和最新的模型性能指标。此外，还讨论了当前评估设置中的注意事项和未来的挑战。 |
| [^72] | [Adversarial Style Transfer for Robust Policy Optimization in Deep Reinforcement Learning.](http://arxiv.org/abs/2308.15550) | 本文提出了一种对抗式风格转移的算法，通过消除对混淆特征的过拟合来提高深度强化学习智能体的泛化能力。这种算法使用了生成器和策略网络，并通过最大-最小博弈的方式进行优化，以找到一个可以泛化到未见环境的鲁棒策略。实验证明，这种算法相比于其他基准算法有更好的性能。 |
| [^73] | [International Governance of Civilian AI: A Jurisdictional Certification Approach.](http://arxiv.org/abs/2308.15514) | 这项研究提出了一种国际治理民用人工智能的方法，通过建立国际人工智能组织来认证国家的管辖区域是否符合国际监督标准，进而禁止从未经认证的管辖区域进口AI供应链所包含产品。 |
| [^74] | [Tuning the perplexity for and computing sampling-based t-SNE embeddings.](http://arxiv.org/abs/2308.15513) | 本文通过采样的方法改进了大数据集下t-SNE嵌入的质量和计算速度。 |
| [^75] | [Detecting Inactive Cyberwarriors from Online Forums.](http://arxiv.org/abs/2308.15491) | 本研究调查了大型在线论坛中网络战士的活动水平，发现只有少数网络战士是活跃用户，他们在和平时期保持沉默，只在必要时行动。此外，检测不活跃的网络战士比识别活跃的网络战士更具挑战性。研究提供了更好捕捉网络战士行动的方法。 |
| [^76] | [Dynamic Dual-Graph Fusion Convolutional Network For Alzheimer's Disease Diagnosis.](http://arxiv.org/abs/2308.15484) | 本文提出了一种动态双图融合卷积网络，用于阿尔茨海默病诊断。主要贡献包括：1）提出了一种新颖的动态GCN架构，实现了端到端的诊断；2）该架构能够动态调整图结构，学习最优的潜在图，从而产生更好的诊断结果；3）结合特征图学习和动态图学习，加权处理有用的受试者特征，减少其他噪声特征的影响。实验结果表明，该模型在AD诊断中具有灵活性和稳定性，并取得了出色的分类效果。 |
| [^77] | [Online Job Failure Prediction in an HPC System.](http://arxiv.org/abs/2308.15481) | 该论文研究了使用经典的机器学习算法在提交时间上进行作业失败预测，并结合自然语言处理工具来表示作业。该方法可用于优化高性能计算系统管理，提高性能和能源效率。 |
| [^78] | [Elucidating the Exposure Bias in Diffusion Models.](http://arxiv.org/abs/2308.15321) | 本文系统地研究了扩散模型中的曝光偏差问题，并提出了一种名为Epsilon Scaling的免训练方法来减轻这一问题。实验结果验证了该方法的有效性。 |
| [^79] | [FurChat: An Embodied Conversational Agent using LLMs, Combining Open and Closed-Domain Dialogue with Facial Expressions.](http://arxiv.org/abs/2308.15214) | 本研究开发了一个交互式对话系统，将开放和封闭领域对话、脸部表情结合起来，通过使用LLMs和GPT-3.5模型来生成引人入胜的对话，以提供信息并与访客进行自然交流。 |
| [^80] | [Adapting text-based dialogue state tracker for spoken dialogues.](http://arxiv.org/abs/2308.15053) | 这篇论文描述了对构建适应口语对话系统的文本对话状态跟踪器进行的工程工作，利用自动语音识别错误校正和文本对话系统实现了插槽和值的估计。 |
| [^81] | [Distributionally Robust Statistical Verification with Imprecise Neural Networks.](http://arxiv.org/abs/2308.14815) | 本文提出了一种使用不精确神经网络的分布鲁棒统计验证方法，通过结合主动学习、不确定性量化和神经网络验证，可以在大量的分布上提供对黑盒系统行为的保证。 |
| [^82] | [Context-Aware Composition of Agent Policies by Markov Decision Process Entity Embeddings and Agent Ensembles.](http://arxiv.org/abs/2308.14521) | 该论文提出了一种通过马尔可夫决策过程实体嵌入和代理集合的方法，以上下文感知地组合代理策略，以在复杂且动态变化的环境中优化执行活动。 |
| [^83] | [Effect of Attention and Self-Supervised Speech Embeddings on Non-Semantic Speech Tasks.](http://arxiv.org/abs/2308.14359) | 该论文探讨了注意力和自监督语音嵌入对非语义语音任务的影响，特别是情感理解。实验结果表明，基于自注意力的轻量级HuBERT-Large模型在这些任务中表现出色。 |
| [^84] | [Evaluating the Robustness to Instructions of Large Language Models.](http://arxiv.org/abs/2308.14306) | 本论文评估了大型语言模型对指令的鲁棒性。结果表明，指令微调可以提升中等规模模型的性能，并且模型对陌生指令的处理能力有待改进。 |
| [^85] | [Trustworthy Representation Learning Across Domains.](http://arxiv.org/abs/2308.12315) | 本论文首次提出了跨领域的可信表示学习框架，通过包括鲁棒性、隐私、公平性和可解释性等概念，对该研究方向进行了全面的文献综述。 |
| [^86] | [Diversifying AI: Towards Creative Chess with AlphaZero.](http://arxiv.org/abs/2308.09175) | 本研究探索了AI在计算任务中是否可以从创造性决策机制中受益，并通过构建多样化的AI系统团队，在挑战性任务中超越单个AI，通过生成更多的想法，并选择最佳想法。在国际象棋中的实验结果显示，多样化AI系统以不同方式下国际象棋。 |
| [^87] | [Large Language Models in Cryptocurrency Securities Cases: Can ChatGPT Replace Lawyers?.](http://arxiv.org/abs/2308.06032) | 本研究探讨了在加密货币证券案件中，大型语言模型（LLMs）是否能够准确判断违法行为，并比较了由LLM和律师撰写的投诉书对陪审团决策的影响。研究发现，目前的LLMs在法律推理方面表现较弱，但随着未来模型的改进，其潜力有望提升。 |
| [^88] | [Developmental Bootstrapping of AIs.](http://arxiv.org/abs/2308.04586) | 传统的符号AI方法和深度学习AI方法无法满足创建强大和可信赖的AI的挑战，然而，发展脱靴法通过模仿人类儿童的能力发展过程，为创建稳健可靠的AI提供了希望。 |
| [^89] | [Why We Don't Have AGI Yet.](http://arxiv.org/abs/2308.03598) | 本论文探讨了为什么尚未实现人工通用智能（AGI），并指出了纯粹的统计方法和资金推广不足是制约AGI发展的原因之一，同时还分析了实现人类适应能力和自主学习所需的关键认知能力。 |
| [^90] | [Discrete Message via Online Clustering Labels in Decentralized POMDP.](http://arxiv.org/abs/2308.03358) | 本文通过建立回报差距上界，将多智能体通信问题转化为离散消息的在线聚类问题。该方法能够提供量化保证，并且具有通信开销低、可解释性好的特点。 |
| [^91] | [Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies.](http://arxiv.org/abs/2308.03188) | 本文总结了最近的研究，对多样化的自我纠正策略进行了分类和分析，以解决大型语言模型中的问题行为。自动化反馈技术被证明是一种可行的方法，可以使基于大型语言模型的解决方案更实用和可部署。 |
| [^92] | [Food Classification using Joint Representation of Visual and Textual Data.](http://arxiv.org/abs/2308.02562) | 本研究提出了一种使用联合表示的多模态分类框架，通过修改版的EfficientNet和Mish激活函数实现图像分类，使用基于BERT的网络实现文本分类。实验结果表明，所提出的网络在图像和文本分类上表现优于其他方法，准确率提高了11.57%和6.34%。比较分析还证明了所提出方法的效率和鲁棒性。 |
| [^93] | [How Good is Google Bard's Visual Understanding? An Empirical Study on Open Challenges.](http://arxiv.org/abs/2307.15016) | 本研究探索了Google Bard在理解和解释文本问题条件下的视觉数据方面的能力，并发现Bard在各种视觉场景中仍然存在困境，这凸显出在视觉理解方面存在重要的差距。 |
| [^94] | [Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models.](http://arxiv.org/abs/2307.08303) | 本论文提出了一种使用软提示调优来增强密集检索的方法（SPTAR）。通过优化任务特定的软提示并利用大型语言模型为未标记的文档生成弱查询，可以提高零样本和少样本的密集检索模型的性能。 |
| [^95] | [The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence.](http://arxiv.org/abs/2307.07522) | 生成型人工智能和大型语言模型可能为基础科学的发现提供机会，通过其自主生成假设和探索假设空间的闭环方法，加速科学发现的进程。 |
| [^96] | [Digital Modeling for Everyone: Exploring How Novices Approach Voice-Based 3D Modeling.](http://arxiv.org/abs/2307.04481) | 该研究探索了新手在基于语音的3D建模中的心智模型，并为语音助手的设计提供了实用的设计启示，例如处理模糊、不完整和错误的命令，提供简单的命令来塑造对象，以及选择3D对象的不同策略。 |
| [^97] | [Tranfer Learning of Semantic Segmentation Methods for Identifying Buried Archaeological Structures on LiDAR Data.](http://arxiv.org/abs/2307.03512) | 本文研究了利用传输学习方法在LiDAR数据上识别埋藏的考古结构的语义分割。实验结果表明，传输学习的应用可以提高性能，为未来工作提供基准。 |
| [^98] | [Maximizing Seaweed Growth on Autonomous Farms: A Dynamic Programming Approach for Underactuated Systems Navigating on Uncertain Ocean Currents.](http://arxiv.org/abs/2307.01916) | 设计了一种基于动态规划的方法，用于在不确定的海洋洋流中最大化海藻生长，通过利用非线性时变的洋流实现高生长区域的探测。 |
| [^99] | [HypLL: The Hyperbolic Learning Library.](http://arxiv.org/abs/2306.06154) | HypLL是一个使用希亚空间的深度学习库，基于PyTorch，旨在使其易于使用，搭建希亚网络模块，特别适用于处理层次化数据和使用少量嵌入维度，是一种新的、开放的研究方向。 |
| [^100] | [Top-Down Network Combines Back-Propagation with Attention.](http://arxiv.org/abs/2306.02415) | 本研究提出了一种新颖的自顶向下网络结构，将反向传播和注意力相结合，使网络能够同时进行学习和引导注意力。 |
| [^101] | [Pre-trained transformer for adversarial purification.](http://arxiv.org/abs/2306.01762) | 本文提出了一个快速防御对抗性攻击的方案RaPiD（Rapid Plug-in Defender），通过预训练的Transformer微调来提纯对抗样本，使其逼近清洁数据分布，实验结果表明，在有限数据情况下，该方法优于最先进的方法。 |
| [^102] | [Large Language Models are not Fair Evaluators.](http://arxiv.org/abs/2305.17926) | 本文揭示了使用大语言模型作为评估器时存在的系统偏差，可以通过改变候选响应的顺序来操纵评估结果。为了解决这个问题，提出了一个校准框架，包括多证据校准、均衡位置校准和人机协同校准。 |
| [^103] | [Evaluating GPT-3 Generated Explanations for Hateful Content Moderation.](http://arxiv.org/abs/2305.17680) | 本文通过调查和分析，评估了使用GPT-3生成的针对仇恨内容的解释是否准确和有用。结果显示，GPT-3生成的解释普遍存在过于模糊、聚焦不当等缺点，同时也存在不同类型仇恨言论生成的解释质量差异大的问题。 |
| [^104] | [Sensecape: Enabling Multilevel Exploration and Sensemaking with Large Language Models.](http://arxiv.org/abs/2305.11483) | 这篇论文讲述了一个交互式系统Sensecape，它能够利用大语言模型（LLM）支持复杂的信息任务，帮助用户通过多级抽象管理信息的复杂性，并在规划和知识建构之间无缝切换，有助于增强用户的信息组织和探索能力。 |
| [^105] | [Assessing Hidden Risks of LLMs: An Empirical Study on Robustness, Consistency, and Credibility.](http://arxiv.org/abs/2305.10235) | 本研究是一项关于大型语言模型方面的实证研究，对主流语言模型进行了大量查询和分析，结果发现这些模型存在着鲁棒性、一致性和可信性方面的潜在风险。 |
| [^106] | [Laughing Matters: Introducing Laughing-Face Generation using Diffusion Models.](http://arxiv.org/abs/2305.08854) | 该论文提出了一种新颖的模型，利用扩散模型生成逼真的笑脸序列，以填补非语言交流领域的研究空白。与传统方法相比，该模型在所有指标上都取得了最先进的性能。 |
| [^107] | [Interpretable and Robust AI in EEG Systems: A Survey.](http://arxiv.org/abs/2304.10755) | 这篇论文综述了近年来脑电图系统中可解释和鲁棒的AI技术的发展。其中，作者提出了解释性分类法，详细介绍了鲁棒AI的方法，包括对抗攻击和防御、迁移学习和不确定性建模，并讨论了未来的研究方向和挑战。 |
| [^108] | [RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment.](http://arxiv.org/abs/2304.06767) | RAFT框架引入了奖励排名微调方法，用于对齐生成型基础模型，以解决强化学习带来的低效和不稳定性问题。 |
| [^109] | [WDiscOOD: Out-of-Distribution Detection via Whitened Linear Discriminative Analysis.](http://arxiv.org/abs/2303.07543) | 本论文提出了一种名为WDiscOOD的新型OOD检测方法，其中使用白化线性判别分析将特征投影到判别子空间和残留子空间中，确定OOD分数。在大规模ImageNet-1k基准测试和六个OOD数据集中，WDiscOOD表现出了优越的性能。 |
| [^110] | [Evolutionary Reinforcement Learning: A Survey.](http://arxiv.org/abs/2303.04150) | 这篇文章系统地总结了最新的进化计算方法在解决强化学习中的关键挑战方面所取得的良好性能。 |
| [^111] | [EvHandPose: Event-based 3D Hand Pose Estimation with Sparse Supervision.](http://arxiv.org/abs/2303.02862) | 本文提出了EvHandPose，该方法利用稀疏监督下的新型手部流表示进行基于事件的3D手势姿势估计，解决了运动模糊的问题，并通过构建大规模真实世界数据集来填补真实合成领域间的差距。 |
| [^112] | [Reliable Natural Language Understanding with Large Language Models and Answer Set Programming.](http://arxiv.org/abs/2302.03780) | 本研究提出了STAR框架，将大型语言模型与Answer Set Programming相结合，以达到可靠的自然语言理解。实验证明，该框架能够成功应对需要推理的不同任务，并提供可靠的结果。 |
| [^113] | [Alien Coding.](http://arxiv.org/abs/2301.11479) | 这个论文介绍了一种自学习算法，用于合成OEIS序列的程序。该算法通过训练神经机器翻译器学习序列和已发现程序之间的对应关系，并自己发现了超过78000个OEIS序列的程序，有时还开发出非传统的编程方法。 |
| [^114] | [Modeling Moral Choices in Social Dilemmas with Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2301.08491) | 本文使用多智能体强化学习模拟社会困境中的道德选择，设计了一套道德奖励结构，旨在分析和研究AI代理的道德行为。 |
| [^115] | [RecXplainer: Amortized Attribute-based Personalized Explanations for Recommender Systems.](http://arxiv.org/abs/2211.14935) | RecXplainer提供了一种针对推荐系统的分摊属性个性化解释，以解决用户和开发者之间的信任问题。 |
| [^116] | [Identifying Unique Causal Network from Nonstationary Time Series.](http://arxiv.org/abs/2211.10085) | 本文提出了一种名为UCN的新型因果模型，它考虑了时间延迟的影响，并证明了所得到的网络结构的唯一性，解决了因果解释性和非静态性问题。 |
| [^117] | [E-MCTS: Deep Exploration in Model-Based Reinforcement Learning by Planning with Epistemic Uncertainty.](http://arxiv.org/abs/2210.13455) | 本文提出了一种新的方法E-MCTS，通过在MCTS预测中应用表观不确定性估计，实现了模型基强化学习中的深度探索，以及规划探索策略。通过实验证明这种方法在成功的表观不确定性估计和深度探索方面表现优异。 |
| [^118] | [Quantification and Aggregation over Concepts of the Ontology.](http://arxiv.org/abs/2202.00898) | 该论文介绍了一种对本体概念进行量化和聚合的方法，通过扩展一阶逻辑，并验证了良式句子的有效性。该方法在知识表示中能够以扩展容忍的方式准确建模各种问题领域。 |
| [^119] | [Control Theoretic Analysis of Temporal Difference Learning.](http://arxiv.org/abs/2112.14417) | 本研究对Temporal Difference学习算法进行了控制论分析，并引入了一个有限时间的框架，从控制论角度提供了对TD学习机制和强化学习领域的更深入洞察。 |
| [^120] | [MetaCOG: Learning a Metacognition to Recover What Objects Are Actually There.](http://arxiv.org/abs/2110.03105) | MetaCOG是一个学习元认知的模型，通过学习目标检测器的可靠性表示，增加了目标检测器的鲁棒性，而无需反馈和地面真实的物体标签。 |
| [^121] | [Efficient Joinable Table Discovery in Data Lakes: A High-Dimensional Similarity-Based Approach.](http://arxiv.org/abs/2010.13273) | 本论文提出了一种基于高维相似度的方法，在数据湖中高效地发现可连接表。通过将文本值嵌入高维向量并使用相似性谓词连接列，该方法能够解决等值连接方法的限制，识别出更有意义的结果。实验证明，该方法能够识别出比传统方法更多的可连接表。 |
| [^122] | [Coagent Networks Revisited.](http://arxiv.org/abs/2001.10474) | Coagent Networks（共智网络）是指在强化学习环境中协作的随机代理网络。这篇论文重新审视了共智网络理论，提出了执行路径的思想，并通过这一思想实现了对策梯度定理的简洁证明。 |

# 详细

[^1]: 学习基于视觉的追逐-逃避机器人策略

    Learning Vision-based Pursuit-Evasion Robot Policies. (arXiv:2308.16185v1 [cs.RO])

    [http://arxiv.org/abs/2308.16185](http://arxiv.org/abs/2308.16185)

    本文提出了一种学习基于视觉的追逐-逃避机器人策略的方法。通过将问题转化为监督学习问题，利用完全可观测机器人策略为部分可观测策略生成监督信号。实验结果表明，部分可观测策略的监督信号质量取决于逃避者行为的多样性和最优性的平衡，以及完全可观测策略中建模假设的强度。我们在一台具有RGB-D相机的四足机器人上进行了实际应用，证明了该方法的有效性和创新性。

    

    在现实世界的约束条件下，学习战略性的机器人行为，如追逐-逃避交互，是非常具有挑战性的。它需要利用交互的动态性，并通过物理状态和潜在意图的不确定性进行规划。在本文中，我们将这个棘手的问题转化为一个监督学习问题，其中一个完全可观测的机器人策略为一个部分可观测的策略生成监督信号。我们发现，部分可观测的追逐者策略的监督信号质量取决于两个关键因素：逃避者行为的多样性和最优性的平衡，以及完全可观测策略中建模假设的强度。我们将我们的策略部署在一台具有RGB-D相机的四足机器人上，在野外的追逐-逃避交互中进行。尽管存在种种挑战，但感知约束带来了创造力：当机器人感觉不确定时，它被推动收集信息，从嘈杂的测量中预测目的意图。

    Learning strategic robot behavior -- like that required in pursuit-evasion interactions -- under real-world constraints is extremely challenging. It requires exploiting the dynamics of the interaction, and planning through both physical state and latent intent uncertainty. In this paper, we transform this intractable problem into a supervised learning problem, where a fully-observable robot policy generates supervision for a partially-observable one. We find that the quality of the supervision signal for the partially-observable pursuer policy depends on two key factors: the balance of diversity and optimality of the evader's behavior and the strength of the modeling assumptions in the fully-observable policy. We deploy our policy on a physical quadruped robot with an RGB-D camera on pursuit-evasion interactions in the wild. Despite all the challenges, the sensing constraints bring about creativity: the robot is pushed to gather information when uncertain, predict intent from noisy mea
    
[^2]: 通过内在和外在置信度评估来量化任意语言模型回答的不确定性

    Quantifying Uncertainty in Answers from any Language Model via Intrinsic and Extrinsic Confidence Assessment. (arXiv:2308.16175v1 [cs.CL])

    [http://arxiv.org/abs/2308.16175](http://arxiv.org/abs/2308.16175)

    本文引入了BSDetector，一种用于检测预训练大型语言模型生成的错误和推测性回答的方法。该方法通过估计置信度量化了回答的不确定性，并在闭合型和开放型问答基准实验中表现出更准确的识别能力。

    

    我们引入了BSDetector，一种通过估计预训练大型语言模型生成的任何输出的数值置信度来检测错误和推测性回答的方法。我们的不确定性量化技术适用于仅通过黑盒API访问的任何LLM，并将内在和外在评估的置信度结合为对给定提示下LLM响应的单个可信度估计。我们的方法非常通用，可以应用于当今所有最好的LLM（其训练数据未知）。通过额外的计算，任何LLM API的用户现在可以获得与通常相同的响应，以及一个置信度估计，以便在不信任该响应时保持谨慎。对于闭合型和开放型问答基准的实验表明，BSDetector比其他不确定性估计方法（对于GPT-3和ChatGPT）更准确地识别出错误的LLM响应。通过对多个响应进行采样

    We introduce BSDetector, a method for detecting bad and speculative answers from a pretrained Large Language Model by estimating a numeric confidence score for any output it generated. Our uncertainty quantification technique works for any LLM accessible only via a black-box API, and combines intrinsic and extrinsic assessments of confidence into a single trustworthiness estimate for any LLM response to a given prompt. Our method is extremely general and can applied to all of the best LLMs available today (whose training data remains unknown). By expending a bit of extra computation, users of any LLM API can now get the same response as they would ordinarily, as well as a confidence estimate that caution when not to trust this response. Experiments on both closed and open-form Question-Answer benchmarks reveal that BSDetector more accurately identifies incorrect LLM responses than alternative uncertainty estimation procedures (for both GPT-3 and ChatGPT). By sampling multiple responses
    
[^3]: 存在性颗粒的代数、拓扑和细部学基础

    Algebraic, Topological, and Mereological Foundations of Existential Granules. (arXiv:2308.16157v1 [cs.LO])

    [http://arxiv.org/abs/2308.16157](http://arxiv.org/abs/2308.16157)

    本研究从代数、拓扑和细部学的角度创造了新的存在性颗粒概念，并刻画了其特征。这些颗粒首先确定自己，然后与环境互动，并且适用于多种颗粒计算理论框架。研究结果对算法开发、分类问题应用和方法推广的数学基础具有重要意义。

    

    在这项研究中，发明了确定自己的存在性颗粒的新概念，并从代数、拓扑和细部学的角度对其进行了刻画。存在性颗粒是那些最初确定自己，并随后与其环境进行交互的颗粒。这个概念的示例，比如颗粒球，在之前其他人的作品中虽然定义不完备、算法建立不充分、理论化不足，但已经在粗糙集和软计算的应用中使用。研究表明它们适合于颗粒计算的多个理论框架（公理化、适应性等）。这种刻画旨在用于算法开发、分类问题的应用以及可能的方法推广的数学基础。此外，还提出了许多开放问题并提供了方向。

    In this research, new concepts of existential granules that determine themselves are invented, and are characterized from algebraic, topological, and mereological perspectives. Existential granules are those that determine themselves initially, and interact with their environment subsequently. Examples of the concept, such as those of granular balls, though inadequately defined, algorithmically established, and insufficiently theorized in earlier works by others, are already used in applications of rough sets and soft computing. It is shown that they fit into multiple theoretical frameworks (axiomatic, adaptive, and others) of granular computing. The characterization is intended for algorithm development, application to classification problems and possible mathematical foundations of generalizations of the approach. Additionally, many open problems are posed and directions provided.
    
[^4]: Jais和Jais-chat：以阿拉伯语为中心的基础和指导调优的开放式生成式大型语言模型

    Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models. (arXiv:2308.16149v1 [cs.CL])

    [http://arxiv.org/abs/2308.16149](http://arxiv.org/abs/2308.16149)

    Jais和Jais-chat是新的以阿拉伯语为中心的开放式生成式大型语言模型，具有13亿参数，在阿拉伯语方面表现出优异的知识和推理能力，并且在英语方面也具有竞争力。这些模型的发布旨在促进阿拉伯语LLMs的研究。

    

    我们介绍了Jais和Jais-chat，这是新的最先进的以阿拉伯语为中心的基础和指导调优的开放式生成式大型语言模型（LLMs）。这些模型基于GPT-3的仅解码器架构，并在阿拉伯语和英语文本的混合物中进行预训练，包括各种编程语言的源代码。这些模型具有130亿个参数，根据广泛的评估结果，在阿拉伯语知识和推理能力方面表现优于任何现有的开放式阿拉伯语和多语言模型。此外，尽管在训练时使用的英语数据要少得多，但这些模型在英语方面与类似规模的以英语为中心的开放模型相比仍具有竞争力。我们提供了模型的训练、调优、安全对齐和评估的详细描述。我们发布了模型的两个开放版本--基础Jais模型和指导调优的Jais-chat变种--旨在促进阿拉伯语LLMs的研究。详见https://hugging

    We introduce Jais and Jais-chat, new state-of-the-art Arabic-centric foundation and instruction-tuned open generative large language models (LLMs). The models are based on the GPT-3 decoder-only architecture and are pretrained on a mixture of Arabic and English texts, including source code in various programming languages. With 13 billion parameters, they demonstrate better knowledge and reasoning capabilities in Arabic than any existing open Arabic and multilingual models by a sizable margin, based on extensive evaluation. Moreover, the models are competitive in English compared to English-centric open models of similar size, despite being trained on much less English data. We provide a detailed description of the training, the tuning, the safety alignment, and the evaluation of the models. We release two open versions of the model -- the foundation Jais model, and an instruction-tuned Jais-chat variant -- with the aim of promoting research on Arabic LLMs. Available at https://hugging
    
[^5]: LM-Infinite: 大规模语言模型的简单即时长度推广

    LM-Infinite: Simple On-the-Fly Length Generalization for Large Language Models. (arXiv:2308.16137v1 [cs.CL])

    [http://arxiv.org/abs/2308.16137](http://arxiv.org/abs/2308.16137)

    LM-Infinite研究了大规模语言模型在长序列上的长度推广失败问题，并提出了一种简单的即时推广方法，以更高效地利用现有模型的生成能力。

    

    近年来，在Transformer-based大规模语言模型（LLM）在各个领域取得了显著的进展。随着这些LLM在越来越复杂的任务上的部署，它们往往面临着对长时间推理过程或理解更大上下文的需求。在这些情况下，LLM在长序列上的长度推广失败变得更加突出。大多数预训练方案将训练序列截断到固定长度（例如LLaMa的2048）。即使使用了相对位置编码来应对这个问题，LLM在更长的上下文之后往往难以生成流畅的文本，更不用说进行下游任务了。常见的解决方案，如在更长的语料库上进行微调，往往需要耗费大量的硬件和时间成本，并需要进行仔细的训练过程设计。为了更高效地利用现有LLM的生成能力，我们在理论和实证上研究了主要的分布外(OOD) f

    In recent years, there have been remarkable advancements in the performance of Transformer-based Large Language Models (LLMs) across various domains. As these LLMs are deployed for increasingly complex tasks, they often face the needs to conduct longer reasoning processes or understanding larger contexts. In these situations, the length generalization failure of LLMs on long sequences become more prominent. Most pre-training schemes truncate training sequences to a fixed length (such as 2048 for LLaMa). LLMs often struggle to generate fluent texts, let alone carry out downstream tasks, after longer contexts, even with relative positional encoding which is designed to cope with this problem. Common solutions such as finetuning on longer corpora often involves daunting hardware and time costs and requires careful training process design. To more efficiently leverage the generation capacity of existing LLMs, we theoretically and empirically investigate the main out-of-distribution (OOD) f
    
[^6]: CorrEmbed: 用一种新的度量方法评估预训练模型的图像相似性效果

    CorrEmbed: Evaluating Pre-trained Model Image Similarity Efficacy with a Novel Metric. (arXiv:2308.16126v1 [cs.CV])

    [http://arxiv.org/abs/2308.16126](http://arxiv.org/abs/2308.16126)

    本论文提出了一种新的方法，名为CorrEmbed，用于评估预训练模型生成的图像嵌入的效果。通过计算图像嵌入中的距离与人工标注向量中的距离之间的相关性，揭示了ImageNet1k准确度得分和标签相关性之间的直线关系。

    

    在计算产品推荐时，检测视觉上相似的图像是一个特别有用的属性。使用预训练的计算机视觉模型提取高级图像特征的嵌入相似性在识别具有相似构成的图像方面展示出了显著的效果。然而，目前缺乏评估这些模型所生成的嵌入的方法，传统的损失和性能度量不能充分捕捉其在图像相似性搜索任务中的性能。本文中，我们使用一种名为CorrEmbed的新方法评估了多个预训练的计算机视觉模型的图像嵌入的可行性。我们的方法计算了图像嵌入中距离和人工标注向量中距离的相关性。我们使用这个度量方法对多个预训练的Torchvision模型进行了广泛的评估，揭示了ImageNet1k准确度得分和标签相关性之间的直线关系。

    Detecting visually similar images is a particularly useful attribute to look to when calculating product recommendations. Embedding similarity, which utilizes pre-trained computer vision models to extract high-level image features, has demonstrated remarkable efficacy in identifying images with similar compositions. However, there is a lack of methods for evaluating the embeddings generated by these models, as conventional loss and performance metrics do not adequately capture their performance in image similarity search tasks.  In this paper, we evaluate the viability of the image embeddings from numerous pre-trained computer vision models using a novel approach named CorrEmbed. Our approach computes the correlation between distances in image embeddings and distances in human-generated tag vectors. We extensively evaluate numerous pre-trained Torchvision models using this metric, revealing an intuitive relationship of linear scaling between ImageNet1k accuracy scores and tag-correlati
    
[^7]: 回应：大型语言模型中的紧急类比推理

    Response: Emergent analogical reasoning in large language models. (arXiv:2308.16118v1 [cs.CL])

    [http://arxiv.org/abs/2308.16118](http://arxiv.org/abs/2308.16118)

    该论文回应了关于大型语言模型中紧急类比推理的主张，并通过提供字符串类比的反例来反驳。在测试中，GPT-3无法解决最简单的类比问题。为了加强零点推理等人类推理的主张，需要发展出排除数据记忆的方法。

    

    在最近的《自然人类行为》论文中，“大型语言模型中的紧急类比推理”（Webb，Holyoak和Lu，2023），作者们认为“像GPT-3这样的大型语言模型已经获得了发现广泛类比问题的零点解的紧急能力”。在本回应中，我们提供了一些字符串类比的反例。在我们的测试中，GPT-3甚至无法解决原始论文中提出的最简单的变体问题。零点推理是一个需要非常充分证据支持的非凡主张。在我们的实验中，我们没有看到这样的证据。为了加强像零点推理这样类似人类推理的主张，重要的是该领域开发出能够排除数据记忆的方法。

    In their recent Nature Human Behaviour paper, "Emergent analogical reasoning in large language models," (Webb, Holyoak, and Lu, 2023) the authors argue that "large language models such as GPT-3 have acquired an emergent ability to find zero-shot solutions to a broad range of analogy problems." In this response, we provide counterexamples of the letter string analogies. In our tests, GPT-3 fails to solve even the easiest variants of the problems presented in the original paper. Zero-shot reasoning is an extraordinary claim that requires extraordinary evidence. We do not see that evidence in our experiments. To strengthen claims of humanlike reasoning such as zero-shot reasoning, it is important that the field develop approaches that rule out data memorization.
    
[^8]: survex：用于解释机器学习生存模型的R软件包

    survex: an R package for explaining machine learning survival models. (arXiv:2308.16113v1 [cs.LG])

    [http://arxiv.org/abs/2308.16113](http://arxiv.org/abs/2308.16113)

    survex是一个R软件包，通过应用可解释的人工智能技术，提供了一个连贯的框架来解释任何生存模型，可以改进模型，提高透明度和责任感。

    

    由于其灵活性和出色性能，机器学习模型经常用于补充和超越传统的统计生存模型。然而，它们的广泛应用受到缺乏用户友好的工具来解释其内部操作和预测原理的限制。为了解决这个问题，我们引入了survex R软件包，通过应用可解释的人工智能技术，提供了一个连贯的框架来解释任何生存模型。所提软件的功能包括理解和诊断生存模型，从而可以改进它们。通过揭示变量效应和重要性等决策过程的见解，survex能够评估模型的可靠性并检测偏差。因此，在生物医学研究和医疗应用等敏感领域可以促进透明度和责任。

    Due to their flexibility and superior performance, machine learning models frequently complement and outperform traditional statistical survival models. However, their widespread adoption is hindered by a lack of user-friendly tools to explain their internal operations and prediction rationales. To tackle this issue, we introduce the survex R package, which provides a cohesive framework for explaining any survival model by applying explainable artificial intelligence techniques. The capabilities of the proposed software encompass understanding and diagnosing survival models, which can lead to their improvement. By revealing insights into the decision-making process, such as variable effects and importances, survex enables the assessment of model reliability and the detection of biases. Thus, transparency and responsibility may be promoted in sensitive areas, such as biomedical research and healthcare applications.
    
[^9]: Grandma Karl今年27岁——研究匿名化研究数据的议程

    Grandma Karl is 27 years old -- research agenda for pseudonymization of research data. (arXiv:2308.16109v1 [cs.CL])

    [http://arxiv.org/abs/2308.16109](http://arxiv.org/abs/2308.16109)

    研究数据的共享面临个人和敏感信息保护的问题，该论文提出了一个关于假名化的研究议程，包括对假名化对无结构化数据的影响，假名化作为保护作者身份的有效性，以及开发上下文敏感算法用于处理个人信息。

    

    研究数据的可访问性对于许多研究领域的进展至关重要，但由于其中包含个人和敏感信息（如姓名或政治观点），文本数据通常不能被共享。《通用数据保护条例》（GDPR）建议使用假名化作为一种解决方案，以确保对研究数据的开放访问的安全性，但在采用假名化方法处理研究数据之前，我们需要更多地了解假名化。本文概述了一个关于假名化的研究议程，包括对无结构化数据中假名化对可读性和语言评估等影响的研究需求，以及假名化作为保护作者身份的方式的有效性，并探讨了开发上下文敏感算法用于检测、标记和替换无结构化数据中个人信息的不同方法。最近获得的关于假名化的项目“Grandma Karl今年27岁”解决了其中一部分议程。

    Accessibility of research data is critical for advances in many research fields, but textual data often cannot be shared due to the personal and sensitive information which it contains, e.g names or political opinions. General Data Protection Regulation (GDPR) suggests pseudonymization as a solution to secure open access to research data, but we need to learn more about pseudonymization as an approach before adopting it for manipulation of research data. This paper outlines a research agenda within pseudonymization, namely need of studies into the effects of pseudonymization on unstructured data in relation to e.g. readability and language assessment, as well as the effectiveness of pseudonymization as a way of protecting writer identity, while also exploring different ways of developing context-sensitive algorithms for detection, labelling and replacement of personal information in unstructured data. The recently granted project on pseudonymization Grandma Karl is 27 years old address
    
[^10]: 基于区域方法的机器学习和物理约束神经网络在加热炉中的应用

    Application of Zone Method based Machine Learning and Physics-Informed Neural Networks in Reheating Furnaces. (arXiv:2308.16089v1 [cs.LG])

    [http://arxiv.org/abs/2308.16089](http://arxiv.org/abs/2308.16089)

    本文将经典的Hottel区域方法与机器学习和深度学习相结合，利用生成的数据进行加热炉控制系统的训练，为基础产业的可持续制造和能耗降低目标做出贡献。

    

    尽管基础产业的经济重要性很高，但其生产链中的一些组件，如加热炉，能耗较高。通过减少加热炉中的整体加热时间，可以显著降低能耗。在基础产业可持续制造中，计算机集成的机器学习（ML）和人工智能（AI）控制系统可能是实现“零净排放”目标的关键。本文中，由于在加热炉等场景中无法获得高质量的数据的可行性，采用经典的Hottel区域方法基于计算模型生成数据，用于ML和深度学习（DL）模型的回归训练。值得注意的是，区域方法提供了一种优雅的方式来建模辐射传热（RHT）的物理现象，这是加热炉内高温过程中占主导地位的传热机制。利用这些数据，进行了详细的实验研究。

    Despite the high economic relevance of Foundation Industries, certain components like Reheating furnaces within their manufacturing chain are energy-intensive. Notable energy consumption reduction could be obtained by reducing the overall heating time in furnaces. Computer-integrated Machine Learning (ML) and Artificial Intelligence (AI) powered control systems in furnaces could be enablers in achieving the Net-Zero goals in Foundation Industries for sustainable manufacturing.  In this work, due to the infeasibility of achieving good quality data in scenarios like reheating furnaces, classical Hottel's zone method based computational model has been used to generate data for ML and Deep Learning (DL) based model training via regression. It should be noted that the zone method provides an elegant way to model the physical phenomenon of Radiative Heat Transfer (RHT), the dominating heat transfer mechanism in high-temperature processes inside heating furnaces. Using this data, an extensive
    
[^11]: 视觉背景对嘈杂的多模态神经机器翻译的影响：对英印语言的实证研究

    Impact of Visual Context on Noisy Multimodal NMT: An Empirical Study for English to Indian Languages. (arXiv:2308.16075v1 [cs.CL])

    [http://arxiv.org/abs/2308.16075](http://arxiv.org/abs/2308.16075)

    该研究实证研究了神经机器翻译中利用多模态信息的有效性，发现在大规模预训练的单模态系统中添加图像特征可能是多余的。此外，该研究还引入了合成噪声来评估图像对处理文本噪声的帮助。实验结果表明，多模态模型在嘈杂的环境中略优于文本模型，即使是随机图像。研究在英语翻译为印地语、孟加拉语和马拉雅拉姆语时表现出色，且视觉背景对翻译效果的影响与源文本噪声有所不同。

    

    本研究调查了在神经机器翻译中利用多模态信息的有效性。先前的研究主要关注在资源匮乏的情况下使用多模态数据，而本研究则考察了将图像特征添加到大规模预训练的单模态神经机器翻译系统中的翻译效果。令人惊讶的是，研究发现在这种情况下图像可能是多余的。此外，该研究引入了合成噪声来评估图像是否有助于模型处理文本噪声。在嘈杂的环境中，即使是随机图像，多模态模型在性能上略优于文本模型。实验将英语翻译为印地语、孟加拉语和马拉雅拉姆语，结果显著优于最先进的基准。有趣的是，视觉背景的影响与源文本噪声有所不同：对于非噪声翻译，不使用视觉背景效果最好；对于低噪声，裁剪的图像特征最佳；在高噪声情况下，完整的图像特征效果更好。

    The study investigates the effectiveness of utilizing multimodal information in Neural Machine Translation (NMT). While prior research focused on using multimodal data in low-resource scenarios, this study examines how image features impact translation when added to a large-scale, pre-trained unimodal NMT system. Surprisingly, the study finds that images might be redundant in this context. Additionally, the research introduces synthetic noise to assess whether images help the model deal with textual noise. Multimodal models slightly outperform text-only models in noisy settings, even with random images. The study's experiments translate from English to Hindi, Bengali, and Malayalam, outperforming state-of-the-art benchmarks significantly. Interestingly, the effect of visual context varies with source text noise: no visual context works best for non-noisy translations, cropped image features are optimal for low noise, and full image features work better in high-noise scenarios. This she
    
[^12]: 基于类自适应交叉注意力的语义图像合成

    Semantic Image Synthesis via Class-Adaptive Cross-Attention. (arXiv:2308.16071v1 [cs.CV])

    [http://arxiv.org/abs/2308.16071](http://arxiv.org/abs/2308.16071)

    本文提出了一种基于类自适应交叉注意力的语义图像合成方法，通过使用交叉注意力层来调节图像生成，实现了优秀的视觉生成质量和编辑灵活性，并解决了全局样式不一致和局部样式编辑不真实的问题。

    

    在语义图像合成领域，最先进的方法主要使用空间自适应归一化层，可以实现出色的视觉生成质量和编辑灵活性。然而，这些方法往往忽略全局图像统计信息，导致局部样式编辑不真实，并引起诸如色彩或光照分布偏移等全局不一致性。此外，生成器需要语义布局来映射样式，对特征提出了严格的对齐约束。为解决这些问题，我们设计了一种新颖的架构，使用交叉注意力层代替反归一化层来调节图像生成。我们的模型继承了两种方法的优点，保持了最先进的重建质量，并且改进了全局和局部样式转移。

    In semantic image synthesis, the state of the art is dominated by methods that use spatially-adaptive normalization layers, which allow for excellent visual generation quality and editing versatility. Granted their efficacy, recent research efforts have focused toward finer-grained local style control and multi-modal generation. By construction though, such layers tend to overlook global image statistics leading to unconvincing local style editing and causing global inconsistencies such as color or illumination distribution shifts. Also, the semantic layout is required for mapping styles in the generator, putting a strict alignment constraint over the features. In response, we designed a novel architecture where cross-attention layers are used in place of de-normalization ones for conditioning the image generation. Our model inherits the advantages of both solutions, retaining state-of-the-art reconstruction quality, as well as improved global and local style transfer. Code and models 
    
[^13]: 最新的死亡预测模型的共识：从全因死亡到突发死亡预测

    Consensus of state of the art mortality prediction models: From all-cause mortality to sudden death prediction. (arXiv:2308.16067v1 [cs.LG])

    [http://arxiv.org/abs/2308.16067](http://arxiv.org/abs/2308.16067)

    本研究共识了最新的死亡预测模型，从全因死亡到突发死亡预测，展示了结合医疗历史、血液检查、药物处方和住院治疗可以预测突发死亡的风险增加的有效性。

    

    全球每年有数百万人突然和意外死亡，无论是否有心血管疾病的先前历史。这种事件很少见，许多受害者在心脏疾病之前没有接受过调查，而突发死亡的定义也存在许多不同。因此，突发死亡很难预测。本分析使用了2010年大格拉斯哥和克莱德（GG＆C）地区50岁及以上的人群的英国国民保健服务电子健康记录（EHR）（n = 380,000）来尝试克服这些挑战。我们调查了医疗史、血液检查、药物处方和住院治疗是否相结合可以预测突发死亡的风险增加。我们比较了训练用于预测突发死亡或全因死亡的模型的性能。我们为每个感兴趣的结果构建了六个模型：三个取自最新研究（BEHRT，Deepr和Deep Patient），三个为我们自己创建。我们进行了训练

    Worldwide, many millions of people die suddenly and unexpectedly each year, either with or without a prior history of cardiovascular disease. Such events are sparse (once in a lifetime), many victims will not have had prior investigations for cardiac disease and many different definitions of sudden death exist. Accordingly, sudden death is hard to predict.  This analysis used NHS Electronic Health Records (EHRs) for people aged $\geq$50 years living in the Greater Glasgow and Clyde (GG\&C) region in 2010 (n = 380,000) to try to overcome these challenges. We investigated whether medical history, blood tests, prescription of medicines, and hospitalisations might, in combination, predict a heightened risk of sudden death.  We compared the performance of models trained to predict either sudden death or all-cause mortality. We built six models for each outcome of interest: three taken from state-of-the-art research (BEHRT, Deepr and Deep Patient), and three of our own creation. We trained t
    
[^14]: Text-to-OverpassQL：一个用于查询OpenStreetMap复杂地理数据的自然语言界面

    Text-to-OverpassQL: A Natural Language Interface for Complex Geodata Querying of OpenStreetMap. (arXiv:2308.16060v1 [cs.CL])

    [http://arxiv.org/abs/2308.16060](http://arxiv.org/abs/2308.16060)

    Text-to-OverpassQL是一个使用自然语言查询OpenStreetMap中地理数据的界面，能够帮助用户制定复杂的数据库查询，并为序列生成模型提供一个基准。

    

    我们提出了Text-to-OverpassQL，这是一个旨在促进通过自然语言查询OpenStreetMap (OSM)中地理数据的任务。Overpass查询语言（OverpassQL）允许用户制定复杂的数据库查询，并在OSM生态系统中被广泛采用。从自然语言输入生成Overpass查询可以满足多个用例。它使新手用户能够在无需先前知识的情况下利用OverpassQL，帮助有经验的用户制作高级查询，并使工具增强的大型语言模型能够访问存储在OSM数据库中的信息。为了评估当前序列生成模型在这一任务上的性能，我们提出了OverpassNL，一个包含8,352个查询和相应自然语言输入的数据集。我们进一步介绍了任务特定的评估指标，并通过对OSM数据库执行查询来对Text-to-OverpassQL任务进行评估。我们通过微调序列到序列模型建立了强大的基线。

    We present Text-to-OverpassQL, a task designed to facilitate a natural language interface for querying geodata from OpenStreetMap (OSM). The Overpass Query Language (OverpassQL) allows users to formulate complex database queries and is widely adopted in the OSM ecosystem. Generating Overpass queries from natural language input serves multiple use-cases. It enables novice users to utilize OverpassQL without prior knowledge, assists experienced users with crafting advanced queries, and enables tool-augmented large language models to access information stored in the OSM database. In order to assess the performance of current sequence generation models on this task, we propose OverpassNL, a dataset of 8,352 queries with corresponding natural language inputs. We further introduce task specific evaluation metrics and ground the evaluation of the Text-to-OverpassQL task by executing the queries against the OSM database. We establish strong baselines by finetuning sequence-to-sequence models a
    
[^15]: 异步学习的知识图谱实体类型推断方法与辅助关系的应用

    AsyncET: Asynchronous Learning for Knowledge Graph Entity Typing with Auxiliary Relations. (arXiv:2308.16055v1 [cs.CL])

    [http://arxiv.org/abs/2308.16055](http://arxiv.org/abs/2308.16055)

    本文介绍了一种采用异步学习方法并引入多个辅助关系的知识图谱实体类型推断方法。实验结果表明，该方法在不同粒度的实体类型模式建模方面具有更强的表达能力。

    

    知识图谱实体类型推断（KGET）是预测知识图谱中缺失实体类型的任务。以前，知识图谱嵌入（KGE）方法通过引入辅助关系“hasType”来建模实体与其类型之间的关系，尝试解决KGET任务。然而，单个辅助关系在表达多样的实体类型模式方面具有限制性。我们通过引入多个辅助关系来提高KGE方法的表达能力。类似的实体类型被分组，以减少辅助关系的数量，并提高它们对不同粒度的实体类型模式建模的能力。在多个辅助关系存在的情况下，我们提出了一种名为AsyncET的实体类型异步学习方法，该方法通过交替更新实体和类型嵌入来保持学到的实体嵌入对于实体类型推断的最新和信息丰富。在两个常用的KGE数据集上进行了实验。

    Knowledge graph entity typing (KGET) is a task to predict the missing entity types in knowledge graphs (KG). Previously, KG embedding (KGE) methods tried to solve the KGET task by introducing an auxiliary relation, 'hasType', to model the relationship between entities and their types. However, a single auxiliary relation has limited expressiveness for diverse entity-type patterns. We improve the expressiveness of KGE methods by introducing multiple auxiliary relations in this work. Similar entity types are grouped to reduce the number of auxiliary relations and improve their capability to model entity-type patterns with different granularities. With the presence of multiple auxiliary relations, we propose a method adopting an Asynchronous learning scheme for Entity Typing, named AsyncET, which updates the entity and type embeddings alternatively to keep the learned entity embedding up-to-date and informative for entity type prediction. Experiments are conducted on two commonly used KGE
    
[^16]: EnsembleFollower: 基于强化学习和分层规划的混合车辆跟驰框架

    EnsembleFollower: A Hybrid Car-Following Framework Based On Reinforcement Learning and Hierarchical Planning. (arXiv:2308.16008v1 [cs.RO])

    [http://arxiv.org/abs/2308.16008](http://arxiv.org/abs/2308.16008)

    EnsembleFollower是一个采用分层规划和强化学习的混合车辆跟驰框架，能够实现先进的类人车辆跟驰。

    

    车辆跟驰模型对于我们对纵向行驶行为的理解做出了重要贡献。然而，它们常常表现出有限的准确性和灵活性，因为它们无法完全捕捉到跟驰过程中的复杂性，或者由于依赖于训练数据中存在的受限驾驶技能而在未知情况下出现问题。值得注意的是，每种车辆跟驰模型在特定驾驶场景中具有自己的优势和劣势。因此，我们提出了一种名为EnsembleFollower的分层规划框架，用于实现先进的类人车辆跟驰。EnsembleFollower框架涉及一个高层强化学习代理的使用，负责根据当前状态，通过选择适当的低层模型执行动作或分配不同的权重来管理多个低层车辆跟驰模型。

    Car-following models have made significant contributions to our understanding of longitudinal driving behavior. However, they often exhibit limited accuracy and flexibility, as they cannot fully capture the complexity inherent in car-following processes, or may falter in unseen scenarios due to their reliance on confined driving skills present in training data. It is worth noting that each car-following model possesses its own strengths and weaknesses depending on specific driving scenarios. Therefore, we propose EnsembleFollower, a hierarchical planning framework for achieving advanced human-like car-following. The EnsembleFollower framework involves a high-level Reinforcement Learning-based agent responsible for judiciously managing multiple low-level car-following models according to the current state, either by selecting an appropriate low-level model to perform an action or by allocating different weights across all low-level components. Moreover, we propose a jerk-constrained kin
    
[^17]: 基于深度强化学习的自主驾驶中运动相关模块的轨迹跟踪

    DRL-Based Trajectory Tracking for Motion-Related Modules in Autonomous Driving. (arXiv:2308.15991v1 [cs.RO])

    [http://arxiv.org/abs/2308.15991](http://arxiv.org/abs/2308.15991)

    本文提出了一种基于深度强化学习的轨迹跟踪方法，适用于自主驾驶系统中的运动相关模块。该方法通过DL的表示学习能力和RL的探索性质，提高了轨迹跟踪的准确性和稳健性，在真实系统中具有较好的适应性和效果。

    

    自主驾驶系统总是建立在运动相关模块（如规划器和控制器）之上。准确而稳健的轨迹跟踪方法对于这些运动相关模块来说是不可或缺的原始例程。当前的方法往往对模型（如上下文和动力学）做出了强烈的假设，这些假设不足以应对真实系统中的场景变化。在本文中，我们提出了一种基于深度强化学习（DRL）的自主驾驶系统中运动相关模块的轨迹跟踪方法。DL的表示学习能力和RL的探索性质既带来了强健性又提高了准确性。与此同时，它通过以无模型和数据驱动的方式运行轨迹跟踪来增强了通用性。通过大量实验，我们证明了我们的方法相比当前方法在效率和效果上的优势。

    Autonomous driving systems are always built on motion-related modules such as the planner and the controller. An accurate and robust trajectory tracking method is indispensable for these motion-related modules as a primitive routine. Current methods often make strong assumptions about the model such as the context and the dynamics, which are not robust enough to deal with the changing scenarios in a real-world system. In this paper, we propose a Deep Reinforcement Learning (DRL)-based trajectory tracking method for the motion-related modules in autonomous driving systems. The representation learning ability of DL and the exploration nature of RL bring strong robustness and improve accuracy. Meanwhile, it enhances versatility by running the trajectory tracking in a model-free and data-driven manner. Through extensive experiments, we demonstrate both the efficiency and effectiveness of our method compared to current methods.
    
[^18]: FPTQ：面向大型语言模型的细粒度训练后量化

    FPTQ: Fine-grained Post-Training Quantization for Large Language Models. (arXiv:2308.15987v1 [cs.CL])

    [http://arxiv.org/abs/2308.15987](http://arxiv.org/abs/2308.15987)

    本研究提出了一种面向大型语言模型的细粒度训练后量化方法，结合了W4A8和W8A8两种方案的优点，通过逐层激活量化和细粒度权重量化来解决性能下降的问题。

    

    在大规模语言模型的时代中，庞大的参数大小给部署带来了巨大的挑战。作为一种流行的压缩技术，量化已经成为解决这个问题的主流实践，主要集中在两种方案W8A8和W4A16（即这两种位宽的权重和激活）。在本研究中，我们提出了一种新颖的W4A8训练后量化方法，用于现有的开放源码语言模型，结合了这两种方案的优点。因此，我们可以利用4位权重量化的I/O利用率优势和8位矩阵计算的加速效果。然而，W4A8面临着明显的性能下降问题。为了解决这个问题，我们采用了逐层激活量化策略，对于最棘手的层使用了一种新颖的对数均衡方法，并将其与细粒度权重量化相结合。在没有额外的调整的情况下，我们消除了进一步微调的必要性。

    In the era of large-scale language models, the substantial parameter size poses significant challenges for deployment. Being a prevalent compression technique, quantization has emerged as the mainstream practice to tackle this issue, which is mainly centered on two recipes W8A8 and W4A16 (i.e. weights and activations in such bit widths). In this study, we propose a novel W4A8 post-training quantization method for the available open-sourced LLMs, which combines the advantages of both two recipes. Therefore, we can leverage the benefit in the I/O utilization of 4-bit weight quantization and the acceleration due to 8-bit matrix computation. Nevertheless, the W4A8 faces notorious performance degradation. As a remedy, we involve layerwise activation quantization strategies which feature a novel logarithmic equalization for most intractable layers, and we combine them with fine-grained weight quantization. Without whistles and bells, we eliminate the necessity for further fine-tuning and obt
    
[^19]: 基于视觉的交通事故检测和预测：综述

    Vision-Based Traffic Accident Detection and Anticipation: A Survey. (arXiv:2308.15985v1 [cs.AI])

    [http://arxiv.org/abs/2308.15985](http://arxiv.org/abs/2308.15985)

    本综述是关于基于视觉的交通事故检测和预测的第一篇在深度学习时代的综述，它探讨了交通事故检测和预测中的分布外特征以及当前的人工智能发展方向。

    

    交通事故检测和预测是一个棘手的道路安全问题，人们已经付出了大量努力。随着视频数据的快速增长，基于视觉的交通事故检测和预测（称为Vision-TAD和Vision-TAA）成为安全驾驶和监控安全的最后一英里问题。然而，交通事故的长尾、不平衡、高动态、复杂和不确定属性形成了Vision-TAD和Vision-TAA的分布外特征。当前的人工智能发展可能会关注这些分布外但重要的问题。为了解决这个问题，综述至关重要。我们在深度学习时代提出了第一篇关于Vision-TAD的综述，也是第一篇关于Vision-TAA的综述。在调查过程中，我们详细讨论了每个研究原型的优缺点。此外，我们还对31个公开可用的原型进行了批判性评论。

    Traffic accident detection and anticipation is an obstinate road safety problem and painstaking efforts have been devoted. With the rapid growth of video data, Vision-based Traffic Accident Detection and Anticipation (named Vision-TAD and Vision-TAA) become the last one-mile problem for safe driving and surveillance safety. However, the long-tailed, unbalanced, highly dynamic, complex, and uncertain properties of traffic accidents form the Out-of-Distribution (OOD) feature for Vision-TAD and Vision-TAA. Current AI development may focus on these OOD but important problems. What has been done for Vision-TAD and Vision-TAA? What direction we should focus on in the future for this problem? A comprehensive survey is important. We present the first survey on Vision-TAD in the deep learning era and the first-ever survey for Vision-TAA. The pros and cons of each research prototype are discussed in detail during the investigation. In addition, we also provide a critical review of 31 publicly av
    
[^20]: RoboTAP: 追踪任意点进行少样本视觉模仿

    RoboTAP: Tracking Arbitrary Points for Few-Shot Visual Imitation. (arXiv:2308.15975v1 [cs.RO])

    [http://arxiv.org/abs/2308.15975](http://arxiv.org/abs/2308.15975)

    RoboTAP通过利用稠密追踪技术实现了快速、普适的学习，可以从短时间内收集的演示中解决复杂的物体排列任务。

    

    为了使机器人在实验室和专门的工厂之外也能发挥作用，我们需要一种快速教授它们新的有用行为的方法。当前的方法要么缺乏普适性以进行新任务的上线，而不需要特定任务的工程化，要么缺乏数据效率，无法在实践中使用的时间范围内完成。在这项工作中，我们探索了稠密追踪作为一种表示工具，以实现更快速、更普适的示教学习。我们的方法利用Track-Any-Point (TAP)模型，将演示中的相关运动隔离出来，并参数化一个低级控制器，在场景配置发生变化时重现该运动。我们展示了这种方法可以生成稳健的机器人策略，可以解决复杂的物体排列任务，如形状匹配、叠放，甚至可以完成完整的路径跟踪任务，如施胶和粘合物体，所有这些任务的演示可以在几分钟内收集到。

    For robots to be useful outside labs and specialized factories we need a way to teach them new useful behaviors quickly. Current approaches lack either the generality to onboard new tasks without task-specific engineering, or else lack the data-efficiency to do so in an amount of time that enables practical use. In this work we explore dense tracking as a representational vehicle to allow faster and more general learning from demonstration. Our approach utilizes Track-Any-Point (TAP) models to isolate the relevant motion in a demonstration, and parameterize a low-level controller to reproduce this motion across changes in the scene configuration. We show this results in robust robot policies that can solve complex object-arrangement tasks such as shape-matching, stacking, and even full path-following tasks such as applying glue and sticking objects together, all from demonstrations that can be collected in minutes.
    
[^21]: 使用人机反馈的迭代奖励塑造来纠正奖励规格化错误

    Iterative Reward Shaping using Human Feedback for Correcting Reward Misspecification. (arXiv:2308.15969v1 [cs.AI])

    [http://arxiv.org/abs/2308.15969](http://arxiv.org/abs/2308.15969)

    这项工作提出了ITERS，一种使用人机反馈的迭代奖励塑造方法，用于纠正奖励函数规格化错误。通过让用户提供基于轨迹的反馈，并结合用户的解释，我们实现了自动化的奖励调整过程，并在多种环境中对该方法进行了评估。

    

    对于强化学习（RL）代理的成功训练，一个明确定义的奖励函数至关重要。然而，在复杂的多目标环境中定义一个合适的奖励函数是一项极具挑战性的任务。开发人员常常不得不从一个初始的、可能存在错误的奖励函数开始，并根据观察到的学习行为迭代地调整其参数。在这项工作中，我们旨在通过提出ITERS，一种使用人机反馈的迭代奖励塑造方法，来自动化这个过程，以减轻奖励函数规格化错误的影响。我们的方法允许用户在训练过程中提供基于轨迹的反馈，这些反馈可以作为下一个训练迭代中的奖励塑造信号进行整合。我们还允许用户提供对他们的反馈的解释，这些解释被用来增强反馈并减少用户的工作量和反馈频率。我们在三种环境中评估了ITERS并展示了其效果。

    A well-defined reward function is crucial for successful training of an reinforcement learning (RL) agent. However, defining a suitable reward function is a notoriously challenging task, especially in complex, multi-objective environments. Developers often have to resort to starting with an initial, potentially misspecified reward function, and iteratively adjusting its parameters, based on observed learned behavior. In this work, we aim to automate this process by proposing ITERS, an iterative reward shaping approach using human feedback for mitigating the effects of a misspecified reward function. Our approach allows the user to provide trajectory-level feedback on agent's behavior during training, which can be integrated as a reward shaping signal in the following training iteration. We also allow the user to provide explanations of their feedback, which are used to augment the feedback and reduce user effort and feedback frequency. We evaluate ITERS in three environments and show t
    
[^22]: 自然启发算法参数调整方法综述

    Review of Parameter Tuning Methods for Nature-Inspired Algorithms. (arXiv:2308.15965v1 [cs.AI])

    [http://arxiv.org/abs/2308.15965](http://arxiv.org/abs/2308.15965)

    本文综述了自然启发算法参数调整的主要方法，并强调了参数调整最新发展中的重要问题。

    

    几乎所有优化算法都有与算法相关的参数，而这些参数的设置可以极大地影响所考虑算法的行为。因此，应进行适当的参数调整，以确保用于优化的算法可以良好地执行，并能够足够稳健地解决不同类型的优化问题。本章综述了一些主要的参数调整方法，并重点介绍了参数调整的最新发展中的重要问题。还讨论了一些开放问题，并提出了对未来研究的一些建议。

    Almost all optimization algorithms have algorithm-dependent parameters, and the setting of such parameter values can largely influence the behaviour of the algorithm under consideration. Thus, proper parameter tuning should be carried out to ensure the algorithm used for optimization may perform well and can be sufficiently robust for solving different types of optimization problems. This chapter reviews some of the main methods for parameter tuning and then highlights the important issues concerning the latest development in parameter tuning. A few open problems are also discussed with some recommendations for future research.
    
[^23]: WALL-E: 具有大型语言模型的实体机器人服务员举重

    WALL-E: Embodied Robotic WAiter Load Lifting with Large Language Model. (arXiv:2308.15962v1 [cs.RO])

    [http://arxiv.org/abs/2308.15962](http://arxiv.org/abs/2308.15962)

    本文研究了将大型语言模型与视觉定位和机器人抓取系统集成，通过使用WALL-E实现了在餐厅场景中提高人机交互准确性和效率的目标。通过实验和评估，证明了这种集成可以使WALL-E成为一位更有能力和智能的机器人服务员。

    

    让机器人能够理解语言指令并根据视觉感知做出反应一直以来都是机器人研究界的一个长期目标。实现这一目标需要在自然语言处理、计算机视觉和机器人工程方面取得前沿进展。因此，本文主要研究了将最新的大型语言模型（LLMs）与现有的视觉定位和机器人抓取系统集成以增强人机交互效果的潜力。我们以WALL-E（具有大型语言模型的实体机器人服务员举重）作为集成的示例。系统利用ChatGPT的LLM通过多轮交互式对话将用户的偏好物体总结为目标指令。然后将目标指令传递给视觉定位系统进行物体姿势和大小估计，然后机器人相应地抓取物体。我们将这个LLM增强系统部署在

    Enabling robots to understand language instructions and react accordingly to visual perception has been a long-standing goal in the robotics research community. Achieving this goal requires cutting-edge advances in natural language processing, computer vision, and robotics engineering. Thus, this paper mainly investigates the potential of integrating the most recent Large Language Models (LLMs) and existing visual grounding and robotic grasping system to enhance the effectiveness of the human-robot interaction. We introduce the WALL-E (Embodied Robotic WAiter load lifting with Large Language model) as an example of this integration. The system utilizes the LLM of ChatGPT to summarize the preference object of the users as a target instruction via the multi-round interactive dialogue. The target instruction is then forwarded to a visual grounding system for object pose and size estimation, following which the robot grasps the object accordingly. We deploy this LLM-empowered system on the
    
[^24]: 周期性排斥学习

    Cyclophobic Reinforcement Learning. (arXiv:2308.15911v1 [cs.LG])

    [http://arxiv.org/abs/2308.15911](http://arxiv.org/abs/2308.15911)

    本文提出一种新的周期性排斥增强学习方法，通过避免循环来惩罚冗余而不奖励新颖性，在奖励稀疏的环境中能取得优异的结果。

    

    在奖励稀疏的环境中，寻找良好的归纳偏差以促进探索对于智能体的成功至关重要。然而，存在着两个竞争的目标：新颖性搜索和系统性探索。现有的方法，如好奇心驱动的探索，可以找到新颖性，但有时不会对整个状态空间进行系统性的探索，类似于深度优先搜索与广度优先搜索。在本文中，我们提出了一种新的内在奖励，即周期性排斥型，它不会奖励新颖性，而是通过避免循环来惩罚冗余。通过将周期性排斥的内在奖励与基于智能体裁剪观测的分层表示序列相结合，我们在MiniGrid和MiniHack环境中取得了极好的结果。这两个环境都特别难以解决，因为它们需要与不同对象进行复杂的交互才能解决。与先前方法的详细比较和彻底的消融研究表明，我们新提出的周期性排斥增强学习方法在这些环境中表现出色。

    In environments with sparse rewards, finding a good inductive bias for exploration is crucial to the agent's success. However, there are two competing goals: novelty search and systematic exploration. While existing approaches such as curiosity-driven exploration find novelty, they sometimes do not systematically explore the whole state space, akin to depth-first-search vs breadth-first-search. In this paper, we propose a new intrinsic reward that is cyclophobic, i.e., it does not reward novelty, but punishes redundancy by avoiding cycles. Augmenting the cyclophobic intrinsic reward with a sequence of hierarchical representations based on the agent's cropped observations we are able to achieve excellent results in the MiniGrid and MiniHack environments. Both are particularly hard, as they require complex interactions with different objects in order to be solved. Detailed comparisons with previous approaches and thorough ablation studies show that our newly proposed cyclophobic reinforc
    
[^25]: 美国法律体系是否准备好应对人工智能对人类价值观的挑战？

    Is the U.S. Legal System Ready for AI's Challenges to Human Values?. (arXiv:2308.15906v1 [cs.CY])

    [http://arxiv.org/abs/2308.15906](http://arxiv.org/abs/2308.15906)

    美国法律需要加强应对生成式人工智能对人类价值观挑战的能力，并提供积极、可审计的指导，以填补现有法律框架在保护基本价值观方面的空白和不确定性。

    

    我们的跨学科研究调查了美国法律在面对生成式人工智能对人类价值观挑战时的有效性。通过分析专家研讨会期间制定的多种假设情景，我们发现现有法律框架在保护自主权、隐私权、尊严、多样性、平等以及身心健康等基本价值观方面存在明显的空白和不确定性。宪法和民权法似乎无法对人工智能生成的歧视性产出提供足够的保护。此外，即使我们排除第230条款提供的责任保护，由于人工智能系统的复杂和不透明性，证明诽谤和产品责任索赔的因果关系也是一项具有挑战性的任务。为了应对生成式人工智能带来的独特和难以预测的威胁，我们主张建立能够适应新威胁并为行业利益相关者提供积极、可审计的指导的法律框架。

    Our interdisciplinary study investigates how effectively U.S. laws confront the challenges posed by Generative AI to human values. Through an analysis of diverse hypothetical scenarios crafted during an expert workshop, we have identified notable gaps and uncertainties within the existing legal framework regarding the protection of fundamental values, such as autonomy, privacy, dignity, diversity, equality, and physical/mental well-being. Constitutional and civil rights, it appears, may not provide sufficient protection against AI-generated discriminatory outputs. Furthermore, even if we exclude the liability shield provided by Section 230, proving causation for defamation and product liability claims is a challenging endeavor due to the intricate and opaque nature of AI systems. To address the unique and unforeseeable threats posed by Generative AI, we advocate for legal frameworks that evolve to recognize new threat and provide proactive, auditable guidelines to industry stakeholders
    
[^26]: 通过自主量子热机实现热力学计算

    Thermodynamic Computing via Autonomous Quantum Thermal Machines. (arXiv:2308.15905v1 [quant-ph])

    [http://arxiv.org/abs/2308.15905](http://arxiv.org/abs/2308.15905)

    通过自主量子热机实现了热力学计算模型。通过热流进行计算，可实现任何线性可分离函数，并可扩展到神经元网络执行任何 needed功能。

    

    我们基于自主量子热机开发了一个基于物理的模型，用于经典计算。这些机器由少数相互作用的量子位（qubits）与不同温度的几个环境相连。通过机器的热流进行计算。过程从根据逻辑输入设定环境温度开始。机器演化，最终达到非平衡稳态，通过辅助有限尺寸储存池的温度可以确定计算结果。这样的机器，我们称之为“热力学神经元”，可以实现任何线性可分离函数，我们明确讨论了NOT，3-majority和NOR门的情况。反过来，我们展示了热力学神经元网络可以执行任何需要的函数。我们讨论了我们的模型与人工神经元（感知器）之间的密切关系，并认为我们的模型提供了一种基于物理的替代方法。

    We develop a physics-based model for classical computation based on autonomous quantum thermal machines. These machines consist of few interacting quantum bits (qubits) connected to several environments at different temperatures. Heat flows through the machine are here exploited for computing. The process starts by setting the temperatures of the environments according to the logical input. The machine evolves, eventually reaching a non-equilibrium steady state, from which the output of the computation can be determined via the temperature of an auxilliary finite-size reservoir. Such a machine, which we term a "thermodynamic neuron", can implement any linearly-separable function, and we discuss explicitly the cases of NOT, 3-majority and NOR gates. In turn, we show that a network of thermodynamic neurons can perform any desired function. We discuss the close connection between our model and artificial neurons (perceptrons), and argue that our model provides an alternative physics-based
    
[^27]: 可解释性答案集编程

    Explainable Answer-set Programming. (arXiv:2308.15901v1 [cs.AI])

    [http://arxiv.org/abs/2308.15901](http://arxiv.org/abs/2308.15901)

    这篇论文研究了可解释性答案集编程，该编程方法在许多领域中广泛应用，并提出了对ASP解决方案的解释方法。

    

    人工智能（AI）中的可解释性问题由于AI在我们的生活中几乎无处不在，以及AI系统的日益复杂而变得越来越受关注。答案集编程（ASP）在许多领域中被使用，其中包括工业优化、知识管理或生命科学，因此在可解释性的背景下具有极大的兴趣。为了确保ASP作为未来的问题解决范式的成功应用，研究ASP解决方案的解释至关重要。这样的解释试图回答为什么某个决策产生了或者为什么某个问题的解决方案是什么的问题。虽然目前存在一些ASP的解释方法，但几乎所有方法都缺乏对实践中使用的某些语言特性的支持。特别是，它们缺乏对近年来开发的用于在理论、外部通信等方面进行推理的各种ASP扩展的支持。

    The interest in explainability in artificial intelligence (AI) is growing vastly due to the near ubiquitous state of AI in our lives and the increasing complexity of AI systems. Answer-set Programming (ASP) is used in many areas, among them are industrial optimisation, knowledge management or life sciences, and thus of great interest in the context of explainability. To ensure the successful application of ASP as a problem-solving paradigm in the future, it is thus crucial to investigate explanations for ASP solutions. Such an explanation generally tries to give an answer to the question of why something is, respectively is not, part of the decision produced or solution to the formulated problem. Although several explanation approaches for ASP exist, almost all of them lack support for certain language features that are used in practice. Most notably, this encompasses the various ASP extensions that have been developed in the recent years to enable reasoning over theories, external com
    
[^28]: 超越传统神经网络：通过计算逻辑技术增加推理和学习能力

    Beyond Traditional Neural Networks: Toward adding Reasoning and Learning Capabilities through Computational Logic Techniques. (arXiv:2308.15899v1 [cs.AI])

    [http://arxiv.org/abs/2308.15899](http://arxiv.org/abs/2308.15899)

    通过计算逻辑技术，本研究提出了一种超越传统神经网络的方法，将神经网络和符号推理相结合，解决了深度学习模型在高质量训练数据、透明性和鲁棒性方面的限制。同时，通过改进知识注入过程，将机器学习和逻辑元素融入多主体系统。

    

    深度学习（DL）模型已经成为解决复杂问题的常用方法，但它们存在一些限制，如需要高质量的训练数据、缺乏透明性和鲁棒性问题。神经符号人工智能已经成为一种有希望的方法，将神经网络和符号推理的优势结合起来。符号知识注入（SKI）技术是一种将符号知识融入子符号系统的流行方法。本文提出了改进知识注入过程并将机器学习和逻辑元素融入多主体系统（MAS）的解决方案。

    Deep Learning (DL) models have become popular for solving complex problems, but they have limitations such as the need for high-quality training data, lack of transparency, and robustness issues. Neuro-Symbolic AI has emerged as a promising approach combining the strengths of neural networks and symbolic reasoning. Symbolic knowledge injection (SKI) techniques are a popular method to incorporate symbolic knowledge into sub-symbolic systems. This work proposes solutions to improve the knowledge injection process and integrate elements of ML and logic into multi-agent systems (MAS).
    
[^29]: 基于ASP的数据生成文本处理的xAI方法

    An xAI Approach for Data-to-Text Processing with ASP. (arXiv:2308.15898v1 [cs.AI])

    [http://arxiv.org/abs/2308.15898](http://arxiv.org/abs/2308.15898)

    本文提出了一个基于ASP的框架，用于从数据生成自然语言文本，具备明确控制准确性错误和合成量的能力，采用逻辑规则逐步丰富文本描述。

    

    从数据序列生成自然语言文本在人工智能研究目标中重新引起了关注。不出所料，现有技术中的少数提议是基于训练系统以产生描述数据且与输入数据一致的文本。这些方法面临的主要挑战是恰确地确定要说的内容（在数据中要描述的关键元素）以及如何表达：数据和文本之间的对应准确性，文本中可能存在的矛盾/冗余，合成量的控制。本文提出了一个符合xAI要求的框架。特别地，我们建模ASP/Python程序，以确保对准确性错误和合成量进行明确的控制，并提供了证明最优解的解决方案。文本描述以层次结构组织，在自顶向下的结构中，文本会根据逻辑规则补充更多细节。

    The generation of natural language text from data series gained renewed interest among AI research goals. Not surprisingly, the few proposals in the state of the art are based on training some system, in order to produce a text that describes and that is coherent to the data provided as input. Main challenges of such approaches are the proper identification of "what" to say (the key descriptive elements to be addressed in the data) and "how" to say: the correspondence and accuracy between data and text, the presence of contradictions/redundancy in the text, the control of the amount of synthesis.  This paper presents a framework that is compliant with xAI requirements. In particular we model ASP/Python programs that enable an explicit control of accuracy errors and amount of synthesis, with proven optimal solutions. The text description is hierarchically organized, in a top-down structure where text is enriched with further details, according to logic rules. The generation of natural l
    
[^30]: Nemo: 首个全新规则引擎的初次披露

    Nemo: First Glimpse of a New Rule Engine. (arXiv:2308.15897v1 [cs.AI])

    [http://arxiv.org/abs/2308.15897](http://arxiv.org/abs/2308.15897)

    Nemo是一个全新的、注重可靠性和性能的逻辑编程引擎，通过数据中心的分析计算，使用了完全声明式的Datalog方言，具有出色的可扩展性。

    

    这个系统演示介绍了Nemo，一个注重可靠性和性能的新型逻辑编程引擎。Nemo专注于数据中心的分析计算，在完全声明式的Datalog方言中建模。对于这些任务，Nemo的可扩展性与或超过领先的Datalog系统。我们演示了在笔记本上使用10^5到10^8个输入事实进行知识图谱和本体推理的应用。Nemo使用Rust编写，并作为一个免费开源工具提供。

    This system demonstration presents Nemo, a new logic programming engine with a focus on reliability and performance. Nemo is built for data-centric analytic computations, modelled in a fully declarative Datalog dialect. Its scalability for these tasks matches or exceeds that of leading Datalog systems. We demonstrate uses in reasoning with knowledge graphs and ontologies with 10^5 to 10^8 input facts, all on a laptop. Nemo is written in Rust and available as a free and open source tool.
    
[^31]: 评估半自动驾驶车辆中的驾驶员情境感知: 基于ASP的驾驶动力学特征建模场景解释和投影

    Assessing Drivers' Situation Awareness in Semi-Autonomous Vehicles: ASP based Characterisations of Driving Dynamics for Modelling Scene Interpretation and Projection. (arXiv:2308.15895v1 [cs.AI])

    [http://arxiv.org/abs/2308.15895](http://arxiv.org/abs/2308.15895)

    构建了一个软硬件框架来评估驾驶员对情况的感知，并提供以人为中心的辅助，以帮助建立情境感知。

    

    半自动驾驶作为已经可用并且将来会更加普及的技术，需要驾驶员和自动化系统可靠地合作以确保安全驾驶。在这个努力中的一个特别挑战是当车辆自动化无法驾驶并要求人员接管时。在这些情况下，驾驶员必须快速认识到交通情况，才能接管并安全驾驶汽车。在这个背景下，我们提出了一个软件和硬件框架来评估驾驶员对情况的认知，并提供以人为中心的辅助，以帮助建立情境感知。该框架是在机器人操作系统(ROS)内以模块化系统的形式开发的，包括感知环境和驾驶员状态的模块，建模驾驶员情境感知的模块，以及使用专门的人机界面指导驾驶员注意力的模块。

    Semi-autonomous driving, as it is already available today and will eventually become even more accessible, implies the need for driver and automation system to reliably work together in order to ensure safe driving. A particular challenge in this endeavour are situations in which the vehicle's automation is no longer able to drive and is thus requesting the human to take over. In these situations the driver has to quickly build awareness for the traffic situation to be able to take over control and safely drive the car. Within this context we present a software and hardware framework to asses how aware the driver is about the situation and to provide human-centred assistance to help in building situation awareness. The framework is developed as a modular system within the Robot Operating System (ROS) with modules for sensing the environment and the driver state, modelling the driver's situation awareness, and for guiding the driver's attention using specialized Human Machine Interfaces
    
[^32]: 在共同设计环境中运用逻辑编程的方法解决全球物流问题

    A Logic Programming Approach to Global Logistics in a Co-Design Environment. (arXiv:2308.15892v1 [cs.AI])

    [http://arxiv.org/abs/2308.15892](http://arxiv.org/abs/2308.15892)

    本文提出了一种利用逻辑编程方法解决共同设计环境中全球物流问题的方法，旨在通过与产品同时开发工业系统，提高其韧性并降低供应链瓶颈的风险。

    

    在共同设计环境中，需要快速且自动地集成变更。本文探讨了在共同设计方法下创建和优化用于客机制造的全球物流系统的挑战，考虑关键绩效指标（如成本、时间或韧性）。所讨论的产品是一架客机，由多个组件组成，分别在全球多个地点制造。目标是找到一种最优的方式来建造该飞机，同时考虑其工业系统的需求。解决这一挑战的主要动机是与产品同时开发工业系统，并使其更具韧性以应对意外事件，降低供应链瓶颈的风险。这种风险降低保证了持续的效率和运营成功。为了解决这一具有挑战性和复杂性的任务，我们选择了Answer Set Programming（ASP）作为建模语言，对问题进行形式化。

    In a co-design environment changes need to be integrated quickly and in an automated manner. This paper considers the challenge of creating and optimizing a global logistics system for the construction of a passenger aircraft within a co-design approach with respect to key performance indicators (like cost, time or resilience). The product in question is an aircraft, comprised of multiple components, manufactured at multiple sites worldwide. The goal is to find an optimal way to build the aircraft taking into consideration the requirements for its industrial system. The main motivation for approaching this challenge is to develop the industrial system in tandem with the product and making it more resilient against unforeseen events, reducing the risks of bottlenecks in the supply chain. This risk reduction ensures continued efficiency and operational success. To address this challenging and complex task we have chosen Answer Set Programming (ASP) as the modeling language, formalizing t
    
[^33]: 了解ProbLog作为概率论证的概率论

    Understanding ProbLog as Probabilistic Argumentation. (arXiv:2308.15891v1 [cs.AI])

    [http://arxiv.org/abs/2308.15891](http://arxiv.org/abs/2308.15891)

    在这篇论文中，我们研究了ProbLog和概率论证之间的关系，发现了ProbLog是Probabilistic Abstract Argumentation (PAA)的一种形式的实例，并为ProbLog提供了使用PAA/PABA的替代语义的可能性，以及为PAA/PABA获得新的论证语义的可能性。这些结果还为ProbLog的输出提供了新形式的论证性解释的可能性。

    

    ProbLog是一种流行的概率逻辑编程语言/工具，广泛应用于需要处理结构化领域内固有不确定性的应用。本文研究了ProbLog与另一种结合了符号推理和不确定推理的知名形式主义变体，即概率论证之间的关系。具体而言，我们展示了ProbLog是Probabilistic Abstract Argumentation (PAA)的一种形式的实例，PAA是基于假设的论证（ABA）构建的。这些联系为ProbLog提供了使用PAA/PABA的替代语义的可能性，并为PAA/PABA获得新的论证语义铺平了道路，其利用了ProbLog与论证之间的先前联系。此外，这些联系为ProbLog的输出提供了新形式的论证性解释的可能性。

    ProbLog is a popular probabilistic logic programming language/tool, widely used for applications requiring to deal with inherent uncertainties in structured domains. In this paper we study connections between ProbLog and a variant of another well-known formalism combining symbolic reasoning and reasoning under uncertainty, i.e. probabilistic argumentation. Specifically, we show that ProbLog is an instance of a form of Probabilistic Abstract Argumentation (PAA) that builds upon Assumption-Based Argumentation (ABA). The connections pave the way towards equipping ProbLog with alternative semantics, inherited from PAA/PABA, as well as obtaining novel argumentation semantics for PAA/PABA, leveraging on prior connections between ProbLog and argumentation. Further, the connections pave the way towards novel forms of argumentative explanations for ProbLog's outputs.
    
[^34]: Natlog: 将逻辑编程嵌入Python深度学习生态系统

    Natlog: Embedding Logic Programming into the Python Deep-Learning Ecosystem. (arXiv:2308.15890v1 [cs.AI])

    [http://arxiv.org/abs/2308.15890](http://arxiv.org/abs/2308.15890)

    Natlog通过高级交互模式和多种功能的连接，将逻辑编程嵌入到Python深度学习生态系统中，实现了逻辑语言结构对Python生态系统的完全访问能力。

    

    受到Python和我们基于Python的嵌入式逻辑语言Natlog的表达力共性的驱动，我们设计了两者之间的等效语言结构和数据类型的高级交互模式。通过直接连接生成器和回溯、嵌套元组和术语、协程和一流逻辑引擎、反射和元解释，我们使逻辑语言结构能够访问Python生态系统的全部能力。我们通过Natlog应用程序作为JAX和Pytorch管道的编排器以及作为DCG驱动的GPT3和DALL.E提示生成器展示了我们设计的有效性。

    Driven by expressiveness commonalities of Python and our Python-based embedded logic-based language Natlog, we design high-level interaction patterns between equivalent language constructs and data types on the two sides.  By directly connecting generators and backtracking, nested tuples and terms, coroutines and first-class logic engines, reflection and meta-interpretation, we enable logic-based language constructs to access the full power of the Python ecosystem.  We show the effectiveness of our design via Natlog apps working as orchestrators for JAX and Pytorch pipelines and as DCG-driven GPT3 and DALL.E prompt generators.  Keyphrases: embedding of logic programming in the Python ecosystem, high-level inter-paradigm data exchanges, coroutining with logic engines, logic-based neuro-symbolic computing, logic grammars as prompt-generators for Large Language Models, logic-based neural network configuration and training.
    
[^35]: 广义化级别排名约束用于单调和凸聚合

    Generalizing Level Ranking Constraints for Monotone and Convex Aggregates. (arXiv:2308.15888v1 [cs.LO])

    [http://arxiv.org/abs/2308.15888](http://arxiv.org/abs/2308.15888)

    这项工作通过将级别排名约束重写为保持单调和凸聚合结构的一般形式，提供了一种统一的解决方案，以覆盖ASP的聚合扩展。

    

    在答案集规划中，答案集捕捉到了对搜索问题的解决方案，因此高效计算答案集是非常重要的。一种可行的实现策略是基于转换的ASP，其中逻辑程序被转换为其他知识表示形式，如布尔可满足性（SAT），SAT模理论（SMT）和混合整数规划（MIP）。因此，现有的求解器可以用于计算答案集。现有的许多转换依赖于程序完成和级别排名来捕捉答案集的最小性和默认否定的正确性。在这项工作中，我们重新考虑级别排名约束，旨在对ASP的基于聚合的扩展进行更系统化的一般化。通过应用一些程序转换，可以将排名约束重写为保持单调和凸聚合结构的一般形式，从而提供了一种统一的解决方案。

    In answer set programming (ASP), answer sets capture solutions to search problems of interest and thus the efficient computation of answer sets is of utmost importance. One viable implementation strategy is provided by translation-based ASP where logic programs are translated into other KR formalisms such as Boolean satisfiability (SAT), SAT modulo theories (SMT), and mixed-integer programming (MIP). Consequently, existing solvers can be harnessed for the computation of answer sets. Many of the existing translations rely on program completion and level rankings to capture the minimality of answer sets and default negation properly. In this work, we take level ranking constraints into reconsideration, aiming at their generalizations to cover aggregate-based extensions of ASP in more systematic way. By applying a number of program transformations, ranking constraints can be rewritten in a general form that preserves the structure of monotone and convex aggregates and thus offers a unifor
    
[^36]: 对于组合逻辑推理的 CLIP 潜力的研究

    On the Potential of CLIP for Compositional Logical Reasoning. (arXiv:2308.15887v1 [cs.AI])

    [http://arxiv.org/abs/2308.15887](http://arxiv.org/abs/2308.15887)

    本文研究了使用CLIP进行组合逻辑推理的潜力，并发现通常配置的CLIP无法进行这种推理。

    

    在本文中，我们探讨了使用OpenAI的CLIP进行逻辑连贯的视觉推理的可能性。为此，我们形式化了我们的术语，并对CLIP潜在空间中的嵌入进行了几何分析，以便系统在逻辑上连贯。我们的主要结论是，通常配置的CLIP不能进行这种推理。

    In this paper we explore the possibility of using OpenAI's CLIP to perform logically coherent grounded visual reasoning. To that end, we formalize our terms and give a geometric analysis of how embeddings in CLIP's latent space would need to be configured in order for the system to be logically coherent. Our main conclusion is that, as usually configured, CLIP cannot perform such reasoning.
    
[^37]: 如果我处于AI中，生活会更有趣吗？基于概率归纳逻辑编程回答反事实问题

    "Would life be more interesting if I were in AI?" Answering Counterfactuals based on Probabilistic Inductive Logic Programming. (arXiv:2308.15883v1 [cs.LO])

    [http://arxiv.org/abs/2308.15883](http://arxiv.org/abs/2308.15883)

    该论文提出了一种使用概率归纳逻辑编程回答反事实问题的方法，在学习程序结构时考虑了因果机制，使得可以进行反事实推理。

    

    概率逻辑程序是一种某些事实以特定概率成立的逻辑程序。在这里，我们使用因果框架来研究这些程序，使其能够回答反事实查询。通常通过启发式搜索和统计测试来从观测数据中学习程序结构。然而，这些统计测试缺乏关于生成数据的因果机制的信息，使得使用生成的程序进行反事实推理变得不可行。为了解决这个问题，我们提出了一种语言片段，允许从其引导分布中重建程序。这进一步使我们能够学习支持反事实查询的程序。

    Probabilistic logic programs are logic programs where some facts hold with a specified probability. Here, we investigate these programs with a causal framework that allows counterfactual queries. Learning the program structure from observational data is usually done through heuristic search relying on statistical tests. However, these statistical tests lack information about the causal mechanism generating the data, which makes it unfeasible to use the resulting programs for counterfactual reasoning. To address this, we propose a language fragment that allows reconstructing a program from its induced distribution. This further enables us to learn programs supporting counterfactual queries.
    
[^38]: Answer Set Programming的解释

    Explanations for Answer Set Programming. (arXiv:2308.15879v1 [cs.AI])

    [http://arxiv.org/abs/2308.15879](http://arxiv.org/abs/2308.15879)

    本文介绍了对Answer Set Programming (ASP)进行解释的系统xASP的改进版本xASP2，它支持了更多的clingo构造并能够以有向无环图的形式呈现解释。

    

    本文介绍了对Answer Set Programming (ASP)进行解释的系统xASP的改进版本xASP2。与xASP不同，新系统xASP2支持不同的clingo构造，如选择规则、约束和聚合函数，如#sum、#min。该工作形式化并呈现了一个可解释的人工智能系统，适用于ASP的广泛片段，能够尽可能地缩小假设集，并以有向无环图的形式呈现解释。

    The paper presents an enhancement of xASP, a system that generates explanation graphs for Answer Set Programming (ASP). Different from xASP, the new system, xASP2, supports different clingo constructs like the choice rules, the constraints, and the aggregates such as #sum, #min. This work formalizes and presents an explainable artificial intelligence system for a broad fragment of ASP, capable of shrinking as much as possible the set of assumptions and presenting explanations in terms of directed acyclic graphs.
    
[^39]: 通过ASP实现ABA学习

    ABA Learning via ASP. (arXiv:2308.15877v1 [cs.AI])

    [http://arxiv.org/abs/2308.15877](http://arxiv.org/abs/2308.15877)

    该论文通过使用ASP实现ABA学习的方法提出了一种新颖的符号机器学习方法，用于从背景知识和正负例中绘制基于假设的论证框架。

    

    最近，ABA学习被提出作为一种符号机器学习方法，用于从背景知识和正负例中绘制基于假设的论证框架。我们提出了一种新颖的方法，使用Answer Set Programming来实现ABA学习，以帮助指导ABA学习中的记忆学习和泛化过程。

    Recently, ABA Learning has been proposed as a form of symbolic machine learning for drawing Assumption-Based Argumentation frameworks from background knowledge and positive and negative examples. We propose a novel method for implementing ABA Learning using Answer Set Programming as a way to help guide Rote Learning and generalisation in ABA Learning.
    
[^40]: ASP中的弱约束下的道义悖论

    Deontic Paradoxes in ASP with Weak Constraints. (arXiv:2308.15870v1 [cs.LO])

    [http://arxiv.org/abs/2308.15870](http://arxiv.org/abs/2308.15870)

    本文通过使用Answer Set Programming（ASP）和弱约束，解决了道义逻辑面临的悖论问题，并提出了一种方法来翻译带有弱约束的ASP中的道义系统，应用于"道德"版本的Pac-man取得了较好的结果。

    

    强大的人工智能技术的崛起使得对遵守法律、社会和伦理准则敏感的各种应用需求决策支持。道义推理是道义逻辑的领域，它面临着众所周知的基准问题（道义悖论），并且缺乏有效的计算工具。本文使用Answer Set Programming（ASP）来解决这些问题，并展示了如何使用弱约束对几个众所周知的道义悖论进行编码和解决。通过对这种编码进行抽象和概括，我们提出了一种在带有弱约束的ASP中翻译道义系统的方法论。我们将这种方法应用于"道德"版本的Pac-man，结果表明我们获得了与相关工作相当的性能，并且获得了道德上更可取的结果。

    The rise of powerful AI technology for a range of applications that are sensitive to legal, social, and ethical norms demands decision-making support in presence of norms and regulations. Normative reasoning is the realm of deontic logics, that are challenged by well-known benchmark problems (deontic paradoxes), and lack efficient computational tools. In this paper, we use Answer Set Programming (ASP) for addressing these shortcomings and showcase how to encode and resolve several well-known deontic paradoxes utilizing weak constraints. By abstracting and generalizing this encoding, we present a methodology for translating normative systems in ASP with weak constraints. This methodology is applied to "ethical" versions of Pac-man, where we obtain a comparable performance with related works, but ethically preferable results.
    
[^41]: 关于概率逻辑程序结构中隐藏的独立性

    On the Independencies Hidden in the Structure of a Probabilistic Logic Program. (arXiv:2308.15865v1 [cs.LO])

    [http://arxiv.org/abs/2308.15865](http://arxiv.org/abs/2308.15865)

    该论文推广了基于贝叶斯网络的条件独立性推理方法，并提出了一种用于判断非ground情况下的条件独立性陈述的方法。实验评估证明了该方法的有效性。

    

    Pearl和Verma开发了d-分离，作为一种广泛使用的图形准则，用于推理由贝叶斯网络的因果结构所暗示的条件独立性。由于无环的基于概率的逻辑程序对应于其依赖图上的贝叶斯网络，因此我们可以从后者的d-分离中计算条件独立性。在本文中，我们将上述推理推广到非ground情况。首先，我们将概率逻辑程序的概念抽象出来，摒弃外部数据库和概率，得到所谓的程序结构。然后，我们提出了一个正确的元解释器，用于判断在给定外部数据库上是否由程序结构进一步暗示了某个特定的条件独立性陈述。最后，我们给出了程序结构的一个片段，对于这个片段，我们得到了一个关于条件独立性预言的完备性陈述。我们通过实验评估我们的方法，揭示了我们的元解释器的性能。

    Pearl and Verma developed d-separation as a widely used graphical criterion to reason about the conditional independencies that are implied by the causal structure of a Bayesian network. As acyclic ground probabilistic logic programs correspond to Bayesian networks on their dependency graph, we can compute conditional independencies from d-separation in the latter.  In the present paper, we generalize the reasoning above to the non-ground case. First, we abstract the notion of a probabilistic logic program away from external databases and probabilities to obtain so-called program structures. We then present a correct meta-interpreter that decides whether a certain conditional independence statement is implied by a program structure on a given external database. Finally, we give a fragment of program structures for which we obtain a completeness statement of our conditional independence oracle. We close with an experimental evaluation of our approach revealing that our meta-interpreter 
    
[^42]: 用于ASP的声明性领域特定启发式算法的归纳式学习

    Inductive Learning of Declarative Domain-Specific Heuristics for ASP. (arXiv:2308.15863v1 [cs.AI])

    [http://arxiv.org/abs/2308.15863](http://arxiv.org/abs/2308.15863)

    本文介绍了一种用于自动学习声明性领域特定启发式算法的新方法。实验结果表明，学习到的启发式算法可以提高求解性能和解的质量。

    

    领域特定启发式算法是解决大规模或计算困难问题的重要技术。答案集规划（ASP）系统支持声明性的领域特定启发式算法以提高求解性能。然而，目前这些启发式算法必须手动发明。为了为答案集程序发明领域特定的启发式算法，需要对所考虑领域有专业知识，并熟悉ASP的语法、语义和求解技术。自动化支持会极大地改善发明有用启发式算法的过程。本文提出了一种自动学习这些启发式算法的新方法。我们使用归纳逻辑编程（ILP）从小而具有代表性的问题实例的（近似）最优答案集的示例中学习声明性的领域特定启发式算法。实验结果表明，这些学习到的启发式算法在求解大规模问题时可以提高求解性能和解的质量。

    Domain-specific heuristics are a crucial technique for the efficient solving of problems that are large or computationally hard. Answer Set Programming (ASP) systems support declarative specifications of domain-specific heuristics to improve solving performance. However, such heuristics must be invented manually so far. Inventing domain-specific heuristics for answer-set programs requires expertise with the domain under consideration and familiarity with ASP syntax, semantics, and solving technology. The process of inventing useful heuristics would highly profit from automatic support. This paper presents a novel approach to the automatic learning of such heuristics. We use Inductive Logic Programming (ILP) to learn declarative domain-specific heuristics from examples stemming from (near-)optimal answer sets of small but representative problem instances. Our experimental results indicate that the learned heuristics can improve solving performance and solution quality when solving large
    
[^43]: 图像属性编辑的零样本反演过程与扩散模型

    Zero-shot Inversion Process for Image Attribute Editing with Diffusion Models. (arXiv:2308.15854v1 [cs.CV])

    [http://arxiv.org/abs/2308.15854](http://arxiv.org/abs/2308.15854)

    提出了一种零样本反演过程（ZIP）框架，用于图像属性编辑。该方法利用生成的视觉参考和文本引导注入扩散模型的语义潜空间，可以在文本提示的直观控制下产生多样的内容和属性，并展现出对不同属性操作的鲁棒性。

    

    降噪扩散模型在图像编辑中表现出优秀的性能。现有的方法倾向于使用图像引导方法，提供视觉参考但缺乏语义连贯性的控制，或者使用文本引导方法，确保对文本引导的忠实，但缺乏视觉质量。为了解决这个问题，我们提出了零样本反演过程（ZIP）框架，它将生成的视觉参考和文本引导的融合注入到预训练扩散模型的语义潜空间中。仅使用一个微小的神经网络，提出的ZIP在文本提示的直观控制下产生多样的内容和属性。此外，ZIP在真实图像上展示了对域内和域外属性操作的显著鲁棒性。我们在各种基准数据集上进行了详细的实验。与最先进的方法相比，ZIP产生了与之相当质量的图像，同时提供了逼真的编辑效果。

    Denoising diffusion models have shown outstanding performance in image editing. Existing works tend to use either image-guided methods, which provide a visual reference but lack control over semantic coherence, or text-guided methods, which ensure faithfulness to text guidance but lack visual quality. To address the problem, we propose the Zero-shot Inversion Process (ZIP), a framework that injects a fusion of generated visual reference and text guidance into the semantic latent space of a \textit{frozen} pre-trained diffusion model. Only using a tiny neural network, the proposed ZIP produces diverse content and attributes under the intuitive control of the text prompt. Moreover, ZIP shows remarkable robustness for both in-domain and out-of-domain attribute manipulation on real images. We perform detailed experiments on various benchmark datasets. Compared to state-of-the-art methods, ZIP produces images of equivalent quality while providing a realistic editing effect.
    
[^44]: MSGNN: 多尺度时空图神经网络用于流行病预测

    MSGNN: Multi-scale Spatio-temporal Graph Neural Network for Epidemic Forecasting. (arXiv:2308.15840v1 [cs.LG])

    [http://arxiv.org/abs/2308.15840](http://arxiv.org/abs/2308.15840)

    MSGNN是一种多尺度时空图神经网络，通过创新的多尺度视图和图学习模块，有效地解决了现有GNN模型在保留远距离连接和多尺度流行病模式上的局限性。它在传染病预测中具有重要的应用价值。

    

    传染病预测是防控流行病的关键，并被证明具有重要性。最近的趋势是基于图神经网络（GNN）开发预测模型。然而，现有的基于GNN的方法存在两个关键限制：（1）当前模型通过缩放GNN的深度来扩大感受野，但这对于保留远距离但与流行病相关的地区之间的语义不足够。（2）以前的方法模拟单一空间尺度内的流行病，而忽视了不同尺度上导出的多尺度流行病模式。为了解决这些缺陷，我们设计了基于创新的多尺度视图的多尺度时空图神经网络（MSGNN）。具体来说，在提出的MSGNN模型中，我们首先设计了一个新颖的图学习模块，它直接捕捉跨区域流行病信号的远距离连接，并将它们集成到一个多尺度图中。基于学习的多尺度图，我们使用空间-时间GCN进行流行病预测。

    Infectious disease forecasting has been a key focus and proved to be crucial in controlling epidemic. A recent trend is to develop forecast-ing models based on graph neural networks (GNNs). However, existing GNN-based methods suffer from two key limitations: (1) Current models broaden receptive fields by scaling the depth of GNNs, which is insuffi-cient to preserve the semantics of long-range connectivity between distant but epidemic related areas. (2) Previous approaches model epidemics within single spatial scale, while ignoring the multi-scale epidemic pat-terns derived from different scales. To address these deficiencies, we devise the Multi-scale Spatio-temporal Graph Neural Network (MSGNN) based on an innovative multi-scale view. To be specific, in the proposed MSGNN model, we first devise a novel graph learning module, which directly captures long-range connectivity from trans-regional epidemic signals and integrates them into a multi-scale graph. Based on the learned multi-scal
    
[^45]: 基于数据驱动方法的电池性能深入分析

    Depth analysis of battery performance based on a data-driven approach. (arXiv:2308.15833v1 [cs.AI])

    [http://arxiv.org/abs/2308.15833](http://arxiv.org/abs/2308.15833)

    本论文利用机器学习技术研究了电池容量衰减问题，提出了WOA-ELM模型来解析电池性能关键因素，并克服了机器学习黑盒的缺陷。研究结果揭示了电极材料的结构损伤与电池故障之间的联系，对于电池研究和改进具有重要意义。

    

    容量衰减是当前电池应用中最棘手的问题之一。在整个系统中，电池的分解机制被认为非常复杂。充分理解这个过程并准确预测它是一个巨大的挑战。因此，本研究采用了机器学习技术来预测电池在循环过程中的特定容量变化，并了解这个复杂的过程。与之前的工作不同的是，根据本研究提出的WOA-ELM模型（R2 = 0.9999871），确定了影响电池特定容量的关键因素，并通过可解释的模型克服了机器学习黑盒的缺陷。它们与电极材料的结构损伤和电池在循环过程中的故障之间的联系得到了全面解释，揭示了它们对于电池性能的重要性，有利于对当代电池进行优秀的研究和改进。

    Capacity attenuation is one of the most intractable issues in the current of application of the cells. The disintegration mechanism is well known to be very complex across the system. It is a great challenge to fully comprehend this process and predict the process accurately. Thus, the machine learning (ML) technology is employed to predict the specific capacity change of the cell throughout the cycle and grasp this intricate procedure. Different from the previous work, according to the WOA-ELM model proposed in this work (R2 = 0.9999871), the key factors affecting the specific capacity of the battery are determined, and the defects in the machine learning black box are overcome by the interpretable model. Their connection with the structural damage of electrode materials and battery failure during battery cycling is comprehensively explained, revealing their essentiality to battery performance, which is conducive to superior research on contemporary batteries and modification.
    
[^46]: 早期使用深度学习对红棕象侵染进行声学信号分类的检测方法

    Early Detection of Red Palm Weevil Infestations using Deep Learning Classification of Acoustic Signals. (arXiv:2308.15829v1 [cs.CV])

    [http://arxiv.org/abs/2308.15829](http://arxiv.org/abs/2308.15829)

    本文提出了一种基于深度学习分类声学信号的红棕象侵染早期检测方法，可以解决栽培枣椰树中最具挑战性的问题之一。

    

    红棕象被认为是全球最具破坏性的棕榈树害虫之一。目前的检测技术包括使用视觉或声音检查以及化学检测受侵染棕榈树生成的挥发性特征的病症检测。然而，对于栽培枣椰树来说，及早检测红棕象病害被认为是最具挑战性的问题之一。本文提出了一种有效的红棕象早期检测方法。该方法基于记录和分析红棕象声音活动。第一步是根据选择的一组特征将声音数据转换成图像。第二步是将来自同一声音文件但由不同特征计算得出的图像组合成单个图像。第三步是应用不同的深度学习技术将结果图像分类为两类：受侵染和未受侵染。

    The Red Palm Weevil (RPW), also known as the palm weevil, is considered among the world's most damaging insect pests of palms. Current detection techniques include the detection of symptoms of RPW using visual or sound inspection and chemical detection of volatile signatures generated by infested palm trees. However, efficient detection of RPW diseases at an early stage is considered one of the most challenging issues for cultivating date palms. In this paper, an efficient approach to the early detection of RPW is proposed. The proposed approach is based on RPW sound activities being recorded and analyzed. The first step involves the conversion of sound data into images based on a selected set of features. The second step involves the combination of images from the same sound file but computed by different features into a single image. The third step involves the application of different Deep Learning (DL) techniques to classify resulting images into two classes: infested and not infes
    
[^47]: 具有自适应个性化层的联邦化两阶段解耦

    Federated Two Stage Decoupling With Adaptive Personalization Layers. (arXiv:2308.15821v1 [cs.LG])

    [http://arxiv.org/abs/2308.15821](http://arxiv.org/abs/2308.15821)

    该论文提出了一种具有自适应个性化层的联邦化两阶段解耦方法，通过将同质客户端聚类到同一组的方式来提高联邦学习的性能，并解决了数据异质性和聚类时间选择的问题。

    

    由于分布式设备间的数据异质性，联邦学习在保持隐私约束的同时实现分布式学习的突破性能力引起了广泛关注。然而，由于数据异质性导致了显著的学习降级和慢收敛速度。因此，自然地采用将同质客户端聚类到同一组的概念，只允许在每个组内聚合模型权重。尽管大多数现有的聚类联邦学习方法采用模型梯度或推理输出作为客户端分区的度量标准，目的是将相似设备组合在一起，但每个聚类内部仍可能存在异质性。此外，缺乏研究探索确定聚类的适当时间的根本原因，导致常见做法是将每个客户端分配到其自己的独立聚类中，特别是在高度非ind情况下。

    Federated learning has gained significant attention due to its groundbreaking ability to enable distributed learning while maintaining privacy constraints. However, as a consequence of data heterogeneity among decentralized devices, it inherently experiences significant learning degradation and slow convergence speed. Therefore, it is natural to employ the concept of clustering homogeneous clients into the same group, allowing only the model weights within each group to be aggregated. While most existing clustered federated learning methods employ either model gradients or inference outputs as metrics for client partitioning, with the goal of grouping similar devices together, may still have heterogeneity within each cluster. Moreover, there is a scarcity of research exploring the underlying reasons for determining the appropriate timing for clustering, resulting in the common practice of assigning each client to its own individual cluster, particularly in the context of highly non ind
    
[^48]: SharpSAT-TD在2021-2023模型计数竞赛中的应用

    SharpSAT-TD in Model Counting Competitions 2021-2023. (arXiv:2308.15819v1 [cs.AI])

    [http://arxiv.org/abs/2308.15819](http://arxiv.org/abs/2308.15819)

    SharpSAT-TD是基于SharpSAT的改进版本，在模型计数竞赛中获得了多个第一名，并引入了树分解的变量选择启发式算法。

    

    我们描述了SharpSAT-TD，我们提交到2021-2023模型计数竞赛的非加权和加权赛道的作品。它在比赛的不同赛道中共获得6次第一名。SharpSAT-TD基于SharpSAT [Thurley, SAT 2006]，其主要的创新修改是引入了作者在[CP 2021]中介绍的变量选择启发式算法中的树分解方法。与[CP 2021]中评估的SharpSAT-TD版本不同，目前在https://github.com/Laakeri/sharpsat-td上可用的版本与原始的SharpSAT相比也有其他重要的修改，例如添加了新的预处理器。

    We describe SharpSAT-TD, our submission to the unweighted and weighted tracks of the Model Counting Competition in 2021-2023, which has won in total $6$ first places in different tracks of the competition. SharpSAT-TD is based on SharpSAT [Thurley, SAT 2006], with the primary novel modification being the use of tree decompositions in the variable selection heuristic as introduced by the authors in [CP 2021]. Unlike the version of SharpSAT-TD evaluated in [CP 2021], the current version that is available in https://github.com/Laakeri/sharpsat-td features also other significant modifications compared to the original SharpSAT, for example, a new preprocessor.
    
[^49]: 透过偏好看大型语言模型的反馈获取：揭示对齐的重要性

    Peering Through Preferences: Unraveling Feedback Acquisition for Aligning Large Language Models. (arXiv:2308.15812v1 [cs.LG])

    [http://arxiv.org/abs/2308.15812](http://arxiv.org/abs/2308.15812)

    本研究分析了对于对齐和评估大型语言模型而言，设计反馈选择是评分还是排名对结果的影响。研究发现评分和排名所推断出的偏好存在不一致问题，并且注释者的偏见也会影响结果。同时，研究还发现反馈协议的选择也对评估结果有显著影响。

    

    大型语言模型（LLMs）与人类价值观和意图的对齐承诺涉及使用人工智能或人类反馈。稠密的反馈注释获取和整合成本较高，而稀疏的反馈则涉及结构性设计选择，即评分（例如，在1-7的范围内对回答A进行评分）和排名（例如，回答A是否比回答B更好？）。在这项工作中，我们分析了这种设计选择对LLMs的对齐和评估的影响。我们发现，评分和排名所推断出的偏好在人类和AI注释者中都存在严重的不一致问题，达到了60%。我们的后续分析确定了解释这个现象的各种注释者偏见方面，比如人类注释者更喜欢密集回答并在两个选项之间更青睐准确性。令我们惊讶的是，我们还观察到反馈协议的选择对对齐的LLMs的评估也有显著影响。特别是，我们发现LLMs的评估结果因为反馈协议的选择而有所不同。

    Aligning large language models (LLMs) with human values and intents critically involves the use of human or AI feedback. While dense feedback annotations are expensive to acquire and integrate, sparse feedback presents a structural design choice between ratings (e.g., score Response A on a scale of 1-7) and rankings (e.g., is Response A better than Response B?). In this work, we analyze the effect of this design choice for the alignment and evaluation of LLMs. We uncover an inconsistency problem wherein the preferences inferred from ratings and rankings significantly disagree 60% for both human and AI annotators. Our subsequent analysis identifies various facets of annotator biases that explain this phenomena, such as human annotators would rate denser responses higher while preferring accuracy during pairwise judgments. To our surprise, we also observe that the choice of feedback protocol also has a significant effect on the evaluation of aligned LLMs. In particular, we find that LLMs
    
[^50]: 在多代理系统中对鲁棒性和泛化性能进行基准测试: 以神经MMO为例的研究

    Benchmarking Robustness and Generalization in Multi-Agent Systems: A Case Study on Neural MMO. (arXiv:2308.15802v1 [cs.AI])

    [http://arxiv.org/abs/2308.15802](http://arxiv.org/abs/2308.15802)

    这篇论文介绍了第二届神经MMO挑战赛的研究结果，表明通过使用标准的强化学习方法和领域特定的工程技术，成功解决了多代理系统中的鲁棒性和泛化性能问题，并提出比赛作为解决困难问题和建立算法标准的有效方法。

    

    我们介绍了在IJCAI 2022举办的第二届神经MMO挑战赛的结果，共收到1600多个投稿。该比赛旨在测试多代理系统中的鲁棒性和泛化性能：参与者训练代理团队以完成在训练期间未见过的对手的多任务目标。比赛结合了相对复杂的环境设计与大量代理在环境中的运行。顶级投稿展示了使用主要基于强化学习（RL）方法和领域特定的工程相结合的方式，在这个任务上取得了很好的成绩。我们总结了比赛的设计和结果，并建议作为学术界，比赛可能是解决困难问题和建立算法稳健标准的一个强大方法。我们将开源我们的基准测试，包括环境封装器、基准源码、可视化工具和选定的策略，供进一步研究使用。

    We present the results of the second Neural MMO challenge, hosted at IJCAI 2022, which received 1600+ submissions. This competition targets robustness and generalization in multi-agent systems: participants train teams of agents to complete a multi-task objective against opponents not seen during training. The competition combines relatively complex environment design with large numbers of agents in the environment. The top submissions demonstrate strong success on this task using mostly standard reinforcement learning (RL) methods combined with domain-specific engineering. We summarize the competition design and results and suggest that, as an academic community, competitions may be a powerful approach to solving hard problems and establishing a solid benchmark for algorithms. We will open-source our benchmark including the environment wrapper, baselines, a visualization tool, and selected policies for further research.
    
[^51]: FedCiR: 客户端不变表示学习用于联邦非独立同分布特征

    FedCiR: Client-Invariant Representation Learning for Federated Non-IID Features. (arXiv:2308.15786v1 [cs.LG])

    [http://arxiv.org/abs/2308.15786](http://arxiv.org/abs/2308.15786)

    FedCiR是一种客户端不变表示学习框架，用于解决联邦学习中的特征偏移问题，通过改进表示和标签之间的互信息项来提取信息且与客户无关的特征。

    

    联邦学习（FL）是一种分布式学习范式，它在不共享原始数据的情况下最大化了边缘设备上数据驱动模型的潜力。然而，设备的数据往往是非独立同分布（non-IID）的，意味着它们的本地数据分布可能会有很大的差异。设备之间输入数据分布的异质性，通常称为特征偏移问题，可能会对全局模型的训练收敛性和准确性产生不利影响。为了分析特征偏移问题的内在原因，我们在FL中开发了一个广义误差边界，这激励我们提出了FedCiR，一种客户端不变表示学习框架，使客户能够提取信息且与客户无关的特征。具体而言，我们改进了表示和标签之间的互信息项，以鼓励表示携带基本的分类知识，并减小了客户端和表示之间的互信息项。

    Federated learning (FL) is a distributed learning paradigm that maximizes the potential of data-driven models for edge devices without sharing their raw data. However, devices often have non-independent and identically distributed (non-IID) data, meaning their local data distributions can vary significantly. The heterogeneity in input data distributions across devices, commonly referred to as the feature shift problem, can adversely impact the training convergence and accuracy of the global model. To analyze the intrinsic causes of the feature shift problem, we develop a generalization error bound in FL, which motivates us to propose FedCiR, a client-invariant representation learning framework that enables clients to extract informative and client-invariant features. Specifically, we improve the mutual information term between representations and labels to encourage representations to carry essential classification knowledge, and diminish the mutual information term between the client 
    
[^52]: ASTER: 面向口吃患者的自动语音识别系统可访问性测试

    ASTER: Automatic Speech Recognition System Accessibility Testing for Stutterers. (arXiv:2308.15742v1 [cs.SD])

    [http://arxiv.org/abs/2308.15742](http://arxiv.org/abs/2308.15742)

    ASTER是一种面向口吃患者的自动语音识别系统可访问性测试框架，提出了一种生成模拟口吃语音并用于测试和分析ASR系统性能的方法。

    

    当今自动语音识别（ASR）系统的普及性导致了对其可访问性的不断改善的需求。处理口吃的语音是可访问性ASR系统的重要特性。为了提高对口吃患者的ASR系统的可访问性，我们需要暴露和分析ASR系统在口吃语音上的失败。从口吃患者录制的语音数据集不足以暴露大部分的失败。此外，这些数据集缺乏关于非口吃文本的基本信息，使其不适合作为全面的测试套件。因此，需要提出一种生成模拟口吃语音并用于测试和分析ASR系统性能的方法。然而，在这种情况下，生成有效的测试输入是具有挑战性的。原因在于虽然生成的测试输入应该模仿口吃者的说话方式，但也应该具有足够的多样性以触发更多的失败。为了解决这个挑战，我们提出了ASTER，一个用于测试口吃者使用的自动语音识别系统的可访问性的测试框架。

    The popularity of automatic speech recognition (ASR) systems nowadays leads to an increasing need for improving their accessibility. Handling stuttering speech is an important feature for accessible ASR systems. To improve the accessibility of ASR systems for stutterers, we need to expose and analyze the failures of ASR systems on stuttering speech. The speech datasets recorded from stutterers are not diverse enough to expose most of the failures. Furthermore, these datasets lack ground truth information about the non-stuttered text, rendering them unsuitable as comprehensive test suites. Therefore, a methodology for generating stuttering speech as test inputs to test and analyze the performance of ASR systems is needed. However, generating valid test inputs in this scenario is challenging. The reason is that although the generated test inputs should mimic how stutterers speak, they should also be diverse enough to trigger more failures. To address the challenge, we propose ASTER, a te
    
[^53]: 高效且可解释的图神经网络架构搜索通过蒙特卡洛树搜索

    Efficient and Explainable Graph Neural Architecture Search via Monte-Carlo Tree Search. (arXiv:2308.15734v1 [cs.LG])

    [http://arxiv.org/abs/2308.15734](http://arxiv.org/abs/2308.15734)

    该论文提出了一种高效且可解释的图神经网络架构搜索方法，名为ExGNAS。它包括适应各种图形的简单搜索空间和能解释决策过程的搜索算法。通过蒙特卡洛树搜索高效地搜索最佳GNN架构。

    

    图神经网络（GNNs）是在各个领域进行数据科学任务的强大工具。尽管我们在广泛的应用场景中使用GNNs，但对研究人员和实践者来说，在不同的图中设计/选择最佳GNN架构是一项费力的任务。为了节省人力和计算成本，已经使用图神经网络架构搜索（Graph NAS）来搜索结合现有组件的次优GNN架构。然而，目前没有现有的Graph NAS方法能够同时满足可解释性、高效性和适应多样化图形的要求。因此，我们提出了一种高效且可解释的Graph NAS方法，称为ExGNAS，它包括（i）一个可以适应各种图形的简单搜索空间和（ii）一个能够解释决策过程的搜索算法。搜索空间仅包含可以处理同质和异质图的基本函数。搜索算法通过蒙特卡洛树搜索高效地搜索最佳GNN架构。

    Graph neural networks (GNNs) are powerful tools for performing data science tasks in various domains. Although we use GNNs in wide application scenarios, it is a laborious task for researchers and practitioners to design/select optimal GNN rchitectures in diverse graphs. To save human efforts and computational costs, graph neural architecture search (Graph NAS) has been used to search for a sub-optimal GNN architecture that combines existing components. However, there are no existing Graph NAS methods that satisfy explainability, efficiency, and adaptability to various graphs. Therefore, we propose an efficient and explainable Graph NAS method, called ExGNAS, which consists of (i) a simple search space that can adapt to various graphs and (ii) a search algorithm that makes the decision process explainable. The search space includes only fundamental functions that can handle homophilic and heterophilic graphs. The search algorithm efficiently searches for the best GNN architecture via M
    
[^54]: AGS: 一种用于家庭环境声音事件识别的数据集和分类系统

    AGS: An Dataset and Taxonomy for Domestic Scene Sound Event Recognition. (arXiv:2308.15726v1 [cs.SD])

    [http://arxiv.org/abs/2308.15726](http://arxiv.org/abs/2308.15726)

    本文提出了一个用于家庭环境声音事件识别的数据集（AGS），对于室内环境声音场景的声音事件识别研究领域来说具有重要意义。该数据集考虑了重叠音频和背景噪声，并通过比较和分析先进的方法来验证其可靠性和研究新数据集带来的挑战。

    

    环境声音场景和声音事件识别对于室内和室外环境中可疑事件的识别（如托儿所、智能家居、养老院等）非常重要，也是许多音频监控应用中的基本任务。尤其是在室内环境声音场景的声音事件识别研究领域中，尚未有公共的常见数据集。因此，本文提出了一种用于家庭环境声音的数据集（称为AGS）。该数据集考虑了场景中各种类型的重叠音频和背景噪声。此外，基于提出的数据集，本文对声音事件识别的先进方法进行了比较和分析，并验证了本文提出的数据集的可靠性，并研究了新数据集带来的挑战。

    Environmental sound scene and sound event recognition is important for the recognition of suspicious events in indoor and outdoor environments (such as nurseries, smart homes, nursing homes, etc.) and is a fundamental task involved in many audio surveillance applications. In particular, there is no public common data set for the research field of sound event recognition for the data set of the indoor environmental sound scene. Therefore, this paper proposes a data set (called as AGS) for the home environment sound. This data set considers various types of overlapping audio in the scene, background noise. Moreover, based on the proposed data set, this paper compares and analyzes the advanced methods for sound event recognition, and then illustrates the reliability of the data set proposed in this paper, and studies the challenges raised by the new data set. Our proposed AGS and the source code of the corresponding baselines at https://github.com/taolunzu11/AGS .
    
[^55]: 基于替代模型的自动调优方法在回归问题中随机化草图算法的应用

    Surrogate-based Autotuning for Randomized Sketching Algorithms in Regression Problems. (arXiv:2308.15720v1 [cs.LG])

    [http://arxiv.org/abs/2308.15720](http://arxiv.org/abs/2308.15720)

    本文介绍了如何使用基于替代模型的自动调优方法解决随机化草图算法中的参数选择问题，在随机数值线性代数中取得了接近最优性能的实证结果。

    

    从随机数值线性代数(RandNLA)中提出的算法在处理高维计算问题方面表现出很好的效果，提供高质量的经验性能以及强大的概率保证。然而，它们的实际应用受到一个问题的复杂性所限制，即用户需要设置各种不同于传统NLA中使用的算法特定调参参数。本文展示了如何使用基于替代模型的自动调优方法来解决RandNLA算法中参数选择的基础性问题。具体而言，我们对基于草图和预处理(SAP)的随机化最小二乘方法进行了替代模型自动调优的详细研究，这在现代RandNLA中是一个巨大的成功案例。实证结果表明，我们的基于替代模型的自动调优方法可以以比随机搜索少约4倍的试验成本实现接近最优的性能。

    Algorithms from Randomized Numerical Linear Algebra (RandNLA) are known to be effective in handling high-dimensional computational problems, providing high-quality empirical performance as well as strong probabilistic guarantees. However, their practical application is complicated by the fact that the user needs to set various algorithm-specific tuning parameters which are different than those used in traditional NLA. This paper demonstrates how a surrogate-based autotuning approach can be used to address fundamental problems of parameter selection in RandNLA algorithms. In particular, we provide a detailed investigation of surrogate-based autotuning for sketch-and-precondition (SAP) based randomized least squares methods, which have been one of the great success stories in modern RandNLA. Empirical results show that our surrogate-based autotuning approach can achieve near-optimal performance with much less tuning cost than a random search (up to about 4x fewer trials of different para
    
[^56]: 通过动态知识选择优化文本生成中的事实准确性

    Optimizing Factual Accuracy in Text Generation through Dynamic Knowledge Selection. (arXiv:2308.15711v1 [cs.CL])

    [http://arxiv.org/abs/2308.15711](http://arxiv.org/abs/2308.15711)

    本文提出了DKGen系统，通过动态选择知识参考，消除了文本生成过程中的非关联参考，从而提高了生成文本的事实准确性。

    

    语言模型（LMs）在我们与信息互动方面产生了革命性的影响，但它们往往会生成非事实性的文本，引发对其可靠性的担忧。以往的方法通过使用外部知识作为文本生成的参考来增强事实性，但往往在无关参考的知识混乱（如实体不匹配）方面遇到困难。此外，随着输出文本的长度增加，随机采样的随意性会加剧，对生成文本的事实准确性产生不利影响。在本文中，我们提出了DKGen，将文本生成过程划分为迭代过程。在每个迭代中，DKGen将输入的查询、先前生成的文本和一部分参考段落作为输入来生成短文本。在此过程中，根据先前生成的文本和查询与之的相关性，动态选择子集，从完整的段落集中大量消除了不相关的参考内容的输入。为进一步增强DKGen的能力，

    Language models (LMs) have revolutionized the way we interact with information, but they often generate nonfactual text, raising concerns about their reliability. Previous methods use external knowledge as references for text generation to enhance factuality but often struggle with the knowledge mix-up(e.g., entity mismatch) of irrelevant references. Besides,as the length of the output text grows, the randomness of sampling can escalate, detrimentally impacting the factual accuracy of the generated text. In this paper, we present DKGen, which divide the text generation process into an iterative process. In each iteration, DKGen takes the input query, the previously generated text and a subset of the reference passages as input to generate short text. During the process, the subset is dynamically selected from the full passage set based on their relevance to the previously generated text and the query, largely eliminating the irrelevant references from input. To further enhance DKGen's 
    
[^57]: Speech Wikimedia：一种包括77种语言的多语音数据集

    Speech Wikimedia: A 77 Language Multilingual Speech Dataset. (arXiv:2308.15710v1 [cs.AI])

    [http://arxiv.org/abs/2308.15710](http://arxiv.org/abs/2308.15710)

    Speech Wikimedia是一个包含来自77种语言的大量音频和转录的数据集，适用于训练语音识别、语音翻译和机器翻译模型。

    

    Speech Wikimedia数据集是从维基媒体共享资源中提取的带有转录的音频的公开可用编译。它包括来自不同场景和说话者的1780小时（195GB）的CC-BY-SA许可的转录语音，涵盖了77种不同的语言。每个音频文件都有一个或多个不同语言的转录，使得这个数据集适用于训练语音识别、语音翻译和机器翻译模型。

    The Speech Wikimedia Dataset is a publicly available compilation of audio with transcriptions extracted from Wikimedia Commons. It includes 1780 hours (195 GB) of CC-BY-SA licensed transcribed speech from a diverse set of scenarios and speakers, in 77 different languages. Each audio file has one or more transcriptions in different languages, making this dataset suitable for training speech recognition, speech translation, and machine translation models.
    
[^58]: 对对比学习中互信息的严格分析的探索

    Towards a Rigorous Analysis of Mutual Information in Contrastive Learning. (arXiv:2308.15704v1 [cs.AI])

    [http://arxiv.org/abs/2308.15704](http://arxiv.org/abs/2308.15704)

    本研究探索了对比学习中互信息的严格分析，引入了三种新方法和相关定理，提升了互信息分析的严谨性与实用性。

    

    对比学习已成为无监督表示学习的重要基石。其主要范式涉及一个互信息损失的实例区分任务。这种损失被称为InfoNCE，通过互信息分析的视角提供了对对比学习的重要见解。然而，互信息的估计可能具有挑战性，导致其数学基础的优雅与估计的复杂性之间存在差距。因此，从互信息分析中得出严格的见解或结论变得复杂。在本研究中，我们引入了三种新方法和一些相关定理，旨在增强互信息分析的严谨性。尽管它们很简单，但这些方法具有重要的实用性。利用这些方法，我们重新评估了三个对比学习分析实例，展示了它们促进更深入理解或纠正错误的能力。

    Contrastive learning has emerged as a cornerstone in recent achievements of unsupervised representation learning. Its primary paradigm involves an instance discrimination task with a mutual information loss. The loss is known as InfoNCE and it has yielded vital insights into contrastive learning through the lens of mutual information analysis. However, the estimation of mutual information can prove challenging, creating a gap between the elegance of its mathematical foundation and the complexity of its estimation. As a result, drawing rigorous insights or conclusions from mutual information analysis becomes intricate. In this study, we introduce three novel methods and a few related theorems, aimed at enhancing the rigor of mutual information analysis. Despite their simplicity, these methods can carry substantial utility. Leveraging these approaches, we reassess three instances of contrastive learning analysis, illustrating their capacity to facilitate deeper comprehension or to rectif
    
[^59]: 训练朝向批判使用：学习将人工智能预测置于人类知识之中

    Training Towards Critical Use: Learning to Situate AI Predictions Relative to Human Knowledge. (arXiv:2308.15700v1 [cs.HC])

    [http://arxiv.org/abs/2308.15700](http://arxiv.org/abs/2308.15700)

    本文介绍了一种过程导向的适当依赖概念，称为批判使用，旨在帮助人们更好地利用基于人工智能的决策支持。研究通过在儿童虐待筛查领域进行在线实验，发现通过提供特定培训可以支持人们的批判使用能力。

    

    越来越多的研究探讨如何支持人们更好地利用基于人工智能的决策支持，包括通过培训和入门指导。现有的研究集中在决策任务上，这些任务可以通过比较每个决策与现实标签的一致性来评估“适当的依赖”，这些标签清晰地映射到人工智能的预测目标和人类决策者的目标。然而，在许多现实世界的环境中，这种假设不成立，因为人工智能工具被部署在社会工作、刑事司法和医疗保健等领域。在本文中，我们引入了一种过程导向的适当依赖概念，称为批判使用，其将人类能够将人工智能预测置于他们独特的知识之中，而这些知识对于人工智能模型来说是不可获得的。为了探索训练如何支持批判使用，我们在一个复杂的社会决策场景中进行了一项随机在线实验：儿童虐待筛查。我们发现，通过提供...

    A growing body of research has explored how to support humans in making better use of AI-based decision support, including via training and onboarding. Existing research has focused on decision-making tasks where it is possible to evaluate "appropriate reliance" by comparing each decision against a ground truth label that cleanly maps to both the AI's predictive target and the human decision-maker's goals. However, this assumption does not hold in many real-world settings where AI tools are deployed today (e.g., social work, criminal justice, and healthcare). In this paper, we introduce a process-oriented notion of appropriate reliance called critical use that centers the human's ability to situate AI predictions against knowledge that is uniquely available to them but unavailable to the AI model. To explore how training can support critical use, we conduct a randomized online experiment in a complex social decision-making setting: child maltreatment screening. We find that, by providi
    
[^60]: CongNaMul: 一种用于大豆芽图像处理的数据集

    CongNaMul: A Dataset for Advanced Image Processing of Soybean Sprouts. (arXiv:2308.15690v1 [cs.CV])

    [http://arxiv.org/abs/2308.15690](http://arxiv.org/abs/2308.15690)

    提出了一个用于大豆芽图像处理的名为CongNaMul的数据集，旨在支持图像分类、语义分割、分解和测量等任务。提供了质量分类、语义分割和图像分解的标记，以及5个芽的物理特征供测量使用。

    

    我们提出了“CongNaMul”，这是一个为大豆芽图像分析的各种任务而设计的综合数据集。CongNaMul数据集旨在促进图像分类、语义分割、分解以及长度和重量的测量等任务。分类任务提供了四个类别来确定大豆芽的质量：正常、断裂、斑点和断裂和斑点，以开发基于人工智能辅助的自动质量检测技术。对于语义分割，数据集包括了具有不同复杂度的图像，从单个芽图像到具有多个芽的图像，以及人工标记的掩膜图像。标签包括4个不同的类别：背景、头部、身体和尾部。数据集还为图像分解任务提供了图像和掩膜，包括两个分离的芽图像和它们的组合形式。最后，还提供了芽的5个物理特征（头部长度、身体长度、身体厚度、尾部长度、重量）供基于图像的测量使用。

    We present 'CongNaMul', a comprehensive dataset designed for various tasks in soybean sprouts image analysis. The CongNaMul dataset is curated to facilitate tasks such as image classification, semantic segmentation, decomposition, and measurement of length and weight. The classification task provides four classes to determine the quality of soybean sprouts: normal, broken, spotted, and broken and spotted, for the development of AI-aided automatic quality inspection technology. For semantic segmentation, images with varying complexity, from single sprout images to images with multiple sprouts, along with human-labelled mask images, are included. The label has 4 different classes: background, head, body, tail. The dataset also provides images and masks for the image decomposition task, including two separate sprout images and their combined form. Lastly, 5 physical features of sprouts (head length, body length, body thickness, tail length, weight) are provided for image-based measurement
    
[^61]: 通过大型语言模型进行交互机器人行动规划与不确定性分析和主动提问

    Interactively Robot Action Planning with Uncertainty Analysis and Active Questioning by Large Language Model. (arXiv:2308.15684v1 [cs.RO])

    [http://arxiv.org/abs/2308.15684](http://arxiv.org/abs/2308.15684)

    本文提出了一种交互式机器人行动规划方法，利用大型语言模型（LLM）通过向人类提问来分析并收集缺失信息，最大程度地减少生成精确机器人指令的设计成本。揭示了在机器人行动规划中使用LLM面临的挑战，并为未来研究提供了有价值的见解。

    

    将大型语言模型（LLM）应用于机器人行动规划已经被积极研究。通过自然语言给出的LLM指令可能存在歧义和缺乏信息，这取决于任务环境。可以通过使指令输入更详细来调整LLM的输出；然而，设计成本很高。在本文中，我们提出了一种交互式机器人行动规划方法，允许LLM通过向人类提问来分析并收集缺失信息。该方法可以最大程度地减少生成精确机器人指令的设计成本。我们通过烹饪任务的具体示例证明了我们方法的有效性。然而，我们的实验也揭示了LLM在机器人行动规划中面临的挑战，如提出不重要的问题和在不询问的情况下假设关键信息。对这些问题的阐明为未来利用LLM进行机器人技术研究提供了有价值的见解。

    The application of the Large Language Model (LLM) to robot action planning has been actively studied. The instructions given to the LLM by natural language may include ambiguity and lack of information depending on the task context. It is possible to adjust the output of LLM by making the instruction input more detailed; however, the design cost is high. In this paper, we propose the interactive robot action planning method that allows the LLM to analyze and gather missing information by asking questions to humans. The method can minimize the design cost of generating precise robot instructions. We demonstrated the effectiveness of our method through concrete examples in cooking tasks. However, our experiments also revealed challenges in robot action planning with LLM, such as asking unimportant questions and assuming crucial information without asking. Shedding light on these issues provides valuable insights for future research on utilizing LLM for robotics.
    
[^62]: 用于心脏超声解读的多模式基础模型

    Multimodal Foundation Models For Echocardiogram Interpretation. (arXiv:2308.15670v1 [cs.CV])

    [http://arxiv.org/abs/2308.15670](http://arxiv.org/abs/2308.15670)

    该论文提出了一个名为EchoCLIP的多模式基础模型，用于心脏超声解读。该模型利用大量的心脏超声视频和专家解读来实现强大的零样本性能，并在心脏功能评估和植入心脏内器件识别方面表现出良好的性能。

    

    多模式深度学习基础模型可以学习图像和文本之间的关系。在医学成像的背景下，将图像映射到语言概念反映了诊断图像解释的临床任务，然而当前通用的基础模型在这个背景下表现不佳，因为它们的训练文本和图像数据有限。为了解决这个挑战并考虑到心脏生理的范围，我们利用1,032,975个心脏超声视频和相应的专家解读开发了EchoCLIP，一个用于心脏超声的多模式基础模型。EchoCLIP在心脏功能评估（外部验证左室射血分数的平均绝对误差（MAE）为7.1%）和植入心脏内器件的识别方面表现出强大的零样本（未经过显式训练）性能（起搏器和人工心脏瓣膜的曲线下面积（AUC）在0.84至0.98之间）。我们还开发了一个长上下文可变模型来实现更好的模型性能。

    Multimodal deep learning foundation models can learn the relationship between images and text. In the context of medical imaging, mapping images to language concepts reflects the clinical task of diagnostic image interpretation, however current general-purpose foundation models do not perform well in this context because their training corpus have limited medical text and images. To address this challenge and account for the range of cardiac physiology, we leverage 1,032,975 cardiac ultrasound videos and corresponding expert interpretations to develop EchoCLIP, a multimodal foundation model for echocardiography. EchoCLIP displays strong zero-shot (not explicitly trained) performance in cardiac function assessment (external validation left ventricular ejection fraction mean absolute error (MAE) of 7.1%) and identification of implanted intracardiac devices (areas under the curve (AUC) between 0.84 and 0.98 for pacemakers and artificial heart valves). We also developed a long-context vari
    
[^63]: 基于深度强化学习的移动能量传播器调度框架用于在道路上为电动车充电

    Deep Reinforcement Learning Based Framework for Mobile Energy Disseminator Dispatching to Charge On-the-Road Electric Vehicles. (arXiv:2308.15656v1 [cs.RO])

    [http://arxiv.org/abs/2308.15656](http://arxiv.org/abs/2308.15656)

    本论文提出了一个基于深度强化学习的移动能量传播器调度框架，用于在道路上为电动车充电，解决了充电期间车辆排队导致的行车效率低的问题，并提出了一种有效的调度策略来确定最佳时间和位置。

    

    电动车的快速增长给保护电池健康和解决车辆续航焦虑问题带来了新的挑战。为了解决这些问题，特别是移动能量传播器（MEDs）已经成为一个有希望的解决方案。MED安装在大型车辆后方，并在它的上游半径范围内为所有参与的电动车充电。然而，V2V充电期间，MED和电动车意外地形成车队，从而占据了多条车道，并严重影响了整个通道的行车效率。此外，有限的MED配置预算需要开发一种有效的调度策略，以确定在交通中引入MED的最佳时间和位置。本文提出了一种基于深度强化学习（DRL）的方法来开发一个车辆调度框架。

    The exponential growth of electric vehicles (EVs) presents novel challenges in preserving battery health and in addressing the persistent problem of vehicle range anxiety. To address these concerns, wireless charging, particularly, Mobile Energy Disseminators (MEDs) have emerged as a promising solution. The MED is mounted behind a large vehicle and charges all participating EVs within a radius upstream of it. Unfortuantely, during such V2V charging, the MED and EVs inadvertently form platoons, thereby occupying multiple lanes and impairing overall corridor travel efficiency. In addition, constrained budgets for MED deployment necessitate the development of an effective dispatching strategy to determine optimal timing and locations for introducing the MEDs into traffic. This paper proposes a deep reinforcement learning (DRL) based methodology to develop a vehicle dispatching framework. In the first component of the framework, we develop a realistic reinforcement learning environment ter
    
[^64]: 自动机器学习在实践中的一般方法

    A General Recipe for Automated Machine Learning in Practice. (arXiv:2308.15647v1 [cs.LG])

    [http://arxiv.org/abs/2308.15647](http://arxiv.org/abs/2308.15647)

    本文提出了一个构建通用AutoML系统的参考框架，通过叙事性回顾主要方法，将基本概念提炼出来以支持在单一设计中的应用。

    

    自动机器学习（AutoML）是一项研究领域，专注于开发能够自动生成机器学习模型的方法。能够几乎不需要人工干预地建立机器学习模型的想法为应用机器学习的实践提供了巨大机会。然而，在实践中如何设计AutoML系统的信息非常有限。大部分研究关注的是优化算法面临的问题，而忽略了实际应用的细节。在本文中，我们提出了一个构建通用AutoML系统的参考框架。通过对该领域主要方法的叙事性回顾，我们的主要思想是提炼基本概念，以支持它们在单一设计中的应用。最后，我们讨论了一些与AutoML应用相关的未来研究中的开放性问题。

    Automated Machine Learning (AutoML) is an area of research that focuses on developing methods to generate machine learning models automatically. The idea of being able to build machine learning models with very little human intervention represents a great opportunity for the practice of applied machine learning. However, there is very little information on how to design an AutoML system in practice. Most of the research focuses on the problems facing optimization algorithms and leaves out the details of how that would be done in practice. In this paper, we propose a frame of reference for building general AutoML systems. Through a narrative review of the main approaches in the area, our main idea is to distill the fundamental concepts in order to support them in a single design. Finally, we discuss some open problems related to the application of AutoML for future research.
    
[^65]: AskIt: 大型语言模型的统一编程接口

    AskIt: Unified Programming Interface for Programming with Large Language Models. (arXiv:2308.15645v1 [cs.PL])

    [http://arxiv.org/abs/2308.15645](http://arxiv.org/abs/2308.15645)

    AskIt是一个专为大型语言模型设计的领域特定语言，通过简化LLM的集成和提供统一的接口，解决了LLM嵌入应用程序和代码生成的挑战。

    

    在软件开发的不断发展中，大型语言模型 (LLMs) 展示了一种独特的现象，即 emergent abilities，展示了在多个任务中的熟练能力，从文本摘要到代码生成。虽然这些能力在软件设计和开发方面开辟了新的途径，但它们的整合也带来了重大挑战。开发者面临着将LLMs直接嵌入应用程序或将其用于代码生成的决策。此外，有效的提示设计成为一个关键问题，考虑到从自然语言输出中提取数据的必要性。为了解决这些复杂性，本文介绍了AskIt，一种专为LLMs设计的领域特定语言 (DSL)。AskIt简化了LLM的集成，提供了类型指导的输出控制，基于模板的函数定义以及统一的接口，减少了LLM的基于代码生成和应用程序集成之间的区别。

    In the evolving landscape of software development, Large Language Models (LLMs) exhibit a unique phenomenon known as emergent abilities, demonstrating adeptness across numerous tasks, from text summarization to code generation. While these abilities open up novel avenues in software design and crafting, their incorporation presents substantial challenges. Developers grapple with decisions surrounding the direct embedding of LLMs within applications versus employing them for code generation. Moreover, effective prompt design becomes a critical concern, given the necessity of data extraction from natural language outputs. To address these intricacies, this paper introduces AskIt, a domain-specific language (DSL) specifically designed for LLMs. AskIt simplifies LLM integration, offering type-guided output control, template-based function definitions, and a unified interface that diminishes the distinction between LLM-based code generation and application integration. Furthermore, through 
    
[^66]: 双曲卷积神经网络

    Hyperbolic Convolutional Neural Networks. (arXiv:2308.15639v1 [cs.LG])

    [http://arxiv.org/abs/2308.15639](http://arxiv.org/abs/2308.15639)

    双曲卷积神经网络利用双曲空间进行数据嵌入，具有更强大和可解释的模型特性。浅层嵌入构建了层次化嵌入。

    

    在过去的十年里，深度学习主要推动了人工智能领域的兴趣。迄今为止，深度学习研究人员在图像处理领域取得了显著的成功，其中使用了卷积神经网络。尽管在图像分类方面表现出色，但卷积神经网络在图像嵌入空间上没有设定归纳偏置，可以说相当幼稚。另一种类型的卷积网络 - 图卷积神经网络也存在类似的缺陷。然而，使用非欧几里德空间来嵌入数据可能会产生更强大和可解释的模型。非欧几里德空间中的一个例子就是双曲空间。由于能够将更多的数据适应于低维空间并具有树状特性，双曲空间尤其有用。先前的多篇论文已经表明，这些吸引人的特性有助于使用浅层嵌入来构建层次化嵌入。

    Deep Learning is mostly responsible for the surge of interest in Artificial Intelligence in the last decade. So far, deep learning researchers have been particularly successful in the domain of image processing, where Convolutional Neural Networks are used. Although excelling at image classification, Convolutional Neural Networks are quite naive in that no inductive bias is set on the embedding space for images. Similar flaws are also exhibited by another type of Convolutional Networks - Graph Convolutional Neural Networks. However, using non-Euclidean space for embedding data might result in more robust and explainable models. One example of such a non-Euclidean space is hyperbolic space. Hyperbolic spaces are particularly useful due to their ability to fit more data in a low-dimensional space and tree-likeliness properties. These attractive properties have been previously used in multiple papers which indicated that they are beneficial for building hierarchical embeddings using shall
    
[^67]: 评估大学生个性发展和就业准备的智能系统

    Intelligent System for Assessing University Student Personality Development and Career Readiness. (arXiv:2308.15620v1 [cs.AI])

    [http://arxiv.org/abs/2308.15620](http://arxiv.org/abs/2308.15620)

    本论文研究使用一个智能系统来评估大学生的个性发展和就业准备情况。该系统通过设计基于“平衡轮”理论的调查问卷来收集学生的情感数据，并使用机器学习模型和模糊集进行处理，从而评估毕业生对未来职业的准备程度。

    

    尽管常常使用成绩单和绩点等学术指标来评估学生的知识获得情况，但缺乏全面的指标来衡量他们对毕业后生活挑战的准备程度。本研究探讨了各种因素对大学生对变化和过渡的准备程度的影响，重点关注他们对职业的准备程度。该研究采用的方法涉及设计一份基于Paul J. Mayer的“平衡轮”理论的调查问卷，以捕捉学生在不同生活方面的情感，包括对教育过程的满意度和对薪资的期望。通过对来自KBTU学生调查的收集数据（n=47）进行线性回归、支持向量回归（SVR）、随机森林回归等机器学习模型的处理，随后使用这些模型和模糊集构建了一个智能系统。该系统能够评估毕业生对未来职业的准备程度

    While academic metrics such as transcripts and GPA are commonly used to evaluate students' knowledge acquisition, there is a lack of comprehensive metrics to measure their preparedness for the challenges of post-graduation life. This research paper explores the impact of various factors on university students' readiness for change and transition, with a focus on their preparedness for careers. The methodology employed in this study involves designing a survey based on Paul J. Mayer's "The Balance Wheel" to capture students' sentiments on various life aspects, including satisfaction with the educational process and expectations of salary. The collected data from a KBTU student survey (n=47) were processed through machine learning models: Linear Regression, Support Vector Regression (SVR), Random Forest Regression. Subsequently, an intelligent system was built using these models and fuzzy sets. The system is capable of evaluating graduates' readiness for their future careers and demonstr
    
[^68]: InstaTune: 在微调期间即时神经架构搜索

    InstaTune: Instantaneous Neural Architecture Search During Fine-Tuning. (arXiv:2308.15609v1 [cs.LG])

    [http://arxiv.org/abs/2308.15609](http://arxiv.org/abs/2308.15609)

    InstaTune是一种在微调阶段即时生成超级网络的方法，可以最小化神经架构搜索所需的时间和计算资源。

    

    一次性神经架构搜索（NAS）算法通常依赖于为特定领域任务训练硬件无关的超级网络。然后从训练好的超级网络中提取出适用于不同硬件平台的最佳子网络。然而，从头开始训练超级网络可能非常耗时且计算密集，特别是对于依赖于预训练和微调的两阶段训练过程的大型模型。现有的最先进的预训练模型适用于各种任务，但它们的尺寸较大，极大限制了它们在不同硬件平台上的适用性。我们提出了InstaTune，一种利用即时微调阶段生成超级网络的方法。InstaTune具有多个优点。首先，由于该过程发生在微调期间，它可以最小化进行NAS所需的总时间和计算资源。其次，提取出的子网络针对目标任务进行了优化。

    One-Shot Neural Architecture Search (NAS) algorithms often rely on training a hardware agnostic super-network for a domain specific task. Optimal sub-networks are then extracted from the trained super-network for different hardware platforms. However, training super-networks from scratch can be extremely time consuming and compute intensive especially for large models that rely on a two-stage training process of pre-training and fine-tuning. State of the art pre-trained models are available for a wide range of tasks, but their large sizes significantly limits their applicability on various hardware platforms. We propose InstaTune, a method that leverages off-the-shelf pre-trained weights for large models and generates a super-network during the fine-tuning stage. InstaTune has multiple benefits. Firstly, since the process happens during fine-tuning, it minimizes the overall time and compute resources required for NAS. Secondly, the sub-networks extracted are optimized for the target ta
    
[^69]: 变形金刚是否能学会最大公约数？

    Can transformers learn the greatest common divisor?. (arXiv:2308.15594v1 [cs.LG])

    [http://arxiv.org/abs/2308.15594](http://arxiv.org/abs/2308.15594)

    本文研究了小型变形金刚模型计算最大公约数的能力。通过选择合适的训练分布和表示基准，模型可以达到高准确率，并在预测中表现出明确的模式。

    

    本文研究小型变形金刚模型计算两个正整数的最大公约数（GCD）的能力。当训练分布和表示基准仔细选择时，模型可以达到98%的准确率，并且正确预测前100个GCD中的91个。模型的预测是确定性的，并且完全可解释的。在训练过程中，模型学会将具有相同GCD的输入对聚类，并通过其除数进行分类。基本模型通过使用小型基数编码的均匀操作数仅计算少数GCD（最多100个中的38个）：基数的除数乘积。更长的训练时间和更大的基数允许一些模型“了解”小的素数GCD。使用对数均匀操作数进行训练将性能提升到正确的73个GCD，并通过从倒数平方到对数均匀的GCD训练分布的平衡，使性能达到91个GCD。从GCD的均匀分布进行训练模型破坏了确定性模型行为。

    I investigate the capability of small transformers to compute the greatest common divisor (GCD) of two positive integers. When the training distribution and the representation base are carefully chosen, models achieve 98% accuracy and correctly predict 91 of the 100 first GCD. Model predictions are deterministic and fully interpretable. During training, the models learn to cluster input pairs with the same GCD, and classify them by their divisors. Basic models, trained from uniform operands encoded on small bases, only compute a handful of GCD (up to 38 out of 100): the products of divisors of the base. Longer training and larger bases allow some models to "grok" small prime GCD. Training from log-uniform operands boosts performance to 73 correct GCD, and balancing the training distribution of GCD, from inverse square to log-uniform, to 91 GCD. Training models from a uniform distribution of GCD breaks the deterministic model behavior.
    
[^70]: 图神经网络中的过度压缩问题：一项全面调查

    Over-Squashing in Graph Neural Networks: A Comprehensive survey. (arXiv:2308.15568v1 [cs.AI])

    [http://arxiv.org/abs/2308.15568](http://arxiv.org/abs/2308.15568)

    过度压缩是图神经网络面临的关键挑战，它限制了节点之间的长程信息传递，影响了在需要广泛上下文洞察力的情况下的准确预测。

    

    图神经网络（GNN）已成为机器学习领域的一种革命性范 Paradigm，为分析图结构数据中固有的复杂关系提供了一种变革性方法。大多数GNN的基本架构涉及通过消息聚合和转换在相互连接的节点之间传播信息的机制，在包括节点分类、链接预测和推荐系统的各种应用中已经展现出显著的有效性。然而，它们的潜在实力遇到了在需要广泛上下文洞察力的情况下固有的限制。在某些情境中，准确的预测不仅取决于节点的即时局部环境，还取决于跨越广域的交互作用。这种复杂的对长程信息传播的需求暴露了一个被称为“过度压缩”的关键挑战，其中来自远离节点的信息流的可靠性受到影响。

    Graph Neural Networks (GNNs) have emerged as a revolutionary paradigm in the realm of machine learning, offering a transformative approach to dissect intricate relationships inherent in graph-structured data. The foundational architecture of most GNNs involves the dissemination of information through message aggregation and transformation among interconnected nodes, a mechanism that has demonstrated remarkable efficacy across diverse applications encompassing node classification, link prediction, and recommendation systems. Nonetheless, their potential prowess encounters a restraint intrinsic to scenarios necessitating extensive contextual insights. In certain contexts, accurate predictions hinge not only upon a node's immediate local surroundings but also on interactions spanning far-reaching domains. This intricate demand for long-range information dissemination exposes a pivotal challenge recognized as "over-squashing," wherein the fidelity of information flow from distant nodes bec
    
[^71]: WeatherBench 2：下一代数据驱动全球天气模型的基准测试

    WeatherBench 2: A benchmark for the next generation of data-driven global weather models. (arXiv:2308.15560v1 [physics.ao-ph])

    [http://arxiv.org/abs/2308.15560](http://arxiv.org/abs/2308.15560)

    WeatherBench 2更新了全球中期天气预测基准测试，旨在加速数据驱动天气建模的进展，提供了开源评估框架和最新的模型性能指标。此外，还讨论了当前评估设置中的注意事项和未来的挑战。

    

    WeatherBench 2是对Rasp等人（2020）提出的全球中期（1-14天）天气预测基准测试的更新，旨在加速数据驱动天气建模的进展。WeatherBench 2包括一个开源评估框架，公开可用的训练、基准数据和基线数据，以及一个持续更新的网站，其中包含最新的指标和最先进的模型：https://sites.research.google/weatherbench。本文描述了评估框架的设计原则，并提供当前最先进的物理和数据驱动天气模型的结果。这些指标基于领先操作性天气中心评估天气预报的实践。我们定义了一组主要得分，以提供模型性能的概览。此外，我们还讨论了当前评估设置中的注意事项和数据驱动天气预测未来的挑战。

    WeatherBench 2 is an update to the global, medium-range (1-14 day) weather forecasting benchmark proposed by Rasp et al. (2020), designed with the aim to accelerate progress in data-driven weather modeling. WeatherBench 2 consists of an open-source evaluation framework, publicly available training, ground truth and baseline data as well as a continuously updated website with the latest metrics and state-of-the-art models: https://sites.research.google/weatherbench. This paper describes the design principles of the evaluation framework and presents results for current state-of-the-art physical and data-driven weather models. The metrics are based on established practices for evaluating weather forecasts at leading operational weather centers. We define a set of headline scores to provide an overview of model performance. In addition, we also discuss caveats in the current evaluation setup and challenges for the future of data-driven weather forecasting.
    
[^72]: 对抗式风格转移在深度强化学习中的鲁棒策略优化

    Adversarial Style Transfer for Robust Policy Optimization in Deep Reinforcement Learning. (arXiv:2308.15550v1 [cs.LG])

    [http://arxiv.org/abs/2308.15550](http://arxiv.org/abs/2308.15550)

    本文提出了一种对抗式风格转移的算法，通过消除对混淆特征的过拟合来提高深度强化学习智能体的泛化能力。这种算法使用了生成器和策略网络，并通过最大-最小博弈的方式进行优化，以找到一个可以泛化到未见环境的鲁棒策略。实验证明，这种算法相比于其他基准算法有更好的性能。

    

    本文提出了一种算法，旨在通过消除对混淆特征过拟合来提高强化学习智能体的泛化能力。我们的方法包括了一个最大-最小博弈理论的目标。生成器在强化学习过程中转移观察样式。生成器的另一个目标是扰动观察，以最大化智能体采取不同行动的概率。相反，策略网络更新其参数以最小化这种扰动的影响，从而在最大化未来预期奖励的同时保持鲁棒性。基于这一设置，我们提出了一个实用的深度强化学习算法，Adversarial Robust Policy Optimization (ARPO)，以找到一个可以泛化到未见环境的鲁棒策略。我们在Procgen和Distracting Control Suite上评估了我们的方法的泛化和样本效率。实验证明，与几种基准算法（包括数据增广）相比，ARPO表现出了改进的性能。

    This paper proposes an algorithm that aims to improve generalization for reinforcement learning agents by removing overfitting to confounding features. Our approach consists of a max-min game theoretic objective. A generator transfers the style of observation during reinforcement learning. An additional goal of the generator is to perturb the observation, which maximizes the agent's probability of taking a different action. In contrast, a policy network updates its parameters to minimize the effect of such perturbations, thus staying robust while maximizing the expected future reward. Based on this setup, we propose a practical deep reinforcement learning algorithm, Adversarial Robust Policy Optimization (ARPO), to find a robust policy that generalizes to unseen environments. We evaluate our approach on Procgen and Distracting Control Suite for generalization and sample efficiency. Empirically, ARPO shows improved performance compared to a few baseline algorithms, including data augmen
    
[^73]: 国际民用人工智能治理: 一种管辖认证方法

    International Governance of Civilian AI: A Jurisdictional Certification Approach. (arXiv:2308.15514v1 [cs.AI])

    [http://arxiv.org/abs/2308.15514](http://arxiv.org/abs/2308.15514)

    这项研究提出了一种国际治理民用人工智能的方法，通过建立国际人工智能组织来认证国家的管辖区域是否符合国际监督标准，进而禁止从未经认证的管辖区域进口AI供应链所包含产品。

    

    本报告描述了国际民用人工智能（AI）治理安排设计中的权衡，并详细介绍了一种方法。该方法将一个标准、许可和责任制度扩展到全球范围。我们建议各国建立一个国际人工智能组织（IAIO）来认证国家管辖区域（而不是公司或AI项目）是否符合国际监督标准。各国可以通过采用禁止从未经IAIO认证的管辖区域进口AI供应链所包含产品的法规来实施这些国际标准。这一方法借鉴了现有国际组织模式，如国际民用航空组织（ICAO）、国际海事组织（IMO）和金融行动特别工作组（FATF）。各国还可以对非认证国家采取多边控制措施，例如对AI产品输入（如专用硬件）的出口。

    This report describes trade-offs in the design of international governance arrangements for civilian artificial intelligence (AI) and presents one approach in detail. This approach represents the extension of a standards, licensing, and liability regime to the global level. We propose that states establish an International AI Organization (IAIO) to certify state jurisdictions (not firms or AI projects) for compliance with international oversight standards. States can give force to these international standards by adopting regulations prohibiting the import of goods whose supply chains embody AI from non-IAIO-certified jurisdictions. This borrows attributes from models of existing international organizations, such as the International Civilian Aviation Organization (ICAO), the International Maritime Organization (IMO), and the Financial Action Task Force (FATF). States can also adopt multilateral controls on the export of AI product inputs, such as specialized hardware, to non-certified
    
[^74]: 调整困惑度并计算基于采样的t-SNE嵌入

    Tuning the perplexity for and computing sampling-based t-SNE embeddings. (arXiv:2308.15513v1 [cs.LG])

    [http://arxiv.org/abs/2308.15513](http://arxiv.org/abs/2308.15513)

    本文通过采样的方法改进了大数据集下t-SNE嵌入的质量和计算速度。

    

    高维数据分析常用的管道利用二维可视化，例如通过t分布邻近随机嵌入（t-SNE）。但在处理大数据集时，应用这些可视化技术会生成次优的嵌入，因为超参数不适用于大数据。将这些参数增加通常不起作用，因为计算对于实际工作流程来说太昂贵。本文中，我们认为基于采样的嵌入方法可以解决这些问题。我们展示了必须谨慎选择超参数，取决于采样率和预期的最终嵌入。此外，我们展示了该方法如何加速计算并提高嵌入的质量。

    Widely used pipelines for the analysis of high-dimensional data utilize two-dimensional visualizations. These are created, e.g., via t-distributed stochastic neighbor embedding (t-SNE). When it comes to large data sets, applying these visualization techniques creates suboptimal embeddings, as the hyperparameters are not suitable for large data. Cranking up these parameters usually does not work as the computations become too expensive for practical workflows. In this paper, we argue that a sampling-based embedding approach can circumvent these problems. We show that hyperparameters must be chosen carefully, depending on the sampling rate and the intended final embedding. Further, we show how this approach speeds up the computation and increases the quality of the embeddings.
    
[^75]: 从在线论坛中检测不活跃的网络战士

    Detecting Inactive Cyberwarriors from Online Forums. (arXiv:2308.15491v1 [cs.SI])

    [http://arxiv.org/abs/2308.15491](http://arxiv.org/abs/2308.15491)

    本研究调查了大型在线论坛中网络战士的活动水平，发现只有少数网络战士是活跃用户，他们在和平时期保持沉默，只在必要时行动。此外，检测不活跃的网络战士比识别活跃的网络战士更具挑战性。研究提供了更好捕捉网络战士行动的方法。

    

    在信息时代，虚假信息的传播成为一种新形式的战争。这种战争涉及到网络战士，他们有意传播旨在诽谤对手或团结盟友的信息。在这项研究中，我们调查了大型在线论坛中网络战士的活动水平，令人惊讶的是，我们发现只有少数网络战士是活跃用户。令人意外的是，尽管他们被期望积极传播虚假信息，在和平时期网络战士却保持沉默，只在必要时才行动起来。此外，我们分析了识别网络战士所面临的挑战，并提供证据表明检测不活跃的网络战士比识别活跃的网络战士要难得多。最后，我们讨论了更有效地在网络战士不活跃的阶段识别他们的潜在方法，为更好地捕捉他们的行动提供了洞察。

    The proliferation of misinformation has emerged as a new form of warfare in the information age. This type of warfare involves cyberwarriors, who deliberately propagate messages aimed at defaming opponents or fostering unity among allies. In this study, we investigate the level of activity exhibited by cyberwarriors within a large online forum, and remarkably, we discover that only a minute fraction of cyberwarriors are active users. Surprisingly, despite their expected role of actively disseminating misinformation, cyberwarriors remain predominantly silent during peacetime and only spring into action when necessary. Moreover, we analyze the challenges associated with identifying cyberwarriors and provide evidence that detecting inactive cyberwarriors is considerably more challenging than identifying their active counterparts. Finally, we discuss potential methodologies to more effectively identify cyberwarriors during their inactive phases, offering insights into better capturing thei
    
[^76]: 动态双图融合卷积网络用于阿尔茨海默病诊断

    Dynamic Dual-Graph Fusion Convolutional Network For Alzheimer's Disease Diagnosis. (arXiv:2308.15484v1 [eess.IV])

    [http://arxiv.org/abs/2308.15484](http://arxiv.org/abs/2308.15484)

    本文提出了一种动态双图融合卷积网络，用于阿尔茨海默病诊断。主要贡献包括：1）提出了一种新颖的动态GCN架构，实现了端到端的诊断；2）该架构能够动态调整图结构，学习最优的潜在图，从而产生更好的诊断结果；3）结合特征图学习和动态图学习，加权处理有用的受试者特征，减少其他噪声特征的影响。实验结果表明，该模型在AD诊断中具有灵活性和稳定性，并取得了出色的分类效果。

    

    本文提出了一种动态双图融合卷积网络，以提高阿尔茨海默病诊断性能。主要贡献包括：（a）提出了一种新颖的动态GCN架构，用于AD任务的端到端诊断；（b）该架构可以动态调整GCN的图结构，通过学习最优的潜在图来产生更好的诊断结果；（c）结合特征图学习和动态图学习，给予那些有用的受试者特征更多的权重，同时降低其他噪声特征的权重。实验证明，我们的模型在AD诊断中能够提供灵活性和稳定性，并取得了优越的分类结果。

    In this paper, a dynamic dual-graph fusion convolutional network is proposed to improve Alzheimer's disease (AD) diagnosis performance. The following are the paper's main contributions: (a) propose a novel dynamic GCN architecture, which is an end-to-end pipeline for diagnosis of the AD task; (b) the proposed architecture can dynamically adjust the graph structure for GCN to produce better diagnosis outcomes by learning the optimal underlying latent graph; (c) incorporate feature graph learning and dynamic graph learning, giving those useful features of subjects more weight while decreasing the weights of other noise features. Experiments indicate that our model provides flexibility and stability while achieving excellent classification results in AD diagnosis.
    
[^77]: 在HPC系统中的在线作业失败预测

    Online Job Failure Prediction in an HPC System. (arXiv:2308.15481v1 [cs.DC])

    [http://arxiv.org/abs/2308.15481](http://arxiv.org/abs/2308.15481)

    该论文研究了使用经典的机器学习算法在提交时间上进行作业失败预测，并结合自然语言处理工具来表示作业。该方法可用于优化高性能计算系统管理，提高性能和能源效率。

    

    现代高性能计算（HPC）系统是复杂的机器，对经济和社会都有重大影响。除了计算能力外，能源消耗也在不断增长，这是一个关键问题，考虑到当前的环境和能源危机。因此，开发优化HPC系统管理的策略至关重要，既可以保证一流的性能，又可以提高能源效率。一种策略是通过在工作负载级别上进行操作，并在系统上执行之前突出显示最有可能失败的作业。作业在执行过程中失败会不必要地占用资源，可能会延迟其他作业，对系统性能和能源消耗产生不利影响。在本文中，我们使用经典的机器学习算法研究了提交时间上的作业失败预测。我们的创新在于（i）将这些算法与自然语言处理（NLP）工具结合起来，以表示作业和（ii）th

    Modern High Performance Computing (HPC) systems are complex machines, with major impacts on economy and society. Along with their computational capability, their energy consumption is also steadily raising, representing a critical issue given the ongoing environmental and energetic crisis. Therefore, developing strategies to optimize HPC system management has paramount importance, both to guarantee top-tier performance and to improve energy efficiency. One strategy is to act at the workload level and highlight the jobs that are most likely to fail, prior to their execution on the system. Jobs failing during their execution unnecessarily occupy resources which could delay other jobs, adversely affecting the system performance and energy consumption. In this paper, we study job failure prediction at submit-time using classical machine learning algorithms. Our novelty lies in (i) the combination of these algorithms with Natural Language Processing (NLP) tools to represent jobs and (ii) th
    
[^78]: 阐明扩散模型中的曝光偏差问题

    Elucidating the Exposure Bias in Diffusion Models. (arXiv:2308.15321v1 [cs.LG])

    [http://arxiv.org/abs/2308.15321](http://arxiv.org/abs/2308.15321)

    本文系统地研究了扩散模型中的曝光偏差问题，并提出了一种名为Epsilon Scaling的免训练方法来减轻这一问题。实验结果验证了该方法的有效性。

    

    扩散模型展示了令人印象深刻的生成能力，但它们的“曝光偏差”问题，即训练和采样之间的输入不匹配，缺乏深入探索。本文通过首先对采样分布进行分析建模，然后将每个采样步骤的预测误差归因为曝光偏差问题的根本原因，系统地研究了扩散模型中的曝光偏差问题。此外，我们讨论了解决这个问题的潜在方法，并提出了一个直观的度量标准。除了阐明曝光偏差问题，我们提出了一种简单但有效的免训练方法，称为Epsilon Scaling，以减轻曝光偏差。我们展示了Epsilon Scaling通过缩小网络输出（Epsilon）明确地将采样轨迹移近训练阶段学习到的向量场，从而减轻了训练和采样之间的输入不匹配。在各种扩散框架上进行了实验。

    Diffusion models have demonstrated impressive generative capabilities, but their 'exposure bias' problem, described as the input mismatch between training and sampling, lacks in-depth exploration. In this paper, we systematically investigate the exposure bias problem in diffusion models by first analytically modelling the sampling distribution, based on which we then attribute the prediction error at each sampling step as the root cause of the exposure bias issue. Furthermore, we discuss potential solutions to this issue and propose an intuitive metric for it. Along with the elucidation of exposure bias, we propose a simple, yet effective, training-free method called Epsilon Scaling to alleviate the exposure bias. We show that Epsilon Scaling explicitly moves the sampling trajectory closer to the vector field learned in the training phase by scaling down the network output (Epsilon), mitigating the input mismatch between training and sampling. Experiments on various diffusion framework
    
[^79]: FurChat: 使用LLMs的具有脸部表情的交互式对话系统，结合开放和封闭领域对话

    FurChat: An Embodied Conversational Agent using LLMs, Combining Open and Closed-Domain Dialogue with Facial Expressions. (arXiv:2308.15214v1 [cs.CL])

    [http://arxiv.org/abs/2308.15214](http://arxiv.org/abs/2308.15214)

    本研究开发了一个交互式对话系统，将开放和封闭领域对话、脸部表情结合起来，通过使用LLMs和GPT-3.5模型来生成引人入胜的对话，以提供信息并与访客进行自然交流。

    

    我们展示了一个交互式对话系统，可以作为接待员，生成结合开放和封闭领域对话以及脸部表情的混合对话。通过使用大型语言模型（LLM）来开发引人入胜的对话，我们将该系统部署到了一个高度表达力的Furhat机器人上，在互动过程中使用了口头和非语言提示。该系统专门为国家机器人实验室设计，通过自然对话与访客进行交互，并向他们提供有关设施、研究、新闻、即将举行的活动等方面的信息。系统利用最先进的GPT-3.5模型根据提示生成这些信息，同时生成领域通用的对话和面部表情。

    We demonstrate an embodied conversational agent that can function as a receptionist and generate a mixture of open and closed-domain dialogue along with facial expressions, by using a large language model (LLM) to develop an engaging conversation. We deployed the system onto a Furhat robot, which is highly expressive and capable of using both verbal and nonverbal cues during interaction. The system was designed specifically for the National Robotarium to interact with visitors through natural conversations, providing them with information about the facilities, research, news, upcoming events, etc. The system utilises the state-of-the-art GPT-3.5 model to generate such information along with domain-general conversations and facial expressions based on prompt engineering.
    
[^80]: 适应口语对话的文本对话状态跟踪器

    Adapting text-based dialogue state tracker for spoken dialogues. (arXiv:2308.15053v1 [cs.CL])

    [http://arxiv.org/abs/2308.15053](http://arxiv.org/abs/2308.15053)

    这篇论文描述了对构建适应口语对话系统的文本对话状态跟踪器进行的工程工作，利用自动语音识别错误校正和文本对话系统实现了插槽和值的估计。

    

    尽管通过对话系统技术竞赛（DSTC）取得了显著进展，但构建一个具有语音界面的稳健的任务导向对话系统仍然是一个关键挑战。大部分进展都是针对基于文本的对话系统，因为有丰富的书面语料库数据集，而具有口语对话的数据集非常稀缺。然而，正如Siri和Alexa等语音助手系统所展示的，将这种成功转移到口语对话中具有实际重要性。在本文中，我们描述了我们在DSTC11的具有语音感知的对话系统技术挑战赛中的高度成功模型的工程努力。我们的模型由三个主要模块组成：（1）自动语音识别错误校正，以弥合口语和文本话语之间的差距，（2）用于估计插槽和值的基于文本的对话系统（D3ST），该系统使用插槽描述。

    Although there have been remarkable advances in dialogue systems through the dialogue systems technology competition (DSTC), it remains one of the key challenges to building a robust task-oriented dialogue system with a speech interface. Most of the progress has been made for text-based dialogue systems since there are abundant datasets with written corpora while those with spoken dialogues are very scarce. However, as can be seen from voice assistant systems such as Siri and Alexa, it is of practical importance to transfer the success to spoken dialogues. In this paper, we describe our engineering effort in building a highly successful model that participated in the speech-aware dialogue systems technology challenge track in DSTC11. Our model consists of three major modules: (1) automatic speech recognition error correction to bridge the gap between the spoken and the text utterances, (2) text-based dialogue system (D3ST) for estimating the slots and values using slot descriptions, an
    
[^81]: 使用不精确神经网络的分布鲁棒统计验证

    Distributionally Robust Statistical Verification with Imprecise Neural Networks. (arXiv:2308.14815v1 [cs.AI])

    [http://arxiv.org/abs/2308.14815](http://arxiv.org/abs/2308.14815)

    本文提出了一种使用不精确神经网络的分布鲁棒统计验证方法，通过结合主动学习、不确定性量化和神经网络验证，可以在大量的分布上提供对黑盒系统行为的保证。

    

    在AI安全领域，一个特别具有挑战性的问题是在高维自主系统的行为上提供保证。以可达性分析为中心的验证方法无法扩展，而纯粹的统计方法受到对采样过程的分布假设的限制。相反，我们提出了一个针对黑盒系统的分布鲁棒版本的统计验证问题，其中我们的性能保证适用于大量的分布。本文提出了一种基于主动学习、不确定性量化和神经网络验证的新方法。我们方法的一个核心部分是一种称为不精确神经网络的集成技术，它提供了不确定性以指导主动学习。主动学习使用了一种称为Sherlock的全面神经网络验证工具来收集样本。在openAI gym Mujoco环境中使用多个物理模拟器进行评估。

    A particularly challenging problem in AI safety is providing guarantees on the behavior of high-dimensional autonomous systems. Verification approaches centered around reachability analysis fail to scale, and purely statistical approaches are constrained by the distributional assumptions about the sampling process. Instead, we pose a distributionally robust version of the statistical verification problem for black-box systems, where our performance guarantees hold over a large family of distributions. This paper proposes a novel approach based on a combination of active learning, uncertainty quantification, and neural network verification. A central piece of our approach is an ensemble technique called Imprecise Neural Networks, which provides the uncertainty to guide active learning. The active learning uses an exhaustive neural-network verification tool Sherlock to collect samples. An evaluation on multiple physical simulators in the openAI gym Mujoco environments with reinforcement-
    
[^82]: 通过马尔可夫决策过程实体嵌入和代理集合上下文感知地组合代理策略

    Context-Aware Composition of Agent Policies by Markov Decision Process Entity Embeddings and Agent Ensembles. (arXiv:2308.14521v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.14521](http://arxiv.org/abs/2308.14521)

    该论文提出了一种通过马尔可夫决策过程实体嵌入和代理集合的方法，以上下文感知地组合代理策略，以在复杂且动态变化的环境中优化执行活动。

    

    计算代理在生活的许多领域中支持人类，并因此存在异构环境。这意味着它们在快速变化的环境中运作，并且可能面临巨大的状态和动作空间。为了以目标导向的方式执行服务和活动，代理需要先前的知识，因此必须制定和追求依赖于上下文的策略。然而，预先规定策略在动态变化的环境中存在限制和不灵活性。此外，代理的上下文决定了它的动作选择。由于环境可能具有随机性，并且在状态和可行动作的数量上复杂，因此通常通过马尔可夫决策过程以简化的方式建模活动，以便使用强化学习的代理能够学习策略，从而帮助捕捉上下文并根据最优方式执行活动。

    Computational agents support humans in many areas of life and are therefore found in heterogeneous contexts. This means they operate in rapidly changing environments and can be confronted with huge state and action spaces. In order to perform services and carry out activities in a goal-oriented manner, agents require prior knowledge and therefore have to develop and pursue context-dependent policies. However, prescribing policies in advance is limited and inflexible, especially in dynamically changing environments. Moreover, the context of an agent determines its choice of actions. Since the environments can be stochastic and complex in terms of the number of states and feasible actions, activities are usually modelled in a simplified way by Markov decision processes so that, e.g., agents with reinforcement learning are able to learn policies, that help to capture the context and act accordingly to optimally perform activities. However, training policies for all possible contexts using
    
[^83]: 注意力和自监督语音嵌入对非语义语音任务的影响

    Effect of Attention and Self-Supervised Speech Embeddings on Non-Semantic Speech Tasks. (arXiv:2308.14359v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.14359](http://arxiv.org/abs/2308.14359)

    该论文探讨了注意力和自监督语音嵌入对非语义语音任务的影响，特别是情感理解。实验结果表明，基于自注意力的轻量级HuBERT-Large模型在这些任务中表现出色。

    

    在现实中，人类情感理解在使对话技术成为主流方面至关重要。我们将语音情感理解视为一种知觉任务，这是一种更现实的情景。在不同的上下文（语言，人口统计学等），不同比例的人会将相同的语音片段视为非一致的情感。作为ACM多媒体2023计算语音联机挑战（ComParE）的一部分，在EMotion Share轨道上，我们利用他们丰富的多语种演讲者和多标签回归目标的数据集，即“情感分享”或对该情感的感知。我们证明了不同基础模型的训练方案决定了它们在超越语音识别的任务中的有效性，特别是对于情感理解等非语义语音任务。这是一个非常复杂的任务，因为涉及到多语种演讲者，目标标签的变化以及回归数据集中的固有不平衡性。我们的结果表明，基于自注意力的轻量级HuBERT-Large模型在这些任务中表现出色。

    Human emotion understanding is pivotal in making conversational technology mainstream. We view speech emotion understanding as a perception task which is a more realistic setting. With varying contexts (languages, demographics, etc.) different share of people perceive the same speech segment as a non-unanimous emotion. As part of the ACM Multimedia 2023 Computational Paralinguistics ChallengE (ComParE) in the EMotion Share track, we leverage their rich dataset of multilingual speakers and multi-label regression target of 'emotion share' or perception of that emotion. We demonstrate that the training scheme of different foundation models dictates their effectiveness for tasks beyond speech recognition, especially for non-semantic speech tasks like emotion understanding. This is a very complex task due to multilingual speakers, variability in the target labels, and inherent imbalance in the regression dataset. Our results show that HuBERT-Large with a self-attention-based light-weight se
    
[^84]: 评估大型语言模型对指令的鲁棒性

    Evaluating the Robustness to Instructions of Large Language Models. (arXiv:2308.14306v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.14306](http://arxiv.org/abs/2308.14306)

    本论文评估了大型语言模型对指令的鲁棒性。结果表明，指令微调可以提升中等规模模型的性能，并且模型对陌生指令的处理能力有待改进。

    

    最近，指令微调已成为提升大型语言模型在新任务中零-shot能力的潜在方法。该技术显示出出色的能力，可以提升中等规模的语言模型的性能，有时甚至达到相当于更大模型变体的性能水平。本研究重点研究了经过指令微调的语言模型对已知任务和未知任务的鲁棒性。我们对六个模型进行了探索，包括Alpaca、Vicuna、WizardLM和传统的任务导向模型（Flan-T5-XL/XXL、T0++），以真实世界的关系提取数据集作为案例研究。我们对这些遵循指令的语言模型进行了全面评估，这些模型是基于开放域指令和任务导向指令进行微调的。主要讨论的是它们在处理指令时的性能和鲁棒性。我们观察到，在大多数情况下，模型在处理陌生指令方面的性能往往会受到影响。

    Recently, Instruction fine-tuning has risen to prominence as a potential method for enhancing the zero-shot capabilities of Large Language Models (LLMs) on novel tasks. This technique has shown an exceptional ability to boost the performance of moderately sized LLMs, sometimes even reaching performance levels comparable to those of much larger model variants. The focus is on the robustness of instruction-tuned LLMs to seen and unseen tasks. We conducted an exploration of six models including Alpaca, Vicuna, WizardLM, and Traditional Task-oriented Models(Flan-T5-XL/XXL, T0++) using real-world relation extraction datasets as case studies. We carried out a comprehensive evaluation of these instruction-following LLMs which have been tuned based on open-domain instructions and task-oriented instructions. The main discussion is their performance and robustness towards instructions. We have observed that in most cases, the model's performance in dealing with unfamiliar instructions tends to w
    
[^85]: 跨领域的可信表示学习

    Trustworthy Representation Learning Across Domains. (arXiv:2308.12315v1 [cs.LG])

    [http://arxiv.org/abs/2308.12315](http://arxiv.org/abs/2308.12315)

    本论文首次提出了跨领域的可信表示学习框架，通过包括鲁棒性、隐私、公平性和可解释性等概念，对该研究方向进行了全面的文献综述。

    

    随着人工智能系统在我们日常生活和人类社会中取得显著的性能，人们既享受到了这些技术带来的好处，也面临因这些系统而引发的许多社会问题。为了使人工智能系统足够好并且可信，已经进行了大量研究，建立了可信人工智能系统的指南。机器学习是人工智能系统中最重要的部分之一，而表示学习是机器学习中的基础技术。如何使表示学习在现实世界的应用中具有可信度，例如跨领域场景，对于机器学习和人工智能系统领域都是非常有价值和必要的。在可信人工智能的概念启发下，我们提出了第一个跨领域的可信表示学习框架，包括了鲁棒性、隐私、公平性和可解释性这四个概念，对这个研究方向进行了全面的文献综述。

    As AI systems have obtained significant performance to be deployed widely in our daily live and human society, people both enjoy the benefits brought by these technologies and suffer many social issues induced by these systems. To make AI systems good enough and trustworthy, plenty of researches have been done to build guidelines for trustworthy AI systems. Machine learning is one of the most important parts for AI systems and representation learning is the fundamental technology in machine learning. How to make the representation learning trustworthy in real-world application, e.g., cross domain scenarios, is very valuable and necessary for both machine learning and AI system fields. Inspired by the concepts in trustworthy AI, we proposed the first trustworthy representation learning across domains framework which includes four concepts, i.e, robustness, privacy, fairness, and explainability, to give a comprehensive literature review on this research direction. Specifically, we first 
    
[^86]: 扩展AI：向拥有创造性的AlphaZero国际象棋迈进

    Diversifying AI: Towards Creative Chess with AlphaZero. (arXiv:2308.09175v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.09175](http://arxiv.org/abs/2308.09175)

    本研究探索了AI在计算任务中是否可以从创造性决策机制中受益，并通过构建多样化的AI系统团队，在挑战性任务中超越单个AI，通过生成更多的想法，并选择最佳想法。在国际象棋中的实验结果显示，多样化AI系统以不同方式下国际象棋。

    

    近年来，人工智能系统在各种计算任务上已经超过了人类的智能。然而，与人类一样，AI系统也会犯错误，有盲点，产生幻觉，并且在面对新情况时很难进行泛化。本研究探讨了当AI系统的计算合理性推到极限时，是否可以从创造性的决策机制中受益。特别是，我们研究了是否通过作为一个团队的多样化AI系统在具有挑战性的任务中可以胜过单个AI，通过生成更多的想法，然后选择最好的想法。我们以国际象棋这个被称为AI果蝇的游戏为例进行了研究。我们在AlphaZero (AZ)的基础上，通过潜变条件架构扩展它，构建了一个代理团队，我们称之为AZ_db。我们使用行为多样性技术对AZ_db进行训练，以生成更广泛的想法，并通过次加性计划选择最有希望的想法。我们的实验表明，AZ_db以不同方式下国际象棋。

    In recent years, Artificial Intelligence (AI) systems have surpassed human intelligence in a variety of computational tasks. However, AI systems, like humans, make mistakes, have blind spots, hallucinate, and struggle to generalize to new situations. This work explores whether AI can benefit from creative decision-making mechanisms when pushed to the limits of its computational rationality. In particular, we investigate whether a team of diverse AI systems can outperform a single AI in challenging tasks by generating more ideas as a group and then selecting the best ones. We study this question in the game of chess, the so-called drosophila of AI. We build on AlphaZero (AZ) and extend it to represent a league of agents via a latent-conditioned architecture, which we call AZ_db. We train AZ_db to generate a wider range of ideas using behavioral diversity techniques and select the most promising ones with sub-additive planning. Our experiments suggest that AZ_db plays chess in diverse wa
    
[^87]: 加密货币证券案件中的大型语言模型：ChatGPT能否取代律师？

    Large Language Models in Cryptocurrency Securities Cases: Can ChatGPT Replace Lawyers?. (arXiv:2308.06032v1 [cs.AI])

    [http://arxiv.org/abs/2308.06032](http://arxiv.org/abs/2308.06032)

    本研究探讨了在加密货币证券案件中，大型语言模型（LLMs）是否能够准确判断违法行为，并比较了由LLM和律师撰写的投诉书对陪审团决策的影响。研究发现，目前的LLMs在法律推理方面表现较弱，但随着未来模型的改进，其潜力有望提升。

    

    大型语言模型（LLMs）可以增强对法律系统的访问。然而，关于它们在进行法律任务方面的有效性的实证研究非常有限。我们研究涉及加密货币的证券案件，作为AI可以支持法律过程的众多情境之一，研究LLMs的法律推理和起草能力。我们检查以下两个方面：a）LLM能否准确确定事实模式中可能存在的违法行为，b）基于LLM和律师撰写的投诉书，陪审团的决策是否有所差异。我们将真实案例中的事实模式输入GPT-3.5，并评估其确定正确潜在违法行为并排除虚假违法行为的能力。其次，我们请模拟陪审员评估LLM和律师撰写的投诉书。GPT-3.5的法律推理能力较弱，但我们预期未来模型的改进，特别是考虑到它建议的违法行为往往是正确的（它仅仅过于保守）。

    Large Language Models (LLMs) could enhance access to the legal system. However, empirical research on their effectiveness in conducting legal tasks is scant. We study securities cases involving cryptocurrencies as one of numerous contexts where AI could support the legal process, studying LLMs' legal reasoning and drafting capabilities. We examine whether a) an LLM can accurately determine which laws are potentially being violated from a fact pattern, and b) whether there is a difference in juror decision-making based on complaints written by a lawyer compared to an LLM. We feed fact patterns from real-life cases to GPT-3.5 and evaluate its ability to determine correct potential violations from the scenario and exclude spurious violations. Second, we had mock jurors assess complaints written by the LLM and lawyers. GPT-3.5's legal reasoning skills proved weak, though we expect improvement in future models, particularly given the violations it suggested tended to be correct (it merely m
    
[^88]: AIs的发展脱靴法

    Developmental Bootstrapping of AIs. (arXiv:2308.04586v1 [cs.AI])

    [http://arxiv.org/abs/2308.04586](http://arxiv.org/abs/2308.04586)

    传统的符号AI方法和深度学习AI方法无法满足创建强大和可信赖的AI的挑战，然而，发展脱靴法通过模仿人类儿童的能力发展过程，为创建稳健可靠的AI提供了希望。

    

    尽管当前一些AI在封闭的世界，如棋盘游戏中超越了人类能力，但它们在混乱的现实世界中的表现有限。它们会犯奇怪的错误而且没有意识到。它们很难受到指导，不能运用常识，缺乏好奇心。它们不能成为良好的合作者。传统手动构建的符号AI方法构建的系统和使用生成和深度学习AI方法(包括大规模语言模型)构建的系统都无法应对这些挑战。它们不适合创建强大和可信赖的AI。尽管此方法不属于主流的AI方法，但发展脱靴法显示出希望。在发展脱靴法中，AI像人类儿童一样发展能力。它们从先天能力开始。像人类一样，它们与环境互动，并从互动中学习。它们通过自我发展的能力逐步扩展先天能力。它们互动并逐渐将所学应用于实际操作。

    Although some current AIs surpass human abilities especially in closed worlds such as board games, their performance in the messy real world is limited. They make strange mistakes and do not notice them. They cannot be instructed easily, fail to use common sense, and lack curiosity. They do not make good collaborators. Neither systems built using the traditional manually-constructed symbolic AI approach nor systems built using generative and deep learning AI approaches including large language models (LLMs) can meet the challenges. They are not well suited for creating robust and trustworthy AIs. Although it is outside of mainstream AI approaches, developmental bootstrapping shows promise. In developmental bootstrapping, AIs develop competences like human children do. They start with innate competences. Like humans, they interact with the environment and learn from their interactions. They incrementally extend their innate competences with self-developed competences. They interact and 
    
[^89]: 为什么我们尚未拥有AGI

    Why We Don't Have AGI Yet. (arXiv:2308.03598v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.03598](http://arxiv.org/abs/2308.03598)

    本论文探讨了为什么尚未实现人工通用智能（AGI），并指出了纯粹的统计方法和资金推广不足是制约AGI发展的原因之一，同时还分析了实现人类适应能力和自主学习所需的关键认知能力。

    

    2002年重新阐述了AI的原始愿景，称之为“人工通用智能”或AGI。这一愿景是构建能够像人类一样学习、推理和解决问题的“思考机器”计算机系统。这与几十年来几乎所有人在该领域实践的“狭义AI”方法形成鲜明对比。虽然有几个大规模的项目名义上在致力于AGI的研发（尤其是DeepMind），但在纯粹专注的AGI发展领域，资金和推广并不充足。这令人惊讶，因为真正的AGI可以为人类带来巨大的价值。除了在这个领域缺乏努力之外，还存在亏欠的理论和方法上的错误。我们强调纯粹的统计方法无法实现AGI，并确定了实现类似人类适应能力和自主学习的关键认知能力。最终，我们概述了社会技术发展方面的一些问题。

    The original vision of AI was re-articulated in 2002 via the term 'Artificial General Intelligence' or AGI. This vision is to build 'Thinking Machines' computer systems that can learn, reason, and solve problems similar to the way humans do. This is in stark contrast to the 'Narrow AI' approach practiced by almost everyone in the field over the many decades. While several large-scale efforts have nominally been working on AGI (most notably DeepMind), the field of pure focused AGI development has not been well funded or promoted. This is surprising given the fantastic value that true AGI can bestow on humanity. In addition to the dearth of effort in this field, there are also several theoretical and methodical missteps that are hampering progress. We highlight why purely statistical approaches are unlikely to lead to AGI, and identify several crucial cognitive abilities required to achieve human-like adaptability and autonomous learning. We conclude with a survey of socio-technical fa
    
[^90]: 分散式POMDP中基于在线聚类标签的离散消息传递

    Discrete Message via Online Clustering Labels in Decentralized POMDP. (arXiv:2308.03358v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.03358](http://arxiv.org/abs/2308.03358)

    本文通过建立回报差距上界，将多智能体通信问题转化为离散消息的在线聚类问题。该方法能够提供量化保证，并且具有通信开销低、可解释性好的特点。

    

    在部分可观察的马尔可夫决策过程中，通信对于解决合作多智能体强化学习任务至关重要。现有工作通常依赖于黑盒方法，将本地信息/特征编码成与其他智能体共享的消息。然而，这种黑盒方法无法对期望回报提供任何量化保证，常常导致生成通信开销高、可解释性差的连续消息。本文在理想策略与最优部分可观察策略之间建立了回报差距的上界。该结果使我们能够将多智能体通信重新定义为每个智能体的本地观察中的一种新颖的在线聚类问题，其中消息作为聚类标签，并且回报差距的上界作为聚类损失。通过最小化上界，我们提出了一个令人惊讶地简单的消息生成函数设计。

    Communication is crucial for solving cooperative Multi-Agent Reinforcement Learning tasks in Partially-Observable Markov Decision Processes. Existing works often rely on black-box methods to encode local information/features into messages shared with other agents. However, such black-box approaches are unable to provide any quantitative guarantees on the expected return and often lead to the generation of continuous messages with high communication overhead and poor interpretability. In this paper, we establish an upper bound on the return gap between an ideal policy with full observability and an optimal partially-observable policy with discrete communication. This result enables us to recast multi-agent communication into a novel online clustering problem over the local observations at each agent, with messages as cluster labels and the upper bound on the return gap as clustering loss. By minimizing the upper bound, we propose a surprisingly simple design of message generation functi
    
[^91]: 自动纠正大型语言模型：多样化自我纠正策略的概述调查

    Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies. (arXiv:2308.03188v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2308.03188](http://arxiv.org/abs/2308.03188)

    本文总结了最近的研究，对多样化的自我纠正策略进行了分类和分析，以解决大型语言模型中的问题行为。自动化反馈技术被证明是一种可行的方法，可以使基于大型语言模型的解决方案更实用和可部署。

    

    大型语言模型(LLMs)在各种自然语言处理任务中展现了卓越的性能。然而，它们的功效受到了不受欢迎和不一致的行为的削弱，包括幻觉、不忠实的推理和有害内容。纠正这些缺陷的一种有前景的方法是自我纠正，即引导或指导LLM自行修复输出问题。利用自动反馈的技术--无论是由LLM自身产生还是由某个外部系统产生--尤其有趣，因为它们是使基于LLM的解决方案更实际和可部署的一种有前景的方式，且只需最少的人类反馈。本文对这一新兴技术类别进行了全面的评估。我们分析和分类了许多最近利用这些策略的工作，包括训练时、生成时和事后纠正的技术。我们还总结了这一策略的主要应用，并在最后讨论了未来的发展方向和挑战。

    Large language models (LLMs) have demonstrated remarkable performance across a wide array of NLP tasks. However, their efficacy is undermined by undesired and inconsistent behaviors, including hallucination, unfaithful reasoning, and toxic content. A promising approach to rectify these flaws is self-correction, where the LLM itself is prompted or guided to fix problems in its own output. Techniques leveraging automated feedback -- either produced by the LLM itself or some external system -- are of particular interest as they are a promising way to make LLM-based solutions more practical and deployable with minimal human feedback. This paper presents a comprehensive review of this emerging class of techniques. We analyze and taxonomize a wide array of recent work utilizing these strategies, including training-time, generation-time, and post-hoc correction. We also summarize the major applications of this strategy and conclude by discussing future directions and challenges.
    
[^92]: 使用视觉和文本数据的联合表示进行食物分类

    Food Classification using Joint Representation of Visual and Textual Data. (arXiv:2308.02562v1 [cs.CV])

    [http://arxiv.org/abs/2308.02562](http://arxiv.org/abs/2308.02562)

    本研究提出了一种使用联合表示的多模态分类框架，通过修改版的EfficientNet和Mish激活函数实现图像分类，使用基于BERT的网络实现文本分类。实验结果表明，所提出的网络在图像和文本分类上表现优于其他方法，准确率提高了11.57%和6.34%。比较分析还证明了所提出方法的效率和鲁棒性。

    

    食物分类是健康保健中的重要任务。在这项工作中，我们提出了一个多模态分类框架，该框架使用了修改版的EfficientNet和Mish激活函数用于图像分类，同时使用传统的基于BERT的网络进行文本分类。我们在一个大型开源数据集UPMC Food-101上评估了所提出的网络和其他最先进的方法。实验结果显示，所提出的网络在图像和文本分类上的准确率分别比第二最好的方法提高了11.57%和6.34%。我们还比较了使用机器学习和深度学习模型进行文本分类的准确率、精确率和召回率。通过对图像和文本的预测结果进行比较分析，证明了所提出方法的效率和鲁棒性。

    Food classification is an important task in health care. In this work, we propose a multimodal classification framework that uses the modified version of EfficientNet with the Mish activation function for image classification, and the traditional BERT transformer-based network is used for text classification. The proposed network and the other state-of-the-art methods are evaluated on a large open-source dataset, UPMC Food-101. The experimental results show that the proposed network outperforms the other methods, a significant difference of 11.57% and 6.34% in accuracy is observed for image and text classification, respectively, when compared with the second-best performing method. We also compared the performance in terms of accuracy, precision, and recall for text classification using both machine learning and deep learning-based models. The comparative analysis from the prediction results of both images and text demonstrated the efficiency and robustness of the proposed approach.
    
[^93]: Google Bard的视觉理解能力如何？开放挑战的实证研究。

    How Good is Google Bard's Visual Understanding? An Empirical Study on Open Challenges. (arXiv:2307.15016v1 [cs.CV])

    [http://arxiv.org/abs/2307.15016](http://arxiv.org/abs/2307.15016)

    本研究探索了Google Bard在理解和解释文本问题条件下的视觉数据方面的能力，并发现Bard在各种视觉场景中仍然存在困境，这凸显出在视觉理解方面存在重要的差距。

    

    Google的Bard在对话型人工智能领域与OpenAI的ChatGPT成为了强大的竞争对手。值得注意的是，Bard最近已经更新，可以在对话过程中处理文本提示和视觉输入。鉴于Bard在处理文本输入方面的出色表现，我们探索了其在理解和解释由文本问题条件下的视觉数据（图像）方面的能力。这种探索有潜力揭示Bard和其他即将发布的多模式生成模型在解决需要准确的视觉和语言理解的复杂计算机视觉问题时的新见解和挑战。具体而言，在这项研究中，我们专注于15个不同的任务场景，包括常规、伪装、医学、水下和遥感数据，全面评估了Bard的性能。我们的主要发现表明，Bard在这些视觉场景中仍然存在困境，突显了在基于视觉的理解方面存在的重要差距。

    Google's Bard has emerged as a formidable competitor to OpenAI's ChatGPT in the field of conversational AI. Notably, Bard has recently been updated to handle visual inputs alongside text prompts during conversations. Given Bard's impressive track record in handling textual inputs, we explore its capabilities in understanding and interpreting visual data (images) conditioned by text questions. This exploration holds the potential to unveil new insights and challenges for Bard and other forthcoming multi-modal Generative models, especially in addressing complex computer vision problems that demand accurate visual and language understanding. Specifically, in this study, we focus on 15 diverse task scenarios encompassing regular, camouflaged, medical, under-water and remote sensing data to comprehensively evaluate Bard's performance. Our primary finding indicates that Bard still struggles in these vision scenarios, highlighting the significant gap in vision-based understanding that needs t
    
[^94]: 使用大型语言模型增强密集检索的软提示调优

    Soft Prompt Tuning for Augmenting Dense Retrieval with Large Language Models. (arXiv:2307.08303v1 [cs.IR] CROSS LISTED)

    [http://arxiv.org/abs/2307.08303](http://arxiv.org/abs/2307.08303)

    本论文提出了一种使用软提示调优来增强密集检索的方法（SPTAR）。通过优化任务特定的软提示并利用大型语言模型为未标记的文档生成弱查询，可以提高零样本和少样本的密集检索模型的性能。

    

    密集检索（DR）将查询和文档转化为密集向量表示，并在向量空间中测量查询与文档之间的相似性。DR的一个挑战是缺乏领域特定的训练数据。虽然DR模型可以通过迁移学习从大规模公共数据集（如MS MARCO）中学习，但证据表明，并非所有DR模型和领域都能同等受益于迁移学习。最近，一些研究人员转向使用大型语言模型（LLMs）来改进零样本和少样本的DR模型。然而，这些方法中采用的硬提示或人工编写的提示无法保证生成的弱查询的质量。为了解决这个问题，我们提出了用于增强DR的软提示调优（SPTAR）：对于每个任务，我们利用软提示调优在有限的真实数据上优化任务特定的软提示，然后用这些提示引导LLMs为未标记的文档标记弱查询，从而得到足够的弱文档-查询对来训练任务特定的模型。

    Dense retrieval (DR) converts queries and documents into dense embeddings and measures the similarity between queries and documents in vector space. One of the challenges in DR is the lack of domain-specific training data. While DR models can learn from large-scale public datasets like MS MARCO through transfer learning, evidence shows that not all DR models and domains can benefit from transfer learning equally. Recently, some researchers have resorted to large language models (LLMs) to improve the zero-shot and few-shot DR models. However, the hard prompts or human-written prompts utilized in these works cannot guarantee the good quality of generated weak queries. To tackle this, we propose soft prompt tuning for augmenting DR (SPTAR): For each task, we leverage soft prompt-tuning to optimize a task-specific soft prompt on limited ground truth data and then prompt the LLMs to tag unlabeled documents with weak queries, yielding enough weak document-query pairs to train task-specific d
    
[^95]: 由生成闭环人工智能引领的基础科学的未来

    The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence. (arXiv:2307.07522v1 [cs.AI])

    [http://arxiv.org/abs/2307.07522](http://arxiv.org/abs/2307.07522)

    生成型人工智能和大型语言模型可能为基础科学的发现提供机会，通过其自主生成假设和探索假设空间的闭环方法，加速科学发现的进程。

    

    机器学习和人工智能的最新进展，包括生成型人工智能和大型语言模型，正在颠覆技术创新、产品开发和整个社会。人工智能对技术的贡献可以通过多种途径实现，需要大量训练数据集和明确的性能评估标准，范围从模式识别和分类到生成模型。然而，由于科学实践和模型发现需要访问高质量的大型数据集，人工智能对基础科学的贡献较少。生成型人工智能，特别是大型语言模型，可能代表了通过定量模型增强和加速基础深度科学的科学发现的机会。在这里，我们探索和研究了一种由人工智能驱动、自动化的闭环科学发现方法的各个方面，包括自主生成假设和开放式自主探索假设空间。

    Recent advances in machine learning and AI, including Generative AI and LLMs, are disrupting technological innovation, product development, and society as a whole. AI's contribution to technology can come from multiple approaches that require access to large training data sets and clear performance evaluation criteria, ranging from pattern recognition and classification to generative models. Yet, AI has contributed less to fundamental science in part because large data sets of high-quality data for scientific practice and model discovery are more difficult to access. Generative AI, in general, and Large Language Models in particular, may represent an opportunity to augment and accelerate the scientific discovery of fundamental deep science with quantitative models. Here we explore and investigate aspects of an AI-driven, automated, closed-loop approach to scientific discovery, including self-driven hypothesis generation and open-ended autonomous exploration of the hypothesis space. Int
    
[^96]: 每个人的数字建模：探索新手如何进行基于语音的3D建模

    Digital Modeling for Everyone: Exploring How Novices Approach Voice-Based 3D Modeling. (arXiv:2307.04481v2 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2307.04481](http://arxiv.org/abs/2307.04481)

    该研究探索了新手在基于语音的3D建模中的心智模型，并为语音助手的设计提供了实用的设计启示，例如处理模糊、不完整和错误的命令，提供简单的命令来塑造对象，以及选择3D对象的不同策略。

    

    制造工具如3D打印机已经变得可供更广泛的社会使用，数字制造对每个人的承诺似乎可以实现。尽管实际的制造过程在今天是大部分自动化的，但用户仍然需要掌握复杂的设计应用程序，以制作出准备好的设计对象，并根据需要进行调整，或者从零开始设计新的对象。为了降低个性化3D模型的设计和定制门槛，我们通过高保真Wizard of Oz研究与22名参与者一起探索了新手的心智模型在基于语音的3D建模中的体现。我们对收集到的数据进行主题分析，以了解新手的心智模型如何转化为基于语音的3D建模。最后，我们给出了用于语音助手的设计启示。例如，它们必须处理模糊、不完整和错误的命令；提供一组直接的命令来塑造简单和复合对象；并提供不同的策略来选择3D对象。

    Manufacturing tools like 3D printers have become accessible to the wider society, making the promise of digital fabrication for everyone seemingly reachable. While the actual manufacturing process is largely automated today, users still require knowledge of complex design applications to produce ready-designed objects and adapt them to their needs or design new objects from scratch. To lower the barrier to the design and customization of personalized 3D models, we explored novice mental models in voice-based 3D modeling by conducting a high-fidelity Wizard of Oz study with 22 participants. We performed a thematic analysis of the collected data to understand how the mental model of novices translates into voice-based 3D modeling. We conclude with design implications for voice assistants. For example, they have to: deal with vague, incomplete and wrong commands; provide a set of straightforward commands to shape simple and composite objects; and offer different strategies to select 3D ob
    
[^97]: 利用传输学习方法在LiDAR数据上识别埋藏的考古结构的语义分割研究

    Tranfer Learning of Semantic Segmentation Methods for Identifying Buried Archaeological Structures on LiDAR Data. (arXiv:2307.03512v1 [cs.CV])

    [http://arxiv.org/abs/2307.03512](http://arxiv.org/abs/2307.03512)

    本文研究了利用传输学习方法在LiDAR数据上识别埋藏的考古结构的语义分割。实验结果表明，传输学习的应用可以提高性能，为未来工作提供基准。

    

    当将深度学习应用于考古研究中的遥感数据时，一个显著的障碍是适用于模型训练的合适数据集的有限可用性。传输学习的应用经常被用来减轻这个缺点。然而，仍有必要探索在不同考古数据集上应用传输学习的有效性。本文比较了使用两个语义分割深度神经网络在两个LiDAR数据集上的各种传输学习配置的性能。实验结果表明，基于传输学习的方法在考古学中可以提高性能，尽管尚未观察到系统性的改进。我们提供了关于此类技术有效性的具体见解，可作为未来工作的基准。

    When applying deep learning to remote sensing data in archaeological research, a notable obstacle is the limited availability of suitable datasets for training models. The application of transfer learning is frequently employed to mitigate this drawback. However, there is still a need to explore its effectiveness when applied across different archaeological datasets. This paper compares the performance of various transfer learning configurations using two semantic segmentation deep neural networks on two LiDAR datasets. The experimental results indicate that transfer learning-based approaches in archaeology can lead to performance improvements, although a systematic enhancement has not yet been observed. We provide specific insights about the validity of such techniques that can serve as a baseline for future works.
    
[^98]: 在不确定的海洋洋流中进行动力编程的无效系统上的自主农场上的海藻生长的最大化方法

    Maximizing Seaweed Growth on Autonomous Farms: A Dynamic Programming Approach for Underactuated Systems Navigating on Uncertain Ocean Currents. (arXiv:2307.01916v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2307.01916](http://arxiv.org/abs/2307.01916)

    设计了一种基于动态规划的方法，用于在不确定的海洋洋流中最大化海藻生长，通过利用非线性时变的洋流实现高生长区域的探测。

    

    海藻生物量在气候减缓方面具有重要潜力，但需要大规模的自主开放式海洋农场来充分利用。这些农场通常具有低推进力，并受到海洋洋流的重大影响。我们希望设计一个控制器，通过利用非线性时变的海洋洋流来达到高生长区域，从而在几个月内最大化海藻生长。复杂的动力学和无效性使得即使知道洋流情况，这也是具有挑战性的。当只有短期不完善的预测且不确定性逐渐增大时，情况变得更加困难。我们提出了一种基于动态规划的方法，可以在已知真实洋流情况时有效地求解最优生长值函数。此外，我们还提出了三个扩展，即在现实中只知道预测的情况下：（1）我们方法得到的值函数可以作为反馈策略，以获得所有状态和时间的最佳生长控制，实现闭环控制的等价性。

    Seaweed biomass offers significant potential for climate mitigation, but large-scale, autonomous open-ocean farms are required to fully exploit it. Such farms typically have low propulsion and are heavily influenced by ocean currents. We want to design a controller that maximizes seaweed growth over months by taking advantage of the non-linear time-varying ocean currents for reaching high-growth regions. The complex dynamics and underactuation make this challenging even when the currents are known. This is even harder when only short-term imperfect forecasts with increasing uncertainty are available. We propose a dynamic programming-based method to efficiently solve for the optimal growth value function when true currents are known. We additionally present three extensions when as in reality only forecasts are known: (1) our methods resulting value function can be used as feedback policy to obtain the growth-optimal control for all states and times, allowing closed-loop control equival
    
[^99]: HypLL: 希亚空间深度学习库

    HypLL: The Hyperbolic Learning Library. (arXiv:2306.06154v1 [cs.LG])

    [http://arxiv.org/abs/2306.06154](http://arxiv.org/abs/2306.06154)

    HypLL是一个使用希亚空间的深度学习库，基于PyTorch，旨在使其易于使用，搭建希亚网络模块，特别适用于处理层次化数据和使用少量嵌入维度，是一种新的、开放的研究方向。

    

    在机器学习、多媒体和计算机视觉等领域，希亚空间深度学习正迅速引起关注。深度网络通常在欧几里得空间中运行，隐含地假设数据在规则网格上。最近的研究表明，当处理层次化数据和使用少量嵌入维度时，希亚几何提供了一个可行的深度学习基础。然而，目前没有可访问的开源库用于构建类似于众所周知的深度学习库的希亚网络模块。我们提出了HypLL, 即希亚空间深度学习库，以将希亚深度学习的进展聚集在一起。HypLL建立在PyTorch之上，特别强调其易用性设计，以吸引广泛的受众关注这个新的和开放的研究方向。代码可在以下网址找到：https://github.com/maxvanspengler/hyperbolic_learning_library。压缩文件可在以下网址找到：https://d

    Deep learning in hyperbolic space is quickly gaining traction in the fields of machine learning, multimedia, and computer vision. Deep networks commonly operate in Euclidean space, implicitly assuming that data lies on regular grids. Recent advances have shown that hyperbolic geometry provides a viable alternative foundation for deep learning, especially when data is hierarchical in nature and when working with few embedding dimensions. Currently however, no accessible open-source library exists to build hyperbolic network modules akin to well-known deep learning libraries. We present HypLL, the Hyperbolic Learning Library to bring the progress on hyperbolic deep learning together. HypLL is built on top of PyTorch, with an emphasis in its design for easy-of-use, in order to attract a broad audience towards this new and open-ended research direction. The code is available at: https://github.com/maxvanspengler/hyperbolic_learning_library. The compressed archive is available at: https://d
    
[^100]: 自顶向下网络将反向传播与注意力相结合

    Top-Down Network Combines Back-Propagation with Attention. (arXiv:2306.02415v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2306.02415](http://arxiv.org/abs/2306.02415)

    本研究提出了一种新颖的自顶向下网络结构，将反向传播和注意力相结合，使网络能够同时进行学习和引导注意力。

    

    大脑在视觉和其他领域中的皮层处理将自下而上的处理与广泛的自顶向下处理相结合。自顶向下处理的两个主要目标是学习和引导注意力。目前的网络模型通过不同的机制实现这两个作用。注意力引导通常通过扩展模型的结构来实现，而学习通常通过外部学习算法（如反向传播）来实现。在这项工作中，我们提出了一个综合上述两个看似无关的功能的方法，该方法受人脑启发。我们提出了一种新颖的对称自下而上自顶向下网络结构，可以将传统的自下而上网络与对称的自顶向下网络结合起来，使每个网络可以互相循环地引导和影响对方。例如，在多任务学习中，同一个自顶向下网络被用于学习和通过传递反馈信号进行引导。

    Cortical processing, in vision and other domains, combines bottom-up (BU) with extensive top-down (TD) processing. Two primary goals attributed to TD processing are learning and directing attention. These two roles are accomplished in current network models through distinct mechanisms. Attention guidance is often implemented by extending the model's architecture, while learning is typically accomplished by an external learning algorithm such as back-propagation. In the current work, we present an integration of the two functions above, which appear unrelated, using a single unified mechanism inspired by the human brain. We propose a novel symmetric bottom-up top-down network structure that can integrate conventional bottom-up networks with a symmetric top-down counterpart, allowing each network to recurrently guide and influence the other. For example, during multi-task learning, the same top-down network is being used for both learning, via propagating feedback signals, and at the sam
    
[^101]: 预训练Transformer用于对抗性样本提纯

    Pre-trained transformer for adversarial purification. (arXiv:2306.01762v1 [cs.CR])

    [http://arxiv.org/abs/2306.01762](http://arxiv.org/abs/2306.01762)

    本文提出了一个快速防御对抗性攻击的方案RaPiD（Rapid Plug-in Defender），通过预训练的Transformer微调来提纯对抗样本，使其逼近清洁数据分布，实验结果表明，在有限数据情况下，该方法优于最先进的方法。

    

    随着越来越多的深度神经网络被部署为各种日常服务，它们的可靠性至关重要。深度神经网络容易受到对抗性攻击的影响，其中逃避攻击是最普遍的一种。最近的研究通常通过对抗训练或利用大量清洁数据的知识来增强其健壮性。然而，在实际应用中，重新训练和部署模型需要大量的计算资源，对在线服务造成重大损失。此外，当检测到某种攻击的对抗性例子时，服务提供者只能获得有限的对抗性样本，而大量的清洁数据可能无法获取。针对这些问题，我们提出了一种新的方案，名为RaPiD（Rapid Plug-in Defender），旨在快速防御具有少量干净和对抗性示例限制的原始服务模型的某种攻击。受到预训练模型提供转移学习良好初始化的通用趋势的启发，我们建议通过微调预先训练的Transformer来提纯对抗性样本。预训练的Transformer作为正则化器，鼓励提纯后的对抗性样本接近清晰数据的分布。实验结果表明，RaPiD在防御各种具有限数据的攻击方面优于最先进的方法。

    With more and more deep neural networks being deployed as various daily services, their reliability is essential. It's frightening that deep neural networks are vulnerable and sensitive to adversarial attacks, the most common one of which for the services is evasion-based. Recent works usually strengthen the robustness by adversarial training or leveraging the knowledge of an amount of clean data. However, in practical terms, retraining and redeploying the model need a large computational budget, leading to heavy losses to the online service. In addition, when adversarial examples of a certain attack are detected, only limited adversarial examples are available for the service provider, while much clean data may not be accessible. Given the mentioned problems, we propose a new scenario, RaPiD (Rapid Plug-in Defender), which is to rapidly defend against a certain attack for the frozen original service model with limitations of few clean and adversarial examples. Motivated by the general
    
[^102]: 大语言模型不是公平的评估器。

    Large Language Models are not Fair Evaluators. (arXiv:2305.17926v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17926](http://arxiv.org/abs/2305.17926)

    本文揭示了使用大语言模型作为评估器时存在的系统偏差，可以通过改变候选响应的顺序来操纵评估结果。为了解决这个问题，提出了一个校准框架，包括多证据校准、均衡位置校准和人机协同校准。

    

    在这篇论文中，我们揭示了采用大语言模型（LLMs）（例如GPT-4）作为裁判来评分和比较候选模型生成的响应质量的评估范式中存在的系统偏差。我们发现，通过简单地改变候选响应在上下文中出现的顺序，可以轻松地操纵候选响应的质量排名。这种操纵使得一个模型看起来比另一个模型要优越得多，例如，使用ChatGPT作为评估器，在80个测试查询中，Vicuna-13B可以击败ChatGPT的66个。为了解决这个问题，我们提出了一个校准框架，其中包含三个简单而有效的策略：1）多证据校准，要求评估模型在分配评分之前生成多个评估证据；2）均衡位置校准，在各种顺序中聚合结果以确定最终分数；3）人机协同校准，引入平衡的位置多样性。

    In this paper, we uncover a systematic bias in the evaluation paradigm of adopting large language models~(LLMs), e.g., GPT-4, as a referee to score and compare the quality of responses generated by candidate models. We find that the quality ranking of candidate responses can be easily hacked by simply altering their order of appearance in the context. This manipulation allows us to skew the evaluation result, making one model appear considerably superior to the other, e.g., Vicuna-13B could beat ChatGPT on 66 over 80 tested queries with ChatGPT as an evaluator. To address this issue, we propose a calibration framework with three simple yet effective strategies: 1) Multiple Evidence Calibration, which requires the evaluator model to generate multiple evaluation evidence before assigning ratings; 2) Balanced Position Calibration, which aggregates results across various orders to determine the final score; 3) Human-in-the-Loop Calibration, which introduces a balanced position diversity en
    
[^103]: 评估GPT-3生成的仇恨内容审核解释

    Evaluating GPT-3 Generated Explanations for Hateful Content Moderation. (arXiv:2305.17680v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.17680](http://arxiv.org/abs/2305.17680)

    本文通过调查和分析，评估了使用GPT-3生成的针对仇恨内容的解释是否准确和有用。结果显示，GPT-3生成的解释普遍存在过于模糊、聚焦不当等缺点，同时也存在不同类型仇恨言论生成的解释质量差异大的问题。

    

    最近的研究聚焦于使用基于大型语言模型（LLMs）的Fine-tune或提示生成仇恨言论的解释。尽管这个领域越来越受关注，但这些生成解释的有效性和潜在限制仍然不为人们所了解。一个关键问题是，由LLMs生成的这些解释可能会导致用户和内容审核员对标记内容本质做出错误判断。我们提出一个分析框架来检查仇恨言论解释，并进行了一个广泛的调查来评估这些解释。我们在GPT-3上输入仇恨和非仇恨内容，发现受调查者在人工审核GPT生成的解释时，将仇恨言论解释评价为不够准确和有用。

    Recent research has focused on using large language models (LLMs) to generate explanations for hate speech through fine-tuning or prompting. Despite the growing interest in this area, these generated explanations' effectiveness and potential limitations remain poorly understood. A key concern is that these explanations, generated by LLMs, may lead to erroneous judgments about the nature of flagged content by both users and content moderators. For instance, an LLM-generated explanation might inaccurately convince a content moderator that a benign piece of content is hateful. In light of this, we propose an analytical framework for examining hate speech explanations and conducted an extensive survey on evaluating such explanations. Specifically, we prompted GPT-3 to generate explanations for both hateful and non-hateful content, and a survey was conducted with 2,400 unique respondents to evaluate the generated explanations. Our findings reveal that (1) human evaluators rated the GPT-gene
    
[^104]: Sensecape：利用大语言模型实现多层次探索和知识建构

    Sensecape: Enabling Multilevel Exploration and Sensemaking with Large Language Models. (arXiv:2305.11483v1 [cs.HC])

    [http://arxiv.org/abs/2305.11483](http://arxiv.org/abs/2305.11483)

    这篇论文讲述了一个交互式系统Sensecape，它能够利用大语言模型（LLM）支持复杂的信息任务，帮助用户通过多级抽象管理信息的复杂性，并在规划和知识建构之间无缝切换，有助于增强用户的信息组织和探索能力。

    

    如今，人们越来越多地将大语言模型（LLM）应用于复杂的信息任务中，例如学术研究或计划搬到另一个城市。然而，尽管这些任务通常需要非线性工作方式，例如将信息在空间上进行排布以组织并理解它，但目前与LLM交互的界面通常是线性的，以支持对话式交互。为了解决这个限制并探索如何支持LLM-powered的探索和知识建构，我们开发了Sensecape，这是一个交互式系统，旨在通过使用户能够（1）通过多级抽象来管理信息的复杂性，（2）无缝地在规划和知识建构之间切换，以支持LLM进行复杂信息任务。我们的被试用户研究表明，Sensecape使用户能够探索更多的主题并以分层结构组织他们的知识。我们为基于LLM的工作流程和信息任务界面做出了贡献和启示。

    People are increasingly turning to large language models (LLMs) for complex information tasks like academic research or planning a move to another city. However, while they often require working in a nonlinear manner - e.g., to arrange information spatially to organize and make sense of it, current interfaces for interacting with LLMs are generally linear to support conversational interaction. To address this limitation and explore how we can support LLM-powered exploration and sensemaking, we developed Sensecape, an interactive system designed to support complex information tasks with an LLM by enabling users to (1) manage the complexity of information through multilevel abstraction and (2) seamlessly switch between foraging and sensemaking. Our within-subject user study reveals that Sensecape empowers users to explore more topics and structure their knowledge hierarchically. We contribute implications for LLM-based workflows and interfaces for information tasks.
    
[^105]: 评估LLM的隐藏风险：关于鲁棒性、一致性和可信性的实证研究

    Assessing Hidden Risks of LLMs: An Empirical Study on Robustness, Consistency, and Credibility. (arXiv:2305.10235v1 [cs.LG])

    [http://arxiv.org/abs/2305.10235](http://arxiv.org/abs/2305.10235)

    本研究是一项关于大型语言模型方面的实证研究，对主流语言模型进行了大量查询和分析，结果发现这些模型存在着鲁棒性、一致性和可信性方面的潜在风险。

    

    大型语言模型（LLMs）的普及对于许多领域产生了重大影响，特别是在其开放式环境（如API、开源模型和插件）中。然而，随着LLMs的广泛部署，缺乏全面讨论和分析潜在风险的研究。因此，我们进行了一项初步但开创性的研究，涵盖了LLMs系统的鲁棒性、一致性和可信性。我们提出了一个自动化工作流程来处理大量查询/响应。总体而言，我们对包括ChatGPT、LLaMA和OPT在内的主流LLMs进行了100多万个查询。我们的工作流核心包括数据原语，随后是自动解释器，评估这些LLMs在不同的对抗性度量系统下的表现。结果，我们得出了几个、也许是不幸的结论，这些结论相当不同

    The recent popularity of large language models (LLMs) has brought a significant impact to boundless fields, particularly through their open-ended ecosystem such as the APIs, open-sourced models, and plugins. However, with their widespread deployment, there is a general lack of research that thoroughly discusses and analyzes the potential risks concealed. In that case, we intend to conduct a preliminary but pioneering study covering the robustness, consistency, and credibility of LLMs systems. With most of the related literature in the era of LLM uncharted, we propose an automated workflow that copes with an upscaled number of queries/responses. Overall, we conduct over a million queries to the mainstream LLMs including ChatGPT, LLaMA, and OPT. Core to our workflow consists of a data primitive, followed by an automated interpreter that evaluates these LLMs under different adversarial metrical systems. As a result, we draw several, and perhaps unfortunate, conclusions that are quite unco
    
[^106]: 笑声很重要：引入使用扩散模型生成笑脸的方法

    Laughing Matters: Introducing Laughing-Face Generation using Diffusion Models. (arXiv:2305.08854v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.08854](http://arxiv.org/abs/2305.08854)

    该论文提出了一种新颖的模型，利用扩散模型生成逼真的笑脸序列，以填补非语言交流领域的研究空白。与传统方法相比，该模型在所有指标上都取得了最先进的性能。

    

    近年来，基于语音的动画在提高真实感方面取得了显著进展，但在非语言交流方面仍然很少有研究。本文提出了一种新颖的模型，能够根据静态肖像和包含笑声的音频剪辑生成逼真的笑脸序列。我们强调了传统面部动画方法的失败案例，并利用最近扩散模型的进展产生令人信服的笑脸视频。我们使用各种各样的笑声数据集对模型进行训练，并引入了一种专门设计用于笑声的评估指标。与之前的基于语音的方法相比，我们的模型在所有指标上均取得了最先进的性能，甚至在...

    Speech-driven animation has gained significant traction in recent years, with current methods achieving near-photorealistic results. However, the field remains underexplored regarding non-verbal communication despite evidence demonstrating its importance in human interaction. In particular, generating laughter sequences presents a unique challenge due to the intricacy and nuances of this behaviour. This paper aims to bridge this gap by proposing a novel model capable of generating realistic laughter sequences, given a still portrait and an audio clip containing laughter. We highlight the failure cases of traditional facial animation methods and leverage recent advances in diffusion models to produce convincing laughter videos. We train our model on a diverse set of laughter datasets and introduce an evaluation metric specifically designed for laughter. When compared with previous speech-driven approaches, our model achieves state-of-the-art performance across all metrics, even when the
    
[^107]: 可解释和鲁棒的脑电图AI系统综述

    Interpretable and Robust AI in EEG Systems: A Survey. (arXiv:2304.10755v1 [eess.SP])

    [http://arxiv.org/abs/2304.10755](http://arxiv.org/abs/2304.10755)

    这篇论文综述了近年来脑电图系统中可解释和鲁棒的AI技术的发展。其中，作者提出了解释性分类法，详细介绍了鲁棒AI的方法，包括对抗攻击和防御、迁移学习和不确定性建模，并讨论了未来的研究方向和挑战。

    

    在人工智能时代，人工智能（AI）和脑电图（EEG）的密切耦合极大地推动了人机交互（HCI）技术的发展。相较于传统的EEG系统，基于AI的EEG系统的可解释性和鲁棒性变得尤为关键。可解释性能够阐释AI模型的内部工作机制，因此可以获得用户的信任。鲁棒性则反映了AI对抗攻击和扰动的可靠性，这对于敏感和脆弱的EEG信号来说是至关重要的。因此，EEG系统中AI的可解释性和鲁棒性受到越来越多的关注，并且最近的研究取得了巨大进展。然而，关于这一领域的最新进展仍然没有综述。本文首先提出了一种解释性分类法，通过特征化模型、数据和输出解释性，总结了脑电图系统中解释性和鲁棒的AI技术，并详细介绍了鲁棒AI的方法，包括对抗攻击和防御、迁移学习和不确定性建模。最后，我们讨论了这一领域未来的方向和面临的挑战。

    The close coupling of artificial intelligence (AI) and electroencephalography (EEG) has substantially advanced human-computer interaction (HCI) technologies in the AI era. Different from traditional EEG systems, the interpretability and robustness of AI-based EEG systems are becoming particularly crucial. The interpretability clarifies the inner working mechanisms of AI models and thus can gain the trust of users. The robustness reflects the AI's reliability against attacks and perturbations, which is essential for sensitive and fragile EEG signals. Thus the interpretability and robustness of AI in EEG systems have attracted increasing attention, and their research has achieved great progress recently. However, there is still no survey covering recent advances in this field. In this paper, we present the first comprehensive survey and summarize the interpretable and robust AI techniques for EEG systems. Specifically, we first propose a taxonomy of interpretability by characterizing it 
    
[^108]: RAFT: 奖励排名微调用于生成型基础模型对齐

    RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment. (arXiv:2304.06767v1 [cs.LG])

    [http://arxiv.org/abs/2304.06767](http://arxiv.org/abs/2304.06767)

    RAFT框架引入了奖励排名微调方法，用于对齐生成型基础模型，以解决强化学习带来的低效和不稳定性问题。

    

    生成型基础模型容易受到广泛的无监督训练数据带来的隐式偏见的影响。这些偏见可能导致子优样本、扭曲的结果和不公平，可能产生重大影响。因此，将这些模型与人的伦理和偏好对齐是确保它们在真实应用中负责任和有效的部署的关键步骤。以往的研究主要采用人类反馈的强化学习（ RLHF）作为解决这个问题的手段。在 RL 算法的指导下，用人类反馈指导的奖励模型对生成模型进行微调。然而， RL 算法的低效性和不稳定性常常会对生成模型的成功对齐产生重大障碍，因此需要开发一种更为强大和简化的方法。为此，我们引入了一个新的框架，即奖励排名微调（ RAFT ），旨在对齐生成基础模型。

    Generative foundation models are susceptible to implicit biases that can arise from extensive unsupervised training data. Such biases can produce suboptimal samples, skewed outcomes, and unfairness, with potentially significant repercussions. Consequently, aligning these models with human ethics and preferences is an essential step toward ensuring their responsible and effective deployment in real-world applications. Prior research has primarily employed Reinforcement Learning from Human Feedback (RLHF) as a means of addressing this problem, wherein generative models are fine-tuned using RL algorithms guided by a human-feedback-informed reward model. However, the inefficiencies and instabilities associated with RL algorithms frequently present substantial obstacles to the successful alignment of generative models, necessitating the development of a more robust and streamlined approach. To this end, we introduce a new framework, Reward rAnked FineTuning (RAFT), designed to align generat
    
[^109]: WDiscOOD：通过白化线性判别分析进行区分度优化的OOD检测

    WDiscOOD: Out-of-Distribution Detection via Whitened Linear Discriminative Analysis. (arXiv:2303.07543v1 [cs.CV])

    [http://arxiv.org/abs/2303.07543](http://arxiv.org/abs/2303.07543)

    本论文提出了一种名为WDiscOOD的新型OOD检测方法，其中使用白化线性判别分析将特征投影到判别子空间和残留子空间中，确定OOD分数。在大规模ImageNet-1k基准测试和六个OOD数据集中，WDiscOOD表现出了优越的性能。

    

    深度神经网络容易在遇到未知概念的情形下产生过度自信但错误的预测。这个挑战突显了在开放世界中检测OOD样本的重要性。本文提出了一种新颖的特征空间OOD检测分数，同时结合了类别特定和类别不可知的信息。具体地，我们的方法使用白化线性判别分析将特征投影到两个子空间中——判别子空间和残留子空间，其中ID类在判别子空间中被最大化地分离，并在残差子空间中被紧密地聚类。然后，在两个子空间中将来自输入数据与ID分布的偏差组合起来确定OOD分数。我们的方法名为WDiscOOD，在覆盖多种分布偏移的六个OOD数据集上验证了其高效性，包括大规模ImageNet-1k基准测试。WDiscOOD在深度分类器上表现出了优越的性能。

    Deep neural networks are susceptible to generating overconfident yet erroneous predictions when presented with data beyond known concepts. This challenge underscores the importance of detecting out-of-distribution (OOD) samples in the open world. In this work, we propose a novel feature-space OOD detection score that jointly reasons with both class-specific and class-agnostic information. Specifically, our approach utilizes Whitened Linear Discriminative Analysis to project features into two subspaces - the discriminative and residual subspaces - in which the ID classes are maximally separated and closely clustered, respectively. The OOD score is then determined by combining the deviation from the input data to the ID distribution in both subspaces. The efficacy of our method, named WDiscOOD, is verified on the large-scale ImageNet-1k benchmark, with six OOD datasets that covers a variety of distribution shifts. WDiscOOD demonstrates superior performance on deep classifiers with divers
    
[^110]: 进化强化学习综述

    Evolutionary Reinforcement Learning: A Survey. (arXiv:2303.04150v3 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2303.04150](http://arxiv.org/abs/2303.04150)

    这篇文章系统地总结了最新的进化计算方法在解决强化学习中的关键挑战方面所取得的良好性能。

    

    强化学习是一种通过与环境交互训练智能体最大化累积奖励的机器学习方法。最近将强化学习与深度学习相结合，在棋盘游戏、街机游戏和机器人控制等各种挑战性任务中取得了令人瞩目的成就。尽管取得了成功，但仍存在一些关键挑战，包括由敏感超参数导致的脆弱收敛特性，长时间跨度和稀疏奖励的时间分配困难，特别是在连续搜索空间场景中的多样性探索不足，多智能体强化学习中的信用分配困难以及奖励冲突目标。进化计算维护着一群学习智能体，已展现出解决这些限制的良好性能。本文介绍了集成进化计算的最新方法的全面综述。

    Reinforcement learning (RL) is a machine learning approach that trains agents to maximize cumulative rewards through interactions with environments. The integration of RL with deep learning has recently resulted in impressive achievements in a wide range of challenging tasks, including board games, arcade games, and robot control. Despite these successes, there remain several crucial challenges, including brittle convergence properties caused by sensitive hyperparameters, difficulties in temporal credit assignment with long time horizons and sparse rewards, a lack of diverse exploration, especially in continuous search space scenarios, difficulties in credit assignment in multi-agent reinforcement learning, and conflicting objectives for rewards. Evolutionary computation (EC), which maintains a population of learning agents, has demonstrated promising performance in addressing these limitations. This article presents a comprehensive survey of state-of-the-art methods for integrating EC
    
[^111]: EvHandPose: 使用稀疏监督进行基于事件的3D手势姿势估计

    EvHandPose: Event-based 3D Hand Pose Estimation with Sparse Supervision. (arXiv:2303.02862v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.02862](http://arxiv.org/abs/2303.02862)

    本文提出了EvHandPose，该方法利用稀疏监督下的新型手部流表示进行基于事件的3D手势姿势估计，解决了运动模糊的问题，并通过构建大规模真实世界数据集来填补真实合成领域间的差距。

    

    事件相机在3D手势姿势估计中显示出了巨大的潜力，尤其在解决快速运动和高动态范围的挑战以低功耗方式处理时。然而，由于异步差分成像机制，设计事件表示来编码手部运动信息尤其是当手部不动时（导致运动模糊）是具有挑战性的，并且不可能对时间密集的事件流进行完全注释。在本文中，我们提出了EvHandPose，用于准确的手势姿势估计和减轻运动模糊问题的新型手部流表示。为了解决稀疏注释下的问题，我们在Pose-to-IWE（具有扭曲事件的图像）模块中设计了对比度最大化和手边缘约束，并将EvHandPose构建为弱监督框架。我们还构建了EvRealHands，首个针对几个具有挑战性场景的大规模真实世界事件驱动手势姿势数据集，以填补真实合成领域间的差距。

    Event camera shows great potential in 3D hand pose estimation, especially addressing the challenges of fast motion and high dynamic range in a low-power way. However, due to the asynchronous differential imaging mechanism, it is challenging to design event representation to encode hand motion information especially when the hands are not moving (causing motion ambiguity), and it is infeasible to fully annotate the temporally dense event stream. In this paper, we propose EvHandPose with novel hand flow representations in Event-to-Pose module for accurate hand pose estimation and alleviating the motion ambiguity issue. To solve the problem under sparse annotation, we design contrast maximization and hand-edge constraints in Pose-to-IWE (Image with Warped Events) module and formulate EvHandPose in a weakly-supervision framework. We further build EvRealHands, the first large-scale real-world event-based hand pose dataset on several challenging scenes to bridge the real-synthetic domain gap
    
[^112]: 通过大型语言模型和Answer Set Programming实现可靠的自然语言理解

    Reliable Natural Language Understanding with Large Language Models and Answer Set Programming. (arXiv:2302.03780v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.03780](http://arxiv.org/abs/2302.03780)

    本研究提出了STAR框架，将大型语言模型与Answer Set Programming相结合，以达到可靠的自然语言理解。实验证明，该框架能够成功应对需要推理的不同任务，并提供可靠的结果。

    

    人类通过从句子中提取信息（意义），将其与已有的常识知识结合，并进行推理来理解语言。虽然像GPT-3和ChatGPT这样的大型语言模型可以利用文本中的模式来解决各种自然语言处理任务，但在需要推理的问题上表现不佳。它们也无法可靠地解释生成的答案。为了更好地模拟人类，我们提出了STAR框架，将LLMs与Answer Set Programming (ASP) 结合起来。我们展示了如何使用LLMs有效地从语言中提取以谓词表示的知识。然后使用目标导向的ASP来可靠地进行推理。我们将STAR框架应用于需要推理的三个不同自然语言理解任务：定性推理，数学推理和目标导向对话。我们的实验表明，STAR能够填补自然语言理解任务中的推理差距，提供可靠的结果。

    Humans understand language by extracting information (meaning) from sentences, combining it with existing commonsense knowledge, and then performing reasoning to draw conclusions. While large language models (LLMs) such as GPT-3 and ChatGPT are able to leverage patterns in the text to solve a variety of NLP tasks, they fall short in problems that require reasoning. They also cannot reliably explain the answers generated for a given question. In order to emulate humans better, we propose STAR, a framework that combines LLMs with Answer Set Programming (ASP). We show how LLMs can be used to effectively extract knowledge -- represented as predicates -- from language. Goal-directed ASP is then employed to reliably reason over this knowledge. We apply the STAR framework to three different NLU tasks requiring reasoning: qualitative reasoning, mathematical reasoning, and goal-directed conversation. Our experiments reveal that STAR is able to bridge the gap of reasoning in NLU tasks, leading t
    
[^113]: 外星编码

    Alien Coding. (arXiv:2301.11479v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.11479](http://arxiv.org/abs/2301.11479)

    这个论文介绍了一种自学习算法，用于合成OEIS序列的程序。该算法通过训练神经机器翻译器学习序列和已发现程序之间的对应关系，并自己发现了超过78000个OEIS序列的程序，有时还开发出非传统的编程方法。

    

    我们介绍了一种自学习算法，用于合成OEIS序列的程序。该算法最初随机生成程序，然后通过训练神经机器翻译来学习序列和已发现程序之间的对应关系，并通过训练后的神经机器翻译器为每个OEIS序列提出许多新程序。该算法自己发现了超过78000个OEIS序列的程序，有时开发出非传统的编程方法。我们在几个实验中分析了算法的行为和发明的程序。

    We introduce a self-learning algorithm for synthesizing programs for OEIS sequences. The algorithm starts from scratch initially generating programs at random. Then it runs many iterations of a self-learning loop that interleaves (i) training neural machine translation to learn the correspondence between sequences and the programs discovered so far, and (ii) proposing many new programs for each OEIS sequence by the trained neural machine translator. The algorithm discovers on its own programs for more than 78000 OEIS sequences, sometimes developing unusual programming methods. We analyze its behavior and the invented programs in several experiments.
    
[^114]: 用多智能体强化学习模拟社会困境中的道德选择

    Modeling Moral Choices in Social Dilemmas with Multi-Agent Reinforcement Learning. (arXiv:2301.08491v2 [cs.MA] UPDATED)

    [http://arxiv.org/abs/2301.08491](http://arxiv.org/abs/2301.08491)

    本文使用多智能体强化学习模拟社会困境中的道德选择，设计了一套道德奖励结构，旨在分析和研究AI代理的道德行为。

    

    在实际应用中，人工智能（AI）在智能代理中纳入道德选择的重要性不断展现。同时也强调，按照任何一种道德观定义顶层的AI伦理约束非常具有挑战，并且会带来风险。从底层学习的角度出发，或许更适合研究和开发AI代理的道德行为。我们认为，分析根据预定义的道德奖励在社会困境中实行行动的强化学习代理的新兴行为是一个有趣和富有洞察力的起点。在这项工作中，我们对强化学习代理根据道德理论的奖励进行的选择进行了系统分析。我们旨在设计简化但代表一组关键伦理系统的奖励结构。因此，我们首先定义了区分后果和规范伦理的道德奖励函数，并将它们混合以创建新的奖励方案。然后，我们通过训练在社会困境下进行内在动机驱动的强化学习代理来评估这些奖励函数。结果表明，我们的方法能够复制并扩展有关道德选择的文献研究中的许多发现，并能够出现以前未曾报道的新行为。

    Practical uses of Artificial Intelligence (AI) in the real world have demonstrated the importance of embedding moral choices into intelligent agents. They have also highlighted that defining top-down ethical constraints on AI according to any one type of morality is extremely challenging and can pose risks. A bottom-up learning approach may be more appropriate for studying and developing ethical behavior in AI agents. In particular, we believe that an interesting and insightful starting point is the analysis of emergent behavior of Reinforcement Learning (RL) agents that act according to a predefined set of moral rewards in social dilemmas.  In this work, we present a systematic analysis of the choices made by intrinsically-motivated RL agents whose rewards are based on moral theories. We aim to design reward structures that are simplified yet representative of a set of key ethical systems. Therefore, we first define moral reward functions that distinguish between consequence- and norm
    
[^115]: RecXplainer: 针对推荐系统的分摊属性个性化解释

    RecXplainer: Amortized Attribute-based Personalized Explanations for Recommender Systems. (arXiv:2211.14935v2 [cs.IR] UPDATED)

    [http://arxiv.org/abs/2211.14935](http://arxiv.org/abs/2211.14935)

    RecXplainer提供了一种针对推荐系统的分摊属性个性化解释，以解决用户和开发者之间的信任问题。

    

    推荐系统在数字世界中影响着我们的许多交互，影响着我们购物、浏览YouTube或TikTok时所看到的内容，以及在使用酒店平台时展示给我们的餐馆和酒店。现代推荐系统是基于专有和开源数据集训练的庞大且不透明的模型。自然而然地，在开发者和用户方面引发了信任问题：系统是否正常工作，为什么用户收到（或未收到）特定的推荐？在推荐旁边提供解释可以减轻一些这些关注。目前辅助推荐系统反馈的现状要么是用户特定的解释（例如，“购买商品B的用户也购买了商品A”），要么是物品特定的解释（例如，“我们推荐商品A是因为您观看/购买了商品B”）。然而，用户将个性化的背景信息带入他们的搜索体验中，将一个物品的价值视为该物品的函数.

    Recommender systems influence many of our interactions in the digital world -- impacting how we shop for clothes, sorting what we see when browsing YouTube or TikTok, and determining which restaurants and hotels we are shown when using hospitality platforms. Modern recommender systems are large, opaque models trained on a mixture of proprietary and open-source datasets. Naturally, issues of trust arise on both the developer and user side: is the system working correctly, and why did a user receive (or not receive) a particular recommendation? Providing an explanation alongside a recommendation alleviates some of these concerns. The status quo for auxiliary recommender system feedback is either user-specific explanations (e.g., "users who bought item B also bought item A") or item-specific explanations (e.g., "we are recommending item A because you watched/bought item B"). However, users bring personalized context into their search experience, valuing an item as a function of that item'
    
[^116]: 从非静止时间序列中识别独特的因果网络

    Identifying Unique Causal Network from Nonstationary Time Series. (arXiv:2211.10085v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.10085](http://arxiv.org/abs/2211.10085)

    本文提出了一种名为UCN的新型因果模型，它考虑了时间延迟的影响，并证明了所得到的网络结构的唯一性，解决了因果解释性和非静态性问题。

    

    在许多数据密集型场景下，识别因果关系是一项具有挑战性的任务。已经提出了许多用于此关键任务的算法。然而，大多数算法仅考虑了贝叶斯网络（BN）的有向无环图（DAG）的学习算法。这些基于BN的模型仅具有有限的因果可解释性，因为存在马尔可夫等价类的问题。此外，它们依赖于静止性假设，而来自复杂系统的许多采样时间序列是非静止的。非静止的时间序列带来了数据集漂移问题，导致这些算法的性能不佳。为了填补这些空白，本文提出了一种名为Unique Causal Network（UCN）的新型因果模型。与以前的基于BN的模型不同，UCN考虑了时间延迟的影响，并证明了所得到的网络结构的唯一性，解决了马尔可夫等价类的问题。此外，基于UCN的可分解性属性，提出了更高的...

    Identifying causality is a challenging task in many data-intensive scenarios. Many algorithms have been proposed for this critical task. However, most of them consider the learning algorithms for directed acyclic graph (DAG) of Bayesian network (BN). These BN-based models only have limited causal explainability because of the issue of Markov equivalence class. Moreover, they are dependent on the assumption of stationarity, whereas many sampling time series from complex system are nonstationary. The nonstationary time series bring dataset shift problem, which leads to the unsatisfactory performances of these algorithms. To fill these gaps, a novel causation model named Unique Causal Network (UCN) is proposed in this paper. Different from the previous BN-based models, UCN considers the influence of time delay, and proves the uniqueness of obtained network structure, which addresses the issue of Markov equivalence class. Furthermore, based on the decomposability property of UCN, a higher-
    
[^117]: E-MCTS：通过规划表观不确定性进行深度探索的模型基强化学习

    E-MCTS: Deep Exploration in Model-Based Reinforcement Learning by Planning with Epistemic Uncertainty. (arXiv:2210.13455v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.13455](http://arxiv.org/abs/2210.13455)

    本文提出了一种新的方法E-MCTS，通过在MCTS预测中应用表观不确定性估计，实现了模型基强化学习中的深度探索，以及规划探索策略。通过实验证明这种方法在成功的表观不确定性估计和深度探索方面表现优异。

    

    模拟退火树搜索（MCTS）是模型基强化学习中应用最广泛、性能最优秀的规划方法之一。MCTS的关键挑战在于深度探索和面对未知时的可靠性，这两个挑战可以通过在MCTS预测中使用原则性的表观不确定性估计来缓解。本文提出了两个主要贡献：首先，我们开发了一种在MCTS中传播表观不确定性的方法，使智能体能够估计其预测的表观不确定性。其次，我们利用传播的不确定性提出了一种新的深度探索算法，通过明确规划探索策略。我们将这种方法应用于基于MCTS的模型基强化学习方法中，包括使用学习和提供的模型，通过实验证明了我们的方法实现了成功的表观不确定性估计并进行了深度探索。我们将其与基于非规划的深度探索基线进行了比较，并表明...

    One of the most well-studied and highly performing planning approaches used in Model-Based Reinforcement Learning (MBRL) is Monte-Carlo Tree Search (MCTS). Key challenges of MCTS-based MBRL methods remain dedicated deep exploration and reliability in the face of the unknown, and both challenges can be alleviated through principled epistemic uncertainty estimation in the predictions of MCTS. We present two main contributions: First, we develop methodology to propagate epistemic uncertainty in MCTS, enabling agents to estimate the epistemic uncertainty in their predictions. Second, we utilize the propagated uncertainty for a novel deep exploration algorithm by explicitly planning to explore. We incorporate our approach into variations of MCTS-based MBRL approaches with learned and provided models, and empirically show deep exploration through successful epistemic uncertainty estimation achieved by our approach. We compare to a non-planning-based deep-exploration baseline, and demonstrate
    
[^118]: 本体概念的量化和聚合

    Quantification and Aggregation over Concepts of the Ontology. (arXiv:2202.00898v4 [cs.LO] UPDATED)

    [http://arxiv.org/abs/2202.00898](http://arxiv.org/abs/2202.00898)

    该论文介绍了一种对本体概念进行量化和聚合的方法，通过扩展一阶逻辑，并验证了良式句子的有效性。该方法在知识表示中能够以扩展容忍的方式准确建模各种问题领域。

    

    我们认为在一些知识表示应用中，我们希望对词汇中符号形式表示的概念集进行量化。我们展示了这种量化与二阶量化和元编程量化应该有所区别。我们还研究了与内涵逻辑中的概念的关系。我们提出了一个扩展的一阶逻辑来支持这样的抽象，并展示它允许编写对知识进行扩展容忍的表达式。为了避免形式主义中的无意义句子，我们改进了良式句子的概念，并提出了一种验证良式性的方法，其复杂度与公式中令牌的数量线性相关。我们相应地扩展了FO(.)，一种知识表示语言，和IDP-Z3，一种用于FO(.)的推理引擎。我们展示了这个扩展在以扩展容忍的方式（即没有实体化）准确建模各种问题领域中的重要性。

    We argue that in some KR applications, we want to quantify over sets of concepts formally represented by symbols in the vocabulary. We show that this quantification should be distinguished from second-order quantification and meta-programming quantification. We also investigate the relationship with concepts in intensional logic.  We present an extension of first-order logic to support such abstractions, and show that it allows writing expressions of knowledge that are elaboration tolerant. To avoid nonsensical sentences in this formalism, we refine the concept of well-formed sentences, and propose a method to verify well-formedness with a complexity that is linear with the number of tokens in the formula.  We have extended FO(.), a Knowledge Representation language, and IDP-Z3, a reasoning engine for FO(.), accordingly. We show that this extension was essential in accurately modelling various problem domains in an elaboration-tolerant way, i.e., without reification.
    
[^119]: Temporal Difference学习算法的控制论分析

    Control Theoretic Analysis of Temporal Difference Learning. (arXiv:2112.14417v5 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2112.14417](http://arxiv.org/abs/2112.14417)

    本研究对Temporal Difference学习算法进行了控制论分析，并引入了一个有限时间的框架，从控制论角度提供了对TD学习机制和强化学习领域的更深入洞察。

    

    本文旨在对Temporal Difference (TD)学习算法进行控制论分析。TD学习作为强化学习领域的基石，提供了一种近似计算与马尔科夫决策过程中给定策略相关的值函数的方法。尽管已存在多篇关于TD学习理论理解的研究成果，但直到最近几年，研究人员才能对其统计效率提供具体保证。本文引入了一个有限时间的控制论框架，用于分析TD学习，借鉴了线性系统控制领域的已有概念。因此，本文通过使用控制论导出的简单分析工具，为TD学习的机制和强化学习的更广阔领域提供了额外的洞察。

    The goal of this manuscript is to conduct a controltheoretic analysis of Temporal Difference (TD) learning algorithms. TD-learning serves as a cornerstone in the realm of reinforcement learning, offering a methodology for approximating the value function associated with a given policy in a Markov Decision Process. Despite several existing works that have contributed to the theoretical understanding of TD-learning, it is only in recent years that researchers have been able to establish concrete guarantees on its statistical efficiency. In this paper, we introduce a finite-time, control-theoretic framework for analyzing TD-learning, leveraging established concepts from the field of linear systems control. Consequently, this paper provides additional insights into the mechanics of TD learning and the broader landscape of reinforcement learning, all while employing straightforward analytical tools derived from control theory.
    
[^120]: MetaCOG: 学习元认知以恢复实际存在的物体

    MetaCOG: Learning a Metacognition to Recover What Objects Are Actually There. (arXiv:2110.03105v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2110.03105](http://arxiv.org/abs/2110.03105)

    MetaCOG是一个学习元认知的模型，通过学习目标检测器的可靠性表示，增加了目标检测器的鲁棒性，而无需反馈和地面真实的物体标签。

    

    人类不仅根据我们所看到的内容形成关于世界的表征，还学习关于我们自己视觉如何工作的元认知表征。这使我们能够识别出我们的视觉不可靠（例如，当我们意识到我们正在经历视觉错觉时），并使我们能够对我们所看到的内容提出质疑。受到这种人类能力的启发，我们提出了MetaCOG：一种通过学习其可靠性表示来增加目标检测器的鲁棒性的模型，并且在没有反馈的情况下实现。具体而言，MetaCOG是一个层次概率模型，对一个三维场景中的物体和检测器产生的输出表达了一个联合分布。当与现成的目标检测器配对使用时，MetaCOG将检测结果作为输入，并推断出检测器错漏检某些类别的物体和虚构不存在的物体的倾向，而无需访问地面真实的物体标签。

    Humans not only form representations about the world based on what we see, but also learn meta-cognitive representations about how our own vision works. This enables us to recognize when our vision is unreliable (e.g., when we realize that we are experiencing a visual illusion) and enables us to question what we see. Inspired by this human capacity, we present MetaCOG: a model that increases the robustness of object detectors by learning representations of their reliability, and does so without feedback. Specifically, MetaCOG is a hierarchical probabilistic model that expresses a joint distribution over the objects in a 3D scene and the outputs produced by a detector. When paired with an off-the-shelf object detector, MetaCOG takes detections as input and infers the detector's tendencies to miss objects of certain categories and to hallucinate objects that are not actually present, all without access to ground-truth object labels. When paired with three modern neural object detectors, 
    
[^121]: 数据湖中高维相似度为基础的高效可连接表发现方法

    Efficient Joinable Table Discovery in Data Lakes: A High-Dimensional Similarity-Based Approach. (arXiv:2010.13273v4 [cs.IR] CROSS LISTED)

    [http://arxiv.org/abs/2010.13273](http://arxiv.org/abs/2010.13273)

    本论文提出了一种基于高维相似度的方法，在数据湖中高效地发现可连接表。通过将文本值嵌入高维向量并使用相似性谓词连接列，该方法能够解决等值连接方法的限制，识别出更有意义的结果。实验证明，该方法能够识别出比传统方法更多的可连接表。

    

    在数据湖中寻找可连接表是许多应用的关键过程，例如数据集成、数据增强、数据分析和数据市场。传统的方法只能找到等值连接的表，无法处理拼写错误和不同的格式，也无法捕捉到任何语义连接。在本文中，我们提出了PEXESO，一种用于在数据湖中发现可连接表的框架。我们将文本值嵌入到高维向量中，并在高维向量上使用相似性谓词来连接列，从而解决了等值连接方法的限制，并且能够识别出更有意义的结果。为了高效地找到具有相似性的可连接表，我们提出了一种基于块和验证的方法，利用基于中心点的过滤技术。针对数据湖很大且索引无法适应主内存的情况，我们开发了一种分区技术。实验评估结果表明，与等值连接和公共自然语言处理方法相比，我们的解决方案能够识别出更多的表。

    Finding joinable tables in data lakes is key procedure in many applications such as data integration, data augmentation, data analysis, and data market. Traditional approaches that find equi-joinable tables are unable to deal with misspellings and different formats, nor do they capture any semantic joins. In this paper, we propose PEXESO, a framework for joinable table discovery in data lakes. We embed textual values as high-dimensional vectors and join columns under similarity predicates on high-dimensional vectors, hence to address the limitations of equi-join approaches and identify more meaningful results. To efficiently find joinable tables with similarity, we propose a block-and-verify method that utilizes pivot-based filtering. A partitioning technique is developed to cope with the case when the data lake is large and the index cannot fit in main memory. An experimental evaluation on real datasets shows that our solution identifies substantially more tables than equi-joins and o
    
[^122]: Coagent Networks再探讨

    Coagent Networks Revisited. (arXiv:2001.10474v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2001.10474](http://arxiv.org/abs/2001.10474)

    Coagent Networks（共智网络）是指在强化学习环境中协作的随机代理网络。这篇论文重新审视了共智网络理论，提出了执行路径的思想，并通过这一思想实现了对策梯度定理的简洁证明。

    

    Coagent networks（共智网络）形式化了在强化学习环境中协作以采取行动的随机代理网络的概念。共智网络的显著应用包括层次强化学习（HRL）的方法，例如使用选项的方法，通过在HRL代理中串联多个随机网络引入不同层次的抽象动作，来解决探索利用权衡问题。我们首先通过在共智网络中形式化执行规则、通过共智网络中执行路径的新颖而直观的思想，提供了一个统一的视角来描述许多不同的例子。在层次选项评论者架构中受到参数共享的启发，我们重新审视了共智网络理论，并使用我们的执行路径思想得到了对策梯度定理的更简洁证明，而不需要对参数共享做出任何假设。

    Coagent networks formalize the concept of arbitrary networks of stochastic agents that collaborate to take actions in a reinforcement learning environment. Prominent examples of coagent networks in action include approaches to hierarchical reinforcement learning (HRL), such as those using options, which attempt to address the exploration exploitation trade-off by introducing abstract actions at different levels by sequencing multiple stochastic networks within the HRL agents. We first provide a unifying perspective on the many diverse examples that fall under coagent networks. We do so by formalizing the rules of execution in a coagent network, enabled by the novel and intuitive idea of execution paths in a coagent network. Motivated by parameter sharing in the hierarchical option-critic architecture, we revisit the coagent network theory and achieve a much shorter proof of the policy gradient theorem using our idea of execution paths, without any assumption on how parameters are share
    

