# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [3D Human Pose Estimation via Intuitive Physics.](http://arxiv.org/abs/2303.18246) | 用物理引擎强制实现3D人体姿态估计的物理合理性在实践中有很大困难。这篇论文中开发了一种基于直觉物理的方法，借助压力热图、压力中心和身体质心等术语，在估计3D人体姿态的同时，实现了物理合理性。 |
| [^2] | [Where are we in the search for an Artificial Visual Cortex for Embodied Intelligence?.](http://arxiv.org/abs/2303.18240) | 该研究研究了使用预训练视觉表征来实现身体智能的最新进展。他们展示了最大、最全面的经验研究，发现没有一种表征是普遍优越的，并且数据集的大小和多样性并不能普遍改善性能。 |
| [^3] | [A Survey of Large Language Models.](http://arxiv.org/abs/2303.18223) | 本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。 |
| [^4] | [TPMCF: Temporal QoS Prediction using Multi-Source Collaborative Features.](http://arxiv.org/abs/2303.18201) | 本文提出了一种新的方法TPMCF，利用多源特征进行QoS预测。该方法利用带有注意力机制的编码器-解码器架构，并使用协作特征捕捉用户和服务之间的关系，有效地处理数据稀疏和异常值。 |
| [^5] | [Detecting Backdoors During the Inference Stage Based on Corruption Robustness Consistency.](http://arxiv.org/abs/2303.18191) | 本文提出了一种新的测试时间触发样本检测方法 TeCo，该方法只需要受害模型的硬标签输出，通过评估测试时间鲁棒性一致性来检测后门，不需要其他额外的信息，提高了实用性。 |
| [^6] | [How Efficient Are Today's Continual Learning Algorithms?.](http://arxiv.org/abs/2303.18171) | 这篇论文研究了增量班级学习的最新方法，并指出许多方法在计算、内存和存储方面非常低效。为了使迭代学习在现实世界中具有适用性，研究界不能忽视这些算法使用的资源。 |
| [^7] | [Constrained Optimization of Rank-One Functions with Indicator Variables.](http://arxiv.org/abs/2303.18158) | 本文提出了一种基于透视重构技术的紧凑扩展公式，用于解决涉及指标变量限制下决策变量支持集合的秩一凸函数的最小化问题。 |
| [^8] | [Machine-learned Adversarial Attacks against Fault Prediction Systems in Smart Electrical Grids.](http://arxiv.org/abs/2303.18136) | 该论文提出了针对智能电网故障预测系统的机器学习对抗攻击的研究，证明智能电网中使用的深度神经网络方法容易受到对抗性攻击，并突出了目前在智能电网中的机器学习算法存在对各种对抗性攻击的弱点。 |
| [^9] | [AdvCheck: Characterizing Adversarial Examples via Local Gradient Checking.](http://arxiv.org/abs/2303.18131) | 本文提出了一种新的方法AdvCheck，通过计算本地梯度检测对抗性样本，相较于其他最先进的检测方法具有更高的效率和更好的表现。 |
| [^10] | [Automatic Detection of Out-of-body Frames in Surgical Videos for Privacy Protection Using Self-supervised Learning and Minimal Labels.](http://arxiv.org/abs/2303.18106) | 该论文提出了一种利用自监督学习和少量标签实现医疗视频中体外镜头自动检测的方法，可以有效保护隐私，比以前的方法表现更好，甚至使用 95% 更少的标签时也表现出色。 |
| [^11] | [Dataset and Baseline System for Multi-lingual Extraction and Normalization of Temporal and Numerical Expressions.](http://arxiv.org/abs/2303.18103) | 该论文描述了一个覆盖14种语言、多元化的时间和数字表达式，包括提取、规范化和解析的多语言数据集(NTX)，并提供了一个强大的基于规则的系统作为评估其他模型的比较基准。 |
| [^12] | [INoD: Injected Noise Discriminator for Self-Supervised Representation Learning in Agricultural Fields.](http://arxiv.org/abs/2303.18101) | 本文提出了一个名为INoD的注入噪声鉴别器，通过特征替换和数据集鉴别的原则进行农田自监督表示学习，提升了模型性能。 |
| [^13] | [Solving morphological analogies: from retrieval to generation.](http://arxiv.org/abs/2303.18062) | 该论文提出了一个基于深度学习和条件变分自编码器的框架来解决基于类比的推理中的类比检测和解决两个任务，该框架可以生成之前不存在于数据集中的类比。 |
| [^14] | [NOSTROMO: Lessons learned, conclusions and way forward.](http://arxiv.org/abs/2303.18060) | 本文介绍了元建模对于空中交通管理研究的价值，并强调了其在实现欧洲ATM总体计划中的关键绩效指标方面所起的作用。 |
| [^15] | [Simple Domain Generalization Methods are Strong Baselines for Open Domain Generalization.](http://arxiv.org/abs/2303.18031) | 该论文评估了基于领域泛化的方法在开放领域泛化中的表现，证明了CORAL和MMD等简单DG方法在某些情况下的竞争力，提出了这些方法的简单扩展。 |
| [^16] | [LaCViT: A Label-aware Contrastive Training Framework for Vision Transformers.](http://arxiv.org/abs/2303.18013) | LaCViT是一种针对视觉Transformer预训练表示空间的各向等性不足问题，提高其表示空间等性的面向标签的对比训练框架，经过实验证明其在五个标准图像分类数据集中具有卓越的性能。 |
| [^17] | [Augmented Collective Intelligence in Collaborative Ideation: Agenda and Challenges.](http://arxiv.org/abs/2303.18010) | 本文探讨了增强集体智能（ACI）在协同创新中的应用，包括设计一个实验来评估人工智能和人类混合团队的表现，并考察一种实时数据收集工具Polis。作者讨论了设计ACI实验时需要考虑的三个挑战：主题选择，参与者选择和结果评估。 |
| [^18] | [Asking Better Questions -- The Art and Science of Forecasting: A mechanism for truer answers to high-stakes questions.](http://arxiv.org/abs/2303.18006) | 本文探讨了使用政治科学工具——预测来提高预测准确性的最新发展，成功案例揭示了一类“超级预测者”，对于适应快速变化的技术环境，建议将预测作为第一道防线考虑。 |
| [^19] | [Artificial Intelligence in Ovarian Cancer Histopathology: A Systematic Review.](http://arxiv.org/abs/2303.18005) | 通过对36篇文章的综述，该研究发现人工智能模型在卵巢癌的诊断和预后中显示出有希望的结果，但现有研究受到小样本量，潜在偏见和缺乏外部验证的限制。 |
| [^20] | [Neural Network Entropy (NNetEn): EEG Signals and Chaotic Time Series Separation by Entropy Features, Python Package for NNetEn Calculation.](http://arxiv.org/abs/2303.17995) | 该研究提出了一种新的熵估计方法NNetEn，用于有效地分离时间序列系统的混沌动态，并在分离混沌时间序列方面证明了其高效率。 |
| [^21] | [Federated Learning for Metaverse: A Survey.](http://arxiv.org/abs/2303.17987) | 本文综述了早期FL4M的研究进展，并探讨了FL对于保护元宇宙参与者的数据隐私和降低服务器计算和存储需求的重要性。 |
| [^22] | [Social Honeypot for Humans: Luring People through Self-managed Instagram Pages.](http://arxiv.org/abs/2303.17946) | 本文介绍一种新颖的社交蜜罐概念，用于吸引对通用目标主题感兴趣的在线社交网络用户，并提供了一个基于完全自动化的内容生成策略和参与计划的框架。该框架提供了一种完全自动化，经济实惠和可扩展的方法，用于社交数据收集和研究目的。 |
| [^23] | [Procedural Generation of Complex Roundabouts for Autonomous Vehicle Testing.](http://arxiv.org/abs/2303.17900) | 本文提出了一种基于附近道路结构的几何限制的过程生成方法，用于生成非完全圆形且类似于真实世界中的环形交叉口的车道，适用于自动驾驶场景测试。 |
| [^24] | [Exploring the Limits of Deep Image Clustering using Pretrained Models.](http://arxiv.org/abs/2303.17896) | 本文提出了一种利用预训练模型实现无标签图像分类的方法，通过自蒸馏训练聚类头学习图像之间的关联性，并提出了一种新的目标函数，可以高效准确地通过预训练特征空间中的结构来学习。使用该方法在ImageNet和CIFAR100的17个不同的预训练模型上将聚类精度相对于k-均值提高了6.1%和12.2%。在ImageNet上，使用自监督的预训练视觉变换器能够将聚类准确度提高到61.6%。 |
| [^25] | [Interval Logic Tensor Networks.](http://arxiv.org/abs/2303.17892) | 本文提出了Interval Logic Tensor Networks (ILTN)一个神经符号系统，可以处理模糊逻辑、模糊时间区间的知识表示学习，并在推理事件和预测它们的模糊持续时间等任务上表现良好。 |
| [^26] | [A Benchmark Generative Probabilistic Model for Weak Supervised Learning.](http://arxiv.org/abs/2303.17841) | 本文提出一种基准生成性概率模型，在启发式标注的原始数据集上训练，生成伪标签作为一种准确、快速、经济的弱监督学习方法，在图像分类和自然语言处理中达到了最先进的表现。 |
| [^27] | [Learning Procedure-aware Video Representation from Instructional Videos and Their Narrations.](http://arxiv.org/abs/2303.17839) | 本文提出了一种从教学视频及其解说中学习过程感知的视频表示方法，联合学习视频表示和深度概率模型可以增强过程推理的新功能，同时对个体步骤的识别也能得到加强。 |
| [^28] | [Rethinking interpretation: Input-agnostic saliency mapping of deep visual classifiers.](http://arxiv.org/abs/2303.17836) | 提出了一种新的无特定输入显著性映射视角，它计算了模型对其输出所归属的高级特征，这种方法能够独立于输入进行模型解释，且鲁棒性较好。 |
| [^29] | [Towards Enhancing In-Context Learning for Code Generation.](http://arxiv.org/abs/2303.17780) | 本文提出了一种名为AceCoder的代码生成上下文学习方法，与标准上下文学习相比，它通过示例检索和引导代码生成来提高生成代码的准确性和鲁棒性。 |
| [^30] | [Semi-Weakly Supervised Object Kinematic Motion Prediction.](http://arxiv.org/abs/2303.17774) | 本研究提出了一种半弱监督的方法，通过利用物体部件语义分割数据集和方法，解决了物体运动动力学预测问题。通过一个图神经网络，可以检测底层3D结构中的移动部分。 |
| [^31] | [Domain Knowledge integrated for Blast Furnace Classifier Design.](http://arxiv.org/abs/2303.17769) | 本文设计了一种融合领域知识的分类模型框架，生成适用于工业应用的分类器，有效解决了安全和能源等不同学习目标下爆炉复杂系统的问题。 |
| [^32] | [Towards Adversarially Robust Continual Learning.](http://arxiv.org/abs/2303.17764) | 该论文是关于在持续学习中提高对抗鲁棒性的研究，首次提出一种新方法“任务感知边界增强（TABA）”，并在CIFAR-10和CIFAR-100上进行了充分的实验验证其有效性。 |
| [^33] | [CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society.](http://arxiv.org/abs/2303.17760) | 本文介绍了一个名为角色扮演的新型交互式代理框架，用于实现语言模型之间的自主合作，并展示了其在生成对话数据方面的有效性。 |
| [^34] | [Optimal Input Gain: All You Need to Supercharge a Feed-Forward Neural Network.](http://arxiv.org/abs/2303.17732) | 通过优化输入增益，可以显著提高前馈神经网络的性能，特别是在使用反向传播和隐藏权重优化等算法时。 |
| [^35] | [Evaluation of GPT and BERT-based models on identifying protein-protein interactions in biomedical text.](http://arxiv.org/abs/2303.17728) | 该论文评估了预先训练的语言模型(GPT和BERT)识别生物医学文本中蛋白质相互作用的性能, 结果显示BERT模型表现最佳，其中PubMedBERT具有最高的精度和F1分数，BioM-ALBERT具有最高的召回率。 |
| [^36] | [Rethinking AI Explainability and Plausibility.](http://arxiv.org/abs/2303.17707) | 本文研究了XAI评估中最普遍的人为概念——解释合理性。虽然一直被制定为AI可解释性任务的重要评估目标，但是评估XAI的合理性有时是有害的，且无法达到模型可理解性、透明度和可信度的目的。 |
| [^37] | [Fine-Tuning BERT with Character-Level Noise for Zero-Shot Transfer to Dialects and Closely-Related Languages.](http://arxiv.org/abs/2303.17683) | 本研究使用字符级噪音微调BERT以实现对未见方言和语言的零样本跨语言迁移。本研究发现只有在任务依赖表面级别提示并且源-目标跨语言对具有相对较高的词汇重叠时，在微调过程中引入字符级噪音对跨语言迁移的效果才特别突出。 |
| [^38] | [Utilizing Remote Sensing to Analyze Land Usage and Rice Planting Patterns.](http://arxiv.org/abs/2303.17670) | 该研究利用遥感技术分析了巴厘岛水稻田中的空间分布模式，揭示了决策和环境因素对种植决策的影响。 |
| [^39] | [MetaEnhance: Metadata Quality Improvement for Electronic Theses and Dissertations of University Libraries.](http://arxiv.org/abs/2303.17661) | 本论文提出了MetaEnhance，一个利用最先进的人工智能方法来提高电子学位论文关键字段质量的框架，并成功在500份样本中实现了高准确性的元数据错误检测和纠正。 |
| [^40] | [Q-learning Based System for Path Planning with UAV Swarms in Obstacle Environments.](http://arxiv.org/abs/2303.17655) | 本文提出了一种基于强化学习的Q学习算法，能够在有障碍物的环境中通过人工神经网络进行路径规划优化，从而减少能量消耗和人力成本。 |
| [^41] | [Self-Refine: Iterative Refinement with Self-Feedback.](http://arxiv.org/abs/2303.17651) | 自我反馈迭代精炼是一种无需监督学习或加强学习的LLMs初始输出优化方法，优于直接生成，被证实在7个不同任务中表现更好。 |
| [^42] | [Gaze-based Attention Recognition for Human-Robot Collaboration.](http://arxiv.org/abs/2303.17619) | 该论文介绍了一种基于凝视的注意力识别模型，可以用于改善人机协作体验，减少心理压力。 |
| [^43] | [Estimating Continuous Muscle Fatigue For Multi-Muscle Coordinated Exercise: A Pilot Study.](http://arxiv.org/abs/2303.17614) | 本研究通过多种肌肉特征的无监督估计，有效地评估了涉及多肌肉协调运动的疲劳，为制定康复和训练计划提供了重要依据。 |
| [^44] | [oBERTa: Improving Sparse Transfer Learning via improved initialization, distillation, and pruning regimes.](http://arxiv.org/abs/2303.17612) | oBERTa是一组易于使用的语言模型，通过改进初始化、蒸馏、剪枝等技术，可以在不需要模型压缩方面的专业知识的情况下提高稀疏迁移学习的效率和准确性。 |
| [^45] | [Transformer-based Self-supervised Multimodal Representation Learning for Wearable Emotion Recognition.](http://arxiv.org/abs/2303.17611) | 提出了一种基于Transformer的自监督多模态表示学习方法，其中采用时间卷积特定编码器和共享编码器实现高效的多模态融合，利用自动标记的未标记数据对模型进行了预训练，可用于情感相关下游任务。 |
| [^46] | [Visual Response to Emotional State of User Interaction.](http://arxiv.org/abs/2303.17608) | 本文介绍了一种交互艺术装置“情绪弹簧”，通过解释语言和语调来反映环境的心情，并使用情感检测方法处理用户的音频和文本输入。 |
| [^47] | [Machine learning for discovering laws of nature.](http://arxiv.org/abs/2303.17607) | 模型基于达尔文自然选择，结合函数选择和运算符选择两个过程，通过从数据中学习构建理论，可自动发现和表示自然定律，成功应用于模拟多领域问题，并提供一种新方法解决描述自然定律的严格数学模型不足的问题。 |
| [^48] | [Preventing Object-centric Discovery of Unsound Process Models for Object Interactions with Loops in Collaborative Systems: Extended Version.](http://arxiv.org/abs/2303.16680) | OCPD范例转变了流程挖掘，可以处理与一系列对象相关联的事件，本文提出的扩展OCPD方法可以避免原方法中关于多对象交互循环的错误问题。 |
| [^49] | [Reproducibility is Nothing without Correctness: The Importance of Testing Code in NLP.](http://arxiv.org/abs/2303.16166) | 在NLP研究中，我们不能仅凭感知质量假定代码正确性，应该推动采用编码最佳实践以提高实验结果的正确性和可靠性。 |
| [^50] | [Learning Reward Machines in Cooperative Multi-Agent Tasks.](http://arxiv.org/abs/2303.14061) | 本文提出了一种新的多智能体强化学习方法，将合作任务分解与学习奖励机制相结合。该方法有助于解决部分可观察环境中奖励的非马尔可夫性质，并提高了学习策略的可解释性，同时也降低了合作任务的复杂性。 |
| [^51] | [Prompting Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages.](http://arxiv.org/abs/2303.13592) | 本文探讨了使用大型语言模型（LLMs）生成东南亚五种语言和Singlish的混合代码数据的方法，发现ChatGPT展现出最高的潜力。然而，由于词汇选择错误的影响，ChatGPT和InstructGPT在生成混合代码时的熟练程度受到限制。 |
| [^52] | [Fairness-guided Few-shot Prompting for Large Language Models.](http://arxiv.org/abs/2303.13217) | 本文提出了一种新的搜索策略-FairPrompt，在保证公正性的前提下，通过评估提示预测偏差，确定近似最优的提示，从而改进大型语言模型的上下文学习性能，实验表明该方法在准确性和公正性方面均优于现有方法。 |
| [^53] | [Rewarding Chatbots for Real-World Engagement with Millions of Users.](http://arxiv.org/abs/2303.06135) | 本文研究了如何通过利用用户反馈来提高聊天机器人的参与度，从而增强其留存能力。具体方法是使用自动伪标签来训练奖励模型，并使用平均对话长度一类的指标来衡量其效果。在试验中，该方法可将聊天机器人的平均对话长度提高70%。 |
| [^54] | [BO-Muse: A human expert and AI teaming framework for accelerated experimental design.](http://arxiv.org/abs/2303.01684) | BO-Muse是一种新的人工智能和人类专家协作的优化方法，它让人类专家发挥主导作用，通过注入新颖性并发现弱点来打破过度开发，以加速实验设计。 |
| [^55] | [Understanding the Diffusion Objective as a Weighted Integral of ELBOs.](http://arxiv.org/abs/2303.00848) | 本文深入理解了扩散目标，并揭示了加权损失和ELBO目标之间的直接关系。 |
| [^56] | [CitySpec with Shield: A Secure Intelligent Assistant for Requirement Formalization.](http://arxiv.org/abs/2302.09665) | CitySpec with Shield是一种安全的智能助手，用于帮助城市决策者将人类指定的需求转换为监测系统可理解的形式。 |
| [^57] | [Towards Verifying the Geometric Robustness of Large-scale Neural Networks.](http://arxiv.org/abs/2301.12456) | 本文提出了一种名为GeoRobust的黑盒鲁棒性分析器，旨在对大规模神经网络进行多个几何变换的鲁棒性验证，并且无论网络的体系结构、激活函数和神经元数量如何，GeoRobust都能够提供高精度的最坏情况的变换组合。 |
| [^58] | [Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture.](http://arxiv.org/abs/2301.08243) | 本论文提出了一种非生成方法的自监督学习架构，即Image-based Joint-Embedding Predictive Architecture（I-JEPA），可以生成高度语义图像表示，通过联合嵌入预测架构和掩模策略达到这一目的。 |
| [^59] | [Estimating truncation effects of quantum bosonic systems using sampling algorithms.](http://arxiv.org/abs/2212.08546) | 本文提出了一种使用传统采样方法估计量子玻色系统截断误差的方法，该方法可用于估计实际量子模拟玻色理论所需的资源，并检查对应量子模拟的结果的有效性。 |
| [^60] | [DATID-3D: Diversity-Preserved Domain Adaptation Using Text-to-Image Diffusion for 3D Generative Model.](http://arxiv.org/abs/2211.16374) | 本文提出一种基于文本图像扩散的多样性保留领域自适应方法，用于解决3D生成模型在多种不同领域的训练挑战，该方法应用于将2D生成模型转化为其它风格的领域模型，通过CLIP学习文本和图像之间的关系。 |
| [^61] | [Improving Sample Quality of Diffusion Models Using Self-Attention Guidance.](http://arxiv.org/abs/2210.00939) | 该论文提出了一种利用自注意力指导的策略来提升扩散模型生成图像的稳定性和质量，具有较高的实用价值。 |
| [^62] | [Black-box Dataset Ownership Verification via Backdoor Watermarking.](http://arxiv.org/abs/2209.06015) | 本文提出了一种通过后门水印技术验证已发布数据集的所有权的方法，以检测其是否被用于训练（可疑的）第三方模型。 |
| [^63] | [Towards Unconstrained Audio Splicing Detection and Localization with Neural Networks.](http://arxiv.org/abs/2207.14682) | 研究提出了一种基于 Transformer 序列到序列（seq2seq）网络的音频拼接检测与定位方法，能够在各种攻击场景中准确检测出拼接并定位，具有普适性和鲁棒性。 |
| [^64] | [Continual evaluation for lifelong learning: Identifying the stability gap.](http://arxiv.org/abs/2205.13452) | 终身学习中，时间相关的数据生成分布对神经网络的梯度训练具有困难性。一些最先进的方法在开始学习新任务时会存在轻微的遗忘，随后会有一段性能恢复的阶段跟随，我们称之为“稳定性差距”。 |
| [^65] | [HIT-UAV: A high-altitude infrared thermal dataset for Unmanned Aerial Vehicle-based object detection.](http://arxiv.org/abs/2204.03245) | HIT-UAV是一个高空红外热数据集，用于无人机目标检测，包括2898个图像和飞行数据，手动注释了定向和标准边界框。此数据集是公开的、首个用于检测人和车辆的高空无人机红外热数据集。 |
| [^66] | [From Natural Language to Simulations: Applying GPT-3 Codex to Automate Simulation Modeling of Logistics Systems.](http://arxiv.org/abs/2202.12107) | 该论文展示了自然语言处理的自动化能力应用到物流系统模拟建模中，证明了基于GPT-3 Codex的框架能够生成功能有效的排队和库存控制系统的模拟模型，为简化模拟模型开发工作流程开启了重要大门。 |
| [^67] | [VRL3: A Data-Driven Framework for Visual Deep Reinforcement Learning.](http://arxiv.org/abs/2202.10324) | 本文提出VRL3，一种数据驱动的框架，可用于解决具有挑战性的视觉深度强化学习任务。该框架包含三个阶段，并能在具有稀疏奖励和逼真视觉输入的手部操纵任务中显著提高样本效率。 |
| [^68] | [Near-Optimal Learning of Extensive-Form Games with Imperfect Information.](http://arxiv.org/abs/2202.01752) | 本文提出了一种新的算法系列，可以更快速地在不完美信息广义博弈中找到一个近似最优解。 |
| [^69] | [Automated scholarly paper review: Concepts, technologies, and challenges.](http://arxiv.org/abs/2111.07533) | 提出自动学术论文审稿（ASPR）的概念和流程，综述了实现全面计算机化审稿流程的相关文献和技术，同时指出实现中存在的挑战，如文档解析和表达不完美、数据不足、人机交互缺陷和发现低质量文章的难度。 |
| [^70] | [One-Step Abductive Multi-Target Learning with Diverse Noisy Samples and Its Application to Tumour Segmentation for Breast Cancer.](http://arxiv.org/abs/2110.10325) | 本论文提出了一种新的机器学习方法——一步式诱导式多目标学习与DiNS（OSAMTL-DiNS），以处理医学组织病理学全幻灯片图像分析中的复杂噪声标签。在乳腺癌肿瘤分割中得到了成功应用。 |

# 详细

[^1]: 基于直觉物理的3D人体姿态估计

    3D Human Pose Estimation via Intuitive Physics. (arXiv:2303.18246v1 [cs.CV])

    [http://arxiv.org/abs/2303.18246](http://arxiv.org/abs/2303.18246)

    用物理引擎强制实现3D人体姿态估计的物理合理性在实践中有很大困难。这篇论文中开发了一种基于直觉物理的方法，借助压力热图、压力中心和身体质心等术语，在估计3D人体姿态的同时，实现了物理合理性。

    

    图像估计人体姿态时往往会出现不合理的身体倾斜、浮动或穿透地板的情况。这样的方法忽视了身体通常由场景支撑的事实。物理引擎可以用来强制实现物理合理性，但这些引擎不可微分，依赖于不现实的代理物体，并且难以集成到现有的优化和学习框架中。相比之下，我们利用新颖的直觉物理（IP）术语，这些术语可以从一个与场景相互作用的3D SMPL身体中推断出来。受生物力学的启发，我们推断出身体上的压力热图、热图上的压力中心（CoP）以及SMPL身体的质心。借助这些，我们开发了IPMAN，通过鼓励合理的地板接触和重叠的CoP和CoM，在彩色图像中估计一个“稳定”的3D身体。我们的IP术语直观易懂，易于实现，计算速度快，可微分，并且可以集成到现有的优化和回归模型中。

    Estimating 3D humans from images often produces implausible bodies that lean, float, or penetrate the floor. Such methods ignore the fact that bodies are typically supported by the scene. A physics engine can be used to enforce physical plausibility, but these are not differentiable, rely on unrealistic proxy bodies, and are difficult to integrate into existing optimization and learning frameworks. In contrast, we exploit novel intuitive-physics (IP) terms that can be inferred from a 3D SMPL body interacting with the scene. Inspired by biomechanics, we infer the pressure heatmap on the body, the Center of Pressure (CoP) from the heatmap, and the SMPL body's Center of Mass (CoM). With these, we develop IPMAN, to estimate a 3D body from a color image in a "stable" configuration by encouraging plausible floor contact and overlapping CoP and CoM. Our IP terms are intuitive, easy to implement, fast to compute, differentiable, and can be integrated into existing optimization and regression m
    
[^2]: 寻找具有身体智能的人工视觉皮层在哪里？

    Where are we in the search for an Artificial Visual Cortex for Embodied Intelligence?. (arXiv:2303.18240v1 [cs.CV])

    [http://arxiv.org/abs/2303.18240](http://arxiv.org/abs/2303.18240)

    该研究研究了使用预训练视觉表征来实现身体智能的最新进展。他们展示了最大、最全面的经验研究，发现没有一种表征是普遍优越的，并且数据集的大小和多样性并不能普遍改善性能。

    

    我们提出了最大、最全面的预训练视觉表征（PVR）或视觉基础模型的经验研究，用于身体智能。首先，我们策划了 CortexBench，其中包括涵盖动力学、导航、熟练和移动操作的17种不同任务。接下来，我们系统评估了现有的PVR，发现没有一种是普遍优越的。为了研究预训练数据规模和多样性的影响，我们结合了来自7个不同来源的超过4000小时的自我中心视频（超过560万张图像）和ImageNet，使用切片数据的遮盖自编码（MAE）来训练不同大小的视觉变形器。与先前的工作推断相反，我们发现扩展数据集的规模和多样性并不能普遍改善性能（但平均性能有所提高）。我们最大的模型名为VC-1，平均表现超过所有先前的PVR，但也没有普遍优势。最后，我们展示了VC-1的特定于任务或领域的适应会带来实质性的改进。

    We present the largest and most comprehensive empirical study of pre-trained visual representations (PVRs) or visual 'foundation models' for Embodied AI. First, we curate CortexBench, consisting of 17 different tasks spanning locomotion, navigation, dexterous, and mobile manipulation. Next, we systematically evaluate existing PVRs and find that none are universally dominant.  To study the effect of pre-training data scale and diversity, we combine over 4,000 hours of egocentric videos from 7 different sources (over 5.6M images) and ImageNet to train different-sized vision transformers using Masked Auto-Encoding (MAE) on slices of this data. Contrary to inferences from prior work, we find that scaling dataset size and diversity does not improve performance universally (but does so on average).  Our largest model, named VC-1, outperforms all prior PVRs on average but does not universally dominate either. Finally, we show that task or domain-specific adaptation of VC-1 leads to substantia
    
[^3]: 大型语言模型综述

    A Survey of Large Language Models. (arXiv:2303.18223v1 [cs.CL])

    [http://arxiv.org/abs/2303.18223](http://arxiv.org/abs/2303.18223)

    本文综述了大型语言模型的研究历程以及最近的预训练语言模型(PLMs)，并强调模型扩展将带来性能改进和特殊能力的发掘。

    

    语言本质上是一个由语法规则控制的复杂精细的人类表达系统，对于开发理解和掌握语言的能力的AI算法来说是一项重大挑战。作为主要方法之一，语言建模在过去二十年里广泛研究用于语言理解和生成，从统计语言模型演化为神经语言模型。最近，通过在大规模语料库上预训练Transformer模型，提出了预训练语言模型（PLMs），在解决各种NLP任务方面显示出强大的能力。由于研究人员发现模型缩放可以导致性能改进，他们进一步通过增加模型规模来研究缩放效应，有趣的是，当参数规模超过一定水平时，这些扩大的语言模型不仅可以实现显着的性能提升，而且还显示出一些小规模语言模型所没有的特殊能力。

    Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale langu
    
[^4]: TPMCF: 使用多源协同特征进行时间QoS预测

    TPMCF: Temporal QoS Prediction using Multi-Source Collaborative Features. (arXiv:2303.18201v1 [cs.SE])

    [http://arxiv.org/abs/2303.18201](http://arxiv.org/abs/2303.18201)

    本文提出了一种新的方法TPMCF，利用多源特征进行QoS预测。该方法利用带有注意力机制的编码器-解码器架构，并使用协作特征捕捉用户和服务之间的关系，有效地处理数据稀疏和异常值。

    

    最近，随着服务API的快速部署，个性化的服务推荐在电子商务行业的增长中发挥了至关重要的作用。决定服务性能的服务质量(QoS)参数经常被用于推荐，但随时间波动。因此，QoS的预测对于在等价服务中识别合适的服务至关重要。当代的时间QoS预测方法由于各种限制而很难达到期望的精度，例如无法处理数据稀疏和异常值以及捕获用户-服务交互之间的高阶时间关系。虽然最近一些基于循环神经网络的体系结构可以建模QoS数据之间的时间关系，但由于缺乏其他特征（例如协作特征）来理解用户-服务交互之间的关系，预测精度会降低。本文通过提出一种解决方案TPMCF，来解决上述挑战。TPMCF利用多源特征（包括时间、用户和服务特征）进行QoS预测。具体地，它使用一个带有注意机制的新颖编码器解码器架构来利用用户-服务交互之间的高阶时间关系。此外，它使用协作特征来捕捉用户和服务之间的关系，并处理数据稀疏和异常值。对实际数据集进行的大量实验证明了TPMCF的有效性和优越性。

    Recently, with the rapid deployment of service APIs, personalized service recommendations have played a paramount role in the growth of the e-commerce industry. Quality-of-Service (QoS) parameters determining the service performance, often used for recommendation, fluctuate over time. Thus, the QoS prediction is essential to identify a suitable service among functionally equivalent services over time. The contemporary temporal QoS prediction methods hardly achieved the desired accuracy due to various limitations, such as the inability to handle data sparsity and outliers and capture higher-order temporal relationships among user-service interactions. Even though some recent recurrent neural-network-based architectures can model temporal relationships among QoS data, prediction accuracy degrades due to the absence of other features (e.g., collaborative features) to comprehend the relationship among the user-service interactions. This paper addresses the above challenges and proposes a s
    
[^5]: 基于破坏鲁棒性一致性的推理阶段后门检测

    Detecting Backdoors During the Inference Stage Based on Corruption Robustness Consistency. (arXiv:2303.18191v1 [cs.CR])

    [http://arxiv.org/abs/2303.18191](http://arxiv.org/abs/2303.18191)

    本文提出了一种新的测试时间触发样本检测方法 TeCo，该方法只需要受害模型的硬标签输出，通过评估测试时间鲁棒性一致性来检测后门，不需要其他额外的信息，提高了实用性。

    

    深度神经网络被证明容易受到后门攻击。在推理阶段检测触发样本，即测试时间触发样本检测，可以防止后门被触发。然而，现有的检测方法通常需要防御者对受害模型具有高度可访问性、额外的清洁数据或了解后门触发器的外观知识等，限制了它们的实用性。本文提出了一种新的测试时间触发样本检测方法 TeCo，该方法只需要受害模型的硬标签输出，不需要任何额外的信息。我们的研究从一项有趣的观察开始，即被感染的后门模型在对于干净图像的不同图像破坏方面具有相似的性能，但对于触发样本表现不一致。基于这一现象，我们设计了 TeCo 来评估测试时间鲁棒性一致性，通过计算预测结果的偏差来进行检测。

    Deep neural networks are proven to be vulnerable to backdoor attacks. Detecting the trigger samples during the inference stage, i.e., the test-time trigger sample detection, can prevent the backdoor from being triggered. However, existing detection methods often require the defenders to have high accessibility to victim models, extra clean data, or knowledge about the appearance of backdoor triggers, limiting their practicality. In this paper, we propose the test-time corruption robustness consistency evaluation (TeCo), a novel test-time trigger sample detection method that only needs the hard-label outputs of the victim models without any extra information. Our journey begins with the intriguing observation that the backdoor-infected models have similar performance across different image corruptions for the clean images, but perform discrepantly for the trigger samples. Based on this phenomenon, we design TeCo to evaluate test-time robustness consistency by calculating the deviation o
    
[^6]: 今天的迭代学习算法有多高效？

    How Efficient Are Today's Continual Learning Algorithms?. (arXiv:2303.18171v1 [cs.CV])

    [http://arxiv.org/abs/2303.18171](http://arxiv.org/abs/2303.18171)

    这篇论文研究了增量班级学习的最新方法，并指出许多方法在计算、内存和存储方面非常低效。为了使迭代学习在现实世界中具有适用性，研究界不能忽视这些算法使用的资源。

    

    监督式迭代学习涉及从不断增长的带标签数据流中更新深度神经网络（DNN）。尽管大部分工作集中在克服灾难性遗忘上，但迭代学习背后的主要动机之一是能够有效地更新网络，而不是随着训练数据集随时间增长，从头开始重新训练。尽管最近的迭代学习方法基本上解决了灾难遗忘问题，但对这些算法的效率关注不足。在这里，我们研究了增量班级学习的最新方法，并表明许多方法在计算、内存和存储方面非常低效。有些方法甚至需要更多的计算资源才能完成训练！我们认为，为了使迭代学习在现实世界中具有适用性，研究界不能忽视这些算法使用的资源。迭代学习不仅仅是缓解灾难性遗忘。

    Supervised Continual learning involves updating a deep neural network (DNN) from an ever-growing stream of labeled data. While most work has focused on overcoming catastrophic forgetting, one of the major motivations behind continual learning is being able to efficiently update a network with new information, rather than retraining from scratch on the training dataset as it grows over time. Despite recent continual learning methods largely solving the catastrophic forgetting problem, there has been little attention paid to the efficiency of these algorithms. Here, we study recent methods for incremental class learning and illustrate that many are highly inefficient in terms of compute, memory, and storage. Some methods even require more compute than training from scratch! We argue that for continual learning to have real-world applicability, the research community cannot ignore the resources used by these algorithms. There is more to continual learning than mitigating catastrophic forg
    
[^7]: 指标变量限制下秩一函数的约束优化

    Constrained Optimization of Rank-One Functions with Indicator Variables. (arXiv:2303.18158v1 [math.OC])

    [http://arxiv.org/abs/2303.18158](http://arxiv.org/abs/2303.18158)

    本文提出了一种基于透视重构技术的紧凑扩展公式，用于解决涉及指标变量限制下决策变量支持集合的秩一凸函数的最小化问题。

    

    在各种机器学习应用中，涉及到通过约束来建模决策变量支持集合的秩一凸函数的最小化的优化问题。这些问题通常采用指标变量来识别连续变量的支持。本文通过透视重构技术研究了这些问题的紧凑扩展公式。与大多数先前的研究依赖于支持函数参数和离散规划技术以提供凸包结果不同，我们提出了一种构造方法，利用透视函数引起的隐藏圆锥结构。为此，我们首先针对每个圆锥约束涉及独立连续变量的线性函数和一组二元变量的一般圆锥混合二进制集合建立了一个凸包结果。然后，我们展示了与应对epi相关的集合的扩展表示形式。

    Optimization problems involving minimization of a rank-one convex function over constraints modeling restrictions on the support of the decision variables emerge in various machine learning applications. These problems are often modeled with indicator variables for identifying the support of the continuous variables. In this paper we investigate compact extended formulations for such problems through perspective reformulation techniques. In contrast to the majority of previous work that relies on support function arguments and disjunctive programming techniques to provide convex hull results, we propose a constructive approach that exploits a hidden conic structure induced by perspective functions. To this end, we first establish a convex hull result for a general conic mixed-binary set in which each conic constraint involves a linear function of independent continuous variables and a set of binary variables. We then demonstrate that extended representations of sets associated with epi
    
[^8]: 智能电网故障预测系统的机器学习对抗攻击

    Machine-learned Adversarial Attacks against Fault Prediction Systems in Smart Electrical Grids. (arXiv:2303.18136v1 [cs.CR])

    [http://arxiv.org/abs/2303.18136](http://arxiv.org/abs/2303.18136)

    该论文提出了针对智能电网故障预测系统的机器学习对抗攻击的研究，证明智能电网中使用的深度神经网络方法容易受到对抗性攻击，并突出了目前在智能电网中的机器学习算法存在对各种对抗性攻击的弱点。

    

    在智能电网中，由于经济和关键性的原因，故障检测任务可能会对社会产生很大的影响。近年来，许多智能电网应用程序，如缺陷检测和负载预测，已经采用了数据驱动的方法。本研究的目的是研究智能电网情况下机器学习（ML）应用的安全性挑战。事实上，这些数据驱动算法的鲁棒性和安全性尚未与所有电网应用程序相关地进行广泛研究。我们首先证明了智能电网中使用的深度神经网络方法容易受到对抗性攻击。接着，我们突出展示了故障定位和类型分类方面的研究，说明了目前在智能电网中的机器学习算法对各种对抗性攻击的弱点。

    In smart electrical grids, fault detection tasks may have a high impact on society due to their economic and critical implications. In the recent years, numerous smart grid applications, such as defect detection and load forecasting, have embraced data-driven methodologies. The purpose of this study is to investigate the challenges associated with the security of machine learning (ML) applications in the smart grid scenario. Indeed, the robustness and security of these data-driven algorithms have not been extensively studied in relation to all power grid applications. We demonstrate first that the deep neural network method used in the smart grid is susceptible to adversarial perturbation. Then, we highlight how studies on fault localization and type classification illustrate the weaknesses of present ML algorithms in smart grids to various adversarial attacks
    
[^9]: AdvCheck：通过本地梯度检查表征对抗生成样本

    AdvCheck: Characterizing Adversarial Examples via Local Gradient Checking. (arXiv:2303.18131v1 [cs.CR])

    [http://arxiv.org/abs/2303.18131](http://arxiv.org/abs/2303.18131)

    本文提出了一种新的方法AdvCheck，通过计算本地梯度检测对抗性样本，相较于其他最先进的检测方法具有更高的效率和更好的表现。

    

    深度神经网络（DNN）容易受到对抗性样本攻击，在安全关键领域可能导致灾难。已经提出了各种检测方法来表征对抗生成样本的特征唯一性，或区分由对抗性样本触发的DNN的行为。基于特征的检测方法不能处理受到大扰动的对抗性样本，还需要大量的对抗性样本。另一个主流的基于模型的检测方法，通过模型行为表征输入属性，计算代价很高。为了解决这些问题，我们引入了本地梯度的概念，并揭示出对抗性样本的本地梯度较正常样本有更大的边界。我们受到这一观察的启发，利用本地梯度检测对抗性样本，并提出了一个通用的框架AdvCheck。具体地，通过从一些正常样本和添加噪声的杂项样本计算本地梯度，我们可以有效地区分对抗性样本和正常样本。我们进一步提出了一种名为AdvCheck-LIME的变体，通过引入局部性来处理本地梯度。广泛的实验在基准数据集上证明了我们提出的方法的优越性和效率，相较于其他最先进的检测方法。

    Deep neural networks (DNNs) are vulnerable to adversarial examples, which may lead to catastrophe in security-critical domains. Numerous detection methods are proposed to characterize the feature uniqueness of adversarial examples, or to distinguish DNN's behavior activated by the adversarial examples. Detections based on features cannot handle adversarial examples with large perturbations. Besides, they require a large amount of specific adversarial examples. Another mainstream, model-based detections, which characterize input properties by model behaviors, suffer from heavy computation cost. To address the issues, we introduce the concept of local gradient, and reveal that adversarial examples have a quite larger bound of local gradient than the benign ones. Inspired by the observation, we leverage local gradient for detecting adversarial examples, and propose a general framework AdvCheck. Specifically, by calculating the local gradient from a few benign examples and noise-added misc
    
[^10]: 利用自监督学习和最少标签实现医疗视频中体外镜头的自动检测以保护隐私

    Automatic Detection of Out-of-body Frames in Surgical Videos for Privacy Protection Using Self-supervised Learning and Minimal Labels. (arXiv:2303.18106v1 [cs.CV])

    [http://arxiv.org/abs/2303.18106](http://arxiv.org/abs/2303.18106)

    该论文提出了一种利用自监督学习和少量标签实现医疗视频中体外镜头自动检测的方法，可以有效保护隐私，比以前的方法表现更好，甚至使用 95% 更少的标签时也表现出色。

    

    内窥镜视频记录广泛应用于微创机器人手术中，但当内镜在病人体外时，可能会捕获到包含敏感信息的无关片段。为了解决这个问题，我们提出了一个框架，利用自监督学习和最少的数据标签，准确检测医疗视频中的体外镜头。我们使用大量未标记的内窥镜图像以自监督方式学习有意义的特征表示。我们的方法需要进行辅助任务的预训练，然后在有限的监督下进行微调，优于以前的方法，在从 da Vinci X 和 Xi 手术系统拍摄的医疗视频中检测体外画面时，平均 F1 得分在 96.00 到 98.02 之间。有趣的是，仅使用 5% 的训练标签，我们的方法仍然保持平均 F1 得分在 97 以上，比全监督方法少用 95% 的标签表现更出色。这些结果证明了该方法的潜力。

    Endoscopic video recordings are widely used in minimally invasive robot-assisted surgery, but when the endoscope is outside the patient's body, it can capture irrelevant segments that may contain sensitive information. To address this, we propose a framework that accurately detects out-of-body frames in surgical videos by leveraging self-supervision with minimal data labels. We use a massive amount of unlabeled endoscopic images to learn meaningful representations in a self-supervised manner. Our approach, which involves pre-training on an auxiliary task and fine-tuning with limited supervision, outperforms previous methods for detecting out-of-body frames in surgical videos captured from da Vinci X and Xi surgical systems. The average F1 scores range from 96.00 to 98.02. Remarkably, using only 5% of the training labels, our approach still maintains an average F1 score performance above 97, outperforming fully-supervised methods with 95% fewer labels. These results demonstrate the pote
    
[^11]: 多语种时间和数字表达式的抽取和规范化数据集和基线系统

    Dataset and Baseline System for Multi-lingual Extraction and Normalization of Temporal and Numerical Expressions. (arXiv:2303.18103v1 [cs.CL])

    [http://arxiv.org/abs/2303.18103](http://arxiv.org/abs/2303.18103)

    该论文描述了一个覆盖14种语言、多元化的时间和数字表达式，包括提取、规范化和解析的多语言数据集(NTX)，并提供了一个强大的基于规则的系统作为评估其他模型的比较基准。

    

    在许多自然语言处理和信息检索任务中，时间和数字表达式的理解非常重要。然而，大多数以前的工作仅涵盖了少量的子类型，并且只关注实体抽取，这严重限制了识别到的提及的可用性。为了在下游场景中使用这些实体，子类型的覆盖范围和粒度很重要；并且更加重要的是，提供可以操作的具体值解析。此外，大多数先前的工作仅处理几种语言。在这里，我们描述了一个多语言评估数据集-NTX-涵盖了14种语言的各种时间和数字表达式，并覆盖了提取，规范化和解析。除了数据集之外，我们还提供了一个强大的基于规则的系统作为与在该数据集中评估其他模型的比较的强大基准。数据和代码可在 \url{https://aka.ms/NTX}上获得。

    Temporal and numerical expression understanding is of great importance in many downstream Natural Language Processing (NLP) and Information Retrieval (IR) tasks. However, much previous work covers only a few sub-types and focuses only on entity extraction, which severely limits the usability of identified mentions. In order for such entities to be useful in downstream scenarios, coverage and granularity of sub-types are important; and, even more so, providing resolution into concrete values that can be manipulated. Furthermore, most previous work addresses only a handful of languages. Here we describe a multi-lingual evaluation dataset - NTX - covering diverse temporal and numerical expressions across 14 languages and covering extraction, normalization, and resolution. Along with the dataset we provide a robust rule-based system as a strong baseline for comparisons against other models to be evaluated in this dataset. Data and code are available at \url{https://aka.ms/NTX}.
    
[^12]: 农田自监督表示学习的注入噪声鉴别器

    INoD: Injected Noise Discriminator for Self-Supervised Representation Learning in Agricultural Fields. (arXiv:2303.18101v1 [cs.CV])

    [http://arxiv.org/abs/2303.18101](http://arxiv.org/abs/2303.18101)

    本文提出了一个名为INoD的注入噪声鉴别器，通过特征替换和数据集鉴别的原则进行农田自监督表示学习，提升了模型性能。

    

    农业领域的感知数据集数量和多样性都受限，这影响了监督学习方法的有效训练。自监督学习技术可以缓解此问题，但现有方法没有针对农业领域的密集预测任务进行优化，导致模型性能下降。本文提出了注入噪声鉴别器（INoD），利用特征替换和数据集鉴别的原则进行自监督表示学习。INoD通过在两个不同数据集的卷积编码中交错特征图，并预测产生的特征图的数据集隶属关系作为预文本任务。我们的方法使网络能够学习一个数据集中对象的明确表示，同时与不同数据集中的相似特征一起观察。

    Perception datasets for agriculture are limited both in quantity and diversity which hinders effective training of supervised learning approaches. Self-supervised learning techniques alleviate this problem, however, existing methods are not optimized for dense prediction tasks in agriculture domains which results in degraded performance. In this work, we address this limitation with our proposed Injected Noise Discriminator (INoD) which exploits principles of feature replacement and dataset discrimination for self-supervised representation learning. INoD interleaves feature maps from two disjoint datasets during their convolutional encoding and predicts the dataset affiliation of the resultant feature map as a pretext task. Our approach enables the network to learn unequivocal representations of objects seen in one dataset while observing them in conjunction with similar features from the disjoint dataset. This allows the network to reason about higher-level semantics of the entailed o
    
[^13]: 解决形态学类比问题：从检索到生成

    Solving morphological analogies: from retrieval to generation. (arXiv:2303.18062v1 [cs.CL])

    [http://arxiv.org/abs/2303.18062](http://arxiv.org/abs/2303.18062)

    该论文提出了一个基于深度学习和条件变分自编码器的框架来解决基于类比的推理中的类比检测和解决两个任务，该框架可以生成之前不存在于数据集中的类比。

    

    类比推理是人类思维的一种非凡能力，并且已被用来解决难以理解的任务。 基于类比的推理（AR）受到了人工智能社区的越来越多的关注，并在多个机器学习任务中表现出其潜力，例如分类，决策和具有竞争性结果的推荐。 我们提出了一个基于深度学习（DL）的框架来解决AR中的两个关键任务：类比检测和解决。该框架在整个Siganalogies数据集上进行了全面测试，该数据集包含单词之间的形态学类比比例（APs），并且在许多语言中显示出优于符号方法的表现。 之前的工作已经探索了分类问题上的类比神经网络行为（ANNc）和检索问题上的类比神经网络行为（ANNr），以及自编码器（AE）在生成解决方案单词上的潜力。 在本文中，我们通过提出一个基于条件变分自编码器（CVAE）的统一框架来总结并扩展以前的工作，该框架可以共同解决两个任务。我们提出的框架可以生成在数据集中以前不存在的类比。

    Analogical inference is a remarkable capability of human reasoning, and has been used to solve hard reasoning tasks. Analogy based reasoning (AR) has gained increasing interest from the artificial intelligence community and has shown its potential in multiple machine learning tasks such as classification, decision making and recommendation with competitive results. We propose a deep learning (DL) framework to address and tackle two key tasks in AR: analogy detection and solving. The framework is thoroughly tested on the Siganalogies dataset of morphological analogical proportions (APs) between words, and shown to outperform symbolic approaches in many languages. Previous work have explored the behavior of the Analogy Neural Network for classification (ANNc) on analogy detection and of the Analogy Neural Network for retrieval (ANNr) on analogy solving by retrieval, as well as the potential of an autoencoder (AE) for analogy solving by generating the solution word. In this article we sum
    
[^14]: NOSTROMO: 教训、结论与未来方向

    NOSTROMO: Lessons learned, conclusions and way forward. (arXiv:2303.18060v1 [cs.LG])

    [http://arxiv.org/abs/2303.18060](http://arxiv.org/abs/2303.18060)

    本文介绍了元建模对于空中交通管理研究的价值，并强调了其在实现欧洲ATM总体计划中的关键绩效指标方面所起的作用。

    

    本白皮书旨在解释元建模对空中交通管理(ATM)研究的价值。它将定义元建模并探讨其能力和不能做到的事情。读者假定具有SESAR的基础知识：单一欧洲天空ATM研究项目。 SESAR的重要组成部分是带来改进，该项目是单一欧洲天空倡议的技术支柱，改进是通过特定关键绩效指标(KPIs)衡量的，并由所谓的SESAR“解决方案”系列来实施。这些“解决方案”是新的或改进的操作程序或技术，旨在满足欧洲ATM总体计划中描述的操作和性能改进。

    This White Paper sets out to explain the value that metamodelling can bring to air traffic management (ATM) research. It will define metamodelling and explore what it can, and cannot, do. The reader is assumed to have basic knowledge of SESAR: the Single European Sky ATM Research project. An important element of SESAR, as the technological pillar of the Single European Sky initiative, is to bring about improvements, as measured through specific key performance indicators (KPIs), and as implemented by a series of so-called SESAR 'Solutions'. These 'Solutions' are new or improved operational procedures or technologies, designed to meet operational and performance improvements described in the European ATM Master Plan.
    
[^15]: 简单的领域泛化方法是开放领域泛化的强大基准方法

    Simple Domain Generalization Methods are Strong Baselines for Open Domain Generalization. (arXiv:2303.18031v1 [cs.CV])

    [http://arxiv.org/abs/2303.18031](http://arxiv.org/abs/2303.18031)

    该论文评估了基于领域泛化的方法在开放领域泛化中的表现，证明了CORAL和MMD等简单DG方法在某些情况下的竞争力，提出了这些方法的简单扩展。

    

    在现实世界的应用中，机器学习模型需要处理开放集识别（OSR），即在推理过程中出现未知类别，以及领域漂移（domain shift），即训练和推理阶段之间数据分布不同的情况。领域泛化（DG）旨在处理推理阶段的目标领域在模型训练期间不可访问的情况下的领域漂移情况。开放领域泛化（ODG）同时考虑了DG和OSR。领域增强元学习（DAML）是一个面向ODG的方法，但其学习过程较为复杂。另一方面，尽管提出了各种DG方法，但它们尚未在ODG情况下进行评估。本文全面评估现有的DG方法在ODG中的表现，并展示了两种简单的DG方法，即CORrelation ALignment（CORAL）和Maximum Mean Discrepancy（MMD）在若干情况下与DAML具有竞争力。此外，我们通过引入一个小调整，提出了CORAL和MMD的简单扩展。

    In real-world applications, a machine learning model is required to handle an open-set recognition (OSR), where unknown classes appear during the inference, in addition to a domain shift, where the distribution of data differs between the training and inference phases. Domain generalization (DG) aims to handle the domain shift situation where the target domain of the inference phase is inaccessible during model training. Open domain generalization (ODG) takes into account both DG and OSR. Domain-Augmented Meta-Learning (DAML) is a method targeting ODG but has a complicated learning process. On the other hand, although various DG methods have been proposed, they have not been evaluated in ODG situations. This work comprehensively evaluates existing DG methods in ODG and shows that two simple DG methods, CORrelation ALignment (CORAL) and Maximum Mean Discrepancy (MMD), are competitive with DAML in several cases. In addition, we propose simple extensions of CORAL and MMD by introducing th
    
[^16]: LaCViT：一种面向标签的对比训练框架，提高视觉Transformer的表示空间的等性

    LaCViT: A Label-aware Contrastive Training Framework for Vision Transformers. (arXiv:2303.18013v1 [cs.CV])

    [http://arxiv.org/abs/2303.18013](http://arxiv.org/abs/2303.18013)

    LaCViT是一种针对视觉Transformer预训练表示空间的各向等性不足问题，提高其表示空间等性的面向标签的对比训练框架，经过实验证明其在五个标准图像分类数据集中具有卓越的性能。

    

    视觉 Transformer 已经在处理计算机视觉任务时表现出了惊人的效果，这是由于其模拟长时间的特征依赖能力。通过使用大规模的训练数据和各种自监督信号（例如，遮蔽随机块），视觉 Transformer 在 ImageNet-1k 和 CIFAR-10 等几个基准数据集上提供了最先进的性能。然而，这些基于通用大规模图像语料库预训练的视觉Transformer只能产生各向异性表示空间，限制了它们在目标下游任务中的通用性和可转移性。在本文中，我们提出了一种简单而有效的面向标签的对比训练框架 LaCViT，它提高了视觉Transformer预训练表示空间的等性，从而实现了更有效的转移学习。通过对五个标准图像分类数据集的实验，我们证明了LaCViT训练的模型在各种图像分类任务中都具有卓越的性能。

    Vision Transformers have been incredibly effective when tackling computer vision tasks due to their ability to model long feature dependencies. By using large-scale training data and various self-supervised signals (e.g., masked random patches), vision transformers provide state-of-the-art performance on several benchmarking datasets, such as ImageNet-1k and CIFAR-10. However, these vision transformers pretrained over general large-scale image corpora could only produce an anisotropic representation space, limiting their generalizability and transferability to the target downstream tasks. In this paper, we propose a simple and effective Label-aware Contrastive Training framework LaCViT, which improves the isotropy of the pretrained representation space for vision transformers, thereby enabling more effective transfer learning amongst a wide range of image classification tasks. Through experimentation over five standard image classification datasets, we demonstrate that LaCViT-trained m
    
[^17]: 协同创新中的增强集体智能：议程与挑战

    Augmented Collective Intelligence in Collaborative Ideation: Agenda and Challenges. (arXiv:2303.18010v1 [cs.CY])

    [http://arxiv.org/abs/2303.18010](http://arxiv.org/abs/2303.18010)

    本文探讨了增强集体智能（ACI）在协同创新中的应用，包括设计一个实验来评估人工智能和人类混合团队的表现，并考察一种实时数据收集工具Polis。作者讨论了设计ACI实验时需要考虑的三个挑战：主题选择，参与者选择和结果评估。

    

    人工智能系统可能更应被看作是同伴而不是工具。

    AI systems may be better thought of as peers than as tools. This paper explores applications of augmented collective intelligence (ACI) beneficial to collaborative ideation. Design considerations are offered for an experiment that evaluates the performance of hybrid human- AI collectives. The investigation described combines humans and large language models (LLMs) to ideate on increasingly complex topics. A promising real-time collection tool called Polis is examined to facilitate ACI, including case studies from citizen engagement projects in Taiwan and Bowling Green, Kentucky. The authors discuss three challenges to consider when designing an ACI experiment: topic selection, participant selection, and evaluation of results. The paper concludes that researchers should address these challenges to conduct empirical studies of ACI in collaborative ideation.
    
[^18]: 提出更好的问题--预测的艺术与科学：实现对高风险问题真实答案的机制

    Asking Better Questions -- The Art and Science of Forecasting: A mechanism for truer answers to high-stakes questions. (arXiv:2303.18006v1 [cs.CY])

    [http://arxiv.org/abs/2303.18006](http://arxiv.org/abs/2303.18006)

    本文探讨了使用政治科学工具——预测来提高预测准确性的最新发展，成功案例揭示了一类“超级预测者”，对于适应快速变化的技术环境，建议将预测作为第一道防线考虑。

    

    如果无法评估和基准定量技术发展水平，组织就将被迫采取反应性方式应对每一次变化，从而阻碍其建立可行的中长期战略。本文探讨了政治科学工具——预测的最近发展情况，该工具使用明确的假设和定量的估计方法，从而提高了预测的准确性。当预测在集体层面进行时，可以确定和验证人才，使领导者能够构建更好的技术发展模型以及改进制定政策的方法。本文还研究了预测的成功案例，并揭示了一类“超级预测者”，他们的见解最为可靠，超过了98%的人群。最后，本文概述了成功预测背后的技术，包括菲利普·特特洛克的“十诫”。为了适应快速变化的技术环境，设计师和政策制定者应该将预测作为第一道防线考虑。

    Without the ability to estimate and benchmark AI capability advancements, organizations are left to respond to each change reactively, impeding their ability to build viable mid and long-term strategies. This paper explores the recent growth of forecasting, a political science tool that uses explicit assumptions and quantitative estimation that leads to improved prediction accuracy. Done at the collective level, forecasting can identify and verify talent, enable leaders to build better models of AI advancements and improve inputs into design policy. Successful approaches to forecasting and case studies are examined, revealing a subclass of "superforecasters" who outperform 98% of the population and whose insights will be most reliable. Finally, techniques behind successful forecasting are outlined, including Phillip Tetlock's "Ten Commandments." To adapt to a quickly changing technology landscape, designers and policymakers should consider forecasting as a first line of defense.
    
[^19]: 卵巢癌组织病理学中的人工智能：一项系统综述

    Artificial Intelligence in Ovarian Cancer Histopathology: A Systematic Review. (arXiv:2303.18005v1 [eess.IV])

    [http://arxiv.org/abs/2303.18005](http://arxiv.org/abs/2303.18005)

    通过对36篇文章的综述，该研究发现人工智能模型在卵巢癌的诊断和预后中显示出有希望的结果，但现有研究受到小样本量，潜在偏见和缺乏外部验证的限制。

    

    目的-特征化和评估已发表的研究，评估利用组织病理学数据进行卵巢癌诊断或预后的人工智能（AI）方法的质量。方法-在2022年1月12日之前，对5个来源进行搜索。包括标准要求研究评估AI在卵巢癌的组织病理学图像上，对卵巢癌，包括输卵管卵巢和腹膜肿瘤的诊断或预后推断。排除评论和非英语文章。对每个包含的模型使用PROBAST评估偏倚风险。结果-共发现1434篇研究文章，其中36篇符合纳入标准。这些研究报告了62个感兴趣的模型，其中包括35个分类器，14个生存预测模型，7个分割模型和6个回归模型。使用1-1375张从1-664个卵巢癌患者中得到的幻灯片开发了这些模型。预测了广泛的结果，包括总体生存（9/62），组织学亚型（7/62）和淋巴结状态（6/62）。结论-基于可用的文献，AI模型在卵巢癌组织病理学的诊断和预后中显示出有希望的结果。但是，现有的研究受到样本量小、潜在的偏见和缺乏外部验证的限制。

    Purpose - To characterise and assess the quality of published research evaluating artificial intelligence (AI) methods for ovarian cancer diagnosis or prognosis using histopathology data. Methods - A search of 5 sources was conducted up to 01/12/2022. The inclusion criteria required that research evaluated AI on histopathology images for diagnostic or prognostic inferences in ovarian cancer, including tubo-ovarian and peritoneal tumours. Reviews and non-English language articles were excluded. The risk of bias was assessed for every included model using PROBAST. Results - A total of 1434 research articles were identified, of which 36 were eligible for inclusion. These studies reported 62 models of interest, including 35 classifiers, 14 survival prediction models, 7 segmentation models, and 6 regression models. Models were developed using 1-1375 slides from 1-664 ovarian cancer patients. A wide array of outcomes were predicted, including overall survival (9/62), histological subtypes (7
    
[^20]: 神经网络熵(NNetEn)：基于熵特征的脑电信号和混沌时间序列分离，用于NNetEn计算的Python包

    Neural Network Entropy (NNetEn): EEG Signals and Chaotic Time Series Separation by Entropy Features, Python Package for NNetEn Calculation. (arXiv:2303.17995v1 [cs.LG])

    [http://arxiv.org/abs/2303.17995](http://arxiv.org/abs/2303.17995)

    该研究提出了一种新的熵估计方法NNetEn，用于有效地分离时间序列系统的混沌动态，并在分离混沌时间序列方面证明了其高效率。

    

    熵测量是时间序列分类问题中有效的特征。传统的熵测量方法，例如香农熵，使用概率分布函数。然而，为了有效地分离时间序列，需要新的熵估计方法来表征系统的混沌动态。我们的神经网络熵(NNetEn)概念是基于特殊数据集(MNIST-10和SARS-CoV-2-RBV1)的分类，这些数据集与记录在LogNNet神经网络储层中的时间序列熵相关。NNetEn以原始方式估计时间序列的混沌动态。基于NNetEn算法，我们提出了两个新的分类度量：R2效率和皮尔逊效率。NNetEn的效率在使用离散分析(ANOVA)分离正弦映射的两个混沌时间序列方面得到验证。对于两个接近的动态时间序列 (r=1.1918和r=1.2243)，F比值达到了124的值，反映了高效率。

    Entropy measures are effective features for time series classification problems. Traditional entropy measures, such as Shannon entropy, use probability distribution function. However, for the effective separation of time series, new entropy estimation methods are required to characterize the chaotic dynamic of the system. Our concept of Neural Network Entropy (NNetEn) is based on the classification of special datasets (MNIST-10 and SARS-CoV-2-RBV1) in relation to the entropy of the time series recorded in the reservoir of the LogNNet neural network. NNetEn estimates the chaotic dynamics of time series in an original way. Based on the NNetEn algorithm, we propose two new classification metrics: R2 Efficiency and Pearson Efficiency. The efficiency of NNetEn is verified on separation of two chaotic time series of sine mapping using dispersion analysis (ANOVA). For two close dynamic time series (r = 1.1918 and r = 1.2243), the F-ratio has reached the value of 124 and reflects high efficien
    
[^21]: 面向元宇宙的联邦学习：综述

    Federated Learning for Metaverse: A Survey. (arXiv:2303.17987v1 [cs.CR])

    [http://arxiv.org/abs/2303.17987](http://arxiv.org/abs/2303.17987)

    本文综述了早期FL4M的研究进展，并探讨了FL对于保护元宇宙参与者的数据隐私和降低服务器计算和存储需求的重要性。

    

    在元宇宙发展的过程中，数据采集和私人数据泄漏问题成为了制约其广泛应用的难题。联邦学习（FL）是一种分布式机器学习范式，具有隐私保护功能，专门设计用于大量边缘设备的训练任务。将FL应用于元宇宙不仅可以保护参与者的数据隐私，还可以减少服务器上高计算能力和高存储量的需求。本文回顾了针对FL4M的一些早期研究进展。

    The metaverse, which is at the stage of innovation and exploration, faces the dilemma of data collection and the problem of private data leakage in the process of development. This can seriously hinder the widespread deployment of the metaverse. Fortunately, federated learning (FL) is a solution to the above problems. FL is a distributed machine learning paradigm with privacy-preserving features designed for a large number of edge devices. Federated learning for metaverse (FL4M) will be a powerful tool. Because FL allows edge devices to participate in training tasks locally using their own data, computational power, and model-building capabilities. Applying FL to the metaverse not only protects the data privacy of participants but also reduces the need for high computing power and high memory on servers. Until now, there have been many studies about FL and the metaverse, respectively. In this paper, we review some of the early advances of FL4M, which will be a research direction with u
    
[^22]: 人类社交蜜罐：通过自管理的Instagram页面吸引人们

    Social Honeypot for Humans: Luring People through Self-managed Instagram Pages. (arXiv:2303.17946v1 [cs.SI])

    [http://arxiv.org/abs/2303.17946](http://arxiv.org/abs/2303.17946)

    本文介绍一种新颖的社交蜜罐概念，用于吸引对通用目标主题感兴趣的在线社交网络用户，并提供了一个基于完全自动化的内容生成策略和参与计划的框架。该框架提供了一种完全自动化，经济实惠和可扩展的方法，用于社交数据收集和研究目的。

    

    社交蜜罐是在线社交网络中部署的工具，用于吸引垃圾邮件和机器人执行的恶意活动。为此，它们的内容被设计成对恶意用户最感兴趣。然而，通过选择合适的内容主题，这种吸引机制可以扩展到任何在线社交网络用户，而不仅是吸引恶意用户。因此，蜜罐可以用于吸引对广泛主题感兴趣的个人，从体育和爱好到更敏感的政治观点和阴谋论。有了所有这些个人聚集在同一个地方，蜜罐所有者可以进行许多分析，从社交到市场研究。在这项工作中，我们引入了一个新颖的社交蜜罐概念，用于吸引对通用目标主题感兴趣的在线社交网络用户。我们提出了一个基于完全自动化的内容生成策略和参与计划的框架，以模拟合法的Instagram页面。为了验证我们的框架，我们在Instagram上创建了21个自我管理的社交蜜罐，侧重于21个不同的主题，从科技到生活方式，并总共获得了3,592个有机粉丝。通过这些社交蜜罐，我们收集了社交数据，用户行为和参与度指标。此外，我们还测试了我们蜜罐吸引具有不同兴趣和背景的用户的有效性。我们的框架提供了一种完全自动化，经济实惠和可扩展的方法，用于社交数据收集和研究目的。

    Social Honeypots are tools deployed in Online Social Networks (OSN) to attract malevolent activities performed by spammers and bots. To this end, their content is designed to be of maximum interest to malicious users. However, by choosing an appropriate content topic, this attractive mechanism could be extended to any OSN users, rather than only luring malicious actors. As a result, honeypots can be used to attract individuals interested in a wide range of topics, from sports and hobbies to more sensitive subjects like political views and conspiracies. With all these individuals gathered in one place, honeypot owners can conduct many analyses, from social to marketing studies.  In this work, we introduce a novel concept of social honeypot for attracting OSN users interested in a generic target topic. We propose a framework based on fully-automated content generation strategies and engagement plans to mimic legit Instagram pages. To validate our framework, we created 21 self-managed soc
    
[^23]: 用于自动驾驶测试的复杂环形交叉口的过程生成

    Procedural Generation of Complex Roundabouts for Autonomous Vehicle Testing. (arXiv:2303.17900v1 [cs.RO])

    [http://arxiv.org/abs/2303.17900](http://arxiv.org/abs/2303.17900)

    本文提出了一种基于附近道路结构的几何限制的过程生成方法，用于生成非完全圆形且类似于真实世界中的环形交叉口的车道，适用于自动驾驶场景测试。

    

    高清道路是自动驾驶场景模拟测试的重要组成部分，而环形交叉口是其中一个关键的路段，目前对其研究还不够深入。本研究基于附近道路结构的几何限制，提出一种新颖的建造环形交叉口的过程生成方法。该方法可以产生不完全圆形且类似于真实世界中的环形交叉口的车道，因为它允许连接到环形交叉口的途径道路的任意角度。可以轻松地将环形交叉口融入高清道路生成过程中，或使用独立的环形交叉口进行自动驾驶场景测试。

    High-definition roads are an essential component of realistic driving scenario simulation for autonomous vehicle testing. Roundabouts are one of the key road segments that have not been thoroughly investigated. Based on the geometric constraints of the nearby road structure, this work presents a novel method for procedurally building roundabouts. The suggested method can result in roundabout lanes that are not perfectly circular and resemble real-world roundabouts by allowing approaching roadways to be connected to a roundabout at any angle. One can easily incorporate the roundabout in their HD road generation process or use the standalone roundabouts in scenario-based testing of autonomous driving.
    
[^24]: 利用预训练模型探索深度图像聚类的极限

    Exploring the Limits of Deep Image Clustering using Pretrained Models. (arXiv:2303.17896v1 [cs.CV])

    [http://arxiv.org/abs/2303.17896](http://arxiv.org/abs/2303.17896)

    本文提出了一种利用预训练模型实现无标签图像分类的方法，通过自蒸馏训练聚类头学习图像之间的关联性，并提出了一种新的目标函数，可以高效准确地通过预训练特征空间中的结构来学习。使用该方法在ImageNet和CIFAR100的17个不同的预训练模型上将聚类精度相对于k-均值提高了6.1%和12.2%。在ImageNet上，使用自监督的预训练视觉变换器能够将聚类准确度提高到61.6%。

    

    我们提出了一种通用方法，利用预训练的特征提取器学习在没有标签的情况下对图像进行分类的方法。我们的方法涉及到基于预训练特征空间中最近邻居共享相同标签的事实对聚类头进行自蒸馏训练。我们提出了一种新的目标函数，通过引入一种点对点的互信息变量以及实例加权来学习图像之间的关联性。我们证明了所提出的目标函数能够减弱假阳性对的影响，同时高效地利用预训练特征空间中的结构。因此，我们在ImageNet和CIFAR100的17个不同的预训练模型上将聚类精度相对于k-均值提高了6.1%和12.2%。最后，使用自监督的预训练视觉变换器，我们将在ImageNet上的聚类准确度提高到了61.6%。代码将公开源代码化。

    We present a general methodology that learns to classify images without labels by leveraging pretrained feature extractors. Our approach involves self-distillation training of clustering heads, based on the fact that nearest neighbors in the pretrained feature space are likely to share the same label. We propose a novel objective to learn associations between images by introducing a variant of pointwise mutual information together with instance weighting. We demonstrate that the proposed objective is able to attenuate the effect of false positive pairs while efficiently exploiting the structure in the pretrained feature space. As a result, we improve the clustering accuracy over $k$-means on $17$ different pretrained models by $6.1$\% and $12.2$\% on ImageNet and CIFAR100, respectively. Finally, using self-supervised pretrained vision transformers we push the clustering accuracy on ImageNet to $61.6$\%. The code will be open-sourced.
    
[^25]: 区间逻辑张量网络

    Interval Logic Tensor Networks. (arXiv:2303.17892v1 [cs.AI])

    [http://arxiv.org/abs/2303.17892](http://arxiv.org/abs/2303.17892)

    本文提出了Interval Logic Tensor Networks (ILTN)一个神经符号系统，可以处理模糊逻辑、模糊时间区间的知识表示学习，并在推理事件和预测它们的模糊持续时间等任务上表现良好。

    

    本文介绍了一个两排序知识表示系统Interval Real Logic (IRL)，用于解释顺序属性（痕迹）和事件属性，使用实数特征数据序列。我们使用模糊逻辑对连接词进行解释，使用梯形模糊区间对事件持续时间进行解释，使用示性函数对模糊时间关系进行解释。我们提出了Interval Logic Tensor Networks(ILTN)这个神经符号系统，通过IRL通过梯度传播进行学习。为了支持有效的学习，ILTN使用softplus激活函数定义了平滑版本的IRL的模糊区间和时间关系。我们展示了，在需要推理事件并预测它们的模糊持续时间的合成任务中，ILTN可以成功利用表示在IRL中的知识。我们的结果表明，该系统能够使事件符合背景时间知识。

    In this paper, we introduce Interval Real Logic (IRL), a two-sorted logic that interprets knowledge such as sequential properties (traces) and event properties using sequences of real-featured data. We interpret connectives using fuzzy logic, event durations using trapezoidal fuzzy intervals, and fuzzy temporal relations using relationships between the intervals' areas. We propose Interval Logic Tensor Networks (ILTN), a neuro-symbolic system that learns by propagating gradients through IRL. In order to support effective learning, ILTN defines smoothened versions of the fuzzy intervals and temporal relations of IRL using softplus activations. We show that ILTN can successfully leverage knowledge expressed in IRL in synthetic tasks that require reasoning about events to predict their fuzzy durations. Our results show that the system is capable of making events compliant with background temporal knowledge.
    
[^26]: 一种针对弱监督学习的基准生成性概率模型

    A Benchmark Generative Probabilistic Model for Weak Supervised Learning. (arXiv:2303.17841v1 [cs.LG])

    [http://arxiv.org/abs/2303.17841](http://arxiv.org/abs/2303.17841)

    本文提出一种基准生成性概率模型，在启发式标注的原始数据集上训练，生成伪标签作为一种准确、快速、经济的弱监督学习方法，在图像分类和自然语言处理中达到了最先进的表现。

    

    寻找相关高质量的数据集来训练机器学习模型对于实践者来说是一个主要 bottleneck。而且，为了解决野心勃勃实际应用场景下的问题，数据通常需要附带带有高质量注释的标签，以便于监督模型的训练。手动标记具有高质量标签的数据通常是一项耗时且具有挑战性的任务，往往成为机器学习项目的瓶颈。弱监督学习 (WSL) 方法已被开发出来，通过根据启发式、远程监视和知识库来赋予未标记数据大约标签 (伪标签) 的自动方式，从而减轻注释负担。我们应用概率生成隐变量模型 (PLVMs)，在启发式标注表示的原始数据集上进行训练，作为一种生成伪标签的准确、快速、经济的方式。我们展示了 PLVMs 在图像分类中的多个基准数据集上实现了最先进的表现，并展示了它们在自然语言处理中的事件检测任务上的多才多艺。

    Finding relevant and high-quality datasets to train machine learning models is a major bottleneck for practitioners. Furthermore, to address ambitious real-world use-cases there is usually the requirement that the data come labelled with high-quality annotations that can facilitate the training of a supervised model. Manually labelling data with high-quality labels is generally a time-consuming and challenging task and often this turns out to be the bottleneck in a machine learning project. Weak Supervised Learning (WSL) approaches have been developed to alleviate the annotation burden by offering an automatic way of assigning approximate labels (pseudo-labels) to unlabelled data based on heuristics, distant supervision and knowledge bases. We apply probabilistic generative latent variable models (PLVMs), trained on heuristic labelling representations of the original dataset, as an accurate, fast and cost-effective way to generate pseudo-labels. We show that the PLVMs achieve state-of-
    
[^27]: 从教学视频及其解说中学习过程感知的视频表示

    Learning Procedure-aware Video Representation from Instructional Videos and Their Narrations. (arXiv:2303.17839v1 [cs.CV])

    [http://arxiv.org/abs/2303.17839](http://arxiv.org/abs/2303.17839)

    本文提出了一种从教学视频及其解说中学习过程感知的视频表示方法，联合学习视频表示和深度概率模型可以增强过程推理的新功能，同时对个体步骤的识别也能得到加强。

    

    互联网上教学视频及其解说的丰富资源为理解过程活动提供了令人兴奋的途径。本文提出了一种学习视频表示的方法，该表示对基于大规模网络教学视频及其解说的个体步骤及其时间顺序进行编码，而不使用人工注释。方法联合学习视频表示和深度概率模型，以捕获步骤的时间依赖关系和巨大个体差异。实验证明，学习时间排序不仅能够增强过程推理的新功能，还可以加强对个体步骤的识别。我们的模型在步骤分类（在COIN/EPIC-Kitchens上分别增加2.8% / 3.3%）和步骤预测（在COIN上增加7.4%）方面显著提高了最先进的结果。此外，我们的模型在步骤提取的零样本推理方面取得了有希望的结果。

    The abundance of instructional videos and their narrations over the Internet offers an exciting avenue for understanding procedural activities. In this work, we propose to learn video representation that encodes both action steps and their temporal ordering, based on a large-scale dataset of web instructional videos and their narrations, without using human annotations. Our method jointly learns a video representation to encode individual step concepts, and a deep probabilistic model to capture both temporal dependencies and immense individual variations in the step ordering. We empirically demonstrate that learning temporal ordering not only enables new capabilities for procedure reasoning, but also reinforces the recognition of individual steps. Our model significantly advances the state-of-the-art results on step classification (+2.8% / +3.3% on COIN / EPIC-Kitchens) and step forecasting (+7.4% on COIN). Moreover, our model attains promising results in zero-shot inference for step c
    
[^28]: 重新思考解释：深度视觉分类器的无特定输入显著性映射

    Rethinking interpretation: Input-agnostic saliency mapping of deep visual classifiers. (arXiv:2303.17836v1 [cs.CV])

    [http://arxiv.org/abs/2303.17836](http://arxiv.org/abs/2303.17836)

    提出了一种新的无特定输入显著性映射视角，它计算了模型对其输出所归属的高级特征，这种方法能够独立于输入进行模型解释，且鲁棒性较好。

    

    显著性方法通过将输入特征归属于模型输出，提供事后的模型解释。 当前的方法主要使用单个输入样本来实现这一点，因此无法回答有关模型的独立于输入的查询。 我们还表明，特定于输入的显著性映射本质上容易受到误导性特征归属的影响。试图使用“通用”输入特征来进行模型解释的现有尝试假定可以访问包含这些特征的数据集，这会导致解释的偏差。针对这一差距，我们提出了一种新的无特定输入显著性映射视角，该方法计算了模型对其输出所归属的高级特征。 这些特征是几何相关的，并通过积累模型相对于无限制数据分布的梯度信息来计算。 为了计算这些特征，我们将独立的数据点沿着人类可理解标签相关联的局部最小值推向模型损失面。 所提出的方法提供了一种新的解释深度分类器的方式，不依赖于特定输入信息，并且经过检验，在输入变化、噪声和对抗性攻击方面都很鲁棒。

    Saliency methods provide post-hoc model interpretation by attributing input features to the model outputs. Current methods mainly achieve this using a single input sample, thereby failing to answer input-independent inquiries about the model. We also show that input-specific saliency mapping is intrinsically susceptible to misleading feature attribution. Current attempts to use 'general' input features for model interpretation assume access to a dataset containing those features, which biases the interpretation. Addressing the gap, we introduce a new perspective of input-agnostic saliency mapping that computationally estimates the high-level features attributed by the model to its outputs. These features are geometrically correlated, and are computed by accumulating model's gradient information with respect to an unrestricted data distribution. To compute these features, we nudge independent data points over the model loss surface towards the local minima associated by a human-understa
    
[^29]: 《增强上下文学习提高代码生成能力》

    Towards Enhancing In-Context Learning for Code Generation. (arXiv:2303.17780v1 [cs.SE])

    [http://arxiv.org/abs/2303.17780](http://arxiv.org/abs/2303.17780)

    本文提出了一种名为AceCoder的代码生成上下文学习方法，与标准上下文学习相比，它通过示例检索和引导代码生成来提高生成代码的准确性和鲁棒性。

    

    基于预先训练的语言模型的上下文学习已经在代码生成领域表现出了强大的成功。通过这种方法，无需训练，模型只需要输入一个由少量需求-代码示例和一个新需求组成的提示，就能生成出新的程序。但是，现有的研究仅仅将上下文学习用于自然语言生成，忽略了代码生成的独特特性。我们称这些研究为标准上下文学习。本文通过对人类编码过程的观察，提出了一种新的名为AceCoder的代码生成上下文学习方法。与标准上下文学习相比，AceCoder有两个新颖之处。(1)示例检索。它检索类似程序作为示例，并从中学习编程技能(如算法、API)。(2)引导代码生成。它鼓励预训练的语言模型生成中间预备代码(如测试用例、API)并帮助模型理解需求和指导下一步代码生成。我们将AceCoder应用到大量代码生成任务中，实验结果表明，与现有的代码生成系统相比，AceCoder具有更高的准确性和鲁棒性。

    In-context learning (ICL) with pre-trained language models (PTLMs) has shown great success in code generation. ICL does not require training. PTLMs take as the input a prompt consisting of a few requirement-code examples and a new requirement, and output a new program. However, existing studies simply reuse ICL techniques for natural language generation and ignore unique features of code generation. We refer to these studies as standard ICL.  Inspired by observations of the human coding process, we propose a novel ICL approach for code generation named AceCoder. Compared to standard ICL, AceCoder has two novelties. (1) Example retrieval. It retrieves similar programs as examples and learns programming skills (e.g., algorithms, APIs) from them. (2) Guided Code Generation. It encourages PTLMs to output an intermediate preliminary (e.g., test cases, APIs) before generating programs. The preliminary can help PTLMs understand requirements and guide the next code generation. We apply AceCode
    
[^30]: 半弱监督下的物体运动动力学预测

    Semi-Weakly Supervised Object Kinematic Motion Prediction. (arXiv:2303.17774v1 [cs.CV])

    [http://arxiv.org/abs/2303.17774](http://arxiv.org/abs/2303.17774)

    本研究提出了一种半弱监督的方法，通过利用物体部件语义分割数据集和方法，解决了物体运动动力学预测问题。通过一个图神经网络，可以检测底层3D结构中的移动部分。

    

    给定一个3D物体，运动动力学预测旨在确定移动部件以及相应的运动参数。由于3D物体的拓扑结构和几何细节的巨大变化，这仍然是一项具有挑战性的任务，缺乏大型标记数据也限制了基于深度学习的方法的表现。本文以半弱监督方式解决了物体运动动力学预测问题。我们的主要观察结果有两个。首先，尽管全面注释运动标签的3D数据集是有限的，但存在大规模的物体部件语义分割数据集和方法。其次，语义部分分割和移动部分分割并不总是一致的，但可以从底层3D结构中检测出移动部分。为此，我们提出了一个图神经网络来学习分层部件级别分割和移动部件参数之间的映射。

    Given a 3D object, kinematic motion prediction aims to identify the mobile parts as well as the corresponding motion parameters. Due to the large variations in both topological structure and geometric details of 3D objects, this remains a challenging task and the lack of large scale labeled data also constrain the performance of deep learning based approaches. In this paper, we tackle the task of object kinematic motion prediction problem in a semi-weakly supervised manner. Our key observations are two-fold. First, although 3D dataset with fully annotated motion labels is limited, there are existing datasets and methods for object part semantic segmentation at large scale. Second, semantic part segmentation and mobile part segmentation is not always consistent but it is possible to detect the mobile parts from the underlying 3D structure. Towards this end, we propose a graph neural network to learn the map between hierarchical part-level segmentation and mobile parts parameters, which 
    
[^31]: 爆炉分类器设计中融合领域知识

    Domain Knowledge integrated for Blast Furnace Classifier Design. (arXiv:2303.17769v1 [cs.LG])

    [http://arxiv.org/abs/2303.17769](http://arxiv.org/abs/2303.17769)

    本文设计了一种融合领域知识的分类模型框架，生成适用于工业应用的分类器，有效解决了安全和能源等不同学习目标下爆炉复杂系统的问题。

    

    爆炉建模和控制是工业领域中的重要问题，黑匣子模型是描述复杂爆炉系统的有效手段。为了满足工业应用中的安全和节能等不同学习目标，本文提出了一种框架，用于设计融合领域知识的分类模型，生成适用于工业应用的分类器。我们的知识融入学习方案允许用户更正确地创建一个分类器，以识别“重要样本”（其错误分类可能导致严重后果），同时保持恰当的分类精度。所提出的方法的有效性已经通过两个真实的爆炉数据集得到验证，这将指导操作人员更好地利用他们的先前经验来控制爆炉系统。

    Blast furnace modeling and control is one of the important problems in the industrial field, and the black-box model is an effective mean to describe the complex blast furnace system. In practice, there are often different learning targets, such as safety and energy saving in industrial applications, depending on the application. For this reason, this paper proposes a framework to design a domain knowledge integrated classification model that yields a classifier for industrial application. Our knowledge incorporated learning scheme allows the users to create a classifier that identifies "important samples" (whose misclassifications can lead to severe consequences) more correctly, while keeping the proper precision of classifying the remaining samples. The effectiveness of the proposed method has been verified by two real blast furnace datasets, which guides the operators to utilize their prior experience for controlling the blast furnace systems better.
    
[^32]: 朝向对抗鲁棒的持续学习

    Towards Adversarially Robust Continual Learning. (arXiv:2303.17764v1 [cs.LG])

    [http://arxiv.org/abs/2303.17764](http://arxiv.org/abs/2303.17764)

    该论文是关于在持续学习中提高对抗鲁棒性的研究，首次提出一种新方法“任务感知边界增强（TABA）”，并在CIFAR-10和CIFAR-100上进行了充分的实验验证其有效性。

    

    最近的研究表明，经过持续学习训练的模型可以达到与标准监督学习相当的性能，并且持续学习模型的学习灵活性使得它们在实际应用中具有广泛的应用前景。然而，深度学习模型显示出对抗攻击的弱点。虽然在标准监督学习的情况下有许多关于模型鲁棒性的研究，但保护持续学习免受对抗攻击尚未受到研究。为了填补这一研究空白，我们是首次研究持续学习中的对抗鲁棒性，并提出一种名为任务感知边界增强（Task-Aware Boundary Augmentation，TABA）的新方法来提高持续学习模型的鲁棒性。通过在CIFAR-10和CIFAR-100上进行全面的实验，我们展示了对抗训练和TABA在防御对抗攻击方面的有效性。

    Recent studies show that models trained by continual learning can achieve the comparable performances as the standard supervised learning and the learning flexibility of continual learning models enables their wide applications in the real world. Deep learning models, however, are shown to be vulnerable to adversarial attacks. Though there are many studies on the model robustness in the context of standard supervised learning, protecting continual learning from adversarial attacks has not yet been investigated. To fill in this research gap, we are the first to study adversarial robustness in continual learning and propose a novel method called \textbf{T}ask-\textbf{A}ware \textbf{B}oundary \textbf{A}ugmentation (TABA) to boost the robustness of continual learning models. With extensive experiments on CIFAR-10 and CIFAR-100, we show the efficacy of adversarial training and TABA in defending adversarial attacks.
    
[^33]: CAMEL: 用于“心智”探索大规模语言模型社群的交互式代理

    CAMEL: Communicative Agents for "Mind" Exploration of Large Scale Language Model Society. (arXiv:2303.17760v1 [cs.AI])

    [http://arxiv.org/abs/2303.17760](http://arxiv.org/abs/2303.17760)

    本文介绍了一个名为角色扮演的新型交互式代理框架，用于实现语言模型之间的自主合作，并展示了其在生成对话数据方面的有效性。

    

    对话式语言模型的快速发展已取得了在复杂任务解决方面的显著进展。然而，它们的成功在很大程度上依赖于人类的指导，以引导对话，这可能是具有挑战性和耗时的。本文探讨了构建可扩展技术以促进交互式代理之间的自主合作并深入了解它们的“认知”过程的潜力。为了解决实现自主合作的挑战，我们提出了一个名为角色扮演的新型交互式代理框架。我们的方法涉及使用启动提示来引导聊天代理完成任务，同时保持与人类意图的一致性。我们展示了如何使用角色扮演来生成对话数据，以研究聊天代理的行为和能力，为研究对话式语言模型提供了有价值的资源。我们的贡献是介绍了一种新型的交互式代理框架，名为角色扮演，用于实现语言模型之间的自主合作，并展示了其在生成对话数据方面的有效性。

    The rapid advancement of conversational and chat-based language models has led to remarkable progress in complex task-solving. However, their success heavily relies on human input to guide the conversation, which can be challenging and time-consuming. This paper explores the potential of building scalable techniques to facilitate autonomous cooperation among communicative agents and provide insight into their "cognitive" processes. To address the challenges of achieving autonomous cooperation, we propose a novel communicative agent framework named role-playing. Our approach involves using inception prompting to guide chat agents toward task completion while maintaining consistency with human intentions. We showcase how role-playing can be used to generate conversational data for studying the behaviors and capabilities of chat agents, providing a valuable resource for investigating conversational language models. Our contributions include introducing a novel communicative agent framewor
    
[^34]: 最优输入增益：超级前馈神经网络所需的全部。

    Optimal Input Gain: All You Need to Supercharge a Feed-Forward Neural Network. (arXiv:2303.17732v1 [cs.LG])

    [http://arxiv.org/abs/2303.17732](http://arxiv.org/abs/2303.17732)

    通过优化输入增益，可以显著提高前馈神经网络的性能，特别是在使用反向传播和隐藏权重优化等算法时。

    

    输入的线性转换改变了等效的前馈网络的训练性能。然而，大多数线性变换被视为与实际训练分离的预处理操作。从等效网络开始，通过线性转换对输入进行预处理等效于在每次训练迭代中将负梯度矩阵与自相关矩阵相乘。提出了一个二阶方法，用于找到在给定迭代中最大化学习的自相关矩阵。当自相关矩阵为对角线矩阵时，该方法优化了输入增益。该最优输入增益（OIG）方法用于改进两个一阶二级训练算法，即反向传播（BP）和隐藏权重优化（HWO），这两种算法交替更新输入权重并解线性方程以确定输出权重。结果证明，所提出的OIG方法极大地提高了第一顺序算法的性能。

    Linear transformation of the inputs alters the training performance of feed-forward networks that are otherwise equivalent. However, most linear transforms are viewed as a pre-processing operation separate from the actual training. Starting from equivalent networks, it is shown that pre-processing inputs using linear transformation are equivalent to multiplying the negative gradient matrix with an autocorrelation matrix per training iteration. Second order method is proposed to find the autocorrelation matrix that maximizes learning in a given iteration. When the autocorrelation matrix is diagonal, the method optimizes input gains. This optimal input gain (OIG) approach is used to improve two first-order two-stage training algorithms, namely back-propagation (BP) and hidden weight optimization (HWO), which alternately update the input weights and solve linear equations for output weights. Results show that the proposed OIG approach greatly enhances the performance of the first-order al
    
[^35]: 基于GPT和BERT的模型在生物医学文本中鉴定蛋白质相互作用的评估

    Evaluation of GPT and BERT-based models on identifying protein-protein interactions in biomedical text. (arXiv:2303.17728v1 [cs.CL])

    [http://arxiv.org/abs/2303.17728](http://arxiv.org/abs/2303.17728)

    该论文评估了预先训练的语言模型(GPT和BERT)识别生物医学文本中蛋白质相互作用的性能, 结果显示BERT模型表现最佳，其中PubMedBERT具有最高的精度和F1分数，BioM-ALBERT具有最高的召回率。

    

    检测蛋白质相互作用(PPIs)对于理解遗传机制、疾病发病机理和药物设计至关重要。然而，随着生物医学文献的快速增长，需要自动化和准确提取PPIs以促进科学知识的发掘。已经预先训练的语言模型，如生成式预训练变压器(GPT)和双向编码器表示变压器(BERT)，在自然语言处理(NLP)任务上表现出有希望的结果。我们使用手动编制的LLL基准语料库评估了各种GPT和BERT模型的PPI识别性能，该语料库包含77个句子中的164个PPIs。BERT模型取得了最佳的性能，其中PubMedBERT具有最高的精度(85.17%)和F1分数(86.47%)，BioM-ALBERT具有最高的召回率(93.83%)。尽管GPT-4没有专门针对生物医学文本进行训练，但其性能可与其他模型相媲美。

    Detecting protein-protein interactions (PPIs) is crucial for understanding genetic mechanisms, disease pathogenesis, and drug design. However, with the fast-paced growth of biomedical literature, there is a growing need for automated and accurate extraction of PPIs to facilitate scientific knowledge discovery. Pre-trained language models, such as generative pre-trained transformer (GPT) and bidirectional encoder representations from transformers (BERT), have shown promising results in natural language processing (NLP) tasks. We evaluated the PPI identification performance of various GPT and BERT models using a manually curated benchmark corpus of 164 PPIs in 77 sentences from learning language in logic (LLL). BERT-based models achieved the best overall performance, with PubMedBERT achieving the highest precision (85.17%) and F1-score (86.47%) and BioM-ALBERT achieving the highest recall (93.83%). Despite not being explicitly trained for biomedical texts, GPT-4 achieved comparable perfo
    
[^36]: 重新思考人工智能可解释性与合理性

    Rethinking AI Explainability and Plausibility. (arXiv:2303.17707v1 [cs.AI])

    [http://arxiv.org/abs/2303.17707](http://arxiv.org/abs/2303.17707)

    本文研究了XAI评估中最普遍的人为概念——解释合理性。虽然一直被制定为AI可解释性任务的重要评估目标，但是评估XAI的合理性有时是有害的，且无法达到模型可理解性、透明度和可信度的目的。

    

    为了使可解释人工智能（XAI）算法符合人类交流规范，支持人类推理过程，并满足人类对于AI解释的需求，设定适当的评估目标至关重要。在本文中，我们研究了解释合理性，这是XAI评估中最普遍的人为概念。合理性衡量机器解释与人类解释相比的合理程度。合理性一直被传统地制定为AI可解释性任务的重要评估目标。我们反对这个想法，并展示了如何优化和评估XAI的合理性有时是有害的，且无法达到模型可理解性、透明度和可信度的目的。具体来说，评估XAI算法的合理性会规范机器解释，以表达与人类解释完全相同的内容，这偏离了人类解释的基本动机：表达自己的理解。

    Setting proper evaluation objectives for explainable artificial intelligence (XAI) is vital for making XAI algorithms follow human communication norms, support human reasoning processes, and fulfill human needs for AI explanations. In this article, we examine explanation plausibility, which is the most pervasive human-grounded concept in XAI evaluation. Plausibility measures how reasonable the machine explanation is compared to the human explanation. Plausibility has been conventionally formulated as an important evaluation objective for AI explainability tasks. We argue against this idea, and show how optimizing and evaluating XAI for plausibility is sometimes harmful, and always ineffective to achieve model understandability, transparency, and trustworthiness. Specifically, evaluating XAI algorithms for plausibility regularizes the machine explanation to express exactly the same content as human explanation, which deviates from the fundamental motivation for humans to explain: expres
    
[^37]: 用字符级噪音微调BERT实现零样本跨方言及相关语言迁移

    Fine-Tuning BERT with Character-Level Noise for Zero-Shot Transfer to Dialects and Closely-Related Languages. (arXiv:2303.17683v1 [cs.CL])

    [http://arxiv.org/abs/2303.17683](http://arxiv.org/abs/2303.17683)

    本研究使用字符级噪音微调BERT以实现对未见方言和语言的零样本跨语言迁移。本研究发现只有在任务依赖表面级别提示并且源-目标跨语言对具有相对较高的词汇重叠时，在微调过程中引入字符级噪音对跨语言迁移的效果才特别突出。

    

    本研究中，我们使用不同形式的字符级噪音进行BERT微调，以实现对未见方言和语言的零样本跨语言迁移。我们在三个句子级分类任务上微调BERT，并在一些未见方言和语言上评估了我们的方法。我们发现，在某些条件下，字符级噪音可以是跨语言迁移的极其有效的工具，而在其他情况下则不太有帮助。具体而言，我们通过任务的性质和源语言和目标语言之间的关系探讨了这些差异，发现在任务依赖表面级别提示并且源-目标跨语言对具有相对较高的词汇重叠时，在微调过程中引入字符级噪音特别有帮助。

    In this work, we induce character-level noise in various forms when fine-tuning BERT to enable zero-shot cross-lingual transfer to unseen dialects and languages. We fine-tune BERT on three sentence-level classification tasks and evaluate our approach on an assortment of unseen dialects and languages. We find that character-level noise can be an extremely effective agent of cross-lingual transfer under certain conditions, while it is not as helpful in others. Specifically, we explore these differences in terms of the nature of the task and the relationships between source and target languages, finding that introduction of character-level noise during fine-tuning is particularly helpful when a task draws on surface level cues and the source-target cross-lingual pair has a relatively high lexical overlap with shorter (i.e., less meaningful) unseen tokens on average.
    
[^38]: 利用遥感技术分析土地利用和水稻种植模式

    Utilizing Remote Sensing to Analyze Land Usage and Rice Planting Patterns. (arXiv:2303.17670v1 [cs.CY])

    [http://arxiv.org/abs/2303.17670](http://arxiv.org/abs/2303.17670)

    该研究利用遥感技术分析了巴厘岛水稻田中的空间分布模式，揭示了决策和环境因素对种植决策的影响。

    

    在巴厘岛合作管理水稻梯田中，人类决策和生态系统过程之间的反馈环路引出了有趣的现象。特别地，观察到空间分布模式，受农民种植作物的决策以及物理环境如害虫损害和水源短缺的响应，严重依赖于决策。最近的一项研究提出了演化博弈理论模型，推断了支配这种空间分布模式的特定幂律规律。本文展示了巴厘岛水稻田光亮的快照，使用颜色来指示不同生长阶段的水稻。

    The cooperative management of rice terraces in Bali reveals an interesting phenomenon that stems from the feedback loop between human decisions and the ecosystem process. In particular, spatial patterning is observed, which is heavily reliant on the farmer's decision to plant crops as well as the response from the physical environment like pest damage and water shortage. A recent study proposed an evolutionary game theoretic model to infer particular power laws governing this spatial patterning along the Bali region. In this paper, we show a snapshot of rice patches in Bali with colors to indicate the different stages of rice growth
    
[^39]: MetaEnhance:大学图书馆电子学位论文元数据质量提升

    MetaEnhance: Metadata Quality Improvement for Electronic Theses and Dissertations of University Libraries. (arXiv:2303.17661v1 [cs.DL])

    [http://arxiv.org/abs/2303.17661](http://arxiv.org/abs/2303.17661)

    本论文提出了MetaEnhance，一个利用最先进的人工智能方法来提高电子学位论文关键字段质量的框架，并成功在500份样本中实现了高准确性的元数据错误检测和纠正。

    

    数字对象的元数据质量对于通过数字库界面进行发现非常重要。但由于各种原因，数字对象的元数据通常展示出不完整、不一致和不正确的值。我们研究了自动检测、纠正和规范学术元数据的方法，以电子学位论文的七个关键字段为案例研究。我们提出了MetaEnhance，这是一个利用最先进的人工智能方法来提高这些字段质量的框架。为了评估MetaEnhance，我们编制了一个元数据质量评估基准，其中包含500个电子学位论文，通过多个标准进行采样子集来组合。我们对这个基准测试MetaEnhance，结果发现所提出的方法几乎完美地实现了错误检测的F1分数以及五个字段中的错误纠正的F1分数在0.85到1.00之间。

    Metadata quality is crucial for digital objects to be discovered through digital library interfaces. However, due to various reasons, the metadata of digital objects often exhibits incomplete, inconsistent, and incorrect values. We investigate methods to automatically detect, correct, and canonicalize scholarly metadata, using seven key fields of electronic theses and dissertations (ETDs) as a case study. We propose MetaEnhance, a framework that utilizes state-of-the-art artificial intelligence methods to improve the quality of these fields. To evaluate MetaEnhance, we compiled a metadata quality evaluation benchmark containing 500 ETDs, by combining subsets sampled using multiple criteria. We tested MetaEnhance on this benchmark and found that the proposed methods achieved nearly perfect F1-scores in detecting errors and F1-scores in correcting errors ranging from 0.85 to 1.00 for five of seven fields.
    
[^40]: 基于Q学习的无人机集群障碍物路径规划系统

    Q-learning Based System for Path Planning with UAV Swarms in Obstacle Environments. (arXiv:2303.17655v1 [cs.AI])

    [http://arxiv.org/abs/2303.17655](http://arxiv.org/abs/2303.17655)

    本文提出了一种基于强化学习的Q学习算法，能够在有障碍物的环境中通过人工神经网络进行路径规划优化，从而减少能量消耗和人力成本。

    

    随着无人机集群的自主控制需求不断增加，面对复杂环境中的障碍物，路径规划对于优化能量消耗和减少人力成本具有重要作用。本篇论文提出了一种基于强化学习的Q学习算法，通过人工神经网络不断调整学习，实现在有障碍物的环境中进行路径规划。

    Path Planning methods for autonomous control of Unmanned Aerial Vehicle (UAV) swarms are on the rise because of all the advantages they bring. There are more and more scenarios where autonomous control of multiple UAVs is required. Most of these scenarios present a large number of obstacles, such as power lines or trees. If all UAVs can be operated autonomously, personnel expenses can be decreased. In addition, if their flight paths are optimal, energy consumption is reduced. This ensures that more battery time is left for other operations. In this paper, a Reinforcement Learning based system is proposed for solving this problem in environments with obstacles by making use of Q-Learning. This method allows a model, in this particular case an Artificial Neural Network, to self-adjust by learning from its mistakes and achievements. Regardless of the size of the map or the number of UAVs in the swarm, the goal of these paths is to ensure complete coverage of an area with fixed obstacles f
    
[^41]: 自我反馈迭代精炼：一种无需监督学习或加强学习的LM改进框架

    Self-Refine: Iterative Refinement with Self-Feedback. (arXiv:2303.17651v1 [cs.CL])

    [http://arxiv.org/abs/2303.17651](http://arxiv.org/abs/2303.17651)

    自我反馈迭代精炼是一种无需监督学习或加强学习的LLMs初始输出优化方法，优于直接生成，被证实在7个不同任务中表现更好。

    

    鉴于语言模型(LLMs)不总是能在第一次良好地解决生成问题（如摘要、答案、解释等），我们引入自我反馈迭代精炼（SELF-REFINE）框架，通过迭代反馈和精炼相似地优化LLMs的初始输出。主要思想是：使用LLM生成输出，然后允许同一模型提供其自身输出的多方面反馈，最后利用反馈使相同模型精炼先前生成的输出。我们的迭代精炼框架与早期工作不同，无需监督训练数据或加强学习，并且可以与单个LLM一起使用。我们对七个不同的任务进行了实验，范围从评论重写到数学推理，表明我们的方法优于直接生成。在所有任务中，使用SELF-REFINE生成的输出被人类和自动化指标优先于使用GPT-3.5和GPT-4直接生成的输出，表现得更好。

    Like people, LLMs do not always generate the best text for a given generation problem on their first try (e.g., summaries, answers, explanations). Just as people then refine their text, we introduce SELF-REFINE, a framework for similarly improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an output using an LLM, then allow the same model to provide multi-aspect feedback for its own output; finally, the same model refines its previously generated output given its own feedback. Unlike earlier work, our iterative refinement framework does not require supervised training data or reinforcement learning, and works with a single LLM. We experiment with 7 diverse tasks, ranging from review rewriting to math reasoning, demonstrating that our approach outperforms direct generation. In all tasks, outputs generated with SELF-REFINE are preferred by humans and by automated metrics over those generated directly with GPT-3.5 and GPT-4, improving
    
[^42]: 基于凝视的人机协作中的注意力识别

    Gaze-based Attention Recognition for Human-Robot Collaboration. (arXiv:2303.17619v1 [cs.HC])

    [http://arxiv.org/abs/2303.17619](http://arxiv.org/abs/2303.17619)

    该论文介绍了一种基于凝视的注意力识别模型，可以用于改善人机协作体验，减少心理压力。

    

    注意力（和分心）识别是改善人机协作的关键因素。我们介绍了一个组装场景，在其中，人类操作员和协作机器人平等地合作拼装变速箱。该设置提供了多种机会，使机器人能够根据操作员的注意力而适应其行为，从而可以提高协作体验并减少心理压力。作为第一步，我们识别人类操作员关注的工作区域，并因此检测出操作员注意力分散的情况。我们提出了一种新颖的深度学习方法来开发注意力识别模型。首先，我们使用公开的图像数据集训练卷积神经网络来估计注视方向。然后，我们使用少量数据集的迁移学习将凝视方向映射到预定义的感兴趣区域。在我们实验室收集的小数据集上进行交叉验证时，使用这种方法训练的模型表现非常好。我们的实验表明，所提出的注意力识别模型可以用于通过使机器人根据操作者的注意力调整其行为来改善人机协作。

    Attention (and distraction) recognition is a key factor in improving human-robot collaboration. We present an assembly scenario where a human operator and a cobot collaborate equally to piece together a gearbox. The setup provides multiple opportunities for the cobot to adapt its behavior depending on the operator's attention, which can improve the collaboration experience and reduce psychological strain. As a first step, we recognize the areas in the workspace that the human operator is paying attention to, and consequently, detect when the operator is distracted. We propose a novel deep-learning approach to develop an attention recognition model. First, we train a convolutional neural network to estimate the gaze direction using a publicly available image dataset. Then, we use transfer learning with a small dataset to map the gaze direction onto pre-defined areas of interest. Models trained using this approach performed very well in leave-one-subject-out evaluation on the small datas
    
[^43]: 评估多肌肉协调运动的持续肌肉疲劳：一项试点研究

    Estimating Continuous Muscle Fatigue For Multi-Muscle Coordinated Exercise: A Pilot Study. (arXiv:2303.17614v1 [cs.HC])

    [http://arxiv.org/abs/2303.17614](http://arxiv.org/abs/2303.17614)

    本研究通过多种肌肉特征的无监督估计，有效地评估了涉及多肌肉协调运动的疲劳，为制定康复和训练计划提供了重要依据。

    

    评估日常锻炼中肌肉疲劳程度为精确定制康复和个性化训练剂量提供重要指标，特别是在Metaverse的背景下。评估涉及多肌肉协调运动的疲劳需要表示多肌肉时空适应的疲劳特征和捕捉疲劳时间演变进程的估计器的神经肌肉特征。本文提出了通过肌肉补偿和脊髓模块激活变化的特征来描述疲劳，并通过生理基础模型估计持续性疲劳。我们提取了肌肉协同分数和脊髓模块尖峰值方差作为疲劳诱导神经肌肉适应的特征，并将这些特征视为观测值，开发了贝叶斯高斯过程用于捕捉时间演变过程。我们采用无监督估计策略解决了训练数据中缺乏监督的问题。我们在8名健康参与者进行了一项试点研究，参与者进行了一系列协同抬腿练习，结果证明了所提出的方法根据神经肌肉特征有效地估计了持续性疲劳。

    Assessing the progression of muscle fatigue for daily exercises provides vital indicators for precise rehabilitation, personalized training dose, especially under the context of Metaverse. Assessing fatigue of multi-muscle coordination-involved daily exercises requires the neuromuscular features that represent the fatigue-induced characteristics of spatiotemporal adaptions of multiple muscles and the estimator that captures the time-evolving progression of fatigue. In this paper, we propose to depict fatigue by the features of muscle compensation and spinal module activation changes and estimate continuous fatigue by a physiological rationale model. First, we extract muscle synergy fractionation and the variance of spinal module spikings as features inspired by the prior of fatigue-induced neuromuscular adaptations. Second, we treat the features as observations and develop a Bayesian Gaussian process to capture the time-evolving progression. Third, we solve the issue of lacking supervi
    
[^44]: oBERTa: 通过改进初始化、蒸馏和剪枝来提高稀疏迁移学习

    oBERTa: Improving Sparse Transfer Learning via improved initialization, distillation, and pruning regimes. (arXiv:2303.17612v1 [cs.CL])

    [http://arxiv.org/abs/2303.17612](http://arxiv.org/abs/2303.17612)

    oBERTa是一组易于使用的语言模型，通过改进初始化、蒸馏、剪枝等技术，可以在不需要模型压缩方面的专业知识的情况下提高稀疏迁移学习的效率和准确性。

    

    本文介绍了oBERTa语言模型的范围，它是一组易于使用的语言模型，允许自然语言处理（NLP）从业者在不需要模型压缩方面的专业知识的情况下获得3.8到24.3倍的更快速的模型。oBERTa扩展了现有的剪枝、知识蒸馏和量化工作，并利用冻结的嵌入来改进知识蒸馏，并改进模型初始化，以在广泛的传递任务上提供更高的准确性。在生成oBERTa时，我们探索了高度优化的RoBERTa与BERT在预训练和微调期间剪枝方面的不同之处，并发现它在微调期间不太适合压缩。我们探索了oBERTa在七个具有代表性的NLP任务上的使用，并发现改进的压缩技术使得经过剪枝的oBERTa模型能够匹配BERTBASE的性能，并超过SQUAD V1.1问答数据的Prune OFA Large的性能。

    In this paper, we introduce the range of oBERTa language models, an easy-to-use set of language models, which allows Natural Language Processing (NLP) practitioners to obtain between 3.8 and 24.3 times faster models without expertise in model compression. Specifically, oBERTa extends existing work on pruning, knowledge distillation, and quantization and leverages frozen embeddings to improve knowledge distillation, and improved model initialization to deliver higher accuracy on a a broad range of transfer tasks. In generating oBERTa, we explore how the highly optimized RoBERTa differs from the BERT with respect to pruning during pre-training and fine-tuning and find it less amenable to compression during fine-tuning. We explore the use of oBERTa on a broad seven representative NLP tasks and find that the improved compression techniques allow a pruned oBERTa model to match the performance of BERTBASE and exceed the performance of Prune OFA Large on the SQUAD V1.1 Question Answering data
    
[^45]: 基于Transformer自监督多模态表示学习的可穿戴情感识别

    Transformer-based Self-supervised Multimodal Representation Learning for Wearable Emotion Recognition. (arXiv:2303.17611v1 [cs.HC])

    [http://arxiv.org/abs/2303.17611](http://arxiv.org/abs/2303.17611)

    提出了一种基于Transformer的自监督多模态表示学习方法，其中采用时间卷积特定编码器和共享编码器实现高效的多模态融合，利用自动标记的未标记数据对模型进行了预训练，可用于情感相关下游任务。

    

    近年来，基于周边生理信号的可穿戴情感识别因其非侵入性和在实际场景中的应用性而受到广泛关注。然而，如何有效地融合多模态数据仍是一个具有挑战性的问题。另外，传统的完全监督式方法在有限的有标签数据下容易出现过拟合。针对上述问题，我们提出了一个新颖的自监督学习框架，其中通过基于时间卷积的模态特定编码器和基于Transformer的共享编码器实现了高效的多模态融合，捕获了模态内和模态间的相关性。利用5个信号变换，大量未标记的数据被自动赋予标签，所提出的SSL模型通过信号变换的识别作为掩饰任务进行预训练，允许提取用于情感相关下游任务的广义多模态表示。

    Recently, wearable emotion recognition based on peripheral physiological signals has drawn massive attention due to its less invasive nature and its applicability in real-life scenarios. However, how to effectively fuse multimodal data remains a challenging problem. Moreover, traditional fully-supervised based approaches suffer from overfitting given limited labeled data. To address the above issues, we propose a novel self-supervised learning (SSL) framework for wearable emotion recognition, where efficient multimodal fusion is realized with temporal convolution-based modality-specific encoders and a transformer-based shared encoder, capturing both intra-modal and inter-modal correlations. Extensive unlabeled data is automatically assigned labels by five signal transforms, and the proposed SSL model is pre-trained with signal transformation recognition as a pretext task, allowing the extraction of generalized multimodal representations for emotion-related downstream tasks. For evaluat
    
[^46]: 交互情感状态的视觉响应

    Visual Response to Emotional State of User Interaction. (arXiv:2303.17608v1 [cs.HC])

    [http://arxiv.org/abs/2303.17608](http://arxiv.org/abs/2303.17608)

    本文介绍了一种交互艺术装置“情绪弹簧”，通过解释语言和语调来反映环境的心情，并使用情感检测方法处理用户的音频和文本输入。

    

    本文提出了一种交互式艺术装置“情绪弹簧”，设计目的是通过解释语言和语调来反映环境的心情。情绪弹簧包含一个控制季节的沉浸式3D动画的AI程序。如果AI程序感知到用户的语言和语调是愉悦的，动画将进展到理想化的季节再现。否则，它将滑入季节中不愉快的天气和自然灾害。为了解释用户交互的语言和语调，混合了最先进的情感检测方法来处理用户的音频和文本输入。从语调和语言分别检测到的情感状态通过一种新颖的方法融合，旨在最小化跨不同人群的可能模型分歧。

    This work proposes an interactive art installation "Mood spRing" designed to reflect the mood of the environment through interpretation of language and tone. Mood spRing consists of an AI program that controls an immersive 3D animation of the seasons. If the AI program perceives the language and tone of the users as pleasant, the animation progresses through idealized renditions of seasons. Otherwise, it slips into unpleasant weather and natural disasters of the season. To interpret the language and tone of the user interaction, hybrid state-of-the-art emotion detection methods are applied to the user audio and text inputs. The emotional states detected separately from tone and language are fused by a novel approach that aims at minimizing the possible model disparity across diverse demographic groups.
    
[^47]: 发现自然定律的机器学习

    Machine learning for discovering laws of nature. (arXiv:2303.17607v1 [cs.LG])

    [http://arxiv.org/abs/2303.17607](http://arxiv.org/abs/2303.17607)

    模型基于达尔文自然选择，结合函数选择和运算符选择两个过程，通过从数据中学习构建理论，可自动发现和表示自然定律，成功应用于模拟多领域问题，并提供一种新方法解决描述自然定律的严格数学模型不足的问题。

    

    微观粒子遵循量子力学的原理——那么宏观和微观世界之间的明确界限在哪里呢？正是这个“解释问题”促使薛定谔提出了他著名的思想实验（一只同时死亡和活着的猫），引发了关于量子测量问题的激烈争论，但至今仍没有令人满意的答案。这正是描述自然定律的严格数学模型的不足之处。我们提出了一个基于达尔文自然选择的计算模型来描述和理解自然定律。实际上，无论是宏观粒子、微观电子还是安全问题，它们都可以被认为是一个实体，这个实体随着时间的推移变化，可以用状态和值组成的数据序列来描述。观察者可以从这个数据序列中学习，构建理论（通常由函数和微分方程组成）。我们不再使用用户的经验或逻辑来建模，而是使用数据。计算模型的核心基于两个过程：函数选择和运算符选择。函数选择过程类似于达尔文的进化，允许具有优势特征的函数生存和繁殖；而运算符选择过程捕捉了自然定律的相互依存性，可以平衡自然界中不同函数的优势。该方法使我们能够从数据中自动发现和表示自然定律，并已成功应用于模拟量子力学、经典力学和系统生物学。

    A microscopic particle obeys the principles of quantum mechanics -- so where is the sharp boundary between the macroscopic and microscopic worlds? It was this "interpretation problem" that prompted Schr\"odinger to propose his famous thought experiment (a cat that is simultaneously both dead and alive) and sparked a great debate about the quantum measurement problem, and there is still no satisfactory answer yet. This is precisely the inadequacy of rigorous mathematical models in describing the laws of nature. We propose a computational model to describe and understand the laws of nature based on Darwin's natural selection. In fact, whether it's a macro particle, a micro electron or a security, they can all be considered as an entity, the change of this entity over time can be described by a data series composed of states and values. An observer can learn from this data series to construct theories (usually consisting of functions and differential equations). We don't model with the us
    
[^48]: 针对循环协同系统中对象交互的不良过程模型的目标导向防止方法：扩展版

    Preventing Object-centric Discovery of Unsound Process Models for Object Interactions with Loops in Collaborative Systems: Extended Version. (arXiv:2303.16680v1 [cs.AI])

    [http://arxiv.org/abs/2303.16680](http://arxiv.org/abs/2303.16680)

    OCPD范例转变了流程挖掘，可以处理与一系列对象相关联的事件，本文提出的扩展OCPD方法可以避免原方法中关于多对象交互循环的错误问题。

    

    对象中心的过程发现（OCPD）是流程挖掘中的范式转变。 OCPD能够处理不具有单个案例概念但与具有特定类型的一系列对象相关联的事件。对象类型构成多个交互案例概念。 OCPD的输出是一个对象中心Petri网，即具有对象类型位置的Petri网，表示与对象类型对应的多个执行流的并行执行。本文提出了一种扩展OCPD方法，并证明其不会受到原始方法中出现的不良问题的影响。

    Object-centric process discovery (OCPD) constitutes a paradigm shift in process mining. Instead of assuming a single case notion present in the event log, OCPD can handle events without a single case notion, but that are instead related to a collection of objects each having a certain type. The object types constitute multiple, interacting case notions. The output of OCPD is an object-centric Petri net, i.e. a Petri net with object-typed places, that represents the parallel execution of multiple execution flows corresponding to object types. Similar to classical process discovery, where we aim for behaviorally sound process models as a result, in OCPD, we aim for soundness of the resulting object-centric Petri nets. However, the existing OCPD approach can result in violations of soundness. As we will show, one violation arises for multiple interacting object types with loops that arise in collaborative systems. This paper proposes an extended OCPD approach and proves that it does not s
    
[^49]: 没有正确性的可重复性并不重要：在NLP领域中测试代码的重要性。

    Reproducibility is Nothing without Correctness: The Importance of Testing Code in NLP. (arXiv:2303.16166v1 [cs.CL])

    [http://arxiv.org/abs/2303.16166](http://arxiv.org/abs/2303.16166)

    在NLP研究中，我们不能仅凭感知质量假定代码正确性，应该推动采用编码最佳实践以提高实验结果的正确性和可靠性。

    

    尽管其在研究实验中发挥了关键作用，但代码正确性往往仅基于结果的感知质量而被假定。这带来了错误结果和潜在误导性发现的风险。为了解决这个问题，我们认为当前关注结果重现应该与强调编码最佳实践相辅相成。我们通过一个案例研究来支持我们向NLP社区发出的号召，在这个案例研究中，我们识别出并纠正了广泛使用的最先进Conformer架构的开源实现中的三个Bug。通过在各种语言环境下进行的自动语音识别和翻译的比较实验，我们证明了Bug的存在并不会妨碍获得良好的和可重复的结果，反而可能导致不正确的结论，为未来的研究可能提供错误的指导。为了应对这一问题，这项研究呼吁采用旨在促进NLP研究中正确性的编码最佳实践，并提高实验结果的可靠性。

    Despite its pivotal role in research experiments, code correctness is often presumed only on the basis of the perceived quality of the results. This comes with the risk of erroneous outcomes and potentially misleading findings. To address this issue, we posit that the current focus on result reproducibility should go hand in hand with the emphasis on coding best practices. We bolster our call to the NLP community by presenting a case study, in which we identify (and correct) three bugs in widely used open-source implementations of the state-of-the-art Conformer architecture. Through comparative experiments on automatic speech recognition and translation in various language settings, we demonstrate that the existence of bugs does not prevent the achievement of good and reproducible results and can lead to incorrect conclusions that potentially misguide future research. In response to this, this study is a call to action toward the adoption of coding best practices aimed at fostering cor
    
[^50]: 合作多智能体任务中学习奖励机制

    Learning Reward Machines in Cooperative Multi-Agent Tasks. (arXiv:2303.14061v1 [cs.AI])

    [http://arxiv.org/abs/2303.14061](http://arxiv.org/abs/2303.14061)

    本文提出了一种新的多智能体强化学习方法，将合作任务分解与学习奖励机制相结合。该方法有助于解决部分可观察环境中奖励的非马尔可夫性质，并提高了学习策略的可解释性，同时也降低了合作任务的复杂性。

    

    本文提出了一种新颖的多智能体强化学习方法，将合作任务分解与学习奖励机制相结合，以编码子任务的结构。该方法有助于应对部分观测环境中奖励的非马尔可夫性质，并提高所学习的策略的可解释性，以完成合作任务。与每个子任务相关联的奖励机制是以分散的方式学习的，然后用于指导每个智能体的行为。通过这样做，合作任务的复杂性得到了降低，从而更有效地学习。结果表明，我们的方法是未来在多智能体强化学习研究中的一个有 promising 的方向，特别是在具有大状态空间和多个智能体的复杂环境中。

    This paper presents a novel approach to Multi-Agent Reinforcement Learning (MARL) that combines cooperative task decomposition with the learning of reward machines (RMs) encoding the structure of the sub-tasks. The proposed method helps deal with the non-Markovian nature of the rewards in partially observable environments and improves the interpretability of the learnt policies required to complete the cooperative task. The RMs associated with each sub-task are learnt in a decentralised manner and then used to guide the behaviour of each agent. By doing so, the complexity of a cooperative multi-agent problem is reduced, allowing for more effective learning. The results suggest that our approach is a promising direction for future research in MARL, especially in complex environments with large state spaces and multiple agents.
    
[^51]: 大型语言模型生成混合代码文本的提示：东南亚语言的案例

    Prompting Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages. (arXiv:2303.13592v1 [cs.CL])

    [http://arxiv.org/abs/2303.13592](http://arxiv.org/abs/2303.13592)

    本文探讨了使用大型语言模型（LLMs）生成东南亚五种语言和Singlish的混合代码数据的方法，发现ChatGPT展现出最高的潜力。然而，由于词汇选择错误的影响，ChatGPT和InstructGPT在生成混合代码时的熟练程度受到限制。

    

    尽管混合代码在世界许多地区是一种常见的语言实践，但收集高质量且低成本的混合代码数据仍然是自然语言处理（NLP）研究的重大挑战。最近大型语言模型（LLMs）的普及迫使人们问：这些系统能用于数据生成吗？在本文中，我们探讨了在一个零-shot的方式下如何提示LLMs为东南亚（SEA）的五种语言（印尼语，马来语，中文，塔加路语，越南语）及克里奥尔语S ingl ish创造混合代码数据。我们发现，ChatGPT显示出最大的潜力，当明确定义“混合代码”术语时，能够68%的时间生成混合代码文本。此外，ChatGPT和InstructGPT（davinci-003）生成S ingl ish文本的表现也值得注意，它们在各种提示下的成功率平均为96%。但是，ChatGPT和InstructGPT的混合代码熟练程度受到词汇选择错误的影响，导致语义不正确的输出。

    While code-mixing is a common linguistic practice in many parts of the world, collecting high-quality and low-cost code-mixed data remains a challenge for natural language processing (NLP) research. The proliferation of Large Language Models (LLMs) in recent times compels one to ask: can these systems be used for data generation? In this article, we explore prompting LLMs in a zero-shot manner to create code-mixed data for five languages in South East Asia (SEA) -Indonesian, Malay, Chinese, Tagalog, Vietnamese, as well as the creole language Singlish. We find that ChatGPT shows the most potential, capable of producing code-mixed text 68% of the time when the term "code-mixing" is explicitly defined. Moreover, both ChatGPT and InstructGPT's (davinci-003) performances in generating Singlish texts are noteworthy, averaging a 96% success rate across a variety of prompts. The code-mixing proficiency of ChatGPT and InstructGPT, however, is dampened by word choice errors that lead to semant
    
[^52]: 大型语言模型的公正引导少样本提示

    Fairness-guided Few-shot Prompting for Large Language Models. (arXiv:2303.13217v1 [cs.CL])

    [http://arxiv.org/abs/2303.13217](http://arxiv.org/abs/2303.13217)

    本文提出了一种新的搜索策略-FairPrompt，在保证公正性的前提下，通过评估提示预测偏差，确定近似最优的提示，从而改进大型语言模型的上下文学习性能，实验表明该方法在准确性和公正性方面均优于现有方法。

    

    大型语言模型已经表现出惊人的能力，能够通过几个输入输出示例构建的提示进行直接应用来解决众多下游任务。但是，先前的研究表明，由于训练示例，示例顺序和提示格式的变化导致上下文学习容易出现高度不稳定性。因此，构建适当的提示对于改进上下文学习的性能至关重要。在这篇文章中，我们从预测偏差的角度重新探讨了这个问题。具体而言，我们引入了一个指标来评估固定提示相对于标签或给定属性的预测偏差。然后我们通过实验证明了预测偏差较大的提示总是导致不令人满意的预测质量。基于这个观察，我们提出了一种新的搜索策略，基于贪婪搜索来确定近似最优的提示，从而改进上下文学习的性能。我们提出的方法叫做"公正提示"，其中融入了公平性约束，以指导搜索不展现出对某些人群的偏见。我们在多种少样本分类任务上证明了FairPrompt的有效性，并展示了它在准确性和公正性方面均优于现有的最先进方法。

    Large language models have demonstrated surprising ability to perform in-context learning, i.e., these models can be directly applied to solve numerous downstream tasks by conditioning on a prompt constructed by a few input-output examples. However, prior research has shown that in-context learning can suffer from high instability due to variations in training examples, example order, and prompt formats. Therefore, the construction of an appropriate prompt is essential for improving the performance of in-context learning. In this paper, we revisit this problem from the view of predictive bias. Specifically, we introduce a metric to evaluate the predictive bias of a fixed prompt against labels or a given attributes. Then we empirically show that prompts with higher bias always lead to unsatisfactory predictive quality. Based on this observation, we propose a novel search strategy based on the greedy search to identify the near-optimal prompt for improving the performance of in-context l
    
[^53]: 基于百万用户的现实世界互动来奖励聊天机器人

    Rewarding Chatbots for Real-World Engagement with Millions of Users. (arXiv:2303.06135v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2303.06135](http://arxiv.org/abs/2303.06135)

    本文研究了如何通过利用用户反馈来提高聊天机器人的参与度，从而增强其留存能力。具体方法是使用自动伪标签来训练奖励模型，并使用平均对话长度一类的指标来衡量其效果。在试验中，该方法可将聊天机器人的平均对话长度提高70%。

    

    预先训练的大型语言模型的出现，导致部署了一系列的社交聊天机器人。虽然这些聊天机器人展示了其语言能力和流畅性，但它们并不能保证很有吸引力，很容易失去用户。本文研究了开发优先考虑用户参与度以增强留存的社交聊天机器人，具体探讨了使用人工反馈以高效地开发高度有吸引力的聊天机器人。提出的方法使用从用户交互中收集的自动伪标签来训练奖励模型，该模型可用于在推理时拒绝低得分的样本响应，以提高用户参与度。引入了直观的评估指标，例如平均对话长度（MCL），作为衡量已部署聊天机器人参与度水平的代理。在Chai Research平台上对每日的10,000个新聊天机器人用户进行A/B测试，结果表明，这种方法可使MCL增加70％，这相当于将留存时间延长1.5倍。

    The emergence of pretrained large language models has led to the deployment of a range of social chatbots for chitchat. Although these chatbots demonstrate language ability and fluency, they are not guaranteed to be engaging and can struggle to retain users. This work investigates the development of social chatbots that prioritize user engagement to enhance retention, specifically examining the use of human feedback to efficiently develop highly engaging chatbots. The proposed approach uses automatic pseudo-labels collected from user interactions to train a reward model that can be used to reject low-scoring sample responses generated by the chatbot model at inference time. Intuitive evaluation metrics, such as mean conversation length (MCL), are introduced as proxies to measure the level of engagement of deployed chatbots. A/B testing on groups of 10,000 new daily chatbot users on the Chai Research platform shows that this approach increases the MCL by up to 70%, which translates to a
    
[^54]: BO-Muse：一种用于加速实验设计的人工智能和人类专家的协作框架

    BO-Muse: A human expert and AI teaming framework for accelerated experimental design. (arXiv:2303.01684v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.01684](http://arxiv.org/abs/2303.01684)

    BO-Muse是一种新的人工智能和人类专家协作的优化方法，它让人类专家发挥主导作用，通过注入新颖性并发现弱点来打破过度开发，以加速实验设计。

    

    本文介绍了BO-Muse，一种新的人工智能和人类专家协作的方法，用于优化昂贵的黑盒函数。受到从专家知识中提取和蒸馏回AI模型的内在困难以及对真实世界实验设计中人类行为的观察的启发，我们的算法让人类专家在实验过程中发挥主导作用。人类专家可以充分利用他们的领域专业知识，而人工智能则扮演着灵感的角色，在寻找弱点的同时注入新颖性，从而打破由认知融入引起的过度开发。在温和的假设下，我们证明了我们的算法亚线性收敛，速度快于单独使用人工智能或人类专家。我们使用合成数据以及人类专家进行真实世界实验来验证我们的算法。

    In this paper we introduce BO-Muse, a new approach to human-AI teaming for the optimization of expensive black-box functions. Inspired by the intrinsic difficulty of extracting expert knowledge and distilling it back into AI models and by observations of human behavior in real-world experimental design, our algorithm lets the human expert take the lead in the experimental process. The human expert can use their domain expertise to its full potential, while the AI plays the role of a muse, injecting novelty and searching for areas of weakness to break the human out of over-exploitation induced by cognitive entrenchment. With mild assumptions, we show that our algorithm converges sub-linearly, at a rate faster than the AI or human alone. We validate our algorithm using synthetic data and with human experts performing real-world experiments.
    
[^55]: 以ELBOs的加权积分理解扩散目标

    Understanding the Diffusion Objective as a Weighted Integral of ELBOs. (arXiv:2303.00848v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.00848](http://arxiv.org/abs/2303.00848)

    本文深入理解了扩散目标，并揭示了加权损失和ELBO目标之间的直接关系。

    

    文献中的扩散模型采用不同的目标进行优化，并且这些目标都是加权损失的特例，其中加权函数指定每个噪声级别的权重。均匀加权对应于最大似然的原则性近似ELBO的最大化。但是实际上，由于更好的样本质量，目前的扩散模型使用非均匀加权。本文揭示了加权损失（带有任何加权）和ELBO目标之间的直接关系。我们展示了加权损失可以被写成一种ELBOs的加权积分形式，其中每个噪声级别都有一个ELBO。如果权重函数是单调的，那么加权损失是一种基于似然的目标：它在简单的数据增强下（即高斯噪声扰动）下最大化ELBO。我们的主要贡献是更深入地理解了扩散目标，但我们还进行了一些比较单调和非单调权重的实验。

    Diffusion models in the literature are optimized with various objectives that are special cases of a weighted loss, where the weighting function specifies the weight per noise level. Uniform weighting corresponds to maximizing the ELBO, a principled approximation of maximum likelihood. In current practice diffusion models are optimized with non-uniform weighting due to better results in terms of sample quality. In this work we expose a direct relationship between the weighted loss (with any weighting) and the ELBO objective.  We show that the weighted loss can be written as a weighted integral of ELBOs, with one ELBO per noise level. If the weighting function is monotonic, then the weighted loss is a likelihood-based objective: it maximizes the ELBO under simple data augmentation, namely Gaussian noise perturbation. Our main contribution is a deeper theoretical understanding of the diffusion objective, but we also performed some experiments comparing monotonic with non-monotonic weight
    
[^56]: CitySpec with Shield：安全的智能助手实现需求规范化

    CitySpec with Shield: A Secure Intelligent Assistant for Requirement Formalization. (arXiv:2302.09665v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.09665](http://arxiv.org/abs/2302.09665)

    CitySpec with Shield是一种安全的智能助手，用于帮助城市决策者将人类指定的需求转换为监测系统可理解的形式。

    

    智能城市中需要开发越来越多的监测系统来确保城市的实时运营达到安全和性能的要求。然而，许多现有的城市要求都是用英语编写的，存在缺失、不准确或模糊的信息。为了解决这一局限，我们构建了CitySpec，这是智能城市需求规格化的第一个智能辅助系统。

    An increasing number of monitoring systems have been developed in smart cities to ensure that the real-time operations of a city satisfy safety and performance requirements. However, many existing city requirements are written in English with missing, inaccurate, or ambiguous information. There is a high demand for assisting city policymakers in converting human-specified requirements to machine-understandable formal specifications for monitoring systems. To tackle this limitation, we build CitySpec, the first intelligent assistant system for requirement specification in smart cities. To create CitySpec, we first collect over 1,500 real-world city requirements across different domains (e.g., transportation and energy) from over 100 cities and extract city-specific knowledge to generate a dataset of city vocabulary with 3,061 words. We also build a translation model and enhance it through requirement synthesis and develop a novel online learning framework with shielded validation. The e
    
[^57]: 为验证大规模神经网络的几何鲁棒性迈进

    Towards Verifying the Geometric Robustness of Large-scale Neural Networks. (arXiv:2301.12456v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12456](http://arxiv.org/abs/2301.12456)

    本文提出了一种名为GeoRobust的黑盒鲁棒性分析器，旨在对大规模神经网络进行多个几何变换的鲁棒性验证，并且无论网络的体系结构、激活函数和神经元数量如何，GeoRobust都能够提供高精度的最坏情况的变换组合。

    

    深度神经网络(DNNs)已知对抗性几何变换易受攻击。本文旨在通过可证明的保证来验证大规模DNNs对多个几何变换的鲁棒性。我们开发了GeoRobust，一个基于新型全局优化策略的黑盒子鲁棒性分析器，用于定位影响甚至改变网络输出的最坏变换组合。 GeoRobust可以根据Lipschitzian理论的最新进展，提供找到最坏情况组合的可证明保证。由于其黑盒子性质，GeoRobust可以部署在大规模DNNs上，无论它们的体系结构、激活函数和神经元数量如何。实际上，GeoRobust可以在几秒钟内以高精度定位ImageNet上ResNet50模型的最坏几何变换。

    Deep neural networks (DNNs) are known to be vulnerable to adversarial geometric transformation. This paper aims to verify the robustness of large-scale DNNs against the combination of multiple geometric transformations with a provable guarantee. Given a set of transformations (e.g., rotation, scaling, etc.), we develop GeoRobust, a black-box robustness analyser built upon a novel global optimisation strategy, for locating the worst-case combination of transformations that affect and even alter a network's output. GeoRobust can provide provable guarantees on finding the worst-case combination based on recent advances in Lipschitzian theory. Due to its black-box nature, GeoRobust can be deployed on large-scale DNNs regardless of their architectures, activation functions, and the number of neurons. In practice, GeoRobust can locate the worst-case geometric transformation with high precision for the ResNet50 model on ImageNet in a few seconds on average. We examined 18 ImageNet classifiers
    
[^58]: 具有联合嵌入预测架构的图像自监督学习

    Self-Supervised Learning from Images with a Joint-Embedding Predictive Architecture. (arXiv:2301.08243v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.08243](http://arxiv.org/abs/2301.08243)

    本论文提出了一种非生成方法的自监督学习架构，即Image-based Joint-Embedding Predictive Architecture（I-JEPA），可以生成高度语义图像表示，通过联合嵌入预测架构和掩模策略达到这一目的。

    

    本论文提出了一种在不依赖手工制作数据增强的情况下学习高度语义图像表示的方法。我们介绍了基于图像的联合嵌入预测架构（I-JEPA），这是一种从图像中进行自我监督学习的非生成方法。I-JEPA的核心设计选择是掩模策略，以引导I-JEPA产生语义表示。当与Vision Transformers结合使用时，证明I-JEPA具有高度可扩展性。

    This paper demonstrates an approach for learning highly semantic image representations without relying on hand-crafted data-augmentations. We introduce the Image-based Joint-Embedding Predictive Architecture (I-JEPA), a non-generative approach for self-supervised learning from images. The idea behind I-JEPA is simple: from a single context block, predict the representations of various target blocks in the same image. A core design choice to guide I-JEPA towards producing semantic representations is the masking strategy; specifically, it is crucial to (a) sample target blocks with sufficiently large scale (semantic), and to (b) use a sufficiently informative (spatially distributed) context block. Empirically, when combined with Vision Transformers, we find I-JEPA to be highly scalable. For instance, we train a ViT-Huge/14 on ImageNet using 16 A100 GPUs in under 72 hours to achieve strong downstream performance across a wide range of tasks, from linear classification to object counting a
    
[^59]: 使用采样算法估计量子玻色系统的截断效应

    Estimating truncation effects of quantum bosonic systems using sampling algorithms. (arXiv:2212.08546v2 [quant-ph] UPDATED)

    [http://arxiv.org/abs/2212.08546](http://arxiv.org/abs/2212.08546)

    本文提出了一种使用传统采样方法估计量子玻色系统截断误差的方法，该方法可用于估计实际量子模拟玻色理论所需的资源，并检查对应量子模拟的结果的有效性。

    

    要在基于量子比特或量子位的量子计算机上模拟玻色子，必须通过将无限维局部希尔伯特空间截断为有限维来规范理论。在寻求实际量子应用的过程中，了解截断误差有多大非常重要。通常情况下，除非我们拥有好的量子计算机，否则很难估计误差。本文表明，传统的经典设备采样方法，具体而言是马尔科夫链蒙特卡罗方法可以用现有合理的计算资源解决这个问题。我们以二维格点上的标量场理论为例演示了这个想法，其大小超过了使用确切对角化方法所能达到的范围。这种方法可用于估计实际量子模拟玻色理论所需的资源，并检查对应量子模拟的结果的有效性。

    To simulate bosons on a qubit- or qudit-based quantum computer, one has to regularize the theory by truncating infinite-dimensional local Hilbert spaces to finite dimensions. In the search for practical quantum applications, it is important to know how big the truncation errors can be. In general, it is not easy to estimate errors unless we have a good quantum computer. In this paper we show that traditional sampling methods on classical devices, specifically Markov Chain Monte Carlo, can address this issue with a reasonable amount of computational resources available today. As a demonstration, we apply this idea to the scalar field theory on a two-dimensional lattice, with a size that goes beyond what is achievable using exact diagonalization methods. This method can be used to estimate the resources needed for realistic quantum simulations of bosonic theories, and also, to check the validity of the results of the corresponding quantum simulations.
    
[^60]: DATID-3D: 基于文本图像扩散的多样性保留领域自适应方法应用于3D生成模型

    DATID-3D: Diversity-Preserved Domain Adaptation Using Text-to-Image Diffusion for 3D Generative Model. (arXiv:2211.16374v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.16374](http://arxiv.org/abs/2211.16374)

    本文提出一种基于文本图像扩散的多样性保留领域自适应方法，用于解决3D生成模型在多种不同领域的训练挑战，该方法应用于将2D生成模型转化为其它风格的领域模型，通过CLIP学习文本和图像之间的关系。

    

    近期的3D生成模型在合成高分辨率逼真图像且保持视角一致性和详细的三维形状方面已经取得了显著的成果，但在多种不同领域的训练上仍然具有挑战性，因为需要大量的训练图像及其相机分布信息。指导文本信息的领域自适应方法通过利用CLIP（Contrastive Language-Image Pre-training）将一个2D生成模型转换为具有不同风格的其他领域模型，而不需要收集这些领域的大量数据集。然而，它们的一个缺点是由于CLIP文本编码器的确定性，原始生成模型中的样本多样性在领域适应生成模型中并没有得到很好的保留。对3D生成模型进行指导文本信息的领域自适应不仅由于灾难性多样性损失的原因，还由于图像和文本之间的对应关系不佳而更加具有挑战性。

    Recent 3D generative models have achieved remarkable performance in synthesizing high resolution photorealistic images with view consistency and detailed 3D shapes, but training them for diverse domains is challenging since it requires massive training images and their camera distribution information. Text-guided domain adaptation methods have shown impressive performance on converting the 2D generative model on one domain into the models on other domains with different styles by leveraging the CLIP (Contrastive Language-Image Pre-training), rather than collecting massive datasets for those domains. However, one drawback of them is that the sample diversity in the original generative model is not well-preserved in the domain-adapted generative models due to the deterministic nature of the CLIP text encoder. Text-guided domain adaptation will be even more challenging for 3D generative models not only because of catastrophic diversity loss, but also because of inferior text-image corresp
    
[^61]: 利用自注意力指导提高扩散模型的样本质量

    Improving Sample Quality of Diffusion Models Using Self-Attention Guidance. (arXiv:2210.00939v5 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.00939](http://arxiv.org/abs/2210.00939)

    该论文提出了一种利用自注意力指导的策略来提升扩散模型生成图像的稳定性和质量，具有较高的实用价值。

    

    去噪扩散模型以其出色的生成质量和多样性受到关注。这种成功很大程度上归因于使用分类或文本条件的扩散指导方法，如分类器和无分类器指导。在本文中，我们提出了一个更全面的视角，超越了传统的指导方法。从这个广义的视角出发，我们引入了新的无条件和无监督的策略来提高生成图像的质量。作为一种简单的解决方案，模糊指导改善了中间样本的适用性，使得扩散模型能够以适度的指导尺度生成更高质量的样本。在此基础上，自注意力指导（SAG）利用了扩散模型的中间自注意力映射来增强它们的稳定性和效果。具体而言，SAG在每次迭代中仅对扩散模型关注的区域进行对抗性模糊处理。

    Denoising diffusion models (DDMs) have attracted attention for their exceptional generation quality and diversity. This success is largely attributed to the use of class- or text-conditional diffusion guidance methods, such as classifier and classifier-free guidance. In this paper, we present a more comprehensive perspective that goes beyond the traditional guidance methods. From this generalized perspective, we introduce novel condition- and training-free strategies to enhance the quality of generated images. As a simple solution, blur guidance improves the suitability of intermediate samples for their fine-scale information and structures, enabling diffusion models to generate higher quality samples with a moderate guidance scale. Improving upon this, Self-Attention Guidance (SAG) uses the intermediate self-attention maps of diffusion models to enhance their stability and efficacy. Specifically, SAG adversarially blurs only the regions that diffusion models attend to at each iteratio
    
[^62]: 通过后门水印的黑盒数据集所有权验证

    Black-box Dataset Ownership Verification via Backdoor Watermarking. (arXiv:2209.06015v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2209.06015](http://arxiv.org/abs/2209.06015)

    本文提出了一种通过后门水印技术验证已发布数据集的所有权的方法，以检测其是否被用于训练（可疑的）第三方模型。

    

    深度学习，特别是深度神经网络（DNNs），由于其高效性和高效性，在许多重要应用中被广泛且成功地采用。DNN的快速发展受益于一些高质量数据集（例如ImageNet）的存在，这些数据集允许研究人员和开发者轻松验证其方法的性能。目前，几乎所有现有的已发布数据集都要求它们仅能用于学术或教育目的而非商业目的，但仍然没有很好的方法来确保这一点。在本文中，我们将保护已发布数据集的形式化为验证它们是否被用于训练（可疑的）第三方模型，而防御者只能查询模型，而没有关于其参数和训练细节的信息。

    Deep learning, especially deep neural networks (DNNs), has been widely and successfully adopted in many critical applications for its high effectiveness and efficiency. The rapid development of DNNs has benefited from the existence of some high-quality datasets ($e.g.$, ImageNet), which allow researchers and developers to easily verify the performance of their methods. Currently, almost all existing released datasets require that they can only be adopted for academic or educational purposes rather than commercial purposes without permission. However, there is still no good way to ensure that. In this paper, we formulate the protection of released datasets as verifying whether they are adopted for training a (suspicious) third-party model, where defenders can only query the model while having no information about its parameters and training details. Based on this formulation, we propose to embed external patterns via backdoor watermarking for the ownership verification to protect them. 
    
[^63]: 基于神经网络的无约束音频拼接检测与定位方法研究

    Towards Unconstrained Audio Splicing Detection and Localization with Neural Networks. (arXiv:2207.14682v3 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2207.14682](http://arxiv.org/abs/2207.14682)

    研究提出了一种基于 Transformer 序列到序列（seq2seq）网络的音频拼接检测与定位方法，能够在各种攻击场景中准确检测出拼接并定位，具有普适性和鲁棒性。

    

    容易获取且易于使用的音频编辑工具使得音频拼接变得简单。可通过组合同一人的各种语音样本来创建令人信服的伪造品。检测此类拼接在公共领域中考虑到虚假信息甚至在法律背景下核实证据的完整性都至关重要。然而，大多数现有的音频拼接检测算法使用手工制作的特征并做出了特定的假设。但是，刑事调查人员通常面临来自未知来源具有未知特征的音频样本，这引发了对更普适的方法的需求。本文旨在朝着无约束音频拼接检测方向迈出第一步以满足这一需求。我们通过各种攻击形式的后处理操作来模拟不同的攻击场景，可能掩盖拼接存在。我们提出了一种基于 Transformer 序列到序列（seq2seq）网络用于拼接检测和定位。我们广泛的实验表明所提出的方法优于几种最先进的方法，能够检测和定位甚至存在强烈失真和背景噪声的拼接。

    Freely available and easy-to-use audio editing tools make it straightforward to perform audio splicing. Convincing forgeries can be created by combining various speech samples from the same person. Detection of such splices is important both in the public sector when considering misinformation, and in a legal context to verify the integrity of evidence. Unfortunately, most existing detection algorithms for audio splicing use handcrafted features and make specific assumptions. However, criminal investigators are often faced with audio samples from unconstrained sources with unknown characteristics, which raises the need for more generally applicable methods.  With this work, we aim to take a first step towards unconstrained audio splicing detection to address this need. We simulate various attack scenarios in the form of post-processing operations that may disguise splicing. We propose a Transformer sequence-to-sequence (seq2seq) network for splicing detection and localization. Our exte
    
[^64]: 终身学习的持续评估：识别稳定性差距。

    Continual evaluation for lifelong learning: Identifying the stability gap. (arXiv:2205.13452v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.13452](http://arxiv.org/abs/2205.13452)

    终身学习中，时间相关的数据生成分布对神经网络的梯度训练具有困难性。一些最先进的方法在开始学习新任务时会存在轻微的遗忘，随后会有一段性能恢复的阶段跟随，我们称之为“稳定性差距”。

    

    时间相关的数据生成分布已被证明对神经网络的梯度训练是困难的，因为贪婪的更新会导致以前学习的知识灾难性地被遗忘。尽管终身学习领域已经取得了一定进展以克服这种遗忘，但我们发现一组常见的最先进的方法在开始学习新任务时仍然存在严重遗忘，只是这种遗忘是暂时的，会被一段性能恢复的阶段所跟随。我们将这种有趣但潜在有问题的现象称为稳定性差距。由于终身学习模型评估领域仅在每个任务之后进行评估的标准做法，因此稳定性差距可能仍然未被发现。而我们则建立了一个终身评估框架，使用每次迭代的评估，并定义了一组新的指标来量化最坏情况下的性能。实证结果显示，经验回放、基于约束的回放、知识_distillation和_expansion都存在稳定性差距。

    Time-dependent data-generating distributions have proven to be difficult for gradient-based training of neural networks, as the greedy updates result in catastrophic forgetting of previously learned knowledge. Despite the progress in the field of continual learning to overcome this forgetting, we show that a set of common state-of-the-art methods still suffers from substantial forgetting upon starting to learn new tasks, except that this forgetting is temporary and followed by a phase of performance recovery. We refer to this intriguing but potentially problematic phenomenon as the stability gap. The stability gap had likely remained under the radar due to standard practice in the field of evaluating continual learning models only after each task. Instead, we establish a framework for continual evaluation that uses per-iteration evaluation and we define a new set of metrics to quantify worst-case performance. Empirically we show that experience replay, constraint-based replay, knowledg
    
[^65]: HIT-UAV：面向无人机目标检测的高空红外热数据集

    HIT-UAV: A high-altitude infrared thermal dataset for Unmanned Aerial Vehicle-based object detection. (arXiv:2204.03245v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2204.03245](http://arxiv.org/abs/2204.03245)

    HIT-UAV是一个高空红外热数据集，用于无人机目标检测，包括2898个图像和飞行数据，手动注释了定向和标准边界框。此数据集是公开的、首个用于检测人和车辆的高空无人机红外热数据集。

    

    本文介绍了HIT-UAV数据集，这是一个面向无人机目标检测应用的高空红外热数据集。该数据集包括2898个红外热图像，这些图像来自于数百个无人机在各种场景中拍摄的43470帧视频。此外，HIT-UAV还提供了每个图像的关键飞行数据，例如飞行高度、相机视角、日期和日光强度。对于每个图像，我们手动注释了两种类型（定向和标准）的边界框，以解决空中图像中物体实例重叠的难题。据我们所知，HIT-UAV是第一个公开的高空无人机红外热数据集用于检测人和车辆。我们在HIT-UAV上训练和评估了一些知名的目标检测算法，结果表明这些检测算法表现良好。

    We present the HIT-UAV dataset, a high-altitude infrared thermal dataset for object detection applications on Unmanned Aerial Vehicles (UAVs). The dataset comprises 2,898 infrared thermal images extracted from 43,470 frames in hundreds of videos captured by UAVs in various scenarios including schools, parking lots, roads, and playgrounds. Moreover, the HIT-UAV provides essential flight data for each image, such as flight altitude, camera perspective, date, and daylight intensity. For each image, we have manually annotated object instances with bounding boxes of two types (oriented and standard) to tackle the challenge of significant overlap of object instances in aerial images. To the best of our knowledge, the HIT-UAV is the first publicly available high-altitude UAV-based infrared thermal dataset for detecting persons and vehicles. We have trained and evaluated well-established object detection algorithms on the HIT-UAV. Our results demonstrate that the detection algorithms perform e
    
[^66]: 从自然语言到模拟：应用GPT-3 Codex自动化物流系统模拟建模

    From Natural Language to Simulations: Applying GPT-3 Codex to Automate Simulation Modeling of Logistics Systems. (arXiv:2202.12107v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2202.12107](http://arxiv.org/abs/2202.12107)

    该论文展示了自然语言处理的自动化能力应用到物流系统模拟建模中，证明了基于GPT-3 Codex的框架能够生成功能有效的排队和库存控制系统的模拟模型，为简化模拟模型开发工作流程开启了重要大门。

    

    本文是首次尝试使用自然语言处理自动化开发物流系统模拟模型。我们证明了在基于经过微调的GPT-3 Codex的框架上能够根据口头描述生成功能有效的排队和库存控制系统模拟模型。在所进行的实验中，GPT-3 Codex展现出对Python编程的深厚技能以及对行业特定词汇的理解。结果，该语言模型能够在给定行业特定场景下，根据流程说明和变量值列表生成单品库存控制系统和单服务器排队系统的模拟模型。这些结果的呈现，以及语言模型持续的迅速进步，打开了简化模拟模型开发工作流程的重要大门，这将有助于加快自动化物流系统的部署。

    Our work is the first attempt to apply Natural Language Processing to automate the development of simulation models of systems vitally important for logistics. We demonstrated that the framework built on top of the fine-tuned GPT-3 Codex, a Transformer-based language model, could produce functionally valid simulations of queuing and inventory control systems given the verbal description. In conducted experiments, GPT-3 Codex demonstrated convincing expertise in Python as well as an understanding of the domain-specific vocabulary. As a result, the language model could produce simulations of a single-product inventory-control system and single-server queuing system given the domain-specific context, a detailed description of the process, and a list of variables with the corresponding values. The demonstrated results, along with the rapid improvement of language models, open the door for significant simplification of the workflow behind the simulation model development, which will allow e
    
[^67]: VRL3：一种用于视觉深度强化学习的数据驱动框架

    VRL3: A Data-Driven Framework for Visual Deep Reinforcement Learning. (arXiv:2202.10324v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2202.10324](http://arxiv.org/abs/2202.10324)

    本文提出VRL3，一种数据驱动的框架，可用于解决具有挑战性的视觉深度强化学习任务。该框架包含三个阶段，并能在具有稀疏奖励和逼真视觉输入的手部操纵任务中显著提高样本效率。

    

    本文提出了VRL3，这是一个采用简单设计解决具有挑战性的视觉深度强化学习（DRL）任务的强大数据驱动框架。作者分析了采用数据驱动方法的主要障碍，并提出了一系列的设计原则、新的发现和关于数据驱动视觉DRL的关键见解。该框架包括三个阶段：在第一阶段，作者利用非RL数据集（例如ImageNet）来学习任务无关的视觉表示；在第二阶段，作者利用离线RL数据（例如有限数量的专家演示）将任务无关的表示转化为更强大的任务特定的表示；在第三阶段，作者通过在线RL对智能体进行微调。在一组具有稀疏奖励和逼真视觉输入的挑战性手部操纵任务中，与之前的SOTA相比，VRL3的样本效率平均提高了780%。在最难的任务上，VRL3的样本效率提高了1220%（使用更宽的编码器，提高到2440%），并以超过SOTA的性能解决了该任务。

    We propose VRL3, a powerful data-driven framework with a simple design for solving challenging visual deep reinforcement learning (DRL) tasks. We analyze a number of major obstacles in taking a data-driven approach, and present a suite of design principles, novel findings, and critical insights about data-driven visual DRL. Our framework has three stages: in stage 1, we leverage non-RL datasets (e.g. ImageNet) to learn task-agnostic visual representations; in stage 2, we use offline RL data (e.g. a limited number of expert demonstrations) to convert the task-agnostic representations into more powerful task-specific representations; in stage 3, we fine-tune the agent with online RL. On a set of challenging hand manipulation tasks with sparse reward and realistic visual inputs, compared to the previous SOTA, VRL3 achieves an average of 780% better sample efficiency. And on the hardest task, VRL3 is 1220% more sample efficient (2440% when using a wider encoder) and solves the task with on
    
[^68]: 不完美信息博弈中的近似最优学习

    Near-Optimal Learning of Extensive-Form Games with Imperfect Information. (arXiv:2202.01752v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.01752](http://arxiv.org/abs/2202.01752)

    本文提出了一种新的算法系列，可以更快速地在不完美信息广义博弈中找到一个近似最优解。

    

    本文解决了学习不完美信息广义博弈的近似最优算法设计的开放性问题。我们提出了第一种算法系列，仅需要 $\widetilde{\mathcal{O}}((XA+YB)/\varepsilon^2)$ 局游戏即可在两人零和博弈中找到一个 $\varepsilon$-近似纳什均衡，其中 $X,Y$ 是信息集的数量，$A,B$ 是两名玩家的行动数。这比已知的样本复杂度 $\widetilde{\mathcal{O}}((X^2A+Y^2B)/\varepsilon^2)$ 有着 $\widetilde{\mathcal{O}}(\max\{X, Y\})$ 的巨大改进，并且在对数因子内与信息理论下限一致。我们通过两种新算法实现了这种样本复杂度：平衡在线镜面下降和平衡反事实后悔最小化。这两种算法都依赖于将“平衡探索策略”集成到它们的经典对手中的新方法。此外，我们还将我们的结果扩展到了更广泛的支持不完美信息博弈的二人博弈和多人博弈中。

    This paper resolves the open question of designing near-optimal algorithms for learning imperfect-information extensive-form games from bandit feedback. We present the first line of algorithms that require only $\widetilde{\mathcal{O}}((XA+YB)/\varepsilon^2)$ episodes of play to find an $\varepsilon$-approximate Nash equilibrium in two-player zero-sum games, where $X,Y$ are the number of information sets and $A,B$ are the number of actions for the two players. This improves upon the best known sample complexity of $\widetilde{\mathcal{O}}((X^2A+Y^2B)/\varepsilon^2)$ by a factor of $\widetilde{\mathcal{O}}(\max\{X, Y\})$, and matches the information-theoretic lower bound up to logarithmic factors. We achieve this sample complexity by two new algorithms: Balanced Online Mirror Descent, and Balanced Counterfactual Regret Minimization. Both algorithms rely on novel approaches of integrating \emph{balanced exploration policies} into their classical counterparts. We also extend our results t
    
[^69]: 自动学术论文审稿：概念、技术与挑战。

    Automated scholarly paper review: Concepts, technologies, and challenges. (arXiv:2111.07533v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2111.07533](http://arxiv.org/abs/2111.07533)

    提出自动学术论文审稿（ASPR）的概念和流程，综述了实现全面计算机化审稿流程的相关文献和技术，同时指出实现中存在的挑战，如文档解析和表达不完美、数据不足、人机交互缺陷和发现低质量文章的难度。

    

    同行评审是研究评价的广泛接受机制，在学术出版中扮演着重要的角色。然而，由于其效率低下和可重复性差，这一机制长期以来备受批评。近年来，人工智能应用于辅助同行评审。尽管如此，在涉及人员的情况下，这些限制仍是不可避免的。本文提出了自动学术论文审稿（ASPR）的概念和流程，并综述了实现全面计算机化审稿流程的相关文献和技术。在审查和讨论的基础上，我们得出结论：ASPR 的每个阶段已经有相应的研究和初步实施。我们还进一步探讨了ASPR存在的挑战。主要困难在于文档解析和表达不完美、数据不足、人机交互缺陷和发现低质量文章的难度。

    Peer review is a widely accepted mechanism for research evaluation, playing a pivotal role in academic publishing. However, criticisms have long been leveled on this mechanism, mostly because of its poor efficiency and low reproducibility. Recent years have seen the application of artificial intelligence (AI) in assisting the peer review process. Nonetheless, with the involvement of humans, such limitations remain inevitable. In this paper, we propose the concept and pipeline of automated scholarly paper review (ASPR) and review the relevant literature and technologies of achieving a full-scale computerized review process. On the basis of the review and discussion, we conclude that there is already corresponding research and preliminary implementation at each stage of ASPR. We further look into the challenges in ASPR with the existing technologies. The major difficulties lie in imperfect document parsing and representation, inadequate data, defective human-computer interaction, and fla
    
[^70]: 一步式诱导式多目标学习及其在乳腺癌肿瘤分割中的应用

    One-Step Abductive Multi-Target Learning with Diverse Noisy Samples and Its Application to Tumour Segmentation for Breast Cancer. (arXiv:2110.10325v9 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2110.10325](http://arxiv.org/abs/2110.10325)

    本论文提出了一种新的机器学习方法——一步式诱导式多目标学习与DiNS（OSAMTL-DiNS），以处理医学组织病理学全幻灯片图像分析中的复杂噪声标签。在乳腺癌肿瘤分割中得到了成功应用。

    

    近年来的研究表明，机器学习和逻辑推理的结合，包括数据驱动的逻辑推理、知识驱动的机器学习和诱导学习，在发明先进的人工智能技术方面具有很高的有效性。在医学组织病理学全幻灯片图像分析中，一步式诱导式多目标学习（OSAMTL），作为一种受诱导学习启发的方法，通过以一种平衡的方式简单地结合机器学习和逻辑推理，已经证明了其处理单个嘈杂标签的复杂噪声标签的有效性。但是，OSAMTL不适用于提供多种嘈杂样本（DiNS）的学习任务情况。在本文中，我们给出了DiNS的定义，并提出了一步式诱导式多目标学习与DiNS（OSAMTL-DiNS），以扩展原始的OSAMTL以处理DiNS的复杂噪声标签。将OSAMTL-DiNS应用于MHWSIA中的乳腺癌肿瘤分割中，我们展示了其有效性。

    Recent studies have demonstrated the effectiveness of the combination of machine learning and logical reasoning, including data-driven logical reasoning, knowledge driven machine learning and abductive learning, in inventing advanced artificial intelligence technologies. One-step abductive multi-target learning (OSAMTL), an approach inspired by abductive learning, via simply combining machine learning and logical reasoning in a one-step balanced way, has as well shown its effectiveness in handling complex noisy labels of a single noisy sample in medical histopathology whole slide image analysis (MHWSIA). However, OSAMTL is not suitable for the situation where diverse noisy samples (DiNS) are provided for a learning task. In this paper, giving definition of DiNS, we propose one-step abductive multi-target learning with DiNS (OSAMTL-DiNS) to expand the original OSAMTL to handle complex noisy labels of DiNS. Applying OSAMTL-DiNS to tumour segmentation for breast cancer in MHWSIA, we show 
    

