# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Accelerating Scalable Graph Neural Network Inference with Node-Adaptive Propagation.](http://arxiv.org/abs/2310.10998) | 本论文提出了一种在线传播框架和两种新的节点自适应传播方法，用于加速可扩展的图神经网络推论。这些方法能够根据节点的拓扑信息自定义每个节点的最佳传播深度，从而避免冗余特征传播，并通过简单的超参数灵活地管理准确性和延迟之间的权衡，以适应不同的延迟限制。 |
| [^2] | [From Complexity to Clarity: Analytical Expressions of Deep Neural Network Weights via Clifford's Geometric Algebra and Convexity.](http://arxiv.org/abs/2309.16512) | 本文通过Clifford的几何代数和凸优化，提出了一种分析深度神经网络的新方法。我们展示了深度ReLU神经网络的最优权重可以通过训练样本的楔积来获得，并且训练问题可以简化为对楔积特征进行凸优化，从而揭示了神经网络内部的几何结构。 |
| [^3] | [A Spectral Theory of Neural Prediction and Alignment.](http://arxiv.org/abs/2309.12821) | 该论文提出了一个光谱理论，用于理解神经预测和对齐问题。通过研究模型激活的光谱偏差和神经响应与可学习子空间的对齐情况，我们可以获得深度神经网络的几何属性，并区分在神经预测方面表现相同的模型。 |
| [^4] | [Talk2Care: Facilitating Asynchronous Patient-Provider Communication with Large-Language-Model.](http://arxiv.org/abs/2309.09357) | 本研究利用大型语言模型（LLMs）来促进患者和医生之间的异步通信，通过访谈研究了解了他们对LLMs的需求，并构建了一个名为Talk2Care的LLM驱动的通信系统。 |
| [^5] | [Characterizing Lipschitz Stability of GNN for Fairness.](http://arxiv.org/abs/2309.03648) | 论文通过研究GNN的Lipschitz界限表征了GNN对公平性稳定性的影响，尤其是在处理非欧几里得数据和固有偏倚的情况下。同时，该研究对于限制GNN输出的扰动以保障公平性训练提出了挑战。 |
| [^6] | [Detection of Unknown-Unknowns in Cyber-Physical Systems using Statistical Conformance with Physics Guided Process Models.](http://arxiv.org/abs/2309.02603) | 该论文提出了一个新的框架来分析安全关键的协同实体系统的操作输出特性的随机符合性，从而发现未知-未知情况并评估潜在的安全风险。 |
| [^7] | [Distributionally Robust Statistical Verification with Imprecise Neural Networks.](http://arxiv.org/abs/2308.14815) | 本文提出了一种使用不精确神经网络的分布鲁棒统计验证方法，通过结合主动学习、不确定性量化和神经网络验证，可以在大量的分布上提供对黑盒系统行为的保证。 |
| [^8] | [InstructME: An Instruction Guided Music Edit And Remix Framework with Latent Diffusion Models.](http://arxiv.org/abs/2308.14360) | InstructME是一个基于潜在扩散模型的指导音乐编辑和混音框架，通过多尺度聚合和引入和弦进展矩阵来保持编辑的一致性和提高旋律和谐性。 |
| [^9] | [INFLECT-DGNN: Influencer Prediction with Dynamic Graph Neural Networks.](http://arxiv.org/abs/2307.08131) | INFLECT-DGNN是一个结合了图神经网络和递归神经网络的框架，使用加权损失函数、针对图数据适应的合成少数过采样技术和滚动窗口策略，用于影响者预测。实验结果显示，使用RNN来编码时间属性和GNN显著提高了预测性能。 |
| [^10] | [Exploring AI-enhanced Shared Control for an Assistive Robotic Arm.](http://arxiv.org/abs/2306.13509) | 本文研究如何将人工智能集成到机械臂的共享控制范式中，以帮助运动受损人士实现更高程度的个人自治。 |
| [^11] | [DIFFender: Diffusion-Based Adversarial Defense against Patch Attacks.](http://arxiv.org/abs/2306.09124) | DIFFender是一种基于扩散的对抗性防御方法，通过定位和恢复两个阶段的操作，利用文本引导的扩散模型来防御对抗性Patch，从而提高其整体防御性能。 |
| [^12] | [Improving Offline-to-Online Reinforcement Learning with Q-Ensembles.](http://arxiv.org/abs/2306.06871) | 我们提出了一种名为Q-Ensembles的新框架，通过增加Q网络的数量，无缝地连接离线预训练和在线微调，同时不降低性能。此外，我们适当放宽Q值估计的悲观性，并将基于集合的探索机制融入我们的框架中，从而提升了离线到在线强化学习的性能。 |
| [^13] | [Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and GPT-4 for Cost-Efficient Question Answering.](http://arxiv.org/abs/2306.05036) | 本文探讨了 ChatGPT 和 GPT-4 两个大型语言模型在实际情况下的运用和性能表现，通过以人机交互领域的研究挑战为例，结论是 ChatGPT 和 GPT-4 的组合是分析文本语料库的一种非常高效且节省成本的方法。 |
| [^14] | [Understanding the Effectiveness of Early Weight Averaging for Training Large Language Models.](http://arxiv.org/abs/2306.03241) | 本文研究了使用早期权重平均化方法来提高大型语言模型质量的有效性，证明该方法可以加速收敛且测试和零样本泛化效果显著，同时有效缓解了训练中的损失波动问题。 |
| [^15] | [SPRING: GPT-4 Out-performs RL Algorithms by Studying Papers and Reasoning.](http://arxiv.org/abs/2305.15486) | SPRING是一个新的方法，能够在开放世界游戏中表现出色，它通过阅读游戏的原始学术论文并使用所学知识进行推理并玩游戏。。 |
| [^16] | [Time-Selective RNN for Device-Free Multi-Room Human Presence Detection Using WiFi CSI.](http://arxiv.org/abs/2304.13107) | 这篇论文提出了一种使用基于WiFi信道状态信息提取人体移动和空间特征的无设备多房间人体存在检测系统，能够通过时间-selective特征提取算法区分有直觉视线路径阻塞和无视线路径阻塞的情况。 |
| [^17] | [CornerFormer: Boosting Corner Representation for Fine-Grained Structured Reconstruction.](http://arxiv.org/abs/2304.07072) | CornerFormer是一种新的方法，它利用不同建模策略于单个模型中融合角点检测和边缘预测来提升精细结构重建的表现，并在挑战性的基准测试中取得了最好的结果。 |
| [^18] | [Bayesian Learning for the Robust Verification of Autonomous Robots.](http://arxiv.org/abs/2303.08476) | 本文提出了一种新框架，利用贝叶斯学习方法对验证机器人系统的先验知识和观测数据进行处理，以计算其期望的事件发生率范围，进而进行强健验证。该框架所用方法可处理常规事件和罕见情况，能处理真实系统内在的不确定性。 |
| [^19] | [Generalization-based similarity.](http://arxiv.org/abs/2302.10096) | 本文从头构建了一个基于抽象代数和定性概念的相似性概念，并将其通过模型论类型自然地嵌入到一阶逻辑中。 |
| [^20] | [Adversarial Detection: Attacking Object Detection in Real Time.](http://arxiv.org/abs/2209.01962) | 本文首次提出了针对目标检测模型的实时在线攻击，这些攻击可以在所需要的位置制造不存在的物体，攻击成功率约为90\%，揭示了目标检测模型的弱点和安全性问题。 |
| [^21] | [The Best Decisions Are Not the Best Advice: Making Adherence-Aware Recommendations.](http://arxiv.org/abs/2209.01874) | 论文提出了一个考虑服从度的优化框架，来捕获推荐策略和实际执行策略之间的差异。通过分析部分服从度对最佳建议的影响，发现忽略部分服从度可能导致任意严重的性能恶化。 |

# 详细

[^1]: 使用节点自适应传播加速可扩展的图神经网络推论

    Accelerating Scalable Graph Neural Network Inference with Node-Adaptive Propagation. (arXiv:2310.10998v1 [cs.LG])

    [http://arxiv.org/abs/2310.10998](http://arxiv.org/abs/2310.10998)

    本论文提出了一种在线传播框架和两种新的节点自适应传播方法，用于加速可扩展的图神经网络推论。这些方法能够根据节点的拓扑信息自定义每个节点的最佳传播深度，从而避免冗余特征传播，并通过简单的超参数灵活地管理准确性和延迟之间的权衡，以适应不同的延迟限制。

    

    图神经网络（GNNs）在各种应用中展现出了非凡的功效。然而，大规模图的规模使得GNNs的实时推论面临巨大挑战。尽管现有的可扩展GNNs利用线性传播对特征进行预处理并加速训练和推论过程，但在对未知节点进行推论时仍然存在可扩展性问题，因为特征预处理需要已知且固定的图。为了进一步加速这种归纳设置下的可扩展GNNs推论，我们提出了一个在线传播框架和两种新的节点自适应传播方法，可以根据节点的拓扑信息自定义每个节点的最佳传播深度，从而避免冗余特征传播。通过简单的超参数，可以灵活地管理准确性和延迟之间的权衡，以适应不同的延迟限制。此外，为了补偿损失的精度，我们还引入了一个补偿机制，该机制允许传播的层数超过所选择的深度，以提高精度。

    Graph neural networks (GNNs) have exhibited exceptional efficacy in a diverse array of applications. However, the sheer size of large-scale graphs presents a significant challenge to real-time inference with GNNs. Although existing Scalable GNNs leverage linear propagation to preprocess the features and accelerate the training and inference procedure, these methods still suffer from scalability issues when making inferences on unseen nodes, as the feature preprocessing requires the graph to be known and fixed. To further accelerate Scalable GNNs inference in this inductive setting, we propose an online propagation framework and two novel node-adaptive propagation methods that can customize the optimal propagation depth for each node based on its topological information and thereby avoid redundant feature propagation. The trade-off between accuracy and latency can be flexibly managed through simple hyper-parameters to accommodate various latency constraints. Moreover, to compensate for 
    
[^2]: 从复杂到清晰：通过Clifford的几何代数和凸优化的分析表达深度神经网络的权重

    From Complexity to Clarity: Analytical Expressions of Deep Neural Network Weights via Clifford's Geometric Algebra and Convexity. (arXiv:2309.16512v1 [cs.LG])

    [http://arxiv.org/abs/2309.16512](http://arxiv.org/abs/2309.16512)

    本文通过Clifford的几何代数和凸优化，提出了一种分析深度神经网络的新方法。我们展示了深度ReLU神经网络的最优权重可以通过训练样本的楔积来获得，并且训练问题可以简化为对楔积特征进行凸优化，从而揭示了神经网络内部的几何结构。

    

    本文介绍了一种基于几何（Clifford）代数和凸优化的神经网络分析方法。我们展示了当使用标准正则化损失进行训练时，深度ReLU神经网络的最优权重由训练样本的楔积给出。此外，训练问题可简化为对楔积特征进行凸优化，在其中编码训练数据集的几何结构。该结构以数据向量生成的三角形和平行体的有符号体积表示。凸问题通过$\ell_1$正则化找到样本的一个小子集，以发现仅相关的楔积特征。我们的分析提供了对深度神经网络内部工作机制的新视角，并揭示了隐藏层的作用。

    In this paper, we introduce a novel analysis of neural networks based on geometric (Clifford) algebra and convex optimization. We show that optimal weights of deep ReLU neural networks are given by the wedge product of training samples when trained with standard regularized loss. Furthermore, the training problem reduces to convex optimization over wedge product features, which encode the geometric structure of the training dataset. This structure is given in terms of signed volumes of triangles and parallelotopes generated by data vectors. The convex problem finds a small subset of samples via $\ell_1$ regularization to discover only relevant wedge product features. Our analysis provides a novel perspective on the inner workings of deep neural networks and sheds light on the role of the hidden layers.
    
[^3]: 神经预测和对齐的光谱理论

    A Spectral Theory of Neural Prediction and Alignment. (arXiv:2309.12821v1 [q-bio.NC])

    [http://arxiv.org/abs/2309.12821](http://arxiv.org/abs/2309.12821)

    该论文提出了一个光谱理论，用于理解神经预测和对齐问题。通过研究模型激活的光谱偏差和神经响应与可学习子空间的对齐情况，我们可以获得深度神经网络的几何属性，并区分在神经预测方面表现相同的模型。

    

    神经网络的表示经常通过将神经网络响应与生物系统测得的响应进行回归来进行比较。许多不同的先进神经网络产生了类似的神经预测，但仍然不清楚如何区分在预测神经响应方面表现相同的模型。为了深入了解这一点，我们使用了近期提出的理论框架，该框架将回归中的泛化误差与模型激活的光谱偏差和神经响应与可学习子空间之间的对齐联系起来。我们将这个理论扩展到了模型激活和神经响应之间的回归情况，并定义了描述误差嵌入几何性质的几何属性。我们测试了大量预测视觉皮层活动的深度神经网络，并展示了多种几何形状导致低神经预测误差的情况。

    The representations of neural networks are often compared to those of biological systems by performing regression between the neural network responses and those measured from biological systems. Many different state-of-the-art deep neural networks yield similar neural predictions, but it remains unclear how to differentiate among models that perform equally well at predicting neural responses. To gain insight into this, we use a recent theoretical framework that relates the generalization error from regression to the spectral bias of the model activations and the alignment of the neural responses onto the learnable subspace of the model. We extend this theory to the case of regression between model activations and neural responses, and define geometrical properties describing the error embedding geometry. We test a large number of deep neural networks that predict visual cortical activity and show that there are multiple types of geometries that result in low neural prediction error as
    
[^4]: Talk2Care: 利用大型语言模型促进异步患者-医生通信

    Talk2Care: Facilitating Asynchronous Patient-Provider Communication with Large-Language-Model. (arXiv:2309.09357v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.09357](http://arxiv.org/abs/2309.09357)

    本研究利用大型语言模型（LLMs）来促进患者和医生之间的异步通信，通过访谈研究了解了他们对LLMs的需求，并构建了一个名为Talk2Care的LLM驱动的通信系统。

    

    尽管有大量的远程医疗应用程序来帮助家庭中的老年人和医疗提供者，但基本的消息和电话仍然是最常见的通信方法，这些方法存在有限的可用性、信息丢失和流程效率低下的问题。促进患者-医生通信的一个有希望的解决方案是利用大型语言模型(LLMs)及其强大的自然对话和摘要能力。然而，对于LLMs在通信过程中的作用还存在有限的理解。我们首先进行了两项访谈研究，分别与老年人(N=10)和医疗提供者(N=9)进行了交流，以了解他们在患者-医生异步通信中对LLMs的需求和机会。基于这些见解，我们构建了一个LLM驱动的通信系统Talk2Care，并为两个群体设计了交互组件: (1) 对于老年人，我们利用语音助手的便利性和易于获取性，构建了一个LLM驱动的语音助手

    Despite the plethora of telehealth applications to assist home-based older adults and healthcare providers, basic messaging and phone calls are still the most common communication methods, which suffer from limited availability, information loss, and process inefficiencies. One promising solution to facilitate patient-provider communication is to leverage large language models (LLMs) with their powerful natural conversation and summarization capability. However, there is a limited understanding of LLMs' role during the communication. We first conducted two interview studies with both older adults (N=10) and healthcare providers (N=9) to understand their needs and opportunities for LLMs in patient-provider asynchronous communication. Based on the insights, we built an LLM-powered communication system, Talk2Care, and designed interactive components for both groups: (1) For older adults, we leveraged the convenience and accessibility of voice assistants (VAs) and built an LLM-powered VA i
    
[^5]: GNN对公平性稳定性的Lipschitz特性表征

    Characterizing Lipschitz Stability of GNN for Fairness. (arXiv:2309.03648v1 [cs.LG])

    [http://arxiv.org/abs/2309.03648](http://arxiv.org/abs/2309.03648)

    论文通过研究GNN的Lipschitz界限表征了GNN对公平性稳定性的影响，尤其是在处理非欧几里得数据和固有偏倚的情况下。同时，该研究对于限制GNN输出的扰动以保障公平性训练提出了挑战。

    

    Lipschitz界限是从鲁棒统计学中借鉴的一种技术，可以限制输出相对于输入的最大变化，考虑到相关的非关键偏倚因素。这是一种高效且可证明的方法，可以检查机器学习模型的输出稳定性，而不会增加额外的计算成本。最近，对于在非欧几里得数据上操作的图神经网络（GNN）引起了广泛的关注。然而，之前没有研究调查GNN的Lipschitz界限以揭示模型输出的稳定性，特别是在处理具有固有偏倚的非欧几里得数据时。由于常见图形数据在GNN训练中存在固有偏差，这给限制由输入偏差引起的GNN输出扰动，从而在训练期间保障公平性，带来了严峻的挑战。最近，尽管Lipschitz常数在控制欧几里得神经网络的稳定性方面有所应用，但精确Lipschitz常数的计算十分困难。

    The Lipschitz bound, a technique from robust statistics, can limit the maximum changes in the output concerning the input, taking into account associated irrelevant biased factors. It is an efficient and provable method for examining the output stability of machine learning models without incurring additional computation costs. Recently, Graph Neural Networks (GNNs), which operate on non-Euclidean data, have gained significant attention. However, no previous research has investigated the GNN Lipschitz bounds to shed light on stabilizing model outputs, especially when working on non-Euclidean data with inherent biases. Given the inherent biases in common graph data used for GNN training, it poses a serious challenge to constraining the GNN output perturbations induced by input biases, thereby safeguarding fairness during training. Recently, despite the Lipschitz constant's use in controlling the stability of Euclideanneural networks, the calculation of the precise Lipschitz constant rem
    
[^6]: 使用统计学与物理引导的过程模型在协同实体系统中检测未知-未知情况

    Detection of Unknown-Unknowns in Cyber-Physical Systems using Statistical Conformance with Physics Guided Process Models. (arXiv:2309.02603v1 [cs.AI])

    [http://arxiv.org/abs/2309.02603](http://arxiv.org/abs/2309.02603)

    该论文提出了一个新的框架来分析安全关键的协同实体系统的操作输出特性的随机符合性，从而发现未知-未知情况并评估潜在的安全风险。

    

    未知-未知情况是指在设计和测试阶段未考虑到的协同实体系统中的操作场景。在未知-未知情况下，协同实体系统的操作行为不能保证满足通过输出轨迹上的信号时间逻辑（STL）指定的安全性和有效性等要求。我们提出了一种新颖的框架，用于分析安全关键协同实体系统操作输出特性的随机符合性，可以发现未知-未知情况并评估潜在的安全风险。我们提出了一种动力学诱导的混合循环神经网络（DiH-RNN），用于挖掘物理引导的代理模型（PGSM），并使用STL对模型系数进行模型一致性检查。我们演示了通过未知胰岛素卡带错误导致人工胰腺(AP)操作变化的检测。

    Unknown unknowns are operational scenarios in a cyber-physical system that are not accounted for in the design and test phase. As such under unknown-unknown scenarios, the operational behavior of the CPS is not guaranteed to meet requirements such as safety and efficacy specified using Signal Temporal Logic (STL) on the output trajectories. We propose a novel framework for analyzing the stochastic conformance of operational output characteristics of safety-critical cyber-physical systems that can discover unknown-unknown scenarios and evaluate potential safety hazards. We propose dynamics-induced hybrid recurrent neural networks (DiH-RNN) to mine a physics-guided surrogate model (PGSM) which is used to check the model conformance using STL on the model coefficients. We demonstrate the detection of operational changes in an Artificial Pancreas(AP) due to unknown insulin cartridge errors.
    
[^7]: 使用不精确神经网络的分布鲁棒统计验证

    Distributionally Robust Statistical Verification with Imprecise Neural Networks. (arXiv:2308.14815v1 [cs.AI])

    [http://arxiv.org/abs/2308.14815](http://arxiv.org/abs/2308.14815)

    本文提出了一种使用不精确神经网络的分布鲁棒统计验证方法，通过结合主动学习、不确定性量化和神经网络验证，可以在大量的分布上提供对黑盒系统行为的保证。

    

    在AI安全领域，一个特别具有挑战性的问题是在高维自主系统的行为上提供保证。以可达性分析为中心的验证方法无法扩展，而纯粹的统计方法受到对采样过程的分布假设的限制。相反，我们提出了一个针对黑盒系统的分布鲁棒版本的统计验证问题，其中我们的性能保证适用于大量的分布。本文提出了一种基于主动学习、不确定性量化和神经网络验证的新方法。我们方法的一个核心部分是一种称为不精确神经网络的集成技术，它提供了不确定性以指导主动学习。主动学习使用了一种称为Sherlock的全面神经网络验证工具来收集样本。在openAI gym Mujoco环境中使用多个物理模拟器进行评估。

    A particularly challenging problem in AI safety is providing guarantees on the behavior of high-dimensional autonomous systems. Verification approaches centered around reachability analysis fail to scale, and purely statistical approaches are constrained by the distributional assumptions about the sampling process. Instead, we pose a distributionally robust version of the statistical verification problem for black-box systems, where our performance guarantees hold over a large family of distributions. This paper proposes a novel approach based on a combination of active learning, uncertainty quantification, and neural network verification. A central piece of our approach is an ensemble technique called Imprecise Neural Networks, which provides the uncertainty to guide active learning. The active learning uses an exhaustive neural-network verification tool Sherlock to collect samples. An evaluation on multiple physical simulators in the openAI gym Mujoco environments with reinforcement-
    
[^8]: InstructME:一个基于潜在扩散模型的指导音乐编辑和混音框架

    InstructME: An Instruction Guided Music Edit And Remix Framework with Latent Diffusion Models. (arXiv:2308.14360v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2308.14360](http://arxiv.org/abs/2308.14360)

    InstructME是一个基于潜在扩散模型的指导音乐编辑和混音框架，通过多尺度聚合和引入和弦进展矩阵来保持编辑的一致性和提高旋律和谐性。

    

    音乐编辑主要涉及到修改乐器轨道或整体混音，通过一系列操作为原始作品提供了新颖的重新诠释。这些音乐处理方法在各种应用中具有巨大的潜力，但需要深厚的专业知识。以往的方法虽然对图像和音频修改有效，但直接应用于音乐时存在问题。这归因于音乐的独特数据性质，这些方法可能会无意中破坏音乐的内在和谐一致性。本文介绍了InstructME，一种基于潜在扩散模型的指导音乐编辑和混音框架。我们的框架在编辑之前和之后通过多尺度聚合强化了U-Net以保持一致性。此外，我们引入了和弦进展矩阵作为条件信息，并将其融入语义空间以提高编辑时的旋律和谐性。为了适应外部需求，我们还创新地提出了半监督学习方法来改进混音质量。

    Music editing primarily entails the modification of instrument tracks or remixing in the whole, which offers a novel reinterpretation of the original piece through a series of operations. These music processing methods hold immense potential across various applications but demand substantial expertise. Prior methodologies, although effective for image and audio modifications, falter when directly applied to music. This is attributed to music's distinctive data nature, where such methods can inadvertently compromise the intrinsic harmony and coherence of music. In this paper, we develop InstructME, an Instruction guided Music Editing and remixing framework based on latent diffusion models. Our framework fortifies the U-Net with multi-scale aggregation in order to maintain consistency before and after editing. In addition, we introduce chord progression matrix as condition information and incorporate it in the semantic space to improve melodic harmony while editing. For accommodating ext
    
[^9]: INFLECT-DGNN: 动态图神经网络进行影响者预测

    INFLECT-DGNN: Influencer Prediction with Dynamic Graph Neural Networks. (arXiv:2307.08131v2 [cs.SI] UPDATED)

    [http://arxiv.org/abs/2307.08131](http://arxiv.org/abs/2307.08131)

    INFLECT-DGNN是一个结合了图神经网络和递归神经网络的框架，使用加权损失函数、针对图数据适应的合成少数过采样技术和滚动窗口策略，用于影响者预测。实验结果显示，使用RNN来编码时间属性和GNN显著提高了预测性能。

    

    在许多领域中，利用网络信息进行预测建模已经变得非常普遍。在推荐和定向营销领域中，影响者检测是一个可以通过动态网络表示大大受益的领域，原因是不断发展的客户-品牌关系。为了阐述这一思想，我们引入了INFLECT-DGNN，这是一个使用加权损失函数的图神经网络（GNN）和递归神经网络（RNN），针对图数据适应的合成少数过采样技术（SMOTE）以及精心设计的滚动窗口策略的新框架。为了评估预测性能，我们利用一个包含三个城市网络的独特企业数据集，并制定了一个以利润为驱动的影响者预测评估方法。我们的结果表明，使用RNN来编码时间属性以及GNN显著改善了预测性能。

    Leveraging network information for predictive modeling has become widespread in many domains. Within the realm of referral and targeted marketing, influencer detection stands out as an area that could greatly benefit from the incorporation of dynamic network representation due to the ongoing development of customer-brand relationships. To elaborate this idea, we introduce INFLECT-DGNN, a new framework for INFLuencer prEdiCTion with Dynamic Graph Neural Networks that combines Graph Neural Networks (GNN) and Recurrent Neural Networks (RNN) with weighted loss functions, the Synthetic Minority Oversampling TEchnique (SMOTE) adapted for graph data, and a carefully crafted rolling-window strategy. To evaluate predictive performance, we utilize a unique corporate data set with networks of three cities and derive a profit-driven evaluation methodology for influencer prediction. Our results show how using RNN to encode temporal attributes alongside GNNs significantly improves predictive perform
    
[^10]: 探索AI增强的协作控制对于辅助机械臂的影响

    Exploring AI-enhanced Shared Control for an Assistive Robotic Arm. (arXiv:2306.13509v1 [cs.HC])

    [http://arxiv.org/abs/2306.13509](http://arxiv.org/abs/2306.13509)

    本文研究如何将人工智能集成到机械臂的共享控制范式中，以帮助运动受损人士实现更高程度的个人自治。

    

    辅助技术，特别是辅助机械臂已经成为帮助运动受损人士实现自主生活的可能性。近年来，越来越多这样的系统已经面向最终用户提供，例如Kinova Jaco机械臂。然而，它们大多需要复杂的手动控制，这可能会使用户不堪重负。因此，研究人员探索让这些机器人自主行动的方式。然而，至少对于这个特定的用户群体来说，这种方法已经被证明是徒劳的。在这里，用户希望保持控制权以实现更高程度的个人自治，但自主的机器人与此相反。在我们的研究中，我们探讨了如何将人工智能（AI）集成到共享控制范式中。特别是，我们关注了人与机器人之间界面的必要要求，以及如何在显著减少心理负担和所需的机动能力的同时保持人类的控制。

    Assistive technologies and in particular assistive robotic arms have the potential to enable people with motor impairments to live a self-determined life. More and more of these systems have become available for end users in recent years, such as the Kinova Jaco robotic arm. However, they mostly require complex manual control, which can overwhelm users. As a result, researchers have explored ways to let such robots act autonomously. However, at least for this specific group of users, such an approach has shown to be futile. Here, users want to stay in control to achieve a higher level of personal autonomy, to which an autonomous robot runs counter. In our research, we explore how Artifical Intelligence (AI) can be integrated into a shared control paradigm. In particular, we focus on the consequential requirements for the interface between human and robot and how we can keep humans in the loop while still significantly reducing the mental load and required motor skills.
    
[^11]: DIFFender：基于扩散的对抗性防御方法用于抵御Patch攻击

    DIFFender: Diffusion-Based Adversarial Defense against Patch Attacks. (arXiv:2306.09124v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.09124](http://arxiv.org/abs/2306.09124)

    DIFFender是一种基于扩散的对抗性防御方法，通过定位和恢复两个阶段的操作，利用文本引导的扩散模型来防御对抗性Patch，从而提高其整体防御性能。

    

    对抗性攻击，尤其是Patch攻击，对深度学习模型的鲁棒性和可靠性构成了重大威胁。开发可靠的防御方法以抵御Patch攻击对于实际应用至关重要，然而当前在这个领域的研究还不令人满意。在本文中，我们提出了DIFFender，一种新颖的防御方法，它利用文本引导的扩散模型来防御对抗性Patch。DIFFender包括两个主要阶段：Patch定位和Patch恢复。在定位阶段，我们发现并利用了扩散模型的一个有趣特性，以有效地识别对抗性Patch的位置。在恢复阶段，我们利用扩散模型重建图像中的对抗性区域同时保持视觉内容的完整性。重要的是，这两个阶段都受到统一的扩散模型的精心引导，因此我们可以利用它们之间的紧密相互作用来提高整个防御性能。

    Adversarial attacks, particularly patch attacks, pose significant threats to the robustness and reliability of deep learning models. Developing reliable defenses against patch attacks is crucial for real-world applications, yet current research in this area is not satisfactory. In this paper, we propose DIFFender, a novel defense method that leverages a text-guided diffusion model to defend against adversarial patches. DIFFender includes two main stages: patch localization and patch restoration. In the localization stage, we find and exploit an intriguing property of the diffusion model to effectively identify the locations of adversarial patches. In the restoration stage, we employ the diffusion model to reconstruct the adversarial regions in the images while preserving the integrity of the visual content. Importantly, these two stages are carefully guided by a unified diffusion model, thus we can utilize the close interaction between them to improve the whole defense performance. Mor
    
[^12]: 提升离线到在线强化学习的Q-Ensembles方法

    Improving Offline-to-Online Reinforcement Learning with Q-Ensembles. (arXiv:2306.06871v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.06871](http://arxiv.org/abs/2306.06871)

    我们提出了一种名为Q-Ensembles的新框架，通过增加Q网络的数量，无缝地连接离线预训练和在线微调，同时不降低性能。此外，我们适当放宽Q值估计的悲观性，并将基于集合的探索机制融入我们的框架中，从而提升了离线到在线强化学习的性能。

    

    离线强化学习是一种学习范式，代理根据固定的经验数据集进行学习。然而，仅从静态数据集中学习可能限制了性能，因为缺乏探索能力。为了克服这个问题，将离线预训练与在线微调结合起来的离线到在线强化学习方法能够让代理与环境实时交互，进一步完善其策略。然而，现有的离线到在线强化学习方法存在性能下降和在线阶段改进缓慢的问题。为了解决这些挑战，我们提出了一种名为Q-Ensembles的新框架，它通过增加Q网络的数量，无缝地连接离线预训练和在线微调，同时不降低性能。此外，为了加快在线性能提升，我们适当放宽Q值估计的悲观性，并将基于集合的探索机制融入我们的框架中。

    Offline reinforcement learning (RL) is a learning paradigm where an agent learns from a fixed dataset of experience. However, learning solely from a static dataset can limit the performance due to the lack of exploration. To overcome it, offline-to-online RL combines offline pre-training with online fine-tuning, which enables the agent to further refine its policy by interacting with the environment in real-time. Despite its benefits, existing offline-to-online RL methods suffer from performance degradation and slow improvement during the online phase. To tackle these challenges, we propose a novel framework called Ensemble-based Offline-to-Online (E2O) RL. By increasing the number of Q-networks, we seamlessly bridge offline pre-training and online fine-tuning without degrading performance. Moreover, to expedite online performance enhancement, we appropriately loosen the pessimism of Q-value estimation and incorporate ensemble-based exploration mechanisms into our framework. Experiment
    
[^13]: HCI挑战的映射：ChatGPT和GPT-4在成本效益问答中的应用与评估

    Mapping the Challenges of HCI: An Application and Evaluation of ChatGPT and GPT-4 for Cost-Efficient Question Answering. (arXiv:2306.05036v1 [cs.HC])

    [http://arxiv.org/abs/2306.05036](http://arxiv.org/abs/2306.05036)

    本文探讨了 ChatGPT 和 GPT-4 两个大型语言模型在实际情况下的运用和性能表现，通过以人机交互领域的研究挑战为例，结论是 ChatGPT 和 GPT-4 的组合是分析文本语料库的一种非常高效且节省成本的方法。

    

    大型语言模型（LLM）如ChatGPT和GPT-4正在广泛应用于实际情况。但是，这两种LLM是闭源的，并且很少有关于它们在实际使用案例中的性能的了解。在学术界中，LLM的性能通常是在基准测试中测量的，这些基准测试可能已泄漏到ChatGPT和GPT-4的训练数据中。本文中，我们将ChatGPT和GPT-4应用于成本效益问答的实际任务，以从2023年人机交互会议（CHI）的论文集中提取人机交互领域研究人员面临的挑战。我们对LLM在这个实际任务上进行了评估，并得出结论，ChatGPT和GPT-4的组合是分析文本语料库的极佳成本效益手段。成本效率对于原型研究想法和从不同角度分析文本语料库非常重要。

    Large language models (LLMs), such as ChatGPT and GPT-4, are gaining wide-spread real world use. Yet, the two LLMs are closed source, and little is known about the LLMs' performance in real-world use cases. In academia, LLM performance is often measured on benchmarks which may have leaked into ChatGPT's and GPT-4's training data. In this paper, we apply and evaluate ChatGPT and GPT-4 for the real-world task of cost-efficient extractive question answering over a text corpus that was published after the two LLMs completed training. More specifically, we extract research challenges for researchers in the field of HCI from the proceedings of the 2023 Conference on Human Factors in Computing Systems (CHI). We critically evaluate the LLMs on this practical task and conclude that the combination of ChatGPT and GPT-4 makes an excellent cost-efficient means for analyzing a text corpus at scale. Cost-efficiency is key for prototyping research ideas and analyzing text corpora from different persp
    
[^14]: 理解早期权重平均对训练大语言模型的有效性

    Understanding the Effectiveness of Early Weight Averaging for Training Large Language Models. (arXiv:2306.03241v1 [cs.LG])

    [http://arxiv.org/abs/2306.03241](http://arxiv.org/abs/2306.03241)

    本文研究了使用早期权重平均化方法来提高大型语言模型质量的有效性，证明该方法可以加速收敛且测试和零样本泛化效果显著，同时有效缓解了训练中的损失波动问题。

    

    训练大型语言模型代价高昂，最近的研究表明训练至收敛并不高效。在本文中，我们研究了一种简单的想法，即在训练过程中沿着轨迹进行检查点平均化，以在模型收敛之前提高其质量。这种方法在训练或推理期间不会产生额外的成本。具体而言，我们分析了具有10亿到120亿参数的Pythia LLM的训练轨迹，并证明特别是在训练的早期和中期阶段，这种想法可以加速收敛并提高测试和零样本泛化效果。损失波动是LLM训练中众所周知的问题；在我们的分析中，我们遇到了两种基础轨迹的这种情况，并且我们的平均化可以缓解这两种情况。例如，对于一个拥有69亿参数的LLM，我们的早期权重平均化配方可以节省高达4200小时的GPU时间，这对云计算成本来说是显著的节约。

    Training LLMs is expensive, and recent evidence indicates training all the way to convergence is inefficient. In this paper, we investigate the ability of a simple idea, checkpoint averaging along the trajectory of a training run to improve the quality of models before they have converged. This approach incurs no extra cost during training or inference. Specifically, we analyze the training trajectories of Pythia LLMs with 1 to 12 billion parameters and demonstrate that, particularly during the early to mid stages of training, this idea accelerates convergence and improves both test and zero-shot generalization. Loss spikes are a well recognized problem in LLM training; in our analysis we encountered two instances of this in the underlying trajectories, and both instances were mitigated by our averaging.  For a 6.9B parameter LLM, for example, our early weight averaging recipe can save upto 4200 hours of GPU time, which corresponds to significant savings in cloud compute costs.
    
[^15]: SPRING: GPT-4通过学习论文和推理在游戏中表现超过RL算法

    SPRING: GPT-4 Out-performs RL Algorithms by Studying Papers and Reasoning. (arXiv:2305.15486v1 [cs.AI])

    [http://arxiv.org/abs/2305.15486](http://arxiv.org/abs/2305.15486)

    SPRING是一个新的方法，能够在开放世界游戏中表现出色，它通过阅读游戏的原始学术论文并使用所学知识进行推理并玩游戏。。

    

    开放世界游戏由于其多任务、深度探索和目标优先级要求，对AI算法提出了重大挑战。尽管强化学习（RL）在解决游戏方面很受欢迎，但其高样本复杂性限制了它在像Crafter或Minecraft这样复杂的开放世界游戏中的有效性。我们提出了一种新颖的方法SPRING，通过阅读游戏的原始学术论文并使用所学知识进行推理并玩游戏，来解决这个问题。在给定LaTeX源作为游戏语境和代理当前观察的描述的情况下，我们的SPRING框架利用具有游戏相关问题的定向无环图（DAG）作为节点和依赖关系作为边。通过按拓扑顺序遍历DAG并计算每个节点的LLM响应来确定在环境中采取的最优行动，LLM对最终节点的答案直接转化为环境行动。在我们的实验中，我们研究了

    Open-world survival games pose significant challenges for AI algorithms due to their multi-tasking, deep exploration, and goal prioritization requirements. Despite reinforcement learning (RL) being popular for solving games, its high sample complexity limits its effectiveness in complex open-world games like Crafter or Minecraft. We propose a novel approach, SPRING, to read the game's original academic paper and use the knowledge learned to reason and play the game through a large language model (LLM). Prompted with the LaTeX source as game context and a description of the agent's current observation, our SPRING framework employs a directed acyclic graph (DAG) with game-related questions as nodes and dependencies as edges. We identify the optimal action to take in the environment by traversing the DAG and calculating LLM responses for each node in topological order, with the LLM's answer to final node directly translating to environment actions. In our experiments, we study the quality
    
[^16]: 基于WiFi CSI的无设备多房间人体存在检测的时间选择性循环神经网络

    Time-Selective RNN for Device-Free Multi-Room Human Presence Detection Using WiFi CSI. (arXiv:2304.13107v1 [cs.AI])

    [http://arxiv.org/abs/2304.13107](http://arxiv.org/abs/2304.13107)

    这篇论文提出了一种使用基于WiFi信道状态信息提取人体移动和空间特征的无设备多房间人体存在检测系统，能够通过时间-selective特征提取算法区分有直觉视线路径阻塞和无视线路径阻塞的情况。

    

    人类存在检测是各种应用的重要技术，包括家居自动化、安全和医疗保健。虽然传统上采用基于摄像机的系统来实现这一目的，但会引发隐私问题。为了解决这个问题，最近的研究探讨了利用商用WiFi接入点提供的信道状态信息(CSI)方法，提供详细的信道特征。在本论文中，我们提出了一个基于时间选择性条件双特征提取递归网络(TCD-FERN)的无设备多房间人体存在检测系统。我们的系统旨在使用动态和静态(DaS)数据预处理技术，在条件人体特征下捕捉重要的时间特征，提取人的移动和空间特征，并区分有直接视线路径阻塞和无视线路径阻塞的情况。为了减少房间隔断造成的特征衰减问题，我们使用基于 LSTM 的 NCoV-DaS 技术。

    Human presence detection is a crucial technology for various applications, including home automation, security, and healthcare. While camera-based systems have traditionally been used for this purpose, they raise privacy concerns. To address this issue, recent research has explored the use of channel state information (CSI) approaches that can be extracted from commercial WiFi access points (APs) and provide detailed channel characteristics. In this thesis, we propose a device-free human presence detection system for multi-room scenarios using a time-selective conditional dual feature extract recurrent Network (TCD-FERN). Our system is designed to capture significant time features with the condition on current human features using a dynamic and static (DaS) data preprocessing technique to extract moving and spatial features of people and differentiate between line-of-sight (LoS) path blocking and non-blocking cases. To mitigate the feature attenuation problem caused by room partitions,
    
[^17]: CornerFormer: 提升角点表征以进行精细结构重建

    CornerFormer: Boosting Corner Representation for Fine-Grained Structured Reconstruction. (arXiv:2304.07072v1 [cs.CV])

    [http://arxiv.org/abs/2304.07072](http://arxiv.org/abs/2304.07072)

    CornerFormer是一种新的方法，它利用不同建模策略于单个模型中融合角点检测和边缘预测来提升精细结构重建的表现，并在挑战性的基准测试中取得了最好的结果。

    

    结构化重建是一种非平凡的密集预测问题，它从栅格图像中提取结构信息（例如，建筑角点和边缘），然后相应地重建为二维平面图。与常见的分割或检测问题相比，它显著依赖于利用整体几何信息进行结构推理的能力。目前，基于transformer的方法采用两阶段方式解决这个具有挑战性的问题，在第一个模型中检测角点，并在第二个模型中分类拟议边缘（角对）。然而，它们将两个阶段分开成不同的模型，并且只共享主干编码器。与现有的建模策略不同，我们提出了增强的角点表示方法：1）通过在不同的粒度中共享特征，它在角点检测和边缘预测之间融合知识；2）角点候选者根据其方向作为四个热图通道提出。定性和定量评估均表明，我们的CornerFormer明显优于以前的transformer-based模型，在具有挑战性的基准测试中取得了最先进的结果。

    Structured reconstruction is a non-trivial dense prediction problem, which extracts structural information (\eg, building corners and edges) from a raster image, then reconstructs it to a 2D planar graph accordingly. Compared with common segmentation or detection problems, it significantly relays on the capability that leveraging holistic geometric information for structural reasoning. Current transformer-based approaches tackle this challenging problem in a two-stage manner, which detect corners in the first model and classify the proposed edges (corner-pairs) in the second model. However, they separate two-stage into different models and only share the backbone encoder. Unlike the existing modeling strategies, we present an enhanced corner representation method: 1) It fuses knowledge between the corner detection and edge prediction by sharing feature in different granularity; 2) Corner candidates are proposed in four heatmap channels w.r.t its direction. Both qualitative and quantita
    
[^18]: 自主机器人强健验证的贝叶斯学习方法

    Bayesian Learning for the Robust Verification of Autonomous Robots. (arXiv:2303.08476v1 [cs.RO])

    [http://arxiv.org/abs/2303.08476](http://arxiv.org/abs/2303.08476)

    本文提出了一种新框架，利用贝叶斯学习方法对验证机器人系统的先验知识和观测数据进行处理，以计算其期望的事件发生率范围，进而进行强健验证。该框架所用方法可处理常规事件和罕见情况，能处理真实系统内在的不确定性。

    

    本文开发了一种新颖的贝叶斯学习框架，能够在不确定环境中运行验证自主机器人进行关键任务。该框架利用验证机器人系统的先验知识和观测数据，学习其事件发生率的预期值的范围。该框架支持在系统操作期间常规观察到的事件以及那些罕见或是灾难性故障等回报巨大的事件。此外，我们利用学习到的事件发生率范围组装区间连续时间马尔可夫模型，并应用定量验证方法来计算关键系统属性的预期变化区间。这些区间反映了许多真实世界系统的内在不确定性，能够在参数不确定性下强健验证其定量属性。本文将所提出的框架应用于水下自主机器人任务验证的案例研究中。

    We develop a novel Bayesian learning framework that enables the runtime verification of autonomous robots performing critical missions in uncertain environments. Our framework exploits prior knowledge and observations of the verified robotic system to learn expected ranges of values for the occurrence rates of its events. We support both events observed regularly during system operation, and singular events such as catastrophic failures or the completion of difficult one-off tasks. Furthermore, we use the learnt event-rate ranges to assemble interval continuous-time Markov models, and we apply quantitative verification to these models to compute expected intervals of variation for key system properties. These intervals reflect the uncertainty intrinsic to many real-world systems, enabling the robust verification of their quantitative properties under parametric uncertainty. We apply the proposed framework to the case study of verification of an autonomous robotic mission for underwater
    
[^19]: 基于泛化的相似性

    Generalization-based similarity. (arXiv:2302.10096v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.10096](http://arxiv.org/abs/2302.10096)

    本文从头构建了一个基于抽象代数和定性概念的相似性概念，并将其通过模型论类型自然地嵌入到一阶逻辑中。

    

    检测和利用看似不相关的对象之间的相似性是类比推理的核心，而类比推理又是人工智能的核心。本文从头开始开发了一个基于抽象代数和定性概念的相似性概念，基于观察到泛化集合可以编码元素的重要属性。我们证明了以这种方式定义的相似性具有吸引人的数学属性。通过从基本概念出发构建相似性概念，并将其自然地嵌入到模型论类型中的一阶逻辑中，我们使读者相信其合理性。

    Detecting and exploiting similarities between seemingly distant objects is at the core of analogical reasoning which itself is at the core of artificial intelligence. This paper develops {\em from the ground up} an abstract algebraic and {\em qualitative} notion of similarity based on the observation that sets of generalizations encode important properties of elements. We show that similarity defined in this way has appealing mathematical properties. As we construct our notion of similarity from first principles using only elementary concepts of universal algebra, to convince the reader of its plausibility, we show that it can be naturally embedded into first-order logic via model-theoretic types.
    
[^20]: 对抗检测: 实时攻击目标检测

    Adversarial Detection: Attacking Object Detection in Real Time. (arXiv:2209.01962v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2209.01962](http://arxiv.org/abs/2209.01962)

    本文首次提出了针对目标检测模型的实时在线攻击，这些攻击可以在所需要的位置制造不存在的物体，攻击成功率约为90\%，揭示了目标检测模型的弱点和安全性问题。

    

    智能机器人依赖目标检测模型来感知环境。随着深度学习安全性的进步，揭示了目标检测模型易受到对抗性攻击的威胁。然而先前的研究主要侧重于攻击静态图像或离线视频。因此，仍不清楚此类攻击是否会危及动态环境下实际的机器人应用。本文通过提出针对目标检测模型的首次实时在线攻击来填补这一空白。我们设计了三种攻击方式，可以在所需位置生成不存在对象的边界框。这些攻击在约20次迭代内达到约90\%的成功率。演示视频可在https://youtu.be/zJZ1aNlXsMU上观看。

    Intelligent robots rely on object detection models to perceive the environment. Following advances in deep learning security it has been revealed that object detection models are vulnerable to adversarial attacks. However, prior research primarily focuses on attacking static images or offline videos. Therefore, it is still unclear if such attacks could jeopardize real-world robotic applications in dynamic environments. This paper bridges this gap by presenting the first real-time online attack against object detection models. We devise three attacks that fabricate bounding boxes for nonexistent objects at desired locations. The attacks achieve a success rate of about 90\% within about 20 iterations. The demo video is available at https://youtu.be/zJZ1aNlXsMU.
    
[^21]: 最佳决策并不是最佳建议：制定考虑服从度的推荐

    The Best Decisions Are Not the Best Advice: Making Adherence-Aware Recommendations. (arXiv:2209.01874v3 [cs.HC] UPDATED)

    [http://arxiv.org/abs/2209.01874](http://arxiv.org/abs/2209.01874)

    论文提出了一个考虑服从度的优化框架，来捕获推荐策略和实际执行策略之间的差异。通过分析部分服从度对最佳建议的影响，发现忽略部分服从度可能导致任意严重的性能恶化。

    

    许多高风险决策遵循专家参与的结构，即人类操作员从算法中接收建议但最终是决策制定者。因此，算法的建议可能与实践中实际执行的决策不同。然而，大多数算法建议是通过解决优化问题获得的，该问题假定建议将完美执行。我们提出了一种考虑服从度的优化框架，以捕获推荐策略和实际执行策略之间的差异，并分析部分服从度对最佳建议的影响。我们发现，忽略部分服从度现象，与目前大多数推荐引擎所做的，可能导致与当前人类基线性能和推荐算法预期性能相比，出现任意严重的性能恶化。我们的框架还提供了有用的工具来分析结构和计算最佳推荐方案。

    Many high-stake decisions follow an expert-in-loop structure in that a human operator receives recommendations from an algorithm but is the ultimate decision maker. Hence, the algorithm's recommendation may differ from the actual decision implemented in practice. However, most algorithmic recommendations are obtained by solving an optimization problem that assumes recommendations will be perfectly implemented. We propose an adherence-aware optimization framework to capture the dichotomy between the recommended and the implemented policy and analyze the impact of partial adherence on the optimal recommendation. We show that overlooking the partial adherence phenomenon, as is currently being done by most recommendation engines, can lead to arbitrarily severe performance deterioration, compared with both the current human baseline performance and what is expected by the recommendation algorithm. Our framework also provides useful tools to analyze the structure and to compute optimal recom
    

