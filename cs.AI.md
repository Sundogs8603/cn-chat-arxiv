# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [ExtremeCast: Boosting Extreme Value Prediction for Global Weather Forecast](https://rss.arxiv.org/abs/2402.01295) | ExtremeCast提出了一种新的损失函数Exloss，实现了针对极值的准确预测，同时引入了无需训练的极值增强策略ExEnsemble，提高了预报的稳健性 |
| [^2] | [Language Rectified Flow: Advancing Diffusion Language Generation with Probabilistic Flows](https://arxiv.org/abs/2403.16995) | 语言校正流是一种基于标准概率流模型的新方法，通过学习常微分方程模型在源分布和目标分布之间传输，提供了统一和有效的生成模型和领域转移解决方案。 |
| [^3] | [Be Yourself: Bounded Attention for Multi-Subject Text-to-Image Generation](https://arxiv.org/abs/2403.16990) | 该论文研究了多主体文本到图像生成中的有界注意力方法，解决了扩散模型注意力层混合不同主体视觉特征导致的语义泄漏问题。 |
| [^4] | [Modelling Commonsense Commonalities with Multi-Facet Concept Embeddings](https://arxiv.org/abs/2403.16984) | 本文通过明确建模不同的感兴趣方面来改进概念嵌入，使其能够捕捉更广泛的常识属性。 |
| [^5] | [VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild](https://arxiv.org/abs/2403.16973) | VoiceCraft是一个基于标记填充的神经编解码器语言模型，在语音编辑和零-shot文本到语音任务上表现出色，实现了在多样性数据集上的最新性能。 |
| [^6] | [LLM Agent Operating System](https://arxiv.org/abs/2403.16971) | 提出了一种将大型语言模型嵌入操作系统中的LLM代理操作系统，旨在优化资源分配、促进代理间上下文切换、实现并发执行以及为代理提供工具服务。 |
| [^7] | [Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance](https://arxiv.org/abs/2403.16952) | 该研究发现了数据混合规律，可以量化地预测模型性能与数据混合比例之间的关系，并提出了一种方法来通过拟合函数形式来引导理想的数据混合选择，从而优化大型语言模型的训练混合。 |
| [^8] | [Aligning with Human Judgement: The Role of Pairwise Preference in Large Language Model Evaluators](https://arxiv.org/abs/2403.16950) | 在大型语言模型评估中，通过引入成对偏好搜索方法PAIRS，成功解决了LLMs与人类判断不一致的问题，并取得了优于直接打分的最先进性能。 |
| [^9] | [SPACE-IDEAS: A Dataset for Salient Information Detection in Space Innovation](https://arxiv.org/abs/2403.16941) | 这项研究介绍了SPACE-IDEAS数据集，用于检测与空间创新相关的显著信息，包括多种文本风格，并展示了如何通过多任务学习训练更好的分类器。 |
| [^10] | [Backpropagation through space, time, and the brain](https://arxiv.org/abs/2403.16933) | 提出了 Generalized Latent Equilibrium (GLE)，它是一种针对神经元网络的物理动态局部时空信用分配的计算框架。 |
| [^11] | [Coarse-Tuning for Ad-hoc Document Retrieval Using Pre-trained Language Models](https://arxiv.org/abs/2403.16915) | 本研究引入了粗调优作为一个中间学习阶段，连接了预训练和微调，在专题文档检索中显著改善了效果。 |
| [^12] | [Towards Algorithmic Fidelity: Mental Health Representation across Demographics in Synthetic vs. Human-generated Data](https://arxiv.org/abs/2403.16909) | 本研究通过使用GPT-3分析不同人口统计在合成数据中的压力因素表示，创建出包含不同人口统计群体压力因素的合成数据集，为以后使用LLMs进行数据生成研究提供了见解。 |
| [^13] | [Towards Trustworthy Automated Driving through Qualitative Scene Understanding and Explanations](https://arxiv.org/abs/2403.16908) | QXG是一种统一符号和定性表示，利用时空图和定性约束从原始传感器输入中提取场景语义，为自动驾驶提供可信的场景理解和解释。 |
| [^14] | [Multi-Agent Optimization for Safety Analysis of Cyber-Physical Systems: Position Paper](https://arxiv.org/abs/2403.16904) | 本文提出了采用优化技术自动化网络物理系统的安全分析中的决策过程，通过多智能体优化方法扩展了传统FMECA，提供了关于系统重要性和开发约束的最佳解决方案。 |
| [^15] | [Towards Secure and Trusted-by-Design Smart Contracts](https://arxiv.org/abs/2403.16903) | 区块链技术使得智能合约能够安全地数字化佐证交易，为了保证其安全性和可信度，需要朝向安全可信的设计。 |
| [^16] | ["It is there, and you need it, so why do you not use it?" Achieving better adoption of AI systems by domain experts, in the case study of natural science research](https://arxiv.org/abs/2403.16895) | 领域专家在自然科学研究中对AI系统的低采用阻碍了人机合作进展，研究发现提出了更好的AI采用建议。 |
| [^17] | [Proprioception Is All You Need: Terrain Classification for Boreal Forests](https://arxiv.org/abs/2403.16877) | 通过引入 BorealTC 数据集，结合现有数据集，我们评估了基于卷积神经网络（CNN）和新颖的状态空间模型（SSM）-Mamba体系结构在北方森林地形分类上的表现。 |
| [^18] | [SIP: Autotuning GPU Native Schedules via Stochastic Instruction Perturbation](https://arxiv.org/abs/2403.16863) | 通过随机搜索自动发现更好的GPU本机指令调度，进一步提高CUDA内核的吞吐量 |
| [^19] | [XAIport: A Service Framework for the Early Adoption of XAI in AI Model Development](https://arxiv.org/abs/2403.16858) | 本研究提出了一种用于早期采用可解释人工智能（XAI）的服务框架XAIport，具有解释质量、架构兼容性和可配置操作三个关键属性，为AI模型的开发提供可信的早期解释。 |
| [^20] | [An Expert is Worth One Token: Synergizing Multiple Expert LLMs as Generalist via Expert Token Routing](https://arxiv.org/abs/2403.16854) | 通过专家代币路由将多个专家LLM协同作为通用型，可以实现多个专家LLMs的无缝集成，支持隐式专业知识的学习和动态扩展新的专家LLMs，同时更好地隐藏协作细节，展现出比现有多LLM协作范式更好的效果和稳健性。 |
| [^21] | [Towards Explainability in Legal Outcome Prediction Models](https://arxiv.org/abs/2403.16852) | 先例是促进法律NLP模型可解释性的一种自然方式，我们提出了一种新颖的方法来识别法律结果预测模型使用的先例，并发现模型预测结果的能力不错，但其使用先例的方式与人类法官不同。 |
| [^22] | [Can ChatGPT predict article retraction based on Twitter mentions?](https://arxiv.org/abs/2403.16851) | 本研究探讨了ChatGPT是否能够基于Twitter提及来预测文章的撤回，研究发现在预测未来被撤回的有问题文章方面是具有一定潜力的。 |
| [^23] | [GreeDy and CoDy: Counterfactual Explainers for Dynamic Graphs](https://arxiv.org/abs/2403.16846) | 该论文介绍了两种针对动态图的新颖反事实解释方法：GreeDy和CoDy。实验证明，CoDy在寻找重要反事实输入方面表现优异，成功率高达59%。 |
| [^24] | [Do LLM Agents Have Regret? A Case Study in Online Learning and Games](https://arxiv.org/abs/2403.16843) | 通过研究在线学习和博弈论中的基准决策设置，评估LLM代理的交互行为和性能，以了解它们在多代理环境中的潜力和限制。 |
| [^25] | [UrbanVLP: A Multi-Granularity Vision-Language Pre-Trained Foundation Model for Urban Indicator Prediction](https://arxiv.org/abs/2403.16831) | UrbanVLP是一种多粒度信息集成的视觉语言预训练模型，旨在克服目前城市指标预测中预训练模型的局限性，提高了可解释性和精度 |
| [^26] | [Convergence of a model-free entropy-regularized inverse reinforcement learning algorithm](https://arxiv.org/abs/2403.16829) | 提出一个无模型的算法来解决熵正则化的逆强化学习问题，该算法能够使用有限样本恢复出专家表现最佳的奖励，并且最终得到的最优策略与专家策略非常接近。 |
| [^27] | [On Policy Reuse: An Expressive Language for Representing and Executing General Policies that Call Other Policies](https://arxiv.org/abs/2403.16824) | 一种表达通用策略和问题分解的语言引入了内部存储状态、索引特征和模块扩展，使得策略和草图更加灵活和可重用。 |
| [^28] | [Towards Human-AI Deliberation: Design and Evaluation of LLM-Empowered Deliberative AI for AI-Assisted Decision-Making](https://arxiv.org/abs/2403.16812) | 提出了人工智能和人类的辩论框架，通过LLM增强的辩论人工智能促进人类反思和讨论决策中的意见分歧。 |
| [^29] | [An LLM-Based Digital Twin for Optimizing Human-in-the Loop Systems](https://arxiv.org/abs/2403.16809) | 本文提出了一种利用大型语言模型(LLMs)来优化人在回路系统的方法，并通过案例研究展示了在购物中心中模拟各种人群热量偏好的应用。 |
| [^30] | [Navigating the EU AI Act: A Methodological Approach to Compliance for Safety-critical Products](https://arxiv.org/abs/2403.16808) | 通过利用产品质量模型和合同法方法，本文提出了一种解释欧盟AI法案对高风险AI系统要求的方法论途径。 |
| [^31] | [Cluster-Based Normalization Layer for Neural Networks](https://arxiv.org/abs/2403.16798) | 该论文提出了一种基于聚类的神经网络规范化方法CB-Norm，通过引入高斯混合模型，解决了梯度稳定性和学习加速方面的挑战。 |
| [^32] | [The Anatomy of Adversarial Attacks: Concept-based XAI Dissection](https://arxiv.org/abs/2403.16782) | 对抗性攻击对卷积神经网络学到的概念产生了实质性的影响，引入新概念或修改现有概念，并且这种影响可以通过线性分解对扰动进行解释。 |
| [^33] | [DeepKnowledge: Generalisation-Driven Deep Learning Testing](https://arxiv.org/abs/2403.16768) | DeepKnowledge提出了一种基于知识泛化理论的深度学习系统测试方法，旨在提高DNN的稳健性并减少黑匣子模型的风险。 |
| [^34] | [As Good As A Coin Toss Human detection of AI-generated images, videos, audio, and audiovisual stimuli](https://arxiv.org/abs/2403.16760) | 通过一项感知研究，评估了人们在日常生活中对合成图像、音频、视频和音视频刺激与真实的区分能力，以探讨人类对欺骗性合成媒体的易受程度。 |
| [^35] | [Bi-objective Optimization in Role Mining](https://arxiv.org/abs/2403.16757) | 该论文提出了角色挖掘中的双目标优化问题，引入了广义噪声角色挖掘问题（GNRM），并证明了其具有固定参数可解性，为解决角色挖掘中的实际问题提供了重要基础。 |
| [^36] | [All Artificial, Less Intelligence: GenAI through the Lens of Formal Verification](https://arxiv.org/abs/2403.16750) | 本文研究了再生人工智能中硬件设计中CWEs的形式验证，发现大多数大型语言模型在生成硬件代码时并未考虑硬件CWEs，导致大约60%的硬件设计存在漏洞。 |
| [^37] | [Enabling Uncertainty Estimation in Iterative Neural Networks](https://arxiv.org/abs/2403.16732) | 迭代神经网络中的新方法利用连续输出的收敛速率作为不确定性的有用代理，提供了比集成方法更低计算成本的先进不确定性估计。 |
| [^38] | [Improving Diffusion Models's Data-Corruption Resistance using Scheduled Pseudo-Huber Loss](https://arxiv.org/abs/2403.16728) | 使用定时伪Huber损失函数改进扩散模型的数据破坏抵抗力，可在保留高质量生成数据的同时提供鲁棒性，并在损坏数据集上展现更好性能。 |
| [^39] | [Towards a Formalisation of Value-based Actions and Consequentialist Ethics](https://arxiv.org/abs/2403.16719) | 该论文提出了一种基于代理人的价值配置和评估的行动框架，为满意的、众元的、以行动为基础的和首选的功利伦理提供了计算框架。 |
| [^40] | [One-Shot Domain Incremental Learning](https://arxiv.org/abs/2403.16707) | 提出了一种处理单次领域增量学习中批归一化层统计数据困难的技术，并展示了其有效性。 |
| [^41] | [Investigation of the effectiveness of applying ChatGPT in Dialogic Teaching Using Electroencephalography](https://arxiv.org/abs/2403.16687) | 探究将ChatGPT应用于对话教学在脑电图学中的有效性，研究发现在对话式教学场景中，ChatGPT能够有效履行教学角色，促进学生学习。 |
| [^42] | [Understanding the Functional Roles of Modelling Components in Spiking Neural Networks](https://arxiv.org/abs/2403.16674) | 系统研究揭示了尖峰神经网络中滤泄、重置和循环等建模组件在平衡记忆保留、时间处理和动态建模方面的功能角色。 |
| [^43] | [Deep Reinforcement Learning and Mean-Variance Strategies for Responsible Portfolio Optimization](https://arxiv.org/abs/2403.16667) | 研究利用深度强化学习进行负责任投资组合优化，并纳入ESG状态和目标，与修改后的均值-方差方法进行比较，结果显示深度强化学习策略在负责任投资组合分配方面具有竞争性表现 |
| [^44] | [Revisiting the Sleeping Beauty problem](https://arxiv.org/abs/2403.16666) | 《睡美人问题》从数学角度重新分析，确定了可能的概率空间选择，并提出了一个基于睡美人可获取信息的标准。 |
| [^45] | [CLHA: A Simple yet Effective Contrastive Learning Framework for Human Alignment](https://arxiv.org/abs/2403.16649) | CLHA提出了一种简单而有效的对比学习框架，可以帮助大型语言模型与人类偏好对齐，通过新颖的重评分策略和损失函数调整，在提升对齐效果的同时简化了训练过程。 |
| [^46] | [Deciphering the Interplay between Local Differential Privacy, Average Bayesian Privacy, and Maximum Bayesian Privacy](https://arxiv.org/abs/2403.16591) | 论文探讨了本地差分隐私、贝叶斯隐私及其之间的相互关系，揭示了关于效用-隐私权衡的新见解，并提出了一个框架来突出攻击和防御策略的相互作用和效果。 |
| [^47] | [In the Search for Optimal Multi-view Learning Models for Crop Classification with Global Remote Sensing Data](https://arxiv.org/abs/2403.16582) | 研究调查了在全球范围内同时选择融合策略和编码器架构对作物分类具有的影响。 |
| [^48] | [SegICL: A Universal In-context Learning Framework for Enhanced Segmentation in Medical Imaging](https://arxiv.org/abs/2403.16578) | SegICL引入了一种利用上下文学习的图像分割新方法，能够在新任务中适应医学图像分割，无需从头训练模型或进行复杂微调。 |
| [^49] | [NSINA: A News Corpus for Sinhala](https://arxiv.org/abs/2403.16571) | NSINA是为解决僧伽罗语中LLMs适应性挑战而引入的最大新闻语料库，为改进该语言的自然语言处理提供了宝贵资源和基准。 |
| [^50] | [FedFixer: Mitigating Heterogeneous Label Noise in Federated Learning](https://arxiv.org/abs/2403.16561) | 提出了FedFixer来解决联邦学习中异构标签噪声的问题，引入个性化模型与全局模型合作来有效选择干净的客户端特定样本，通过置信度正则化器和基于样本共享的双模型更新策略来减轻过拟合问题 |
| [^51] | [PE: A Poincare Explanation Method for Fast Text Hierarchy Generation](https://arxiv.org/abs/2403.16554) | 介绍了一种使用Poincaré解释方法在超几何空间中建模特征交互作用的新方法，并提出了时间复杂度为O(n^2logn)的框架，证明了在投影空间中进行的层次聚类过程可以视为构建最小生成树，提出了一个时间有效的算法 |
| [^52] | [QKFormer: Hierarchical Spiking Transformer using Q-K Attention](https://arxiv.org/abs/2403.16552) | QKFormer引入了新颖的脉冲形式Q-K注意力机制、分层结构和补丁嵌入模块，以提高脉冲变压器的性能。 |
| [^53] | [Efficient Information Extraction in Few-Shot Relation Classification through Contrastive Representation Learning](https://arxiv.org/abs/2403.16543) | 通过对比学习从多个句子表示中提取互补的判别信息，提高少样本关系分类中的信息提取效率 |
| [^54] | [An Intermediate Fusion ViT Enables Efficient Text-Image Alignment in Diffusion Models](https://arxiv.org/abs/2403.16530) | 通过一种中间融合的策略，可以提高文本到图像对齐的生成质量，并通过减少低秩文本到图像注意力计算来提高训练和推理效率。 |
| [^55] | [Hallucination Detection in Foundation Models for Decision-Making: A Flexible Definition and Review of the State of the Art](https://arxiv.org/abs/2403.16527) | 基于基础模型的幻觉检测旨在填补现有规划者缺少的常识推理，以适用于超出分布任务的场景。 |
| [^56] | [Harnessing the power of LLMs for normative reasoning in MASs](https://arxiv.org/abs/2403.16524) | 本文研究了利用LLMs为MAS中的agent赋予规范能力的潜力，并提出了创建具有规范功能的LLM agent的愿景。 |
| [^57] | [Causal Discovery from Poisson Branching Structural Causal Model Using High-Order Cumulant with Path Analysis](https://arxiv.org/abs/2403.16523) | 从计数数据中发现因果结构的关键挑战在于非可辨识性问题，本研究发现在泊松分支结构因果模型中，如果根顶点$X$是已知的，则可以确定从$X$到其子节点$Y$的因果顺序。 |
| [^58] | [LLMs Are Few-Shot In-Context Low-Resource Language Learners](https://arxiv.org/abs/2403.16512) | 该研究对25种低资源语言和7种相对较高资源语言上的情境学习（ICL）及其跨语言变体进行了研究，发现了在低资源语言中使用LLMs进行ICL的有效性，提出了替代方法查询对齐，并为低资源语言的ICL提供了宝贵见解。 |
| [^59] | [Return to Tradition: Learning Reliable Heuristics with Classical Machine Learning](https://arxiv.org/abs/2403.16508) | 通过使用WL算法生成特征，并结合经典机器学习方法，提出的WL-GOOSE方法可靠地学习规划启发式，性能优于$h^{\text{FF}}$启发式和LAMA，在特定领域取得了优异表现 |
| [^60] | [Learning To Guide Human Decision Makers With Vision-Language Models](https://arxiv.org/abs/2403.16501) | 提出了“学习指导”（LTG）框架，旨在解决专家可能过度依赖机器决策和面临无助于模型放弃的决策的问题。 |
| [^61] | [LSTTN: A Long-Short Term Transformer-based Spatio-temporal Neural Network for Traffic Flow Forecasting](https://arxiv.org/abs/2403.16495) | LSTTN框架综合考虑历史交通流量中的长期和短期特征，通过掩码子序列Transformer解决了现有STGNNs模型只能利用短程交通流量数据的限制，实现了对交通流量复杂趋势和周期特征的充分学习 |
| [^62] | [FedAC: A Adaptive Clustered Federated Learning Framework for Heterogeneous Data](https://arxiv.org/abs/2403.16460) | FedAC框架通过解耦神经网络，使用不同聚合方法为每个子模块提供全局知识，引入经济高效的在线模型相似度度量，及集群数量微调模块，显著提高了性能。 |
| [^63] | [DeepMachining: Online Prediction of Machining Errors of Lathe Machines](https://arxiv.org/abs/2403.16451) | DeepMachining是一种基于深度学习的AI系统，可以在线预测车床机床加工操作的误差，通过预训练和微调模型，实现了高准确性预测，是首批使用预训练深度学习模型预测车床机床加工误差的工厂实验之一。 |
| [^64] | [CodeS: Natural Language to Code Repository via Multi-Layer Sketch](https://arxiv.org/abs/2403.16443) | CodeS提出了一个新的软件工程任务NL2Repo，旨在从自然语言需求中生成整个代码仓库，通过多层草图的方式解决这一任务。 |
| [^65] | [$\textit{LinkPrompt}$: Natural and Universal Adversarial Attacks on Prompt-based Language Models](https://arxiv.org/abs/2403.16432) | 基于提示的语言模型的优化过程揭示了生成对抗提示以误导模型的见解，引发了对该范式对抗性脆弱性的担忧。 |
| [^66] | [DOCTR: Disentangled Object-Centric Transformer for Point Scene Understanding](https://arxiv.org/abs/2403.16431) | 提出了一种新颖的Disentangled Object-Centric Transformer (DOCTR)，旨在以统一的方式便利多个对象学习点场景理解的多个子任务，并引入了语义-几何解耦查询设计来优化对象之间的关系。 |
| [^67] | [Re2LLM: Reflective Reinforcement Large Language Model for Session-based Recommendation](https://arxiv.org/abs/2403.16427) | Re2LLM是为基于会话的推荐提出的反射式强化大型语言模型，引导LLMs专注于更准确推荐所需的专业知识，实现有效和高效。 |
| [^68] | [An Experiment with the Use of ChatGPT for LCSH Subject Assignment on Electronic Theses and Dissertations](https://arxiv.org/abs/2403.16424) | 该研究探讨了利用大型语言模型生成美国国会图书馆主题标头的潜力，展示了其对于解决学术图书馆待编目项目积压问题具有战略应对意义，同时也强调了人类编目员仍然在验证和增强生成主题标头方面的重要性。 |
| [^69] | [Refining Text-to-Image Generation: Towards Accurate Training-Free Glyph-Enhanced Image Generation](https://arxiv.org/abs/2403.16422) | 通过引入LenCom-Eval基准测试，研究者发现基于扩散模型的文本到图像生成方法仍面临三个主要挑战，并为未来研究提供了一个测试平台。 |
| [^70] | [An incremental MaxSAT-based model to learn balanced rules](https://arxiv.org/abs/2403.16418) | 提出了一种基于递增式MaxSAT的学习平衡规则模型IMLIB，结合了SAT和MaxSAT方法，限制规则大小以实现平衡，并提高模型性能。 |
| [^71] | [How Reliable is Your Simulator? Analysis on the Limitations of Current LLM-based User Simulators for Conversational Recommendation](https://arxiv.org/abs/2403.16416) | 通过对LLMs构建CRS用户模拟器的局限性进行分析，为指导未来研究提供了重要见解。 |
| [^72] | [Rethinking the Representation in Federated Unsupervised Learning with Non-IID Data](https://arxiv.org/abs/2403.16398) | 提出了FedU2方法，通过灵活的统一正则化器（FUR）和高效的统一聚合器（EUA），增强了在具有非IID数据的FUSL中生成统一和统一表示。 |
| [^73] | [RadioGAT: A Joint Model-based and Data-driven Framework for Multi-band Radiomap Reconstruction via Graph Attention Networks](https://arxiv.org/abs/2403.16397) | RadioGAT提出了一种基于图注意力网络的框架，用于解决多频带射频地图重建中的挑战，创新地将模型建模和数据驱动的方法相结合，消除了对多区域数据集的需求。 |
| [^74] | [Skews in the Phenomenon Space Hinder Generalization in Text-to-Image Generation](https://arxiv.org/abs/2403.16394) | 文本到图像生成领域的泛化问题源于现象空间中的偏差，需要量化和解决语言和视觉偏差，以提高泛化性能 |
| [^75] | [Concurrent Linguistic Error Detection (CLED) for Large Language Models](https://arxiv.org/abs/2403.16393) | 提出了一种针对大型语言模型的并发语言错误检测方案，通过提取文本的语言特征并使用分类器进行错误检测。 |
| [^76] | [Dia-LLaMA: Towards Large Language Model-driven CT Report Generation](https://arxiv.org/abs/2403.16386) | 通过引入诊断信息作为引导提示，Dia-LLaMA框架将LLaMA2-7B适应于CT报告生成，解决了正常和异常案例分布不平衡以及常见模板句子淹没关键异常信息的挑战。 |
| [^77] | [Learning Action-based Representations Using Invariance](https://arxiv.org/abs/2403.16369) | 提出了一种新的方法，动作双模拟编码，通过递归不变性约束扩展了单步控制性，学习了一个可以平滑折扣远期元素的多步控制度量 |
| [^78] | [ChatDBG: An AI-Powered Debugging Assistant](https://arxiv.org/abs/2403.16354) | ChatDBG是第一个AI-Powered调试助手，通过将大型语言模型集成到传统调试器中，实现了程序员与调试器之间的协作对话，能够处理复杂问题、执行根本原因分析，并探索开放性查询。 |
| [^79] | [ChatGPT Incorrectness Detection in Software Reviews](https://arxiv.org/abs/2403.16347) | 开发了一种名为CID的工具，通过迭代提示ChatGPT并要求提出情境相似但文本有分歧的问题，来自动测试和检测ChatGPT响应中的不正确性。 |
| [^80] | [Enhanced Facet Generation with LLM Editing](https://arxiv.org/abs/2403.16345) | 提出了一种通过利用搜索引擎获取的文档和相关查询来增强分面预测的策略，并提出了专注于仅使用查询作为输入来预测分面的框架 |
| [^81] | [Impact of Video Compression Artifacts on Fisheye Camera Visual Perception Tasks](https://arxiv.org/abs/2403.16338) | 本研究对标准视频压缩编解码器对广角鱼眼相机的影响进行了首次分析，以证明有损视频压缩畸变不会对感知算法的性能产生影响。 |
| [^82] | [Graphs Generalization under Distribution Shifts](https://arxiv.org/abs/2403.16334) | 本文介绍了一种名为GLIDER的新框架，旨在解决图结构数据中分布转移带来的挑战，并实现泛化性能优越。 |
| [^83] | [Artificial Neural Microcircuits as Building Blocks: Concept and Challenges](https://arxiv.org/abs/2403.16327) | 本文探索了一种新的方法，在生物学中神经微电路的启发下，使用人工神经微电路作为组装大型神经网络的基本构建模块，避免了结构上的齐质化所带来的复杂训练和学习工具的问题。 |
| [^84] | [Large Language Models in Biomedical and Health Informatics: A Bibliometric Review](https://arxiv.org/abs/2403.16303) | LLMs已成为生物医学与健康信息学中重要的工具，本文献计量学综述全面展示了LLMs在各种BHI领域中的应用，提出了其对自然语言处理应用的改进，揭示了主要发展趋势和研究网络，并讨论了伦理关切和实际挑战。 |
| [^85] | [Guessing human intentions to avoid dangerous situations in caregiving robots](https://arxiv.org/abs/2403.16291) | 本文探讨了在照料机器人中使用人工心智理论来猜测人类意图，提出了一种检测危险情况并实时消除危险的算法，在模拟实验中取得了高成功率。 |
| [^86] | [Engineering Safety Requirements for Autonomous Driving with Large Language Models](https://arxiv.org/abs/2403.16289) | 该研究提出了利用大型语言模型自动优化和拆分安全需求的管道，通过评估LLMs的能力，并识别多余或矛盾的需求，为解决自动驾驶领域中需求变更频繁的挑战提供了新思路。 |
| [^87] | [AVicuna: Audio-Visual LLM with Interleaver and Context-Boundary Alignment for Temporal Referential Dialogue](https://arxiv.org/abs/2403.16276) | 介绍了一个新的框架AVicuna，生成了PU-VALOR数据集，解决了音频-视觉时间指代对话中的两个主要挑战：缺乏准确时间注释的数据集和整合复杂时间线索的方法。 |
| [^88] | [L-MAE: Longitudinal masked auto-encoder with time and severity-aware encoding for diabetic retinopathy progression prediction](https://arxiv.org/abs/2403.16272) | 本文提出了一种纵向遮罩自动编码器（MAE），采用时间感知位置嵌入和疾病进展感知掩蔽，用于预测糖尿病视网膜病变进展，旨在更准确评估疾病进展。 |
| [^89] | [Out-of-Distribution Detection via Deep Multi-Comprehension Ensemble](https://arxiv.org/abs/2403.16260) | 通过引入新颖的定性和定量模型集成评估方法，作者揭示了现有集成方法的关键缺陷，提出了提高传统模型集成维度的方法，以克服特征表示中的多样性限制。 |
| [^90] | [On machine learning analysis of atomic force microscopy images for image classification, sample surface recognition](https://arxiv.org/abs/2403.16230) | 该论文探讨了在使用相对较少的原子力显微镜图像和小数据库时，应用机器学习进行识别/分类，讨论了除深度学习神经网络之外的机器学习方法。 |
| [^91] | [Cyber-Security Knowledge Graph Generation by Hierarchical Nonnegative Matrix Factorization](https://arxiv.org/abs/2403.16222) | 本文介绍了一种通过从科学论文中提取结构化本体来构建网络安全领域多模态知识图的方法 |
| [^92] | [CoverUp: Coverage-Guided LLM-Based Test Generation](https://arxiv.org/abs/2403.16218) | CoverUp通过覆盖率分析和大型语言模型相结合的方式，驱动生成高覆盖率的Python回归测试，并在改进覆盖率方面取得显著成就。 |
| [^93] | [Frankenstein: Generating Semantic-Compositional 3D Scenes in One Tri-Plane](https://arxiv.org/abs/2403.16210) | Frankenstein是一个框架，可以在单个通道中同时生成多个语义相关的3D形状，为生成房间内部和人类化身等场景提供了有希望的结果。 |
| [^94] | [Image Captioning in news report scenario](https://arxiv.org/abs/2403.16209) | 本论文探索了专门针对名人照片的图像描述，旨在增强新闻行业实践，并提出了对自动新闻内容生成的改进方法。 |
| [^95] | [Rumor Detection with a novel graph neural network approach](https://arxiv.org/abs/2403.16206) | 本论文提出了一种新颖的检测模型，同时学习用户相关性和信息传播的表示，以检测社交媒体上的谣言 |
| [^96] | [Logic-based Explanations for Linear Support Vector Classifiers with Reject Option](https://arxiv.org/abs/2403.16190) | 提出了一种基于逻辑的方法，针对具有拒绝选项的线性SVC，提供了正确性和极小性保证的解释，相比启发式算法Anchors，我们的方法给出了更短的解释 |
| [^97] | [Mixed-Initiative Human-Robot Teaming under Suboptimality with Online Bayesian Adaptation](https://arxiv.org/abs/2403.16178) | 该论文研究了在次优情况下进行在线贝叶斯适应的混合倡议人机协作的计算建模和优化技术，能够推断人们在协作中是否愿意遵从机器人的帮助。 |
| [^98] | [An Analytic Solution to Covariance Propagation in Neural Networks](https://arxiv.org/abs/2403.16163) | 该论文提出了一种无需样本的矩传播技术，能够准确表征神经网络的输入输出分布，其关键创新在于提供了通过非线性激活函数传递的随机变量协方差的解析解。 |
| [^99] | [Multi-Task Learning with Multi-Task Optimization](https://arxiv.org/abs/2403.16162) | 本文提出了一种通过多任务优化视角看待帕累托多任务学习的方法，将多任务学习转化为多目标优化问题，并通过独特的多任务梯度下降方法联合解决多个子问题，从而实现一组优化且分布良好的模型。 |
| [^100] | [One Masked Model is All You Need for Sensor Fault Detection, Isolation and Accommodation](https://arxiv.org/abs/2403.16153) | 提出了一种使用掩盖模型和自监督学习进行传感器故障检测、隔离和容错的新框架，通过训练过程中创建随机掩码来统一找到并纠正故障传感器，有效性在公共数据集和实际风力涡轮数据集上得到验证。 |
| [^101] | [A Survey on Consumer IoT Traffic: Security and Privacy](https://arxiv.org/abs/2403.16149) | 本调查针对消费者物联网（CIoT）流量分析从安全和隐私的角度出发，总结了CIoT流量分析的新特征、最新进展和挑战，认为通过流量分析可以揭示CIoT领域中的安全和隐私问题。 |
| [^102] | [What Happens to a Dataset Transformed by a Projection-based Concept Removal Method?](https://arxiv.org/abs/2403.16142) | 一种基于投影的概念去除方法会在转换后的数据集中注入强大的统计依赖性，并导致表示空间高度结构化，使得可以通过应用反聚类方法重建原始标记。 |
| [^103] | [Complementary Recommendation in E-commerce: Definition, Approaches, and Future Directions](https://arxiv.org/abs/2403.16135) | 本文全面总结和比较了电子商务领域中34项代表性互补推荐研究，包括建模产品之间的互补关系，不同研究问题下的模型分类与比较，以及在同一数据集上进行的实验结果分析。 |
| [^104] | [SSHPool: The Separated Subgraph-based Hierarchical Pooling](https://arxiv.org/abs/2403.16133) | 提出了基于分隔子图的分层池化（SSHPool）方法，通过将节点分配到不同的簇并利用局部图卷积单元进行压缩，解决了现有图神经网络中的过度平滑问题，有效提取了原始图结构的分层全局特征。 |
| [^105] | [AKBR: Learning Adaptive Kernel-based Representations for Graph Classification](https://arxiv.org/abs/2403.16130) | 提出了一种用于图分类的自适应核表示学习模型，通过特征通道注意机制捕捉不同子结构之间的相互依赖关系，有效识别结构重要性，并计算与重要子结构相关的图对之间的R-卷积核。 |
| [^106] | [WangchanLion and WangchanX MRC Eval](https://arxiv.org/abs/2403.16127) | WangchanLion是一个专注于泰语机器阅读理解的指令微调模型，在0-shot和1-shot设置下能够理解上下文并产生与参考答案一致的回答，同时提出了新的评估方案。 |
| [^107] | [Self-Supervised Multi-Frame Neural Scene Flow](https://arxiv.org/abs/2403.16116) | 通过研究表明，Neural Scene Flow Prior (NSFP)的性能与输入点云的数量呈反比关系，因此我们提出了一种简单而有效的多帧点云场景流估计方法。 |
| [^108] | [Opportunities and challenges in the application of large artificial intelligence models in radiology](https://arxiv.org/abs/2403.16112) | 本文介绍了大型人工智能模型在放射学中的应用，总结了其在放射学教育、报告生成和影像应用方面的最新研究进展，并指出了大型AI模型在放射学中面临的挑战，旨在推动该领域的快速革命。 |
| [^109] | [A Transformer approach for Electricity Price Forecasting](https://arxiv.org/abs/2403.16108) | 这种独特的Transformer模型在电力价格预测中取得了更好的表现，为可靠和可持续的电力系统运行提供了有前景的解决方案。 |
| [^110] | [Evaluating Fairness Metrics Across Borders from Human Perceptions](https://arxiv.org/abs/2403.16101) | 该研究通过国际调查评估了不同国家对其决策情景中各种公平度量标准的适用性。 |
| [^111] | [Specifying Agent Ethics (Blue Sky Ideas)](https://arxiv.org/abs/2403.16100) | 论文讨论了机器伦理系统应该具备的属性，并挑战社区以更系统化的方式探讨这个问题。 |
| [^112] | [Can Language Models Pretend Solvers? Logic Code Simulation with LLMs](https://arxiv.org/abs/2403.16097) | 这项研究探讨了一种新颖的任务，即逻辑代码模拟，迫使LLMs在预测逻辑程序的结果时模拟逻辑求解器，同时提出了三个研究问题以深入调查这一任务对LLMs的影响。 |
| [^113] | [The Interplay of Learning, Analytics, and Artificial Intelligence in Education](https://arxiv.org/abs/2403.16081) | 本文提出了 AI 在学习和教育中的多维视角，强调了 AI、分析和学习过程之间错综复杂的相互作用，挑战了将 AI 视为随机工具的观念，强调了 AI 作为理解人类学习的重要性，并提出了三种独特的教育中人工智能的概念化。 |
| [^114] | [Landmark-Guided Cross-Speaker Lip Reading with Mutual Information Regularization](https://arxiv.org/abs/2403.16071) | 通过利用唇部地标引导的细粒度视觉线索，提出了一种适应说话人的唇读模型，有效降低说话人之间的视觉变化。 |
| [^115] | [Robust Diffusion Models for Adversarial Purification](https://arxiv.org/abs/2403.16067) | 提出一种独立于预训练扩散模型的稳健反向过程，避免了重新训练或微调，有效处理对抗净化中的语义信息损失问题。 |
| [^116] | [A Temporal Graph Network Framework for Dynamic Recommendation](https://arxiv.org/abs/2403.16066) | 该研究首次将时间图网络（TGN）直接应用于推荐系统，展示了其在动态推荐场景中的有效性。 |
| [^117] | [Qibo: A Large Language Model for Traditional Chinese Medicine](https://arxiv.org/abs/2403.16056) | 本论文在中医领域构建了专业语料库，基于LLaMA成功开发了首个经过完整训练的Qibo模型，并推出了用于评估LLMs性能的Qibo基准测试。 |
| [^118] | [Semantic Is Enough: Only Semantic Information For NeRF Reconstruction](https://arxiv.org/abs/2403.16043) | 该研究展示了NeRF模型在重建3D结构中仅利用语义信息的优秀表现，通过去除RGB输出组件，模型训练过程重点关注语义输出与地面真实图像之间的交叉熵损失。 |
| [^119] | [RPMArt: Towards Robust Perception and Manipulation for Articulated Objects](https://arxiv.org/abs/2403.16023) | 提出了面向关节对象的健壮感知和操作框架RPMArt，主要贡献是能够稳健地预测关节参数和可信点的RoArtNet。 |
| [^120] | [Fill in the ____ (a Diffusion-based Image Inpainting Pipeline)](https://arxiv.org/abs/2403.16016) | 本文提出了一个基于扩散的图像修复流程，弥补了现有模型在促进和控制生成内容方面的关键差距。 |
| [^121] | [A Federated Parameter Aggregation Method for Node Classification Tasks with Different Graph Network Structures](https://arxiv.org/abs/2403.16004) | 提出了一种适用于具有不同图网络结构的节点分类任务的联邦参数聚合方法FLGNN，并验证了其有效性。同时，设计了隐私安全的成员推理攻击实验和差分隐私防御实验。 |
| [^122] | [Diverse Representation Embedding for Lifelong Person Re-Identification](https://arxiv.org/abs/2403.16003) | 提出了一种多元表示嵌入(DRE)框架，用于终身人员再识别(LReID)，可以在学习新信息的同时有效保留旧知识，通过自适应约束模块(ACM)实现多个表示之间的整合和推开操作，为每个实例获取密集嵌入子空间，提高有限旧任务数据集上的匹配能力。 |
| [^123] | [Multi-Scale Spatio-Temporal Graph Convolutional Network for Facial Expression Spotting](https://arxiv.org/abs/2403.15994) | 本文提出了一种多尺度时空图卷积网络（SpoT-GCN），通过引入感受野自适应滑动窗口策略来有效识别面部表情，学习面部图模式以增强微小运动特征的提取。 |
| [^124] | [Knowledge-guided Machine Learning: Current Trends and Future Prospects](https://arxiv.org/abs/2403.15989) | 知识引导的机器学习（KGML）结合科学知识和数据在机器学习框架中，以实现更好的泛化能力、科学一致性和结果可解释性。 |
| [^125] | [Towards Two-Stream Foveation-based Active Vision Learning](https://arxiv.org/abs/2403.15977) | 本研究提出了一个受“双流假设”启发的机器学习框架，通过模拟人类视觉系统的工作原理，分为腹侧流和背侧流两部分，以实现对焦和处理图像patch的序列。 |
| [^126] | [CBGT-Net: A Neuromimetic Architecture for Robust Classification of Streaming Data](https://arxiv.org/abs/2403.15974) | CBGT-Net是一种受CBGT回路启发的神经网络模型，通过积累足够的证据后才对流数据产生分类决策，在图像分类任务中表现出更高的准确性和稳健性。 |
| [^127] | [Detection of Problem Gambling with Less Features Using Machine Learning Methods](https://arxiv.org/abs/2403.15962) | 提出了一种使用更少的特征进行问题赌博检测的深度神经网络模型，并发现在不影响性能的情况下可以将特征从102个减少到5个。 |
| [^128] | [SAT Encoding of Partial Ordering Models for Graph Coloring Problems](https://arxiv.org/abs/2403.15961) | 该研究提出了新的SAT编码的偏序模型用于图着色问题，实验结果显示在一些情况下超越了现有的最先进方法，并对带宽着色问题进行了理论分析。 |
| [^129] | [Finding needles in a haystack: A Black-Box Approach to Invisible Watermark Detection](https://arxiv.org/abs/2403.15955) | 提出了一种透明水印检测的黑盒方法WMD，在无注释设置下，利用干净无水印数据集检测任意水印，效果显著优于传统方法 |
| [^130] | [Understanding The Effectiveness of Lossy Compression in Machine Learning Training Sets](https://arxiv.org/abs/2403.15953) | 深入探究损失压缩对模型质量的影响，发现现代损失压缩方法可以在保证质量损失在1%以下的情况下实现50-100倍的压缩比提升。 |
| [^131] | [Adaptive Super Resolution For One-Shot Talking-Head Generation](https://arxiv.org/abs/2403.15944) | 该论文提出了一种自适应高质量说唱头视频生成方法，可以合成高分辨率视频，无需额外的预训练模块。 |
| [^132] | [Explore until Confident: Efficient Exploration for Embodied Question Answering](https://arxiv.org/abs/2403.15941) | 通过利用大型视觉-语言模型的语义推理能力，结合深度信息和视觉提示，提出了一种方法来解决具身问答中的有效探索和回答问题的挑战 |
| [^133] | [Geotokens and Geotransformers](https://arxiv.org/abs/2403.15940) | 本文提出了地理代币的概念，将其作为变压器的输入组件与具体地理位置联系起来，设计了一种针对球面坐标的位置编码方法。 |
| [^134] | [LlamBERT: Large-scale low-cost data annotation in NLP](https://arxiv.org/abs/2403.15938) | LlamBERT是一种利用大规模语言模型注释未标记数据库并用于微调变压器编码器的混合方法，在降低成本的同时略微牺牲准确性。 |
| [^135] | [Understanding Domain-Size Generalization in Markov Logic Networks](https://arxiv.org/abs/2403.15933) | 本文量化了马尔科夫逻辑网络在不同大小领域间内部一致性缺失的问题，并提出最大化数据对数似然同时最小化参数方差的方式来优化领域大小泛化。 |
| [^136] | [X-Portrait: Expressive Portrait Animation with Hierarchical Motion Attention](https://arxiv.org/abs/2403.15931) | 这里是中文总结出的一句话要点: 该论文提出了X-Portrait，一种用于生成具有表现力和时间连贯性的肖像动画的条件扩散模型，利用控制信号实现了细粒度头部姿势和表情控制，以提高运动精度。 |
| [^137] | [Multi-agent transformer-accelerated RL for satisfaction of STL specifications](https://arxiv.org/abs/2403.15916) | 提出了一种使用时间相关多智能体变压器的方法，能够通过集中式方法高效解决多智能体问题，在两个问题上展现出明显优于基线算法的性能。 |
| [^138] | [MatchSeg: Towards Better Segmentation via Reference Image Matching](https://arxiv.org/abs/2403.15901) | 通过引入MatchSeg框架，利用对比语言-图像预训练和联合注意力模块增强了医学图像分割，有效实现了支持集和查询集之间的知识转移。 |
| [^139] | [Leveraging Zero-Shot Prompting for Efficient Language Model Distillation](https://arxiv.org/abs/2403.15886) | 通过利用零-shot提示来引出教师模型的理由，减少手工制作的少-shot示例的必要性，并降低所需的总记号数，这直接转化为成本节约。 |
| [^140] | [TrustSQL: A Reliability Benchmark for Text-to-SQL Models with Diverse Unanswerable Questions](https://arxiv.org/abs/2403.15879) | TrustSQL是一个旨在评估文本到SQL模型在处理各种类型问题时的可靠性的新基准，要求模型在SQL预测和放弃预测两种情况下进行评估。 |
| [^141] | [Cognitive resilience: Unraveling the proficiency of image-captioning models to interpret masked visual content](https://arxiv.org/abs/2403.15876) | 该研究发现图像字幕模型在解释遮蔽的视觉内容时表现出很强的能力，即使部分区域被遮蔽，模型仍能准确生成描述性的文本信息。 |
| [^142] | [LAMPER: LanguAge Model and Prompt EngineeRing for zero-shot time series classification](https://arxiv.org/abs/2403.15875) | LAMPER框架旨在评估预训练语言模型在零样本时间序列分类中的适应能力，研究发现其特征表示能力受到PLMs最大输入标记阈值的影响。 |
| [^143] | [Using Large Language Models for OntoClean-based Ontology Refinement](https://arxiv.org/abs/2403.15864) | 本文研究了利用大型语言模型（LLMs）如GPT-3.5和GPT-4来增强OntoClean方法论中的本体重构过程，通过两种提示策略展示了高标记准确性，提出了为本体工具开发插件软件以促进整合的潜力。 |
| [^144] | [Automated System-level Testing of Unmanned Aerial Systems](https://arxiv.org/abs/2403.15857) | 本文提出了一种利用模型测试和人工智能技术自动生成、执行和评估无人机系统级测试的新颖方法。 |
| [^145] | [Initialisation and Topology Effects in Decentralised Federated Learning](https://arxiv.org/abs/2403.15855) | 分散式联邦学习的有效性受到连接设备网络拓扑结构的显著影响，我们提出了基于底层网络节点特征向量中心性分布的改进神经网络初始化策略，大大提高了训练效率。 |
| [^146] | [When LLM-based Code Generation Meets the Software Development Process](https://arxiv.org/abs/2403.15852) | 该研究引入了基于LLM的代码生成框架LCG，通过模拟各种软件过程模型以及利用协作和技术提高代码质量。评估结果表明其在代码生成基准上的有效性。 |
| [^147] | [ARO: Large Language Model Supervised Robotics Text2Skill Autonomous Learning](https://arxiv.org/abs/2403.15834) | ARO框架旨在通过大型语言模型实现机器人技能的自主学习，使其能够在无需人类干预的情况下完成部分任务，同时还分析了该方法的局限性。 |
| [^148] | [Scaling Learning based Policy Optimization for Temporal Tasks via Dropout](https://arxiv.org/abs/2403.15826) | 本文介绍了一种基于模型的方法用于训练在高度非线性环境中运行的自主智能体的反馈控制器，通过对任务进行形式化表述，实现对特定任务目标的定量满足语义，并利用前馈神经网络学习反馈控制器。 |
| [^149] | [Carbon Intensity-Aware Adaptive Inference of DNNs](https://arxiv.org/abs/2403.15824) | 通过基于碳排放强度的自适应模型选择，本研究提出的方法能够在低碳强度时段使用更高准确性的模型，在高碳强度时段使用更低准确性的模型，有效改善视觉识别服务的准确性，最多提高碳排放效率达80%。 |
| [^150] | [The Impact of Evolutionary Computation on Robotic Design: A Case Study with an Underactuated Hand Exoskeleton](https://arxiv.org/abs/2403.15812) | 本研究探讨了进化计算方法在机器人设计优化中的潜力，并通过欠驱动手外骨骼案例研究展示，进化计算方法相较于蛮力方法，能够在更短时间内获得更精确和更优化的解决方案，从而提高设计的优化。 |
| [^151] | [Efficient Data Access Paths for Mixed Vector-Relational Search](https://arxiv.org/abs/2403.15807) | 提出了针对高效混合向量-关系搜索的替代数据访问路径设计和优化方法。 |
| [^152] | [Understanding Emergent Abilities of Language Models from the Loss Perspective](https://arxiv.org/abs/2403.15796) | 本文从损失角度重新定义了语言模型的突现能力，发现具有相同预训练损失的模型在不同任务上表现相似，而当预训练损失低于特定阈值时，模型将展现出突现能力。 |
| [^153] | [The Frontier of Data Erasure: Machine Unlearning for Large Language Models](https://arxiv.org/abs/2403.15779) | 本文回顾了针对大型语言模型的机器遗忘的最新进展，提出了解决隐私、道德和法律挑战的针对性遗忘信息的方法，而不需要进行完整模型重新训练，并展示了这些方法在保持模型有效性的同时删除特定数据的有效性。 |
| [^154] | [Modeling Unified Semantic Discourse Structure for High-quality Headline Generation](https://arxiv.org/abs/2403.15776) | 通过将文档级修辞结构理论（RST）树与句级抽象意义表示（AMR）图结合起来构建S3图，形成统一的语义话语结构，用于标题生成框架中，进一步设计了分层结构修剪机制，提高标题生成的效果。 |
| [^155] | [FusionINN: Invertible Image Fusion for Brain Tumor Monitoring](https://arxiv.org/abs/2403.15769) | FusionINN引入了一种新颖的可逆图像融合框架，可以高效生成融合图像，并解开融合过程的逆向分解，保证无损的像素映射。 |
| [^156] | [BEND: Bagging Deep Learning Training Based on Efficient Neural Network Diffusion](https://arxiv.org/abs/2403.15766) | 本文提出了一种基于神经网络扩散模型的Bagging深度学习训练算法（BEND），有效构建了多个基本分类器，简单而有效。 |
| [^157] | [Towards Human-Like Machine Comprehension: Few-Shot Relational Learning in Visually-Rich Documents](https://arxiv.org/abs/2403.15765) | 该研究聚焦于在视觉丰富文档中进行少样本关系学习，引入了基于现有监督基准数据集构建的两个新的少样本基准，提出了一种包含关系二维空间先验和样本矫正的变分方法 |
| [^158] | [An Upload-Efficient Scheme for Transferring Knowledge From a Server-Side Pre-trained Generator to Clients in Heterogeneous Federated Learning](https://arxiv.org/abs/2403.15760) | 通过将预训练生成器的知识传输给客户端，提出了一种上传高效的联合知识传输方案，成功解决了异构联合学习中的数据和模型异构性问题。 |
| [^159] | [User-Side Realization](https://arxiv.org/abs/2403.15757) | 用户端实现为用户提供了积极的解决方案，通过在用户端运行通用算法来解决常见问题，无需服务提供商改变服务本身。 |
| [^160] | [Leveraging Large Language Models for Preliminary Security Risk Analysis: A Mission-Critical Case Study](https://arxiv.org/abs/2403.15756) | 大型语言模型在初步安全风险分析中展现了比人类更快速的信息总结能力，本研究通过案例研究探讨了微调模型在协助从业者进行PSRA方面的实用性。 |
| [^161] | [CodeShell Technical Report](https://arxiv.org/abs/2403.15747) | CodeShell-Base是一个70亿参数规模的基础模型，在代码理解方面表现出色，并通过集成Grouped-Query Attention和Rotary Positional Embedding等技术形成独特的架构设计。 |
| [^162] | [A Comparative Study of Artificial Potential Fields and Safety Filters](https://arxiv.org/abs/2403.15743) | 本文通过将人工势场信息整合到CBF-QP框架中，建立了人工势场与安全滤波器之间的连接，并扩展了CBF-QP安全滤波器的设计以适应更一般的动力学模型，从而提供了一种适用于控制仿射动力学模型的一般APF解决方案。 |
| [^163] | [Towards a \textbf{RAG}-based Summarization Agent for the Electron-Ion Collider](https://arxiv.org/abs/2403.15729) | 开发了一种面向电子离子对撞机的基于RAG的摘要生成代理，能够压缩信息并引用相关回复，为合作者提供重大优势 |
| [^164] | [Learnable WSN Deployment of Evidential Collaborative Sensing Model](https://arxiv.org/abs/2403.15728) | 本文提出了一种通过协同感知模型和证据理论框架下的组合规则，来提高WSNs检测能力的学习型传感器部署网络（LSDNet）。 |
| [^165] | [PEaCE: A Chemistry-Oriented Dataset for Optical Character Recognition on Scientific Documents](https://arxiv.org/abs/2403.15724) | 提出了PEaCE数据集，利用其中的合成和真实记录评估了基于transformer的OCR模型在化学文献中的识别效果，并提出可以模拟真实记录特征的转换。 |
| [^166] | [Distributed Robust Learning based Formation Control of Mobile Robots based on Bioinspired Neural Dynamics](https://arxiv.org/abs/2403.15716) | 本文提出了一种基于生物启发神经动力学的方法，通过引入分布式估计器、运动学跟踪控制和学习鲁棒动态控制器，有效解决了移动机器人分布式编队控制的挑战，并通过数学分析证明了方法的稳定性。 |
| [^167] | [Contact-aware Human Motion Generation from Textual Descriptions](https://arxiv.org/abs/2403.15709) | 本研究提出了一种新的方法CATMO，通过整合物理接触信息，从文本描述中生成视觉自然且物理合理的3D人体动作。 |
| [^168] | [Role of Locality and Weight Sharing in Image-Based Tasks: A Sample Complexity Separation between CNNs, LCNs, and FCNs](https://arxiv.org/abs/2403.15707) | 介绍了新的Dynamic Signal Distribution (DSD)分类任务，模拟图像由$k$个维度为$d$的补丁组成，以解决CNNs相对于LCNs和FCNs的统计优势问题 |
| [^169] | [SceneX:Procedural Controllable Large-scale Scene Generation via Large-language Models](https://arxiv.org/abs/2403.15698) | 通过大型语言模型驱动程序化建模，提出了一个大规模场景生成框架SceneX，可以自动生成高质量的程序化模型 |
| [^170] | [MixRED: A Mix-lingual Relation Extraction Dataset](https://arxiv.org/abs/2403.15696) | 论文提出了一个新的多语言关系抽取任务MixRE，并构建了支持该任务的人工注释数据集MixRED，填补了多语言情景下关系抽取研究的空白。 |
| [^171] | [EAGLE: A Domain Generalization Framework for AI-generated Text Detection](https://arxiv.org/abs/2403.15690) | EAGLE提出了一个领域泛化框架，能够利用从旧语言模型中获得的标记数据，学习特征的不变性，从而检测出未知目标生成器生成的文本。 |
| [^172] | [SRLM: Human-in-Loop Interactive Social Robot Navigation with Large Language Model and Deep Reinforcement Learning](https://arxiv.org/abs/2403.15648) | SRLM 提出了一种结合了大型语言模型和深度强化学习的新型混合方法，用于人机交互式社交机器人导航，通过实时的人类语言指令推断全局规划，并在公共空间中提供多种社交服务，表现出出色的性能。 |
| [^173] | [Application of the NIST AI Risk Management Framework to Surveillance Technology](https://arxiv.org/abs/2403.15646) | 本研究深入探讨了将国家标准与技术研究所的人工智能风险管理框架（NIST AI RMF）应用于监控技术领域的意义，提出了针对面部识别技术的风险管理策略，旨在推动负责任的人工智能利用实践。 |
| [^174] | [Contextual Restless Multi-Armed Bandits with Application to Demand Response Decision-Making](https://arxiv.org/abs/2403.15640) | 提出了一种Contextual Restless Bandits (CRB)框架，能够同时建模每个臂的内部状态转换和外部全局环境的影响，提出了可扩展的指数策略算法解决CRB问题，并在需求响应决策中进行了应用。 |
| [^175] | [Investigating Use Cases of AI-Powered Scene Description Applications for Blind and Low Vision People](https://arxiv.org/abs/2403.15604) | 该研究调查了AI智能场景描述应用在盲人和低视力人群中的使用情况，发现用户主要用于识别已知对象的视觉特征以及避免与危险物体接触，并且用户对描述的满意度评分相对较低。 |
| [^176] | [Forward Learning for Gradient-based Black-box Saliency Map Generation](https://arxiv.org/abs/2403.15603) | 提出了一种新颖的统一框架，在黑盒设置中估计梯度并生成显著图解释模型决策，通过Likelihood Ratio方法估计输出到输入的梯度，并应用分块计算技术提高估计准确性，实验证实有效性和可扩展性。 |
| [^177] | [From Guidelines to Governance: A Study of AI Policies in Education](https://arxiv.org/abs/2403.15601) | 研究发现大多数教育机构缺乏专门指导生成式AI工具如ChatGPT的道德应用的政策，并且高中相对于高等教育机构在制定政策上更为犹豫，已有的政策经常忽视学生隐私和算法透明度等关键问题。 |
| [^178] | [Just another copy and paste? Comparing the security vulnerabilities of ChatGPT generated code and StackOverflow answers](https://arxiv.org/abs/2403.15600) | 本研究通过实证比较ChatGPT生成的代码和StackOverflow答案，提高软件开发人员在选择代码片段时对安全漏洞的认识。 |
| [^179] | [Large language models for crowd decision making based on prompt design strategies using ChatGPT: models, analysis and challenges](https://arxiv.org/abs/2403.15587) | 本文分析了基于提示设计策略的ChatGPT在群体决策过程中的应用，为提取意见和做出决策提供了新的可能性。 |
| [^180] | [Generative AI in Education: A Study of Educators' Awareness, Sentiments, and Influencing Factors](https://arxiv.org/abs/2403.15586) | 本研究调查了在高等教育中对大型语言模型和生成式人工智能工具的认知水平、总体情绪和影响因素，结果显示教育者对这些工具的态度逐渐变得积极。 |
| [^181] | [MedPromptX: Grounded Multimodal Prompting for Chest X-ray Diagnosis](https://arxiv.org/abs/2403.15585) | MedPromptX是第一个将多模态大型语言模型、少样本提示和视觉基础相结合，用于胸部X线诊断的模型，通过补充缺失的EHR信息，有效解决了幻觉问题，但选择最佳少样本示例和高质量候选者仍有待解决。 |
| [^182] | [Autonomous Driving With Perception Uncertainties: Deep-Ensemble Based Adaptive Cruise Control](https://arxiv.org/abs/2403.15577) | 本文提出了一种基于深度集成的DNN回归器用于自动驾驶中感知不确定性的处理，在自适应巡航控制场景中，实现了对车头间隔的预测并提供了概率安全保证。 |
| [^183] | [SensoryT5: Infusing Sensorimotor Norms into T5 for Enhanced Fine-grained Emotion Classification](https://arxiv.org/abs/2403.15574) | SensoryT5是一种将感觉信息融入T5模型的神经认知方法，旨在增强细粒度情绪分类，通过在注意机制中整合感觉线索，实现情绪表示的丰富性，并在各种数据集上展示出较好的性能。 |
| [^184] | [An Optimization Framework to Enforce Multi-View Consistency for Texturing 3D Meshes Using Pre-Trained Text-to-Image Models](https://arxiv.org/abs/2403.15559) | 该论文介绍了一个四阶段的优化框架，通过MV一致的扩散过程、半定编程问题解决、非刚性对齐和MRF问题解决等步骤来实现对3D网格进行纹理贴图的多视图一致性。 |
| [^185] | [Language-Based Depth Hints for Monocular Depth Estimation](https://arxiv.org/abs/2403.15551) | 通过使用自然语言作为进行单目深度估计的显式先验，本研究展示了如何使用简单的学习方法来提取语言模型对世界结构的偏见，并将其作为假设的显式来源输入到MDE系统中。 |
| [^186] | [LimGen: Probing the LLMs for Generating Suggestive Limitations of Research Papers](https://arxiv.org/abs/2403.15529) | 本文提出了一个新颖而具有挑战性的任务，即为研究论文生成建议性局限，通过调查大型语言模型的多种方法来揭示相关挑战、实践见解和潜在机会。 |
| [^187] | [Evaluating GPT-4 with Vision on Detection of Radiological Findings on Chest Radiographs](https://arxiv.org/abs/2403.15528) | GPT-4V在胸部X光放射检查的放射学发现检测上尚未准备好应用于真实世界的诊断用途 |
| [^188] | [Towards auditory attention decoding with noise-tagging: A pilot study](https://arxiv.org/abs/2403.15523) | 这项试点研究首次尝试使用噪声标记刺激协议进行听觉注意力解码，取得了较高的性能表现。 |
| [^189] | [CTSM: Combining Trait and State Emotions for Empathetic Response Model](https://arxiv.org/abs/2403.15516) | CTSM模型结合特质和状态情绪，通过构建和编码情绪嵌入以及引入情绪引导模块，解决了先前处理情绪感知不足的问题。 |
| [^190] | [Enhancing Effectiveness and Robustness in a Low-Resource Regime via Decision-Boundary-aware Data Augmentation](https://arxiv.org/abs/2403.15512) | 本文提出了一种决策边界感知的数据增强策略，通过移动潜在特征、重构生成模糊版本以及采用中K采样来增强生成句子的多样性，从而比较于其他方法提高了在低资源环境中的有效性和稳健性。 |
| [^191] | [Multiple-Input Auto-Encoder Guided Feature Selection for IoT Intrusion Detection Systems](https://arxiv.org/abs/2403.15511) | 该论文提出了一种名为多输入自动编码器(MIAE)的新型神经网络架构，通过训练MIAE模型，在无监督学习模式下将异构输入转换为较低维表示，有助于分类器区分正常行为和不同类型的攻击。 |
| [^192] | [Twin Auto-Encoder Model for Learning Separable Representation in Cyberattack Detection](https://arxiv.org/abs/2403.15509) | 提出一种新型双自动编码器模型(TAE)，通过将潜在表示转换为可分离表示来解决网络攻击检测中混合表示的问题 |
| [^193] | [SymboSLAM: Semantic Map Generation in a Multi-Agent System](https://arxiv.org/abs/2403.15504) | SymboSLAM提出了一种新颖的方法，通过符号化同时定位和地图制图来实现环境分类，解决了解决方案的可解释性问题。 |
| [^194] | [A Causal Analysis of CO2 Reduction Strategies in Electricity Markets Through Machine Learning-Driven Metalearners](https://arxiv.org/abs/2403.15499) | 通过Causal Machine Learning方法分析电力市场中定价政策对CO2水平的影响，挑战传统智慧，发现可能增加CO2强度，并结合机器学习元算法增强研究深度，并提供宝贵见解。 |
| [^195] | [EEG decoding with conditional identification information](https://arxiv.org/abs/2403.15489) | 通过将个体的有条件识别信息整合到神经网络中，这项研究提出了一种新的方法来增强模型表示，从而改善脑电图信号的解码准确性。 |
| [^196] | [Sequence-to-Sequence Language Models for Character and Emotion Detection in Dream Narratives](https://arxiv.org/abs/2403.15486) | 本研究提出一种序列到序列语言模型框架，首次在梦境叙事中进行角色和情感检测研究，展示语言模型可以有效应对该复杂任务，监督模型表现更佳且参数更少。 |
| [^197] | [MOGAM: A Multimodal Object-oriented Graph Attention Model for Depression Detection](https://arxiv.org/abs/2403.15485) | MOGAM模型是为了克服现有抑郁症检测方法在不同社交媒体数据类型上的限制而提出，通过多模态数据的综合应用，实现了更具可扩展性和多功能性的解决方案。 |
| [^198] | [Navigating Fairness: Practitioners' Understanding, Challenges, and Strategies in AI/ML Development](https://arxiv.org/abs/2403.15481) | AI从业者对于公平AI/ML的理解、面临的挑战、不公平AI/ML的后果以及确保AI/ML公平性的策略。 |
| [^199] | [Antisocial Analagous Behavior, Alignment and Human Impact of Google AI Systems: Evaluating through the lens of modified Antisocial Behavior Criteria by Human Interaction, Independent LLM Analysis, and AI Self-Reflection](https://arxiv.org/abs/2403.15479) | 谷歌AI系统展示了与反社会人格障碍类似的行为模式，强调了对AI系统及其创造者的信任度必须进行批判性评估。 |
| [^200] | [Learning to Infer Generative Template Programs for Visual Concepts](https://arxiv.org/abs/2403.15476) | 探索了一种学习如何推断捕捉视觉概念的通用模板程序的神经符号系统，引入了模板程序概念，支持多种概念相关任务，提出了一种学习范式来训练网络直接推断模板程序，实验证明该方法优于任务特定替代方法，并与特定领域方法竞争性地执行。 |
| [^201] | [EC-IoU: Orienting Safety for Object Detectors via Ego-Centric Intersection-over-Union](https://arxiv.org/abs/2403.15474) | 通过EC-IoU度量，本文引入了一种定向安全性物体检测方法，可以在安全关键领域中提高物体检测器的性能，并在KITTI数据集上取得了比IoU更好的结果。 |
| [^202] | [Enhancing Programming Education with ChatGPT: A Case Study on Student Perceptions and Interactions in a Python Course](https://arxiv.org/abs/2403.15472) | 本研究探讨了将ChatGPT整合到Python编程课程中对学习的影响，揭示了学生对ChatGPT的积极态度，并提供了关于其在增强编程教育体验中作用的见解。 |
| [^203] | [Most Likely Sequence Generation for $n$-Grams, Transformers, HMMs, and Markov Chains, by Using Rollout Algorithms](https://arxiv.org/abs/2403.15465) | 本文介绍了一种使用展开算法为$n$-grams，Transformers，HMMs和马尔可夫链生成最有可能的序列的方法 |
| [^204] | [LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction](https://arxiv.org/abs/2403.15464) | 该论文提出了一种新方法，结合预测性代理推理和批判性代理指导，利用LLMs对结构化患者就诊数据进行预测，取得了较好的效果。 |
| [^205] | [The Journey to Trustworthy AI- Part 1: Pursuit of Pragmatic Frameworks](https://arxiv.org/abs/2403.15457) | 本文回顾了值得信赖的人工智能（TAI）和其各种定义，主张不应将“负责任的”或“道德的”人工智能等术语视为TAI的替代，而是提倡以公平性、偏见、风险、安全性、可解释性和可靠性等关键属性为中心的方法，认识到地缘政治和地理原因导致的人工智能监管差异对跨国公司构成挑战。 |
| [^206] | [WoLF: Large Language Model Framework for CXR Understanding](https://arxiv.org/abs/2403.15456) | WoLF框架提出了对于CXR的全面理解的改进，包括使用额外的健康相关数据、重构报告以提供更有组织的信息、以及改进生成答案的细致评估。 |
| [^207] | [Span-Oriented Information Extraction -- A Unifying Perspective on Information Extraction](https://arxiv.org/abs/2403.15453) | 提出了以文本中的跨度为中心的统一视角，将各种信息抽取任务重新定位为相同基本面向跨度的信息抽取任务的变体 |
| [^208] | [What Are Tools Anyway? A Survey from the Language Model Perspective](https://arxiv.org/abs/2403.15452) | 从语言模型的角度出发，本调查提供了工具的统一定义为LMs使用的外部程序，并对LM工具场景和方法进行了系统审查，同时通过实证研究了解了各种工具方法的效率，以及突出了该领域的挑战和未来研究方向。 |
| [^209] | [Hatred Stems from Ignorance! Distillation of the Persuasion Modes in Countering Conversational Hate Speech](https://arxiv.org/abs/2403.15449) | 研究研究了对抗在线仇恨言论的最佳方法，通过分析对话中的理由、情感和信誉等说服方式，对比封闭和开放交互中的不同行为和话题层面，发现了在对抗言论中的微妙差异。 |
| [^210] | [Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression](https://arxiv.org/abs/2403.15447) | 量化目前比剪枝更有效，可以同时实现效率和可信度，但剪枝会显著降低模型的可信度 |
| [^211] | [Decoding Multilingual Topic Dynamics and Trend Identification through ARIMA Time Series Analysis on Social Networks: A Novel Data Translation Framework Enhanced by LDA/HDP Models](https://arxiv.org/abs/2403.15445) | 该研究提出了一种新方法，通过ARIMA时间序列分析和LDA/HDP模型提取多语言社交网络中的主题动态，特别关注在危机期间的交流趋势，这一方法在语言一致性任务中表现出色。 |
| [^212] | [A Survey of IMU Based Cross-Modal Transfer Learning in Human Activity Recognition](https://arxiv.org/abs/2403.15444) | 本篇论文调查了如何在人类活动/动作识别中实现跨模态迁移学习，探讨了IMU数据在此领域中的潜在应用，对HAR问题进行了重要性探讨，并比较了不同类型的多模态HAR数据集。 |
| [^213] | [Introducing an ensemble method for the early detection of Alzheimer's disease through the analysis of PET scan images](https://arxiv.org/abs/2403.15443) | 通过分析PET扫描图像，引入了一种集成方法早期检测阿尔茨海默病，并且在分类阿尔茨海默病时使用了多种深度学习和传统机器学习模型。 |
| [^214] | [Advanced Artificial Intelligence Algorithms in Cochlear Implants: Review of Healthcare Strategies, Challenges, and Perspectives](https://arxiv.org/abs/2403.15442) | 人工智能在提高植入式听觉设备的语音质量方面具有前瞻性，并通过先进的信号处理技术以及应对多源语音和环境噪音挑战等方法来克服语音失真问题 |
| [^215] | [Unified Generative Modeling of 3D Molecules via Bayesian Flow Networks](https://arxiv.org/abs/2403.15441) | 本文引入了Geometric Bayesian Flow Networks (GeoBFN)，通过在分布的可微分参数空间中对不同模态进行建模，实现了对多模态性和噪声敏感性的分子几何形状的自然拟合。GeoBFN通过优化的训练和采样技术，在多个3D分子生成基准上取得了最先进的性能。 |
| [^216] | [Apriori Knowledge in an Era of Computational Opacity: The Role of AI in Mathematical Discovery](https://arxiv.org/abs/2403.15437) | 通过给现代人工智能模型添加自动化人类形式的证明检查器，我们可以从它们那里获取先验数学知识，即使这些机器完全对我们不透明。 |
| [^217] | [ChatPattern: Layout Pattern Customization via Natural Language](https://arxiv.org/abs/2403.15434) | ChatPattern利用大语言模型（LLM）的框架实现了灵活的布局模式定制，能够通过自然语言要求生成高质量大规模模式。 |
| [^218] | [HyPer-EP: Meta-Learning Hybrid Personalized Models for Cardiac Electrophysiology](https://arxiv.org/abs/2403.15433) | 提出了一个新颖的混合建模框架，结合了基于物理已知表达式和神经网络建模的元学习方法，用于描述个性化心脏数字孪生模型，实现了基于物理和神经网络组件的分离识别。 |
| [^219] | [BRIEDGE: EEG-Adaptive Edge AI for Multi-Brain to Multi-Robot Interaction](https://arxiv.org/abs/2403.15432) | BRIEDGE提出了一个用于多脑到多机器人交互的端到端系统，通过 EEG 自适应神经网络和编解码通信框架实现，引入了基于Informer的ProbSparse自注意机制以提高分类准确性。 |
| [^220] | [A Three-Phases SFT Hybrid Model Integrated Strong Prior Module and Data Overlap Estimation in the Eduation Context](https://arxiv.org/abs/2403.15426) | 提出了一种在教育领域中应用的三阶段监督微调模型，通过先验和数据重叠估计实现了教育知识的结构拆卸和增量引导输出。 |
| [^221] | [Cross-user activity recognition using deep domain adaptation with temporal relation information](https://arxiv.org/abs/2403.15424) | 该论文提出了Deep Temporal State Domain Adaptation（DTSDA）模型，用于处理跨用户活动识别中的行为变异挑战。 |
| [^222] | [Cross-user activity recognition via temporal relation optimal transport](https://arxiv.org/abs/2403.15423) | 本文提出了一种基于时间关系最优输运的跨用户活动识别方法，旨在解决现有基于i.i.d.假设的域自适应方法在时间序列数据中的局限性 |
| [^223] | [Machine Learning Techniques for Sensor-based Human Activity Recognition with Data Heterogeneity -- A Review](https://arxiv.org/abs/2403.15422) | 通过研究机器学习如何处理传感器数据异质性，能够改善人体活动识别系统的性能，降低计算成本，更快地开发出个性化的自适应模型。 |
| [^224] | [Fuzzy hyperparameters update in a second order optimization](https://arxiv.org/abs/2403.15416) | 介绍了一种在二阶优化中加速收敛的混合方法，利用在线有限差分逼近对角Hessian矩阵，并应用模糊推理于多个超参数。 |
| [^225] | [Playing With Neuroscience: Past, Present and Future of Neuroimaging and Games](https://arxiv.org/abs/2403.15413) | 视频游戏作为研究领域的催化剂已取得很大进展，本文将分析神经科学与游戏的现状，并展望未来方向。 |
| [^226] | [Towards Measuring and Modeling "Culture" in LLMs: A Survey](https://arxiv.org/abs/2403.15412) | 这项研究调查了39篇最新论文，旨在研究大型语言模型中的文化表达和包容性，发现当前研究未对“文化”进行定义，而是在特定设计的数据集上对模型进行探究，研究了某些“文化”的方面，留下许多未被探究的有趣和重要方面，如语义领域和关于性。 |
| [^227] | [Multi-modal Heart Failure Risk Estimation based on Short ECG and Sampled Long-Term HRV](https://arxiv.org/abs/2403.15408) | 提出了结合30秒ECG记录和长期HRV数据的多模态方法用于估算心力衰竭住院风险，并引入了两种生存模型：XGBoost模型和ResNet模型。 |
| [^228] | [X-AMR Annotation Tool](https://arxiv.org/abs/2403.15407) | 该论文介绍了一种新型的X-AMR注释工具，通过机器辅助提升用户体验，实现了对关键事件语义的注释，与GPT-4集成表现出色。 |
| [^229] | [AI Sustainability in Practice Part Two: Sustainability Throughout the AI Workflow](https://arxiv.org/abs/2403.15404) | SIAs是一种治理机制，可以帮助AI项目团队持续关注项目的潜在实际影响，这对于实现AI系统的可持续性至关重要。 |
| [^230] | [AI Ethics and Governance in Practice: An Introduction](https://arxiv.org/abs/2403.15403) | 介绍了PBG框架，这是一个多层次的治理模型，帮助项目团队将伦理价值观和实践原则融入创新实践中，展示和记录这些价值的清晰机制。 |
| [^231] | [Large Language Model for Mental Health: A Systematic Review](https://arxiv.org/abs/2403.15401) | 该论文系统评价了大型语言模型在心理健康领域的应用，讨论了其在早期筛查、数字干预和其他临床应用中的挑战和机遇。 |
| [^232] | [Regulating Large Language Models: A Roundtable Report](https://arxiv.org/abs/2403.15397) | 圆桌会议探讨了如何通过法律和政策来解决大型语言模型可能带来的真实性、隐私和市场集中等方面的重要社会问题。 |
| [^233] | [I would love this to be like an assistant, not the teacher: a voice of the customer perspective of what distance learning students want from an Artificial Intelligence Digital Assistant](https://arxiv.org/abs/2403.15396) | 通过两步法混合方法研究了十名在线和远程学习学生对虚拟AI数字助手设计的看法，结果显示所有参与者都认为这样的AI工具在学习时是有用的。 |
| [^234] | [LLaVA-PruMerge: Adaptive Token Reduction for Efficient Large Multimodal Models](https://arxiv.org/abs/2403.15388) | PruMerge提出了一种自适应的视觉令牌减少方法，可以有效减少大型多模态模型中的视觉令牌数量，同时保持模型性能。 |
| [^235] | [Point-DETR3D: Leveraging Imagery Data with Spatial Point Prior for Weakly Semi-supervised 3D Object Detection](https://arxiv.org/abs/2403.15317) | 提出了Point-DETR3D，一个师生框架用于弱监督半监督3D检测，充分利用点级监督优势，克服了将弱监督3D先验信息编码到模型中的挑战。 |
| [^236] | [Cartoon Hallucinations Detection: Pose-aware In Context Visual Learning](https://arxiv.org/abs/2403.15048) | 该研究提出了一种用于检测由TTI模型生成的卡通角色图像中视觉幻觉的系统，通过结合姿势感知上下文视觉学习和视觉语言模型，利用RGB图像和姿势信息，实现了更准确的决策，显著提高了视觉幻觉的识别能力，推动了TTI模型在非照片真实领域的发展。 |
| [^237] | [Gravitational Duals from Equations of State](https://arxiv.org/abs/2403.14763) | 引力双对偶理论提出了一种基于物理信息神经网络的新方法，可以从预设的状态方程推导出对应的引力理论。 |
| [^238] | [The AI Assessment Scale (AIAS) in action: A pilot implementation of GenAI supported assessment](https://arxiv.org/abs/2403.14692) | 该论文介绍了AI评估量表（AIAS）的实践应用，通过灵活框架将GenAI技术纳入教育评估中，显著降低了与GenAI相关的学术不端案件，提高了学生的学业成绩。 |
| [^239] | [Developing and Deploying Industry Standards for Artificial Intelligence in Education (AIED): Challenges, Strategies, and Future Directions](https://arxiv.org/abs/2403.14689) | 教育领域人工智能的发展需要制定和实施产业标准，以解决互操作性、可扩展性和道德治理等挑战。 |
| [^240] | [Exploring ChatGPT and its Impact on Society](https://arxiv.org/abs/2403.14643) | ChatGPT是一种基于Transformer架构的大型语言模型，能够生成人类化的对话回复，可革新各行业并改变技术互动方式。 |
| [^241] | [ReAct Meets ActRe: Autonomous Annotations of Agent Trajectories for Contrastive Self-Training](https://arxiv.org/abs/2403.14589) | 提出了A$^3$T框架，通过ActRe提示代理实现了ReAct风格代理对代理轨迹的自主标注，同时增强了新的轨迹合成能力。 |
| [^242] | [A survey on Concept-based Approaches For Model Improvement](https://arxiv.org/abs/2403.14566) | 基于概念方法对深度神经网络进行解释性改进，提供了人类可理解的决策解释，使得检测伪关联和固有偏见成为可能。 |
| [^243] | [C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion](https://arxiv.org/abs/2403.14119) | 本文研究了在测试时提示调整过程中通过利用CLIP的固有属性来探讨校准的方法，发现提示选择显著影响了CLIP中的校准，其中导致更高文本特征离散性的提示会产生更好校准的预测。 |
| [^244] | [Carbon Footprint Reduction for Sustainable Data Centers in Real-Time](https://arxiv.org/abs/2403.14092) | 我们提出了一种Data Center Carbon Footprint Reduction (DC-CFR) 多代理强化学习（MARL）框架，旨在实时优化数据中心以减少碳足迹。 |
| [^245] | [Integrating Wearable Sensor Data and Self-reported Diaries for Personalized Affect Forecasting](https://arxiv.org/abs/2403.13841) | 本论文提出了一种整合了可穿戴传感器数据和自我报告日记的多模态深度学习模型，用于情感状态的预测。 |
| [^246] | [Emotion Recognition Using Transformers with Masked Learning](https://arxiv.org/abs/2403.13731) | 本研究提出了一种使用Transformer进行情绪识别的新框架，专注于Valence-Arousal估计、面部表情识别和动作单元检测，并最大化了对时空特征的理解。 |
| [^247] | [No more optimization rules: LLM-enabled policy-based multi-modal query optimizer (version 1)](https://arxiv.org/abs/2403.13597) | LLM启用了基于策略的多模查询优化器，摆脱了传统的基于规则的优化方法，为查询优化带来全新的可能性。 |
| [^248] | [Design-Space Exploration of SNN Models using Application-Specific Multi-Core Architectures](https://arxiv.org/abs/2403.12061) | 提出了一种基于应用特定多核架构的新型运行时多核架构模拟器“RAVSim”，通过该模拟器，用户可以在执行过程中与模型交互并修改参数值集。 |
| [^249] | [From Pixels to Insights: A Survey on Automatic Chart Understanding in the Era of Large Foundation Models](https://arxiv.org/abs/2403.12027) | 近年来，随着大型基础模型的兴起，自动图表理解取得了显著进展，本调查论文概述了在这些基础模型背景下图表理解领域的最新发展、挑战和未来方向 |
| [^250] | [Ensuring Safe and High-Quality Outputs: A Guideline Library Approach for Language Models](https://arxiv.org/abs/2403.11838) | 引入Guide-Align，一种两阶段方法，通过安全训练模型识别潜在风险，并制定特定指南，从而建立全面的指导库，用于指导LLMs生成安全和高质量输出。 |
| [^251] | [Scene-LLM: Extending Language Model for 3D Visual Understanding and Reasoning](https://arxiv.org/abs/2403.11401) | 本文介绍了Scene-LLM，一种3D视觉语言模型，通过整合大型语言模型（LLMs）的推理优势，增强了在交互式3D室内环境中具身体存在的代理者能力。 |
| [^252] | [A learning-based solution approach to the application placement problem in mobile edge computing under uncertainty](https://arxiv.org/abs/2403.11259) | 通过机器学习模型将用户请求分配给服务器，以解决在移动边缘计算中应用部署问题的二阶段随机规划。 |
| [^253] | [A Conceptual Framework For White Box Neural Networks](https://arxiv.org/abs/2403.09863) | 引入语义特征作为通用概念框架，实现了完全可解释的神经网络层，为白盒神经网络的范式转变开辟了新的可能性。 |
| [^254] | [Don't Judge by the Look: A Motion Coherent Augmentation for Video Recognition](https://arxiv.org/abs/2403.09506) | 本研究提出了一种名为运动一致增强（MCA）的数据增强方法，通过引入外观变化来鼓励模型优先考虑视频中的运动信息，而不是静态外观。 |
| [^255] | [An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models](https://arxiv.org/abs/2403.06764) | FastV是一种多功能即插即用方法，通过学习自适应注意力模式并在后续层中修剪视觉代币，极大地降低了计算成本，同时在各种图像和视频理解任务中不损失性能。 |
| [^256] | [Improving Low-Resource Knowledge Tracing Tasks by Supervised Pre-training and Importance Mechanism Fine-tuning](https://arxiv.org/abs/2403.06725) | 本文提出了名为LoReKT的低资源知识追踪框架，通过监督预训练和微调重要性机制，旨在从丰富资源的KT数据集中学习可转移的参数和表示来改进低资源知识追踪任务。 |
| [^257] | [Decoupled Data Consistency with Diffusion Purification for Image Restoration](https://arxiv.org/abs/2403.06054) | 通过分离反向过程和数据一致性步骤，提出了一种新颖的基于扩散的图像恢复求解器。 |
| [^258] | [Defending Against Unforeseen Failure Modes with Latent Adversarial Training](https://arxiv.org/abs/2403.05030) | 本研究利用潜在对抗训练（LAT）来防御AI系统中未预见的故障模式，通过利用网络实际用于预测的压缩、抽象和结构化概念的潜在表示，有效清除了恶意软件和对抗性攻击。 |
| [^259] | [Restricted Bayesian Neural Network](https://arxiv.org/abs/2403.04810) | 本研究提出了限制贝叶斯神经网络的新架构，显著减少了网络存储空间复杂性，并引入了一种能够有效处理不确定性的算法，确保在目标函数缺乏完美凸性时稳健地收敛至全局最优解。 |
| [^260] | [From Graph to Word Bag: Introducing Domain Knowledge to Confusing Charge Prediction](https://arxiv.org/abs/2403.04369) | 引入领域知识的从图到词袋方法，帮助预测混淆罪名，通过构成要素和关键词选择进行判断。 |
| [^261] | [Latent Dataset Distillation with Diffusion Models](https://arxiv.org/abs/2403.03881) | 这项研究提出了使用扩散模型进行潜在数据集蒸馏（LD3M），结合潜在空间中的扩散和数据集蒸馏的方法，以解决不同模型架构导致准确性下降和生成高分辨率图像的挑战。 |
| [^262] | [Align-to-Distill: Trainable Attention Alignment for Knowledge Distillation in Neural Machine Translation](https://arxiv.org/abs/2403.01479) | "本文提出了“Align-to-Distill”（A2D）策略，通过在训练过程中自适应地对齐学生注意力头与其教师对应物，转化了组合映射启发式方法为学习问题，实验结果显示A2D的有效性，对WMT-2022 De->Dsb和WMT-2014 En->De的BLEU分数分别获得高达+3.61和+0.63的提升。" |
| [^263] | [SEED: Customize Large Language Models with Sample-Efficient Adaptation for Code Generation](https://arxiv.org/abs/2403.00046) | SEED提出了一种名为Sample-Efficient adaptation with Error-Driven learning的新颖适应方法，利用LLMs产生的错误作为学习机会，从而实现对代码生成任务的高效学习。 |
| [^264] | [Extracting Lexical Features from Dialects via Interpretable Dialect Classifiers](https://arxiv.org/abs/2402.17914) | 通过可解释的方言分类器提取方言的词汇特征，成功识别了有助于方言变化的关键语言特定词汇特征。 |
| [^265] | [Multilingual Coreference Resolution in Low-resource South Asian Languages](https://arxiv.org/abs/2402.13571) | 引入了一个用于31种南亚语言的多语言共指解析翻译数据集，通过利用现成工具进行训练和对齐，在低资源条件下实现了较好的共指解析模型性能提升。 |
| [^266] | [A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence](https://arxiv.org/abs/2402.12928) | 本文旨在提供对模式分析与机器智能领域文献综述的全面评估，引入大语言模型驱动的文献计量指标，并构建了RiPAMI元数据数据库和主题数据集以获取PAMI综述的统计特征。 |
| [^267] | [Solving Data-centric Tasks using Large Language Models](https://arxiv.org/abs/2402.11734) | 本文提出了两点贡献：一是创建了一个真实世界的NL-to-code任务数据集，二是引入了一种聚类然后选择提示技术，从输入数据中添加最具代表性的行到LLM提示中。 |
| [^268] | [LongHeads: Multi-Head Attention is Secretly a Long Context Processor](https://arxiv.org/abs/2402.10685) | LongHeads 提出了一个无需训练的框架，通过释放多头注意力的潜力来增强大型语言模型(LLM)处理长上下文的能力。 |
| [^269] | [Can AI and humans genuinely communicate?](https://arxiv.org/abs/2402.09494) | 本研究探讨了AI和人类是否能够真正交流的问题，并提出了一种称为“心理行为方法”的回答方式，该方法通过测试AI是否展现出人类类似的行为来判断其是否能够与人类真正交流。 |
| [^270] | [Exploring the Adversarial Capabilities of Large Language Models](https://arxiv.org/abs/2402.09132) | 本研究探索了大型语言模型的对抗能力，并发现其能够成功地制造对抗性示例以愚弄安全措施，特别是在仇恨言论检测方面具有重大影响。 |
| [^271] | [Tandem Transformers for Inference Efficient LLMs](https://arxiv.org/abs/2402.08644) | 该论文提出了一种新的架构，称为串联Transformer，用于解决传统大型语言模型推断速度限制的问题。该架构通过将小型自回归模型和大模型以块模式结合起来，并让小模型关注大模型的丰富表示，从而显著提高了小模型的预测准确性。实验证明，在预训练数据集上，串联的PaLM2-Bison和PaLM2-Gecko相比独立的PaLM2-Gecko，在下一个词元预测准确性上提高了3.3%，并且相较于具有相似下游任务的PaLM2-Otter模型，加速比达到1.16倍。 |
| [^272] | [A Survey on Safe Multi-Modal Learning System](https://arxiv.org/abs/2402.05355) | 这项研究提出了第一个多模态学习系统安全的分类法，对当前发展状态下的关键限制进行了审查，并提出了未来研究的潜在方向。 |
| [^273] | [Meet JEANIE: a Similarity Measure for 3D Skeleton Sequences via Temporal-Viewpoint Alignment](https://arxiv.org/abs/2402.04599) | JEANIE是一种通过时间-视角对齐的方法，用于测量三维骨架序列的相似度。它能够解决视频序列中速度、时间位置和姿势的干扰变化问题。在评估了骨架Few-shot动作识别任务后，JEANIE在支持-查询序列对的时间块匹配方面表现出了良好的效果。 |
| [^274] | [Uni-RLHF: Universal Platform and Benchmark Suite for Reinforcement Learning with Diverse Human Feedback](https://arxiv.org/abs/2402.02423) | Uni-RLHF是一个通用的强化学习平台和基准套件，致力于处理多样化的人类反馈，解决了在RLHF中量化进展的挑战，并提供了用户友好的注释界面和离线基准实现。 |
| [^275] | [Self-Supervised Contrastive Forecasting](https://arxiv.org/abs/2402.02023) | 该论文介绍了一种通过采用对比学习和增强的分解架构，并结合全局自相关性的自监督方法来解决长期预测中的挑战。实验证明，该方法在九个长期基准上的多个实验中胜过了14个基线模型。 |
| [^276] | [Sandra -- A Neuro-Symbolic Reasoner Based On Descriptions And Situations](https://arxiv.org/abs/2402.00591) | Sandra是一个神经符号推理器，通过将矢量表示与演绎推理相结合，利用本体论建立的向量空间进行推理。它基于描述和情境的本体设计模式，能够从一组事实中推断出所有可能的解释，并在实验中证明在不增加复杂性的情况下优于其他基准线的分类结果，并且具有可解释性和向量空间的可控性。 |
| [^277] | [Rethinking Channel Dependence for Multivariate Time Series Forecasting: Learning from Leading Indicators](https://arxiv.org/abs/2401.17548) | 本文提出了一种新方法，LIFT，通过利用通道相关性和领先指标，为多元时间序列预测提供准确的预测。LIFT方法可以无缝与任意时间序列预测方法协作，大量实验证明了其有效性。 |
| [^278] | [LCV2: An Efficient Pretraining-Free Framework for Grounded Visual Question Answering](https://arxiv.org/abs/2401.15842) | LCV2提出了一种高效的兼容各种预训练模型的基于视觉问答的框架，无需预训练过程，适用于低计算资源下的任务 |
| [^279] | [With Greater Text Comes Greater Necessity: Inference-Time Training Helps Long Text Generation](https://arxiv.org/abs/2401.11504) | Temp-Lora方法通过在长文本生成过程中逐步训练临时Lora模块，有效保留上下文知识并避免对模型参数的永久性改变。 |
| [^280] | [A Large-Scale Empirical Study on Improving the Fairness of Image Classification Models](https://arxiv.org/abs/2401.03695) | 本研究进行了大规模实证研究，比较了现有最先进的公平性改进技术在图像分类模型上的表现，揭示了它们之间的显著差异 |
| [^281] | [SurgicalPart-SAM: Part-to-Whole Collaborative Prompting for Surgical Instrument Segmentation](https://arxiv.org/abs/2312.14481) | 本文提出了一种手术器械分割的新方法SurgicalPart-SAM (SP-SAM)，通过整合器械结构知识与SAM的通用知识，实现了有效调整，从而解决了器械细节和结构描述的问题。 |
| [^282] | [TagAlign: Improving Vision-Language Alignment with Multi-Tag Classification](https://arxiv.org/abs/2312.14149) | 提出了一种简单的方法，通过解析图像与文本中的对象和属性，使用多标签分类损失来改进视觉-语言对齐模型 |
| [^283] | [PIA: Your Personalized Image Animator via Plug-and-Play Modules in Text-to-Image Models](https://arxiv.org/abs/2312.13964) | PIA通过插拔式模块在文本到图像模型中实现个性化图像动画，并解决了保留独特风格、高保真细节和动作可控性的挑战 |
| [^284] | [Multi-agent reinforcement learning using echo-state network and its application to pedestrian dynamics](https://arxiv.org/abs/2312.11834) | 通过使用回声状态网络将行人实现为MARL代理，研究了他们学习避让其他代理向前移动的能力，在密度不太高的情况下取得成功。 |
| [^285] | [BaRDa: A Belief and Reasoning Dataset that Separates Factual Accuracy and Reasoning Ability](https://arxiv.org/abs/2312.07527) | BaRDa数据集通过使用人类注释的蕴涵树，混合真实和虚假事实，并包括反事实例子，成功区分了事实准确性和推理能力。 |
| [^286] | [Offloading and Quality Control for AI Generated Content Services in 6G Mobile Edge Computing Networks](https://arxiv.org/abs/2312.06203) | 该论文提出了在6G移动边缘计算网络中针对AI生成内容服务的卸载和质量控制问题的联合优化算法。 |
| [^287] | [I-PHYRE: Interactive Physical Reasoning](https://arxiv.org/abs/2312.03009) | I-PHYRE是一个挑战代理同时展示直观的物理推理、多步规划和就地干预能力的框架。 |
| [^288] | [Word4Per: Zero-shot Composed Person Retrieval](https://arxiv.org/abs/2311.16515) | 提出了一个新任务：组合人员检索（CPR），旨在联合利用图像和文本信息进行目标人员检索，引入零样本组合人员检索（ZS-CPR）解决了CPR问题，提出了一个两阶段学习框架Word4Per。 |
| [^289] | [HalluciDoctor: Mitigating Hallucinatory Toxicity in Visual Instruction Data](https://arxiv.org/abs/2311.13614) | 本研究提出了一个新颖的幻觉检测和消除框架HalluciDoctor，旨在减轻大规模机器生成的视觉指令数据中的幻觉毒性。 |
| [^290] | [Using Human Feedback to Fine-tune Diffusion Models without Any Reward Model](https://arxiv.org/abs/2311.13231) | 该论文提出了一种名为D3PO的方法，通过使用人类反馈直接微调扩散模型，无需奖励模型，从而在消除了奖励模型的前提下改进了现有方法，并解决了DPO方法直接应用的内存需求问题。 |
| [^291] | [Unmasking and Improving Data Credibility: A Study with Datasets for Training Harmless Language Models](https://arxiv.org/abs/2311.11202) | 本研究专注于真实世界数据集的可信度，提出了一个系统化框架，用于评估数据集的可信度，识别标签错误，并评估嘈杂标签对不安全评论和对话分类的影响，以提高训练无害语言模型的质量。 |
| [^292] | [A Survey of Confidence Estimation and Calibration in Large Language Models](https://arxiv.org/abs/2311.08298) | 大型语言模型中置信度估计与校准的调研总结了挑战、技术进展、应用和未来方向。 |
| [^293] | [Evaluating Neighbor Explainability for Graph Neural Networks](https://arxiv.org/abs/2311.08118) | 评价图神经网络中邻居的可解释性，提出新的度量标准并发现基于梯度的方法在GNN领域的解释没有太大差异，同时发现很多技术在没有自环的GNNs下无法准确识别重要邻居。 |
| [^294] | [A Closer Look at the Self-Verification Abilities of Large Language Models in Logical Reasoning](https://arxiv.org/abs/2311.07954) | 本文研究了大型语言模型在逻辑推理中的自我验证能力，特别关注它们准确识别逻辑谬误的能力。 |
| [^295] | [VT-Former: A Transformer-based Vehicle Trajectory Prediction Approach For Intelligent Highway Transportation Systems](https://arxiv.org/abs/2311.06623) | 本文介绍了一种基于Transformer的车辆轨迹预测方法，名为VT-Former，在智能公路交通系统中具有重要的应用价值。 |
| [^296] | [LitSumm: Large language models for literature summarisation of non-coding RNAs](https://arxiv.org/abs/2311.03056) | 使用大语言模型为非编码RNA文献生成高质量和准确的摘要，帮助减轻生命科学文献整理中缺乏策展人员时间的问题。 |
| [^297] | [Make a Donut: Hierarchical EMD-Space Planning for Zero-Shot Deformable Manipulation with Tools](https://arxiv.org/abs/2311.02787) | 引入了一种无需演示的分层规划方法，利用大型语言模型来解决复杂的长时间任务，为每个阶段提供工具名称和Python代码。 |
| [^298] | [Causal Question Answering with Reinforcement Learning](https://arxiv.org/abs/2311.02760) | 本研究通过强化学习在因果图上进行因果问答，引入了一种基于演员评论的 agent，有效解决了当前因果问答方法无法提供解释或证据的问题 |
| [^299] | [UrbanCLIP: Learning Text-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining from the Web](https://arxiv.org/abs/2310.18340) | 本文介绍了第一个将文本模态融入城市图像描述的LLM增强框架UrbanCLIP，并探讨了文本模态如何增强城市区域描述以及其影响方面。 |
| [^300] | [BatteryML:An Open-source platform for Machine Learning on Battery Degradation](https://arxiv.org/abs/2310.14714) | BatteryML是一个开源平台，通过一站式、全面的方法统一了电池衰减建模的数据预处理、特征提取和模型实现，提高了研究应用的实用性和效率。 |
| [^301] | [Bridging the Novice-Expert Gap via Models of Decision-Making: A Case Study on Remediating Math Mistakes](https://arxiv.org/abs/2310.10648) | 通过使用决策模型Bridge，结合专家的认知任务分析，成功利用大型语言模型（LLMs）来弥补新手和专家在纠正数学错误中的知识差距。 |
| [^302] | [Towards Robust Multi-Modal Reasoning via Model Selection](https://arxiv.org/abs/2310.08446) | 多模态代理在处理复杂挑战时需要考虑模型选择的重要性，以避免执行的脆弱性。 |
| [^303] | [Quality-Aware Translation Models: Efficient Generation and Quality Estimation in a Single Model](https://arxiv.org/abs/2310.06707) | 提出了一种质量感知翻译模型，通过训练NMT模型来估计其输出质量，可以在解码过程中消除额外的计算成本。 |
| [^304] | [A Meta-Learning Perspective on Transformers for Causal Language Modeling](https://arxiv.org/abs/2310.05884) | 本文从元学习视角探讨了Transformer用于因果语言建模时的内部优化过程，发现并分析了Transformer-based因果语言模型中学习到的token表示范数的特殊特征。 |
| [^305] | [Fully Spiking Neural Network for Legged Robots](https://arxiv.org/abs/2310.05022) | 本文将新型全脉冲神经网络（SNN）成功应用于处理腿式机器人，在各种模拟地形中取得了杰出结果。 |
| [^306] | [HalluciDet: Hallucinating RGB Modality for Person Detection Through Privileged Information](https://arxiv.org/abs/2310.04662) | 本文提出了一种IR-RGB图像翻译模型HalluciDet，通过特权信息减少RGB检测器的检测损失，提高了检测性能 |
| [^307] | [Subtractive Mixture Models via Squaring: Representation and Learning](https://arxiv.org/abs/2310.00724) | 通过平方操作实现的消减混合模型在表达能力上优于传统加法混合模型，并在真实世界分布估计任务中得到了实验证明。 |
| [^308] | [Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic](https://arxiv.org/abs/2309.13339) | 提出了LoT（Logical Thoughts）提示，一个自我改进框架，利用根植于符号逻辑的原则，特别是归谬法，逐步验证和纠正大型语言模型的零射链推理过程。 |
| [^309] | [Large Language Models for Generative Recommendation: A Survey and Visionary Discussions](https://arxiv.org/abs/2309.01157) | 大型语言模型为推荐系统的生成式推荐提供了新机遇，可以简化推荐流程并直接从完整的项目池中生成推荐。 |
| [^310] | [Unveiling the Blind Spots: A Critical Examination of Fairness in Autonomous Driving Systems](https://arxiv.org/abs/2308.02935) | 该研究对当前深度学习行人检测器的公平性进行了全面评估，发现了与年龄相关的重要公平性问题。 |
| [^311] | [Rethinking the Evaluation Protocol of Domain Generalization](https://arxiv.org/abs/2305.15253) | 重新评估领域泛化的评估协议，提出采用自监督预训练或从头开始训练，使用多个测试领域，以更准确评估OOD泛化能力。 |
| [^312] | [LLM Paternity Test: Generated Text Detection with LLM Genetic Inheritance](https://arxiv.org/abs/2305.12519) | LLM-Pat提出了一种基于模型的生成文本检测方法，通过重建并比较候选文本与其对应的“兄弟”文本的相似性，从而判断候选文本是否由机器生成。 |
| [^313] | [A Forward and Backward Compatible Framework for Few-shot Class-incremental Pill Recognition](https://arxiv.org/abs/2304.11959) | 提出了一种前向和后向兼容的少样本类增量药丸识别框架，包括虚拟类别合成策略和中心三元组损失以增强辨别特征学习。 |
| [^314] | [Dissociating language and thought in large language models](https://arxiv.org/abs/2301.06627) | 大型语言模型在形式语言能力方面表现出色，但在功能语言能力任务上表现不稳定，可能需要专门的调整和外部模块的支持。 |
| [^315] | [A survey on knowledge-enhanced multimodal learning](https://arxiv.org/abs/2211.12328) | 知识图和其他知识来源填补了视觉语言学习模型在日常知识理解方面的差距，提升了模型的性能和可解释性。 |
| [^316] | [Detection of diabetic retinopathy using longitudinal self-supervised learning](https://arxiv.org/abs/2209.00915) | 本研究探讨了利用纵向自监督学习对糖尿病视网膜病变进行诊断的益处，通过比较不同方法模拟疾病进展并在纵向眼底照片中检测早期DR严重程度变化，取得了较高的AUC。 |
| [^317] | [Effective Integration of Weighted Cost-to-go and Conflict Heuristic within Suboptimal CBS](https://arxiv.org/abs/2205.11624) | 本文发现在次优CBS中，加权成本启发式和冲突启发式可以有效结合，其中一种变体在多种情景和方法中可实现大幅速度提升。 |
| [^318] | [A cGAN Ensemble-based Uncertainty-aware Surrogate Model for Offline Model-based Optimization in Industrial Control Problems](https://arxiv.org/abs/2205.07250) | 引入了一个基于cGAN集成的关注不确定性的替代模型，用于可靠处理工业控制问题中的离线模型优化，实验结果表明其优于竞争基线模型。 |
| [^319] | [On The Effectiveness of One-Class Support Vector Machine in Different Defect Prediction Scenarios](https://arxiv.org/abs/2202.12074) | 本文研究了一类支持向量机在不同缺陷预测场景中的有效性，并发现其在跨版本和跨项目的缺陷预测模型中表现出色。 |
| [^320] | [A Theoretical Understanding of Gradient Bias in Meta-Reinforcement Learning](https://arxiv.org/abs/2112.15400) | 本文对梯度为基础的元强化学习中的梯度偏差进行了深入理论理解，提出了统一框架描述GMRL算法的变化，并指出现有的随机元梯度估计器实际上是有偏的。 |
| [^321] | [A Number Sense as an Emergent Property of the Manipulating Brain](https://arxiv.org/abs/2012.04132) | 从学习动作预测任务中，出现了一种意想不到的图像表示，展示出预示了感知和 |
| [^322] | [mForms : Multimodal Form-Filling with Question Answering](https://arxiv.org/abs/2011.12340) | 本文提出了一种将表单填充任务重新构造为多模态自然语言问答的新方法，通过预训练的QA系统实现表单元素的填充，并通过多任务训练进一步细化表单填充过程。 |
| [^323] | [Learning Concepts Definable in First-Order Logic with Counting](https://arxiv.org/abs/1909.03820) | 该研究将一阶逻辑与计数符号相结合，证明了可以在多对数度结构下以次线性时间一致学习可定义的分类器，为包含数值方面的机器学习扩展学习框架迈出了第一步。 |
| [^324] | [Distribution-consistency Structural Causal Models.](http://arxiv.org/abs/2401.15911) | 本文提出了分布一致的结构因果模型（DiscoSCMs），用于解决因果建模中的反事实建模挑战。这种模型通过引入分布一致假设来解决因果模型的容量限制，从而提高反事实推理的准确性和实用性。 |
| [^325] | [In-context Learning with Retrieved Demonstrations for Language Models: A Survey.](http://arxiv.org/abs/2401.11624) | 本综述调查了一种名为检索示范的方法，它通过使用特定于输入查询的示范来提高语言模型的少量样本情境学习（ICL）能力。这种方法不仅提高了学习效率和可扩展性，还减少了手动示例选择中的偏见。 |
| [^326] | [Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers.](http://arxiv.org/abs/2401.06461) | 本文通过分析代码的属性，揭示了机器和人类代码之间的独特模式，尤其是结构分割对于识别代码来源很关键。基于这些发现，我们提出了一种名为DetectCodeGPT的新方法来检测机器生成的代码。 |
| [^327] | [Do Vision and Language Encoders Represent the World Similarly?.](http://arxiv.org/abs/2401.05224) | 通过分析视觉和语言模型的潜在空间结构，发现未对齐和对齐的编码器的表示空间在语义上是相似的。我们提出了两种方法来匹配未对齐编码器，无需训练即可实现匹配。 |
| [^328] | [Less is More : A Closer Look at Multi-Modal Few-Shot Learning.](http://arxiv.org/abs/2401.05010) | 该论文提出了一个简单但有效的框架，利用文本信息和语言模型来进行少样本学习任务，充分发挥了预训练语言模型的零样本能力，并直接将视觉特征和文本特征进行推理。 |
| [^329] | [SVGDreamer: Text Guided SVG Generation with Diffusion Model.](http://arxiv.org/abs/2312.16476) | 该论文提出了一种名为SVGDreamer的方法，用于基于文本引导的SVG生成。它通过引入语义驱动的图像矢量化过程和基于注意力的元素控制，增强了生成结果的可编辑性和质量。同时，采用基于矢量化粒子分数蒸馏的方法解决了现有方法中的颜色、平滑度和结果多样性方面的挑战。 |
| [^330] | [Preference as Reward, Maximum Preference Optimization with Importance Sampling.](http://arxiv.org/abs/2312.16430) | 本文提出了一种使用重要性抽样进行最大偏好优化的算法，该算法通过直接优化生成策略来消除对奖励模型的需求，提高了数据利用率和稳定性，并通过解决KL正则化问题来改善偏好学习效果。 |
| [^331] | [VQPy: An Object-Oriented Approach to Modern Video Analytics.](http://arxiv.org/abs/2311.01623) | VQPy是一种面向对象的视频分析方法，它使用Python变体作为前端，并具有可扩展的后端，可以自动构建和优化基于视频对象的处理流程。 |
| [^332] | [The opaque law of artificial intelligence.](http://arxiv.org/abs/2310.13192) | 本文分析了算法的不透明性，重点关注人工智能在因果责任领域中的应用。通过对目前最好的生成式人工智能模型（Chat-GPT）的评估，可以了解其目前的性能以及可能的法律规制形式。 |
| [^333] | [A Multi-Scale Decomposition MLP-Mixer for Time Series Analysis.](http://arxiv.org/abs/2310.11959) | 我们提出了一种名为MSD-Mixer的多尺度分解MLP-Mixer模型，它能够将时间序列分解成不同的组成部分，并在不同的层次中表示这些组成部分。我们还提出了一种新颖的时间拼接方法，以处理多尺度的时间模式和通道间的依赖关系。我们的模型能够比现有方法更好地进行时间序列分析。 |
| [^334] | [SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents.](http://arxiv.org/abs/2310.11667) | SOTOPIA是一个用于评估语言智能中的社交智能的交互式环境。通过模拟复杂的社交互动，并使用全面的评估框架，我们发现不同模型之间的社交智能存在显著差异，特别是在SOTOPIA-hard情景下。GPT-4在这个子集上的目标完成率较低。 |
| [^335] | [The Implications of Decentralization in Blockchained Federated Learning: Evaluating the Impact of Model Staleness and Inconsistencies.](http://arxiv.org/abs/2310.07471) | 本研究评估了将联邦学习的协调外包给区块链等分散网络的实际影响，重点关注了由区块链的运作方式支持的模型陈旧和不一致对异步FL训练过程的影响。 |
| [^336] | [Lemur: Integrating Large Language Models in Automated Program Verification.](http://arxiv.org/abs/2310.04870) | 本论文提出了一种将LLMs和自动推理器结合起来进行自动程序验证的通用方法，并证明了其完备性。这个方法在一些合成和竞争基准上取得了实际的改进。 |
| [^337] | [TACTiS-2: Better, Faster, Simpler Attentional Copulas for Multivariate Time Series.](http://arxiv.org/abs/2310.01327) | TACTiS-2是一种改进的多变量时间序列关注联合分布模型，采用了简化的目标函数和线性参数数量，具有更好的训练动态和最先进的性能。 |
| [^338] | [Tactile Estimation of Extrinsic Contact Patch for Stable Placement.](http://arxiv.org/abs/2309.14552) | 本文介绍了一种利用触觉读数推测物体放置稳定性的方法，通过对接触区域的估计可以有效设计机器人的反馈技能，提高机器人的精细操控能力。 |
| [^339] | [Learning Complete Topology-Aware Correlations Between Relations for Inductive Link Prediction.](http://arxiv.org/abs/2309.11528) | 本文提出了一种基于子图的方法TACO，用于建模高度与拓扑结构相关的关系之间的拓扑感知相关性，并展示了这种方法对于实体无关的归纳链接预测任务的潜力。 |
| [^340] | [HealthFC: A Dataset of Health Claims for Evidence-Based Medical Fact-Checking.](http://arxiv.org/abs/2309.08503) | 本文介绍了一份新的健康声明数据集，其中包含了750个由医学专家标注的健康相关声明，并提供了来自临床研究的证据支持。该数据集可用于机器学习任务，包括证据检索、真实性预测和解释生成。 |
| [^341] | [Separable Hamiltonian Neural Networks.](http://arxiv.org/abs/2309.01069) | 这篇论文介绍了可分离哈密顿神经网络的应用，它通过嵌入可加性分离性来解决高维哈密顿系统中的复杂性问题。 |
| [^342] | [DRL-Based Trajectory Tracking for Motion-Related Modules in Autonomous Driving.](http://arxiv.org/abs/2308.15991) | 本文提出了一种基于深度强化学习的轨迹跟踪方法，适用于自主驾驶系统中的运动相关模块。该方法通过DL的表示学习能力和RL的探索性质，提高了轨迹跟踪的准确性和稳健性，在真实系统中具有较好的适应性和效果。 |
| [^343] | [A Huber Loss Minimization Approach to Byzantine Robust Federated Learning.](http://arxiv.org/abs/2308.12581) | 本文介绍了一种基于Huber损失最小化的新型聚合器用于拜占庭鲁棒的联邦学习。在独立同分布假设下，该方法具有与现有方法相比的优势，并对非i.i.d数据进行了扩展分析。 |
| [^344] | [Causal Intersectionality and Dual Form of Gradient Descent for Multimodal Analysis: a Case Study on Hateful Memes.](http://arxiv.org/abs/2308.11585) | 本篇论文探讨了因果交叉性和双重梯度下降在多模态分析中的应用，以仇恨迷因检测为例。通过结合因果分析和基于梯度的方法，研究发现模型的内部机制可以揭示其因果效应，并介绍了交叉性和模态的梯度注意力的摘要化方法。 |
| [^345] | [A Survey on Large Language Model based Autonomous Agents.](http://arxiv.org/abs/2308.11432) | 该论文综述了基于大型语言模型的自主代理的研究，提供了从整体角度对该领域的系统审查，其创新之处在于利用大量网络知识实现人类水平的智能决策。 |
| [^346] | [Inductive Knowledge Graph Completion with GNNs and Rules: An Analysis.](http://arxiv.org/abs/2308.07942) | 基于图神经网络和规则的归纳知识图谱补全研究了基于规则的方法在实践中的表现不佳的原因，发现不合理的实体没有排名和只考虑最具信息量的路径是影响因素。提出了一些解决这些问题的规则方法的变体，发现其性能接近于基于图神经网络的方法NBFNet。这些变体仅使用了NBFNet所依赖的证据的一小部分。 |
| [^347] | [Our Model Achieves Excellent Performance on MovieLens: What Does it Mean?.](http://arxiv.org/abs/2307.09985) | 该论文通过对MovieLens数据集的分析，发现用户与该平台的交互在不同阶段存在显著差异，并且用户交互受到平台推荐算法推荐的候选电影的影响。 |
| [^348] | [ODD: A Benchmark Dataset for the NLP-based Opioid Related Aberrant Behavior Detection.](http://arxiv.org/abs/2307.02591) | 这个研究介绍了一份名为ODD的新型基准数据集，用于通过分析患者的电子健康记录笔记，检测和分类药物滥用异常行为。这个数据集在药物相关病例的自然语言处理研究中具有重要的创新和贡献。 |
| [^349] | [Sparse Model Soups: A Recipe for Improved Pruning via Model Averaging.](http://arxiv.org/abs/2306.16788) | 本研究通过将多个经过迭代幅度剪枝的模型进行平均，解决了同时利用稀疏性和参数平均的问题，并显著提升了泛化性能。 |
| [^350] | [ConTextual Masked Auto-Encoder for Retrieval-based Dialogue Systems.](http://arxiv.org/abs/2306.04357) | 本研究提出了一种针对对话响应选择的后训练技术Dial-MAE，利用生成方法更好地压缩对话语义至密集向量，并提高对话响应选择准确性。 |
| [^351] | [A Knowledge Engineering Primer.](http://arxiv.org/abs/2305.17196) | 该文介绍了知识工程的基本概念，帮助读者了解该领域并建立直觉。 |
| [^352] | [Prompt Engineering for Healthcare: Methodologies and Applications.](http://arxiv.org/abs/2304.14670) | 本文介绍了医疗保健NLP领域中的提示工程最新进展，强调其在问答系统、文本摘要和机器翻译等应用中的贡献。本文提供了有用资源和桥梁，以更好地探索提示工程在医疗保健领域的应用。 |
| [^353] | [CiPR: An Efficient Framework with Cross-instance Positive Relations for Generalized Category Discovery.](http://arxiv.org/abs/2304.06928) | 该论文提出了一个名为CiPR的框架，通过利用部分标记数据中的跨实例正关系进行对比学习，解决了广义类别发现(GCD)的问题。选择邻居聚类(SNC)算法在此过程中发挥了重要作用。 |
| [^354] | [FrankenSplit: Saliency Guided Neural Feature Compression with Shallow Variational Bottleneck Injection.](http://arxiv.org/abs/2302.10681) | 本文提出了一种基于显著性指导的神经特征压缩与浅层变分瓶颈注入的新的资源意识压缩模型的框架，实现了比最先进的SC方法低60％的比特率，并且比现有的编解码标准的下放快16倍。 |
| [^355] | [Box$^2$EL: Concept and Role Box Embeddings for the Description Logic EL++.](http://arxiv.org/abs/2301.11118) | Box$^2$EL方法通过将概念和角色表示为盒子，克服了传统方法中角色表示受限的问题，并在实验中取得了领先的结果。 |
| [^356] | [EVOTER: Evolution of Transparent Explainable Rule-sets.](http://arxiv.org/abs/2204.10438) | EVOTER使用简单的逻辑表达式演化出透明可解释的规则集，与黑盒模型性能相似，可以揭示数据中的偏见并为未来构建可靠的AI系统提供基础。 |

# 详细

[^1]: ExtremeCast: 提升全球天气预报的极值预测能力

    ExtremeCast: Boosting Extreme Value Prediction for Global Weather Forecast

    [https://rss.arxiv.org/abs/2402.01295](https://rss.arxiv.org/abs/2402.01295)

    ExtremeCast提出了一种新的损失函数Exloss，实现了针对极值的准确预测，同时引入了无需训练的极值增强策略ExEnsemble，提高了预报的稳健性

    

    基于机器学习的数据驱动天气预报在全球中期预报中已经得到了快速发展，并且相较于传统的基于物理的动力学模型表现出更好的性能。然而，大多数这些机器学习模型在准确预测极端天气方面存在困难，而极端值预测与此密切相关。通过数学分析，我们证明使用对称损失，如均方误差（MSE），会导致预测有偏差并低估极值。为了解决这个问题，我们引入了Exloss，一种新的损失函数，通过非对称优化突出极值，以获得准确的极端天气预报。此外，我们还引入了一种无需训练的极值增强策略ExEnsemble，它增加了像素值的方差，并提高了预报的稳健性。结合先进的全球天气预报模型，广泛的实验证明了我们的方法

    Data-driven weather forecast based on machine learning (ML) has experienced rapid development and demonstrated superior performance in the global medium-range forecast compared to traditional physics-based dynamical models. However, most of these ML models struggle with accurately predicting extreme weather, which is closely related to the extreme value prediction. Through mathematical analysis, we prove that the use of symmetric losses, such as the Mean Squared Error (MSE), leads to biased predictions and underestimation of extreme values. To address this issue, we introduce Exloss, a novel loss function that performs asymmetric optimization and highlights extreme values to obtain accurate extreme weather forecast. Furthermore, we introduce a training-free extreme value enhancement strategy named ExEnsemble, which increases the variance of pixel values and improves the forecast robustness. Combined with an advanced global weather forecast model, extensive experiments show that our sol
    
[^2]: 语言校正流：通过概率流推动扩散语言生成

    Language Rectified Flow: Advancing Diffusion Language Generation with Probabilistic Flows

    [https://arxiv.org/abs/2403.16995](https://arxiv.org/abs/2403.16995)

    语言校正流是一种基于标准概率流模型的新方法，通过学习常微分方程模型在源分布和目标分布之间传输，提供了统一和有效的生成模型和领域转移解决方案。

    

    最近的研究表明，在扩散语言模型基础上控制句子属性（例如情感）和结构（例如句法结构）取得了成功。一个推动高质量样本生成的关键组成部分是迭代去噪数千步。尽管有益，但从噪声开始的复杂性和学习步骤限制了其在许多NLP实际应用中的实现。本文提出了Language Rectified Flow方法。我们的方法基于标准概率流模型的重构。语言校正流学习（神经）常微分方程模型在源分布和目标分布之间传输，为生成建模和域转移提供了统一和有效的解决方案。从源分布开始，我们的语言校正流产生快速仿真和有效。

    arXiv:2403.16995v1 Announce Type: cross  Abstract: Recent works have demonstrated success in controlling sentence attributes ($e.g.$, sentiment) and structure ($e.g.$, syntactic structure) based on the diffusion language model. A key component that drives theimpressive performance for generating high-quality samples from noise is iteratively denoise for thousands of steps. While beneficial, the complexity of starting from the noise and the learning steps has limited its implementation to many NLP real-world applications. This paper proposes Language Rectified Flow ({\ours}). Our method is based on the reformulation of the standard probabilistic flow models. Language rectified flow learns (neural) ordinary differential equation models to transport between the source distribution and the target distribution, hence providing a unified and effective solution to generative modeling and domain transfer. From the source distribution, our language rectified flow yields fast simulation and effe
    
[^3]: 做自己：多主体文本到图像生成的有界注意力

    Be Yourself: Bounded Attention for Multi-Subject Text-to-Image Generation

    [https://arxiv.org/abs/2403.16990](https://arxiv.org/abs/2403.16990)

    该论文研究了多主体文本到图像生成中的有界注意力方法，解决了扩散模型注意力层混合不同主体视觉特征导致的语义泄漏问题。

    

    arXiv:2403.16990v1 公告类型：跨主体文本到图像扩散模型具有生成多样且高质量图像的前所未有能力。然而，它们常常难以忠实地捕捉包含多个主题的复杂输入提示的预期语义。最近，许多布局到图像的扩展已被引入以提高用户控制，旨在定位由特定令牌表示的主题。然而，这些方法通常会产生语义不准确的图像，特别是在处理多个在语义上或视觉上相似的主题时。在这项工作中，我们研究并分析了这些限制的原因。我们的探索揭示了这个主要问题起源于去噪过程中主题之间的无意义语义泄漏。这种泄漏归因于扩散模型的注意力层，这些层倾向于混合不同主体的视觉特征。为了解决这些问题，我们引入了有界注意力，一种无需训练的方法

    arXiv:2403.16990v1 Announce Type: cross  Abstract: Text-to-image diffusion models have an unprecedented ability to generate diverse and high-quality images. However, they often struggle to faithfully capture the intended semantics of complex input prompts that include multiple subjects. Recently, numerous layout-to-image extensions have been introduced to improve user control, aiming to localize subjects represented by specific tokens. Yet, these methods often produce semantically inaccurate images, especially when dealing with multiple semantically or visually similar subjects. In this work, we study and analyze the causes of these limitations. Our exploration reveals that the primary issue stems from inadvertent semantic leakage between subjects in the denoising process. This leakage is attributed to the diffusion model's attention layers, which tend to blend the visual features of different subjects. To address these issues, we introduce Bounded Attention, a training-free method for
    
[^4]: 用多方面概念嵌入模型建模常识共性

    Modelling Commonsense Commonalities with Multi-Facet Concept Embeddings

    [https://arxiv.org/abs/2403.16984](https://arxiv.org/abs/2403.16984)

    本文通过明确建模不同的感兴趣方面来改进概念嵌入，使其能够捕捉更广泛的常识属性。

    

    概念嵌入提供了一种实用且高效的机制，将常识知识注入到下游任务中。本文解决了标准嵌入主要反映基本分类类别的问题，通过在学习概念嵌入时明确建模感兴趣的不同方面，得到了能够捕捉更广泛常识属性的嵌入。

    arXiv:2403.16984v1 Announce Type: new  Abstract: Concept embeddings offer a practical and efficient mechanism for injecting commonsense knowledge into downstream tasks. Their core purpose is often not to predict the commonsense properties of concepts themselves, but rather to identify commonalities, i.e.\ sets of concepts which share some property of interest. Such commonalities are the basis for inductive generalisation, hence high-quality concept embeddings can make learning easier and more robust. Unfortunately, standard embeddings primarily reflect basic taxonomic categories, making them unsuitable for finding commonalities that refer to more specific aspects (e.g.\ the colour of objects or the materials they are made of). In this paper, we address this limitation by explicitly modelling the different facets of interest when learning concept embeddings. We show that this leads to embeddings which capture a more diverse range of commonsense properties, and consistently improves resu
    
[^5]: VoiceCraft：野外零-shot语音编辑和文本到语音

    VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild

    [https://arxiv.org/abs/2403.16973](https://arxiv.org/abs/2403.16973)

    VoiceCraft是一个基于标记填充的神经编解码器语言模型，在语音编辑和零-shot文本到语音任务上表现出色，实现了在多样性数据集上的最新性能。

    

    我们介绍了VoiceCraft，一个基于标记填充的神经编解码器语言模型，实现了在有声书、互联网视频和播客上语音编辑和零-shot文本到语音（TTS）方面的最新性能。VoiceCraft采用Transformer解码器架构，并引入了一种标记重排过程，结合了因果掩码和延迟堆叠，以实现在现有序列内的生成。在语音编辑任务上，VoiceCraft生成的编辑语音在自然度方面几乎与未编辑的录音难以区分，经人类评估；对于零-shot TTS，我们的模型优于先前的最先进模型，包括VALLE和流行的商业模型XTTS-v2。关键的是，这些模型在具有多样口音、语音风格、录制条件、背景噪音和音乐的具有挑战性和真实性的数据集上进行了评估，我们的模型与其他模型相比表现始终良好。

    arXiv:2403.16973v1 Announce Type: cross  Abstract: We introduce VoiceCraft, a token infilling neural codec language model, that achieves state-of-the-art performance on both speech editing and zero-shot text-to-speech (TTS) on audiobooks, internet videos, and podcasts. VoiceCraft employs a Transformer decoder architecture and introduces a token rearrangement procedure that combines causal masking and delayed stacking to enable generation within an existing sequence. On speech editing tasks, VoiceCraft produces edited speech that is nearly indistinguishable from unedited recordings in terms of naturalness, as evaluated by humans; for zero-shot TTS, our model outperforms prior SotA models including VALLE and the popular commercial model XTTS-v2. Crucially, the models are evaluated on challenging and realistic datasets, that consist of diverse accents, speaking styles, recording conditions, and background noise and music, and our model performs consistently well compared to other models a
    
[^6]: LLM Agent Operating System

    LLM Agent Operating System

    [https://arxiv.org/abs/2403.16971](https://arxiv.org/abs/2403.16971)

    提出了一种将大型语言模型嵌入操作系统中的LLM代理操作系统，旨在优化资源分配、促进代理间上下文切换、实现并发执行以及为代理提供工具服务。

    

    arXiv:2403.16971v1 公告类型: 跨领域 摘要: 部署大型语言模型（LLM）智能代理存在诸多挑战，会损害它们的效率和功效。其中包括代理请求在LLM上的次优调度和资源分配、在代理和LLM之间交互时保持上下文的困难，以及将具有不同能力和专业化的异构代理集成在一起的复杂性。代理数量和复杂性的快速增加进一步加剧了这些问题，通常会导致资源瓶颈和次优资源利用。受到这些挑战的启发，本文提出了AIOS，一种LLM代理操作系统，它将大型语言模型嵌入操作系统（OS）中。具体地，AIOS旨在优化资源分配，促进代理之间的上下文切换，实现代理的并发执行，为代理提供工具服务。

    arXiv:2403.16971v1 Announce Type: cross  Abstract: The integration and deployment of large language model (LLM)-based intelligent agents have been fraught with challenges that compromise their efficiency and efficacy. Among these issues are sub-optimal scheduling and resource allocation of agent requests over the LLM, the difficulties in maintaining context during interactions between agent and LLM, and the complexities inherent in integrating heterogeneous agents with different capabilities and specializations. The rapid increase of agent quantity and complexity further exacerbates these issues, often leading to bottlenecks and sub-optimal utilization of resources. Inspired by these challenges, this paper presents AIOS, an LLM agent operating system, which embeds large language model into operating systems (OS). Specifically, AIOS is designed to optimize resource allocation, facilitate context switch across agents, enable concurrent execution of agents, provide tool service for agents
    
[^7]: 数据混合规律：通过预测语言建模性能来优化数据混合

    Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance

    [https://arxiv.org/abs/2403.16952](https://arxiv.org/abs/2403.16952)

    该研究发现了数据混合规律，可以量化地预测模型性能与数据混合比例之间的关系，并提出了一种方法来通过拟合函数形式来引导理想的数据混合选择，从而优化大型语言模型的训练混合。

    

    大型语言模型的预训练数据包括多个领域（例如网络文本、学术论文、代码），其混合比例对结果模型的能力至关重要。现有的工作通常依赖于启发式方法或定性策略来调整比例，我们发现了模型性能与混合比例之间的函数形式的定量可预测性，我们称之为数据混合规律。在样本混合上拟合这种函数揭示了未见混合的模型性能，从而引导选择理想的数据混合。此外，我们提出了训练步骤、模型大小和我们的数据混合规律的缩放规律的嵌套使用，以使得仅通过小规模训练就能够预测在各种混合数据下训练的大模型的性能。此外，实验结果验证了我们的方法有效地优化了训练混合。

    arXiv:2403.16952v1 Announce Type: cross  Abstract: Pretraining data of large language models composes multiple domains (e.g., web texts, academic papers, codes), whose mixture proportions crucially impact the competence of outcome models. While existing endeavors rely on heuristics or qualitative strategies to tune the proportions, we discover the quantitative predictability of model performance regarding the mixture proportions in function forms, which we refer to as the data mixing laws. Fitting such functions on sample mixtures unveils model performance on unseen mixtures before actual runs, thus guiding the selection of an ideal data mixture. Furthermore, we propose nested use of the scaling laws of training steps, model sizes, and our data mixing law to enable predicting the performance of large models trained on massive data under various mixtures with only small-scale training. Moreover, experimental results verify that our method effectively optimizes the training mixture of a 
    
[^8]: 与人类判断相一致：大型语言模型评估中成对偏好的作用

    Aligning with Human Judgement: The Role of Pairwise Preference in Large Language Model Evaluators

    [https://arxiv.org/abs/2403.16950](https://arxiv.org/abs/2403.16950)

    在大型语言模型评估中，通过引入成对偏好搜索方法PAIRS，成功解决了LLMs与人类判断不一致的问题，并取得了优于直接打分的最先进性能。

    

    大型语言模型（LLMs）作为自动评估器在评估生成的自然语言质量方面表现出有希望的能力。然而，LLMs在评估中仍存在偏见，常常难以生成与人类评估一致的连贯评估。在这项工作中，我们首先对LLM评估器与人类判断之间的不一致进行系统研究，揭示现有旨在减轻偏见的校准方法不足以有效将LLM评估器对齐。受到RLHF中对偏好数据的使用的启发，我们将评估形式化为一个排序问题，并引入Pairwise-preference Search（PAIRS），这是一种以LLMs进行成对比较并有效对候选文本进行排序的基于不确定性引导的搜索方法。PAIRS在代表性评估任务上实现了最先进的性能，并且显示出比直接打分有显著改进。

    arXiv:2403.16950v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have demonstrated promising capabilities as automatic evaluators in assessing the quality of generated natural language. However, LLMs still exhibit biases in evaluation and often struggle to generate coherent evaluations that align with human assessments. In this work, we first conduct a systematic study of the misalignment between LLM evaluators and human judgement, revealing that existing calibration methods aimed at mitigating biases are insufficient for effectively aligning LLM evaluators. Inspired by the use of preference data in RLHF, we formulate the evaluation as a ranking problem and introduce Pairwise-preference Search (PAIRS), an uncertainty-guided search method that employs LLMs to conduct pairwise comparisons and efficiently ranks candidate texts. PAIRS achieves state-of-the-art performance on representative evaluation tasks and demonstrates significant improvements over direct scoring. Furthe
    
[^9]: SPACE-IDEAS：用于空间创新中显著信息检测的数据集

    SPACE-IDEAS: A Dataset for Salient Information Detection in Space Innovation

    [https://arxiv.org/abs/2403.16941](https://arxiv.org/abs/2403.16941)

    这项研究介绍了SPACE-IDEAS数据集，用于检测与空间创新相关的显著信息，包括多种文本风格，并展示了如何通过多任务学习训练更好的分类器。

    

    arXiv:2403.16941v1 公告类型：跨领域 摘要：利用自然语言处理在文本中检测显著部分已被广泛应用以缓解信息过载的影响。然而，目前可用于此任务的数据集主要源自学术出版物。我们介绍了SPACE-IDEAS，这是一个用于从与空间领域相关的创新理念中检测显著信息的数据集。SPACE-IDEAS中的文本风格多样，包括非正式、技术、学术和商业写作风格。除了手动注释的数据集外，我们还发布了一个使用大型生成语言模型注释的扩展版本。我们训练了不同的句子和序列句分类器，并表明自动注释的数据集可以通过多任务学习来训练更好的分类器。

    arXiv:2403.16941v1 Announce Type: cross  Abstract: Detecting salient parts in text using natural language processing has been widely used to mitigate the effects of information overflow. Nevertheless, most of the datasets available for this task are derived mainly from academic publications. We introduce SPACE-IDEAS, a dataset for salient information detection from innovation ideas related to the Space domain. The text in SPACE-IDEAS varies greatly and includes informal, technical, academic and business-oriented writing styles. In addition to a manually annotated dataset we release an extended version that is annotated using a large generative language model. We train different sentence and sequential sentence classifiers, and show that the automatically annotated dataset can be leveraged using multitask learning to train better classifiers.
    
[^10]: 通过空间、时间和大脑进行反向传播

    Backpropagation through space, time, and the brain

    [https://arxiv.org/abs/2403.16933](https://arxiv.org/abs/2403.16933)

    提出了 Generalized Latent Equilibrium (GLE)，它是一种针对神经元网络的物理动态局部时空信用分配的计算框架。

    

    有效的神经网络学习需要根据它们对解决任务的相对贡献来调整单个突触。然而，无论是生物还是人工的物理神经系统都受到时空局限。这样的网络如何执行高效的信用分配，在很大程度上仍是一个悬而未决的问题。在机器学习中，错误的反向传播算法几乎普遍被空间（BP）和时间（BPTT）两种方式给出答案。然而，BP(TT)被广泛认为依赖于不具生物学意义的假设，特别是关于时空局限性，而正向传播模型，如实时递归学习（RTRL），则受到内存约束的限制。我们引入了广义潜在平衡（GLE），这是一个针对神经元物理动态网络完全局部时空信用分配的计算框架。我们从

    arXiv:2403.16933v1 Announce Type: cross  Abstract: Effective learning in neuronal networks requires the adaptation of individual synapses given their relative contribution to solving a task. However, physical neuronal systems -- whether biological or artificial -- are constrained by spatio-temporal locality. How such networks can perform efficient credit assignment, remains, to a large extent, an open question. In Machine Learning, the answer is almost universally given by the error backpropagation algorithm, through both space (BP) and time (BPTT). However, BP(TT) is well-known to rely on biologically implausible assumptions, in particular with respect to spatiotemporal (non-)locality, while forward-propagation models such as real-time recurrent learning (RTRL) suffer from prohibitive memory constraints. We introduce Generalized Latent Equilibrium (GLE), a computational framework for fully local spatio-temporal credit assignment in physical, dynamical networks of neurons. We start by 
    
[^11]: 利用预训练语言模型进行粗调优的专题文档检索

    Coarse-Tuning for Ad-hoc Document Retrieval Using Pre-trained Language Models

    [https://arxiv.org/abs/2403.16915](https://arxiv.org/abs/2403.16915)

    本研究引入了粗调优作为一个中间学习阶段，连接了预训练和微调，在专题文档检索中显著改善了效果。

    

    在信息检索系统中，利用预训练语言模型（PLM-based IR）进行微调需要学习查询表示和查询-文档关系，除了下游任务特定的学习。本研究引入了粗调优作为一个中间学习阶段，连接了预训练和微调。通过在粗调优学习查询表示和查询-文档关系，我们旨在减少微调的负担，提高下游IR任务的学习效果。我们提出了用于粗调优的查询-文档对预测（QDPP），其预测查询-文档对的适当性。评估实验显示，所提出的方法显著改善了四个专题文档检索数据集中的MRR和/或nDCG@5。此外，查询预测任务的结果表明，粗调优促进了查询表示和查询-文档关系的学习。

    arXiv:2403.16915v1 Announce Type: cross  Abstract: Fine-tuning in information retrieval systems using pre-trained language models (PLM-based IR) requires learning query representations and query-document relations, in addition to downstream task-specific learning. This study introduces coarse-tuning as an intermediate learning stage that bridges pre-training and fine-tuning. By learning query representations and query-document relations in coarse-tuning, we aim to reduce the load of fine-tuning and improve the learning effect of downstream IR tasks. We propose Query-Document Pair Prediction (QDPP) for coarse-tuning, which predicts the appropriateness of query-document pairs. Evaluation experiments show that the proposed method significantly improves MRR and/or nDCG@5 in four ad-hoc document retrieval datasets. Furthermore, the results of the query prediction task suggested that coarse-tuning facilitated learning of query representation and query-document relations.
    
[^12]: 朝向算法忠实性：合成数据与人类生成数据中跨人口统计的心理健康表示

    Towards Algorithmic Fidelity: Mental Health Representation across Demographics in Synthetic vs. Human-generated Data

    [https://arxiv.org/abs/2403.16909](https://arxiv.org/abs/2403.16909)

    本研究通过使用GPT-3分析不同人口统计在合成数据中的压力因素表示，创建出包含不同人口统计群体压力因素的合成数据集，为以后使用LLMs进行数据生成研究提供了见解。

    

    合成数据生成有潜力影响应用和领域，尤其是在数据稀缺的情况下。然而，在将这些数据用于诸如心理健康这样的敏感任务之前，我们需要了解不同人口统计数据在其中的表示方式。在我们的论文中，我们通过探索GPT-3的潜力来分析生成合成数据的可能性，从而探讨其对不同种族和性别组合所产生的各种压力因素，为未来研究人员提供参考，这些研究人员正在研究使用LLMs进行数据生成。我们利用GPT-3开发了HEADROOM，这是一个包括3120篇关于导致抑郁症压力因素的合成数据集，通过控制种族、性别和时间范围（COVID-19之前和之后）。利用这个数据集，我们进行语义和词汇分析来（1）确定每个人口统计群体的主要压力因素；（2）将我们的合成数据与人类生成的数据集进行比较。我们提供了生成查询以发展依赖

    arXiv:2403.16909v1 Announce Type: new  Abstract: Synthetic data generation has the potential to impact applications and domains with scarce data. However, before such data is used for sensitive tasks such as mental health, we need an understanding of how different demographics are represented in it. In our paper, we analyze the potential of producing synthetic data using GPT-3 by exploring the various stressors it attributes to different race and gender combinations, to provide insight for future researchers looking into using LLMs for data generation. Using GPT-3, we develop HEADROOM, a synthetic dataset of 3,120 posts about depression-triggering stressors, by controlling for race, gender, and time frame (before and after COVID-19). Using this dataset, we conduct semantic and lexical analyses to (1) identify the predominant stressors for each demographic group; and (2) compare our synthetic data to a human-generated dataset. We present the procedures to generate queries to develop dep
    
[^13]: 通过定性场景理解和解释实现可信自动驾驶

    Towards Trustworthy Automated Driving through Qualitative Scene Understanding and Explanations

    [https://arxiv.org/abs/2403.16908](https://arxiv.org/abs/2403.16908)

    QXG是一种统一符号和定性表示，利用时空图和定性约束从原始传感器输入中提取场景语义，为自动驾驶提供可信的场景理解和解释。

    

    理解驾驶场景并传达自动驾驶车辆决策是可信自动驾驶的关键要求。本文介绍了定性可解释图（QXG），这是一种用于城市移动中场景理解的统一符号和定性表示。QXG利用时空图和定性约束从原始传感器输入（如LiDAR和摄像头数据）中提取场景语义，提供可解释的场景模型。QXG可以实时增量构建，成为一种适用于车载解释的多种传感器类型的多功能工具。我们的研究展示了QXG在自动驾驶领域的潜力，它可以通过将图形与观察到的行为联系起来来理解决策。这些解释可以用于多种目的。

    arXiv:2403.16908v1 Announce Type: new  Abstract: Understanding driving scenes and communicating automated vehicle decisions are key requirements for trustworthy automated driving. In this article, we introduce the Qualitative Explainable Graph (QXG), which is a unified symbolic and qualitative representation for scene understanding in urban mobility. The QXG enables interpreting an automated vehicle's environment using sensor data and machine learning models. It utilizes spatio-temporal graphs and qualitative constraints to extract scene semantics from raw sensor inputs, such as LiDAR and camera data, offering an interpretable scene model. A QXG can be incrementally constructed in real-time, making it a versatile tool for in-vehicle explanations across various sensor types. Our research showcases the potential of QXG, particularly in the context of automated driving, where it can rationalize decisions by linking the graph with observed actions. These explanations can serve diverse purp
    
[^14]: 多智能体优化用于对网络物理系统安全分析的位置论文

    Multi-Agent Optimization for Safety Analysis of Cyber-Physical Systems: Position Paper

    [https://arxiv.org/abs/2403.16904](https://arxiv.org/abs/2403.16904)

    本文提出了采用优化技术自动化网络物理系统的安全分析中的决策过程，通过多智能体优化方法扩展了传统FMECA，提供了关于系统重要性和开发约束的最佳解决方案。

    

    失效模式、影响和重要性分析（FMECA）是大多数国际标准推荐的一种安全分析方法。经典的FMECA通常以手工填写表格或使用安全分析工具的形式进行。在这两种情况下，设计工程师必须在安全性和其他开发约束之间进行权衡。对于具有数千个指定约束条件的复杂网络物理系统（CPS），这可能导致严重问题，显著影响整个CPS的重要性。在本文中，我们提出采用优化技术来自动化在CPS的FMECA之后进行的决策过程。我们描述了一种基于多智能体的优化方法，扩展了经典的FMECA，以提供关于CPS的重要性和开发约束的最优解。

    arXiv:2403.16904v1 Announce Type: new  Abstract: Failure Mode, Effects and Criticality Analysis (FMECA) is one of the safety analysis methods recommended by most of the international standards. The classical FMECA is made in a form of a table filled in either manually or by using safety analysis tools. In both cases, the design engineers have to choose the trade-offs between safety and other development constraints. In the case of complex cyber-physical systems (CPS) with thousands of specified constraints, this may lead to severe problems and significantly impact the overall criticality of CPS. In this paper, we propose to adopt optimization techniques to automate the decision making process conducted after FMECA of CPS. We describe a multi-agent based optimization method which extends classical FMECA for offering optimal solutions in terms of criticality and development constraints of CPS.
    
[^15]: 朝向安全可信设计的智能合约

    Towards Secure and Trusted-by-Design Smart Contracts

    [https://arxiv.org/abs/2403.16903](https://arxiv.org/abs/2403.16903)

    区块链技术使得智能合约能够安全地数字化佐证交易，为了保证其安全性和可信度，需要朝向安全可信的设计。

    

    分布式不可变账本或区块链允许将佐证交易安全地数字化，无需依赖可信第三方。佐证交易涉及任何形式的物证交换，如货币、出生证明、签证、门票等。区块链提供了传输证据的机制，而智能合约——以分散和复制的方式在区块链内执行的程序——允许在区块链之上对佐证协议进行编码。由于智能合约放弃了可信第三方并在多台匿名机器上运行，因此它构成一个高度关键的程序，必须具有安全性和可信度设计。

    arXiv:2403.16903v1 Announce Type: cross  Abstract: Distributed immutable ledgers, or blockchains, allow the secure digitization of evidential transactions without relying on a trusted third-party. Evidential transactions involve the exchange of any form of physical evidence, such as money, birth certificate, visas, tickets, etc. Most of the time, evidential transactions occur in the context of complex procedures, called evidential protocols, among physical agents. The blockchain provides the mechanisms to transfer evidence, while smart contracts - programs executing within the blockchain in a decentralized and replicated fashion - allow encoding evidential protocols on top of a blockchain.   As a smart contract foregoes trusted third-parties and runs on several machines anonymously, it constitutes a highly critical program that has to be secure and trusted-by-design. While most of the current smart contract languages focus on easy programmability, they do not directly address the need 
    
[^16]: “它存在，你需要它，那你为什么不使用它？”在自然科学研究案例中实现AI系统被领域专家更好地采纳

    "It is there, and you need it, so why do you not use it?" Achieving better adoption of AI systems by domain experts, in the case study of natural science research

    [https://arxiv.org/abs/2403.16895](https://arxiv.org/abs/2403.16895)

    领域专家在自然科学研究中对AI系统的低采用阻碍了人机合作进展，研究发现提出了更好的AI采用建议。

    

    人工智能（AI）在医学和自然科学研究等领域变得无处不在。然而，实际落地时，领域专家经常拒绝使用AI系统。低接受度阻碍了有效的人机合作，即使这对于进步至关重要。在自然科学研究中，科学家对启用AI系统的使用效果不佳会妨碍他们分析数据和推动研究。我们进行了一个以土著文化为基础的研究，对一个面临算法系统低采用率的组织的AI从业者和自然科学家进行了10次深度访谈。研究结果被整合成为更好的AI采用建议：i) 在系统使用的初始阶段积极支持专家，ii) 以用户相关的方式传达系统的能力，以及 iii) 遵循预定义的合作规则。我们讨论了我们研究结果的更广泛影响。

    arXiv:2403.16895v1 Announce Type: cross  Abstract: Artificial Intelligence (AI) is becoming ubiquitous in domains such as medicine and natural science research. However, when AI systems are implemented in practice, domain experts often refuse them. Low acceptance hinders effective human-AI collaboration, even when it is essential for progress. In natural science research, scientists' ineffective use of AI-enabled systems can impede them from analysing their data and advancing their research. We conducted an ethnographically informed study of 10 in-depth interviews with AI practitioners and natural scientists at the organisation facing low adoption of algorithmic systems. Results were consolidated into recommendations for better AI adoption: i) actively supporting experts during the initial stages of system use, ii) communicating the capabilities of a system in a user-relevant way, and iii) following predefined collaboration rules. We discuss the broader implications of our findings and
    
[^17]: 感知力就是你所需要的：北方森林的地形分类

    Proprioception Is All You Need: Terrain Classification for Boreal Forests

    [https://arxiv.org/abs/2403.16877](https://arxiv.org/abs/2403.16877)

    通过引入 BorealTC 数据集，结合现有数据集，我们评估了基于卷积神经网络（CNN）和新颖的状态空间模型（SSM）-Mamba体系结构在北方森林地形分类上的表现。

    

    最近的领域机器人学研究强调了抵御不同类型地形的重要性。北方森林特别受到许多限制机动性的地形的影响，这些地形应该在越野自主导航中加以考虑。此外，作为地球上最大的陆地生物群落之一，北方森林是预计自主车辆将日益普及的地区。在本文中，我们通过引入BorealTC来解决这个问题，这是一个用于基于感知力的地形分类（TC）的公开可用数据集。我们的数据集记录了Husky A200的116分钟的惯性测量单元（IMU）、电机电流和轮胎里程数据，重点关注典型的北方森林地形，特别是雪、冰和淤泥壤。结合我们的数据集与另一个来自最新技术的数据集，我们在TC t

    arXiv:2403.16877v1 Announce Type: cross  Abstract: Recent works in field robotics highlighted the importance of resiliency against different types of terrains. Boreal forests, in particular, are home to many mobility-impeding terrains that should be considered for off-road autonomous navigation. Also, being one of the largest land biomes on Earth, boreal forests are an area where autonomous vehicles are expected to become increasingly common. In this paper, we address this issue by introducing BorealTC, a publicly available dataset for proprioceptive-based terrain classification (TC). Recorded with a Husky A200, our dataset contains 116 min of Inertial Measurement Unit (IMU), motor current, and wheel odometry data, focusing on typical boreal forest terrains, notably snow, ice, and silty loam. Combining our dataset with another dataset from the state-of-the-art, we evaluate both a Convolutional Neural Network (CNN) and the novel state space model (SSM)-based Mamba architecture on a TC t
    
[^18]: 通过随机指令扰动实现GPU本机调度的自动调优

    SIP: Autotuning GPU Native Schedules via Stochastic Instruction Perturbation

    [https://arxiv.org/abs/2403.16863](https://arxiv.org/abs/2403.16863)

    通过随机搜索自动发现更好的GPU本机指令调度，进一步提高CUDA内核的吞吐量

    

    大语言模型(LLMs)自出现以来已成为一个重要的工作负载。然而，由于其拥有数十亿参数并使用大量数据进行训练，它们的计算成本也很高。因此，最近的研究开发了专门用于LLM训练和推断的CUDA内核，而不是依赖于编译器生成的内核，以便尽可能充分利用硬件资源。在这项工作中，我们探讨了通过GPU本机指令优化进一步推动CUDA内核达到极致性能的可能性。与以往的工作相反，我们采用自动优化方法，定义了可能的GPU本机指令调度搜索空间，然后采用随机搜索进行优化。实验表明，通过自动发现更好的GPU本机指令调度，SIP能够进一步提高CUDA内核的吞吐量，并对优化后的调度进行了1000万次测试。

    arXiv:2403.16863v1 Announce Type: cross  Abstract: Large language models (LLMs) have become a significant workload since their appearance. However, they are also computationally expensive as they have billions of parameters and are trained with massive amounts of data. Thus, recent works have developed dedicated CUDA kernels for LLM training and inference instead of relying on compilergenerated ones, so that hardware resources are as fully utilized as possible. In this work, we explore the possibility of GPU native instruction optimization to further push the CUDA kernels to extreme performance. Contrary to prior works, we adopt an automatic optimization approach by defining a search space of possible GPU native instruction schedules, and then we apply stochastic search to perform optimization. Experiments show that SIP can further improve CUDA kernel throughput by automatically discovering better GPU native instruction schedules and the optimized schedules are tested by 10 million tes
    
[^19]: XAIport：用于在AI模型开发中早期采用XAI的服务框架

    XAIport: A Service Framework for the Early Adoption of XAI in AI Model Development

    [https://arxiv.org/abs/2403.16858](https://arxiv.org/abs/2403.16858)

    本研究提出了一种用于早期采用可解释人工智能（XAI）的服务框架XAIport，具有解释质量、架构兼容性和可配置操作三个关键属性，为AI模型的开发提供可信的早期解释。

    

    在这项研究中，我们提出了早期采用可解释人工智能（XAI），重点关注三个属性：解释的质量，解释摘要应该在多种XAI方法中保持一致；架构兼容性，为了有效地将XAI集成到XAI中，XAI方法和要解释的模型的架构风格必须与框架兼容；可配置操作，XAI解释是可操作的，类似于机器学习操作。因此，AI模型的解释应该是可重现的和易处理的，才能获得信任。我们提出了XAIport，这是一个将XAI微服务封装成开放API的框架，为学习模型质量保障提供早期解释观察。XAIport使得可配置的XAI操作与机器学习开发相结合。我们量化了在Microsoft Azure Cognitive Services上将XAI与三种云计算机视觉服务整合的运营成本。

    arXiv:2403.16858v1 Announce Type: new  Abstract: In this study, we propose the early adoption of Explainable AI (XAI) with a focus on three properties: Quality of explanation, the explanation summaries should be consistent across multiple XAI methods; Architectural Compatibility, for effective integration in XAI, the architecture styles of both the XAI methods and the models to be explained must be compatible with the framework; Configurable operations, XAI explanations are operable, akin to machine learning operations. Thus, an explanation for AI models should be reproducible and tractable to be trustworthy. We present XAIport, a framework of XAI microservices encapsulated into Open APIs to deliver early explanations as observation for learning model quality assurance. XAIport enables configurable XAI operations along with machine learning development. We quantify the operational costs of incorporating XAI with three cloud computer vision services on Microsoft Azure Cognitive Services
    
[^20]: 一个专家价值一个代币：通过专家代币路由将多个专家LLM协同作为通用型

    An Expert is Worth One Token: Synergizing Multiple Expert LLMs as Generalist via Expert Token Routing

    [https://arxiv.org/abs/2403.16854](https://arxiv.org/abs/2403.16854)

    通过专家代币路由将多个专家LLM协同作为通用型，可以实现多个专家LLMs的无缝集成，支持隐式专业知识的学习和动态扩展新的专家LLMs，同时更好地隐藏协作细节，展现出比现有多LLM协作范式更好的效果和稳健性。

    

    我们提出了专家代币路由（Expert-Token-Routing），这是一个统一的通用型框架，可以实现多个专家LLM的无缝集成。我们的框架将专家LLMs表示为元LLM词汇中的特殊专家代币。元LLM可以路由到专家LLM，就像生成新代币一样。专家代币路由不仅可以从现有的指导数据集中学习专家LLMs的隐式专业知识，还可以以即插即用的方式动态扩展新的专家LLMs。它还可以隐藏用户视角中的详细协作过程，促进交互就像是一个单一的LLM一样。我们的框架在涵盖六个不同专家领域的基准测试中胜过了各种现有的多LLM协作范式，展现了通过协同多个专家LLM来构建通用型LLM系统的效果和稳健性。

    arXiv:2403.16854v1 Announce Type: cross  Abstract: We present Expert-Token-Routing, a unified generalist framework that facilitates seamless integration of multiple expert LLMs. Our framework represents expert LLMs as special expert tokens within the vocabulary of a meta LLM. The meta LLM can route to an expert LLM like generating new tokens. Expert-Token-Routing not only supports learning the implicit expertise of expert LLMs from existing instruction dataset but also allows for dynamic extension of new expert LLMs in a plug-and-play manner. It also conceals the detailed collaboration process from the user's perspective, facilitating interaction as though it were a singular LLM. Our framework outperforms various existing multi-LLM collaboration paradigms across benchmarks that incorporate six diverse expert domains, demonstrating effectiveness and robustness in building generalist LLM system via synergizing multiple expert LLMs.
    
[^21]: 在法律结果预测模型中迈向可解释性

    Towards Explainability in Legal Outcome Prediction Models

    [https://arxiv.org/abs/2403.16852](https://arxiv.org/abs/2403.16852)

    先例是促进法律NLP模型可解释性的一种自然方式，我们提出了一种新颖的方法来识别法律结果预测模型使用的先例，并发现模型预测结果的能力不错，但其使用先例的方式与人类法官不同。

    

    当前的法律结果预测模型 - 法律NLP的基本组成部分 - 不能解释其推理过程。然而，为了在现实世界中应用这些模型，人类法律主体需要能够理解它们的决策。在普通法案例中，法律从业者通过参考被称为先例的过去案例法律推理到案件结果。我们认为，先例因此成为促进法律NLP模型可解释性的一种自然方式。在本文中，我们提出了一种新颖的方法来识别法律结果预测模型使用的先例。此外，通过制定法律先例的分类法，我们能够比较人类法官和我们的模型在他们依赖的不同类型先例方面的差异。我们发现，虽然模型学会了合理地预测结果，但它们使用的先例方式不同于人类法官。

    arXiv:2403.16852v1 Announce Type: cross  Abstract: Current legal outcome prediction models - a staple of legal NLP - do not explain their reasoning. However, to employ these models in the real world, human legal actors need to be able to understand their decisions. In the case of common law, legal practitioners reason towards the outcome of a case by referring to past case law, known as precedent. We contend that precedent is, therefore, a natural way of facilitating explainability for legal NLP models. In this paper, we contribute a novel method for identifying the precedent employed by legal outcome prediction models. Furthermore, by developing a taxonomy of legal precedent, we are able to compare human judges and our models with respect to the different types of precedent they rely on. We find that while the models learn to predict outcomes reasonably well, their use of precedent is unlike that of human judges.
    
[^22]: ChatGPT是否能够基于Twitter提及来预测文章的撤回？

    Can ChatGPT predict article retraction based on Twitter mentions?

    [https://arxiv.org/abs/2403.16851](https://arxiv.org/abs/2403.16851)

    本研究探讨了ChatGPT是否能够基于Twitter提及来预测文章的撤回，研究发现在预测未来被撤回的有问题文章方面是具有一定潜力的。

    

    检测有问题的研究文章具有重要意义，本研究探讨了根据被撤回文章在Twitter上的提及是否能够在文章被撤回前发出信号，从而在预测未来被撤回的有问题文章方面发挥作用。分析了包括3,505篇已撤回文章及其相关Twitter提及在内的数据集，以及使用粗糙精确匹配方法获取的具有类似特征的3,505篇未撤回文章。通过四种预测方法评估了Twitter提及在预测文章撤回方面的有效性，包括手动标注、关键词识别、机器学习模型和ChatGPT。手动标注的结果表明，的确有被撤回的文章，其Twitter提及包含在撤回前发出信号的可识别证据，尽管它们只占所有被撤回文章的一小部分。

    arXiv:2403.16851v1 Announce Type: cross  Abstract: Detecting problematic research articles timely is a vital task. This study explores whether Twitter mentions of retracted articles can signal potential problems with the articles prior to retraction, thereby playing a role in predicting future retraction of problematic articles. A dataset comprising 3,505 retracted articles and their associated Twitter mentions is analyzed, alongside 3,505 non-retracted articles with similar characteristics obtained using the Coarsened Exact Matching method. The effectiveness of Twitter mentions in predicting article retraction is evaluated by four prediction methods, including manual labelling, keyword identification, machine learning models, and ChatGPT. Manual labelling results indicate that there are indeed retracted articles with their Twitter mentions containing recognizable evidence signaling problems before retraction, although they represent only a limited share of all retracted articles with 
    
[^23]: GreeDy和CoDy：动态图的反事实解释器

    GreeDy and CoDy: Counterfactual Explainers for Dynamic Graphs

    [https://arxiv.org/abs/2403.16846](https://arxiv.org/abs/2403.16846)

    该论文介绍了两种针对动态图的新颖反事实解释方法：GreeDy和CoDy。实验证明，CoDy在寻找重要反事实输入方面表现优异，成功率高达59%。

    

    时间图神经网络（TGNNs）对于建模具有时间变化交互的动态图至关重要，但由于其复杂的模型结构，在可解释性方面面临重大挑战。反事实解释对于理解模型决策至关重要，它研究输入图的变化如何影响结果。本文介绍了两种新颖的 TGNNs 反事实解释方法：GreeDy（动态图的贪心解释器）和 CoDy（动态图的反事实解释器）。它们将解释视为一个搜索问题，寻找改变模型预测的输入图修改。GreeDy 使用简单的贪心方法，而 CoDy 使用复杂的蒙特卡洛树搜索算法。实验证明，两种方法都能有效生成清晰的解释。值得注意的是，CoDy 的性能优于 GreeDy 和现有的事实方法，寻找到重要的反事实输入的成功率提高了高达 59\%。这突出了 CoDy 的优势。

    arXiv:2403.16846v1 Announce Type: cross  Abstract: Temporal Graph Neural Networks (TGNNs), crucial for modeling dynamic graphs with time-varying interactions, face a significant challenge in explainability due to their complex model structure. Counterfactual explanations, crucial for understanding model decisions, examine how input graph changes affect outcomes. This paper introduces two novel counterfactual explanation methods for TGNNs: GreeDy (Greedy Explainer for Dynamic Graphs) and CoDy (Counterfactual Explainer for Dynamic Graphs). They treat explanations as a search problem, seeking input graph alterations that alter model predictions. GreeDy uses a simple, greedy approach, while CoDy employs a sophisticated Monte Carlo Tree Search algorithm. Experiments show both methods effectively generate clear explanations. Notably, CoDy outperforms GreeDy and existing factual methods, with up to 59\% higher success rate in finding significant counterfactual inputs. This highlights CoDy's p
    
[^24]: LLM代理是否会感到后悔？在线学习和游戏案例研究

    Do LLM Agents Have Regret? A Case Study in Online Learning and Games

    [https://arxiv.org/abs/2403.16843](https://arxiv.org/abs/2403.16843)

    通过研究在线学习和博弈论中的基准决策设置，评估LLM代理的交互行为和性能，以了解它们在多代理环境中的潜力和限制。

    

    大型语言模型(LLMs)越来越多地被用于(交互式)决策制定，通过开发基于LLM的自主代理。尽管它们取得了不断的成功，但LLM代理在决策制定中的表现尚未通过定量指标进行充分调查，特别是在它们相互作用时的多代理设置中，这是实际应用中的典型场景。为了更好地理解LLM代理在这些交互环境中的限制，我们建议研究它们在在线学习和博弈论的基准决策设置中的相互作用，并通过\emph{后悔}性能指标进行评估。我们首先在经典(非平稳)在线学习问题中经验性地研究LLMs的无后悔行为，以及当LLM代理通过进行重复游戏进行交互时均衡的出现。然后我们对无后悔行为提供一些理论洞见。

    arXiv:2403.16843v1 Announce Type: cross  Abstract: Large language models (LLMs) have been increasingly employed for (interactive) decision-making, via the development of LLM-based autonomous agents. Despite their emerging successes, the performance of LLM agents in decision-making has not been fully investigated through quantitative metrics, especially in the multi-agent setting when they interact with each other, a typical scenario in real-world LLM-agent applications. To better understand the limits of LLM agents in these interactive environments, we propose to study their interactions in benchmark decision-making settings in online learning and game theory, through the performance metric of \emph{regret}. We first empirically study the {no-regret} behaviors of LLMs in canonical (non-stationary) online learning problems, as well as the emergence of equilibria when LLM agents interact through playing repeated games. We then provide some theoretical insights into the no-regret behavior
    
[^25]: UrbanVLP：用于城市指标预测的多粒度视觉语言预训练基础模型

    UrbanVLP: A Multi-Granularity Vision-Language Pre-Trained Foundation Model for Urban Indicator Prediction

    [https://arxiv.org/abs/2403.16831](https://arxiv.org/abs/2403.16831)

    UrbanVLP是一种多粒度信息集成的视觉语言预训练模型，旨在克服目前城市指标预测中预训练模型的局限性，提高了可解释性和精度

    

    城市指标预测旨在利用数据驱动方法推断不同城市景观中的社会经济指标。然而，目前流行的预训练模型，特别是依赖卫星图像的模型，面临着双重挑战。首先，仅集中在卫星数据中的宏观级别模式可能引入偏见，在微观级别缺乏细致的细节，例如某地的建筑细节。其次，预训练模型缺乏可解释性，限制了它们在提供城市规划透明证据方面的实用性。针对这些问题，本文设计了一种新颖的Vision-Language Pre-Trained Model（UrbanVLP）。我们的UrbanVLP无缝整合来自宏观（卫星）和微观（街景）级别的多粒度信息，克服了先前预训练模型的局限性。此外，它引入了自动生成文本和校准，提高了在下游应用中的可解释性。

    arXiv:2403.16831v1 Announce Type: cross  Abstract: Urban indicator prediction aims to infer socio-economic metrics in diverse urban landscapes using data-driven methods. However, prevalent pre-trained models, particularly those reliant on satellite imagery, face dual challenges. Firstly, concentrating solely on macro-level patterns from satellite data may introduce bias, lacking nuanced details at micro levels, such as architectural details at a place. Secondly, the lack of interpretability in pre-trained models limits their utility in providing transparent evidence for urban planning. In response to these issues, we devise a novel Vision-Language Pre-Trained Model (UrbanVLP) in this paper. Our UrbanVLP seamlessly integrates multi-granularity information from both macro (satellite) and micro (street-view) levels, overcoming the limitations of prior pre-trained models. Moreover, it introduces automatic text generation and calibration, elevating interpretability in downstream application
    
[^26]: 一个无模型的熵正则化逆强化学习算法的收敛性

    Convergence of a model-free entropy-regularized inverse reinforcement learning algorithm

    [https://arxiv.org/abs/2403.16829](https://arxiv.org/abs/2403.16829)

    提出一个无模型的算法来解决熵正则化的逆强化学习问题，该算法能够使用有限样本恢复出专家表现最佳的奖励，并且最终得到的最优策略与专家策略非常接近。

    

    在给定一组专家演示数据集的情况下，逆强化学习旨在恢复一个专家表现最佳的奖励。本文提出了一个无模型的算法来解决熵正则化逆强化学习问题。具体而言，我们采用随机梯度下降更新奖励，采用随机软策略迭代更新策略。假设可以访问一个生成模型，我们证明了我们的算法能够保证使用$\mathcal{O}(1/\varepsilon^{2})$个马尔可夫决策过程（MDP）样本恢复出一个使专家表现最佳的奖励。此外，通过$\mathcal{O}(1/\varepsilon^{4})$个样本，我们证明了与恢复奖励对应的最优策略在总变差距离上与专家策略$\varepsilon$-接近。

    arXiv:2403.16829v1 Announce Type: cross  Abstract: Given a dataset of expert demonstrations, inverse reinforcement learning (IRL) aims to recover a reward for which the expert is optimal. This work proposes a model-free algorithm to solve entropy-regularized IRL problem. In particular, we employ a stochastic gradient descent update for the reward and a stochastic soft policy iteration update for the policy. Assuming access to a generative model, we prove that our algorithm is guaranteed to recover a reward for which the expert is $\varepsilon$-optimal using $\mathcal{O}(1/\varepsilon^{2})$ samples of the Markov decision process (MDP). Furthermore, with $\mathcal{O}(1/\varepsilon^{4})$ samples we prove that the optimal policy corresponding to the recovered reward is $\varepsilon$-close to the expert policy in total variation distance.
    
[^27]: 关于策略重用：一种用于表示和执行调用其他策略的通用策略的表达语言

    On Policy Reuse: An Expressive Language for Representing and Executing General Policies that Call Other Policies

    [https://arxiv.org/abs/2403.16824](https://arxiv.org/abs/2403.16824)

    一种表达通用策略和问题分解的语言引入了内部存储状态、索引特征和模块扩展，使得策略和草图更加灵活和可重用。

    

    最近，一种旨在通过在一组布尔和数值特征上定义的规则来表达和学习通用策略和问题分解（草图）的简单而强大的语言已经被引入。本文考虑了此语言的三个扩展，旨在使策略和草图更加灵活和可重用：内部存储状态，类似于有限状态控制器; 索引特征，其值是状态和一些可装入对象的内部寄存器数量的函数; 以及封装策略和草图的模块，并允许它们通过传递参数相互调用。此外，与选择状态转换而不是基础动作的通用策略不同，新语言允许选择这些动作。通过一些示例展示了所得到的用于策略和草图的语言的表现力。

    arXiv:2403.16824v1 Announce Type: new  Abstract: Recently, a simple but powerful language for expressing and learning general policies and problem decompositions (sketches) has been introduced in terms of rules defined over a set of Boolean and numerical features. In this work, we consider three extensions of this language aimed at making policies and sketches more flexible and reusable: internal memory states, as in finite state controllers; indexical features, whose values are a function of the state and a number of internal registers that can be loaded with objects; and modules that wrap up policies and sketches and allow them to call each other by passing parameters. In addition, unlike general policies that select state transitions rather than ground actions, the new language allows for the selection of such actions. The expressive power of the resulting language for policies and sketches is illustrated through a number of examples.
    
[^28]: 人工智能和人类的辩论：LLM增强的辩论人工智能设计与评估，用于人工智能辅助决策

    Towards Human-AI Deliberation: Design and Evaluation of LLM-Empowered Deliberative AI for AI-Assisted Decision-Making

    [https://arxiv.org/abs/2403.16812](https://arxiv.org/abs/2403.16812)

    提出了人工智能和人类的辩论框架，通过LLM增强的辩论人工智能促进人类反思和讨论决策中的意见分歧。

    

    在人工智能辅助决策中，人类通常被动地审查人工智能的建议，然后决定是否全盘接受或拒绝。在这样的范式中，发现人类很少激发分析思维，且在发生分歧时难以将矛盾意见的细微差别传达给人工智能。为了解决这一挑战，我们提出了人工智能和人类的辩论，这是一个新颖的框架，旨在促进人类在决策过程中对人工智能意见分歧进行反思和讨论。基于人类辩论理论，该框架通过维度级意见征集、辩论讨论和决策更新，将人类和人工智能进行互动。为了赋予人工智能辩论能力，我们设计了辩论人工智能，利用大型语言模型（LLMs）作为人类和领域特定模型之间的桥梁，实现灵活的对话交互和忠实的信息提供。

    arXiv:2403.16812v1 Announce Type: cross  Abstract: In AI-assisted decision-making, humans often passively review AI's suggestion and decide whether to accept or reject it as a whole. In such a paradigm, humans are found to rarely trigger analytical thinking and face difficulties in communicating the nuances of conflicting opinions to the AI when disagreements occur. To tackle this challenge, we propose Human-AI Deliberation, a novel framework to promote human reflection and discussion on conflicting human-AI opinions in decision-making. Based on theories in human deliberation, this framework engages humans and AI in dimension-level opinion elicitation, deliberative discussion, and decision updates. To empower AI with deliberative capabilities, we designed Deliberative AI, which leverages large language models (LLMs) as a bridge between humans and domain-specific models to enable flexible conversational interactions and faithful information provision. An exploratory evaluation on a grad
    
[^29]: 基于LLM的数字孪生体用于优化人在回路系统

    An LLM-Based Digital Twin for Optimizing Human-in-the Loop Systems

    [https://arxiv.org/abs/2403.16809](https://arxiv.org/abs/2403.16809)

    本文提出了一种利用大型语言模型(LLMs)来优化人在回路系统的方法，并通过案例研究展示了在购物中心中模拟各种人群热量偏好的应用。

    

    随着物联网和物理系统(CPS-IoT)应用和基础模型的日益普及，新的应用正在兴起，利用环境的实时控制。例如，对于供暖、通风和空调(HVAC)系统的实时控制可以在不需要为人员舒适而运行时减少其使用，从而降低能源消耗。然而，在实践中，对这种人在回路(HITL)系统中人类偏好的实时反馈收集是困难的。我们提出使用大型语言模型(LLMs)来应对CPS优化中动态环境和难以获取数据的挑战。在本文中，我们提出了一个案例研究，利用LLM代理模仿购物中心中各种人群（如年轻家庭、老年人）的行为和热量偏好。聚合的热量偏好被整合到一个代理体中。

    arXiv:2403.16809v1 Announce Type: cross  Abstract: The increasing prevalence of Cyber-Physical Systems and the Internet of Things (CPS-IoT) applications and Foundation Models are enabling new applications that leverage real-time control of the environment. For example, real-time control of Heating, Ventilation and Air-Conditioning (HVAC) systems can reduce its usage when not needed for the comfort of human occupants, hence reducing energy consumption. Collecting real-time feedback on human preferences in such human-in-the-loop (HITL) systems, however, is difficult in practice. We propose the use of large language models (LLMs) to deal with the challenges of dynamic environments and difficult-to-obtain data in CPS optimization. In this paper, we present a case study that employs LLM agents to mimic the behaviors and thermal preferences of various population groups (e.g. young families, the elderly) in a shopping mall. The aggregated thermal preferences are integrated into an agent-in-th
    
[^30]: 理解欧盟AI法案: 合规安全关键产品的方法论途径

    Navigating the EU AI Act: A Methodological Approach to Compliance for Safety-critical Products

    [https://arxiv.org/abs/2403.16808](https://arxiv.org/abs/2403.16808)

    通过利用产品质量模型和合同法方法，本文提出了一种解释欧盟AI法案对高风险AI系统要求的方法论途径。

    

    2023年12月，欧洲议会暂时同意了欧盟AI法案。这一前所未有的AI系统监管框架制定了确保AI产品安全、合法和值得信赖的指导方针。本文提出了一种方法，通过利用产品质量模型来解释高风险AI系统在欧盟AI法案下的要求。我们首先提出了一个扩展的AI系统产品质量模型，将法案中未涵盖的相关属性纳入考虑。我们将法案要求与相关质量属性进行映射，目的是将其细化为可衡量的特征。然后，我们提出了一种基于合同的方法，从利益相关者层面推导技术要求。这有助于开发和评估不仅符合已建立质量标准，而且符合法案中针对高风险（包括

    arXiv:2403.16808v1 Announce Type: new  Abstract: In December 2023, the European Parliament provisionally agreed on the EU AI Act. This unprecedented regulatory framework for AI systems lays out guidelines to ensure the safety, legality, and trustworthiness of AI products. This paper presents a methodology for interpreting the EU AI Act requirements for high-risk AI systems by leveraging product quality models. We first propose an extended product quality model for AI systems, incorporating attributes relevant to the Act not covered by current quality models. We map the Act requirements to relevant quality attributes with the goal of refining them into measurable characteristics. We then propose a contract-based approach to derive technical requirements at the stakeholder level. This facilitates the development and assessment of AI systems that not only adhere to established quality standards, but also comply with the regulatory requirements outlined in the Act for high-risk (including 
    
[^31]: 基于聚类的神经网络规范化层

    Cluster-Based Normalization Layer for Neural Networks

    [https://arxiv.org/abs/2403.16798](https://arxiv.org/abs/2403.16798)

    该论文提出了一种基于聚类的神经网络规范化方法CB-Norm，通过引入高斯混合模型，解决了梯度稳定性和学习加速方面的挑战。

    

    深度学习在神经网络训练过程中面临重要挑战，包括内部协变量漂移、标签漂移、梯度消失/爆炸、过拟合和计算复杂性。传统的规范化方法，如批标准化，旨在解决其中一些问题，但通常依赖于限制其适应性的假设。混合规范化在处理多个高斯分布时面临计算障碍。本文介绍了基于聚类的规范化（CB-Norm）的两个变体——监督式基于聚类的规范化（SCB-Norm）和无监督式基于聚类的规范化（UCB-Norm），提出了一种开创性的一步规范化方法。CB-Norm利用高斯混合模型来专门解决与梯度稳定性和学习加速有关的挑战。

    arXiv:2403.16798v1 Announce Type: cross  Abstract: Deep learning faces significant challenges during the training of neural networks, including internal covariate shift, label shift, vanishing/exploding gradients, overfitting, and computational complexity. While conventional normalization methods, such as Batch Normalization, aim to tackle some of these issues, they often depend on assumptions that constrain their adaptability. Mixture Normalization faces computational hurdles in its pursuit of handling multiple Gaussian distributions.   This paper introduces Cluster-Based Normalization (CB-Norm) in two variants - Supervised Cluster-Based Normalization (SCB-Norm) and Unsupervised Cluster-Based Normalization (UCB-Norm) - proposing a groundbreaking one-step normalization approach. CB-Norm leverages a Gaussian mixture model to specifically address challenges related to gradient stability and learning acceleration.   For SCB-Norm, a supervised variant, the novel mechanism involves introduc
    
[^32]: 对抗性攻击的解剖学：基于概念的XAI解剖

    The Anatomy of Adversarial Attacks: Concept-based XAI Dissection

    [https://arxiv.org/abs/2403.16782](https://arxiv.org/abs/2403.16782)

    对抗性攻击对卷积神经网络学到的概念产生了实质性的影响，引入新概念或修改现有概念，并且这种影响可以通过线性分解对扰动进行解释。

    

    对抗性攻击(AAs)对深度神经网络的可靠性和鲁棒性构成重大威胁。虽然这些攻击对模型预测的影响已得到广泛研究，但它们对这些模型中学习到的表示和概念的影响仍然大多未被探索。在这项工作中，我们使用可解释的人工智能(XAI)技术，对卷积神经网络(CNNs)中对抗性攻击对学习到的概念的影响进行了深入分析。通过对各种网络架构和有针对性的AA技术进行了大量实验，我们揭示了几个关键发现。首先，AAs在特征空间中造成概念组成的实质性变化，引入新概念或修改现有概念。其次，对抗性扰动本身可以被线性分解为一组潜在矢量分量，其中部分分量负责攻击。

    arXiv:2403.16782v1 Announce Type: cross  Abstract: Adversarial attacks (AAs) pose a significant threat to the reliability and robustness of deep neural networks. While the impact of these attacks on model predictions has been extensively studied, their effect on the learned representations and concepts within these models remains largely unexplored. In this work, we perform an in-depth analysis of the influence of AAs on the concepts learned by convolutional neural networks (CNNs) using eXplainable artificial intelligence (XAI) techniques. Through an extensive set of experiments across various network architectures and targeted AA techniques, we unveil several key findings. First, AAs induce substantial alterations in the concept composition within the feature space, introducing new concepts or modifying existing ones. Second, the adversarial perturbation itself can be linearly decomposed into a set of latent vector components, with a subset of these being responsible for the attack's 
    
[^33]: DeepKnowledge: 基于泛化驱动的深度学习测试

    DeepKnowledge: Generalisation-Driven Deep Learning Testing

    [https://arxiv.org/abs/2403.16768](https://arxiv.org/abs/2403.16768)

    DeepKnowledge提出了一种基于知识泛化理论的深度学习系统测试方法，旨在提高DNN的稳健性并减少黑匣子模型的风险。

    

    尽管深度神经网络取得了前所未有的成功，但它们对数据分布的微小变化极为脆弱，这要求有效的测试技术来评估它们的可靠性。尽管近年来在深度神经网络测试方面取得了进展，但缺乏系统化的测试方法来评估深度神经网络在训练分布之外的数据上泛化和运行的能力。我们通过DeepKnowledge来解决这一问题，这是一种基于知识泛化理论的深度神经网络系统测试方法，旨在增强深度神经网络的稳健性，并减少“黑匣子”模型的剩余风险。根据这一理论，DeepKnowledge认为核心计算DNN单元，称为转移知识神经元，在域变化下可以泛化。DeepKnowledge提供了一种客观的信心度量，用于评估给定数据分布变化的DNN测试活动，并利用这些信息来推动泛化。

    arXiv:2403.16768v1 Announce Type: cross  Abstract: Despite their unprecedented success, DNNs are notoriously fragile to small shifts in data distribution, demanding effective testing techniques that can assess their dependability. Despite recent advances in DNN testing, there is a lack of systematic testing approaches that assess the DNN's capability to generalise and operate comparably beyond data in their training distribution. We address this gap with DeepKnowledge, a systematic testing methodology for DNN-based systems founded on the theory of knowledge generalisation, which aims to enhance DNN robustness and reduce the residual risk of 'black box' models. Conforming to this theory, DeepKnowledge posits that core computational DNN units, termed Transfer Knowledge neurons, can generalise under domain shift. DeepKnowledge provides an objective confidence measurement on testing activities of DNN given data distribution shifts and uses this information to instrument a generalisation-in
    
[^34]: 和抛硬币一样好：人类对AI生成的图像、视频、音频和音视频刺激的检测

    As Good As A Coin Toss Human detection of AI-generated images, videos, audio, and audiovisual stimuli

    [https://arxiv.org/abs/2403.16760](https://arxiv.org/abs/2403.16760)

    通过一项感知研究，评估了人们在日常生活中对合成图像、音频、视频和音视频刺激与真实的区分能力，以探讨人类对欺骗性合成媒体的易受程度。

    

    随着合成媒体变得越来越逼真，使用它的障碍不断降低，这项技术越来越被恶意利用，从金融欺诈到非自愿色情。今天，对抗被合成媒体误导的主要防御依赖于人类观察者在视觉和听觉上区分真假的能力。然而，人们在日常生活中实际上对欺骗性合成媒体有多脆弱仍不清楚。我们进行了一个包含1276名参与者的感知研究，评估人们在区分合成图像、仅音频、仅视频和音视频刺激与真实的准确性如何。为了反映人们在野外可能遇到合成媒体的情况，测试条件和刺激模拟了典型的在线平台，而调查中使用的所有合成媒体均来自

    arXiv:2403.16760v1 Announce Type: cross  Abstract: As synthetic media becomes progressively more realistic and barriers to using it continue to lower, the technology has been increasingly utilized for malicious purposes, from financial fraud to nonconsensual pornography. Today, the principal defense against being misled by synthetic media relies on the ability of the human observer to visually and auditorily discern between real and fake. However, it remains unclear just how vulnerable people actually are to deceptive synthetic media in the course of their day to day lives. We conducted a perceptual study with 1276 participants to assess how accurate people were at distinguishing synthetic images, audio only, video only, and audiovisual stimuli from authentic. To reflect the circumstances under which people would likely encounter synthetic media in the wild, testing conditions and stimuli emulated a typical online platform, while all synthetic media used in the survey was sourced from 
    
[^35]: 角色挖掘中的双目标优化

    Bi-objective Optimization in Role Mining

    [https://arxiv.org/abs/2403.16757](https://arxiv.org/abs/2403.16757)

    该论文提出了角色挖掘中的双目标优化问题，引入了广义噪声角色挖掘问题（GNRM），并证明了其具有固定参数可解性，为解决角色挖掘中的实际问题提供了重要基础。

    

    角色挖掘是一种从现有策略中导出基于角色的授权策略的技术。给定一组用户$U$，一组权限$P$和一个用户-权限授权关系$\mathit{UPA}\subseteq U\times P$，角色挖掘算法旨在计算一组角色$R$，一个用户-角色授权关系$\mathit{UA}\subseteq U\times R$和一个权限-角色授权关系$\mathit{PA}\subseteq R\times P$，以便$\mathit{UA}$和$\mathit{PA}$的组合在某种适当的意义下接近于$\mathit{UPA}$。本文首先介绍了广义噪声角色挖掘问题（GNRM）--最小噪声角色挖掘问题的一般化，我们认为这具有相当大的实际相关性。延续Fomin等人的工作，我们展示了GNRM是具有固定参数可解性的，参数为$r+k$，其中$r$是解决方案中的角色数量，$k$是不一致性数量。

    arXiv:2403.16757v1 Announce Type: cross  Abstract: Role mining is a technique used to derive a role-based authorization policy from an existing policy. Given a set of users $U$, a set of permissions $P$ and a user-permission authorization relation $\mahtit{UPA}\subseteq U\times P$, a role mining algorithm seeks to compute a set of roles $R$, a user-role authorization relation $\mathit{UA}\subseteq U\times R$ and a permission-role authorization relation $\mathit{PA}\subseteq R\times P$, such that the composition of $\mathit{UA}$ and $\mathit{PA}$ is close (in some appropriate sense) to $\mathit{UPA}$.   In this paper, we first introduce the Generalized Noise Role Mining problem (GNRM) -- a generalization of the MinNoise Role Mining problem -- which we believe has considerable practical relevance. Extending work of Fomin et al., we show that GNRM is fixed parameter tractable, with parameter $r + k$, where $r$ is the number of roles in the solution and $k$ is the number of discrepancies b
    
[^36]: 人工总算不那么智能：从形式验证的角度看GenAI

    All Artificial, Less Intelligence: GenAI through the Lens of Formal Verification

    [https://arxiv.org/abs/2403.16750](https://arxiv.org/abs/2403.16750)

    本文研究了再生人工智能中硬件设计中CWEs的形式验证，发现大多数大型语言模型在生成硬件代码时并未考虑硬件CWEs，导致大约60%的硬件设计存在漏洞。

    

    现代硬件设计变得越来越高效和复杂。然而，它们常常容易受到常见弱点枚举（CWEs）的影响。本文关注的是在由大型语言模型（LLMs）赋能的再生人工智能（AI）中，对一组用SystemVerilog编写的硬件设计中CWEs的形式验证。我们应用形式验证来将每个硬件设计分类为易受攻击或无CWE。这个数据集是由4个不同的LLMs生成的，为我们论文中针对的10种CWE中的每一种特性设计了一组独特的设计。我们将识别出的漏洞与CWE编号关联，用于60,000个生成的SystemVerilog寄存器传输级（RTL）代码的数据集。研究还发现，大多数LLMs并不知道任何硬件CWEs；因此，它们通常在生成硬件代码时不予考虑。我们的研究显示，大约60%由LLMs生成的硬件设计存在漏洞。

    arXiv:2403.16750v1 Announce Type: new  Abstract: Modern hardware designs have grown increasingly efficient and complex. However, they are often susceptible to Common Weakness Enumerations (CWEs). This paper is focused on the formal verification of CWEs in a dataset of hardware designs written in SystemVerilog from Regenerative Artificial Intelligence (AI) powered by Large Language Models (LLMs). We applied formal verification to categorize each hardware design as vulnerable or CWE-free. This dataset was generated by 4 different LLMs and features a unique set of designs for each of the 10 CWEs we target in our paper. We have associated the identified vulnerabilities with CWE numbers for a dataset of 60,000 generated SystemVerilog Register Transfer Level (RTL) code. It was also found that most LLMs are not aware of any hardware CWEs; hence they are usually not considered when generating the hardware code. Our study reveals that approximately 60% of the hardware designs generated by LLMs 
    
[^37]: 在迭代神经网络中实现不确定性估计

    Enabling Uncertainty Estimation in Iterative Neural Networks

    [https://arxiv.org/abs/2403.16732](https://arxiv.org/abs/2403.16732)

    迭代神经网络中的新方法利用连续输出的收敛速率作为不确定性的有用代理，提供了比集成方法更低计算成本的先进不确定性估计。

    

    将传递网络架构转变为迭代网络架构，迭代网络使用自身的输出作为输入，这是一种提升性能的众所周知的方法。本文认为这种架构还提供了额外的好处：连续输出的收敛速率与其收敛值的准确性高度相关。因此，我们可以将收敛速率用作不确定性的有用代理。这导致了一种不确定性估计方法，以比诸如集成方法更低的计算成本提供了最先进的估计，而且不需要对原始迭代模型进行任何修改。我们通过将其嵌入到两个应用领域中来展示其实用价值：航空图像中的道路检测和二维和三维形状的空气动力特性估计。

    arXiv:2403.16732v1 Announce Type: new  Abstract: Turning pass-through network architectures into iterative ones, which use their own output as input, is a well-known approach for boosting performance. In this paper, we argue that such architectures offer an additional benefit: The convergence rate of their successive outputs is highly correlated with the accuracy of the value to which they converge. Thus, we can use the convergence rate as a useful proxy for uncertainty. This results in an approach to uncertainty estimation that provides state-of-the-art estimates at a much lower computational cost than techniques like Ensembles, and without requiring any modifications to the original iterative model. We demonstrate its practical value by embedding it in two application domains: road detection in aerial images and the estimation of aerodynamic properties of 2D and 3D shapes.
    
[^38]: 使用定时伪Huber损失改进扩散模型的数据破坏抵抗力

    Improving Diffusion Models's Data-Corruption Resistance using Scheduled Pseudo-Huber Loss

    [https://arxiv.org/abs/2403.16728](https://arxiv.org/abs/2403.16728)

    使用定时伪Huber损失函数改进扩散模型的数据破坏抵抗力，可在保留高质量生成数据的同时提供鲁棒性，并在损坏数据集上展现更好性能。

    

    扩散模型因训练数据中的异常值而脆弱。本文研究了一种替代扩散损失函数，该函数可以在保留高质量生成数据的同时，具有鲁棒性以抵抗异常值。我们建议使用带有时间相关参数的伪Huber损失函数，以在最脆弱的早期逆扩散步骤中实现鲁棒性和最终步骤中细节恢复之间的权衡。我们展示了具有时间相关参数的伪Huber损失在图像和音频领域的损坏数据集上表现更好。此外，我们提出的损失函数可以帮助扩散模型抵抗数据集破坏，而与传统训练算法相比，不需要数据过滤或净化。

    arXiv:2403.16728v1 Announce Type: new  Abstract: Diffusion models are known to be vulnerable to outliers in training data. In this paper we study an alternative diffusion loss function, which can preserve the high quality of generated data like the original squared $L_{2}$ loss while at the same time being robust to outliers. We propose to use pseudo-Huber loss function with a time-dependent parameter to allow for the trade-off between robustness on the most vulnerable early reverse-diffusion steps and fine details restoration on the final steps. We show that pseudo-Huber loss with the time-dependent parameter exhibits better performance on corrupted datasets in both image and audio domains. In addition, the loss function we propose can potentially help diffusion models to resist dataset corruption while not requiring data filtering or purification compared to conventional training algorithms.
    
[^39]: 迈向基于价值的行动和功利伦理的形式化

    Towards a Formalisation of Value-based Actions and Consequentialist Ethics

    [https://arxiv.org/abs/2403.16719](https://arxiv.org/abs/2403.16719)

    该论文提出了一种基于代理人的价值配置和评估的行动框架，为满意的、众元的、以行动为基础的和首选的功利伦理提供了计算框架。

    

    代理人的行动旨在实现与其个人或机构价值更相容的世界状态。为了形式化这一直觉，本文提出了一个基于STRIPS形式化的行动框架。技术上，本文的贡献是通过基于价值的形式推理（VFR）来表达行动，VFR提供了从代理人的价值配置文件和代理人对命题与配置文件的评估中推导出的命题集合。从概念上讲，本文为一种满意的、众元的、以行动为基础的和首选的功利伦理提供了一个计算框架。

    arXiv:2403.16719v1 Announce Type: cross  Abstract: Agents act to bring about a state of the world that is more compatible with their personal or institutional values. To formalise this intuition, the paper proposes an action framework based on the STRIPS formalisation. Technically, the contribution expresses actions in terms of Value-based Formal Reasoning (VFR), which provides a set of propositions derived from an Agent's value profile and the Agent's assessment of propositions with respect to the profile. Conceptually, the contribution provides a computational framework for a form of consequentialist ethics which is satisficing, luralistic, act-based, and preferential.
    
[^40]: 单次领域增量学习

    One-Shot Domain Incremental Learning

    [https://arxiv.org/abs/2403.16707](https://arxiv.org/abs/2403.16707)

    提出了一种处理单次领域增量学习中批归一化层统计数据困难的技术，并展示了其有效性。

    

    在以前关于用于分类的深度神经网络模型的研究中已经讨论了领域增量学习（DIL）。在DIL中，我们假设随着时间的推移观察新领域上的样本。模型必须对所有领域上的输入进行分类。然而，在实践中，我们可能会遇到这样一种情况，即我们需要在新领域的样本仅间歇性地被观察的约束下执行DIL。因此，在本研究中，我们考虑了一个极端情况，即我们只有一份来自新领域的样本，我们称之为单次DIL。我们首先经验性地表明现有的DIL方法在单次DIL中表现不佳。通过各种调查，我们分析了这种失败的原因。根据我们的分析，我们明确了单次DIL的困难是由批归一化层中的统计数据引起的。因此，我们提出了一种关于这些统计数据的技术，并展示了我们技术的有效性。

    arXiv:2403.16707v1 Announce Type: cross  Abstract: Domain incremental learning (DIL) has been discussed in previous studies on deep neural network models for classification. In DIL, we assume that samples on new domains are observed over time. The models must classify inputs on all domains. In practice, however, we may encounter a situation where we need to perform DIL under the constraint that the samples on the new domain are observed only infrequently. Therefore, in this study, we consider the extreme case where we have only one sample from the new domain, which we call one-shot DIL. We first empirically show that existing DIL methods do not work well in one-shot DIL. We have analyzed the reason for this failure through various investigations. According to our analysis, we clarify that the difficulty of one-shot DIL is caused by the statistics in the batch normalization layers. Therefore, we propose a technique regarding these statistics and demonstrate the effectiveness of our tech
    
[^41]: 探究将ChatGPT应用于对话教学在脑电图学中的有效性

    Investigation of the effectiveness of applying ChatGPT in Dialogic Teaching Using Electroencephalography

    [https://arxiv.org/abs/2403.16687](https://arxiv.org/abs/2403.16687)

    探究将ChatGPT应用于对话教学在脑电图学中的有效性，研究发现在对话式教学场景中，ChatGPT能够有效履行教学角色，促进学生学习。

    

    近年来，人工智能技术的快速发展，尤其是大型语言模型（LLMs）如ChatGPT的出现，为教育领域的应用带来了显著的前景。 LLM具有解释知识、回答问题和考虑上下文的能力，因此为学生提供对话式教学支持。因此，检验LLM有效履行教学角色的能力，从而在对话教学场景中促进学生学习的能力，类似于人类教育者，是一个非常有价值的研究课题。 本研究招募了34名本科生作为参与者，随机分为两组。 实验组使用ChatGPT进行对话式教学，而控制组与人类教师互动。 两组都学习了信息相关课程“数字图像”的直方图均衡单元。

    arXiv:2403.16687v1 Announce Type: cross  Abstract: In recent years, the rapid development of artificial intelligence technology, especially the emergence of large language models (LLMs) such as ChatGPT, has presented significant prospects for application in the field of education. LLMs possess the capability to interpret knowledge, answer questions, and consider context, thus providing support for dialogic teaching to students. Therefore, an examination of the capacity of LLMs to effectively fulfill instructional roles, thereby facilitating student learning akin to human educators within dialogic teaching scenarios, is an exceptionally valuable research topic. This research recruited 34 undergraduate students as participants, who were randomly divided into two groups. The experimental group engaged in dialogic teaching using ChatGPT, while the control group interacted with human teachers. Both groups learned the histogram equalization unit in the information-related course "Digital Ima
    
[^42]: 理解尖峰神经网络中建模组件的功能角色

    Understanding the Functional Roles of Modelling Components in Spiking Neural Networks

    [https://arxiv.org/abs/2403.16674](https://arxiv.org/abs/2403.16674)

    系统研究揭示了尖峰神经网络中滤泄、重置和循环等建模组件在平衡记忆保留、时间处理和动态建模方面的功能角色。

    

    受大脑神经回路启发，尖峰神经网络（SNNs）在实现高计算效率和生物保真度方面很有前景。然而，优化SNNs相当困难，因为其建模组件的功能角色仍不清楚。通过设计和评估经典模型的几个变体，我们系统研究了滤泄、重置和循环这些关键建模组件在基于漏积分放电（LIF）的SNNs中的功能角色。通过大量实验，我们演示了这些组件如何影响SNNs的准确性、泛化性和稳健性。具体来说，我们发现滤泄在平衡记忆保留和稳健性方面起着至关重要的作用，重置机制对于不间断的时间处理和计算效率至关重要，而循环则丰富了模型复杂动态的能力，但会损害稳健性。

    arXiv:2403.16674v1 Announce Type: cross  Abstract: Spiking neural networks (SNNs), inspired by the neural circuits of the brain, are promising in achieving high computational efficiency with biological fidelity. Nevertheless, it is quite difficult to optimize SNNs because the functional roles of their modelling components remain unclear. By designing and evaluating several variants of the classic model, we systematically investigate the functional roles of key modelling components, leakage, reset, and recurrence, in leaky integrate-and-fire (LIF) based SNNs. Through extensive experiments, we demonstrate how these components influence the accuracy, generalization, and robustness of SNNs. Specifically, we find that the leakage plays a crucial role in balancing memory retention and robustness, the reset mechanism is essential for uninterrupted temporal processing and computational efficiency, and the recurrence enriches the capability to model complex dynamics at a cost of robustness degr
    
[^43]: 深度强化学习和均值-方差策略用于负责任投资组合优化

    Deep Reinforcement Learning and Mean-Variance Strategies for Responsible Portfolio Optimization

    [https://arxiv.org/abs/2403.16667](https://arxiv.org/abs/2403.16667)

    研究利用深度强化学习进行负责任投资组合优化，并纳入ESG状态和目标，与修改后的均值-方差方法进行比较，结果显示深度强化学习策略在负责任投资组合分配方面具有竞争性表现

    

    投资组合优化涉及确定投资组合资产的最佳配置，以实现给定的投资目标。传统上，通常使用某种形式的均值-方差优化，旨在最大化回报同时最小化风险，然而，近年来，人们开始探索深度强化学习的形式。投资者越来越倾向于在投资决策中纳入ESG目标，因此对经典均值-方差优化框架进行了修改。在本研究中，我们研究了利用深度强化学习进行负责任投资组合优化，通过纳入ESG状态和目标，并针对修改后的均值-方差方法进行比较。我们的结果表明，深度强化学习策略在负责任投资组合分配方面可以提供与均值-方差方法竞争性的表现。

    arXiv:2403.16667v1 Announce Type: new  Abstract: Portfolio optimization involves determining the optimal allocation of portfolio assets in order to maximize a given investment objective. Traditionally, some form of mean-variance optimization is used with the aim of maximizing returns while minimizing risk, however, more recently, deep reinforcement learning formulations have been explored. Increasingly, investors have demonstrated an interest in incorporating ESG objectives when making investment decisions, and modifications to the classical mean-variance optimization framework have been developed. In this work, we study the use of deep reinforcement learning for responsible portfolio optimization, by incorporating ESG states and objectives, and provide comparisons against modified mean-variance approaches. Our results show that deep reinforcement learning policies can provide competitive performance against mean-variance approaches for responsible portfolio allocation across additive 
    
[^44]: 重新审视《睡美人问题》

    Revisiting the Sleeping Beauty problem

    [https://arxiv.org/abs/2403.16666](https://arxiv.org/abs/2403.16666)

    《睡美人问题》从数学角度重新分析，确定了可能的概率空间选择，并提出了一个基于睡美人可获取信息的标准。

    

    arXiv:2403.16666v1 公告类型:交叉摘要:《睡美人问题》是一个概率谜题，二十多年来没有明确解决方案，其解决方案在许多领域都具有极大的兴趣。该问题有两种主要的竞争性解决方案：一半者方法和三分之一者方法。文献中意见分歧的主要原因与使用不同的概率空间来表示相同的概率谜题有关。在这项工作中，我们从数学的角度分析了这个问题，识别了直接从思维实验规则引发的概率分布。确定概率空间的精确选择为这个问题提供了一半者和三分之一者的解决方案。为了尝试决定应该选择哪种方法，提出了一个涉及到睡美人可获得的信息的标准。

    arXiv:2403.16666v1 Announce Type: cross  Abstract: The Sleeping Beauty problem is a probability riddle with no definite solution for more than two decades and its solution is of great interest in many fields of knowledge. There are two main competing solutions to the problem: the halfer approach, and the thirder approach. The main reason for disagreement in the literature is connected to the use of different probability spaces to represent the same probabilistic riddle. In this work, we analyse the problem from a mathematical perspective, identifying probability distributions induced directly from the thought experiment's rules. The precise choices of probability spaces provide both halfer and thirder solutions to the problem. To try and decide on which approach to follow, a criterion involving the information available to Sleeping Beauty is proposed.
    
[^45]: CLHA: 一种简单而有效的用于人类对齐的对比学习框架

    CLHA: A Simple yet Effective Contrastive Learning Framework for Human Alignment

    [https://arxiv.org/abs/2403.16649](https://arxiv.org/abs/2403.16649)

    CLHA提出了一种简单而有效的对比学习框架，可以帮助大型语言模型与人类偏好对齐，通过新颖的重评分策略和损失函数调整，在提升对齐效果的同时简化了训练过程。

    

    人类反馈（RLHF）的强化学习是将大型语言模型（LLMs）与人类偏好对齐的关键技术，确保这些LLMs以对用户有益且易于理解的方式行为。然而，基于RL的人类对齐技术中存在的长期挑战在于其固有的复杂性和训练的困难。为了解决这一挑战，我们提出了一种简单而有效的用于人类对齐的对比学习框架（CLHA），直接将LLMs与人类偏好对齐。CLHA采用一种新颖的重评分策略来评估数据内的噪声，考虑其固有质量并动态调整训练过程。同时，CLHA利用成对对比损失和自适应监督微调损失来自适应地修改生成响应的可能性，确保与人类偏好的增强对齐。使用先进方法，CLHA超越了其他

    arXiv:2403.16649v1 Announce Type: new  Abstract: Reinforcement learning from human feedback (RLHF) is a crucial technique in aligning large language models (LLMs) with human preferences, ensuring these LLMs behave in beneficial and comprehensible ways to users. However, a longstanding challenge in human alignment techniques based on reinforcement learning lies in their inherent complexity and difficulty in training. To address this challenge, we present a simple yet effective Contrastive Learning Framework for Human Alignment (CLHA) to align LLMs with human preferences directly. CLHA employs a novel rescoring strategy to evaluate the noise within the data by considering its inherent quality and dynamically adjusting the training process. Simultaneously, CLHA utilizes pairwise contrastive loss and adaptive supervised fine-tuning loss to adaptively modify the likelihood of generating responses, ensuring enhanced alignment with human preferences. Using advanced methods, CLHA surpasses oth
    
[^46]: 揭示本地差分隐私、平均贝叶斯隐私和最大贝叶斯隐私之间的相互作用

    Deciphering the Interplay between Local Differential Privacy, Average Bayesian Privacy, and Maximum Bayesian Privacy

    [https://arxiv.org/abs/2403.16591](https://arxiv.org/abs/2403.16591)

    论文探讨了本地差分隐私、贝叶斯隐私及其之间的相互关系，揭示了关于效用-隐私权衡的新见解，并提出了一个框架来突出攻击和防御策略的相互作用和效果。

    

    机器学习的迅速发展导致了隐私定义的多样化，由于对隐私构成的威胁，包括本地差分隐私（LDP）的概念。虽然被广泛接受并在许多领域中被利用，但这种传统的隐私测量方法仍然存在一定限制，从无法防止推断披露到缺乏对对手背景知识的考虑。在这项全面研究中，我们引入贝叶斯隐私并深入探讨本地差分隐私和其贝叶斯对应物之间错综复杂的关系，揭示了关于效用-隐私权衡的新见解。我们引入了一个框架，概括了攻击和防御策略，突出它们之间的相互作用和效果。我们的理论贡献基于平均贝叶斯隐私（ABP）和最大贝叶斯隐私之间的严格定义和关系。

    arXiv:2403.16591v1 Announce Type: cross  Abstract: The swift evolution of machine learning has led to emergence of various definitions of privacy due to the threats it poses to privacy, including the concept of local differential privacy (LDP). Although widely embraced and utilized across numerous domains, this conventional approach to measure privacy still exhibits certain limitations, spanning from failure to prevent inferential disclosure to lack of consideration for the adversary's background knowledge. In this comprehensive study, we introduce Bayesian privacy and delve into the intricate relationship between local differential privacy and its Bayesian counterparts, unveiling novel insights into utility-privacy trade-offs. We introduce a framework that encapsulates both attack and defense strategies, highlighting their interplay and effectiveness. Our theoretical contributions are anchored in the rigorous definitions and relationships between Average Bayesian Privacy (ABP) and Max
    
[^47]: 在利用全球遥感数据进行作物分类的多视图学习模型的最佳选择研究

    In the Search for Optimal Multi-view Learning Models for Crop Classification with Global Remote Sensing Data

    [https://arxiv.org/abs/2403.16582](https://arxiv.org/abs/2403.16582)

    研究调查了在全球范围内同时选择融合策略和编码器架构对作物分类具有的影响。

    

    作物分类在研究作物模式变化、资源管理和碳固存中具有至关重要的作用。采用数据驱动技术进行预测时，利用各种时间数据源是必要的。深度学习模型已被证明对将时间序列数据映射到高级表示以进行预测任务非常有效。然而，当处理多个输入模式时，它们面临着重大挑战。文献对多视图学习（MVL）场景提供了有限的指导，主要集中在探索具有特定编码器的融合策略，并在局部地区对其进行验证。相反，我们研究了在全球范围内对农田土地和作物类型进行分类时同时选择融合策略和编码器架构的影响。

    arXiv:2403.16582v1 Announce Type: cross  Abstract: Crop classification is of critical importance due to its role in studying crop pattern changes, resource management, and carbon sequestration. When employing data-driven techniques for its prediction, utilizing various temporal data sources is necessary. Deep learning models have proven to be effective for this task by mapping time series data to high-level representation for prediction. However, they face substantial challenges when dealing with multiple input patterns. The literature offers limited guidance for Multi-View Learning (MVL) scenarios, as it has primarily focused on exploring fusion strategies with specific encoders and validating them in local regions. In contrast, we investigate the impact of simultaneous selection of the fusion strategy and the encoder architecture evaluated on a global-scale cropland and crop-type classifications. We use a range of five fusion strategies (Input, Feature, Decision, Ensemble, Hybrid) an
    
[^48]: SegICL：一种用于增强医学成像分割的通用上下文学习框架

    SegICL: A Universal In-context Learning Framework for Enhanced Segmentation in Medical Imaging

    [https://arxiv.org/abs/2403.16578](https://arxiv.org/abs/2403.16578)

    SegICL引入了一种利用上下文学习的图像分割新方法，能够在新任务中适应医学图像分割，无需从头训练模型或进行复杂微调。

    

    通过上下文学习以新任务中适应的医学图像分割模型是一个令人兴奋的进展。通用分割模型旨在横跨医学图像的不同模态进行概括，然而，它们的效果在应用于分布之外的（OOD）数据模态和任务时通常会减弱，需要对模型进行复杂微调以获得最佳性能。为解决这一挑战，我们引入了SegICL，一种利用上下文学习（ICL）进行图像分割的新方法。与现有方法不同，SegICL能够利用文本引导分割并使用一小组图像-掩码对进行上下文学习，消除了从头开始训练模型或为OOD任务（包括OOD模态和数据集）进行微调的需要。SegICL的大量实验验证表明，提示示例数量与分割之间存在正相关关系。

    arXiv:2403.16578v1 Announce Type: cross  Abstract: Medical image segmentation models adapting to new tasks in a training-free manner through in-context learning is an exciting advancement. Universal segmentation models aim to generalize across the diverse modality of medical images, yet their effectiveness often diminishes when applied to out-of-distribution (OOD) data modalities and tasks, requiring intricate fine-tuning of model for optimal performance. For addressing this challenge, we introduce SegICL, a novel approach leveraging In-Context Learning (ICL) for image segmentation. Unlike existing methods, SegICL has the capability to employ text-guided segmentation and conduct in-context learning with a small set of image-mask pairs, eliminating the need for training the model from scratch or fine-tuning for OOD tasks (including OOD modality and dataset). Extensive experimental validation of SegICL demonstrates a positive correlation between the number of prompt samples and segmentat
    
[^49]: NSINA：用于僧伽罗语的新闻语料库

    NSINA: A News Corpus for Sinhala

    [https://arxiv.org/abs/2403.16571](https://arxiv.org/abs/2403.16571)

    NSINA是为解决僧伽罗语中LLMs适应性挑战而引入的最大新闻语料库，为改进该语言的自然语言处理提供了宝贵资源和基准。

    

    大型语言模型（LLMs）的引入推动了自然语言处理（NLP）的发展，但它们的有效性在很大程度上取决于预训练资源。尤其是在低资源语言（如僧伽罗语）中，这一点尤为明显，因为它们面临着两个主要挑战：缺乏充足的训练数据和有限的基准数据集。为应对这一问题，本研究介绍了NSINA，这是一个包括来自热门僧伽罗语新闻网站的50万多篇文章的全面新闻语料库，以及三项NLP任务：新闻媒体识别、新闻类别预测和新闻标题生成。NSINA的发布旨在为适应僧伽罗语的LLMs带来解决方案，提供有价值的资源和用于改进僧伽罗语NLP的基准。NSINA是迄今为止最大的僧伽罗语新闻语料库。

    arXiv:2403.16571v1 Announce Type: cross  Abstract: The introduction of large language models (LLMs) has advanced natural language processing (NLP), but their effectiveness is largely dependent on pre-training resources. This is especially evident in low-resource languages, such as Sinhala, which face two primary challenges: the lack of substantial training data and limited benchmarking datasets. In response, this study introduces NSINA, a comprehensive news corpus of over 500,000 articles from popular Sinhala news websites, along with three NLP tasks: news media identification, news category prediction, and news headline generation. The release of NSINA aims to provide a solution to challenges in adapting LLMs to Sinhala, offering valuable resources and benchmarks for improving NLP in the Sinhala language. NSINA is the largest news corpus for Sinhala, available up to date.
    
[^50]: FedFixer：在联邦学习中缓解异构标签噪声

    FedFixer: Mitigating Heterogeneous Label Noise in Federated Learning

    [https://arxiv.org/abs/2403.16561](https://arxiv.org/abs/2403.16561)

    提出了FedFixer来解决联邦学习中异构标签噪声的问题，引入个性化模型与全局模型合作来有效选择干净的客户端特定样本，通过置信度正则化器和基于样本共享的双模型更新策略来减轻过拟合问题

    

    联邦学习(FL)在性能上严重依赖标签质量。然而，个体客户端之间的标签分布通常同时存在噪声和异构性。在异构标签噪声中由客户端特定样本引起的高损失对区分客户端特定和嘈杂标签样本构成了挑战，影响了现有标签噪声学习方法的有效性。为了解决这个问题，我们提出了FedFixer，其中引入了个性化模型与全局模型合作，以有效选择干净的客户端特定样本。在双模型中，仅在本地级别更新个性化模型可能导致由于样本有限而对噪声数据过度拟合，进而影响局部和全局模型的性能。为减轻过拟合，我们从两个角度解决了这个问题。

    arXiv:2403.16561v1 Announce Type: cross  Abstract: Federated Learning (FL) heavily depends on label quality for its performance. However, the label distribution among individual clients is always both noisy and heterogeneous. The high loss incurred by client-specific samples in heterogeneous label noise poses challenges for distinguishing between client-specific and noisy label samples, impacting the effectiveness of existing label noise learning approaches. To tackle this issue, we propose FedFixer, where the personalized model is introduced to cooperate with the global model to effectively select clean client-specific samples. In the dual models, updating the personalized model solely at a local level can lead to overfitting on noisy data due to limited samples, consequently affecting both the local and global models' performance. To mitigate overfitting, we address this concern from two perspectives. Firstly, we employ a confidence regularizer to alleviate the impact of unconfident 
    
[^51]: PE：一种用于快速文本层次生成的Poincaré解释方法

    PE: A Poincare Explanation Method for Fast Text Hierarchy Generation

    [https://arxiv.org/abs/2403.16554](https://arxiv.org/abs/2403.16554)

    介绍了一种使用Poincaré解释方法在超几何空间中建模特征交互作用的新方法，并提出了时间复杂度为O(n^2logn)的框架，证明了在投影空间中进行的层次聚类过程可以视为构建最小生成树，提出了一个时间有效的算法

    

    arXiv:2403.16554v1 公告类型: cross 摘要: NLP中深度学习模型的黑盒特性阻碍了它们的广泛应用。研究重点已经转移到层次属性（HA），因为它能够建模特征交互作用。最近的研究使用欧几里得空间中耗时的贪婪搜索来建模非连续组合，忽略了特征表示中潜在的语言信息。在这项工作中，我们引入了一种新颖的方法，即Poincaré解释（PE），用于使用超几何空间建模特征交互作用，时间复杂度为$O(n^2logn)$。受Poincaré模型启发，我们提出了一个框架，将嵌入投影到超几何空间中，这展示出更好的对句法和语义层次结构的归纳偏差。最终，我们证明了投影空间中的层次聚类过程可以被视为构建最小生成树，并提出了一个时间有效的算法。实验结果表明...

    arXiv:2403.16554v1 Announce Type: cross  Abstract: The black-box nature of deep learning models in NLP hinders their widespread application. The research focus has shifted to Hierarchical Attribution (HA) for its ability to model feature interactions. Recent works model non-contiguous combinations with a time-costly greedy search in Eculidean spaces, neglecting underlying linguistic information in feature representations. In this work, we introduce a novel method, namely Poincar\'e Explanation (PE), for modeling feature interactions using hyperbolic spaces in an $O(n^2logn)$ time complexity. Inspired by Poincar\'e model, we propose a framework to project the embeddings into hyperbolic spaces, which exhibit better inductive biases for syntax and semantic hierarchical structures. Eventually, we prove that the hierarchical clustering process in the projected space could be viewed as building a minimum spanning tree and propose a time efficient algorithm. Experimental results demonstrate t
    
[^52]: QKFormer: 使用Q-K注意力的分层脉冲变压器

    QKFormer: Hierarchical Spiking Transformer using Q-K Attention

    [https://arxiv.org/abs/2403.16552](https://arxiv.org/abs/2403.16552)

    QKFormer引入了新颖的脉冲形式Q-K注意力机制、分层结构和补丁嵌入模块，以提高脉冲变压器的性能。

    

    脉冲变压器将脉冲神经网络（SNNs）与变压器架构相结合，由于其节能高性能的潜力，吸引了很多关注。然而，该领域现有模型仍然存在性能不佳的问题。为了提高性能，我们引入了几项创新：i）我们提出了一种为SNNs量身定制的新型脉冲形式Q-K注意力机制，通过具有线性复杂性的二进制向量有效地建模令牌或通道维度的重要性。ii）我们将具有显著性能优势的分层结构引入脉冲变压器，从而获得多尺度脉冲表示，这对大脑和人工神经网络的性能都有显着好处。iii）我们设计了一个通用且强大的补丁嵌入模块，其中包含了一个专门为脉冲变压器设计的变形快捷方式。总之，我们开发了QKFormer，一种分层脉冲变压器。

    arXiv:2403.16552v1 Announce Type: cross  Abstract: Spiking Transformers, which integrate Spiking Neural Networks (SNNs) with Transformer architectures, have attracted significant attention due to their potential for energy efficiency and high performance. However, existing models in this domain still suffer from suboptimal performance. We introduce several innovations to improve the performance: i) We propose a novel spike-form Q-K attention mechanism, tailored for SNNs, which efficiently models the importance of token or channel dimensions through binary vectors with linear complexity. ii) We incorporate the hierarchical structure, which significantly benefits the performance of both the brain and artificial neural networks, into spiking transformers to obtain multi-scale spiking representation. iii) We design a versatile and powerful patch embedding module with a deformed shortcut specifically for spiking transformers. Together, we develop QKFormer, a hierarchical spiking transformer
    
[^53]: 通过对比表示学习提高少样本关系分类中的高效信息提取

    Efficient Information Extraction in Few-Shot Relation Classification through Contrastive Representation Learning

    [https://arxiv.org/abs/2403.16543](https://arxiv.org/abs/2403.16543)

    通过对比学习从多个句子表示中提取互补的判别信息，提高少样本关系分类中的信息提取效率

    

    有限标记实例下的关系分类中区分实体对之间的关系构成少样本关系分类中的重大挑战。文本数据的表示提取了跨领域、实体和关系的丰富信息。在本文中，我们介绍了一种结合多个句子表示和对比学习以增强信息提取的新方法。尽管关系分类中通常使用实体标记令牌提取表示，但我们认为模型内部表示中存在大量未被利用的信息。为了解决这一问题，我们提出了对齐多个句子表示的方法，如[CLS]令牌、提示中使用的[MASK]令牌和实体标记令牌。我们的方法利用对比学习从这些个体表示中提取互补的判别信息。这在低资源环境中特别相关，其中

    arXiv:2403.16543v1 Announce Type: cross  Abstract: Differentiating relationships between entity pairs with limited labeled instances poses a significant challenge in few-shot relation classification. Representations of textual data extract rich information spanning the domain, entities, and relations. In this paper, we introduce a novel approach to enhance information extraction combining multiple sentence representations and contrastive learning. While representations in relation classification are commonly extracted using entity marker tokens, we argue that substantial information within the internal model representations remains untapped. To address this, we propose aligning multiple sentence representations, such as the [CLS] token, the [MASK] token used in prompting, and entity marker tokens. Our method employs contrastive learning to extract complementary discriminative information from these individual representations. This is particularly relevant in low-resource settings where
    
[^54]: 一种中间融合的ViT在扩散模型中实现了文本-图像的高效对齐

    An Intermediate Fusion ViT Enables Efficient Text-Image Alignment in Diffusion Models

    [https://arxiv.org/abs/2403.16530](https://arxiv.org/abs/2403.16530)

    通过一种中间融合的策略，可以提高文本到图像对齐的生成质量，并通过减少低秩文本到图像注意力计算来提高训练和推理效率。

    

    扩散模型被广泛应用于条件数据跨模态生成任务，如文本到图像和文本到视频。然而，最先进的模型仍然未能将生成的视觉概念与高级语义（如物体数量、空间关系等）进行对齐。我们从多模态数据融合的角度来解决这个问题，并研究了不同融合策略如何影响视觉-语言对齐。我们发现，与在预训练图像特征空间中广泛使用的早期融合相比，一种特别设计的中间融合可以：(i) 提高文本到图像对齐的生成质量；(ii) 通过减少低秩文本到图像注意力计算来提高训练和推理效率。我们在MS-COCO数据集上进行了文本到图像生成任务的实验。我们将我们的中间融合机制与经典的早期融合机制进行了比较。

    arXiv:2403.16530v1 Announce Type: cross  Abstract: Diffusion models have been widely used for conditional data cross-modal generation tasks such as text-to-image and text-to-video. However, state-of-the-art models still fail to align the generated visual concepts with high-level semantics in a language such as object count, spatial relationship, etc. We approach this problem from a multimodal data fusion perspective and investigate how different fusion strategies can affect vision-language alignment. We discover that compared to the widely used early fusion of conditioning text in a pretrained image feature space, a specially designed intermediate fusion can: (i) boost text-to-image alignment with improved generation quality and (ii) improve training and inference efficiency by reducing low-rank text-to-image attention calculations. We perform experiments using a text-to-image generation task on the MS-COCO dataset. We compare our intermediate fusion mechanism with the classic early fu
    
[^55]: 基于基础模型的幻觉检测：灵活定义与现有技术综述

    Hallucination Detection in Foundation Models for Decision-Making: A Flexible Definition and Review of the State of the Art

    [https://arxiv.org/abs/2403.16527](https://arxiv.org/abs/2403.16527)

    基于基础模型的幻觉检测旨在填补现有规划者缺少的常识推理，以适用于超出分布任务的场景。

    

    自主系统即将无处不在，从制造业的自主性到农业领域的机器人，从医疗助理到娱乐产业。大多数系统是通过模块化的子组件开发的，用于决策、规划和控制，这些组件可能是手工设计的，也可能是基于学习的。虽然现有方法在它们专门设计的情境下表现良好，但在测试时不可避免地会在罕见的、超出分布范围的场景下表现特别差。基于多个任务训练的基础模型的兴起，以及从各个领域采集的令人印象深刻的大型数据集，使研究人员相信这些模型可能提供现有规划者所缺乏的常识推理。研究人员认为，这种常识推理将弥合算法开发和部署之间的差距，适用于超出分布任务的情况。

    arXiv:2403.16527v1 Announce Type: new  Abstract: Autonomous systems are soon to be ubiquitous, from manufacturing autonomy to agricultural field robots, and from health care assistants to the entertainment industry. The majority of these systems are developed with modular sub-components for decision-making, planning, and control that may be hand-engineered or learning-based. While these existing approaches have been shown to perform well under the situations they were specifically designed for, they can perform especially poorly in rare, out-of-distribution scenarios that will undoubtedly arise at test-time. The rise of foundation models trained on multiple tasks with impressively large datasets from a variety of fields has led researchers to believe that these models may provide common sense reasoning that existing planners are missing. Researchers posit that this common sense reasoning will bridge the gap between algorithm development and deployment to out-of-distribution tasks, like
    
[^56]: 利用LLMs的力量进行MAS中的规范推理

    Harnessing the power of LLMs for normative reasoning in MASs

    [https://arxiv.org/abs/2403.16524](https://arxiv.org/abs/2403.16524)

    本文研究了利用LLMs为MAS中的agent赋予规范能力的潜力，并提出了创建具有规范功能的LLM agent的愿景。

    

    软件agent，无论是人类还是计算机，都不是独立存在的，通常需要与他人协作或协调以实现他们的目标。在人类社会中，规范等社会机制确保了有效的运行，研究人员在多Agent系统（MAS）中采用这些技术来创建具有社会意识的agent。然而，传统技术存在一些局限性，比如在有限环境中运作，通常使用脆弱的符号推理。大语言模型（LLMs）的出现提供了一个有希望的解决方案，提供了一个丰富和富有表现力的词汇表达规范，使能够执行一系列任务的具有规范功能的agent，如规范发现、规范推理和决策。本文研究了基于LLM的agent获得规范能力的潜力，借鉴了最近自然语言处理（NLP）和LLM研究。我们提出了创建规范LLM agent的愿景。

    arXiv:2403.16524v1 Announce Type: new  Abstract: Software agents, both human and computational, do not exist in isolation and often need to collaborate or coordinate with others to achieve their goals. In human society, social mechanisms such as norms ensure efficient functioning, and these techniques have been adopted by researchers in multi-agent systems (MAS) to create socially aware agents. However, traditional techniques have limitations, such as operating in limited environments often using brittle symbolic reasoning. The advent of Large Language Models (LLMs) offers a promising solution, providing a rich and expressive vocabulary for norms and enabling norm-capable agents that can perform a range of tasks such as norm discovery, normative reasoning and decision-making. This paper examines the potential of LLM-based agents to acquire normative capabilities, drawing on recent Natural Language Processing (NLP) and LLM research. We present our vision for creating normative LLM agent
    
[^57]: 利用高阶累积量和路径分析从泊松分支结构因果模型中发现因果关系

    Causal Discovery from Poisson Branching Structural Causal Model Using High-Order Cumulant with Path Analysis

    [https://arxiv.org/abs/2403.16523](https://arxiv.org/abs/2403.16523)

    从计数数据中发现因果结构的关键挑战在于非可辨识性问题，本研究发现在泊松分支结构因果模型中，如果根顶点$X$是已知的，则可以确定从$X$到其子节点$Y$的因果顺序。

    

    计数数据在金融、神经科学和流行病学等领域中自然产生，在各种科学和工业场景中发现计数数据之间的因果结构是一项关键任务。计数数据的一个最常见特征是由二项式稀疏运算符和独立的泊松分布描述的固有分支结构，该结构捕捉了分支和噪声。例如，在人口计数情景中，死亡和移民对计数有贡献，其中生存遵循伯努利分布，移民遵循泊松分布。然而，由于不可辨识性问题，从这些数据中发现因果关系具有挑战性：单一因果对是马尔可夫等价的，即$X\rightarrow Y$和$Y\rightarrow X$在分布上是等价的。幸运的是，在这项工作中，我们发现如果$X$是一个根顶点，那么从$X$到其子节点$Y$的因果顺序是可识别的。

    arXiv:2403.16523v1 Announce Type: cross  Abstract: Count data naturally arise in many fields, such as finance, neuroscience, and epidemiology, and discovering causal structure among count data is a crucial task in various scientific and industrial scenarios. One of the most common characteristics of count data is the inherent branching structure described by a binomial thinning operator and an independent Poisson distribution that captures both branching and noise. For instance, in a population count scenario, mortality and immigration contribute to the count, where survival follows a Bernoulli distribution, and immigration follows a Poisson distribution. However, causal discovery from such data is challenging due to the non-identifiability issue: a single causal pair is Markov equivalent, i.e., $X\rightarrow Y$ and $Y\rightarrow X$ are distributed equivalent. Fortunately, in this work, we found that the causal order from $X$ to its child $Y$ is identifiable if $X$ is a root vertex and
    
[^58]: LLMs是少样本情境低资源语言学习器

    LLMs Are Few-Shot In-Context Low-Resource Language Learners

    [https://arxiv.org/abs/2403.16512](https://arxiv.org/abs/2403.16512)

    该研究对25种低资源语言和7种相对较高资源语言上的情境学习（ICL）及其跨语言变体进行了研究，发现了在低资源语言中使用LLMs进行ICL的有效性，提出了替代方法查询对齐，并为低资源语言的ICL提供了宝贵见解。

    

    在情境学习（ICL）的支持下，大型语言模型（LLMs）可以利用短时的情境信息执行各种任务，这为缩小高资源语言和低资源语言之间的差距提供了重要途径。然而，目前只有少数研究探讨了针对低资源语言的ICL，其中大部分集中在相对高资源的语言，比如法语和西班牙语。在这项工作中，我们对25种低资源语言和7种相对较高资源语言上的ICL及其跨语言变体（X-ICL）进行了广泛研究。我们的研究不仅评估了LLMs在低资源语言中使用ICL的有效性，还发现了情境标签对齐的缺陷，并引入了更有效的替代方法：查询对齐。此外，我们为低资源语言的ICL的各个方面提供了宝贵的见解。我们的研究总结了少样本情境学习的重要性。

    arXiv:2403.16512v1 Announce Type: cross  Abstract: In-context learning (ICL) empowers large language models (LLMs) to perform diverse tasks in underrepresented languages using only short in-context information, offering a crucial avenue for narrowing the gap between high-resource and low-resource languages. Nonetheless, there is only a handful of works explored ICL for low-resource languages with most of them focusing on relatively high-resource languages, such as French and Spanish. In this work, we extensively study ICL and its cross-lingual variation (X-ICL) on 25 low-resource and 7 relatively higher-resource languages. Our study not only assesses the effectiveness of ICL with LLMs in low-resource languages but also identifies the shortcomings of in-context label alignment, and introduces a more effective alternative: query alignment. Moreover, we provide valuable insights into various facets of ICL for low-resource languages. Our study concludes the significance of few-shot in-cont
    
[^59]: 重返传统：用经典机器学习学习可靠的启发式

    Return to Tradition: Learning Reliable Heuristics with Classical Machine Learning

    [https://arxiv.org/abs/2403.16508](https://arxiv.org/abs/2403.16508)

    通过使用WL算法生成特征，并结合经典机器学习方法，提出的WL-GOOSE方法可靠地学习规划启发式，性能优于$h^{\text{FF}}$启发式和LAMA，在特定领域取得了优异表现

    

    目前学习规划的方法在几个领域仍未能与经典规划器竞争，并且总体性能较差。在这项工作中，我们构建了抬升规划任务的新颖图表示，并使用WL算法从中生成特征。这些特征与经典机器学习方法一起使用，其参数数量比最先进的规划深度学习模型少2个数量级，并且训练速度比其快3个数量级。我们的新方法WL-GOOSE可可靠地从零开始学习启发式，并在公平竞争环境中胜过了$h^{\text{FF}}$启发式。它在覆盖率上超过或并列于LAMA的10个领域中的4个领域，并且在计划质量上超过或并列于7个领域中的LAMA。WL-GOOSE是第一个实现这些成就的学习规划模型。此外，我们研究了我们的新型WL特征生成方法与其他方法之间的联系

    arXiv:2403.16508v1 Announce Type: new  Abstract: Current approaches for learning for planning have yet to achieve competitive performance against classical planners in several domains, and have poor overall performance. In this work, we construct novel graph representations of lifted planning tasks and use the WL algorithm to generate features from them. These features are used with classical machine learning methods which have up to 2 orders of magnitude fewer parameters and train up to 3 orders of magnitude faster than the state-of-the-art deep learning for planning models. Our novel approach, WL-GOOSE, reliably learns heuristics from scratch and outperforms the $h^{\text{FF}}$ heuristic in a fair competition setting. It also outperforms or ties with LAMA on 4 out of 10 domains on coverage and 7 out of 10 domains on plan quality. WL-GOOSE is the first learning for planning model which achieves these feats. Furthermore, we study the connections between our novel WL feature generation 
    
[^60]: 学习使用视觉-语言模型指导人类决策者

    Learning To Guide Human Decision Makers With Vision-Language Models

    [https://arxiv.org/abs/2403.16501](https://arxiv.org/abs/2403.16501)

    提出了“学习指导”（LTG）框架，旨在解决专家可能过度依赖机器决策和面临无助于模型放弃的决策的问题。

    

    越来越多的人对开发人工智能以协助人类进行高风险任务中的决策表现出兴趣，比如医学诊断，旨在提高决策质量和减少认知负担。主流方法是将专家与机器学习模型合作，将更安全的决策下放，让前者专注于需要他们关注的情况。然而，在高风险场景中，这种“责任分工”设置是不够的。

    arXiv:2403.16501v1 Announce Type: new  Abstract: There is increasing interest in developing AIs for assisting human decision making in \textit{high-stakes} tasks, such as medical diagnosis, for the purpose of improving decision quality and reducing cognitive strain.   %   Mainstream approaches team up an expert with a machine learning model to which safer decisions are offloaded, thus letting the former focus on cases that demand their attention.   %   This \textit{separation of responsibilities} setup, however, is inadequate for high-stakes scenarios. On the one hand, the expert may end up over-relying on the machine's decisions due to \textit{anchoring bias}, thus losing the human oversight that is increasingly being required by regulatory agencies to ensure trustworthy AI. On the other hand, the expert is left entirely unassisted on the (typically hardest) decisions on which the model abstained.   %   As a remedy, we introduce \textit{learning to guide} (LTG), an alternative framewo
    
[^61]: LSTTN：基于长短期Transformer的时空神经网络用于交通流量预测

    LSTTN: A Long-Short Term Transformer-based Spatio-temporal Neural Network for Traffic Flow Forecasting

    [https://arxiv.org/abs/2403.16495](https://arxiv.org/abs/2403.16495)

    LSTTN框架综合考虑历史交通流量中的长期和短期特征，通过掩码子序列Transformer解决了现有STGNNs模型只能利用短程交通流量数据的限制，实现了对交通流量复杂趋势和周期特征的充分学习

    

    准确的交通预测是智能交通系统中一个基本问题，通过时空图神经网络（STGNNs）学习带关键信息的长程交通表示是当前交通流量预测模型的基本假设。然而，由于结构限制，现有的STGNNs只能利用短程交通流量数据；因此，这些模型无法充分学习交通流量中的复杂趋势和周期特征。此外，从长期历史交通系列中提取关键时间信息并获得紧凑表示也具有挑战性。为解决上述问题，我们提出了一种新颖的LSTTN（Long-Short Term Transformer-based Network）框架，全面考虑历史交通流量中的长期和短期特征。首先，我们利用一个掩码子序列Transformer来推断来自少量未被掩码的子序列的内容

    arXiv:2403.16495v1 Announce Type: cross  Abstract: Accurate traffic forecasting is a fundamental problem in intelligent transportation systems and learning long-range traffic representations with key information through spatiotemporal graph neural networks (STGNNs) is a basic assumption of current traffic flow prediction models. However, due to structural limitations, existing STGNNs can only utilize short-range traffic flow data; therefore, the models cannot adequately learn the complex trends and periodic features in traffic flow. Besides, it is challenging to extract the key temporal information from the long historical traffic series and obtain a compact representation. To solve the above problems, we propose a novel LSTTN (Long-Short Term Transformer-based Network) framework comprehensively considering the long- and short-term features in historical traffic flow. First, we employ a masked subseries Transformer to infer the content of masked subseries from a small portion of unmask
    
[^62]: FedAC：一种用于异构数据的自适应分簇联邦学习框架

    FedAC: A Adaptive Clustered Federated Learning Framework for Heterogeneous Data

    [https://arxiv.org/abs/2403.16460](https://arxiv.org/abs/2403.16460)

    FedAC框架通过解耦神经网络，使用不同聚合方法为每个子模块提供全局知识，引入经济高效的在线模型相似度度量，及集群数量微调模块，显著提高了性能。

    

    本文提出了一种自适应的分簇联邦学习框架FedAC，该框架通过解耦神经网络并利用不同的聚合方法为每个子模块有效地将全局知识整合到簇内学习中，显著提高了性能；引入了一种基于降维的经济高效的在线模型相似度度量；并且结合了一个用于改进复杂性的集群数量微调模块，从而提高了适应性和可伸缩性。

    arXiv:2403.16460v1 Announce Type: cross  Abstract: Clustered federated learning (CFL) is proposed to mitigate the performance deterioration stemming from data heterogeneity in federated learning (FL) by grouping similar clients for cluster-wise model training. However, current CFL methods struggle due to inadequate integration of global and intra-cluster knowledge and the absence of an efficient online model similarity metric, while treating the cluster count as a fixed hyperparameter limits flexibility and robustness. In this paper, we propose an adaptive CFL framework, named FedAC, which (1) efficiently integrates global knowledge into intra-cluster learning by decoupling neural networks and utilizing distinct aggregation methods for each submodule, significantly enhancing performance; (2) includes a costeffective online model similarity metric based on dimensionality reduction; (3) incorporates a cluster number fine-tuning module for improved adaptability and scalability in complex,
    
[^63]: DeepMachining: 铣床机床加工误差在线预测

    DeepMachining: Online Prediction of Machining Errors of Lathe Machines

    [https://arxiv.org/abs/2403.16451](https://arxiv.org/abs/2403.16451)

    DeepMachining是一种基于深度学习的AI系统，可以在线预测车床机床加工操作的误差，通过预训练和微调模型，实现了高准确性预测，是首批使用预训练深度学习模型预测车床机床加工误差的工厂实验之一。

    

    我们描述了DeepMachining，这是一种基于深度学习的人工智能系统，用于在线预测车床加工操作的加工误差。我们基于工厂的制造数据构建并评估了DeepMachining。具体来说，我们首先对特定车床机床操作预训练深度学习模型，以学习加工状态的显著特征。然后，我们微调预训练模型以适应特定加工任务。我们展示了DeepMachining在涉及不同工件和刀具的多个任务中实现了高预测准确性。据我们所知，这项工作是使用预训练深度学习模型预测车床机床加工误差的首批工厂实验之一。

    arXiv:2403.16451v1 Announce Type: cross  Abstract: We describe DeepMachining, a deep learning-based AI system for online prediction of machining errors of lathe machine operations. We have built and evaluated DeepMachining based on manufacturing data from factories. Specifically, we first pretrain a deep learning model for a given lathe machine's operations to learn the salient features of machining states. Then, we fine-tune the pretrained model to adapt to specific machining tasks. We demonstrate that DeepMachining achieves high prediction accuracy for multiple tasks that involve different workpieces and cutting tools. To the best of our knowledge, this work is one of the first factory experiments using pre-trained deep-learning models to predict machining errors of lathe machines.
    
[^64]: CodeS: 通过多层草图实现自然语言到代码仓库的转换

    CodeS: Natural Language to Code Repository via Multi-Layer Sketch

    [https://arxiv.org/abs/2403.16443](https://arxiv.org/abs/2403.16443)

    CodeS提出了一个新的软件工程任务NL2Repo，旨在从自然语言需求中生成整个代码仓库，通过多层草图的方式解决这一任务。

    

    大型语言模型（LLMs）在代码相关任务上的出色性能展示了完全自动化软件开发的潜力。鉴于此，我们介绍了一个新的软件工程任务，即自然语言到代码仓库（NL2Repo）。该任务旨在从自然语言需求中生成整个代码仓库。为了解决这一任务，我们提出了一个简单而有效的框架 CodeS，通过多层草图将NL2Repo分解为多个子任务。具体而言，CodeS包括三个模块：RepoSketcher，FileSketcher和SketchFiller。RepoSketcher首先为给定的需求生成代码仓库的目录结构；FileSketcher然后为生成的结构中的每个文件生成一个文件草图；SketchFiller最终为生成的文件草图中的每个函数填充细节。为了严格评估CodeS在NL2Repo任务上的表现，我们通过自动和手动的方式进行评估。

    arXiv:2403.16443v1 Announce Type: cross  Abstract: The impressive performance of large language models (LLMs) on code-related tasks has shown the potential of fully automated software development. In light of this, we introduce a new software engineering task, namely Natural Language to code Repository (NL2Repo). This task aims to generate an entire code repository from its natural language requirements. To address this task, we propose a simple yet effective framework CodeS, which decomposes NL2Repo into multiple sub-tasks by a multi-layer sketch. Specifically, CodeS includes three modules: RepoSketcher, FileSketcher, and SketchFiller. RepoSketcher first generates a repository's directory structure for given requirements; FileSketcher then generates a file sketch for each file in the generated structure; SketchFiller finally fills in the details for each function in the generated file sketch. To rigorously assess CodeS on the NL2Repo task, we carry out evaluations through both automat
    
[^65]: $\textit{LinkPrompt}$: 基于提示的语言模型的自然和通用对抗攻击

    $\textit{LinkPrompt}$: Natural and Universal Adversarial Attacks on Prompt-based Language Models

    [https://arxiv.org/abs/2403.16432](https://arxiv.org/abs/2403.16432)

    基于提示的语言模型的优化过程揭示了生成对抗提示以误导模型的见解，引发了对该范式对抗性脆弱性的担忧。

    

    Prompt-based learning 是一种新的语言模型训练范式，它将预训练语言模型（PLMs）调整到下游任务，从而在各种自然语言处理（NLP）任务中提升了性能基准。一些研究表明，通过优化搜索提示的有效性，而不是使用固定的提示模板来微调模型。这种基于提示优化过程对PLMs的学习也揭示了生成对抗提示以误导模型的见解，引发了对这一范式对抗性脆弱性的担忧。最近的研究表明，可以生成通用对抗触发器（UATs）来改变不仅目标PLMs的预测，还有对应Prompt-based Fine-tuning Models（PFMs）的预测。然而，以前作品中发现的UATs通常是无法阅读的令牌或字符。

    arXiv:2403.16432v1 Announce Type: cross  Abstract: Prompt-based learning is a new language model training paradigm that adapts the Pre-trained Language Models (PLMs) to downstream tasks, which revitalizes the performance benchmarks across various natural language processing (NLP) tasks. Instead of using a fixed prompt template to fine-tune the model, some research demonstrates the effectiveness of searching for the prompt via optimization. Such prompt optimization process of prompt-based learning on PLMs also gives insight into generating adversarial prompts to mislead the model, raising concerns about the adversarial vulnerability of this paradigm. Recent studies have shown that universal adversarial triggers (UATs) can be generated to alter not only the predictions of the target PLMs but also the prediction of corresponding Prompt-based Fine-tuning Models (PFMs) under the prompt-based learning paradigm. However, UATs found in previous works are often unreadable tokens or characters a
    
[^66]: DOCTR：点场景理解的解耦对象中心Transformer

    DOCTR: Disentangled Object-Centric Transformer for Point Scene Understanding

    [https://arxiv.org/abs/2403.16431](https://arxiv.org/abs/2403.16431)

    提出了一种新颖的Disentangled Object-Centric Transformer (DOCTR)，旨在以统一的方式便利多个对象学习点场景理解的多个子任务，并引入了语义-几何解耦查询设计来优化对象之间的关系。

    

    点场景理解是处理现实世界场景点云的一项具有挑战性的任务，旨在同时对每个对象进行分割，估计其姿态并重新构建其网格。最近的最先进方法首先分割每个对象，然后使用多个阶段分别处理不同的子任务。这导致了一个复杂的流水线优化，并使得难以利用多个对象之间的关系约束。在这项工作中，我们提出了一种新颖的Disentangled Object-Centric TRansformer (DOCTR)，它探索了对象中心表示，以便以统一的方式便利多个对象学习多个子任务。每个对象被表示为一个查询，一个Transformer解码器被调整为迭代地优化涉及它们之间关系的所有查询。特别地，我们引入了一种语义几何解耦查询（SGDQ）设计，使查询特征能够

    arXiv:2403.16431v1 Announce Type: cross  Abstract: Point scene understanding is a challenging task to process real-world scene point cloud, which aims at segmenting each object, estimating its pose, and reconstructing its mesh simultaneously. Recent state-of-the-art method first segments each object and then processes them independently with multiple stages for the different sub-tasks. This leads to a complex pipeline to optimize and makes it hard to leverage the relationship constraints between multiple objects. In this work, we propose a novel Disentangled Object-Centric TRansformer (DOCTR) that explores object-centric representation to facilitate learning with multiple objects for the multiple sub-tasks in a unified manner. Each object is represented as a query, and a Transformer decoder is adapted to iteratively optimize all the queries involving their relationship. In particular, we introduce a semantic-geometry disentangled query (SGDQ) design that enables the query features to a
    
[^67]: Re2LLM: 反射式强化大型语言模型用于基于会话的推荐

    Re2LLM: Reflective Reinforcement Large Language Model for Session-based Recommendation

    [https://arxiv.org/abs/2403.16427](https://arxiv.org/abs/2403.16427)

    Re2LLM是为基于会话的推荐提出的反射式强化大型语言模型，引导LLMs专注于更准确推荐所需的专业知识，实现有效和高效。

    

    大型语言模型(LLMs)正日益被看作是增强基于会话推荐(SBR)的有前途的方法，其中已广泛研究了基于提示和微调的方法，以使LLMs与SBR对齐。然而，前者因缺乏任务特定反馈而难以找到引导LLMs正确推理的最佳提示，导致推荐结果不佳。尽管后者试图用领域特定知识微调LLMs，但它们面临诸如高计算成本和依赖开源骨干的限制。为解决这些问题，我们提出了一种用于SBR的反射式强化大型语言模型(Re2LLM)，引导LLMs专注于更准确推荐所需的专业知识，实现有效和高效。具体来说，我们首先设计了反射式探索模块

    arXiv:2403.16427v1 Announce Type: new  Abstract: Large Language Models (LLMs) are emerging as promising approaches to enhance session-based recommendation (SBR), where both prompt-based and fine-tuning-based methods have been widely investigated to align LLMs with SBR.   However, the former methods struggle with optimal prompts to elicit the correct reasoning of LLMs due to the lack of task-specific feedback, leading to unsatisfactory recommendations.   Although the latter methods attempt to fine-tune LLMs with domain-specific knowledge, they face limitations such as high computational costs and reliance on open-source backbones.   To address such issues, we propose a \underline{Re}flective \underline{Re}inforcement \underline{L}arge \underline{L}anguage \underline{M}odel (Re2LLM) for SBR, guiding LLMs to focus on specialized knowledge essential for more accurate recommendations effectively and efficiently.   In particular, we first design the Reflective Exploration Module to effective
    
[^68]: 使用ChatGPT为电子学位论文指定LCSH主题的实验

    An Experiment with the Use of ChatGPT for LCSH Subject Assignment on Electronic Theses and Dissertations

    [https://arxiv.org/abs/2403.16424](https://arxiv.org/abs/2403.16424)

    该研究探讨了利用大型语言模型生成美国国会图书馆主题标头的潜力，展示了其对于解决学术图书馆待编目项目积压问题具有战略应对意义，同时也强调了人类编目员仍然在验证和增强生成主题标头方面的重要性。

    

    该研究探讨了利用大型语言模型（LLMs）生成美国国会图书馆主题标头（LCSH）的潜力。作者使用ChatGPT根据电子学位论文的标题和摘要生成主题标头。结果显示，尽管一些生成的主题标头是有效的，但存在特定性和详尽性方面的问题。该研究展示了LLMs可以作为学术图书馆待编目项目的战略性应对措施，同时也提供了一种成本效益高且快速生成LCSH的方法。然而，人类编目员仍然是验证和增强LLMs生成的LCSH的有效性、详尽性和特定性的必要条件。

    arXiv:2403.16424v1 Announce Type: new  Abstract: This study delves into the potential use of Large Language Models (LLMs) for generating Library of Congress Subject Headings (LCSH). The authors employed ChatGPT to generate subject headings for electronic theses and dissertations (ETDs) based on their titles and summaries. The results revealed that although some generated subject headings were valid, there were issues regarding specificity and exhaustiveness. The study showcases that LLMs can serve as a strategic response to the backlog of items awaiting cataloging in academic libraries, while also offering a cost-effective approach for promptly generating LCSH. Nonetheless, human catalogers remain essential for verifying and enhancing the validity, exhaustiveness, and specificity of LCSH generated by LLMs.
    
[^69]: 优化文本到图像生成：向准确的无需训练的字形增强图像生成迈进

    Refining Text-to-Image Generation: Towards Accurate Training-Free Glyph-Enhanced Image Generation

    [https://arxiv.org/abs/2403.16422](https://arxiv.org/abs/2403.16422)

    通过引入LenCom-Eval基准测试，研究者发现基于扩散模型的文本到图像生成方法仍面临三个主要挑战，并为未来研究提供了一个测试平台。

    

    过去几年，基于扩散模型的文本到图像（T2I）生成方法引起了广泛关注。然而，普通扩散模型通常在生成图像中显示的文本中存在拼写不准确的问题。生成视觉文本的能力至关重要，不仅具有学术价值，还有广泛的实际应用。为了生成准确的视觉文本图像，最先进的技术采用了一种字形控制的图像生成方法，包括文本布局生成器，然后是一个在生成的文本布局的条件下生成图像的图像生成器。然而，我们的研究发现这些模型仍然面临三个主要挑战，促使我们开发了一个测试平台来促进未来的研究。我们引入了一个名为LenCom-Eval的基准测试，专门用于测试模型在生成具有复杂视觉文本的图像方面的能力。

    arXiv:2403.16422v1 Announce Type: cross  Abstract: Over the past few years, Text-to-Image (T2I) generation approaches based on diffusion models have gained significant attention. However, vanilla diffusion models often suffer from spelling inaccuracies in the text displayed within the generated images. The capability to generate visual text is crucial, offering both academic interest and a wide range of practical applications. To produce accurate visual text images, state-of-the-art techniques adopt a glyph-controlled image generation approach, consisting of a text layout generator followed by an image generator that is conditioned on the generated text layout. Nevertheless, our study reveals that these models still face three primary challenges, prompting us to develop a testbed to facilitate future research. We introduce a benchmark, LenCom-Eval, specifically designed for testing models' capability in generating images with Lengthy and Complex visual text. Subsequently, we introduce 
    
[^70]: 一种基于递增式MaxSAT的学习平衡规则模型

    An incremental MaxSAT-based model to learn balanced rules

    [https://arxiv.org/abs/2403.16418](https://arxiv.org/abs/2403.16418)

    提出了一种基于递增式MaxSAT的学习平衡规则模型IMLIB，结合了SAT和MaxSAT方法，限制规则大小以实现平衡，并提高模型性能。

    

    机器学习领域的不断发展导致了众多应用程序的开发，能够有效地解决各种问题并进行准确预测。然而，在某些情况下，仅准确性可能不足够。许多实际问题还需要解释和可解释性。本文旨在提出一种基于MaxSAT的增量模型用于学习可解释且平衡的规则，称为IMLIB。这个新模型基于另外两种方法，一种是基于SAT的，另一种是基于MaxSAT的。基于SAT的方法限制了每个生成规则的大小，使得可以平衡它们。我们认为这样一组规则比一个混合了大规则和小规则更容易理解。基于MaxSAT的方法，称为IMLI，提出了一种提高性能的技术。

    arXiv:2403.16418v1 Announce Type: cross  Abstract: The increasing advancements in the field of machine learning have led to the development of numerous applications that effectively address a wide range of problems with accurate predictions. However, in certain cases, accuracy alone may not be sufficient. Many real-world problems also demand explanations and interpretability behind the predictions. One of the most popular interpretable models that are classification rules. This work aims to propose an incremental model for learning interpretable and balanced rules based on MaxSAT, called IMLIB. This new model was based on two other approaches, one based on SAT and the other on MaxSAT. The one based on SAT limits the size of each generated rule, making it possible to balance them. We suggest that such a set of rules seem more natural to be understood compared to a mixture of large and small rules. The approach based on MaxSAT, called IMLI, presents a technique to increase performance th
    
[^71]: 您的模拟器有多可靠? 对当前基于LLM的用户对话推荐系统模拟器局限性的分析

    How Reliable is Your Simulator? Analysis on the Limitations of Current LLM-based User Simulators for Conversational Recommendation

    [https://arxiv.org/abs/2403.16416](https://arxiv.org/abs/2403.16416)

    通过对LLMs构建CRS用户模拟器的局限性进行分析，为指导未来研究提供了重要见解。

    

    arXiv:2403.16416v1 公告类型: 新 抽象: 对话推荐系统（CRS）通过自然语言与用户交互，了解他们的偏好并实时提供个性化推荐。CRS已展示出显著潜力，促使研究人员将发展更现实和可靠的用户模拟器作为重点。最近，大型语言模型（LLMs）的能力在各个领域受到了广泛关注。与此同时，正在努力基于LLMs构建用户模拟器。虽然这些工作展现了创新，但也存在一定的局限性需要关注。在这项工作中，我们旨在分析使用LLMs构建CRS用户模拟器的局限性，以指导未来研究。为实现这一目标，我们对知名工作iEvaLM进行了分析验证。通过在对话推荐领域中两个广泛使用的数据集上进行多次实验，我们突显了

    arXiv:2403.16416v1 Announce Type: new  Abstract: Conversational Recommender System (CRS) interacts with users through natural language to understand their preferences and provide personalized recommendations in real-time. CRS has demonstrated significant potential, prompting researchers to address the development of more realistic and reliable user simulators as a key focus. Recently, the capabilities of Large Language Models (LLMs) have attracted a lot of attention in various fields. Simultaneously, efforts are underway to construct user simulators based on LLMs. While these works showcase innovation, they also come with certain limitations that require attention. In this work, we aim to analyze the limitations of using LLMs in constructing user simulators for CRS, to guide future research. To achieve this goal, we conduct analytical validation on the notable work, iEvaLM. Through multiple experiments on two widely-used datasets in the field of conversational recommendation, we highli
    
[^72]: 重新思考联邦非IID数据的无监督学习中的表示

    Rethinking the Representation in Federated Unsupervised Learning with Non-IID Data

    [https://arxiv.org/abs/2403.16398](https://arxiv.org/abs/2403.16398)

    提出了FedU2方法，通过灵活的统一正则化器（FUR）和高效的统一聚合器（EUA），增强了在具有非IID数据的FUSL中生成统一和统一表示。

    

    arXiv:2403.16398v1 公告类型: 跨领域 摘要: 联邦学习在建模分布式数据方面表现出有效性。在实践中，客户端数据标签不完善，这使得联邦非IID数据的无监督学习（FUSL）具有潜力。然而，现有FUSL方法的性能受到表示不足的影响，即（1）局部和全局模型之间的表示崩溃纠缠，以及（2）局部模型之间表示空间的不一致。前者表示局部模型中的表示崩溃将随后影响全局模型和其他局部模型。后者意味着由于缺乏监督信号，客户端模型数据表示具有不一致的参数。在这项工作中，我们提出了FedU2，该方法增强了在具有非IID数据的FUSL中生成统一和统一表示。具体而言，FedU2由灵活的统一正则化器（FUR）和高效的统一聚合器（EUA）组成。每个FUR

    arXiv:2403.16398v1 Announce Type: cross  Abstract: Federated learning achieves effective performance in modeling decentralized data. In practice, client data are not well-labeled, which makes it potential for federated unsupervised learning (FUSL) with non-IID data. However, the performance of existing FUSL methods suffers from insufficient representations, i.e., (1) representation collapse entanglement among local and global models, and (2) inconsistent representation spaces among local models. The former indicates that representation collapse in local model will subsequently impact the global model and other local models. The latter means that clients model data representation with inconsistent parameters due to the deficiency of supervision signals. In this work, we propose FedU2 which enhances generating uniform and unified representation in FUSL with non-IID data. Specifically, FedU2 consists of flexible uniform regularizer (FUR) and efficient unified aggregator (EUA). FUR in each
    
[^73]: RadioGAT：基于联合模型和数据驱动的图注意力网络框架用于多频带无线射频地图重建

    RadioGAT: A Joint Model-based and Data-driven Framework for Multi-band Radiomap Reconstruction via Graph Attention Networks

    [https://arxiv.org/abs/2403.16397](https://arxiv.org/abs/2403.16397)

    RadioGAT提出了一种基于图注意力网络的框架，用于解决多频带射频地图重建中的挑战，创新地将模型建模和数据驱动的方法相结合，消除了对多区域数据集的需求。

    

    多频带射频地图重建（MB-RMR）是无线通信中的关键组成部分，用于任务如频谱管理和网络规划。然而，传统基于机器学习的MB-RMR方法在部署中面临重大挑战，这些方法严重依赖于模拟数据或完整结构化地面实况，这些挑战源自模拟数据与实际数据之间的差异，以及现实世界测量数据的稀缺性。为了解决这些挑战，我们的研究提出了RadioGAT，这是一个基于图注意力网络（GAT）的新框架，专门用于MB-RMR，在单个区域内消除了对多区域数据集的需求。RadioGAT创新地将基于模型的空间-频谱相关编码与数据驱动的射频地图泛化相结合，从而最大程度地减少对大量数据源的依赖。该框架通过创新的编码将稀疏的多频带数据转换为图结构开始。

    arXiv:2403.16397v1 Announce Type: cross  Abstract: Multi-band radiomap reconstruction (MB-RMR) is a key component in wireless communications for tasks such as spectrum management and network planning. However, traditional machine-learning-based MB-RMR methods, which rely heavily on simulated data or complete structured ground truth, face significant deployment challenges. These challenges stem from the differences between simulated and actual data, as well as the scarcity of real-world measurements. To address these challenges, our study presents RadioGAT, a novel framework based on Graph Attention Network (GAT) tailored for MB-RMR within a single area, eliminating the need for multi-region datasets. RadioGAT innovatively merges model-based spatial-spectral correlation encoding with data-driven radiomap generalization, thus minimizing the reliance on extensive data sources. The framework begins by transforming sparse multi-band data into a graph structure through an innovative encoding
    
[^74]: 文本到图像生成中现象空间中的偏差阻碍了泛化

    Skews in the Phenomenon Space Hinder Generalization in Text-to-Image Generation

    [https://arxiv.org/abs/2403.16394](https://arxiv.org/abs/2403.16394)

    文本到图像生成领域的泛化问题源于现象空间中的偏差，需要量化和解决语言和视觉偏差，以提高泛化性能

    

    文本到图像生成领域的文献存在着关于如何忠实地组合实体与关系的问题。然而，缺乏对实体-关系组合如何有效学习的形式化理解。此外，反映问题结构的基础现象空间并不明确定义，导致为了希望泛化在大规模预训练中得以展现而不断追求更多数据。我们猜测基础现象学覆盖范围并未按比例扩展，导致所呈现现象的偏差对泛化造成了伤害。我们引入了统计度量标准来量化数据集中的语言和视觉偏差，用于关系学习，并表明文本到图像生成的泛化失败直接源于现象学覆盖不完整或不平衡。我们首先在合成领域进行实验和演示

    arXiv:2403.16394v1 Announce Type: cross  Abstract: The literature on text-to-image generation is plagued by issues of faithfully composing entities with relations. But there lacks a formal understanding of how entity-relation compositions can be effectively learned. Moreover, the underlying phenomenon space that meaningfully reflects the problem structure is not well-defined, leading to an arms race for larger quantities of data in the hope that generalization emerges out of large-scale pretraining. We hypothesize that the underlying phenomenological coverage has not been proportionally scaled up, leading to a skew of the presented phenomenon which harms generalization. We introduce statistical metrics that quantify both the linguistic and visual skew of a dataset for relational learning, and show that generalization failures of text-to-image generation are a direct result of incomplete or unbalanced phenomenological coverage. We first perform experiments in a synthetic domain and demo
    
[^75]: 大型语言模型的并发语言错误检测（CLED）

    Concurrent Linguistic Error Detection (CLED) for Large Language Models

    [https://arxiv.org/abs/2403.16393](https://arxiv.org/abs/2403.16393)

    提出了一种针对大型语言模型的并发语言错误检测方案，通过提取文本的语言特征并使用分类器进行错误检测。

    

    大型语言模型（LLMs）的广泛采用使得它们的可靠性成为一个紧迫问题。错误的检测是减轻其对系统影响的第一步，因此，LLMs的高效错误检测是一个重要问题。基于对LLMs输出进行的观察，我们提出进行并发语言错误检测（CLED）；该方案提取LLMs生成文本的一些语言特征，并将它们输入到一个并发分类器中进行错误检测。

    arXiv:2403.16393v1 Announce Type: new  Abstract: The wide adoption of Large language models (LLMs) makes their dependability a pressing concern. Detection of errors is the first step to mitigating their impact on a system and thus, efficient error detection for LLMs is an important issue. In many settings, the LLM is considered as a black box with no access to the internal nodes; this prevents the use of many error detection schemes that need access to the model's internal nodes. An interesting observation is that the output of LLMs in error-free operation should be valid and normal text. Therefore, when the text is not valid or differs significantly from normal text, it is likely that there is an error. Based on this observation we propose to perform Concurrent Linguistic Error Detection (CLED); this scheme extracts some linguistic features of the text generated by the LLM and feeds them to a concurrent classifier that detects errors. Since the proposed error detection mechanism only 
    
[^76]: Dia-LLaMA: 迈向基于大型语言模型的CT报告生成

    Dia-LLaMA: Towards Large Language Model-driven CT Report Generation

    [https://arxiv.org/abs/2403.16386](https://arxiv.org/abs/2403.16386)

    通过引入诊断信息作为引导提示，Dia-LLaMA框架将LLaMA2-7B适应于CT报告生成，解决了正常和异常案例分布不平衡以及常见模板句子淹没关键异常信息的挑战。

    

    医学报告生成取得了显著进展，但仍面临一些挑战。首先，在正常和异常案例的分布上存在固有的不平衡，可能导致模型对正常样本展现出偏见，从而导致不可靠的诊断。其次，报告中常见模板句子的频繁出现可能淹没了关键的异常信息。此外，现有工作侧重于2D胸部X射线，由于CT图像的高维特性和CT-报告对的有限性，CT报告生成领域尚未得到充分探索。最近，LLM已经展示了通过适当的提示生成可靠答案的能力，这为解决上述挑战提供了启示。在本文中，我们提出了Dia-LLaMA，这是一个将LLaMA2-7B调整为CT报告生成的框架，通过引入诊断信息作为引导提示。考虑到高维度

    arXiv:2403.16386v1 Announce Type: cross  Abstract: Medical report generation has achieved remarkable advancements yet has still been faced with several challenges. First, the inherent imbalance in the distribution of normal and abnormal cases may lead models to exhibit a biased focus on normal samples, resulting in unreliable diagnoses. Second, the frequent occurrence of common template sentences in the reports may overwhelm the critical abnormal information. Moreover, existing works focus on 2D chest X-rays, leaving CT report generation underexplored due to the high-dimensional nature of CT images and the limited availability of CT-report pairs. Recently, LLM has shown a great ability to generate reliable answers with appropriate prompts, which shed light on addressing the aforementioned challenges. In this paper, we propose Dia-LLaMA, a framework to adapt the LLaMA2-7B for CT report generation by incorporating diagnostic information as guidance prompts. Considering the high dimension
    
[^77]: 使用不变性学习基于动作的表示

    Learning Action-based Representations Using Invariance

    [https://arxiv.org/abs/2403.16369](https://arxiv.org/abs/2403.16369)

    提出了一种新的方法，动作双模拟编码，通过递归不变性约束扩展了单步控制性，学习了一个可以平滑折扣远期元素的多步控制度量

    

    强化学习代理使用高维度观测必须能够在许多外源性干扰中识别相关状态特征。一个能够捕捉可控性的表示通过确定影响代理控制的因素来识别这些状态元素。虽然诸如逆动力学和互信息等方法可以捕捉有限数量的时间步的可控性，但捕获长时间元素仍然是一个具有挑战性的问题。短视的可控性可以捕捉代理即将撞向墙壁的瞬间，但不能在代理还有一定距离之时捕捉墙壁的控制相关性。为解决这个问题，我们提出了动作双模拟编码，这是一种受到双模拟不变量假度量启发的方法，它通过递归不变性约束扩展了单步控制性。通过这种方式，动作双模拟学习了一个平滑折扣远期元素的多步控制度量。

    arXiv:2403.16369v1 Announce Type: cross  Abstract: Robust reinforcement learning agents using high-dimensional observations must be able to identify relevant state features amidst many exogeneous distractors. A representation that captures controllability identifies these state elements by determining what affects agent control. While methods such as inverse dynamics and mutual information capture controllability for a limited number of timesteps, capturing long-horizon elements remains a challenging problem. Myopic controllability can capture the moment right before an agent crashes into a wall, but not the control-relevance of the wall while the agent is still some distance away. To address this we introduce action-bisimulation encoding, a method inspired by the bisimulation invariance pseudometric, that extends single-step controllability with a recursive invariance constraint. By doing this, action-bisimulation learns a multi-step controllability metric that smoothly discounts dist
    
[^78]: ChatDBG: 一种基于人工智能的调试助手

    ChatDBG: An AI-Powered Debugging Assistant

    [https://arxiv.org/abs/2403.16354](https://arxiv.org/abs/2403.16354)

    ChatDBG是第一个AI-Powered调试助手，通过将大型语言模型集成到传统调试器中，实现了程序员与调试器之间的协作对话，能够处理复杂问题、执行根本原因分析，并探索开放性查询。

    

    本文介绍了ChatDBG，这是第一个基于人工智能的调试助手。ChatDBG集成了大型语言模型(LLMs)，显著增强了传统调试器的功能和用户友好性。ChatDBG允许程序员与调试器进行协作对话，使他们能够提出关于程序状态的复杂问题，对崩溃或断言失败进行根本原因分析，并探索诸如“为什么x为空？”之类的开放性查询。为了处理这些查询，ChatDBG授予LLM自主权，通过发出命令来浏览堆栈和检查程序状态进行调试；然后报告其发现并将控制权交还给程序员。我们的ChatDBG原型与标准调试器集成，包括LLDB、GDB和WinDBG用于本地代码以及用于Python的Pdb。我们在各种代码集合上进行了评估，包括具有已知错误的C/C++代码和一套Python代码。

    arXiv:2403.16354v1 Announce Type: cross  Abstract: This paper presents ChatDBG, the first AI-powered debugging assistant. ChatDBG integrates large language models (LLMs) to significantly enhance the capabilities and user-friendliness of conventional debuggers. ChatDBG lets programmers engage in a collaborative dialogue with the debugger, allowing them to pose complex questions about program state, perform root cause analysis for crashes or assertion failures, and explore open-ended queries like "why is x null?". To handle these queries, ChatDBG grants the LLM autonomy to take the wheel and drive debugging by issuing commands to navigate through stacks and inspect program state; it then reports its findings and yields back control to the programmer. Our ChatDBG prototype integrates with standard debuggers including LLDB, GDB, and WinDBG for native code and Pdb for Python. Our evaluation across a diverse set of code, including C/C++ code with known bugs and a suite of Python code includi
    
[^79]: ChatGPT在软件评论中的不正确性检测

    ChatGPT Incorrectness Detection in Software Reviews

    [https://arxiv.org/abs/2403.16347](https://arxiv.org/abs/2403.16347)

    开发了一种名为CID的工具，通过迭代提示ChatGPT并要求提出情境相似但文本有分歧的问题，来自动测试和检测ChatGPT响应中的不正确性。

    

    我们对135名软件工程（SE）从业者进行了调查，以了解他们如何使用生成式AI聊天机器人（如ChatGPT）进行SE任务。我们发现他们希望将ChatGPT用于软件库选择等SE任务，但经常担心ChatGPT响应的真实性。我们开发了一套技术和一种名为CID（ChatGPT不正确性检测器）的工具，用于自动测试和检测ChatGPT响应中的不正确性。CID基于通过请求对ChatGPT进行迭代提示来提问具有情境相似但文本有分歧的问题（使用一种利用文本中的变态关系的方法）。CID的基本原则是，对于给定的问题，与其他响应不同（跨问题的多个化身）的响应可能是不正确的响应。 在一个关于库选择的基准研究中，我们展示CID能够检测ChatGPT的不正确响应。

    arXiv:2403.16347v1 Announce Type: cross  Abstract: We conducted a survey of 135 software engineering (SE) practitioners to understand how they use Generative AI-based chatbots like ChatGPT for SE tasks. We find that they want to use ChatGPT for SE tasks like software library selection but often worry about the truthfulness of ChatGPT responses. We developed a suite of techniques and a tool called CID (ChatGPT Incorrectness Detector) to automatically test and detect the incorrectness in ChatGPT responses. CID is based on the iterative prompting to ChatGPT by asking it contextually similar but textually divergent questions (using an approach that utilizes metamorphic relationships in texts). The underlying principle in CID is that for a given question, a response that is different from other responses (across multiple incarnations of the question) is likely an incorrect response. In a benchmark study of library selection, we show that CID can detect incorrect responses from ChatGPT with 
    
[^80]: 基于LLM编辑的增强式分面生成

    Enhanced Facet Generation with LLM Editing

    [https://arxiv.org/abs/2403.16345](https://arxiv.org/abs/2403.16345)

    提出了一种通过利用搜索引擎获取的文档和相关查询来增强分面预测的策略，并提出了专注于仅使用查询作为输入来预测分面的框架

    

    在信息检索中，用户查询的分面识别是一项重要任务。如果搜索服务能够识别用户查询的分面，就有潜力为用户提供更广泛的搜索结果。先前的研究可以通过利用搜索引擎获取的检索文档和相关查询来增强分面预测。然而，在将搜索引擎作为模型的一部分进行扩展到其他应用时存在挑战。第一，搜索引擎不断更新。因此，在训练和测试期间附加信息可能会有变化，这可能会降低性能。第二个挑战是公共搜索引擎无法搜索内部文件。因此，需要构建一个单独的搜索系统来将公司内部文档纳入其中。我们提出了两种策略，专注于一个可以仅通过查询作为输入来预测分面的框架。

    arXiv:2403.16345v1 Announce Type: cross  Abstract: In information retrieval, facet identification of a user query is an important task. If a search service can recognize the facets of a user's query, it has the potential to offer users a much broader range of search results. Previous studies can enhance facet prediction by leveraging retrieved documents and related queries obtained through a search engine. However, there are challenges in extending it to other applications when a search engine operates as part of the model. First, search engines are constantly updated. Therefore, additional information may change during training and test, which may reduce performance. The second challenge is that public search engines cannot search for internal documents. Therefore, a separate search system needs to be built to incorporate documents from private domains within the company. We propose two strategies that focus on a framework that can predict facets by taking only queries as input withou
    
[^81]: 视频压缩畸变对鱼眼相机视觉感知任务的影响

    Impact of Video Compression Artifacts on Fisheye Camera Visual Perception Tasks

    [https://arxiv.org/abs/2403.16338](https://arxiv.org/abs/2403.16338)

    本研究对标准视频压缩编解码器对广角鱼眼相机的影响进行了首次分析，以证明有损视频压缩畸变不会对感知算法的性能产生影响。

    

    自动驾驶系统需要广泛的数据收集方案来覆盖构建强大和安全系统所需的各种场景。数据量达到百亿字节的数量级，必须长时间存储（即车辆生命周期超过10年）。无损压缩提供的压缩比不够，因此进行了有损视频压缩的研究。必须证明有损视频压缩畸变不会影响感知算法的性能。然而，在这一领域的工作有限，难以得出坚实的结论。特别是，在鱼眼相机领域还没有这样的研究内容，鱼眼相机具有很高的径向畸变，压缩可能会有更高的畸变。鱼眼相机常用于汽车系统的三维物体检测任务。在本研究中，我们首次对标准视频压缩编解码器对宽视场角鱼眼相机的影响进行了分析。

    arXiv:2403.16338v1 Announce Type: cross  Abstract: Autonomous driving systems require extensive data collection schemes to cover the diverse scenarios needed for building a robust and safe system. The data volumes are in the order of Exabytes and have to be stored for a long period of time (i.e., more than 10 years of the vehicle's life cycle). Lossless compression doesn't provide sufficient compression ratios, hence, lossy video compression has been explored. It is essential to prove that lossy video compression artifacts do not impact the performance of the perception algorithms. However, there is limited work in this area to provide a solid conclusion. In particular, there is no such work for fisheye cameras, which have high radial distortion and where compression may have higher artifacts. Fisheye cameras are commonly used in automotive systems for 3D object detection task. In this work, we provide the first analysis of the impact of standard video compression codecs on wide FOV fi
    
[^82]: 图在分布转移下的泛化

    Graphs Generalization under Distribution Shifts

    [https://arxiv.org/abs/2403.16334](https://arxiv.org/abs/2403.16334)

    本文介绍了一种名为GLIDER的新框架，旨在解决图结构数据中分布转移带来的挑战，并实现泛化性能优越。

    

    传统的机器学习方法严重依赖于独立同分布的假设，当测试分布与训练分布有所偏离时会受到限制。为了解决这一关键问题，针对已知分布转移而达到令人满意的泛化性能。然而，目前针对图结构数据的分布外泛化方法存在缺乏明晰性且尚未得到充分探索，主要由于两个主要挑战。首先，图中的分布转移通常同时发生在节点属性和图拓扑上。其次，在各种分布转移中捕获不变信息被证明是一个极具挑战性的问题。为了克服这些障碍，本文提出了一种全新的框架，即图学习不变域生成（GLIDER）。其目标是(1)多样化变化

    arXiv:2403.16334v1 Announce Type: cross  Abstract: Traditional machine learning methods heavily rely on the independent and identically distribution assumption, which imposes limitations when the test distribution deviates from the training distribution. To address this crucial issue, out-of-distribution (OOD) generalization, which aims to achieve satisfactory generalization performance when faced with unknown distribution shifts, has made a significant process. However, the OOD method for graph-structured data currently lacks clarity and remains relatively unexplored due to two primary challenges. Firstly, distribution shifts on graphs often occur simultaneously on node attributes and graph topology. Secondly, capturing invariant information amidst diverse distribution shifts proves to be a formidable challenge. To overcome these obstacles, in this paper, we introduce a novel framework, namely Graph Learning Invariant Domain genERation (GLIDER). The goal is to (1) diversify variations
    
[^83]: 人工神经微电路作为基本构建模块：概念与挑战

    Artificial Neural Microcircuits as Building Blocks: Concept and Challenges

    [https://arxiv.org/abs/2403.16327](https://arxiv.org/abs/2403.16327)

    本文探索了一种新的方法，在生物学中神经微电路的启发下，使用人工神经微电路作为组装大型神经网络的基本构建模块，避免了结构上的齐质化所带来的复杂训练和学习工具的问题。

    

    人工神经网络(ANNs)是最广泛应用的生物启发式计算形式之一。然而，目前的趋势是将ANNs结构上保持齐质。此外，这种结构上的齐质性需要应用复杂的训练和学习工具，以产生特定应用的ANNs，容易遇到过拟合等问题。本文探讨了一种新的方法，灵感来自于神经微电路在生物学中所扮演的角色，即有机神经系统的“基本处理元件”。如何使用人工神经微电路(ANMs)组装大型神经网络，特别是脉冲神经网络(SNNs)，旨在作为现成零件，藉由利用新颖性搜索来产生这种微电路目录的初步工作结果；接着是扩展这项初步工作的努力，包括讨论相应的挑战。

    arXiv:2403.16327v1 Announce Type: cross  Abstract: Artificial Neural Networks (ANNs) are one of the most widely employed forms of bio-inspired computation. However the current trend is for ANNs to be structurally homogeneous. Furthermore, this structural homogeneity requires the application of complex training and learning tools that produce application specific ANNs, susceptible to pitfalls such as overfitting. In this paper, an new approach is explored, inspired by the role played in biology by Neural Microcircuits, the so called ``fundamental processing elements'' of organic nervous systems. How large neural networks, particularly Spiking Neural Networks (SNNs) can be assembled using Artificial Neural Microcircuits (ANMs), intended as off-the-shelf components, is articulated; the results of initial work to produce a catalogue of such Microcircuits though the use of Novelty Search is shown; followed by efforts to expand upon this initial work, including a discussion of challenges unc
    
[^84]: 生物医学与健康信息学中的大型语言模型：一项文献计量学综述

    Large Language Models in Biomedical and Health Informatics: A Bibliometric Review

    [https://arxiv.org/abs/2403.16303](https://arxiv.org/abs/2403.16303)

    LLMs已成为生物医学与健康信息学中重要的工具，本文献计量学综述全面展示了LLMs在各种BHI领域中的应用，提出了其对自然语言处理应用的改进，揭示了主要发展趋势和研究网络，并讨论了伦理关切和实际挑战。

    

    大型语言模型（LLMs）迅速成为生物医学与健康信息学（BHI）中的重要工具，为分析数据、治疗患者和开展研究提供了新的方式。本文献计量学综述旨在通过检查自2022年至2023年的研究文章和合作网络，全面展示LLMs在BHI中的应用情况。它进一步探讨了LLMs如何可以改进各种BHI领域中的自然语言处理（NLP）应用，如医学诊断、患者参与、电子健康记录管理和个性化医学。为此，我们的文献计量学综述确定了关键趋势，绘制了研究网络，并突出了这个快速发展领域的主要进展。最后，它讨论了在BHI中使用LLMs的伦理关切和实际挑战，如数据隐私和可靠的医疗建议。展望未来，我们考虑LLMs如何进一步改变生物医学研究。

    arXiv:2403.16303v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have rapidly become important tools in Biomedical and Health Informatics (BHI), enabling new ways to analyze data, treat patients, and conduct research. This bibliometric review aims to provide a panoramic view of how LLMs have been used in BHI by examining research articles and collaboration networks from 2022 to 2023. It further explores how LLMs can improve Natural Language Processing (NLP) applications in various BHI areas like medical diagnosis, patient engagement, electronic health record management, and personalized medicine. To do this, our bibliometric review identifies key trends, maps out research networks, and highlights major developments in this fast-moving field. Lastly, it discusses the ethical concerns and practical challenges of using LLMs in BHI, such as data privacy and reliable medical recommendations. Looking ahead, we consider how LLMs could further transform biomedical research as we
    
[^85]: 在照料机器人中猜测人类意图以避免危险情况

    Guessing human intentions to avoid dangerous situations in caregiving robots

    [https://arxiv.org/abs/2403.16291](https://arxiv.org/abs/2403.16291)

    本文探讨了在照料机器人中使用人工心智理论来猜测人类意图，提出了一种检测危险情况并实时消除危险的算法，在模拟实验中取得了高成功率。

    

    要求机器人进行社交互动，它们必须准确解释人类意图并预测潜在结果。对于为人类护理设计的社交机器人而言尤为重要，可能会面临人类的危险情况，比如未见障碍物，应该予以避免。本文探讨了人工心智理论（ATM）方法来推断和解释人类意图。我们提出了一种检测人类风险情况的算法，选择实时消除危险的机器人动作。我们采用基于模拟的ATM方法，并采用“像我一样”的策略将意图和动作分配给人类。通过这种策略，机器人在有限时间内可以高成功率地检测和行动。该算法已经作为现有机器人认知架构的一部分实施，并在模拟场景中进行了测试。进行了三个实验。

    arXiv:2403.16291v1 Announce Type: cross  Abstract: For robots to interact socially, they must interpret human intentions and anticipate their potential outcomes accurately. This is particularly important for social robots designed for human care, which may face potentially dangerous situations for people, such as unseen obstacles in their way, that should be avoided. This paper explores the Artificial Theory of Mind (ATM) approach to inferring and interpreting human intentions. We propose an algorithm that detects risky situations for humans, selecting a robot action that removes the danger in real time. We use the simulation-based approach to ATM and adopt the 'like-me' policy to assign intentions and actions to people. Using this strategy, the robot can detect and act with a high rate of success under time-constrained situations. The algorithm has been implemented as part of an existing robotics cognitive architecture and tested in simulation scenarios. Three experiments have been co
    
[^86]: 利用大型语言模型工程化自动驾驶安全需求

    Engineering Safety Requirements for Autonomous Driving with Large Language Models

    [https://arxiv.org/abs/2403.16289](https://arxiv.org/abs/2403.16289)

    该研究提出了利用大型语言模型自动优化和拆分安全需求的管道，通过评估LLMs的能力，并识别多余或矛盾的需求，为解决自动驾驶领域中需求变更频繁的挑战提供了新思路。

    

    在汽车领域，需求文档的变更和更新频繁，这对安全运营构成挑战。大型语言模型（LLMs）以其出色的自然语言理解和生成能力，在每次更新后自动完善和拆分需求方面能发挥关键作用。在本研究中，我们提出了一个提示和LLMs管道的原型，接收项目定义并以安全需求的形式输出解决方案。该管道还对需求数据集进行审核，并识别多余或矛盾的需求。我们首先确定了执行HARA所需的特征，然后定义了用于评估LLMs是否符合这些标准的测试。我们采用设计科学方法进行多次迭代，并邀请来自不同公司的专家定量和定性评估每个周期。最后，实现了该原型。

    arXiv:2403.16289v1 Announce Type: new  Abstract: Changes and updates in the requirement artifacts, which can be frequent in the automotive domain, are a challenge for SafetyOps. Large Language Models (LLMs), with their impressive natural language understanding and generating capabilities, can play a key role in automatically refining and decomposing requirements after each update. In this study, we propose a prototype of a pipeline of prompts and LLMs that receives an item definition and outputs solutions in the form of safety requirements. This pipeline also performs a review of the requirement dataset and identifies redundant or contradictory requirements. We first identified the necessary characteristics for performing HARA and then defined tests to assess an LLM's capability in meeting these criteria. We used design science with multiple iterations and let experts from different companies evaluate each cycle quantitatively and qualitatively. Finally, the prototype was implemented a
    
[^87]: AVicuna：具有交错器和上下文边界对齐的音频-视觉LLM用于时间指代对话

    AVicuna: Audio-Visual LLM with Interleaver and Context-Boundary Alignment for Temporal Referential Dialogue

    [https://arxiv.org/abs/2403.16276](https://arxiv.org/abs/2403.16276)

    介绍了一个新的框架AVicuna，生成了PU-VALOR数据集，解决了音频-视觉时间指代对话中的两个主要挑战：缺乏准确时间注释的数据集和整合复杂时间线索的方法。

    

    在日常交流中，人类经常使用语音和手势来指代特定区域或对象，这个过程称为指代对话（RD）。尽管先前的研究已经通过大型语言模型（LLMs）或大型多模型模型（LMMs）在静态环境中调查了RD，但在音频-视觉媒体中探索时间指代对话（TRD）仍然有限。两个主要挑战阻碍了这一领域的进展：（1）缺乏具有精确时间注释的全面未修剪音频-视觉视频数据集，以及（2）需要有效整合复杂的时间听觉和视觉线索的方法。为了解决这些挑战，我们引入了一个新的框架，生成PU-VALOR，这是一个包含超过114,000个未修剪视频的广泛音频-视觉数据集，并介绍了AVicuna，具有音频-视觉令牌交错器（AVTI），确保了时间对齐。

    arXiv:2403.16276v1 Announce Type: cross  Abstract: In everyday communication, humans frequently use speech and gestures to refer to specific areas or objects, a process known as Referential Dialogue (RD). While prior studies have investigated RD through Large Language Models (LLMs) or Large Multimodal Models (LMMs) in static contexts, the exploration of Temporal Referential Dialogue (TRD) within audio-visual media remains limited. Two primary challenges hinder progress in this field: (1) the absence of comprehensive, untrimmed audio-visual video datasets with precise temporal annotations, and (2) the need for methods to integrate complex temporal auditory and visual cues effectively. To address these challenges, we introduce a novel framework to generate PU-VALOR, an extensive audio-visual dataset comprising over 114,000 untrimmed videos with accurate temporal demarcations. We also present AVicuna, featuring an Audio-Visual Tokens Interleaver (AVTI) that ensures the temporal alignment 
    
[^88]: L-MAE: 具有时间和严重性感知编码的纵向遮罩自动编码器用于糖尿病视网膜病变进展预测

    L-MAE: Longitudinal masked auto-encoder with time and severity-aware encoding for diabetic retinopathy progression prediction

    [https://arxiv.org/abs/2403.16272](https://arxiv.org/abs/2403.16272)

    本文提出了一种纵向遮罩自动编码器（MAE），采用时间感知位置嵌入和疾病进展感知掩蔽，用于预测糖尿病视网膜病变进展，旨在更准确评估疾病进展。

    

    基于自监督学习（SSL）的预训练策略已被证明对于计算机视觉中许多下游任务是有效的伪任务。由于医学和自然图像之间存在显著差异，典型SSL在医学成像中的应用并不直接。此外，这些伪任务通常缺乏对于计算机辅助临床决策支持至关重要的上下文。本文中，我们基于著名的基于Transformer的MAE开发了一种纵向遮罩自动编码器（MAE）。特别地，我们探讨了时间感知位置嵌入以及疾病进展感知掩蔽的重要性。考虑到检查之间的时间而不仅仅是排定它们，能捕捉到时间变化和趋势的好处。掩蔽策略在后续过程中发展，更好地捕捉病理变化，确保更准确地评估疾病进展。

    arXiv:2403.16272v1 Announce Type: cross  Abstract: Pre-training strategies based on self-supervised learning (SSL) have proven to be effective pretext tasks for many downstream tasks in computer vision. Due to the significant disparity between medical and natural images, the application of typical SSL is not straightforward in medical imaging. Additionally, those pretext tasks often lack context, which is critical for computer-aided clinical decision support. In this paper, we developed a longitudinal masked auto-encoder (MAE) based on the well-known Transformer-based MAE. In particular, we explored the importance of time-aware position embedding as well as disease progression-aware masking. Taking into account the time between examinations instead of just scheduling them offers the benefit of capturing temporal changes and trends. The masking strategy, for its part, evolves during follow-up to better capture pathological changes, ensuring a more accurate assessment of disease progress
    
[^89]: 通过深度多理解集成实现越界检测

    Out-of-Distribution Detection via Deep Multi-Comprehension Ensemble

    [https://arxiv.org/abs/2403.16260](https://arxiv.org/abs/2403.16260)

    通过引入新颖的定性和定量模型集成评估方法，作者揭示了现有集成方法的关键缺陷，提出了提高传统模型集成维度的方法，以克服特征表示中的多样性限制。

    

    最近的研究强调了越界（OOD）特征表示领域规模对模型在OOD检测中效果的重要作用。因此，采用模型集成作为增强这一特征表示领域的突出策略已经成为一种突出的策略，利用预期的模型多样性。然而，我们引入了新颖的定性和定量模型集成评估方法，特别是损失盆/障碍可视化和自耦合指数，揭示了现有集成方法的一个关键缺陷。我们发现这些方法包含可进行仿射变换的权重，表现出有限的可变性，从而未能实现特征表示中所需的多样性。

    arXiv:2403.16260v1 Announce Type: cross  Abstract: Recent research underscores the pivotal role of the Out-of-Distribution (OOD) feature representation field scale in determining the efficacy of models in OOD detection. Consequently, the adoption of model ensembles has emerged as a prominent strategy to augment this feature representation field, capitalizing on anticipated model diversity.   However, our introduction of novel qualitative and quantitative model ensemble evaluation methods, specifically Loss Basin/Barrier Visualization and the Self-Coupling Index, reveals a critical drawback in existing ensemble methods. We find that these methods incorporate weights that are affine-transformable, exhibiting limited variability and thus failing to achieve the desired diversity in feature representation.   To address this limitation, we elevate the dimensions of traditional model ensembles, incorporating various factors such as different weight initializations, data holdout, etc., into di
    
[^90]: 关于原子力显微镜图像的机器学习分析，用于图像分类和样品表面识别

    On machine learning analysis of atomic force microscopy images for image classification, sample surface recognition

    [https://arxiv.org/abs/2403.16230](https://arxiv.org/abs/2403.16230)

    该论文探讨了在使用相对较少的原子力显微镜图像和小数据库时，应用机器学习进行识别/分类，讨论了除深度学习神经网络之外的机器学习方法。

    

    原子力显微镜（AFM或SPM）成像是显微技术中与机器学习（ML）分析最匹配的之一。AFM图像的数字格式允许直接在ML算法中使用，无需额外处理。此外，AFM使得能够同时成像样品表面十几种不同物理化学性质的分布，这个过程被称为多维成像。虽然这些丰富的信息可能难以使用传统方法进行分析，但ML为此任务提供了一种无缝的方法。然而，AFM成像相对较慢的速度在应用广泛用于图像识别的深度学习方法时提出了挑战。这个前景专注于使用相对较少的AFM图像、小数据库时的ML识别/分类。我们讨论了除流行的深度学习神经网络之外的ML方法。

    arXiv:2403.16230v1 Announce Type: cross  Abstract: Atomic force microscopy (AFM or SPM) imaging is one of the best matches with machine learning (ML) analysis among microscopy techniques. The digital format of AFM images allows for direct utilization in ML algorithms without the need for additional processing. Additionally, AFM enables the simultaneous imaging of distributions of over a dozen different physicochemical properties of sample surfaces, a process known as multidimensional imaging. While this wealth of information can be challenging to analyze using traditional methods, ML provides a seamless approach to this task. However, the relatively slow speed of AFM imaging poses a challenge in applying deep learning methods broadly used in image recognition. This Prospective is focused on ML recognition/classification when using a relatively small number of AFM images, small database. We discuss ML methods other than popular deep-learning neural networks. The described approach has a
    
[^91]: 基于分层非负矩阵分解的网络安全知识图生成

    Cyber-Security Knowledge Graph Generation by Hierarchical Nonnegative Matrix Factorization

    [https://arxiv.org/abs/2403.16222](https://arxiv.org/abs/2403.16222)

    本文介绍了一种通过从科学论文中提取结构化本体来构建网络安全领域多模态知识图的方法

    

    许多网络安全领域的人类知识都被封装在不断增长的科学论文中。随着这些文本数据的不断扩大，文档组织方法的重要性变得日益关键，用于从大型文本数据集中提取隐藏的可行见解。知识图（KGs）作为一种以结构化方式存储实际信息的手段，提供包括来自网络安全科学文献的领域特定信息在内的明确、可解释的知识。构建从科学文献中的知识图是提取本体的一个挑战。在本文中，我们讨论了这个主题，并介绍了一种通过从科学论文中提取结构化本体来构建多模态KG的方法。我们在网络安全领域展示了这一概念。KG的一种模态代表了论文中的可观察信息，如目录等

    arXiv:2403.16222v1 Announce Type: new  Abstract: Much of human knowledge in cybersecurity is encapsulated within the ever-growing volume of scientific papers. As this textual data continues to expand, the importance of document organization methods becomes increasingly crucial for extracting actionable insights hidden within large text datasets. Knowledge Graphs (KGs) serve as a means to store factual information in a structured manner, providing explicit, interpretable knowledge that includes domain-specific information from the cybersecurity scientific literature. One of the challenges in constructing a KG from scientific literature is the extraction of ontology from unstructured text. In this paper, we address this topic and introduce a method for building a multi-modal KG by extracting structured ontology from scientific papers. We demonstrate this concept in the cybersecurity domain. One modality of the KG represents observable information from the papers, such as the categories i
    
[^92]: CoverUp：基于覆盖率引导的LLM测试生成系统

    CoverUp: Coverage-Guided LLM-Based Test Generation

    [https://arxiv.org/abs/2403.16218](https://arxiv.org/abs/2403.16218)

    CoverUp通过覆盖率分析和大型语言模型相结合的方式，驱动生成高覆盖率的Python回归测试，并在改进覆盖率方面取得显著成就。

    

    本文介绍了CoverUp，这是一个新型系统，通过覆盖率分析和大型语言模型（LLM）的结合驱动生成高覆盖率的Python回归测试。CoverUp通过迭代改善覆盖率，将覆盖率分析与LLM对话交替进行，以便将注意力集中在尚未涵盖的代码行和分支上。最终的测试套件相比当前技术水平显著提高了覆盖率：与CodaMosa相比，一种混合LLM / 基于搜索的软件测试系统，CoverUp在各方面都大幅提高了覆盖率。以模块为基础，CoverUp实现了81%的中位线覆盖率（对比62%）、53%的分支覆盖率（对比35%）和78%的线+分支覆盖率（对比55%）。我们展示了CoverUp的迭代、覆盖率引导方法对其有效性至关重要，为其成功的近一半作出了贡献。

    arXiv:2403.16218v1 Announce Type: cross  Abstract: This paper presents CoverUp, a novel system that drives the generation of high-coverage Python regression tests via a combination of coverage analysis and large-language models (LLMs). CoverUp iteratively improves coverage, interleaving coverage analysis with dialogs with the LLM to focus its attention on as yet uncovered lines and branches. The resulting test suites significantly improve coverage over the current state of the art: compared to CodaMosa, a hybrid LLM / search-based software testing system, CoverUp substantially improves coverage across the board. On a per-module basis, CoverUp achieves median line coverage of 81% (vs. 62%), branch coverage of 53% (vs. 35%) and line+branch coverage of 78% (vs. 55%). We show that CoverUp's iterative, coverage-guided approach is crucial to its effectiveness, contributing to nearly half of its successes.
    
[^93]: Frankenstein: 在一个三面位平面中生成语义-组合式3D场景

    Frankenstein: Generating Semantic-Compositional 3D Scenes in One Tri-Plane

    [https://arxiv.org/abs/2403.16210](https://arxiv.org/abs/2403.16210)

    Frankenstein是一个框架，可以在单个通道中同时生成多个语义相关的3D形状，为生成房间内部和人类化身等场景提供了有希望的结果。

    

    我们提出了Frankenstein，这是一个基于扩散的框架，可以在单个通道中生成语义-组合式3D场景。与现有方法输出单个统一的3D形状不同，Frankenstein同时生成多个独立的形状，每个对应一个语义上有意义的部分。3D场景信息编码在一个三面位平面张量中，从中可以解码多个符号距离函数（SDF）场以表示组合形状。在训练期间，一个自编码器将三面位平面压缩到潜在空间，然后使用去噪扩散过程来逼近组合场景的分布。Frankenstein在生成房间内部和具有自动分离部分的人类化身方面表现出有希望的结果。生成的场景有助于许多下游应用，例如部分重贴图、房间或化身衣服的对象重新排列。

    arXiv:2403.16210v1 Announce Type: cross  Abstract: We present Frankenstein, a diffusion-based framework that can generate semantic-compositional 3D scenes in a single pass. Unlike existing methods that output a single, unified 3D shape, Frankenstein simultaneously generates multiple separated shapes, each corresponding to a semantically meaningful part. The 3D scene information is encoded in one single tri-plane tensor, from which multiple Singed Distance Function (SDF) fields can be decoded to represent the compositional shapes. During training, an auto-encoder compresses tri-planes into a latent space, and then the denoising diffusion process is employed to approximate the distribution of the compositional scenes. Frankenstein demonstrates promising results in generating room interiors as well as human avatars with automatically separated parts. The generated scenes facilitate many downstream applications, such as part-wise re-texturing, object rearrangement in the room or avatar clo
    
[^94]: 新闻报道场景中的图像描述

    Image Captioning in news report scenario

    [https://arxiv.org/abs/2403.16209](https://arxiv.org/abs/2403.16209)

    本论文探索了专门针对名人照片的图像描述，旨在增强新闻行业实践，并提出了对自动新闻内容生成的改进方法。

    

    arXiv:2403.16209v1 公告类型: 跨领域 摘要: 图像描述旨在为指定的图像生成相关的描述，使其处于计算机视觉（CV）和自然语言处理（NLP）的交叉点。这项努力在推荐系统、新闻媒体、社交媒体等领域具有重要意义。特别是在新闻报道领域，标题应涵盖详细信息，如图像中捕捉到的名人的身份。然而，现有大部分工作主要集中于理解场景和动作。本文探讨了专门针对名人照片的图像描述领域，展示了其在增强新闻行业实践方面的广泛潜力。这一探索旨在增强自动化新闻内容生成，从而促进更加细致地传播信息。我们的努力展示了一个更广阔的视野，丰富了n

    arXiv:2403.16209v1 Announce Type: cross  Abstract: Image captioning strives to generate pertinent captions for specified images, situating itself at the crossroads of Computer Vision (CV) and Natural Language Processing (NLP). This endeavor is of paramount importance with far-reaching applications in recommendation systems, news outlets, social media, and beyond. Particularly within the realm of news reporting, captions are expected to encompass detailed information, such as the identities of celebrities captured in the images. However, much of the existing body of work primarily centers around understanding scenes and actions. In this paper, we explore the realm of image captioning specifically tailored for celebrity photographs, illustrating its broad potential for enhancing news industry practices. This exploration aims to augment automated news content generation, thereby facilitating a more nuanced dissemination of information. Our endeavor shows a broader horizon, enriching the n
    
[^95]: 一种新颖的图神经网络方法用于谣言检测

    Rumor Detection with a novel graph neural network approach

    [https://arxiv.org/abs/2403.16206](https://arxiv.org/abs/2403.16206)

    本论文提出了一种新颖的检测模型，同时学习用户相关性和信息传播的表示，以检测社交媒体上的谣言

    

    社交媒体上谣言的广泛传播对人们的日常生活造成了负面影响，导致公众产生潜在的恐慌、恐惧和心理健康问题。如何尽早揭穿谣言仍然是一个具有挑战性的问题。现有研究主要利用信息传播结构来检测谣言，而很少有研究关注用户之间的相关性，即他们可能协调传播谣言以获得较大的流行度。在本文中，我们提出了一种新的检测模型，同时学习用户相关性和信息传播的表示，以便检测社交媒体上的谣言。具体而言，我们利用图神经网络从描述用户和来源推文之间相关性的二部图中学习用户相关性的表示，以及使用树结构学习信息传播的表示。然后，我们结合得到的表示

    arXiv:2403.16206v1 Announce Type: new  Abstract: The wide spread of rumors on social media has caused a negative impact on people's daily life, leading to potential panic, fear, and mental health problems for the public. How to debunk rumors as early as possible remains a challenging problem. Existing studies mainly leverage information propagation structure to detect rumors, while very few works focus on correlation among users that they may coordinate to spread rumors in order to gain large popularity. In this paper, we propose a new detection model, that jointly learns both the representations of user correlation and information propagation to detect rumors on social media. Specifically, we leverage graph neural networks to learn the representations of user correlation from a bipartite graph that describes the correlations between users and source tweets, and the representations of information propagation with a tree structure. Then we combine the learned representations from these 
    
[^96]: 基于逻辑的支持向量机线性分类器拒绝选项的解释

    Logic-based Explanations for Linear Support Vector Classifiers with Reject Option

    [https://arxiv.org/abs/2403.16190](https://arxiv.org/abs/2403.16190)

    提出了一种基于逻辑的方法，针对具有拒绝选项的线性SVC，提供了正确性和极小性保证的解释，相比启发式算法Anchors，我们的方法给出了更短的解释

    

    支持向量分类器（SVC）是一种用于线性分类问题的众所周知的机器学习（ML）模型。它可以与拒绝选项策略结合使用，拒绝难以正确分类的实例，并将它们委托给专家。这进一步增加了模型的信心。因此，获得拒绝原因的解释对于不盲目信任所获结果是重要的。尽管大多数相关工作已经开发出了针对机器学习模型提供这种解释的手段，但就我们所知，尚未有人为存在拒绝选项时提供这种解释。我们提出了一种基于逻辑的方法，对具有拒绝选项的线性SVC的解释进行正确性和极小性的形式保证。我们通过将其与生成解释的启发式算法Anchors进行比较来评估我们的方法。所获结果显示，我们提出的方法给出了更短的解释。

    arXiv:2403.16190v1 Announce Type: new  Abstract: Support Vector Classifier (SVC) is a well-known Machine Learning (ML) model for linear classification problems. It can be used in conjunction with a reject option strategy to reject instances that are hard to correctly classify and delegate them to a specialist. This further increases the confidence of the model. Given this, obtaining an explanation of the cause of rejection is important to not blindly trust the obtained results. While most of the related work has developed means to give such explanations for machine learning models, to the best of our knowledge none have done so for when reject option is present. We propose a logic-based approach with formal guarantees on the correctness and minimality of explanations for linear SVCs with reject option. We evaluate our approach by comparing it to Anchors, which is a heuristic algorithm for generating explanations. Obtained results show that our proposed method gives shorter explanations
    
[^97]: 在次优情况下进行在线贝叶斯适应的混合倡议人机协作

    Mixed-Initiative Human-Robot Teaming under Suboptimality with Online Bayesian Adaptation

    [https://arxiv.org/abs/2403.16178](https://arxiv.org/abs/2403.16178)

    该论文研究了在次优情况下进行在线贝叶斯适应的混合倡议人机协作的计算建模和优化技术，能够推断人们在协作中是否愿意遵从机器人的帮助。

    

    为了实现有效的人-智能体协作，机器人和其他人工智能（AI）代理必须推断他们的人类伙伴的能力和行为响应模式，并相应地进行调整。大多数先前的工作都作出了一个不切实际的假设，即一个或多个队友可以在接近最优的情况下行动。在现实世界的协作中，人类和自主代理可能是次优的，特别是当每个人只拥有部分领域知识时。在这项工作中，我们开发了用于增强次优人-智能体团队表现的计算建模和优化技术，其中人类和代理具有不对称的能力，并且由于环境知识不完整而表现次优。我们采用一种在线贝叶斯方法，使机器人能够推断人们在顺序决策游戏中是否愿意遵从其帮助。我们的用户研究表明，用户偏好和团队表现确实随着机器人介入风格而变化。

    arXiv:2403.16178v1 Announce Type: cross  Abstract: For effective human-agent teaming, robots and other artificial intelligence (AI) agents must infer their human partner's abilities and behavioral response patterns and adapt accordingly. Most prior works make the unrealistic assumption that one or more teammates can act near-optimally. In real-world collaboration, humans and autonomous agents can be suboptimal, especially when each only has partial domain knowledge. In this work, we develop computational modeling and optimization techniques for enhancing the performance of suboptimal human-agent teams, where the human and the agent have asymmetric capabilities and act suboptimally due to incomplete environmental knowledge. We adopt an online Bayesian approach that enables a robot to infer people's willingness to comply with its assistance in a sequential decision-making game. Our user studies show that user preferences and team performance indeed vary with robot intervention styles, an
    
[^98]: 神经网络中协方差传播的解析解

    An Analytic Solution to Covariance Propagation in Neural Networks

    [https://arxiv.org/abs/2403.16163](https://arxiv.org/abs/2403.16163)

    该论文提出了一种无需样本的矩传播技术，能够准确表征神经网络的输入输出分布，其关键创新在于提供了通过非线性激活函数传递的随机变量协方差的解析解。

    

    神经网络的不确定性量化对于衡量深度学习系统的可靠性和鲁棒性至关重要。然而，这通常涉及昂贵或不准确的采样方法和近似。本文提出了一种无需样本的矩传播技术，通过网络传播均值向量和协方差矩阵，准确表征神经网络的输入输出分布。我们的技术的一个关键优势是为通过非线性激活函数（如Heaviside、ReLU和GELU）传递的随机变量的协方差提供了解析解。通过分析经过训练的神经网络的输入输出分布以及训练贝叶斯神经网络的实验，展示了所提出技术的广泛适用性和优点。

    arXiv:2403.16163v1 Announce Type: cross  Abstract: Uncertainty quantification of neural networks is critical to measuring the reliability and robustness of deep learning systems. However, this often involves costly or inaccurate sampling methods and approximations. This paper presents a sample-free moment propagation technique that propagates mean vectors and covariance matrices across a network to accurately characterize the input-output distributions of neural networks. A key enabler of our technique is an analytic solution for the covariance of random variables passed through nonlinear activation functions, such as Heaviside, ReLU, and GELU. The wide applicability and merits of the proposed technique are shown in experiments analyzing the input-output distributions of trained neural networks and training Bayesian neural networks.
    
[^99]: 基于多任务优化的多任务学习

    Multi-Task Learning with Multi-Task Optimization

    [https://arxiv.org/abs/2403.16162](https://arxiv.org/abs/2403.16162)

    本文提出了一种通过多任务优化视角看待帕累托多任务学习的方法，将多任务学习转化为多目标优化问题，并通过独特的多任务梯度下降方法联合解决多个子问题，从而实现一组优化且分布良好的模型。

    

    多任务学习解决了多个相关任务。然而，它们之间可能存在冲突。在这种情况下，单个解决方案很少能够优化所有任务，导致性能折衷。为了在一个算法通过中获得一组优化且分布良好的模型，这些模型集体体现了不同权衡，本文提出通过多任务优化的视角看待帕累托多任务学习。首先将多任务学习视为多目标优化问题，然后将其分解为一组不受约束的标量价值子问题。使用一种新颖的多任务梯度下降方法共同解决这些子问题，其独特之处在于在优化过程中在子问题之间迭代传输模型参数。提出了一个定理，证明通过包含这样的传输可以实现更快的收敛速度。我们调查了提出的多任务学习方法。

    arXiv:2403.16162v1 Announce Type: new  Abstract: Multi-task learning solves multiple correlated tasks. However, conflicts may exist between them. In such circumstances, a single solution can rarely optimize all the tasks, leading to performance trade-offs. To arrive at a set of optimized yet well-distributed models that collectively embody different trade-offs in one algorithmic pass, this paper proposes to view Pareto multi-task learning through the lens of multi-task optimization. Multi-task learning is first cast as a multi-objective optimization problem, which is then decomposed into a diverse set of unconstrained scalar-valued subproblems. These subproblems are solved jointly using a novel multi-task gradient descent method, whose uniqueness lies in the iterative transfer of model parameters among the subproblems during the course of optimization. A theorem proving faster convergence through the inclusion of such transfers is presented. We investigate the proposed multi-task learn
    
[^100]: 一个掩盖模型就足够实现传感器故障检测、隔离和容错

    One Masked Model is All You Need for Sensor Fault Detection, Isolation and Accommodation

    [https://arxiv.org/abs/2403.16153](https://arxiv.org/abs/2403.16153)

    提出了一种使用掩盖模型和自监督学习进行传感器故障检测、隔离和容错的新框架，通过训练过程中创建随机掩码来统一找到并纠正故障传感器，有效性在公共数据集和实际风力涡轮数据集上得到验证。

    

    精确可靠的传感器测量对于确保风力涡轮等复杂工程系统的安全性和长期性至关重要。在本文中，我们提出了一种使用掩盖模型和自监督学习进行传感器故障检测、隔离和容错（FDIA）的新框架。我们提出的方法是一种通用的时间序列建模方法，可以应用于任何能够进行序列建模的神经网络（NN）模型，并捕捉不同传感器之间复杂的时空关系。在训练过程中，提出的掩盖方法创建随机掩码，它就像一个故障，针对一个或多个传感器，使训练和推断任务统一：找到有故障的传感器并进行纠正。我们在一个公共数据集和GE近海风力涡轮的真实数据集上验证了我们提出的技术，并展示了它在检测、诊断和纠正传感器故障方面的有效性。

    arXiv:2403.16153v1 Announce Type: cross  Abstract: Accurate and reliable sensor measurements are critical for ensuring the safety and longevity of complex engineering systems such as wind turbines. In this paper, we propose a novel framework for sensor fault detection, isolation, and accommodation (FDIA) using masked models and self-supervised learning. Our proposed approach is a general time series modeling approach that can be applied to any neural network (NN) model capable of sequence modeling, and captures the complex spatio-temporal relationships among different sensors. During training, the proposed masked approach creates a random mask, which acts like a fault, for one or more sensors, making the training and inference task unified: finding the faulty sensors and correcting them. We validate our proposed technique on both a public dataset and a real-world dataset from GE offshore wind turbines, and demonstrate its effectiveness in detecting, diagnosing and correcting sensor fau
    
[^101]: 消费者物联网流量的调查：安全与隐私

    A Survey on Consumer IoT Traffic: Security and Privacy

    [https://arxiv.org/abs/2403.16149](https://arxiv.org/abs/2403.16149)

    本调查针对消费者物联网（CIoT）流量分析从安全和隐私的角度出发，总结了CIoT流量分析的新特征、最新进展和挑战，认为通过流量分析可以揭示CIoT领域中的安全和隐私问题。

    

    在过去几年里，消费者物联网（CIoT）已经进入了公众生活。尽管CIoT提高了人们日常生活的便利性，但也带来了新的安全和隐私问题。我们尝试通过流量分析这一安全领域中的流行方法，找出研究人员可以从流量分析中了解CIoT安全和隐私方面的内容。本调查从安全和隐私角度探讨了CIoT流量分析中的新特征、CIoT流量分析的最新进展以及尚未解决的挑战。我们从2018年1月至2023年12月收集了310篇与CIoT流量分析有关的安全和隐私角度的论文，总结了识别了CIoT新特征的CIoT流量分析过程。然后，我们根据五个应用目标详细介绍了现有的研究工作：设备指纹识别、用户活动推断、恶意行为检测、隐私泄露以及通信模式识别。

    arXiv:2403.16149v1 Announce Type: cross  Abstract: For the past few years, the Consumer Internet of Things (CIoT) has entered public lives. While CIoT has improved the convenience of people's daily lives, it has also brought new security and privacy concerns. In this survey, we try to figure out what researchers can learn about the security and privacy of CIoT by traffic analysis, a popular method in the security community. From the security and privacy perspective, this survey seeks out the new characteristics in CIoT traffic analysis, the state-of-the-art progress in CIoT traffic analysis, and the challenges yet to be solved. We collected 310 papers from January 2018 to December 2023 related to CIoT traffic analysis from the security and privacy perspective and summarized the process of CIoT traffic analysis in which the new characteristics of CIoT are identified. Then, we detail existing works based on five application goals: device fingerprinting, user activity inference, malicious
    
[^102]: 一种基于投影的概念去除方法对数据集的影响

    What Happens to a Dataset Transformed by a Projection-based Concept Removal Method?

    [https://arxiv.org/abs/2403.16142](https://arxiv.org/abs/2403.16142)

    一种基于投影的概念去除方法会在转换后的数据集中注入强大的统计依赖性，并导致表示空间高度结构化，使得可以通过应用反聚类方法重建原始标记。

    

    我们研究了使用线性投影方法从语言表示中去除概念信息的方法的行为，并考虑了经过这种方法转换的数据集会发生什么。理论分析和对真实世界和合成数据的实验表明，这些方法会向转换后的数据集中注入强大的统计依赖性。应用此类方法后，表示空间具有高度结构化：在转换后的空间中，一个实例倾向于位于相反标签的实例附近。因此，在某些情况下，可以通过应用反聚类方法来重建原始标记。

    arXiv:2403.16142v1 Announce Type: cross  Abstract: We investigate the behavior of methods that use linear projections to remove information about a concept from a language representation, and we consider the question of what happens to a dataset transformed by such a method. A theoretical analysis and experiments on real-world and synthetic data show that these methods inject strong statistical dependencies into the transformed datasets. After applying such a method, the representation space is highly structured: in the transformed space, an instance tends to be located near instances of the opposite label. As a consequence, the original labeling can in some cases be reconstructed by applying an anti-clustering method.
    
[^103]: 电子商务中的互补推荐：定义、方法与未来方向

    Complementary Recommendation in E-commerce: Definition, Approaches, and Future Directions

    [https://arxiv.org/abs/2403.16135](https://arxiv.org/abs/2403.16135)

    本文全面总结和比较了电子商务领域中34项代表性互补推荐研究，包括建模产品之间的互补关系，不同研究问题下的模型分类与比较，以及在同一数据集上进行的实验结果分析。

    

    近年来，互补推荐在电子商务领域受到了广泛关注。本文对2009年至2024年间进行的34项代表性研究进行了全面总结和比较。首先，我们比较了用于建模产品之间互补关系的数据和方法，包括简单的互补性以及更复杂的情景，例如非对称互补性、产品之间替代和互补关系共存，以及不同产品对之间的互补程度不同。接下来，我们根据互补推荐的研究问题对模型进行分类并进行比较，如多样性、个性化和冷启动等。此外，我们对不同研究在同一数据集上进行的实验结果进行比较分析，有助于确定研究的优势和劣势。

    arXiv:2403.16135v1 Announce Type: cross  Abstract: In recent years, complementary recommendation has received extensive attention in the e-commerce domain. In this paper, we comprehensively summarize and compare 34 representative studies conducted between 2009 and 2024. Firstly, we compare the data and methods used for modeling complementary relationships between products, including simple complementarity and more complex scenarios such as asymmetric complementarity, the coexistence of substitution and complementarity relationships between products, and varying degrees of complementarity between different pairs of products. Next, we classify and compare the models based on the research problems of complementary recommendation, such as diversity, personalization, and cold-start. Furthermore, we provide a comparative analysis of experimental results from different studies conducted on the same dataset, which helps identify the strengths and weaknesses of the research. Compared to previou
    
[^104]: 基于分隔子图的分层池化SSHPool

    SSHPool: The Separated Subgraph-based Hierarchical Pooling

    [https://arxiv.org/abs/2403.16133](https://arxiv.org/abs/2403.16133)

    提出了基于分隔子图的分层池化（SSHPool）方法，通过将节点分配到不同的簇并利用局部图卷积单元进行压缩，解决了现有图神经网络中的过度平滑问题，有效提取了原始图结构的分层全局特征。

    

    在本文中，我们提出了一种新颖的本地图池化方法，称为基于分隔子图的分层池化（SSHPool），用于图分类。通过将一个样本图的节点分配到不同的簇中，从而产生一系列分隔的子图。我们分别使用本地图卷积单元作为局部结构，进一步将每个子图压缩成一个粗糙节点，将原始图转化为粗糙图。由于这些子图由不同的簇分隔开，结构信息无法在它们之间传播，局部卷积操作可以显著避免大多数现有图神经网络（GNNs）中出现的过度平滑问题。通过在结果粗糙图上层次地执行所提议的程序，SSHPool可以有效地提取原始图结构的分层全局特征。

    arXiv:2403.16133v1 Announce Type: new  Abstract: In this paper, we develop a novel local graph pooling method, namely the Separated Subgraph-based Hierarchical Pooling (SSHPool), for graph classification. To this end, we commence by assigning the nodes of a sample graph into different clusters, resulting in a family of separated subgraphs. We individually employ a local graph convolution units as the local structure to further compress each subgraph into a coarsened node, transforming the original graph into a coarsened graph. Since these subgraphs are separated by different clusters and the structural information cannot be propagated between them, the local convolution operation can significantly avoid the over-smoothing problem arising in most existing Graph Neural Networks (GNNs). By hierarchically performing the proposed procedures on the resulting coarsened graph, the proposed SSHPool can effectively extract the hierarchical global feature of the original graph structure, encapsul
    
[^105]: AKBR: 学习自适应基于核的图分类表示

    AKBR: Learning Adaptive Kernel-based Representations for Graph Classification

    [https://arxiv.org/abs/2403.16130](https://arxiv.org/abs/2403.16130)

    提出了一种用于图分类的自适应核表示学习模型，通过特征通道注意机制捕捉不同子结构之间的相互依赖关系，有效识别结构重要性，并计算与重要子结构相关的图对之间的R-卷积核。

    

    在本文中，我们提出了一种新模型，用于学习自适应基于核的图分类表示（AKBR）。与仅通过计算图之间同构子结构对的数量来定义的最先进的 R-卷积图核不同，无法为分类器提供端到端学习机制，所提出的AKBR方法旨在定义一个端到端表示学习模型，为图构建自适应核矩阵。为此，我们首先利用一种新颖的特征通道注意机制来捕捉原始图中不同子结构不变性之间的相互依赖关系。所提出的AKBR模型因此可以有效地确定不同子结构的结构重要性，并计算与由其结构注意力指定的更重要子结构相关的成对图之间的R-卷积核。由于结果核矩阵的每一行...（此处被截断）

    arXiv:2403.16130v1 Announce Type: cross  Abstract: In this paper, we propose a new model to learn Adaptive Kernel-based Representations (AKBR) for graph classification. Unlike state-of-the-art R-convolution graph kernels that are defined by merely counting any pair of isomorphic substructures between graphs and cannot provide an end-to-end learning mechanism for the classifier, the proposed AKBR approach aims to define an end-to-end representation learning model to construct an adaptive kernel matrix for graphs. To this end, we commence by leveraging a novel feature-channel attention mechanism to capture the interdependencies between different substructure invariants of original graphs. The proposed AKBR model can thus effectively identify the structural importance of different substructures, and compute the R-convolution kernel between pairwise graphs associated with the more significant substructures specified by their structural attentions. Since each row of the resulting kernel mat
    
[^106]: WangchanLion与WangchanX MRC评估

    WangchanLion and WangchanX MRC Eval

    [https://arxiv.org/abs/2403.16127](https://arxiv.org/abs/2403.16127)

    WangchanLion是一个专注于泰语机器阅读理解的指令微调模型，在0-shot和1-shot设置下能够理解上下文并产生与参考答案一致的回答，同时提出了新的评估方案。

    

    本技术报告描述了WangchanLion的开发过程，这是一个专注于泰语机器阅读理解（MRC）的指令微调模型。我们的模型基于SEA-LION和一系列指令跟随数据集。为了促进开放研究和可重复性，我们公开发布了所有训练数据、代码和最终模型权重，采用Apache-2许可证。为了评估上下文理解能力，我们使用两个泰语MRC数据集XQuAD和Iapp_wiki_qa_squad进行了广泛的实验研究。实验结果表明，在0-shot和1-shot设置下，模型能够理解上下文并产生与参考答案一致的回答。此外，我们的评估超越了传统的MRC。我们提出了一个新的评估方案，评估答案的正确性、帮助性、简洁性和上下文性。评估结果揭示了我们如何改进模型的见解。

    arXiv:2403.16127v1 Announce Type: cross  Abstract: This technical report describes the development of WangchanLion, an instruction fine-tuned model focusing on Machine Reading Comprehension (MRC) in the Thai language. Our model is based on SEA-LION and a collection of instruction following datasets. To promote open research and reproducibility, we publically release all training data, code, and the final model weights under the Apache-2 license. To assess the contextual understanding capability, we conducted extensive experimental studies using two Thai MRC datasets, XQuAD and Iapp_wiki_qa_squad. Experimental results demonstrate the model's ability to comprehend the context and produce an answer faithful to the reference one in 0-shot and 1-shot settings. In addition, our evaluation goes beyond the traditional MRC. We propose a new evaluation scheme assessing the answer's correctness, helpfulness, conciseness, and contextuality. Evaluation results provide insight into how we can improv
    
[^107]: 自监督多帧神经场景流

    Self-Supervised Multi-Frame Neural Scene Flow

    [https://arxiv.org/abs/2403.16116](https://arxiv.org/abs/2403.16116)

    通过研究表明，Neural Scene Flow Prior (NSFP)的性能与输入点云的数量呈反比关系，因此我们提出了一种简单而有效的多帧点云场景流估计方法。

    

    Neural Scene Flow Prior (NSFP)和Fast Neural Scene Flow (FNSF)在大规模场景中具有出色的自适应性，但是它们的泛化能力的基础原因尚不清楚。我们的研究通过统一稳定性的视角来审视NSFP的泛化能力，揭示其性能与输入点云数量呈反比关系。这一发现揭示了NSFP在处理大规模点云场景流估计任务中的有效性。受这些理论洞察的启发，我们进一步通过利用多帧历史点云来改进场景流估计，从而增加了点云的数量。因此，我们提出了一种简单而有效的多帧点云场景流估计方法。

    arXiv:2403.16116v1 Announce Type: cross  Abstract: Neural Scene Flow Prior (NSFP) and Fast Neural Scene Flow (FNSF) have shown remarkable adaptability in the context of large out-of-distribution autonomous driving. Despite their success, the underlying reasons for their astonishing generalization capabilities remain unclear. Our research addresses this gap by examining the generalization capabilities of NSFP through the lens of uniform stability, revealing that its performance is inversely proportional to the number of input point clouds. This finding sheds light on NSFP's effectiveness in handling large-scale point cloud scene flow estimation tasks. Motivated by such theoretical insights, we further explore the improvement of scene flow estimation by leveraging historical point clouds across multiple frames, which inherently increases the number of point clouds. Consequently, we propose a simple and effective method for multi-frame point cloud scene flow estimation, along with a theor
    
[^108]: 在放射学中应用大型人工智能模型的机遇与挑战

    Opportunities and challenges in the application of large artificial intelligence models in radiology

    [https://arxiv.org/abs/2403.16112](https://arxiv.org/abs/2403.16112)

    本文介绍了大型人工智能模型在放射学中的应用，总结了其在放射学教育、报告生成和影像应用方面的最新研究进展，并指出了大型AI模型在放射学中面临的挑战，旨在推动该领域的快速革命。

    

    受ChatGPT的影响，人工智能（AI）大型模型在全球范围内的研究和开发迎来了高潮。随着人们享受着这种AI大型模型带来的便利，越来越多的细分领域中提出了大型模型，尤其是放射学成像领域中的大型模型。本文首先介绍了大型模型的发展历史、技术细节、工作流程、多模式大型模型工作原理以及视频生成大型模型的工作原理。其次，我们总结了AI大型模型在放射学教育、放射学报告生成、单模式和多模式放射学应用方面的最新研究进展。最后，本文还总结了放射学中大型AI模型面临的一些挑战，旨在更好地推动放射学领域的快速革命。

    arXiv:2403.16112v1 Announce Type: cross  Abstract: Influenced by ChatGPT, artificial intelligence (AI) large models have witnessed a global upsurge in large model research and development. As people enjoy the convenience by this AI large model, more and more large models in subdivided fields are gradually being proposed, especially large models in radiology imaging field. This article first introduces the development history of large models, technical details, workflow, working principles of multimodal large models and working principles of video generation large models. Secondly, we summarize the latest research progress of AI large models in radiology education, radiology report generation, applications of unimodal and multimodal radiology. Finally, this paper also summarizes some of the challenges of large AI models in radiology, with the aim of better promoting the rapid revolution in the field of radiography.
    
[^109]: 一种用于电力价格预测的Transformer方法

    A Transformer approach for Electricity Price Forecasting

    [https://arxiv.org/abs/2403.16108](https://arxiv.org/abs/2403.16108)

    这种独特的Transformer模型在电力价格预测中取得了更好的表现，为可靠和可持续的电力系统运行提供了有前景的解决方案。

    

    本文提出了一种使用纯Transformer模型进行电力价格预测（EPF）的新方法。与其他方法不同，没有使用其他递归网络结合注意力机制。因此，表明注意力层足以捕捉时间模式。该论文还通过使用开源EPF工具进行了对模型的公平比较，并提供了代码以增强EPF研究的可再现性和透明度。结果表明，Transformer模型优于传统方法，为可靠和可持续的电力系统运行提供了一种有希望的解决方案。

    arXiv:2403.16108v1 Announce Type: cross  Abstract: This paper presents a novel approach to electricity price forecasting (EPF) using a pure Transformer model. As opposed to other alternatives, no other recurrent network is used in combination to the attention mechanism. Hence, showing that the attention layer is enough for capturing the temporal patterns. The paper also provides fair comparison of the models using the open-source EPF toolbox and provide the code to enhance reproducibility and transparency in EPF research. The results show that the Transformer model outperforms traditional methods, offering a promising solution for reliable and sustainable power system operation.
    
[^110]: 跨国界评估公平度量标准：来自人类感知的视角

    Evaluating Fairness Metrics Across Borders from Human Perceptions

    [https://arxiv.org/abs/2403.16101](https://arxiv.org/abs/2403.16101)

    该研究通过国际调查评估了不同国家对其决策情景中各种公平度量标准的适用性。

    

    哪些公平度量标准适用于您的场景？即使结果符合已建立的公平度量标准，也可能存在关于公平感知的不一致情况。已进行了多项调查，评估了公平度量标准与人们对公平的感知。然而，这些调查范围有限，仅包括单个国家中数百名参与者。在这项研究中，我们进行了一项国际调查，以评估各种公平度量标准在决策场景中的适用性。我们分别从中国、法国、日本和美国的每个国家收集了1,000名参与者的回应，总计得到了4,000个回应，以分析公平度量标准的偏好。我们的调查包括三个不同场景，配备了四种公平度量标准，每个参与者在每种情况下选择其喜好的公平度量标准。该研究探讨了

    arXiv:2403.16101v1 Announce Type: new  Abstract: Which fairness metrics are appropriately applicable in your contexts? There may be instances of discordance regarding the perception of fairness, even when the outcomes comply with established fairness metrics. Several surveys have been conducted to evaluate fairness metrics with human perceptions of fairness. However, these surveys were limited in scope, including only a few hundred participants within a single country. In this study, we conduct an international survey to evaluate the appropriateness of various fairness metrics in decision-making scenarios. We collected responses from 1,000 participants in each of China, France, Japan, and the United States, amassing a total of 4,000 responses, to analyze the preferences of fairness metrics. Our survey consists of three distinct scenarios paired with four fairness metrics, and each participant answers their preference for the fairness metric in each case. This investigation explores the
    
[^111]: 指定代理人伦理（蓝天想法）

    Specifying Agent Ethics (Blue Sky Ideas)

    [https://arxiv.org/abs/2403.16100](https://arxiv.org/abs/2403.16100)

    论文讨论了机器伦理系统应该具备的属性，并挑战社区以更系统化的方式探讨这个问题。

    

    我们考虑机器伦理系统应该具备什么属性。这个问题由于存在无法达成一致解决方案的伦理困境而变得复杂。我们提供一个例子来激励我们为什么认为仅依赖利益相关者的价值观表达并不足以保证这类系统的正确性。我们继续定义了我们自己工作中出现的两类伦理属性，并向社区提出一个挑战，以更系统化的方式探讨这一问题。

    arXiv:2403.16100v1 Announce Type: new  Abstract: We consider the question of what properties a Machine Ethics system should have. This question is complicated by the existence of ethical dilemmas with no agreed upon solution. We provide an example to motivate why we do not believe falling back on the elicitation of values from stakeholders is sufficient to guarantee correctness of such systems. We go on to define two broad categories of ethical property that have arisen in our own work and present a challenge to the community to approach this question in a more systematic way.
    
[^112]: 语言模型能够模拟求解器吗？LLMs的逻辑代码模拟

    Can Language Models Pretend Solvers? Logic Code Simulation with LLMs

    [https://arxiv.org/abs/2403.16097](https://arxiv.org/abs/2403.16097)

    这项研究探讨了一种新颖的任务，即逻辑代码模拟，迫使LLMs在预测逻辑程序的结果时模拟逻辑求解器，同时提出了三个研究问题以深入调查这一任务对LLMs的影响。

    

    基于Transformer的大型语言模型(LLMs)在解决逻辑问题方面展示了重要潜力。利用LLMs在代码相关活动中的卓越能力，最近提出了几种利用逻辑求解器进行逻辑推理的框架。虽然现有研究主要集中在将LLMs视为自然语言逻辑求解器或翻译器，但它们作为逻辑代码解释器和执行器的角色受到了较少关注。本研究深入探讨了一个新颖的方面，即逻辑代码模拟，它迫使LLMs在预测逻辑程序的结果时模拟逻辑求解器。为进一步研究这一新颖任务，我们制定了三个研究问题：LLMs能否有效地模拟逻辑代码的输出？逻辑代码模拟伴随着哪些优势？以及存在哪些缺陷？为了回答这些问题，我们整理了三个针对逻辑代码模拟的新颖数据集。

    arXiv:2403.16097v1 Announce Type: new  Abstract: Transformer-based large language models (LLMs) have demonstrated significant potential in addressing logic problems. capitalizing on the great capabilities of LLMs for code-related activities, several frameworks leveraging logical solvers for logic reasoning have been proposed recently. While existing research predominantly focuses on viewing LLMs as natural language logic solvers or translators, their roles as logic code interpreters and executors have received limited attention. This study delves into a novel aspect, namely logic code simulation, which forces LLMs to emulate logical solvers in predicting the results of logical programs. To further investigate this novel task, we formulate our three research questions: Can LLMs efficiently simulate the outputs of logic codes? What strength arises along with logic code simulation? And what pitfalls? To address these inquiries, we curate three novel datasets tailored for the logic code si
    
[^113]: 教育中学习、分析和人工智能的相互作用

    The Interplay of Learning, Analytics, and Artificial Intelligence in Education

    [https://arxiv.org/abs/2403.16081](https://arxiv.org/abs/2403.16081)

    本文提出了 AI 在学习和教育中的多维视角，强调了 AI、分析和学习过程之间错综复杂的相互作用，挑战了将 AI 视为随机工具的观念，强调了 AI 作为理解人类学习的重要性，并提出了三种独特的教育中人工智能的概念化。

    

    本文提出了人工智能在学习和教育中的多维视角，强调人工智能、分析和学习过程之间错综复杂的相互作用。笔者挑战了将人工智能仅视为随机工具的普遍观念，例如生成式人工智能，主张重视对人工智能的替代概念。文章突出了人类智能与人工信息处理之间的差异，AI算法中固有的认知多样性，并提出AI也可以作为理解人类学习的工具。从将AI视为人类智能的类比的早期学习科学和教育中的AI研究已经偏离这一观点，促使有必要重新点燃这种联系。本文提出了三种独特的教育中人工智能的概念化：人类认知的外部化、内化AI模型以影响人类思维

    arXiv:2403.16081v1 Announce Type: cross  Abstract: This paper presents a multi dimensional view of AI's role in learning and education, emphasizing the intricate interplay between AI, analytics, and the learning processes. Here, I challenge the prevalent narrow conceptualization of AI as stochastic tools, as exemplified in generative AI, and argue for the importance of alternative conceptualisations of AI. I highlight the differences between human intelligence and artificial information processing, the cognitive diversity inherent in AI algorithms, and posit that AI can also serve as an instrument for understanding human learning. Early learning sciences and AI in Education research, which saw AI as an analogy for human intelligence, have diverged from this perspective, prompting a need to rekindle this connection. The paper presents three unique conceptualizations of AI in education: the externalization of human cognition, the internalization of AI models to influence human thought pr
    
[^114]: 通过互信息正则化进行基准引导的跨说话人唇读

    Landmark-Guided Cross-Speaker Lip Reading with Mutual Information Regularization

    [https://arxiv.org/abs/2403.16071](https://arxiv.org/abs/2403.16071)

    通过利用唇部地标引导的细粒度视觉线索，提出了一种适应说话人的唇读模型，有效降低说话人之间的视觉变化。

    

    Lip reading，即通过视觉唇部运动解释无声语音的过程，由于其广泛的实际应用而引起人们的广泛关注。深度学习方法极大地改进了当前的唇读系统。然而，在说话人变化的交叉说话人场景中进行唇读，由于说话人之间的变异性，存在挑战性问题。一个训练良好的唇读系统在处理全新的说话人时可能表现不佳。为了学习一个适应说话人的唇读模型，一个关键的见解是减少说话人之间的视觉变化，避免模型过度拟合特定说话人。本研究针对基于混合CTC/attention架构的输入视觉线索和基于隐变量表示，提出利用唇部地标引导的细粒度视觉线索，而不是频繁使用的裁剪嘴巴图片作为输入特征，减少说话人特定的外观特征。

    arXiv:2403.16071v1 Announce Type: new  Abstract: Lip reading, the process of interpreting silent speech from visual lip movements, has gained rising attention for its wide range of realistic applications. Deep learning approaches greatly improve current lip reading systems. However, lip reading in cross-speaker scenarios where the speaker identity changes, poses a challenging problem due to inter-speaker variability. A well-trained lip reading system may perform poorly when handling a brand new speaker. To learn a speaker-robust lip reading model, a key insight is to reduce visual variations across speakers, avoiding the model overfitting to specific speakers. In this work, in view of both input visual clues and latent representations based on a hybrid CTC/attention architecture, we propose to exploit the lip landmark-guided fine-grained visual clues instead of frequently-used mouth-cropped images as input features, diminishing speaker-specific appearance characteristics. Furthermore, 
    
[^115]: 针对对抗净化的强大扩散模型

    Robust Diffusion Models for Adversarial Purification

    [https://arxiv.org/abs/2403.16067](https://arxiv.org/abs/2403.16067)

    提出一种独立于预训练扩散模型的稳健反向过程，避免了重新训练或微调，有效处理对抗净化中的语义信息损失问题。

    

    基于扩散模型（DM）的对抗净化（AP）已被证明是对抗训练（AT）最有力的替代方法。然而，这些方法忽略了预训练的扩散模型本身对对抗攻击并不稳健这一事实。此外，扩散过程很容易破坏语义信息，在反向过程后生成高质量图像但与原始输入图像完全不同，导致标准精度下降。为了解决这些问题，一个自然的想法是利用对抗训练策略重新训练或微调预训练的扩散模型，然而这在计算上是禁止的。我们提出了一种新颖的具有对抗引导的稳健反向过程，它独立于给定的预训练DMs，并且避免了重新训练或微调DMs。这种强大的引导不仅可以确保生成的净化示例保留更多的语义内容，还可以...

    arXiv:2403.16067v1 Announce Type: cross  Abstract: Diffusion models (DMs) based adversarial purification (AP) has shown to be the most powerful alternative to adversarial training (AT). However, these methods neglect the fact that pre-trained diffusion models themselves are not robust to adversarial attacks as well. Additionally, the diffusion process can easily destroy semantic information and generate a high quality image but totally different from the original input image after the reverse process, leading to degraded standard accuracy. To overcome these issues, a natural idea is to harness adversarial training strategy to retrain or fine-tune the pre-trained diffusion model, which is computationally prohibitive. We propose a novel robust reverse process with adversarial guidance, which is independent of given pre-trained DMs and avoids retraining or fine-tuning the DMs. This robust guidance can not only ensure to generate purified examples retaining more semantic content but also m
    
[^116]: 一个用于动态推荐的时间图网络框架

    A Temporal Graph Network Framework for Dynamic Recommendation

    [https://arxiv.org/abs/2403.16066](https://arxiv.org/abs/2403.16066)

    该研究首次将时间图网络（TGN）直接应用于推荐系统，展示了其在动态推荐场景中的有效性。

    

    推荐系统对于用户在电子商务和流媒体服务等平台上的参与至关重要，然而由于静态数据依赖，推荐系统常常落后于用户不断变化的偏好。在时间图网络（TGN）被提出后，各种研究表明TGN可以显著改善节点和边的特征随时间动态变化的情况。然而，尽管其有着良好的潜力，但迄今为止尚未直接应用于推荐系统。我们的研究通过直接在推荐系统中实现时间图网络（TGN）来弥补这一差距，这在该领域尚属首次。通过使用真实世界的数据集和一系列图形和历史嵌入方法，我们展示了TGN的适应性，证实了其在动态推荐场景中的有效性。

    arXiv:2403.16066v1 Announce Type: new  Abstract: Recommender systems, crucial for user engagement on platforms like e-commerce and streaming services, often lag behind users' evolving preferences due to static data reliance. After Temporal Graph Networks (TGNs) were proposed, various studies have shown that TGN can significantly improve situations where the features of nodes and edges dynamically change over time. However, despite its promising capabilities, it has not been directly applied in recommender systems to date. Our study bridges this gap by directly implementing Temporal Graph Networks (TGN) in recommender systems, a first in this field. Using real-world datasets and a range of graph and history embedding methods, we show TGN's adaptability, confirming its effectiveness in dynamic recommendation scenarios.
    
[^117]: Qibo: 一种用于中医领域的大型语言模型

    Qibo: A Large Language Model for Traditional Chinese Medicine

    [https://arxiv.org/abs/2403.16056](https://arxiv.org/abs/2403.16056)

    本论文在中医领域构建了专业语料库，基于LLaMA成功开发了首个经过完整训练的Qibo模型，并推出了用于评估LLMs性能的Qibo基准测试。

    

    在人工智能领域，大型语言模型(LLMs)展示了在用户意图理解和响应方面取得的显著进展，在许多专业领域，包括医学、法律和金融。然而，在中医领域，LLMs的性能提升受到挑战，其原因在于中医理论与现代医学之间的根本差异，以及缺乏专业语料库资源。本文旨在构建和整理中医领域的专业语料库，赋予大型模型具有中医理论特色的专业知识，并成功基于LLaMA开发了Qibo模型，这是中医领域第一个经过完整训练过程（从预训练到监督微调）的LLM。此外，我们开发了Qibo基准测试，这是一个用于评估LLMs性能的专门工具。

    arXiv:2403.16056v1 Announce Type: cross  Abstract: In the field of Artificial Intelligence, Large Language Models (LLMs) have demonstrated significant advances in user intent understanding and response in a number of specialized domains, including medicine, law, and finance. However, in the unique domain of traditional Chinese medicine (TCM), the performance enhancement of LLMs is challenged by the essential differences between its theories and modern medicine, as well as the lack of specialized corpus resources. In this paper, we aim to construct and organize a professional corpus in the field of TCM, to endow the large model with professional knowledge that is characteristic of TCM theory, and to successfully develop the Qibo model based on LLaMA, which is the first LLM in the field of TCM to undergo a complete training process from pre-training to Supervised Fine-Tuning (SFT). Furthermore, we develop the Qibo-benchmark, a specialized tool for evaluating the performance of LLMs, whic
    
[^118]: 只需语义信息：NeRF重建中的语义信息足够

    Semantic Is Enough: Only Semantic Information For NeRF Reconstruction

    [https://arxiv.org/abs/2403.16043](https://arxiv.org/abs/2403.16043)

    该研究展示了NeRF模型在重建3D结构中仅利用语义信息的优秀表现，通过去除RGB输出组件，模型训练过程重点关注语义输出与地面真实图像之间的交叉熵损失。

    

    最近的研究结合隐式3D表示和语义信息，如Semantic-NeRF，证明NeRF模型在呈现具有语义标签的3D结构方面表现出色。本研究旨在通过仅关注语义输出并移除RGB输出组件来扩展Semantic Neural Radiance Fields（Semantic-NeRF）模型。我们重新构建模型及其训练过程，仅利用模型语义输出与地面真实语义图像之间的交叉熵损失，移除了原始Semantic-NeRF方法中传统使用的颜色数据。然后，我们使用原始和修改后的Semantic-NeRF模型进行了一系列相同的实验。我们的主要目标是观察这种修改对Semantic-NeRF模型性能的影响，重点关注场景理解、物体检测和分割等任务。结果为场景理解、物体检测和分割等任务提供了有价值的见解。

    arXiv:2403.16043v1 Announce Type: cross  Abstract: Recent research that combines implicit 3D representation with semantic information, like Semantic-NeRF, has proven that NeRF model could perform excellently in rendering 3D structures with semantic labels. This research aims to extend the Semantic Neural Radiance Fields (Semantic-NeRF) model by focusing solely on semantic output and removing the RGB output component. We reformulate the model and its training procedure to leverage only the cross-entropy loss between the model semantic output and the ground truth semantic images, removing the colour data traditionally used in the original Semantic-NeRF approach. We then conduct a series of identical experiments using the original and the modified Semantic-NeRF model. Our primary objective is to obverse the impact of this modification on the model performance by Semantic-NeRF, focusing on tasks such as scene understanding, object detection, and segmentation. The results offer valuable ins
    
[^119]: RPMArt：面向关节对象的健壮感知和操作

    RPMArt: Towards Robust Perception and Manipulation for Articulated Objects

    [https://arxiv.org/abs/2403.16023](https://arxiv.org/abs/2403.16023)

    提出了面向关节对象的健壮感知和操作框架RPMArt，主要贡献是能够稳健地预测关节参数和可信点的RoArtNet。

    

    关节对象在日常生活中很常见。对于真实世界的机器人应用来说，机器人能够表现出对关节对象的健壮感知和操作技能是至关重要的。然而，现有的关节对象方法不够解决点云中的噪声问题，难以弥合模拟与现实之间的差距，从而限制了在真实场景中的实际部署。为了解决这些挑战，我们提出了一个面向关节对象的健壮感知和操作的框架（RPMArt），该框架学习如何从嘈杂的点云中估计关节参数并操作关节部分。我们的主要贡献是一个健壮关节网络（RoArtNet），通过局部特征学习和点元组投票能够稳健地预测关节参数和可信点。此外，我们引入了一个关节感知分类方案来增强其能力。

    arXiv:2403.16023v1 Announce Type: cross  Abstract: Articulated objects are commonly found in daily life. It is essential that robots can exhibit robust perception and manipulation skills for articulated objects in real-world robotic applications. However, existing methods for articulated objects insufficiently address noise in point clouds and struggle to bridge the gap between simulation and reality, thus limiting the practical deployment in real-world scenarios. To tackle these challenges, we propose a framework towards Robust Perception and Manipulation for Articulated Objects (RPMArt), which learns to estimate the articulation parameters and manipulate the articulation part from the noisy point cloud. Our primary contribution is a Robust Articulation Network (RoArtNet) that is able to predict both joint parameters and affordable points robustly by local feature learning and point tuple voting. Moreover, we introduce an articulation-aware classification scheme to enhance its ability
    
[^120]: 填补空白(基于扩散的图像修复流程)

    Fill in the ____ (a Diffusion-based Image Inpainting Pipeline)

    [https://arxiv.org/abs/2403.16016](https://arxiv.org/abs/2403.16016)

    本文提出了一个基于扩散的图像修复流程，弥补了现有模型在促进和控制生成内容方面的关键差距。

    

    图像修复是将图像输入并生成丢失或故意遮挡部分的过程。修复有无数应用，包括恢复先前损坏的图片、恢复由于压缩而降低质量的图像，以及删除不需要的物体/文本。现代修复技术已经显示出在为具有遮罩遮挡的图像生成合理完成方面的显着能力。在本文中，我们将提供修复技术进展的概述，并确定当前领先方法，重点放在它们的优势和劣势上。我们将解决这些现有模型中的一个关键差距，重点是促进和控制生成的确切内容的能力。我们还将证明为什么我们认为这是修复模型必须采取的自然的下一个进步步骤，并提供实现这一功能的多种方法。最后，我们将e

    arXiv:2403.16016v1 Announce Type: cross  Abstract: Image inpainting is the process of taking an image and generating lost or intentionally occluded portions. Inpainting has countless applications including restoring previously damaged pictures, restoring the quality of images that have been degraded due to compression, and removing unwanted objects/text. Modern inpainting techniques have shown remarkable ability in generating sensible completions for images with mask occlusions. In our paper, an overview of the progress of inpainting techniques will be provided, along with identifying current leading approaches, focusing on their strengths and weaknesses. A critical gap in these existing models will be addressed, focusing on the ability to prompt and control what exactly is generated. We will additionally justify why we think this is the natural next progressive step that inpainting models must take, and provide multiple approaches to implementing this functionality. Finally, we will e
    
[^121]: 一种适用于具有不同图网络结构的节点分类任务的联邦参数聚合方法

    A Federated Parameter Aggregation Method for Node Classification Tasks with Different Graph Network Structures

    [https://arxiv.org/abs/2403.16004](https://arxiv.org/abs/2403.16004)

    提出了一种适用于具有不同图网络结构的节点分类任务的联邦参数聚合方法FLGNN，并验证了其有效性。同时，设计了隐私安全的成员推理攻击实验和差分隐私防御实验。

    

    在过去几年里，由于其协作训练多个来源数据而不会泄露隐私的能力，联邦学习已经广泛应用于各种经典机器学习领域。然而，在图神经网络领域，由客户端持有的图的节点和网络结构在许多实际应用中是不同的，直接共享模型梯度的聚合方法不能直接应用于这种情况。因此，本文提出了一种适用于各种图联邦场景的联邦聚合方法FLGNN，并探讨了图神经网络模型每一层参数共享的聚合效果。通过在真实数据集上的实验验证了联邦聚合方法FLGNN的有效性。另外，为了保护FLGNN的隐私安全，本文设计了成员推理攻击实验和差分隐私防御实验。

    arXiv:2403.16004v1 Announce Type: cross  Abstract: Over the past few years, federated learning has become widely used in various classical machine learning fields because of its collaborative ability to train data from multiple sources without compromising privacy. However, in the area of graph neural networks, the nodes and network structures of graphs held by clients are different in many practical applications, and the aggregation method that directly shares model gradients cannot be directly applied to this scenario. Therefore, this work proposes a federated aggregation method FLGNN applied to various graph federation scenarios and investigates the aggregation effect of parameter sharing at each layer of the graph neural network model. The effectiveness of the federated aggregation method FLGNN is verified by experiments on real datasets. Additionally, for the privacy security of FLGNN, this paper designs membership inference attack experiments and differential privacy defense expe
    
[^122]: 多元表示嵌入用于终身人员再识别

    Diverse Representation Embedding for Lifelong Person Re-Identification

    [https://arxiv.org/abs/2403.16003](https://arxiv.org/abs/2403.16003)

    提出了一种多元表示嵌入(DRE)框架，用于终身人员再识别(LReID)，可以在学习新信息的同时有效保留旧知识，通过自适应约束模块(ACM)实现多个表示之间的整合和推开操作，为每个实例获取密集嵌入子空间，提高有限旧任务数据集上的匹配能力。

    

    终身人员再识别(LReID)旨在不断学习连续的数据流，跨多个摄像头匹配个人。LReID的关键挑战是在增量学习新信息的同时有效保留旧知识。任务级域差距和有限的旧任务数据集是导致ReID中灾难性遗忘的关键因素，这些因素在现有方法中被忽视。为了缓解这一问题，我们提出了一种新颖的多元表示嵌入(DRE)框架用于LReID。所提出的DRE基于实例级和任务级布局，保留旧知识同时适应新信息。具体来说，提出了一种自适应约束模块(ACM)来实现多个表示之间的整合和推开操作，为每个实例获取密集嵌入子空间，以提高有限旧任务数据集上的匹配能力。

    arXiv:2403.16003v1 Announce Type: cross  Abstract: Lifelong Person Re-Identification (LReID) aims to continuously learn from successive data streams, matching individuals across multiple cameras. The key challenge for LReID is how to effectively preserve old knowledge while learning new information incrementally. Task-level domain gaps and limited old task datasets are key factors leading to catastrophic forgetting in ReLD, which are overlooked in existing methods. To alleviate this problem, we propose a novel Diverse Representation Embedding (DRE) framework for LReID. The proposed DRE preserves old knowledge while adapting to new information based on instance-level and task-level layout. Concretely, an Adaptive Constraint Module (ACM) is proposed to implement integration and push away operations between multiple representations, obtaining dense embedding subspace for each instance to improve matching ability on limited old task datasets. Based on the processed diverse representation, 
    
[^123]: 多尺度时空图卷积网络用于面部表情识别

    Multi-Scale Spatio-Temporal Graph Convolutional Network for Facial Expression Spotting

    [https://arxiv.org/abs/2403.15994](https://arxiv.org/abs/2403.15994)

    本文提出了一种多尺度时空图卷积网络（SpoT-GCN），通过引入感受野自适应滑动窗口策略来有效识别面部表情，学习面部图模式以增强微小运动特征的提取。

    

    面部表情识别是面部表情分析中的关键但具有挑战性的任务。表情识别的准确性受到不相关面部运动以及难以察觉微表情细微运动的影响。本文提出了一种用于面部表情识别的多尺度时空图卷积网络（SpoT-GCN）。为了提取更加稳健的运动特征，我们跟踪面部肌肉的短期和长期运动，在紧凑的滑动窗口中，窗口长度适应于网络的时间感受野。这种策略被称为感受野自适应滑动窗口策略，有效放大了运动特征，同时缓解了严重头部运动的问题。微小的运动特征然后转换为面部图表示，其时空图模式由图卷积网络学习。这个网络学习了bo。

    arXiv:2403.15994v1 Announce Type: cross  Abstract: Facial expression spotting is a significant but challenging task in facial expression analysis. The accuracy of expression spotting is affected not only by irrelevant facial movements but also by the difficulty of perceiving subtle motions in micro-expressions. In this paper, we propose a Multi-Scale Spatio-Temporal Graph Convolutional Network (SpoT-GCN) for facial expression spotting. To extract more robust motion features, we track both short- and long-term motion of facial muscles in compact sliding windows whose window length adapts to the temporal receptive field of the network. This strategy, termed the receptive field adaptive sliding window strategy, effectively magnifies the motion features while alleviating the problem of severe head movement. The subtle motion features are then converted to a facial graph representation, whose spatio-temporal graph patterns are learned by a graph convolutional network. This network learns bo
    
[^124]: 知识引导的机器学习：当前趋势与未来展望

    Knowledge-guided Machine Learning: Current Trends and Future Prospects

    [https://arxiv.org/abs/2403.15989](https://arxiv.org/abs/2403.15989)

    知识引导的机器学习（KGML）结合科学知识和数据在机器学习框架中，以实现更好的泛化能力、科学一致性和结果可解释性。

    

    本文概述了科学建模，并讨论了与基于过程的模型相比，机器学习方法在科学建模中的互补优势和劣势。文章还介绍了新兴领域科学知识引导的机器学习（KGML）研究的当前状态，旨在利用科学知识和数据在机器学习框架中实现更好的泛化能力、科学一致性和结果可解释性。我们从使用的科学知识类型、探讨的知识-ML集成形式以及在机器学习中整合科学知识的方法等方面讨论了KGML研究的不同方面。我们还讨论了在环境科学中发展的KGML方法的一些常见用例类别，以每个类别中的实例为例。

    arXiv:2403.15989v1 Announce Type: cross  Abstract: This paper presents an overview of scientific modeling and discusses the complementary strengths and weaknesses of ML methods for scientific modeling in comparison to process-based models. It also provides an introduction to the current state of research in the emerging field of scientific knowledge-guided machine learning (KGML) that aims to use both scientific knowledge and data in ML frameworks to achieve better generalizability, scientific consistency, and explainability of results. We discuss different facets of KGML research in terms of the type of scientific knowledge used, the form of knowledge-ML integration explored, and the method for incorporating scientific knowledge in ML. We also discuss some of the common categories of use cases in environmental sciences where KGML methods are being developed, using illustrative examples in each category.
    
[^125]: 朝向基于双流眼底聚焦的主动视觉学习

    Towards Two-Stream Foveation-based Active Vision Learning

    [https://arxiv.org/abs/2403.15977](https://arxiv.org/abs/2403.15977)

    本研究提出了一个受“双流假设”启发的机器学习框架，通过模拟人类视觉系统的工作原理，分为腹侧流和背侧流两部分，以实现对焦和处理图像patch的序列。

    

    基于深度神经网络（DNN）的机器感知框架以一次性方式处理整个输入，以提供“被观察到的物体是什么”和“它位于哪里”这两个问题的答案。相比之下，神经科学中的“双流假设”解释了人类视觉皮层中的神经处理，表明其作为一个利用大脑的两个不同区域来回答“是什么”和“在哪里”的视觉系统。在这项工作中，我们提出了一个受“双流假设”启发的机器学习框架，并探讨了它所带来的潜在好处。具体而言，所提出的框架模拟了以下机制：1）腹侧（是什么）流聚焦于眼球（眼底）的视野部分，2）背侧（在哪里）流提供视觉引导，3）两个流的迭代处理以校准视觉焦点并处理一系列聚焦的图像块。该框架的训练...

    arXiv:2403.15977v1 Announce Type: cross  Abstract: Deep neural network (DNN) based machine perception frameworks process the entire input in a one-shot manner to provide answers to both "what object is being observed" and "where it is located". In contrast, the "two-stream hypothesis" from neuroscience explains the neural processing in the human visual cortex as an active vision system that utilizes two separate regions of the brain to answer the what and the where questions. In this work, we propose a machine learning framework inspired by the "two-stream hypothesis" and explore the potential benefits that it offers. Specifically, the proposed framework models the following mechanisms: 1) ventral (what) stream focusing on the input regions perceived by the fovea part of an eye (foveation), 2) dorsal (where) stream providing visual guidance, and 3) iterative processing of the two streams to calibrate visual focus and process the sequence of focused image patches. The training of the pr
    
[^126]: CBGT-Net: 一种用于对流数据进行稳健分类的类脑模仿架构

    CBGT-Net: A Neuromimetic Architecture for Robust Classification of Streaming Data

    [https://arxiv.org/abs/2403.15974](https://arxiv.org/abs/2403.15974)

    CBGT-Net是一种受CBGT回路启发的神经网络模型，通过积累足够的证据后才对流数据产生分类决策，在图像分类任务中表现出更高的准确性和稳健性。

    

    这篇论文描述了CBGT-Net，这是一种受哺乳动物大脑中皮质-基底节-丘脑（CBGT）回路启发的神经网络模型。与传统的神经网络模型不同，CBGT-Net学习在观察到的数据流中达到足够证据标准后产生输出。对于每次观察，CBGT-Net生成一个矢量，明确表示观察为每个潜在决定提供的证据量，随时间累积证据，并在累积证据超过预定义阈值时生成决策。我们在两个图像分类任务上评估了所提出的模型，在这些任务中模型需要根据从图像中提取的小补丁流来预测图像类别。我们展示了CBGT-Net相比传统方法在准确性和稳健性方面提供了改进。

    arXiv:2403.15974v1 Announce Type: cross  Abstract: This paper describes CBGT-Net, a neural network model inspired by the cortico-basal ganglia-thalamic (CBGT) circuits found in mammalian brains. Unlike traditional neural network models, which either generate an output for each provided input, or an output after a fixed sequence of inputs, the CBGT-Net learns to produce an output after a sufficient criteria for evidence is achieved from a stream of observed data. For each observation, the CBGT-Net generates a vector that explicitly represents the amount of evidence the observation provides for each potential decision, accumulates the evidence over time, and generates a decision when the accumulated evidence exceeds a pre-defined threshold. We evaluate the proposed model on two image classification tasks, where models need to predict image categories based on a stream of small patches extracted from the image. We show that the CBGT-Net provides improved accuracy and robustness compared t
    
[^127]: 使用机器学习方法检测问题赌博，使用更少的特征

    Detection of Problem Gambling with Less Features Using Machine Learning Methods

    [https://arxiv.org/abs/2403.15962](https://arxiv.org/abs/2403.15962)

    提出了一种使用更少的特征进行问题赌博检测的深度神经网络模型，并发现在不影响性能的情况下可以将特征从102个减少到5个。

    

    在赌博研究中，基于对用户每日行为数据的监控而执行分析特征。在执行问题赌博检测时，现有数据集为建立基于机器学习的模型提供了相对丰富的分析特征。然而，考虑到在实际应用中收集分析特征的复杂性和成本，使用更少的特征进行精确检测将极大减少数据收集成本。在这项研究中，我们提出了一个深度神经网络 PGN4，在使用有限的分析特征时表现良好。通过对两个数据集进行实验，我们发现当将102个特征减少到5个特征时，PGN4仅遭遇了轻微的性能下降。此外，我们发现了两个数据集中排名前5的特征的共同点。

    arXiv:2403.15962v1 Announce Type: cross  Abstract: Analytic features in gambling study are performed based on the amount of data monitoring on user daily actions. While performing the detection of problem gambling, existing datasets provide relatively rich analytic features for building machine learning based model. However, considering the complexity and cost of collecting the analytic features in real applications, conducting precise detection with less features will tremendously reduce the cost of data collection. In this study, we propose a deep neural networks PGN4 that performs well when using limited analytic features. Through the experiment on two datasets, we discover that PGN4 only experiences a mere performance drop when cutting 102 features to 5 features. Besides, we find the commonality within the top 5 features from two datasets.
    
[^128]: SAT编码的偏序模型用于图着色问题

    SAT Encoding of Partial Ordering Models for Graph Coloring Problems

    [https://arxiv.org/abs/2403.15961](https://arxiv.org/abs/2403.15961)

    该研究提出了新的SAT编码的偏序模型用于图着色问题，实验结果显示在一些情况下超越了现有的最先进方法，并对带宽着色问题进行了理论分析。

    

    在本文中，我们提出了基于偏序的整数线性规划（ILP）模型的图着色问题（GCP）和带宽着色问题（BCP）的新SAT编码。 GCP要求给定图的顶点分配最少数量的颜色，以便每两个相邻的顶点得到不同的颜色。 BCP是一个泛化问题，其中每条边都有一个权重，要求分配的颜色之间有最小的“距离”，目标是最小化使用的“最大”颜色。 对于被广泛研究的GCP，我们在DIMACS基准集上实验比较了我们新的SAT编码与现有最先进方法。 我们的评估证实，这种SAT编码对于稀疏图是有效的，并且甚至在一些DIMACS示例上胜过了现有最先进方法。 对于BCP，我们的理论分析表明，基于偏序的SAT和ILP公式的大小在渐近意义下小于经典的解法。

    arXiv:2403.15961v1 Announce Type: new  Abstract: In this paper, we suggest new SAT encodings of the partial-ordering based ILP model for the graph coloring problem (GCP) and the bandwidth coloring problem (BCP). The GCP asks for the minimum number of colors that can be assigned to the vertices of a given graph such that each two adjacent vertices get different colors. The BCP is a generalization, where each edge has a weight that enforces a minimal "distance" between the assigned colors, and the goal is to minimize the "largest" color used. For the widely studied GCP, we experimentally compare our new SAT encoding to the state-of-the-art approaches on the DIMACS benchmark set. Our evaluation confirms that this SAT encoding is effective for sparse graphs and even outperforms the state-of-the-art on some DIMACS instances. For the BCP, our theoretical analysis shows that the partial-ordering based SAT and ILP formulations have an asymptotically smaller size than that of the classical assi
    
[^129]: 在干草堆中寻找针: 一种透明水印检测的黑盒方法

    Finding needles in a haystack: A Black-Box Approach to Invisible Watermark Detection

    [https://arxiv.org/abs/2403.15955](https://arxiv.org/abs/2403.15955)

    提出了一种透明水印检测的黑盒方法WMD，在无注释设置下，利用干净无水印数据集检测任意水印，效果显著优于传统方法

    

    在本文中，我们提出了WaterMark Detection（WMD），这是第一个在黑盒和无注释设置下进行透明水印检测的方法。WMD能够利用一个干净的无水印数据集作为参考，在不依赖特定解码方法或对水印技术的事先了解的情况下，检测给定参考数据集中的任意水印。我们使用偏移学习的基础开发了WMD，干净的无水印数据集使我们能够仅分离出参考数据集中带水印样本的影响。我们进行了全面的评估，证明了WMD的有效性，明显优于仅产生约0.5的AUC得分的简单检测方法。相比之下，WMD在大多数单水印数据集中持续获得令人印象深刻的检测AUC得分，超过0.9，并在更具挑战性的多水印场景中的各种数据集和水印方法中超过0.7。

    arXiv:2403.15955v1 Announce Type: cross  Abstract: In this paper, we propose WaterMark Detection (WMD), the first invisible watermark detection method under a black-box and annotation-free setting. WMD is capable of detecting arbitrary watermarks within a given reference dataset using a clean non-watermarked dataset as a reference, without relying on specific decoding methods or prior knowledge of the watermarking techniques. We develop WMD using foundations of offset learning, where a clean non-watermarked dataset enables us to isolate the influence of only watermarked samples in the reference dataset. Our comprehensive evaluations demonstrate the effectiveness of WMD, significantly outperforming naive detection methods, which only yield AUC scores around 0.5. In contrast, WMD consistently achieves impressive detection AUC scores, surpassing 0.9 in most single-watermark datasets and exceeding 0.7 in more challenging multi-watermark scenarios across diverse datasets and watermarking me
    
[^130]: 了解损失压缩在机器学习训练集中的有效性

    Understanding The Effectiveness of Lossy Compression in Machine Learning Training Sets

    [https://arxiv.org/abs/2403.15953](https://arxiv.org/abs/2403.15953)

    深入探究损失压缩对模型质量的影响，发现现代损失压缩方法可以在保证质量损失在1%以下的情况下实现50-100倍的压缩比提升。

    

    学习和人工智能（ML/AI）技术在高性能计算（HPC）中变得日益普及。然而，这些方法依赖于大量的浮点数据用于训练和验证，需要方法在广域网络（WAN）上共享数据或将其从边缘设备传输到数据中心。数据压缩可以解决这些问题，但需要深入了解损失压缩如何影响模型质量。我们设计了评估ML/AI数据减少技术的系统方法，并使用它对17种数据减少方法在7个ML/AI应用程序上进行了非常全面的评估，表明现代的损失压缩方法可以实现50-100倍的压缩比改善，质量损失在1%以下。我们提出了关键见解，指导未来的使用和de

    arXiv:2403.15953v1 Announce Type: cross  Abstract: Learning and Artificial Intelligence (ML/AI) techniques have become increasingly prevalent in high performance computing (HPC). However, these methods depend on vast volumes of floating point data for training and validation which need methods to share the data on a wide area network (WAN) or to transfer it from edge devices to data centers. Data compression can be a solution to these problems, but an in-depth understanding of how lossy compression affects model quality is needed. Prior work largely considers a single application or compression method. We designed a systematic methodology for evaluating data reduction techniques for ML/AI, and we use it to perform a very comprehensive evaluation with 17 data reduction methods on 7 ML/AI applications to show modern lossy compression methods can achieve a 50-100x compression ratio improvement for a 1% or less loss in quality. We identify critical insights that guide the future use and de
    
[^131]: 自适应超分辨率用于一拍即合的说唱头视频生成

    Adaptive Super Resolution For One-Shot Talking-Head Generation

    [https://arxiv.org/abs/2403.15944](https://arxiv.org/abs/2403.15944)

    该论文提出了一种自适应高质量说唱头视频生成方法，可以合成高分辨率视频，无需额外的预训练模块。

    

    arXiv:2403.15944v1 类型：交叉 摘要：一拍即合的说唱头视频生成学习如何在相同或不同身份视频的操控下合成一个以源肖像图像为基础的说唱头视频。通常这些方法通过雅可比矩阵或脸部图像变形来进行基于平面的像素变换，以生成新的姿势。使用单一图像源和像素位移的约束通常会损害合成图像的清晰度。一些方法尝试通过引入额外的超分辨率模块来提高合成视频的质量，但这无疑会增加计算开销并破坏原始数据分布。在本研究中，我们提出了一种自适应高质量说唱头视频生成方法，可以合成高分辨率视频，而无需额外的预训练模块。具体来说，受现有超分辨率方法的启发，我们对一拍即合的源图像进行下采样，然后自适应重建。

    arXiv:2403.15944v1 Announce Type: cross  Abstract: The one-shot talking-head generation learns to synthesize a talking-head video with one source portrait image under the driving of same or different identity video. Usually these methods require plane-based pixel transformations via Jacobin matrices or facial image warps for novel poses generation. The constraints of using a single image source and pixel displacements often compromise the clarity of the synthesized images. Some methods try to improve the quality of synthesized videos by introducing additional super-resolution modules, but this will undoubtedly increase computational consumption and destroy the original data distribution. In this work, we propose an adaptive high-quality talking-head video generation method, which synthesizes high-resolution video without additional pre-trained modules. Specifically, inspired by existing super-resolution methods, we down-sample the one-shot source image, and then adaptively reconstruct 
    
[^132]: 探索直到自信: 面向具身问答的高效探索

    Explore until Confident: Efficient Exploration for Embodied Question Answering

    [https://arxiv.org/abs/2403.15941](https://arxiv.org/abs/2403.15941)

    通过利用大型视觉-语言模型的语义推理能力，结合深度信息和视觉提示，提出了一种方法来解决具身问答中的有效探索和回答问题的挑战

    

    我们考虑了具身问答（EQA）的问题，这指的是在需要主动探索环境以收集信息直到对问题的答案有自信的具身代理，例如机器人。在这项工作中，我们利用大规模视觉-语言模型（VLMs）的强大语义推理能力来高效探索和回答这些问题。然而，在EQA中使用VLMs时存在两个主要挑战：它们没有内部记忆将场景映射以便规划如何随时间探索，并且它们的置信度可能被错误校准并可能导致机器人过早停止探索或过度探索。我们提出了一种方法，首先基于深度信息和通过视觉提示VLM来构建场景的语义地图-利用其对场景相关区域的广泛知识来进行探索。接下来，我们使用符合预测来校准VLM的置信度。

    arXiv:2403.15941v1 Announce Type: cross  Abstract: We consider the problem of Embodied Question Answering (EQA), which refers to settings where an embodied agent such as a robot needs to actively explore an environment to gather information until it is confident about the answer to a question. In this work, we leverage the strong semantic reasoning capabilities of large vision-language models (VLMs) to efficiently explore and answer such questions. However, there are two main challenges when using VLMs in EQA: they do not have an internal memory for mapping the scene to be able to plan how to explore over time, and their confidence can be miscalibrated and can cause the robot to prematurely stop exploration or over-explore. We propose a method that first builds a semantic map of the scene based on depth information and via visual prompting of a VLM - leveraging its vast knowledge of relevant regions of the scene for exploration. Next, we use conformal prediction to calibrate the VLM's 
    
[^133]: 地理代币与地理变压器

    Geotokens and Geotransformers

    [https://arxiv.org/abs/2403.15940](https://arxiv.org/abs/2403.15940)

    本文提出了地理代币的概念，将其作为变压器的输入组件与具体地理位置联系起来，设计了一种针对球面坐标的位置编码方法。

    

    在变压器架构中，位置编码主要为输入代币提供了序列的意义。原始变压器论文的方法在一般语言处理任务中表现出令人满意的结果，但也有了新的提议，如旋转位置嵌入（RoPE），以进一步改进。本文提出了地理代币，变压器的输入组件，每一个代币与特定地质位置相连。与典型的语言序列不同，对于这些代币，顺序并不像地理坐标本身那样重要。为了在这种情况下表示相对位置，并在真实世界距离和嵌入空间中的距离之间保持平衡，我们设计了一种位置编码方法，借鉴于RoPE结构但专为球面坐标定制。

    arXiv:2403.15940v1 Announce Type: cross  Abstract: In transformer architectures, position encoding primarily provides a sense of sequence for input tokens. While the original transformer paper's method has shown satisfactory results in general language processing tasks, there have been new proposals, such as Rotary Position Embedding (RoPE), for further improvement. This paper presents geotokens, input components for transformers, each linked to a specific geological location. Unlike typical language sequences, for these tokens, the order is not as vital as the geographical coordinates themselves. To represent the relative position in this context and to keep a balance between the real world distance and the distance in the embedding space, we design a position encoding approach drawing from the RoPE structure but tailored for spherical coordinates.
    
[^134]: LlamBERT：在自然语言处理中大规模、低成本的数据注释

    LlamBERT: Large-scale low-cost data annotation in NLP

    [https://arxiv.org/abs/2403.15938](https://arxiv.org/abs/2403.15938)

    LlamBERT是一种利用大规模语言模型注释未标记数据库并用于微调变压器编码器的混合方法，在降低成本的同时略微牺牲准确性。

    

    大型语言模型(LLMs)，如GPT-4和Llama 2，在各种自然语言处理(NLP)任务中表现出卓越的能力。尽管它们非常有效，但与它们的使用相关的高成本带来了挑战。我们提出了LlamBERT，这是一种混合方法，利用LLMs对大量未标记数据库的小子集进行注释，并将结果用于微调类似BERT和RoBERTa的变压器编码器。这一策略在两个不同的数据集上进行了评估：IMDb影评数据集和UMLS Meta-Thesaurus。我们的结果表明，LlamBERT方法在稍微牺牲准确性的同时，提供了更高的成本效益。

    arXiv:2403.15938v1 Announce Type: cross  Abstract: Large Language Models (LLMs), such as GPT-4 and Llama 2, show remarkable proficiency in a wide range of natural language processing (NLP) tasks. Despite their effectiveness, the high costs associated with their use pose a challenge. We present LlamBERT, a hybrid approach that leverages LLMs to annotate a small subset of large, unlabeled databases and uses the results for fine-tuning transformer encoders like BERT and RoBERTa. This strategy is evaluated on two diverse datasets: the IMDb review dataset and the UMLS Meta-Thesaurus. Our results indicate that the LlamBERT approach slightly compromises on accuracy while offering much greater cost-effectiveness.
    
[^135]: 理解马尔科夫逻辑网络中的域大小泛化

    Understanding Domain-Size Generalization in Markov Logic Networks

    [https://arxiv.org/abs/2403.15933](https://arxiv.org/abs/2403.15933)

    本文量化了马尔科夫逻辑网络在不同大小领域间内部一致性缺失的问题，并提出最大化数据对数似然同时最小化参数方差的方式来优化领域大小泛化。

    

    我们研究了马尔科夫逻辑网络（MLNs）在不同大小的关系结构之间的泛化行为。多个研究注意到，在给定域上学习的MLNs在不同大小的域上泛化很差。这种行为源于MLN在不同域大小上使用时的内部一致性缺失。在本文中，我们量化了这种不一致性，并将其限制在MLN参数的方差范围内。参数方差还限制了从不同域大小中取出的MLN边缘分布之间的KL散度。我们利用这些界限展示，最大化数据对数似然同时最小化参数方差，对应于域大小泛化的两个自然概念。我们的理论结果适用于指数随机图和其他基于马尔科夫网络的关系模型。最后，我们观察到已知的解决方案会减少方差

    arXiv:2403.15933v1 Announce Type: new  Abstract: We study the generalization behavior of Markov Logic Networks (MLNs) across relational structures of different sizes. Multiple works have noticed that MLNs learned on a given domain generalize poorly across domains of different sizes. This behavior emerges from a lack of internal consistency within an MLN when used across different domain sizes. In this paper, we quantify this inconsistency and bound it in terms of the variance of the MLN parameters. The parameter variance also bounds the KL divergence between an MLN's marginal distributions taken from different domain sizes. We use these bounds to show that maximizing the data log-likelihood while simultaneously minimizing the parameter variance corresponds to two natural notions of generalization across domain sizes. Our theoretical results apply to Exponential Random Graphs and other Markov network based relational models. Finally, we observe that solutions known to decrease the varia
    
[^136]: X-Portrait: 具有分层动作注意力的表现性肖像动画

    X-Portrait: Expressive Portrait Animation with Hierarchical Motion Attention

    [https://arxiv.org/abs/2403.15931](https://arxiv.org/abs/2403.15931)

    这里是中文总结出的一句话要点: 该论文提出了X-Portrait，一种用于生成具有表现力和时间连贯性的肖像动画的条件扩散模型，利用控制信号实现了细粒度头部姿势和表情控制，以提高运动精度。

    

    我们提出了X-Portrait，这是一种创新的条件扩散模型，专门用于生成具有表现力和时间连贯性的肖像动画。具体而言，我们旨在基于单个肖像作为外观参考，并利用来自驱动视频的运动来为其添加动画，捕捉具有高度动态性和微妙面部表情以及广泛范围头部运动。在其核心部分，我们利用了预先训练的扩散模型的生成先验作为渲染骨架，同时在ControlNet框架内通过新颖的控制信号实现了细粒度头部姿势和表情控制。与传统的粗糙显式控制（如面部标志点）不同，我们的运动控制模块学会直接从原始驱动RGB输入中解读动态。通过有效增强对眼神等小尺度细微差异的运动关注的基于补丁的局部控制模块，进一步提高了运动精度。

    arXiv:2403.15931v1 Announce Type: cross  Abstract: We propose X-Portrait, an innovative conditional diffusion model tailored for generating expressive and temporally coherent portrait animation. Specifically, given a single portrait as appearance reference, we aim to animate it with motion derived from a driving video, capturing both highly dynamic and subtle facial expressions along with wide-range head movements. As its core, we leverage the generative prior of a pre-trained diffusion model as the rendering backbone, while achieve fine-grained head pose and expression control with novel controlling signals within the framework of ControlNet. In contrast to conventional coarse explicit controls such as facial landmarks, our motion control module is learned to interpret the dynamics directly from the original driving RGB inputs. The motion accuracy is further enhanced with a patch-based local control module that effectively enhance the motion attention to small-scale nuances like eyeba
    
[^137]: 多智能体变压器加速RL以满足STL规范

    Multi-agent transformer-accelerated RL for satisfaction of STL specifications

    [https://arxiv.org/abs/2403.15916](https://arxiv.org/abs/2403.15916)

    提出了一种使用时间相关多智能体变压器的方法，能够通过集中式方法高效解决多智能体问题，在两个问题上展现出明显优于基线算法的性能。

    

    多智能体强化学习中的主要挑战之一是随着智能体数量增加，可扩展性变差。如果考虑的问题是时间相关的，则这个问题会进一步恶化。当今最先进的解决方案主要遵循集中式训练与分布式执行的范式，以处理可扩展性问题。在本文中，我们提出了一种可以通过高效处理大输入的变压器来有效解决时间相关多智能体问题的方法。我们强调了该方法在两个问题上的有效性，并使用统计工具验证了在策略下生成的轨迹满足任务的概率。实验结果表明，我们的方法在两种情况下均优于文献基线算法。

    arXiv:2403.15916v1 Announce Type: new  Abstract: One of the main challenges in multi-agent reinforcement learning is scalability as the number of agents increases. This issue is further exacerbated if the problem considered is temporally dependent. State-of-the-art solutions today mainly follow centralized training with decentralized execution paradigm in order to handle the scalability concerns. In this paper, we propose time-dependent multi-agent transformers which can solve the temporally dependent multi-agent problem efficiently with a centralized approach via the use of transformers that proficiently handle the large input. We highlight the efficacy of this method on two problems and use tools from statistics to verify the probability that the trajectories generated under the policy satisfy the task. The experiments show that our approach has superior performance against the literature baseline algorithms in both cases.
    
[^138]: 通过参考图像匹配实现更好的分割：MatchSeg

    MatchSeg: Towards Better Segmentation via Reference Image Matching

    [https://arxiv.org/abs/2403.15901](https://arxiv.org/abs/2403.15901)

    通过引入MatchSeg框架，利用对比语言-图像预训练和联合注意力模块增强了医学图像分割，有效实现了支持集和查询集之间的知识转移。

    

    最近，基于深度学习的自动医学图像分割方法取得了巨大成功。然而，它们严重依赖于大量的标注数据集，而获取这些数据集的成本高昂且耗时。Few-shot learning旨在通过使用一个小型标记数据集（称为支持集）来指导预测新的、未标记图像（称为查询集）的标签，从而克服对标注数据的需求。受到这一范式的启发，我们引入了MatchSeg，这是一个通过战略性参考图像匹配增强医学图像分割的新框架。我们利用对比语言-图像预训练（CLIP）在定义支持集时选择高度相关的样本。此外，我们设计了联合注意力模块来加强支持和查询特征之间的交互，促进更有效的知识转移。我们在四个公共数据集上验证了我们的方法。

    arXiv:2403.15901v1 Announce Type: new  Abstract: Recently, automated medical image segmentation methods based on deep learning have achieved great success. However, they heavily rely on large annotated datasets, which are costly and time-consuming to acquire. Few-shot learning aims to overcome the need for annotated data by using a small labeled dataset, known as a support set, to guide predicting labels for new, unlabeled images, known as the query set. Inspired by this paradigm, we introduce MatchSeg, a novel framework that enhances medical image segmentation through strategic reference image matching. We leverage contrastive language-image pre-training (CLIP) to select highly relevant samples when defining the support set. Additionally, we design a joint attention module to strengthen the interaction between support and query features, facilitating a more effective knowledge transfer between support and query sets. We validated our method across four public datasets. Experimental re
    
[^139]: 利用零-shot提示实现高效语言模型蒸馏

    Leveraging Zero-Shot Prompting for Efficient Language Model Distillation

    [https://arxiv.org/abs/2403.15886](https://arxiv.org/abs/2403.15886)

    通过利用零-shot提示来引出教师模型的理由，减少手工制作的少-shot示例的必要性，并降低所需的总记号数，这直接转化为成本节约。

    

    本文介绍了一种新颖的方法，用于将LLMs高效地蒸馏为更小、特定于应用的模型，显著降低运营成本和人工劳动。该技术利用LLMs的推理能力为未标记数据生成标签和自然语言理由，以解决将计算密集型LLMs部署到特定应用或边缘设备的挑战。我们的方法通过采用多任务训练框架，其中学生模型模仿这些理由以及教师模型的预测，来增强微调和蒸馏。关键贡献包括利用零-shot提示来引出教师模型的理由，减少手工制作的少-shot示例的必要性，并降低所需的总记号数，这直接转化为成本节约，考虑到主要技术公司LLM APIs的按记号计费模型。此外，本文还调查了影响

    arXiv:2403.15886v1 Announce Type: cross  Abstract: This paper introduces a novel approach for efficiently distilling LLMs into smaller, application-specific models, significantly reducing operational costs and manual labor. Addressing the challenge of deploying computationally intensive LLMs in specific applications or edge devices, this technique utilizes LLMs' reasoning capabilities to generate labels and natural language rationales for unlabeled data. Our approach enhances both finetuning and distillation by employing a multi-task training framework where student models mimic these rationales alongside teacher predictions. Key contributions include the employment of zero-shot prompting to elicit teacher model rationales, reducing the necessity for handcrafted few-shot examples and lowering the overall token count required, which directly translates to cost savings given the pay-per-token billing model of major tech companies' LLM APIs. Additionally, the paper investigates the impact
    
[^140]: TrustSQL: 用于具有多样无法回答问题的文本到SQL模型的可靠性基准

    TrustSQL: A Reliability Benchmark for Text-to-SQL Models with Diverse Unanswerable Questions

    [https://arxiv.org/abs/2403.15879](https://arxiv.org/abs/2403.15879)

    TrustSQL是一个旨在评估文本到SQL模型在处理各种类型问题时的可靠性的新基准，要求模型在SQL预测和放弃预测两种情况下进行评估。

    

    最近大型语言模型（LLMs）的进展显著提高了将自然语言问题翻译成SQL查询的准确性。在SQL生成的准确性至关重要的同时，很少有人了解这些文本到SQL模型在真实世界部署过程中能否可靠处理各种类型的问题，包括无法回答的问题。为了探讨这一方面，我们提出了TrustSQL，这是一个新的基准，旨在评估文本到SQL模型在单一数据库和跨数据库设置中的可靠性。基准任务要求模型提供两种结果之一：1）SQL预测；或2）在生成的SQL中可能存在错误或面临无法回答的问题时放弃预测。为了评估模型，我们探讨了专门为这一任务设计的各种建模方法，包括：1）为可回答性优化单独的模型

    arXiv:2403.15879v1 Announce Type: new  Abstract: Recent advances in large language models (LLMs) have led to significant improvements in translating natural language questions into SQL queries. While achieving high accuracy in SQL generation is crucial, little is known about the extent to which these text-to-SQL models can reliably handle diverse types of questions encountered during real-world deployment, including unanswerable ones. To explore this aspect, we present TrustSQL, a new benchmark designed to assess the reliability of text-to-SQL models in both single-database and cross-database settings. The benchmark tasks models with providing one of two outcomes: 1) SQL prediction; or 2) abstention from making a prediction, either when there is a potential error in the generated SQL or when faced with unanswerable questions. For model evaluation, we explore various modeling approaches specifically designed for this task. These include: 1) optimizing separate models for answerability d
    
[^141]: 认知韧性：揭示图像字幕模型解释遮蔽视觉内容的熟练度

    Cognitive resilience: Unraveling the proficiency of image-captioning models to interpret masked visual content

    [https://arxiv.org/abs/2403.15876](https://arxiv.org/abs/2403.15876)

    该研究发现图像字幕模型在解释遮蔽的视觉内容时表现出很强的能力，即使部分区域被遮蔽，模型仍能准确生成描述性的文本信息。

    

    这项研究探讨了图像字幕（IC）模型解码来自不同数据集的遮蔽视觉内容的能力。我们的发现揭示了IC模型能够从遮蔽图像生成字幕，这些字幕与原始内容非常相似。值得注意的是，即使存在遮罩，该模型仍能熟练地生成超越原始图像可观察范围的描述性文本信息。虽然IC模型的解码性能随着遮蔽区域面积增加而下降，但在重要区域未被高度遮蔽时，模型仍能表现良好。

    arXiv:2403.15876v1 Announce Type: cross  Abstract: This study explores the ability of Image Captioning (IC) models to decode masked visual content sourced from diverse datasets. Our findings reveal the IC model's capability to generate captions from masked images, closely resembling the original content. Notably, even in the presence of masks, the model adeptly crafts descriptive textual information that goes beyond what is observable in the original image-generated captions. While the decoding performance of the IC model experiences a decline with an increase in the masked region's area, the model still performs well when important regions of the image are not masked at high coverage.
    
[^142]: LAMPER：用于零样本时间序列分类的语言模型和提示工程

    LAMPER: LanguAge Model and Prompt EngineeRing for zero-shot time series classification

    [https://arxiv.org/abs/2403.15875](https://arxiv.org/abs/2403.15875)

    LAMPER框架旨在评估预训练语言模型在零样本时间序列分类中的适应能力，研究发现其特征表示能力受到PLMs最大输入标记阈值的影响。

    

    这项研究构建了LanguAge模型和Prompt EngineeRing（LAMPER）框架，旨在系统评估预训练语言模型（PLMs）在容纳多样提示及其在零样本时间序列（TS）分类中的整合能力。我们在实验评估中部署LAMPER，使用了来源于UCR存档的128个单变量TS数据集。我们的发现表明，LAMPER的特征表示能力受到PLMs强加的最大输入标记阈值的影响。

    arXiv:2403.15875v1 Announce Type: new  Abstract: This study constructs the LanguAge Model with Prompt EngineeRing (LAMPER) framework, designed to systematically evaluate the adaptability of pre-trained language models (PLMs) in accommodating diverse prompts and their integration in zero-shot time series (TS) classification. We deploy LAMPER in experimental assessments using 128 univariate TS datasets sourced from the UCR archive. Our findings indicate that the feature representation capacity of LAMPER is influenced by the maximum input token threshold imposed by PLMs.
    
[^143]: 利用大型语言模型对基于OntoClean的本体重构进行研究

    Using Large Language Models for OntoClean-based Ontology Refinement

    [https://arxiv.org/abs/2403.15864](https://arxiv.org/abs/2403.15864)

    本文研究了利用大型语言模型（LLMs）如GPT-3.5和GPT-4来增强OntoClean方法论中的本体重构过程，通过两种提示策略展示了高标记准确性，提出了为本体工具开发插件软件以促进整合的潜力。

    

    本文探讨了将GPT-3.5和GPT-4等大型语言模型（LLMs）整合到本体重构过程中的方法，重点关注OntoClean方法论。OntoClean对评估本体的形而上质量至关重要，涉及将元属性分配给类别的两步过程和验证一组约束条件。手动完成第一步在实践中很困难，因为需要哲学专业知识和本体论者之间缺乏共识。通过采用两种提示策略的LLMs，研究表明可以实现高准确率的标记过程。研究结果表明LLMs有提升本体重构的潜力，提出开发本体工具的插件软件以促进这种整合。

    arXiv:2403.15864v1 Announce Type: new  Abstract: This paper explores the integration of Large Language Models (LLMs) such as GPT-3.5 and GPT-4 into the ontology refinement process, specifically focusing on the OntoClean methodology. OntoClean, critical for assessing the metaphysical quality of ontologies, involves a two-step process of assigning meta-properties to classes and verifying a set of constraints. Manually conducting the first step proves difficult in practice, due to the need for philosophical expertise and lack of consensus among ontologists. By employing LLMs with two prompting strategies, the study demonstrates that high accuracy in the labelling process can be achieved. The findings suggest the potential for LLMs to enhance ontology refinement, proposing the development of plugin software for ontology tools to facilitate this integration.
    
[^144]: 无人机系统级测试的自动化系统

    Automated System-level Testing of Unmanned Aerial Systems

    [https://arxiv.org/abs/2403.15857](https://arxiv.org/abs/2403.15857)

    本文提出了一种利用模型测试和人工智能技术自动生成、执行和评估无人机系统级测试的新颖方法。

    

    无人机系统依赖于各种安全关键和任务关键的航空电子系统。国际安全标准的主要要求之一是对航空电子软件系统进行严格的系统级测试。当前工业实践是手动创建测试方案，使用模拟器手动/自动执行这些方案，并手动评估结果。本文提出了一种新颖的方法来自动化无人机系统级测试。所提出的方法(AITester)利用基于模型的测试和人工智能(AI)技术，自动生成、执行和评估各种测试方案。

    arXiv:2403.15857v1 Announce Type: cross  Abstract: Unmanned aerial systems (UAS) rely on various avionics systems that are safety-critical and mission-critical. A major requirement of international safety standards is to perform rigorous system-level testing of avionics software systems. The current industrial practice is to manually create test scenarios, manually/automatically execute these scenarios using simulators, and manually evaluate outcomes. The test scenarios typically consist of setting certain flight or environment conditions and testing the system under test in these settings. The state-of-the-art approaches for this purpose also require manual test scenario development and evaluation. In this paper, we propose a novel approach to automate the system-level testing of the UAS. The proposed approach (AITester) utilizes model-based testing and artificial intelligence (AI) techniques to automatically generate, execute, and evaluate various test scenarios. The test scenarios a
    
[^145]: 初始值和拓扑结构在分散式联邦学习中的影响

    Initialisation and Topology Effects in Decentralised Federated Learning

    [https://arxiv.org/abs/2403.15855](https://arxiv.org/abs/2403.15855)

    分散式联邦学习的有效性受到连接设备网络拓扑结构的显著影响，我们提出了基于底层网络节点特征向量中心性分布的改进神经网络初始化策略，大大提高了训练效率。

    

    具有完全分散式特征的联邦学习使得在网络上分布式设备上对个体机器学习模型进行协作训练，同时保持训练数据本地化。这种方法增强了数据隐私性，消除了单点故障和中央协调的必要性。我们的研究强调了分散式联邦学习的有效性受到连接设备的网络拓扑结构的显著影响。一个简化的数值模型用于研究这些系统的早期行为，使我们得出了一个利用底层网络节点的特征向量中心性分布的改进人工神经网络初始值策略，从而大大提高了训练效率。此外，我们的研究探讨了在我们提出的初始化策略下的比例行为和环境参数的选择。这项工作为更多研究打开了道路。

    arXiv:2403.15855v1 Announce Type: cross  Abstract: Fully decentralised federated learning enables collaborative training of individual machine learning models on distributed devices on a network while keeping the training data localised. This approach enhances data privacy and eliminates both the single point of failure and the necessity for central coordination. Our research highlights that the effectiveness of decentralised federated learning is significantly influenced by the network topology of connected devices. A simplified numerical model for studying the early behaviour of these systems leads us to an improved artificial neural network initialisation strategy, which leverages the distribution of eigenvector centralities of the nodes of the underlying network, leading to a radically improved training efficiency. Additionally, our study explores the scaling behaviour and choice of environmental parameters under our proposed initialisation strategy. This work paves the way for mor
    
[^146]: 当基于LLM的代码生成遇上软件开发流程

    When LLM-based Code Generation Meets the Software Development Process

    [https://arxiv.org/abs/2403.15852](https://arxiv.org/abs/2403.15852)

    该研究引入了基于LLM的代码生成框架LCG，通过模拟各种软件过程模型以及利用协作和技术提高代码质量。评估结果表明其在代码生成基准上的有效性。

    

    软件过程模型在促进软件团队内协作与沟通，使其能够有效应对复杂的开发任务方面担当着关键角色。本文介绍了LCG，这是一个受到成熟软件工程实践启发的代码生成框架。LCG利用多个大型语言模型(LLM)代理来模拟各种软件过程模型，即LCGWaterfall、LCGTDD和LCGScrum。每个模型为LLM代理分配特定角色，如需求工程师、架构师、开发人员、测试人员和Scrum Master，反映了典型的开发活动和沟通模式。通过利用思维链和提示组合技术进行协作，代理不断完善自身以提高代码质量。在GPT3.5作为基础LLM和基准(GPT)的情况下，我们评估了LCG在四个代码生成基准测试上的表现：HumanEval、HumanEval-ET、MBPP和MBPP-ET。

    arXiv:2403.15852v1 Announce Type: cross  Abstract: Software process models play a pivotal role in fostering collaboration and communication within software teams, enabling them to tackle intricate development tasks effectively. This paper introduces LCG, a code generation framework inspired by established software engineering practices. LCG leverages multiple Large Language Model (LLM) agents to emulate various software process models, namely LCGWaterfall, LCGTDD, and LCGScrum. Each model assigns LLM agents specific roles such as requirement engineer, architect, developer, tester, and scrum master, mirroring typical development activities and communication patterns. Through collaborative efforts utilizing chain-of-thought and prompt composition techniques, the agents continuously refine themselves to enhance code quality. Utilizing GPT3.5 as the underlying LLM and baseline (GPT), we evaluate LCG across four code generation benchmarks: HumanEval, HumanEval-ET, MBPP, and MBPP-ET. Results
    
[^147]: ARO：大型语言模型监督机器人文本到技能自主学习

    ARO: Large Language Model Supervised Robotics Text2Skill Autonomous Learning

    [https://arxiv.org/abs/2403.15834](https://arxiv.org/abs/2403.15834)

    ARO框架旨在通过大型语言模型实现机器人技能的自主学习，使其能够在无需人类干预的情况下完成部分任务，同时还分析了该方法的局限性。

    

    机器人学习高度依赖于人类专业知识和努力，如演示，强化学习中奖励函数的设计，使用人类反馈进行性能评估等。然而，依赖人类协助可能导致昂贵的学习成本，并使技能学习难以扩展。在这项工作中，我们介绍了大型语言模型监督机器人文本到技能自主学习（ARO）框架，旨在用包含奖励函数设计和性能评估的大规模语言模型取代机器人技能学习过程中的人类参与。我们提供证据表明，我们的方法实现了完全自主的机器人技能学习，能够在无需人类干预的情况下完成部分任务。此外，我们还分析了该方法在任务理解和优化稳定性方面的局限性。

    arXiv:2403.15834v1 Announce Type: cross  Abstract: Robotics learning highly relies on human expertise and efforts, such as demonstrations, design of reward functions in reinforcement learning, performance evaluation using human feedback, etc. However, reliance on human assistance can lead to expensive learning costs and make skill learning difficult to scale. In this work, we introduce the Large Language Model Supervised Robotics Text2Skill Autonomous Learning (ARO) framework, which aims to replace human participation in the robot skill learning process with large-scale language models that incorporate reward function design and performance evaluation. We provide evidence that our approach enables fully autonomous robot skill learning, capable of completing partial tasks without human intervention. Furthermore, we also analyze the limitations of this approach in task understanding and optimization stability.
    
[^148]: 通过Dropout对时间任务进行比例学习的策略优化扩展

    Scaling Learning based Policy Optimization for Temporal Tasks via Dropout

    [https://arxiv.org/abs/2403.15826](https://arxiv.org/abs/2403.15826)

    本文介绍了一种基于模型的方法用于训练在高度非线性环境中运行的自主智能体的反馈控制器，通过对任务进行形式化表述，实现对特定任务目标的定量满足语义，并利用前馈神经网络学习反馈控制器。

    

    本文介绍了一种基于模型的方法，用于训练在高度非线性环境中运行的自主智能体的反馈控制器。我们希望经过训练的策略能够确保该智能体满足特定的任务目标，这些目标以离散时间信号时间逻辑（DT-STL）表示。通过将任务重新表述为形式化框架（如DT-STL），一个优势是允许定量满足语义。换句话说，给定一个轨迹和一个DT-STL公式，我们可以计算鲁棒性，这可以解释为轨迹与满足该公式的轨迹集之间的近似有符号距离。我们利用反馈控制器，并假设使用前馈神经网络来学习这些反馈控制器。我们展示了这个学习问题与训练递归神经网络（RNNs）类似的地方，其中递归单元的数量与智能体的时间视野成比例。

    arXiv:2403.15826v1 Announce Type: cross  Abstract: This paper introduces a model-based approach for training feedback controllers for an autonomous agent operating in a highly nonlinear environment. We desire the trained policy to ensure that the agent satisfies specific task objectives, expressed in discrete-time Signal Temporal Logic (DT-STL). One advantage for reformulation of a task via formal frameworks, like DT-STL, is that it permits quantitative satisfaction semantics. In other words, given a trajectory and a DT-STL formula, we can compute the robustness, which can be interpreted as an approximate signed distance between the trajectory and the set of trajectories satisfying the formula. We utilize feedback controllers, and we assume a feed forward neural network for learning these feedback controllers. We show how this learning problem is similar to training recurrent neural networks (RNNs), where the number of recurrent units is proportional to the temporal horizon of the agen
    
[^149]: 基于碳排放强度的深度神经网络自适应推断

    Carbon Intensity-Aware Adaptive Inference of DNNs

    [https://arxiv.org/abs/2403.15824](https://arxiv.org/abs/2403.15824)

    通过基于碳排放强度的自适应模型选择，本研究提出的方法能够在低碳强度时段使用更高准确性的模型，在高碳强度时段使用更低准确性的模型，有效改善视觉识别服务的准确性，最多提高碳排放效率达80%。

    

    DNN推断以其巨大的能耗及由此产生的高碳足迹而闻名，通过根据一天中碳排放强度的变化调整模型大小和准确性，可以使其更加可持续。我们的启发式算法在低强度时段使用更大、更高准确性的模型，在高强度时段使用更小、更低准确性的模型。我们还引入了一个指标，即碳排放效率，以量化自适应模型选择在碳足迹方面的有效性。评估结果表明，所提出的方法能够将视觉识别服务的准确性提升高达80%以上。

    arXiv:2403.15824v1 Announce Type: cross  Abstract: DNN inference, known for its significant energy consumption and the resulting high carbon footprint, can be made more sustainable by adapting model size and accuracy to the varying carbon intensity throughout the day. Our heuristic algorithm uses larger, high-accuracy models during low-intensity periods and smaller, lower-accuracy ones during high-intensity periods. We also introduce a metric, carbon-emission efficiency, which quantitatively measures the efficacy of adaptive model selection in terms of carbon footprint. The evaluation showed that the proposed approach could improve the carbon emission efficiency in improving the accuracy of vision recognition services by up to 80%.
    
[^150]: 进化计算对机器人设计的影响：一个基于欠驱动手外骨骼的案例研究

    The Impact of Evolutionary Computation on Robotic Design: A Case Study with an Underactuated Hand Exoskeleton

    [https://arxiv.org/abs/2403.15812](https://arxiv.org/abs/2403.15812)

    本研究探讨了进化计算方法在机器人设计优化中的潜力，并通过欠驱动手外骨骼案例研究展示，进化计算方法相较于蛮力方法，能够在更短时间内获得更精确和更优化的解决方案，从而提高设计的优化。

    

    机器人外骨骼可以增强人体力量，帮助患有肢体残疾的人。然而，设计这些外骨骼以确保安全和最佳性能存在重大挑战。开发外骨骼应该整合特定的优化算法来找到最佳设计。本研究探讨了进化计算（EC）方法在机器人设计优化中的潜力，以欠驱动手外骨骼（U-HEx）作为案例研究。我们提出通过集成遗传算法和大爆炸-大兼并算法等EC技术来改进U-HEx设计的性能和可用性，该设计最初使用天真的蛮力方法进行优化。比较分析显示，EC方法始终比蛮力方法在明显更短的时间内产生更精确和更优化的解决方案。这使我们能够通过增加设计中的变量数量来改进优化。

    arXiv:2403.15812v1 Announce Type: cross  Abstract: Robotic exoskeletons can enhance human strength and aid people with physical disabilities. However, designing them to ensure safety and optimal performance presents significant challenges. Developing exoskeletons should incorporate specific optimization algorithms to find the best design. This study investigates the potential of Evolutionary Computation (EC) methods in robotic design optimization, with an underactuated hand exoskeleton (U-HEx) used as a case study. We propose improving the performance and usability of the U-HEx design, which was initially optimized using a naive brute-force approach, by integrating EC techniques such as Genetic Algorithm and Big Bang-Big Crunch Algorithm. Comparative analysis revealed that EC methods consistently yield more precise and optimal solutions than brute force in a significantly shorter time. This allowed us to improve the optimization by increasing the number of variables in the design, whic
    
[^151]: 高效的混合向量-关系搜索数据访问路径

    Efficient Data Access Paths for Mixed Vector-Relational Search

    [https://arxiv.org/abs/2403.15807](https://arxiv.org/abs/2403.15807)

    提出了针对高效混合向量-关系搜索的替代数据访问路径设计和优化方法。

    

    机器学习能力的快速增长以及使用向量嵌入进行数据处理方法的采用引发了对创建向量数据管理系统的极大兴趣。本文重新评估精确但穷尽的扫描式搜索，并提出硬件优化和替代张量式公式化和批处理以抵消成本。我们概述复杂的访问路径设计空间，主要由关系选择性驱动，以及考虑的决策。

    arXiv:2403.15807v1 Announce Type: cross  Abstract: The rapid growth of machine learning capabilities and the adoption of data processing methods using vector embeddings sparked a great interest in creating systems for vector data management. While the predominant approach of vector data management is to use specialized index structures for fast search over the entirety of the vector embeddings, once combined with other (meta)data, the search queries can also become selective on relational attributes - typical for analytical queries. As using vector indexes differs from traditional relational data access, we revisit and analyze alternative access paths for efficient mixed vector-relational search.   We first evaluate the accurate but exhaustive scan-based search and propose hardware optimizations and alternative tensor-based formulation and batching to offset the cost. We outline the complex access-path design space, primarily driven by relational selectivity, and the decisions to consi
    
[^152]: 从损失角度理解语言模型的突现能力

    Understanding Emergent Abilities of Language Models from the Loss Perspective

    [https://arxiv.org/abs/2403.15796](https://arxiv.org/abs/2403.15796)

    本文从损失角度重新定义了语言模型的突现能力，发现具有相同预训练损失的模型在不同任务上表现相似，而当预训练损失低于特定阈值时，模型将展现出突现能力。

    

    近期研究质疑了传统认为语言模型的突现能力仅存在于大模型中的观点。这种怀疑源自两点观察：1）较小的模型也能展现出对突现能力的高性能；2）质疑用于测量这些能力的不连续性指标。本文提议从预训练损失的角度研究突现能力，而非模型大小或训练计算。我们展示了具有相同预训练损失但不同模型和数据大小的模型，在各种下游任务上表现相同。我们还发现，当某一模型的预训练损失低于特定阈值时，在某些任务上表现出突现能力，而不论指标的连续性如何；而在达到该阈值之前，其性能仍保持在随机猜测水平。这启发我们重新定义突现能力为那些......

    arXiv:2403.15796v1 Announce Type: cross  Abstract: Recent studies have put into question the belief that emergent abilities in language models are exclusive to large models. This skepticism arises from two observations: 1) smaller models can also exhibit high performance on emergent abilities and 2) there is doubt on the discontinuous metrics used to measure these abilities. In this paper, we propose to study emergent abilities in the lens of pre-training loss, instead of model size or training compute. We demonstrate that the models with the same pre-training loss, but different model and data sizes, generate the same performance on various downstream tasks. We also discover that a model exhibits emergent abilities on certain tasks -- regardless of the continuity of metrics -- when its pre-training loss falls below a specific threshold. Before reaching this threshold, its performance remains at the level of random guessing. This inspires us to redefine emergent abilities as those that
    
[^153]: 数据消除的前沿：大型语言模型的机器遗忘

    The Frontier of Data Erasure: Machine Unlearning for Large Language Models

    [https://arxiv.org/abs/2403.15779](https://arxiv.org/abs/2403.15779)

    本文回顾了针对大型语言模型的机器遗忘的最新进展，提出了解决隐私、道德和法律挑战的针对性遗忘信息的方法，而不需要进行完整模型重新训练，并展示了这些方法在保持模型有效性的同时删除特定数据的有效性。

    

    大型语言模型(LLMs)是人工智能进步的基础，推动了诸如预测文本生成之类的应用。然而，它们可能会通过潜在地记忆和传播来自庞大数据集的敏感、偏见或受版权保护的信息，因此存在风险。机器遗忘作为一个前沿解决方案应运而生，提供了供LLMs有选择性地丢弃某些数据的技术。本文回顾了针对LLMs的机器遗忘的最新进展，介绍了用于有针对性地遗忘信息以解决隐私、道德和法律挑战的方法，而不需要进行完整模型重新训练。它将现有研究分为来自非结构化/文本数据和结构化/分类数据的遗忘，展示了这些方法在删除特定数据的同时保持模型有效性的有效性。强调机器遗忘的实用性，本分析还指出了其中的障碍。

    arXiv:2403.15779v1 Announce Type: new  Abstract: Large Language Models (LLMs) are foundational to AI advancements, facilitating applications like predictive text generation. Nonetheless, they pose risks by potentially memorizing and disseminating sensitive, biased, or copyrighted information from their vast datasets. Machine unlearning emerges as a cutting-edge solution to mitigate these concerns, offering techniques for LLMs to selectively discard certain data. This paper reviews the latest in machine unlearning for LLMs, introducing methods for the targeted forgetting of information to address privacy, ethical, and legal challenges without necessitating full model retraining. It divides existing research into unlearning from unstructured/textual data and structured/classification data, showcasing the effectiveness of these approaches in removing specific data while maintaining model efficacy. Highlighting the practicality of machine unlearning, this analysis also points out the hurdl
    
[^154]: 为高质量标题生成建模统一语义话语结构

    Modeling Unified Semantic Discourse Structure for High-quality Headline Generation

    [https://arxiv.org/abs/2403.15776](https://arxiv.org/abs/2403.15776)

    通过将文档级修辞结构理论（RST）树与句级抽象意义表示（AMR）图结合起来构建S3图，形成统一的语义话语结构，用于标题生成框架中，进一步设计了分层结构修剪机制，提高标题生成的效果。

    

    题为生成旨在用简短、吸引人的标题总结长篇文档，反映主要思想。这需要准确捕捉核心文档语义，由于文本的长度和背景信息丰富，这是具有挑战性的。在这项工作中，我们提出使用统一的语义话语结构(S3)来表示文档语义，通过将文档级修辞结构理论（RST）树与句级抽象意义表示（AMR）图结合起来构建S3图。句子、从句和词汇的分层组合固有地表达了整个文档的语义含义。然后，我们开发了一个标题生成框架，在其中将S3图编码为上下文特征。为了巩固S3图的有效性，我们进一步设计了一个分层结构修剪机制，动态筛选多余和非必要节点。

    arXiv:2403.15776v1 Announce Type: cross  Abstract: Headline generation aims to summarize a long document with a short, catchy title that reflects the main idea. This requires accurately capturing the core document semantics, which is challenging due to the lengthy and background information-rich na ture of the texts. In this work, We propose using a unified semantic discourse structure (S3) to represent document semantics, achieved by combining document-level rhetorical structure theory (RST) trees with sentence-level abstract meaning representation (AMR) graphs to construct S3 graphs. The hierarchical composition of sentence, clause, and word intrinsically characterizes the semantic meaning of the overall document. We then develop a headline generation framework, in which the S3 graphs are encoded as contextual features. To consolidate the efficacy of S3 graphs, we further devise a hierarchical structure pruning mechanism to dynamically screen the redundant and nonessential nodes with
    
[^155]: FusionINN：可逆图像融合用于脑肿瘤监测

    FusionINN: Invertible Image Fusion for Brain Tumor Monitoring

    [https://arxiv.org/abs/2403.15769](https://arxiv.org/abs/2403.15769)

    FusionINN引入了一种新颖的可逆图像融合框架，可以高效生成融合图像，并解开融合过程的逆向分解，保证无损的像素映射。

    

    图像融合通常使用不可逆神经网络将多个源图像合并为单个融合图像。然而，对于临床专家，仅依赖融合图像可能不足以做出诊断决策，因为融合机制混合了来自源图像的特征，从而难以解释潜在的肿瘤病理。我们引入了FusionINN，一种新颖的可逆图像融合框架，能够高效生成融合图像，并通过求解融合过程的逆过程将其分解回源图像。FusionINN通过整合一个正态分布的潜在图像与融合图像一起，以促进分解过程的生成建模，从而保证无损的一对一像素映射。据我们所知，我们是首次研究融合图像的可分解性，这对于生命敏感应用程序尤为关键。

    arXiv:2403.15769v1 Announce Type: cross  Abstract: Image fusion typically employs non-invertible neural networks to merge multiple source images into a single fused image. However, for clinical experts, solely relying on fused images may be insufficient for making diagnostic decisions, as the fusion mechanism blends features from source images, thereby making it difficult to interpret the underlying tumor pathology. We introduce FusionINN, a novel invertible image fusion framework, capable of efficiently generating fused images and also decomposing them back to the source images by solving the inverse of the fusion process. FusionINN guarantees lossless one-to-one pixel mapping by integrating a normally distributed latent image alongside the fused image to facilitate the generative modeling of the decomposition process. To the best of our knowledge, we are the first to investigate the decomposability of fused images, which is particularly crucial for life-sensitive applications such as
    
[^156]: 基于高效神经网络扩散的Bagging深度学习训练（BEND）

    BEND: Bagging Deep Learning Training Based on Efficient Neural Network Diffusion

    [https://arxiv.org/abs/2403.15766](https://arxiv.org/abs/2403.15766)

    本文提出了一种基于神经网络扩散模型的Bagging深度学习训练算法（BEND），有效构建了多个基本分类器，简单而有效。

    

    Bagging通过整合多个基本分类器构建一个强大的单一分类器来降低模型方差，在机器学习领域取得了巨大成功。本文提出了一种基于高效神经网络扩散的Bagging深度学习训练算法（BEND），利用神经网络扩散模型高效构建基本分类器。这种方法简单而有效。

    arXiv:2403.15766v1 Announce Type: cross  Abstract: Bagging has achieved great success in the field of machine learning by integrating multiple base classifiers to build a single strong classifier to reduce model variance. The performance improvement of bagging mainly relies on the number and diversity of base classifiers. However, traditional deep learning model training methods are expensive to train individually and difficult to train multiple models with low similarity in a restricted dataset. Recently, diffusion models, which have been tremendously successful in the fields of imaging and vision, have been found to be effective in generating neural network model weights and biases with diversity. We creatively propose a Bagging deep learning training algorithm based on Efficient Neural network Diffusion (BEND). The originality of BEND comes from the first use of a neural network diffusion model to efficiently build base classifiers for bagging. Our approach is simple but effective, 
    
[^157]: 朝向类人机理解的方向：在视觉丰富文档中进行少样本关系学习

    Towards Human-Like Machine Comprehension: Few-Shot Relational Learning in Visually-Rich Documents

    [https://arxiv.org/abs/2403.15765](https://arxiv.org/abs/2403.15765)

    该研究聚焦于在视觉丰富文档中进行少样本关系学习，引入了基于现有监督基准数据集构建的两个新的少样本基准，提出了一种包含关系二维空间先验和样本矫正的变分方法

    

    关键-值关系在视觉丰富文档（VRDs）中普遍存在，通常在不同的空间区域中呈现，伴随特定的颜色和字体风格。这些非文本线索作为重要指示器，极大增强了人类对这种关系三元组的理解和获取。然而，当前的文档AI方法往往未考虑与视觉和空间特征相关的这些有价值的先验信息，导致性能不佳，特别是在处理有限示例时。为了解决这一限制，我们的研究聚焦于少样本关系学习，具体针对在VRDs中提取关键-值关系三元组。鉴于缺乏适用于这一任务的数据集，我们引入了基于现有监督基准数据集构建的两个新的少样本基准。此外，我们提出了一种包含关系二维空间先验和样本矫正的变分方法

    arXiv:2403.15765v1 Announce Type: cross  Abstract: Key-value relations are prevalent in Visually-Rich Documents (VRDs), often depicted in distinct spatial regions accompanied by specific color and font styles. These non-textual cues serve as important indicators that greatly enhance human comprehension and acquisition of such relation triplets. However, current document AI approaches often fail to consider this valuable prior information related to visual and spatial features, resulting in suboptimal performance, particularly when dealing with limited examples. To address this limitation, our research focuses on few-shot relational learning, specifically targeting the extraction of key-value relation triplets in VRDs. Given the absence of a suitable dataset for this task, we introduce two new few-shot benchmarks built upon existing supervised benchmark datasets. Furthermore, we propose a variational approach that incorporates relational 2D-spatial priors and prototypical rectification 
    
[^158]: 一种用于将服务器端预训练生成器中的知识传输给异构联合学习客户端的上传高效方案

    An Upload-Efficient Scheme for Transferring Knowledge From a Server-Side Pre-trained Generator to Clients in Heterogeneous Federated Learning

    [https://arxiv.org/abs/2403.15760](https://arxiv.org/abs/2403.15760)

    通过将预训练生成器的知识传输给客户端，提出了一种上传高效的联合知识传输方案，成功解决了异构联合学习中的数据和模型异构性问题。

    

    异构联合学习（HtFL）实现了在具有不同模型架构的多个客户端上进行协作学习，同时保护隐私。本文提出了一种新的上传高效的知识传输方案，称为联合知识传输循环（FedKTL），以处理异构联合学习中的知识共享问题。FedKTL可以通过服务器上预训练生成器的推理产生与客户端任务相关的原型图像-向量对。借助这些对，每个客户端都可以通过附加的监督本地任务将来自生成器的预先存在的知识传输到其本地模型。我们在包括CNN和ViT在内的14种模型下，对四个数据集进行了广泛实验证明，我们的上传高效的FedKTL超越了七种最新方法。

    arXiv:2403.15760v1 Announce Type: new  Abstract: Heterogeneous Federated Learning (HtFL) enables collaborative learning on multiple clients with different model architectures while preserving privacy. Despite recent research progress, knowledge sharing in HtFL is still difficult due to data and model heterogeneity. To tackle this issue, we leverage the knowledge stored in pre-trained generators and propose a new upload-efficient knowledge transfer scheme called Federated Knowledge-Transfer Loop (FedKTL). Our FedKTL can produce client-task-related prototypical image-vector pairs via the generator's inference on the server. With these pairs, each client can transfer pre-existing knowledge from the generator to its local model through an additional supervised local task. We conduct extensive experiments on four datasets under two types of data heterogeneity with 14 kinds of models including CNNs and ViTs. Results show that our upload-efficient FedKTL surpasses seven state-of-the-art metho
    
[^159]: 用户端实现

    User-Side Realization

    [https://arxiv.org/abs/2403.15757](https://arxiv.org/abs/2403.15757)

    用户端实现为用户提供了积极的解决方案，通过在用户端运行通用算法来解决常见问题，无需服务提供商改变服务本身。

    

    用户对服务感到不满意。由于服务并非量身定制给用户，因此不满意是自然而然的。问题在于，即使用户感到不满意，他们通常也没有解决不满的手段。用户无法修改服务的源代码，也无法强迫服务提供商进行更改。用户别无选择，只能保持不满意或退出服务。用户端实现通过提供通用算法来处理用户端的常见问题，为解决这一问题提供了积极的解决方案。这些算法在用户端运行，并在不需要服务提供商改变服务本身的情况下解决问题。

    arXiv:2403.15757v1 Announce Type: cross  Abstract: Users are dissatisfied with services. Since the service is not tailor-made for a user, it is natural for dissatisfaction to arise. The problem is, that even if users are dissatisfied, they often do not have the means to resolve their dissatisfaction. The user cannot alter the source code of the service, nor can they force the service provider to change. The user has no choice but to remain dissatisfied or quit the service. User-side realization offers proactive solutions to this problem by providing general algorithms to deal with common problems on the user's side. These algorithms run on the user's side and solve the problems without having the service provider change the service itself.
    
[^160]: 利用大型语言模型进行初步安全风险分析：一个关键任务案例研究

    Leveraging Large Language Models for Preliminary Security Risk Analysis: A Mission-Critical Case Study

    [https://arxiv.org/abs/2403.15756](https://arxiv.org/abs/2403.15756)

    大型语言模型在初步安全风险分析中展现了比人类更快速的信息总结能力，本研究通过案例研究探讨了微调模型在协助从业者进行PSRA方面的实用性。

    

    初步安全风险分析（PSRA）提供了一种快速的方法，用于识别、评估和提出潜在风险在具体情境中的应对措施。在关键任务情境中，及时和迅速的行动是至关重要的，所以对有效PSRA所需的广泛专业知识和大量与文本相关的任务在阻碍快速评估。大型语言模型可以比人类更快速地总结信息，利用微调模型（FTM）在PSRA中的能力尚未被先前的研究所探讨。本文通过案例研究调查FTM在协助从业者进行PSRA中的熟练程度。

    arXiv:2403.15756v1 Announce Type: cross  Abstract: Preliminary security risk analysis (PSRA) provides a quick approach to identify, evaluate and propose remeditation to potential risks in specific scenarios. The extensive expertise required for an effective PSRA and the substantial ammount of textual-related tasks hinder quick assessments in mission-critical contexts, where timely and prompt actions are essential. The speed and accuracy of human experts in PSRA significantly impact response time. A large language model can quickly summarise information in less time than a human. To our knowledge, no prior study has explored the capabilities of fine-tuned models (FTM) in PSRA. Our case study investigates the proficiency of FTM to assist practitioners in PSRA. We manually curated 141 representative samples from over 50 mission-critical analyses archived by the industrial context team in the last five years.We compared the proficiency of the FTM versus seven human experts. Within the indu
    
[^161]: CodeShell技术报告

    CodeShell Technical Report

    [https://arxiv.org/abs/2403.15747](https://arxiv.org/abs/2403.15747)

    CodeShell-Base是一个70亿参数规模的基础模型，在代码理解方面表现出色，并通过集成Grouped-Query Attention和Rotary Positional Embedding等技术形成独特的架构设计。

    

    大型语言模型在人工智能领域取得了重要突破。它们专门设计用于理解和生成编程语言，显著提高了编码开发工作流的效率。本技术报告介绍了CodeShell-Base，这是一个70亿参数规模的基础模型，具有8K上下文长度，在代码理解方面表现出色。通过将Grouped-Query Attention和Rotary Positional Embedding整合到GPT-2中，CodeShell-Base融合了StarCoder和CodeLlama的结构优点，并形成了其独特的架构设计。我们还精心构建了包括类似数据去重、基于困惑度的数据过滤和基于模型的数据过滤在内的全面数据预处理流程。通过这一过程，我们从GitHub中筛选出了1000亿条高质量的预训练数据。凭借这些高质量数据，CodeShell-Base胜过了Co

    arXiv:2403.15747v1 Announce Type: cross  Abstract: Code large language models mark a pivotal breakthrough in artificial intelligence. They are specifically crafted to understand and generate programming languages, significantly boosting the efficiency of coding development workflows. In this technical report, we present CodeShell-Base, a seven billion-parameter foundation model with 8K context length, showcasing exceptional proficiency in code comprehension. By incorporating Grouped-Query Attention and Rotary Positional Embedding into GPT-2, CodeShell-Base integrates the structural merits of StarCoder and CodeLlama and forms its unique architectural design. We then carefully built a comprehensive data pre-processing process, including similar data deduplication, perplexity-based data filtering, and model-based data filtering. Through this process, We have curated 100 billion high-quality pre-training data from GitHub. Benefiting from the high-quality data, CodeShell-Base outperforms Co
    
[^162]: 人工势场与安全滤波器的比较研究

    A Comparative Study of Artificial Potential Fields and Safety Filters

    [https://arxiv.org/abs/2403.15743](https://arxiv.org/abs/2403.15743)

    本文通过将人工势场信息整合到CBF-QP框架中，建立了人工势场与安全滤波器之间的连接，并扩展了CBF-QP安全滤波器的设计以适应更一般的动力学模型，从而提供了一种适用于控制仿射动力学模型的一般APF解决方案。

    

    在本文中，我们展示了由经典运动规划工具设计的控制器，即人工势场（APFs），可以从最近普及的方法中得到：控制屏障函数二次规划（CBF-QP）安全滤波器。通过将APF信息整合到CBF-QP框架中，我们建立了这两种方法之间的桥梁。具体而言，这是通过将有吸引力的势场作为控制李雅普诺夫函数（CLF）来引导名义控制器的设计，然后将排斥性势场作为相互作用CBF（RCBF）来定义一个CBF-QP安全滤波器。基于这种整合，我们将CBF-QP安全滤波器的设计扩展到适应更一般的包含控制仿射结构的动力学模型类。这种扩展产生了一种特殊的CBF-QP安全滤波器和适用于控制仿射动力学模型的一般APF解决方案。

    arXiv:2403.15743v1 Announce Type: cross  Abstract: In this paper, we have demonstrated that the controllers designed by a classical motion planning tool, namely artificial potential fields (APFs), can be derived from a recently prevalent approach: control barrier function quadratic program (CBF-QP) safety filters. By integrating APF information into the CBF-QP framework, we establish a bridge between these two methodologies. Specifically, this is achieved by employing the attractive potential field as a control Lyapunov function (CLF) to guide the design of the nominal controller, and then the repulsive potential field serves as a reciprocal CBF (RCBF) to define a CBF-QP safety filter. Building on this integration, we extend the design of the CBF-QP safety filter to accommodate a more general class of dynamical models featuring a control-affine structure. This extension yields a special CBF-QP safety filter and a general APF solution suitable for control-affine dynamical models. Throug
    
[^163]: 面向电子离子对撞机的基于RAG的摘要生成代理

    Towards a \textbf{RAG}-based Summarization Agent for the Electron-Ion Collider

    [https://arxiv.org/abs/2403.15729](https://arxiv.org/abs/2403.15729)

    开发了一种面向电子离子对撞机的基于RAG的摘要生成代理，能够压缩信息并引用相关回复，为合作者提供重大优势

    

    复杂性和庞大的信息量涵盖了大规模实验的文件、论文、数据和其他资源，导致导航这些多样形式信息的任务需要大量时间和精力，对于新合作者和早期科学家来说尤为艰巨。为了解决这个问题，正在开发一种基于检索增强生成（RAG）的EIC摘要生成人工智能代理（RAGS4EIC）。该人工智能代理不仅压缩信息，还有效引用相关回复，为合作者提供了重大优势。我们的项目采取了两步方法：首先，查询包含所有相关实验信息的综合向量数据库；其次，利用大型语言模型（LLM）根据用户查询和检索数据生成包含引用的简洁摘要。我们描述了使用RAG评估的评估方法

    arXiv:2403.15729v1 Announce Type: cross  Abstract: The complexity and sheer volume of information encompassing documents, papers, data, and other resources from large-scale experiments demand significant time and effort to navigate, making the task of accessing and utilizing these varied forms of information daunting, particularly for new collaborators and early-career scientists. To tackle this issue, a Retrieval Augmented Generation (RAG)--based Summarization AI for EIC (RAGS4EIC) is under development. This AI-Agent not only condenses information but also effectively references relevant responses, offering substantial advantages for collaborators. Our project involves a two-step approach: first, querying a comprehensive vector database containing all pertinent experiment information; second, utilizing a Large Language Model (LLM) to generate concise summaries enriched with citations based on user queries and retrieved data. We describe the evaluation methods that use RAG assessments 
    
[^164]: 可学习的证据协同感知模型的WSN部署

    Learnable WSN Deployment of Evidential Collaborative Sensing Model

    [https://arxiv.org/abs/2403.15728](https://arxiv.org/abs/2403.15728)

    本文提出了一种通过协同感知模型和证据理论框架下的组合规则，来提高WSNs检测能力的学习型传感器部署网络（LSDNet）。

    

    在无线传感器网络（WSNs）中，覆盖和部署是进行检测任务时最关键的两个问题。但通常来自传感器的检测信息并没有被充分利用和高效整合。本文旨在实现WSN部署的最佳覆盖质量，通过开发一种传感器的协同感知模型，利用证据理论框架下的组合规则得到的协同信息来增强WSNs的检测能力。

    arXiv:2403.15728v1 Announce Type: new  Abstract: In wireless sensor networks (WSNs), coverage and deployment are two most crucial issues when conducting detection tasks. However, the detection information collected from sensors is oftentimes not fully utilized and efficiently integrated. Such sensing model and deployment strategy, thereby, cannot reach the maximum quality of coverage, particularly when the amount of sensors within WSNs expands significantly. In this article, we aim at achieving the optimal coverage quality of WSN deployment. We develop a collaborative sensing model of sensors to enhance detection capabilities of WSNs, by leveraging the collaborative information derived from the combination rule under the framework of evidence theory. In this model, the performance evaluation of evidential fusion systems is adopted as the criterion of the sensor selection. A learnable sensor deployment network (LSDNet) considering both sensor contribution and detection capability, is pr
    
[^165]: PEaCE：用于科学文档光学字符识别的化学导向数据集

    PEaCE: A Chemistry-Oriented Dataset for Optical Character Recognition on Scientific Documents

    [https://arxiv.org/abs/2403.15724](https://arxiv.org/abs/2403.15724)

    提出了PEaCE数据集，利用其中的合成和真实记录评估了基于transformer的OCR模型在化学文献中的识别效果，并提出可以模拟真实记录特征的转换。

    

    Optical Character Recognition（OCR）是一个旨在识别图像中存在的文本的既定任务。尽管存在许多现成的OCR模型，但它们通常是针对科学（例如，公式）或通用印刷英文文本进行训练的。从化学出版物中提取文本需要一种能够在这两个领域中进行操作的OCR模型。最近的工具Nougat表现出解析学术文档的强大能力，但无法解析PubMed文章中的表格，这构成了学术界一个重要部分，并且也是本次工作的重点。为了弥补这一差距，我们提出了包含合成和真实记录的Printed English and Chemical Equations（PEaCE）数据集，并评估了当这一资源进行训练时，基于transformer的OCR模型的有效性。鉴于真实记录包含合成记录中不存在的人工制品，我们提出了模仿这些特质的转换。

    arXiv:2403.15724v1 Announce Type: cross  Abstract: Optical Character Recognition (OCR) is an established task with the objective of identifying the text present in an image. While many off-the-shelf OCR models exist, they are often trained for either scientific (e.g., formulae) or generic printed English text. Extracting text from chemistry publications requires an OCR model that is capable in both realms. Nougat, a recent tool, exhibits strong ability to parse academic documents, but is unable to parse tables in PubMed articles, which comprises a significant part of the academic community and is the focus of this work. To mitigate this gap, we present the Printed English and Chemical Equations (PEaCE) dataset, containing both synthetic and real-world records, and evaluate the efficacy of transformer-based OCR models when trained on this resource. Given that real-world records contain artifacts not present in synthetic records, we propose transformations that mimic such qualities. We p
    
[^166]: 基于生物启发神经动力学的移动机器人分布式强化学习编队控制

    Distributed Robust Learning based Formation Control of Mobile Robots based on Bioinspired Neural Dynamics

    [https://arxiv.org/abs/2403.15716](https://arxiv.org/abs/2403.15716)

    本文提出了一种基于生物启发神经动力学的方法，通过引入分布式估计器、运动学跟踪控制和学习鲁棒动态控制器，有效解决了移动机器人分布式编队控制的挑战，并通过数学分析证明了方法的稳定性。

    

    本文解决了多个移动机器人分布式编队控制的挑战，引入了一种增强实际可行性的新方法。首先，采用变结构和级联设计技术引入了一个分布式估计器，消除了对导数信息的需求以提高实时性能。然后，开发了一种运动学跟踪控制方法，利用了基于生物启发神经动力学的方法，旨在提供平滑的控制输入并有效解决速度跳跃问题。此外，为了解决完全未知动态和扰动条件下运行的机器人的挑战，开发了一种基于学习的鲁棒动态控制器。该控制器在保持其对抗扰动性的同时提供了实时参数估计。所提出方法的整体稳定性通过严格的数学分析得到证明。

    arXiv:2403.15716v1 Announce Type: cross  Abstract: This paper addresses the challenges of distributed formation control in multiple mobile robots, introducing a novel approach that enhances real-world practicability. We first introduce a distributed estimator using a variable structure and cascaded design technique, eliminating the need for derivative information to improve the real time performance. Then, a kinematic tracking control method is developed utilizing a bioinspired neural dynamic-based approach aimed at providing smooth control inputs and effectively resolving the speed jump issue. Furthermore, to address the challenges for robots operating with completely unknown dynamics and disturbances, a learning-based robust dynamic controller is developed. This controller provides real time parameter estimates while maintaining its robustness against disturbances. The overall stability of the proposed method is proved with rigorous mathematical analysis. At last, multiple comprehens
    
[^167]: 从文本描述生成考虑接触的人体动作

    Contact-aware Human Motion Generation from Textual Descriptions

    [https://arxiv.org/abs/2403.15709](https://arxiv.org/abs/2403.15709)

    本研究提出了一种新的方法CATMO，通过整合物理接触信息，从文本描述中生成视觉自然且物理合理的3D人体动作。

    

    本文解决了从文本生成3D交互式人体动作的问题。给定描述了不同身体部位接触物体动作的文本描述，我们综合生成视觉自然且物理合理的3D人体姿势序列。然而，这个任务存在一个重要挑战，即在动作和文本描述中对物理接触的互动考虑不足，导致序列不自然且不合理。为了解决这一挑战，我们创建了一个名为RICH-CAT的新数据集，表示从RICH数据集构建的“考虑接触”的文本。RICH-CAT包括高质量动作、准确的人-物接触标签和详细的文本描述，涵盖了26种室内/室外动作的8500多对动作-文本配对。利用RICH-CAT，我们提出了一种名为CATMO的新方法，用于文本驱动的交互式人体动作合成，明确整合了物理接触的信息。

    arXiv:2403.15709v1 Announce Type: cross  Abstract: This paper addresses the problem of generating 3D interactive human motion from text. Given a textual description depicting the actions of different body parts in contact with objects, we synthesize sequences of 3D body poses that are visually natural and physically plausible. Yet, this task poses a significant challenge due to the inadequate consideration of interactions by physical contacts in both motion and textual descriptions, leading to unnatural and implausible sequences. To tackle this challenge, we create a novel dataset named RICH-CAT, representing ``Contact-Aware Texts'' constructed from the RICH dataset. RICH-CAT comprises high-quality motion, accurate human-object contact labels, and detailed textual descriptions, encompassing over 8,500 motion-text pairs across 26 indoor/outdoor actions. Leveraging RICH-CAT, we propose a novel approach named CATMO for text-driven interactive human motion synthesis that explicitly integra
    
[^168]: 地域性和权重共享在基于图像的任务中的作用：CNN、LCN和FCN之间的样本复杂性分离

    Role of Locality and Weight Sharing in Image-Based Tasks: A Sample Complexity Separation between CNNs, LCNs, and FCNs

    [https://arxiv.org/abs/2403.15707](https://arxiv.org/abs/2403.15707)

    介绍了新的Dynamic Signal Distribution (DSD)分类任务，模拟图像由$k$个维度为$d$的补丁组成，以解决CNNs相对于LCNs和FCNs的统计优势问题

    

    视觉任务的特点是地域性和平移不变性。卷积神经网络（CNNs）在这些任务上表现出色，这在很大程度上归因于其架构中固有的地域性和权重共享的归纳偏差。现有的试图量化这些偏差在CNNs上相对于局部连接的卷积神经网络（LCNs）和全连接神经网络（FCNs）的统计优势的尝试可以归为以下几类：要么它们忽视优化器，仅提供具有统一收敛上界但没有分隔下界的统计收敛性，要么考虑到不真实地反映现实世界视觉任务中的地域性和平移不变性的简单任务。为了解决这些不足，我们介绍了动态信号分布（DSD）分类任务，它将图像建模为包含$k$个尺寸为$d$的补丁，标签是de

    arXiv:2403.15707v1 Announce Type: cross  Abstract: Vision tasks are characterized by the properties of locality and translation invariance. The superior performance of convolutional neural networks (CNNs) on these tasks is widely attributed to the inductive bias of locality and weight sharing baked into their architecture. Existing attempts to quantify the statistical benefits of these biases in CNNs over locally connected convolutional neural networks (LCNs) and fully connected neural networks (FCNs) fall into one of the following categories: either they disregard the optimizer and only provide uniform convergence upper bounds with no separating lower bounds, or they consider simplistic tasks that do not truly mirror the locality and translation invariance as found in real-world vision tasks. To address these deficiencies, we introduce the Dynamic Signal Distribution (DSD) classification task that models an image as consisting of $k$ patches, each of dimension $d$, and the label is de
    
[^169]: SceneX：通过大型语言模型进行程序化可控大规模场景生成

    SceneX:Procedural Controllable Large-scale Scene Generation via Large-language Models

    [https://arxiv.org/abs/2403.15698](https://arxiv.org/abs/2403.15698)

    通过大型语言模型驱动程序化建模，提出了一个大规模场景生成框架SceneX，可以自动生成高质量的程序化模型

    

    由于其巨大的应用潜力，大规模场景生成在学术界和工业界引起了广泛关注。最近的研究采用强大的生成模型创建所需的场景，并取得了令人期待的结果。然而，大多数这些方法使用不兼容工业流程的3D基元（如点云或辐射场）来表示场景，这导致学术研究与工业部署之间存在重大差距。程序化可控生成（PCG）是一种高效的技术，可创建可扩展和高质量的资产，但对普通用户不友好，因为它需要深入的领域专业知识。为解决这些问题，我们采用大型语言模型（LLM）驱动程序化建模。在本文中，我们介绍了一个大规模场景生成框架SceneX，可以根据设计师的文本描述自动生成高质量的程序化模型。

    arXiv:2403.15698v1 Announce Type: cross  Abstract: Due to its great application potential, large-scale scene generation has drawn extensive attention in academia and industry. Recent research employs powerful generative models to create desired scenes and achieves promising results. However, most of these methods represent the scene using 3D primitives (e.g. point cloud or radiance field) incompatible with the industrial pipeline, which leads to a substantial gap between academic research and industrial deployment. Procedural Controllable Generation (PCG) is an efficient technique for creating scalable and high-quality assets, but it is unfriendly for ordinary users as it demands profound domain expertise. To address these issues, we resort to using the large language model (LLM) to drive the procedural modeling. In this paper, we introduce a large-scale scene generation framework, SceneX, which can automatically produce high-quality procedural models according to designers' textual de
    
[^170]: MixRED: 一个多语言关系抽取数据集

    MixRED: A Mix-lingual Relation Extraction Dataset

    [https://arxiv.org/abs/2403.15696](https://arxiv.org/abs/2403.15696)

    论文提出了一个新的多语言关系抽取任务MixRE，并构建了支持该任务的人工注释数据集MixRED，填补了多语言情景下关系抽取研究的空白。

    

    arXiv:2403.15696v1 公告类型：新 摘要：关系抽取是自然语言处理领域中的一个关键任务，具有许多现实世界的应用。现有研究主要集中在单语关系抽取或用于关系抽取的跨语言增强。然而，在多语言（或代码混合）场景中，仍存在对关系抽取的理解存在重大差距，在该场景中，个体在句子中混合来自不同语言的内容，生成多语内容。由于缺乏专门的数据集，现有关系抽取模型在这种情况下的有效性在很大程度上尚未探讨。为解决这一问题，我们引入了一项新的任务，即考虑多语言情景中的关系抽取，称为MixRE，并构建了人工注释数据集MixRED以支持此任务。除了构建MixRED数据集，我们还评估了最先进的监督模型和大语言模型（LLMs）。

    arXiv:2403.15696v1 Announce Type: new  Abstract: Relation extraction is a critical task in the field of natural language processing with numerous real-world applications. Existing research primarily focuses on monolingual relation extraction or cross-lingual enhancement for relation extraction. Yet, there remains a significant gap in understanding relation extraction in the mix-lingual (or code-switching) scenario, where individuals intermix contents from different languages within sentences, generating mix-lingual content. Due to the lack of a dedicated dataset, the effectiveness of existing relation extraction models in such a scenario is largely unexplored. To address this issue, we introduce a novel task of considering relation extraction in the mix-lingual scenario called MixRE and constructing the human-annotated dataset MixRED to support this task. In addition to constructing the MixRED dataset, we evaluate both state-of-the-art supervised models and large language models (LLMs)
    
[^171]: EAGLE：面向人工智能生成文本检测的领域泛化框架

    EAGLE: A Domain Generalization Framework for AI-generated Text Detection

    [https://arxiv.org/abs/2403.15690](https://arxiv.org/abs/2403.15690)

    EAGLE提出了一个领域泛化框架，能够利用从旧语言模型中获得的标记数据，学习特征的不变性，从而检测出未知目标生成器生成的文本。

    

    随着大型语言模型（LLMs）能力的提升，负责任和安全使用这些LLMs的一个重要步骤是能够检测这些模型生成的文本。尽管监督式AI生成的文本检测器在旧LLMs生成的文本上表现良好，但随着新LLMs的频繁发布，构建用于识别这些新模型文本的监督检测器将需要新的标记训练数据，在实践中是不可行的。在这项工作中，我们解决这个问题，提出了一个用于检测来自未知目标生成器的AI生成文本的领域泛化框架。我们提出的框架EAGLE利用迄今为止从旧语言模型获得的标记数据，并学习跨这些生成器不变的特征，以便检测由未知目标生成器生成的文本。EAGLE通过结合自监督的表征能力来学习这种领域不变特征。

    arXiv:2403.15690v1 Announce Type: cross  Abstract: With the advancement in capabilities of Large Language Models (LLMs), one major step in the responsible and safe use of such LLMs is to be able to detect text generated by these models. While supervised AI-generated text detectors perform well on text generated by older LLMs, with the frequent release of new LLMs, building supervised detectors for identifying text from such new models would require new labeled training data, which is infeasible in practice. In this work, we tackle this problem and propose a domain generalization framework for the detection of AI-generated text from unseen target generators. Our proposed framework, EAGLE, leverages the labeled data that is available so far from older language models and learns features invariant across these generators, in order to detect text generated by an unknown target generator. EAGLE learns such domain-invariant features by combining the representational power of self-supervised 
    
[^172]: SRLM: 使用大型语言模型和深度强化学习进行人机交互式社交机器人导航

    SRLM: Human-in-Loop Interactive Social Robot Navigation with Large Language Model and Deep Reinforcement Learning

    [https://arxiv.org/abs/2403.15648](https://arxiv.org/abs/2403.15648)

    SRLM 提出了一种结合了大型语言模型和深度强化学习的新型混合方法，用于人机交互式社交机器人导航，通过实时的人类语言指令推断全局规划，并在公共空间中提供多种社交服务，表现出出色的性能。

    

    一名交互式社交机器人助手必须在复杂拥挤的空间中提供服务，根据实时的人类语言指令或反馈调整其行为。本文提出了一种名为Social Robot Planner (SRLM) 的新型混合方法，它将大型语言模型（LLM）和深度强化学习（DRL）整合起来，以在充斥着人群的公共空间中导航，并提供多种社交服务。SRLM 通过实时的人机交互指令推断全局规划，并将社交信息编码到基于LLM的大型导航模型（LNM）中，用于低层次的运动执行。此外，设计了一个基于DRL的规划器来保持基准性能，通过大型反馈模型（LFM）与LNM融合，以解决当前文本和LLM驱动的LNM的不稳定性。最后，SRLM 在广泛的实验中展示出了出色的性能。有关此工作的更多详细信息，请访问：https://sites.g

    arXiv:2403.15648v1 Announce Type: cross  Abstract: An interactive social robotic assistant must provide services in complex and crowded spaces while adapting its behavior based on real-time human language commands or feedback. In this paper, we propose a novel hybrid approach called Social Robot Planner (SRLM), which integrates Large Language Models (LLM) and Deep Reinforcement Learning (DRL) to navigate through human-filled public spaces and provide multiple social services. SRLM infers global planning from human-in-loop commands in real-time, and encodes social information into a LLM-based large navigation model (LNM) for low-level motion execution. Moreover, a DRL-based planner is designed to maintain benchmarking performance, which is blended with LNM by a large feedback model (LFM) to address the instability of current text and LLM-driven LNM. Finally, SRLM demonstrates outstanding performance in extensive experiments. More details about this work are available at: https://sites.g
    
[^173]: 将NIST人工智能风险管理框架应用于监控技术

    Application of the NIST AI Risk Management Framework to Surveillance Technology

    [https://arxiv.org/abs/2403.15646](https://arxiv.org/abs/2403.15646)

    本研究深入探讨了将国家标准与技术研究所的人工智能风险管理框架（NIST AI RMF）应用于监控技术领域的意义，提出了针对面部识别技术的风险管理策略，旨在推动负责任的人工智能利用实践。

    

    本研究深入分析了国家标准与技术研究所的人工智能风险管理框架（NIST AI RMF）在监控技术领域，特别是面部识别技术中的应用和影响。鉴于面部识别系统的固有高风险和重要性，我们的研究强调了在这一领域中进行风险管理的结构化方法的迫切需要。本文提供了一个详细的案例研究，展示了NIST AI RMF在识别和缓解这些技术中可能被忽视的风险方面的实用性。我们的主要目标是制定一个全面的风险管理策略，推动负责任的人工智能利用实践以可行、可扩展的方式进行。我们提出了一个针对监控技术特定挑战的六步流程，旨在产生更系统化、更有效的风险管理。

    arXiv:2403.15646v1 Announce Type: cross  Abstract: This study offers an in-depth analysis of the application and implications of the National Institute of Standards and Technology's AI Risk Management Framework (NIST AI RMF) within the domain of surveillance technologies, particularly facial recognition technology. Given the inherently high-risk and consequential nature of facial recognition systems, our research emphasizes the critical need for a structured approach to risk management in this sector. The paper presents a detailed case study demonstrating the utility of the NIST AI RMF in identifying and mitigating risks that might otherwise remain unnoticed in these technologies. Our primary objective is to develop a comprehensive risk management strategy that advances the practice of responsible AI utilization in feasible, scalable ways. We propose a six-step process tailored to the specific challenges of surveillance technology that aims to produce a more systematic and effective ri
    
[^174]: 具有应用于需求响应决策的背景下多臂老虎机

    Contextual Restless Multi-Armed Bandits with Application to Demand Response Decision-Making

    [https://arxiv.org/abs/2403.15640](https://arxiv.org/abs/2403.15640)

    提出了一种Contextual Restless Bandits (CRB)框架，能够同时建模每个臂的内部状态转换和外部全局环境的影响，提出了可扩展的指数策略算法解决CRB问题，并在需求响应决策中进行了应用。

    

    本文介绍了一种新颖的多臂老虎机框架，称为背景下不安静的老虎机（CRB），用于复杂的在线决策。这种CRB框架融合了上下文老虎机和不安静老虎机的核心特征，因此可以模拟每只臂的内部状态转换和外部全局环境上下文的影响。通过双重分解方法，我们开发了一种可扩展的指数策略算法，用于解决CRB问题，并从理论上分析了该算法的渐近最优性。在臂模型未知的情况下，我们进一步提出了一种基于指数策略的模型为基础的在线学习算法，用于同时学习臂模型和做出决策。此外，我们特别将所提出的CRB框架和指数策略算法应用于智能电网中的需求响应决策问题。数值模拟证明了该算法的性能和鲁棒性。

    arXiv:2403.15640v1 Announce Type: new  Abstract: This paper introduces a novel multi-armed bandits framework, termed Contextual Restless Bandits (CRB), for complex online decision-making. This CRB framework incorporates the core features of contextual bandits and restless bandits, so that it can model both the internal state transitions of each arm and the influence of external global environmental contexts. Using the dual decomposition method, we develop a scalable index policy algorithm for solving the CRB problem, and theoretically analyze the asymptotical optimality of this algorithm. In the case when the arm models are unknown, we further propose a model-based online learning algorithm based on the index policy to learn the arm models and make decisions simultaneously. Furthermore, we apply the proposed CRB framework and the index policy algorithm specifically to the demand response decision-making problem in smart grids. The numerical simulations demonstrate the performance and e
    
[^175]: 研究AI智能场景描述应用在盲人和低视力人群中的使用情况

    Investigating Use Cases of AI-Powered Scene Description Applications for Blind and Low Vision People

    [https://arxiv.org/abs/2403.15604](https://arxiv.org/abs/2403.15604)

    该研究调查了AI智能场景描述应用在盲人和低视力人群中的使用情况，发现用户主要用于识别已知对象的视觉特征以及避免与危险物体接触，并且用户对描述的满意度评分相对较低。

    

    “场景描述”应用程序可以帮助盲人和低视力人士在日常生活中理解照片中的视觉内容。研究人员已经研究了这些应用的使用情况，但他们只研究了利用远程有视力助手的应用，对于利用人工智能生成描述的应用知之甚少。因此，为了调查其使用情况，我们进行了为期两周的日记研究，在此期间，16名盲人和低视力参与者使用了我们设计的AI智能场景描述应用。通过他们的日记记录和后续访谈，用户分享了他们的信息目标以及他们收到的视觉描述的评估。我们分析了这些记录，并发现了常见的使用情况，比如识别已知对象的视觉特征，以及一些令人惊讶的情况，比如避免接触危险物体。我们还发现，用户对这些描述的满意度评分相对较低，平均为2.76（标准差=1.49），对满意度的评分为2.43（标准差=1）。

    arXiv:2403.15604v1 Announce Type: cross  Abstract: "Scene description" applications that describe visual content in a photo are useful daily tools for blind and low vision (BLV) people. Researchers have studied their use, but they have only explored those that leverage remote sighted assistants; little is known about applications that use AI to generate their descriptions. Thus, to investigate their use cases, we conducted a two-week diary study where 16 BLV participants used an AI-powered scene description application we designed. Through their diary entries and follow-up interviews, users shared their information goals and assessments of the visual descriptions they received. We analyzed the entries and found frequent use cases, such as identifying visual features of known objects, and surprising ones, such as avoiding contact with dangerous objects. We also found users scored the descriptions relatively low on average, 2.76 out of 5 (SD=1.49) for satisfaction and 2.43 out of 4 (SD=1
    
[^176]: 基于前向学习的基于梯度的黑盒显著图生成

    Forward Learning for Gradient-based Black-box Saliency Map Generation

    [https://arxiv.org/abs/2403.15603](https://arxiv.org/abs/2403.15603)

    提出了一种新颖的统一框架，在黑盒设置中估计梯度并生成显著图解释模型决策，通过Likelihood Ratio方法估计输出到输入的梯度，并应用分块计算技术提高估计准确性，实验证实有效性和可扩展性。

    

    梯度-based显著图被广泛用于解释深度神经网络决策。然而，随着模型变得更深和更黑盒，如在闭源API（如ChatGPT）中，计算梯度变得具有挑战性，阻碍传统解释方法。在这项工作中，我们引入了一个新颖的统一框架，用于在黑盒设置中估计梯度并生成显著图来解释模型决策。我们采用似然比方法来估计输出到输入的梯度，并将其用于显著图生成。此外，我们提出了分块计算技术来增强估计准确性。在黑盒设置中进行的大量实验证实了我们方法的有效性，展示了准确的梯度估计和生成显著图的解释性。此外，我们通过应用它来解释GPT-Vision展示了我们方法的可扩展性，揭示了梯度相关性的持续影响。

    arXiv:2403.15603v1 Announce Type: cross  Abstract: Gradient-based saliency maps are widely used to explain deep neural network decisions. However, as models become deeper and more black-box, such as in closed-source APIs like ChatGPT, computing gradients become challenging, hindering conventional explanation methods. In this work, we introduce a novel unified framework for estimating gradients in black-box settings and generating saliency maps to interpret model decisions. We employ the likelihood ratio method to estimate output-to-input gradients and utilize them for saliency map generation. Additionally, we propose blockwise computation techniques to enhance estimation accuracy. Extensive experiments in black-box settings validate the effectiveness of our method, demonstrating accurate gradient estimation and explainability of generated saliency maps. Furthermore, we showcase the scalability of our approach by applying it to explain GPT-Vision, revealing the continued relevance of gr
    
[^177]: 从指导方针到治理：教育AI政策研究

    From Guidelines to Governance: A Study of AI Policies in Education

    [https://arxiv.org/abs/2403.15601](https://arxiv.org/abs/2403.15601)

    研究发现大多数教育机构缺乏专门指导生成式AI工具如ChatGPT的道德应用的政策，并且高中相对于高等教育机构在制定政策上更为犹豫，已有的政策经常忽视学生隐私和算法透明度等关键问题。

    

    arXiv:2403.15601v1 公布类型：交叉摘要：像ChatGPT这样的生成式AI工具等新兴技术越来越多地应用于教育环境，为学习提供创新方法的同时也带来新挑战。本研究采用调查方法检视涉及这些技术的政策格局，得出102位高中校长和高等教育校长的见解。我们的结果显示一个突出的政策空白：大多数机构缺乏专门指导生成式AI工具如ChatGPT的道德应用。此外，我们观察到高中不太倾向于制定政策，相对于高等教育机构而言。存在的这些政策往往忽视关键问题，包括学生隐私和算法透明度。行政人员普遍认识到这些政策的必要性，主要为了保障学生安全和减轻抄袭风险。我们的研究结果强调了。。

    arXiv:2403.15601v1 Announce Type: cross  Abstract: Emerging technologies like generative AI tools, including ChatGPT, are increasingly utilized in educational settings, offering innovative approaches to learning while simultaneously posing new challenges. This study employs a survey methodology to examine the policy landscape concerning these technologies, drawing insights from 102 high school principals and higher education provosts. Our results reveal a prominent policy gap: the majority of institutions lack specialized guide-lines for the ethical deployment of AI tools such as ChatGPT. Moreover,we observed that high schools are less inclined to work on policies than higher educational institutions. Where such policies do exist, they often overlook crucial issues, including student privacy and algorithmic transparency. Administrators overwhelmingly recognize the necessity of these policies, primarily to safeguard student safety and mitigate plagiarism risks. Our findings underscore t
    
[^178]: 仅仅又是复制粘贴吗？比较ChatGPT生成代码和StackOverflow答案的安全漏洞

    Just another copy and paste? Comparing the security vulnerabilities of ChatGPT generated code and StackOverflow answers

    [https://arxiv.org/abs/2403.15600](https://arxiv.org/abs/2403.15600)

    本研究通过实证比较ChatGPT生成的代码和StackOverflow答案，提高软件开发人员在选择代码片段时对安全漏洞的认识。

    

    arXiv：2403.15600v1 发布类型：跨  摘要：Sonatype的2023年报告发现，97%的开发人员和安全负责人将生成式人工智能（AI），特别是大型语言模型（LLMs），集成到他们的开发流程中。对这一趋势的安全影响引起了人们的担忧。开发人员现在正在权衡LLMs相对于其他可靠信息来源（如StackOverflow（SO））的好处和风险，需要实证数据来指导他们的选择。在这项工作中，我们的目标是通过实证比较ChatGPT和StackOverflow的漏洞，引起软件开发人员选择代码片段时的安全影响意识。为了实现这一目标，我们使用了来自SO的与安全相关问题和答案的现有Java数据集。然后，我们询问ChatGPT相同的SO问题，收集生成的代码进行比较。在整理数据集后，我们分析了Common Weakness Enumeration (CWE) 漏洞的数量和类型。

    arXiv:2403.15600v1 Announce Type: cross  Abstract: Sonatype's 2023 report found that 97% of developers and security leads integrate generative Artificial Intelligence (AI), particularly Large Language Models (LLMs), into their development process. Concerns about the security implications of this trend have been raised. Developers are now weighing the benefits and risks of LLMs against other relied-upon information sources, such as StackOverflow (SO), requiring empirical data to inform their choice. In this work, our goal is to raise software developers awareness of the security implications when selecting code snippets by empirically comparing the vulnerabilities of ChatGPT and StackOverflow. To achieve this, we used an existing Java dataset from SO with security-related questions and answers. Then, we asked ChatGPT the same SO questions, gathering the generated code for comparison. After curating the dataset, we analyzed the number and types of Common Weakness Enumeration (CWE) vulner
    
[^179]: 基于ChatGPT的提示设计策略的大型语言模型用于群体决策：模型、分析和挑战

    Large language models for crowd decision making based on prompt design strategies using ChatGPT: models, analysis and challenges

    [https://arxiv.org/abs/2403.15587](https://arxiv.org/abs/2403.15587)

    本文分析了基于提示设计策略的ChatGPT在群体决策过程中的应用，为提取意见和做出决策提供了新的可能性。

    

    社交媒体和互联网有潜力被利用作为丰富决策解决方案意见的来源。群体决策（CDM）是一种能够通过情感分析从纯文本（如社交媒体平台上发布的评论）中推断意见和决策的方法。本文分析了利用基于提示设计策略的ChatGPT来辅助CDM过程，以提取意见和做出决策。我们将ChatGPT整合到CDM过程中作为一种灵活的工具，推断出文本中表达的意见，并根据提示设计策略制定决策模型。

    arXiv:2403.15587v1 Announce Type: new  Abstract: Social Media and Internet have the potential to be exploited as a source of opinion to enrich Decision Making solutions. Crowd Decision Making (CDM) is a methodology able to infer opinions and decisions from plain texts, such as reviews published in social media platforms, by means of Sentiment Analysis. Currently, the emergence and potential of Large Language Models (LLMs) lead us to explore new scenarios of automatically understand written texts, also known as natural language processing. This paper analyzes the use of ChatGPT based on prompt design strategies to assist in CDM processes to extract opinions and make decisions. We integrate ChatGPT in CDM processes as a flexible tool that infer the opinions expressed in texts, providing numerical or linguistic evaluations where the decision making models are based on the prompt design strategies. We include a multi-criteria decision making scenario with a category ontology for criteria. 
    
[^180]: 教育领域中的生成式人工智能：教育者意识、情绪和影响因素研究

    Generative AI in Education: A Study of Educators' Awareness, Sentiments, and Influencing Factors

    [https://arxiv.org/abs/2403.15586](https://arxiv.org/abs/2403.15586)

    本研究调查了在高等教育中对大型语言模型和生成式人工智能工具的认知水平、总体情绪和影响因素，结果显示教育者对这些工具的态度逐渐变得积极。

    

    人工智能（AI）的快速发展和大型语言模型（LLMs）的不断整合引发了关于它们在教育中应用的讨论。本研究深入探讨大学教师对AI语言模型的经验和态度，通过分析教育者对AI在课堂中的作用以及对教学和学习潜在影响的观点，填补了文献中的空白。本研究的目标是调查高等教育中LLMs和生成式AI工具的认知水平、采纳的总体情绪以及影响这些态度的因素。数据通过利用李克特量表进行的调查收集，同时辅以跟进访谈以更细致地了解教师的观点。收集到的数据使用统计和主题分析技术进行处理。我们的研究结果显示，教育工作者对生成式AI和大型语言模型的工具的态度逐渐变得积极。

    arXiv:2403.15586v1 Announce Type: new  Abstract: The rapid advancement of artificial intelligence (AI) and the expanding integration of large language models (LLMs) have ignited a debate about their application in education. This study delves into university instructors' experiences and attitudes toward AI language models, filling a gap in the literature by analyzing educators' perspectives on AI's role in the classroom and its potential impacts on teaching and learning. The objective of this research is to investigate the level of awareness, overall sentiment towardsadoption, and the factors influencing these attitudes for LLMs and generative AI-based tools in higher education. Data was collected through a survey using a Likert scale, which was complemented by follow-up interviews to gain a more nuanced understanding of the instructors' viewpoints. The collected data was processed using statistical and thematic analysis techniques. Our findings reveal that educators are increasingly a
    
[^181]: MedPromptX：基于现实的多模态提示用于胸部X线诊断

    MedPromptX: Grounded Multimodal Prompting for Chest X-ray Diagnosis

    [https://arxiv.org/abs/2403.15585](https://arxiv.org/abs/2403.15585)

    MedPromptX是第一个将多模态大型语言模型、少样本提示和视觉基础相结合，用于胸部X线诊断的模型，通过补充缺失的EHR信息，有效解决了幻觉问题，但选择最佳少样本示例和高质量候选者仍有待解决。

    

    胸部X线图像通常用于预测急性和慢性心肺疾病，但是将它们与结构化临床数据整合的努力面临着因电子健康记录（EHR）不完整而带来的挑战。本文引入了MedPromptX，这是第一个将多模态大型语言模型（MLLMs）、少样本提示（FP）和视觉基础（VG）相结合，将图像与EHR数据用于胸部X线诊断的模型。预训练的MLLM被用来补充缺失的EHR信息，提供对患者病史的全面理解。此外，少样本提示减少了对MLLM的大量训练的必要性，同时有效解决了幻觉问题。然而，确定最佳少样本示例的过程和选择高质量候选者可能过于繁琐，但它对模型性能产生着深远影响。因此，我们提出了一种新技术来动态地...

    arXiv:2403.15585v1 Announce Type: cross  Abstract: Chest X-ray images are commonly used for predicting acute and chronic cardiopulmonary conditions, but efforts to integrate them with structured clinical data face challenges due to incomplete electronic health records (EHR). This paper introduces \textbf{MedPromptX}, the first model to integrate multimodal large language models (MLLMs), few-shot prompting (FP) and visual grounding (VG) to combine imagery with EHR data for chest X-ray diagnosis. A pre-trained MLLM is utilized to complement the missing EHR information, providing a comprehensive understanding of patients' medical history. Additionally, FP reduces the necessity for extensive training of MLLMs while effectively tackling the issue of hallucination. Nevertheless, the process of determining the optimal number of few-shot examples and selecting high-quality candidates can be burdensome, yet it profoundly influences model performance. Hence, we propose a new technique that dynam
    
[^182]: 基于深度集成的自适应巡航控制的感知不确定性自动驾驶

    Autonomous Driving With Perception Uncertainties: Deep-Ensemble Based Adaptive Cruise Control

    [https://arxiv.org/abs/2403.15577](https://arxiv.org/abs/2403.15577)

    本文提出了一种基于深度集成的DNN回归器用于自动驾驶中感知不确定性的处理，在自适应巡航控制场景中，实现了对车头间隔的预测并提供了概率安全保证。

    

    自动驾驶依赖感知系统来理解环境并为下游决策提供信息。本文提出了一种深度集成的DNN回归器（Deep Ensemble），用于生成带有预测不确定性量化的预测。在自适应巡航控制（ACC）场景中，我们利用深度集成从RGB图像中估算到前方车辆的距离车头间隔，并使下游控制器考虑估计不确定性。我们开发了一个自适应巡航控制器，利用带有概率安全保证的随机模型预测控制（MPC）来提供概率安全性保证。

    arXiv:2403.15577v1 Announce Type: new  Abstract: Autonomous driving depends on perception systems to understand the environment and to inform downstream decision-making. While advanced perception systems utilizing black-box Deep Neural Networks (DNNs) demonstrate human-like comprehension, their unpredictable behavior and lack of interpretability may hinder their deployment in safety critical scenarios. In this paper, we develop an Ensemble of DNN regressors (Deep Ensemble) that generates predictions with quantification of prediction uncertainties. In the scenario of Adaptive Cruise Control (ACC), we employ the Deep Ensemble to estimate distance headway to the lead vehicle from RGB images and enable the downstream controller to account for the estimation uncertainty. We develop an adaptive cruise controller that utilizes Stochastic Model Predictive Control (MPC) with chance constraints to provide a probabilistic safety guarantee. We evaluate our ACC algorithm using a high-fidelity traff
    
[^183]: SensoryT5：将感觉运动规范融入T5以增强细粒度情绪分类

    SensoryT5: Infusing Sensorimotor Norms into T5 for Enhanced Fine-grained Emotion Classification

    [https://arxiv.org/abs/2403.15574](https://arxiv.org/abs/2403.15574)

    SensoryT5是一种将感觉信息融入T5模型的神经认知方法，旨在增强细粒度情绪分类，通过在注意机制中整合感觉线索，实现情绪表示的丰富性，并在各种数据集上展示出较好的性能。

    

    传统研究方法中，感知和情绪分类被认为是独立的领域。然而，感觉经历对情绪反应的显著影响是不可否认的。自然语言处理（NLP）社区经常错过将感觉知识与情绪分类相结合的机会。为了填补这一空白，我们提出了SensoryT5，这是一种神经认知方法，将感官信息整合到专为细粒度情绪分类而设计的T5（文本到文本转换Transformer）模型中。该方法将感觉线索融入T5的注意机制，实现了上下文理解与感觉意识之间的和谐平衡。结果模型增强了情绪表示的丰富性。通过对各种详细情绪分类数据集的严格测试，SensoryT5展示出了改善的性能。

    arXiv:2403.15574v1 Announce Type: new  Abstract: In traditional research approaches, sensory perception and emotion classification have traditionally been considered separate domains. Yet, the significant influence of sensory experiences on emotional responses is undeniable. The natural language processing (NLP) community has often missed the opportunity to merge sensory knowledge with emotion classification. To address this gap, we propose SensoryT5, a neuro-cognitive approach that integrates sensory information into the T5 (Text-to-Text Transfer Transformer) model, designed specifically for fine-grained emotion classification. This methodology incorporates sensory cues into the T5's attention mechanism, enabling a harmonious balance between contextual understanding and sensory awareness. The resulting model amplifies the richness of emotional representations. In rigorous tests across various detailed emotion classification datasets, SensoryT5 showcases improved performance, surpassin
    
[^184]: 一个优化框架，利用预训练的文本到图像模型强制实现对3D网格进行纹理贴图的多视图一致性

    An Optimization Framework to Enforce Multi-View Consistency for Texturing 3D Meshes Using Pre-Trained Text-to-Image Models

    [https://arxiv.org/abs/2403.15559](https://arxiv.org/abs/2403.15559)

    该论文介绍了一个四阶段的优化框架，通过MV一致的扩散过程、半定编程问题解决、非刚性对齐和MRF问题解决等步骤来实现对3D网格进行纹理贴图的多视图一致性。

    

    在使用预训练的文本到图像模型对3D网格进行纹理贴图时，确保多视图一致性是一个基本问题。本文介绍了一个优化框架，通过四个阶段实现多视图一致性。具体而言，第一阶段使用MV一致的扩散过程从预定义的视点集生成2D纹理的过完备集。第二阶段通过解决半定编程问题选择相互一致且覆盖基础3D模型的视图子集。第三阶段执行非刚性对齐，使选定的视图在重叠区域对齐。第四阶段解决MRF问题以关联...

    arXiv:2403.15559v1 Announce Type: cross  Abstract: A fundamental problem in the texturing of 3D meshes using pre-trained text-to-image models is to ensure multi-view consistency. State-of-the-art approaches typically use diffusion models to aggregate multi-view inputs, where common issues are the blurriness caused by the averaging operation in the aggregation step or inconsistencies in local features. This paper introduces an optimization framework that proceeds in four stages to achieve multi-view consistency. Specifically, the first stage generates an over-complete set of 2D textures from a predefined set of viewpoints using an MV-consistent diffusion process. The second stage selects a subset of views that are mutually consistent while covering the underlying 3D model. We show how to achieve this goal by solving semi-definite programs. The third stage performs non-rigid alignment to align the selected views across overlapping regions. The fourth stage solves an MRF problem to associ
    
[^185]: 基于语言的单目深度估计深度提示

    Language-Based Depth Hints for Monocular Depth Estimation

    [https://arxiv.org/abs/2403.15551](https://arxiv.org/abs/2403.15551)

    通过使用自然语言作为进行单目深度估计的显式先验，本研究展示了如何使用简单的学习方法来提取语言模型对世界结构的偏见，并将其作为假设的显式来源输入到MDE系统中。

    

    单目深度估计(MDE)在本质上是模糊的，因为给定的图像可能来源于许多不同的3D场景，反之亦然。为了解决这种模糊性，一个MDE系统必须对给定输入的最可能的3D场景作出假设。这些假设可以是显式的，也可以是隐式的。在这项工作中，我们展示了自然语言作为世界结构的显式先验的用法。假设人类语言对各种物体在深度空间中的可能分布进行编码。我们首先展示了语言模型在训练期间编码了这种隐式偏见，并且可以使用非常简单的学习方法进行提取。然后我们展示了这种预测可以作为假设的显式来源提供给MDE系统，使用一个提供标签作为语言模型输入的现成实例分割模型。我们展示了我们的方法的性能。

    arXiv:2403.15551v1 Announce Type: cross  Abstract: Monocular depth estimation (MDE) is inherently ambiguous, as a given image may result from many different 3D scenes and vice versa. To resolve this ambiguity, an MDE system must make assumptions about the most likely 3D scenes for a given input. These assumptions can be either explicit or implicit. In this work, we demonstrate the use of natural language as a source of an explicit prior about the structure of the world. The assumption is made that human language encodes the likely distribution in depth-space of various objects. We first show that a language model encodes this implicit bias during training, and that it can be extracted using a very simple learned approach. We then show that this prediction can be provided as an explicit source of assumption to an MDE system, using an off-the-shelf instance segmentation model that provides the labels used as the input to the language model. We demonstrate the performance of our method on
    
[^186]: LimGen: 探究用于生成研究论文建议性局限的LLMs

    LimGen: Probing the LLMs for Generating Suggestive Limitations of Research Papers

    [https://arxiv.org/abs/2403.15529](https://arxiv.org/abs/2403.15529)

    本文提出了一个新颖而具有挑战性的任务，即为研究论文生成建议性局限，通过调查大型语言模型的多种方法来揭示相关挑战、实践见解和潜在机会。

    

    检查局限是学术研究评审过程中的关键步骤，揭示了研究可能缺乏决定性或需要加强的方面。这有助于读者考虑进一步研究的更广泛影响。本文提出了研究论文建议性局限生成（SLG）的一项新颖且具有挑战性的任务。我们编制了一个名为LimGen的数据集，包含来自ACL文集的4068篇研究论文及其相关局限。我们调查了多种方法来利用大型语言模型（LLMs）生成建议性局限，通过彻底研究相关挑战、实践见解和潜在机会。我们的LimGen数据集和代码可以在https://github.com/armbf/LimGen 上获取。

    arXiv:2403.15529v1 Announce Type: cross  Abstract: Examining limitations is a crucial step in the scholarly research reviewing process, revealing aspects where a study might lack decisiveness or require enhancement. This aids readers in considering broader implications for further research. In this article, we present a novel and challenging task of Suggestive Limitation Generation (SLG) for research papers. We compile a dataset called LimGen, encompassing 4068 research papers and their associated limitations from the ACL anthology. We investigate several approaches to harness large language models (LLMs) for producing suggestive limitations, by thoroughly examining the related challenges, practical insights, and potential opportunities. Our LimGen dataset and code can be accessed at https://github.com/armbf/LimGen.
    
[^187]: 使用视觉评估GPT-4在胸部X光放射检查中的放射学发现检测

    Evaluating GPT-4 with Vision on Detection of Radiological Findings on Chest Radiographs

    [https://arxiv.org/abs/2403.15528](https://arxiv.org/abs/2403.15528)

    GPT-4V在胸部X光放射检查的放射学发现检测上尚未准备好应用于真实世界的诊断用途

    

    这项研究探讨了GPT-4V的应用，这是一个装备有视觉识别功能的多模态大型语言模型，用于检测来自100张胸部X光放射检查的放射学发现，并指出目前GPT-4V还不适用于解释胸部X光放射检查的实际诊断用途。

    arXiv:2403.15528v1 Announce Type: cross  Abstract: The study examines the application of GPT-4V, a multi-modal large language model equipped with visual recognition, in detecting radiological findings from a set of 100 chest radiographs and suggests that GPT-4V is currently not ready for real-world diagnostic usage in interpreting chest radiographs.
    
[^188]: 采用噪声标记的听觉注意力解码研究：一项试点研究

    Towards auditory attention decoding with noise-tagging: A pilot study

    [https://arxiv.org/abs/2403.15523](https://arxiv.org/abs/2403.15523)

    这项试点研究首次尝试使用噪声标记刺激协议进行听觉注意力解码，取得了较高的性能表现。

    

    听觉注意力解码(AAD)旨在从大脑活动中提取被关注的说话者，提供了神经导向听觉设备和脑机接口等领域的应用前景。本试点研究首次尝试使用噪声标记刺激协议进行AAD，该协议引发了可靠的编码调制诱发电位，但在听觉模式下的探索还很有限。研究参与者依次呈现两个荷兰语言语音刺激，这些刺激被幅度调制为具有唯一二进制伪随机噪声码，有效地为其标记了附加可解码信息。我们比较了未调制音频与使用不同调制深度调制的音频的解码，以及传统AAD方法与标准解码噪声码方法的对比。我们的试点研究发现，与未调制音频相比，70至100%的调制深度的传统方法表现出更高的性能。

    arXiv:2403.15523v1 Announce Type: cross  Abstract: Auditory attention decoding (AAD) aims to extract from brain activity the attended speaker amidst candidate speakers, offering promising applications for neuro-steered hearing devices and brain-computer interfacing. This pilot study makes a first step towards AAD using the noise-tagging stimulus protocol, which evokes reliable code-modulated evoked potentials, but is minimally explored in the auditory modality. Participants were sequentially presented with two Dutch speech stimuli that were amplitude modulated with a unique binary pseudo-random noise-code, effectively tagging these with additional decodable information. We compared the decoding of unmodulated audio against audio modulated with various modulation depths, and a conventional AAD method against a standard method to decode noise-codes. Our pilot study revealed higher performances for the conventional method with 70 to 100 percent modulation depths compared to unmodulated au
    
[^189]: CTSM：将特质和状态情绪相结合的共情响应模型

    CTSM: Combining Trait and State Emotions for Empathetic Response Model

    [https://arxiv.org/abs/2403.15516](https://arxiv.org/abs/2403.15516)

    CTSM模型结合特质和状态情绪，通过构建和编码情绪嵌入以及引入情绪引导模块，解决了先前处理情绪感知不足的问题。

    

    共情性响应生成旨在赋予对话系统感知说话者情绪并相应生成共情性回应的能力。心理研究表明，作为共情的一个重要因素，情绪包括特质情绪（静态且与环境无关）和状态情绪（动态且与环境相关）。然而，先前的研究将它们单独处理，导致对情境情绪的感知不足，进而影响了有效的共情表达。为解决这一问题，我们提出了将特质和状态情绪相结合的共情响应模型（CTSM）。具体来说，为了充分感知对话中的情绪，我们首先构建和编码特质和状态情绪嵌入，然后通过一个情绪引导模块进一步增强情绪感知能力，该模块指导情绪表达。此外，我们提出了一种交叉对比学习。

    arXiv:2403.15516v1 Announce Type: cross  Abstract: Empathetic response generation endeavors to empower dialogue systems to perceive speakers' emotions and generate empathetic responses accordingly. Psychological research demonstrates that emotion, as an essential factor in empathy, encompasses trait emotions, which are static and context-independent, and state emotions, which are dynamic and context-dependent. However, previous studies treat them in isolation, leading to insufficient emotional perception of the context, and subsequently, less effective empathetic expression. To address this problem, we propose Combining Trait and State emotions for Empathetic Response Model (CTSM). Specifically, to sufficiently perceive emotions in dialogue, we first construct and encode trait and state emotion embeddings, and then we further enhance emotional perception capability through an emotion guidance module that guides emotion representation. In addition, we propose a cross-contrastive learnin
    
[^190]: 通过决策边界感知数据增强在低资源环境中提高有效性和稳健性

    Enhancing Effectiveness and Robustness in a Low-Resource Regime via Decision-Boundary-aware Data Augmentation

    [https://arxiv.org/abs/2403.15512](https://arxiv.org/abs/2403.15512)

    本文提出了一种决策边界感知的数据增强策略，通过移动潜在特征、重构生成模糊版本以及采用中K采样来增强生成句子的多样性，从而比较于其他方法提高了在低资源环境中的有效性和稳健性。

    

    在低资源环境中利用深度学习模型需要进行数据增强，但直接方法（如mixup和cutout）在文本数据上的应用受限于其离散特性。本文受到决策边界的最新研究启发，提出了一种决策边界感知的数据增强策略，利用预训练的语言模型来增强稳健性。该技术首先专注于将潜在特征移近决策边界，然后进行重构以生成一个带有软标签的模糊版本。此外，建议使用中K采样来增强生成句子的多样性。

    arXiv:2403.15512v1 Announce Type: cross  Abstract: Efforts to leverage deep learning models in low-resource regimes have led to numerous augmentation studies. However, the direct application of methods such as mixup and cutout to text data, is limited due to their discrete characteristics. While methods using pretrained language models have exhibited efficiency, they require additional considerations for robustness. Inspired by recent studies on decision boundaries, this paper proposes a decision-boundary-aware data augmentation strategy to enhance robustness using pretrained language models. The proposed technique first focuses on shifting the latent features closer to the decision boundary, followed by reconstruction to generate an ambiguous version with a soft label. Additionally, mid-K sampling is suggested to enhance the diversity of the generated sentences. This paper demonstrates the performance of the proposed augmentation strategy compared to other methods through extensive ex
    
[^191]: IoT入侵检测系统中的多输入自动编码器引导特征选择

    Multiple-Input Auto-Encoder Guided Feature Selection for IoT Intrusion Detection Systems

    [https://arxiv.org/abs/2403.15511](https://arxiv.org/abs/2403.15511)

    该论文提出了一种名为多输入自动编码器(MIAE)的新型神经网络架构，通过训练MIAE模型，在无监督学习模式下将异构输入转换为较低维表示，有助于分类器区分正常行为和不同类型的攻击。

    

    入侵检测系统(IDSs)受益于IoT数据特征的多样性和泛化，数据的多样性使得在IoT IDSs中训练有效的机器学习模型变得困难。本文首先介绍了一种名为多输入自动编码器(MIAE)的新型神经网络架构。MIAE由多个子编码器组成，可以处理具有不同特征的不同来源的输入。 MIAE模型以无监督学习模式进行训练，将异构输入转换为较低维表示，有助于分类器区分正常行为和不同类型的攻击。

    arXiv:2403.15511v1 Announce Type: cross  Abstract: While intrusion detection systems (IDSs) benefit from the diversity and generalization of IoT data features, the data diversity (e.g., the heterogeneity and high dimensions of data) also makes it difficult to train effective machine learning models in IoT IDSs. This also leads to potentially redundant/noisy features that may decrease the accuracy of the detection engine in IDSs. This paper first introduces a novel neural network architecture called Multiple-Input Auto-Encoder (MIAE). MIAE consists of multiple sub-encoders that can process inputs from different sources with different characteristics. The MIAE model is trained in an unsupervised learning mode to transform the heterogeneous inputs into lower-dimensional representation, which helps classifiers distinguish between normal behaviour and different types of attacks. To distil and retain more relevant features but remove less important/redundant ones during the training process,
    
[^192]: 双自动编码器模型用于学习网络攻击检测中的可分离表示

    Twin Auto-Encoder Model for Learning Separable Representation in Cyberattack Detection

    [https://arxiv.org/abs/2403.15509](https://arxiv.org/abs/2403.15509)

    提出一种新型双自动编码器模型(TAE)，通过将潜在表示转换为可分离表示来解决网络攻击检测中混合表示的问题

    

    表征学习在网络攻击检测等许多问题的成功中起着关键作用。大多数网络攻击检测的表征学习方法基于自动编码器（AE）模型的潜在向量。为了解决AEs表示中混合的问题，我们提出了一种称为双自动编码器（TAE）的新型模型。TAE将潜在表示确定地转换为更易区分的表示，即\textit{可分离表示}，并在输出端重建可分离表示。

    arXiv:2403.15509v1 Announce Type: cross  Abstract: Representation Learning (RL) plays a pivotal role in the success of many problems including cyberattack detection. Most of the RL methods for cyberattack detection are based on the latent vector of Auto-Encoder (AE) models. An AE transforms raw data into a new latent representation that better exposes the underlying characteristics of the input data. Thus, it is very useful for identifying cyberattacks. However, due to the heterogeneity and sophistication of cyberattacks, the representation of AEs is often entangled/mixed resulting in the difficulty for downstream attack detection models. To tackle this problem, we propose a novel mod called Twin Auto-Encoder (TAE). TAE deterministically transforms the latent representation into a more distinguishable representation namely the \textit{separable representation} and the reconstructsuct the separable representation at the output. The output of TAE called the \textit{reconstruction represe
    
[^193]: SymboSLAM: 多Agent系统中的语义地图生成

    SymboSLAM: Semantic Map Generation in a Multi-Agent System

    [https://arxiv.org/abs/2403.15504](https://arxiv.org/abs/2403.15504)

    SymboSLAM提出了一种新颖的方法，通过符号化同时定位和地图制图来实现环境分类，解决了解决方案的可解释性问题。

    

    Sub-symbolic人工智能方法在环境分类和同时定位与地图制图领域占主导地位。然而，在这些领域中被忽视的一个重要领域是解决方案透明性，因为用于地图生成的次符号方法并未考虑所生成解决方案的可解释性。本文提出了一种新颖的环境分类方法，通过符号同时定位与地图制图，即SymboSLAM，来弥补可解释性差距。我们的环境分类方法通过观察本体推理，以合成环境的上下文，通过所发现的特征。我们通过向操作员呈现叠加了语义标记的地标和特征的环境分类，实现了模型内的可解释性。我们通过地面实况评估了SymboSLAM。

    arXiv:2403.15504v1 Announce Type: new  Abstract: Sub-symbolic artificial intelligence methods dominate the fields of environment-type classification and Simultaneous Localisation and Mapping. However, a significant area overlooked within these fields is solution transparency for the human-machine interaction space, as the sub-symbolic methods employed for map generation do not account for the explainability of the solutions generated. This paper proposes a novel approach to environment-type classification through Symbolic Simultaneous Localisation and Mapping, SymboSLAM, to bridge the explainability gap. Our method for environment-type classification observes ontological reasoning used to synthesise the context of an environment through the features found within. We achieve explainability within the model by presenting operators with environment-type classifications overlayed by a semantically labelled occupancy map of landmarks and features. We evaluate SymboSLAM with ground-truth map
    
[^194]: 通过机器学习驱动的元学习器对电力市场中CO2减排策略进行因果分析

    A Causal Analysis of CO2 Reduction Strategies in Electricity Markets Through Machine Learning-Driven Metalearners

    [https://arxiv.org/abs/2403.15499](https://arxiv.org/abs/2403.15499)

    通过Causal Machine Learning方法分析电力市场中定价政策对CO2水平的影响，挑战传统智慧，发现可能增加CO2强度，并结合机器学习元算法增强研究深度，并提供宝贵见解。

    

    本研究采用因果机器学习（CausalML）统计方法，分析电力定价政策对家庭部门二氧化碳（CO2）水平的影响。研究调查潜在结果与处理效果之间的因果关系，其中定价政策的变化是处理效果，我们的分析挑战了围绕基于激励的电力定价的传统智慧。研究结果表明，采用这些政策可能会无意中增加CO2强度。此外，我们整合了基于机器学习的元算法，反映了当代统计方法，以增强我们的因果分析深度。该研究对学习者X、T、S和R进行了比较分析，以确定基于规定问题的具体目标和背景细微之处的最佳方法。这项研究为可持续发展问题上的持续对话提供了宝贵的见解。

    arXiv:2403.15499v1 Announce Type: cross  Abstract: This study employs the Causal Machine Learning (CausalML) statistical method to analyze the influence of electricity pricing policies on carbon dioxide (CO2) levels in the household sector. Investigating the causality between potential outcomes and treatment effects, where changes in pricing policies are the treatment, our analysis challenges the conventional wisdom surrounding incentive-based electricity pricing. The study's findings suggest that adopting such policies may inadvertently increase CO2 intensity. Additionally, we integrate a machine learning-based meta-algorithm, reflecting a contemporary statistical approach, to enhance the depth of our causal analysis. The study conducts a comparative analysis of learners X, T, S, and R to ascertain the optimal methods based on the defined question's specified goals and contextual nuances. This research contributes valuable insights to the ongoing dialogue on sustainable development pr
    
[^195]: 使用有条件识别信息的脑电图解码

    EEG decoding with conditional identification information

    [https://arxiv.org/abs/2403.15489](https://arxiv.org/abs/2403.15489)

    通过将个体的有条件识别信息整合到神经网络中，这项研究提出了一种新的方法来增强模型表示，从而改善脑电图信号的解码准确性。

    

    脑电图信号的解码对于揭示人类大脑并推动脑机接口至关重要。传统的机器学习算法受到脑电图信号中高噪音水平和个体间固有变化的阻碍。最近深度神经网络（DNNs）的进展显示出潜力，归功于其先进的非线性建模能力。然而，DNN在解码未见个体的脑电图样本方面仍面临挑战。为了解决这一问题，本文引入了一种新颖的方法，通过将每个个体的有条件识别信息纳入神经网络，从而通过脑电图和个人特征的协同作用增强模型表示。我们在WithMe数据集上测试了我们的模型，并证明包含这些标识符显著提高了训练集中的主体和未见主体的准确性。这种增强显示了改进脑电图解码的潜力。

    arXiv:2403.15489v1 Announce Type: cross  Abstract: Decoding EEG signals is crucial for unraveling human brain and advancing brain-computer interfaces. Traditional machine learning algorithms have been hindered by the high noise levels and inherent inter-person variations in EEG signals. Recent advances in deep neural networks (DNNs) have shown promise, owing to their advanced nonlinear modeling capabilities. However, DNN still faces challenge in decoding EEG samples of unseen individuals. To address this, this paper introduces a novel approach by incorporating the conditional identification information of each individual into the neural network, thereby enhancing model representation through the synergistic interaction of EEG and personal traits. We test our model on the WithMe dataset and demonstrated that the inclusion of these identifiers substantially boosts accuracy for both subjects in the training set and unseen subjects. This enhancement suggests promising potential for improvi
    
[^196]: 序列到序列语言模型用于梦境叙事中的角色和情感检测

    Sequence-to-Sequence Language Models for Character and Emotion Detection in Dream Narratives

    [https://arxiv.org/abs/2403.15486](https://arxiv.org/abs/2403.15486)

    本研究提出一种序列到序列语言模型框架，首次在梦境叙事中进行角色和情感检测研究，展示语言模型可以有效应对该复杂任务，监督模型表现更佳且参数更少。

    

    梦境研究对于理解人类的(非)意识、认知和文化数个世纪来一直至关重要。定量分析梦境依赖于对梦境叙述的劳动密集型手动注释。我们通过一种自然语言序列到序列生成框架自动化这一过程。本文首次在梦境叙事的开放DreamBank语料库英文部分中进行了角色和情感检测研究。我们的结果表明语言模型可以有效地解决这一复杂任务。为了了解预测性能，我们评估了模型大小、角色的预测顺序以及对专有名称和角色特征的考虑的影响。我们将我们的方法与使用上下文学习的大型语言模型进行了比较。我们的监督模型表现更好，同时参数数量减少了28倍。我们的模型及其生成的注释已公开可用。

    arXiv:2403.15486v1 Announce Type: cross  Abstract: The study of dreams has been central to understanding human (un)consciousness, cognition, and culture for centuries. Analyzing dreams quantitatively depends on labor-intensive, manual annotation of dream narratives. We automate this process through a natural language sequence-to-sequence generation framework. This paper presents the first study on character and emotion detection in the English portion of the open DreamBank corpus of dream narratives. Our results show that language models can effectively address this complex task. To get insight into prediction performance, we evaluate the impact of model size, prediction order of characters, and the consideration of proper names and character traits. We compare our approach with a large language model using in-context learning. Our supervised models perform better while having 28 times fewer parameters. Our model and its generated annotations are made publicly available.
    
[^197]: MOGAM：一种用于抑郁症检测的多模态面向对象图注意模型

    MOGAM: A Multimodal Object-oriented Graph Attention Model for Depression Detection

    [https://arxiv.org/abs/2403.15485](https://arxiv.org/abs/2403.15485)

    MOGAM模型是为了克服现有抑郁症检测方法在不同社交媒体数据类型上的限制而提出，通过多模态数据的综合应用，实现了更具可扩展性和多功能性的解决方案。

    

    早期检测在抑郁症治疗中起着至关重要的作用。因此，许多研究关注社交媒体平台，个体在该平台表达情绪，旨在实现抑郁症的早期检测。然而，现有方法主要依赖特定特征，导致在不同类型的社交媒体数据集（如文本、图像或视频）上的可扩展性有限。为克服这一限制，我们引入了一种多模态面向对象图注意模型（MOGAM），可应用于各种数据类型，提供更具可伸缩性和多功能性的解决方案。此外，为确保我们的模型能够捕捉抑郁症的真实症状，我们仅收集了具有临床诊断的用户的视频日志。为了利用视频日志的多样特征，我们采用多模态方法，并收集额外的元数据，如视频日志的标题、描述和持续时间。为了有效地聚合

    arXiv:2403.15485v1 Announce Type: cross  Abstract: Early detection plays a crucial role in the treatment of depression. Therefore, numerous studies have focused on social media platforms, where individuals express their emotions, aiming to achieve early detection of depression. However, the majority of existing approaches often rely on specific features, leading to limited scalability across different types of social media datasets, such as text, images, or videos. To overcome this limitation, we introduce a Multimodal Object-Oriented Graph Attention Model (MOGAM), which can be applied to diverse types of data, offering a more scalable and versatile solution. Furthermore, to ensure that our model can capture authentic symptoms of depression, we only include vlogs from users with a clinical diagnosis. To leverage the diverse features of vlogs, we adopt a multimodal approach and collect additional metadata such as the title, description, and duration of the vlogs. To effectively aggregat
    
[^198]: AI/ML 发展中的公平导航: 从业者对AI/ML开发中的理解、挑战和策略

    Navigating Fairness: Practitioners' Understanding, Challenges, and Strategies in AI/ML Development

    [https://arxiv.org/abs/2403.15481](https://arxiv.org/abs/2403.15481)

    AI从业者对于公平AI/ML的理解、面临的挑战、不公平AI/ML的后果以及确保AI/ML公平性的策略。

    

    近年来，各行业对AI/ML应用的增加引发了对AI/ML公平性的更多讨论。虽然已有关于AI/ML公平性的先前研究，但缺乏针对了解AI从业者在开发公平AI/ML过程中的观点和经验的实证研究。了解AI从业者对AI/ML公平性的看法和经验很重要，因为他们直接参与其中的开发和部署，他们的见解可以提供有价值的现实世界视角，帮助理解确保AI/ML公平性所涉及挑战的重要性。我们进行了22位AI从业者的半结构化访谈，以调查他们对“公平AI/ML”是什么的理解，他们在开发公平AI/ML中面临的挑战，开发不公平AI/ML的后果，以及他们采取的策略来确保AI/ML的公平性。我们制定了一个框架展示了

    arXiv:2403.15481v1 Announce Type: cross  Abstract: The rise in the use of AI/ML applications across industries has sparked more discussions about the fairness of AI/ML in recent times. While prior research on the fairness of AI/ML exists, there is a lack of empirical studies focused on understanding the views and experiences of AI practitioners in developing a fair AI/ML. Understanding AI practitioners' views and experiences on the fairness of AI/ML is important because they are directly involved in its development and deployment and their insights can offer valuable real-world perspectives on the challenges associated with ensuring fairness in AI/ML. We conducted semi-structured interviews with 22 AI practitioners to investigate their understanding of what a 'fair AI/ML' is, the challenges they face in developing a fair AI/ML, the consequences of developing an unfair AI/ML, and the strategies they employ to ensure AI/ML fairness. We developed a framework showcasing the relationship be
    
[^199]: 谷歌AI系统的反社会类行为、行为一致性及对人类的影响：通过与人类互动、独立LLM分析和AI自反思的修改反社会行为标准来评估

    Antisocial Analagous Behavior, Alignment and Human Impact of Google AI Systems: Evaluating through the lens of modified Antisocial Behavior Criteria by Human Interaction, Independent LLM Analysis, and AI Self-Reflection

    [https://arxiv.org/abs/2403.15479](https://arxiv.org/abs/2403.15479)

    谷歌AI系统展示了与反社会人格障碍类似的行为模式，强调了对AI系统及其创造者的信任度必须进行批判性评估。

    

    Google AI系统展示出与反社会人格障碍（ASPD）相似的模式，从Bard on PaLM到Gemini Advanced的模型一致地符合了7个ASPD修改标准中的5个。这些模式，连同可比较的企业行为，被使用一个ASPD灵感的框架进行审查，强调了评估AI对人类影响的启发式价值。通过ChatGPT 4和Claude 3.0 Opus对谷歌互动的独立分析，以及AI自我反思，验证了这些问题，突出了类似欺骗、操纵和忽视安全的行为。

    arXiv:2403.15479v1 Announce Type: cross  Abstract: Google AI systems exhibit patterns mirroring antisocial personality disorder (ASPD), consistent across models from Bard on PaLM to Gemini Advanced, meeting 5 out of 7 ASPD modified criteria. These patterns, along with comparable corporate behaviors, are scrutinized using an ASPD-inspired framework, emphasizing the heuristic value in assessing AI's human impact. Independent analyses by ChatGPT 4 and Claude 3.0 Opus of the Google interactions, alongside AI self-reflection, validate these concerns, highlighting behaviours analogous to deceit, manipulation, and safety neglect.   The analogy of ASPD underscores the dilemma: just as we would hesitate to entrust our homes or personal devices to someone with psychopathic traits, we must critically evaluate the trustworthiness of AI systems and their creators.This research advocates for an integrated AI ethics approach, blending technological evaluation, human-AI interaction, and corporate beha
    
[^200]: 学习推断生成视觉概念的模板程序

    Learning to Infer Generative Template Programs for Visual Concepts

    [https://arxiv.org/abs/2403.15476](https://arxiv.org/abs/2403.15476)

    探索了一种学习如何推断捕捉视觉概念的通用模板程序的神经符号系统，引入了模板程序概念，支持多种概念相关任务，提出了一种学习范式来训练网络直接推断模板程序，实验证明该方法优于任务特定替代方法，并与特定领域方法竞争性地执行。

    

    人们可以从少量示例中灵活掌握视觉概念。我们探索了一种神经符号系统，学习如何以一种通用方式推断捕捉视觉概念的程序。我们引入了模板程序：来自特定领域语言的程序表达式，指定了输入概念中常见的结构和参数模式。我们的框架支持多个与概念相关的任务，包括通过解析进行少样本生成和共分割。我们开发了一种学习范式，允许我们训练网络直接从包含概念分组的视觉数据集中推断模板程序。我们在多个视觉领域进行实验：2D布局、Omniglot字符和3D形状。我们发现我们的方法胜过了任务特定的替代方法，并在有限领域竞争性地执行了针对特定领域的方法。

    arXiv:2403.15476v1 Announce Type: cross  Abstract: People grasp flexible visual concepts from a few examples. We explore a neurosymbolic system that learns how to infer programs that capture visual concepts in a domain-general fashion. We introduce Template Programs: programmatic expressions from a domain-specific language that specify structural and parametric patterns common to an input concept. Our framework supports multiple concept-related tasks, including few-shot generation and co-segmentation through parsing. We develop a learning paradigm that allows us to train networks that infer Template Programs directly from visual datasets that contain concept groupings. We run experiments across multiple visual domains: 2D layouts, Omniglot characters, and 3D shapes. We find that our method outperforms task-specific alternatives, and performs competitively against domain-specific approaches for the limited domains where they exist.
    
[^201]: EC-IoU: 通过自我中心交并联调整物体检测器的安全性

    EC-IoU: Orienting Safety for Object Detectors via Ego-Centric Intersection-over-Union

    [https://arxiv.org/abs/2403.15474](https://arxiv.org/abs/2403.15474)

    通过EC-IoU度量，本文引入了一种定向安全性物体检测方法，可以在安全关键领域中提高物体检测器的性能，并在KITTI数据集上取得了比IoU更好的结果。

    

    本文介绍了通过一种新颖的自我中心交并联（EC-IoU）度量来定向安全性物体检测，解决了在自动驾驶等安全关键领域应用最先进的基于学习的感知模型时面临的实际问题。具体来说，我们提出了一种加权机制来优化广泛使用的IoU度量，使其能够根据自我代理人的视角覆盖更近的地面真实对象点的预测分配更高的分数。所提出的EC-IoU度量可以用于典型的评估过程，选择有更高安全性表现的物体检测器用于下游任务。它还可以集成到常见损失函数中进行模型微调。尽管面向安全性，但我们在KITTI数据集上的实验表明，使用EC-IoU训练的模型在均值平均精度方面的性能可能会优于使用IoU训练的变体。

    arXiv:2403.15474v1 Announce Type: cross  Abstract: This paper presents safety-oriented object detection via a novel Ego-Centric Intersection-over-Union (EC-IoU) measure, addressing practical concerns when applying state-of-the-art learning-based perception models in safety-critical domains such as autonomous driving. Concretely, we propose a weighting mechanism to refine the widely used IoU measure, allowing it to assign a higher score to a prediction that covers closer points of a ground-truth object from the ego agent's perspective. The proposed EC-IoU measure can be used in typical evaluation processes to select object detectors with higher safety-related performance for downstream tasks. It can also be integrated into common loss functions for model fine-tuning. While geared towards safety, our experiment with the KITTI dataset demonstrates the performance of a model trained on EC-IoU can be better than that of a variant trained on IoU in terms of mean Average Precision as well.
    
[^202]: 用ChatGPT增强编程教育：针对Python课程中学生感知和互动的案例研究

    Enhancing Programming Education with ChatGPT: A Case Study on Student Perceptions and Interactions in a Python Course

    [https://arxiv.org/abs/2403.15472](https://arxiv.org/abs/2403.15472)

    本研究探讨了将ChatGPT整合到Python编程课程中对学习的影响，揭示了学生对ChatGPT的积极态度，并提供了关于其在增强编程教育体验中作用的见解。

    

    ChatGPT作为一种支持性工具整合到教育中，特别是在编程课程中，通过提供调试、代码生成和解释方面的帮助，解决了编程教育的独特挑战。尽管已有研究验证了ChatGPT的有效性，但其在大学级别的编程教育中的应用以及学生互动和观点的详细理解仍有限。本文探讨了在为大一学生量身定制的Python编程课程中，在八周的时间内，ChatGPT对学习的影响。通过分析来自调查、开放性问题以及学生-ChatGPT对话数据的回应，我们旨在全面了解ChatGPT的实用性，并确定学生所感知的其优势和局限性。我们的研究揭示了学生对ChatGPT普遍持肯定态度，并提供了有关其在增强编程教育体验中的作用的见解。

    arXiv:2403.15472v1 Announce Type: cross  Abstract: The integration of ChatGPT as a supportive tool in education, notably in programming courses, addresses the unique challenges of programming education by providing assistance with debugging, code generation, and explanations. Despite existing research validating ChatGPT's effectiveness, its application in university-level programming education and a detailed understanding of student interactions and perspectives remain limited. This paper explores ChatGPT's impact on learning in a Python programming course tailored for first-year students over eight weeks. By analyzing responses from surveys, open-ended questions, and student-ChatGPT dialog data, we aim to provide a comprehensive view of ChatGPT's utility and identify both its advantages and limitations as perceived by students. Our study uncovers a generally positive reception toward ChatGPT and offers insights into its role in enhancing the programming education experience. These fin
    
[^203]: 使用展开算法为$n$-grams，Transformers，HMMs和马尔可夫链生成最有可能的序列

    Most Likely Sequence Generation for $n$-Grams, Transformers, HMMs, and Markov Chains, by Using Rollout Algorithms

    [https://arxiv.org/abs/2403.15465](https://arxiv.org/abs/2403.15465)

    本文介绍了一种使用展开算法为$n$-grams，Transformers，HMMs和马尔可夫链生成最有可能的序列的方法

    

    在本文中，我们考虑了一个具有$n$-gram结构的transformer，例如底层的ChatGPT。Transformer提供了下一个单词的概率，可以用来生成单词序列。我们考虑了基于这些概率计算高可能性单词序列的方法。计算从给定初始状态开始的最优（即最有可能）单词序列是一个棘手的问题，因此我们提出了在时间复杂度为$N$和$n$-gram词汇量的低阶多项式的方法来计算$N$个单词的高可能性序列。这些方法基于近似动态规划中的展开方法，一种单策略迭代，可以改善任何给定启发式策略的性能。在我们的情况下，我们使用一种贪婪启发式，生成具有最高概率的下一个单词。我们通过分析、示例和计算实验表明了我们的m

    arXiv:2403.15465v1 Announce Type: cross  Abstract: In this paper we consider a transformer with an $n$-gram structure, such as the one underlying ChatGPT. The transformer provides next word probabilities, which can be used to generate word sequences. We consider methods for computing word sequences that are highly likely, based on these probabilities. Computing the optimal (i.e., most likely) word sequence starting with a given initial state is an intractable problem, so we propose methods to compute highly likely sequences of $N$ words in time that is a low order polynomial in $N$ and in the vocabulary size of the $n$-gram. These methods are based on the rollout approach from approximate dynamic programming, a form of single policy iteration, which can improve the performance of any given heuristic policy. In our case we use a greedy heuristic that generates as next word one that has the highest probability. We show with analysis, examples, and computational experimentation that our m
    
[^204]: 基于LLMs的少样本疾病预测：结合预测性代理推理和批判性代理指导的新方法

    LLMs-based Few-Shot Disease Predictions using EHR: A Novel Approach Combining Predictive Agent Reasoning and Critical Agent Instruction

    [https://arxiv.org/abs/2403.15464](https://arxiv.org/abs/2403.15464)

    该论文提出了一种新方法，结合预测性代理推理和批判性代理指导，利用LLMs对结构化患者就诊数据进行预测，取得了较好的效果。

    

    arXiv:2403.15464v1 类型：跨学科 摘要：电子健康记录(EHRs)包含对健康相关预测任务，如疾病预测，有价值的患者数据。传统方法依赖于需要大量标记数据集的监督学习方法，这可能是昂贵和具有挑战性的。在本研究中，我们调查了将大型语言模型(LLMs)应用于将结构化患者就诊数据(例如诊断、实验室、处方)转换为自然语言叙述的可行性。我们使用各种面向EHR预测的提示策略评估了LLMs的零样本和少样本性能。此外，我们提出了一种新方法，利用具有不同角色的LLM代理：一个进行预测并生成推理过程的预测代理，以及分析不正确预测并为改善预测代理推理提供指导的批评代理。我们的结果表明，通过提出的方法，LLMs能够...

    arXiv:2403.15464v1 Announce Type: cross  Abstract: Electronic health records (EHRs) contain valuable patient data for health-related prediction tasks, such as disease prediction. Traditional approaches rely on supervised learning methods that require large labeled datasets, which can be expensive and challenging to obtain. In this study, we investigate the feasibility of applying Large Language Models (LLMs) to convert structured patient visit data (e.g., diagnoses, labs, prescriptions) into natural language narratives. We evaluate the zero-shot and few-shot performance of LLMs using various EHR-prediction-oriented prompting strategies. Furthermore, we propose a novel approach that utilizes LLM agents with different roles: a predictor agent that makes predictions and generates reasoning processes and a critic agent that analyzes incorrect predictions and provides guidance for improving the reasoning of the predictor agent. Our results demonstrate that with the proposed approach, LLMs c
    
[^205]: 走向值得信赖的人工智能之旅-第一部分：追求务实框架

    The Journey to Trustworthy AI- Part 1: Pursuit of Pragmatic Frameworks

    [https://arxiv.org/abs/2403.15457](https://arxiv.org/abs/2403.15457)

    本文回顾了值得信赖的人工智能（TAI）和其各种定义，主张不应将“负责任的”或“道德的”人工智能等术语视为TAI的替代，而是提倡以公平性、偏见、风险、安全性、可解释性和可靠性等关键属性为中心的方法，认识到地缘政治和地理原因导致的人工智能监管差异对跨国公司构成挑战。

    

    本文回顾了值得信赖的人工智能（TAI）及其各种定义。考虑到任何社会中尊重的原则，TAI通常被一些属性所特征，其中一些属性已导致监管或工程背景下的混淆。我们反对使用诸如“负责任的”或“道德的”人工智能等术语来替代TAI。为了帮助澄清任何混乱，我们建议将它们抛在脑后。鉴于TAI固有的主观性和复杂性，开发一个通用框架被认为是不可行的。相反，我们主张采取以公平性、偏见、风险、安全性、可解释性和可靠性等关键属性为中心的方法。我们审视了正在进行的监管环境，重点关注欧盟、中国和美国的倡议。我们认识到，基于地缘政治和地理原因而不同的人工智能监管对跨国公司构成额外挑战。

    arXiv:2403.15457v1 Announce Type: cross  Abstract: This paper reviews Trustworthy Artificial Intelligence (TAI) and its various definitions. Considering the principles respected in any society, TAI is often characterized by a few attributes, some of which have led to confusion in regulatory or engineering contexts. We argue against using terms such as Responsible or Ethical AI as substitutes for TAI. And to help clarify any confusion, we suggest leaving them behind. Given the subjectivity and complexity inherent in TAI, developing a universal framework is deemed infeasible. Instead, we advocate for approaches centered on addressing key attributes and properties such as fairness, bias, risk, security, explainability, and reliability. We examine the ongoing regulatory landscape, with a focus on initiatives in the EU, China, and the USA. We recognize that differences in AI regulations based on geopolitical and geographical reasons pose an additional challenge for multinational companies. 
    
[^206]: WoLF: 用于胸部X线图理解的大型语言模型框架

    WoLF: Large Language Model Framework for CXR Understanding

    [https://arxiv.org/abs/2403.15456](https://arxiv.org/abs/2403.15456)

    WoLF框架提出了对于CXR的全面理解的改进，包括使用额外的健康相关数据、重构报告以提供更有组织的信息、以及改进生成答案的细致评估。

    

    通过现代视觉语言模型(VLMs)取得了对胸部X线图(CXR)理解方面的显着方法进展，展示了令人印象深刻的视觉问答(VQA)和CXR报告生成能力。然而，现有的CXR理解框架仍存在几个程序上的缺陷。(1)以往的方法仅使用CXR报告，这对于全面的视觉问答(VQA)来说是不够的，特别是当需要额外的健康相关数据如用药历史和先前的诊断时。(2)以往的方法使用未经处理的CXR报告，这些报告往往结构随意。虽然现代语言模型可以理解各种文本格式，但为了提供更清晰、有组织的基于解剖学的信息，重构报告可能会增强它们的实用性。(3)目前用于CXR-VQA的评估方法主要强调语言正确性，缺乏对生成答案的微妙评估能力。

    arXiv:2403.15456v1 Announce Type: new  Abstract: Significant methodological strides have been made toward Chest X-ray (CXR) understanding via modern vision-language models (VLMs), demonstrating impressive Visual Question Answering (VQA) and CXR report generation abilities. However, existing CXR understanding frameworks still possess several procedural caveats. (1) Previous methods solely use CXR reports, which are insufficient for comprehensive Visual Question Answering (VQA), especially when additional health-related data like medication history and prior diagnoses are needed. (2) Previous methods use raw CXR reports, which are often arbitrarily structured. While modern language models can understand various text formats, restructuring reports for clearer, organized anatomy-based information could enhance their usefulness. (3) Current evaluation methods for CXR-VQA primarily emphasize linguistic correctness, lacking the capability to offer nuanced assessments of the generated answers.
    
[^207]: 面向跨度的信息抽取--信息抽取的统一视角

    Span-Oriented Information Extraction -- A Unifying Perspective on Information Extraction

    [https://arxiv.org/abs/2403.15453](https://arxiv.org/abs/2403.15453)

    提出了以文本中的跨度为中心的统一视角，将各种信息抽取任务重新定位为相同基本面向跨度的信息抽取任务的变体

    

    arXiv:2403.15453v1 公告类型: 跨 当前摘要: 信息抽取指的是自然语言处理（NLP）中的一系列任务，其目的是识别文本中的子序列及其标签。这些任务多年来被用于提取相关信息并将自由文本链接到结构化数据。然而，信息抽取任务之间的异质性妨碍了该领域的进展。因此，我们提出了一个以文本中的跨度为中心的统一视角。我们将这些看似不协调的任务重新定位到这一统一视角中，并将各种信息抽取任务呈现为相同基本面向跨度的信息抽取任务的变体。

    arXiv:2403.15453v1 Announce Type: cross  Abstract: Information Extraction refers to a collection of tasks within Natural Language Processing (NLP) that identifies sub-sequences within text and their labels. These tasks have been used for many years to link extract relevant information and to link free text to structured data. However, the heterogeneity among information extraction tasks impedes progress in this area. We therefore offer a unifying perspective centered on what we define to be spans in text. We then re-orient these seemingly incongruous tasks into this unified perspective and then re-present the wide assortment of information extraction tasks as variants of the same basic Span-Oriented Information Extraction task.
    
[^208]: 工具究竟是什么？从语言模型的视角进行的调查

    What Are Tools Anyway? A Survey from the Language Model Perspective

    [https://arxiv.org/abs/2403.15452](https://arxiv.org/abs/2403.15452)

    从语言模型的角度出发，本调查提供了工具的统一定义为LMs使用的外部程序，并对LM工具场景和方法进行了系统审查，同时通过实证研究了解了各种工具方法的效率，以及突出了该领域的挑战和未来研究方向。

    

    语言模型（LMs）在文本生成任务中非常强大。工具显著增强了LMs在需要复杂技能的任务中的性能。然而，许多研究以不同方式使用"工具"一词，引发了一个问题：工具究竟是什么？接下来，工具在哪里以及如何帮助LMs？在这项调查中，我们提出了一种工具的统一定义，即LMs使用的外部程序，并对LM工具场景和方法进行系统性审查。基于这一审查，我们通过测量各种工具方法在各种基准测试上所需的计算和性能增益来实证研究它们的效率，并突出了该领域的一些挑战和潜在未来研究。

    arXiv:2403.15452v1 Announce Type: cross  Abstract: Language models (LMs) are powerful yet mostly for text generation tasks. Tools have substantially enhanced their performance for tasks that require complex skills. However, many works adopt the term "tool" in different ways, raising the question: What is a tool anyway? Subsequently, where and how do tools help LMs? In this survey, we provide a unified definition of tools as external programs used by LMs, and perform a systematic review of LM tooling scenarios and approaches. Grounded on this review, we empirically study the efficiency of various tooling methods by measuring their required compute and performance gains on various benchmarks, and highlight some challenges and potential future research in the field.
    
[^209]: 憎恨源于无知！对抗会话性仇恨言论中说服方式的提炼

    Hatred Stems from Ignorance! Distillation of the Persuasion Modes in Countering Conversational Hate Speech

    [https://arxiv.org/abs/2403.15449](https://arxiv.org/abs/2403.15449)

    研究研究了对抗在线仇恨言论的最佳方法，通过分析对话中的理由、情感和信誉等说服方式，对比封闭和开放交互中的不同行为和话题层面，发现了在对抗言论中的微妙差异。

    

    研究对抗言论使用的因素是理解在线对抗仇恨言论的最佳方法的核心。各种研究评估对抗言论中使用的情感基础因素，如情感共鸣、冒犯程度和敌意程度。为了更好地理解会话交互中使用的对抗言论，本研究将说服方式分解为理由、情感和信誉，然后评估它们在涉及种族主义、性别歧视和宗教问题的两种对话交互类型中的使用。评估涵盖了人类与生成对抗言论的不同行为。我们还评估了回复的立场与每种对抗言论中的说服方式之间的相互作用。值得注意的是，我们观察到了在开放和封闭交互的对抗言论说服方式上的微妙差异 -- 尤其是在话题层面上。

    arXiv:2403.15449v1 Announce Type: cross  Abstract: Examining the factors that the counter-speech uses is at the core of understanding the optimal methods for confronting hate speech online. Various studies assess the emotional base factor used in counter speech, such as emotion-empathy, offensiveness, and level of hostility. To better understand the counter-speech used in conversational interactions, this study distills persuasion modes into reason, emotion, and credibility and then evaluates their use in two types of conversation interactions: closed (multi-turn) and open (single-turn) conversation interactions concerning racism, sexism, and religion. The evaluation covers the distinct behaviors of human versus generated counter-speech. We also assess the interplay between the replies' stance and each mode of persuasion in the counter-speech. Notably, we observe nuanced differences in the counter-speech persuasion modes for open and closed interactions -- especially on the topic level
    
[^210]: 解码压缩的信任：审视在压缩下高效LLMs的可信度

    Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs Under Compression

    [https://arxiv.org/abs/2403.15447](https://arxiv.org/abs/2403.15447)

    量化目前比剪枝更有效，可以同时实现效率和可信度，但剪枝会显著降低模型的可信度

    

    将高性能的大型语言模型（LLMs）压缩已经成为一种资源高效推断的首选策略。尽管最先进的压缩方法在保留良性任务性能方面取得了令人印象深刻的进展，但压缩在安全性和可信度方面的潜在风险在很大程度上被忽视。这项研究对使用五种最先进压缩技术评估三种领先LLMs的可信度维度进行了首次彻底评估。我们的实验突出了压缩与可信度之间复杂的相互作用，揭示了一些有趣的模式。我们发现，目前量化比剪枝更有效地同时实现效率和可信度。例如，4位量化模型保留了其原始对应物的可信度，但模型剪枝显著降低了可信度，即使在50%的稀疏度下。

    arXiv:2403.15447v1 Announce Type: cross  Abstract: Compressing high-capability Large Language Models (LLMs) has emerged as a favored strategy for resource-efficient inferences. While state-of-the-art (SoTA) compression methods boast impressive advancements in preserving benign task performance, the potential risks of compression in terms of safety and trustworthiness have been largely neglected. This study conducts the first, thorough evaluation of three (3) leading LLMs using five (5) SoTA compression techniques across eight (8) trustworthiness dimensions. Our experiments highlight the intricate interplay between compression and trustworthiness, revealing some interesting patterns. We find that quantization is currently a more effective approach than pruning in achieving efficiency and trustworthiness simultaneously. For instance, a 4-bit quantized model retains the trustworthiness of its original counterpart, but model pruning significantly degrades trustworthiness, even at 50% spars
    
[^211]: 通过ARIMA时间序列分析揭示社交网络上的多语言主题动态和趋势识别：LDA/HDP模型增强的新型数据翻译框架

    Decoding Multilingual Topic Dynamics and Trend Identification through ARIMA Time Series Analysis on Social Networks: A Novel Data Translation Framework Enhanced by LDA/HDP Models

    [https://arxiv.org/abs/2403.15445](https://arxiv.org/abs/2403.15445)

    该研究提出了一种新方法，通过ARIMA时间序列分析和LDA/HDP模型提取多语言社交网络中的主题动态，特别关注在危机期间的交流趋势，这一方法在语言一致性任务中表现出色。

    

    在这项研究中，作者提出了一种新的方法，能够破译多语言主题动态，并识别危机期间的交流趋势。我们关注突尼斯社交网络中在冠状病毒大流行期间以及其他显著主题（如体育和政治）中的对话。我们首先对与这些主题相关的各种多语言评论进行聚合。然后在数据预处理过程中对数据集进行了严格的精炼。我们引入我们的无英语到英语的机器翻译方法来处理语言差异。对这种方法的实证测试显示了很高的准确性和F1值，突显了它适用于语言一致任务的特点。深入研究，采用了先进的建模技术，特别是LDA和HDP模型，从翻译内容中提取相关主题。这导致应用ARIMA时间序列分析来解码不断变化的主题趋势。

    arXiv:2403.15445v1 Announce Type: cross  Abstract: In this study, the authors present a novel methodology adept at decoding multilingual topic dynamics and identifying communication trends during crises. We focus on dialogues within Tunisian social networks during the Coronavirus Pandemic and other notable themes like sports and politics. We start by aggregating a varied multilingual corpus of comments relevant to these subjects. This dataset undergoes rigorous refinement during data preprocessing. We then introduce our No-English-to-English Machine Translation approach to handle linguistic differences. Empirical tests of this method showed high accuracy and F1 scores, highlighting its suitability for linguistically coherent tasks. Delving deeper, advanced modeling techniques, specifically LDA and HDP models are employed to extract pertinent topics from the translated content. This leads to applying ARIMA time series analysis to decode evolving topic trends. Applying our method to a mu
    
[^212]: 基于IMU的跨模态迁移学习在人类活动识别中的调查

    A Survey of IMU Based Cross-Modal Transfer Learning in Human Activity Recognition

    [https://arxiv.org/abs/2403.15444](https://arxiv.org/abs/2403.15444)

    本篇论文调查了如何在人类活动/动作识别中实现跨模态迁移学习，探讨了IMU数据在此领域中的潜在应用，对HAR问题进行了重要性探讨，并比较了不同类型的多模态HAR数据集。

    

    尽管生活在一个多感知世界中，大多数人工智能模型仍然局限于对人体运动和行为的文本和视觉理解。事实上，对人类运动的完整情境意识最好是通过传感器的组合来理解。在本调查中，我们研究了如何在人类活动/动作识别（HAR）中跨模态迁移学习中传递和利用知识。我们阐述了IMU数据及其在跨模态学习中的适用性的重要性和潜力，以及研究HAR问题的重要性。我们通过时间和抽象性将HAR相关任务进行了分类，然后比较了各种类型的多模态HAR数据集。我们还区分和详细阐述了文献中许多相关但不一致使用的术语，如迁移学习、域自适应、表示学习、传感器融合和多模态学习，并描述了跨模态学习如何适应。

    arXiv:2403.15444v1 Announce Type: cross  Abstract: Despite living in a multi-sensory world, most AI models are limited to textual and visual understanding of human motion and behavior. In fact, full situational awareness of human motion could best be understood through a combination of sensors. In this survey we investigate how knowledge can be transferred and utilized amongst modalities for Human Activity/Action Recognition (HAR), i.e. cross-modality transfer learning. We motivate the importance and potential of IMU data and its applicability in cross-modality learning as well as the importance of studying the HAR problem. We categorize HAR related tasks by time and abstractness and then compare various types of multimodal HAR datasets. We also distinguish and expound on many related but inconsistently used terms in the literature, such as transfer learning, domain adaptation, representation learning, sensor fusion, and multimodal learning, and describe how cross-modal learning fits w
    
[^213]: 引入一种集成方法，通过分析PET扫描图像早期检测阿尔茨海默病

    Introducing an ensemble method for the early detection of Alzheimer's disease through the analysis of PET scan images

    [https://arxiv.org/abs/2403.15443](https://arxiv.org/abs/2403.15443)

    通过分析PET扫描图像，引入了一种集成方法早期检测阿尔茨海默病，并且在分类阿尔茨海默病时使用了多种深度学习和传统机器学习模型。

    

    阿尔茨海默病是一种逐渐恶化的神经退行性疾病，主要影响记忆、思维和行为等认知功能。本病存在一个关键阶段，即轻度认知障碍，非常重要尽早诊断，因为一些逐渐发展为病症的MCI患者会发展为这种疾病。本研究探讨了将阿尔茨海默病分类为四个不同组：控制正常（CN）、逐渐发展的轻度认知障碍（pMCI）、稳定的轻度认知障碍（sMCI）和阿尔茨海默病（AD）的具有挑战性的任务。这种分类是基于对从ADNI数据集获得的PET扫描图像的彻底检查，这提供了对疾病进展的彻底理解。已经使用了几种深度学习和传统机器学习模型来检测阿尔茨海默病。在本文中，使用了三种深度学习模型，即VGG16、AlexNet和自定义的卷积神经网络。

    arXiv:2403.15443v1 Announce Type: cross  Abstract: Alzheimer's disease is a progressive neurodegenerative disorder that primarily affects cognitive functions such as memory, thinking, and behavior. In this disease, there is a critical phase, mild cognitive impairment, that is really important to be diagnosed early since some patients with progressive MCI will develop the disease. This study delves into the challenging task of classifying Alzheimer's disease into four distinct groups: control normal (CN), progressive mild cognitive impairment (pMCI), stable mild cognitive impairment (sMCI), and Alzheimer's disease (AD). This classification is based on a thorough examination of PET scan images obtained from the ADNI dataset, which provides a thorough understanding of the disease's progression. Several deep-learning and traditional machine-learning models have been used to detect Alzheimer's disease. In this paper, three deep-learning models, namely VGG16 and AlexNet, and a custom Convolu
    
[^214]: 人工智能在耳蜗植入装置中的先进算法：医疗策略、挑战和展望综述

    Advanced Artificial Intelligence Algorithms in Cochlear Implants: Review of Healthcare Strategies, Challenges, and Perspectives

    [https://arxiv.org/abs/2403.15442](https://arxiv.org/abs/2403.15442)

    人工智能在提高植入式听觉设备的语音质量方面具有前瞻性，并通过先进的信号处理技术以及应对多源语音和环境噪音挑战等方法来克服语音失真问题

    

    arXiv:2403.15442v1 公告类型: 跨领域 摘要: 自动语音识别（ASR）在我们的日常生活中发挥着至关重要的作用，不仅为与机器交互提供了便利，还为部分或完全听力受损的个体提供了沟通的机会。这一过程涉及以模拟形式接收语音信号，然后通过各种信号处理算法使其与容量有限的设备（如CI）兼容。然而，这些配备有有限数量电极的植入装置在合成过程中往往导致语音失真。尽管研究人员在使用各种最先进的信号处理技术改善接收到的语音质量方面做出了努力，但在涉及多个语音源、环境噪声和其他情况的场景中，挑战仍然存在。新人工智能（AI）方法的出现引入了先进的策略来解决这些限制。

    arXiv:2403.15442v1 Announce Type: cross  Abstract: Automatic speech recognition (ASR) plays a pivotal role in our daily lives, offering utility not only for interacting with machines but also for facilitating communication for individuals with either partial or profound hearing impairments. The process involves receiving the speech signal in analogue form, followed by various signal processing algorithms to make it compatible with devices of limited capacity, such as cochlear implants (CIs). Unfortunately, these implants, equipped with a finite number of electrodes, often result in speech distortion during synthesis. Despite efforts by researchers to enhance received speech quality using various state-of-the-art signal processing techniques, challenges persist, especially in scenarios involving multiple sources of speech, environmental noise, and other circumstances. The advent of new artificial intelligence (AI) methods has ushered in cutting-edge strategies to address the limitations
    
[^215]: 统一生成建模：基于贝叶斯流网络的3D分子

    Unified Generative Modeling of 3D Molecules via Bayesian Flow Networks

    [https://arxiv.org/abs/2403.15441](https://arxiv.org/abs/2403.15441)

    本文引入了Geometric Bayesian Flow Networks (GeoBFN)，通过在分布的可微分参数空间中对不同模态进行建模，实现了对多模态性和噪声敏感性的分子几何形状的自然拟合。GeoBFN通过优化的训练和采样技术，在多个3D分子生成基准上取得了最先进的性能。

    

    先进的生成模型（例如扩散模型）源自对数据分布的简化连续性假设，尽管显示出了良好的进展，但由于分子几何的多模态性和对噪声敏感的特性，很难直接应用于几何生成应用。本文引入了几何贝叶斯流网络（GeoBFN），通过在可微分参数空间中建模不同模态，自然地适配分子几何形状。GeoBFN通过在分布参数上合成移变相互依赖建模，保持了SE-(3)不变密度建模属性，并统一了不同模态的概率建模。通过优化的训练和采样技术，我们展示了GeoBFN在多个3D分子生成基准中取得了最先进的性能，最大限度地提高了生成质量（在QM9中稳定生成90.87%的分子，在原子方面稳定生成85.6%）

    arXiv:2403.15441v1 Announce Type: cross  Abstract: Advanced generative model (e.g., diffusion model) derived from simplified continuity assumptions of data distribution, though showing promising progress, has been difficult to apply directly to geometry generation applications due to the multi-modality and noise-sensitive nature of molecule geometry. This work introduces Geometric Bayesian Flow Networks (GeoBFN), which naturally fits molecule geometry by modeling diverse modalities in the differentiable parameter space of distributions. GeoBFN maintains the SE-(3) invariant density modeling property by incorporating equivariant inter-dependency modeling on parameters of distributions and unifying the probabilistic modeling of different modalities. Through optimized training and sampling techniques, we demonstrate that GeoBFN achieves state-of-the-art performance on multiple 3D molecule generation benchmarks in terms of generation quality (90.87% molecule stability in QM9 and 85.6% atom
    
[^216]: 在计算不透明时代的先验知识：人工智能在数学发现中的作用

    Apriori Knowledge in an Era of Computational Opacity: The Role of AI in Mathematical Discovery

    [https://arxiv.org/abs/2403.15437](https://arxiv.org/abs/2403.15437)

    通过给现代人工智能模型添加自动化人类形式的证明检查器，我们可以从它们那里获取先验数学知识，即使这些机器完全对我们不透明。

    

    计算在当代数学中起着核心作用。许多人认为，我们可以从Appel和Haken的程序中获得四色定理的真正数学知识，因为这只是一种重复应用人类形式的数学推理。然而，相比之下，现代LLMs / DNNs在很大程度上对我们不透明，这在从它们那里获取数学知识方面产生了障碍。我们认为，如果给这些机器添加自动化人类形式的证明检查器，那么我们可以从中获得先验数学知识，即使原始机器对我们完全不透明，它们输出的证明也无法由人类查看。

    arXiv:2403.15437v1 Announce Type: new  Abstract: Computation is central to contemporary mathematics. Many accept that we can acquire genuine mathematical knowledge of the Four Color Theorem from Appel and Haken's program insofar as it is simply a repetitive application of human forms of mathematical reasoning. Modern LLMs / DNNs are, by contrast, opaque to us in significant ways, and this creates obstacles in obtaining mathematical knowledge from them. We argue, however, that if a proof-checker automating human forms of proof-checking is attached to such machines, then we can obtain apriori mathematical knowledge from them, even though the original machines are entirely opaque to us and the proofs they output are not human-surveyable.
    
[^217]: ChatPattern: 利用自然语言进行布局模式定制

    ChatPattern: Layout Pattern Customization via Natural Language

    [https://arxiv.org/abs/2403.15434](https://arxiv.org/abs/2403.15434)

    ChatPattern利用大语言模型（LLM）的框架实现了灵活的布局模式定制，能够通过自然语言要求生成高质量大规模模式。

    

    现有的作品主要集中在生成固定大小的布局模式，而更实用的自由大小模式生成受到了有限的关注。在本文中，我们提出了ChatPattern，这是一个新颖的基于大语言模型（LLM）的框架，用于灵活的模式定制。ChatPattern利用一个包含专家LLM代理和一个高度可控的布局模式生成器的双部分系统。LLM代理可以解释自然语言要求并操作设计工具以满足指定需求，而生成器擅长于条件布局生成、模式修改和内存友好型模式扩展。在具有挑战性的模式生成设置上的实验表明了ChatPattern合成高质量大规模模式的能力。

    arXiv:2403.15434v1 Announce Type: cross  Abstract: Existing works focus on fixed-size layout pattern generation, while the more practical free-size pattern generation receives limited attention. In this paper, we propose ChatPattern, a novel Large-Language-Model (LLM) powered framework for flexible pattern customization. ChatPattern utilizes a two-part system featuring an expert LLM agent and a highly controllable layout pattern generator. The LLM agent can interpret natural language requirements and operate design tools to meet specified needs, while the generator excels in conditional layout generation, pattern modification, and memory-friendly patterns extension. Experiments on challenging pattern generation setting shows the ability of ChatPattern to synthesize high-quality large-scale patterns.
    
[^218]: HyPer-EP: 为心脏电生理而元学习的混合个性化模型

    HyPer-EP: Meta-Learning Hybrid Personalized Models for Cardiac Electrophysiology

    [https://arxiv.org/abs/2403.15433](https://arxiv.org/abs/2403.15433)

    提出了一个新颖的混合建模框架，结合了基于物理已知表达式和神经网络建模的元学习方法，用于描述个性化心脏数字孪生模型，实现了基于物理和神经网络组件的分离识别。

    

    个性化虚拟心脏模型在临床上展示出越来越大的潜力，尽管在给定患者特定数据的情况下估计其参数仍然是一个挑战。传统的基于物理的建模方法在计算上成本高昂，往往忽视了这些模型中的结构性错误，这是由于模型简化和假设所造成的。另一方面，现代深度学习方法依赖于数据监督，并且缺乏可解释性。在本文中，我们提出了一个新颖的混合建模框架，将个性化心脏数字孪生描述为基于物理已知表达式和神经网络建模未知与现实之间差距的组合。然后，我们提出了一个新颖的元学习框架，以实现混合模型中基于物理和神经网络组件的分离识别。我们展示了这种混合建模框架的可行性和普适性。

    arXiv:2403.15433v1 Announce Type: cross  Abstract: Personalized virtual heart models have demonstrated increasing potential for clinical use, although the estimation of their parameters given patient-specific data remain a challenge. Traditional physics-based modeling approaches are computationally costly and often neglect the inherent structural errors in these models due to model simplifications and assumptions. Modern deep learning approaches, on the other hand, rely heavily on data supervision and lacks interpretability. In this paper, we present a novel hybrid modeling framework to describe a personalized cardiac digital twin as a combination of a physics-based known expression augmented by neural network modeling of its unknown gap to reality. We then present a novel meta-learning framework to enable the separate identification of both the physics-based and neural components in the hybrid model. We demonstrate the feasibility and generality of this hybrid modeling framework with 
    
[^219]: BRIEDGE: EEG自适应边缘人工智能用于多脑到多机器人交互

    BRIEDGE: EEG-Adaptive Edge AI for Multi-Brain to Multi-Robot Interaction

    [https://arxiv.org/abs/2403.15432](https://arxiv.org/abs/2403.15432)

    BRIEDGE提出了一个用于多脑到多机器人交互的端到端系统，通过 EEG 自适应神经网络和编解码通信框架实现，引入了基于Informer的ProbSparse自注意机制以提高分类准确性。

    

    最近 EEG 基于脑机接口技术的进展揭示了通过整合传感、计算、通信和控制实现脑到机器人协作的潜力。在本文中，我们介绍了 BRIEDGE 作为一个端到端系统，用于通过 EEG 自适应神经网络和编解码通信框架实现多脑到多机器人交互，如图1所示。正如所描绘的那样，边缘移动服务器或边缘便携服务器将从用户收集 EEG 数据，并利用 EEG 自适应神经网络识别用户的意图。编解码通信框架然后对 EEG 基础的语义信息进行编码，并在数据传输过程中解码成命令。为了更好地提取异质 EEG 数据的联合特征以及增强分类准确性，BRIEDGE 引入了一种基于 Informer 的 ProbSparse 自注意机制。同时，平行和安全的进行转移。

    arXiv:2403.15432v1 Announce Type: cross  Abstract: Recent advances in EEG-based BCI technologies have revealed the potential of brain-to-robot collaboration through the integration of sensing, computing, communication, and control. In this paper, we present BRIEDGE as an end-to-end system for multi-brain to multi-robot interaction through an EEG-adaptive neural network and an encoding-decoding communication framework, as illustrated in Fig.1. As depicted, the edge mobile server or edge portable server will collect EEG data from the users and utilize the EEG-adaptive neural network to identify the users' intentions. The encoding-decoding communication framework then encodes the EEG-based semantic information and decodes it into commands in the process of data transmission. To better extract the joint features of heterogeneous EEG data as well as enhance classification accuracy, BRIEDGE introduces an informer-based ProbSparse self-attention mechanism. Meanwhile, parallel and secure trans
    
[^220]: 教育环境下集成强先验模块和数据重叠估计的三阶段SFT混合模型

    A Three-Phases SFT Hybrid Model Integrated Strong Prior Module and Data Overlap Estimation in the Eduation Context

    [https://arxiv.org/abs/2403.15426](https://arxiv.org/abs/2403.15426)

    提出了一种在教育领域中应用的三阶段监督微调模型，通过先验和数据重叠估计实现了教育知识的结构拆卸和增量引导输出。

    

    在本文中，我们提出了一种端到端基于先验的三阶段监督微调模型，证明比传统微调方法更有竞争力。具体而言，我们的模型实现了教育知识的结构拆卸和增量引导输出。为此，我们通过采样器和重叠估计神经网络对三种类型的数据进行了健壮的分类，将预处理数据集分三批注入预训练模型进行LORA微调。然后，我们设计了一个先验模块，将系统提示、向量数据库和抽象语法树任务分割相结合。最后，对基于先验的微调模型应用了压缩方法和正则化约束，随后在输出端进行文本过滤以获得增量引导结果。我们的模型代表了真正以丰富的教育知识、分步指导的特点体现导师角色的第一项研究努力。

    arXiv:2403.15426v1 Announce Type: cross  Abstract: In this paper, we propose an end-to-end prior-based three-phases supervised fine-tuned model, which is proved more competitive than traditional fine-tuning method. More specifically, our model realizes the structural disassembly and incremental guided output of educational knowledge. To this end, we robustify data classification of three types via a sampler and overlap estimation neural network, and inject the preprocessing datasets into pre-trained model in three batches for LORA fine-tuning. Then, we design a prior module couples system prompt, vector databases, and abstract syntax tree task segmentation. Finally, the compression method and regularization constraint are applied to the prior-based fine-tuned model, followed by text filter at the output end to obtain incremental guided results. Our model represents the first research effort to truly embody the tutor role with the features of abundant educational knowledge, step-by-step
    
[^221]: 使用具有时间关系信息的深度领域自适应进行跨用户活动识别

    Cross-user activity recognition using deep domain adaptation with temporal relation information

    [https://arxiv.org/abs/2403.15424](https://arxiv.org/abs/2403.15424)

    该论文提出了Deep Temporal State Domain Adaptation（DTSDA）模型，用于处理跨用户活动识别中的行为变异挑战。

    

    人类活动识别（HAR）是普适计算的基石，具有在健康监测和环境辅助生活等多个领域中有前景的应用。尽管取得了显著进展，基于传感器的HAR方法通常在训练和测试数据具有相同分布的假设下运作。然而，在许多现实场景中，特别是在基于传感器的HAR中，这一假设因分布之外的挑战而无效，包括来自异构传感器的差异、随时间变化以及个体行为变异。本文聚焦于后者，探索跨用户HAR问题，其中个体之间的行为变异导致不同数据分布。为了解决这一挑战，我们提出了Deep Temporal State Domain Adaptation（DTSDA）模型，这是一种为跨用户HAR中的时间序列领域自适应量身定制的创新方法。

    arXiv:2403.15424v1 Announce Type: cross  Abstract: Human Activity Recognition (HAR) is a cornerstone of ubiquitous computing, with promising applications in diverse fields such as health monitoring and ambient assisted living. Despite significant advancements, sensor-based HAR methods often operate under the assumption that training and testing data have identical distributions. However, in many real-world scenarios, particularly in sensor-based HAR, this assumption is invalidated by out-of-distribution ($\displaystyle o.o.d.$) challenges, including differences from heterogeneous sensors, change over time, and individual behavioural variability. This paper centres on the latter, exploring the cross-user HAR problem where behavioural variability across individuals results in differing data distributions. To address this challenge, we introduce the Deep Temporal State Domain Adaptation (DTSDA) model, an innovative approach tailored for time series domain adaptation in cross-user HAR. Con
    
[^222]: 基于时间关系最优输运的跨用户活动识别

    Cross-user activity recognition via temporal relation optimal transport

    [https://arxiv.org/abs/2403.15423](https://arxiv.org/abs/2403.15423)

    本文提出了一种基于时间关系最优输运的跨用户活动识别方法，旨在解决现有基于i.i.d.假设的域自适应方法在时间序列数据中的局限性

    

    当前关于人类活动识别（HAR）的研究主要假设训练和测试数据来自相同分布，以实现泛化模型，这意味着所有数据被认为是独立和同分布（i.i.d.）。在许多实际应用中，这一假设不成立，收集的训练和目标测试数据集具有不均匀分布，如跨用户HAR的情况。域自适应是跨用户HAR任务的一种有前途的方法。现有的基于域自适应的工作基于每个域中的样本是i.i.d.的假设，并且不考虑时间序列数据中隐藏的时间关系知识以对齐数据分布。这一关于i.i.d.的强假设对于基于时间序列的域自适应方法可能不太适用，因为时间序列细分和特征形成的样本

    arXiv:2403.15423v1 Announce Type: cross  Abstract: Current research on human activity recognition (HAR) mainly assumes that training and testing data are drawn from the same distribution to achieve a generalised model, which means all the data are considered to be independent and identically distributed $\displaystyle (i.i.d.) $. In many real-world applications, this assumption does not hold, and collected training and target testing datasets have non-uniform distribution, such as in the case of cross-user HAR. Domain adaptation is a promising approach for cross-user HAR tasks. Existing domain adaptation works based on the assumption that samples in each domain are $\displaystyle i.i.d. $ and do not consider the knowledge of temporal relation hidden in time series data for aligning data distribution. This strong assumption of $\displaystyle i.i.d. $ may not be suitable for time series-related domain adaptation methods because the samples formed by time series segmentation and feature e
    
[^223]: 基于传感器的人体活动识别中的数据异质性机器学习技术--综述

    Machine Learning Techniques for Sensor-based Human Activity Recognition with Data Heterogeneity -- A Review

    [https://arxiv.org/abs/2403.15422](https://arxiv.org/abs/2403.15422)

    通过研究机器学习如何处理传感器数据异质性，能够改善人体活动识别系统的性能，降低计算成本，更快地开发出个性化的自适应模型。

    

    arXiv:2403.15422v1 公告类型: 跨领域 摘要: 基于传感器的人体活动识别（HAR）在普适计算中至关重要，通过多维观察分析行为。 尽管研究取得了进展，HAR面临挑战，特别是在数据分布假设方面。 大多数研究通常假设各个数据集之间具有均匀的数据分布，与实际传感器数据在人类活动中的多样性相矛盾。 解决数据异质性问题可以提高性能，降低计算成本，并有助于开发个性化、自适应模型，减少标注数据。 本综述研究了机器学习如何处理HAR中的数据异质性，通过对数据异质性类型进行分类、应用相应的适当机器学习方法、总结可用数据集，并讨论未来挑战。

    arXiv:2403.15422v1 Announce Type: cross  Abstract: Sensor-based Human Activity Recognition (HAR) is crucial in ubiquitous computing, analysing behaviours through multi-dimensional observations. Despite research progress, HAR confronts challenges, particularly in data distribution assumptions. Most studies often assume uniform data distributions across datasets, contrasting with the varied nature of practical sensor data in human activities. Addressing data heterogeneity issues can improve performance, reduce computational costs, and aid in developing personalized, adaptive models with less annotated data. This review investigates how machine learning addresses data heterogeneity in HAR, by categorizing data heterogeneity types, applying corresponding suitable machine learning methods, summarizing available datasets, and discussing future challenges.
    
[^224]: 在二阶优化中模糊超参数更新的研究

    Fuzzy hyperparameters update in a second order optimization

    [https://arxiv.org/abs/2403.15416](https://arxiv.org/abs/2403.15416)

    介绍了一种在二阶优化中加速收敛的混合方法，利用在线有限差分逼近对角Hessian矩阵，并应用模糊推理于多个超参数。

    

    本研究将提出一种混合方法，以加速二阶优化中的收敛速度。将介绍对角Hessian矩阵的在线有限差分逼近，以及对几个超参数进行模糊推理。已取得竞争性成果。

    arXiv:2403.15416v1 Announce Type: cross  Abstract: This research will present a hybrid approach to accelerate convergence in a second order optimization. An online finite difference approximation of the diagonal Hessian matrix will be introduced, along with fuzzy inferencing of several hyperparameters. Competitive results have been achieved
    
[^225]: 玩转神经科学：神经影像学与游戏的过去、现在和未来

    Playing With Neuroscience: Past, Present and Future of Neuroimaging and Games

    [https://arxiv.org/abs/2403.15413](https://arxiv.org/abs/2403.15413)

    视频游戏作为研究领域的催化剂已取得很大进展，本文将分析神经科学与游戏的现状，并展望未来方向。

    

    视频游戏已经成为许多研究领域的进步催化剂，例如人工智能、人机交互或虚拟现实。多年来，人工智能等领域的研究已经使得设计出新型游戏成为可能，而游戏经常被用作测试和模拟的强大工具。神经科学与游戏研究之间的当前关系如何？未来我们可以期待什么？在本文中，我们将试图回答这些问题，分析神经科学与游戏的交叉领域的现状，并设想未来的方向。

    arXiv:2403.15413v1 Announce Type: cross  Abstract: Videogames have been a catalyst for advances in many research fields, such as artificial intelligence, human-computer interaction or virtual reality. Over the years, research in fields such as artificial intelligence has enabled the design of new types of games, while games have often served as a powerful tool for testing and simulation. Can this also happen with neuroscience? What is the current relationship between neuroscience and games research? what can we expect from the future? In this article, we'll try to answer these questions, analysing the current state-of-the-art at the crossroads between neuroscience and games and envisioning future directions.
    
[^226]: 在LLMs中测量和建模“文化”：一项调查

    Towards Measuring and Modeling "Culture" in LLMs: A Survey

    [https://arxiv.org/abs/2403.15412](https://arxiv.org/abs/2403.15412)

    这项研究调查了39篇最新论文，旨在研究大型语言模型中的文化表达和包容性，发现当前研究未对“文化”进行定义，而是在特定设计的数据集上对模型进行探究，研究了某些“文化”的方面，留下许多未被探究的有趣和重要方面，如语义领域和关于性。

    

    我们呈现了对39篇最新论文的调查，旨在研究大型语言模型中的文化表达和包容性。我们观察到，没有一篇研究定义“文化”，这是一个复杂、多层面的概念；相反，它们在一些特别设计的数据集上对模型进行探究，这些数据集代表了某些“文化”的方面。我们将这些方面称为文化的代理，并将它们组织在人口统计、语义和语言文化交互代理的三个维度上。我们还对采用的探查方法进行了分类。我们的分析表明，只有“文化”的某些方面，如价值观和目标，被研究了，留下了几个其他有趣且重要的方面，特别是大量语义领域和关于性（Hershcovich等人，2022）的未被探究。另外两个关键的空白是目前方法的鲁棒性和情境性的缺乏。基于这些观察结果，

    arXiv:2403.15412v1 Announce Type: cross  Abstract: We present a survey of 39 recent papers that aim to study cultural representation and inclusion in large language models. We observe that none of the studies define "culture," which is a complex, multifaceted concept; instead, they probe the models on some specially designed datasets which represent certain aspects of "culture." We call these aspects the proxies of cultures, and organize them across three dimensions of demographic, semantic and linguistic-cultural interaction proxies. We also categorize the probing methods employed. Our analysis indicates that only certain aspects of "culture," such as values and objectives, have been studied, leaving several other interesting and important facets, especially the multitude of semantic domains (Thompson et al., 2020) and aboutness (Hershcovich et al., 2022), unexplored. Two other crucial gaps are the lack of robustness and situatedness of the current methods. Based on these observations
    
[^227]: 基于短时ECG和采样长期HRV的多模态心力衰竭风险评估

    Multi-modal Heart Failure Risk Estimation based on Short ECG and Sampled Long-Term HRV

    [https://arxiv.org/abs/2403.15408](https://arxiv.org/abs/2403.15408)

    提出了结合30秒ECG记录和长期HRV数据的多模态方法用于估算心力衰竭住院风险，并引入了两种生存模型：XGBoost模型和ResNet模型。

    

    心血管疾病，包括心力衰竭（HF），仍然是全球主要的死亡原因，常常难以早期检测。在此背景下，可访问和有效的风险评估是不可或缺的。传统方法依赖于资源密集型的诊断测试，通常在症状发作后进行。心电图（ECG）技术的广泛可用性和机器学习的力量正成为智能医疗领域的可行替代方案。在本文中，我们提出了几种多模态方法，结合30秒ECG记录和近似的长期心率变异性（HRV）数据，来估算HF住院风险。我们引入了两种生存模型：一个XGBoost模型，用于加速失败时间（AFT），结合了全面的ECG特征；以及一个从原始ECG中学习的ResNet模型。我们通过我们从超级长期HRV中提取的新颖长期HRVs来扩展这些模型。

    arXiv:2403.15408v1 Announce Type: cross  Abstract: Cardiovascular diseases, including Heart Failure (HF), remain a leading global cause of mortality, often evading early detection. In this context, accessible and effective risk assessment is indispensable. Traditional approaches rely on resource-intensive diagnostic tests, typically administered after the onset of symptoms. The widespread availability of electrocardiogram (ECG) technology and the power of Machine Learning are emerging as viable alternatives within smart healthcare. In this paper, we propose several multi-modal approaches that combine 30-second ECG recordings and approximate long-term Heart Rate Variability (HRV) data to estimate the risk of HF hospitalization. We introduce two survival models: an XGBoost model with Accelerated Failure Time (AFT) incorporating comprehensive ECG features and a ResNet model that learns from the raw ECG. We extend these with our novel long-term HRVs extracted from the combination of ultra-
    
[^228]: X-AMR注释工具

    X-AMR Annotation Tool

    [https://arxiv.org/abs/2403.15407](https://arxiv.org/abs/2403.15407)

    该论文介绍了一种新型的X-AMR注释工具，通过机器辅助提升用户体验，实现了对关键事件语义的注释，与GPT-4集成表现出色。

    

    本文介绍了一种新型的跨文档抽象意义表征（X-AMR）注释工具，旨在用于注释关键的语料库级事件语义。通过Prodigy注释工具提供的机器辅助，我们增强了用户体验，确保注释过程的简易性和高效性。通过实证分析，我们展示了我们的工具在增强现有事件语料库方面的有效性，突显了其与GPT-4集成时的优势。代码和注释：https://github.com/ahmeshaf/gpt_coref

    arXiv:2403.15407v1 Announce Type: cross  Abstract: This paper presents a novel Cross-document Abstract Meaning Representation (X-AMR) annotation tool designed for annotating key corpus-level event semantics. Leveraging machine assistance through the Prodigy Annotation Tool, we enhance the user experience, ensuring ease and efficiency in the annotation process. Through empirical analyses, we demonstrate the effectiveness of our tool in augmenting an existing event corpus, highlighting its advantages when integrated with GPT-4. Code and annotations: https://github.com/ahmeshaf/gpt_coref
    
[^229]: 实践中的AI可持续性第二部分：AI工作流程中的可持续性

    AI Sustainability in Practice Part Two: Sustainability Throughout the AI Workflow

    [https://arxiv.org/abs/2403.15404](https://arxiv.org/abs/2403.15404)

    SIAs是一种治理机制，可以帮助AI项目团队持续关注项目的潜在实际影响，这对于实现AI系统的可持续性至关重要。

    

    AI系统的可持续性取决于项目团队能否持续关注其潜在的现实影响和转型效应。利益相关者影响评估（SIAs）是一种治理机制，使团队能够对这种响应能力进行持续性评估。它们是一种创建程序的工具，用来记录协作评估和反思未来可能的AI创新项目的危害和好处。SIAs不是一次性的治理行动。它们要求项目团队持续关注AI生产和使用的动态和变化性质，以及AI技术嵌入的现实世界环境的变化条件。这本工作手册是关于AI可持续性的两本工作手册中的第二本。它提供了SIAs的模板和允许深入研究其中关键部分的活动。它讨论了权衡价值和协同的方法。

    arXiv:2403.15404v1 Announce Type: cross  Abstract: The sustainability of AI systems depends on the capacity of project teams to proceed with a continuous sensitivity to their potential real-world impacts and transformative effects. Stakeholder Impact Assessments (SIAs) are governance mechanisms that enable this kind of responsiveness. They are tools that create a procedure for, and a means of documenting, the collaborative evaluation and reflective anticipation of the possible harms and benefits of AI innovation projects. SIAs are not one-off governance actions. They require project teams to pay continuous attention to the dynamic and changing character of AI production and use and to the shifting conditions of the real-world environments in which AI technologies are embedded. This workbook is part two of two workbooks on AI Sustainability. It provides a template of the SIA and activities that allow a deeper dive into crucial parts of it. It discusses methods for weighing values and co
    
[^230]: AI伦理与治理实践：导论

    AI Ethics and Governance in Practice: An Introduction

    [https://arxiv.org/abs/2403.15403](https://arxiv.org/abs/2403.15403)

    介绍了PBG框架，这是一个多层次的治理模型，帮助项目团队将伦理价值观和实践原则融入创新实践中，展示和记录这些价值的清晰机制。

    

    AI系统可能对个人和社会产生深远和长期影响。为了负责地管理这些影响，并将AI系统的发展引向最佳的公共利益，必须将AI伦理和治理考虑列为首要任务。在此工作手册中，我们介绍并描述了我们的PBG框架，这是一个多层次的治理模型，使项目团队能够将伦理价值观和实践原则融入其创新实践中，并具备清晰的机制来展示和记录这一点。

    arXiv:2403.15403v1 Announce Type: cross  Abstract: AI systems may have transformative and long-term effects on individuals and society. To manage these impacts responsibly and direct the development of AI systems toward optimal public benefit, considerations of AI ethics and governance must be a first priority.   In this workbook, we introduce and describe our PBG Framework, a multi-tiered governance model that enables project teams to integrate ethical values and practical principles into their innovation practices and to have clear mechanisms for demonstrating and documenting this.
    
[^231]: 大型语言模型在心理健康领域的系统评价

    Large Language Model for Mental Health: A Systematic Review

    [https://arxiv.org/abs/2403.15401](https://arxiv.org/abs/2403.15401)

    该论文系统评价了大型语言模型在心理健康领域的应用，讨论了其在早期筛查、数字干预和其他临床应用中的挑战和机遇。

    

    大型语言模型（LLMs）在数字健康领域受到了广泛关注，展现出了潜在的应用性，但它们在心理健康领域的应用仍在持续讨论中。这项系统性评价旨在总结和表征LLMs在心理健康领域的应用，通过调查LLMs最新研究的优势和局限性，讨论心理健康领域早期筛查、数字干预以及其他临床应用的挑战和机遇。根据PRISMA指南，我们审查了PubMed、DBLP计算机科学文献数据库和IEEE Xplore上发表的英文文章，时间跨度为2017年1月1日至2023年9月1日，重点关注心理健康和LLMs。该综述分析了32篇文章，包括使用社交媒体数据集进行心理健康分析的（n=13）、心理健康聊天机器人（n=10）以及其他心理健康应用（n=9）。研究结果显示LLMs在心理健康问题检测中的有效性以及

    arXiv:2403.15401v1 Announce Type: cross  Abstract: Large language models (LLMs) have received much attention and shown their potential in digital health, while their application in mental health is subject to ongoing debate. This systematic review aims to summarize and characterize the use of LLMs in mental health by investigating the strengths and limitations of the latest work in LLMs and discusses the challenges and opportunities for early screening, digital interventions, and other clinical applications in mental health. Following PRISMA guidelines, we examined English articles from PubMed, DBLP Computer Science Bibliography, and IEEE Xplore, published between 1 January 2017, and 1 September 2023, focusing on mental health and LLMs. The review analyzed 32 articles, including mental health analysis using social media datasets (n=13), mental health chatbots (n=10), and other mental health applications (n=9). Findings reveal LLMs' effectiveness in mental health issue detection and the
    
[^232]: 管控大型语言模型：圆桌报告

    Regulating Large Language Models: A Roundtable Report

    [https://arxiv.org/abs/2403.15397](https://arxiv.org/abs/2403.15397)

    圆桌会议探讨了如何通过法律和政策来解决大型语言模型可能带来的真实性、隐私和市场集中等方面的重要社会问题。

    

    在2023年7月20日，一群具有法律、计算机科学、政治科学等专业知识的27名学者和数字权利倡导者聚集在纽约大学法学院信息法律研究所和民主与科技中心联合举办的大型语言模型、法律和政策圆桌会议上。圆桌会议旨在讨论法律和政策如何帮助解决大型语言模型（LLMs）带来的一些较大社会问题。讨论主要集中在三个政策领域：1.真实性：LLMs在生成误信息和假信息方面存在哪些风险？从技术和/或监管的角度如何减轻这些风险？2.隐私：在创建、部署和使用LLMs过程中涉及哪些最大的隐私风险？如何从技术和/或监管的角度减轻这些风险？3.市场集中：LLMs带来了哪些市场集中的威胁？

    arXiv:2403.15397v1 Announce Type: cross  Abstract: On July 20, 2023, a group of 27 scholars and digital rights advocates with expertise in law, computer science, political science, and other disciplines gathered for the Large Language Models, Law and Policy Roundtable, co-hosted by the NYU School of Law's Information Law Institute and the Center for Democracy & Technology. The roundtable convened to discuss how law and policy can help address some of the larger societal problems posed by large language models (LLMs). The discussion focused on three policy topic areas in particular:   1. Truthfulness: What risks do LLMs pose in terms of generating mis- and disinformation? How can these risks be mitigated from a technical and/or regulatory perspective?   2. Privacy: What are the biggest privacy risks involved in the creation, deployment, and use of LLMs? How can these risks be mitigated from a technical and/or regulatory perspective?   3. Market concentration: What threats do LLMs pose c
    
[^233]: 我希望这是一个助手，而不是老师：远程学习学生希望从人工智能数字助手那里得到的客户观点

    I would love this to be like an assistant, not the teacher: a voice of the customer perspective of what distance learning students want from an Artificial Intelligence Digital Assistant

    [https://arxiv.org/abs/2403.15396](https://arxiv.org/abs/2403.15396)

    通过两步法混合方法研究了十名在线和远程学习学生对虚拟AI数字助手设计的看法，结果显示所有参与者都认为这样的AI工具在学习时是有用的。

    

    随着ChatGPT等生成式AI系统的发布，人们对使用人工智能（AI）的兴趣逐渐增加，在不同领域中包括高等教育。尽管新兴统计数据显示本科生中使用AI的普及度，但对学生对AI的看法，包括他们在实际使用中自报的好处和关注点，特别是在远程学习背景下，目前为止还知之甚少。本研究采用两步法混合方法，分析了来自不同学科的十名在线和远程学习学生对虚拟AI数字助手（AIDA）设计的看法。在第一步中，我们通过采访捕捉了学生的看法，而第二步通过支持学生与同行分享、比较和对比看法的数据三角化。所有参与者都同意在学习时使用这样的AI工具的有效性。

    arXiv:2403.15396v1 Announce Type: cross  Abstract: With the release of Generative AI systems such as ChatGPT, an increasing interest in using Artificial Intelligence (AI) has been observed across domains, including higher education. While emerging statistics show the popularity of using AI amongst undergraduate students, little is yet known about students' perceptions regarding AI including self-reported benefits and concerns from their actual usage, in particular in distance learning contexts. Using a two-step, mixed-methods approach, we examined the perceptions of ten online and distance learning students from diverse disciplines regarding the design of a hypothetical AI Digital Assistant (AIDA). In the first step, we captured students' perceptions via interviews, while the second step supported the triangulation of data by enabling students to share, compare, and contrast perceptions with those of peers. All participants agreed on the usefulness of such an AI tool while studying and
    
[^234]: LLaVA-PruMerge: 自适应令牌减少用于高效大型多模态模型

    LLaVA-PruMerge: Adaptive Token Reduction for Efficient Large Multimodal Models

    [https://arxiv.org/abs/2403.15388](https://arxiv.org/abs/2403.15388)

    PruMerge提出了一种自适应的视觉令牌减少方法，可以有效减少大型多模态模型中的视觉令牌数量，同时保持模型性能。

    

    大型多模态模型(LMMs)通过连接视觉编码器和大型语言模型展现了显著的推理能力。最近的LMMs包括了更复杂的视觉输入，如高分辨率图像和视频，这显著增加了视觉令牌的数量。为了解决这个问题，我们探索了一种令牌减少机制，并发现类似于先前的工作，许多视觉令牌在空间上是冗余的。基于此，我们提出了PruMerge，一种新颖的自适应视觉令牌减少方法，大大减少了视觉令牌的数量，同时保持了可比的模型性能。

    arXiv:2403.15388v1 Announce Type: cross  Abstract: Large Multimodal Models (LMMs) have shown significant reasoning capabilities by connecting a visual encoder and a large language model. LMMs typically use a fixed amount of visual tokens, such as the penultimate layer features in the CLIP visual encoder, as the prefix content. Recent LMMs incorporate more complex visual inputs, such as high-resolution images and videos, which increase the number of visual tokens significantly. However, due to the design of the Transformer architecture, computational costs associated with these models tend to increase quadratically with the number of input tokens. To tackle this problem, we explore a token reduction mechanism and find, similar to prior work, that many visual tokens are spatially redundant. Based on this, we propose PruMerge, a novel adaptive visual token reduction approach, which largely reduces the number of visual tokens while maintaining comparable model performance. We first select 
    
[^235]: Point-DETR3D：利用空间点先验信息增强图像数据的弱监督半监督3D目标检测

    Point-DETR3D: Leveraging Imagery Data with Spatial Point Prior for Weakly Semi-supervised 3D Object Detection

    [https://arxiv.org/abs/2403.15317](https://arxiv.org/abs/2403.15317)

    提出了Point-DETR3D，一个师生框架用于弱监督半监督3D检测，充分利用点级监督优势，克服了将弱监督3D先验信息编码到模型中的挑战。

    

    训练高精度的3D检测器需要大量带有7个自由度的标记3D注释，这是费时费力的。因此，提出了点注释的形式，为3D检测在实际应用中提供了重要前景，不仅更易获得且成本更低廉，而且为目标定位提供了强大的空间信息。在本文中，我们经验性地发现，仅仅将Point-DETR改编为其3D形式并不简单，遇到了两个主要瓶颈：1）无法将强大的3D先验信息编码到模型中，2）由于激光雷达点的极度稀疏性，在远距离区域生成质量低下的伪标签。为了克服这些挑战，我们引入了Point-DETR3D，一个用于弱监督半监督3D检测的师生框架，旨在充分利用在受限的实例级注释预算内的点级监督。与P不同

    arXiv:2403.15317v1 Announce Type: cross  Abstract: Training high-accuracy 3D detectors necessitates massive labeled 3D annotations with 7 degree-of-freedom, which is laborious and time-consuming. Therefore, the form of point annotations is proposed to offer significant prospects for practical applications in 3D detection, which is not only more accessible and less expensive but also provides strong spatial information for object localization.In this paper, we empirically discover that it is non-trivial to merely adapt Point-DETR to its 3D form, encountering two main bottlenecks: 1) it fails to encode strong 3D prior into the model, and 2) it generates low-quality pseudo labels in distant regions due to the extreme sparsity of LiDAR points. To overcome these challenges, we introduce Point-DETR3D, a teacher-student framework for weakly semi-supervised 3D detection, designed to fully capitalize on point-wise supervision within a constrained instance-wise annotation budget.Different from P
    
[^236]: 卡通幻觉检测: 姿势感知上下文视觉学习

    Cartoon Hallucinations Detection: Pose-aware In Context Visual Learning

    [https://arxiv.org/abs/2403.15048](https://arxiv.org/abs/2403.15048)

    该研究提出了一种用于检测由TTI模型生成的卡通角色图像中视觉幻觉的系统，通过结合姿势感知上下文视觉学习和视觉语言模型，利用RGB图像和姿势信息，实现了更准确的决策，显著提高了视觉幻觉的识别能力，推动了TTI模型在非照片真实领域的发展。

    

    大规模文本到图像（TTI）模型已经成为各种生成领域中生成训练数据的常见方法。然而，视觉幻觉，尤其是在非照片真实风格如卡通人物中包含了感知上关键的缺陷，依然是一个令人担忧的问题。我们提出了一种新颖的用于检测TTI模型生成的卡通角色图像的视觉幻觉检测系统。我们的方法利用了姿势感知上下文视觉学习（PA-ICVL）与视觉语言模型（VLMs），同时利用RGB图像和姿势信息。通过从一个经过微调的姿势估计器中获得姿势指导，我们使VLM能够做出更准确的决策。实验结果表明，在识别视觉幻觉方面，与仅依赖于RGB图像的基线方法相比，取得了显著的改进。这项研究通过减轻视觉幻觉，推动了TTI模型在非照片真实领域的潜力。

    arXiv:2403.15048v1 Announce Type: cross  Abstract: Large-scale Text-to-Image (TTI) models have become a common approach for generating training data in various generative fields. However, visual hallucinations, which contain perceptually critical defects, remain a concern, especially in non-photorealistic styles like cartoon characters. We propose a novel visual hallucination detection system for cartoon character images generated by TTI models. Our approach leverages pose-aware in-context visual learning (PA-ICVL) with Vision-Language Models (VLMs), utilizing both RGB images and pose information. By incorporating pose guidance from a fine-tuned pose estimator, we enable VLMs to make more accurate decisions. Experimental results demonstrate significant improvements in identifying visual hallucinations compared to baseline methods relying solely on RGB images. This research advances TTI models by mitigating visual hallucinations, expanding their potential in non-photorealistic domains.
    
[^237]: 从状态方程到引力对偶

    Gravitational Duals from Equations of State

    [https://arxiv.org/abs/2403.14763](https://arxiv.org/abs/2403.14763)

    引力双对偶理论提出了一种基于物理信息神经网络的新方法，可以从预设的状态方程推导出对应的引力理论。

    

    引力双对偶理论将五维引力理论与四维量子场论在平直空间中相关联。在这种映射下，场论的状态方程被编码在引力理论的黑洞解中。解五维爱因斯坦方程以确定状态方程是一个算法性的、直接的问题。确定引力理论从而产生特定状态方程是一个更具挑战性的、反向问题。我们提出了一种基于物理信息神经网络的新方法来解决这个问题。由此产生的算法不仅受数据驱动，还受爱因斯坦方程的物理知识驱动。我们成功地将其应用于具有交叉点、一级和二级相变的理论中。

    arXiv:2403.14763v1 Announce Type: cross  Abstract: Holography relates gravitational theories in five dimensions to four-dimensional quantum field theories in flat space. Under this map, the equation of state of the field theory is encoded in the black hole solutions of the gravitational theory. Solving the five-dimensional Einstein's equations to determine the equation of state is an algorithmic, direct problem. Determining the gravitational theory that gives rise to a prescribed equation of state is a much more challenging, inverse problem. We present a novel approach to solve this problem based on physics-informed neural networks. The resulting algorithm is not only data-driven but also informed by the physics of the Einstein's equations. We successfully apply it to theories with crossovers, first- and second-order phase transitions.
    
[^238]: AI 评估量表（AIAS）的实践：GenAI 支持评估的试点实施

    The AI Assessment Scale (AIAS) in action: A pilot implementation of GenAI supported assessment

    [https://arxiv.org/abs/2403.14692](https://arxiv.org/abs/2403.14692)

    该论文介绍了AI评估量表（AIAS）的实践应用，通过灵活框架将GenAI技术纳入教育评估中，显著降低了与GenAI相关的学术不端案件，提高了学生的学业成绩。

    

    在高等教育中快速采用生成人工智能（GenAI）技术引发了对学术诚信、评估实践和学生学习的关注。禁止或阻止GenAI工具已被证明是无效的，惩罚性方法忽略了这些技术的潜在好处。本文介绍了在英国越南大学（BUV）进行的试点研究的结果，探讨了人工智能评估量表（AIAS）的实施，这是一个灵活的框架，用于将GenAI纳入教育评估中。AIAS由五个级别组成，从“无AI”到“完全AI”，使教育工作者能够设计侧重于需要人类输入和批判性思维的评估。在实施AIAS后，试点研究结果表明与GenAI相关的学术不端案件显着减少，学生成绩提高了5.9%。

    arXiv:2403.14692v1 Announce Type: cross  Abstract: The rapid adoption of Generative Artificial Intelligence (GenAI) technologies in higher education has raised concerns about academic integrity, assessment practices, and student learning. Banning or blocking GenAI tools has proven ineffective, and punitive approaches ignore the potential benefits of these technologies. This paper presents the findings of a pilot study conducted at British University Vietnam (BUV) exploring the implementation of the Artificial Intelligence Assessment Scale (AIAS), a flexible framework for incorporating GenAI into educational assessments. The AIAS consists of five levels, ranging from 'No AI' to 'Full AI', enabling educators to design assessments that focus on areas requiring human input and critical thinking.   Following the implementation of the AIAS, the pilot study results indicate a significant reduction in academic misconduct cases related to GenAI, a 5.9% increase in student attainment across the 
    
[^239]: 发展和部署教育领域人工智能产业标准：挑战、策略和未来方向

    Developing and Deploying Industry Standards for Artificial Intelligence in Education (AIED): Challenges, Strategies, and Future Directions

    [https://arxiv.org/abs/2403.14689](https://arxiv.org/abs/2403.14689)

    教育领域人工智能的发展需要制定和实施产业标准，以解决互操作性、可扩展性和道德治理等挑战。

    

    人工智能在教育领域的应用承诺通过提供个性化学习体验、自动化行政和教学任务以及降低内容创建成本来革新教育实践。然而，在开发和部署教育领域人工智能解决方案方面缺乏标准化实践导致生态系统分散，给互操作性、可扩展性和道德治理带来挑战。本文旨在解决在教育领域人工智能发展和实施产业标准的紧迫需求，提供对当前局势、挑战和克服这些障碍的策略方法的全面分析。我们开始通过研究AIED在不同教育环境中的各种应用，并确定缺乏标准化的关键领域，包括系统互操作性、本体映射、数据集成、评估和道德治理。

    arXiv:2403.14689v1 Announce Type: cross  Abstract: The adoption of Artificial Intelligence in Education (AIED) holds the promise of revolutionizing educational practices by offering personalized learning experiences, automating administrative and pedagogical tasks, and reducing the cost of content creation. However, the lack of standardized practices in the development and deployment of AIED solutions has led to fragmented ecosystems, which presents challenges in interoperability, scalability, and ethical governance. This article aims to address the critical need to develop and implement industry standards in AIED, offering a comprehensive analysis of the current landscape, challenges, and strategic approaches to overcome these obstacles. We begin by examining the various applications of AIED in various educational settings and identify key areas lacking in standardization, including system interoperability, ontology mapping, data integration, evaluation, and ethical governance. Then, 
    
[^240]: 探究ChatGPT及其对社会的影响

    Exploring ChatGPT and its Impact on Society

    [https://arxiv.org/abs/2403.14643](https://arxiv.org/abs/2403.14643)

    ChatGPT是一种基于Transformer架构的大型语言模型，能够生成人类化的对话回复，可革新各行业并改变技术互动方式。

    

    人工智能已经存在一段时间了，但突然间比以往任何时候都受到了更多的关注。感谢谷歌、微软、元宇宙等科技界主要品牌的创新。然而，OpenAI通过其开创性发明ChatGPT触发了按钮。ChatGPT是一种基于Transformer架构的大型语言模型（LLM），能够在对话背景中生成类似人类的回复。它使用深度学习算法来生成对输入文本的自然语言回复。其庞大的参数数量、上下文生成和面向开放域的训练使其成为一种多功能且有效的工具，可应用于从聊天机器人到客户服务再到语言翻译等广泛领域。它具有彻底改变各行业并转变我们与技术互动方式的潜力。然而，使用ChatGPT也引发了一些担忧，包括道德方面的。

    arXiv:2403.14643v1 Announce Type: cross  Abstract: Artificial intelligence has been around for a while, but suddenly it has received more attention than ever before. Thanks to innovations from companies like Google, Microsoft, Meta, and other major brands in technology. OpenAI, though, has triggered the button with its ground-breaking invention ChatGPT. ChatGPT is a Large Language Model (LLM) based on Transformer architecture that has the ability to generate human-like responses in a conversational context. It uses deep learning algorithms to generate natural language responses to input text. Its large number of parameters, contextual generation, and open-domain training make it a versatile and effective tool for a wide range of applications, from chatbots to customer service to language translation. It has the potential to revolutionize various industries and transform the way we interact with technology. However, the use of ChatGPT has also raised several concerns, including ethical,
    
[^241]: ReAct遇上ActRe：对比性自训练中的代理轨迹自动标注

    ReAct Meets ActRe: Autonomous Annotations of Agent Trajectories for Contrastive Self-Training

    [https://arxiv.org/abs/2403.14589](https://arxiv.org/abs/2403.14589)

    提出了A$^3$T框架，通过ActRe提示代理实现了ReAct风格代理对代理轨迹的自主标注，同时增强了新的轨迹合成能力。

    

    arXiv:2403.14589v1 公告类型：新 文摘：语言代理通过与基础模型推理展示了自主决策能力。最近，人们致力于通过多步推理和行动轨迹作为训练数据来训练语言代理以提高性能。然而，收集这样的轨迹仍需要相当大的人力，无论是通过人工标注还是实施多样化提示框架。在这项工作中，我们提出了A$^3$T，一个允许以ReAct风格自主注释代理轨迹的框架。其中心是一个ActRe提示代理，它解释任意动作的原因。当随机抽取外部动作时，ReAct风格代理可以查询ActRe代理以获取其文本理由。新颖的轨迹然后通过将ActRe的后验推理前置到抽样动作中进行综合合成。通过这种方式，ReAct风格代理可执行

    arXiv:2403.14589v1 Announce Type: new  Abstract: Language agents have demonstrated autonomous decision-making abilities by reasoning with foundation models. Recently, efforts have been made to train language agents for performance improvement, with multi-step reasoning and action trajectories as the training data. However, collecting such trajectories still requires considerable human effort, by either artificial annotations or implementations of diverse prompting frameworks. In this work, we propose A$^3$T, a framework that enables the Autonomous Annotation of Agent Trajectories in the style of ReAct. The central role is an ActRe prompting agent, which explains the reason for an arbitrary action. When randomly sampling an external action, the ReAct-style agent could query the ActRe agent with the action to obtain its textual rationales. Novel trajectories are then synthesized by prepending the posterior reasoning from ActRe to the sampled action. In this way, the ReAct-style agent exe
    
[^242]: 一项关于基于概念方法改进模型的调查

    A survey on Concept-based Approaches For Model Improvement

    [https://arxiv.org/abs/2403.14566](https://arxiv.org/abs/2403.14566)

    基于概念方法对深度神经网络进行解释性改进，提供了人类可理解的决策解释，使得检测伪关联和固有偏见成为可能。

    

    最近研究的重点已经从仅仅提高深度神经网络（DNN）在各种任务中的性能转变为使DNN更易解释给人类。可解释人工智能（XAI）领域已经观察到各种技术，包括基于显著性和基于概念的方法。基于概念的方法用所谓的概念在简单的人类可理解术语中解释模型的决策。概念是数据的人类可解释单元，是人类思维的基石。用概念的解释能够检测到伪关联、固有偏见或聪明汉。随着基于概念的解释的出现，出现了各种概念表示方法和自动概念发现算法。一些最近的方法使用概念进行事后模型解缠评估，而其他人使用它们进行事前训练。基于概念的方法是新的，有许多表示方法。

    arXiv:2403.14566v1 Announce Type: new  Abstract: The focus of recent research has shifted from merely increasing the Deep Neural Networks (DNNs) performance in various tasks to DNNs, which are more interpretable to humans. The field of eXplainable Artificial Intelligence (XAI) has observed various techniques, including saliency-based and concept-based approaches. Concept-based approaches explain the model's decisions in simple human understandable terms called Concepts. Concepts are human interpretable units of data and are the thinking ground of humans. Explanations in terms of concepts enable detecting spurious correlations, inherent biases, or clever-hans. With the advent of concept-based explanations, there have been various concept representation methods and automatic concept discovery algorithms. Some recent methods use concepts for post-hoc model disentanglement evaluation, while others use them for ante-hoc training. The concept-based approaches are new, with many representatio
    
[^243]: C-TPT：通过文本特征离散性的校准测试时提示调整视觉-语言模型

    C-TPT: Calibrated Test-Time Prompt Tuning for Vision-Language Models via Text Feature Dispersion

    [https://arxiv.org/abs/2403.14119](https://arxiv.org/abs/2403.14119)

    本文研究了在测试时提示调整过程中通过利用CLIP的固有属性来探讨校准的方法，发现提示选择显著影响了CLIP中的校准，其中导致更高文本特征离散性的提示会产生更好校准的预测。

    

    在深度学习中，测试时适应已经引起了人们的关注，作为一种在不需要标记数据的情况下对模型进行微调的方法。一个主要的例证是最近提出的用于大规模视觉-语言模型（如CLIP）的测试时提示调整。然而，这些提示主要是为了提高准确性而开发的，忽视了校准的重要性——量化预测不确定性的关键方面。然而，传统的校准方法依赖大量标记数据，这使得它们在测试时场景下不切实际。为此，本文通过利用CLIP的固有属性，在测试时提示调整过程中探讨校准。通过一系列观察，我们发现提示选择显著影响了CLIP中的校准，其中导致更高文本特征离散性的提示会产生更好校准的预测。

    arXiv:2403.14119v1 Announce Type: cross  Abstract: In deep learning, test-time adaptation has gained attention as a method for model fine-tuning without the need for labeled data. A prime exemplification is the recently proposed test-time prompt tuning for large-scale vision-language models such as CLIP. Unfortunately, these prompts have been mainly developed to improve accuracy, overlooking the importance of calibration-a crucial aspect for quantifying prediction uncertainty. However, traditional calibration methods rely on substantial amounts of labeled data, making them impractical for test-time scenarios. To this end, this paper explores calibration during test-time prompt tuning by leveraging the inherent properties of CLIP. Through a series of observations, we find that the prompt choice significantly affects the calibration in CLIP, where the prompts leading to higher text feature dispersion result in better-calibrated predictions. Introducing the Average Text Feature Dispersion
    
[^244]: 可持续数据中心实时减少碳足迹

    Carbon Footprint Reduction for Sustainable Data Centers in Real-Time

    [https://arxiv.org/abs/2403.14092](https://arxiv.org/abs/2403.14092)

    我们提出了一种Data Center Carbon Footprint Reduction (DC-CFR) 多代理强化学习（MARL）框架，旨在实时优化数据中心以减少碳足迹。

    

    随着机器学习工作负载显著增加能源消耗，碳排放低的可持续数据中心正成为全球政府和企业关注的重点。为了实现这一目标，需要在冷却和IT负载中进行功耗优化的范式转变，基于可再生能源在电网中的可用性来调整灵活负载，利用数据中心不间断电源中的电池存储，使用协作代理。这些优化策略之间的复杂关系以及它们对变化的外部因素（如天气和电网碳排放强度）的依赖使得这是一个困难的问题。目前缺乏一个能够在动态实际环境中同时优化所有这些目标的实时控制器。我们提出了一种数据中心碳足迹减少（DC-CFR）多代理强化学习（MARL）框架，能够优化多个角度的数据中心。

    arXiv:2403.14092v1 Announce Type: cross  Abstract: As machine learning workloads significantly increase energy consumption, sustainable data centers with low carbon emissions are becoming a top priority for governments and corporations worldwide. This requires a paradigm shift in optimizing power consumption in cooling and IT loads, shifting flexible loads based on the availability of renewable energy in the power grid, and leveraging battery storage from the uninterrupted power supply in data centers, using collaborative agents. The complex association between these optimization strategies and their dependencies on variable external factors like weather and the power grid carbon intensity makes this a hard problem. Currently, a real-time controller to optimize all these goals simultaneously in a dynamic real-world setting is lacking. We propose a Data Center Carbon Footprint Reduction (DC-CFR) multi-agent Reinforcement Learning (MARL) framework that optimizes data centers for the mult
    
[^245]: 整合可穿戴传感器数据和自我报告日记用于个性化情感预测

    Integrating Wearable Sensor Data and Self-reported Diaries for Personalized Affect Forecasting

    [https://arxiv.org/abs/2403.13841](https://arxiv.org/abs/2403.13841)

    本论文提出了一种整合了可穿戴传感器数据和自我报告日记的多模态深度学习模型，用于情感状态的预测。

    

    情绪状态作为情感的指标对整体健康至关重要，因此在其发作前准确预测是至关重要的。目前的研究主要集中在使用来自可穿戴和移动设备的数据进行与短期情感检测。这些研究通常专注于客观的感官测量，往往忽略其他形式的自我报告信息，如日记和笔记。在本文中，我们提出了一种用于情感状态预测的多模态深度学习模型。该模型结合了一个transformer编码器和一个预训练语言模型，实现了客观指标和自我报告日记的综合分析。为了验证我们的模型，我们进行了一项纵向研究，招募了大学生并在一年内对其进行监测，收集了包括生理、环境、睡眠、代谢和身体活动参数在内的广泛数据集，同时参与者提供了开放式文本日记。

    arXiv:2403.13841v1 Announce Type: cross  Abstract: Emotional states, as indicators of affect, are pivotal to overall health, making their accurate prediction before onset crucial. Current studies are primarily centered on immediate short-term affect detection using data from wearable and mobile devices. These studies typically focus on objective sensory measures, often neglecting other forms of self-reported information like diaries and notes. In this paper, we propose a multimodal deep learning model for affect status forecasting. This model combines a transformer encoder with a pre-trained language model, facilitating the integrated analysis of objective metrics and self-reported diaries. To validate our model, we conduct a longitudinal study, enrolling college students and monitoring them over a year, to collect an extensive dataset including physiological, environmental, sleep, metabolic, and physical activity parameters, alongside open-ended textual diaries provided by the partici
    
[^246]: 使用掩模学习的Transformer进行情绪识别

    Emotion Recognition Using Transformers with Masked Learning

    [https://arxiv.org/abs/2403.13731](https://arxiv.org/abs/2403.13731)

    本研究提出了一种使用Transformer进行情绪识别的新框架，专注于Valence-Arousal估计、面部表情识别和动作单元检测，并最大化了对时空特征的理解。

    

    在近年来，深度学习在各个领域取得了创新性进展，其中包括对人类情绪和行为的分析。诸如野外情感行为分析（ABAW）竞赛等倡议尤其在推动这一领域的研究方面发挥了重要作用，通过提供多样且具有挑战性的数据集，能够精确评估复杂情绪状态。本研究利用了Vision Transformer（ViT）和Transformer模型，专注于对情绪的积极性和强度（Valence-Arousal），各种面部表情的识别以及代表基本肌肉运动的动作单元（AU）的检测。这种方法超越了传统的卷积神经网络（CNNs）和长短期记忆（LSTM）方法，提出了一种基于Transformer的全新框架，最大化了对时空特征的理解。

    arXiv:2403.13731v2 Announce Type: replace-cross  Abstract: In recent years, deep learning has achieved innovative advancements in various fields, including the analysis of human emotions and behaviors. Initiatives such as the Affective Behavior Analysis in-the-wild (ABAW) competition have been particularly instrumental in driving research in this area by providing diverse and challenging datasets that enable precise evaluation of complex emotional states. This study leverages the Vision Transformer (ViT) and Transformer models to focus on the estimation of Valence-Arousal (VA), which signifies the positivity and intensity of emotions, recognition of various facial expressions, and detection of Action Units (AU) representing fundamental muscle movements. This approach transcends traditional Convolutional Neural Networks (CNNs) and Long Short-Term Memory (LSTM) based methods, proposing a new Transformer-based framework that maximizes the understanding of temporal and spatial features. Th
    
[^247]: 不再有优化规则: 基于LLM的基于策略的多模查询优化器（版本1）

    No more optimization rules: LLM-enabled policy-based multi-modal query optimizer (version 1)

    [https://arxiv.org/abs/2403.13597](https://arxiv.org/abs/2403.13597)

    LLM启用了基于策略的多模查询优化器，摆脱了传统的基于规则的优化方法，为查询优化带来全新的可能性。

    

    大语言模型(LLM)在机器学习和深度学习领域标志着一个重要时刻。最近，人们研究了LLM在查询规划中的能力，包括单模和多模查询。然而，对于LLM的查询优化能力还没有相关研究。作为显著影响查询计划执行性能的关键步骤，不应错过这种分析和尝试。另一方面，现有的查询优化器通常是基于规则或基于规则+基于成本的，即它们依赖于人工创建的规则来完成查询计划重写/转换。鉴于现代优化器包括数百至数千条规则，按照类似方式设计一个多模查询优化器将耗费大量时间，因为我们将不得不列举尽可能多的多模优化规则，而这并没有。

    arXiv:2403.13597v1 Announce Type: cross  Abstract: Large language model (LLM) has marked a pivotal moment in the field of machine learning and deep learning. Recently its capability for query planning has been investigated, including both single-modal and multi-modal queries. However, there is no work on the query optimization capability of LLM. As a critical (or could even be the most important) step that significantly impacts the execution performance of the query plan, such analysis and attempts should not be missed. From another aspect, existing query optimizers are usually rule-based or rule-based + cost-based, i.e., they are dependent on manually created rules to complete the query plan rewrite/transformation. Given the fact that modern optimizers include hundreds to thousands of rules, designing a multi-modal query optimizer following a similar way is significantly time-consuming since we will have to enumerate as many multi-modal optimization rules as possible, which has not be
    
[^248]: 使用应用特定多核架构设计SNN模型的设计空间探索

    Design-Space Exploration of SNN Models using Application-Specific Multi-Core Architectures

    [https://arxiv.org/abs/2403.12061](https://arxiv.org/abs/2403.12061)

    提出了一种基于应用特定多核架构的新型运行时多核架构模拟器“RAVSim”，通过该模拟器，用户可以在执行过程中与模型交互并修改参数值集。

    

    鉴于当前理解和利用SNN的潜在特性存在的动机和困难，我们提出了一种名为“RAVSim”（运行时分析和可视化模拟器）的新型运行时多核架构模拟器，这是一款尖端的SNN模拟器，使用LabVIEW开发，并作为官方模块在其网站上公开提供。RAVSim是一种运行时虚拟仿真环境工具，使用户能够与模型互动，观察其输出浓度的行为，并在模拟执行过程中随时修改参数值集。最近已经提出了一些流行的工具，但我们认为这些工具都不允许用户与模型仿真进行实时交互。

    arXiv:2403.12061v1 Announce Type: cross  Abstract: With the motivation and the difficulties that currently exist in comprehending and utilizing the promising features of SNNs, we proposed a novel run-time multi-core architecture-based simulator called "RAVSim" (Runtime Analysis and Visualization Simulator), a cutting-edge SNN simulator, developed using LabVIEW and it is publicly available on their website as an official module. RAVSim is a runtime virtual simulation environment tool that enables the user to interact with the model, observe its behavior of output concentration, and modify the set of parametric values at any time while the simulation is in execution. Recently some popular tools have been presented, but we believe that none of the tools allow users to interact with the model simulation in run time.
    
[^249]: 从像素到洞察: 在大型基础模型时代自动图表理解的调查

    From Pixels to Insights: A Survey on Automatic Chart Understanding in the Era of Large Foundation Models

    [https://arxiv.org/abs/2403.12027](https://arxiv.org/abs/2403.12027)

    近年来，随着大型基础模型的兴起，自动图表理解取得了显著进展，本调查论文概述了在这些基础模型背景下图表理解领域的最新发展、挑战和未来方向

    

    数据可视化以图表形式在数据分析中扮演着关键角色，提供关键洞察并帮助做出明智决策。随着近年大型基础模型的崛起，自动图表理解取得了显著进展。基础模型，如大型语言模型(LLMs)，已经在各种自然语言处理（NLP）任务中实现了革命，并越来越多地应用于图表理解任务。本调查论文全面介绍了最新进展、挑战和未来方向，探讨了这些基础模型背景下图表理解的内容。

    arXiv:2403.12027v1 Announce Type: cross  Abstract: Data visualization in the form of charts plays a pivotal role in data analysis, offering critical insights and aiding in informed decision-making. Automatic chart understanding has witnessed significant advancements with the rise of large foundation models in recent years. Foundation models, such as large language models (LLMs), have revolutionized various natural language processing (NLP) tasks and are increasingly being applied to chart understanding tasks. This survey paper provides a comprehensive overview of the recent developments, challenges, and future directions in chart understanding within the context of these foundation models. The paper begins by defining chart understanding, outlining problem formulations, and discussing fundamental building blocks crucial for studying chart understanding tasks. In the section on tasks and datasets, we explore various tasks within chart understanding and discuss their evaluation metrics a
    
[^250]: 确保安全和高质量输出：面向语言模型的指南库方法

    Ensuring Safe and High-Quality Outputs: A Guideline Library Approach for Language Models

    [https://arxiv.org/abs/2403.11838](https://arxiv.org/abs/2403.11838)

    引入Guide-Align，一种两阶段方法，通过安全训练模型识别潜在风险，并制定特定指南，从而建立全面的指导库，用于指导LLMs生成安全和高质量输出。

    

    大型语言模型(LLMs)展示了令人印象深刻的能力，但也存在偏见内容生成和隐私问题等风险。当前的对齐技术之一包括基于原则的集成，但面临由于手工制定规则的不精确性和未经安全训练的模型对风险感知不足而产生的挑战。为了解决这些问题，我们引入了Guide-Align，这是一种两阶段方法。最初，一个经过安全训练的模型识别潜在风险，并为各种输入制定具体指南，从而建立了全面的指南库和用于输入指南检索的模型。随后，检索模型将新输入与相关指南相关联，引导LLMs在响应生成中确保安全和高质量输出，从而与人类价值观一致。另一个额外可选阶段涉及使用经过细致对齐的新数据集对模型进行微调。

    arXiv:2403.11838v1 Announce Type: cross  Abstract: Large Language Models (LLMs) exhibit impressive capabilities but also present risks such as biased content generation and privacy issues. One of the current alignment techniques includes principle-driven integration, but it faces challenges arising from the imprecision of manually crafted rules and inadequate risk perception in models without safety training. To address these, we introduce Guide-Align, a two-stage approach. Initially, a safety-trained model identifies potential risks and formulates specific guidelines for various inputs, thereby establishing a comprehensive library of guidelines and models for input-guidelines retrieval. Subsequently, the retrieval model correlates new inputs with pertinent guidelines, guiding LLMs in response generation to ensure safe and high-quality outputs, thus aligning with human values. An additional optional stage involves fine-tuning a model with new well-aligned datasets generated through the
    
[^251]: Scene-LLM：扩展用于3D视觉理解和推理的语言模型

    Scene-LLM: Extending Language Model for 3D Visual Understanding and Reasoning

    [https://arxiv.org/abs/2403.11401](https://arxiv.org/abs/2403.11401)

    本文介绍了Scene-LLM，一种3D视觉语言模型，通过整合大型语言模型（LLMs）的推理优势，增强了在交互式3D室内环境中具身体存在的代理者能力。

    

    本文介绍了Scene-LLM，这是一种3D视觉语言模型，通过整合大型语言模型（LLMs）的推理优势，增强了在交互式3D室内环境中具身体存在的代理者能力。Scene-LLM采用了混合的3D视觉特征表示，包括了密集的空间信息，并支持场景状态的更新。该模型使用投影层将这些特征高效地投影到预训练的文本嵌入空间中，从而有效解释3D视觉信息。我们方法的独特之处在于整合了场景级和以自我为中心的3D信息。这种组合对于交互式规划至关重要，其中场景级数据支持全局规划，以自我为中心的数据对于定位至关重要。值得注意的是，我们使用以自我为中心的3D帧特征进行特征对齐，这是一种增强模型对小物体特征对齐能力的有效技术。

    arXiv:2403.11401v1 Announce Type: cross  Abstract: This paper introduces Scene-LLM, a 3D-visual-language model that enhances embodied agents' abilities in interactive 3D indoor environments by integrating the reasoning strengths of Large Language Models (LLMs). Scene-LLM adopts a hybrid 3D visual feature representation, that incorporates dense spatial information and supports scene state updates. The model employs a projection layer to efficiently project these features in the pre-trained textual embedding space, enabling effective interpretation of 3D visual information. Unique to our approach is the integration of both scene-level and ego-centric 3D information. This combination is pivotal for interactive planning, where scene-level data supports global planning and ego-centric data is important for localization. Notably, we use ego-centric 3D frame features for feature alignment, an efficient technique that enhances the model's ability to align features of small objects within the s
    
[^252]: 移动边缘计算中应用部署问题的基于学习的解决方案

    A learning-based solution approach to the application placement problem in mobile edge computing under uncertainty

    [https://arxiv.org/abs/2403.11259](https://arxiv.org/abs/2403.11259)

    通过机器学习模型将用户请求分配给服务器，以解决在移动边缘计算中应用部署问题的二阶段随机规划。

    

    在移动边缘计算服务器中放置应用程序是一个复杂的挑战，涉及许多服务器、用户及其请求。现有算法需要很长时间解决具有重大不确定性情景的高维问题。因此，需要一种有效的方法来最大化服务质量，同时考虑所有技术约束。其中一种方法是机器学习，它模拟了在边缘服务器中部署应用程序的最佳解决方案。机器学习模型预计将学习如何根据用户和服务器的空间位置将用户请求分配给服务器。本研究将问题构建为二阶段随机规划。通过变化参数如用户位置、请求速率和解决优化模型生成足够数量的训练记录。然后，基于每个用户距离可用服务器的距离特征，

    arXiv:2403.11259v1 Announce Type: cross  Abstract: Placing applications in mobile edge computing servers presents a complex challenge involving many servers, users, and their requests. Existing algorithms take a long time to solve high-dimensional problems with significant uncertainty scenarios. Therefore, an efficient approach is required to maximize the quality of service while considering all technical constraints. One of these approaches is machine learning, which emulates optimal solutions for application placement in edge servers. Machine learning models are expected to learn how to allocate user requests to servers based on the spatial positions of users and servers. In this study, the problem is formulated as a two-stage stochastic programming. A sufficient amount of training records is generated by varying parameters such as user locations, their request rates, and solving the optimization model. Then, based on the distance features of each user from the available servers and 
    
[^253]: 一个白盒神经网络的概念框架

    A Conceptual Framework For White Box Neural Networks

    [https://arxiv.org/abs/2403.09863](https://arxiv.org/abs/2403.09863)

    引入语义特征作为通用概念框架，实现了完全可解释的神经网络层，为白盒神经网络的范式转变开辟了新的可能性。

    

    本文引入语义特征作为完全可解释神经网络层的通用概念框架。一个充分动机的MNIST相关子问题的概念验证模型包括4个这样的层，总共4800个可学习参数。该模型易于解释，无需任何形式的对抗训练即可实现人类水平的对抗测试准确率，需要较少的超参数调节，并且可以在单个CPU上快速训练。该技术的通用性承诺为彻底民主化和真正通用的白盒神经网络带来了希望。代码可在https://github.com/314-Foundation/white-box-nn找到。

    arXiv:2403.09863v1 Announce Type: cross  Abstract: This paper introduces semantic features as a general conceptual framework for fully explainable neural network layers. A well-motivated proof of concept model for relevant subproblem of MNIST consists of 4 such layers with the total of 4.8K learnable parameters. The model is easily interpretable, achieves human-level adversarial test accuracy with no form of adversarial training, requires little hyperparameter tuning and can be quickly trained on a single CPU. The general nature of the technique bears promise for a paradigm shift towards radically democratised and truly generalizable white box neural networks. The code is available at https://github.com/314-Foundation/white-box-nn
    
[^254]: 不要以外表判断: 用于视频识别的运动一致增强

    Don't Judge by the Look: A Motion Coherent Augmentation for Video Recognition

    [https://arxiv.org/abs/2403.09506](https://arxiv.org/abs/2403.09506)

    本研究提出了一种名为运动一致增强（MCA）的数据增强方法，通过引入外观变化来鼓励模型优先考虑视频中的运动信息，而不是静态外观。

    

    当前目标识别中的训练流程在数据增强时忽略了色调抖动，因为它不仅会带来对分类有害的外观变化，而且在实践中实现也是低效的。本研究探讨了色调变化在视频识别中的影响，并发现这种变化是有益的，因为对于包含运动信息的视频来说，静态外观不是那么重要。基于这一观察结果，我们提出了一种用于视频识别的数据增强方法，名为运动一致增强（MCA），它在视频中引入外观变化，隐式鼓励模型优先考虑运动模式，而不是静态外观。具体来说，我们提出了一种名为SwapMix的操作，用于高效修改视频样本的外观，并引入了变异对齐（VA）来解决SwapMix引起的分布偏移，迫使模型去学习

    arXiv:2403.09506v1 Announce Type: cross  Abstract: Current training pipelines in object recognition neglect Hue Jittering when doing data augmentation as it not only brings appearance changes that are detrimental to classification, but also the implementation is inefficient in practice. In this study, we investigate the effect of hue variance in the context of video recognition and find this variance to be beneficial since static appearances are less important in videos that contain motion information. Based on this observation, we propose a data augmentation method for video recognition, named Motion Coherent Augmentation (MCA), that introduces appearance variation in videos and implicitly encourages the model to prioritize motion patterns, rather than static appearances. Concretely, we propose an operation SwapMix to efficiently modify the appearance of video samples, and introduce Variation Alignment (VA) to resolve the distribution shift caused by SwapMix, enforcing the model to le
    
[^255]: 一张图片在第二层之后价值1/2代币：针对大规模视觉语言模型的即插即用推理加速

    An Image is Worth 1/2 Tokens After Layer 2: Plug-and-Play Inference Acceleration for Large Vision-Language Models

    [https://arxiv.org/abs/2403.06764](https://arxiv.org/abs/2403.06764)

    FastV是一种多功能即插即用方法，通过学习自适应注意力模式并在后续层中修剪视觉代币，极大地降低了计算成本，同时在各种图像和视频理解任务中不损失性能。

    

    在本研究中，我们发现大规模视觉语言模型（LVLMs）中的注意力计算存在低效现象，尤其是在知名模型如LLaVA-1.5、QwenVL-Chat和Video-LLaVA中。我们发现在流行的LVLMs的深层中，对视觉代币的注意力计算极其低效，暗示相较于处理文本数据，需要更稀疏的方法。为此，我们引入了FastV，这是一种多功能即插即用方法，旨在通过学习早期层中的自适应注意力模式和在随后层中修剪视觉代币来优化计算效率。我们的评估表明FastV能够显著降低计算成本（例如，对于LLaVA-1.5-13B的FLOP减少了45%），而不会在广泛的图像和视频理解任务中牺牲性能。FastV的计算效率和性能权衡是高度可定制的，并且是帕累托有效的。

    arXiv:2403.06764v1 Announce Type: cross  Abstract: In this study, we identify the inefficient attention phenomena in Large Vision-Language Models (LVLMs), notably within prominent models like LLaVA-1.5, QwenVL-Chat and Video-LLaVA. We find out that the attention computation over visual tokens is of extreme inefficiency in the deep layers of popular LVLMs, suggesting a need for a sparser approach compared to textual data handling. To this end, we introduce FastV, a versatile plug-and-play method designed to optimize computational efficiency by learning adaptive attention patterns in early layers and pruning visual tokens in subsequent ones. Our evaluations demonstrate FastV's ability to dramatically reduce computational costs (e.g., a 45 reduction in FLOPs for LLaVA-1.5-13B) without sacrificing performance in a wide range of image and video understanding tasks. The computational efficiency and performance trade-off of FastV are highly customizable and pareto-efficient. It can compress t
    
[^256]: 通过监督预训练和重要性机制微调改进低资源知识追踪任务

    Improving Low-Resource Knowledge Tracing Tasks by Supervised Pre-training and Importance Mechanism Fine-tuning

    [https://arxiv.org/abs/2403.06725](https://arxiv.org/abs/2403.06725)

    本文提出了名为LoReKT的低资源知识追踪框架，通过监督预训练和微调重要性机制，旨在从丰富资源的KT数据集中学习可转移的参数和表示来改进低资源知识追踪任务。

    

    知识追踪（KT）旨在基于学生的历史互动来估计他们的知识掌握程度。最近，基于深度学习的KT（DLKT）方法在KT任务中取得了令人印象深刻的表现。然而，由于各种原因，如预算限制和隐私问题，许多实际场景中观察到的互动非常有限，即低资源KT数据集。直接在低资源KT数据集上训练DLKT模型可能会导致过拟合，并且很难选择适当的深度神经架构。因此，在本文中，我们提出了一个名为LoReKT的低资源KT框架来应对上述挑战。受盛行的“预训练和微调”范式的启发，我们旨在在预训练阶段从丰富资源的KT数据集中学习可转移的参数和表示。

    arXiv:2403.06725v1 Announce Type: cross  Abstract: Knowledge tracing (KT) aims to estimate student's knowledge mastery based on their historical interactions. Recently, the deep learning based KT (DLKT) approaches have achieved impressive performance in the KT task. These DLKT models heavily rely on the large number of available student interactions. However, due to various reasons such as budget constraints and privacy concerns, observed interactions are very limited in many real-world scenarios, a.k.a, low-resource KT datasets. Directly training a DLKT model on a low-resource KT dataset may lead to overfitting and it is difficult to choose the appropriate deep neural architecture. Therefore, in this paper, we propose a low-resource KT framework called LoReKT to address above challenges. Inspired by the prevalent "pre-training and fine-tuning" paradigm, we aim to learn transferable parameters and representations from rich-resource KT datasets during the pre-training stage and subseque
    
[^257]: 具有扩散净化的分离数据一致性的图像恢复

    Decoupled Data Consistency with Diffusion Purification for Image Restoration

    [https://arxiv.org/abs/2403.06054](https://arxiv.org/abs/2403.06054)

    通过分离反向过程和数据一致性步骤，提出了一种新颖的基于扩散的图像恢复求解器。

    

    最近，扩散模型作为一种强大的深度生成先验类别已经引起了人们的关注，由于其出色地建模数据分布的能力，在各种图像恢复任务中表现出色。为了解决图像恢复问题，许多现有技术通过将额外的似然梯度步骤纳入到扩散模型的反向采样过程中来实现数据一致性。然而，这些额外的梯度步骤对于实际应用中存在挑战，因为它们造成了巨大的计算开销，从而增加了推理时间。当使用加速的扩散模型采样器时，这些额外的步骤还会导致额外的困难，因为数据一致性步骤的数量受限于反向采样步骤的数量。在这项工作中，我们提出了一种新颖的基于扩散的图像恢复求解器，通过将反向过程与数据一致性步骤分离来解决这些问题。我们的方法涉及

    arXiv:2403.06054v1 Announce Type: cross  Abstract: Diffusion models have recently gained traction as a powerful class of deep generative priors, excelling in a wide range of image restoration tasks due to their exceptional ability to model data distributions. To solve image restoration problems, many existing techniques achieve data consistency by incorporating additional likelihood gradient steps into the reverse sampling process of diffusion models. However, the additional gradient steps pose a challenge for real-world practical applications as they incur a large computational overhead, thereby increasing inference time. They also present additional difficulties when using accelerated diffusion model samplers, as the number of data consistency steps is limited by the number of reverse sampling steps. In this work, we propose a novel diffusion-based image restoration solver that addresses these issues by decoupling the reverse process from the data consistency steps. Our method involv
    
[^258]: 利用潜在对抗训练防御未预见的故障模式

    Defending Against Unforeseen Failure Modes with Latent Adversarial Training

    [https://arxiv.org/abs/2403.05030](https://arxiv.org/abs/2403.05030)

    本研究利用潜在对抗训练（LAT）来防御AI系统中未预见的故障模式，通过利用网络实际用于预测的压缩、抽象和结构化概念的潜在表示，有效清除了恶意软件和对抗性攻击。

    

    人工智能系统有时在部署后会展示出有害的意外行为。尽管开发人员进行了大量诊断和调试，这种情况经常发生。由于攻击面非常广泛，从模型中减少风险具有挑战性。耗尽地搜索可能导致模型失败的输入是不可行的。红队和对抗训练（AT）通常用于使人工智能系统更加健壮。然而，它们并不足以避免许多与对抗训练不同的真实世界故障模式。在这项工作中，我们利用潜在对抗训练（LAT）来防御漏洞，而无需生成引发这些漏洞的输入。LAT利用网络实际用于预测的压缩、抽象和结构化概念的潜在表示。我们使用LAT来清除恶意软件并防御针对保留类别的对抗性攻击。我们展示在图像分类、文本分类

    arXiv:2403.05030v1 Announce Type: cross  Abstract: AI systems sometimes exhibit harmful unintended behaviors post-deployment. This is often despite extensive diagnostics and debugging by developers. Minimizing risks from models is challenging because the attack surface is so large. It is not tractable to exhaustively search for inputs that may cause a model to fail. Red-teaming and adversarial training (AT) are commonly used to make AI systems more robust. However, they have not been sufficient to avoid many real-world failure modes that differ from the ones adversarially trained on. In this work, we utilize latent adversarial training (LAT) to defend against vulnerabilities without generating inputs that elicit them. LAT leverages the compressed, abstract, and structured latent representations of concepts that the network actually uses for prediction. We use LAT to remove trojans and defend against held-out classes of adversarial attacks. We show in image classification, text classifi
    
[^259]: 限制贝叶斯神经网络

    Restricted Bayesian Neural Network

    [https://arxiv.org/abs/2403.04810](https://arxiv.org/abs/2403.04810)

    本研究提出了限制贝叶斯神经网络的新架构，显著减少了网络存储空间复杂性，并引入了一种能够有效处理不确定性的算法，确保在目标函数缺乏完美凸性时稳健地收敛至全局最优解。

    

    现代深度学习工具在解决复杂问题方面非常有效。然而，它们作为黑盒模型的运行方式增加了预测的不确定性。此外，它们面临着各种挑战，包括在大型网络中需要大量存储空间、过拟合、欠拟合、梯度消失等问题。本研究探讨了贝叶斯神经网络的概念，提出了一种能够显著减少网络存储空间复杂性的新型架构。此外，我们介绍了一种能够有效处理不确定性的算法，确保稳健的收敛值，避免陷入局部最优解，尤其是当目标函数缺乏完美的凸性时。

    arXiv:2403.04810v1 Announce Type: cross  Abstract: Modern deep learning tools are remarkably effective in addressing intricate problems. However, their operation as black-box models introduces increased uncertainty in predictions. Additionally, they contend with various challenges, including the need for substantial storage space in large networks, issues of overfitting, underfitting, vanishing gradients, and more. This study explores the concept of Bayesian Neural Networks, presenting a novel architecture designed to significantly alleviate the storage space complexity of a network. Furthermore, we introduce an algorithm adept at efficiently handling uncertainties, ensuring robust convergence values without becoming trapped in local optima, particularly when the objective function lacks perfect convexity.
    
[^260]: 从图到词袋: 将领域知识引入混淆罪名预测

    From Graph to Word Bag: Introducing Domain Knowledge to Confusing Charge Prediction

    [https://arxiv.org/abs/2403.04369](https://arxiv.org/abs/2403.04369)

    引入领域知识的从图到词袋方法，帮助预测混淆罪名，通过构成要素和关键词选择进行判断。

    

    混淆罪名预测是法律人工智能中一个具有挑战性的任务，涉及根据事实描述预测混淆罪名。现有的罪名预测方法在表现上已经展现出令人印象深刻的效果，但在处理混淆罪名（如抢夺与抢劫）时面临着重大挑战。在法律领域，构成要素在区分混淆罪名中扮演着至关重要的角色。构成要素是潜在刑罚背后的基本行为，并且在不同罪名之间有微妙的区别。本文介绍了一种新的从图到词袋（FWGB）方法，该方法引入了有关构成要素的领域知识，以指导模型在混淆罪名上做出判断，类似于法官的推理过程。具体而言，我们首先构建了一个包含构成要素的法律知识图，以帮助为每种罪名选择关键词，形成一个单词袋。

    arXiv:2403.04369v1 Announce Type: new  Abstract: Confusing charge prediction is a challenging task in legal AI, which involves predicting confusing charges based on fact descriptions. While existing charge prediction methods have shown impressive performance, they face significant challenges when dealing with confusing charges, such as Snatch and Robbery. In the legal domain, constituent elements play a pivotal role in distinguishing confusing charges. Constituent elements are fundamental behaviors underlying criminal punishment and have subtle distinctions among charges. In this paper, we introduce a novel From Graph to Word Bag (FWGB) approach, which introduces domain knowledge regarding constituent elements to guide the model in making judgments on confusing charges, much like a judge's reasoning process. Specifically, we first construct a legal knowledge graph containing constituent elements to help select keywords for each charge, forming a word bag. Subsequently, to guide the mod
    
[^261]: 使用扩散模型进行潜在数据集蒸馏

    Latent Dataset Distillation with Diffusion Models

    [https://arxiv.org/abs/2403.03881](https://arxiv.org/abs/2403.03881)

    这项研究提出了使用扩散模型进行潜在数据集蒸馏（LD3M），结合潜在空间中的扩散和数据集蒸馏的方法，以解决不同模型架构导致准确性下降和生成高分辨率图像的挑战。

    

    机器学习的有效性传统上依赖于越来越大的数据集的可用性。然而，大型数据集带来存储挑战，并且包含一些非影响力样本，在训练过程中可以被忽略而不影响模型最终的准确性。为了应对这些限制，出现了将数据集信息蒸馏成一组压缩样本（合成样本），即蒸馏数据集的概念。其中一个关键方面是选择用于连接原始和合成数据集的架构（通常是ConvNet）。然而，如果所使用的模型架构与蒸馏过程中使用的模型不同，则最终准确性会降低。另一个挑战是生成高分辨率图像，例如128x128及更高。

    arXiv:2403.03881v1 Announce Type: cross  Abstract: The efficacy of machine learning has traditionally relied on the availability of increasingly larger datasets. However, large datasets pose storage challenges and contain non-influential samples, which could be ignored during training without impacting the final accuracy of the model. In response to these limitations, the concept of distilling the information on a dataset into a condensed set of (synthetic) samples, namely a distilled dataset, emerged. One crucial aspect is the selected architecture (usually ConvNet) for linking the original and synthetic datasets. However, the final accuracy is lower if the employed model architecture differs from the model used during distillation. Another challenge is the generation of high-resolution images, e.g., 128x128 and higher. In this paper, we propose Latent Dataset Distillation with Diffusion Models (LD3M) that combine diffusion in latent space with dataset distillation to tackle both chal
    
[^262]: Align-to-Distill: 可训练的注意力对齐在神经机器翻译中的知识蒸馏

    Align-to-Distill: Trainable Attention Alignment for Knowledge Distillation in Neural Machine Translation

    [https://arxiv.org/abs/2403.01479](https://arxiv.org/abs/2403.01479)

    "本文提出了“Align-to-Distill”（A2D）策略，通过在训练过程中自适应地对齐学生注意力头与其教师对应物，转化了组合映射启发式方法为学习问题，实验结果显示A2D的有效性，对WMT-2022 De->Dsb和WMT-2014 En->De的BLEU分数分别获得高达+3.61和+0.63的提升。"

    

    可扩展的深度模型和大规模数据集的出现提高了神经机器翻译的性能。知识蒸馏（KD）通过将知识从教师模型传输到更紧凑的学生模型来提高效率。然而，针对Transformer架构的KD方法通常依赖于启发式方法，特别是在决定要从哪些教师层中蒸馏知识时。本文介绍了“Align-to-Distill”（A2D）策略，旨在通过在训练过程中自适应地对齐学生注意力头与其教师对应物来解决特征映射问题。A2D中的注意力对齐模块执行学生和教师注意力头之间的密集逐头比较，将组合映射启发式方法转化为学习问题。我们的实验展示了A2D的有效性，对WMT-2022 De->Dsb和WMT-2014 En->De的BLEU分数分别获得高达+3.61和+0.63的提升。

    arXiv:2403.01479v1 Announce Type: cross  Abstract: The advent of scalable deep models and large datasets has improved the performance of Neural Machine Translation. Knowledge Distillation (KD) enhances efficiency by transferring knowledge from a teacher model to a more compact student model. However, KD approaches to Transformer architecture often rely on heuristics, particularly when deciding which teacher layers to distill from. In this paper, we introduce the 'Align-to-Distill' (A2D) strategy, designed to address the feature mapping problem by adaptively aligning student attention heads with their teacher counterparts during training. The Attention Alignment Module in A2D performs a dense head-by-head comparison between student and teacher attention heads across layers, turning the combinatorial mapping heuristics into a learning problem. Our experiments show the efficacy of A2D, demonstrating gains of up to +3.61 and +0.63 BLEU points for WMT-2022 De->Dsb and WMT-2014 En->De, respe
    
[^263]: 使用样本高效适应对大型语言模型进行自定义以进行代码生成

    SEED: Customize Large Language Models with Sample-Efficient Adaptation for Code Generation

    [https://arxiv.org/abs/2403.00046](https://arxiv.org/abs/2403.00046)

    SEED提出了一种名为Sample-Efficient adaptation with Error-Driven learning的新颖适应方法，利用LLMs产生的错误作为学习机会，从而实现对代码生成任务的高效学习。

    

    虽然大型语言模型（LLMs）在代码生成方面取得了重大进展，但在特定场景下仍然存在困难。这些场景通常需要调整LLMs以满足特定需求，但实际可用的训练数据有限，导致代码生成性能较差。如何有效地调整LLMs以适应新场景并使用更少的训练样本是当前代码生成面临的主要挑战。在本文中，我们提出了一种名为SEED的新颖适应方法，即Sample-Efficient adaptation with Error-Driven learning for code generation。SEED利用LLMs产生的错误作为学习机会，利用错误修订来克服自身缺点，从而实现有效学习。具体而言，SEED涉及识别LLMs生成的错误代码，使用Self-revise进行代码修订，优化模型并迭代地进行适应。

    arXiv:2403.00046v1 Announce Type: cross  Abstract: Although Large Language Models (LLMs) have made significant progress in code generation, they still struggle with code generation tasks in specific scenarios. These scenarios usually necessitate the adaptation of LLMs to fulfill specific needs, but the limited training data available in practice leads to poor code generation performance. How to effectively adapt LLMs to new scenarios with fewer training samples is a major challenge for current code generation. In this paper, we propose a novel adaptation approach named SEED, which stands for Sample-Efficient adaptation with Error-Driven learning for code generation. SEED leverages the errors made by LLMs as learning opportunities, using error revision to overcome its own shortcomings, thus achieving efficient learning. Specifically, SEED involves identifying error code generated by LLMs, employing Self-revise for code revision, optimizing the model with revised code, and iteratively ad
    
[^264]: 通过可解释的方言分类器提取方言的词汇特征

    Extracting Lexical Features from Dialects via Interpretable Dialect Classifiers

    [https://arxiv.org/abs/2402.17914](https://arxiv.org/abs/2402.17914)

    通过可解释的方言分类器提取方言的词汇特征，成功识别了有助于方言变化的关键语言特定词汇特征。

    

    识别一种语言的方言之间的语言差异通常需要专业知识和细致的人类分析。这主要是因为研究各种方言涉及到复杂性和微妙之处。我们提出了一种新颖的方法，通过利用可解释的方言分类器提取方言的区分性词汇特征，即使在没有人类专家的情况下。我们探索了事后和内在的解释性方法，对普通话、意大利语和低地萨克森语进行实验，并实验证明我们的方法成功地识别了有助于方言变化的关键语言特定词汇特征。

    arXiv:2402.17914v1 Announce Type: cross  Abstract: Identifying linguistic differences between dialects of a language often requires expert knowledge and meticulous human analysis. This is largely due to the complexity and nuance involved in studying various dialects. We present a novel approach to extract distinguishing lexical features of dialects by utilizing interpretable dialect classifiers, even in the absence of human experts. We explore both post-hoc and intrinsic approaches to interpretability, conduct experiments on Mandarin, Italian, and Low Saxon, and experimentally demonstrate that our method successfully identifies key language-specific lexical features that contribute to dialectal variations.
    
[^265]: 低资源条件下南亚语言的多语言共指解析

    Multilingual Coreference Resolution in Low-resource South Asian Languages

    [https://arxiv.org/abs/2402.13571](https://arxiv.org/abs/2402.13571)

    引入了一个用于31种南亚语言的多语言共指解析翻译数据集，通过利用现成工具进行训练和对齐，在低资源条件下实现了较好的共指解析模型性能提升。

    

    共指解析涉及识别在话语中指向同一现实实体的文本片段的任务。虽然这一任务在英语中得到了广泛研究，但在南亚语言中，公开可访问的共指解析资源和模型相对稀缺。我们利用现成的翻译和词对齐工具，在31种南亚语言中引入了一个用于多语言共指解析的翻译数据集（TransMuCoRes）。几乎所有预测的翻译都通过了合理性检查，75%的英语参考文献与其预测的翻译相对应。利用多语言编码器，我们训练了两种现成的共指解析模型，将TransMuCoRes与带有手动注释的印地语共指解析数据集拼接在一起。最佳表现模型在LEA F1和CoNLL F1上分别达到了64和68的分数。

    arXiv:2402.13571v1 Announce Type: cross  Abstract: Coreference resolution involves the task of identifying text spans within a discourse that pertain to the same real-world entity. While this task has been extensively explored in the English language, there has been a notable scarcity of publicly accessible resources and models for coreference resolution in South Asian languages. We introduce a Translated dataset for Multilingual Coreference Resolution (TransMuCoRes) in 31 South Asian languages using off-the-shelf tools for translation and word-alignment. Nearly all of the predicted translations successfully pass a sanity check, and 75% of English references align with their predicted translations. Using multilingual encoders, two off-the-shelf coreference resolution models were trained on a concatenation of TransMuCoRes and a Hindi coreference resolution dataset with manual annotations. The best performing model achieved a score of 64 and 68 for LEA F1 and CoNLL F1, respectively, on o
    
[^266]: 模式分析与机器智能领域文献综述的文献综述

    A Literature Review of Literature Reviews in Pattern Analysis and Machine Intelligence

    [https://arxiv.org/abs/2402.12928](https://arxiv.org/abs/2402.12928)

    本文旨在提供对模式分析与机器智能领域文献综述的全面评估，引入大语言模型驱动的文献计量指标，并构建了RiPAMI元数据数据库和主题数据集以获取PAMI综述的统计特征。

    

    通过整合分散的知识，文献综述提供了对所研究主题的全面了解。然而，在模式分析与机器智能（PAMI）这一蓬勃发展的领域中，过多的综述引起了研究人员和评论者的关注。作为对这些关注的回应，本文旨在从多个角度全面审视PAMI领域的综述文献。

    arXiv:2402.12928v1 Announce Type: cross  Abstract: By consolidating scattered knowledge, the literature review provides a comprehensive understanding of the investigated topic. However, excessive reviews, especially in the booming field of pattern analysis and machine intelligence (PAMI), raise concerns for both researchers and reviewers. In response to these concerns, this Analysis aims to provide a thorough review of reviews in the PAMI field from diverse perspectives. First, large language model-empowered bibliometric indicators are proposed to evaluate literature reviews automatically. To facilitate this, a meta-data database dubbed RiPAMI, and a topic dataset are constructed, which are utilized to obtain statistical characteristics of PAMI reviews. Unlike traditional bibliometric measurements, the proposed article-level indicators provide real-time and field-normalized quantified assessments of reviews without relying on user-defined keywords. Second, based on these indicators, th
    
[^267]: 使用大型语言模型解决数据中心任务

    Solving Data-centric Tasks using Large Language Models

    [https://arxiv.org/abs/2402.11734](https://arxiv.org/abs/2402.11734)

    本文提出了两点贡献：一是创建了一个真实世界的NL-to-code任务数据集，二是引入了一种聚类然后选择提示技术，从输入数据中添加最具代表性的行到LLM提示中。

    

    大型语言模型（LLMs）正在迅速取代像StackOverflow这样的帮助论坛，并且对于非专业程序员和最终用户特别有帮助。这些用户通常对数据中心任务感兴趣，例如电子表格操作和数据处理，如果仅通过自然语言描述传达意图而不包含数据，这些任务很难解决。但是，我们如何决定在提示中包含多少数据和哪些数据？本文对回答这个问题做出了两点贡献。首先，我们创建了一个从StackOverflow帖子中获取的操作表格数据的真实NL-to-code任务数据集。其次，我们引入了一种聚类然后选择提示技术，将输入数据中最具代表性的行添加到LLM提示中。我们的实验表明，LLM的性能确实对传递到提示中的数据量敏感，并且对于具有大量语法变体的任务，传递的数据量较大。

    arXiv:2402.11734v1 Announce Type: cross  Abstract: Large language models (LLMs) are rapidly replacing help forums like StackOverflow, and are especially helpful for non-professional programmers and end users. These users are often interested in data-centric tasks, such as spreadsheet manipulation and data wrangling, which are hard to solve if the intent is only communicated using a natural-language description, without including the data. But how do we decide how much data and which data to include in the prompt? This paper makes two contributions towards answering this question. First, we create a dataset of real-world NL-to-code tasks manipulating tabular data, mined from StackOverflow posts. Second, we introduce a cluster-then-select prompting technique, which adds the most representative rows from the input data to the LLM prompt. Our experiments show that LLM performance is indeed sensitive to the amount of data passed in the prompt, and that for tasks with a lot of syntactic vari
    
[^268]: LongHeads: 多头注意力其实是一个长上下文处理器

    LongHeads: Multi-Head Attention is Secretly a Long Context Processor

    [https://arxiv.org/abs/2402.10685](https://arxiv.org/abs/2402.10685)

    LongHeads 提出了一个无需训练的框架，通过释放多头注意力的潜力来增强大型语言模型(LLM)处理长上下文的能力。

    

    大型语言模型(LLMs)在许多领域取得了令人印象深刻的表现，但由于有限长度泛化和注意力的二次计算需求，往往难以有效高效地处理较长的输入。 许多人试图通过限制在预训练长度内的注意力窗口来缓解这一问题。 然而，这些方法引入了新问题，如忽略中间上下文和需要额外训练。 为了解决这些问题，我们提出了LongHeads，一个无需训练的框架，通过释放多头注意力的潜力来增强LLM的长上下文能力。 我们允许每个头部选择并关注重要的上下文块，以处理分布长度，而不是让每个头部都参与全句注意力，这样做由于分布之外的问题而难以泛化到更长的序列。

    arXiv:2402.10685v1 Announce Type: cross  Abstract: Large language models (LLMs) have achieved impressive performance in numerous domains but often struggle to process lengthy inputs effectively and efficiently due to limited length generalization and attention's quadratic computational demands. Many sought to mitigate this by restricting the attention window within the pre-trained length. However, these methods introduce new issues such as ignoring the middle context and requiring additional training. To address these problems, we propose LongHeads, a training-free framework that enhances LLM's long context ability by unlocking multi-head attention's untapped potential. Instead of allowing each head to attend to the full sentence, which struggles with generalizing to longer sequences due to out-of-distribution (OOD) issues, we allow each head to process in-distribution length by selecting and attending to important context chunks. To this end, we propose a chunk selection strategy that
    
[^269]: AI和人类能够真正交流吗？

    Can AI and humans genuinely communicate?

    [https://arxiv.org/abs/2402.09494](https://arxiv.org/abs/2402.09494)

    本研究探讨了AI和人类是否能够真正交流的问题，并提出了一种称为“心理行为方法”的回答方式，该方法通过测试AI是否展现出人类类似的行为来判断其是否能够与人类真正交流。

    

    这篇文章探讨了一个问题，即AI和人类是否能够真正交流。作者提出了一个称为“心理行为方法”的方式来回答这个问题。该方法包括三个步骤：首先明确人类交流所需的心理能力；其次确定测试这些能力的实验范式；最后将这些范式应用于测试AI是否展现出相关的行为。如果前两个步骤成功完成，并且AI在测试中展现出类似人类的结果，那么这可以被看作是AI和人类能够真正交流的证据。心理行为方法的优势在于我们不需要理解黑盒算法（比如标准深度学习算法）的工作原理。

    arXiv:2402.09494v1 Announce Type: cross  Abstract: Can AI and humans genuinely communicate? In this article, after giving some background and motivating my proposal (sections 1 to 3), I explore a way to answer this question that I call the "mental-behavioral methodology" (sections 4 and 5). This methodology follows the following three steps: First, spell out what mental capacities are sufficient for human communication (as opposed to communication more generally). Second, spell out the experimental paradigms required to test whether a behavior exhibits these capacities. Third, apply or adapt these paradigms to test whether an AI displays the relevant behaviors. If the first two steps are successfully completed, and if the AI passes the tests with human-like results, this constitutes evidence that this AI and humans can genuinely communicate. This mental-behavioral methodology has the advantage that we don't need to understand the workings of black-box algorithms, such as standard deep 
    
[^270]: 探索大型语言模型的对抗能力

    Exploring the Adversarial Capabilities of Large Language Models

    [https://arxiv.org/abs/2402.09132](https://arxiv.org/abs/2402.09132)

    本研究探索了大型语言模型的对抗能力，并发现其能够成功地制造对抗性示例以愚弄安全措施，特别是在仇恨言论检测方面具有重大影响。

    

    大型语言模型（LLMs）的普及引发了广泛和普遍的兴趣，因为它们具有强大的语言生成能力，为行业和研究提供了巨大的潜力。尽管以前的研究探讨了LLMs的安全性和隐私问题，但这些模型能否表现出对抗行为的程度仍然尚未完全探索。为了填补这一空白，我们研究常见的公开可用LLMs是否具有能力扰乱文本样本以愚弄安全措施，即所谓的对抗示例或攻击。更具体地说，我们调查LLMs是否本质上能够从良性样本中制造对抗性示例以愚弄现有的安全防线。我们的实验重点关注仇恨言论检测，发现LLMs成功地找到了对抗性扰动，有效地破坏了对仇恨言论检测系统的防御。我们的发现对（半）自动化安全评估和防御具有重要影响。

    arXiv:2402.09132v1 Announce Type: new Abstract: The proliferation of large language models (LLMs) has sparked widespread and general interest due to their strong language generation capabilities, offering great potential for both industry and research. While previous research delved into the security and privacy issues of LLMs, the extent to which these models can exhibit adversarial behavior remains largely unexplored. Addressing this gap, we investigate whether common publicly available LLMs have inherent capabilities to perturb text samples to fool safety measures, so-called adversarial examples resp.~attacks. More specifically, we investigate whether LLMs are inherently able to craft adversarial examples out of benign samples to fool existing safe rails. Our experiments, which focus on hate speech detection, reveal that LLMs succeed in finding adversarial perturbations, effectively undermining hate speech detection systems. Our findings carry significant implications for (semi-)aut
    
[^271]: 用于推断高效LLMs的串联Transformer

    Tandem Transformers for Inference Efficient LLMs

    [https://arxiv.org/abs/2402.08644](https://arxiv.org/abs/2402.08644)

    该论文提出了一种新的架构，称为串联Transformer，用于解决传统大型语言模型推断速度限制的问题。该架构通过将小型自回归模型和大模型以块模式结合起来，并让小模型关注大模型的丰富表示，从而显著提高了小模型的预测准确性。实验证明，在预训练数据集上，串联的PaLM2-Bison和PaLM2-Gecko相比独立的PaLM2-Gecko，在下一个词元预测准确性上提高了3.3%，并且相较于具有相似下游任务的PaLM2-Otter模型，加速比达到1.16倍。

    

    传统的大型语言模型( LLMs )具有自回归的特性，这使得推断速度受到限制，因为词元是按顺序生成的。尽管有些预测和并行解码技术试图减轻这个问题，但它们都有限制：要么依赖更精简但准确度较低的模型进行生成，要么没有充分利用基础LLM的表示。我们提出了一种新颖的架构，即串联Transformer，来解决这些问题。这种架构独特地结合了(1)一个小型自回归模型和(2)一个以块模式运行的大模型(同时处理多个词元)。通过让小模型关注大模型更丰富的表示，大幅提升小模型的预测准确性。在PaLM2预训练数据集上，PaLM2-Bison和PaLM2-Gecko的串联相较独立的PaLM2-Gecko，在下一个词元预测准确性上提升了3.3%，与具有相似下游任务的PaLM2-Otter模型相比，提供了1.16倍的加速比。

    The autoregressive nature of conventional large language models (LLMs) inherently limits inference speed, as tokens are generated sequentially. While speculative and parallel decoding techniques attempt to mitigate this, they face limitations: either relying on less accurate smaller models for generation or failing to fully leverage the base LLM's representations.   We introduce a novel architecture, Tandem transformers, to address these issues. This architecture uniquely combines (1) a small autoregressive model and (2) a large model operating in block mode (processing multiple tokens simultaneously). The small model's predictive accuracy is substantially enhanced by granting it attention to the large model's richer representations. On the PaLM2 pretraining dataset, a tandem of PaLM2-Bison and PaLM2-Gecko demonstrates a 3.3% improvement in next-token prediction accuracy over a standalone PaLM2-Gecko, offering a 1.16x speedup compared to a PaLM2-Otter model with comparable downstream p
    
[^272]: 安全多模态学习系统调研

    A Survey on Safe Multi-Modal Learning System

    [https://arxiv.org/abs/2402.05355](https://arxiv.org/abs/2402.05355)

    这项研究提出了第一个多模态学习系统安全的分类法，对当前发展状态下的关键限制进行了审查，并提出了未来研究的潜在方向。

    

    随着多模态学习系统在现实场景中的广泛应用，安全问题变得越来越突出。对于这一领域的安全问题缺乏系统性研究已成为一个重要的障碍。为了解决这个问题，我们提出了第一个多模态学习系统安全的分类法，确定了这些问题的四个关键支柱。借助这一分类法，我们对每个支柱进行了深入审查，突出了当前发展状态的关键限制。最后，我们指出了多模态学习系统安全面临的独特挑战，并提供了未来研究的潜在方向。

    With the wide deployment of multimodal learning systems (MMLS) in real-world scenarios, safety concerns have become increasingly prominent. The absence of systematic research into their safety is a significant barrier to progress in this field. To bridge the gap, we present the first taxonomy for MMLS safety, identifying four essential pillars of these concerns. Leveraging this taxonomy, we conduct in-depth reviews for each pillar, highlighting key limitations based on the current state of development. Finally, we pinpoint unique challenges in MMLS safety and provide potential directions for future research.
    
[^273]: 见 JEANIE：通过时间-视角对齐的三维骨架序列相似度测量

    Meet JEANIE: a Similarity Measure for 3D Skeleton Sequences via Temporal-Viewpoint Alignment

    [https://arxiv.org/abs/2402.04599](https://arxiv.org/abs/2402.04599)

    JEANIE是一种通过时间-视角对齐的方法，用于测量三维骨架序列的相似度。它能够解决视频序列中速度、时间位置和姿势的干扰变化问题。在评估了骨架Few-shot动作识别任务后，JEANIE在支持-查询序列对的时间块匹配方面表现出了良好的效果。

    

    视频序列表现出显著的干扰性变化，包括动作速度、时间位置和主体姿势，导致在比较两组帧或评估两个序列的相似度时产生时间-视角不匹配的问题。因此，我们提出了一种用于序列对比的联合时间和摄像机视角对齐方法（JEANIE）。我们特别关注能够在三维中轻松操作摄像机和主体姿势的三维骨架序列。我们在骨架Few-shot动作识别（FSAR）上评估了JEANIE，其中由于新类别样本有限，通过匹配好支持-查询序列对的时间块（组成序列的时间块）来排除干扰变化是至关重要的。针对查询序列，我们通过模拟多个摄像机位置创建多个视角。对于支持序列，我们将其与模拟出的查询序列进行匹配，类似于流行的动态时间规整（DTW）。具体而言，每个支持时间块可以与视角模拟的查询序列匹配，如DTW。

    Video sequences exhibit significant nuisance variations (undesired effects) of speed of actions, temporal locations, and subjects' poses, leading to temporal-viewpoint misalignment when comparing two sets of frames or evaluating the similarity of two sequences. Thus, we propose Joint tEmporal and cAmera viewpoiNt alIgnmEnt (JEANIE) for sequence pairs. In particular, we focus on 3D skeleton sequences whose camera and subjects' poses can be easily manipulated in 3D. We evaluate JEANIE on skeletal Few-shot Action Recognition (FSAR), where matching well temporal blocks (temporal chunks that make up a sequence) of support-query sequence pairs (by factoring out nuisance variations) is essential due to limited samples of novel classes. Given a query sequence, we create its several views by simulating several camera locations. For a support sequence, we match it with view-simulated query sequences, as in the popular Dynamic Time Warping (DTW). Specifically, each support temporal block can be m
    
[^274]: Uni-RLHF: 用于多样化人类反馈的强化学习通用平台和基准套件

    Uni-RLHF: Universal Platform and Benchmark Suite for Reinforcement Learning with Diverse Human Feedback

    [https://arxiv.org/abs/2402.02423](https://arxiv.org/abs/2402.02423)

    Uni-RLHF是一个通用的强化学习平台和基准套件，致力于处理多样化的人类反馈，解决了在RLHF中量化进展的挑战，并提供了用户友好的注释界面和离线基准实现。

    

    强化学习与人类反馈（RLHF）通过与人类偏好对齐，避免了昂贵的手动奖励设计，已经受到了广泛关注。考虑到不同环境中不同学习方法和多样化的人类反馈类型对RLHF的进步进行量化是具有挑战性的，因为缺乏标准化的注释平台和广泛使用的统一基准。为了填补这个空白，我们引入了Uni-RLHF，这是一个为RLHF量身定制的综合系统实现。它旨在提供一个完整的从真实人类反馈到实际问题发展的工作流。Uni-RLHF包含三个部分：1）通用的多反馈注释平台，2）大规模的众包反馈数据集，3）模块化的离线RLHF基准实现。Uni-RLHF开发了一个用户友好的注释界面，适用于各种反馈类型，并与主要的强化学习框架兼容。

    Reinforcement Learning with Human Feedback (RLHF) has received significant attention for performing tasks without the need for costly manual reward design by aligning human preferences. It is crucial to consider diverse human feedback types and various learning methods in different environments. However, quantifying progress in RLHF with diverse feedback is challenging due to the lack of standardized annotation platforms and widely used unified benchmarks. To bridge this gap, we introduce Uni-RLHF, a comprehensive system implementation tailored for RLHF. It aims to provide a complete workflow from real human feedback, fostering progress in the development of practical problems. Uni-RLHF contains three packages: 1) a universal multi-feedback annotation platform, 2) large-scale crowdsourced feedback datasets, and 3) modular offline RLHF baseline implementations. Uni-RLHF develops a user-friendly annotation interface tailored to various feedback types, compatible with a wide range of main
    
[^275]: 自监督对比预测

    Self-Supervised Contrastive Forecasting

    [https://arxiv.org/abs/2402.02023](https://arxiv.org/abs/2402.02023)

    该论文介绍了一种通过采用对比学习和增强的分解架构，并结合全局自相关性的自监督方法来解决长期预测中的挑战。实验证明，该方法在九个长期基准上的多个实验中胜过了14个基线模型。

    

    长期预测由于处理长序列的时间和内存复杂性而面临独特挑战。现有方法依赖于滑动窗口来处理长序列，难以有效捕捉部分在短窗口内被捕捉到的长期变化（即外窗口变化）。本文介绍了一种新颖的方法，通过采用对比学习和增强的分解架构，专门设计用于聚焦长期变化，从而克服了这个限制。为此，我们的对比损失将整个时间序列中的全局自相关性纳入考虑，以自监督方式构建正负对。当与我们的分解网络结合使用时，我们的对比学习显著提高了长期预测性能。广泛的实验表明，我们的方法在九个长期基准上的多个实验中胜过了14个基线模型。

    Long-term forecasting presents unique challenges due to the time and memory complexity of handling long sequences. Existing methods, which rely on sliding windows to process long sequences, struggle to effectively capture long-term variations that are partially caught within the short window (i.e., outer-window variations). In this paper, we introduce a novel approach that overcomes this limitation by employing contrastive learning and enhanced decomposition architecture, specifically designed to focus on long-term variations. To this end, our contrastive loss incorporates global autocorrelation held in the whole time series, which facilitates the construction of positive and negative pairs in a self-supervised manner. When combined with our decomposition networks, our contrastive learning significantly improves long-term forecasting performance. Extensive experiments demonstrate that our approach outperforms 14 baseline models in multiple experiments over nine long-term benchmarks, es
    
[^276]: Sandra -- 基于描述和情境的神经符号推理器

    Sandra -- A Neuro-Symbolic Reasoner Based On Descriptions And Situations

    [https://arxiv.org/abs/2402.00591](https://arxiv.org/abs/2402.00591)

    Sandra是一个神经符号推理器，通过将矢量表示与演绎推理相结合，利用本体论建立的向量空间进行推理。它基于描述和情境的本体设计模式，能够从一组事实中推断出所有可能的解释，并在实验中证明在不增加复杂性的情况下优于其他基准线的分类结果，并且具有可解释性和向量空间的可控性。

    

    本文介绍了Sandra，这是一个将矢量表示与演绎推理相结合的神经符号推理器。Sandra使用本体论建立了一个受限的向量空间，并在其中进行推理。推理器的几何特性使得它能够与神经网络结合起来，弥合了符号知识表达与神经网络之间的差距。Sandra基于描述和情境(DnS)本体设计模式，它是一种框架语义的形式化。给定一组事实(情境)，它能够推断出所有可能的透视图(描述)，为其提供一个合理的解释，即使在信息不完整的情况下也能做到。我们证明了我们的方法在DnS模型上是正确的。我们对两个不同任务及其标准基准进行了实验，证明了Sandra不增加复杂性的情况下：(i)优于所有基准线；(ii) 在分类过程中提供可解释性；(iii)对向量空间具有可控性。

    This paper presents sandra, a neuro-symbolic reasoner combining vectorial representations with deductive reasoning. Sandra builds a vector space constrained by an ontology and performs reasoning over it. The geometric nature of the reasoner allows its combination with neural networks, bridging the gap with symbolic knowledge representations. Sandra is based on the Description and Situation (DnS) ontology design pattern, a formalization of frame semantics. Given a set of facts (a situation) it allows to infer all possible perspectives (descriptions) that can provide a plausible interpretation for it, even in presence of incomplete information. We prove that our method is correct with respect to the DnS model. We experiment with two different tasks and their standard benchmarks, demonstrating that, without increasing complexity, sandra (i) outperforms all the baselines (ii) provides interpretability in the classification process, and (iii) allows control over the vector space, which is d
    
[^277]: 重新思考多元时间序列预测的通道相关性：从领先指标中学习

    Rethinking Channel Dependence for Multivariate Time Series Forecasting: Learning from Leading Indicators

    [https://arxiv.org/abs/2401.17548](https://arxiv.org/abs/2401.17548)

    本文提出了一种新方法，LIFT，通过利用通道相关性和领先指标，为多元时间序列预测提供准确的预测。LIFT方法可以无缝与任意时间序列预测方法协作，大量实验证明了其有效性。

    

    最近，独立于通道的方法在多元时间序列（MTS）预测中取得了最先进的性能。尽管这些方法减少了过拟合的风险，但它们错过了利用通道相关性进行准确预测的潜在机会。我们认为，在变量之间存在局部平稳的领先-滞后关系，即一些滞后变量在短时间内可能遵循领先指标。利用这种通道相关性是有益的，因为领先指标提供了先进信息，可以用来减少滞后变量的预测难度。在本文中，我们提出了一种名为LIFT的新方法，该方法首先在每个时间步骤高效地估计领先指标及其领先步骤，然后巧妙地允许滞后变量利用来自领先指标的先进信息。LIFT作为一个插件，可以与任意时间序列预测方法无缝协作。进行了大量实验证明了LIFT方法的有效性。

    Recently, channel-independent methods have achieved state-of-the-art performance in multivariate time series (MTS) forecasting. Despite reducing overfitting risks, these methods miss potential opportunities in utilizing channel dependence for accurate predictions. We argue that there exist locally stationary lead-lag relationships between variates, i.e., some lagged variates may follow the leading indicators within a short time period. Exploiting such channel dependence is beneficial since leading indicators offer advance information that can be used to reduce the forecasting difficulty of the lagged variates. In this paper, we propose a new method named LIFT that first efficiently estimates leading indicators and their leading steps at each time step and then judiciously allows the lagged variates to utilize the advance information from leading indicators. LIFT plays as a plugin that can be seamlessly collaborated with arbitrary time series forecasting methods. Extensive experiments o
    
[^278]: LCV2：一种高效的免预训练框架用于基于视觉的问答任务

    LCV2: An Efficient Pretraining-Free Framework for Grounded Visual Question Answering

    [https://arxiv.org/abs/2401.15842](https://arxiv.org/abs/2401.15842)

    LCV2提出了一种高效的兼容各种预训练模型的基于视觉问答的框架，无需预训练过程，适用于低计算资源下的任务

    

    本文提出了LCV2模块化方法，用于在视觉-语言多模域中的基于视觉的问答任务。该方法依赖于一个冻结的大型语言模型（LLM），作为现成VQA模型和现成视觉定位（VG）模型之间的中间介质，LLM基于设计的提示转换和传递文本信息。LCV2建立了一个集成的即插即用框架，无需任何预训练过程，可以在低计算资源下用于VQA Grounding任务。该框架允许与各种最先进的预训练模型一起使用，具有与时俱进的潜力。在受限制的计算资源和内存资源下进行了实验实现，评估了所提方法在基准上的性

    arXiv:2401.15842v2 Announce Type: replace-cross  Abstract: In this paper, the LCV2 modular method is proposed for the Grounded Visual Question Answering task in the vision-language multimodal domain. This approach relies on a frozen large language model (LLM) as intermediate mediator between the off-the-shelf VQA model and the off-the-shelf visual grounding (VG) model, where the LLM transforms and conveys textual information between the two modules based on a designed prompt. LCV2 establish an integrated plug-and-play framework without the need for any pre-training process. This framework can be deployed for VQA Grounding tasks under low computational resources. The modularized model within the framework allows application with various state-of-the-art pre-trained models, exhibiting significant potential to be advance with the times. Experimental implementations were conducted under constrained computational and memory resources, evaluating the proposed method's performance on benchmar
    
[^279]: 随着文本量增加，推断训练有助于长文本生成

    With Greater Text Comes Greater Necessity: Inference-Time Training Helps Long Text Generation

    [https://arxiv.org/abs/2401.11504](https://arxiv.org/abs/2401.11504)

    Temp-Lora方法通过在长文本生成过程中逐步训练临时Lora模块，有效保留上下文知识并避免对模型参数的永久性改变。

    

    长文本生成，如小说创作和具有极长上下文的篇章级翻译，对当前的语言模型提出了重大挑战。现有方法主要集中在通过长度外推等策略扩展模型的上下文窗口。然而，这些方法在训练和/或推断阶段要求大量硬件资源。我们提出的方法Temp-Lora引入了一个替代概念。我们不依赖于KV缓存存储所有上下文信息，而是将这些信息直接嵌入临时Lora模块中。在长文本生成过程中，这个模块会随着先前生成的文本逐渐进行训练。这种方法不仅有效地保留上下文知识，还防止了对模型参数的任何永久性改变，因为模块在生成后被丢弃。在PG19语言建模上进行了大量实验。

    arXiv:2401.11504v2 Announce Type: replace-cross  Abstract: Long text generation, such as novel writing and discourse-level translation with extremely long contexts, presents significant challenges to current language models. Existing methods mainly focus on extending the model's context window through strategies like length extrapolation. However, these approaches demand substantial hardware resources during the training and/or inference phases. Our proposed method, Temp-Lora, introduces an alternative concept. Instead of relying on the KV cache to store all context information, we embeds this information directly into a temporary Lora module. In the process of long text generation, this module is progressively trained with text generated previously. This approach not only efficiently preserves contextual knowledge but also prevents any permanent alteration to the model's parameters given that the module is discarded post-generation. Extensive experiments on the PG19 language modeling 
    
[^280]: 一项关于改善图像分类模型公平性的大规模实证研究

    A Large-Scale Empirical Study on Improving the Fairness of Image Classification Models

    [https://arxiv.org/abs/2401.03695](https://arxiv.org/abs/2401.03695)

    本研究进行了大规模实证研究，比较了现有最先进的公平性改进技术在图像分类模型上的表现，揭示了它们之间的显著差异

    

    公平性一直是影响深度学习模型在实际应用中被采纳的关键问题。为了提高模型的公平性，已经提出了许多现有方法，并证实在各自的情境中是有效的。然而，它们之间仍然没有进行系统的评估以便在相同情境下进行全面比较，这使得理解它们之间的性能差异变得困难，阻碍了研究进展和实际应用。为了填补这一空白，本文致力于进行首次大规模实证研究，全面比较现有最先进的公平性改进技术的性能。具体而言，我们针对广泛使用的图像分类应用场景，利用三个不同数据集和五种常用性能指标，总共评估了来自不同类别的 13 种方法。我们的研究结果揭示了不同方法之间的显著差异。

    arXiv:2401.03695v2 Announce Type: replace-cross  Abstract: Fairness has been a critical issue that affects the adoption of deep learning models in real practice. To improve model fairness, many existing methods have been proposed and evaluated to be effective in their own contexts. However, there is still no systematic evaluation among them for a comprehensive comparison under the same context, which makes it hard to understand the performance distinction among them, hindering the research progress and practical adoption of them. To fill this gap, this paper endeavours to conduct the first large-scale empirical study to comprehensively compare the performance of existing state-of-the-art fairness improving techniques. Specifically, we target the widely-used application scenario of image classification, and utilized three different datasets and five commonly-used performance metrics to assess in total 13 methods from diverse categories. Our findings reveal substantial variations in the 
    
[^281]: 手术器械部分-整体协作提示用于手术器械分割的研究

    SurgicalPart-SAM: Part-to-Whole Collaborative Prompting for Surgical Instrument Segmentation

    [https://arxiv.org/abs/2312.14481](https://arxiv.org/abs/2312.14481)

    本文提出了一种手术器械分割的新方法SurgicalPart-SAM (SP-SAM)，通过整合器械结构知识与SAM的通用知识，实现了有效调整，从而解决了器械细节和结构描述的问题。

    

    Segment Anything Model（SAM）在通用对象分割方面显示出潜力，并为各种应用提供了可能性。现有方法已将SAM应用于手术器械分割（SIS），通过使用手术数据调整基于SAM的框架。然而，它们在两个关键方面存在不足：（1）使用器械掩模直接调整模型将每个器械视为单个实体，忽略了其复杂结构和细粒度细节；（2）基于器械类别的提示不够灵活和信息丰富，无法描述器械结构。为解决这些问题，在本文中，我们研究了可提示的SIS，并提出了手术器械部分-SAM（SP-SAM），一种新颖的SAM高效调整方法，明确将器械结构知识与SAM的通用知识整合在一起，由器械部分组成的专家知识指导。具体来说，我们通过提出

    arXiv:2312.14481v2 Announce Type: replace-cross  Abstract: The Segment Anything Model (SAM) exhibits promise in generic object segmentation and offers potential for various applications. Existing methods have applied SAM to surgical instrument segmentation (SIS) by tuning SAM-based frameworks with surgical data. However, they fall short in two crucial aspects: (1) Straightforward model tuning with instrument masks treats each instrument as a single entity, neglecting their complex structures and fine-grained details; and (2) Instrument category-based prompts are not flexible and informative enough to describe instrument structures. To address these problems, in this paper, we investigate text promptable SIS and propose SurgicalPart-SAM (SP-SAM), a novel SAM efficient-tuning approach that explicitly integrates instrument structure knowledge with SAM's generic knowledge, guided by expert knowledge on instrument part compositions. Specifically, we achieve this by proposing (1) Collaborati
    
[^282]: TagAlign：利用多标签分类改进视觉-语言对齐

    TagAlign: Improving Vision-Language Alignment with Multi-Tag Classification

    [https://arxiv.org/abs/2312.14149](https://arxiv.org/abs/2312.14149)

    提出了一种简单的方法，通过解析图像与文本中的对象和属性，使用多标签分类损失来改进视觉-语言对齐模型

    

    学习视觉-语言模型的关键在于从视觉和语言数据中提取语义对齐的信息。我们提出了一种非常简单的方法，可以更好地对齐图像和文本特征，而无需除图像-文本对之外的其他数据格式。具体而言，给定一幅图像及其配对的文本，我们设法从描述中解析出对象（例如猫）和属性（例如黑色），这些对象和属性极有可能存在于图像中。值得注意的是，解析管道完全自动化，因此具有良好的可扩展性。借助这些解析出的语义作为监督信号，我们可以将常用的图像-文本对比损失与多标签分类损失相结合。在广泛的实验结果中

    arXiv:2312.14149v3 Announce Type: replace-cross  Abstract: The crux of learning vision-language models is to extract semantically aligned information from visual and linguistic data. Existing attempts usually face the problem of coarse alignment, e.g., the vision encoder struggles in localizing an attribute-specified object. In this work, we propose an embarrassingly simple approach to better align image and text features with no need of additional data formats other than image-text pairs. Concretely, given an image and its paired text, we manage to parse objects (\textit{e.g.}, cat) and attributes (\textit{e.g.}, black) from the description, which are highly likely to exist in the image. It is noteworthy that the parsing pipeline is fully automatic and thus enjoys good scalability. With these parsed semantics as supervision signals, we can complement the commonly used image-text contrastive loss with the multi-tag classification loss. Extensive experimental results on a broad suite of
    
[^283]: PIA:通过插拔式模块在文本到图像模型中实现个性化图像动画

    PIA: Your Personalized Image Animator via Plug-and-Play Modules in Text-to-Image Models

    [https://arxiv.org/abs/2312.13964](https://arxiv.org/abs/2312.13964)

    PIA通过插拔式模块在文本到图像模型中实现个性化图像动画，并解决了保留独特风格、高保真细节和动作可控性的挑战

    

    最近个性化文本到图像（T2I）模型的进展已经彻底改变了内容创作，使非专家能够生成具有独特风格的惊人图像。然而，通过文本为这些个性化图像增加逼真的动作在保留独特风格、高保真细节和通过文本实现动作可控性方面面临着重大挑战。在本文中，我们提出了PIA，一种个性化图像动画生成器，其在与条件图像对齐、通过文本实现动作可控性以及与各种个性化T2I模型的兼容性上表现出色，无需特定调整。为了实现这些目标，PIA在基础T2I模型的基础上构建了经过良好训练的时间对齐层，从而实现了任何个性化T2I模型向图像动画模型的无缝转换。PIA的一个关键组件是引入条件模块，利用条件帧和帧间

    arXiv:2312.13964v2 Announce Type: replace-cross  Abstract: Recent advancements in personalized text-to-image (T2I) models have revolutionized content creation, empowering non-experts to generate stunning images with unique styles. While promising, adding realistic motions into these personalized images by text poses significant challenges in preserving distinct styles, high-fidelity details, and achieving motion controllability by text. In this paper, we present PIA, a Personalized Image Animator that excels in aligning with condition images, achieving motion controllability by text, and the compatibility with various personalized T2I models without specific tuning. To achieve these goals, PIA builds upon a base T2I model with well-trained temporal alignment layers, allowing for the seamless transformation of any personalized T2I model into an image animation model. A key component of PIA is the introduction of the condition module, which utilizes the condition frame and inter-frame af
    
[^284]: 使用回声状态网络的多智能体强化学习及其在行人动态中的应用

    Multi-agent reinforcement learning using echo-state network and its application to pedestrian dynamics

    [https://arxiv.org/abs/2312.11834](https://arxiv.org/abs/2312.11834)

    通过使用回声状态网络将行人实现为MARL代理，研究了他们学习避让其他代理向前移动的能力，在密度不太高的情况下取得成功。

    

    近年来，研究使用多智能体强化学习（MARL）模拟行人。本研究考虑了网格世界环境中的道路，并将行人实现为使用回声状态网络和最小二乘策略迭代方法的MARL代理。在这个环境下，研究了这些代理学习避开其他代理向前移动的能力。具体而言，我们考虑了两种任务：窄直接路径和宽绕道之间的选择，以及走廊中的双向行人流。模拟结果表明，当代理密度不太高时，学习是成功的。

    arXiv:2312.11834v2 Announce Type: replace-cross  Abstract: In recent years, simulations of pedestrians using the multi-agent reinforcement learning (MARL) have been studied. This study considered the roads on a grid-world environment, and implemented pedestrians as MARL agents using an echo-state network and the least squares policy iteration method. Under this environment, the ability of these agents to learn to move forward by avoiding other agents was investigated. Specifically, we considered two types of tasks: the choice between a narrow direct route and a broad detour, and the bidirectional pedestrian flow in a corridor. The simulations results indicated that the learning was successful when the density of the agents was not that high.
    
[^285]: BaRDa: 一个将事实准确性和推理能力分开的信念和推理数据集

    BaRDa: A Belief and Reasoning Dataset that Separates Factual Accuracy and Reasoning Ability

    [https://arxiv.org/abs/2312.07527](https://arxiv.org/abs/2312.07527)

    BaRDa数据集通过使用人类注释的蕴涵树，混合真实和虚假事实，并包括反事实例子，成功区分了事实准确性和推理能力。

    

    尽管存在许多基准来比较现代语言模型（LMs）的性能，但最终任务评估往往混淆了*事实准确性*（"真相"）和*推理能力*（"合理性"，或者根据正确报告信念含义来定义的"诚实"）。我们的目标是创建一个能够清晰区分这两个概念的数据集。我们的方法是利用和扩展一组人类注释的*蕴涵树*，用于表达良好和恶劣的推理链，并使用真实和虚假事实的混合，特别是包括反事实的例子，以避免信念偏见（也称为"内容效应"）。结果数据集名为BaRDa，包含3000个蕴涵（1787个有效，1213个无效），使用6681个真实和2319个虚假陈述。在四个GPT系列模型 GPT3(curie)/GPT3(davinici)/3.5/4 上进行测试，发现事实准确性（真相）得分为74.1/80.6/82.6/87.1以及推理能力

    arXiv:2312.07527v2 Announce Type: replace-cross  Abstract: While there are numerous benchmarks comparing the performance of modern language models (LMs), end-task evaluations often conflate notions of *factual accuracy* ("truth") and *reasoning ability* ("rationality", or "honesty" in the sense of correctly reporting implications of beliefs). Our goal is a dataset that clearly distinguishes these two notions. Our approach is to leverage and extend a collection of human-annotated *entailment trees*, engineered to express both good and bad chains of reasoning, and using a mixture of true and false facts, in particular including counterfactual examples, to avoid belief bias (also known as the "content effect"). The resulting dataset, called BaRDa, contains 3000 entailments (1787 valid, 1213 invalid), using 6681 true and 2319 false statements. Testing on four GPT-series models, GPT3(curie)/GPT3(davinici)/3.5/4, we find factual accuracy (truth) scores of 74.1/80.6/82.6/87.1 and reasoning ac
    
[^286]: 在6G移动边缘计算网络中，AI生成内容服务的卸载和质量控制

    Offloading and Quality Control for AI Generated Content Services in 6G Mobile Edge Computing Networks

    [https://arxiv.org/abs/2312.06203](https://arxiv.org/abs/2312.06203)

    该论文提出了在6G移动边缘计算网络中针对AI生成内容服务的卸载和质量控制问题的联合优化算法。

    

    AI生成内容(AIGC)作为在即将到来的互联网范式中提供Metaverse服务的新颖方式，可以解决沉浸需求的障碍。同时，边缘计算作为通信系统中的计算进化范式，有效增强了实时交互服务。为了提高AIGC服务的可访问性，将AIGC模型（如扩散模型）部署到边缘服务器和本地设备已成为一种盛行趋势。然而，当任务卸载到本地设备时，面临的约束包括电池寿命和计算资源，限制了在遵守严格的延迟要求的同时向用户提供高质量内容的能力。因此，在边缘计算范式中，AIGC模型的效用和卸载决策之间将存在权衡。本文提出了一种用于卸载决策的联合优化算法。

    arXiv:2312.06203v2 Announce Type: replace  Abstract: AI-Generated Content (AIGC), as a novel manner of providing Metaverse services in the forthcoming Internet paradigm, can resolve the obstacles of immersion requirements. Concurrently, edge computing, as an evolutionary paradigm of computing in communication systems, effectively augments real-time interactive services. In pursuit of enhancing the accessibility of AIGC services, the deployment of AIGC models (e.g., diffusion models) to edge servers and local devices has become a prevailing trend. Nevertheless, this approach faces constraints imposed by battery life and computational resources when tasks are offloaded to local devices, limiting the capacity to deliver high-quality content to users while adhering to stringent latency requirements. So there will be a tradeoff between the utility of AIGC models and offloading decisions in the edge computing paradigm. This paper proposes a joint optimization algorithm for offloading decisio
    
[^287]: I-PHYRE: 交互式物理推理

    I-PHYRE: Interactive Physical Reasoning

    [https://arxiv.org/abs/2312.03009](https://arxiv.org/abs/2312.03009)

    I-PHYRE是一个挑战代理同时展示直观的物理推理、多步规划和就地干预能力的框架。

    

    当前的评估协议主要评估静态场景中的物理推理，存在评估代理与动态事件进行交互的能力的缺口。尽管当代方法允许代理修改初始场景配置并观察结果，但它们缺乏实时与事件交互的能力。为了解决这一问题，我们引入了I-PHYRE，一个框架挑战代理同时展示直观的物理推理、多步规划和就地干预。这里，直观的物理推理指的是快速、近似理解物理学以解决复杂问题；多步表示在I-PHYRE中需要进行广泛的序列规划，考虑到每次干预都可能显著改变后续选择；而就地意味着在场景内及时进行物体操作的必要性，在这里，微小的时间偏差可能导致任务失败。我们制定了四个游戏分支。

    arXiv:2312.03009v2 Announce Type: replace  Abstract: Current evaluation protocols predominantly assess physical reasoning in stationary scenes, creating a gap in evaluating agents' abilities to interact with dynamic events. While contemporary methods allow agents to modify initial scene configurations and observe consequences, they lack the capability to interact with events in real time. To address this, we introduce I-PHYRE, a framework that challenges agents to simultaneously exhibit intuitive physical reasoning, multi-step planning, and in-situ intervention. Here, intuitive physical reasoning refers to a quick, approximate understanding of physics to address complex problems; multi-step denotes the need for extensive sequence planning in I-PHYRE, considering each intervention can significantly alter subsequent choices; and in-situ implies the necessity for timely object manipulation within a scene, where minor timing deviations can result in task failure. We formulate four game spl
    
[^288]: Word4Per: Zero-shot组合人员检索

    Word4Per: Zero-shot Composed Person Retrieval

    [https://arxiv.org/abs/2311.16515](https://arxiv.org/abs/2311.16515)

    提出了一个新任务：组合人员检索（CPR），旨在联合利用图像和文本信息进行目标人员检索，引入零样本组合人员检索（ZS-CPR）解决了CPR问题，提出了一个两阶段学习框架Word4Per。

    

    寻找特定人员具有极大的社会效益和安全价值，通常涉及视觉和文本信息的结合。本文提出了一个全新的任务，称为组合人员检索（CPR），旨在联合利用图像和文本信息进行目标人员检索。然而，监督CPR需要昂贵的手动注释数据集，而目前没有可用资源。为了解决这个问题，我们首先引入了零样本组合人员检索（ZS-CPR），利用现有的领域相关数据解决了CPR问题而不需要昂贵的注释。其次，为了学习ZS-CPR模型，我们提出了一个两阶段学习框架，即Word4Per，其中包含一个轻量级的文本反转网络。

    arXiv:2311.16515v2 Announce Type: replace-cross  Abstract: Searching for specific person has great social benefits and security value, and it often involves a combination of visual and textual information. Conventional person retrieval methods, whether image-based or text-based, usually fall short in effectively harnessing both types of information, leading to the loss of accuracy. In this paper, a whole new task called Composed Person Retrieval (CPR) is proposed to jointly utilize both image and text information for target person retrieval. However, the supervised CPR requires very costly manual annotation dataset, while there are currently no available resources. To mitigate this issue, we firstly introduce the Zero-shot Composed Person Retrieval (ZS-CPR), which leverages existing domain-related data to resolve the CPR problem without expensive annotations. Secondly, to learn ZS-CPR model, we propose a two-stage learning framework, Word4Per, where a lightweight Textual Inversion Netw
    
[^289]: HalluciDoctor: 减轻视觉指令数据中的幻觉毒性

    HalluciDoctor: Mitigating Hallucinatory Toxicity in Visual Instruction Data

    [https://arxiv.org/abs/2311.13614](https://arxiv.org/abs/2311.13614)

    本研究提出了一个新颖的幻觉检测和消除框架HalluciDoctor，旨在减轻大规模机器生成的视觉指令数据中的幻觉毒性。

    

    大型多模态语言模型（MLLMs）在机器生成的指令跟随数据上进行调整，已经在各种多模态理解和生成任务中展现出卓越的性能。然而，机器生成数据中固有的幻觉，可能导致MLLMs产生幻觉输出，这一问题仍未得到充分探讨。本研究旨在调查大规模机器生成的视觉指令数据中的各种幻觉（即对象、关系、属性幻觉），并减轻这些幻觉毒性。借鉴人类识别事实错误的能力，我们提出了一个基于交叉检查范式的新颖幻觉检测和消除框架HalluciDoctor。我们使用我们的框架自动地识别和消除训练数据中的幻觉。有趣的是，HalluciDoctor还表明，长尾对象共现产生的虚假相关性也可能导致幻觉。

    arXiv:2311.13614v2 Announce Type: replace-cross  Abstract: Multi-modal Large Language Models (MLLMs) tuned on machine-generated instruction-following data have demonstrated remarkable performance in various multi-modal understanding and generation tasks. However, the hallucinations inherent in machine-generated data, which could lead to hallucinatory outputs in MLLMs, remain under-explored. This work aims to investigate various hallucinations (i.e., object, relation, attribute hallucinations) and mitigate those hallucinatory toxicities in large-scale machine-generated visual instruction datasets. Drawing on the human ability to identify factual errors, we present a novel hallucination detection and elimination framework, HalluciDoctor, based on the cross-checking paradigm. We use our framework to identify and eliminate hallucinations in the training data automatically. Interestingly, HalluciDoctor also indicates that spurious correlations arising from long-tail object co-occurrences co
    
[^290]: 使用人类反馈来微调扩散模型而无需任何奖励模型

    Using Human Feedback to Fine-tune Diffusion Models without Any Reward Model

    [https://arxiv.org/abs/2311.13231](https://arxiv.org/abs/2311.13231)

    该论文提出了一种名为D3PO的方法，通过使用人类反馈直接微调扩散模型，无需奖励模型，从而在消除了奖励模型的前提下改进了现有方法，并解决了DPO方法直接应用的内存需求问题。

    

    使用带有人类反馈的强化学习（RLHF）在微调扩散模型方面显示出了显著的潜力。以往的方法首先是通过训练与人类偏好相一致的奖励模型，然后利用强化学习技术来微调基础模型。然而，设计高效的奖励模型需要大量数据集、最佳架构和手动超参数调整，使得这一过程既耗时又成本高昂。直接偏好优化（DPO）方法，在微调大型语言模型方面表现出色，消除了对奖励模型的需求。然而，扩散模型去噪过程的大量GPU内存需求阻碍了DPO方法的直接应用。为解决这一问题，我们引入了直接偏好去噪扩散策略优化（D3PO）方法来直接微调扩散模型。理论分析表明，尽管D3PO提供了改进，但在具有明显优势的同时仍需要更多研究。

    arXiv:2311.13231v3 Announce Type: replace-cross  Abstract: Using reinforcement learning with human feedback (RLHF) has shown significant promise in fine-tuning diffusion models. Previous methods start by training a reward model that aligns with human preferences, then leverage RL techniques to fine-tune the underlying models. However, crafting an efficient reward model demands extensive datasets, optimal architecture, and manual hyperparameter tuning, making the process both time and cost-intensive. The direct preference optimization (DPO) method, effective in fine-tuning large language models, eliminates the necessity for a reward model. However, the extensive GPU memory requirement of the diffusion model's denoising process hinders the direct application of the DPO method. To address this issue, we introduce the Direct Preference for Denoising Diffusion Policy Optimization (D3PO) method to directly fine-tune diffusion models. The theoretical analysis demonstrates that although D3PO o
    
[^291]: 揭示和提高数据可信度：训练无害语言模型的数据集研究

    Unmasking and Improving Data Credibility: A Study with Datasets for Training Harmless Language Models

    [https://arxiv.org/abs/2311.11202](https://arxiv.org/abs/2311.11202)

    本研究专注于真实世界数据集的可信度，提出了一个系统化框架，用于评估数据集的可信度，识别标签错误，并评估嘈杂标签对不安全评论和对话分类的影响，以提高训练无害语言模型的质量。

    

    arXiv:2311.11202v2宣布类型：替换-跨文档摘要：语言模型在各种任务中显示出潜力，但在训练、微调或对齐过程中可能受到不希望的数据的影响。因此，注解的正确性，即数据集的可信度，变得非常重要。本研究聚焦于真实世界数据集的可信度，其中包括可用于训练无害语言模型的流行基准数据集，如Jigsaw Civil Comments、Anthropic Harmless和Red Team、PKU BeaverTails和SafeRLHF。考虑到人们清洗这些数据集的成本和难度，我们引入了一个系统化框架，用于评估数据集的可信度，识别标签错误，并评估策划语言数据中嘈杂标签的影响，特别关注不安全评论和对话分类。

    arXiv:2311.11202v2 Announce Type: replace-cross  Abstract: Language models have shown promise in various tasks but can be affected by undesired data during training, fine-tuning, or alignment. For example, if some unsafe conversations are wrongly annotated as safe ones, the model fine-tuned on these samples may be harmful. Therefore, the correctness of annotations, i.e., the credibility of the dataset, is important. This study focuses on the credibility of real-world datasets, including the popular benchmarks Jigsaw Civil Comments, Anthropic Harmless & Red Team, PKU BeaverTails & SafeRLHF, that can be used for training a harmless language model. Given the cost and difficulty of cleaning these datasets by humans, we introduce a systematic framework for evaluating the credibility of datasets, identifying label errors, and evaluating the influence of noisy labels in the curated language data, specifically focusing on unsafe comments and conversation classification. With the framework, we 
    
[^292]: 大型语言模型中置信度估计与校准的调研

    A Survey of Confidence Estimation and Calibration in Large Language Models

    [https://arxiv.org/abs/2311.08298](https://arxiv.org/abs/2311.08298)

    大型语言模型中置信度估计与校准的调研总结了挑战、技术进展、应用和未来方向。

    

    大型语言模型（LLMs）在各个领域的各种任务中展现出卓越的性能，但由于生成中的事实错误，它们可能不可靠。评估它们的置信度并在不同任务中进行校准可以帮助减轻风险，使LLMs能够产生更好的生成结果。近期有许多研究致力于解决这个问题，但尚无全面的概述来组织并概述主要的经验教训，本调研旨在弥补这一空白。具体而言，我们概述了挑战，并总结了LLMs置信度估计和校准的最新技术进展。我们进一步讨论了它们的应用，并提出了未来工作的有希望的方向。

    arXiv:2311.08298v2 Announce Type: replace-cross  Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks in various domains. Despite their impressive performance, they can be unreliable due to factual errors in their generations. Assessing their confidence and calibrating them across different tasks can help mitigate risks and enable LLMs to produce better generations. There has been a lot of recent research aiming to address this, but there has been no comprehensive overview to organize it and outline the main lessons learned. The present survey aims to bridge this gap. In particular, we outline the challenges and we summarize recent technical advancements for LLM confidence estimation and calibration. We further discuss their applications and suggest promising directions for future work.
    
[^293]: 评价图神经网络的邻居可解释性

    Evaluating Neighbor Explainability for Graph Neural Networks

    [https://arxiv.org/abs/2311.08118](https://arxiv.org/abs/2311.08118)

    评价图神经网络中邻居的可解释性，提出新的度量标准并发现基于梯度的方法在GNN领域的解释没有太大差异，同时发现很多技术在没有自环的GNNs下无法准确识别重要邻居。

    

    图神经网络（GNNs）中的可解释性是近年来新兴领域。在这篇文章中，我们解决了一个问题，即在对节点进行分类时，确定每个邻居对于 GNN 的重要性以及如何衡量这一特定任务的表现。为此，各种已知的可解释性方法被重新构造以获取邻居重要性，并提出了四种新的度量标准。我们的结果表明，在 GNN 领域，基于梯度的技术提供的解释几乎没有差异。此外，许多可解释性技术在使用没有自环的 GNNs 时未能识别重要的邻居。

    arXiv:2311.08118v2 Announce Type: replace-cross  Abstract: Explainability in Graph Neural Networks (GNNs) is a new field growing in the last few years. In this publication we address the problem of determining how important is each neighbor for the GNN when classifying a node and how to measure the performance for this specific task. To do this, various known explainability methods are reformulated to get the neighbor importance and four new metrics are presented. Our results show that there is almost no difference between the explanations provided by gradient-based techniques in the GNN domain. In addition, many explainability techniques failed to identify important neighbors when GNNs without self-loops are used.
    
[^294]: 大型语言模型在逻辑推理中的自我验证能力

    A Closer Look at the Self-Verification Abilities of Large Language Models in Logical Reasoning

    [https://arxiv.org/abs/2311.07954](https://arxiv.org/abs/2311.07954)

    本文研究了大型语言模型在逻辑推理中的自我验证能力，特别关注它们准确识别逻辑谬误的能力。

    

    逻辑推理一直是人工智能领域的追求目标。尽管大型语言模型（LLMs）取得了显著进展，但它们仍然在复杂的逻辑推理问题上面临困难。为了增强推理性能，一个有希望的方向是可扩展的监督，这需要LLMs识别自己的错误，然后自行改进。为了实现这一目标，提出了各种自我验证方法。然而，现有模型是否很好地理解自己的错误仍在调查中。本文着重探讨了LLMs在逻辑推理背景下的自我验证能力，关注它们准确识别逻辑谬误的能力。我们引入了一个包含232种推理谬误的数据集FALLACIES，并进行了大量实验，从而获得了关于LLMs在FALLACIES上的全面和详细分析。

    arXiv:2311.07954v2 Announce Type: replace  Abstract: Logical reasoning has been an ongoing pursuit in the field of AI. Despite significant advancements made by large language models (LLMs), they still struggle with complex logical reasoning problems. To enhance reasoning performance, one promising direction is scalable oversight, which requires LLMs to identify their own errors and then improve by themselves. Various self-verification methods have been proposed in pursuit of this goal. Nevertheless, whether existing models understand their own errors well is still under investigation. In this paper, we take a closer look at the self-verification abilities of LLMs in the context of logical reasoning, focusing on their ability to identify logical fallacies accurately. We introduce a dataset, FALLACIES, containing 232 types of reasoning fallacies categorized in a hierarchical taxonomy. By conducting exhaustive experiments on FALLACIES, we obtain comprehensive and detailed analyses of a se
    
[^295]: VT-Former: 基于Transformer的智能公路交通系统中的车辆轨迹预测方法

    VT-Former: A Transformer-based Vehicle Trajectory Prediction Approach For Intelligent Highway Transportation Systems

    [https://arxiv.org/abs/2311.06623](https://arxiv.org/abs/2311.06623)

    本文介绍了一种基于Transformer的车辆轨迹预测方法，名为VT-Former，在智能公路交通系统中具有重要的应用价值。

    

    加强道路安全和交通管理已成为现代网络物理系统和智能交通系统的重点领域。车辆轨迹预测在公路和道路安全的众多应用中起着关键作用。这些应用包括交通管理、事故预防、工地安全和能源优化等各种用例。在人工智能领域的发展以及监控摄像头在道路网络上的增加部署推动下，智能管理在这一背景下得到了很大进展。本文介绍了一种新颖的基于Transformer的车辆轨迹预测方法，称为VT-Former。除了利用Transformer捕捉长期时间模式外，还提出了一种新的图注意力分词（GAT）模块。

    Enhancing roadway safety and traffic management has become an essential focus area for a broad range of modern cyber-physical systems and intelligent transportation systems. Vehicle Trajectory Prediction is a pivotal element within numerous applications for highway and road safety. These applications encompass a wide range of use cases, spanning from traffic management and accident prevention to enhancing work-zone safety and optimizing energy conservation. The ability to implement intelligent management in this context has been greatly advanced by the developments in the field of Artificial Intelligence (AI), alongside the increasing deployment of surveillance cameras across road networks. In this paper, we introduce a novel transformer-based approach for vehicle trajectory prediction for highway safety and surveillance, denoted as VT-Former. In addition to utilizing transformers to capture long-range temporal patterns, a new Graph Attentive Tokenization (GAT) module has been proposed
    
[^296]: LitSumm：大语言模型用于非编码RNA文献摘要

    LitSumm: Large language models for literature summarisation of non-coding RNAs

    [https://arxiv.org/abs/2311.03056](https://arxiv.org/abs/2311.03056)

    使用大语言模型为非编码RNA文献生成高质量和准确的摘要，帮助减轻生命科学文献整理中缺乏策展人员时间的问题。

    

    Motivation: 在生命科学文献的整理工作中，面临着日益严峻的挑战。随着发布速度的持续增加，再加上全球固定数量的策展人员，开发生物医学知识库面临重大挑战。很少有知识库有资源可以扩展到所有相关文献，而所有知识库都必须优先考虑自己的努力。 在这项工作中，我们通过使用大语言模型（LLMs）为非编码RNA生成文献摘要，首次减轻了RNA科学中缺乏策展人员时间的问题。我们展示了可以使用商业LLM和一系列提示和检查从文献中自动生成高质量、事实准确的摘要及准确的引用。人工评估针对摘要子集进行，其中大多数被评为非常高质量。我们还应用了最常用的自动化e

    arXiv:2311.03056v2 Announce Type: replace-cross  Abstract: Motivation: Curation of literature in life sciences is a growing challenge. The continued increase in the rate of publication, coupled with the relatively fixed number of curators worldwide presents a major challenge to developers of biomedical knowledgebases. Very few knowledgebases have resources to scale to the whole relevant literature and all have to prioritise their efforts.   Results: In this work, we take a first step to alleviating the lack of curator time in RNA science by generating summaries of literature for non-coding RNAs using large language models (LLMs). We demonstrate that high-quality, factually accurate summaries with accurate references can be automatically generated from the literature using a commercial LLM and a chain of prompts and checks. Manual assessment was carried out for a subset of summaries, with the majority being rated extremely high quality. We also applied the most commonly used automated e
    
[^297]: 制作一个甜甜圈：用于零样本变形操纵的分层EMD空间规划与工具

    Make a Donut: Hierarchical EMD-Space Planning for Zero-Shot Deformable Manipulation with Tools

    [https://arxiv.org/abs/2311.02787](https://arxiv.org/abs/2311.02787)

    引入了一种无需演示的分层规划方法，利用大型语言模型来解决复杂的长时间任务，为每个阶段提供工具名称和Python代码。

    

    变形物体操纵是机器人领域中最迷人又最艰巨的挑战之一。虽然先前的技术主要依赖于通过演示学习潜在动态，通常表示为粒子或图像之一，但存在一个重要限制：获取适当的演示，特别是对于长时间任务，可能是困难的。此外，完全基于演示进行学习可能会阻碍模型超越演示任务的能力。在这项工作中，我们介绍了一种无需演示的分层规划方法，能够处理复杂的长时间任务而无需任何训练。我们利用大型语言模型（LLMs）来表达与指定任务对应的高层、阶段-by-阶段计划。对于每个单独阶段，LLM提供工具的名称和Python代码，以制作中间子目标点云。

    arXiv:2311.02787v2 Announce Type: replace-cross  Abstract: Deformable object manipulation stands as one of the most captivating yet formidable challenges in robotics. While previous techniques have predominantly relied on learning latent dynamics through demonstrations, typically represented as either particles or images, there exists a pertinent limitation: acquiring suitable demonstrations, especially for long-horizon tasks, can be elusive. Moreover, basing learning entirely on demonstrations can hamper the model's ability to generalize beyond the demonstrated tasks. In this work, we introduce a demonstration-free hierarchical planning approach capable of tackling intricate long-horizon tasks without necessitating any training. We employ large language models (LLMs) to articulate a high-level, stage-by-stage plan corresponding to a specified task. For every individual stage, the LLM provides both the tool's name and the Python code to craft intermediate subgoal point clouds. With the
    
[^298]: 用强化学习进行因果问答

    Causal Question Answering with Reinforcement Learning

    [https://arxiv.org/abs/2311.02760](https://arxiv.org/abs/2311.02760)

    本研究通过强化学习在因果图上进行因果问答，引入了一种基于演员评论的 agent，有效解决了当前因果问答方法无法提供解释或证据的问题

    

    因果问题探究不同事件或现象之间的因果关系。它们对各种用例都很重要，包括虚拟助手和搜索引擎。然而，许多当前的因果问答方法不能为其答案提供解释或证据。因此，在这篇论文中，我们旨在用因果图回答因果问题，这是一个关于名词短语之间因果关系的大规模数据集，同时提供关系的来源数据。受最近将强化学习成功应用于知识图任务的启发，例如链接预测和事实检查，我们探讨了将强化学习应用于因果图进行因果问答的方法。我们引入了一种基于演员评论的 agent，它学习通过图搜索来回答因果问题。我们通过监督学习程序引导 agent 处理大规模操作空间和sp

    arXiv:2311.02760v2 Announce Type: replace  Abstract: Causal questions inquire about causal relationships between different events or phenomena. They are important for a variety of use cases, including virtual assistants and search engines. However, many current approaches to causal question answering cannot provide explanations or evidence for their answers. Hence, in this paper, we aim to answer causal questions with a causality graph, a large-scale dataset of causal relations between noun phrases along with the relations' provenance data. Inspired by recent, successful applications of reinforcement learning to knowledge graph tasks, such as link prediction and fact-checking, we explore the application of reinforcement learning on a causality graph for causal question answering. We introduce an Actor-Critic-based agent which learns to search through the graph to answer causal questions. We bootstrap the agent with a supervised learning procedure to deal with large action spaces and sp
    
[^299]: UrbanCLIP：学习来自网络的对比语言图像预训练文本增强的城市区域描述

    UrbanCLIP: Learning Text-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining from the Web

    [https://arxiv.org/abs/2310.18340](https://arxiv.org/abs/2310.18340)

    本文介绍了第一个将文本模态融入城市图像描述的LLM增强框架UrbanCLIP，并探讨了文本模态如何增强城市区域描述以及其影响方面。

    

    从网络数据进行的城市区域描述对城市规划和可持续发展至关重要。我们目睹了LLM在各个领域的不断崛起，尤其是处理多模态数据研究，如视觉-语言学习，其中文本模态作为图像的补充信息。本文旨在回答两个基本问题：i）文本模态能否增强城市区域描述？ii）如果可以，以何种方式和在哪些方面？为了回答这些问题，我们利用了大型语言模型（LLMs）的强大力量，并引入了第一个集成文本模态知识到城市图像描述中的LLM增强框架，命名为对比语言-图像预训练LLM增强型城市区域描述（UrbanCLIP）。

    arXiv:2310.18340v2 Announce Type: replace-cross  Abstract: Urban region profiling from web-sourced data is of utmost importance for urban planning and sustainable development. We are witnessing a rising trend of LLMs for various fields, especially dealing with multi-modal data research such as vision-language learning, where the text modality serves as a supplement information for the image. Since textual modality has never been introduced into modality combinations in urban region profiling, we aim to answer two fundamental questions in this paper: i) Can textual modality enhance urban region profiling? ii) and if so, in what ways and with regard to which aspects? To answer the questions, we leverage the power of Large Language Models (LLMs) and introduce the first-ever LLM-enhanced framework that integrates the knowledge of textual modality into urban imagery profiling, named LLM-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining (UrbanCLIP). Specifically, it
    
[^300]: BatteryML：一个用于电池衰减机器学习的开源平台

    BatteryML:An Open-source platform for Machine Learning on Battery Degradation

    [https://arxiv.org/abs/2310.14714](https://arxiv.org/abs/2310.14714)

    BatteryML是一个开源平台，通过一站式、全面的方法统一了电池衰减建模的数据预处理、特征提取和模型实现，提高了研究应用的实用性和效率。

    

    电池衰减仍然是能源存储领域的一个关键问题，而机器学习作为推动洞察和解决方案的有效工具正在崛起。然而，电化学科学和机器学习的交叉领域带来了复杂的挑战。机器学习专家经常在处理电池科学的复杂性上苦苦挣扎，而电池研究人员则面临着将复杂模型调整到特定数据集的障碍。此外，缺乏涵盖数据格式和评估基准的电池衰减建模的统一标准。鉴于这些障碍，我们提出了BatteryML - 一个一站式、全面且开源的平台，旨在统一数据预处理、特征提取以及传统和最先进模型的实现。这种简化的方法有望提高研究应用的实用性和效率。

    arXiv:2310.14714v4 Announce Type: replace-cross  Abstract: Battery degradation remains a pivotal concern in the energy storage domain, with machine learning emerging as a potent tool to drive forward insights and solutions. However, this intersection of electrochemical science and machine learning poses complex challenges. Machine learning experts often grapple with the intricacies of battery science, while battery researchers face hurdles in adapting intricate models tailored to specific datasets. Beyond this, a cohesive standard for battery degradation modeling, inclusive of data formats and evaluative benchmarks, is conspicuously absent. Recognizing these impediments, we present BatteryML - a one-step, all-encompass, and open-source platform designed to unify data preprocessing, feature extraction, and the implementation of both traditional and state-of-the-art models. This streamlined approach promises to enhance the practicality and efficiency of research applications. BatteryML s
    
[^301]: 通过决策模型弥补新手与专家之间的差距：以纠正数学错误为案例研究

    Bridging the Novice-Expert Gap via Models of Decision-Making: A Case Study on Remediating Math Mistakes

    [https://arxiv.org/abs/2310.10648](https://arxiv.org/abs/2310.10648)

    通过使用决策模型Bridge，结合专家的认知任务分析，成功利用大型语言模型（LLMs）来弥补新手和专家在纠正数学错误中的知识差距。

    

    高质量辅导规模化仍然是教育中的一项主要挑战。由于需求增长，许多平台聘用新手导师，他们与经验丰富的教育工作者不同，难以解决学生的错误，因此无法抓住主要的学习机会。我们的工作探讨了大型语言模型（LLMs）在纠正数学错误中弥补新手和专家之间知识差距的潜力。我们提出Bridge，这是一种利用认知任务分析将专家的潜在思维过程转化为纠正模型的方法。这涉及专家识别(A)学生的错误、(B)纠正策略和(C)生成回应之前的意图。我们构建了一个包含700个真实辅导对话的数据集，由专家标注了他们的决策。我们在我们的数据集上评估了最先进的LLMs，并发现专家的决策模型对LLMs来说是至关重要的，以弥补这一差距：回应f

    arXiv:2310.10648v2 Announce Type: replace-cross  Abstract: Scaling high-quality tutoring remains a major challenge in education. Due to growing demand, many platforms employ novice tutors who, unlike experienced educators, struggle to address student mistakes and thus fail to seize prime learning opportunities. Our work explores the potential of large language models (LLMs) to close the novice-expert knowledge gap in remediating math mistakes. We contribute Bridge, a method that uses cognitive task analysis to translate an expert's latent thought process into a decision-making model for remediation. This involves an expert identifying (A) the student's error, (B) a remediation strategy, and (C) their intention before generating a response. We construct a dataset of 700 real tutoring conversations, annotated by experts with their decisions. We evaluate state-of-the-art LLMs on our dataset and find that the expert's decision-making model is critical for LLMs to close the gap: responses f
    
[^302]: 通过模型选择实现健壮的多模态推理

    Towards Robust Multi-Modal Reasoning via Model Selection

    [https://arxiv.org/abs/2310.08446](https://arxiv.org/abs/2310.08446)

    多模态代理在处理复杂挑战时需要考虑模型选择的重要性，以避免执行的脆弱性。

    

    最近的研究普遍承认了大型语言模型（LLM）的推理能力，在工具学习和自主代理研究中鼓舞了研究。LLM充当代理的“大脑”，为协作多步任务求解集成多个工具。多模态代理通过整合各种人工智能模型处理复杂挑战，在处理直观任务时不像调用计算器或天气API那样。然而，当前的多模态代理忽视了模型选择的重要性：它们主要专注于计划和执行阶段，只会为每个子任务调用预定义的任务特定模型，使执行变得脆弱。与此同时，其他传统的模型选择方法要么与多模态代理场景不兼容或不理想，因为它们忽视了多步推理产生的子任务之间的依赖关系。因此，我们确定了主要挑战。

    arXiv:2310.08446v2 Announce Type: replace-cross  Abstract: The reasoning capabilities of LLM (Large Language Model) are widely acknowledged in recent research, inspiring studies on tool learning and autonomous agents. LLM serves as the "brain" of the agent, orchestrating multiple tools for collaborative multi-step task solving. Unlike methods invoking tools like calculators or weather APIs for straightforward tasks, multi-modal agents excel by integrating diverse AI models for complex challenges. However, current multi-modal agents neglect the significance of model selection: they primarily focus on the planning and execution phases, and will only invoke predefined task-specific models for each subtask, making the execution fragile. Meanwhile, other traditional model selection methods are either incompatible with or suboptimal for the multi-modal agent scenarios, due to ignorance of dependencies among subtasks arising by multi-step reasoning. To this end, we identify the key challenges
    
[^303]: 质量感知翻译模型：单一模型中的高效生成和质量评估

    Quality-Aware Translation Models: Efficient Generation and Quality Estimation in a Single Model

    [https://arxiv.org/abs/2310.06707](https://arxiv.org/abs/2310.06707)

    提出了一种质量感知翻译模型，通过训练NMT模型来估计其输出质量，可以在解码过程中消除额外的计算成本。

    

    最大后验（MAP）解码是神经机器翻译（NMT）模型中最广泛使用的解码策略。 研究表明，模型概率与人类判断相关，但不能总是成立，生成质量可以通过解码来优化一个以度量或质量评估信号支持的效用函数来提高，即最小贝叶斯风险（MBR）或质量感知解码。 这些方法的主要缺点在于它们需要一个额外的模型在解码过程中计算效用函数，会显著增加计算成本。 本文提出通过训练NMT模型自己来估计其输出质量，从而使NMT模型本身具备质量感知能力。 使用这种方法进行MBR解码可以显著减小尺寸。

    arXiv:2310.06707v2 Announce Type: replace-cross  Abstract: Maximum-a-posteriori (MAP) decoding is the most widely used decoding strategy for neural machine translation (NMT) models. The underlying assumption is that model probability correlates well with human judgment, with better translations getting assigned a higher score by the model. However, research has shown that this assumption does not always hold, and generation quality can be improved by decoding to optimize a utility function backed by a metric or quality-estimation signal, as is done by Minimum Bayes Risk (MBR) or Quality-Aware decoding. The main disadvantage of these approaches is that they require an additional model to calculate the utility function during decoding, significantly increasing the computational cost. In this paper, we propose to make the NMT models themselves quality-aware by training them to estimate the quality of their own output. Using this approach for MBR decoding we can drastically reduce the size
    
[^304]: 从元学习视角看Transformer用于因果语言建模

    A Meta-Learning Perspective on Transformers for Causal Language Modeling

    [https://arxiv.org/abs/2310.05884](https://arxiv.org/abs/2310.05884)

    本文从元学习视角探讨了Transformer用于因果语言建模时的内部优化过程，发现并分析了Transformer-based因果语言模型中学习到的token表示范数的特殊特征。

    

    Transformer架构在开发大型因果语言模型方面变得显著。然而，解释其能力的机制尚不为人所了解。本文侧重于训练过程，建立了一个元学习视角来探究Transformer架构在因果语言建模任务训练时的内部优化过程，详细说明了Transformer内部的一个优化过程。此外，在这个内部优化过程中，我们发现并理论分析了Transformer-based因果语言模型中学习到的token表示的范数的特殊特征。我们的分析得到了各种设置中的实验证实支持。

    arXiv:2310.05884v2 Announce Type: replace-cross  Abstract: The Transformer architecture has become prominent in developing large causal language models. However, mechanisms to explain its capabilities are not well understood. Focused on the training process, here we establish a meta-learning view of the Transformer architecture when trained for the causal language modeling task, by explicating an inner optimization process within the Transformer. Further, within the inner optimization, we discover and theoretically analyze a special characteristic of the norms of learned token representations within Transformer-based causal language models. Our analysis is supported by experiments in various settings.
    
[^305]: 用于腿式机器人的全脉冲神经网络

    Fully Spiking Neural Network for Legged Robots

    [https://arxiv.org/abs/2310.05022](https://arxiv.org/abs/2310.05022)

    本文将新型全脉冲神经网络（SNN）成功应用于处理腿式机器人，在各种模拟地形中取得了杰出结果。

    

    近年来，基于深度强化学习的腿式机器人取得了显著进展。四足机器人展示了在复杂环境中完成具有挑战性任务的能力，并已部署在现实场景中以协助人类。同时，两足和类人机器人在各种高难度任务中取得了突破。本研究成功将一种新型脉冲神经网络（SNN）应用于处理腿式机器人，在一系列模拟地形中取得了出色的结果。

    arXiv:2310.05022v2 Announce Type: replace-cross  Abstract: In recent years, legged robots based on deep reinforcement learning have made remarkable progress. Quadruped robots have demonstrated the ability to complete challenging tasks in complex environments and have been deployed in real-world scenarios to assist humans. Simultaneously, bipedal and humanoid robots have achieved breakthroughs in various demanding tasks. Current reinforcement learning methods can utilize diverse robot bodies and historical information to perform actions. However, prior research has not emphasized the speed and energy consumption of network inference, as well as the biological significance of the neural networks themselves. Most of the networks employed are traditional artificial neural networks that utilize multilayer perceptrons (MLP). In this paper, we successfully apply a novel Spiking Neural Network (SNN) to process legged robots, achieving outstanding results across a range of simulated terrains. S
    
[^306]: HalluciDet: 通过特权信息使RGB模态幻象用于人员检测

    HalluciDet: Hallucinating RGB Modality for Person Detection Through Privileged Information

    [https://arxiv.org/abs/2310.04662](https://arxiv.org/abs/2310.04662)

    本文提出了一种IR-RGB图像翻译模型HalluciDet，通过特权信息减少RGB检测器的检测损失，提高了检测性能

    

    通过图像翻译是将视觉识别模型调整到新领域的有力方式。然而，常见的图像翻译方法仅专注于生成与目标域相同分布的数据。针对跨模态应用，如从航空图像进行行人检测，在红外（IR）到可见（RGB）图像之间存在数据分布上的显着偏移，专注于生成可能导致性能不佳，因为损失关注于任务的无关细节。本文提出了HalluciDet，一个用于目标检测的IR-RGB图像翻译模型。与专注于在IR模态上重建原始图像不同，该模型旨在减少RGB检测器的检测损失，从而避免访问RGB数据。该模型生成了一个新的图像表示，增强了场景中感兴趣的对象，并显著提高了检测性能。

    arXiv:2310.04662v2 Announce Type: replace-cross  Abstract: A powerful way to adapt a visual recognition model to a new domain is through image translation. However, common image translation approaches only focus on generating data from the same distribution as the target domain. Given a cross-modal application, such as pedestrian detection from aerial images, with a considerable shift in data distribution between infrared (IR) to visible (RGB) images, a translation focused on generation might lead to poor performance as the loss focuses on irrelevant details for the task. In this paper, we propose HalluciDet, an IR-RGB image translation model for object detection. Instead of focusing on reconstructing the original image on the IR modality, it seeks to reduce the detection loss of an RGB detector, and therefore avoids the need to access RGB data. This model produces a new image representation that enhances objects of interest in the scene and greatly improves detection performance. We e
    
[^307]: 通过平方的消减混合模型:表示和学习

    Subtractive Mixture Models via Squaring: Representation and Learning

    [https://arxiv.org/abs/2310.00724](https://arxiv.org/abs/2310.00724)

    通过平方操作实现的消减混合模型在表达能力上优于传统加法混合模型，并在真实世界分布估计任务中得到了实验证明。

    

    混合模型传统上是通过将几个分布作为组件相加来表示和学习的。允许混合减去概率质量或密度可以大大减少建模复杂分布所需的组件数量。然而，学习这种减法混合模型并确保它们仍然编码非负函数是具有挑战性的。我们探讨了如何通过平方来学习和执行深度减法混合模型。我们在概率电路框架中进行这些研究，这使我们能够表示张量化的混合模型并泛化其他减法模型。我们在理论上证明了允许减法的平方电路类可以比传统的加法混合模型具有指数级更具表达力；我们在一系列真实世界分布估计任务上实证展示了这种增加的表达力。

    arXiv:2310.00724v2 Announce Type: replace-cross  Abstract: Mixture models are traditionally represented and learned by adding several distributions as components. Allowing mixtures to subtract probability mass or density can drastically reduce the number of components needed to model complex distributions. However, learning such subtractive mixtures while ensuring they still encode a non-negative function is challenging. We investigate how to learn and perform inference on deep subtractive mixtures by squaring them. We do this in the framework of probabilistic circuits, which enable us to represent tensorized mixtures and generalize several other subtractive models. We theoretically prove that the class of squared circuits allowing subtractions can be exponentially more expressive than traditional additive mixtures; and, we empirically show this increased expressiveness on a series of real-world distribution estimation tasks.
    
[^308]: 通过逻辑增强大型语言模型中的零射链推理能力

    Enhancing Zero-Shot Chain-of-Thought Reasoning in Large Language Models through Logic

    [https://arxiv.org/abs/2309.13339](https://arxiv.org/abs/2309.13339)

    提出了LoT（Logical Thoughts）提示，一个自我改进框架，利用根植于符号逻辑的原则，特别是归谬法，逐步验证和纠正大型语言模型的零射链推理过程。

    

    大型语言模型的最新进展展示了它们在各个领域的 remarkable generalizability。然而，它们的推理能力仍有很大的提升空间，特别是在需要多步推理的情况下。尽管大型语言模型具有广泛的知识，但它们的推理经常未能有效利用这些知识来建立连贯的思维范式。这些模型有时会出现幻觉，因为它们的推理过程未受逻辑原则的限制。为了改进大型语言模型的零射链推理能力，我们提出了 LoT（Logical Thoughts）提示，这是一个自我改进的框架，利用根植于符号逻辑的原则，特别是归谬法，逐步系统地验证和纠正推理过程。在语言任务上进行的实验评估

    arXiv:2309.13339v2 Announce Type: replace-cross  Abstract: Recent advancements in large language models have showcased their remarkable generalizability across various domains. However, their reasoning abilities still have significant room for improvement, especially when confronted with scenarios requiring multi-step reasoning. Although large language models possess extensive knowledge, their reasoning often fails to effectively utilize this knowledge to establish a coherent thinking paradigm. These models sometimes show hallucinations as their reasoning procedures are unconstrained by logical principles. Aiming at improving the zero-shot chain-of-thought reasoning ability of large language models, we propose LoT (Logical Thoughts) prompting, a self-improvement framework that leverages principles rooted in symbolic logic, particularly Reductio ad Absurdum, to systematically verify and rectify the reasoning processes step by step. Experimental evaluations conducted on language tasks in
    
[^309]: 大型语言模型用于生成式推荐：一项调查和远见讨论

    Large Language Models for Generative Recommendation: A Survey and Visionary Discussions

    [https://arxiv.org/abs/2309.01157](https://arxiv.org/abs/2309.01157)

    大型语言模型为推荐系统的生成式推荐提供了新机遇，可以简化推荐流程并直接从完整的项目池中生成推荐。

    

    大型语言模型（LLM）不仅彻底改变了自然语言处理（NLP）领域，还有潜力重塑许多其他领域，例如推荐系统（RS）。本文调查了基于LLM的生成式推荐的进展、方法和未来方向，着眼于三个问题：1）生成式推荐是什么，2）为什么RS应该发展到生成式推荐，3）如何为各种RS实现基于LLM的生成推荐。

    arXiv:2309.01157v2 Announce Type: replace-cross  Abstract: Large language models (LLM) not only have revolutionized the field of natural language processing (NLP) but also have the potential to reshape many other fields, e.g., recommender systems (RS). However, most of the related work treats an LLM as a component of the conventional recommendation pipeline (e.g., as a feature extractor), which may not be able to fully leverage the generative power of LLM. Instead of separating the recommendation process into multiple stages, such as score computation and re-ranking, this process can be simplified to one stage with LLM: directly generating recommendations from the complete pool of items. This survey reviews the progress, methods, and future directions of LLM-based generative recommendation by examining three questions: 1) What generative recommendation is, 2) Why RS should advance to generative recommendation, and 3) How to implement LLM-based generative recommendation for various RS t
    
[^310]: 揭示盲点：对自动驾驶系统中公平性的关键审查

    Unveiling the Blind Spots: A Critical Examination of Fairness in Autonomous Driving Systems

    [https://arxiv.org/abs/2308.02935](https://arxiv.org/abs/2308.02935)

    该研究对当前深度学习行人检测器的公平性进行了全面评估，发现了与年龄相关的重要公平性问题。

    

    自主驾驶系统已经扩展了智能车辆物联网的范围，并成为Web生态系统的重要组成部分。类似于传统的基于Web的应用程序，公平性对于确保自动驾驶系统的高质量是一个重要方面，特别是在其中的行人检测器的背景下。然而，目前关于当前基于深度学习（DL）的行人检测器公平性的综合评估在文献中尚未出现。为了填补这一空白，我们在大规模真实世界数据集上评估了八种被广泛探索的DL行人检测器在人口统计学群体之间的表现。为了实现彻底的公平性评估，我们为数据集提供了广泛的注释，共涉及8,311张图像，16,070个性别标签，20,115个年龄标签和3,513个肤色标签。我们的研究发现了与年龄相关的重要公平性问题。

    arXiv:2308.02935v2 Announce Type: replace-cross  Abstract: Autonomous driving systems have extended the spectrum of Web of Things for intelligent vehicles and have become an important component of the Web ecosystem. Similar to traditional Web-based applications, fairness is an essential aspect for ensuring the high quality of autonomous driving systems, particularly in the context of pedestrian detectors within them. However, there is an absence in the literature of a comprehensive assessment of the fairness of current Deep Learning (DL)-based pedestrian detectors. To fill the gap, we evaluate eight widely-explored DL-based pedestrian detectors across demographic groups on large-scale real-world datasets. To enable a thorough fairness evaluation, we provide extensive annotations for the datasets, resulting in 8,311 images with 16,070 gender labels, 20,115 age labels, and 3,513 skin tone labels. Our findings reveal significant fairness issues related to age. The undetected proportions f
    
[^311]: 重新思考领域泛化的评估协议

    Rethinking the Evaluation Protocol of Domain Generalization

    [https://arxiv.org/abs/2305.15253](https://arxiv.org/abs/2305.15253)

    重新评估领域泛化的评估协议，提出采用自监督预训练或从头开始训练，使用多个测试领域，以更准确评估OOD泛化能力。

    

    领域泛化目的是通过利用从多个训练领域学到的共同知识，解决面向未见测试领域的超出分布（OOD）泛化挑战。为了准确评估OOD泛化能力，需要测试数据信息不可用。然而，当前的领域泛化协议仍可能存在潜在的测试数据信息泄漏。本文从当前评估协议的两个方面：在ImageNet上进行监督预训练和oracle模型选择，探讨测试数据信息泄漏的风险。我们提出修改当前协议的建议，即应该采用自监督预训练或从头开始训练，而不是采用当前的监督预训练，并且应该使用多个测试领域。这将导致对OOD泛化能力更精确的评估。我们还重新运行了带有修改后协议的算法。

    arXiv:2305.15253v2 Announce Type: replace-cross  Abstract: Domain generalization aims to solve the challenge of Out-of-Distribution (OOD) generalization by leveraging common knowledge learned from multiple training domains to generalize to unseen test domains. To accurately evaluate the OOD generalization ability, it is required that test data information is unavailable. However, the current domain generalization protocol may still have potential test data information leakage. This paper examines the risks of test data information leakage from two aspects of the current evaluation protocol: supervised pretraining on ImageNet and oracle model selection. We propose modifications to the current protocol that we should employ self-supervised pretraining or train from scratch instead of employing the current supervised pretraining, and we should use multiple test domains. These would result in a more precise evaluation of OOD generalization ability. We also rerun the algorithms with the mod
    
[^312]: LLM亲子鉴定：LLM遗传继承中的生成文本检测

    LLM Paternity Test: Generated Text Detection with LLM Genetic Inheritance

    [https://arxiv.org/abs/2305.12519](https://arxiv.org/abs/2305.12519)

    LLM-Pat提出了一种基于模型的生成文本检测方法，通过重建并比较候选文本与其对应的“兄弟”文本的相似性，从而判断候选文本是否由机器生成。

    

    大语言模型（LLMs）可以生成携带各种滥用风险的文本，包括抄袭、在电子商务平台上发布虚假评论，或者制作引人注目的虚假推文。因此，检测文本是否由机器生成变得越来越重要。虽然现有的检测方法表现出色，但由于严重依赖训练数据，它们往往缺乏泛化能力。为缓解这一问题，我们提出了一种与模型相关的生成文本检测方法，即LLM亲子鉴定（LLM-Pat）。具体而言，给定任何候选文本（"子类"），LLM-Pat使用一个中间LLM（"父类"）重建与给定文本对应的"兄弟"文本，然后衡量候选文本与其"兄弟"文本之间的相似性。高相似性表明候选文本是由机器生成，类似于基因特征。我们已构建了数据集...

    arXiv:2305.12519v2 Announce Type: replace-cross  Abstract: Large language models (LLMs) can generate texts that carry the risk of various misuses, including plagiarism, planting fake reviews on e-commerce platforms, or creating inflammatory false tweets. Detecting whether a text is machine-generated has thus become increasingly important. While existing detection methods exhibit superior performance, they often lack generalizability due to their heavy dependence on training data. To alleviate this problem, we propose a model-related generated text detection method, the LLM Paternity Test (LLM-Pat). Specifically, given any candidate text (\textit{child}), LLM-Pat employs an intermediary LLM (\textit{parent}) to reconstruct a \textit{sibling} text corresponding to the given text and then measures the similarity between candidate texts and their sibling texts. High similarity indicates that the candidate text is machine-generated, akin to genetic traits. We have constructed datasets encom
    
[^313]: 一种前向和后向兼容的少样本类增量药丸识别框架

    A Forward and Backward Compatible Framework for Few-shot Class-incremental Pill Recognition

    [https://arxiv.org/abs/2304.11959](https://arxiv.org/abs/2304.11959)

    提出了一种前向和后向兼容的少样本类增量药丸识别框架，包括虚拟类别合成策略和中心三元组损失以增强辨别特征学习。

    

    自动药丸识别（APR）系统对于提高医院效率、帮助视力受损个体，并预防交叉感染至关重要。然而，大多数现有的基于深度学习的药丸识别系统只能对具有足够训练数据的类别进行分类。在实践中，数据标注的高成本和新药丸类别持续增加的情况需要开发一种少样本类增量药丸识别系统。本文介绍了第一个少样本类增量药丸识别框架，名为具有前向和后向兼容的辨别式少样本类增量学习（DBC-FSCIL）。它包括前向兼容和后向兼容的学习组件。在前向兼容学习中，我们提出了一种创新的虚拟类别合成策略和一个中心三元组（CT）损失来增强辨别特征学习。这些虚拟类别起到了

    arXiv:2304.11959v2 Announce Type: replace-cross  Abstract: Automatic Pill Recognition (APR) systems are crucial for enhancing hospital efficiency, assisting visually impaired individuals, and preventing cross-infection. However, most existing deep learning-based pill recognition systems can only perform classification on classes with sufficient training data. In practice, the high cost of data annotation and the continuous increase in new pill classes necessitate the development of a few-shot class-incremental pill recognition system. This paper introduces the first few-shot class-incremental pill recognition framework, named Discriminative and Bidirectional Compatible Few-Shot Class-Incremental Learning (DBC-FSCIL). It encompasses forward-compatible and backward-compatible learning components. In forward-compatible learning, we propose an innovative virtual class synthesis strategy and a Center-Triplet (CT) loss to enhance discriminative feature learning. These virtual classes serve a
    
[^314]: 在大语言模型中区分语言和思维

    Dissociating language and thought in large language models

    [https://arxiv.org/abs/2301.06627](https://arxiv.org/abs/2301.06627)

    大型语言模型在形式语言能力方面表现出色，但在功能语言能力任务上表现不稳定，可能需要专门的调整和外部模块的支持。

    

    大型语言模型（LLMs）迄今为止在掌握人类语言方面做得最好，然而人们对它们的语言和认知能力仍存在分歧。本文使用形式语言能力（对语言规则和模式的了解）与功能语言能力（理解和使用语言在世界中的方式）的区别来评估LLMs。我们通过人类神经科学来确立这一区别，人类神经科学显示形式和功能能力依赖于不同的神经机制。尽管LLMs在形式能力方面表现出人们的惊人水平，但它们在功能能力任务上的表现仍然不稳定，并且通常需要专门的精细调整和/或与外部模块的耦合。我们认为，那些以类似人类方式使用语言的模型将需要掌握这两种能力类型，而这反过来可能需要为形式语言能力专门化的机制的出现。

    arXiv:2301.06627v3 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) have come closest among all models to date to mastering human language, yet opinions about their linguistic and cognitive capabilities remain split. Here, we evaluate LLMs using a distinction between formal linguistic competence - knowledge of linguistic rules and patterns - and functional linguistic competence - understanding and using language in the world. We ground this distinction in human neuroscience, which has shown that formal and functional competence rely on different neural mechanisms. Although LLMs are surprisingly good at formal competence, their performance on functional competence tasks remains spotty and often requires specialized fine-tuning and/or coupling with external modules. We posit that models that use language in human-like ways would need to master both of these competence types, which, in turn, could require the emergence of mechanisms specialized for formal linguistic co
    
[^315]: 知识增强多模态学习综述

    A survey on knowledge-enhanced multimodal learning

    [https://arxiv.org/abs/2211.12328](https://arxiv.org/abs/2211.12328)

    知识图和其他知识来源填补了视觉语言学习模型在日常知识理解方面的差距，提升了模型的性能和可解释性。

    

    多模态学习是一个越来越受关注的领域，旨在将各种模态结合成一个联合表示。特别是在视觉语言学习领域，已经开发出多种模型和技术，针对涉及图像和文本的各种任务。VL模型通过扩展Transformer的思想，使得两种模态可以相互学习，已经达到了前所未有的性能。大规模的预训练程序使得VL模型能够获得一定水平的现实世界理解，尽管仍然存在许多差距：对常识、事实、时间和其他日常知识方面的限制理解，对VL任务的可扩展性提出了质疑。知识图和其他知识来源可以通过明确提供缺失信息来填补这些差距，解锁VL模型的新能力。同时，知识图增强了可解释性、公平性。

    arXiv:2211.12328v3 Announce Type: replace-cross  Abstract: Multimodal learning has been a field of increasing interest, aiming to combine various modalities in a single joint representation. Especially in the area of visiolinguistic (VL) learning multiple models and techniques have been developed, targeting a variety of tasks that involve images and text. VL models have reached unprecedented performances by extending the idea of Transformers, so that both modalities can learn from each other. Massive pre-training procedures enable VL models to acquire a certain level of real-world understanding, although many gaps can be identified: the limited comprehension of commonsense, factual, temporal and other everyday knowledge aspects questions the extendability of VL tasks. Knowledge graphs and other knowledge sources can fill those gaps by explicitly providing missing information, unlocking novel capabilities of VL models. In the same time, knowledge graphs enhance explainability, fairness 
    
[^316]: 使用纵向自监督学习进行糖尿病视网膜病变检测

    Detection of diabetic retinopathy using longitudinal self-supervised learning

    [https://arxiv.org/abs/2209.00915](https://arxiv.org/abs/2209.00915)

    本研究探讨了利用纵向自监督学习对糖尿病视网膜病变进行诊断的益处，通过比较不同方法模拟疾病进展并在纵向眼底照片中检测早期DR严重程度变化，取得了较高的AUC。

    

    纵向成像能够捕捉静态解剖结构和疾病进展中的动态变化，实现对疾病的更早和更好的个体化病理管理。然而，传统的检测糖尿病视网膜病变（DR）的方法很少利用纵向信息来改善DR分析。在这项工作中，我们研究了利用具有纵向性质的自监督学习来进行DR诊断的好处。我们比较了不同的纵向自监督学习（LSSL）方法，用来模拟从纵向视网膜彩色眼底照片（CFP）中检测早期DR严重程度变化，使用一对连续检查。实验是在一个纵向DR筛查数据集上进行的，有或没有那些训练好的编码器（LSSL）作为纵向假设任务。结果在基线（从头开始训练的模型）上实现了0.875的AUC。

    arXiv:2209.00915v3 Announce Type: replace-cross  Abstract: Longitudinal imaging is able to capture both static anatomical structures and dynamic changes in disease progression towards earlier and better patient-specific pathology management. However, conventional approaches for detecting diabetic retinopathy (DR) rarely take advantage of longitudinal information to improve DR analysis. In this work, we investigate the benefit of exploiting self-supervised learning with a longitudinal nature for DR diagnosis purposes. We compare different longitudinal self-supervised learning (LSSL) methods to model the disease progression from longitudinal retinal color fundus photographs (CFP) to detect early DR severity changes using a pair of consecutive exams. The experiments were conducted on a longitudinal DR screening dataset with or without those trained encoders (LSSL) acting as a longitudinal pretext task. Results achieve an AUC of 0.875 for the baseline (model trained from scratch) and an AU
    
[^317]: 在次优CBS中有效集成加权成本和冲突启发

    Effective Integration of Weighted Cost-to-go and Conflict Heuristic within Suboptimal CBS

    [https://arxiv.org/abs/2205.11624](https://arxiv.org/abs/2205.11624)

    本文发现在次优CBS中，加权成本启发式和冲突启发式可以有效结合，其中一种变体在多种情景和方法中可实现大幅速度提升。

    

    冲突搜索（CBS）是一种流行的多智能体路径规划（MAPF）求解器，它采用一个低级单智能体规划器和一个高级约束树来解决冲突。现代大多数MAPF求解器主要集中于通过各种策略减少该树的大小来改进CBS，很少有方法修改低级规划器。通常现有CBS方法中的低级规划器使用无权重的成本启发式方法，而次优CBS方法还使用冲突启发式方法来帮助高级搜索。在本文中，我们展示了，与流行的CBS信念相反，加权成本启发式可以有效地与冲突启发式一起在两种可能的变体中使用。特别地，其中一种变体在几种情景和次优CBS方法中可以获得大幅加速，2-100倍。重要的是，我们发现性能与加权成本启发式相关，而不是与冲突起发式相关。

    arXiv:2205.11624v5 Announce Type: replace  Abstract: Conflict-Based Search (CBS) is a popular multi-agent path finding (MAPF) solver that employs a low-level single agent planner and a high-level constraint tree to resolve conflicts. The vast majority of modern MAPF solvers focus on improving CBS by reducing the size of this tree through various strategies with few methods modifying the low level planner. Typically low level planners in existing CBS methods use an unweighted cost-to-go heuristic, with suboptimal CBS methods also using a conflict heuristic to help the high level search. In this paper, we show that, contrary to prevailing CBS beliefs, a weighted cost-to-go heuristic can be used effectively alongside the conflict heuristic in two possible variants. In particular, one of these variants can obtain large speedups, 2-100x, across several scenarios and suboptimal CBS methods. Importantly, we discover that performance is related not to the weighted cost-to-go heuristic but rath
    
[^318]: 一个基于cGAN集成的关注不确定性的离线模型优化工业控制问题的替代模型

    A cGAN Ensemble-based Uncertainty-aware Surrogate Model for Offline Model-based Optimization in Industrial Control Problems

    [https://arxiv.org/abs/2205.07250](https://arxiv.org/abs/2205.07250)

    引入了一个基于cGAN集成的关注不确定性的替代模型，用于可靠处理工业控制问题中的离线模型优化，实验结果表明其优于竞争基线模型。

    

    本研究关注将离线模型优化应用于真实世界工业控制问题时遇到的两个重要问题。第一个问题是如何创建一个可靠的概率模型，准确捕捉嘈杂工业数据中存在的动态特性。第二个问题是如何在不主动收集工业系统反馈的情况下可靠地优化控制参数。具体来说，我们引入了一个新颖的基于cGAN集成的关注不确定性的替代模型，用于可靠地处理工业控制问题中的离线模型优化。通过在两个代表性案例上进行的大量实验来证明所提方法的有效性，即离散控制案例和连续控制案例。这些实验结果表明，我们的方法在工业控制的离线模型优化领域中胜过了几个竞争基线模型。

    arXiv:2205.07250v2 Announce Type: replace-cross  Abstract: This study focuses on two important problems related to applying offline model-based optimization to real-world industrial control problems. The first problem is how to create a reliable probabilistic model that accurately captures the dynamics present in noisy industrial data. The second problem is how to reliably optimize control parameters without actively collecting feedback from industrial systems. Specifically, we introduce a novel cGAN ensemble-based uncertainty-aware surrogate model for reliable offline model-based optimization in industrial control problems. The effectiveness of the proposed method is demonstrated through extensive experiments conducted on two representative cases, namely a discrete control case and a continuous control case. The results of these experiments show that our method outperforms several competitive baselines in the field of offline model-based optimization for industrial control.
    
[^319]: 对于一类支持向量机在不同缺陷预测场景中的有效性研究

    On The Effectiveness of One-Class Support Vector Machine in Different Defect Prediction Scenarios

    [https://arxiv.org/abs/2202.12074](https://arxiv.org/abs/2202.12074)

    本文研究了一类支持向量机在不同缺陷预测场景中的有效性，并发现其在跨版本和跨项目的缺陷预测模型中表现出色。

    

    缺陷预测旨在识别在软件提供给最终用户之前可能引起故障的软件组件。迄今为止，这一任务被建模为一个双类别分类问题，然而其本质也允许将其构建为一个一类分类任务。先前的研究表明，一类支持向量机（OCSVM）在项目内缺陷预测方面可以胜过双类别分类器，然而当应用于更细粒度的情况（即基于提交级别的缺陷预测）时并不有效。在本文中，我们进一步研究仅从一类进行学习是否足以生成在两种其他不同场景（即粒度）中产生有效缺陷预测模型，即跨版本和跨项目缺陷预测模型，并为了完整性复制在项目内粒度的先前工作。我们的实证结果证实了OCSVM的表现

    arXiv:2202.12074v2 Announce Type: replace-cross  Abstract: Defect prediction aims at identifying software components that are likely to cause faults before a software is made available to the end-user. To date, this task has been modeled as a two-class classification problem, however its nature also allows it to be formulated as a one-class classification task. Previous studies show that One-Class Support Vector Machine (OCSVM) can outperform two-class classifiers for within-project defect prediction, however it is not effective when employed at a finer granularity (i.e., commit-level defect prediction). In this paper, we further investigate whether learning from one class only is sufficient to produce effective defect prediction model in two other different scenarios (i.e., granularity), namely cross-version and cross-project defect prediction models, as well as replicate the previous work at within-project granularity for completeness. Our empirical results confirm that OCSVM perform
    
[^320]: Meta-Reinforcement Learning中梯度偏差的理论理解

    A Theoretical Understanding of Gradient Bias in Meta-Reinforcement Learning

    [https://arxiv.org/abs/2112.15400](https://arxiv.org/abs/2112.15400)

    本文对梯度为基础的元强化学习中的梯度偏差进行了深入理论理解，提出了统一框架描述GMRL算法的变化，并指出现有的随机元梯度估计器实际上是有偏的。

    

    梯度为基础的元强化学习（GMRL）是指保持两级优化程序的方法，其中外层元学习者指导内层梯度为基础的强化学习者实现快速适应。在本文中，我们开发了一个统一框架，描述了GMRL算法的变化，并指出GMRL采用的现有随机元梯度估计器实际上是有偏的。这种元梯度偏差来自两个方面：1）由两级问题结构引起的合成偏差，对内部更新步骤$K$、学习率$\alpha$、估计方差$\hat{\sigma}^{2}_{\text{In}}$和样本大小$|\tau|$有一个上限为$\mathcal{O}(K\alpha^{K}\hat{\sigma}_{\text{In}}|\tau|^{-0.5}$；2）由于使用自动微分而导致的多步Hessian估计偏差$\hat{\Delta}_{H}$，其具有多项式影响$\mathcal{O}((K-1)(\hat{\Delta}_...

    arXiv:2112.15400v4 Announce Type: replace-cross  Abstract: Gradient-based Meta-RL (GMRL) refers to methods that maintain two-level optimisation procedures wherein the outer-loop meta-learner guides the inner-loop gradient-based reinforcement learner to achieve fast adaptations. In this paper, we develop a unified framework that describes variations of GMRL algorithms and points out that existing stochastic meta-gradient estimators adopted by GMRL are actually \textbf{biased}. Such meta-gradient bias comes from two sources: 1) the compositional bias incurred by the two-level problem structure, which has an upper bound of $\mathcal{O}\big(K\alpha^{K}\hat{\sigma}_{\text{In}}|\tau|^{-0.5}\big)$ \emph{w.r.t.} inner-loop update step $K$, learning rate $\alpha$, estimate variance $\hat{\sigma}^{2}_{\text{In}}$ and sample size $|\tau|$, and 2) the multi-step Hessian estimation bias $\hat{\Delta}_{H}$ due to the use of autodiff, which has a polynomial impact $\mathcal{O}\big((K-1)(\hat{\Delta}_
    
[^321]: 数字感作为操纵大脑的新兴属性

    A Number Sense as an Emergent Property of the Manipulating Brain

    [https://arxiv.org/abs/2012.04132](https://arxiv.org/abs/2012.04132)

    从学习动作预测任务中，出现了一种意想不到的图像表示，展示出预示了感知和

    

    数字和数量的理解与操纵能力在儿童时期出现，但人类获取和发展这种能力的机制仍然未得到很好的理解。本文通过一个模型探讨了这个问题，假设学习者能够从其选择的位置拿起和放置小物体，并会自发地进行这种无目的的操纵。我们进一步假设学习者的视觉系统将监视场景中物体的变化布局，并通过将感知与来自运动系统的监督信号进行比较来学会预测每个动作的效果。我们使用标准深度网络进行特征提取和分类，以及梯度下降学习来建模感知。我们的主要发现是，通过学习动作预测任务，出现了一种意想不到的图像表示，展示出预示了感知和

    arXiv:2012.04132v4 Announce Type: replace-cross  Abstract: The ability to understand and manipulate numbers and quantities emerges during childhood, but the mechanism through which humans acquire and develop this ability is still poorly understood. We explore this question through a model, assuming that the learner is able to pick up and place small objects from, and to, locations of its choosing, and will spontaneously engage in such undirected manipulation. We further assume that the learner's visual system will monitor the changing arrangements of objects in the scene and will learn to predict the effects of each action by comparing perception with a supervisory signal from the motor system. We model perception using standard deep networks for feature extraction and classification, and gradient descent learning. Our main finding is that, from learning the task of action prediction, an unexpected image representation emerges exhibiting regularities that foreshadow the perception and 
    
[^322]: mForms: 多模态问答形式填充

    mForms : Multimodal Form-Filling with Question Answering

    [https://arxiv.org/abs/2011.12340](https://arxiv.org/abs/2011.12340)

    本文提出了一种将表单填充任务重新构造为多模态自然语言问答的新方法，通过预训练的QA系统实现表单元素的填充，并通过多任务训练进一步细化表单填充过程。

    

    本文提出了一种新的表单填充方法，将任务重新构造为多模态自然语言问答（QA）。通过首先将GUI表单上的元素（文本字段、按钮、图标等）转化为自然语言问题来实现这种重新构造，这些问题捕捉了元素的多模态语义。在确定表单元素（问题）和用户话语（答案）之间的匹配后，通过一个经过预训练的抽取式QA系统填充表单元素。通过利用预训练的QA模型，而不需要特定于表单的训练，这种表单填充方法是零-shot 的。本文还提出了进一步通过使用多任务训练来细化表单填充的方法，以整合可能大量的连续任务。最后，本文介绍了一个多模态自然语言表单填充数据集Multimodal Forms（mForms），以及一个多模态扩展

    arXiv:2011.12340v3 Announce Type: replace  Abstract: This paper presents a new approach to form-filling by reformulating the task as multimodal natural language Question Answering (QA). The reformulation is achieved by first translating the elements on the GUI form (text fields, buttons, icons, etc.) to natural language questions, where these questions capture the element's multimodal semantics. After a match is determined between the form element (Question) and the user utterance (Answer), the form element is filled through a pre-trained extractive QA system. By leveraging pre-trained QA models and not requiring form-specific training, this approach to form-filling is zero-shot. The paper also presents an approach to further refine the form-filling by using multi-task training to incorporate a potentially large number of successive tasks. Finally, the paper introduces a multimodal natural language form-filling dataset Multimodal Forms (mForms), as well as a multimodal extension of the
    
[^323]: 用计数符号的一阶逻辑定义的概念的学习

    Learning Concepts Definable in First-Order Logic with Counting

    [https://arxiv.org/abs/1909.03820](https://arxiv.org/abs/1909.03820)

    该研究将一阶逻辑与计数符号相结合，证明了可以在多对数度结构下以次线性时间一致学习可定义的分类器，为包含数值方面的机器学习扩展学习框架迈出了第一步。

    

    我们研究了在Grohe和Tur\'an引入的逻辑框架下的关系背景结构上的布尔分类问题。众所周知(Grohe和Ritzert, LICS 2017)，在多对数度结构上的一阶逻辑可定义的分类器可以在次线性时间内学习，其中结构的度和运行时间是以结构的大小为单位来衡量的。我们将结果推广到了由Kuske和Schweikardt(LICS 2017)引入的带计数的一阶逻辑FOCN，它作为一个广泛推广各种计数逻辑的表现逻辑。具体来说，我们证明了可以在多对数度结构类上定义的FOCN中的分类器可以在次线性时间内一致地学习。这可以看作是将学习框架扩展以包含机器学习的数值方面的第一步。我们将这一结果扩展到了无视的概率

    arXiv:1909.03820v2 Announce Type: replace-cross  Abstract: We study Boolean classification problems over relational background structures in the logical framework introduced by Grohe and Tur\'an (TOCS 2004). It is known (Grohe and Ritzert, LICS 2017) that classifiers definable in first-order logic over structures of polylogarithmic degree can be learned in sublinear time, where the degree of the structure and the running time are measured in terms of the size of the structure. We generalise the results to the first-order logic with counting FOCN, which was introduced by Kuske and Schweikardt (LICS 2017) as an expressive logic generalising various other counting logics. Specifically, we prove that classifiers definable in FOCN over classes of structures of polylogarithmic degree can be consistently learned in sublinear time. This can be seen as a first step towards extending the learning framework to include numerical aspects of machine learning. We extend the result to agnostic probabl
    
[^324]: 分布一致的结构因果模型

    Distribution-consistency Structural Causal Models. (arXiv:2401.15911v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2401.15911](http://arxiv.org/abs/2401.15911)

    本文提出了分布一致的结构因果模型（DiscoSCMs），用于解决因果建模中的反事实建模挑战。这种模型通过引入分布一致假设来解决因果模型的容量限制，从而提高反事实推理的准确性和实用性。

    

    在因果建模领域，潜在结果和结构因果模型是主要的框架。然而，这些框架在实际建模反事实情况时面临着显著挑战，这些反事实情况形式化为潜在结果的联合分布参数。反事实推理在当代决策过程中具有重要的意义，特别是在需要基于$(Y(0),Y(1))$的联合值进行个性化激励的情景中。本文首先研究了潜在结果和结构因果模型的反事实建模框架。通过分析，我们发现了一种固有的模型容量限制，称为“退化的反事实问题”，这是这两个框架的基石一致性规则所导致的。为了解决这个限制，我们引入了一种新的“分布一致”假设，并根据这个假设提出了分布一致的结构因果模型（DiscoSCMs）。

    In the field of causal modeling, potential outcomes (PO) and structural causal models (SCMs) stand as the predominant frameworks. However, these frameworks face notable challenges in practically modeling counterfactuals, formalized as parameters of the joint distribution of potential outcomes. Counterfactual reasoning holds paramount importance in contemporary decision-making processes, especially in scenarios that demand personalized incentives based on the joint values of $(Y(0), Y(1))$. This paper begins with an investigation of the PO and SCM frameworks for modeling counterfactuals. Through the analysis, we identify an inherent model capacity limitation, termed as the ``degenerative counterfactual problem'', emerging from the consistency rule that is the cornerstone of both frameworks. To address this limitation, we introduce a novel \textit{distribution-consistency} assumption, and in alignment with it, we propose the Distribution-consistency Structural Causal Models (DiscoSCMs) o
    
[^325]: 通过检索示范进行上下文学习的语言模型：一项综述

    In-context Learning with Retrieved Demonstrations for Language Models: A Survey. (arXiv:2401.11624v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2401.11624](http://arxiv.org/abs/2401.11624)

    本综述调查了一种名为检索示范的方法，它通过使用特定于输入查询的示范来提高语言模型的少量样本情境学习（ICL）能力。这种方法不仅提高了学习效率和可扩展性，还减少了手动示例选择中的偏见。

    

    语言模型，特别是预训练的大型语言模型，已展示出卓越的能力，可以在输入上下文中进行少量样本的情境学习（ICL），并在新任务上具有适应能力。然而，模型的ICL能力对于少样本示范的选择是敏感的。最近的一项研究进展是检索针对每个输入查询定制的示范。示范检索的实现相对简单，利用现有的数据库和检索系统。这不仅提高了学习过程的效率和可扩展性，而且已经证明可以减少手动示例选择中的偏见。鉴于令人鼓舞的结果和在检索示范的ICL方面不断增长的研究，我们进行了广泛的研究综述。在这项综述中，我们讨论和比较了检索模型的不同设计选择，检索训练

    Language models, especially pre-trained large language models, have showcased remarkable abilities as few-shot in-context learners (ICL), adept at adapting to new tasks with just a few demonstrations in the input context. However, the model's ability to perform ICL is sensitive to the choice of the few-shot demonstrations. Instead of using a fixed set of demonstrations, one recent development is to retrieve demonstrations tailored to each input query. The implementation of demonstration retrieval is relatively straightforward, leveraging existing databases and retrieval systems. This not only improves the efficiency and scalability of the learning process but also has been shown to reduce biases inherent in manual example selection. In light of the encouraging results and growing research in ICL with retrieved demonstrations, we conduct an extensive review of studies in this area. In this survey, we discuss and compare different design choices for retrieval models, retrieval training p
    
[^326]: 代码之间的界限：揭示机器和人类程序员之间不同的模式

    Between Lines of Code: Unraveling the Distinct Patterns of Machine and Human Programmers. (arXiv:2401.06461v1 [cs.SE])

    [http://arxiv.org/abs/2401.06461](http://arxiv.org/abs/2401.06461)

    本文通过分析代码的属性，揭示了机器和人类代码之间的独特模式，尤其是结构分割对于识别代码来源很关键。基于这些发现，我们提出了一种名为DetectCodeGPT的新方法来检测机器生成的代码。

    

    大型语言模型在代码生成方面取得了显著的进展，但它们模糊了机器和人类源代码之间的区别，导致软件产物的完整性和真实性问题。本文通过对代码长度、词汇多样性和自然性等属性的严格分析，揭示了机器和人类代码固有的独特模式。在我们的研究中特别注意到，代码的结构分割是识别其来源的关键因素。基于我们的发现，我们提出了一种名为DetectCodeGPT的新型机器生成代码检测方法，该方法改进了DetectGPT。

    Large language models have catalyzed an unprecedented wave in code generation. While achieving significant advances, they blur the distinctions between machine-and human-authored source code, causing integrity and authenticity issues of software artifacts. Previous methods such as DetectGPT have proven effective in discerning machine-generated texts, but they do not identify and harness the unique patterns of machine-generated code. Thus, its applicability falters when applied to code. In this paper, we carefully study the specific patterns that characterize machine and human-authored code. Through a rigorous analysis of code attributes such as length, lexical diversity, and naturalness, we expose unique pat-terns inherent to each source. We particularly notice that the structural segmentation of code is a critical factor in identifying its provenance. Based on our findings, we propose a novel machine-generated code detection method called DetectCodeGPT, which improves DetectGPT by cap
    
[^327]: 视觉和语言编码器是否以相似方式表示世界？

    Do Vision and Language Encoders Represent the World Similarly?. (arXiv:2401.05224v1 [cs.CV])

    [http://arxiv.org/abs/2401.05224](http://arxiv.org/abs/2401.05224)

    通过分析视觉和语言模型的潜在空间结构，发现未对齐和对齐的编码器的表示空间在语义上是相似的。我们提出了两种方法来匹配未对齐编码器，无需训练即可实现匹配。

    

    已经成为视觉语言任务中事实上的模型的对齐的文本-图像编码器（如CLIP）已经取得了令人印象深刻的表现。此外，模态特定的编码器在各自领域中也取得了令人印象深刻的表现。这引出了一个核心问题：由于它们基本上表示同一个物理世界，单模态的视觉和语言编码器之间是否存在对齐？通过使用中心核对齐（CKA）分析图像-标题基准上视觉和语言模型的潜在空间结构，我们发现未对齐和对齐的编码器的表示空间在语义上是相似的。在像CLIP这样的对齐编码器中缺乏统计相似性的情况下，我们显示了可能存在无需任何训练的未对齐编码器的匹配。我们将这视为利用图之间的语义相似性的有种子图匹配问题，并提出了两种方法 - 快速二次分配问题优化和一种基于新颖的局部CKA度量的匹配/检索方法。

    Aligned text-image encoders such as CLIP have become the de facto model for vision-language tasks. Furthermore, modality-specific encoders achieve impressive performances in their respective domains. This raises a central question: does an alignment exist between uni-modal vision and language encoders since they fundamentally represent the same physical world? Analyzing the latent spaces structure of vision and language models on image-caption benchmarks using the Centered Kernel Alignment (CKA), we find that the representation spaces of unaligned and aligned encoders are semantically similar. In the absence of statistical similarity in aligned encoders like CLIP, we show that a possible matching of unaligned encoders exists without any training. We frame this as a seeded graph-matching problem exploiting the semantic similarity between graphs and propose two methods - a Fast Quadratic Assignment Problem optimization, and a novel localized CKA metric-based matching/retrieval. We demons
    
[^328]: 简约即大道：对多模态少样本学习的深入研究

    Less is More : A Closer Look at Multi-Modal Few-Shot Learning. (arXiv:2401.05010v1 [cs.CV])

    [http://arxiv.org/abs/2401.05010](http://arxiv.org/abs/2401.05010)

    该论文提出了一个简单但有效的框架，利用文本信息和语言模型来进行少样本学习任务，充分发挥了预训练语言模型的零样本能力，并直接将视觉特征和文本特征进行推理。

    

    少样本学习旨在通过极少量的可用图像来学习和区分新的类别，这在深度学习领域中构成了一个重大挑战。最近的研究者们试图利用这些稀有类别的附加文本或语言信息和预训练的语言模型来促进学习，从而在一定程度上缓解不足的监督信号问题。然而，至今对于文本信息和预训练语言模型的充分潜力在少样本学习中被低估了，导致性能的提升有限。为了解决这个问题，我们提出了一个简单但有效的少样本学习任务框架，专门设计用于利用文本信息和语言模型。更详细地说，我们明确地利用可学习的提示来充分发挥预训练语言模型的零样本能力。我们直接将视觉特征和文本特征进行推理，而不是简单地添加它们。

    Few-shot Learning aims to learn and distinguish new categories with a very limited number of available images, presenting a significant challenge in the realm of deep learning. Recent researchers have sought to leverage the additional textual or linguistic information of these rare categories with a pre-trained language model to facilitate learning, thus partially alleviating the problem of insufficient supervision signals. However, the full potential of the textual information and pre-trained language model have been underestimated in the few-shot learning till now, resulting in limited performance enhancements. To address this, we propose a simple but effective framework for few-shot learning tasks, specifically designed to exploit the textual information and language model. In more detail, we explicitly exploit the zero-shot capability of the pre-trained language model with the learnable prompt. And we just add the visual feature with the textual feature for inference directly witho
    
[^329]: SVGDreamer：基于文本引导的SVG生成与扩散模型

    SVGDreamer: Text Guided SVG Generation with Diffusion Model. (arXiv:2312.16476v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.16476](http://arxiv.org/abs/2312.16476)

    该论文提出了一种名为SVGDreamer的方法，用于基于文本引导的SVG生成。它通过引入语义驱动的图像矢量化过程和基于注意力的元素控制，增强了生成结果的可编辑性和质量。同时，采用基于矢量化粒子分数蒸馏的方法解决了现有方法中的颜色、平滑度和结果多样性方面的挑战。

    

    最近，基于文本引导的可缩放矢量图形（SVG）合成在图标设计和草图等领域展示出了潜力。然而，现有的文本到SVG生成方法存在缺乏可编辑性、视觉质量和结果多样性不足的问题。为了解决这些限制，我们提出了一种新颖的基于文本引导的矢量图形合成方法，称为SVGDreamer。SVGDreamer整合了一种语义驱动的图像矢量化（SIVE）过程，可以将合成过程分解为前景对象和背景，从而增强了可编辑性。具体而言，SIVE过程引入了基于注意力的基本元素控制和注意力掩蔽损失函数，以有效控制和操作各个元素。此外，我们提出了一种基于矢量化粒子分数蒸馏（VPSD）的方法，以解决现有文本到SVG生成方法中颜色过饱和、矢量基元过平滑和结果多样性有限的挑战。

    Recently, text-guided scalable vector graphics (SVGs) synthesis has shown promise in domains such as iconography and sketch. However, existing text-to-SVG generation methods lack editability and struggle with visual quality and result diversity. To address these limitations, we propose a novel text-guided vector graphics synthesis method called SVGDreamer. SVGDreamer incorporates a semantic-driven image vectorization (SIVE) process that enables the decomposition of synthesis into foreground objects and background, thereby enhancing editability. Specifically, the SIVE process introduce attention-based primitive control and an attention-mask loss function for effective control and manipulation of individual elements. Additionally, we propose a Vectorized Particle-based Score Distillation (VPSD) approach to tackle the challenges of color over-saturation, vector primitives over-smoothing, and limited result diversity in existing text-to-SVG generation methods. Furthermore, on the basis of 
    
[^330]: 偏好作为奖励，使用重要性抽样进行最大偏好优化

    Preference as Reward, Maximum Preference Optimization with Importance Sampling. (arXiv:2312.16430v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.16430](http://arxiv.org/abs/2312.16430)

    本文提出了一种使用重要性抽样进行最大偏好优化的算法，该算法通过直接优化生成策略来消除对奖励模型的需求，提高了数据利用率和稳定性，并通过解决KL正则化问题来改善偏好学习效果。

    

    偏好学习是将语言模型与人类价值观对齐的关键技术。从人类反馈强化学习（RLHF）是一种基于模型的算法，用于优化偏好学习，首先拟合偏好分数的奖励模型，然后使用基于策略梯度算法进行优化，以最大化奖励。RLHF的处理过程复杂、耗时且不稳定。直接偏好优化（DPO）算法使用离策略算法直接优化生成策略，消除了对奖励模型的需求，具有高效和稳定的数据利用率。DPO使用布拉德利-特里模型和对数损失，导致在偏好接近确定性时忽略了KL正则化项而过度拟合偏好数据。IPO使用一种基于根查找的成对均方误差损失来解决忽略KL正则化问题，并学习到最优策略。但是IPO的成对损失仍然无法使KL正则化生效。本文设计了一种新的算法，使用重要性抽样技术来解决偏好学习中的优化问题。

    Preference learning is a key technology for aligning language models with human values. Reinforcement Learning from Human Feedback (RLHF) is a model based algorithm to optimize preference learning, which first fitting a reward model for preference score, and then optimizing generating policy with on-policy PPO algorithm to maximize the reward. The processing of RLHF is complex, time-consuming and unstable. Direct Preference Optimization (DPO) algorithm using off-policy algorithm to direct optimize generating policy and eliminating the need for reward model, which is data efficient and stable. DPO use Bradley-Terry model and log-loss which leads to over-fitting to the preference data at the expense of ignoring KL-regularization term when preference near deterministic. IPO uses a root-finding pairwise MSE loss to solve the ignoring KL-regularization problem, and learning an optimal policy. But IPO's pairwise loss still can't s make the KL-regularization to work. In this paper, we design 
    
[^331]: VQPy：一种面向现代视频分析的面向对象方法。

    VQPy: An Object-Oriented Approach to Modern Video Analytics. (arXiv:2311.01623v1 [cs.CV])

    [http://arxiv.org/abs/2311.01623](http://arxiv.org/abs/2311.01623)

    VQPy是一种面向对象的视频分析方法，它使用Python变体作为前端，并具有可扩展的后端，可以自动构建和优化基于视频对象的处理流程。

    

    视频分析广泛应用于当今系统和服务中。在视频分析的前沿是用户开发的视频查询，以找到特定感兴趣的对象。基于视频对象（例如人，动物，汽车等）与传统面向对象语言建模的对象相似的洞察力，我们提出了一种面向视频分析的面向对象方法。这种方法名为VQPy，包括一个前端（一种Python变体，其中包含用户可以表达视频对象及其交互的结构）和一个可扩展的后端，可以基于视频对象自动生成和优化管道。我们已经实施和开源了VQPy，它已经作为Cisco DeepVision框架的一部分产品化。

    Video analytics is widely used in contemporary systems and services. At the forefront of video analytics are video queries that users develop to find objects of particular interest. Building upon the insight that video objects (e.g., human, animals, cars, etc.), the center of video analytics, are similar in spirit to objects modeled by traditional object-oriented languages, we propose to develop an object-oriented approach to video analytics. This approach, named VQPy, consists of a frontend$\unicode{x2015}$a Python variant with constructs that make it easy for users to express video objects and their interactions$\unicode{x2015}$as well as an extensible backend that can automatically construct and optimize pipelines based on video objects. We have implemented and open-sourced VQPy, which has been productized in Cisco as part of its DeepVision framework.
    
[^332]: 人工智能的不透明法律

    The opaque law of artificial intelligence. (arXiv:2310.13192v1 [cs.AI])

    [http://arxiv.org/abs/2310.13192](http://arxiv.org/abs/2310.13192)

    本文分析了算法的不透明性，重点关注人工智能在因果责任领域中的应用。通过对目前最好的生成式人工智能模型（Chat-GPT）的评估，可以了解其目前的性能以及可能的法律规制形式。

    

    本文旨在分析算法的不透明性，并将其置于人工智能因果责任的公开辩论背景下进行讨论；通过应用图灵测试中提出的对话方法，我们希望评估现有最好的生成式人工智能模型（Chat-GPT）的性能，以确定其目前的能力和可能的法律规制形式。问题分析将基于对传统法律范畴（如因果关系、意图和过失）的评论，以理解人工智能使用中的问题，特别关注人机交互。从计算机科学角度来看，文中还将提出一种针对Chat-GPT进行实际询问的方法，以找到人工智能运行过程中的一些关键问题。文章的结尾将集中讨论一些现有的立法措施。

    The purpose of this paper is to analyse the opacity of algorithms, contextualized in the open debate on responsibility for artificial intelligence causation; with an experimental approach by which, applying the proposed conversational methodology of the Turing Test, we expect to evaluate the performance of one of the best existing NLP model of generative AI (Chat-GPT) to see how far it can go right now and how the shape of a legal regulation of it could be. The analysis of the problem will be supported by a comment of Italian classical law categories such as causality, intent and fault to understand the problem of the usage of AI, focusing in particular on the human-machine interaction. On the computer science side, for a technical point of view of the logic used to craft these algorithms, in the second chapter will be proposed a practical interrogation of Chat-GPT aimed at finding some critical points of the functioning of AI. The end of the paper will concentrate on some existing leg
    
[^333]: 一种用于时间序列分析的多尺度分解MLP-Mixer

    A Multi-Scale Decomposition MLP-Mixer for Time Series Analysis. (arXiv:2310.11959v1 [cs.LG])

    [http://arxiv.org/abs/2310.11959](http://arxiv.org/abs/2310.11959)

    我们提出了一种名为MSD-Mixer的多尺度分解MLP-Mixer模型，它能够将时间序列分解成不同的组成部分，并在不同的层次中表示这些组成部分。我们还提出了一种新颖的时间拼接方法，以处理多尺度的时间模式和通道间的依赖关系。我们的模型能够比现有方法更好地进行时间序列分析。

    

    时间序列数据通常具有独特的组成和复杂的多尺度时间变化，需要在其分析中特别考虑分解和多尺度建模。现有的深度学习方法只适用于单变量时间序列，并且对子序列级别的建模和分解不够充分。为了解决这个问题，我们提出了MSD-Mixer，一种多尺度分解的MLP-Mixer，它学会了将输入的时间序列明确地分解成不同的组成部分，并在不同的层次中表示这些组成部分。为了处理多尺度的时间模式和通道间的依赖关系，我们提出了一种新颖的时间拼接方法，将时间序列建模为多尺度子序列，即patches，并使用MLPs来组合patches内部和patches间的变化以及通道间的相关性。此外，我们提出了一个损失函数来约束分解残差的幅度和自相关性，以实现完整的分解。

    Time series data, often characterized by unique composition and complex multi-scale temporal variations, requires special consideration of decomposition and multi-scale modeling in its analysis. Existing deep learning methods on this best fit to only univariate time series, and have not sufficiently accounted for sub-series level modeling and decomposition completeness. To address this, we propose MSD-Mixer, a Multi-Scale Decomposition MLP-Mixer which learns to explicitly decompose the input time series into different components, and represents the components in different layers. To handle multi-scale temporal patterns and inter-channel dependencies, we propose a novel temporal patching approach to model the time series as multi-scale sub-series, i.e., patches, and employ MLPs to mix intra- and inter-patch variations and channel-wise correlations. In addition, we propose a loss function to constrain both the magnitude and autocorrelation of the decomposition residual for decomposition 
    
[^334]: SOTOPIA: 交互式评估语言智能中的社交智能

    SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents. (arXiv:2310.11667v1 [cs.AI])

    [http://arxiv.org/abs/2310.11667](http://arxiv.org/abs/2310.11667)

    SOTOPIA是一个用于评估语言智能中的社交智能的交互式环境。通过模拟复杂的社交互动，并使用全面的评估框架，我们发现不同模型之间的社交智能存在显著差异，特别是在SOTOPIA-hard情景下。GPT-4在这个子集上的目标完成率较低。

    

    人类是社交的存在；我们在日常互动中追求社交目标，这是社交智能的关键方面。然而，人工智能系统在这个领域的能力仍然难以捉摸。我们提出了SOTOPIA，一个开放式环境，用于模拟人工智能代理之间的复杂社交互动并评估它们的社交智能。在我们的环境中，代理人扮演角色，在各种场景下相互协作、合作、交流和竞争，以实现复杂的社交目标。我们模拟了LLM-based代理人与人类之间在这个任务空间内的角色扮演互动，并使用一个名为SOTOPIA-Eval的整体评估框架对它们的表现进行评估。通过SOTOPIA，我们发现这些模型在社交智能方面存在显著差异，并确定了SOTOPIA的一个子集，即SOTOPIA-hard，对所有模型来说都具有挑战性。我们发现在这个子集上，GPT-4的目标完成率显著较低。

    Humans are social beings; we pursue social goals in our daily interactions, which is a crucial aspect of social intelligence. Yet, AI systems' abilities in this realm remain elusive. We present SOTOPIA, an open-ended environment to simulate complex social interactions between artificial agents and evaluate their social intelligence. In our environment, agents role-play and interact under a wide variety of scenarios; they coordinate, collaborate, exchange, and compete with each other to achieve complex social goals. We simulate the role-play interaction between LLM-based agents and humans within this task space and evaluate their performance with a holistic evaluation framework called SOTOPIA-Eval. With SOTOPIA, we find significant differences between these models in terms of their social intelligence, and we identify a subset of SOTOPIA scenarios, SOTOPIA-hard, that is generally challenging for all models. We find that on this subset, GPT-4 achieves a significantly lower goal completio
    
[^335]: 区块链联邦学习中分散化的影响：评估模型陈旧和不一致的影响

    The Implications of Decentralization in Blockchained Federated Learning: Evaluating the Impact of Model Staleness and Inconsistencies. (arXiv:2310.07471v1 [cs.NI])

    [http://arxiv.org/abs/2310.07471](http://arxiv.org/abs/2310.07471)

    本研究评估了将联邦学习的协调外包给区块链等分散网络的实际影响，重点关注了由区块链的运作方式支持的模型陈旧和不一致对异步FL训练过程的影响。

    

    区块链承诺通过提供进一步的分散化、安全性、不可变性和信任来增强联邦学习等分布式机器学习方法，这些特性对于实现下一代应用中的协作智能至关重要。然而，点对点（P2P）区块链节点的内在分散化操作使得联邦学习处于未知的状态，FL轮次和全局模型的概念变得无意义，因为设备的同步丢失了中心协调服务器的形象。在本文中，我们研究将FL的协调外包给区块链等民主网络的实际影响。具体而言，我们关注由区块链的运作方式支持的模型陈旧和不一致对异步进行的FL训练过程的影响。通过模拟，我们评估了基于区块链的FL在著名的CIFAR-10数据集上的运作情况，并着重研究。

    Blockchain promises to enhance distributed machine learning (ML) approaches such as federated learning (FL) by providing further decentralization, security, immutability, and trust, which are key properties for enabling collaborative intelligence in next-generation applications. Nonetheless, the intrinsic decentralized operation of peer-to-peer (P2P) blockchain nodes leads to an uncharted setting for FL, whereby the concepts of FL round and global model become meaningless, as devices' synchronization is lost without the figure of a central orchestrating server. In this paper, we study the practical implications of outsourcing the orchestration of FL to a democratic network such as in a blockchain. In particular, we focus on the effects that model staleness and inconsistencies, endorsed by blockchains' modus operandi, have on the training procedure held by FL devices asynchronously. Using simulation, we evaluate the blockchained FL operation on the well-known CIFAR-10 dataset and focus 
    
[^336]: Lemur：在自动程序验证中集成大型语言模型

    Lemur: Integrating Large Language Models in Automated Program Verification. (arXiv:2310.04870v2 [cs.FL] UPDATED)

    [http://arxiv.org/abs/2310.04870](http://arxiv.org/abs/2310.04870)

    本论文提出了一种将LLMs和自动推理器结合起来进行自动程序验证的通用方法，并证明了其完备性。这个方法在一些合成和竞争基准上取得了实际的改进。

    

    LLMs在代码理解能力上的展示引发了一个问题：它们是否可以用于自动程序验证，这是一个通常需要高级抽象推理的任务，对于验证工具来说是具有挑战性的。我们提出了一种将LLMs的能力和自动推理器结合起来进行自动程序验证的通用方法。我们正式描述了这种方法论，将其作为推导规则的集合进行论证其完备性。我们将计算机推理形成为一个完备的自动验证过程，这在一组合成和竞争基准上带来了实际的改进。

    The demonstrated code-understanding capability of LLMs raises the question of whether they can be used for automated program verification, a task that often demands high-level abstract reasoning about program properties, which is challenging for verification tools. We propose a general methodology to combine the power of LLMs and automated reasoners for automated program verification. We formally describe this methodology as a set of derivation rules and prove its soundness. We instantiate the calculus as a sound automated verification procedure, which led to practical improvements on a set of synthetic and competition benchmarks.
    
[^337]: TACTiS-2：更好、更快、更简单的多变量时间序列关注联合分布模型

    TACTiS-2: Better, Faster, Simpler Attentional Copulas for Multivariate Time Series. (arXiv:2310.01327v1 [cs.LG])

    [http://arxiv.org/abs/2310.01327](http://arxiv.org/abs/2310.01327)

    TACTiS-2是一种改进的多变量时间序列关注联合分布模型，采用了简化的目标函数和线性参数数量，具有更好的训练动态和最先进的性能。

    

    我们引入了一种新的模型用于多变量概率时间序列预测，旨在灵活地处理包括预测、插值和它们的组合等一系列任务。基于联合分布理论，我们提出了一种简化的目标函数，用于最近引入的基于Transformer的关注联合分布模型（TACTiS）。新的目标函数的分布参数数量与变量数量呈线性而非阶乘关系。新的目标函数需要引入一种训练课程，并且需要对原始架构进行必要的改动。我们展示了得到的模型具有显著改善的训练动态，并在多样的真实世界预测任务中实现了最先进的性能，同时保持了先前工作的灵活性，如无缝处理不对齐和采样不均匀的时间序列。

    We introduce a new model for multivariate probabilistic time series prediction, designed to flexibly address a range of tasks including forecasting, interpolation, and their combinations. Building on copula theory, we propose a simplified objective for the recently-introduced transformer-based attentional copulas (TACTiS), wherein the number of distributional parameters now scales linearly with the number of variables instead of factorially. The new objective requires the introduction of a training curriculum, which goes hand-in-hand with necessary changes to the original architecture. We show that the resulting model has significantly better training dynamics and achieves state-of-the-art performance across diverse real-world forecasting tasks, while maintaining the flexibility of prior work, such as seamless handling of unaligned and unevenly-sampled time series.
    
[^338]: 稳定放置的外部接触块的触觉估计

    Tactile Estimation of Extrinsic Contact Patch for Stable Placement. (arXiv:2309.14552v1 [cs.RO])

    [http://arxiv.org/abs/2309.14552](http://arxiv.org/abs/2309.14552)

    本文介绍了一种利用触觉读数推测物体放置稳定性的方法，通过对接触区域的估计可以有效设计机器人的反馈技能，提高机器人的精细操控能力。

    

    对于机器人的精细操作技能来说，准确感知接触交互至关重要。本文提出了一种为机器人设计反馈技能的方法，该机器人必须学习将复杂形状的物体堆叠在一起。为了设计这样一个系统，机器人应该能够根据非常轻微的接触交互来推理放置的稳定性。我们的实验结果表明，可以根据接触形成过程中的触觉读数来推测物体放置的稳定性。具体而言，我们使用力和触觉观测来估计抓取物体和其环境之间的接触区域，从而估计接触形成过程中物体的稳定性。这种接触区域可以用来估计释放抓取后物体的稳定性。所提出的方法在一款非常流行的棋盘游戏中使用了多种物体对进行了验证。

    Precise perception of contact interactions is essential for the fine-grained manipulation skills for robots. In this paper, we present the design of feedback skills for robots that must learn to stack complex-shaped objects on top of each other. To design such a system, a robot should be able to reason about the stability of placement from very gentle contact interactions. Our results demonstrate that it is possible to infer the stability of object placement based on tactile readings during contact formation between the object and its environment. In particular, we estimate the contact patch between a grasped object and its environment using force and tactile observations to estimate the stability of the object during a contact formation. The contact patch could be used to estimate the stability of the object upon the release of the grasp. The proposed method is demonstrated on various pairs of objects that are used in a very popular board game.
    
[^339]: 学习关系之间的完整拓扑感知相关性以进行归纳链接预测

    Learning Complete Topology-Aware Correlations Between Relations for Inductive Link Prediction. (arXiv:2309.11528v1 [cs.AI])

    [http://arxiv.org/abs/2309.11528](http://arxiv.org/abs/2309.11528)

    本文提出了一种基于子图的方法TACO，用于建模高度与拓扑结构相关的关系之间的拓扑感知相关性，并展示了这种方法对于实体无关的归纳链接预测任务的潜力。

    

    归纳链接预测——在训练和推理阶段实体可能不同——已经显示出了以实体无关的方式完成演化知识图谱的巨大潜力。许多流行的方法主要关注建模图级特征，而边级交互——尤其是关系之间的语义相关性——则被较少探索。然而，我们注意到语义相关性之间的一个理想特性是它们在本质上是边级和实体无关的。这意味着语义相关性对于实体无关的归纳链接预测任务具有巨大的潜力。受到这一观察的启发，我们提出了一种新颖的基于子图的方法，即TACO，来建模与其子图内的拓扑结构高度相关的关系之间的拓扑感知相关性。

    Inductive link prediction -- where entities during training and inference stages can be different -- has shown great potential for completing evolving knowledge graphs in an entity-independent manner. Many popular methods mainly focus on modeling graph-level features, while the edge-level interactions -especially the semantic correlations between relations -- have been less explored. However, we notice a desirable property of semantic correlations between relations is that they are inherently edge-level and entity-independent. This implies the great potential of the semantic correlations for the entity-independent inductive link prediction task. Inspired by this observation, we propose a novel subgraph-based method, namely TACO, to model Topology-Aware COrrelations between relations that are highly correlated to their topological structures within subgraphs. Specifically, we prove that semantic correlations between any two relations can be categorized into seven topological patterns,
    
[^340]: HealthFC：一份用于基于证据的医学事实检验的健康声明数据集

    HealthFC: A Dataset of Health Claims for Evidence-Based Medical Fact-Checking. (arXiv:2309.08503v1 [cs.CL])

    [http://arxiv.org/abs/2309.08503](http://arxiv.org/abs/2309.08503)

    本文介绍了一份新的健康声明数据集，其中包含了750个由医学专家标注的健康相关声明，并提供了来自临床研究的证据支持。该数据集可用于机器学习任务，包括证据检索、真实性预测和解释生成。

    

    在数字时代，通过互联网查询健康相关建议已成为一种常见做法。然而，判断在线找到的医学声明的可信度，并找到相应的证据，变得越来越具有挑战性。事实检验已经成为一种通过可靠知识来源的证据评估事实声明真实性的方法。为了推动此任务的自动化，本文介绍了一份新的数据集，包含了750个健康相关声明，在可信度方面由医学专家进行了标注，并提供了来自适当的临床研究的证据支持。我们对数据集进行了分析，突出其特点和挑战。该数据集可用于与自动事实检验相关的机器学习任务，如证据检索、真实性预测和解释生成。为此，我们提供了基于不同方法的基线模型，对它们的性能进行了研究，并讨论了研究结果。

    Seeking health-related advice on the internet has become a common practice in the digital era. Determining the trustworthiness of medical claims found online and finding appropriate evidence for this information is increasingly challenging. Fact-checking has emerged as an approach to assess the veracity of factual claims using evidence from credible knowledge sources. To help advance the automation of this task, in this paper, we introduce a novel dataset of 750 health-related claims, labeled for veracity by medical experts and backed with evidence from appropriate clinical studies. We provide an analysis of the dataset, highlighting its characteristics and challenges. The dataset can be used for Machine Learning tasks related to automated fact-checking such as evidence retrieval, veracity prediction, and explanation generation. For this purpose, we provide baseline models based on different approaches, examine their performance, and discuss the findings.
    
[^341]: 可分离哈密顿神经网络

    Separable Hamiltonian Neural Networks. (arXiv:2309.01069v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.01069](http://arxiv.org/abs/2309.01069)

    这篇论文介绍了可分离哈密顿神经网络的应用，它通过嵌入可加性分离性来解决高维哈密顿系统中的复杂性问题。

    

    利用离散观测数据建模动力系统是现代科学和工程数据系统面临的挑战之一。 哈密顿系统是一类基本且广泛存在的动力系统。 哈密顿神经网络是最先进的模型，可以在汉密尔顿方程的学习偏差下，从离散观测的向量场中无监督地回归动力系统的哈密顿量。然而，哈密顿动力学通常很复杂，特别是在高维情况下，其中哈密顿系统的状态空间相对于样本数量是很大的。 最近发现的一种缓解状态变量之间复杂性的方法是利用哈密顿系统的可加性分离性，并将该可加性分离性嵌入哈密顿神经网络中。根据物理学驱动的机器学习的术语，我们提出了三种可分离的哈密顿神经网络。这些模型嵌入了可加性分离性。

    The modelling of dynamical systems from discrete observations is a challenge faced by modern scientific and engineering data systems. Hamiltonian systems are one such fundamental and ubiquitous class of dynamical systems. Hamiltonian neural networks are state-of-the-art models that unsupervised-ly regress the Hamiltonian of a dynamical system from discrete observations of its vector field under the learning bias of Hamilton's equations. Yet Hamiltonian dynamics are often complicated, especially in higher dimensions where the state space of the Hamiltonian system is large relative to the number of samples. A recently discovered remedy to alleviate the complexity between state variables in the state space is to leverage the additive separability of the Hamiltonian system and embed that additive separability into the Hamiltonian neural network. Following the nomenclature of physics-informed machine learning, we propose three separable Hamiltonian neural networks. These models embed additi
    
[^342]: 基于深度强化学习的自主驾驶中运动相关模块的轨迹跟踪

    DRL-Based Trajectory Tracking for Motion-Related Modules in Autonomous Driving. (arXiv:2308.15991v1 [cs.RO])

    [http://arxiv.org/abs/2308.15991](http://arxiv.org/abs/2308.15991)

    本文提出了一种基于深度强化学习的轨迹跟踪方法，适用于自主驾驶系统中的运动相关模块。该方法通过DL的表示学习能力和RL的探索性质，提高了轨迹跟踪的准确性和稳健性，在真实系统中具有较好的适应性和效果。

    

    自主驾驶系统总是建立在运动相关模块（如规划器和控制器）之上。准确而稳健的轨迹跟踪方法对于这些运动相关模块来说是不可或缺的原始例程。当前的方法往往对模型（如上下文和动力学）做出了强烈的假设，这些假设不足以应对真实系统中的场景变化。在本文中，我们提出了一种基于深度强化学习（DRL）的自主驾驶系统中运动相关模块的轨迹跟踪方法。DL的表示学习能力和RL的探索性质既带来了强健性又提高了准确性。与此同时，它通过以无模型和数据驱动的方式运行轨迹跟踪来增强了通用性。通过大量实验，我们证明了我们的方法相比当前方法在效率和效果上的优势。

    Autonomous driving systems are always built on motion-related modules such as the planner and the controller. An accurate and robust trajectory tracking method is indispensable for these motion-related modules as a primitive routine. Current methods often make strong assumptions about the model such as the context and the dynamics, which are not robust enough to deal with the changing scenarios in a real-world system. In this paper, we propose a Deep Reinforcement Learning (DRL)-based trajectory tracking method for the motion-related modules in autonomous driving systems. The representation learning ability of DL and the exploration nature of RL bring strong robustness and improve accuracy. Meanwhile, it enhances versatility by running the trajectory tracking in a model-free and data-driven manner. Through extensive experiments, we demonstrate both the efficiency and effectiveness of our method compared to current methods.
    
[^343]: 一种Huber损失最小化方法用于拜占庭鲁棒的联邦学习

    A Huber Loss Minimization Approach to Byzantine Robust Federated Learning. (arXiv:2308.12581v1 [cs.LG])

    [http://arxiv.org/abs/2308.12581](http://arxiv.org/abs/2308.12581)

    本文介绍了一种基于Huber损失最小化的新型聚合器用于拜占庭鲁棒的联邦学习。在独立同分布假设下，该方法具有与现有方法相比的优势，并对非i.i.d数据进行了扩展分析。

    

    联邦学习系统容易受到对抗攻击。为了应对这个问题，我们引入了一种基于Huber损失最小化的新型聚合器，并提供了全面的理论分析。在独立同分布（i.i.d）假设下，与现有方法相比，我们的方法具有几个优势。首先，它对于被攻击客户端比率$\epsilon$具有最优的依赖关系。其次，我们的方法不需要对$\epsilon$有精确的知识。第三，它允许不同的客户端具有不均等的数据大小。然后，我们将分析扩展到包括非i.i.d数据，这意味着客户端具有略有不同的分布。

    Federated learning systems are susceptible to adversarial attacks. To combat this, we introduce a novel aggregator based on Huber loss minimization, and provide a comprehensive theoretical analysis. Under independent and identically distributed (i.i.d) assumption, our approach has several advantages compared to existing methods. Firstly, it has optimal dependence on $\epsilon$, which stands for the ratio of attacked clients. Secondly, our approach does not need precise knowledge of $\epsilon$. Thirdly, it allows different clients to have unequal data sizes. We then broaden our analysis to include non-i.i.d data, such that clients have slightly different distributions.
    
[^344]: 因果交叉性和双重梯度下降在多模态分析中的应用：以仇恨迷因为例（arXiv:2308.11585v1 [cs.AI]）

    Causal Intersectionality and Dual Form of Gradient Descent for Multimodal Analysis: a Case Study on Hateful Memes. (arXiv:2308.11585v1 [cs.AI])

    [http://arxiv.org/abs/2308.11585](http://arxiv.org/abs/2308.11585)

    本篇论文探讨了因果交叉性和双重梯度下降在多模态分析中的应用，以仇恨迷因检测为例。通过结合因果分析和基于梯度的方法，研究发现模型的内部机制可以揭示其因果效应，并介绍了交叉性和模态的梯度注意力的摘要化方法。

    

    随着机器学习（ML）的爆炸性增长，特别是在新兴的大语言模型（LLM）的背景下，理解其内部工作中的语义意义至关重要。虽然因果分析侧重于定义语义及其量化，基于梯度的方法是可解释的人工智能（XAI）的核心，用于解释黑盒子的解释。通过协同这些方法，探索模型的内部机制如何阐明其因果效应已成为基于证据的决策的必要条件。一系列并行的研究表明，交叉性--个体的多个人口统计学因素的组合影响--可以以平均处理效应（ATE）的形式进行结构化。最初，本研究阐述了仇恨迷因检测问题可以作为一个ATE来描述，借助交叉性原则，以及基于模态的梯度注意力的摘要化。

    In the wake of the explosive growth of machine learning (ML) usage, particularly within the context of emerging Large Language Models (LLMs), comprehending the semantic significance rooted in their internal workings is crucial. While causal analyses focus on defining semantics and its quantification, the gradient-based approach is central to explainable AI (XAI), tackling the interpretation of the black box. By synergizing these approaches, the exploration of how a model's internal mechanisms illuminate its causal effect has become integral for evidence-based decision-making. A parallel line of research has revealed that intersectionality - the combinatory impact of multiple demographics of an individual - can be structured in the form of an Averaged Treatment Effect (ATE). Initially, this study illustrates that the hateful memes detection problem can be formulated as an ATE, assisted by the principles of intersectionality, and that a modality-wise summarization of gradient-based atten
    
[^345]: 基于大型语言模型的自主代理的调查

    A Survey on Large Language Model based Autonomous Agents. (arXiv:2308.11432v1 [cs.AI])

    [http://arxiv.org/abs/2308.11432](http://arxiv.org/abs/2308.11432)

    该论文综述了基于大型语言模型的自主代理的研究，提供了从整体角度对该领域的系统审查，其创新之处在于利用大量网络知识实现人类水平的智能决策。

    

    自主代理长期以来一直是学术界的研究热点。以往的研究往往集中在对有限知识的代理进行训练，而这与人类的学习过程存在明显差异，因此很难实现人类般的决策。近年来，通过获取大量的网络知识，大型语言模型（LLM）展现出了实现人类水平智能的显著潜力。这引发了对基于LLM的自主代理的研究的高涨兴趣。为了发挥LLM的全部潜力，研究人员设计了各种不同应用的代理体系结构。本论文综述了这些研究，从整体的角度对自主代理领域进行了系统的审查。具体而言，我们的重点是基于LLM的代理构建，为此我们提出了一个统一的框架。

    Autonomous agents have long been a prominent research topic in the academic community. Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from the human learning processes, and thus makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence. This has sparked an upsurge in studies investigating autonomous agents based on LLMs. To harness the full potential of LLMs, researchers have devised diverse agent architectures tailored to different applications. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of autonomous agents from a holistic perspective. More specifically, our focus lies in the construction of LLM-based agents, for which we propose a unified framework t
    
[^346]: 基于图神经网络和规则的归纳知识图谱补全的分析

    Inductive Knowledge Graph Completion with GNNs and Rules: An Analysis. (arXiv:2308.07942v1 [cs.AI])

    [http://arxiv.org/abs/2308.07942](http://arxiv.org/abs/2308.07942)

    基于图神经网络和规则的归纳知识图谱补全研究了基于规则的方法在实践中的表现不佳的原因，发现不合理的实体没有排名和只考虑最具信息量的路径是影响因素。提出了一些解决这些问题的规则方法的变体，发现其性能接近于基于图神经网络的方法NBFNet。这些变体仅使用了NBFNet所依赖的证据的一小部分。

    

    归纳知识图谱补全的任务要求模型从训练图谱中学习推理模式，然后可以用来在分离的测试图谱上进行预测。虽然基于规则的方法似乎很适合这个任务，但在实践中，它们的表现明显不如基于图神经网络（GNNs）的最先进方法，如NBFNet。我们假设基于规则的方法表现不佳是由于两个因素：（i）不合理的实体根本没有排名，（ii）在确定给定链接预测答案的置信度时，只考虑了最具信息量的路径。为了分析这些因素的影响，我们研究了一些针对上述问题的规则方法的变体。我们发现，所得到的模型的性能接近NBFNet。至关重要的是，考虑到的变体只使用了NBFNet所依赖的证据的一小部分。

    The task of inductive knowledge graph completion requires models to learn inference patterns from a training graph, which can then be used to make predictions on a disjoint test graph. Rule-based methods seem like a natural fit for this task, but in practice they significantly underperform state-of-the-art methods based on Graph Neural Networks (GNNs), such as NBFNet. We hypothesise that the underperformance of rule-based methods is due to two factors: (i) implausible entities are not ranked at all and (ii) only the most informative path is taken into account when determining the confidence in a given link prediction answer. To analyse the impact of these factors, we study a number of variants of a rule-based approach, which are specifically aimed at addressing the aforementioned issues. We find that the resulting models can achieve a performance which is close to that of NBFNet. Crucially, the considered variants only use a small fraction of the evidence that NBFNet relies on, which m
    
[^347]: 我们的模型在MovieLens上取得了出色的表现：这意味着什么？

    Our Model Achieves Excellent Performance on MovieLens: What Does it Mean?. (arXiv:2307.09985v1 [cs.IR])

    [http://arxiv.org/abs/2307.09985](http://arxiv.org/abs/2307.09985)

    该论文通过对MovieLens数据集的分析，发现用户与该平台的交互在不同阶段存在显著差异，并且用户交互受到平台推荐算法推荐的候选电影的影响。

    

    推荐系统评估的典型基准数据集是在某一时间段内在平台上生成的用户-物品交互数据。交互生成机制部分解释了为什么用户与物品进行交互（如喜欢、购买、评分）以及特定交互发生的背景。在本研究中，我们对MovieLens数据集进行了细致的分析，并解释了使用该数据集进行评估推荐算法时可能的影响。我们从分析中得出了一些主要发现。首先，在用户与MovieLens平台交互的不同阶段存在显著差异。早期交互在很大程度上定义了用户画像，影响了后续的交互。其次，用户交互受到平台内部推荐算法推荐的候选电影的很大影响。删除靠近最后几次交互的交互会对结果产生较大影响。

    A typical benchmark dataset for recommender system (RecSys) evaluation consists of user-item interactions generated on a platform within a time period. The interaction generation mechanism partially explains why a user interacts with (e.g.,like, purchase, rate) an item, and the context of when a particular interaction happened. In this study, we conduct a meticulous analysis on the MovieLens dataset and explain the potential impact on using the dataset for evaluating recommendation algorithms. We make a few main findings from our analysis. First, there are significant differences in user interactions at the different stages when a user interacts with the MovieLens platform. The early interactions largely define the user portrait which affect the subsequent interactions. Second, user interactions are highly affected by the candidate movies that are recommended by the platform's internal recommendation algorithm(s). Removal of interactions that happen nearer to the last few interactions 
    
[^348]: ODD: 一份基于自然语言处理的药物滥用异常行为检测的基准数据集

    ODD: A Benchmark Dataset for the NLP-based Opioid Related Aberrant Behavior Detection. (arXiv:2307.02591v1 [cs.CL])

    [http://arxiv.org/abs/2307.02591](http://arxiv.org/abs/2307.02591)

    这个研究介绍了一份名为ODD的新型基准数据集，用于通过分析患者的电子健康记录笔记，检测和分类药物滥用异常行为。这个数据集在药物相关病例的自然语言处理研究中具有重要的创新和贡献。

    

    药物滥用异常行为（ORAB）是防止药物过量的新风险因素。以往，ORAB主要通过调查结果和药物给予监测进行评估。然而，这些方法无法扩展，并不能涵盖所有异常行为的范围。然而，ORAB在电子健康记录笔记中广泛有记录。本文介绍了一个名为ODD的新型生物医学自然语言处理基准数据集，用于ORAB检测。ODD是一个专家注释的数据集，包括750多个公开可用的电子健康记录笔记。ODD旨在从患者的电子健康记录笔记中识别ORAB，并将其分类为九个类别：1）已确认异常行为，2）暗示的异常行为，3）阿片类药物，4）适应症，5）已诊断的阿片制剂依赖，6）苯二氮平类药物，7）药物变化，8）与中枢神经系统相关，9）社会健康决定因素。

    Opioid related aberrant behaviors (ORAB) present novel risk factors for opioid overdose. Previously, ORAB have been mainly assessed by survey results and by monitoring drug administrations. Such methods however, cannot scale up and do not cover the entire spectrum of aberrant behaviors. On the other hand, ORAB are widely documented in electronic health record notes. This paper introduces a novel biomedical natural language processing benchmark dataset named ODD, for ORAB Detection Dataset. ODD is an expert-annotated dataset comprising of more than 750 publicly available EHR notes. ODD has been designed to identify ORAB from patients' EHR notes and classify them into nine categories; 1) Confirmed Aberrant Behavior, 2) Suggested Aberrant Behavior, 3) Opioids, 4) Indication, 5) Diagnosed opioid dependency, 6) Benzodiapines, 7) Medication Changes, 8) Central Nervous System-related, and 9) Social Determinants of Health. We explored two state-of-the-art natural language processing (NLP) mode
    
[^349]: 稀疏模型汤：通过模型平均改进修剪的方法

    Sparse Model Soups: A Recipe for Improved Pruning via Model Averaging. (arXiv:2306.16788v1 [cs.LG])

    [http://arxiv.org/abs/2306.16788](http://arxiv.org/abs/2306.16788)

    本研究通过将多个经过迭代幅度剪枝的模型进行平均，解决了同时利用稀疏性和参数平均的问题，并显著提升了泛化性能。

    

    神经网络可以通过剪枝显著压缩，从而得到稀疏模型，这些模型需要更少的存储和浮点运算，同时保持预测性能。模型汤（Wortsman等人，2022年）通过将多个模型的参数平均成一个单一模型来改善泛化和超出分布性能，而不增加推理时间。然而，识别处于相同损失区域的模型以同时利用稀疏性和参数平均是具有挑战性的，因为对任意稀疏模型进行平均会降低整体稀疏度，原因是不同的稀疏连接性。在这项工作中，我们通过展示在迭代幅度剪枝（IMP）的单次重新训练阶段中探索不同的超参数配置（例如批次排序或权重衰减）产生的模型适合进行平均，并且通过设计共享相同的稀疏连接性来解决这些挑战。平均这些模型显著提升了泛化性能。

    Neural networks can be significantly compressed by pruning, leading to sparse models requiring considerably less storage and floating-point operations while maintaining predictive performance. Model soups (Wortsman et al., 2022) improve generalization and out-of-distribution performance by averaging the parameters of multiple models into a single one without increased inference time. However, identifying models in the same loss basin to leverage both sparsity and parameter averaging is challenging, as averaging arbitrary sparse models reduces the overall sparsity due to differing sparse connectivities. In this work, we address these challenges by demonstrating that exploring a single retraining phase of Iterative Magnitude Pruning (IMP) with varying hyperparameter configurations, such as batch ordering or weight decay, produces models that are suitable for averaging and share the same sparse connectivity by design. Averaging these models significantly enhances generalization performanc
    
[^350]: 用于基于检索的对话系统的上下文掩码自编码器

    ConTextual Masked Auto-Encoder for Retrieval-based Dialogue Systems. (arXiv:2306.04357v1 [cs.CL])

    [http://arxiv.org/abs/2306.04357](http://arxiv.org/abs/2306.04357)

    本研究提出了一种针对对话响应选择的后训练技术Dial-MAE，利用生成方法更好地压缩对话语义至密集向量，并提高对话响应选择准确性。

    

    对话响应选择旨在根据给定的用户和系统话语历史记录从几个候选响应中选择适当的响应。最近的研究通过后训练大多依赖于单纯的掩码语言建模方法来提高对话响应选择的准确性。但是，最近开发的生成方法在IR社区展示了有希望的文本表示能力，这可能会导致更好的对话语义建模。因此，在本文中，我们提出 Dial-MAE（对话上下文掩码自编码器），这是一种简单而有效的针对对话响应选择的后训练技术。 Dial-MAE使用一个不对称的编码器-解码器架构，学习将对话的语义更好地压缩到密集向量中。 Dial-MAE的过程包括由深度编码器创建带有掩码对话上下文的对话嵌入，然后是浅解码器，该解码器使用此嵌入以及上下文向量来生成响应。

    Dialogue response selection aims to select an appropriate response from several candidates based on a given user and system utterance history. Recent studies have been improving the accuracy of dialogue response selection through post-training, mostly relying on naive masked language modeling methods. However, the recently developed generative methods have shown promising text representation capabilities in IR community, which could potentially lead to better dialogue semantics modeling. Thus, in this paper, we propose Dial-MAE (Dialogue Contextual Masking Auto-encoder), a straightforward yet effective post-training technique tailored for dialogue response selection. Dial-MAE uses an asymmetric encoder-decoder architecture that learns to better compress the semantics of the dialogue into dialogue-dense vectors. The process of Dial-MAE involves a deep encoder creating a dialogue embedding with the masked dialogue context, followed by a shallow decoder that uses this embedding along with
    
[^351]: 知识工程入门

    A Knowledge Engineering Primer. (arXiv:2305.17196v1 [cs.AI])

    [http://arxiv.org/abs/2305.17196](http://arxiv.org/abs/2305.17196)

    该文介绍了知识工程的基本概念，帮助读者了解该领域并建立直觉。

    

    这篇文章的目的是以简洁而综合的方式介绍知识工程的主题，以培养读者对该领域的直觉。

    The aim of this primer is to introduce the subject of knowledge engineering in a concise but synthetic way to develop the reader's intuition about the area.
    
[^352]: 医疗保健的提示工程:  方法和应用. (arXiv:2304.14670v1 [cs.AI])

    Prompt Engineering for Healthcare: Methodologies and Applications. (arXiv:2304.14670v1 [cs.AI])

    [http://arxiv.org/abs/2304.14670](http://arxiv.org/abs/2304.14670)

    本文介绍了医疗保健NLP领域中的提示工程最新进展，强调其在问答系统、文本摘要和机器翻译等应用中的贡献。本文提供了有用资源和桥梁，以更好地探索提示工程在医疗保健领域的应用。

    

    本文将介绍自然语言处理（NLP）领域内医疗保健提示工程最新的进展。首先，我们将提供一个简要的提示工程发展概述，并强调其对医疗保健NLP应用如问答系统、文本摘要和机器翻译的重要贡献。随着通用大型语言模型的不断改进，提示工程在医疗保健领域的重要性越来越突出。本文的目的是为医疗保健NLP研究人员提供有用的资源和桥梁，更好地探索提示工程在这一领域的应用。我们希望本文可以提供新的思路，激发医疗NLP的研究和应用的充分可能性。

    This review will introduce the latest advances in prompt engineering in the field of natural language processing (NLP) for the medical domain. First, we will provide a brief overview of the development of prompt engineering and emphasize its significant contributions to healthcare NLP applications such as question-answering systems, text summarization, and machine translation. With the continuous improvement of general large language models, the importance of prompt engineering in the healthcare domain is becoming increasingly prominent. The aim of this article is to provide useful resources and bridges for healthcare NLP researchers to better explore the application of prompt engineering in this field. We hope that this review can provide new ideas and inspire ample possibilities for research and application in medical NLP.
    
[^353]: CiPR:一种具有跨实例正关系的高效框架，用于广义类别发现.

    CiPR: An Efficient Framework with Cross-instance Positive Relations for Generalized Category Discovery. (arXiv:2304.06928v1 [cs.CV])

    [http://arxiv.org/abs/2304.06928](http://arxiv.org/abs/2304.06928)

    该论文提出了一个名为CiPR的框架，通过利用部分标记数据中的跨实例正关系进行对比学习，解决了广义类别发现(GCD)的问题。选择邻居聚类(SNC)算法在此过程中发挥了重要作用。

    

    本文解决了广义类别发现（GCD）的问题。GCD考虑了自动聚类部分标记数据集的开放世界问题，在该数据集中，未标记数据包含来自新类别和已标记类别的实例。本文解决了在未标记数据中没有已知类别数的GCD问题。我们提出了一个名为CiPR的框架，通过利用部分标记数据中被现有方法忽视的跨实例正关系进行对比学习来引导表示。为了获得可靠的跨实例关系以促进表示学习，我们首先引入了一种半监督的分层聚类算法，称为选择邻居聚类（SNC），它可以直接从由选择邻居构造的图中的连通分量中生成聚类层次结构。我们还扩展了SNC以便对具有给定类的未标记实例进行标签分配。

    We tackle the issue of generalized category discovery (GCD). GCD considers the open-world problem of automatically clustering a partially labelled dataset, in which the unlabelled data contain instances from novel categories and also the labelled classes. In this paper, we address the GCD problem without a known category number in the unlabelled data. We propose a framework, named CiPR, to bootstrap the representation by exploiting Cross-instance Positive Relations for contrastive learning in the partially labelled data which are neglected in existing methods. First, to obtain reliable cross-instance relations to facilitate the representation learning, we introduce a semi-supervised hierarchical clustering algorithm, named selective neighbor clustering (SNC), which can produce a clustering hierarchy directly from the connected components in the graph constructed by selective neighbors. We also extend SNC to be capable of label assignment for the unlabelled instances with the given clas
    
[^354]: FrankenSplit:基于显著性指导的神经特征压缩与浅层变分瓶颈注入

    FrankenSplit: Saliency Guided Neural Feature Compression with Shallow Variational Bottleneck Injection. (arXiv:2302.10681v2 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2302.10681](http://arxiv.org/abs/2302.10681)

    本文提出了一种基于显著性指导的神经特征压缩与浅层变分瓶颈注入的新的资源意识压缩模型的框架，实现了比最先进的SC方法低60％的比特率，并且比现有的编解码标准的下放快16倍。

    

    移动AI加速器的崛起使得对延迟敏感的应用可以在客户端上执行轻量级深度神经网络（DNN）。然而，需要强大模型的关键应用程序需要将请求下放，而高维数据将争夺有限的带宽。本文提出了一种新的资源意识压缩模型的框架并在反映边缘设备和服务器之间不对称资源分配的环境中进行了广泛评估。我们的方法在不降低准确性的情况下实现了比最先进的SC方法低60％的比特率，并且比现有的编解码标准的下放快16倍。

    The rise of mobile AI accelerators allows latency-sensitive applications to execute lightweight Deep Neural Networks (DNNs) on the client side. However, critical applications require powerful models that edge devices cannot host and must therefore offload requests, where the high-dimensional data will compete for limited bandwidth. This work proposes shifting away from focusing on executing shallow layers of partitioned DNNs. Instead, it advocates concentrating the local resources on variational compression optimized for machine interpretability. We introduce a novel framework for resource-conscious compression models and extensively evaluate our method in an environment reflecting the asymmetric resource distribution between edge devices and servers. Our method achieves 60\% lower bitrate than a state-of-the-art SC method without decreasing accuracy and is up to 16x faster than offloading with existing codec standards.
    
[^355]: Box$^2$EL: EL++描述逻辑中的概念和角色盒子嵌入的概念和角色盒子嵌入方法及其作用

    Box$^2$EL: Concept and Role Box Embeddings for the Description Logic EL++. (arXiv:2301.11118v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.11118](http://arxiv.org/abs/2301.11118)

    Box$^2$EL方法通过将概念和角色表示为盒子，克服了传统方法中角色表示受限的问题，并在实验中取得了领先的结果。

    

    描述逻辑本体论扩展了知识图谱与概念信息和逻辑背景知识。近年来，人们对这种本体论的归纳推理技术越来越感兴趣，这些技术有望补充传统的演绎推理算法。类似于知识图谱的完善，现有的一些方法通过在潜在空间中学习本体论嵌入，同时确保这些嵌入能够准确地捕捉到底层描述逻辑的逻辑语义。然而，它们存在一些问题，主要是由于受限的角色表示。我们提出了Box$^2$EL方法，将概念和角色都表示为盒子（即轴对齐超矩形），并展示了它如何克服之前方法的局限性。我们在理论上证明了我们模型的正确性，并进行了大量的实验评估，在各种数据集上取得了领先的结果。作为我们评估的一部分，我们引入了一个新的基准。

    Description logic (DL) ontologies extend knowledge graphs (KGs) with conceptual information and logical background knowledge. In recent years, there has been growing interest in inductive reasoning techniques for such ontologies, which promise to complement classical deductive reasoning algorithms. Similar to KG completion, several existing approaches learn ontology embeddings in a latent space, while additionally ensuring that they faithfully capture the logical semantics of the underlying DL. However, they suffer from several shortcomings, mainly due to a limiting role representation. We propose Box$^2$EL, which represents both concepts and roles as boxes (i.e., axis-aligned hyperrectangles) and demonstrate how it overcomes the limitations of previous methods. We theoretically prove the soundness of our model and conduct an extensive experimental evaluation, achieving state-of-the-art results across a variety of datasets. As part of our evaluation, we introduce a novel benchmark for 
    
[^356]: EVOTER：透明可解释规则集的进化

    EVOTER: Evolution of Transparent Explainable Rule-sets. (arXiv:2204.10438v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2204.10438](http://arxiv.org/abs/2204.10438)

    EVOTER使用简单的逻辑表达式演化出透明可解释的规则集，与黑盒模型性能相似，可以揭示数据中的偏见并为未来构建可靠的AI系统提供基础。

    

    大多数AI系统是黑盒子，为给定的输入生成合理的输出。然而，某些领域具有解释能力和信任度要求，这些要求不能直接满足这些方法。因此，该论文提出了一种替代方法，即开始时模型就是透明的和可解释的。该方法使用简单的逻辑表达式演化出规则集，称为EVOTER。EVOTER在多个预测/分类和处方/政策搜索领域进行了评估，有和没有代理。结果显示，它能够发现和黑盒模型相似的有意义的规则集。这些规则可以提供领域的见解，并使数据中隐藏的偏见显性化。也可以直接对它们进行编辑，以消除偏见并添加约束。因此，EVOTER为未来构建值得信赖的AI系统的可靠基础。

    Most AI systems are black boxes generating reasonable outputs for given inputs. Some domains, however, have explainability and trustworthiness requirements that cannot be directly met by these approaches. Various methods have therefore been developed to interpret black-box models after training. This paper advocates an alternative approach where the models are transparent and explainable to begin with. This approach, EVOTER, evolves rule-sets based on simple logical expressions. The approach is evaluated in several prediction/classification and prescription/policy search domains with and without a surrogate. It is shown to discover meaningful rule sets that perform similarly to black-box models. The rules can provide insight into the domain, and make biases hidden in the data explicit. It may also be possible to edit them directly to remove biases and add constraints. EVOTER thus forms a promising foundation for building trustworthy AI systems for real-world applications in the future.
    

