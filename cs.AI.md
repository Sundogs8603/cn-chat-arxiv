# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Computer Assisted Proofs and Automated Methods in Mathematics Education.](http://arxiv.org/abs/2303.10166) | 本研究探讨了计算辅助证明和自动化方法在数学和STEAM教育中的应用，强调了探索-发现-猜想-证明方案与21世纪教育的关系，并提出了机器与人之间的交流与批判性思维的重要性。 |
| [^2] | [Data-centric Artificial Intelligence: A Survey.](http://arxiv.org/abs/2303.10158) | 本文讨论了数据中心人工智能的必要性并从三个一般性数据中心目标和代表性方法的全面视角进行了介绍。该综述从自动化和协作的角度组织了现有文献并讨论了挑战。 |
| [^3] | [Hybrid Classic-Quantum Computing for Staging of Invasive Ductal Carcinoma of Breast.](http://arxiv.org/abs/2303.10142) | 本文介绍了应用混合经典-量子计算模型进行乳腺癌分期的方法，并且相比于传统经典模型，具有出色的表现。 |
| [^4] | [Distill n' Explain: explaining graph neural networks using simple surrogates.](http://arxiv.org/abs/2303.10139) | 本文提出了Distill n' Explain (DnX)方法，通过知识蒸馏学习简单的替代模型，并通过解决简单的凸规划提取节点或边级别的解释，从而解释图神经网络（GNN）。实验结果显示，DnX和FastDnX通常优于最先进的GNN解释器，并且运行速度快得多。 |
| [^5] | [Generate, Transform, Answer: Question Specific Tool Synthesis for Tabular Data.](http://arxiv.org/abs/2303.10138) | 本文提出了一种名为ToolWriter的工具，用于生成查询特定的程序并将其应用于转换表格，以提高表格问答（TQA）的性能。这个工具通过生成行过滤工具，改进了WikiTableQuestions和WikiSQL的最新技术。随着表格尺寸的增加，传统的语言模型在处理表格的过程中存在信息丢失的问题，我们通过利用程序化工具与神经组件相结合的方法来解决这个问题，并展示了这种方法的广泛潜力。 |
| [^6] | [She Elicits Requirements and He Tests: Software Engineering Gender Bias in Large Language Models.](http://arxiv.org/abs/2303.10131) | 本研究使用数据挖掘技术调查了56项与软件开发相关的任务，发现性别代词与不同任务的相关性明显不同。其中，只有6%的需求收集任务与代词“他”相关联，而测试任务则在100%的情况下与“他”相关联。此外，帮助他人的任务有91%的相关性与“他”相关联。 |
| [^7] | [GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models.](http://arxiv.org/abs/2303.10130) | 该研究调查了GPT（大语言模型）和相关技术对美国劳动力市场的潜在影响，发现大约80%的美国劳动力可能会受到10%的工作任务的影响，涵盖了所有工资水平和各行各业，预示着这些模型可能具有显著的经济、社会和政策影响。 |
| [^8] | [$\textit{Clingraph}$: A System for ASP-based Visualization.](http://arxiv.org/abs/2303.10118) | Clingraph是一款ASP可视化系统，使用ASP事实的图形规范传递给图形系统，提供了极好的接口，且具有Python API，可连接和监视求解过程的各个方面。 |
| [^9] | [A multidomain relational framework to guide institutional AI research and adoption.](http://arxiv.org/abs/2303.10106) | 该论文提出一个多元关系框架来指导机构人工智能的研究和采纳，解决社会技术话语中的关系问题，包括语义模糊、概念之间缺乏明确的关系和不同的标准术语，帮助评估机构AI系统，避免概念孤立。 |
| [^10] | [Enhancing the Role of Context in Region-Word Alignment for Object Detection.](http://arxiv.org/abs/2303.10093) | 本研究提出了一种增强上下文在目标检测区域-词对齐中作用的方法，通过特定的负采样方法提高了属性的作用，从而提高了目标检测的效果。 |
| [^11] | [Hierarchical-Hyperplane Kernels for Actively Learning Gaussian Process Models of Nonstationary Systems.](http://arxiv.org/abs/2303.10022) | 本文提出了一种层次-超平面核函数族，能够在高斯过程模型积极学习中使用，以建模非平稳性和非线性特性。 |
| [^12] | [Improving Data Transfer Efficiency for AIs in the DareFightingICE using gRPC.](http://arxiv.org/abs/2303.10001) | 本文介绍了一种新的通信接口gRPC，以改善DareFightingICE中AI数据传输的效率，减少游戏服务器信息接收所花费的时间。在实现控制非玩家角色的AI的应用中，该方法十分有效。 |
| [^13] | [Stochastic Submodular Maximization via Polynomial Estimators.](http://arxiv.org/abs/2303.09960) | 本文研究了随机子模最大化问题，特别是通过使用多项式估算器实现了随机连续贪心算法的 $(1-1/e) \approx 63\%$ 的近似比效果，同时显著降低了执行时间。 |
| [^14] | [GNNFormer: A Graph-based Framework for Cytopathology Report Generation.](http://arxiv.org/abs/2303.09956) | 提出了一种名为GNNFormer的图神经网络和Transformer结合的基于图的框架，用于细胞病理学报告生成，这是第一个明确对病理图像中的细胞之间的结构信息进行建模的报告生成方法，并在语言生成指标和诊断准确度方面表现优异。 |
| [^15] | [mCPT at SemEval-2023 Task 3: Multilingual Label-Aware Contrastive Pre-Training of Transformers for Few- and Zero-shot Framing Detection.](http://arxiv.org/abs/2303.09901) | 本研究提出了mCPT模型用于多语言的、多标签的零样本或少样本的框架检测任务，并在西班牙语和其他8种语言中取得了良好的成绩。该方案采用了基于多语言变压器的预训练程序，使用标签感知对比损失函数。 |
| [^16] | [Exploiting Semantic Attributes for Transductive Zero-Shot Learning.](http://arxiv.org/abs/2303.09849) | 该论文提出了一种新的转导式零样本学习方法，该方法生成未知数据的语义属性，并将它们导入到生成过程中，以解决现有方法无法生成高保真度的属性一致的未知特征的问题。 |
| [^17] | [DUDES: Deep Uncertainty Distillation using Ensembles for Semantic Segmentation.](http://arxiv.org/abs/2303.09843) | 本文提出了一种名为 DUDES 的新方法，通过集成学习和知识蒸馏技术，准确地估算预测的不确定性，同时具有高效性和适应性。实验结果表明，DUDES 能够准确地捕获预测的不确定性，并在不牺牲分割任务性能的前提下，具有检测错误分类实例和检测分布之外样本的出色能力。 |
| [^18] | [DORIC : Domain Robust Fine-Tuning for Open Intent Clustering through Dependency Parsing.](http://arxiv.org/abs/2303.09827) | 该论文提出了一种名为DORIC的方法，通过利用多领域对话数据集进行微调，提取动词-宾语对以达到消除不必要信息的目的，最终实现了在各种领域数据集上的高精度聚类。 |
| [^19] | [Path Planning for Autonomous Driving: The State of the Art and Perspectives.](http://arxiv.org/abs/2303.09824) | 本文综述了现有的自动驾驶路径规划方法，包括管道规划和端到端规划方法。在挑战和潜在解决方案方面提供了讨论，有助于为智能汽车的发展提供更好的规划方法。 |
| [^20] | [Transformers and Ensemble methods: A solution for Hate Speech Detection in Arabic languages.](http://arxiv.org/abs/2303.09823) | 本文提出了一种使用Transformer和Ensemble方法的解决方案，用于阿语恶意言论的检测。实验结果表明，基于多数表决的集成方法具有最佳效果，其在测试集上的准确率为0.86，F1分数为0.60。 |
| [^21] | [DiffusionSeg: Adapting Diffusion Towards Unsupervised Object Discovery.](http://arxiv.org/abs/2303.09813) | 本文提出了一种新的框架DiffusionSeg，利用扩散模型解决了无监督目标发现任务中的判别性问题，包含两个阶段的策略，通过合成大量图像和Pixelwise回归来解决标记数据不足和生成、判别模型结构不同的问题。在基准测试中表现出最先进的性能。 |
| [^22] | [TKN: Transformer-based Keypoint Prediction Network For Real-time Video Prediction.](http://arxiv.org/abs/2303.09807) | TKN是一种基于Transformer的实时视频预测解决方案，通过受限信息提取和并行预测方案来提升预测过程的速度，具有更高的精度和更低的计算成本。 |
| [^23] | [Urban Regional Function Guided Traffic Flow Prediction.](http://arxiv.org/abs/2303.09789) | 本文提出了一个名为POI-MetaBlock的新模块，结合区域的功能性和交通特征，采用自注意力架构进行交通流预测。 |
| [^24] | [SE-GSL: A General and Effective Graph Structure Learning Framework through Structural Entropy Optimization.](http://arxiv.org/abs/2303.09778) | 本论文提出了一个通用且有效的图结构学习框架SE-GSL，通过利用结构熵和编码树中的层次结构来最大化嵌入信息内容，同时提出了一个声慢构建最优编码树的方案。该框架还提出了一个新颖的基于样本的机制，通过节点结构熵分布来恢复图结构。 |
| [^25] | [Understanding Frontline Workers' and Unhoused Individuals' Perspectives on AI Used in Homeless Services.](http://arxiv.org/abs/2303.09743) | 研究了受影响的利益相关方对于优先考虑有限住房资源的 AI 决策支持系统的看法，发现相关利益相关方可提供具体和关键性的反馈，即使他们没有 AI 知识。 |
| [^26] | [Dynamic Structure Pruning for Compressing CNNs.](http://arxiv.org/abs/2303.09736) | 本文介绍了一种新的动态结构剪枝方法，它可以自动优化每层内通道剪枝的最优粒度，从而更加紧凑和高效。 |
| [^27] | [Exorcising ''Wraith'': Protecting LiDAR-based Object Detector in Automated Driving System from Appearing Attacks.](http://arxiv.org/abs/2303.09731) | 本文提出了一种新的防御模块，用于保护自动驾驶系统中基于LiDAR的物体检测器免遭出现攻击。该模块根据局部部分的物体性低下来消除伪造的障碍物，并通过变体连体网络进行识别。在基准测试中，平均点对点F1分数为96.2％。 |
| [^28] | [A New Policy Iteration Algorithm For Reinforcement Learning in Zero-Sum Markov Games.](http://arxiv.org/abs/2303.09716) | 本文提出了一种适用于零和马尔可夫博弈的简单但有效的策略迭代算法。 |
| [^29] | [Delayed and Indirect Impacts of Link Recommendations.](http://arxiv.org/abs/2303.09700) | 本研究研究了链接推荐在动态环境中对社交网络演化的影响，并发现推荐链接有令人惊讶的延迟和间接影响。 |
| [^30] | [DiGeo: Discriminative Geometry-Aware Learning for Generalized Few-Shot Object Detection.](http://arxiv.org/abs/2303.09674) | 本文提出了一种新的训练框架 DiGeo，学习几何感知特征来实现跨类别间的分离和类内紧密性。通过引导特征聚类的分离，采用自适应的类特定间距，本文方法有效提升了广义少样本目标检测的性能。 |
| [^31] | [Tribe or Not? Critical Inspection of Group Differences Using TribalGram.](http://arxiv.org/abs/2303.09664) | 本文提出了一组负责任的群体分析设计指南，并通过开发TribalGram工具使用可解释的机器学习算法和可视化来对群体分析进行推断评估、模型解释、数据协作和理解，以增强对分析群体的深刻理解，并防止因刻板印象和过度概括导致的潜在危害。 |
| [^32] | [ESCAPE: Countering Systematic Errors from Machine's Blind Spots via Interactive Visual Analysis.](http://arxiv.org/abs/2303.09657) | 本论文提出了ESCAPE，一个交互式视觉分析系统，利用人机交互帮助用户发现并修正机器学习中的系统误差。 |
| [^33] | [Online Reinforcement Learning in Periodic MDP.](http://arxiv.org/abs/2303.09629) | 本文提出了用于解决周期性MDP中强化学习问题的四种算法，其中包括PUCRL2，PUCRLB，U-PUCRL2和U-PUCRLB。PUCRLB表现更好，且其遗憾随周期$N$的变化为$O(\sqrt{N})$。 |
| [^34] | [HIVE: Harnessing Human Feedback for Instructional Visual Editing.](http://arxiv.org/abs/2303.09618) | 本文提出了一种新的框架，利用人类反馈进行指导性视觉编辑。通过收集被编辑图像的人类反馈，并学习奖励函数捕捉用户的偏好，可以缓解数据限制所带来的偏差，并提高模型性能。 |
| [^35] | [Measuring Improvement of F$_1$-Scores in Detection of Self-Admitted Technical Debt.](http://arxiv.org/abs/2303.09617) | 本研究提出了一种利用BERT架构改进SATD检测的方法，在跨项目情况下表现优于所有先前方法的最佳表现。 |
| [^36] | [Psychotherapy AI Companion with Reinforcement Learning Recommendations and Interpretable Policy Dynamics.](http://arxiv.org/abs/2303.09601) | 本文介绍了一种使用强化学习生成心理治疗主题推荐的AI伴侣，能够很好地捕获真实数据，并通过可解释的策略轨迹可视化提供对不同奖励信号和不同临床诊断下训练的策略的独特模式。 |
| [^37] | [Residual Physics Learning and System Identification for Sim-to-real Transfer of Policies on Buoyancy Assisted Legged Robots.](http://arxiv.org/abs/2303.09597) | 本文利用残差物理学习方法和系统识别，在轻量化、柔软机器人BALLU上实现了从模拟到真实世界的稳健控制转移。通过使用强化学习训练外部力策略以匹配真实世界轨迹，建模残差物理学，提高了仿真精度。 |
| [^38] | [Protecting Society from AI Misuse: When are Restrictions on Capabilities Warranted?.](http://arxiv.org/abs/2303.09377) | 随着人工智能系统能力不断提升，控制某些能力将有助于防止其滥用，这些限制可能包括控制访问、使用目的、输出与溯源以及开发资源，非AI能力限制也是必要的。尽管可能会降低使用率而增加滥用风险，但这些限制是当其他干预行不通、潜在危害性高、有有针对性方式干预时所必要的。 |
| [^39] | [Towards Robust Bangla Complex Named Entity Recognition.](http://arxiv.org/abs/2303.09306) | 本研究构建了基于 CRF 和深度学习（如 BanglaBERT）的鲁棒孟加拉复杂命名实体识别模型，解决了 CNER 任务，填补了孟加拉语复杂命名实体识别领域的空白。 |
| [^40] | [Maximum Margin Learning of t-SPNs for Cell Classification with Filtering.](http://arxiv.org/abs/2303.09065) | 本研究提出了一种基于t-SPN算法和滤波技术的细胞分类方法，通过最大化边缘和L2正则化，该方法在HEp-2和Feulgen基准数据集上取得了最高的准确率。 |
| [^41] | [Commonsense Knowledge Assisted Deep Learning for Resource-constrained and Fine-grained Object Detection.](http://arxiv.org/abs/2303.09026) | 本文提出了一种通识知识辅助的细粒度目标检测方法，利用通识知识推理模块处理由基准深度学习检测器给出的粗粒度标签，从而提高目标检测的准确性。经过实验验证，该方法相比于现有方法需要更少的计算量和标注资源。 |
| [^42] | [KGNv2: Separating Scale and Pose Prediction for Keypoint-based 6-DoF Grasp Synthesis on RGB-D input.](http://arxiv.org/abs/2303.05617) | 本文提出了一种基于关键点的RGB-D输入的六自由度抓取姿态合成方法，既可以从关键点检测中预测抓取姿态，也可以预测相对于相机的尺度，实验结果表明其优越性。 |
| [^43] | [Guiding Pseudo-labels with Uncertainty Estimation for Source-free Unsupervised Domain Adaptation.](http://arxiv.org/abs/2303.03770) | 本研究提出一种基于损失重新加权策略的无源自适应域自适应（SF-UDA）方法，用于适应目标域，其关键是通过估计伪标签的不确定性来指导其进一步精化，并利用自监督对比框架作为目标空间的正则化器以提高预测精度。 |
| [^44] | [Scalable Object Detection on Embedded Devices Using Weight Pruning and Singular Value Decomposition.](http://arxiv.org/abs/2303.02735) | 本文提出了一种利用权重修剪和奇异值分解来优化物体检测模型的方法，并在自定义数据集上进行了评估，结果表明此方法可以在平衡准确性、速度和模型大小过程中有效地优化物体检测模型性能。 |
| [^45] | [Compensating for Sensing Failures via Delegation in Human-AI Hybrid Systems.](http://arxiv.org/abs/2303.01300) | 本文探讨了人工智能与人类混合系统中的感知失败问题，提出了通过委派管理代理来选择人类或自主系统控制，以补偿可能发生的感知缺失，保障系统安全的方法。 |
| [^46] | [Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision.](http://arxiv.org/abs/2303.00462) | 本研究提出了一种使用跨模态监督学习的新方法，用于精确地估计4D雷达场景流，并在运动分割和自我运动估计等子任务中显示了其实用性。 |
| [^47] | [Eagle: Large-Scale Learning of Turbulent Fluid Dynamics with Mesh Transformers.](http://arxiv.org/abs/2302.10803) | EAGLE引入了大规模数据集和新模型，其中包括一种新的网格变换器，能够预测具有挑战性的流体动力学数据集中的压力和速度变化。 |
| [^48] | [Sources of Richness and Ineffability for Phenomenally Conscious States.](http://arxiv.org/abs/2302.06403) | 本文提供了一个信息论动力系统的视角，来解释意识的丰富性和难以言说性。在我们的框架中，意识体验的丰富性对应于意识状态中的信息量，而难以言说性则对应于不同处理阶段丢失的信息量。 |
| [^49] | [LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease Assessment from Fundus Images.](http://arxiv.org/abs/2302.03008) | LAVA是一个基于颗粒化神经元级别可解释性的 AI 框架，可以直接从静脉荧光成像中评估阿尔茨海默病的进程，验证视网膜血管系统为 AD 评估的生物标志物和诊断手段。 |
| [^50] | [A Pre-training Framework for Knowledge Graph Completion.](http://arxiv.org/abs/2302.02614) | 本研究提出了一个基于网络的预训练框架NetPeace，能够在知识图谱补全任务中获得显著提升，尤其是在稠密的知识图上表现更好。 |
| [^51] | [Greedy Ordering of Layer Weight Matrices in Transformers Improves Translation.](http://arxiv.org/abs/2302.02123) | 本论文提出了一种基于贪婪重排权重矩阵的算法AEIUOrder，能够最大化总的经过充分训练的层所贡献的"well-trainedness"指标进行优化，从而提高翻译质量并在各种翻译任务上达到最佳性能。 |
| [^52] | [Matching Exemplar as Next Sentence Prediction (MeNSP): Zero-shot Prompt Learning for Automatic Scoring in Science Education.](http://arxiv.org/abs/2301.08771) | 本研究提出了一种零样本学习自动评分的方法，利用预训练的语言模型配合匹配标本作为下一句预测技术，成功应用于科学教育领域的论证任务，极大地减少了训练成本和时间。 |
| [^53] | [SIRL: Similarity-based Implicit Representation Learning.](http://arxiv.org/abs/2301.00810) | SIRL是基于人提供相似度判断的任务表示学习方法，能够帮助机器人识别和隔离因果特征并生成适当行为，在各种机器人任务上表现优秀。 |
| [^54] | [Learning to Select Prototypical Parts for Interpretable Sequential Data Modeling.](http://arxiv.org/abs/2212.03396) | 提出了一种自解释选择模型，使用典型的概念的线性组合来解释其自身的预测，通过选择大部分激活不同概念的子序列作为典型部分来解释模型决策，为了更好的解释性，还设计了多个约束条件。 |
| [^55] | [Analysis of Utterance Embeddings and Clustering Methods Related to Intent Induction for Task-Oriented Dialogue.](http://arxiv.org/abs/2212.02021) | 本文旨在研究任务导向对话中的意图识别问题，并提出两个关键因素：聚类算法和用户话语嵌入空间。实验证明，利用预训练的MiniLM与层次聚类相结合可以显著提高意图归纳任务的效果。 |
| [^56] | [Representations of Domains via CF-approximation Spaces.](http://arxiv.org/abs/2211.17099) | 本文研究了通过CF-逼近空间的表示领域，介绍了CF-逼近空间和CF闭集的概念，并且证明了CF-逼近空间中的CF闭集族是连续领域，使用范畴论的方法，证明了CF-逼近空间和CF-可逼近关系的范畴与连续领域和Scott连续映射的范畴等同。 |
| [^57] | [An Interpretable Machine Learning System to Identify EEG Patterns on the Ictal-Interictal-Injury Continuum.](http://arxiv.org/abs/2211.05207) | 该论文设计了一种可解释的深度学习模型，以预测ICU脑电监测中常见的6种脑波图案的存在，并提供高质量的解释和三种解释方法，这对于建立AI的信任和临床采用至关重要。 |
| [^58] | [Liability regimes in the age of AI: a use-case driven analysis of the burden of proof.](http://arxiv.org/abs/2211.01817) | 本文通过用例分析探讨了基于AI技术的责任制度下证明负担的挑战和规则改革的建议。 |
| [^59] | [Observable Perfect Equilibrium.](http://arxiv.org/abs/2210.16506) | 本文提出一种新的博弈均衡概念——可观测完美均衡，在顺序不完全信息博弈中可以帮助创建真正的策略代理。这种均衡概念在公开观察的行动概率方面具有鲁棒性。 |
| [^60] | [TabLLM: Few-shot Classification of Tabular Data with Large Language Models.](http://arxiv.org/abs/2210.10723) | 本文应用大语言模型将表格数据序列化为自然语言字符串进行分类，微调后即可在非常少的样本设置下与传统基线方法竞争力十足。 |
| [^61] | [Mine yOur owN Anatomy: Revisiting Medical Image Segmentation with Extremely Limited Labels.](http://arxiv.org/abs/2209.13476) | 提出了一种新的医学图像分割方法MOAN，该方法可以在极度有限的标签情况下实现高性能。MOAN由两个互补的流水线组成：协同邻域挖掘和自监督对比学习。实验结果表明，MOAN在Dice评分和其他评估指标方面优于现有最先进方法。 |
| [^62] | [Learning Relational Causal Models with Cycles through Relational Acyclification.](http://arxiv.org/abs/2208.12210) | 本文通过引入关系无环化的算法，能够处理循环关系的因果模型，从而学习复杂动态系统。 |
| [^63] | [Temporal Attention Unit: Towards Efficient Spatiotemporal Predictive Learning.](http://arxiv.org/abs/2206.12126) | 本研究提出了时间注意力单元（TAU）以提高时空预测学习的计算效率，将时间注意力分解为帧内静态注意力和帧间动态注意力。同时引入差分离散正则化方法来考虑帧间变化，大量实验表明该方法能够高效地进行预测学习。 |
| [^64] | [Partition-Based Active Learning for Graph Neural Networks.](http://arxiv.org/abs/2201.09391) | 本文提出了一种基于分区的图神经网络主动学习方法GraphPart，该方法在不引入额外超参数的情况下，在多个基准数据集上显著优于现有主动学习方法，并且在不同的注释预算约束下性能稳定。 |
| [^65] | [Over-Fit: Noisy-Label Detection based on the Overfitted Model Property.](http://arxiv.org/abs/2106.07217) | 本文提出一种基于模型过拟合特性的后训练学习方法，能够识别错误标记的样本，并逐步删除对决策边界有较高影响的样本，从而提高模型的泛化性能。 |

# 详细

[^1]: 计算辅助证明与数学教育中的自动化方法

    Computer Assisted Proofs and Automated Methods in Mathematics Education. (arXiv:2303.10166v1 [math.HO])

    [http://arxiv.org/abs/2303.10166](http://arxiv.org/abs/2303.10166)

    本研究探讨了计算辅助证明和自动化方法在数学和STEAM教育中的应用，强调了探索-发现-猜想-证明方案与21世纪教育的关系，并提出了机器与人之间的交流与批判性思维的重要性。

    

    本调查论文是 ThEdu'22 研讨会的特邀主题演讲的扩展版本，于 2022 年 8 月在以色列海法举行。在简要介绍计算机代数系统、动态几何软件和其他有用技术的发展后，我们展示了其在数学教育和更广泛的 STEAM 教育框架中的影响。特别地，我们讨论了将数学教育转化为探索-发现-猜想-证明的方案，避免使用成为一个黑盒子。这种方案很好地符合 21 世纪教育所称的 4C，即创新、协作、批判性思维和沟通。强调了人与人、机器与机器、人与机器之间的交流与协作。对于输出的特定特征加强了批判性思维的需求。我们讨论了利用自动化命令进行探索和发现的方式，并提及其存在的局限性。我们用参数积分（描述数学概念的“认知领域”）、平面几何（引入自动化证明的“猜想不变量”概念）和代数操作的例子说明了这个主题。

    This survey paper is an expanded version of an invited keynote at the ThEdu'22 workshop, August 2022, in Haifa (Israel). After a short introduction on the developments of CAS, DGS and other useful technologies, we show implications in Mathematics Education, and in the broader frame of STEAM Education. In particular, we discuss the transformation of Mathematics Education into exploration-discovery-conjecture-proof scheme, avoiding usage as a black box . This scheme fits well into the so-called 4 C's of 21st Century Education. Communication and Collaboration are emphasized not only between humans, but also between machines, and between man and machine. Specific characteristics of the outputs enhance the need of Critical Thinking. The usage of automated commands for exploration and discovery is discussed, with mention of limitations where they exist. We illustrate the topic with examples from parametric integrals (describing a "cognitive neighborhood" of a mathematical notion), plane geom
    
[^2]: 数据中心人工智能综述：一份调查报告。

    Data-centric Artificial Intelligence: A Survey. (arXiv:2303.10158v1 [cs.LG])

    [http://arxiv.org/abs/2303.10158](http://arxiv.org/abs/2303.10158)

    本文讨论了数据中心人工智能的必要性并从三个一般性数据中心目标和代表性方法的全面视角进行了介绍。该综述从自动化和协作的角度组织了现有文献并讨论了挑战。

    

    人工智能（AI）正在几乎所有领域产生深远的影响，其成功的关键之一是可用于构建机器学习模型的丰富高质量数据。最近，数据在AI中的作用得到了显著放大，引发了数据中心AI这一新兴概念的出现。研究人员和从业者的注意力逐渐从推进模型设计转向提高数据质量和数量。在本调查中，我们讨论了数据中心AI的必要性，随后从训练数据开发、推理数据开发和数据维护三个一般性数据中心目标以及代表性方法的全面视角进行了介绍。我们还从自动化和协作的角度组织了现有文献，讨论了挑战，并列出了各种任务的测试基准。我们认为，这是第一份提供跨越各个阶段一系列任务的全球视角的综合性调查。

    Artificial Intelligence (AI) is making a profound impact in almost every domain. A vital enabler of its great success is the availability of abundant and high-quality data for building machine learning models. Recently, the role of data in AI has been significantly magnified, giving rise to the emerging concept of data-centric AI. The attention of researchers and practitioners has gradually shifted from advancing model design to enhancing the quality and quantity of the data. In this survey, we discuss the necessity of data-centric AI, followed by a holistic view of three general data-centric goals (training data development, inference data development, and data maintenance) and the representative methods. We also organize the existing literature from automation and collaboration perspectives, discuss the challenges, and tabulate the benchmarks for various tasks. We believe this is the first comprehensive survey that provides a global view of a spectrum of tasks across various stages o
    
[^3]: 混合经典-量子计算在乳腺浸润性导管癌分期中的应用研究

    Hybrid Classic-Quantum Computing for Staging of Invasive Ductal Carcinoma of Breast. (arXiv:2303.10142v1 [cs.AI])

    [http://arxiv.org/abs/2303.10142](http://arxiv.org/abs/2303.10142)

    本文介绍了应用混合经典-量子计算模型进行乳腺癌分期的方法，并且相比于传统经典模型，具有出色的表现。

    

    尽管人工智能具有极大的现实意义，并且这门学科为许多领域带来了非凡的创新，其中当然包括医学，但是在医学应用人工智能的专家正在寻求解决现有人工智能方案无法提供最佳解决方案的问题的新途径。因此，一种有前途的选择可能是使用量子力学的概念和思想构建基于量子的人工智能系统。本文从混合经典-量子的角度出发，论述了量子计算技术在乳腺浸润性导管癌分期中的应用。

    Despite the great current relevance of Artificial Intelligence, and the extraordinary innovations that this discipline has brought to many fields -among which, without a doubt, medicine is found-, experts in medical applications of Artificial Intelligence are looking for new alternatives to solve problems for which current Artificial Intelligence programs do not provide with optimal solutions. For this, one promising option could be the use of the concepts and ideas of Quantum Mechanics, for the construction of quantum-based Artificial Intelligence systems. From a hybrid classical-quantum perspective, this article deals with the application of quantum computing techniques for the staging of Invasive Ductal Carcinoma of the breast. It includes: (1) a general explanation of a classical, and well-established, approach for medical reasoning, (2) a description of the clinical problem, (3) a conceptual model for staging invasive ductal carcinoma, (4) some basic notions about Quantum Rule-Bas
    
[^4]: Distill n' Explain：使用简单替代模型解释图神经网络

    Distill n' Explain: explaining graph neural networks using simple surrogates. (arXiv:2303.10139v1 [cs.LG])

    [http://arxiv.org/abs/2303.10139](http://arxiv.org/abs/2303.10139)

    本文提出了Distill n' Explain (DnX)方法，通过知识蒸馏学习简单的替代模型，并通过解决简单的凸规划提取节点或边级别的解释，从而解释图神经网络（GNN）。实验结果显示，DnX和FastDnX通常优于最先进的GNN解释器，并且运行速度快得多。

    

    解释图神经网络中节点预测的方法通常是找到保持预测的图子结构。这通常意味着反向传播由于GNN的复杂性（例如，层数）而导致解释的成本上升。因此，作者提出了Distill n' Explain (DnX)方法。首先，DnX通过知识蒸馏来学习替代的GNN。然后，DnX通过解决简单的凸规划来提取节点或边级别的解释。同时，作者还提出了FastDnX，这是DnX的更快版本，它利用了我们替代模型的线性分解。实验表明，DnX和FastDnX通常优于最先进的GNN解释器，并且运行速度快得多。此外，我们还通过理论结果支持了我们的实验发现。

    Explaining node predictions in graph neural networks (GNNs) often boils down to finding graph substructures that preserve predictions. Finding these structures usually implies back-propagating through the GNN, bonding the complexity (e.g., number of layers) of the GNN to the cost of explaining it. This naturally begs the question: Can we break this bond by explaining a simpler surrogate GNN? To answer the question, we propose Distill n' Explain (DnX). First, DnX learns a surrogate GNN via knowledge distillation. Then, DnX extracts node or edge-level explanations by solving a simple convex program. We also propose FastDnX, a faster version of DnX that leverages the linear decomposition of our surrogate model. Experiments show that DnX and FastDnX often outperform state-of-the-art GNN explainers while being orders of magnitude faster. Additionally, we support our empirical findings with theoretical results linking the quality of the surrogate model (i.e., distillation error) to the faith
    
[^5]: 对表格数据进行问题特定工具合成：生成、转换、回答

    Generate, Transform, Answer: Question Specific Tool Synthesis for Tabular Data. (arXiv:2303.10138v1 [cs.LG])

    [http://arxiv.org/abs/2303.10138](http://arxiv.org/abs/2303.10138)

    本文提出了一种名为ToolWriter的工具，用于生成查询特定的程序并将其应用于转换表格，以提高表格问答（TQA）的性能。这个工具通过生成行过滤工具，改进了WikiTableQuestions和WikiSQL的最新技术。随着表格尺寸的增加，传统的语言模型在处理表格的过程中存在信息丢失的问题，我们通过利用程序化工具与神经组件相结合的方法来解决这个问题，并展示了这种方法的广泛潜力。

    

    表格问答（TQA）对于神经系统来说是一个具有挑战性的设置，因为它需要自然语言与大量半结构化数据的联合推理。与人类使用程序化工具（如过滤器）在处理之前转换数据不同，TQA中的语言模型直接处理表格，随着表格尺寸的增加，会导致信息丢失。本文提出了ToolWriter，用于生成查询特定的程序，并在需要时检测何时将其应用于转换表格，并将其与TQA模型的能力对齐。将ToolWriter专注于生成行过滤工具，改进了WikiTableQuestions和WikiSQL的最新技术，最大的性能提升出现在长表格上。通过调查空间，我们的工作突出了将程序化工具与神经组件相结合以操作大量结构化数据的广泛潜力。

    Tabular question answering (TQA) presents a challenging setting for neural systems by requiring joint reasoning of natural language with large amounts of semi-structured data. Unlike humans who use programmatic tools like filters to transform data before processing, language models in TQA process tables directly, resulting in information loss as table size increases. In this paper we propose ToolWriter to generate query specific programs and detect when to apply them to transform tables and align them with the TQA model's capabilities. Focusing ToolWriter to generate row-filtering tools improves the state-of-the-art for WikiTableQuestions and WikiSQL with the most performance gained on long tables. By investigating headroom, our work highlights the broader potential for programmatic tools combined with neural components to manipulate large amounts of structured data.
    
[^6]: 她收集需求，他进行测试：大型语言模型中的软件工程性别偏见

    She Elicits Requirements and He Tests: Software Engineering Gender Bias in Large Language Models. (arXiv:2303.10131v1 [cs.SE])

    [http://arxiv.org/abs/2303.10131](http://arxiv.org/abs/2303.10131)

    本研究使用数据挖掘技术调查了56项与软件开发相关的任务，发现性别代词与不同任务的相关性明显不同。其中，只有6%的需求收集任务与代词“他”相关联，而测试任务则在100%的情况下与“他”相关联。此外，帮助他人的任务有91%的相关性与“他”相关联。

    

    软件开发中的隐性性别偏见是一个被广泛研究的问题，比如将技术角色与男性联系在一起。为了解决这种偏见，更详细地了解它是非常重要的。本研究使用数据挖掘技术调查与软件开发相关的56项任务（如分配GitHub问题和测试），以了解嵌入大型语言模型中的隐性性别偏见所产生的影响程度。我们将每个任务从英语系统地翻译成无性别语言，然后再翻译回英语，并调查与每个任务相关的代词。通过在不同排列中反复翻译每个任务100次，我们确定了不同任务与性别代词的显著差异。具体而言，只有6%的需求收集任务与代词“他”相关联，而测试任务则在100%的情况下与“他”相关联。此外，涉及帮助他人的任务有91%的相关性与“他”相关联，而执行同样任务的女性则很容易被忽视。

    Implicit gender bias in software development is a well-documented issue, such as the association of technical roles with men. To address this bias, it is important to understand it in more detail. This study uses data mining techniques to investigate the extent to which 56 tasks related to software development, such as assigning GitHub issues and testing, are affected by implicit gender bias embedded in large language models. We systematically translated each task from English into a genderless language and back, and investigated the pronouns associated with each task. Based on translating each task 100 times in different permutations, we identify a significant disparity in the gendered pronoun associations with different tasks. Specifically, requirements elicitation was associated with the pronoun "he" in only 6% of cases, while testing was associated with "he" in 100% of cases. Additionally, tasks related to helping others had a 91% association with "he" while the same association fo
    
[^7]: GPT是GPT：大语言模型对劳动力市场影响的早期研究

    GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models. (arXiv:2303.10130v1 [econ.GN])

    [http://arxiv.org/abs/2303.10130](http://arxiv.org/abs/2303.10130)

    该研究调查了GPT（大语言模型）和相关技术对美国劳动力市场的潜在影响，发现大约80%的美国劳动力可能会受到10%的工作任务的影响，涵盖了所有工资水平和各行各业，预示着这些模型可能具有显著的经济、社会和政策影响。

    

    我们研究了生成预训练变压器（GPT）模型和相关技术对美国劳动力市场的潜在影响。使用新的标准，我们评估职业与GPT能力的对应关系，结合人类专业知识和GPT-4的分类。我们的研究结果表明，约80%的美国劳动力可能会至少有10%的工作任务受到GPT引入的影响，而约19%的工人可能会看到至少50%的任务受到影响。影响范围涵盖了所有工资水平，高收入工作可能面临更大的风险。值得注意的是，影响并不局限于最近生产率增长较高的行业。我们得出结论，生成预训练变压器具有通用技术（GPT）的特性，表明这些模型可能具有显著的经济、社会和政策影响。

    We investigate the potential implications of Generative Pre-trained Transformer (GPT) models and related technologies on the U.S. labor market. Using a new rubric, we assess occupations based on their correspondence with GPT capabilities, incorporating both human expertise and classifications from GPT-4. Our findings indicate that approximately 80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of GPTs, while around 19% of workers may see at least 50% of their tasks impacted. The influence spans all wage levels, with higher-income jobs potentially facing greater exposure. Notably, the impact is not limited to industries with higher recent productivity growth. We conclude that Generative Pre-trained Transformers exhibit characteristics of general-purpose technologies (GPTs), suggesting that as these models could have notable economic, social, and policy implications.
    
[^8]: Clingraph：ASP可视化系统

    $\textit{Clingraph}$: A System for ASP-based Visualization. (arXiv:2303.10118v1 [cs.AI])

    [http://arxiv.org/abs/2303.10118](http://arxiv.org/abs/2303.10118)

    Clingraph是一款ASP可视化系统，使用ASP事实的图形规范传递给图形系统，提供了极好的接口，且具有Python API，可连接和监视求解过程的各个方面。

    

    我们提出了基于ASP的可视化工具clingraph，它旨在通过ASP本身来可视化ASP的各种概念。这个想法可以追溯到aspviz工具，而clingraph则在现代ASP系统的背景下重新开发和扩展它。更精确地说，clingraph通过ASP事实的图形规范将它们传递给图形可视化系统graphviz。ASP的使用提供了逻辑程序和/或答案集及其可视化之间的极好接口。另外，clingraph提供了一个Python API，扩展了这种易于接口化到clingo的API，从而连接和监视求解过程的各个方面。

    We present the ASP-based visualization tool $\textit{clingraph}$ which aims at visualizing various concepts of ASP by means of ASP itself. This idea traces back to the $\textit{aspviz}$ tool and $\textit{clingraph}$ redevelops and extends it in the context of modern ASP systems. More precisely, $\textit{clingraph}$ takes graph specifications in terms of ASP facts and hands them over to the graph visualization system $\textit{graphviz}$. The use of ASP provides a great interface between logic programs and/or answer sets and their visualization. Also, $\textit{clingraph}$ offers a $\textit{python}$ API that extends this ease of interfacing to $\textit{clingo}$'s API, and in turn to connect and monitor various aspects of the solving process.
    
[^9]: 一个多元关系框架指导机构人工智能研究和采纳

    A multidomain relational framework to guide institutional AI research and adoption. (arXiv:2303.10106v1 [cs.CY])

    [http://arxiv.org/abs/2303.10106](http://arxiv.org/abs/2303.10106)

    该论文提出一个多元关系框架来指导机构人工智能的研究和采纳，解决社会技术话语中的关系问题，包括语义模糊、概念之间缺乏明确的关系和不同的标准术语，帮助评估机构AI系统，避免概念孤立。

    

    对于指导机构和公共管理中人工智能（AI）采纳的新指标、技术标准和管理机制的呼吁现已司空见惯。然而，大多数旨在了解采纳AI的影响的研究和政策努力往往只优先考虑少数想法，而未完全考虑所有潜在相关的不同视角和主题。在这篇立场文件中，我们认为这种遗漏在一定程度上源于我们所称的社会技术话语中的关系问题:基本的本体论问题尚未解决，包括语义模糊、概念之间缺乏明确的关系和不同的标准术语。这导致在评估机构AI系统的不同推理模式以及研究它们的领域，包括机器学习、人类因素、社会科学和政策方面存在概念孤立。在发展了这一批判之后，

    Calls for new metrics, technical standards and governance mechanisms to guide the adoption of Artificial Intelligence (AI) in institutions and public administration are now commonplace. Yet, most research and policy efforts aimed at understanding the implications of adopting AI tend to prioritize only a handful of ideas; they do not fully account for all the different perspectives and topics that are potentially relevant. In this position paper, we contend that this omission stems, in part, from what we call the relational problem in socio-technical discourse: fundamental ontological issues have not yet been settled-including semantic ambiguity, a lack of clear relations between concepts and differing standard terminologies. This contributes to the persistence of disparate modes of reasoning to assess institutional AI systems, and the prevalence of conceptual isolation in the fields that study them including ML, human factors, social science and policy. After developing this critique, 
    
[^10]: 提高上下文在目标检测区域-词对齐中的作用

    Enhancing the Role of Context in Region-Word Alignment for Object Detection. (arXiv:2303.10093v1 [cs.CV])

    [http://arxiv.org/abs/2303.10093](http://arxiv.org/abs/2303.10093)

    本研究提出了一种增强上下文在目标检测区域-词对齐中作用的方法，通过特定的负采样方法提高了属性的作用，从而提高了目标检测的效果。

    

    视觉语言预训练学习图像-标注配对之间的细粒度区域-词对齐，推动了开放词汇目标检测的进展。我们观察到，区域-词对齐方法通常仅针对目标名词在检测中使用，其他上下文，例如属性，对检测的影响不明确。在本研究中，我们探讨了语言上下文如何影响下游目标检测，并提议增强上下文的作用。特别地，我们展示了如何策略性地将接地预训练目标情境化以实现更好的对齐。我们进一步研究了属性作为特别有用的目标上下文并提出了一种新的基于形容词和名词的负采样策略，以增加对它们的对比学习的关注。总的来说，与区域-词预训练的最新技术相比，我们的方法提升了目标检测的效果。我们还通过文本-区域可视化显示属性敏感模型的细粒度实用性。

    Vision-language pretraining to learn a fine-grained, region-word alignment between image-caption pairs has propelled progress in open-vocabulary object detection. We observe that region-word alignment methods are typically used in detection with respect to only object nouns, and the impact of other rich context in captions, such as attributes, is unclear. In this study, we explore how language context affects downstream object detection and propose to enhance the role of context. In particular, we show how to strategically contextualize the grounding pretraining objective for improved alignment. We further hone in on attributes as especially useful object context and propose a novel adjective and noun-based negative sampling strategy for increasing their focus in contrastive learning. Overall, our methods enhance object detection when compared to the state-of-the-art in region-word pretraining. We also highlight the fine-grained utility of an attribute-sensitive model through text-regi
    
[^11]: 层次-超平面核在高斯过程模型积极学习中的应用

    Hierarchical-Hyperplane Kernels for Actively Learning Gaussian Process Models of Nonstationary Systems. (arXiv:2303.10022v1 [cs.LG])

    [http://arxiv.org/abs/2303.10022](http://arxiv.org/abs/2303.10022)

    本文提出了一种层次-超平面核函数族，能够在高斯过程模型积极学习中使用，以建模非平稳性和非线性特性。

    

    学习复杂计算机模拟和物理机器的精确代理模型通常需要长时间或昂贵的实验。此外，建模的物理依赖关系表现出非线性和非平稳性。因此，用于产生代理模型的机器学习方法应通过提供保持查询数量少的方案（例如使用积极学习），并能够捕获系统的非线性和非平稳特性来解决这些问题。一种建模非平稳性的方法是引入输入分区，这种方法在高斯过程的积极学习中被证明是有优势的。但是，这些方法要么假定已知分区，需要引入复杂的抽样方案，要么依赖于非常简单的几何形状。在本文中，我们提出了一种简单但强大的核函数族，它包括一个可通过基于梯度的方法进行学习的分区，并使用更灵活的几何形状。

    Learning precise surrogate models of complex computer simulations and physical machines often require long-lasting or expensive experiments. Furthermore, the modeled physical dependencies exhibit nonlinear and nonstationary behavior. Machine learning methods that are used to produce the surrogate model should therefore address these problems by providing a scheme to keep the number of queries small, e.g. by using active learning and be able to capture the nonlinear and nonstationary properties of the system. One way of modeling the nonstationarity is to induce input-partitioning, a principle that has proven to be advantageous in active learning for Gaussian processes. However, these methods either assume a known partitioning, need to introduce complex sampling schemes or rely on very simple geometries. In this work, we present a simple, yet powerful kernel family that incorporates a partitioning that: i) is learnable via gradient-based methods, ii) uses a geometry that is more flexible
    
[^12]: 使用gRPC提高DareFightingICE中AI的数据传输效率

    Improving Data Transfer Efficiency for AIs in the DareFightingICE using gRPC. (arXiv:2303.10001v1 [cs.NI])

    [http://arxiv.org/abs/2303.10001](http://arxiv.org/abs/2303.10001)

    本文介绍了一种新的通信接口gRPC，以改善DareFightingICE中AI数据传输的效率，减少游戏服务器信息接收所花费的时间。在实现控制非玩家角色的AI的应用中，该方法十分有效。

    

    本文介绍了DareFightingICE平台的一种新的通信接口，该平台是一个基于Java的格斗游戏，其重点是实现控制非玩家角色的AI。该接口使用一个开源的远程过程调用系统，即gRPC，以提高游戏和AI之间的数据传输效率，减少从游戏服务器接收信息所花费的时间。这是很重要的，因为在格斗游戏中实现AI的主要挑战是需要AI在短时间内选择要执行的动作。DareFightingICE平台已经集成了Py4J，允许开发人员使用Python创建AI。然而，Py4J处理大量数据的效率较低，导致延迟过高。相比之下，gRPC很适合传输大量数据。为了评估新的通信接口的有效性，我们进行了一个实验，比较了gRPC和Py4J的延迟，使用的是一个基于规则的AI，该AI发送了一个ki

    This paper presents a new communication interface for the DareFightingICE platform, a Java-based fighting game focused on implementing AI for controlling a non-player character. The interface uses an open-source remote procedure call, gRPC to improve the efficiency of data transfer between the game and the AI, reducing the time spent on receiving information from the game server. This is important because the main challenge of implementing AI in a fighting game is the need for the AI to select an action to perform within a short response time. The DareFightingICE platform has been integrated with Py4J, allowing developers to create AIs using Python. However, Py4J is less efficient at handling large amounts of data, resulting in excessive latency. In contrast, gRPC is well-suited for transmitting large amounts of data. To evaluate the effectiveness of the new communication interface, we conducted an experiment comparing the latency of gRPC and Py4J, using a rule-based AI that sends a ki
    
[^13]: 基于多项式估算器的随机子模最大化问题

    Stochastic Submodular Maximization via Polynomial Estimators. (arXiv:2303.09960v1 [cs.LG])

    [http://arxiv.org/abs/2303.09960](http://arxiv.org/abs/2303.09960)

    本文研究了随机子模最大化问题，特别是通过使用多项式估算器实现了随机连续贪心算法的 $(1-1/e) \approx 63\%$ 的近似比效果，同时显著降低了执行时间。

    

    本文研究了在在线学习、团队组建、设施选址、影响最大化、主动学习和感知目标函数等领域中自然而然出现的带有一般拟阵约束的随机子模最大化问题。我们针对一类由未知分布下的子模函数期望定义的随机最大化问题进行了研究。我们展示了对于这种单调函数，使用多项式梯度估算器的随机连续贪心算法可以达到 $(1-1/e) \approx 63\%$ 的近似比（期望值），同时我们也证明了使用多项式估算器代替先前采用采样的算法能够消除一些随机因素并显著降低执行时间。

    In this paper, we study stochastic submodular maximization problems with general matroid constraints, that naturally arise in online learning, team formation, facility location, influence maximization, active learning and sensing objective functions. In other words, we focus on maximizing submodular functions that are defined as expectations over a class of submodular functions with an unknown distribution. We show that for monotone functions of this form, the stochastic continuous greedy algorithm attains an approximation ratio (in expectation) arbitrarily close to $(1-1/e) \approx 63\%$ using a polynomial estimation of the gradient. We argue that using this polynomial estimator instead of the prior art that uses sampling eliminates a source of randomness and experimentally reduces execution time.
    
[^14]: GNNFormer：一种基于图的细胞病理学报告生成框架

    GNNFormer: A Graph-based Framework for Cytopathology Report Generation. (arXiv:2303.09956v1 [cs.CV])

    [http://arxiv.org/abs/2303.09956](http://arxiv.org/abs/2303.09956)

    提出了一种名为GNNFormer的图神经网络和Transformer结合的基于图的框架，用于细胞病理学报告生成，这是第一个明确对病理图像中的细胞之间的结构信息进行建模的报告生成方法，并在语言生成指标和诊断准确度方面表现优异。

    

    细胞病理学报告的自动生成是病理图像标准化检验的必要步骤，但是手动撰写详细报告会给病理学家带来沉重的工作负担。为了提高效率，一些现有的工作研究了利用最初针对自然图像的视觉编码器应用于细胞病理图像的图像描述生成框架，自动生成细胞病理学报告。这些工作的一个共同缺点是它们没有明确地对细胞之间的结构信息进行建模，而这是病理图像的关键特征，并为诊断提供了重要信息。本文提出了一种新颖的基于图的框架GNNFormer，无缝地将图神经网络（GNN）和Transformer集成到同一框架中，用于细胞病理学报告生成。据我们所知，GNNFormer是第一个明确对病理图像中的细胞之间的结构信息进行建模的报告生成方法。它还能够同时轻松处理细胞级分类和报告级语言生成任务。我们在两个公开数据集上的实验证明了GNNFormer在语言生成指标和诊断准确度方面优于几种最先进的方法。

    Cytopathology report generation is a necessary step for the standardized examination of pathology images. However, manually writing detailed reports brings heavy workloads for pathologists. To improve efficiency, some existing works have studied automatic generation of cytopathology reports, mainly by applying image caption generation frameworks with visual encoders originally proposed for natural images. A common weakness of these works is that they do not explicitly model the structural information among cells, which is a key feature of pathology images and provides significant information for making diagnoses. In this paper, we propose a novel graph-based framework called GNNFormer, which seamlessly integrates graph neural network (GNN) and Transformer into the same framework, for cytopathology report generation. To the best of our knowledge, GNNFormer is the first report generation method that explicitly models the structural information among cells in pathology images. It also eff
    
[^15]: SemEval-2023任务3上的mCPT：用于零样本和少样本框架检测的多语言标签感知对比预训练变压器

    mCPT at SemEval-2023 Task 3: Multilingual Label-Aware Contrastive Pre-Training of Transformers for Few- and Zero-shot Framing Detection. (arXiv:2303.09901v1 [cs.CL])

    [http://arxiv.org/abs/2303.09901](http://arxiv.org/abs/2303.09901)

    本研究提出了mCPT模型用于多语言的、多标签的零样本或少样本的框架检测任务，并在西班牙语和其他8种语言中取得了良好的成绩。该方案采用了基于多语言变压器的预训练程序，使用标签感知对比损失函数。

    

    本文介绍了零样本的西班牙语框架检测任务的获胜系统，并在另外八种语言中取得了良好的成绩。框架检测任务的挑战在于在只有少量或零个样本的情况下识别一组14个框架，即多语言多标签的少样本和零样本设置。我们开发的解决方案采用了基于多语言变压器的预训练程序，使用标签感知对比损失函数。除了描述系统外，我们还进行了嵌入空间分析和消融研究，以展示我们的预训练程序如何支持框架检测以推进计算框架分析。

    This paper presents the winning system for the zero-shot Spanish framing detection task, which also achieves competitive places in eight additional languages. The challenge of the framing detection task lies in identifying a set of 14 frames when only a few or zero samples are available, i.e., a multilingual multi-label few- or zero-shot setting. Our developed solution employs a pre-training procedure based on multilingual Transformers using a label-aware contrastive loss function. In addition to describing the system, we perform an embedding space analysis and ablation study to demonstrate how our pre-training procedure supports framing detection to advance computational framing analysis.
    
[^16]: 利用语义属性的转导式零样本学习

    Exploiting Semantic Attributes for Transductive Zero-Shot Learning. (arXiv:2303.09849v1 [cs.CV])

    [http://arxiv.org/abs/2303.09849](http://arxiv.org/abs/2303.09849)

    该论文提出了一种新的转导式零样本学习方法，该方法生成未知数据的语义属性，并将它们导入到生成过程中，以解决现有方法无法生成高保真度的属性一致的未知特征的问题。

    

    零样本学习旨在通过泛化从已知类别学习到的视觉特征和语义属性的关系来识别未知类别。最近的一种称为转导式零样本学习的范式，更进一步利用在训练过程中不标记的未知数据，并取得了令人印象深刻的结果。然而，这些方法总是通过生成对抗网络从属性中合成未知特征，以减少对已知类别的偏差。但是，它们忽视了未标记的未知数据中的语义信息，因此无法生成高保真的属性一致的未知特征。为解决这个问题，我们提出了一种新的转导式零样本学习方法，该方法生成未知数据的语义属性，并将它们导入到生成过程中。具体来说，我们首先训练一个语义属性解码器，该解码器学习从视觉特征到语义属性的映射。然后，从属性解码器中，我们获得未标记的数据的伪属性，并将它们集成到生成的过程中。

    Zero-shot learning (ZSL) aims to recognize unseen classes by generalizing the relation between visual features and semantic attributes learned from the seen classes. A recent paradigm called transductive zero-shot learning further leverages unlabeled unseen data during training and has obtained impressive results. These methods always synthesize unseen features from attributes through a generative adversarial network to mitigate the bias towards seen classes. However, they neglect the semantic information in the unlabeled unseen data and thus fail to generate high-fidelity attribute-consistent unseen features. To address this issue, we present a novel transductive ZSL method that produces semantic attributes of the unseen data and imposes them on the generative process. In particular, we first train an attribute decoder that learns the mapping from visual features to semantic attributes. Then, from the attribute decoder, we obtain pseudo-attributes of unlabeled data and integrate them 
    
[^17]: DUDES: 使用集成学习的深度不确定性蒸馏在语义分割中的应用

    DUDES: Deep Uncertainty Distillation using Ensembles for Semantic Segmentation. (arXiv:2303.09843v1 [cs.CV])

    [http://arxiv.org/abs/2303.09843](http://arxiv.org/abs/2303.09843)

    本文提出了一种名为 DUDES 的新方法，通过集成学习和知识蒸馏技术，准确地估算预测的不确定性，同时具有高效性和适应性。实验结果表明，DUDES 能够准确地捕获预测的不确定性，并在不牺牲分割任务性能的前提下，具有检测错误分类实例和检测分布之外样本的出色能力。

    

    深度神经网络缺乏可解释性且往往过于自信，这在安全关键应用（如自动驾驶、医疗成像或对可靠性要求较高的机器视觉任务）中会带来严重问题。量化预测的不确定性是开发深度神经网络用于此类应用的一种有前途的方法，但当前可用方法计算负担较大。本文提出一种名为 Deep Uncertainty Distillation using Ensembles （DUDES）的新方法，用于高效可靠地估算不确定性。DUDES 使用深度集成的知识蒸馏，在保持简单易用的同时，通过单个向前传递准确地近似预测不确定性。实验结果表明，DUDES 在不牺牲分割任务的性能的前提下准确地捕获了预测的不确定性，并表现出识别错误分类实例和检测到分布之外样本的出色能力

    Deep neural networks lack interpretability and tend to be overconfident, which poses a serious problem in safety-critical applications like autonomous driving, medical imaging, or machine vision tasks with high demands on reliability. Quantifying the predictive uncertainty is a promising endeavour to open up the use of deep neural networks for such applications. Unfortunately, current available methods are computationally expensive. In this work, we present a novel approach for efficient and reliable uncertainty estimation which we call Deep Uncertainty Distillation using Ensembles for Segmentation (DUDES). DUDES applies student-teacher distillation with a Deep Ensemble to accurately approximate predictive uncertainties with a single forward pass while maintaining simplicity and adaptability. Experimentally, DUDES accurately captures predictive uncertainties without sacrificing performance on the segmentation task and indicates impressive capabilities of identifying wrongly classified 
    
[^18]: DORIC: 通过依赖解析进行领域鲁棒微调的开放意图聚类

    DORIC : Domain Robust Fine-Tuning for Open Intent Clustering through Dependency Parsing. (arXiv:2303.09827v1 [cs.CL])

    [http://arxiv.org/abs/2303.09827](http://arxiv.org/abs/2303.09827)

    该论文提出了一种名为DORIC的方法，通过利用多领域对话数据集进行微调，提取动词-宾语对以达到消除不必要信息的目的，最终实现了在各种领域数据集上的高精度聚类。

    

    我们在Dialog System Technology Challenges 11（DSTC11）的第2轨道上展示了我们的工作。DSTC11-Track2旨在为0-shot，跨领域的意图集归纳提供基准。在没有领域内训练数据集的情况下，需要强大的话语表示，可用于跨领域归纳用户意图。为了实现这一目标，我们利用多领域对话数据集来微调语言模型，并提出提取动词-宾语对以消除不必要信息的方法。此外，我们设计了一种方法，为聚类结果的可解释性生成每个群集的名称。我们的方法在各种领域数据集上展示出了优秀的准确性和标准化互信息（NMI）得分，相较于基线模型，我们在精度得分上获得了第三名。

    We present our work on Track 2 in the Dialog System Technology Challenges 11 (DSTC11). DSTC11-Track2 aims to provide a benchmark for zero-shot, cross-domain, intent-set induction. In the absence of in-domain training dataset, robust utterance representation that can be used across domains is necessary to induce users' intentions. To achieve this, we leveraged a multi-domain dialogue dataset to fine-tune the language model and proposed extracting Verb-Object pairs to remove the artifacts of unnecessary information. Furthermore, we devised the method that generates each cluster's name for the explainability of clustered results. Our approach achieved 3rd place in the precision score and showed superior accuracy and normalized mutual information (NMI) score than the baseline model on various domain datasets.
    
[^19]: 自动驾驶路径规划：现状与展望

    Path Planning for Autonomous Driving: The State of the Art and Perspectives. (arXiv:2303.09824v1 [cs.RO])

    [http://arxiv.org/abs/2303.09824](http://arxiv.org/abs/2303.09824)

    本文综述了现有的自动驾驶路径规划方法，包括管道规划和端到端规划方法。在挑战和潜在解决方案方面提供了讨论，有助于为智能汽车的发展提供更好的规划方法。

    

    智能汽车由于提高的便利性、安全性和潜在的商业价值而受到广泛关注。但由于各种问题，如安全性、可靠性和规划方法的泛化等限制，它们的部署仍局限于小规模验证阶段。本文旨在综述最先进的路径规划方法，包括管道规划和端到端规划方法。针对管道方法，本文提供了选取算法的概述，并讨论了扩展和优化机制；针对端到端方法，本文强调培训和验证方法。此外，本文还讨论了挑战和潜在解决方案，这有助于为智能汽车的发展提供更好的规划方法。

    Intelligent vehicles (IVs) have attracted wide attention thanks to the augmented convenience, safety advantages, and potential commercial value. Although a few of autonomous driving unicorns assert that IVs will be commercially deployable by 2025, their deployment is still restricted to small-scale validation due to various issues, among which safety, reliability, and generalization of planning methods are prominent concerns. Precise computation of control commands or trajectories by planning methods remains a prerequisite for IVs, owing to perceptual imperfections under complex environments, which pose an obstacle to the successful commercialization of IVs. This paper aims to review state-of-the-art planning methods, including pipeline planning and end-to-end planning methods. In terms of pipeline methods, a survey of selecting algorithms is provided along with a discussion of the expansion and optimization mechanisms, whereas in end-to-end methods, the training approaches and verific
    
[^20]: Transformers和Ensemble方法：阿语恶意言论检测的一种解决方案

    Transformers and Ensemble methods: A solution for Hate Speech Detection in Arabic languages. (arXiv:2303.09823v1 [cs.CL])

    [http://arxiv.org/abs/2303.09823](http://arxiv.org/abs/2303.09823)

    本文提出了一种使用Transformer和Ensemble方法的解决方案，用于阿语恶意言论的检测。实验结果表明，基于多数表决的集成方法具有最佳效果，其在测试集上的准确率为0.86，F1分数为0.60。

    

    本文描述了我们参加CERIST NLP挑战赛2022中恶意言论检测共享任务的实验过程。我们评估了6个Transformer模型及其组合的性能，并使用了2种集成方法。在五折交叉验证的训练集上，基于多数表决的集成方法获得了最佳结果。在测试集上的评估结果为F1分数为0.60，准确性为0.86。

    This paper describes our participation in the shared task of hate speech detection, which is one of the subtasks of the CERIST NLP Challenge 2022. Our experiments evaluate the performance of six transformer models and their combination using 2 ensemble approaches. The best results on the training set, in a five-fold cross validation scenario, were obtained by using the ensemble approach based on the majority vote. The evaluation of this approach on the test set resulted in an F1-score of 0.60 and an Accuracy of 0.86.
    
[^21]: DiffusionSeg：将扩散技术应用于无监督目标发现中的自适应架构

    DiffusionSeg: Adapting Diffusion Towards Unsupervised Object Discovery. (arXiv:2303.09813v1 [cs.CV])

    [http://arxiv.org/abs/2303.09813](http://arxiv.org/abs/2303.09813)

    本文提出了一种新的框架DiffusionSeg，利用扩散模型解决了无监督目标发现任务中的判别性问题，包含两个阶段的策略，通过合成大量图像和Pixelwise回归来解决标记数据不足和生成、判别模型结构不同的问题。在基准测试中表现出最先进的性能。

    

    预训练模型从大量数据中学习，现在已经取得了令人瞩目的进展。作为流行的生成预训练模型，扩散模型捕捉了低级视觉知识和高级语义关系。本文提出了一种利用这种知识库扩散模型来进行主流判别性任务——无监督目标发现：显着性分割和目标定位。然而，由于生成和判别式模型之间存在一种结构上的差异，这限制了直接使用的可能性。此外，显式标记数据的缺乏在无监督设置下显著限制了性能。为了应对这些问题，我们引入了DiffusionSeg，这是一个包含两个阶段策略的新型合成-利用框架。为了减轻数据不足的问题，我们使用第一个合成阶段合成大量的图像，并提出了一种新的无需训练的AttentionCut来获得掩膜。在第二个利用阶段中，为了弥补生成和判别式模型之间的差距，我们提出了Pixelwise回归，通过物体位置约束生成扩散过程。所提出的方法在无监督目标发现基准测试中实现了最先进的性能，表明扩散模型可以有效地应用于判别性任务。

    Learning from a large corpus of data, pre-trained models have achieved impressive progress nowadays. As popular generative pre-training, diffusion models capture both low-level visual knowledge and high-level semantic relations. In this paper, we propose to exploit such knowledgeable diffusion models for mainstream discriminative tasks, i.e., unsupervised object discovery: saliency segmentation and object localization. However, the challenges exist as there is one structural difference between generative and discriminative models, which limits the direct use. Besides, the lack of explicitly labeled data significantly limits performance in unsupervised settings. To tackle these issues, we introduce DiffusionSeg, one novel synthesis-exploitation framework containing two-stage strategies. To alleviate data insufficiency, we synthesize abundant images, and propose a novel training-free AttentionCut to obtain masks in the first synthesis stage. In the second exploitation stage, to bridge th
    
[^22]: TKN：基于Transformer的实时视频关键点预测网络

    TKN: Transformer-based Keypoint Prediction Network For Real-time Video Prediction. (arXiv:2303.09807v1 [cs.CV])

    [http://arxiv.org/abs/2303.09807](http://arxiv.org/abs/2303.09807)

    TKN是一种基于Transformer的实时视频预测解决方案，通过受限信息提取和并行预测方案来提升预测过程的速度，具有更高的精度和更低的计算成本。

    

    视频预测是一项具有广泛用途的复杂时间序列预测任务。然而，传统方法过于强调准确性，忽视了由于过于复杂的模型结构而导致的较慢的预测速度以及过多的冗余信息学习和GPU内存消耗。因此，我们提出了TKN，一种基于Transformer的关键点预测神经网络，通过受限信息提取和并行预测方案来提升预测过程的速度。TKN是我们目前所知的第一个实时视频预测解决方案，同时显著降低计算成本并保持其他性能。在KTH和Human Action 3D数据集上的大量实验表明，TKN在预测准确性和速度方面均优于现有的基准线。

    Video prediction is a complex time-series forecasting task with great potential in many use cases. However, conventional methods overemphasize accuracy while ignoring the slow prediction speed caused by complicated model structures that learn too much redundant information with excessive GPU memory consumption. Furthermore, conventional methods mostly predict frames sequentially (frame-by-frame) and thus are hard to accelerate. Consequently, valuable use cases such as real-time danger prediction and warning cannot achieve fast enough inference speed to be applicable in reality. Therefore, we propose a transformer-based keypoint prediction neural network (TKN), an unsupervised learning method that boost the prediction process via constrained information extraction and parallel prediction scheme. TKN is the first real-time video prediction solution to our best knowledge, while significantly reducing computation costs and maintaining other performance. Extensive experiments on KTH and Hum
    
[^23]: 基于城市区域功能引导的交通流预测

    Urban Regional Function Guided Traffic Flow Prediction. (arXiv:2303.09789v1 [cs.CV])

    [http://arxiv.org/abs/2303.09789](http://arxiv.org/abs/2303.09789)

    本文提出了一个名为POI-MetaBlock的新模块，结合区域的功能性和交通特征，采用自注意力架构进行交通流预测。

    

    交通流预测是时空分析中具有挑战性但至关重要的问题，近年来越来越受到关注。除了时空相关性，城市区域的功能性也在交通流预测中起着至关重要的作用。然而，对区域功能属性的探索主要集中在添加额外的拓扑结构上，忽略了功能属性对区域交通特征的影响。与现有作品不同的是，我们提出了一个名为POI-MetaBlock的新模块，利用每个区域的功能性（由兴趣点分布表示）作为元数据来进一步挖掘不同功能区域的不同交通特征。具体而言，所提出的POI-MetaBlock采用自注意力架构，结合POI和时间信息生成每个区域的动态注意参数，使模型能够适应不同的各种区域交通模式。

    The prediction of traffic flow is a challenging yet crucial problem in spatial-temporal analysis, which has recently gained increasing interest. In addition to spatial-temporal correlations, the functionality of urban areas also plays a crucial role in traffic flow prediction. However, the exploration of regional functional attributes mainly focuses on adding additional topological structures, ignoring the influence of functional attributes on regional traffic patterns. Different from the existing works, we propose a novel module named POI-MetaBlock, which utilizes the functionality of each region (represented by Point of Interest distribution) as metadata to further mine different traffic characteristics in areas with different functions. Specifically, the proposed POI-MetaBlock employs a self-attention architecture and incorporates POI and time information to generate dynamic attention parameters for each region, which enables the model to fit different traffic patterns of various ar
    
[^24]: SE-GSL：一种通过结构熵优化实现通用有效图结构学习的框架。

    SE-GSL: A General and Effective Graph Structure Learning Framework through Structural Entropy Optimization. (arXiv:2303.09778v1 [cs.LG])

    [http://arxiv.org/abs/2303.09778](http://arxiv.org/abs/2303.09778)

    本论文提出了一个通用且有效的图结构学习框架SE-GSL，通过利用结构熵和编码树中的层次结构来最大化嵌入信息内容，同时提出了一个声慢构建最优编码树的方案。该框架还提出了一个新颖的基于样本的机制，通过节点结构熵分布来恢复图结构。

    

    图神经网络是学习结构化数据的实际解决方案。 然而，它容易受到低质量和不可靠结构的影响，这在真实世界的图中是常态而不是例外。现有的图结构学习框架仍然缺乏鲁棒性和可解释性。本文通过结构熵和编码树中抽象的图层次结构提出了一种通用的GSL框架SE-GSL。特别地，我们利用一维结构熵来最大化嵌入信息内容，当辅助邻域属性被融合以增强原始图时。提出了一种构建最优编码树的新方案，以在分层抽象中最小化图中的不确定性和噪音，同时确保适当的社区划分。我们提出了一个新颖的基于样本的机制，通过节点结构熵分布来恢复图结构。它增加了更大不确定性的节点之间的连通性。

    Graph Neural Networks (GNNs) are de facto solutions to structural data learning. However, it is susceptible to low-quality and unreliable structure, which has been a norm rather than an exception in real-world graphs. Existing graph structure learning (GSL) frameworks still lack robustness and interpretability. This paper proposes a general GSL framework, SE-GSL, through structural entropy and the graph hierarchy abstracted in the encoding tree. Particularly, we exploit the one-dimensional structural entropy to maximize embedded information content when auxiliary neighbourhood attributes are fused to enhance the original graph. A new scheme of constructing optimal encoding trees is proposed to minimize the uncertainty and noises in the graph whilst assuring proper community partition in hierarchical abstraction. We present a novel sample-based mechanism for restoring the graph structure via node structural entropy distribution. It increases the connectivity among nodes with larger unce
    
[^25]: 理解前线工作者和无家可归人员对无家者服务中使用的人工智能的观点

    Understanding Frontline Workers' and Unhoused Individuals' Perspectives on AI Used in Homeless Services. (arXiv:2303.09743v1 [cs.HC])

    [http://arxiv.org/abs/2303.09743](http://arxiv.org/abs/2303.09743)

    研究了受影响的利益相关方对于优先考虑有限住房资源的 AI 决策支持系统的看法，发现相关利益相关方可提供具体和关键性的反馈，即使他们没有 AI 知识。

    

    近年来，基于人工智能的决策支持系统（ADS）在无家可归者服务中得到了广泛应用，但我们对于涉及该技术的利益相关方的愿望和关注知之甚少。在这项研究中，我们旨在了解受影响利益相关方对一个优先考虑有限住房资源的 ADS 的看法。我们采用了 AI 生命周期漫画板设计方法的改进版本进行反馈搜集和设计思路收集跨 AI 系统设计的各个组成部分。我们从每日操作 ADS 的县工作人员，直接受到 ADS 影响的服务提供者以及该地区的无家可归个体中获取反馈。我们的参与者分享了对 AI 系统的整体目标、特定模型设计选择、数据集选择以及在部署中使用的关注和设计建议。我们的发现表明，利益相关方即使没有 AI 知识，也能提供对于 AI 系统设计和部署的具体和关键性反馈。

    Recent years have seen growing adoption of AI-based decision-support systems (ADS) in homeless services, yet we know little about stakeholder desires and concerns surrounding their use. In this work, we aim to understand impacted stakeholders' perspectives on a deployed ADS that prioritizes scarce housing resources. We employed AI lifecycle comicboarding, an adapted version of the comicboarding method, to elicit stakeholder feedback and design ideas across various components of an AI system's design. We elicited feedback from county workers who operate the ADS daily, service providers whose work is directly impacted by the ADS, and unhoused individuals in the region. Our participants shared concerns and design suggestions around the AI system's overall objective, specific model design choices, dataset selection, and use in deployment. Our findings demonstrate that stakeholders, even without AI knowledge, can provide specific and critical feedback on an AI system's design and deployment
    
[^26]: 压缩CNN的动态结构剪枝方法

    Dynamic Structure Pruning for Compressing CNNs. (arXiv:2303.09736v1 [cs.CV])

    [http://arxiv.org/abs/2303.09736](http://arxiv.org/abs/2303.09736)

    本文介绍了一种新的动态结构剪枝方法，它可以自动优化每层内通道剪枝的最优粒度，从而更加紧凑和高效。

    

    结构剪枝是一种压缩和加速神经网络的有效方法。尽管在实际加速和硬件兼容性方面滤波和通道剪枝是优于其他结构剪枝方法的，但细粒度的剪枝方法，如内通道剪枝，有望产生更紧凑和计算效率更高的网络。现有的内通道剪枝方法通常使用静态和手动制定的剪枝粒度，这留给了优化剪枝性能的空间。在这项工作中，我们介绍了一种新的结构剪枝方法，称为动态结构剪枝，来确定内通道剪枝的最优剪枝粒度。与现有的内通道剪枝方法不同，所提出的方法在训练深度神经网络时自动优化每层的动态剪枝粒度。为了实现这一点，我们提出了一种可区分的组学习方法

    Structure pruning is an effective method to compress and accelerate neural networks. While filter and channel pruning are preferable to other structure pruning methods in terms of realistic acceleration and hardware compatibility, pruning methods with a finer granularity, such as intra-channel pruning, are expected to be capable of yielding more compact and computationally efficient networks. Typical intra-channel pruning methods utilize a static and hand-crafted pruning granularity due to a large search space, which leaves room for improvement in their pruning performance. In this work, we introduce a novel structure pruning method, termed as dynamic structure pruning, to identify optimal pruning granularities for intra-channel pruning. In contrast to existing intra-channel pruning methods, the proposed method automatically optimizes dynamic pruning granularities in each layer while training deep neural networks. To achieve this, we propose a differentiable group learning method desig
    
[^27]: 驱邪“Wraith”：保护自动驾驶系统中基于LiDAR的物体检测器免遭出现攻击

    Exorcising ''Wraith'': Protecting LiDAR-based Object Detector in Automated Driving System from Appearing Attacks. (arXiv:2303.09731v1 [cs.CR])

    [http://arxiv.org/abs/2303.09731](http://arxiv.org/abs/2303.09731)

    本文提出了一种新的防御模块，用于保护自动驾驶系统中基于LiDAR的物体检测器免遭出现攻击。该模块根据局部部分的物体性低下来消除伪造的障碍物，并通过变体连体网络进行识别。在基准测试中，平均点对点F1分数为96.2％。

    

    自动驾驶系统依赖于3D物体检测器从LiDAR点云中识别可能的障碍物，但是最近的研究表明，攻击者可以使用少量的伪造点（即出现攻击）在预测结果中伪造不存在的车辆。现有的防御措施通过去除统计上的离群值来针对特定攻击或通过预定义的启发式规则进行防御。为了更全面地减轻攻击，我们首先系统地检查了最近出现的攻击机制：他们的共同弱点在于伪造的障碍物(i)与真实障碍物相比具有明显的局部差异，(ii)违反了深度和点密度之间的物理关系。在本文中，我们提出了一种新的即插即用的防御模块，它可以在受过训练的基于LiDAR的物体检测器的一侧工作，以消除伪造的障碍物，其中大部分局部部分的物体性较低，即它属于实际物体的程度。我们设计的核心是变体连体网络（VSN），它将检测器的原始和屏蔽输入都作为输入，并为识别假点生成成对相似性图。实验表明，我们的方法可以在没有任何先前攻击知识的情况下有效地防御出现攻击，在两个基准数据集上的平均点对点F1分数为96.2％。

    Automated driving systems rely on 3D object detectors to recognize possible obstacles from LiDAR point clouds. However, recent works show the adversary can forge non-existent cars in the prediction results with a few fake points (i.e., appearing attack). By removing statistical outliers, existing defenses are however designed for specific attacks or biased by predefined heuristic rules. Towards more comprehensive mitigation, we first systematically inspect the mechanism of recent appearing attacks: Their common weaknesses are observed in crafting fake obstacles which (i) have obvious differences in the local parts compared with real obstacles and (ii) violate the physical relation between depth and point density. In this paper, we propose a novel plug-and-play defensive module which works by side of a trained LiDAR-based object detector to eliminate forged obstacles where a major proportion of local parts have low objectness, i.e., to what degree it belongs to a real object. At the cor
    
[^28]: 零和马尔可夫博弈中强化学习的新政策迭代算法

    A New Policy Iteration Algorithm For Reinforcement Learning in Zero-Sum Markov Games. (arXiv:2303.09716v1 [cs.LG])

    [http://arxiv.org/abs/2303.09716](http://arxiv.org/abs/2303.09716)

    本文提出了一种适用于零和马尔可夫博弈的简单但有效的策略迭代算法。

    

    许多基于模型的强化学习算法可以被视为具有两个阶段: 学习阶段和规划阶段。在标准MDPs情况下，可以使用价值迭代或策略迭代来解决学习问题。但在零和马尔可夫博弈的情况下，没有有效的策略迭代算法，以前的尝试都有局限性。本文提出了一种简单的策略迭代变体，能够有效地解决这个问题。

    Many model-based reinforcement learning (RL) algorithms can be viewed as having two phases that are iteratively implemented: a learning phase where the model is approximately learned and a planning phase where the learned model is used to derive a policy. In the case of standard MDPs, the learning problem can be solved using either value iteration or policy iteration. However, in the case of zero-sum Markov games, there is no efficient policy iteration algorithm; e.g., it has been shown in Hansen et al. (2013) that one has to solve Omega(1/(1-alpha)) MDPs, where alpha is the discount factor, to implement the only known convergent version of policy iteration. Another algorithm for Markov zero-sum games, called naive policy iteration, is easy to implement but is only provably convergent under very restrictive assumptions. Prior attempts to fix naive policy iteration algorithm have several limitations. Here, we show that a simple variant of naive policy iteration for games converges, and 
    
[^29]: 推荐链接的延时和间接影响

    Delayed and Indirect Impacts of Link Recommendations. (arXiv:2303.09700v1 [cs.SI])

    [http://arxiv.org/abs/2303.09700](http://arxiv.org/abs/2303.09700)

    本研究研究了链接推荐在动态环境中对社交网络演化的影响，并发现推荐链接有令人惊讶的延迟和间接影响。

    

    推荐链接对社交网络的影响很难评估，迄今为止研究受限于有限的环境。观察性研究受限于它们所能回答的因果问题的种类，天真的 A/B 测试常常会由于未考虑到的网络干扰而导致偏见评估。此外，模拟环境中的评估经常局限于静态网络模型，不考虑链接推荐和有机网络演化之间的潜在反馈。为此，我们在动态环境中研究了推荐对社交网络的影响。采用模拟方法，考虑一个显式的动态形成模型——著名的Jackson-Rogers模型的扩展——并研究链接推荐如何随时间影响网络演化。实证上，我们发现链接推荐对网络结构属性有令人惊讶的延迟和间接影响。

    The impacts of link recommendations on social networks are challenging to evaluate, and so far they have been studied in limited settings. Observational studies are restricted in the kinds of causal questions they can answer and naive A/B tests often lead to biased evaluations due to unaccounted network interference. Furthermore, evaluations in simulation settings are often limited to static network models that do not take into account the potential feedback loops between link recommendation and organic network evolution. To this end, we study the impacts of recommendations on social networks in dynamic settings. Adopting a simulation-based approach, we consider an explicit dynamic formation model -- an extension of the celebrated Jackson-Rogers model -- and investigate how link recommendations affect network evolution over time. Empirically, we find that link recommendations have surprising delayed and indirect effects on the structural properties of networks. Specifically, we find th
    
[^30]: DiGeo: 判别几何感知学习用于广义少样本物体检测

    DiGeo: Discriminative Geometry-Aware Learning for Generalized Few-Shot Object Detection. (arXiv:2303.09674v1 [cs.CV])

    [http://arxiv.org/abs/2303.09674](http://arxiv.org/abs/2303.09674)

    本文提出了一种新的训练框架 DiGeo，学习几何感知特征来实现跨类别间的分离和类内紧密性。通过引导特征聚类的分离，采用自适应的类特定间距，本文方法有效提升了广义少样本目标检测的性能。

    

    广义少样本目标检测旨在实现基础类别和新颖类别的精准检测。现有方法在增强少样本泛化的同时牺牲了基础类别的性能，或者在基础类别检测精度有限的情况下，在新颖类别的适应性方面有限的提高。本文指出了这个问题的原因在于所有类别的不足的判别特征学习。因此，我们提出了一种新的训练框架 DiGeo，学习几何感知特征来实现跨类别间的分离和类内紧密性。为了指导特征聚类的分离，我们推导出离线的简单光角紧框架（ETF）分类器，其权重作为类中心并最大、均等的分开。为了紧密每个类别的聚类，我们将自适应的类特定间距添加到分类损失中，并鼓励接近类中心的特征。实验结果证明了我们提出的方法的有效性，同时在公共基准上取得了最新水平。

    Generalized few-shot object detection aims to achieve precise detection on both base classes with abundant annotations and novel classes with limited training data. Existing approaches enhance few-shot generalization with the sacrifice of base-class performance, or maintain high precision in base-class detection with limited improvement in novel-class adaptation. In this paper, we point out the reason is insufficient Discriminative feature learning for all of the classes. As such, we propose a new training framework, DiGeo, to learn Geometry-aware features of inter-class separation and intra-class compactness. To guide the separation of feature clusters, we derive an offline simplex equiangular tight frame (ETF) classifier whose weights serve as class centers and are maximally and equally separated. To tighten the cluster for each class, we include adaptive class-specific margins into the classification loss and encourage the features close to the class centers. Experimental studies on
    
[^31]: 用TribalGram对群体间差异进行关键检查：部落分析的批判性视察

    Tribe or Not? Critical Inspection of Group Differences Using TribalGram. (arXiv:2303.09664v1 [cs.LG])

    [http://arxiv.org/abs/2303.09664](http://arxiv.org/abs/2303.09664)

    本文提出了一组负责任的群体分析设计指南，并通过开发TribalGram工具使用可解释的机器学习算法和可视化来对群体分析进行推断评估、模型解释、数据协作和理解，以增强对分析群体的深刻理解，并防止因刻板印象和过度概括导致的潜在危害。

    

    随着人工智能和数据挖掘技术的兴起，群体分析和群体层面的分析在包括政策制定和直接营销在内的许多领域中得到了越来越广泛的应用。在一些情况下，从数据中提取的统计信息可能为一个群体的共同特征提供见解；而在其他情况下，群体层面的分析可能会导致刻板印象和系统性压迫。分析工具如何促进更加有意识的群体分析过程？在本研究中，我们确定了一组负责任的群体分析设计指南，以阐明群体差异的需要和防止对群体的过度概括。遵循这些设计指南，我们开发了TribalGram，这是一个利用可解释的机器学习算法和可视化来提供推断评估、模型解释、数据协作和理解的视觉分析工具。通过与领域专家的访谈，我们展示了我们的设计和工具如何带来对分析群体的更深入理解，并防止由于刻板印象和过度概括而带来的潜在危害。

    With the rise of AI and data mining techniques, group profiling and group-level analysis have been increasingly used in many domains including policy making and direct marketing. In some cases, the statistics extracted from data may provide insights to a group's shared characteristics; in others, the group-level analysis can lead to problems including stereotyping and systematic oppression. How can analytic tools facilitate a more conscientious process in group analysis? In this work, we identify a set of accountable group analytics design guidelines to explicate the needs for group differentiation and preventing overgeneralization of a group. Following the design guidelines, we develop TribalGram, a visual analytic suite that leverages interpretable machine learning algorithms and visualization to offer inference assessment, model explanation, data corroboration, and sense-making. Through the interviews with domain experts, we showcase how our design and tools can bring a richer under
    
[^32]: ESCAPE：通过交互式视觉分析消除机器的盲区系统误差

    ESCAPE: Countering Systematic Errors from Machine's Blind Spots via Interactive Visual Analysis. (arXiv:2303.09657v1 [cs.LG])

    [http://arxiv.org/abs/2303.09657](http://arxiv.org/abs/2303.09657)

    本论文提出了ESCAPE，一个交互式视觉分析系统，利用人机交互帮助用户发现并修正机器学习中的系统误差。

    

    分类模型学习推广数据和目标类之间的关联。然而，研究人员越来越多地观察到机器学习实践很容易在AI应用程序中导致系统错误，这种现象称为AI盲区。当模型使用训练样本进行训练（例如，猫/狗分类），其中重要模式（例如，黑猫）缺失或周边/不良模式（例如，草地背景的狗）会误导到某个类时，会出现这些盲区。甚至更复杂的技术也不能保证捕获、理解和防止伪关联。在这项工作中，我们提出了一个名为ESCAPE的视觉分析系统，它促进了消除系统误差的人机交互工作流程。通过允许人类用户轻松检查虚假关联，该系统有助于用户自发地识别与错误分类相关的概念并评估缓解策略。

    Classification models learn to generalize the associations between data samples and their target classes. However, researchers have increasingly observed that machine learning practice easily leads to systematic errors in AI applications, a phenomenon referred to as AI blindspots. Such blindspots arise when a model is trained with training samples (e.g., cat/dog classification) where important patterns (e.g., black cats) are missing or periphery/undesirable patterns (e.g., dogs with grass background) are misleading towards a certain class. Even more sophisticated techniques cannot guarantee to capture, reason about, and prevent the spurious associations. In this work, we propose ESCAPE, a visual analytic system that promotes a human-in-the-loop workflow for countering systematic errors. By allowing human users to easily inspect spurious associations, the system facilitates users to spontaneously recognize concepts associated misclassifications and evaluate mitigation strategies that ca
    
[^33]: 周期性MDP中的在线强化学习

    Online Reinforcement Learning in Periodic MDP. (arXiv:2303.09629v1 [cs.LG])

    [http://arxiv.org/abs/2303.09629](http://arxiv.org/abs/2303.09629)

    本文提出了用于解决周期性MDP中强化学习问题的四种算法，其中包括PUCRL2，PUCRLB，U-PUCRL2和U-PUCRLB。PUCRLB表现更好，且其遗憾随周期$N$的变化为$O(\sqrt{N})$。

    

    我们研究了周期性马尔可夫决策过程（MDP）下的强化学习问题，这是一种特殊的非平稳MDP，其中状态转移概率和奖励函数都会周期性变化，在平均奖励最大化的设置下。我们通过在状态空间中添加周期索引来将问题归结为静态MDP，并提出了一种周期性上置信区间强化学习-2（PUCRL2）算法。我们证明了PUCRL2的遗憾值随周期$N$线性变化，并且随着时限长度$T$呈$\mathcal{O}(\sqrt{Tlog T})$的变化。利用增广MDP的转移矩阵的稀疏信息，我们提出另一个算法PUCRLB，它在遗憾（周期的$O(\sqrt{N})$依赖关系）和经验表现方面都比PUCRL2更出色。最后，我们还提出了两个算法U-PUCRL2和U-PUCRLB，用于环境中扩展不确定性，其中周期未知，但已知一组候选周期。数值结果证明，

    We study learning in periodic Markov Decision Process (MDP), a special type of non-stationary MDP where both the state transition probabilities and reward functions vary periodically, under the average reward maximization setting. We formulate the problem as a stationary MDP by augmenting the state space with the period index, and propose a periodic upper confidence bound reinforcement learning-2 (PUCRL2) algorithm. We show that the regret of PUCRL2 varies linearly with the period $N$ and as $\mathcal{O}(\sqrt{Tlog T})$ with the horizon length $T$. Utilizing the information about the sparsity of transition matrix of augmented MDP, we propose another algorithm PUCRLB which enhances upon PUCRL2, both in terms of regret ($O(\sqrt{N})$ dependency on period) and empirical performance. Finally, we propose two other algorithms U-PUCRL2 and U-PUCRLB for extended uncertainty in the environment in which the period is unknown but a set of candidate periods are known. Numerical results demonstrate
    
[^34]: HIVE：利用人类反馈进行指导性视觉编辑

    HIVE: Harnessing Human Feedback for Instructional Visual Editing. (arXiv:2303.09618v1 [cs.CV])

    [http://arxiv.org/abs/2303.09618](http://arxiv.org/abs/2303.09618)

    本文提出了一种新的框架，利用人类反馈进行指导性视觉编辑。通过收集被编辑图像的人类反馈，并学习奖励函数捕捉用户的偏好，可以缓解数据限制所带来的偏差，并提高模型性能。

    

    研究表明，将人类反馈纳入大型语言模型生成的文本对齐到人类偏好至关重要。本文假设，最先进的指导性图像编辑模型，其输出基于输入图像和编辑指令，同样可以从人类反馈中受益，因为其输出可能不符合用户的正确指令和偏好。本文提出了一种利用人类反馈进行指导性视觉编辑（HIVE）的新框架。具体而言，我们在编辑的图像上收集人类反馈并学习奖励函数以捕捉基础用户偏好。随后，我们引入可扩展的扩散模型微调方法，可根据估计的奖励值融入人类偏好。此外，为减轻数据限制带来的偏差，我们贡献了1M训练数据集，3.6K奖励数据集以用于奖励学习，以及1K评估数据集，以提高指导性图像编辑模型的性能。

    Incorporating human feedback has been shown to be crucial to align text generated by large language models to human preferences. We hypothesize that state-of-the-art instructional image editing models, where outputs are generated based on an input image and an editing instruction, could similarly benefit from human feedback, as their outputs may not adhere to the correct instructions and preferences of users. In this paper, we present a novel framework to harness human feedback for instructional visual editing (HIVE). Specifically, we collect human feedback on the edited images and learn a reward function to capture the underlying user preferences. We then introduce scalable diffusion model fine-tuning methods that can incorporate human preferences based on the estimated reward. Besides, to mitigate the bias brought by the limitation of data, we contribute a new 1M training dataset, a 3.6K reward dataset for rewards learning, and a 1K evaluation dataset to boost the performance of inst
    
[^35]: 论检测自我承认技术债务F$_1$-得分的改进方法的研究

    Measuring Improvement of F$_1$-Scores in Detection of Self-Admitted Technical Debt. (arXiv:2303.09617v1 [cs.SE])

    [http://arxiv.org/abs/2303.09617](http://arxiv.org/abs/2303.09617)

    本研究提出了一种利用BERT架构改进SATD检测的方法，在跨项目情况下表现优于所有先前方法的最佳表现。

    

    人工智能和机器学习在自然语言处理（NLP）任务中取得了快速而显著的进展。利用深度学习，研究人员利用软件工程中的版本库注释，提出了一种准确检测20个开源Java项目代码中自我承认技术债务（SATD）的方法。本文提出了一种新的方法，利用转换器中的双向编码器表示（BERT）架构改进SATD检测。为了进行比较，我们重新评估了以前的深度学习方法，并应用分层的10折交叉验证来报告可靠的F$_{1}$-得分。我们在跨项目和内部项目上检验了我们的模型。针对每个上下文，我们使用重新抽样和复制作为增广策略，以考虑数据不平衡的影响。我们发现，我们的训练BERT模型在19个项目的跨项目情况下优于所有先前方法的最佳表现。

    Artificial Intelligence and Machine Learning have witnessed rapid, significant improvements in Natural Language Processing (NLP) tasks. Utilizing Deep Learning, researchers have taken advantage of repository comments in Software Engineering to produce accurate methods for detecting Self-Admitted Technical Debt (SATD) from 20 open-source Java projects' code. In this work, we improve SATD detection with a novel approach that leverages the Bidirectional Encoder Representations from Transformers (BERT) architecture. For comparison, we re-evaluated previous deep learning methods and applied stratified 10-fold cross-validation to report reliable F$_1$-scores. We examine our model in both cross-project and intra-project contexts. For each context, we use re-sampling and duplication as augmentation strategies to account for data imbalance. We find that our trained BERT model improves over the best performance of all previous methods in 19 of the 20 projects in cross-project scenarios. However,
    
[^36]: 强化学习心理治疗AI伴侣与可解释的策略动态

    Psychotherapy AI Companion with Reinforcement Learning Recommendations and Interpretable Policy Dynamics. (arXiv:2303.09601v1 [cs.LG])

    [http://arxiv.org/abs/2303.09601](http://arxiv.org/abs/2303.09601)

    本文介绍了一种使用强化学习生成心理治疗主题推荐的AI伴侣，能够很好地捕获真实数据，并通过可解释的策略轨迹可视化提供对不同奖励信号和不同临床诊断下训练的策略的独特模式。

    

    本文介绍了一种使用Deep Reinforcement Learning（DRL）生成心理治疗主题推荐的强化学习心理治疗AI伴侣。该系统针对四种不同的精神疾病（焦虑症，抑郁症，精神分裂症和自杀病例）使用多目标策略生成器进行生成，同时通过三个不同的工作联盟评分标准（任务，关系和目标）来检验推荐主题的准确性。我们展示了系统能够相对较好地捕获真实数据（治疗师讨论的历史主题），最佳模型的表现因疾病和评级标准而异。为了获得可解释的洞见，我们在2D主成分分析空间和转移矩阵中可视化策略轨迹。这些可视化呈现了在不同奖励信号和不同临床诊断下训练的策略之间的独特模式。本系统在生成多目标策略心理治疗主题方面的成功表现为开发能够帮助治疗师提供个性化治疗的AI伴侣提供了有希望的方向。

    We introduce a Reinforcement Learning Psychotherapy AI Companion that generates topic recommendations for therapists based on patient responses. The system uses Deep Reinforcement Learning (DRL) to generate multi-objective policies for four different psychiatric conditions: anxiety, depression, schizophrenia, and suicidal cases. We present our experimental results on the accuracy of recommended topics using three different scales of working alliance ratings: task, bond, and goal. We show that the system is able to capture the real data (historical topics discussed by the therapists) relatively well, and that the best performing models vary by disorder and rating scale. To gain interpretable insights into the learned policies, we visualize policy trajectories in a 2D principal component analysis space and transition matrices. These visualizations reveal distinct patterns in the policies trained with different reward signals and trained on different clinical diagnoses. Our system's succe
    
[^37]: 基于残差物理学习和系统识别的浮力辅助腿式机器人的模拟到真实世界转移方案

    Residual Physics Learning and System Identification for Sim-to-real Transfer of Policies on Buoyancy Assisted Legged Robots. (arXiv:2303.09597v1 [cs.RO])

    [http://arxiv.org/abs/2303.09597](http://arxiv.org/abs/2303.09597)

    本文利用残差物理学习方法和系统识别，在轻量化、柔软机器人BALLU上实现了从模拟到真实世界的稳健控制转移。通过使用强化学习训练外部力策略以匹配真实世界轨迹，建模残差物理学，提高了仿真精度。

    

    浮力辅助轻量化腿部机器人具有轻便和柔软的特性，与许多沉重和刚性机器人相比，有很大的潜力提供内在安全性交互。然而，它们独特而敏感的动态特性对于在真实世界中获得稳健的控制策略而言是具有挑战性的。在这项工作中，我们通过系统识别和我们的新颖的残差物理学习方法——环境模型（EnvMimic），展示了在BALLU机器人上稳健的模拟到真实世界控制策略转移。首先，我们通过收集硬件数据并优化模拟参数来建模执行器的非线性动态。我们不依赖标准的监督式学习公式，而是利用深度强化学习来训练一个外部力策略以匹配真实世界轨迹，这使我们能够更准确地建模残差物理学。我们通过比较仿真轨迹来分析改进的仿真准确度。

    The light and soft characteristics of Buoyancy Assisted Lightweight Legged Unit (BALLU) robots have a great potential to provide intrinsically safe interactions in environments involving humans, unlike many heavy and rigid robots. However, their unique and sensitive dynamics impose challenges to obtaining robust control policies in the real world. In this work, we demonstrate robust sim-to-real transfer of control policies on the BALLU robots via system identification and our novel residual physics learning method, Environment Mimic (EnvMimic). First, we model the nonlinear dynamics of the actuators by collecting hardware data and optimizing the simulation parameters. Rather than relying on standard supervised learning formulations, we utilize deep reinforcement learning to train an external force policy to match real-world trajectories, which enables us to model residual physics with greater fidelity. We analyze the improved simulation fidelity by comparing the simulation trajectories
    
[^38]: 保护社会免受AI滥用：何时限制AI能力是必要的？

    Protecting Society from AI Misuse: When are Restrictions on Capabilities Warranted?. (arXiv:2303.09377v1 [cs.AI])

    [http://arxiv.org/abs/2303.09377](http://arxiv.org/abs/2303.09377)

    随着人工智能系统能力不断提升，控制某些能力将有助于防止其滥用，这些限制可能包括控制访问、使用目的、输出与溯源以及开发资源，非AI能力限制也是必要的。尽管可能会降低使用率而增加滥用风险，但这些限制是当其他干预行不通、潜在危害性高、有有针对性方式干预时所必要的。

    

    随着人工智能（AI）系统不断提高能力，其被用于造成伤害的情况将会越来越多。事实上，AI系统已经开始用于自动化的欺诈活动、侵犯人权、创建有害的虚假图像以及识别危险毒素。为了防止AI的某些滥用，我们认为有必要对某些能力进行有针对性的干预。这些限制可能包括控制谁能访问某些类型的AI模型、它们可以用于什么、是否过滤输出或者可以追溯到使用者以及开发它们所需的资源。我们还认为，一些对滥用所需的非AI能力限制也是必要的。虽然能力限制可能会降低使用率而不是滥用率（存在不利的滥用-使用权衡），但我们认为当其他干预行不通、潜在滥用的危害性很高，并且有有针对性的方式来干预能力时，干预能力是必要的。

    Artificial intelligence (AI) systems will increasingly be used to cause harm as they grow more capable. In fact, AI systems are already starting to be used to automate fraudulent activities, violate human rights, create harmful fake images, and identify dangerous toxins. To prevent some misuses of AI, we argue that targeted interventions on certain capabilities will be warranted. These restrictions may include controlling who can access certain types of AI models, what they can be used for, whether outputs are filtered or can be traced back to their user, and the resources needed to develop them. We also contend that some restrictions on non-AI capabilities needed to cause harm will be required. Though capability restrictions risk reducing use more than misuse (facing an unfavorable Misuse-Use Tradeoff), we argue that interventions on capabilities are warranted when other interventions are insufficient, the potential harm from misuse is high, and there are targeted ways to intervene on
    
[^39]: 构建鲁棒的孟加拉复杂命名实体识别模型

    Towards Robust Bangla Complex Named Entity Recognition. (arXiv:2303.09306v1 [cs.CL])

    [http://arxiv.org/abs/2303.09306](http://arxiv.org/abs/2303.09306)

    本研究构建了基于 CRF 和深度学习（如 BanglaBERT）的鲁棒孟加拉复杂命名实体识别模型，解决了 CNER 任务，填补了孟加拉语复杂命名实体识别领域的空白。

    

    命名实体识别 (NER) 是自然语言处理中的基础任务，包括在文本中识别和分类命名实体。尽管孟加拉语是全球第七大使用语言，但针对孟加拉语复杂命名实体识别的工作还很少。CNER 是一项更具挑战性的任务，因为它涉及识别和分类复杂和复合实体，而这在孟加拉语中不常见。在本文中，我们提出了解决 BanglaCoNER 数据集上的 CNER 任务的获胜解决方案，使用了两种不同的方法，即条件随机场 (CRF) 和基于 finetuning transformer 的深度学习模型（如 BanglaBERT）。数据集包括 15300 个用于训练的句子和 800 个用于验证的句子，格式为 .conll。对数据集的探索性数据分析 (EDA) 揭示出数据集有 7 种不同的 NER 标签，其中有英语单词的明显存在。

    Named Entity Recognition (NER) is a fundamental task in natural language processing that involves identifying and classifying named entities in text. But much work hasn't been done for complex named entity recognition in Bangla, despite being the seventh most spoken language globally. CNER is a more challenging task than traditional NER as it involves identifying and classifying complex and compound entities, which are not common in Bangla language. In this paper, we present the winning solution of Bangla Complex Named Entity Recognition Challenge - addressing the CNER task on BanglaCoNER dataset using two different approaches, namely Conditional Random Fields (CRF) and finetuning transformer based Deep Learning models such as BanglaBERT.  The dataset consisted of 15300 sentences for training and 800 sentences for validation, in the .conll format. Exploratory Data Analysis (EDA) on the dataset revealed that the dataset had 7 different NER tags, with notable presence of English words, s
    
[^40]: 基于t-SPN和滤波的细胞分类的最大间隔学习

    Maximum Margin Learning of t-SPNs for Cell Classification with Filtering. (arXiv:2303.09065v1 [cs.LG])

    [http://arxiv.org/abs/2303.09065](http://arxiv.org/abs/2303.09065)

    本研究提出了一种基于t-SPN算法和滤波技术的细胞分类方法，通过最大化边缘和L2正则化，该方法在HEp-2和Feulgen基准数据集上取得了最高的准确率。

    

    本文探讨了一种基于深度概率体系结构的算法，称为树形求和产品网络(t-SPN)，用于细胞分类。构建t-SPN的目的是表示未归一化概率作为最相似的细胞类别的条件概率。通过最大化边缘来学习构建的t-SPN体系结构，该边缘是真实标签和最有竞争力的错误标签之间的条件概率差。为了增强体系结构的泛化能力，在学习过程中考虑了L2正则化（REG）和最大间隔（MM）标准。为了突出细胞特征，本文探讨了两种通用的高通滤波器的有效性：理想高通滤波和拉普拉斯滤波(Log)。在HEp-2和Feulgen基准数据集上，基于最大间隔准则与正则化学习的t-SPN体系结构产生了最高的准确率。

    An algorithm based on a deep probabilistic architecture referred to as a tree-structured sum-product network (t-SPN) is considered for cell classification. The t-SPN is constructed such that the unnormalized probability is represented as conditional probabilities of a subset of most similar cell classes. The constructed t-SPN architecture is learned by maximizing the margin, which is the difference in the conditional probability between the true and the most competitive false label. To enhance the generalization ability of the architecture, L2-regularization (REG) is considered along with the maximum margin (MM) criterion in the learning process. To highlight cell features, this paper investigates the effectiveness of two generic high-pass filters: ideal high-pass filtering and the Laplacian of Gaussian (LOG) filtering. On both HEp-2 and Feulgen benchmark datasets, the t-SPN architecture learned based on the max-margin criterion with regularization produced the highest accuracy rate co
    
[^41]: 通识知识辅助的资源受限和细粒度目标检测的深度学习方法

    Commonsense Knowledge Assisted Deep Learning for Resource-constrained and Fine-grained Object Detection. (arXiv:2303.09026v1 [cs.CV])

    [http://arxiv.org/abs/2303.09026](http://arxiv.org/abs/2303.09026)

    本文提出了一种通识知识辅助的细粒度目标检测方法，利用通识知识推理模块处理由基准深度学习检测器给出的粗粒度标签，从而提高目标检测的准确性。经过实验验证，该方法相比于现有方法需要更少的计算量和标注资源。

    

    本文考虑边缘计算等资源受限场景下的细粒度图像目标检测问题。针对使用现代深度学习目标检测器时需要使用大型模型和大量数据标注的精准细粒度检测需求，提出一种方法，即利用通识知识辅助粗粒度目标检测器获取精准的细粒度检测结果。引入通识知识推理模块(CKIM)处理由基准深度学习检测器给出的粗粒度标签，从而生成细粒度标签。论文中考虑了模糊规则和清晰规则的推理，前者用于处理目标语义标签的模糊性。实验结果表明所提方法可以有效提高目标检测的准确性，同时相比于现有方法需要更少的计算量和标注资源。

    In this paper, we consider fine-grained image object detection in resource-constrained cases such as edge computing. Deep learning (DL), namely learning with deep neural networks (DNNs), has become the dominating approach to object detection. To achieve accurate fine-grained detection, one needs to employ a large enough DNN model and a vast amount of data annotations, which brings a challenge for using modern DL object detectors in resource-constrained cases. To this end, we propose an approach, which leverages commonsense knowledge to assist a coarse-grained object detector to get accurate fine-grained detection results. Specifically, we introduce a commonsense knowledge inference module (CKIM) to process coarse-grained lables given by a benchmark DL detector to produce fine-grained lables. We consider both crisp-rule and fuzzy-rule based inference in our CKIM; the latter is used to handle ambiguity in the target semantic labels. We implement our method based on several modern DL dete
    
[^42]: KGNv2: 基于关键点的RGB-D输入六自由度抓取合成中的尺度和姿态分离

    KGNv2: Separating Scale and Pose Prediction for Keypoint-based 6-DoF Grasp Synthesis on RGB-D input. (arXiv:2303.05617v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2303.05617](http://arxiv.org/abs/2303.05617)

    本文提出了一种基于关键点的RGB-D输入的六自由度抓取姿态合成方法，既可以从关键点检测中预测抓取姿态，也可以预测相对于相机的尺度，实验结果表明其优越性。

    

    本文提出了一种6自由度抓取姿态合成方法，该方法基于关键点从2D/2.5D输入中进行。在前期研究中，基于关键点的抓取检测器已经证明了良好的结果，其中彩色图像提供的额外视觉信息弥补了嘈杂的深度感知。然而，它严重依赖于准确预测图像空间中的关键点位置。因此，我们设计了一种新的抓取生成网络，既可以从关键点检测中预测抓取姿态，也可以预测相对于相机的尺度。另外，我们还重新设计了关键点输出空间，以减轻关键点预测噪声对透视n点(PnP)算法的负面影响。实验结果表明，所提出的方法在性能上比基线表现出了显著的优越性，验证了我们方法的有效性。最后，尽管是在简单的合成对象上训练的，我们的方法也可以用于真实物体上的抓取。

    We propose a new 6-DoF grasp pose synthesis approach from 2D/2.5D input based on keypoints. Keypoint-based grasp detector from image input has demonstrated promising results in the previous study, where the additional visual information provided by color images compensates for the noisy depth perception. However, it relies heavily on accurately predicting the location of keypoints in the image space. In this paper, we devise a new grasp generation network that reduces the dependency on precise keypoint estimation. Given an RGB-D input, our network estimates both the grasp pose from keypoint detection as well as scale towards the camera. We further re-design the keypoint output space in order to mitigate the negative impact of keypoint prediction noise to Perspective-n-Point (PnP) algorithm. Experiments show that the proposed method outperforms the baseline by a large margin, validating the efficacy of our approach. Finally, despite trained on simple synthetic objects, our method demons
    
[^43]: 使用不确定性估计指导伪标签的无源自适应域自适应方法研究

    Guiding Pseudo-labels with Uncertainty Estimation for Source-free Unsupervised Domain Adaptation. (arXiv:2303.03770v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.03770](http://arxiv.org/abs/2303.03770)

    本研究提出一种基于损失重新加权策略的无源自适应域自适应（SF-UDA）方法，用于适应目标域，其关键是通过估计伪标签的不确定性来指导其进一步精化，并利用自监督对比框架作为目标空间的正则化器以提高预测精度。

    

    标准的无监督域自适应方法假定在适应过程中同时可用源域和目标域数据。在这项工作中，我们研究了无源自适应域自适应（SF-UDA）方法，它是UDA的一个特殊情况，在该情况下，模型在没有访问源数据的情况下适应目标域。我们提出了一种新的方法来处理SF-UDA设置，基于损失重新加权策略，以增强对伪标签的噪声的鲁棒性。该分类损失基于估计其不确定性来重新加权，以指导伪标签的进一步精化，并通过聚集相邻样本的知识来逐步提高其准确性。此外，我们引入了自监督对比框架来作为目标空间的正则化器，以增强知识的聚合。同时，我们提出了一种负样本对排除策略，以识别和排除由共享相同特征的样本构成的负样本对。

    Standard Unsupervised Domain Adaptation (UDA) methods assume the availability of both source and target data during the adaptation. In this work, we investigate Source-free Unsupervised Domain Adaptation (SF-UDA), a specific case of UDA where a model is adapted to a target domain without access to source data. We propose a novel approach for the SF-UDA setting based on a loss reweighting strategy that brings robustness against the noise that inevitably affects the pseudo-labels. The classification loss is reweighted based on the reliability of the pseudo-labels that is measured by estimating their uncertainty. Guided by such reweighting strategy, the pseudo-labels are progressively refined by aggregating knowledge from neighbouring samples. Furthermore, a self-supervised contrastive framework is leveraged as a target space regulariser to enhance such knowledge aggregation. A novel negative pairs exclusion strategy is proposed to identify and exclude negative pairs made of samples shari
    
[^44]: 利用权重修剪和奇异值分解在嵌入式设备上进行可扩展物体检测

    Scalable Object Detection on Embedded Devices Using Weight Pruning and Singular Value Decomposition. (arXiv:2303.02735v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.02735](http://arxiv.org/abs/2303.02735)

    本文提出了一种利用权重修剪和奇异值分解来优化物体检测模型的方法，并在自定义数据集上进行了评估，结果表明此方法可以在平衡准确性、速度和模型大小过程中有效地优化物体检测模型性能。

    

    本文提出了一种组合利用权重修剪和奇异值分解（SVD）进行优化物体检测模型的方法。在https://universe.roboflow.com/roboflow-100/street-work获取的街道工作图像自定义数据集上对所提出的方法进行了评估。数据集包含611个训练图像，175个验证图像和87个具有7个分类的测试图像。我们通过帧率、平均精度（mAP@50）和权重大小等方面比较了优化后的模型与原始未优化模型的性能。结果表明，权重修剪+SVD模型具有0.724 mAP@50，帧率为1.48 FPS，权重大小为12.1 MB，优于原始模型（0.717 mAP@50，1.50 FPS和12.3 MB）。所有模型的精度-召回曲线也绘制出来。我们的研究表明，所提出的方法可以在平衡准确性、速度和模型大小的同时有效地优化物体检测模型。

    This paper presents a method for optimizing object detection models by combining weight pruning and singular value decomposition (SVD). The proposed method was evaluated on a custom dataset of street work images obtained from https://universe.roboflow.com/roboflow-100/street-work. The dataset consists of 611 training images, 175 validation images, and 87 test images with 7 classes. We compared the performance of the optimized models with the original unoptimized model in terms of frame rate, mean average precision (mAP@50), and weight size. The results show that the weight pruning + SVD model achieved a 0.724 mAP@50 with a frame rate of 1.48 FPS and a weight size of 12.1 MB, outperforming the original model (0.717 mAP@50, 1.50 FPS, and 12.3 MB). Precision-recall curves were also plotted for all models. Our work demonstrates that the proposed method can effectively optimize object detection models while balancing accuracy, speed, and model size.
    
[^45]: 通过委派在人工智能与人类混合系统中弥补感知失败

    Compensating for Sensing Failures via Delegation in Human-AI Hybrid Systems. (arXiv:2303.01300v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2303.01300](http://arxiv.org/abs/2303.01300)

    本文探讨了人工智能与人类混合系统中的感知失败问题，提出了通过委派管理代理来选择人类或自主系统控制，以补偿可能发生的感知缺失，保障系统安全的方法。

    

    随着智能系统在自主行为或增强人类活动方面的普及，考虑人类、自主系统或两者都会因多种因素之一（例如感知）而出现失败的情况非常重要。无论是人类还是自主代理的失败都可能导致降低性能水平，甚至严重到导致伤害或死亡。本文考虑了混合人工智能团队的情况，其中管理代理负责识别何时执行委派任务以及人类或自主系统是否应该掌控。在这种情况下，管理者将根据他们的感知能力和可能的缺陷，估计最佳行动，以预测人工智能和人类代理的失败几率。我们模拟环境背景如何导致或加剧感知能力的缺陷，以提供情况。

    Given an increasing prevalence of intelligent systems capable of autonomous actions or augmenting human activities, it is important to consider scenarios in which the human, autonomous system, or both can exhibit failures as a result of one of several contributing factors (e.g. perception). Failures for either humans or autonomous agents can lead to simply a reduced performance level, or a failure can lead to something as severe as injury or death. For our topic, we consider the hybrid human-AI teaming case where a managing agent is tasked with identifying when to perform a delegation assignment and whether the human or autonomous system should gain control. In this context, the manager will estimate its best action based on the likelihood of either (human, autonomous) agent failure as a result of their sensing capabilities and possible deficiencies. We model how the environmental context can contribute to, or exacerbate, the sensing deficiencies. These contexts provide cases where the
    
[^46]: 隐藏的宝石：使用跨模态监督的4D雷达场景流学习

    Hidden Gems: 4D Radar Scene Flow Learning Using Cross-Modal Supervision. (arXiv:2303.00462v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.00462](http://arxiv.org/abs/2303.00462)

    本研究提出了一种使用跨模态监督学习的新方法，用于精确地估计4D雷达场景流，并在运动分割和自我运动估计等子任务中显示了其实用性。

    

    本文提出一种通过跨模态学习进行4D雷达基础场景流量估计的新方法。我们的方法受到现代自动驾驶车辆中同一位置的传感器冗余的启发。这种冗余隐含地为雷达场景流估计提供了各种形式的监督线索。具体来说，我们提出了一个多任务模型，针对已确定的跨模态学习问题，提出了损失函数，以使用多个跨模态约束机会有效地进行场景流量估计进行模型训练。广泛的实验显示了我们方法的最先进性能，并证明了跨模态监督学习用于推断更准确的4D雷达场景流的有效性。我们还展示了它对两个子任务-运动分割和自我运动估计的有用性。我们的源代码将在https://github.com/Toytiny/CMFlow上提供。

    This work proposes a novel approach to 4D radar-based scene flow estimation via cross-modal learning. Our approach is motivated by the co-located sensing redundancy in modern autonomous vehicles. Such redundancy implicitly provides various forms of supervision cues to the radar scene flow estimation. Specifically, we introduce a multi-task model architecture for the identified cross-modal learning problem and propose loss functions to opportunistically engage scene flow estimation using multiple cross-modal constraints for effective model training. Extensive experiments show the state-of-the-art performance of our method and demonstrate the effectiveness of cross-modal supervised learning to infer more accurate 4D radar scene flow. We also show its usefulness to two subtasks - motion segmentation and ego-motion estimation. Our source code will be available on https://github.com/Toytiny/CMFlow.
    
[^47]: Eagle: 基于网格变换器的湍流流体动力学大规模学习

    Eagle: Large-Scale Learning of Turbulent Fluid Dynamics with Mesh Transformers. (arXiv:2302.10803v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.10803](http://arxiv.org/abs/2302.10803)

    EAGLE引入了大规模数据集和新模型，其中包括一种新的网格变换器，能够预测具有挑战性的流体动力学数据集中的压力和速度变化。

    

    传统上通过模拟和计算数值模型解决Navier-Stokes方程来估计流体动力学，即使在高端硬件上也要耗费大量的计算时间和资源，这是一个极其复杂的问题。近年来，机器学习，特别是基于图神经网络（GNN）和变种的方法已经开始尝试解决此类问题，但是这些方法都只针对几何形状固定的静态场景中的静态对象进行了数据集的训练和评估。我们试图超越现有工作的复杂度，引入一种新的模型、方法和基准。我们提出了EAGLE，一个包含1.1百万个二维网格的大规模数据集，这些网格是由一个移动流体源引起的不稳定流体动力学模拟生成的，其相互作用导致了非线性场景结构，其中包括三种不同类型的600个不同场景。为了对这个具有挑战性的EAGLE数据集进行未来的压力和速度预测，我们引入了一种新的网格变换器，它利用了节点聚类、图池化和全局池化。

    Estimating fluid dynamics is classically done through the simulation and integration of numerical models solving the Navier-Stokes equations, which is computationally complex and time-consuming even on high-end hardware. This is a notoriously hard problem to solve, which has recently been addressed with machine learning, in particular graph neural networks (GNN) and variants trained and evaluated on datasets of static objects in static scenes with fixed geometry. We attempt to go beyond existing work in complexity and introduce a new model, method and benchmark. We propose EAGLE, a large-scale dataset of 1.1 million 2D meshes resulting from simulations of unsteady fluid dynamics caused by a moving flow source interacting with nonlinear scene structure, comprised of 600 different scenes of three different types. To perform future forecasting of pressure and velocity on the challenging EAGLE dataset, we introduce a new mesh transformer. It leverages node clustering, graph pooling and glo
    
[^48]: 现象意识状态的丰富性和难以言说性的来源

    Sources of Richness and Ineffability for Phenomenally Conscious States. (arXiv:2302.06403v3 [q-bio.NC] UPDATED)

    [http://arxiv.org/abs/2302.06403](http://arxiv.org/abs/2302.06403)

    本文提供了一个信息论动力系统的视角，来解释意识的丰富性和难以言说性。在我们的框架中，意识体验的丰富性对应于意识状态中的信息量，而难以言说性则对应于不同处理阶段丢失的信息量。

    This paper provides an information theoretic dynamical systems perspective on the richness and ineffability of consciousness. In their framework, the richness of conscious experience corresponds to the amount of information in a conscious state and ineffability corresponds to the amount of information lost at different stages of processing.

    意识状态（即有某种感受的状态）似乎既丰富又充满细节，又难以完全描述或回忆。特别是难以言说性的问题是哲学上长期存在的问题，部分激发了解释鸿沟的信念：意识不能归结为基础物理过程。在这里，我们提供了一个信息论动力系统的视角，来解释意识的丰富性和难以言说性。在我们的框架中，意识体验的丰富性对应于意识状态中的信息量，而难以言说性则对应于不同处理阶段丢失的信息量。我们描述了工作记忆中的吸引子动力学如何导致我们原始体验的贫乏回忆，语言的离散符号性质不足以描述体验的丰富和高维结构，以及认知功能相似性如何影响体验的共享和交流。

    Conscious states (states that there is something it is like to be in) seem both rich or full of detail, and ineffable or hard to fully describe or recall. The problem of ineffability, in particular, is a longstanding issue in philosophy that partly motivates the explanatory gap: the belief that consciousness cannot be reduced to underlying physical processes. Here, we provide an information theoretic dynamical systems perspective on the richness and ineffability of consciousness. In our framework, the richness of conscious experience corresponds to the amount of information in a conscious state and ineffability corresponds to the amount of information lost at different stages of processing. We describe how attractor dynamics in working memory would induce impoverished recollections of our original experiences, how the discrete symbolic nature of language is insufficient for describing the rich and high-dimensional structure of experiences, and how similarity in the cognitive function o
    
[^49]: LAVA：基于颗粒化神经元级别可解释性的静脉荧光成像诊断阿尔茨海默病的 AI

    LAVA: Granular Neuron-Level Explainable AI for Alzheimer's Disease Assessment from Fundus Images. (arXiv:2302.03008v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.03008](http://arxiv.org/abs/2302.03008)

    LAVA是一个基于颗粒化神经元级别可解释性的 AI 框架，可以直接从静脉荧光成像中评估阿尔茨海默病的进程，验证视网膜血管系统为 AD 评估的生物标志物和诊断手段。

    

    阿尔茨海默病（AD）是渐进性神经退行性疾病，是痴呆的主要原因。早期诊断对患者从潜在的干预和治疗中获益至关重要。视网膜因其与大脑的解剖联系，被假定为 AD 检测的诊断部位。然而相关的 AI 模型尚未提供关于决策的合理解释，也无法推断疾病进展的阶段。因此，我们提出了一个新颖的模型无关的可解释性 AI 框架，称为 Granular Neuron-level Explainer（LAVA），它是一个解释原型，可以探测卷积神经网络（CNN）模型的中间层以直接从视网膜成像中评估 AD 进程。本方法应用于验证视网膜血管系统为 AD 评估的生物标志物和诊断手段。通过 UK Biobank 认知测试和血管鉴定。

    Alzheimer's Disease (AD) is a progressive neurodegenerative disease and the leading cause of dementia. Early diagnosis is critical for patients to benefit from potential intervention and treatment. The retina has been hypothesized as a diagnostic site for AD detection owing to its anatomical connection with the brain. Developed AI models for this purpose have yet to provide a rational explanation about the decision and neither infer the stage of disease's progression. Along this direction, we propose a novel model-agnostic explainable-AI framework, called Granular Neuron-level Explainer (LAVA), an interpretation prototype that probes into intermediate layers of the Convolutional Neural Network (CNN) models to assess the AD continuum directly from the retinal imaging without longitudinal or clinical evaluation. This method is applied to validate the retinal vasculature as a biomarker and diagnostic modality for Alzheimer's Disease (AD) evaluation. UK Biobank cognitive tests and vascular
    
[^50]: 知识图谱补全的预训练框架

    A Pre-training Framework for Knowledge Graph Completion. (arXiv:2302.02614v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.02614](http://arxiv.org/abs/2302.02614)

    本研究提出了一个基于网络的预训练框架NetPeace，能够在知识图谱补全任务中获得显著提升，尤其是在稠密的知识图上表现更好。

    

    知识图谱补全(KGC)是确定知识图谱中新事实的有效方法之一。除了一些基于图网络的方法外，大部分KGC方法倾向于基于独立的三元组进行训练，很难考虑到知识网络中包含的全局网络连接信息。为了解决这些问题，本研究提出了一个简单有效的基于网络的预训练框架NetPeace，该框架考虑了知识图谱中全局网络连接信息和本地三元组关系的影响。实验表明，NetPeace框架中的多个KGC模型对基准测试中（例如，在FB15k-237数据集上，TuckER的Hits@1得分增加了36.45%，MRR得分增加了27.40%），特别是稠密知识图的提升持续且显著。在具有挑战性的低资源任务上，受益于KG的全局特征，NetPeace获得了更高的性能（104.03%的MRR增益）。

    Knowledge graph completion (KGC) is one of the effective methods to identify new facts in knowledge graph. Except for a few methods based on graph network, most of KGC methods trend to be trained based on independent triples, while are difficult to take a full account of the information of global network connection contained in knowledge network. To address these issues, in this study, we propose a simple and effective Network-based Pre-training framework for knowledge graph completion (termed NetPeace), which takes into account the information of global network connection and local triple relationships in knowledge graph. Experiments show that in NetPeace framework, multiple KGC models yields consistent and significant improvements on benchmarks (e.g., 36.45% Hits@1 and 27.40% MRR improvements for TuckER on FB15k-237), especially dense knowledge graph. On the challenging low-resource task, NetPeace that benefits from the global features of KG achieves higher performance (104.03% MRR a
    
[^51]: 基于Transformers的贪婪排序优化翻译性能

    Greedy Ordering of Layer Weight Matrices in Transformers Improves Translation. (arXiv:2302.02123v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.02123](http://arxiv.org/abs/2302.02123)

    本论文提出了一种基于贪婪重排权重矩阵的算法AEIUOrder，能够最大化总的经过充分训练的层所贡献的"well-trainedness"指标进行优化，从而提高翻译质量并在各种翻译任务上达到最佳性能。

    

    先前的工作试图在多头注意力和前馈子图层的层次上理解基于Transformer的编码器-解码器架构的内部结构和功能。但是，如果不检查低层次的结构，就不能深入理解子层重排背后的动机。本文通过AEIUOrder算法，通过衡量经过充分训练的层的Heavy-Tailed Self-Regularization（HT-SR）指标，贪婪地对编码器中的层重量矩阵进行重新排序，然后相应地排序解码器矩阵。我们的结果表明，通过最大化总的经过充分训练的层所贡献的"well-trainedness"指标进行重排，可以更好地学习表示，并生成更高质量的翻译输出，在各种翻译任务上达到了最好的性能。

    Prior work has attempted to understand the internal structures and functionalities of Transformer-based encoder-decoder architectures on the level of multi-head attention and feed-forward sublayers. Interpretations have focused on the encoder and decoder, along with the combinatorial possibilities of the self-attention, cross-attention, and feed-forward sublayers. However, without examining the low-level structures, one gains limited understanding of the motivation behind sublayer reordering. Could we dive into the sublayer abstraction and permute layer weight matrices to improve the quality of translation? We propose AEIUOrder to greedily reorder layer weight matrices in the encoder by their well-trainedness, as measured by Heavy-Tailed Self-Regularization (HT-SR) metrics, and order the decoder matrices correspondingly. Our results suggest that greedily reordering layer weight matrices to maximize Total well-trainedness facilitates the model to learn representations and generate trans
    
[^52]: 匹配标本作为下一句预测：自然语言处理科学教育中的零样本学习自动评分

    Matching Exemplar as Next Sentence Prediction (MeNSP): Zero-shot Prompt Learning for Automatic Scoring in Science Education. (arXiv:2301.08771v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2301.08771](http://arxiv.org/abs/2301.08771)

    本研究提出了一种零样本学习自动评分的方法，利用预训练的语言模型配合匹配标本作为下一句预测技术，成功应用于科学教育领域的论证任务，极大地减少了训练成本和时间。

    

    开发能够自动评分科学问题的学生书面答案的模型对于科学教育至关重要。然而，收集和标记足够的学生答案以训练模型是耗时和费用高昂的。最近的研究表明，预训练的语言模型（PLMs）可以在不需要prompt调整的情况下适应下游任务。然而，在科学教育中还没有使用过这种提示方法的研究。由于学生的答案是用自然语言呈现的，因此使用提示将评分过程对齐为下一句预测任务可以跳过昂贵的调整阶段。在这项研究中，我们通过匹配标本作为下一句预测（MeNSP）开发了一种零样本自动评分方法。这种方法不需要训练样本。我们首先在评分三个科学论证任务中应用MeNSP，并发现机器-人评分的一致性，Cohen的Kappa系数在0.30到0.57之间，F1分数

    Developing models to automatically score students' written responses to science problems is critical for science education. However, collecting and labeling sufficient student responses for training models is time and cost-consuming. Recent studies suggest that pre-trained language models (PLMs) can be adapted to downstream tasks without fine-tuning with prompts. However, no research has employed such a prompt approach in science education. As student responses are presented with natural language, aligning the scoring procedure as the next sentence prediction task using prompts can skip the costly fine-tuning stage. In this study, we developed a zero-shot approach to automatically score student responses via Matching Exemplars as Next Sentence Prediction (MeNSP). This approach employs no training samples. We first apply MeNSP in scoring three assessment tasks of scientific argumentation and found machine-human scoring agreements, Cohen's Kappa ranges from 0.30 to 0.57, and F1 score ran
    
[^53]: SIRL: 基于相似度的隐式表示学习

    SIRL: Similarity-based Implicit Representation Learning. (arXiv:2301.00810v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2301.00810](http://arxiv.org/abs/2301.00810)

    SIRL是基于人提供相似度判断的任务表示学习方法，能够帮助机器人识别和隔离因果特征并生成适当行为，在各种机器人任务上表现优秀。

    

    当机器人使用高容量模型以原始状态作为输入学习奖励函数时，他们需要同时学习任务的“特征”表示及如何将这些特征组合成一个目标。如果他们尝试从用于教授完整奖励函数的输入中同时学习两者，很容易产生包含数据中假相关性的表示，导致不能推广到新的环境中。我们的最终目标是使机器人能够识别和隔离人们实际关心和使用的因果特征，当表示状态和行为时。我们的想法是，我们可以通过询问用户认为相似的行为来调整这种表示：如果关键特征相似，这些行为将相似，即使低层行为有所不同；相反，如果即使有一个关键特征不同，那么这些行为就会有所不同。这正是使机器人能够学习任务目标并生成适当行为的关键。为了实现这一目标，我们提出了基于相似度的隐式表示学习（SIRL）方法，该方法使用由人提供的相似性判断来学习隐式任务表示。我们在各种机器人任务上评估SIRL，并展示它在最终任务性能和泛化能力方面胜过其他表示学习方法。

    When robots learn reward functions using high capacity models that take raw state directly as input, they need to both learn a representation for what matters in the task -- the task ``features" -- as well as how to combine these features into a single objective. If they try to do both at once from input designed to teach the full reward function, it is easy to end up with a representation that contains spurious correlations in the data, which fails to generalize to new settings. Instead, our ultimate goal is to enable robots to identify and isolate the causal features that people actually care about and use when they represent states and behavior. Our idea is that we can tune into this representation by asking users what behaviors they consider similar: behaviors will be similar if the features that matter are similar, even if low-level behavior is different; conversely, behaviors will be different if even one of the features that matter differs. This, in turn, is what enables the rob
    
[^54]: 学习选择典型部分以解释序列数据建模

    Learning to Select Prototypical Parts for Interpretable Sequential Data Modeling. (arXiv:2212.03396v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.03396](http://arxiv.org/abs/2212.03396)

    提出了一种自解释选择模型，使用典型的概念的线性组合来解释其自身的预测，通过选择大部分激活不同概念的子序列作为典型部分来解释模型决策，为了更好的解释性，还设计了多个约束条件。

    

    原型解释方法通过将样本与参考集中的典型代表进行相似度比较，提供了模型预测的直观解释。在序列数据建模领域，原型的相似性计算通常基于编码表示向量。然而，由于高度递归的函数，原型解释与原始输入之间通常存在明显差异。在本文中，我们提出了一种自解释选择模型（SESM），它使用典型的概念的线性组合来解释其自身的预测。该模型采用基于案例的推理思想，通过选择大部分激活不同概念的子序列作为典型部分来解释模型决策，用户可以将其与选择自不同示例输入的子序列进行比较以理解模型决策。为了更好的解释性，我们设计了多个约束条件，包括多样性，稳定性等。

    Prototype-based interpretability methods provide intuitive explanations of model prediction by comparing samples to a reference set of memorized exemplars or typical representatives in terms of similarity. In the field of sequential data modeling, similarity calculations of prototypes are usually based on encoded representation vectors. However, due to highly recursive functions, there is usually a non-negligible disparity between the prototype-based explanations and the original input. In this work, we propose a Self-Explaining Selective Model (SESM) that uses a linear combination of prototypical concepts to explain its own predictions. The model employs the idea of case-based reasoning by selecting sub-sequences of the input that mostly activate different concepts as prototypical parts, which users can compare to sub-sequences selected from different example inputs to understand model decisions. For better interpretability, we design multiple constraints including diversity, stabilit
    
[^55]: 与任务导向对话的意图识别相关的话语嵌入和聚类方法的分析

    Analysis of Utterance Embeddings and Clustering Methods Related to Intent Induction for Task-Oriented Dialogue. (arXiv:2212.02021v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.02021](http://arxiv.org/abs/2212.02021)

    本文旨在研究任务导向对话中的意图识别问题，并提出两个关键因素：聚类算法和用户话语嵌入空间。实验证明，利用预训练的MiniLM与层次聚类相结合可以显著提高意图归纳任务的效果。

    

    本文重点研究无监督方法，以克服设计任务导向对话图谱中的典型挑战：为每个对话转折指定意图标签（意图聚类）并基于意图聚类方法生成一组意图（意图归纳）。我们假设自动归纳意图有两个显著因素：（1）意图标签的聚类算法和（2）用户话语嵌入空间。 我们根据DSTC11评估比较了现有的成品聚类模型和嵌入。我们的实验表明，认真考虑意图归纳任务中话语嵌入和聚类方法的综合选择是必要的。我们还发现，利用预训练的MiniLM与层次聚类相结合可显著提高意图归纳任务中的NMI，ARI，F1，准确性和示例覆盖。源代码可在https://github.com/Jeiyoon/dstc11-track2上获得。

    The focus of this work is to investigate unsupervised approaches to overcome quintessential challenges in designing task-oriented dialog schema: assigning intent labels to each dialog turn (intent clustering) and generating a set of intents based on the intent clustering methods (intent induction). We postulate there are two salient factors for automatic induction of intents: (1) clustering algorithm for intent labeling and (2) user utterance embedding space. We compare existing off-the-shelf clustering models and embeddings based on DSTC11 evaluation. Our extensive experiments demonstrate that the combined selection of utterance embedding and clustering method in the intent induction task should be carefully considered. We also present that pretrained MiniLM with Agglomerative clustering shows significant improvement in NMI, ARI, F1, accuracy and example coverage in intent induction tasks. The source codes are available at https://github.com/Jeiyoon/dstc11-track2.
    
[^56]: 通过CF-逼近空间的表示领域

    Representations of Domains via CF-approximation Spaces. (arXiv:2211.17099v2 [math.RA] UPDATED)

    [http://arxiv.org/abs/2211.17099](http://arxiv.org/abs/2211.17099)

    本文研究了通过CF-逼近空间的表示领域，介绍了CF-逼近空间和CF闭集的概念，并且证明了CF-逼近空间中的CF闭集族是连续领域，使用范畴论的方法，证明了CF-逼近空间和CF-可逼近关系的范畴与连续领域和Scott连续映射的范畴等同。

    

    领域的表示通常指将领域表示为一些含有某些数学结构的适当族，该族带有集合包含顺序。本文研究了通过CF-逼近空间的表示领域。介绍了CF-逼近空间和CF闭集的概念，证明了在带有集合包含顺序的CF-逼近空间中，CF闭集族是连续领域，而且每个连续领域都与某个带有集合包含顺序的CF-逼近空间的CF闭集族同构。使用范畴论的方法引入了CF-可逼近关系的概念，这后来有助于证明CF-逼近空间和CF-可逼近关系的范畴等同于连续领域和Scott连续映射的范畴。

    Representations of domains mean in a general way representing a domain as a suitable family endowed with set-inclusion order of some mathematical structures. In this paper, representations of domains via CF-approximation spaces are considered. Concepts of CF-approximation spaces and CF-closed sets are introduced. It is proved that the family of CF-closed sets in a CF-approximation space endowed with set-inclusion order is a continuous domain and that every continuous domain is isomorphic to the family of CF-closed sets of some CF-approximation space endowed with set-inclusion order. The concept of CF-approximable relations is introduced using a categorical approach, which later facilitates the proof that the category of CF-approximation spaces and CF-approximable relations is equivalent to that of continuous domains and Scott continuous maps.
    
[^57]: 一种可解释的机器学习系统来识别癫痫-间隙-损伤连续状态下的脑电图图案

    An Interpretable Machine Learning System to Identify EEG Patterns on the Ictal-Interictal-Injury Continuum. (arXiv:2211.05207v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.05207](http://arxiv.org/abs/2211.05207)

    该论文设计了一种可解释的深度学习模型，以预测ICU脑电监测中常见的6种脑波图案的存在，并提供高质量的解释和三种解释方法，这对于建立AI的信任和临床采用至关重要。

    

    在许多医学领域，人们呼吁在用于临床工作的机器学习系统中增加可解释性。在本文中，我们设计了一个可解释的深度学习模型，用于预测ICU脑电监测中常见的6种脑波图案（癫痫、LPD、GPD、LRDA、GRDA、其他）的存在。每个预测都配有一个高质量的解释，借助于专门的用户界面提供支持。此新型模型架构学习了一组原型示例（“原型”），并通过将新的EEG片段与这些原型进行比较来做出决策。这些原型可以是单类（仅与一个类相关）或双类（与两个类相关）。我们提出了三种主要的模型解释方法：1）使用全局结构保持方法，将1275维cEEG潜在特征映射到二维空间中，可视化癫痫-间隙-损伤连续状态，从而深入了解其高维结构。2）我们提出了一种交互式解释方法，使人类专家能够查询模型预测的不同方面，并以自然语言接收经过专家验证的解释。3）我们可视化了导致模型做出某个决策的输入的最重要特征，允许详细检查输入和输出之间的关系。总的来说，我们展示了解释性模型分类EEG图案和提供专家友好的解释的实用性，这两个方面对于建立AI的信任和临床采用至关重要。

    In many medical subfields, there is a call for greater interpretability in the machine learning systems used for clinical work. In this paper, we design an interpretable deep learning model to predict the presence of 6 types of brainwave patterns (Seizure, LPD, GPD, LRDA, GRDA, other) commonly encountered in ICU EEG monitoring. Each prediction is accompanied by a high-quality explanation delivered with the assistance of a specialized user interface. This novel model architecture learns a set of prototypical examples (``prototypes'') and makes decisions by comparing a new EEG segment to these prototypes. These prototypes are either single-class (affiliated with only one class) or dual-class (affiliated with two classes).  We present three main ways of interpreting the model: 1) Using global-structure preserving methods, we map the 1275-dimensional cEEG latent features to a 2D space to visualize the ictal-interictal-injury continuum and gain insight into its high-dimensional structure. 2
    
[^58]: AI时代的责任制度：基于用例的证明负担分析

    Liability regimes in the age of AI: a use-case driven analysis of the burden of proof. (arXiv:2211.01817v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2211.01817](http://arxiv.org/abs/2211.01817)

    本文通过用例分析探讨了基于AI技术的责任制度下证明负担的挑战和规则改革的建议。

    

    由人工智能（AI）驱动的新兴技术有可能为我们的社会带来颠覆性的转型，并推进各种应用领域的多项技术的发展，其中数据驱动的学习方法（即机器学习（ML））是一次真正的革命。但与此同时，人们越来越关注这些方法学固有的某些特征，这些特征可能对安全和基本权利带来潜在风险。尽管在采用过程中有机制来最小化这些风险（例如安全规定），但这并不排除损害发生的可能，如果这种情况发生，受害者应该能够寻求补偿。因此，责任制度将在确保使用或与这些系统交互的受害者的基本保护方面发挥关键作用。然而，使AI系统固有风险的相同特征，例如缺乏因果关系、不透明、不可预测或他们自我和自适应的本质，也使得传统的责任规则难以应用。本文通过对各种用例及其潜在危害的分析，提出了基于用例的责任规则证明负担分析，识别了当前责任规则在AI技术领域面临的挑战，并探讨了改革这些规则的建议。

    New emerging technologies powered by Artificial Intelligence (AI) have the potential to disruptively transform our societies for the better. In particular, data-driven learning approaches (i.e., Machine Learning (ML)) have been a true revolution in the advancement of multiple technologies in various application domains. But at the same time there is growing concern about certain intrinsic characteristics of these methodologies that carry potential risks to both safety and fundamental rights. Although there are mechanisms in the adoption process to minimize these risks (e.g., safety regulations), these do not exclude the possibility of harm occurring, and if this happens, victims should be able to seek compensation. Liability regimes will therefore play a key role in ensuring basic protection for victims using or interacting with these systems. However, the same characteristics that make AI systems inherently risky, such as lack of causality, opacity, unpredictability or their self and 
    
[^59]: 可观测完美均衡 (Observable Perfect Equilibrium)

    Observable Perfect Equilibrium. (arXiv:2210.16506v5 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2210.16506](http://arxiv.org/abs/2210.16506)

    本文提出一种新的博弈均衡概念——可观测完美均衡，在顺序不完全信息博弈中可以帮助创建真正的策略代理。这种均衡概念在公开观察的行动概率方面具有鲁棒性。

    

    尽管纳什均衡成为了博弈论的核心解决方案概念，许多重要的博弈包含多个纳什均衡，我们必须确定如何在其中选择，以创建真正的策略代理。为顺序不完全信息博弈提出了几个纳什均衡细化概念，其中最突出的是颤抖手完美均衡、拟完美均衡和最近提出的单侧拟完美均衡。这些概念对某些任意小的错误具有鲁棒性，并保证始终存在。但我们认为，对于发展顺序不完全信息博弈中强大的代理人，这些概念都不正确。我们为游戏树中提出了一种新的均衡概念——可观测完美均衡，在其中，解决方案在公开观察的行动概率方面具有鲁棒性（并不一定针对所有可能不可观察的行动概率具有鲁棒性）。

    While Nash equilibrium has emerged as the central game-theoretic solution concept, many important games contain several Nash equilibria and we must determine how to select between them in order to create real strategic agents. Several Nash equilibrium refinement concepts have been proposed and studied for sequential imperfect-information games, the most prominent being trembling-hand perfect equilibrium, quasi-perfect equilibrium, and recently one-sided quasi-perfect equilibrium. These concepts are robust to certain arbitrarily small mistakes, and are guaranteed to always exist; however, we argue that neither of these is the correct concept for developing strong agents in sequential games of imperfect information. We define a new equilibrium refinement concept for extensive-form games called observable perfect equilibrium in which the solution is robust over trembles in publicly-observable action probabilities (not necessarily over all action probabilities that may not be observable by
    
[^60]: TabLLM: 大语言模型在少样本表格数据分类中的应用

    TabLLM: Few-shot Classification of Tabular Data with Large Language Models. (arXiv:2210.10723v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.10723](http://arxiv.org/abs/2210.10723)

    本文应用大语言模型将表格数据序列化为自然语言字符串进行分类，微调后即可在非常少的样本设置下与传统基线方法竞争力十足。

    

    本文研究了大语言模型在零样本和少样本表格数据分类中的应用。我们将表格数据序列化为自然语言字符串，并加上分类问题的简短描述，然后启用大语言模型。在少样本场景下，我们使用一些标记样本微调大语言模型。我们评估了多种序列化方法，包括模板、表格到文本模型和大语言模型。尽管方法简单，但我们发现它在多个基准数据集上优于以前的基于深度学习的表格分类方法。在大多数情况下，即使是零样本分类也获得了非平凡的表现，说明该方法能够利用大语言模型中编码的先前知识。与许多针对表格数据的深度学习方法不同，这种方法在非常少的样本设置下也与强大的传统基线方法（如梯度提升树）竞争力十足。

    We study the application of large language models to zero-shot and few-shot classification of tabular data. We prompt the large language model with a serialization of the tabular data to a natural-language string, together with a short description of the classification problem. In the few-shot setting, we fine-tune the large language model using some labeled examples. We evaluate several serialization methods including templates, table-to-text models, and large language models. Despite its simplicity, we find that this technique outperforms prior deep-learning-based tabular classification methods on several benchmark datasets. In most cases, even zero-shot classification obtains non-trivial performance, illustrating the method's ability to exploit prior knowledge encoded in large language models. Unlike many deep learning methods for tabular datasets, this approach is also competitive with strong traditional baselines like gradient-boosted trees, especially in the very-few-shot setting
    
[^61]: 重新审视医学图像分割:极度有限标签下的医学图像分割

    Mine yOur owN Anatomy: Revisiting Medical Image Segmentation with Extremely Limited Labels. (arXiv:2209.13476v4 [eess.IV] UPDATED)

    [http://arxiv.org/abs/2209.13476](http://arxiv.org/abs/2209.13476)

    提出了一种新的医学图像分割方法MOAN，该方法可以在极度有限的标签情况下实现高性能。MOAN由两个互补的流水线组成：协同邻域挖掘和自监督对比学习。实验结果表明，MOAN在Dice评分和其他评估指标方面优于现有最先进方法。

    

    最近，关于对比学习的研究在医学图像分割的背景下仅凭借几个标签取得了卓越的性能。现有方法主要集中在实体区分和不变映射上。然而，它们面临三个常见瓶颈：(1)尾部分布：医学图像数据通常遵循隐含的长尾类分布。盲目利用所有训练像素可能导致数据不平衡问题，并导致性能恶化；(2)一致性：由于不同解剖特征之间的类内变化，分割模型是否学会了有意义且一致的解剖特征仍不清楚；以及(3)多样性：整个数据集内部切片的相关性受到的关注显著较少。这促使我们寻找一个基于数据集本身的策略方法，从不同的解剖视图中发现相似但不同的样本。在本文中，我们介绍了一个新的框架，称为MOAN，用于极度有限标签下的医学图像分割。 MOAN由两个互补的流水线组成：协同邻域挖掘和自监督对比学习。前者提取共同依赖的像素区域，而后者强制网络学习有意义的解剖学表示。实验结果表明，MOAN在Dice评分和其他评估指标方面优于现有最先进方法。

    Recent studies on contrastive learning have achieved remarkable performance solely by leveraging few labels in the context of medical image segmentation. Existing methods mainly focus on instance discrimination and invariant mapping. However, they face three common pitfalls: (1) tailness: medical image data usually follows an implicit long-tail class distribution. Blindly leveraging all pixels in training hence can lead to the data imbalance issues, and cause deteriorated performance; (2) consistency: it remains unclear whether a segmentation model has learned meaningful and yet consistent anatomical features due to the intra-class variations between different anatomical features; and (3) diversity: the intra-slice correlations within the entire dataset have received significantly less attention. This motivates us to seek a principled approach for strategically making use of the dataset itself to discover similar yet distinct samples from different anatomical views. In this paper, we i
    
[^62]: 通过关系无环化学习带有循环关系的关系因果模型

    Learning Relational Causal Models with Cycles through Relational Acyclification. (arXiv:2208.12210v7 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2208.12210](http://arxiv.org/abs/2208.12210)

    本文通过引入关系无环化的算法，能够处理循环关系的因果模型，从而学习复杂动态系统。

    

    在互相影响或具有因果效应的联通单元的现实世界现象中，平衡状态通常用图模型中的循环表示。关系因果模型是一种表达复杂动态系统且能展示循环或反馈环的图模型，可以表示和推理。现有的从观测数据学习因果模型的循环因果发现算法假定数据实例是独立且同分布的，因此不适用于关系因果模型。同时，为关系因果模型设计的因果发现算法假定了无环性。本文研究约束基的关系因果发现算法在关系循环因果模型中为什么是正确且完全的必要和充分条件。我们引入关系无环化作为一个为关系模型设计的操作，能够对可确定性做出推理。

    In real-world phenomena which involve mutual influence or causal effects between interconnected units, equilibrium states are typically represented with cycles in graphical models. An expressive class of graphical models, relational causal models, can represent and reason about complex dynamic systems exhibiting such cycles or feedback loops. Existing cyclic causal discovery algorithms for learning causal models from observational data assume that the data instances are independent and identically distributed which makes them unsuitable for relational causal models. At the same time, causal discovery algorithms for relational causal models assume acyclicity. In this work, we examine the necessary and sufficient conditions under which a constraint-based relational causal discovery algorithm is sound and complete for cyclic relational causal models. We introduce relational acyclification, an operation specifically designed for relational models that enables reasoning about the identifiab
    
[^63]: 时间注意力单元：面向高效时空预测学习的方法研究

    Temporal Attention Unit: Towards Efficient Spatiotemporal Predictive Learning. (arXiv:2206.12126v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2206.12126](http://arxiv.org/abs/2206.12126)

    本研究提出了时间注意力单元（TAU）以提高时空预测学习的计算效率，将时间注意力分解为帧内静态注意力和帧间动态注意力。同时引入差分离散正则化方法来考虑帧间变化，大量实验表明该方法能够高效地进行预测学习。

    

    时空预测学习旨在通过学习历史帧来生成未来帧。本文研究了现有方法，并提出了一个通用的时空预测学习框架，其中空间编码器和解码器捕捉帧内特征，中间的时间模块捕捉帧间相关性。虽然主流方法采用递归单元来捕获长期时间依赖关系，但由于无法并行化的体系结构，它们的计算效率低下。为了并行化时间模块，我们提出了时间注意力单元（TAU），将时间注意力分解为帧内静态注意力和帧间动态注意力。此外，虽然均方误差损失侧重于帧内误差，但我们引入了一种新的差分离散正则化方法，考虑帧间变化。大量实验表明，所提出的方法使派生模型可以高效地进行预测学习。

    Spatiotemporal predictive learning aims to generate future frames by learning from historical frames. In this paper, we investigate existing methods and present a general framework of spatiotemporal predictive learning, in which the spatial encoder and decoder capture intra-frame features and the middle temporal module catches inter-frame correlations. While the mainstream methods employ recurrent units to capture long-term temporal dependencies, they suffer from low computational efficiency due to their unparallelizable architectures. To parallelize the temporal module, we propose the Temporal Attention Unit (TAU), which decomposes the temporal attention into intra-frame statical attention and inter-frame dynamical attention. Moreover, while the mean squared error loss focuses on intra-frame errors, we introduce a novel differential divergence regularization to take inter-frame variations into account. Extensive experiments demonstrate that the proposed method enables the derived mode
    
[^64]: 基于分区的图神经网络主动学习方法研究

    Partition-Based Active Learning for Graph Neural Networks. (arXiv:2201.09391v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2201.09391](http://arxiv.org/abs/2201.09391)

    本文提出了一种基于分区的图神经网络主动学习方法GraphPart，该方法在不引入额外超参数的情况下，在多个基准数据集上显著优于现有主动学习方法，并且在不同的注释预算约束下性能稳定。

    

    我们研究了在主动学习设置下，使用图神经网络（GNNs）进行半监督学习的问题。我们提出了一种新的基于分区的GNN主动学习方法GraphPart。GraphPart首先将图分成不相交的子图，然后在每个子图中选择代表性节点进行查询。所提出的方法是基于图和节点特征下的现实平滑假设的分类误差的新颖分析。对多个基准数据集的广泛实验表明，该方法在各种注释预算约束下，优于现有的GNN主动学习方法。此外，该方法不会引入额外的超参数，这对于模型训练尤为重要，特别是在没有标记验证集的主动学习设置下。

    We study the problem of semi-supervised learning with Graph Neural Networks (GNNs) in an active learning setup. We propose GraphPart, a novel partition-based active learning approach for GNNs. GraphPart first splits the graph into disjoint partitions and then selects representative nodes within each partition to query. The proposed method is motivated by a novel analysis of the classification error under realistic smoothness assumptions over the graph and the node features. Extensive experiments on multiple benchmark datasets demonstrate that the proposed method outperforms existing active learning methods for GNNs under a wide range of annotation budget constraints. In addition, the proposed method does not introduce additional hyperparameters, which is crucial for model training, especially in the active learning setting where a labeled validation set may not be available.
    
[^65]: 基于过拟合模型特性的噪声标签检测方法

    Over-Fit: Noisy-Label Detection based on the Overfitted Model Property. (arXiv:2106.07217v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2106.07217](http://arxiv.org/abs/2106.07217)

    本文提出一种基于模型过拟合特性的后训练学习方法，能够识别错误标记的样本，并逐步删除对决策边界有较高影响的样本，从而提高模型的泛化性能。

    

    由于深度神经网络具有高容量特性，即使是噪声标签，也容易过度拟合，从而降低模型的泛化性能。为了解决这个问题，我们提出了一种新的后训练学习方法，用于从含噪声标签的数据中显著提高任何预训练模型的泛化性能。具体而言，我们利用训练模型的过拟合特性来识别错误标记的样本，逐步删除对决策边界有较高影响的样本，并改善决策边界来提高泛化性能。我们的后训练方法与现有的噪声标签学习方法相结合具有很好的协同效果。在多种真实世界和合成基准数据集上的实验证明了我们方法在各种实际情况下的有效性。

    Deep neural network can easily overfit to even noisy labels due to its high capacity, which degrades the generalization performance of a model. To overcome this issue, we propose a new approach for learning from noisy labels (LNL) via post-training, which can significantly improve the generalization performance of any pre-trained model on noisy label data. To this end, we rather exploit the overfitting property of a trained model to identify mislabeled samples. Specifically, our post-training approach gradually removes samples with high influence on the decision boundary and refines the decision boundary to improve generalization performance. Our post-training approach creates great synergies when combined with the existing LNL methods. Experimental results on various real-world and synthetic benchmark datasets demonstrate the validity of our approach in diverse realistic scenarios.
    

