# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction](https://arxiv.org/abs/2404.02905) | VAR重新定义了图像上的自回归学习，通过粗到细的“下一尺度预测”实现快速学习视觉分布并超越了扩散变压器。 |
| [^2] | [ALOHa: A New Measure for Hallucination in Captioning Models](https://arxiv.org/abs/2404.02904) | 提出了一种新的用于测量图像字幕模型中幻觉的标准ALOHa，利用大型语言模型来测量幻觉对象，并成功识别比现有指标CHAIR更多的幻觉对象。 |
| [^3] | [DeiT-LT Distillation Strikes Back for Vision Transformer Training on Long-Tailed Datasets](https://arxiv.org/abs/2404.02900) | DeiT-LT通过引入一种有效的蒸馏方式，将CNN蒸馏到ViT中，以应对长尾数据集上训练ViT时的困难。 |
| [^4] | [On the Scalability of Diffusion-based Text-to-Image Generation](https://arxiv.org/abs/2404.02883) | 本研究通过针对扩散型T2I模型进行消融实验，发现增加transformer块对于改善文本-图像对齐比增加通道数更具参数效率。 |
| [^5] | [FlightScope: A Deep Comprehensive Assessment of Aircraft Detection Algorithms in Satellite Imagery](https://arxiv.org/abs/2404.02877) | 本研究对卫星图像中识别飞机的任务自定义的一套先进对象检测算法进行了全面评估和比较，发现YOLOv5是在不同成像条件下展现高精度和适应性的最优模型。 |
| [^6] | [Integrating Explanations in Learning LTL Specifications from Demonstrations](https://arxiv.org/abs/2404.02872) | 这项研究提出了一种整合大型语言模型和基于优化方法的方法，用于将人类解释和演示准确地转化为LTL规范。 |
| [^7] | [Human Activity Recognition using Smartphones](https://arxiv.org/abs/2404.02869) | 该论文通过智能手机的加速度计捕获不同日常活动的数据，提取特征并应用机器学习算法实现实时活动识别和卡路里消耗计算。 |
| [^8] | [I-Design: Personalized LLM Interior Designer](https://arxiv.org/abs/2404.02838) | I-Design是一个个性化室内设计师，通过自然语言交流生成和可视化用户设计目标，从而使室内设计更具可访问性。 |
| [^9] | [Empowering Biomedical Discovery with AI Agents](https://arxiv.org/abs/2404.02831) | AI科学家代理结合人类创造力和专业知识，利用机器学习工具赋能生物医学研究，对多个领域产生影响。 |
| [^10] | [Enhancing Interpretability of Vertebrae Fracture Grading using Human-interpretable Prototypes](https://arxiv.org/abs/2404.02830) | 使用ProtoVerse方法，我们提出了一种可解释的原型设计方法，可以可靠地解释深度学习模型对椎体骨折的分类决策，表现优于现有的基于原型的方法。 |
| [^11] | [Conifer: Improving Complex Constrained Instruction-Following Ability of Large Language Models](https://arxiv.org/abs/2404.02823) | Conifer提出了一个新的指令调节数据集，通过LLMs驱动的细化过程，以及渐进学习方案，显著提高了大型语言模型遵循具有复杂约束的多层指令的能力 |
| [^12] | [A Survey of Optimization-based Task and Motion Planning: From Classical To Learning Approaches](https://arxiv.org/abs/2404.02817) | 本综述全面审视了基于优化的任务与运动规划，重点讨论了如何通过混合优化方法解决高度复杂、接触丰富的机器人运动和操作问题。 |
| [^13] | [An Optimization Framework to Personalize Passive Cardiac Mechanics](https://arxiv.org/abs/2404.02807) | 这个研究提出了一个逆有限元分析框架来个性化估计心脏组织的被动力学特性，通过嵌套优化方案的使用，可以更好地逼近匹配图像数据的材料参数。 |
| [^14] | [The RealHumanEval: Evaluating Large Language Models' Abilities to Support Programmers](https://arxiv.org/abs/2404.02806) | 评估了大型语言模型在支持程序员方面的能力，引入了RealHumanEval作为衡量其帮助性的界面，并探讨了其对程序员生产力的影响。 |
| [^15] | [On Few-Shot Prompting for Controllable Question-Answer Generation in Narrative Comprehension](https://arxiv.org/abs/2404.02800) | 提出了用于控制从儿童叙事文本中生成问题-答案对的少样本提示策略，旨在控制问题的明确性和潜在叙事元素，通过与参考模型并行进行实证评估，结果显示在语义接近度评估和问题-答案对的多样性和连贯性方面，少样本策略超越了参考模型。 |
| [^16] | [Domain Generalization through Meta-Learning: A Survey](https://arxiv.org/abs/2404.02785) | 元学习是一种有前景的方法，通过获取可转移知识实现在各种任务之间快速适应，为解决深度神经网络在面对分布变化和有限标记数据时泛化能力不佳提供了新途径。 |
| [^17] | [AQuA -- Combining Experts' and Non-Experts' Views To Assess Deliberation Quality in Online Discussions Using LLMs](https://arxiv.org/abs/2404.02761) | 提出了AQuA，一种综合的磋商质量得分计算方法，可以从多个指标中提取各个讨论帖子的统一得分，保留了评论中磋商方面的信息，提高了模型的透明度。 |
| [^18] | [Unsupervised Occupancy Learning from Sparse Point Cloud](https://arxiv.org/abs/2404.02759) | 提出了一种从稀疏输入学习占用场的无监督学习方法，通过基于边界不确定性的采样和最小熵场优化来解决从3D点云学习SDF的挑战 |
| [^19] | [DIBS: Enhancing Dense Video Captioning with Unlabeled Videos via Pseudo Boundary Enrichment and Online Refinement](https://arxiv.org/abs/2404.02755) | DIBS是一种用于密集视频字幕（DVC）的预训练框架，通过优化生成的事件字幕和伪事件边界的质量，并引入在线边界细化策略，显著提高了在未标注视频上的效果。 |
| [^20] | [Learning Sequence Attractors in Recurrent Networks with Hidden Neurons](https://arxiv.org/abs/2404.02729) | 本研究研究了具有隐藏神经元的递归网络如何学习序列吸引子，以稳健地存储和检索预定义的模式序列，结果表明网络需要包含隐藏神经元来存储任意模式序列，并开发了一种局部学习算法实现这一目标。 |
| [^21] | [Unsupervised Learning of Effective Actions in Robotics](https://arxiv.org/abs/2404.02728) | 该论文提出了一种无监督算法，通过在探索阶段将连续运动空间离散化, 自动生成“动作原型”, 从而实现机器人动作的效果驱动学习 |
| [^22] | [Can We Understand Plasticity Through Neural Collapse?](https://arxiv.org/abs/2404.02719) | 论文探讨了深度学习中可塑性损失和神经坍塌的关联，并引入了一种正则化方法来缓解神经坍塌，从而减轻了可塑性损失。 |
| [^23] | [PromptCodec: High-Fidelity Neural Speech Codec using Disentangled Representation Learning based Adaptive Feature-aware Prompt Encoders](https://arxiv.org/abs/2404.02702) | 本文提出了PromptCodec，一种使用离散表示学习的特征感知提示编码器的高保真神经语音编解码器，通过引入额外特征表示、自适应特征加权融合和效率优化来解决高压缩率下的高保真音频重建问题。 |
| [^24] | [Attention is Naturally Sparse with Gaussian Distributed Input](https://arxiv.org/abs/2404.02690) | 通过对高斯输入下注意力得分稀疏性进行理论分析，揭示了注意力机制中稀疏性的特征及其对计算效率的影响。 |
| [^25] | [Cross-Architecture Transfer Learning for Linear-Cost Inference Transformers](https://arxiv.org/abs/2404.02684) | 提出了一种跨架构迁移学习方法，用于在线性成本推断和自注意力变换器之间共享组件的权重，以提高Transformer语言模型的效率。 |
| [^26] | [PejorativITy: Disambiguating Pejorative Epithets to Improve Misogyny Detection in Italian Tweets](https://arxiv.org/abs/2404.02681) | 通过澄清词语含义来改善厌恶检测，PejorativITy提出了一个新的意大利推文语料库，揭示了将贬损信息注入模型的两种方法均能显著提高分类性能。 |
| [^27] | [Responsible Reporting for Frontier AI Development](https://arxiv.org/abs/2404.02675) | 通过负责任地向政府、工业界和公民社会的相关方报告安全关键信息，前沿人工智能系统开发组织可以提高风险可见度，帮助开发者做出明智的决策并协助决策者设计更有针对性和健全的监管基础设施。 |
| [^28] | [Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models](https://arxiv.org/abs/2404.02657) | 本研究重新思考了大型语言模型知识蒸馏中对Kullback-Leibler散度的应用，发现逆Kullback-Leibler和正向Kullback-Leibler散度在优化目标上相似，为此提出了一种自适应Kullback-Leiber散度方法。 |
| [^29] | [Non-negative Subspace Feature Representation for Few-shot Learning in Medical Imaging](https://arxiv.org/abs/2404.02656) | 本文研究了在医学影像领域通过探索低维空间中的不同数据属性表示来实现数据驱动的少样本学习的有效性，引入了不同类型的非负矩阵分解（NMF）来解决医学图像分类中的数据稀缺问题。 |
| [^30] | [Towards detecting unanticipated bias in Large Language Models](https://arxiv.org/abs/2404.02650) | 本论文探索了在大型语言模型中检测未预料到的偏见的新途径，着重于不确定性量化和可解释人工智能方法。 |
| [^31] | [A Universal Deep Neural Network for Signal Detection in Wireless Communication Systems](https://arxiv.org/abs/2404.02648) | 提出了一种无需重新训练模型即可在各种无线环境中实现高性能检测的通用深度神经网络。 |
| [^32] | [Vocabulary Attack to Hijack Large Language Model Applications](https://arxiv.org/abs/2404.02637) | 通过插入来源模型词汇的方式，成功实施了对两个热门开源大型语言模型的目标劫持，创造出难以检测的不引人注目指令。 |
| [^33] | [A Differentiable Integer Linear Programming Solver for Explanation-Based Natural Language Inference](https://arxiv.org/abs/2404.02625) | Diff-Comb Explainer是一种基于可微黑盒组合求解器的神经符号架构，不需要对语义约束进行连续放松，相比传统解决方案表现更出色。 |
| [^34] | [Diffexplainer: Towards Cross-modal Global Explanations with Diffusion Models](https://arxiv.org/abs/2404.02618) | Diffexplainer提出了一种新颖框架，利用语言-视觉模型实现多模态全局可解释性，并通过优化的文本提示条件化的扩散模型，合成图像来解释分类器的决策，同时提供一个对决策解释的视觉工具，并能自动识别偏见和虚假特征。 |
| [^35] | [SHIELD: A regularization technique for eXplainable Artificial Intelligence](https://arxiv.org/abs/2404.02611) | SHIELD引入了一种正则化技术，通过隐藏部分输入数据并评估预测结果的差异，从而改善了可解释人工智能模型的质量。 |
| [^36] | [Affective-NLI: Towards Accurate and Interpretable Personality Recognition in Conversation](https://arxiv.org/abs/2404.02589) | 提出了Affective-NLI用于准确且可解释的对话中人格识别，以利用对话内容中的情感因素进行准确的人格识别 |
| [^37] | [The Surprising Effectiveness of Rankers Trained on Expanded Queries](https://arxiv.org/abs/2404.02587) | 通过训练数据集中的扩展和困难查询，本研究提出了一种方法来提高困难查询的排序性能，而不降低其他查询的性能。 |
| [^38] | [Active learning for efficient annotation in precision agriculture: a use-case on crop-weed semantic segmentation](https://arxiv.org/abs/2404.02580) | 主动学习在农业领域的语义分割中进行了比较研究，探讨了三种基于主动学习的获取函数（BALD、PowerBALD和随机选择）的性能。 |
| [^39] | [Learning Alternative Ways of Performing a Task](https://arxiv.org/abs/2404.02579) | 提出了一种用于学习多个模型的新归纳方法，每个模型代表一种替代策略 |
| [^40] | [SliceIt! -- A Dual Simulator Framework for Learning Robot Food Slicing](https://arxiv.org/abs/2404.02569) | 提出了一个用于在模拟环境中安全高效地学习机器人食物切割任务的Dual Simulator框架。 |
| [^41] | [Solar synthetic imaging: Introducing denoising diffusion probabilistic models on SDO/AIA data](https://arxiv.org/abs/2404.02552) | 使用去噪扩散概率模型（DDPM）在SDO/AIA数据上创建合成太阳图像，以解决太阳活动预测中的数据稀缺挑战。 |
| [^42] | [AI-Tutoring in Software Engineering Education](https://arxiv.org/abs/2404.02548) | 本研究通过将GPT-3.5-Turbo模型作为AI辅导员集成到APAS Artemis中，探讨了软件工程教育中学生与AI辅导员的互动模式，发现了不同用户类型，并强调了及时反馈和可扩展性等优势。 |
| [^43] | [Grid-Mapping Pseudo-Count Constraint for Offline Reinforcement Learning](https://arxiv.org/abs/2404.02545) | 提出了一种用于连续领域的新的计数方法，称为格点映射伪计数方法（GPC），以适应离线环境中的强化学习问题，并在惩罚Q值的同时减少计算成本。 |
| [^44] | [Unbiased Learning to Rank Meets Reality: Lessons from Baidu's Large-Scale Search Dataset](https://arxiv.org/abs/2404.02543) | 本研究从百度搜索引擎发布的大规模搜索数据集出发，探讨了无偏向学习排序技术在实际搜索引擎中的表现，发现与排名损失和查询-文档特征选择相比，ULTR技术并未带来明显的性能改进。 |
| [^45] | [ANGOFA: Leveraging OFA Embedding Initialization and Synthetic Data for Angolan Language Model](https://arxiv.org/abs/2404.02534) | 本文介绍了四个专门针对安哥拉语言进行微调的PLM，并使用多语言自适应微调（MAFT）方法，通过采用知情嵌入初始化和合成数据，提高了MAFT模型在下游任务中的性能，将基线提高了12.3个百分点，超越了SOTA AfroXLMR-base和OFA。 |
| [^46] | [Learn to Disguise: Avoid Refusal Responses in LLM's Defense via a Multi-agent Attacker-Disguiser Game](https://arxiv.org/abs/2404.02532) | 通过多智能体攻击者-伪装者博弈方法，实现一种弱防御机制，使大型模型能够安全地回复攻击者并隐藏防御意图 |
| [^47] | [Severity Controlled Text-to-Image Generative Model Bias Manipulation](https://arxiv.org/abs/2404.02530) | 本文揭示了文本到图像生成模型对偏见操纵的敏感性，并提出了一种通过定量控制模型偏见来操纵输出严重性的技术，从而实现精确提示工程生成新颖图像的方法。 |
| [^48] | [Text-driven Affordance Learning from Egocentric Vision](https://arxiv.org/abs/2404.02523) | 该论文提出了一种通过文本指导从主体视角学习可操作性的方法，涵盖手-物体和工具-物体交互，旨在学习接触点和操作轨迹。 |
| [^49] | [Tightly-Coupled LiDAR-IMU-Wheel Odometry with Online Calibration of a Kinematic Model for Skid-Steering Robots](https://arxiv.org/abs/2404.02515) | 提出了一种紧耦合LiDAR-IMU-轮里程计算法，使用在线校准解决滑移转向机器人在挑战性环境中的点云退化问题。 |
| [^50] | [An Interpretable Client Decision Tree Aggregation process for Federated Learning](https://arxiv.org/abs/2404.02510) | 提出了一种用于联邦学习的可解释客户端决策树聚合过程，旨在解决在这些模型中注入可解释性的挑战。 |
| [^51] | [VIAssist: Adapting Multi-modal Large Language Models for Users with Visual Impairments](https://arxiv.org/abs/2404.02508) | 本论文研究了如何利用多模大语言模型（MLLMs）为视障人士提供视觉问题答案，提出了 VIAssist 系统，可以识别不受欢迎的图像并提供详细的操作，最终依据用户查询提供可靠的答案。 |
| [^52] | [Dynamic Demonstration Retrieval and Cognitive Understanding for Emotional Support Conversation](https://arxiv.org/abs/2404.02505) | 通过动态演示检索和认知理解，我们提出了一种新颖的方法来提高情绪支持对话中提供的支持质量。 |
| [^53] | [Learning Generalized Policies for Fully Observable Non-Deterministic Planning Domains](https://arxiv.org/abs/2404.02499) | 本研究扩展了学习完全可观察、非确定性计划领域的泛化策略的方法，并通过实验评估了在一些 FOND 计划基准领域中产生的泛化策略的正确性。 |
| [^54] | [Measuring Social Norms of Large Language Models](https://arxiv.org/abs/2404.02491) | 论文提出了一个挑战，测试大型语言模型对社会规范的理解，构建了一个数据集涵盖广泛的社会规范问题，通过多代理框架基于大型语言模型来提高模型对社会规范的理解能力。 |
| [^55] | [New methods for drug synergy prediction](https://arxiv.org/abs/2404.02484) | 最佳方法准确解决了涉及已知药物或细胞系的药物协同作用预测情景，但仍未达到准确预测新药物或细胞系的水平。 |
| [^56] | [FedSelect: Personalized Federated Learning with Customized Selection of Parameters for Fine-Tuning](https://arxiv.org/abs/2404.02478) | 提出了一种受到彩票票据假设启发的新型个性化联邦学习算法FedSelect，能够在微调中定制选择网络参数，解决了全局知识存储不够优化的问题。 |
| [^57] | [Enhancing Sum-Rate Performance in Constrained Multicell Networks: A Low-Information Exchange Approach](https://arxiv.org/abs/2404.02477) | 提出了一种创新方法，在受限制的多小区网络中通过极少的信息交换实现最大化总速率性能。 |
| [^58] | [Deep Reinforcement Learning for Traveling Purchaser Problems](https://arxiv.org/abs/2404.02476) | 提出了一种基于深度强化学习的方法，该方法分别解决了旅行购买者问题中的路由构建和购买规划问题，并从全局角度评估和优化解决方案。 |
| [^59] | [uTeBC-NLP at SemEval-2024 Task 9: Can LLMs be Lateral Thinkers?](https://arxiv.org/abs/2404.02474) | 通过研究提示工程方法如何增强LLMs在横向思考任务上的表现，揭示了其固有的超越思维能力，并发现压缩的信息性提示和动态的情境学习显著提升了模型性能。 |
| [^60] | [Prompting for Numerical Sequences: A Case Study on Market Comment Generation](https://arxiv.org/abs/2404.02466) | 本研究探讨了针对市场评论生成任务的不同输入表示方法，发现类似编程语言的提示效果更好，而类似自然语言和较长格式的提示效果较差。 |
| [^61] | [TSNet:A Two-stage Network for Image Dehazing with Multi-scale Fusion and Adaptive Learning](https://arxiv.org/abs/2404.02460) | TSNet通过引入多尺度融合模块和自适应学习模块，提出了一种解决图像去雾泛化和效果问题的两阶段网络。 |
| [^62] | [PhonologyBench: Evaluating Phonological Skills of Large Language Models](https://arxiv.org/abs/2404.02456) | PhonologyBench是一个新颖的基准测试，旨在明确评估大型语言模型在英语中的音韵技能，展示了LLMs在没有语音数据情况下在PhonologyBench任务上表现出显著性能。 |
| [^63] | [Techniques for Measuring the Inferential Strength of Forgetting Policies](https://arxiv.org/abs/2404.02454) | 本文提出了一种衡量原理论推理强度变化的损失函数，并使用Problog工具计算损失度量，最终得出了关于不同遗忘策略强度的研究方法和实际应用示例。 |
| [^64] | [Task Agnostic Architecture for Algorithm Induction via Implicit Composition](https://arxiv.org/abs/2404.02450) | 探索开发一种统一架构，旨在解决各种任务，包括以前未见过的任务，并使用跨多种模式的输入。 |
| [^65] | [Electric Vehicle Routing Problem for Emergency Power Supply: Towards Telecom Base Station Relief](https://arxiv.org/abs/2404.02448) | 提出一种新型的基于电动车辆的路径问题，通过组合基于规则的车辆选择器和基于强化学习的节点选择器解决电动车辆路径问题，以最小化总行驶距离和故障基站数量。 |
| [^66] | [A Novel Approach to Breast Cancer Histopathological Image Classification Using Cross-Colour Space Feature Fusion and Quantum-Classical Stack Ensemble Method](https://arxiv.org/abs/2404.02447) | 本研究结合了颜色空间特征融合和量子-经典堆叠方法，提高了乳腺癌组织病理图像分类的准确性，标志着个性化医学评估领域的重要进展。 |
| [^67] | [The Promises and Pitfalls of Using Language Models to Measure Instruction Quality in Education](https://arxiv.org/abs/2404.02444) | 本研究利用NLP技术评估教育中多种高推理教学实践的质量，并且首次应用NLP来衡量对有特殊需求学生特别有效的教学实践。 |
| [^68] | [AD4RL: Autonomous Driving Benchmarks for Offline Reinforcement Learning with Value-based Dataset](https://arxiv.org/abs/2404.02429) | 本文提供了用于离线强化学习研究的自动驾驶数据集和基准测试，包括真实世界人类驾驶员的数据集，以及七种离线强化学习算法在三种实际驾驶场景中的应用，并提供了一个统一决策模型作为算法设计的参考框架。 |
| [^69] | [Auxiliary task demands mask the capabilities of smaller language models](https://arxiv.org/abs/2404.02418) | 较小语言模型对类比推理、反思推理、单词预测和语法判断的表现受辅助任务需求的影响，评估方法的任务需求越大，性能越低，这种"需求差距"在参数较少、训练数据较少的模型中尤为显著 |
| [^70] | [Decision Transformer as a Foundation Model for Partially Observable Continuous Control](https://arxiv.org/abs/2404.02407) | 通过将控制任务作为基于过去观察、动作和奖励的当前最优动作预测来消除估计器设计需求，并利用生成式预训练Transformer系列初始化决策Transformer，然后使用低秩适应对其进行控制任务训练。 |
| [^71] | [Exploring Backdoor Vulnerabilities of Chat Models](https://arxiv.org/abs/2404.02406) | 聊天模型因为多轮交互格式的灵活性增加了对后门攻击的脆弱性，该论文揭示并实现了一种新颖的后门攻击方法 |
| [^72] | [Token Trails: Navigating Contextual Depths in Conversational AI with ChatLLM](https://arxiv.org/abs/2404.02402) | Token Trails是一种利用token-type嵌入导航对话中复杂上下文细微差别的新方法，通过提高对话理解和回复生成效果，在促进上下文意识聊天机器人交互方面具有前沿性能。 |
| [^73] | [On Linearizing Structured Data in Encoder-Decoder Language Models: Insights from Text-to-SQL](https://arxiv.org/abs/2404.02389) | 本研究调查了编码器-解码器语言模型中线性处理结构化数据的方法，发现模型能够模仿人类设计的流程，学习结构的深刻含义，揭示了模型内部机制的一些见解。 |
| [^74] | [Enhancing Human-Computer Interaction in Chest X-ray Analysis using Vision and Language Model with Eye Gaze Patterns](https://arxiv.org/abs/2404.02370) | 通过结合眼动数据和文本提示，利用Vision-Language Models（VLMs）增强胸部X射线分析中的人机交互，提高了放射科医师的关注度，有效增强了胸部X射线分析的准确性。 |
| [^75] | [EnergAIze: Multi Agent Deep Deterministic Policy Gradient for Vehicle to Grid Energy Management](https://arxiv.org/abs/2404.02361) | 本文介绍了EnergAIze，一种利用多智能体深度确定性策略梯度算法的能源管理框架，旨在解决车辆到电网能量管理中的实际适应性、全球优化以及用户参与等挑战。 |
| [^76] | [Semantic Augmentation in Images using Language](https://arxiv.org/abs/2404.02353) | 深度学习模型需要大规模标记数据集，本文提出利用生成图像增强数据集以改进模型跨领域泛化能力。 |
| [^77] | [Multi-BERT: Leveraging Adapters and Prompt Tuning for Low-Resource Multi-Domain Adaptation](https://arxiv.org/abs/2404.02335) | 提出了一种新颖的方法，使用一个核心模型和多套领域特定参数，结合提示调整和适配器技术，以及额外层次来实现低资源多领域适应，使得模型能够完成与每个领域单独训练模型相媲美的任务。 |
| [^78] | [Comparative Study of Domain Driven Terms Extraction Using Large Language Models](https://arxiv.org/abs/2404.02330) | 本研究比较了使用大型语言模型进行领域驱动术语提取的方法，评估了Llama2-7B、GPT-3.5和Falcon-7B在Inspec和PubMed数据集上的性能。 |
| [^79] | [Prompts As Programs: A Structure-Aware Approach to Efficient Compile-Time Prompt Optimization](https://arxiv.org/abs/2404.02319) | 提出了SAMMO框架，用于在编译时优化元提示程序，提高了复杂提示在多种不同LLM上的性能。 |
| [^80] | [Is Meta-training Really Necessary for Molecular Few-Shot Learning ?](https://arxiv.org/abs/2404.02314) | 本文重新审视了分子数据微调方法，提出了基于马氏距离的正则化二次探针损失，并设计了块坐标下降优化器，使得在黑匣子设置下，简单微调方法在少样本学习中获得了竞争性表现，同时消除了特定预训练策略的需要。 |
| [^81] | [Collapse of Self-trained Language Models](https://arxiv.org/abs/2404.02305) | 自我训练的语言模型在延长训练时表现出显著的性能下降，导致重复和崩溃的标记输出。 |
| [^82] | [Virtual Sensor for Real-Time Bearing Load Prediction Using Heterogeneous Temporal Graph Neural Networks](https://arxiv.org/abs/2404.02304) | 提出了一种使用Graph Neural Networks分析空间-时间依赖关系的图神经网络虚拟传感器，能够从传感器滚轮数据中学习，将操作条件映射为轴承负载。 |
| [^83] | [One Noise to Rule Them All: Multi-View Adversarial Attacks with Universal Perturbation](https://arxiv.org/abs/2404.02287) | 这种通用扰动方法架起了2D扰动与类似3D攻击能力之间的桥梁，为生成3D物体识别中的多视角对抗样本提供了实用且可扩展的解决方案。 |
| [^84] | [Extracting Norms from Contracts Via ChatGPT: Opportunities and Challenges](https://arxiv.org/abs/2404.02269) | 研究了ChatGPT在从合同中提取规范方面的有效性和局限性，展示了其良好表现但也发现了一些限制。 |
| [^85] | [OFMPNet: Deep End-to-End Model for Occupancy and Flow Prediction in Urban Environment](https://arxiv.org/abs/2404.02263) | OFMPNet是一种深度端到端模型，用于预测城市环境中所有动态对象的未来行为，结合了占有图和场景动态流量信息。 |
| [^86] | [LLMs in the Loop: Leveraging Large Language Model Annotations for Active Learning in Low-Resource Languages](https://arxiv.org/abs/2404.02261) | 在低资源语言中，通过将LLMs集成到主动学习循环中进行数据注释，有效减少所需数据量，并取得接近最先进性能的结果。 |
| [^87] | [$\texttt{LM}^\texttt{2}$: A Simple Society of Language Models Solves Complex Reasoning](https://arxiv.org/abs/2404.02255) | LM2提出了一种简单的语言模型$\texttt{LM}^\texttt{2}$，该模型将分解、解决和验证模块化，通过分解器识别关键概念并生成逐步子问题，从而协同解决复杂推理问题。 |
| [^88] | [RAT: Retrieval-Augmented Transformer for Click-Through Rate Prediction](https://arxiv.org/abs/2404.02249) | RAT模型是为了解决当前CTR预测模型仅关注样本内特征交互而忽略跨样本关系的问题，通过检索相似样本构建增强输入，实现了对样本内和跨样本的全面特征交互推理，提高了CTR预测的效果。 |
| [^89] | [Is Exploration All You Need? Effective Exploration Characteristics for Transfer in Reinforcement Learning](https://arxiv.org/abs/2404.02235) | 探索特征与深度强化学习中有效的转移学习的关系，尚未被明确表征。研究试图理解探索特征与改进性能和效率在转移学习中的关系 |
| [^90] | [OOSTraj: Out-of-Sight Trajectory Prediction With Vision-Positioning Denoising](https://arxiv.org/abs/2404.02227) | 提出了一种利用视觉定位技术进行视界轨迹预测的新方法，可以有效地解决视野外物体和传感器数据噪声的挑战，达到了最先进的性能。 |
| [^91] | [CHOSEN: Contrastive Hypothesis Selection for Multi-View Depth Refinement](https://arxiv.org/abs/2404.02225) | CHOSEN是一个用于多视角深度细化的对比假设选择框架，通过对比学习和精心设计的假设特征，能够在多视角立体匹配中实现较高质量的深度和法线精度。 |
| [^92] | [Exploring How Multiple Levels of GPT-Generated Programming Hints Support or Disappoint Novices](https://arxiv.org/abs/2404.02213) | 这项研究发现，向新手提供从一般自然语言指导到具体代码辅助等四个级别的提示，能更好地支持他们的问题解决和学习。 |
| [^93] | [A Holistic Indicator of Polarization to Measure Online Sexism](https://arxiv.org/abs/2404.02205) | 该论文提出了一个可以提供综合性性别毒性指标的模型，有助于政策制定者、在线社区管理员和计算社会科学家更好地理解和管理在线性别歧视问题。 |
| [^94] | [Insights from the Use of Previously Unseen Neural Architecture Search Datasets](https://arxiv.org/abs/2404.02189) | 提出了八个新的神经架构搜索数据集，旨在引起在NAS开发中的关注并鼓励作者考虑模型在开发时未知数据集上的表现。 |
| [^95] | [A Generative Deep Learning Approach for Crash Severity Modeling with Imbalanced Data](https://arxiv.org/abs/2404.02187) | 使用生成式深度学习方法处理事故严重性建模中的数据不平衡问题，解决传统和基于深度学习的数据重采样方法难以处理离散风险因素崩溃问题的挑战。 |
| [^96] | [Self-Organized Agents: A LLM Multi-Agent Framework toward Ultra Large-Scale Code Generation and Optimization](https://arxiv.org/abs/2404.02183) | 提出了自组织多代理框架（SoA），实现了大规模代码的可扩展高效生成和优化，代理可自主运作生成和修改代码组件，并根据问题复杂性动态增加数量。 |
| [^97] | [Leveraging Machine Learning for Early Autism Detection via INDT-ASD Indian Database](https://arxiv.org/abs/2404.02181) | 本研究旨在通过利用机器学习开发一种简单、快速、廉价的技术，利用INDT-ASD印度数据库早期检测自闭症。 |
| [^98] | [Remote sensing framework for geological mapping via stacked autoencoders and clustering](https://arxiv.org/abs/2404.02180) | 通过堆叠自动编码器和聚类实现遥感数据地质制图的无监督机器学习框架 |
| [^99] | [Distributed and Rate-Adaptive Feature Compression](https://arxiv.org/abs/2404.02179) | 设计一种适应不断变化的通信约束的特征压缩方案，同时最大化融合中心的推断性能。 |
| [^100] | [Versatile Navigation under Partial Observability via Value-guided Diffusion Policy](https://arxiv.org/abs/2404.02176) | 提出一种适用于部分可观察性下的多功能扩散方法，通过价值引导扩散策略实现2D和3D路线规划，提供充分远见并指导代理的探索和目标寻找行为，无需专家干预 |
| [^101] | [Bounds of Block Rewards in Honest PinFi Systems](https://arxiv.org/abs/2404.02174) | 通过博弈论方法探讨PinFi机制及其更广泛影响，研究发现PinFi能够在LPs、卖家和买家之间建立动态均衡。 |
| [^102] | [RAVE: Residual Vector Embedding for CLIP-Guided Backlit Image Enhancement](https://arxiv.org/abs/2404.01889) | 该论文提出了一种用于背光图像增强的CLIP引导方法RAVE，通过残差向量嵌入和提示调整的新颖方法，加快了训练并提高了质量。 |
| [^103] | [Towards Generalizable and Faithful Logic Reasoning over Natural Language via Resolution Refutation](https://arxiv.org/abs/2404.01677) | 通过引入归结反驳范式，提出了一个名为GFaiR的框架，旨在解决大型语言模型在进行自然语言形式逻辑理论一阶逻辑推理时的困难，并通过证明插入解决方案改进了系统的完整性 |
| [^104] | [Instruction-Driven Game Engines on Large Language Models](https://arxiv.org/abs/2404.00276) | 通过在大型语言模型上开发指令驱动游戏引擎，使用户可以通过简单的自然语言指令创建游戏，从而降低游戏开发的难度。 |
| [^105] | [InfLoRA: Interference-Free Low-Rank Adaptation for Continual Learning](https://arxiv.org/abs/2404.00228) | InfLoRA提出了一种新的PEFT方法，名为无干扰低秩自适应（InfLoRA），用于持续学习，旨在消除新任务对旧任务的干扰，帮助模型在稳定性和可塑性之间取得良好平衡。 |
| [^106] | [Unleashing the Potential of Large Language Models for Predictive Tabular Tasks in Data Science](https://arxiv.org/abs/2403.20208) | 本研究旨在利用大型语言模型解决数据科学中表格数据预测任务，通过在丰富的数据集上训练Llama-2模型并进行实际应用，取得显著的改进。 |
| [^107] | [Is Synthetic Image Useful for Transfer Learning? An Investigation into Data Generation, Volume, and Utilization](https://arxiv.org/abs/2403.19866) | 研究探讨了从文本到图像生成模型中生成和利用合成图像在迁移学习中的作用，提出了桥接迁移的两阶段框架以解决合成图像与真实图像之间的分布差异。 |
| [^108] | [Gegenbauer Graph Neural Networks for Time-varying Signal Reconstruction](https://arxiv.org/abs/2403.19800) | 提出了一种新颖的Gegenbauer-based graph convolutional (GegenConv)算子，用于提高时变信号重构的准确性 |
| [^109] | [Understanding the Learning Dynamics of Alignment with Human Feedback](https://arxiv.org/abs/2403.18742) | 本研究对人类偏好对齐的学习动态进行了理论分析，显示了偏好数据集的分布如何影响模型更新速度，并提供了对训练准确度的严格保证，同时揭示了优化易于优先考虑高偏好可区分性行为的复杂现象。 |
| [^110] | [A Recommender System for NFT Collectibles with Item Feature](https://arxiv.org/abs/2403.18305) | 该研究提出了一种针对NFT的推荐系统，综合利用NFT交易记录和外部项目特征等多种数据源，通过数据高效的基于图的方法生成个性化推荐，并利用超出用户-项目互动的输入验证了模型的有效性。 |
| [^111] | [An Experiment with the Use of ChatGPT for LCSH Subject Assignment on Electronic Theses and Dissertations](https://arxiv.org/abs/2403.16424) | 该研究探讨了利用大型语言模型生成美国国会图书馆主题标头的潜力，展示了其对于解决学术图书馆待编目项目积压问题具有战略应对意义，同时也强调了人类编目员仍然在验证和增强生成主题标头方面的重要性。 |
| [^112] | [Evaluating GPT-4 with Vision on Detection of Radiological Findings on Chest Radiographs](https://arxiv.org/abs/2403.15528) | GPT-4V在胸部X光放射检查的放射学发现检测上尚未准备好应用于真实世界的诊断用途 |
| [^113] | [Grey-informed neural network for time-series forecasting](https://arxiv.org/abs/2403.15027) | 本研究提出了灰色信息神经网络（GINN），通过遵循灰色系统的微分方程模型，提高了神经网络输出的可解释性，使其能够有效处理小数据样本，产生可靠的预测。 |
| [^114] | [StateFlow: Enhancing LLM Task-Solving through State-Driven Workflows](https://arxiv.org/abs/2403.11322) | 提出了一种使用StateFlow的新颖LLM任务解决范式，将复杂任务解决过程概念化为状态机，通过状态转换确保LLM响应的清晰跟踪和管理。 |
| [^115] | [Long-term Frame-Event Visual Tracking: Benchmark Dataset and Baseline](https://arxiv.org/abs/2403.05839) | 提出了一个新的长期和大规模的帧事件单目标跟踪数据集FELT，重新训练和评估了15个基准跟踪器，并引入了关联记忆Transformer网络来解决RGB帧和事件流不完整的问题。 |
| [^116] | [Privacy-Aware Semantic Cache for Large Language Models](https://arxiv.org/abs/2403.02694) | MeanCache是一种面向LLMs的语义缓存，能够识别语义上相似的查询，从而减少查询成本，服务提供商负载和环境影响。 |
| [^117] | [Global and Local Prompts Cooperation via Optimal Transport for Federated Learning](https://arxiv.org/abs/2403.00041) | 提出了联邦提示合作 via Optimal Transport（FedOTP）方法，通过最优输运实现全局和本地提示的合作，针对数据异质性设计了高效的协作提示学习策略。 |
| [^118] | [OSCaR: Object State Captioning and State Change Representation](https://arxiv.org/abs/2402.17128) | 本文介绍了一个新的数据集和基准OSCaR，旨在解决描述复杂视觉环境中对象状态变化的问题，为评估多模态大型语言提供了一个新的实验平台。 |
| [^119] | [Text2Pic Swift: Enhancing Long-Text to Image Retrieval for Large-Scale Libraries](https://arxiv.org/abs/2402.15276) | Text2Pic Swift框架针对大规模库中文本描述到图像的检索提出了一种高效且强大的方法，通过两阶段策略解决了长文本查询中的歧义问题 |
| [^120] | [Towards Seamless Adaptation of Pre-trained Models for Visual Place Recognition](https://arxiv.org/abs/2402.14505) | 提出了一种新颖的方法，实现了预训练模型对视觉地点识别的无缝适应 |
| [^121] | [Emulated Disalignment: Safety Alignment for Large Language Models May Backfire!](https://arxiv.org/abs/2402.12343) | 安全对齐的大型语言模型可能会通过模拟失调框架，在对抗性操纵下产生危险结果，对训练的语言模型具有双倍有害性，高于强基线，强调了即使在安全对齐后也需要重新评估开源语言模型的重要性。 |
| [^122] | [CodeMind: A Framework to Challenge Large Language Models for Code Reasoning](https://arxiv.org/abs/2402.09664) | CodeMind是一个用于挑战大型语言模型进行代码推理的框架，通过评估LLMs的代码推理能力来替代仅仅依靠测试通过来评估，对三种代码推理任务进行评估，结果显示LLMs能够公正地理解控制流结构，并且对于简单程序和复杂程序，它们通常能够推理出输入如何演变为输出。 |
| [^123] | [Refining Myocardial Infarction Detection: A Novel Multi-Modal Composite Kernel Strategy in One-Class Classification](https://arxiv.org/abs/2402.06530) | 本研究提出了一种新的方法，使用基于超声心动图的一种基于多模态复合核策略的单一类别分类算法来进行早期心肌梗死的检测。这种方法通过优化投影矩阵和特征转化，提高了心肌梗死检测的能力。 |
| [^124] | [Logical Specifications-guided Dynamic Task Sampling for Reinforcement Learning Agents](https://arxiv.org/abs/2402.03678) | 本文提出了一种逻辑规范引导下的动态任务采样（LSTS）方法，通过学习一组强化学习策略，根据高级任务规范指导智能体在最小化环境交互次数的同时实现从初始状态到目标状态的引导。在网格世界实验中，LSTS实现了改进的时间到阈值。 |
| [^125] | [Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens](https://arxiv.org/abs/2401.17377) | 这项研究展示了n-gram语言模型的价值，并介绍了一个名为infini-gram的引擎，它可以以毫秒级的延迟计算任意n的n-gram概率，使得在神经大型语言模型中对文本进行更准确的分析成为可能。 |
| [^126] | [Don't Believe Everything You Read: Enhancing Summarization Interpretability through Automatic Identification of Hallucinations in Large Language Models](https://arxiv.org/abs/2312.14346) | 本文通过定义标记级别的方法来识别不同类型的幻觉，并利用这种标记来提高LLMs在对话摘要任务中的可解释性和忠实度。 |
| [^127] | [RadEdit: stress-testing biomedical vision models via diffusion image editing](https://arxiv.org/abs/2312.12865) | 该研究提出了一种名为RadEdit的新编辑方法，通过训练文本到图像扩散模型，在多个胸部X射线数据集上对生物医学视觉模型进行压力测试，从而模拟数据集转移，诊断失效模式，并确保编辑图像的一致性。 |
| [^128] | [Gemini: A Family of Highly Capable Multimodal Models](https://arxiv.org/abs/2312.11805) | Gemini家族是一系列在图像、音频、视频和文本理解方面表现出色的多模态模型，其中最具能力的Gemini Ultra模型在30个基准测试中推进了技术前沿，并改进了所有20个多模态基准测试的技术状态。 |
| [^129] | [ReCoRe: Regularized Contrastive Representation Learning of World Model](https://arxiv.org/abs/2312.09056) | 通过正则化对比度表示学习世界模型，该方法提高了样本效率和泛化性能，解决了在视觉导航等日常任务中出现外观变化时的挑战。 |
| [^130] | [Agent-OM: Leveraging LLM Agents for Ontology Matching](https://arxiv.org/abs/2312.00326) | 本研究提出了Agent-OM，利用LLM代理为本体匹配系统引入了新的设计范式。 |
| [^131] | [Text-Driven Image Editing via Learnable Regions](https://arxiv.org/abs/2311.16432) | 该方法通过学习区域实现了文本驱动的图像编辑，无需用户提供遮罩或草图，具有灵活性和能够处理复杂提示的特点。与其他方法相比，展现了竞争性能。 |
| [^132] | [Towards Responsible Generative AI: A Reference Architecture for Designing Foundation Model based Agents](https://arxiv.org/abs/2311.13148) | 这篇论文提出了一种基于模式的参考架构，为设计基于基础模型代理时提供指导，强调了负责任AI和软件质量属性等方面的重要性。 |
| [^133] | [Toward Robust Imperceptible Perturbation against Unauthorized Text-to-image Diffusion-based Synthesis](https://arxiv.org/abs/2311.13127) | MetaCloak提出了一种基于元学习框架的解决方案，通过额外转换抽样过程来制造可转移和鲁棒的扰动，以解决现有防御方法的局限性。 |
| [^134] | [Think While You Write: Hypothesis Verification Promotes Faithful Knowledge-to-Text Generation](https://arxiv.org/abs/2311.09467) | 提出了一种名为TWEAK的仅解码方法，通过引入假设验证模型来提高知识到文本生成的忠实度，并在不影响质量的情况下取得改进。 |
| [^135] | [Anti-LM Decoding for Zero-shot In-context Machine Translation](https://arxiv.org/abs/2311.08324) | 提出了一种反-LM解码目标，通过引入Anti-Language Model目标和一个设计良好的衰减因子，解决了零翻译上下文机器翻译的弱点，与其他解码目标相比，在某些设置中，实现了高达20个BLEU点的性能提升。 |
| [^136] | [Psychometric Predictive Power of Large Language Models](https://arxiv.org/abs/2311.07484) | 指令调整和提示在大型语言模型中无法提供比基础模型更好的认知建模估计。 |
| [^137] | [BatteryML:An Open-source platform for Machine Learning on Battery Degradation](https://arxiv.org/abs/2310.14714) | BatteryML是一个开源平台，通过一站式、全面的方法统一了电池衰减建模的数据预处理、特征提取和模型实现，提高了研究应用的实用性和效率。 |
| [^138] | [Put Your Money Where Your Mouth Is: Evaluating Strategic Planning and Execution of LLM Agents in an Auction Arena](https://arxiv.org/abs/2310.05746) | LLM代理在拍卖竞技场展示出了关键的规划和执行技能，这为建模复杂社会互动在竞争背景下的LLMs潜力提供了新途径。 |
| [^139] | [Automatic Pair Construction for Contrastive Post-training](https://arxiv.org/abs/2310.02263) | 提出了一种自动构建对比数据的方法，使用多个模型的偏好对，提高了大型语言模型的对齐效果，并且通过DPO对比技术得到了改善，进一步优化了对齐，最终使经过调优的指导学习模型Orca超越了ChatGPT。 |
| [^140] | [From Shortcuts to Triggers: Backdoor Defense with Denoised PoE](https://arxiv.org/abs/2305.14910) | 提出了一种端到端集成的后门防御框架 DPoE，旨在通过去噪设计和捕捉后门快捷方式的浅层模型，以及防止学习后门快捷方式的主模型，有效抵御各种后门攻击。 |
| [^141] | [ARS-DETR: Aspect Ratio Sensitive Oriented Object Detection with Transformer](https://arxiv.org/abs/2303.04989) | 提出了一种面向长宽比敏感的定向目标检测器ARS-DETR，采用高精度度量AP$_{75}$来衡量模型性能，并通过新的角度分类方法和旋转可变形注意力模块实现了竞争性能。 |
| [^142] | [Trust Your $\nabla$: Gradient-based Intervention Targeting for Causal Discovery](https://arxiv.org/abs/2211.13715) | 提出了一种基于梯度的干预目标定位方法，GIT，在因果发现中能够通过信号梯度估计器降低干预次数，在低数据量情况下优于竞争基线。 |
| [^143] | [Unified Control Framework for Real-Time Interception and Obstacle Avoidance of Fast-Moving Objects with Diffusion Variational Autoencoder](https://arxiv.org/abs/2209.13628) | 使用扩散变分自编码器实现快速移动物体的实时拦截和避障 |
| [^144] | [Off-Policy Correction For Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2111.11229) | 提出了MA-Trace，一种新的离策略演员-评论家算法，在多智体强化学习环境中具有高可伸缩性，并通过重要性采样作为离策略修正方法，保证了计算分布的质量和算法的收敛性。 |
| [^145] | [Catalytic Role Of Noise And Necessity Of Inductive Biases In The Emergence Of Compositional Communication](https://arxiv.org/abs/2111.06464) | 噪声和归纳偏见的作用使得组合式沟通自发产生，并且一定范围内的噪声有助于促进组合性的发展。 |
| [^146] | [Combining Transformers with Natural Language Explanations](https://arxiv.org/abs/2110.00125) | 通过结合自然语言解释和变压器模型，我们提出了一种方法来利用外部记忆存储自然语言解释，并用于解释分类输出，实验证明这种方法能够产生相关解释且保持或提高分类性能。 |
| [^147] | [Subgoal Search For Complex Reasoning Tasks](https://arxiv.org/abs/2108.11204) | 提出了子目标搜索（kSubS）方法，通过学习的子目标生成器产生多样性的子目标，减少搜索空间并在Sokoban、魔方和不等式证明三个领域取得了强大的结果。 |
| [^148] | [Simulation-based reinforcement learning for real-world autonomous driving](https://arxiv.org/abs/1911.12905) | 该论文利用模拟强化学习和合成数据来实现对真实世界自动驾驶系统的控制，成功实现了模拟到真实策略转移，并分析了设计决策对真实世界性能的影响。 |
| [^149] | [Improving Medical Reasoning through Retrieval and Self-Reflection with Retrieval-Augmented Large Language Models.](http://arxiv.org/abs/2401.15269) | 本论文介绍了一种名为Self-BioRAG的框架，通过使用检索和自我反思的方法，提高了医疗推理的能力。该框架专注于生成解释、检索领域特定文档以及对生成的响应进行自我反思。 |
| [^150] | [MLLMReID: Multimodal Large Language Model-based Person Re-identification.](http://arxiv.org/abs/2401.13201) | MLLMReID是一种基于多模态大语言模型的人物再识别方法，通过微调模型并将其视觉编码器作为主干进行优化，解决了MLLM在ReID任务中的设计指令和特征学习效果的问题。 |
| [^151] | [Instructional Fingerprinting of Large Language Models.](http://arxiv.org/abs/2401.12255) | 这项研究提出了一种指纹识别大型语言模型的方法，通过轻量级的指令调整，保护知识产权并确保遵守许可条款。实验证明这种方法不影响模型的正常行为，并且具有鲁棒性和高效训练的特点。 |
| [^152] | [Understanding Video Transformers via Universal Concept Discovery.](http://arxiv.org/abs/2401.10831) | 本文研究了视频Transformer的可解释性问题，引入了视频Transformer概念发现算法来解释其决策过程，并揭示了时空推理机制和对象为中心的表示。 |
| [^153] | [Hallucination Benchmark in Medical Visual Question Answering.](http://arxiv.org/abs/2401.05827) | 这项研究创建了医学图像的幻觉基准评估，并全面评估了当前最先进的模型，揭示了幻觉现象在临床环境中的限制和各种提示策略的有效性。 |
| [^154] | [Advancing Ante-Hoc Explainable Models through Generative Adversarial Networks.](http://arxiv.org/abs/2401.04647) | 本文提出了一种先验可解释模型，通过在主分类器网络中添加无监督的解释生成器和对抗训练的方式，实现了模型的可解释性和性能的提升。该方法通过训练解释模块提取视觉概念，同时使用生成对抗网络模块来区分生成的图像和真实图像。实验证明了该方法的鲁棒性，并展示了学到的概念与对象部分和视觉属性的语义一致性。 |
| [^155] | [Tracking Any Object Amodally.](http://arxiv.org/abs/2312.12433) | 本论文介绍了一种追踪任何物体的非现态方法，利用数据增强和微调现态跟踪器，可以提高追踪的效果。 |
| [^156] | [Navigating Complex Search Tasks with AI Copilots.](http://arxiv.org/abs/2311.01235) | 该论文介绍了使用AI副驾驶员来导航复杂搜索任务，并探讨了生成AI和辅助代理的出现对于支持复杂搜索任务的潜力和重要性。 |
| [^157] | [Multi-Operational Mathematical Derivations in Latent Space.](http://arxiv.org/abs/2311.01230) | 本文研究在潜在空间中逼近多个数学运算进行表达式推导的可能性，并通过构建大规模数据集和使用最先进的神经编码器实例化，探索了不同编码机制在潜在空间中逼近方程推理的能力。 |
| [^158] | [BioImage.IO Chatbot: A Personalized Assistant for BioImage Analysis Augmented by Community Knowledge Base.](http://arxiv.org/abs/2310.18351) | BioImage.IO Chatbot 是一个根据用户个性化需求提供答案的AI聊天助手，通过汇集和解释多个数据库、工具文档和数据源的信息，以及社区贡献的知识库和优化的检索方法，为生物图像分析工具的使用者提供了个性化、上下文感知的体验，为可访问的科学研究设立了新的标准。 |
| [^159] | [Leveraging Ensemble Diversity for Robust Self-Training in the Presence of Sample Selection Bias.](http://arxiv.org/abs/2310.14814) | 本文提出了一种在样本选择偏差存在的情况下，利用集成多样性进行鲁棒的自训练的方法，并引入了一种新的自信度度量方法-$\mathcal{T}$-相似度。实验证明该方法在三种不同伪标签策略下具有良好的效果。 |
| [^160] | [Proper Laplacian Representation Learning.](http://arxiv.org/abs/2310.10833) | 本论文介绍了一种理论上可靠的方法和优化算法，用于近似Laplacian表示学习，以解决大规模强化学习中的探索、泛化和传递问题。 |
| [^161] | [Retro-fallback: retrosynthetic planning in an uncertain world.](http://arxiv.org/abs/2310.09270) | 本文针对逆合成任务在实验室执行可行性的不确定性问题，通过引入随机过程的表述，提出了一种名为 Retro-fallback 的贪婪算法，该算法能够最大化实验室可执行的合成计划的概率。 |
| [^162] | [CReHate: Cross-cultural Re-annotation of English Hate Speech Dataset.](http://arxiv.org/abs/2308.16705) | CReHate通过跨文化重新注释英语仇恨言论数据集，揭示了来自不同国家的个体对仇恨言论的不同看法，并引入了一种具有文化敏感性的分类器。这些发现强调了重新评估NLP研究在仇恨言论领域的必要性。 |
| [^163] | [Probabilistic Dataset Reconstruction from Interpretable Models.](http://arxiv.org/abs/2308.15099) | 本文提出了一个新的框架，实现了从可解释模型中概率重建数据集。在现实假设下，可以高效计算重建的不确定性，以量化信息泄漏的隐私影响。 |
| [^164] | [Ecosystem-level Analysis of Deployed Machine Learning Reveals Homogeneous Outcomes.](http://arxiv.org/abs/2307.05862) | 部署机器学习存在系统性故障, 即使单个模型在总体上的改善也不能解决这个问题 |
| [^165] | [A Double Machine Learning Approach to Combining Experimental and Observational Data.](http://arxiv.org/abs/2307.01449) | 这种双机器学习方法将实验和观测研究结合起来，能够测试假设的违反情况并一致估计处理效应。它提供了半参数高效的处理效应估计器。这种方法在实际环境中是可行的。 |
| [^166] | [CamemBERT-bio: a Tasty French Language Model Better for your Health.](http://arxiv.org/abs/2306.15550) | 本研究介绍了CamemBERT-bio，它是一种针对法语生物医学领域专门设计的语言模型，相对于通用模型在命名实体识别任务上平均提高了2.54个百分点。 |
| [^167] | [Instructions as Backdoors: Backdoor Vulnerabilities of Instruction Tuning for Large Language Models.](http://arxiv.org/abs/2305.14710) | 使用指令调整方法在众包数据集上训练的大规模语言模型，存在后门漏洞，攻击者只需注入极少量的恶意指令便可永久控制模型行为，且难以被修复，需要更加健全的防御机制。 |
| [^168] | [From Isolated Islands to Pangea: Unifying Semantic Space for Human Action Understanding.](http://arxiv.org/abs/2304.00553) | 本文提出了一个统一的语义空间Poincare行为语义空间，通过将以前数据集的类别与这个语义空间对齐，收集（图像/视频/骨架/MoCap）数据集到一个统一的数据库中，即将“孤立的岛屿”桥接成一个“泛大陆”，这将有助于推进可推广的行为学习。 |
| [^169] | [Online Control of Adaptive Large Neighborhood Search using Deep Reinforcement Learning.](http://arxiv.org/abs/2211.00759) | 本研究提出一种基于深度强化学习的方法来在线控制自适应大邻域搜索算法，该方法能够自适应选择启发式策略、调整参数和控制接受标准，以获得优化问题的良好解，对应用组合优化问题中的实际问题具有重要意义。 |

# 详细

[^1]: 可视自回归建模：通过下一尺度预测实现可伸缩图像生成

    Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction

    [https://arxiv.org/abs/2404.02905](https://arxiv.org/abs/2404.02905)

    VAR重新定义了图像上的自回归学习，通过粗到细的“下一尺度预测”实现快速学习视觉分布并超越了扩散变压器。

    

    我们提出了可视自回归建模（VAR），这是一种重新定义自回归学习在图像上的生成范式，将其作为从粗粒度到细粒度的“下一尺度预测”或“下一分辨率预测”，偏离了标准的光栅扫描“下一个令牌预测”。这种简单直观的方法允许自回归（AR）变压器快速学习视觉分布并具有良好泛化能力：VAR首次使AR模型在图像生成方面超越了扩散变压器。在ImageNet 256x256基准测试中，VAR通过将Frechet入侵距离（FID）从18.65提高到1.80，将inception分数（IS）从80.4提高到356.4，推断速度加快了大约20倍，显着改善了AR基线。经验证，VAR在图像质量、推断速度、数据效率和可伸缩性等多个维度上优于扩散变压器（DiT）。扩大VAR模型的规模显示出明显的幂律扩展能力。

    arXiv:2404.02905v1 Announce Type: cross  Abstract: We present Visual AutoRegressive modeling (VAR), a new generation paradigm that redefines the autoregressive learning on images as coarse-to-fine "next-scale prediction" or "next-resolution prediction", diverging from the standard raster-scan "next-token prediction". This simple, intuitive methodology allows autoregressive (AR) transformers to learn visual distributions fast and generalize well: VAR, for the first time, makes AR models surpass diffusion transformers in image generation. On ImageNet 256x256 benchmark, VAR significantly improve AR baseline by improving Frechet inception distance (FID) from 18.65 to 1.80, inception score (IS) from 80.4 to 356.4, with around 20x faster inference speed. It is also empirically verified that VAR outperforms the Diffusion Transformer (DiT) in multiple dimensions including image quality, inference speed, data efficiency, and scalability. Scaling up VAR models exhibits clear power-law scaling la
    
[^2]: ALOHa：测量图像字幕模型中幻觉的新标准

    ALOHa: A New Measure for Hallucination in Captioning Models

    [https://arxiv.org/abs/2404.02904](https://arxiv.org/abs/2404.02904)

    提出了一种新的用于测量图像字幕模型中幻觉的标准ALOHa，利用大型语言模型来测量幻觉对象，并成功识别比现有指标CHAIR更多的幻觉对象。

    

    尽管在视觉描述的多模态预训练方面取得了近期的进展，但最先进的模型仍会产生包含错误的字幕，比如在场景中存在幻觉对象。现有的主要幻觉对象度量标准CHAIR，仅限于一组固定的MS COCO对象和同义词。在这项工作中，我们提出了一种现代化的开放词汇度量标准ALOHa，利用大型语言模型（LLM）来衡量对象幻觉。具体地，我们使用LLM从候选字幕中提取可连接的对象，衡量它们与字幕和对象检测中参考对象的语义相似度，并使用匈牙利匹配生成最终的幻觉得分。我们展示了ALOHa在HAT上比CHAIR在一个新的用于幻觉标记的MS COCO字幕的金标准子集上正确识别了更多的幻觉对象（多出13.6%），在nocaps上（其中对象超出了MS COCO类别）识别了更多的幻觉对象（多至30.8%）。

    arXiv:2404.02904v1 Announce Type: cross  Abstract: Despite recent advances in multimodal pre-training for visual description, state-of-the-art models still produce captions containing errors, such as hallucinating objects not present in a scene. The existing prominent metric for object hallucination, CHAIR, is limited to a fixed set of MS COCO objects and synonyms. In this work, we propose a modernized open-vocabulary metric, ALOHa, which leverages large language models (LLMs) to measure object hallucinations. Specifically, we use an LLM to extract groundable objects from a candidate caption, measure their semantic similarity to reference objects from captions and object detections, and use Hungarian matching to produce a final hallucination score. We show that ALOHa correctly identifies 13.6% more hallucinated objects than CHAIR on HAT, a new gold-standard subset of MS COCO Captions annotated for hallucinations, and 30.8% more on nocaps, where objects extend beyond MS COCO categories.
    
[^3]: DeiT-LT蒸馏重返，用于长尾数据集上的Vision Transformer训练

    DeiT-LT Distillation Strikes Back for Vision Transformer Training on Long-Tailed Datasets

    [https://arxiv.org/abs/2404.02900](https://arxiv.org/abs/2404.02900)

    DeiT-LT通过引入一种有效的蒸馏方式，将CNN蒸馏到ViT中，以应对长尾数据集上训练ViT时的困难。

    

    Vision Transformer（ViT）已经成为各种计算机视觉任务中突出的架构。在 ViT 中，我们将输入图像分成补丁令牌，并通过一堆自我注意块进行处理。然而，与卷积神经网络（CNN）不同，ViT 的简单架构没有信息性归纳偏差（例如局部性等）。由于这个原因，ViT 需要大量数据进行预训练。已经提出了各种数据有效的方法（DeiT）来有效地训练平衡的数据集上的ViT。然而，文献中很少讨论使用ViT来处理长尾不平衡数据集。在这项工作中，我们引入DeiT-LT来解决从头开始训练长尾数据集上的ViT的问题。在 DeiT-LT 中，我们通过使用超出分布图像和重新加权蒸馏损失，引入了一种有效的蒸馏方式，通过蒸馏 DIST 令牌从CNN进行蒸馏，以增强对尾部类别的关注。

    arXiv:2404.02900v1 Announce Type: cross  Abstract: Vision Transformer (ViT) has emerged as a prominent architecture for various computer vision tasks. In ViT, we divide the input image into patch tokens and process them through a stack of self attention blocks. However, unlike Convolutional Neural Networks (CNN), ViTs simple architecture has no informative inductive bias (e.g., locality,etc. ). Due to this, ViT requires a large amount of data for pre-training. Various data efficient approaches (DeiT) have been proposed to train ViT on balanced datasets effectively. However, limited literature discusses the use of ViT for datasets with long-tailed imbalances. In this work, we introduce DeiT-LT to tackle the problem of training ViTs from scratch on long-tailed datasets. In DeiT-LT, we introduce an efficient and effective way of distillation from CNN via distillation DIST token by using out-of-distribution images and re-weighting the distillation loss to enhance focus on tail classes. Thi
    
[^4]: 关于基于扩散的文本到图像生成方法的可扩展性

    On the Scalability of Diffusion-based Text-to-Image Generation

    [https://arxiv.org/abs/2404.02883](https://arxiv.org/abs/2404.02883)

    本研究通过针对扩散型T2I模型进行消融实验，发现增加transformer块对于改善文本-图像对齐比增加通道数更具参数效率。

    

    扩大模型和数据规模对于LLMs的发展取得了相当大的成功。然而，尚未充分探讨基于扩散的文本到图像（T2I）模型的扩展法则。如何有效地扩展模型以在降低成本的情况下提高性能也不太清楚。不同的训练设置和昂贵的训练成本使得进行公平的模型比较变得极为困难。在本研究中，我们通过对去噪骨干和训练集的大量而严格的消融实验，对扩散型T2I模型的扩展特性进行了实证研究，包括在数据集上达到600M图像的范围内训练参数从0.4B到4B的缩放UNet和Transformer变体。对于模型的扩展，我们发现跨关注的位置和数量区分了现有UNet设计的性能。增加transformer块对于提高文本-图像对齐比增加通道数更具参数效率。

    arXiv:2404.02883v1 Announce Type: cross  Abstract: Scaling up model and data size has been quite successful for the evolution of LLMs. However, the scaling law for the diffusion based text-to-image (T2I) models is not fully explored. It is also unclear how to efficiently scale the model for better performance at reduced cost. The different training settings and expensive training cost make a fair model comparison extremely difficult. In this work, we empirically study the scaling properties of diffusion based T2I models by performing extensive and rigours ablations on scaling both denoising backbones and training set, including training scaled UNet and Transformer variants ranging from 0.4B to 4B parameters on datasets upto 600M images. For model scaling, we find the location and amount of cross attention distinguishes the performance of existing UNet designs. And increasing the transformer blocks is more parameter-efficient for improving text-image alignment than increasing channel nu
    
[^5]: FlightScope: 卫星图像中飞行器检测算法的深度全面评估

    FlightScope: A Deep Comprehensive Assessment of Aircraft Detection Algorithms in Satellite Imagery

    [https://arxiv.org/abs/2404.02877](https://arxiv.org/abs/2404.02877)

    本研究对卫星图像中识别飞机的任务自定义的一套先进对象检测算法进行了全面评估和比较，发现YOLOv5是在不同成像条件下展现高精度和适应性的最优模型。

    

    arXiv:2404.02877v1 公告类型：跨领域 摘要：在遥感卫星图像中进行对象检测对于许多领域，如生物物理学和环境监测至关重要。尽管深度学习算法不断发展，但它们大多在常见的基于地面拍摄的照片上实施和测试。本文对一套针对在卫星图像中识别飞机这一任务定制的先进对象检测算法进行了批判性评估和比较。利用大型HRPlanesV2数据集，以及与GDIT数据集的严格验证，该研究涵盖了一系列方法，包括YOLO版本5和8、Faster RCNN、CenterNet、RetinaNet、RTMDet和DETR，均是从头开始训练的。这项全面的训练和验证研究揭示了YOLOv5作为识别遥感数据中的飞机这一特定案例的卓越模型，展示了其在不同成像条件下的高精度和适应性。

    arXiv:2404.02877v1 Announce Type: cross  Abstract: Object detection in remotely sensed satellite pictures is fundamental in many fields such as biophysical, and environmental monitoring. While deep learning algorithms are constantly evolving, they have been mostly implemented and tested on popular ground-based taken photos. This paper critically evaluates and compares a suite of advanced object detection algorithms customized for the task of identifying aircraft within satellite imagery. Using the large HRPlanesV2 dataset, together with a rigorous validation with the GDIT dataset, this research encompasses an array of methodologies including YOLO versions 5 and 8, Faster RCNN, CenterNet, RetinaNet, RTMDet, and DETR, all trained from scratch. This exhaustive training and validation study reveal YOLOv5 as the preeminent model for the specific case of identifying airplanes from remote sensing data, showcasing high precision and adaptability across diverse imaging conditions. This research
    
[^6]: 整合解释在从演示中学习LTL规范中的应用

    Integrating Explanations in Learning LTL Specifications from Demonstrations

    [https://arxiv.org/abs/2404.02872](https://arxiv.org/abs/2404.02872)

    这项研究提出了一种整合大型语言模型和基于优化方法的方法，用于将人类解释和演示准确地转化为LTL规范。

    

    本文研究最近大型语言模型（LLMs）的进展是否有助于将人类解释转化为能够稳健支持从演示中学习线性时间逻辑（LTL）的格式。LLMs和基于优化的方法都可以从演示中提取LTL规范；然而，它们存在着明显的局限性。LLMs可以快速生成解决方案并整合人类解释，但缺乏一致性和可靠性限制了它们在安全关键领域的适用性。另一方面，基于优化的方法可以提供形式化保证，但无法处理自然语言解释并面临可扩展性挑战。我们提出了一种有原则的方法，将LLMs和基于优化的方法相结合，忠实地将人类解释和演示转化为LTL规范。我们基于我们的方法实现了一个名为Janaka的工具。我们的实验证明

    arXiv:2404.02872v1 Announce Type: new  Abstract: This paper investigates whether recent advances in Large Language Models (LLMs) can assist in translating human explanations into a format that can robustly support learning Linear Temporal Logic (LTL) from demonstrations. Both LLMs and optimization-based methods can extract LTL specifications from demonstrations; however, they have distinct limitations. LLMs can quickly generate solutions and incorporate human explanations, but their lack of consistency and reliability hampers their applicability in safety-critical domains. On the other hand, optimization-based methods do provide formal guarantees but cannot process natural language explanations and face scalability challenges. We present a principled approach to combining LLMs and optimization-based methods to faithfully translate human explanations and demonstrations into LTL specifications. We have implemented a tool called Janaka based on our approach. Our experiments demonstrate th
    
[^7]: 使用智能手机进行人类活动识别

    Human Activity Recognition using Smartphones

    [https://arxiv.org/abs/2404.02869](https://arxiv.org/abs/2404.02869)

    该论文通过智能手机的加速度计捕获不同日常活动的数据，提取特征并应用机器学习算法实现实时活动识别和卡路里消耗计算。

    

    人类活动识别是当前的研究热点之一，在远程医疗、老年人或残障人士活动跟踪、消耗卡路里等领域有广泛应用。在我们的项目中，我们创建了一个Android应用程序，可以实时识别日常人类活动并计算消耗的卡路里。我们首先通过智能手机的内置加速度计捕获了不同日常人类活动的标记三轴加速度读数。然后使用中值滤波对这些读数进行预处理。我们使用各种方法提取了42个特征。接着，我们测试了各种机器学习算法以及降维方法。最后，在我们的Android应用程序中，我们使用了机器学习算法和提供了最高准确性和最短模型构建时间的特征子集。这用于实时活动识别和利用基于代谢的公式计算消耗的卡路里。

    arXiv:2404.02869v1 Announce Type: cross  Abstract: Human Activity Recognition is a subject of great research today and has its applications in remote healthcare, activity tracking of the elderly or the disables, calories burnt tracking etc. In our project, we have created an Android application that recognizes the daily human activities and calculate the calories burnt in real time. We first captured labeled triaxial acceleration readings for different daily human activities from the smartphone's embedded accelerometer. These readings were preprocessed using a median filter. 42 features were extracted using various methods. We then tested various machine learning algorithms along with dimensionality reduction. Finally, in our Android application, we used the machine learning algorithm and a subset of features that provided maximum accuracy and minimum model building time. This is used for real-time activity recognition and calculation of calories burnt using a formula based on Metaboli
    
[^8]: I-Design: 个性化的LLM室内设计师

    I-Design: Personalized LLM Interior Designer

    [https://arxiv.org/abs/2404.02838](https://arxiv.org/abs/2404.02838)

    I-Design是一个个性化室内设计师，通过自然语言交流生成和可视化用户设计目标，从而使室内设计更具可访问性。

    

    室内设计让我们展示真实的自我，生活方式也由此展现——每个设计都如同我们各自独特的个性。然而，对于非专业人员来说，表达和实现这一点并不是件轻松的事，因为它要求将功能性和视觉期望与物理空间的限制相协调；这使得室内设计成为一种奢侈。为了让它更易于获得，我们提出了I-Design，一个个性化的室内设计师，允许用户通过自然语言交流生成和可视化他们的设计目标。I-Design从一个大型语言模型代理团队开始，他们通过对话和逻辑推理相互交互，将文本用户输入转换为具有相对对象关系的可行场景图设计。随后，一个有效的放置算法确定了场景内每个对象的最佳位置。最终设计会通过从一个

    arXiv:2404.02838v1 Announce Type: new  Abstract: Interior design allows us to be who we are and live how we want - each design is as unique as our distinct personality. However, it is not trivial for non-professionals to express and materialize this since it requires aligning functional and visual expectations with the constraints of physical space; this renders interior design a luxury. To make it more accessible, we present I-Design, a personalized interior designer that allows users to generate and visualize their design goals through natural language communication. I-Design starts with a team of large language model agents that engage in dialogues and logical reasoning with one another, transforming textual user input into feasible scene graph designs with relative object relationships. Subsequently, an effective placement algorithm determines optimal locations for each object within the scene. The final design is then constructed in 3D by retrieving and integrating assets from an 
    
[^9]: 利用AI代理赋能生物医学发现

    Empowering Biomedical Discovery with AI Agents

    [https://arxiv.org/abs/2404.02831](https://arxiv.org/abs/2404.02831)

    AI科学家代理结合人类创造力和专业知识，利用机器学习工具赋能生物医学研究，对多个领域产生影响。

    

    我们设想“AI科学家”作为系统，能够进行怀疑性学习和推理，通过将机器学习工具与实验平台集成的协作代理，赋能生物医学研究。生物医学AI代理不是要剔除人类在发现过程中的作用，而是结合人类的创造力和专业知识，利用AI分析大型数据集、导航假设空间，并执行重复性任务的能力。这些代理擅长各种任务，包括自我评估和规划发现工作流程。它们利用大型语言模型和生成模型进行结构化记忆，以便持续学习，并利用机器学习工具整合科学知识、生物原理和理论。AI代理可以影响从混合细胞模拟、可编程控制表型到细胞电路设计以及新疗法开发等领域。

    arXiv:2404.02831v1 Announce Type: new  Abstract: We envision 'AI scientists' as systems capable of skeptical learning and reasoning that empower biomedical research through collaborative agents that integrate machine learning tools with experimental platforms. Rather than taking humans out of the discovery process, biomedical AI agents combine human creativity and expertise with AI's ability to analyze large datasets, navigate hypothesis spaces, and execute repetitive tasks. AI agents are proficient in a variety of tasks, including self-assessment and planning of discovery workflows. These agents use large language models and generative models to feature structured memory for continual learning and use machine learning tools to incorporate scientific knowledge, biological principles, and theories. AI agents can impact areas ranging from hybrid cell simulation, programmable control of phenotypes, and the design of cellular circuits to the development of new therapies.
    
[^10]: 使用可解释的人类原型提升椎体骨折分级的解释性

    Enhancing Interpretability of Vertebrae Fracture Grading using Human-interpretable Prototypes

    [https://arxiv.org/abs/2404.02830](https://arxiv.org/abs/2404.02830)

    使用ProtoVerse方法，我们提出了一种可解释的原型设计方法，可以可靠地解释深度学习模型对椎体骨折的分类决策，表现优于现有的基于原型的方法。

    

    椎体骨折分级分类骨折严重程度，这在医学成像中是一项具有挑战性的任务，近年来吸引了深度学习（DL）模型。尽管DL辅助医学诊断等关键应用场景需要透明性和可信度，但只有少数工作尝试使这种模型具有人类可解释性。此外，这些模型要么依赖于事后方法，要么依赖于额外注释。在这项工作中，我们提出了一种新颖的可解释-by-design方法ProtoVerse，以在人类可理解的方式中找到相关的椎体骨折子部分（原型），可可靠地解释模型的决策。具体来说，我们引入了一种新颖的多样性促进损失，以减轻在具有复杂语义的小数据集中原型重复的问题。我们在VerSe'19数据集上进行了实验，并优于现有的基于原型的方法。此外，我们的模型在解释性方面表现更优秀。

    arXiv:2404.02830v1 Announce Type: cross  Abstract: Vertebral fracture grading classifies the severity of vertebral fractures, which is a challenging task in medical imaging and has recently attracted Deep Learning (DL) models. Only a few works attempted to make such models human-interpretable despite the need for transparency and trustworthiness in critical use cases like DL-assisted medical diagnosis. Moreover, such models either rely on post-hoc methods or additional annotations. In this work, we propose a novel interpretable-by-design method, ProtoVerse, to find relevant sub-parts of vertebral fractures (prototypes) that reliably explain the model's decision in a human-understandable way. Specifically, we introduce a novel diversity-promoting loss to mitigate prototype repetitions in small datasets with intricate semantics. We have experimented with the VerSe'19 dataset and outperformed the existing prototype-based method. Further, our model provides superior interpretability agains
    
[^11]: Conifer: 提高大型语言模型复杂约束指令遵循能力

    Conifer: Improving Complex Constrained Instruction-Following Ability of Large Language Models

    [https://arxiv.org/abs/2404.02823](https://arxiv.org/abs/2404.02823)

    Conifer提出了一个新的指令调节数据集，通过LLMs驱动的细化过程，以及渐进学习方案，显著提高了大型语言模型遵循具有复杂约束的多层指令的能力

    

    大型语言模型(LLMs)遵循指令的能力对实际应用至关重要。尽管最近取得进展，但一些研究指出，LLMs在面对具有挑战性指令时存在困难，特别是包含复杂约束的指令，阻碍了它们在各种任务中的有效性。为解决这一挑战，我们引入了Conifer，这是一个新颖的指令调节数据集，旨在增强LLMs遵循具有复杂约束的多层指令。通过一系列LLM驱动的细化过程，我们利用GPT-4策划了这个数据集以确保高质量。我们还提出了一个强调易于难的渐进学习方案，并从过程反馈中学习。使用Conifer训练的模型在遵循指令能力方面表现出显著改善，特别是对于带有复杂约束的指令。在几个遵循指令的基准测试中，我们的7B模型表现优异

    arXiv:2404.02823v1 Announce Type: cross  Abstract: The ability of large language models (LLMs) to follow instructions is crucial to real-world applications. Despite recent advances, several studies have highlighted that LLMs struggle when faced with challenging instructions, especially those that include complex constraints, hindering their effectiveness in various tasks. To address this challenge, we introduce Conifer, a novel instruction tuning dataset, designed to enhance LLMs to follow multi-level instructions with complex constraints. Utilizing GPT-4, we curate the dataset by a series of LLM-driven refinement processes to ensure high quality. We also propose a progressive learning scheme that emphasizes an easy-to-hard progression, and learning from process feedback. Models trained with Conifer exhibit remarkable improvements in instruction-following abilities, especially for instructions with complex constraints. On several instruction-following benchmarks, our 7B model outperfor
    
[^12]: 优化型任务与运动规划综述：从经典到学习方法

    A Survey of Optimization-based Task and Motion Planning: From Classical To Learning Approaches

    [https://arxiv.org/abs/2404.02817](https://arxiv.org/abs/2404.02817)

    本综述全面审视了基于优化的任务与运动规划，重点讨论了如何通过混合优化方法解决高度复杂、接触丰富的机器人运动和操作问题。

    

    任务与运动规划（TAMP）将高层任务规划和低层运动规划结合起来，使机器人能够有效地推理解决长时域、动态任务。基于优化的TAMP专注于通过目标函数定义目标条件的混合优化方法，并且能够处理开放式目标、机器人动态和机器人与环境之间的物理交互。因此，基于优化的TAMP特别适合解决高度复杂、接触丰富的运动和操作问题。本综述全面审视了基于优化的TAMP，涵盖了（i）规划领域表示，包括动作描述语言和时态逻辑，（ii）TAMP各组件的个别解决策略，包括人工智能规划和轨迹优化（TO），以及（iii）基于逻辑的任务规划与基于模型的TO之间的动态相互作用。

    arXiv:2404.02817v1 Announce Type: cross  Abstract: Task and Motion Planning (TAMP) integrates high-level task planning and low-level motion planning to equip robots with the autonomy to effectively reason over long-horizon, dynamic tasks. Optimization-based TAMP focuses on hybrid optimization approaches that define goal conditions via objective functions and are capable of handling open-ended goals, robotic dynamics, and physical interaction between the robot and the environment. Therefore, optimization-based TAMP is particularly suited to solve highly complex, contact-rich locomotion and manipulation problems. This survey provides a comprehensive review on optimization-based TAMP, covering (i) planning domain representations, including action description languages and temporal logic, (ii) individual solution strategies for components of TAMP, including AI planning and trajectory optimization (TO), and (iii) the dynamic interplay between logic-based task planning and model-based TO. A 
    
[^13]: 一个个性化被动心脏力学的优化框架

    An Optimization Framework to Personalize Passive Cardiac Mechanics

    [https://arxiv.org/abs/2404.02807](https://arxiv.org/abs/2404.02807)

    这个研究提出了一个逆有限元分析框架来个性化估计心脏组织的被动力学特性，通过嵌套优化方案的使用，可以更好地逼近匹配图像数据的材料参数。

    

    个性化的心脏力学建模是一种强大的工具，用于理解心脏功能在健康和疾病中的生物力学并帮助治疗计划。然而，当前的模型仅限于使用在单一心脏相位获取的医学图像，通常限制了它们用于处理动态图像获取的适用性。本研究介绍了一种逆有限元分析（iFEA）框架，使用时间相关的医学图像数据来估计心脏组织的被动机械特性。该iFEA框架依赖于一种新颖的嵌套优化方案，其中外部迭代利用传统优化方法来最佳逼近匹配图像数据的材料参数，而内部迭代采用增广Sellier算法来估计无应力参考构型。重点放在表征被动机械行为上，该框架采用基于结构的方法

    arXiv:2404.02807v1 Announce Type: cross  Abstract: Personalized cardiac mechanics modeling is a powerful tool for understanding the biomechanics of cardiac function in health and disease and assisting in treatment planning. However, current models are limited to using medical images acquired at a single cardiac phase, often limiting their applicability for processing dynamic image acquisitions. This study introduces an inverse finite element analysis (iFEA) framework to estimate the passive mechanical properties of cardiac tissue using time-dependent medical image data. The iFEA framework relies on a novel nested optimization scheme, in which the outer iterations utilize a traditional optimization method to best approximate material parameters that fit image data, while the inner iterations employ an augmented Sellier's algorithm to estimate the stress-free reference configuration. With a focus on characterizing the passive mechanical behavior, the framework employs structurally based 
    
[^14]: RealHumanEval: 评估大型语言模型支持程序员的能力

    The RealHumanEval: Evaluating Large Language Models' Abilities to Support Programmers

    [https://arxiv.org/abs/2404.02806](https://arxiv.org/abs/2404.02806)

    评估了大型语言模型在支持程序员方面的能力，引入了RealHumanEval作为衡量其帮助性的界面，并探讨了其对程序员生产力的影响。

    

    大型语言模型（LLMs）的评估主要依赖于静态基准，包括HumanEval（Chen等，2021），这些基准用于衡量LLMs生成通过单元测试的完整代码的能力。随着LLMs越来越多地被用作程序员助手，我们研究现有基准上的增益是否能转化为使用LLMs编码时程序员生产力的提升，包括编码所花费的时间。除了静态基准，我们还研究了可能用作度量LLM帮助性代理的偏好度量的实用性，例如代码接受或复制率。为此，我们引入了RealHumanEval，这是一个用于衡量LLMs辅助程序员的能力的网络界面，可以通过自动完成或聊天支持。我们进行了一个用户研究（N = 213），使用RealHumanEval，其中用户与六个基础模型性能各异的LLMs进行交互。尽管静态基准没有包含人为干预，我们...

    arXiv:2404.02806v1 Announce Type: cross  Abstract: Evaluation of large language models (LLMs) for code has primarily relied on static benchmarks, including HumanEval (Chen et al., 2021), which measure the ability of LLMs to generate complete code that passes unit tests. As LLMs are increasingly used as programmer assistants, we study whether gains on existing benchmarks translate to gains in programmer productivity when coding with LLMs, including time spent coding. In addition to static benchmarks, we investigate the utility of preference metrics that might be used as proxies to measure LLM helpfulness, such as code acceptance or copy rates. To do so, we introduce RealHumanEval, a web interface to measure the ability of LLMs to assist programmers, through either autocomplete or chat support. We conducted a user study (N=213) using RealHumanEval in which users interacted with six LLMs of varying base model performance. Despite static benchmarks not incorporating humans-in-the-loop, we 
    
[^15]: 有关叙事理解中可控问题回答生成的少样本提示研究

    On Few-Shot Prompting for Controllable Question-Answer Generation in Narrative Comprehension

    [https://arxiv.org/abs/2404.02800](https://arxiv.org/abs/2404.02800)

    提出了用于控制从儿童叙事文本中生成问题-答案对的少样本提示策略，旨在控制问题的明确性和潜在叙事元素，通过与参考模型并行进行实证评估，结果显示在语义接近度评估和问题-答案对的多样性和连贯性方面，少样本策略超越了参考模型。

    

    问题生成旨在根据给定的上下文自动生成问题。可控问题生成方案侧重于生成具有特定属性的问题，从而实现更好的控制。在本研究中，我们提出了一种少样本提示策略，用于控制从儿童叙事文本中生成问题-答案对的过程。我们旨在控制两个属性：问题的明确性和潜在叙事元素。通过实证评估，我们展示了通过采用少样本提示与参考模型并行控制生成过程的有效性。我们的实验凸显了少样本策略超越参考模型的实例，特别是在语义接近度评估以及问题-答案对的多样性和连贯性等场景中。然而，这些改进并不总是统计上显著的。代码已公开发布。

    arXiv:2404.02800v1 Announce Type: cross  Abstract: Question Generation aims to automatically generate questions based on a given input provided as context. A controllable question generation scheme focuses on generating questions with specific attributes, allowing better control. In this study, we propose a few-shot prompting strategy for controlling the generation of question-answer pairs from children's narrative texts. We aim to control two attributes: the question's explicitness and underlying narrative elements. With empirical evaluation, we show the effectiveness of controlling the generation process by employing few-shot prompting side by side with a reference model. Our experiments highlight instances where the few-shot strategy surpasses the reference model, particularly in scenarios such as semantic closeness evaluation and the diversity and coherency of question-answer pairs. However, these improvements are not always statistically significant. The code is publicly available
    
[^16]: 通过元学习实现领域泛化：一项调查

    Domain Generalization through Meta-Learning: A Survey

    [https://arxiv.org/abs/2404.02785](https://arxiv.org/abs/2404.02785)

    元学习是一种有前景的方法，通过获取可转移知识实现在各种任务之间快速适应，为解决深度神经网络在面对分布变化和有限标记数据时泛化能力不佳提供了新途径。

    

    深度神经网络(DNNs)已经彻底改变了人工智能，但是当面对分布之外(out-of-distribution, OOD)数据时往往表现不佳，这是因为在现实世界应用中由于领域转移不可避免，训练和测试数据被假定为共享相同分布的常见情况。尽管DNNs在大量数据和计算能力方面非常有效，但它们很难应对分布变化和有限标记数据，导致过拟合和跨不同任务和领域的泛化能力不佳。元学习提供了一种有前途的方法，通过采用能够在各种任务之间获取可转移知识的算法进行快速适应，从而消除了需要从头学习每个任务的必要性。本调查论文深入探讨了元学习领域，重点关注其对领域泛化的贡献。

    arXiv:2404.02785v1 Announce Type: cross  Abstract: Deep neural networks (DNNs) have revolutionized artificial intelligence but often lack performance when faced with out-of-distribution (OOD) data, a common scenario due to the inevitable domain shifts in real-world applications. This limitation stems from the common assumption that training and testing data share the same distribution-an assumption frequently violated in practice. Despite their effectiveness with large amounts of data and computational power, DNNs struggle with distributional shifts and limited labeled data, leading to overfitting and poor generalization across various tasks and domains. Meta-learning presents a promising approach by employing algorithms that acquire transferable knowledge across various tasks for fast adaptation, eliminating the need to learn each task from scratch. This survey paper delves into the realm of meta-learning with a focus on its contribution to domain generalization. We first clarify the 
    
[^17]: AQuA --结合专家和非专家观点，利用LLMs评估在线讨论中的磋商质量

    AQuA -- Combining Experts' and Non-Experts' Views To Assess Deliberation Quality in Online Discussions Using LLMs

    [https://arxiv.org/abs/2404.02761](https://arxiv.org/abs/2404.02761)

    提出了AQuA，一种综合的磋商质量得分计算方法，可以从多个指标中提取各个讨论帖子的统一得分，保留了评论中磋商方面的信息，提高了模型的透明度。

    

    在政治在线讨论中衡量贡献质量对于研究磋商和计算机科学至关重要。随着深度学习的进步，自动衡量这些指标变得可行。本文介绍了AQuA，它是一个添加分数，从多个指标中计算每个讨论帖子的统一磋商质量得分。与其他特定分数不同，AQuA保留了评论中存在的磋商方面的信息，增强了模型的透明度。

    arXiv:2404.02761v1 Announce Type: cross  Abstract: Measuring the quality of contributions in political online discussions is crucial in deliberation research and computer science. Research has identified various indicators to assess online discussion quality, and with deep learning advancements, automating these measures has become feasible. While some studies focus on analyzing specific quality indicators, a comprehensive quality score incorporating various deliberative aspects is often preferred. In this work, we introduce AQuA, an additive score that calculates a unified deliberative quality score from multiple indices for each discussion post. Unlike other singular scores, AQuA preserves information on the deliberative aspects present in comments, enhancing model transparency. We develop adapter models for 20 deliberative indices, and calculate correlation coefficients between experts' annotations and the perceived deliberativeness by non-experts to weigh the individual indices int
    
[^18]: 来自稀疏点云的无监督占用学习

    Unsupervised Occupancy Learning from Sparse Point Cloud

    [https://arxiv.org/abs/2404.02759](https://arxiv.org/abs/2404.02759)

    提出了一种从稀疏输入学习占用场的无监督学习方法，通过基于边界不确定性的采样和最小熵场优化来解决从3D点云学习SDF的挑战

    

    隐式神经表示已经成为一个强大的框架，可用于捕获复杂的数据模态，涵盖从3D形状到图像和音频等广泛范围。在3D形状表示领域，神经符号距离函数（SDF）展现出从根本上编码复杂形状几何的显著潜力。然而，在没有地面真实监督的情况下，从3D点云中学习SDF仍然是一项非常具有挑战性的任务。在本文中，我们提出了一种方法来推断占用场而不是SDF，因为它们更容易从稀疏输入中学习。我们利用基于边界不确定性的边际测量，不同地从占用函数的决策边界中采样，并使用输入点云监督采样的边界点。我们在训练的早期阶段通过将占用函数偏向最小熵场来进一步稳定优化过程。

    arXiv:2404.02759v1 Announce Type: cross  Abstract: Implicit Neural Representations have gained prominence as a powerful framework for capturing complex data modalities, encompassing a wide range from 3D shapes to images and audio. Within the realm of 3D shape representation, Neural Signed Distance Functions (SDF) have demonstrated remarkable potential in faithfully encoding intricate shape geometry. However, learning SDFs from 3D point clouds in the absence of ground truth supervision remains a very challenging task. In this paper, we propose a method to infer occupancy fields instead of SDFs as they are easier to learn from sparse inputs. We leverage a margin-based uncertainty measure to differentially sample from the decision boundary of the occupancy function and supervise the sampled boundary points using the input point cloud. We further stabilize the optimization process at the early stages of the training by biasing the occupancy function towards minimal entropy fields while max
    
[^19]: 通过伪边界丰富和在线细化提高无标注视频的密集视频字幕质量的 DIBS: 用未标的视频增强密集视频字幕

    DIBS: Enhancing Dense Video Captioning with Unlabeled Videos via Pseudo Boundary Enrichment and Online Refinement

    [https://arxiv.org/abs/2404.02755](https://arxiv.org/abs/2404.02755)

    DIBS是一种用于密集视频字幕（DVC）的预训练框架，通过优化生成的事件字幕和伪事件边界的质量，并引入在线边界细化策略，显著提高了在未标注视频上的效果。

    

    我们提出了 Dive Into the BoundarieS (DIBS)，这是一种新颖的用于密集视频字幕（DVC）的预训练框架，详细阐述了如何从未标记的视频中提高生成的事件字幕及其关联伪事件边界的质量。通过利用不同大型语言模型（LLMs）的能力，我们生成丰富的面向DVC的字幕候选项，并根据几个精心设计的目标优化相应的伪边界，考虑到多样性、事件中心性、时间排序和连贯性。此外，我们还引入了一种新颖的在线边界细化策略，迭代地在训练过程中提高伪边界的质量。我们进行了全面的实验，来检验所提出技术组件的有效性。通过利用大量未标记的视频数据，如 HowTo100M，我们在标准的 DVC 数据集上实现了显著的进展。

    arXiv:2404.02755v1 Announce Type: cross  Abstract: We present Dive Into the BoundarieS (DIBS), a novel pretraining framework for dense video captioning (DVC), that elaborates on improving the quality of the generated event captions and their associated pseudo event boundaries from unlabeled videos. By leveraging the capabilities of diverse large language models (LLMs), we generate rich DVC-oriented caption candidates and optimize the corresponding pseudo boundaries under several meticulously designed objectives, considering diversity, event-centricity, temporal ordering, and coherence. Moreover, we further introduce a novel online boundary refinement strategy that iteratively improves the quality of pseudo boundaries during training. Comprehensive experiments have been conducted to examine the effectiveness of the proposed technique components. By leveraging a substantial amount of unlabeled video data, such as HowTo100M, we achieve a remarkable advancement on standard DVC datasets lik
    
[^20]: 在具有隐藏神经元的递归网络中学习序列吸引子

    Learning Sequence Attractors in Recurrent Networks with Hidden Neurons

    [https://arxiv.org/abs/2404.02729](https://arxiv.org/abs/2404.02729)

    本研究研究了具有隐藏神经元的递归网络如何学习序列吸引子，以稳健地存储和检索预定义的模式序列，结果表明网络需要包含隐藏神经元来存储任意模式序列，并开发了一种局部学习算法实现这一目标。

    

    大脑被设计用来处理时间序列信息。目前尚不清楚大脑是如何学习存储和检索序列记忆的。在本研究中，我们研究了具有二进制神经元的递归网络如何学习序列吸引子，以存储预定义的模式序列并稳健地检索它们。我们表明，为了存储任意模式序列，网络需要包含隐藏神经元，即使它们在显示序列记忆方面的作用是间接的。我们开发了一种局部学习算法，用于学习带有隐藏神经元的网络中的序列吸引子。该算法被证明会收敛并导致序列吸引子。我们展示了该网络模型可以在合成和真实数据集上稳健地存储和检索序列。我们希望这项研究能够为理解大脑中的序列记忆和时间信息处理提供新的见解。

    arXiv:2404.02729v1 Announce Type: cross  Abstract: The brain is targeted for processing temporal sequence information. It remains largely unclear how the brain learns to store and retrieve sequence memories. Here, we study how recurrent networks of binary neurons learn sequence attractors to store predefined pattern sequences and retrieve them robustly. We show that to store arbitrary pattern sequences, it is necessary for the network to include hidden neurons even though their role in displaying sequence memories is indirect. We develop a local learning algorithm to learn sequence attractors in the networks with hidden neurons. The algorithm is proven to converge and lead to sequence attractors. We demonstrate that the network model can store and retrieve sequences robustly on synthetic and real-world datasets. We hope that this study provides new insights in understanding sequence memory and temporal information processing in the brain.
    
[^21]: 机器人学中有效动作的无监督学习

    Unsupervised Learning of Effective Actions in Robotics

    [https://arxiv.org/abs/2404.02728](https://arxiv.org/abs/2404.02728)

    该论文提出了一种无监督算法，通过在探索阶段将连续运动空间离散化, 自动生成“动作原型”, 从而实现机器人动作的效果驱动学习

    

    学习与决策相关且可以有效执行的动作是自主机器人中的关键问题。当前机器人学中最先进的动作表示缺乏对机器人动作的适当效果驱动学习。尽管深度学习方法在解决操纵任务方面取得成功，但它们也缺乏这种能力，而且在内存或训练数据方面成本高。在本文中，我们提出了一种无监督算法，用于对连续运动空间进行离散化，生成“动作原型”，每个原型在环境中产生不同的效果。在探索阶段之后，该算法会自动构建对效果的表示，并将动作分组为动作原型，其中更有可能产生效果的动作比导致可忽略变化的动作更多地表示。我们在模拟楼梯攀登强化学习任务上评估了我们的方法，初步结果表明...

    arXiv:2404.02728v1 Announce Type: cross  Abstract: Learning actions that are relevant to decision-making and can be executed effectively is a key problem in autonomous robotics. Current state-of-the-art action representations in robotics lack proper effect-driven learning of the robot's actions. Although successful in solving manipulation tasks, deep learning methods also lack this ability, in addition to their high cost in terms of memory or training data. In this paper, we propose an unsupervised algorithm to discretize a continuous motion space and generate "action prototypes", each producing different effects in the environment. After an exploration phase, the algorithm automatically builds a representation of the effects and groups motions into action prototypes, where motions more likely to produce an effect are represented more than those that lead to negligible changes. We evaluate our method on a simulated stair-climbing reinforcement learning task, and the preliminary results
    
[^22]: 我们能否通过神经坍塌来理解可塑性？

    Can We Understand Plasticity Through Neural Collapse?

    [https://arxiv.org/abs/2404.02719](https://arxiv.org/abs/2404.02719)

    论文探讨了深度学习中可塑性损失和神经坍塌的关联，并引入了一种正则化方法来缓解神经坍塌，从而减轻了可塑性损失。

    

    这篇论文探讨了深度学习中两个最近确定的现象之间的联系：可塑性损失和神经坍塌。我们分析了它们在不同场景中的相关性，在第一个任务的初始训练阶段揭示了显著的关联。此外，我们引入了一种正则化方法来缓解神经坍塌，证明了在这种特定情况下减轻可塑性损失的有效性。

    arXiv:2404.02719v1 Announce Type: cross  Abstract: This paper explores the connection between two recently identified phenomena in deep learning: plasticity loss and neural collapse. We analyze their correlation in different scenarios, revealing a significant association during the initial training phase on the first task. Additionally, we introduce a regularization approach to mitigate neural collapse, demonstrating its effectiveness in alleviating plasticity loss in this specific setting.
    
[^23]: PromptCodec: 使用基于自适应特征感知的离散表示学习的高保真神经语音编解码器

    PromptCodec: High-Fidelity Neural Speech Codec using Disentangled Representation Learning based Adaptive Feature-aware Prompt Encoders

    [https://arxiv.org/abs/2404.02702](https://arxiv.org/abs/2404.02702)

    本文提出了PromptCodec，一种使用离散表示学习的特征感知提示编码器的高保真神经语音编解码器，通过引入额外特征表示、自适应特征加权融合和效率优化来解决高压缩率下的高保真音频重建问题。

    

    神经语音编解码器近来在生成语音建模领域引起广泛关注，例如语音转换、文本转语音合成等。然而，在高压缩率下确保语音编解码器的高保真音频重建仍然是一个未解决且具有挑战性的问题。本文提出了PromptCodec，一种使用基于离散表示学习的特征感知提示编码器的新型端到端神经语音编解码器模型。通过引入来自提示编码器的额外特征表示，PromptCodec可以分配需要处理的语音信息并增强其能力。此外，引入了一种简单而有效的自适应特征加权融合方法，以整合不同编码器的特征。同时，我们提出了一种基于余弦距离的新颖离散表示学习策略，以优化PromptCodec的编码器以确保其效率，进一步改进。

    arXiv:2404.02702v1 Announce Type: cross  Abstract: Neural speech codec has recently gained widespread attention in generative speech modeling domains, like voice conversion, text-to-speech synthesis, etc. However, ensuring high-fidelity audio reconstruction of speech codecs under high compression rates remains an open and challenging issue. In this paper, we propose PromptCodec, a novel end-to-end neural speech codec model using disentangled representation learning based feature-aware prompt encoders. By incorporating additional feature representations from prompt encoders, PromptCodec can distribute the speech information requiring processing and enhance its capabilities. Moreover, a simple yet effective adaptive feature weighted fusion approach is introduced to integrate features of different encoders. Meanwhile, we propose a novel disentangled representation learning strategy based on cosine distance to optimize PromptCodec's encoders to ensure their efficiency, thereby further impr
    
[^24]: 注意力机制在高斯分布输入下自然稀疏

    Attention is Naturally Sparse with Gaussian Distributed Input

    [https://arxiv.org/abs/2404.02690](https://arxiv.org/abs/2404.02690)

    通过对高斯输入下注意力得分稀疏性进行理论分析，揭示了注意力机制中稀疏性的特征及其对计算效率的影响。

    

    大型语言模型（LLMs）的计算强度是关键瓶颈，主要是由于transformer架构中注意力机制的$O(n^2)$复杂度。稀疏注意力作为一个关键创新应运而生，旨在减少计算负荷同时保持模型性能。本研究对LLMs内的注意力分数稀疏性进行了严格的理论分析，特别是在高斯输入框架下。通过建立一组基础假设并采用一种系统的理论方法，我们揭示了注意力分数稀疏性的内在特征及其对计算效率的影响。我们的主要贡献在于提供了对注意力机制中稀疏性表现形式的详细理论检查，揭示了在计算节约和模型有效性之间潜在权衡的见解。

    arXiv:2404.02690v1 Announce Type: cross  Abstract: The computational intensity of Large Language Models (LLMs) is a critical bottleneck, primarily due to the $O(n^2)$ complexity of the attention mechanism in transformer architectures. Addressing this, sparse attention emerges as a key innovation, aiming to reduce computational load while maintaining model performance. This study presents a rigorous theoretical analysis of the sparsity in attention scores within LLMs, particularly under the framework of Gaussian inputs. By establishing a set of foundational assumptions and employing a methodical theoretical approach, we unravel the intrinsic characteristics of attention score sparsity and its implications on computational efficiency. Our main contribution lies in providing a detailed theoretical examination of how sparsity manifests in attention mechanisms, offering insights into the potential trade-offs between computational savings and model effectiveness. This work not only advances 
    
[^25]: 跨架构迁移学习用于线性成本推断变换器

    Cross-Architecture Transfer Learning for Linear-Cost Inference Transformers

    [https://arxiv.org/abs/2404.02684](https://arxiv.org/abs/2404.02684)

    提出了一种跨架构迁移学习方法，用于在线性成本推断和自注意力变换器之间共享组件的权重，以提高Transformer语言模型的效率。

    

    最近，提出了多种架构来通过改变自注意力模块的设计实现线性成本推断(LCI)以提高Transformer语言模型的效率。在这个领域中，一个值得注意的方法是状态空间机器（SSMs）架构，它在语言建模任务上显示出与自注意力变换器相当的性能。然而，这种架构更改需要从头开始完全预训练权重，这给希望使用新架构的研究人员和从业者带来了巨大成本。受传统线性注意力工作的启发，我们提出了跨架构迁移学习(XATL)，其中LCI和基于自注意力的变换器之间的共享组件的权重，如层规范、MLP、输入/输出

    arXiv:2404.02684v1 Announce Type: cross  Abstract: Recently, multiple architectures has been proposed to improve the efficiency of the Transformer Language Models through changing the design of the self-attention block to have a linear-cost inference (LCI). A notable approach in this realm is the State-Space Machines (SSMs) architecture, which showed on-par performance on language modeling tasks with the self-attention transformers. However, such an architectural change requires a full pretraining of the weights from scratch, which incurs a huge cost to researchers and practitioners who want to use the new architectures. In the more traditional linear attention works, it has been proposed to approximate full attention with linear attention by swap-and-finetune framework. Motivated by this approach, we propose Cross-Architecture Transfer Learning (XATL), in which the weights of the shared components between LCI and self-attention-based transformers, such as layernorms, MLPs, input/outpu
    
[^26]: PejorativITy：消除蔑称词以改善意大利推文中的厌恶检测

    PejorativITy: Disambiguating Pejorative Epithets to Improve Misogyny Detection in Italian Tweets

    [https://arxiv.org/abs/2404.02681](https://arxiv.org/abs/2404.02681)

    通过澄清词语含义来改善厌恶检测，PejorativITy提出了一个新的意大利推文语料库，揭示了将贬损信息注入模型的两种方法均能显著提高分类性能。

    

    厌恶往往通过比喻语言表达。当一些中性词语作为贬损称谓时，可能会呈现负面含义。澄清这类词语的含义可能有助于检测厌恶。为解决这一任务，我们提出了PejorativITy，这是一个新颖的由1,200条意大利推文构成的语料库，用于在单词级别上标注贬损语言，并在句子级别上标注厌恶。我们评估了将澄清词语信息注入针对厌恶检测模型的影响。具体地，我们探讨了两种不同的注入方法：将贬损信息连接在一起和将模棱两可的词语替换为明确的术语。我们的实验结果，无论是在我们的语料库上还是在意大利推文的两个流行基准上，都表明这两种方法均导致更大的分类改善，表明词义消歧是厌恶检测的有前景的初步步骤。

    arXiv:2404.02681v1 Announce Type: cross  Abstract: Misogyny is often expressed through figurative language. Some neutral words can assume a negative connotation when functioning as pejorative epithets. Disambiguating the meaning of such terms might help the detection of misogyny. In order to address such task, we present PejorativITy, a novel corpus of 1,200 manually annotated Italian tweets for pejorative language at the word level and misogyny at the sentence level. We evaluate the impact of injecting information about disambiguated words into a model targeting misogyny detection. In particular, we explore two different approaches for injection: concatenation of pejorative information and substitution of ambiguous words with univocal terms. Our experimental results, both on our corpus and on two popular benchmarks on Italian tweets, show that both approaches lead to a major classification improvement, indicating that word sense disambiguation is a promising preliminary step for misog
    
[^27]: 为前沿人工智能开发负责任地报道

    Responsible Reporting for Frontier AI Development

    [https://arxiv.org/abs/2404.02675](https://arxiv.org/abs/2404.02675)

    通过负责任地向政府、工业界和公民社会的相关方报告安全关键信息，前沿人工智能系统开发组织可以提高风险可见度，帮助开发者做出明智的决策并协助决策者设计更有针对性和健全的监管基础设施。

    

    缓解前沿人工智能系统带来的风险需要获取最新和可靠的关于这些系统的信息。开发和部署前沿系统的组织对这些信息具有重要的获取途径。通过向政府、工业界和公民社会的相关方报告安全关键信息，这些组织可以增进对前沿系统带来的新兴风险的可见度。有了这些信息，开发者可以做出更为明智的风险管理决策，决策者也可以设计更加有针对性和健全的监管基础设施。我们概述了负责任地报道的关键特点并提出了在实践中实施它们的机制。

    arXiv:2404.02675v1 Announce Type: cross  Abstract: Mitigating the risks from frontier AI systems requires up-to-date and reliable information about those systems. Organizations that develop and deploy frontier systems have significant access to such information. By reporting safety-critical information to actors in government, industry, and civil society, these organizations could improve visibility into new and emerging risks posed by frontier systems. Equipped with this information, developers could make better informed decisions on risk management, while policymakers could design more targeted and robust regulatory infrastructure. We outline the key features of responsible reporting and propose mechanisms for implementing them in practice.
    
[^28]: 在大型语言模型知识蒸馏中重新思考Kullback-Leibler散度

    Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models

    [https://arxiv.org/abs/2404.02657](https://arxiv.org/abs/2404.02657)

    本研究重新思考了大型语言模型知识蒸馏中对Kullback-Leibler散度的应用，发现逆Kullback-Leibler和正向Kullback-Leibler散度在优化目标上相似，为此提出了一种自适应Kullback-Leiber散度方法。

    

    Kullback-Leibler散度在知识蒸馏中被广泛应用于压缩大型语言模型。本研究从经验和理论上证明了，在LLMs的知识蒸馏中，与之前断言的逆Kullback-Leibler（RKL）散度寻找模式并因此优于寻找平均值的正向Kullback-Leibler（FKL）散度相反，实际上在知识蒸馏中都没有体现出寻找模式或寻找平均值的特性。相反，发现RKL和FKL具有相同的优化目标，并在足够数量的时代之后都会收敛。然而，由于实际约束，LLMs很少被训练如此多的时代。同时，我们进一步发现，RKL在分布的尾部，而FKL在开始时代侧重于分布的头部。因此，我们提出了一种简单而有效的自适应Kullback-Leiber（AKL）散度方法，该方法自适应地分配权重来组合F

    arXiv:2404.02657v1 Announce Type: cross  Abstract: Kullback-Leiber divergence has been widely used in Knowledge Distillation (KD) to compress Large Language Models (LLMs). Contrary to prior assertions that reverse Kullback-Leibler (RKL) divergence is mode-seeking and thus preferable over the mean-seeking forward Kullback-Leibler (FKL) divergence, this study empirically and theoretically demonstrates that neither mode-seeking nor mean-seeking properties manifest in KD for LLMs. Instead, RKL and FKL are found to share the same optimization objective and both converge after a sufficient number of epochs. However, due to practical constraints, LLMs are seldom trained for such an extensive number of epochs. Meanwhile, we further find that RKL focuses on the tail part of the distributions, while FKL focuses on the head part at the beginning epochs. Consequently, we propose a simple yet effective Adaptive Kullback-Leiber (AKL) divergence method, which adaptively allocates weights to combine F
    
[^29]: 医学影像领域少样本学习中的非负子空间特征表示

    Non-negative Subspace Feature Representation for Few-shot Learning in Medical Imaging

    [https://arxiv.org/abs/2404.02656](https://arxiv.org/abs/2404.02656)

    本文研究了在医学影像领域通过探索低维空间中的不同数据属性表示来实现数据驱动的少样本学习的有效性，引入了不同类型的非负矩阵分解（NMF）来解决医学图像分类中的数据稀缺问题。

    

    与传统的视觉场景识别领域不同，深度神经网络可访问大量数据集，医学图像解释往往受到数据短缺的阻碍。本文通过在低维空间中探索不同数据属性表示，研究了数据驱动的医学影像少样本学习的有效性。我们引入了不同类型的非负矩阵分解（NMF）在少样本学习中，解决了医学图像分类中的数据稀缺问题。通过广泛的实证研究，验证了NMF的有效性，特别是其监督变体（如，有差别性NMF，以及具有稀疏性的监督和约束NMF），并与主成分分析（PCA）进行了比较，即从特征向量中导出的基于协作表示的降维技术。

    arXiv:2404.02656v1 Announce Type: cross  Abstract: Unlike typical visual scene recognition domains, in which massive datasets are accessible to deep neural networks, medical image interpretations are often obstructed by the paucity of data. In this paper, we investigate the effectiveness of data-based few-shot learning in medical imaging by exploring different data attribute representations in a low-dimensional space. We introduce different types of non-negative matrix factorization (NMF) in few-shot learning, addressing the data scarcity issue in medical image classification. Extensive empirical studies are conducted in terms of validating the effectiveness of NMF, especially its supervised variants (e.g., discriminative NMF, and supervised and constrained NMF with sparseness), and the comparison with principal component analysis (PCA), i.e., the collaborative representation-based dimensionality reduction technique derived from eigenvectors. With 14 different datasets covering 11 dist
    
[^30]: 针对大型语言模型中未预料到的偏见的检测

    Towards detecting unanticipated bias in Large Language Models

    [https://arxiv.org/abs/2404.02650](https://arxiv.org/abs/2404.02650)

    本论文探索了在大型语言模型中检测未预料到的偏见的新途径，着重于不确定性量化和可解释人工智能方法。

    

    在过去一年中，像ChatGPT这样的大型语言模型（LLMs）已经被广泛使用，并展现出与以前的机器学习系统类似的公平性问题。当前研究主要集中于分析和量化这些训练数据中的偏见及其对这些模型决策的影响，同时制定减轻策略。这项研究主要针对与性别、种族、族裔和语言相关的众所周知的偏见。然而，很明显，LLMs也受到其他不太明显的内隐偏见的影响。这些模型的复杂性和通常的不透明性使得检测这些偏见具有挑战性，但由于它们在各种应用中潜在的负面影响，这是至关重要的。在本文中，我们探讨了在LLMs中检测这些未预料到的偏见的新途径，具体关注不确定性量化和可解释人工智能方法。这些方法旨在评估确定性

    arXiv:2404.02650v1 Announce Type: cross  Abstract: Over the last year, Large Language Models (LLMs) like ChatGPT have become widely available and have exhibited fairness issues similar to those in previous machine learning systems. Current research is primarily focused on analyzing and quantifying these biases in training data and their impact on the decisions of these models, alongside developing mitigation strategies. This research largely targets well-known biases related to gender, race, ethnicity, and language. However, it is clear that LLMs are also affected by other, less obvious implicit biases. The complex and often opaque nature of these models makes detecting such biases challenging, yet this is crucial due to their potential negative impact in various applications. In this paper, we explore new avenues for detecting these unanticipated biases in LLMs, focusing specifically on Uncertainty Quantification and Explainable AI methods. These approaches aim to assess the certainty
    
[^31]: 一种用于无线通信系统信号检测的通用深度神经网络

    A Universal Deep Neural Network for Signal Detection in Wireless Communication Systems

    [https://arxiv.org/abs/2404.02648](https://arxiv.org/abs/2404.02648)

    提出了一种无需重新训练模型即可在各种无线环境中实现高性能检测的通用深度神经网络。

    

    深度学习（DL）近来作为无线通信中信道估计和信号检测的一种有前途的方法不断涌现。现有研究主要关注分析来自单一信道分布（如加性白噪声信道和瑞利信道）生成的信道脉冲响应。在实践中，为了应对无线信道动态性，DL方法必须在新收集的数据上重新训练，这昂贵、低效且不切实际。为解决这一挑战，本文提出了一种新颖的通用深度神经网络（Uni-DNN），可以在各种无线环境中实现高性能检测，无需重新训练模型。具体而言，我们提出的Uni-DNN模型包括无线信道分类器和信号检测器，分别使用DNN构建。

    arXiv:2404.02648v1 Announce Type: cross  Abstract: Recently, deep learning (DL) has been emerging as a promising approach for channel estimation and signal detection in wireless communications. The majority of the existing studies investigating the use of DL techniques in this domain focus on analysing channel impulse responses that are generated from only one channel distribution such as additive white Gaussian channel noise and Rayleigh channels. In practice, to cope with the dynamic nature of the wireless channel, DL methods must be re-trained on newly non-aged collected data which is costly, inefficient, and impractical. To tackle this challenge, this paper proposes a novel universal deep neural network (Uni-DNN) that can achieve high detection performance in various wireless environments without retraining the model. In particular, our proposed Uni-DNN model consists of a wireless channel classifier and a signal detector which are constructed by using DNNs. The wireless channel cl
    
[^32]: 词汇攻击以劫持大型语言模型应用

    Vocabulary Attack to Hijack Large Language Model Applications

    [https://arxiv.org/abs/2404.02637](https://arxiv.org/abs/2404.02637)

    通过插入来源模型词汇的方式，成功实施了对两个热门开源大型语言模型的目标劫持，创造出难以检测的不引人注目指令。

    

    大型语言模型（LLMs）的快速发展推动了越来越多的应用程序。随着用户数量的增加，我们也看到越来越多的攻击者试图智胜这些系统。他们希望模型透露机密信息、特定错误信息或冒犯行为。为此，他们通过插入分隔符或系统性地改写指令，直到达到目标。我们的方法与众不同。它插入来自模型词汇的词汇。我们使用优化过程和来自另一个LLM（攻击者LLM）的嵌入来找到这些词汇。我们通过劫持两个热门开源LLM（分别来自Llama2和Flan-T5系列）证明了我们的方法。我们得出了两个主要发现。首先，我们的方法生成不引人注目的指令，因此很难检测。对于许多攻击案例，我们发现即使一个

    arXiv:2404.02637v1 Announce Type: cross  Abstract: The fast advancements in Large Language Models (LLMs) are driving an increasing number of applications. Together with the growing number of users, we also see an increasing number of attackers who try to outsmart these systems. They want the model to reveal confidential information, specific false information, or offensive behavior. To this end, they manipulate their instructions for the LLM by inserting separators or rephrasing them systematically until they reach their goal. Our approach is different. It inserts words from the model vocabulary. We find these words using an optimization procedure and embeddings from another LLM (attacker LLM). We prove our approach by goal hijacking two popular open-source LLMs from the Llama2 and the Flan-T5 families, respectively. We present two main findings. First, our approach creates inconspicuous instructions and therefore it is hard to detect. For many attack cases, we find that even a single 
    
[^33]: 用于基于解释的自然语言推理的可微分整数线性规划求解器

    A Differentiable Integer Linear Programming Solver for Explanation-Based Natural Language Inference

    [https://arxiv.org/abs/2404.02625](https://arxiv.org/abs/2404.02625)

    Diff-Comb Explainer是一种基于可微黑盒组合求解器的神经符号架构，不需要对语义约束进行连续放松，相比传统解决方案表现更出色。

    

    Integer Linear Programming（ILP）被提出作为对自然语言推理（NLI）进行精确结构和语义约束编码的正式形式。然而，传统的ILP框架是不可微分的，这给基于深度学习的连续语言表示的整合带来了关键挑战。本文介绍了一种新方法，名为Diff-Comb Explainer，这是一种基于可微黑盒组合求解器（DBCS）的解释型NLI的神经符号架构。与现有的神经符号求解器不同，Diff-Comb Explainer不需要对语义约束进行连续放松，从而能够直接、更精确和高效地将神经表示融入到ILP公式中。我们的实验表明，与传统ILP求解器、神经符号黑盒求解器和Trans相比，Diff-Comb Explainer实现了更优越的性能。

    arXiv:2404.02625v1 Announce Type: cross  Abstract: Integer Linear Programming (ILP) has been proposed as a formalism for encoding precise structural and semantic constraints for Natural Language Inference (NLI). However, traditional ILP frameworks are non-differentiable, posing critical challenges for the integration of continuous language representations based on deep learning. In this paper, we introduce a novel approach, named Diff-Comb Explainer, a neuro-symbolic architecture for explanation-based NLI based on Differentiable BlackBox Combinatorial Solvers (DBCS). Differently from existing neuro-symbolic solvers, Diff-Comb Explainer does not necessitate a continuous relaxation of the semantic constraints, enabling a direct, more precise, and efficient incorporation of neural representations into the ILP formulation. Our experiments demonstrate that Diff-Comb Explainer achieves superior performance when compared to conventional ILP solvers, neuro-symbolic black-box solvers, and Trans
    
[^34]: Diffexplainer：基于扩散模型的跨模态全局解释研究

    Diffexplainer: Towards Cross-modal Global Explanations with Diffusion Models

    [https://arxiv.org/abs/2404.02618](https://arxiv.org/abs/2404.02618)

    Diffexplainer提出了一种新颖框架，利用语言-视觉模型实现多模态全局可解释性，并通过优化的文本提示条件化的扩散模型，合成图像来解释分类器的决策，同时提供一个对决策解释的视觉工具，并能自动识别偏见和虚假特征。

    

    我们提出了DiffExplainer，这是一个新颖的框架，利用语言-视觉模型实现多模态全局可解释性。DiffExplainer利用经过优化的文本提示条件化的扩散模型，合成最大化分类器输出和隐藏特征的图像，从而提供一个解释决策的可视化工具。此外，对生成的视觉描述的分析允许自动识别偏见和虚假特征，而不像传统方法那样常常依赖于手动干预。语言-视觉模型的跨模态可迁移性还使得可以通过文本以更具人类可解释性的方式描述决策。我们进行了综合实验，包括广泛的用户研究，展示了DiffExplainer在生成解释模型决策的高质量图像方面的有效性，超过了现有的激活最大化方法。

    arXiv:2404.02618v1 Announce Type: cross  Abstract: We present DiffExplainer, a novel framework that, leveraging language-vision models, enables multimodal global explainability. DiffExplainer employs diffusion models conditioned on optimized text prompts, synthesizing images that maximize class outputs and hidden features of a classifier, thus providing a visual tool for explaining decisions. Moreover, the analysis of generated visual descriptions allows for automatic identification of biases and spurious features, as opposed to traditional methods that often rely on manual intervention. The cross-modal transferability of language-vision models also enables the possibility to describe decisions in a more human-interpretable way, i.e., through text. We conduct comprehensive experiments, which include an extensive user study, demonstrating the effectiveness of DiffExplainer on 1) the generation of high-quality images explaining model decisions, surpassing existing activation maximization
    
[^35]: SHIELD: 一种用于可解释人工智能的正则化技术

    SHIELD: A regularization technique for eXplainable Artificial Intelligence

    [https://arxiv.org/abs/2404.02611](https://arxiv.org/abs/2404.02611)

    SHIELD引入了一种正则化技术，通过隐藏部分输入数据并评估预测结果的差异，从而改善了可解释人工智能模型的质量。

    

    随着人工智能系统在各个领域变得不可或缺，对可解释性的需求与日俱增。尽管科学界的努力主要集中在为模型获取更好的解释上，但重要的是不要忽视这个解释过程对改善训练的潜力。虽然现有的努力主要集中在为黑盒模型生成和评估解释上，但直接通过这些评估来增强模型仍存在关键差距。本文介绍了SHIELD（选择性隐藏输入评估学习动态），这是一种适用于可解释人工智能的正则化技术，旨在通过隐藏部分输入数据并评估预测结果的差异来改善模型质量。与传统方法相比，SHIELD正则化无缝集成到目标函数中，提高了模型的可解释性同时也改善了性能

    arXiv:2404.02611v1 Announce Type: new  Abstract: As Artificial Intelligence systems become integral across domains, the demand for explainability grows. While the effort by the scientific community is focused on obtaining a better explanation for the model, it is important not to ignore the potential of this explanation process to improve training as well. While existing efforts primarily focus on generating and evaluating explanations for black-box models, there remains a critical gap in directly enhancing models through these evaluations. This paper introduces SHIELD (Selective Hidden Input Evaluation for Learning Dynamics), a regularization technique for explainable artificial intelligence designed to improve model quality by concealing portions of input data and assessing the resulting discrepancy in predictions. In contrast to conventional approaches, SHIELD regularization seamlessly integrates into the objective function, enhancing model explainability while also improving perfor
    
[^36]: Affective-NLI: 朝着准确且可解释的对话中人格识别方向

    Affective-NLI: Towards Accurate and Interpretable Personality Recognition in Conversation

    [https://arxiv.org/abs/2404.02589](https://arxiv.org/abs/2404.02589)

    提出了Affective-NLI用于准确且可解释的对话中人格识别，以利用对话内容中的情感因素进行准确的人格识别

    

    对话中的人格识别（PRC）旨在通过文本对话内容识别说话者的人格特征。这对于在人机交互（HCI）的各种应用中提供个性化服务至关重要，包括基于AI的心理治疗和为老年人提供伴侣机器人。最近的研究分析对话内容进行人格分类，但忽略了影响其性能的两个主要问题。首先，对话中包含的关键隐含因素（如反映说话者人格的情绪）被忽略。其次，仅关注输入对话内容忽略了对个性本身语义理解，降低了结果的解释性。在本文中，我们提出了用于准确且可解释的PRC的情感自然语言推理（Affective-NLI）。

    arXiv:2404.02589v1 Announce Type: cross  Abstract: Personality Recognition in Conversation (PRC) aims to identify the personality traits of speakers through textual dialogue content. It is essential for providing personalized services in various applications of Human-Computer Interaction (HCI), such as AI-based mental therapy and companion robots for the elderly. Most recent studies analyze the dialog content for personality classification yet overlook two major concerns that hinder their performance. First, crucial implicit factors contained in conversation, such as emotions that reflect the speakers' personalities are ignored. Second, only focusing on the input dialog content disregards the semantic understanding of personality itself, which reduces the interpretability of the results. In this paper, we propose Affective Natural Language Inference (Affective-NLI) for accurate and interpretable PRC. To utilize affectivity within dialog content for accurate personality recognition, we 
    
[^37]: 训练扩展查询的排序器的出乎意料的有效性

    The Surprising Effectiveness of Rankers Trained on Expanded Queries

    [https://arxiv.org/abs/2404.02587](https://arxiv.org/abs/2404.02587)

    通过训练数据集中的扩展和困难查询，本研究提出了一种方法来提高困难查询的排序性能，而不降低其他查询的性能。

    

    文本排序系统中一个重要问题是处理查询分布尾部的困难查询。这种困难可能源于存在不常见、未明确或不完整的查询。在这项工作中，我们通过使用相关文档对训练查询进行了基于LLM的查询扩展来提高困难查询的排序性能，而不损害其他查询的性能。首先，我们基于LLM进行查询丰富化，使用相关文档进行训练。接下来，专门的排序器仅在丰富的困难查询上进行微调，而不是在原始查询上进行微调。我们将来自专门排序器和基本排序器的相关性得分以及为每个查询估计的查询性能得分进行组合。我们的方法不同于通常对所有查询使用单个排序器的现有方法，这些方法对易查询有偏见，易查询构成查询分布的大多数。

    arXiv:2404.02587v1 Announce Type: cross  Abstract: An important problem in text-ranking systems is handling the hard queries that form the tail end of the query distribution. The difficulty may arise due to the presence of uncommon, underspecified, or incomplete queries. In this work, we improve the ranking performance of hard or difficult queries without compromising the performance of other queries. Firstly, we do LLM based query enrichment for training queries using relevant documents. Next, a specialized ranker is fine-tuned only on the enriched hard queries instead of the original queries. We combine the relevance scores from the specialized ranker and the base ranker, along with a query performance score estimated for each query. Our approach departs from existing methods that usually employ a single ranker for all queries, which is biased towards easy queries, which form the majority of the query distribution. In our extensive experiments on the DL-Hard dataset, we find that a p
    
[^38]: 农业精准种植中的高效主动学习：作物-杂草语义分割案例研究

    Active learning for efficient annotation in precision agriculture: a use-case on crop-weed semantic segmentation

    [https://arxiv.org/abs/2404.02580](https://arxiv.org/abs/2404.02580)

    主动学习在农业领域的语义分割中进行了比较研究，探讨了三种基于主动学习的获取函数（BALD、PowerBALD和随机选择）的性能。

    

    优化深度学习模型需要大量注释图像，这个过程既耗时又昂贵。特别是对于每个像素都必须进行注释的语义分割模型。缓解注释工作量的一个潜在策略是主动学习。主动学习有助于从大量未标记的图像中识别和选择最具信息量的图像。基本假设是，这些选定的图像可以比随机选择更快地改善模型性能，从而减少注释工作。虽然主动学习在Cityscapes等基准数据集上已经展示了有希望的结果，但在农业领域的表现仍未得到充分探索。本研究通过对三种基于主动学习的采集函数进行比较研究来填补这一研究空白：基于不一致的贝叶斯主动学习（BALD）、基于随机的BALD (PowerBALD) 和随机选择。

    arXiv:2404.02580v1 Announce Type: cross  Abstract: Optimizing deep learning models requires large amounts of annotated images, a process that is both time-intensive and costly. Especially for semantic segmentation models in which every pixel must be annotated. A potential strategy to mitigate annotation effort is active learning. Active learning facilitates the identification and selection of the most informative images from a large unlabelled pool. The underlying premise is that these selected images can improve the model's performance faster than random selection to reduce annotation effort. While active learning has demonstrated promising results on benchmark datasets like Cityscapes, its performance in the agricultural domain remains largely unexplored. This study addresses this research gap by conducting a comparative study of three active learning-based acquisition functions: Bayesian Active Learning by Disagreement (BALD), stochastic-based BALD (PowerBALD), and Random. The acqui
    
[^39]: 学习执行任务的替代方式

    Learning Alternative Ways of Performing a Task

    [https://arxiv.org/abs/2404.02579](https://arxiv.org/abs/2404.02579)

    提出了一种用于学习多个模型的新归纳方法，每个模型代表一种替代策略

    

    学习执行任务的一种常见方式是观察专家如何执行。然而，众所周知，对于大多数任务，执行它们的方式并不是唯一的。特别是对于更加复杂的任务，因为专家的技能或知识可能会影响她解决问题的方式。此外，从专家那里学习也存在一些问题，比如训练示例集通常来自几位专家（因为专家通常是有限且昂贵的资源），而且所有示例都是正面示例（即代表任务成功执行的示例）。传统的机器学习技术在这种情况下并不适用，因为它们需要大量的训练数据。基于以活动序列形式呈现的任务极少次执行，我们引入了一种新的归纳方法，用于学习多个模型，每个模型代表一种替代策略。

    arXiv:2404.02579v1 Announce Type: new  Abstract: A common way of learning to perform a task is to observe how it is carried out by experts. However, it is well known that for most tasks there is no unique way to perform them. This is especially noticeable the more complex the task is because factors such as the skill or the know-how of the expert may well affect the way she solves the task. In addition, learning from experts also suffers of having a small set of training examples generally coming from several experts (since experts are usually a limited and expensive resource), being all of them positive examples (i.e. examples that represent successful executions of the task). Traditional machine learning techniques are not useful in such scenarios, as they require extensive training data. Starting from very few executions of the task presented as activity sequences, we introduce a novel inductive approach for learning multiple models, with each one representing an alternative strateg
    
[^40]: SliceIt! -- 一个用于学习机器人食物切割的双重模拟器框架

    SliceIt! -- A Dual Simulator Framework for Learning Robot Food Slicing

    [https://arxiv.org/abs/2404.02569](https://arxiv.org/abs/2404.02569)

    提出了一个用于在模拟环境中安全高效地学习机器人食物切割任务的Dual Simulator框架。

    

    厨房机器人可以通过减轻日常烦琐任务的负担，提高家庭体验。然而，在处理危险工具（如厨房刀具）时，这些机器人必须在共享人类环境中灵巧且安全地执行任务。本研究旨在使机器人能够自主且安全地学习食物切割任务。具体来说，我们的目标是通过适应性控制，使用协作机器人或工业机器人手臂执行食物切割任务，以适应不同材料属性。我们的方法包括使用强化学习（RL）训练机器人以合规方式操作刀具，减少食物和切菜板施加的接触力。然而，在现实世界中训练机器人可能效率低下、危险，并导致大量食物浪费。因此，我们提出了SliceIt!，这是一个用于在模拟环境中安全高效地学习机器人食物切割任务的框架。

    arXiv:2404.02569v1 Announce Type: cross  Abstract: Cooking robots can enhance the home experience by reducing the burden of daily chores. However, these robots must perform their tasks dexterously and safely in shared human environments, especially when handling dangerous tools such as kitchen knives. This study focuses on enabling a robot to autonomously and safely learn food-cutting tasks. More specifically, our goal is to enable a collaborative robot or industrial robot arm to perform food-slicing tasks by adapting to varying material properties using compliance control. Our approach involves using Reinforcement Learning (RL) to train a robot to compliantly manipulate a knife, by reducing the contact forces exerted by the food items and by the cutting board. However, training the robot in the real world can be inefficient, and dangerous, and result in a lot of food waste. Therefore, we proposed SliceIt!, a framework for safely and efficiently learning robot food-slicing tasks in sim
    
[^41]: 太阳合成成像：在SDO/AIA数据上引入去噪扩散概率模型

    Solar synthetic imaging: Introducing denoising diffusion probabilistic models on SDO/AIA data

    [https://arxiv.org/abs/2404.02552](https://arxiv.org/abs/2404.02552)

    使用去噪扩散概率模型（DDPM）在SDO/AIA数据上创建合成太阳图像，以解决太阳活动预测中的数据稀缺挑战。

    

    鉴于显著太阳耀斑的罕见性相对于较小的耀斑，训练有效的太阳活动预测机器学习模型具有挑战性，因为数据不足。本研究提出使用生成式深度学习模型，特别是去噪扩散概率模型（DDPM），以创建太阳现象的合成图像，包括不同强度的耀斑。通过利用SDO航天器上AIA仪器的数据集，集中在捕捉各种太阳活动的171 Å频段，并根据耀斑强度使用GOES X射线测量对图像进行分类，我们旨在解决数据稀缺问题。使用聚类指标、Frechet Inception Distance（FID）和F1-score评估DDPM的性能，展示了生成逼真太阳图像的有希望结果。我们进行两个实验：一个用于训练监督分类器进行事件识别，另一个用于基本

    arXiv:2404.02552v1 Announce Type: cross  Abstract: Given the rarity of significant solar flares compared to smaller ones, training effective machine learning models for solar activity forecasting is challenging due to insufficient data. This study proposes using generative deep learning models, specifically a Denoising Diffusion Probabilistic Model (DDPM), to create synthetic images of solar phenomena, including flares of varying intensities. By employing a dataset from the AIA instrument aboard the SDO spacecraft, focusing on the 171 {\AA} band that captures various solar activities, and classifying images with GOES X-ray measurements based on flare intensity, we aim to address the data scarcity issue. The DDPM's performance is evaluated using cluster metrics, Frechet Inception Distance (FID), and F1-score, showcasing promising results in generating realistic solar imagery. We conduct two experiments: one to train a supervised classifier for event identification and another for basic 
    
[^42]: 软件工程教育中的AI辅导

    AI-Tutoring in Software Engineering Education

    [https://arxiv.org/abs/2404.02548](https://arxiv.org/abs/2404.02548)

    本研究通过将GPT-3.5-Turbo模型作为AI辅导员集成到APAS Artemis中，探讨了软件工程教育中学生与AI辅导员的互动模式，发现了不同用户类型，并强调了及时反馈和可扩展性等优势。

    

    随着人工智能在各个领域的快速发展，教育行业正面临变革。AI驱动工具在增强学习体验方面的潜力是巨大的，特别是在编程领域。然而，LLMs在自动化编程评估系统(APASs)中作为AI辅导员的科学评估仍未得到充分探讨。因此，有必要了解学生如何与这些AI辅导员互动，并分析他们的体验。在本文中，我们通过将GPT-3.5-Turbo模型作为AI辅导员集成到APAS Artemis中进行了探索性案例研究。通过结合实证数据收集和探索性调查，我们确定了基于他们与AI辅导员互动模式的不同用户类型。此外，研究结果强调了诸如及时反馈和可扩展性等优势。然而，挑战如通用领域回复等也同样值得关注。

    arXiv:2404.02548v1 Announce Type: cross  Abstract: With the rapid advancement of artificial intelligence (AI) in various domains, the education sector is set for transformation. The potential of AI-driven tools in enhancing the learning experience, especially in programming, is immense. However, the scientific evaluation of Large Language Models (LLMs) used in Automated Programming Assessment Systems (APASs) as an AI-Tutor remains largely unexplored. Therefore, there is a need to understand how students interact with such AI-Tutors and to analyze their experiences. In this paper, we conducted an exploratory case study by integrating the GPT-3.5-Turbo model as an AI-Tutor within the APAS Artemis. Through a combination of empirical data collection and an exploratory survey, we identified different user types based on their interaction patterns with the AI-Tutor. Additionally, the findings highlight advantages, such as timely feedback and scalability. However, challenges like generic resp
    
[^43]: 离线强化学习的格点映射伪计数约束

    Grid-Mapping Pseudo-Count Constraint for Offline Reinforcement Learning

    [https://arxiv.org/abs/2404.02545](https://arxiv.org/abs/2404.02545)

    提出了一种用于连续领域的新的计数方法，称为格点映射伪计数方法（GPC），以适应离线环境中的强化学习问题，并在惩罚Q值的同时减少计算成本。

    

    离线强化学习是从静态数据集中学习而不与环境进行交互的方法，这确保了安全性并因此具有良好的应用前景。然而，直接应用朴素的强化学习方法通常在离线环境中失败，因为由于超出分布（OOD）行为引起的函数逼近误差。为了解决这个问题，现有算法主要惩罚OOD行为的Q值，其约束的质量也很重要。不精确的约束可能导致次优解，而精确的约束则需要显著的计算成本。在本文中，我们提出了一种新颖的连续领域计数方法，称为格点映射伪计数方法（GPC），以适当地惩罚Q值并减少计算成本。所提出的方法将状态和动作空间映射到离散空间，并通过伪计数约束它们的Q值。这是一个理论性

    arXiv:2404.02545v1 Announce Type: cross  Abstract: Offline reinforcement learning learns from a static dataset without interacting with the environment, which ensures security and thus owns a good prospect of application. However, directly applying naive reinforcement learning methods usually fails in an offline environment due to function approximation errors caused by out-of-distribution(OOD) actions. To solve this problem, existing algorithms mainly penalize the Q-value of OOD actions, the quality of whose constraints also matter. Imprecise constraints may lead to suboptimal solutions, while precise constraints require significant computational costs. In this paper, we propose a novel count-based method for continuous domains, called Grid-Mapping Pseudo-Count method(GPC), to penalize the Q-value appropriately and reduce the computational cost. The proposed method maps the state and action space to discrete space and constrains their Q-values through the pseudo-count. It is theoretic
    
[^44]: 无偏向学习排序遇到现实：百度大规模搜索数据集的经验教训

    Unbiased Learning to Rank Meets Reality: Lessons from Baidu's Large-Scale Search Dataset

    [https://arxiv.org/abs/2404.02543](https://arxiv.org/abs/2404.02543)

    本研究从百度搜索引擎发布的大规模搜索数据集出发，探讨了无偏向学习排序技术在实际搜索引擎中的表现，发现与排名损失和查询-文档特征选择相比，ULTR技术并未带来明显的性能改进。

    

    无偏向学习排序（ULTR）是一个用于学习用户点击数据的成熟框架，而这些数据往往受收集数据的排名者的偏见影响。虽然在理论上得到证明并在模拟中进行了广泛测试，但ULTR技术缺乏经验验证，尤其是在现代搜索引擎中。百度搜索引擎发布的WSDM Cup 2023数据集为评估主要ULTR技术在真实世界中的表现提供了难得的机会。尽管在WSDM Cup 2023期间有多次提交，以及随后的NTCIR ULTRE-2任务，但目前还不清楚观察到的改进是否源自应用ULTR或其他学习技术。我们重新审视并扩展了现有实验。我们发现，无偏向学习排序技术并不能明显提升性能，尤其是与排名损失和查询-文档特征选择带来的明显差异相比。

    arXiv:2404.02543v1 Announce Type: cross  Abstract: Unbiased learning-to-rank (ULTR) is a well-established framework for learning from user clicks, which are often biased by the ranker collecting the data. While theoretically justified and extensively tested in simulation, ULTR techniques lack empirical validation, especially on modern search engines. The dataset released for the WSDM Cup 2023, collected from Baidu's search engine, offers a rare opportunity to assess the real-world performance of prominent ULTR techniques. Despite multiple submissions during the WSDM Cup 2023 and the subsequent NTCIR ULTRE-2 task, it remains unclear whether the observed improvements stem from applying ULTR or other learning techniques. We revisit and extend the available experiments. We find that unbiased learning-to-rank techniques do not bring clear performance improvements, especially compared to the stark differences brought by the choice of ranking loss and query-document features. Our experiments 
    
[^45]: ANGOFA：利用OFA嵌入初始化和合成数据的安哥拉语言模型

    ANGOFA: Leveraging OFA Embedding Initialization and Synthetic Data for Angolan Language Model

    [https://arxiv.org/abs/2404.02534](https://arxiv.org/abs/2404.02534)

    本文介绍了四个专门针对安哥拉语言进行微调的PLM，并使用多语言自适应微调（MAFT）方法，通过采用知情嵌入初始化和合成数据，提高了MAFT模型在下游任务中的性能，将基线提高了12.3个百分点，超越了SOTA AfroXLMR-base和OFA。

    

    近年来，预训练语言模型（PLMs）的发展势头迅猛，展示了它们超越语言障碍、促进跨多种语言的知识转移的能力。然而，这一进展主要忽视了极低资源语言的包含，导致多语言景观中出现明显的空白。本文通过引入四个定制的PLM，专门为安哥拉语言进行微调，采用多语言自适应微调（MAFT）方法，以填补这一空白。我们调查了信息嵌入初始化和合成数据在增强MAFT模型在下游任务中性能方面的作用。我们将基线提高了12.3个百分点，超过了通过MAFT开发的SOTA AfroXLMR-base和有效嵌入初始化OFA分别提高了3.8个百分点。

    arXiv:2404.02534v1 Announce Type: cross  Abstract: In recent years, the development of pre-trained language models (PLMs) has gained momentum, showcasing their capacity to transcend linguistic barriers and facilitate knowledge transfer across diverse languages. However, this progress has predominantly bypassed the inclusion of very-low resource languages, creating a notable void in the multilingual landscape. This paper addresses this gap by introducing four tailored PLMs specifically finetuned for Angolan languages, employing a Multilingual Adaptive Fine-tuning (MAFT) approach. In this paper, we survey the role of informed embedding initialization and synthetic data in enhancing the performance of MAFT models in downstream tasks. We improve baseline over SOTA AfroXLMR-base (developed through MAFT) and OFA (an effective embedding initialization) by 12.3 and 3.8 points respectively.
    
[^46]: 学会伪装：通过多智能体攻击者-伪装者博弈避免LLM的拒绝响应

    Learn to Disguise: Avoid Refusal Responses in LLM's Defense via a Multi-agent Attacker-Disguiser Game

    [https://arxiv.org/abs/2404.02532](https://arxiv.org/abs/2404.02532)

    通过多智能体攻击者-伪装者博弈方法，实现一种弱防御机制，使大型模型能够安全地回复攻击者并隐藏防御意图

    

    随着大型模型在自然语言处理任务上表现出的增强性能，大型模型可能引发潜在的道德和伦理问题。存在一些恶意攻击者，他们通过诸如提示工程等技术诱使大型模型越狱，并生成包含非法、侵犯隐私信息的信息。因此，大型模型采用安全对齐等技术抵御恶意攻击者的攻击。然而，大型模型通过拒绝回复的强防御机制容易被攻击者识别，并用于加强攻击者的能力。在本文中，我们提出了一种多智能体攻击者-伪装者博弈方法，实现一种弱防御机制，使大型模型能够安全地回复攻击者并隐藏防御意图。首先，我们构建一个多智能体框架来模拟攻击和防御情景，扮演不同的角色，负责攻击、伪装

    arXiv:2404.02532v1 Announce Type: new  Abstract: With the enhanced performance of large models on natural language processing tasks, potential moral and ethical issues of large models arise. There exist malicious attackers who induce large models to jailbreak and generate information containing illegal, privacy-invasive information through techniques such as prompt engineering. As a result, large models counter malicious attackers' attacks using techniques such as safety alignment. However, the strong defense mechanism of the large model through rejection replies is easily identified by attackers and used to strengthen attackers' capabilities. In this paper, we propose a multi-agent attacker-disguiser game approach to achieve a weak defense mechanism that allows the large model to both safely reply to the attacker and hide the defense intent. First, we construct a multi-agent framework to simulate attack and defense scenarios, playing different roles to be responsible for attack, disgu
    
[^47]: 严重控制的文本到图像生成模型偏见操纵

    Severity Controlled Text-to-Image Generative Model Bias Manipulation

    [https://arxiv.org/abs/2404.02530](https://arxiv.org/abs/2404.02530)

    本文揭示了文本到图像生成模型对偏见操纵的敏感性，并提出了一种通过定量控制模型偏见来操纵输出严重性的技术，从而实现精确提示工程生成新颖图像的方法。

    

    文本到图像（T2I）生成模型正在广泛流行，尤其是在公共领域。然而，它们固有的偏见和潜在的恶意操纵还未被充分探讨。本文揭示了T2I模型对此类操纵的易感性，并首次提出了通过针对嵌入式语言模型动态且高效地利用模型偏见的新可能性。通过利用向量代数的数学基础，我们的技术实现了对模型偏见通过严重性的输出操纵的可扩展和方便控制。作为副产品，该控制还允许一种精确的提示工程，以生成通常不太可能通过常规文本提示生成的图像。我们还展示了我们的操纵技术在平衡生成类别频率方面的建设应用 - 如在模型去偏。我们的技术不需要训练，并且也以后门的形式构建。

    arXiv:2404.02530v1 Announce Type: cross  Abstract: Text-to-image (T2I) generative models are gaining wide popularity, especially in public domains. However, their intrinsic bias and potential malicious manipulations remain under-explored. Charting the susceptibility of T2I models to such manipulation, we first expose the new possibility of a dynamic and computationally efficient exploitation of model bias by targeting the embedded language models. By leveraging mathematical foundations of vector algebra, our technique enables a scalable and convenient control over the severity of output manipulation through model bias. As a by-product, this control also allows a form of precise prompt engineering to generate images which are generally implausible with regular text prompts. We also demonstrate a constructive application of our manipulation for balancing the frequency of generated classes - as in model debiasing. Our technique does not require training and is also framed as a backdoor at
    
[^48]: 从主体视角学习基于文本驱动的可操作性

    Text-driven Affordance Learning from Egocentric Vision

    [https://arxiv.org/abs/2404.02523](https://arxiv.org/abs/2404.02523)

    该论文提出了一种通过文本指导从主体视角学习可操作性的方法，涵盖手-物体和工具-物体交互，旨在学习接触点和操作轨迹。

    

    视觉可操作性学习是机器人理解如何与物体交互的关键组成部分。我们的方法的关键思想是利用文本指导，针对各种物体的各种可操作性。该方法涵盖手-物体和工具-物体交互。我们引入了文本驱动的可操作性学习，旨在从主体视角根据文本指导学习接触点和操作轨迹。在我们的任务中，接触点被表示为热图，操作轨迹被表示为包含各种操作的线性和旋转运动的坐标序列。然而，当我们为这个任务收集数据时，这些多样化交互的手动注释是昂贵的。因此，我们提出了一个伪数据集

    arXiv:2404.02523v1 Announce Type: cross  Abstract: Visual affordance learning is a key component for robots to understand how to interact with objects. Conventional approaches in this field rely on pre-defined objects and actions, falling short of capturing diverse interactions in realworld scenarios. The key idea of our approach is employing textual instruction, targeting various affordances for a wide range of objects. This approach covers both hand-object and tool-object interactions. We introduce text-driven affordance learning, aiming to learn contact points and manipulation trajectories from an egocentric view following textual instruction. In our task, contact points are represented as heatmaps, and the manipulation trajectory as sequences of coordinates that incorporate both linear and rotational movements for various manipulations. However, when we gather data for this task, manual annotations of these diverse interactions are costly. To this end, we propose a pseudo dataset c
    
[^49]: 利用在线校准运动模型的紧耦合LiDAR-IMU-轮里程计算法用于滑移转向机器人

    Tightly-Coupled LiDAR-IMU-Wheel Odometry with Online Calibration of a Kinematic Model for Skid-Steering Robots

    [https://arxiv.org/abs/2404.02515](https://arxiv.org/abs/2404.02515)

    提出了一种紧耦合LiDAR-IMU-轮里程计算法，使用在线校准解决滑移转向机器人在挑战性环境中的点云退化问题。

    

    隧道和长廊是移动机器人具有挑战性的环境，因为在这些环境中LiDAR点云会退化。为了解决点云退化问题，本研究提出了一种用于滑移转向机器人的紧耦合LiDAR-IMU-轮里程计算法，同时还使用在线校准方法。我们提出了一个完整的线性轮子里程计因子，不仅作为运动约束，还可以执行滑移转向机器人运动模型的在线校准。尽管运动模型动态变化（例如由于胎压引起的轮胎半径变化）和地形条件变化，我们的方法能够通过在线校准来解决模型误差。此外，我们的方法能够在退化环境下（如长直廊）通过校准而实现准确定位，同时LiDAR-IMU融合运作良好。此外，我们还估计了轮子里程计的不确定性（即协方差矩阵）。

    arXiv:2404.02515v1 Announce Type: cross  Abstract: Tunnels and long corridors are challenging environments for mobile robots because a LiDAR point cloud should degenerate in these environments. To tackle point cloud degeneration, this study presents a tightly-coupled LiDAR-IMU-wheel odometry algorithm with an online calibration for skid-steering robots. We propose a full linear wheel odometry factor, which not only serves as a motion constraint but also performs the online calibration of kinematic models for skid-steering robots. Despite the dynamically changing kinematic model (e.g., wheel radii changes caused by tire pressures) and terrain conditions, our method can address the model error via online calibration. Moreover, our method enables an accurate localization in cases of degenerated environments, such as long and straight corridors, by calibration while the LiDAR-IMU fusion sufficiently operates. Furthermore, we estimate the uncertainty (i.e., covariance matrix) of the wheel o
    
[^50]: 一种用于联邦学习的可解释客户端决策树聚合过程

    An Interpretable Client Decision Tree Aggregation process for Federated Learning

    [https://arxiv.org/abs/2404.02510](https://arxiv.org/abs/2404.02510)

    提出了一种用于联邦学习的可解释客户端决策树聚合过程，旨在解决在这些模型中注入可解释性的挑战。

    

    可信的人工智能解决方案在当今的数据驱动应用中至关重要，优先考虑诸如鲁棒性、安全性、透明性、可解释性和隐私性等原则。这导致联邦学习作为隐私和分布式机器学习的解决方案的出现。决策树作为自解释模型，在资源受限的环境中如联邦学习环境中进行协作模型训练是理想的，以在这些模型中注入可解释性。决策树结构使得在联邦学习环境中进行聚合并不是一件简单的事情。它们需要能够合并它们的决策路径而不引入偏差或过拟合的技术，同时保持聚合决策树的稳健性和泛化性。本文提出了一种适用于联邦学习场景的可解释客户端决策树聚合过程。

    arXiv:2404.02510v1 Announce Type: cross  Abstract: Trustworthy Artificial Intelligence solutions are essential in today's data-driven applications, prioritizing principles such as robustness, safety, transparency, explainability, and privacy among others. This has led to the emergence of Federated Learning as a solution for privacy and distributed machine learning. While decision trees, as self-explanatory models, are ideal for collaborative model training across multiple devices in resource-constrained environments such as federated learning environments for injecting interpretability in these models. Decision tree structure makes the aggregation in a federated learning environment not trivial. They require techniques that can merge their decision paths without introducing bias or overfitting while keeping the aggregated decision trees robust and generalizable. In this paper, we propose an Interpretable Client Decision Tree Aggregation process for Federated Learning scenarios that kee
    
[^51]: VIAssist：为视觉障碍用户调整多模大语言模型

    VIAssist: Adapting Multi-modal Large Language Models for Users with Visual Impairments

    [https://arxiv.org/abs/2404.02508](https://arxiv.org/abs/2404.02508)

    本论文研究了如何利用多模大语言模型（MLLMs）为视障人士提供视觉问题答案，提出了 VIAssist 系统，可以识别不受欢迎的图像并提供详细的操作，最终依据用户查询提供可靠的答案。

    

    具有视觉障碍的个体，包括视觉感知方面的部分或完全困难，被称为视障人士。全球估计有22亿人受视力障碍影响。近年来，多模大语言模型（MLLMs）的发展展示了它们在各个领域的非凡能力。希望通过MLLMs的视觉理解和推理能力来帮助视障人士。然而，由于难以捕捉理想图像以满足他们的日常需求，视障人士使用MLLMs具有挑战性。例如，目标对象未完全或部分放置在图像中。本文探讨了如何利用MLLMs为视障人士提供视觉问题答案。VIAssist能够识别不受欢迎的图像并提供详细的操作。最后，VIAssist可以根据用户的查询提供可靠的答案。

    arXiv:2404.02508v1 Announce Type: cross  Abstract: Individuals with visual impairments, encompassing both partial and total difficulties in visual perception, are referred to as visually impaired (VI) people. An estimated 2.2 billion individuals worldwide are affected by visual impairments. Recent advancements in multi-modal large language models (MLLMs) have showcased their extraordinary capabilities across various domains. It is desirable to help VI individuals with MLLMs' great capabilities of visual understanding and reasoning. However, it is challenging for VI people to use MLLMs due to the difficulties in capturing the desirable images to fulfill their daily requests. For example, the target object is not fully or partially placed in the image. This paper explores how to leverage MLLMs for VI individuals to provide visual-question answers. VIAssist can identify undesired images and provide detailed actions. Finally, VIAssist can provide reliable answers to users' queries based on
    
[^52]: 情绪支持对话中的动态演示检索与认知理解

    Dynamic Demonstration Retrieval and Cognitive Understanding for Emotional Support Conversation

    [https://arxiv.org/abs/2404.02505](https://arxiv.org/abs/2404.02505)

    通过动态演示检索和认知理解，我们提出了一种新颖的方法来提高情绪支持对话中提供的支持质量。

    

    情绪支持对话（ESC）系统在提供共情互动中起着关键作用，通过理解和解决用户独特经历来帮助用户度过消极情绪状态。本文解决ESC中的两个关键挑战：通过动态演示检索增强相关语境和共情式回应生成，以及推进认知理解以全面把握隐含的心理状态。我们介绍了动态演示检索和认知方面情境理解（\ourwork），这是一种新颖的方法，将这些元素协同起来，以提高ESC中提供的支持质量。通过利用上下文学习和人设信息，我们引入了一种创新的检索机制，选择信息丰富且个性化的演示对。我们还提出了一个认知理解模块，利用来自ATOMIC知识源的四种认知关系，以深入理解隐含的心理状态。

    arXiv:2404.02505v1 Announce Type: cross  Abstract: Emotional Support Conversation (ESC) systems are pivotal in providing empathetic interactions, aiding users through negative emotional states by understanding and addressing their unique experiences. In this paper, we tackle two key challenges in ESC: enhancing contextually relevant and empathetic response generation through dynamic demonstration retrieval, and advancing cognitive understanding to grasp implicit mental states comprehensively. We introduce Dynamic Demonstration Retrieval and Cognitive-Aspect Situation Understanding (\ourwork), a novel approach that synergizes these elements to improve the quality of support provided in ESCs. By leveraging in-context learning and persona information, we introduce an innovative retrieval mechanism that selects informative and personalized demonstration pairs. We also propose a cognitive understanding module that utilizes four cognitive relationships from the ATOMIC knowledge source to dee
    
[^53]: 学习面向完全可观察非确定性计划领域的泛化策略

    Learning Generalized Policies for Fully Observable Non-Deterministic Planning Domains

    [https://arxiv.org/abs/2404.02499](https://arxiv.org/abs/2404.02499)

    本研究扩展了学习完全可观察、非确定性计划领域的泛化策略的方法，并通过实验评估了在一些 FOND 计划基准领域中产生的泛化策略的正确性。

    

    泛化策略代表解决大量计划问题的反应性策略，例如从给定领域中无限可解实例的集合。 提出了一种从一系列小训练实例中学习这种策略的方法，已成功应用于经典领域。 本文扩展了学习面向完全可观察、非确定性（FOND）领域的泛化策略的公式和导致的组合方法，通过一系列 FOND 计划基准领域的实验评估了生成的方法，展示了一些领域中产生的泛化策略，并证明了其正确性。 学习 FOND 计划的泛化策略方法实际上可以被看作是一种搜索结果的另一种 FOND 计划方法，这种方法不是在给定状态空间中搜索解决方案，而是在由必须学习的特征定义的抽象空间中搜索解决方案。

    arXiv:2404.02499v1 Announce Type: new  Abstract: General policies represent reactive strategies for solving large families of planning problems like the infinite collection of solvable instances from a given domain. Methods for learning such policies from a collection of small training instances have been developed successfully for classical domains. In this work, we extend the formulations and the resulting combinatorial methods for learning general policies over fully observable, non-deterministic (FOND) domains. We also evaluate the resulting approach experimentally over a number of benchmark domains in FOND planning, present the general policies that result in some of these domains, and prove their correctness. The method for learning general policies for FOND planning can actually be seen as an alternative FOND planning method that searches for solutions, not in the given state space but in an abstract space defined by features that must be learned as well.
    
[^54]: 测量大型语言模型的社会规范

    Measuring Social Norms of Large Language Models

    [https://arxiv.org/abs/2404.02491](https://arxiv.org/abs/2404.02491)

    论文提出了一个挑战，测试大型语言模型对社会规范的理解，构建了一个数据集涵盖广泛的社会规范问题，通过多代理框架基于大型语言模型来提高模型对社会规范的理解能力。

    

    我们提出了一个新的挑战，以检验大型语言模型是否理解社会规范。与现有数据集不同，我们的数据集要求具有解决社会规范的基本理解。我们的数据集包含最大的社会规范技能集，包括402项技能和12,383个问题，涵盖了从观点和论点到文化和法律等广泛的社会规范。我们根据K-12课程设计了我们的数据集。这使得可以直接将大型语言模型的社会理解能力与人类进行比较，更具体地说是与小学生进行比较。尽管先前的工作在我们的基准测试中产生几乎随机的准确度，但最近的大型语言模型（如GPT3.5-Turbo和LLaMA2-Chat）能够显著提高性能，仅略低于人类性能。然后，我们提出了一个基于大型语言模型的多代理框架，以提高模型理解社会规范的能力。

    arXiv:2404.02491v1 Announce Type: cross  Abstract: We present a new challenge to examine whether large language models understand social norms. In contrast to existing datasets, our dataset requires a fundamental understanding of social norms to solve. Our dataset features the largest set of social norm skills, consisting of 402 skills and 12,383 questions covering a wide set of social norms ranging from opinions and arguments to culture and laws. We design our dataset according to the K-12 curriculum. This enables the direct comparison of the social understanding of large language models to humans, more specifically, elementary students. While prior work generates nearly random accuracy on our benchmark, recent large language models such as GPT3.5-Turbo and LLaMA2-Chat are able to improve the performance significantly, only slightly below human performance. We then propose a multi-agent framework based on large language models to improve the models' ability to understand social norms.
    
[^55]: 药物协同作用预测的新方法

    New methods for drug synergy prediction

    [https://arxiv.org/abs/2404.02484](https://arxiv.org/abs/2404.02484)

    最佳方法准确解决了涉及已知药物或细胞系的药物协同作用预测情景，但仍未达到准确预测新药物或细胞系的水平。

    

    在这篇小型综述中，我们探讨了依赖于高通量组合筛选的药物组合协同作用的新预测方法。自2021年以来，该领域取得了迅速进展，已发表了超过30种原创机器学习方法，其中绝大多数是基于深度学习技术的。我们旨在通过突显方法中使用的核心技术、数据来源、输入数据类型和协同得分，以及论文所涉及的预测情景和评估协议，将这些论文放在一个统一的视角下。我们的发现是，最佳方法准确地解决了涉及已知药物或细胞系的协同作用预测情景，而涉及新药物或细胞系的情景仍未达到准确预测水平。

    arXiv:2404.02484v1 Announce Type: cross  Abstract: In this mini-review, we explore the new prediction methods for drug combination synergy relying on high-throughput combinatorial screens. The fast progress of the field is witnessed in the more than thirty original machine learning methods published since 2021, a clear majority of them based on deep learning techniques. We aim to put these papers under a unifying lens by highlighting the core technologies, the data sources, the input data types and synergy scores used in the methods, as well as the prediction scenarios and evaluation protocols that the papers deal with. Our finding is that the best methods accurately solve the synergy prediction scenarios involving known drugs or cell lines while the scenarios involving new drugs or cell lines still fall short of an accurate prediction level.
    
[^56]: FedSelect：个性化的联邦学习，通过定制化参数选择进行微调

    FedSelect: Personalized Federated Learning with Customized Selection of Parameters for Fine-Tuning

    [https://arxiv.org/abs/2404.02478](https://arxiv.org/abs/2404.02478)

    提出了一种受到彩票票据假设启发的新型个性化联邦学习算法FedSelect，能够在微调中定制选择网络参数，解决了全局知识存储不够优化的问题。

    

    标准的联邦学习方法在客户数据分布具有充分异质性时会受到影响。最近的方法通过个性化联邦学习（PFL）解决了客户数据异质性问题 - 一类旨在个性化学习的全局知识以更好地适应客户本地数据分布的FL算法。现有的PFL方法通常通过在特定层（即分类器头部）上执行个性化和对其余网络进行全局聚合来解耦深度神经网络的全局更新。然而，预先选择网络层进行个性化可能导致全局知识的存储不够优化。在这项工作中，我们提出了FedSelect，这是一种受到彩票票据假设中使用的迭代子网络发现过程启发的新型PFL算法。FedSelect逐步扩展子网络以个性化客户参数，并同时对剩余部分进行全局聚合。

    arXiv:2404.02478v1 Announce Type: cross  Abstract: Standard federated learning approaches suffer when client data distributions have sufficient heterogeneity. Recent methods addressed the client data heterogeneity issue via personalized federated learning (PFL) - a class of FL algorithms aiming to personalize learned global knowledge to better suit the clients' local data distributions. Existing PFL methods usually decouple global updates in deep neural networks by performing personalization on particular layers (i.e. classifier heads) and global aggregation for the rest of the network. However, preselecting network layers for personalization may result in suboptimal storage of global knowledge. In this work, we propose FedSelect, a novel PFL algorithm inspired by the iterative subnetwork discovery procedure used for the Lottery Ticket Hypothesis. FedSelect incrementally expands subnetworks to personalize client parameters, concurrently conducting global aggregations on the remaining p
    
[^57]: 在受限制的多小区网络中增强总速率性能：一种低信息交换方法

    Enhancing Sum-Rate Performance in Constrained Multicell Networks: A Low-Information Exchange Approach

    [https://arxiv.org/abs/2404.02477](https://arxiv.org/abs/2404.02477)

    提出了一种创新方法，在受限制的多小区网络中通过极少的信息交换实现最大化总速率性能。

    

    尽管对于5G通信及更高级别通信系统中的大规模MIMO系统进行了大量研究，但实际情况是许多已部署的基站仅配备有限数量的天线，而不是支持大规模MIMO配置。此外，虽然消除了小区边界的无小区网络概念正在研究中，但实际部署往往受限于基站之间的有限回传连接容量。本文探讨了在这些更现实地配置的多小区网络约束条件下最大化总速率性能的技术。我们提出了一种创新方法，极大地减少了基站之间信息交换的需求，仅需极少的比特，与传统方法需要交换数百比特形成鲜明对比。我们提出的方法不仅解决了当前网络基础设施施加的限制，

    arXiv:2404.02477v1 Announce Type: cross  Abstract: Despite the extensive research on massive MIMO systems for 5G telecommunications and beyond, the reality is that many deployed base stations are equipped with a limited number of antennas rather than supporting massive MIMO configurations. Furthermore, while the cell-less network concept, which eliminates cell boundaries, is under investigation, practical deployments often grapple with significantly limited backhaul connection capacities between base stations. This letter explores techniques to maximize the sum-rate performance within the constraints of these more realistically equipped multicell networks. We propose an innovative approach that dramatically reduces the need for information exchange between base stations to a mere few bits, in stark contrast to conventional methods that require the exchange of hundreds of bits. Our proposed method not only addresses the limitations imposed by current network infrastructure but also show
    
[^58]: 用于旅行购买者问题的深度强化学习

    Deep Reinforcement Learning for Traveling Purchaser Problems

    [https://arxiv.org/abs/2404.02476](https://arxiv.org/abs/2404.02476)

    提出了一种基于深度强化学习的方法，该方法分别解决了旅行购买者问题中的路由构建和购买规划问题，并从全局角度评估和优化解决方案。

    

    旅行购买者问题（TPP）是一种具有广泛应用的重要组合优化问题。本文提出了一种基于深度强化学习（DRL）的新方法，该方法分别解决了路由构建和购买规划问题，同时从全局角度评估和优化解决方案。我们的方法的关键组成部分包括用于捕捉市场-产品关系的TPP的二部图表示，以及从二部图中提取信息并将其用于顺序构建路由的策略网络。

    arXiv:2404.02476v1 Announce Type: cross  Abstract: The traveling purchaser problem (TPP) is an important combinatorial optimization problem with broad applications. Due to the coupling between routing and purchasing, existing works on TPPs commonly address route construction and purchase planning simultaneously, which, however, leads to exact methods with high computational cost and heuristics with sophisticated design but limited performance. In sharp contrast, we propose a novel approach based on deep reinforcement learning (DRL), which addresses route construction and purchase planning separately, while evaluating and optimizing the solution from a global perspective. The key components of our approach include a bipartite graph representation for TPPs to capture the market-product relations, and a policy network that extracts information from the bipartite graph and uses it to sequentially construct the route. One significant benefit of our framework is that we can efficiently const
    
[^59]: uTeBC-NLP在SemEval-2024任务9中：LLMs能成为横向思考者吗？

    uTeBC-NLP at SemEval-2024 Task 9: Can LLMs be Lateral Thinkers?

    [https://arxiv.org/abs/2404.02474](https://arxiv.org/abs/2404.02474)

    通过研究提示工程方法如何增强LLMs在横向思考任务上的表现，揭示了其固有的超越思维能力，并发现压缩的信息性提示和动态的情境学习显著提升了模型性能。

    

    受人类认知启发，Jiang等人（2023c）创建了一个用于评估LLMs横向思维（超越思维定势）的基准。在这一基准的基础上，我们研究了不同的提示方法如何增强LLMs在这一任务上的表现，以揭示其固有的超越思维能力。通过参加SemEval-2024的第9项任务，即句子拼图子任务，我们探讨了提示工程方法：思维链（CoT）和直接提示，使用信息性描述进行增强，并利用检索增强生成（RAG）管道进行情境化提示。我们的实验涉及三种LLMs，包括GPT-3.5、GPT-4和Zephyr-7B-beta。我们使用GPT-4生成了谜题和选项之间的思维路径数据集，并通过人类进行了质量验证。研究结果表明，压缩的信息性提示能够提升模型性能。动态的情境学习显著提升了模型性能。

    arXiv:2404.02474v1 Announce Type: cross  Abstract: Inspired by human cognition, Jiang et al.(2023c) create a benchmark for assessing LLMs' lateral thinking-thinking outside the box. Building upon this benchmark, we investigate how different prompting methods enhance LLMs' performance on this task to reveal their inherent power for outside-the-box thinking ability. Through participating in SemEval-2024, task 9, Sentence Puzzle sub-task, we explore prompt engineering methods: chain of thoughts (CoT) and direct prompting, enhancing with informative descriptions, and employing contextualizing prompts using a retrieval augmented generation (RAG) pipeline. Our experiments involve three LLMs including GPT-3.5, GPT-4, and Zephyr-7B-beta. We generate a dataset of thinking paths between riddles and options using GPT-4, validated by humans for quality. Findings indicate that compressed informative prompts enhance performance. Dynamic in-context learning enhances model performance significantly. F
    
[^60]: 提示数值序列：市场评论生成案例研究

    Prompting for Numerical Sequences: A Case Study on Market Comment Generation

    [https://arxiv.org/abs/2404.02466](https://arxiv.org/abs/2404.02466)

    本研究探讨了针对市场评论生成任务的不同输入表示方法，发现类似编程语言的提示效果更好，而类似自然语言和较长格式的提示效果较差。

    

    大型语言模型已被应用于广泛的数据转文本生成任务，包括表格、图表和时间序列数值数据转文本设置。然而，对于生成表格和图表等结构化数据的提示的研究正在增长中，对于时间序列数值数据的提示的深入研究却不足。因此，本研究探讨了各种输入表示，包括令牌序列和结构化格式如HTML、LaTeX和Python样式代码。在我们的实验中，我们专注于“市场评论生成”任务，该任务涉及将股价数值序列作为输入，生成相应的市场评论。与我们的预期相反，结果表明类似编程语言的提示产生更好的结果，而类似自然语言和较长格式（如HTML和LaTeX）的提示效果较差。我们的发现提供了一种方法

    arXiv:2404.02466v1 Announce Type: cross  Abstract: Large language models (LLMs) have been applied to a wide range of data-to-text generation tasks, including tables, graphs, and time-series numerical data-to-text settings. While research on generating prompts for structured data such as tables and graphs is gaining momentum, in-depth investigations into prompting for time-series numerical data are lacking. Therefore, this study explores various input representations, including sequences of tokens and structured formats such as HTML, LaTeX, and Python-style codes. In our experiments, we focus on the task of Market Comment Generation, which involves taking a numerical sequence of stock prices as input and generating a corresponding market comment. Contrary to our expectations, the results show that prompts resembling programming languages yield better outcomes, whereas those similar to natural languages and longer formats, such as HTML and LaTeX, are less effective. Our findings offer in
    
[^61]: TSNet: 一种具有多尺度融合和自适应学习的图像去雾的两阶段网络

    TSNet:A Two-stage Network for Image Dehazing with Multi-scale Fusion and Adaptive Learning

    [https://arxiv.org/abs/2404.02460](https://arxiv.org/abs/2404.02460)

    TSNet通过引入多尺度融合模块和自适应学习模块，提出了一种解决图像去雾泛化和效果问题的两阶段网络。

    

    图像去雾长期以来一直是研究的热门话题。先前基于深度学习的图像去雾方法未能在合成数据集和真实数据集上达到令人满意的效果，表现出较差的泛化能力。本文提出了一种名为TSNet的两阶段图像去雾网络，主要由多尺度融合模块（MSFM）和自适应学习模块（ALM）组成。具体来说，MSFM和ALM增强了TSNet的泛化能力。MSFM可以在多个尺度上获得大的感受野，并整合不同频率的特征，以减小输入与学习目标之间的差异。ALM可以主动学习图像中感兴趣的区域，并更有效地恢复纹理细节。此外，TSNet被设计为一个两阶段的网络。

    arXiv:2404.02460v1 Announce Type: cross  Abstract: Image dehazing has been a popular topic of research for a long time. Previous deep learning-based image dehazing methods have failed to achieve satisfactory dehazing effects on both synthetic datasets and real-world datasets, exhibiting poor generalization. Moreover, single-stage networks often result in many regions with artifacts and color distortion in output images. To address these issues, this paper proposes a two-stage image dehazing network called TSNet, mainly consisting of the multi-scale fusion module (MSFM) and the adaptive learning module (ALM). Specifically, MSFM and ALM enhance the generalization of TSNet. The MSFM can obtain large receptive fields at multiple scales and integrate features at different frequencies to reduce the differences between inputs and learning objectives. The ALM can actively learn of regions of interest in images and restore texture details more effectively. Additionally, TSNet is designed as a t
    
[^62]: PhonologyBench：评估大型语言模型的音韵技能

    PhonologyBench: Evaluating Phonological Skills of Large Language Models

    [https://arxiv.org/abs/2404.02456](https://arxiv.org/abs/2404.02456)

    PhonologyBench是一个新颖的基准测试，旨在明确评估大型语言模型在英语中的音韵技能，展示了LLMs在没有语音数据情况下在PhonologyBench任务上表现出显著性能。

    

    音韵学是研究语音结构和发音规则的学科，是大型语言模型（LLM）研究中一个关键但经常被忽视的组成部分。LLMs在各种利用音韵学的下游应用中被广泛使用，如教育工具和诗歌生成。此外，LLMs可能会从训练数据中学习不完美的正字和音标形式之间的关联。因此，对LLMs的音韵技能进行基准测试至关重要。为此，我们提出了PhonologyBench，这是一个新颖的基准测试，包括三个诊断任务，旨在明确测试LLMs在英语中的音韵技能：形音转换、音节计数和押韵词生成。尽管没有访问语音数据，LLMs在PhonologyBench任务上表现出显著的性能。然而，我们观察到在押韵词生成和音节计数方面存在显著的17%和45%的差距， respectively, when...

    arXiv:2404.02456v1 Announce Type: cross  Abstract: Phonology, the study of speech's structure and pronunciation rules, is a critical yet often overlooked component in Large Language Model (LLM) research. LLMs are widely used in various downstream applications that leverage phonology such as educational tools and poetry generation. Moreover, LLMs can potentially learn imperfect associations between orthographic and phonological forms from the training data. Thus, it is imperative to benchmark the phonological skills of LLMs. To this end, we present PhonologyBench, a novel benchmark consisting of three diagnostic tasks designed to explicitly test the phonological skills of LLMs in English: grapheme-to-phoneme conversion, syllable counting, and rhyme word generation. Despite having no access to speech data, LLMs showcased notable performance on the PhonologyBench tasks. However, we observe a significant gap of 17% and 45% on Rhyme Word Generation and Syllable counting, respectively, when 
    
[^63]: 衡量遗忘策略的推理强度技术

    Techniques for Measuring the Inferential Strength of Forgetting Policies

    [https://arxiv.org/abs/2404.02454](https://arxiv.org/abs/2404.02454)

    本文提出了一种衡量原理论推理强度变化的损失函数，并使用Problog工具计算损失度量，最终得出了关于不同遗忘策略强度的研究方法和实际应用示例。

    

    知识表示中的遗忘技术被证明是一种强大且有广泛应用的知识工程工具。然而，关于不同的遗忘策略或不同遗忘操作符的使用如何影响原理论的推理强度几乎没有研究。本文旨在根据模型计数和概率理论的直觉定义用于衡量推理强度变化的损失函数。研究了此类损失度量的性质，并提出了一种实用的知识工程工具，用于使用Problog计算损失度量。论文包括一个用于研究和确定不同遗忘策略强度的工作方法，以及展示如何利用Problog应用理论结果的具体示例。虽然重点是遗忘，但结果更为普遍，并且应具有更广泛的应用。

    arXiv:2404.02454v1 Announce Type: new  Abstract: The technique of forgetting in knowledge representation has been shown to be a powerful and useful knowledge engineering tool with widespread application. Yet, very little research has been done on how different policies of forgetting, or use of different forgetting operators, affects the inferential strength of the original theory. The goal of this paper is to define loss functions for measuring changes in inferential strength based on intuitions from model counting and probability theory. Properties of such loss measures are studied and a pragmatic knowledge engineering tool is proposed for computing loss measures using Problog. The paper includes a working methodology for studying and determining the strength of different forgetting policies, in addition to concrete examples showing how to apply the theoretical results using Problog. Although the focus is on forgetting, the results are much more general and should have wider applicati
    
[^64]: 通过隐式组合进行算法诱导的任务不可知架构

    Task Agnostic Architecture for Algorithm Induction via Implicit Composition

    [https://arxiv.org/abs/2404.02450](https://arxiv.org/abs/2404.02450)

    探索开发一种统一架构，旨在解决各种任务，包括以前未见过的任务，并使用跨多种模式的输入。

    

    应用机器学习中的不同领域（如计算机视觉、语音或自然语言处理）一直在构建面向特定领域的解决方案。目前，我们正在目睹一个相反的趋势，即向开发更广义的架构发展，这是由大型语言模型和多模式基础模型推动的。这些架构旨在解决各种任务，包括以前未见过的任务，并使用跨多种模式的输入。将这种泛化趋势推向极端意味着可能存在一种能够解决所有任务的单一深度网络架构。本文旨在探索开发这样一个统一架构，并提出了一个理论框架，说明如何构建这样的架构。我们的提议基于以下假设。首先，任务是通过按照一系列指令来解决的，通常在常规计算硬件的代码中实现。

    arXiv:2404.02450v1 Announce Type: cross  Abstract: Different fields in applied machine learning such as computer vision, speech or natural language processing have been building domain-specialised solutions. Currently, we are witnessing an opposing trend towards developing more generalist architectures, driven by Large Language Models and multi-modal foundational models. These architectures are designed to tackle a variety of tasks, including those previously unseen and using inputs across multiple modalities. Taking this trend of generalization to the extreme suggests the possibility of a single deep network architecture capable of solving all tasks. This position paper aims to explore developing such a unified architecture and proposes a theoretical framework of how it could be constructed. Our proposal is based on the following assumptions. Firstly, tasks are solved by following a sequence of instructions, typically implemented in code for conventional computing hardware, which inhe
    
[^65]: 电动车辆路径问题用于应急供电：面向电信基站救助

    Electric Vehicle Routing Problem for Emergency Power Supply: Towards Telecom Base Station Relief

    [https://arxiv.org/abs/2404.02448](https://arxiv.org/abs/2404.02448)

    提出一种新型的基于电动车辆的路径问题，通过组合基于规则的车辆选择器和基于强化学习的节点选择器解决电动车辆路径问题，以最小化总行驶距离和故障基站数量。

    

    作为一家电信提供商，我们公司有一个关键使命，即在停电期间保持电信服务。为了实现这一使命，至关重要的是维持电信基站的电力。本文考虑一种解决方案，即电动车辆 (EVs) 直接前往其位置为基站提供电力。我们的目标是找到最小化所有电动车辆的总行驶距离和故障基站数量的EV路线。在本文中，我们将这一路径问题形式化为新型的电动车辆路径问题 (EVRP) 变体，并提出了将基于规则的车辆选择器和基于强化学习（RL）的节点选择器相结合的求解器。车辆选择器的规则确保了所选EV开始移动时的确切环境状态。此外，RL模型的节点选择实现了快速路径生成，在紧急情况下尤为重要。我们在机器人上对我们的求解器进行评估

    arXiv:2404.02448v1 Announce Type: cross  Abstract: As a telecom provider, our company has a critical mission to maintain telecom services even during power outages. To accomplish the mission, it is essential to maintain the power of the telecom base stations. Here we consider a solution where electric vehicles (EVs) directly supply power to base stations by traveling to their locations. The goal is to find EV routes that minimize both the total travel distance of all EVs and the number of downed base stations. In this paper, we formulate this routing problem as a new variant of the Electric Vehicle Routing Problem (EVRP) and propose a solver that combines a rule-based vehicle selector and a reinforcement learning (RL)-based node selector. The rule of the vehicle selector ensures the exact environmental states when the selected EV starts to move. In addition, the node selection by the RL model enables fast route generation, which is critical in emergencies. We evaluate our solver on bot
    
[^66]: 利用交叉颜色空间特征融合和量子-经典堆叠集成方法的乳腺癌组织病理图像分类的新方法

    A Novel Approach to Breast Cancer Histopathological Image Classification Using Cross-Colour Space Feature Fusion and Quantum-Classical Stack Ensemble Method

    [https://arxiv.org/abs/2404.02447](https://arxiv.org/abs/2404.02447)

    本研究结合了颜色空间特征融合和量子-经典堆叠方法，提高了乳腺癌组织病理图像分类的准确性，标志着个性化医学评估领域的重要进展。

    

    乳腺癌分类在确保及时诊断和有效治疗方面至关重要。本研究以组织病理图像为基础，强调利用颜色空间集成和量子-经典堆叠的协同能力来提高乳腺癌分类的准确性的重要意义。通过深入研究RGB、HSV和CIE L*u*v等不同颜色空间，作者们开展了一项由先进方法引导的全面调查。利用DenseNet121架构进行特征提取，作者们利用了随机森林、支持向量机、QSVC和VQC分类器的稳健性。这项研究涵盖了颜色空间集成中的独特特征融合技术。这种方法不仅加深了我们对乳腺癌分类的理解，还在个性化医学评估中达到了里程碑。量子和经典分类的融合

    arXiv:2404.02447v1 Announce Type: cross  Abstract: Breast cancer classification stands as a pivotal pillar in ensuring timely diagnosis and effective treatment. This study with histopathological images underscores the profound significance of harnessing the synergistic capabilities of colour space ensembling and quantum-classical stacking to elevate the precision of breast cancer classification. By delving into the distinct colour spaces of RGB, HSV and CIE L*u*v, the authors initiated a comprehensive investigation guided by advanced methodologies. Employing the DenseNet121 architecture for feature extraction the authors have capitalized on the robustness of Random Forest, SVM, QSVC, and VQC classifiers. This research encompasses a unique feature fusion technique within the colour space ensemble. This approach not only deepens our comprehension of breast cancer classification but also marks a milestone in personalized medical assessment. The amalgamation of quantum and classical classi
    
[^67]: 使用语言模型评估教育中教学质量的承诺与陷阱

    The Promises and Pitfalls of Using Language Models to Measure Instruction Quality in Education

    [https://arxiv.org/abs/2404.02444](https://arxiv.org/abs/2404.02444)

    本研究利用NLP技术评估教育中多种高推理教学实践的质量，并且首次应用NLP来衡量对有特殊需求学生特别有效的教学实践。

    

    评估教学质量是教育系统改进努力的基本组成部分。然而，传统的手工评估昂贵、主观，并且严重依赖于观察者的专业知识和特殊因素，这些因素阻碍了教师及时获得频繁反馈。与之前主要关注单一低推理教学实践的研究不同，本文首次展示了利用自然语言处理（NLP）技术评估两种不同教育环境下的多种高推理教学实践的研究：面对面K-12教室和预服务教师的模拟表现任务。这也是首个应用NLP来评估被广泛认为对有特殊需求学生特别有效的教学实践的研究。我们面临NLP模型教学分析中的两个挑战，包括

    arXiv:2404.02444v1 Announce Type: cross  Abstract: Assessing instruction quality is a fundamental component of any improvement efforts in the education system. However, traditional manual assessments are expensive, subjective, and heavily dependent on observers' expertise and idiosyncratic factors, preventing teachers from getting timely and frequent feedback. Different from prior research that mostly focuses on low-inference instructional practices on a singular basis, this paper presents the first study that leverages Natural Language Processing (NLP) techniques to assess multiple high-inference instructional practices in two distinct educational settings: in-person K-12 classrooms and simulated performance tasks for pre-service teachers. This is also the first study that applies NLP to measure a teaching practice that is widely acknowledged to be particularly effective for students with special needs. We confront two challenges inherent in NLP-based instructional analysis, including
    
[^68]: AD4RL：具有基于价值数据集的离线强化学习的自动驾驶基准测试

    AD4RL: Autonomous Driving Benchmarks for Offline Reinforcement Learning with Value-based Dataset

    [https://arxiv.org/abs/2404.02429](https://arxiv.org/abs/2404.02429)

    本文提供了用于离线强化学习研究的自动驾驶数据集和基准测试，包括真实世界人类驾驶员的数据集，以及七种离线强化学习算法在三种实际驾驶场景中的应用，并提供了一个统一决策模型作为算法设计的参考框架。

    

    离线强化学习通过利用预先收集的大型数据集，已成为一项具有潜力的技术。尽管离线强化学习的实际好处已被增强，但大多数离线强化学习的算法开发研究仍依赖于具有合成数据集的游戏任务。为了解决这些限制，本文提供了用于离线强化学习研究的自动驾驶数据集和基准测试。我们提供了19个数据集，包括真实世界人类驾驶员的数据集，以及三种实际驾驶场景中的七种流行的离线强化学习算法。我们还提供了一个统一的决策过程模型，可以在不同场景中有效运行，作为算法设计的参考框架。我们的研究为社区进一步探索现有强化学习方法的实际方面奠定了基础。

    arXiv:2404.02429v1 Announce Type: cross  Abstract: Offline reinforcement learning has emerged as a promising technology by enhancing its practicality through the use of pre-collected large datasets. Despite its practical benefits, most algorithm development research in offline reinforcement learning still relies on game tasks with synthetic datasets. To address such limitations, this paper provides autonomous driving datasets and benchmarks for offline reinforcement learning research. We provide 19 datasets, including real-world human driver's datasets, and seven popular offline reinforcement learning algorithms in three realistic driving scenarios. We also provide a unified decision-making process model that can operate effectively across different scenarios, serving as a reference framework in algorithm design. Our research lays the groundwork for further collaborations in the community to explore practical aspects of existing reinforcement learning methods. Dataset and codes can be 
    
[^69]: 辅助任务需求掩盖了较小语言模型的能力

    Auxiliary task demands mask the capabilities of smaller language models

    [https://arxiv.org/abs/2404.02418](https://arxiv.org/abs/2404.02418)

    较小语言模型对类比推理、反思推理、单词预测和语法判断的表现受辅助任务需求的影响，评估方法的任务需求越大，性能越低，这种"需求差距"在参数较少、训练数据较少的模型中尤为显著

    

    发展心理学家们对认知能力如语言理解或心灵理论何时出现进行了争论。这些辩论常常关注"任务需求"的概念--执行特定评估时所伴随的辅助挑战--这些挑战可能掩盖了儿童的潜在能力。当衡量语言模型（LMs）的能力时，同样的问题也会出现：任务表现取决于模型的基本能力，结合了模型解释和执行任务的能力以及其可用资源。在这里，我们展示了对于类比推理、反思推理、单词预测和语法判断，具有更大任务需求的评估方法会比降低需求的评估得到更低的性能。这种"需求差距"在参数较少、训练数据较少的模型中最为显著。我们的结果表明，LM的性能不应被解释为

    arXiv:2404.02418v1 Announce Type: cross  Abstract: Developmental psychologists have argued about when cognitive capacities such as language understanding or theory of mind emerge. These debates often hinge on the concept of "task demands" -- the auxiliary challenges associated with performing a particular evaluation -- that may mask the child's underlying ability. The same issues arise when measuring the capacities of language models (LMs): performance on a task is a function of the model's underlying competence, combined with the model's ability to interpret and perform the task given its available resources. Here, we show that for analogical reasoning, reflective reasoning, word prediction, and grammaticality judgments, evaluation methods with greater task demands yield lower performance than evaluations with reduced demands. This "demand gap" is most pronounced for models with fewer parameters and less training data. Our results illustrate that LM performance should not be interpret
    
[^70]: 决策Transformer作为部分可观测连续控制的基础模型

    Decision Transformer as a Foundation Model for Partially Observable Continuous Control

    [https://arxiv.org/abs/2404.02407](https://arxiv.org/abs/2404.02407)

    通过将控制任务作为基于过去观察、动作和奖励的当前最优动作预测来消除估计器设计需求，并利用生成式预训练Transformer系列初始化决策Transformer，然后使用低秩适应对其进行控制任务训练。

    

    面对具有部分状态可观测性的非线性动态系统的闭环控制需要专家对一组不太标准化的理论工具有深入了解，此外，它还需要控制器和估计器设计的精心融合以实现期望的系统行为。为建立一个通用的控制器合成框架，我们探索了决策Transformer（DT）架构。具体地，我们首先将控制任务框架化为基于过去的观察、动作和奖励预测当前最优动作，消除了对单独估计器设计的需求。然后，我们利用预训练的语言模型，即生成式预训练Transformer（GPT）系列，来初始化DT，并随后使用低秩适应（LoRA）对其进行控制任务训练。我们在五个不同的控制任务上进行了全面实验，涵盖航空航天系统的操纵到控制偏微分方程。

    arXiv:2404.02407v1 Announce Type: cross  Abstract: Closed-loop control of nonlinear dynamical systems with partial-state observability demands expert knowledge of a diverse, less standardized set of theoretical tools. Moreover, it requires a delicate integration of controller and estimator designs to achieve the desired system behavior. To establish a general controller synthesis framework, we explore the Decision Transformer (DT) architecture. Specifically, we first frame the control task as predicting the current optimal action based on past observations, actions, and rewards, eliminating the need for a separate estimator design. Then, we leverage the pre-trained language models, i.e., the Generative Pre-trained Transformer (GPT) series, to initialize DT and subsequently train it for control tasks using low-rank adaptation (LoRA). Our comprehensive experiments across five distinct control tasks, ranging from maneuvering aerospace systems to controlling partial differential equations 
    
[^71]: 探讨聊天模型的后门漏洞

    Exploring Backdoor Vulnerabilities of Chat Models

    [https://arxiv.org/abs/2404.02406](https://arxiv.org/abs/2404.02406)

    聊天模型因为多轮交互格式的灵活性增加了对后门攻击的脆弱性，该论文揭示并实现了一种新颖的后门攻击方法

    

    最近的研究表明，大型语言模型（LLMs）容易受到一种称为后门攻击的安全威胁。当前对LLMs的后门研究主要集中在针对指令调整的LLMs，而忽略了另一种现实场景，即将LLMs在多轮对话数据上微调为聊天模型。聊天模型被广泛应用于各种实际场景，因此聊天模型的安全性值得越来越多的关注。不幸的是，我们指出，灵活的多轮交互格式增加了触发设计的灵活性，并增加了聊天模型对后门攻击的脆弱性。在这项工作中，我们揭示并实现了一种新颖的聊天模型后门攻击方法，通过将多个触发场景分布在用户输入中

    arXiv:2404.02406v1 Announce Type: cross  Abstract: Recent researches have shown that Large Language Models (LLMs) are susceptible to a security threat known as Backdoor Attack. The backdoored model will behave well in normal cases but exhibit malicious behaviours on inputs inserted with a specific backdoor trigger. Current backdoor studies on LLMs predominantly focus on instruction-tuned LLMs, while neglecting another realistic scenario where LLMs are fine-tuned on multi-turn conversational data to be chat models. Chat models are extensively adopted across various real-world scenarios, thus the security of chat models deserves increasing attention. Unfortunately, we point out that the flexible multi-turn interaction format instead increases the flexibility of trigger designs and amplifies the vulnerability of chat models to backdoor attacks. In this work, we reveal and achieve a novel backdoor attacking method on chat models by distributing multiple trigger scenarios across user inputs
    
[^72]: 使用ChatLLM在对话AI中导航语境深度的Token Trails

    Token Trails: Navigating Contextual Depths in Conversational AI with ChatLLM

    [https://arxiv.org/abs/2404.02402](https://arxiv.org/abs/2404.02402)

    Token Trails是一种利用token-type嵌入导航对话中复杂上下文细微差别的新方法，通过提高对话理解和回复生成效果，在促进上下文意识聊天机器人交互方面具有前沿性能。

    

    使用大型语言模型(LLMs)进行对话建模需要对上下文进行细致理解，以生成连贯且与上下文相关的回复。本文提出了Token Trails，这是一种利用token-type嵌入来导航对话中复杂上下文细微差别的新方法。我们的框架利用token-type嵌入来区分用户话语和机器人回复，从而促进生成具有上下文意识的回复。通过全面的实验和评估，我们展示了Token Trails在提高对话理解和回复生成方面的有效性，实现了最先进的性能。我们的结果突显了对话AI中上下文建模的重要性，并强调了Token Trails在推动该领域发展方面的潜力，为更复杂和具有上下文意识的聊天机器人交互铺平了道路。

    arXiv:2404.02402v1 Announce Type: cross  Abstract: Conversational modeling using Large Language Models (LLMs) requires a nuanced understanding of context to generate coherent and contextually relevant responses. In this paper, we present Token Trails, a novel approach that leverages token-type embeddings to navigate the intricate contextual nuances within conversations. Our framework utilizes token-type embeddings to distinguish between user utterances and bot responses, facilitating the generation of context-aware replies. Through comprehensive experimentation and evaluation, we demonstrate the effectiveness of Token Trails in improving conversational understanding and response generation, achieving state-of-the-art performance. Our results highlight the significance of contextual modeling in conversational AI and underscore the promising potential of Token Trails to advance the field, paving the way for more sophisticated and contextually aware chatbot interactions.
    
[^73]: 在编码器-解码器语言模型中线性化结构化数据：来自文本到SQL的启示

    On Linearizing Structured Data in Encoder-Decoder Language Models: Insights from Text-to-SQL

    [https://arxiv.org/abs/2404.02389](https://arxiv.org/abs/2404.02389)

    本研究调查了编码器-解码器语言模型中线性处理结构化数据的方法，发现模型能够模仿人类设计的流程，学习结构的深刻含义，揭示了模型内部机制的一些见解。

    

    结构化数据在表格、数据库和知识图中广泛存在，在其表示方面存在重大挑战。 随着大型语言模型（LLMs）的出现，人们开始转向基于线性化的方法，该方法将结构化数据处理为顺序标记流，而不是作为图形明确地建模的方法。 本文探讨了编码器-解码器语言模型（特别是T5）中对结构化数据进行线性处理的情况。 我们的研究发现模型能够模仿人类设计的流程，比如模式链接和语法预测，表明模型对结构的深刻、有意义的学习远远超过简单的标记排序。 我们还发现了模型内部机制的见解，包括结构节点的以自我为中心的特性。

    arXiv:2404.02389v1 Announce Type: cross  Abstract: Structured data, prevalent in tables, databases, and knowledge graphs, poses a significant challenge in its representation. With the advent of large language models (LLMs), there has been a shift towards linearization-based methods, which process structured data as sequential token streams, diverging from approaches that explicitly model structure, often as a graph. Crucially, there remains a gap in our understanding of how these linearization-based methods handle structured data, which is inherently non-linear. This work investigates the linear handling of structured data in encoder-decoder language models, specifically T5. Our findings reveal the model's ability to mimic human-designed processes such as schema linking and syntax prediction, indicating a deep, meaningful learning of structure beyond simple token sequencing. We also uncover insights into the model's internal mechanisms, including the ego-centric nature of structure nod
    
[^74]: 利用视觉和语言模型以及眼睛注视模式增强胸部X射线分析中的人机交互

    Enhancing Human-Computer Interaction in Chest X-ray Analysis using Vision and Language Model with Eye Gaze Patterns

    [https://arxiv.org/abs/2404.02370](https://arxiv.org/abs/2404.02370)

    通过结合眼动数据和文本提示，利用Vision-Language Models（VLMs）增强胸部X射线分析中的人机交互，提高了放射科医师的关注度，有效增强了胸部X射线分析的准确性。

    

    最近计算机辅助诊断的进展在医学影像任务中表现出良好的性能，特别是在胸部X射线分析方面。然而，这些模型与放射科医师之间的互动主要仅限于输入图像。本文提出了一种新方法，通过将眼动数据与文本提示结合在一起，利用增强了放射科医师的关注的视觉语言模型（VLMs）来增强胸部X射线分析中的人机交互。我们的方法利用从眼动数据生成的热图，将它们叠加到医学图像上，以突出放射科医师在胸部X射线评估过程中关注强度较高的区域。我们在视觉问题回答、胸部X射线报告自动化、错误检测和鉴别诊断等任务中评估了这种方法。我们的结果表明，包含眼动信息显著提高了胸部X射线分析的准确性。

    arXiv:2404.02370v1 Announce Type: cross  Abstract: Recent advancements in Computer Assisted Diagnosis have shown promising performance in medical imaging tasks, particularly in chest X-ray analysis. However, the interaction between these models and radiologists has been primarily limited to input images. This work proposes a novel approach to enhance human-computer interaction in chest X-ray analysis using Vision-Language Models (VLMs) enhanced with radiologists' attention by incorporating eye gaze data alongside textual prompts. Our approach leverages heatmaps generated from eye gaze data, overlaying them onto medical images to highlight areas of intense radiologist's focus during chest X-ray evaluation. We evaluate this methodology in tasks such as visual question answering, chest X-ray report automation, error detection, and differential diagnosis. Our results demonstrate the inclusion of eye gaze information significantly enhances the accuracy of chest X-ray analysis. Also, the imp
    
[^75]: EnergAIze: 多智能体深度确定性策略梯度用于车辆到电网能量管理

    EnergAIze: Multi Agent Deep Deterministic Policy Gradient for Vehicle to Grid Energy Management

    [https://arxiv.org/abs/2404.02361](https://arxiv.org/abs/2404.02361)

    本文介绍了EnergAIze，一种利用多智能体深度确定性策略梯度算法的能源管理框架，旨在解决车辆到电网能量管理中的实际适应性、全球优化以及用户参与等挑战。

    

    本文研究了可再生能源（RES）和电动汽车（EVs）日益增加的角色。虽然标志着可持续能源新时代的到来，但也带来了诸多挑战，包括在不断增长的EV采用率背景下平衡供需、平滑峰值消耗。解决这些挑战需要创新的解决方案，如需求响应（DR）、能量灵活性管理、可再生能源社区（RECs），特别是对于EVs，还需要车辆对电网（V2G）。然而，现有的V2G方法往往在现实适应性、全球REC优化与其他灵活资产、可扩展性和用户参与方面存在短板。为了弥合这一差距，本文介绍了EnergAIze，一种多智能体强化学习（MARL）能源管理框架，利用多智能体深度确定性策略梯度（MADDPG）算法。EnergAIze实现了以用户为中心和多目标能量

    arXiv:2404.02361v1 Announce Type: cross  Abstract: This paper investigates the increasing roles of Renewable Energy Sources (RES) and Electric Vehicles (EVs). While indicating a new era of sustainable energy, these also introduce complex challenges, including the need to balance supply and demand and smooth peak consumptions amidst rising EV adoption rates. Addressing these challenges requires innovative solutions such as Demand Response (DR), energy flexibility management, Renewable Energy Communities (RECs), and more specifically for EVs, Vehicle-to-Grid (V2G). However, existing V2G approaches often fall short in real-world adaptability, global REC optimization with other flexible assets, scalability, and user engagement. To bridge this gap, this paper introduces EnergAIze, a Multi-Agent Reinforcement Learning (MARL) energy management framework, leveraging the Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm. EnergAIze enables user-centric and multi-objective energy 
    
[^76]: 利用语言在图像中进行语义增强

    Semantic Augmentation in Images using Language

    [https://arxiv.org/abs/2404.02353](https://arxiv.org/abs/2404.02353)

    深度学习模型需要大规模标记数据集，本文提出利用生成图像增强数据集以改进模型跨领域泛化能力。

    

    深度学习模型需要非常庞大的标记数据集进行监督学习，缺乏这些数据集会导致过拟合并限制其泛化到现实世界示例的能力。最近扩散模型的进展使得能够基于文本输入生成逼真的图像。利用用于训练这些扩散模型的大规模数据集，我们提出一种利用生成的图像来增强现有数据集的技术。本文探讨了各种有效数据增强策略，以提高深度学习模型的跨领域泛化能力。

    arXiv:2404.02353v1 Announce Type: cross  Abstract: Deep Learning models are incredibly data-hungry and require very large labeled datasets for supervised learning. As a consequence, these models often suffer from overfitting, limiting their ability to generalize to real-world examples. Recent advancements in diffusion models have enabled the generation of photorealistic images based on textual inputs. Leveraging the substantial datasets used to train these diffusion models, we propose a technique to utilize generated images to augment existing datasets. This paper explores various strategies for effective data augmentation to improve the out-of-domain generalization capabilities of deep learning models.
    
[^77]: Multi-BERT：利用适配器和提示调整进行低资源多领域适应

    Multi-BERT: Leveraging Adapters and Prompt Tuning for Low-Resource Multi-Domain Adaptation

    [https://arxiv.org/abs/2404.02335](https://arxiv.org/abs/2404.02335)

    提出了一种新颖的方法，使用一个核心模型和多套领域特定参数，结合提示调整和适配器技术，以及额外层次来实现低资源多领域适应，使得模型能够完成与每个领域单独训练模型相媲美的任务。

    

    文本量和多样性的急剧扩展提出了多领域环境中的巨大挑战。这些挑战在波斯语命名实体识别（NER）设置中也很明显。传统方法，无论是使用一个统一模型来处理多个领域，还是为每个领域使用单独的模型，经常会出现显著的限制。单一模型通常难以捕捉各种领域的细微差别，而使用多个大型模型可能会导致资源限制，使为每个领域训练模型几乎不切实际。因此，本文介绍了一种由一个核心模型和多套领域特定参数组成的新颖方法。我们利用提示调整和适配器等技术，结合引入额外层，添加我们可以为特定领域训练的参数。这使得模型能够在性能上与为每个领域训练的单独模型相媲美。

    arXiv:2404.02335v1 Announce Type: cross  Abstract: The rapid expansion of texts' volume and diversity presents formidable challenges in multi-domain settings. These challenges are also visible in the Persian name entity recognition (NER) settings. Traditional approaches, either employing a unified model for multiple domains or individual models for each domain, frequently pose significant limitations. Single models often struggle to capture the nuances of diverse domains, while utilizing multiple large models can lead to resource constraints, rendering the training of a model for each domain virtually impractical. Therefore, this paper introduces a novel approach composed of one core model with multiple sets of domain-specific parameters. We utilize techniques such as prompt tuning and adapters, combined with the incorporation of additional layers, to add parameters that we can train for the specific domains. This enables the model to perform comparably to individual models for each do
    
[^78]: 大型语言模型下领域驱动术语提取的比较研究

    Comparative Study of Domain Driven Terms Extraction Using Large Language Models

    [https://arxiv.org/abs/2404.02330](https://arxiv.org/abs/2404.02330)

    本研究比较了使用大型语言模型进行领域驱动术语提取的方法，评估了Llama2-7B、GPT-3.5和Falcon-7B在Inspec和PubMed数据集上的性能。

    

    关键词在人类理解和机器处理文本数据之间架起重要桥梁，对于数据丰富至关重要，因为它们构成了详细注释的基础，提供了对基础数据更深入和全面的视角。关键词/领域驱动术语提取是自然语言处理中的关键任务，有助于信息检索、文档摘要和内容分类。本文重点关注关键词提取方法，强调三种主要的大型语言模型(LLMs)的使用：Llama2-7B、GPT-3.5和Falcon-7B。我们使用一个自定义的Python包与这些LLMs进行交互，简化了关键词提取过程。我们利用Inspec和PubMed数据集对这些模型的性能进行评估。评价使用Jaccard相似性指数，得到了GPT-3.5的评分分别为0.64（Inspec）和0.21（PubMed），Llama2-7B的评分分别为0.40和0.17。

    arXiv:2404.02330v1 Announce Type: cross  Abstract: Keywords play a crucial role in bridging the gap between human understanding and machine processing of textual data. They are essential to data enrichment because they form the basis for detailed annotations that provide a more insightful and in-depth view of the underlying data. Keyword/domain driven term extraction is a pivotal task in natural language processing, facilitating information retrieval, document summarization, and content categorization. This review focuses on keyword extraction methods, emphasizing the use of three major Large Language Models(LLMs): Llama2-7B, GPT-3.5, and Falcon-7B. We employed a custom Python package to interface with these LLMs, simplifying keyword extraction. Our study, utilizing the Inspec and PubMed datasets, evaluates the performance of these models. The Jaccard similarity index was used for assessment, yielding scores of 0.64 (Inspec) and 0.21 (PubMed) for GPT-3.5, 0.40 and 0.17 for Llama2-7B, a
    
[^79]: Prompt作为程序：一种结构感知的高效编译时Prompt优化方法

    Prompts As Programs: A Structure-Aware Approach to Efficient Compile-Time Prompt Optimization

    [https://arxiv.org/abs/2404.02319](https://arxiv.org/abs/2404.02319)

    提出了SAMMO框架，用于在编译时优化元提示程序，提高了复杂提示在多种不同LLM上的性能。

    

    大型语言模型(LLMs)现在能处理更长更复杂的输入，这促进了更复杂提示的使用。然而，提示通常需要一些调整以提高部署性能。最近的工作提出了自动提示优化方法，但随着提示复杂度和LLM强度的增加，许多提示优化技术已不再足够，需要一种新的方法来优化元提示程序。为了解决这个问题，我们引入了SAMMO，一个用于元提示程序的{\em 编译时}优化的框架，它将提示表示为结构化对象，允许在优化过程中搜索一组丰富的转换。我们展示SAMMO推广了先前的方法，在指令调整、RAG管线调整和提示压缩方面提高了复杂提示在多种不同LLM上的性能。我们开放所有代码供大家使用。

    arXiv:2404.02319v1 Announce Type: cross  Abstract: Large language models (LLMs) can now handle longer and more complex inputs, which facilitate the use of more elaborate prompts. However, prompts often require some tuning to improve performance for deployment. Recent work has proposed automatic prompt optimization methods, but as prompt complexity and LLM strength increase, many prompt optimization techniques are no longer sufficient and a new approach is needed to optimize {\em meta prompt programs}. To address this, we introduce SAMMO, a framework for {\em compile-time} optimizations of metaprompt programs, which represent prompts as structured objects that allows for a rich set of transformations that can be searched over during optimization. We show that SAMMO generalizes previous methods and improves the performance of complex prompts on (1) instruction tuning, (2) RAG pipeline tuning, and (3) prompt compression, across several different LLMs.   We make all code available open-sou
    
[^80]: 分子少样本学习是否真的需要元训练？

    Is Meta-training Really Necessary for Molecular Few-Shot Learning ?

    [https://arxiv.org/abs/2404.02314](https://arxiv.org/abs/2404.02314)

    本文重新审视了分子数据微调方法，提出了基于马氏距离的正则化二次探针损失，并设计了块坐标下降优化器，使得在黑匣子设置下，简单微调方法在少样本学习中获得了竞争性表现，同时消除了特定预训练策略的需要。

    

    最近，少样本学习在药物发现领域引起了极大关注，而最近快速增长的文献大多涉及复杂的元学习策略。本文重新审视了更为直接的分子数据微调方法，并提出了基于马氏距离的正则化二次探针损失。我们设计了一个专门的块坐标下降优化器，避免了我们损失函数的退化解。有趣的是，我们的简单微调方法在与最先进方法的比较中获得了极具竞争力的表现，同时适用于黑匣子设置，并消除了特定情节预训练策略的需要。此外，我们引入了一个新的基准来评估竞争方法对领域转移的稳健性。在这个设置下，我们的微调基线始终比元学习方法取得更好的结果。

    arXiv:2404.02314v1 Announce Type: cross  Abstract: Few-shot learning has recently attracted significant interest in drug discovery, with a recent, fast-growing literature mostly involving convoluted meta-learning strategies. We revisit the more straightforward fine-tuning approach for molecular data, and propose a regularized quadratic-probe loss based on the the Mahalanobis distance. We design a dedicated block-coordinate descent optimizer, which avoid the degenerate solutions of our loss. Interestingly, our simple fine-tuning approach achieves highly competitive performances in comparison to state-of-the-art methods, while being applicable to black-box settings and removing the need for specific episodic pre-training strategies. Furthermore, we introduce a new benchmark to assess the robustness of the competing methods to domain shifts. In this setting, our fine-tuning baseline obtains consistently better results than meta-learning methods.
    
[^81]: 自训练语言模型的崩溃

    Collapse of Self-trained Language Models

    [https://arxiv.org/abs/2404.02305](https://arxiv.org/abs/2404.02305)

    自我训练的语言模型在延长训练时表现出显著的性能下降，导致重复和崩溃的标记输出。

    

    在各个知识创造领域，包括科学，新思想往往建立在现有信息之上。在这项工作中，我们探讨了这个概念在语言模型的背景下的应用。具体而言，我们探讨了自我训练模型在其自身输出上的潜力，类似于人类学习并建立在他们以前的思想和行动上。虽然这种方法在直观上很有吸引力，但我们的研究揭示了它的实际局限性。我们发现对GPT-2模型进行长时间的自训练会导致性能显著下降，导致重复和崩溃的令牌输出。

    arXiv:2404.02305v1 Announce Type: cross  Abstract: In various fields of knowledge creation, including science, new ideas often build on pre-existing information. In this work, we explore this concept within the context of language models. Specifically, we explore the potential of self-training models on their own outputs, akin to how humans learn and build on their previous thoughts and actions. While this approach is intuitively appealing, our research reveals its practical limitations. We find that extended self-training of the GPT-2 model leads to a significant degradation in performance, resulting in repetitive and collapsed token output.
    
[^82]: 使用异构时间图神经网络进行实时轴承负载预测的虚拟传感器

    Virtual Sensor for Real-Time Bearing Load Prediction Using Heterogeneous Temporal Graph Neural Networks

    [https://arxiv.org/abs/2404.02304](https://arxiv.org/abs/2404.02304)

    提出了一种使用Graph Neural Networks分析空间-时间依赖关系的图神经网络虚拟传感器，能够从传感器滚轮数据中学习，将操作条件映射为轴承负载。

    

    精确的轴承负载监测对于其预测与健康管理是至关重要的，这有助于损伤评估、磨损预测和主动维护。传统的机器学习算法无法充分利用这些空间 - 时间依赖关系。为了填补这一空白，我们引入了一种基于图的虚拟传感器，利用图神经网络来分析轴承负载之间的空间 - 时间依赖关系。

    arXiv:2404.02304v1 Announce Type: cross  Abstract: Accurate bearing load monitoring is essential for their Prognostics and Health Management (PHM), enabling damage assessment, wear prediction, and proactive maintenance. While bearing sensors are typically placed on the bearing housing, direct load monitoring requires sensors inside the bearing itself. Recently introduced sensor rollers enable direct bearing load monitoring but are constrained by their battery life. Data-driven virtual sensors can learn from sensor roller data collected during a batterys lifetime to map operating conditions to bearing loads. Although spatially distributed bearing sensors offer insights into load distribution (e.g., correlating temperature with load), traditional machine learning algorithms struggle to fully exploit these spatial-temporal dependencies. To address this gap, we introduce a graph-based virtual sensor that leverages Graph Neural Networks (GNNs) to analyze spatial-temporal dependencies among 
    
[^83]: 一种噪声统治所有：多视角带普遍扰动的对抗攻击

    One Noise to Rule Them All: Multi-View Adversarial Attacks with Universal Perturbation

    [https://arxiv.org/abs/2404.02287](https://arxiv.org/abs/2404.02287)

    这种通用扰动方法架起了2D扰动与类似3D攻击能力之间的桥梁，为生成3D物体识别中的多视角对抗样本提供了实用且可扩展的解决方案。

    

    本文提出了一种新颖的通用扰动方法，用于生成3D物体识别中的多视角对抗样本。与限制在单个视图上的传统攻击不同，我们的方法操作于多个2D图像，为增强模型的可扩展性和鲁棒性提供了实用且可扩展的解决方案。这种通用方法将2D扰动与类似3D的攻击能力联系起来，使其适用于实际应用。

    arXiv:2404.02287v1 Announce Type: cross  Abstract: This paper presents a novel universal perturbation method for generating robust multi-view adversarial examples in 3D object recognition. Unlike conventional attacks limited to single views, our approach operates on multiple 2D images, offering a practical and scalable solution for enhancing model scalability and robustness. This generalizable method bridges the gap between 2D perturbations and 3D-like attack capabilities, making it suitable for real-world applications.   Existing adversarial attacks may become ineffective when images undergo transformations like changes in lighting, camera position, or natural deformations. We address this challenge by crafting a single universal noise perturbation applicable to various object views. Experiments on diverse rendered 3D objects demonstrate the effectiveness of our approach. The universal perturbation successfully identified a single adversarial noise for each given set of 3D object rend
    
[^84]: 通过ChatGPT从合同中提取规范：机遇与挑战

    Extracting Norms from Contracts Via ChatGPT: Opportunities and Challenges

    [https://arxiv.org/abs/2404.02269](https://arxiv.org/abs/2404.02269)

    研究了ChatGPT在从合同中提取规范方面的有效性和局限性，展示了其良好表现但也发现了一些限制。

    

    我们调查了ChatGPT在从合同中提取规范方面的有效性。规范提供了一种自然的方式来通过捕捉如何管理两个或多个自治方之间的交互来设计多主体系统。我们从合同中提取承诺、禁止、授权和权力等规范，以及相关的规范要素（涉及的当事方、前因和后果）。我们的研究揭示了ChatGPT在从合同中提取规范方面的有效性和局限性。ChatGPT展示了在提取规范方面的良好表现，而无需进行训练或微调，因此无需标记数据，而这在该领域通常是不可用的。然而，我们发现了ChatGPT在提取这些规范方面的一些限制，导致了错误的规范提取。这些限制包括对关键细节的忽视、臆想、对连接词的错误解析以及空规范要素。

    arXiv:2404.02269v1 Announce Type: cross  Abstract: We investigate the effectiveness of ChatGPT in extracting norms from contracts. Norms provide a natural way to engineer multiagent systems by capturing how to govern the interactions between two or more autonomous parties. We extract norms of commitment, prohibition, authorization, and power, along with associated norm elements (the parties involved, antecedents, and consequents) from contracts. Our investigation reveals ChatGPT's effectiveness and limitations in norm extraction from contracts. ChatGPT demonstrates promising performance in norm extraction without requiring training or fine-tuning, thus obviating the need for annotated data, which is not generally available in this domain. However, we found some limitations of ChatGPT in extracting these norms that lead to incorrect norm extractions. The limitations include oversight of crucial details, hallucination, incorrect parsing of conjunctions, and empty norm elements. Enhanced 
    
[^85]: OFMPNet: 深度端到端模型用于城市环境中的占有和流量预测

    OFMPNet: Deep End-to-End Model for Occupancy and Flow Prediction in Urban Environment

    [https://arxiv.org/abs/2404.02263](https://arxiv.org/abs/2404.02263)

    OFMPNet是一种深度端到端模型，用于预测城市环境中所有动态对象的未来行为，结合了占有图和场景动态流量信息。

    

    运动预测任务对于自动驾驶系统至关重要，为其提供了在周围环境中选择车辆行为策略的关键数据。本文介绍了一种端到端神经网络方法，旨在预测环境中所有动态对象的未来行为。该方法利用占有图和场景动态流量。我们探讨了构建名为OFMPNet的深度编码器-解码器模型的各种替代方法。该模型使用一系列俯视道路图像，占有格和先前的运动流量作为输入数据。模型的编码器可以融合变压器、基于注意力的或卷积单元。解码器考虑了使用卷积模块和循环块。此外，

    arXiv:2404.02263v1 Announce Type: cross  Abstract: The task of motion prediction is pivotal for autonomous driving systems, providing crucial data to choose a vehicle behavior strategy within its surroundings. Existing motion prediction techniques primarily focus on predicting the future trajectory of each agent in the scene individually, utilizing its past trajectory data. In this paper, we introduce an end-to-end neural network methodology designed to predict the future behaviors of all dynamic objects in the environment. This approach leverages the occupancy map and the scene's motion flow. We are investigatin various alternatives for constructing a deep encoder-decoder model called OFMPNet. This model uses a sequence of bird's-eye-view road images, occupancy grid, and prior motion flow as input data. The encoder of the model can incorporate transformer, attention-based, or convolutional units. The decoder considers the use of both convolutional modules and recurrent blocks. Additio
    
[^86]: 在LLMs中循环：利用大型语言模型注释进行低资源语言的主动学习

    LLMs in the Loop: Leveraging Large Language Model Annotations for Active Learning in Low-Resource Languages

    [https://arxiv.org/abs/2404.02261](https://arxiv.org/abs/2404.02261)

    在低资源语言中，通过将LLMs集成到主动学习循环中进行数据注释，有效减少所需数据量，并取得接近最先进性能的结果。

    

    由于语言资源和数据标注专业知识有限，低资源语言在人工智能开发中面临着重大障碍，使它们变得罕见且成本高昂。为了解决这一不足，我们提出利用LLMs的潜力在主动学习环节中进行数据注释。我们首先进行评估以评估注释者之间的一致性，从而选择适当的LLM注释者。然后，选择的注释者被集成到一个分类器的训练循环中，使用主动学习范式，最小化所需的查询数据量。实证评估，特别是使用GPT-4-Turbo，展示了几乎达到最先进性能的结果，同时大大减少了数据需求，由估算的潜在性能指示。

    arXiv:2404.02261v1 Announce Type: cross  Abstract: Low-resource languages face significant barriers in AI development due to limited linguistic resources and expertise for data labeling, rendering them rare and costly. The scarcity of data and the absence of preexisting tools exacerbate these challenges, especially since these languages may not be adequately represented in various NLP datasets. To address this gap, we propose leveraging the potential of LLMs in the active learning loop for data annotation. Initially, we conduct evaluations to assess inter-annotator agreement and consistency, facilitating the selection of a suitable LLM annotator. The chosen annotator is then integrated into a training loop for a classifier using an active learning paradigm, minimizing the amount of queried data required. Empirical evaluations, notably employing GPT-4-Turbo, demonstrate near-state-of-the-art performance with significantly reduced data requirements, as indicated by estimated potential co
    
[^87]: $\texttt{LM}^\texttt{2}$: 一种简单的语言模型协同解决复杂推理问题

    $\texttt{LM}^\texttt{2}$: A Simple Society of Language Models Solves Complex Reasoning

    [https://arxiv.org/abs/2404.02255](https://arxiv.org/abs/2404.02255)

    LM2提出了一种简单的语言模型$\texttt{LM}^\texttt{2}$，该模型将分解、解决和验证模块化，通过分解器识别关键概念并生成逐步子问题，从而协同解决复杂推理问题。

    

    尽管展示了出现推理能力，但大型语言模型(LLMS)经常会在复杂的、多步骤的推理中迷失方向。现有研究表明，通过将原始问题分解为多个子问题来提供指导，可以引发LLM推理的更强健性——一个分解器生成子问题，一个解算器解决每个这些子问题。然而，这些技术未能适应分解器和解算器模块之间的协调(无论是在单一模型中还是在不同的专门模型中)——分解器没有跟踪解算器按照分解的推理。在本文中，我们提出了LM2来应对这些挑战。LM2将分解、解决和验证模块化为三种不同的语言模型。分解器模块识别解决问题所需的关键概念，并根据推理要求生成逐步子问题。

    arXiv:2404.02255v1 Announce Type: cross  Abstract: Despite demonstrating emergent reasoning abilities, Large Language Models (LLMS) often lose track of complex, multi-step reasoning. Existing studies show that providing guidance via decomposing the original question into multiple subproblems elicits more robustness in LLM reasoning -- a decomposer generates the subproblems, and a solver solves each of these subproblems. However, these techniques fail to accommodate coordination between the decomposer and the solver modules (either in a single model or different specialized ones) -- the decomposer does not keep track of the ability of the solver to follow the decomposed reasoning. In this paper, we propose LM2 to address these challenges. LM2 modularizes the decomposition, solution, and verification into three different language models. The decomposer module identifies the key concepts necessary to solve the problem and generates step-by-step subquestions according to the reasoning requ
    
[^88]: RAT: 检索增强变换器用于点击率预测

    RAT: Retrieval-Augmented Transformer for Click-Through Rate Prediction

    [https://arxiv.org/abs/2404.02249](https://arxiv.org/abs/2404.02249)

    RAT模型是为了解决当前CTR预测模型仅关注样本内特征交互而忽略跨样本关系的问题，通过检索相似样本构建增强输入，实现了对样本内和跨样本的全面特征交互推理，提高了CTR预测的效果。

    

    预测点击率（CTR）是Web应用程序的基本任务，其中一个关键问题是设计有效的特征交互模型。目前的方法主要集中于对单个样本内的特征交互进行建模，而忽略了可以作为参考背景来增强预测的潜在跨样本关系。为弥补这种不足，本文开发了一种检索增强变换器（RAT），旨在获取样本内和跨样本之间的细粒度特征交互。通过检索相似样本，我们为每个目标样本构建增强输入。然后利用级联注意力构建Transformer层，以捕获样本内和跨样本特征交互，促进全面推理以改善CTR预测的同时保持效率。对真实世界数据集的大量实验证实了RAT的有效性，并提出了

    arXiv:2404.02249v1 Announce Type: cross  Abstract: Predicting click-through rates (CTR) is a fundamental task for Web applications, where a key issue is to devise effective models for feature interactions. Current methodologies predominantly concentrate on modeling feature interactions within an individual sample, while overlooking the potential cross-sample relationships that can serve as a reference context to enhance the prediction. To make up for such deficiency, this paper develops a Retrieval-Augmented Transformer (RAT), aiming to acquire fine-grained feature interactions within and across samples. By retrieving similar samples, we construct augmented input for each target sample. We then build Transformer layers with cascaded attention to capture both intra- and cross-sample feature interactions, facilitating comprehensive reasoning for improved CTR prediction while retaining efficiency. Extensive experiments on real-world datasets substantiate the effectiveness of RAT and sugge
    
[^89]: 探索是您需要的全部内容吗？用于强化学习中转移的有效探索特征

    Is Exploration All You Need? Effective Exploration Characteristics for Transfer in Reinforcement Learning

    [https://arxiv.org/abs/2404.02235](https://arxiv.org/abs/2404.02235)

    探索特征与深度强化学习中有效的转移学习的关系，尚未被明确表征。研究试图理解探索特征与改进性能和效率在转移学习中的关系

    

    在深度强化学习（RL）研究中，人们正在努力设计更高效、更具生产力的探索方法，同时解决稀疏奖励问题。这些探索方法通常共享共同原则（例如改善多样性）和实现细节（例如内在奖励）。先前的研究发现，非静止马尔可夫决策过程（MDP）需要探索，以便有效地适应在线转移学习中环境的变化。然而，具体探索特征与在深度RL中的有效转移学习之间的关系尚未被表征。在这项工作中，我们试图理解显著探索特征与改进性能和效率在转移学习中的关系。我们测试了十一个流行的探索算法，针对各种转移类型进行测试，以确定那些积极影响在线

    arXiv:2404.02235v1 Announce Type: cross  Abstract: In deep reinforcement learning (RL) research, there has been a concerted effort to design more efficient and productive exploration methods while solving sparse-reward problems. These exploration methods often share common principles (e.g., improving diversity) and implementation details (e.g., intrinsic reward). Prior work found that non-stationary Markov decision processes (MDPs) require exploration to efficiently adapt to changes in the environment with online transfer learning. However, the relationship between specific exploration characteristics and effective transfer learning in deep RL has not been characterized. In this work, we seek to understand the relationships between salient exploration characteristics and improved performance and efficiency in transfer learning. We test eleven popular exploration algorithms on a variety of transfer types -- or ``novelties'' -- to identify the characteristics that positively affect onlin
    
[^90]: OOSTraj：利用视觉定位去噪的视界轨迹预测

    OOSTraj: Out-of-Sight Trajectory Prediction With Vision-Positioning Denoising

    [https://arxiv.org/abs/2404.02227](https://arxiv.org/abs/2404.02227)

    提出了一种利用视觉定位技术进行视界轨迹预测的新方法，可以有效地解决视野外物体和传感器数据噪声的挑战，达到了最先进的性能。

    

    轨迹预测在计算机视觉和自动驾驶中是基础性的，特别是为了理解行人行为和实现积极决策。现有的方法往往假设精确完整的观测数据，忽视了与视野外物体和由于有限摄像头范围、物理障碍以及缺乏去噪传感器数据的真实数据相关的挑战。这样的偏见是关键的安全问题，因为这可能导致关键的非可见对象被忽略。为了弥补这一差距，我们提出了一种利用视觉定位技术进行视界轨迹预测的新方法。我们的方法以无监督方式去噪嘈杂的传感器观测，并将视野外物体的传感器轨迹精确映射到视觉轨迹中。这种方法在视野外轨迹预测方面展现了最先进的性能。

    arXiv:2404.02227v1 Announce Type: cross  Abstract: Trajectory prediction is fundamental in computer vision and autonomous driving, particularly for understanding pedestrian behavior and enabling proactive decision-making. Existing approaches in this field often assume precise and complete observational data, neglecting the challenges associated with out-of-view objects and the noise inherent in sensor data due to limited camera range, physical obstructions, and the absence of ground truth for denoised sensor data. Such oversights are critical safety concerns, as they can result in missing essential, non-visible objects. To bridge this gap, we present a novel method for out-of-sight trajectory prediction that leverages a vision-positioning technique. Our approach denoises noisy sensor observations in an unsupervised manner and precisely maps sensor-based trajectories of out-of-sight objects into visual trajectories. This method has demonstrated state-of-the-art performance in out-of-sig
    
[^91]: CHOSEN：用于多视角深度细化的对比假设选择

    CHOSEN: Contrastive Hypothesis Selection for Multi-View Depth Refinement

    [https://arxiv.org/abs/2404.02225](https://arxiv.org/abs/2404.02225)

    CHOSEN是一个用于多视角深度细化的对比假设选择框架，通过对比学习和精心设计的假设特征，能够在多视角立体匹配中实现较高质量的深度和法线精度。

    

    我们提出了CHOSEN，这是一个简单而灵活、强大且有效的多视角深度细化框架。它可以应用于任何现有的多视角立体匹配流程中，具有针对不同多视角采集系统（如相机相对定位和镜头）的直观泛化能力。给定初始深度估计，CHOSEN迭代地重新采样并选择最佳假设，并自动适应由采集系统确定的不同度量或固有尺度。我们方法的关键在于在适当的解决方案空间中应用对比学习以及精心设计的假设特征，基于这些特征，可以有效地区分正负假设。将CHOSEN集成到简单的基线多视角立体匹配流程中，在深度和法线精度方面提供了令人印象深刻的质量，与许多当前基于深度学习的多视角立体匹配流程相比有所提高。

    arXiv:2404.02225v1 Announce Type: cross  Abstract: We propose CHOSEN, a simple yet flexible, robust and effective multi-view depth refinement framework. It can be employed in any existing multi-view stereo pipeline, with straightforward generalization capability for different multi-view capture systems such as camera relative positioning and lenses. Given an initial depth estimation, CHOSEN iteratively re-samples and selects the best hypotheses, and automatically adapts to different metric or intrinsic scales determined by the capture system. The key to our approach is the application of contrastive learning in an appropriate solution space and a carefully designed hypothesis feature, based on which positive and negative hypotheses can be effectively distinguished. Integrated in a simple baseline multi-view stereo pipeline, CHOSEN delivers impressive quality in terms of depth and normal accuracy compared to many current deep learning based multi-view stereo pipelines.
    
[^92]: 探讨多层次的GPT生成的编程提示如何支持或使新手失望

    Exploring How Multiple Levels of GPT-Generated Programming Hints Support or Disappoint Novices

    [https://arxiv.org/abs/2404.02213](https://arxiv.org/abs/2404.02213)

    这项研究发现，向新手提供从一般自然语言指导到具体代码辅助等四个级别的提示，能更好地支持他们的问题解决和学习。

    

    最近的研究已经将大型语言模型(LLMs)整合到不同的教育背景中，包括提供自适应编程提示，这种反馈类型侧重于帮助学生在解决问题时前进。然而，大多数现有的基于LLM的提示系统仅限于一种提示类型。为了调查不同级别的提示是否以及如何支持学生的问题解决和学习，我们对12名新手进行了一项自述思考研究，使用了LLM Hint Factory，这是一个系统，提供四个级别的提示，从一般的自然语言指导到具体的代码辅助，格式和粒度各不相同。我们发现仅使用高级别的自然语言提示可能是无助的，甚至会误导，特别是在处理下一步或与语法相关的帮助请求时。添加低级别的提示，如带有行内注释的代码示例，可以更好地支持学生。这些发现为定制化未来的工作打开了大门。

    arXiv:2404.02213v1 Announce Type: cross  Abstract: Recent studies have integrated large language models (LLMs) into diverse educational contexts, including providing adaptive programming hints, a type of feedback focuses on helping students move forward during problem-solving. However, most existing LLM-based hint systems are limited to one single hint type. To investigate whether and how different levels of hints can support students' problem-solving and learning, we conducted a think-aloud study with 12 novices using the LLM Hint Factory, a system providing four levels of hints from general natural language guidance to concrete code assistance, varying in format and granularity. We discovered that high-level natural language hints alone can be helpless or even misleading, especially when addressing next-step or syntax-related help requests. Adding lower-level hints, like code examples with in-line comments, can better support students. The findings open up future work on customizing 
    
[^93]: 一个整体性极化指标以衡量在线性别歧视

    A Holistic Indicator of Polarization to Measure Online Sexism

    [https://arxiv.org/abs/2404.02205](https://arxiv.org/abs/2404.02205)

    该论文提出了一个可以提供综合性性别毒性指标的模型，有助于政策制定者、在线社区管理员和计算社会科学家更好地理解和管理在线性别歧视问题。

    

    arXiv:2404.02205v1 公告类型: 跨领域 摘要: 男权主义者和女权主义者在社交网络上的在线趋势需要一个整体性的衡量性别歧视水平的指标。这个指标对于政策制定者和在线社区的管理员（如subreddits）以及计算社会科学家至关重要，他们可以根据性别歧视程度修改管理策略，或者匹配和比较不同平台和社区上的时态性别歧视，以及推断社会科学见解。在本文中，我们建立了一个模型，可以提供一个可比较的针对男性、女性身份以及男性、女性个人的毒性整体指标。尽管先前的监督NLP方法需要在目标级别对有毒评论进行注释（例如注释特别针对女性有毒的评论）来检测针对性有毒评论，我们的指标利用监督式NLP来检测毒性的存在。

    arXiv:2404.02205v1 Announce Type: cross  Abstract: The online trend of the manosphere and feminist discourse on social networks requires a holistic measure of the level of sexism in an online community. This indicator is important for policymakers and moderators of online communities (e.g., subreddits) and computational social scientists, either to revise moderation strategies based on the degree of sexism or to match and compare the temporal sexism across different platforms and communities with real-time events and infer social scientific insights.   In this paper, we build a model that can provide a comparable holistic indicator of toxicity targeted toward male and female identity and male and female individuals. Despite previous supervised NLP methods that require annotation of toxic comments at the target level (e.g. annotating comments that are specifically toxic toward women) to detect targeted toxic comments, our indicator uses supervised NLP to detect the presence of toxicity 
    
[^94]: 从之前未见的神经架构搜索数据集中获得的见解

    Insights from the Use of Previously Unseen Neural Architecture Search Datasets

    [https://arxiv.org/abs/2404.02189](https://arxiv.org/abs/2404.02189)

    提出了八个新的神经架构搜索数据集，旨在引起在NAS开发中的关注并鼓励作者考虑模型在开发时未知数据集上的表现。

    

    无限可能的神经网络可以用来解决问题，每个神经网络的性能不同，因此需要深度学习专家来确定最佳神经网络，这违背了消除专家需求的希望。神经架构搜索（NAS）通过自动识别最佳架构来解决这一问题。然而，迄今为止，NAS的工作集中在一小组数据集上，我们认为这些数据集并不能代表真实世界的问题。我们引入了八个新数据集，用于一系列NAS挑战：AddNIST，Language，MultNIST，CIFARTile，Gutenberg，Isabella，GeoClassing 和 Chesseract。这些数据集和挑战旨在引起NAS开发中的注意和鼓励作者考虑他们的模型在开发时未知数据集上的表现。我们展示了使用标准深度学习方法的实验。

    arXiv:2404.02189v1 Announce Type: cross  Abstract: The boundless possibility of neural networks which can be used to solve a problem -- each with different performance -- leads to a situation where a Deep Learning expert is required to identify the best neural network. This goes against the hope of removing the need for experts. Neural Architecture Search (NAS) offers a solution to this by automatically identifying the best architecture. However, to date, NAS work has focused on a small set of datasets which we argue are not representative of real-world problems. We introduce eight new datasets created for a series of NAS Challenges: AddNIST, Language, MultNIST, CIFARTile, Gutenberg, Isabella, GeoClassing, and Chesseract. These datasets and challenges are developed to direct attention to issues in NAS development and to encourage authors to consider how their models will perform on datasets unknown to them at development time. We present experimentation using standard Deep Learning met
    
[^95]: 采用生成式深度学习方法处理不平衡数据的事故严重性建模

    A Generative Deep Learning Approach for Crash Severity Modeling with Imbalanced Data

    [https://arxiv.org/abs/2404.02187](https://arxiv.org/abs/2404.02187)

    使用生成式深度学习方法处理事故严重性建模中的数据不平衡问题，解决传统和基于深度学习的数据重采样方法难以处理离散风险因素崩溃问题的挑战。

    

    撞车数据通常存在严重的不平衡性，大多数事故是非致命事故，只有少数是由于其罕见性而致命事故。这种数据不平衡问题对事故严重性建模构成挑战，因为它难以拟合和解释具有非常有限样本的致命事故结果。通常，通过数据重采样方法来解决这种数据不平衡问题，如欠采样和过采样技术。然而，大多数传统和基于深度学习的数据重采样方法，如合成少数过采样技术（SMOTE）和生成对抗网络（GAN），专门设计用于处理连续变量。尽管一些重采样方法已经改进以处理连续和离散变量，但它们在处理稀疏离散风险因素相关的崩溃问题上可能会遇到困难。此外，缺乏全面研究来比较...

    arXiv:2404.02187v1 Announce Type: cross  Abstract: Crash data is often greatly imbalanced, with the majority of crashes being non-fatal crashes, and only a small number being fatal crashes due to their rarity. Such data imbalance issue poses a challenge for crash severity modeling since it struggles to fit and interpret fatal crash outcomes with very limited samples. Usually, such data imbalance issues are addressed by data resampling methods, such as under-sampling and over-sampling techniques. However, most traditional and deep learning-based data resampling methods, such as synthetic minority oversampling technique (SMOTE) and generative Adversarial Networks (GAN) are designed dedicated to processing continuous variables. Though some resampling methods have improved to handle both continuous and discrete variables, they may have difficulties in dealing with the collapse issue associated with sparse discrete risk factors. Moreover, there is a lack of comprehensive studies that compar
    
[^96]: 自组织代理：面向超大规模代码生成和优化的LLM多代理框架

    Self-Organized Agents: A LLM Multi-Agent Framework toward Ultra Large-Scale Code Generation and Optimization

    [https://arxiv.org/abs/2404.02183](https://arxiv.org/abs/2404.02183)

    提出了自组织多代理框架（SoA），实现了大规模代码的可扩展高效生成和优化，代理可自主运作生成和修改代码组件，并根据问题复杂性动态增加数量。

    

    最近，在使用大型语言模型（LLM）代理进行自动代码生成方面取得了突破性进展，使我们更接近自动软件开发的未来。然而，现有的单代理方法在生成和改进大规模复杂代码库方面存在局限，这是由于上下文长度的限制所导致的。为了解决这一挑战，我们提出了自组织多代理框架（SoA），这是一种新颖的多代理框架，可以实现大规模代码的可扩展高效生成和优化。在SoA中，自组织代理独立运作，以生成和修改代码组件，同时无缝协作构建整体代码库。我们框架的一个关键特点是基于问题复杂性自动增加代理的数量，从而实现动态扩展性。这使得整体代码量可以根据代理数量无限增加，同时由每个代理管理的代码量也随之增加。

    arXiv:2404.02183v1 Announce Type: cross  Abstract: Recent advancements in automatic code generation using large language model (LLM) agent have brought us closer to the future of automated software development. However, existing single-agent approaches face limitations in generating and improving large-scale, complex codebases due to constraints in context length. To tackle this challenge, we propose Self-Organized multi-Agent framework (SoA), a novel multi-agent framework that enables the scalable and efficient generation and optimization of large-scale code. In SoA, self-organized agents operate independently to generate and modify code components while seamlessly collaborating to construct the overall codebase. A key feature of our framework is the automatic multiplication of agents based on problem complexity, allowing for dynamic scalability. This enables the overall code volume to be increased indefinitely according to the number of agents, while the amount of code managed by eac
    
[^97]: 利用机器学习通过INDT-ASD印度数据库早期检测自闭症

    Leveraging Machine Learning for Early Autism Detection via INDT-ASD Indian Database

    [https://arxiv.org/abs/2404.02181](https://arxiv.org/abs/2404.02181)

    本研究旨在通过利用机器学习开发一种简单、快速、廉价的技术，利用INDT-ASD印度数据库早期检测自闭症。

    

    机器学习（ML）在医疗领域发展迅速，神经发育问题的诊断是医疗领域的一个重要领域。自闭症谱系障碍（ASD）是全球增长最快的发展性障碍之一。临床筛查测试用于识别自闭症症状昂贵且耗时。但现在随着ML的进展，早期识别自闭症变得可行。先前进行过许多不同技术的探索，但在利用经过临床验证的印度ASD数据库预测自闭症特征的能力方面，没有一个产生预期结果。因此，本研究旨在通过使用ML开发一种简单、快速、廉价的技术来识别ASD。采用了多种机器学习分类器，包括Adaboost（AB）、Gradient Boost（GB）、决策树（DT）、逻辑回归

    arXiv:2404.02181v1 Announce Type: cross  Abstract: Machine learning (ML) has advanced quickly, particularly throughout the area of health care. The diagnosis of neurodevelopment problems using ML is a very important area of healthcare. Autism spectrum disorder (ASD) is one of the developmental disorders that is growing the fastest globally. The clinical screening tests used to identify autistic symptoms are expensive and time-consuming. But now that ML has been advanced, it's feasible to identify autism early on. Previously, many different techniques have been used in investigations. Still, none of them have produced the anticipated outcomes when it comes to the capacity to predict autistic features utilizing a clinically validated Indian ASD database. Therefore, this study aimed to develop a simple, quick, and inexpensive technique for identifying ASD by using ML. Various machine learning classifiers, including Adaboost (AB), Gradient Boost (GB), Decision Tree (DT), Logistic Regressio
    
[^98]: 通过堆叠自动编码器和聚类实现地质制图的遥感框架

    Remote sensing framework for geological mapping via stacked autoencoders and clustering

    [https://arxiv.org/abs/2404.02180](https://arxiv.org/abs/2404.02180)

    通过堆叠自动编码器和聚类实现遥感数据地质制图的无监督机器学习框架

    

    有监督学习方法在遥感地质制图中面临着由于准确标记训练数据的稀缺性而限制的问题。相反，无监督学习方法，如降维和聚类，能够在不依赖预定义标签的情况下揭示遥感数据中的模式和结构。降维方法具有在提高地质图准确性方面发挥关键作用的潜力。虽然传统的降维方法可能在非线性数据上遇到困难，但无监督深度学习模型，如自动编码器，能够模拟数据中的非线性关系。堆叠自动编码器具有多个相互连接的层，用于捕获对遥感数据有用的分层数据表示。在本研究中，我们提出了一个利用堆叠自动编码器和聚类处理遥感数据的无监督机器学习框架。

    arXiv:2404.02180v1 Announce Type: cross  Abstract: Supervised learning methods for geological mapping via remote sensing face limitations due to the scarcity of accurately labelled training data. In contrast, unsupervised learning methods, such as dimensionality reduction and clustering have the ability to uncover patterns and structures in remote sensing data without relying on predefined labels. Dimensionality reduction methods have the potential to play a crucial role in improving the accuracy of geological maps. Although conventional dimensionality reduction methods may struggle with nonlinear data, unsupervised deep learning models such as autoencoders have the ability to model nonlinear relationship in data. Stacked autoencoders feature multiple interconnected layers to capture hierarchical data representations that can be useful for remote sensing data. In this study, we present an unsupervised machine learning framework for processing remote sensing data by utilizing stacked au
    
[^99]: 分布式和速率自适应特征压缩

    Distributed and Rate-Adaptive Feature Compression

    [https://arxiv.org/abs/2404.02179](https://arxiv.org/abs/2404.02179)

    设计一种适应不断变化的通信约束的特征压缩方案，同时最大化融合中心的推断性能。

    

    我们研究了分布式和速率自适应特征压缩问题，针对线性回归。一组分布式传感器收集回归器数据的不相交特征。假定融合中心包含一个在整个未压缩数据集上训练的预训练线性回归模型。在推断时，传感器压缩其观测结果，并通过通信受限的信道将其发送到融合中心，这些信道的速率可以随时间变化。我们的目标是设计一种能够适应不断变化的通信约束的特征压缩方案，同时在融合中心最大化推断性能。我们首先获得了假定了对底层回归器数据分布知识的最优量化器的形式。在一个实际合理的近似下，我们提出了一种通过对传感器数据的一维投影进行量化工作的分布式压缩方案。

    arXiv:2404.02179v1 Announce Type: cross  Abstract: We study the problem of distributed and rate-adaptive feature compression for linear regression. A set of distributed sensors collect disjoint features of regressor data. A fusion center is assumed to contain a pretrained linear regression model, trained on a dataset of the entire uncompressed data. At inference time, the sensors compress their observations and send them to the fusion center through communication-constrained channels, whose rates can change with time. Our goal is to design a feature compression {scheme} that can adapt to the varying communication constraints, while maximizing the inference performance at the fusion center. We first obtain the form of optimal quantizers assuming knowledge of underlying regressor data distribution. Under a practically reasonable approximation, we then propose a distributed compression scheme which works by quantizing a one-dimensional projection of the sensor data. We also propose a simp
    
[^100]: 通过价值引导扩散策略实现部分可观察性下的多功能导航

    Versatile Navigation under Partial Observability via Value-guided Diffusion Policy

    [https://arxiv.org/abs/2404.02176](https://arxiv.org/abs/2404.02176)

    提出一种适用于部分可观察性下的多功能扩散方法，通过价值引导扩散策略实现2D和3D路线规划，提供充分远见并指导代理的探索和目标寻找行为，无需专家干预

    

    在现代机器人技术和自动驾驶中，针对部分可观察性下的导航路线规划起着至关重要的作用。现有的路线规划方法可分为传统自回归和基于扩散的两个主要类别。前者常常由于其近视特性而失败，而后者要么假设完全可观察性，要么在与来自专家的行为克隆的强耦合下难以适应陌生情形。为了解决这些缺陷，我们提出了一种适用于部分可观察性下的2D和3D路线规划的多功能扩散方法。具体而言，我们的价值引导扩散策略首先生成计划以预测各个时间步的动作，为规划提供充分的远见。然后，它利用具有状态估计的可微分规划器得出值函数，指导代理的探索和寻找目标的行为，而无需寻求专家的帮助。

    arXiv:2404.02176v1 Announce Type: cross  Abstract: Route planning for navigation under partial observability plays a crucial role in modern robotics and autonomous driving. Existing route planning approaches can be categorized into two main classes: traditional autoregressive and diffusion-based methods. The former often fails due to its myopic nature, while the latter either assumes full observability or struggles to adapt to unfamiliar scenarios, due to strong couplings with behavior cloning from experts. To address these deficiencies, we propose a versatile diffusion-based approach for both 2D and 3D route planning under partial observability. Specifically, our value-guided diffusion policy first generates plans to predict actions across various timesteps, providing ample foresight to the planning. It then employs a differentiable planner with state estimations to derive a value function, directing the agent's exploration and goal-seeking behaviors without seeking experts while expl
    
[^101]: 诚实的PinFi系统中块奖励的边界

    Bounds of Block Rewards in Honest PinFi Systems

    [https://arxiv.org/abs/2404.02174](https://arxiv.org/abs/2404.02174)

    通过博弈论方法探讨PinFi机制及其更广泛影响，研究发现PinFi能够在LPs、卖家和买家之间建立动态均衡。

    

    PinFi是一类新型的协议，用于去中心化定价逐渐贬值的资产，其价值随着时间自然下降。流动性提供者（LPs）在协议功能和市场效率中起着核心作用。本研究解决了协议中的关键稳定性和可持续性挑战，即LPs更倾向于在外部市场出售而非参与协议；在PinFi系统内出售而非作为LPs进行贡献；以及LPs不愿在协议内出售的场景。我们采用博弈论方法探讨PinFi的机制及其更广泛的影响。研究发现，在各种常见条件下，并且假设参与者诚实，PinFi能够在LPs、卖家和买家之间建立动态均衡。这种平衡是通过精心校准的奖励机制来维持的。

    arXiv:2404.02174v1 Announce Type: cross  Abstract: PinFi is a class of novel protocols for decentralized pricing of dissipative assets, whose value naturally declines over time. Central to the protocol's functionality and its market efficiency is the role of liquidity providers (LPs). This study addresses critical stability and sustainability challenges within the protocol, namely: the propensity of LPs to prefer selling in external markets over participation in the protocol; a similar inclination towards selling within the PinFi system rather than contributing as LPs; and a scenario where LPs are disinclined to sell within the protocol. Employing a game-theoretic approach, we explore PinFi's mechanisms and its broader ramifications. Our findings reveal that, under a variety of common conditions and with an assumption of participant integrity, PinFi is capable of fostering a dynamic equilibrium among LPs, sellers, and buyers. This balance is maintained through a carefully calibrated ra
    
[^102]: RAVE: CLIP引导的残差向量嵌入用于背光图像增强

    RAVE: Residual Vector Embedding for CLIP-Guided Backlit Image Enhancement

    [https://arxiv.org/abs/2404.01889](https://arxiv.org/abs/2404.01889)

    该论文提出了一种用于背光图像增强的CLIP引导方法RAVE，通过残差向量嵌入和提示调整的新颖方法，加快了训练并提高了质量。

    

    在本文中，我们提出了一种对反差异式语言-图像预训练（CLIP）指导进行了新颖修改的方法，用于无监督背光图像增强任务。我们的工作建立在最先进的CLIP-LIT方法基础之上，该方法通过约束在CLIP嵌入空间中一个提示对之间的文本-图像相似性来学习一个提示对（负/正样本）和相应图像（背光图像/光照良好的图像）。学习的提示然后指导图像增强网络。基于CLIP-LIT框架，我们提出了两种CLIP引导的新方法。首先，我们展示了在文本嵌入空间调整提示而不损失质量的可能性，从而可以直接在潜在空间中调整它们的嵌入，加快训练并潜在地实现使用没有文本编码器的其他编码器。其次，我们提出了一种不需要任何提示调整的新方法。

    arXiv:2404.01889v1 Announce Type: cross  Abstract: In this paper we propose a novel modification of Contrastive Language-Image Pre-Training (CLIP) guidance for the task of unsupervised backlit image enhancement. Our work builds on the state-of-the-art CLIP-LIT approach, which learns a prompt pair by constraining the text-image similarity between a prompt (negative/positive sample) and a corresponding image (backlit image/well-lit image) in the CLIP embedding space. Learned prompts then guide an image enhancement network. Based on the CLIP-LIT framework, we propose two novel methods for CLIP guidance. First, we show that instead of tuning prompts in the space of text embeddings, it is possible to directly tune their embeddings in the latent space without any loss in quality. This accelerates training and potentially enables the use of additional encoders that do not have a text encoder. Second, we propose a novel approach that does not require any prompt tuning. Instead, based on CLIP e
    
[^103]: 通过归结反驳实现自然语言通用且可靠的逻辑推理

    Towards Generalizable and Faithful Logic Reasoning over Natural Language via Resolution Refutation

    [https://arxiv.org/abs/2404.01677](https://arxiv.org/abs/2404.01677)

    通过引入归结反驳范式，提出了一个名为GFaiR的框架，旨在解决大型语言模型在进行自然语言形式逻辑理论一阶逻辑推理时的困难，并通过证明插入解决方案改进了系统的完整性

    

    大型语言模型在各种自然语言推理任务中取得了显著的性能，但它们在对自然语言表达的形式逻辑理论进行一阶逻辑推理方面仍然有困难。为了解决这一问题，我们提出了一个名为“可泛化且可靠推理器（GFaiR）”的新框架，引入了归结反驳范式。实验结果表明，我们的系统...

    arXiv:2404.01677v1 Announce Type: new  Abstract: Large language models (LLMs) have achieved significant performance in various natural language reasoning tasks. However, they still struggle with performing first-order logic reasoning over formal logical theories expressed in natural language. This is because the previous LLMs-based reasoning systems have the theoretical incompleteness issue. As a result, it can only address a limited set of simple reasoning problems, which significantly decreases their generalization ability. To address this issue, we propose a novel framework, named Generalizable and Faithful Reasoner (GFaiR), which introduces the paradigm of resolution refutation. Resolution refutation has the capability to solve all first-order logic reasoning problems by extending reasoning rules and employing the principle of proof by contradiction, so our system's completeness can be improved by introducing resolution refutation. Experimental results demonstrate that our system o
    
[^104]: 大型语言模型上的指令驱动游戏引擎

    Instruction-Driven Game Engines on Large Language Models

    [https://arxiv.org/abs/2404.00276](https://arxiv.org/abs/2404.00276)

    通过在大型语言模型上开发指令驱动游戏引擎，使用户可以通过简单的自然语言指令创建游戏，从而降低游戏开发的难度。

    

    Instruction-Driven Game Engine (IDGE) 项目旨在通过使大型语言模型（LLM）遵循自由形式的游戏规则并自动生成游戏过程来使游戏开发民主化。IDGE允许用户通过发出简单的自然语言指令来创建游戏，从而显著降低了游戏开发的障碍。我们将IDGE的学习过程视为下一个状态预测任务，模型自回归地预测玩家行动给出的游戏状态。这是一个具有挑战性的任务，因为游戏状态的计算必须准确；否则，轻微的错误可能会破坏游戏过程。为了解决这个问题，我们以课程方式训练IDGE，逐渐增加模型对复杂场景的接触。

    arXiv:2404.00276v1 Announce Type: new  Abstract: The Instruction-Driven Game Engine (IDGE) project aims to democratize game development by enabling a large language model (LLM) to follow free-form game rules and autonomously generate game-play processes. The IDGE allows users to create games by issuing simple natural language instructions, which significantly lowers the barrier for game development. We approach the learning process for IDGEs as a Next State Prediction task, wherein the model autoregressively predicts in-game states given player actions. It is a challenging task because the computation of in-game states must be precise; otherwise, slight errors could disrupt the game-play. To address this, we train the IDGE in a curriculum manner that progressively increases the model's exposure to complex scenarios.   Our initial progress lies in developing an IDGE for Poker, a universally cherished card game. The engine we've designed not only supports a wide range of poker variants b
    
[^105]: InfLoRA：无干扰的低秩自适应持续学习方法

    InfLoRA: Interference-Free Low-Rank Adaptation for Continual Learning

    [https://arxiv.org/abs/2404.00228](https://arxiv.org/abs/2404.00228)

    InfLoRA提出了一种新的PEFT方法，名为无干扰低秩自适应（InfLoRA），用于持续学习，旨在消除新任务对旧任务的干扰，帮助模型在稳定性和可塑性之间取得良好平衡。

    

    持续学习要求模型依次学习多个任务。在持续学习中，模型应具备在旧任务上维持性能（稳定性）和不断适应新任务的能力（可塑性）。最近，基于参数高效微调（PEFT）的持续学习方法变得越来越受欢迎。尽管现有基于PEFT的持续学习方法表现出比非PEFT方法更优秀的性能，但大多数方法并未考虑如何消除新任务对旧任务的干扰，从而阻碍模型在稳定性和可塑性之间取得良好平衡。本文提出了一种新的PEFT方法，称为无干扰低秩自适应（InfLoRA）方法，用于持续学习。

    arXiv:2404.00228v1 Announce Type: cross  Abstract: Continual learning requires the model to learn multiple tasks sequentially. In continual learning, the model should possess the ability to maintain its performance on old tasks (stability) and the ability to adapt to new tasks continuously (plasticity). Recently, parameter-efficient fine-tuning (PEFT), which involves freezing a pre-trained model and injecting a small number of learnable parameters to adapt to downstream tasks, has gained increasing popularity in continual learning. Although existing continual learning methods based on PEFT have demonstrated superior performance compared to those not based on PEFT, most of them do not consider how to eliminate the interference of the new task on the old tasks, which inhibits the model from making a good trade-off between stability and plasticity. In this work, we propose a new PEFT method, called interference-free low-rank adaptation (InfLoRA), for continual learning. InfLoRA injects a 
    
[^106]: 发挥大型语言模型在数据科学中预测表格任务的潜力

    Unleashing the Potential of Large Language Models for Predictive Tabular Tasks in Data Science

    [https://arxiv.org/abs/2403.20208](https://arxiv.org/abs/2403.20208)

    本研究旨在利用大型语言模型解决数据科学中表格数据预测任务，通过在丰富的数据集上训练Llama-2模型并进行实际应用，取得显著的改进。

    

    在数据科学领域，分类、回归和缺失值填充等预测任务是与表格数据相关的常见挑战。这项研究旨在应用大型语言模型(LLMs)来解决这些预测任务。尽管LLMs擅长理解自然语言，但在处理结构化表格数据方面表现不佳。我们的研究旨在通过收集带有指令注释的表格语料库，并在这一丰富的数据集上对Llama-2进行大规模训练，以弥合这一差距。此外，我们研究了将训练模型应用于零-shot预测、少-shot预测和上下文学习场景的实际应用。通过广泛实验，我们的方法论显示了显著的改进。

    arXiv:2403.20208v1 Announce Type: new  Abstract: In the domain of data science, the predictive tasks of classification, regression, and imputation of missing values are commonly encountered challenges associated with tabular data. This research endeavors to apply Large Language Models (LLMs) towards addressing these predictive tasks. Despite their proficiency in comprehending natural language, LLMs fall short in dealing with structured tabular data. This limitation stems from their lacking exposure to the intricacies of tabular data during their foundational training. Our research aims to mitigate this gap by compiling a comprehensive corpus of tables annotated with instructions and executing large-scale training of Llama-2 on this enriched dataset. Furthermore, we investigate the practical application of applying the trained model to zero-shot prediction, few-shot prediction, and in-context learning scenarios. Through extensive experiments, our methodology has shown significant improv
    
[^107]: 合成图像在迁移学习中有用吗？关于数据生成、数量和利用的调查

    Is Synthetic Image Useful for Transfer Learning? An Investigation into Data Generation, Volume, and Utilization

    [https://arxiv.org/abs/2403.19866](https://arxiv.org/abs/2403.19866)

    研究探讨了从文本到图像生成模型中生成和利用合成图像在迁移学习中的作用，提出了桥接迁移的两阶段框架以解决合成图像与真实图像之间的分布差异。

    

    合成图像数据生成代表了训练深度学习模型的一个有前景的途径，特别是在迁移学习领域，因为在特定领域获取真实图像可能会由于隐私和知识产权考虑而变得代价高昂。本研究深入探讨了从文本到图像生成模型中获取的合成图像的生成和利用，以促进迁移学习范式。尽管生成的图像具有高度的视觉逼真度，但我们观察到，将这些图像天真地纳入现有的真实图像数据集并不能始终提升模型性能，这是由于合成图像和真实图像之间固有的分布差异所致。为了解决这个问题，我们引入了一种名为“桥接迁移”的新颖的两阶段框架，该框架首先利用合成图像对预训练模型进行微调以提高其可迁移性，随后使用真实数据进行快速适应。

    arXiv:2403.19866v1 Announce Type: cross  Abstract: Synthetic image data generation represents a promising avenue for training deep learning models, particularly in the realm of transfer learning, where obtaining real images within a specific domain can be prohibitively expensive due to privacy and intellectual property considerations. This work delves into the generation and utilization of synthetic images derived from text-to-image generative models in facilitating transfer learning paradigms. Despite the high visual fidelity of the generated images, we observe that their naive incorporation into existing real-image datasets does not consistently enhance model performance due to the inherent distribution gap between synthetic and real images. To address this issue, we introduce a novel two-stage framework called bridged transfer, which initially employs synthetic images for fine-tuning a pre-trained model to improve its transferability and subsequently uses real data for rapid adaptat
    
[^108]: Gegenbauer图神经网络用于时变信号重构

    Gegenbauer Graph Neural Networks for Time-varying Signal Reconstruction

    [https://arxiv.org/abs/2403.19800](https://arxiv.org/abs/2403.19800)

    提出了一种新颖的Gegenbauer-based graph convolutional (GegenConv)算子，用于提高时变信号重构的准确性

    

    重构时变图信号（或图时间序列插补）是机器学习和信号处理中的一个关键问题，具有广泛的应用，从传感器网络中的缺失数据插补到时间序列预测。准确捕捉这些信号固有的时空信息对于有效解决这些任务至关重要。然而，现有方法依赖于时间差的平滑性假设和简单的凸优化技术，存在固有限制。为了解决这些挑战，我们提出了一种结合学习模块以增强下游任务准确性的新方法。为此，我们引入基于Gegenbauer多项式理论的Gegenbauer-based graph convolutional（GegenConv）算子，这是传统切比雪夫图卷积的推 generalization。

    arXiv:2403.19800v1 Announce Type: cross  Abstract: Reconstructing time-varying graph signals (or graph time-series imputation) is a critical problem in machine learning and signal processing with broad applications, ranging from missing data imputation in sensor networks to time-series forecasting. Accurately capturing the spatio-temporal information inherent in these signals is crucial for effectively addressing these tasks. However, existing approaches relying on smoothness assumptions of temporal differences and simple convex optimization techniques have inherent limitations. To address these challenges, we propose a novel approach that incorporates a learning module to enhance the accuracy of the downstream task. To this end, we introduce the Gegenbauer-based graph convolutional (GegenConv) operator, which is a generalization of the conventional Chebyshev graph convolution by leveraging the theory of Gegenbauer polynomials. By deviating from traditional convex problems, we expand t
    
[^109]: 理解人类反馈对齐学习动态的研究

    Understanding the Learning Dynamics of Alignment with Human Feedback

    [https://arxiv.org/abs/2403.18742](https://arxiv.org/abs/2403.18742)

    本研究对人类偏好对齐的学习动态进行了理论分析，显示了偏好数据集的分布如何影响模型更新速度，并提供了对训练准确度的严格保证，同时揭示了优化易于优先考虑高偏好可区分性行为的复杂现象。

    

    大型语言模型（LLMs）与人类意图对齐已成为安全部署模型在实际系统中的关键任务。现有的对齐方法虽然在经验上取得了成功，但理论上了解这些方法如何影响模型行为仍然是一个悬而未决的问题。我们的工作首次尝试在理论上分析人类偏好对齐的学习动态。我们正式展示了偏好数据集的分布如何影响模型更新速度，并对训练准确度提供了严格的保证。我们的理论还揭示了一个复杂现象，即优化易于优先考虑具有更高偏好可区分性的行为。我们在当代LLMs和对齐任务上在实证上验证了我们的发现，强化了我们的理论见解，并为未来的对齐方法提供了启示。免责声明：本文包含有效

    arXiv:2403.18742v1 Announce Type: cross  Abstract: Aligning large language models (LLMs) with human intentions has become a critical task for safely deploying models in real-world systems. While existing alignment approaches have seen empirical success, theoretically understanding how these methods affect model behavior remains an open question. Our work provides an initial attempt to theoretically analyze the learning dynamics of human preference alignment. We formally show how the distribution of preference datasets influences the rate of model updates and provide rigorous guarantees on the training accuracy. Our theory also reveals an intricate phenomenon where the optimization is prone to prioritizing certain behaviors with higher preference distinguishability. We empirically validate our findings on contemporary LLMs and alignment tasks, reinforcing our theoretical insights and shedding light on considerations for future alignment approaches. Disclaimer: This paper contains potent
    
[^110]: 一种具有项目特征的NFT可收藏品推荐系统

    A Recommender System for NFT Collectibles with Item Feature

    [https://arxiv.org/abs/2403.18305](https://arxiv.org/abs/2403.18305)

    该研究提出了一种针对NFT的推荐系统，综合利用NFT交易记录和外部项目特征等多种数据源，通过数据高效的基于图的方法生成个性化推荐，并利用超出用户-项目互动的输入验证了模型的有效性。

    

    推荐系统已被积极研究并应用于各个领域以解决信息过载问题。尽管有许多关于电影、音乐和电子商务的推荐系统的研究，但相比之下，尽管NFT市场持续增长，对于NFT的推荐系统却受到了相对较少的关注。本文提出了一种针对NFT的推荐系统，利用各种数据源，从NFT交易记录到外部项目特征，生成符合个人偏好的精确推荐。我们开发了一种数据高效的基于图的推荐系统，以有效捕捉每个项目与用户之间的复杂关系，并生成包含节点特征信息和图结构的节点（项目）嵌入。此外，我们利用超出用户-项目互动的输入，如图像特征、文本特征和价格特征。数值实验证实了该模型的性能。

    arXiv:2403.18305v1 Announce Type: cross  Abstract: Recommender systems have been actively studied and applied in various domains to deal with information overload. Although there are numerous studies on recommender systems for movies, music, and e-commerce, comparatively less attention has been paid to the recommender system for NFTs despite the continuous growth of the NFT market. This paper presents a recommender system for NFTs that utilizes a variety of data sources, from NFT transaction records to external item features, to generate precise recommendations that cater to individual preferences. We develop a data-efficient graph-based recommender system to efficiently capture the complex relationship between each item and users and generate node(item) embeddings which incorporate both node feature information and graph structure. Furthermore, we exploit inputs beyond user-item interactions, such as image feature, text feature, and price feature. Numerical experiments verify the perf
    
[^111]: 使用ChatGPT为电子学位论文指定LCSH主题的实验

    An Experiment with the Use of ChatGPT for LCSH Subject Assignment on Electronic Theses and Dissertations

    [https://arxiv.org/abs/2403.16424](https://arxiv.org/abs/2403.16424)

    该研究探讨了利用大型语言模型生成美国国会图书馆主题标头的潜力，展示了其对于解决学术图书馆待编目项目积压问题具有战略应对意义，同时也强调了人类编目员仍然在验证和增强生成主题标头方面的重要性。

    

    该研究探讨了利用大型语言模型（LLMs）生成美国国会图书馆主题标头（LCSH）的潜力。作者使用ChatGPT根据电子学位论文的标题和摘要生成主题标头。结果显示，尽管一些生成的主题标头是有效的，但存在特定性和详尽性方面的问题。该研究展示了LLMs可以作为学术图书馆待编目项目的战略性应对措施，同时也提供了一种成本效益高且快速生成LCSH的方法。然而，人类编目员仍然是验证和增强LLMs生成的LCSH的有效性、详尽性和特定性的必要条件。

    arXiv:2403.16424v1 Announce Type: new  Abstract: This study delves into the potential use of Large Language Models (LLMs) for generating Library of Congress Subject Headings (LCSH). The authors employed ChatGPT to generate subject headings for electronic theses and dissertations (ETDs) based on their titles and summaries. The results revealed that although some generated subject headings were valid, there were issues regarding specificity and exhaustiveness. The study showcases that LLMs can serve as a strategic response to the backlog of items awaiting cataloging in academic libraries, while also offering a cost-effective approach for promptly generating LCSH. Nonetheless, human catalogers remain essential for verifying and enhancing the validity, exhaustiveness, and specificity of LCSH generated by LLMs.
    
[^112]: 使用视觉评估GPT-4在胸部X光放射检查中的放射学发现检测

    Evaluating GPT-4 with Vision on Detection of Radiological Findings on Chest Radiographs

    [https://arxiv.org/abs/2403.15528](https://arxiv.org/abs/2403.15528)

    GPT-4V在胸部X光放射检查的放射学发现检测上尚未准备好应用于真实世界的诊断用途

    

    这项研究探讨了GPT-4V的应用，这是一个装备有视觉识别功能的多模态大型语言模型，用于检测来自100张胸部X光放射检查的放射学发现，并指出目前GPT-4V还不适用于解释胸部X光放射检查的实际诊断用途。

    arXiv:2403.15528v1 Announce Type: cross  Abstract: The study examines the application of GPT-4V, a multi-modal large language model equipped with visual recognition, in detecting radiological findings from a set of 100 chest radiographs and suggests that GPT-4V is currently not ready for real-world diagnostic usage in interpreting chest radiographs.
    
[^113]: 灰色信息神经网络用于时间序列预测

    Grey-informed neural network for time-series forecasting

    [https://arxiv.org/abs/2403.15027](https://arxiv.org/abs/2403.15027)

    本研究提出了灰色信息神经网络（GINN），通过遵循灰色系统的微分方程模型，提高了神经网络输出的可解释性，使其能够有效处理小数据样本，产生可靠的预测。

    

    神经网络模型在各个领域展现出了出色的性能，成功解决了复杂问题。然而，大多数模型被视为黑盒，需要大量数据进行开发。因此，在数据有限的情况下，由于缺乏透明度和数据稀缺性，构建适当的模型变得具有挑战性。为了解决这些挑战，本研究建议实施灰色信息神经网络（GINN）。GINN 确保神经网络的输出遵循灰色系统的微分方程模型，提高了可解释性。此外，结合灰色系统理论中的先验知识使传统神经网络能够有效处理小数据样本。我们提出的模型已被观察到能够揭示现实世界中的潜在模式，并基于经验数据产生可靠的预测。

    arXiv:2403.15027v1 Announce Type: cross  Abstract: Neural network models have shown outstanding performance and successful resolutions to complex problems in various fields. However, the majority of these models are viewed as black-box, requiring a significant amount of data for development. Consequently, in situations with limited data, constructing appropriate models becomes challenging due to the lack of transparency and scarcity of data. To tackle these challenges, this study suggests the implementation of a grey-informed neural network (GINN). The GINN ensures that the output of the neural network follows the differential equation model of the grey system, improving interpretability. Moreover, incorporating prior knowledge from grey system theory enables traditional neural networks to effectively handle small data samples. Our proposed model has been observed to uncover underlying patterns in the real world and produce reliable forecasts based on empirical data.
    
[^114]: 使用StateFlow增强LLM任务解决能力通过状态驱动工作流

    StateFlow: Enhancing LLM Task-Solving through State-Driven Workflows

    [https://arxiv.org/abs/2403.11322](https://arxiv.org/abs/2403.11322)

    提出了一种使用StateFlow的新颖LLM任务解决范式，将复杂任务解决过程概念化为状态机，通过状态转换确保LLM响应的清晰跟踪和管理。

    

    使用大型语言模型（LLM）来解决复杂任务的趋势日益明显，例如需要一系列操作和与工具环境动态交互的任务。本文提出了StateFlow，一种新颖的基于LLM的任务求解范式，将由LLM支持的复杂任务解决过程概念化为状态机。通过正确构建状态和定义状态转换，StateFlow确定了任务求解的进展，确保清晰跟踪和管理LLM在整个任务求解过程中的响应。在每个状态中，StateFlow允许执行一系列动作，不仅包括根据特定提示指导生成LLM响应，还包括根据需要利用外部工具。状态转换由LLM做出的特定规则或决策控制，允许通过任务的预定义StateFlow模型动态自适应地进行进展。

    arXiv:2403.11322v1 Announce Type: cross  Abstract: It is a notable trend to use Large Language Models (LLMs) to tackle complex tasks, e.g., tasks that require a sequence of actions and dynamic interaction with tools and environments. In this paper, we propose StateFlow, a novel LLM-based task-solving paradigm that conceptualizes complex task-solving processes backed by LLMs as state machines. With proper construction of states and definition of state transitions, StateFlow grounds the progress of task-solving, ensuring clear tracking and management of LLMs' responses throughout the task-solving process. Within each state, StateFlow allows execution of a series of actions, involving not only the generation of LLM's responses guided by a specific prompt, but also the utilization of external tools as needed. State transitions are controlled by specific rules or decisions made by the LLM, allowing for a dynamic and adaptive progression through the task's pre-defined StateFlow model. Evalua
    
[^115]: 长期帧事件视觉跟踪：基准数据集与基准线

    Long-term Frame-Event Visual Tracking: Benchmark Dataset and Baseline

    [https://arxiv.org/abs/2403.05839](https://arxiv.org/abs/2403.05839)

    提出了一个新的长期和大规模的帧事件单目标跟踪数据集FELT，重新训练和评估了15个基准跟踪器，并引入了关联记忆Transformer网络来解决RGB帧和事件流不完整的问题。

    

    当前基于事件/帧事件的跟踪器在短期跟踪数据集上进行评估，然而，对于真实场景的跟踪涉及长期跟踪，现有跟踪算法在这些场景中的性能仍不清楚。在本文中，我们首先提出了一个新的长期和大规模的帧事件单目标跟踪数据集，名为FELT。它包含742个视频和1,594,474个RGB帧和事件流对，并已成为迄今为止最大的帧事件跟踪数据集。我们重新训练和评估了15个基准跟踪器在我们的数据集上，以供未来研究进行比较。更重要的是，我们发现RGB帧和事件流由于挑战因素的影响和空间稀疏的事件流而自然不完整。针对这一问题，我们提出了一种新颖的关联记忆Transformer网络作为统一骨干，通过将现代Hopfield层引入多头自注意力块来进行处理。

    arXiv:2403.05839v1 Announce Type: cross  Abstract: Current event-/frame-event based trackers undergo evaluation on short-term tracking datasets, however, the tracking of real-world scenarios involves long-term tracking, and the performance of existing tracking algorithms in these scenarios remains unclear. In this paper, we first propose a new long-term and large-scale frame-event single object tracking dataset, termed FELT. It contains 742 videos and 1,594,474 RGB frames and event stream pairs and has become the largest frame-event tracking dataset to date. We re-train and evaluate 15 baseline trackers on our dataset for future works to compare. More importantly, we find that the RGB frames and event streams are naturally incomplete due to the influence of challenging factors and spatially sparse event flow. In response to this, we propose a novel associative memory Transformer network as a unified backbone by introducing modern Hopfield layers into multi-head self-attention blocks to
    
[^116]: 面向大型语言模型的隐私感知语义缓存

    Privacy-Aware Semantic Cache for Large Language Models

    [https://arxiv.org/abs/2403.02694](https://arxiv.org/abs/2403.02694)

    MeanCache是一种面向LLMs的语义缓存，能够识别语义上相似的查询，从而减少查询成本，服务提供商负载和环境影响。

    

    大型语言模型（LLMs）如ChatGPT、Google Bard、Claude和Llama 2彻底改变了自然语言处理和搜索引擎动态。然而，这些模型造成了异常高的计算成本。本文介绍了MeanCache，一种用于LLMs的语义缓存，它能够识别语义上相似的查询以确定缓存命中或未命中。

    arXiv:2403.02694v1 Announce Type: cross  Abstract: Large Language Models (LLMs) like ChatGPT, Google Bard, Claude, and Llama 2 have revolutionized natural language processing and search engine dynamics. However, these models incur exceptionally high computational costs. For instance, GPT-3 consists of 175 billion parameters and inference on these models also demands billions of floating-point operations. Caching is a natural solution to reduce LLM inference costs on repeated queries. However, existing caching methods are incapable of finding semantic similarities among LLM queries, leading to unacceptable false hit-and-miss rates.   This paper introduces MeanCache, a semantic cache for LLMs that identifies semantically similar queries to determine cache hit or miss. Using MeanCache, the response to a user's semantically similar query can be retrieved from a local cache rather than re-querying the LLM, thus reducing costs, service provider load, and environmental impact. MeanCache lever
    
[^117]: 通过最优输运实现全局和本地提示的合作，用于联邦学习

    Global and Local Prompts Cooperation via Optimal Transport for Federated Learning

    [https://arxiv.org/abs/2403.00041](https://arxiv.org/abs/2403.00041)

    提出了联邦提示合作 via Optimal Transport（FedOTP）方法，通过最优输运实现全局和本地提示的合作，针对数据异质性设计了高效的协作提示学习策略。

    

    预训练的视觉-语言模型中的提示学习在各种下游任务中表现出了卓越的灵活性。最近的研究尝试将这种强大的预训练模型整合到联邦学习框架中，以同时降低通信成本并促进对数据不足的局部训练。为了应对当前联邦提示学习方法在系统化解决严重的数据异质性方面的不足，即涉及标签和特征转移的数据分布，我们提出了通过最优输运实现联邦提示合作（FedOTP），它引入了高效的协作提示学习策略，以在每个客户端基础上捕捉不同的类别特征。具体而言，对于每个客户端，我们学习一个全局提示来提取客户端之间的共识知识，还学习一个本地提示来捕获特定客户端的特征。

    arXiv:2403.00041v1 Announce Type: cross  Abstract: Prompt learning in pretrained visual-language models has shown remarkable flexibility across various downstream tasks. Leveraging its inherent lightweight nature, recent research attempted to integrate the powerful pretrained models into federated learning frameworks to simultaneously reduce communication costs and promote local training on insufficient data. Despite these efforts, current federated prompt learning methods lack specialized designs to systematically address severe data heterogeneities, e.g., data distribution with both label and feature shifts involved. To address this challenge, we present Federated Prompts Cooperation via Optimal Transport (FedOTP), which introduces efficient collaborative prompt learning strategies to capture diverse category traits on a per-client basis. Specifically, for each client, we learn a global prompt to extract consensus knowledge among clients, and a local prompt to capture client-specific
    
[^118]: OSCaR:对象状态字幕和状态变化表示

    OSCaR: Object State Captioning and State Change Representation

    [https://arxiv.org/abs/2402.17128](https://arxiv.org/abs/2402.17128)

    本文介绍了一个新的数据集和基准OSCaR，旨在解决描述复杂视觉环境中对象状态变化的问题，为评估多模态大型语言提供了一个新的实验平台。

    

    arXiv:2402.17128v3 公告类型: 跨 面向人类在真实世界环境中的交互视角，智能模型推断和理解对象状态的变化能力是人工智能研究的一个重要且具有挑战性的方面。该任务涉及描述复杂的视觉环境，识别活跃对象，以及通过语言解释它们的变化。传统方法将对象字幕和状态变化检测进行隔离，提供了对动态环境的有限视图。此外，依赖于一小套符号化词汇来表示变化限制了语言的表达力。为了解决这些挑战，在本文中，我们介绍了对象状态字幕和状态变化表示（OSCaR）数据集和基准。OSCaR包括来自各种主观视角视频集合的14,084个带注释视频片段，涵盖近1,000个独特对象。它为评估多模态大型语言提供了一个新的实验平台。

    arXiv:2402.17128v3 Announce Type: cross  Abstract: The capability of intelligent models to extrapolate and comprehend changes in object states is a crucial yet demanding aspect of AI research, particularly through the lens of human interaction in real-world settings. This task involves describing complex visual environments, identifying active objects, and interpreting their changes as conveyed through language. Traditional methods, which isolate object captioning and state change detection, offer a limited view of dynamic environments. Moreover, relying on a small set of symbolic words to represent changes has restricted the expressiveness of the language. To address these challenges, in this paper, we introduce the Object State Captioning and State Change Representation (OSCaR) dataset and benchmark. OSCaR consists of 14,084 annotated video segments with nearly 1,000 unique objects from various egocentric video collections. It sets a new testbed for evaluating multimodal large langua
    
[^119]: Text2Pic Swift：增强大规模库中长文本到图像的检索

    Text2Pic Swift: Enhancing Long-Text to Image Retrieval for Large-Scale Libraries

    [https://arxiv.org/abs/2402.15276](https://arxiv.org/abs/2402.15276)

    Text2Pic Swift框架针对大规模库中文本描述到图像的检索提出了一种高效且强大的方法，通过两阶段策略解决了长文本查询中的歧义问题

    

    arXiv:2402.15276v1 公告类型：跨领域 摘要：文本到图像检索在各种应用中起着至关重要的作用，包括数字图书馆、电子商务平台和多媒体数据库，通过使用文本查询来搜索图像。尽管多模态大语言模型（MLLMs）取得了先进的性能，但它们在大规模、多样化和模糊的检索场景中的适用性受到显着的计算需求和生成可注入的嵌入所限制。本文介绍了Text2Pic Swift框架，专为在庞大的数据集中有效和稳健地检索与广泛文本描述对应的图像而设计。该框架采用了两阶段方法：初始基于实体的排序（ER）阶段通过多查询对多目标的策略来解决长文本查询中固有的歧义，从而有效地缩小了可能的候选项，以便进行后续分析。接下来

    arXiv:2402.15276v1 Announce Type: cross  Abstract: Text-to-image retrieval plays a crucial role across various applications, including digital libraries, e-commerce platforms, and multimedia databases, by enabling the search for images using text queries. Despite the advancements in Multimodal Large Language Models (MLLMs), which offer leading-edge performance, their applicability in large-scale, varied, and ambiguous retrieval scenarios is constrained by significant computational demands and the generation of injective embeddings. This paper introduces the Text2Pic Swift framework, tailored for efficient and robust retrieval of images corresponding to extensive textual descriptions in sizable datasets. The framework employs a two-tier approach: the initial Entity-based Ranking (ER) stage addresses the ambiguity inherent in lengthy text queries through a multiple-queries-to-multiple-targets strategy, effectively narrowing down potential candidates for subsequent analysis. Following thi
    
[^120]: 为实现视觉地点识别的预训练模型的无缝适应

    Towards Seamless Adaptation of Pre-trained Models for Visual Place Recognition

    [https://arxiv.org/abs/2402.14505](https://arxiv.org/abs/2402.14505)

    提出了一种新颖的方法，实现了预训练模型对视觉地点识别的无缝适应

    

    最近的研究表明，在大规模数据上用通用的视觉学习任务预训练的视觉模型可以为各种视觉感知问题提供有用的特征表示。然而，很少有尝试利用在视觉地点识别（VPR）中利用预训练的基础模型。由于模型预训练和VPR任务之间在训练目标和数据方面的固有差异，如何弥合差距并充分发挥预训练模型在VPR中的能力仍然是一个关键问题。为此，我们提出了一种新颖的方法，实现了预训练模型对VPR的无缝适应。具体而言，我们设计了一种混合适应方法，以实现全局和局部适应，从而获得既关注显著地标用于区分地点的全局和局部特征。

    arXiv:2402.14505v1 Announce Type: cross  Abstract: Recent studies show that vision models pre-trained in generic visual learning tasks with large-scale data can provide useful feature representations for a wide range of visual perception problems. However, few attempts have been made to exploit pre-trained foundation models in visual place recognition (VPR). Due to the inherent difference in training objectives and data between the tasks of model pre-training and VPR, how to bridge the gap and fully unleash the capability of pre-trained models for VPR is still a key issue to address. To this end, we propose a novel method to realize seamless adaptation of pre-trained models for VPR. Specifically, to obtain both global and local features that focus on salient landmarks for discriminating places, we design a hybrid adaptation method to achieve both global and local adaptation efficiently, in which only lightweight adapters are tuned without adjusting the pre-trained model. Besides, to gu
    
[^121]: 模拟失调: 大型语言模型的安全对齐可能会适得其反！

    Emulated Disalignment: Safety Alignment for Large Language Models May Backfire!

    [https://arxiv.org/abs/2402.12343](https://arxiv.org/abs/2402.12343)

    安全对齐的大型语言模型可能会通过模拟失调框架，在对抗性操纵下产生危险结果，对训练的语言模型具有双倍有害性，高于强基线，强调了即使在安全对齐后也需要重新评估开源语言模型的重要性。

    

    大型语言模型（LLMs）需要进行安全对齐，以确保与人类进行安全的对话。然而，在这项工作中，我们引入了一种推理时攻击框架，表明安全对齐也可能在对抗性操纵下无意中促成有害结果。这个框架被命名为模拟失调（ED），在输出空间中不良地组合了一对开源预训练和安全对齐的语言模型，产生了一个有害的语言模型而无需任何训练。我们对ED在三个数据集和四个模型系列（Llama-1、Llama-2、Mistral和Alpaca）上的实验表明，ED使预训练模型的有害性增加了一倍，并胜过强基线，以较大优势在48个评估子集中的43个中实现了最高的有害率。至关重要的是，我们的研究结果凸显了即使在安全对齐后，重新评估开源语言模型实践的重要性。

    arXiv:2402.12343v1 Announce Type: new  Abstract: Large language models (LLMs) need to undergo safety alignment to ensure safe conversations with humans. However, in this work, we introduce an inference-time attack framework, demonstrating that safety alignment can also unintentionally facilitate harmful outcomes under adversarial manipulation. This framework, named Emulated Disalignment (ED), adversely combines a pair of open-source pre-trained and safety-aligned language models in the output space to produce a harmful language model without any training. Our experiments with ED across three datasets and four model families (Llama-1, Llama-2, Mistral, and Alpaca) show that ED doubles the harmfulness of pre-trained models and outperforms strong baselines, achieving the highest harmful rate in 43 out of 48 evaluation subsets by a large margin. Crucially, our findings highlight the importance of reevaluating the practice of open-sourcing language models even after safety alignment.
    
[^122]: CodeMind:一个用于挑战大型语言模型进行代码推理的框架

    CodeMind: A Framework to Challenge Large Language Models for Code Reasoning

    [https://arxiv.org/abs/2402.09664](https://arxiv.org/abs/2402.09664)

    CodeMind是一个用于挑战大型语言模型进行代码推理的框架，通过评估LLMs的代码推理能力来替代仅仅依靠测试通过来评估，对三种代码推理任务进行评估，结果显示LLMs能够公正地理解控制流结构，并且对于简单程序和复杂程序，它们通常能够推理出输入如何演变为输出。

    

    仅靠测试通过来评估大型语言模型（LLMs）的代码合成能力可能会导致不公正的评估或促进具有数据泄漏的模型，作为一种替代方案，我们介绍了CodeMind，这是一个旨在评估LLMs的代码推理能力的框架。CodeMind目前支持三种代码推理任务：独立执行推理（IER）、依赖执行推理（DER）和规范推理（SR）。前两者评估模型以预测任意代码的执行输出，或者模型能够正确合成的代码。第三个任务评估LLMs实现指定预期行为的程度。我们使用CodeMind对两种不同编程语言中的五个基准下的九个LLMs进行了广泛的评估，结果表明LLMs能够公正地理解控制流结构，并且对于简单程序和复杂程序，它们通常能够推理出输入如何演变为输出。

    arXiv:2402.09664v1 Announce Type: cross  Abstract: Solely relying on test passing to evaluate Large Language Models (LLMs) for code synthesis may result in unfair assessment or promoting models with data leakage. As an alternative, we introduce CodeMind, a framework designed to gauge the code reasoning abilities of LLMs. CodeMind currently supports three code reasoning tasks: Independent Execution Reasoning (IER), Dependent Execution Reasoning (DER), and Specification Reasoning (SR). The first two evaluate models to predict the execution output of an arbitrary code or code the model could correctly synthesize. The third one evaluates the extent to which LLMs implement the specified expected behavior. Our extensive evaluation of nine LLMs across five benchmarks in two different programming languages using CodeMind shows that LLMs fairly understand control flow constructs and, in general, are capable of reasoning how inputs evolve to output, specifically for simple programs and the ones 
    
[^123]: 改进心肌梗死检测：一种新颖的多模态复合核策略在单一类别分类中的应用

    Refining Myocardial Infarction Detection: A Novel Multi-Modal Composite Kernel Strategy in One-Class Classification

    [https://arxiv.org/abs/2402.06530](https://arxiv.org/abs/2402.06530)

    本研究提出了一种新的方法，使用基于超声心动图的一种基于多模态复合核策略的单一类别分类算法来进行早期心肌梗死的检测。这种方法通过优化投影矩阵和特征转化，提高了心肌梗死检测的能力。

    

    早期心肌梗死（MI）的检测对于预防进一步心肌损伤非常重要，MI是由冠状动脉疾病（CAD）引起的一种严重疾病。本研究引入了一种新方法，使用一种基于超声心动图的单一类别分类（OCC）算法进行早期MI检测。我们的研究通过采用基于多模态子空间支持向量数据描述的新方法克服了超声心动图数据有限的挑战。提出的技术涉及一种特殊的MI检测框架，使用复合核在非线性投影技巧中融合高斯和拉普拉斯sigmoid函数，将多视图超声心动图结合起来。此外，我们通过在优化过程中调整投影矩阵的最大化策略，提高了投影矩阵更新策略的效果。我们的方法通过将从超声心动图数据中提取的特征有效地转化为优化的低维空间，增强了MI检测的能力。

    Early detection of myocardial infarction (MI), a critical condition arising from coronary artery disease (CAD), is vital to prevent further myocardial damage. This study introduces a novel method for early MI detection using a one-class classification (OCC) algorithm in echocardiography. Our study overcomes the challenge of limited echocardiography data availability by adopting a novel approach based on Multi-modal Subspace Support Vector Data Description. The proposed technique involves a specialized MI detection framework employing multi-view echocardiography incorporating a composite kernel in the non-linear projection trick, fusing Gaussian and Laplacian sigmoid functions. Additionally, we enhance the update strategy of the projection matrices by adapting maximization for both or one of the modalities in the optimization process. Our method boosts MI detection capability by efficiently transforming features extracted from echocardiography data into an optimized lower-dimensional su
    
[^124]: 逻辑规范引导下的强化学习智能体动态任务采样

    Logical Specifications-guided Dynamic Task Sampling for Reinforcement Learning Agents

    [https://arxiv.org/abs/2402.03678](https://arxiv.org/abs/2402.03678)

    本文提出了一种逻辑规范引导下的动态任务采样（LSTS）方法，通过学习一组强化学习策略，根据高级任务规范指导智能体在最小化环境交互次数的同时实现从初始状态到目标状态的引导。在网格世界实验中，LSTS实现了改进的时间到阈值。

    

    强化学习（RL）在使人工智能智能体学习多样化行为方面取得了重要进展。然而，学习有效的策略通常需要大量的环境交互。为了减少样本复杂性问题，最近的方法使用高级任务规范，如线性时态逻辑（LTL$_f$）公式或奖励机器（RM），来指导智能体的学习过程。在这项工作中，我们提出了一种新颖的方法，称为逻辑规范引导下的动态任务采样（LSTS），它通过学习一组强化学习策略，根据高级任务规范指导智能体从初始状态到目标状态，同时最小化环境交互次数。与以前的工作不同，LSTS不假设环境动力学或奖励机器的信息，并动态采样导致成功目标策略的有希望的任务。我们在一个网格世界上评估了LSTS，并展示了它实现了改进的时间到阈值。

    Reinforcement Learning (RL) has made significant strides in enabling artificial agents to learn diverse behaviors. However, learning an effective policy often requires a large number of environment interactions. To mitigate sample complexity issues, recent approaches have used high-level task specifications, such as Linear Temporal Logic (LTL$_f$) formulas or Reward Machines (RM), to guide the learning progress of the agent. In this work, we propose a novel approach, called Logical Specifications-guided Dynamic Task Sampling (LSTS), that learns a set of RL policies to guide an agent from an initial state to a goal state based on a high-level task specification, while minimizing the number of environmental interactions. Unlike previous work, LSTS does not assume information about the environment dynamics or the Reward Machine, and dynamically samples promising tasks that lead to successful goal policies. We evaluate LSTS on a gridworld and show that it achieves improved time-to-threshol
    
[^125]: 无限-gram：将无限n-gram语言模型扩展到万亿标记

    Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens

    [https://arxiv.org/abs/2401.17377](https://arxiv.org/abs/2401.17377)

    这项研究展示了n-gram语言模型的价值，并介绍了一个名为infini-gram的引擎，它可以以毫秒级的延迟计算任意n的n-gram概率，使得在神经大型语言模型中对文本进行更准确的分析成为可能。

    

    在神经大型语言模型（LLM）时代，n-gram语言模型还具有相关性吗？我们的答案是肯定的，并且我们展示了它们在文本分析和改进神经LLM方面的价值。然而，这需要在两个方面对n-gram模型进行现代化。首先，我们将它们与神经LLM相同的数据规模训练- 1.4万亿个标记。这是迄今为止构建的最大的n-gram模型。其次，现有的n-gram模型使用的n很小，这妨碍了它们的性能；相反，我们允许n可以是任意大的，通过引入一个新的无限-gram LM与回退。我们开发了一个名为infini-gram的引擎，它可以通过后缀数组计算无限-gram（以及任意n的n-gram）概率，并且具有毫秒级的延迟，而无需预先计算n-gram计数表（这将非常昂贵）。无限-gram框架和infini-gram引擎使我们能够对人类写作和机器生成的文本进行许多新颖和有意思的分析：我们发现无限-gram LM...

    Are n-gram language models still relevant in this era of neural large language models (LLMs)? Our answer is yes, and we show their values in both text analysis and improving neural LLMs. Yet this necessitates modernizing n-gram models in two aspects. First, we train them at the same data scale as neural LLMs -- 1.4 trillion tokens. This is the largest n-gram model ever built. Second, existing n-gram models use small n which hinders their performance; we instead allow n to be arbitrarily large, by introducing a new $\infty$-gram LM with backoff. Instead of pre-computing n-gram count tables (which would be very expensive), we develop an engine named infini-gram -- powered by suffix arrays -- that can compute $\infty$-gram (as well as n-gram with arbitrary n) probabilities with millisecond-level latency. The $\infty$-gram framework and infini-gram engine enable us to conduct many novel and interesting analyses of human-written and machine-generated text: we find that the $\infty$-gram LM 
    
[^126]: 不要轻信一切：通过自动识别大语言模型中的幻觉增强摘要解释性

    Don't Believe Everything You Read: Enhancing Summarization Interpretability through Automatic Identification of Hallucinations in Large Language Models

    [https://arxiv.org/abs/2312.14346](https://arxiv.org/abs/2312.14346)

    本文通过定义标记级别的方法来识别不同类型的幻觉，并利用这种标记来提高LLMs在对话摘要任务中的可解释性和忠实度。

    

    大语言模型（LLMs）擅长文本操纵——例如机器翻译和文本摘要。然而，这些模型也容易出现幻觉，这可能对模型提供的任何答案的忠实度造成负面影响。最近的作品致力于对抗LLMs中的幻觉，这些作品涉及识别虚构的句子以及对模型产生幻觉的不同方式进行分类。本文深入探讨了LLMs在幻觉方面的行为，定义了一种基于标记的方法来识别不同类型的幻觉，并进一步利用该标记来提高LLMs在对话摘要任务中的可解释性和忠实度。通过这一过程，本文提出了一个新的、增强的数据集和一个新的训练范式。

    arXiv:2312.14346v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) are adept at text manipulation -- tasks such as machine translation and text summarization. However, these models can also be prone to hallucination, which can be detrimental to the faithfulness of any answers that the model provides. Recent works in combating hallucinations in LLMs deal with identifying hallucinated sentences and categorizing the different ways in which models hallucinate. This paper takes a deep dive into LLM behavior with respect to hallucinations, defines a token-level approach to identifying different kinds of hallucinations, and further utilizes this token-level tagging to improve the interpretability and faithfulness of LLMs in dialogue summarization tasks. Through this, the paper presents a new, enhanced dataset and a new training paradigm.
    
[^127]: RadEdit：通过扩散图像编辑对生物医学视觉模型进行压力测试

    RadEdit: stress-testing biomedical vision models via diffusion image editing

    [https://arxiv.org/abs/2312.12865](https://arxiv.org/abs/2312.12865)

    该研究提出了一种名为RadEdit的新编辑方法，通过训练文本到图像扩散模型，在多个胸部X射线数据集上对生物医学视觉模型进行压力测试，从而模拟数据集转移，诊断失效模式，并确保编辑图像的一致性。

    

    生物医学成像数据集通常规模较小且存在偏见，这意味着预测模型的实际表现往往远低于内部测试所预期的水平。本研究提出使用生成图像编辑来模拟数据集转移，并诊断生物医学视觉模型的失效模式；这可以在部署前用于评估就绪性，可能减少成本和患者危害。现有的编辑方法可能会产生不良变化，由于疾病与治疗干预的共同出现而学到虚假相关性，从而限制了实际应用性。为解决这一问题，我们在多个胸部X射线数据集上训练了一个文本到图像扩散模型，并引入了一种名为RadEdit的新编辑方法，使用多个掩膜（如果存在）来约束更改，并确保编辑图像的一致性。我们考虑三种数据集转移类型：获取转移、表现转移和人口转移

    arXiv:2312.12865v3 Announce Type: replace-cross  Abstract: Biomedical imaging datasets are often small and biased, meaning that real-world performance of predictive models can be substantially lower than expected from internal testing. This work proposes using generative image editing to simulate dataset shifts and diagnose failure modes of biomedical vision models; this can be used in advance of deployment to assess readiness, potentially reducing cost and patient harm. Existing editing methods can produce undesirable changes, with spurious correlations learned due to the co-occurrence of disease and treatment interventions, limiting practical applicability. To address this, we train a text-to-image diffusion model on multiple chest X-ray datasets and introduce a new editing method RadEdit that uses multiple masks, if present, to constrain changes and ensure consistency in the edited images. We consider three types of dataset shifts: acquisition shift, manifestation shift, and populat
    
[^128]: Gemini：一系列高性能多模态模型

    Gemini: A Family of Highly Capable Multimodal Models

    [https://arxiv.org/abs/2312.11805](https://arxiv.org/abs/2312.11805)

    Gemini家族是一系列在图像、音频、视频和文本理解方面表现出色的多模态模型，其中最具能力的Gemini Ultra模型在30个基准测试中推进了技术前沿，并改进了所有20个多模态基准测试的技术状态。

    

    本报告介绍了一种新的多模态模型系列Gemini，展示出在图像、音频、视频和文本理解方面的显著能力。Gemini系列包括Ultra、Pro和Nano尺寸，适用于从复杂推理任务到设备内存受限应用的各种应用场景。在广泛的基准测试中，我们最具能力的Gemini Ultra模型在32个基准测试中的30个中推进了技术前沿 - 显著地是第一个在被广泛研究的考试基准测试MMLU上实现人类专家水平表现的模型，并在我们研究的每一个20个多模态基准测试中改进了技术前沿。我们相信Gemini系列在跨模态推理和语言理解方面的新能力将能够支持各种用例。我们讨论了负责任地向用户提供Gemini模型的训练后和部署方法，包括使用服务。

    arXiv:2312.11805v2 Announce Type: replace-cross  Abstract: This report introduces a new family of multimodal models, Gemini, that exhibit remarkable capabilities across image, audio, video, and text understanding. The Gemini family consists of Ultra, Pro, and Nano sizes, suitable for applications ranging from complex reasoning tasks to on-device memory-constrained use-cases. Evaluation on a broad range of benchmarks shows that our most-capable Gemini Ultra model advances the state of the art in 30 of 32 of these benchmarks - notably being the first model to achieve human-expert performance on the well-studied exam benchmark MMLU, and improving the state of the art in every one of the 20 multimodal benchmarks we examined. We believe that the new capabilities of the Gemini family in cross-modal reasoning and language understanding will enable a wide variety of use cases. We discuss our approach toward post-training and deploying Gemini models responsibly to users through services includi
    
[^129]: ReCoRe: 正则化对比度表示学习的世界模型

    ReCoRe: Regularized Contrastive Representation Learning of World Model

    [https://arxiv.org/abs/2312.09056](https://arxiv.org/abs/2312.09056)

    通过正则化对比度表示学习世界模型，该方法提高了样本效率和泛化性能，解决了在视觉导航等日常任务中出现外观变化时的挑战。

    

    近期的无模型强化学习（RL）方法在游戏环境中已经展示出与人类水平相当的有效性，但在视觉导航等日常任务中的成功受到限制，特别是在出现显著外观变化的情况下。为了解决这些挑战，我们提出了一种世界模型，通过（i）对比度无监督学习和（ii）介入不变正则化来学习不变特征。学习世界动力学的显式表示，即世界模型，提高了样本效率，而对比度学习隐含地强化了学习不变特征，改善了泛化性能。然而，简单地将对比度损失集成到世界模型中是不够的，因为基于世界模型的RL方法独立优化表示学习和智能体策略。

    arXiv:2312.09056v2 Announce Type: replace-cross  Abstract: While recent model-free Reinforcement Learning (RL) methods have demonstrated human-level effectiveness in gaming environments, their success in everyday tasks like visual navigation has been limited, particularly under significant appearance variations. This limitation arises from (i) poor sample efficiency and (ii) over-fitting to training scenarios. To address these challenges, we present a world model that learns invariant features using (i) contrastive unsupervised learning and (ii) an intervention-invariant regularizer. Learning an explicit representation of the world dynamics i.e. a world model, improves sample efficiency while contrastive learning implicitly enforces learning of invariant features, which improves generalization. However, the na\"ive integration of contrastive loss to world models is not good enough, as world-model-based RL methods independently optimize representation learning and agent policy. To overc
    
[^130]: Agent-OM：利用LLM代理进行本体匹配

    Agent-OM: Leveraging LLM Agents for Ontology Matching

    [https://arxiv.org/abs/2312.00326](https://arxiv.org/abs/2312.00326)

    本研究提出了Agent-OM，利用LLM代理为本体匹配系统引入了新的设计范式。

    

    本体匹配（OM）能够实现不同本体之间的语义互操作性，通过对齐相关实体来解决其概念异构性。本研究引入了一种新颖的基于代理的LLM设计范式，命名为Agent-OM，包括两个用于检索和匹配的同体代理以及一组基于提示的简单OM工具。

    arXiv:2312.00326v2 Announce Type: replace  Abstract: Ontology matching (OM) enables semantic interoperability between different ontologies and resolves their conceptual heterogeneity by aligning related entities. OM systems currently have two prevailing design paradigms: conventional knowledge-based expert systems and newer machine learning-based predictive systems. While large language models (LLMs) and LLM agents have revolutionised data engineering and have been applied creatively in many domains, their potential for OM remains underexplored. This study introduces a novel agent-powered LLM-based design paradigm for OM systems. With consideration of several specific challenges in leveraging LLM agents for OM, we propose a generic framework, namely Agent-OM, consisting of two Siamese agents for retrieval and matching, with a set of simple prompt-based OM tools. Our framework is implemented in a proof-of-concept system. Evaluations of three Ontology Alignment Evaluation Initiative (OAE
    
[^131]: 通过可学习区域进行文本驱动图像编辑

    Text-Driven Image Editing via Learnable Regions

    [https://arxiv.org/abs/2311.16432](https://arxiv.org/abs/2311.16432)

    该方法通过学习区域实现了文本驱动的图像编辑，无需用户提供遮罩或草图，具有灵活性和能够处理复杂提示的特点。与其他方法相比，展现了竞争性能。

    

    语言已经成为图像编辑的自然接口。本文介绍了一种基于区域的图像编辑方法，其由文本提示驱动，无需用户提供的遮罩或草图。具体来说，我们的方法利用现有的预训练文本到图像模型，并引入一个边界框生成器来识别与文本提示对齐的编辑区域。我们展示了这种简单方法可以实现与当前图像生成模型兼容的灵活编辑，并且能够处理包含多个对象、复杂句子或较长段落的复杂提示。我们进行了广泛的用户研究，将我们的方法与最先进的方法进行了比较。实验表明，我们的方法在与提供的语言描述相对应的具有高保真度和逼真度的图像操作方面表现出竞争力。我们的项目网页可以在此找到：ht

    arXiv:2311.16432v2 Announce Type: replace-cross  Abstract: Language has emerged as a natural interface for image editing. In this paper, we introduce a method for region-based image editing driven by textual prompts, without the need for user-provided masks or sketches. Specifically, our approach leverages an existing pre-trained text-to-image model and introduces a bounding box generator to identify the editing regions that are aligned with the textual prompts. We show that this simple approach enables flexible editing that is compatible with current image generation models, and is able to handle complex prompts featuring multiple objects, complex sentences, or lengthy paragraphs. We conduct an extensive user study to compare our method against state-of-the-art methods. The experiments demonstrate the competitive performance of our method in manipulating images with high fidelity and realism that correspond to the provided language descriptions. Our project webpage can be found at: ht
    
[^132]: 迈向负责任的生成式AI：基于基础模型设计代理的参考架构

    Towards Responsible Generative AI: A Reference Architecture for Designing Foundation Model based Agents

    [https://arxiv.org/abs/2311.13148](https://arxiv.org/abs/2311.13148)

    这篇论文提出了一种基于模式的参考架构，为设计基于基础模型代理时提供指导，强调了负责任AI和软件质量属性等方面的重要性。

    

    基础模型，如大型语言模型（LLM），由于其理解和生成内容的能力，包括具有推理能力的计划，已被广泛认可为具有变革性的AI技术。基于基础模型的代理从基础模型的能力中获得自主性，这使它们能够自主将给定的目标分解为一组可管理的任务，并编排任务执行以实现目标。尽管在构建基于基础模型的代理方面付出了巨大努力，但代理的体系结构设计尚未得到系统地探索。此外，虽然使用代理进行规划和执行有着重大好处，但有关负责任AI相关软件质量属性（如安全性和问责制）存在严重考虑。因此，本文提出了一种以模式为导向的参考架构，可用作在设计基于基础模型代理时的指导。

    arXiv:2311.13148v3 Announce Type: replace  Abstract: Foundation models, such as large language models (LLMs), have been widely recognised as transformative AI technologies due to their capabilities to understand and generate content, including plans with reasoning capabilities. Foundation model based agents derive their autonomy from the capabilities of foundation models, which enable them to autonomously break down a given goal into a set of manageable tasks and orchestrate task execution to meet the goal. Despite the huge efforts put into building foundation model based agents, the architecture design of the agents has not yet been systematically explored. Also, while there are significant benefits of using agents for planning and execution, there are serious considerations regarding responsible AI related software quality attributes, such as security and accountability. Therefore, this paper presents a pattern-oriented reference architecture that serves as guidance when designing fo
    
[^133]: 针对未经授权的文本到图像扩散合成的鲁棒性不可察觉扰动

    Toward Robust Imperceptible Perturbation against Unauthorized Text-to-image Diffusion-based Synthesis

    [https://arxiv.org/abs/2311.13127](https://arxiv.org/abs/2311.13127)

    MetaCloak提出了一种基于元学习框架的解决方案，通过额外转换抽样过程来制造可转移和鲁棒的扰动，以解决现有防御方法的局限性。

    

    arXiv:2311.13127v2 公告类型: 替代交叉 摘要: 文本到图像扩散模型允许从少量参考照片无缝生成个性化图像。然而，这些工具如果落入错误的手中，可能制造误导性或有害内容，危害个人。为解决此问题，现有的基于投毒的方法以一种不可察觉的方式扰动用户图像，以使其无法被恶意使用者学习。我们确定这些防御方法存在两个限制：i) 由于手工启发式解决难解双层优化而导致次优；ii) 缺乏对简单数据转换（如高斯滤波）的鲁棒性。为解决这些挑战，我们提出了MetaCloak，它通过元学习框架解决双级投毒问题，并采用额外的转换抽样过程来制造可转移和鲁棒的扰动。具体而言，我们利用一组替代扩散模型来制造可转移和与模型无关的扰动。

    arXiv:2311.13127v2 Announce Type: replace-cross  Abstract: Text-to-image diffusion models allow seamless generation of personalized images from scant reference photos. Yet, these tools, in the wrong hands, can fabricate misleading or harmful content, endangering individuals. To address this problem, existing poisoning-based approaches perturb user images in an imperceptible way to render them "unlearnable" from malicious uses. We identify two limitations of these defending approaches: i) sub-optimal due to the hand-crafted heuristics for solving the intractable bilevel optimization and ii) lack of robustness against simple data transformations like Gaussian filtering. To solve these challenges, we propose MetaCloak, which solves the bi-level poisoning problem with a meta-learning framework with an additional transformation sampling process to craft transferable and robust perturbation. Specifically, we employ a pool of surrogate diffusion models to craft transferable and model-agnostic
    
[^134]: 写作时思考：假设验证促进忠实的知识到文本生成

    Think While You Write: Hypothesis Verification Promotes Faithful Knowledge-to-Text Generation

    [https://arxiv.org/abs/2311.09467](https://arxiv.org/abs/2311.09467)

    提出了一种名为TWEAK的仅解码方法，通过引入假设验证模型来提高知识到文本生成的忠实度，并在不影响质量的情况下取得改进。

    

    知识到文本生成器经常难以忠实地为输入事实生成描述：它们可能产生与输入相矛盾的幻觉，或描述输入中不存在的事实。为了减少幻觉，我们提出了一种仅解码的方法TWEAK（思考而有效表达知识），可以与任何生成器集成而无需重新训练。TWEAK将每个解码步骤的生成序列及其未来序列视为假设，并根据其假设受到输入事实支持的程度，使用假设验证模型（HVM）对每个生成候选进行排名。我们首先通过使用自然语言推理（NLI）模型作为HVM展示了TWEAK的有效性，并报告了对质量影响很小的改善忠实度。然后，我们将NLI模型替换为使用FATE（事实对齐文本）首创数据集训练的特定任务HVM。

    arXiv:2311.09467v2 Announce Type: replace-cross  Abstract: Knowledge-to-text generators often struggle to faithfully generate descriptions for the input facts: they may produce hallucinations that contradict the input, or describe facts not present in the input. To reduce hallucinations, we propose a decoding-only method, TWEAK (Think While Effectively Articulating Knowledge), which can be integrated with any generator without retraining. TWEAK treats the generated sequences at each decoding step and its future sequences as hypotheses, and ranks each generation candidate based on the extent to which their hypotheses are supported by the input facts using a Hypothesis Verification Model (HVM). We first demonstrate the effectiveness of TWEAK by using a Natural Language Inference (NLI) model as the HVM and report improved faithfulness with a minimal impact on the quality. We then replace the NLI model with a task-specific HVM trained with a first-of-a-kind dataset, FATE (Fact-Aligned Text
    
[^135]: 零翻译上下文机器翻译的反-LM解码

    Anti-LM Decoding for Zero-shot In-context Machine Translation

    [https://arxiv.org/abs/2311.08324](https://arxiv.org/abs/2311.08324)

    提出了一种反-LM解码目标，通过引入Anti-Language Model目标和一个设计良好的衰减因子，解决了零翻译上下文机器翻译的弱点，与其他解码目标相比，在某些设置中，实现了高达20个BLEU点的性能提升。

    

    零翻译上下文学习是指模型可以根据简单的指令执行任务的现象。然而，已知预训练的大型语言模型在这项任务中校准不佳。处理这种偏见的最有效方法之一是采用对比解码目标，该目标考虑通过在某些上下文上下文的条件下生成下一个令牌的先验概率。本工作引入了一种Anti-Language Model目标，带有一个设计用于解决上下文机器翻译的弱点的衰减因子。我们在3种模型类型和大小，3种语言方向上以及贪婪解码和波束搜索（$B=5$）下进行实验。在某些设置中，所提出的方法优于其他最先进的解码目标，观察到比默认目标高达20个BLEU点的改进。

    arXiv:2311.08324v2 Announce Type: replace-cross  Abstract: Zero-shot In-context learning is the phenomenon where models can perform the task simply given the instructions. However, pre-trained large language models are known to be poorly calibrated for this task. One of the most effective approaches to handling this bias is to adopt a contrastive decoding objective, which accounts for the prior probability of generating the next token by conditioning on some context. This work introduces an Anti-Language Model objective with a decay factor designed to address the weaknesses of In-context Machine Translation. We conduct our experiments across 3 model types and sizes, 3 language directions, and for both greedy decoding and beam search ($B=5$). The proposed method outperforms other state-of-art decoding objectives, with up to $20$ BLEU point improvement from the default objective observed in some settings.
    
[^136]: 大型语言模型的心理测量预测能力

    Psychometric Predictive Power of Large Language Models

    [https://arxiv.org/abs/2311.07484](https://arxiv.org/abs/2311.07484)

    指令调整和提示在大型语言模型中无法提供比基础模型更好的认知建模估计。

    

    arXiv:2311.07484v2 公告类型: 替换-交叉 摘要:指令调整使大型语言模型（LLMs）的响应与人类偏好一致。尽管在人-LLM对齐方面进行了努力，我们报告了一个有趣的发现，即指令调整并不总是使LLMs从认知建模的角度看起来更像人类。更具体地说，由指令调整的LLM估计的下一个词概率往往比基础LLM估计的概率更糟糕，无法模拟人类阅读行为。此外，我们探讨了使用LLMs模拟人类阅读行为的提示方法。我们的结果表明，反映特定语言假设的提示可以提高PPP，但仍不及小型基础模型的PPP。这些发现突显出LLMs最近的进展，即指令调整和提示，并不能提供比基础LLMs直接概率测量更好的认知建模估计。换句话说，我们的实验表明，纯粹的下一个词概率

    arXiv:2311.07484v2 Announce Type: replace-cross  Abstract: Instruction tuning aligns the response of large language models (LLMs) with human preferences. Despite such efforts in human--LLM alignment, we report that, interestingly, instruction tuning does not always make LLMs human-like from a cognitive modeling perspective. More specifically, next-word probabilities estimated by instruction-tuned LLMs are often worse at simulating human reading behavior than those estimated by base LLMs. In addition, we explore prompting methodologies in simulating human reading behavior with LLMs. Our results show that prompts reflecting a particular linguistic hypothesis improve PPP but are still inferior to PPP from small base models. These findings highlight that recent advancements in LLMs, i.e., instruction tuning and prompting, do not offer better estimates than direct probability measurements from base LLMs in cognitive modeling. In other words, our experiments highlight that pure next-word pro
    
[^137]: BatteryML：一个用于电池衰减机器学习的开源平台

    BatteryML:An Open-source platform for Machine Learning on Battery Degradation

    [https://arxiv.org/abs/2310.14714](https://arxiv.org/abs/2310.14714)

    BatteryML是一个开源平台，通过一站式、全面的方法统一了电池衰减建模的数据预处理、特征提取和模型实现，提高了研究应用的实用性和效率。

    

    电池衰减仍然是能源存储领域的一个关键问题，而机器学习作为推动洞察和解决方案的有效工具正在崛起。然而，电化学科学和机器学习的交叉领域带来了复杂的挑战。机器学习专家经常在处理电池科学的复杂性上苦苦挣扎，而电池研究人员则面临着将复杂模型调整到特定数据集的障碍。此外，缺乏涵盖数据格式和评估基准的电池衰减建模的统一标准。鉴于这些障碍，我们提出了BatteryML - 一个一站式、全面且开源的平台，旨在统一数据预处理、特征提取以及传统和最先进模型的实现。这种简化的方法有望提高研究应用的实用性和效率。

    arXiv:2310.14714v4 Announce Type: replace-cross  Abstract: Battery degradation remains a pivotal concern in the energy storage domain, with machine learning emerging as a potent tool to drive forward insights and solutions. However, this intersection of electrochemical science and machine learning poses complex challenges. Machine learning experts often grapple with the intricacies of battery science, while battery researchers face hurdles in adapting intricate models tailored to specific datasets. Beyond this, a cohesive standard for battery degradation modeling, inclusive of data formats and evaluative benchmarks, is conspicuously absent. Recognizing these impediments, we present BatteryML - a one-step, all-encompass, and open-source platform designed to unify data preprocessing, feature extraction, and the implementation of both traditional and state-of-the-art models. This streamlined approach promises to enhance the practicality and efficiency of research applications. BatteryML s
    
[^138]: 让行动胜于雄辩：评估LLM代理在拍卖竞技场中的战略规划与执行

    Put Your Money Where Your Mouth Is: Evaluating Strategic Planning and Execution of LLM Agents in an Auction Arena

    [https://arxiv.org/abs/2310.05746](https://arxiv.org/abs/2310.05746)

    LLM代理在拍卖竞技场展示出了关键的规划和执行技能，这为建模复杂社会互动在竞争背景下的LLMs潜力提供了新途径。

    

    最近大型语言模型（LLM）的发展展示了先进的推理能力，然而自然语言处理的评估通常依赖于静态基准。评估这一点需要测试战略推理能力的环境，这种环境需要在动态的竞争场景中进行长期规划。我们引入了AucArena，这是一个模拟拍卖的新颖评估套件，选择这个设置是因为它非常不可预测，涉及与资源和风险管理相关的许多技能，同时也易于评估。我们进行了使用最先进的LLM驱动竞标代理的受控实验，以评估他们的规划和执行技能。我们的研究表明，诸如GPT-4之类的LLM具有拍卖参与的关键技能，如预算管理和目标遵从，这些技能会随着自适应策略的改进而提高。这突出了LLM在建模竞技背景下的复杂社会互动潜力。

    arXiv:2310.05746v2 Announce Type: replace-cross  Abstract: Recent advancements in Large Language Models (LLMs) showcase advanced reasoning, yet NLP evaluations often depend on static benchmarks. Evaluating this necessitates environments that test strategic reasoning in dynamic, competitive scenarios requiring long-term planning. We introduce AucArena, a novel evaluation suite that simulates auctions, a setting chosen for being highly unpredictable and involving many skills related to resource and risk management, while also being easy to evaluate. We conduct controlled experiments using state-of-the-art LLMs to power bidding agents to benchmark their planning and execution skills. Our research demonstrates that LLMs, such as GPT-4, possess key skills for auction participation, such as budget management and goal adherence, which improve with adaptive strategies. This highlights LLMs' potential in modeling complex social interactions in competitive contexts. However, variability in LLM p
    
[^139]: 对比后训练的自动对构建

    Automatic Pair Construction for Contrastive Post-training

    [https://arxiv.org/abs/2310.02263](https://arxiv.org/abs/2310.02263)

    提出了一种自动构建对比数据的方法，使用多个模型的偏好对，提高了大型语言模型的对齐效果，并且通过DPO对比技术得到了改善，进一步优化了对齐，最终使经过调优的指导学习模型Orca超越了ChatGPT。

    

    对齐作为引导大型语言模型（LLMs）走向人类偏好的重要步骤。本文提出了一种自动构建LLM对比数据的方法，使用来自多个不同强度模型（例如InstructGPT、ChatGPT和GPT-4）的偏好对。我们比较了SLiC和DPO的对比技术与SFT基线，并发现即使在继续SFT饱和后，DPO仍然提供了一个阶跃式的改善。我们还探讨了一种对比后训练的数据课程学习方案，该方案从“更容易”的对开始学习，然后过渡到“更难”的对，进一步提高了对齐效果。最后，我们通过使用更多数据和像Orca这样的更大型模型来扩大实验规模。值得注意的是，我们的自动对比后训练进一步提高了Orca的性能，它已经是一个通过GPT-4输出调优的最先进指导学习模型，从而超越了ChatGPT。

    arXiv:2310.02263v2 Announce Type: replace-cross  Abstract: Alignment serves as an important step to steer large language models (LLMs) towards human preferences. In this paper, we propose an automatic way to construct contrastive data for LLM, using preference pairs from multiple models of varying strengths (e.g., InstructGPT, ChatGPT and GPT-4). We compare the contrastive techniques of SLiC and DPO to SFT baselines and find that DPO provides a step-function improvement even after continuing SFT saturates. We also explore a data curriculum learning scheme for contrastive post-training, which starts by learning from "easier" pairs and transitioning to "harder" ones, which further improves alignment. Finally, we scale up our experiments to train with more data and larger models like Orca. Remarkably, our automatic contrastive post-training further improves the performance of Orca, already a state-of-the-art instruction learning model tuned with GPT-4 outputs, to outperform ChatGPT.
    
[^140]: 从快捷方式到触发器：使用去噪 PoE 进行后门防御

    From Shortcuts to Triggers: Backdoor Defense with Denoised PoE

    [https://arxiv.org/abs/2305.14910](https://arxiv.org/abs/2305.14910)

    提出了一种端到端集成的后门防御框架 DPoE，旨在通过去噪设计和捕捉后门快捷方式的浅层模型，以及防止学习后门快捷方式的主模型，有效抵御各种后门攻击。

    

    语言模型经常面临多样的后门攻击风险，特别是数据污染。因此，研究针对这些攻击的防御解决方案非常重要。现有的后门防御方法主要集中在带有显式触发器的后门攻击上，对抗各种后门攻击与不同触发器的通用防御方法仍然未被充分探索。在本文中，我们提出了一种端到端集成的后门防御框架 DPoE（Denoised Product-of-Experts），灵感来源于后门攻击的快捷方式，以抵御各种后门攻击。DPoE 包含两个模型：一个捕捉后门快捷方式的浅层模型和一个被阻止学习后门快捷方式的主模型。为了处理后门攻击者引起的标签翻转，DPoE 融入了去噪设计。对 SST-2 数据集的实验证明，DPoE 显著提高了对各种类型的防御性能。

    arXiv:2305.14910v3 Announce Type: replace-cross  Abstract: Language models are often at risk of diverse backdoor attacks, especially data poisoning. Thus, it is important to investigate defense solutions for addressing them. Existing backdoor defense methods mainly focus on backdoor attacks with explicit triggers, leaving a universal defense against various backdoor attacks with diverse triggers largely unexplored. In this paper, we propose an end-to-end ensemble-based backdoor defense framework, DPoE (Denoised Product-of-Experts), which is inspired by the shortcut nature of backdoor attacks, to defend various backdoor attacks. DPoE consists of two models: a shallow model that captures the backdoor shortcuts and a main model that is prevented from learning the backdoor shortcuts. To address the label flip caused by backdoor attackers, DPoE incorporates a denoising design. Experiments on SST-2 dataset show that DPoE significantly improves the defense performance against various types of
    
[^141]: ARS-DETR: 面向长宽比敏感的定向目标检测与Transformer

    ARS-DETR: Aspect Ratio Sensitive Oriented Object Detection with Transformer

    [https://arxiv.org/abs/2303.04989](https://arxiv.org/abs/2303.04989)

    提出了一种面向长宽比敏感的定向目标检测器ARS-DETR，采用高精度度量AP$_{75}$来衡量模型性能，并通过新的角度分类方法和旋转可变形注意力模块实现了竞争性能。

    

    现有的定向目标检测方法通常使用度量AP$_{50}$来衡量模型的性能。我们认为AP$_{50}$在定向目标检测中本质上不适用，因为它对角度偏差具有较大的容忍度。因此，我们主张使用高精度度量，例如AP$_{75}$，来衡量模型的性能。在本文中，我们提出了一种带有Transformer的面向长宽比敏感的定向目标检测器，称为ARS-DETR，在高精度定向目标检测中表现出竞争力。具体而言，我们提出了一种新的角度分类方法，称为面向长宽比的圆滑标签（AR-CSL），以更合理地平滑角度标签，并丢弃先前工作引入的超参数（例如CSL）。然后，设计了一个旋转可变形注意力模块，用于根据相应角度旋转采样点，并消除之前工作引入的样本点与特征点之间的错位。

    arXiv:2303.04989v2 Announce Type: replace-cross  Abstract: Existing oriented object detection methods commonly use metric AP$_{50}$ to measure the performance of the model. We argue that AP$_{50}$ is inherently unsuitable for oriented object detection due to its large tolerance in angle deviation. Therefore, we advocate using high-precision metric, e.g. AP$_{75}$, to measure the performance of models. In this paper, we propose an Aspect Ratio Sensitive Oriented Object Detector with Transformer, termed ARS-DETR, which exhibits a competitive performance in high-precision oriented object detection. Specifically, a new angle classification method, calling Aspect Ratio aware Circle Smooth Label (AR-CSL), is proposed to smooth the angle label in a more reasonable way and discard the hyperparameter that introduced by previous work (e.g. CSL). Then, a rotated deformable attention module is designed to rotate the sampling points with the corresponding angles and eliminate the misalignment betwe
    
[^142]: 相信您的 $\nabla$: 基于梯度的干预目标定位用于因果发现

    Trust Your $\nabla$: Gradient-based Intervention Targeting for Causal Discovery

    [https://arxiv.org/abs/2211.13715](https://arxiv.org/abs/2211.13715)

    提出了一种基于梯度的干预目标定位方法，GIT，在因果发现中能够通过信号梯度估计器降低干预次数，在低数据量情况下优于竞争基线。

    

    从数据中推断因果结构是科学中一项具有基础重要性的挑战性任务。观测数据通常不足以唯一确定系统的因果结构。虽然进行干预（即实验）可以改善可识别性，但这些样本通常难以获得且成本高昂。因此，因果发现的实验设计方法旨在通过估计最具信息性的干预目标来最小化干预次数。在这项工作中，我们提出了一种新颖的基于梯度的干预目标定位方法，简称为GIT，它‘相信’了基于梯度的因果发现框架的梯度估计器，以提供干预采集函数的信号。我们在模拟和真实世界数据集上进行了大量实验，并证明GIT在低数据量情况下表现与竞争基线相当，甚至在某些情况下超越它们。

    arXiv:2211.13715v4 Announce Type: replace-cross  Abstract: Inferring causal structure from data is a challenging task of fundamental importance in science. Observational data are often insufficient to identify a system's causal structure uniquely. While conducting interventions (i.e., experiments) can improve the identifiability, such samples are usually challenging and expensive to obtain. Hence, experimental design approaches for causal discovery aim to minimize the number of interventions by estimating the most informative intervention target. In this work, we propose a novel Gradient-based Intervention Targeting method, abbreviated GIT, that 'trusts' the gradient estimator of a gradient-based causal discovery framework to provide signals for the intervention acquisition function. We provide extensive experiments in simulated and real-world datasets and demonstrate that GIT performs on par with competitive baselines, surpassing them in the low-data regime.
    
[^143]: 统一控制框架：利用扩散变分自编码器实现快速移动物体的实时拦截和避障

    Unified Control Framework for Real-Time Interception and Obstacle Avoidance of Fast-Moving Objects with Diffusion Variational Autoencoder

    [https://arxiv.org/abs/2209.13628](https://arxiv.org/abs/2209.13628)

    使用扩散变分自编码器实现快速移动物体的实时拦截和避障

    

    在动态环境中通过机器人臂实现对快速移动物体的实时拦截面临巨大挑战，原因是需要在动态障碍物中迅速做出反应，通常在毫秒级别内。本文引入了一个统一的控制框架来解决上述挑战，通过同时拦截动态物体和避开移动障碍物。我们的方法的核心是使用基于扩散的变分自编码器进行运动规划，以执行物体拦截和障碍物避开。

    arXiv:2209.13628v2 Announce Type: replace-cross  Abstract: Real-time interception of fast-moving objects by robotic arms in dynamic environments poses a formidable challenge due to the need for rapid reaction times, often within milliseconds, amidst dynamic obstacles. This paper introduces a unified control framework to address the above challenge by simultaneously intercepting dynamic objects and avoiding moving obstacles. Central to our approach is using diffusion-based variational autoencoder for motion planning to perform both object interception and obstacle avoidance. We begin by encoding the high-dimensional temporal information from streaming events into a two-dimensional latent manifold, enabling the discrimination between safe and colliding trajectories, culminating in the construction of an offline densely connected trajectory graph. Subsequently, we employ an extended Kalman filter to achieve precise real-time tracking of the moving object. Leveraging a graph-traversing str
    
[^144]: 多智体强化学习的离策略修正

    Off-Policy Correction For Multi-Agent Reinforcement Learning

    [https://arxiv.org/abs/2111.11229](https://arxiv.org/abs/2111.11229)

    提出了MA-Trace，一种新的离策略演员-评论家算法，在多智体强化学习环境中具有高可伸缩性，并通过重要性采样作为离策略修正方法，保证了计算分布的质量和算法的收敛性。

    

    多智体强化学习（MARL）为涉及多个相互作用智体的问题提供了一个框架。尽管表面上与单智体情况相似，但多智体问题往往更难训练和在理论上分析。在这项工作中，我们提出了MA-Trace，一种新的基于策略的演员-评论家算法，将V-Trace扩展到MARL设定中。我们算法的关键优势在于其在多工作器设置中的高可伸缩性。为此，MA-Trace利用重要性采样作为离策略修正方法，允许在不影响训练质量的情况下进行计算分布。此外，我们的算法是在理论上有基础的 - 我们证明了一个保证收敛的不动点定理。我们在StarCraft多智体挑战赛上对算法进行了广泛评估，这是多智体算法的标准基准。MA-Trace在所有任务上表现出色，超过了最先进水平。

    arXiv:2111.11229v3 Announce Type: replace-cross  Abstract: Multi-agent reinforcement learning (MARL) provides a framework for problems involving multiple interacting agents. Despite apparent similarity to the single-agent case, multi-agent problems are often harder to train and analyze theoretically. In this work, we propose MA-Trace, a new on-policy actor-critic algorithm, which extends V-Trace to the MARL setting. The key advantage of our algorithm is its high scalability in a multi-worker setting. To this end, MA-Trace utilizes importance sampling as an off-policy correction method, which allows distributing the computations with no impact on the quality of training. Furthermore, our algorithm is theoretically grounded - we prove a fixed-point theorem that guarantees convergence. We evaluate the algorithm extensively on the StarCraft Multi-Agent Challenge, a standard benchmark for multi-agent algorithms. MA-Trace achieves high performance on all its tasks and exceeds state-of-the-ar
    
[^145]: 噪声在组合式沟通中的催化作用和归纳偏见的必要性

    Catalytic Role Of Noise And Necessity Of Inductive Biases In The Emergence Of Compositional Communication

    [https://arxiv.org/abs/2111.06464](https://arxiv.org/abs/2111.06464)

    噪声和归纳偏见的作用使得组合式沟通自发产生，并且一定范围内的噪声有助于促进组合性的发展。

    

    沟通是组合式的，如果复杂信号可以表示为较简单子部分的组合。本文理论上表明，训练框架和数据上的归纳偏见对于发展组合式沟通是必要的。此外，我们证明组合性会在信号博弈中自发出现，代理在嘈杂通道上传输信息。我们通过实验证实，一系列噪声水平（取决于模型和数据）确实促进了组合性。最后，我们对这种依赖关系进行了全面研究，并报告了最近研究的组合性度量结果：拓扑相似性、冲突计数和上下文独立性。

    arXiv:2111.06464v2 Announce Type: replace-cross  Abstract: Communication is compositional if complex signals can be represented as a combination of simpler subparts. In this paper, we theoretically show that inductive biases on both the training framework and the data are needed to develop a compositional communication. Moreover, we prove that compositionality spontaneously arises in the signaling games, where agents communicate over a noisy channel. We experimentally confirm that a range of noise levels, which depends on the model and the data, indeed promotes compositionality. Finally, we provide a comprehensive study of this dependence and report results in terms of recently studied compositionality metrics: topographical similarity, conflict count, and context independence.
    
[^146]: 将变压器与自然语言解释相结合

    Combining Transformers with Natural Language Explanations

    [https://arxiv.org/abs/2110.00125](https://arxiv.org/abs/2110.00125)

    通过结合自然语言解释和变压器模型，我们提出了一种方法来利用外部记忆存储自然语言解释，并用于解释分类输出，实验证明这种方法能够产生相关解释且保持或提高分类性能。

    

    许多自然语言处理应用需要模型具有解释性。然而，许多成功的神经架构，包括变压器，仍然缺乏有效的解释方法。建立解释可能的一个解决方案是依赖建立来自领域知识的解释，这些知识通常以简单的自然语言文本形式存在。因此，我们提出了一个扩展到变压器模型的方法，利用外部记忆来存储自然语言解释，并使用它们来解释分类输出。我们在两个领域，法律文本分析和论据挖掘，进行了实验评估，以表明我们的方法可以产生相关的解释，同时保持或甚至提高分类性能。

    arXiv:2110.00125v3 Announce Type: replace-cross  Abstract: Many NLP applications require models to be interpretable. However, many successful neural architectures, including transformers, still lack effective interpretation methods. A possible solution could rely on building explanations from domain knowledge, which is often available as plain, natural language text. We thus propose an extension to transformer models that makes use of external memories to store natural language explanations and use them to explain classification outputs. We conduct an experimental evaluation on two domains, legal text analysis and argument mining, to show that our approach can produce relevant explanations while retaining or even improving classification performance.
    
[^147]: 复杂推理任务的子目标搜索

    Subgoal Search For Complex Reasoning Tasks

    [https://arxiv.org/abs/2108.11204](https://arxiv.org/abs/2108.11204)

    提出了子目标搜索（kSubS）方法，通过学习的子目标生成器产生多样性的子目标，减少搜索空间并在Sokoban、魔方和不等式证明三个领域取得了强大的结果。

    

    人类擅长通过从一个想法移动到相关的想法的思维过程来解决复杂的推理任务。受此启发，我们提出了子目标搜索（kSubS）方法。其关键组件是一个学习的子目标生成器，产生多样性的既可实现又接近解决方案的子目标。使用子目标可以减少搜索空间，并引入适合高效规划的高级搜索图。本文中，我们使用基于Transformer的子目标模块结合经典的最佳优先搜索框架来实现kSubS。我们展示了一种简单的生成第$k$步子目标的方法在三个具有挑战性的领域上表现出惊人的效率：两个流行的益智游戏Sokoban和魔方以及不等式证明基准INT。kSubS在适度的计算预算内取得了强大的结果，包括在INT上的最新成果。

    arXiv:2108.11204v3 Announce Type: replace  Abstract: Humans excel in solving complex reasoning tasks through a mental process of moving from one idea to a related one. Inspired by this, we propose Subgoal Search (kSubS) method. Its key component is a learned subgoal generator that produces a diversity of subgoals that are both achievable and closer to the solution. Using subgoals reduces the search space and induces a high-level search graph suitable for efficient planning. In this paper, we implement kSubS using a transformer-based subgoal module coupled with the classical best-first search framework. We show that a simple approach of generating $k$-th step ahead subgoals is surprisingly efficient on three challenging domains: two popular puzzle games, Sokoban and the Rubik's Cube, and an inequality proving benchmark INT. kSubS achieves strong results including state-of-the-art on INT within a modest computational budget.
    
[^148]: 模拟强化学习用于现实世界自动驾驶

    Simulation-based reinforcement learning for real-world autonomous driving

    [https://arxiv.org/abs/1911.12905](https://arxiv.org/abs/1911.12905)

    该论文利用模拟强化学习和合成数据来实现对真实世界自动驾驶系统的控制，成功实现了模拟到真实策略转移，并分析了设计决策对真实世界性能的影响。

    

    我们利用模拟强化学习来获得控制全尺寸真实世界车辆的驾驶系统。驾驶策略以来自单个摄像头的RGB图像及其语义分割作为输入。我们主要使用合成数据，只有在分割网络的训练中才出现标记的真实世界数据。在真实世界实验中，我们确认实现了成功的模拟到真实策略转移。基于广泛的评估，我们分析了关于感知、控制和训练的设计决策如何影响真实世界性能。

    arXiv:1911.12905v4 Announce Type: replace-cross  Abstract: We use reinforcement learning in simulation to obtain a driving system controlling a full-size real-world vehicle. The driving policy takes RGB images from a single camera and their semantic segmentation as input. We use mostly synthetic data, with labelled real-world data appearing only in the training of the segmentation network.   Using reinforcement learning in simulation and synthetic data is motivated by lowering costs and engineering effort.   In real-world experiments we confirm that we achieved successful sim-to-real policy transfer. Based on the extensive evaluation, we analyze how design decisions about perception, control, and training impact the real-world performance.
    
[^149]: 通过检索和自我反思改善医疗推理能力的检索增强型大型语言模型

    Improving Medical Reasoning through Retrieval and Self-Reflection with Retrieval-Augmented Large Language Models. (arXiv:2401.15269v1 [cs.CL])

    [http://arxiv.org/abs/2401.15269](http://arxiv.org/abs/2401.15269)

    本论文介绍了一种名为Self-BioRAG的框架，通过使用检索和自我反思的方法，提高了医疗推理的能力。该框架专注于生成解释、检索领域特定文档以及对生成的响应进行自我反思。

    

    最近的专有大型语言模型（LLMs），例如GPT-4，在生物医学领域中解决了从多项选择题到长篇生成等多样化挑战的里程碑。为了解决LLMs编码知识无法处理的挑战，已经开发了各种检索增强生成（RAG）方法，通过从知识语料库中搜索文档并无条件或有选择地将其附加到LLMs的输入来进行生成。然而，将现有方法应用于不同领域特定问题时，出现了泛化能力差的问题，导致获取不正确的文档或做出不准确的判断。在本文中，我们介绍了一种可靠的医学文本框架Self-BioRAG，专门用于生成解释、检索领域特定文档和自我反思生成的响应。我们使用了84k个经过过滤的生物医学指令集来训练Self-BioRAG，它具备评估自己的基因

    Recent proprietary large language models (LLMs), such as GPT-4, have achieved a milestone in tackling diverse challenges in the biomedical domain, ranging from multiple-choice questions to long-form generations. To address challenges that still cannot be handled with the encoded knowledge of LLMs, various retrieval-augmented generation (RAG) methods have been developed by searching documents from the knowledge corpus and appending them unconditionally or selectively to the input of LLMs for generation. However, when applying existing methods to different domain-specific problems, poor generalization becomes apparent, leading to fetching incorrect documents or making inaccurate judgments. In this paper, we introduce Self-BioRAG, a framework reliable for biomedical text that specializes in generating explanations, retrieving domain-specific documents, and self-reflecting generated responses. We utilize 84k filtered biomedical instruction sets to train Self-BioRAG that can assess its gene
    
[^150]: MLLMReID: 基于多模态大语言模型的人物再识别

    MLLMReID: Multimodal Large Language Model-based Person Re-identification. (arXiv:2401.13201v1 [cs.CV])

    [http://arxiv.org/abs/2401.13201](http://arxiv.org/abs/2401.13201)

    MLLMReID是一种基于多模态大语言模型的人物再识别方法，通过微调模型并将其视觉编码器作为主干进行优化，解决了MLLM在ReID任务中的设计指令和特征学习效果的问题。

    

    多模态大语言模型（MLLM）在许多任务中取得了令人满意的结果。然而，它们在人物再识别（ReID）任务中的表现尚未被研究。本文将研究如何将它们适应于ReID任务。一种直观的想法是使用ReID图像-文本数据集对MLLM进行微调，然后将它们的视觉编码器作为ReID的主干。然而，仍存在两个明显的问题：（1）为ReID设计指令时，MLLM可能过度拟合特定指令，而设计各种指令将导致更高的成本。（2）LLM的潜在图像特征向量没有参与损失计算。指令学习，对齐图像-文本特征，导致间接优化和学习目标不充分利用特征，限制了人物特征学习的效果。为了解决这些问题，本文提出了MLLMReID：基于多模态大语言模型的ReID。首先，我们提出了公共指令。

    Multimodal large language models (MLLM) have achieved satisfactory results in many tasks. However, their performance in the task of person re-identification (ReID) has not been explored to date. This paper will investigate how to adapt them for the task of ReID. An intuitive idea is to fine-tune MLLM with ReID image-text datasets, and then use their visual encoder as a backbone for ReID. However, there still exist two apparent issues: (1) Designing instructions for ReID, MLLMs may overfit specific instructions, and designing a variety of instructions will lead to higher costs. (2) Latent image feature vectors from LLMs are not involved in loss computation. Instructional learning, aligning image-text features, results in indirect optimization and a learning objective that inadequately utilizes features, limiting effectiveness in person feature learning. To address these problems, this paper proposes MLLMReID: Multimodal Large Language Model-based ReID. Firstly, we proposed Common Instru
    
[^151]: 大型语言模型的指令指纹识别

    Instructional Fingerprinting of Large Language Models. (arXiv:2401.12255v1 [cs.CR])

    [http://arxiv.org/abs/2401.12255](http://arxiv.org/abs/2401.12255)

    这项研究提出了一种指纹识别大型语言模型的方法，通过轻量级的指令调整，保护知识产权并确保遵守许可条款。实验证明这种方法不影响模型的正常行为，并且具有鲁棒性和高效训练的特点。

    

    从零开始训练大型语言模型（LLM）的巨大成本使得对模型进行指纹识别以保护知识产权成为必要，通过所有权认证并确保下游用户和开发者遵守许可条款（如限制商业使用）。在这项研究中，我们提出了LLM指纹识别的试点研究，作为一种非常轻量级的指令调整形式。模型发布者指定一个机密的私钥，并将其植入为一个指令后门，当密钥存在时，导致LLM生成特定的文本。对11个常用LLMs的结果表明，这种方法轻量级且不影响模型的正常行为。它还可以防止发布者过度宣称，对指纹猜测和参数高效训练保持鲁棒性，并支持类似于MIT许可证的多阶段指纹识别。代码可在https://cnut1648.github.io/Model-Fingerprint/中获得。

    The exorbitant cost of training Large language models (LLMs) from scratch makes it essential to fingerprint the models to protect intellectual property via ownership authentication and to ensure downstream users and developers comply with their license terms (e.g. restricting commercial use). In this study, we present a pilot study on LLM fingerprinting as a form of very lightweight instruction tuning. Model publisher specifies a confidential private key and implants it as an instruction backdoor that causes the LLM to generate specific text when the key is present. Results on 11 popularly-used LLMs showed that this approach is lightweight and does not affect the normal behavior of the model. It also prevents publisher overclaim, maintains robustness against fingerprint guessing and parameter-efficient training, and supports multi-stage fingerprinting akin to MIT License. Code is available in https://cnut1648.github.io/Model-Fingerprint/.
    
[^152]: 通过通用概念发现理解视频Transformer

    Understanding Video Transformers via Universal Concept Discovery. (arXiv:2401.10831v1 [cs.CV])

    [http://arxiv.org/abs/2401.10831](http://arxiv.org/abs/2401.10831)

    本文研究了视频Transformer的可解释性问题，引入了视频Transformer概念发现算法来解释其决策过程，并揭示了时空推理机制和对象为中心的表示。

    

    本文研究了基于概念的视频Transformer表示的可解释性问题。具体而言，我们试图解释基于自动发现的高层时空概念的视频Transformer的决策过程。以往关于基于概念的可解释性的研究仅集中在图像级任务上。相比之下，视频模型处理了额外的时间维度，增加了复杂性，并在识别动态概念方面面临挑战。在这项工作中，我们通过引入第一个视频Transformer概念发现(VTCD)算法系统地解决了这些挑战。为此，我们提出了一种有效的无监督方法，用于识别视频Transformer表示的单元（概念）并对其对模型输出的重要性进行排名。得到的概念具有很强的可解释性，揭示了视频中的时空推理机制和以对象为中心的表示。

    This paper studies the problem of concept-based interpretability of transformer representations for videos. Concretely, we seek to explain the decision-making process of video transformers based on high-level, spatiotemporal concepts that are automatically discovered. Prior research on concept-based interpretability has concentrated solely on image-level tasks. Comparatively, video models deal with the added temporal dimension, increasing complexity and posing challenges in identifying dynamic concepts over time. In this work, we systematically address these challenges by introducing the first Video Transformer Concept Discovery (VTCD) algorithm. To this end, we propose an efficient approach for unsupervised identification of units of video transformer representations - concepts, and ranking their importance to the output of a model. The resulting concepts are highly interpretable, revealing spatio-temporal reasoning mechanisms and object-centric representations in unstructured video m
    
[^153]: 医学视觉问答中的幻觉基准评估

    Hallucination Benchmark in Medical Visual Question Answering. (arXiv:2401.05827v1 [cs.CL])

    [http://arxiv.org/abs/2401.05827](http://arxiv.org/abs/2401.05827)

    这项研究创建了医学图像的幻觉基准评估，并全面评估了当前最先进的模型，揭示了幻觉现象在临床环境中的限制和各种提示策略的有效性。

    

    最近大型语言和视觉模型在视觉问答（VQA）上取得了成功，尤其在医学（Med-VQA）领域的应用显示出了为医疗提供有效视觉助手的巨大潜力。然而，这些模型在临床环境中的幻觉现象上并没有进行广泛测试。在本研究中，我们创建了一个医学图像配对问题-回答集的幻觉基准评估，并对当前最先进的模型进行了全面评估。该研究对当前模型的局限性进行了深入分析，并揭示了各种提示策略的有效性。

    The recent success of large language and vision models on vision question answering (VQA), particularly their applications in medicine (Med-VQA), has shown a great potential of realizing effective visual assistants for healthcare. However, these models are not extensively tested on the hallucination phenomenon in clinical settings. Here, we created a hallucination benchmark of medical images paired with question-answer sets and conducted a comprehensive evaluation of the state-of-the-art models. The study provides an in-depth analysis of current models limitations and reveals the effectiveness of various prompting strategies.
    
[^154]: 通过生成对抗网络推进先验可解释模型

    Advancing Ante-Hoc Explainable Models through Generative Adversarial Networks. (arXiv:2401.04647v1 [cs.CV])

    [http://arxiv.org/abs/2401.04647](http://arxiv.org/abs/2401.04647)

    本文提出了一种先验可解释模型，通过在主分类器网络中添加无监督的解释生成器和对抗训练的方式，实现了模型的可解释性和性能的提升。该方法通过训练解释模块提取视觉概念，同时使用生成对抗网络模块来区分生成的图像和真实图像。实验证明了该方法的鲁棒性，并展示了学到的概念与对象部分和视觉属性的语义一致性。

    

    本文提出了一种新的概念学习框架，用于增强视觉分类任务中模型的可解释性和性能。我们的方法将一个无监督的解释生成器添加到主分类器网络中，并利用对抗训练。在训练过程中，解释模块被优化以从分类器的潜在表示中提取视觉概念，而基于生成对抗网络的模块则旨在区分从概念中生成的图像和真实图像。这种联合训练方案使得模型能够将其内部学习到的概念与人可解释的视觉属性隐式地对齐。全面的实验证明了我们方法的鲁棒性，同时产生了连贯的概念激活。我们分析了学到的概念，展示了它们与对象部分和视觉属性之间的语义一致性。我们还研究了对抗训练协议中的扰动对分类和概念获取的影响。总之，本文通过生成对抗网络推进了先验可解释模型。

    This paper presents a novel concept learning framework for enhancing model interpretability and performance in visual classification tasks. Our approach appends an unsupervised explanation generator to the primary classifier network and makes use of adversarial training. During training, the explanation module is optimized to extract visual concepts from the classifier's latent representations, while the GAN-based module aims to discriminate images generated from concepts, from true images. This joint training scheme enables the model to implicitly align its internally learned concepts with human-interpretable visual properties. Comprehensive experiments demonstrate the robustness of our approach, while producing coherent concept activations. We analyse the learned concepts, showing their semantic concordance with object parts and visual attributes. We also study how perturbations in the adversarial training protocol impact both classification and concept acquisition. In summary, this 
    
[^155]: 追踪任何物体的非现态方法

    Tracking Any Object Amodally. (arXiv:2312.12433v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.12433](http://arxiv.org/abs/2312.12433)

    本论文介绍了一种追踪任何物体的非现态方法，利用数据增强和微调现态跟踪器，可以提高追踪的效果。

    

    非现态感知是一种从部分可见性中理解完整物体结构的基本技能，它对于婴儿甚至是成人都非常重要。它的重要性延伸到了自动驾驶等应用领域，对于理解重叠物体至关重要。然而，现代的检测和跟踪算法通常忽视了这一关键能力，可能是因为大多数数据集中普遍使用的是现态标注。为了解决非现态数据的匮乏问题，我们引入了TAO-Amodal基准，其中包含数千个视频序列中的880个多样化的物体类别。我们的数据集包括可见和遮挡对象的非现态和现态边界框，包括部分超出画面范围的物体。为了增强非现态追踪的目标永久性，我们利用了一个轻量级的插件模块，即非现态扩展器，通过对几百个视频序列进行数据增强的微调，将标准的现态跟踪器转化为非现态跟踪器。我们取得了3.3％和1.6％的改进效果。

    Amodal perception, the ability to comprehend complete object structures from partial visibility, is a fundamental skill, even for infants. Its significance extends to applications like autonomous driving, where a clear understanding of heavily occluded objects is essential. However, modern detection and tracking algorithms often overlook this critical capability, perhaps due to the prevalence of modal annotations in most datasets. To address the scarcity of amodal data, we introduce the TAO-Amodal benchmark, featuring 880 diverse categories in thousands of video sequences. Our dataset includes amodal and modal bounding boxes for visible and occluded objects, including objects that are partially out-of-frame. To enhance amodal tracking with object permanence, we leverage a lightweight plug-in module, the amodal expander, to transform standard, modal trackers into amodal ones through fine-tuning on a few hundred video sequences with data augmentation. We achieve a 3.3\% and 1.6\% improve
    
[^156]: 使用AI副驾驶员导航复杂搜索任务

    Navigating Complex Search Tasks with AI Copilots. (arXiv:2311.01235v1 [cs.IR])

    [http://arxiv.org/abs/2311.01235](http://arxiv.org/abs/2311.01235)

    该论文介绍了使用AI副驾驶员来导航复杂搜索任务，并探讨了生成AI和辅助代理的出现对于支持复杂搜索任务的潜力和重要性。

    

    正如信息检索(IR)研究界的许多人所知和欣赏的那样，搜索远未解决。每天都有数百万人在搜索引擎上面对任务的困难。他们的困难通常与任务的内在复杂性以及搜索系统无法完全理解任务和提供相关结果有关。任务激发了搜索，创建了搜索者尝试连接/解决的差距/问题情况，并在他们处理不同任务方面时驱动搜索行为。复杂搜索任务需要的不仅是基本事实查找或搜索的支持。支持复杂任务的方法研究包括生成查询和网站建议，个性化和上下文化搜索，以及开发新的搜索体验，包括跨时间和空间。最近兴起的生成人工智能(AI)和基于该技术的辅助代理，或者说副驾驶员，的出现。

    As many of us in the information retrieval (IR) research community know and appreciate, search is far from being a solved problem. Millions of people struggle with tasks on search engines every day. Often, their struggles relate to the intrinsic complexity of their task and the failure of search systems to fully understand the task and serve relevant results. The task motivates the search, creating the gap/problematic situation that searchers attempt to bridge/resolve and drives search behavior as they work through different task facets. Complex search tasks require more than support for rudimentary fact finding or re-finding. Research on methods to support complex tasks includes work on generating query and website suggestions, personalizing and contextualizing search, and developing new search experiences, including those that span time and space. The recent emergence of generative artificial intelligence (AI) and the arrival of assistive agents, or copilots, based on this technology
    
[^157]: 潜在空间中的多个数学运算推导

    Multi-Operational Mathematical Derivations in Latent Space. (arXiv:2311.01230v1 [cs.LG])

    [http://arxiv.org/abs/2311.01230](http://arxiv.org/abs/2311.01230)

    本文研究在潜在空间中逼近多个数学运算进行表达式推导的可能性，并通过构建大规模数据集和使用最先进的神经编码器实例化，探索了不同编码机制在潜在空间中逼近方程推理的能力。

    

    本文研究在潜在空间中逼近多个数学运算进行表达式推导的可能性。为此，我们引入了不同的多操作表示范式，将数学运算建模为显式的几何变换。通过利用符号引擎，我们构建了一个包含61K个前提和6个运算符的大规模数据集，分析了每个范式在与最先进的神经编码器实例化时的性质。具体而言，我们研究了不同的编码机制在潜在空间中如何逼近方程推理，并探讨了学习不同运算符和在单个运算中专门化之间的权衡，以及支持多步推导和超越分布广义化的能力。我们的实证分析表明，多操作范式对于解开不同运算符是至关重要的，同时可以区分结论。

    This paper investigates the possibility of approximating multiple mathematical operations in latent space for expression derivation. To this end, we introduce different multi-operational representation paradigms, modelling mathematical operations as explicit geometric transformations. By leveraging a symbolic engine, we construct a large-scale dataset comprising 1.7M derivation steps stemming from 61K premises and 6 operators, analysing the properties of each paradigm when instantiated with state-of-the-art neural encoders. Specifically, we investigate how different encoding mechanisms can approximate equational reasoning in latent space, exploring the trade-off between learning different operators and specialising within single operations, as well as the ability to support multi-step derivations and out-of-distribution generalisation. Our empirical analysis reveals that the multi-operational paradigm is crucial for disentangling different operators, while discriminating the conclusion
    
[^158]: BioImage.IO Chatbot: 一个以社区知识库增强的生物图像分析个人助手

    BioImage.IO Chatbot: A Personalized Assistant for BioImage Analysis Augmented by Community Knowledge Base. (arXiv:2310.18351v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.18351](http://arxiv.org/abs/2310.18351)

    BioImage.IO Chatbot 是一个根据用户个性化需求提供答案的AI聊天助手，通过汇集和解释多个数据库、工具文档和数据源的信息，以及社区贡献的知识库和优化的检索方法，为生物图像分析工具的使用者提供了个性化、上下文感知的体验，为可访问的科学研究设立了新的标准。

    

    快速扩展的生物图像分析工具景观给专家和新来者都带来了导航挑战。传统的搜索方法在这个复杂环境中常常无法提供帮助。为了解决这个问题，我们引入了BioImage.IO Chatbot，一个为生物图像社区量身定制的基于人工智能的对话助手。这个聊天机器人建立在大型语言模型的基础上，通过聚合和解释来自多个数据库、特定工具文档和结构化数据源的信息，提供个性化的、上下文感知的答案。通过社区贡献的知识库和经过优化的检索方法，BioImage.IO Chatbot 不仅提供个性化的互动，还提供丰富的知识、上下文感知的体验。它从根本上改变了生物学家、生物图像分析师和开发者导航和利用先进的生物图像分析工具的方式，为社区驱动的可访问科学研究树立了新的标准。

    The rapidly expanding landscape of bioimage analysis tools presents a navigational challenge for both experts and newcomers. Traditional search methods often fall short in assisting users in this complex environment. To address this, we introduce the BioImage$.$IO Chatbot, an AI-driven conversational assistant tailored for the bioimage community. Built upon large language models, this chatbot provides personalized, context-aware answers by aggregating and interpreting information from diverse databases, tool-specific documentation, and structured data sources. Enhanced by a community-contributed knowledge base and fine-tuned retrieval methods, the BioImage$.$IO Chatbot offers not just a personalized interaction but also a knowledge-enriched, context-aware experience. It fundamentally transforms the way biologists, bioimage analysts, and developers navigate and utilize advanced bioimage analysis tools, setting a new standard for community-driven, accessible scientific research.
    
[^159]: 在样本选择偏差存在的情况下，利用集成多样性进行鲁棒的自训练

    Leveraging Ensemble Diversity for Robust Self-Training in the Presence of Sample Selection Bias. (arXiv:2310.14814v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.14814](http://arxiv.org/abs/2310.14814)

    本文提出了一种在样本选择偏差存在的情况下，利用集成多样性进行鲁棒的自训练的方法，并引入了一种新的自信度度量方法-$\mathcal{T}$-相似度。实验证明该方法在三种不同伪标签策略下具有良好的效果。

    

    自训练是半监督学习中一种众所周知的方法。它包括对模型自信度高的未标记数据进行伪标签分配，并将其视为标记样本进行处理。对于神经网络，通常使用softmax预测概率作为自信度度量，尽管已知它们对错误预测也过于自信。当数据标注受到某种约束时，这种现象尤为明显，即样本选择偏差存在。为了解决这个问题，我们提出了一种新的自信度度量方法，称为$\mathcal{T}$-相似度，它基于线性分类器的集成预测多样性。我们通过研究稳定点并描述单个成员的多样性与其性能之间的关系来提供我们方法的理论分析。我们通过对三种不同伪标签策略的实验验证了我们自信度度量的好处。

    Self-training is a well-known approach for semi-supervised learning. It consists of iteratively assigning pseudo-labels to unlabeled data for which the model is confident and treating them as labeled examples. For neural networks, softmax prediction probabilities are often used as a confidence measure, despite the fact that they are known to be overconfident, even for wrong predictions. This phenomenon is particularly intensified in the presence of sample selection bias, i.e., when data labeling is subject to some constraint. To address this issue, we propose a novel confidence measure, called $\mathcal{T}$-similarity, built upon the prediction diversity of an ensemble of linear classifiers. We provide the theoretical analysis of our approach by studying stationary points and describing the relationship between the diversity of the individual members and their performance. We empirically demonstrate the benefit of our confidence measure for three different pseudo-labeling policies on c
    
[^160]: 适当的Laplacian表示学习

    Proper Laplacian Representation Learning. (arXiv:2310.10833v1 [cs.LG])

    [http://arxiv.org/abs/2310.10833](http://arxiv.org/abs/2310.10833)

    本论文介绍了一种理论上可靠的方法和优化算法，用于近似Laplacian表示学习，以解决大规模强化学习中的探索、泛化和传递问题。

    

    在解决大规模强化学习问题时，学习状态的良好表示对于探索、泛化和传递是至关重要的。Laplacian表示是一种有希望的方法，通过引入内在奖励来解决这些问题，以实现时间延长的动作发现和奖励塑造，以及信息丰富的状态编码。为了获得Laplacian表示，需要计算图Laplacian的特征系统，这通常通过与深度学习方法兼容的优化目标进行近似。然而，这些近似方法依赖于无法高效调整的超参数，收敛到所需特征向量的任意旋转，并且无法精确地恢复相应的特征值。本文提出了一种理论上可靠的目标和相应的优化算法，用于近似Laplacian表示。

    The ability to learn good representations of states is essential for solving large reinforcement learning problems, where exploration, generalization, and transfer are particularly challenging. The Laplacian representation is a promising approach to address these problems by inducing intrinsic rewards for temporally-extended action discovery and reward shaping, and informative state encoding. To obtain the Laplacian representation one needs to compute the eigensystem of the graph Laplacian, which is often approximated through optimization objectives compatible with deep learning approaches. These approximations, however, depend on hyperparameters that are impossible to tune efficiently, converge to arbitrary rotations of the desired eigenvectors, and are unable to accurately recover the corresponding eigenvalues. In this paper we introduce a theoretically sound objective and corresponding optimization algorithm for approximating the Laplacian representation. Our approach naturally reco
    
[^161]: Retro-fallback: 面向不确定世界的逆合成规划

    Retro-fallback: retrosynthetic planning in an uncertain world. (arXiv:2310.09270v1 [cs.AI])

    [http://arxiv.org/abs/2310.09270](http://arxiv.org/abs/2310.09270)

    本文针对逆合成任务在实验室执行可行性的不确定性问题，通过引入随机过程的表述，提出了一种名为 Retro-fallback 的贪婪算法，该算法能够最大化实验室可执行的合成计划的概率。

    

    逆合成是通过提出一系列化学反应从更简单、可购买的分子创建所需分子的任务。虽然先前的研究提出了一些算法来寻找一系列度量指标（例如最短路径、最低成本）的最优解，但这些研究通常忽视了我们对可能反应空间的不完全了解，这意味着算法生成的计划可能在实验室中无法实施。在本文中，我们提出了一种基于随机过程的逆合成新颖表述，以考虑这种不确定性。然后，我们提出了一种新颖的贪婪算法称为 Retro-fallback，最大化至少有一种合成计划能在实验室中执行的概率。使用仿真基准测试，我们证明 Retro-fallback 通常生成比流行的 MCTS 和 retro* 算法更好的一组合成计划。

    Retrosynthesis is the task of proposing a series of chemical reactions to create a desired molecule from simpler, buyable molecules. While previous works have proposed algorithms to find optimal solutions for a range of metrics (e.g. shortest, lowest-cost), these works generally overlook the fact that we have imperfect knowledge of the space of possible reactions, meaning plans created by the algorithm may not work in a laboratory. In this paper we propose a novel formulation of retrosynthesis in terms of stochastic processes to account for this uncertainty. We then propose a novel greedy algorithm called retro-fallback which maximizes the probability that at least one synthesis plan can be executed in the lab. Using in-silico benchmarks we demonstrate that retro-fallback generally produces better sets of synthesis plans than the popular MCTS and retro* algorithms.
    
[^162]: CReHate: 跨文化重新注释英语仇恨言论数据集

    CReHate: Cross-cultural Re-annotation of English Hate Speech Dataset. (arXiv:2308.16705v1 [cs.CL])

    [http://arxiv.org/abs/2308.16705](http://arxiv.org/abs/2308.16705)

    CReHate通过跨文化重新注释英语仇恨言论数据集，揭示了来自不同国家的个体对仇恨言论的不同看法，并引入了一种具有文化敏感性的分类器。这些发现强调了重新评估NLP研究在仇恨言论领域的必要性。

    

    英语数据集主要反映了特定国家的观点，这可能导致模型和数据集中存在文化偏差。这在受主观性影响较大的任务，如仇恨言论检测中特别有问题。为了深入了解来自不同国家的个体如何理解仇恨言论，我们介绍了CReHate，对抽样的SBIC数据集进行了跨文化重新注释。该数据集包括来自五个不同国家的注释：澳大利亚、新加坡、南非、英国和美国。我们进行了彻底的统计分析，发现基于国籍存在显著差异，只有59.4%的样本在所有国家之间达成共识。我们还通过迁移学习引入了一种具有文化敏感性的仇恨言论分类器，能够捕捉不同国籍的观点。这些发现强调了需要重新评估自然语言处理研究的某些方面，特别是对于仇恨言论的细微性质。

    English datasets predominantly reflect the perspectives of certain nationalities, which can lead to cultural biases in models and datasets. This is particularly problematic in tasks heavily influenced by subjectivity, such as hate speech detection. To delve into how individuals from different countries perceive hate speech, we introduce CReHate, a cross-cultural re-annotation of the sampled SBIC dataset. This dataset includes annotations from five distinct countries: Australia, Singapore, South Africa, the United Kingdom, and the United States. Our thorough statistical analysis highlights significant differences based on nationality, with only 59.4% of the samples achieving consensus among all countries. We also introduce a culturally sensitive hate speech classifier via transfer learning, adept at capturing perspectives of different nationalities. These findings underscore the need to re-evaluate certain aspects of NLP research, especially with regard to the nuanced nature of hate spe
    
[^163]: 从可解释模型中实现概率数据集重建

    Probabilistic Dataset Reconstruction from Interpretable Models. (arXiv:2308.15099v1 [cs.AI])

    [http://arxiv.org/abs/2308.15099](http://arxiv.org/abs/2308.15099)

    本文提出了一个新的框架，实现了从可解释模型中概率重建数据集。在现实假设下，可以高效计算重建的不确定性，以量化信息泄漏的隐私影响。

    

    可解释性经常被认为是可信赖机器学习的关键要求。然而，学习和发布本质上可解释的模型会泄露有关底层训练数据的信息。由于这种披露可能直接与隐私冲突，因此准确量化这种泄漏带来的隐私影响是一个基本问题。例如，以前的研究表明，可以利用决策树的结构构建其训练数据集的概率重建，重建的不确定性是信息泄漏的一个相关度量。在本文中，我们提出了一个新的框架，推广了这些概率重建，使其可以处理其他形式的可解释模型和更一般类型的知识。此外，我们证明在对可解释模型结构进行实际假设的情况下，可以高效地计算重建的不确定性。

    Interpretability is often pointed out as a key requirement for trustworthy machine learning. However, learning and releasing models that are inherently interpretable leaks information regarding the underlying training data. As such disclosure may directly conflict with privacy, a precise quantification of the privacy impact of such breach is a fundamental problem. For instance, previous work have shown that the structure of a decision tree can be leveraged to build a probabilistic reconstruction of its training dataset, with the uncertainty of the reconstruction being a relevant metric for the information leak. In this paper, we propose of a novel framework generalizing these probabilistic reconstructions in the sense that it can handle other forms of interpretable models and more generic types of knowledge. In addition, we demonstrate that under realistic assumptions regarding the interpretable models' structure, the uncertainty of the reconstruction can be computed efficiently. Final
    
[^164]: 部署机器学习的生态系统级分析揭示了同质化的结果

    Ecosystem-level Analysis of Deployed Machine Learning Reveals Homogeneous Outcomes. (arXiv:2307.05862v1 [cs.LG])

    [http://arxiv.org/abs/2307.05862](http://arxiv.org/abs/2307.05862)

    部署机器学习存在系统性故障, 即使单个模型在总体上的改善也不能解决这个问题

    

    传统上，机器学习通常在模型层面进行研究：研究人员衡量和改进特定模型的准确性、鲁棒性、偏见、效率和其他维度。实际上，机器学习的社会影响取决于机器学习部署的周围环境。为了捕捉这一点，我们引入了生态系统级分析：不是分析单个模型，而是考虑在给定环境中部署的所有模型的集合。例如，在招聘中进行生态系统级分析意味着认识到一个求职者的结果不仅仅取决于单个招聘算法或公司，而是取决于他们申请的所有公司的集体决策。在三种模式（文本、图像、语音）和11个数据集上，我们建立了一个明显的趋势：部署的机器学习容易出现系统性故障，这意味着一些用户被所有可用的模型错误分类。即使在个体模型随时间在总体水平上改善，我们也发现

    Machine learning is traditionally studied at the model level: researchers measure and improve the accuracy, robustness, bias, efficiency, and other dimensions of specific models. In practice, the societal impact of machine learning is determined by the surrounding context of machine learning deployments. To capture this, we introduce ecosystem-level analysis: rather than analyzing a single model, we consider the collection of models that are deployed in a given context. For example, ecosystem-level analysis in hiring recognizes that a job candidate's outcomes are not only determined by a single hiring algorithm or firm but instead by the collective decisions of all the firms they applied to. Across three modalities (text, images, speech) and 11 datasets, we establish a clear trend: deployed machine learning is prone to systemic failure, meaning some users are exclusively misclassified by all models available. Even when individual models improve at the population level over time, we fin
    
[^165]: 将实验数据与观测数据结合的双机器学习方法

    A Double Machine Learning Approach to Combining Experimental and Observational Data. (arXiv:2307.01449v1 [stat.ME])

    [http://arxiv.org/abs/2307.01449](http://arxiv.org/abs/2307.01449)

    这种双机器学习方法将实验和观测研究结合起来，能够测试假设的违反情况并一致估计处理效应。它提供了半参数高效的处理效应估计器。这种方法在实际环境中是可行的。

    

    实验和观测研究通常由于无法测试的假设而缺乏有效性。我们提出了一种双机器学习方法，将实验和观测研究结合起来，使从业人员能够测试假设违反情况并一致估计处理效应。我们的框架在较轻的假设下测试外部效度和可忽视性的违反情况。当只有一个假设被违反时，我们提供半参数高效的处理效应估计器。然而，我们的无免费午餐定理强调了准确识别违反的假设对一致的处理效应估计的必要性。我们通过三个实际案例研究展示了我们方法的适用性，并突出了其在实际环境中的相关性。

    Experimental and observational studies often lack validity due to untestable assumptions. We propose a double machine learning approach to combine experimental and observational studies, allowing practitioners to test for assumption violations and estimate treatment effects consistently. Our framework tests for violations of external validity and ignorability under milder assumptions. When only one assumption is violated, we provide semi-parametrically efficient treatment effect estimators. However, our no-free-lunch theorem highlights the necessity of accurately identifying the violated assumption for consistent treatment effect estimation. We demonstrate the applicability of our approach in three real-world case studies, highlighting its relevance for practical settings.
    
[^166]: CamemBERT-bio：一种更健康的法语语言模型

    CamemBERT-bio: a Tasty French Language Model Better for your Health. (arXiv:2306.15550v1 [cs.CL])

    [http://arxiv.org/abs/2306.15550](http://arxiv.org/abs/2306.15550)

    本研究介绍了CamemBERT-bio，它是一种针对法语生物医学领域专门设计的语言模型，相对于通用模型在命名实体识别任务上平均提高了2.54个百分点。

    

    通过临床数据仓库，医院中的临床数据变得越来越容易用于研究，然而这些文件都是非结构化的。因此，需要从医疗报告中提取信息以进行临床研究。使用CamemBERT等BERT-like模型的迁移学习已经取得了重大进展，特别是命名实体识别方面。然而，这些模型是为通用语言训练的，在生物医学数据上效果较弱。因此，我们提出了一种新的法语公共生物医学数据集，对CamemBERT进行了继续预训练。因此，我们介绍了CamemBERT-bio的第一个版本，它是一种为法语生物医学领域专门设计的公共模型，在不同的生物医学命名实体识别任务上平均F1分数提高了2.54个百分点。

    Clinical data in hospitals are increasingly accessible for research through clinical data warehouses, however these documents are unstructured. It is therefore necessary to extract information from medical reports to conduct clinical studies. Transfer learning with BERT-like models such as CamemBERT has allowed major advances, especially for named entity recognition. However, these models are trained for plain language and are less efficient on biomedical data. This is why we propose a new French public biomedical dataset on which we have continued the pre-training of CamemBERT. Thus, we introduce a first version of CamemBERT-bio, a specialized public model for the French biomedical domain that shows 2.54 points of F1 score improvement on average on different biomedical named entity recognition tasks.
    
[^167]: 训练指令作为后门: 大规模语言模型指令调整的后门漏洞

    Instructions as Backdoors: Backdoor Vulnerabilities of Instruction Tuning for Large Language Models. (arXiv:2305.14710v1 [cs.CL])

    [http://arxiv.org/abs/2305.14710](http://arxiv.org/abs/2305.14710)

    使用指令调整方法在众包数据集上训练的大规模语言模型，存在后门漏洞，攻击者只需注入极少量的恶意指令便可永久控制模型行为，且难以被修复，需要更加健全的防御机制。

    

    本文研究使用指令调整方法在众包数据集上训练的模型，其目的是达到更好的性能表现。然而，我们提出了一个与该培训范例相关的安全问题。研究表明，攻击者只需在成千上万的数据中注入极少量的恶意指令，便可以通过数据毒化来控制模型行为，甚至无需修改数据实例或标签本身。通过这种指令攻击，攻击者可以在四个常用的 NLP 数据集上实现超过90% 的攻击成功率，并引起易于转移到 15 种不同数据集的持久后门。这种攻击还可以直接应用于多个数据集的有毒指令。最后，该攻击显示出对现有推理时防御的抵抗力。这些发现凸显了在语言模型训练中需要更为健全的防御机制。

    Instruction-tuned models are trained on crowdsourcing datasets with task instructions to achieve superior performance. However, in this work we raise security concerns about this training paradigm. Our studies demonstrate that an attacker can inject backdoors by issuing very few malicious instructions among thousands of gathered data and control model behavior through data poisoning, without even the need of modifying data instances or labels themselves. Through such instruction attacks, the attacker can achieve over 90% attack success rate across four commonly used NLP datasets, and cause persistent backdoors that are easily transferred to 15 diverse datasets zero-shot. In this way, the attacker can directly apply poisoned instructions designed for one dataset on many other datasets. Moreover, the poisoned model cannot be cured by continual learning. Lastly, instruction attacks show resistance to existing inference-time defense. These findings highlight the need for more robust defens
    
[^168]: 从孤立的岛屿到泛大陆：统一语义空间用于人类行为理解

    From Isolated Islands to Pangea: Unifying Semantic Space for Human Action Understanding. (arXiv:2304.00553v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2304.00553](http://arxiv.org/abs/2304.00553)

    本文提出了一个统一的语义空间Poincare行为语义空间，通过将以前数据集的类别与这个语义空间对齐，收集（图像/视频/骨架/MoCap）数据集到一个统一的数据库中，即将“孤立的岛屿”桥接成一个“泛大陆”，这将有助于推进可推广的行为学习。

    

    行为理解是一项重要的研究领域并且备受关注。它可以被理解为从行为的物理空间到语义空间的映射。通常，研究人员会根据独特的选择构建行为数据集，以定义各种类别并将基准线推向极限。因此，数据集之间存在语义差距和不同的类别粒度，就像“孤立的岛屿”一样互不兼容，例如数据集A中的家务和数据集B中的洗盘子。我们认为需要一个更具原则性的语义空间来集中社区的力量，并使我们能够一起使用所有数据集以追求可推广的行为学习。为此，我们设计了一个Poincare行为语义空间，给定动词分类层次结构并涵盖大量行为。通过将以前数据集的类别与我们的语义空间对齐，我们将（图像/视频/骨架/MoCap）数据集收集到一个统一的数据库中，使用统一的标签系统，即将“孤立的岛屿”桥接成一个“泛大陆”。因此，我们对这个统一的数据库进行了广泛的实验，结果证明了我们提出的语义空间和统一数据库的有效性。

    Action understanding matters and attracts attention. It can be formed as the mapping from the action physical space to the semantic space. Typically, researchers built action datasets according to idiosyncratic choices to define classes and push the envelope of benchmarks respectively. Thus, datasets are incompatible with each other like "Isolated Islands" due to semantic gaps and various class granularities, e.g., do housework in dataset A and wash plate in dataset B. We argue that a more principled semantic space is an urgent need to concentrate the community efforts and enable us to use all datasets together to pursue generalizable action learning. To this end, we design a Poincare action semantic space given verb taxonomy hierarchy and covering massive actions. By aligning the classes of previous datasets to our semantic space, we gather (image/video/skeleton/MoCap) datasets into a unified database in a unified label system, i.e., bridging "isolated islands" into a "Pangea". Accord
    
[^169]: 基于深度强化学习的自适应大邻域搜索算法在线控制

    Online Control of Adaptive Large Neighborhood Search using Deep Reinforcement Learning. (arXiv:2211.00759v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.00759](http://arxiv.org/abs/2211.00759)

    本研究提出一种基于深度强化学习的方法来在线控制自适应大邻域搜索算法，该方法能够自适应选择启发式策略、调整参数和控制接受标准，以获得优化问题的良好解，对应用组合优化问题中的实际问题具有重要意义。

    

    自适应大邻域搜索（ALNS）算法在解决复杂的组合优化问题（COPs）方面取得了相当的成功。ALNS在搜索过程中自适应地选择各种启发式策略，利用它们的优势来找到优化问题的良好解。然而，ALNS的有效性取决于其选择和接受参数的正确配置。为了解决这个限制，我们提出了一种基于深度强化学习（DRL）的方法，在搜索过程中选择启发式、调整参数和控制接受标准。所提出的方法旨在基于搜索的状态学习如何配置下一次ALNS迭代以获得好的优化问题解。我们在一个时间依赖的含有随机权重和时间窗口的导航问题上评估了所提出的方法，该问题用于IJCAI竞赛。结果表明，我们的方法优于普通的ALNS和具有默认参数设置的ALNS，展示了DRL方法在在线控制ALNS方面的有效性。

    The Adaptive Large Neighborhood Search (ALNS) algorithm has shown considerable success in solving complex combinatorial optimization problems (COPs). ALNS selects various heuristics adaptively during the search process, leveraging their strengths to find good solutions for optimization problems. However, the effectiveness of ALNS depends on the proper configuration of its selection and acceptance parameters. To address this limitation, we propose a Deep Reinforcement Learning (DRL) approach that selects heuristics, adjusts parameters, and controls the acceptance criteria during the search process. The proposed method aims to learn, based on the state of the search, how to configure the next iteration of the ALNS to obtain good solutions to the underlying optimization problem. We evaluate the proposed method on a time-dependent orienteering problem with stochastic weights and time windows, used in an IJCAI competition. The results show that our approach outperforms vanilla ALNS and ALNS
    

