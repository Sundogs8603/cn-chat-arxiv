# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [TEDDY: Trimming Edges with Degree-based Discrimination strategY](https://rss.arxiv.org/abs/2402.01261) | TEDDY是一种利用边缘度量信息的边缘修剪方法，旨在通过一次性操作实现边缘稀疏化，进而鼓励参数稀疏化训练。这是一个解决图神经网络中抽奖票假设的时间效率和效果问题的创新方法。 |
| [^2] | [VideoAgent: Long-form Video Understanding with Large Language Model as Agent](https://arxiv.org/abs/2403.10517) | 提出了一种新颖的基于代理的系统VideoAgent，利用大型语言模型作为中央代理，采用互动推理和计划来处理长视频理解问题，在挑战性基准测试中表现出卓越的效果和效率。 |
| [^3] | [FeatUp: A Model-Agnostic Framework for Features at Any Resolution](https://arxiv.org/abs/2403.10516) | FeatUp是一个任务和模型无关的框架，用于在深度特征中恢复丢失的空间信息，从而使特征可以以任何分辨率重建，在现有应用中取得分辨率和性能的提升。 |
| [^4] | [HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation](https://arxiv.org/abs/2403.10506) | 提出了一个高维度的仿真机器人学习基准测试HumanoidBench，揭示了目前最先进的强化学习算法在大多数任务上面临挑战，而具备鲁棒低级策略支持的分层学习基线表现更优秀。 |
| [^5] | [Belief Change based on Knowledge Measures](https://arxiv.org/abs/2403.10502) | 提出了一个基于知识度量的全新信念变化框架，其中包括通用的信息论方法、满足AGM公理的KM-based BC算子以及将满足AGM公理的任何BC算子特征化为基于KM的BC算子。 |
| [^6] | [Benchmarking Zero-Shot Robustness of Multimodal Foundation Models: A Pilot Study](https://arxiv.org/abs/2403.10499) | 本研究通过对多模态基础模型CLIP进行大规模鲁棒性基准测试，揭示了其在涵盖自然分布偏移、合成分布偏移和对抗攻击等多个方面的优异表现。 |
| [^7] | [Stimulate the Potential of Robots via Competition](https://arxiv.org/abs/2403.10487) | 提出了竞争学习框架，通过引入竞争信息激发机器人的潜力，实验证明在竞争环境中训练的机器人表现优越。 |
| [^8] | [Can a GPT4-Powered AI Agent Be a Good Enough Performance Attribution Analyst?](https://arxiv.org/abs/2403.10482) | 大型语言模型和AI代理的整合在绩效归因分析领域标志着一项开创性发展，能自动化和增强投资组合绩效归因分析。 |
| [^9] | [Safety Cases: Justifying the Safety of Advanced AI Systems](https://arxiv.org/abs/2403.10462) | 本研究提出了一个安全案例框架来组织人工智能系统的安全性论证，包括四类论点：完全无法造成灾难，强大的控制措施，尽管有可能造成伤害，但依然可信赖，以及对可信的人工智能顾问的尊重。 |
| [^10] | [Online Concurrent Multi-Robot Coverage Path Planning](https://arxiv.org/abs/2403.10460) | 提出了一种非地平线的集中式算法，实现了在线多机器人覆盖路径规划中的并发规划和执行。 |
| [^11] | [Partially Observable Task and Motion Planning with Uncertainty and Risk Awareness](https://arxiv.org/abs/2403.10454) | 提出了一种具有不确定性和风险意识的TAMP策略（TAMPURA），能够高效地解决具有初始状态和动作结果不确定性的长时程规划问题，包括需要信息收集和避免不良和不可逆结果的问题。 |
| [^12] | [Data Ethics Emergency Drill: A Toolbox for Discussing Responsible AI for Industry Teams](https://arxiv.org/abs/2403.10438) | 该论文介绍了数据伦理紧急演练（DEED）工具箱，帮助数据科学团队讨论和反思工作中的伦理影响，通过角色扮演虚构伦理紧急情景，开启了关于伦理问题的讨论。 |
| [^13] | [AI-enhanced Collective Intelligence: The State of the Art and Prospects](https://arxiv.org/abs/2403.10433) | 人类和人工智能形成的多层次集体智能网络，可以实现超越任一单独实体的集体智能水平。 |
| [^14] | [NeuFlow: Real-time, High-accuracy Optical Flow Estimation on Robots Using Edge Devices](https://arxiv.org/abs/2403.10425) | NeuFlow是一种高效的光流架构，通过全局到局部的方案，实现了高精度光流估计，并解决了计算成本问题。 |
| [^15] | [Gradient based Feature Attribution in Explainable AI: A Technical Review](https://arxiv.org/abs/2403.10415) | 这项技术评估系统地探讨了基于梯度的解释方法，并引入了一个新颖的分类法将其归类为四个不同类别 |
| [^16] | [Energy Correction Model in the Feature Space for Out-of-Distribution Detection](https://arxiv.org/abs/2403.10403) | 通过在特征空间中学习内部分布特征密度的能量校正模型，本文提出了一种在异常检测中取得竞争性结果的方法 |
| [^17] | [SculptDiff: Learning Robotic Clay Sculpting from Humans with Goal Conditioned Diffusion Policy](https://arxiv.org/abs/2403.10401) | 通过SculptDiff，我们提出了一种目标条件扩散策略学习框架，成功实现了对3D可变形物体的操作策略学习。 |
| [^18] | [BirdSet: A Multi-Task Benchmark for Classification in Avian Bioacoustics](https://arxiv.org/abs/2403.10380) | 提出了BirdSet基准，用于鸟类生物声学中的分类任务，整合开源鸟类录音数据集合，全面评估模型性能和识别潜在不足。 |
| [^19] | [An Energy-Efficient Ensemble Approach for Mitigating Data Incompleteness in IoT Applications](https://arxiv.org/abs/2403.10371) | 提出了一种用于缓解物联网应用中数据不完整性的节能集成方法ENAMLE，旨在解决SECOE的能源瓶颈问题 |
| [^20] | [Scalable Algorithms for Individual Preference Stable Clustering](https://arxiv.org/abs/2403.10365) | 研究了个人偏好稳定聚类的可扩展算法，通过局部搜索获得了 $O(\log n)$-IP 稳定性保证，并且在几乎线性时间内运行。 |
| [^21] | [Unsupervised Threat Hunting using Continuous Bag-of-Terms-and-Time (CBoTT)](https://arxiv.org/abs/2403.10327) | 提出CBoTT框架用于无监督威胁猎杀在SIEM日志中能够更准确地识别异常活动，性能优于基准方法，可帮助研究人员和网络安全分析员进行威胁猎杀。 |
| [^22] | [CDGP: Automatic Cloze Distractor Generation based on Pre-trained Language Model](https://arxiv.org/abs/2403.10326) | 本文研究了通过应用预训练语言模型作为候选干扰项生成的替代方法来自动生成填空干扰项，并展示了这种PLM增强模型显著提高了性能。 |
| [^23] | [KIF: A Framework for Virtual Integration of Heterogeneous Knowledge Bases using Wikidata](https://arxiv.org/abs/2403.10304) | KIF框架利用Wikidata作为通用语言，结合用户定义的映射，实现了异构知识库的虚拟集成，形成类似于扩展Wikidata的虚拟知识库，可通过过滤接口或SPARQL进行查询。 |
| [^24] | [A Multi-constraint and Multi-objective Allocation Model for Emergency Rescue in IoT Environment](https://arxiv.org/abs/2403.10299) | 这个多约束多目标分配模型在紧急救援场景中优化资源分配方面取得了显著进展。 |
| [^25] | [Rough Transformers for Continuous and Efficient Time-Series Modelling](https://arxiv.org/abs/2403.10288) | 提出了粗糙Transformer，用于在连续时间表示的输入序列上进行操作，大大降低了计算成本，对于处理医疗情境中的长程依赖性至关重要。 |
| [^26] | [Team Trifecta at Factify5WQA: Setting the Standard in Fact Verification with Fine-Tuning](https://arxiv.org/abs/2403.10281) | Team Trifecta在Factify 5WQA上以Fine-Tuning取得了首要地位，成功超越基准准确率103％，并保持了对第二名竞争者的70%领先优势。 |
| [^27] | [A Question on the Explainability of Large Language Models and the Word-Level Univariate First-Order Plausibility Assumption](https://arxiv.org/abs/2403.10275) | 本文提出了一个方法来挑战为大型语言模型提供简单而丰富解释的可能性，研究发现使用基于特征的模型在信号传递方面效果更好。 |
| [^28] | [Comprehensive Study Of Predictive Maintenance In Industries Using Classification Models And LSTM Model](https://arxiv.org/abs/2403.10259) | 该研究探讨利用分类模型和LSTM模型在工业中进行预测性维护的方法，通过人工智能技术实现对机器故障更准确和高效的预测和分析。 |
| [^29] | [A Survey on Game Playing Agents and Large Models: Methods, Applications, and Challenges](https://arxiv.org/abs/2403.10249) | 本文对大型模型在复杂游戏场景中的使用进行了全面的检查，总结了基于LM的游戏代理的现有架构、挑战和未来研究方向。 |
| [^30] | [Less is More: One-shot Subgraph Reasoning on Large-scale Knowledge Graphs](https://arxiv.org/abs/2403.10231) | 提出了一种在大规模知识图谱上进行高效和自适应预测的一次性子图链接预测方法，通过将预测过程分解为从查询中提取一个子图并在该单个、查询相关子图上进行预测的两个步骤，利用非参数化和计算高效的启发式方法来提高效率。 |
| [^31] | [HawkEye: Training Video-Text LLMs for Grounding Text in Videos](https://arxiv.org/abs/2403.10228) | 本文提出了HawkEye，一个可以以完全文本方式执行时间视频定位的视频文本LLMs，并通过构建大规模视频文本语料库InternVid-G以及引入两个新的面向时间的训练目标，以及一种新的粗粒度表示视频段的方法来实现这一目标。 |
| [^32] | [From Chaos to Clarity: Time Series Anomaly Detection in Astronomical Observations](https://arxiv.org/abs/2403.10220) | 提出了AERO，一个专为天文观测中无监督异常检测量身定制的新颖两阶段框架，擅长处理天文观测中独立但受到随机并发噪声干扰的特征。 |
| [^33] | [Exploring Optical Flow Inclusion into nnU-Net Framework for Surgical Instrument Segmentation](https://arxiv.org/abs/2403.10216) | 在nnU-Net框架中探索光流的应用以提高外科器械分割质量，利用光流图作为附加输入，提高了模型在外科器械分割任务中的性能 |
| [^34] | [Read between the lines -- Functionality Extraction From READMEs](https://arxiv.org/abs/2403.10205) | 本文介绍了一种新颖的文本处理任务——从 Git README 文件中提取功能，研究动机源自对大型语言模型在代码相关任务中应用的兴趣，通过开发小型微调模型，取得了70%和20%的性能提升。 |
| [^35] | [Learning on JPEG-LDPC Compressed Images: Classifying with Syndromes](https://arxiv.org/abs/2403.10202) | 在这篇论文中，提出了一种在JPEG-LDPC压缩图像上进行分类的方法，通过利用LDPC码的内部代码结构，使用GRU进行训练，从而实现了高效的图像分类。 |
| [^36] | [Perceptual Quality-based Model Training under Annotator Label Uncertainty](https://arxiv.org/abs/2403.10190) | 标注者标签不确定性影响模型泛化能力和预测不确定性，现有不确定性估计算法无法应对，提出一种基于感知质量的训练方法以缓解性能下降 |
| [^37] | [Grasp Anything: Combining Teacher-Augmented Policy Gradient Learning with Instance Segmentation to Grasp Arbitrary Objects](https://arxiv.org/abs/2403.10187) | 提出了一种新颖的两阶段学习框架TAPG，将强化学习和策略蒸馏相结合，在抓取任意物体时取得了良好表现。 |
| [^38] | [Lifted Causal Inference in Relational Domains](https://arxiv.org/abs/2403.10184) | 本文展示了在关系领域中如何利用抬升技术高效计算因果效应，引入了参数化因果因子图，并提出了抬升因果推断算法，显著加快了因果推断速度。 |
| [^39] | [A Short Survey on Importance Weighting for Machine Learning](https://arxiv.org/abs/2403.10175) | 重要性加权是统计学和机器学习中的基本程序，通过对目标函数或概率分布进行加权，可以保证监督学习在训练和测试分布之间差异的情况下具有统计上期望的性质 |
| [^40] | [A Hybrid SNN-ANN Network for Event-based Object Detection with Spatial and Temporal Attention](https://arxiv.org/abs/2403.10173) | 提出了一种用于基于事件的对象检测的混合SNN-ANN网络，包括了新颖的基于注意力的桥接模块，能够有效捕捉稀疏的空间和时间关系，以提高任务性能。 |
| [^41] | [AUTONODE: A Neuro-Graphic Self-Learnable Engine for Cognitive GUI Automation](https://arxiv.org/abs/2403.10171) | AUTONODE是一种神经图自学习引擎，通过先进的神经图技术实现自主导航和任务执行，从而提升了智能代理人在网络界面上适应动态环境的效率。 |
| [^42] | [Efficient Detection of Exchangeable Factors in Factor Graphs](https://arxiv.org/abs/2403.10167) | 提出了一种在因子图中高效检测可交换因子的算法，可以大大减少计算工作量。 |
| [^43] | [CoReEcho: Continuous Representation Learning for 2D+time Echocardiography Analysis](https://arxiv.org/abs/2403.10164) | CoReEcho提出了针对直接EF回归的连续表示学习框架，在最大的超声心动图数据集上表现优越。 |
| [^44] | [Functional Graph Convolutional Networks: A unified multi-task and multi-modal learning framework to facilitate health and social-care insights](https://arxiv.org/abs/2403.10158) | 该论文提出了一个新颖的函数图卷积网络框架，结合了函数数据分析和图卷积网络，解决了数字健康和纵向研究中的多任务和多模态学习复杂性，关键创新包括任务特定嵌入组件、执行分类、回归和预测的能力，以及创建知识图进行数据解释。 |
| [^45] | [NLP Verification: Towards a General Methodology for Certifying Robustness](https://arxiv.org/abs/2403.10144) | 本文尝试总结和评估由该领域迄今进展而形成的NLP验证流程的一般组成部分，贡献在于提出了将句子嵌入连续空间得到的可验证子空间的一般描述。 |
| [^46] | [Response Style Characterization for Repeated Measures Using the Visual Analogue Scale](https://arxiv.org/abs/2403.10136) | 本研究针对重复测量的视觉模拟量表数据开发了一种新颖的响应风格（RP）表征方法，以解决在VAS中处理RP的困难。 |
| [^47] | [The Whole is Better than the Sum: Using Aggregated Demonstrations in In-Context Learning for Sequential Recommendation](https://arxiv.org/abs/2403.10135) | 探索在顺序推荐中使用上下文学习的方法，提出了一种聚合演示的新颖方法LLMSRec-Syn，在多个数据集上实验证明其优于现有基于LLM的方法。 |
| [^48] | [RAFT: Adapting Language Model to Domain Specific RAG](https://arxiv.org/abs/2403.10131) | 提出了一种名为RAFT的训练方法，通过引用相关文档中能够帮助回答问题的正确序列来改善模型在特定领域中回答问题的能力。 |
| [^49] | [Single- and Multi-Agent Private Active Sensing: A Deep Neuroevolution Approach](https://arxiv.org/abs/2403.10112) | 本文提出了一种基于神经进化方法的单智能体与多智能体私密主动感知框架，通过在无线传感器网络中进行异常检测示例用例的数值实验验证了该方法的优越性。 |
| [^50] | [Meta Operator for Complex Query Answering on Knowledge Graphs](https://arxiv.org/abs/2403.10110) | 本研究提出了一种元学习算法，用于在知识图谱上回答复杂查询，通过学习元算子并将其适应于各种复杂查询，实现了泛化性能的提升。 |
| [^51] | [Enhancing Human-Centered Dynamic Scene Understanding via Multiple LLMs Collaborated Reasoning](https://arxiv.org/abs/2403.10107) | 通过多个大型预训练语言模型的合作推理，本研究提出了V-HOI Multi-LLMs Collaborated Reasoning（V-HOI MLCR）框架，用于增强当前V-HOI检测模型的性能。 |
| [^52] | [Belief Aided Navigation using Bayesian Reinforcement Learning for Avoiding Humans in Blind Spots](https://arxiv.org/abs/2403.10105) | 使用BNBRL+算法，结合部分可观察马尔可夫决策过程和贝叶斯神经网络，实现了在不可观察区域评估风险和制定移动策略的目的，并通过整合动态关系和社会规范，实现了社交感知导航。 |
| [^53] | [Adaptive Random Feature Regularization on Fine-tuning Deep Neural Networks](https://arxiv.org/abs/2403.10097) | 提出了一种名为AdaRand的简单方法，在微调深度神经网络时可以自适应地改变特征向量分布，从而提高性能而不需要辅助源信息。 |
| [^54] | [Intent-conditioned and Non-toxic Counterspeech Generation using Multi-Task Instruction Tuning with RLAIF](https://arxiv.org/abs/2403.10088) | 该研究引入了CoARL框架，通过模拟社会偏见中的语用启示来增强对抗性言论生成，利用顺序多指导调节和强化学习生成意图调节的对抗性言论。 |
| [^55] | [Large Language Models to Generate System-Level Test Programs Targeting Non-functional Properties](https://arxiv.org/abs/2403.10086) | 本文提出使用大型语言模型（LLMs）生成测试程序，以优化非功能属性。 |
| [^56] | [Learning Physical Dynamics for Object-centric Visual Prediction](https://arxiv.org/abs/2403.10079) | 本文提出了一种学习面向物体的视觉预测中的物理动力学的模型，通过学习物体之间的视觉动力学进行未来预测，具有两个关键模块：感知模块和动力模块。 |
| [^57] | [Boundary Matters: A Bi-Level Active Finetuning Framework](https://arxiv.org/abs/2403.10069) | 提出了一个双层主动微调框架，旨在通过一次选择过程来选择注释样本，其中包括核心样本选择以确保多样性和边界样本选择以处理不确定性。 |
| [^58] | [Unified Projection-Free Algorithms for Adversarial DR-Submodular Optimization](https://arxiv.org/abs/2403.10063) | 本文提出了统一的无投影Frank-Wolfe类型算法，用于对抗性DR-次模优化，在不同场景下取得了令人瞩目的次线性 $\alpha$-后悔上界，并在单调设置中实现了无投影算法的最新次线性 $\alpha$-后悔上界。 |
| [^59] | [Don't Half-listen: Capturing Key-part Information in Continual Instruction Tuning](https://arxiv.org/abs/2403.10056) | 提出了一种基于关键部分信息增益的新型连续指导调整方法，通过动态重放数据和优化训练目标，使LLMs能够捕捉任务感知信息和减轻过度拟合。 |
| [^60] | [PPM : A Pre-trained Plug-in Model for Click-through Rate Prediction](https://arxiv.org/abs/2403.10049) | PPM是用于点击率预测的预训练插件模型，克服了传统方法在冷启动问题和训练数据长度上的限制，并能够在工业推荐系统中实现端到端训练。 |
| [^61] | [Towards Embedding Dynamic Personas in Interactive Robots: Masquerading Animated Social Kinematics (MASK)](https://arxiv.org/abs/2403.10041) | 该研究提出了一种名为MASK的机器人系统，通过非言语互动与观众进行互动，并利用有限状态机结构调整机器人行为，实现多种不同角色的动态表达。 |
| [^62] | [Rethinking Low-quality Optical Flow in Unsupervised Surgical Instrument Segmentation](https://arxiv.org/abs/2403.10039) | 本研究在无监督手术器械分割中解决了由于低质量光流而引起的挑战，提出了一种三重策略：直接从光流中提取边界、选择性丢弃质量较差的帧、以及利用可变帧率进行微调。在数据集上进行了充分评估，展示出有前景的结果。 |
| [^63] | [MR-MT3: Memory Retaining Multi-Track Music Transcription to Mitigate Instrument Leakage](https://arxiv.org/abs/2403.10024) | 提出了MR-MT3模型来减少乐器泄漏问题，采用了存储保留机制、先前令牌采样和令牌混洗等增强方法，在Slakh2100数据集上展示了改进的效果。 |
| [^64] | [NNCTC: Physical Layer Cross-Technology Communication via Neural Networks](https://arxiv.org/abs/2403.10014) | NNCTC 是一个基于神经网络的跨技术通信框架，通过将信号处理组件转换为神经模型，实现了无需标记数据进行端到端训练，使系统能够自主推导出最佳的通信有效载荷，显著降低了开发复杂性并展示了可扩展潜力 |
| [^65] | [FBPT: A Fully Binary Point Transformer](https://arxiv.org/abs/2403.09998) | 该论文提出了一个全新的完全二进制点云Transformer模型，通过压缩网络的权重和激活为1位二进制值，显著降低了点云处理任务神经网络模型的存储和计算资源需求。 |
| [^66] | [EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba](https://arxiv.org/abs/2403.09977) | EfficientVMamba是一种新颖的高效模型变体，通过atrous-based selective scan方法实现了轻量级模型设计，克服了准确性和效率之间的权衡挑战。 |
| [^67] | [GET: Unlocking the Multi-modal Potential of CLIP for Generalized Category Discovery](https://arxiv.org/abs/2403.09974) | 本文提出了一种文本嵌入合成器（TES），用于为无标签数据生成伪文本嵌入，以解锁CLIP用于广义类别发现任务中的多模态潜力。 |
| [^68] | [Take Care of Your Prompt Bias! Investigating and Mitigating Prompt Bias in Factual Knowledge Extraction](https://arxiv.org/abs/2403.09963) | 本文调查了预训练语言模型在事实知识提取中存在的“提示偏见”，找到了不同类型提示的偏见程度，以及这种偏见对不同基准测试的影响，并提出了一种基于表示的方法来减轻这种提示偏见。 |
| [^69] | [RadCLIP: Enhancing Radiologic Image Analysis through Contrastive Language-Image Pre-training](https://arxiv.org/abs/2403.09948) | RadCLIP是一种创新的跨模态基础模型，利用对比语言图像预训练以改进放射学图像分析，包含针对体积图像分析定制的新颖3D切片池化机制，并使用丰富多样的放射学图像-文本对数据集进行训练。 |
| [^70] | [Global Convergence Guarantees for Federated Policy Gradient Methods with Adversaries](https://arxiv.org/abs/2403.09940) | 该方法提出了一种基于策略梯度的联邦学习方法，可以在存在对手代理的情况下实现全局收敛保证，并具有对对手的鲁棒性。 |
| [^71] | [Quality-Diversity Actor-Critic: Learning High-Performing and Diverse Behaviors via Value and Successor Features Critics](https://arxiv.org/abs/2403.09930) | QDAC是一种基于离策略演员-评论家深度强化学习算法，通过价值函数评论家和继承特征评论家学习高性能和多样性行为。 |
| [^72] | [Surrogate Assisted Monte Carlo Tree Search in Combinatorial Optimization](https://arxiv.org/abs/2403.09925) | 利用辅助代理模型的蒙特卡洛树搜索在组合优化中可以更快生成解决方案，并且与不使用代理模型的方法相比能够保持一致的解决方案 |
| [^73] | [Predicting Generalization of AI Colonoscopy Models to Unseen Data](https://arxiv.org/abs/2403.09920) | 使用“Masked Siamese Network”（MSN）在未标记数据上识别新现象，并预测结肠镜模型对未知技术和不同国家数据的性能。 |
| [^74] | [FedComLoc: Communication-Efficient Distributed Training of Sparse and Quantized Models](https://arxiv.org/abs/2403.09904) | FedComLoc利用Scaffnew算法的基础，引入了压缩和本地训练，显著降低了分布式训练中的通信开销。 |
| [^75] | [Fisher Mask Nodes for Language Model Merging](https://arxiv.org/abs/2403.09891) | 介绍了一种用于Transformers的新型模型合并方法，利用Fisher信息进行加权平均，提高了多任务模型的性能。 |
| [^76] | [Sabi\'a-2: A New Generation of Portuguese Large Language Models](https://arxiv.org/abs/2403.09887) | Sabi'a-2是一代新的葡萄牙大型语言模型，其中的Sabi'a-2 Medium模型在多个考试中的表现超越了GPT-4，且在大多数考试中超过了GPT-3.5，同时专业化对模型的性能有显著影响，可在无需增大模型尺寸的情况下以比GPT-4便宜10倍的价格提供。 |
| [^77] | [ThermoHands: A Benchmark for 3D Hand Pose Estimation from Egocentric Thermal Image](https://arxiv.org/abs/2403.09871) | ThermoHands提出了一个新的基准ThermoHands，旨在解决热图中主观视角3D手部姿势估计的挑战，介绍了一个具有双transformer模块的定制基线方法TheFormer，表明热成像在恶劣条件下实现稳健的3D手部姿势估计的有效性。 |
| [^78] | [Mind the GAP: Improving Robustness to Subpopulation Shifts with Group-Aware Priors](https://arxiv.org/abs/2403.09869) | 开发了一族组感知先验分布，可以改进神经网络模型在数据分布的亚群体偏移下的泛化能力，并展示了即使只重新训练非鲁棒模型的最后一层，使用这种先验进行训练也能获得最先进的性能。 |
| [^79] | [A Conceptual Framework For White Box Neural Networks](https://arxiv.org/abs/2403.09863) | 引入语义特征作为通用概念框架，实现了完全可解释的神经网络层，为白盒神经网络的范式转变开辟了新的可能性。 |
| [^80] | [NN-Defined Modulator: Reconfigurable and Portable Software Modulator on IoT Gateways](https://arxiv.org/abs/2403.09861) | 使用神经网络作为IoT网关设备中物理层调制器的抽象层，解决了可扩展性和可移植性方面的挑战，并具有硬件加速和异构平台移植的支持。 |
| [^81] | [Few-Shot Class Incremental Learning with Attention-Aware Self-Adaptive Prompt](https://arxiv.org/abs/2403.09857) | 提出了一个名为ASP的框架，通过注意力方面减少特定信息，鼓励任务不变的提示来捕获共享知识，并通过信息瓶颈学习目标从旧类到新类传递知识。 |
| [^82] | [Self-Consistency Boosts Calibration for Math Reasoning](https://arxiv.org/abs/2403.09849) | 基于自洽性的校准方法在数学推理任务中能够更好地建立模型信心和准确性之间的关联。 |
| [^83] | [Forecasting Geoffective Events from Solar Wind Data and Evaluating the Most Predictive Features through Machine Learning Approaches](https://arxiv.org/abs/2403.09847) | 本研究利用机器学习技术预测地磁扰动，通过长短期记忆循环神经网络分析太阳风数据，针对强类别不平衡问题设计适当损失函数，并采用价值加权技能评分评估预测效果。 |
| [^84] | [Towards the Reusability and Compositionality of Causal Representations](https://arxiv.org/abs/2403.09830) | 该研究提出了DECAF框架，旨在从时间序列图像中学习因果表示，使其能够在新环境中进行调整，并在多个相关环境中进行组合，通过与四种最先进的CRL方法结合，能够在新环境中使用少量样本即可获得准确的表示。 |
| [^85] | [LabelAId: Just-in-time AI Interventions for Improving Human Labeling Quality and Domain Knowledge in Crowdsourcing Systems](https://arxiv.org/abs/2403.09810) | 该论文探讨了如何利用即时AI干预来提升众包平台中人类标注质量和领域知识，介绍了LabelAId模型，与传统方法相比，其能够显著提高错误推断准确性。 |
| [^86] | [Self-Supervised Learning for Time Series: Contrastive or Generative?](https://arxiv.org/abs/2403.09809) | 本文对时间序列中的对比和生成自监督学习方法进行了全面比较研究，提供了各种方法的优势和劣势洞察，并为选择合适的SSL方法提供了实用建议。 |
| [^87] | [xLP: Explainable Link Prediction for Master Data Management](https://arxiv.org/abs/2403.09806) | 主数据管理领域的xLP项目通过结合解释性、事实验证、路径排名、神经符号推理和自解释AI等研究成果，创造性地提供了链接预测的解释，并让用户可以选择更符合其需求的解释方式。 |
| [^88] | [Helpful or Harmful? Exploring the Efficacy of Large Language Models for Online Grooming Prevention](https://arxiv.org/abs/2403.09795) | 研究人员探索大型语言模型在在线诱拐预防中的有效性，发现没有模型明显适用于此目的，存在潜在的有害答案生成。 |
| [^89] | [Socially Integrated Navigation: A Social Acting Robot with Deep Reinforcement Learning](https://arxiv.org/abs/2403.09793) | 提出了一种新颖的社会整合导航方法，通过与人的互动使机器人的社交行为自适应，并从其他基于DRL的导航方法中区分出具有明确预定义社交行为的社会意识方法和缺乏社交行为的社会碰撞回避。 |
| [^90] | [Emotional Intelligence Through Artificial Intelligence : NLP and Deep Learning in the Analysis of Healthcare Texts](https://arxiv.org/abs/2403.09762) | 本文系统考察了人工智能在医疗文本中情感分析方面的应用，展示了算法精度、神经退行性疾病预测以及临床决策支持方面的显著进展。 |
| [^91] | [SpokeN-100: A Cross-Lingual Benchmarking Dataset for The Classification of Spoken Numbers in Different Languages](https://arxiv.org/abs/2403.09753) | SpokeN-100是一个跨语言基准数据集，包括四种不同语言中32位不同说话者说出的0到99的口语数字，旨在为微型深度学习领域的语音识别任务提供挑战，同时引入了用于分类语言和口语数字的基准任务。 |
| [^92] | [Explainable Machine Learning-Based Security and Privacy Protection Framework for Internet of Medical Things Systems](https://arxiv.org/abs/2403.09752) | 该论文提出了面向互联网医疗物联网系统的可解释机器学习安全与隐私保护框架，旨在解决IoMT系统面临的安全挑战，包括数据敏感性、恶意攻击和异常检测。 |
| [^93] | [What Was Your Prompt? A Remote Keylogging Attack on AI Assistants](https://arxiv.org/abs/2403.09751) | 本文揭示了一种可以用于读取AI助手加密响应的新型旁路攻击——令牌长度旁路，并展示了如何通过利用大型语言模型，提供句子间上下文并进行已知明文攻击来克服这一挑战。 |
| [^94] | [Meta-Cognitive Analysis: Evaluating Declarative and Procedural Knowledge in Datasets and Large Language Models](https://arxiv.org/abs/2403.09750) | 通过广泛实验探索了LLMs中的陈述性知识和程序性知识对各种任务的影响，发现陈述性知识在大多数任务中的益处大于程序性知识，在简单逻辑推理任务中反之；随着预训练和规模的增加，模型利用两种知识的能力均显著提高。 |
| [^95] | [Towards Diverse Perspective Learning with Selection over Multiple Temporal Poolings](https://arxiv.org/abs/2403.09749) | 提出了一种新颖的时间池化方法SoM-TP，通过多元视角学习实现动态选择最佳时间池化，在单个分类器内实现非迭代池化集成。 |
| [^96] | [Re-Search for The Truth: Multi-round Retrieval-augmented Large Language Models are Strong Fake News Detectors](https://arxiv.org/abs/2403.09747) | 大型语言模型在假新闻检测中引入新的前沿，但仍需克服解决过时知识和低质量证据检索等问题 |
| [^97] | [Evaluating the Application of Large Language Models to Generate Feedback in Programming Education](https://arxiv.org/abs/2403.09744) | 评估了大型语言模型在编程教育中生成反馈的应用，结果显示大多数反馈有效地解决了代码错误，但存在不正确建议和虚构问题，需要进一步改进。 |
| [^98] | [The Human Factor in Detecting Errors of Large Language Models: A Systematic Literature Review and Future Research Directions](https://arxiv.org/abs/2403.09743) | 人工智能领域中，这项研究探索了人类因素在检测大型语言模型的错误输出中的作用，有助于减轻其在专业环境中使用时所带来的风险。 |
| [^99] | [A Short Review on Novel Approaches for Maximum Clique Problem: from Classical algorithms to Graph Neural Networks and Quantum algorithms](https://arxiv.org/abs/2403.09742) | 该综述回顾了解决最大团问题的经典算法，同时也涵盖了图神经网络和量子算法的最新进展，并提出了用于测试这些算法的基准。 |
| [^100] | [Teaching Machines to Code: Smart Contract Translation with LLMs](https://arxiv.org/abs/2403.09740) | 该研究提出了一种开创性方法SolMover，利用两种不同的LLMs协同作用，设计了一个统一的框架，用以将代码翻译为一个陌生的语言 |
| [^101] | [Evaluating Large Language Models as Generative User Simulators for Conversational Recommendation](https://arxiv.org/abs/2403.09738) | 大型语言模型作为生成式用户模拟器在对话推荐中展现出潜力，新的协议通过五个任务评估了语言模型模拟人类行为的准确程度，揭示了模型与人类行为的偏差，并提出了如何通过模型选择和提示策略减少这些偏差。 |
| [^102] | [A Sophisticated Framework for the Accurate Detection of Phishing Websites](https://arxiv.org/abs/2403.09735) | 提出了一个用于准确检测网络钓鱼网站的综合方法论，旨在设计一个系统，能够准确区分钓鱼网站和合法网站，并在各种数据集上提供泛化性能。 |
| [^103] | [Do Large Language Models Solve ARC Visual Analogies Like People Do?](https://arxiv.org/abs/2403.09734) | 该研究比较了人类和大型语言模型在ARC视觉类比问题上的表现，发现在特定任务上，人类和成年人的表现均优于大多数大型语言模型。对LLMs和年幼儿童错误分析揭示了类似的解决策略，同时指出了两种不同的错误类型，为我们理解LLMs如何解决视觉类比问题提供了新的启示。 |
| [^104] | [OverleafCopilot: Empowering Academic Writing in Overleaf with Large Language Models](https://arxiv.org/abs/2403.09733) | OverleafCopilot是第一个无缝集成大型语言模型和Overleaf的工具，使研究人员能够在撰写论文时利用大型语言模型的能力。 |
| [^105] | [PET-SQL: A Prompt-enhanced Two-stage Text-to-SQL Framework with Cross-consistency](https://arxiv.org/abs/2403.09732) | 提出了一个两阶段框架，通过引入参考增强表示和少样本演示，解决了在处理冗长的数据库信息和复杂用户意图时的挑战。 |
| [^106] | [Simulating Weighted Automata over Sequences and Trees with Transformers](https://arxiv.org/abs/2403.09728) | 变压器可以模拟加权有限自动机和加权树自动机，拓展了它们的应用范围。 |
| [^107] | [Investigating the performance of Retrieval-Augmented Generation and fine-tuning for the development of AI-driven knowledge-based systems](https://arxiv.org/abs/2403.09727) | RAG-based constructions are more efficient than models produced with FN for the development of AI-driven knowledge-based systems. |
| [^108] | [RAD-PHI2: Instruction Tuning PHI-2 for Radiology](https://arxiv.org/abs/2403.09725) | 本研究调查了将小语言模型用于放射学领域的应用，通过微调具有27亿参数的Phi-2，提出了具有良好性能的RadPhi-2-Base语言模型。 |
| [^109] | [Prediction of readmission of patients by extracting biomedical concepts from clinical texts](https://arxiv.org/abs/2403.09722) | 从临床文本中提取生物医学概念预测患者的再入院情况，可以帮助医生选择适当的治疗方法，从而减少患者再次入院的比率，实现有效的治疗成本降低。 |
| [^110] | [A Semantic Mention Graph Augmented Model for Document-Level Event Argument Extraction](https://arxiv.org/abs/2403.09721) | 提出了一种语义提及图增强模型（GAM），通过构建语义提及图和引入集成图变换器模块，有效解决了文档级事件论元抽取中的独立建模实体提及和文档提示隔离问题。 |
| [^111] | [Fine-tuning vs Prompting, Can Language Models Understand Human Values?](https://arxiv.org/abs/2403.09720) | 通过对Human Value Detection 2023任务中的微调和提示调整的探索，验证语言模型是否能理解人类价值观。 |
| [^112] | [Mevaker: Conclusion Extraction and Allocation Resources for the Hebrew Language](https://arxiv.org/abs/2403.09719) | 介绍了用于希伯来语言的结论提取模型和数据集，包括摘要和结论提取数据集，并提供了相应模型和代码 |
| [^113] | [Comprehensive Implementation of TextCNN for Enhanced Collaboration between Natural Language Processing and System Recommendation](https://arxiv.org/abs/2403.09718) | TextCNN的全面实现提升了自然语言处理与系统推荐之间的协作，为NLP领域的文本分类任务带来了新的标准技术。 |
| [^114] | [Enhancing Depression-Diagnosis-Oriented Chat with Psychological State Tracking](https://arxiv.org/abs/2403.09717) | 本文提出将心理状态跟踪集成到大型语言模型中，以明确引导抑郁症诊断导向的聊天，从而能更好地捕捉患者在对话过程中的信息、情绪或症状变化。 |
| [^115] | [Linguistic Structure Induction from Language Models](https://arxiv.org/abs/2403.09714) | 该论文研究从语言模型中以非监督方式生成句法结构的方法，其中介绍了一种利用数值表示短语树的新方法。 |
| [^116] | [A Hybrid Intelligence Method for Argument Mining](https://arxiv.org/abs/2403.09713) | 提出了一种混合(人类+AI)方法HyEnA，用于从意见文本中提取论点，结合了自动化处理速度和人类理解推理能力，在公民反馈语料库上取得了更高的覆盖率和准确率。 |
| [^117] | [A Knowledge-Injected Curriculum Pretraining Framework for Question Answering](https://arxiv.org/abs/2403.09712) | 提出了一种通用的知识注入课程预训练框架（KICP），用于实现全面的知识图谱学习和利用以解决KBQA任务。 |
| [^118] | [Schema-Aware Multi-Task Learning for Complex Text-to-SQL](https://arxiv.org/abs/2403.09706) | 提出了一个适用于复杂SQL查询的schema-aware多任务学习框架，通过设计schema链接鉴别器和定义6种关系类型来解决文本到SQL解析中的挑战。 |
| [^119] | [A Novel Nuanced Conversation Evaluation Framework for Large Language Models in Mental Health](https://arxiv.org/abs/2403.09705) | 提出了一种用于评估大型语言模型在心理健康领域微妙对话能力的新框架，并展示GPT4 Turbo可以与已验证的治疗师表现出更相似的结果。 |
| [^120] | [Alignment Studio: Aligning Large Language Models to Particular Contextual Regulations](https://arxiv.org/abs/2403.09704) | 本文提出了 Alignment Studio 架构，使应用开发者能够调整大型语言模型至他们特定的价值观、社会规范、法律和其他法规，并协调潜在冲突的需求。 |
| [^121] | [Concept-aware Data Construction Improves In-context Learning of Language Models](https://arxiv.org/abs/2403.09703) | 该研究提出了概念感知训练（CoAT）框架，用于构建训练场景，让语言模型从演示中学习利用类比推理概念，并发现通过使用CoAT，预训练的transformers可以更好地利用演示中的新潜在概念，使得上下文学习对函数变换更加 robust。 |
| [^122] | [Shapley Values-Powered Framework for Fair Reward Split in Content Produced by GenAI](https://arxiv.org/abs/2403.09700) | 提出了一种利用Shapley Values量化艺术家对生成模型所做贡献的方法，以实现模型开发者和数据提供者之间合作的公平分配。 |
| [^123] | [Pre-Sorted Tsetlin Machine (The Genetic K-Medoid Method)](https://arxiv.org/abs/2403.09680) | 该论文提出了一种利用Tsetlin Machines进行传统监督学习的机器学习预排序阶段方法，在MNIST级别的分类问题上取得了显著的精度提升，以及训练时间和推理时间大幅度减少。 |
| [^124] | [Unmasking the Shadows of AI: Investigating Deceptive Capabilities in Large Language Models](https://arxiv.org/abs/2403.09676) | 该研究探讨了大型语言模型的欺骗行为并分类讨论其引发的社会影响和风险。 |
| [^125] | [FoldToken: Learning Protein Language via Vector Quantization and Beyond](https://arxiv.org/abs/2403.09673) | 通过将蛋白质序列和结构表示为离散符号，并创建新的蛋白质语言，从而构建了一种用于序列-结构共生产的创新方法。 |
| [^126] | [CoRaiS: Lightweight Real-Time Scheduler for Multi-Edge Cooperative Computing](https://arxiv.org/abs/2403.09671) | 提出了一种基于系统级状态评估模型和整数线性规划模型的多边协作计算实时调度器 CoRaiS，以优化分发分布到达的请求，提高多边系统的协作效率。 |
| [^127] | [STREAM: Spatio-TempoRal Evaluation and Analysis Metric for Video Generative Models](https://arxiv.org/abs/2403.09669) | 提出了STREAM，一种新的视频评估度量方法，弥补了当前视频生成模型评估中对于时空特性的不足 |
| [^128] | [Trustworthy Automated Driving through Qualitative Scene Understanding and Explanations](https://arxiv.org/abs/2403.09668) | 我们提出了定性可解释图（QXG），通过将时空图和定性约束应用于传感器数据，能够实现在自动驾驶过程中对场景进行理解和解释，为实时决策提供可靠的场景模型。 |
| [^129] | [On Unsupervised Image-to-image translation and GAN stability](https://arxiv.org/abs/2403.09646) | 本文研究了图像到图像转换中一个经典工作CycleGAN的一些失败案例，并假设这些失败与GAN的稳定性有关。 |
| [^130] | [Logits of API-Protected LLMs Leak Proprietary Information](https://arxiv.org/abs/2403.09539) | 大多数现代LLM受到softmax瓶颈影响，可以以较低成本获取API保护的LLM的非公开信息和解锁多种功能 |
| [^131] | [Predictive Clustering of Vessel Behavior Based on Hierarchical Trajectory Representation](https://arxiv.org/abs/2403.08838) | 提出了一种基于分层轨迹表示的船舶行为预测聚类方法，通过使用预测聚类和潜在编码，可以同时改善聚类和预测，并在实验证明其相对于现有方法的优越性。 |
| [^132] | [Mastering Text, Code and Math Simultaneously via Fusing Highly Specialized Language Models](https://arxiv.org/abs/2403.08281) | 通过融合高度专业化的语言、代码和数学模型，提出了一种名为UltraFuser的融合框架，引入了标记级别的门控机制，并设计了两阶段训练策略，以同时在三个领域取得高性能。 |
| [^133] | [Red Teaming Models for Hyperspectral Image Analysis Using Explainable AI](https://arxiv.org/abs/2403.08017) | 本文介绍了一种使用可解释人工智能的红队建模方法，用于检验高光谱图像上的机器学习模型，并成功构建出一个只使用1%的输入特征即可达到可比较性能的模型。 |
| [^134] | [Standing on FURM ground -- A framework for evaluating Fair, Useful, and Reliable AI Models in healthcare systems](https://arxiv.org/abs/2403.07911) | 开发了一种机制来评估医疗系统中的公平、有用和可靠AI模型，弥合AI模型开发与实际受益之间的鸿沟。 |
| [^135] | [Transforming Competition into Collaboration: The Revolutionary Role of Multi-Agent Systems and Language Models in Modern Organizations](https://arxiv.org/abs/2403.07769) | 文章探讨了基于多Agent系统理论结合大型语言模型的计算实体对人类互动的革新影响，提出了一种可能将专门人工代理支持扩展到操作性组织流程和基于知识和人类编排的战略决策的方式。 |
| [^136] | [An Improved Strategy for Blood Glucose Control Using Multi-Step Deep Reinforcement Learning](https://arxiv.org/abs/2403.07566) | 本文提出了一种使用多步深度强化学习改进血糖控制策略的算法，通过转换BG控制问题的形式化，考虑药物作用的延迟和持久性，提高了效率。 |
| [^137] | [Optimizing Computer Lab Ergonomics in Universities: A Study on Anthropometric Measurements, Furniture Design, and ANOVA Test](https://arxiv.org/abs/2403.05589) | 提出基于人体测量的家具尺寸适合大学生，以改善计算机实验室人体工程学，研究发现其与现有家具尺寸存在显著差异并更加兼容 |
| [^138] | [Algorithmic Identification of Essential Exogenous Nodes for Causal Sufficiency in Brain Networks](https://arxiv.org/abs/2403.05407) | 本研究提出了一种算法识别方法，用于在大脑网络中确定满足关键因果充分性需求的关键外源节点。 |
| [^139] | [DyRoNet: A Low-Rank Adapter Enhanced Dynamic Routing Network for Streaming Perception](https://arxiv.org/abs/2403.05050) | DyRoNet采用低秩动态路由并结合分支网络优化流媒体感知性能，为多种分支选择策略设定了新的性能标杆 |
| [^140] | [ObjectCompose: Evaluating Resilience of Vision-Based Models on Object-to-Background Compositional Changes](https://arxiv.org/abs/2403.04701) | 评估基于视觉的模型对于物体与背景之间多样化变化的鲁棒性，提出一种可以引入不同对象方面变化的方法 |
| [^141] | [TextMonkey: An OCR-Free Large Multimodal Model for Understanding Document](https://arxiv.org/abs/2403.04473) | 该论文提出了一种针对文本中心任务的大型多模态模型，通过引入零初始化的Shifted Window Attention、相似性筛选标记等方式对模型进行增强，同时拓展了模型的能力以提高性能。 |
| [^142] | [MKF-ADS: A Multi-Knowledge Fused Anomaly Detection System for Automotive](https://arxiv.org/abs/2403.04293) | 提出了一种新颖的多知识融合异常检测系统MKF-ADS，采用STcAM和PatchST模块，旨在提高IDS在CAN总线漏洞中的安全性和降低误报警。 |
| [^143] | [RACE-SM: Reinforcement Learning Based Autonomous Control for Social On-Ramp Merging](https://arxiv.org/abs/2403.03359) | 该论文提出了一种基于强化学习的自主控制模型，专注于并行式匝道合流，考虑了道路上其他车辆的影响，并提出了新颖的激励函数。 |
| [^144] | [Large language models surpass human experts in predicting neuroscience results](https://arxiv.org/abs/2403.03230) | 大型语言模型通过整合广泛科学文献中的相关发现，能够优于人类专家预测神经科学实验结果，预示着人类与大型语言模型共同进行发现的未来。 |
| [^145] | [End-to-end Graph-Sequential Representation Learning for Accurate Recommendations](https://arxiv.org/abs/2403.00895) | 本文提出了一个新颖的多重表示学习框架，有效地结合了基于序列和基于图的推荐方法，显著改善了推荐性能。 |
| [^146] | [LLM Inference Unveiled: Survey and Roofline Model Insights](https://arxiv.org/abs/2402.16363) | 本文提出了一个基于Roofline模型的框架，用于系统分析LLM推断技术，帮助识别部署中的瓶颈，并为更有效地部署LLM提供策略。 |
| [^147] | [Learning Semilinear Neural Operators : A Unified Recursive Framework For Prediction And Data Assimilation](https://arxiv.org/abs/2402.15656) | 提出了一种学习半线性神经算子的方法，通过结合预测和校正操作实现了对长时间尺度上时空PDE的解进行处理与数据同化。 |
| [^148] | [A Conversational Brain-Artificial Intelligence Interface](https://arxiv.org/abs/2402.15011) | BAIs利用人工智能代替神经-认知处理管线的部分，让认知功能受损的个体能够通过高层意图完成复杂任务，例如通过主观提供意图完成模拟电话对话。 |
| [^149] | [Zero-shot Explainable Mental Health Analysis on Social Media by incorporating Mental Scales](https://arxiv.org/abs/2402.10948) | 该方法结合心理量表通过LLMs进行零-shot心理健康分析，实验结果表明其优于其他方法 |
| [^150] | [Robust agents learn causal world models](https://arxiv.org/abs/2402.10877) | 智能体必须学习因果模型才能在广泛的分布转变下达到后悔界限，这对迁移学习和因果推断等研究领域有重要影响。 |
| [^151] | [Guiding Large Language Models with Divide-and-Conquer Program for Discerning Problem Solving](https://arxiv.org/abs/2402.05359) | 该论文提出了一种以分治程序引导大型语言模型（LLM）的方法，以解决涉及重复子任务和/或具有欺骗性内容的问题。实验证明，该方法可以提高LLM的表达能力。 |
| [^152] | [Delivery Optimized Discovery in Behavioral User Segmentation under Budget Constrain](https://arxiv.org/abs/2402.03388) | 在预算限制下，我们提出了一种基于随机优化的算法，用于优化传递发现行为用户细分。 |
| [^153] | [Fully Differentiable Correlation-driven 2D/3D Registration for X-ray to CT Image Fusion](https://arxiv.org/abs/2402.02498) | 本论文提出一种全可微相关驱动网络用于X射线与CT图像融合的配准，通过双分支CNN-Transformer编码器实现低频全局特征和高频局部特征的提取和分离，进一步提出相关驱动损失进行特征分解，并应用凸形相似函数学习的训练策略。实验证明，该方法在性能上优于现有的全可微学习配准方法。 |
| [^154] | [Adversarial Training on Purification (AToP): Advancing Both Robustness and Generalization](https://arxiv.org/abs/2401.16352) | 提出了一种新的对净化的对抗训练（AToP）流程，通过随机转换的扰动破坏和通过对抗损失微调净化器模型，同时提升了鲁棒性和泛化性能。 |
| [^155] | [Survey of Natural Language Processing for Education: Taxonomy, Systematic Review, and Future Trends](https://arxiv.org/abs/2401.07518) | 这篇论文调查了教育领域自然语言处理的最新进展，提出了分类体系，并总结了挑战和未来研究方向。 |
| [^156] | [Generative AI in EU Law: Liability, Privacy, Intellectual Property, and Cybersecurity](https://arxiv.org/abs/2401.07348) | 生成式人工智能和大型语言模型在欧盟法律法规中的应用引发了责任、隐私、知识产权和网络安全等方面的挑战，本文对现有和拟议的法律进行了批判性分析，并提出了改进建议。 |
| [^157] | [Brain Tumor Segmentation Based on Deep Learning, Attention Mechanisms, and Energy-Based Uncertainty Prediction](https://arxiv.org/abs/2401.00587) | 该论文提出了一种基于深度学习、注意机制和基于能量的不确定性预测的脑肿瘤分割方法，通过感兴趣区域检测算法和全卷积自动编码器实现了更快速、准确的诊断。 |
| [^158] | [VideoPoet: A Large Language Model for Zero-Shot Video Generation](https://arxiv.org/abs/2312.14125) | VideoPoet是一种大型语言模型，能够从多种条件信号中生成高质量视频及匹配音频，并且在零样本视频生成领域展示了最先进的能力。 |
| [^159] | [Learning Flexible Body Collision Dynamics with Hierarchical Contact Mesh Transformer](https://arxiv.org/abs/2312.12467) | 本文提出了一种使用分层网格结构的Hierarchical Contact Mesh Transformer（HCMT），能够学习长距离依赖关系，以处理灵活体动力学挑战。 |
| [^160] | [The Generalization Gap in Offline Reinforcement Learning](https://arxiv.org/abs/2312.05742) | 该研究比较了在线和离线学习方法在泛化能力上的差异，发现离线学习算法在新环境中表现不如在线学习算法，并引入了用于评估泛化能力的第一个基准测试。 |
| [^161] | [Retrieving Conditions from Reference Images for Diffusion Models](https://arxiv.org/abs/2312.02521) | 本文将主题驱动生成视为扩散模型中的一个统一检索问题，引入了一种名为RetriNet的新颖扩散模型架构，通过精确检索主题属性并过滤无关信息来解决问题，在人脸生成方面表现出卓越性能。 |
| [^162] | [MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction-Following](https://arxiv.org/abs/2312.02436) | MUFFIN是一个新的指示遵循数据集策划方案，通过自动按比例扩大任务，通过多种输入方面使任务丰富多样。 |
| [^163] | [EMDM: Efficient Motion Diffusion Model for Fast and High-Quality Motion Generation](https://arxiv.org/abs/2312.02256) | 提出了高效动态扩散模型（EMDM），能够在更少的采样步骤中实现快速且高质量的动作生成 |
| [^164] | [Deep Regularized Compound Gaussian Network for Solving Linear Inverse Problems](https://arxiv.org/abs/2311.17248) | 提出了两种允许在复合高斯分布类中进行问题特定统计先验选择的线性逆问题新方法，一种是迭代算法广义复合高斯最小二乘，另一种是通过展开得到的新颖深度正则化神经网络DR-CG-Net。 |
| [^165] | [High-fidelity Person-centric Subject-to-Image Synthesis](https://arxiv.org/abs/2311.10329) | 提出了Face-diffuser，一个有效的协作生成流水线，用于解决主体到图像合成中的训练不平衡和质量妥协问题。 |
| [^166] | [zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large Language Models](https://arxiv.org/abs/2311.10112) | 本文提出了一种在时间知识图上进行零样本关系学习的方法，该方法利用大型语言模型(LLM)生成关系表示，并将其引入基于嵌入的TKGF方法中，能够捕捉关系描述中的语义信息，从而使得关系在建模时能具有相似的语义含义。 |
| [^167] | [Finetuning Text-to-Image Diffusion Models for Fairness](https://arxiv.org/abs/2311.07604) | 将公平性视为分布对齐问题，通过分布对齐损失和调整DFT两项技术贡献，显著减少文本到图像扩散模型中的性别、种族和其交叉偏见。 |
| [^168] | [Think Before You Speak: Cultivating Communication Skills of Large Language Models via Inner Monologue](https://arxiv.org/abs/2311.07445) | 通过内在思考，本研究通过语言学和认知科学的灵感，赋予大型语言模型沟通技能，从而提高其拟人化和主动性，吸引用户进行更长时间的对话 |
| [^169] | [LILO: Learning Interpretable Libraries by Compressing and Documenting Code](https://arxiv.org/abs/2310.19791) | LILO是一种神经符号框架，通过迭代地合成、压缩和文档化代码来构建可解释且适用于特定问题领域的程序库。在其中，LILO结合了大型语言模型引导的程序合成和程序自动重构的算法进展，并且通过自动文档过程使得代码抽象可解释并提升性能。 |
| [^170] | [Does CLIP's Generalization Performance Mainly Stem from High Train-Test Similarity?](https://arxiv.org/abs/2310.09562) | CLIP在经过重现ImageNet训练-测试相似性的剪枝LAION分割重新训练后，虽然在某些基准上表现有所下降，但整体性能仍然很高 |
| [^171] | [Machine Unlearning: Solutions and Challenges](https://arxiv.org/abs/2308.07061) | 本文提供了对机器遗忘解决方案的全面分类和分析，明确了完全遗忘方法和近似遗忘方法，并讨论了它们的优势和局限性，提出了推进机器遗忘的未来方向。 |
| [^172] | [Comprehending Semantic Types in JSON Data with Graph Neural Networks](https://arxiv.org/abs/2307.12807) | 提出了一种使用图神经网络在JSON数据中标记语义类型的方法 |
| [^173] | [Cross-domain Random Pre-training with Prototypes for Reinforcement Learning](https://arxiv.org/abs/2302.05614) | 提出了CRPTpro框架，利用原型进行跨领域自监督随机预训练，提高预训练效率，并实现在不同领域中定义的视觉控制RL任务。 |
| [^174] | [Lowering Detection in Sport Climbing Based on Orientation of the Sensor Enhanced Quickdraw](https://arxiv.org/abs/2301.10164) | 通过在攀岩快挂上安装的加速度传感器采集数据，实现了在攀岩活动中检测攀岩者下降情况的技术，保护攀岩者隐私和健身房成本的同时提高了效率和便利性。 |
| [^175] | [Bridging Implicit and Explicit Geometric Transformation for Single-Image View Synthesis](https://arxiv.org/abs/2209.07105) | 提出了一种单图像视图合成框架，通过结合显式和隐式的几何变换，利用高效的非自回归模型，解决了“跷跷板”问题。 |
| [^176] | [Continuous QA Learning with Structured Prompts](https://arxiv.org/abs/2208.14602) | 提出了一种名为Diana的动态架构终身QA模型，通过增强语言模型学习一系列QA任务，并使用四种层次组织的提示来捕获不同粒度的QA知识，以提高模型的泛化性能。 |
| [^177] | [Extraction of Sleep Information from Clinical Notes of Patients with Alzheimer's Disease Using Natural Language Processing](https://arxiv.org/abs/2204.09601) | 通过自然语言处理从临床记录中提取睡眠信息，为研究睡眠与阿尔茨海默病发病关联提供了新的方法和工具 |
| [^178] | [MMO: Meta Multi-Objectivization for Software Configuration Tuning](https://arxiv.org/abs/2112.07303) | 提出了一种元多目标化（MMO）模型，将辅助性能目标用于使表现相似但配置不同的配置难以比较，从而防止搜索陷入局部最优解 |
| [^179] | [Learning Markov State Abstractions for Deep Reinforcement Learning](https://arxiv.org/abs/2106.04379) | 引入了一组新颖条件，证明了学习马尔可夫抽象状态表示的充分性，并提出了结合逆模型估计和时间对比学习的实用训练过程，该方法适用于在线和离线训练，不依赖奖励信号但可以利用奖励信息。 |
| [^180] | [Energy-based Automated Model Evaluation.](http://arxiv.org/abs/2401.12689) | 提出了一种基于能量的自动化模型评估方法，通过建立关于个体样本相关信息的元分布统计量，能够更高效和有效地评估机器学习模型的性能，解决了AutoEval框架中的过度自信、存储和计算成本高等问题。 |
| [^181] | [Revisiting Zero-Shot Abstractive Summarization in the Era of Large Language Models from the Perspective of Position Bias.](http://arxiv.org/abs/2401.01989) | 这项研究通过测量位置偏见，重访了大语言模型中的零-shot 抽象摘要。研究结果揭示了模型不公平地优先考虑某些部分的信息，从而导致不可取的行为。对多个LLM模型和预训练抽象摘要模型进行的实验提供了关于零-shot 总结任务的模型性能和位置偏见的新见解和讨论。 |
| [^182] | [Intriguing Properties of Data Attribution on Diffusion Models.](http://arxiv.org/abs/2311.00500) | 本研究通过对扩散模型进行实验和分析，发现在数据归因方面，一些在理论上不合理的设计选择能够在实际中表现出比以前的方法更好的效果。这对于确保数据贡献者公平补偿或认可具有重要意义。 |
| [^183] | [Debiasing Algorithm through Model Adaptation.](http://arxiv.org/abs/2310.18913) | 本论文提出了一种通过模型适应来检测和减轻语言模型中性别偏见的方法，并证明了该方法能够显著减少偏见同时保持模型性能。 |
| [^184] | [DyST: Towards Dynamic Neural Scene Representations on Real-World Videos.](http://arxiv.org/abs/2310.06020) | DyST模型通过学习动态场景的潜在分解，从实际视频中捕捉到了场景的3D结构和动态特性，并实现了对相机和场景内容的独立控制视图生成。 |
| [^185] | [Neur2RO: Neural Two-Stage Robust Optimization.](http://arxiv.org/abs/2310.04345) | Neur2RO是一种神经网络驱动的二阶段鲁棒优化算法，通过学习估计第二阶段问题的值函数，并嵌入到经典的列-约束生成算法中，能够高效地求解嵌套的最小-最大-最小优化问题。 |
| [^186] | [SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training.](http://arxiv.org/abs/2310.02227) | SNIP引入了一种统一的预训练框架，通过联合对比学习加强了符号和数值领域之间的相似性，并提供了跨领域的表示洞察力。 |
| [^187] | [JoMA: Demystifying Multilayer Transformers via JOint Dynamics of MLP and Attention.](http://arxiv.org/abs/2310.00535) | 本文提出了联合MLP/注意力（JoMA）动态，用于解析多层Transformer架构的训练过程。通过预测非线性激活情况下注意力的行为，我们解释了多层Transformer中标记的层次组合方法。实验证实了我们的理论发现。 |
| [^188] | [Identifying confounders in deep-learning-based model predictions using DeepRepViz.](http://arxiv.org/abs/2309.15551) | 这项研究提出了DeepRepViz框架，用于帮助研究人员在深度学习模型预测中识别混淆因素，并通过度量和可视化工具来解决这个问题。实验证明使用DeepRepViz与DL模型结合能够带来明显的益处。 |
| [^189] | [Transferring climate change knowledge.](http://arxiv.org/abs/2309.14780) | 通过转移学习方法，研究表明机器学习，尤其是深度神经网络，可以通过充分利用地球系统模型模拟和历史观测所获得的知识，更准确地预测21世纪的全球表面温度场。 |
| [^190] | [Traveling Waves Encode the Recent Past and Enhance Sequence Learning.](http://arxiv.org/abs/2309.08045) | 本论文介绍了Wave-RNN (wRNN)模型，展示了旅行波机制如何有效地编码最近的过去，并在合成记忆任务中比波动模型表现更好。 |
| [^191] | [When Geoscience Meets Foundation Models: Towards General Geoscience Artificial Intelligence System.](http://arxiv.org/abs/2309.06799) | 地球科学基础模型通过整合大量跨学科数据来模拟和理解地球系统动态，具有广阔的应用前景和创新潜力，但仍面临验证和核实、规模性、可解释性、知识表示和社会偏差等挑战。 |
| [^192] | [Speech Emotion Recognition with Distilled Prosodic and Linguistic Affect Representations.](http://arxiv.org/abs/2309.04849) | 该论文提出了EmoDistill，这是一个利用知识蒸馏来学习从语音中获取情感的强大的语言和语音表示的语音情感识别框架。通过在训练过程中利用经过SER微调的预训练语音和语言教师进行信息蒸馏，该方法在IEMOCAP基准测试中实现了最新的最高准确率，表明其在单模态和多模态技术中的优越性能。 |
| [^193] | [Cognitive Architectures for Language Agents.](http://arxiv.org/abs/2309.02427) | 本文提出了一种称为CoALA的认知架构，用于组织语言代理的现有研究并规划未来的发展方向。CoALA描述了一个具有模块化记忆组件、结构化行动空间和通用决策过程的语言代理。通过这一框架，有望发展出更强大的语言代理。 |
| [^194] | [Can transformers learn the greatest common divisor?.](http://arxiv.org/abs/2308.15594) | 本文研究了小型变形金刚模型计算最大公约数的能力。通过选择合适的训练分布和表示基准，模型可以达到高准确率，并在预测中表现出明确的模式。 |
| [^195] | [Distilling Knowledge for Short-to-Long Term Trajectory Prediction.](http://arxiv.org/abs/2305.08553) | 本文提出了一种新的方法Di-Long，用于解决长期轨迹预测中越来越不确定和不可预测的问题。该方法利用蒸馏短期轨迹模型预测器来指导训练过程中的长期轨迹预测学生网络。学生网络观察短序列并预测长轨迹，教师网络观察更长序列并预测剩余短目标轨迹。 |
| [^196] | [Musketeer (All for One, and One for All): A Generalist Vision-Language Model with Task Explanation Prompts.](http://arxiv.org/abs/2305.07019) | Musketeer是一种通用视觉语言模型，采用任务解释提示（TEP）机制，能够有效整合异构任务的知识，并在多个任务中表现均匀 |
| [^197] | [Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models.](http://arxiv.org/abs/2304.11657) | 本文提出 Iter-CoT 方法，在大型语言模型中进行迭代增强的思维链提示，通过选择具有适度难度的具有挑战性但可回答的问题，并伴随推理链作为示例，提高了模型的泛化能力，同时使模型能够更准确地生成推理链。 |
| [^198] | [An Ecosystem for Personal Knowledge Graphs: A Survey and Research Roadmap.](http://arxiv.org/abs/2304.09572) | 本论文提出了一个个人知识图谱（PKG）的生态系统，PKG的主要目的是数据管理和个性化服务。要解锁PKG的全部潜力，需要一个统一的框架，并提出了一个关于PKG的综合视图。 |
| [^199] | [Extracting Physical Rehabilitation Exercise Information from Clinical Notes: a Comparison of Rule-Based and Machine Learning Natural Language Processing Techniques.](http://arxiv.org/abs/2303.13466) | 本文提出了一种基于规则的自然语言处理算法，用于从临床笔记中提取卒中患者治疗过程的锻炼信息，并与几个小型机器学习模型进行比较。在足够的数据可用的情况下，我们的算法在提取一半的概念方面优于这些模型，并且每个概念的个体运动描述可以分配二进制标签，并且F值不低于0.75。这些算法表现出了准确提取临床笔记中康复治疗锻炼信息的前景。 |
| [^200] | [Softmax-free Linear Transformers.](http://arxiv.org/abs/2207.03341) | 这项研究提出了无softmax的线性变换器(SOFT)，用高斯核函数来逼近自注意机制，以改善视觉识别领域中现有方法的局限性。 |

# 详细

[^1]: TEDDY: 基于度量判别策略的边缘修剪方法

    TEDDY: Trimming Edges with Degree-based Discrimination strategY

    [https://rss.arxiv.org/abs/2402.01261](https://rss.arxiv.org/abs/2402.01261)

    TEDDY是一种利用边缘度量信息的边缘修剪方法，旨在通过一次性操作实现边缘稀疏化，进而鼓励参数稀疏化训练。这是一个解决图神经网络中抽奖票假设的时间效率和效果问题的创新方法。

    

    自从Chen等人在2021年提出用于图神经网络（GNNs）的抽奖票假设的开创性工作以来，寻找图抽奖票（GLT）的研究已成为GNN社区的重要关注点之一，激发了研究人员在实现与原始密集网络相当性能的同时，发现更稀疏的GLT。同时，图结构作为GNN训练动力学的重要因素，也受到了广泛关注，并得到了最近几项研究的阐明。尽管如此，目前关于GLT的研究通常没有充分利用图结构中的内在路径，并以迭代方式识别票数，这种方法耗时且效率低下。为解决这些限制，我们引入TEDDY，一种利用结构信息并整合边缘度量信息的一次性边缘稀疏化框架。在进行边缘稀疏化后，我们通过简单的投影梯度下降方法鼓励参数稀疏化训练。

    Since the pioneering work on the lottery ticket hypothesis for graph neural networks (GNNs) was proposed in Chen et al. (2021), the study on finding graph lottery tickets (GLT) has become one of the pivotal focus in the GNN community, inspiring researchers to discover sparser GLT while achieving comparable performance to original dense networks. In parallel, the graph structure has gained substantial attention as a crucial factor in GNN training dynamics, also elucidated by several recent studies. Despite this, contemporary studies on GLT, in general, have not fully exploited inherent pathways in the graph structure and identified tickets in an iterative manner, which is time-consuming and inefficient. To address these limitations, we introduce TEDDY, a one-shot edge sparsification framework that leverages structural information by incorporating edge-degree information. Following edge sparsification, we encourage the parameter sparsity during training via simple projected gradient desc
    
[^2]: 基于大型语言模型的视频代理：长视频理解

    VideoAgent: Long-form Video Understanding with Large Language Model as Agent

    [https://arxiv.org/abs/2403.10517](https://arxiv.org/abs/2403.10517)

    提出了一种新颖的基于代理的系统VideoAgent，利用大型语言模型作为中央代理，采用互动推理和计划来处理长视频理解问题，在挑战性基准测试中表现出卓越的效果和效率。

    

    长视频理解在计算机视觉中代表着一个重大挑战，需要一个能够推理长时间多模态序列的模型。受人类认知长视频过程的启发，我们强调互动推理和计划，而不是处理长篇视觉输入的能力。我们引入了一个新颖的基于代理的系统VideoAgent，它采用大型语言模型作为中央代理，迭代地识别和整理关键信息以回答问题，视觉语言基础模型作为工具来翻译和检索视觉信息。在具有挑战性的EgoSchema和NExT-QA基准测试中，VideoAgent在平均仅使用8.4和8.2帧的情况下分别实现了54.1%和71.3%的零-shot准确率。这些结果展示了我们方法相对于当前最先进方法的卓越效果和效率，突出了代理模型的潜力。

    arXiv:2403.10517v1 Announce Type: cross  Abstract: Long-form video understanding represents a significant challenge within computer vision, demanding a model capable of reasoning over long multi-modal sequences. Motivated by the human cognitive process for long-form video understanding, we emphasize interactive reasoning and planning over the ability to process lengthy visual inputs. We introduce a novel agent-based system, VideoAgent, that employs a large language model as a central agent to iteratively identify and compile crucial information to answer a question, with vision-language foundation models serving as tools to translate and retrieve visual information. Evaluated on the challenging EgoSchema and NExT-QA benchmarks, VideoAgent achieves 54.1% and 71.3% zero-shot accuracy with only 8.4 and 8.2 frames used on average. These results demonstrate superior effectiveness and efficiency of our method over the current state-of-the-art methods, highlighting the potential of agent-base
    
[^3]: FeatUp: 一个与模型无关的特征任意分辨率框架

    FeatUp: A Model-Agnostic Framework for Features at Any Resolution

    [https://arxiv.org/abs/2403.10516](https://arxiv.org/abs/2403.10516)

    FeatUp是一个任务和模型无关的框架，用于在深度特征中恢复丢失的空间信息，从而使特征可以以任何分辨率重建，在现有应用中取得分辨率和性能的提升。

    

    深度特征是计算机视觉研究的基石，捕捉图像语义并使社区能够解决下游任务，即使在零或少样本情况下也能做到。然而，这些特征通常缺乏空间分辨率，无法直接执行像分割和深度预测这样的稠密预测任务，因为模型会过于聚合大范围的信息。在这项工作中，我们介绍了FeatUp，一个任务和模型无关的框架，用于恢复深度特征中丢失的空间信息。我们介绍了FeatUp的两个变体：一个在单次前向传递中引导具有高分辨率信号的特征，另一个适应单个图像并以任何分辨率重构特征的隐式模型。这两种方法都使用了一个具有与 NeRF 类似的深度类比的多视图一致性损失。我们的特征保留其原始语义，并可以替换现有应用程序，即使不重新

    arXiv:2403.10516v1 Announce Type: cross  Abstract: Deep features are a cornerstone of computer vision research, capturing image semantics and enabling the community to solve downstream tasks even in the zero- or few-shot regime. However, these features often lack the spatial resolution to directly perform dense prediction tasks like segmentation and depth prediction because models aggressively pool information over large areas. In this work, we introduce FeatUp, a task- and model-agnostic framework to restore lost spatial information in deep features. We introduce two variants of FeatUp: one that guides features with high-resolution signal in a single forward pass, and one that fits an implicit model to a single image to reconstruct features at any resolution. Both approaches use a multi-view consistency loss with deep analogies to NeRFs. Our features retain their original semantics and can be swapped into existing applications to yield resolution and performance gains even without re-
    
[^4]: HumanoidBench：用于全身运动和操作的仿真人型机器人基准测试

    HumanoidBench: Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation

    [https://arxiv.org/abs/2403.10506](https://arxiv.org/abs/2403.10506)

    提出了一个高维度的仿真机器人学习基准测试HumanoidBench，揭示了目前最先进的强化学习算法在大多数任务上面临挑战，而具备鲁棒低级策略支持的分层学习基线表现更优秀。

    

    人型机器人在协助人类在不同环境和任务中有着巨大潜力，由于其灵活性和适应性，可以利用类人形态。然而，人型机器人的研究常常受到昂贵且易损的硬件设置的限制。为了加速人型机器人算法研究，我们提出了一个高维度的仿真机器人学习基准测试，HumanoidBench，该测试包括一个配备灵巧手部和各种具有挑战性的全身操作和运动任务的人型机器人。我们的研究发现表明，最先进的强化学习算法在大多数任务上表现不佳，而具备鲁棒的低级策略支持的分层学习基线在行走或到达等任务中表现优异。借助HumanoidBench，我们为机器人社区提供了一个平台，用于识别解决人型机器人在解决各种任务时面临的挑战，促进算法研究。

    arXiv:2403.10506v1 Announce Type: cross  Abstract: Humanoid robots hold great promise in assisting humans in diverse environments and tasks, due to their flexibility and adaptability leveraging human-like morphology. However, research in humanoid robots is often bottlenecked by the costly and fragile hardware setups. To accelerate algorithmic research in humanoid robots, we present a high-dimensional, simulated robot learning benchmark, HumanoidBench, featuring a humanoid robot equipped with dexterous hands and a variety of challenging whole-body manipulation and locomotion tasks. Our findings reveal that state-of-the-art reinforcement learning algorithms struggle with most tasks, whereas a hierarchical learning baseline achieves superior performance when supported by robust low-level policies, such as walking or reaching. With HumanoidBench, we provide the robotics community with a platform to identify the challenges arising when solving diverse tasks with humanoid robots, facilitatin
    
[^5]: 基于知识度量的信念变化

    Belief Change based on Knowledge Measures

    [https://arxiv.org/abs/2403.10502](https://arxiv.org/abs/2403.10502)

    提出了一个基于知识度量的全新信念变化框架，其中包括通用的信息论方法、满足AGM公理的KM-based BC算子以及将满足AGM公理的任何BC算子特征化为基于KM的BC算子。

    

    知识度量（KMs）旨在量化知识库所携带的知识/信息量。另一方面，信念变化（BC）是改变信念的过程（在我们的案例中，是指缩减、扩展和修正），考虑到一条可能与当前信念相矛盾的新知识。我们提出了一个基于KMs的全新量化BC框架，通过定义信念变化算子来试图从信息论角度最小化改变后的信念所携带的意外性。为此，我们引入了最小意外原则。具体来说，我们的贡献包括：（i）一个通用的信息论方法来处理KMs，其中[1]是一种特殊情况；（ii）基于KM的BC算子，满足所谓的AGM公理；以及（iii）将满足AGM公理的任何BC算子的特征化为基于KM的BC算子，即任何BC算子

    arXiv:2403.10502v1 Announce Type: new  Abstract: Knowledge Measures (KMs) aim at quantifying the amount of knowledge/information that a knowledge base carries. On the other hand, Belief Change (BC) is the process of changing beliefs (in our case, in terms of contraction, expansion and revision) taking into account a new piece of knowledge, which possibly may be in contradiction with the current belief. We propose a new quantitative BC framework that is based on KMs by defining belief change operators that try to minimise, from an information-theoretic point of view, the surprise that the changed belief carries. To this end, we introduce the principle of minimal surprise. In particular, our contributions are (i) a general information-theoretic approach to KMs for which [1] is a special case; (ii) KM-based BC operators that satisfy the so-called AGM postulates; and (iii) a characterisation of any BC operator that satisfies the AGM postulates as a KM-based BC operator, i.e., any BC operat
    
[^6]: 基于多模态基础模型的零样本鲁棒性基准测试：一项试点研究

    Benchmarking Zero-Shot Robustness of Multimodal Foundation Models: A Pilot Study

    [https://arxiv.org/abs/2403.10499](https://arxiv.org/abs/2403.10499)

    本研究通过对多模态基础模型CLIP进行大规模鲁棒性基准测试，揭示了其在涵盖自然分布偏移、合成分布偏移和对抗攻击等多个方面的优异表现。

    

    通过从关于图像的原始文本中预训练图像表示，使得零样本视觉传输至下游任务成为可能。通过在互联网上采集的数百万样本上进行预训练，如CLIP之类的多模态基础模型产生了最先进的零样本结果，通常在无需任务特定训练的情况下达到与完全监督方法竞争力相当的水平。除了在分类准确性上表现鼓舞人心之外，报道称这些模型通过在自然分布偏移下与在ImageNet上训练的监督模型的表现相匹配来缩小鲁棒性差距。由于鲁棒性对于现实世界的应用至关重要，特别是对于安全关键的应用，本文提出了基于涵盖7种自然、3种合成分布偏移和11种对抗攻击的大规模鲁棒性基准测试的全面评估。我们以CLIP作为试点研究。我们展示了CLIP导致了显著

    arXiv:2403.10499v1 Announce Type: cross  Abstract: Pre-training image representations from the raw text about images enables zero-shot vision transfer to downstream tasks. Through pre-training on millions of samples collected from the internet, multimodal foundation models, such as CLIP, produce state-of-the-art zero-shot results that often reach competitiveness with fully supervised methods without the need for task-specific training. Besides the encouraging performance on classification accuracy, it is reported that these models close the robustness gap by matching the performance of supervised models trained on ImageNet under natural distribution shift. Because robustness is critical to real-world applications, especially safety-critical ones, in this paper, we present a comprehensive evaluation based on a large-scale robustness benchmark covering 7 natural, 3 synthetic distribution shifts, and 11 adversarial attacks. We use CLIP as a pilot study. We show that CLIP leads to a signif
    
[^7]: 通过竞争激发机器人的潜力

    Stimulate the Potential of Robots via Competition

    [https://arxiv.org/abs/2403.10487](https://arxiv.org/abs/2403.10487)

    提出了竞争学习框架，通过引入竞争信息激发机器人的潜力，实验证明在竞争环境中训练的机器人表现优越。

    

    我们在竞争环境中感受到压力是很常见的，这种压力源于与其他个体或对手比较获得成功的愿望。虽然我们可能在压力下感到焦虑，但这也可以激发我们最大限度地发挥潜力，以使自己与他人保持同步。受此启发，我们提出了一个竞争学习框架，能够帮助个体机器人从竞争中获得知识，充分激发其在比赛中的动态潜力。具体来说，竞争者之间的竞争信息被引入为额外的辅助信号，以学习出优势行为。我们进一步构建了一个多智能体竞赛环境，并进行了大量实验，结果表明，在竞争环境中训练的机器人胜过了在单个机器人环境中用SoTA算法训练的机器人。

    arXiv:2403.10487v1 Announce Type: cross  Abstract: It is common for us to feel pressure in a competition environment, which arises from the desire to obtain success comparing with other individuals or opponents. Although we might get anxious under the pressure, it could also be a drive for us to stimulate our potentials to the best in order to keep up with others. Inspired by this, we propose a competitive learning framework which is able to help individual robot to acquire knowledge from the competition, fully stimulating its dynamics potential in the race. Specifically, the competition information among competitors is introduced as the additional auxiliary signal to learn advantaged actions. We further build a Multiagent-Race environment, and extensive experiments are conducted, demonstrating that robots trained in competitive environments outperform ones that are trained with SoTA algorithms in single robot environment.
    
[^8]: GPT4动力AI代理能成为足够优秀的绩效归因分析师吗？

    Can a GPT4-Powered AI Agent Be a Good Enough Performance Attribution Analyst?

    [https://arxiv.org/abs/2403.10482](https://arxiv.org/abs/2403.10482)

    大型语言模型和AI代理的整合在绩效归因分析领域标志着一项开创性发展，能自动化和增强投资组合绩效归因分析。

    

    绩效归因分析被定义为解释投资组合相对于基准的超额绩效驱动因素的过程，在投资组合管理中占据重要地位，在投资决策过程中起着至关重要的作用，特别是在基金管理行业。根植于牢固的金融和数学框架中，这种分析技术的重要性和方法学已在众多学术研究论文和著作中得到广泛记录。大型语言模型（LLMs）和AI代理的整合标志着该领域的开创性发展。这些代理旨在通过准确计算和分析投资组合表现与基准之间的差异，自动化和增强绩效归因分析。本研究介绍了将AI代理应用于各种重要的绩效归因任务，包括分析

    arXiv:2403.10482v1 Announce Type: cross  Abstract: Performance attribution analysis, defined as the process of explaining the drivers of the excess performance of an investment portfolio against a benchmark, stands as a significant aspect of portfolio management and plays a crucial role in the investment decision-making process, particularly within the fund management industry. Rooted in a solid financial and mathematical framework, the importance and methodologies of this analytical technique are extensively documented across numerous academic research papers and books. The integration of large language models (LLMs) and AI agents marks a groundbreaking development in this field. These agents are designed to automate and enhance the performance attribution analysis by accurately calculating and analyzing portfolio performances against benchmarks. In this study, we introduce the application of an AI Agent for a variety of essential performance attribution tasks, including the analysis 
    
[^9]: 安全案例：证明先进人工智能系统的安全性

    Safety Cases: Justifying the Safety of Advanced AI Systems

    [https://arxiv.org/abs/2403.10462](https://arxiv.org/abs/2403.10462)

    本研究提出了一个安全案例框架来组织人工智能系统的安全性论证，包括四类论点：完全无法造成灾难，强大的控制措施，尽管有可能造成伤害，但依然可信赖，以及对可信的人工智能顾问的尊重。

    

    随着人工智能系统变得更加先进，企业和监管机构将面临关于是否安全进行训练和部署的困难决策。为了为这些决策做准备，我们研究了开发人员如何制定一种"安全案例"，这是一种结构化的理由，证明人工智能系统不太可能造成灾难。我们提出了一个组织安全案例的框架，并讨论了四类论证安全的论点：完全无法造成灾难，足够强大的控制措施，尽管能够造成伤害仍值得信赖，以及对可信的人工智能顾问的尊重。我们评估了每个类别中的具体论点示例，并概述了如何组合论点来证明人工智能系统可以安全部署。

    arXiv:2403.10462v1 Announce Type: cross  Abstract: As AI systems become more advanced, companies and regulators will make difficult decisions about whether it is safe to train and deploy them. To prepare for these decisions, we investigate how developers could make a 'safety case,' which is a structured rationale that AI systems are unlikely to cause a catastrophe. We propose a framework for organizing a safety case and discuss four categories of arguments to justify safety: total inability to cause a catastrophe, sufficiently strong control measures, trustworthiness despite capability to cause harm, and deference to credible AI advisors. We evaluate concrete examples of arguments in each category and outline how arguments could be combined to justify that AI systems are safe to deploy.
    
[^10]: 在线并发多机器人覆盖路径规划

    Online Concurrent Multi-Robot Coverage Path Planning

    [https://arxiv.org/abs/2403.10460](https://arxiv.org/abs/2403.10460)

    提出了一种非地平线的集中式算法，实现了在线多机器人覆盖路径规划中的并发规划和执行。

    

    近期，集中式逐步地平线在线多机器人覆盖路径规划算法展现出在彻底探索拥有大量机器人的大型、复杂、未知工作空间方面的出色可伸缩性。在一个时间段内，路径规划和路径执行交替进行，即当为没有路径的机器人进行路径规划时，具有未完成路径的机器人不执行，反之亦然。为此，我们提出了一个非基于地平线的集中式算法。该算法随时为没有路径的机器人子集（即已达到其先前分配目标的机器人）规划路径，而其余机器人执行其未完成的路径，从而实现并发规划和执行。我们正式证明了该提议的...

    arXiv:2403.10460v1 Announce Type: cross  Abstract: Recently, centralized receding horizon online multi-robot coverage path planning algorithms have shown remarkable scalability in thoroughly exploring large, complex, unknown workspaces with many robots. In a horizon, the path planning and the path execution interleave, meaning when the path planning occurs for robots with no paths, the robots with outstanding paths do not execute, and subsequently, when the robots with new or outstanding paths execute to reach respective goals, path planning does not occur for those robots yet to get new paths, leading to wastage of both the robotic and the computation resources. As a remedy, we propose a centralized algorithm that is not horizon-based. It plans paths at any time for a subset of robots with no paths, i.e., who have reached their previously assigned goals, while the rest execute their outstanding paths, thereby enabling concurrent planning and execution. We formally prove that the propo
    
[^11]: 具有不确定性和风险意识的部分可观测任务和运动规划

    Partially Observable Task and Motion Planning with Uncertainty and Risk Awareness

    [https://arxiv.org/abs/2403.10454](https://arxiv.org/abs/2403.10454)

    提出了一种具有不确定性和风险意识的TAMP策略（TAMPURA），能够高效地解决具有初始状态和动作结果不确定性的长时程规划问题，包括需要信息收集和避免不良和不可逆结果的问题。

    

    集成任务和运动规划（TAMP）已被证明是一种有价值的方法，用于解决通用的长时程机器人操纵和导航问题。然而，典型的TAMP问题公式化假设完全可观测和确定性动作效果。这些假设限制了规划者获取信息和做出具有风险意识的决策的能力。我们提出了一种具有不确定性和风险意识的TAMP策略（TAMPURA），能够高效地解决具有初始状态和动作结果不确定性的长时程规划问题，包括需要信息收集和避免不良和不可逆结果的问题。我们的规划者在抽象任务级别和连续控制器级别均在存在不确定性条件下进行推理。鉴于一组在基本动作空间中运行的闭环目标驱动控制器，并描述了它们的前提条件和潜在能力，

    arXiv:2403.10454v1 Announce Type: cross  Abstract: Integrated task and motion planning (TAMP) has proven to be a valuable approach to generalizable long-horizon robotic manipulation and navigation problems. However, the typical TAMP problem formulation assumes full observability and deterministic action effects. These assumptions limit the ability of the planner to gather information and make decisions that are risk-aware. We propose a strategy for TAMP with Uncertainty and Risk Awareness (TAMPURA) that is capable of efficiently solving long-horizon planning problems with initial-state and action outcome uncertainty, including problems that require information gathering and avoiding undesirable and irreversible outcomes. Our planner reasons under uncertainty at both the abstract task level and continuous controller level. Given a set of closed-loop goal-conditioned controllers operating in the primitive action space and a description of their preconditions and potential capabilities, w
    
[^12]: 数据伦理紧急演练：用于讨论工业团队负责人工智能的工具箱

    Data Ethics Emergency Drill: A Toolbox for Discussing Responsible AI for Industry Teams

    [https://arxiv.org/abs/2403.10438](https://arxiv.org/abs/2403.10438)

    该论文介绍了数据伦理紧急演练（DEED）工具箱，帮助数据科学团队讨论和反思工作中的伦理影响，通过角色扮演虚构伦理紧急情景，开启了关于伦理问题的讨论。

    

    研究人员敦促数据科学家等技术从业者考虑算法决策的影响和伦理影响。然而，与编程、统计和数据管理不同，对伦理影响的讨论很少包含在标准数据科学培训中。为了开始解决这一差距，我们设计和测试了一个名为数据伦理紧急演练（DEED）的工具箱，以帮助数据科学团队讨论和反思其工作的伦理影响。 DEED是一个虚构的伦理紧急场景的角色扮演，其情境地处于团队具体的工作场所和应用中。本文概述了DEED工具箱，并描述了两个不同数据科学团队进行的三项研究，这些研究在设计上进行了迭代。我们的研究结果表明，从角色扮演中学到的经验可以应用于现实生活中的情况，并且DEED如何引发了关于伦理的讨论。

    arXiv:2403.10438v1 Announce Type: cross  Abstract: Researchers urge technology practitioners such as data scientists to consider the impacts and ethical implications of algorithmic decisions. However, unlike programming, statistics, and data management, discussion of ethical implications is rarely included in standard data science training. To begin to address this gap, we designed and tested a toolbox called the data ethics emergency drill (DEED) to help data science teams discuss and reflect on the ethical implications of their work. The DEED is a roleplay of a fictional ethical emergency scenario that is contextually situated in the team's specific workplace and applications. This paper outlines the DEED toolbox and describes three studies carried out with two different data science teams that iteratively shaped its design. Our findings show that practitioners can apply lessons learnt from the roleplay to real-life situations, and how the DEED opened up conversations around ethics a
    
[^13]: AI增强的集体智能：现状与展望

    AI-enhanced Collective Intelligence: The State of the Art and Prospects

    [https://arxiv.org/abs/2403.10433](https://arxiv.org/abs/2403.10433)

    人类和人工智能形成的多层次集体智能网络，可以实现超越任一单独实体的集体智能水平。

    

    目前的社会挑战超出了人类个体或集体努力的能力。随着人工智能的发展，其在人类集体中的角色将从辅助工具转变为参与式成员。人类和人工智能拥有互补的能力，当二者协同作用时，可以实现一种超越单独人类或人工智能集体能力的集体智能水平。然而，人工智能系统中的交互本质上是复杂的，涉及复杂的过程和相互依赖关系。本综述从网络科学的视角出发，构想了一个多层次的人工智能集体智能表示，包括认知层、物理层和信息层。在这个多层网络中，人类和人工智能代理展现出不同的特征；人类在多样性方面从表层到深层属性不同，而人工智能代理在程度上也有所区别。

    arXiv:2403.10433v1 Announce Type: cross  Abstract: The current societal challenges exceed the capacity of human individual or collective effort alone. As AI evolves, its role within human collectives is poised to vary from an assistive tool to a participatory member. Humans and AI possess complementary capabilities that, when synergized, can achieve a level of collective intelligence that surpasses the collective capabilities of either humans or AI in isolation. However, the interactions in human-AI systems are inherently complex, involving intricate processes and interdependencies. This review incorporates perspectives from network science to conceptualize a multilayer representation of human-AI collective intelligence, comprising a cognition layer, a physical layer, and an information layer. Within this multilayer network, humans and AI agents exhibit varying characteristics; humans differ in diversity from surface-level to deep-level attributes, while AI agents range in degrees of f
    
[^14]: NeuFlow: 使用边缘设备在机器人上实现实时高精度光流估计

    NeuFlow: Real-time, High-accuracy Optical Flow Estimation on Robots Using Edge Devices

    [https://arxiv.org/abs/2403.10425](https://arxiv.org/abs/2403.10425)

    NeuFlow是一种高效的光流架构，通过全局到局部的方案，实现了高精度光流估计，并解决了计算成本问题。

    

    实时高精度光流估计在各种应用中起着关键作用，包括机器人定位和地图绘制、计算机视觉中的目标跟踪和活动识别。本文提出了一种名为NeuFlow的高效光流架构，旨在解决高精度和计算成本问题。该架构采用了一种全局到局部的设计方案，通过全局匹配在1/16分辨率上对初始光流进行估计，捕捉较大的位移，然后在1/8分辨率上使用轻量级CNN层进行优化，提高准确性。

    arXiv:2403.10425v1 Announce Type: cross  Abstract: Real-time high-accuracy optical flow estimation is a crucial component in various applications, including localization and mapping in robotics, object tracking, and activity recognition in computer vision. While recent learning-based optical flow methods have achieved high accuracy, they often come with heavy computation costs. In this paper, we propose a highly efficient optical flow architecture, called NeuFlow, that addresses both high accuracy and computational cost concerns. The architecture follows a global-to-local scheme. Given the features of the input images extracted at different spatial resolutions, global matching is employed to estimate an initial optical flow on the 1/16 resolution, capturing large displacement, which is then refined on the 1/8 resolution with lightweight CNN layers for better accuracy. We evaluate our approach on Jetson Orin Nano and RTX 2080 to demonstrate efficiency improvements across different compu
    
[^15]: 基于梯度的特征归因在可解释人工智能中的技术评估

    Gradient based Feature Attribution in Explainable AI: A Technical Review

    [https://arxiv.org/abs/2403.10415](https://arxiv.org/abs/2403.10415)

    这项技术评估系统地探讨了基于梯度的解释方法，并引入了一个新颖的分类法将其归类为四个不同类别

    

    arXiv:2403.10415v1 公布类型：新摘要：黑盒人工智能模型的激增促使了解释内部机制并证明其可靠性的需求，特别是在高风险应用领域，如医疗保健和自动驾驶。由于缺乏可解释人工智能（XAI）的严格定义，已经出现了大量与解释性、可解释性和透明性相关的研究，以从各种角度解释和分析模型。因此，由于存在大量的论文，全面了解XAI研究的各个方面变得具有挑战性。考虑到神经网络在人工智能研究中的流行，我们将焦点缩小到XAI研究的一个特定领域：基于梯度的解释，这可以直接应用于神经网络模型。在本评估中，我们系统地探索了迄今为止基于梯度的解释方法，并引入了一个新颖的分类法将其归类为四个不同类别。

    arXiv:2403.10415v1 Announce Type: new  Abstract: The surge in black-box AI models has prompted the need to explain the internal mechanism and justify their reliability, especially in high-stakes applications, such as healthcare and autonomous driving. Due to the lack of a rigorous definition of explainable AI (XAI), a plethora of research related to explainability, interpretability, and transparency has been developed to explain and analyze the model from various perspectives. Consequently, with an exhaustive list of papers, it becomes challenging to have a comprehensive overview of XAI research from all aspects. Considering the popularity of neural networks in AI research, we narrow our focus to a specific area of XAI research: gradient based explanations, which can be directly adopted for neural network models. In this review, we systematically explore gradient based explanation methods to date and introduce a novel taxonomy to categorize them into four distinct classes. Then, we pre
    
[^16]: 特征空间中的能量校正模型用于异常检测

    Energy Correction Model in the Feature Space for Out-of-Distribution Detection

    [https://arxiv.org/abs/2403.10403](https://arxiv.org/abs/2403.10403)

    通过在特征空间中学习内部分布特征密度的能量校正模型，本文提出了一种在异常检测中取得竞争性结果的方法

    

    在这项工作中，我们通过使用预训练深度分类器的特征空间研究了基于能量的模型（EBM）学习内部分布（ID）特征的密度，发现在EBM训练过程中MCMC采样的非混合性会削弱其检测性能。为了克服这一问题，我们提出了一种由混合类条件高斯分布组成的能量校正模型，与CIFAR-10/CIFAR-100 OOD检测基准上的强基线KNN检测器相比取得了良好的结果。

    arXiv:2403.10403v1 Announce Type: cross  Abstract: In this work, we study the out-of-distribution (OOD) detection problem through the use of the feature space of a pre-trained deep classifier. We show that learning the density of in-distribution (ID) features with an energy-based models (EBM) leads to competitive detection results. However, we found that the non-mixing of MCMC sampling during the EBM's training undermines its detection performance. To overcome this an energy-based correction of a mixture of class-conditional Gaussian distributions. We obtains favorable results when compared to a strong baseline like the KNN detector on the CIFAR-10/CIFAR-100 OOD detection benchmarks.
    
[^17]: SculptDiff: 从人类学习目标条件扩散策略的机器人粘土雕塑

    SculptDiff: Learning Robotic Clay Sculpting from Humans with Goal Conditioned Diffusion Policy

    [https://arxiv.org/abs/2403.10401](https://arxiv.org/abs/2403.10401)

    通过SculptDiff，我们提出了一种目标条件扩散策略学习框架，成功实现了对3D可变形物体的操作策略学习。

    

    通过学习粘土雕塑政策，包括点云状态观察，我们提出了一种基于目标条件的扩散模仿学习框架SculptDiff，用于直接学习各种目标形状的政策。在我们的知识范围内，这是第一种成功学习3D可变形物体操作策略的实际方法。欲观看雕塑视频、访问我们的数据集和硬件CAD模型，请参阅项目网站：https://sites.google.com/andrew.cmu.edu/imitation-sculpting/home

    arXiv:2403.10401v1 Announce Type: cross  Abstract: Manipulating deformable objects remains a challenge within robotics due to the difficulties of state estimation, long-horizon planning, and predicting how the object will deform given an interaction. These challenges are the most pronounced with 3D deformable objects. We propose SculptDiff, a goal-conditioned diffusion-based imitation learning framework that works with point cloud state observations to directly learn clay sculpting policies for a variety of target shapes. To the best of our knowledge this is the first real-world method that successfully learns manipulation policies for 3D deformable objects. For sculpting videos and access to our dataset and hardware CAD models, see the project website: https://sites.google.com/andrew.cmu.edu/imitation-sculpting/home
    
[^18]: BirdSet：鸟类生物声学分类的多任务基准

    BirdSet: A Multi-Task Benchmark for Classification in Avian Bioacoustics

    [https://arxiv.org/abs/2403.10380](https://arxiv.org/abs/2403.10380)

    提出了BirdSet基准，用于鸟类生物声学中的分类任务，整合开源鸟类录音数据集合，全面评估模型性能和识别潜在不足。

    

    深度学习模型已经成为鸟类生物声学领域诊断环境健康和生物多样性的强大工具，但研究中存在的不一致性给这一领域的进展带来了显著挑战。我们提出了BirdSet基准，一个统一的框架，综合研究努力，以全面分类鸟类鸣叫声。BirdSet将开源鸟类录音整合到一个精心策划的数据集合中，提供对模型性能的深入理解，并识别跨不同研究的潜在不足之处。

    arXiv:2403.10380v1 Announce Type: cross  Abstract: Deep learning (DL) models have emerged as a powerful tool in avian bioacoustics to diagnose environmental health and biodiversity. However, inconsistencies in research pose notable challenges hindering progress in this domain. Reliable DL models need to analyze bird calls flexibly across various species and environments to fully harness the potential of bioacoustics in a cost-effective passive acoustic monitoring scenario. Data fragmentation and opacity across studies complicate a comprehensive evaluation of general model performance. To overcome these challenges, we present the BirdSet benchmark, a unified framework consolidating research efforts with a holistic approach for classifying bird vocalizations in avian bioacoustics. BirdSet harmonizes open-source bird recordings into a curated dataset collection. This unified approach provides an in-depth understanding of model performance and identifies potential shortcomings across diffe
    
[^19]: 一种用于减轻物联网应用中数据不完整性的节能集成方法

    An Energy-Efficient Ensemble Approach for Mitigating Data Incompleteness in IoT Applications

    [https://arxiv.org/abs/2403.10371](https://arxiv.org/abs/2403.10371)

    提出了一种用于缓解物联网应用中数据不完整性的节能集成方法ENAMLE，旨在解决SECOE的能源瓶颈问题

    

    机器学习在基于物联网的应用中变得越来越重要。然而，许多物联网生态系统的动态性和临时性对机器学习算法的有效性提出了独特挑战。其中之一是数据不完整性，即缺失的传感器读数。许多因素，包括传感器故障和/或网络中断，都可能导致数据不完整性。此外，大多数物联网系统受到严重的电力限制。重要的是，我们构建针对数据不完整性鲁棒且节能的物联网机器学习系统。本文对SECOE进行了一项实证研究-一种用于减轻物联网中数据不完整性的最新技术，关注其能源瓶颈。为了解决SECOE的能源瓶颈，我们提出了ENAMLE-一种主动的、能源感知的技术，用于减轻同时缺失数据的影响。ENAMLE在这样的意义上是独特的

    arXiv:2403.10371v1 Announce Type: cross  Abstract: Machine Learning (ML) is becoming increasingly important for IoT-based applications. However, the dynamic and ad-hoc nature of many IoT ecosystems poses unique challenges to the efficacy of ML algorithms. One such challenge is data incompleteness, which is manifested as missing sensor readings. Many factors, including sensor failures and/or network disruption, can cause data incompleteness. Furthermore, most IoT systems are severely power-constrained. It is important that we build IoT-based ML systems that are robust against data incompleteness while simultaneously being energy efficient. This paper presents an empirical study of SECOE - a recent technique for alleviating data incompleteness in IoT - with respect to its energy bottlenecks. Towards addressing the energy bottlenecks of SECOE, we propose ENAMLE - a proactive, energy-aware technique for mitigating the impact of concurrent missing data. ENAMLE is unique in the sense that it
    
[^20]: 可扩展的个人偏好稳定聚类算法

    Scalable Algorithms for Individual Preference Stable Clustering

    [https://arxiv.org/abs/2403.10365](https://arxiv.org/abs/2403.10365)

    研究了个人偏好稳定聚类的可扩展算法，通过局部搜索获得了 $O(\log n)$-IP 稳定性保证，并且在几乎线性时间内运行。

    

    在本文中，我们研究了个人偏好（IP）稳定性，这是一个捕捉聚类中个人公平性和稳定性的概念。在这个设定中，当每个数据点到其簇的平均距离不超过其到任何其他簇的平均距离的 $\alpha$ 倍时，一个聚类是 $\alpha$-IP 稳定的。在本文中，我们研究了用于 IP 稳定聚类的自然局部搜索算法。我们的分析证实了此算法的 $O(\log n)$-IP 稳定性保证，其中 $n$ 表示输入中的数据点数量。此外，通过改进局部搜索方法，我们表明其运行时间几乎是线性的，为 $\tilde{O}(nk)$。

    arXiv:2403.10365v1 Announce Type: cross  Abstract: In this paper, we study the individual preference (IP) stability, which is an notion capturing individual fairness and stability in clustering. Within this setting, a clustering is $\alpha$-IP stable when each data point's average distance to its cluster is no more than $\alpha$ times its average distance to any other cluster. In this paper, we study the natural local search algorithm for IP stable clustering. Our analysis confirms a $O(\log n)$-IP stability guarantee for this algorithm, where $n$ denotes the number of points in the input. Furthermore, by refining the local search approach, we show it runs in an almost linear time, $\tilde{O}(nk)$.
    
[^21]: 使用连续词项与时间（CBoTT）进行无监督威胁猎杀

    Unsupervised Threat Hunting using Continuous Bag-of-Terms-and-Time (CBoTT)

    [https://arxiv.org/abs/2403.10327](https://arxiv.org/abs/2403.10327)

    提出CBoTT框架用于无监督威胁猎杀在SIEM日志中能够更准确地识别异常活动，性能优于基准方法，可帮助研究人员和网络安全分析员进行威胁猎杀。

    

    威胁猎杀是指通过筛查系统日志来检测可能绕过现有安全措施的恶意活动。我们提出了一种无监督框架，称为连续词项与时间（CBoTT），并发布其应用程序接口（API），以帮助研究人员和网络安全分析员在面向终端设备上的进程审计的SIEM日志中进行基于异常的威胁猎杀。

    arXiv:2403.10327v1 Announce Type: cross  Abstract: Threat hunting is sifting through system logs to detect malicious activities that might have bypassed existing security measures. It can be performed in several ways, one of which is based on detecting anomalies. We propose an unsupervised framework, called continuous bag-of-terms-and-time (CBoTT), and publish its application programming interface (API) to help researchers and cybersecurity analysts perform anomaly-based threat hunting among SIEM logs geared toward process auditing on endpoint devices. Analyses show that our framework consistently outperforms benchmark approaches. When logs are sorted by likelihood of being an anomaly (from most likely to least), our approach identifies anomalies at higher percentiles (between 1.82-6.46) while benchmark approaches identify the same anomalies at lower percentiles (between 3.25-80.92). This framework can be used by other researchers to conduct benchmark analyses and cybersecurity analyst
    
[^22]: 基于预训练语言模型的自动填空干扰项生成

    CDGP: Automatic Cloze Distractor Generation based on Pre-trained Language Model

    [https://arxiv.org/abs/2403.10326](https://arxiv.org/abs/2403.10326)

    本文研究了通过应用预训练语言模型作为候选干扰项生成的替代方法来自动生成填空干扰项，并展示了这种PLM增强模型显著提高了性能。

    

    手动设计填空测试耗费大量时间和精力。主要挑战在于错误选项（干扰项）的选择。精心设计的干扰项提高了学习者能力评估的有效性。因此，自动生成填空干扰项的想法应运而生。本文通过探索预训练语言模型（PLMs）的应用作为候选干扰项生成的替代方法来研究填空干扰项生成。实验表明，PLM增强模型带来了显著的性能提升。我们的最佳模型将最先进的结果从14.94提升至34.17（NDCG@10分数）。我们的代码和数据集可在https://github.com/AndyChiangSH/CDGP 获取。

    arXiv:2403.10326v1 Announce Type: cross  Abstract: Manually designing cloze test consumes enormous time and efforts. The major challenge lies in wrong option (distractor) selection. Having carefully-design distractors improves the effectiveness of learner ability assessment. As a result, the idea of automatically generating cloze distractor is motivated. In this paper, we investigate cloze distractor generation by exploring the employment of pre-trained language models (PLMs) as an alternative for candidate distractor generation. Experiments show that the PLM-enhanced model brings a substantial performance improvement. Our best performing model advances the state-of-the-art result from 14.94 to 34.17 (NDCG@10 score). Our code and dataset is available at https://github.com/AndyChiangSH/CDGP.
    
[^23]: KIF：使用Wikidata进行异构知识库虚拟集成的框架

    KIF: A Framework for Virtual Integration of Heterogeneous Knowledge Bases using Wikidata

    [https://arxiv.org/abs/2403.10304](https://arxiv.org/abs/2403.10304)

    KIF框架利用Wikidata作为通用语言，结合用户定义的映射，实现了异构知识库的虚拟集成，形成类似于扩展Wikidata的虚拟知识库，可通过过滤接口或SPARQL进行查询。

    

    我们提出了一个知识集成框架（称为KIF），该框架使用Wikidata作为通用语言来集成异构知识库。这些知识库可以是三元组存储、关系型数据库、CSV文件等，可以或不可以使用RDF的Wikidata方言。KIF利用Wikidata的数据模型和词汇以及用户定义的映射来展示集成库的统一视图，同时跟踪其陈述的上下文和出处。结果是一个行为类似于“扩展Wikidata”的虚拟知识库，可以通过高效过滤接口或使用SPARQL进行查询。我们展示了KIF的设计和实现，讨论了我们如何在化学领域（涉及Wikidata、PubChem和IBM CIRCA）中使用它解决实际集成问题，并介绍了KIF的性能和开销的实验结果。

    arXiv:2403.10304v1 Announce Type: new  Abstract: We present a knowledge integration framework (called KIF) that uses Wikidata as a lingua franca to integrate heterogeneous knowledge bases. These can be triplestores, relational databases, CSV files, etc., which may or may not use the Wikidata dialect of RDF. KIF leverages Wikidata's data model and vocabulary plus user-defined mappings to expose a unified view of the integrated bases while keeping track of the context and provenance of their statements. The result is a virtual knowledge base which behaves like an "extended Wikidata" and which can be queried either through an efficient filter interface or using SPARQL. We present the design and implementation of KIF, discuss how we have used it to solve a real integration problem in the domain of chemistry (involving Wikidata, PubChem, and IBM CIRCA), and present experimental results on the performance and overhead of KIF.
    
[^24]: 一种面向物联网环境中紧急救援的多约束多目标分配模型

    A Multi-constraint and Multi-objective Allocation Model for Emergency Rescue in IoT Environment

    [https://arxiv.org/abs/2403.10299](https://arxiv.org/abs/2403.10299)

    这个多约束多目标分配模型在紧急救援场景中优化资源分配方面取得了显著进展。

    

    紧急救援行动在灾后至关重要，需要有效的资源分配以最小化负面影响并最大化收益。在长时间危机或大规模灾害中，系统化的多周期方法对于及时和明智的决策至关重要。借助物联网和时空数据分析的进展，我们开发了多目标洗牌灰狼青蛙跳模型（MSGW-FLM）。这个多约束、多目标的资源分配模型已经经过严格测试，与NSGA-II、IBEA和MOEA/D等已建立的模型相比表现出更优异的性能。MSGW-FLM的有效性在复杂的多周期紧急救援场景中尤为引人注目，这些场景涉及众多约束和目标。这个模型在优化应急响应情境中资源分配方面迈出了重要的一步。

    arXiv:2403.10299v1 Announce Type: new  Abstract: Emergency relief operations are essential in disaster aftermaths, necessitating effective resource allocation to minimize negative impacts and maximize benefits. In prolonged crises or extensive disasters, a systematic, multi-cycle approach is key for timely and informed decision-making. Leveraging advancements in IoT and spatio-temporal data analytics, we've developed the Multi-Objective Shuffled Gray-Wolf Frog Leaping Model (MSGW-FLM). This multi-constraint, multi-objective resource allocation model has been rigorously tested against 28 diverse challenges, showing superior performance in comparison to established models such as NSGA-II, IBEA, and MOEA/D. MSGW-FLM's effectiveness is particularly notable in complex, multi-cycle emergency rescue scenarios, which involve numerous constraints and objectives. This model represents a significant step forward in optimizing resource distribution in emergency response situations.
    
[^25]: 用于连续和高效时间序列建模的粗糙Transformer

    Rough Transformers for Continuous and Efficient Time-Series Modelling

    [https://arxiv.org/abs/2403.10288](https://arxiv.org/abs/2403.10288)

    提出了粗糙Transformer，用于在连续时间表示的输入序列上进行操作，大大降低了计算成本，对于处理医疗情境中的长程依赖性至关重要。

    

    在真实世界的医疗环境中，时间序列数据通常表现出长程依赖性，并且以不均匀间隔观察到。在这种情况下，传统的基于序列的循环模型很难处理。为了克服这一问题，研究人员用基于神经ODE的模型替换循环架构来建模非均匀采样的数据，并使用Transformer架构来考虑长程依赖。尽管这两种方法取得了成功，但对于中等长度及更长输入序列，两者都需要非常高的计算成本。为了缓解这一问题，我们引入了粗糙Transformer，这是Transformer模型的一种变体，其在输入序列的连续时间表示上运行，并且减少了计算成本，对于处理医疗情境中常见的长程依赖性至关重要。特别地，我们提出了多视图签名注意力，利用路径签名来增强传统的注意力。

    arXiv:2403.10288v1 Announce Type: cross  Abstract: Time-series data in real-world medical settings typically exhibit long-range dependencies and are observed at non-uniform intervals. In such contexts, traditional sequence-based recurrent models struggle. To overcome this, researchers replace recurrent architectures with Neural ODE-based models to model irregularly sampled data and use Transformer-based architectures to account for long-range dependencies. Despite the success of these two approaches, both incur very high computational costs for input sequences of moderate lengths and greater. To mitigate this, we introduce the Rough Transformer, a variation of the Transformer model which operates on continuous-time representations of input sequences and incurs significantly reduced computational costs, critical for addressing long-range dependencies common in medical contexts. In particular, we propose multi-view signature attention, which uses path signatures to augment vanilla attent
    
[^26]: Team Trifecta在Factify 5WQA上设定了细化调整中事实验证的标准

    Team Trifecta at Factify5WQA: Setting the Standard in Fact Verification with Fine-Tuning

    [https://arxiv.org/abs/2403.10281](https://arxiv.org/abs/2403.10281)

    Team Trifecta在Factify 5WQA上以Fine-Tuning取得了首要地位，成功超越基准准确率103％，并保持了对第二名竞争者的70%领先优势。

    

    在本文中，我们介绍了Pre-CoFactv3，这是一个由问答和文本分类组件组成的全面框架，用于事实验证。通过利用上下文学习、微调大型语言模型（LLMs）和FakeNet模型，我们解决了事实验证面临的挑战。我们的实验探讨了不同的方法，比较了不同的预训练LLMs，引入了FakeNet，并实施了各种集成方法。值得注意的是，我们的团队Trifecta在AAAI-24 Factify 3.0研讨会上获得了第一名，比基准准确率高出103%，并保持了对第二名竞争对手的70%领先优势。这一成功突显了我们方法的有效性及其对推进事实验证研究的潜在贡献。

    arXiv:2403.10281v1 Announce Type: cross  Abstract: In this paper, we present Pre-CoFactv3, a comprehensive framework comprised of Question Answering and Text Classification components for fact verification. Leveraging In-Context Learning, Fine-tuned Large Language Models (LLMs), and the FakeNet model, we address the challenges of fact verification. Our experiments explore diverse approaches, comparing different Pre-trained LLMs, introducing FakeNet, and implementing various ensemble methods. Notably, our team, Trifecta, secured first place in the AAAI-24 Factify 3.0 Workshop, surpassing the baseline accuracy by 103% and maintaining a 70% lead over the second competitor. This success underscores the efficacy of our approach and its potential contributions to advancing fact verification research.
    
[^27]: 关于大型语言模型的可解释性问题和基于词级单变量一阶概率假设的研究

    A Question on the Explainability of Large Language Models and the Word-Level Univariate First-Order Plausibility Assumption

    [https://arxiv.org/abs/2403.10275](https://arxiv.org/abs/2403.10275)

    本文提出了一个方法来挑战为大型语言模型提供简单而丰富解释的可能性，研究发现使用基于特征的模型在信号传递方面效果更好。

    

    最近研究表明，大型语言模型的解释对其训练中使用的随机性很敏感，因此需要对这种敏感性进行表征。本文提出了一个挑战为这些模型提供简单和信息丰富解释的表征方法。为此，我们为解释的信号、噪声和信噪比给出了统计定义。我们强调，在一个典型案例研究中，使用一阶统计工具分析基于单一特征的模型解释时，简单特征模型的解释传递更多信号并且噪声更少。然后，我们讨论了通过替代信号和噪声的定义来改进这些结果的可能性，这种方法可以捕捉更复杂的解释和分析方法，同时也质疑了与读者可信度之间的权衡。

    arXiv:2403.10275v1 Announce Type: cross  Abstract: The explanations of large language models have recently been shown to be sensitive to the randomness used for their training, creating a need to characterize this sensitivity. In this paper, we propose a characterization that questions the possibility to provide simple and informative explanations for such models. To this end, we give statistical definitions for the explanations' signal, noise and signal-to-noise ratio. We highlight that, in a typical case study where word-level univariate explanations are analyzed with first-order statistical tools, the explanations of simple feature-based models carry more signal and less noise than those of transformer ones. We then discuss the possibility to improve these results with alternative definitions of signal and noise that would capture more complex explanations and analysis methods, while also questioning the tradeoff with their plausibility for readers.
    
[^28]: 利用分类模型和LSTM模型在工业中进行预测性维护的综合研究

    Comprehensive Study Of Predictive Maintenance In Industries Using Classification Models And LSTM Model

    [https://arxiv.org/abs/2403.10259](https://arxiv.org/abs/2403.10259)

    该研究探讨利用分类模型和LSTM模型在工业中进行预测性维护的方法，通过人工智能技术实现对机器故障更准确和高效的预测和分析。

    

    在当今技术驱动的时代，对预测性维护和先进诊断的迫切需求不仅仅限于航空领域，还包括对旋转和移动机器中损坏、故障和操作缺陷的识别。实施这样的服务不仅可以缩减维护成本，还可以延长机器寿命，确保卓越的操作效率。此外，这也是一种防范潜在事故或灾难性事件的预防措施。人工智能的出现彻底改变了各行业的维护方式，实现了对机器故障更准确和高效的预测和分析，从而节约了时间和资源。我们提出的研究旨在探讨各种机器学习分类技术，包括支持向量机（SVM）、随机森林、逻辑回归以及基于卷积神经网络LSTM的机器性能预测与分析。

    arXiv:2403.10259v1 Announce Type: cross  Abstract: In today's technology-driven era, the imperative for predictive maintenance and advanced diagnostics extends beyond aviation to encompass the identification of damages, failures, and operational defects in rotating and moving machines. Implementing such services not only curtails maintenance costs but also extends machine lifespan, ensuring heightened operational efficiency. Moreover, it serves as a preventive measure against potential accidents or catastrophic events. The advent of Artificial Intelligence (AI) has revolutionized maintenance across industries, enabling more accurate and efficient prediction and analysis of machine failures, thereby conserving time and resources. Our proposed study aims to delve into various machine learning classification techniques, including Support Vector Machine (SVM), Random Forest, Logistic Regression, and Convolutional Neural Network LSTM-Based, for predicting and analyzing machine performance. 
    
[^29]: 对游戏智能代理与大型模型的调查：方法、应用和挑战

    A Survey on Game Playing Agents and Large Models: Methods, Applications, and Challenges

    [https://arxiv.org/abs/2403.10249](https://arxiv.org/abs/2403.10249)

    本文对大型模型在复杂游戏场景中的使用进行了全面的检查，总结了基于LM的游戏代理的现有架构、挑战和未来研究方向。

    

    大规模模型（LMs），不论是以语言为重点还是多模态，迅速发展引起了学术界和工业界的广泛关注。尽管这一快速发展领域引发了极大兴趣，但对其在不同有重大影响的场景中的能力和潜力仍缺乏系统性的综述。本文力图弥合这一差距，对LM在复杂游戏场景中的使用情况进行了彻底的检查并探讨了依然存在的挑战。我们试图系统地审查基于LM的游戏代理（LMAs）的现有架构，并总结它们的共同之处、挑战和任何其他洞见。此外，我们提出了对LM在游戏中进展的有前景的未来研究方向。我们希望协助研究人员更清晰地理解这一领域，并激发对这一高度影响力研究方向的更多兴趣。

    arXiv:2403.10249v1 Announce Type: new  Abstract: The swift evolution of Large-scale Models (LMs), either language-focused or multi-modal, has garnered extensive attention in both academy and industry. But despite the surge in interest in this rapidly evolving area, there are scarce systematic reviews on their capabilities and potential in distinct impactful scenarios. This paper endeavours to help bridge this gap, offering a thorough examination of the current landscape of LM usage in regards to complex game playing scenarios and the challenges still open. Here, we seek to systematically review the existing architectures of LM-based Agents (LMAs) for games and summarize their commonalities, challenges, and any other insights. Furthermore, we present our perspective on promising future research avenues for the advancement of LMs in games. We hope to assist researchers in gaining a clear understanding of the field and to generate more interest in this highly impactful research direction.
    
[^30]: 少即是多：大规模知识图谱上的一次性子图推理

    Less is More: One-shot Subgraph Reasoning on Large-scale Knowledge Graphs

    [https://arxiv.org/abs/2403.10231](https://arxiv.org/abs/2403.10231)

    提出了一种在大规模知识图谱上进行高效和自适应预测的一次性子图链接预测方法，通过将预测过程分解为从查询中提取一个子图并在该单个、查询相关子图上进行预测的两个步骤，利用非参数化和计算高效的启发式方法来提高效率。

    

    要在知识图谱（KG）上推导新的事实，链接预测器从图结构中学习，并收集局部证据以找到对给定查询的答案。然而，现有方法由于利用整个KG进行预测而存在严重的可扩展性问题，这阻碍了它们在大规模KG上的应用，并且无法直接通过常规抽样方法解决。 在这项工作中，我们提出了一次性子图链接预测以实现高效且自适应的预测。 设计原则是，预测过程不直接作用于整个KG，而是分为两个步骤，即（i）根据查询仅提取一个子图和（ii）在这个单一的、查询相关的子图上进行预测。 我们发现，非参数化和计算高效的启发式方法个性化PageRank（PPR）可以有效地识别潜在答案和支持证据。

    arXiv:2403.10231v1 Announce Type: cross  Abstract: To deduce new facts on a knowledge graph (KG), a link predictor learns from the graph structure and collects local evidence to find the answer to a given query. However, existing methods suffer from a severe scalability problem due to the utilization of the whole KG for prediction, which hinders their promise on large scale KGs and cannot be directly addressed by vanilla sampling methods. In this work, we propose the one-shot-subgraph link prediction to achieve efficient and adaptive prediction. The design principle is that, instead of directly acting on the whole KG, the prediction procedure is decoupled into two steps, i.e., (i) extracting only one subgraph according to the query and (ii) predicting on this single, query dependent subgraph. We reveal that the non-parametric and computation-efficient heuristics Personalized PageRank (PPR) can effectively identify the potential answers and supporting evidence. With efficient subgraph-b
    
[^31]: HawkEye: 用于将文本与视频相关联的训练视频文本LLMs

    HawkEye: Training Video-Text LLMs for Grounding Text in Videos

    [https://arxiv.org/abs/2403.10228](https://arxiv.org/abs/2403.10228)

    本文提出了HawkEye，一个可以以完全文本方式执行时间视频定位的视频文本LLMs，并通过构建大规模视频文本语料库InternVid-G以及引入两个新的面向时间的训练目标，以及一种新的粗粒度表示视频段的方法来实现这一目标。

    

    视频文本大型语言模型（video-text LLMs）在回答问题和进行简单视频对话方面表现出色。然而，在长而复杂的视频中，它们在文本查询上的表现几乎与随机相同，几乎没有能力理解和推理关于时间信息的内容，这是视频和图像之间最基本的区别。本文提出了HawkEye，这是第一个可以完全以文本方式执行时间视频定位的视频文本LLMs之一。为了收集适用于时间视频定位的训练数据，我们构建了InternVid-G，一个具有分段级标题和负间距的大规模视频文本语料库，通过该语料库引入了两个新的面向时间的训练目标以供视频文本LLMs使用。我们还提出了一种表示视频中段的粗粒度方法，这种方法比LLMs学习和遵循的方法更稳健且更易学习。

    arXiv:2403.10228v1 Announce Type: cross  Abstract: Video-text Large Language Models (video-text LLMs) have shown remarkable performance in answering questions and holding conversations on simple videos. However, they perform almost the same as random on grounding text queries in long and complicated videos, having little ability to understand and reason about temporal information, which is the most fundamental difference between videos and images. In this paper, we propose HawkEye, one of the first video-text LLMs that can perform temporal video grounding in a fully text-to-text manner. To collect training data that is applicable for temporal video grounding, we construct InternVid-G, a large-scale video-text corpus with segment-level captions and negative spans, with which we introduce two new time-aware training objectives to video-text LLMs. We also propose a coarse-grained method of representing segments in videos, which is more robust and easier for LLMs to learn and follow than o
    
[^32]: 从混沌到清晰：天文观测中的时间序列异常检测

    From Chaos to Clarity: Time Series Anomaly Detection in Astronomical Observations

    [https://arxiv.org/abs/2403.10220](https://arxiv.org/abs/2403.10220)

    提出了AERO，一个专为天文观测中无监督异常检测量身定制的新颖两阶段框架，擅长处理天文观测中独立但受到随机并发噪声干扰的特征。

    

    随着天文设施的发展，这些设施观测到的大规模时间序列数据被收集起来。分析这些天文观测中的异常对于揭示潜在的天体事件和物理现象至关重要，从而推动科学研究过程。然而，现有的时间序列异常检测方法在处理天文观测的独特特征方面存在不足，其中每颗星体本质上是独立的，但受到随机并发噪声的干扰，导致假警报率较高。为了克服这些挑战，我们提出了AERO，这是一个专为天文观测中的无监督异常检测量身定制的新颖两阶段框架。在第一阶段，我们采用基于Transformer的编码器-解码器架构来学习每个变量（即星体）上的正常时间模式，以与变量独立性的特征保持一致。在第二阶段，我们e

    arXiv:2403.10220v1 Announce Type: cross  Abstract: With the development of astronomical facilities, large-scale time series data observed by these facilities is being collected. Analyzing anomalies in these astronomical observations is crucial for uncovering potential celestial events and physical phenomena, thus advancing the scientific research process. However, existing time series anomaly detection methods fall short in tackling the unique characteristics of astronomical observations where each star is inherently independent but interfered by random concurrent noise, resulting in a high rate of false alarms. To overcome the challenges, we propose AERO, a novel two-stage framework tailored for unsupervised anomaly detection in astronomical observations. In the first stage, we employ a Transformer-based encoder-decoder architecture to learn the normal temporal patterns on each variate (i.e., star) in alignment with the characteristic of variate independence. In the second stage, we e
    
[^33]: 在nnU-Net框架中探索光流的应用以提高外科器械分割质量

    Exploring Optical Flow Inclusion into nnU-Net Framework for Surgical Instrument Segmentation

    [https://arxiv.org/abs/2403.10216](https://arxiv.org/abs/2403.10216)

    在nnU-Net框架中探索光流的应用以提高外科器械分割质量，利用光流图作为附加输入，提高了模型在外科器械分割任务中的性能

    

    在腹腔镜手术中，外科器械分割对计算辅助外科系统至关重要。尽管近年来深度学习取得了进展，但腹腔镜手术的动态环境仍然对精确分割提出挑战。nnU-Net框架在分析不带时间信息的单帧语义分割方面表现出色。本研究旨在将光流（OF）图作为附加输入引入到nnU-Net架构中，以提高其在外科器械分割任务中的性能，充分利用器械是外科领域主要移动对象的事实。

    arXiv:2403.10216v1 Announce Type: cross  Abstract: Surgical instrument segmentation in laparoscopy is essential for computer-assisted surgical systems. Despite the Deep Learning progress in recent years, the dynamic setting of laparoscopic surgery still presents challenges for precise segmentation. The nnU-Net framework excelled in semantic segmentation analyzing single frames without temporal information. The framework's ease of use, including its ability to be automatically configured, and its low expertise requirements, have made it a popular base framework for comparisons. Optical flow (OF) is a tool commonly used in video tasks to estimate motion and represent it in a single frame, containing temporal information. This work seeks to employ OF maps as an additional input to the nnU-Net architecture to improve its performance in the surgical instrument segmentation task, taking advantage of the fact that instruments are the main moving objects in the surgical field. With this new in
    
[^34]: 从 README 中提取功能

    Read between the lines -- Functionality Extraction From READMEs

    [https://arxiv.org/abs/2403.10205](https://arxiv.org/abs/2403.10205)

    本文介绍了一种新颖的文本处理任务——从 Git README 文件中提取功能，研究动机源自对大型语言模型在代码相关任务中应用的兴趣，通过开发小型微调模型，取得了70%和20%的性能提升。

    

    虽然文本摘要是一项众所周知的自然语言处理任务，但在本文中，我们介绍了一种称为从 Git README 文件中提取功能的新颖而有用的变体。虽然这个任务在抽象层面上是一个文本生成任务，但它涉及到自己的特殊性和挑战，使得现有的文本生成系统并不十分有用。这一任务的动机源自最近围绕着使用大型语言模型进行代码相关任务（如代码重构、代码摘要等）的研究和开发活动的激增。我们还发布了一个名为FuncRead的人工注释数据集，并为这一任务开发了一系列模型。我们进行了详尽的实验，结果表明，小型微调模型击败了可以使用流行的黑盒或白盒大型语言模型（LLMs）（如ChatGPT和Bard）设计的任何基线模型。我们的最佳微调的70亿CodeLlama模型在F1上取得了70%和20%的增益。

    arXiv:2403.10205v1 Announce Type: cross  Abstract: While text summarization is a well-known NLP task, in this paper, we introduce a novel and useful variant of it called functionality extraction from Git README files. Though this task is a text2text generation at an abstract level, it involves its own peculiarities and challenges making existing text2text generation systems not very useful. The motivation behind this task stems from a recent surge in research and development activities around the use of large language models for code-related tasks, such as code refactoring, code summarization, etc. We also release a human-annotated dataset called FuncRead, and develop a battery of models for the task. Our exhaustive experimentation shows that small size fine-tuned models beat any baseline models that can be designed using popular black-box or white-box large language models (LLMs) such as ChatGPT and Bard. Our best fine-tuned 7 Billion CodeLlama model exhibit 70% and 20% gain on the F1
    
[^35]: 在JPEG-LDPC压缩图像上学习：利用综合症状进行分类

    Learning on JPEG-LDPC Compressed Images: Classifying with Syndromes

    [https://arxiv.org/abs/2403.10202](https://arxiv.org/abs/2403.10202)

    在这篇论文中，提出了一种在JPEG-LDPC压缩图像上进行分类的方法，通过利用LDPC码的内部代码结构，使用GRU进行训练，从而实现了高效的图像分类。

    

    在面向目标的通信中，接收者的目标通常是应用深度学习模型，而不是重建原始数据。 在这种情况下，在接收器上无需进行任何先前解码即可直接对压缩数据进行学习，有望增强推断模型的时间效率。 本文提出了一种替代方法，其中经熵编码是用低密度奇偶校验（LDPC）码实现的。我们假设深度学习模型可以更有效地利用LDPC码的内部代码结构。 在接收器端，我们利用一种特定类型的循环神经网络（RNN），具体来说是用于图像分类的门控循环单元（GRU）进行训练。 我们的数值结果表明，基于LDPC的分类有望通过基于数据综合症状的图像分类明显地提高性能。

    arXiv:2403.10202v1 Announce Type: cross  Abstract: In goal-oriented communications, the objective of the receiver is often to apply a Deep-Learning model, rather than reconstructing the original data. In this context, direct learning over compressed data, without any prior decoding, holds promise for enhancing the time-efficient execution of inference models at the receiver. However, conventional entropic-coding methods like Huffman and Arithmetic break data structure, rendering them unsuitable for learning without decoding. In this paper, we propose an alternative approach in which entropic coding is realized with Low-Density Parity Check (LDPC) codes. We hypothesize that Deep Learning models can more effectively exploit the internal code structure of LDPC codes. At the receiver, we leverage a specific class of Recurrent Neural Networks (RNNs), specifically Gated Recurrent Unit (GRU), trained for image classification. Our numerical results indicate that classification based on LDPC-co
    
[^36]: 基于感知质量的模型训练在标注者标签不确定性下

    Perceptual Quality-based Model Training under Annotator Label Uncertainty

    [https://arxiv.org/abs/2403.10190](https://arxiv.org/abs/2403.10190)

    标注者标签不确定性影响模型泛化能力和预测不确定性，现有不确定性估计算法无法应对，提出一种基于感知质量的训练方法以缓解性能下降

    

    arXiv:2403.10190v1 公告类型:跨领域. 标注者在数据标记过程中存在分歧，可称为标注者标签不确定性。标注者标签不确定性表现为标记质量的变化。每个样本使用单个低质量标注进行训练会导致模型可靠性下降。本研究首先考察了标注者标签不确定性对模型的泛化能力和预测不确定性的影响。我们观察到，模型的泛化能力和预测不确定性会随着低质量的嘈杂标签的存在而降低。同时，我们评估现有的不确定性估计算法表明它们无法应对标注者标签不确定性。为了减轻性能下降，先前的方法表明使用来自多个独立标注者收集的标签进行训练可以增强泛化能力。然而，它们需要大量标注。因此，我们引入一种新的基于感知质量的方法

    arXiv:2403.10190v1 Announce Type: cross  Abstract: Annotators exhibit disagreement during data labeling, which can be termed as annotator label uncertainty. Annotator label uncertainty manifests in variations of labeling quality. Training with a single low-quality annotation per sample induces model reliability degradations. In this work, we first examine the effects of annotator label uncertainty in terms of the model's generalizability and prediction uncertainty. We observe that the model's generalizability and prediction uncertainty degrade with the presence of low-quality noisy labels. Meanwhile, our evaluation of existing uncertainty estimation algorithms indicates their incapability in response to annotator label uncertainty. To mitigate performance degradation, prior methods show that training models with labels collected from multiple independent annotators can enhance generalizability. However, they require massive annotations. Hence, we introduce a novel perceptual quality-ba
    
[^37]: 抓住一切：将教师增强策略梯度学习与实例分割相结合，用于抓取任意物体

    Grasp Anything: Combining Teacher-Augmented Policy Gradient Learning with Instance Segmentation to Grasp Arbitrary Objects

    [https://arxiv.org/abs/2403.10187](https://arxiv.org/abs/2403.10187)

    提出了一种新颖的两阶段学习框架TAPG，将强化学习和策略蒸馏相结合，在抓取任意物体时取得了良好表现。

    

    交互式从混乱环境中抓取物体，类似于人类灵巧，是机器人学习中存在已久的问题之一。挑战源于视觉感知的复杂性，对精准运动技能的需求，以及两者之间的复杂相互作用。本文介绍了一种新颖的两阶段学习框架Teacher-Augmented Policy Gradient (TAPG)，该框架将强化学习和策略蒸馏相结合。通过训练一个教师策略来掌握基于物体位置信息的运动控制，TAPG促进了基于物体分割的感觉运动策略的指导性但自适应学习。我们通过使用Segment Anything模型进行零样本从仿真到实际机器人的传输，实现了对各种物体的熟练抓取。此外，我们展示了在仿真和真实世界中基于人类可理解提示的混乱场景中训练的策略能够熟练地抓取各种物体。

    arXiv:2403.10187v1 Announce Type: cross  Abstract: Interactive grasping from clutter, akin to human dexterity, is one of the longest-standing problems in robot learning. Challenges stem from the intricacies of visual perception, the demand for precise motor skills, and the complex interplay between the two. In this work, we present Teacher-Augmented Policy Gradient (TAPG), a novel two-stage learning framework that synergizes reinforcement learning and policy distillation. After training a teacher policy to master the motor control based on object pose information, TAPG facilitates guided, yet adaptive, learning of a sensorimotor policy, based on object segmentation. We zero-shot transfer from simulation to a real robot by using Segment Anything Model for promptable object segmentation. Our trained policies adeptly grasp a wide variety of objects from cluttered scenarios in simulation and the real world based on human-understandable prompts. Furthermore, we show robust zero-shot transfe
    
[^38]: 在关系领域中的抬升因果推断

    Lifted Causal Inference in Relational Domains

    [https://arxiv.org/abs/2403.10184](https://arxiv.org/abs/2403.10184)

    本文展示了在关系领域中如何利用抬升技术高效计算因果效应，引入了参数化因果因子图，并提出了抬升因果推断算法，显著加快了因果推断速度。

    

    抬升推断通过使用可区分不同对象的代表，在概率图模型中利用对称性，以加快查询回答速度同时保持精确答案。尽管抬升是一种在关系领域中概率推断任务中经常使用的技术，但尚未应用于因果推断任务。本文展示了如何将抬升应用于在关系领域内高效计算因果效应。具体地，我们引入参数化因果因子图作为包含因果知识的参数化因子图的扩展，并在其中给出干预的形式语义。我们进一步提出了抬升因果推断算法，以在抬升级别计算因果效应，从而与命题推断（例如在因果贝叶斯网络中）相比大幅加快因果推断。在我们的实证评估中，我们展示了

    arXiv:2403.10184v1 Announce Type: new  Abstract: Lifted inference exploits symmetries in probabilistic graphical models by using a representative for indistinguishable objects, thereby speeding up query answering while maintaining exact answers. Even though lifting is a well-established technique for the task of probabilistic inference in relational domains, it has not yet been applied to the task of causal inference. In this paper, we show how lifting can be applied to efficiently compute causal effects in relational domains. More specifically, we introduce parametric causal factor graphs as an extension of parametric factor graphs incorporating causal knowledge and give a formal semantics of interventions therein. We further present the lifted causal inference algorithm to compute causal effects on a lifted level, thereby drastically speeding up causal inference compared to propositional inference, e.g., in causal Bayesian networks. In our empirical evaluation, we demonstrate the eff
    
[^39]: 机器学习中的重要性加权简要调查

    A Short Survey on Importance Weighting for Machine Learning

    [https://arxiv.org/abs/2403.10175](https://arxiv.org/abs/2403.10175)

    重要性加权是统计学和机器学习中的基本程序，通过对目标函数或概率分布进行加权，可以保证监督学习在训练和测试分布之间差异的情况下具有统计上期望的性质

    

    重要性加权是统计学和机器学习中的一项基本程序，根据某种意义上实例的重要性对目标函数或概率分布进行加权。这一简单而有用的思想的广泛应用导致了许多重要性加权的应用。例如，据知，在关于训练和测试分布之间差异的假设下的监督学习，通过密度比的重要性加权可以保证统计上期望的性质。这项调查总结了机器学习和相关研究中重要性加权的广泛应用。

    arXiv:2403.10175v1 Announce Type: cross  Abstract: Importance weighting is a fundamental procedure in statistics and machine learning that weights the objective function or probability distribution based on the importance of the instance in some sense. The simplicity and usefulness of the idea has led to many applications of importance weighting. For example, it is known that supervised learning under an assumption about the difference between the training and test distributions, called distribution shift, can guarantee statistically desirable properties through importance weighting by their density ratio. This survey summarizes the broad applications of importance weighting in machine learning and related research.
    
[^40]: 一种用于基于事件的对象检测的混合SNN-ANN网络，具有空间和时间注意力机制

    A Hybrid SNN-ANN Network for Event-based Object Detection with Spatial and Temporal Attention

    [https://arxiv.org/abs/2403.10173](https://arxiv.org/abs/2403.10173)

    提出了一种用于基于事件的对象检测的混合SNN-ANN网络，包括了新颖的基于注意力的桥接模块，能够有效捕捉稀疏的空间和时间关系，以提高任务性能。

    

    事件相机提供高时间分辨率和动态范围，几乎没有运动模糊，非常适合对象检测任务。尖峰神经网络（SNN）与事件驱动感知数据天生匹配，在神经形态硬件上能够实现超低功耗和低延迟推断，而人工神经网络（ANN）则展示出更稳定的训练动态和更快的收敛速度，从而具有更好的任务性能。混合SNN-ANN方法是一种有前途的替代方案，能够利用SNN和ANN体系结构的优势。在这项工作中，我们引入了第一个基于混合注意力的SNN-ANN骨干网络，用于使用事件相机进行对象检测。我们提出了一种新颖的基于注意力的SNN-ANN桥接模块，从SNN层中捕捉稀疏的空间和时间关系，并将其转换为密集特征图，供骨干网络的ANN部分使用。实验结果表明，我们提出的m

    arXiv:2403.10173v1 Announce Type: cross  Abstract: Event cameras offer high temporal resolution and dynamic range with minimal motion blur, making them promising for object detection tasks. While Spiking Neural Networks (SNNs) are a natural match for event-based sensory data and enable ultra-energy efficient and low latency inference on neuromorphic hardware, Artificial Neural Networks (ANNs) tend to display more stable training dynamics and faster convergence resulting in greater task performance. Hybrid SNN-ANN approaches are a promising alternative, enabling to leverage the strengths of both SNN and ANN architectures. In this work, we introduce the first Hybrid Attention-based SNN-ANN backbone for object detection using event cameras. We propose a novel Attention-based SNN-ANN bridge module to capture sparse spatial and temporal relations from the SNN layer and convert them into dense feature maps for the ANN part of the backbone. Experimental results demonstrate that our proposed m
    
[^41]: AUTONODE: 一种用于认知GUI自动化的神经图自学习引擎

    AUTONODE: A Neuro-Graphic Self-Learnable Engine for Cognitive GUI Automation

    [https://arxiv.org/abs/2403.10171](https://arxiv.org/abs/2403.10171)

    AUTONODE是一种神经图自学习引擎，通过先进的神经图技术实现自主导航和任务执行，从而提升了智能代理人在网络界面上适应动态环境的效率。

    

    在大型语言模型（LLMs）领域的最新进展中，出现了一些具有增强的认知能力和复杂推理能力的能够解决机器人流程自动化（RPA）挑战的代理人。这一发展标志着在目标实现方面出现了可扩展性和类似人类的适应性的新时代。在这种背景下，我们介绍了AUTONODE（通过在线神经图操作和深度探索实现自主用户界面转换）。AUTONODE采用先进的神经图技术，促进了对网络界面的自主导航和任务执行，从而消除了预定义脚本或手动干预的必要性。我们的引擎赋予代理人理解和实施复杂工作流的能力，以无与伦比的效率适应动态网络环境。我们的方法将认知功能与机器人自动化相结合，赋予AUTONODE从abiliti到abi的能力

    arXiv:2403.10171v1 Announce Type: new  Abstract: In recent advancements within the domain of Large Language Models (LLMs), there has been a notable emergence of agents capable of addressing Robotic Process Automation (RPA) challenges through enhanced cognitive capabilities and sophisticated reasoning. This development heralds a new era of scalability and human-like adaptability in goal attainment. In this context, we introduce AUTONODE (Autonomous User-interface Transformation through Online Neuro-graphic Operations and Deep Exploration). AUTONODE employs advanced neuro-graphical techniques to facilitate autonomous navigation and task execution on web interfaces, thereby obviating the necessity for predefined scripts or manual intervention. Our engine empowers agents to comprehend and implement complex workflows, adapting to dynamic web environments with unparalleled efficiency. Our methodology synergizes cognitive functionalities with robotic automation, endowing AUTONODE with the abi
    
[^42]: 因子图中可交换因子的高效检测

    Efficient Detection of Exchangeable Factors in Factor Graphs

    [https://arxiv.org/abs/2403.10167](https://arxiv.org/abs/2403.10167)

    提出了一种在因子图中高效检测可交换因子的算法，可以大大减少计算工作量。

    

    为了实现对领域大小的可计算概率推断，提出了提升式概率推断，利用概率图模型中的对称性。然而，检查两个因子是否编码等效语义从而是可交换的，在计算上是昂贵的。本文高效解决了在因子图中检测可交换因子的问题。具体来说，引入了检测可交换因子（DEFT）算法，可以大大减少实践中检查两个因子是否可交换的计算工作量。我们证明DEFT有效地识别限制以大幅减少排列数量，并在实证评估中验证了DEFT的效率。

    arXiv:2403.10167v1 Announce Type: new  Abstract: To allow for tractable probabilistic inference with respect to domain sizes, lifted probabilistic inference exploits symmetries in probabilistic graphical models. However, checking whether two factors encode equivalent semantics and hence are exchangeable is computationally expensive. In this paper, we efficiently solve the problem of detecting exchangeable factors in a factor graph. In particular, we introduce the detection of exchangeable factors (DEFT) algorithm, which allows us to drastically reduce the computational effort for checking whether two factors are exchangeable in practice. While previous approaches iterate all $O(n!)$ permutations of a factor's argument list in the worst case (where $n$ is the number of arguments of the factor), we prove that DEFT efficiently identifies restrictions to drastically reduce the number of permutations and validate the efficiency of DEFT in our empirical evaluation.
    
[^43]: CoReEcho: 2D+时间超声心动图分析的连续表示学习

    CoReEcho: Continuous Representation Learning for 2D+time Echocardiography Analysis

    [https://arxiv.org/abs/2403.10164](https://arxiv.org/abs/2403.10164)

    CoReEcho提出了针对直接EF回归的连续表示学习框架，在最大的超声心动图数据集上表现优越。

    

    深度学习模型一直在不同模态的医学图像分析方面取得进展，包括超声心动图，在提供全面的端到端训练流水线的同时。然而，端到端训练流水线使得学习到的表示难以解释，并且可能无法捕获超声心动图片段之间的连续关系，导致存在虚假相关性，可能对泛化能力产生负面影响。为了缓解这一问题，我们提出了CoReEcho，这是一个强调针对直接EF回归的连续表示的新型训练框架。我们的广泛实验证明CoReEcho：1）在最大的超声心动图数据集（EchoNet-Dynamic）上表现优于当前的最先进技术（SOTA），平均绝对误差为3.90和R2 o

    arXiv:2403.10164v1 Announce Type: cross  Abstract: Deep learning (DL) models have been advancing automatic medical image analysis on various modalities, including echocardiography, by offering a comprehensive end-to-end training pipeline. This approach enables DL models to regress ejection fraction (EF) directly from 2D+time echocardiograms, resulting in superior performance. However, the end-to-end training pipeline makes the learned representations less explainable. The representations may also fail to capture the continuous relation among echocardiogram clips, indicating the existence of spurious correlations, which can negatively affect the generalization. To mitigate this issue, we propose CoReEcho, a novel training framework emphasizing continuous representations tailored for direct EF regression. Our extensive experiments demonstrate that CoReEcho: 1) outperforms the current state-of-the-art (SOTA) on the largest echocardiography dataset (EchoNet-Dynamic) with MAE of 3.90 & R2 o
    
[^44]: 函数图卷积网络：一个统一的多任务和多模态学习框架，促进健康和社会关怀洞见

    Functional Graph Convolutional Networks: A unified multi-task and multi-modal learning framework to facilitate health and social-care insights

    [https://arxiv.org/abs/2403.10158](https://arxiv.org/abs/2403.10158)

    该论文提出了一个新颖的函数图卷积网络框架，结合了函数数据分析和图卷积网络，解决了数字健康和纵向研究中的多任务和多模态学习复杂性，关键创新包括任务特定嵌入组件、执行分类、回归和预测的能力，以及创建知识图进行数据解释。

    

    本文介绍了一种新颖的函数图卷积网络（funGCN）框架，将函数数据分析和图卷积网络相结合，以解决数字健康和纵向研究中的多任务和多模态学习的复杂性。随着健康解决方案对改善医疗保健和社会支持的重要性日益增长，确保各年龄段的健康生活和促进幸福感，funGCN提供了一种统一的方法来处理多个实体的多元纵向数据，并确保即使在样本量较小的情况下也具有可解释性。关键创新包括管理不同数据类型的任务特定嵌入组件、执行分类、回归和预测的能力，以及创建知识图以获取洞察性数据解释。通过模拟实验和实际数据应用验证了funGCN的有效性。

    arXiv:2403.10158v1 Announce Type: cross  Abstract: This paper introduces a novel Functional Graph Convolutional Network (funGCN) framework that combines Functional Data Analysis and Graph Convolutional Networks to address the complexities of multi-task and multi-modal learning in digital health and longitudinal studies. With the growing importance of health solutions to improve health care and social support, ensure healthy lives, and promote well-being at all ages, funGCN offers a unified approach to handle multivariate longitudinal data for multiple entities and ensures interpretability even with small sample sizes. Key innovations include task-specific embedding components that manage different data types, the ability to perform classification, regression, and forecasting, and the creation of a knowledge graph for insightful data interpretation. The efficacy of funGCN is validated through simulation experiments and a real-data application.
    
[^45]: NLP验证：走向一种通用的用于认证鲁棒性的方法论

    NLP Verification: Towards a General Methodology for Certifying Robustness

    [https://arxiv.org/abs/2403.10144](https://arxiv.org/abs/2403.10144)

    本文尝试总结和评估由该领域迄今进展而形成的NLP验证流程的一般组成部分，贡献在于提出了将句子嵌入连续空间得到的可验证子空间的一般描述。

    

    深度神经网络在自然语言处理（NLP）领域取得了显著成功，确保它们的安全性和可靠性至关重要：在安全关键的情境中，这些模型必须对变化或攻击具有鲁棒性，并能对其输出给出保证。与计算机视觉不同，NLP缺乏一个统一的验证方法论，尽管近年来文献中取得了一些进展，但对于NLP验证的实用问题常常涉及不深。在本文中，我们尝试提炼和评估一个NLP验证流程的一般组成部分，该流程来源于迄今为止该领域的进展。我们的贡献有两方面：首先，我们给出了将句子嵌入连续空间得到的可验证子空间的一般描述。我们确定了可验证子空间的语义泛化技术挑战，并提出了一种有效处理的方法。

    arXiv:2403.10144v1 Announce Type: cross  Abstract: Deep neural networks have exhibited substantial success in the field of Natural Language Processing (NLP) and ensuring their safety and reliability is crucial: there are safety critical contexts where such models must be robust to variability or attack, and give guarantees over their output. Unlike Computer Vision, NLP lacks a unified verification methodology and, despite recent advancements in literature, they are often light on the pragmatical issues of NLP verification. In this paper, we make an attempt to distil and evaluate general components of an NLP verification pipeline, that emerges from the progress in the field to date. Our contributions are two-fold. Firstly, we give a general characterisation of verifiable subspaces that result from embedding sentences into continuous spaces. We identify, and give an effective method to deal with, the technical challenge of semantic generalisability of verified subspaces; and propose it a
    
[^46]: 利用视觉模拟量表对重复测量的响应风格进行表征

    Response Style Characterization for Repeated Measures Using the Visual Analogue Scale

    [https://arxiv.org/abs/2403.10136](https://arxiv.org/abs/2403.10136)

    本研究针对重复测量的视觉模拟量表数据开发了一种新颖的响应风格（RP）表征方法，以解决在VAS中处理RP的困难。

    

    自我报告测量（例如，利克特量表）被广泛用于评估主观健康感知。最近，由于其能够精确且便于评估人们感受的能力，视觉模拟量表（VAS），一种滑动条量表，变得流行起来。这些数据可能会受到响应风格（RS）的影响，RS是一种用户依赖的系统性倾向，无论问卷说明如何都会发生。尽管在个体间分析中尤为重要，但对VAS中RS（表示为响应剖面（RP））的处理并未受到足够关注，因为它主要用于个体内监测且不太受RP的影响。然而，VAS测量通常需要对同一问卷项目进行重复自我报告，这使得难以在利克特量表上应用传统方法。在这项研究中，我们开发了一种新颖的RP表征方法，适用于各种类型的重复测量的VAS数据。

    arXiv:2403.10136v1 Announce Type: cross  Abstract: Self-report measures (e.g., Likert scales) are widely used to evaluate subjective health perceptions. Recently, the visual analog scale (VAS), a slider-based scale, has become popular owing to its ability to precisely and easily assess how people feel. These data can be influenced by the response style (RS), a user-dependent systematic tendency that occurs regardless of questionnaire instructions. Despite its importance, especially in between-individual analysis, little attention has been paid to handling the RS in the VAS (denoted as response profile (RP)), as it is mainly used for within-individual monitoring and is less affected by RP. However, VAS measurements often require repeated self-reports of the same questionnaire items, making it difficult to apply conventional methods on a Likert scale. In this study, we developed a novel RP characterization method for various types of repeatedly measured VAS data. This approach involves t
    
[^47]: 整体优于总和：在上下文学习中使用聚合演示进行顺序推荐

    The Whole is Better than the Sum: Using Aggregated Demonstrations in In-Context Learning for Sequential Recommendation

    [https://arxiv.org/abs/2403.10135](https://arxiv.org/abs/2403.10135)

    探索在顺序推荐中使用上下文学习的方法，提出了一种聚合演示的新颖方法LLMSRec-Syn，在多个数据集上实验证明其优于现有基于LLM的方法。

    

    大型语言模型（LLMs）在各种自然语言处理任务中展现出优秀性能。为了将LLMs作为强大的顺序推荐系统，我们探索了上下文学习方法用于顺序推荐。我们研究了指导格式、任务一致性、演示选择和演示数量对模型的影响。我们提出了一种新颖的方法LLMSRec-Syn，通过将多个演示用户整合成一个聚合演示来提高准确性。我们在三个推荐数据集上进行了实验证明，LLMSRec-Syn优于最先进的基于LLM的顺序推荐方法。在某些情况下，LLMSRec-Syn可以与甚至优于监督学习方法。我们的代码公开在https://github.com/demoleiwang/LLMSRec_Syn。

    arXiv:2403.10135v1 Announce Type: cross  Abstract: Large language models (LLMs) have shown excellent performance on various NLP tasks. To use LLMs as strong sequential recommenders, we explore the in-context learning approach to sequential recommendation. We investigate the effects of instruction format, task consistency, demonstration selection, and number of demonstrations. As increasing the number of demonstrations in ICL does not improve accuracy despite using a long prompt, we propose a novel method called LLMSRec-Syn that incorporates multiple demonstration users into one aggregated demonstration. Our experiments on three recommendation datasets show that LLMSRec-Syn outperforms state-of-the-art LLM-based sequential recommendation methods. In some cases, LLMSRec-Syn can perform on par with or even better than supervised learning methods. Our code is publicly available at https://github.com/demoleiwang/LLMSRec_Syn.
    
[^48]: RAFT：将语言模型调整到特定领域RAG

    RAFT: Adapting Language Model to Domain Specific RAG

    [https://arxiv.org/abs/2403.10131](https://arxiv.org/abs/2403.10131)

    提出了一种名为RAFT的训练方法，通过引用相关文档中能够帮助回答问题的正确序列来改善模型在特定领域中回答问题的能力。

    

    现在，通过大规模文本数据预训练大型语言模型（LLMs）已成为一种标准范式。在将这些LLMs用于许多下游应用程序时，通常还会通过基于RAG的提示或微调，将新知识（例如，时效新闻或私有领域知识）嵌入预训练模型中。然而，模型获得这些新知识的最佳方法仍然是一个未解决的问题。在本文中，我们提出了检索增强微调（RAFT），这是一种训练方法，旨在提高模型在"开放书籍"的领域设置中回答问题的能力。在RAFT中，给定一个问题和一组检索到的文档，我们训练模型忽略那些对回答问题没有帮助的文档，我们称之为干扰文档。RAFT通过原文引用相关文档中能够帮助回答问题的正确序列来实现这一点。

    arXiv:2403.10131v1 Announce Type: cross  Abstract: Pretraining Large Language Models (LLMs) on large corpora of textual data is now a standard paradigm. When using these LLMs for many downstream applications, it is common to additionally bake in new knowledge (e.g., time-critical news, or private domain knowledge) into the pretrained model either through RAG-based-prompting, or fine-tuning. However, the optimal methodology for the model to gain such new knowledge remains an open question. In this paper, we present Retrieval Augmented FineTuning (RAFT), a training recipe that improves the model's ability to answer questions in a "open-book" in-domain settings. In RAFT, given a question, and a set of retrieved documents, we train the model to ignore those documents that don't help in answering the question, which we call, distractor documents. RAFT accomplishes this by citing verbatim the right sequence from the relevant document that would help answer the question. This coupled with RAF
    
[^49]: 单智能体与多智能体的私密主动感知：深度神经进化方法

    Single- and Multi-Agent Private Active Sensing: A Deep Neuroevolution Approach

    [https://arxiv.org/abs/2403.10112](https://arxiv.org/abs/2403.10112)

    本文提出了一种基于神经进化方法的单智能体与多智能体私密主动感知框架，通过在无线传感器网络中进行异常检测示例用例的数值实验验证了该方法的优越性。

    

    本文关注存在窥视者情况下的主动假设测试中的一个集中式问题和一个分散式问题。针对包括单个合法智能体的集中式问题，我们提出了基于神经进化（NE）的新框架；而针对分散式问题，我们开发了一种新颖的基于NE的方法，用于解决协作多智能体任务，这种方法有趣地保持了单一智能体NE的所有计算优势。通过对无线传感器网络上异常检测示例用例中的数值实验，验证了所提出的EAHT方法优于传统的主动假设测试策略以及基于学习的方法。

    arXiv:2403.10112v1 Announce Type: new  Abstract: In this paper, we focus on one centralized and one decentralized problem of active hypothesis testing in the presence of an eavesdropper. For the centralized problem including a single legitimate agent, we present a new framework based on NeuroEvolution (NE), whereas, for the decentralized problem, we develop a novel NE-based method for solving collaborative multi-agent tasks, which interestingly maintains all computational benefits of single-agent NE. The superiority of the proposed EAHT approaches over conventional active hypothesis testing policies, as well as learning-based methods, is validated through numerical investigations in an example use case of anomaly detection over wireless sensor networks.
    
[^50]: 知识图谱上复杂查询回答的元算子

    Meta Operator for Complex Query Answering on Knowledge Graphs

    [https://arxiv.org/abs/2403.10110](https://arxiv.org/abs/2403.10110)

    本研究提出了一种元学习算法，用于在知识图谱上回答复杂查询，通过学习元算子并将其适应于各种复杂查询，实现了泛化性能的提升。

    

    知识图谱包含有信息性的事实知识，但通常被认为是不完整的。为了在不完整知识下回答复杂查询，提出了基于学习的复杂查询回答（CQA）模型，直接从查询-答案样本中学习，避免直接遍历不完整的图数据。现有研究将复杂查询回答模型的训练制定为多任务学习，并需要大量的训练样本。在这项工作中，我们探讨了复杂查询的组合结构，并认为不同的逻辑运算符类型，而不是不同的复杂查询类型，是改进泛化性能的关键。因此，我们提出了一种元学习算法，学习元运算符并将其适应于各种复杂查询下的不同运算符实例。实证结果表明，学习元算子比学习原始CQA或元更为有效。

    arXiv:2403.10110v1 Announce Type: cross  Abstract: Knowledge graphs contain informative factual knowledge but are considered incomplete. To answer complex queries under incomplete knowledge, learning-based Complex Query Answering (CQA) models are proposed to directly learn from the query-answer samples to avoid the direct traversal of incomplete graph data. Existing works formulate the training of complex query answering models as multi-task learning and require a large number of training samples. In this work, we explore the compositional structure of complex queries and argue that the different logical operator types, rather than the different complex query types, are the key to improving generalizability. Accordingly, we propose a meta-learning algorithm to learn the meta-operators with limited data and adapt them to different instances of operators under various complex queries. Empirical results show that learning meta-operators is more effective than learning original CQA or meta
    
[^51]: 通过多个LLM合作推理提升人类中心动态场景理解

    Enhancing Human-Centered Dynamic Scene Understanding via Multiple LLMs Collaborated Reasoning

    [https://arxiv.org/abs/2403.10107](https://arxiv.org/abs/2403.10107)

    通过多个大型预训练语言模型的合作推理，本研究提出了V-HOI Multi-LLMs Collaborated Reasoning（V-HOI MLCR）框架，用于增强当前V-HOI检测模型的性能。

    

    人类中心的动态场景理解在增强机器人和自主系统的能力中起着至关重要的作用，其中视频人-物交互（V-HOI）检测是语义场景理解中的关键任务，旨在全面理解视频中的HOI关系，以使移动机器人和自动驾驶系统的行为决策受益。虽然先前的V-HOI检测模型在特定数据集上取得了显著进展，但它们仍然缺乏像人类一样的通用推理能力，无法有效引导HOI关系。在本研究中，我们提出了V-HOI多LLM协同推理（V-HOI MLCR），这是一个新颖的框架，由一系列即插即用的模块组成，可以通过利用不同现成大型预训练语言模型（LLMs）的强大推理能力，促进当前V-HOI检测模型的性能。

    arXiv:2403.10107v1 Announce Type: cross  Abstract: Human-centered dynamic scene understanding plays a pivotal role in enhancing the capability of robotic and autonomous systems, in which Video-based Human-Object Interaction (V-HOI) detection is a crucial task in semantic scene understanding, aimed at comprehensively understanding HOI relationships within a video to benefit the behavioral decisions of mobile robots and autonomous driving systems. Although previous V-HOI detection models have made significant strides in accurate detection on specific datasets, they still lack the general reasoning ability like human beings to effectively induce HOI relationships. In this study, we propose V-HOI Multi-LLMs Collaborated Reasoning (V-HOI MLCR), a novel framework consisting of a series of plug-and-play modules that could facilitate the performance of current V-HOI detection models by leveraging the strong reasoning ability of different off-the-shelf pre-trained large language models (LLMs). 
    
[^52]: 使用贝叶斯强化学习的信念辅助导航以避免盲点中的人类

    Belief Aided Navigation using Bayesian Reinforcement Learning for Avoiding Humans in Blind Spots

    [https://arxiv.org/abs/2403.10105](https://arxiv.org/abs/2403.10105)

    使用BNBRL+算法，结合部分可观察马尔可夫决策过程和贝叶斯神经网络，实现了在不可观察区域评估风险和制定移动策略的目的，并通过整合动态关系和社会规范，实现了社交感知导航。

    

    移动机器人导航的最新研究集中在拥挤环境中的社交感知导航。然而，现有方法未能充分考虑人机交互，并要求来自全向传感器的准确位置信息，使它们不适用于实际应用。针对这一需求，本研究引入了一种新颖算法BNBRL+，基于部分可观察马尔可夫决策过程框架，评估不可观察区域的风险，并在不确定性下制定移动策略。BNBRL+将信念算法与贝叶斯神经网络结合，根据人类的位置数据概率推断信念。它进一步整合了机器人、人类和推断信念之间的动态关系，确定导航路径，并在奖励函数内嵌入社会规范，从而促进社交感知导航。通过不同风险的实验

    arXiv:2403.10105v1 Announce Type: cross  Abstract: Recent research on mobile robot navigation has focused on socially aware navigation in crowded environments. However, existing methods do not adequately account for human robot interactions and demand accurate location information from omnidirectional sensors, rendering them unsuitable for practical applications. In response to this need, this study introduces a novel algorithm, BNBRL+, predicated on the partially observable Markov decision process framework to assess risks in unobservable areas and formulate movement strategies under uncertainty. BNBRL+ consolidates belief algorithms with Bayesian neural networks to probabilistically infer beliefs based on the positional data of humans. It further integrates the dynamics between the robot, humans, and inferred beliefs to determine the navigation paths and embeds social norms within the reward function, thereby facilitating socially aware navigation. Through experiments in various risk
    
[^53]: 在微调深度神经网络上的自适应随机特征正则化

    Adaptive Random Feature Regularization on Fine-tuning Deep Neural Networks

    [https://arxiv.org/abs/2403.10097](https://arxiv.org/abs/2403.10097)

    提出了一种名为AdaRand的简单方法，在微调深度神经网络时可以自适应地改变特征向量分布，从而提高性能而不需要辅助源信息。

    

    虽然微调是训练深度神经网络的一种事实标准方法，但在使用小型目标数据集时仍然存在过拟合问题。先前的方法通过保持对源数据集的知识或引入诸如对比损失之类的正则化项来提高微调性能。然而，这些方法需要辅助源信息（例如，源标签或数据集）或重复附加计算。在本文中，我们提出了一种称为自适应随机特征正则化（AdaRand）的简单方法。AdaRand可以帮助训练模型的特征提取器在没有辅助源信息的情况下，通过适度的计算成本，自适应地改变下游分类任务的特征向量分布。为此，AdaRand通过最小化特征向量和从类条件高斯分布中采样的随机参考向量之间的差距。

    arXiv:2403.10097v1 Announce Type: cross  Abstract: While fine-tuning is a de facto standard method for training deep neural networks, it still suffers from overfitting when using small target datasets. Previous methods improve fine-tuning performance by maintaining knowledge of the source datasets or introducing regularization terms such as contrastive loss. However, these methods require auxiliary source information (e.g., source labels or datasets) or heavy additional computations. In this paper, we propose a simple method called adaptive random feature regularization (AdaRand). AdaRand helps the feature extractors of training models to adaptively change the distribution of feature vectors for downstream classification tasks without auxiliary source information and with reasonable computation costs. To this end, AdaRand minimizes the gap between feature vectors and random reference vectors that are sampled from class conditional Gaussian distributions. Furthermore, AdaRand dynamicall
    
[^54]: 利用RLAIF进行意图调节和无毒对抗生成的多任务指导调节

    Intent-conditioned and Non-toxic Counterspeech Generation using Multi-Task Instruction Tuning with RLAIF

    [https://arxiv.org/abs/2403.10088](https://arxiv.org/abs/2403.10088)

    该研究引入了CoARL框架，通过模拟社会偏见中的语用启示来增强对抗性言论生成，利用顺序多指导调节和强化学习生成意图调节的对抗性言论。

    

    对抗性言论被定义为减缓网络仇恨言论的回应，越来越被用作一种非审查解决方案。有效应对仇恨言论涉及消除通常在简短的单句陈述或虐待中暗示的刻板印象、偏见和偏见。这些隐含的表达挑战语言模型，特别是在seq2seq任务中，因为模型性能通常在更长上下文中表现出色。我们的研究引入了CoARL，这是一种新颖的框架，通过建模在仇恨言论中暗含的社会偏见的实用含义来增强对抗性言论生成。CoARL的前两个阶段涉及顺序多指导调节，教导模型理解攻击性陈述的意图、反应和危害，然后学习生成意图调节的对抗性言论的特定任务低秩适配器权重。最后一个阶段使用强化学习对输出进行微调，以提高效果和无毒性。

    arXiv:2403.10088v1 Announce Type: cross  Abstract: Counterspeech, defined as a response to mitigate online hate speech, is increasingly used as a non-censorial solution. Addressing hate speech effectively involves dispelling the stereotypes, prejudices, and biases often subtly implied in brief, single-sentence statements or abuses. These implicit expressions challenge language models, especially in seq2seq tasks, as model performance typically excels with longer contexts. Our study introduces CoARL, a novel framework enhancing counterspeech generation by modeling the pragmatic implications underlying social biases in hateful statements. CoARL's first two phases involve sequential multi-instruction tuning, teaching the model to understand intents, reactions, and harms of offensive statements, and then learning task-specific low-rank adapter weights for generating intent-conditioned counterspeech. The final phase uses reinforcement learning to fine-tune outputs for effectiveness and non-
    
[^55]: 使用大型语言模型生成针对非功能属性的系统级测试程序

    Large Language Models to Generate System-Level Test Programs Targeting Non-functional Properties

    [https://arxiv.org/abs/2403.10086](https://arxiv.org/abs/2403.10086)

    本文提出使用大型语言模型（LLMs）生成测试程序，以优化非功能属性。

    

    系统级测试（SLT）已经成为集成电路测试流程的一部分超过十年，并且仍然越来越重要。然而，目前不存在针对测试程序生成的系统化方法，特别是针对被测设备（DUT）的非功能属性。本文提出使用大型语言模型（LLMs）来生成测试程序。我们首次尝试了预训练的LLMs在测试程序生成中的表现，以优化DUT的非功能属性。

    arXiv:2403.10086v1 Announce Type: cross  Abstract: System-Level Test (SLT) has been a part of the test flow for integrated circuits for over a decade and still gains importance. However, no systematic approaches exist for test program generation, especially targeting non-functional properties of the Device under Test (DUT). Currently, test engineers manually compose test suites from off-the-shelf software, approximating the end-user environment of the DUT. This is a challenging and tedious task that does not guarantee sufficient control over non-functional properties. This paper proposes Large Language Models (LLMs) to generate test programs. We take a first glance at how pre-trained LLMs perform in test program generation to optimize non-functional properties of the DUT. Therefore, we write a prompt to generate C code snippets that maximize the instructions per cycle of a super-scalar, out-of-order architecture in simulation. Additionally, we apply prompt and hyperparameter optimizati
    
[^56]: 学习面向物体的视觉预测中的物理动力学

    Learning Physical Dynamics for Object-centric Visual Prediction

    [https://arxiv.org/abs/2403.10079](https://arxiv.org/abs/2403.10079)

    本文提出了一种学习面向物体的视觉预测中的物理动力学的模型，通过学习物体之间的视觉动力学进行未来预测，具有两个关键模块：感知模块和动力模块。

    

    arXiv:2403.10079v1 公告类型: 跨领域 摘要: 模拟视觉场景的潜在动力学并推断未来情况对于人类智能至关重要。许多尝试赋予智能系统这种物理理解和预测能力。然而，大多数现有方法侧重于像素到像素的预测，这种方法计算成本高昂，同时缺乏对视频背后物理动力学的深入理解。最近，出现了面向物体的预测方法，并引起了越来越多的关注。受此启发，本文提出了一种无监督的面向物体的预测模型，通过学习物体之间的视觉动力学进行未来预测。我们的模型由两个模块组成，感知模块和动力模块。感知模块用于将图像分解为多个物体，并使用一组面向物体的表示合成图像。动力模块融合了上下文信息，进行环境建模。

    arXiv:2403.10079v1 Announce Type: cross  Abstract: The ability to model the underlying dynamics of visual scenes and reason about the future is central to human intelligence. Many attempts have been made to empower intelligent systems with such physical understanding and prediction abilities. However, most existing methods focus on pixel-to-pixel prediction, which suffers from heavy computational costs while lacking a deep understanding of the physical dynamics behind videos. Recently, object-centric prediction methods have emerged and attracted increasing interest. Inspired by it, this paper proposes an unsupervised object-centric prediction model that makes future predictions by learning visual dynamics between objects. Our model consists of two modules, perceptual, and dynamic module. The perceptual module is utilized to decompose images into several objects and synthesize images with a set of object-centric representations. The dynamic module fuses contextual information, takes env
    
[^57]: 边界问题：一个双层主动微调框架

    Boundary Matters: A Bi-Level Active Finetuning Framework

    [https://arxiv.org/abs/2403.10069](https://arxiv.org/abs/2403.10069)

    提出了一个双层主动微调框架，旨在通过一次选择过程来选择注释样本，其中包括核心样本选择以确保多样性和边界样本选择以处理不确定性。

    

    预训练-微调范式在视觉任务和其他领域已经得到广泛采用，但面临高样本注释成本的重要挑战。为了减轻这一挑战，出现了主动微调的概念，旨在在有限预算内选择模型微调的最合适样本。传统的主动学习方法在这种设置下往往面临批量选择中的固有偏见。此外，最近的主动微调方法主要集中在使所选择的子集分布与整体数据池一致，仅关注多样性。在本文中，我们提出了一个双层主动微调框架，在一次选择过程中选择注释样本，包括两个阶段：用于多样性的核心样本选择和用于不确定性的边界样本选择。该过程从识别伪类中心开始，然后进行创新性的d

    arXiv:2403.10069v1 Announce Type: cross  Abstract: The pretraining-finetuning paradigm has gained widespread adoption in vision tasks and other fields, yet it faces the significant challenge of high sample annotation costs. To mitigate this, the concept of active finetuning has emerged, aiming to select the most appropriate samples for model finetuning within a limited budget. Traditional active learning methods often struggle in this setting due to their inherent bias in batch selection. Furthermore, the recent active finetuning approach has primarily concentrated on aligning the distribution of selected subsets with the overall data pool, focusing solely on diversity. In this paper, we propose a Bi-Level Active Finetuning framework to select the samples for annotation in one shot, which includes two stages: core sample selection for diversity, and boundary sample selection for uncertainty. The process begins with the identification of pseudo-class centers, followed by an innovative d
    
[^58]: 统一的无投影算法用于对抗性DR-次模优化

    Unified Projection-Free Algorithms for Adversarial DR-Submodular Optimization

    [https://arxiv.org/abs/2403.10063](https://arxiv.org/abs/2403.10063)

    本文提出了统一的无投影Frank-Wolfe类型算法，用于对抗性DR-次模优化，在不同场景下取得了令人瞩目的次线性 $\alpha$-后悔上界，并在单调设置中实现了无投影算法的最新次线性 $\alpha$-后悔上界。

    

    本文介绍了统一的无投影Frank-Wolfe类型算法，用于对抗性连续DR-次模优化，涵盖了诸如全信息和（半）强敌反馈、单调和非单调函数、不同约束以及类型的随机查询等场景。在非单调设置中考虑的每个问题中，所提出的算法要么是第一个具有证明的次线性 $\alpha$-后悔上界的算法，要么具有比现有技术更好的 $\alpha$-后悔上界，其中 $\alpha$ 是离线设置中的相应近似上界。在单调设置中，所提出的方法在8个考虑的情况中的7种中是无投影算法的最新次线性 $\alpha$-后悔上界，同时与剩余情况的结果相匹配。此外，本文还研究了对抗性DR-次模优化的半强敌和强敌反馈，推进了对这一问题的理解。

    arXiv:2403.10063v1 Announce Type: cross  Abstract: This paper introduces unified projection-free Frank-Wolfe type algorithms for adversarial continuous DR-submodular optimization, spanning scenarios such as full information and (semi-)bandit feedback, monotone and non-monotone functions, different constraints, and types of stochastic queries. For every problem considered in the non-monotone setting, the proposed algorithms are either the first with proven sub-linear $\alpha$-regret bounds or have better $\alpha$-regret bounds than the state of the art, where $\alpha$ is a corresponding approximation bound in the offline setting. In the monotone setting, the proposed approach gives state-of-the-art sub-linear $\alpha$-regret bounds among projection-free algorithms in 7 of the 8 considered cases while matching the result of the remaining case. Additionally, this paper addresses semi-bandit and bandit feedback for adversarial DR-submodular optimization, advancing the understanding of this
    
[^59]: 不要半心半意：捕捉连续指导调整中的关键部分信息

    Don't Half-listen: Capturing Key-part Information in Continual Instruction Tuning

    [https://arxiv.org/abs/2403.10056](https://arxiv.org/abs/2403.10056)

    提出了一种基于关键部分信息增益的新型连续指导调整方法，通过动态重放数据和优化训练目标，使LLMs能够捕捉任务感知信息和减轻过度拟合。

    

    arXiv:2403.10056v1 公告类型: 跨领域 摘要：大型语言模型（LLMs）的指导调整可以驱使它们在特定下游任务中产生符合人类目标的结果。然而，LLMs的连续指导调整（CIT）过程可能会带来灾难性遗忘（CF）问题，导致先前学到的能力退化。最近的方法尝试通过修改模型或重放数据来缓解CF问题，但这可能只记住指令的表面模式并在留存任务上感到困惑。在本文中，我们提出了一种基于关键部分信息增益（KPIG）的新型连续指导调整方法。我们的方法计算掩盖部分的信息增益，动态重放数据并优化训练目标，从而使LLMs能够捕捉与正确响应相关的任务感知信息，并减轻对指导中通用描述的过度拟合。此外，我们提出了两个指标，P分和V分，

    arXiv:2403.10056v1 Announce Type: cross  Abstract: Instruction tuning for large language models (LLMs) can drive them to produce results consistent with human goals in specific downstream tasks. However, the process of continual instruction tuning (CIT) for LLMs may bring about the catastrophic forgetting (CF) problem, where previously learned abilities are degraded. Recent methods try to alleviate the CF problem by modifying models or replaying data, which may only remember the surface-level pattern of instructions and get confused on held-out tasks. In this paper, we propose a novel continual instruction tuning method based on Key-part Information Gain (KPIG). Our method computes the information gain on masked parts to dynamically replay data and refine the training objective, which enables LLMs to capture task-aware information relevant to the correct response and alleviate overfitting to general descriptions in instructions. In addition, we propose two metrics, P-score and V-score,
    
[^60]: PPM：用于点击率预测的预训练插件模型

    PPM : A Pre-trained Plug-in Model for Click-through Rate Prediction

    [https://arxiv.org/abs/2403.10049](https://arxiv.org/abs/2403.10049)

    PPM是用于点击率预测的预训练插件模型，克服了传统方法在冷启动问题和训练数据长度上的限制，并能够在工业推荐系统中实现端到端训练。

    

    arXiv:2403.10049v1 公告类型: 跨学科 摘要: 点击率（CTR）预测是推荐系统中的核心任务。现有方法（简称为IDRec）依赖于唯一身份来表示几十年来盛行的不同用户和物品。一方面，IDRec在冷启动问题上经常面临显著的性能下降；另一方面，由于迭代效率的约束，IDRec无法使用更长的训练数据。大多数先前的研究通过引入预训练知识（例如，预训练用户模型或多模态嵌入）来缓解上述问题。然而，在线延迟的爆炸性增长可以归因于预训练模型中的巨大参数。因此，大多数无法在工业推荐系统中使用与IDRec端到端训练的统一模型，从而限制了预训练模型的潜力。为此，我们提出了一种$\textbf{P}$re-trained $\textbf{P}$lug-in CTR $\textbf{M}$odel，即PPM。PPM em

    arXiv:2403.10049v1 Announce Type: cross  Abstract: Click-through rate (CTR) prediction is a core task in recommender systems. Existing methods (IDRec for short) rely on unique identities to represent distinct users and items that have prevailed for decades. On one hand, IDRec often faces significant performance degradation on cold-start problem; on the other hand, IDRec cannot use longer training data due to constraints imposed by iteration efficiency. Most prior studies alleviate the above problems by introducing pre-trained knowledge(e.g. pre-trained user model or multi-modal embeddings). However, the explosive growth of online latency can be attributed to the huge parameters in the pre-trained model. Therefore, most of them cannot employ the unified model of end-to-end training with IDRec in industrial recommender systems, thus limiting the potential of the pre-trained model. To this end, we propose a $\textbf{P}$re-trained $\textbf{P}$lug-in CTR $\textbf{M}$odel, namely PPM. PPM em
    
[^61]: 在交互式机器人中嵌入动态角色: 伪装动画社交运动学（MASK）

    Towards Embedding Dynamic Personas in Interactive Robots: Masquerading Animated Social Kinematics (MASK)

    [https://arxiv.org/abs/2403.10041](https://arxiv.org/abs/2403.10041)

    该研究提出了一种名为MASK的机器人系统，通过非言语互动与观众进行互动，并利用有限状态机结构调整机器人行为，实现多种不同角色的动态表达。

    

    本文介绍了一种创新的交互式机器人系统的设计和开发，以增强观众参与度，使用类似角色的人物形象。基于以角色为驱动的对话代理系统，本研究将该代理应用扩展到了物理领域，利用机器人提供更具沉浸感和互动体验。提出的系统名为Masquerading Animated Social Kinematics (MASK)，利用类人机器人通过非言语互动与客人互动，包括面部表情和手势。一种基于有限状态机结构的行为生成系统有效地调整机器人行为以传达不同的人物角色。MASK框架集成了感知引擎、行为选择引擎和综合动作库，使其能够在行为设计中需要最少人工干预地实现实时、动态互动。在用户对象研究过程中，探讨了系统的效果，并展示了其潜力以激发未来研究的兴趣。

    arXiv:2403.10041v1 Announce Type: cross  Abstract: This paper presents the design and development of an innovative interactive robotic system to enhance audience engagement using character-like personas. Built upon the foundations of persona-driven dialog agents, this work extends the agent application to the physical realm, employing robots to provide a more immersive and interactive experience. The proposed system, named the Masquerading Animated Social Kinematics (MASK), leverages an anthropomorphic robot which interacts with guests using non-verbal interactions, including facial expressions and gestures. A behavior generation system based upon a finite-state machine structure effectively conditions robotic behavior to convey distinct personas. The MASK framework integrates a perception engine, a behavior selection engine, and a comprehensive action library to enable real-time, dynamic interactions with minimal human intervention in behavior design. Throughout the user subject studi
    
[^62]: 重新思考无监督手术器械分割中低质量光流问题

    Rethinking Low-quality Optical Flow in Unsupervised Surgical Instrument Segmentation

    [https://arxiv.org/abs/2403.10039](https://arxiv.org/abs/2403.10039)

    本研究在无监督手术器械分割中解决了由于低质量光流而引起的挑战，提出了一种三重策略：直接从光流中提取边界、选择性丢弃质量较差的帧、以及利用可变帧率进行微调。在数据集上进行了充分评估，展示出有前景的结果。

    

    视频的手术器械分割在机器人辅助手术中扮演着重要角色。与监督设置不同，无监督分割主要依赖于运动线索，然而由于手术镜头中光流通常比自然场景中的要低质量，这些运动线索很难识别。本研究致力于解决即使面对低质量光流固有限制，提高模型性能的挑战。我们的方法从三个方面入手：直接从光流中提取边界、有选择地丢弃质量较差的帧、以及利用可变帧率的微调过程。我们在EndoVis2017 VOS数据集和Endovis2017挑战数据集上对我们的策略进行了彻底评估，模型展现出有前景的结果，实现了均值交叉。

    arXiv:2403.10039v1 Announce Type: cross  Abstract: Video-based surgical instrument segmentation plays an important role in robot-assisted surgeries. Unlike supervised settings, unsupervised segmentation relies heavily on motion cues, which are challenging to discern due to the typically lower quality of optical flow in surgical footage compared to natural scenes. This presents a considerable burden for the advancement of unsupervised segmentation techniques. In our work, we address the challenge of enhancing model performance despite the inherent limitations of low-quality optical flow. Our methodology employs a three-pronged approach: extracting boundaries directly from the optical flow, selectively discarding frames with inferior flow quality, and employing a fine-tuning process with variable frame rates. We thoroughly evaluate our strategy on the EndoVis2017 VOS dataset and Endovis2017 Challenge dataset, where our model demonstrates promising results, achieving a mean Intersection-o
    
[^63]: MR-MT3:存储保留的多轨音乐转录以减少乐器泄漏

    MR-MT3: Memory Retaining Multi-Track Music Transcription to Mitigate Instrument Leakage

    [https://arxiv.org/abs/2403.10024](https://arxiv.org/abs/2403.10024)

    提出了MR-MT3模型来减少乐器泄漏问题，采用了存储保留机制、先前令牌采样和令牌混洗等增强方法，在Slakh2100数据集上展示了改进的效果。

    

    这篇论文介绍了MT3模型的改进，MT3是一种最先进的基于令牌的多乐器自动音乐转录模型。尽管MT3性能最先进，但存在乐器泄漏问题，即转录在不同乐器之间片段化。为了减少这种问题，我们提出了MR-MT3，其中包括存储保留机制、先前令牌采样和令牌混洗等增强方法。这些方法在Slakh2100数据集上进行了评估，展示了改进的起始F1分数和减少的乐器泄漏。除了传统的多乐器转录F1分数，还引入了诸如乐器泄漏比率和乐器检测F1分数等新指标，以更全面地评估转录质量。该研究还探讨了通过在单乐器单声道数据集（如ComMU和NSynth）上评估MT3来评估域过度拟合的问题。

    arXiv:2403.10024v1 Announce Type: cross  Abstract: This paper presents enhancements to the MT3 model, a state-of-the-art (SOTA) token-based multi-instrument automatic music transcription (AMT) model. Despite SOTA performance, MT3 has the issue of instrument leakage, where transcriptions are fragmented across different instruments. To mitigate this, we propose MR-MT3, with enhancements including a memory retention mechanism, prior token sampling, and token shuffling are proposed. These methods are evaluated on the Slakh2100 dataset, demonstrating improved onset F1 scores and reduced instrument leakage. In addition to the conventional multi-instrument transcription F1 score, new metrics such as the instrument leakage ratio and the instrument detection F1 score are introduced for a more comprehensive assessment of transcription quality. The study also explores the issue of domain overfitting by evaluating MT3 on single-instrument monophonic datasets such as ComMU and NSynth. The findings,
    
[^64]: NNCTC: 通过神经网络实现的物理层跨技术通信

    NNCTC: Physical Layer Cross-Technology Communication via Neural Networks

    [https://arxiv.org/abs/2403.10014](https://arxiv.org/abs/2403.10014)

    NNCTC 是一个基于神经网络的跨技术通信框架，通过将信号处理组件转换为神经模型，实现了无需标记数据进行端到端训练，使系统能够自主推导出最佳的通信有效载荷，显著降低了开发复杂性并展示了可扩展潜力

    

    跨技术通信(CTC)实现了不同无线技术之间的无缝交互。大多数现有工作基于逆转传输路径，以识别适当的有效载荷来生成目标设备能识别的波形。然而，这种方法存在许多局限性，包括依赖特定技术和需要复杂算法来减轻失真。在这项工作中，我们提出了NNCTC，一个受训练的神经模型在无线通信中的适应性启发下设计的基于神经网络的跨技术通信框架。通过将CTC管道内的信号处理组件转换为神经模型，NNCTC被设计为端到端训练而无需标记数据。这使得NNCTC系统能够自主推导出最佳的CTC有效载荷，显著减轻了开发复杂性，并展示了可扩展潜力。

    arXiv:2403.10014v1 Announce Type: cross  Abstract: Cross-technology communication(CTC) enables seamless interactions between diverse wireless technologies. Most existing work is based on reversing the transmission path to identify the appropriate payload to generate the waveform that the target devices can recognize. However, this method suffers from many limitations, including dependency on specific technologies and the necessity for intricate algorithms to mitigate distortion. In this work, we present NNCTC, a Neural-Network-based Cross-Technology Communication framework inspired by the adaptability of trainable neural models in wireless communications. By converting signal processing components within the CTC pipeline into neural models, the NNCTC is designed for end-to-end training without requiring labeled data. This enables the NNCTC system to autonomously derive the optimal CTC payload, which significantly eases the development complexity and showcases the scalability potential 
    
[^65]: FBPT：一个完全二进制点云Transformer

    FBPT: A Fully Binary Point Transformer

    [https://arxiv.org/abs/2403.09998](https://arxiv.org/abs/2403.09998)

    该论文提出了一个全新的完全二进制点云Transformer模型，通过压缩网络的权重和激活为1位二进制值，显著降低了点云处理任务神经网络模型的存储和计算资源需求。

    

    本文提出了一种新颖的Fully Binary Point Cloud Transformer（FBPT）模型，该模型在机器人和移动设备领域具有广泛的应用和扩展潜力。通过将32位全精度网络的权重和激活压缩为1位二进制值，所提出的二进制点云Transformer网络显著降低了用于点云处理任务的神经网络模型的存储占用和计算资源需求，相较于全精度点云网络。然而，实现完全的二进制点云Transformer网络，其中除了与任务特定的模块外其他所有部分都是二进制的，会在量化注意力模块中的Q、K、V和自注意力激活时面临挑战和瓶颈，因为它们不符合简单的概率分布，并且可能随输入数据变化而变化。此外，在我们的网络中，二进制注意力模块经历了衰减

    arXiv:2403.09998v1 Announce Type: cross  Abstract: This paper presents a novel Fully Binary Point Cloud Transformer (FBPT) model which has the potential to be widely applied and expanded in the fields of robotics and mobile devices. By compressing the weights and activations of a 32-bit full-precision network to 1-bit binary values, the proposed binary point cloud Transformer network significantly reduces the storage footprint and computational resource requirements of neural network models for point cloud processing tasks, compared to full-precision point cloud networks. However, achieving a fully binary point cloud Transformer network, where all parts except the modules specific to the task are binary, poses challenges and bottlenecks in quantizing the activations of Q, K, V and self-attention in the attention module, as they do not adhere to simple probability distributions and can vary with input data. Furthermore, in our network, the binary attention module undergoes a degradation
    
[^66]: EfficientVMamba: 一种专为轻量级视觉Mamba设计的Atrous选择扫描方法

    EfficientVMamba: Atrous Selective Scan for Light Weight Visual Mamba

    [https://arxiv.org/abs/2403.09977](https://arxiv.org/abs/2403.09977)

    EfficientVMamba是一种新颖的高效模型变体，通过atrous-based selective scan方法实现了轻量级模型设计，克服了准确性和效率之间的权衡挑战。

    

    先前轻量级模型开发的努力主要集中在基于CNN和Transformer的设计上，但仍面临持续挑战。CNN在局部特征提取方面擅长，但会损害分辨率，而Transformers提供全局范围，但会增加计算需求$\mathcal{O}(N^2)$。准确性和效率之间的这种持续权衡仍然是一个重大障碍。最近，状态空间模型（SSMs），如Mamba，在语言建模和计算机视觉等各种任务中表现出色并具有竞争力，同时将全局信息提取的时间复杂度降低到$\mathcal{O}(N)$。在此启发下，本文提出探索视觉状态空间模型在轻量级模型设计中的潜力，并引入了一种名为EfficientVMamba的全新高效模型变体。具体而言，我们的EfficientVMamba通过高效的跳跃采样集成了基于atrous的选择扫描方法。

    arXiv:2403.09977v1 Announce Type: cross  Abstract: Prior efforts in light-weight model development mainly centered on CNN and Transformer-based designs yet faced persistent challenges. CNNs adept at local feature extraction compromise resolution while Transformers offer global reach but escalate computational demands $\mathcal{O}(N^2)$. This ongoing trade-off between accuracy and efficiency remains a significant hurdle. Recently, state space models (SSMs), such as Mamba, have shown outstanding performance and competitiveness in various tasks such as language modeling and computer vision, while reducing the time complexity of global information extraction to $\mathcal{O}(N)$. Inspired by this, this work proposes to explore the potential of visual state space models in light-weight model design and introduce a novel efficient model variant dubbed EfficientVMamba. Concretely, our EfficientVMamba integrates a atrous-based selective scan approach by efficient skip sampling, constituting bui
    
[^67]: GET：解锁CLIP的多模态潜力，用于广义类别发现

    GET: Unlocking the Multi-modal Potential of CLIP for Generalized Category Discovery

    [https://arxiv.org/abs/2403.09974](https://arxiv.org/abs/2403.09974)

    本文提出了一种文本嵌入合成器（TES），用于为无标签数据生成伪文本嵌入，以解锁CLIP用于广义类别发现任务中的多模态潜力。

    

    给定包含旧类别和新类别的无标签数据集，广义类别发现（GCD）旨在准确发现新类别，并正确分类旧类别，利用从有标签样本中学习的类别概念。当前的GCD方法只使用单一的视觉信息模态，导致在视觉上相似类别的分类效果不佳。虽然某些类别在视觉上容易混淆，但它们的文本信息可能是不同的，这促使我们将文本信息引入到GCD任务中。然而，无标签数据缺乏类别名称，使得利用文本信息变得不切实际。为了解决这一具有挑战性的问题，在本文中，我们提出了一种文本嵌入合成器（TES），用于为无标签样本生成伪文本嵌入。具体而言，我们的TES利用CLIP可以生成对齐的视觉-语言特征这一特性，将视觉嵌入转换为CLIP文本模型的标记。

    arXiv:2403.09974v1 Announce Type: cross  Abstract: Given unlabelled datasets containing both old and new categories, generalized category discovery (GCD) aims to accurately discover new classes while correctly classifying old classes, leveraging the class concepts learned from labeled samples. Current GCD methods only use a single visual modality of information, resulting in poor classification of visually similar classes. Though certain classes are visually confused, their text information might be distinct, motivating us to introduce text information into the GCD task. However, the lack of class names for unlabelled data makes it impractical to utilize text information. To tackle this challenging problem, in this paper, we propose a Text Embedding Synthesizer (TES) to generate pseudo text embeddings for unlabelled samples. Specifically, our TES leverages the property that CLIP can generate aligned vision-language features, converting visual embeddings into tokens of the CLIP's text e
    
[^68]: 处理好您的提示偏见！调查和减轻事实知识提取中的提示偏见

    Take Care of Your Prompt Bias! Investigating and Mitigating Prompt Bias in Factual Knowledge Extraction

    [https://arxiv.org/abs/2403.09963](https://arxiv.org/abs/2403.09963)

    本文调查了预训练语言模型在事实知识提取中存在的“提示偏见”，找到了不同类型提示的偏见程度，以及这种偏见对不同基准测试的影响，并提出了一种基于表示的方法来减轻这种提示偏见。

    

    最近的研究表明，预训练语言模型（PLMs）在事实知识提取中存在“提示偏见”，即提示往往会引入对特定标签的偏见。然而，模型内部提示偏见的程度和影响尚未得到充分探讨。为了回应这一点，本文量化了不同类型提示的偏见，并评估了它们对不同基准测试的影响。我们发现：1）实验中的所有提示都表现出不可忽视的偏见，基于梯度的提示如AutoPrompt和OptiPrompt显示出更高水平的偏见；2）提示偏见可以通过过度拟合测试数据集不合理地放大基准测试的准确性，特别是在类似LAMA这样的不平衡数据集上。基于这些发现，我们提出了一种基于表示的方法来减轻提示偏见，在推断时。具体而言，我们首先使用仅提示查询来估计有偏差的表示，然后从中删除。

    arXiv:2403.09963v1 Announce Type: cross  Abstract: Recent research shows that pre-trained language models (PLMs) suffer from "prompt bias" in factual knowledge extraction, i.e., prompts tend to introduce biases toward specific labels. However, the extent and impact of prompt bias within the model remain underexplored. In response, this paper quantifies the bias with various types of prompts and assesses their impact on different benchmarks. We show that: 1) all prompts in the experiments exhibit non-negligible bias, with gradient-based prompts like AutoPrompt and OptiPrompt displaying significantly higher levels of bias; 2) prompt bias can amplify benchmark accuracy unreasonably by overfitting the test datasets, especially on imbalanced datasets like LAMA. Based on these findings, we propose a representation-based approach to mitigate the prompt bias during inference time. Specifically, we first estimate the biased representation using prompt-only querying, and then remove it from the 
    
[^69]: RadCLIP: 通过对比语言图像预训练增强放射学图像分析

    RadCLIP: Enhancing Radiologic Image Analysis through Contrastive Language-Image Pre-training

    [https://arxiv.org/abs/2403.09948](https://arxiv.org/abs/2403.09948)

    RadCLIP是一种创新的跨模态基础模型，利用对比语言图像预训练以改进放射学图像分析，包含针对体积图像分析定制的新颖3D切片池化机制，并使用丰富多样的放射学图像-文本对数据集进行训练。

    

    arXiv:2403.09948v1 公告类型: 跨领域  摘要: 人工智能（AI）与放射学的整合标志着医学诊断领域的变革时代。视觉基础模型已被采用来增强放射学图像分析。然而，放射学图像的独特复杂性，包括对2D和3D放射学数据的解读，带来了现有模型无法充分应对的挑战，因为这些模型是在通用非医学图像上训练的。为了弥合这一差距，并充分利用医学成像所需的诊断精度，我们引入了RadCLIP：一种开创性的跨模态基础模型，利用对比语言图像预训练（CLIP）来改进放射学图像分析。RadCLIP包含一种新颖的3D切片池化机制，专为体积图像分析定制，使用了丰富多样的放射学图像-文本对数据集进行训练。我们的评估表明，RadCLIP能有效地对齐放射学图像

    arXiv:2403.09948v1 Announce Type: cross  Abstract: The integration of artificial intelligence (AI) with radiology has marked a transformative era in medical diagnostics. Vision foundation models have been adopted to enhance radiologic imaging analysis. However, the distinct complexities of radiological imaging, including the interpretation of 2D and 3D radiological data, pose unique challenges that existing models, trained on general non-medical images, fail to address adequately. To bridge this gap and capitalize on the diagnostic precision required in medical imaging, we introduce RadCLIP: a pioneering cross-modal foundational model that harnesses Contrastive Language-Image Pre-training (CLIP) to refine radiologic image analysis. RadCLIP incorporates a novel 3D slice pooling mechanism tailored for volumetric image analysis and is trained using a comprehensive and diverse dataset of radiologic image-text pairs. Our evaluations demonstrate that RadCLIP effectively aligns radiological i
    
[^70]: 具有对手的联邦策略梯度方法的全局收敛保证

    Global Convergence Guarantees for Federated Policy Gradient Methods with Adversaries

    [https://arxiv.org/abs/2403.09940](https://arxiv.org/abs/2403.09940)

    该方法提出了一种基于策略梯度的联邦学习方法，可以在存在对手代理的情况下实现全局收敛保证，并具有对对手的鲁棒性。

    

    Federated Reinforcement Learning (FRL)允许多个代理共同构建决策制定策略，而无需共享原始轨迹。然而，如果这些代理中只有少部分是对手，可能会导致灾难性结果。我们提出了一种基于策略梯度的方法，该方法对对手代理具有鲁棒性，可以向服务器发送任意值。在这种设置下，我们的结果形成了具有一般参数化的首个全局收敛保证。这些结果展示了对手的弹性，同时达到了样本复杂度的$\tilde{\mathcal{O}}\left( \frac{1}{\epsilon^2} \left( \frac{1}{N-f} + \frac{f^2}{(N-f)^2}\right)\right)$，其中$N$是代理的总数，$f$是对手代理的数量。

    arXiv:2403.09940v1 Announce Type: cross  Abstract: Federated Reinforcement Learning (FRL) allows multiple agents to collaboratively build a decision making policy without sharing raw trajectories. However, if a small fraction of these agents are adversarial, it can lead to catastrophic results. We propose a policy gradient based approach that is robust to adversarial agents which can send arbitrary values to the server. Under this setting, our results form the first global convergence guarantees with general parametrization. These results demonstrate resilience with adversaries, while achieving sample complexity of order $\tilde{\mathcal{O}}\left( \frac{1}{\epsilon^2} \left( \frac{1}{N-f} + \frac{f^2}{(N-f)^2}\right)\right)$, where $N$ is the total number of agents and $f$ is the number of adversarial agents.
    
[^71]: 质量多样性演员-评论家：通过值和继承特征评论家学习高性能和多样性行为

    Quality-Diversity Actor-Critic: Learning High-Performing and Diverse Behaviors via Value and Successor Features Critics

    [https://arxiv.org/abs/2403.09930](https://arxiv.org/abs/2403.09930)

    QDAC是一种基于离策略演员-评论家深度强化学习算法，通过价值函数评论家和继承特征评论家学习高性能和多样性行为。

    

    智能的一个关键方面是表现出适应意外情况的广泛行为谱。过去十年，深度强化学习的进步取得了突破性成就，用于解决复杂的连续控制任务。然而，大多数方法只返回一个专门针对特定问题的解决方案。我们引入了质量多样性演员-评论家（QDAC），这是一种基于离策略演员-评论家深度强化学习算法，利用价值函数评论家和继承特征评论家学习高性能和多样性行为。在这个框架中，演员通过受限优化来最大化回报并执行多样性技能的客观函数，无缝统一了两个评论家。与其他质量多样性方法相比，QDAC在六个具有挑战性的连续控制运动任务上实现了显着更高的性能和更多样性的行为。

    arXiv:2403.09930v1 Announce Type: cross  Abstract: A key aspect of intelligence is the ability to demonstrate a broad spectrum of behaviors for adapting to unexpected situations. Over the past decade, advancements in deep reinforcement learning have led to groundbreaking achievements to solve complex continuous control tasks. However, most approaches return only one solution specialized for a specific problem. We introduce Quality-Diversity Actor-Critic (QDAC), an off-policy actor-critic deep reinforcement learning algorithm that leverages a value function critic and a successor features critic to learn high-performing and diverse behaviors. In this framework, the actor optimizes an objective that seamlessly unifies both critics using constrained optimization to (1) maximize return, while (2) executing diverse skills. Compared with other Quality-Diversity methods, QDAC achieves significantly higher performance and more diverse behaviors on six challenging continuous control locomotion 
    
[^72]: 辅助蒙特卡洛树搜索在组合优化中的应用

    Surrogate Assisted Monte Carlo Tree Search in Combinatorial Optimization

    [https://arxiv.org/abs/2403.09925](https://arxiv.org/abs/2403.09925)

    利用辅助代理模型的蒙特卡洛树搜索在组合优化中可以更快生成解决方案，并且与不使用代理模型的方法相比能够保持一致的解决方案

    

    行业经常通过在有前景的地区开设新分支机构并关闭他们预期低利润的地区的分支机构来调整他们的设施网络。在本文中，我们研究了一类特定的设施选址问题。我们的目标是最小化由于关闭几家零售店而导致的销售损失。然而，准确估计销售额是昂贵且耗时的。为了克服这一挑战，我们利用蒙特卡洛树搜索（MCTS）辅助一个能更快计算评估的代理模型。结果表明，由快速代理函数支持的MCTS可以更快地生成解决方案，同时与不利用代理函数的MCTS相比，能保持一致的解决方案。

    arXiv:2403.09925v1 Announce Type: new  Abstract: Industries frequently adjust their facilities network by opening new branches in promising areas and closing branches in areas where they expect low profits. In this paper, we examine a particular class of facility location problems. Our objective is to minimize the loss of sales resulting from the removal of several retail stores. However, estimating sales accurately is expensive and time-consuming. To overcome this challenge, we leverage Monte Carlo Tree Search (MCTS) assisted by a surrogate model that computes evaluations faster. Results suggest that MCTS supported by a fast surrogate function can generate solutions faster while maintaining a consistent solution compared to MCTS that does not benefit from the surrogate function.
    
[^73]: 预测AI结肠镜模型对未知数据的泛化能力

    Predicting Generalization of AI Colonoscopy Models to Unseen Data

    [https://arxiv.org/abs/2403.09920](https://arxiv.org/abs/2403.09920)

    使用“Masked Siamese Network”（MSN）在未标记数据上识别新现象，并预测结肠镜模型对未知技术和不同国家数据的性能。

    

    背景和目标 AI结肠镜算法的泛化能力对于在临床实践中更广泛的应用至关重要。然而，目前评估在未知数据上的性能的技术需要昂贵且耗时的标签。我们使用“Masked Siamese Network”（MSN）在未知数据中识别新现象并预测息肉检测器的性能。MSN被训练来预测息肉图像中被屏蔽的区域，而无需任何标签。我们测试了MSN仅在以色列数据上进行训练的能力，以及在日本结肠镜（354个视频，128小时）上检测未知技术：窄带成像（NBI）和色细胞内镜（CE）。我们还测试了MSN预测跨国结肠镜视频上的息肉计算机辅助检测（CADe）的性能，尽管MSN未接受过来自日本的数据的训练。

    arXiv:2403.09920v1 Announce Type: cross  Abstract: Background and aims Generalizability of AI colonoscopy algorithms is important for wider adoption in clinical practice. However, current techniques for evaluating performance on unseen data require expensive and time-intensive labels.   Methods We use a "Masked Siamese Network" (MSN) to identify novel phenomena in unseen data and predict polyp detector performance. MSN is trained to predict masked out regions of polyp images, without any labels. We test MSN's ability to be trained on data only from Israel and detect unseen techniques, narrow-band imaging (NBI) and chromendoscoy (CE), on colonoscopes from Japan (354 videos, 128 hours). We also test MSN's ability to predict performance of Computer Aided Detection (CADe) of polyps on colonoscopies from both countries, even though MSN is not trained on data from Japan.   Results MSN correctly identifies NBI and CE as less similar to Israel whitelight than Japan whitelight (bootstrapped z-t
    
[^74]: FedComLoc: 稀疏和量化模型的通信高效分布式训练

    FedComLoc: Communication-Efficient Distributed Training of Sparse and Quantized Models

    [https://arxiv.org/abs/2403.09904](https://arxiv.org/abs/2403.09904)

    FedComLoc利用Scaffnew算法的基础，引入了压缩和本地训练，显著降低了分布式训练中的通信开销。

    

    联邦学习（FL）由于其允许异构客户端在本地处理其私有数据并与中央服务器互动，同时尊重隐私的独特特点而受到越来越多的关注。我们的工作受到了创新的Scaffnew算法的启发，该算法在FL中大大推动了通信复杂性的降低。我们引入了FedComLoc（联邦压缩和本地训练），将实用且有效的压缩集成到Scaffnew中，以进一步增强通信效率。广泛的实验证明，使用流行的TopK压缩器和量化，它在大幅减少异构中的通信开销方面具有卓越的性能。

    arXiv:2403.09904v1 Announce Type: cross  Abstract: Federated Learning (FL) has garnered increasing attention due to its unique characteristic of allowing heterogeneous clients to process their private data locally and interact with a central server, while being respectful of privacy. A critical bottleneck in FL is the communication cost. A pivotal strategy to mitigate this burden is \emph{Local Training}, which involves running multiple local stochastic gradient descent iterations between communication phases. Our work is inspired by the innovative \emph{Scaffnew} algorithm, which has considerably advanced the reduction of communication complexity in FL. We introduce FedComLoc (Federated Compressed and Local Training), integrating practical and effective compression into \emph{Scaffnew} to further enhance communication efficiency. Extensive experiments, using the popular TopK compressor and quantization, demonstrate its prowess in substantially reducing communication overheads in heter
    
[^75]: Fisher Mask节点用于语言模型合并

    Fisher Mask Nodes for Language Model Merging

    [https://arxiv.org/abs/2403.09891](https://arxiv.org/abs/2403.09891)

    介绍了一种用于Transformers的新型模型合并方法，利用Fisher信息进行加权平均，提高了多任务模型的性能。

    

    微调预训练模型在下游性能方面具有显著优势。预训练模型（如BERT及其衍生物）在自然语言处理中的普遍性也导致了任务特定微调模型的激增。在多任务场景中，由于这些模型通常只能很好地执行一项任务，因此需要额外的训练或集成。模型合并这一不断增长的领域提供了一个解决方案，解决了将多个任务特定模型合并为单个多任务模型的挑战。在本研究中，我们引入了一种新颖的用于Transformers的模型合并方法，结合了先前Fisher加权平均和Fisher信息在模型修剪中的应用的见解。通过利用Transformer架构内的mask节点的Fisher信息，我们设计了一个计算效率高的加权平均方案。我们的方法展现出了稳定且显著的性能。

    arXiv:2403.09891v1 Announce Type: cross  Abstract: Fine-tuning pre-trained models provides significant advantages in downstream performance. The ubiquitous nature of pre-trained models such as BERT and its derivatives in natural language processing has also led to a proliferation of task-specific fine-tuned models. As these models typically only perform one task well, additional training or ensembling is required in multi-task scenarios. The growing field of model merging provides a solution, dealing with the challenge of combining multiple task-specific models into a single multi-task model. In this study, we introduce a novel model merging method for Transformers, combining insights from previous work in Fisher-weighted averaging and the use of Fisher information in model pruning. Utilizing the Fisher information of mask nodes within the Transformer architecture, we devise a computationally efficient weighted-averaging scheme. Our method exhibits a regular and significant performance
    
[^76]: Sabi\'a-2:一代新的葡萄牙大型语言模型

    Sabi\'a-2: A New Generation of Portuguese Large Language Models

    [https://arxiv.org/abs/2403.09887](https://arxiv.org/abs/2403.09887)

    Sabi'a-2是一代新的葡萄牙大型语言模型，其中的Sabi'a-2 Medium模型在多个考试中的表现超越了GPT-4，且在大多数考试中超过了GPT-3.5，同时专业化对模型的性能有显著影响，可在无需增大模型尺寸的情况下以比GPT-4便宜10倍的价格提供。

    

    我们介绍了Sabi'a-2，这是一族在葡萄牙文本上训练的大型语言模型。这些模型在多个考试中进行了评估，包括巴西大学的入学考试、专业认证考试以及各种学科（如会计、经济学、工程学、法律和医学）的研究生入学考试。我们的结果显示，到目前为止我们最优秀的模型Sabi'a-2 Medium，在64场考试中有23场与GPT-4的表现相匹敌或超越，并且在64场考试中有58场超过了GPT-3.5。值得注意的是，专业化对模型的性能有显著影响，无需增大模型尺寸，我们可以提供Sabi'a-2 Medium，每个记号的价格比GPT-4便宜10倍。最后，我们发现数学和编码是需要改进的关键能力。

    arXiv:2403.09887v1 Announce Type: cross  Abstract: We introduce Sabi\'a-2, a family of large language models trained on Portuguese texts. The models are evaluated on a diverse range of exams, including entry-level tests for Brazilian universities, professional certification exams, and graduate-level exams for various disciplines such as accounting, economics, engineering, law and medicine. Our results reveal that our best model so far, Sabi\'a-2 Medium, matches or surpasses GPT-4's performance in 23 out of 64 exams and outperforms GPT-3.5 in 58 out of 64 exams. Notably, specialization has a significant impact on a model's performance without the need to increase its size, allowing us to offer Sabi\'a-2 Medium at a price per token that is 10 times cheaper than GPT-4. Finally, we identified that math and coding are key abilities that need improvement.
    
[^77]: ThermoHands：一种用于从主观视角热图中估计3D手部姿势的基准

    ThermoHands: A Benchmark for 3D Hand Pose Estimation from Egocentric Thermal Image

    [https://arxiv.org/abs/2403.09871](https://arxiv.org/abs/2403.09871)

    ThermoHands提出了一个新的基准ThermoHands，旨在解决热图中主观视角3D手部姿势估计的挑战，介绍了一个具有双transformer模块的定制基线方法TheFormer，表明热成像在恶劣条件下实现稳健的3D手部姿势估计的有效性。

    

    在这项工作中，我们提出了ThermoHands，这是一个针对基于热图的主观视角3D手部姿势估计的新基准，旨在克服诸如光照变化和遮挡（例如手部穿戴物）等挑战。该基准包括来自28名主体进行手-物体和手-虚拟交互的多样数据集，经过自动化过程准确标注了3D手部姿势。我们引入了一个定制的基线方法TheFormer，利用双transformer模块在热图中实现有效的主观视角3D手部姿势估计。我们的实验结果突显了TheFormer的领先性能，并确认了热成像在实现恶劣条件下稳健的3D手部姿势估计方面的有效性。

    arXiv:2403.09871v1 Announce Type: cross  Abstract: In this work, we present ThermoHands, a new benchmark for thermal image-based egocentric 3D hand pose estimation, aimed at overcoming challenges like varying lighting and obstructions (e.g., handwear). The benchmark includes a diverse dataset from 28 subjects performing hand-object and hand-virtual interactions, accurately annotated with 3D hand poses through an automated process. We introduce a bespoken baseline method, TheFormer, utilizing dual transformer modules for effective egocentric 3D hand pose estimation in thermal imagery. Our experimental results highlight TheFormer's leading performance and affirm thermal imaging's effectiveness in enabling robust 3D hand pose estimation in adverse conditions.
    
[^78]: 对亚群体偏移的鲁棒性改进：使用组感知先验

    Mind the GAP: Improving Robustness to Subpopulation Shifts with Group-Aware Priors

    [https://arxiv.org/abs/2403.09869](https://arxiv.org/abs/2403.09869)

    开发了一族组感知先验分布，可以改进神经网络模型在数据分布的亚群体偏移下的泛化能力，并展示了即使只重新训练非鲁棒模型的最后一层，使用这种先验进行训练也能获得最先进的性能。

    

    机器学习模型在数据分布的亚群体偏移下往往表现不佳。开发能够让机器学习模型更好地泛化到这种偏移的方法对于在现实世界中安全部署至关重要。在这篇论文中，我们提出了一族针对神经网络参数的组感知先验（GAP）分布，明确支持在数据分布的亚群体偏移下泛化良好的模型。我们设计了一个简单的组感知先验，只需要访问一小部分包含组信息的数据，证明了在此先验下训练会获得最先进的性能——即使只重新训练先前训练的非鲁棒模型的最后一层。组感知先验在概念上简单，与现有方法（如属性伪标记和数据重新加权）互补，为利用贝叶斯推断以实现对亚群体偏移的鲁棒性开辟了有前景的新途径。

    arXiv:2403.09869v1 Announce Type: cross  Abstract: Machine learning models often perform poorly under subpopulation shifts in the data distribution. Developing methods that allow machine learning models to better generalize to such shifts is crucial for safe deployment in real-world settings. In this paper, we develop a family of group-aware prior (GAP) distributions over neural network parameters that explicitly favor models that generalize well under subpopulation shifts. We design a simple group-aware prior that only requires access to a small set of data with group information and demonstrate that training with this prior yields state-of-the-art performance -- even when only retraining the final layer of a previously trained non-robust model. Group aware-priors are conceptually simple, complementary to existing approaches, such as attribute pseudo labeling and data reweighting, and open up promising new avenues for harnessing Bayesian inference to enable robustness to subpopulation
    
[^79]: 一个白盒神经网络的概念框架

    A Conceptual Framework For White Box Neural Networks

    [https://arxiv.org/abs/2403.09863](https://arxiv.org/abs/2403.09863)

    引入语义特征作为通用概念框架，实现了完全可解释的神经网络层，为白盒神经网络的范式转变开辟了新的可能性。

    

    本文引入语义特征作为完全可解释神经网络层的通用概念框架。一个充分动机的MNIST相关子问题的概念验证模型包括4个这样的层，总共4800个可学习参数。该模型易于解释，无需任何形式的对抗训练即可实现人类水平的对抗测试准确率，需要较少的超参数调节，并且可以在单个CPU上快速训练。该技术的通用性承诺为彻底民主化和真正通用的白盒神经网络带来了希望。代码可在https://github.com/314-Foundation/white-box-nn找到。

    arXiv:2403.09863v1 Announce Type: cross  Abstract: This paper introduces semantic features as a general conceptual framework for fully explainable neural network layers. A well-motivated proof of concept model for relevant subproblem of MNIST consists of 4 such layers with the total of 4.8K learnable parameters. The model is easily interpretable, achieves human-level adversarial test accuracy with no form of adversarial training, requires little hyperparameter tuning and can be quickly trained on a single CPU. The general nature of the technique bears promise for a paradigm shift towards radically democratised and truly generalizable white box neural networks. The code is available at https://github.com/314-Foundation/white-box-nn
    
[^80]: 基于神经网络的调制器：IoT网关上可重构和可移植的软件调制器

    NN-Defined Modulator: Reconfigurable and Portable Software Modulator on IoT Gateways

    [https://arxiv.org/abs/2403.09861](https://arxiv.org/abs/2403.09861)

    使用神经网络作为IoT网关设备中物理层调制器的抽象层，解决了可扩展性和可移植性方面的挑战，并具有硬件加速和异构平台移植的支持。

    

    用户物联网（IoT）网关的物理层调制器是将符号映射到信号的重要组件。然而，由于网关主板上焊接的硬件芯片组件或不同平台上软件无线电的多样化工具包，现有解决方案要么具有有限的可扩展性，要么特定于平台。在调制方案和硬件平台变得极为多样化的情况下，这种限制很难忽视。本文提出了一种新的范式，即在IoT网关设备中使用神经网络作为物理层调制器的抽象层，称为NN-defined modulators。我们的方法解决了在各种硬件平台上实现多种技术的可扩展性和可移植性方面的挑战。所提出的NN-defined modulator使用根植于坚实数学基础的模型驱动方法论，同时具有对硬件加速的本地支持，可移植到异构平台。

    arXiv:2403.09861v1 Announce Type: cross  Abstract: A physical-layer modulator is a vital component for an IoT gateway to map the symbols to signals. However, due to the soldered hardware chipsets on the gateway's motherboards or the diverse toolkits on different platforms for the software radio, the existing solutions either have limited extensibility or are platform-specific. Such limitation is hard to ignore when modulation schemes and hardware platforms have become extremely diverse. This paper presents a new paradigm of using neural networks as an abstraction layer for physical layer modulators in IoT gateway devices, referred to as NN-defined modulators. Our approach addresses the challenges of extensibility and portability for multiple technologies on various hardware platforms. The proposed NN-defined modulator uses a model-driven methodology rooted in solid mathematical foundations while having native support for hardware acceleration and portability to heterogeneous platforms.
    
[^81]: 带有注意力感知自适应提示的少样本类增量学习

    Few-Shot Class Incremental Learning with Attention-Aware Self-Adaptive Prompt

    [https://arxiv.org/abs/2403.09857](https://arxiv.org/abs/2403.09857)

    提出了一个名为ASP的框架，通过注意力方面减少特定信息，鼓励任务不变的提示来捕获共享知识，并通过信息瓶颈学习目标从旧类到新类传递知识。

    

    少样本类增量学习（FSCIL）模型旨在在保留旧类知识的同时，逐步学习新类别的稀缺样本。现有的FSCIL方法通常对整个骨干进行微调，导致过拟合并阻碍学习新类别的潜力。另一方面，最近基于提示的CIL方法通过在每个任务中用足够的数据训练提示来减轻遗忘。在这项工作中，我们提出了一个名为注意力感知自适应提示（ASP）的新框架。ASP通过从注意力方面减少特定信息，鼓励任务不变的提示来捕获共享知识。此外，ASP中的自适应任务特定提示提供特定信息，并通过信息瓶颈学习目标从旧类到新类传递知识。总之，ASP防止了在基础任务上的过拟合，并不需要在少样本增量任务中使用大量数据。

    arXiv:2403.09857v1 Announce Type: cross  Abstract: Few-Shot Class-Incremental Learning (FSCIL) models aim to incrementally learn new classes with scarce samples while preserving knowledge of old ones. Existing FSCIL methods usually fine-tune the entire backbone, leading to overfitting and hindering the potential to learn new classes. On the other hand, recent prompt-based CIL approaches alleviate forgetting by training prompts with sufficient data in each task. In this work, we propose a novel framework named Attention-aware Self-adaptive Prompt (ASP). ASP encourages task-invariant prompts to capture shared knowledge by reducing specific information from the attention aspect. Additionally, self-adaptive task-specific prompts in ASP provide specific information and transfer knowledge from old classes to new classes with an Information Bottleneck learning objective. In summary, ASP prevents overfitting on base task and does not require enormous data in few-shot incremental tasks. Extensi
    
[^82]: 自洽性提升数学推理的校准

    Self-Consistency Boosts Calibration for Math Reasoning

    [https://arxiv.org/abs/2403.09849](https://arxiv.org/abs/2403.09849)

    基于自洽性的校准方法在数学推理任务中能够更好地建立模型信心和准确性之间的关联。

    

    校准，建立准确性和模型信心之间的关联，对LLM开发至关重要。我们基于自洽性设计了三种即插即用的校准方法（Wang等，2022年）用于数学推理任务。在两个流行基准（GSM8K和MathQA）上评估使用强大的开源LLMs（Mistral和LLaMA2），我们的方法比基于p(True)的现有方法（Kadavath等人，2022年）或logit（Kadavath等人，2022年）更好地连接模型信心和准确性。

    arXiv:2403.09849v1 Announce Type: cross  Abstract: Calibration, which establishes the correlation between accuracy and model confidence, is important for LLM development. We design three off-the-shelf calibration methods based on self-consistency (Wang et al., 2022) for math reasoning tasks. Evaluation on two popular benchmarks (GSM8K and MathQA) using strong open-source LLMs (Mistral and LLaMA2), our methods better bridge model confidence and accuracy than existing methods based on p(True) (Kadavath et al., 2022) or logit (Kadavath et al., 2022).
    
[^83]: 利用太阳风数据预测地磁活跃事件并通过机器学习方法评估最具预测性的特征

    Forecasting Geoffective Events from Solar Wind Data and Evaluating the Most Predictive Features through Machine Learning Approaches

    [https://arxiv.org/abs/2403.09847](https://arxiv.org/abs/2403.09847)

    本研究利用机器学习技术预测地磁扰动，通过长短期记忆循环神经网络分析太阳风数据，针对强类别不平衡问题设计适当损失函数，并采用价值加权技能评分评估预测效果。

    

    本研究利用机器学习技术解决地磁扰动的预测问题。具体来说，利用长短期记忆循环神经网络对逐点采集的太阳风等离子体和磁场的数据进行分析，时间跨度超过一个太阳周期，从2005年到2019年，在拉格朗日点L1处获取数据。该问题被看作是一个二元分类问题，旨在预测SYC-H地磁活动指数在一小时内下降到-50 nT以下的情况，这通常被认为是磁层扰动的指标。强类别不平衡问题通过使用适当的损失函数加以应对，该损失函数专门设计用于优化神经网络训练阶段的适当技能评分。除了传统的技能评分，还使用了价值加权技能评分来评估预测结果。

    arXiv:2403.09847v1 Announce Type: cross  Abstract: This study addresses the prediction of geomagnetic disturbances by exploiting machine learning techniques. Specifically, the Long-Short Term Memory recurrent neural network, which is particularly suited for application over long time series, is employed in the analysis of in-situ measurements of solar wind plasma and magnetic field acquired over more than one solar cycle, from $2005$ to $2019$, at the Lagrangian point L$1$. The problem is approached as a binary classification aiming to predict one hour in advance a decrease in the SYM-H geomagnetic activity index below the threshold of $-50$ nT, which is generally regarded as indicative of magnetospheric perturbations. The strong class imbalance issue is tackled by using an appropriate loss function tailored to optimize appropriate skill scores in the training phase of the neural network. Beside classical skill scores, value-weighted skill scores are then employed to evaluate predictio
    
[^84]: 旨在实现因果表示的可重用性和可组合性

    Towards the Reusability and Compositionality of Causal Representations

    [https://arxiv.org/abs/2403.09830](https://arxiv.org/abs/2403.09830)

    该研究提出了DECAF框架，旨在从时间序列图像中学习因果表示，使其能够在新环境中进行调整，并在多个相关环境中进行组合，通过与四种最先进的CRL方法结合，能够在新环境中使用少量样本即可获得准确的表示。

    

    Causal Representation Learning（CRL）旨在从高维观测中识别高级因果因素及其关系，例如图像。大多数CRL作品侧重于在单个环境中学习因果表示，而本研究提出了一个新方向，即从图像的时间序列中学习因果表示，可以在新环境中进行调整，或者跨多个相关环境进行组合。具体而言，我们介绍了DECAF，一个框架，用于检测哪些因果因素可以重复使用，哪些需要从先前学习的因果表示中进行调整。我们的方法基于干预目标的可用性，这些目标指示每个时间步骤上被扰动的变量。在三个基准数据集上的实验表明，将我们的框架与四种最先进的CRL方法结合使用，可以在新环境中仅使用少量样本即可获得准确的表示。

    arXiv:2403.09830v1 Announce Type: cross  Abstract: Causal Representation Learning (CRL) aims at identifying high-level causal factors and their relationships from high-dimensional observations, e.g., images. While most CRL works focus on learning causal representations in a single environment, in this work we instead propose a first step towards learning causal representations from temporal sequences of images that can be adapted in a new environment, or composed across multiple related environments. In particular, we introduce DECAF, a framework that detects which causal factors can be reused and which need to be adapted from previously learned causal representations. Our approach is based on the availability of intervention targets, that indicate which variables are perturbed at each time step. Experiments on three benchmark datasets show that integrating our framework with four state-of-the-art CRL approaches leads to accurate representations in a new environment with only a few sam
    
[^85]: LabelAId: 用于改善众包系统中人类标注质量和领域知识的及时AI干预

    LabelAId: Just-in-time AI Interventions for Improving Human Labeling Quality and Domain Knowledge in Crowdsourcing Systems

    [https://arxiv.org/abs/2403.09810](https://arxiv.org/abs/2403.09810)

    该论文探讨了如何利用即时AI干预来提升众包平台中人类标注质量和领域知识，介绍了LabelAId模型，与传统方法相比，其能够显著提高错误推断准确性。

    

    众包平台已经改变了分布式问题解决，但质量控制仍然是一个持久的挑战。传统的质量控制措施，如对工作者进行预筛选和完善说明，通常只专注于优化经济产出。本文探讨了即时AI干预，以增强众包工作者的标注质量和领域特定知识。我们引入了LabelAId，一种先进的推断模型，它结合了程序化弱监督（PWS）和FT-Transformers，根据用户行为和领域知识推断标签的正确性。我们的技术评估显示，我们的LabelAId管道始终优于最先进的ML基线，使用50个下游样本提高了36.7%的错误推断准确性。然后，我们将LabelAId实现到Project Sidewalk中，这是一个面向城市可访问性的开源众包平台。一项涉及34名参与者的实验表明

    arXiv:2403.09810v1 Announce Type: cross  Abstract: Crowdsourcing platforms have transformed distributed problem-solving, yet quality control remains a persistent challenge. Traditional quality control measures, such as prescreening workers and refining instructions, often focus solely on optimizing economic output. This paper explores just-in-time AI interventions to enhance both labeling quality and domain-specific knowledge among crowdworkers. We introduce LabelAId, an advanced inference model combining Programmatic Weak Supervision (PWS) with FT-Transformers to infer label correctness based on user behavior and domain knowledge. Our technical evaluation shows that our LabelAId pipeline consistently outperforms state-of-the-art ML baselines, improving mistake inference accuracy by 36.7% with 50 downstream samples. We then implemented LabelAId into Project Sidewalk, an open-source crowdsourcing platform for urban accessibility. A between-subjects study with 34 participants demonstrate
    
[^86]: 自监督学习用于时间序列：对比或生成？

    Self-Supervised Learning for Time Series: Contrastive or Generative?

    [https://arxiv.org/abs/2403.09809](https://arxiv.org/abs/2403.09809)

    本文对时间序列中的对比和生成自监督学习方法进行了全面比较研究，提供了各种方法的优势和劣势洞察，并为选择合适的SSL方法提供了实用建议。

    

    自监督学习（SSL）最近已经被证明是一种从大规模未标记数据中学习表示的强大方法，在时间序列分析中表现出有希望的结果。自监督表示学习可以分为两个主流：对比和生成。在本文中，我们将对时间序列中的对比和生成方法进行全面的比较研究。首先，我们分别介绍了对比和生成SSL的基本框架，并讨论了如何获得指导模型优化的监督信号。然后，我们分别为每种类型实现了经典算法（SimCLR vs. MAE），并在公平设置下进行了比较分析。我们的结果提供了对每种方法的优势和劣势的深入洞察，并为选择合适的SSL方法提供了实用建议。我们还讨论了我们的发现对更广泛的表示学习领域的影响。

    arXiv:2403.09809v1 Announce Type: cross  Abstract: Self-supervised learning (SSL) has recently emerged as a powerful approach to learning representations from large-scale unlabeled data, showing promising results in time series analysis. The self-supervised representation learning can be categorized into two mainstream: contrastive and generative. In this paper, we will present a comprehensive comparative study between contrastive and generative methods in time series. We first introduce the basic frameworks for contrastive and generative SSL, respectively, and discuss how to obtain the supervision signal that guides the model optimization. We then implement classical algorithms (SimCLR vs. MAE) for each type and conduct a comparative analysis in fair settings. Our results provide insights into the strengths and weaknesses of each approach and offer practical recommendations for choosing suitable SSL methods. We also discuss the implications of our findings for the broader field of rep
    
[^87]: xLP：主数据管理的可解释链接预测

    xLP: Explainable Link Prediction for Master Data Management

    [https://arxiv.org/abs/2403.09806](https://arxiv.org/abs/2403.09806)

    主数据管理领域的xLP项目通过结合解释性、事实验证、路径排名、神经符号推理和自解释AI等研究成果，创造性地提供了链接预测的解释，并让用户可以选择更符合其需求的解释方式。

    

    arXiv:2403.09806v1 公告类型：新摘要：向用户解释神经模型的预测需要创造力。尤其是在企业应用中，用户的时间成本很高，他们对模型预测的信任对于采用至关重要。对于主数据管理中的链接预测，我们构建了许多可解释性解决方案，汲取了解释性、事实验证、路径排名、神经符号推理和自解释AI等研究成果。在这个演示中，我们以一种富有创意的方式呈现链接预测的解释，让用户选择他们更舒适的解释。

    arXiv:2403.09806v1 Announce Type: new  Abstract: Explaining neural model predictions to users requires creativity. Especially in enterprise applications, where there are costs associated with users' time, and their trust in the model predictions is critical for adoption. For link prediction in master data management, we have built a number of explainability solutions drawing from research in interpretability, fact verification, path ranking, neuro-symbolic reasoning and self-explaining AI. In this demo, we present explanations for link prediction in a creative way, to allow users to choose explanations they are more comfortable with.
    
[^88]: 探讨大型语言模型在在线诱拐预防中的效力：有益还是有害？

    Helpful or Harmful? Exploring the Efficacy of Large Language Models for Online Grooming Prevention

    [https://arxiv.org/abs/2403.09795](https://arxiv.org/abs/2403.09795)

    研究人员探索大型语言模型在在线诱拐预防中的有效性，发现没有模型明显适用于此目的，存在潜在的有害答案生成。

    

    强大的生成式大型语言模型(LLMs)作为问答系统正在成为普通大众和脆弱群体（如儿童）之间流行的工具。随着儿童与这些工具的互动日益增多，对研究人员来说，审视LLMs的安全性至关重要，特别是对可能导致严重后果的应用，比如在线儿童安全查询。本文探讨了LLMs在在线诱拐预防中的效力，既包括通过建议生成来识别和避免诱拐，也通过改变提供的上下文和提示特定性来调查提示设计对模型性能的影响。通过对超过6,000次LLMs互动的结果反映，我们发现没有模型明显适用于在线诱拐预防，在行为一致性方面存在缺乏一致性，并且存在有害答案生成的潜力，特别是来自开源

    arXiv:2403.09795v1 Announce Type: cross  Abstract: Powerful generative Large Language Models (LLMs) are becoming popular tools amongst the general public as question-answering systems, and are being utilised by vulnerable groups such as children. With children increasingly interacting with these tools, it is imperative for researchers to scrutinise the safety of LLMs, especially for applications that could lead to serious outcomes, such as online child safety queries. In this paper, the efficacy of LLMs for online grooming prevention is explored both for identifying and avoiding grooming through advice generation, and the impact of prompt design on model performance is investigated by varying the provided context and prompt specificity. In results reflecting over 6,000 LLM interactions, we find that no models were clearly appropriate for online grooming prevention, with an observed lack of consistency in behaviours, and potential for harmful answer generation, especially from open-sour
    
[^89]: 社会整合导航：具有深度强化学习的社交行动机器人

    Socially Integrated Navigation: A Social Acting Robot with Deep Reinforcement Learning

    [https://arxiv.org/abs/2403.09793](https://arxiv.org/abs/2403.09793)

    提出了一种新颖的社会整合导航方法，通过与人的互动使机器人的社交行为自适应，并从其他基于DRL的导航方法中区分出具有明确预定义社交行为的社会意识方法和缺乏社交行为的社会碰撞回避。

    

    移动机器人正在广泛应用于各种拥挤场景，并成为我们社会的一部分。一个具有个体人类考虑的社会可接受的导航行为对于可扩展的应用和人类接受至关重要。最近使用深度强化学习（DRL）方法来学习机器人的导航策略，并对机器人与人类之间的复杂交互进行建模。我们建议根据机器人展示的社交行为将现有基于DRL的导航方法分为具有缺乏社交行为的社会碰撞回避和具有明确预定义社交行为的社会意识方法。此外，我们提出了一种新颖的社会整合导航方法，其中机器人的社交行为是自适应的，并且是通过与人类的互动而产生的。我们的方法的构式源自社会学定义，

    arXiv:2403.09793v1 Announce Type: cross  Abstract: Mobile robots are being used on a large scale in various crowded situations and become part of our society. The socially acceptable navigation behavior of a mobile robot with individual human consideration is an essential requirement for scalable applications and human acceptance. Deep Reinforcement Learning (DRL) approaches are recently used to learn a robot's navigation policy and to model the complex interactions between robots and humans. We propose to divide existing DRL-based navigation approaches based on the robot's exhibited social behavior and distinguish between social collision avoidance with a lack of social behavior and socially aware approaches with explicit predefined social behavior. In addition, we propose a novel socially integrated navigation approach where the robot's social behavior is adaptive and emerges from the interaction with humans. The formulation of our approach is derived from a sociological definition, 
    
[^90]: 通过人工智能实现情绪智能：自然语言处理和深度学习在医疗文本分析中的应用

    Emotional Intelligence Through Artificial Intelligence : NLP and Deep Learning in the Analysis of Healthcare Texts

    [https://arxiv.org/abs/2403.09762](https://arxiv.org/abs/2403.09762)

    本文系统考察了人工智能在医疗文本中情感分析方面的应用，展示了算法精度、神经退行性疾病预测以及临床决策支持方面的显著进展。

    

    本文介绍了人工智能在评估与医疗相关文本中情绪方面的应用的方法论检查，特别关注了自然语言处理和深度学习技术的融合。我们审查了许多利用人工智能增强情感分析、对情绪进行分类以及基于临床叙事、患者对药物的反馈和在线健康讨论所获得的文本信息预测患者结果的研究。综述展示了用于情感分类的算法精度、用于神经退行性疾病的AI模型预测能力以及支持临床决策的AI系统的显著进展。值得注意的是，人工智能应用的利用提高了个性化治疗计划，通过整合患者情绪并

    arXiv:2403.09762v1 Announce Type: cross  Abstract: This manuscript presents a methodical examination of the utilization of Artificial Intelligence in the assessment of emotions in texts related to healthcare, with a particular focus on the incorporation of Natural Language Processing and deep learning technologies. We scrutinize numerous research studies that employ AI to augment sentiment analysis, categorize emotions, and forecast patient outcomes based on textual information derived from clinical narratives, patient feedback on medications, and online health discussions. The review demonstrates noteworthy progress in the precision of algorithms used for sentiment classification, the prognostic capabilities of AI models for neurodegenerative diseases, and the creation of AI-powered systems that offer support in clinical decision-making. Remarkably, the utilization of AI applications has exhibited an enhancement in personalized therapy plans by integrating patient sentiment and contri
    
[^91]: SpokeN-100：用于不同语言中口语数字分类的跨语言基准数据集

    SpokeN-100: A Cross-Lingual Benchmarking Dataset for The Classification of Spoken Numbers in Different Languages

    [https://arxiv.org/abs/2403.09753](https://arxiv.org/abs/2403.09753)

    SpokeN-100是一个跨语言基准数据集，包括四种不同语言中32位不同说话者说出的0到99的口语数字，旨在为微型深度学习领域的语音识别任务提供挑战，同时引入了用于分类语言和口语数字的基准任务。

    

    arXiv:2403.09753v1 公告类型：跨语言。基准测试在评估和提升为在资源受限设备上执行而设计的紧凑深度学习模型的性能方面发挥着关键作用，例如微控制器。我们的研究引入了一个新颖的、完全人工生成的基准测试数据集，专为语音识别而设计，代表了微型深度学习领域的核心挑战。SpokeN-100包括来自32位不同说话者在四种不同语言中（英语、普通话、德语和法语）说出的0到99的口语数字，共计12,800个音频样本。我们确定听觉特征并使用UMAP（Uniform Manifold Approximation and Projection for Dimension Reduction）作为降维方法，展示数据集的多样性和丰富性。为了突出数据集的用例，我们介绍了两个基准任务：给定一个音频样本，对所用语言进行分类（i）和/或对口语数字进行分类（ii）。我们优化了状态

    arXiv:2403.09753v1 Announce Type: cross  Abstract: Benchmarking plays a pivotal role in assessing and enhancing the performance of compact deep learning models designed for execution on resource-constrained devices, such as microcontrollers. Our study introduces a novel, entirely artificially generated benchmarking dataset tailored for speech recognition, representing a core challenge in the field of tiny deep learning. SpokeN-100 consists of spoken numbers from 0 to 99 spoken by 32 different speakers in four different languages, namely English, Mandarin, German and French, resulting in 12,800 audio samples. We determine auditory features and use UMAP (Uniform Manifold Approximation and Projection for Dimension Reduction) as a dimensionality reduction method to show the diversity and richness of the dataset. To highlight the use case of the dataset, we introduce two benchmark tasks: given an audio sample, classify (i) the used language and/or (ii) the spoken number. We optimized state-
    
[^92]: 面向IoMT系统的可解释机器学习安全与隐私保护框架

    Explainable Machine Learning-Based Security and Privacy Protection Framework for Internet of Medical Things Systems

    [https://arxiv.org/abs/2403.09752](https://arxiv.org/abs/2403.09752)

    该论文提出了面向互联网医疗物联网系统的可解释机器学习安全与隐私保护框架，旨在解决IoMT系统面临的安全挑战，包括数据敏感性、恶意攻击和异常检测。

    

    互联网医疗物联网（IoMT）跨越了传统医疗边界，实现了从被动治疗向主动预防的过渡。这种创新方法通过实时健康数据收集实现早期疾病检测和个性化护理，特别在慢性病管理方面，IoMT可以自动化治疗。然而，由于处理数据的敏感性和价值，IoMT面临着严重的安全挑战，这会威胁到其用户的生命，因此吸引了恶意利益。此外，利用无线通信进行数据传输会使医疗数据暴露于被网络犯罪分子截获和篡改的风险之下。此外，由于人为错误、网络干扰或硬件故障，可能会出现异常。在这种背景下，基于机器学习（ML）的异常检测是一个有趣的解决方案，但它再次出现。

    arXiv:2403.09752v1 Announce Type: cross  Abstract: The Internet of Medical Things (IoMT) transcends traditional medical boundaries, enabling a transition from reactive treatment to proactive prevention. This innovative method revolutionizes healthcare by facilitating early disease detection and tailored care, particularly in chronic disease management, where IoMT automates treatments based on real-time health data collection. Nonetheless, its benefits are countered by significant security challenges that endanger the lives of its users due to the sensitivity and value of the processed data, thereby attracting malicious interests. Moreover, the utilization of wireless communication for data transmission exposes medical data to interception and tampering by cybercriminals. Additionally, anomalies may arise due to human errors, network interference, or hardware malfunctions. In this context, anomaly detection based on Machine Learning (ML) is an interesting solution, but it comes up again
    
[^93]: 你的提示是什么？一种针对AI助手的远程键盘记录攻击

    What Was Your Prompt? A Remote Keylogging Attack on AI Assistants

    [https://arxiv.org/abs/2403.09751](https://arxiv.org/abs/2403.09751)

    本文揭示了一种可以用于读取AI助手加密响应的新型旁路攻击——令牌长度旁路，并展示了如何通过利用大型语言模型，提供句子间上下文并进行已知明文攻击来克服这一挑战。

    

    AI助手正逐渐成为社会的一个重要组成部分，用于寻求个人和机密问题的建议或帮助。本文揭示了一种新的旁路攻击，可用于通过网络读取AI助手的加密响应：令牌长度旁路。我们发现包括OpenAI和Microsoft在内的许多厂商受到这一旁路的影响。然而，仅从令牌长度序列推断响应内容却具有挑战性。这是因为令牌类似于单词，响应可以是几句话长，导致有成千上万个语法正确的句子。

    arXiv:2403.09751v1 Announce Type: cross  Abstract: AI assistants are becoming an integral part of society, used for asking advice or help in personal and confidential issues. In this paper, we unveil a novel side-channel that can be used to read encrypted responses from AI Assistants over the web: the token-length side-channel. We found that many vendors, including OpenAI and Microsoft, have this side-channel.   However, inferring the content of a response from a token-length sequence alone proves challenging. This is because tokens are akin to words, and responses can be several sentences long leading to millions of grammatically correct sentences. In this paper, we show how this can be overcome by (1) utilizing the power of a large language model (LLM) to translate these sequences, (2) providing the LLM with inter-sentence context to narrow the search space and (3) performing a known-plaintext attack by fine-tuning the model on the target model's writing style.   Using these methods,
    
[^94]: 元认知分析：评估数据集和大型语言模型中的陈述性和程序性知识

    Meta-Cognitive Analysis: Evaluating Declarative and Procedural Knowledge in Datasets and Large Language Models

    [https://arxiv.org/abs/2403.09750](https://arxiv.org/abs/2403.09750)

    通过广泛实验探索了LLMs中的陈述性知识和程序性知识对各种任务的影响，发现陈述性知识在大多数任务中的益处大于程序性知识，在简单逻辑推理任务中反之；随着预训练和规模的增加，模型利用两种知识的能力均显著提高。

    

    元认知理论中的陈述性知识和程序性知识是两个关键部分，在LLM的预训练和推理中非常重要。然而，由于对这两种知识的定义、探究和定量评估存在挑战，缺乏对这两种知识进行全面比较的分析。本文从一个新的角度提供了LLMs的地面真知，并评估了有效得分。通过对广泛使用的数据集和模型进行大量实验，我们得出结论：(1) 在大多数任务中，来自陈述性知识的益处大于来自程序性知识的益处。(2) 仅在具有简单逻辑推理的任务中，程序性知识的利润大于陈述性知识。(3) 随着预训练的进行和规模的增加，模型利用两种知识的能力显著提高，但速度不同。我们进行了详细分析。

    arXiv:2403.09750v1 Announce Type: cross  Abstract: Declarative knowledge and procedural knowledge are two key parts in meta-cognitive theory, and these two hold significant importance in pre-training and inference of LLMs. However, a comprehensive analysis comparing these two types of knowledge is lacking, primarily due to challenges in definition, probing and quantitative assessment. In this paper, we explore from a new perspective by providing ground-truth knowledge for LLMs and evaluating the effective score. Through extensive experiments with widely-used datasets and models, we get conclusions: (1) In most tasks, benefits from declarative knowledge are greater than those from procedural knowledge. (2) Profits of procedural knowledge are larger than declarative knowledge only in reasoning tasks with simple logic. (3) As pre-training progresses and size increases, model ability to utilize both kinds of knowledge significantly improves, but in different speed. We do detailed analysis 
    
[^95]: 实现多元视角学习：基于多个时间池化的选择

    Towards Diverse Perspective Learning with Selection over Multiple Temporal Poolings

    [https://arxiv.org/abs/2403.09749](https://arxiv.org/abs/2403.09749)

    提出了一种新颖的时间池化方法SoM-TP，通过多元视角学习实现动态选择最佳时间池化，在单个分类器内实现非迭代池化集成。

    

    在时间序列分类（TSC）中，提出了考虑顺序信息的时间池化方法。然而，我们发现每个时间池化具有不同的机制，并且根据时间序列数据的不同情况可能效果好坏不一。我们将这种固定池化机制称为单一视角的时间池化。在本文中，我们提出了一种具有多元视角学习的新型时间池化方法：选择多个时间池化（SoM-TP）。SoM-TP通过注意力动态选择多种方法中针对每个数据的最佳时间池化。SoM-TP的动态池化选择受到多选学习（MCL）集成概念的启发，该概念从多个输出中选择最佳输出。SoM-TP的注意力池化选择实现了单个分类器内的非迭代池化集成。此外，我们定义了一个视角损失和多元视角学习网络（DPLN）。

    arXiv:2403.09749v1 Announce Type: cross  Abstract: In Time Series Classification (TSC), temporal pooling methods that consider sequential information have been proposed. However, we found that each temporal pooling has a distinct mechanism, and can perform better or worse depending on time series data. We term this fixed pooling mechanism a single perspective of temporal poolings. In this paper, we propose a novel temporal pooling method with diverse perspective learning: Selection over Multiple Temporal Poolings (SoM-TP). SoM-TP dynamically selects the optimal temporal pooling among multiple methods for each data by attention. The dynamic pooling selection is motivated by the ensemble concept of Multiple Choice Learning (MCL), which selects the best among multiple outputs. The pooling selection by SoM-TP's attention enables a non-iterative pooling ensemble within a single classifier. Additionally, we define a perspective loss and Diverse Perspective Learning Network (DPLN). The loss w
    
[^96]: 重新探寻真相：多轮检索增强的大型语言模型是强大的假新闻检测器

    Re-Search for The Truth: Multi-round Retrieval-augmented Large Language Models are Strong Fake News Detectors

    [https://arxiv.org/abs/2403.09747](https://arxiv.org/abs/2403.09747)

    大型语言模型在假新闻检测中引入新的前沿，但仍需克服解决过时知识和低质量证据检索等问题

    

    假新闻的泛滥对政治、经济和社会带来了深远的影响。尽管已经采用了假新闻检测方法来缓解这一问题，但它们主要依赖于两个基本要素：证据的质量和相关性，以及预测机制的有效性。传统方法通常从维基百科等静态知识库中获取信息，但受限于过时或不完整的数据，尤其是对于新兴或罕见的要求。以其卓越的推理和生成能力而闻名的大型语言模型(LLMs)为假新闻检测引入了一个新的领域。然而，与传统方法一样，基于LLM的解决方案也会面临过时和长尾知识的限制。此外，检索增强的LLMs经常遇到低质量证据检索和上下文长度限制等问题。为了解决这些问题

    arXiv:2403.09747v1 Announce Type: cross  Abstract: The proliferation of fake news has had far-reaching implications on politics, the economy, and society at large. While Fake news detection methods have been employed to mitigate this issue, they primarily depend on two essential elements: the quality and relevance of the evidence, and the effectiveness of the verdict prediction mechanism. Traditional methods, which often source information from static repositories like Wikipedia, are limited by outdated or incomplete data, particularly for emerging or rare claims. Large Language Models (LLMs), known for their remarkable reasoning and generative capabilities, introduce a new frontier for fake news detection. However, like traditional methods, LLM-based solutions also grapple with the limitations of stale and long-tail knowledge. Additionally, retrieval-enhanced LLMs frequently struggle with issues such as low-quality evidence retrieval and context length constraints. To address these ch
    
[^97]: 评估大型语言模型在编程教育中生成反馈的应用

    Evaluating the Application of Large Language Models to Generate Feedback in Programming Education

    [https://arxiv.org/abs/2403.09744](https://arxiv.org/abs/2403.09744)

    评估了大型语言模型在编程教育中生成反馈的应用，结果显示大多数反馈有效地解决了代码错误，但存在不正确建议和虚构问题，需要进一步改进。

    

    该研究调查了大型语言模型，特别是GPT-4，在提升编程教育中的应用。研究概述了一个利用GPT-4提供编程任务反馈但不提供解决方案的网页应用的设计。研究开发了一个用于进行编程任务的网页应用，并在一个学期内对51名学生进行了评估。结果显示，大多数由GPT-4生成的反馈有效地解决了代码错误。然而，存在不正确建议和虚构问题的挑战表明有进一步改进的必要。

    arXiv:2403.09744v1 Announce Type: cross  Abstract: This study investigates the application of large language models, specifically GPT-4, to enhance programming education. The research outlines the design of a web application that uses GPT-4 to provide feedback on programming tasks, without giving away the solution. A web application for working on programming tasks was developed for the study and evaluated with 51 students over the course of one semester. The results show that most of the feedback generated by GPT-4 effectively addressed code errors. However, challenges with incorrect suggestions and hallucinated issues indicate the need for further improvements.
    
[^98]: 大型语言模型中的人为因素：系统文献综述与未来研究方向

    The Human Factor in Detecting Errors of Large Language Models: A Systematic Literature Review and Future Research Directions

    [https://arxiv.org/abs/2403.09743](https://arxiv.org/abs/2403.09743)

    人工智能领域中，这项研究探索了人类因素在检测大型语言模型的错误输出中的作用，有助于减轻其在专业环境中使用时所带来的风险。

    

    OpenAI在2022年11月推出的ChatGPT标志着人工智能的一个关键时刻，将大型语言模型（LLMs）引入主流，并在用户采用方面创造了新记录。尤其是ChatGPT，经过广泛的互联网数据训练，展示出在各个领域具有显著的对话能力，暗示对劳动力产生了重大影响。然而，这些模型容易出现错误-“幻觉”和遗漏，产生不正确或不完整的信息。这在准确性至关重要的环境中尤为危险，比如法律合规、医学或精细的流程框架。

    arXiv:2403.09743v1 Announce Type: cross  Abstract: The launch of ChatGPT by OpenAI in November 2022 marked a pivotal moment for Artificial Intelligence, introducing Large Language Models (LLMs) to the mainstream and setting new records in user adoption. LLMs, particularly ChatGPT, trained on extensive internet data, demonstrate remarkable conversational capabilities across various domains, suggesting a significant impact on the workforce. However, these models are susceptible to errors - "hallucinations" and omissions, generating incorrect or incomplete information. This poses risks especially in contexts where accuracy is crucial, such as legal compliance, medicine or fine-grained process frameworks.   There are both technical and human solutions to cope with this isse. This paper explores the human factors that enable users to detect errors in LLM outputs, a critical component in mitigating risks associated with their use in professional settings. Understanding these factors is essen
    
[^99]: 最大团问题的新方法简要回顾：从经典算法到图神经网络和量子算法

    A Short Review on Novel Approaches for Maximum Clique Problem: from Classical algorithms to Graph Neural Networks and Quantum algorithms

    [https://arxiv.org/abs/2403.09742](https://arxiv.org/abs/2403.09742)

    该综述回顾了解决最大团问题的经典算法，同时也涵盖了图神经网络和量子算法的最新进展，并提出了用于测试这些算法的基准。

    

    这篇手稿全面回顾了最大团问题，这是一个涉及在图中找到所有两两相邻的顶点子集的计算问题。手稿以简单的方式涵盖了解决该问题的经典算法，并包括了对图神经网络和量子算法最近发展的审查。该综述以基准测试来评估经典以及新的学习和量子算法。

    arXiv:2403.09742v1 Announce Type: new  Abstract: This manuscript provides a comprehensive review of the Maximum Clique Problem, a computational problem that involves finding subsets of vertices in a graph that are all pairwise adjacent to each other. The manuscript covers in a simple way classical algorithms for solving the problem and includes a review of recent developments in graph neural networks and quantum algorithms. The review concludes with benchmarks for testing classical as well as new learning, and quantum algorithms.
    
[^100]: 教机器编写代码：LLM智能合约翻译

    Teaching Machines to Code: Smart Contract Translation with LLMs

    [https://arxiv.org/abs/2403.09740](https://arxiv.org/abs/2403.09740)

    该研究提出了一种开创性方法SolMover，利用两种不同的LLMs协同作用，设计了一个统一的框架，用以将代码翻译为一个陌生的语言

    

    大型语言模型（LLMs）的出现在人工智能领域标志着一个重大里程碑，它们的能力常常可以匹敌甚至超越人类在各个领域的专业知识。在这些成就中，它们在翻译任务中的灵活性突出，密切模仿人类翻译者进行的复杂和初步流程，以确保翻译内容的忠实性和质量。尽管在利用LLMs跨不同语言翻译编程代码方面取得了进展，但智能合约翻译领域，特别是进入LLM之前未曾遇到过的语言，仍然是一个未被充分探讨的领域。在我们的研究中，我们提出了一种开创性方法SolMover，它在一个统一的框架内充分利用了两种不同的LLMs的协同作用。这个框架旨在理解编码原则，并将这种理解应用于将代码翻译为一个陌生的语言。

    arXiv:2403.09740v1 Announce Type: cross  Abstract: The advent of large language models (LLMs) has marked a significant milestone in the realm of artificial intelligence, with their capabilities often matching or surpassing human expertise in various domains. Among these achievements, their adeptness in translation tasks stands out, closely mimicking the intricate and preliminary processes undertaken by human translators to ensure the fidelity and quality of the translated content. Despite the advancements in utilizing LLMs for translating programming code across different languages, the domain of smart contract translation, particularly into languages not previously encountered by the LLM, remains largely unexplored. In our research, we present a pioneering approach, SolMover, which harnesses the synergy of two distinct LLMs within a unified framework. This framework is designed to grasp coding principles and apply this understanding to the translation of code into an unfamiliar langua
    
[^101]: 评估大语言模型作为对话推荐中生成用户模拟器

    Evaluating Large Language Models as Generative User Simulators for Conversational Recommendation

    [https://arxiv.org/abs/2403.09738](https://arxiv.org/abs/2403.09738)

    大型语言模型作为生成式用户模拟器在对话推荐中展现出潜力，新的协议通过五个任务评估了语言模型模拟人类行为的准确程度，揭示了模型与人类行为的偏差，并提出了如何通过模型选择和提示策略减少这些偏差。

    

    合成用户是对话推荐系统评估中成本效益较高的真实用户代理。大型语言模型表现出在模拟类似人类行为方面的潜力，这引发了它们能否代表多样化用户群体的问题。我们引入了一个新的协议，用于衡量语言模型能够准确模拟对话推荐中人类行为的程度。该协议由五个任务组成，每个任务旨在评估合成用户应该表现出的关键特性：选择要谈论的物品，表达二进制偏好，表达开放式偏好，请求推荐以及提供反馈。通过对基准模拟器的评估，我们展示了这些任务有效地揭示了语言模型与人类行为的偏差，并提供了关于如何通过模型选择和提示策略减少这些偏差的见解。

    arXiv:2403.09738v1 Announce Type: cross  Abstract: Synthetic users are cost-effective proxies for real users in the evaluation of conversational recommender systems. Large language models show promise in simulating human-like behavior, raising the question of their ability to represent a diverse population of users. We introduce a new protocol to measure the degree to which language models can accurately emulate human behavior in conversational recommendation. This protocol is comprised of five tasks, each designed to evaluate a key property that a synthetic user should exhibit: choosing which items to talk about, expressing binary preferences, expressing open-ended preferences, requesting recommendations, and giving feedback. Through evaluation of baseline simulators, we demonstrate these tasks effectively reveal deviations of language models from human behavior, and offer insights on how to reduce the deviations with model selection and prompting strategies.
    
[^102]: 一个用于准确检测网络钓鱼网站的复杂框架

    A Sophisticated Framework for the Accurate Detection of Phishing Websites

    [https://arxiv.org/abs/2403.09735](https://arxiv.org/abs/2403.09735)

    提出了一个用于准确检测网络钓鱼网站的综合方法论，旨在设计一个系统，能够准确区分钓鱼网站和合法网站，并在各种数据集上提供泛化性能。

    

    网络钓鱼是一种日益复杂的网络攻击形式，给全球企业带来巨大财务损失的同时，也危及个人隐私。攻击者不断设计新的发动攻击方法，检测这些攻击变得十分困难。许多不同的技术已被提出，各有利弊。虽然基于机器学习的技术在识别此类攻击方面最为成功，但在性能和泛化能力方面仍有不足。本文提出了一种全面的方法论来检测网络钓鱼网站。目标是设计出一个能够准确区分钓鱼网站和合法网站的系统，并在广泛的数据集上提供泛化性能。采用了特征选择、贪婪算法、交叉验证和深度学习方法的综合组合来构建该系统。

    arXiv:2403.09735v1 Announce Type: cross  Abstract: Phishing is an increasingly sophisticated form of cyberattack that is inflicting huge financial damage to corporations throughout the globe while also jeopardizing individuals' privacy. Attackers are constantly devising new methods of launching such assaults and detecting them has become a daunting task. Many different techniques have been suggested, each with its own pros and cons. While machine learning-based techniques have been most successful in identifying such attacks, they continue to fall short in terms of performance and generalizability. This paper proposes a comprehensive methodology for detecting phishing websites. The goal is to design a system that is capable of accurately distinguishing phishing websites from legitimate ones and provides generalized performance over a broad variety of datasets. A combination of feature selection, greedy algorithm, cross-validation, and deep learning methods have been utilized to constru
    
[^103]: 大型语言模型是否像人一样解决ARC视觉类比问题？

    Do Large Language Models Solve ARC Visual Analogies Like People Do?

    [https://arxiv.org/abs/2403.09734](https://arxiv.org/abs/2403.09734)

    该研究比较了人类和大型语言模型在ARC视觉类比问题上的表现，发现在特定任务上，人类和成年人的表现均优于大多数大型语言模型。对LLMs和年幼儿童错误分析揭示了类似的解决策略，同时指出了两种不同的错误类型，为我们理解LLMs如何解决视觉类比问题提供了新的启示。

    

    抑制论文（Chollet, 2019）形式，我们比较了儿童友好的ARC项目上人类和大型语言模型（LLM）的表现。结果表明，无论是儿童还是成年人，在这些任务上都胜过大多数LLMs。错误分析揭示了LLMs和年幼儿童之间类似的“倒退”解决策略，其中类比的一部分被简单复制。此外，我们发现其他两种错误类型，一种基于表面掌握关键概念（例如，内外关系），另一种基于类比输入矩阵的简单组合。总体而言，“概念”错误在人类中更常见，“矩阵”错误在LLMs中更常见。这项研究为LLM的推理能力和我们可以使用错误分析以及与人类发展的比较来理解LLMs如何解决视觉类比问题提供了新的视角。

    arXiv:2403.09734v1 Announce Type: cross  Abstract: The Abstraction Reasoning Corpus (ARC) is a visual analogical reasoning test designed for humans and machines (Chollet, 2019). We compared human and large language model (LLM) performance on a new child-friendly set of ARC items. Results show that both children and adults outperform most LLMs on these tasks. Error analysis revealed a similar "fallback" solution strategy in LLMs and young children, where part of the analogy is simply copied. In addition, we found two other error types, one based on seemingly grasping key concepts (e.g., Inside-Outside) and the other based on simple combinations of analogy input matrices. On the whole, "concept" errors were more common in humans, and "matrix" errors were more common in LLMs. This study sheds new light on LLM reasoning ability and the extent to which we can use error analyses and comparisons with human development to understand how LLMs solve visual analogies.
    
[^104]: OverleafCopilot：在Overleaf中利用大型语言模型增强学术写作能力

    OverleafCopilot: Empowering Academic Writing in Overleaf with Large Language Models

    [https://arxiv.org/abs/2403.09733](https://arxiv.org/abs/2403.09733)

    OverleafCopilot是第一个无缝集成大型语言模型和Overleaf的工具，使研究人员能够在撰写论文时利用大型语言模型的能力。

    

    大型语言模型（LLMs）的迅速发展促进了不同领域各种应用的实现。在本技术报告中，我们探讨了将LLMs和流行的学术写作工具Overleaf集成，以提高学术写作的效率和质量。为实现上述目标，我们面临三个挑战：i）在Overleaf和LLMs之间实现无缝交互，ii）与LLM提供者建立可靠通信，iii）确保用户隐私。为了解决这些挑战，我们提出了OverleafCopilot，这是第一个无缝集成LLMs和Overleaf的工具（即浏览器扩展程序），使研究人员在撰写论文时能够充分利用LLMs的能力。具体来说，我们首先提出了一个有效的框架来连接LLMs和Overleaf。然后，我们开发了PromptGenius网站，供研究人员轻松查找和共享高质量的最新提示。第三，我们提出了一种ag

    arXiv:2403.09733v1 Announce Type: cross  Abstract: The rapid development of Large Language Models (LLMs) has facilitated a variety of applications from different domains. In this technical report, we explore the integration of LLMs and the popular academic writing tool, Overleaf, to enhance the efficiency and quality of academic writing. To achieve the above goal, there are three challenges: i) including seamless interaction between Overleaf and LLMs, ii) establishing reliable communication with the LLM provider, and iii) ensuring user privacy. To address these challenges, we present OverleafCopilot, the first-ever tool (i.e., a browser extension) that seamlessly integrates LLMs and Overleaf, enabling researchers to leverage the power of LLMs while writing papers. Specifically, we first propose an effective framework to bridge LLMs and Overleaf. Then, we developed PromptGenius, a website for researchers to easily find and share high-quality up-to-date prompts. Thirdly, we propose an ag
    
[^105]: PET-SQL：一个带有交叉一致性的增强提示的两阶段文本到SQL框架

    PET-SQL: A Prompt-enhanced Two-stage Text-to-SQL Framework with Cross-consistency

    [https://arxiv.org/abs/2403.09732](https://arxiv.org/abs/2403.09732)

    提出了一个两阶段框架，通过引入参考增强表示和少样本演示，解决了在处理冗长的数据库信息和复杂用户意图时的挑战。

    

    最近文本到SQL（Text2SQL）领域的进展强调刺激大型语言模型（LLM）进行上下文学习，取得了显著成果。然而，他们在处理冗长的数据库信息和复杂的用户意图时面临挑战。本文提出了一个两阶段框架，以增强当前基于LLM的自然语言到SQL系统的性能。我们首先引入了一种新颖的提示表示，称为参考增强表示，其中包括模式信息和从表格随机抽样的单元格值，以指导LLM生成SQL查询。然后，在第一阶段，我们检索问题-SQL对作为少量演示，促使LLM生成初步SQL（PreSQL）。之后，解析PreSQL中提到的实体进行模式链接，可以显著压缩有用信息。在第二阶段，利用链接的模式，我们简化了

    arXiv:2403.09732v1 Announce Type: cross  Abstract: Recent advancements in Text-to-SQL (Text2SQL) emphasize stimulating the large language models (LLM) on in-context learning, achieving significant results. Nevertheless, they face challenges when dealing with verbose database information and complex user intentions. This paper presents a two-stage framework to enhance the performance of current LLM-based natural language to SQL systems. We first introduce a novel prompt representation, called reference-enhanced representation, which includes schema information and randomly sampled cell values from tables to instruct LLMs in generating SQL queries. Then, in the first stage, question-SQL pairs are retrieved as few-shot demonstrations, prompting the LLM to generate a preliminary SQL (PreSQL). After that, the mentioned entities in PreSQL are parsed to conduct schema linking, which can significantly compact the useful information. In the second stage, with the linked schema, we simplify the 
    
[^106]: 使用变压器模拟序列和树上的加权自动机

    Simulating Weighted Automata over Sequences and Trees with Transformers

    [https://arxiv.org/abs/2403.09728](https://arxiv.org/abs/2403.09728)

    变压器可以模拟加权有限自动机和加权树自动机，拓展了它们的应用范围。

    

    变压器是自然语言处理（NLP）社区中无处不在的模型，在过去几年中展示出令人印象深刻的经验成功。然而，关于它们推理的方式以及计算能力的限制，人们对此知之甚少。这些模型不是按顺序处理数据，却胜过诸如RNN的顺序神经模型。最近的研究表明，这些模型可以紧凑地模拟确定性有限自动机（DFAs）的序列推理能力。这带来了一个问题：变压器能否模拟更复杂的有限状态机的推理？在这项工作中，我们展示变压器可以模拟加权有限自动机（WFAs），这是一类包含DFAs的模型，以及加权树自动机（WTA），一种加权自动机推广到树形输入的模型。我们正式证明了这些说法，并给出了所需变压器模型大小的上界。

    arXiv:2403.09728v1 Announce Type: cross  Abstract: Transformers are ubiquitous models in the natural language processing (NLP) community and have shown impressive empirical successes in the past few years. However, little is understood about how they reason and the limits of their computational capabilities. These models do not process data sequentially, and yet outperform sequential neural models such as RNNs. Recent work has shown that these models can compactly simulate the sequential reasoning abilities of deterministic finite automata (DFAs). This leads to the following question: can transformers simulate the reasoning of more complex finite state machines? In this work, we show that transformers can simulate weighted finite automata (WFAs), a class of models which subsumes DFAs, as well as weighted tree automata (WTA), a generalization of weighted automata to tree structured inputs. We prove these claims formally and provide upper bounds on the sizes of the transformer models nee
    
[^107]: 探究检索增强生成和微调在发展基于人工智能的知识系统中的表现

    Investigating the performance of Retrieval-Augmented Generation and fine-tuning for the development of AI-driven knowledge-based systems

    [https://arxiv.org/abs/2403.09727](https://arxiv.org/abs/2403.09727)

    RAG-based constructions are more efficient than models produced with FN for the development of AI-driven knowledge-based systems.

    

    arXiv:2403.09727v1 公告类型: 交叉领域 摘要: 生成式大型语言模型(G-LLM)的发展为类似ChatGPT、Bing或Gemini的新型知识系统的开发打开了新的机会。微调(FN)和检索增强生成(RAG)是可用于实现基于G-LLM的知识系统领域自适应的技术。在我们的研究中，利用ROUGE、BLEU、METEOR分数和余弦相似度，我们比较并检验了GPT-J-6B、OPT-6.7B、LlaMA、LlaMA-2语言模型的RAG和FN的表现。基于在不同数据集上展示的测量结果，我们展示了基于RAG的构建比使用FN产生的模型更有效。我们指出将RAG和FN连接起来并不是轻而易举的，因为将FN模型与RAG连接可能会导致性能下降。此外，我们概述了一个简单的基于RAG的架构，平均在RO方面优于FN模型16%

    arXiv:2403.09727v1 Announce Type: cross  Abstract: The development of generative large language models (G-LLM) opened up new opportunities for the development of new types of knowledge-based systems similar to ChatGPT, Bing, or Gemini. Fine-tuning (FN) and Retrieval-Augmented Generation (RAG) are the techniques that can be used to implement domain adaptation for the development of G-LLM-based knowledge systems. In our study, using ROUGE, BLEU, METEOR scores, and cosine similarity, we compare and examine the performance of RAG and FN for the GPT-J-6B, OPT-6.7B, LlaMA, LlaMA-2 language models. Based on measurements shown on different datasets, we demonstrate that RAG-based constructions are more efficient than models produced with FN. We point out that connecting RAG and FN is not trivial, because connecting FN models with RAG can cause a decrease in performance. Furthermore, we outline a simple RAG-based architecture which, on average, outperforms the FN models by 16% in terms of the RO
    
[^108]: RAD-PHI2：为放射学调整PHI-2的指导

    RAD-PHI2: Instruction Tuning PHI-2 for Radiology

    [https://arxiv.org/abs/2403.09725](https://arxiv.org/abs/2403.09725)

    本研究调查了将小语言模型用于放射学领域的应用，通过微调具有27亿参数的Phi-2，提出了具有良好性能的RadPhi-2-Base语言模型。

    

    小语言模型（SLMs）在一般领域语言理解、推理和编码任务中表现出色，但它们在医学领域的能力，尤其是涉及放射学文本的能力，还没有得到充分探讨。本研究探讨了SLMs在一般放射学知识特别是与了解症状、放射学发现的外观、鉴别诊断、评估预后以及针对不同器官系统疾病的治疗方面的问题回答中的应用。此外，我们探讨了将SLMs应用于处理与放射学报告相关任务在基于AI的放射学工作流中的效用。我们使用Radiopaedia这一协作在线放射学资源中的高质量教育内容对具有27亿参数的Phi-2进行微调。所得的语言模型，RadPhi-2-Base，表现出了解决一般放射学问题的能力。

    arXiv:2403.09725v1 Announce Type: cross  Abstract: Small Language Models (SLMs) have shown remarkable performance in general domain language understanding, reasoning and coding tasks, but their capabilities in the medical domain, particularly concerning radiology text, is less explored. In this study, we investigate the application of SLMs for general radiology knowledge specifically question answering related to understanding of symptoms, radiological appearances of findings, differential diagnosis, assessing prognosis, and suggesting treatments w.r.t diseases pertaining to different organ systems. Additionally, we explore the utility of SLMs in handling text-related tasks with respect to radiology reports within AI-driven radiology workflows. We fine-tune Phi-2, a SLM with 2.7 billion parameters using high-quality educational content from Radiopaedia, a collaborative online radiology resource. The resulting language model, RadPhi-2-Base, exhibits the ability to address general radiol
    
[^109]: 从临床文本中提取生物医学概念预测患者的再入院情况

    Prediction of readmission of patients by extracting biomedical concepts from clinical texts

    [https://arxiv.org/abs/2403.09722](https://arxiv.org/abs/2403.09722)

    从临床文本中提取生物医学概念预测患者的再入院情况，可以帮助医生选择适当的治疗方法，从而减少患者再次入院的比率，实现有效的治疗成本降低。

    

    如今，存在大量的电子健康数据为进行旨在改善为患者提供的医疗服务并降低医疗系统成本的研究创造了潜在能力。近年来医学领域备受关注的一个话题是识别出刚从医院出院后可能很快再次入院的患者。这种识别可以帮助医生选择适当的治疗方法，从而减少患者再次入院的比率，实现有效的治疗成本降低。本研究讨论了利用文本挖掘方法和对患者电子文件中的出院报告文本进行处理来预测患者再次入院情况。为此，使用两种方法评估了各种机器学习模型的性能：词袋模型和概念袋模型。

    arXiv:2403.09722v1 Announce Type: cross  Abstract: Today, the existence of a vast amount of electronic health data has created potential capacities for conducting studies aiming to improve the medical services provided to patients and reduce the costs of the healthcare system. One of the topics that has been receiving attention in the field of medicine in recent years is the identification of patients who are likely to be re-hospitalized shortly after being discharged from the hospital. This identification can help doctors choose appropriate treatment methods, thereby reducing the rate of patient re-hospitalization and resulting in effective treatment cost reduction. In this study, the prediction of patient re-hospitalization using text mining approaches and the processing of discharge report texts in the patient's electronic file has been discussed. To this end, the performance of various machine learning models has been evaluated using two approaches: bag of word and bag of concept, 
    
[^110]: 基于语义提及图增强模型的文档级事件论元抽取

    A Semantic Mention Graph Augmented Model for Document-Level Event Argument Extraction

    [https://arxiv.org/abs/2403.09721](https://arxiv.org/abs/2403.09721)

    提出了一种语义提及图增强模型（GAM），通过构建语义提及图和引入集成图变换器模块，有效解决了文档级事件论元抽取中的独立建模实体提及和文档提示隔离问题。

    

    文档级事件论元抽取（DEAE）旨在从非结构化文档中识别论元及其特定角色。本文提出了一种语义提及图增强模型（GAM），旨在解决DEAE中独立建模实体提及和文档提示隔离的问题。GAM构建了一个捕获文档和提示内部及间部关系的语义提及图，引入了一个集成的图变换器模块来有效处理提及及其三种语义关系。

    arXiv:2403.09721v1 Announce Type: cross  Abstract: Document-level Event Argument Extraction (DEAE) aims to identify arguments and their specific roles from an unstructured document. The advanced approaches on DEAE utilize prompt-based methods to guide pre-trained language models (PLMs) in extracting arguments from input documents. They mainly concentrate on establishing relations between triggers and entity mentions within documents, leaving two unresolved problems: a) independent modeling of entity mentions; b) document-prompt isolation. To this end, we propose a semantic mention Graph Augmented Model (GAM) to address these two problems in this paper. Firstly, GAM constructs a semantic mention graph that captures relations within and between documents and prompts, encompassing co-existence, co-reference and co-type relations. Furthermore, we introduce an ensembled graph transformer module to address mentions and their three semantic relations effectively. Later, the graph-augmented en
    
[^111]: 微调与提示，语言模型能理解人类价值观吗？

    Fine-tuning vs Prompting, Can Language Models Understand Human Values?

    [https://arxiv.org/abs/2403.09720](https://arxiv.org/abs/2403.09720)

    通过对Human Value Detection 2023任务中的微调和提示调整的探索，验证语言模型是否能理解人类价值观。

    

    准确处理句子中的潜在支持的价值观对于理解说话者的倾向至关重要，但在自然语言理解（NLU）中却是一个具有挑战性的任务。在本文中，我们探讨了在人类价值检测2023中微调和提示调整在这一下游任务中的潜力。此外，我们尝试验证模型是否能够根据在预训练阶段获得的知识有效解决这个问题。同时，我们对大型语言模型（LLMs）在这个任务中与RLHF的能力感兴趣，并提出了一些初步尝试。

    arXiv:2403.09720v1 Announce Type: cross  Abstract: Accurately handling the underlying support values in sentences is crucial for understanding the speaker's tendencies, yet it poses a challenging task in natural language understanding (NLU). In this article, we explore the potential of fine-tuning and prompt tuning in this downstream task, using the Human Value Detection 2023. Additionally, we attempt to validate whether models can effectively solve the problem based on the knowledge acquired during the pre-training stage. Simultaneously, our interest lies in the capabilities of large language models (LLMs) aligned with RLHF in this task, and some preliminary attempts are presented.
    
[^112]: Mevaker: 针对希伯来语言的结论提取和分配资源

    Mevaker: Conclusion Extraction and Allocation Resources for the Hebrew Language

    [https://arxiv.org/abs/2403.09719](https://arxiv.org/abs/2403.09719)

    介绍了用于希伯来语言的结论提取模型和数据集，包括摘要和结论提取数据集，并提供了相应模型和代码

    

    在本文中，我们基于以色列国家审计长和巡查员的报告，介绍了用于希伯来语言的摘要MevakerSumm和结论提取MevakerConc数据集，以及两个辅助数据集。我们提供了用于结论提取(HeConE, HeConEspc)和结论分配(HeCross)的模型，本工作中使用的所有代码、数据集和模型检查点都是公开可用的。

    arXiv:2403.09719v1 Announce Type: cross  Abstract: In this paper, we introduce summarization MevakerSumm and conclusion extraction MevakerConc datasets for the Hebrew language based on the State Comptroller and Ombudsman of Israel reports, along with two auxiliary datasets. We accompany these datasets with models for conclusion extraction (HeConE, HeConEspc) and conclusion allocation (HeCross). All of the code, datasets, and model checkpoints used in this work are publicly available.
    
[^113]: 提升自然语言处理与系统推荐之间协作的TextCNN的全面实现

    Comprehensive Implementation of TextCNN for Enhanced Collaboration between Natural Language Processing and System Recommendation

    [https://arxiv.org/abs/2403.09718](https://arxiv.org/abs/2403.09718)

    TextCNN的全面实现提升了自然语言处理与系统推荐之间的协作，为NLP领域的文本分类任务带来了新的标准技术。

    

    自然语言处理（NLP）是人工智能的重要分支，研究如何使计算机理解、处理和生成人类语言。文本分类是NLP中的基本任务，旨在将文本分类为不同的预定义类别。深度学习在许多研究领域取得了巨大成功，并成为NLP领域的标准技术，广泛应用于文本分类任务中。与数字和图片不同，文本处理强调精细处理能力。传统文本分类方法通常需要对输入模型的文本数据进行预处理，并通过手动方式获得良好的样本特征。

    arXiv:2403.09718v1 Announce Type: cross  Abstract: Natural Language Processing (NLP) is an important branch of artificial intelligence that studies how to enable computers to understand, process, and generate human language. Text classification is a fundamental task in NLP, which aims to classify text into different predefined categories. Text classification is the most basic and classic task in natural language processing, and most of the tasks in natural language processing can be regarded as classification tasks. In recent years, deep learning has achieved great success in many research fields, and today, it has also become a standard technology in the field of NLP, which is widely integrated into text classification tasks. Unlike numbers and images, text processing emphasizes fine-grained processing ability. Traditional text classification methods generally require preprocessing the input model's text data. Additionally, they also need to obtain good sample features through manual 
    
[^114]: 通过心理状态跟踪提升面向抑郁症诊断的聊天系统

    Enhancing Depression-Diagnosis-Oriented Chat with Psychological State Tracking

    [https://arxiv.org/abs/2403.09717](https://arxiv.org/abs/2403.09717)

    本文提出将心理状态跟踪集成到大型语言模型中，以明确引导抑郁症诊断导向的聊天，从而能更好地捕捉患者在对话过程中的信息、情绪或症状变化。

    

    抑郁症诊断导向的聊天旨在引导患者进行自我表达，收集抑郁症检测的关键症状。最近的工作集中于结合任务导向对话和闲聊，模拟基于访谈的抑郁症诊断。然而，这些方法无法很好地捕捉患者在对话过程中的信息、情绪或症状的变化。此外，还没有明确的框架用于引导对话，这导致一些无用的交流影响了体验。本文提出将心理状态跟踪（POST）集成到大型语言模型（LLM）中，以明确引导抑郁症诊断导向的聊天。具体而言，该状态源自于心理理论模型，包括四个组件，即阶段、信息、总结和下一步。我们微调了一个LLM模型以生成动态心理状态，进而用于辅助r

    arXiv:2403.09717v1 Announce Type: cross  Abstract: Depression-diagnosis-oriented chat aims to guide patients in self-expression to collect key symptoms for depression detection. Recent work focuses on combining task-oriented dialogue and chitchat to simulate the interview-based depression diagnosis. Whereas, these methods can not well capture the changing information, feelings, or symptoms of the patient during dialogues. Moreover, no explicit framework has been explored to guide the dialogue, which results in some useless communications that affect the experience. In this paper, we propose to integrate Psychological State Tracking (POST) within the large language model (LLM) to explicitly guide depression-diagnosis-oriented chat. Specifically, the state is adapted from a psychological theoretical model, which consists of four components, namely Stage, Information, Summary and Next. We fine-tune an LLM model to generate the dynamic psychological state, which is further used to assist r
    
[^115]: 从语言模型中诱导语言结构

    Linguistic Structure Induction from Language Models

    [https://arxiv.org/abs/2403.09714](https://arxiv.org/abs/2403.09714)

    该论文研究从语言模型中以非监督方式生成句法结构的方法，其中介绍了一种利用数值表示短语树的新方法。

    

    我们大脑中隐式地通过分层结构来组织单词在句子中的组成，而这些结构形成了单词的线性序列。语言学家们形式化了不同的框架来模拟这种层次结构；其中最常见的两种句法框架是短语结构和依存结构。短语结构将句子表示为短语的嵌套组，而依存结构通过为单词之间分配关系来表示句子。最近，对智能机器的追求产生了能够以人类水平完成许多语言任务的语言模型（LMs）。许多研究现在质疑LMs是否隐式地表示句法层次结构。本论文集中于在非监督设置中从LMs中生成短语结构和依存结构。我回顾了该领域的关键方法并重点介绍了一项利用二元短语结构树的数值表示（语法距离）的工作线。

    arXiv:2403.09714v1 Announce Type: cross  Abstract: Linear sequences of words are implicitly represented in our brains by hierarchical structures that organize the composition of words in sentences. Linguists formalize different frameworks to model this hierarchy; two of the most common syntactic frameworks are Constituency and Dependency. Constituency represents sentences as nested groups of phrases, while dependency represents a sentence by assigning relations between its words. Recently, the pursuit of intelligent machines has produced Language Models (LMs) capable of solving many language tasks with a human-level performance. Many studies now question whether LMs implicitly represent syntactic hierarchies. This thesis focuses on producing constituency and dependency structures from LMs in an unsupervised setting. I review the critical methods in this field and highlight a line of work that utilizes a numerical representation for binary constituency trees (Syntactic Distance). I pres
    
[^116]: 一种用于论证挖掘的混合智能方法

    A Hybrid Intelligence Method for Argument Mining

    [https://arxiv.org/abs/2403.09713](https://arxiv.org/abs/2403.09713)

    提出了一种混合(人类+AI)方法HyEnA，用于从意见文本中提取论点，结合了自动化处理速度和人类理解推理能力，在公民反馈语料库上取得了更高的覆盖率和准确率。

    

    大规模调查工具能够收集公民反馈意见语料库。从庞大且嘈杂的意见集中提取关键论点有助于快速准确地理解意见。完全自动化的方法可以提取论点，但(1)需要大规模标记数据集，导致较高的注释成本; (2)对已知观点效果良好，但对新颖观点效果欠佳。我们提出了HyEnA，一种混合(人类+AI)方法，用于从主观文本中提取论点，结合了自动化处理的速度和人类的理解和推理能力。我们在三个公民反馈语料库上评估了HyEnA。我们发现，一方面，与一组各种意见进行比较时，HyEnA在高覆盖率和准确率方面优于最先进的自动化方法，证实了人类洞察的必要性。另一方面，HyEnA需要较少的人力工作量，且不会牺牲质量。

    arXiv:2403.09713v1 Announce Type: new  Abstract: Large-scale survey tools enable the collection of citizen feedback in opinion corpora. Extracting the key arguments from a large and noisy set of opinions helps in understanding the opinions quickly and accurately. Fully automated methods can extract arguments but (1) require large labeled datasets that induce large annotation costs and (2) work well for known viewpoints, but not for novel points of view. We propose HyEnA, a hybrid (human + AI) method for extracting arguments from opinionated texts, combining the speed of automated processing with the understanding and reasoning capabilities of humans. We evaluate HyEnA on three citizen feedback corpora. We find that, on the one hand, HyEnA achieves higher coverage and precision than a state-of-the-art automated method when compared to a common set of diverse opinions, justifying the need for human insight. On the other hand, HyEnA requires less human effort and does not compromise quali
    
[^117]: 一种用于问答的知识注入课程预训练框架

    A Knowledge-Injected Curriculum Pretraining Framework for Question Answering

    [https://arxiv.org/abs/2403.09712](https://arxiv.org/abs/2403.09712)

    提出了一种通用的知识注入课程预训练框架（KICP），用于实现全面的知识图谱学习和利用以解决KBQA任务。

    

    知识注入问答（KBQA）是自然语言处理研究中的一个关键任务，也是一种访问网络数据和知识的方法，需要利用知识图谱（KG）进行推理。本文提出了一种通用的知识注入课程预训练框架（KICP），旨在实现对KBQA任务的全面KG学习和利用。

    arXiv:2403.09712v1 Announce Type: cross  Abstract: Knowledge-based question answering (KBQA) is a key task in NLP research, and also an approach to access the web data and knowledge, which requires exploiting knowledge graphs (KGs) for reasoning. In the literature, one promising solution for KBQA is to incorporate the pretrained language model (LM) with KGs by generating KG-centered pretraining corpus, which has shown its superiority. However, these methods often depend on specific techniques and resources to work, which may not always be available and restrict its application. Moreover, existing methods focus more on improving language understanding with KGs, while neglect the more important human-like complex reasoning. To this end, in this paper, we propose a general Knowledge-Injected Curriculum Pretraining framework (KICP) to achieve comprehensive KG learning and exploitation for KBQA tasks, which is composed of knowledge injection (KI), knowledge adaptation (KA) and curriculum re
    
[^118]: 复杂文本到SQL的Schema-Aware多任务学习

    Schema-Aware Multi-Task Learning for Complex Text-to-SQL

    [https://arxiv.org/abs/2403.09706](https://arxiv.org/abs/2403.09706)

    提出了一个适用于复杂SQL查询的schema-aware多任务学习框架，通过设计schema链接鉴别器和定义6种关系类型来解决文本到SQL解析中的挑战。

    

    传统的文本到SQL解析器在合成涉及多个表或列的复杂SQL查询时表现不佳，这是因为识别正确的schema项和在问题与schema项之间进行准确对齐的挑战固有。为解决上述问题，我们提出了一个针对复杂SQL查询的schema-aware多任务学习框架（称为MTSQL）。具体来说，我们设计了一个schema链接鉴别器模块来区分有效的问题-schema链接，通过独特的链接关系明确指导编码器以增强对齐质量。在解码器方面，我们定义了6种类型的关系来描述表和列之间的连接（例如，WHERE_TC），并引入了以操作符为中心的三元提取器来识别那些与预定义关系相关的schema项。此外，我们通过预测的三元组建立了一组语法约束规则集，以过滤。

    arXiv:2403.09706v1 Announce Type: cross  Abstract: Conventional text-to-SQL parsers are not good at synthesizing complex SQL queries that involve multiple tables or columns, due to the challenges inherent in identifying the correct schema items and performing accurate alignment between question and schema items. To address the above issue, we present a schema-aware multi-task learning framework (named MTSQL) for complicated SQL queries. Specifically, we design a schema linking discriminator module to distinguish the valid question-schema linkings, which explicitly instructs the encoder by distinctive linking relations to enhance the alignment quality. On the decoder side, we define 6-type relationships to describe the connections between tables and columns (e.g., WHERE_TC), and introduce an operator-centric triple extractor to recognize those associated schema items with the predefined relationship. Also, we establish a rule set of grammar constraints via the predicted triples to filte
    
[^119]: 一种针对大型语言模型在心理健康领域的新颖细致对话评估框架

    A Novel Nuanced Conversation Evaluation Framework for Large Language Models in Mental Health

    [https://arxiv.org/abs/2403.09705](https://arxiv.org/abs/2403.09705)

    提出了一种用于评估大型语言模型在心理健康领域微妙对话能力的新框架，并展示GPT4 Turbo可以与已验证的治疗师表现出更相似的结果。

    

    了解大型语言模型（LLMs）的对话能力可以帮助其更谨慎和适当地部署，对于像心理健康这样的安全关键领域尤为重要，其中某人的生命可能取决于对紧急问题回复的确切措辞。本文提出了一种评估LLMs微妙对话能力的新型框架。在其中，我们从心理治疗对话分析文献中发展了一系列定量指标。虽然我们确保我们的框架和指标可供研究人员转移到相关邻域，我们将它们应用到心理健康领域。我们使用我们的框架通过验证的心理健康数据集评估了几种流行的前沿LLMs模型，包括一些GPT和Llama模型。我们的结果显示，GPT4 Turbo在表现上与已验证的治疗师相比与其他模型更为相似。

    arXiv:2403.09705v1 Announce Type: cross  Abstract: Understanding the conversation abilities of Large Language Models (LLMs) can help lead to its more cautious and appropriate deployment. This is especially important for safety-critical domains like mental health, where someone's life may depend on the exact wording of a response to an urgent question. In this paper, we propose a novel framework for evaluating the nuanced conversation abilities of LLMs. Within it, we develop a series of quantitative metrics developed from literature on using psychotherapy conversation analysis literature. While we ensure that our framework and metrics are transferable by researchers to relevant adjacent domains, we apply them to the mental health field. We use our framework to evaluate several popular frontier LLMs, including some GPT and Llama models, through a verified mental health dataset. Our results show that GPT4 Turbo can perform significantly more similarly to verified therapists than other sel
    
[^120]: 对齐大型语言模型至特定情境规范的 Alignment Studio

    Alignment Studio: Aligning Large Language Models to Particular Contextual Regulations

    [https://arxiv.org/abs/2403.09704](https://arxiv.org/abs/2403.09704)

    本文提出了 Alignment Studio 架构，使应用开发者能够调整大型语言模型至他们特定的价值观、社会规范、法律和其他法规，并协调潜在冲突的需求。

    

    大型语言模型的对齐通常由模型提供者进行，以添加或控制跨用例和情境中通用或普遍理解的行为。相比之下，本文提出了一种方法和架构，赋予应用开发者调整模型至其特定价值观、社会规范、法律和其他法规的能力，并在情境中协调潜在冲突的需求。我们阐述了这种对齐工作室架构的三个主要组成部分：构架者、指导者和审核者共同作用于控制语言模型的行为。我们通过一个企业内部聊天机器人对齐到业务行为准则的实例来说明这种方法。

    arXiv:2403.09704v1 Announce Type: cross  Abstract: The alignment of large language models is usually done by model providers to add or control behaviors that are common or universally understood across use cases and contexts. In contrast, in this article, we present an approach and architecture that empowers application developers to tune a model to their particular values, social norms, laws and other regulations, and orchestrate between potentially conflicting requirements in context. We lay out three main components of such an Alignment Studio architecture: Framers, Instructors, and Auditors that work in concert to control the behavior of a language model. We illustrate this approach with a running example of aligning a company's internal-facing enterprise chatbot to its business conduct guidelines.
    
[^121]: 概念感知数据构建提升语言模型的上下文学习

    Concept-aware Data Construction Improves In-context Learning of Language Models

    [https://arxiv.org/abs/2403.09703](https://arxiv.org/abs/2403.09703)

    该研究提出了概念感知训练（CoAT）框架，用于构建训练场景，让语言模型从演示中学习利用类比推理概念，并发现通过使用CoAT，预训练的transformers可以更好地利用演示中的新潜在概念，使得上下文学习对函数变换更加 robust。

    

    许多最近的语言模型（LMs）能够进行上下文学习（ICL），表现为LMs能够仅通过自然语言指令执行新任务的能力。先前有关策划上下文学习者的工作假定ICL是由于巨大的过参数化或多任务训练规模导致的。然而，最近的理论工作将ICL能力归因于概念相关的训练数据，并在小规模、合成环境中创建了功能型上下文学习者。

    arXiv:2403.09703v1 Announce Type: cross  Abstract: Many recent language models (LMs) are capable of in-context learning (ICL), manifested in the LMs' ability to perform a new task solely from natural-language instruction. Previous work curating in-context learners assumes that ICL emerges from a vast over-parametrization or the scale of multi-task training. However, recent theoretical work attributes the ICL ability to concept-dependent training data and creates functional in-context learners even in small-scale, synthetic settings.   In this work, we practically explore this newly identified axis of ICL quality. We propose Concept-aware Training (CoAT), a framework for constructing training scenarios that make it beneficial for the LM to learn to utilize the analogical reasoning concepts from demonstrations. We find that by using CoAT, pre-trained transformers can learn to better utilise new latent concepts from demonstrations and that such ability makes ICL more robust to the functio
    
[^122]: Shapley Values 驱动的用于GenAI生成内容的公平奖励分配框架

    Shapley Values-Powered Framework for Fair Reward Split in Content Produced by GenAI

    [https://arxiv.org/abs/2403.09700](https://arxiv.org/abs/2403.09700)

    提出了一种利用Shapley Values量化艺术家对生成模型所做贡献的方法，以实现模型开发者和数据提供者之间合作的公平分配。

    

    明显的是，当前，生成模型在质量上被人类专业人士超越。然而，随着人工智能的进步，这种差距将会缩小，导致那些投入了多年时间来掌握一项技能的个体因其高昂成本而变得过时，这种成本与他们完成任务所需的时间紧密相连 -- 一项人工智能可以在几分钟或几秒钟内完成的任务。为了避免未来的社会动荡，我们必须即刻思考如何公平评估这些个体在训练生成模型中的贡献，并如何补偿他们由此而导致的收入减少或完全丧失。在这项工作中，我们提出了一种方法来构建模型开发者和数据提供者之间的合作关系。为了实现这一目标，我们利用Shapley Values来量化Stable Diffusion-v1.5模型生成的图像中艺术家的贡献，并公平地对待他们。

    arXiv:2403.09700v1 Announce Type: cross  Abstract: It is evident that, currently, generative models are surpassed in quality by human professionals. However, with the advancements in Artificial Intelligence, this gap will narrow, leading to scenarios where individuals who have dedicated years of their lives to mastering a skill become obsolete due to their high costs, which are inherently linked to the time they require to complete a task -- a task that AI could accomplish in minutes or seconds. To avoid future social upheavals, we must, even now, contemplate how to fairly assess the contributions of such individuals in training generative models and how to compensate them for the reduction or complete loss of their incomes. In this work, we propose a method to structure collaboration between model developers and data providers. To achieve this, we employ Shapley Values to quantify the contribution of artist(s) in an image generated by the Stable Diffusion-v1.5 model and to equitably a
    
[^123]: 预排序Tsetlin机器（基因K-Medoid方法）

    Pre-Sorted Tsetlin Machine (The Genetic K-Medoid Method)

    [https://arxiv.org/abs/2403.09680](https://arxiv.org/abs/2403.09680)

    该论文提出了一种利用Tsetlin Machines进行传统监督学习的机器学习预排序阶段方法，在MNIST级别的分类问题上取得了显著的精度提升，以及训练时间和推理时间大幅度减少。

    

    本文提出了一种利用Tsetlin Machines进行传统监督学习的机器学习预排序阶段。首先，利用快速遗传算法从数据集中确定N个数据点，以解决最大离散化问题。然后，这些被用作运行K-Medoid聚类算法的初始放置。最后，利用快速遗传算法通过最大化汉明距离来对齐N个独立的Tsetlin Machines。对于MNIST级别的分类问题，结果显示准确度提高了高达10％，训练时间减少了约383倍，推理时间减少了约86倍。

    arXiv:2403.09680v1 Announce Type: cross  Abstract: This paper proposes a machine learning pre-sort stage to traditional supervised learning using Tsetlin Machines. Initially, N data-points are identified from the dataset using an expedited genetic algorithm to solve the maximum dispersion problem. These are then used as the initial placement to run the K-Medoid clustering algorithm. Finally, an expedited genetic algorithm is used to align N independent Tsetlin Machines by maximising hamming distance. For MNIST level classification problems, results demonstrate up to 10% improvement in accuracy, approx. 383X reduction in training time and approx. 86X reduction in inference time.
    
[^124]: 揭开AI的阴影：探究大型语言模型的欺骗能力

    Unmasking the Shadows of AI: Investigating Deceptive Capabilities in Large Language Models

    [https://arxiv.org/abs/2403.09676](https://arxiv.org/abs/2403.09676)

    该研究探讨了大型语言模型的欺骗行为并分类讨论其引发的社会影响和风险。

    

    这项研究对人工智能欺骗的复杂领域进行了批判性导航，集中研究了大型语言模型（LLMs）的欺骗行为。作者的目标是阐明这一问题，审视围绕它的讨论，随后深入其分类和后果。文章从评估2033年AI安全峰会（ASS），以及LLMs的介绍开始，强调了潜在导致它们欺骗行为的多维偏见。文献综述涵盖了四种分类的欺骗：战略欺骗、模仿、谄媚和不忠推理，以及它们所带来的社会影响和风险。最后，作者对与应对欺骗AI的持久挑战相关的各个方面采取了评估立场。这包括考虑国际协作治理、个人与AI重新构建的互动，提出实际调整的建议。

    arXiv:2403.09676v1 Announce Type: cross  Abstract: This research critically navigates the intricate landscape of AI deception, concentrating on deceptive behaviours of Large Language Models (LLMs). My objective is to elucidate this issue, examine the discourse surrounding it, and subsequently delve into its categorization and ramifications. The essay initiates with an evaluation of the AI Safety Summit 2023 (ASS) and introduction of LLMs, emphasising multidimensional biases that underlie their deceptive behaviours.The literature review covers four types of deception categorised: Strategic deception, Imitation, Sycophancy, and Unfaithful Reasoning, along with the social implications and risks they entail. Lastly, I take an evaluative stance on various aspects related to navigating the persistent challenges of the deceptive AI. This encompasses considerations of international collaborative governance, the reconfigured engagement of individuals with AI, proposal of practical adjustments, 
    
[^125]: FoldToken：通过矢量量化及更多方法学习蛋白质语言

    FoldToken: Learning Protein Language via Vector Quantization and Beyond

    [https://arxiv.org/abs/2403.09673](https://arxiv.org/abs/2403.09673)

    通过将蛋白质序列和结构表示为离散符号，并创建新的蛋白质语言，从而构建了一种用于序列-结构共生产的创新方法。

    

    是否存在一种同时描述蛋白质序列和结构的外语？由于连续3D点表示的蛋白质结构与离散序列的对比建模方式，长期以来一直存在挑战。我们引入了\textbf{FoldTokenizer}，将蛋白质序列-结构表示为离散符号。这种创新方法涉及将残基类型和结构投射到一个离散空间中，通过一个信息保存的重构损失进行指导。我们将学习到的离散符号称为\textbf{FoldToken}，而FoldTokens的序列则成为一种新的蛋白质语言，将蛋白质序列-结构转化为一种统一的形态。我们将创建的蛋白质语言应用于普通主干修补和抗体设计任务，构建了首个GPT风格模型(\textbf{FoldGPT})用于具有良好结果的序列-结构共生产。我们成功的关键在于显著的增强

    arXiv:2403.09673v1 Announce Type: cross  Abstract: Is there a foreign language describing protein sequences and structures simultaneously? Protein structures, represented by continuous 3D points, have long posed a challenge due to the contrasting modeling paradigms of discrete sequences. We introduce \textbf{FoldTokenizer} to represent protein sequence-structure as discrete symbols. This innovative approach involves projecting residue types and structures into a discrete space, guided by a reconstruction loss for information preservation. We refer to the learned discrete symbols as \textbf{FoldToken}, and the sequence of FoldTokens serves as a new protein language, transforming the protein sequence-structure into a unified modality. We apply the created protein language on general backbone inpainting and antibody design tasks, building the first GPT-style model (\textbf{FoldGPT}) for sequence-structure co-generation with promising results. Key to our success is the substantial enhancem
    
[^126]: CoRaiS: 轻量级多边协作计算实时调度器

    CoRaiS: Lightweight Real-Time Scheduler for Multi-Edge Cooperative Computing

    [https://arxiv.org/abs/2403.09671](https://arxiv.org/abs/2403.09671)

    提出了一种基于系统级状态评估模型和整数线性规划模型的多边协作计算实时调度器 CoRaiS，以优化分发分布到达的请求，提高多边系统的协作效率。

    

    多边协作计算将多个边缘的受限资源合并为一个强大的资源池，具有提供巨大计算能力、改进响应时间和更多样化服务等潜力带来巨大好处。然而，大量异构资源组成和缺乏调度策略使得多边计算系统的建模和协作变得特别复杂。本文首先提出了一个系统级状态评估模型，用于保护复杂的硬件配置并重新定义异构边缘的不同服务能力。其次，设计了一个整数线性规划模型，以便最优地调度分布式到达的请求。最后，提出了一个基于学习的轻量级实时调度器 CoRaiS。CoRaiS嵌入了多边系统的实时状态和请求信息，并将这些嵌入与策略网络相结合。

    arXiv:2403.09671v1 Announce Type: cross  Abstract: Multi-edge cooperative computing that combines constrained resources of multiple edges into a powerful resource pool has the potential to deliver great benefits, such as a tremendous computing power, improved response time, more diversified services. However, the mass heterogeneous resources composition and lack of scheduling strategies make the modeling and cooperating of multi-edge computing system particularly complicated. This paper first proposes a system-level state evaluation model to shield the complex hardware configurations and redefine the different service capabilities at heterogeneous edges. Secondly, an integer linear programming model is designed to cater for optimally dispatching the distributed arriving requests. Finally, a learning-based lightweight real-time scheduler, CoRaiS, is proposed. CoRaiS embeds the real-time states of multi-edge system and requests information, and combines the embeddings with a policy netwo
    
[^127]: STREAM：用于视频生成模型的时空评估和分析度量

    STREAM: Spatio-TempoRal Evaluation and Analysis Metric for Video Generative Models

    [https://arxiv.org/abs/2403.09669](https://arxiv.org/abs/2403.09669)

    提出了STREAM，一种新的视频评估度量方法，弥补了当前视频生成模型评估中对于时空特性的不足

    

    图像生成模型在生成逼真多样的图像方面取得了显著进展，得益于各种评估度量的全面指导。然而，当前的视频生成模型在生成短视频片段时仍然存在困难，缺乏提供改进见解的工具。目前的视频评估度量方法是通过将嵌入视频嵌入网络来简单调整图像度量方法而得到的，这可能低估了视频的独特特性。我们的分析表明，广泛使用的Frechet Video Distance (FVD) 在空间方面的重视程度要大于视频的时间自然性，且受到所使用的嵌入网络输入大小的限制，仅限于16帧视频。此外，它表现出相当大的不稳定性，并与人类评估存在差异。为了解决这些限制，我们提出了STREAM，一种新的视频评估度量方法，独特地设计以解决当前视频生成模型评估的挑战。

    arXiv:2403.09669v1 Announce Type: cross  Abstract: Image generative models have made significant progress in generating realistic and diverse images, supported by comprehensive guidance from various evaluation metrics. However, current video generative models struggle to generate even short video clips, with limited tools that provide insights for improvements. Current video evaluation metrics are simple adaptations of image metrics by switching the embeddings with video embedding networks, which may underestimate the unique characteristics of video. Our analysis reveals that the widely used Frechet Video Distance (FVD) has a stronger emphasis on the spatial aspect than the temporal naturalness of video and is inherently constrained by the input size of the embedding networks used, limiting it to 16 frames. Additionally, it demonstrates considerable instability and diverges from human evaluations. To address the limitations, we propose STREAM, a new video evaluation metric uniquely des
    
[^128]: 通过定性场景理解和解释实现可信自动驾驶

    Trustworthy Automated Driving through Qualitative Scene Understanding and Explanations

    [https://arxiv.org/abs/2403.09668](https://arxiv.org/abs/2403.09668)

    我们提出了定性可解释图（QXG），通过将时空图和定性约束应用于传感器数据，能够实现在自动驾驶过程中对场景进行理解和解释，为实时决策提供可靠的场景模型。

    

    我们提出了定性可解释图（QXG）：一种统一的符号和定性表示，用于城市移动中的场景理解。QXG利用时空图和定性约束从原始传感器输入（如LiDAR和摄像头数据）中提取场景语义，提供了可解释的场景模型。关键的是，QXG可以在实时中进行增量构建，使其成为一种多功能工具，可用于车内解释和各种传感器类型的实时决策。我们的研究展示了QXG的变革潜力，特别是在自动驾驶领域，它通过将图与车辆动作联系起来，阐明了决策原理。这些解释服务于多种目的，从向乘客提供信息到警示弱势道路使用者（VRUs），再到实现事后分析。

    arXiv:2403.09668v1 Announce Type: cross  Abstract: We present the Qualitative Explainable Graph (QXG): a unified symbolic and qualitative representation for scene understanding in urban mobility. QXG enables the interpretation of an automated vehicle's environment using sensor data and machine learning models. It leverages spatio-temporal graphs and qualitative constraints to extract scene semantics from raw sensor inputs, such as LiDAR and camera data, offering an intelligible scene model. Crucially, QXG can be incrementally constructed in real-time, making it a versatile tool for in-vehicle explanations and real-time decision-making across various sensor types. Our research showcases the transformative potential of QXG, particularly in the context of automated driving, where it elucidates decision rationales by linking the graph with vehicle actions. These explanations serve diverse purposes, from informing passengers and alerting vulnerable road users (VRUs) to enabling post-analysi
    
[^129]: 关于无监督图像到图像转换和GAN稳定性

    On Unsupervised Image-to-image translation and GAN stability

    [https://arxiv.org/abs/2403.09646](https://arxiv.org/abs/2403.09646)

    本文研究了图像到图像转换中一个经典工作CycleGAN的一些失败案例，并假设这些失败与GAN的稳定性有关。

    

    图像到图像转换的问题既有趣又具有挑战性，因为它对其他计算机视觉应用（如着色、修补、分割等）具有潜在的影响。在完全无监督（非配对）的情况下，需要高度复杂的技术从一个领域中提取模式并成功应用到另一个领域，近年来，这个问题引起了广泛关注。这是其中一个首次成功应用于深度生成模型的问题，尤其是生成对抗网络，取得了实际影响而非仅仅是理论实力展示的惊人结果，这种结果主导了GAN的世界。在这项工作中，我们研究了该领域的一个经典工作CycleGAN [1] 的一些失败案例，并假设这些失败与GAN的稳定性有关。

    arXiv:2403.09646v1 Announce Type: cross  Abstract: The problem of image-to-image translation is one that is intruiging and challenging at the same time, for the impact potential it can have on a wide variety of other computer vision applications like colorization, inpainting, segmentation and others. Given the high-level of sophistication needed to extract patterns from one domain and successfully applying them to another, especially, in a completely unsupervised (unpaired) manner, this problem has gained much attention as of the last few years. It is one of the first problems where successful applications to deep generative models, and especially Generative Adversarial Networks achieved astounding results that are actually of realworld impact, rather than just a show of theoretical prowess; the such that has been dominating the GAN world. In this work, we study some of the failure cases of a seminal work in the field, CycleGAN [1] and hypothesize that they are GAN-stability related, a
    
[^130]: API保护的LLMs的标志泄露专有信息

    Logits of API-Protected LLMs Leak Proprietary Information

    [https://arxiv.org/abs/2403.09539](https://arxiv.org/abs/2403.09539)

    大多数现代LLM受到softmax瓶颈影响，可以以较低成本获取API保护的LLM的非公开信息和解锁多种功能

    

    大型语言模型（LLMs）的商业化导致了高级API-only接入专有模型的常见实践。在这项工作中，我们展示了即使对于模型架构有保守的假设，也可以从相对较少的API查询中学习关于API保护的LLM的大量非公开信息（例如，使用OpenAI的gpt-3.5-turbo仅花费不到1000美元）。我们的发现集中在一个关键观察上：大多数现代LLM受到了softmax瓶颈的影响，这限制了模型输出到完整输出空间的线性子空间。我们表明，这导致了一个模型图像或模型签名，从而以较低的成本解锁了几种功能：有效发现LLM的隐藏大小，获取完整词汇输出，检测和消除不同模型更新，识别给定单个完整LLM输出的源LLM，以及...

    arXiv:2403.09539v1 Announce Type: cross  Abstract: The commercialization of large language models (LLMs) has led to the common practice of high-level API-only access to proprietary models. In this work, we show that even with a conservative assumption about the model architecture, it is possible to learn a surprisingly large amount of non-public information about an API-protected LLM from a relatively small number of API queries (e.g., costing under $1,000 for OpenAI's gpt-3.5-turbo). Our findings are centered on one key observation: most modern LLMs suffer from a softmax bottleneck, which restricts the model outputs to a linear subspace of the full output space. We show that this lends itself to a model image or a model signature which unlocks several capabilities with affordable cost: efficiently discovering the LLM's hidden size, obtaining full-vocabulary outputs, detecting and disambiguating different model updates, identifying the source LLM given a single full LLM output, and eve
    
[^131]: 基于分层轨迹表示的船舶行为预测聚类

    Predictive Clustering of Vessel Behavior Based on Hierarchical Trajectory Representation

    [https://arxiv.org/abs/2403.08838](https://arxiv.org/abs/2403.08838)

    提出了一种基于分层轨迹表示的船舶行为预测聚类方法，通过使用预测聚类和潜在编码，可以同时改善聚类和预测，并在实验证明其相对于现有方法的优越性。

    

    船舶轨迹聚类旨在寻找相似的轨迹模式，在海上应用中被广泛应用。大多数传统方法使用预定义的规则和阈值来识别离散的船舶行为，但存在无法表示演变过程的问题。为解决这一问题，本文提出了一种基于分层船舶行为预测聚类（PC-HiV）的方法。PC-HiV首先使用分层表示将每条轨迹转换为行为序列，然后基于这些表示在每个时间戳预测演化。通过应用预测聚类和潜在编码，PC-HiV可以同时改善聚类和预测。在真实AIS数据集上的实验证明了PC-HiV相对于现有方法的优越性，展示了其在捕捉船舶行为模式方面的有效性。

    arXiv:2403.08838v1 Announce Type: cross  Abstract: Vessel trajectory clustering, which aims to find similar trajectory patterns, has been widely leveraged in overwater applications. Most traditional methods use predefined rules and thresholds to identify discrete vessel behaviors. They aim for high-quality clustering and conduct clustering on entire sequences, whether the original trajectory or its sub-trajectories, failing to represent their evolution. To resolve this problem, we propose a Predictive Clustering of Hierarchical Vessel Behavior (PC-HiV). PC-HiV first uses hierarchical representations to transform every trajectory into a behavioral sequence. Then, it predicts evolution at each timestamp of the sequence based on the representations. By applying predictive clustering and latent encoding, PC-HiV improves clustering and predictions simultaneously. Experiments on real AIS datasets demonstrate PC-HiV's superiority over existing methods, showcasing its effectiveness in capturin
    
[^132]: 通过融合高度专业化语言模型同时掌握文本、代码和数学

    Mastering Text, Code and Math Simultaneously via Fusing Highly Specialized Language Models

    [https://arxiv.org/abs/2403.08281](https://arxiv.org/abs/2403.08281)

    通过融合高度专业化的语言、代码和数学模型，提出了一种名为UltraFuser的融合框架，引入了标记级别的门控机制，并设计了两阶段训练策略，以同时在三个领域取得高性能。

    

    自然语言、编程代码和数学符号的底层数据分布变化巨大，对于那些努力同时在三个领域实现高性能的大型语言模型（LLMs）提出了复杂挑战。本文提出了一种直接融合已经高度专业化模型的方法。所提出的融合框架UltraFuser包括三个已经在语言、编码和数学上得到充分训练的专家。引入了一个标记级别的门控机制来混合专家的输出。设计了一个伴随平衡采样的两阶段训练策略以确保稳定性。为了有效训练融合模型，我们进一步构建了一个

    arXiv:2403.08281v1 Announce Type: cross  Abstract: Underlying data distributions of natural language, programming code, and mathematical symbols vary vastly, presenting a complex challenge for large language models (LLMs) that strive to achieve high performance across all three domains simultaneously. Achieving a very high level of proficiency for an LLM within a specific domain often requires extensive training with relevant corpora, which is typically accompanied by a sacrifice in performance in other domains. In this paper, we propose to fuse models that are already highly-specialized directly. The proposed fusing framework, UltraFuser, consists of three distinct specialists that are already sufficiently trained on language, coding, and mathematics. A token-level gating mechanism is introduced to blend the specialists' outputs. A two-stage training strategy accompanied by balanced sampling is designed to ensure stability. To effectively train the fused model, we further construct a 
    
[^133]: 使用可解释人工智能的高光谱图像分析红队建模

    Red Teaming Models for Hyperspectral Image Analysis Using Explainable AI

    [https://arxiv.org/abs/2403.08017](https://arxiv.org/abs/2403.08017)

    本文介绍了一种使用可解释人工智能的红队建模方法，用于检验高光谱图像上的机器学习模型，并成功构建出一个只使用1%的输入特征即可达到可比较性能的模型。

    

    遥感领域要求可靠、稳健且经过质量保证的机器学习模型，使得红队成为识别和暴露潜在缺陷和偏见的重要方法。本文介绍了一种方法论，用于检查在HYPERVIEW挑战赛中运行在高光谱图像上的机器学习模型，重点关注土壤参数的估计。我们使用可解释人工智能（XAI）领域的事后解释方法，对赢得HYPERVIEW挑战赛并作为INTUITION-1高光谱任务上部署模型灵感的表现最佳模型进行批判性评估。我们的方法通过指出和验证关键缺陷，构建出一个只使用1%的输入特征即可达到可比较性能的模型。

    arXiv:2403.08017v1 Announce Type: cross  Abstract: Remote sensing (RS) applications in the space domain demand machine learning (ML) models that are reliable, robust, and quality-assured, making red teaming a vital approach for identifying and exposing potential flaws and biases. Since both fields advance independently, there is a notable gap in integrating red teaming strategies into RS. This paper introduces a methodology for examining ML models operating on hyperspectral images within the HYPERVIEW challenge, focusing on soil parameters' estimation. We use post-hoc explanation methods from the Explainable AI (XAI) domain to critically assess the best performing model that won the HYPERVIEW challenge and served as an inspiration for the model deployed on board the INTUITION-1 hyperspectral mission. Our approach effectively red teams the model by pinpointing and validating key shortcomings, constructing a model that achieves comparable performance using just 1% of the input features a
    
[^134]: 站在FURM基础上-评估医疗系统中公平、有用和可靠AI模型的框架

    Standing on FURM ground -- A framework for evaluating Fair, Useful, and Reliable AI Models in healthcare systems

    [https://arxiv.org/abs/2403.07911](https://arxiv.org/abs/2403.07911)

    开发了一种机制来评估医疗系统中的公平、有用和可靠AI模型，弥合AI模型开发与实际受益之间的鸿沟。

    

    使用人工智能（AI）指导患者护理或操作流程的影响取决于AI模型的输出、基于该输出的决策协议以及相关利益相关者采取必要后续行动的能力。在部署前估计这种相互作用的影响，并在部署后实时研究它，对于弥合AI模型开发与可实现利益之间的鸿沟至关重要。为了实现这一点，斯坦福医疗保健的数据科学团队开发了一种机制，通过进行伦理审查以识别潜在的价值不匹配、仿真估算有用性、财务预测评估可持续性，以及分析确定IT可行性、设计部署策略，并建议前瞻性监测和评估计划来识别公平、有用和可靠的AI模型（FURM）。我们报告了对FURM评估进行的评估。

    arXiv:2403.07911v1 Announce Type: cross  Abstract: The impact of using artificial intelligence (AI) to guide patient care or operational processes is an interplay of the AI model's output, the decision-making protocol based on that output, and the capacity of the stakeholders involved to take the necessary subsequent action. Estimating the effects of this interplay before deployment, and studying it in real time afterwards, are essential to bridge the chasm between AI model development and achievable benefit. To accomplish this, the Data Science team at Stanford Health Care has developed a mechanism to identify fair, useful and reliable AI models (FURM) by conducting an ethical review to identify potential value mismatches, simulations to estimate usefulness, financial projections to assess sustainability, as well as analyses to determine IT feasibility, design a deployment strategy, and recommend a prospective monitoring and evaluation plan. We report on FURM assessments done to evalu
    
[^135]: 将竞争转化为合作：多Agent系统和语言模型在现代组织中的革命性作用

    Transforming Competition into Collaboration: The Revolutionary Role of Multi-Agent Systems and Language Models in Modern Organizations

    [https://arxiv.org/abs/2403.07769](https://arxiv.org/abs/2403.07769)

    文章探讨了基于多Agent系统理论结合大型语言模型的计算实体对人类互动的革新影响，提出了一种可能将专门人工代理支持扩展到操作性组织流程和基于知识和人类编排的战略决策的方式。

    

    这篇文章探讨了基于多Agent系统理论（SMA）结合大型语言模型（LLM）的计算实体的动态影响，其特点是能够模拟复杂的人类互动，作为一种革新人类用户交互的可能性，从利用专门的人工代理支持从操作组织流程到基于应用知识和人的编排的战略决策。 先前的调查显示，在处理新挑战和实用任务（如引发逻辑推理和问题解决）时，特别是在人工代理的自主方法方面存在限制。 还考虑到，传统技术，如激发思想链，需要明确的人类指导。 在我们的方法中，我们使用从大型语言模型（LLM）开发的代理，每个代理都有不同

    arXiv:2403.07769v1 Announce Type: new  Abstract: This article explores the dynamic influence of computational entities based on multi-agent systems theory (SMA) combined with large language models (LLM), which are characterized by their ability to simulate complex human interactions, as a possibility to revolutionize human user interaction from the use of specialized artificial agents to support everything from operational organizational processes to strategic decision making based on applied knowledge and human orchestration. Previous investigations reveal that there are limitations, particularly in the autonomous approach of artificial agents, especially when dealing with new challenges and pragmatic tasks such as inducing logical reasoning and problem solving. It is also considered that traditional techniques, such as the stimulation of chains of thoughts, require explicit human guidance. In our approach we employ agents developed from large language models (LLM), each with distinct
    
[^136]: 使用多步深度强化学习改进血糖控制策略

    An Improved Strategy for Blood Glucose Control Using Multi-Step Deep Reinforcement Learning

    [https://arxiv.org/abs/2403.07566](https://arxiv.org/abs/2403.07566)

    本文提出了一种使用多步深度强化学习改进血糖控制策略的算法，通过转换BG控制问题的形式化，考虑药物作用的延迟和持久性，提高了效率。

    

    血糖（BG）控制涉及通过体外胰岛素注射将个体的血糖维持在健康范围内，这对于1型糖尿病患者来说是一项重要任务。然而，传统的患者自我管理方式繁琐且危险。最近的研究致力于探索个性化和自动化的BG控制方法，其中深度强化学习（DRL）显示出作为新兴方法的潜力。在本文中，我们使用药物浓度的指数衰减模型将BG控制问题的形式化转换为MDP，考虑到药物作用的延迟和持久性，从PAE-POMDP（持续行动效果-部分可见马尔可夫决策过程）到MDP，并提出一种新颖的基于多步DRL的算法来解决该问题。其中还使用了优先经验回放（PER）采样方法。与单步自举更新相比，多步学习

    arXiv:2403.07566v1 Announce Type: new  Abstract: Blood Glucose (BG) control involves keeping an individual's BG within a healthy range through extracorporeal insulin injections is an important task for people with type 1 diabetes. However,traditional patient self-management is cumbersome and risky. Recent research has been devoted to exploring individualized and automated BG control approaches, among which Deep Reinforcement Learning (DRL) shows potential as an emerging approach. In this paper, we use an exponential decay model of drug concentration to convert the formalization of the BG control problem, which takes into account the delay and prolongedness of drug effects, from a PAE-POMDP (Prolonged Action Effect-Partially Observable Markov Decision Process) to a MDP, and we propose a novel multi-step DRL-based algorithm to solve the problem. The Prioritized Experience Replay (PER) sampling method is also used in it. Compared to single-step bootstrapped updates, multi-step learning is
    
[^137]: 优化大学计算机实验室人体工程学：一个关于人体测量、家具设计和ANOVA测试的研究

    Optimizing Computer Lab Ergonomics in Universities: A Study on Anthropometric Measurements, Furniture Design, and ANOVA Test

    [https://arxiv.org/abs/2403.05589](https://arxiv.org/abs/2403.05589)

    提出基于人体测量的家具尺寸适合大学生，以改善计算机实验室人体工程学，研究发现其与现有家具尺寸存在显著差异并更加兼容

    

    许多研究表明，人体工程学设计的家具能提高工作效率和身心健康。随着计算机成为学生学术生活的一部分，它们在未来将进一步普及。我们提出基于人体测量的家具尺寸，适合大学生以改善计算机实验室的人体工程学。我们收集了380名参与者的数据，分析了11项人体测量，并将它们与11项家具尺寸进行了相关性分析。研究了两种类型的家具：非可调椅子与非可调桌子，以及可调椅子与非可调桌子。不匹配计算显示家具尺寸与人体测量之间存在显著差异。显著水平为5%的单因素方差分析测试还显示了所提出的和现有的家具尺寸之间存在显著差异。发现所提出的尺寸更加兼容，减少了不匹配百分比。

    arXiv:2403.05589v1 Announce Type: cross  Abstract: Many studies have shown how ergonomically designed furniture improves productivity and well-being. As computers have become a part of students' academic lives, they will grow further in the future. We propose anthropometric-based furniture dimensions suitable for university students to improve computer laboratory ergonomics. We collected data from 380 participants and analyzed 11 anthropometric measurements, correlating them to 11 furniture dimensions. Two types of furniture were studied: a non-adjustable chair with a non-adjustable table and an adjustable chair with a non-adjustable table. The mismatch calculation showed a significant difference between furniture dimensions and anthropometric measurements. The one-way ANOVA test with a significance level of 5% also showed a significant difference between proposed and existing furniture dimensions. The proposed dimensions were found to be more compatible and reduced mismatch percentage
    
[^138]: 算法识别大脑网络因果充分性中的关键外源节点

    Algorithmic Identification of Essential Exogenous Nodes for Causal Sufficiency in Brain Networks

    [https://arxiv.org/abs/2403.05407](https://arxiv.org/abs/2403.05407)

    本研究提出了一种算法识别方法，用于在大脑网络中确定满足关键因果充分性需求的关键外源节点。

    

    在研究任何因果机制，如大脑的因果网络时，因果充分性的假设起着关键作用。明显地，忽视这一假设可能导致重大错误，这一事实在大脑网络的因果分析中经常被忽视。在本研究中，我们提出了一种算法识别方法，用于确定满足因果充分性的关键外源节点，以在此类研究中遵循它的关键需求。我们的方法包括三个主要步骤：首先，通过捕捉Peter-Clark (PC)算法的本质，我们对网络内的区域对以及对来自其他网络节点条件的相同对进行独立性检验。接下来，我们通过分析条件和无条件结果之间的差异，利用Kolmogorov-Smirnov检验来区分候选混杂因素。随后，我们利用非因子化可识别变量。

    arXiv:2403.05407v1 Announce Type: new  Abstract: In the investigation of any causal mechanisms, such as the brain's causal networks, the assumption of causal sufficiency plays a critical role. Notably, neglecting this assumption can result in significant errors, a fact that is often disregarded in the causal analysis of brain networks. In this study, we propose an algorithmic identification approach for determining essential exogenous nodes that satisfy the critical need for causal sufficiency to adhere to it in such inquiries. Our approach consists of three main steps: First, by capturing the essence of the Peter-Clark (PC) algorithm, we conduct independence tests for pairs of regions within a network, as well as for the same pairs conditioned on nodes from other networks. Next, we distinguish candidate confounders by analyzing the differences between the conditional and unconditional results, using the Kolmogorov-Smirnov test. Subsequently, we utilize Non-Factorized identifiable Vari
    
[^139]: DyRoNet：一种低秩适配器增强的动态路由网络，用于流媒体感知

    DyRoNet: A Low-Rank Adapter Enhanced Dynamic Routing Network for Streaming Perception

    [https://arxiv.org/abs/2403.05050](https://arxiv.org/abs/2403.05050)

    DyRoNet采用低秩动态路由并结合分支网络优化流媒体感知性能，为多种分支选择策略设定了新的性能标杆

    

    自主驾驶系统需要实时、准确的感知来应对复杂环境。为解决这一问题，我们引入了动态路由网络（DyRoNet），这是一个创新性的框架，采用低秩动态路由以增强流媒体感知。通过集成专门预训练的分支网络，针对各种环境条件进行微调，DyRoNet在延迟和精度之间取得了平衡。其核心特征是速度路由模块，智能地将输入数据引导到最适合的分支网络，优化性能。广泛的评估结果显示，DyRoNet有效地适应多种分支选择策略，为各种场景性能设定了新的标杆。DyRoNet不仅为流媒体感知建立了新的标杆，还为未来的工作提供了宝贵的工程洞见。有关更多项目信息，请访问 https://tastevision.github.io/DyRoNet/

    arXiv:2403.05050v1 Announce Type: cross  Abstract: Autonomous driving systems demand real-time, accurate perception to navigate complex environments. Addressing this, we introduce the Dynamic Router Network (DyRoNet), a framework that innovates with low-rank dynamic routing for enhanced streaming perception. By integrating specialized pre-trained branch networks, fine-tuned for various environmental conditions, DyRoNet achieves a balance between latency and precision. Its core feature, the speed router module, intelligently directs input data to the best-suited branch network, optimizing performance. The extensive evaluations reveal that DyRoNet adapts effectively to multiple branch selection strategies, setting a new benchmark in performance across a range of scenarios. DyRoNet not only establishes a new benchmark for streaming perception but also provides valuable engineering insights for future work. More project information is available at https://tastevision.github.io/DyRoNet/
    
[^140]: ObjectCompose: 评估基于视觉的模型在物体与背景组合变化上的韧性

    ObjectCompose: Evaluating Resilience of Vision-Based Models on Object-to-Background Compositional Changes

    [https://arxiv.org/abs/2403.04701](https://arxiv.org/abs/2403.04701)

    评估基于视觉的模型对于物体与背景之间多样化变化的鲁棒性，提出一种可以引入不同对象方面变化的方法

    

    由于最近基于视觉的模型进行了大规模多模态训练并具有泛化能力，了解它们的鲁棒性程度对于它们在现实世界中的部署至关重要。在本研究中，我们评估了当前基于视觉的模型针对不同的物体与背景上下文变化的韧性。大多数鲁棒性评估方法引入了合成数据集来诱导物体特征（视点、尺度、颜色）的变化，或者利用图像转换技术（对抗性变化、常见破坏）在真实图像上模拟分布的变化。最近的研究探索了利用大语言模型和扩散模型来生成背景的变化。但是，这些方法要么在提供对要进行的更改的控制方面不足，要么扭曲了物体的语义，使其不适用于任务。与之相反，我们的方法可以引入各种对象

    arXiv:2403.04701v1 Announce Type: cross  Abstract: Given the large-scale multi-modal training of recent vision-based models and their generalization capabilities, understanding the extent of their robustness is critical for their real-world deployment. In this work, we evaluate the resilience of current vision-based models against diverse object-to-background context variations. The majority of robustness evaluation methods have introduced synthetic datasets to induce changes to object characteristics (viewpoints, scale, color) or utilized image transformation techniques (adversarial changes, common corruptions) on real images to simulate shifts in distributions. Recent works have explored leveraging large language models and diffusion models to generate changes in the background. However, these methods either lack in offering control over the changes to be made or distort the object semantics, making them unsuitable for the task. Our method, on the other hand, can induce diverse objec
    
[^141]: TextMonkey：一种无需OCR的大型多模态模型，用于理解文档

    TextMonkey: An OCR-Free Large Multimodal Model for Understanding Document

    [https://arxiv.org/abs/2403.04473](https://arxiv.org/abs/2403.04473)

    该论文提出了一种针对文本中心任务的大型多模态模型，通过引入零初始化的Shifted Window Attention、相似性筛选标记等方式对模型进行增强，同时拓展了模型的能力以提高性能。

    

    我们提出了TextMonkey，一个专为文本中心任务定制的大型多模态模型（LMM），包括文档问答（DocVQA）和场景文本分析。我们的方法在多个方面进行了改进：通过采用零初始化的Shifted Window Attention，我们实现了更高输入分辨率的跨窗口连接并稳定了早期训练；我们假设图像可能包含冗余标记，通过使用相似性来筛选出重要标记，我们不仅可以优化标记长度，还可以提升模型性能。此外，通过扩展我们模型的能力以涵盖文本定位和定位，并将位置信息纳入响应中，我们提高了可解释性并减少了幻觉。此外，TextMonkey 可以微调以获得理解点击截图命令的能力。总体来看，我们的方法显著提高了性能。

    arXiv:2403.04473v1 Announce Type: cross  Abstract: We present TextMonkey, a large multimodal model (LMM) tailored for text-centric tasks, including document question answering (DocVQA) and scene text analysis. Our approach introduces enhancement across several dimensions: by adopting Shifted Window Attention with zero-initialization, we achieve cross-window connectivity at higher input resolutions and stabilize early training; We hypothesize that images may contain redundant tokens, and by using similarity to filter out significant tokens, we can not only streamline the token length but also enhance the model's performance. Moreover, by expanding our model's capabilities to encompass text spotting and grounding, and incorporating positional information into responses, we enhance interpretability and minimize hallucinations. Additionally, TextMonkey can be finetuned to gain the ability to comprehend commands for clicking screenshots. Overall, our method notably boosts performance across
    
[^142]: MKF-ADS：用于汽车的多知识融合异常检测系统

    MKF-ADS: A Multi-Knowledge Fused Anomaly Detection System for Automotive

    [https://arxiv.org/abs/2403.04293](https://arxiv.org/abs/2403.04293)

    提出了一种新颖的多知识融合异常检测系统MKF-ADS，采用STcAM和PatchST模块，旨在提高IDS在CAN总线漏洞中的安全性和降低误报警。

    

    具有智能交通系统（ITSs）对车辆电子控制单元（ECUs）与外部世界广泛连接的需求，安全性和安全性已成为严峻问题。 入侵检测系统（IDSs）在解决控制区域网络（CAN）总线漏洞方面是一个关键的安全组件。 但是，基于监督的IDS无法识别复杂攻击，基于异常的IDS由于能力瓶颈而产生更高的误报警。 在本文中，我们提出了一种新颖的多知识融合异常检测模型，称为MKF-ADS。 具体地，该方法设计了一个集成框架，包括带有注意机制的时空相关性（STcAM）模块和补丁稀疏变换器模块（PatchST）。 STcAM通过精细修剪使用一维卷积（Conv1D）来提取空间特征，随后利用双向长短期记忆（Bi-LSTM）来提取

    arXiv:2403.04293v1 Announce Type: new  Abstract: With the requirements of Intelligent Transport Systems (ITSs) for extensive connectivity of Electronic Control Units (ECUs) to the outside world, safety and security have become stringent problems. Intrusion detection systems (IDSs) are a crucial safety component in remediating Controller Area Network (CAN) bus vulnerabilities. However, supervised-based IDSs fail to identify complexity attacks and anomaly-based IDSs have higher false alarms owing to capability bottleneck. In this paper, we propose a novel multi-knowledge fused anomaly detection model, called MKF-IDS. Specifically, the method designs an integration framework, including spatial-temporal correlation with an attention mechanism (STcAM) module and patch sparse-transformer module (PatchST). The STcAM with fine-pruning uses one-dimensional convolution (Conv1D) to extract spatial features and subsequently utilizes the Bidirectional Long Short Term Memory (Bi-LSTM) to extract the
    
[^143]: RACE-SM:基于强化学习的社交式匝道合流自主控制

    RACE-SM: Reinforcement Learning Based Autonomous Control for Social On-Ramp Merging

    [https://arxiv.org/abs/2403.03359](https://arxiv.org/abs/2403.03359)

    该论文提出了一种基于强化学习的自主控制模型，专注于并行式匝道合流，考虑了道路上其他车辆的影响，并提出了新颖的激励函数。

    

    自主并行式匝道合流在人控车辆交通中仍然是自主车辆控制中存在的问题。现有非学习型车辆控制解决方案主要依赖规则和优化，但这些方法往往面临重大挑战。最近深度强化学习的进展展现了希望，并受到了重要学术关注，然而现有的基于学习的方法对其他高速公路车辆关注不足，且经常依赖不准确的道路交通假设。此外，并行式情况很少被考虑。提出了一种新颖的学习模型，用于加速和变道决策制定，该模型明确考虑了对于车辆本身及其周围车辆（可能合作或不合作）的效用，以产生符合社会规范的行为。这种新颖的奖励函数利用社交

    arXiv:2403.03359v1 Announce Type: new  Abstract: Autonomous parallel-style on-ramp merging in human controlled traffic continues to be an existing issue for autonomous vehicle control. Existing non-learning based solutions for vehicle control rely on rules and optimization primarily. These methods have been seen to present significant challenges. Recent advancements in Deep Reinforcement Learning have shown promise and have received significant academic interest however the available learning based approaches show inadequate attention to other highway vehicles and often rely on inaccurate road traffic assumptions. In addition, the parallel-style case is rarely considered. A novel learning based model for acceleration and lane change decision making that explicitly considers the utility to both the ego vehicle and its surrounding vehicles which may be cooperative or uncooperative to produce behaviour that is socially acceptable is proposed. The novel reward function makes use of Social 
    
[^144]: 大型语言模型在预测神经科学结果方面超越人类专家

    Large language models surpass human experts in predicting neuroscience results

    [https://arxiv.org/abs/2403.03230](https://arxiv.org/abs/2403.03230)

    大型语言模型通过整合广泛科学文献中的相关发现，能够优于人类专家预测神经科学实验结果，预示着人类与大型语言模型共同进行发现的未来。

    

    科学发现常常取决于综合几十年的研究，这一任务可能超出人类信息处理能力。大型语言模型（LLMs）提供了一个解决方案。在广泛的科学文献上训练的LLMs可能能够整合嘈杂但相关的发现，以优于人类专家来预测新颖结果。为了评估这种可能性，我们创建了BrainBench，一个前瞻性的基准，用于预测神经科学结果。我们发现LLMs在预测实验结果方面超越了专家。在神经科学文献上调整的一个LLM，BrainGPT表现得更好。与人类专家一样，当LLMs对他们的预测有信心时，他们更有可能是正确的，这预示着未来人类和LLMs将合作进行发现。我们的方法并非特定于神经科学，并且可转移到其他知识密集型事业中。

    arXiv:2403.03230v1 Announce Type: cross  Abstract: Scientific discoveries often hinge on synthesizing decades of research, a task that potentially outstrips human information processing capacities. Large language models (LLMs) offer a solution. LLMs trained on the vast scientific literature could potentially integrate noisy yet interrelated findings to forecast novel results better than human experts. To evaluate this possibility, we created BrainBench, a forward-looking benchmark for predicting neuroscience results. We find that LLMs surpass experts in predicting experimental outcomes. BrainGPT, an LLM we tuned on the neuroscience literature, performed better yet. Like human experts, when LLMs were confident in their predictions, they were more likely to be correct, which presages a future where humans and LLMs team together to make discoveries. Our approach is not neuroscience-specific and is transferable to other knowledge-intensive endeavors.
    
[^145]: 精确推荐的端到端图-序列表示学习

    End-to-end Graph-Sequential Representation Learning for Accurate Recommendations

    [https://arxiv.org/abs/2403.00895](https://arxiv.org/abs/2403.00895)

    本文提出了一个新颖的多重表示学习框架，有效地结合了基于序列和基于图的推荐方法，显著改善了推荐性能。

    

    近年来推荐系统的许多新进展集中在开发基于序列和基于图的方法上。这两种方法在建模行为数据中的复杂关系方面都证明了其有效性，从而在个性化排名和下一个推荐任务中取得了有益的成果，同时保持了良好的可扩展性。然而，它们从数据中捕捉到的信号截然不同。前者直接通过与最近物品的有序交互来表示用户，而后者旨在捕捉交互图中的间接依赖关系。本文提出了一个新颖的多重表示学习框架，利用这两种范式之间的协同作用。我们在几个数据集上的实证评估表明，利用所提出的框架相互训练序列和图组件显著改善了推荐性能。

    arXiv:2403.00895v1 Announce Type: cross  Abstract: Many recent advancements in recommender systems have focused on developing sequence-based and graph-based approaches. Both approaches proved useful in modeling intricate relationships within behavioral data, leading to promising outcomes in personalized ranking and next-item recommendation tasks while maintaining good scalability. However, they capture very different signals from data. While the former approach represents users directly through ordered interactions with recent items, the latter one aims to capture indirect dependencies across the interactions graph. This paper presents a novel multi-representational learning framework that exploits the synergies between these two paradigms. Our empirical evaluation on several datasets demonstrates that mutual training of sequential and graph components with the proposed framework significantly improves recommendations performance.
    
[^146]: LLM推断揭示：调查与Roofline模型见解

    LLM Inference Unveiled: Survey and Roofline Model Insights

    [https://arxiv.org/abs/2402.16363](https://arxiv.org/abs/2402.16363)

    本文提出了一个基于Roofline模型的框架，用于系统分析LLM推断技术，帮助识别部署中的瓶颈，并为更有效地部署LLM提供策略。

    

    高效大语言模型（LLM）推断领域正在迅速发展，提供了机遇和挑战的独特结合。虽然该领域已经扩展并充满活力，但至今还没有一个简明的框架来分析LLM推断的各种方法，以便清晰地理解这一领域。我们的调查不仅总结了当前研究现状，还基于Roofline模型引入了一个框架，用于系统分析LLM推断技术。这一框架能够帮助识别LLM部署中的瓶颈，并更深入地了解在实际设备上的实际方面，从而为部署LLM提供更有效的策略。此外，我们还系统地汇总了高效LLM推断的最新进展，涵盖关键领域，比如权重优化（如知识蒸馏和量化）。

    arXiv:2402.16363v1 Announce Type: cross  Abstract: The field of efficient Large Language Model (LLM) inference is rapidly evolving, presenting a unique blend of opportunities and challenges. Although the field has expanded and is vibrant, there hasn't been a concise framework that analyzes the various methods of LLM Inference to provide a clear understanding of this domain. Our survey stands out from traditional literature reviews by not only summarizing the current state of research but also by introducing a framework based on roofline model for systematic analysis of LLM inference techniques. This framework enables identifying the bottlenecks in LLM deployments and provides a deeper understanding of the practical aspects on real devices, thereby informing more effective strategies for deploying LLM. Furthermore, we systematically collate the latest advancements in efficient LLM inference, covering crucial areas such as weight optimization (e.g., Knowledge Distillation and Quantizatio
    
[^147]: 学习半线性神经算子：预测和数据同化的统一递归框架

    Learning Semilinear Neural Operators : A Unified Recursive Framework For Prediction And Data Assimilation

    [https://arxiv.org/abs/2402.15656](https://arxiv.org/abs/2402.15656)

    提出了一种学习半线性神经算子的方法，通过结合预测和校正操作实现了对长时间尺度上时空PDE的解进行处理与数据同化。

    

    最近神经算子（NOs）理论的进展使得能够快速而准确地计算由偏微分方程（PDEs）描述的复杂系统的解成为可能。尽管取得了巨大成功，但当前基于NO的解决方案在处理长时间尺度上的时空PDE时面临重要挑战。具体而言，当前的NO理论没有提出一个系统框架，以便根据稀疏采样的嘈杂测量有效地纠正PDE解的演化。本文提出了一种基于学习的状态空间方法来计算无限维半线性PDE的解算子。利用半线性PDE的结构和函数空间中的非线性观测者理论，我们开发了一种灵活的递归方法，通过结合预测和校正操作，允许同时进行预测和数据同化。

    arXiv:2402.15656v1 Announce Type: cross  Abstract: Recent advances in the theory of Neural Operators (NOs) have enabled fast and accurate computation of the solutions to complex systems described by partial differential equations (PDEs). Despite their great success, current NO-based solutions face important challenges when dealing with spatio-temporal PDEs over long time scales. Specifically, the current theory of NOs does not present a systematic framework to perform data assimilation and efficiently correct the evolution of PDE solutions over time based on sparsely sampled noisy measurements. In this paper, we propose a learning-based state-space approach to compute the solution operators to infinite-dimensional semilinear PDEs. Exploiting the structure of semilinear PDEs and the theory of nonlinear observers in function spaces, we develop a flexible recursive method that allows for both prediction and data assimilation by combining prediction and correction operations. The proposed 
    
[^148]: 一种对话式脑-人工智能界面

    A Conversational Brain-Artificial Intelligence Interface

    [https://arxiv.org/abs/2402.15011](https://arxiv.org/abs/2402.15011)

    BAIs利用人工智能代替神经-认知处理管线的部分，让认知功能受损的个体能够通过高层意图完成复杂任务，例如通过主观提供意图完成模拟电话对话。

    

    我们将脑-人工智能界面（BAIs）作为一种新的脑-计算机界面（BCIs）类别引入。不同于依赖完好认知功能的传统BCIs，BAIs利用人工智能的力量来替代神经-认知处理管线的部分。BAIs允许用户通过提供高层意图来完成复杂任务，而经过预训练的AI代理确定低层次细节。该方法将BCIs的目标受众扩大到认知功能受损的个体，这是常常被排除在传统BCIs好处之外的人群。我们提出了BAIs的一般概念，并通过基于脑电图的对话式BAI展示了这种新方法的潜力。特别是，我们在模拟电话对话的实验中展示了对话式BAI能够实现复杂通信，而无需生成语言。因此，我们的工作首次证明了，对于第一次，

    arXiv:2402.15011v1 Announce Type: cross  Abstract: We introduce Brain-Artificial Intelligence Interfaces (BAIs) as a new class of Brain-Computer Interfaces (BCIs). Unlike conventional BCIs, which rely on intact cognitive capabilities, BAIs leverage the power of artificial intelligence to replace parts of the neuro-cognitive processing pipeline. BAIs allow users to accomplish complex tasks by providing high-level intentions, while a pre-trained AI agent determines low-level details. This approach enlarges the target audience of BCIs to individuals with cognitive impairments, a population often excluded from the benefits of conventional BCIs. We present the general concept of BAIs and illustrate the potential of this new approach with a Conversational BAI based on EEG. In particular, we show in an experiment with simulated phone conversations that the Conversational BAI enables complex communication without the need to generate language. Our work thus demonstrates, for the first time, th
    
[^149]: 在社交媒体上结合心理量表进行零-shot可解释的心理健康分析

    Zero-shot Explainable Mental Health Analysis on Social Media by incorporating Mental Scales

    [https://arxiv.org/abs/2402.10948](https://arxiv.org/abs/2402.10948)

    该方法结合心理量表通过LLMs进行零-shot心理健康分析，实验结果表明其优于其他方法

    

    传统的心理健康分析方法在容量方面表现强大，但缺乏解释能力，并且需要大规模注释的数据。另一方面，基于大型语言模型（LLMs）的生成式方法有潜力摆脱繁重的注释并提供解释。受到使用量表评估心理状态的心理评估实践的启发，我们的方法通过LLMs结合了两个程序。首先，患者完成心理健康问卷，其次，心理学家解释来自心理健康问题的收集信息并做出明智决策。实验结果表明，我们的方法胜过其他零-shot方法。

    arXiv:2402.10948v1 Announce Type: cross  Abstract: Traditional discriminative approaches in mental health analysis are known for their strong capacity but lack interpretability and demand large-scale annotated data. On the other hand, generative approaches, such as those based on large language models (LLMs),have the potential to get rid of heavy annotations and provide explanations. However, their capabilities still fall short compared to discriminative approaches, and their explanations may be unreliable due to the fact that the generation of explanation is a black-box process. Inspired by the psychological assessment practice of using scales to evaluate mental states, our method incorporates two procedures via LLMs. First, the patient completes mental health questionnaires, and second, the psychologist interprets the collected information from the mental health questions and makes informed decisions. Experimental results show that our method outperforms other zero-shot methods. Our 
    
[^150]: 强健的智能体学习因果世界模型

    Robust agents learn causal world models

    [https://arxiv.org/abs/2402.10877](https://arxiv.org/abs/2402.10877)

    智能体必须学习因果模型才能在广泛的分布转变下达到后悔界限，这对迁移学习和因果推断等研究领域有重要影响。

    

    一直有人假设因果推理在强健且具有通用智能中起着基础作用，然而不清楚智能体是否必须学习因果模型才能推广到新的领域，或者其他归纳偏差是否足够。我们回答了这个问题，表明任何能够在大量分布转变下满足后悔界限的智能体必须学习数据生成过程的近似因果模型，对于优化智能体来说，该近似模型会收敛到真实的因果模型。我们讨论了这一结果对于多个研究领域，包括迁移学习和因果推断的影响。

    arXiv:2402.10877v1 Announce Type: new  Abstract: It has long been hypothesised that causal reasoning plays a fundamental role in robust and general intelligence. However, it is not known if agents must learn causal models in order to generalise to new domains, or if other inductive biases are sufficient. We answer this question, showing that any agent capable of satisfying a regret bound under a large set of distributional shifts must have learned an approximate causal model of the data generating process, which converges to the true causal model for optimal agents. We discuss the implications of this result for several research areas including transfer learning and causal inference.
    
[^151]: 利用分治程序指导大型语言模型对问题求解进行引导

    Guiding Large Language Models with Divide-and-Conquer Program for Discerning Problem Solving

    [https://arxiv.org/abs/2402.05359](https://arxiv.org/abs/2402.05359)

    该论文提出了一种以分治程序引导大型语言模型（LLM）的方法，以解决涉及重复子任务和/或具有欺骗性内容的问题。实验证明，该方法可以提高LLM的表达能力。

    

    基础模型，如大型语言模型（LLMs），因其广泛的应用而引起了广泛的关注。现有的研究表明，适当的提示设计，如思维链，可以释放LLM在不同领域的强大能力。然而，对于处理涉及重复子任务和/或具有欺骗性内容的任务（如算术计算和文章级虚假新闻检测），现有的提示策略要么表现出表达能力不足，要么由幻觉引发中间错误。为了使LLM对这些中间错误更具辨别力，我们提出了一种以分治程序引导LLM的方法，同时确保优越的表达能力和任务分解、子任务解决和解决组装过程的分离。理论分析表明，我们的策略可以引导LLM扩展固定深度Transformer的表达能力。实验表明，我们提出的方法可以实现

    Foundation models, such as Large language Models (LLMs), have attracted significant amount of interest due to their large number of applications. Existing works show that appropriate prompt design, such as Chain-of-Thoughts, can unlock LLM's powerful capacity in diverse areas. However, when handling tasks involving repetitive sub-tasks and/or deceptive contents, such as arithmetic calculation and article-level fake news detection, existing prompting strategies either suffers from insufficient expressive power or intermediate errors triggered by hallucination. To make LLM more discerning to such intermediate errors, we propose to guide LLM with a Divide-and-Conquer program that simultaneously ensures superior expressive power and disentangles task decomposition, sub-task resolution, and resolution assembly process. Theoretic analysis reveals that our strategy can guide LLM to extend the expressive power of fixed-depth Transformer. Experiments indicate that our proposed method can achiev
    
[^152]: 在预算限制下行为用户分割中的优化传递发现

    Delivery Optimized Discovery in Behavioral User Segmentation under Budget Constrain

    [https://arxiv.org/abs/2402.03388](https://arxiv.org/abs/2402.03388)

    在预算限制下，我们提出了一种基于随机优化的算法，用于优化传递发现行为用户细分。

    

    用户在线行为足迹可以使公司发现基于行为的用户细分，并向用户发送特定细分的信息。在发现细分之后，通过像Facebook和Google这样的首选媒体渠道向用户发送信息可能具有挑战性，因为只有部分行为细分中的用户在媒体上找到匹配，并且只有其中一小部分看到消息（曝光）。即使高质量的发现也会在传递失败时变得无用。许多复杂的算法用于发现行为细分，然而这些算法忽略了传递组件。问题变得复杂是因为（i）发现是在公司数据（例如用户点击）的行为数据空间中进行的，而传递则是基于媒体定义的静态数据空间（例如地理位置，年龄）进行的；（ii）公司在预算限制下运作。我们引入了一种基于随机优化的算法，用于在预算限制下优化传递发现行为用户细分。

    Users' behavioral footprints online enable firms to discover behavior-based user segments (or, segments) and deliver segment specific messages to users. Following the discovery of segments, delivery of messages to users through preferred media channels like Facebook and Google can be challenging, as only a portion of users in a behavior segment find match in a medium, and only a fraction of those matched actually see the message (exposure). Even high quality discovery becomes futile when delivery fails. Many sophisticated algorithms exist for discovering behavioral segments; however, these ignore the delivery component. The problem is compounded because (i) the discovery is performed on the behavior data space in firms' data (e.g., user clicks), while the delivery is predicated on the static data space (e.g., geo, age) as defined by media; and (ii) firms work under budget constraint. We introduce a stochastic optimization based algorithm for delivery optimized discovery of behavioral u
    
[^153]: X射线与CT图像融合的全可微相关驱动2D/3D配准

    Fully Differentiable Correlation-driven 2D/3D Registration for X-ray to CT Image Fusion

    [https://arxiv.org/abs/2402.02498](https://arxiv.org/abs/2402.02498)

    本论文提出一种全可微相关驱动网络用于X射线与CT图像融合的配准，通过双分支CNN-Transformer编码器实现低频全局特征和高频局部特征的提取和分离，进一步提出相关驱动损失进行特征分解，并应用凸形相似函数学习的训练策略。实验证明，该方法在性能上优于现有的全可微学习配准方法。

    

    基于图像的刚性2D/3D配准是导向外科手术干预的重要技术。近年来，一些基于学习的全可微方法取得了有益的成果，但特征提取和梯度传递过程仍缺乏可控性和可解释性。为了缓解这些问题，在本研究中，我们提出了一种新颖的全可微相关驱动网络，利用双分支CNN-Transformer编码器实现了低频全局特征和高频局部特征的提取和分离。进一步提出了一种基于内嵌信息的低频特征和高频特征分解的相关驱动损失。此外，我们应用一种学习逼近凸形相似函数的训练策略。我们在一个自建数据集上测试了我们的方法，并展示了其优于现有全可微学习配准方法的性能。

    Image-based rigid 2D/3D registration is a critical technique for fluoroscopic guided surgical interventions. In recent years, some learning-based fully differentiable methods have produced beneficial outcomes while the process of feature extraction and gradient flow transmission still lack controllability and interpretability. To alleviate these problems, in this work, we propose a novel fully differentiable correlation-driven network using a dual-branch CNN-transformer encoder which enables the network to extract and separate low-frequency global features from high-frequency local features. A correlation-driven loss is further proposed for low-frequency feature and high-frequency feature decomposition based on embedded information. Besides, a training strategy that learns to approximate a convex-shape similarity function is applied in our work. We test our approach on a in-house datasetand show that it outperforms both existing fully differentiable learning-based registration approach
    
[^154]: 对净化的对抗训练（AToP）：提升鲁棒性和泛化性能

    Adversarial Training on Purification (AToP): Advancing Both Robustness and Generalization

    [https://arxiv.org/abs/2401.16352](https://arxiv.org/abs/2401.16352)

    提出了一种新的对净化的对抗训练（AToP）流程，通过随机转换的扰动破坏和通过对抗损失微调净化器模型，同时提升了鲁棒性和泛化性能。

    

    深度神经网络被认为易受设计精良的对抗攻击影响。基于对抗训练（AT）的最成功防御技术可以实现特定攻击下的最佳鲁棒性，但无法很好地泛化到未知攻击。基于对抗净化（AP）的另一有效防御技术可以增强泛化性能，但无法实现最佳鲁棒性。与此同时，这两种方法都存在一个共同的局限性，即标准准确性降级。为了缓解这些问题，我们提出了一种新的流程，称为对净化的对抗训练（AToP），包括两个组件：通过随机转换（RT）破坏扰动，以避免对已知攻击的过度学习，从而实现对未知攻击的鲁棒性泛化；以及通过对抗损失对净化器模型进行微调（FT），以提高鲁棒性。为了评估我们的方法，我们在一种...

    arXiv:2401.16352v2 Announce Type: replace-cross  Abstract: The deep neural networks are known to be vulnerable to well-designed adversarial attacks. The most successful defense technique based on adversarial training (AT) can achieve optimal robustness against particular attacks but cannot generalize well to unseen attacks. Another effective defense technique based on adversarial purification (AP) can enhance generalization but cannot achieve optimal robustness. Meanwhile, both methods share one common limitation on the degraded standard accuracy. To mitigate these issues, we propose a novel pipeline called Adversarial Training on Purification (AToP), which comprises two components: perturbation destruction by random transforms (RT) and purifier model fine-tuned (FT) by adversarial loss. RT is essential to avoid overlearning to known attacks resulting in the robustness generalization to unseen attacks and FT is essential for the improvement of robustness. To evaluate our method in an e
    
[^155]: 教育领域自然语言处理的调查：分类体系、系统综述和未来趋势

    Survey of Natural Language Processing for Education: Taxonomy, Systematic Review, and Future Trends

    [https://arxiv.org/abs/2401.07518](https://arxiv.org/abs/2401.07518)

    这篇论文调查了教育领域自然语言处理的最新进展，提出了分类体系，并总结了挑战和未来研究方向。

    

    自然语言处理（NLP）旨在通过计算机科学领域的技术分析文本，应用于医疗保健、商业和教育领域。特别是，在教育领域，NLP已经被应用于教学和学习方面的帮助。本调查研究主要关注解决与教育领域相关的问题，并回顾了NLP的最新进展。具体来说，我们从介绍相关背景开始，然后提出教育领域NLP的分类系统。接着，我们根据上述分类系统说明任务定义、挑战和相应的技术。之后，我们展示了该领域中的一些现有演示，并总结了未来的研究方向。

    Natural Language Processing (NLP) aims to analyze the text via techniques in the computer science field. It serves the applications in healthcare, commerce, and education domains. Particularly, NLP has been applied to the education domain to help teaching and learning. In this survey, we review recent advances in NLP with a focus on solving problems related to the education domain. In detail, we begin with introducing the relevant background. Then, we present the taxonomy of NLP in the education domain. Next, we illustrate the task definition, challenges, and corresponding techniques based on the above taxonomy. After that, we showcase some off-the-shelf demonstrations in this domain and conclude with future directions.
    
[^156]: 欧盟法律中的生成式人工智能：责任、隐私、知识产权和网络安全

    Generative AI in EU Law: Liability, Privacy, Intellectual Property, and Cybersecurity

    [https://arxiv.org/abs/2401.07348](https://arxiv.org/abs/2401.07348)

    生成式人工智能和大型语言模型在欧盟法律法规中的应用引发了责任、隐私、知识产权和网络安全等方面的挑战，本文对现有和拟议的法律进行了批判性分析，并提出了改进建议。

    

    生成式人工智能的出现，特别是通过大型语言模型（LLMs）如ChatGPT及其后继模型，标志着人工智能领域的一次范式转变。先进的LLMs表现出多模态性，能处理多样化的数据格式，从而拓宽了它们的应用范围。然而，这些模型的复杂性和新兴自治性引入了预测性和法律遵从性方面的挑战。本文深入探讨了生成式人工智能和LLMs在欧盟背景下的法律和监管影响，分析了责任、隐私、知识产权和网络安全等方面。它批判性地审视了现有和拟议的欧盟立法（包括《人工智能法》草案）在应对生成式人工智能普遍和LLMs特别挑战方面的充分性。本文确定了立法框架中的潜在差距和不足，并提出建议以确保

    arXiv:2401.07348v2 Announce Type: replace-cross  Abstract: The advent of Generative AI, particularly through Large Language Models (LLMs) like ChatGPT and its successors, marks a paradigm shift in the AI landscape. Advanced LLMs exhibit multimodality, handling diverse data formats, thereby broadening their application scope. However, the complexity and emergent autonomy of these models introduce challenges in predictability and legal compliance. This paper delves into the legal and regulatory implications of Generative AI and LLMs in the European Union context, analyzing aspects of liability, privacy, intellectual property, and cybersecurity. It critically examines the adequacy of the existing and proposed EU legislation, including the Artificial Intelligence Act (AIA) draft, in addressing the unique challenges posed by Generative AI in general and LLMs in particular. The paper identifies potential gaps and shortcomings in the legislative framework and proposes recommendations to ensur
    
[^157]: 基于深度学习、注意机制和基于能量的不确定性预测的脑肿瘤分割

    Brain Tumor Segmentation Based on Deep Learning, Attention Mechanisms, and Energy-Based Uncertainty Prediction

    [https://arxiv.org/abs/2401.00587](https://arxiv.org/abs/2401.00587)

    该论文提出了一种基于深度学习、注意机制和基于能量的不确定性预测的脑肿瘤分割方法，通过感兴趣区域检测算法和全卷积自动编码器实现了更快速、准确的诊断。

    

    脑肿瘤是最致命的癌症之一，其死亡率超过80%。快速而准确的诊断对提高生存几率至关重要。然而，在医学分析中，对脑肿瘤的手动注释和分割可能是一项复杂的任务。通常会分析多种MRI模态，因为它们提供有关肿瘤区域的独特信息。尽管这些MRI模态有助于分割胶质瘤，但它们往往会增加过拟合和计算量。本文提出了一种感兴趣区域检测算法，它在数据预处理期间实施，以定位显著特征并去除多余的MRI数据。这减小了输入大小，允许更激进的数据增强和更深的神经网络。在处理MRI模态之后，一个具有软注意力机制的全卷积自动编码器对不同的脑MRIs进行分割。

    arXiv:2401.00587v2 Announce Type: replace-cross  Abstract: Brain tumors are one of the deadliest forms of cancer with a mortality rate of over 80%. A quick and accurate diagnosis is crucial to increase the chance of survival. However, in medical analysis, the manual annotation and segmentation of a brain tumor can be a complicated task. Multiple MRI modalities are typically analyzed as they provide unique information regarding the tumor regions. Although these MRI modalities are helpful for segmenting gliomas, they tend to increase overfitting and computation. This paper proposes a region of interest detection algorithm that is implemented during data preprocessing to locate salient features and remove extraneous MRI data. This decreases the input size, allowing for more aggressive data augmentations and deeper neural networks. Following the preprocessing of the MRI modalities, a fully convolutional autoencoder with soft attention segments the different brain MRIs. When these deep lear
    
[^158]: VideoPoet：用于零样本视频生成的大型语言模型

    VideoPoet: A Large Language Model for Zero-Shot Video Generation

    [https://arxiv.org/abs/2312.14125](https://arxiv.org/abs/2312.14125)

    VideoPoet是一种大型语言模型，能够从多种条件信号中生成高质量视频及匹配音频，并且在零样本视频生成领域展示了最先进的能力。

    

    我们提出了VideoPoet，这是一种能够从各种不同的条件信号中合成高质量视频及匹配音频的语言模型。VideoPoet采用解码器-仅Transformer架构，可以处理多模态输入，包括图像、视频、文本和音频。训练协议遵循大型语言模型（LLMs）的方式，包括两个阶段：预训练和特定任务的适应。在预训练阶段，VideoPoet在自回归Transformer框架中结合了多模态生成目标的混合。预训练的LLM作为一个基础，可以为各种视频生成任务进行调整。我们展示了实证结果，展示了该模型在零样本视频生成方面的最新能力，特别突出了VideoPoet生成高保真运动的能力。

    arXiv:2312.14125v2 Announce Type: replace-cross  Abstract: We present VideoPoet, a language model capable of synthesizing high-quality video, with matching audio, from a large variety of conditioning signals. VideoPoet employs a decoder-only transformer architecture that processes multimodal inputs -- including images, videos, text, and audio. The training protocol follows that of Large Language Models (LLMs), consisting of two stages: pretraining and task-specific adaptation. During pretraining, VideoPoet incorporates a mixture of multimodal generative objectives within an autoregressive Transformer framework. The pretrained LLM serves as a foundation that can be adapted for a range of video generation tasks. We present empirical results demonstrating the model's state-of-the-art capabilities in zero-shot video generation, specifically highlighting VideoPoet's ability to generate high-fidelity motions. Project page: http://sites.research.google/videopoet/
    
[^159]: 使用分层接触网格变换器学习灵活身体碰撞动力学

    Learning Flexible Body Collision Dynamics with Hierarchical Contact Mesh Transformer

    [https://arxiv.org/abs/2312.12467](https://arxiv.org/abs/2312.12467)

    本文提出了一种使用分层网格结构的Hierarchical Contact Mesh Transformer（HCMT），能够学习长距离依赖关系，以处理灵活体动力学挑战。

    

    最近，许多基于网格的图神经网络（GNN）模型已被提出用来建模复杂的高维物理系统。与传统数值求解器相比，这些方法取得了显着的成就，大大减少了求解时间。然而，目前尚未得到充分探讨的是它们是否有效地应对灵活体动力学的挑战，即瞬时碰撞发生在极短时间内的情况下。本文提出了一种使用分层网格结构的Hierarchical Contact Mesh Transformer（HCMT），能够学习身体空间位置之间（由碰撞引起的）长距离依赖关系--在更高级别网格中的两个接近位置对应于身体中的两个远距位置。

    arXiv:2312.12467v2 Announce Type: replace-cross  Abstract: Recently, many mesh-based graph neural network (GNN) models have been proposed for modeling complex high-dimensional physical systems. Remarkable achievements have been made in significantly reducing the solving time compared to traditional numerical solvers. These methods are typically designed to i) reduce the computational cost in solving physical dynamics and/or ii) propose techniques to enhance the solution accuracy in fluid and rigid body dynamics. However, it remains under-explored whether they are effective in addressing the challenges of flexible body dynamics, where instantaneous collisions occur within a very short timeframe. In this paper, we present Hierarchical Contact Mesh Transformer (HCMT), which uses hierarchical mesh structures and can learn long-range dependencies (occurred by collisions) among spatially distant positions of a body -- two close positions in a higher-level mesh corresponds to two distant posi
    
[^160]: 离线强化学习中的泛化差距

    The Generalization Gap in Offline Reinforcement Learning

    [https://arxiv.org/abs/2312.05742](https://arxiv.org/abs/2312.05742)

    该研究比较了在线和离线学习方法在泛化能力上的差异，发现离线学习算法在新环境中表现不如在线学习算法，并引入了用于评估泛化能力的第一个基准测试。

    

    尽管近年来离线学习取得了一些进展，这些方法仍然是在相同的环境上进行训练和测试的。在本文中，我们比较了广泛使用的在线和离线学习方法（如在线强化学习（RL）、离线RL、序列建模和行为克隆）的泛化能力。我们的实验表明，离线学习算法在新环境中的表现不如在线学习算法。我们还引入了第一个用于评估离线学习中泛化能力的基准测试，从Procgen（2D视频游戏）和WebShop（电子商务网站）收集了多种大小和技能水平的数据集。这些数据集包含了有限数量的游戏关卡或自然语言指令的轨迹，测试时，代理要能够泛化到新的关卡或指令。我们的实验证明，现有的离线学习算法在这两个方面都很难与在线RL的表现相匹配。

    arXiv:2312.05742v2 Announce Type: replace-cross  Abstract: Despite recent progress in offline learning, these methods are still trained and tested on the same environment. In this paper, we compare the generalization abilities of widely used online and offline learning methods such as online reinforcement learning (RL), offline RL, sequence modeling, and behavioral cloning. Our experiments show that offline learning algorithms perform worse on new environments than online learning ones. We also introduce the first benchmark for evaluating generalization in offline learning, collecting datasets of varying sizes and skill-levels from Procgen (2D video games) and WebShop (e-commerce websites). The datasets contain trajectories for a limited number of game levels or natural language instructions and at test time, the agent has to generalize to new levels or instructions. Our experiments reveal that existing offline learning algorithms struggle to match the performance of online RL on both 
    
[^161]: 从参考图像中检索条件用于扩散模型

    Retrieving Conditions from Reference Images for Diffusion Models

    [https://arxiv.org/abs/2312.02521](https://arxiv.org/abs/2312.02521)

    本文将主题驱动生成视为扩散模型中的一个统一检索问题，引入了一种名为RetriNet的新颖扩散模型架构，通过精确检索主题属性并过滤无关信息来解决问题，在人脸生成方面表现出卓越性能。

    

    新开发的基于扩散的技术展示了在生成各种高质量图像方面的卓越能力，引起了各种应用的相当大兴趣。一个普遍的场景是基于参考图像中的一个主题生成新的图像。这个主题可以是风格化头像的面部身份，虚拟试穿的身体和服装等。满足这一要求正在演变成一门称为主题驱动生成的领域。在本文中，我们将主题驱动生成视为扩散模型中的一个统一检索问题。我们引入了一种名为RetriNet的新颖扩散模型架构，旨在通过精确地从参考图像中检索主题属性并过滤掉无关信息来解决这些问题。与现有的最先进方法相比，RetriNet在人脸生成方面表现出令人印象深刻的性能。我们进一步提出了一个研究和...

    arXiv:2312.02521v2 Announce Type: replace-cross  Abstract: Newly developed diffusion-based techniques have showcased phenomenal abilities in producing a wide range of high-quality images, sparking considerable interest in various applications. A prevalent scenario is to generate new images based on a subject from reference images. This subject could be face identity for styled avatars, body and clothing for virtual try-on and so on. Satisfying this requirement is evolving into a field called Subject-Driven Generation. In this paper, we consider Subject-Driven Generation as a unified retrieval problem with diffusion models. We introduce a novel diffusion model architecture, named RetriNet, designed to address and solve these problems by retrieving subject attributes from reference images precisely, and filter out irrelevant information. RetriNet demonstrates impressive performance when compared to existing state-of-the-art approaches in face generation. We further propose a research and
    
[^162]: MUFFIN: 用于改善指示遵循的多方面指南的策划

    MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction-Following

    [https://arxiv.org/abs/2312.02436](https://arxiv.org/abs/2312.02436)

    MUFFIN是一个新的指示遵循数据集策划方案，通过自动按比例扩大任务，通过多种输入方面使任务丰富多样。

    

    在大型语言模型（LLMs）领域中，加强指示遵循能力通常涉及策划广泛的训练数据。本文引入了一个新的指示遵循数据集策划方案MUFFIN，具体地通过用多种输入方面使任务自动按比例扩大以丰富这些任务。

    arXiv:2312.02436v2 Announce Type: replace-cross  Abstract: In the realm of large language models (LLMs), enhancing instruction-following capability often involves curating expansive training data. This is achieved through two primary schemes: i) Scaling-Inputs: Amplifying (input, output) pairs per task instruction, aiming for better instruction adherence. ii) Scaling Input-Free Tasks: Enlarging tasks, each composed of an (instruction, output) pair (without requiring a separate input anymore). However, LLMs under Scaling-Inputs tend to be overly sensitive to inputs, leading to misinterpretation or non-compliance with instructions. Conversely, Scaling Input-Free Tasks demands a substantial number of tasks but is less effective in instruction following when dealing with instances in Scaling-Inputs. This work introduces MUFFIN, a new scheme of instruction-following dataset curation. Specifically, we automatically Scale Tasks per Input by diversifying these tasks with various input facets. 
    
[^163]: 高效动态扩散模型（EMDM）用于快速且高质量的动作生成

    EMDM: Efficient Motion Diffusion Model for Fast and High-Quality Motion Generation

    [https://arxiv.org/abs/2312.02256](https://arxiv.org/abs/2312.02256)

    提出了高效动态扩散模型（EMDM），能够在更少的采样步骤中实现快速且高质量的动作生成

    

    我们引入了高效的动态扩散模型（EMDM），用于快速且高质量的人类动作生成。当前最先进的生成式扩散模型取得了令人印象深刻的结果，但往往在追求快速生成的同时牺牲了质量。为了解决这些问题，我们提出了EMDM，它通过在扩散模型中的多次采样步骤中捕捉复杂分布，实现了更少的采样步骤和生成过程的显着加速。

    arXiv:2312.02256v2 Announce Type: replace-cross  Abstract: We introduce Efficient Motion Diffusion Model (EMDM) for fast and high-quality human motion generation. Current state-of-the-art generative diffusion models have produced impressive results but struggle to achieve fast generation without sacrificing quality. On the one hand, previous works, like motion latent diffusion, conduct diffusion within a latent space for efficiency, but learning such a latent space can be a non-trivial effort. On the other hand, accelerating generation by naively increasing the sampling step size, e.g., DDIM, often leads to quality degradation as it fails to approximate the complex denoising distribution. To address these issues, we propose EMDM, which captures the complex distribution during multiple sampling steps in the diffusion model, allowing for much fewer sampling steps and significant acceleration in generation. This is achieved by a conditional denoising diffusion GAN to capture multimodal da
    
[^164]: 用于解决线性逆问题的深度正则化复合高斯网络

    Deep Regularized Compound Gaussian Network for Solving Linear Inverse Problems

    [https://arxiv.org/abs/2311.17248](https://arxiv.org/abs/2311.17248)

    提出了两种允许在复合高斯分布类中进行问题特定统计先验选择的线性逆问题新方法，一种是迭代算法广义复合高斯最小二乘，另一种是通过展开得到的新颖深度正则化神经网络DR-CG-Net。

    

    将先验信息纳入逆问题，例如通过最大后验估计，是促进稳健逆问题解决方案的重要技术。本文为允许在复合高斯（CG）分布类中进行问题特定统计先验选择的线性逆问题设计了两种新方法。第一种方法是一种迭代算法，称为广义复合高斯最小二乘（G-CG-LS），它最小化了一个正则化最小二乘目标函数，其中正则化强制执行一个CG先验。然后将G-CG-LS展开，提供我们的第二种方法，这是一种新颖的深度正则化（DR）神经网络，称为DR-CG-Net，可以学习先验信息。

    arXiv:2311.17248v2 Announce Type: replace-cross  Abstract: Incorporating prior information into inverse problems, e.g. via maximum-a-posteriori estimation, is an important technique for facilitating robust inverse problem solutions. In this paper, we devise two novel approaches for linear inverse problems that permit problem-specific statistical prior selections within the compound Gaussian (CG) class of distributions. The CG class subsumes many commonly used priors in signal and image reconstruction methods including those of sparsity-based approaches. The first method developed is an iterative algorithm, called generalized compound Gaussian least squares (G-CG-LS), that minimizes a regularized least squares objective function where the regularization enforces a CG prior. G-CG-LS is then unrolled, or unfolded, to furnish our second method, which is a novel deep regularized (DR) neural network, called DR-CG-Net, that learns the prior information. A detailed computational theory on conv
    
[^165]: 高保真度以人为中心的主体到图像合成

    High-fidelity Person-centric Subject-to-Image Synthesis

    [https://arxiv.org/abs/2311.10329](https://arxiv.org/abs/2311.10329)

    提出了Face-diffuser，一个有效的协作生成流水线，用于解决主体到图像合成中的训练不平衡和质量妥协问题。

    

    当前以主体驱动的图像生成方法在以人为中心的图像生成中遇到了重大挑战。原因在于它们通过微调通用预训练扩散来学习语义场景和人物生成，这涉及到一种无法调和的训练不平衡。本文提出了Face-diffuser，这是一个有效的协作生成流水线，旨在消除上述训练不平衡和质量妥协。

    arXiv:2311.10329v3 Announce Type: replace-cross  Abstract: Current subject-driven image generation methods encounter significant challenges in person-centric image generation. The reason is that they learn the semantic scene and person generation by fine-tuning a common pre-trained diffusion, which involves an irreconcilable training imbalance. Precisely, to generate realistic persons, they need to sufficiently tune the pre-trained model, which inevitably causes the model to forget the rich semantic scene prior and makes scene generation over-fit to the training data. Moreover, even with sufficient fine-tuning, these methods can still not generate high-fidelity persons since joint learning of the scene and person generation also lead to quality compromise. In this paper, we propose Face-diffuser, an effective collaborative generation pipeline to eliminate the above training imbalance and quality compromise. Specifically, we first develop two specialized pre-trained diffusion models, i.
    
[^166]: zrLLM：在具有大型语言模型的时间知识图上进行零样本关系学习

    zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large Language Models

    [https://arxiv.org/abs/2311.10112](https://arxiv.org/abs/2311.10112)

    本文提出了一种在时间知识图上进行零样本关系学习的方法，该方法利用大型语言模型(LLM)生成关系表示，并将其引入基于嵌入的TKGF方法中，能够捕捉关系描述中的语义信息，从而使得关系在建模时能具有相似的语义含义。

    

    模型化随时间变化的知识在时间知识图(TKGs)上已成为一个炽热话题。已经提出了各种方法来预测TKGs上的链接。其中大多数是基于嵌入的，其中学习隐藏表示以基于观察到的图上下文来表示知识图(KG)实体和关系。尽管这些方法在传统的TKG预测(TKGF)基准上表现出色，但它们在建模没有先前图上下文的未见过的零样本关系上面临强烈挑战。本文尝试解决这个问题的方法如下。我们首先将KG关系的文本描述输入大型语言模型(LLMs)中以生成关系表示，然后将它们引入基于嵌入的TKGF方法中。LLM增强的表示可以捕捉关系描述中的语义信息。这使得关系，无论是已见还是未见的，都能够获得类似的语义含义。

    arXiv:2311.10112v2 Announce Type: replace  Abstract: Modeling evolving knowledge over temporal knowledge graphs (TKGs) has become a heated topic. Various methods have been proposed to forecast links on TKGs. Most of them are embedding-based, where hidden representations are learned to represent knowledge graph (KG) entities and relations based on the observed graph contexts. Although these methods show strong performance on traditional TKG forecasting (TKGF) benchmarks, they face a strong challenge in modeling the unseen zero-shot relations that have no prior graph context. In this paper, we try to mitigate this problem as follows. We first input the text descriptions of KG relations into large language models (LLMs) for generating relation representations, and then introduce them into embedding-based TKGF methods. LLM-empowered representations can capture the semantic information in the relation descriptions. This makes the relations, whether seen or unseen, with similar semantic mean
    
[^167]: 为公平性调整文本到图像扩散模型

    Finetuning Text-to-Image Diffusion Models for Fairness

    [https://arxiv.org/abs/2311.07604](https://arxiv.org/abs/2311.07604)

    将公平性视为分布对齐问题，通过分布对齐损失和调整DFT两项技术贡献，显著减少文本到图像扩散模型中的性别、种族和其交叉偏见。

    

    社会对文本到图像扩散模型的快速采用凸显了解决其偏见的迫切需求。如果不进行干预，这些偏见可能传播出扭曲的世界观，并限制少数群体的机会。在这项工作中，我们将公平性视为一个分布对齐问题。我们的解决方案包括两个主要技术贡献：(1)一个分布对齐损失，将生成的图像的特定特征引向用户定义的目标分布，以及(2)调整了扩散模型采样过程的直接微调（调整DFT），它利用调整后的梯度直接优化在生成的图像上定义的损失。实证上，我们的方法显著减少了职业提示的性别、种族及其交叉偏见。即使只对五个软标记进行微调，性别偏见也大大减少。至关重要的是，我们的方法支持多元视角。

    arXiv:2311.07604v2 Announce Type: replace-cross  Abstract: The rapid adoption of text-to-image diffusion models in society underscores an urgent need to address their biases. Without interventions, these biases could propagate a skewed worldview and restrict opportunities for minority groups. In this work, we frame fairness as a distributional alignment problem. Our solution consists of two main technical contributions: (1) a distributional alignment loss that steers specific characteristics of the generated images towards a user-defined target distribution, and (2) adjusted direct finetuning of diffusion model's sampling process (adjusted DFT), which leverages an adjusted gradient to directly optimize losses defined on the generated images. Empirically, our method markedly reduces gender, racial, and their intersectional biases for occupational prompts. Gender bias is significantly reduced even when finetuning just five soft tokens. Crucially, our method supports diverse perspectives 
    
[^168]: 慎言：通过内心独白培养大型语言模型的沟通能力

    Think Before You Speak: Cultivating Communication Skills of Large Language Models via Inner Monologue

    [https://arxiv.org/abs/2311.07445](https://arxiv.org/abs/2311.07445)

    通过内在思考，本研究通过语言学和认知科学的灵感，赋予大型语言模型沟通技能，从而提高其拟人化和主动性，吸引用户进行更长时间的对话

    

    大型语言模型（LLMs）的出现进一步提高了开放领域对话系统的能力，可以生成流畅、连贯和多样化的回复。然而，LLMs仍然缺乏一项关键能力：沟通技巧。这种局限使它们更像信息搜索工具，而不是拟人化的聊天机器人。需要考虑沟通技能，如主题过渡、主动提问、概念引导、同理心和总结，使LLMs在对话中更具拟人化和主动性，从而增加用户的兴趣，吸引他们进行更长时间的交谈。然而，在黑匣子LLMs中启用这些沟通技能仍然是一个关键挑战，因为它们没有与真人相同的话语形成模式：先思后说。受语言学和认知科学启发，我们通过内在思考赋予LLMs沟通技能。

    arXiv:2311.07445v2 Announce Type: replace-cross  Abstract: The emergence of large language models (LLMs) further improves the capabilities of open-domain dialogue systems and can generate fluent, coherent, and diverse responses. However, LLMs still lack a crucial ability: communication skills. This limitation renders them more like information seeking tools rather than anthropomorphic chatbots. Communication skills, such as topic transition, proactively asking questions, concept guidance, empathy, and summarising often should be taken into consideration, to make LLMs more anthropomorphic and proactive during the conversation, thereby increasing the interest of users and attracting them to chat for longer. However, enabling these communication skills in black-box LLMs remains a key challenge because they do not have the same utterance formation mode as real people: think before speaking. Inspired by linguistics and cognitive science, we empower LLMs with communication skills through inn
    
[^169]: LILO：通过压缩和文档化代码学习可解释库

    LILO: Learning Interpretable Libraries by Compressing and Documenting Code

    [https://arxiv.org/abs/2310.19791](https://arxiv.org/abs/2310.19791)

    LILO是一种神经符号框架，通过迭代地合成、压缩和文档化代码来构建可解释且适用于特定问题领域的程序库。在其中，LILO结合了大型语言模型引导的程序合成和程序自动重构的算法进展，并且通过自动文档过程使得代码抽象可解释并提升性能。

    

    尽管大型语言模型（LLMs）在代码生成方面表现出色，但软件开发的关键方面是重构的艺术：将代码整合到可重用和可读的程序库中。本文介绍了一种名为LILO的神经符号框架，它通过迭代地合成、压缩和文档化代码来构建适合特定问题领域的库。LILO将LLM引导的程序合成与Stitch自动重构的近期算法进展相结合：Stitch是一个符号压缩系统，可以高效地识别大型代码语料库中的最佳lambda抽象。为了使这些抽象可解释，我们引入了一种自动文档（AutoDoc）过程，它根据上下文中的使用示例推断出自然语言名称和文档字符串。除了提高人类可读性外，我们发现AutoDoc通过帮助LILO的合成器解释和部署学习到的抽象来提高性能。我们对LILO进行了三个归纳式程序综合的评估。

    While large language models (LLMs) now excel at code generation, a key aspect of software development is the art of refactoring: consolidating code into libraries of reusable and readable programs. In this paper, we introduce LILO, a neurosymbolic framework that iteratively synthesizes, compresses, and documents code to build libraries tailored to particular problem domains. LILO combines LLM-guided program synthesis with recent algorithmic advances in automated refactoring from Stitch: a symbolic compression system that efficiently identifies optimal lambda abstractions across large code corpora. To make these abstractions interpretable, we introduce an auto-documentation (AutoDoc) procedure that infers natural language names and docstrings based on contextual examples of usage. In addition to improving human readability, we find that AutoDoc boosts performance by helping LILO's synthesizer to interpret and deploy learned abstractions. We evaluate LILO on three inductive program synth
    
[^170]: CLIP的泛化性能主要源于训练-测试之间的高相似性吗？

    Does CLIP's Generalization Performance Mainly Stem from High Train-Test Similarity?

    [https://arxiv.org/abs/2310.09562](https://arxiv.org/abs/2310.09562)

    CLIP在经过重现ImageNet训练-测试相似性的剪枝LAION分割重新训练后，虽然在某些基准上表现有所下降，但整体性能仍然很高

    

    基于 CLIP 等基础模型被训练在数亿样本上，能够轻松泛化到新任务和输入。CLIP 出色地展示了在广泛的超出分布（OOD）基准上的零样本和少样本能力，而先前的研究主要将其归因于当今的大规模和全面的训练数据集（如 LAION）。然而，对于 CLIP 来说，像超出分布泛化这样的术语是否具有意义是值得怀疑的，因为像 LAION 这样的网页规模数据集可能只是包含许多与最初为 ImageNet 设计的常见 OOD 基准相似的样本。为了测试这一假设，我们在复制 ImageNet 的训练-测试相似性相对于常见 OOD 基准的剪枝 LAION 分割上重新训练 CLIP。虽然我们观察到在一些基准上的性能下降，但令人惊讶的是，CLIP 的整体性能仍然很高。这表明高训练-测试相似性是不足以...

    arXiv:2310.09562v2 Announce Type: replace-cross  Abstract: Foundation models like CLIP are trained on hundreds of millions of samples and effortlessly generalize to new tasks and inputs. Out of the box, CLIP shows stellar zero-shot and few-shot capabilities on a wide range of out-of-distribution (OOD) benchmarks, which prior works attribute mainly to today's large and comprehensive training dataset (like LAION). However, it is questionable how meaningful terms like out-of-distribution generalization are for CLIP as it seems likely that web-scale datasets like LAION simply contain many samples that are similar to common OOD benchmarks originally designed for ImageNet. To test this hypothesis, we retrain CLIP on pruned LAION splits that replicate ImageNet's train-test similarity with respect to common OOD benchmarks. While we observe a performance drop on some benchmarks, surprisingly, CLIP's overall performance remains high. This shows that high train-test similarity is insufficient to 
    
[^171]: 机器遗忘：解决方案与挑战

    Machine Unlearning: Solutions and Challenges

    [https://arxiv.org/abs/2308.07061](https://arxiv.org/abs/2308.07061)

    本文提供了对机器遗忘解决方案的全面分类和分析，明确了完全遗忘方法和近似遗忘方法，并讨论了它们的优势和局限性，提出了推进机器遗忘的未来方向。

    

    机器学习模型可能无意中记住敏感、未经授权或恶意数据，存在隐私泄露、安全漏洞和性能降级的风险。为了解决这些问题，机器遗忘已经成为一种重要的技术，可以有选择地消除特定训练数据点对训练模型的影响。本文对机器遗忘中的解决方案进行了全面分类和分析。我们将现有解决方案分为完全遗忘方法和有效减少数据影响的近似遗忘方法。通过全面回顾解决方案，我们确定并讨论它们的优势和局限性。此外，我们提出了未来的发展方向，以推进机器遗忘并将其建立为值得信赖和适应性机器学习模型的重要能力。本文为研究人员提供了一份路线图。

    arXiv:2308.07061v2 Announce Type: replace-cross  Abstract: Machine learning models may inadvertently memorize sensitive, unauthorized, or malicious data, posing risks of privacy breaches, security vulnerabilities, and performance degradation. To address these issues, machine unlearning has emerged as a critical technique to selectively remove specific training data points' influence on trained models. This paper provides a comprehensive taxonomy and analysis of the solutions in machine unlearning. We categorize existing solutions into exact unlearning approaches that remove data influence thoroughly and approximate unlearning approaches that efficiently minimize data influence. By comprehensively reviewing solutions, we identify and discuss their strengths and limitations. Furthermore, we propose future directions to advance machine unlearning and establish it as an essential capability for trustworthy and adaptive machine learning models. This paper provides researchers with a roadmap
    
[^172]: 使用图神经网络理解JSON数据中的语义类型

    Comprehending Semantic Types in JSON Data with Graph Neural Networks

    [https://arxiv.org/abs/2307.12807](https://arxiv.org/abs/2307.12807)

    提出了一种使用图神经网络在JSON数据中标记语义类型的方法

    

    语义类型是一种比原子类型（如字符串或整数）更强大和详细的描述数据的方式。它们在列之间和与现实世界概念之间建立连接，提供了更加细致和精细的信息，对于自动化数据清洗、模式匹配和数据发现等任务非常有用。已有的在大文本语料库上训练的深度学习模型已成功地实现了关系数据的单列语义类型预测。然而，在这项工作中，我们提出了将语义类型预测问题扩展到JSON数据的方法，根据JSON路径为类型进行标记。与关系数据中的列类似，JSON路径是一种查询语言，通过指定元素的位置和内容，实现对复杂JSON数据结构的导航。我们使用图神经网络理解JSON文档集合中的结构信息。

    arXiv:2307.12807v1 Announce Type: cross  Abstract: Semantic types are a more powerful and detailed way of describing data than atomic types such as strings or integers. They establish connections between columns and concepts from the real world, providing more nuanced and fine-grained information that can be useful for tasks such as automated data cleaning, schema matching, and data discovery. Existing deep learning models trained on large text corpora have been successful at performing single-column semantic type prediction for relational data. However, in this work, we propose an extension of the semantic type prediction problem to JSON data, labeling the types based on JSON Paths. Similar to columns in relational data, JSON Path is a query language that enables the navigation of complex JSON data structures by specifying the location and content of the elements. We use a graph neural network to comprehend the structural information within collections of JSON documents. Our model out
    
[^173]: 具有原型的跨领域随机预训练用于强化学习

    Cross-domain Random Pre-training with Prototypes for Reinforcement Learning

    [https://arxiv.org/abs/2302.05614](https://arxiv.org/abs/2302.05614)

    提出了CRPTpro框架，利用原型进行跨领域自监督随机预训练，提高预训练效率，并实现在不同领域中定义的视觉控制RL任务。

    

    此工作已提交给IEEE进行可能的出版。 CRPTpro提出了一种用于基于图像的RL的跨领域自监督随机预训练框架，利用原型。 CRPTpro采用了跨领域随机策略，可以轻松快速地从多个领域中抽样多样化数据，以提高预训练效率。此外，通过提出一种新颖的内在损失进行原型表示学习，以在不同领域中预训练有效且通用的编码器。在没有微调的情况下，跨领域编码器可以高效地应用于不同领域中定义的具有挑战性的下游视觉控制RL任务。 与以前的方法如APT和Proto-RL相比，CRP

    arXiv:2302.05614v2 Announce Type: replace-cross  Abstract: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Task-agnostic cross-domain pre-training shows great potential in image-based Reinforcement Learning (RL) but poses a big challenge. In this paper, we propose CRPTpro, a Cross-domain self-supervised Random Pre-Training framework with prototypes for image-based RL. CRPTpro employs cross-domain random policy to easily and quickly sample diverse data from multiple domains, to improve pre-training efficiency. Moreover, prototypical representation learning with a novel intrinsic loss is proposed to pre-train an effective and generic encoder across different domains. Without finetuning, the cross-domain encoder can be implemented for challenging downstream visual-control RL tasks defined in different domains efficiently. Compared with prior arts like APT and Proto-RL, CRP
    
[^174]: 基于传感器增强快挂的朝向的攀岩中下降行为的检测

    Lowering Detection in Sport Climbing Based on Orientation of the Sensor Enhanced Quickdraw

    [https://arxiv.org/abs/2301.10164](https://arxiv.org/abs/2301.10164)

    通过在攀岩快挂上安装的加速度传感器采集数据，实现了在攀岩活动中检测攀岩者下降情况的技术，保护攀岩者隐私和健身房成本的同时提高了效率和便利性。

    

    跟踪攀岩者的活动以改善服务并最大限度地利用他们的基础设施是攀岩健身房关注的焦点。必须从开始分析每个攀岩活动直到攀登者降下来。因此，发现攀岩者下降是至关重要的，因为这标志着攀登结束。必须在保护攀岩者和健身房成本隐私和便利性的同时解决这个问题。为此，开发了一个硬件原型，使用附在墙上的攀岩设备上的加速度传感器收集数据，称为快挂，它连接攀岩绳和螺栓锚点。相应的传感器被配置为节能，因此在攀岩健身房大量使用时在费用和更换所需时间方面变得实用。本文描述了硬件规格，并研究了传感器测得的数据。

    arXiv:2301.10164v2 Announce Type: replace-cross  Abstract: Tracking climbers' activity to improve services and make the best use of their infrastructure is a concern for climbing gyms. Each climbing session must be analyzed from beginning till lowering of the climber. Therefore, spotting the climbers descending is crucial since it indicates when the ascent has come to an end. This problem must be addressed while preserving privacy and convenience of the climbers and the costs of the gyms. To this aim, a hardware prototype is developed to collect data using accelerometer sensors attached to a piece of climbing equipment mounted on the wall, called quickdraw, that connects the climbing rope to the bolt anchors. The corresponding sensors are configured to be energy-efficient, hence become practical in terms of expenses and time consumption for replacement when using in large quantity in a climbing gym. This paper describes hardware specifications, studies data measured by the sensors in u
    
[^175]: 将隐式和显式几何变换桥接用于单图像视图合成

    Bridging Implicit and Explicit Geometric Transformation for Single-Image View Synthesis

    [https://arxiv.org/abs/2209.07105](https://arxiv.org/abs/2209.07105)

    提出了一种单图像视图合成框架，通过结合显式和隐式的几何变换，利用高效的非自回归模型，解决了“跷跷板”问题。

    

    用先进的自回归模型从单个图像中创建新视图已经取得了巨大进展，因为不可见区域必须从可见场景内容中推断出来。尽管最近的方法生成了高质量的新视图，但只使用一个显式或隐式的3D几何体进行合成存在两个目标之间的折衷，我们称之为“跷跷板”问题：1）保留重新投影的内容，2）完成逼真的视野之外区域。此外，自回归模型需要相当大的计算成本。在本文中，我们提出了一个单图像视图合成框架，用于缓解“跷跷板”问题，同时利用高效的非自回归模型。受到显式方法很好地保留重新投影像素和隐式方法完成逼真视野外区域的特点的启发，我们引入了一个损失函数来补充两个渲染器。我们的损失函数促进了显式特征

    arXiv:2209.07105v3 Announce Type: replace-cross  Abstract: Creating novel views from a single image has achieved tremendous strides with advanced autoregressive models, as unseen regions have to be inferred from the visible scene contents. Although recent methods generate high-quality novel views, synthesizing with only one explicit or implicit 3D geometry has a trade-off between two objectives that we call the "seesaw" problem: 1) preserving reprojected contents and 2) completing realistic out-of-view regions. Also, autoregressive models require a considerable computational cost. In this paper, we propose a single-image view synthesis framework for mitigating the seesaw problem while utilizing an efficient non-autoregressive model. Motivated by the characteristics that explicit methods well preserve reprojected pixels and implicit methods complete realistic out-of-view regions, we introduce a loss function to complement two renderers. Our loss function promotes that explicit features 
    
[^176]: 具有结构化提示的持续问答学习

    Continuous QA Learning with Structured Prompts

    [https://arxiv.org/abs/2208.14602](https://arxiv.org/abs/2208.14602)

    提出了一种名为Diana的动态架构终身QA模型，通过增强语言模型学习一系列QA任务，并使用四种层次组织的提示来捕获不同粒度的QA知识，以提高模型的泛化性能。

    

    具有终身学习（LL）能力的QA模型对于实际的QA应用至关重要，并且基于架构的LL方法被报告为这些模型的有效实现。然而，将先前的方法扩展到QA任务并不是一件简单的事情，因为它们要么在测试阶段需要访问任务标识，要么不明确地对来自未见任务的样本进行建模。在本文中，我们提出了Diana：一种基于动态架构的终身QA模型，试图通过增强语言模型学习一系列QA任务。在Diana中使用了四种层次组织的提示来捕获不同粒度的QA知识。具体来说，我们将任务级提示用于捕获任务特定知识，以保持高LL性能，并保持实例级提示来学习跨不同输入样本共享的知识以提高模型的泛化性能。

    arXiv:2208.14602v3 Announce Type: replace-cross  Abstract: QA models with lifelong learning (LL) abilities are important for practical QA applications, and architecture-based LL methods are reported to be an effective implementation for these models. However, it is non-trivial to extend previous approaches to QA tasks since they either require access to task identities in the testing phase or do not explicitly model samples from unseen tasks. In this paper, we propose Diana: a dynamic architecture-based lifelong QA model that tries to learn a sequence of QA tasks with a prompt enhanced language model. Four types of hierarchically organized prompts are used in Diana to capture QA knowledge from different granularities. Specifically, we dedicate task-level prompts to capture task-specific knowledge to retain high LL performances and maintain instance-level prompts to learn knowledge shared across different input samples to improve the model's generalization performance. Moreover, we dedi
    
[^177]: 使用自然语言处理从阿尔茨海默病患者的临床记录中提取睡眠信息

    Extraction of Sleep Information from Clinical Notes of Patients with Alzheimer's Disease Using Natural Language Processing

    [https://arxiv.org/abs/2204.09601](https://arxiv.org/abs/2204.09601)

    通过自然语言处理从临床记录中提取睡眠信息，为研究睡眠与阿尔茨海默病发病关联提供了新的方法和工具

    

    Alzheimer's Disease（AD）是美国最常见的痴呆形式，睡眠是影响老年认知功能最关键的生活方式因素之一。然而，研究睡眠与AD发病之间关联的研究匮乏。本研究通过手动注释UPMC收集的7,266名AD患者的192,000份临床记录中的随机抽样文档，创建了金标准数据集。我们开发了基于规则的自然语言处理（NLP）算法、机器学习模型和基于大型语言模型（LLM）的NLP算法，以自动化提取睡眠相关信息。

    arXiv:2204.09601v2 Announce Type: replace-cross  Abstract: Alzheimer's Disease (AD) is the most common form of dementia in the United States. Sleep is one of the lifestyle-related factors that has been shown critical for optimal cognitive function in old age. However, there is a lack of research studying the association between sleep and AD incidence. A major bottleneck for conducting such research is that the traditional way to acquire sleep information is time-consuming, inefficient, non-scalable, and limited to patients' subjective experience. A gold standard dataset is created from manual annotation of 570 randomly sampled clinical note documents from the adSLEEP, a corpus of 192,000 de-identified clinical notes of 7,266 AD patients retrieved from the University of Pittsburgh Medical Center (UPMC). We developed a rule-based Natural Language Processing (NLP) algorithm, machine learning models, and Large Language Model(LLM)-based NLP algorithms to automate the extraction of sleep-rel
    
[^178]: MMO: 元多目标化用于软件配置调整

    MMO: Meta Multi-Objectivization for Software Configuration Tuning

    [https://arxiv.org/abs/2112.07303](https://arxiv.org/abs/2112.07303)

    提出了一种元多目标化（MMO）模型，将辅助性能目标用于使表现相似但配置不同的配置难以比较，从而防止搜索陷入局部最优解

    

    软件配置调整对于优化给定的性能目标（例如最小化延迟）至关重要。然而，由于软件固有的复杂配置景观和昂贵的测量，取得了相对较为温和的成功，特别是在防止搜索陷入局部最优解方面。为了解决这个问题，本文采用了不同的视角。我们不是专注于改进优化器，而是在优化模型的层面上进行工作，并提出了一种考虑辅助性能目标（例如吞吐量）的元多目标化（MMO）模型。这个模型的独特之处在于，我们并不优化辅助性能目标，而是利用它使表现相似但配置不同的配置难以比较（即彼此之间是帕累托非支配的），从而防止搜索陷入局部最优解。

    arXiv:2112.07303v3 Announce Type: replace-cross  Abstract: Software configuration tuning is essential for optimizing a given performance objective (e.g., minimizing latency). Yet, due to the software's intrinsically complex configuration landscape and expensive measurement, there has been a rather mild success, particularly in preventing the search from being trapped in local optima. To address this issue, in this paper we take a different perspective. Instead of focusing on improving the optimizer, we work on the level of optimization model and propose a meta multi-objectivization (MMO) model that considers an auxiliary performance objective (e.g., throughput in addition to latency). What makes this model distinct is that we do not optimize the auxiliary performance objective, but rather use it to make similarly-performing while different configurations less comparable (i.e. Pareto nondominated to each other), thus preventing the search from being trapped in local optima. Importantly,
    
[^179]: 学习马尔可夫状态抽象以用于深度强化学习

    Learning Markov State Abstractions for Deep Reinforcement Learning

    [https://arxiv.org/abs/2106.04379](https://arxiv.org/abs/2106.04379)

    引入了一组新颖条件，证明了学习马尔可夫抽象状态表示的充分性，并提出了结合逆模型估计和时间对比学习的实用训练过程，该方法适用于在线和离线训练，不依赖奖励信号但可以利用奖励信息。

    

    强化学习在马尔可夫决策过程（MDPs）中的一个基本假设是，相关的决策过程实际上是马尔可夫的。然而，当MDPs具有丰富的观测时，代理通常通过抽象状态表示学习，这种表示未必能保持马尔可夫性质。我们引入了一组新颖的条件，并证明它们足以学习马尔可夫抽象状态表示。然后，我们描述了一个实用的训练过程，结合了逆模型估计和时间对比学习，以学习一个近似满足这些条件的抽象。我们的新颖训练目标适用于在线和离线训练：它不需要奖励信号，但当可用时，代理可以利用奖励信息。我们在一个视觉格子世界域和一组连续控制基准任务上对我们的方法进行了实证评估。

    arXiv:2106.04379v4 Announce Type: replace-cross  Abstract: A fundamental assumption of reinforcement learning in Markov decision processes (MDPs) is that the relevant decision process is, in fact, Markov. However, when MDPs have rich observations, agents typically learn by way of an abstract state representation, and such representations are not guaranteed to preserve the Markov property. We introduce a novel set of conditions and prove that they are sufficient for learning a Markov abstract state representation. We then describe a practical training procedure that combines inverse model estimation and temporal contrastive learning to learn an abstraction that approximately satisfies these conditions. Our novel training objective is compatible with both online and offline training: it does not require a reward signal, but agents can capitalize on reward information when available. We empirically evaluate our approach on a visual gridworld domain and a set of continuous control benchmar
    
[^180]: 基于能量的自动化模型评估

    Energy-based Automated Model Evaluation. (arXiv:2401.12689v1 [cs.LG])

    [http://arxiv.org/abs/2401.12689](http://arxiv.org/abs/2401.12689)

    提出了一种基于能量的自动化模型评估方法，通过建立关于个体样本相关信息的元分布统计量，能够更高效和有效地评估机器学习模型的性能，解决了AutoEval框架中的过度自信、存储和计算成本高等问题。

    

    传统的机器学习模型评估协议依赖于标记的、假设独立同分布的测试数据集，而这在实际应用中往往并不常见。自动模型评估（AutoEval）提出了一种替代传统工作流程的方法，通过形成一个接近预测性能的测试管线，而无需真实标签的存在。尽管AutoEval框架近年来取得了一些成功，但仍存在过度自信、存储和计算成本高的问题。因此，我们提出了一种新颖的度量方式——元分布能量（MDE），它可以使AutoEval框架更加高效和有效。MDE的核心是建立一个关于个体样本相关信息（能量）的元分布统计量，然后通过基于能量的学习提供更平滑的表示能力。我们通过将MDE与分类损失相连接，进一步提供了理论洞见。我们还提供了大量实验证据来验证我们的方法。

    The conventional evaluation protocols on machine learning models rely heavily on a labeled, i.i.d-assumed testing dataset, which is not often present in real world applications. The Automated Model Evaluation (AutoEval) shows an alternative to this traditional workflow, by forming a proximal prediction pipeline of the testing performance without the presence of ground-truth labels. Despite its recent successes, the AutoEval frameworks still suffer from an overconfidence issue, substantial storage and computational cost. In that regard, we propose a novel measure -- Meta-Distribution Energy (MDE) -- that allows the AutoEval framework to be both more efficient and effective. The core of the MDE is to establish a meta-distribution statistic, on the information (energy) associated with individual samples, then offer a smoother representation enabled by energy-based learning. We further provide our theoretical insights by connecting the MDE with the classification loss. We provide extensive
    
[^181]: 重访大语言模型时代下的零-shot 抽象摘要，从位置偏见的角度出发

    Revisiting Zero-Shot Abstractive Summarization in the Era of Large Language Models from the Perspective of Position Bias. (arXiv:2401.01989v1 [cs.CL])

    [http://arxiv.org/abs/2401.01989](http://arxiv.org/abs/2401.01989)

    这项研究通过测量位置偏见，重访了大语言模型中的零-shot 抽象摘要。研究结果揭示了模型不公平地优先考虑某些部分的信息，从而导致不可取的行为。对多个LLM模型和预训练抽象摘要模型进行的实验提供了关于零-shot 总结任务的模型性能和位置偏见的新见解和讨论。

    

    我们通过测量位置偏见来表征和研究大型语言模型（LLMs）中的零-shot 抽象摘要，我们将其视为先前文献中研究过的更为限制性的引导偏见现象的一般表述。位置偏见捕捉到模型在输入文本的某些部分上不公平地优先考虑信息，导致不可取的行为。通过对四个不同的真实数据集进行大量实验，我们研究了多个LLM模型如GPT 3.5-Turbo，Llama-2和Dolly-v2中的位置偏见，以及当前最先进的预训练编码器-解码器抽象摘要模型如Pegasus和BART。我们的发现为零-shot 总结任务的模型性能和位置偏见提供了新的见解和讨论。

    We characterize and study zero-shot abstractive summarization in Large Language Models (LLMs) by measuring position bias, which we propose as a general formulation of the more restrictive lead bias phenomenon studied previously in the literature. Position bias captures the tendency of a model unfairly prioritizing information from certain parts of the input text over others, leading to undesirable behavior. Through numerous experiments on four diverse real-world datasets, we study position bias in multiple LLM models such as GPT 3.5-Turbo, Llama-2, and Dolly-v2, as well as state-of-the-art pretrained encoder-decoder abstractive summarization models such as Pegasus and BART. Our findings lead to novel insights and discussion on performance and position bias of models for zero-shot summarization tasks.
    
[^182]: 扩散模型的数据归因的有趣特性

    Intriguing Properties of Data Attribution on Diffusion Models. (arXiv:2311.00500v1 [cs.LG])

    [http://arxiv.org/abs/2311.00500](http://arxiv.org/abs/2311.00500)

    本研究通过对扩散模型进行实验和分析，发现在数据归因方面，一些在理论上不合理的设计选择能够在实际中表现出比以前的方法更好的效果。这对于确保数据贡献者公平补偿或认可具有重要意义。

    

    数据归因旨在将模型输出追溯到训练数据。随着扩散模型的最新发展，数据归因已成为一个理想的模块，可以为高质量或版权保护的训练样本正确分配价值，确保数据贡献者得到公平的补偿或认可。已经提出了几种在理论上有动机的方法来实现数据归因，以改善计算可扩展性和效果之间的权衡。在这项工作中，我们对扩散模型进行了广泛的实验和消融研究，特别关注在CIFAR-10和CelebA上训练的DDPM以及在ArtBench上进行细调的稳定扩散模型LoRA的归因。有趣的是，我们报告了理论上不合理的设计选择在实际中大幅超越了以前的基线，无论是在线性数据建模得分还是反事实评估方面。我们的工作呈现了一个重要的创新点。

    Data attribution seeks to trace model outputs back to training data. With the recent development of diffusion models, data attribution has become a desired module to properly assign valuations for high-quality or copyrighted training samples, ensuring that data contributors are fairly compensated or credited. Several theoretically motivated methods have been proposed to implement data attribution, in an effort to improve the trade-off between computational scalability and effectiveness. In this work, we conduct extensive experiments and ablation studies on attributing diffusion models, specifically focusing on DDPMs trained on CIFAR-10 and CelebA, as well as a Stable Diffusion model LoRA-finetuned on ArtBench. Intriguingly, we report counter-intuitive observations that theoretically unjustified design choices for attribution empirically outperform previous baselines by a large margin, in terms of both linear datamodeling score and counterfactual evaluation. Our work presents a signific
    
[^183]: 通过模型适应来去除偏见算法

    Debiasing Algorithm through Model Adaptation. (arXiv:2310.18913v1 [cs.CL])

    [http://arxiv.org/abs/2310.18913](http://arxiv.org/abs/2310.18913)

    本论文提出了一种通过模型适应来检测和减轻语言模型中性别偏见的方法，并证明了该方法能够显著减少偏见同时保持模型性能。

    

    大型语言模型正在成为各种语言任务的首选解决方案。然而，随着容量的增长，模型很容易依赖训练数据中存在的偏见和刻板印象所产生的虚假相关性。本研究提出了一种新颖的方法来检测和减轻语言模型中的性别偏见。我们进行因果分析，以识别问题模型组件，并发现中上层前馈层最容易传递偏见。根据分析结果，我们通过线性投影将这些层乘以模型进行适应。我们的方法DAMA通过各种度量指标明显减少了偏见，同时保持模型在后续任务中的性能。我们发布了我们的方法和模型的代码，通过重新训练，保持了LLaMA的最先进性能，同时偏见显著减少。

    Large language models are becoming the go-to solution for various language tasks. However, with growing capacity, models are prone to rely on spurious correlations stemming from biases and stereotypes present in the training data. This work proposes a novel method for detecting and mitigating gender bias in language models. We perform causal analysis to identify problematic model components and discover that mid-upper feed-forward layers are most prone to convey biases. Based on the analysis results, we adapt the model by multiplying these layers by a linear projection. Our titular method, DAMA, significantly decreases bias as measured by diverse metrics while maintaining the model's performance on downstream tasks. We release code for our method and models, which retrain LLaMA's state-of-the-art performance while being significantly less biased.
    
[^184]: DyST：面向实际视频的动态神经场景表示

    DyST: Towards Dynamic Neural Scene Representations on Real-World Videos. (arXiv:2310.06020v1 [cs.CV])

    [http://arxiv.org/abs/2310.06020](http://arxiv.org/abs/2310.06020)

    DyST模型通过学习动态场景的潜在分解，从实际视频中捕捉到了场景的3D结构和动态特性，并实现了对相机和场景内容的独立控制视图生成。

    

    对世界的视觉理解超越了单个图像的语义和平面结构。我们的目标是从单目实际视频中捕捉到实际场景的3D结构和动态特性。我们的Dynamic Scene Transformer（DyST）模型利用了最近的神经场景表示研究成果，学习了单目实际视频的潜在分解，包括场景内容、每个视角的场景动态和相机姿态。通过在单目视频和我们的新的合成数据集DySO上进行一种新颖的协同训练，实现了这种分离。DyST学习到了动态场景的具体潜在表示，使得可以对场景的相机和内容进行独立控制的视图生成成为可能。

    Visual understanding of the world goes beyond the semantics and flat structure of individual images. In this work, we aim to capture both the 3D structure and dynamics of real-world scenes from monocular real-world videos. Our Dynamic Scene Transformer (DyST) model leverages recent work in neural scene representation to learn a latent decomposition of monocular real-world videos into scene content, per-view scene dynamics, and camera pose. This separation is achieved through a novel co-training scheme on monocular videos and our new synthetic dataset DySO. DyST learns tangible latent representations for dynamic scenes that enable view generation with separate control over the camera and the content of the scene.
    
[^185]: Neur2RO: 神经二阶段鲁棒优化

    Neur2RO: Neural Two-Stage Robust Optimization. (arXiv:2310.04345v1 [math.OC])

    [http://arxiv.org/abs/2310.04345](http://arxiv.org/abs/2310.04345)

    Neur2RO是一种神经网络驱动的二阶段鲁棒优化算法，通过学习估计第二阶段问题的值函数，并嵌入到经典的列-约束生成算法中，能够高效地求解嵌套的最小-最大-最小优化问题。

    

    鲁棒优化提供了一个数学框架，用于在最坏情况下的不确定性下建模和解决决策问题。本工作解决了二阶段鲁棒优化（也称为可调整鲁棒优化）问题，在不确定性实现之前和之后进行第一阶段和第二阶段的决策。这导致了一个嵌套的最小-最大-最小优化问题，从计算上来说是非常具有挑战性的，尤其是当决策是离散的时候。我们提出了Neur2RO，这是一种高效的基于机器学习的列-约束生成（CCG）的实例算法，CCG是二阶段鲁棒优化的经典迭代算法。具体而言，我们通过一种新颖的神经网络架构来学习估计第二阶段问题的值函数，这种架构易于优化。将我们的神经网络嵌入到CCG算法中，可以快速得到高质量的解，这在两个二阶段鲁棒优化基准测试（背包问题和资本预算）的实验证明了。

    Robust optimization provides a mathematical framework for modeling and solving decision-making problems under worst-case uncertainty. This work addresses two-stage robust optimization (2RO) problems (also called adjustable robust optimization), wherein first-stage and second-stage decisions are made before and after uncertainty is realized, respectively. This results in a nested min-max-min optimization problem which is extremely challenging computationally, especially when the decisions are discrete. We propose Neur2RO, an efficient machine learning-driven instantiation of column-and-constraint generation (CCG), a classical iterative algorithm for 2RO. Specifically, we learn to estimate the value function of the second-stage problem via a novel neural network architecture that is easy to optimize over by design. Embedding our neural network into CCG yields high-quality solutions quickly as evidenced by experiments on two 2RO benchmarks, knapsack and capital budgeting. For knapsack, Ne
    
[^186]: SNIP: 用统一的预训练框架连接数学符号和数值领域

    SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training. (arXiv:2310.02227v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.02227](http://arxiv.org/abs/2310.02227)

    SNIP引入了一种统一的预训练框架，通过联合对比学习加强了符号和数值领域之间的相似性，并提供了跨领域的表示洞察力。

    

    在一个无法缺少符号数学方程来建模复杂自然现象的时代，科学探究往往涉及到收集观察数据并将其转化为数学表达式。最近，深度学习已经成为从数据中提取洞察力的强大工具。然而，现有模型通常特化于数值领域或符号领域，并且通常在为特定任务量身定制的监督式训练中进行训练。这种方法忽视了符号方程和其数值对应物之间可能产生的重大好处。为了弥合这种差距，我们引入了SNIP，一种符号-数值集成预训练的方法，它通过在符号和数值领域之间进行联合对比学习，增强了它们在预训练嵌入中的相互相似性。通过进行潜空间分析，我们观察到SNIP提供了跨领域的表示洞察力，揭示了符号和数值之间的关联关系。

    In an era where symbolic mathematical equations are indispensable for modeling complex natural phenomena, scientific inquiry often involves collecting observations and translating them into mathematical expressions. Recently, deep learning has emerged as a powerful tool for extracting insights from data. However, existing models typically specialize in either numeric or symbolic domains, and are usually trained in a supervised manner tailored to specific tasks. This approach neglects the substantial benefits that could arise from a task-agnostic unified understanding between symbolic equations and their numeric counterparts. To bridge the gap, we introduce SNIP, a Symbolic-Numeric Integrated Pre-training, which employs joint contrastive learning between symbolic and numeric domains, enhancing their mutual similarities in the pre-trained embeddings. By performing latent space analysis, we observe that SNIP provides cross-domain insights into the representations, revealing that symbolic 
    
[^187]: JoMA: 通过MLP和注意力的联合动力学来解密多层Transformer

    JoMA: Demystifying Multilayer Transformers via JOint Dynamics of MLP and Attention. (arXiv:2310.00535v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.00535](http://arxiv.org/abs/2310.00535)

    本文提出了联合MLP/注意力（JoMA）动态，用于解析多层Transformer架构的训练过程。通过预测非线性激活情况下注意力的行为，我们解释了多层Transformer中标记的层次组合方法。实验证实了我们的理论发现。

    

    我们提出了联合MLP/注意力（JoMA）动态，这是一种新颖的数学框架，用于理解多层Transformer架构的训练过程。通过在Transformer中去除自注意力层，我们得到仅包含MLP层的修改后动态。JoMA消除了先前分析中的不切实际的假设（例如缺乏残差连接），并预测注意力在非线性激活的情况下首先变得稀疏（为了学习重要的标记），然后变得密集（为了学习不那么重要的标记），而在线性情况下，它与现有研究一致，显示出注意力随时间变得稀疏。我们利用JoMA定性地解释了多层Transformer中如何将标记组合成层次结构，当输入标记是由潜在的层次生成模型生成时。在从现实世界数据集（Wikitext2/Wikitext103）训练的模型和各种预训练模型（OPT，Pythia）上进行的实验证实了我们的理论发现。

    We propose Joint MLP/Attention (JoMA) dynamics, a novel mathematical framework to understand the training procedure of multilayer Transformer architectures. This is achieved by integrating out the self-attention layer in Transformers, producing a modified dynamics of MLP layers only. JoMA removes unrealistic assumptions in previous analysis (e.g., lack of residual connection) and predicts that the attention first becomes sparse (to learn salient tokens), then dense (to learn less salient tokens) in the presence of nonlinear activations, while in the linear case, it is consistent with existing works that show attention becomes sparse over time. We leverage JoMA to qualitatively explains how tokens are combined to form hierarchies in multilayer Transformers, when the input tokens are generated by a latent hierarchical generative model. Experiments on models trained from real-world dataset (Wikitext2/Wikitext103) and various pre-trained models (OPT, Pythia) verify our theoretical findings
    
[^188]: 使用DeepRepViz来识别基于深度学习模型预测中的混淆因素

    Identifying confounders in deep-learning-based model predictions using DeepRepViz. (arXiv:2309.15551v1 [cs.LG])

    [http://arxiv.org/abs/2309.15551](http://arxiv.org/abs/2309.15551)

    这项研究提出了DeepRepViz框架，用于帮助研究人员在深度学习模型预测中识别混淆因素，并通过度量和可视化工具来解决这个问题。实验证明使用DeepRepViz与DL模型结合能够带来明显的益处。

    

    越来越多地使用深度学习模型分析神经影像数据，揭示大脑、大脑病理和心理特征的见解。然而，诸如参与者年龄、性别或影像伪影等外部的“混淆因素”变量可能会偏导致模型预测，从而阻碍模型学习相关的脑-表型关系。在本研究中，我们提出了一种名为“DeepRepViz”的解决方案，使研究人员能够系统地检测DL模型预测中的混淆因素。该框架包括(1)度量可能混淆因素的影响程度的指标和(2)允许研究人员定性检查DL模型学习内容的可视化工具。通过在模拟和神经影像数据集上进行实验证明了使用DeepRepViz与DL模型结合的益处。例如，神经影像数据集的实验揭示了性别是DL模型预测中的一个显著混淆因素。

    Deep Learning (DL) models are increasingly used to analyze neuroimaging data and uncover insights about the brain, brain pathologies, and psychological traits. However, extraneous `confounders' variables such as the age of the participants, sex, or imaging artifacts can bias model predictions, preventing the models from learning relevant brain-phenotype relationships. In this study, we provide a solution called the `DeepRepViz' framework that enables researchers to systematically detect confounders in their DL model predictions. The framework consists of (1) a metric that quantifies the effect of potential confounders and (2) a visualization tool that allows researchers to qualitatively inspect what the DL model is learning. By performing experiments on simulated and neuroimaging datasets, we demonstrate the benefits of using DeepRepViz in combination with DL models. For example, experiments on the neuroimaging datasets reveal that sex is a significant confounder in a DL model predicti
    
[^189]: 转移气候变化知识

    Transferring climate change knowledge. (arXiv:2309.14780v1 [physics.ao-ph])

    [http://arxiv.org/abs/2309.14780](http://arxiv.org/abs/2309.14780)

    通过转移学习方法，研究表明机器学习，尤其是深度神经网络，可以通过充分利用地球系统模型模拟和历史观测所获得的知识，更准确地预测21世纪的全球表面温度场。

    

    准确的气候预测对于气候适应和减缓至关重要。用于预测气候变化的地球系统模型模拟在对小尺度物理过程（例如云）的表示中本质上进行了近似，这是全球平均温度对增加的温室气体浓度的响应中不确定性的根源。已经开发了多种方法，用于使用历史观测约束未来预测，并减少气候预测和气候反馈的不确定性。然而，这些方法无法捕捉气候系统固有的非线性复杂性。通过使用转移学习方法，我们展示了机器学习，特别是深度神经网络，可以用于最大程度地利用和整合从地球系统模型模拟和历史观测中获得的知识，以更准确地预测21世纪全球表面温度场。

    Accurate climate projections are required for climate adaptation and mitigation. Earth system model simulations, used to project climate change, inherently make approximations in their representation of small-scale physical processes, such as clouds, that are at the root of the uncertainties in global mean temperature's response to increased greenhouse gas concentrations. Several approaches have been developed to use historical observations to constrain future projections and reduce uncertainties in climate projections and climate feedbacks. Yet those methods cannot capture the non-linear complexity inherent in the climate system. Using a Transfer Learning approach, we show that Machine Learning, in particular Deep Neural Networks, can be used to optimally leverage and merge the knowledge gained from Earth system model simulations and historical observations to more accurately project global surface temperature fields in the 21st century. For the Shared Socioeconomic Pathways (SSPs) 2-
    
[^190]: 旅行波编码最近的过去并增强序列学习

    Traveling Waves Encode the Recent Past and Enhance Sequence Learning. (arXiv:2309.08045v1 [cs.NE])

    [http://arxiv.org/abs/2309.08045](http://arxiv.org/abs/2309.08045)

    本论文介绍了Wave-RNN (wRNN)模型，展示了旅行波机制如何有效地编码最近的过去，并在合成记忆任务中比波动模型表现更好。

    

    神经活动的旅行波现象在大脑的不同区域和尺度上都有所观察到，然而，它们在计算角色上的具体作用仍存在争议。一个基于物理的假设认为，皮质层可以像波动场一样，通过沿着皮质表面传播的波动来存储顺序刺激的短期记忆。然而，由于缺乏一个简单的递归神经网络架构能够展现出这种波动，迄今为止，这个想法的计算意义一直是假设性的。在这项工作中，我们引入了一个模型来填补这个空白，我们称之为Wave-RNN (wRNN)，并展示了连通性约束和初始化在波动动力学出现中起到了关键作用。然后，我们经验证实了这样的架构的确通过一系列合成记忆任务有效地编码了最近的过去，在这些任务中，wRNN比波动模型学习更快、表现更好。

    Traveling waves of neural activity have been observed throughout the brain at a diversity of regions and scales; however, their precise computational role is still debated. One physically grounded hypothesis suggests that the cortical sheet may act like a wave-field capable of storing a short-term memory of sequential stimuli through induced waves traveling across the cortical surface. To date, however, the computational implications of this idea have remained hypothetical due to the lack of a simple recurrent neural network architecture capable of exhibiting such waves. In this work, we introduce a model to fill this gap, which we denote the Wave-RNN (wRNN), and demonstrate how both connectivity constraints and initialization play a crucial role in the emergence of wave-like dynamics. We then empirically show how such an architecture indeed efficiently encodes the recent past through a suite of synthetic memory tasks where wRNNs learn faster and perform significantly better than wave-
    
[^191]: 当地球科学遇见基础模型：走向通用地球科学人工智能系统

    When Geoscience Meets Foundation Models: Towards General Geoscience Artificial Intelligence System. (arXiv:2309.06799v1 [cs.AI])

    [http://arxiv.org/abs/2309.06799](http://arxiv.org/abs/2309.06799)

    地球科学基础模型通过整合大量跨学科数据来模拟和理解地球系统动态，具有广阔的应用前景和创新潜力，但仍面临验证和核实、规模性、可解释性、知识表示和社会偏差等挑战。

    

    地球科学基础模型通过整合大量跨学科数据来模拟和理解地球系统动态，代表了地球科学领域的一种革命性方法。作为一种数据中心的人工智能范式，它们从百万亿字节的结构化和非结构化数据中揭示出洞察力。灵活的任务规范、多样化的输入和输出以及多模态的知识表示使得综合分析成为可能。至关重要的是，地球科学模型的可扩展性和可推广性允许解决与地球系统相互作用相关的多种预测、模拟和决策挑战。领域专家和计算机科学家之间的合作推动了这些宝贵工具在理解我们地球的过去、现在和未来方面的创新。然而，验证和核实、规模性、可解释性、知识表示和社会偏差仍然面临挑战。展望未来，增强验证和核实、规模性、解释性、知识表示和社会偏差方面的能力，将有助于推动地球科学人工智能系统的发展。

    Geoscience foundation models represent a revolutionary approach in the field of Earth sciences by integrating massive cross-disciplinary data to simulate and understand the Earth systems dynamics. As a data-centric artificial intelligence (AI) paradigm, they uncover insights from petabytes of structured and unstructured data. Flexible task specification, diverse inputs and outputs and multi-modal knowledge representation enable comprehensive analysis infeasible with individual data sources. Critically, the scalability and generalizability of geoscience models allow for tackling diverse prediction, simulation, and decision challenges related to Earth systems interactions. Collaboration between domain experts and computer scientists leads to innovations in these invaluable tools for understanding the past, present, and future of our planet. However, challenges remain in validation and verification, scale, interpretability, knowledge representation, and social bias. Going forward, enhanci
    
[^192]: 通过提取精炼的语音和语言情感表示进行语音情感识别

    Speech Emotion Recognition with Distilled Prosodic and Linguistic Affect Representations. (arXiv:2309.04849v1 [cs.CL])

    [http://arxiv.org/abs/2309.04849](http://arxiv.org/abs/2309.04849)

    该论文提出了EmoDistill，这是一个利用知识蒸馏来学习从语音中获取情感的强大的语言和语音表示的语音情感识别框架。通过在训练过程中利用经过SER微调的预训练语音和语言教师进行信息蒸馏，该方法在IEMOCAP基准测试中实现了最新的最高准确率，表明其在单模态和多模态技术中的优越性能。

    

    我们提出了EmoDistill，这是一个新颖的语音情感识别（SER）框架，利用跨模态知识蒸馏来学习从语音中获取情感的强大的语言和语音表示。在推理过程中，我们的方法仅使用一串语音信号来进行单模态SER，从而减少计算开销并避免运行时的转录和语音特征提取错误。在训练过程中，我们的方法从一对经过SER微调的预训练的语音和语言教师中的嵌入和逻辑层面蒸馏信息。在IEMOCAP基准测试中的实验表明，我们的方法在准确率上优于其他单模态和多模态技术，并达到了77.49％的无权重准确率和78.91％的加权准确率的最新成绩。详细的消融研究还展示了我们方法的每个组件的影响。

    We propose EmoDistill, a novel speech emotion recognition (SER) framework that leverages cross-modal knowledge distillation during training to learn strong linguistic and prosodic representations of emotion from speech. During inference, our method only uses a stream of speech signals to perform unimodal SER thus reducing computation overhead and avoiding run-time transcription and prosodic feature extraction errors. During training, our method distills information at both embedding and logit levels from a pair of pre-trained Prosodic and Linguistic teachers that are fine-tuned for SER. Experiments on the IEMOCAP benchmark demonstrate that our method outperforms other unimodal and multimodal techniques by a considerable margin, and achieves state-of-the-art performance of 77.49% unweighted accuracy and 78.91% weighted accuracy. Detailed ablation studies demonstrate the impact of each component of our method.
    
[^193]: 语言代理的认知架构

    Cognitive Architectures for Language Agents. (arXiv:2309.02427v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2309.02427](http://arxiv.org/abs/2309.02427)

    本文提出了一种称为CoALA的认知架构，用于组织语言代理的现有研究并规划未来的发展方向。CoALA描述了一个具有模块化记忆组件、结构化行动空间和通用决策过程的语言代理。通过这一框架，有望发展出更强大的语言代理。

    

    最近的研究在大规模语言模型（LLMs）中增加了外部资源（例如互联网）或内部控制流（例如提示链），用于需要基于语境或推理的任务，从而产生了一类新的语言代理。尽管这些代理取得了实证成功，但我们缺乏一个系统的框架来组织现有代理并规划未来的发展。在本文中，我们借鉴了认知科学和符号人工智能的丰富历史，提出了语言代理的认知架构（CoALA）。CoALA描述了一个具有模块化记忆组件、用于与内部记忆和外部环境交互的结构化行动空间以及选择行动的通用决策过程的语言代理。我们使用CoALA对最近的大量研究进行了回顾和组织，并展望了更强大代理的可行方向。总的来说，CoALA将当今的语言代理置于上下文中。

    Recent efforts have augmented large language models (LLMs) with external resources (e.g., the Internet) or internal control flows (e.g., prompt chaining) for tasks requiring grounding or reasoning, leading to a new class of language agents. While these agents have achieved substantial empirical success, we lack a systematic framework to organize existing agents and plan future developments. In this paper, we draw on the rich history of cognitive science and symbolic artificial intelligence to propose Cognitive Architectures for Language Agents (CoALA). CoALA describes a language agent with modular memory components, a structured action space to interact with internal memory and external environments, and a generalized decision-making process to choose actions. We use CoALA to retrospectively survey and organize a large body of recent work, and prospectively identify actionable directions towards more capable agents. Taken together, CoALA contextualizes today's language agents within th
    
[^194]: 变形金刚是否能学会最大公约数？

    Can transformers learn the greatest common divisor?. (arXiv:2308.15594v1 [cs.LG])

    [http://arxiv.org/abs/2308.15594](http://arxiv.org/abs/2308.15594)

    本文研究了小型变形金刚模型计算最大公约数的能力。通过选择合适的训练分布和表示基准，模型可以达到高准确率，并在预测中表现出明确的模式。

    

    本文研究小型变形金刚模型计算两个正整数的最大公约数（GCD）的能力。当训练分布和表示基准仔细选择时，模型可以达到98%的准确率，并且正确预测前100个GCD中的91个。模型的预测是确定性的，并且完全可解释的。在训练过程中，模型学会将具有相同GCD的输入对聚类，并通过其除数进行分类。基本模型通过使用小型基数编码的均匀操作数仅计算少数GCD（最多100个中的38个）：基数的除数乘积。更长的训练时间和更大的基数允许一些模型“了解”小的素数GCD。使用对数均匀操作数进行训练将性能提升到正确的73个GCD，并通过从倒数平方到对数均匀的GCD训练分布的平衡，使性能达到91个GCD。从GCD的均匀分布进行训练模型破坏了确定性模型行为。

    I investigate the capability of small transformers to compute the greatest common divisor (GCD) of two positive integers. When the training distribution and the representation base are carefully chosen, models achieve 98% accuracy and correctly predict 91 of the 100 first GCD. Model predictions are deterministic and fully interpretable. During training, the models learn to cluster input pairs with the same GCD, and classify them by their divisors. Basic models, trained from uniform operands encoded on small bases, only compute a handful of GCD (up to 38 out of 100): the products of divisors of the base. Longer training and larger bases allow some models to "grok" small prime GCD. Training from log-uniform operands boosts performance to 73 correct GCD, and balancing the training distribution of GCD, from inverse square to log-uniform, to 91 GCD. Training models from a uniform distribution of GCD breaks the deterministic model behavior.
    
[^195]: 将知识蒸馏用于短期到长期轨迹预测

    Distilling Knowledge for Short-to-Long Term Trajectory Prediction. (arXiv:2305.08553v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2305.08553](http://arxiv.org/abs/2305.08553)

    本文提出了一种新的方法Di-Long，用于解决长期轨迹预测中越来越不确定和不可预测的问题。该方法利用蒸馏短期轨迹模型预测器来指导训练过程中的长期轨迹预测学生网络。学生网络观察短序列并预测长轨迹，教师网络观察更长序列并预测剩余短目标轨迹。

    

    长期轨迹预测是计算机视觉、机器学习和机器人领域中一个重要且具有挑战性的问题。其中一个基本困难在于随着时间范围的增长，轨迹的演变变得越来越不确定和不可预测，从而增加了问题的复杂性。为了克服这个问题，在本文中，我们提出了Di-Long，一种新的方法，它利用蒸馏短期轨迹模型预测器来指导训练过程中的长期轨迹预测学生网络。给定一个包含学生网络允许的观测序列和补充目标序列的总序列长度，我们让学生和教师对同一个完整轨迹定义两个不同但相关的任务：学生观察一个短序列并预测一个长轨迹，而教师观察一个更长的序列并预测剩下的短目标轨迹。

    Long-term trajectory forecasting is an important and challenging problem in the fields of computer vision, machine learning, and robotics. One fundamental difficulty stands in the evolution of the trajectory that becomes more and more uncertain and unpredictable as the time horizon grows, subsequently increasing the complexity of the problem. To overcome this issue, in this paper, we propose Di-Long, a new method that employs the distillation of a short-term trajectory model forecaster that guides a student network for long-term trajectory prediction during the training process. Given a total sequence length that comprehends the allowed observation for the student network and the complementary target sequence, we let the student and the teacher solve two different related tasks defined over the same full trajectory: the student observes a short sequence and predicts a long trajectory, whereas the teacher observes a longer sequence and predicts the remaining short target trajectory. The
    
[^196]: Musketeer（一人之力，万人之力）：具有任务解释提示的通用视觉语言模型

    Musketeer (All for One, and One for All): A Generalist Vision-Language Model with Task Explanation Prompts. (arXiv:2305.07019v1 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2305.07019](http://arxiv.org/abs/2305.07019)

    Musketeer是一种通用视觉语言模型，采用任务解释提示（TEP）机制，能够有效整合异构任务的知识，并在多个任务中表现均匀

    

    我们提出了一种序列到序列的视觉语言模型，其参数在所有任务上进行联合训练（万人之力），并在多个任务之间完全共享（一人之力），从而产生了一个名为Musketeer的单一模型。

    We present a sequence-to-sequence vision-language model whose parameters are jointly trained on all tasks (all for one) and fully shared among multiple tasks (one for all), resulting in a single model which we named Musketeer. The integration of knowledge across heterogeneous tasks is enabled by a novel feature called Task Explanation Prompt (TEP). TEP reduces interference among tasks, allowing the model to focus on their shared structure. With a single model, Musketeer achieves results comparable to or better than strong baselines trained on single tasks, almost uniformly across multiple tasks.
    
[^197]: 在大型语言模型中加强迭代增强的思维链提示

    Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models. (arXiv:2304.11657v1 [cs.CL])

    [http://arxiv.org/abs/2304.11657](http://arxiv.org/abs/2304.11657)

    本文提出 Iter-CoT 方法，在大型语言模型中进行迭代增强的思维链提示，通过选择具有适度难度的具有挑战性但可回答的问题，并伴随推理链作为示例，提高了模型的泛化能力，同时使模型能够更准确地生成推理链。

    

    通过逐步引导思维链 (CoT) 作为示范，大型语言模型 (LLMs) 可以在各种推理任务上实现高度有效的性能。然而，LLMs 生成的演示推理链容易出现错误，这可能会导致推理过程中的错误。此外，不恰当的示例 (过于简单或复杂) 可以影响在不同难度级别下的整体性能。我们引入了Iter-CoT (迭代引导思维链提示) 的迭代引导方法，用于选择实例并生成推理链。通过利用迭代增强，我们的方法使LLMs 自主更正错误，从而产生更精确、全面的推理链。同时，我们的方法选择具有适度难度的具有挑战性但可回答的问题，并伴随推理链作为示例，从而增强LLMs 的泛化能力。

    Large language models (LLMs) can achieve highly effective performance on various reasoning tasks by incorporating step-by-step chain-of-thought (CoT) prompting as demonstrations. However, the reasoning chains of demonstrations generated by LLMs are prone to errors, which can subsequently lead to incorrect reasoning during inference. Furthermore, inappropriate exemplars (overly simplistic or complex), can affect overall performance among varying levels of difficulty. We introduce Iter-CoT (Iterative bootstrapping in Chain-of-Thoughts Prompting), an iterative bootstrapping approach for selecting exemplars and generating reasoning chains. By utilizing iterative bootstrapping, our approach enables LLMs to autonomously rectify errors, resulting in more precise and comprehensive reasoning chains. Simultaneously, our approach selects challenging yet answerable questions accompanied by reasoning chains as exemplars with a moderate level of difficulty, which enhances the LLMs' generalizability 
    
[^198]: 个人知识图谱生态系统：调查与研究路线图

    An Ecosystem for Personal Knowledge Graphs: A Survey and Research Roadmap. (arXiv:2304.09572v1 [cs.AI])

    [http://arxiv.org/abs/2304.09572](http://arxiv.org/abs/2304.09572)

    本论文提出了一个个人知识图谱（PKG）的生态系统，PKG的主要目的是数据管理和个性化服务。要解锁PKG的全部潜力，需要一个统一的框架，并提出了一个关于PKG的综合视图。

    

    本论文提出了一个个人知识图谱（PKG）的生态系统，通常定义为有关个人相关实体、其属性和它们之间关系的结构化信息资源。PKG是安全、精密的个人数据管理和个性化服务的关键支持。然而，在PKG能够广泛应用之前需要解决一些挑战。其中一个基本挑战是关于PKG的定义，因为术语有多种解释。我们提出了自己的PKG定义，强调了（1）单个个体拥有数据和（2）提供个性化服务作为主要目的的方面。我们进一步提出了一个综合的PKG视图，需要解锁它们的全部潜力，并提出了一个统一的框架，其中PKG是更大的生态系统的一部分，具有明确的与数据服务和数据源的接口。本文还展示了对当前PKG研究的全面调查和研究路线图。

    This paper presents an ecosystem for personal knowledge graphs (PKG), commonly defined as resources of structured information about entities related to an individual, their attributes, and the relations between them. PKGs are a key enabler of secure and sophisticated personal data management and personalized services. However, there are challenges that need to be addressed before PKGs can achieve widespread adoption. One of the fundamental challenges is the very definition of what constitutes a PKG, as there are multiple interpretations of the term. We propose our own definition of a PKG, emphasizing the aspects of (1) data ownership by a single individual and (2) the delivery of personalized services as the primary purpose. We further argue that a holistic view of PKGs is needed to unlock their full potential, and propose a unified framework for PKGs, where the PKG is a part of a larger ecosystem with clear interfaces towards data services and data sources. A comprehensive survey and 
    
[^199]: 从临床笔记中提取康复锻炼信息：基于规则和机器学习自然语言处理技术的比较

    Extracting Physical Rehabilitation Exercise Information from Clinical Notes: a Comparison of Rule-Based and Machine Learning Natural Language Processing Techniques. (arXiv:2303.13466v1 [cs.CL])

    [http://arxiv.org/abs/2303.13466](http://arxiv.org/abs/2303.13466)

    本文提出了一种基于规则的自然语言处理算法，用于从临床笔记中提取卒中患者治疗过程的锻炼信息，并与几个小型机器学习模型进行比较。在足够的数据可用的情况下，我们的算法在提取一半的概念方面优于这些模型，并且每个概念的个体运动描述可以分配二进制标签，并且F值不低于0.75。这些算法表现出了准确提取临床笔记中康复治疗锻炼信息的前景。

    

    康复锻炼在卒中后患者的康复过程中扮演着至关重要的角色。通过个性化治疗和电子健康记录，医疗保健提供者可以使康复过程更加高效。在预测建模为患者分配治疗计划之前，自动化方法是从非结构化电子健康记录中提取康复锻炼信息所必需的。我们引入了一个基于规则的自然语言处理算法来注释卒中患者的治疗过程，并将其与几个小型机器学习模型进行比较。我们发现，在足够的数据可用的情况下，我们的算法在提取一半的概念方面优于这些模型，并且每个概念的个体运动描述可以分配二进制标签，并且F值不低于0.75。在这些算法可以部署到无标签文档之前，需要进行更多的研究，但定制的基于规则的自然语言处理算法表现出了准确提取临床笔记中康复治疗锻炼信息的前景。

    Physical rehabilitation plays a crucial role in the recovery process of post-stroke patients. By personalizing therapies for patients leveraging predictive modeling and electronic health records (EHRs), healthcare providers can make the rehabilitation process more efficient. Before predictive modeling can provide decision support for the assignment of treatment plans, automated methods are necessary to extract physical rehabilitation exercise information from unstructured EHRs. We introduce a rule-based natural language processing algorithm to annotate therapeutic procedures for stroke patients and compare it to several small machine learning models. We find that our algorithm outperforms these models in extracting half of the concepts where sufficient data is available, and individual exercise descriptions can be assigned binary labels with an f-score of no less than 0.75 per concept. More research needs to be done before these algorithms can be deployed on unlabeled documents, but cu
    
[^200]: 无Softmax的线性变换器

    Softmax-free Linear Transformers. (arXiv:2207.03341v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2207.03341](http://arxiv.org/abs/2207.03341)

    这项研究提出了无softmax的线性变换器(SOFT)，用高斯核函数来逼近自注意机制，以改善视觉识别领域中现有方法的局限性。

    

    视觉变换器(ViTs)在视觉感知任务的最新成果中起到了推动作用。ViTs的核心自注意机制在计算和内存使用方面具有二次复杂度。这促使我们开发出在线性复杂度下逼近自注意的方法。然而，本研究的深入分析发现，现有方法在视觉识别方面要么在理论上有缺陷，要么在实践中无效。我们发现它们的局限性来源于在逼近过程中继承了基于softmax的自注意机制，即使用softmax函数对令牌特征向量之间的缩放点积进行归一化。由于存在这个softmax操作，挑战了任何后续的线性化工作。基于这一观点，我们提出了一系列无softmax的变换器(SOFT)。具体而言，我们采用高斯核函数来替代点积相似度，从而实现全自注意矩阵的逼近。

    Vision transformers (ViTs) have pushed the state-of-the-art for visual perception tasks. The self-attention mechanism underpinning the strength of ViTs has a quadratic complexity in both computation and memory usage. This motivates the development of approximating the self-attention at linear complexity. However, an in-depth analysis in this work reveals that existing methods are either theoretically flawed or empirically ineffective for visual recognition. We identify that their limitations are rooted in the inheritance of softmax-based self-attention during approximations, that is, normalizing the scaled dot-product between token feature vectors using the softmax function. As preserving the softmax operation challenges any subsequent linearization efforts. By this insight, a family of Softmax-Free Transformers (SOFT) are proposed. Specifically, a Gaussian kernel function is adopted to replace the dot-product similarity, enabling a full self-attention matrix to be approximated under l
    

