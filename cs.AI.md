# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [OntoChat: a Framework for Conversational Ontology Engineering using Language Models](https://arxiv.org/abs/2403.05921) | OntoChat是一个支持对话本体工程的框架，通过与对话代理互动，用户可以引导用户故事的创建和能力问题的提取，同时接收计算支持以分析整体需求并进行早期测试。 |
| [^2] | [Multimodal Large Language Models to Support Real-World Fact-Checking](https://arxiv.org/abs/2403.03627) | 多模态大型语言模型在支持现实世界事实核查中展现出优越性能，并能够解释恶意和误导性声明的不合理之处和潜在动机。 |
| [^3] | [Enhancing Long-Term Recommendation with Bi-level Learnable Large Language Model Planning](https://arxiv.org/abs/2403.00843) | 利用大型语言模型的规划能力来增强长期推荐，使模型在个性化推荐中更有效地理解和应用任务解决原则 |
| [^4] | [Rethinking The Uniformity Metric in Self-Supervised Learning](https://arxiv.org/abs/2403.00642) | 通过识别并满足现有均匀性度量未能达标的五个基本性质，本文引入了一个对维度崩溃敏感的新均匀性度量。 |
| [^5] | [Fine-Tuning, Prompting, In-Context Learning and Instruction-Tuning: How Many Labelled Samples Do We Need?](https://arxiv.org/abs/2402.12819) | 专门模型通常只需少量标记样本（100-1000个）就能与通用模型持平甚至更好，取决于任务的复杂性和结果的变化。 |
| [^6] | [Learning to Defer in Content Moderation: The Human-AI Interplay](https://arxiv.org/abs/2402.12237) | 本文提出了一个模型，捕捉内容审核中人工智能的相互作用。 |
| [^7] | [On Computing Plans with Uniform Action Costs](https://arxiv.org/abs/2402.09877) | 该论文提出了适用于自动规划的三种一致性度量，并引入了基于规划的编译技术，可以生成动作成本一致的计划。 |
| [^8] | [PythonSaga: Redefining the Benchmark to Evaluate Code Generating LLM](https://arxiv.org/abs/2401.03855) | PythonSaga提出了一种新的基准，针对Python代码生成进行评估,弥补了现有基准存在的编程概念偏见和简单任务普遍性的问题 |
| [^9] | [Batched Low-Rank Adaptation of Foundation Models](https://arxiv.org/abs/2312.05677) | 提出了Fast LoRA（FLoRA）框架，使得基础模型的低秩调整可以高效批处理异构请求，并在绩效上保持竞争性。 |
| [^10] | [MAIRA-1: A specialised large multimodal model for radiology report generation](https://arxiv.org/abs/2311.13668) | MAIRA-1是一种专门用于放射学报告生成的大型多模态模型，在与预训练的视觉编码器对齐和文本数据增强的基础上，利用了CXR特定的图像编码器和经过微调的大型语言模型，生成具有最先进质量的报告。 |
| [^11] | [Reasoning over Description Logic-based Contexts with Transformers](https://arxiv.org/abs/2311.08941) | 本研究构建了一个由描述逻辑知识库生成的合成自然语言问答数据集，以评估基于Transformer模型在丰富语境中的推理能力。 |
| [^12] | [Raising the ClaSS of Streaming Time Series Segmentation](https://arxiv.org/abs/2310.20431) | ClaSS是一种新颖、高效且高精度的流式时间序列分割算法，通过自监督时间序列分类评估同质性，并应用统计测试检测显著的变化点。 |
| [^13] | [Subtractive Mixture Models via Squaring: Representation and Learning](https://arxiv.org/abs/2310.00724) | 通过平方操作实现的消减混合模型在表达能力上优于传统加法混合模型，并在真实世界分布估计任务中得到了实验证明。 |
| [^14] | [Deep Classifier Mimicry without Data Access](https://arxiv.org/abs/2306.02090) | 提出了一种无需访问原始数据的模型-无关知识蒸馏过程CAKE，可以模拟深度分类器，通过生成噪声合成样本对比地扩散到模型的决策边界。 |
| [^15] | [Learning Optimal Control with Stochastic Models of Hamiltonian Dynamics](https://arxiv.org/abs/2111.08108) | 本文提出了一种新颖的学习框架来解决最优控制问题，通过学习减少的哈密顿动力学和伴随变量，利用变分自动编码器逐渐学习后验分布，从而提高了路径探索过程的效率。 |
| [^16] | [A Linguistic Comparison between Human and ChatGPT-Generated Conversations.](http://arxiv.org/abs/2401.16587) | 本研究比较了人类和ChatGPT生成的对话的语言差异，发现ChatGPT在社交、分析、认知、关注焦点和积极情绪等方面表现出色，但人类对话更具变异性和真实性，尽管在情绪方面无显著差异。同时，该研究还提供了一个新颖的、由ChatGPT生成的对话组成的数据集。 |
| [^17] | [Benchmarking the Fairness of Image Upsampling Methods.](http://arxiv.org/abs/2401.13555) | 这项工作提出了一个评估有条件生成模型性能和公平性的框架，并针对图像上采样应用创建了一个涵盖现代方法的基准测试。实证研究发现使用无偏训练集对结果至关重要，并揭示了不同算法对该问题的响应变化。 |
| [^18] | [Learning to Visually Connect Actions and their Effects.](http://arxiv.org/abs/2401.10805) | 该论文提出了视觉连接动作和其效果的概念（CATE），用于视频理解。研究表明，不同的任务形式产生了捕捉直观动作特性的表示，但模型表现不佳，人类的表现明显优于它们。该研究为未来的努力奠定了基础，并希望能激发出高级形式和模型的灵感。 |
| [^19] | [Weakly Supervised Gaussian Contrastive Grounding with Large Multimodal Models for Video Question Answering.](http://arxiv.org/abs/2401.10711) | 本论文提出了一种使用大型多模型的弱监督高斯对比基础模型来处理视频问答问题的方法。通过将问题和答案对作为事件描述，找到多个关键帧作为目标时刻，并利用这些时刻作为伪标签来强制LMMs进行推理。所提出的方法使用轻量级的基于高斯的对比基础模块（GCG）来学习时效结构。 |
| [^20] | [Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges.](http://arxiv.org/abs/2401.08664) | 本文回顾了针对教育能力的大型语言模型研究，包括数学、写作、编程、推理和基于知识的问答，旨在探索其在构建下一代智能教育系统中的潜力和挑战。 |
| [^21] | [ODIN: A Single Model for 2D and 3D Perception.](http://arxiv.org/abs/2401.02416) | ODIN是一个模型，可以同时对2D RGB图像和3D点云进行分割和标记，使用变压器架构进行2D和3D视图间的信息融合。 |
| [^22] | [Boosting Defect Detection in Manufacturing using Tensor Convolutional Neural Networks.](http://arxiv.org/abs/2401.01373) | 我们引入了一种张量卷积神经网络（T-CNN）来提高制造业中的缺陷检测任务，通过减少模型参数空间，我们实现了比等效CNN模型更快的训练速度和性能。与传统的人类视觉检查相比，在质量指标方面，T-CNN在参数数量上只有15倍少，训练时间快4%至19%。这项研究在实际制造应用中取得了显著的成果。 |
| [^23] | [FENet: Focusing Enhanced Network for Lane Detection.](http://arxiv.org/abs/2312.17163) | FENet是一个增强聚焦网络用于精准车道检测，通过聚焦采样和部分视野评估等创新方法，显著提高了检测准确性，尤其适用于曲线和远距离车道，在安全性方面具有重要意义。 |
| [^24] | [Conditional Variational Diffusion Models.](http://arxiv.org/abs/2312.02246) | 该论文提出了一种新的条件变分扩散模型，通过学习调度作为训练过程的一部分，解决了扩散模型的敏感性问题，并且能够适应不同的应用场景，提供高质量的解决方案。 |
| [^25] | [Ensemble Distillation for Unsupervised Constituency Parsing.](http://arxiv.org/abs/2310.01717) | 本论文提出了一种集成蒸馏的方法来提高无监督句法解析的性能，并且通过蒸馏将集成知识转移到一个学生模型中，解决了常见的多教师蒸馏方法中的过度平滑问题。 |
| [^26] | [Towards Understanding In-Context Learning with Contrastive Demonstrations and Saliency Maps.](http://arxiv.org/abs/2307.05052) | 本研究探索了对比演示和显著性图在上下文学习中的作用，并发现改变标签对显著性有显著影响，尤其对于更大的语言模型更为明显。在情感分析任务中，将表达情感的术语改为中性词并不像改变标签那样具有显著影响。另外，补充解释在提高上下文学习方面是有效的。 |
| [^27] | [DocumentCLIP: Linking Figures and Main Body Text in Reflowed Documents.](http://arxiv.org/abs/2306.06306) | DocumentCLIP是一种显著性感知对比学习框架，用于理解文档内长文本和图像之间的交互作用。我们是第一个在多模态文档内部链接方面进行对比学习的人。 |
| [^28] | [Model-agnostic explainable artificial intelligence for object detection in image data.](http://arxiv.org/abs/2303.17249) | 本文设计并实现了一种新的黑盒解释方法——BODEM，它采用了局部和远程掩蔽生成多个版本的输入图像，从而比目前用于解释对象检测的其他三种最先进的方法提供更详细和有用的解释。 |
| [^29] | [Full Characterization of Adaptively Strong Majority Voting in Crowdsourcing.](http://arxiv.org/abs/2111.06390) | 本研究通过利用吸收式马尔可夫链对众包中自适应强多数投票进行建模和分析，得出了该投票过程的一些重要特征，包括共识投票的质量、投票数和需求的方差等。研究结果显示，可以通过调整阈值来实现在不同准确性水平的工人参与的投票过程中的质量等效。 |

# 详细

[^1]: OntoChat: 一种使用语言模型进行对话本体工程的框架

    OntoChat: a Framework for Conversational Ontology Engineering using Language Models

    [https://arxiv.org/abs/2403.05921](https://arxiv.org/abs/2403.05921)

    OntoChat是一个支持对话本体工程的框架，通过与对话代理互动，用户可以引导用户故事的创建和能力问题的提取，同时接收计算支持以分析整体需求并进行早期测试。

    

    大型项目中的本体工程(OE)面临着许多挑战，其中的挑战源于各方利益相关者、领域专家及其与本体设计者的复杂互动背景的异质性。这种多方互动经常会在本体需求的引申中产生系统性的歧义和偏见，直接影响设计、评估并可能危及目标的重复使用性。与此同时，目前的OE方法强烈依赖于手工活动（如采访、讨论页面）。在收集了关于最关键OE活动的证据后，我们引入了OntoChat，这是一个支持需求引申、分析和测试的对话本体工程框架。通过与对话代理进行互动，用户可以引导用户故事的创建和能力问题的提取，同时接收计算支持以分析整体需求并进行早期测试。

    arXiv:2403.05921v1 Announce Type: new  Abstract: Ontology engineering (OE) in large projects poses a number of challenges arising from the heterogeneous backgrounds of the various stakeholders, domain experts, and their complex interactions with ontology designers. This multi-party interaction often creates systematic ambiguities and biases from the elicitation of ontology requirements, which directly affect the design, evaluation and may jeopardise the target reuse. Meanwhile, current OE methodologies strongly rely on manual activities (e.g., interviews, discussion pages). After collecting evidence on the most crucial OE activities, we introduce OntoChat, a framework for conversational ontology engineering that supports requirement elicitation, analysis, and testing. By interacting with a conversational agent, users can steer the creation of user stories and the extraction of competency questions, while receiving computational support to analyse the overall requirements and test early
    
[^2]: 多模态大型语言模型支持现实世界事实核查

    Multimodal Large Language Models to Support Real-World Fact-Checking

    [https://arxiv.org/abs/2403.03627](https://arxiv.org/abs/2403.03627)

    多模态大型语言模型在支持现实世界事实核查中展现出优越性能，并能够解释恶意和误导性声明的不合理之处和潜在动机。

    

    多模态大型语言模型（MLLMs）具有潜力支持人类处理大量信息。虽然MLLMs已经被用作事实核查工具，但就其在此方面的能力和局限性而言，尚未得到充分研究。我们旨在弥合这一差距。具体而言，我们提出了一个框架，系统评估当前多模态模型促进现实世界事实核查的能力。我们的方法论是无需证据的，仅利用这些模型的固有知识和推理能力。通过设计能够提取模型预测、解释和置信水平的提示，我们深入研究关于模型准确性、鲁棒性以及失败原因的研究问题。我们在实证上发现，(1) GPT-4V在识别恶意和误导性多模态声明方面表现出超凡性能，能够解释不合理的方面和潜在动机，以及(2)现有的o

    arXiv:2403.03627v1 Announce Type: cross  Abstract: Multimodal large language models (MLLMs) carry the potential to support humans in processing vast amounts of information. While MLLMs are already being used as a fact-checking tool, their abilities and limitations in this regard are understudied. Here is aim to bridge this gap. In particular, we propose a framework for systematically assessing the capacity of current multimodal models to facilitate real-world fact-checking. Our methodology is evidence-free, leveraging only these models' intrinsic knowledge and reasoning capabilities. By designing prompts that extract models' predictions, explanations, and confidence levels, we delve into research questions concerning model accuracy, robustness, and reasons for failure. We empirically find that (1) GPT-4V exhibits superior performance in identifying malicious and misleading multimodal claims, with the ability to explain the unreasonable aspects and underlying motives, and (2) existing o
    
[^3]: 利用双层可学习大型语言模型规划增强长期推荐

    Enhancing Long-Term Recommendation with Bi-level Learnable Large Language Model Planning

    [https://arxiv.org/abs/2403.00843](https://arxiv.org/abs/2403.00843)

    利用大型语言模型的规划能力来增强长期推荐，使模型在个性化推荐中更有效地理解和应用任务解决原则

    

    传统推荐系统倾向于过分迎合用户的即时兴趣而忽视他们的长期参与。 为了解决这个问题，在推荐决策过程中合并规划能力是至关重要的，以开发能够同时考虑即时兴趣和长期参与的策略。本文提出利用大型语言模型（LLMs）对稀疏数据的显著规划能力用于长期推荐。关键在于使语言模型能够在个性化推荐场景中有效理解和应用任务解决原则，因为模型的预训练可能并未自然包含这些内容。

    arXiv:2403.00843v1 Announce Type: cross  Abstract: Traditional recommendation setting tends to excessively cater to users' immediate interests and neglect their long-term engagement. To address it, it is crucial to incorporate planning capabilities into the recommendation decision-making process to develop policies that take into account both immediate interests and long-term engagement. Despite Reinforcement Learning (RL) can learn planning capacity by maximizing cumulative reward, the scarcity of recommendation data presents challenges such as instability and susceptibility to overfitting when training RL models from scratch.   In this context, we propose to leverage the remarkable planning capabilities over sparse data of Large Language Models (LLMs) for long-term recommendation. The key lies in enabling a language model to understand and apply task-solving principles effectively in personalized recommendation scenarios, as the model's pre-training may not naturally encompass these 
    
[^4]: 重新审视自监督学习中的均匀性度量

    Rethinking The Uniformity Metric in Self-Supervised Learning

    [https://arxiv.org/abs/2403.00642](https://arxiv.org/abs/2403.00642)

    通过识别并满足现有均匀性度量未能达标的五个基本性质，本文引入了一个对维度崩溃敏感的新均匀性度量。

    

    均匀性在评估学习表示方面起着至关重要的作用，有助于更深入理解自监督学习。之前的一项开创性工作引入了一个均匀性度量，定量衡量学习表示的崩溃程度。直接优化这一度量与对齐一起，被证明能够有效地防止不断崩溃。然而，我们提出理论和实证证据表明这一度量缺乏对维度崩溃的敏感性，凸显了其局限性。为了解决这一局限性并设计一个更有效的均匀性度量，本文确定了五个基本性质，其中现有的均匀性度量未能满足其中的一些。我们随后引入了一个新的均匀性度量，满足所有这些期望，并且对维度崩溃具有敏感性。

    arXiv:2403.00642v1 Announce Type: cross  Abstract: Uniformity plays a crucial role in the assessment of learned representations, contributing to a deeper comprehension of self-supervised learning. The seminal work by \citet{Wang2020UnderstandingCR} introduced a uniformity metric that quantitatively measures the collapse degree of learned representations. Directly optimizing this metric together with alignment proves to be effective in preventing constant collapse. However, we present both theoretical and empirical evidence revealing that this metric lacks sensitivity to dimensional collapse, highlighting its limitations. To address this limitation and design a more effective uniformity metric, this paper identifies five fundamental properties, some of which the existing uniformity metric fails to meet. We subsequently introduce a novel uniformity metric that satisfies all of these desiderata and exhibits sensitivity to dimensional collapse. When applied as an auxiliary loss in various 
    
[^5]: 微调、提示、上下文学习和指导微调：我们需要多少标记样本？

    Fine-Tuning, Prompting, In-Context Learning and Instruction-Tuning: How Many Labelled Samples Do We Need?

    [https://arxiv.org/abs/2402.12819](https://arxiv.org/abs/2402.12819)

    专门模型通常只需少量标记样本（100-1000个）就能与通用模型持平甚至更好，取决于任务的复杂性和结果的变化。

    

    当解决具有有限标记数据的任务时，研究人员可以选择使用通用的大型语言模型而不进行进一步更新，或者使用少量示例来调整专门的较小模型。 当有足够的标记可用时，专门的模型在许多自然语言处理任务上表现优于通用模型。 在这项工作中，我们旨在调查专门模型需要多少标记样本才能实现这种出色的性能，同时考虑结果的变化。观察提示、上下文学习、微调和指导微调的行为，识别它们在增加不同复杂性任务的标记训练样本数量时的收支平衡点，我们发现专门模型通常只需少量样本（100-1000个）就能与通用模型持平甚至更好。 同时，所需的标记数据量强烈依赖于任务的复杂性和结果的变化。

    arXiv:2402.12819v1 Announce Type: cross  Abstract: When solving a task with limited labelled data, researchers can either use a general large language model without further update, or use the few examples to tune a specialised smaller model. When enough labels are available, the specialised models outperform the general ones on many NLP tasks. In this work, we aim to investigate how many labelled samples are required for the specialised models to achieve this superior performance, while taking the results variance into consideration. Observing the behaviour of prompting, in-context learning, fine-tuning and instruction-tuning, identifying their break-even points when increasing number of labelled training samples across three tasks of varying complexity, we find that the specialised models often need only few samples ($100-1000$) to be on par or better than the general ones. At the same time, the amount of required labelled data strongly depends on the task complexity and results varia
    
[^6]: 学习在内容审核中推迟：人工智能与人类协同作用

    Learning to Defer in Content Moderation: The Human-AI Interplay

    [https://arxiv.org/abs/2402.12237](https://arxiv.org/abs/2402.12237)

    本文提出了一个模型，捕捉内容审核中人工智能的相互作用。

    

    成功的在线平台内容审核依赖于人工智能协同方法。本文介绍了一个模型，捕捉内容审核中人工智能的相互作用。算法观察到即将发布的帖子的背景信息，做出分类和准入决策，并安排帖子进行人工审核。

    arXiv:2402.12237v1 Announce Type: cross  Abstract: Successful content moderation in online platforms relies on a human-AI collaboration approach. A typical heuristic estimates the expected harmfulness of a post and uses fixed thresholds to decide whether to remove it and whether to send it for human review. This disregards the prediction uncertainty, the time-varying element of human review capacity and post arrivals, and the selective sampling in the dataset (humans only review posts filtered by the admission algorithm).   In this paper, we introduce a model to capture the human-AI interplay in content moderation. The algorithm observes contextual information for incoming posts, makes classification and admission decisions, and schedules posts for human review. Only admitted posts receive human reviews on their harmfulness. These reviews help educate the machine-learning algorithms but are delayed due to congestion in the human review system. The classical learning-theoretic way to ca
    
[^7]: 计算具有统一动作成本的计划

    On Computing Plans with Uniform Action Costs

    [https://arxiv.org/abs/2402.09877](https://arxiv.org/abs/2402.09877)

    该论文提出了适用于自动规划的三种一致性度量，并引入了基于规划的编译技术，可以生成动作成本一致的计划。

    

    在许多实际的规划应用中，代理人可能有兴趣找到动作成本尽可能一致的计划。这样的计划为代理人提供了稳定性和可预测性，这在人类执行规划工具建议的计划时是关键特征。本文将三个一致性度量应用于自动规划，并引入了基于规划的编译技术，允许以动作成本总和和动作成本一致性进行词典排序最优化。在知名和新颖的规划基准测试中的实验结果表明，可以有效地解决重构的任务以生成一致的计划。

    arXiv:2402.09877v1 Announce Type: new  Abstract: In many real-world planning applications, agents might be interested in finding plans whose actions have costs that are as uniform as possible. Such plans provide agents with a sense of stability and predictability, which are key features when humans are the agents executing plans suggested by planning tools. This paper adapts three uniformity metrics to automated planning, and introduce planning-based compilations that allow to lexicographically optimize sum of action costs and action costs uniformity. Experimental results both in well-known and novel planning benchmarks show that the reformulated tasks can be effectively solved in practice to generate uniform plans.
    
[^8]: PythonSaga：重新定义评估代码生成LLM的基准

    PythonSaga: Redefining the Benchmark to Evaluate Code Generating LLM

    [https://arxiv.org/abs/2401.03855](https://arxiv.org/abs/2401.03855)

    PythonSaga提出了一种新的基准，针对Python代码生成进行评估,弥补了现有基准存在的编程概念偏见和简单任务普遍性的问题

    

    受到使用大型语言模型(LLMs)生成代码激增的推动，出现了许多基准用于评估这些LLMs的功能。我们对HumanEval和MBPP两个流行的Python代码生成基准进行了大规模人工评估，分析了它们的多样性和难度。我们的研究揭示了对一组有限的编程概念存在严重偏见，完全忽视了大多数其他概念。此外，我们发现了大量简单任务的普遍存在，可能夸大了模型性能的估计。为了解决这些限制，我们提出了一种新颖的基准，PythonSaga，包含了185个手工制作的提示，涵盖了38个不同难度级别的编程概念。

    arXiv:2401.03855v2 Announce Type: replace-cross  Abstract: Driven by the surge in code generation using large language models (LLMs), numerous benchmarks have emerged to evaluate these LLMs capabilities. We conducted a large-scale human evaluation of HumanEval and MBPP, two popular benchmarks for Python code generation, analyzing their diversity and difficulty. Our findings unveil a critical bias towards a limited set of programming concepts, neglecting most of the other concepts entirely. Furthermore, we uncover a worrying prevalence of easy tasks, potentially inflating model performance estimations. To address these limitations, we propose a novel benchmark, PythonSaga, featuring 185 hand-crafted prompts on a balanced representation of 38 programming concepts across diverse difficulty levels.
    
[^9]: 基于批处理的基础模型低秩调整

    Batched Low-Rank Adaptation of Foundation Models

    [https://arxiv.org/abs/2312.05677](https://arxiv.org/abs/2312.05677)

    提出了Fast LoRA（FLoRA）框架，使得基础模型的低秩调整可以高效批处理异构请求，并在绩效上保持竞争性。

    

    最近，低秩适应（LoRA）因通过引入可训练的低秩矩阵微调基础模型并减少可训练参数的数量而引起关注。虽然LoRA提供了许多优点，但其在实时为各种全球用户提供服务时无法高效处理多个特定任务适配器的能力受到限制。这为需要为每个传入请求个性化、特定任务适应的场景中造成了性能瓶颈。为了减轻这一约束，我们提出了快速LoRA（FLoRA）框架，其中批处理中的每个输入示例都可以与其独特的低秩适应权重相关联，从而实现对异构请求的高效批处理。我们通过实证表明，FLoRA保留了LoRA的绩效优点，在跨越8种语言的MultiPL-E代码生成基准测试上展示出竞争结果。

    arXiv:2312.05677v2 Announce Type: replace-cross  Abstract: Low-Rank Adaptation (LoRA) has recently gained attention for fine-tuning foundation models by incorporating trainable low-rank matrices, thereby reducing the number of trainable parameters. While LoRA offers numerous advantages, its applicability for real-time serving to a diverse and global user base is constrained by its incapability to handle multiple task-specific adapters efficiently. This imposes a performance bottleneck in scenarios requiring personalized, task-specific adaptations for each incoming request. To mitigate this constraint, we introduce Fast LoRA (FLoRA), a framework in which each input example in a minibatch can be associated with its unique low-rank adaptation weights, allowing for efficient batching of heterogeneous requests. We empirically demonstrate that FLoRA retains the performance merits of LoRA, showcasing competitive results on the MultiPL-E code generation benchmark spanning over 8 languages and 
    
[^10]: MAIRA-1：一种专门用于放射学报告生成的大型多模态模型

    MAIRA-1: A specialised large multimodal model for radiology report generation

    [https://arxiv.org/abs/2311.13668](https://arxiv.org/abs/2311.13668)

    MAIRA-1是一种专门用于放射学报告生成的大型多模态模型，在与预训练的视觉编码器对齐和文本数据增强的基础上，利用了CXR特定的图像编码器和经过微调的大型语言模型，生成具有最先进质量的报告。

    

    我们提出了一种放射学特定的多模态模型，用于从胸部X光（CXR）生成放射学报告的任务。我们的工作基于一个思想，即可以通过与预训练视觉编码器对齐，使大型语言模型具备多模态能力。在自然图像上，这已被证明可以使多模态模型获得图像理解和描述能力。我们提出的模型（MAIRA-1）利用了一个CXR特定的图像编码器，结合基于Vicuna-7B的微调的大型语言模型，并进行基于文本的数据增强，以产生具有最先进质量的报告。特别地，MAIRA-1在与放射科医生对齐的RadCliQ度量和考虑的所有词汇度量上都有显著改进。对模型输出的手动审核显示出了产生报告的流畅性和准确性，同时揭示了现有评估方法所未捕捉到的失败模式。更多信息和资源可在项目网站上找到：

    We present a radiology-specific multimodal model for the task for generating radiological reports from chest X-rays (CXRs). Our work builds on the idea that large language model(s) can be equipped with multimodal capabilities through alignment with pre-trained vision encoders. On natural images, this has been shown to allow multimodal models to gain image understanding and description capabilities. Our proposed model (MAIRA-1) leverages a CXR-specific image encoder in conjunction with a fine-tuned large language model based on Vicuna-7B, and text-based data augmentation, to produce reports with state-of-the-art quality. In particular, MAIRA-1 significantly improves on the radiologist-aligned RadCliQ metric and across all lexical metrics considered. Manual review of model outputs demonstrates promising fluency and accuracy of generated reports while uncovering failure modes not captured by existing evaluation practices. More information and resources can be found on the project website:
    
[^11]: 基于Transformer的描述逻辑语境推理

    Reasoning over Description Logic-based Contexts with Transformers

    [https://arxiv.org/abs/2311.08941](https://arxiv.org/abs/2311.08941)

    本研究构建了一个由描述逻辑知识库生成的合成自然语言问答数据集，以评估基于Transformer模型在丰富语境中的推理能力。

    

    目前，衡量基于Transformer模型的推理能力的一种方式是通过评估在自然语言表达的合成语境中对逻辑问题回答或证明生成等下游任务的准确性。然而，大多数实际使用的语境非常简单；在大多数情况下，它们是由仅含有少量逻辑运算符和量词的短一阶逻辑句子生成的。本文旨在回答基于Transformer模型能够在表达丰富语境中执行推理的问题。为此，我们构建了一个由描述逻辑知识库生成的合成自然语言问答数据集。为生成知识库，我们使用了表达式语言$\mathcal{ALCQ$。生成的数据集包含384K个示例，并且在两个维度上增加：i) 推理深度，和ii) 句子长度。

    arXiv:2311.08941v2 Announce Type: replace-cross  Abstract: One way that the current state of the art measures the reasoning ability of transformer-based models is by evaluating accuracy in downstream tasks like logical question answering or proof generation over synthetic contexts expressed in natural language. However, most of the contexts used are in practice very simple; in most cases, they are generated from short first-order logic sentences with only a few logical operators and quantifiers. In this work, we seek to answer the question how well a transformer-based model will perform reasoning over expressive contexts. For this purpose, we construct a synthetic natural language question-answering dataset, generated by description logic knowledge bases. For the generation of the knowledge bases, we use the expressive language $\mathcal{ALCQ}$. The resulting dataset contains 384K examples, and increases in two dimensions: i) reasoning depth, and ii) length of sentences. We show that t
    
[^12]: 提升流式时间序列分割的等级

    Raising the ClaSS of Streaming Time Series Segmentation

    [https://arxiv.org/abs/2310.20431](https://arxiv.org/abs/2310.20431)

    ClaSS是一种新颖、高效且高精度的流式时间序列分割算法，通过自监督时间序列分类评估同质性，并应用统计测试检测显著的变化点。

    

    今天，普遍存在的传感器发射高频数值测量流，反映了人类、动物、工业、商业和自然过程的特性。这些过程的变化，例如由外部事件或内部状态变化引起的，会表现为记录信号中的变化。流式时间序列分割（STSS）的任务是将流分割为对应于所观察的过程或实体状态的连续可变大小的分段。分割操作本身必须能够应对输入信号的频率。我们引入了ClaSS，一种新颖、高效且高精度的STSS算法。ClaSS使用自监督时间序列分类评估潜在分割的同质性，并应用统计测试来检测显著的变化点（CPs）。在我们的实验证评中使用了两个大型基准和六个真实世界的数据档案。

    arXiv:2310.20431v2 Announce Type: replace-cross  Abstract: Ubiquitous sensors today emit high frequency streams of numerical measurements that reflect properties of human, animal, industrial, commercial, and natural processes. Shifts in such processes, e.g. caused by external events or internal state changes, manifest as changes in the recorded signals. The task of streaming time series segmentation (STSS) is to partition the stream into consecutive variable-sized segments that correspond to states of the observed processes or entities. The partition operation itself must in performance be able to cope with the input frequency of the signals. We introduce ClaSS, a novel, efficient, and highly accurate algorithm for STSS. ClaSS assesses the homogeneity of potential partitions using self-supervised time series classification and applies statistical tests to detect significant change points (CPs). In our experimental evaluation using two large benchmarks and six real-world data archives, 
    
[^13]: 通过平方的消减混合模型:表示和学习

    Subtractive Mixture Models via Squaring: Representation and Learning

    [https://arxiv.org/abs/2310.00724](https://arxiv.org/abs/2310.00724)

    通过平方操作实现的消减混合模型在表达能力上优于传统加法混合模型，并在真实世界分布估计任务中得到了实验证明。

    

    混合模型传统上是通过将几个分布作为组件相加来表示和学习的。允许混合减去概率质量或密度可以大大减少建模复杂分布所需的组件数量。然而，学习这种减法混合模型并确保它们仍然编码非负函数是具有挑战性的。我们探讨了如何通过平方来学习和执行深度减法混合模型。我们在概率电路框架中进行这些研究，这使我们能够表示张量化的混合模型并泛化其他减法模型。我们在理论上证明了允许减法的平方电路类可以比传统的加法混合模型具有指数级更具表达力；我们在一系列真实世界分布估计任务上实证展示了这种增加的表达力。

    arXiv:2310.00724v2 Announce Type: replace-cross  Abstract: Mixture models are traditionally represented and learned by adding several distributions as components. Allowing mixtures to subtract probability mass or density can drastically reduce the number of components needed to model complex distributions. However, learning such subtractive mixtures while ensuring they still encode a non-negative function is challenging. We investigate how to learn and perform inference on deep subtractive mixtures by squaring them. We do this in the framework of probabilistic circuits, which enable us to represent tensorized mixtures and generalize several other subtractive models. We theoretically prove that the class of squared circuits allowing subtractions can be exponentially more expressive than traditional additive mixtures; and, we empirically show this increased expressiveness on a series of real-world distribution estimation tasks.
    
[^14]: 没有数据访问的深度分类器模拟

    Deep Classifier Mimicry without Data Access

    [https://arxiv.org/abs/2306.02090](https://arxiv.org/abs/2306.02090)

    提出了一种无需访问原始数据的模型-无关知识蒸馏过程CAKE，可以模拟深度分类器，通过生成噪声合成样本对比地扩散到模型的决策边界。

    

    最近，对预先训练模型的访问已经成为许多机器学习领域的标准。不幸的是，可能无法等同地获得模型训练所需的原始数据。这使得微调、压缩模型、持续调整或进行任何其他类型的数据驱动更新变得极具挑战性。我们认为可能无需原始数据访问。具体而言，我们提出了对比推理知识提取（CAKE），这是一种模型无关的知识蒸馏过程，可以模拟深度分类器而无需访问原始数据。为此，CAKE生成一对噪声合成样本，并将它们对比地扩散到模型的决策边界。我们通过几个基准数据集和各种架构选择在实证上证实了CAKE的有效性，为广泛应用铺平了道路。

    arXiv:2306.02090v2 Announce Type: replace-cross  Abstract: Access to pre-trained models has recently emerged as a standard across numerous machine learning domains. Unfortunately, access to the original data the models were trained on may not equally be granted. This makes it tremendously challenging to fine-tune, compress models, adapt continually, or to do any other type of data-driven update. We posit that original data access may however not be required. Specifically, we propose Contrastive Abductive Knowledge Extraction (CAKE), a model-agnostic knowledge distillation procedure that mimics deep classifiers without access to the original data. To this end, CAKE generates pairs of noisy synthetic samples and diffuses them contrastively toward a model's decision boundary. We empirically corroborate CAKE's effectiveness using several benchmark datasets and various architectural choices, paving the way for broad application.
    
[^15]: 使用哈密顿动力学随机模型学习最优控制

    Learning Optimal Control with Stochastic Models of Hamiltonian Dynamics

    [https://arxiv.org/abs/2111.08108](https://arxiv.org/abs/2111.08108)

    本文提出了一种新颖的学习框架来解决最优控制问题，通过学习减少的哈密顿动力学和伴随变量，利用变分自动编码器逐渐学习后验分布，从而提高了路径探索过程的效率。

    

    通过应用庞特里亚金最大值原理，然后求解哈密顿动力系统，最优控制问题可以得到解决。本文提出了新颖的学习框架来解决最优控制问题。通过将庞特里亚金最大值原理应用于原始最优控制问题，学习重点转移到了减少的哈密顿动力学和相应的伴随变量上。减少的哈密顿网络可以通过向后推进时间，然后最小化从庞特里亚金最大值原理条件推导出的损失函数来学习。通过逐渐学习减少的哈密顿的后验分布，利用变分自动编码器进一步改进了学习过程，从而导致更有效的路径探索过程。我们将我们的学习框架应用于控制任务并获得了竞争力的结果。

    arXiv:2111.08108v2 Announce Type: replace-cross  Abstract: Optimal control problems can be solved by applying the Pontryagin maximum principle and then solving for a Hamiltonian dynamical system. In this paper, we propose novel learning frameworks to tackle optimal control problems. By applying the Pontryagin maximum principle to the original optimal control problem, the learning focus shifts to reduced Hamiltonian dynamics and corresponding adjoint variables. The reduced Hamiltonian networks can be learned by going backward in time and then minimizing loss function deduced from the Pontryagin maximum principle's conditions. The learning process is further improved by progressively learning a posterior distribution of reduced Hamiltonians, utilizing a variational autoencoder which leads to more effective path exploration process. We apply our learning frameworks to control tasks and obtain competitive results.
    
[^16]: 人类与ChatGPT生成对话之间的语言对比

    A Linguistic Comparison between Human and ChatGPT-Generated Conversations. (arXiv:2401.16587v1 [cs.CL])

    [http://arxiv.org/abs/2401.16587](http://arxiv.org/abs/2401.16587)

    本研究比较了人类和ChatGPT生成的对话的语言差异，发现ChatGPT在社交、分析、认知、关注焦点和积极情绪等方面表现出色，但人类对话更具变异性和真实性，尽管在情绪方面无显著差异。同时，该研究还提供了一个新颖的、由ChatGPT生成的对话组成的数据集。

    

    本研究探讨了人类和LLM生成的对话之间的语言差异，使用了由ChatGPT-3.5生成的19.5K个对话作为EmpathicDialogues数据集的补充。研究采用Linguistic Inquiry and Word Count (LIWC) 分析，比较了ChatGPT生成的对话和人类对话在118个语言类别上的差异。结果显示人类对话具有更大的变异性和真实性，但ChatGPT在社交过程、分析风格、认知、关注焦点和积极情绪色彩等方面表现出色，这进一步证明了LLMs“比真人更像真人”的最新发现。然而，在ChatGPT和人类对话之间没有找到积极或消极情绪的显著差异。对话嵌入的分类器分析表明，尽管对话中没有明确提及情绪，但对情感价值的隐性编码存在。研究还提供了一个新颖的、由两个ChatGPT生成的对话组成的数据集。

    This study explores linguistic differences between human and LLM-generated dialogues, using 19.5K dialogues generated by ChatGPT-3.5 as a companion to the EmpathicDialogues dataset. The research employs Linguistic Inquiry and Word Count (LIWC) analysis, comparing ChatGPT-generated conversations with human conversations across 118 linguistic categories. Results show greater variability and authenticity in human dialogues, but ChatGPT excels in categories such as social processes, analytical style, cognition, attentional focus, and positive emotional tone, reinforcing recent findings of LLMs being "more human than human." However, no significant difference was found in positive or negative affect between ChatGPT and human dialogues. Classifier analysis of dialogue embeddings indicates implicit coding of the valence of affect despite no explicit mention of affect in the conversations. The research also contributes a novel, companion ChatGPT-generated dataset of conversations between two i
    
[^17]: 图像上采样方法的公平性基准测试

    Benchmarking the Fairness of Image Upsampling Methods. (arXiv:2401.13555v1 [cs.CV])

    [http://arxiv.org/abs/2401.13555](http://arxiv.org/abs/2401.13555)

    这项工作提出了一个评估有条件生成模型性能和公平性的框架，并针对图像上采样应用创建了一个涵盖现代方法的基准测试。实证研究发现使用无偏训练集对结果至关重要，并揭示了不同算法对该问题的响应变化。

    

    近年来，深度生成模型在创建合成媒体（如图像和视频）方面取得了快速发展。虽然这些模型在日常任务中的实际应用非常诱人，但评估其公平性相关的潜在风险至关重要。在这项工作中，我们引入了一个全面的框架，用于评估有条件生成模型的性能和公平性。我们开发了一套度量标准——受监督公平性的灵感来源——来评估模型的公平性和多样性。我们针对图像上采样这个特定应用，创建了一个涵盖各种现代上采样方法的基准测试。作为基准测试的一部分，我们引入了UnfairFace，这是FairFace的一个子集，复制了常见大规模人脸数据集的种族分布。我们的实证研究凸显了使用无偏训练集的重要性，并揭示了算法对该问题的响应变化。

    Recent years have witnessed a rapid development of deep generative models for creating synthetic media, such as images and videos. While the practical applications of these models in everyday tasks are enticing, it is crucial to assess the inherent risks regarding their fairness. In this work, we introduce a comprehensive framework for benchmarking the performance and fairness of conditional generative models. We develop a set of metrics$\unicode{x2013}$inspired by their supervised fairness counterparts$\unicode{x2013}$to evaluate the models on their fairness and diversity. Focusing on the specific application of image upsampling, we create a benchmark covering a wide variety of modern upsampling methods. As part of the benchmark, we introduce UnfairFace, a subset of FairFace that replicates the racial distribution of common large-scale face datasets. Our empirical study highlights the importance of using an unbiased training set and reveals variations in how the algorithms respond to 
    
[^18]: 学习视觉连接动作和其效果

    Learning to Visually Connect Actions and their Effects. (arXiv:2401.10805v1 [cs.CV])

    [http://arxiv.org/abs/2401.10805](http://arxiv.org/abs/2401.10805)

    该论文提出了视觉连接动作和其效果的概念（CATE），用于视频理解。研究表明，不同的任务形式产生了捕捉直观动作特性的表示，但模型表现不佳，人类的表现明显优于它们。该研究为未来的努力奠定了基础，并希望能激发出高级形式和模型的灵感。

    

    在这项工作中，我们引入了视觉连接动作和其效果（CATE）的新概念，用于视频理解。CATE可以在任务规划和从示范中学习等领域中应用。我们提出了不同基于CATE的任务形式，如动作选择和动作指定，其中视频理解模型以语义和细粒度的方式连接动作和效果。我们观察到不同的形式产生了捕捉直观动作特性的表示。我们还设计了各种基线模型用于动作选择和动作指定。尽管任务具有直观性，但我们观察到模型困难重重，人类表现明显优于它们。本研究旨在为未来的努力奠定基础，展示了连接视频理解中动作和效果的灵活性和多功能性，希望能激发出高级形式和模型的灵感。

    In this work, we introduce the novel concept of visually Connecting Actions and Their Effects (CATE) in video understanding. CATE can have applications in areas like task planning and learning from demonstration. We propose different CATE-based task formulations, such as action selection and action specification, where video understanding models connect actions and effects at semantic and fine-grained levels. We observe that different formulations produce representations capturing intuitive action properties. We also design various baseline models for action selection and action specification. Despite the intuitive nature of the task, we observe that models struggle, and humans outperform them by a large margin. The study aims to establish a foundation for future efforts, showcasing the flexibility and versatility of connecting actions and effects in video understanding, with the hope of inspiring advanced formulations and models.
    
[^19]: 使用大型多模型的弱监督高斯对比基础模型来处理视频问答问题

    Weakly Supervised Gaussian Contrastive Grounding with Large Multimodal Models for Video Question Answering. (arXiv:2401.10711v1 [cs.CV])

    [http://arxiv.org/abs/2401.10711](http://arxiv.org/abs/2401.10711)

    本论文提出了一种使用大型多模型的弱监督高斯对比基础模型来处理视频问答问题的方法。通过将问题和答案对作为事件描述，找到多个关键帧作为目标时刻，并利用这些时刻作为伪标签来强制LMMs进行推理。所提出的方法使用轻量级的基于高斯的对比基础模块（GCG）来学习时效结构。

    

    视频问答（VideoQA）旨在基于观察到的视频信息回答自然语言问题。尽管大型多模型（LMMs）在图像语言理解和推理方面取得了近期的成功，但它们在处理视频问答方面还不足够，仅仅是将均匀采样的帧作为视觉输入，忽略了与问题相关的视觉线索。此外，现有的视频问答数据集中没有针对问题关键时间戳的人工注释。基于此，我们提出了一种新的弱监督框架，强制LMMs使用问题关键时刻作为视觉输入推理出答案。具体来说，我们将问题和答案对合并为事件描述，以找到多个关键帧作为目标时刻，这些时刻将作为伪标签。通过将这些伪标签作为额外的弱监督，我们设计了一个轻量级的基于高斯的对比基础模块（GCG）。GCG学习多个高斯函数来描述时效结构。

    Video Question Answering (VideoQA) aims to answer natural language questions based on the information observed in videos. Despite the recent success of Large Multimodal Models (LMMs) in image-language understanding and reasoning, they deal with VideoQA insufficiently by simply taking uniformly sampled frames as visual inputs, which ignores question-relevant visual clues. Moreover, there are no human annotations for question-critical timestamps in existing VideoQA datasets. In light of this, we propose a novel weakly supervised framework to enforce the LMMs to reason out the answers with question-critical moments as visual inputs. Specifically, we fuse the question and answer pairs as event descriptions to find multiple keyframes as target moments, which will be pseudo-labels. With these pseudo-labels as additionally weak supervision, we devise a lightweight Gaussian-based Contrastive Grounding (GCG) module. GCG learns multiple Gaussian functions to characterize the temporal structure o
    
[^20]: 将大型语言模型应用于教育：基本能力、潜力和挑战

    Adapting Large Language Models for Education: Foundational Capabilities, Potentials, and Challenges. (arXiv:2401.08664v1 [cs.AI])

    [http://arxiv.org/abs/2401.08664](http://arxiv.org/abs/2401.08664)

    本文回顾了针对教育能力的大型语言模型研究，包括数学、写作、编程、推理和基于知识的问答，旨在探索其在构建下一代智能教育系统中的潜力和挑战。

    

    在线教育平台利用互联网分发教育资源，旨在提供便捷的教育，但往往在与学生的实时交流方面存在不足。由于需要解决学生在学习过程中遇到的多样化障碍的挑战，它们经常难以提供个性化的教育资源。最近出现的大型语言模型（LLMs），如ChatGPT，提供了通过理解个体请求解决这一问题的可能性。虽然LLMs在各个领域都取得了成功，但基于LLM的教育系统的构建仍然面临着广泛的教育技能要求。本文回顾了与教育能力相关的近期出现的LLM研究，包括数学、写作、编程、推理和基于知识的问答，旨在探索它们在构建下一代智能教育系统方面的潜力。

    Online education platforms, leveraging the internet to distribute education resources, seek to provide convenient education but often fall short in real-time communication with students. They often struggle to offer personalized education resources due to the challenge of addressing the diverse obstacles students encounter throughout their learning journey. Recently, the emergence of large language models (LLMs), such as ChatGPT, offers the possibility for resolving this issue by comprehending individual requests. Although LLMs have been successful in various fields, creating an LLM-based education system is still challenging for the wide range of educational skills required. This paper reviews the recently emerged LLM researches related to educational capabilities, including mathematics, writing, programming, reasoning, and knowledge-based question answering, with the aim to explore their potential in constructing the next-generation intelligent education system. Based on the current 
    
[^21]: ODIN: 一个用于2D和3D感知的单一模型

    ODIN: A Single Model for 2D and 3D Perception. (arXiv:2401.02416v1 [cs.CV])

    [http://arxiv.org/abs/2401.02416](http://arxiv.org/abs/2401.02416)

    ODIN是一个模型，可以同时对2D RGB图像和3D点云进行分割和标记，使用变压器架构进行2D和3D视图间的信息融合。

    

    目前的先进模型在像ScanNet这样的当代3D感知基准上使用并标记依赖于数据集提供的3D点云，该点云是通过对感知到的多视角RGB-D图像进行后处理获得的。它们通常在领域内进行训练，放弃了大规模的2D预训练，并且胜过将姿态RGB-D多视角图像进行特征化的替代方案。消耗姿态图像和后处理的3D点云之间的性能差距，加剧了2D和3D感知需要不同模型架构的观点。在本文中，我们挑战这个观点，并提出ODIN（Omni-Dimensional INstance segmentation），一种能够使用变压器架构对2D RGB图像和3D点云进行分割和标记的模型，该模型通过交替的2D视图内和3D视图间信息融合来区分2D和3D特征操作，利用涉及的令牌的位置编码来捕捉2D补丁令牌和3D坐标的像素坐标。

    State-of-the-art models on contemporary 3D perception benchmarks like ScanNet consume and label dataset-provided 3D point clouds, obtained through post processing of sensed multiview RGB-D images. They are typically trained in-domain, forego large-scale 2D pre-training and outperform alternatives that featurize the posed RGB-D multiview images instead. The gap in performance between methods that consume posed images versus post-processed 3D point clouds has fueled the belief that 2D and 3D perception require distinct model architectures. In this paper, we challenge this view and propose ODIN (Omni-Dimensional INstance segmentation), a model that can segment and label both 2D RGB images and 3D point clouds, using a transformer architecture that alternates between 2D within-view and 3D cross-view information fusion. Our model differentiates 2D and 3D feature operations through the positional encodings of the tokens involved, which capture pixel coordinates for 2D patch tokens and 3D coor
    
[^22]: 使用张量卷积神经网络提高制造业中的缺陷检测

    Boosting Defect Detection in Manufacturing using Tensor Convolutional Neural Networks. (arXiv:2401.01373v1 [cs.CV])

    [http://arxiv.org/abs/2401.01373](http://arxiv.org/abs/2401.01373)

    我们引入了一种张量卷积神经网络（T-CNN）来提高制造业中的缺陷检测任务，通过减少模型参数空间，我们实现了比等效CNN模型更快的训练速度和性能。与传统的人类视觉检查相比，在质量指标方面，T-CNN在参数数量上只有15倍少，训练时间快4%至19%。这项研究在实际制造应用中取得了显著的成果。

    

    缺陷检测是制造业质量控制阶段中最重要但也最具挑战性的任务之一。在本研究中，我们引入了一种张量卷积神经网络（T-CNN），并在罗伯特·博世制造厂生产的超声波传感器组件的真实缺陷检测应用中考察其性能。我们的量子启发式T-CNN在减少的模型参数空间上运行，极大地提高了等效CNN模型的训练速度和性能，而不会牺牲准确性。具体来说，我们演示了T-CNN可以通过质量指标来衡量与传统CNN相同的性能，但参数数量只有其15倍少，训练时间快4%至19%。我们的结果表明，T-CNN大大超越了传统人类视觉检查的结果，在当前制造应用中具有价值。

    Defect detection is one of the most important yet challenging tasks in the quality control stage in the manufacturing sector. In this work, we introduce a Tensor Convolutional Neural Network (T-CNN) and examine its performance on a real defect detection application in one of the components of the ultrasonic sensors produced at Robert Bosch's manufacturing plants. Our quantum-inspired T-CNN operates on a reduced model parameter space to substantially improve the training speed and performance of an equivalent CNN model without sacrificing accuracy. More specifically, we demonstrate how T-CNNs are able to reach the same performance as classical CNNs as measured by quality metrics, with up to fifteen times fewer parameters and 4% to 19% faster training times. Our results demonstrate that the T-CNN greatly outperforms the results of traditional human visual inspection, providing value in a current real application in manufacturing.
    
[^23]: FENet: 增强聚焦网络用于车道检测

    FENet: Focusing Enhanced Network for Lane Detection. (arXiv:2312.17163v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.17163](http://arxiv.org/abs/2312.17163)

    FENet是一个增强聚焦网络用于精准车道检测，通过聚焦采样和部分视野评估等创新方法，显著提高了检测准确性，尤其适用于曲线和远距离车道，在安全性方面具有重要意义。

    

    受到人类驾驶注意力的启发，本研究首次开发了增强聚焦采样、部分视野评估、增强FPN架构和定向IoU损失的网络创新，解决了自动驾驶车道检测中的精准性障碍。实验证明，我们的聚焦采样策略，强调远处重要细节，与均匀方法相比，显著提高了基准和实际曲线/远距离车道识别的准确性，这对安全至关重要。虽然FENetV1通过模拟驾驶员视觉的透视感知上下文改进，实现了最先进的传统度量性能，但FENetV2在提出的部分视野分析中证明是最可靠的。因此，我们特别推荐V2用于实际车道导航，尽管在标准的整张图像测量上有轻微的降级。未来的方向包括收集实际道路数据和集成互补的双重框架，以进一步通过人类感知指导实现突破性进展。

    Inspired by human driving focus, this research pioneers networks augmented with Focusing Sampling, Partial Field of View Evaluation, Enhanced FPN architecture and Directional IoU Loss - targeted innovations addressing obstacles to precise lane detection for autonomous driving. Experiments demonstrate our Focusing Sampling strategy, emphasizing vital distant details unlike uniform approaches, significantly boosts both benchmark and practical curved/distant lane recognition accuracy essential for safety. While FENetV1 achieves state-of-the-art conventional metric performance via enhancements isolating perspective-aware contexts mimicking driver vision, FENetV2 proves most reliable on the proposed Partial Field analysis. Hence we specifically recommend V2 for practical lane navigation despite fractional degradation on standard entire-image measures. Future directions include collecting on-road data and integrating complementary dual frameworks to further breakthroughs guided by human perc
    
[^24]: 条件变分扩散模型

    Conditional Variational Diffusion Models. (arXiv:2312.02246v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.02246](http://arxiv.org/abs/2312.02246)

    该论文提出了一种新的条件变分扩散模型，通过学习调度作为训练过程的一部分，解决了扩散模型的敏感性问题，并且能够适应不同的应用场景，提供高质量的解决方案。

    

    逆问题旨在从观测中确定参数，这是工程和科学中的一个关键任务。最近，生成模型，特别是扩散模型，因其能够产生逼真的解决方案和良好的数学特性而在这一领域中越来越受欢迎。尽管取得了成功，但扩散模型的一个重要缺点是对方差调度的选择敏感，该调度控制着扩散过程的动态。为特定应用程序微调这个调度是至关重要的，但时间成本高昂，并且不能保证最优结果。我们提出了一种新颖的方法，将学习调度作为训练过程的一部分。我们的方法支持对数据的概率条件，提供高质量的解决方案，并且具有灵活性，能够在最小的开销下适应不同的应用。这种方法在两个不相关的逆问题中进行了测试：超分辨率显微镜和定量相位成像，结果表明比较或更好。

    Inverse problems aim to determine parameters from observations, a crucial task in engineering and science. Lately, generative models, especially diffusion models, have gained popularity in this area for their ability to produce realistic solutions and their good mathematical properties. Despite their success, an important drawback of diffusion models is their sensitivity to the choice of variance schedule, which controls the dynamics of the diffusion process. Fine-tuning this schedule for specific applications is crucial but time-costly and does not guarantee an optimal result. We propose a novel approach for learning the schedule as part of the training process. Our method supports probabilistic conditioning on data, provides high-quality solutions, and is flexible, proving able to adapt to different applications with minimum overhead. This approach is tested in two unrelated inverse problems: super-resolution microscopy and quantitative phase imaging, yielding comparable or superior 
    
[^25]: 无监督句法分析的集成蒸馏

    Ensemble Distillation for Unsupervised Constituency Parsing. (arXiv:2310.01717v1 [cs.CL])

    [http://arxiv.org/abs/2310.01717](http://arxiv.org/abs/2310.01717)

    本论文提出了一种集成蒸馏的方法来提高无监督句法解析的性能，并且通过蒸馏将集成知识转移到一个学生模型中，解决了常见的多教师蒸馏方法中的过度平滑问题。

    

    我们研究了无监督句法分析任务，该任务将句子的词和短语组织成一个层次结构，而不使用语言学注释的数据。我们观察到现有的无监督解析器捕捉到了解析结构的不同方面，可以利用这些来提高无监督分析的性能。为此，我们提出了“树平均”的概念，基于此我们进一步提出了一种新的无监督解析的集成方法。为了提高推理效率，我们进一步将集成知识蒸馏到一个学生模型中；这种集成-蒸馏的过程是缓解常见的多教师蒸馏方法中存在的过度平滑问题的有效方法。实验证明我们的方法超过了所有先前的方法，始终表现出其在不同集成组件和领域转移条件下的有效性和稳健性。

    We investigate the unsupervised constituency parsing task, which organizes words and phrases of a sentence into a hierarchical structure without using linguistically annotated data. We observe that existing unsupervised parsers capture differing aspects of parsing structures, which can be leveraged to enhance unsupervised parsing performance. To this end, we propose a notion of "tree averaging," based on which we further propose a novel ensemble method for unsupervised parsing. To improve inference efficiency, we further distill the ensemble knowledge into a student model; such an ensemble-then-distill process is an effective approach to mitigate the over-smoothing problem existing in common multi-teacher distilling methods. Experiments show that our method surpasses all previous approaches, consistently demonstrating its effectiveness and robustness across various runs, with different ensemble components, and under domain-shift conditions.
    
[^26]: 探索对比演示和显著性图在上下文学习中的作用

    Towards Understanding In-Context Learning with Contrastive Demonstrations and Saliency Maps. (arXiv:2307.05052v1 [cs.CL])

    [http://arxiv.org/abs/2307.05052](http://arxiv.org/abs/2307.05052)

    本研究探索了对比演示和显著性图在上下文学习中的作用，并发现改变标签对显著性有显著影响，尤其对于更大的语言模型更为明显。在情感分析任务中，将表达情感的术语改为中性词并不像改变标签那样具有显著影响。另外，补充解释在提高上下文学习方面是有效的。

    

    本文研究了在大型语言模型的上下文学习(ICL)性能中，各种演示组件的作用。具体而言，我们探讨了标签、输入分布和补充解释等因素的影响，特别是在这些因素被修改或扰动时的影响。我们基于之前的工作，这些工作对于这些元素如何影响ICL给出了不一致的结果。为了探究这些问题，我们采用了可解释的自然语言处理(XNLP)方法，并利用对比演示的显著性图进行定性和定量分析。我们的研究结果表明，改变标签对显著性有显著影响，尤其对于更大的语言模型更为明显。我们对输入分布进行了粒度级别的分析，发现在情感分析任务中，将表达情感的术语改为中性词并不像改变标签那样具有显著影响。最后，我们发现补充解释在提高ICL方面的效果是存在的。

    We investigate the role of various demonstration components in the in-context learning (ICL) performance of large language models (LLMs). Specifically, we explore the impacts of ground-truth labels, input distribution, and complementary explanations, particularly when these are altered or perturbed. We build on previous work, which offers mixed findings on how these elements influence ICL. To probe these questions, we employ explainable NLP (XNLP) methods and utilize saliency maps of contrastive demonstrations for both qualitative and quantitative analysis. Our findings reveal that flipping ground-truth labels significantly affects the saliency, though it's more noticeable in larger LLMs. Our analysis of the input distribution at a granular level reveals that changing sentiment-indicative terms in a sentiment analysis task to neutral ones does not have as substantial an impact as altering ground-truth labels. Finally, we find that the effectiveness of complementary explanations in boos
    
[^27]: DocumentCLIP：链接换行文件中的图像和正文文本

    DocumentCLIP: Linking Figures and Main Body Text in Reflowed Documents. (arXiv:2306.06306v1 [cs.CV])

    [http://arxiv.org/abs/2306.06306](http://arxiv.org/abs/2306.06306)

    DocumentCLIP是一种显著性感知对比学习框架，用于理解文档内长文本和图像之间的交互作用。我们是第一个在多模态文档内部链接方面进行对比学习的人。

    

    视觉语言预训练模型通过理解图像和文本之间的对齐而在支持多媒体应用方面取得了巨大成功。然而，现有的视觉语言预训练模型主要集中在理解单个图像与一段文本相关联，而往往忽略了多句话与多个图像组成的文档内部的对齐。在本文中，我们提出了一种称为DocumentCLIP的显著性感知对比学习框架，以强制视觉语言预训练模型理解文档内长文本和图像之间的交互作用。我们的模型有助于对新闻文章、杂志、产品描述等具有更丰富语言和视觉内容的真实世界多模态文档理解。据我们所知，我们是第一个通过对比学习探索多模态文档内部链接的人。此外，我们收集了一个大型的Wikipedia数据集进行预培训，为训练提供了多样化的来源。

    Vision-language pretraining models have achieved great success in supporting multimedia applications by understanding the alignments between images and text. While existing vision-language pretraining models primarily focus on understanding single image associated with a single piece of text, they often ignore the alignment at the intra-document level, consisting of multiple sentences with multiple images. In this work, we propose DocumentCLIP, a salience-aware contrastive learning framework to enforce vision-language pretraining models to comprehend the interaction between images and longer text within documents. Our model is beneficial for the real-world multimodal document understanding like news article, magazines, product descriptions, which contain linguistically and visually richer content. To the best of our knowledge, we are the first to explore multimodal intra-document links by contrastive learning. In addition, we collect a large Wikipedia dataset for pretraining, which pro
    
[^28]: 面向对象检测的模型无关可解释人工智能

    Model-agnostic explainable artificial intelligence for object detection in image data. (arXiv:2303.17249v1 [cs.CV])

    [http://arxiv.org/abs/2303.17249](http://arxiv.org/abs/2303.17249)

    本文设计并实现了一种新的黑盒解释方法——BODEM，它采用了局部和远程掩蔽生成多个版本的输入图像，从而比目前用于解释对象检测的其他三种最先进的方法提供更详细和有用的解释。

    

    对象检测是计算机视觉中的基本任务之一，通过开发大型复杂的深度学习模型已经取得了很大进展。然而，缺乏透明度是一个重要的挑战，可能妨碍这些模型的广泛应用。可解释的人工智能是一个研究领域，其中开发方法来帮助用户理解基于人工智能的系统的行为、决策逻辑和漏洞。本文为了解释基于人工智能的对象检测系统设计和实现了一种名为Black-box Object Detection Explanation by Masking（BODEM）的黑盒说明方法，采用新的掩蔽方法。我们提出了局部和远程掩蔽来生成输入图像的多个版本。局部掩蔽用于干扰目标对象内的像素，以了解对象检测器对这些变化的反应，而远程掩蔽则用于研究对象检测器在图像背景上的行为。我们在三个基准数据集上的实验表明，与用于解释对象检测的其他三种最先进的方法相比，BODEM提供了更详细和有用的说明。

    Object detection is a fundamental task in computer vision, which has been greatly progressed through developing large and intricate deep learning models. However, the lack of transparency is a big challenge that may not allow the widespread adoption of these models. Explainable artificial intelligence is a field of research where methods are developed to help users understand the behavior, decision logics, and vulnerabilities of AI-based systems. Black-box explanation refers to explaining decisions of an AI system without having access to its internals. In this paper, we design and implement a black-box explanation method named Black-box Object Detection Explanation by Masking (BODEM) through adopting a new masking approach for AI-based object detection systems. We propose local and distant masking to generate multiple versions of an input image. Local masks are used to disturb pixels within a target object to figure out how the object detector reacts to these changes, while distant ma
    
[^29]: 众包中自适应强多数投票的全面特征化

    Full Characterization of Adaptively Strong Majority Voting in Crowdsourcing. (arXiv:2111.06390v2 [stat.AP] UPDATED)

    [http://arxiv.org/abs/2111.06390](http://arxiv.org/abs/2111.06390)

    本研究通过利用吸收式马尔可夫链对众包中自适应强多数投票进行建模和分析，得出了该投票过程的一些重要特征，包括共识投票的质量、投票数和需求的方差等。研究结果显示，可以通过调整阈值来实现在不同准确性水平的工人参与的投票过程中的质量等效。

    

    在众包中，通过让工人检查项目并对其正确性进行投票，可以实现质量控制。为了最小化不可靠工人响应的影响，采用了一个$\delta$-边界投票过程，直到超过了工人之间达成一致的预定阈值$\delta$为止，额外的投票将被征求意见。该过程被广泛采用，但仅作为一种经验法则。我们的研究提出了一种利用吸收式马尔可夫链来分析在众包过程中与这种投票过程相关的特征的建模方法。我们提供了一种闭式方程，用于描述所得出的共识投票的质量、达成共识所需的平均投票数、投票需求的方差和其他分布矩。我们的研究结果表明，可以调整阈值$\delta$以实现在使用具有不同准确性水平的工人的投票过程中的质量等效。我们还提供了与投票过程效率相等的支付费率。

    In crowdsourcing, quality control is commonly achieved by having workers examine items and vote on their correctness. To minimize the impact of unreliable worker responses, a $\delta$-margin voting process is utilized, where additional votes are solicited until a predetermined threshold $\delta$ for agreement between workers is exceeded. The process is widely adopted but only as a heuristic. Our research presents a modeling approach using absorbing Markov chains to analyze the characteristics of this voting process that matter in crowdsourced processes. We provide closed-form equations for the quality of resulting consensus vote, the expected number of votes required for consensus, the variance of vote requirements, and other distribution moments. Our findings demonstrate how the threshold $\delta$ can be adjusted to achieve quality equivalence across voting processes that employ workers with varying accuracy levels. We also provide efficiency-equalizing payment rates for voting proces
    

