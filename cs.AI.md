# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Large Language Models in Biomedical and Health Informatics: A Bibliometric Review](https://arxiv.org/abs/2403.16303) | LLMs已成为生物医学与健康信息学中重要的工具，本文献计量学综述全面展示了LLMs在各种BHI领域中的应用，提出了其对自然语言处理应用的改进，揭示了主要发展趋势和研究网络，并讨论了伦理关切和实际挑战。 |
| [^2] | [Robust Learning of Noisy Time Series Collections Using Stochastic Process Models with Motion Codes](https://arxiv.org/abs/2402.14081) | 使用具有学习谱核的混合高斯过程的潜变量模型方法，针对嘈杂时间序列数据进行鲁棒学习。 |
| [^3] | [MuChin: A Chinese Colloquial Description Benchmark for Evaluating Language Models in the Field of Music](https://arxiv.org/abs/2402.09871) | MuChin是一个用于评估多模态语言模型在音乐理解和描述方面性能的中文口语描述基准。 |
| [^4] | [Faster and Lighter LLMs: A Survey on Current Challenges and Way Forward](https://arxiv.org/abs/2402.01799) | 本调查文章概述了在提高LLM推理效果方面的最新方法和进展，通过实验评估不同压缩技术的有效性，并提出改进LLM推理效率的潜在未来方向。 |
| [^5] | [Can LLM-Generated Misinformation Be Detected?](https://arxiv.org/abs/2309.13788) | LLM生成的虚假信息可能比人类撰写的虚假信息更难以检测，具有更具欺骗性的风格，可能造成更多危害。 |
| [^6] | [LLMCheckup: Conversational Examination of Large Language Models via Interpretability Tools.](http://arxiv.org/abs/2401.12576) | LLMCheckup是一个可解释性工具，通过连接大型语言模型与可解释的AI工具，使用户能够与模型进行对话，生成自我解释并提供建议。 |
| [^7] | [Consistent Query Answering for Existential Rules under Tuple-Deletion Semantics.](http://arxiv.org/abs/2401.05743) | 我们研究了存在规则下基于元组删除语义的一致性查询回答，并确定了一般类别和若干子类别的数据复杂性。我们发现在某些情况下这些问题是可处理的，甚至可以进行一阶重写。这项研究提出了新的查询重写技术，可用于实现容忍不一致性的查询回答系统。 |
| [^8] | [Selectively Sharing Experiences Improves Multi-Agent Reinforcement Learning.](http://arxiv.org/abs/2311.00865) | 本文介绍了一种选择性多智能体强化学习方法，即选择性多智能体优先体验中继，代理之间共享有限数量的训练经验。与其他算法相比，该方法实现了去中心化训练，并取得了比基准算法和最先进算法更好的性能。 |
| [^9] | [DEFT: Data Efficient Fine-Tuning for Large Language Models via Unsupervised Core-Set Selection.](http://arxiv.org/abs/2310.16776) | 这项研究介绍了一种名为DEFT的数据高效微调框架，通过无监督核心集选择来最小化微调大规模语言模型所需的数据量。研究结果表明，DEFT模型在准确性上与现有模型相当，并且仅使用了70%的数据量。 |
| [^10] | [Correspondence learning between morphologically different robots through task demonstrations.](http://arxiv.org/abs/2310.13458) | 本论文提出了一种学习不同形态机器人间对应关系的方法，通过演示实现了共同的潜变量表示，使得不同机器人可以更直接地转移技能。 |
| [^11] | [Learning Generalizable Tool-use Skills through Trajectory Generation.](http://arxiv.org/abs/2310.00156) | 通过轨迹生成，我们提出了一种学习通用工具使用技能的方法，可以适应不同形状的工具，从而使自主系统能够处理复杂的可变形物体操作任务。 |
| [^12] | [Uncertainty-driven Exploration Strategies for Online Grasp Learning.](http://arxiv.org/abs/2309.12038) | 本文提出了一种在线抓取学习方法，通过使用有效的探索策略，提高了机器人对未知环境的适应能力和抓取预测的准确性。 |
| [^13] | [Embed-Search-Align: DNA Sequence Alignment using Transformer Models.](http://arxiv.org/abs/2309.11087) | 这项研究使用Transformer模型对DNA序列进行对齐，通过生成数值表示来实现。相比传统方法，该方法在短DNA序列的分类任务上取得了更好的性能，对于基因组学分析具有潜在的应用价值。 |
| [^14] | [P-ROCKET: Pruning Random Convolution Kernels for Time Series Classification.](http://arxiv.org/abs/2309.08499) | 本研究提出了一种名为P-ROCKET的方法，通过在特征选择的角度删除卷积核，从而实现对时间序列分类中的随机卷积核进行剪枝。 |
| [^15] | [Rapid-INR: Storage Efficient CPU-free DNN Training Using Implicit Neural Representation.](http://arxiv.org/abs/2306.16699) | 本文提出了一种使用隐式神经表示进行高效的无CPU深度神经网络训练的新方法，通过在GPU上直接存储整个数据集以INR格式，减少了数据传输开销，从而加速训练过程。同时，采用高度并行化和实时执行的解码过程，进一步提升了压缩效果。 |
| [^16] | [LANISTR: Multimodal Learning from Structured and Unstructured Data.](http://arxiv.org/abs/2305.16556) | LANISTR是一个新颖的基于注意力机制的框架，可从结构化和非结构化数据中进行学习，在挑战性数据集上表现优异。 |
| [^17] | [Two is Better Than One: Digital Siblings to Improve Autonomous Driving Testing.](http://arxiv.org/abs/2305.08060) | 本文提出了数字孪生的概念，使用不同技术构建多个通用仿真器，强化了自动驾驶软件的基于仿真的测试，提高了测试结果的普适性和可靠性。 |
| [^18] | [CT Multi-Task Learning with a Large Image-Text (LIT) Model.](http://arxiv.org/abs/2304.02649) | 本研究通过将大型图像模型和大语言模型结合起来，建立了一个用于肺癌诊断的多任务CT大型图像文本（LIT）模型，能很好地执行肺部CT分割等多个医学任务。 |
| [^19] | [A Low Latency Adaptive Coding Spiking Framework for Deep Reinforcement Learning.](http://arxiv.org/abs/2211.11760) | 本文提出了一个低延迟自适应编码脉冲框架用于深度强化学习，在编码器灵活性、延迟和能量效率方面具有优异性能和广泛应用范围。 |

# 详细

[^1]: 生物医学与健康信息学中的大型语言模型：一项文献计量学综述

    Large Language Models in Biomedical and Health Informatics: A Bibliometric Review

    [https://arxiv.org/abs/2403.16303](https://arxiv.org/abs/2403.16303)

    LLMs已成为生物医学与健康信息学中重要的工具，本文献计量学综述全面展示了LLMs在各种BHI领域中的应用，提出了其对自然语言处理应用的改进，揭示了主要发展趋势和研究网络，并讨论了伦理关切和实际挑战。

    

    大型语言模型（LLMs）迅速成为生物医学与健康信息学（BHI）中的重要工具，为分析数据、治疗患者和开展研究提供了新的方式。本文献计量学综述旨在通过检查自2022年至2023年的研究文章和合作网络，全面展示LLMs在BHI中的应用情况。它进一步探讨了LLMs如何可以改进各种BHI领域中的自然语言处理（NLP）应用，如医学诊断、患者参与、电子健康记录管理和个性化医学。为此，我们的文献计量学综述确定了关键趋势，绘制了研究网络，并突出了这个快速发展领域的主要进展。最后，它讨论了在BHI中使用LLMs的伦理关切和实际挑战，如数据隐私和可靠的医疗建议。展望未来，我们考虑LLMs如何进一步改变生物医学研究。

    arXiv:2403.16303v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have rapidly become important tools in Biomedical and Health Informatics (BHI), enabling new ways to analyze data, treat patients, and conduct research. This bibliometric review aims to provide a panoramic view of how LLMs have been used in BHI by examining research articles and collaboration networks from 2022 to 2023. It further explores how LLMs can improve Natural Language Processing (NLP) applications in various BHI areas like medical diagnosis, patient engagement, electronic health record management, and personalized medicine. To do this, our bibliometric review identifies key trends, maps out research networks, and highlights major developments in this fast-moving field. Lastly, it discusses the ethical concerns and practical challenges of using LLMs in BHI, such as data privacy and reliable medical recommendations. Looking ahead, we consider how LLMs could further transform biomedical research as we
    
[^2]: 使用具有运动代码的随机过程模型对嘈杂时间序列集合进行鲁棒学习

    Robust Learning of Noisy Time Series Collections Using Stochastic Process Models with Motion Codes

    [https://arxiv.org/abs/2402.14081](https://arxiv.org/abs/2402.14081)

    使用具有学习谱核的混合高斯过程的潜变量模型方法，针对嘈杂时间序列数据进行鲁棒学习。

    

    虽然时间序列分类和预测问题已经得到广泛研究，但具有任意时间序列长度的嘈杂时间序列数据的情况仍具挑战性。每个时间序列实例可以看作是嘈杂动态模型的一个样本实现，其特点是连续随机过程。对于许多应用，数据是混合的，由多个随机过程建模的几种类型的嘈杂时间序列序列组成，使得预测和分类任务变得更具挑战性。我们不是简单地将数据回归到每种时间序列类型，而是采用具有学习谱核的混合高斯过程的潜变量模型方法。更具体地说，我们为每种类型的嘈杂时间序列数据自动分配一个称为其运动代码的签名向量。然后，在每个分配的运动代码的条件下，我们推断出相关性的稀疏近似。

    arXiv:2402.14081v1 Announce Type: cross  Abstract: While time series classification and forecasting problems have been extensively studied, the cases of noisy time series data with arbitrary time sequence lengths have remained challenging. Each time series instance can be thought of as a sample realization of a noisy dynamical model, which is characterized by a continuous stochastic process. For many applications, the data are mixed and consist of several types of noisy time series sequences modeled by multiple stochastic processes, making the forecasting and classification tasks even more challenging. Instead of regressing data naively and individually to each time series type, we take a latent variable model approach using a mixtured Gaussian processes with learned spectral kernels. More specifically, we auto-assign each type of noisy time series data a signature vector called its motion code. Then, conditioned on each assigned motion code, we infer a sparse approximation of the corr
    
[^3]: MuChin：用于评估音乐领域中语言模型的中文口语描述基准

    MuChin: A Chinese Colloquial Description Benchmark for Evaluating Language Models in the Field of Music

    [https://arxiv.org/abs/2402.09871](https://arxiv.org/abs/2402.09871)

    MuChin是一个用于评估多模态语言模型在音乐理解和描述方面性能的中文口语描述基准。

    

    快速发展的多模态大型语言模型（LLMs）迫切需要新的基准来统一评估它们在理解和以文字描述音乐方面的性能。然而，由于音乐信息检索（MIR）算法与人类理解之间的语义差距，专业人士和公众之间的差异，以及注释的低精度，现有的音乐描述数据集无法作为基准。为此，我们提出了MuChin，这是第一个用中文口语描述的开源音乐描述基准，旨在评估多模态LLMs在理解和描述音乐方面的性能。我们建立了采虫音乐注释平台（CaiMAP），采用创新的多人、多阶段保证方法，并招募了业余爱好者和专业人士，以确保注释的精度和与流行语义的对齐。利用这种方法，我们构建了一个数据集。

    arXiv:2402.09871v1 Announce Type: cross  Abstract: The rapidly evolving multimodal Large Language Models (LLMs) urgently require new benchmarks to uniformly evaluate their performance on understanding and textually describing music. However, due to semantic gaps between Music Information Retrieval (MIR) algorithms and human understanding, discrepancies between professionals and the public, and low precision of annotations, existing music description datasets cannot serve as benchmarks. To this end, we present MuChin, the first open-source music description benchmark in Chinese colloquial language, designed to evaluate the performance of multimodal LLMs in understanding and describing music. We established the Caichong Music Annotation Platform (CaiMAP) that employs an innovative multi-person, multi-stage assurance method, and recruited both amateurs and professionals to ensure the precision of annotations and alignment with popular semantics. Utilizing this method, we built a dataset w
    
[^4]: 更快更轻的LLMs：当前挑战和未来发展的调查

    Faster and Lighter LLMs: A Survey on Current Challenges and Way Forward

    [https://arxiv.org/abs/2402.01799](https://arxiv.org/abs/2402.01799)

    本调查文章概述了在提高LLM推理效果方面的最新方法和进展，通过实验评估不同压缩技术的有效性，并提出改进LLM推理效率的潜在未来方向。

    

    尽管LLMs表现出色，但由于推理过程中需要大量的计算和内存资源，它们的普及面临着挑战。最近在模型压缩和系统级优化方法方面的进展旨在增强LLM推理效果。本调查提供了这些方法的概述，强调了最近的发展。通过对LLaMA(/2)-7B的实验，我们评估了各种压缩技术，为在统一环境中高效部署LLM提供了实践见解。对LLaMA(/2)-7B的实证分析突出了这些方法的有效性。基于调查结果，我们确定了当前的局限性，并讨论了改善LLM推理效率的潜在未来方向。我们在https://github.com/nyunAI/Faster-LLM-Survey发布了用于复现本文结果的代码库。

    Despite the impressive performance of LLMs, their widespread adoption faces challenges due to substantial computational and memory requirements during inference. Recent advancements in model compression and system-level optimization methods aim to enhance LLM inference. This survey offers an overview of these methods, emphasizing recent developments. Through experiments on LLaMA(/2)-7B, we evaluate various compression techniques, providing practical insights for efficient LLM deployment in a unified setting. The empirical analysis on LLaMA(/2)-7B highlights the effectiveness of these methods. Drawing from survey insights, we identify current limitations and discuss potential future directions to improve LLM inference efficiency. We release the codebase to reproduce the results presented in this paper at https://github.com/nyunAI/Faster-LLM-Survey
    
[^5]: 能够检测到LLM生成的虚假信息吗?

    Can LLM-Generated Misinformation Be Detected?

    [https://arxiv.org/abs/2309.13788](https://arxiv.org/abs/2309.13788)

    LLM生成的虚假信息可能比人类撰写的虚假信息更难以检测，具有更具欺骗性的风格，可能造成更多危害。

    

    大型语言模型（LLMs）的出现产生了深远影响。然而，LLMs（如ChatGPT）可能被利用来生成虚假信息，这给在线安全和公众信任带来了严重关切。一个基本的研究问题是：LLM生成的虚假信息是否会比人类撰写的虚假信息造成更大危害?我们提出从检测难度的角度来探讨这个问题。我们首先建立了一个LLM生成的虚假信息分类法。然后，我们对利用LLMs生成虚假信息的潜在真实世界方法进行分类和验证。通过广泛的实证调查，我们发现与具有相同语义的人类撰写的虚假信息相比，LLM生成的虚假信息对人类和检测器来说更难检测，这表明它可能具有更具欺骗性的风格，潜在地造成更多危害。我们还讨论了我们发现的影响。

    arXiv:2309.13788v3 Announce Type: replace-cross  Abstract: The advent of Large Language Models (LLMs) has made a transformative impact. However, the potential that LLMs such as ChatGPT can be exploited to generate misinformation has posed a serious concern to online safety and public trust. A fundamental research question is: will LLM-generated misinformation cause more harm than human-written misinformation? We propose to tackle this question from the perspective of detection difficulty. We first build a taxonomy of LLM-generated misinformation. Then we categorize and validate the potential real-world methods for generating misinformation with LLMs. Then, through extensive empirical investigation, we discover that LLM-generated misinformation can be harder to detect for humans and detectors compared to human-written misinformation with the same semantics, which suggests it can have more deceptive styles and potentially cause more harm. We also discuss the implications of our discovery
    
[^6]: LLMCheckup：通过可解释性工具对大型语言模型进行对话式检查

    LLMCheckup: Conversational Examination of Large Language Models via Interpretability Tools. (arXiv:2401.12576v1 [cs.CL])

    [http://arxiv.org/abs/2401.12576](http://arxiv.org/abs/2401.12576)

    LLMCheckup是一个可解释性工具，通过连接大型语言模型与可解释的AI工具，使用户能够与模型进行对话，生成自我解释并提供建议。

    

    提供以对话形式进行解释的可解释性工具已经证明在增强用户理解方面具有效果，因为一次性解释有时无法提供足够的信息给用户。然而，当前基于对话的解释方案需要许多依赖项，并且不容易转移到它们未设计的任务上。通过LLMCheckup，我们提供了一个易于访问的工具，允许用户与任何最新的大型语言模型（LLM）进行对话以了解其行为。我们使LLMs能够自行生成所有解释，并通过与一系列可解释性AI（XAI）工具（例如特征归因、基于嵌入的相似性以及反事实和基于理由生成的提示策略）连接，以完成意图识别而无需微调。LLM（自我）解释以交互对话的形式呈现，支持后续问题和生成建议。

    Interpretability tools that offer explanations in the form of a dialogue have demonstrated their efficacy in enhancing users' understanding, as one-off explanations may occasionally fall short in providing sufficient information to the user. Current solutions for dialogue-based explanations, however, require many dependencies and are not easily transferable to tasks they were not designed for. With LLMCheckup, we present an easily accessible tool that allows users to chat with any state-of-the-art large language model (LLM) about its behavior. We enable LLMs to generate all explanations by themselves and take care of intent recognition without fine-tuning, by connecting them with a broad spectrum of Explainable AI (XAI) tools, e.g. feature attributions, embedding-based similarity, and prompting strategies for counterfactual and rationale generation. LLM (self-)explanations are presented as an interactive dialogue that supports follow-up questions and generates suggestions. LLMCheckup p
    
[^7]: 在元组删除语义下的存在规则一致性查询回答

    Consistent Query Answering for Existential Rules under Tuple-Deletion Semantics. (arXiv:2401.05743v1 [cs.AI])

    [http://arxiv.org/abs/2401.05743](http://arxiv.org/abs/2401.05743)

    我们研究了存在规则下基于元组删除语义的一致性查询回答，并确定了一般类别和若干子类别的数据复杂性。我们发现在某些情况下这些问题是可处理的，甚至可以进行一阶重写。这项研究提出了新的查询重写技术，可用于实现容忍不一致性的查询回答系统。

    

    我们研究了基于存在规则的知识库的一致性查询回答。具体地，我们确定了在元组删除语义下一般类别的多义存在规则以及其若干子类别（无环、线性、完全、保护和粘滞）的一致性查询回答和修复检查的数据复杂性。特别地，我们识别出了几种情况，在这些情况下这些问题是可处理的，甚至可以进行一阶重写，并呈现了新的查询重写技术，可以成为实用的容忍不一致性查询回答系统的基础。

    We study consistent query answering over knowledge bases expressed by existential rules. Specifically, we establish the data complexity of consistent query answering and repair checking under tuple-deletion semantics for a general class of disjunctive existential rules and for several subclasses thereof (acyclic, linear, full, guarded, and sticky). In particular, we identify several cases in which the above problems are tractable or even first-order rewritable, and present new query rewriting techniques that can be the basis for practical inconsistency-tolerant query answering systems.
    
[^8]: 选择性分享体验提升多智能体强化学习

    Selectively Sharing Experiences Improves Multi-Agent Reinforcement Learning. (arXiv:2311.00865v1 [cs.LG])

    [http://arxiv.org/abs/2311.00865](http://arxiv.org/abs/2311.00865)

    本文介绍了一种选择性多智能体强化学习方法，即选择性多智能体优先体验中继，代理之间共享有限数量的训练经验。与其他算法相比，该方法实现了去中心化训练，并取得了比基准算法和最先进算法更好的性能。

    

    我们提出了一种新颖的多智能体强化学习方法，即选择性多智能体优先体验中继，其中代理通过分享训练过程中观察到的有限的转换与其他代理共享。其背后的直觉是，来自其他代理的少量相关经验可以帮助每个代理学习。与许多其他多智能体强化学习算法不同，该方法允许基本去中心化的训练，只需要代理之间的有限通信渠道。我们展示了我们的方法优于基准无共享去中心化训练和最先进的多智能体强化学习算法。此外，仅分享少量高度相关的经验优于代理之间的所有经验共享，而且选择性体验共享的性能提升在各种超参数和DQN变体中均具有鲁棒性。我们的算法的参考实现可在https://github.com/mgerstgrasser/super获得。

    We present a novel multi-agent RL approach, Selective Multi-Agent Prioritized Experience Relay, in which agents share with other agents a limited number of transitions they observe during training. The intuition behind this is that even a small number of relevant experiences from other agents could help each agent learn. Unlike many other multi-agent RL algorithms, this approach allows for largely decentralized training, requiring only a limited communication channel between agents. We show that our approach outperforms baseline no-sharing decentralized training and state-of-the art multi-agent RL algorithms. Further, sharing only a small number of highly relevant experiences outperforms sharing all experiences between agents, and the performance uplift from selective experience sharing is robust across a range of hyperparameters and DQN variants. A reference implementation of our algorithm is available at https://github.com/mgerstgrasser/super.
    
[^9]: DEFT：通过无监督核心集选择实现大规模语言模型数据高效微调

    DEFT: Data Efficient Fine-Tuning for Large Language Models via Unsupervised Core-Set Selection. (arXiv:2310.16776v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.16776](http://arxiv.org/abs/2310.16776)

    这项研究介绍了一种名为DEFT的数据高效微调框架，通过无监督核心集选择来最小化微调大规模语言模型所需的数据量。研究结果表明，DEFT模型在准确性上与现有模型相当，并且仅使用了70%的数据量。

    

    最近的进展使得许多预训练语言模型（PLMs）可以使用；然而，一个仍然存在的问题是微调PLMs以用于下游任务究竟需要多少数据？在这项工作中，我们介绍了DEFT，一种数据高效的微调框架，它利用无监督的核心集选择来最小化微调PLMs所需的数据量。我们在文本编辑LM的背景下展示了DEFT框架的有效性，并与最先进的文本编辑模型CoEDIT进行了比较。我们的定量和定性结果表明，DEFT模型在准确性上与CoEDIT一样，而使用的数据量要少约70%。

    Recent advances have led to the availability of many pre-trained language models (PLMs); however, a question that remains is how much data is truly needed to fine-tune PLMs for downstream tasks? In this work, we introduce DEFT, a data-efficient fine-tuning framework that leverages unsupervised core-set selection to minimize the amount of data needed to fine-tune PLMs for downstream tasks. We demonstrate the efficacy of our DEFT framework in the context of text-editing LMs, and compare to the state-of-the art text-editing model, CoEDIT. Our quantitative and qualitative results demonstrate that DEFT models are just as accurate as CoEDIT while being finetuned on ~70% less data.
    
[^10]: 不同形态机器人间的任务演示学习与对应关系

    Correspondence learning between morphologically different robots through task demonstrations. (arXiv:2310.13458v1 [cs.RO])

    [http://arxiv.org/abs/2310.13458](http://arxiv.org/abs/2310.13458)

    本论文提出了一种学习不同形态机器人间对应关系的方法，通过演示实现了共同的潜变量表示，使得不同机器人可以更直接地转移技能。

    

    我们观察到机器人在其机身、传感器和执行器方面有着各种各样的差异。考虑到机器人领域的巨大多样性，独立地教导每个不同机器人的每个技能是低效且不可扩展的。如果我们能够学习不同机器人的感官运动空间之间的对应关系，那么我们可以期望在一个机器人上学习的技能可以更直接有效地转移到其他机器人上。本文提出了一种方法，在具有关节控制的固定基座操纵机器人和差动驱动移动机器人之间学习对应关系。为此，首先让两个机器人进行执行相同任务的演示。在学习对应策略的同时形成一个共同的潜变量表示。在这个初始学习阶段之后，通过观察一个机器人的新任务执行就足以生成一个潜变量的表示，从而实现对应关系的学习。

    We observe a large variety of robots in terms of their bodies, sensors, and actuators. Given the commonalities in the skill sets, teaching each skill to each different robot independently is inefficient and not scalable when the large variety in the robotic landscape is considered. If we can learn the correspondences between the sensorimotor spaces of different robots, we can expect a skill that is learned in one robot can be more directly and easily transferred to the other robots. In this paper, we propose a method to learn correspondences between robots that have significant differences in their morphologies: a fixed-based manipulator robot with joint control and a differential drive mobile robot. For this, both robots are first given demonstrations that achieve the same tasks. A common latent representation is formed while learning the corresponding policies. After this initial learning stage, the observation of a new task execution by one robot becomes sufficient to generate a lat
    
[^11]: 通过轨迹生成学习具有通用性的工具使用技能

    Learning Generalizable Tool-use Skills through Trajectory Generation. (arXiv:2310.00156v1 [cs.RO])

    [http://arxiv.org/abs/2310.00156](http://arxiv.org/abs/2310.00156)

    通过轨迹生成，我们提出了一种学习通用工具使用技能的方法，可以适应不同形状的工具，从而使自主系统能够处理复杂的可变形物体操作任务。

    

    高效利用工具的自主系统可以帮助人们完成许多常见任务，如烹饪和清洁。然而，当前的系统在适应新工具方面远远不及人类的智能水平。基于可及性的先前工作通常对环境做出了很强的假设，并且无法扩展到更复杂、接触丰富的任务。 在这项工作中，我们解决了这个挑战，并探索了代理如何学习使用以前未见过的工具来操纵可变形物体。 我们提出了将工具使用轨迹作为一系列点云的生成模型，可以推广到不同的工具形状。对于任何新的工具，我们首先生成一个工具使用轨迹，然后优化工具姿势序列以与生成的轨迹对齐。我们为四种不同的具有挑战性的可变形物体操纵任务训练了一个单一模型。我们的模型仅使用每个任务的单个工具的示范数据进行训练，并且能够...

    Autonomous systems that efficiently utilize tools can assist humans in completing many common tasks such as cooking and cleaning. However, current systems fall short of matching human-level of intelligence in terms of adapting to novel tools. Prior works based on affordance often make strong assumptions about the environments and cannot scale to more complex, contact-rich tasks. In this work, we tackle this challenge and explore how agents can learn to use previously unseen tools to manipulate deformable objects. We propose to learn a generative model of the tool-use trajectories as a sequence of point clouds, which generalizes to different tool shapes. Given any novel tool, we first generate a tool-use trajectory and then optimize the sequence of tool poses to align with the generated trajectory. We train a single model for four different challenging deformable object manipulation tasks. Our model is trained with demonstration data from just a single tool for each task and is able to 
    
[^12]: 在线抓取学习中基于不确定性驱动的探索策略

    Uncertainty-driven Exploration Strategies for Online Grasp Learning. (arXiv:2309.12038v1 [cs.RO])

    [http://arxiv.org/abs/2309.12038](http://arxiv.org/abs/2309.12038)

    本文提出了一种在线抓取学习方法，通过使用有效的探索策略，提高了机器人对未知环境的适应能力和抓取预测的准确性。

    

    现有的抓取预测方法主要基于离线学习，而忽略了在线适应新的拾取场景时的探索性抓取学习，例如未见目标组合、摄像机和箱子设置等。本文提出了一种新颖的用于机器人箱子拾取的在线抓取预测学习方法。具体而言，使用有效的探索策略的在线学习算法可以显著提高其对未见环境设置的适应性能力。为此，我们首先将在线抓取学习建模为强化学习问题，以实现对抓取策略的自适应学习。

    Existing grasp prediction approaches are mostly based on offline learning, while, ignored the exploratory grasp learning during online adaptation to new picking scenarios, i.e., unseen object portfolio, camera and bin settings etc. In this paper, we present a novel method for online learning of grasp predictions for robotic bin picking in a principled way. Existing grasp prediction approaches are mostly based on offline learning, while, ignored the exploratory grasp learning during online adaptation to new picking scenarios, i.e., unseen object portfolio, camera and bin settings etc. In this paper, we present a novel method for online learning of grasp predictions for robotic bin picking in a principled way. Specifically, the online learning algorithm with an effective exploration strategy can significantly improve its adaptation performance to unseen environment settings. To this end, we first propose to formulate online grasp learning as a RL problem that will allow to adapt both gra
    
[^13]: Embed-Search-Align: 使用Transformer模型进行DNA序列对齐

    Embed-Search-Align: DNA Sequence Alignment using Transformer Models. (arXiv:2309.11087v1 [q-bio.GN])

    [http://arxiv.org/abs/2309.11087](http://arxiv.org/abs/2309.11087)

    这项研究使用Transformer模型对DNA序列进行对齐，通过生成数值表示来实现。相比传统方法，该方法在短DNA序列的分类任务上取得了更好的性能，对于基因组学分析具有潜在的应用价值。

    

    DNA序列对齐涉及将短DNA读取分配到广泛的参考基因组上的最可能位置。这个过程对于各种基因组学分析至关重要，包括变异调用、转录组学和表观基因组学。传统方法经过数十年的改进，以两个步骤解决这个挑战：先进行基因组索引，然后进行高效搜索以确定给定读取的可能位置。在大规模语言模型（LLM）在将文本编码为嵌入向量方面取得成功的基础上，最近的研究努力探索了是否可以使用相同的Transformer架构为DNA序列生成数值表示。这样的模型已经在涉及分类短DNA序列的任务中显示出早期的潜力，例如检测编码和非编码区域以及识别增强子和启动子序列。然而，序列分类任务的性能并不能直接应用于序列对齐任务，对齐任务的关键是在保持序列相似性的同时找到最佳的对应位置。

    DNA sequence alignment involves assigning short DNA reads to the most probable locations on an extensive reference genome. This process is crucial for various genomic analyses, including variant calling, transcriptomics, and epigenomics. Conventional methods, refined over decades, tackle this challenge in two steps: genome indexing followed by efficient search to locate likely positions for given reads. Building on the success of Large Language Models (LLM) in encoding text into embeddings, where the distance metric captures semantic similarity, recent efforts have explored whether the same Transformer architecture can produce numerical representations for DNA sequences. Such models have shown early promise in tasks involving classification of short DNA sequences, such as the detection of coding vs non-coding regions, as well as the identification of enhancer and promoter sequences. Performance at sequence classification tasks does not, however, translate to sequence alignment, where i
    
[^14]: P-ROCKET: 针对时间序列分类的随机卷积核剪枝

    P-ROCKET: Pruning Random Convolution Kernels for Time Series Classification. (arXiv:2309.08499v1 [cs.LG])

    [http://arxiv.org/abs/2309.08499](http://arxiv.org/abs/2309.08499)

    本研究提出了一种名为P-ROCKET的方法，通过在特征选择的角度删除卷积核，从而实现对时间序列分类中的随机卷积核进行剪枝。

    

    在最近几年，两个时间序列分类模型ROCKET和MINIROCKET因其低训练成本和最先进的准确性而受到广泛关注。ROCKET和MINIROCKET利用无需训练的随机一维卷积核，可以快速从时间序列数据中提取特征，从而实现线性分类器的高效拟合。然而，为了全面捕捉有用的特征，需要大量的随机卷积核，这对于资源受限的设备来说是不兼容的。因此，我们设计了一种启发式进化算法S-ROCKET，用于识别和剪枝冗余的卷积核。然而，进化算法本身的特性导致在S-ROCKET中评估卷积核是一个耗时的过程。本文中，与直接评估具有非显著差异的随机卷积核的S-ROCKET不同，我们从特征选择的角度删除卷积核，通过消除序列中的相关连接来实现。

    In recent years, two time series classification models, ROCKET and MINIROCKET, have attracted much attention for their low training cost and state-of-the-art accuracy. Utilizing random 1-D convolutional kernels without training, ROCKET and MINIROCKET can rapidly extract features from time series data, allowing for the efficient fitting of linear classifiers. However, to comprehensively capture useful features, a large number of random kernels are required, which is incompatible for resource-constrained devices. Therefore, a heuristic evolutionary algorithm named S-ROCKET is devised to recognize and prune redundant kernels. Nevertheless, the inherent nature of evolutionary algorithms renders the evaluation of kernels within S-ROCKET an unacceptable time-consuming process. In this paper, diverging from S-ROCKET, which directly evaluates random kernels with nonsignificant differences, we remove kernels from a feature selection perspective by eliminating associating connections in the sequ
    
[^15]: 快速-INR: 使用隐式神经表示进行效率高的无CPU深度神经网络训练

    Rapid-INR: Storage Efficient CPU-free DNN Training Using Implicit Neural Representation. (arXiv:2306.16699v1 [cs.CV])

    [http://arxiv.org/abs/2306.16699](http://arxiv.org/abs/2306.16699)

    本文提出了一种使用隐式神经表示进行高效的无CPU深度神经网络训练的新方法，通过在GPU上直接存储整个数据集以INR格式，减少了数据传输开销，从而加速训练过程。同时，采用高度并行化和实时执行的解码过程，进一步提升了压缩效果。

    

    隐式神经表示(INR)是一种创新方法，用于表示复杂的形状或对象，而无需明确定义它们的几何形状或表面结构。相反，INR将对象表示为连续函数。先前的研究已经证明了将神经网络用作INR进行图像压缩的有效性，展示了与传统方法（如JPEG）相当的性能。然而，INR在图像压缩之外还具有各种应用潜力。本文介绍了Rapid-INR，一种利用INR对图像进行编码和压缩的新方法，从而加速计算机视觉任务中的神经网络训练。我们的方法在GPU上直接以INR格式存储整个数据集，减少了训练过程中CPU和GPU之间的数据传输开销。此外，从INR到RGB格式的解码过程高度并行化并实时执行。为了进一步提高压缩效果，我们提出了一种迭代的图像压缩算法。

    Implicit Neural Representation (INR) is an innovative approach for representing complex shapes or objects without explicitly defining their geometry or surface structure. Instead, INR represents objects as continuous functions. Previous research has demonstrated the effectiveness of using neural networks as INR for image compression, showcasing comparable performance to traditional methods such as JPEG. However, INR holds potential for various applications beyond image compression. This paper introduces Rapid-INR, a novel approach that utilizes INR for encoding and compressing images, thereby accelerating neural network training in computer vision tasks. Our methodology involves storing the whole dataset directly in INR format on a GPU, mitigating the significant data communication overhead between the CPU and GPU during training. Additionally, the decoding process from INR to RGB format is highly parallelized and executed on-the-fly. To further enhance compression, we propose iterativ
    
[^16]: LANISTR：从结构化和非结构化数据中进行多模态学习

    LANISTR: Multimodal Learning from Structured and Unstructured Data. (arXiv:2305.16556v1 [cs.LG])

    [http://arxiv.org/abs/2305.16556](http://arxiv.org/abs/2305.16556)

    LANISTR是一个新颖的基于注意力机制的框架，可从结构化和非结构化数据中进行学习，在挑战性数据集上表现优异。

    

    多模态的大规模预训练已经在处理非结构化数据（包括文本、图像、音频和视频）方面展现了令人瞩目的性能提升。但是，现实世界中最常见的情况是结构化（包括表格和时间序列）和非结构化数据的结合，但这一领域尚未得到充分的研究。为此，我们提出了LANISTR，这是一个新颖的基于注意力机制的框架，用于从语言、图像和结构化数据中进行学习。我们引入了一个新的多模态融合模块，并采用基于相似性的多模态遮罩损失，使得LANISTR能够在大规模多模态数据中学习跨模态关系，并在训练和测试时处理缺失的模态。在两个公开可用的具有挑战性的数据集MIMIC-IV和Amazon Product Review上，与最先进的多模态模型相比，LANISTR分别达到了6.47%（AUROC）和高达17.69%（准确度）的绝对提升，并显示出更强的泛化能力。

    Multimodal large-scale pretraining has shown impressive performance gains for unstructured data including language, image, audio, and video. Yet, the scenario most prominent in real-world applications is the existence of combination of structured (including tabular and time-series) and unstructured data, and this has so far been understudied. Towards this end, we propose LANISTR, a novel attention-based framework to learn from LANguage, Image, and STRuctured data. We introduce a new multimodal fusion module with a similarity-based multimodal masking loss that enables LANISTR to learn cross-modal relations from large-scale multimodal data with missing modalities during training and test time. On two publicly available challenging datasets, MIMIC-IV and Amazon Product Review, LANISTR achieves absolute improvements of 6.47% (AUROC) and up to 17.69% (accuracy), respectively, compared to the state-of-the-art multimodal models while showing superior generalization capabilities.
    
[^17]: 两个优于一个：数字孪生以提高自动驾驶测试

    Two is Better Than One: Digital Siblings to Improve Autonomous Driving Testing. (arXiv:2305.08060v1 [cs.SE])

    [http://arxiv.org/abs/2305.08060](http://arxiv.org/abs/2305.08060)

    本文提出了数字孪生的概念，使用不同技术构建多个通用仿真器，强化了自动驾驶软件的基于仿真的测试，提高了测试结果的普适性和可靠性。

    

    基于仿真的测试是确保自动驾驶软件可靠性的重要一步。实际中，当企业依赖第三方通用仿真器进行内部或外包测试时，测试结果的普适性受到威胁。在本文中，我们通过引入“数字孪生”的概念加强了基于仿真的测试，这是一个新颖的框架，在其中AV在多个使用不同技术构建的通用仿真器上进行测试。首先，针对每个单独的仿真器自动生成测试用例。然后，使用特征映射将测试迁移至各个仿真器之间，以表征所进行的行驶条件。最后，计算联合预测失效概率，并仅在孪生之间达成一致的情况下报告故障。我们使用两个开源仿真器实现了该框架，并在数字孪生的物理比例模型上进行了经验比较。

    Simulation-based testing represents an important step to ensure the reliability of autonomous driving software. In practice, when companies rely on third-party general-purpose simulators, either for in-house or outsourced testing, the generalizability of testing results to real autonomous vehicles is at stake.  In this paper, we strengthen simulation-based testing by introducing the notion of digital siblings, a novel framework in which the AV is tested on multiple general-purpose simulators, built with different technologies. First, test cases are automatically generated for each individual simulator. Then, tests are migrated between simulators, using feature maps to characterize of the exercised driving conditions. Finally, the joint predicted failure probability is computed and a failure is reported only in cases of agreement among the siblings.  We implemented our framework using two open-source simulators and we empirically compared it against a digital twin of a physical scaled a
    
[^18]: 带有大型图像文本（LIT）模型的CT多任务学习

    CT Multi-Task Learning with a Large Image-Text (LIT) Model. (arXiv:2304.02649v1 [eess.IV])

    [http://arxiv.org/abs/2304.02649](http://arxiv.org/abs/2304.02649)

    本研究通过将大型图像模型和大语言模型结合起来，建立了一个用于肺癌诊断的多任务CT大型图像文本（LIT）模型，能很好地执行肺部CT分割等多个医学任务。

    

    大语言模型（LLM）不仅能够支持多种语言任务，而且还可以作为不同领域的通用接口。迄今为止，还没有证明如何将LLM在计算机视觉领域的成功有效地转化为涉及高维和多模态医学图像的医学成像领域。在本文中，我们报告了一项可行性研究，通过组合LLM和大型图像模型（LIM），建立多任务CT大型图像文本（LIT）模型，用于肺癌诊断。具体而言，LLM和LIM用作编码器，根据特定任务的文本提示来感知多模态信息，从而协同作用于多源信息和任务特定和患者特定的先验，以优化诊断性能。我们的LIT模型和相关技术的关键组成部分将重点评估3D肺部CT分析。我们的初步结果表明，LIT模型能够很好地执行多项医学任务，包括肺分割。

    Large language models (LLM) not only empower multiple language tasks but also serve as a general interface across different spaces. Up to now, it has not been demonstrated yet how to effectively translate the successes of LLMs in the computer vision field to the medical imaging field which involves high-dimensional and multi-modal medical images. In this paper, we report a feasibility study of building a multi-task CT large image-text (LIT) model for lung cancer diagnosis by combining an LLM and a large image model (LIM). Specifically, the LLM and LIM are used as encoders to perceive multi-modal information under task-specific text prompts, which synergizes multi-source information and task-specific and patient-specific priors for optimized diagnostic performance. The key components of our LIT model and associated techniques are evaluated with an emphasis on 3D lung CT analysis. Our initial results show that the LIT model performs multiple medical tasks well, including lung segmentatio
    
[^19]: 一个低延迟自适应编码脉冲框架用于深度强化学习

    A Low Latency Adaptive Coding Spiking Framework for Deep Reinforcement Learning. (arXiv:2211.11760v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2211.11760](http://arxiv.org/abs/2211.11760)

    本文提出了一个低延迟自适应编码脉冲框架用于深度强化学习，在编码器灵活性、延迟和能量效率方面具有优异性能和广泛应用范围。

    

    近年来，由于低功耗和事件驱动特性，脉冲神经网络（SNNs）被用于强化学习（RL）。然而，固定编码方法导致的脉冲强化学习（SRL）仍然面临高延迟和较差的灵活性问题。本文中，我们使用可学习的矩阵乘法对脉冲进行编码和解码，提高编码器的灵活性，从而降低延迟。同时，我们使用直接训练方法训练SNNs，并使用两种不同的结构用于在线和离线强化学习算法，使我们的模型拥有更广泛的应用范围。广泛的实验表明，我们的方法在不同的算法和不同的环境中实现了最佳性能，延迟极低（仅为其他SRL方法的0.8%）且具有极高的能量效率（高达DNNs的5倍）。

    In recent years, spiking neural networks (SNNs) have been used in reinforcement learning (RL) due to their low power consumption and event-driven features. However, spiking reinforcement learning (SRL), which suffers from fixed coding methods, still faces the problems of high latency and poor versatility. In this paper, we use learnable matrix multiplication to encode and decode spikes, improving the flexibility of the coders and thus reducing latency. Meanwhile, we train the SNNs using the direct training method and use two different structures for online and offline RL algorithms, which gives our model a wider range of applications. Extensive experiments have revealed that our method achieves optimal performance with ultra-low latency (as low as 0.8% of other SRL methods) and excellent energy efficiency (up to 5X the DNNs) in different algorithms and different environments.
    

