# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models.](http://arxiv.org/abs/2401.01335) | 本文提出了一种名为自我对弱语言模型进行细调（SPIN）的方法，通过模型自我对弈生成训练数据，并从中优化模型策略，从而将弱语言模型转化为强语言模型，无需额外的人类标注数据。 |
| [^2] | [TREC iKAT 2023: The Interactive Knowledge Assistance Track Overview.](http://arxiv.org/abs/2401.01330) | TREC iKAT 2023是一个交互式的知识辅助任务，旨在开发适应用户交互和上下文的会话搜索代理。该任务还强调决策搜索任务，用户通过筛选数据和信息来进行决策和执行动作。 |
| [^3] | [An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction.](http://arxiv.org/abs/2401.01326) | 这篇论文提出了一种新颖的方法，通过将联合实体和关系抽取问题作为条件序列生成问题来解决。该方法使用了基于跨度的图生成方式，并通过指向机制将生成的输出与原始文本对齐。评估结果证明了该方法的有效性，并获得了竞争性的结果。 |
| [^4] | [LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning.](http://arxiv.org/abs/2401.01325) | 本研究提出了一种名为Self-Extend的方法，通过自身扩展现有LLMs的上下文窗口，无需调整，充分利用LLMs处理长上下文的固有能力。 |
| [^5] | [Experimental Validation of Sensor Fusion-based GNSS Spoofing Attack Detection Framework for Autonomous Vehicles.](http://arxiv.org/abs/2401.01304) | 本研究验证了一种基于传感器融合的GNSS欺骗攻击检测框架在自动驾驶车辆中的性能。该框架采用两种策略，分别是比较预测位置偏移和惯性传感器位置偏移以及利用转向角传感器来检测和分类转弯。实验结果证明了该框架的有效性。 |
| [^6] | [Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models.](http://arxiv.org/abs/2401.01301) | 大型语言模型存在法律幻觉，不一致法律事实，幻觉普遍存在高达69%至88%的情况，无法纠正用户错误法律假设。 |
| [^7] | [Physics-informed Generalizable Wireless Channel Modeling with Segmentation and Deep Learning: Fundamentals, Methodologies, and Challenges.](http://arxiv.org/abs/2401.01288) | 本论文介绍了基于物理信息神经网络（PINN）的无线信道建模方法，总结了其具有通用性、可解释性和鲁棒性等优点，并提出了一个综合的PINN方法体系结构，为未来模型发展提供指导与启示。另外，还针对室内信道预测提出了精确和深度学习的案例研究，同时探讨了相关挑战。 |
| [^8] | [A Comprehensive Study of Knowledge Editing for Large Language Models.](http://arxiv.org/abs/2401.01286) | 本研究全面研究了大型语言模型的知识编辑，旨在有效修改模型的行为，同时保持整体性能。 |
| [^9] | [LLbezpeky: Leveraging Large Language Models for Vulnerability Detection.](http://arxiv.org/abs/2401.01269) | LLbezpeky是一项利用大型语言模型进行漏洞检测的研究，研究发现LLMs在理解人类和编程语言中的语义方面展现出巨大潜力，并通过构建一个AI驱动的工作流程来帮助开发人员识别和修复漏洞。 |
| [^10] | [Optimal Synthesis of Finite State Machines with Universal Gates using Evolutionary Algorithm.](http://arxiv.org/abs/2401.01265) | 本文提出了一种使用进化算法综合有限状态机的最优化方法，通过减少门数来降低芯片面积和电路成本，实验结果显示平均减少了近30％的门数。 |
| [^11] | [Fairness Certification for Natural Language Processing and Large Language Models.](http://arxiv.org/abs/2401.01262) | 这项研究旨在为自然语言处理领域开发公平性认证方法。通过综述大量文献和专家访谈，我们提出了六个公平性标准，为操作化和测试过程提供了基础。 |
| [^12] | [Do Concept Bottleneck Models Obey Locality?.](http://arxiv.org/abs/2401.01259) | 本文研究了概念瓶颈模型（CBMs）是否能够正确捕捉到概念之间的条件独立程度，通过分析对于概念局部性之外特征的变化如何影响概念的预测。 |
| [^13] | [Encoding Binary Events from Continuous Time Series in Rooted Trees using Contrastive Learning.](http://arxiv.org/abs/2401.01242) | 本研究提出了一种对连续时间序列数据进行二进制事件编码的对比学习方法，具有推断本地网络拓扑结构的潜力。 |
| [^14] | [IdentiFace : A VGG Based Multimodal Facial Biometric System.](http://arxiv.org/abs/2401.01227) | 本文介绍了一种基于VGG的多模态人脸生物特征系统"IdentiFace"，通过将人脸识别与性别、脸型和情感等软生物特征相结合，实现了高效、有意义的结合。通过使用统一的架构和对学到的特征进行解释，该系统在高内类别变异下取得了99.2%的测试精确度。 |
| [^15] | [Zero-Shot Position Debiasing for Large Language Models.](http://arxiv.org/abs/2401.01218) | 本文提出了一种零样本位置去偏方法（ZOE）来降低大语言模型（LLMs）的位置偏差问题，该方法利用预训练的LLMs的无监督响应进行去偏。实验证实ZOE在多个数据集和任务中均表现出优异的性能。 |
| [^16] | [PPBFL: A Privacy Protected Blockchain-based Federated Learning Model.](http://arxiv.org/abs/2401.01204) | PPBFL是一种隐私保护的基于区块链的联邦学习模型，通过应用区块链和自适应差分隐私添加算法，增强了联邦学习的安全性和节点的积极参与。同时引入了交易混合机制，更好地保护本地训练的身份隐私。 |
| [^17] | [Skin cancer diagnosis using NIR spectroscopy data of skin lesions in vivo using machine learning algorithms.](http://arxiv.org/abs/2401.01200) | 这项研究讨论了使用近红外光谱数据进行皮肤病变诊断的机器学习算法。近红外光谱可以提供病变分子结构的信息，为自动计算机辅助诊断提供了替代信息来源。现代机器学习和深度学习技术对光谱学的应用也引起了越来越多的关注。 |
| [^18] | [JMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example.](http://arxiv.org/abs/2401.01199) | JMA是一种通用算法，用于生成几乎最优的定向对抗样本。该算法通过最小化Jacobian引起的马氏距离，考虑了将输入样本的潜在空间表示在给定方向上移动所需的投入。该算法在解决对抗样本问题方面提供了最优解。 |
| [^19] | [Uncertainty Resolution in Misinformation Detection.](http://arxiv.org/abs/2401.01197) | 该研究介绍了一种解决误解信息中不确定性的新方法，通过提出一个分类框架和生成有效的用户查询来解决缺失上下文的问题，提高了误解信息检测的性能。 |
| [^20] | [NID-SLAM: Neural Implicit Representation-based RGB-D SLAM in dynamic environments.](http://arxiv.org/abs/2401.01189) | NID-SLAM是一种基于神经隐式表示的RGB-D SLAM算法，它通过提升语义掩膜中的不准确区域和引入关键帧选择策略，显著改善了在动态环境下的性能，提高了跟踪精度和建图质量。 |
| [^21] | [Accurate and Efficient Urban Street Tree Inventory with Deep Learning on Mobile Phone Imagery.](http://arxiv.org/abs/2401.01180) | 本论文提出了一种利用深度学习技术和手机影像进行城市街道树木清查的创新方法，可以精确地分割树干并计算胸径，相比传统方法具有更高准确性、更少对专业设备的依赖，并适用于难以接触的地区。在实验证明，该方法在胸径估算上的准确率误差率小于2.5%，有望在城市街道树木清查方面产生显著的改进效果。 |
| [^22] | [Freeze the backbones: A Parameter-Efficient Contrastive Approach to Robust Medical Vision-Language Pre-training.](http://arxiv.org/abs/2401.01179) | 这项研究提出了一种冻结主干的适配器框架，可以实现参数高效的抗干扰医学视觉语言预训练。实验证明，该框架在保留信息的同时大大减少了可训练参数，并在医学图像分类和分割任务上取得了竞争性的性能。 |
| [^23] | [Quadratic Time-Frequency Analysis of Vibration Signals for Diagnosing Bearing Faults.](http://arxiv.org/abs/2401.01172) | 本文提出了一种融合时间频率分析和深度学习技术的方法，用于在实际条件下诊断带有时间变化速度和不同噪声水平的轴承故障。这种方法有效地解析与不同轴承故障相关的独特动态模式。 |
| [^24] | [Spiker+: a framework for the generation of efficient Spiking Neural Networks FPGA accelerators for inference at the edge.](http://arxiv.org/abs/2401.01141) | Spiker+是一个在边缘进行推理的高效Spiking神经网络FPGA加速器生成框架，具有低资源消耗和低功耗的特点。 |
| [^25] | [Explainable Adaptive Tree-based Model Selection for Time Series Forecasting.](http://arxiv.org/abs/2401.01124) | 提出了一种用于时间序列预测的在线选择基于树的模型的新方法，采用了TreeSHAP解释性方法进行模型的专门化，以应对基于树的模型在实际决策中的过拟合问题。 |
| [^26] | [Utilizing Autoregressive Networks for Full Lifecycle Data Generation of Rolling Bearings for RUL Prediction.](http://arxiv.org/abs/2401.01119) | 本文介绍了一种利用CVGAN模型生成滚动轴承振动信号的方法，该模型能够根据历史振动数据和剩余寿命条件生成一维振动信号，同时提出了一种自回归生成方法来指导信号的生成。实验证明，CVGAN模型在MMD和FID指标方面优于其他高级方法。 |
| [^27] | [AI-FLARES: Artificial Intelligence for the Analysis of Solar Flares Data.](http://arxiv.org/abs/2401.01104) | AI-FLARES是一项研究项目，通过开发和使用计算方法分析太阳耀斑数据，成果包括耀斑预测、耀斑源形态重建和太阳耀斑加速机制解释。 |
| [^28] | [Efficient Parallel Audio Generation using Group Masked Language Modeling.](http://arxiv.org/abs/2401.01099) | 我们提出了一种有效的并行语音生成方法，通过使用组掩码语言模型和组迭代并行解码，能够快速生成高质量的音频，并成功捕捉提示语音的说话人风格，提高了计算效率。 |
| [^29] | [Quokka: An Open-source Large Language Model ChatBot for Material Science.](http://arxiv.org/abs/2401.01089) | 本文介绍了Quokka——一个用于材料科学的开源大型语言模型聊天机器人，通过对超过一百万篇领域特定的论文进行预训练，并在材料科学领域的查询中提供即时的上下文意识响应。 |
| [^30] | [Vietnamese Poem Generation & The Prospect Of Cross-Language Poem-To-Poem Translation.](http://arxiv.org/abs/2401.01078) | 本文通过使用大型语言模型，成功提出了一种生成越南诗歌的方法，并探索了将诗歌翻译成不同语言的可能性，同时保持对生成内容的完全控制。 |
| [^31] | [Discovering Significant Topics from Legal Decisions with Selective Inference.](http://arxiv.org/abs/2401.01068) | 本研究提出了一个自动化流程，通过主题模型和统计分析方法从法律裁决文本中发现重要主题。该方法可以识别与结果相关的案例主题，并通过主题-词分布和案例-主题权重来提供更多信息。研究结果表明该方法具有很好的准确性和实用性。 |
| [^32] | [BEV-CLIP: Multi-modal BEV Retrieval Methodology for Complex Scene in Autonomous Driving.](http://arxiv.org/abs/2401.01065) | BEV-CLIP是一种用于自动驾驶中复杂场景的多模态BEV检索方法，通过使用描述性文本进行检索，利用大型语言模型的 semantic feature extraction 和知识图谱的半结构化信息来提高检索准确性。 |
| [^33] | [Enhancing Automatic Modulation Recognition through Robust Global Feature Extraction.](http://arxiv.org/abs/2401.01056) | 该论文提出了一种名为TLDNN的混合深度框架，将Transformer和LSTM的结构结合，通过全局特征提取和捕捉时域依赖性的增强，为自动调制识别带来了改进。 |
| [^34] | [LLaMA Beyond English: An Empirical Study on Language Capability Transfer.](http://arxiv.org/abs/2401.01055) | 本文提出了LLaMA超越英语：语言能力转移的实证研究。通过对LLaMA进行广泛的实证调查，分析了词汇扩展、进一步预训练和指导调整等关键因素对非英语语言上的能力转移的影响，并通过四个标准化测试基准评估了模型的知识水平和响应质量。 |
| [^35] | [Elastic Multi-Gradient Descent for Parallel Continual Learning.](http://arxiv.org/abs/2401.01054) | 这是一篇关于并行连续学习的论文，介绍了在动态多任务场景下的挑战和解决方法。通过使用任务特定的弹性因子，可以解决梯度差异和负迁移的问题。 |
| [^36] | [Auffusion: Leveraging the Power of Diffusion and Large Language Models for Text-to-Audio Generation.](http://arxiv.org/abs/2401.01044) | 这篇论文介绍了一种名为Auffusion的文本到音频生成系统，它利用扩散和大型语言模型，通过跨模态对齐的能力，提高了生成质量和文本-音频对齐。该系统在有限的数据和计算资源下胜过了之前的方法，并关注了编码器选择对跨模态对齐的重要性。 |
| [^37] | [Towards Cognitive AI Systems: a Survey and Prospective on Neuro-Symbolic AI.](http://arxiv.org/abs/2401.01040) | 本文回顾了神经符号人工智能的最新进展，分析了其模型的性能特征和计算运算符，并讨论了从系统和架构角度上NSAI面临的挑战和潜在未来方向。 |
| [^38] | [Fast Inference Through The Reuse Of Attention Maps In Diffusion Models.](http://arxiv.org/abs/2401.01008) | 本文提出了一种无需训练的方法，通过重用注意力映射来实现Text-to-image diffusion models中的快速推理，以提高效率。 |
| [^39] | [Towards Net-Zero Carbon Emissions in Network AI for 6G and Beyond.](http://arxiv.org/abs/2401.01007) | 本论文旨在实现6G及以后网络AI的零排放碳目标。通过确定排放源并引入评估框架，提出了一种联合动态能源交易和任务分配优化框架，以解决移动网络能源消耗和碳排放的问题。 |
| [^40] | [Metalearning-Informed Competence in Children: Implications for Responsible Brain-Inspired Artificial Intelligence.](http://arxiv.org/abs/2401.01001) | 本文提出了一个新颖的概念框架，该框架解释了儿童是如何通过四个认知机制实现元学习策略的，并以此作为模型，为基于脑启发式计算的人工智能提供启示。 |
| [^41] | [Safety and Performance, Why Not Both? Bi-Objective Optimized Model Compression against Heterogeneous Attacks Toward AI Software Deployment.](http://arxiv.org/abs/2401.00996) | 本文提出了一个名为SafeCompress的测试驱动稀疏训练框架，用于解决人工智能软件中的安全模型压缩问题。 |
| [^42] | [Real-Time Object Detection in Occluded Environment with Background Cluttering Effects Using Deep Learning.](http://arxiv.org/abs/2401.00986) | 本文集中研究了在有背景干扰效果和遮挡环境中利用深度学习进行实时目标检测的问题。通过应用SSD和YOLO算法，并改善检测精度，减少问题，我们得到了高准确性和高帧率的SSD-Mobilenet v2模型。 |
| [^43] | [Nature-Inspired Algorithms in Optimization: Introduction, Hybridization and Insights.](http://arxiv.org/abs/2401.00976) | 本论文综述了优化、自然启发式算法以及混合方法的概述，并讨论了算法混合过程中的问题。 |
| [^44] | [Downstream Task-Oriented Generative Model Selections on Synthetic Data Training for Fraud Detection Models.](http://arxiv.org/abs/2401.00974) | 本论文研究了欺诈检测模型训练中针对下游任务的生成模型选择问题，并调查了在不同的可解释性和性能约束条件下的最佳实践。研究结果表明，在合成训练欺诈检测模型时，贝叶斯网络（BN）的生成模型优于神经网络（NN）的生成模型。 |
| [^45] | [Data Augmentation Techniques for Cross-Domain WiFi CSI-based Human Activity Recognition.](http://arxiv.org/abs/2401.00964) | 本研究应用基于图像学习的数据增强技术于WiFi CSI，旨在解决人体活动识别中模型泛化能力差的问题。通过跨场景和跨系统的实验，研究了线性视线（LOS）和非线性视线（NLOS）穿墙场景之间以及不同天线系统之间的泛化效果。通过构建基于EfficientNetV2架构的活动识别模型并进行消融研究，评估了不同数据增强技术的效果。 |
| [^46] | [Automated Model Selection for Tabular Data.](http://arxiv.org/abs/2401.00961) | 本文介绍了一种自动化模型选择算法，用于表格数据的预测。该算法考虑了特征之间的交互，并包含了基于优先级的随机网格搜索和贪婪搜索两种不同的特征选择方法。 |
| [^47] | [Accurate Leukocyte Detection Based on Deformable-DETR and Multi-Level Feature Fusion for Aiding Diagnosis of Blood Diseases.](http://arxiv.org/abs/2401.00926) | 本文提出了一种创新的白细胞检测方法，使用多级特征融合和变形自注意DETR，通过解决白细胞尺度差异问题和提高检测精度，以改善传统血液检测的效率和准确性。 |
| [^48] | [Data Assimilation in Chaotic Systems Using Deep Reinforcement Learning.](http://arxiv.org/abs/2401.00916) | 本文介绍了一种使用强化学习在混沌系统中进行数据同化的新策略。该方法通过使用完整或部分观测的状态变量进行状态校正，旨在最小化观测和预测状态之间的误差。 |
| [^49] | [LaFFi: Leveraging Hybrid Natural Language Feedback for Fine-tuning Language Models.](http://arxiv.org/abs/2401.00907) | LaFFi是一种用于微调语言模型的替代方法，通过要求模型预测标注者将会给出的反馈，显著提高了在问答任务中的准确性，为应用自然语言反馈提供了一个有前途的方向。 |
| [^50] | [Masked Modeling for Self-supervised Representation Learning on Vision and Beyond.](http://arxiv.org/abs/2401.00897) | 蒙面建模是一种自监督学习方法，通过预测被蒙面部分实现深度模型学习稳健的表示，已在计算机视觉和自然语言处理等领域展现出卓越性能。 |
| [^51] | [Social-LLM: Modeling User Behavior at Scale using Language Models and Social Network Data.](http://arxiv.org/abs/2401.00893) | Social-LLM使用语言模型和社交网络数据，通过结合本地化社交网络互动和大型语言模型的能力，解决了在大规模社交网络数据建模中的计算挑战，实现了对用户行为的规模化建模。基于社交网络同质性的前提，该方法能够在用户检测任务中发挥重要作用。 |
| [^52] | [Automating Leukemia Diagnosis with Autoencoders: A Comparative Study.](http://arxiv.org/abs/2401.00883) | 本研究使用自动编码器开发出有价值的特征，提高了白血病诊断的准确性，并相较于传统的机器学习模型在精确度和F1-score指标上表现更好。 |
| [^53] | [Towards Bridging the Gap between High-Level Reasoning and Execution on Robots.](http://arxiv.org/abs/2401.00880) | 本论文提出了几种方法来解决机器人领域高级推理和执行之间的差距问题。 |
| [^54] | [Balanced Graph Structure Information for Brain Disease Detection.](http://arxiv.org/abs/2401.00876) | 这项工作提出了一种名为Bargrain的平衡脑图结构方法，通过同时模拟经过滤波的相关矩阵和最优样本图来改进脑疾病检测性能，并解决了仅依赖单一类型结构的限制。 |
| [^55] | [Teach Large Language Models to Forget Privacy.](http://arxiv.org/abs/2401.00870) | 这项研究提出了Prompt2Forget（P2F）框架，通过教导大型语言模型（LLM）忘记隐私信息，解决了LLM本地隐私挑战。P2F方法将问题分解为片段并生成虚构答案，模糊化模型对原始输入的记忆。实验证明，P2F具有很强的模糊化能力，并且可以在各种应用场景下自适应使用，无需手动设置。 |
| [^56] | [Tensor Networks for Explainable Machine Learning in Cybersecurity.](http://arxiv.org/abs/2401.00867) | 张量网络可以帮助发展可解释的机器学习算法，并提供丰富的模型可解释性。在网络安全中，我们的无监督聚类算法基于矩阵乘积状态，在性能上与传统的深度学习模型相媲美。我们的方法还能提取特征概率、熵和互信息，提供了分类异常的引人入胜的叙述，并实现了前所未有的透明度和可解释性水平。 |
| [^57] | [A Reliable Knowledge Processing Framework for Combustion Science using Foundation Models.](http://arxiv.org/abs/2401.00544) | 本研究介绍了一种可靠的知识处理框架，将大型语言模型整合到燃烧科学中。该框架通过使用基础模型和RAG框架，处理多样化的燃烧研究数据，最大限度地减少计算和经济开销，同时优化数据隐私和准确性。 |
| [^58] | [Towards Auto-Modeling of Formal Verification for NextG Protocols: A Multimodal cross- and self-attention Large Language Model Approach.](http://arxiv.org/abs/2312.17353) | AVRE是一种用于形式验证NextG通信协议的自动建模系统，利用大型语言模型转化协议描述为依赖图和形式模型，并通过交叉和自注意力机制建立可量化的依赖关系，进而提高了复杂通信协议的验证准确性和相关性。 |
| [^59] | [Hybrid Internal Model: Learning Agile Legged Locomotion with Simulated Robot Response.](http://arxiv.org/abs/2312.11460) | 本论文提出了一种混合内模方法，通过模拟机器人的响应来估计外部状态，这对于健壮的运动控制非常重要。使用对比学习优化嵌入表示，使其接近机器人的后继状态。这种方法只需要机器人的固有感知。 |
| [^60] | [Global Feature Pyramid Network.](http://arxiv.org/abs/2312.11231) | 全局特征金字塔网络 (GFPNet) 是一个增强版本的 PAFPN，通过整合全局信息来增强目标检测任务。通过捕获全局特征信息，并利用VNC编码器处理这些特征，GFPNet具有显着的优势，可以减少误检和漏检。 |
| [^61] | [MusER: Musical Element-Based Regularization for Generating Symbolic Music with Emotion.](http://arxiv.org/abs/2312.10307) | 本论文提出了一种名为MusER的音乐生成模型，通过引入基于音乐元素的正则化处理，实现了对不同音乐元素在情感中的作用的剖析，并进一步操纵元素来改变音乐的情感。这项研究填补了现有研究对情感音乐生成中音乐元素贡献的不足，并为细粒度的情感控制提供了新的方法。 |
| [^62] | [Data-Efficient Multimodal Fusion on a Single GPU.](http://arxiv.org/abs/2312.10144) | 本论文提出了一种在单一GPU上进行数据高效多模态融合的方法，通过使用预训练的单模态编码器的潜在空间，我们在多模态对齐中取得了有竞争力的性能，且计算和数据量减少了数个数量级。 |
| [^63] | [Rational Sensibility: LLM Enhanced Empathetic Response Generation Guided by Self-presentation Theory.](http://arxiv.org/abs/2312.08702) | 本文通过以自我展示理论为指导，设计了一种创新的分类方法，将历史对话分成合理和理性的句子，并通过注意力机制来阐明上下文，从而增强同理心回应生成的能力。 |
| [^64] | [Vision-based Learning for Drones: A Survey.](http://arxiv.org/abs/2312.05019) | 本文调查了基于视觉学习的无人机技术，指出其对无人机操作能力的关键作用，并提出了基于视觉学习的控制方法和各种应用的挑战与创新。 |
| [^65] | [A Study on the Calibration of In-context Learning.](http://arxiv.org/abs/2312.04021) | 本研究关注上下文学习（ICL），通过定制提示来调整静态语言模型（LMs），研究了在各种自然语言理解和推理任务中性能和校准之间的平衡。研究发现随着ICL示例数量的增加，模型的校准会先增加而后得到改善，而校准误差主要出现在低样本场景下。此外，微调和CoT提示等方法可能导致校准误差和不可靠的自然语言解释，提示需要针对可靠性场景开发新的方法。 |
| [^66] | [Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents.](http://arxiv.org/abs/2310.19923) | Jina Embeddings 2是一个能够处理长篇文档的文本嵌入模型，突破了传统512个标记限制，提供了高达8192个标记的容量。 |
| [^67] | [AI Alignment: A Comprehensive Survey.](http://arxiv.org/abs/2310.19852) | 本篇论文主要介绍了AI对齐的概念、方法和实践。研究围绕四个关键目标：健壮性、可解释性、可控性和道德性展开，并将其分为前向对齐和后向对齐两个部分。 AI对齐是为了构建符合人类意图和价值观的AI系统，并减轻由于系统不对齐带来的潜在风险。 |
| [^68] | [Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis.](http://arxiv.org/abs/2310.10477) | 该论文介绍了一种基于错误分析的对齐策略，通过暴露大型语言模型的错误输出并进行评估，以理解内部原因。通过这种方法，有毒回应可以转化为模型对齐的指导调谐语料，从而提高模型的安全性并训练其进行自我批评。 |
| [^69] | [Content Bias in Deep Learning Age Approximation: A new Approach Towards more Explainability.](http://arxiv.org/abs/2310.02067) | 本文提出了一种新的方法来评估深度学习年龄估计中的内容偏差，并验证了训练的神经网络依赖于图像内容。通过使用两种不同的技术减轻图像内容的影响，提出的方法具有潜在的对策效果。 |
| [^70] | [Multi-Modal Financial Time-Series Retrieval Through Latent Space Projections.](http://arxiv.org/abs/2309.16741) | 本文提出了一种通过深度编码器在低维潜空间中存储金融时间序列的多模态数据的框架，以捕捉数据的重要特征。 |
| [^71] | [Collaborative Watermarking for Adversarial Speech Synthesis.](http://arxiv.org/abs/2309.15224) | 本文提出了一种对抗性语音合成的协同水印技术，通过与现有对策模型合作进行训练，实现了对生成语音的有效检测和水印识别。 |
| [^72] | [Era Splitting.](http://arxiv.org/abs/2309.14496) | 本研究提出了两种新的分裂准则，使得决策树模型能够利用时代信息进行优化，从而将超分布泛化研究中的思想应用于决策树模型。 |
| [^73] | [Exploiting Causality Signals in Medical Images: A Pilot Study with Empirical Results.](http://arxiv.org/abs/2309.10399) | 本研究提出了一种利用医学图像中的因果信号进行自动分类的新方法，通过模型化图像中一个部分特征的存在如何影响另一个部分特征的外观，改善了分类性能并产生了更稳健的预测，聚焦于图像中的相关部分。 |
| [^74] | [CLIP-based Synergistic Knowledge Transfer for Text-based Person Retrieval.](http://arxiv.org/abs/2309.09496) | 本文提出了一种基于CLIP的文字化人物检索的协同知识传递（CSKT）方法，通过双向提示传递（BPT）和双适配器传递（DAT）实现了输入端和输出端的知识传递，并在三个基准数据集上取得了优于现有方法的性能。 |
| [^75] | [SayCanPay: Heuristic Planning with Large Language Models using Learnable Domain Knowledge.](http://arxiv.org/abs/2308.12682) | SayCanPay是一种结合了大型语言模型(LLMs)和启发式规划的方法，通过利用LLMs的世界知识和启发式搜索的原则，生成可行的最优计划。 |
| [^76] | [Evidence of Human-Like Visual-Linguistic Integration in Multimodal Large Language Models During Predictive Language Processing.](http://arxiv.org/abs/2308.06035) | 这篇论文研究了多模态大语言模型（mLLMs）在预测语言处理过程中与人类的视觉-语言集成能力是否一致的问题，并通过实验验证了mLLMs的多模态输入方法可以减少认知负荷，提高感知和理解能力。 |
| [^77] | [Convolutional Transformer for Autonomous Recognition and Grading of Tomatoes Under Various Lighting, Occlusion, and Ripeness Conditions.](http://arxiv.org/abs/2307.01530) | 本研究引入了一种卷积变换器架构的框架，能够在不同光照、遮挡和成熟度条件下自主识别和分级西红柿。 |
| [^78] | [RS5M: A Large Scale Vision-Language Dataset for Remote Sensing Vision-Language Foundation Model.](http://arxiv.org/abs/2306.11300) | 本文提出了一个新的框架RS5M，该框架包括领域基础模型（DFM），用于实现通用基础模型（GFM）和领域特定下游任务之间的转换。另外，还介绍了一个遥感领域的大规模图像-文本配对数据集RS5M，该数据集是通过过滤公开可用的图像-文本配对数据集并使用预训练的视觉-语言基础模型为标签数据集生成标题。 |
| [^79] | [In-depth analysis of music structure as a self-organized network.](http://arxiv.org/abs/2303.13631) | 本文介绍了一种利用Essential Element Network (EEN)算法将音频编码成文本并进行相关性计算和优化应用于聚类系数的频率和排名的方法，得到了音乐的深层结构信息，为厘清音乐结构提供了新方法。 |
| [^80] | [On the Application of Efficient Neural Mapping to Real-Time Indoor Localisation for Unmanned Ground Vehicles.](http://arxiv.org/abs/2211.04718) | 本文评估了将神经网络映射应用于实际机器人场景中的可行性，通过限制问题维度并增加训练数据量，可以实现嵌入式平台上几厘米级别的实时定位精度。 |
| [^81] | [Approximation analysis of CNNs from a feature extraction view.](http://arxiv.org/abs/2210.09041) | 本文通过深度卷积神经网络对线性特征提取进行了近似分析，并展示了深度学习相对于传统线性变换的强大能力。通过创造性的构造，我们有效地实现了线性特征提取，并且探究了深层网络的函数逼近速度。线性特征的多分辨卷积分解在我们的工作中起着核心作用。 |
| [^82] | [Estimating and Mitigating the Congestion Effect of Curbside Pick-ups and Drop-offs: A Causal Inference Approach.](http://arxiv.org/abs/2206.02164) | 该论文开发了一种严格的因果推断方法，评估了取货和送货对路边交通的拥堵影响，并提出了一种双重和分离的机器学习方法来量化这种影响。 |
| [^83] | [From Statistical Relational to Neural Symbolic Artificial Intelligence: a Survey.](http://arxiv.org/abs/2108.11451) | 这篇调查综述了NeSy和StarAI两种人工智能方法中，学习和推理的集成方法。共有七个维度用于对两种方法进行分类和比较。 |
| [^84] | [Tuned Compositional Feature Replays for Efficient Stream Learning.](http://arxiv.org/abs/2104.02206) | 本文提出了一种名为CRUMB的新的持续学习算法，通过重放通过重新组合特征图来缓解遗忘问题。CRUMB通过存储内存块的索引来使得在后续任务中能够回放特定的记忆，这种重建机制还可以帮助神经网络最小化灾难性遗忘。 |

# 详细

[^1]: 自我对弱语言模型进行细调可以将其转化为强语言模型

    Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models. (arXiv:2401.01335v1 [cs.LG])

    [http://arxiv.org/abs/2401.01335](http://arxiv.org/abs/2401.01335)

    本文提出了一种名为自我对弱语言模型进行细调（SPIN）的方法，通过模型自我对弈生成训练数据，并从中优化模型策略，从而将弱语言模型转化为强语言模型，无需额外的人类标注数据。

    

    通过监督细调（SFT）利用人类标注数据的力量对于推进大型语言模型（LLMs）至关重要。本文探讨了在不需要获取额外人类标注数据的情况下，将弱语言模型发展成为强语言模型的可能性。我们提出了一种名为自我对弱语言模型进行细调（SPIN）的新的细调方法，该方法从一个经过监督细调的模型开始。SPIN的核心是自我对弱语言模型的机制，其中弱语言模型通过与自身的实例对弈来提升自己的能力。具体而言，弱语言模型通过生成自己的训练数据来优化自身策略，通过区分自我生成的回应与来自人类标注数据的回应来改进。我们的方法逐步将弱语言模型提升为强大的模型，充分发掘人类标注示范数据在SFT中的潜力。在理论上，我们证明了该方法的训练目标函数的全局最优解是可以达到的。

    Harnessing the power of human-annotated data through Supervised Fine-Tuning (SFT) is pivotal for advancing Large Language Models (LLMs). In this paper, we delve into the prospect of growing a strong LLM out of a weak one without the need for acquiring additional human-annotated data. We propose a new fine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a supervised fine-tuned model. At the heart of SPIN lies a self-play mechanism, where the LLM refines its capability by playing against instances of itself. More specifically, the LLM generates its own training data from its previous iterations, refining its policy by discerning these self-generated responses from those obtained from human-annotated data. Our method progressively elevates the LLM from a nascent model to a formidable one, unlocking the full potential of human-annotated demonstration data for SFT. Theoretically, we prove that the global optimum to the training objective function of our method is achiev
    
[^2]: TREC iKAT 2023: 交互式知识辅助任务概述

    TREC iKAT 2023: The Interactive Knowledge Assistance Track Overview. (arXiv:2401.01330v1 [cs.IR])

    [http://arxiv.org/abs/2401.01330](http://arxiv.org/abs/2401.01330)

    TREC iKAT 2023是一个交互式的知识辅助任务，旨在开发适应用户交互和上下文的会话搜索代理。该任务还强调决策搜索任务，用户通过筛选数据和信息来进行决策和执行动作。

    

    会话式信息查询是一个关键的研究领域，之前的工作也有很大的贡献。TREC交互式知识辅助任务（iKAT）建立在TREC会话辅助任务（CAsT）的基础上。然而，iKAT着重于创建和研究可以根据用户之前的交互和当前情境自适应响应的会话搜索代理。挑战在于使会话搜索代理能够将个性化的上下文信息融入到相应中，以高效地引导用户获取相关信息。iKAT还着重于决策搜索任务，即用户通过数据和信息筛选来衡量各种选择，以达到结论或执行动作。这些任务在日常信息搜索决策中普遍存在，无论是旅游、健康还是购物等，通常涉及一组高级信息操作符，其中查询或问题可能会

    Conversational Information Seeking stands as a pivotal research area with significant contributions from previous works. The TREC Interactive Knowledge Assistance Track (iKAT) builds on the foundational work of the TREC Conversational Assistance Track (CAsT). However, iKAT distinctively emphasizes the creation and research of conversational search agents that adapt responses based on user's prior interactions and present context. The challenge lies in enabling Conversational Search Agents (CSA) to incorporate this personalized context to efficiency and effectively guide users through the relevant information to them. iKAT also emphasizes decisional search tasks, where users sift through data and information to weigh up options in order to reach a conclusion or perform an action. These tasks, prevalent in everyday information-seeking decisions -- be it related to travel, health, or shopping -- often revolve around a subset of high-level information operators where queries or questions a
    
[^3]: 一种用于联合实体和关系抽取的自回归文本到图框架

    An Autoregressive Text-to-Graph Framework for Joint Entity and Relation Extraction. (arXiv:2401.01326v1 [cs.CL])

    [http://arxiv.org/abs/2401.01326](http://arxiv.org/abs/2401.01326)

    这篇论文提出了一种新颖的方法，通过将联合实体和关系抽取问题作为条件序列生成问题来解决。该方法使用了基于跨度的图生成方式，并通过指向机制将生成的输出与原始文本对齐。评估结果证明了该方法的有效性，并获得了竞争性的结果。

    

    本文提出了一种新颖的方法，将非结构化文本中的联合实体和关系抽取问题作为条件序列生成问题来解决。与传统的生成式信息抽取模型不同，我们的方法是基于跨度的，它生成一个线性化的图，其中节点表示文本跨度，边表示关系三元组。我们的方法采用了一个具有指向机制的转换器编码器-解码器架构，使用一个动态词汇表来表示跨度和关系类型。我们的模型能够通过跨度表示捕捉实体和关系的结构特征和边界，同时通过指向机制将生成的输出与原始文本进行对齐。在基准数据集上的评估验证了我们方法的有效性，展示了竞争性的结果。代码可在https://github.com/urchade/ATG找到。

    In this paper, we propose a novel method for joint entity and relation extraction from unstructured text by framing it as a conditional sequence generation problem. In contrast to conventional generative information extraction models that are left-to-right token-level generators, our approach is \textit{span-based}. It generates a linearized graph where nodes represent text spans and edges represent relation triplets. Our method employs a transformer encoder-decoder architecture with pointing mechanism on a dynamic vocabulary of spans and relation types. Our model can capture the structural characteristics and boundaries of entities and relations through span representations while simultaneously grounding the generated output in the original text thanks to the pointing mechanism. Evaluation on benchmark datasets validates the effectiveness of our approach, demonstrating competitive results. Code is available at https://github.com/urchade/ATG.
    
[^4]: 自扩展LLM:无需调整的LLM上下文窗口。

    LLM Maybe LongLM: Self-Extend LLM Context Window Without Tuning. (arXiv:2401.01325v1 [cs.CL])

    [http://arxiv.org/abs/2401.01325](http://arxiv.org/abs/2401.01325)

    本研究提出了一种名为Self-Extend的方法，通过自身扩展现有LLMs的上下文窗口，无需调整，充分利用LLMs处理长上下文的固有能力。

    

    本研究揭示了LLM在处理长上下文时的固有能力，而无需进行精调。在训练过程中，训练序列的有限长度可能限制了大型语言模型（LLMs）在推理过程中对长输入序列的应用。在本研究中，我们认为现有的LLMs本身具有处理长上下文的固有能力。基于这一观点，我们建议通过自身扩展LLMs的上下文窗口，以充分利用其固有能力。我们提出了Self-Extend方法来激发LLMs的长上下文处理潜力。基本思想是构建双层注意信息：群组级和邻居级。这两个级别通过原始模型的自注意力计算，这意味着所提方法不需要任何训练。只需修改四行代码，所提方法就可以轻松扩展现有LLMs的上下文窗口，而无需进行任何精调。我们进行了全面的实验证明，结果表明所提方法可以+摘要减掉文章最后一句話

    This work elicits LLMs' inherent ability to handle long contexts without fine-tuning. The limited length of the training sequence during training may limit the application of Large Language Models (LLMs) on long input sequences for inference. In this work, we argue that existing LLMs themselves have inherent capabilities for handling long contexts. Based on this argument, we suggest extending LLMs' context window by themselves to fully utilize the inherent ability.We propose Self-Extend to stimulate LLMs' long context handling potential. The basic idea is to construct bi-level attention information: the group level and the neighbor level. The two levels are computed by the original model's self-attention, which means the proposed does not require any training. With only four lines of code modification, the proposed method can effortlessly extend existing LLMs' context window without any fine-tuning. We conduct comprehensive experiments and the results show that the proposed method can 
    
[^5]: 自动驾驶车辆的基于传感器融合的GNSS欺骗攻击检测框架的实验验证

    Experimental Validation of Sensor Fusion-based GNSS Spoofing Attack Detection Framework for Autonomous Vehicles. (arXiv:2401.01304v1 [cs.CR])

    [http://arxiv.org/abs/2401.01304](http://arxiv.org/abs/2401.01304)

    本研究验证了一种基于传感器融合的GNSS欺骗攻击检测框架在自动驾驶车辆中的性能。该框架采用两种策略，分别是比较预测位置偏移和惯性传感器位置偏移以及利用转向角传感器来检测和分类转弯。实验结果证明了该框架的有效性。

    

    本文验证了一种基于传感器融合的全球导航卫星系统（GNSS）欺骗攻击检测框架在自动驾驶车辆中的性能。通过配备GNSS接收器和惯性测量单元（IMU）的车辆收集数据。该检测框架采用两种策略：第一种策略通过比较预测的位置偏移（即两个连续时间戳之间的行驶距离）与惯性传感器的位置偏移来进行。为此，将来自低成本车辆内的加速度计和陀螺仪传感器的数据融合并输入到长短期记忆（LSTM）神经网络中。第二种策略采用随机森林监督机器学习模型，利用转向角传感器的输出来检测和分类转弯，并区分左转和右转。在实验中还模拟了两种类型的欺骗攻击模型：一步步转弯和错误转弯。

    In this paper, we validate the performance of the a sensor fusion-based Global Navigation Satellite System (GNSS) spoofing attack detection framework for Autonomous Vehicles (AVs). To collect data, a vehicle equipped with a GNSS receiver, along with Inertial Measurement Unit (IMU) is used. The detection framework incorporates two strategies: The first strategy involves comparing the predicted location shift, which is the distance traveled between two consecutive timestamps, with the inertial sensor-based location shift. For this purpose, data from low-cost in-vehicle inertial sensors such as the accelerometer and gyroscope sensor are fused and fed into a long short-term memory (LSTM) neural network. The second strategy employs a Random-Forest supervised machine learning model to detect and classify turns, distinguishing between left and right turns using the output from the steering angle sensor. In experiments, two types of spoofing attack models: turn-by-turn and wrong turn are simul
    
[^6]: 大型法律虚构：揭示大型语言模型中的法律幻觉

    Large Legal Fictions: Profiling Legal Hallucinations in Large Language Models. (arXiv:2401.01301v1 [cs.CL])

    [http://arxiv.org/abs/2401.01301](http://arxiv.org/abs/2401.01301)

    大型语言模型存在法律幻觉，不一致法律事实，幻觉普遍存在高达69%至88%的情况，无法纠正用户错误法律假设。

    

    大型语言模型（LLMs）有可能改变法律实践，但其潜力受到法律幻觉的威胁，即这些模型产生与法律事实不一致的回答。我们使用一套原创的法律查询来调查这些幻觉的程度，将LLMs的回答与结构化的法律元数据进行对比，并检查其一致性。我们的工作有四个关键贡献：（1）我们建立了法律幻觉的分类体系，为今后在这一领域进行的研究提供了概念框架。（2）我们发现，法律幻觉的普遍性令人担忧，在对随机联邦法院案例进行具体、可验证的问题时，ChatGPT 3.5产生的幻觉发生率为69％，而Llama 2为88％。（3）我们展示了LLMs在逆向问题设置中往往无法纠正用户的错误法律假设。（4）我们提供了证据表明LLMs并不总能预测或并不总知道...

    Large language models (LLMs) have the potential to transform the practice of law, but this potential is threatened by the presence of legal hallucinations -- responses from these models that are not consistent with legal facts. We investigate the extent of these hallucinations using an original suite of legal queries, comparing LLMs' responses to structured legal metadata and examining their consistency. Our work makes four key contributions: (1) We develop a typology of legal hallucinations, providing a conceptual framework for future research in this area. (2) We find that legal hallucinations are alarmingly prevalent, occurring between 69% of the time with ChatGPT 3.5 and 88% with Llama 2, when these models are asked specific, verifiable questions about random federal court cases. (3) We illustrate that LLMs often fail to correct a user's incorrect legal assumptions in a contra-factual question setup. (4) We provide evidence that LLMs cannot always predict, or do not always know, wh
    
[^7]: 采用分割和深度学习的物理信息通用化无线信道建模：基础、方法和挑战

    Physics-informed Generalizable Wireless Channel Modeling with Segmentation and Deep Learning: Fundamentals, Methodologies, and Challenges. (arXiv:2401.01288v1 [cs.IT])

    [http://arxiv.org/abs/2401.01288](http://arxiv.org/abs/2401.01288)

    本论文介绍了基于物理信息神经网络（PINN）的无线信道建模方法，总结了其具有通用性、可解释性和鲁棒性等优点，并提出了一个综合的PINN方法体系结构，为未来模型发展提供指导与启示。另外，还针对室内信道预测提出了精确和深度学习的案例研究，同时探讨了相关挑战。

    

    信道建模是推动无线系统发展的基础，并吸引了相当多的研究关注。最近的趋势是越来越依赖数据驱动技术来促进建模过程，并产生准确的信道预测。本文首先对数据驱动的信道建模方法进行简要概述，并强调其局限性。随后，我们介绍了物理信息神经网络（PINN）建模的概念和优势，并总结了这一领域的最新贡献。我们的研究结果表明，基于PINN的信道建模方法具有很好的通用性、可解释性和鲁棒性。我们提供了一个综合的PINN方法体系结构，旨在为未来模型发展提供指导与启示。本文还介绍了我们最近的关于精确的室内信道预测与语义分割和深度学习的案例研究。最后，我们讨论了面临的挑战。

    Channel modeling is fundamental in advancing wireless systems and has thus attracted considerable research focus. Recent trends have seen a growing reliance on data-driven techniques to facilitate the modeling process and yield accurate channel predictions. In this work, we first provide a concise overview of data-driven channel modeling methods, highlighting their limitations. Subsequently, we introduce the concept and advantages of physics-informed neural network (PINN)-based modeling and a summary of recent contributions in this area. Our findings demonstrate that PINN-based approaches in channel modeling exhibit promising attributes such as generalizability, interpretability, and robustness. We offer a comprehensive architecture for PINN methodology, designed to inform and inspire future model development. A case-study of our recent work on precise indoor channel prediction with semantic segmentation and deep learning is presented. The study concludes by addressing the challenges f
    
[^8]: 大型语言模型的知识编辑全面研究

    A Comprehensive Study of Knowledge Editing for Large Language Models. (arXiv:2401.01286v1 [cs.CL])

    [http://arxiv.org/abs/2401.01286](http://arxiv.org/abs/2401.01286)

    本研究全面研究了大型语言模型的知识编辑，旨在有效修改模型的行为，同时保持整体性能。

    

    大型语言模型(LLM)在理解和生成与人类交流紧密相似的文本方面展现出了非凡的能力。然而，其主要限制在于训练过程中的显著计算需求，这是由于其广泛的参数化造成的。这一挑战在于世界的动态性，需要频繁更新LLM以修正过时的信息或集成新知识，从而确保其持续的相关性。许多应用需要在训练后进行持续的模型调整，以解决缺陷或不良行为。近年来，对于LLM的知识编辑技术的兴趣越来越高，在特定领域内有效地修改LLM的行为，同时保持整体性能在各种输入中的表现。本文首先定义了知识编辑的目标和挑战，然后综述了现有的知识编辑方法和技术，并讨论了其应用和未来发展的方向。

    Large Language Models (LLMs) have shown extraordinary capabilities in understanding and generating text that closely mirrors human communication. However, a primary limitation lies in the significant computational demands during training, arising from their extensive parameterization. This challenge is further intensified by the dynamic nature of the world, necessitating frequent updates to LLMs to correct outdated information or integrate new knowledge, thereby ensuring their continued relevance. Note that many applications demand continual model adjustments post-training to address deficiencies or undesirable behaviors. There is an increasing interest in efficient, lightweight methods for on-the-fly model modifications. To this end, recent years have seen a burgeoning in the techniques of knowledge editing for LLMs, which aim to efficiently modify LLMs' behaviors within specific domains while preserving overall performance across various inputs. In this paper, we first define the kno
    
[^9]: LLbezpeky: 利用大型语言模型进行漏洞检测

    LLbezpeky: Leveraging Large Language Models for Vulnerability Detection. (arXiv:2401.01269v1 [cs.CR])

    [http://arxiv.org/abs/2401.01269](http://arxiv.org/abs/2401.01269)

    LLbezpeky是一项利用大型语言模型进行漏洞检测的研究，研究发现LLMs在理解人类和编程语言中的语义方面展现出巨大潜力，并通过构建一个AI驱动的工作流程来帮助开发人员识别和修复漏洞。

    

    尽管在构建安全系统方面进行了持续的研究和进展，但安卓应用程序仍然存在漏洞，需要有效的检测方法。目前的静态和动态分析工具策略存在一些限制，如大量的误报和有限的分析范围，使得难以采用。在过去的几年中，基于机器学习的方法在漏洞检测方面得到了广泛探索，但其在实际应用中受到数据需求和特征工程挑战的限制。大型语言模型（LLMs）凭借其庞大的参数，在理解人类和编程语言中的语义方面展现出巨大潜力。我们深入研究了在安卓安全的背景下，LLMs用于检测漏洞的效果。我们的重点是构建一个基于人工智能的工作流程，帮助开发人员识别和修复漏洞。我们的实验结果表明，LLMs能够有效检测出漏洞。

    Despite the continued research and progress in building secure systems, Android applications continue to be ridden with vulnerabilities, necessitating effective detection methods. Current strategies involving static and dynamic analysis tools come with limitations like overwhelming number of false positives and limited scope of analysis which make either difficult to adopt. Over the past years, machine learning based approaches have been extensively explored for vulnerability detection, but its real-world applicability is constrained by data requirements and feature engineering challenges. Large Language Models (LLMs), with their vast parameters, have shown tremendous potential in understanding semnatics in human as well as programming languages. We dive into the efficacy of LLMs for detecting vulnerabilities in the context of Android security. We focus on building an AI-driven workflow to assist developers in identifying and rectifying vulnerabilities. Our experiments show that LLMs o
    
[^10]: 使用进化算法综合具有通用门的有限状态机的最优化方法

    Optimal Synthesis of Finite State Machines with Universal Gates using Evolutionary Algorithm. (arXiv:2401.01265v1 [cs.NE])

    [http://arxiv.org/abs/2401.01265](http://arxiv.org/abs/2401.01265)

    本文提出了一种使用进化算法综合有限状态机的最优化方法，通过减少门数来降低芯片面积和电路成本，实验结果显示平均减少了近30％的门数。

    

    该文提出了一种用于综合有限状态机的优化方法，重点是减少芯片面积和电路成本。利用笛卡尔遗传编程演化了MCNC91基准电路中的一系列有限状态机。平均而言，总计减少了近30％的门数。此外，还讨论了一些参数对进化过程的影响。

    This work presents an optimization method for the synthesis of finite state machines. The focus is on the reduction in the on-chip area and the cost of the circuit. A list of finite state machines from MCNC91 benchmark circuits have been evolved using Cartesian Genetic Programming. On the average, almost 30% of reduction in the total number of gates has been achieved. The effects of some parameters on the evolutionary process have also been discussed in the paper.
    
[^11]: 自然语言处理和大型语言模型公平性认证

    Fairness Certification for Natural Language Processing and Large Language Models. (arXiv:2401.01262v1 [cs.CL])

    [http://arxiv.org/abs/2401.01262](http://arxiv.org/abs/2401.01262)

    这项研究旨在为自然语言处理领域开发公平性认证方法。通过综述大量文献和专家访谈，我们提出了六个公平性标准，为操作化和测试过程提供了基础。

    

    自然语言处理（NLP）在我们的日常生活中扮演着重要角色，特别是由于大型语言模型（LLM）的巨大进展。然而，NLP在招聘等公平关键应用场景中存在许多问题，例如作为专家系统或基于LLM的教育导师。由于NLP基于人类语言，可能会导致潜在的有害偏见渗入NLP系统，产生不公平的结果，歧视少数群体或引发法律问题。因此，开展NLP方法的公平性认证非常重要。我们采用定性研究方法，对算法公平性的大量文献进行了综述，并与该领域的多位专家进行了半结构化的专家访谈。我们系统地提出了NLP的六个公平性标准，并进一步细化为18个子类别。我们的标准为实施和测试过程提供了基础。

    Natural Language Processing (NLP) plays an important role in our daily lives, particularly due to the enormous progress of Large Language Models (LLM). However, NLP has many fairness-critical use cases, e.g., as an expert system in recruitment or as an LLM-based tutor in education. Since NLP is based on human language, potentially harmful biases can diffuse into NLP systems and produce unfair results, discriminate against minorities or generate legal issues. Hence, it is important to develop a fairness certification for NLP approaches. We follow a qualitative research approach towards a fairness certification for NLP. In particular, we have reviewed a large body of literature on algorithmic fairness, and we have conducted semi-structured expert interviews with a wide range of experts from that area. We have systematically devised six fairness criteria for NLP, which can be further refined into 18 sub-categories. Our criteria offer a foundation for operationalizing and testing processes
    
[^12]: 概念瓶颈模型是否遵循局部性？

    Do Concept Bottleneck Models Obey Locality?. (arXiv:2401.01259v1 [cs.LG])

    [http://arxiv.org/abs/2401.01259](http://arxiv.org/abs/2401.01259)

    本文研究了概念瓶颈模型（CBMs）是否能够正确捕捉到概念之间的条件独立程度，通过分析对于概念局部性之外特征的变化如何影响概念的预测。

    

    概念基础学习通过解释其预测结果使用人可理解的概念，改善了深度学习模型的可解释性。在这种范式下训练的深度学习模型严重依赖于神经网络能够学习独立于其他概念的给定概念的存在或不存在。然而，最近的研究强烈暗示这种假设可能在概念瓶颈模型（CBMs）这一典型的基于概念的可解释架构中不能成立。本文中，我们研究了当这些概念既在空间上（通过它们的值完全由固定子集的特征定义）又在语义上（通过它们的值仅与预定义的固定子集的概念相关联）定位时，CBMs是否正确捕捉到概念之间的条件独立程度。为了理解局部性，我们分析了概念之外的特征变化对概念预测的影响。

    Concept-based learning improves a deep learning model's interpretability by explaining its predictions via human-understandable concepts. Deep learning models trained under this paradigm heavily rely on the assumption that neural networks can learn to predict the presence or absence of a given concept independently of other concepts. Recent work, however, strongly suggests that this assumption may fail to hold in Concept Bottleneck Models (CBMs), a quintessential family of concept-based interpretable architectures. In this paper, we investigate whether CBMs correctly capture the degree of conditional independence across concepts when such concepts are localised both spatially, by having their values entirely defined by a fixed subset of features, and semantically, by having their values correlated with only a fixed subset of predefined concepts. To understand locality, we analyse how changes to features outside of a concept's spatial or semantic locality impact concept predictions. Our
    
[^13]: 使用对比学习在根树中对连续时间序列的二进制事件进行编码

    Encoding Binary Events from Continuous Time Series in Rooted Trees using Contrastive Learning. (arXiv:2401.01242v1 [cs.LG])

    [http://arxiv.org/abs/2401.01242](http://arxiv.org/abs/2401.01242)

    本研究提出了一种对连续时间序列数据进行二进制事件编码的对比学习方法，具有推断本地网络拓扑结构的潜力。

    

    广域基础设施所有者通常不知道他们的客户在本地网络中是如何连接的，这些网络以根树结构组织。最近的一项研究使用来自树叶（客户）的离散时间序列数据推断本地网络的拓扑结构。在本研究中，我们提出了一种对连续时间序列数据进行二进制事件编码的对比学习方法。作为初步结果，我们展示了我们的方法在学习有价值的编码器方面具有一定潜力。

    Broadband infrastructure owners do not always know how their customers are connected in the local networks, which are structured as rooted trees. A recent study is able to infer the topology of a local network using discrete time series data from the leaves of the tree (customers). In this study we propose a contrastive approach for learning a binary event encoder from continuous time series data. As a preliminary result, we show that our approach has some potential in learning a valuable encoder.
    
[^14]: IdentiFace：基于VGG的多模态人脸生物特征系统

    IdentiFace : A VGG Based Multimodal Facial Biometric System. (arXiv:2401.01227v1 [cs.CV])

    [http://arxiv.org/abs/2401.01227](http://arxiv.org/abs/2401.01227)

    本文介绍了一种基于VGG的多模态人脸生物特征系统"IdentiFace"，通过将人脸识别与性别、脸型和情感等软生物特征相结合，实现了高效、有意义的结合。通过使用统一的架构和对学到的特征进行解释，该系统在高内类别变异下取得了99.2%的测试精确度。

    

    人脸生物特征系统的发展为计算机视觉领域的发展做出了巨大贡献。现今，需要开发一种多模态系统，以高效、有意义的方式结合多种生物特征。本文介绍了“IdentiFace”，这是一种多模态人脸生物特征系统，将人脸识别的核心与性别、脸型和情感等一些重要的软生物特征相结合。我们还着重使用只有VGG-16受到启发的架构，在不同子系统中进行了一些细微的更改。这种统一性使得跨模态的集成更加简单。它更容易解释不同任务之间学到的特征，从而对于决策过程和人脸模态之间的潜在关系给出了很好的指示。对于识别问题，我们使用收集的数据，在五个类别的高内类别变异下获得了99.2%的测试精确度。

    The development of facial biometric systems has contributed greatly to the development of the computer vision field. Nowadays, there's always a need to develop a multimodal system that combines multiple biometric traits in an efficient, meaningful way. In this paper, we introduce "IdentiFace" which is a multimodal facial biometric system that combines the core of facial recognition with some of the most important soft biometric traits such as gender, face shape, and emotion. We also focused on developing the system using only VGG-16 inspired architecture with minor changes across different subsystems. This unification allows for simpler integration across modalities. It makes it easier to interpret the learned features between the tasks which gives a good indication about the decision-making process across the facial modalities and potential connection. For the recognition problem, we acquired a 99.2% test accuracy for five classes with high intra-class variations using data collected 
    
[^15]: 大语言模型的零样本位置去偏方法

    Zero-Shot Position Debiasing for Large Language Models. (arXiv:2401.01218v1 [cs.CL])

    [http://arxiv.org/abs/2401.01218](http://arxiv.org/abs/2401.01218)

    本文提出了一种零样本位置去偏方法（ZOE）来降低大语言模型（LLMs）的位置偏差问题，该方法利用预训练的LLMs的无监督响应进行去偏。实验证实ZOE在多个数据集和任务中均表现出优异的性能。

    

    微调已被证明是改善大语言模型（LLMs）领域性能的有效方法。然而，LLMs可能适应数据集偏见和预测的捷径，导致生成性能差。实验结果显示，LLMs容易表现出位置偏差，即利用位于开头或末尾或输入中特定位置线索的信息。现有的减轻位置偏差的工作需要外部偏差知识或带注释的非偏倚样本，在实际中不太实用。在这项工作中，我们提出了一种零样本位置去偏（ZOE）框架对LLMs进行位置去偏。ZOE利用预训练的LLMs的无监督响应进行去偏，因此不需要任何外部知识或数据集。为了提高无监督响应的质量，我们提出了一种主从对齐（MSA）模块来修剪这些响应。对八个数据集和五个任务的实验表明，ZOE始终优于其他方法。

    Fine-tuning has been demonstrated to be an effective method to improve the domain performance of large language models (LLMs). However, LLMs might fit the dataset bias and shortcuts for prediction, leading to poor generation performance. Experimental result shows that LLMs are prone to exhibit position bias, i.e., leveraging information positioned at the beginning or end, or specific positional cues within the input. Existing works on mitigating position bias require external bias knowledge or annotated non-biased samples, which is unpractical in reality. In this work, we propose a zero-shot position debiasing (ZOE) framework to mitigate position bias for LLMs. ZOE leverages unsupervised responses from pre-trained LLMs for debiasing, thus without any external knowledge or datasets. To improve the quality of unsupervised responses, we propose a master-slave alignment (MSA) module to prune these responses. Experiments on eight datasets and five tasks show that ZOE consistently outperform
    
[^16]: PPBFL: 一种隐私保护的基于区块链的联邦学习模型

    PPBFL: A Privacy Protected Blockchain-based Federated Learning Model. (arXiv:2401.01204v1 [cs.CR])

    [http://arxiv.org/abs/2401.01204](http://arxiv.org/abs/2401.01204)

    PPBFL是一种隐私保护的基于区块链的联邦学习模型，通过应用区块链和自适应差分隐私添加算法，增强了联邦学习的安全性和节点的积极参与。同时引入了交易混合机制，更好地保护本地训练的身份隐私。

    

    随着机器学习的快速发展和对数据隐私的日益关注，联邦学习成为一个越来越突出的焦点。然而，模型参数攻击和缺乏激励机制等挑战阻碍了联邦学习的有效性。因此，我们提出了一种隐私保护的基于区块链的联邦学习模型（PPBFL），以增强联邦学习的安全性并促进节点在模型训练中的积极参与。区块链确保了存储在星际文件系统（IPFS）中的模型参数不被篡改。同时，我们采用了一种新颖的自适应差分隐私添加算法，同时应用于本地模型和全局模型，保护本地模型的隐私同时防止因联邦学习中存在大量本地模型而降低全局模型的安全性。此外，我们引入了一个新的交易混合机制，以更好地保护本地训练的身份隐私。

    With the rapid development of machine learning and growing concerns about data privacy, federated learning has become an increasingly prominent focus. However, challenges such as attacks on model parameters and the lack of incentive mechanisms hinder the effectiveness of federated learning. Therefore, we propose a Privacy Protected Blockchain-based Federated Learning Model (PPBFL) to enhance the security of federated learning and promote the active participation of nodes in model training. Blockchain ensures that model parameters stored in the InterPlanetary File System (IPFS) remain unaltered. A novel adaptive differential privacy addition algorithm is simultaneously applied to local and global models, preserving the privacy of local models and preventing a decrease in the security of the global model due to the presence of numerous local models in federated learning. Additionally, we introduce a new mix transactions mechanism to better protect the identity privacy of local training c
    
[^17]: 使用机器学习算法的皮肤病变诊断的活体近红外光谱数据。 (arXiv:2401.01200v1 [cs.CV])

    Skin cancer diagnosis using NIR spectroscopy data of skin lesions in vivo using machine learning algorithms. (arXiv:2401.01200v1 [cs.CV])

    [http://arxiv.org/abs/2401.01200](http://arxiv.org/abs/2401.01200)

    这项研究讨论了使用近红外光谱数据进行皮肤病变诊断的机器学习算法。近红外光谱可以提供病变分子结构的信息，为自动计算机辅助诊断提供了替代信息来源。现代机器学习和深度学习技术对光谱学的应用也引起了越来越多的关注。

    

    皮肤病变可以分为良性和恶性。在恶性病变中，黑色素瘤是一种非常侵袭性的癌症，也是导致死亡的主要原因。因此，早期诊断皮肤癌非常重要。近年来，人们对使用图像和临床数据在计算机辅助诊断（CAD）中的兴趣越来越大。然而，这些信息来源存在限制，因为它们不能提供病变分子结构的信息。近红外光谱可以为皮肤病变的自动CAD提供替代信息来源。光谱学中最常用的技术和分类算法是主成分分析（PCA）、偏最小二乘-判别分析（PLS-DA）和支持向量机（SVM）。然而，人们对将现代机器学习和深度学习（MDL）应用于光谱学的兴趣日益增长。而将MDL应用于光谱学的主要限制之一是缺乏公共数据集。

    Skin lesions are classified in benign or malignant. Among the malignant, melanoma is a very aggressive cancer and the major cause of deaths. So, early diagnosis of skin cancer is very desired. In the last few years, there is a growing interest in computer aided diagnostic (CAD) using most image and clinical data of the lesion. These sources of information present limitations due to their inability to provide information of the molecular structure of the lesion. NIR spectroscopy may provide an alternative source of information to automated CAD of skin lesions. The most commonly used techniques and classification algorithms used in spectroscopy are Principal Component Analysis (PCA), Partial Least Squares - Discriminant Analysis (PLS-DA), and Support Vector Machines (SVM). Nonetheless, there is a growing interest in applying the modern techniques of machine and deep learning (MDL) to spectroscopy. One of the main limitations to apply MDL to spectroscopy is the lack of public datasets. Si
    
[^18]: JMA:一种快速生成几乎最优定向对抗样本的通用算法

    JMA: a General Algorithm to Craft Nearly Optimal Targeted Adversarial Example. (arXiv:2401.01199v1 [cs.LG])

    [http://arxiv.org/abs/2401.01199](http://arxiv.org/abs/2401.01199)

    JMA是一种通用算法，用于生成几乎最优的定向对抗样本。该算法通过最小化Jacobian引起的马氏距离，考虑了将输入样本的潜在空间表示在给定方向上移动所需的投入。该算法在解决对抗样本问题方面提供了最优解。

    

    目前为止，大多数用于生成针对深度学习分类器的定向对抗样本的方法都是高度次优的，通常依赖于增加目标类别的可能性，因此隐含地专注于一热编码设置。在本文中，我们提出了一种更加通用的、理论上可靠的定向攻击方法，该方法利用最小化雅可比引起的马氏距离（JMA）项，考虑将输入样本的潜在空间表示在给定方向上移动所需的投入（在输入空间中）。通过利用沃尔夫二重性定理求解最小化问题，将问题简化为解非负最小二乘（NNLS）问题。所提出的算法为Szegedy等人最初引入的对抗样本问题的线性化版本提供了最优解。我们进行的实验证实了所提出的攻击的广泛性。

    Most of the approaches proposed so far to craft targeted adversarial examples against Deep Learning classifiers are highly suboptimal and typically rely on increasing the likelihood of the target class, thus implicitly focusing on one-hot encoding settings. In this paper, we propose a more general, theoretically sound, targeted attack that resorts to the minimization of a Jacobian-induced MAhalanobis distance (JMA) term, taking into account the effort (in the input space) required to move the latent space representation of the input sample in a given direction. The minimization is solved by exploiting the Wolfe duality theorem, reducing the problem to the solution of a Non-Negative Least Square (NNLS) problem. The proposed algorithm provides an optimal solution to a linearized version of the adversarial example problem originally introduced by Szegedy et al. \cite{szegedy2013intriguing}. The experiments we carried out confirm the generality of the proposed attack which is proven to be 
    
[^19]: 误解信息检测中的不确定性解决方法

    Uncertainty Resolution in Misinformation Detection. (arXiv:2401.01197v1 [cs.CL])

    [http://arxiv.org/abs/2401.01197](http://arxiv.org/abs/2401.01197)

    该研究介绍了一种解决误解信息中不确定性的新方法，通过提出一个分类框架和生成有效的用户查询来解决缺失上下文的问题，提高了误解信息检测的性能。

    

    误解信息存在各种风险，如破坏公众信任和扭曲事实言论。大型语言模型（LLMs）如GPT-4已被证明在减轻误解信息方面很有效，特别是在处理提供足够上下文的陈述时。然而，它们很难准确评估模糊或缺乏上下文的陈述。本文介绍了一种解决此类陈述中不确定性的新方法。我们提出了一个框架来对缺失信息进行分类，并为LIAR-New数据集提供类别标签，该数据集适用于具有缺失信息的跨域内容。然后，我们利用这个框架来生成缺失上下文的有效用户查询。与基线相比，我们的方法提高了用户可回答问题的比例38个百分点，并且分类性能提高了超过10个百分点的宏F1。因此，这种方法可能为未来的误解信息缓解提供有价值的组成部分。

    Misinformation poses a variety of risks, such as undermining public trust and distorting factual discourse. Large Language Models (LLMs) like GPT-4 have been shown effective in mitigating misinformation, particularly in handling statements where enough context is provided. However, they struggle to assess ambiguous or context-deficient statements accurately. This work introduces a new method to resolve uncertainty in such statements. We propose a framework to categorize missing information and publish category labels for the LIAR-New dataset, which is adaptable to cross-domain content with missing information. We then leverage this framework to generate effective user queries for missing context. Compared to baselines, our method improves the rate at which generated questions are answerable by the user by 38 percentage points and classification performance by over 10 percentage points macro F1. Thus, this approach may provide a valuable component for future misinformation mitigation pi
    
[^20]: NID-SLAM: 基于神经隐式表示的动态环境RGB-D SLAM

    NID-SLAM: Neural Implicit Representation-based RGB-D SLAM in dynamic environments. (arXiv:2401.01189v1 [cs.RO])

    [http://arxiv.org/abs/2401.01189](http://arxiv.org/abs/2401.01189)

    NID-SLAM是一种基于神经隐式表示的RGB-D SLAM算法，它通过提升语义掩膜中的不准确区域和引入关键帧选择策略，显著改善了在动态环境下的性能，提高了跟踪精度和建图质量。

    

    神经隐式表示已被用于增强视觉SLAM算法，特别是提供高保真密集地图方面。现有的方法在静态场景下运作良好，但在移动物体造成的干扰下困难重重。在本文中，我们提出了NID-SLAM，在动态环境中显著改善了神经SLAM的性能。我们提出了一种新的方法，以增强语义掩膜中的不准确区域，特别是边缘区域。利用深度图像中的几何信息，这种方法能够精确地去除动态物体，从而降低相机漂移的概率。此外，我们引入了一种适用于动态场景的关键帧选择策略，增强了相机跟踪对大尺度物体的鲁棒性，并提高了建图的效率。在公开可用的RGB-D数据集上的实验证明，我们的方法在跟踪精度和建图质量上优于竞争性的神经SLAM方法。

    Neural implicit representations have been explored to enhance visual SLAM algorithms, especially in providing high-fidelity dense map. Existing methods operate robustly in static scenes but struggle with the disruption caused by moving objects. In this paper we present NID-SLAM, which significantly improves the performance of neural SLAM in dynamic environments. We propose a new approach to enhance inaccurate regions in semantic masks, particularly in marginal areas. Utilizing the geometric information present in depth images, this method enables accurate removal of dynamic objects, thereby reducing the probability of camera drift. Additionally, we introduce a keyframe selection strategy for dynamic scenes, which enhances camera tracking robustness against large-scale objects and improves the efficiency of mapping. Experiments on publicly available RGB-D datasets demonstrate that our method outperforms competitive neural SLAM approaches in tracking accuracy and mapping quality in dynam
    
[^21]: 用深度学习在移动手机图像上进行精确高效的城市街道树木清查

    Accurate and Efficient Urban Street Tree Inventory with Deep Learning on Mobile Phone Imagery. (arXiv:2401.01180v1 [cs.CV])

    [http://arxiv.org/abs/2401.01180](http://arxiv.org/abs/2401.01180)

    本论文提出了一种利用深度学习技术和手机影像进行城市街道树木清查的创新方法，可以精确地分割树干并计算胸径，相比传统方法具有更高准确性、更少对专业设备的依赖，并适用于难以接触的地区。在实验证明，该方法在胸径估算上的准确率误差率小于2.5%，有望在城市街道树木清查方面产生显著的改进效果。

    

    森林砍伐是气候变化的主要原因之一，会导致农业部门的中断、全球变暖、山洪暴发和滑坡等不利后果。传统的城市街道树木清查方法存在精度不准确和对专业设备的依赖的问题。为了克服这些挑战，本论文提出了一种创新的方法，利用深度学习技术和手机影像进行城市街道树木清查。我们的方法利用智能手机摄像头拍摄的一对图像来精确地分割树干并计算胸径。与传统方法相比，我们的方法具有以下几个优点，包括更高的准确性、对专业设备的依赖较低和适用于难以接触的地区。我们在一个包含400颗树的综合数据集上评估了我们的方法，并且在胸径估算准确率方面达到了小于2.5%的误差率。我们的方法具有显著的潜力可以大幅度改善城市街道树木清查。

    Deforestation, a major contributor to climate change, poses detrimental consequences such as agricultural sector disruption, global warming, flash floods, and landslides. Conventional approaches to urban street tree inventory suffer from inaccuracies and necessitate specialised equipment. To overcome these challenges, this paper proposes an innovative method that leverages deep learning techniques and mobile phone imaging for urban street tree inventory. Our approach utilises a pair of images captured by smartphone cameras to accurately segment tree trunks and compute the diameter at breast height (DBH). Compared to traditional methods, our approach exhibits several advantages, including superior accuracy, reduced dependency on specialised equipment, and applicability in hard-to-reach areas. We evaluated our method on a comprehensive dataset of 400 trees and achieved a DBH estimation accuracy with an error rate of less than 2.5%. Our method holds significant potential for substantially
    
[^22]: 冻结主干：一种参数高效的抗干扰医学视觉语言预训练对比方法

    Freeze the backbones: A Parameter-Efficient Contrastive Approach to Robust Medical Vision-Language Pre-training. (arXiv:2401.01179v1 [cs.CV])

    [http://arxiv.org/abs/2401.01179](http://arxiv.org/abs/2401.01179)

    这项研究提出了一种冻结主干的适配器框架，可以实现参数高效的抗干扰医学视觉语言预训练。实验证明，该框架在保留信息的同时大大减少了可训练参数，并在医学图像分类和分割任务上取得了竞争性的性能。

    

    现代医疗常常在诊断中同时使用放射图像和文字报告，鼓励使用大型预训练模型进行视觉-语言自监督学习(VL-SSL)以学习多功能的医学视觉表征。然而，现有的大多数VL-SSL框架是端到端训练的，这是计算密集型的，并且可能丢失嵌入在预训练编码器中的重要先验信息。为了解决这两个问题，我们引入了无主干适配器框架，通过保持预训练图像和文本编码器的冻结状态，保留医学知识，并使用轻量级适配器模块进行跨模态学习。在三个数据集上进行的医学图像分类和分割任务的实验证明，与当前的预训练方法相比，我们的框架在保留信息的同时，可将可训练参数减少超过90%。值得注意的是，当只使用1%的数据进行微调时，适配器的性能优于几种基于Transformer的方法。

    Modern healthcare often utilises radiographic images alongside textual reports for diagnostics, encouraging the use of Vision-Language Self-Supervised Learning (VL-SSL) with large pre-trained models to learn versatile medical vision representations. However, most existing VL-SSL frameworks are trained end-to-end, which is computation-heavy and can lose vital prior information embedded in pre-trained encoders. To address both issues, we introduce the backbone-agnostic Adaptor framework, which preserves medical knowledge in pre-trained image and text encoders by keeping them frozen, and employs a lightweight Adaptor module for cross-modal learning. Experiments on medical image classification and segmentation tasks across three datasets reveal that our framework delivers competitive performance while cutting trainable parameters by over 90% compared to current pre-training approaches. Notably, when fine-tuned with just 1% of data, Adaptor outperforms several Transformer-based methods trai
    
[^23]: 振动信号的二次时间频率分析用于诊断轴承故障

    Quadratic Time-Frequency Analysis of Vibration Signals for Diagnosing Bearing Faults. (arXiv:2401.01172v1 [cs.LG])

    [http://arxiv.org/abs/2401.01172](http://arxiv.org/abs/2401.01172)

    本文提出了一种融合时间频率分析和深度学习技术的方法，用于在实际条件下诊断带有时间变化速度和不同噪声水平的轴承故障。这种方法有效地解析与不同轴承故障相关的独特动态模式。

    

    轴承故障的诊断对于降低维修成本和设备停机至关重要。轴承故障是机器振动的主要原因，分析其信号形态可以揭示其健康状况。然而，现有的方法主要针对控制环境进行优化，忽略了实际条件下的时间变化的转速和振动的非平稳性。本文提出了一种时间频率分析和深度学习技术的融合方法，用于在时间变化速度和不同噪声水平下诊断轴承故障。首先，我们制定了轴承故障引起的振动，并讨论了它们的非平稳性与轴承固有和操作参数之间的联系。我们还阐述了二次时间频率分布，并验证了它们解析与不同轴承故障相关的独特动态模式的有效性。基于此，我们设计了一个时间频率卷积神经网络。

    Diagnosis of bearing faults is paramount to reducing maintenance costs and operational breakdowns. Bearing faults are primary contributors to machine vibrations, and analyzing their signal morphology offers insights into their health status. Unfortunately, existing approaches are optimized for controlled environments, neglecting realistic conditions such as time-varying rotational speeds and the vibration's non-stationary nature. This paper presents a fusion of time-frequency analysis and deep learning techniques to diagnose bearing faults under time-varying speeds and varying noise levels. First, we formulate the bearing fault-induced vibrations and discuss the link between their non-stationarity and the bearing's inherent and operational parameters. We also elucidate quadratic time-frequency distributions and validate their effectiveness in resolving distinctive dynamic patterns associated with different bearing faults. Based on this, we design a time-frequency convolutional neural n
    
[^24]: Spiker＋：一种用于在边缘进行推理的高效Spiking神经网络FPGA加速器生成框架

    Spiker+: a framework for the generation of efficient Spiking Neural Networks FPGA accelerators for inference at the edge. (arXiv:2401.01141v1 [cs.NE])

    [http://arxiv.org/abs/2401.01141](http://arxiv.org/abs/2401.01141)

    Spiker+是一个在边缘进行推理的高效Spiking神经网络FPGA加速器生成框架，具有低资源消耗和低功耗的特点。

    

    在边缘嵌入式系统中包含人工神经网络可以使应用程序在网络边缘设备中直接利用人工智能能力。本文介绍了Spiker＋，这是一个用于在边缘进行推理的高效、低功耗、低面积的定制Spiking神经网络（SNN）FPGA加速器的综合框架。Spiker＋提供了可配置的多层硬件SNN、高效的神经元架构库以及一个设计框架，使得可以用少量Python代码开发复杂的神经网络加速器。Spiker＋在两个基准数据集MNIST和Spiking Heidelberg Digits（SHD）上进行了测试。在MNIST上，它表现出与最先进的SNN加速器相媲美的性能。它在资源分配方面优于它们，需要7612个逻辑单元和18个Block RAM（BRAM），可以适应非常小的FPGA，并且功耗较低。

    Including Artificial Neural Networks in embedded systems at the edge allows applications to exploit Artificial Intelligence capabilities directly within devices operating at the network periphery. This paper introduces Spiker+, a comprehensive framework for generating efficient, low-power, and low-area customized Spiking Neural Networks (SNN) accelerators on FPGA for inference at the edge. Spiker+ presents a configurable multi-layer hardware SNN, a library of highly efficient neuron architectures, and a design framework, enabling the development of complex neural network accelerators with few lines of Python code. Spiker+ is tested on two benchmark datasets, the MNIST and the Spiking Heidelberg Digits (SHD). On the MNIST, it demonstrates competitive performance compared to state-of-the-art SNN accelerators. It outperforms them in terms of resource allocation, with a requirement of 7,612 logic cells and 18 Block RAMs (BRAMs), which makes it fit in very small FPGA, and power consumption,
    
[^25]: 可解释的自适应基于树的模型选择用于时间序列预测

    Explainable Adaptive Tree-based Model Selection for Time Series Forecasting. (arXiv:2401.01124v1 [cs.LG])

    [http://arxiv.org/abs/2401.01124](http://arxiv.org/abs/2401.01124)

    提出了一种用于时间序列预测的在线选择基于树的模型的新方法，采用了TreeSHAP解释性方法进行模型的专门化，以应对基于树的模型在实际决策中的过拟合问题。

    

    基于树的模型已成功应用于各种任务，包括时间序列预测。由于其相对高的可解释性，它们在需求和广泛认可方面越来越受欢迎。然而，许多模型都存在过拟合问题，这限制了它们在实际决策中的应用。在在线预测设置中，这个问题变得更加严重，因为时间序列观测不断增加，而它们所绘制的分布可能随时间而变化。在这个背景下，我们提出了一种新颖的方法，使用TreeSHAP解释性方法在线选择基于树的模型来进行时间序列预测。我们从任意一组不同的基于树的模型开始。然后，我们概述了一个基于性能的排名，并具有一致的设计，使得TreeSHAP能够根据输入时间序列的不同区域来专门化基于树的预测器。在这个框架中，适当的模式...

    Tree-based models have been successfully applied to a wide variety of tasks, including time series forecasting. They are increasingly in demand and widely accepted because of their comparatively high level of interpretability. However, many of them suffer from the overfitting problem, which limits their application in real-world decision-making. This problem becomes even more severe in online-forecasting settings where time series observations are incrementally acquired, and the distributions from which they are drawn may keep changing over time. In this context, we propose a novel method for the online selection of tree-based models using the TreeSHAP explainability method in the task of time series forecasting. We start with an arbitrary set of different tree-based models. Then, we outline a performance-based ranking with a coherent design to make TreeSHAP able to specialize the tree-based forecasters across different regions in the input time series. In this framework, adequate mode
    
[^26]: 利用自回归网络进行滚动轴承全生命周期数据生成用于剩余寿命预测

    Utilizing Autoregressive Networks for Full Lifecycle Data Generation of Rolling Bearings for RUL Prediction. (arXiv:2401.01119v1 [cs.LG])

    [http://arxiv.org/abs/2401.01119](http://arxiv.org/abs/2401.01119)

    本文介绍了一种利用CVGAN模型生成滚动轴承振动信号的方法，该模型能够根据历史振动数据和剩余寿命条件生成一维振动信号，同时提出了一种自回归生成方法来指导信号的生成。实验证明，CVGAN模型在MMD和FID指标方面优于其他高级方法。

    

    在工业生产中，滚动轴承寿命的预测非常重要。然而，高质量的滚动轴承全生命周期数据的稀缺性一直是精确预测的主要制约因素。为了解决这一挑战，本文引入了CVGAN模型，这是一个能够生成水平和垂直方向上的一维振动信号的新框架，其受历史振动数据和剩余寿命的条件约束。此外，我们提出了一种自回归生成方法，可以迭代地利用之前生成的振动信息来指导当前信号的生成。通过在PHM 2012数据集上进行的实验证明了CVGAN模型的有效性。我们的研究结果表明，CVGAN模型在自回归和非自回归生成模式下，在MMD和FID指标方面表现优于许多高级方法。值得注意的是，训练使用了由CVGAN模型生成的全生命周期数据。

    The prediction of rolling bearing lifespan is of significant importance in industrial production. However, the scarcity of high-quality, full lifecycle data has been a major constraint in achieving precise predictions. To address this challenge, this paper introduces the CVGAN model, a novel framework capable of generating one-dimensional vibration signals in both horizontal and vertical directions, conditioned on historical vibration data and remaining useful life. In addition, we propose an autoregressive generation method that can iteratively utilize previously generated vibration information to guide the generation of current signals. The effectiveness of the CVGAN model is validated through experiments conducted on the PHM 2012 dataset. Our findings demonstrate that the CVGAN model, in terms of both MMD and FID metrics, outperforms many advanced methods in both autoregressive and non-autoregressive generation modes. Notably, training using the full lifecycle data generated by the 
    
[^27]: AI-FLARES: 用于太阳耀斑数据分析的人工智能

    AI-FLARES: Artificial Intelligence for the Analysis of Solar Flares Data. (arXiv:2401.01104v1 [astro-ph.SR])

    [http://arxiv.org/abs/2401.01104](http://arxiv.org/abs/2401.01104)

    AI-FLARES是一项研究项目，通过开发和使用计算方法分析太阳耀斑数据，成果包括耀斑预测、耀斑源形态重建和太阳耀斑加速机制解释。

    

    AI-FLARES（用于太阳耀斑数据分析的人工智能）是由意大利太空局和意大利国家天文物理研究所资助的研究项目，旨在开发和使用计算方法分析与太阳耀斑发射相关的远程感测空间数据。本文概述了该项目取得的主要成果，重点介绍了太阳耀斑预测、耀斑源形态重建和太阳耀斑触发的加速机制解释。

    AI-FLARES (Artificial Intelligence for the Analysis of Solar Flares Data) is a research project funded by the Agenzia Spaziale Italiana and by the Istituto Nazionale di Astrofisica within the framework of the ``Attivit\`a di Studio per la Comunit\`a Scientifica Nazionale Sole, Sistema Solare ed Esopianeti'' program. The topic addressed by this project was the development and use of computational methods for the analysis of remote sensing space data associated to solar flare emission. This paper overviews the main results obtained by the project, with specific focus on solar flare forecasting, reconstruction of morphologies of the flaring sources, and interpretation of acceleration mechanisms triggered by solar flares.
    
[^28]: 有效的并行语音生成方法：使用组掩码语言模型

    Efficient Parallel Audio Generation using Group Masked Language Modeling. (arXiv:2401.01099v1 [eess.AS])

    [http://arxiv.org/abs/2401.01099](http://arxiv.org/abs/2401.01099)

    我们提出了一种有效的并行语音生成方法，通过使用组掩码语言模型和组迭代并行解码，能够快速生成高质量的音频，并成功捕捉提示语音的说话人风格，提高了计算效率。

    

    我们提出了一种快速且高质量的编解码语言模型，用于并行语音生成。虽然SoundStorm是一种先进的并行语音生成模型，相比自回归模型加速了推理速度，但由于迭代采样，它仍然受到推理速度慢的影响。为了解决这个问题，我们提出了组掩码语言模型（G-MLM）和组迭代并行解码（G-IPD），用于有效的并行语音生成。训练和采样方案都能够通过有效建模组间条件依赖来在少数迭代次数内合成高质量的音频。此外，我们的模型采用了基于交叉注意力的架构，以捕捉提示语音的说话人风格并提高计算效率。实验结果表明，我们提出的模型在基于提示的语音生成方面优于基线模型。

    We present a fast and high-quality codec language model for parallel audio generation. While SoundStorm, a state-of-the-art parallel audio generation model, accelerates inference speed compared to autoregressive models, it still suffers from slow inference due to iterative sampling. To resolve this problem, we propose Group-Masked Language Modeling~(G-MLM) and Group Iterative Parallel Decoding~(G-IPD) for efficient parallel audio generation. Both the training and sampling schemes enable the model to synthesize high-quality audio with a small number of iterations by effectively modeling the group-wise conditional dependencies. In addition, our model employs a cross-attention-based architecture to capture the speaker style of the prompt voice and improves computational efficiency. Experimental results demonstrate that our proposed model outperforms the baselines in prompt-based audio generation.
    
[^29]: Quokka: 一个用于材料科学的开源大型语言模型聊天机器人

    Quokka: An Open-source Large Language Model ChatBot for Material Science. (arXiv:2401.01089v1 [cs.CL])

    [http://arxiv.org/abs/2401.01089](http://arxiv.org/abs/2401.01089)

    本文介绍了Quokka——一个用于材料科学的开源大型语言模型聊天机器人，通过对超过一百万篇领域特定的论文进行预训练，并在材料科学领域的查询中提供即时的上下文意识响应。

    

    本文介绍了一个用于材料科学的专用聊天机器人的开发，利用了Llama-2语言模型，并在S2ORC数据集中的材料科学领域的广泛研究文章上进行持续的预训练。方法包括首先在超过一百万篇领域特定的论文上进行预训练，然后进行指令调整过程来改善聊天机器人的能力。该聊天机器人旨在通过提供即时的、具有上下文意识的材料科学领域的查询响应，来帮助研究人员、教师和学生。我们将四个经过训练的检查点（7B、13B，带或不带聊天功能）免费提供给研究界，网址为https://github.com/Xianjun-Yang/Quokka。

    This paper presents the development of a specialized chatbot for materials science, leveraging the Llama-2 language model, and continuing pre-training on the expansive research articles in the materials science domain from the S2ORC dataset. The methodology involves an initial pretraining phase on over one million domain-specific papers, followed by an instruction-tuning process to refine the chatbot's capabilities. The chatbot is designed to assist researchers, educators, and students by providing instant, context-aware responses to queries in the field of materials science. We make the four trained checkpoints (7B, 13B, with or without chat ability) freely available to the research community at https://github.com/Xianjun-Yang/Quokka.
    
[^30]: 越南诗歌生成与跨语言诗歌翻译的前景

    Vietnamese Poem Generation & The Prospect Of Cross-Language Poem-To-Poem Translation. (arXiv:2401.01078v1 [cs.CL])

    [http://arxiv.org/abs/2401.01078](http://arxiv.org/abs/2401.01078)

    本文通过使用大型语言模型，成功提出了一种生成越南诗歌的方法，并探索了将诗歌翻译成不同语言的可能性，同时保持对生成内容的完全控制。

    

    诗歌生成一直是自然语言处理领域的一项挑战任务，因为它要求模型理解语言、情感和风格的细微差别。在本文中，我们提出使用大型语言模型从自然语言提示中生成越南诗歌，从而实现直观的过程和增强的内容控制。我们最有效的模型，GPT-3 Babbage变种，在越南诗歌的“六八词”类型中实现了0.8的自定义评分。此外，我们还探索了将诗歌改写成正常文本提示的想法，并在“六八词”类型中获得了相对较高的0.718分数。这个实验展示了以翻译后的诗歌作为输入进行跨语言诗歌翻译的潜力，并同时保持对生成内容的完全控制。

    Poetry generation has been a challenging task in the field of Natural Language Processing, as it requires the model to understand the nuances of language, sentiment, and style. In this paper, we propose using Large Language Models to generate Vietnamese poems from natural language prompts, thereby facilitating an intuitive process with enhanced content control. Our most efficacious model, the GPT-3 Babbage variant, achieves a custom evaluation score of 0.8, specifically tailored to the "luc bat" genre of Vietnamese poetry. Furthermore, we also explore the idea of paraphrasing poems into normal text prompts and yield a relatively high score of 0.718 in the "luc bat" genre. This experiment presents the potential for cross-Language poem-to-poem translation with translated poems as the inputs while concurrently maintaining complete control over the generated content.
    
[^31]: 从法律裁决中发现重要主题的选择推理方法

    Discovering Significant Topics from Legal Decisions with Selective Inference. (arXiv:2401.01068v1 [cs.CL])

    [http://arxiv.org/abs/2401.01068](http://arxiv.org/abs/2401.01068)

    本研究提出了一个自动化流程，通过主题模型和统计分析方法从法律裁决文本中发现重要主题。该方法可以识别与结果相关的案例主题，并通过主题-词分布和案例-主题权重来提供更多信息。研究结果表明该方法具有很好的准确性和实用性。

    

    我们提出并评估了一个自动化流程，通过将主题模型合成的特征通过受惩罚的回归和后选择显著性检验来发现法律裁决文本中的重要主题。该方法识别出与结果显著相关的案例主题，可以手动解释以获取有关重要主题的见解的主题-词分布，以及可以用于标识每个主题的代表性案例的案例-主题权重。我们在一个新的域名争议数据集和一个欧洲人权法院违规案例的经典数据集上展示了该方法。基于潜在语义分析和语言模型嵌入的主题模型进行了评估。我们证明了通过流程推导的主题在两个领域中与法律教条一致，并且可以在其他相关法律分析任务中有用。

    We propose and evaluate an automated pipeline for discovering significant topics from legal decision texts by passing features synthesized with topic models through penalised regressions and post-selection significance tests. The method identifies case topics significantly correlated with outcomes, topic-word distributions which can be manually-interpreted to gain insights about significant topics, and case-topic weights which can be used to identify representative cases for each topic. We demonstrate the method on a new dataset of domain name disputes and a canonical dataset of European Court of Human Rights violation cases. Topic models based on latent semantic analysis as well as language model embeddings are evaluated. We show that topics derived by the pipeline are consistent with legal doctrines in both areas and can be useful in other related legal analysis tasks.
    
[^32]: BEV-CLIP：用于自动驾驶中复杂场景的多模态BEV检索方法论

    BEV-CLIP: Multi-modal BEV Retrieval Methodology for Complex Scene in Autonomous Driving. (arXiv:2401.01065v1 [cs.CV])

    [http://arxiv.org/abs/2401.01065](http://arxiv.org/abs/2401.01065)

    BEV-CLIP是一种用于自动驾驶中复杂场景的多模态BEV检索方法，通过使用描述性文本进行检索，利用大型语言模型的 semantic feature extraction 和知识图谱的半结构化信息来提高检索准确性。

    

    随着乘用车辆具备在城市环境中导航的能力，自动驾驶中对复杂场景数据的检索需求不断增加，尤其是在处理长尾情景时。然而，在现有的二维图像检索方法下，存在一些场景检索的问题，例如全局特征表征不足和文本检索能力不佳。为了解决这些问题，我们提出了BEV-CLIP，这是第一个利用描述性文本作为输入来检索相应场景的多模态鸟瞰图检索方法。该方法利用大型语言模型 (LLM) 的语义特征提取能力，实现了对广泛文本描述的零样本检索，并结合知识图谱的半结构化信息，提高了语言嵌入的语义丰富性和多样性。实验结果表明，在NuScenes数据集上取得了87.66%的准确率。

    The demand for the retrieval of complex scene data in autonomous driving is increasing, especially as passenger vehicles have been equipped with the ability to navigate urban settings, with the imperative to address long-tail scenarios. Meanwhile, under the pre-existing two dimensional image retrieval method, some problems may arise with scene retrieval, such as lack of global feature representation and subpar text retrieval ability. To address these issues, we have proposed \textbf{BEV-CLIP}, the first multimodal Bird's-Eye View(BEV) retrieval methodology that utilizes descriptive text as an input to retrieve corresponding scenes. This methodology applies the semantic feature extraction abilities of a large language model (LLM) to facilitate zero-shot retrieval of extensive text descriptions, and incorporates semi-structured information from a knowledge graph to improve the semantic richness and variety of the language embedding. Our experiments result in 87.66% accuracy on NuScenes d
    
[^33]: 通过鲁棒的全局特征提取增强自动调制识别

    Enhancing Automatic Modulation Recognition through Robust Global Feature Extraction. (arXiv:2401.01056v1 [eess.SP])

    [http://arxiv.org/abs/2401.01056](http://arxiv.org/abs/2401.01056)

    该论文提出了一种名为TLDNN的混合深度框架，将Transformer和LSTM的结构结合，通过全局特征提取和捕捉时域依赖性的增强，为自动调制识别带来了改进。

    

    自动调制识别在无线通信系统中起着至关重要的作用。近年来，深度学习自动调制识别策略取得了巨大的成功。调制信号展示了长期的时域依赖性，提取全局特征对于识别调制方案至关重要。传统上，人工专家分析星座图中的模式来分类调制方案。由于有限的感受野，传统的卷积网络擅长提取局部特征，但难以捕捉全局关系。为了解决这个问题，我们引入了一种名为TLDNN的新型混合深度框架，它将Transformer和长短期记忆（LSTM）的结构结合在一起。我们利用Transformer的自注意机制模拟信号序列中的全局关联，同时利用LSTM增强时域依赖性的捕捉。为了减轻射频指纹特征和信道特性等因素的影响。

    Automatic Modulation Recognition (AMR) plays a crucial role in wireless communication systems. Deep learning AMR strategies have achieved tremendous success in recent years. Modulated signals exhibit long temporal dependencies, and extracting global features is crucial in identifying modulation schemes. Traditionally, human experts analyze patterns in constellation diagrams to classify modulation schemes. Classical convolutional-based networks, due to their limited receptive fields, excel at extracting local features but struggle to capture global relationships. To address this limitation, we introduce a novel hybrid deep framework named TLDNN, which incorporates the architectures of the transformer and long short-term memory (LSTM). We utilize the self-attention mechanism of the transformer to model the global correlations in signal sequences while employing LSTM to enhance the capture of temporal dependencies. To mitigate the impact like RF fingerprint features and channel characteri
    
[^34]: LLaMA超越英语：语言能力转移的实证研究

    LLaMA Beyond English: An Empirical Study on Language Capability Transfer. (arXiv:2401.01055v1 [cs.CL])

    [http://arxiv.org/abs/2401.01055](http://arxiv.org/abs/2401.01055)

    本文提出了LLaMA超越英语：语言能力转移的实证研究。通过对LLaMA进行广泛的实证调查，分析了词汇扩展、进一步预训练和指导调整等关键因素对非英语语言上的能力转移的影响，并通过四个标准化测试基准评估了模型的知识水平和响应质量。

    

    最近，在大型语言模型（LLM）方面取得了重大进展，如ChatGPT，在各种复杂任务中展现出卓越的熟练度。然而，许多主流的LLM（如LLaMA）是基于以英语为主导的语料库进行预训练的，这限制了它们在其他非英语语言中的性能。本文主要研究如何有效地将语言生成和遵循指示的能力转移到非英语语言上。为了回答这个问题，我们基于LLaMA进行了广泛的实证调查，总计耗费了1440个GPU小时。我们分析了诸如词汇扩展、进一步预训练和指导调整等关键因素对转移的影响。为了准确评估模型的知识水平，我们采用了四个广泛使用的标准化测试基准：C-Eval、MMLU、AGI-Eval和GAOKAO-Bench。此外，我们还对模型的响应质量进行了全面评估，考虑了诸如...

    In recent times, substantial advancements have been witnessed in large language models (LLMs), exemplified by ChatGPT, showcasing remarkable proficiency across a range of complex tasks. However, many mainstream LLMs (e.g. LLaMA) are pretrained on English-dominant corpus, which limits their performance in other non-English languages. In this paper, we focus on how to effectively transfer the capabilities of language generation and following instructions to a non-English language. To answer this question, we conduct an extensive empirical investigation based on LLaMA, accumulating over 1440 GPU hours. We analyze the impact of key factors such as vocabulary extension, further pretraining, and instruction tuning on transfer. To accurately assess the model's level of knowledge, we employ four widely used standardized testing benchmarks: C-Eval, MMLU, AGI-Eval, and GAOKAO-Bench. Furthermore, a comprehensive evaluation of the model's response quality is conducted, considering aspects such as 
    
[^35]: 弹性多梯度下降用于并行连续学习

    Elastic Multi-Gradient Descent for Parallel Continual Learning. (arXiv:2401.01054v1 [cs.LG])

    [http://arxiv.org/abs/2401.01054](http://arxiv.org/abs/2401.01054)

    这是一篇关于并行连续学习的论文，介绍了在动态多任务场景下的挑战和解决方法。通过使用任务特定的弹性因子，可以解决梯度差异和负迁移的问题。

    

    连续学习（CL）的目标是从新的数据流中持续学习并完成相应的任务。过去研究的CL假设数据按任务的顺序给出，因此属于串行连续学习（SCL）。本文研究了动态多任务场景下的新兴范式——并行连续学习（PCL），其中在不同时间点遇到了多样的任务。PCL面临的挑战是训练数量不确定且学习进度不同的任务，导致很难保证所有遇到的任务都能得到有效的模型更新。在我们之前的会议论文中，我们主要研究了在多目标优化问题中测量和减小梯度之间的差异，然而，每次模型更新仍然可能存在负迁移。为了解决这个问题，在动态多目标优化问题中，我们引入了任务特定的弹性因子。

    The goal of Continual Learning (CL) is to continuously learn from new data streams and accomplish the corresponding tasks. Previously studied CL assumes that data are given in sequence nose-to-tail for different tasks, thus indeed belonging to Serial Continual Learning (SCL). This paper studies the novel paradigm of Parallel Continual Learning (PCL) in dynamic multi-task scenarios, where a diverse set of tasks is encountered at different time points. PCL presents challenges due to the training of an unspecified number of tasks with varying learning progress, leading to the difficulty of guaranteeing effective model updates for all encountered tasks. In our previous conference work, we focused on measuring and reducing the discrepancy among gradients in a multi-objective optimization problem, which, however, may still contain negative transfers in every model update. To address this issue, in the dynamic multi-objective optimization problem, we introduce task-specific elastic factors to
    
[^36]: Auffusion: 利用扩散和大型语言模型提升文本到音频生成的能力

    Auffusion: Leveraging the Power of Diffusion and Large Language Models for Text-to-Audio Generation. (arXiv:2401.01044v1 [cs.SD])

    [http://arxiv.org/abs/2401.01044](http://arxiv.org/abs/2401.01044)

    这篇论文介绍了一种名为Auffusion的文本到音频生成系统，它利用扩散和大型语言模型，通过跨模态对齐的能力，提高了生成质量和文本-音频对齐。该系统在有限的数据和计算资源下胜过了之前的方法，并关注了编码器选择对跨模态对齐的重要性。

    

    最近扩散模型和大型语言模型（LLM）的进展显著推动了AIGC领域的发展。文本到音频（TTA）作为一种新兴的AIGC应用，旨在从自然语言提示生成音频，引起了越来越多的关注。然而，现有的TTA研究往往在生成质量和文本-音频对齐方面存在困难，特别是对于复杂的文本输入。受到最先进的文本到图像（T2I）扩散模型的启发，我们介绍了Auffusion，一种将T2I模型框架适应TTA任务的系统，通过有效利用其固有的生成优势和精确的跨模态对齐能力。我们的客观和主观评估表明，Auffusion在使用有限的数据和计算资源时超越了之前的TTA方法。此外，之前的T2I研究认识到编码器选择对跨模态对齐的重要影响，例如细节和物体绑定，而类似的评估则缺乏。

    Recent advancements in diffusion models and large language models (LLMs) have significantly propelled the field of AIGC. Text-to-Audio (TTA), a burgeoning AIGC application designed to generate audio from natural language prompts, is attracting increasing attention. However, existing TTA studies often struggle with generation quality and text-audio alignment, especially for complex textual inputs. Drawing inspiration from state-of-the-art Text-to-Image (T2I) diffusion models, we introduce Auffusion, a TTA system adapting T2I model frameworks to TTA task, by effectively leveraging their inherent generative strengths and precise cross-modal alignment. Our objective and subjective evaluations demonstrate that Auffusion surpasses previous TTA approaches using limited data and computational resource. Furthermore, previous studies in T2I recognizes the significant impact of encoder choice on cross-modal alignment, like fine-grained details and object bindings, while similar evaluation is lack
    
[^37]: 走向认知人工智能系统：神经符号人工智能的调查和展望

    Towards Cognitive AI Systems: a Survey and Prospective on Neuro-Symbolic AI. (arXiv:2401.01040v1 [cs.AI])

    [http://arxiv.org/abs/2401.01040](http://arxiv.org/abs/2401.01040)

    本文回顾了神经符号人工智能的最新进展，分析了其模型的性能特征和计算运算符，并讨论了从系统和架构角度上NSAI面临的挑战和潜在未来方向。

    

    人工智能（AI）的显著进展，主要由深度神经网络推动，已经在我们生活的各个方面产生了重大影响。然而，当前可持续计算轨迹的挑战、有限的鲁棒性和缺乏可解释性要求开发下一代AI系统。神经符号AI（NSAI）作为一种有潜力的范式出现，融合了神经、符号和概率方法，增强了解释能力、鲁棒性和可信度，同时减少了对数据的依赖。最近的NSAI系统在具有推理和认知能力的人工智能协作场景中展示出了巨大的潜力。在本文中，我们对NSAI的最新进展进行了系统回顾，并分析了NSAI模型的性能特征和计算运算符。此外，我们从系统和架构的角度讨论了NSAI面临的挑战和潜在的未来方向。

    The remarkable advancements in artificial intelligence (AI), primarily driven by deep neural networks, have significantly impacted various aspects of our lives. However, the current challenges surrounding unsustainable computational trajectories, limited robustness, and a lack of explainability call for the development of next-generation AI systems. Neuro-symbolic AI (NSAI) emerges as a promising paradigm, fusing neural, symbolic, and probabilistic approaches to enhance interpretability, robustness, and trustworthiness while facilitating learning from much less data. Recent NSAI systems have demonstrated great potential in collaborative human-AI scenarios with reasoning and cognitive capabilities. In this paper, we provide a systematic review of recent progress in NSAI and analyze the performance characteristics and computational operators of NSAI models. Furthermore, we discuss the challenges and potential future directions of NSAI from both system and architectural perspectives.
    
[^38]: Text-to-image diffusion models中通过重用注意力映射实现快速推理

    Fast Inference Through The Reuse Of Attention Maps In Diffusion Models. (arXiv:2401.01008v1 [cs.CV])

    [http://arxiv.org/abs/2401.01008](http://arxiv.org/abs/2401.01008)

    本文提出了一种无需训练的方法，通过重用注意力映射来实现Text-to-image diffusion models中的快速推理，以提高效率。

    

    文字到图像扩散模型在灵活和逼真的图像合成方面展示了前所未有的能力。然而，生成单个图像所需的迭代过程既昂贵又具有较高的延迟，促使研究人员进一步研究其效率。我们提出了一种无需调整采样步长的无需训练的方法。具体地说，我们发现重复计算注意力映射既耗时又冗余，因此我们建议在采样过程中结构化地重用注意力映射。我们的初步重用策略受到初级ODE理论的启发，该理论认为在采样过程的后期重用最合适。在注意到这种理论方法的一些局限性后，我们通过实验证明了一种更好的方法。

    Text-to-image diffusion models have demonstrated unprecedented abilities at flexible and realistic image synthesis. However, the iterative process required to produce a single image is costly and incurs a high latency, prompting researchers to further investigate its efficiency. Typically, improvements in latency have been achieved in two ways: (1) training smaller models through knowledge distillation (KD); and (2) adopting techniques from ODE-theory to facilitate larger step sizes. In contrast, we propose a training-free approach that does not alter the step-size of the sampler. Specifically, we find the repeated calculation of attention maps to be both costly and redundant; therefore, we propose a structured reuse of attention maps during sampling. Our initial reuse policy is motivated by rudimentary ODE-theory, which suggests that reuse is most suitable late in the sampling procedure. After noting a number of limitations in this theoretical approach, we empirically search for a bet
    
[^39]: 朝着实现6G及以后网络AI零排放碳目标迈进

    Towards Net-Zero Carbon Emissions in Network AI for 6G and Beyond. (arXiv:2401.01007v1 [cs.NI])

    [http://arxiv.org/abs/2401.01007](http://arxiv.org/abs/2401.01007)

    本论文旨在实现6G及以后网络AI的零排放碳目标。通过确定排放源并引入评估框架，提出了一种联合动态能源交易和任务分配优化框架，以解决移动网络能源消耗和碳排放的问题。

    

    全球正在努力减少全球温室气体排放（主要是碳排放）到2030年减半，并在2050年实现零排放。发展6G技术也必须符合这一目标。然而，开发可持续且零排放系统以满足用户对移动服务（特别是智能服务和应用）不断增长的需求，可能比预期的要具有更大的挑战性。尤其是尽管硬件和软件设计的能效改进，移动网络的能源消耗和碳排放仍在以惊人的速度增长。资源需求严重的AI算法和解决方案的不断普及进一步加剧了这一挑战。在本文中，我们确定了主要的排放源，并介绍了一个用于分析网络AI实现生命周期的评估框架。提出了一种新颖的联合动态能源交易和任务分配优化框架

    A global effort has been initiated to reduce the worldwide greenhouse gas (GHG) emissions, primarily carbon emissions, by half by 2030 and reach net-zero by 2050. The development of 6G must also be compliant with this goal. Unfortunately, developing a sustainable and net-zero emission systems to meet the users' fast growing demands on mobile services, especially smart services and applications, may be much more challenging than expected. Particularly, despite the energy efficiency improvement in both hardware and software designs, the overall energy consumption and carbon emission of mobile networks are still increasing at a tremendous speed. The growing penetration of resource-demanding AI algorithms and solutions further exacerbate this challenge. In this article, we identify the major emission sources and introduce an evaluation framework for analyzing the lifecycle of network AI implementations. A novel joint dynamic energy trading and task allocation optimization framework, called
    
[^40]: 儿童元学习——对负责任的脑启发式人工智能的启示

    Metalearning-Informed Competence in Children: Implications for Responsible Brain-Inspired Artificial Intelligence. (arXiv:2401.01001v1 [q-bio.NC])

    [http://arxiv.org/abs/2401.01001](http://arxiv.org/abs/2401.01001)

    本文提出了一个新颖的概念框架，该框架解释了儿童是如何通过四个认知机制实现元学习策略的，并以此作为模型，为基于脑启发式计算的人工智能提供启示。

    

    本文提供了一个新颖的概念框架，包括四个基本的认知机制，这些机制同时并协同地运作，以实现儿童元学习（学习的知识和调节）策略的实施。通过呈现一个包含核心机制和相关策略的路线图，本文解释了发展中的大脑在跨环境学习上的出色能力。选择四个基本互补性过程的组合来共同代表精简的元学习架构，这可以扩展到模仿大脑学习和解决问题能力的人工智能系统中。通过将具有元学习能力的年轻思维作为脑启发式计算的模型，本文进一步讨论了对道德立场的人工智能的重要影响。

    This paper offers a novel conceptual framework comprising four essential cognitive mechanisms that operate concurrently and collaboratively to enable metalearning (knowledge and regulation of learning) strategy implementation in young children. A roadmap incorporating the core mechanisms and the associated strategies is presented as an explanation of the developing brain's remarkable cross-context learning competence. The tetrad of fundamental complementary processes is chosen to collectively represent the bare-bones metalearning architecture that can be extended to artificial intelligence (AI) systems emulating brain-like learning and problem-solving skills. Utilizing the metalearning-enabled young mind as a model for brain-inspired computing, this work further discusses important implications for morally grounded AI.
    
[^41]: 安全与性能，为什么不两者兼得？针对人工智能软件部署的异构攻击的双目标优化模型压缩

    Safety and Performance, Why Not Both? Bi-Objective Optimized Model Compression against Heterogeneous Attacks Toward AI Software Deployment. (arXiv:2401.00996v1 [cs.AI])

    [http://arxiv.org/abs/2401.00996](http://arxiv.org/abs/2401.00996)

    本文提出了一个名为SafeCompress的测试驱动稀疏训练框架，用于解决人工智能软件中的安全模型压缩问题。

    

    人工智能（AI）软件中深度学习模型的大小正在迅速增加，这对于资源受限的设备（如智能手机）的大规模部署构成了阻碍。为了解决这个问题，AI软件压缩发挥了关键作用，旨在在保持高性能的同时压缩模型大小。然而，大型模型中的固有缺陷可能会被压缩模型继承。由于压缩模型通常在大量设备上部署且没有足够的保护，这些缺陷可能易被对手利用。在本文中，我们从安全性能协调的角度解决了安全模型压缩问题。具体而言，受软件工程中测试驱动开发（TDD）范式的启发，我们提出了一个名为SafeCompress的测试驱动稀疏训练框架。通过将攻击机制模拟为安全测试，SafeCompress可以自动将大型模型压缩为小型模型。

    The size of deep learning models in artificial intelligence (AI) software is increasing rapidly, hindering the large-scale deployment on resource-restricted devices (e.g., smartphones). To mitigate this issue, AI software compression plays a crucial role, which aims to compress model size while keeping high performance. However, the intrinsic defects in a big model may be inherited by the compressed one. Such defects may be easily leveraged by adversaries, since a compressed model is usually deployed in a large number of devices without adequate protection. In this article, we aim to address the safe model compression problem from the perspective of safety-performance co-optimization. Specifically, inspired by the test-driven development (TDD) paradigm in software engineering, we propose a test-driven sparse training framework called SafeCompress. By simulating the attack mechanism as safety testing, SafeCompress can automatically compress a big model to a small one following the dynam
    
[^42]: 在有背景干扰效果的遮挡环境中利用深度学习进行实时目标检测

    Real-Time Object Detection in Occluded Environment with Background Cluttering Effects Using Deep Learning. (arXiv:2401.00986v1 [cs.CV])

    [http://arxiv.org/abs/2401.00986](http://arxiv.org/abs/2401.00986)

    本文集中研究了在有背景干扰效果和遮挡环境中利用深度学习进行实时目标检测的问题。通过应用SSD和YOLO算法，并改善检测精度，减少问题，我们得到了高准确性和高帧率的SSD-Mobilenet v2模型。

    

    计算机视觉中的主要问题是检测小型、不确定的移动物体或在遮挡环境中具有杂乱背景的物体。这严重影响了深度学习模型的检测准确性。为了克服这些问题，我们集中研究了在遮挡环境中利用SSD和YOLO算法进行实时汽车和坦克检测的深度学习模型，并改善了检测精度，减少了这些模型面临的问题。所开发的方法构建了自定义数据集，并采用预处理技术清除嘈杂的数据集。为了训练所开发的模型，我们应用了数据增强技术来平衡和丰富数据。通过应用这些技术并突出展示我们得到的结果，我们对已建立的数据集上的这些模型进行了微调、训练和评估，比不应用这些技术时得到了更准确的精度和每秒帧数。SSD-Mobilenet v2模型的准确性和帧率均高于其他模型。

    Detection of small, undetermined moving objects or objects in an occluded environment with a cluttered background is the main problem of computer vision. This greatly affects the detection accuracy of deep learning models. To overcome these problems, we concentrate on deep learning models for real-time detection of cars and tanks in an occluded environment with a cluttered background employing SSD and YOLO algorithms and improved precision of detection and reduce problems faced by these models. The developed method makes the custom dataset and employs a preprocessing technique to clean the noisy dataset. For training the developed model we apply the data augmentation technique to balance and diversify the data. We fine-tuned, trained, and evaluated these models on the established dataset by applying these techniques and highlighting the results we got more accurately than without applying these techniques. The accuracy and frame per second of the SSD-Mobilenet v2 model are higher than 
    
[^43]: 运用自然启发式算法的优化：介绍、混合和洞见

    Nature-Inspired Algorithms in Optimization: Introduction, Hybridization and Insights. (arXiv:2401.00976v1 [cs.NE])

    [http://arxiv.org/abs/2401.00976](http://arxiv.org/abs/2401.00976)

    本论文综述了优化、自然启发式算法以及混合方法的概述，并讨论了算法混合过程中的问题。

    

    科学和工程中的许多问题都是优化问题，可能需要复杂的优化技术来解决。自然启发式算法是一类用于优化的元启发式算法，一些算法或变种经常通过混合方法来开发。基准测试在评估优化算法的性能方面也很重要。本章主要介绍优化、自然启发式算法和混合方法的概述。我们还将重点介绍一些算法混合的问题。

    Many problems in science and engineering are optimization problems, which may require sophisticated optimization techniques to solve. Nature-inspired algorithms are a class of metaheuristic algorithms for optimization, and some algorithms or variants are often developed by hybridization. Benchmarking is also important in evaluating the performance of optimization algorithms. This chapter focuses on the overview of optimization, nature-inspired algorithms and the role of hybridization. We will also highlight some issues with hybridization of algorithms.
    
[^44]: 在合成数据训练中，针对下游任务的生成模型选择的欺诈检测模型研究

    Downstream Task-Oriented Generative Model Selections on Synthetic Data Training for Fraud Detection Models. (arXiv:2401.00974v1 [cs.LG])

    [http://arxiv.org/abs/2401.00974](http://arxiv.org/abs/2401.00974)

    本论文研究了欺诈检测模型训练中针对下游任务的生成模型选择问题，并调查了在不同的可解释性和性能约束条件下的最佳实践。研究结果表明，在合成训练欺诈检测模型时，贝叶斯网络（BN）的生成模型优于神经网络（NN）的生成模型。

    

    设计用于下游任务的生成模型选择流程是一个尚未解决但具有重要实际意义的问题。现有研究主要关注单一类型生成模型的实用性，对于合成训练任务中如何选择最佳生成模型家族，给定特定的机器学习模型类别和性能度量，提供的见解有限。本文针对训练欺诈检测模型的下游任务导向生成模型选择问题进行研究，并调查在模型可解释性和模型性能约束不同时的最佳实践。我们的研究支持以下观点：在模型可解释性约束下，神经网络（NN）和贝叶斯网络（BN）的生成模型均能很好完成合成训练任务，但在合成训练欺诈检测模型时，BN-based生成模型比NN-based更好。

    Devising procedures for downstream task-oriented generative model selections is an unresolved problem of practical importance. Existing studies focused on the utility of a single family of generative models. They provided limited insights on how synthetic data practitioners select the best family generative models for synthetic training tasks given a specific combination of machine learning model class and performance metric. In this paper, we approach the downstream task-oriented generative model selections problem in the case of training fraud detection models and investigate the best practice given different combinations of model interpretability and model performance constraints. Our investigation supports that, while both Neural Network(NN)-based and Bayesian Network(BN)-based generative models are both good to complete synthetic training task under loose model interpretability constrain, the BN-based generative models is better than NN-based when synthetic training fraud detectio
    
[^45]: 跨领域WiFi CSI基于人体活动识别的数据增强技术

    Data Augmentation Techniques for Cross-Domain WiFi CSI-based Human Activity Recognition. (arXiv:2401.00964v1 [cs.CV])

    [http://arxiv.org/abs/2401.00964](http://arxiv.org/abs/2401.00964)

    本研究应用基于图像学习的数据增强技术于WiFi CSI，旨在解决人体活动识别中模型泛化能力差的问题。通过跨场景和跨系统的实验，研究了线性视线（LOS）和非线性视线（NLOS）穿墙场景之间以及不同天线系统之间的泛化效果。通过构建基于EfficientNetV2架构的活动识别模型并进行消融研究，评估了不同数据增强技术的效果。

    

    基于WiFi信道状态信息（CSI）的人体活动识别能够在室内环境中实现无接触和视觉保护隐私的感知。然而，由于环境条件和感知硬件的差异，模型泛化能力差是这个领域中一个众所周知的问题。为了解决这个问题，本文将常用于基于图像学习的数据增强技术应用于WiFi CSI，并研究它们对模型泛化性能在跨场景和跨系统设置中的影响。特别是，我们专注于线性视线（LOS）和非线性视线（NLOS）穿墙场景之间的泛化，以及不同天线系统之间的泛化，这仍然是一个未经充分探索的领域。我们收集并公开了一个包含人体活动CSI幅度谱图的数据集。利用这个数据集，进行了一个消融研究，基于EfficientNetV2架构构建了活动识别模型，并评估了不同数据增强技术的效果。

    The recognition of human activities based on WiFi Channel State Information (CSI) enables contactless and visual privacy-preserving sensing in indoor environments. However, poor model generalization, due to varying environmental conditions and sensing hardware, is a well-known problem in this space. To address this issue, in this work, data augmentation techniques commonly used in image-based learning are applied to WiFi CSI to investigate their effects on model generalization performance in cross-scenario and cross-system settings. In particular, we focus on the generalization between line-of-sight (LOS) and non-line-of-sight (NLOS) through-wall scenarios, as well as on the generalization between different antenna systems, which remains under-explored. We collect and make publicly available a dataset of CSI amplitude spectrograms of human activities. Utilizing this data, an ablation study is conducted in which activity recognition models based on the EfficientNetV2 architecture are tr
    
[^46]: 自动化模型选择算法用于表格数据

    Automated Model Selection for Tabular Data. (arXiv:2401.00961v1 [cs.LG])

    [http://arxiv.org/abs/2401.00961](http://arxiv.org/abs/2401.00961)

    本文介绍了一种自动化模型选择算法，用于表格数据的预测。该算法考虑了特征之间的交互，并包含了基于优先级的随机网格搜索和贪婪搜索两种不同的特征选择方法。

    

    表格数据中的结构化数据包含独特且离散的特征，并且这些特征对目标的重要性各不相同。单个特征的组合可能比简单的单个特征贡献更具预测性和意义。R的混合效应线性模型库允许用户在模型设计中提供这种交互式特征组合。然而，鉴于有许多特征和可能的交互选择，模型选择变得非常困难。我们的目标是通过保持计算成本较小，自动化表格数据预测中的模型选择过程，并同时考虑特征之间的交互。该框架包括两种不同的特征选择方法：基于优先级的随机网格搜索和贪婪搜索方法。基于优先级的方法利用先验概率来引导搜索，高效地探索特征组合。贪婪方法通过迭代地添加特征构建解决方案。

    Structured data in the form of tabular datasets contain features that are distinct and discrete, with varying individual and relative importances to the target. Combinations of one or more features may be more predictive and meaningful than simple individual feature contributions. R's mixed effect linear models library allows users to provide such interactive feature combinations in the model design. However, given many features and possible interactions to select from, model selection becomes an exponentially difficult task. We aim to automate the model selection process for predictions on tabular datasets incorporating feature interactions while keeping computational costs small. The framework includes two distinct approaches for feature selection: a Priority-based Random Grid Search and a Greedy Search method. The Priority-based approach efficiently explores feature combinations using prior probabilities to guide the search. The Greedy method builds the solution iteratively by addin
    
[^47]: 准确的变形DETR和多级特征融合用于辅助血液疾病诊断的白细胞检测

    Accurate Leukocyte Detection Based on Deformable-DETR and Multi-Level Feature Fusion for Aiding Diagnosis of Blood Diseases. (arXiv:2401.00926v1 [cs.CV])

    [http://arxiv.org/abs/2401.00926](http://arxiv.org/abs/2401.00926)

    本文提出了一种创新的白细胞检测方法，使用多级特征融合和变形自注意DETR，通过解决白细胞尺度差异问题和提高检测精度，以改善传统血液检测的效率和准确性。

    

    在标准医院血液检测中，传统的方法需要医生使用显微镜从患者的血液显微图像中手动分离白细胞。然后通过自动白细胞分类器对这些分离的白细胞进行分类，以确定血样中不同类型白细胞的比例和体积，从而协助疾病诊断。这种方法不仅耗时、耗力，而且容易出现错误，因为图像质量和环境条件等因素，可能导致后续分类错误和误诊。为了解决这些问题，本文提出了一种创新的白细胞检测方法：多级特征融合和变形自注意DETR（MFDS-DETR）。为了解决白细胞尺度差异的问题，我们设计了高级筛选特征融合金字塔（HS-FPN），实现了多级融合。该模型使用高级特征作为特征融合的输入，同时采用变形自注意DETR实现精确的白细胞检测。

    In standard hospital blood tests, the traditional process requires doctors to manually isolate leukocytes from microscopic images of patients' blood using microscopes. These isolated leukocytes are then categorized via automatic leukocyte classifiers to determine the proportion and volume of different types of leukocytes present in the blood samples, aiding disease diagnosis. This methodology is not only time-consuming and labor-intensive, but it also has a high propensity for errors due to factors such as image quality and environmental conditions, which could potentially lead to incorrect subsequent classifications and misdiagnosis. To address these issues, this paper proposes an innovative method of leukocyte detection: the Multi-level Feature Fusion and Deformable Self-attention DETR (MFDS-DETR). To tackle the issue of leukocyte scale disparity, we designed the High-level Screening-feature Fusion Pyramid (HS-FPN), enabling multi-level fusion. This model uses high-level features as 
    
[^48]: 使用深度强化学习在混沌系统中进行数据同化

    Data Assimilation in Chaotic Systems Using Deep Reinforcement Learning. (arXiv:2401.00916v1 [math.DS])

    [http://arxiv.org/abs/2401.00916](http://arxiv.org/abs/2401.00916)

    本文介绍了一种使用强化学习在混沌系统中进行数据同化的新策略。该方法通过使用完整或部分观测的状态变量进行状态校正，旨在最小化观测和预测状态之间的误差。

    

    数据同化在各种应用中起着关键作用，从气候预测和天气预报到自主车辆的轨迹规划。一个典型的例子是广泛使用的集合卡尔曼滤波器（EnKF），它依赖于线性更新来最小化预测状态集合的方差。最近的进展在这个领域中看到了深度学习方法的出现，主要是在有监督学习框架内。然而，这些模型在未经训练的情况下的适应性仍然是一个挑战。在本研究中，我们引入了一种新的数据同化策略，利用强化学习（RL）来使用完整或部分观测的状态变量进行状态校正。我们的研究重点是在混沌的Lorenz '63系统上展示这种方法，其中代理的目标是将观测和相应的预测状态之间的均方根误差最小化。因此，代理开发出了一种校正策略。

    Data assimilation (DA) plays a pivotal role in diverse applications, ranging from climate predictions and weather forecasts to trajectory planning for autonomous vehicles. A prime example is the widely used ensemble Kalman filter (EnKF), which relies on linear updates to minimize variance among the ensemble of forecast states. Recent advancements have seen the emergence of deep learning approaches in this domain, primarily within a supervised learning framework. However, the adaptability of such models to untrained scenarios remains a challenge. In this study, we introduce a novel DA strategy that utilizes reinforcement learning (RL) to apply state corrections using full or partial observations of the state variables. Our investigation focuses on demonstrating this approach to the chaotic Lorenz '63 system, where the agent's objective is to minimize the root-mean-squared error between the observations and corresponding forecast states. Consequently, the agent develops a correction stra
    
[^49]: LaFFi: 利用混合自然语言反馈来优化语言模型的微调

    LaFFi: Leveraging Hybrid Natural Language Feedback for Fine-tuning Language Models. (arXiv:2401.00907v1 [cs.LG])

    [http://arxiv.org/abs/2401.00907](http://arxiv.org/abs/2401.00907)

    LaFFi是一种用于微调语言模型的替代方法，通过要求模型预测标注者将会给出的反馈，显著提高了在问答任务中的准确性，为应用自然语言反馈提供了一个有前途的方向。

    

    大型语言模型（LLM）的微调可以将训练好的模型适应特定的下游任务，并显著提高任务特定性能。监督微调（SFT）是一种常见的方法，其中LLM被训练成产生期望的答案。然而，使用SFT训练的LLM在推理任务（如问答）中有时会出现简单错误和幻觉。在没有外部反馈的情况下，SFT很难学习到问题和期望答案之间的良好映射，特别是在数据集较小的情况下。本文介绍了一种名为自然语言反馈微调LLM（LaFFi）的替代方法。LaFFi要求LLM直接预测标注者将会给出的反馈。我们发现，这样的反思要求可以显著提高在领域内问答任务中的准确性，为在SFT LLM领域中应用自然语言反馈提供了一个有前途的方向。额外的消融研究表明这种方法的一部分可以被替代。

    Fine-tuning Large Language Models (LLMs) adapts a trained model to specific downstream tasks, significantly improving task-specific performance. Supervised Fine-Tuning (SFT) is a common approach, where an LLM is trained to produce desired answers. However, LLMs trained with SFT sometimes make simple mistakes and result in hallucinations on reasoning tasks such as question-answering. Without external feedback, it is difficult for SFT to learn a good mapping between the question and the desired answer, especially with a small dataset. This paper introduces an alternative to SFT called Natural Language Feedback for Finetuning LLMs (LaFFi). LaFFi has LLMs directly predict the feedback they will receive from an annotator. We find that requiring such reflection can significantly improve the accuracy in in-domain question-answering tasks, providing a promising direction for the application of natural language feedback in the realm of SFT LLMs. Additional ablation studies show that the portion
    
[^50]: 自监督视觉学习中的蒙面建模

    Masked Modeling for Self-supervised Representation Learning on Vision and Beyond. (arXiv:2401.00897v1 [cs.CV])

    [http://arxiv.org/abs/2401.00897](http://arxiv.org/abs/2401.00897)

    蒙面建模是一种自监督学习方法，通过预测被蒙面部分实现深度模型学习稳健的表示，已在计算机视觉和自然语言处理等领域展现出卓越性能。

    

    随着深度学习的革命不断向前，自监督学习因其出色的表示学习能力和对标注数据的低依赖性而受到越来越多的关注。在这些多样的自监督技术中，蒙面建模已经成为一种独特的方法，其中在训练过程中相应比例的原始数据会被蒙面，模型需要预测出这些蒙面的部分。这种范式使深度模型能够学习到稳健的表示，并在计算机视觉、自然语言处理和其他领域展示出了出色的性能。在本调查中，我们对蒙面建模框架及其方法进行了全面的回顾，详细介绍了蒙面建模中的技术细节，包括多样的蒙面策略、恢复目标、网络架构等。然后，我们系统地调查了它在各个领域中的广泛应用。此外，我们还探讨了其共性。

    As the deep learning revolution marches on, self-supervised learning has garnered increasing attention in recent years thanks to its remarkable representation learning ability and the low dependence on labeled data. Among these varied self-supervised techniques, masked modeling has emerged as a distinctive approach that involves predicting parts of the original data that are proportionally masked during training. This paradigm enables deep models to learn robust representations and has demonstrated exceptional performance in the context of computer vision, natural language processing, and other modalities. In this survey, we present a comprehensive review of the masked modeling framework and its methodology. We elaborate on the details of techniques within masked modeling, including diverse masking strategies, recovering targets, network architectures, and more. Then, we systematically investigate its wide-ranging applications across domains. Furthermore, we also explore the commonalit
    
[^51]: Social-LLM: 使用语言模型和社交网络数据对规模化用户行为进行建模

    Social-LLM: Modeling User Behavior at Scale using Language Models and Social Network Data. (arXiv:2401.00893v1 [cs.SI])

    [http://arxiv.org/abs/2401.00893](http://arxiv.org/abs/2401.00893)

    Social-LLM使用语言模型和社交网络数据，通过结合本地化社交网络互动和大型语言模型的能力，解决了在大规模社交网络数据建模中的计算挑战，实现了对用户行为的规模化建模。基于社交网络同质性的前提，该方法能够在用户检测任务中发挥重要作用。

    

    社交网络数据的大量增加为对人类行为进行广泛的数据驱动探索提供了前所未有的机会。社交网络的结构复杂性为各种计算社会科学问题提供了洞察力，特别是社交影响和信息传播方面。然而，对大规模社交网络数据进行建模面临着计算挑战。尽管大型语言模型使得对文本内容进行建模变得更加容易，但任何先进的网络表示方法都难以在可扩展性和高效部署到未知用户的问题上满足要求。为此，我们提出了一种针对用户检测任务中社交网络数据建模的新方法。这种创新方法将本地化社交网络互动与大型语言模型的能力相结合。基于社交网络同质性的前提，即社交连接的用户具有相似性，我们的方法旨在解决这些挑战。

    The proliferation of social network data has unlocked unprecedented opportunities for extensive, data-driven exploration of human behavior. The structural intricacies of social networks offer insights into various computational social science issues, particularly concerning social influence and information diffusion. However, modeling large-scale social network data comes with computational challenges. Though large language models make it easier than ever to model textual content, any advanced network representation methods struggle with scalability and efficient deployment to out-of-sample users. In response, we introduce a novel approach tailored for modeling social network data in user detection tasks. This innovative method integrates localized social network interactions with the capabilities of large language models. Operating under the premise of social network homophily, which posits that socially connected users share similarities, our approach is designed to address these cha
    
[^52]: 使用自动编码器自动化白血病诊断：一项比较研究

    Automating Leukemia Diagnosis with Autoencoders: A Comparative Study. (arXiv:2401.00883v1 [cs.LG])

    [http://arxiv.org/abs/2401.00883](http://arxiv.org/abs/2401.00883)

    本研究使用自动编码器开发出有价值的特征，提高了白血病诊断的准确性，并相较于传统的机器学习模型在精确度和F1-score指标上表现更好。

    

    白血病是威胁人类生命的最常见和致命的癌症之一。来自患者关键参数的医疗数据中隐藏着宝贵的信息。在这个课题上，深度学习可以用来提取这些信息。本文使用自动编码器开发了有价值的特征，以帮助提高白血病诊断的准确性。我们尝试找到最佳的激活函数和优化器来在自动编码器中使用，并设计了最佳的神经网络结构。我们提出的架构与该领域的经典机器学习模型进行了比较。我们的方法在精确度和F1-score指标上比其他机器学习模型提升了超过11%。

    Leukemia is one of the most common and death-threatening types of cancer that threaten human life. Medical data from some of the patient's critical parameters contain valuable information hidden among these data. On this subject, deep learning can be used to extract this information. In this paper, AutoEncoders have been used to develop valuable features to help the precision of leukemia diagnosis. It has been attempted to get the best activation function and optimizer to use in AutoEncoder and designed the best architecture for this neural network. The proposed architecture is compared with this area's classical machine learning models. Our proposed method performs better than other machine learning in precision and f1-score metrics by more than 11%.
    
[^53]: 为弥合机器人高级推理和执行之间的差距而努力

    Towards Bridging the Gap between High-Level Reasoning and Execution on Robots. (arXiv:2401.00880v1 [cs.AI])

    [http://arxiv.org/abs/2401.00880](http://arxiv.org/abs/2401.00880)

    本论文提出了几种方法来解决机器人领域高级推理和执行之间的差距问题。

    

    当进行动作推理时，例如通过任务规划或使用Golog进行代理编程时，通常会将机器人的动作建模为抽象层次，其中复杂的动作（如拾取物体）被视为具有确定性效果和仅依赖于当前状态的前提条件的原子基元。然而，当在机器人上执行此类动作时，它不再可以被视为原子基元。相反，动作执行是一个复杂的任务，涉及多个步骤，具有额外的时间前提条件和时间约束。此外，动作可能会产生噪声，例如产生错误的感知结果，并且不能总是达到期望的效果。尽管在推理任务中通常忽略这些方面，但在执行过程中需要处理它们。在这篇论文中，我们提出了几种方法来弥合这一差距。

    When reasoning about actions, e.g., by means of task planning or agent programming with Golog, the robot's actions are typically modeled on an abstract level, where complex actions such as picking up an object are treated as atomic primitives with deterministic effects and preconditions that only depend on the current state. However, when executing such an action on a robot it can no longer be seen as a primitive. Instead, action execution is a complex task involving multiple steps with additional temporal preconditions and timing constraints. Furthermore, the action may be noisy, e.g., producing erroneous sensing results and not always having the desired effects. While these aspects are typically ignored in reasoning tasks, they need to be dealt with during execution. In this thesis, we propose several approaches towards closing this gap.
    
[^54]: 平衡的图结构信息用于脑疾病检测

    Balanced Graph Structure Information for Brain Disease Detection. (arXiv:2401.00876v1 [cs.LG])

    [http://arxiv.org/abs/2401.00876](http://arxiv.org/abs/2401.00876)

    这项工作提出了一种名为Bargrain的平衡脑图结构方法，通过同时模拟经过滤波的相关矩阵和最优样本图来改进脑疾病检测性能，并解决了仅依赖单一类型结构的限制。

    

    分析脑区间的连接对于检测自闭症或精神分裂等神经系统疾病至关重要。最近的研究采用图神经网络(GNNs)来利用脑中的图结构，提高检测性能。目前的方法使用ROI的血氧水平依赖性(BOLD)信号之间的相关性来生成图结构。其他方法通过端到端学习使用训练样本来学习最优的图结构。然而，独立实施这些方法会导致相关性图中的噪音数据问题以及最优图的过拟合问题。在这项工作中，我们提出了Bargrain(平衡的脑图结构)，它模拟了两种图结构：经过滤波的相关矩阵和使用图卷积网络(GCNs)生成的最优样本图。这种方法旨在充分利用两种图的优点，并解决仅依赖单一类型结构的局限性。

    Analyzing connections between brain regions of interest (ROI) is vital to detect neurological disorders such as autism or schizophrenia. Recent advancements employ graph neural networks (GNNs) to utilize graph structures in brains, improving detection performances. Current methods use correlation measures between ROI's blood-oxygen-level-dependent (BOLD) signals to generate the graph structure. Other methods use the training samples to learn the optimal graph structure through end-to-end learning. However, implementing those methods independently leads to some issues with noisy data for the correlation graphs and overfitting problems for the optimal graph. In this work, we proposed Bargrain (balanced graph structure for brains), which models two graph structures: filtered correlation matrix and optimal sample graph using graph convolution networks (GCNs). This approach aims to get advantages from both graphs and address the limitations of only relying on a single type of structure. Bas
    
[^55]: 教导大型语言模型忘记隐私

    Teach Large Language Models to Forget Privacy. (arXiv:2401.00870v1 [cs.CR])

    [http://arxiv.org/abs/2401.00870](http://arxiv.org/abs/2401.00870)

    这项研究提出了Prompt2Forget（P2F）框架，通过教导大型语言模型（LLM）忘记隐私信息，解决了LLM本地隐私挑战。P2F方法将问题分解为片段并生成虚构答案，模糊化模型对原始输入的记忆。实验证明，P2F具有很强的模糊化能力，并且可以在各种应用场景下自适应使用，无需手动设置。

    

    大型语言模型（LLM）已被证明具有强大的能力，但隐私泄露的风险仍然是一个重要问题。传统的保护隐私方法，如差分隐私和同态加密，在只有黑盒API的环境下是不足够的，要求模型透明性或大量计算资源。我们提出了Prompt2Forget（P2F），这是第一个设计用于解决LLM本地隐私挑战的框架，通过教导LLM忘记来实现。该方法涉及将完整问题分解为较小的片段，生成虚构的答案，并使模型对原始输入的记忆模糊化。我们根据不同领域的包含隐私敏感信息的问题创建了基准数据集。P2F实现了零-shot泛化，可以在多种应用场景下自适应，无需手动调整。实验结果表明，P2F具有很强的模糊化LLM记忆的能力，而不会损失任何实用性。

    Large Language Models (LLMs) have proven powerful, but the risk of privacy leakage remains a significant concern. Traditional privacy-preserving methods, such as Differential Privacy and Homomorphic Encryption, are inadequate for black-box API-only settings, demanding either model transparency or heavy computational resources. We propose Prompt2Forget (P2F), the first framework designed to tackle the LLM local privacy challenge by teaching LLM to forget. The method involves decomposing full questions into smaller segments, generating fabricated answers, and obfuscating the model's memory of the original input. A benchmark dataset was crafted with questions containing privacy-sensitive information from diverse fields. P2F achieves zero-shot generalization, allowing adaptability across a wide range of use cases without manual adjustments. Experimental results indicate P2F's robust capability to obfuscate LLM's memory, attaining a forgetfulness score of around 90\% without any utility los
    
[^56]: 张量网络在可解释的机器学习中在网络安全中的应用

    Tensor Networks for Explainable Machine Learning in Cybersecurity. (arXiv:2401.00867v1 [cs.LG])

    [http://arxiv.org/abs/2401.00867](http://arxiv.org/abs/2401.00867)

    张量网络可以帮助发展可解释的机器学习算法，并提供丰富的模型可解释性。在网络安全中，我们的无监督聚类算法基于矩阵乘积状态，在性能上与传统的深度学习模型相媲美。我们的方法还能提取特征概率、熵和互信息，提供了分类异常的引人入胜的叙述，并实现了前所未有的透明度和可解释性水平。

    

    本文展示了张量网络如何帮助发展可解释的机器学习算法。具体而言，我们基于矩阵乘积状态（MPS）开发了一种无监督聚类算法，并将其应用于实际使用案例中的对手生成的威胁情报。我们的研究证明，MPS在性能方面可以与传统的深度学习模型如自编码器和生成对抗网络相媲美，同时提供更丰富的模型可解释性。我们的方法自然地促进了特征概率、冯·诺伊曼熵和互信息的提取，为异常分类提供了引人入胜的叙述，并促进了前所未有的透明度和可解释性水平，这对于理解人工智能决策的基本原理至关重要。

    In this paper we show how tensor networks help in developing explainability of machine learning algorithms. Specifically, we develop an unsupervised clustering algorithm based on Matrix Product States (MPS) and apply it in the context of a real use-case of adversary-generated threat intelligence. Our investigation proves that MPS rival traditional deep learning models such as autoencoders and GANs in terms of performance, while providing much richer model interpretability. Our approach naturally facilitates the extraction of feature-wise probabilities, Von Neumann Entropy, and mutual information, offering a compelling narrative for classification of anomalies and fostering an unprecedented level of transparency and interpretability, something fundamental to understand the rationale behind artificial intelligence decisions.
    
[^57]: 火燃科学中使用基础模型的可靠知识处理框架

    A Reliable Knowledge Processing Framework for Combustion Science using Foundation Models. (arXiv:2401.00544v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2401.00544](http://arxiv.org/abs/2401.00544)

    本研究介绍了一种可靠的知识处理框架，将大型语言模型整合到燃烧科学中。该框架通过使用基础模型和RAG框架，处理多样化的燃烧研究数据，最大限度地减少计算和经济开销，同时优化数据隐私和准确性。

    

    本研究探讨将大型语言模型（LLMs）整合到科学数据融合中，以燃烧科学为案例研究。通过整合基础模型与检索增强生成（RAG）框架，本研究介绍了一种处理多样化燃烧研究数据的方法，涵盖实验研究、模拟和文献等方面。燃烧研究的多方面性强调了知识处理在从丰富的、多样化的信息来源中导航和提取有价值信息中的关键作用。所开发的方法在优化数据隐私和准确性的同时，最大限度地减少了计算和经济开销。它包括提示工程和离线开源LLMs，为用户选择基础模型提供了自主性。本研究对文本分割策略进行了全面的研究，进行了LLMs之间的比较研究，并探索了各种优化的提示方式，以证明其有效性。

    This research explores the integration of large language models (LLMs) into scientific data assimilation, focusing on combustion science as a case study. Leveraging foundational models integrated with Retrieval-Augmented Generation (RAG) framework, the study introduces an approach to process diverse combustion research data, spanning experimental studies, simulations, and literature. The multifaceted nature of combustion research emphasizes the critical role of knowledge processing in navigating and extracting valuable information from a vast and diverse pool of sources. The developed approach minimizes computational and economic expenses while optimizing data privacy and accuracy. It incorporates prompt engineering and offline open-source LLMs, offering user autonomy in selecting base models. The study provides a thorough examination of text segmentation strategies, conducts comparative studies between LLMs, and explores various optimized prompts to demonstrate the effectiveness of th
    
[^58]: 迈向NextG协议形式验证的自动建模：一种多模态交叉和自注意力的大语言模型方法

    Towards Auto-Modeling of Formal Verification for NextG Protocols: A Multimodal cross- and self-attention Large Language Model Approach. (arXiv:2312.17353v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2312.17353](http://arxiv.org/abs/2312.17353)

    AVRE是一种用于形式验证NextG通信协议的自动建模系统，利用大型语言模型转化协议描述为依赖图和形式模型，并通过交叉和自注意力机制建立可量化的依赖关系，进而提高了复杂通信协议的验证准确性和相关性。

    

    本文介绍了Auto-modeling of Formal Verification with Real-world Prompting for 5G and NextG protocols（AVRE），这是一种新颖的系统，设计用于形式验证Next Generation（NextG）通信协议，解决了网络协议设计和验证中日益复杂和可扩展性挑战。利用大型语言模型（LLM），AVRE将协议描述转化为依赖图和形式模型，高效地解决了歧义问题并捕捉设计意图。系统通过交叉和自注意力机制，将变压器模型与LLM集成，自主建立可量化的依赖关系。经过HyFuzz实验平台的迭代反馈，AVRE显著提高了复杂通信协议正式验证的准确性和相关性，为验证复杂的通信系统提供了一种突破性的方法。我们将CAL的性能与最先进的LL进行了比较。

    This paper introduces Auto-modeling of Formal Verification with Real-world Prompting for 5G and NextG protocols (AVRE), a novel system designed for the formal verification of Next Generation (NextG) communication protocols, addressing the increasing complexity and scalability challenges in network protocol design and verification. Utilizing Large Language Models (LLMs), AVRE transforms protocol descriptions into dependency graphs and formal models, efficiently resolving ambiguities and capturing design intent. The system integrates a transformer model with LLMs to autonomously establish quantifiable dependency relationships through cross- and self-attention mechanisms. Enhanced by iterative feedback from the HyFuzz experimental platform, AVRE significantly advances the accuracy and relevance of formal verification in complex communication protocols, offering a groundbreaking approach to validating sophisticated communication systems. We compare CAL's performance with state-of-the-art L
    
[^59]: 混合内模：通过模拟机器人响应学习敏捷腿部运动

    Hybrid Internal Model: Learning Agile Legged Locomotion with Simulated Robot Response. (arXiv:2312.11460v3 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2312.11460](http://arxiv.org/abs/2312.11460)

    本论文提出了一种混合内模方法，通过模拟机器人的响应来估计外部状态，这对于健壮的运动控制非常重要。使用对比学习优化嵌入表示，使其接近机器人的后继状态。这种方法只需要机器人的固有感知。

    

    健壮的运动控制依赖于准确的状态估计。然而，大多数四足机器人的传感器只能提供部分和嘈杂的观测，使得估计特别具有挑战性，特别是对于外部状态，如地形摩擦和高程图。受经典的内模控制原理的启发，我们将这些外部状态视为干扰，并引入混合内模（HIM）来根据机器人的响应来估计它们。我们将响应称为混合内嵌表示，它包含了机器人的显式速度和隐式稳定性表示，分别对应于运动任务的两个主要目标：显式追踪速度和隐式维持稳定性。我们使用对比学习来优化嵌入式表示，使其接近机器人的后继状态，其中自然嵌入了响应。HIM具有几个吸引人的好处：它只需要机器人的固有感知，即关节感知。

    Robust locomotion control depends on accurate state estimations. However, the sensors of most legged robots can only provide partial and noisy observations, making the estimation particularly challenging, especially for external states like terrain frictions and elevation maps. Inspired by the classical Internal Model Control principle, we consider these external states as disturbances and introduce Hybrid Internal Model (HIM) to estimate them according to the response of the robot. The response, which we refer to as the hybrid internal embedding, contains the robot's explicit velocity and implicit stability representation, corresponding to two primary goals for locomotion tasks: explicitly tracking velocity and implicitly maintaining stability. We use contrastive learning to optimize the embedding to be close to the robot's successor state, in which the response is naturally embedded. HIM has several appealing benefits: It only needs the robot's proprioceptions, i.e., those from joint
    
[^60]: 全局特征金字塔网络

    Global Feature Pyramid Network. (arXiv:2312.11231v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2312.11231](http://arxiv.org/abs/2312.11231)

    全局特征金字塔网络 (GFPNet) 是一个增强版本的 PAFPN，通过整合全局信息来增强目标检测任务。通过捕获全局特征信息，并利用VNC编码器处理这些特征，GFPNet具有显着的优势，可以减少误检和漏检。

    

    视觉特征金字塔在目标检测任务中证明了其有效性和效率。然而，当前的方法往往过分强调层间特征交互，忽视了层内特征调整的重要方面。经验表明，层内特征交互在增强目标检测任务方面具有显着的优势。虽然一些方法尝试使用注意机制或视觉变换器学习压缩的层内特征表示，但却忽视了全局信息交互的整合。这个疏忽导致了误检和漏检的增加。为了解决这个关键问题，本文引入了全局特征金字塔网络（GFPNet），它是PAFPN的增强版本，通过整合全局信息来增强目标检测。具体来说，我们利用轻量级MLP来捕获全局特征信息，利用VNC编码器处理这些特征，并使用并行lea

    The visual feature pyramid has proven its effectiveness and efficiency in target detection tasks. Yet, current methodologies tend to overly emphasize inter-layer feature interaction, neglecting the crucial aspect of intra-layer feature adjustment. Experience underscores the significant advantages of intra-layer feature interaction in enhancing target detection tasks. While some approaches endeavor to learn condensed intra-layer feature representations using attention mechanisms or visual transformers, they overlook the incorporation of global information interaction. This oversight results in increased false detections and missed targets.To address this critical issue, this paper introduces the Global Feature Pyramid Network (GFPNet), an augmented version of PAFPN that integrates global information for enhanced target detection. Specifically, we leverage a lightweight MLP to capture global feature information, utilize the VNC encoder to process these features, and employ a parallel lea
    
[^61]: MusER：基于音乐元素的正则化方法用于产生具有情感的符号音乐

    MusER: Musical Element-Based Regularization for Generating Symbolic Music with Emotion. (arXiv:2312.10307v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2312.10307](http://arxiv.org/abs/2312.10307)

    本论文提出了一种名为MusER的音乐生成模型，通过引入基于音乐元素的正则化处理，实现了对不同音乐元素在情感中的作用的剖析，并进一步操纵元素来改变音乐的情感。这项研究填补了现有研究对情感音乐生成中音乐元素贡献的不足，并为细粒度的情感控制提供了新的方法。

    

    产生具有情感的音乐是自动音乐生成中的一个重要任务，情感通过各种随时间变化并相互协作的音乐元素（如音高和持续时间）来唤起。然而，以往基于深度学习的情感音乐生成研究很少探索不同音乐元素对情感的贡献，更不用说有意识地操纵这些元素来改变音乐的情感了，这不利于对情感进行细粒度的元素级控制。为了填补这一空白，我们提出了一种新颖的方法，采用基于音乐元素的正则化处理在潜变量空间中解耦不同的元素，探究它们在区分情感中的作用，并进一步操纵元素来改变音乐的情感。具体而言，我们提出了一种名为MusER的基于VQ-VAE的模型。MusER在模型中引入了正则化损失，来约束音乐元素序列与特定情感之间的对应关系。

    Generating music with emotion is an important task in automatic music generation, in which emotion is evoked through a variety of musical elements (such as pitch and duration) that change over time and collaborate with each other. However, prior research on deep learning-based emotional music generation has rarely explored the contribution of different musical elements to emotions, let alone the deliberate manipulation of these elements to alter the emotion of music, which is not conducive to fine-grained element-level control over emotions. To address this gap, we present a novel approach employing musical element-based regularization in the latent space to disentangle distinct elements, investigate their roles in distinguishing emotions, and further manipulate elements to alter musical emotions. Specifically, we propose a novel VQ-VAE-based model named MusER. MusER incorporates a regularization loss to enforce the correspondence between the musical element sequences and the specific 
    
[^62]: 单一GPU上的数据高效多模态融合

    Data-Efficient Multimodal Fusion on a Single GPU. (arXiv:2312.10144v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2312.10144](http://arxiv.org/abs/2312.10144)

    本论文提出了一种在单一GPU上进行数据高效多模态融合的方法，通过使用预训练的单模态编码器的潜在空间，我们在多模态对齐中取得了有竞争力的性能，且计算和数据量减少了数个数量级。

    

    多模态对齐的目标是学习共享多模态输入之间的单一潜在空间。在这个领域中，最强大的模型通常是使用大规模数据集和大规模计算资源进行训练的，因此在许多实际场景中训练这些模型的成本非常高昂。我们推测，现有的在大量单模态数据上预训练的单模态编码器应该能够以更低的成本从单模态模型中创建多模态模型。因此，我们提出了FuseMix，一种多模态增强方案，该方案在任意预训练的单模态编码器的潜在空间中操作。通过使用FuseMix进行多模态对齐，我们在图像-文本和音频-文本检索任务中取得了有竞争力的性能，并在某些情况下超越了最先进的方法，而计算和数据量减少了数个数量级：例如，我们在Flickr30K的文本-图像检索任务中比CLIP的性能提高了约600倍，而计算和数据量减少了数个数量级。

    The goal of multimodal alignment is to learn a single latent space that is shared between multimodal inputs. The most powerful models in this space have been trained using massive datasets of paired inputs and large-scale computational resources, making them prohibitively expensive to train in many practical scenarios. We surmise that existing unimodal encoders pre-trained on large amounts of unimodal data should provide an effective bootstrap to create multimodal models from unimodal ones at much lower costs. We therefore propose FuseMix, a multimodal augmentation scheme that operates on the latent spaces of arbitrary pre-trained unimodal encoders. Using FuseMix for multimodal alignment, we achieve competitive performance -- and in certain cases outperform state-of-the art methods -- in both image-text and audio-text retrieval, with orders of magnitude less compute and data: for example, we outperform CLIP on the Flickr30K text-to-image retrieval task with $\sim \! 600\times$ fewer GP
    
[^63]: 理性情感：以自我展示理论为指导的增强型同理心回应生成的LLM方法

    Rational Sensibility: LLM Enhanced Empathetic Response Generation Guided by Self-presentation Theory. (arXiv:2312.08702v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2312.08702](http://arxiv.org/abs/2312.08702)

    本文通过以自我展示理论为指导，设计了一种创新的分类方法，将历史对话分成合理和理性的句子，并通过注意力机制来阐明上下文，从而增强同理心回应生成的能力。

    

    在对话中准确表达人类行为的能力对于同理心至关重要。尽管有许多研究致力于通过引入外部知识来改进模型的认知能力，但对于对话本身的理性表达和合理的表现方面，却受到了有限的关注，而这些是认知同理心的关键组成部分。在社会学中，我们借鉴了自我展示理论，设计了一种创新的分类方法，将历史对话分成合理和理性的句子，并通过设计的注意力机制来阐明上下文。然而，对话中的理性信息受到限制，并且先前方法中使用的外部知识存在语义矛盾和狭窄视野的限制。考虑到LLM在智能代理领域的卓越表现，我们采用LLaMA2-70b作为理性大脑来分析深远的逻辑信息。

    Having the ability to empathize is crucial for accurately representing human behavior during conversations. Despite numerous research aim to improve the cognitive capability of models by incorporating external knowledge, there has been limited attention on the sensible and rational expression of the conversation itself, which are crucial components of the cognitive empathy. Guided by self-presentation theory in sociology, we have designed an innovative categorical approach that segregates historical dialogues into sensible and rational sentences and subsequently elucidate the context through the designed attention mechanism. However, the rational information within the conversation is restricted and the external knowledge used in previous methods have limitations of semantic contradiction and narrow vision field. Considering the impressive performance of LLM in the domain of intelligent agent. We employ LLaMA2-70b as a rational brain to analyze the profound logical information maintain
    
[^64]: 基于视觉学习的无人机：一项调查

    Vision-based Learning for Drones: A Survey. (arXiv:2312.05019v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2312.05019](http://arxiv.org/abs/2312.05019)

    本文调查了基于视觉学习的无人机技术，指出其对无人机操作能力的关键作用，并提出了基于视觉学习的控制方法和各种应用的挑战与创新。

    

    作为先进的智能物理系统，无人机正在经历一次转型变革，采用基于视觉学习的技术，这个领域因其对无人机自主性和功能的深远影响而迅速崛起。不同于现有的特定任务调查，本文提供了一个全面概述了无人机中基于视觉学习的方法，强调其在各种场景下提高无人机操作能力中的关键作用。我们首先阐明了基于视觉学习的基本原理，突出了它如何显著提高无人机的视觉感知和决策过程。然后，从感知-控制的角度，我们将基于视觉的控制方法分为间接、半直接和端到端的方法。我们进一步探讨了具有视觉学习能力的无人机的各种应用，从单个智能体系统到更复杂的多智能体和异构系统的场景，并强调了挑战与创新。

    Drones as advanced cyber-physical systems are undergoing a transformative shift with the advent of vision-based learning, a field that is rapidly gaining prominence due to its profound impact on drone autonomy and functionality. Different from existing task-specific surveys, this review offers a comprehensive overview of vision-based learning in drones, emphasizing its pivotal role in enhancing their operational capabilities under various scenarios. We start by elucidating the fundamental principles of vision-based learning, highlighting how it significantly improves drones' visual perception and decision-making processes. We then categorize vision-based control methods into indirect, semi-direct, and end-to-end approaches from the perception-control perspective. We further explore various applications of vision-based drones with learning capabilities, ranging from single-agent systems to more complex multi-agent and heterogeneous system scenarios, and underscore the challenges and inn
    
[^65]: 关于上下文学习的校准研究

    A Study on the Calibration of In-context Learning. (arXiv:2312.04021v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2312.04021](http://arxiv.org/abs/2312.04021)

    本研究关注上下文学习（ICL），通过定制提示来调整静态语言模型（LMs），研究了在各种自然语言理解和推理任务中性能和校准之间的平衡。研究发现随着ICL示例数量的增加，模型的校准会先增加而后得到改善，而校准误差主要出现在低样本场景下。此外，微调和CoT提示等方法可能导致校准误差和不可靠的自然语言解释，提示需要针对可靠性场景开发新的方法。

    

    准确的不确定性量化对于语言模型（LMs）的安全部署至关重要，以前的研究已经证明了现代LMs校准性的改进。我们的研究重点是上下文学习（ICL），一种通过定制提示来调整静态LMs的常见方法，并研究在广泛的自然语言理解和推理任务中性能和校准之间的平衡。通过全面的实验，我们观察到，随着ICL示例数量的增加，模型最初会出现增加的校准误差，然后才能实现更好的校准，而校准误差往往在低样本场景下出现。此外，我们发现以提高可用性为目标的方法，如微调和CoT提示，可能导致校准误差和不可靠的自然语言解释，这表明在期望模型可靠性的场景中可能需要新的方法。

    Accurate uncertainty quantification is crucial for the safe deployment of language models (LMs), and prior research has demonstrated improvements in the calibration of modern LMs. Our study focuses on in-context learning (ICL), a prevalent method for adapting static LMs through tailored prompts, and examines the balance between performance and calibration across a broad spectrum of natural language understanding and reasoning tasks. Through comprehensive experiments, we observe that, with an increasing number of ICL examples, models initially exhibit increased miscalibration before achieving better calibration and miscalibration tends to arise in low-shot settings. Moreover, we find that methods aimed at improving usability, such as fine-tuning and chain-of-thought (CoT) prompting, can lead to miscalibration and unreliable natural language explanations, suggesting that new methods may be required for scenarios where models are expected to be reliable.
    
[^66]: Jina Embeddings 2: 面向长篇文档的8192-Token通用文本嵌入模型

    Jina Embeddings 2: 8192-Token General-Purpose Text Embeddings for Long Documents. (arXiv:2310.19923v1 [cs.CL])

    [http://arxiv.org/abs/2310.19923](http://arxiv.org/abs/2310.19923)

    Jina Embeddings 2是一个能够处理长篇文档的文本嵌入模型，突破了传统512个标记限制，提供了高达8192个标记的容量。

    

    文本嵌入模型已经成为将句子转化为固定大小特征向量的强大工具，这些向量包含了语义信息。尽管这些模型对于信息检索、语义聚类和文本重排序等任务至关重要，但大多数现有的开源模型，尤其是基于BERT等架构构建的模型，难以表示长篇文档，并且常常会进行截断。为了缓解这个挑战，一种常见的方法是将文档分割成更小的段落进行嵌入。然而，这种策略会导致更大的向量集合，进而增加内存消耗，并且在向量搜索时会出现计算密集和延迟升高的问题。为了解决这些挑战，我们介绍了Jina Embeddings 2，这是一个开源的文本嵌入模型，可以容纳高达8192个标记。该模型旨在突破传统的512个标记限制，能够灵活处理长篇文档。

    Text embedding models have emerged as powerful tools for transforming sentences into fixed-sized feature vectors that encapsulate semantic information. While these models are essential for tasks like information retrieval, semantic clustering, and text re-ranking, most existing open-source models, especially those built on architectures like BERT, struggle to represent lengthy documents and often resort to truncation. One common approach to mitigate this challenge involves splitting documents into smaller paragraphs for embedding. However, this strategy results in a much larger set of vectors, consequently leading to increased memory consumption and computationally intensive vector searches with elevated latency.  To address these challenges, we introduce Jina Embeddings 2, an open-source text embedding model capable of accommodating up to 8192 tokens. This model is designed to transcend the conventional 512-token limit and adeptly process long documents. Jina Embeddings 2 not only ach
    
[^67]: AI对齐: 一项全面调查

    AI Alignment: A Comprehensive Survey. (arXiv:2310.19852v1 [cs.AI])

    [http://arxiv.org/abs/2310.19852](http://arxiv.org/abs/2310.19852)

    本篇论文主要介绍了AI对齐的概念、方法和实践。研究围绕四个关键目标：健壮性、可解释性、可控性和道德性展开，并将其分为前向对齐和后向对齐两个部分。 AI对齐是为了构建符合人类意图和价值观的AI系统，并减轻由于系统不对齐带来的潜在风险。

    

    AI对齐旨在构建符合人类意图和价值观的AI系统。随着拥有超人类能力的AI系统的出现，错误对齐系统所带来的潜在大规模风险变得明显。数百名AI专家和公众人物都对AI风险表达了关注，认为减轻AI带来的灭绝风险应该成为全球的优先事项，与大规模社会风险如大流行病和核战争并列。鉴于AI对齐领域缺乏最新的系统调查，本文深入探讨对齐研究的核心概念、方法论和实践。首先，我们确定了四个目标原则作为AI对齐的关键目标：健壮性、可解释性、可控性和道德性（RICE）。我们概述了当前对齐研究的现状，并将其分解为两个关键组成部分：前向对齐和后向对齐。前者旨在使AI系统与人类意图对齐。

    AI alignment aims to build AI systems that are in accordance with human intentions and values. With the emergence of AI systems possessing superhuman capabilities, the potential large-scale risks associated with misaligned systems become apparent. Hundreds of AI experts and public figures have expressed their concerns about AI risks, arguing that mitigating the risk of extinction from AI should be a global priority, alongside other societal-scale risks such as pandemics and nuclear war. Motivated by the lack of an up-to-date systematic survey on AI alignment, in this paper, we delve into the core concepts, methodology, and practice of alignment research. To begin with, we identify four principles as the key objectives of AI alignment: Robustness, Interpretability, Controllability, and Ethicality (RICE). We outline the landscape of current alignment research and decompose them into two key components: forward alignment and backward alignment. The former aims to make AI systems aligned v
    
[^68]: 从挫折中获得智慧：通过错误分析对齐大型语言模型

    Gaining Wisdom from Setbacks: Aligning Large Language Models via Mistake Analysis. (arXiv:2310.10477v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.10477](http://arxiv.org/abs/2310.10477)

    该论文介绍了一种基于错误分析的对齐策略，通过暴露大型语言模型的错误输出并进行评估，以理解内部原因。通过这种方法，有毒回应可以转化为模型对齐的指导调谐语料，从而提高模型的安全性并训练其进行自我批评。

    

    大型语言模型（LLMs）的快速发展既带来了机遇，也带来了挑战，特别是在意外生成有害和有毒回应方面。传统的对齐方法致力于引导LLMs朝着期望的性能发展并保护它们免受恶意内容的侵害，而本研究提出了一种基于错误分析的全新对齐策略，通过有意暴露LLMs的缺陷输出并进行深入评估，以完全理解内部原因，通过自然语言分析。因此，有毒回应可以转化为模型对齐的指导调谐语料，LLMs不仅可以避免生成有缺陷的回应，还可以训练其进行自我批评，发挥其辨别有毒内容的内在能力。实验结果表明，所提出的方法在安全指令遵循方面优于传统的对齐技术，同时还保持了卓越的效率。

    The rapid advancement of large language models (LLMs) presents both opportunities and challenges, particularly concerning unintentional generation of harmful and toxic responses. While the traditional alignment methods strive to steer LLMs towards desired performance and shield them from malicious content, this study proposes a novel alignment strategy rooted in mistake analysis by exposing LLMs to flawed outputs purposefully and then conducting a thorough assessment to fully comprehend internal reasons via natural language analysis. Thus, toxic responses can be transformed into instruction tuning corpus for model alignment, and LLMs can not only be deterred from generating flawed responses but also trained to self-criticize, leveraging its innate ability to discriminate toxic content. Experimental results demonstrate that the proposed method outperforms conventional alignment techniques for safety instruction following, while maintaining superior efficiency.
    
[^69]: 深度学习年龄估计中的内容偏差：朝着更可解释性的新方法

    Content Bias in Deep Learning Age Approximation: A new Approach Towards more Explainability. (arXiv:2310.02067v1 [cs.CV])

    [http://arxiv.org/abs/2310.02067](http://arxiv.org/abs/2310.02067)

    本文提出了一种新的方法来评估深度学习年龄估计中的内容偏差，并验证了训练的神经网络依赖于图像内容。通过使用两种不同的技术减轻图像内容的影响，提出的方法具有潜在的对策效果。

    

    在时间图像取证的背景下，很难确定一个神经网络训练仅仅利用与年龄相关的特征。通常，时间相近的图像（例如属于同一年龄类别的）具有一些共同的内容属性。这种内容偏差可以被神经网络利用。本文提出了一种评估图像内容影响的新方法。该方法使用带有嵌入式年龄信号的合成图像进行验证，通过该方法表明，在年龄分类的上下文中训练的“标准”神经网络在很大程度上依赖于图像内容。作为潜在的对策，本文应用了两种不同的技术来减轻训练过程中图像内容的影响，并且通过所提出的方法进行了评估。

    In the context of temporal image forensics, it is not evident that a neural network, trained on images from different time-slots (classes), exploit solely age related features. Usually, images taken in close temporal proximity (e.g., belonging to the same age class) share some common content properties. Such content bias can be exploited by a neural network. In this work, a novel approach that evaluates the influence of image content is proposed. This approach is verified using synthetic images (where content bias can be ruled out) with an age signal embedded. Based on the proposed approach, it is shown that a `standard' neural network trained in the context of age classification is strongly dependent on image content. As a potential countermeasure, two different techniques are applied to mitigate the influence of the image content during training, and they are also evaluated by the proposed method.
    
[^70]: 多模态金融时间序列通过潜空间投影的检索

    Multi-Modal Financial Time-Series Retrieval Through Latent Space Projections. (arXiv:2309.16741v1 [cs.LG])

    [http://arxiv.org/abs/2309.16741](http://arxiv.org/abs/2309.16741)

    本文提出了一种通过深度编码器在低维潜空间中存储金融时间序列的多模态数据的框架，以捕捉数据的重要特征。

    

    金融公司通常处理和存储产生连续且高频的数十亿条时间序列数据。为了支持高效的数据存储和检索，出现了专门的时间序列数据库和系统。这些数据库支持通过类似于约束化结构化查询语言（SQL）的格式对时间序列进行索引和查询，以实现像“月度价格回报大于5%的股票”这样的查询，并以严格的格式表达。然而，这样的查询不能捕捉到高维时间序列数据的内在复杂性，它们往往可以通过图像或语言（例如“处于低波动性状态的股票”）更好地描述。而且，在时间序列空间中进行搜索所需的存储、计算时间和检索复杂度往往是非平凡的。在本文中，我们提出并演示了一种利用深度编码器在低维潜空间中存储金融时间序列的多模态数据的框架，使得潜空间投影可以捕捉到数据的重要特征。

    Financial firms commonly process and store billions of time-series data, generated continuously and at a high frequency. To support efficient data storage and retrieval, specialized time-series databases and systems have emerged. These databases support indexing and querying of time-series by a constrained Structured Query Language(SQL)-like format to enable queries like "Stocks with monthly price returns greater than 5%", and expressed in rigid formats. However, such queries do not capture the intrinsic complexity of high dimensional time-series data, which can often be better described by images or language (e.g., "A stock in low volatility regime"). Moreover, the required storage, computational time, and retrieval complexity to search in the time-series space are often non-trivial. In this paper, we propose and demonstrate a framework to store multi-modal data for financial time-series in a lower-dimensional latent space using deep encoders, such that the latent space projections ca
    
[^71]: 对抗性语音合成的协同水印技术

    Collaborative Watermarking for Adversarial Speech Synthesis. (arXiv:2309.15224v1 [eess.AS])

    [http://arxiv.org/abs/2309.15224](http://arxiv.org/abs/2309.15224)

    本文提出了一种对抗性语音合成的协同水印技术，通过与现有对策模型合作进行训练，实现了对生成语音的有效检测和水印识别。

    

    神经语音合成的进展使得技术不仅接近人类的自然度，而且能够以少量数据进行即时语音克隆，并且借助预训练模型具有高度可访问性。当然，生成内容的潜在泛滥引起了对合成语音检测和水印技术的需求。最近，合成语音检测的研究工作主要集中在自动说话人验证和欺骗对策挑战（ASVspoof）上，该挑战专注于被动对策。本文从另一角度出发，针对生成语音的检测，提出了一种协同训练方案，以在不干扰人类听众的情况下，能够通过协同机器检测到生成语音的水印。我们提出了一种与ASVspoof 2021基线对策模型合作的HiFi-GAN神经声码器的合作训练方案，并展示了其有效性。

    Advances in neural speech synthesis have brought us technology that is not only close to human naturalness, but is also capable of instant voice cloning with little data, and is highly accessible with pre-trained models available. Naturally, the potential flood of generated content raises the need for synthetic speech detection and watermarking. Recently, considerable research effort in synthetic speech detection has been related to the Automatic Speaker Verification and Spoofing Countermeasure Challenge (ASVspoof), which focuses on passive countermeasures. This paper takes a complementary view to generated speech detection: a synthesis system should make an active effort to watermark the generated speech in a way that aids detection by another machine, but remains transparent to a human listener. We propose a collaborative training scheme for synthetic speech watermarking and show that a HiFi-GAN neural vocoder collaborating with the ASVspoof 2021 baseline countermeasure models consis
    
[^72]: Era Splitting.（arXiv:2309.14496v1 [cs.LG]）

    Era Splitting. (arXiv:2309.14496v1 [cs.LG])

    [http://arxiv.org/abs/2309.14496](http://arxiv.org/abs/2309.14496)

    本研究提出了两种新的分裂准则，使得决策树模型能够利用时代信息进行优化，从而将超分布泛化研究中的思想应用于决策树模型。

    

    现实生活中的机器学习问题在时间和空间上会呈现出数据的分布变化。这种行为超出了传统的经验风险最小化范式的范围，该范式假设数据在时间和地点上是独立同分布的。新兴的超分布泛化领域通过将环境或时代信息融入算法中，来应对这个现实。迄今为止，大部分研究都集中在线性模型和/或神经网络上。在本研究中，我们针对决策树模型，包括随机森林和梯度提升决策树，开发了两种新的分裂准则，使得树模型能够利用与每个数据点相关的时代信息，来找到在数据的所有不相交时代中都是最优的切分点，从而将超分布泛化研究中的思想应用于决策树模型。

    Real life machine learning problems exhibit distributional shifts in the data from one time to another or from on place to another. This behavior is beyond the scope of the traditional empirical risk minimization paradigm, which assumes i.i.d. distribution of data over time and across locations. The emerging field of out-of-distribution (OOD) generalization addresses this reality with new theory and algorithms which incorporate environmental, or era-wise information into the algorithms. So far, most research has been focused on linear models and/or neural networks. In this research we develop two new splitting criteria for decision trees, which allow us to apply ideas from OOD generalization research to decision tree models, including random forest and gradient-boosting decision trees. The new splitting criteria use era-wise information associated with each data point to allow tree-based models to find split points that are optimal across all disjoint eras in the data, instead of optim
    
[^73]: 在医学图像中利用因果信号的研究：一项带有实证结果的试点研究

    Exploiting Causality Signals in Medical Images: A Pilot Study with Empirical Results. (arXiv:2309.10399v1 [cs.CV])

    [http://arxiv.org/abs/2309.10399](http://arxiv.org/abs/2309.10399)

    本研究提出了一种利用医学图像中的因果信号进行自动分类的新方法，通过模型化图像中一个部分特征的存在如何影响另一个部分特征的外观，改善了分类性能并产生了更稳健的预测，聚焦于图像中的相关部分。

    

    我们提出了一种新的方法，用于自动分类医学图像，该方法利用场景中的弱因果信号来建模图像中一个部分特征的存在如何影响另一个部分特征的外观。我们的方法由两个组成部分组成：卷积神经网络骨干和因果因子提取模块。后者计算特征图的权重，根据其对图像场景的因果影响增强每个特征图。我们可以通过使用两个外部信号来修改因果模块的功能，从而获得我们方法的不同变体。我们使用定量实验、定性评估和削弱实验在公开数据集上对前列腺MRI图像进行前列腺癌诊断评估。我们的结果表明，我们的方法改善了分类性能，并产生了更稳健的预测，聚焦于图像中的相关部分。这在医疗图像中尤为重要。

    We present a new method for automatically classifying medical images that uses weak causal signals in the scene to model how the presence of a feature in one part of the image affects the appearance of another feature in a different part of the image. Our method consists of two components: a convolutional neural network backbone and a causality-factors extractor module. The latter computes weights for the feature maps to enhance each feature map according to its causal influence in the image's scene. We can modify the functioning of the causality module by using two external signals, thus obtaining different variants of our method. We evaluate our method on a public dataset of prostate MRI images for prostate cancer diagnosis, using quantitative experiments, qualitative assessment, and ablation studies. Our results show that our method improves classification performance and produces more robust predictions, focusing on relevant parts of the image. That is especially important in medic
    
[^74]: 基于CLIP的文字化人物检索的协同知识传递

    CLIP-based Synergistic Knowledge Transfer for Text-based Person Retrieval. (arXiv:2309.09496v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2309.09496](http://arxiv.org/abs/2309.09496)

    本文提出了一种基于CLIP的文字化人物检索的协同知识传递（CSKT）方法，通过双向提示传递（BPT）和双适配器传递（DAT）实现了输入端和输出端的知识传递，并在三个基准数据集上取得了优于现有方法的性能。

    

    文字化人物检索（TPR）旨在根据文本查询检索目标人物图像。主要挑战在于弥合视觉和语言模态之间的巨大差距，特别是在处理有限的大规模数据集时。本文提出了一种基于CLIP的文字化人物检索的协同知识传递（CSKT）方法。具体而言，为了探索CLIP在输入端的知识，我们首先提出了一种由文本到图像和图像到文本的双向提示和耦合投影构建的双向提示传递（BPT）模块。其次，在视觉和语言的多头注意力（MHA）的输出端，设计了双适配器传递（DAT）以传递知识。这种协同的双向合作机制促进了早期特征融合，并有效地利用了CLIP的现有知识。当训练参数仅占7%时，CSKT在三个基准数据集上优于现有方法。

    Text-based Person Retrieval (TPR) aims to retrieve the target person images given a textual query. The primary challenge lies in bridging the substantial gap between vision and language modalities, especially when dealing with limited large-scale datasets. In this paper, we introduce a CLIP-based Synergistic Knowledge Transfer (CSKT) approach for TPR. Specifically, to explore the CLIP's knowledge on input side, we first propose a Bidirectional Prompts Transferring (BPT) module constructed by text-to-image and image-to-text bidirectional prompts and coupling projections. Secondly, Dual Adapters Transferring (DAT) is designed to transfer knowledge on output side of Multi-Head Attention (MHA) in vision and language. This synergistic two-way collaborative mechanism promotes the early-stage feature fusion and efficiently exploits the existing knowledge of CLIP. CSKT outperforms the state-of-the-art approaches across three benchmark datasets when the training parameters merely account for 7.
    
[^75]: SayCanPay: 使用可学习的领域知识，基于大型语言模型的启发式规划。

    SayCanPay: Heuristic Planning with Large Language Models using Learnable Domain Knowledge. (arXiv:2308.12682v1 [cs.AI])

    [http://arxiv.org/abs/2308.12682](http://arxiv.org/abs/2308.12682)

    SayCanPay是一种结合了大型语言模型(LLMs)和启发式规划的方法，通过利用LLMs的世界知识和启发式搜索的原则，生成可行的最优计划。

    

    大型语言模型(LLMs)通过其庞大的"世界知识"展示了令人印象深刻的规划能力。然而，尽管最近取得了一些进展，但获得既可行（基于可用性）又具有成本效益（计划长度方面）的计划仍然是一个挑战。这与启发式规划方法形成反差，启发式规划方法利用领域知识(在动作模型如PDDL中形式化)和启发式搜索来生成可行的最优计划。受此启发，我们提出了将LLMs的强大能力和启发式规划相结合的方法，利用LLMs的世界知识和启发式搜索的原则。我们的方法SayCanPay利用LLMs来生成由可学习的领域知识引导的动作(Say)，评估动作的可行性(Can)和长期回报/收益(Pay)，利用启发式搜索来选择最佳的动作序列。我们的贡献有(1)在启发式规划的背景下，对LLM规划问题进行了新颖的构建，(2)整合了可用性和成本效益。

    Large Language Models (LLMs) have demonstrated impressive planning abilities due to their vast "world knowledge". Yet, obtaining plans that are both feasible (grounded in affordances) and cost-effective (in plan length), remains a challenge, despite recent progress. This contrasts with heuristic planning methods that employ domain knowledge (formalized in action models such as PDDL) and heuristic search to generate feasible, optimal plans. Inspired by this, we propose to combine the power of LLMs and heuristic planning by leveraging the world knowledge of LLMs and the principles of heuristic search. Our approach, SayCanPay, employs LLMs to generate actions (Say) guided by learnable domain knowledge, that evaluates actions' feasibility (Can) and long-term reward/payoff (Pay), and heuristic search to select the best sequence of actions. Our contributions are (1) a novel framing of the LLM planning problem in the context of heuristic planning, (2) integrating grounding and cost-effective 
    
[^76]: 多模态大语言模型在预测语言处理期间表现出人类视觉-语言集成的证据

    Evidence of Human-Like Visual-Linguistic Integration in Multimodal Large Language Models During Predictive Language Processing. (arXiv:2308.06035v1 [cs.AI])

    [http://arxiv.org/abs/2308.06035](http://arxiv.org/abs/2308.06035)

    这篇论文研究了多模态大语言模型（mLLMs）在预测语言处理过程中与人类的视觉-语言集成能力是否一致的问题，并通过实验验证了mLLMs的多模态输入方法可以减少认知负荷，提高感知和理解能力。

    

    大语言模型（LLMs）的先进语言处理能力引发了关于它们是否能够复制人类认知过程的争议。LLMs和人类在语言处理方面的一个区别在于，语言输入通常建立在多个知觉模态上，而大多数LLMs仅处理基于文本的信息。多模态基础使人类能够整合视觉背景与语言信息，从而对即将出现的单词的空间施加限制，减少认知负荷，提高感知和理解能力。最近的多模态LLMs（mLLMs）结合了视觉和语言嵌入空间，并使用变压器类型的注意机制进行下一个单词的预测。在多大程度上，基于多模态输入的预测语言处理在mLLMs和人类中吻合？为了回答这个问题，200名被试观看了短的视听剪辑，并估计了即将出现的动词或名词的可预测性。

    The advanced language processing abilities of large language models (LLMs) have stimulated debate over their capacity to replicate human-like cognitive processes. One differentiating factor between language processing in LLMs and humans is that language input is often grounded in more than one perceptual modality, whereas most LLMs process solely text-based information. Multimodal grounding allows humans to integrate - e.g. visual context with linguistic information and thereby place constraints on the space of upcoming words, reducing cognitive load and improving perception and comprehension. Recent multimodal LLMs (mLLMs) combine visual and linguistic embedding spaces with a transformer type attention mechanism for next-word prediction. To what extent does predictive language processing based on multimodal input align in mLLMs and humans? To answer this question, 200 human participants watched short audio-visual clips and estimated the predictability of an upcoming verb or noun. The 
    
[^77]: 应对不同光照、遮挡和成熟度条件下的西红柿自主识别和分级的卷积变换器

    Convolutional Transformer for Autonomous Recognition and Grading of Tomatoes Under Various Lighting, Occlusion, and Ripeness Conditions. (arXiv:2307.01530v1 [cs.CV])

    [http://arxiv.org/abs/2307.01530](http://arxiv.org/abs/2307.01530)

    本研究引入了一种卷积变换器架构的框架，能够在不同光照、遮挡和成熟度条件下自主识别和分级西红柿。

    

    在实际环境中，用移动机器人采摘完全成熟的西红柿面临着诸多挑战。这些挑战来自于叶子和树枝造成的遮挡，以及在果实发育阶段，西红柿和周围植被之间的颜色相似性。自然环境的多样性进一步加剧了这些问题，包括不同的光照条件、视角、遮挡因素和不同的成熟度水平。为了克服这些障碍，本研究引入了一种新颖的框架，利用卷积变换器架构自主识别和分级西红柿，无论其遮挡水平、光照条件和成熟度如何。所提出的模型经过特别为此目的精心注释的图像进行训练和测试。数据集在不同的光照条件、视角和使用不同的移动相机传感器下准备，与现有的数据集（如Laboro）有所区别。

    Harvesting fully ripe tomatoes with mobile robots presents significant challenges in real-world scenarios. These challenges arise from factors such as occlusion caused by leaves and branches, as well as the color similarity between tomatoes and the surrounding foliage during the fruit development stage. The natural environment further compounds these issues with varying light conditions, viewing angles, occlusion factors, and different maturity levels. To overcome these obstacles, this research introduces a novel framework that leverages a convolutional transformer architecture to autonomously recognize and grade tomatoes, irrespective of their occlusion level, lighting conditions, and ripeness. The proposed model is trained and tested using carefully annotated images curated specifically for this purpose. The dataset is prepared under various lighting conditions, viewing perspectives, and employs different mobile camera sensors, distinguishing it from existing datasets such as Laboro 
    
[^78]: RS5M：用于遥感视觉-语言基础模型的大规模视觉-语言数据集

    RS5M: A Large Scale Vision-Language Dataset for Remote Sensing Vision-Language Foundation Model. (arXiv:2306.11300v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2306.11300](http://arxiv.org/abs/2306.11300)

    本文提出了一个新的框架RS5M，该框架包括领域基础模型（DFM），用于实现通用基础模型（GFM）和领域特定下游任务之间的转换。另外，还介绍了一个遥感领域的大规模图像-文本配对数据集RS5M，该数据集是通过过滤公开可用的图像-文本配对数据集并使用预训练的视觉-语言基础模型为标签数据集生成标题。

    

    利用大量图像-文本配对数据进行预训练的视觉-语言基础模型展示了前所未有的图像-文本关联能力，在各种下游任务中取得了显著的成果。关键挑战是如何利用已有的大规模预训练的视觉-语言基础模型，在域相关的下游任务中进行领域特定的迁移。本文提出了一个新的框架，包括领域基础模型（DFM），弥合了通用基础模型（GFM）和领域特定下游任务之间的差距。此外，我们还介绍了一个遥感领域（RS）的图像-文本配对数据集RS5M，其中包含了500万张带有英文描述的RS图像。该数据集是通过过滤公开可用的图像-文本配对数据集，并使用预训练的视觉-语言基础模型为仅带标签的RS数据集生成标题。这是第一个大规模的RS图像-文本配对数据集。

    Pre-trained Vision-Language Foundation Models utilizing extensive image-text paired data have demonstrated unprecedented image-text association capabilities, achieving remarkable results across various downstream tasks. A critical challenge is how to make use of existing large-scale pre-trained VLMs, which are trained on common objects, to perform the domain-specific transfer for accomplishing domain-related downstream tasks. In this paper, we propose a new framework that includes the Domain Foundation Model (DFM), bridging the gap between the General Foundation Model (GFM) and domain-specific downstream tasks. Moreover, we present an image-text paired dataset in the field of remote sensing (RS), RS5M, which has 5 million RS images with English descriptions. The dataset is obtained from filtering publicly available image-text paired datasets and captioning label-only RS datasets with pre-trained VLM. These constitute the first large-scale RS image-text paired dataset. Additionally, we 
    
[^79]: 音乐结构的自组织网络分析

    In-depth analysis of music structure as a self-organized network. (arXiv:2303.13631v1 [cs.SD])

    [http://arxiv.org/abs/2303.13631](http://arxiv.org/abs/2303.13631)

    本文介绍了一种利用Essential Element Network (EEN)算法将音频编码成文本并进行相关性计算和优化应用于聚类系数的频率和排名的方法，得到了音乐的深层结构信息，为厘清音乐结构提供了新方法。

    

    自然语言中的词汇不仅传递信息，还随着文明和人类迁移而演变。音乐也是如此。为了理解音乐背后的复杂结构，我们引入了一个叫做Essential Element Network (EEN)的算法将音频编码成文本。该网络通过计算音调、时间和音量之间的相关性得到，通过优化EEN算法以生成Zipf定律应用于聚类系数的频率和排名，我们可以将语义关系视为词汇并生成它们的映射。我们将这些编码后的词汇映射到音调-时间空间中，有助于我们系统地组织音乐深层结构中的句法。相比于其他深度学习方法的黑盒子特性，我们的算法提供了对音乐背后复杂网络的精确描述。因此，这些过程积累的经验和属性不仅为此类应用提供了新的方法，同时也为许多其他相关领域的研究提供了探索的路径。

    Words in a natural language not only transmit information but also evolve with the development of civilization and human migration. The same is true for music. To understand the complex structure behind the music, we introduced an algorithm called the Essential Element Network (EEN) to encode the audio into text. The network is obtained by calculating the correlations between scales, time, and volume. Optimizing EEN to generate Zipfs law for the frequency and rank of the clustering coefficient enables us to generate and regard the semantic relationships as words. We map these encoded words into the scale-temporal space, which helps us organize systematically the syntax in the deep structure of music. Our algorithm provides precise descriptions of the complex network behind the music, as opposed to the black-box nature of other deep learning approaches. As a result, the experience and properties accumulated through these processes can offer not only a new approach to the applications of
    
[^80]: 关于高效神经映射在无人地面车辆实时室内定位中的应用

    On the Application of Efficient Neural Mapping to Real-Time Indoor Localisation for Unmanned Ground Vehicles. (arXiv:2211.04718v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2211.04718](http://arxiv.org/abs/2211.04718)

    本文评估了将神经网络映射应用于实际机器人场景中的可行性，通过限制问题维度并增加训练数据量，可以实现嵌入式平台上几厘米级别的实时定位精度。

    

    从视觉数据中进行全局定位是一个具有挑战性的问题，适用于许多机器人领域。先前的研究表明，可以训练神经网络将环境的图像映射到该环境下的绝对相机姿态，从而在此过程中学习隐式神经映射。在本研究中，我们评估了这种方法在实际机器人场景中的适用性，证明通过将问题限制在二维空间，并显著增加训练数据量，可以使用紧凑的模型在嵌入式平台上实时推理，实现几厘米的定位精度。我们在地面车辆平台上部署了训练好的模型，在航点导航任务中展示了其有效性，在地面车辆的嵌入式CPU上以6fps的速率和平均精度为9cm进行定位，在嵌入式GPU上以35fps的速率进行定位，在桌面GPU上以220fps的速率进行定位。除此之外，我们还将发布一个新颖的定位数据集

    Global localisation from visual data is a challenging problem applicable to many robotics domains. Prior works have shown that neural networks can be trained to map images of an environment to absolute camera pose within that environment, learning an implicit neural mapping in the process. In this work we evaluate the applicability of such an approach to real-world robotics scenarios, demonstrating that by constraining the problem to 2-dimensions and significantly increasing the quantity of training data, a compact model capable of real-time inference on embedded platforms can be used to achieve localisation accuracy of several centimetres. We deploy our trained model onboard a UGV platform, demonstrating its effectiveness in a waypoint navigation task, wherein it is able to localise with a mean accuracy of 9cm at a rate of 6fps running on the UGV onboard CPU, 35fps on an embedded GPU, or 220fps on a desktop GPU. Along with this work we will release a novel localisation dataset compris
    
[^81]: 从特征提取角度的CNN近似分析

    Approximation analysis of CNNs from a feature extraction view. (arXiv:2210.09041v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.09041](http://arxiv.org/abs/2210.09041)

    本文通过深度卷积神经网络对线性特征提取进行了近似分析，并展示了深度学习相对于传统线性变换的强大能力。通过创造性的构造，我们有效地实现了线性特征提取，并且探究了深层网络的函数逼近速度。线性特征的多分辨卷积分解在我们的工作中起着核心作用。

    

    基于深度神经网络的深度学习在许多实际应用中取得了非常成功的结果，但由于网络架构和结构的限制，它缺乏足够的理论理解。在本文中，我们通过深度多通道卷积神经网络(CNNs)建立了一些线性特征提取的分析，这证明了深度学习在传统线性变换（如傅里叶变换、小波变换、冗余字典编码方法）上的强大能力。此外，我们给出了一个精确的构造，展示了如何利用多通道CNNs高效地进行线性特征提取。它可以用于降低逼近高维函数所需的基本维度。我们还研究了使用通道实现的深层网络和全连接层的函数逼近速率。将线性特征因子分解为多分辨卷积在我们的工作中起着重要作用。

    Deep learning based on deep neural networks has been very successful in many practical applications, but it lacks enough theoretical understanding due to the network architectures and structures. In this paper we establish some analysis for linear feature extraction by a deep multi-channel convolutional neural networks (CNNs), which demonstrates the power of deep learning over traditional linear transformations, like Fourier, wavelets, redundant dictionary coding methods. Moreover, we give an exact construction presenting how linear features extraction can be conducted efficiently with multi-channel CNNs. It can be applied to lower the essential dimension for approximating a high dimensional function. Rates of function approximation by such deep networks implemented with channels and followed by fully-connected layers are investigated as well. Harmonic analysis for factorizing linear features into multi-resolution convolutions plays an essential role in our work. Nevertheless, a dedica
    
[^82]: 评估和减轻路边取货和送货的拥堵影响：一种因果推断方法

    Estimating and Mitigating the Congestion Effect of Curbside Pick-ups and Drop-offs: A Causal Inference Approach. (arXiv:2206.02164v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.02164](http://arxiv.org/abs/2206.02164)

    该论文开发了一种严格的因果推断方法，评估了取货和送货对路边交通的拥堵影响，并提出了一种双重和分离的机器学习方法来量化这种影响。

    

    路边空间是城市道路网络中最繁忙的区域之一。特别是近年来，网约车和商业配送的快速增长导致了大量的取货和送货（PUDOs），这些占据了几十年前设计建造的有限路边空间。这些PUDOs可能导致路边利用率的拥堵和干扰主线交通流，明显带来显著的负面社会外部性。然而，目前缺乏一个严格量化和减轻PUDOs拥堵影响的分析框架，尤其是缺乏数据支持和混淆效应的参与。为了填补这一研究空白，本文采用严格的因果推断方法，评估PUDOs对一般区域网络的拥堵影响。建立了一个因果图来表示PUDOs和交通速度之间的时空关系，并提出了一种双重和分离的机器学习（DSML）方法来量化PUDOs对交通速度的影响。

    Curb space is one of the busiest areas in urban road networks. Especially in recent years, the rapid increase of ride-hailing trips and commercial deliveries has induced massive pick-ups/drop-offs (PUDOs), which occupy the limited curb space that was designed and built decades ago. These PUDOs could jam curbside utilization and disturb the mainline traffic flow, evidently leading to significant negative societal externalities. However, there is a lack of an analytical framework that rigorously quantifies and mitigates the congestion effect of PUDOs in the system view, particularly with little data support and involvement of confounding effects. To bridge this research gap, this paper develops a rigorous causal inference approach to estimate the congestion effect of PUDOs on general regional networks. A causal graph is set to represent the spatio-temporal relationship between PUDOs and traffic speed, and a double and separated machine learning (DSML) method is proposed to quantify how P
    
[^83]: 从统计关系到神经符号人工智能：一项调查

    From Statistical Relational to Neural Symbolic Artificial Intelligence: a Survey. (arXiv:2108.11451v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2108.11451](http://arxiv.org/abs/2108.11451)

    这篇调查综述了NeSy和StarAI两种人工智能方法中，学习和推理的集成方法。共有七个维度用于对两种方法进行分类和比较。

    

    本调查探讨了两个不同人工智能领域中学习和推理的集成方法：神经符号计算（NeSy）和统计关系人工智能（StarAI）。NeSy旨在将符号推理与神经网络相结合，而StarAI则专注于将逻辑与概率图模型相结合。该调查关注了两种方法之间的七个共同维度。这些维度用于对两种领域进行分类，包括：（1）逻辑推理方法，无论是基于模型还是基于证明；（2）逻辑理论的语法；（3）系统的逻辑语义及其扩展以促进学习；（4）学习的范围，包括仅涉及参数还是涉及整个逻辑理论；（5）表示法中符号和子符号成分的存在；（6）系统捕捉原始逻辑、概率和神经范例的程度；和（7）任务类别。

    This survey explores the integration of learning and reasoning in two different fields of artificial intelligence: neural-symbolic computation (NeSy) and statistical relational artificial intelligence (StarAI). NeSy aims to integrate symbolic reasoning and neural networks while StarAI focuses on integrating logic with probabilistic graphical models. The survey brings attention to seven shared dimensions between the two approaches. These dimensions are employed to categorize both fields and include: (1) the approach to logic inference, whether model or proof-based; (2) the syntax of logical theories; (3) the logic semantics of the systems and their extensions to facilitate learning; (4) the scope of learning, encompassing either the parameters alone or the entire logic theory; (5) the presence of symbolic and subsymbolic components in representations; (6) the degree to which the systems can capture the original logic, probabilistic, and neural paradigms; and (7) the classes of tasks the
    
[^84]: 用于高效流学习的调优组合特征回放

    Tuned Compositional Feature Replays for Efficient Stream Learning. (arXiv:2104.02206v7 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2104.02206](http://arxiv.org/abs/2104.02206)

    本文提出了一种名为CRUMB的新的持续学习算法，通过重放通过重新组合特征图来缓解遗忘问题。CRUMB通过存储内存块的索引来使得在后续任务中能够回放特定的记忆，这种重建机制还可以帮助神经网络最小化灾难性遗忘。

    

    我们的大脑从瞬时的世界经验中提取出持久的、可推广的知识。人工神经网络远远不能达到相同的水平：当被要求通过按照时间顺序训练非重复视频帧来学习对象分类时（在线流学习），那些能够从重新排列的数据集中良好学习的模型在学习新的刺激时会灾难性地遗忘旧的知识。我们提出了一种新的持续学习算法，称为Compositional Replay Using Memory Blocks (CRUMB)，通过重放通过重新组合通用部分重建的特征图来缓解遗忘问题。CRUMB在卷积神经网络中串联可训练和可重用的“内存块”向量，以组合方式重建特征图张量，就像面包屑组合成一个面包一样。CRUMB存储用于重建新刺激的内存块索引，从而使得在后续任务中能够回放特定的记忆。这种重建机制还可以引导神经网络最小化灾难性遗忘。

    Our brains extract durable, generalizable knowledge from transient experiences of the world. Artificial neural networks come nowhere close: when tasked with learning to classify objects by training on non-repeating video frames in temporal order (online stream learning), models that learn well from shuffled datasets catastrophically forget old knowledge upon learning new stimuli. We propose a new continual learning algorithm, Compositional Replay Using Memory Blocks (CRUMB), which mitigates forgetting by replaying feature maps reconstructed by recombining generic parts. CRUMB concatenates trainable and re-usable "memory block" vectors to compositionally reconstruct feature map tensors in convolutional neural networks, like crumbs forming a loaf of bread. CRUMB stores the indices of memory blocks used to reconstruct new stimuli, enabling replay of specific memories during later tasks. This reconstruction mechanism also primes the neural network to minimize catastrophic forgetting by for
    

