# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Exploring Large Language Models for Code Explanation.](http://arxiv.org/abs/2310.16673) | 本论文研究了使用大型语言模型（LLMs）为代码片段生成自然语言摘要的任务，发现代码LLMs优于通用对应模型，在处理具有不相似分布的数据集时，零样本方法可以得到更好的结果。 |
| [^2] | [A Picture is Worth a Thousand Words: Principled Recaptioning Improves Image Generation.](http://arxiv.org/abs/2310.16656) | 本文提出了一种原则性重写方法来改善图像生成模型的效果，通过使用专门的自动字幕模型重新标注语料库，并在重写后的数据集上训练文本到图像模型，模型在整体图像质量方面得到了显著改善。 |
| [^3] | [ArTST: Arabic Text and Speech Transformer.](http://arxiv.org/abs/2310.16621) | ArTST是一种用于支持阿拉伯语开源语音技术的预训练模型，通过从头开始的预训练和微调，它在自动语音识别、文本到语音合成和口语方言识别任务中达到了与当前最先进技术相当甚至超过的性能。 |
| [^4] | [Back Transcription as a Method for Evaluating Robustness of Natural Language Understanding Models to Speech Recognition Errors.](http://arxiv.org/abs/2310.16609) | 本文提出了一种使用反转录法和错误分类技术的方法，用于评估语音识别错误对自然语言理解模型性能的影响，结果表明合成语音与音频录制对于该方法的结果没有显著变化。 |
| [^5] | [Balancing central and marginal rejection when combining independent significance tests.](http://arxiv.org/abs/2310.16600) | 该论文提出了一种在组合独立显著性检验时平衡中心和边缘拒绝的方法，并提出了一种用于测量两者平衡的组合函数。 |
| [^6] | [Adaptive Uncertainty Estimation via High-Dimensional Testing on Latent Representations.](http://arxiv.org/abs/2310.16587) | 本论文提出了一种新的框架，通过利用特征表示的统计特性，在潜在表示中使用数据自适应的高维假设检验来进行不确定性估计。这种方法克服了现有不确定性估计方法对低维分布假设的依赖和数据域限制的问题，为不确定性估计提供了更好的泛化能力和性能。 |
| [^7] | [Hybrid Minimax-MCTS and Difficulty Adjustment for General Game Playing.](http://arxiv.org/abs/2310.16581) | 本论文提出了一种混合最小最大-蒙特卡洛树搜索算法和难度调整的通用游戏对战策略，可以在零和博弈中实现具有不同难度级别的人工智能对手。 |
| [^8] | [Adapt Anything: Tailor Any Image Classifiers across Domains And Categories Using Text-to-Image Diffusion Models.](http://arxiv.org/abs/2310.16573) | 本文研究了利用文本生成图片扩散模型适应性地调整任何跨域和跨类别的图像分类器。作者通过使用合成的高保真度图片作为源域数据的代理，并将嵌入在文本生成图片模型中的知识转移到目标域，从而省去了手动收集和注释源域数据的过程。 |
| [^9] | [Label Propagation for Graph Label Noise.](http://arxiv.org/abs/2310.16560) | 本文研究了图中的标签噪声问题，提出了一种基于标签传播的算法来处理任意异质性的图标签噪声，以纠正噪声标签并为未标记的节点分配标签。 |
| [^10] | [Pitfall of Optimism: Distributional Reinforcement Learning by Randomizing Risk Criterion.](http://arxiv.org/abs/2310.16546) | 本论文提出了一种通过随机化风险标准的分布式强化学习算法，以避免在风险上的偏向性，并证明了其收敛性和最优性。实验证明，在包括Atari 55游戏在内的各种环境中，该方法优于其他分布式算法。 |
| [^11] | [FedTherapist: Mental Health Monitoring with User-Generated Linguistic Expressions on Smartphones via Federated Learning.](http://arxiv.org/abs/2310.16538) | FedTherapist是一种使用联邦学习在智能手机上进行用户生成的语言表达的精神健康监测的系统。它有效地利用了持续语音和键盘输入，并通过上下文感知语言学习方法来提高预测的准确性。在评估中，比较了非语言特征，结果显示FedTherapist在预测抑郁、压力、焦虑和心情方面的表现更好。 |
| [^12] | [R$^3$ Prompting: Review, Rephrase and Resolve for Chain-of-Thought Reasoning in Large Language Models under Noisy Context.](http://arxiv.org/abs/2310.16535) | R$^3$提示是一种用于在噪声背景下进行CoT推理的新方法，通过复审、改写和解决的思考过程，与大型语言模型交互以进行关键句提取、变量声明和答案预测。 |
| [^13] | [Improving Diversity of Demographic Representation in Large Language Models via Collective-Critiques and Self-Voting.](http://arxiv.org/abs/2310.16523) | 本文研究了生成式大型语言模型中的人口多样性挑战，并提出了一种新的提示技术CCSV，通过利用模型的多样性推理能力来改善人口多样性，而无需依赖手工制作的示例或提示调整。 |
| [^14] | [Identifying Reasons for Bias: An Argumentation-Based Approach.](http://arxiv.org/abs/2310.16506) | 本文提出了一种基于论证的方法来确定为什么一个个体被分类与相似个体不同，该方法使用定量论证框架来表示个体和与其相似个体的属性-值对，并使用一个众所周知的语义来确定对个体分类产生最大贡献的属性-值对。 |
| [^15] | [On the Powerfulness of Textual Outlier Exposure for Visual OoD Detection.](http://arxiv.org/abs/2310.16492) | 本文研究了文本异常曝光在视觉外界检测中的应用。通过使用文本异常值代替图像中的异常值，我们揭示了使用文本异常值的好处，并提出了多种生成文本异常值的方法。 |
| [^16] | [Semiring Provenance for Lightweight Description Logics.](http://arxiv.org/abs/2310.16472) | 这篇论文研究了在描述逻辑中使用半环溯源的框架，并定义了一种适用于轻量级描述逻辑的溯源语义。论文证明了在半环施加限制的情况下，语义满足一些重要的特性，并对why溯源方法进行了研究。 |
| [^17] | [Towards Explainability in Monocular Depth Estimation.](http://arxiv.org/abs/2310.16457) | 本文研究了单眼深度估计方法中的可解释性，重点关注了人类感知深度的一个最重要的视觉线索——相对尺寸。通过模拟人类实验和测试最先进的方法，本研究实现了平均准确率约为77%的结果，间接揭示了这些方法的可解释性。 |
| [^18] | [Diversity Enhanced Narrative Question Generation for Storybooks.](http://arxiv.org/abs/2310.16446) | 本文介绍了一种多问题生成模型（mQG），该模型可以通过关注上下文和问题来生成多样化且可回答的问题。通过对FairytaleQA数据集进行训练和评估，以及在TellMeWhy和SQuAD1.1数据集上进行零-shot适应，mQG在各种评估指标上显示出有希望的结果。这项研究将问题生成的多样性引入故事书领域，为提高理解和参与度提供了新的方法。 |
| [^19] | [An Integrative Paradigm for Enhanced Stroke Prediction: Synergizing XGBoost and xDeepFM Algorithms.](http://arxiv.org/abs/2310.16430) | 本研究提出了一个结合了XGBoost和xDeepFM算法的集成模型，旨在改进卒中预测的准确性和鲁棒性。通过严格的实验验证了该模型的有效性，并通过与其他模型的对比得出有价值的见解，对卒中预测领域的机器学习和深度学习技术的进展做出了重要贡献。 |
| [^20] | [Graph Agent: Explicit Reasoning Agent for Graphs.](http://arxiv.org/abs/2310.16421) | 图像智能体（GA）是一种创新方法，通过整合图形嵌入方法和符号推理，利用大型语言模型（LLMs）实现了对复杂图形推理任务的解释性推理，并在节点分类和链接预测任务中取得了有效的结果。 |
| [^21] | [Open Knowledge Base Canonicalization with Multi-task Unlearning.](http://arxiv.org/abs/2310.16419) | 本论文提出了一个名为MulCanon的多任务取消学习框架，用于解决开放知识库规范化中的机器取消学习问题。 |
| [^22] | [Bridging the Human-AI Knowledge Gap: Concept Discovery and Transfer in AlphaZero.](http://arxiv.org/abs/2310.16410) | 本研究提出了一种新的方法，可以从AlphaZero中提取新的国际象棋概念，并发现这些概念可以被顶级国际象棋大师所学习和应用。 |
| [^23] | [Challenges of Radio Frequency Fingerprinting: From Data Collection to Deployment.](http://arxiv.org/abs/2310.16406) | 射频指纹识别技术通过利用硬件缺陷在物理层验证无线设备的身份，然而与深度学习技术的整合和实际场景应用带来了许多挑战。本文分析了这些挑战并指出当前阻碍射频指纹识别实际部署的问题，并探讨了未来发展方向。 |
| [^24] | [Fuse Your Latents: Video Editing with Multi-source Latent Diffusion Models.](http://arxiv.org/abs/2310.16400) | 本论文提出了一种名为FLDM的无需训练的框架，通过融合图像 Latent Diffusion Model（LDM）和视频 LDM，在视频编辑过程中实现了文本引导的视频编辑。这一方法既保持了视频的时间一致性，又利用了图像 LDM 的高保真度，并且具有灵活性与可替换性。 |
| [^25] | [Evaluating General-Purpose AI with Psychometrics.](http://arxiv.org/abs/2310.16379) | 本文提出将心理测量学放在评估通用人工智能的核心位置，以解决传统基准的一些挑战和缺点。 |
| [^26] | [GADY: Unsupervised Anomaly Detection on Dynamic Graphs.](http://arxiv.org/abs/2310.16376) | GADY是一种在动态图上进行无监督异常检测的新方法，通过提出连续动态图模型和引入负采样模块来解决了动态结构构建挑战和负采样挑战。 |
| [^27] | [InstructPTS: Instruction-Tuning LLMs for Product Title Summarization.](http://arxiv.org/abs/2310.16361) | InstructPTS是一种用于产品标题摘要的方法，通过指导调节LLMs可根据多种标准生成更准确的摘要，提高了产品名称摘要的质量。 |
| [^28] | [A Comprehensive Review of AI-enabled Unmanned Aerial Vehicle: Trends, Vision , and Challenges.](http://arxiv.org/abs/2310.16360) | AI技术与无人机的结合正引领着农业、监视实践和灾害管理策略等领域的革命，实现了导航、探测、监测和通信等方面的突破。 |
| [^29] | [AccoMontage-3: Full-Band Accompaniment Arrangement via Sequential Style Transfer and Multi-Track Function Prior.](http://arxiv.org/abs/2310.16334) | AccoMontage-3是一种通过顺序风格转换和多轨道功能先验实现全音乐伴奏编排的系统，可以根据主旋律与和弦的输入生成多音轨的伴奏。 |
| [^30] | [CoheSentia: A Novel Benchmark of Incremental versus Holistic Assessment of Coherence in Generated Texts.](http://arxiv.org/abs/2310.16329) | 本文提出了一个名为CoheSentia的新型基准，用于评估自动生成文本的人类感知连贯性。我们的注释协议包括整体评分和逐句评分两个角度。通过此基准，可以更准确地评估生成文本的连贯性并分析其相关因素。 |
| [^31] | [Modality-Agnostic Self-Supervised Learning with Meta-Learned Masked Auto-Encoder.](http://arxiv.org/abs/2310.16318) | 本文提出了一种与语言形式无关的元学习蒙版自监督学习框架MetaMAE，通过将蒙版自编码器（MAE）的蒙版重构视为元学习任务，并采用转换器元学习技术来改进MAE的自监督学习在不同语言形式上的表现。 |
| [^32] | [Sum-of-Parts Models: Faithful Attributions for Groups of Features.](http://arxiv.org/abs/2310.16316) | Sum-of-Parts模型通过构造保证特征组归因的忠实性，将预测分解为可解释的分数之和，帮助天体物理学家发现了关于星系形成的新知识。 |
| [^33] | [Instance-wise Linearization of Neural Network for Model Interpretation.](http://arxiv.org/abs/2310.16295) | 这项研究提出了一种实例化线性化的方法，用于解释神经网络模型。通过给模型内部的每个输入特征分配重要得分，揭示了模型如何使用特征做出决策。这种方法有助于解决当前特征归因方法中的局限性，并提高了模型解释的准确性。 |
| [^34] | [XFEVER: Exploring Fact Verification across Languages.](http://arxiv.org/abs/2310.16278) | XFEVER 数据集是为了在不同语言中对事实验证模型进行基准测试而设计的，实验结果显示多语言语言模型可以有效地构建不同语言的事实验证模型。 |
| [^35] | [Bayesian Domain Invariant Learning via Posterior Generalization of Parameter Distributions.](http://arxiv.org/abs/2310.16277) | 本研究通过学习网络参数的领域不变后验分布，提出了一种名为PosTerior Generalization的方法，能够更好地泛化到未见过的目标领域。 |
| [^36] | [CycleAlign: Iterative Distillation from Black-box LLM to White-box Models for Better Human Alignment.](http://arxiv.org/abs/2310.16271) | CycleAlign提出了一种从语言模型中提炼对齐能力的方法，它通过迭代提炼实现对黑盒模型到白盒模型的转变，解决了语言模型与人类价值对齐的问题。 |
| [^37] | [Attention Lens: A Tool for Mechanistically Interpreting the Attention Head Information Retrieval Mechanism.](http://arxiv.org/abs/2310.16270) | Attention Lens是一种工具，它能够通过学习的注意力头特定转换将注意力头的输出翻译为词汇标记。使用Attention Lens，我们可以解释注意力头在生成最终标记预测中的作用。注意力头在语言模型中扮演着高度专门化的角色。 |
| [^38] | [Enhancing Large Language Models for Secure Code Generation: A Dataset-driven Study on Vulnerability Mitigation.](http://arxiv.org/abs/2310.16263) | 本文介绍了一项针对安全代码生成的综合研究，通过使用经过策划的数据集评估和增强代码大规模语言模型（LLMs），有效解决了使用未经消毒的开源数据训练模型引入安全漏洞的风险。实验结果显示现有模型在安全方面常常被忽视。 |
| [^39] | [rTisane: Externalizing conceptual models for data analysis increases engagement with domain knowledge and improves statistical model quality.](http://arxiv.org/abs/2310.16262) | rTisane是一种使用DSL外部化概念模型的工具，能够帮助分析师更深入地参与并准确地表达他们的假设，从而提高统计模型质量。 |
| [^40] | [A Causal Disentangled Multi-Granularity Graph Classification Method.](http://arxiv.org/abs/2310.16256) | 这篇论文提出了一种因果解缠离散多粒度图分类方法（CDM-GNN），该方法能够解决图数据的多粒度特性，实现了对图中重要子结构和偏差部分的解析，并用于图分类任务中。 |
| [^41] | [ConDefects: A New Dataset to Address the Data Leakage Concern for LLM-based Fault Localization and Program Repair.](http://arxiv.org/abs/2310.16253) | ConDefects是一个新的数据集，专门解决基于LLM的故障定位和程序修复中的数据泄漏问题。该数据集包含了1,254个Java有错误的程序和1,625个Python有错误的程序，来自于线上竞赛平台AtCoder。每一个错误都配有错误位置和相应的修复代码版本，使其适用于故障定位和程序修复的研究。 |
| [^42] | [Speakerly: A Voice-based Writing Assistant for Text Composition.](http://arxiv.org/abs/2310.16251) | Speakerly是一种基于语音的文本创作辅助工具，用户可通过指令或口述与系统进行交互，系统生成格式良好、连贯的文档。该系统使用小型任务特定模型和预训练语言模型，实现快速有效的文本创作，并支持各种输入模式以提高可用性。 |
| [^43] | [A clustering tool for interrogating finite element models based on eigenvectors of graph adjacency.](http://arxiv.org/abs/2310.16249) | 该论文介绍了一种基于图邻接矩阵特征向量的聚类工具，用于调试有限元模型中的错误，并在商业结构FE套件中成功部署，并且已被用户用于真实世界的FE模型调试。 |
| [^44] | [Pixel-Level Clustering Network for Unsupervised Image Segmentation.](http://arxiv.org/abs/2310.16234) | 本文提出了一个无监督的像素级聚类框架，用于将图像分割成区域，而不需要使用地面真值注释。通过特征嵌入、特征统计计算、图像重构和超像素分割等模块，以及利用超像素内部一致性和邻近超像素之间的相似性/不相似性进行训练策略，实现了准确的无监督分割。此外，还提出了后处理方法来避免过分分割。 |
| [^45] | [CleanCoNLL: A Nearly Noise-Free Named Entity Recognition Dataset.](http://arxiv.org/abs/2310.16225) | CleanCoNLL是一种几乎无噪声的命名实体识别数据集，通过全面重标记和自动一致性检查来纠正CoNLL-03中的注释错误，提高了最先进方法的F1分数，并减少了因注释缺失而误判的情况。 |
| [^46] | [Hierarchical Randomized Smoothing.](http://arxiv.org/abs/2310.16221) | 分层随机平滑是一种在复杂数据上进行鲁棒性认证的解决方案，通过只在一个对象的子集上添加随机噪声，以更有针对性的方式提供了更强的鲁棒性保证和高准确性。 |
| [^47] | [Knowledge Editing for Large Language Models: A Survey.](http://arxiv.org/abs/2310.16218) | 大型语言模型(LLMs)在学术和工业领域具有巨大潜力。本文综述了LLMs的知识编辑问题，强调了需要开发有效和高效的技术来更新预训练LLMs以纳入新知识的重要性。 |
| [^48] | [Length is a Curse and a Blessing for Document-level Semantics.](http://arxiv.org/abs/2310.16193) | 本文研究了基于对比学习的模型在长度上的泛化能力，并提出了一个仅依赖于文档长度的无监督学习方法。研究发现，延长文档的长度会加 intensify 达到的高内部相似性，并且这种等向性的表现高度依赖于文本长度范围。基于这些发现，提出了一个简单而通用的文档表示学习框架，用于实现语义鲁棒的句子表示学习。 |
| [^49] | [Correction with Backtracking Reduces Hallucination in Summarization.](http://arxiv.org/abs/2310.16176) | 本文介绍了一种简单而有效的技术，CoBa，用于减少摘要中的幻觉。该方法通过测量条件词概率和上下文词距离的统计信息进行幻觉检测，并通过直观的回溯法进行减轻。实验证明，CoBa在减少摘要幻觉方面是有效且高效的。 |
| [^50] | [Context-aware feature attribution through argumentation.](http://arxiv.org/abs/2310.16157) | 本论文提出了一种基于论证的上下文感知特征归因方法，以解决机器学习和数据分析中特征归因的挑战。该方法利用广义可加模型和梯度方法与替代模型相结合，同时考虑用户的背景信息，从而提高了归因的准确性和解释性。 |
| [^51] | [Yin Yang Convolutional Nets: Image Manifold Extraction by the Analysis of Opposites.](http://arxiv.org/abs/2310.16148) | 提出了Yin Yang卷积网络，通过对立分析提取图像流形，在CIFAR-10数据集上达到了State-of-the-Art的效能，并且相对于之前的SOTA模型，参数减少了150k。 |
| [^52] | [PreWoMe: Exploiting Presuppositions as Working Memory for Long Form Question Answering.](http://arxiv.org/abs/2310.16147) | PreWoMe是一种处理长篇问答中信息检索问题的统一方法，通过提取问题中的预设并利用其作为工作记忆来生成反馈和行动，不仅能有效解决误导性问题，而且适用于处理正常问题，证明了在实际问答场景中利用预设、反馈和行动的有效性。 |
| [^53] | [Clinfo.ai: An Open-Source Retrieval-Augmented Large Language Model System for Answering Medical Questions using Scientific Literature.](http://arxiv.org/abs/2310.16146) | Clinfo.ai是一个开源的系统，使用科学文献回答医学问题。研究人员提出了一个信息检索和抽象概括任务，发布了相应的数据集，并进行了评估。 |
| [^54] | [A Language Model with Limited Memory Capacity Captures Interference in Human Sentence Processing.](http://arxiv.org/abs/2310.16142) | 开发了一个循环神经语言模型，通过使用单个自我注意头紧密模拟了认知理论中假设的记忆系统，并捕捉到人类句子处理中的干扰。 |
| [^55] | [Context-aware explainable recommendations over knowledge graphs.](http://arxiv.org/abs/2310.16141) | 本文提出了CA-KGCN，一个基于上下文的推荐系统框架，能够将知识图谱中的语义关系纳入建模，提高推荐准确性和可解释性。 |
| [^56] | [Alquist 5.0: Dialogue Trees Meet Generative Models. A Novel Approach for Enhancing SocialBot Conversations.](http://arxiv.org/abs/2310.16119) | Alquist 5.0是一种新的SocialBot系统，通过将对话树和生成模型相结合，以及引入NRG Barista和支持多模式设备，提高了用户对话体验，并保持了共情和知识型对话能力。 |
| [^57] | [Anatomically-aware Uncertainty for Semi-supervised Image Segmentation.](http://arxiv.org/abs/2310.16099) | 本研究提出了一种解剖学感知的方法，通过利用分割掩模中的全局信息来估计半监督图像分割的不确定性。该方法克服了传统不确定性估计方法的高计算复杂性和对像素级差异的限制。 |
| [^58] | [Grid Frequency Forecasting in University Campuses using Convolutional LSTM.](http://arxiv.org/abs/2310.16071) | 该论文介绍了一种创新的方法，利用卷积神经网络和长短期记忆网络建立稳健的时间序列预测模型，用于预测电网频率。个体化的卷积LSTM模型可以独立地为大学校园内的建筑进行训练和评估，并且结果证明了该模型的优越性。 |
| [^59] | [The Hyperdimensional Transform: a Holographic Representation of Functions.](http://arxiv.org/abs/2310.16065) | 这项研究介绍了一种新型的积分变换-超维变换，它将函数转换为噪声鲁棒、全息、高维表示的超维向量，与其他积分变换紧密相关，并为超维领域提供了理论基础和新的洞察。 |
| [^60] | [WebWISE: Web Interface Control and Sequential Exploration with Large Language Models.](http://arxiv.org/abs/2310.16042) | 本文介绍了一种利用大型语言模型（LLM）自动执行Web软件任务的方法，通过步骤性生成小型程序来实现对点击、滚动和文本输入操作的控制。与其他方法相比，该方法在MiniWob++基准测试中通过一个上下文示例就能达到相似或更好的性能。 |
| [^61] | [Physically Explainable Deep Learning for Convective Initiation Nowcasting Using GOES-16 Satellite Observations.](http://arxiv.org/abs/2310.16015) | 本研究开发了基于多通道红外卫星观测数据的可解释性深度学习模型，用于预测大气对流起始。通过案例研究，该模型表现出对云层和湿度特性的依赖性，并在误报率上显著优于经典的逻辑模型。 |
| [^62] | [Accented Speech Recognition With Accent-specific Codebooks.](http://arxiv.org/abs/2310.15970) | 本研究提出了一种使用具有专门口音代码本的口音适应方法，通过交叉注意力和可训练代码本，用于端到端ASR系统。在实验证明了该方法在已见和未见的口音上都能获得显著的性能提升。 |
| [^63] | [FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions.](http://arxiv.org/abs/2310.15421) | FANToM是一个新的基准，用于通过问答在信息不对称的对话环境中压力测试机器的心智理论。这个基准对最先进的大型语言模型来说具有挑战性，即使是具有思维链推理和微调的模型也比人类表现得差。 |
| [^64] | [TaskDiff: A Similarity Metric for Task-Oriented Conversations.](http://arxiv.org/abs/2310.15298) | TaskDiff是一种新颖的对话相似度度量方法，通过使用不同的对话组成部分来计算相似度，取得了优越的性能和鲁棒性。 |
| [^65] | [MGAS: Multi-Granularity Architecture Search for Effective and Efficient Neural Networks.](http://arxiv.org/abs/2310.15074) | MGAS是一个多粒度架构搜索的统一框架，通过学习特定粒度级别的离散化函数，自适应地确定剩余比例，从而实现同时优化模型大小和模型性能。 |
| [^66] | [Data Pruning via Moving-one-Sample-out.](http://arxiv.org/abs/2310.14664) | 本文提出了一种新颖的数据修剪方法MoSo，它通过评估样本对最优经验风险的影响来确定每个样本的重要性，并提出了一种高效的一阶近似器来计算样本的重要性，该近似器只需要梯度信息。 |
| [^67] | [An International Consortium for Evaluations of Societal-Scale Risks from Advanced AI.](http://arxiv.org/abs/2310.14455) | 本文提出了面向先进人工智能的社会规模风险评估的国际合作机构解决方案，提议在人工智能开发者和第三方评估人员之间建立联合体，以解决评估人员多样性有限、努力分配不理想和激励机制颠倒等协调挑战。 |
| [^68] | [Hunayn: Elevating Translation Beyond the Literal.](http://arxiv.org/abs/2310.13613) | 这项研究介绍了一种超越传统工具的高级英译阿拉伯语翻译器，使用赫尔辛基变压器和纯文学阿拉伯语数据集，表现出色，并强调了其在文化敏感性和语境准确性方面的优势。 |
| [^69] | [Multiscale Superpixel Structured Difference Graph Convolutional Network for VL Representation.](http://arxiv.org/abs/2310.13447) | 本文提出了一种多尺度超像素结构差异图卷积网络（MDGCN）用于视觉语言表征，通过聚类感知相似像素，减少了后续处理的视觉基元数量，并挖掘了更精确的拓扑关系。 |
| [^70] | [CLAIR: Evaluating Image Captions with Large Language Models.](http://arxiv.org/abs/2310.12971) | CLAIR是一种基于大型语言模型的新方法，用于评估机器生成的图像标题。相对于现有的评估方法，CLAIR在与人类判断的相关性方面表现更好，并针对具体数据集取得了较大改进。 |
| [^71] | [Large Language Model for Multi-objective Evolutionary Optimization.](http://arxiv.org/abs/2310.12541) | 本论文调查了一种利用大型语言模型（LLM）设计MOEA操作符的新方法，通过适当的提示工程，成功将通用的LLM以零-shot方式作为MOEA/D的黑盒搜索操作符，并通过从LLM行为中学习设计了一个显性的白盒操作符。 |
| [^72] | [Guarantees for Self-Play in Multiplayer Games via Polymatrix Decomposability.](http://arxiv.org/abs/2310.11518) | 这篇论文研究了多人游戏中自我对抗的保证问题，通过多矩阵可分解性，在满足一定条件的情况下，通过自我对抗学习的算法能够产生有界脆弱性的策略。 |
| [^73] | [ACES: generating diverse programming puzzles with autotelic language models and semantic descriptors.](http://arxiv.org/abs/2310.10692) | ACES是一种使用自我目标语言模型和语义描述符生成多样化的编程难题的方法，能够优化有趣的多样性和少样本生成。 |
| [^74] | [Improving Summarization with Human Edits.](http://arxiv.org/abs/2310.05857) | 本文介绍了一种改进摘要生成的方法，使用人工编辑的反馈数据，并通过序列对齐（不）似然训练(SALT)技术将人工编辑数据与模型生成数据结合起来。实验证明了这种方法在医学领域摘要生成中的有效性。 |
| [^75] | [CodeTransOcean: A Comprehensive Multilingual Benchmark for Code Translation.](http://arxiv.org/abs/2310.04951) | CodeTransOcean是一个全面的多语言代码翻译基准，包含多个创新的多语言数据集，并满足了现实应用的多样化需求。 |
| [^76] | [Land-cover change detection using paired OpenStreetMap data and optical high-resolution imagery via object-guided Transformer.](http://arxiv.org/abs/2310.02674) | 本文通过直接利用配对的OSM数据和光学图像进行土地覆盖变化检测，提出了一种基于对象引导的Transformer架构，从而拓宽了变化检测任务的范围，并显著减少了计算开销和内存负担。 |
| [^77] | [OceanGPT: A Large Language Model for Ocean Science Tasks.](http://arxiv.org/abs/2310.02031) | OceanGPT是首个专为海洋科学任务设计的大型语言模型，通过DoInstruct框架实现自动获取海洋领域指导数据。这一模型的引入填补了海洋科学领域中对LLM的需求缺口，并为海洋科学研究提供了新的工具和方法。 |
| [^78] | [Learning to Receive Help: Intervention-Aware Concept Embedding Models.](http://arxiv.org/abs/2309.16928) | 这项研究提出了一种干预感知的概念嵌入模型，用于提高神经架构对概念干预的响应性，并解决了概念干预顺序和模型架构的依赖性的问题。 |
| [^79] | [Guide Your Agent with Adaptive Multimodal Rewards.](http://arxiv.org/abs/2309.10790) | 本文提出了一种自适应返回条件策略（ARP）框架，通过使用自然语言任务描述和预训练的多模态编码器来提升智能体的泛化能力。通过在预训练的多模态嵌入空间中计算视觉观察和自然语言指令之间的相似度，并将其用作奖励信号，ARP有效缓解了目标误泛化问题，并在面对未知的文本指令时展现出了出色的泛化性能。 |
| [^80] | [A Configurable Library for Generating and Manipulating Maze Datasets.](http://arxiv.org/abs/2309.10498) | 这个论文介绍了一个可配置的库，用于生成和处理迷宫数据集，研究人员可以通过该库生成不同分布的迷宫数据集，并对生成参数和生成规则进行自定义控制。可以支持多种输出格式，适用于不同类型的模型。 |
| [^81] | [How to Data in Datathons.](http://arxiv.org/abs/2309.09770) | 本文提供了关于如何处理数据马拉松中的数据的指导方针和建议，通过10个案例研究验证了提出的框架的有效性。 |
| [^82] | [Talk2Care: Facilitating Asynchronous Patient-Provider Communication with Large-Language-Model.](http://arxiv.org/abs/2309.09357) | 本研究利用大型语言模型（LLMs）来促进患者和医生之间的异步通信，通过访谈研究了解了他们对LLMs的需求，并构建了一个名为Talk2Care的LLM驱动的通信系统。 |
| [^83] | [Can Large Language Models Discern Evidence for Scientific Hypotheses? Case Studies in the Social Sciences.](http://arxiv.org/abs/2309.06578) | 本文研究了大型语言模型（LLMs）根据科学摘要文本的能力，来辨别支持或反驳特定假设的证据。通过社区驱动的注释建立了一个新的数据集，针对社会科学中的科学假设证据任务。与其他基准进行了性能比较，并为未来研究提供了机会。 |
| [^84] | [EGOFALLS: A visual-audio dataset and benchmark for fall detection using egocentric cameras.](http://arxiv.org/abs/2309.04579) | 这项研究提出了一种使用自我中心摄像头进行摔倒检测的方法，并构建了一个新的视听数据集。通过迟决策融合将音频和视觉信息相结合可以提高检测性能。 |
| [^85] | [RePo: Resilient Model-Based Reinforcement Learning by Regularizing Posterior Predictability.](http://arxiv.org/abs/2309.00082) | 本文提出了RePo算法，通过正则化后验可预测性的方式，增强了视觉模型基础强化学习方法的弹性。该方法通过学习一个对冗余和伪变化具有弹性的潜在表示，提高了方法对视觉干扰的鲁棒性，使其能够在动态环境中运行。 |
| [^86] | [CL-MAE: Curriculum-Learned Masked Autoencoders.](http://arxiv.org/abs/2308.16572) | 本文提出了一种课程学习的遮罩自编码器（CL-MAE）。我们引入了一种可学习的遮罩模块，通过更新遮罩策略来增加自监督重构任务的复杂性。通过逐渐增加任务复杂性，模型可以学习更复杂和可迁移的表示。 |
| [^87] | [Implementation of The Future of Drug Discovery: QuantumBased Machine Learning Simulation (QMLS).](http://arxiv.org/abs/2308.08561) | 该论文介绍了一种名为QMLS的新概念，通过结合机器学习和量子模拟的方法，可以缩短药物研发的时间和降低成本。通过生成命中物和优化分子的过程，可以大大提高药物发现的效率。 |
| [^88] | [Developmental Bootstrapping of AIs.](http://arxiv.org/abs/2308.04586) | 传统的符号AI方法和深度学习AI方法无法满足创建强大和可信赖的AI的挑战，然而，发展脱靴法通过模仿人类儿童的能力发展过程，为创建稳健可靠的AI提供了希望。 |
| [^89] | [AgentBench: Evaluating LLMs as Agents.](http://arxiv.org/abs/2308.03688) | AgentBench是一个用于评估LLMs作为代理人的多维度基准，发现在复杂环境中，商业LLMs在充当代理人方面表现强劲，但与开源竞争对手相比，存在显著性能差距。该研究揭示了LLMs在长期推理、决策和指令遵循能力上的瓶颈。 |
| [^90] | [Select and Augment: Enhanced Dense Retrieval Knowledge Graph Augmentation.](http://arxiv.org/abs/2307.15776) | 本文提出了一种选择和增强的方法来改进文本增强的知识图谱嵌入，通过多任务框架选择相关的文本描述，并对知识图谱嵌入进行对齐或增强。 |
| [^91] | [WebArena: A Realistic Web Environment for Building Autonomous Agents.](http://arxiv.org/abs/2307.13854) | WebArena是一个用于构建自主智能体的真实网络环境，它包含了完全功能的网站，并且通过引入工具和外部知识库来鼓励智能体像人类一样解决任务。此外，WebArena还发布了一组用于评估任务完成功能正确性的基准任务。 |
| [^92] | [SynerGPT: In-Context Learning for Personalized Drug Synergy Prediction and Drug Design.](http://arxiv.org/abs/2307.11694) | 本文提出了一种通过上下文学习个性化药物协同作用并进行药物设计的方法，该方法利用小型的个性化数据集，不依赖于文本语料库、分子指纹或蛋白质相互作用的领域特定知识，取得了竞争性的结果。 |
| [^93] | [A Step Towards Worldwide Biodiversity Assessment: The BIOSCAN-1M Insect Dataset.](http://arxiv.org/abs/2307.10455) | 提出了一个新的大型手工标记昆虫图像数据集BIOSCAN-Insect，用于对昆虫生物多样性进行编目。该数据集还具有引人注目的特征，对广泛的机器学习社区也具有研究价值。 |
| [^94] | [Systematic Comparison of Software Agents and Digital Twins: Differences, Similarities, and Synergies in Industrial Production.](http://arxiv.org/abs/2307.08421) | 本研究系统比较了工业应用中的软件代理和数字孪生。研究旨在确定这两种范式之间的差异、相似之处和潜在的协同作用。 |
| [^95] | [Back to Optimization: Diffusion-based Zero-Shot 3D Human Pose Estimation.](http://arxiv.org/abs/2307.03833) | 本文提出了一种结合基于优化和基于学习方法的零样本扩散优化（ZeDO）管道，用于解决3D人体姿势估计中的跨领域和野外挑战，取得了最先进的性能。 |
| [^96] | [A Vulnerability of Attribution Methods Using Pre-Softmax Scores.](http://arxiv.org/abs/2307.03305) | 这篇论文讨论了使用前softmax分数的归属方法的一个漏洞，该方法用于解释卷积神经网络分类器输出。与对抗性攻击不同，作者关注的是对归属方法进行小修改可能导致的影响，而不会改变模型的输出。 |
| [^97] | [PlanE: Representation Learning over Planar Graphs.](http://arxiv.org/abs/2307.01180) | 本研究的目标是设计用于高效学习平面图完备不变量的架构。 |
| [^98] | [Separable Physics-Informed Neural Networks.](http://arxiv.org/abs/2306.15969) | 这项研究提出了一种可分离的物理信息神经网络（SPINN），通过逐个处理轴来显著减少了多维 PDE 中的网络传播数量，并使用正向模式自动微分降低了计算成本，使得可以在单个普通 GPU 上使用大量的配点。 |
| [^99] | [Unsupervised Episode Generation for Graph Meta-learning.](http://arxiv.org/abs/2306.15217) | 本文研究了无监督的剧集生成方法，通过元学习解决没有标签的少样本节点分类问题。它们充分利用所有节点信息，并且通过泛化能力提高性能。 |
| [^100] | [Training Priors Predict Text-To-Image Model Performance.](http://arxiv.org/abs/2306.01755) | 本文测试了文本到图像模型对于训练先验的依赖程度，发现模型能够更好地生成与训练数据中出现频率更高的三元组对齐的图像，但这也会降低其生成以翻转三元组为基础的图像质量。 |
| [^101] | [Interpretable and Explainable Logical Policies via Neurally Guided Symbolic Abstraction.](http://arxiv.org/abs/2306.01439) | 该论文介绍了一种名为NUDGE的策略，利用训练好的基于神经网络的代理来引导逻辑规则的搜索，实现了可解释和可解释的策略。 |
| [^102] | [Direct Diffusion Bridge using Data Consistency for Inverse Problems.](http://arxiv.org/abs/2305.19809) | 本文提出了一种用于逆问题的直接扩散链桥算法，提高了逆问题求解器的性能，并通过使用数据一致性解决了当前DDB框架存在的关键限制。 |
| [^103] | [Optimal Decision Trees for Separable Objectives: Pushing the Limits of Dynamic Programming.](http://arxiv.org/abs/2305.19706) | 本研究提出了一种通用的动态规划方法来优化任何组合的可分离目标和约束条件，这种方法在可扩展性方面比通用求解器表现得更好。 |
| [^104] | [One Objective to Rule Them All: A Maximization Objective Fusing Estimation and Planning for Exploration.](http://arxiv.org/abs/2305.18258) | 提出一种在线强化学习方法Maximize to Explore (MEX)，只需优化一个无约束的目标函数，自动平衡探索和利用，实现次线性遗憾。 |
| [^105] | [Image Manipulation via Multi-Hop Instructions -- A New Dataset and Weakly-Supervised Neuro-Symbolic Approach.](http://arxiv.org/abs/2305.14410) | 该论文提出了一个基于神经符号概念学习的图像操作系统NeuroSIM，它可以通过多跳指令在多物体场景中执行复杂的推理，只需要弱监督的数据集，并创建了一个新的数据集。该系统具有很高的竞争力或超过SOTA基线。 |
| [^106] | [Vector Autoregressive Evolution for Dynamic Multi-Objective Optimisation.](http://arxiv.org/abs/2305.12752) | 向量自回归演化(VARE)通过使用向量自回归(VAR)模型和环境感知超突变(EAH)策略，有效处理动态多目标优化(DMO)中的环境变化，并提高种群的多样性。 |
| [^107] | [Neural Foundations of Mental Simulation: Future Prediction of Latent Representations on Dynamic Scenes.](http://arxiv.org/abs/2305.11772) | 本研究探究了人类和动物如何推断物理世界的基本动态轨迹以及如何预测未来可能出现的状态，并评估了几类感知-认知网络的预测能力，发现在效率、普遍性和可解释性间存在权衡。 |
| [^108] | [TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks.](http://arxiv.org/abs/2305.11430) | 本文提出了一个通用分类法，可以用来设计具有特定属性的提示来执行各种复杂任务，从而解决了LLM在执行复杂任务方面的性能变异巨大的问题。 |
| [^109] | [API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs.](http://arxiv.org/abs/2304.08244) | API-Bank是一个针对工具增强的大型语言模型的基准测试，通过解决三个关键问题来评估LLMs的能力，并展示了GPT-3.5的改进能力。 |
| [^110] | [Making AI Less "Thirsty": Uncovering and Addressing the Secret Water Footprint of AI Models.](http://arxiv.org/abs/2304.03271) | 本论文揭示以及提出了解决人工智能模型巨大水足迹的方法，因为其淡水消耗已经引起国际社会的重视，并且AI模型应该承担社会责任，做出面对水危机的表率。 |
| [^111] | [Querying Large Language Models with SQL.](http://arxiv.org/abs/2304.00472) | 该论文介绍了使用SQL查询大型语言模型的方法，通过利用预训练的LLMs中的信息，可以从非结构化文本中提取数据并进行查询。通过Galois原型实现了查询LLMs的新物理运算符，并取得了令人鼓舞的结果。 |
| [^112] | [Goal Driven Discovery of Distributional Differences via Language Descriptions.](http://arxiv.org/abs/2302.14233) | 本论文提出了一个新的任务D5，通过目标驱动的方式自动发现两个大型语料库之间的差异。作者构建了一个D5系统，并提出了一套统一的评估指标来衡量其性能。通过实验证明，语言模型可以使用目标驱动的方法来发现语料库差异。 |
| [^113] | [Generalized Munchausen Reinforcement Learning using Tsallis KL Divergence.](http://arxiv.org/abs/2301.11476) | 这篇论文通过研究广义的Tsallis KL散度，扩展了Munchausen强化学习算法，并提供了一种将KL正则化纳入实际算法的方法。对于Tsallis KL，当$q > 1$时，可以获得新的策略优化选项。 |
| [^114] | [AtMan: Understanding Transformer Predictions Through Memory Efficient Attention Manipulation.](http://arxiv.org/abs/2301.08110) | AtMan是一种通过在生成式Transformer模型中操纵注意力机制来解释预测的方法，相较于传统方法几乎不占用额外内存，可在生产环境中使用。 |
| [^115] | [Towards multi-document summarization in the open-domain.](http://arxiv.org/abs/2212.10526) | 本论文针对"开放领域"的多文档摘要任务进行研究，发现最先进的摘要器在此情境下性能下降严重，但进行额外的开放领域的训练可以降低对不完美检索的敏感性。 |
| [^116] | [Variable Decision-Frequency Option Critic.](http://arxiv.org/abs/2212.04407) | 这篇论文提出了一个名为CTCO的框架，其中代理选择选项作为可变持续时间的子策略。这个框架可以以任何所需频率与系统交互，从而提供平滑的动作变化，相比传统RL和时间抽象RL方法，其性能更好。 |
| [^117] | [Welfare and Fairness in Multi-objective Reinforcement Learning.](http://arxiv.org/abs/2212.01382) | 本论文研究了多目标强化学习中的福利和公平性问题，提出了一种基于非线性福利函数的Q-learning算法，通过非线性标量化学习更新和非稳态动作选择来优化策略。算法被证明是可收敛的。 |
| [^118] | [A Survey on Graph Counterfactual Explanations: Definitions, Methods, Evaluation.](http://arxiv.org/abs/2210.12089) | 这篇综述研究了图形反事实解释的概念、方法、评估及其应用于图神经网络的情况，提供了分类法、统一的符号表示、基准数据集和评估指标，并对十四种方法、二十二个数据集和十九个指标进行了讨论和整合。未来的工作主要集中在解决开放的挑战上。 |
| [^119] | [GLM-130B: An Open Bilingual Pre-trained Model.](http://arxiv.org/abs/2210.02414) | GLM-130B是一个具有1300亿参数的开源双语预训练模型，能够超越GPT-3和最大的中文语言模型ERNIE TITAN 3.0 260B，在多个基准测试中表现出色。 |
| [^120] | [Implicit Two-Tower Policies.](http://arxiv.org/abs/2208.01191) | 隐式双塔策略（ITT）是一种新的结构化强化学习策略体系，通过在策略堆栈中显式区分动作和状态处理，实现了显著的计算效益和更好的性能，在黑盒/进化优化方面表现出色。 |
| [^121] | [Theme Aspect Argumentation Model for Handling Fallacies.](http://arxiv.org/abs/2205.15141) | 本文介绍了一种用于处理谬误的主题-方面-论证模型，通过形式约束来表征谬误，提出了可解释的谬误识别的替代方法，能进行修辞建模和深层语义分析。 |
| [^122] | [Impartial Games: A Challenge for Reinforcement Learning.](http://arxiv.org/abs/2205.12787) | AlphaZero-style reinforcement learning algorithms excel in various board games but face challenges with impartial games. The researchers present a concrete example of the game nim, and show that AlphaZero-style algorithms have difficulty learning these impartial games on larger board sizes. The difference between impartial games and partisan games can be explained by the vulnerability to adversarial attacks and perturbations. |
| [^123] | [Limitations of Deep Learning for Inverse Problems on Digital Hardware.](http://arxiv.org/abs/2202.13490) | 本文研究了深度学习在数字硬件上解决反问题的限制，并证明了对于小的松弛参数，有限维反问题无法通过计算方法解决。这些结果还引入了算法可获得准确度的下限。 |
| [^124] | [HEAM: High-Efficiency Approximate Multiplier Optimization for Deep Neural Networks.](http://arxiv.org/abs/2201.08022) | 本文提出了一种优化方法，用于自动设计近似乘法器，并根据操作数分布来最小化平均误差。所提乘法器在DNN中达到了比最佳复制的近似乘法器高达50.24%的准确性，同时具有较小的面积、功耗和延迟。 |
| [^125] | [Forward Composition Propagation for Explainable Neural Reasoning.](http://arxiv.org/abs/2112.12717) | 本文提出了一种被称为前向组合传播（FCP）的算法，用于解释前馈神经网络在结构化分类问题上的预测。该算法通过组合向量描述每个神经元中问题特征的作用，并且模拟结果表明组合值与受保护特征的预期行为紧密对齐。 |
| [^126] | [A Survey of Deep Learning for Low-Shot Object Detection.](http://arxiv.org/abs/2112.02814) | 本综述对低样本物体检测中的深度学习方法进行了综合回顾，提出了LSOD方法的分类，并对其进行了系统分析，为解决数据稀缺场景下的物体检测问题提供了参考。 |
| [^127] | [Process Extraction from Text: Benchmarking the State of the Art and Paving the Way for Future Challenges.](http://arxiv.org/abs/2110.03754) | 该论文评估了从文本中提取流程模型的现有技术，并提供了未来挑战的指导。通过比较10种最先进的方法，包括定性和定量评估，研究者们找到了解决模型提取问题的有效方法。 |
| [^128] | [How do I update my model? On the resilience of Predictive Process Monitoring models to change.](http://arxiv.org/abs/2109.03501) | 本研究针对预测过程监控模型的韧性问题，评估了三种不同策略，并发现增量学习算法具有潜力来解决预测模型的更新和可变性问题。 |
| [^129] | [Lipschitzness Is All You Need To Tame Off-policy Generative Adversarial Imitation Learning.](http://arxiv.org/abs/2006.16785) | 离线生成对抗模仿学习中，将学习到的奖励函数强制变成局部利普希茨连续是取得良好表现的必要条件，并且满足奖励的利普希茨性约束对模仿性能具有积极影响。 |
| [^130] | [A Neurocomputational Account of Consciousness: The Goal-Aligning Representation Internal Manipulation Theory (GARIM).](http://arxiv.org/abs/1912.13490) | 这个论文提出了一个神经计算框架下的意识理论，称为“目标对齐的内部表示操作”（GARIM）。该理论认为意识支持对目标相关的内部表示进行主动操作，使其与追求的目标更加对齐，从而增加目标导向行为的灵活性。 |
| [^131] | [Incremental Predictive Process Monitoring: How to Deal with the Variability of Real Environments.](http://arxiv.org/abs/1804.03967) | 提出使用增量学习算法来解决现有预测性流程监控技术无法处理真实环境的可变性的问题，并通过更新模型适应当前情况，实验证明增量学习在预测性流程监控中具有潜力。 |

# 详细

[^1]: 探索用于代码解释的大型语言模型

    Exploring Large Language Models for Code Explanation. (arXiv:2310.16673v1 [cs.SE])

    [http://arxiv.org/abs/2310.16673](http://arxiv.org/abs/2310.16673)

    本论文研究了使用大型语言模型（LLMs）为代码片段生成自然语言摘要的任务，发现代码LLMs优于通用对应模型，在处理具有不相似分布的数据集时，零样本方法可以得到更好的结果。

    

    自动化代码文档通过解释性文本在代码理解方面可能非常有益。大型语言模型（LLMs）在自然语言处理方面取得了显著的进展，特别是在软件工程任务中，如代码生成和代码摘要。本研究具体研究了使用各种LLMs为代码片段生成自然语言摘要的任务。研究结果表明，代码LLMs优于其通用对应模型，并且当处理具有训练集和测试集之间分布不相似的数据集时，零样本方法产生更好的结果。

    Automating code documentation through explanatory text can prove highly beneficial in code understanding. Large Language Models (LLMs) have made remarkable strides in Natural Language Processing, especially within software engineering tasks such as code generation and code summarization. This study specifically delves into the task of generating natural-language summaries for code snippets, using various LLMs. The findings indicate that Code LLMs outperform their generic counterparts, and zero-shot methods yield superior results when dealing with datasets with dissimilar distributions between training and testing sets.
    
[^2]: 一张图片胜过千言万语：原则性重写改善图像生成

    A Picture is Worth a Thousand Words: Principled Recaptioning Improves Image Generation. (arXiv:2310.16656v1 [cs.CV])

    [http://arxiv.org/abs/2310.16656](http://arxiv.org/abs/2310.16656)

    本文提出了一种原则性重写方法来改善图像生成模型的效果，通过使用专门的自动字幕模型重新标注语料库，并在重写后的数据集上训练文本到图像模型，模型在整体图像质量方面得到了显著改善。

    

    文本到图像扩散模型在过去几年中取得了显著的突破，使得从文本提示中高质量且多样化地合成图像成为可能。然而，即使是最先进的模型也常常难以准确地遵循其提示中的所有指令。这些模型中绝大部分是在由（图像，字幕）对组成的数据集上进行训练的，其中图像通常来自网络，而字幕则是它们的HTML替代文本。一个显著的例子是LAION数据集，被Stable Diffusion和其他模型使用。在这项工作中，我们观察到这些字幕通常质量较低，并认为这显著影响了模型理解文本提示中微妙语义的能力。我们展示通过使用专门的自动字幕模型重新标注语料库，并在重写后的数据集上训练文本到图像模型，模型在各个方面都会得到大幅度的改善。首先，在整体图像质量方面：例如FID 14.84 vs. t

    Text-to-image diffusion models achieved a remarkable leap in capabilities over the last few years, enabling high-quality and diverse synthesis of images from a textual prompt. However, even the most advanced models often struggle to precisely follow all of the directions in their prompts. The vast majority of these models are trained on datasets consisting of (image, caption) pairs where the images often come from the web, and the captions are their HTML alternate text. A notable example is the LAION dataset, used by Stable Diffusion and other models. In this work we observe that these captions are often of low quality, and argue that this significantly affects the model's capability to understand nuanced semantics in the textual prompts. We show that by relabeling the corpus with a specialized automatic captioning model and training a text-to-image model on the recaptioned dataset, the model benefits substantially across the board. First, in overall image quality: e.g. FID 14.84 vs. t
    
[^3]: ArTST: 阿拉伯文本和语音变换器

    ArTST: Arabic Text and Speech Transformer. (arXiv:2310.16621v1 [cs.CL])

    [http://arxiv.org/abs/2310.16621](http://arxiv.org/abs/2310.16621)

    ArTST是一种用于支持阿拉伯语开源语音技术的预训练模型，通过从头开始的预训练和微调，它在自动语音识别、文本到语音合成和口语方言识别任务中达到了与当前最先进技术相当甚至超过的性能。

    

    我们提出了一种用于支持阿拉伯语开源语音技术的预训练阿拉伯文本和语音变换器ArTST。该模型架构遵循最近发布的英文统一模态框架SpeechT5，并且专注于现代标准阿拉伯语（MSA），计划将模型扩展到未来版本的方言和混合阿拉伯语。我们从头开始在MSA语音和文本数据上进行了模型的预训练，并对以下任务进行了微调：自动语音识别（ASR）、文本到语音合成（TTS）和口语方言识别。通过与SpeechT5以及先前报道的这些任务的结果进行比较，ArTST在所有三个任务中的表现与当前最先进的技术持平或超过。此外，我们发现我们的预训练有助于泛化，这在低资源TTS任务中特别明显。预训练模型以及微调的ASR和TTS模型

    We present ArTST, a pre-trained Arabic text and speech transformer for supporting open-source speech technologies for the Arabic language. The model architecture follows the unified-modal framework, SpeechT5, that was recently released for English, and is focused on Modern Standard Arabic (MSA), with plans to extend the model for dialectal and code-switched Arabic in future editions. We pre-trained the model from scratch on MSA speech and text data, and fine-tuned it for the following tasks: Automatic Speech Recognition (ASR), Text-To-Speech synthesis (TTS), and spoken dialect identification. In our experiments comparing ArTST with SpeechT5, as well as with previously reported results in these tasks, ArTST performs on a par with or exceeding the current state-of-the-art in all three tasks. Moreover, we find that our pre-training is conducive for generalization, which is particularly evident in the low-resource TTS task. The pre-trained model as well as the fine-tuned ASR and TTS models
    
[^4]: 作为评估自然语言理解模型对语音识别错误鲁棒性的方法的反转录法

    Back Transcription as a Method for Evaluating Robustness of Natural Language Understanding Models to Speech Recognition Errors. (arXiv:2310.16609v1 [cs.CL])

    [http://arxiv.org/abs/2310.16609](http://arxiv.org/abs/2310.16609)

    本文提出了一种使用反转录法和错误分类技术的方法，用于评估语音识别错误对自然语言理解模型性能的影响，结果表明合成语音与音频录制对于该方法的结果没有显著变化。

    

    在口语对话系统中，自然语言理解模型之前是一个可能影响其性能的语音识别系统。本文提出了一种用于研究语音识别错误对自然语言理解模型性能影响的方法。该方法将反转录程序与细粒度的技术相结合，用于对影响NLU模型性能的错误进行分类。该方法依赖于使用合成语音进行NLU评估。我们证明在重要程度上，将合成语音用于音频录制的替代方法不会显著改变所提出技术的结果。

    In a spoken dialogue system, an NLU model is preceded by a speech recognition system that can deteriorate the performance of natural language understanding. This paper proposes a method for investigating the impact of speech recognition errors on the performance of natural language understanding models. The proposed method combines the back transcription procedure with a fine-grained technique for categorizing the errors that affect the performance of NLU models. The method relies on the usage of synthesized speech for NLU evaluation. We show that the use of synthesized speech in place of audio recording does not change the outcomes of the presented technique in a significant way.
    
[^5]: 在组合独立显著性检验时平衡中心和边缘拒绝

    Balancing central and marginal rejection when combining independent significance tests. (arXiv:2310.16600v1 [stat.ME])

    [http://arxiv.org/abs/2310.16600](http://arxiv.org/abs/2310.16600)

    该论文提出了一种在组合独立显著性检验时平衡中心和边缘拒绝的方法，并提出了一种用于测量两者平衡的组合函数。

    

    当原始数据不可用时，评估一组p值的显著性的常见方法是将它们与汇集函数进行组合。这些汇集的p值将p值样本转化为一个表现类似于单变量p值的单一数值。为了明确讨论这些函数，引入了一系列交叉假设，以传达p值中非零证据的强度和普遍性，然后讨论了常规汇集公式。在特定交叉假设的UMP汇集p值中观察到的模式推动了对于中心和边缘拒绝水平在α处的定义和讨论。证明了中心拒绝总是大于等于边缘拒绝，从而提出了一种用于测量两者在汇集的p值中平衡的商。基于χ²_κ分位数变换的组合函数被提出以控制这个商，并且被证明是有效的。

    A common approach to evaluating the significance of a collection of $p$-values combines them with a pooling function, in particular when the original data are not available. These pooled $p$-values convert a sample of $p$-values into a single number which behaves like a univariate $p$-value. To clarify discussion of these functions, a telescoping series of alternative hypotheses are introduced that communicate the strength and prevalence of non-null evidence in the $p$-values before general pooling formulae are discussed. A pattern noticed in the UMP pooled $p$-value for a particular alternative motivates the definition and discussion of central and marginal rejection levels at $\alpha$. It is proven that central rejection is always greater than or equal to marginal rejection, motivating a quotient to measure the balance between the two for pooled $p$-values. A combining function based on the $\chi^2_{\kappa}$ quantile transformation is proposed to control this quotient and shown to be
    
[^6]: 自适应高维检验在潜在表示中的不确定性估计

    Adaptive Uncertainty Estimation via High-Dimensional Testing on Latent Representations. (arXiv:2310.16587v1 [cs.LG])

    [http://arxiv.org/abs/2310.16587](http://arxiv.org/abs/2310.16587)

    本论文提出了一种新的框架，通过利用特征表示的统计特性，在潜在表示中使用数据自适应的高维假设检验来进行不确定性估计。这种方法克服了现有不确定性估计方法对低维分布假设的依赖和数据域限制的问题，为不确定性估计提供了更好的泛化能力和性能。

    

    不确定性估计旨在评估训练深度神经网络的置信度。然而，现有的不确定性估计方法依赖于低维分布假设，因此受到潜在特征的高维问题的限制。现有方法往往关注于离散分类概率的不确定性，这导致对于其他任务的不确定性估计的泛化能力较差。此外，大部分文献要求在训练时要看到外域（OOD）数据以更好地估计不确定性，这限制了实际中不确定性估计的性能，因为外域数据通常是未见过的。为了克服这些限制，我们提出了一个新的框架，利用数据自适应的高维假设测试来进行不确定性估计，这利用了特征表示的统计特性。我们的方法直接在潜在表示上操作，因此不需要重新训练特征编码器。

    Uncertainty estimation aims to evaluate the confidence of a trained deep neural network. However, existing uncertainty estimation approaches rely on low-dimensional distributional assumptions and thus suffer from the high dimensionality of latent features. Existing approaches tend to focus on uncertainty on discrete classification probabilities, which leads to poor generalizability to uncertainty estimation for other tasks. Moreover, most of the literature requires seeing the out-of-distribution (OOD) data in the training for better estimation of uncertainty, which limits the uncertainty estimation performance in practice because the OOD data are typically unseen. To overcome these limitations, we propose a new framework using data-adaptive high-dimensional hypothesis testing for uncertainty estimation, which leverages the statistical properties of the feature representations. Our method directly operates on latent representations and thus does not require retraining the feature encode
    
[^7]: 混合最小最大-蒙特卡洛树搜索和难度调整的通用游戏对战

    Hybrid Minimax-MCTS and Difficulty Adjustment for General Game Playing. (arXiv:2310.16581v1 [cs.AI])

    [http://arxiv.org/abs/2310.16581](http://arxiv.org/abs/2310.16581)

    本论文提出了一种混合最小最大-蒙特卡洛树搜索算法和难度调整的通用游戏对战策略，可以在零和博弈中实现具有不同难度级别的人工智能对手。

    

    棋盘游戏是一种适合各个年龄段的娱乐方式，它创造了竞争和吸引人的环境，同时也促进了学习和战略思考。对于数字版本的棋盘游戏（以及其他类型的数字游戏），通常可以选择游戏的难度。通常通过自定义AI算法的搜索参数来实现。然而，这种方法无法扩展到通用游戏对战代理程序，因为不同的游戏可能需要不同的参数设置来适应各个难度级别。本文提出了一种通用方法来实现具有难度级别的零和博弈的人工智能对手，并提出了一个最小最大-蒙特卡洛树搜索混合算法，它结合了最小最大搜索过程和GGP（通用游戏对战）中的MCTS（蒙特卡洛树搜索）的特点。这种方法在我们的移动应用程序LoBoGames中进行了测试，该应用程序是一个可扩展的棋盘游戏平台，旨在拥有广泛的游戏目录，并注重可访问性。

    Board games are a great source of entertainment for all ages, as they create a competitive and engaging environment, as well as stimulating learning and strategic thinking. It is common for digital versions of board games, as any other type of digital games, to offer the option to select the difficulty of the game. This is usually done by customizing the search parameters of the AI algorithm. However, this approach cannot be extended to General Game Playing agents, as different games might require different parametrization for each difficulty level. In this paper, we present a general approach to implement an artificial intelligence opponent with difficulty levels for zero-sum games, together with a propose of a Minimax-MCTS hybrid algorithm, which combines the minimax search process with GGP aspects of MCTS. This approach was tested in our mobile application LoBoGames, an extensible board games platform, that is intended to have an broad catalog of games, with an emphasis on accessibi
    
[^8]: 通过文本生成图片扩散模型，适应性地调整任何图像分类器跨域和类别

    Adapt Anything: Tailor Any Image Classifiers across Domains And Categories Using Text-to-Image Diffusion Models. (arXiv:2310.16573v1 [cs.CV])

    [http://arxiv.org/abs/2310.16573](http://arxiv.org/abs/2310.16573)

    本文研究了利用文本生成图片扩散模型适应性地调整任何跨域和跨类别的图像分类器。作者通过使用合成的高保真度图片作为源域数据的代理，并将嵌入在文本生成图片模型中的知识转移到目标域，从而省去了手动收集和注释源域数据的过程。

    

    本文研究的不是一种新的方法，而是研究了现代文本生成图片扩散模型能否适应性地调整任何跨域和跨类别的图像分类器。现有的领域适应性图像分类方法通过利用源域和目标域数据进行域对齐，从而将从有标签源域数据中学到的知识转移到无标签目标域数据中。然而，随着文本生成图片扩散模型的发展，我们想知道从文本生成的高保真度合成数据是否可以作为实际场景中源域数据的代理。这样，我们就不需要以一对一的方式收集和注释每个领域适应的任务中的源域数据。而是只使用一个现成的文本生成图片模型，生成带有相应文本提示派生的类别标签的图片，然后利用这些合成数据作为桥梁，将嵌入在任务无关的文本生成图片模型中的知识转移到目标域。

    We do not pursue a novel method in this paper, but aim to study if a modern text-to-image diffusion model can tailor any task-adaptive image classifier across domains and categories. Existing domain adaptive image classification works exploit both source and target data for domain alignment so as to transfer the knowledge learned from the labeled source data to the unlabeled target data. However, as the development of the text-to-image diffusion model, we wonder if the high-fidelity synthetic data from the text-to-image generator can serve as a surrogate of the source data in real world. In this way, we do not need to collect and annotate the source data for each domain adaptation task in a one-for-one manner. Instead, we utilize only one off-the-shelf text-to-image model to synthesize images with category labels derived from the corresponding text prompts, and then leverage the surrogate data as a bridge to transfer the knowledge embedded in the task-agnostic text-to-image generator t
    
[^9]: 图标签传播算法应对图标签噪声问题

    Label Propagation for Graph Label Noise. (arXiv:2310.16560v1 [cs.LG])

    [http://arxiv.org/abs/2310.16560](http://arxiv.org/abs/2310.16560)

    本文研究了图中的标签噪声问题，提出了一种基于标签传播的算法来处理任意异质性的图标签噪声，以纠正噪声标签并为未标记的节点分配标签。

    

    标签噪声是大型数据集中常见的挑战，它会显著降低深度神经网络的泛化能力。大部分现有研究都集中在计算机视觉中的噪声标签，然而，图模型将节点特征和图拓扑结构作为输入，通过消息传递机制更容易受到标签噪声的影响。近期，只有少数几篇文章提出了解决图中标签噪声的方法。其中一个主要限制是它们假设图是同构的，并且标签是平滑分布的。然而，现实世界中的图可能包含不同程度的异质性甚至是异质性的主导，导致当前方法的不足。本文研究任意异质性条件下的图标签噪声问题，旨在纠正噪声标签并为之前未标记的节点分配标签。我们首先进行了两个实证分析，探讨图同质性对图标签噪声的影响。接着，我们提出了一种基于标签传播的算法来处理任意异质性的图标签噪声。

    Label noise is a common challenge in large datasets, as it can significantly degrade the generalization ability of deep neural networks. Most existing studies focus on noisy labels in computer vision; however, graph models encompass both node features and graph topology as input, and become more susceptible to label noise through message-passing mechanisms. Recently, only a few works have been proposed to tackle the label noise on graphs. One major limitation is that they assume the graph is homophilous and the labels are smoothly distributed. Nevertheless, real-world graphs may contain varying degrees of heterophily or even be heterophily-dominated, leading to the inadequacy of current methods. In this paper, we study graph label noise in the context of arbitrary heterophily, with the aim of rectifying noisy labels and assigning labels to previously unlabeled nodes. We begin by conducting two empirical analyses to explore the impact of graph homophily on graph label noise. Following o
    
[^10]: 乐观主义的陷阱：通过随机化风险标准的分布式强化学习

    Pitfall of Optimism: Distributional Reinforcement Learning by Randomizing Risk Criterion. (arXiv:2310.16546v1 [cs.LG])

    [http://arxiv.org/abs/2310.16546](http://arxiv.org/abs/2310.16546)

    本论文提出了一种通过随机化风险标准的分布式强化学习算法，以避免在风险上的偏向性，并证明了其收敛性和最优性。实验证明，在包括Atari 55游戏在内的各种环境中，该方法优于其他分布式算法。

    

    分布式强化学习算法试图利用估计的不确定性进行探索，如在面对不确定性时的乐观主义。然而，使用估计的方差进行乐观探索可能导致数据收集的偏差，阻碍收敛或性能。本文提出了一种新颖的分布式强化学习算法，通过随机化风险标准来选择动作，避免在风险上的单向倾向。我们通过扭曲风险度量提供了一个扰动的分布贝尔曼最优性算子，并证明了所提方法具有较弱的收缩性质的收敛性和最优性。我们的理论结果支持，所提方法不会陷入偏向性的探索，并确保收敛到最优回报。最后，我们在包括Atari 55游戏在内的各种环境中通过实验证明了我们的方法优于其他现有的基于分布的算法。

    Distributional reinforcement learning algorithms have attempted to utilize estimated uncertainty for exploration, such as optimism in the face of uncertainty. However, using the estimated variance for optimistic exploration may cause biased data collection and hinder convergence or performance. In this paper, we present a novel distributional reinforcement learning algorithm that selects actions by randomizing risk criterion to avoid one-sided tendency on risk. We provide a perturbed distributional Bellman optimality operator by distorting the risk measure and prove the convergence and optimality of the proposed method with the weaker contraction property. Our theoretical results support that the proposed method does not fall into biased exploration and is guaranteed to converge to an optimal return. Finally, we empirically show that our method outperforms other existing distribution-based algorithms in various environments including Atari 55 games.
    
[^11]: FedTherapist：通过联邦学习在智能手机上使用用户生成的语言表达进行精神健康监测

    FedTherapist: Mental Health Monitoring with User-Generated Linguistic Expressions on Smartphones via Federated Learning. (arXiv:2310.16538v1 [cs.CL])

    [http://arxiv.org/abs/2310.16538](http://arxiv.org/abs/2310.16538)

    FedTherapist是一种使用联邦学习在智能手机上进行用户生成的语言表达的精神健康监测的系统。它有效地利用了持续语音和键盘输入，并通过上下文感知语言学习方法来提高预测的准确性。在评估中，比较了非语言特征，结果显示FedTherapist在预测抑郁、压力、焦虑和心情方面的表现更好。

    

    精神科医生通过患者的语言使用来诊断精神疾病。但由于数据隐私问题，现有的被动精神健康监测系统使用手机设备的活动、应用使用和位置等替代特征。我们提出了FedTherapist，一种利用联邦学习以隐私保护方式使用持续语音和键盘输入的移动精神健康监测系统。我们通过比较不同模型设计的性能和开销来克服在智能手机上进行设备内语言模型训练的复杂性。我们还提出了一种上下文感知语言学习（CALL）方法，以有效利用智能手机的大规模和嘈杂文本进行精神健康信号感知。我们在46名参与者中进行了经IRB批准的自我报告抑郁、压力、焦虑和心情的预测评估，结果显示FedTherapist相比于非语言特征的性能提高了0.15 AUROC。

    Psychiatrists diagnose mental disorders via the linguistic use of patients. Still, due to data privacy, existing passive mental health monitoring systems use alternative features such as activity, app usage, and location via mobile devices. We propose FedTherapist, a mobile mental health monitoring system that utilizes continuous speech and keyboard input in a privacy-preserving way via federated learning. We explore multiple model designs by comparing their performance and overhead for FedTherapist to overcome the complex nature of on-device language model training on smartphones. We further propose a Context-Aware Language Learning (CALL) methodology to effectively utilize smartphones' large and noisy text for mental health signal sensing. Our IRB-approved evaluation of the prediction of self-reported depression, stress, anxiety, and mood from 46 participants shows higher accuracy of FedTherapist compared with the performance with non-language features, achieving 0.15 AUROC improveme
    
[^12]: R$^3$ Prompting：无噪声背景下大型语言模型链式思维推理的评审、改写和解决

    R$^3$ Prompting: Review, Rephrase and Resolve for Chain-of-Thought Reasoning in Large Language Models under Noisy Context. (arXiv:2310.16535v1 [cs.CL])

    [http://arxiv.org/abs/2310.16535](http://arxiv.org/abs/2310.16535)

    R$^3$提示是一种用于在噪声背景下进行CoT推理的新方法，通过复审、改写和解决的思考过程，与大型语言模型交互以进行关键句提取、变量声明和答案预测。

    

    在链式思维（CoT）提示的帮助下，大型语言模型（LLMs）在各种推理任务上取得了显著的表现。然而，大多数研究都在无噪声背景下进行评估，LLMs在噪声背景下产生不准确结果的困境尚未得到充分调查。现有研究利用触发句子鼓励LLMs集中于相关信息，但触发对最终答案预测的影响有限。受交互式CoT方法的启发，该方法通过用户和LLMs之间多轮互动促进中间推理步骤，我们提出了一种新的提示方法，即R$^3$提示，用于在噪声背景下进行CoT思维推理。具体而言，R$^3$提示与LLMs进行关键句提取、变量声明和答案预测的交互，对应于复审、改写和解决的思考过程。最后一次互动中生成的响应将执行

    With the help of Chain-of-Thought (CoT) prompting, Large Language Models (LLMs) have achieved remarkable performance on various reasoning tasks. However, most of them have been evaluated under noise-free context and the dilemma for LLMs to produce inaccurate results under the noisy context has not been fully investigated. Existing studies utilize trigger sentences to encourage LLMs to concentrate on the relevant information but the trigger has limited effect on final answer prediction. Inspired by interactive CoT method, where intermediate reasoning steps are promoted by multiple rounds of interaction between users and LLMs, we propose a novel prompting method, namely R$^3$ prompting, for CoT reasoning under noisy context. Specifically, R$^3$ prompting interacts with LLMs to perform key sentence extraction, variable declaration and answer prediction, which corresponds to a thought process of reviewing, rephrasing and resolving. The responses generated at the last interaction will perfo
    
[^13]: 通过集体批评和自我投票改善大型语言模型中的人口多样性

    Improving Diversity of Demographic Representation in Large Language Models via Collective-Critiques and Self-Voting. (arXiv:2310.16523v1 [cs.CL])

    [http://arxiv.org/abs/2310.16523](http://arxiv.org/abs/2310.16523)

    本文研究了生成式大型语言模型中的人口多样性挑战，并提出了一种新的提示技术CCSV，通过利用模型的多样性推理能力来改善人口多样性，而无需依赖手工制作的示例或提示调整。

    

    对于生成式大型语言模型（LLMs）来说，多样性是一个重要挑战：当用户的提示不明确时，模型可能会在生成响应时遵循隐含假设，这可能导致响应的同质化，以及某些人口群体的代表性不足甚至消失在生成的响应中。本文规范了生成式LLMs中的多样性表示。我们提出了评估数据集，并提出了衡量在人和文化方向上生成响应多样性的度量指标。我们发现LLMs理解多样性的概念，并且它们可以对自己的响应进行推理和批评以实现这个目标。这一发现激发了一种名为集体批评和自我投票(CCSC)的新提示技术，通过利用它的多样性推理能力来提高LLMs的人口多样性，而不依赖于手工制作的示例或提示调整。通过人类和自动化评估进行了广泛的实证实验。

    A crucial challenge for generative large language models (LLMs) is diversity: when a user's prompt is under-specified, models may follow implicit assumptions while generating a response, which may result in homogenization of the responses, as well as certain demographic groups being under-represented or even erased from the generated responses. In this paper, we formalize diversity of representation in generative LLMs. We present evaluation datasets and propose metrics to measure diversity in generated responses along people and culture axes. We find that LLMs understand the notion of diversity, and that they can reason and critique their own responses for that goal. This finding motivated a new prompting technique called collective-critique and self-voting (CCSV) to self-improve people diversity of LLMs by tapping into its diversity reasoning capabilities, without relying on handcrafted examples or prompt tuning. Extensive empirical experiments with both human and automated evaluation
    
[^14]: 识别偏见的原因：一种基于论证的方法

    Identifying Reasons for Bias: An Argumentation-Based Approach. (arXiv:2310.16506v1 [cs.LG])

    [http://arxiv.org/abs/2310.16506](http://arxiv.org/abs/2310.16506)

    本文提出了一种基于论证的方法来确定为什么一个个体被分类与相似个体不同，该方法使用定量论证框架来表示个体和与其相似个体的属性-值对，并使用一个众所周知的语义来确定对个体分类产生最大贡献的属性-值对。

    

    随着算法决策系统在社会中的普及，确保这些系统的公平性变得越来越重要。虽然在构建公平算法决策系统方面已经进行了大量研究，但其中大部分方法需要访问训练数据，包括个人特征，并且对于哪些个体被不公平地分类没有透明度。本文提出了一种新颖的、与模型无关的基于论证的方法，以确定为什么一个个体被分类与相似个体不同。我们的方法使用定量论证框架来表示个体和与其相似个体的属性-值对，并使用一个众所周知的语义来确定对个体分类产生最大贡献的属性-值对。我们在两个在公平领域常用的数据集上评估了我们的方法，并展示了它在识别差异分类方面的有效性。

    As algorithmic decision-making systems become more prevalent in society, ensuring the fairness of these systems is becoming increasingly important. Whilst there has been substantial research in building fair algorithmic decision-making systems, the majority of these methods require access to the training data, including personal characteristics, and are not transparent regarding which individuals are classified unfairly. In this paper, we propose a novel model-agnostic argumentation-based method to determine why an individual is classified differently in comparison to similar individuals. Our method uses a quantitative argumentation framework to represent attribute-value pairs of an individual and of those similar to them, and uses a well-known semantics to identify the attribute-value pairs in the individual contributing most to their different classification. We evaluate our method on two datasets commonly used in the fairness literature and illustrate its effectiveness in the identi
    
[^15]: 关于文本异常曝光在视觉外界检测中的效力

    On the Powerfulness of Textual Outlier Exposure for Visual OoD Detection. (arXiv:2310.16492v1 [cs.CV])

    [http://arxiv.org/abs/2310.16492](http://arxiv.org/abs/2310.16492)

    本文研究了文本异常曝光在视觉外界检测中的应用。通过使用文本异常值代替图像中的异常值，我们揭示了使用文本异常值的好处，并提出了多种生成文本异常值的方法。

    

    成功检测越界数据对于确保神经网络的安全部署变得越来越重要。越界检测的主要挑战之一是神经网络在越界数据上输出过度自信的预测，这使得仅根据预测来确定数据的越界性变得困难。异常曝光通过在训练过程中引入额外的损失，鼓励对越界数据进行低置信度预测，从而解决了这个问题。尽管异常曝光在提高越界检测性能方面显示出了很大潜力，但是之前所有关于异常曝光的研究都限于使用视觉异常。受到视觉语言预训练的最新进展的启发，本文首次探索了文本异常曝光在尚未开拓的领域。首先，我们通过用文本等价物替换图像域中的真实或虚拟异常值来揭示使用文本异常值的好处。接下来，我们提出了多种生成文本异常值的方法。

    Successful detection of Out-of-Distribution (OoD) data is becoming increasingly important to ensure safe deployment of neural networks. One of the main challenges in OoD detection is that neural networks output overconfident predictions on OoD data, make it difficult to determine OoD-ness of data solely based on their predictions. Outlier exposure addresses this issue by introducing an additional loss that encourages low-confidence predictions on OoD data during training. While outlier exposure has shown promising potential in improving OoD detection performance, all previous studies on outlier exposure have been limited to utilizing visual outliers. Drawing inspiration from the recent advancements in vision-language pre-training, this paper venture out to the uncharted territory of textual outlier exposure. First, we uncover the benefits of using textual outliers by replacing real or virtual outliers in the image-domain with textual equivalents. Then, we propose various ways of genera
    
[^16]: 适用于轻量级描述逻辑的半环溯源

    Semiring Provenance for Lightweight Description Logics. (arXiv:2310.16472v1 [cs.LO])

    [http://arxiv.org/abs/2310.16472](http://arxiv.org/abs/2310.16472)

    这篇论文研究了在描述逻辑中使用半环溯源的框架，并定义了一种适用于轻量级描述逻辑的溯源语义。论文证明了在半环施加限制的情况下，语义满足一些重要的特性，并对why溯源方法进行了研究。

    

    我们研究了半环溯源——一种最初在关系数据库环境中定义的成功框架，用于描述逻辑。在此上下文中，本体公理被用交换半环的元素进行注释，并且这些注释根据它们的推导方式传播到本体的结果中。我们定义了一种溯源语义，适用于包括几种轻量级描述逻辑的语言，并展示了它与为带有特定类型注释（如模糊度）的本体定义的其他语义之间的关系。我们证明了在一些对半环施加限制的情况下，语义满足一些期望的特性（如扩展了数据库中定义的半环溯源）。然后我们专注于著名的why溯源方法，它允许计算每个加法幂等和乘法幂等的交换半环的半环溯源，并研究了与这种溯源方法相关的问题的复杂性。

    We investigate semiring provenance--a successful framework originally defined in the relational database setting--for description logics. In this context, the ontology axioms are annotated with elements of a commutative semiring and these annotations are propagated to the ontology consequences in a way that reflects how they are derived. We define a provenance semantics for a language that encompasses several lightweight description logics and show its relationships with semantics that have been defined for ontologies annotated with a specific kind of annotation (such as fuzzy degrees). We show that under some restrictions on the semiring, the semantics satisfies desirable properties (such as extending the semiring provenance defined for databases). We then focus on the well-known why-provenance, which allows to compute the semiring provenance for every additively and multiplicatively idempotent commutative semiring, and for which we study the complexity of problems related to the prov
    
[^17]: 《单眼深度估计中的可解释性》

    Towards Explainability in Monocular Depth Estimation. (arXiv:2310.16457v1 [cs.CV])

    [http://arxiv.org/abs/2310.16457](http://arxiv.org/abs/2310.16457)

    本文研究了单眼深度估计方法中的可解释性，重点关注了人类感知深度的一个最重要的视觉线索——相对尺寸。通过模拟人类实验和测试最先进的方法，本研究实现了平均准确率约为77%的结果，间接揭示了这些方法的可解释性。

    

    二维图像深度估计一直是计算机视觉中具有挑战性且广泛研究的课题。近年来，随着基于深度学习的方法的出现，取得了显著的进展，并且取得了极高的成功率。本文关注单眼深度估计方法中的可解释性，即人类如何感知深度。这项初步研究强调了最显著的视觉线索之一，即相对尺寸，在几乎所有观察的图像中都非常突出。我们设计了一个特定的实验来模拟人类实验，并测试了最先进的方法以间接评估在所定义的上下文中的可解释性。此外，我们观察到测量准确性需要进一步关注，并提出了一种特殊的方法来解决这个问题。结果表明，在各种方法中，平均准确率达到了约77%，其中一些方法表现出色，从而间接揭示了它们的可解释性。

    The estimation of depth in two-dimensional images has long been a challenging and extensively studied subject in computer vision. Recently, significant progress has been made with the emergence of Deep Learning-based approaches, which have proven highly successful. This paper focuses on the explainability in monocular depth estimation methods, in terms of how humans perceive depth. This preliminary study emphasizes on one of the most significant visual cues, the relative size, which is prominent in almost all viewed images. We designed a specific experiment to mimic the experiments in humans and have tested state-of-the-art methods to indirectly assess the explainability in the context defined. In addition, we observed that measuring the accuracy required further attention and a particular approach is proposed to this end. The results show that a mean accuracy of around 77% across methods is achieved, with some of the methods performing markedly better, thus, indirectly revealing their
    
[^18]: 故事书的多样性增强叙事问题生成

    Diversity Enhanced Narrative Question Generation for Storybooks. (arXiv:2310.16446v1 [cs.CL])

    [http://arxiv.org/abs/2310.16446](http://arxiv.org/abs/2310.16446)

    本文介绍了一种多问题生成模型（mQG），该模型可以通过关注上下文和问题来生成多样化且可回答的问题。通过对FairytaleQA数据集进行训练和评估，以及在TellMeWhy和SQuAD1.1数据集上进行零-shot适应，mQG在各种评估指标上显示出有希望的结果。这项研究将问题生成的多样性引入故事书领域，为提高理解和参与度提供了新的方法。

    

    从给定的上下文生成问题可以增强理解、参与度、评估和学习或对话环境的整体效力。尽管问题生成领域近年来取得了一些进展，但提高或衡量生成问题的多样性仍然是一个未解决的挑战。在本文中，我们引入了一个多问题生成模型（mQG），该模型可以通过关注上下文和问题来生成多样化且可回答的问题。为了验证生成问题的可回答性，我们使用了一个经过SQuAD2.0微调的问答模型，将问题分类为可回答或不可回答。我们在FairytaleQA数据集上对mQG进行训练和评估，该数据集是基于故事书的结构化问答数据集，包含叙事性问题。我们还对TellMeWhy和SQuAD1.1数据集进行了零-shot适应。mQG在各种评估指标上表现出色，超过了强基线模型。

    Question generation (QG) from a given context can enhance comprehension, engagement, assessment, and overall efficacy in learning or conversational environments. Despite recent advancements in QG, the challenge of enhancing or measuring the diversity of generated questions often remains unaddressed. In this paper, we introduce a multi-question generation model (mQG), which is capable of generating multiple, diverse, and answerable questions by focusing on context and questions. To validate the answerability of the generated questions, we employ a SQuAD2.0 fine-tuned question answering model, classifying the questions as answerable or not. We train and evaluate mQG on the FairytaleQA dataset, a well-structured QA dataset based on storybooks, with narrative questions. We further apply a zero-shot adaptation on the TellMeWhy and SQuAD1.1 datasets. mQG shows promising results across various evaluation metrics, among strong baselines.
    
[^19]: 一个综合性范式用于增强卒中预测：结合XGBoost和xDeepFM算法

    An Integrative Paradigm for Enhanced Stroke Prediction: Synergizing XGBoost and xDeepFM Algorithms. (arXiv:2310.16430v1 [cs.CV])

    [http://arxiv.org/abs/2310.16430](http://arxiv.org/abs/2310.16430)

    本研究提出了一个结合了XGBoost和xDeepFM算法的集成模型，旨在改进卒中预测的准确性和鲁棒性。通过严格的实验验证了该模型的有效性，并通过与其他模型的对比得出有价值的见解，对卒中预测领域的机器学习和深度学习技术的进展做出了重要贡献。

    

    卒中预测在预防和管理这种致残条件中起着关键作用。在这项研究中，我们使用了一套综合数据集来应对卒中预测的挑战，并提出了一种结合了XGBoost和xDeepFM算法力量的集成模型。我们的工作旨在通过实现更高的准确性和鲁棒性来改进现有的卒中预测模型。通过严格的实验，我们利用AUC指标验证了集成模型的有效性。通过将我们的发现与该领域其他模型的发现进行对比，我们对各种方法的优缺点有了宝贵的见解。这反过来对机器学习和深度学习技术在卒中预测领域的进展做出了重要贡献。

    Stroke prediction plays a crucial role in preventing and managing this debilitating condition. In this study, we address the challenge of stroke prediction using a comprehensive dataset, and propose an ensemble model that combines the power of XGBoost and xDeepFM algorithms. Our work aims to improve upon existing stroke prediction models by achieving higher accuracy and robustness. Through rigorous experimentation, we validate the effectiveness of our ensemble model using the AUC metric. Through comparing our findings with those of other models in the field, we gain valuable insights into the merits and drawbacks of various approaches. This, in turn, contributes significantly to the progress of machine learning and deep learning techniques specifically in the domain of stroke prediction.
    
[^20]: 图像感知智能体: 针对图像的显性推理智能体

    Graph Agent: Explicit Reasoning Agent for Graphs. (arXiv:2310.16421v1 [cs.AI])

    [http://arxiv.org/abs/2310.16421](http://arxiv.org/abs/2310.16421)

    图像智能体（GA）是一种创新方法，通过整合图形嵌入方法和符号推理，利用大型语言模型（LLMs）实现了对复杂图形推理任务的解释性推理，并在节点分类和链接预测任务中取得了有效的结果。

    

    图形嵌入方法，如图形神经网络（GNNs）和图形变换器（Graph Transformers），对于知识图谱上的各种任务的图形推理算法的发展做出了贡献。然而，图形嵌入方法的可解释性和可解释性不足，限制了它们在需要显性推理的场景中的适用性。在本文中，我们引入了图像智能体（GA），这是一种利用大型语言模型（LLMs）、归纳-演绎推理模块和长期记忆进行知识图推理任务的智能体方法。GA整合了符号推理和现有的图形嵌入方法，为复杂的图形推理任务提供了创新的方法。通过将图形结构转化为文本数据，GA使LLMs能够处理、推理并提供人类可解释的解释。通过节点分类和链接预测任务评估了GA的效果。结果表明，GA达到了

    Graph embedding methods such as Graph Neural Networks (GNNs) and Graph Transformers have contributed to the development of graph reasoning algorithms for various tasks on knowledge graphs. However, the lack of interpretability and explainability of graph embedding methods has limited their applicability in scenarios requiring explicit reasoning. In this paper, we introduce the Graph Agent (GA), an intelligent agent methodology of leveraging large language models (LLMs), inductive-deductive reasoning modules, and long-term memory for knowledge graph reasoning tasks. GA integrates aspects of symbolic reasoning and existing graph embedding methods to provide an innovative approach for complex graph reasoning tasks. By converting graph structures into textual data, GA enables LLMs to process, reason, and provide predictions alongside human-interpretable explanations. The effectiveness of the GA was evaluated on node classification and link prediction tasks. Results showed that GA reached s
    
[^21]: 多任务取消学习在开放知识库规范化中的应用

    Open Knowledge Base Canonicalization with Multi-task Unlearning. (arXiv:2310.16419v1 [cs.AI])

    [http://arxiv.org/abs/2310.16419](http://arxiv.org/abs/2310.16419)

    本论文提出了一个名为MulCanon的多任务取消学习框架，用于解决开放知识库规范化中的机器取消学习问题。

    

    大型开放知识库（OKB）的构建对移动计算领域中的许多应用至关重要。OKB中的名词短语和关系短语经常存在冗余和歧义，这就需要对OKB进行规范化的研究。然而，为了满足一些隐私保护规定的要求，并确保数据的及时性，规范化后的OKB通常需要删除一些敏感信息或过时数据。OKB规范化中的机器取消学习是解决上述问题的一个很好的方法。目前的解决方案通过设计先进的聚类算法和使用知识图谱嵌入（KGE）进一步促进规范化过程。迫切需要有效的方案充分协同机器取消学习与聚类和KGE学习。为此，我们提出了一个多任务取消学习框架，名为MulCanon，来解决OKB规范化中的机器取消学习问题。

    The construction of large open knowledge bases (OKBs) is integral to many applications in the field of mobile computing. Noun phrases and relational phrases in OKBs often suffer from redundancy and ambiguity, which calls for the investigation on OKB canonicalization. However, in order to meet the requirements of some privacy protection regulations and to ensure the timeliness of the data, the canonicalized OKB often needs to remove some sensitive information or outdated data. The machine unlearning in OKB canonicalization is an excellent solution to the above problem. Current solutions address OKB canonicalization by devising advanced clustering algorithms and using knowledge graph embedding (KGE) to further facilitate the canonicalization process. Effective schemes are urgently needed to fully synergise machine unlearning with clustering and KGE learning. To this end, we put forward a multi-task unlearning framework, namely MulCanon, to tackle machine unlearning problem in OKB canonic
    
[^22]: 弥合人工智能与人类知识的差距：在AlphaZero中进行概念发现和传递

    Bridging the Human-AI Knowledge Gap: Concept Discovery and Transfer in AlphaZero. (arXiv:2310.16410v1 [cs.AI])

    [http://arxiv.org/abs/2310.16410](http://arxiv.org/abs/2310.16410)

    本研究提出了一种新的方法，可以从AlphaZero中提取新的国际象棋概念，并发现这些概念可以被顶级国际象棋大师所学习和应用。

    

    人工智能系统在各个领域取得了超人类水平的表现，为我们提供了一个进一步提升人类知识和提高人类专家表现的机会。然而，这些高效的人工智能系统所包含的知识往往难以提取，也可能难以理解或学习。在这里，我们提出了一种新方法，可以在AlphaZero中提取新的国际象棋概念，AlphaZero是一个通过自我对弈而掌握国际象棋的人工智能系统。我们的分析表明，AlphaZero可能编码了超越现有人类知识的知识，但这些知识最终并不超出人类的理解范围，并且可以成功地学习。在人类研究中，我们展示了这些概念是可以被顶级国际象棋大师所学习的，因为四名顶级国际象棋大师在解决所呈现的概念原型位置时显示出了进步。

    Artificial Intelligence (AI) systems have made remarkable progress, attaining super-human performance across various domains. This presents us with an opportunity to further human knowledge and improve human expert performance by leveraging the hidden knowledge encoded within these highly performant AI systems. Yet, this knowledge is often hard to extract, and may be hard to understand or learn from. Here, we show that this is possible by proposing a new method that allows us to extract new chess concepts in AlphaZero, an AI system that mastered the game of chess via self-play without human supervision. Our analysis indicates that AlphaZero may encode knowledge that extends beyond the existing human knowledge, but knowledge that is ultimately not beyond human grasp, and can be successfully learned from. In a human study, we show that these concepts are learnable by top human experts, as four top chess grandmasters show improvements in solving the presented concept prototype positions. 
    
[^23]: 射频指纹识别的挑战：从数据收集到部署

    Challenges of Radio Frequency Fingerprinting: From Data Collection to Deployment. (arXiv:2310.16406v1 [cs.CR])

    [http://arxiv.org/abs/2310.16406](http://arxiv.org/abs/2310.16406)

    射频指纹识别技术通过利用硬件缺陷在物理层验证无线设备的身份，然而与深度学习技术的整合和实际场景应用带来了许多挑战。本文分析了这些挑战并指出当前阻碍射频指纹识别实际部署的问题，并探讨了未来发展方向。

    

    射频指纹识别（RFF）技术承诺基于制造过程中引入的固有硬件缺陷来在物理层对无线设备进行身份验证。这些射频发射器的缺陷反映在空中信号中，使接收器能够准确识别射频发射源。近年来，机器学习，特别是深度学习（DL）的进步，提高了RFF系统提取和学习构成设备特定指纹的复杂特征的能力。然而，将DL技术与RFF集成并在实际场景中运行系统面临许多挑战。本文在考虑DL-based RFF系统的三个参考阶段（数据收集和预处理，训练，最后部署）的基础上，识别和分析了这些挑战。我们的调查指出了目前阻碍RFF实际部署的现有问题，并讨论了有前途的未来发展方向。

    Radio Frequency Fingerprinting (RFF) techniques promise to authenticate wireless devices at the physical layer based on inherent hardware imperfections introduced during manufacturing. Such RF transmitter imperfections are reflected into over-the-air signals, allowing receivers to accurately identify the RF transmitting source. Recent advances in Machine Learning, particularly in Deep Learning (DL), have improved the ability of RFF systems to extract and learn complex features that make up the device-specific fingerprint. However, integrating DL techniques with RFF and operating the system in real-world scenarios presents numerous challenges. This article identifies and analyzes these challenges while considering the three reference phases of any DL-based RFF system: (i) data collection and preprocessing, (ii) training, and finally, (iii) deployment. Our investigation points out the current open problems that prevent real deployment of RFF while discussing promising future directions, 
    
[^24]: 融合潜变扩散模型的视频编辑：多源潜变扩散模型

    Fuse Your Latents: Video Editing with Multi-source Latent Diffusion Models. (arXiv:2310.16400v1 [cs.CV])

    [http://arxiv.org/abs/2310.16400](http://arxiv.org/abs/2310.16400)

    本论文提出了一种名为FLDM的无需训练的框架，通过融合图像 Latent Diffusion Model（LDM）和视频 LDM，在视频编辑过程中实现了文本引导的视频编辑。这一方法既保持了视频的时间一致性，又利用了图像 LDM 的高保真度，并且具有灵活性与可替换性。

    

    潜变扩散模型（LDM）以其在图像和视频合成方面的强大能力而闻名。然而，视频编辑方法存在着预训练数据不足或视频逐帧重新训练成本高的问题。为了解决这个问题，我们提出了FLDM（融合潜变扩散模型），这是一个无需训练的框架，通过在视频LDM中应用现成的图像编辑方法来实现基于文本的视频编辑。具体而言，FLDM在去噪过程中融合了图像LDM和视频LDM的潜变。这样，可以保持视频LDM的时间一致性，同时也可以利用图像LDM的高保真度。同时，由于图像LDM和视频LDM都可以替换，所以FLDM具有很高的灵活性，可以利用高级图像编辑方法，如InstructPix2Pix和ControlNet。据我们所知，FLDM是第一种将现成的图像编辑方法应用于视频LDM进行视频编辑的方法。进行了广泛的定量和定性实验。

    Latent Diffusion Models (LDMs) are renowned for their powerful capabilities in image and video synthesis. Yet, video editing methods suffer from insufficient pre-training data or video-by-video re-training cost. In addressing this gap, we propose FLDM (Fused Latent Diffusion Model), a training-free framework to achieve text-guided video editing by applying off-the-shelf image editing methods in video LDMs. Specifically, FLDM fuses latents from an image LDM and an video LDM during the denoising process. In this way, temporal consistency can be kept with video LDM while high-fidelity from the image LDM can also be exploited. Meanwhile, FLDM possesses high flexibility since both image LDM and video LDM can be replaced so advanced image editing methods such as InstructPix2Pix and ControlNet can be exploited. To the best of our knowledge, FLDM is the first method to adapt off-the-shelf image editing methods into video LDMs for video editing. Extensive quantitative and qualitative experiment
    
[^25]: 用心理测量学评估通用人工智能

    Evaluating General-Purpose AI with Psychometrics. (arXiv:2310.16379v1 [cs.AI])

    [http://arxiv.org/abs/2310.16379](http://arxiv.org/abs/2310.16379)

    本文提出将心理测量学放在评估通用人工智能的核心位置，以解决传统基准的一些挑战和缺点。

    

    人工智能（AI）已经从特定任务向通用系统的发展，趋向于人类的多功能性。随着AI系统开始在社会中发挥重要作用，确保对其进行充分评估变得很重要。目前的AI基准通常在特定任务集合上评估性能。然而，对于评估通用AI系统来说，这有一些缺点。首先，很难预测AI系统是否能完成一项它从未见过或之前不存在的新任务。其次，这些基准常常关注整体性能指标，可能忽视了对做出明智决策至关重要的细节。最后，对现有基准的可靠性存在越来越多的担忧，并对正在进行的测量提出了疑问。为解决这些挑战，本文建议将心理测量学，即心理测量的科学，放在评估通用AI的核心位置。

    Artificial intelligence (AI) has witnessed an evolution from task-specific to general-purpose systems that trend toward human versatility. As AI systems begin to play pivotal roles in society, it is important to ensure that they are adequately evaluated. Current AI benchmarks typically assess performance on collections of specific tasks. This has drawbacks when used for assessing general-purpose AI systems. First, it is difficult to predict whether AI systems could complete a new task it has never seen or that did not previously exist. Second, these benchmarks often focus on overall performance metrics, potentially overlooking the finer details crucial for making informed decisions. Lastly, there are growing concerns about the reliability of existing benchmarks and questions about what is being measured. To solve these challenges, this paper suggests that psychometrics, the science of psychological measurement, should be placed at the core of evaluating general-purpose AI. Psychometric
    
[^26]: GADY: 动态图上的无监督异常检测

    GADY: Unsupervised Anomaly Detection on Dynamic Graphs. (arXiv:2310.16376v1 [cs.LG])

    [http://arxiv.org/abs/2310.16376](http://arxiv.org/abs/2310.16376)

    GADY是一种在动态图上进行无监督异常检测的新方法，通过提出连续动态图模型和引入负采样模块来解决了动态结构构建挑战和负采样挑战。

    

    动态图上的异常检测是指检测行为明显偏离图中观察到的规范行为的实体和它们的时间信息。这个领域因其在金融、网络安全、社交网络等方面的应用而受到越来越多的关注。然而，现有方法面临两个挑战：动态结构构建挑战-难以捕捉带有复杂时间信息的图结构，以及负采样挑战-无法构建优秀的负采样进行无监督学习。为了解决这些挑战，我们提出了在动态图上的无监督生成异常检测（GADY）。为了解决第一个挑战，我们提出了一个连续的动态图模型来捕捉细粒度信息，突破了现有离散方法的限制。具体地，我们采用了一个消息传递框架结合位置特征来获取边的嵌入，通过解码来识别异常。对于第二个挑战，我们通过引入一个负采样模块来构造优秀的负样本，从而提高无监督学习的性能。

    Anomaly detection on dynamic graphs refers to detecting entities whose behaviors obviously deviate from the norms observed within graphs and their temporal information. This field has drawn increasing attention due to its application in finance, network security, social networks, and more. However, existing methods face two challenges: dynamic structure constructing challenge - difficulties in capturing graph structure with complex time information and negative sampling challenge - unable to construct excellent negative samples for unsupervised learning. To address these challenges, we propose Unsupervised Generative Anomaly Detection on Dynamic Graphs (GADY). To tackle the first challenge, we propose a continuous dynamic graph model to capture the fine-grained information, which breaks the limit of existing discrete methods. Specifically, we employ a message-passing framework combined with positional features to get edge embeddings, which are decoded to identify anomalies. For the sec
    
[^27]: InstructPTS: 用于产品标题摘要的指导调节LLMs的方法

    InstructPTS: Instruction-Tuning LLMs for Product Title Summarization. (arXiv:2310.16361v1 [cs.CL])

    [http://arxiv.org/abs/2310.16361](http://arxiv.org/abs/2310.16361)

    InstructPTS是一种用于产品标题摘要的方法，通过指导调节LLMs可根据多种标准生成更准确的摘要，提高了产品名称摘要的质量。

    

    电子商务产品目录中包含数十亿个商品。大多数产品标题很长，卖家使用产品属性来改进商品检索并突出关键产品方面。这导致了不自然的产品标题与客户对其的称呼之间的差距。它也限制了电子商务商店使用这些卖家提供的标题进行推荐、问答或评论摘要的能力。受最近有关指导调节LLMs的研究的启示，我们提出了InstructPTS，这是一种用于产品标题摘要任务的可控方法。使用一种新的指导微调策略进行训练，我们的方法能够根据各种标准（例如摘要中的单词数量、包含特定短语等）总结产品标题。对实际电子商务目录进行广泛的评估表明，与简单微调LLMs相比，我们提出的方法可以生成更准确的产品名称摘要，BLEU和ROUG提高了超过14和8个百分点。

    E-commerce product catalogs contain billions of items. Most products have lengthy titles, as sellers pack them with product attributes to improve retrieval, and highlight key product aspects. This results in a gap between such unnatural products titles, and how customers refer to them. It also limits how e-commerce stores can use these seller-provided titles for recommendation, QA, or review summarization.  Inspired by recent work on instruction-tuned LLMs, we present InstructPTS, a controllable approach for the task of Product Title Summarization (PTS). Trained using a novel instruction fine-tuning strategy, our approach is able to summarize product titles according to various criteria (e.g. number of words in a summary, inclusion of specific phrases, etc.). Extensive evaluation on a real-world e-commerce catalog shows that compared to simple fine-tuning of LLMs, our proposed approach can generate more accurate product name summaries, with an improvement of over 14 and 8 BLEU and ROUG
    
[^28]: AI技术与无人机的全面综述：趋势、愿景和挑战

    A Comprehensive Review of AI-enabled Unmanned Aerial Vehicle: Trends, Vision , and Challenges. (arXiv:2310.16360v1 [cs.AI])

    [http://arxiv.org/abs/2310.16360](http://arxiv.org/abs/2310.16360)

    AI技术与无人机的结合正引领着农业、监视实践和灾害管理策略等领域的革命，实现了导航、探测、监测和通信等方面的突破。

    

    近年来，人工智能（AI）与无人机（UAV）的结合在各个领域带来了进展。本综合分析探讨了AI驱动的无人机和友好计算在应用中所带来的变革。它涵盖了新兴趋势、未来愿景以及这种关系所固有的挑战。该研究考察了AI在导航、探测和跟踪物体、监测野生动植物、提升精准农业、方便救援行动、进行监视活动以及使用环保意识计算技术在无人机之间建立通信方面的作用。通过深入研究AI与无人机之间的相互作用，本分析强调了这些技术在农业、监视实践、灾害管理策略等行业革命的潜力。在构想可能性的同时，它还关注了道德考虑。

    In recent years, the combination of artificial intelligence (AI) and unmanned aerial vehicles (UAVs) has brought about advancements in various areas. This comprehensive analysis explores the changing landscape of AI-powered UAVs and friendly computing in their applications. It covers emerging trends, futuristic visions, and the inherent challenges that come with this relationship. The study examines how AI plays a role in enabling navigation, detecting and tracking objects, monitoring wildlife, enhancing precision agriculture, facilitating rescue operations, conducting surveillance activities, and establishing communication among UAVs using environmentally conscious computing techniques. By delving into the interaction between AI and UAVs, this analysis highlights the potential for these technologies to revolutionise industries such as agriculture, surveillance practices, disaster management strategies, and more. While envisioning possibilities, it also takes a look at ethical consider
    
[^29]: AccoMontage-3: 通过顺序风格转换和多轨道功能先验实现全音乐伴奏编排

    AccoMontage-3: Full-Band Accompaniment Arrangement via Sequential Style Transfer and Multi-Track Function Prior. (arXiv:2310.16334v1 [cs.SD])

    [http://arxiv.org/abs/2310.16334](http://arxiv.org/abs/2310.16334)

    AccoMontage-3是一种通过顺序风格转换和多轨道功能先验实现全音乐伴奏编排的系统，可以根据主旋律与和弦的输入生成多音轨的伴奏。

    

    我们提出了AccoMontage-3，这是一个符号音乐自动化系统，可以根据主旋律与和弦的输入（即引导乐谱），生成多音轨的全音乐伴奏。该系统包含三个模块化组件，每个组件模拟全音乐作曲的重要方面。第一个组件是钢琴编曲师，通过将纹理风格转换为和弦，使用潜在的和弦-纹理分离和启发式纹理供应者检索，生成钢琴伴奏。第二个组件根据个别音轨功能编码的管弦乐风格，将钢琴伴奏乐谱编排成全音乐伴奏。将前两个组件连接起来的第三个组件是一个先验模型，用于描述整首音乐作品上的编曲风格的全局结构。整个系统以端到端的方式自我监督地学习生成全音乐伴奏，将风格转换应用于两个层面的多声部协调。

    We propose AccoMontage-3, a symbolic music automation system capable of generating multi-track, full-band accompaniment based on the input of a lead melody with chords (i.e., a lead sheet). The system contains three modular components, each modelling a vital aspect of full-band composition. The first component is a piano arranger that generates piano accompaniment for the lead sheet by transferring texture styles to the chords using latent chord-texture disentanglement and heuristic retrieval of texture donors. The second component orchestrates the piano accompaniment score into full-band arrangement according to the orchestration style encoded by individual track functions. The third component, which connects the previous two, is a prior model characterizing the global structure of orchestration style over the whole piece of music. From end to end, the system learns to generate full-band accompaniment in a self-supervised fashion, applying style transfer at two levels of polyphonic co
    
[^30]: CoheSentia: 一个对生成文本连贯性进行增量与整体评估的新型基准。（arXiv:2310.16329v1 [cs.CL]）

    CoheSentia: A Novel Benchmark of Incremental versus Holistic Assessment of Coherence in Generated Texts. (arXiv:2310.16329v1 [cs.CL])

    [http://arxiv.org/abs/2310.16329](http://arxiv.org/abs/2310.16329)

    本文提出了一个名为CoheSentia的新型基准，用于评估自动生成文本的人类感知连贯性。我们的注释协议包括整体评分和逐句评分两个角度。通过此基准，可以更准确地评估生成文本的连贯性并分析其相关因素。

    

    连贯性是一个语言学术语，指的是文本单元（句子、命题）之间的关系，使文本在逻辑上一致并对读者有意义。随着自然语言处理中生成模型的进展，迫切需要自动评估自动生成文本的人类感知连贯性。目前为止，关于明确评估生成文本的连贯性并分析（不）连贯性因素的工作很少。以往关于该主题的研究使用其他任务（如句子重排）作为连贯性的替代指标，而不是直接进行连贯性检测。本文介绍了一个名为CoheSentia的新型基准，用于评估自动生成文本的人类感知连贯性。我们的注释协议反映了两个角度：一个是全局角度，给出一个总体连贯性分数；另一个是逐句评分的增量角度。增量方法产生了一个（不）连贯性评估以及相应的分数。

    Coherence is a linguistic term that refers to the relations between small textual units (sentences, propositions), which make the text logically consistent and meaningful to the reader. With the advances of generative foundational models in NLP, there is a pressing need to automatically assess the human-perceived coherence of automatically generated texts. Up until now, little work has been done on explicitly assessing the coherence of generated texts and analyzing the factors contributing to (in)coherence. Previous work on the topic used other tasks, e.g., sentence reordering, as proxies of coherence, rather than approaching coherence detection heads on. In this paper, we introduce {\sc CoheSentia}, a novel benchmark of human-perceived coherence of automatically generated texts. Our annotation protocol reflects two perspectives; one is global, assigning a single coherence score, and the other is incremental, scoring sentence by sentence. The incremental method produces an (in)coherenc
    
[^31]: 一种与语言形式无关的元学习蒙版自监督学习方法

    Modality-Agnostic Self-Supervised Learning with Meta-Learned Masked Auto-Encoder. (arXiv:2310.16318v1 [cs.LG])

    [http://arxiv.org/abs/2310.16318](http://arxiv.org/abs/2310.16318)

    本文提出了一种与语言形式无关的元学习蒙版自监督学习框架MetaMAE，通过将蒙版自编码器（MAE）的蒙版重构视为元学习任务，并采用转换器元学习技术来改进MAE的自监督学习在不同语言形式上的表现。

    

    尽管自监督学习在各种语言形式中具有实际重要性，但近期的研究主要集中在少数经过精选的领域，如视觉和语言，并且常常依赖于特定领域的知识。本文中，我们将蒙版自编码器（MAE）作为一个统一的、与语言形式无关的自监督学习框架进行了拓展。我们认为元学习是解释MAE作为与语言形式无关学习器的关键，并从共同提高其在多种语言形式上的自监督学习能力的动机出发，提出了MetaMAE框架。我们的核心思想是将MAE的蒙版重构视为一个元学习任务：通过对未蒙版标记进行自适应来预测蒙版标记，从而通过转换器元学习实现对其进行总误差减小。基于这一新的解释，我们提出了将两种高级元学习技术结合的方法。

    Despite its practical importance across a wide range of modalities, recent advances in self-supervised learning (SSL) have been primarily focused on a few well-curated domains, e.g., vision and language, often relying on their domain-specific knowledge. For example, Masked Auto-Encoder (MAE) has become one of the popular architectures in these domains, but less has explored its potential in other modalities. In this paper, we develop MAE as a unified, modality-agnostic SSL framework. In turn, we argue meta-learning as a key to interpreting MAE as a modality-agnostic learner, and propose enhancements to MAE from the motivation to jointly improve its SSL across diverse modalities, coined MetaMAE as a result. Our key idea is to view the mask reconstruction of MAE as a meta-learning task: masked tokens are predicted by adapting the Transformer meta-learner through the amortization of unmasked tokens. Based on this novel interpretation, we propose to integrate two advanced meta-learning tec
    
[^32]: Sum-of-Parts模型：对特征组的忠实归因

    Sum-of-Parts Models: Faithful Attributions for Groups of Features. (arXiv:2310.16316v1 [cs.LG])

    [http://arxiv.org/abs/2310.16316](http://arxiv.org/abs/2310.16316)

    Sum-of-Parts模型通过构造保证特征组归因的忠实性，将预测分解为可解释的分数之和，帮助天体物理学家发现了关于星系形成的新知识。

    

    如果机器学习模型的解释准确反映了其决策过程，则被认为是“忠实”的解释。然而，例如深度学习的特征归因等解释并不能保证忠实，有可能产生具有误导性的解释。在这项工作中，我们开发了Sum-of-Parts（SOP）模型，它是一类模型，其预测具有通过构造保证忠实的特征组归因。该模型将预测分解为可解释的分数之和，每个分数直接归因于一组稀疏特征。我们使用标准可解释性指标对SOP进行评估，并在一个案例研究中，利用SOP提供的忠实解释帮助天体物理学家发现了关于星系形成的新知识。

    An explanation of a machine learning model is considered "faithful" if it accurately reflects the model's decision-making process. However, explanations such as feature attributions for deep learning are not guaranteed to be faithful, and can produce potentially misleading interpretations. In this work, we develop Sum-of-Parts (SOP), a class of models whose predictions come with grouped feature attributions that are faithful-by-construction. This model decomposes a prediction into an interpretable sum of scores, each of which is directly attributable to a sparse group of features. We evaluate SOP on benchmarks with standard interpretability metrics, and in a case study, we use the faithful explanations from SOP to help astrophysicists discover new knowledge about galaxy formation.
    
[^33]: 对于模型解释的神经网络实例化线性化

    Instance-wise Linearization of Neural Network for Model Interpretation. (arXiv:2310.16295v1 [cs.LG])

    [http://arxiv.org/abs/2310.16295](http://arxiv.org/abs/2310.16295)

    这项研究提出了一种实例化线性化的方法，用于解释神经网络模型。通过给模型内部的每个输入特征分配重要得分，揭示了模型如何使用特征做出决策。这种方法有助于解决当前特征归因方法中的局限性，并提高了模型解释的准确性。

    

    神经网络在许多科学领域取得了显著的成功。然而，神经网络模型的可解释性仍然是将这种技术应用于我们日常生活的主要瓶颈。挑战在于神经网络的非线性行为，这提出了一个关键性问题，即模型如何使用输入特征进行决策。解决这一挑战的经典方法是特征归因，它为每个输入特征分配一个重要得分，并揭示其对当前预测的重要性。然而，当前的特征归因方法经常指示每个输入特征的重要性，而没有详细说明它们在模型内部实际上是如何处理的。这些归因方法常常引发一个关注点，即它们是否正确地强调了模型预测的特征。对于神经网络模型，非线性行为通常是由模型的非线性激活单元引起的。然而，预测的计算行为往往是复杂的，这使得解释和理解模型的决策变得困难。

    Neural network have achieved remarkable successes in many scientific fields. However, the interpretability of the neural network model is still a major bottlenecks to deploy such technique into our daily life. The challenge can dive into the non-linear behavior of the neural network, which rises a critical question that how a model use input feature to make a decision. The classical approach to address this challenge is feature attribution, which assigns an important score to each input feature and reveal its importance of current prediction. However, current feature attribution approaches often indicate the importance of each input feature without detail of how they are actually processed by a model internally. These attribution approaches often raise a concern that whether they highlight correct features for a model prediction.  For a neural network model, the non-linear behavior is often caused by non-linear activation units of a model. However, the computation behavior of a predict
    
[^34]: XFEVER: 跨语言事实验证的探索

    XFEVER: Exploring Fact Verification across Languages. (arXiv:2310.16278v1 [cs.CL])

    [http://arxiv.org/abs/2310.16278](http://arxiv.org/abs/2310.16278)

    XFEVER 数据集是为了在不同语言中对事实验证模型进行基准测试而设计的，实验结果显示多语言语言模型可以有效地构建不同语言的事实验证模型。

    

    本文介绍了适用于跨语言事实验证模型基准测试的Cross-lingual Fact Extraction and VERification (XFEVER)数据集。我们通过将Fact Extraction and VERification (FEVER)数据集的主张和证据文本翻译成六种语言来构建它。训练集和开发集使用机器翻译进行翻译，而测试集包括由专业翻译人员和机器翻译生成的文本。使用XFEVER数据集，本文定义了两种跨语言事实验证场景，即零样本学习和翻译训练学习，并针对每个场景提出了基准模型。实验结果表明，多语言语言模型可以有效地构建不同语言的事实验证模型。然而，性能在不同语言之间有差异，并且在英语情况下稍逊一筹。我们还发现，我们可以有效地减轻模型的误差校准问题。

    This paper introduces the Cross-lingual Fact Extraction and VERification (XFEVER) dataset designed for benchmarking the fact verification models across different languages. We constructed it by translating the claim and evidence texts of the Fact Extraction and VERification (FEVER) dataset into six languages. The training and development sets were translated using machine translation, whereas the test set includes texts translated by professional translators and machine-translated texts. Using the XFEVER dataset, two cross-lingual fact verification scenarios, zero-shot learning and translate-train learning, are defined, and baseline models for each scenario are also proposed in this paper. Experimental results show that the multilingual language model can be used to build fact verification models in different languages efficiently. However, the performance varies by language and is somewhat inferior to the English case. We also found that we can effectively mitigate model miscalibratio
    
[^35]: Bayesian领域不变学习通过参数分布的后验泛化

    Bayesian Domain Invariant Learning via Posterior Generalization of Parameter Distributions. (arXiv:2310.16277v1 [cs.LG])

    [http://arxiv.org/abs/2310.16277](http://arxiv.org/abs/2310.16277)

    本研究通过学习网络参数的领域不变后验分布，提出了一种名为PosTerior Generalization的方法，能够更好地泛化到未见过的目标领域。

    

    领域不变学习旨在学习能够提取各种训练领域中不变特征的模型，从而更好地泛化到未见过的目标领域。最近，贝叶斯神经网络在领域不变学习方面取得了良好的结果，但大多数研究集中在对齐特征分布而不是参数分布。受到贝叶斯神经网络原理的启发，我们试图直接学习网络参数的领域不变后验分布。首先，我们提出了一个定理，表明可以通过聚合不同训练领域上的后验来隐式推断参数的不变后验。我们的假设更具宽松性，可以提取更多的领域不变信息。我们还提出了一种名为"PosTerior Generalization (PTG)"的简单而有效的方法，用于估计不变的参数分布。PTG充分利用了变分推断来近似参数分布。

    Domain invariant learning aims to learn models that extract invariant features over various training domains, resulting in better generalization to unseen target domains. Recently, Bayesian Neural Networks have achieved promising results in domain invariant learning, but most works concentrate on aligning features distributions rather than parameter distributions. Inspired by the principle of Bayesian Neural Network, we attempt to directly learn the domain invariant posterior distribution of network parameters. We first propose a theorem to show that the invariant posterior of parameters can be implicitly inferred by aggregating posteriors on different training domains. Our assumption is more relaxed and allows us to extract more domain invariant information. We also propose a simple yet effective method, named PosTerior Generalization (PTG), that can be used to estimate the invariant parameter distribution. PTG fully exploits variational inference to approximate parameter distribution
    
[^36]: CycleAlign: 从黑盒语言模型到白盒模型进行迭代提炼，以实现更好的人类对齐

    CycleAlign: Iterative Distillation from Black-box LLM to White-box Models for Better Human Alignment. (arXiv:2310.16271v1 [cs.CL])

    [http://arxiv.org/abs/2310.16271](http://arxiv.org/abs/2310.16271)

    CycleAlign提出了一种从语言模型中提炼对齐能力的方法，它通过迭代提炼实现对黑盒模型到白盒模型的转变，解决了语言模型与人类价值对齐的问题。

    

    在大规模语料库上训练的语言模型通常会生成有害、有毒或与人类偏好相悖的内容，使得其与人类价值的对齐成为一个关键问题。强化学习从人类反馈中进行对齐的方法（如PPO）是一种常见的方法，但往往复杂、不稳定且资源密集。最近，基于排名的对齐方法已经出现，通过用监督微调替换强化学习框架，提供稳定性和有效性，但由于需要带注释的数据，它们的成本较高。考虑到现有的大型语言模型（如ChatGPT）已经相对较好地对齐并且成本较低，研究人员已经开始从AI反馈中对语言模型与人类偏好进行对齐。现有的常规实践仅仅从LLMs提炼出遵循指令的响应，受到了瓶颈的限制。因此，我们引入CycleAlign来从参数非可见的模型中提炼对齐能力。

    Language models trained on large-scale corpus often generate content that is harmful, toxic, or contrary to human preferences, making their alignment with human values a critical concern. Reinforcement learning from human feedback (RLHF) with algorithms like PPO is a prevalent approach for alignment but is often complex, unstable, and resource-intensive. Recently, ranking-based alignment methods have emerged, offering stability and effectiveness by replacing the RL framework with supervised fine-tuning, but they are costly due to the need for annotated data. Considering that existing large language models (LLMs) like ChatGPT are already relatively well-aligned and cost-friendly, researchers have begun to align the language model with human preference from AI feedback. The common practices, which unidirectionally distill the instruction-following responses from LLMs, are constrained by their bottleneck. Thus we introduce CycleAlign to distill alignment capabilities from parameter-invisi
    
[^37]: 注意力镜头：一种解释注意力头信息检索机制的工具

    Attention Lens: A Tool for Mechanistically Interpreting the Attention Head Information Retrieval Mechanism. (arXiv:2310.16270v1 [cs.CL])

    [http://arxiv.org/abs/2310.16270](http://arxiv.org/abs/2310.16270)

    Attention Lens是一种工具，它能够通过学习的注意力头特定转换将注意力头的输出翻译为词汇标记。使用Attention Lens，我们可以解释注意力头在生成最终标记预测中的作用。注意力头在语言模型中扮演着高度专门化的角色。

    

    基于Transformer的大型语言模型(LLMs)是自然语言任务的最先进技术。最近的研究尝试通过逆向工程线性层的作用，解码LLMs为文本完成任务做出最终预测的内部机制。然而，关于注意力头在生成最终标记预测中的具体作用还知之甚少。我们提出了Attention Lens，一个工具，可以通过学习的注意力头特定转换(称为镜头)将注意力头的输出翻译为词汇标记。我们训练的镜头的初步发现表明，注意力头在语言模型中扮演着高度专门化的角色。Attention Lens的代码可在github.com/msakarvadia/AttentionLens上获得。

    Transformer-based Large Language Models (LLMs) are the state-of-the-art for natural language tasks. Recent work has attempted to decode, by reverse engineering the role of linear layers, the internal mechanisms by which LLMs arrive at their final predictions for text completion tasks. Yet little is known about the specific role of attention heads in producing the final token prediction. We propose Attention Lens, a tool that enables researchers to translate the outputs of attention heads into vocabulary tokens via learned attention-head-specific transformations called lenses. Preliminary findings from our trained lenses indicate that attention heads play highly specialized roles in language models. The code for Attention Lens is available at github.com/msakarvadia/AttentionLens.
    
[^38]: 提升大规模语言模型用于安全代码生成：基于数据集驱动的漏洞缓解研究

    Enhancing Large Language Models for Secure Code Generation: A Dataset-driven Study on Vulnerability Mitigation. (arXiv:2310.16263v1 [cs.SE])

    [http://arxiv.org/abs/2310.16263](http://arxiv.org/abs/2310.16263)

    本文介绍了一项针对安全代码生成的综合研究，通过使用经过策划的数据集评估和增强代码大规模语言模型（LLMs），有效解决了使用未经消毒的开源数据训练模型引入安全漏洞的风险。实验结果显示现有模型在安全方面常常被忽视。

    

    大规模语言模型（LLMs）对代码生成带来了显著的进展，既有利于新手开发人员，也有利于经验丰富的开发人员。然而，它们使用来自开源仓库（如GitHub）的未经消毒的数据进行训练，会引入意外传播安全漏洞的风险。为了有效缓解这个问题，本文从软件安全的角度进行了一项综合研究，旨在评估和增强代码LLMs。我们引入了SecuCoGen，一个精心策划的数据集，针对21种关键漏洞类型。SecuCoGen包含180个样本，并作为进行三个关键的与代码相关任务的实验的基础：代码生成、代码修复和漏洞分类，其中安全性得到了极大的强调。我们的实验结果表明，现有模型在处理安全问题时经常被忽视了。

    Large language models (LLMs) have brought significant advancements to code generation, benefiting both novice and experienced developers. However, their training using unsanitized data from open-source repositories, like GitHub, introduces the risk of inadvertently propagating security vulnerabilities. To effectively mitigate this concern, this paper presents a comprehensive study focused on evaluating and enhancing code LLMs from a software security perspective. We introduce SecuCoGen\footnote{SecuCoGen has been uploaded as supplemental material and will be made publicly available after publication.}, a meticulously curated dataset targeting 21 critical vulnerability types. SecuCoGen comprises 180 samples and serves as the foundation for conducting experiments on three crucial code-related tasks: code generation, code repair and vulnerability classification, with a strong emphasis on security. Our experimental results reveal that existing models often overlook security concerns during
    
[^39]: rTisane: 外部化概念模型提高与领域知识的互动并提高统计模型质量

    rTisane: Externalizing conceptual models for data analysis increases engagement with domain knowledge and improves statistical model quality. (arXiv:2310.16262v1 [cs.HC])

    [http://arxiv.org/abs/2310.16262](http://arxiv.org/abs/2310.16262)

    rTisane是一种使用DSL外部化概念模型的工具，能够帮助分析师更深入地参与并准确地表达他们的假设，从而提高统计模型质量。

    

    统计模型应准确反映分析师对变量及其关系的领域知识。尽管近期工具允许分析师表达这些假设并使用它们产生结果的统计模型，但是目前不清楚分析师想要表达什么以及外部化如何影响统计模型质量。本文填补了这些空白。我们首先进行了一项探索性研究，研究分析师使用特定领域语言（DSL）来表达概念模型。我们观察到分析师更倾向于详细描述变量之间的关系，并希望能够允许并稍后解决概念模型中的歧义。我们利用这些发现开发了rTisane，一种用于表达概念模型的DSL，并配合一个交互式消歧过程。在一项受控评估中，我们发现rTisane的DSL能帮助分析师更深入地参与并准确地外部化他们的假设。rTisane还能产生符合分析师假设的统计模型，保持分析师假设的一致性。

    Statistical models should accurately reflect analysts' domain knowledge about variables and their relationships. While recent tools let analysts express these assumptions and use them to produce a resulting statistical model, it remains unclear what analysts want to express and how externalization impacts statistical model quality. This paper addresses these gaps. We first conduct an exploratory study of analysts using a domain-specific language (DSL) to express conceptual models. We observe a preference for detailing how variables relate and a desire to allow, and then later resolve, ambiguity in their conceptual models. We leverage these findings to develop rTisane, a DSL for expressing conceptual models augmented with an interactive disambiguation process. In a controlled evaluation, we find that rTisane's DSL helps analysts engage more deeply with and accurately externalize their assumptions. rTisane also leads to statistical models that match analysts' assumptions, maintain analys
    
[^40]: 一种因果解缠离散多粒度图分类方法

    A Causal Disentangled Multi-Granularity Graph Classification Method. (arXiv:2310.16256v1 [cs.LG])

    [http://arxiv.org/abs/2310.16256](http://arxiv.org/abs/2310.16256)

    这篇论文提出了一种因果解缠离散多粒度图分类方法（CDM-GNN），该方法能够解决图数据的多粒度特性，实现了对图中重要子结构和偏差部分的解析，并用于图分类任务中。

    

    实际生活中广泛存在大量数据和复杂结构的图数据。将图数据映射到低维嵌入空间是必要的。图分类是一项关键的图任务，主要依赖于识别图中的重要子结构。目前，一些图分类方法没有结合图数据的多粒度特性。建模中缺乏粒度区分导致模型中关键信息和虚假相关性混淆。因此，实现可信和可解释的模型的目标变得具有挑战性。本文提出了一种因果解缠离散多粒度图表示学习方法（CDM-GNN）来解决这个挑战。CDM-GNN模型从多粒度的角度对图中的重要子结构和偏差部分进行解缠离。CDM-GNN模型的解缠离揭示了重要和偏差部分，为其分类任务奠定了基础。

    Graph data widely exists in real life, with large amounts of data and complex structures. It is necessary to map graph data to low-dimensional embedding. Graph classification, a critical graph task, mainly relies on identifying the important substructures within the graph. At present, some graph classification methods do not combine the multi-granularity characteristics of graph data. This lack of granularity distinction in modeling leads to a conflation of key information and false correlations within the model. So, achieving the desired goal of a credible and interpretable model becomes challenging. This paper proposes a causal disentangled multi-granularity graph representation learning method (CDM-GNN) to solve this challenge. The CDM-GNN model disentangles the important substructures and bias parts within the graph from a multi-granularity perspective. The disentanglement of the CDM-GNN model reveals important and bias parts, forming the foundation for its classification task, spe
    
[^41]: ConDefects：解决基于LLM的故障定位和程序修复中的数据泄漏问题的新数据集

    ConDefects: A New Dataset to Address the Data Leakage Concern for LLM-based Fault Localization and Program Repair. (arXiv:2310.16253v1 [cs.SE])

    [http://arxiv.org/abs/2310.16253](http://arxiv.org/abs/2310.16253)

    ConDefects是一个新的数据集，专门解决基于LLM的故障定位和程序修复中的数据泄漏问题。该数据集包含了1,254个Java有错误的程序和1,625个Python有错误的程序，来自于线上竞赛平台AtCoder。每一个错误都配有错误位置和相应的修复代码版本，使其适用于故障定位和程序修复的研究。

    

    随着对于大型语言模型（LLMs）在故障定位和程序修复中的兴趣增加，确保LLM方法的完整性和普适性变得非常重要。现有广泛采用的这些任务的基准代码是在LLMs的兴起之前编写的，可能包含在现有流行的LLMs的训练数据中，从而面临数据泄漏的威胁，导致误导性乐观的性能指标。为了解决这个问题，我们引入了“ConDefects”这个新颖的数据集，精心策划以消除这种重叠。ConDefects包含1,254个Java有错误的程序和1,625个Python有错误的程序。所有这些程序都来自线上竞赛平台AtCoder，并在2021年10月至2023年9月之间产生。我们将每个错误与错误位置和相应的修复代码版本配对，使其适用于故障定位和程序修复相关的研究。我们还提供...

    With the growing interest on Large Language Models (LLMs) for fault localization and program repair, ensuring the integrity and generalizability of the LLM-based methods becomes paramount. The code in existing widely-adopted benchmarks for these tasks was written before the the bloom of LLMs and may be included in the training data of existing popular LLMs, thereby suffering from the threat of data leakage, leading to misleadingly optimistic performance metrics. To address this issue, we introduce "ConDefects", a novel dataset of real faults meticulously curated to eliminate such overlap. ConDefects contains 1,254 Java faulty programs and 1,625 Python faulty programs. All these programs are sourced from the online competition platform AtCoder and were produced between October 2021 and September 2023. We pair each fault with fault locations and the corresponding repaired code versions, making it tailored for in fault localization and program repair related research. We also provide inte
    
[^42]: Speakerly：一种基于语音的文本创作辅助工具

    Speakerly: A Voice-based Writing Assistant for Text Composition. (arXiv:2310.16251v1 [cs.CL])

    [http://arxiv.org/abs/2310.16251](http://arxiv.org/abs/2310.16251)

    Speakerly是一种基于语音的文本创作辅助工具，用户可通过指令或口述与系统进行交互，系统生成格式良好、连贯的文档。该系统使用小型任务特定模型和预训练语言模型，实现快速有效的文本创作，并支持各种输入模式以提高可用性。

    

    我们提出了Speakerly，一种新的实时语音文本创作辅助系统，可帮助用户在各种用例中进行文本创作，如电子邮件、即时通讯和笔记。用户可以通过指令或口述与系统进行交互，系统生成格式良好、连贯的文档。我们描述了系统架构，并详细介绍了在构建和部署如此规模的系统时如何解决各种挑战。具体而言，我们的系统使用了一组小型、任务特定的模型以及预训练的语言模型，实现快速有效的文本创作，同时支持各种输入模式以提高可用性。

    We present Speakerly, a new real-time voice-based writing assistance system that helps users with text composition across various use cases such as emails, instant messages, and notes. The user can interact with the system through instructions or dictation, and the system generates a well-formatted and coherent document. We describe the system architecture and detail how we address the various challenges while building and deploying such a system at scale. More specifically, our system uses a combination of small, task-specific models as well as pre-trained language models for fast and effective text composition while supporting a variety of input modes for better usability.
    
[^43]: 基于图邻接矩阵的特征向量的聚类工具用于有限元模型的研究

    A clustering tool for interrogating finite element models based on eigenvectors of graph adjacency. (arXiv:2310.16249v1 [cs.CE])

    [http://arxiv.org/abs/2310.16249](http://arxiv.org/abs/2310.16249)

    该论文介绍了一种基于图邻接矩阵特征向量的聚类工具，用于调试有限元模型中的错误，并在商业结构FE套件中成功部署，并且已被用户用于真实世界的FE模型调试。

    

    本文介绍了一种无监督学习算法，用于调试有限元（FE）仿真模型中的错误，并详细说明了该算法的生产化过程。该算法使用刚度矩阵的邻接性质对FE模型的自由度进行聚类。该算法已经作为一种名为“模型稳定性分析”工具部署在商业结构FE套件Oasys GSA（www.oasys-software.com/gsa）中。它已经成功地被最终用户用于调试真实世界的FE模型，并且我们展示了该工具的实际应用示例。

    This note introduces an unsupervised learning algorithm to debug errors in finite element (FE) simulation models and details how it was productionised. The algorithm clusters degrees of freedom in the FE model using numerical properties of the adjacency of its stiffness matrix. The algorithm has been deployed as a tool called `Model Stability Analysis' tool within the commercial structural FE suite Oasys GSA (www.oasys-software.com/gsa). It has been used successfully by end-users for debugging real world FE models and we present examples of the tool in action.
    
[^44]: 无监督图像分割的像素级聚类网络

    Pixel-Level Clustering Network for Unsupervised Image Segmentation. (arXiv:2310.16234v1 [cs.CV])

    [http://arxiv.org/abs/2310.16234](http://arxiv.org/abs/2310.16234)

    本文提出了一个无监督的像素级聚类框架，用于将图像分割成区域，而不需要使用地面真值注释。通过特征嵌入、特征统计计算、图像重构和超像素分割等模块，以及利用超像素内部一致性和邻近超像素之间的相似性/不相似性进行训练策略，实现了准确的无监督分割。此外，还提出了后处理方法来避免过分分割。

    

    尽管图像分割在各种计算机视觉应用中都至关重要，如自动驾驶、抓取和机器人导航，但为训练所有像素级别上的对象进行注释几乎是不可能的。因此，研究无监督图像分割方法非常重要。在本文中，我们提出了一个像素级聚类框架，将图像分割成区域，而不使用地面真值注释。所提出的框架包括具有注意机制的特征嵌入模块、特征统计计算模块、图像重构和超像素分割，以实现准确的无监督分割。此外，我们提出了一种训练策略，利用每个超像素内部一致性、邻近超像素之间的相似性/不相似性以及图像的结构相似性。为了避免超像素损失引起的过分分割，我们还提出了一种后处理方法。此外，我们还介绍了一种新的评价指标，用于评估分割性能并与现有方法进行比较。

    While image segmentation is crucial in various computer vision applications, such as autonomous driving, grasping, and robot navigation, annotating all objects at the pixel-level for training is nearly impossible. Therefore, the study of unsupervised image segmentation methods is essential. In this paper, we present a pixel-level clustering framework for segmenting images into regions without using ground truth annotations. The proposed framework includes feature embedding modules with an attention mechanism, a feature statistics computing module, image reconstruction, and superpixel segmentation to achieve accurate unsupervised segmentation. Additionally, we propose a training strategy that utilizes intra-consistency within each superpixel, inter-similarity/dissimilarity between neighboring superpixels, and structural similarity between images. To avoid potential over-segmentation caused by superpixel-based losses, we also propose a post-processing method. Furthermore, we present an e
    
[^45]: CleanCoNLL: 一种几乎无噪声的命名实体识别数据集

    CleanCoNLL: A Nearly Noise-Free Named Entity Recognition Dataset. (arXiv:2310.16225v1 [cs.CL])

    [http://arxiv.org/abs/2310.16225](http://arxiv.org/abs/2310.16225)

    CleanCoNLL是一种几乎无噪声的命名实体识别数据集，通过全面重标记和自动一致性检查来纠正CoNLL-03中的注释错误，提高了最先进方法的F1分数，并减少了因注释缺失而误判的情况。

    

    CoNLL-03语料库被认为是最著名和广泛使用的命名实体识别（NER）基准数据集。然而，之前的研究发现了大量的注释错误、不完整性和数据不一致性。这给客观比较NER方法和分析其错误带来了挑战，因为目前最先进的模型在CoNLL-03中达到的F1分数与估计的噪声水平相当甚至更高。为了解决这个问题，我们通过自动一致性检查辅助的全面重标记工作来纠正英文CoNLL-03中所有标签的7.0％。我们的工作还为了更好地解释NER标签和作为附加保证注释质量而添加了一个实体链接注释层。我们的实验证明，最先进的方法不仅在我们的数据上达到了显著更高的F1分数（97.1％），而且关键是正确预测被错误地计算为错误的比例由于注释的缺失得到了改善。

    The CoNLL-03 corpus is arguably the most well-known and utilized benchmark dataset for named entity recognition (NER). However, prior works found significant numbers of annotation errors, incompleteness, and inconsistencies in the data. This poses challenges to objectively comparing NER approaches and analyzing their errors, as current state-of-the-art models achieve F1-scores that are comparable to or even exceed the estimated noise level in CoNLL-03. To address this issue, we present a comprehensive relabeling effort assisted by automatic consistency checking that corrects 7.0% of all labels in the English CoNLL-03. Our effort adds a layer of entity linking annotation both for better explainability of NER labels and as additional safeguard of annotation quality. Our experimental evaluation finds not only that state-of-the-art approaches reach significantly higher F1-scores (97.1%) on our data, but crucially that the share of correct predictions falsely counted as errors due to annota
    
[^46]: 分层随机平滑

    Hierarchical Randomized Smoothing. (arXiv:2310.16221v1 [cs.LG])

    [http://arxiv.org/abs/2310.16221](http://arxiv.org/abs/2310.16221)

    分层随机平滑是一种在复杂数据上进行鲁棒性认证的解决方案，通过只在一个对象的子集上添加随机噪声，以更有针对性的方式提供了更强的鲁棒性保证和高准确性。

    

    真实世界的数据是复杂的，通常由可分解为多个实体的对象组成（例如，将图像分解为像素，将图形分解为相互连接的节点）。随机平滑是一种强大的框架，可以使模型在其输入的微小变化上具有证明的鲁棒性-通过在分类之前随机添加噪声来保证多数投票的鲁棒性。然而，当对手不是任意干扰整个对象（例如图像），而是对象的某个实体的子集（例如像素）时，通过随机平滑对这种复杂数据进行鲁棒性认证是具有挑战性的。作为解决方案，我们引入了分层随机平滑：我们通过仅在随机选择的实体子集上添加随机噪声来部分平滑对象。通过以比现有方法更有针对性的方式添加噪声，我们获得更强的鲁棒性保证，同时保持高准确性。我们使用不同的噪声分布初始化分层平滑，得到了新的鲁棒性保证。

    Real-world data is complex and often consists of objects that can be decomposed into multiple entities (e.g. images into pixels, graphs into interconnected nodes). Randomized smoothing is a powerful framework for making models provably robust against small changes to their inputs - by guaranteeing robustness of the majority vote when randomly adding noise before classification. Yet, certifying robustness on such complex data via randomized smoothing is challenging when adversaries do not arbitrarily perturb entire objects (e.g. images) but only a subset of their entities (e.g. pixels). As a solution, we introduce hierarchical randomized smoothing: We partially smooth objects by adding random noise only on a randomly selected subset of their entities. By adding noise in a more targeted manner than existing methods we obtain stronger robustness guarantees while maintaining high accuracy. We initialize hierarchical smoothing using different noising distributions, yielding novel robustness
    
[^47]: 大型语言模型的知识编辑：一项综述

    Knowledge Editing for Large Language Models: A Survey. (arXiv:2310.16218v1 [cs.CL])

    [http://arxiv.org/abs/2310.16218](http://arxiv.org/abs/2310.16218)

    大型语言模型(LLMs)在学术和工业领域具有巨大潜力。本文综述了LLMs的知识编辑问题，强调了需要开发有效和高效的技术来更新预训练LLMs以纳入新知识的重要性。

    

    大型语言模型(LLMs)近期以其出色的理解、分析和生成文本的能力，根据其广博的知识和推理能力，改变了学术和工业领域的格局。然而，LLMs的一个主要缺点是它们在预训练时需要大量计算资源，因为其参数数量前所未有。当需要频繁引入新知识到预训练模型中时，这个缺点更加显著。因此，开发有效和高效的技术来更新预训练LLMs是必不可少的。传统方法是通过直接微调将新知识编码到预训练LLMs中。然而，简单地重新训练LLMs可能计算资源密集，并且存在将与模型更新无关的有价值的预训练知识退化的风险。最近，基于知识的模型编辑(KME)引起了越来越多的关注，旨在精确修改LLMs以纳入特定的知识。

    Large language models (LLMs) have recently transformed both the academic and industrial landscapes due to their remarkable capacity to understand, analyze, and generate texts based on their vast knowledge and reasoning ability. Nevertheless, one major drawback of LLMs is their substantial computational cost for pre-training due to their unprecedented amounts of parameters. The disadvantage is exacerbated when new knowledge frequently needs to be introduced into the pre-trained model. Therefore, it is imperative to develop effective and efficient techniques to update pre-trained LLMs. Traditional methods encode new knowledge in pre-trained LLMs through direct fine-tuning. However, naively re-training LLMs can be computationally intensive and risks degenerating valuable pre-trained knowledge irrelevant to the update in the model. Recently, Knowledge-based Model Editing (KME) has attracted increasing attention, which aims to precisely modify the LLMs to incorporate specific knowledge, wit
    
[^48]: 长度对于文档级语义而言既是诅咒也是福音

    Length is a Curse and a Blessing for Document-level Semantics. (arXiv:2310.16193v1 [cs.CL])

    [http://arxiv.org/abs/2310.16193](http://arxiv.org/abs/2310.16193)

    本文研究了基于对比学习的模型在长度上的泛化能力，并提出了一个仅依赖于文档长度的无监督学习方法。研究发现，延长文档的长度会加 intensify 达到的高内部相似性，并且这种等向性的表现高度依赖于文本长度范围。基于这些发现，提出了一个简单而通用的文档表示学习框架，用于实现语义鲁棒的句子表示学习。

    

    最近几年，对比学习（CL）已经广泛应用于从预训练的语言模型中恢复句子和文档级别的编码能力。在这项工作中，我们质疑基于CL的模型的长度泛化能力，即它们对于长度引起的语义变化的易受攻击的程度。我们验证了长度易受攻击是一个重要但被忽视的研究空白，并且我们可以设计仅依赖于文档长度提供的语义信号的无监督CL方法。我们首先推导了长度攻击的理论基础，表明延长文档会加 intensify 已经由CL带来的高内部文档相似性。此外，我们发现CL承诺的等向性高度依赖于训练中暴露的文本长度范围。受到这些发现的启发，我们引入了一个简单而通用的文档表示学习框架，LA(SER)$^{3}$: 长度不受限的自我参照用于语义鲁棒的句子表示学习

    In recent years, contrastive learning (CL) has been extensively utilized to recover sentence and document-level encoding capability from pre-trained language models. In this work, we question the length generalizability of CL-based models, i.e., their vulnerability towards length-induced semantic shift. We verify not only that length vulnerability is a significant yet overlooked research gap, but we can devise unsupervised CL methods solely depending on the semantic signal provided by document length. We first derive the theoretical foundations underlying length attacks, showing that elongating a document would intensify the high intra-document similarity that is already brought by CL. Moreover, we found that isotropy promised by CL is highly dependent on the length range of text exposed in training. Inspired by these findings, we introduce a simple yet universal document representation learning framework, LA(SER)$^{3}$: length-agnostic self-reference for semantically robust sentence r
    
[^49]: 通过回溯法纠正，减少摘要中的幻觉

    Correction with Backtracking Reduces Hallucination in Summarization. (arXiv:2310.16176v1 [cs.CL])

    [http://arxiv.org/abs/2310.16176](http://arxiv.org/abs/2310.16176)

    本文介绍了一种简单而有效的技术，CoBa，用于减少摘要中的幻觉。该方法通过测量条件词概率和上下文词距离的统计信息进行幻觉检测，并通过直观的回溯法进行减轻。实验证明，CoBa在减少摘要幻觉方面是有效且高效的。

    

    摘要生成旨在生成源文件的自然语言摘要，既简洁又保留重要元素。尽管最近取得了一些进展，但神经文本摘要模型容易产生幻觉（或更准确地说是混淆），即生成的摘要包含源文件中没有根据的细节。在本文中，我们引入了一种简单而有效的技术，CoBa，用于减少摘要中的幻觉。该方法基于两个步骤：幻觉检测和减轻。我们展示了通过测量有关条件词概率和上下文词距离的简单统计信息可以实现前者。此外，我们还证明了直观的回溯法在减轻幻觉方面的惊人效果。我们在三个文本摘要基准数据集上对所提出的方法进行了全面评估。结果表明，CoBa在减少摘要幻觉方面是有效且高效的。

    Abstractive summarization aims at generating natural language summaries of a source document that are succinct while preserving the important elements. Despite recent advances, neural text summarization models are known to be susceptible to hallucinating (or more correctly confabulating), that is to produce summaries with details that are not grounded in the source document. In this paper, we introduce a simple yet efficient technique, CoBa, to reduce hallucination in abstractive summarization. The approach is based on two steps: hallucination detection and mitigation. We show that the former can be achieved through measuring simple statistics about conditional word probabilities and distance to context words. Further, we demonstrate that straight-forward backtracking is surprisingly effective at mitigation. We thoroughly evaluate the proposed method with prior art on three benchmark datasets for text summarization. The results show that CoBa is effective and efficient in reducing hall
    
[^50]: 基于论证的上下文感知特征归因

    Context-aware feature attribution through argumentation. (arXiv:2310.16157v1 [cs.LG])

    [http://arxiv.org/abs/2310.16157](http://arxiv.org/abs/2310.16157)

    本论文提出了一种基于论证的上下文感知特征归因方法，以解决机器学习和数据分析中特征归因的挑战。该方法利用广义可加模型和梯度方法与替代模型相结合，同时考虑用户的背景信息，从而提高了归因的准确性和解释性。

    

    特征归因是机器学习和数据分析中的基本任务，涉及确定个别特征或变量对模型输出的贡献。这个过程有助于确定预测结果最重要的特征。特征归因方法的历史可以追溯到广义可加模型 (GAMs)，它通过将因变量和自变量之间的非线性关系纳入模型，扩展了线性回归模型。近年来，基于梯度的方法和替代模型已经被应用于揭示复杂的人工智能 (AI) 系统，但这些方法存在一些局限性。GAMs 往往能够达到较低的准确性，基于梯度的方法很难解释，替代模型通常存在稳定性和保真度问题。此外，大部分现有方法都没有考虑用户的背景，而用户的背景可能会对他们的偏好产生重要影响。为了解决这些限制并推进当前的研究

    Feature attribution is a fundamental task in both machine learning and data analysis, which involves determining the contribution of individual features or variables to a model's output. This process helps identify the most important features for predicting an outcome. The history of feature attribution methods can be traced back to General Additive Models (GAMs), which extend linear regression models by incorporating non-linear relationships between dependent and independent variables. In recent years, gradient-based methods and surrogate models have been applied to unravel complex Artificial Intelligence (AI) systems, but these methods have limitations. GAMs tend to achieve lower accuracy, gradient-based methods can be difficult to interpret, and surrogate models often suffer from stability and fidelity issues. Furthermore, most existing methods do not consider users' contexts, which can significantly influence their preferences. To address these limitations and advance the current s
    
[^51]: Yin Yang卷积网络：通过对立分析提取图像流形

    Yin Yang Convolutional Nets: Image Manifold Extraction by the Analysis of Opposites. (arXiv:2310.16148v1 [cs.CV])

    [http://arxiv.org/abs/2310.16148](http://arxiv.org/abs/2310.16148)

    提出了Yin Yang卷积网络，通过对立分析提取图像流形，在CIFAR-10数据集上达到了State-of-the-Art的效能，并且相对于之前的SOTA模型，参数减少了150k。

    

    计算机视觉在训练优化、新的架构（纯注意力、高效块、视觉语言模型、生成模型等）等方面取得了一些进步。这些进步改善了分类等多个任务的性能。然而，大多数这些模型都集中于与大脑相关的现实神经科学方法的修改。在这项工作中，我们采用更具生物启发的方法，并提出了Yin Yang卷积网络，这是一种提取视觉流形的架构，它的块旨在在初始层分离颜色和形状的分析，模拟枕叶的操作。我们的结果表明，在CIFAR-10数据集上，我们的架构在参数较低的架构中提供了最先进的效能。我们的第一个模型达到了93.32％的测试准确率，比该类别中更早的最佳结果高出0.8％，同时参数减少了15万个（总共726k）。

    Computer vision in general presented several advances such as training optimizations, new architectures (pure attention, efficient block, vision language models, generative models, among others). This have improved performance in several tasks such as classification, and others. However, the majority of these models focus on modifications that are taking distance from realistic neuroscientific approaches related to the brain. In this work, we adopt a more bio-inspired approach and present the Yin Yang Convolutional Network, an architecture that extracts visual manifold, its blocks are intended to separate analysis of colors and forms at its initial layers, simulating occipital lobe's operations. Our results shows that our architecture provides State-of-the-Art efficiency among low parameter architectures in the dataset CIFAR-10. Our first model reached 93.32\% test accuracy, 0.8\% more than the older SOTA in this category, while having 150k less parameters (726k in total). Our second m
    
[^52]: PreWoMe:利用预设为长篇问答中的工作记忆进行问题回答

    PreWoMe: Exploiting Presuppositions as Working Memory for Long Form Question Answering. (arXiv:2310.16147v1 [cs.CL])

    [http://arxiv.org/abs/2310.16147](http://arxiv.org/abs/2310.16147)

    PreWoMe是一种处理长篇问答中信息检索问题的统一方法，通过提取问题中的预设并利用其作为工作记忆来生成反馈和行动，不仅能有效解决误导性问题，而且适用于处理正常问题，证明了在实际问答场景中利用预设、反馈和行动的有效性。

    

    长篇问答中的信息检索问题常常由于问题中的模糊或错误预设而误导。虽然许多现有方法可以处理误导性问题，但它们针对的是有限的问题，很难适应实际情况中不可预测的输入特征。在这项工作中，我们提出了PreWoMe，这是一种统一的方法，能够处理任何类型的信息检索问题。PreWoMe的关键思想是提取问题中的预设，并将其作为工作记忆来生成对问题的反馈和行动。我们的实验证明，PreWoMe不仅在解决误导性问题方面有效，而且在处理正常问题方面也很有效，从而证明了在实际问答场景中利用预设、反馈和行动的有效性。

    Information-seeking questions in long-form question answering (LFQA) often prove misleading due to ambiguity or false presupposition in the question. While many existing approaches handle misleading questions, they are tailored to limited questions, which are insufficient in a real-world setting with unpredictable input characteristics. In this work, we propose PreWoMe, a unified approach capable of handling any type of information-seeking question. The key idea of PreWoMe involves extracting presuppositions in the question and exploiting them as working memory to generate feedback and action about the question. Our experiment shows that PreWoMe is effective not only in tackling misleading questions but also in handling normal ones, thereby demonstrating the effectiveness of leveraging presuppositions, feedback, and action for real-world QA settings.
    
[^53]: Clinfo.ai:用科学文献回答医学问题的开源检索增强型大型语言模型系统

    Clinfo.ai: An Open-Source Retrieval-Augmented Large Language Model System for Answering Medical Questions using Scientific Literature. (arXiv:2310.16146v1 [cs.IR])

    [http://arxiv.org/abs/2310.16146](http://arxiv.org/abs/2310.16146)

    Clinfo.ai是一个开源的系统，使用科学文献回答医学问题。研究人员提出了一个信息检索和抽象概括任务，发布了相应的数据集，并进行了评估。

    

    随着医学文献的快速增长，医生和研究人员很难及时跟上并总结最近的相关发现。虽然现在存在几个基于大型语言模型（LLMs）的闭源摘要工具，但其输出结果缺乏严格和系统的评估。此外，缺乏高质量的数据集和适当的基准任务来评估这些工具。我们通过四个贡献来解决这些问题：我们发布了名为Clinfo.ai的开源WebApp，它基于动态检索的科学文献回答临床问题；我们指定了一个信息检索和抽象概括任务，以评估这种检索增强型LLM系统的性能；我们发布了一个包含200个问题及其对应答案的数据集，我们将其命名为PubMed检索和综述（PubMedRS-200）；并报告了Cli的基准结果。

    The quickly-expanding nature of published medical literature makes it challenging for clinicians and researchers to keep up with and summarize recent, relevant findings in a timely manner. While several closed-source summarization tools based on large language models (LLMs) now exist, rigorous and systematic evaluations of their outputs are lacking. Furthermore, there is a paucity of high-quality datasets and appropriate benchmark tasks with which to evaluate these tools. We address these issues with four contributions: we release Clinfo.ai, an open-source WebApp that answers clinical questions based on dynamically retrieved scientific literature; we specify an information retrieval and abstractive summarization task to evaluate the performance of such retrieval-augmented LLM systems; we release a dataset of 200 questions and corresponding answers derived from published systematic reviews, which we name PubMed Retrieval and Synthesis (PubMedRS-200); and report benchmark results for Cli
    
[^54]: 有限记忆容量的语言模型捕捉人类句子处理中的干扰

    A Language Model with Limited Memory Capacity Captures Interference in Human Sentence Processing. (arXiv:2310.16142v1 [cs.CL])

    [http://arxiv.org/abs/2310.16142](http://arxiv.org/abs/2310.16142)

    开发了一个循环神经语言模型，通过使用单个自我注意头紧密模拟了认知理论中假设的记忆系统，并捕捉到人类句子处理中的干扰。

    

    人类句子处理困难的两个核心因素被认为是期望和来自工作记忆的检索。最近的一个尝试，旨在创建一个综合认知模型，将这两个因素整合在一起，依赖于transformer语言模型的自我注意机制和人类句子处理中基于暗示的工作记忆检索理论之间的相似之处。（Ryu and Lewis, 2021）.虽然Ryu和Lewis展示了GPT-2的特殊自注意头中的注意模式与基于相似性的干扰的关键预测一致，这是基于暗示的检索模型，但他们的方法需要识别出句法特化的自注意头，并做出认知上不合理的假设，即数百次的内存检索操作是并行进行的。在本研究中，我们开发了一个具有单个自我注意头的循环神经语言模型，更贴近认知理论所假设的记忆系统。我们展示了我们模型的...

    Two of the central factors believed to underpin human sentence processing difficulty are expectations and retrieval from working memory. A recent attempt to create a unified cognitive model integrating these two factors relied on the parallels between the self-attention mechanism of transformer language models and cue-based retrieval theories of working memory in human sentence processing (Ryu and Lewis 2021). While Ryu and Lewis show that attention patterns in specialized attention heads of GPT-2 are consistent with similarity-based interference, a key prediction of cue-based retrieval models, their method requires identifying syntactically specialized attention heads, and makes the cognitively implausible assumption that hundreds of memory retrieval operations take place in parallel. In the present work, we develop a recurrent neural language model with a single self-attention head, which more closely parallels the memory system assumed by cognitive theories. We show that our model's
    
[^55]: 基于上下文的可解释知识图谱推荐

    Context-aware explainable recommendations over knowledge graphs. (arXiv:2310.16141v1 [cs.IR])

    [http://arxiv.org/abs/2310.16141](http://arxiv.org/abs/2310.16141)

    本文提出了CA-KGCN，一个基于上下文的推荐系统框架，能够将知识图谱中的语义关系纳入建模，提高推荐准确性和可解释性。

    

    知识图谱包含与项目相关的丰富语义关系，将这些语义关系纳入推荐系统有助于探索项目的潜在连接，从而提高预测准确性并增强推荐的可解释性。然而，这种可解释性不适应用户的情境，而情境可以显著影响其偏好。本文提出了CA-KGCN（上下文感知知识图谱卷积网络），这是一个端到端的框架，可以根据用户的情境来建模其偏好，并将与项目相关的丰富语义关系纳入知识图谱中。该框架捕捉用户对不同因素的注意力：上下文和项目特征。具体而言，该框架可以根据特定情境建模用户的偏好并提供适应给定情境的解释。在三个真实世界数据集上的实验证明了我们框架的有效性。

    Knowledge graphs contain rich semantic relationships related to items and incorporating such semantic relationships into recommender systems helps to explore the latent connections of items, thus improving the accuracy of prediction and enhancing the explainability of recommendations. However, such explainability is not adapted to users' contexts, which can significantly influence their preferences. In this work, we propose CA-KGCN (Context-Aware Knowledge Graph Convolutional Network), an end-to-end framework that can model users' preferences adapted to their contexts and can incorporate rich semantic relationships in the knowledge graph related to items. This framework captures users' attention to different factors: contexts and features of items. More specifically, the framework can model users' preferences adapted to their contexts and provide explanations adapted to the given context. Experiments on three real-world datasets show the effectiveness of our framework: modeling users' 
    
[^56]: Alquist 5.0：对话树与生成模型相结合。增强SocialBot对话的一种新方法。

    Alquist 5.0: Dialogue Trees Meet Generative Models. A Novel Approach for Enhancing SocialBot Conversations. (arXiv:2310.16119v1 [cs.LG])

    [http://arxiv.org/abs/2310.16119](http://arxiv.org/abs/2310.16119)

    Alquist 5.0是一种新的SocialBot系统，通过将对话树和生成模型相结合，以及引入NRG Barista和支持多模式设备，提高了用户对话体验，并保持了共情和知识型对话能力。

    

    我们介绍了我们的SocialBot- Alquist 5.0-，该系统是为Alexa Prize SocialBot大挑战5开发的。在我们系统的前几个版本基础上，我们引入了NRG Barista，并概述了将Barista整合到我们的SocialBot中的几种创新方法，从而改善了整体的对话体验。此外，我们还扩展了我们的SocialBot以支持多模式设备。本文提供了关于Alquist 5.0开发的见解，该系统在满足用户不断变化的期望的同时，保持了对各种主题的共情和知识型对话能力。

    We present our SocialBot -- Alquist~5.0 -- developed for the Alexa Prize SocialBot Grand Challenge~5. Building upon previous versions of our system, we introduce the NRG Barista and outline several innovative approaches for integrating Barista into our SocialBot, improving the overall conversational experience. Additionally, we extend our SocialBot to support multimodal devices. This paper offers insights into the development of Alquist~5.0, which meets evolving user expectations while maintaining empathetic and knowledgeable conversational abilities across diverse topics.
    
[^57]: 解剖学感知的半监督图像分割的不确定性研究

    Anatomically-aware Uncertainty for Semi-supervised Image Segmentation. (arXiv:2310.16099v1 [cs.CV])

    [http://arxiv.org/abs/2310.16099](http://arxiv.org/abs/2310.16099)

    本研究提出了一种解剖学感知的方法，通过利用分割掩模中的全局信息来估计半监督图像分割的不确定性。该方法克服了传统不确定性估计方法的高计算复杂性和对像素级差异的限制。

    

    半监督学习通过利用无标签数据来放宽对图像分割大规模像素级标注数据的需求。利用无标签数据的一个重要方法是对模型预测进行规范化。然而，由于无标签数据的预测可能不可靠，通常需要借助不确定性感知的方法逐渐学习有意义和可靠的预测。然而，不确定性估计方法依赖于模型预测的多次推断，每个训练步骤都需要计算，这在计算上是昂贵的。此外，这些不确定性图像捕捉像素级差异，并不能考虑全局信息。本研究提出了一种新的方法，通过利用分割掩模中的全局信息来估计分割不确定性。更确切地说，首先学习解剖学感知的表示来建模可用的分割掩模。然后，该学习表示将新的分割预测映射到一个解剖结构上。

    Semi-supervised learning relaxes the need of large pixel-wise labeled datasets for image segmentation by leveraging unlabeled data. A prominent way to exploit unlabeled data is to regularize model predictions. Since the predictions of unlabeled data can be unreliable, uncertainty-aware schemes are typically employed to gradually learn from meaningful and reliable predictions. Uncertainty estimation methods, however, rely on multiple inferences from the model predictions that must be computed for each training step, which is computationally expensive. Moreover, these uncertainty maps capture pixel-wise disparities and do not consider global information. This work proposes a novel method to estimate segmentation uncertainty by leveraging global information from the segmentation masks. More precisely, an anatomically-aware representation is first learnt to model the available segmentation masks. The learnt representation thereupon maps the prediction of a new segmentation into an anatomic
    
[^58]: 使用卷积LSTM在大学校园中预测电网频率

    Grid Frequency Forecasting in University Campuses using Convolutional LSTM. (arXiv:2310.16071v1 [cs.LG])

    [http://arxiv.org/abs/2310.16071](http://arxiv.org/abs/2310.16071)

    该论文介绍了一种创新的方法，利用卷积神经网络和长短期记忆网络建立稳健的时间序列预测模型，用于预测电网频率。个体化的卷积LSTM模型可以独立地为大学校园内的建筑进行训练和评估，并且结果证明了该模型的优越性。

    

    现代电网面临着越来越复杂的问题，主要源于可再生能源的整合和消费模式的演变。本文引入了一种创新的方法，利用卷积神经网络（CNN）和长短期记忆（LSTM）网络建立稳健的时间序列预测模型，用于电网频率。这些模型有效地捕捉了电网频率数据中固有的时空复杂性，显著提高了预测准确性，增强了电网的可靠性。研究探讨了大学校园内个体化的卷积LSTM（ConvLSTM）模型的潜力和发展，使它们能够独立地针对每一栋建筑进行训练和评估。个体ConvLSTM模型基于每栋校园建筑的用电数据进行训练，并根据历史趋势预测电网频率。结果有力地证明了所提出模型的优越性。

    The modern power grid is facing increasing complexities, primarily stemming from the integration of renewable energy sources and evolving consumption patterns. This paper introduces an innovative methodology that harnesses Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks to establish robust time series forecasting models for grid frequency. These models effectively capture the spatiotemporal intricacies inherent in grid frequency data, significantly enhancing prediction accuracy and bolstering power grid reliability. The research explores the potential and development of individualized Convolutional LSTM (ConvLSTM) models for buildings within a university campus, enabling them to be independently trained and evaluated for each building. Individual ConvLSTM models are trained on power consumption data for each campus building and forecast the grid frequency based on historical trends. The results convincingly demonstrate the superiority of the proposed mode
    
[^59]: 超维变换：函数的全息表示

    The Hyperdimensional Transform: a Holographic Representation of Functions. (arXiv:2310.16065v1 [cs.LG])

    [http://arxiv.org/abs/2310.16065](http://arxiv.org/abs/2310.16065)

    这项研究介绍了一种新型的积分变换-超维变换，它将函数转换为噪声鲁棒、全息、高维表示的超维向量，与其他积分变换紧密相关，并为超维领域提供了理论基础和新的洞察。

    

    积分变换是将函数映射到更容易表征的空间中的宝贵数学工具。我们引入了超维变换作为一种新型的积分变换。它将可积函数转换为噪声鲁棒、全息、高维表示，称为超维向量。其核心思想是用随机函数的线性组合来逼近一个函数。我们正式引入了一组随机的正交基函数，并定义了超维变换及其逆变换。我们讨论了一般变换相关的性质，如其唯一性、逆变换的逼近性质以及积分和导数的表示。超维变换提供了一个强大而灵活的框架，与傅里叶、拉普拉斯和模糊变换等其他积分变换密切相关。此外，它为超维领域提供了理论基础和新的洞察。

    Integral transforms are invaluable mathematical tools to map functions into spaces where they are easier to characterize. We introduce the hyperdimensional transform as a new kind of integral transform. It converts square-integrable functions into noise-robust, holographic, high-dimensional representations called hyperdimensional vectors. The central idea is to approximate a function by a linear combination of random functions. We formally introduce a set of stochastic, orthogonal basis functions and define the hyperdimensional transform and its inverse. We discuss general transform-related properties such as its uniqueness, approximation properties of the inverse transform, and the representation of integrals and derivatives. The hyperdimensional transform offers a powerful, flexible framework that connects closely with other integral transforms, such as the Fourier, Laplace, and fuzzy transforms. Moreover, it provides theoretical foundations and new insights for the field of hyperdim
    
[^60]: WebWISE：具有大型语言模型的Web界面控制和顺序探索

    WebWISE: Web Interface Control and Sequential Exploration with Large Language Models. (arXiv:2310.16042v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.16042](http://arxiv.org/abs/2310.16042)

    本文介绍了一种利用大型语言模型（LLM）自动执行Web软件任务的方法，通过步骤性生成小型程序来实现对点击、滚动和文本输入操作的控制。与其他方法相比，该方法在MiniWob++基准测试中通过一个上下文示例就能达到相似或更好的性能。

    

    本文研究了使用大型语言模型（LLM）自动执行点击、滚动和文本输入操作的Web软件任务。之前的方法，如强化学习（RL）或模仿学习，训练效率低且特定于任务。我们的方法使用筛选后的文档对象模型（DOM）元素作为观察，逐步执行任务，根据当前观察生成小型程序。我们使用上下文学习，可以从单个手动提供的示例中获益，或者从成功的零样例试验中生成自动示例。我们在MiniWob++基准测试上评估了所提出的方法。只有一个上下文示例，我们的WebWISE方法的性能与其他需要许多演示或试验的方法相当或更好。

    The paper investigates using a Large Language Model (LLM) to automatically perform web software tasks using click, scroll, and text input operations. Previous approaches, such as reinforcement learning (RL) or imitation learning, are inefficient to train and task-specific. Our method uses filtered Document Object Model (DOM) elements as observations and performs tasks step-by-step, sequentially generating small programs based on the current observations. We use in-context learning, either benefiting from a single manually provided example, or an automatically generated example based on a successful zero-shot trial. We evaluate the proposed method on the MiniWob++ benchmark. With only one in-context example, our WebWISE method achieves similar or better performance than other methods that require many demonstrations or trials.
    
[^61]: 使用GOES-16卫星观测数据的可解释性深度学习对大气对流起始进行预测

    Physically Explainable Deep Learning for Convective Initiation Nowcasting Using GOES-16 Satellite Observations. (arXiv:2310.16015v1 [physics.ao-ph] CROSS LISTED)

    [http://arxiv.org/abs/2310.16015](http://arxiv.org/abs/2310.16015)

    本研究开发了基于多通道红外卫星观测数据的可解释性深度学习模型，用于预测大气对流起始。通过案例研究，该模型表现出对云层和湿度特性的依赖性，并在误报率上显著优于经典的逻辑模型。

    

    大气对流起始（CI）的预测在数值天气预报模型和现有的预测算法中仍然是个具有挑战性的问题。本研究开发了基于多通道红外GOES-R卫星观测数据的基于对象的概率深度学习模型，用于预测CI。数据来自于2020年6月和7月以及2021年6月在美国大平原地区多雷达多传感器多普勒天气雷达产品中识别出的潜在CI事件周围的补丁。使用客观的基于雷达的方法来识别这些事件。深度学习模型在提前时间为1小时的情况下显著优于经典的逻辑模型，特别是在误报率上。通过案例研究，深度学习模型展示了对云层和多层次湿度特性的依赖性。模型解释进一步揭示了模型在不同基线下的决策过程。解释结果突出了湿度的重要性。

    Convection initiation (CI) nowcasting remains a challenging problem for both numerical weather prediction models and existing nowcasting algorithms. In this study, object-based probabilistic deep learning models are developed to predict CI based on multichannel infrared GOES-R satellite observations. The data come from patches surrounding potential CI events identified in Multi-Radar Multi-Sensor Doppler weather radar products over the Great Plains region from June and July 2020 and June 2021. An objective radar-based approach is used to identify these events. The deep learning models significantly outperform the classical logistic model at lead times up to 1 hour, especially on the false alarm ratio. Through case studies, the deep learning model exhibits the dependence on the characteristics of clouds and moisture at multiple levels. Model explanation further reveals the model's decision-making process with different baselines. The explanation results highlight the importance of moist
    
[^62]: 使用具有专门口音代码本的口音识别

    Accented Speech Recognition With Accent-specific Codebooks. (arXiv:2310.15970v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.15970](http://arxiv.org/abs/2310.15970)

    本研究提出了一种使用具有专门口音代码本的口音适应方法，通过交叉注意力和可训练代码本，用于端到端ASR系统。在实验证明了该方法在已见和未见的口音上都能获得显著的性能提升。

    

    语音口音对于现有自动语音识别（ASR）系统构成了重要挑战。在代表性不足的口音中的性能下降严重阻碍了ASR的普及应用。本研究提出了一种新颖的口音适应方法，通过交叉注意力和可训练代码本，用于端到端ASR系统。这些可学习的代码本捕捉了口音特定信息，并被整合到ASR编码器层中。模型在带口音的英语语音上进行训练，而测试数据中也包含了在训练过程中未见过的口音。在Mozilla Common Voice多口音数据集上，我们展示了我们提出的方法在不仅在已见的英语口音中获得显著的性能提升（单词错误率相对提升高达37%），而且在未见的口音上也获得了5%的相对提升。此外，我们还展示了在L2Artic数据集上的零样本迁移设置的好处。我们还进行了对比实验。

    Speech accents pose a significant challenge to state-of-the-art automatic speech recognition (ASR) systems. Degradation in performance across underrepresented accents is a severe deterrent to the inclusive adoption of ASR. In this work, we propose a novel accent adaptation approach for end-to-end ASR systems using cross-attention with a trainable set of codebooks. These learnable codebooks capture accent-specific information and are integrated within the ASR encoder layers. The model is trained on accented English speech, while the test data also contained accents which were not seen during training. On the Mozilla Common Voice multi-accented dataset, we show that our proposed approach yields significant performance gains not only on the seen English accents (up to $37\%$ relative improvement in word error rate) but also on the unseen accents (up to $5\%$ relative improvement in WER). Further, we illustrate benefits for a zero-shot transfer setup on the L2Artic dataset. We also compare
    
[^63]: FANToM: 在交互中对机器心智理论进行压力测试的基准

    FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions. (arXiv:2310.15421v1 [cs.CL])

    [http://arxiv.org/abs/2310.15421](http://arxiv.org/abs/2310.15421)

    FANToM是一个新的基准，用于通过问答在信息不对称的对话环境中压力测试机器的心智理论。这个基准对最先进的大型语言模型来说具有挑战性，即使是具有思维链推理和微调的模型也比人类表现得差。

    

    目前关于心智理论（ToM）的评估主要集中在使用缺乏互动性的被动故事，我们介绍了FANToM，一个新的基准，通过问答在信息不对称的对话环境中进行心智理论的压力测试。我们的基准结合了心理学中的重要理论要求和对评估大型语言模型（LLM）时必要的经验考虑。特别地，我们制定了多种类型的问题，要求相同的基本推理来识别LLM中不存在或虚假的心智理论能力。我们展示了FANToM对最先进的LLM来说具有挑战性，即使是具有思维链推理和微调的LLM也表现比人类差得多。

    Theory of mind (ToM) evaluations currently focus on testing models using passive narratives that inherently lack interactivity. We introduce FANToM, a new benchmark designed to stress-test ToM within information-asymmetric conversational contexts via question answering. Our benchmark draws upon important theoretical requisites from psychology and necessary empirical considerations when evaluating large language models (LLMs). In particular, we formulate multiple types of questions that demand the same underlying reasoning to identify illusory or false sense of ToM capabilities in LLMs. We show that FANToM is challenging for state-of-the-art LLMs, which perform significantly worse than humans even with chain-of-thought reasoning or fine-tuning.
    
[^64]: 任务导向对话的相似度度量方法

    TaskDiff: A Similarity Metric for Task-Oriented Conversations. (arXiv:2310.15298v1 [cs.CL])

    [http://arxiv.org/abs/2310.15298](http://arxiv.org/abs/2310.15298)

    TaskDiff是一种新颖的对话相似度度量方法，通过使用不同的对话组成部分来计算相似度，取得了优越的性能和鲁棒性。

    

    会话式数字助手的普及导致了大量会话数据的可用性，这可以用于改善用户体验和个性化响应生成。使用像ChatGPT这样的流行大型语言模型构建这些助手还需要额外强调提示工程和评估方法。文本相似度度量是这种分析和评估的关键因素。虽然文献中提出了许多相似度度量方法，但它们在任务导向对话方面并不有效，因为它们没有充分利用独特的对话特征。为了填补这一差距，我们提出了一种新颖的对话相似度度量方法TaskDiff，它利用对话的不同组成部分（话语、意图和槽）及其分布来计算相似度。在基准数据集上进行的广泛实验证明了TaskDiff在性能和鲁棒性方面的优越表现，超过了其他相关方法。

    The popularity of conversational digital assistants has resulted in the availability of large amounts of conversational data which can be utilized for improved user experience and personalized response generation. Building these assistants using popular large language models like ChatGPT also require additional emphasis on prompt engineering and evaluation methods. Textual similarity metrics are a key ingredient for such analysis and evaluations. While many similarity metrics have been proposed in the literature, they have not proven effective for task-oriented conversations as they do not take advantage of unique conversational features. To address this gap, we present TaskDiff, a novel conversational similarity metric that utilizes different dialogue components (utterances, intents, and slots) and their distributions to compute similarity. Extensive experimental evaluation of TaskDiff on a benchmark dataset demonstrates its superior performance and improved robustness over other rela
    
[^65]: MGAS: 多粒度架构搜索以实现高效且有效的神经网络

    MGAS: Multi-Granularity Architecture Search for Effective and Efficient Neural Networks. (arXiv:2310.15074v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.15074](http://arxiv.org/abs/2310.15074)

    MGAS是一个多粒度架构搜索的统一框架，通过学习特定粒度级别的离散化函数，自适应地确定剩余比例，从而实现同时优化模型大小和模型性能。

    

    可微分架构搜索(DAS)通过时间高效的自动化改变了神经网络架构搜索(NAS)的方式，从离散候选采样和评估转变为可微分超网络优化和离散化。然而，现有的DAS方法要么只进行粗粒度的操作级搜索，要么手动定义剩余的细粒度的核级和权重级单位的比例，从而无法同时优化模型大小和模型性能。此外，这些方法为了减少内存消耗而牺牲了搜索质量。为了解决这些问题，我们引入了多粒度架构搜索(MGAS)，这是一个统一的框架，旨在全面而内存高效地探索多粒度搜索空间，发现既有效又高效的神经网络。具体来说，我们学习了针对每个粒度级别的离散化函数，根据不断演化的架构自适应地确定剩余的比例。

    Differentiable architecture search (DAS) revolutionizes neural architecture search (NAS) with time-efficient automation, transitioning from discrete candidate sampling and evaluation to differentiable super-net optimization and discretization. However, existing DAS methods either only conduct coarse-grained operation-level search or manually define the remaining ratios for fine-grained kernel-level and weight-level units, which fail to simultaneously optimize model size and model performance. Furthermore, these methods compromise search quality to reduce memory consumption. To tackle these issues, we introduce multi-granularity architecture search (MGAS), a unified framework which aims to comprehensively and memory-efficiently explore the multi-granularity search space to discover both effective and efficient neural networks. Specifically, we learn discretization functions specific to each granularity level to adaptively determine the remaining ratios according to the evolving architec
    
[^66]: 通过移除单个样本进行数据修剪

    Data Pruning via Moving-one-Sample-out. (arXiv:2310.14664v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2310.14664](http://arxiv.org/abs/2310.14664)

    本文提出了一种新颖的数据修剪方法MoSo，它通过评估样本对最优经验风险的影响来确定每个样本的重要性，并提出了一种高效的一阶近似器来计算样本的重要性，该近似器只需要梯度信息。

    

    本文提出了一种新颖的数据修剪方法称为移除单个样本(MoSo)，旨在从训练集中识别并移除最不相关的样本。MoSo的核心思想是通过评估样本对最优经验风险的影响来确定每个样本的重要性。这通过衡量从训练集中排除一个特定样本时，经验风险的变化程度来实现。我们提出了一种高效的一阶近似器，它仅需要来自不同训练阶段的梯度信息，而不是使用计算上昂贵的逐个样本重新训练的过程。我们近似的关键思想是，梯度与训练集的平均梯度一致的样本更具信息量，并且应该获得更高的分数，可以直观地理解为：如果来自特定样本的梯度与平均梯度向量一致，则意味着

    In this paper, we propose a novel data-pruning approach called moving-one-sample-out (MoSo), which aims to identify and remove the least informative samples from the training set. The core insight behind MoSo is to determine the importance of each sample by assessing its impact on the optimal empirical risk. This is achieved by measuring the extent to which the empirical risk changes when a particular sample is excluded from the training set. Instead of using the computationally expensive leaving-one-out-retraining procedure, we propose an efficient first-order approximator that only requires gradient information from different training stages. The key idea behind our approximation is that samples with gradients that are consistently aligned with the average gradient of the training set are more informative and should receive higher scores, which could be intuitively understood as follows: if the gradient from a specific sample is consistent with the average gradient vector, it implies
    
[^67]: 一个国际合作机构评估面向先进人工智能的社会规模风险。

    An International Consortium for Evaluations of Societal-Scale Risks from Advanced AI. (arXiv:2310.14455v2 [cs.CY] UPDATED)

    [http://arxiv.org/abs/2310.14455](http://arxiv.org/abs/2310.14455)

    本文提出了面向先进人工智能的社会规模风险评估的国际合作机构解决方案，提议在人工智能开发者和第三方评估人员之间建立联合体，以解决评估人员多样性有限、努力分配不理想和激励机制颠倒等协调挑战。

    

    鉴于先进人工智能的快速发展和前沿人工智能系统的风险，人工智能治理和监管方案的创建和实施应该优先考虑并进行大量投资。然而，现状是难以维持的，而且危险。监管缺口使得人工智能实验室可以在很少监督下进行研究、开发和部署活动。作为回应，提出了前沿人工智能系统评估作为评估前沿人工智能系统的风险的方法。然而，新兴的人工智能风险评估生态系统面临着重大的协调挑战，例如评估人员的多样性有限、努力分配不理想和激励机制颠倒。本文提出了一种解决方案，即通过一个由人工智能开发者和第三方风险评估人员组成的国际联合体来进行人工智能风险评估。这样的联合体可以发挥决定性作用。

    Given rapid progress toward advanced AI and risks from frontier AI systems (advanced AI systems pushing the boundaries of the AI capabilities frontier), the creation and implementation of AI governance and regulatory schemes deserves prioritization and substantial investment. However, the status quo is untenable and, frankly, dangerous. A regulatory gap has permitted AI labs to conduct research, development, and deployment activities with minimal oversight. In response, frontier AI system evaluations have been proposed as a way of assessing risks from the development and deployment of frontier AI systems. Yet, the budding AI risk evaluation ecosystem faces significant coordination challenges, such as a limited diversity of evaluators, suboptimal allocation of effort, and perverse incentives. This paper proposes a solution in the form of an international consortium for AI risk evaluations, comprising both AI developers and third-party AI risk evaluators. Such a consortium could play a c
    
[^68]: Hunayn：超越字面意义的翻译进步

    Hunayn: Elevating Translation Beyond the Literal. (arXiv:2310.13613v1 [cs.CL])

    [http://arxiv.org/abs/2310.13613](http://arxiv.org/abs/2310.13613)

    这项研究介绍了一种超越传统工具的高级英译阿拉伯语翻译器，使用赫尔辛基变压器和纯文学阿拉伯语数据集，表现出色，并强调了其在文化敏感性和语境准确性方面的优势。

    

    该项目介绍了一种超越传统工具的高级英译阿拉伯语翻译器。利用赫尔辛基变压器（MarianMT），我们的方法涉及在一个自动生成的、纯文学阿拉伯语数据集上进行微调。与谷歌翻译的评估表明，在定性评估中始终表现出色。值得注意的是，它在文化敏感性和语境准确性方面表现出色。这项研究强调了赫尔辛基变压器在使用Fusha数据集的英阿翻译中的优势。

    This project introduces an advanced English-to-Arabic translator surpassing conventional tools. Leveraging the Helsinki transformer (MarianMT), our approach involves fine-tuning on a self-scraped, purely literary Arabic dataset. Evaluations against Google Translate show consistent outperformance in qualitative assessments. Notably, it excels in cultural sensitivity and context accuracy. This research underscores the Helsinki transformer's superiority for English-to-Arabic translation using a Fusha dataset.
    
[^69]: 多尺度超像素结构差异图卷积网络用于视觉语言表征

    Multiscale Superpixel Structured Difference Graph Convolutional Network for VL Representation. (arXiv:2310.13447v1 [cs.CV])

    [http://arxiv.org/abs/2310.13447](http://arxiv.org/abs/2310.13447)

    本文提出了一种多尺度超像素结构差异图卷积网络（MDGCN）用于视觉语言表征，通过聚类感知相似像素，减少了后续处理的视觉基元数量，并挖掘了更精确的拓扑关系。

    

    在多模态领域中，整合视觉和语言的关键在于建立一个良好的对齐策略。最近，受到自监督学习成功的启发，基于预训练模型的视觉和语言的多模态语义表征取得了重大进展。然而，视觉语义表征仍有改进的空间。当前基于像素或块的方法在准确提取复杂场景边界方面存在空间语义连贯性不足和对噪声的脆弱性的挑战。为此，本文将超像素作为可学习图像数据的综合紧凑表征，通过对感知相似像素进行聚类，有效地减少了后续处理的视觉基元数量。为了挖掘更精确的拓扑关系，我们提出了一种多尺度差异图卷积网络（MDGCN）。它将整个图像解析为细到粗的层次结构，从而实现了整个图像的解析。

    Within the multimodal field, the key to integrating vision and language lies in establishing a good alignment strategy. Recently, benefiting from the success of self-supervised learning, significant progress has been made in multimodal semantic representation based on pre-trained models for vision and language. However, there is still room for improvement in visual semantic representation. The lack of spatial semantic coherence and vulnerability to noise makes it challenging for current pixel or patch-based methods to accurately extract complex scene boundaries. To this end, this paper develops superpixel as a comprehensive compact representation of learnable image data, which effectively reduces the number of visual primitives for subsequent processing by clustering perceptually similar pixels. To mine more precise topological relations, we propose a Multiscale Difference Graph Convolutional Network (MDGCN). It parses the entire image as a fine-to-coarse hierarchical structure of cons
    
[^70]: CLAIR: 用大型语言模型评估图像标题

    CLAIR: Evaluating Image Captions with Large Language Models. (arXiv:2310.12971v1 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2310.12971](http://arxiv.org/abs/2310.12971)

    CLAIR是一种基于大型语言模型的新方法，用于评估机器生成的图像标题。相对于现有的评估方法，CLAIR在与人类判断的相关性方面表现更好，并针对具体数据集取得了较大改进。

    

    机器生成图像标题的评估是一个有趣但持久存在的挑战。有效的评估指标必须考虑多个相似性维度，包括语义相关性、视觉结构、物体交互、标题多样性和特定性。现有的高度工程化的评估方法试图捕捉特定方面，但在提供与人类判断密切一致的整体评分方面仍有不足之处。在这里，我们提出了CLAIR，一种利用大型语言模型（LLM）的零射语言建模能力来评估候选标题的新方法。在我们的评估中，CLAIR相对于现有指标更能与人类对标题质量的判断相关。值得注意的是，在Flickr8K-Expert上，CLAIR在与SPICE相比的相关改进方面提高了39.6％，在与RefCLIP-S等图像增强方法相比的相关改进方面提高了18.3％。此外，CLAIR提供了可解释性结果，允许语言模型识别u

    The evaluation of machine-generated image captions poses an interesting yet persistent challenge. Effective evaluation measures must consider numerous dimensions of similarity, including semantic relevance, visual structure, object interactions, caption diversity, and specificity. Existing highly-engineered measures attempt to capture specific aspects, but fall short in providing a holistic score that aligns closely with human judgments. Here, we propose CLAIR, a novel method that leverages the zero-shot language modeling capabilities of large language models (LLMs) to evaluate candidate captions. In our evaluations, CLAIR demonstrates a stronger correlation with human judgments of caption quality compared to existing measures. Notably, on Flickr8K-Expert, CLAIR achieves relative correlation improvements over SPICE of 39.6% and over image-augmented methods such as RefCLIP-S of 18.3%. Moreover, CLAIR provides noisily interpretable results by allowing the language model to identify the u
    
[^71]: 大型语言模型用于多目标进化优化

    Large Language Model for Multi-objective Evolutionary Optimization. (arXiv:2310.12541v1 [cs.NE])

    [http://arxiv.org/abs/2310.12541](http://arxiv.org/abs/2310.12541)

    本论文调查了一种利用大型语言模型（LLM）设计MOEA操作符的新方法，通过适当的提示工程，成功将通用的LLM以零-shot方式作为MOEA/D的黑盒搜索操作符，并通过从LLM行为中学习设计了一个显性的白盒操作符。

    

    多目标进化算法（MOEAs）是解决多目标优化问题（MOPs）的主要方法。在过去几十年中，提出了许多MOEAs，其操作符需要通过领域知识进行精心设计。最近，一些尝试将MOEAs中手动设计的操作符替换为基于学习的操作符（如神经网络模型）已经取得了一些进展。然而，设计和训练这样的模型仍然需要大量的工作，并且学习到的操作符可能不能很好地推广到解决新问题。为了解决上述挑战，本文研究了一种利用强大的大型语言模型（LLM）来设计MOEA操作符的新方法。通过适当的提示工程，我们成功地让一个通用的LLM以零-shot的方式作为分解型MOEA（MOEA/D）的黑盒搜索操作符。此外，通过从LLM行为中学习，我们进一步设计了一个显性的白盒操作符，并提出了...

    Multiobjective evolutionary algorithms (MOEAs) are major methods for solving multiobjective optimization problems (MOPs). Many MOEAs have been proposed in the past decades, of which the operators need carefully handcrafted design with domain knowledge. Recently, some attempts have been made to replace the manually designed operators in MOEAs with learning-based operators (e.g., neural network models). However, much effort is still required for designing and training such models, and the learned operators might not generalize well to solve new problems. To tackle the above challenges, this work investigates a novel approach that leverages the powerful large language model (LLM) to design MOEA operators. With proper prompt engineering, we successfully let a general LLM serve as a black-box search operator for decomposition-based MOEA (MOEA/D) in a zero-shot manner. In addition, by learning from the LLM behavior, we further design an explicit white-box operator with randomness and propose
    
[^72]: 通过多矩阵可分解性在多人游戏中对自我对抗的保证

    Guarantees for Self-Play in Multiplayer Games via Polymatrix Decomposability. (arXiv:2310.11518v1 [cs.GT])

    [http://arxiv.org/abs/2310.11518](http://arxiv.org/abs/2310.11518)

    这篇论文研究了多人游戏中自我对抗的保证问题，通过多矩阵可分解性，在满足一定条件的情况下，通过自我对抗学习的算法能够产生有界脆弱性的策略。

    

    自我对抗是一种机器学习在多智能体系统中的技术，其中学习算法通过与自身的副本交互来学习。自我对抗对于生成大量的学习数据很有用，但它的缺点是训练后学习者将面对的智能体可能与通过与自身交互时所期望的智能体行为截然不同。对于两人常和游戏的特殊情况，达到纳什均衡的自我对抗能够保证产生对任何训练后对手表现良好的策略；然而，对于多人游戏来说没有这样的保证存在。我们展示了在近似分解为一组两人常和游戏（称为多矩阵游戏）的游戏中，其中全局 $\epsilon$-纳什均衡在每个子游戏中都与纳什均衡有有界距离的情况下，通过自我对抗学习的无外部遗憾算法将产生一个有界脆弱性的策略。我们的结果首次确定了……

    Self-play is a technique for machine learning in multi-agent systems where a learning algorithm learns by interacting with copies of itself. Self-play is useful for generating large quantities of data for learning, but has the drawback that the agents the learner will face post-training may have dramatically different behavior than the learner came to expect by interacting with itself. For the special case of two-player constant-sum games, self-play that reaches Nash equilibrium is guaranteed to produce strategies that perform well against any post-training opponent; however, no such guarantee exists for multi-player games. We show that in games that approximately decompose into a set of two-player constant-sum games (called polymatrix games) where global $\epsilon$-Nash equilibria are boundedly far from Nash-equilibria in each subgame, any no-external-regret algorithm that learns by self-play will produce a strategy with bounded vulnerability. For the first time, our results identify 
    
[^73]: ACES: 使用自我目标语言模型和语义描述符生成多样的编程难题

    ACES: generating diverse programming puzzles with autotelic language models and semantic descriptors. (arXiv:2310.10692v1 [cs.LG])

    [http://arxiv.org/abs/2310.10692](http://arxiv.org/abs/2310.10692)

    ACES是一种使用自我目标语言模型和语义描述符生成多样化的编程难题的方法，能够优化有趣的多样性和少样本生成。

    

    寻找和选择新颖有趣的问题是好奇心、科学和创新的核心。在Python编程难题的无限空间中，我们研究了自动问题生成。现有的生成模型通常旨在建模参考分布，没有明确的多样性优化。其他方法在有限的手工编码表示空间或不可解释的学习嵌入空间中明确优化多样性，这些嵌入空间可能与人类对有趣变化的感知不符。通过ACES（自我目标代码探索与语义描述符），我们引入了一种新的自我目标生成方法，利用大型语言模型（LLM）生成语义描述符，直接优化有趣的多样性，以及少样本生成。每个难题都标记有10个维度，每个维度捕捉了解决它所需的编程技能。ACES生成并追求新颖可行的目标。

    Finding and selecting new and interesting problems to solve is at the heart of curiosity, science and innovation. We here study automated problem generation in the context of the open-ended space of python programming puzzles. Existing generative models often aim at modeling a reference distribution without any explicit diversity optimization. Other methods explicitly optimizing for diversity do so either in limited hand-coded representation spaces or in uninterpretable learned embedding spaces that may not align with human perceptions of interesting variations. With ACES (Autotelic Code Exploration via Semantic descriptors), we introduce a new autotelic generation method that leverages semantic descriptors produced by a large language model (LLM) to directly optimize for interesting diversity, as well as few-shot-based generation. Each puzzle is labeled along 10 dimensions, each capturing a programming skill required to solve it. ACES generates and pursues novel and feasible goals to 
    
[^74]: 使用人工编辑改进摘要生成

    Improving Summarization with Human Edits. (arXiv:2310.05857v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2310.05857](http://arxiv.org/abs/2310.05857)

    本文介绍了一种改进摘要生成的方法，使用人工编辑的反馈数据，并通过序列对齐（不）似然训练(SALT)技术将人工编辑数据与模型生成数据结合起来。实验证明了这种方法在医学领域摘要生成中的有效性。

    

    最近的研究表明，通过人类反馈范式学习可以产生高质量的文本。现有的工作在通用领域抽象化摘要生成中使用人类反馈来训练大型语言模型(LLMs)，并获得了超越传统似然训练的摘要质量。在本文中，我们关注一种较少探索的人类反馈形式——人工编辑。我们提出了一种新颖的技术——序列对齐（不）似然训练(SALT)，在训练循环中同时使用人工编辑和模型生成的数据。此外，我们还展示了使用现有训练数据中的基准摘要来模拟人工编辑，以及在训练后获取的模型生成摘要，以减少对昂贵的人工编辑数据的需求。在实验中，我们将人类反馈的探索从通用领域摘要生成扩展到医学领域摘要生成。我们的结果表明SALT在改进摘要生成方面的有效性。

    Recent work has shown the promise of learning with human feedback paradigms to produce human-determined high-quality text. Existing works use human feedback to train large language models (LLMs) in general domain abstractive summarization and have obtained summary quality exceeding traditional likelihood training. In this paper, we focus on a less explored form of human feedback -- Human Edits. We propose Sequence Alignment (un)Likelihood Training (SALT), a novel technique to use both the human-edited and model-generated data together in the training loop. In addition, we demonstrate simulating Human Edits with ground truth summaries coming from existing training data -Imitation edits, along with the model-generated summaries obtained after the training, to reduce the need for expensive human-edit data. In our experiments, we extend human feedback exploration from general domain summarization to medical domain summarization. Our results demonstrate the effectiveness of SALT in improv
    
[^75]: CodeTransOcean: 一个覆盖多种语言的全面代码翻译基准

    CodeTransOcean: A Comprehensive Multilingual Benchmark for Code Translation. (arXiv:2310.04951v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2310.04951](http://arxiv.org/abs/2310.04951)

    CodeTransOcean是一个全面的多语言代码翻译基准，包含多个创新的多语言数据集，并满足了现实应用的多样化需求。

    

    最近的代码翻译技术利用神经机器翻译模型将源代码从一种编程语言翻译成另一种，以满足生产兼容性或提高代码库维护效率的需求。大多数现有的代码翻译数据集只关注一对流行编程语言。为了推进代码翻译的研究并满足现实应用的多样化需求，我们构建了CodeTransOcean，这是一个支持最多种编程语言的大规模综合基准。CodeTransOcean包括三个创新的多语言数据集，分别是支持多种流行编程语言之间翻译的MultilingualTrans，用于在小众编程语言和流行编程语言之间翻译的NicheTrans，以及用于评估大型语言模型（LLM）翻译代码的可执行性的LLMTrans。CodeTransOcean还包括一个新颖的跨框架数据集DLTrans，用于翻译...

    Recent code translation techniques exploit neural machine translation models to translate source code from one programming language to another to satisfy production compatibility or to improve efficiency of codebase maintenance. Most existing code translation datasets only focus on a single pair of popular programming languages. To advance research on code translation and meet diverse requirements of real-world applications, we construct CodeTransOcean, a large-scale comprehensive benchmark that supports the largest variety of programming languages for code translation. CodeTransOcean consists of three novel multilingual datasets, namely, MultilingualTrans supporting translations between multiple popular programming languages, NicheTrans for translating between niche programming languages and popular ones, and LLMTrans for evaluating executability of translated code by large language models (LLMs). CodeTransOcean also includes a novel cross-framework dataset, DLTrans, for translating d
    
[^76]: 利用配对的OpenStreetMap数据和光学高分辨率影像进行土地覆盖变化检测

    Land-cover change detection using paired OpenStreetMap data and optical high-resolution imagery via object-guided Transformer. (arXiv:2310.02674v1 [cs.CV])

    [http://arxiv.org/abs/2310.02674](http://arxiv.org/abs/2310.02674)

    本文通过直接利用配对的OSM数据和光学图像进行土地覆盖变化检测，提出了一种基于对象引导的Transformer架构，从而拓宽了变化检测任务的范围，并显著减少了计算开销和内存负担。

    

    光学高分辨率影像和OpenStreetMap（OSM）数据是土地覆盖变化检测的两个重要数据源。先前的研究主要利用OSM数据来辅助多时期光学高分辨率图像的变化检测。本文通过直接利用配对的OSM数据和光学图像进行土地覆盖变化检测，拓宽了变化检测任务的范围，涵盖更多动态地球观测。为此，我们提出了一种基于对象引导的Transformer（ObjFormer）架构，将流行的基于对象的图像分析（OBIA）技术与先进的视觉Transformer架构自然地结合起来。引入OBIA可以显著减少自注意力模块中的计算开销和内存负担。具体而言，所提出的ObjFormer具有层次伪孪生编码器，包含对象引导自注意力模块，用于提取代表性特征。

    Optical high-resolution imagery and OpenStreetMap (OSM) data are two important data sources for land-cover change detection. Previous studies in these two data sources focus on utilizing the information in OSM data to aid the change detection on multi-temporal optical high-resolution images. This paper pioneers the direct detection of land-cover changes utilizing paired OSM data and optical imagery, thereby broadening the horizons of change detection tasks to encompass more dynamic earth observations. To this end, we propose an object-guided Transformer (ObjFormer) architecture by naturally combining the prevalent object-based image analysis (OBIA) technique with the advanced vision Transformer architecture. The introduction of OBIA can significantly reduce the computational overhead and memory burden in the self-attention module. Specifically, the proposed ObjFormer has a hierarchical pseudo-siamese encoder consisting of object-guided self-attention modules that extract representative
    
[^77]: OceanGPT：用于海洋科学任务的大型语言模型

    OceanGPT: A Large Language Model for Ocean Science Tasks. (arXiv:2310.02031v1 [cs.CL])

    [http://arxiv.org/abs/2310.02031](http://arxiv.org/abs/2310.02031)

    OceanGPT是首个专为海洋科学任务设计的大型语言模型，通过DoInstruct框架实现自动获取海洋领域指导数据。这一模型的引入填补了海洋科学领域中对LLM的需求缺口，并为海洋科学研究提供了新的工具和方法。

    

    海洋科学是探索充满生命和生物多样性的海洋的科学，考虑到海洋覆盖了地球表面的70％以上，这一领域具有重要意义。最近，大型语言模型（LLM）的进展改变了科学的范式。尽管在其他领域取得了成功，但现有的LLM通常无法满足海洋学家等领域专家的需求，同时对LLM在海洋科学中的潜力尚未得到充分探索。这其中的根本原因可能是海洋数据的庞大而复杂的性质，以及对更高的粒度和丰富的知识的需求。为了解决这些问题，我们推出了首个海洋领域的LLM——OceanGPT，该模型擅长各种海洋科学任务。我们提出了一个新颖的框架DoInstruct，用于自动获取大量的海洋领域指导数据，它基于多智能体的协作生成指导。

    Ocean science, which delves into the oceans that are reservoirs of life and biodiversity, is of great significance given that oceans cover over 70% of our planet's surface. Recently, advances in Large Language Models (LLMs) have transformed the paradigm in science. Despite the success in other domains, current LLMs often fall short in catering to the needs of domain experts like oceanographers, and the potential of LLMs for ocean science is under-explored. The intrinsic reason may be the immense and intricate nature of ocean data as well as the necessity for higher granularity and richness in knowledge. To alleviate these issues, we introduce OceanGPT, the first-ever LLM in the ocean domain, which is expert in various ocean science tasks. We propose DoInstruct, a novel framework to automatically obtain a large volume of ocean domain instruction data, which generates instructions based on multi-agent collaboration. Additionally, we construct the first oceanography benchmark, OceanBench,
    
[^78]: 学习接受帮助：干预感知的概念嵌入模型

    Learning to Receive Help: Intervention-Aware Concept Embedding Models. (arXiv:2309.16928v1 [cs.LG])

    [http://arxiv.org/abs/2309.16928](http://arxiv.org/abs/2309.16928)

    这项研究提出了一种干预感知的概念嵌入模型，用于提高神经架构对概念干预的响应性，并解决了概念干预顺序和模型架构的依赖性的问题。

    

    概念瓶颈模型（CBMs）通过使用一组高级概念构建和解释神经架构的预测，以解决其不透明性的问题。这些模型的一个特殊属性是它们允许概念干预，用户可以纠正被错误预测的概念，从而提高模型的性能。然而，最近的研究表明，干预有效性可能严重依赖于干预概念的顺序以及模型的架构和训练超参数。我们认为，这源于CBM在训练时缺乏模型适应概念干预的激励。为了解决这个问题，我们提出了干预感知的概念嵌入模型（IntCEMs），这是一种基于CBM的新型架构和训练范式，可以提高模型对测试时干预的响应性。我们的模型以端到端的方式学习了一个概念干预策略，从中可以采样有意义的干预轨迹。

    Concept Bottleneck Models (CBMs) tackle the opacity of neural architectures by constructing and explaining their predictions using a set of high-level concepts. A special property of these models is that they permit concept interventions, wherein users can correct mispredicted concepts and thus improve the model's performance. Recent work, however, has shown that intervention efficacy can be highly dependent on the order in which concepts are intervened on and on the model's architecture and training hyperparameters. We argue that this is rooted in a CBM's lack of train-time incentives for the model to be appropriately receptive to concept interventions. To address this, we propose Intervention-aware Concept Embedding models (IntCEMs), a novel CBM-based architecture and training paradigm that improves a model's receptiveness to test-time interventions. Our model learns a concept intervention policy in an end-to-end fashion from where it can sample meaningful intervention trajectories a
    
[^79]: 用自适应多模态奖励引导你的智能体

    Guide Your Agent with Adaptive Multimodal Rewards. (arXiv:2309.10790v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2309.10790](http://arxiv.org/abs/2309.10790)

    本文提出了一种自适应返回条件策略（ARP）框架，通过使用自然语言任务描述和预训练的多模态编码器来提升智能体的泛化能力。通过在预训练的多模态嵌入空间中计算视觉观察和自然语言指令之间的相似度，并将其用作奖励信号，ARP有效缓解了目标误泛化问题，并在面对未知的文本指令时展现出了出色的泛化性能。

    

    在模仿学习中，开发一个能够适应未知环境的智能体仍然是一个具有挑战性的问题。本文提出了一种名为自适应返回条件策略(ARP)的高效框架，用于通过自然语言任务描述和预训练的多模态编码器来提升智能体的泛化能力。我们的关键思想是在预训练的多模态嵌入空间(例如CLIP)中计算视觉观测和自然语言指令之间的相似度，并将其作为奖励信号。然后，我们使用用多模态奖励标记的专家演示来训练一个返回条件策略。由于多模态奖励在每个时间步提供自适应信号，我们的ARP有效地缓解了目标误泛化问题。与现有的文本条件策略相比，即使面对未知的文本指令，我们的ARP在泛化性能方面也表现出众。为了提高奖励的质量，我们还引入了一种预训练微调方法。

    Developing an agent capable of adapting to unseen environments remains a difficult challenge in imitation learning. This work presents Adaptive Return-conditioned Policy (ARP), an efficient framework designed to enhance the agent's generalization ability using natural language task descriptions and pre-trained multimodal encoders. Our key idea is to calculate a similarity between visual observations and natural language instructions in the pre-trained multimodal embedding space (such as CLIP) and use it as a reward signal. We then train a return-conditioned policy using expert demonstrations labeled with multimodal rewards. Because the multimodal rewards provide adaptive signals at each timestep, our ARP effectively mitigates the goal misgeneralization. This results in superior generalization performances even when faced with unseen text instructions, compared to existing text-conditioned policies. To improve the quality of rewards, we also introduce a fine-tuning method for pre-traine
    
[^80]: 一个可配置的库用于生成和操作迷宫数据集

    A Configurable Library for Generating and Manipulating Maze Datasets. (arXiv:2309.10498v1 [cs.LG])

    [http://arxiv.org/abs/2309.10498](http://arxiv.org/abs/2309.10498)

    这个论文介绍了一个可配置的库，用于生成和处理迷宫数据集，研究人员可以通过该库生成不同分布的迷宫数据集，并对生成参数和生成规则进行自定义控制。可以支持多种输出格式，适用于不同类型的模型。

    

    理解机器学习模型对分布偏移的响应方式是一个重要的研究挑战。由于不同的生成算法提供了一个细致的平台来模拟微妙和显著的分布偏移，迷宫作为一个优秀的测试基准。为了支持对模型在分布偏离数据上行为的系统性研究，我们提出了“maze-dataset”，一个包含迷宫求解任务的生成、处理和可视化数据集的综合库。借助这个库，研究人员可以轻松创建数据集，可以对使用的生成算法、传递给选择算法的参数和生成的迷宫必须满足的筛选器进行广泛的控制。此外，它支持多种输出格式，包括栅格化和基于文本的格式，适用于卷积神经网络和自回归变换模型。这些格式以及用于可视化和转换的工具确保了灵活性和适应性。

    Understanding how machine learning models respond to distributional shifts is a key research challenge. Mazes serve as an excellent testbed due to varied generation algorithms offering a nuanced platform to simulate both subtle and pronounced distributional shifts. To enable systematic investigations of model behavior on out-of-distribution data, we present $\texttt{maze-dataset}$, a comprehensive library for generating, processing, and visualizing datasets consisting of maze-solving tasks. With this library, researchers can easily create datasets, having extensive control over the generation algorithm used, the parameters fed to the algorithm of choice, and the filters that generated mazes must satisfy. Furthermore, it supports multiple output formats, including rasterized and text-based, catering to convolutional neural networks and autoregressive transformer models. These formats, along with tools for visualizing and converting between them, ensure versatility and adaptability in re
    
[^81]: 如何在数据马拉松中处理数据

    How to Data in Datathons. (arXiv:2309.09770v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2309.09770](http://arxiv.org/abs/2309.09770)

    本文提供了关于如何处理数据马拉松中的数据的指导方针和建议，通过10个案例研究验证了提出的框架的有效性。

    

    数据马拉松的兴起提供了一个在短时间内合作、学习和创新的平台。尽管它们具有重要的潜在好处，但组织往往因缺乏明确的指导方针和最佳实践而难以有效处理数据。根据我们自己的经验以及自2016年以来组织了超过80个数据马拉松挑战赛与60个合作伙伴组织的见解，我们提供了指导方针和建议，作为组织者在处理数据相关复杂性时的资源。我们将我们提出的框架应用于10个案例研究。

    The rise of datathons, also known as data or data science hackathons, has provided a platform to collaborate, learn, and innovate in a short timeframe. Despite their significant potential benefits, organizations often struggle to effectively work with data due to a lack of clear guidelines and best practices for potential issues that might arise. Drawing on our own experiences and insights from organizing >80 datathon challenges with >60 partnership organizations since 2016, we provide guidelines and recommendations that serve as a resource for organizers to navigate the data-related complexities of datathons. We apply our proposed framework to 10 case studies.
    
[^82]: Talk2Care: 利用大型语言模型促进异步患者-医生通信

    Talk2Care: Facilitating Asynchronous Patient-Provider Communication with Large-Language-Model. (arXiv:2309.09357v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2309.09357](http://arxiv.org/abs/2309.09357)

    本研究利用大型语言模型（LLMs）来促进患者和医生之间的异步通信，通过访谈研究了解了他们对LLMs的需求，并构建了一个名为Talk2Care的LLM驱动的通信系统。

    

    尽管有大量的远程医疗应用程序来帮助家庭中的老年人和医疗提供者，但基本的消息和电话仍然是最常见的通信方法，这些方法存在有限的可用性、信息丢失和流程效率低下的问题。促进患者-医生通信的一个有希望的解决方案是利用大型语言模型(LLMs)及其强大的自然对话和摘要能力。然而，对于LLMs在通信过程中的作用还存在有限的理解。我们首先进行了两项访谈研究，分别与老年人(N=10)和医疗提供者(N=9)进行了交流，以了解他们在患者-医生异步通信中对LLMs的需求和机会。基于这些见解，我们构建了一个LLM驱动的通信系统Talk2Care，并为两个群体设计了交互组件: (1) 对于老年人，我们利用语音助手的便利性和易于获取性，构建了一个LLM驱动的语音助手

    Despite the plethora of telehealth applications to assist home-based older adults and healthcare providers, basic messaging and phone calls are still the most common communication methods, which suffer from limited availability, information loss, and process inefficiencies. One promising solution to facilitate patient-provider communication is to leverage large language models (LLMs) with their powerful natural conversation and summarization capability. However, there is a limited understanding of LLMs' role during the communication. We first conducted two interview studies with both older adults (N=10) and healthcare providers (N=9) to understand their needs and opportunities for LLMs in patient-provider asynchronous communication. Based on the insights, we built an LLM-powered communication system, Talk2Care, and designed interactive components for both groups: (1) For older adults, we leveraged the convenience and accessibility of voice assistants (VAs) and built an LLM-powered VA i
    
[^83]: 大型语言模型能否辨别科学假设的证据？社会科学案例研究。

    Can Large Language Models Discern Evidence for Scientific Hypotheses? Case Studies in the Social Sciences. (arXiv:2309.06578v1 [cs.CL])

    [http://arxiv.org/abs/2309.06578](http://arxiv.org/abs/2309.06578)

    本文研究了大型语言模型（LLMs）根据科学摘要文本的能力，来辨别支持或反驳特定假设的证据。通过社区驱动的注释建立了一个新的数据集，针对社会科学中的科学假设证据任务。与其他基准进行了性能比较，并为未来研究提供了机会。

    

    假设的制定和测试是经验性研究的核心。一个强有力的假设是基于现有证据的最佳猜测，并且是基于相关文献的全面视图进行启发的。然而，随着每年科学文章数量的指数增长，对于给定假设相关证据的手动汇总和综合是一项挑战。我们的工作探索了当前大型语言模型（LLMs）根据科学摘要文本中的证据，能否辨别支持或反驳特定假设的能力。我们共享了一个新颖的数据集，用于社会科学中使用社区驱动的研究注释的科学假设证据任务。我们将LLMs的性能与几个最先进的基准进行比较，并指出未来研究的机会。该数据集可在https://github.com/Sai90000/ScientificHypothesisEvidencing.git上获得。

    Hypothesis formulation and testing are central to empirical research. A strong hypothesis is a best guess based on existing evidence and informed by a comprehensive view of relevant literature. However, with exponential increase in the number of scientific articles published annually, manual aggregation and synthesis of evidence related to a given hypothesis is a challenge. Our work explores the ability of current large language models (LLMs) to discern evidence in support or refute of specific hypotheses based on the text of scientific abstracts. We share a novel dataset for the task of scientific hypothesis evidencing using community-driven annotations of studies in the social sciences. We compare the performance of LLMs to several state-of-the-art benchmarks and highlight opportunities for future research in this area. The dataset is available at https://github.com/Sai90000/ScientificHypothesisEvidencing.git
    
[^84]: EGOFALLS:一种使用自我中心摄像头进行摔倒检测的视听数据集和基准（arXiv:2309.04579v1 [cs.CV]）

    EGOFALLS: A visual-audio dataset and benchmark for fall detection using egocentric cameras. (arXiv:2309.04579v1 [cs.CV])

    [http://arxiv.org/abs/2309.04579](http://arxiv.org/abs/2309.04579)

    这项研究提出了一种使用自我中心摄像头进行摔倒检测的方法，并构建了一个新的视听数据集。通过迟决策融合将音频和视觉信息相结合可以提高检测性能。

    

    对于脆弱人群，如老年人，摔倒往往是严重且常导致死亡的。以往的研究通过依赖单个传感器（图像或加速度计）捕捉数据来解决摔倒的检测问题。在本研究中，我们依赖于从自我中心摄像头捕捉的视频中提取的多模态描述符。我们提出的方法包括一个在提取的描述符之上构建的迟决策融合层。此外，我们还收集了一个新的数据集来评估我们提出的方法。这是我们认为的第一个公共同类数据集。该数据集包含14个受试者的10,948个视频样本。我们进行了消融实验以评估单个特征提取器的性能，视觉信息融合以及视觉和音频信息的融合。此外，我们还进行了内部和外部交叉验证的实验。我们的结果表明，通过迟决策融合将音频和视觉信息相结合可以提高检测性能。

    Falls are significant and often fatal for vulnerable populations such as the elderly. Previous works have addressed the detection of falls by relying on data capture by a single sensor, images or accelerometers. In this work, we rely on multimodal descriptors extracted from videos captured by egocentric cameras. Our proposed method includes a late decision fusion layer that builds on top of the extracted descriptors. Furthermore, we collect a new dataset on which we assess our proposed approach. We believe this is the first public dataset of its kind. The dataset comprises 10,948 video samples by 14 subjects. We conducted ablation experiments to assess the performance of individual feature extractors, fusion of visual information, and fusion of both visual and audio information. Moreover, we experimented with internal and external cross-validation. Our results demonstrate that the fusion of audio and visual information through late decision fusion improves detection performance, making
    
[^85]: RePo: 通过正则化后验可预测性增强弹性模型基础强化学习

    RePo: Resilient Model-Based Reinforcement Learning by Regularizing Posterior Predictability. (arXiv:2309.00082v1 [cs.LG])

    [http://arxiv.org/abs/2309.00082](http://arxiv.org/abs/2309.00082)

    本文提出了RePo算法，通过正则化后验可预测性的方式，增强了视觉模型基础强化学习方法的弹性。该方法通过学习一个对冗余和伪变化具有弹性的潜在表示，提高了方法对视觉干扰的鲁棒性，使其能够在动态环境中运行。

    

    视觉模型基础强化学习方法通常将图像观测编码为低维表示方式，这种方式未能消除冗余信息。这使得这些方法容易受到伪变化的影响，即与任务无关的组成部分的变化，如背景干扰因素或光照条件的变化。本文提出了一种视觉模型基础强化学习方法，该方法学习到了一种对这种伪变化具有弹性的潜在表示。我们的训练目标鼓励该表示在动力学和奖励预测方面具有最大的预测性，同时限制了观测到潜在表示的信息流。我们证明了这一目标极大增强了视觉模型基础强化学习方法对视觉干扰的弹性，使其能够在动态环境中运行。然后我们展示了虽然学习到的编码器对伪变化具有弹性，但在显著分布变化下并没有不变性。为了解决这个问题，我们提出了一个简单的奖励方案。

    Visual model-based RL methods typically encode image observations into low-dimensional representations in a manner that does not eliminate redundant information. This leaves them susceptible to spurious variations -- changes in task-irrelevant components such as background distractors or lighting conditions. In this paper, we propose a visual model-based RL method that learns a latent representation resilient to such spurious variations. Our training objective encourages the representation to be maximally predictive of dynamics and reward, while constraining the information flow from the observation to the latent representation. We demonstrate that this objective significantly bolsters the resilience of visual model-based RL methods to visual distractors, allowing them to operate in dynamic environments. We then show that while the learned encoder is resilient to spirious variations, it is not invariant under significant distribution shift. To address this, we propose a simple reward-f
    
[^86]: CL-MAE: 课程学习的遮罩自编码器

    CL-MAE: Curriculum-Learned Masked Autoencoders. (arXiv:2308.16572v1 [cs.CV])

    [http://arxiv.org/abs/2308.16572](http://arxiv.org/abs/2308.16572)

    本文提出了一种课程学习的遮罩自编码器（CL-MAE）。我们引入了一种可学习的遮罩模块，通过更新遮罩策略来增加自监督重构任务的复杂性。通过逐渐增加任务复杂性，模型可以学习更复杂和可迁移的表示。

    

    遮罩图像建模已被证明是一种强大的预文本任务，用于生成能够有效泛化到多个下游任务的鲁棒表示。通常，这种方法涉及在输入图像中随机遮罩补丁（标记），并且遮罩策略在训练过程中保持不变。本文提出了一种课程学习方法，通过更新遮罩策略以持续增加自监督重构任务的复杂性。我们推测，通过逐渐增加任务复杂性，模型可以学习更复杂和可迁移的表示。为了实现这一点，我们引入了一种新颖的可学习遮罩模块，具有生成不同复杂度遮罩的能力，并将该模块与遮罩自编码器（MAE）集成。我们的模块与MAE一同训练，同时调整其行为，在训练过程中从MAE的参与者过渡到MAE（优化相同的重构目标）。

    Masked image modeling has been demonstrated as a powerful pretext task for generating robust representations that can be effectively generalized across multiple downstream tasks. Typically, this approach involves randomly masking patches (tokens) in input images, with the masking strategy remaining unchanged during training. In this paper, we propose a curriculum learning approach that updates the masking strategy to continually increase the complexity of the self-supervised reconstruction task. We conjecture that, by gradually increasing the task complexity, the model can learn more sophisticated and transferable representations. To facilitate this, we introduce a novel learnable masking module that possesses the capability to generate masks of different complexities, and integrate the proposed module into masked autoencoders (MAE). Our module is jointly trained with the MAE, while adjusting its behavior during training, transitioning from a partner to the MAE (optimizing the same rec
    
[^87]: 未来药物发现的实施：基于量子的机器学习模拟(QMLS)。

    Implementation of The Future of Drug Discovery: QuantumBased Machine Learning Simulation (QMLS). (arXiv:2308.08561v1 [q-bio.BM])

    [http://arxiv.org/abs/2308.08561](http://arxiv.org/abs/2308.08561)

    该论文介绍了一种名为QMLS的新概念，通过结合机器学习和量子模拟的方法，可以缩短药物研发的时间和降低成本。通过生成命中物和优化分子的过程，可以大大提高药物发现的效率。

    

    药物研发的研究与开发(R&D)阶段是一个漫长而昂贵的过程。为了改革这个过程，我们引入了新概念QMLS，将整个R&D阶段缩短到三到六个月，成本仅为五到八万美元。对于命中产生，机器学习分子生成(MLMG)根据目标蛋白的分子结构生成可能的命中物，而量子模拟(QS)根据与目标蛋白的反应和结合效果过滤原始实验中的分子。然后，对于铅优化，从MLMG和QS生成和过滤的结果分子进行比较，并通过机器学习分子变异(MLMV)将那些出现在两个过程中的分子制成数十种分子变体，而其他分子只制成几种变体。最后，所有优化的分子将经过多轮高标准的QS过滤，以确保反应效果。

    The Research & Development (R&D) phase of drug development is a lengthy and costly process. To revolutionize this process, we introduce our new concept QMLS to shorten the whole R&D phase to three to six months and decrease the cost to merely fifty to eighty thousand USD. For Hit Generation, Machine Learning Molecule Generation (MLMG) generates possible hits according to the molecular structure of the target protein while the Quantum Simulation (QS) filters molecules from the primary essay based on the reaction and binding effectiveness with the target protein. Then, For Lead Optimization, the resultant molecules generated and filtered from MLMG and QS are compared, and molecules that appear as a result of both processes will be made into dozens of molecular variations through Machine Learning Molecule Variation (MLMV), while others will only be made into a few variations. Lastly, all optimized molecules would undergo multiple rounds of QS filtering with a high standard for reaction ef
    
[^88]: AIs的发展脱靴法

    Developmental Bootstrapping of AIs. (arXiv:2308.04586v1 [cs.AI])

    [http://arxiv.org/abs/2308.04586](http://arxiv.org/abs/2308.04586)

    传统的符号AI方法和深度学习AI方法无法满足创建强大和可信赖的AI的挑战，然而，发展脱靴法通过模仿人类儿童的能力发展过程，为创建稳健可靠的AI提供了希望。

    

    尽管当前一些AI在封闭的世界，如棋盘游戏中超越了人类能力，但它们在混乱的现实世界中的表现有限。它们会犯奇怪的错误而且没有意识到。它们很难受到指导，不能运用常识，缺乏好奇心。它们不能成为良好的合作者。传统手动构建的符号AI方法构建的系统和使用生成和深度学习AI方法(包括大规模语言模型)构建的系统都无法应对这些挑战。它们不适合创建强大和可信赖的AI。尽管此方法不属于主流的AI方法，但发展脱靴法显示出希望。在发展脱靴法中，AI像人类儿童一样发展能力。它们从先天能力开始。像人类一样，它们与环境互动，并从互动中学习。它们通过自我发展的能力逐步扩展先天能力。它们互动并逐渐将所学应用于实际操作。

    Although some current AIs surpass human abilities especially in closed worlds such as board games, their performance in the messy real world is limited. They make strange mistakes and do not notice them. They cannot be instructed easily, fail to use common sense, and lack curiosity. They do not make good collaborators. Neither systems built using the traditional manually-constructed symbolic AI approach nor systems built using generative and deep learning AI approaches including large language models (LLMs) can meet the challenges. They are not well suited for creating robust and trustworthy AIs. Although it is outside of mainstream AI approaches, developmental bootstrapping shows promise. In developmental bootstrapping, AIs develop competences like human children do. They start with innate competences. Like humans, they interact with the environment and learn from their interactions. They incrementally extend their innate competences with self-developed competences. They interact and 
    
[^89]: AgentBench: 评估LLMs作为代理人

    AgentBench: Evaluating LLMs as Agents. (arXiv:2308.03688v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2308.03688](http://arxiv.org/abs/2308.03688)

    AgentBench是一个用于评估LLMs作为代理人的多维度基准，发现在复杂环境中，商业LLMs在充当代理人方面表现强劲，但与开源竞争对手相比，存在显著性能差距。该研究揭示了LLMs在长期推理、决策和指令遵循能力上的瓶颈。

    

    大型语言模型(LLMs)变得越来越智能和自主，针对传统的NLP任务之外的现实世界实际任务。因此，迫切需要在互动环境中评估LLMs作为代理人在具有挑战性的任务上的推理和决策能力。我们提出了AgentBench，一个多维度演变的基准，目前包括8个不同的环境，以评估LLM作为代理人在多轮开放式生成设置中的推理和决策能力。我们在27个基于API和开源的LLM上进行了广泛的测试，结果表明，虽然顶级商业LLM在复杂环境中表现出良好的代理人能力，但它们与开源竞争对手之间的性能差距很大。我们找出了环境和LLM中失败的典型原因，表明长期推理、决策和遵循指示能力不佳是开发可用LLM代理人的主要障碍。通过对代码和高质量进行训练

    Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks. As a result, there has been an urgent need to evaluate LLMs as agents on challenging tasks in interactive environments. We present AgentBench, a multi-dimensional evolving benchmark that currently consists of 8 distinct environments to assess LLM-as-Agent's reasoning and decision-making abilities in a multi-turn open-ended generation setting. Our extensive test over 27 API-based and open-sourced (OSS) LLMs shows that, while top commercial LLMs present a strong ability of acting as agents in complex environments, there is a significant disparity in performance between them and OSS competitors. We identify the typical reasons of failures in environments and LLMs, showing that poor long-term reasoning, decision-making, and instruction following abilities are the main obstacles for developing usable LLM agents. Training on code and high quality 
    
[^90]: 选择和增强：增强稠密检索知识图谱增强

    Select and Augment: Enhanced Dense Retrieval Knowledge Graph Augmentation. (arXiv:2307.15776v1 [cs.CL])

    [http://arxiv.org/abs/2307.15776](http://arxiv.org/abs/2307.15776)

    本文提出了一种选择和增强的方法来改进文本增强的知识图谱嵌入，通过多任务框架选择相关的文本描述，并对知识图谱嵌入进行对齐或增强。

    

    在自然语言处理社区中，将文本信息注入知识图谱（KG）实体表示已经成为一个值得探索的领域，以提高KG相关任务的性能。常用的外部知识增强KG嵌入的方法包括语义丰富的依赖解析特征、一组相关关键词，以及来自外部语料库（如维基百科）的完整文本描述。尽管这种创新（文本增强的KG嵌入）取得了一定的进展，但本文提出这种方法可以进一步改进。我们不再使用单一文本描述（因为文本的固有语义歧义无法充分表示一个实体），而是提出了一个多任务框架，既能选择与KG实体相关的一组文本描述，又能将KG嵌入与文本描述进行对齐或增强。与之前将形式化实体描述插入知识库的方法不同，这一方法是提供了对KG嵌入进行增强和对齐的新途径。

    Injecting textual information into knowledge graph (KG) entity representations has been a worthwhile expedition in terms of improving performance in KG oriented tasks within the NLP community. External knowledge often adopted to enhance KG embeddings ranges from semantically rich lexical dependency parsed features to a set of relevant key words to entire text descriptions supplied from an external corpus such as wikipedia and many more. Despite the gains this innovation (Text-enhanced KG embeddings) has made, the proposal in this work suggests that it can be improved even further. Instead of using a single text description (which would not sufficiently represent an entity because of the inherent lexical ambiguity of text), we propose a multi-task framework that jointly selects a set of text descriptions relevant to KG entities as well as align or augment KG embeddings with text descriptions. Different from prior work that plugs formal entity descriptions declared in knowledge bases, th
    
[^91]: WebArena: 一个用于构建自主智能体的真实网络环境

    WebArena: A Realistic Web Environment for Building Autonomous Agents. (arXiv:2307.13854v1 [cs.AI])

    [http://arxiv.org/abs/2307.13854](http://arxiv.org/abs/2307.13854)

    WebArena是一个用于构建自主智能体的真实网络环境，它包含了完全功能的网站，并且通过引入工具和外部知识库来鼓励智能体像人类一样解决任务。此外，WebArena还发布了一组用于评估任务完成功能正确性的基准任务。

    

    随着生成式人工智能的进展，通过自然语言指令进行日常任务的自主智能体的潜力逐渐显现。然而，当前的智能体主要是在简化的合成环境中创建和测试的，严重限制了现实世界场景的表示能力。在本文中，我们构建了一个高度逼真且可复现的智能体指令和控制环境。具体而言，我们关注在网站上执行任务的智能体，我们创建了一个包含来自四个常见领域的完全功能网站的环境，分别是电子商务、社交论坛讨论、协同软件开发和内容管理。我们的环境使用工具（如地图）和外部知识库（如用户手册）来鼓励像人类一样解决任务。在我们的环境基础上，我们发布了一组重点评估任务完成功能正确性的基准任务。我们基准任务具有多样性和长远的视野，并且被设计为鼓励智能体进行更深层次的任务理解和解决。

    With generative AI advances, the exciting potential for autonomous agents to manage daily tasks via natural language commands has emerged. However, cur rent agents are primarily created and tested in simplified synthetic environments, substantially limiting real-world scenario representation. In this paper, we build an environment for agent command and control that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on websites, and we create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and are desi
    
[^92]: SynerGPT:上下文学习用于个性化药物协同作用预测和药物设计

    SynerGPT: In-Context Learning for Personalized Drug Synergy Prediction and Drug Design. (arXiv:2307.11694v1 [cs.AI])

    [http://arxiv.org/abs/2307.11694](http://arxiv.org/abs/2307.11694)

    本文提出了一种通过上下文学习个性化药物协同作用并进行药物设计的方法，该方法利用小型的个性化数据集，不依赖于文本语料库、分子指纹或蛋白质相互作用的领域特定知识，取得了竞争性的结果。

    

    预测药物的协同组合可以加速癌症治疗的发现，特别是通过活检细胞个性化的治疗。在本文中，我们提出了一种新的设置和模型用于上下文中的药物协同学习。我们给出了一个小的“个性化数据集”，其中包含特定癌症靶细胞上下文中的10-20个药物协同关系。我们的目标是预测该上下文中的额外药物协同关系。受最近工作的启发，该工作通过预训练GPT语言模型（LM）来“上下文学习”常见的功能类。我们设计了一种 新的预训练方案，使GPT模型能够上下文学习“药物协同功能”。我们的模型 - 不使用任何文本语料库，分子指纹，蛋白质相互作用或任何其他领域特定的知识 - 能够取得竞争性的结果。我们进一步将我们的上下文方法与遗传算法结合起来，以优化模型提示并选择协同候选项。

    Predicting synergistic drug combinations can help accelerate discovery of cancer treatments, particularly therapies personalized to a patient's specific tumor via biopsied cells. In this paper, we propose a novel setting and models for in-context drug synergy learning. We are given a small "personalized dataset" of 10-20 drug synergy relationships in the context of specific cancer cell targets. Our goal is to predict additional drug synergy relationships in that context. Inspired by recent work that pre-trains a GPT language model (LM) to "in-context learn" common function classes, we devise novel pre-training schemes that enable a GPT model to in-context learn "drug synergy functions". Our model -- which does not use any textual corpora, molecular fingerprints, protein interaction or any other domain-specific knowledge -- is able to achieve competitive results. We further integrate our in-context approach with a genetic algorithm to optimize model prompts and select synergy candidates
    
[^93]: 朝着全球生物多样性评估迈出的一步：BIOSCAN-1M昆虫数据集

    A Step Towards Worldwide Biodiversity Assessment: The BIOSCAN-1M Insect Dataset. (arXiv:2307.10455v1 [cs.CV])

    [http://arxiv.org/abs/2307.10455](http://arxiv.org/abs/2307.10455)

    提出了一个新的大型手工标记昆虫图像数据集BIOSCAN-Insect，用于对昆虫生物多样性进行编目。该数据集还具有引人注目的特征，对广泛的机器学习社区也具有研究价值。

    

    为了对昆虫生物多样性进行编目，我们提出了一个新的大型手工标记昆虫图像数据集，即BIOSCAN-Insect数据集。每个记录都由专家进行分类，并且具有相关的遗传信息，包括原始核苷酸条形码序列和分配的条形码索引号，这些是基于遗传的物种分类的代理。本文介绍了一个精选的百万图像数据集，主要用于训练能够提供基于图像的分类评估的计算机视觉模型，但该数据集还具有引人注目的特征，对广泛的机器学习社区也具有研究价值。由于数据集固有的生物性质，展现出了具有长尾类别不平衡分布的特征。此外，分类标签是一个分层分类方案，在较低级别上呈现出高度细粒度的分类问题。除了激发对生物多样性研究的兴趣外，该数据集还促进了对机器学习的深入研究。

    In an effort to catalog insect biodiversity, we propose a new large dataset of hand-labelled insect images, the BIOSCAN-Insect Dataset. Each record is taxonomically classified by an expert, and also has associated genetic information including raw nucleotide barcode sequences and assigned barcode index numbers, which are genetically-based proxies for species classification. This paper presents a curated million-image dataset, primarily to train computer-vision models capable of providing image-based taxonomic assessment, however, the dataset also presents compelling characteristics, the study of which would be of interest to the broader machine learning community. Driven by the biological nature inherent to the dataset, a characteristic long-tailed class-imbalance distribution is exhibited. Furthermore, taxonomic labelling is a hierarchical classification scheme, presenting a highly fine-grained classification problem at lower levels. Beyond spurring interest in biodiversity research w
    
[^94]: 软件代理和数字孪生的系统比较：在工业生产中的差异、相似之处和协同作用

    Systematic Comparison of Software Agents and Digital Twins: Differences, Similarities, and Synergies in Industrial Production. (arXiv:2307.08421v2 [cs.SE] UPDATED)

    [http://arxiv.org/abs/2307.08421](http://arxiv.org/abs/2307.08421)

    本研究系统比较了工业应用中的软件代理和数字孪生。研究旨在确定这两种范式之间的差异、相似之处和潜在的协同作用。

    

    为了实现高度灵活和可变的生产，工业生产系统逐渐变得更加分散、互联和智能化。在这个愿景中，生产资产彼此合作，展示高度的自主性。此外，个体生产资产的知识在它们整个生命周期中是随时可用的。为了实现这个愿景，需要充分利用信息技术。在这个背景下，两种常用的软件范式是软件代理（简称代理）和数字孪生（DT）。本研究对工业应用中的代理和数字孪生进行了系统比较。研究的目标是确定这两种范式之间的差异、相似之处和潜在的协同作用。比较基于代理和数字孪生的应用目的、这些软件范式展示的属性和能力，以及它们如何在参考框架中分配。

    To achieve a highly agile and flexible production, it is envisioned that industrial production systems gradually become more decentralized, interconnected, and intelligent. Within this vision, production assets collaborate with each other, exhibiting a high degree of autonomy. Furthermore, knowledge about individual production assets is readily available throughout their entire life-cycles. To realize this vision, adequate use of information technology is required. Two commonly applied software paradigms in this context are Software Agents (referred to as Agents) and Digital Twins (DTs). This work presents a systematic comparison of Agents and DTs in industrial applications. The goal of the study is to determine the differences, similarities, and potential synergies between the two paradigms. The comparison is based on the purposes for which Agents and DTs are applied, the properties and capabilities exhibited by these software paradigms, and how they can be allocated within the Refere
    
[^95]: 回归优化：基于扩散的零样本3D人体姿势估计。

    Back to Optimization: Diffusion-based Zero-Shot 3D Human Pose Estimation. (arXiv:2307.03833v1 [cs.CV])

    [http://arxiv.org/abs/2307.03833](http://arxiv.org/abs/2307.03833)

    本文提出了一种结合基于优化和基于学习方法的零样本扩散优化（ZeDO）管道，用于解决3D人体姿势估计中的跨领域和野外挑战，取得了最先进的性能。

    

    基于学习的方法在大多数基准测试中比传统的基于优化的方法表现更好，它们主导了3D人体姿势估计任务。然而，在野外的3D人体姿势估计仍然是基于学习的模型面临的最大挑战，无论是2D-3D提升，图像到3D还是基于扩散的方法，因为训练的网络隐含地学习了相机内参和基于领域的3D人体姿势分布，并通过统计平均来估计姿势。另一方面，基于优化的方法可以逐案例估计结果，能够在野外预测更多样化和复杂的人体姿势。通过结合基于优化和基于学习的方法的优势，我们提出了一种零样本扩散优化（ZeDO）管道用于解决跨领域和野外3D人体姿势估计的问题。我们的多假设ZeDO在Human3.6M数据集上达到了最先进的性能（minMPJPE 51.4mm），并且无需对其进行训练。

    Learning-based methods have dominated the 3D human pose estimation (HPE) tasks with significantly better performance in most benchmarks than traditional optimization-based methods. Nonetheless, 3D HPE in the wild is still the biggest challenge of learning-based models, whether with 2D-3D lifting, image-to-3D, or diffusion-based methods, since the trained networks implicitly learn camera intrinsic parameters and domain-based 3D human pose distributions and estimate poses by statistical average. On the other hand, the optimization-based methods estimate results case-by-case, which can predict more diverse and sophisticated human poses in the wild. By combining the advantages of optimization-based and learning-based methods, we propose the Zero-shot Diffusion-based Optimization (ZeDO) pipeline for 3D HPE to solve the problem of cross-domain and in-the-wild 3D HPE. Our multi-hypothesis ZeDO achieves state-of-the-art (SOTA) performance on Human3.6M as minMPJPE $51.4$mm without training with
    
[^96]: 使用前softmax分数的归属方法的一个漏洞

    A Vulnerability of Attribution Methods Using Pre-Softmax Scores. (arXiv:2307.03305v1 [cs.LG])

    [http://arxiv.org/abs/2307.03305](http://arxiv.org/abs/2307.03305)

    这篇论文讨论了使用前softmax分数的归属方法的一个漏洞，该方法用于解释卷积神经网络分类器输出。与对抗性攻击不同，作者关注的是对归属方法进行小修改可能导致的影响，而不会改变模型的输出。

    

    我们讨论了一类用于解释卷积神经网络分类器输出的归属方法的一个漏洞。已知这种类型的网络容易受到对抗性攻击的影响，即输入的微小扰动可能会改变模型的输出。与此不同的是，我们关注的是对归属方法进行小修改可能导致的影响，而不会改变模型的输出。

    We discuss a vulnerability involving a category of attribution methods used to provide explanations for the outputs of convolutional neural networks working as classifiers. It is known that this type of networks are vulnerable to adversarial attacks, in which imperceptible perturbations of the input may alter the outputs of the model. In contrast, here we focus on effects that small modifications in the model may cause on the attribution method without altering the model outputs.
    
[^97]: PlanE: 平面图的表示学习

    PlanE: Representation Learning over Planar Graphs. (arXiv:2307.01180v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.01180](http://arxiv.org/abs/2307.01180)

    本研究的目标是设计用于高效学习平面图完备不变量的架构。

    

    图神经网络是用于图表示学习的杰出模型，其思想是通过一系列变换来迭代计算输入图中节点的表示，从而学习到的图函数在图同构时是不变的，从而使学习到的表示成为图不变量。另一方面，众所周知，这类模型学习到的图不变量是不完备的：存在一些非同构的图对，标准图神经网络无法区分它们。这在对一般图进行同构性测试的计算困难性的情况下并不令人惊讶，但对于一些特殊的图类来说，情况可能有所不同，例如平面图，对于这些图，已知存在高效的图同构测试算法。本文的目标是设计用于高效学习平面图完备不变量的架构。受Hopcroft和

    Graph neural networks are prominent models for representation learning over graphs, where the idea is to iteratively compute representations of nodes of an input graph through a series of transformations in such a way that the learned graph function is isomorphism invariant on graphs, which makes the learned representations graph invariants. On the other hand, it is well-known that graph invariants learned by these class of models are incomplete: there are pairs of non-isomorphic graphs which cannot be distinguished by standard graph neural networks. This is unsurprising given the computational difficulty of graph isomorphism testing on general graphs, but the situation begs to differ for special graph classes, for which efficient graph isomorphism testing algorithms are known, such as planar graphs. The goal of this work is to design architectures for efficiently learning complete invariants of planar graphs. Inspired by the classical planar graph isomorphism algorithm of Hopcroft and
    
[^98]: 可分离的物理信息神经网络

    Separable Physics-Informed Neural Networks. (arXiv:2306.15969v1 [cs.LG])

    [http://arxiv.org/abs/2306.15969](http://arxiv.org/abs/2306.15969)

    这项研究提出了一种可分离的物理信息神经网络（SPINN），通过逐个处理轴来显著减少了多维 PDE 中的网络传播数量，并使用正向模式自动微分降低了计算成本，使得可以在单个普通 GPU 上使用大量的配点。

    

    物理信息神经网络(PINNs)最近已经成为有希望的基于数据的PDE求解器，在各种PDE上显示出令人鼓舞的结果。然而，训练PINNs来解决多维PDE和逼近高度复杂解函数存在根本限制。在这些具有挑战性的PDE上所需的训练点数量(配点)大大增加，但由于昂贵的计算成本和庞大的内存开销，其受到严重限制。为了解决这个问题，我们提出了一种用于PINNs的网络架构和训练算法。所提出的方法，可分离的PINN (SPINN)，在多维PDE中按轴逐个处理，从而显著减少了网络传播的数量，不同于传统PINNs中的逐点处理。我们还提出使用正向模式自动微分来降低计算PDE残差的计算成本，从而在单个普通GPU上可以使用大量的配点(>10^7)。

    Physics-informed neural networks (PINNs) have recently emerged as promising data-driven PDE solvers showing encouraging results on various PDEs. However, there is a fundamental limitation of training PINNs to solve multi-dimensional PDEs and approximate highly complex solution functions. The number of training points (collocation points) required on these challenging PDEs grows substantially, but it is severely limited due to the expensive computational costs and heavy memory overhead. To overcome this issue, we propose a network architecture and training algorithm for PINNs. The proposed method, separable PINN (SPINN), operates on a per-axis basis to significantly reduce the number of network propagations in multi-dimensional PDEs unlike point-wise processing in conventional PINNs. We also propose using forward-mode automatic differentiation to reduce the computational cost of computing PDE residuals, enabling a large number of collocation points (>10^7) on a single commodity GPU. The
    
[^99]: 无监督的剧集生成方法用于图元学习

    Unsupervised Episode Generation for Graph Meta-learning. (arXiv:2306.15217v1 [cs.LG])

    [http://arxiv.org/abs/2306.15217](http://arxiv.org/abs/2306.15217)

    本文研究了无监督的剧集生成方法，通过元学习解决没有标签的少样本节点分类问题。它们充分利用所有节点信息，并且通过泛化能力提高性能。

    

    本文研究了无监督的剧集生成方法，通过元学习来解决没有标签的少样本节点分类问题。主流的少样本节点分类的元学习方法是在存在大量有标签节点用于训练的情况下开发的，然而在现实世界中可能无法获得这样的数据。虽然已经提出了一些解决标签稀缺性问题的研究，但它们仍然依赖于有限数量的有标签数据，这限制了对图中所有节点信息的充分利用。尽管自监督学习方法在没有标签的节点分类问题上很有效，但它们主要学习通用的节点嵌入，没有考虑要解决的下游任务，这可能限制了其性能。在这项工作中，我们提出了无监督的剧集生成方法，以利用它们在少样本节点分类任务中的泛化能力，同时解决标签稀缺性问题。我们首先提出了一种利用图增强方法的方法

    In this paper, we investigate Unsupervised Episode Generation methods to solve Few-Shot Node-Classification (FSNC) problem via Meta-learning without labels. Dominant meta-learning methodologies for FSNC were developed under the existence of abundant labeled nodes for training, which however may not be possible to obtain in the real-world. Although few studies have been proposed to tackle the label-scarcity problem, they still rely on a limited amount of labeled data, which hinders the full utilization of the information of all nodes in a graph. Despite the effectiveness of Self-Supervised Learning (SSL) approaches on FSNC without labels, they mainly learn generic node embeddings without consideration on the downstream task to be solved, which may limit its performance. In this work, we propose unsupervised episode generation methods to benefit from their generalization ability for FSNC tasks while resolving label-scarcity problem. We first propose a method that utilizes graph augmentat
    
[^100]: 训练先验影响文本到图像模型性能

    Training Priors Predict Text-To-Image Model Performance. (arXiv:2306.01755v1 [cs.CV])

    [http://arxiv.org/abs/2306.01755](http://arxiv.org/abs/2306.01755)

    本文测试了文本到图像模型对于训练先验的依赖程度，发现模型能够更好地生成与训练数据中出现频率更高的三元组对齐的图像，但这也会降低其生成以翻转三元组为基础的图像质量。

    

    文本到图像的模型能够生成一些关系，比如“宇航员骑马”，但却不能生成由相同基本部分组成的其他关系，比如“马骑宇航员”。这些失败通常被视为模型依赖训练先验而不是构建新颖的图像组合的证据。本文直接在稳定扩散2.1文本到图像模型上进行了测试。通过观察组成这些提示的主语-谓语-宾语 (SVO) 三元组（例如，“宇航员”，“骑”，“马”），我们发现，SVO三元组在训练数据中出现的次数越多，该模型就能生成与该三元组对齐的图像就越好。在这里，通过对齐，我们的意思是每个术语在生成的图像中以正确的关系出现。然而，这种增加的频率也会减少模型能够生成与翻转三元组对齐的图像的能力。例如，如果“宇航员骑马”在训练数据中频繁出现，那么“马骑宇航员”的对齐质量就会降低。

    Text-to-image models can often generate some relations, i.e., "astronaut riding horse", but fail to generate other relations composed of the same basic parts, i.e., "horse riding astronaut". These failures are often taken as evidence that the models rely on training priors rather than constructing novel images compositionally. This paper tests this intuition directly on the stablediffusion 2.1 text-to-image model. By looking at the subject-verb-object (SVO) triads that form the backbone of these prompts (e.g., "astronaut", "ride", "horse"), we find that the more often an SVO triad appears in the training data, the better the model can generate an image aligned with that triad. Here, by aligned we mean that each of the terms appears in the generated image in the proper relation to each other. However, this increased frequency also diminishes how well the model can generate an image aligned with the flipped triad. For example, if "astronaut riding horse" appears frequently in the trainin
    
[^101]: 通过神经引导符号抽象实现可解释和可解释逻辑策略

    Interpretable and Explainable Logical Policies via Neurally Guided Symbolic Abstraction. (arXiv:2306.01439v1 [cs.LG])

    [http://arxiv.org/abs/2306.01439](http://arxiv.org/abs/2306.01439)

    该论文介绍了一种名为NUDGE的策略，利用训练好的基于神经网络的代理来引导逻辑规则的搜索，实现了可解释和可解释的策略。

    

    神经网络所需要的有限先验使其成为使用强化学习（RL）编码和学习策略的主要选择。然而，它们也是黑匣子，在工作在图像级别时难以理解代理行为。因此，神经符号RL旨在首先创建可解释的策略。不幸的是，可解释性不意味着可解释性。为了实现解释性和可解释性，我们引入了神经引导可微分逻辑策略（NUDGE）。NUDGE利用训练好的基于神经网络的代理来引导候选加权逻辑规则的搜索，然后使用可微分的逻辑来训练逻辑代理。我们的实验评估表明，NUDGE代理可以产生可解释和可解释的策略，同时胜过纯神经代理，并展现出良好的灵活性，以适应不同初始状态和问题大小的环境。

    The limited priors required by neural networks make them the dominating choice to encode and learn policies using reinforcement learning (RL). However, they are also black-boxes, making it hard to understand the agent's behaviour, especially when working on the image level. Therefore, neuro-symbolic RL aims at creating policies that are interpretable in the first place. Unfortunately, interpretability is not explainability. To achieve both, we introduce Neurally gUided Differentiable loGic policiEs (NUDGE). NUDGE exploits trained neural network-based agents to guide the search of candidate-weighted logic rules, then uses differentiable logic to train the logic agents. Our experimental evaluation demonstrates that NUDGE agents can induce interpretable and explainable policies while outperforming purely neural ones and showing good flexibility to environments of different initial states and problem sizes.
    
[^102]: 使用数据一致性的直接扩散链桥解决逆问题

    Direct Diffusion Bridge using Data Consistency for Inverse Problems. (arXiv:2305.19809v1 [cs.CV])

    [http://arxiv.org/abs/2305.19809](http://arxiv.org/abs/2305.19809)

    本文提出了一种用于逆问题的直接扩散链桥算法，提高了逆问题求解器的性能，并通过使用数据一致性解决了当前DDB框架存在的关键限制。

    

    基于扩散模型的逆问题求解器表现出令人印象深刻的性能，但速度受限，主要是因为需要从噪声开始进行反向扩散采样。近期的一些工作尝试通过构建扩散过程来直接桥接特定逆问题的清洁和污染数据以减轻这个问题。在本文中，我们首先将这些现有工作统一命名为直接扩散链桥（DDB），证明尽管受不同理论的启发，但由此产生的算法在参数选择上的不同。然后，我们强调当前DDB框架的一个关键限制，即它不能保证数据一致性。为了解决这个问题，我们提出了一种修改的推断程序，它在不需要精细调整的情况下强制数据一致性。我们将得到的方法称为数据一致的DDB（CDDB），它在感知和失真指标方面都优于不一致的对应物，从而有效地推动了逆问题求解器的最新进展。

    Diffusion model-based inverse problem solvers have shown impressive performance, but are limited in speed, mostly as they require reverse diffusion sampling starting from noise. Several recent works have tried to alleviate this problem by building a diffusion process, directly bridging the clean and the corrupted for specific inverse problems. In this paper, we first unify these existing works under the name Direct Diffusion Bridges (DDB), showing that while motivated by different theories, the resulting algorithms only differ in the choice of parameters. Then, we highlight a critical limitation of the current DDB framework, namely that it does not ensure data consistency. To address this problem, we propose a modified inference procedure that imposes data consistency without the need for fine-tuning. We term the resulting method data Consistent DDB (CDDB), which outperforms its inconsistent counterpart in terms of both perception and distortion metrics, thereby effectively pushing the
    
[^103]: 可分目标的最优决策树：推动动态规划的极限

    Optimal Decision Trees for Separable Objectives: Pushing the Limits of Dynamic Programming. (arXiv:2305.19706v1 [cs.LG])

    [http://arxiv.org/abs/2305.19706](http://arxiv.org/abs/2305.19706)

    本研究提出了一种通用的动态规划方法来优化任何组合的可分离目标和约束条件，这种方法在可扩展性方面比通用求解器表现得更好。

    

    决策树的全局优化在准确性，大小和人类可理解性方面表现出良好的前景。然而，许多方法仍然依赖于通用求解器，可扩展性仍然是一个问题。动态规划方法已被证明具有更好的可扩展性，因为它们通过将子树作为独立的子问题解决来利用树结构。然而，这仅适用于可以分别优化子树的任务。我们详细研究了这种关系，并展示了实现这种可分离约束和目标任意组合的动态规划方法。在四个应用领域的实验表明了这种方法的普适性，同时也比通用求解器具有更好的可扩展性。

    Global optimization of decision trees has shown to be promising in terms of accuracy, size, and consequently human comprehensibility. However, many of the methods used rely on general-purpose solvers for which scalability remains an issue. Dynamic programming methods have been shown to scale much better because they exploit the tree structure by solving subtrees as independent subproblems. However, this only works when an objective can be optimized separately for subtrees. We explore this relationship in detail and show necessary and sufficient conditions for such separability and generalize previous dynamic programming approaches into a framework that can optimize any combination of separable objectives and constraints. Experiments on four application domains show the general applicability of this framework, while outperforming the scalability of general-purpose solvers by a large margin.
    
[^104]: 一种融合估计和规划实现探索的最大化目标函数的在线强化学习方法

    One Objective to Rule Them All: A Maximization Objective Fusing Estimation and Planning for Exploration. (arXiv:2305.18258v1 [cs.LG])

    [http://arxiv.org/abs/2305.18258](http://arxiv.org/abs/2305.18258)

    提出一种在线强化学习方法Maximize to Explore (MEX)，只需优化一个无约束的目标函数，自动平衡探索和利用，实现次线性遗憾。

    

    在在线强化学习中，平衡探索和利用对于以有效的方式找到最优策略至关重要。为了实现这一目标，现有的在线强化学习算法通常包括三个组成部分：估计、规划和探索。然而，为了应对通用函数逼近器，在大多数情况下都需要使用不切实际的算法组件来激励探索，例如数据相关的级别集内优化或繁琐的采样过程。为了解决这一挑战，我们提出了一种易于实现的强化学习框架，称为Maximize to Explore (MEX) ，它只需要无约束地优化一个集成了估计和规划组件的单一目标函数，同时自动平衡探索和利用。理论上，我们证明了对于马尔可夫决策过程的通用函数逼近，MEX实现了一个次线性的遗憾，进一步：

    In online reinforcement learning (online RL), balancing exploration and exploitation is crucial for finding an optimal policy in a sample-efficient way. To achieve this, existing sample-efficient online RL algorithms typically consist of three components: estimation, planning, and exploration. However, in order to cope with general function approximators, most of them involve impractical algorithmic components to incentivize exploration, such as optimization within data-dependent level-sets or complicated sampling procedures. To address this challenge, we propose an easy-to-implement RL framework called \textit{Maximize to Explore} (\texttt{MEX}), which only needs to optimize \emph{unconstrainedly} a single objective that integrates the estimation and planning components while balancing exploration and exploitation automatically. Theoretically, we prove that \texttt{MEX} achieves a sublinear regret with general function approximations for Markov decision processes (MDP) and is further 
    
[^105]: 通过多跳指令进行图像操作——一个新的数据集和基于弱监督的神经符号方法

    Image Manipulation via Multi-Hop Instructions -- A New Dataset and Weakly-Supervised Neuro-Symbolic Approach. (arXiv:2305.14410v1 [cs.CV])

    [http://arxiv.org/abs/2305.14410](http://arxiv.org/abs/2305.14410)

    该论文提出了一个基于神经符号概念学习的图像操作系统NeuroSIM，它可以通过多跳指令在多物体场景中执行复杂的推理，只需要弱监督的数据集，并创建了一个新的数据集。该系统具有很高的竞争力或超过SOTA基线。

    

    我们对通过自然语言文本进行图像操作感兴趣，这是多个人工智能应用程序中有用的任务，但需要对多模态空间进行复杂的推理。我们扩展了最近提出的神经符号概念学习(NSCL)，该方法在视觉问答(VQA)任务上非常有效，扩展其用于图像操作的任务。我们的系统称为NeuroSIM，可以在多物体场景上执行复杂的多跳推理，只需要以VQA的注释数据形式提供弱监督。NeuroSIM将指令解析成符号程序，基于由对象属性和操作组成的专业领域语言(DSL)，指导其执行。我们为这个任务创建了一个新的数据集，广泛的实验表明，NeuroSIM与使用监督数据进行操作的SOTA基线相比具有很高的竞争力或超过SOTA基线。

    We are interested in image manipulation via natural language text -- a task that is useful for multiple AI applications but requires complex reasoning over multi-modal spaces. We extend recently proposed Neuro Symbolic Concept Learning (NSCL), which has been quite effective for the task of Visual Question Answering (VQA), for the task of image manipulation. Our system referred to as NeuroSIM can perform complex multi-hop reasoning over multi-object scenes and only requires weak supervision in the form of annotated data for VQA. NeuroSIM parses an instruction into a symbolic program, based on a Domain Specific Language (DSL) comprising of object attributes and manipulation operations, that guides its execution. We create a new dataset for the task, and extensive experiments demonstrate that NeuroSIM is highly competitive with or beats SOTA baselines that make use of supervised data for manipulation.
    
[^106]: 动态多目标优化的向量自回归演化

    Vector Autoregressive Evolution for Dynamic Multi-Objective Optimisation. (arXiv:2305.12752v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2305.12752](http://arxiv.org/abs/2305.12752)

    向量自回归演化(VARE)通过使用向量自回归(VAR)模型和环境感知超突变(EAH)策略，有效处理动态多目标优化(DMO)中的环境变化，并提高种群的多样性。

    

    动态多目标优化(DMO)处理在不断变化的环境中具有多个（通常冲突的）目标的优化问题。这些问题对进化算法提出了各种挑战，进化算法通常被用来解决复杂的优化问题，由于其动态性和在变化环境中的资源限制。本文提出了向量自回归演化(VARE)，它由向量自回归(VAR)和环境感知超突变构成，以应对DMO中的环境变化。VARE构建了一种考虑决策变量之间的相互关系的VAR模型，以有效预测动态环境中的变化解。此外，VARE引入了环境感知超突变(EAH)来解决现有超突变策略在增加动态场景下的种群多样性时的盲目性，因为预测方法在这种情况下不适用。VAR和EAH的无缝集成以适应环境的方式使VARE能够有效处理广泛的问题。

    Dynamic multi-objective optimisation (DMO) handles optimisation problems with multiple (often conflicting) objectives in varying environments. Such problems pose various challenges to evolutionary algorithms, which have popularly been used to solve complex optimisation problems, due to their dynamic nature and resource restrictions in changing environments. This paper proposes vector autoregressive evolution (VARE) consisting of vector autoregression (VAR) and environment-aware hypermutation to address environmental changes in DMO. VARE builds a VAR model that considers mutual relationship between decision variables to effectively predict the moving solutions in dynamic environments. Additionally, VARE introduces EAH to address the blindness of existing hypermutation strategies in increasing population diversity in dynamic scenarios where predictive approaches are unsuitable. A seamless integration of VAR and EAH in an environment-adaptive manner makes VARE effective to handle a wide r
    
[^107]: 神经基础中的心理模拟：预测动态场景中的潜在表现

    Neural Foundations of Mental Simulation: Future Prediction of Latent Representations on Dynamic Scenes. (arXiv:2305.11772v1 [cs.AI])

    [http://arxiv.org/abs/2305.11772](http://arxiv.org/abs/2305.11772)

    本研究探究了人类和动物如何推断物理世界的基本动态轨迹以及如何预测未来可能出现的状态，并评估了几类感知-认知网络的预测能力，发现在效率、普遍性和可解释性间存在权衡。

    

    人和动物对物理世界有着丰富而灵活的理解，能够推断出事件的基本动态轨迹，预测未来可能出现的状态，并利用这些信息规划和预测行为的后果。然而，这些计算背后的神经机制尚不清楚。本文采用目标驱动的建模方法，结合密集的神经生理学数据和高通量的人类行为输出来探究这个问题。具体来说，我们构建和评估了几类感知-认知网络来预测丰富、具有行为学意义的环境的未来状态，从像素或面向对象目标的自主监督端到端模型，到将纯静态基于图像或动态视频的预训练基础模型的潜在空间进行未来预测的模型。我们发现这些模型类别在其预测神经和行为数据的能力上有很强的差异，无论在其培训领域内或外，这种差异反映了效率、普遍性和可解释性之间的基本权衡。

    Humans and animals have a rich and flexible understanding of the physical world, which enables them to infer the underlying dynamical trajectories of objects and events, plausible future states, and use that to plan and anticipate the consequences of actions. However, the neural mechanisms underlying these computations are unclear. We combine a goal-driven modeling approach with dense neurophysiological data and high-throughput human behavioral readouts to directly impinge on this question. Specifically, we construct and evaluate several classes of sensory-cognitive networks to predict the future state of rich, ethologically-relevant environments, ranging from self-supervised end-to-end models with pixel-wise or object-centric objectives, to models that future predict in the latent space of purely static image-based or dynamic video-based pretrained foundation models. We find strong differentiation across these model classes in their ability to predict neural and behavioral data both w
    
[^108]: TELeR：用于基准测试复杂任务的LLM提示的通用分类法

    TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks. (arXiv:2305.11430v1 [cs.AI])

    [http://arxiv.org/abs/2305.11430](http://arxiv.org/abs/2305.11430)

    本文提出了一个通用分类法，可以用来设计具有特定属性的提示来执行各种复杂任务，从而解决了LLM在执行复杂任务方面的性能变异巨大的问题。

    

    尽管LLM在传统对话环境中理解和生成文本时取得了巨大成功，但它们在执行不明确的复杂任务方面的潜力仍然受到很少的研究。本文提出了一种通用分类法，可以用来设计具有特定属性的提示，以执行各种复杂任务，从而解决了使用不同提示类型/风格和提示提供的不同详细程度时LLM性能变化巨大的问题。这个分类法将使未来的基准测试研究能够报告研究中使用的特定提示类别，从而实现跨不同研究的有意义的比较。

    While LLMs have shown great success in understanding and generating text in traditional conversational settings, their potential for performing ill-defined complex tasks is largely under-studied. Indeed, we are yet to conduct comprehensive benchmarking studies with multiple LLMs that are exclusively focused on a complex task. However, conducting such benchmarking studies is challenging because of the large variations in LLMs' performance when different prompt types/styles are used and different degrees of detail are provided in the prompts. To address this issue, the paper proposes a general taxonomy that can be used to design prompts with specific properties in order to perform a wide range of complex tasks. This taxonomy will allow future benchmarking studies to report the specific categories of prompts used as part of the study, enabling meaningful comparisons across different studies. Also, by establishing a common standard through this taxonomy, researchers will be able to draw mo
    
[^109]: API-Bank: 一种针对工具增强的大型语言模型的全面基准测试

    API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs. (arXiv:2304.08244v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2304.08244](http://arxiv.org/abs/2304.08244)

    API-Bank是一个针对工具增强的大型语言模型的基准测试，通过解决三个关键问题来评估LLMs的能力，并展示了GPT-3.5的改进能力。

    

    最近的研究表明，大型语言模型（LLMs）可以通过利用外部工具来增强其能力。然而，仍然存在三个关键问题尚未解答：（1）目前的LLMs在利用工具方面的效果如何？（2）如何增强LLMs利用工具的能力？（3）如何克服利用工具所面临的障碍？为了解决这些问题，我们引入了API-Bank，一个具有突破性意义的基准测试，专门为工具增强的LLMs设计。针对第一个问题，我们开发了一个可运行的评估系统，包含73个API工具。我们使用753个API调用注释了314个工具使用对话，以评估现有LLMs在规划、检索和调用API方面的能力。针对第二个问题，我们构建了一个包含来自1,000个不同领域的2,138个API的1,888个工具使用对话的全面训练集。使用这个数据集，我们训练了Lynx，这是一个从Alpaca初始化的工具增强LLM。实验结果表明，GPT-3.5显示出了改进的能力。

    Recent research has demonstrated that Large Language Models (LLMs) can enhance their capabilities by utilizing external tools. However, three pivotal questions remain unanswered: (1) How effective are current LLMs in utilizing tools? (2) How can we enhance LLMs' ability to utilize tools? (3) What obstacles need to be overcome to leverage tools? To address these questions, we introduce API-Bank, a groundbreaking benchmark, specifically designed for tool-augmented LLMs. For the first question, we develop a runnable evaluation system consisting of 73 API tools. We annotate 314 tool-use dialogues with 753 API calls to assess the existing LLMs' capabilities in planning, retrieving, and calling APIs. For the second question, we construct a comprehensive training set containing 1,888 tool-use dialogues from 2,138 APIs spanning 1,000 distinct domains. Using this dataset, we train Lynx, a tool-augmented LLM initialized from Alpaca. Experimental results demonstrate that GPT-3.5 exhibits improved
    
[^110]: 使AI“口渴”减少的方法：揭示和解决AI模型的秘密水消耗

    Making AI Less "Thirsty": Uncovering and Addressing the Secret Water Footprint of AI Models. (arXiv:2304.03271v1 [cs.LG])

    [http://arxiv.org/abs/2304.03271](http://arxiv.org/abs/2304.03271)

    本论文揭示以及提出了解决人工智能模型巨大水足迹的方法，因为其淡水消耗已经引起国际社会的重视，并且AI模型应该承担社会责任，做出面对水危机的表率。

    

    人工智能（AI）模型的碳足迹不断增长，特别是像GPT-3和GPT-4这样的大型模型，已经受到公众的关注。然而，同等重要且巨大的AI模型水印尚未引起人们的注意。例如，在微软最先进的美国数据中心中训练GPT-3可以直接消耗70万升清洁淡水（相当于生产370辆宝马汽车或320辆特斯拉电动汽车），如果在微软的亚洲数据中心进行训练，这个水消耗量将增加三倍，但这样的信息一直被保密。这极其令人担忧，因为淡水短缺已成为在人口迅速增长、水资源减少和老化的水基础设施的背景下，我们所有人面临的最紧迫的挑战之一。为了应对全球水资源的挑战，人工智能模型可以，而且应该，承担社会责任，以身作则解决自己的问题。

    The growing carbon footprint of artificial intelligence (AI) models, especially large ones such as GPT-3 and GPT-4, has been undergoing public scrutiny. Unfortunately, however, the equally important and enormous water footprint of AI models has remained under the radar. For example, training GPT-3 in Microsoft's state-of-the-art U.S. data centers can directly consume 700,000 liters of clean freshwater (enough for producing 370 BMW cars or 320 Tesla electric vehicles) and the water consumption would have been tripled if training were done in Microsoft's Asian data centers, but such information has been kept as a secret. This is extremely concerning, as freshwater scarcity has become one of the most pressing challenges shared by all of us in the wake of the rapidly growing population, depleting water resources, and aging water infrastructures. To respond to the global water challenges, AI models can, and also should, take social responsibility and lead by example by addressing their own 
    
[^111]: 使用SQL查询大型语言模型

    Querying Large Language Models with SQL. (arXiv:2304.00472v2 [cs.DB] UPDATED)

    [http://arxiv.org/abs/2304.00472](http://arxiv.org/abs/2304.00472)

    该论文介绍了使用SQL查询大型语言模型的方法，通过利用预训练的LLMs中的信息，可以从非结构化文本中提取数据并进行查询。通过Galois原型实现了查询LLMs的新物理运算符，并取得了令人鼓舞的结果。

    

    在许多使用场景中，信息存储在文本中，但无法在结构化数据中获取。然而，从自然语言文本中提取数据以精确适配模式，并实现查询，是一项具有挑战性的任务。随着预训练的大型语言模型（LLMs）的兴起，现在有了有效的解决方案，可以存储和使用从大规模文本文档中提取的信息。因此，我们设想使用SQL查询来涵盖传统数据库无法提取的广泛数据，通过利用LLMs中的信息。为了支撑这个愿景，我们提出了基于传统数据库体系结构的Galois原型，但具有用于查询底层LLM的新物理算子。主要思想是使用提示符执行查询计划中的某些操作符，从LLM中检索数据。对于大类别的SQL查询，查询LLMs返回结构良好的关系，取得了令人鼓舞的定性结果。初步实验结果使预训练的LLMs成为一个有前景的方法。

    In many use-cases, information is stored in text but not available in structured data. However, extracting data from natural language text to precisely fit a schema, and thus enable querying, is a challenging task. With the rise of pre-trained Large Language Models (LLMs), there is now an effective solution to store and use information extracted from massive corpora of text documents. Thus, we envision the use of SQL queries to cover a broad range of data that is not captured by traditional databases by tapping the information in LLMs. To ground this vision, we present Galois, a prototype based on a traditional database architecture, but with new physical operators for querying the underlying LLM. The main idea is to execute some operators of the the query plan with prompts that retrieve data from the LLM. For a large class of SQL queries, querying LLMs returns well structured relations, with encouraging qualitative results. Preliminary experimental results make pre-trained LLMs a prom
    
[^112]: 通过基于目标的语言描述发现分布差异

    Goal Driven Discovery of Distributional Differences via Language Descriptions. (arXiv:2302.14233v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.14233](http://arxiv.org/abs/2302.14233)

    本论文提出了一个新的任务D5，通过目标驱动的方式自动发现两个大型语料库之间的差异。作者构建了一个D5系统，并提出了一套统一的评估指标来衡量其性能。通过实验证明，语言模型可以使用目标驱动的方法来发现语料库差异。

    

    挖掘大型语料库可以产生有用的发现，但对人类来说耗时。我们提出了一个新的任务D5，它以目标驱动的方式自动发现两个大型语料库之间的差异。任务输入是一个问题，包括一个研究目标“比较药物A和药物B的副作用”，以及一个语料库对（两个大型患者自报反应的集合）。输出是对这些语料库差异的语言描述（发现）（使用药物A后，患者更经常提到“偏执感”）。我们构建了一个D5系统，并为了定量衡量其性能，我们贡献了一个元数据集OpenD5，聚合了675个开放问题，涵盖了商业、社会科学、人文学科、机器学习和健康等领域，同时我们提出了一套统一的评估指标：有效性、相关性、新颖性和显著性。通过数据集和统一指标，我们确认语言模型可以使用目标驱动的方法来发现语料库差异。

    Mining large corpora can generate useful discoveries but is time-consuming for humans. We formulate a new task, D5, that automatically discovers differences between two large corpora in a goal-driven way. The task input is a problem comprising a research goal "$\textit{comparing the side effects of drug A and drug B}$" and a corpus pair (two large collections of patients' self-reported reactions after taking each drug). The output is a language description (discovery) of how these corpora differ (patients taking drug A "$\textit{mention feelings of paranoia}$" more often). We build a D5 system, and to quantitatively measure its performance, we 1) contribute a meta-dataset, OpenD5, aggregating 675 open-ended problems ranging across business, social sciences, humanities, machine learning, and health, and 2) propose a set of unified evaluation metrics: validity, relevance, novelty, and significance. With the dataset and the unified metrics, we confirm that language models can use the goal
    
[^113]: 使用Tsallis KL散度的广义Munchausen强化学习

    Generalized Munchausen Reinforcement Learning using Tsallis KL Divergence. (arXiv:2301.11476v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.11476](http://arxiv.org/abs/2301.11476)

    这篇论文通过研究广义的Tsallis KL散度，扩展了Munchausen强化学习算法，并提供了一种将KL正则化纳入实际算法的方法。对于Tsallis KL，当$q > 1$时，可以获得新的策略优化选项。

    

    许多强化学习中的策略优化方法都采用Kullback-Leibler（KL）散度到上一个策略，以防止策略变化过快。这个想法最初是在Conservative Policy Iteration的一篇重要论文中提出的，近似算法如TRPO和Munchausen Value Iteration（MVI）给出了有限的方法。我们通过研究一种广义的KL散度 - 称为Tsallis KL散度 - 来继续这一工作，它在定义中使用了$q$-对数。这种方法是一种严格的推广，因为$q = 1$对应于标准的KL散度；$q > 1$提供了一系列新的选项。我们对在Tsallis KL下学习的策略类型进行了表征，并阐述了何时$ q > 1 $可能是有益的。为了获得一个将Tsallis KL正则化纳入实际算法的方法，我们扩展了MVI，它是一种最简单的包含KL正则化的方法之一。我们展示了这种广义MVI（$q$）获得了显著的改进。

    Many policy optimization approaches in reinforcement learning incorporate a Kullback-Leilbler (KL) divergence to the previous policy, to prevent the policy from changing too quickly. This idea was initially proposed in a seminal paper on Conservative Policy Iteration, with approximations given by algorithms like TRPO and Munchausen Value Iteration (MVI). We continue this line of work by investigating a generalized KL divergence -- called the Tsallis KL divergence -- which use the $q$-logarithm in the definition. The approach is a strict generalization, as $q = 1$ corresponds to the standard KL divergence; $q > 1$ provides a range of new options. We characterize the types of policies learned under the Tsallis KL, and motivate when $q >1$ could be beneficial. To obtain a practical algorithm that incorporates Tsallis KL regularization, we extend MVI, which is one of the simplest approaches to incorporate KL regularization. We show that this generalized MVI($q$) obtains significant improve
    
[^114]: AtMan:通过节约内存的注意力机制理解Transformer的预测

    AtMan: Understanding Transformer Predictions Through Memory Efficient Attention Manipulation. (arXiv:2301.08110v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.08110](http://arxiv.org/abs/2301.08110)

    AtMan是一种通过在生成式Transformer模型中操纵注意力机制来解释预测的方法，相较于传统方法几乎不占用额外内存，可在生产环境中使用。

    

    生成式的Transformer模型越来越复杂，参数数量大且具备处理多输入模态的能力。目前解释它们的预测的方法资源密集。最重要的是，它们需要过多的额外内存，因为它们依赖反向传播，而反向传播会分配的GPU内存几乎是前向传播的两倍。这使得在生产环境中使用它们非常困难，甚至不可能。我们提出了AtMan，它几乎不会产生额外的成本，用于解释生成式Transformer模型。具体而言，AtMan是一种模态无关的扰动方法，通过操纵Transformer的注意力机制生成与输出预测相关性的重要性图。AtMan不使用反向传播，而是在嵌入空间中应用一种基于余弦相似度邻近性的可并行化基于记号的搜索方法。我们在文本和图像-文本基准测试中进行了详尽的实验

    Generative transformer models have become increasingly complex, with large numbers of parameters and the ability to process multiple input modalities. Current methods for explaining their predictions are resource-intensive. Most crucially, they require prohibitively large amounts of extra memory, since they rely on backpropagation which allocates almost twice as much GPU memory as the forward pass. This makes it difficult, if not impossible, to use them in production. We present AtMan that provides explanations of generative transformer models at almost no extra cost. Specifically, AtMan is a modality-agnostic perturbation method that manipulates the attention mechanisms of transformers to produce relevance maps for the input with respect to the output prediction. Instead of using backpropagation, AtMan applies a parallelizable token-based search method based on cosine similarity neighborhood in the embedding space. Our exhaustive experiments on text and image-text benchmarks demonstra
    
[^115]: 面向开放领域的多文档摘要

    Towards multi-document summarization in the open-domain. (arXiv:2212.10526v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.10526](http://arxiv.org/abs/2212.10526)

    本论文针对"开放领域"的多文档摘要任务进行研究，发现最先进的摘要器在此情境下性能下降严重，但进行额外的开放领域的训练可以降低对不完美检索的敏感性。

    

    多文档摘要(MDS)通常假设提供一组主题相关的文档。但是，这个文档集通常是数据集策划过程的产物；在实践中，它不一定可用，需要根据信息需求，即问题或主题陈述进行检索。我们通过形式化任务并使用现有数据集，检索器和摘要器来引导这个更具挑战性的“开放领域”设置的研究。通过广泛的实验，我们确定：(1)即使检索性能较高，最先进的摘要器在应用于开放领域时也会大幅降低性能;(2)在开放领域的设置中进行额外的训练可以降低对不完美检索的敏感性，(3)摘要器对检索重复文档和检索文档的顺序不敏感，但对其他错误，如检索无关文档的敏感性较高。根据我们的研究结果，我们提供了

    Multi-document summarization (MDS) traditionally assumes a set of topic-related documents are provided. However, this document set is often an artifact of the dataset curation process; in practice, it is not necessarily available and would need to be retrieved given an information need, i.e. a question or topic statement. We study this more challenging "open-domain" setting by formalizing the task and bootstrapping it using existing datasets, retrievers and summarizers. Via extensive experimentation, we determine that: (1) state-of-the-art summarizers suffer large reductions in performance when applied to the open-domain, even when retrieval performance is high, (2) additional training in the open-domain setting can reduce this sensitivity to imperfect retrieval, and (3) summarizers are insensitive to the retrieval of duplicate documents and the order of retrieved documents, but highly sensitive to other errors, like the retrieval of irrelevant documents. Based on our results, we provi
    
[^116]: 可变化决策频率的选项评论者

    Variable Decision-Frequency Option Critic. (arXiv:2212.04407v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.04407](http://arxiv.org/abs/2212.04407)

    这篇论文提出了一个名为CTCO的框架，其中代理选择选项作为可变持续时间的子策略。这个框架可以以任何所需频率与系统交互，从而提供平滑的动作变化，相比传统RL和时间抽象RL方法，其性能更好。

    

    在传统的强化学习算法中，代理在离散和固定的时间间隔内做出决策。决策之间的持续时间变成了一个关键的超参数，因为设置得太短可能会增加问题的难度，需要代理进行多次决策才能实现其目标，而设置得太长会导致代理失去对系统的控制。然而，物理系统不一定需要恒定的控制频率，对于学习代理来说，一般情况下，当需要时以高频率运行，而在可能时以低频率运行更好。我们提出了一个名为连续时间连续选项 (CTCO) 的框架，其中代理选择选项作为可变持续时间的子策略。这些选项是时间连续的，可以以任何所需频率与系统交互，从而提供平滑的动作变化。我们通过将其性能与传统 RL 和时间抽象 RL 方法进行比较，展示了 CTCO 的有效性。

    In classic reinforcement learning algorithms, agents make decisions at discrete and fixed time intervals. The duration between decisions becomes a crucial hyperparameter, as setting it too short may increase the difficulty of the problem by requiring the agent to make numerous decisions to achieve its goal, while setting it too long can result in the agent losing control over the system. However, physical systems do not necessarily require a constant control frequency, and for learning agents, it is often preferable to operate with a low frequency when possible and a high frequency when necessary. We propose a framework called Continuous-Time Continuous-Options (CTCO), where the agent chooses options as sub-policies of variable durations. These options are time-continuous and can interact with the system at any desired frequency providing a smooth change of actions. We demonstrate the effectiveness of CTCO by comparing its performance to classical RL and temporal-abstraction RL methods
    
[^117]: 多目标强化学习中的福利和公平性

    Welfare and Fairness in Multi-objective Reinforcement Learning. (arXiv:2212.01382v4 [cs.GT] UPDATED)

    [http://arxiv.org/abs/2212.01382](http://arxiv.org/abs/2212.01382)

    本论文研究了多目标强化学习中的福利和公平性问题，提出了一种基于非线性福利函数的Q-learning算法，通过非线性标量化学习更新和非稳态动作选择来优化策略。算法被证明是可收敛的。

    

    我们研究了公平多目标强化学习，其中一个代理必须学习一个能够在多个维度的向量值奖励上同时获得高回报的策略。受公平资源分配文献的启发，我们将其建模为期望福利最大化问题，针对向量的长期累积奖励的非线性公平福利函数。其中一个经典的例子是纳什社会福利函数，或者几何平均数，其对数变换也被称为比例公平目标。我们表明，即使在表格化的情况下，对期望纳什社会福利进行近似最优化也是计算上难以处理的。尽管如此，我们提供了一种创新的Q-learning改进方法，结合非线性标量化学习更新和非稳态动作选择，以学习有效的优化非线性福利函数的策略。我们证明了我们的算法是可收敛的，并进行了实验证明。

    We study fair multi-objective reinforcement learning in which an agent must learn a policy that simultaneously achieves high reward on multiple dimensions of a vector-valued reward. Motivated by the fair resource allocation literature, we model this as an expected welfare maximization problem, for some non-linear fair welfare function of the vector of long-term cumulative rewards. One canonical example of such a function is the Nash Social Welfare, or geometric mean, the log transform of which is also known as the Proportional Fairness objective. We show that even approximately optimal optimization of the expected Nash Social Welfare is computationally intractable even in the tabular case. Nevertheless, we provide a novel adaptation of Q-learning that combines non-linear scalarized learning updates and non-stationary action selection to learn effective policies for optimizing nonlinear welfare functions. We show that our algorithm is provably convergent, and we demonstrate experimental
    
[^118]: 图形反事实解释的综述: 定义, 方法, 评估

    A Survey on Graph Counterfactual Explanations: Definitions, Methods, Evaluation. (arXiv:2210.12089v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2210.12089](http://arxiv.org/abs/2210.12089)

    这篇综述研究了图形反事实解释的概念、方法、评估及其应用于图神经网络的情况，提供了分类法、统一的符号表示、基准数据集和评估指标，并对十四种方法、二十二个数据集和十九个指标进行了讨论和整合。未来的工作主要集中在解决开放的挑战上。

    

    图神经网络 (GNNs) 在社区检测和分子分类方面表现出色。反事实解释 (CE) 提供反例来克服黑盒模型的透明度限制。由于对图学习的关注不断增长，我们将重点关注 GNNs 的 CE 概念。我们分析了非常规的手段，提供了分类法，统一的符号表示，以及基准数据集和评估指标。我们讨论了十四种方法，它们的评估协议，二十二个数据集和十九个指标。我们整合了大多数方法到 GRETEL 库中，进行了实证评估，以了解它们的优势和缺点。我们强调了开放的挑战和未来的工作。

    Graph Neural Networks (GNNs) perform well in community detection and molecule classification. Counterfactual Explanations (CE) provide counter-examples to overcome the transparency limitations of black-box models. Due to the growing attention in graph learning, we focus on the concepts of CE for GNNs. We analysed the SoA to provide a taxonomy, a uniform notation, and the benchmarking datasets and evaluation metrics. We discuss fourteen methods, their evaluation protocols, twenty-two datasets, and nineteen metrics. We integrated the majority of methods into the GRETEL library to conduct an empirical evaluation to understand their strengths and pitfalls. We highlight open challenges and future work.
    
[^119]: GLM-130B: 一个开源的双语预训练模型

    GLM-130B: An Open Bilingual Pre-trained Model. (arXiv:2210.02414v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.02414](http://arxiv.org/abs/2210.02414)

    GLM-130B是一个具有1300亿参数的开源双语预训练模型，能够超越GPT-3和最大的中文语言模型ERNIE TITAN 3.0 260B，在多个基准测试中表现出色。

    

    本文介绍了GLM-130B，一个具有1300亿参数的双语（英语和中文）预训练语言模型。它是为了打开1000亿规模的模型，至少与GPT-3（davinci）一样好，并揭示如何成功地进行如此规模的预训练。在这个过程中，我们遇到了许多意外的技术和工程挑战，特别是在损失峰和发散方面。在本文中，我们介绍了GLM-130B的训练过程，包括设计选择、提高效率和稳定性的训练策略，以及工程努力。GLM-130B模型在广泛的英语基准测试中明显优于GPT-3 175B（davinci），但在OPT-175B和BLOOM-176B中没有观察到性能优势。它还在相关基准测试中始终且显著优于最大的中文语言模型ERNIE TITAN 3.0 260B。最后，我们利用GLM-130B的独特缩放性能进行实验。

    We introduce GLM-130B, a bilingual (English and Chinese) pre-trained language model with 130 billion parameters. It is an attempt to open-source a 100B-scale model at least as good as GPT-3 (davinci) and unveil how models of such a scale can be successfully pre-trained. Over the course of this effort, we face numerous unexpected technical and engineering challenges, particularly on loss spikes and divergence. In this paper, we introduce the training process of GLM-130B including its design choices, training strategies for both efficiency and stability, and engineering efforts. The resultant GLM-130B model offers significant outperformance over GPT-3 175B (davinci) on a wide range of popular English benchmarks while the performance advantage is not observed in OPT-175B and BLOOM-176B. It also consistently and significantly outperforms ERNIE TITAN 3.0 260B -- the largest Chinese language model -- across related benchmarks. Finally, we leverage a unique scaling property of GLM-130B to rea
    
[^120]: 隐式双塔策略

    Implicit Two-Tower Policies. (arXiv:2208.01191v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.01191](http://arxiv.org/abs/2208.01191)

    隐式双塔策略（ITT）是一种新的结构化强化学习策略体系，通过在策略堆栈中显式区分动作和状态处理，实现了显著的计算效益和更好的性能，在黑盒/进化优化方面表现出色。

    

    我们提出了一种新的结构化强化学习策略体系，即隐式双塔（ITT）策略，其中动作基于其可学习的潜在表示与输入状态的注意力分数进行选择。通过在策略堆栈中显式区分动作和状态处理，我们实现了两个主要目标：显著的计算效益和更好的性能。我们的架构适用于离散和连续动作空间。通过在OpenAI Gym和DeepMind Control Suite的15个环境上进行测试，我们展示了ITT架构特别适用于黑盒/进化优化，相应的策略训练算法优于其草率的隐式对应物以及常用的显式策略。我们通过展示如何应用哈希和惰性塔更新等技术，关键依赖于ITT的双塔结构，来补充我们的分析。

    We present a new class of structured reinforcement learning policy-architectures, Implicit Two-Tower (ITT) policies, where the actions are chosen based on the attention scores of their learnable latent representations with those of the input states. By explicitly disentangling action from state processing in the policy stack, we achieve two main goals: substantial computational gains and better performance. Our architectures are compatible with both: discrete and continuous action spaces. By conducting tests on 15 environments from OpenAI Gym and DeepMind Control Suite, we show that ITT-architectures are particularly suited for blackbox/evolutionary optimization and the corresponding policy training algorithms outperform their vanilla unstructured implicit counterparts as well as commonly used explicit policies. We complement our analysis by showing how techniques such as hashing and lazy tower updates, critically relying on the two-tower structure of ITTs, can be applied to obtain add
    
[^121]: 处理谬误的主题-方面-论证模型

    Theme Aspect Argumentation Model for Handling Fallacies. (arXiv:2205.15141v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2205.15141](http://arxiv.org/abs/2205.15141)

    本文介绍了一种用于处理谬误的主题-方面-论证模型，通过形式约束来表征谬误，提出了可解释的谬误识别的替代方法，能进行修辞建模和深层语义分析。

    

    从日常讨论到营销广告再到政治言论，信息操作无处不在。因此，拥有一套正确的工具来抵御操纵性言辞或谬误变得越来越重要。现有的自动识别谬误的技术在自然语言处理研究中正在被探索。然而，一个上下文中的谬误在另一个上下文中可能不是谬误，因此有必要解释它被判断为谬误的方式和原因。为了可解释的谬误识别，我们提出了一种通过形式约束来表征谬误的新方法，作为传统谬误分类的可行替代方法。为了实现这一目标，我们引入了一种新颖的上下文感知论证模型，即主题-方面-论证模型，它可以实现两个功能：对给定的论证进行建模（修辞建模）以及更深入的语义分析。

    From daily discussions to marketing ads to political statements, information manipulation is rife. It is increasingly more important that we have the right set of tools to defend ourselves from manipulative rhetoric, or fallacies. Suitable techniques to automatically identify fallacies are being investigated in natural language processing research. However, a fallacy in one context may not be a fallacy in another context, so there is also a need to explain how and why it has come to be judged a fallacy. For the explainable fallacy identification, we present a novel approach to characterising fallacies through formal constraints, as a viable alternative to more traditional fallacy classifications by informal criteria. To achieve this objective, we introduce a novel context-aware argumentation model, the theme aspect argumentation model, which can do both: the modelling of a given argumentation as it is expressed (rhetorical modelling); and a deeper semantic analysis of the rhetorical ar
    
[^122]: 公正游戏：对强化学习的挑战

    Impartial Games: A Challenge for Reinforcement Learning. (arXiv:2205.12787v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2205.12787](http://arxiv.org/abs/2205.12787)

    AlphaZero-style reinforcement learning algorithms excel in various board games but face challenges with impartial games. The researchers present a concrete example of the game nim, and show that AlphaZero-style algorithms have difficulty learning these impartial games on larger board sizes. The difference between impartial games and partisan games can be explained by the vulnerability to adversarial attacks and perturbations.

    

    类似AlphaZero的强化学习算法在各种棋盘游戏中表现出色，但在公正游戏中却面临挑战，这些游戏中玩家共享棋子。我们提供了一个具体的游戏例子，即小孩们玩的尼姆游戏，以及其他一些公正游戏，这些游戏似乎成为AlphaZero和类似的强化学习算法的绊脚石。我们的发现与最近的研究一致，表明AlphaZero-style算法容易受到敌对攻击和敌对扰动的影响，显示了在所有合法状态下学习掌握这些游戏的困难。我们发现尼姆游戏在小型棋盘上可以学习，但当棋盘尺寸增大时，AlphaZero-style算法的学习速度显著减慢。直观上，尼姆等公正游戏与象棋和围棋等党派游戏之间的区别在于，如果系统中添加了微小的噪音（例如，棋盘的一小部分被覆盖），对于公正游戏来说，这是一种典型的情况。

    AlphaZero-style reinforcement learning (RL) algorithms excel in various board games but face challenges with impartial games, where players share pieces. We present a concrete example of a game - namely the children's game of nim - and other impartial games that seem to be a stumbling block for AlphaZero-style and similar reinforcement learning algorithms.  Our findings are consistent with recent studies showing that AlphaZero-style algorithms are vulnerable to adversarial attacks and adversarial perturbations, showing the difficulty of learning to master the games in all legal states.  We show that nim can be learned on small boards, but AlphaZero-style algorithms learning dramatically slows down when the board size increases. Intuitively, the difference between impartial games like nim and partisan games like Chess and Go can be explained by the fact that if a tiny amount of noise is added to the system (e.g. if a small part of the board is covered), for impartial games, it is typica
    
[^123]: 深度学习在数字硬件上的反问题存在的限制

    Limitations of Deep Learning for Inverse Problems on Digital Hardware. (arXiv:2202.13490v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2202.13490](http://arxiv.org/abs/2202.13490)

    本文研究了深度学习在数字硬件上解决反问题的限制，并证明了对于小的松弛参数，有限维反问题无法通过计算方法解决。这些结果还引入了算法可获得准确度的下限。

    

    过去几年，深度神经网络取得了巨大的成功。由于训练是在数字硬件上进行的，本文分析了在当前模拟为图灵机的硬件平台上实际可以计算的内容，这会导致深度学习的固有限制。为此，我们重点研究了反问题类，特别是涵盖了从测量中重构数据的任何任务。我们证明，对于小的松弛参数，有限维反问题无法通过巴拿赫-马兹尔计算方法解决。更重要的是，我们的结果引入了在算法上可以获得的准确度的下界。

    Deep neural networks have seen tremendous success over the last years. Since the training is performed on digital hardware, in this paper, we analyze what actually can be computed on current hardware platforms modeled as Turing machines, which would lead to inherent restrictions of deep learning. For this, we focus on the class of inverse problems, which, in particular, encompasses any task to reconstruct data from measurements. We prove that finite-dimensional inverse problems are not Banach-Mazur computable for small relaxation parameters. Even more, our results introduce a lower bound on the accuracy that can be obtained algorithmically.
    
[^124]: HEAM: 高效近似乘法器优化的深度神经网络

    HEAM: High-Efficiency Approximate Multiplier Optimization for Deep Neural Networks. (arXiv:2201.08022v4 [cs.AR] UPDATED)

    [http://arxiv.org/abs/2201.08022](http://arxiv.org/abs/2201.08022)

    本文提出了一种优化方法，用于自动设计近似乘法器，并根据操作数分布来最小化平均误差。所提乘法器在DNN中达到了比最佳复制的近似乘法器高达50.24%的准确性，同时具有较小的面积、功耗和延迟。

    

    我们提出了一种自动设计近似乘法器的优化方法，根据操作数分布最小化平均误差。我们的乘法器在DNN中比最佳复制的近似乘法器高达50.24%的准确性，同时面积减小15.76%，功耗减少25.05%，延迟缩短3.50%。与精确乘法器相比，我们的乘法器分别减少了44.94%的面积、47.63%的功耗和16.78%的延迟，几乎没有准确性损失。使用我们的乘法器进行测试的DNN加速器模块比原始模块面积减小了18.70%，功耗减少了9.99%。

    We propose an optimization method for the automatic design of approximate multipliers, which minimizes the average error according to the operand distributions. Our multiplier achieves up to 50.24% higher accuracy than the best reproduced approximate multiplier in DNNs, with 15.76% smaller area, 25.05% less power consumption, and 3.50% shorter delay. Compared with an exact multiplier, our multiplier reduces the area, power consumption, and delay by 44.94%, 47.63%, and 16.78%, respectively, with negligible accuracy losses. The tested DNN accelerator modules with our multiplier obtain up to 18.70% smaller area and 9.99% less power consumption than the original modules.
    
[^125]: 可解释的神经推理的前向组合传播算法

    Forward Composition Propagation for Explainable Neural Reasoning. (arXiv:2112.12717v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2112.12717](http://arxiv.org/abs/2112.12717)

    本文提出了一种被称为前向组合传播（FCP）的算法，用于解释前馈神经网络在结构化分类问题上的预测。该算法通过组合向量描述每个神经元中问题特征的作用，并且模拟结果表明组合值与受保护特征的预期行为紧密对齐。

    

    本文提出一种称为前向组合传播（FCP）的算法，用于解释在结构化分类问题上操作的前馈神经网络的预测。在提出的FCP算法中，每个神经元都由一个组合向量描述，该向量指示了每个问题特征在该神经元中的作用。组合向量使用给定的输入实例初始化，并随后通过整个网络传播，直到达到输出层。每个组合值的符号表示相应特征是否激活或抑制神经元，而绝对值 quantifies 了其影响。FCP算法是在后续基础上执行的，即在学习过程完成后。为了说明FCP算法，本文开展了一个关于公平问题中偏见检测的案例研究，其中地面真相是已知的。模拟结果表明，组合值与受保护特征的预期行为紧密对齐。

    This paper proposes an algorithm called Forward Composition Propagation (FCP) to explain the predictions of feed-forward neural networks operating on structured classification problems. In the proposed FCP algorithm, each neuron is described by a composition vector indicating the role of each problem feature in that neuron. Composition vectors are initialized using a given input instance and subsequently propagated through the whole network until reaching the output layer. The sign of each composition value indicates whether the corresponding feature excites or inhibits the neuron, while the absolute value quantifies its impact. The FCP algorithm is executed on a post-hoc basis, i.e., once the learning process is completed. Aiming to illustrate the FCP algorithm, this paper develops a case study concerning bias detection in a fairness problem in which the ground truth is known. The simulation results show that the composition values closely align with the expected behavior of protected
    
[^126]: 对低样本物体检测中深度学习的综述

    A Survey of Deep Learning for Low-Shot Object Detection. (arXiv:2112.02814v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2112.02814](http://arxiv.org/abs/2112.02814)

    本综述对低样本物体检测中的深度学习方法进行了综合回顾，提出了LSOD方法的分类，并对其进行了系统分析，为解决数据稀缺场景下的物体检测问题提供了参考。

    

    随着深度神经网络和大规模标注数据的出现，物体检测取得了巨大的突破。然而，由于严重的过拟合问题，当前的检测方法不能直接应用于标注数据稀缺的场景。虽然在图像分类领域中广泛探索了少样本学习和零样本学习，但在数据稀缺情况下设计新的物体检测方法是必不可少的，因为物体检测还具有挑战性的位置定位任务。低样本物体检测（LSOD）是一种新兴的研究课题，用于从少量甚至没有标注样本中检测物体，包括一次性物体检测（OSOD）、少样本物体检测（FSOD）和零样本物体检测（ZSD）。本综述对LSOD方法进行了全面的回顾。首先，我们提出了LSOD方法的详细分类，并对其进行了系统分析，包括LSOD的一些扩展主题（半监督LSOD、

    Object detection has achieved a huge breakthrough with deep neural networks and massive annotated data. However, current detection methods cannot be directly transferred to the scenario where the annotated data is scarce due to the severe overfitting problem. Although few-shot learning and zero-shot learning have been extensively explored in the field of image classification, it is indispensable to design new methods for object detection in the data-scarce scenario since object detection has an additional challenging localization task. Low-Shot Object Detection (LSOD) is an emerging research topic of detecting objects from a few or even no annotated samples, consisting of One-Shot Object Detection (OSOD), Few-Shot Object Detection (FSOD) and Zero-Shot Object Detection (ZSD). This survey provides a comprehensive review of LSOD methods. First, we propose a thorough taxonomy of LSOD methods and analyze them systematically, comprising some extensional topics of LSOD (semi-supervised LSOD, 
    
[^127]: 从文本中提取流程：评估现有技术并为未来挑战铺平道路

    Process Extraction from Text: Benchmarking the State of the Art and Paving the Way for Future Challenges. (arXiv:2110.03754v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2110.03754](http://arxiv.org/abs/2110.03754)

    该论文评估了从文本中提取流程模型的现有技术，并提供了未来挑战的指导。通过比较10种最先进的方法，包括定性和定量评估，研究者们找到了解决模型提取问题的有效方法。

    

    从文本中提取流程模型是将非结构化文本流程描述中的信息转化为形式化表示（即流程模型）的问题。目前已经提出了多种自动化方法来解决这个问题，但这些方法在范围和基本假设上存在很大的异质性，包括输入、目标输出和评估数据的差异。因此，目前尚不清楚现有解决方案能够如何有效地解决模型提取问题以及它们之间的比较。为了解决这个问题，我们系统地比较了10种最先进的模型提取方法，涵盖了定性和定量方面的评估。定性评估比较了主要研究的以下方面：1.每种方法的主要特征；2.从输入数据中提取的流程模型元素的类型；3.用于评估提出的框架的实验评估。

    The extraction of process models from text refers to the problem of turning the information contained in an unstructured textual process descriptions into a formal representation,i.e.,a process model. Several automated approaches have been proposed to tackle this problem, but they are highly heterogeneous in scope and underlying assumptions,i.e., differences in input, target output, and data used in their evaluation.As a result, it is currently unclear how well existing solutions are able to solve the model-extraction problem and how they compare to each other.We overcome this issue by comparing 10 state-of-the-art approaches for model extraction in a systematic manner, covering both qualitative and quantitative aspects.The qualitative evaluation compares the analysis of the primary studies on: 1 the main characteristics of each solution;2 the type of process model elements extracted from the input data;3 the experimental evaluation performed to evaluate the proposed framework.The resu
    
[^128]: 我该如何更新我的模型？关于预测过程监控模型对变化的韧性。

    How do I update my model? On the resilience of Predictive Process Monitoring models to change. (arXiv:2109.03501v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2109.03501](http://arxiv.org/abs/2109.03501)

    本研究针对预测过程监控模型的韧性问题，评估了三种不同策略，并发现增量学习算法具有潜力来解决预测模型的更新和可变性问题。

    

    现有的经过充分研究的预测过程监控技术通常基于过去的流程执行构建预测模型，然后使用该模型预测新进行中案例的未来，无法通过新案例的执行来更新它。这使得预测过程监控对于在不断演变和/或随时间展现新变体行为的实际环境中的过程的可变性太过僵化。为解决这个问题，我们评估了三种不同的策略，允许周期性地重新发现或增量构建预测模型，以利用新的可用数据。评估重点放在新学习的预测模型的性能上，包括准确性和时间，与原始模型进行比较，并使用了一些真实和合成的数据集，包括明确的概念漂移和没有明确的概念漂移。结果证明了增量学习算法的潜力。

    Existing well investigated Predictive Process Monitoring techniques typically construct a predictive model based on past process executions, and then use it to predict the future of new ongoing cases, without the possibility of updating it with new cases when they complete their execution. This can make Predictive Process Monitoring too rigid to deal with the variability of processes working in real environments that continuously evolve and/or exhibit new variant behaviours over time. As a solution to this problem, we evaluate the use of three different strategies that allow the periodic rediscovery or incremental construction of the predictive model so as to exploit new available data. The evaluation focuses on the performance of the new learned predictive models, in terms of accuracy and time, against the original one, and uses a number of real and synthetic datasets with and without explicit Concept Drift. The results provide an evidence of the potential of incremental learning algo
    
[^129]: 唯有利普希茨性能够驯服离线生成对抗模仿学习

    Lipschitzness Is All You Need To Tame Off-policy Generative Adversarial Imitation Learning. (arXiv:2006.16785v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2006.16785](http://arxiv.org/abs/2006.16785)

    离线生成对抗模仿学习中，将学习到的奖励函数强制变成局部利普希茨连续是取得良好表现的必要条件，并且满足奖励的利普希茨性约束对模仿性能具有积极影响。

    

    尽管强化学习在各个领域取得了最近的成功，但是这些方法大多对超参数敏感，并且通常需要进行一些关键的工程操作才能取得成功。我们考虑了离线生成对抗模仿学习的情况，并对该方法进行了深入的定性和定量分析。我们证明，将学习到的奖励函数强制变成局部利普希茨连续是该方法表现良好的必要条件。然后，我们研究了这个必要条件的影响，并提供了涉及状态-价值函数的局部利普希茨性质的几个理论结果。我们通过实证证据证明，奖励的利普希茨性约束的一致满足对模仿性能具有极强的积极影响。最后，我们探讨了一个通用的悲观奖励预处理附加项，形成了一个大类的奖励函数。

    Despite the recent success of reinforcement learning in various domains, these approaches remain, for the most part, deterringly sensitive to hyper-parameters and are often riddled with essential engineering feats allowing their success. We consider the case of off-policy generative adversarial imitation learning, and perform an in-depth review, qualitative and quantitative, of the method. We show that forcing the learned reward function to be local Lipschitz-continuous is a sine qua non condition for the method to perform well. We then study the effects of this necessary condition and provide several theoretical results involving the local Lipschitzness of the state-value function. We complement these guarantees with empirical evidence attesting to the strong positive effect that the consistent satisfaction of the Lipschitzness constraint on the reward has on imitation performance. Finally, we tackle a generic pessimistic reward preconditioning add-on spawning a large class of reward 
    
[^130]: 意识的神经计算模型：目标对齐的内部表示操作理论（GARIM）

    A Neurocomputational Account of Consciousness: The Goal-Aligning Representation Internal Manipulation Theory (GARIM). (arXiv:1912.13490v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/1912.13490](http://arxiv.org/abs/1912.13490)

    这个论文提出了一个神经计算框架下的意识理论，称为“目标对齐的内部表示操作”（GARIM）。该理论认为意识支持对目标相关的内部表示进行主动操作，使其与追求的目标更加对齐，从而增加目标导向行为的灵活性。

    

    意识作为人类认知的核心要素，已经通过神经科学、心理学、人工智能和机器人技术等多种科学方法进行研究。然而，这些领域之间的不良整合限制了对意识的完整和清晰理解。在这篇论文中，我们通过提出一个神经计算框架下的“目标对齐的内部表示操作”（GARIM）意识理论，为改善这种整合做出了贡献。GARIM理论的核心思想是，意识支持对目标相关的内部表示（如世界状态、对象和行为序列）进行主动操作，使它们与追求的目标更加对齐。这些操作使得意识代理能够在内部产生其所缺乏的知识，以应对新条件和目标，从而增加目标导向行为的灵活性。表示的操作由四个神经功能宏系统（Hierarc...

    Consciousness, a central element of human cognition, has been studied with multiple scientific approaches spanning neuroscience, psychology, artificial intelligence and robotics. Unfortunately, poor integration between these fields limits a full and clear understanding of consciousness. Here we contribute to improving this integration by proposing, within a neurocomputational framework, the `Goal-Aligning Representations Internal Manipulation' (GARIM) theory of consciousness. The central idea of the GARIM theory is that consciousness supports the active manipulation of goal-relevant internal representations (e.g., world states, objects, and action sequences), making them more aligned with the goals pursued. These manipulations allow the conscious agent to internally produce the knowledge it lacks to cope with novel conditions and goals, increasing the flexibility of goal-directed behaviour. The manipulation of representations is supported by four neuro-functional macro-systems (hierarc
    
[^131]: 增量预测性流程监控：如何处理真实环境的变化性

    Incremental Predictive Process Monitoring: How to Deal with the Variability of Real Environments. (arXiv:1804.03967v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/1804.03967](http://arxiv.org/abs/1804.03967)

    提出使用增量学习算法来解决现有预测性流程监控技术无法处理真实环境的可变性的问题，并通过更新模型适应当前情况，实验证明增量学习在预测性流程监控中具有潜力。

    

    现有的预测性流程监控技术的一个特点是首先基于过去的流程执行构建预测模型，然后使用该模型预测新的进行中案例的未来，但不能通过更新它来处理新完成执行的案例。这使得预测性流程监控过于刚性，无法应对不断演变和/或随时间展示新变体行为的真实环境中的流程的可变性。作为解决这个问题的方法，我们提出了使用允许增量构建预测模型的算法。这些增量学习算法在新案例可用时更新模型，使得预测模型随时间演变以适应当前情况。算法已经使用不同的案例编码策略进行实现，并在一些真实和合成数据集上进行了评估。结果首次证明了增量学习可以应用于预测性流程监控中的潜力。

    A characteristic of existing predictive process monitoring techniques is to first construct a predictive model based on past process executions, and then use it to predict the future of new ongoing cases, without the possibility of updating it with new cases when they complete their execution. This can make predictive process monitoring too rigid to deal with the variability of processes working in real environments that continuously evolve and/or exhibit new variant behaviors over time. As a solution to this problem, we propose the use of algorithms that allow the incremental construction of the predictive model. These incremental learning algorithms update the model whenever new cases become available so that the predictive model evolves over time to fit the current circumstances. The algorithms have been implemented using different case encoding strategies and evaluated on a number of real and synthetic datasets. The results provide a first evidence of the potential of incremental l
    

