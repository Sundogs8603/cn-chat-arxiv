# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Towards Flexible Time-to-event Modeling: Optimizing Neural Networks via Rank Regression.](http://arxiv.org/abs/2307.08044) | 本研究提出了一种深度AFT排名回归模型，用于灵活地进行时间事件建模，从而改善预测性能并减轻严格的假设。 |
| [^2] | [A Neural-Symbolic Approach Towards Identifying Grammatically Correct Sentences.](http://arxiv.org/abs/2307.08036) | 这项研究介绍了一种神经符号方法来解决验证语法正确句子的问题。 |
| [^3] | [Bayesian inference for data-efficient, explainable, and safe robotic motion planning: A review.](http://arxiv.org/abs/2307.08024) | 这篇论文综述了贝叶斯推理在机器人运动规划中的应用优势，包括策略不确定性量化、机器人运动的安全性和最优性保证、数据效率以及模拟到现实的差距。该综述提供了贝叶斯推理的概率理论和估计方法，并介绍了经典的基于模型和无模型的贝叶斯强化学习算法。 |
| [^4] | [Breaking Down the Task: A Unit-Grained Hybrid Training Framework for Vision and Language Decision Making.](http://arxiv.org/abs/2307.08016) | 该论文提出了一个单元级混合训练框架来解决视觉和语言决策任务。通过将任务分解为精细的单元，并利用单位内环境的不变性，使得训练更加有效，减少了曝光偏差，并在 TEACH基准测试上超越了现有的最先进技术。 |
| [^5] | [SHAMSUL: Simultaneous Heatmap-Analysis to investigate Medical Significance Utilizing Local interpretability methods.](http://arxiv.org/abs/2307.08003) | 本研究利用四种解释性方法探索深度神经网络在医学领域的可解释性，通过热图分析解释神经网络的预测结果，并针对特定病理类别进行定量和定性研究。 |
| [^6] | [MargCTGAN: A "Marginally'' Better CTGAN for the Low Sample Regime.](http://arxiv.org/abs/2307.07997) | MargCTGAN提出一个新的合成数据生成方法，在低样本情况下通过添加特征匹配的去相关边际，改善了CTGAN模型在实用性和统计属性方面的表现。 |
| [^7] | [Automated Polynomial Filter Learning for Graph Neural Networks.](http://arxiv.org/abs/2307.07956) | 本文提出了一种自动学习多项式滤波器的框架，名为Auto-Polynomial，在同质性和异质性图上取得了显著的性能提升。 |
| [^8] | [MinT: Boosting Generalization in Mathematical Reasoning via Multi-View Fine-Tuning.](http://arxiv.org/abs/2307.07951) | MinT通过多视角微调方法，利用不同标注风格的数学问题数据集提升了数学推理中小型语言模型的泛化能力。 |
| [^9] | [Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and Class-balanced Pseudo-Labeling.](http://arxiv.org/abs/2307.07944) | 本文通过提出一种适用于多类训练设置的新型ReDB框架来解决现有领域自适应方法在多类训练设置下性能下降的问题，通过产生可靠的、多样化的和类平衡的伪三维框来引导目标领域的自训练。 |
| [^10] | [KECOR: Kernel Coding Rate Maximization for Active 3D Object Detection.](http://arxiv.org/abs/2307.07942) | 本论文提出了一种内核编码率最大化（KECOR）策略，可以通过信息论的视角确定最具信息量的点云，以最小化标注所需的比特数。这种策略可以减轻LiDAR物体检测中的注释负担并提高计算效率。 |
| [^11] | [GeoGPT: Understanding and Processing Geospatial Tasks through An Autonomous GPT.](http://arxiv.org/abs/2307.07930) | GeoGPT是一个基于自主GPT的系统，旨在通过将大规模语言模型的语义理解能力与地理空间任务相结合，降低非专业用户解决地理空间任务的门槛。 |
| [^12] | [Neural Architecture Retrieval.](http://arxiv.org/abs/2307.07919) | 该论文提出了一个新的问题——神经架构检索，主要解决了研究人员在发现相似神经架构时所遇到的困难，并引入了多层对比学习来实现准确的图表示学习。 |
| [^13] | [Is Imitation All You Need? Generalized Decision-Making with Dual-Phase Training.](http://arxiv.org/abs/2307.07909) | DualMind使用双阶段训练策略，在控制任务中学习共同知识，并通过模仿行为在不同上下文中做出决策。在实验中，DualMind在MetaWorld和Habitat上表现优于其他通用性代理，具有超过50%和70%的提升。 |
| [^14] | [Anomaly Detection in Automated Fibre Placement: Learning with Data Limitations.](http://arxiv.org/abs/2307.07893) | 本文提出了一种在数据有限的情况下，通过自动编码器进行异常检测的方法，利用纤维层片的深度图进行二分类，并使用重构误差作为量化指标。 |
| [^15] | [Handwritten and Printed Text Segmentation: A Signature Case Study.](http://arxiv.org/abs/2307.07887) | 本研究旨在解决手写和打印文本分割的挑战，并提出了一种新的方法来完整地恢复不同类别的文本，特别是在重叠部分提高分割性能。同时，还引入了一个新的数据集SignaTR6K，用于支持该任务。 |
| [^16] | [Online Goal Recognition in Discrete and Continuous Domains Using a Vectorial Representation.](http://arxiv.org/abs/2307.07876) | 该论文提出了一种在离散和连续域中使用矢量表达进行在线目标识别的高效方法，该方法通过减少计算负担和提高识别速度，使其成为首个可用于快速变动环境下的机器人应用的在线方法。 |
| [^17] | [Does Double Descent Occur in Self-Supervised Learning?.](http://arxiv.org/abs/2307.07872) | 研究发现，在自监督学习中缺乏双下降现象，进一步的研究有助于揭示其理论基础。 |
| [^18] | [The SocialAI School: Insights from Developmental Psychology Towards Artificial Socio-Cultural Agents.](http://arxiv.org/abs/2307.07871) | 该论文讨论了AI研究应该受发展心理学启发，并研究使代理能够进入文化的社会认知能力。提出了社会AI学校工具以便于进行相关实验。 |
| [^19] | [Large Language Models as Superpositions of Cultural Perspectives.](http://arxiv.org/abs/2307.07870) | 大型语言模型被认为是具有个性或一套价值观的，但实际上它可以看作是具有不同价值观和个性特征的角度的叠加。通过角度可控性的概念，我们研究了大型语言模型在不同角度下展示的价值观和个性特征的变化。实验结果表明，即使在没有明显提示的情况下，大型语言模型也会表达出不同的价值观。 |
| [^20] | [Benchmarking the Effectiveness of Classification Algorithms and SVM Kernels for Dry Beans.](http://arxiv.org/abs/2307.07863) | 本研究通过分析和比较不同的分类算法和SVM核函数在豆类数据集上的性能，发现RBF SVM核心算法在准确率、精确率、召回率和F1得分上表现最佳，提供了重要的指导。 |
| [^21] | [A Multi-Heuristic Search-based Motion Planning for Automated Parking.](http://arxiv.org/abs/2307.07857) | 本论文提出了一种基于多启发式搜索的自动停车运动规划方法，通过使用多个启发式函数来捕捉搜索空间的不同复杂性，以提高计算性能和实现实时规划。 |
| [^22] | [AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity using Contrastive Learning and Structured Knowledge.](http://arxiv.org/abs/2307.07851) | AspectCSE是一种使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入方法，它在信息检索任务中相比之前的最好结果平均提高了3.97%，通过同时考虑多个特定方面的嵌入模型优于单方面嵌入。 |
| [^23] | [AIOptimizer -- A reinforcement learning-based software performance optimisation prototype for cost minimisation.](http://arxiv.org/abs/2307.07846) | AIOptimizer是一种基于强化学习的软件性能优化工具原型，旨在实现成本最小化。它使用强化学习驱动的推荐系统来改善软件系统的效率和可负担性，并突出了准确性、适应性、可扩展性和用户友好性等设计因素。AIOptimizer还提供故障识别、成本优化建议、效率预测和协作等功能，并使用基于强化学习的推荐引擎进行成本优化。 |
| [^24] | [RegExplainer: Generating Explanations for Graph Neural Networks in Regression Task.](http://arxiv.org/abs/2307.07840) | 这项工作提出了一种新的解释方法（XAIG-R），用于解释图回归模型，通过引入信息瓶颈理论的新目标和混合框架来解决回归任务中的挑战，同时还使用对比学习策略来处理连续有序标签。 |
| [^25] | [MixupExplainer: Generalizing Explanations for Graph Neural Networks with Data Augmentation.](http://arxiv.org/abs/2307.07832) | 本文提出了一种通用的图神经网络解释方法MixupExplainer，通过引入广义图信息瓶颈（GIB）和图mixup方法来解决现有解释方法中存在的分布偏移问题。 |
| [^26] | [Improving Trace Link Recommendation by Using Non-Isotropic Distances and Combinations.](http://arxiv.org/abs/2307.07781) | 本文旨在改进追踪链接推荐，通过使用非等向距离和组合方法。通过研究非线性相似度度量，从几何视角探索语义相似性对于追踪性研究是有帮助的。作者在多个项目数据集上进行了评估，并指出这些发现可以对其他信息检索问题起到基础性作用。 |
| [^27] | [Explainable AI with counterfactual paths.](http://arxiv.org/abs/2307.07764) | 本文提出了一种新颖的可解释人工智能方法，使用反事实路径来生成解释。通过确定替代路径，可以提供更直观和可解释的解释模型行为的方式，并帮助识别和减轻模型中的偏见。 |
| [^28] | [Bidirectionally Deformable Motion Modulation For Video-based Human Pose Transfer.](http://arxiv.org/abs/2307.07754) | 该论文提出了一种双向可变形运动调制方法，用于基于视频的人体姿态转移。通过几何核偏移和自适应权重调制，同时实现特征对齐和风格转移。与传统方法相比，该方法能够更好地处理服装上的结构图案和不连续的姿势转移，并提供更加满意的结果。 |
| [^29] | [Learning Expressive Priors for Generalization and Uncertainty Estimation in Neural Networks.](http://arxiv.org/abs/2307.07753) | 本文提出了一种用于神经网络的先验学习方法，通过利用可扩展和结构化的神经网络后验作为推广的信息先验，提高了神经网络的推广和不确定性估计能力。我们的方法在大规模上提供了表达性的概率表示，并产生了非空推广界限。我们的技术贡献是推导出可处理的目标函数，并提出了改进的推广界限计算方法。在经验上，我们证明了该方法在不确定性估计和推广方面的有效性。 |
| [^30] | [Combining model-predictive control and predictive reinforcement learning for stable quadrupedal robot locomotion.](http://arxiv.org/abs/2307.07752) | 本研究结合了模型预测控制和预测强化学习方法，旨在解决四足机器人稳定步态生成的问题。 |
| [^31] | [SINC: Self-Supervised In-Context Learning for Vision-Language Tasks.](http://arxiv.org/abs/2307.07742) | 提出了一种名为SINC的自主上下文学习框架，可以在不依赖于大型语言模型的情况下实现上下文学习，并避免了模板敏感性和幻觉等问题。 |
| [^32] | [Abstracting Concept-Changing Rules for Solving Raven's Progressive Matrix Problems.](http://arxiv.org/abs/2307.07734) | 本论文提出了一个用于提取概念变化规则的深度模型CRAB，通过学习可解释的概念和解析潜空间中的规则，实现了在Raven的渐进矩阵问题中无需辅助监督的全局规则发现和答案生成，实验证明了该模型优于无监督训练的基线模型。 |
| [^33] | [NeurASP: Embracing Neural Networks into Answer Set Programming.](http://arxiv.org/abs/2307.07700) | NeurASP是将神经网络集成到Answer Set Programming中的简单且有效的方法，通过以概率分布的形式处理神经网络输出，NeurASP能够将子符号和符号计算相结合，并通过应用符号推理改进神经网络的感知结果，并且可以通过使用ASP规则训练神经网络，使其从显式复杂语义约束中学习。 |
| [^34] | [Leveraging Large Language Models to Generate Answer Set Programs.](http://arxiv.org/abs/2307.07699) | 本文提出了一种神经符号方法，将大型语言模型和答案集编程的优势相结合，通过使用大型语言模型将自然语言描述转化为答案集程序，以实现处理复杂推理问题的能力。 |
| [^35] | [Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text.](http://arxiv.org/abs/2307.07696) | 这项研究将大型语言模型与逻辑编程相结合，通过将自然语言句子转换为逻辑形式，使模型能够进行强大且通用的推理。该方法只需要少量的示例和可重用的知识模块，即可在多个问答任务中取得最先进的性能。 |
| [^36] | [A Survey on Change Detection Techniques in Document Images.](http://arxiv.org/abs/2307.07691) | 本文调查了文档图像中的变化检测技术，其中主要关注基于内容和基于布局的方法。介绍了现有数据集和评估指标，并报告了现有方法的不足和挑战。 |
| [^37] | [Creating a Dataset Supporting Translation Between OpenMP Fortran and C++ Code.](http://arxiv.org/abs/2307.07686) | 本研究创建了一个数据集，用于训练机器学习模型在OpenMP Fortran和C++代码之间进行翻译。这个数据集通过精细的代码相似性测试确保了可靠性和适用性，并且能够显著提升大规模语言模型的翻译能力。 |
| [^38] | [Efficient Adversarial Attacks on Online Multi-agent Reinforcement Learning.](http://arxiv.org/abs/2307.07670) | 本研究探讨了对在线多智能体强化学习（MARL）的对抗攻击的影响，首先展示了单独进行动作污染和奖励污染攻击的局限性，然后引入了一种混合攻击策略，该策略可以高效地攻击MARL智能体，即使攻击者没有先验信息。 |
| [^39] | [Efficient Action Robust Reinforcement Learning with Probabilistic Policy Execution Uncertainty.](http://arxiv.org/abs/2307.07666) | 本文研究了具有概率策略执行不确定性的行动鲁棒增强学习问题，并提出了ARRLC算法，该算法在遗憾和样本复杂度上达到了极小极大最优，实验证明其优于非鲁棒算法并且收敛更快。 |
| [^40] | [MPDIoU: A Loss for Efficient and Accurate Bounding Box Regression.](http://arxiv.org/abs/2307.07662) | 提出了一种用于高效准确的边界框回归的损失函数MPDIoU，并通过包含多个相关因素的最小点距离来比较边界框的相似性。实验结果表明，该损失函数可以提高目标检测的准确性。 |
| [^41] | [SALC: Skeleton-Assisted Learning-Based Clustering for Time-Varying Indoor Localization.](http://arxiv.org/abs/2307.07650) | SALC是一种基于骨架辅助的学习聚类定位系统，可以适应时变室内环境，提高定位准确性。 |
| [^42] | [Othering and low prestige framing of immigrant cuisines in US restaurant reviews and large language models.](http://arxiv.org/abs/2307.07645) | 通过对2.1M英语Yelp评论的餐厅进行语言分析，研究发现移民美食更容易被构架为客观和他者化，而非西方移民美食受欢迎程度更高。 |
| [^43] | [Dissenting Explanations: Leveraging Disagreement to Reduce Model Overreliance.](http://arxiv.org/abs/2307.07636) | 这项研究介绍了不同解释的概念，旨在通过提供伴随冲突预测的解释来减少模型过度依赖。在模型多样性设置下，这种方法可以帮助人们从不同模型的解释中获得洞察力。 |
| [^44] | [Value-based Fast and Slow AI Nudging.](http://arxiv.org/abs/2307.07628) | 本文提出了一种基于价值的AI-human协作框架，通过提供决策建议引导人类的思考和行动。通过不同的引导方式，刺激人类的快速思考、慢思考或元认知。具体选择使用哪种引导方式取决于特定决策场景中的价值观。 |
| [^45] | [A Dialogue System for Assessing Activities of Daily Living: Improving Consistency with Grounded Knowledge.](http://arxiv.org/abs/2307.07544) | 这个论文介绍了一个用于评估日常生活活动的对话系统，通过模拟评估员和参与者之间的交互，提高了评估的一致性。 |
| [^46] | [Source-Free Domain Adaptation with Temporal Imputation for Time Series Data.](http://arxiv.org/abs/2307.07542) | 本文提出了一种用于时序数据的无源领域适应方法MAPU，通过随机掩蔽和时间插补的方式，捕捉源领域的时间信息并引导目标模型产生目标结果。 |
| [^47] | [Learning Multiple Coordinated Agents under Directed Acyclic Graph Constraints.](http://arxiv.org/abs/2307.07529) | 本文提出了一种在有向无环图约束下学习多个协调代理的新方法，通过利用DAG结构，提高了学习性能，并在实际环境中的多个任务上取得了优于其他非DAG方法的结果。 |
| [^48] | [PatchSorter: A High Throughput Deep Learning Digital Pathology Tool for Object Labeling.](http://arxiv.org/abs/2307.07528) | PatchSorter是一个开源的标注工具，利用深度学习和直观的网络界面，能够实现对大型数据集的高吞吐量标注，相较于无辅助标注，每秒标签数提高超过7倍，对标注准确性的影响非常小。 |
| [^49] | [Machine Learning for Autonomous Vehicle's Trajectory Prediction: A comprehensive survey, Challenges, and Future Research Directions.](http://arxiv.org/abs/2307.07527) | 这项综合研究调查了自主车辆的轨迹预测方法，通过借鉴现有文献并重点关注机器学习技术，特别是深度学习和强化学习。研究总结了目前的挑战，并提出了未来研究的方向。 |
| [^50] | [Can I say, now machines can think?.](http://arxiv.org/abs/2307.07526) | 生成型人工智能技术使得机器具备了人类化的响应能力，这促使我们重新审视了图灵的思考机器概念，并对机器的认知能力进行了评估。我们发现，尽管图灵测试是评估机器能力的关键，但智能还有其他方面，而人工智能机器展示了其中大部分方面。 |
| [^51] | [Reducing Causality to Functions with Structural Models.](http://arxiv.org/abs/2307.07524) | 本文提出了一种基于结构功能模型的约简定义，将因果关系定义为将因果联系起来的函数。作者使用增量压缩和对比前向推理的方法，实现了产生符合直觉的因果表达，并将该模型应用于多个因果场景。这种模型与概率理论兼容但不可约，并且经过与其他因果理论的比较，还应用于自由意志、因果解释和心理因果等问题。 |
| [^52] | [PapagAI:Automated Feedback for Reflective Essays.](http://arxiv.org/abs/2307.07523) | PapagAI是第一个基于教学理论并实现为混合AI系统的开源自动反馈工具，旨在提高学生学习成果并补充讲师的教学活动。 |
| [^53] | [The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence.](http://arxiv.org/abs/2307.07522) | 生成型人工智能和大型语言模型可能为基础科学的发现提供机会，通过其自主生成假设和探索假设空间的闭环方法，加速科学发现的进程。 |
| [^54] | [CephGPT-4: An Interactive Multimodal Cephalometric Measurement and Diagnostic System with Visual Large Language Model.](http://arxiv.org/abs/2307.07518) | CephGPT-4是一个具有视觉大语言模型的交互式多模态颅颌测量与诊断系统，它能够通过自动分析颅颌标志点和生成诊断报告，实现出色的性能，为正畸测量和诊断应用带来革命性的潜力。 |
| [^55] | [Causing is Achieving -- A solution to the problem of causation.](http://arxiv.org/abs/2307.07517) | 从应用本体论的角度解决因果问题，通过系统功能概念理解因果关系，将任何原因分解为实现、防止、允许和不允许四个子功能，最后三个子功能可以仅用实现来定义。因果的本质在于实现功能。 |
| [^56] | [Artificial intelligence is algorithmic mimicry: why artificial "agents" are not (and won't be) proper agents.](http://arxiv.org/abs/2307.07515) | 本研究通过对比生物系统和算法系统，指出了生物系统具有自我制造自主能力、符号和物理方面没有区分以及体验到模糊问题的大世界等特点，而算法系统则与此相反。 |
| [^57] | [Explainability is NOT a Game.](http://arxiv.org/abs/2307.07514) | Shapley values may provide misleading measures of relative feature importance in XAI, challenging their proposed uses in high-stakes application domains. |
| [^58] | [An empirical study of using radiology reports and images to improve ICU mortality prediction.](http://arxiv.org/abs/2307.07513) | 本研究利用放射学报告和图像构建了一个基于深度学习的多模态数据生存预测模型，用于预测重症监护病房（ICU）的死亡率，并在MIMIC-IV数据集上取得了0.7829的平均C-index。 |
| [^59] | [RoPDA: Robust Prompt-based Data Augmentation for Low-Resource Named Entity Recognition.](http://arxiv.org/abs/2307.07417) | RoPDA是一种用于低资源NER的数据增强方法，通过基于预训练语言模型和连续提示进行实体和上下文增强，并提出了自一致性过滤和混合技术以优化增强样本的利用。 |
| [^60] | [DataAssist: A Machine Learning Approach to Data Cleaning and Preparation.](http://arxiv.org/abs/2307.07119) | DataAssist是一种机器学习方法，用于提高数据集质量和节省数据清洗和准备时间。 |
| [^61] | [Video-FocalNets: Spatio-Temporal Focal Modulation for Video Action Recognition.](http://arxiv.org/abs/2307.06947) | 本论文提出了一种名为视频焦点网络的视频识别架构，通过时空焦点调制来模拟局部和全局上下文，结合了Transformer和卷积设计的优点，既有效又高效。 |
| [^62] | [Rad-ReStruct: A Novel VQA Benchmark and Method for Structured Radiology Reporting.](http://arxiv.org/abs/2307.05766) | 本文提出了Rad-ReStruct，一个用于评估和比较不同方法的新型基准数据集，以X光图像的结构化报告形式提供了细粒度、按层次排序的注释。我们提出了一种新方法hi-VQA，将结构化报告任务建模为分层视觉问答(VQA)，并考虑先前提问和回答的上下文来填充结构化放射学报告。实验证明hi-VQA取得了与最先进方法相竞争的性能。 |
| [^63] | [Human in the AI loop via xAI and Active Learning for Visual Inspection.](http://arxiv.org/abs/2307.05508) | 通过xAI和主动学习的人在AI循环中进行视觉检查的论文探讨了工业 5.0 中人机协作的新机会，并分享了关于视觉检查中的人工智能、人类数字孪生和网络安全的最新研究成果。 |
| [^64] | [Unmasking the giant: A comprehensive evaluation of ChatGPT's proficiency in coding algorithms and data structures.](http://arxiv.org/abs/2307.05360) | 本文全面评估了ChatGPT在编码算法和数据结构方面的能力，基于最大的编码挑战目录，重点关注Python编程语言和数据结构算法两个基础主题。总结测试中ChatGPT的代码解决问题的准确性、代码质量和运行时错误的性质。 |
| [^65] | [Combating Data Imbalances in Federated Semi-supervised Learning with Dual Regulators.](http://arxiv.org/abs/2307.05358) | 本文提出了一种带有双调节器的新型联邦半监督学习框架FedDure，解决了数据分布不平衡的问题。通过粗调节器和细调节器对本地模型的更新进行规范，以及学习适应性加权方案，适应不同的数据分布。 |
| [^66] | [ECS -- an Interactive Tool for Data Quality Assurance.](http://arxiv.org/abs/2307.04368) | 本文提出了一种交互工具ECS，用于保证数据质量。该工具能够检测出在安全关键系统中具有潜在危害属性的数据点。 |
| [^67] | [ChatGPT in the Age of Generative AI and Large Language Models: A Concise Survey.](http://arxiv.org/abs/2307.04251) | ChatGPT是由OpenAI创建的一种大型语言模型（LLM），它在自然语言处理（NLP）领域引起了革命性的变革。它是第一个实现公众大规模与生成式人工智能（GAI）互动的关键技术，也引发了类似技术的研究兴趣和应用探索。 |
| [^68] | [Applying human-centered AI in developing effective human-AI teaming: A perspective of human-AI joint cognitive systems.](http://arxiv.org/abs/2307.03913) | 本研究介绍了将人工智能与人类团队协作作为一种新的发展范式的方法，强调有效的人工智能与人类团队需要充分利用双方的独特能力，同时克服挑战和限制，提高联合表现。同时，该研究指出现有研究往往未考虑到动态、适应性和协作团队环境中人工智能的功能，呼吁加强关于人工智能与人类团队协作的研究。 |
| [^69] | [An explainable model to support the decision about the therapy protocol for AML.](http://arxiv.org/abs/2307.02631) | 本文提出了一种可解释的机器学习模型，用于支持AML患者治疗方案的决策，解决了当前风险分类存在的问题和专家需求额外测试和分析的困扰。 |
| [^70] | [Emoji Prediction using Transformer Models.](http://arxiv.org/abs/2307.02054) | 使用基于Transformer的方法，在大型语料库上微调BERT模型以预测给定文本的表情符号。实验结果显示，该方法在预测准确率上优于其他最先进的模型，具有潜在的自然语言处理和社交媒体营销应用价值。 |
| [^71] | [InstructEval: Systematic Evaluation of Instruction Selection Methods.](http://arxiv.org/abs/2307.00259) | InstructEval开发了一个评估套件，用于对指令选择方法进行全面评估。通过使用策划的手动编写的指令，可以显著提高性能。 |
| [^72] | [Learning from Synthetic Human Group Activities.](http://arxiv.org/abs/2306.16772) | 提出了M3Act，一个多视图多团队多人的人类原子动作和团队活动数据生成器，通过Unity引擎驱动实现。该生成器具有大规模数据生成、多模态和高质量注释等特点，能够用于研究复杂的人类互动和团队活动。 |
| [^73] | [Are Good Explainers Secretly Human-in-the-Loop Active Learners?.](http://arxiv.org/abs/2306.13935) | 本文提出了一种可解释的AI技术，用于获取额外的训练数据，同时考虑到人类的介入，这可以通过模拟来评估其效用，同时具有与标准主动学习算法的可比性。 |
| [^74] | [DoubleAdapt: A Meta-learning Approach to Incremental Learning for Stock Trend Forecasting.](http://arxiv.org/abs/2306.09862) | DoubleAdapt是一个增量学习的方法，用于股票趋势预测。它利用元学习技术自动学习如何将股票数据适应到本地平稳分布空间中，从而有效地适应数据和模型，减轻分布漂移的影响。 |
| [^75] | [Pruning the Way to Reliable Policies: A Multi-Objective Deep Q-Learning Approach to Critical Care.](http://arxiv.org/abs/2306.08044) | 该论文介绍了一种深度Q学习方法，通过剪枝动作集来实现将中间生物标志物信号整合到奖励规范中，提高了重症护理策略的可靠性。 |
| [^76] | [Modeling Human-like Concept Learning with Bayesian Inference over Natural Language.](http://arxiv.org/abs/2306.02797) | 该论文通过在自然语言中进行贝叶斯推理来模拟人类类人概念学习，使用大型语言模型作为提议分布并拟合先验以更好地模拟人类学习者，并在生成性和逻辑性概念上进行实验评估。 |
| [^77] | [Navigating Explanatory Multiverse Through Counterfactual Path Geometry.](http://arxiv.org/abs/2306.02786) | 该论文提出了解释性多元宇宙的概念，用于导航和比较所有可能的反事实路径的几何关系。 |
| [^78] | [A Study of Situational Reasoning for Traffic Understanding.](http://arxiv.org/abs/2306.02520) | 本研究提出了三个新的基于文本的交通领域情境推理任务，旨在评估语言模型在情境决策、事件因果关系推理和解决人类驾驶考试方面的能力。研究采用了四种知识增强方法，具有潜力在不同语言推理任务中实现模型的泛化能力。 |
| [^79] | [Fast Matrix Multiplication Without Tears: A Constraint Programming Approach.](http://arxiv.org/abs/2306.01097) | 本文提出了一种基于约束编程的方法，以寻找快速矩阵乘法的非交换算法或提供不可行性证明。我们通过打破对称性的约束条件和有效的不等式约束来修剪搜索空间，可以在合理的时间内找到已知的最佳算法或改进的算法。 |
| [^80] | [Towards Fair Disentangled Online Learning for Changing Environments.](http://arxiv.org/abs/2306.01007) | 本论文提出了一种面向变化环境的在线学习算法，该算法通过将模型参数划分为环境不变部分和环境特定部分，从而实现了数据公平性。通过大量的实验，证明了该算法的有效性。 |
| [^81] | [Training Socially Aligned Language Models in Simulated Human Society.](http://arxiv.org/abs/2305.16960) | 本研究提出了一种在模拟人类社会中训练语言模型的新方法，相比于现有方法，该方法具有更大的可扩展性和高效性，并在对齐基准和人类评估中展示出更优异的性能。 |
| [^82] | [Sustainable Edge Intelligence Through Energy-Aware Early Exiting.](http://arxiv.org/abs/2305.14094) | 本文提出了能量自适应动态早期退出机制，通过能量感知的策略，在EH边缘设备中实现了高效准确推理。 |
| [^83] | [GPT for Semi-Automated Data Science: Introducing CAAFE for Context-Aware Automated Feature Engineering.](http://arxiv.org/abs/2305.03403) | 介绍了一种名为CAAFE的上下文感知自动特征工程方法，它利用大型语言模型根据数据集描述生成更多具有语义意义的特征，能够提高大多数数据集的性能，平均ROC AUC表现提高至0.822。 |
| [^84] | [Spatial-Language Attention Policies for Efficient Robot Learning.](http://arxiv.org/abs/2304.11235) | 本文提出了一种空间-语言注意力策略(SLAP)，使用三维标记作为输入表示，以训练单一多任务和语言条件化的动作预测策略，能够在引入未见过的干扰物和物体配置时达到47.5%的成功率。 |
| [^85] | [CAFIN: Centrality Aware Fairness inducing IN-processing for Unsupervised Representation Learning on Graphs.](http://arxiv.org/abs/2304.04391) | CAFIN是一种基于节点中心性的公平性增强进程技术，用于无监督学习的图表示学习方法中。实验结果表明，CAFIN在提供最优公平结果的同时，具有竞争力或更好的下游任务性能。 |
| [^86] | [How to choose your best allies for a transferable attack?.](http://arxiv.org/abs/2304.02312) | 本文提出了一种新方法来评估可转移性，通过将畸变放置于中心位置并提出了一种新的选择机制FiT，该机制旨在通过只进行几个初步查询即可选择最佳的源模型。 |
| [^87] | [Bridging Imitation and Online Reinforcement Learning: An Optimistic Tale.](http://arxiv.org/abs/2303.11369) | 本文提出了两种算法，iPSRL和iRLSVI，旨在解决给定离线演示数据集的问题，可以显著减少强化学习中的遗憾，桥接了在线 RL 和模仿学习。 |
| [^88] | [Gradient-Free Structured Pruning with Unlabeled Data.](http://arxiv.org/abs/2303.04185) | 本文提出了一种使用无标签数据的无梯度结构化剪枝方法，在GLUE和SQuAD基准测试上的实验证明了其有效性，仅需几分钟就能将原始FLOP计数的最高40%减少而准确度仅下降不超过4%。 |
| [^89] | [CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive Learning.](http://arxiv.org/abs/2303.03323) | CleanCLIP是一个通过独立重新对齐个别模态的表示来削弱后门攻击引入的虚假关联的微调框架。 |
| [^90] | [A Neural Span-Based Continual Named Entity Recognition Model.](http://arxiv.org/abs/2302.12200) | 本文提出了一种基于神经网络的跨时期命名实体识别模型SpanKL，通过知识蒸馏和多标签预测来实现记忆保留和冲突防止，该模型在跨时期NER任务中表现出色，显示出高实际价值。 |
| [^91] | [Regularised neural networks mimic human insight.](http://arxiv.org/abs/2302.11351) | 本文研究了正则化神经网络是否具有类似于人类洞察力的行为。研究发现，正则化神经网络在学习动态和行为特征上密切模仿了人类的洞察力，表现出洞察力的延迟、突然性和选择性发生。 |
| [^92] | [Fair Diffusion: Instructing Text-to-Image Generation Models on Fairness.](http://arxiv.org/abs/2302.10893) | 这篇论文提出了一种名为“公平扩散”的新策略，可以在生成文本到图像模型部署后减轻偏见并使模型接受公平性指导。 |
| [^93] | [PAC-Bayesian Generalization Bounds for Adversarial Generative Models.](http://arxiv.org/abs/2302.08942) | 将PAC-Bayesian理论扩展到生成模型，为基于Wasserstein距离和总变差距离的模型提供了泛化界，为Wasserstein GAN和Energy-Based GAN提供了新的训练目标，并在合成数据集上展示出非虚空泛化界。 |
| [^94] | [HumanMAC: Masked Motion Completion for Human Motion Prediction.](http://arxiv.org/abs/2302.03665) | HumanMAC是一个掩码动作修复框架，通过训练阶段的运动扩散模型和推断阶段的去噪过程，在观察到的运动数据的控制下进行运动预测，并在多个基准数据集上展示了显著的改进。 |
| [^95] | [Diagnose Like a Pathologist: Transformer-Enabled Hierarchical Attention-Guided Multiple Instance Learning for Whole Slide Image Classification.](http://arxiv.org/abs/2301.08125) | 这项研究提出了一种基于Transformer的层次注意力引导多实例学习框架，用于组织病理学全切片图像分类。该框架可以动态和关注地发现并利用WSI的多个分辨率的区分性区域，提高了分类性能。 |
| [^96] | [StitchNet: Composing Neural Networks from Pre-Trained Fragments.](http://arxiv.org/abs/2301.01947) | StitchNet提出了一种新的神经网络创建方式，它通过组合预训练神经网络的片段来创建高性能的网络，无需传统训练的大量计算资源和数据要求。通过居中核对齐（CKA），可以有效指导片段的选择，以满足特定准确性需求和计算资源限制。此外，StitchNet还可以实现即时个性化模型创建和推断。 |
| [^97] | [Closed-form control with spike coding networks.](http://arxiv.org/abs/2212.12887) | 本文扩展了脉冲编码网络理论，通过引入闭式最优估计和控制，实现了对循环脉冲神经网络中动态系统的控制。 |
| [^98] | [Curiosity creates Diversity in Policy Search.](http://arxiv.org/abs/2212.03530) | 本研究使用好奇心作为内在动机，并将其应用于进化策略搜索方法中。与常用的多样性度量指标相比，好奇心能够在没有明确的多样性标准的情况下生成更高的多样性，并找到多种能够获得奖励的策略。 |
| [^99] | [\{kappa}HGCN: Tree-likeness Modeling via Continuous and Discrete Curvature Learning.](http://arxiv.org/abs/2212.01793) | 本文提出了一种新的\{kappa}HGCN模型，在双曲空间内实现树状结构建模，通过结合连续和离散曲率来学习输入图的基础几何结构，并在多个基准测试和数据集上取得了最先进的性能。 |
| [^100] | [CLIP: Train Faster with Less Data.](http://arxiv.org/abs/2212.01452) | 本文提出了CLIP，通过结合课程学习和数据集修剪的方法，在深度学习模型的训练中使用更少的数据，实现更快的收敛速度和更好的泛化能力。 |
| [^101] | [Crowd Density Estimation using Imperfect Labels.](http://arxiv.org/abs/2212.01450) | 本文研究了不完整标签对人群计数准确性的影响，并提出了一种系统，利用深度学习模型自动生成不完整标签，并将其用于训练新的人群计数模型。实验证明，所提出的方案的准确性接近于完美标签数据集的准确性。 |
| [^102] | [Scalable Hierarchical Over-the-Air Federated Learning.](http://arxiv.org/abs/2211.16162) | 本研究提出了一种针对分布式环境的通信高效的分层联邦学习算法，通过使用可扩展的无线聚合方案和带宽有限的广播方案，解决了设备干扰和边缘服务器干扰的问题。 |
| [^103] | [Towards Improved Input Masking for Convolutional Neural Networks.](http://arxiv.org/abs/2211.14646) | 本论文提出了一种改进的卷积神经网络的输入遮罩方法，通过层遮罩能够有效减少遮罩引起的缺失偏差，并消除或最小化了遮罩对模型预测的影响。 |
| [^104] | [Undesirable biases in NLP: Averting a crisis of measurement.](http://arxiv.org/abs/2211.13709) | 这项研究提供了一个跨学科的方法来探讨NLP模型偏见的问题，通过采用心理测量学的视角，特别关注构念效度和测量工具的信度，在衡量模型偏见的情境中如何应用。 |
| [^105] | [A Benchmark of Long-tailed Instance Segmentation with Noisy Labels.](http://arxiv.org/abs/2211.13435) | 本文提出了一个带有噪声标签的大词汇量的长尾数据集，用于实例分割任务的基准测试，并在该数据集上评估了先前的实例分割算法。结果表明，训练数据集中的噪声会影响模型学习稀有类别并降低整体性能，为解决这一实际挑战提供了启示。 |
| [^106] | [DroneNet: Crowd Density Estimation using Self-ONNs for Drones.](http://arxiv.org/abs/2211.07137) | 使用自组织神经网络的无人机进行人群密度估计的模型（DroneNet），相比于使用CNN的模型具有更高的计算效率，能够在保持准确性的前提下降低推断时间。 |
| [^107] | [Graph Neural Networks on SPD Manifolds for Motor Imagery Classification: A Perspective from the Time-Frequency Analysis.](http://arxiv.org/abs/2211.02641) | 本文介绍了一种基于SPD流形的图神经网络用于运动想象分类，利用EEG的二阶统计量，相比传统方法具有更好的性能。 |
| [^108] | [Backdoor Attack and Defense in Federated Generative Adversarial Network-based Medical Image Synthesis.](http://arxiv.org/abs/2210.10886) | 本研究调查了联邦生成对抗网络中后门攻击的被忽视问题，并发现成功攻击是由于部分本地判别器对毒素过度拟合所致。 |
| [^109] | [Underspecification in Language Modeling Tasks: A Causality-Informed Study of Gendered Pronoun Resolution.](http://arxiv.org/abs/2210.00131) | 本研究通过提供一个因果模型，在语言建模任务中探讨了不充分规范化的作用，提出了两种轻量级黑盒评估方法来帮助检测任务的不充分规范化，并在性别代词消解任务中应用这些方法，同时发现了性别与时间、性别与位置之间的虚假相关性。 |
| [^110] | [Exploiting Transformer in Sparse Reward Reinforcement Learning for Interpretable Temporal Logic Motion Planning.](http://arxiv.org/abs/2209.13220) | 该论文提出了一个通过将Transformer应用于稀疏奖励强化学习的方法，开发了一个双Transformer引导的时序逻辑框架(T2TL)，该框架通过两次利用Transformer的结构特性，使得机器人在训练过程中能够高效理解任务指令，并改进任务的性能。 |
| [^111] | [Neural Networks Based on Power Method and Inverse Power Method for Solving Linear Eigenvalue Problems.](http://arxiv.org/abs/2209.11134) | 本文提出了两种神经网络方法，分别基于幂法和反幂法，用于求解线性特征值问题。通过自动微分实现微分算子，通过优化损失函数实施迭代算法，可以高效地求解最大正特征值、最小特征值和内部特征值，并在实验中证明了方法的准确性。 |
| [^112] | [Memory-Augmented Graph Neural Networks: A Brain-Inspired Review.](http://arxiv.org/abs/2209.10818) | 本文提供了一个关于记忆增强型图神经网络的全面回顾，通过心理学和神经科学的视角，提出了分类法和比较标准，并讨论了其局限性和未来发展方向。 |
| [^113] | [SAFARI: Versatile and Efficient Evaluations for Robustness of Interpretability.](http://arxiv.org/abs/2208.09418) | 本文提出了一种名为SAFARI的方法，用于评估深度学习的解释可靠性。该方法针对现有技术无法解决的几个挑战，通过引入两种黑盒评估方法，即最坏情况解释差异和一般情况下的鲁棒性的概率概念，来解决现有度量不全面、XAI技术异质性和误解罕见性等问题。使用遗传算法和子集模拟进行评估。 |
| [^114] | [Semi-supervised cross-lingual speech emotion recognition.](http://arxiv.org/abs/2207.06767) | 通过半监督学习方法，我们提出了一种基于Transformer的半监督跨语言情绪识别方法，通过在未标注的语句上应用伪标签策略来适应新领域，有效解决了跨语言情绪识别中标注数据不足和领域差异大的问题。 |
| [^115] | [Binarizing by Classification: Is soft function really necessary?.](http://arxiv.org/abs/2205.07433) | 本文提出将网络二值化视为一个二值分类问题，使用多层感知器作为分类器和梯度估计器，以解决二值神经网络的梯度估计问题，从而实现更好的性能。 |
| [^116] | [Unsupervised Discovery and Composition of Object Light Fields.](http://arxiv.org/abs/2205.03923) | 本文提出了一种无监督发现和合成物体光场的方法，通过将物体表示为以物体为中心的光场来提高渲染质量和操作效率。 |
| [^117] | [Exploring the Distributed Knowledge Congruence in Proxy-data-free Federated Distillation.](http://arxiv.org/abs/2204.07028) | 本文提出了一种基于分布式知识一致性的无代理数据联邦蒸馏算法，解决了客户端模型异质性引起的知识差异问题，从而提高了模型表示的准确性。 |
| [^118] | [Parameter-efficient Model Adaptation for Vision Transformers.](http://arxiv.org/abs/2203.16329) | 本文研究了针对图像分类任务的视觉Transformer的参数高效模型适应策略，通过将模型子模块投影到子空间进行分解，实现了性能与参数成本的平衡。 |
| [^119] | [Automated scholarly paper review: Concepts, technologies, and challenges.](http://arxiv.org/abs/2111.07533) | 提出自动学术论文审稿（ASPR）的概念和流程，综述了实现全面计算机化审稿流程的相关文献和技术，同时指出实现中存在的挑战，如文档解析和表达不完美、数据不足、人机交互缺陷和发现低质量文章的难度。 |
| [^120] | [Pruning Ternary Quantization.](http://arxiv.org/abs/2107.10998) | 本文提出了一种剪枝三值量化方法（PTQ），通过集成L2归一化、剪枝和权重衰减项，实现同时优化比特宽度、模型大小和准确性，将模型大小大大减小且保持较高的测试准确性。 |
| [^121] | [Sketch-Based Anomaly Detection in Streaming Graphs.](http://arxiv.org/abs/2106.04486) | 本文提出了在动态图中以在线的方式为边和子图分配异常分数的方法，其利用了扩展的草图数据结构，并且在真实数据集上表现优于现有的方法。 |
| [^122] | [The Less Intelligent the Elements, the More Intelligent the Whole. Or, Possibly Not?.](http://arxiv.org/abs/2012.12689) | 我们探讨了个体智能是否对于集体智能的产生是必要的，以及怎样的个体智能有利于更大的集体智能。在Lotka-Volterra模型中，我们发现了一些个体行为，特别是掠食者的行为，有利于与其他种群共存，但如果猎物和掠食者都足够智能以推断彼此的行为，共存将伴随着两个种群的无限增长。 |
| [^123] | [MDP Playground: An Analysis and Debug Testbed for Reinforcement Learning.](http://arxiv.org/abs/1909.07750) | MDP Playground是一个用于强化学习的测试平台，可以根据不同维度的难度控制方式，挑战代理在各种环境中的表现。它提供了参数化的玩具环境集合，并通过实验揭示了这些环境对代理的影响。 |

# 详细

[^1]: 柔性时间事件建模：通过排名回归优化神经网络

    Towards Flexible Time-to-event Modeling: Optimizing Neural Networks via Rank Regression. (arXiv:2307.08044v1 [cs.LG])

    [http://arxiv.org/abs/2307.08044](http://arxiv.org/abs/2307.08044)

    本研究提出了一种深度AFT排名回归模型，用于灵活地进行时间事件建模，从而改善预测性能并减轻严格的假设。

    

    时间事件分析，也被称为生存分析，旨在根据一组特征预测事件发生的时间。这个领域面临的一个主要挑战是处理被截尾的数据，这可能使学习算法更加复杂。传统方法如Cox比例风险模型和加速失效时间（AFT）模型在这个领域很受欢迎，但它们经常需要一些假设，如比例风险和线性。特别是，AFT模型通常需要预先指定的参数分布假设。为了提高预测性能和减轻严格的假设，近年来出现了许多基于深度学习的危险模型方法。然而，神经网络文献中对于AFT的表示学习尚未广泛探索，尽管相对于以危险为重点的方法而言，它更加简单和可解释。在这项工作中，我们引入了深度AFT排名回归模型来进行时间事件预测。

    Time-to-event analysis, also known as survival analysis, aims to predict the time of occurrence of an event, given a set of features. One of the major challenges in this area is dealing with censored data, which can make learning algorithms more complex. Traditional methods such as Cox's proportional hazards model and the accelerated failure time (AFT) model have been popular in this field, but they often require assumptions such as proportional hazards and linearity. In particular, the AFT models often require pre-specified parametric distributional assumptions. To improve predictive performance and alleviate strict assumptions, there have been many deep learning approaches for hazard-based models in recent years. However, representation learning for AFT has not been widely explored in the neural network literature, despite its simplicity and interpretability in comparison to hazard-focused methods. In this work, we introduce the Deep AFT Rank-regression model for Time-to-event predic
    
[^2]: 一种神经符号方法实现对语法正确句子的识别

    A Neural-Symbolic Approach Towards Identifying Grammatically Correct Sentences. (arXiv:2307.08036v1 [cs.CL])

    [http://arxiv.org/abs/2307.08036](http://arxiv.org/abs/2307.08036)

    这项研究介绍了一种神经符号方法来解决验证语法正确句子的问题。

    

    我们身边的文本内容每天都在增长。在网上报纸、博客或社交媒体上，我们正在撰写大量的文章。类似地，人工智能领域的最新进展，如语言模型或传统的经典人工智能方法，正在利用以上所有内容，提高他们学习的表示能力，以实现类似人类的准确性来应对自然语言处理挑战。众所周知，获取来自有效来源的写作文本对于应对文本摘要、问答、机器翻译甚至代词消解等挑战至关重要。例如，要进行良好的摘要，需要选择最重要的句子，然后将它们连接起来形成摘要。然而，如果我们没有获取到写得好的英文句子甚至非有效的句子会怎么样呢？尽管获得写得好的句子的重要性被广泛认可，但找出验证它们的方法仍然是一个开放的研究领域。为了解决这个问题，我们提出了一种神经符号方法。

    Textual content around us is growing on a daily basis. Numerous articles are being written as we speak on online newspapers, blogs, or social media. Similarly, recent advances in the AI field, like language models or traditional classic AI approaches, are utilizing all the above to improve their learned representation to tackle NLP challenges with human-like accuracy. It is commonly accepted that it is crucial to have access to well-written text from valid sources to tackle challenges like text summarization, question-answering, machine translation, or even pronoun resolution. For instance, to summarize well, one needs to select the most important sentences in order to concatenate them to form the summary. However, what happens if we do not have access to well-formed English sentences or even non-valid sentences? Despite the importance of having access to well-written sentences, figuring out ways to validate them is still an open area of research. To address this problem, we present a 
    
[^3]: 贝叶斯推理在数据高效、可解释和安全的机器人运动规划中的应用：一项综述

    Bayesian inference for data-efficient, explainable, and safe robotic motion planning: A review. (arXiv:2307.08024v1 [cs.AI])

    [http://arxiv.org/abs/2307.08024](http://arxiv.org/abs/2307.08024)

    这篇论文综述了贝叶斯推理在机器人运动规划中的应用优势，包括策略不确定性量化、机器人运动的安全性和最优性保证、数据效率以及模拟到现实的差距。该综述提供了贝叶斯推理的概率理论和估计方法，并介绍了经典的基于模型和无模型的贝叶斯强化学习算法。

    

    贝叶斯推理在机器人运动规划中具有许多优势，包括策略的不确定性量化、机器人运动的安全性和最佳性保证、强化学习训练的数据效率以及在机器人应用于真实世界任务时减小模拟到现实的差距。然而，贝叶斯推理在机器人运动规划中的应用滞后于贝叶斯推理的全面理论。此外，还没有综述来总结贝叶斯推理在机器人运动规划中的进展，以便给研究人员提供系统的理解。本文首先介绍了贝叶斯推理的概率理论，这些是解决复杂情况下贝叶斯推理的首要前提。其次，给出了贝叶斯估计用于估计策略或未知函数的后验概率，这些后验概率用于计算策略。第三，介绍了经典的基于模型的贝叶斯强化学习和无模型的贝叶斯强化学习算法。

    Bayesian inference has many advantages in robotic motion planning over four perspectives: The uncertainty quantification of the policy, safety (risk-aware) and optimum guarantees of robot motions, data-efficiency in training of reinforcement learning, and reducing the sim2real gap when the robot is applied to real-world tasks. However, the application of Bayesian inference in robotic motion planning is lagging behind the comprehensive theory of Bayesian inference. Further, there are no comprehensive reviews to summarize the progress of Bayesian inference to give researchers a systematic understanding in robotic motion planning. This paper first provides the probabilistic theories of Bayesian inference which are the preliminary of Bayesian inference for complex cases. Second, the Bayesian estimation is given to estimate the posterior of policies or unknown functions which are used to compute the policy. Third, the classical model-based Bayesian RL and model-free Bayesian RL algorithms f
    
[^4]: 将任务分解：视觉和语言决策的单元级混合训练框架

    Breaking Down the Task: A Unit-Grained Hybrid Training Framework for Vision and Language Decision Making. (arXiv:2307.08016v1 [cs.CV])

    [http://arxiv.org/abs/2307.08016](http://arxiv.org/abs/2307.08016)

    该论文提出了一个单元级混合训练框架来解决视觉和语言决策任务。通过将任务分解为精细的单元，并利用单位内环境的不变性，使得训练更加有效，减少了曝光偏差，并在 TEACH基准测试上超越了现有的最先进技术。

    

    视觉语言决策（VLDM）是一项具有挑战性的多模态任务。代理需要理解复杂的人类指令，并完成涉及环境导航和物体操纵的组合任务。然而，VLDM中涉及的长期行动序列使任务难以学习。从环境的角度来看，我们发现任务可以被细分为精细的“单元”，每个单元包含一个导航阶段和一个交互阶段。由于单位内的环境保持不变，我们提出了一种新颖的混合训练框架，使得在环境中进行主动探索，并减少了曝光偏差。这样的框架利用了单元级配置，是模型无关的。具体而言，我们设计了一个带有内在循环状态的单元转换器（UT），该状态维护着一个单元级的跨模态内存。通过在TEACH基准测试上进行广泛实验，我们证明了我们提出的框架优于现有的最先进技术

    Vision language decision making (VLDM) is a challenging multimodal task. The agent have to understand complex human instructions and complete compositional tasks involving environment navigation and object manipulation. However, the long action sequences involved in VLDM make the task difficult to learn. From an environment perspective, we find that task episodes can be divided into fine-grained \textit{units}, each containing a navigation phase and an interaction phase. Since the environment within a unit stays unchanged, we propose a novel hybrid-training framework that enables active exploration in the environment and reduces the exposure bias. Such framework leverages the unit-grained configurations and is model-agnostic. Specifically, we design a Unit-Transformer (UT) with an intrinsic recurrent state that maintains a unit-scale cross-modal memory. Through extensive experiments on the TEACH benchmark, we demonstrate that our proposed framework outperforms existing state-of-the-art
    
[^5]: SHAMSUL: 利用本地可解释性方法进行同时热图分析以研究医学意义

    SHAMSUL: Simultaneous Heatmap-Analysis to investigate Medical Significance Utilizing Local interpretability methods. (arXiv:2307.08003v1 [eess.IV])

    [http://arxiv.org/abs/2307.08003](http://arxiv.org/abs/2307.08003)

    本研究利用四种解释性方法探索深度神经网络在医学领域的可解释性，通过热图分析解释神经网络的预测结果，并针对特定病理类别进行定量和定性研究。

    

    深度神经网络的可解释性已成为医疗和健康领域的一个热门议题。这种关注来源于对透明度、法律和伦理考虑以及这些深度神经网络在临床决策支持系统中生成的预测的医学意义的担忧。为了解决这个问题，我们的研究深入探讨了四种已建立的解释性方法: 局部可解释模型无关解释(LIME)、Shapley加性解释(SHAP)、梯度加权类别激活映射(Grad-CAM)和层内相关传播(LRP)。我们利用多标签多类胸部放射学数据集的迁移学习方法，旨在解释与特定病理类别相关的预测。我们的分析涵盖了单标签和多标签预测，通过定量和定性研究提供了全面和公正的评估，

    The interpretability of deep neural networks has become a subject of great interest within the medical and healthcare domain. This attention stems from concerns regarding transparency, legal and ethical considerations, and the medical significance of predictions generated by these deep neural networks in clinical decision support systems. To address this matter, our study delves into the application of four well-established interpretability methods: Local Interpretable Model-agnostic Explanations (LIME), Shapley Additive exPlanations (SHAP), Gradient-weighted Class Activation Mapping (Grad-CAM), and Layer-wise Relevance Propagation (LRP). Leveraging the approach of transfer learning with a multi-label-multi-class chest radiography dataset, we aim to interpret predictions pertaining to specific pathology classes. Our analysis encompasses both single-label and multi-label predictions, providing a comprehensive and unbiased assessment through quantitative and qualitative investigations, w
    
[^6]: MargCTGAN: "边际化" 更好的低样本情况下的CTGAN方法

    MargCTGAN: A "Marginally'' Better CTGAN for the Low Sample Regime. (arXiv:2307.07997v1 [cs.LG])

    [http://arxiv.org/abs/2307.07997](http://arxiv.org/abs/2307.07997)

    MargCTGAN提出一个新的合成数据生成方法，在低样本情况下通过添加特征匹配的去相关边际，改善了CTGAN模型在实用性和统计属性方面的表现。

    

    现实而有用的合成数据具有很大的潜力。然而，当前合成表格数据生成的评估方法主要关注下游任务的有用性，往往忽视了统计属性的重要性。这种疏忽在低样本情况下尤为明显，伴随着这些统计指标的迅速恶化。在本文中，我们通过对三种最先进的合成表格数据生成器在边际分布、列对相关性、联合分布和下游任务实用性表现等方面在高到低样本情况下的评估，来解决这个问题。流行的CTGAN模型在实用性方面表现强劲，但在低样本设置方面的实用性较差。为了克服这个限制，我们提出了MargCTGAN方法，通过添加特征匹配的去相关边际，从而在下游实用性和合成数据的统计属性方面实现了持续的改进。

    The potential of realistic and useful synthetic data is significant. However, current evaluation methods for synthetic tabular data generation predominantly focus on downstream task usefulness, often neglecting the importance of statistical properties. This oversight becomes particularly prominent in low sample scenarios, accompanied by a swift deterioration of these statistical measures. In this paper, we address this issue by conducting an evaluation of three state-of-the-art synthetic tabular data generators based on their marginal distribution, column-pair correlation, joint distribution and downstream task utility performance across high to low sample regimes. The popular CTGAN model shows strong utility, but underperforms in low sample settings in terms of utility. To overcome this limitation, we propose MargCTGAN that adds feature matching of de-correlated marginals, which results in a consistent improvement in downstream utility as well as statistical properties of the syntheti
    
[^7]: 图神经网络的自动多项式滤波器学习

    Automated Polynomial Filter Learning for Graph Neural Networks. (arXiv:2307.07956v1 [cs.LG])

    [http://arxiv.org/abs/2307.07956](http://arxiv.org/abs/2307.07956)

    本文提出了一种自动学习多项式滤波器的框架，名为Auto-Polynomial，在同质性和异质性图上取得了显著的性能提升。

    

    多项式图滤波器作为图神经网络设计中的指导原则被广泛应用。最近，自适应学习多项式图滤波器在建模同质性和异质性图信号方面表现出了很大的潜力，具有灵活性和表达性。本文通过一项创新的初步研究，探索了多项式图滤波器学习方法的潜力和限制，揭示了严重的过拟合问题。为了提高多项式图滤波器的效果，我们提出了Auto-Polynomial，这是一个新颖且通用的自动多项式图滤波器学习框架，可以高效地学习更好的滤波器，适应各种复杂的图信号。综合实验和消融研究在考虑多种标签比例的同质性和异质性图上展示了显著且一致的性能提升。

    Polynomial graph filters have been widely used as guiding principles in the design of Graph Neural Networks (GNNs). Recently, the adaptive learning of the polynomial graph filters has demonstrated promising performance for modeling graph signals on both homophilic and heterophilic graphs, owning to their flexibility and expressiveness. In this work, we conduct a novel preliminary study to explore the potential and limitations of polynomial graph filter learning approaches, revealing a severe overfitting issue. To improve the effectiveness of polynomial graph filters, we propose Auto-Polynomial, a novel and general automated polynomial graph filter learning framework that efficiently learns better filters capable of adapting to various complex graph signals. Comprehensive experiments and ablation studies demonstrate significant and consistent performance improvements on both homophilic and heterophilic graphs across multiple learning settings considering various labeling ratios, which u
    
[^8]: MinT: 通过多视角微调提升数学推理的泛化性能

    MinT: Boosting Generalization in Mathematical Reasoning via Multi-View Fine-Tuning. (arXiv:2307.07951v1 [cs.AI])

    [http://arxiv.org/abs/2307.07951](http://arxiv.org/abs/2307.07951)

    MinT通过多视角微调方法，利用不同标注风格的数学问题数据集提升了数学推理中小型语言模型的泛化能力。

    

    对于相对较小的语言模型（LM），在数学推理中进行推理仍然是一个重大挑战。许多当前方法专注于在数学推理中专门化LM，并且过度依赖于强大但低效的大型LM（LLM）所提供的知识蒸馏。在这项工作中，我们探索了一种避免过度依赖LLM教师的新思路，引入了一种利用具有不同标注风格的现有数学问题数据集的多视角微调方法。我们的方法将不同的标注格式视为不同的“视图”，并在模型训练中利用它们。通过将不同的指令附加到输入问题上，模型可以学习以灵活的方式生成不同格式的解决方案。实验证明，我们的策略使LLaMA-7B模型能够超越利用知识蒸馏的先前方法以及精心建立的基准。此外，所提出的方法使模型取得了活跃

    Reasoning in mathematical domains remains a significant challenge for relatively small language models (LMs). Many current methods focus on specializing LMs in mathematical reasoning and rely heavily on knowledge distillation from powerful but inefficient large LMs (LLMs). In this work, we explore a new direction that avoids over-reliance on LLM teachers, introducing a multi-view fine-tuning method that efficiently exploits existing mathematical problem datasets with diverse annotation styles. Our approach uniquely considers the various annotation formats as different "views" and leverages them in training the model. By postpending distinct instructions to input questions, models can learn to generate solutions in diverse formats in a flexible manner. Experimental results show that our strategy enables a LLaMA-7B model to outperform prior approaches that utilize knowledge distillation, as well as carefully established baselines. Additionally, the proposed method grants the models promi
    
[^9]: 通过可靠的、多样化的和类平衡的伪标签来重新审视领域自适应三维物体检测

    Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and Class-balanced Pseudo-Labeling. (arXiv:2307.07944v1 [cs.CV])

    [http://arxiv.org/abs/2307.07944](http://arxiv.org/abs/2307.07944)

    本文通过提出一种适用于多类训练设置的新型ReDB框架来解决现有领域自适应方法在多类训练设置下性能下降的问题，通过产生可靠的、多样化的和类平衡的伪三维框来引导目标领域的自训练。

    

    无监督领域自适应与伪标签技术的辅助已经成为领域自适应三维物体检测的关键方法。然而，现有的领域自适应方法在应用于多类训练设置时性能大幅下降，原因是伪标签的质量低和类别不平衡问题共存。本文通过提出一种针对同时学习检测所有类别的新型ReDB框架来解决这一挑战。我们的方法产生可靠的、多样化的和类平衡的伪三维框，通过迭代地引导不同分布的目标领域的自训练。为了减轻环境差异（例如，光束数量）带来的干扰，我们提出了跨域检查（CDE），通过将目标实例复制粘贴到源环境中并测量预测的一致性来评估伪标签的正确性。为了减少计算开销和缓解物体的转移（例如，

    Unsupervised domain adaptation (DA) with the aid of pseudo labeling techniques has emerged as a crucial approach for domain-adaptive 3D object detection. While effective, existing DA methods suffer from a substantial drop in performance when applied to a multi-class training setting, due to the co-existence of low-quality pseudo labels and class imbalance issues. In this paper, we address this challenge by proposing a novel ReDB framework tailored for learning to detect all classes at once. Our approach produces Reliable, Diverse, and class-Balanced pseudo 3D boxes to iteratively guide the self-training on a distributionally different target domain. To alleviate disruptions caused by the environmental discrepancy (e.g., beam numbers), the proposed cross-domain examination (CDE) assesses the correctness of pseudo labels by copy-pasting target instances into a source environment and measuring the prediction consistency. To reduce computational overhead and mitigate the object shift (e.g.
    
[^10]: KECOR:用于主动3D物体检测的内核编码率最大化

    KECOR: Kernel Coding Rate Maximization for Active 3D Object Detection. (arXiv:2307.07942v1 [cs.CV])

    [http://arxiv.org/abs/2307.07942](http://arxiv.org/abs/2307.07942)

    本论文提出了一种内核编码率最大化（KECOR）策略，可以通过信息论的视角确定最具信息量的点云，以最小化标注所需的比特数。这种策略可以减轻LiDAR物体检测中的注释负担并提高计算效率。

    

    在自动驾驶中实现可靠的基于LiDAR的物体检测器至关重要，但其成功取决于获取大量精确的3D注释。主动学习（AL）通过使用更少的标签和可以达到与完全监督学习相当的性能的算法来减轻注释负担。尽管AL表现出了潜力，但当前方法优先选择具有高不确定性和/或多样性的未标记点云，导致选择更多实例进行标记并降低计算效率。在本文中，我们采用了一种新颖的内核编码率最大化（KECOR）策略，该策略旨在通过信息论的视角确定最具信息量的点云以获取标签。贪婪搜索被应用于寻找能够最大化编码潜在特征所需的最小比特数的期望点云。为了确定所选样本的独特性和信息量，从模型的角度进行了评估。

    Achieving a reliable LiDAR-based object detector in autonomous driving is paramount, but its success hinges on obtaining large amounts of precise 3D annotations. Active learning (AL) seeks to mitigate the annotation burden through algorithms that use fewer labels and can attain performance comparable to fully supervised learning. Although AL has shown promise, current approaches prioritize the selection of unlabeled point clouds with high uncertainty and/or diversity, leading to the selection of more instances for labeling and reduced computational efficiency. In this paper, we resort to a novel kernel coding rate maximization (KECOR) strategy which aims to identify the most informative point clouds to acquire labels through the lens of information theory. Greedy search is applied to seek desired point clouds that can maximize the minimal number of bits required to encode the latent features. To determine the uniqueness and informativeness of the selected samples from the model perspec
    
[^11]: GeoGPT:通过自主GPT理解和处理地理空间任务

    GeoGPT: Understanding and Processing Geospatial Tasks through An Autonomous GPT. (arXiv:2307.07930v1 [cs.CL])

    [http://arxiv.org/abs/2307.07930](http://arxiv.org/abs/2307.07930)

    GeoGPT是一个基于自主GPT的系统，旨在通过将大规模语言模型的语义理解能力与地理空间任务相结合，降低非专业用户解决地理空间任务的门槛。

    

    GIS决策者需要结合一系列的空间算法和操作来解决地理空间任务。最近，经过预训练的Transformer模型在语义理解和推理方面表现出很强的性能。受到这些研究的启发，我们尝试通过将预训练模型的语义理解能力与地理空间任务相结合，降低非专业用户解决地理空间任务的门槛。

    Decision-makers in GIS need to combine a series of spatial algorithms and operations to solve geospatial tasks. For example, in the task of facility siting, the Buffer tool is usually first used to locate areas close or away from some specific entities; then, the Intersect or Erase tool is used to select candidate areas satisfied multiple requirements. Though professionals can easily understand and solve these geospatial tasks by sequentially utilizing relevant tools, it is difficult for non-professionals to handle these problems. Recently, Generative Pre-trained Transformer (e.g., ChatGPT) presents strong performance in semantic understanding and reasoning. Especially, AutoGPT can further extend the capabilities of large language models (LLMs) by automatically reasoning and calling externally defined tools. Inspired by these studies, we attempt to lower the threshold of non-professional users to solve geospatial tasks by integrating the semantic understanding ability inherent in LLMs 
    
[^12]: 神经架构检索

    Neural Architecture Retrieval. (arXiv:2307.07919v1 [cs.AI])

    [http://arxiv.org/abs/2307.07919](http://arxiv.org/abs/2307.07919)

    该论文提出了一个新的问题——神经架构检索，主要解决了研究人员在发现相似神经架构时所遇到的困难，并引入了多层对比学习来实现准确的图表示学习。

    

    随着新型神经架构设计的增加和现有神经架构的大量存在，研究人员很难将自己的贡献与现有的神经架构相比较，或者建立自己的设计与其他相关设计之间的联系。为了以高效且自动的方式发现相似的神经架构，我们定义了一个新的问题——神经架构检索，它检索一组与查询神经架构具有相似设计的现有神经架构。由于神经架构中的图的大小和模式，现有的图预训练策略不能解决计算图问题。为了充分发挥潜力，我们提出将图分成模式，并将其用于重建宏图来解决这些问题，并引入多层对比学习来实现准确的图表示学习。对人工设计和合成神经架构进行了广泛评估。

    With the increasing number of new neural architecture designs and substantial existing neural architectures, it becomes difficult for the researchers to situate their contributions compared with existing neural architectures or establish the connections between their designs and other relevant ones. To discover similar neural architectures in an efficient and automatic manner, we define a new problem Neural Architecture Retrieval which retrieves a set of existing neural architectures which have similar designs to the query neural architecture. Existing graph pre-training strategies cannot address the computational graph in neural architectures due to the graph size and motifs. To fulfill this potential, we propose to divide the graph into motifs which are used to rebuild the macro graph to tackle these issues, and introduce multi-level contrastive learning to achieve accurate graph representation learning. Extensive evaluations on both human-designed and synthesized neural architecture
    
[^13]: 你需要的只是模仿吗？具有双阶段训练的泛化决策制定

    Is Imitation All You Need? Generalized Decision-Making with Dual-Phase Training. (arXiv:2307.07909v1 [cs.AI])

    [http://arxiv.org/abs/2307.07909](http://arxiv.org/abs/2307.07909)

    DualMind使用双阶段训练策略，在控制任务中学习共同知识，并通过模仿行为在不同上下文中做出决策。在实验中，DualMind在MetaWorld和Habitat上表现优于其他通用性代理，具有超过50%和70%的提升。

    

    我们引入了DualMind，这是一个通用性代理，旨在解决当前方法面临的挑战，如过度拟合行为和依赖于特定任务的精细调整。DualMind使用一种新颖的“双阶段”训练策略，模拟了人类学习在世界中行动的方式。模型首先通过针对控制任务定制的自监督目标来学习基本的共同知识，然后通过模仿基于给定提示的行为来学习在不同上下文中做出决策。 DualMind可以处理跨域、场景和具体问题，并仅使用单组模型权重来执行零样本提示，而不需要任务特定的精细调整。我们通过广泛的实验在MetaWorld和Habitat上评估了DualMind，并证明其相较于之前的技术具有更好的泛化性能，在Habitat和MetaWorld上的表现分别超过了其他通用性代理的50%和70%。

    We introduce DualMind, a generalist agent designed to tackle various decision-making tasks that addresses challenges posed by current methods, such as overfitting behaviors and dependence on task-specific fine-tuning. DualMind uses a novel "Dual-phase" training strategy that emulates how humans learn to act in the world. The model first learns fundamental common knowledge through a self-supervised objective tailored for control tasks and then learns how to make decisions based on different contexts through imitating behaviors conditioned on given prompts. DualMind can handle tasks across domains, scenes, and embodiments using just a single set of model weights and can execute zero-shot prompting without requiring task-specific fine-tuning. We evaluate DualMind on MetaWorld and Habitat through extensive experiments and demonstrate its superior generalizability compared to previous techniques, outperforming other generalist agents by over 50$\%$ and 70$\%$ on Habitat and MetaWorld, respe
    
[^14]: 自动化纤维成型中的异常检测：数据有限的学习

    Anomaly Detection in Automated Fibre Placement: Learning with Data Limitations. (arXiv:2307.07893v1 [cs.CV])

    [http://arxiv.org/abs/2307.07893](http://arxiv.org/abs/2307.07893)

    本文提出了一种在数据有限的情况下，通过自动编码器进行异常检测的方法，利用纤维层片的深度图进行二分类，并使用重构误差作为量化指标。

    

    当前自动化纤维成型(AFP)的缺陷检测系统主要基于端到端的监督学习方法，需要大量标记的有缺陷样本，而这些样本很难生成足够数量。为了解决这个数据稀缺的问题，我们引入了一种基于自动编码器的方法，适用于小型数据集。幸运的是，从基础的角度来看，这个问题可以简化为正常样本和异常样本之间的二分类。所提出的方法使用纤维层片（tow）对纤维铺设表面的深度图进行分割成小窗口。其中不包含异常的窗口子集传递给自动编码器来重构输入。因为自动编码器是用正常样本进行训练的，对于这些样本，它产生的重构比对于异常样本更精确。因此，重构误差的值被用作一个量化指标，用于判断是否存在潜在的异常。

    Current defect detection systems for Automated Fibre Placement (AFP) are mostly based on end-to-end supervised learning methods requiring abundant labelled defective samples, which are not easily generated in sufficient numbers. To address this data scarcity problem, we introduce an autoencoder-based approach compatible with small datasets. Fortunately, the problem from a foundational point of view can be simplified as a binary classification between normal and abnormal samples. The proposed approach uses a depth map of the fibre layup surface, split into small windows aligned to each composite strip (tow). A subset of these windows that do not contain anomalies is passed to an autoencoder to reconstruct the input. Because the autoencoder is trained with normal samples, it produces more accurate reconstructions for these samples than for abnormal ones. Therefore, the value of reconstruction error is used as a quantitative metric for whether there are potential anomalies. These values a
    
[^15]: 手写和打印文本分割：一个签名案例研究

    Handwritten and Printed Text Segmentation: A Signature Case Study. (arXiv:2307.07887v1 [cs.CV])

    [http://arxiv.org/abs/2307.07887](http://arxiv.org/abs/2307.07887)

    本研究旨在解决手写和打印文本分割的挑战，并提出了一种新的方法来完整地恢复不同类别的文本，特别是在重叠部分提高分割性能。同时，还引入了一个新的数据集SignaTR6K，用于支持该任务。

    

    在分析扫描文档时，手写文本可能覆盖打印文本。这在文档的光学字符识别（OCR）和数字化过程中造成困难，并且进而影响到下游的自然语言处理（NLP）任务。之前的研究要么仅关注手写文本的二分类，要么进行三类文档的分割，即手写、打印和背景像素的识别。这导致手写和打印重叠的像素只被分配到一个类别中，因此在另一个类别中不被考虑。因此，在这项研究中，我们开发了新的方法来解决手写和打印文本分割的挑战，目标是完整地恢复不同类别的文本，特别是提高重叠部分的分割性能。为了促进这项任务，我们介绍了一个新的数据集SignaTR6K，该数据集收集自真实的法律文件。

    While analyzing scanned documents, handwritten text can overlay printed text. This causes difficulties during the optical character recognition (OCR) and digitization process of documents, and subsequently, hurts downstream NLP tasks. Prior research either focuses only on the binary classification of handwritten text, or performs a three-class segmentation of the document, i.e., recognition of handwritten, printed, and background pixels. This results in the assignment of the handwritten and printed overlapping pixels to only one of the classes, and thus, they are not accounted for in the other class. Thus, in this research, we develop novel approaches for addressing the challenges of handwritten and printed text segmentation with the goal of recovering text in different classes in whole, especially improving the segmentation performance on the overlapping parts. As such, to facilitate with this task, we introduce a new dataset, SignaTR6K, collected from real legal documents, as well as
    
[^16]: 在离散和连续域中使用矢量表达进行在线目标识别

    Online Goal Recognition in Discrete and Continuous Domains Using a Vectorial Representation. (arXiv:2307.07876v1 [cs.AI])

    [http://arxiv.org/abs/2307.07876](http://arxiv.org/abs/2307.07876)

    该论文提出了一种在离散和连续域中使用矢量表达进行在线目标识别的高效方法，该方法通过减少计算负担和提高识别速度，使其成为首个可用于快速变动环境下的机器人应用的在线方法。

    

    最近对于在线目标识别的研究主要关注在低可观测性下有效推断目标，而对于在离散和连续域中都能工作的在线目标识别的研究较少。在线目标识别方法通常需要在每个新的观测中多次调用规划器，造成了很高的计算成本。在连续空间中快速而可靠地识别目标对于任何轨迹规划问题都是至关重要的，因为真实物理世界是快速变动的，例如机器人应用。我们开发了一种高效的目标识别方法，在离散域中每个可能的目标只需要一次调用规划器，而在连续域中利用简化的运动模型来减小计算负担。由此产生的方法比当前最先进的方法在在线识别方面快几个数量级，使之成为首个实际可用于需要亚秒级响应的机器人应用的在线方法。

    While recent work on online goal recognition efficiently infers goals under low observability, comparatively less work focuses on online goal recognition that works in both discrete and continuous domains. Online goal recognition approaches often rely on repeated calls to the planner at each new observation, incurring high computational costs. Recognizing goals online in continuous space quickly and reliably is critical for any trajectory planning problem since the real physical world is fast-moving, e.g. robot applications. We develop an efficient method for goal recognition that relies either on a single call to the planner for each possible goal in discrete domains or a simplified motion model that reduces the computational burden in continuous ones. The resulting approach performs the online component of recognition orders of magnitude faster than the current state of the art, making it the first online method effectively usable for robotics applications that require sub-second rec
    
[^17]: 自监督学习中是否会发生双下降现象？

    Does Double Descent Occur in Self-Supervised Learning?. (arXiv:2307.07872v1 [cs.LG])

    [http://arxiv.org/abs/2307.07872](http://arxiv.org/abs/2307.07872)

    研究发现，在自监督学习中缺乏双下降现象，进一步的研究有助于揭示其理论基础。

    

    大多数关于双下降现象的研究都集中在监督模型上，而对于自监督设置的研究却发现这种现象的缺失令人惊讶。这些结果表明，在自监督模型中可能不存在双下降现象。我们通过使用标准和线性自编码器来进行实证研究，发现测试损失要么呈现经典的U型曲线，要么单调递减，而不是呈现双下降曲线。我们希望进一步的研究能够揭示这一现象的理论基础。

    Most investigations into double descent have focused on supervised models while the few works studying self-supervised settings find a surprising lack of the phenomenon. These results imply that double descent may not exist in self-supervised models. We show this empirically using a standard and linear autoencoder, two previously unstudied settings. The test loss is found to have either a classical U-shape or to monotonically decrease instead of exhibiting a double-descent curve. We hope that further work on this will help elucidate the theoretical underpinnings of this phenomenon.
    
[^18]: 社会AI学校：从发展心理学到人工社会文化代理的观点

    The SocialAI School: Insights from Developmental Psychology Towards Artificial Socio-Cultural Agents. (arXiv:2307.07871v1 [cs.AI])

    [http://arxiv.org/abs/2307.07871](http://arxiv.org/abs/2307.07871)

    该论文讨论了AI研究应该受发展心理学启发，并研究使代理能够进入文化的社会认知能力。提出了社会AI学校工具以便于进行相关实验。

    

    发展心理学家长期以来已经确立了社会认知能力在人类智力中的重要性。这些能力使我们能够进入、参与和从人类文化中受益。社会交互代理的AI研究大多关注多智能体环境中文化的出现（通常没有强烈的发展心理学基础）。我们认为AI研究应该受心理学启发，并研究能够进入文化的社会认知能力。我们讨论了Michael Tomasello和Jerome Bruner的理论，介绍了他们的一些概念，并概述了关键概念和社会认知能力。我们提出了社会AI学校——一个包括定制参数化环境的工具，简化了关于这些概念的实验。我们展示了使用RL代理和大型语言模型进行此类实验的示例。这项工作的主要动机是吸引AI社区围绕这些概念进行讨论和研究。

    Developmental psychologists have long-established the importance of socio-cognitive abilities in human intelligence. These abilities enable us to enter, participate and benefit from human culture. AI research on social interactive agents mostly concerns the emergence of culture in a multi-agent setting (often without a strong grounding in developmental psychology). We argue that AI research should be informed by psychology and study socio-cognitive abilities enabling to enter a culture too. We discuss the theories of Michael Tomasello and Jerome Bruner to introduce some of their concepts to AI and outline key concepts and socio-cognitive abilities. We present The SocialAI school - a tool including a customizable parameterized uite of procedurally generated environments, which simplifies conducting experiments regarding those concepts. We show examples of such experiments with RL agents and Large Language Models. The main motivation of this work is to engage the AI community around the 
    
[^19]: 大型语言模型作为文化角度的叠加

    Large Language Models as Superpositions of Cultural Perspectives. (arXiv:2307.07870v1 [cs.CL])

    [http://arxiv.org/abs/2307.07870](http://arxiv.org/abs/2307.07870)

    大型语言模型被认为是具有个性或一套价值观的，但实际上它可以看作是具有不同价值观和个性特征的角度的叠加。通过角度可控性的概念，我们研究了大型语言模型在不同角度下展示的价值观和个性特征的变化。实验结果表明，即使在没有明显提示的情况下，大型语言模型也会表达出不同的价值观。

    

    大型语言模型（LLMs）常常被错误地认为具有个性或一套价值观。我们认为LLMs可以看作是具有不同价值观和个性特征的角度叠加。LLMs表现出依赖于上下文的价值观和个性特征，这些特征基于产生的角度而改变（与人类相反，人类在不同情境下通常具有更一致的价值观和个性特征）。我们引入了“角度可控性”的概念，指的是模型采用不同具有不同价值观和个性特征的角度的能力。在我们的实验中，我们使用心理学问卷（PVQ、VSM、IPIP）来研究展示的价值观和个性特征如何基于不同角度而改变。通过定性实验，我们展示了当提示中（隐式或显式）暗示了某些价值观时，LLMs表达出不同的价值观，即使在没有明显暗示的情况下，LLMs也会表达出不同的价值观。

    Large Language Models (LLMs) are often misleadingly recognized as having a personality or a set of values. We argue that an LLM can be seen as a superposition of perspectives with different values and personality traits. LLMs exhibit context-dependent values and personality traits that change based on the induced perspective (as opposed to humans, who tend to have more coherent values and personality traits across contexts). We introduce the concept of perspective controllability, which refers to a model's affordance to adopt various perspectives with differing values and personality traits. In our experiments, we use questionnaires from psychology (PVQ, VSM, IPIP) to study how exhibited values and personality traits change based on different perspectives. Through qualitative experiments, we show that LLMs express different values when those are (implicitly or explicitly) implied in the prompt, and that LLMs express different values even when those are not obviously implied (demonstrat
    
[^20]: 检测豆类的分类算法和支持向量机核函数的有效性的基准测试

    Benchmarking the Effectiveness of Classification Algorithms and SVM Kernels for Dry Beans. (arXiv:2307.07863v1 [cs.LG])

    [http://arxiv.org/abs/2307.07863](http://arxiv.org/abs/2307.07863)

    本研究通过分析和比较不同的分类算法和SVM核函数在豆类数据集上的性能，发现RBF SVM核心算法在准确率、精确率、召回率和F1得分上表现最佳，提供了重要的指导。

    

    植物育种师和农业研究人员可以通过分析豆类数据集来识别理想特征、抗病性和营养含量，从而提高作物产量。本研究分析和比较了不同的支持向量机（SVM）分类算法，包括线性、多项式和径向基函数（RBF），以及其他流行的分类算法。分析是在豆类数据集上进行的，主要使用的评估指标是准确率，而RBF SVM核心算法实现了最高的准确率93.34%，精确率92.61%，召回率92.35%和F1得分91.40%。除了熟练的可视化和经验分析，本研究通过强调考虑不同的SVM算法来处理复杂和非线性结构化数据集，提供了有价值的指导。

    Plant breeders and agricultural researchers can increase crop productivity by identifying desirable features, disease resistance, and nutritional content by analysing the Dry Bean dataset. This study analyses and compares different Support Vector Machine (SVM) classification algorithms, namely linear, polynomial, and radial basis function (RBF), along with other popular classification algorithms. The analysis is performed on the Dry Bean Dataset, with PCA (Principal Component Analysis) conducted as a preprocessing step for dimensionality reduction. The primary evaluation metric used is accuracy, and the RBF SVM kernel algorithm achieves the highest Accuracy of 93.34%, Precision of 92.61%, Recall of 92.35% and F1 Score as 91.40%. Along with adept visualization and empirical analysis, this study offers valuable guidance by emphasizing the importance of considering different SVM algorithms for complex and non-linear structured datasets.
    
[^21]: 基于多启发式搜索的自动停车运动规划

    A Multi-Heuristic Search-based Motion Planning for Automated Parking. (arXiv:2307.07857v1 [cs.RO])

    [http://arxiv.org/abs/2307.07857](http://arxiv.org/abs/2307.07857)

    本论文提出了一种基于多启发式搜索的自动停车运动规划方法，通过使用多个启发式函数来捕捉搜索空间的不同复杂性，以提高计算性能和实现实时规划。

    

    在停车场或建筑工地等无结构环境中，由于车辆的大搜索空间和动力学约束，实时规划是具有挑战性的。几种最先进的规划器利用启发式搜索算法。然而，它们过于依赖单个启发式函数的质量，用于引导搜索。因此，它们无法达到合理的计算性能，导致车辆反应不及时。在这项工作中，我们采用了多启发式搜索方法，允许使用多个启发式函数及其各自的优势来捕捉给定搜索空间的不同复杂性。据我们所知，此方法在此问题上尚未被使用。为此，定义了多个可接受和非可接受的启发式函数，扩展了原始的多启发式A*搜索以进行双向使用并处理混合连续问题。

    In unstructured environments like parking lots or construction sites, due to the large search-space and kinodynamic constraints of the vehicle, it is challenging to achieve real-time planning. Several state-of-the-art planners utilize heuristic search-based algorithms. However, they heavily rely on the quality of the single heuristic function, used to guide the search. Therefore, they are not capable to achieve reasonable computational performance, resulting in unnecessary delays in the response of the vehicle. In this work, we are adopting a Multi-Heuristic Search approach, that enables the use of multiple heuristic functions and their individual advantages to capture different complexities of a given search space. Based on our knowledge, this approach was not used previously for this problem. For this purpose, multiple admissible and non-admissible heuristic functions are defined, the original Multi-Heuristic A* Search was extended for bidirectional use and dealing with hybrid contin
    
[^22]: AspectCSE: 使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入

    AspectCSE: Sentence Embeddings for Aspect-based Semantic Textual Similarity using Contrastive Learning and Structured Knowledge. (arXiv:2307.07851v1 [cs.CL])

    [http://arxiv.org/abs/2307.07851](http://arxiv.org/abs/2307.07851)

    AspectCSE是一种使用对比学习和结构化知识进行基于方面的语义文本相似性的句子嵌入方法，它在信息检索任务中相比之前的最好结果平均提高了3.97%，通过同时考虑多个特定方面的嵌入模型优于单方面嵌入。

    

    通用的句子嵌入提供了对语义文本相似性的粗略近似，但忽略了使文本相似的特定方面。相反，基于方面的句子嵌入提供了基于预定义方面的文本相似性。因此，文本的相似性预测更加针对特定要求，并且更容易解释。在本文中，我们提出了AspectCSE，一种用于基于方面的对比学习句子嵌入的方法。结果表明，与之前最好的结果相比，AspectCSE在多个方面的信息检索任务中实现了平均改善3.97%。我们还提出使用Wikidata知识图属性来训练多方面句子嵌入模型，其中在相似性预测过程中同时考虑多个特定方面。我们证明了多方面嵌入在特定方面信息检索任务上优于单方面嵌入。最后，我们展示了嵌入模型的可解释性，并提出通过对比学习来改进嵌入质量。

    Generic sentence embeddings provide a coarse-grained approximation of semantic textual similarity but ignore specific aspects that make texts similar. Conversely, aspect-based sentence embeddings provide similarities between texts based on certain predefined aspects. Thus, similarity predictions of texts are more targeted to specific requirements and more easily explainable. In this paper, we present AspectCSE, an approach for aspect-based contrastive learning of sentence embeddings. Results indicate that AspectCSE achieves an average improvement of 3.97% on information retrieval tasks across multiple aspects compared to the previous best results. We also propose using Wikidata knowledge graph properties to train models of multi-aspect sentence embeddings in which multiple specific aspects are simultaneously considered during similarity predictions. We demonstrate that multi-aspect embeddings outperform single-aspect embeddings on aspect-specific information retrieval tasks. Finally, w
    
[^23]: AIOptimizer ——基于强化学习的软件性能优化原型，旨在实现成本最小化

    AIOptimizer -- A reinforcement learning-based software performance optimisation prototype for cost minimisation. (arXiv:2307.07846v1 [cs.SE])

    [http://arxiv.org/abs/2307.07846](http://arxiv.org/abs/2307.07846)

    AIOptimizer是一种基于强化学习的软件性能优化工具原型，旨在实现成本最小化。它使用强化学习驱动的推荐系统来改善软件系统的效率和可负担性，并突出了准确性、适应性、可扩展性和用户友好性等设计因素。AIOptimizer还提供故障识别、成本优化建议、效率预测和协作等功能，并使用基于强化学习的推荐引擎进行成本优化。

    

    本研究文章介绍了AIOptimizer，一个基于成本降低的软件性能优化工具的原型。AIOptimizer使用强化学习驱动的推荐系统来改善软件系统的效率和可负担性。本文强调了AIOptimizer的设计因素，如准确性、适应性、可扩展性和用户友好性。为了提供有效的用户中心的性能优化解决方案，它强调了模块化设计、数据收集技术、持续学习和弹性集成的使用。本文还调查了AIOptimizer的特性，如故障识别、成本优化建议、效率预测和协作。此外，本文还探讨了几个软件开发生命周期模型，并介绍了AIOptimizer使用基于强化学习的推荐引擎进行成本优化。本研究旨在突出AIOptimizer作为一种利用先进技术进行成本优化的原型。

    This research article introduces AIOptimizer, a prototype for a software performance optimisation tool based on cost reduction. AIOptimizer uses a recommendation system driven by reinforcement learning to improve software system efficiency and affordability. The paper highlights AIOptimizer's design factors, such as accuracy, adaptability, scalability, and user-friendliness. To provide effective and user-centric performance optimisation solutions, it emphasises the use of a modular design, data gathering techniques, continuous learning, and resilient integration. The article also investigates AIOptimizer features such as fault identification, cost optimisation recommendations, efficiency prediction, and cooperation. Furthermore, it explores several software development life cycle models and introduces AIOptimizer uses a reinforcement learning-based recommendation engine for cost optimisation. The purpose of this research study is to highlight AIOptimizer as a prototype that uses advanc
    
[^24]: RegExplainer: 在回归任务中生成图神经网络的解释

    RegExplainer: Generating Explanations for Graph Neural Networks in Regression Task. (arXiv:2307.07840v1 [cs.LG])

    [http://arxiv.org/abs/2307.07840](http://arxiv.org/abs/2307.07840)

    这项工作提出了一种新的解释方法（XAIG-R），用于解释图回归模型，通过引入信息瓶颈理论的新目标和混合框架来解决回归任务中的挑战，同时还使用对比学习策略来处理连续有序标签。

    

    图回归是一项基础任务，在各种图学习任务中受到越来越多的关注。然而，推理过程通常是不可解释的。现有的解释技术大多限于理解分类任务中图神经网络的行为。在这项工作中，我们寻求解释来解释图回归模型（XAIG-R）。我们展示了现有方法忽视了分布偏移和连续有序的决策边界，这阻碍了它们在回归任务中的应用。为了解决这些挑战，我们提出了一种基于信息瓶颈理论的新目标，并引入了一种新的混合框架，可以以模型无关的方式支持各种图神经网络。我们进一步提出了一种对比学习策略来应对回归任务中的连续有序标签。为了从经验上验证所提出的方法的有效性，我们引入了三个基准数据集和一个真实数据集进行评估。

    Graph regression is a fundamental task and has received increasing attention in a wide range of graph learning tasks. However, the inference process is often not interpretable. Most existing explanation techniques are limited to understanding GNN behaviors in classification tasks. In this work, we seek an explanation to interpret the graph regression models (XAIG-R). We show that existing methods overlook the distribution shifting and continuously ordered decision boundary, which hinders them away from being applied in the regression tasks. To address these challenges, we propose a novel objective based on the information bottleneck theory and introduce a new mix-up framework, which could support various GNNs in a model-agnostic manner. We further present a contrastive learning strategy to tackle the continuously ordered labels in regression task. To empirically verify the effectiveness of the proposed method, we introduce three benchmark datasets and a real-life dataset for evaluation
    
[^25]: MixupExplainer:通过数据增强为图神经网络提供通用解释

    MixupExplainer: Generalizing Explanations for Graph Neural Networks with Data Augmentation. (arXiv:2307.07832v1 [cs.LG])

    [http://arxiv.org/abs/2307.07832](http://arxiv.org/abs/2307.07832)

    本文提出了一种通用的图神经网络解释方法MixupExplainer，通过引入广义图信息瓶颈（GIB）和图mixup方法来解决现有解释方法中存在的分布偏移问题。

    

    图神经网络（GNNs）因其学习图结构数据的能力而受到越来越多的关注。然而，它们的预测往往不可解释。已经提出了事后实例级解释方法来理解GNN的预测。这些方法旨在发现解释训练过的GNN预测行为的子结构。本文揭示了现有方法中存在的分布偏移问题，在真实数据集的应用中特别影响解释质量，因为这些数据集具有严格的决策边界。为了解决这个问题，我们引入了一个包括独立于标签的图变量的广义图信息瓶颈（GIB）形式，等价于传统的GIB。受广义GIB的驱动，我们提出了一种图mixup方法，MixupExplainer，具有解决分布偏移问题的理论保证。我们在合成和真实世界数据集上进行了大量实验证明

    Graph Neural Networks (GNNs) have received increasing attention due to their ability to learn from graph-structured data. However, their predictions are often not interpretable. Post-hoc instance-level explanation methods have been proposed to understand GNN predictions. These methods seek to discover substructures that explain the prediction behavior of a trained GNN. In this paper, we shed light on the existence of the distribution shifting issue in existing methods, which affects explanation quality, particularly in applications on real-life datasets with tight decision boundaries. To address this issue, we introduce a generalized Graph Information Bottleneck (GIB) form that includes a label-independent graph variable, which is equivalent to the vanilla GIB. Driven by the generalized GIB, we propose a graph mixup method, MixupExplainer, with a theoretical guarantee to resolve the distribution shifting issue. We conduct extensive experiments on both synthetic and real-world datasets 
    
[^26]: 通过使用非等向距离和组合改进追踪链接推荐

    Improving Trace Link Recommendation by Using Non-Isotropic Distances and Combinations. (arXiv:2307.07781v1 [cs.SE])

    [http://arxiv.org/abs/2307.07781](http://arxiv.org/abs/2307.07781)

    本文旨在改进追踪链接推荐，通过使用非等向距离和组合方法。通过研究非线性相似度度量，从几何视角探索语义相似性对于追踪性研究是有帮助的。作者在多个项目数据集上进行了评估，并指出这些发现可以对其他信息检索问题起到基础性作用。

    

    软件开发生命周期中的构件之间存在追踪链接可以提高软件开发、维护和运营过程中的效率。然而，追踪链接的创建和维护耗时且容易出错。近年来，随着自然语言处理领域强大工具的出现，对自动计算追踪链接进行研究的努力逐渐增加。在本文中，我们报告了在研究用于计算追踪链接的非线性相似度度量时所做的一些观察。我们认为，从几何视角来看待语义相似性可以有助于未来的追踪性研究。我们在四个开源项目和两个工业项目的数据集上评估了我们的观察结果。我们还指出，我们的发现更具普遍性，也可以为其他信息检索问题奠定基础。

    The existence of trace links between artifacts of the software development life cycle can improve the efficiency of many activities during software development, maintenance and operations. Unfortunately, the creation and maintenance of trace links is time-consuming and error-prone. Research efforts have been spent to automatically compute trace links and lately gained momentum, e.g., due to the availability of powerful tools in the area of natural language processing. In this paper, we report on some observations that we made during studying non-linear similarity measures for computing trace links. We argue, that taking a geometric viewpoint on semantic similarity can be helpful for future traceability research. We evaluated our observations on a dataset of four open source projects and two industrial projects. We furthermore point out that our findings are more general and can build the basis for other information retrieval problems as well.
    
[^27]: 使用反事实路径的可解释人工智能

    Explainable AI with counterfactual paths. (arXiv:2307.07764v1 [cs.AI])

    [http://arxiv.org/abs/2307.07764](http://arxiv.org/abs/2307.07764)

    本文提出了一种新颖的可解释人工智能方法，使用反事实路径来生成解释。通过确定替代路径，可以提供更直观和可解释的解释模型行为的方式，并帮助识别和减轻模型中的偏见。

    

    可解释人工智能是机器学习中日益重要的一个研究领域，其原则上旨在使黑盒模型透明可解释。本文提出了一种新颖的可解释人工智能方法，该方法利用条件置换生成了反事实路径。我们的方法通过确定可能导致不同结果的替代路径来提供反事实解释。所提出的方法特别适用于基于知识图谱的反事实路径解释的生成。通过检查知识图谱中输入数据的假设性变化，我们可以系统地验证模型的行为，并检查对模型预测最重要的特征或特征组合。我们的方法提供了比传统的特征加权方法更直观和可解释的解释模型行为的方式，并可以帮助识别和减轻模型中的偏见。

    Explainable AI (XAI) is an increasingly important area of research in machine learning, which in principle aims to make black-box models transparent and interpretable. In this paper, we propose a novel approach to XAI that uses counterfactual paths generated by conditional permutations. Our method provides counterfactual explanations by identifying alternative paths that could have led to different outcomes. The proposed method is particularly suitable for generating explanations based on counterfactual paths in knowledge graphs. By examining hypothetical changes to the input data in the knowledge graph, we can systematically validate the behaviour of the model and examine the features or combination of features that are most important to the model's predictions. Our approach provides a more intuitive and interpretable explanation for the model's behaviour than traditional feature weighting methods and can help identify and mitigate biases in the model.
    
[^28]: 双向可变形运动调制用于基于视频的人体姿态转移

    Bidirectionally Deformable Motion Modulation For Video-based Human Pose Transfer. (arXiv:2307.07754v1 [cs.CV])

    [http://arxiv.org/abs/2307.07754](http://arxiv.org/abs/2307.07754)

    该论文提出了一种双向可变形运动调制方法，用于基于视频的人体姿态转移。通过几何核偏移和自适应权重调制，同时实现特征对齐和风格转移。与传统方法相比，该方法能够更好地处理服装上的结构图案和不连续的姿势转移，并提供更加满意的结果。

    

    基于视频的人体姿态转移是一个将普通源人体图像根据一系列目标人物姿态进行动画化的视频生成任务。鉴于在服装的高度结构性图案和不连续的姿势转移上存在的困难，现有方法通常会产生不理想的结果，如扭曲的纹理和闪烁的伪影。为解决这些问题，我们提出了一种新颖的可变形运动调制（DMM），该方法利用几何核偏移和自适应权重调制来同时进行特征对齐和风格转移。与在风格转移中使用的普通风格调制不同，所提出的调制机制通过一种非规则感受野根据对象形状自适应重构平滑帧，以实现风格转移。为增强时空一致性，我们利用双向传播从由噪声姿势生成的畸变图像序列中提取隐藏的运动信息。

    Video-based human pose transfer is a video-to-video generation task that animates a plain source human image based on a series of target human poses. Considering the difficulties in transferring highly structural patterns on the garments and discontinuous poses, existing methods often generate unsatisfactory results such as distorted textures and flickering artifacts. To address these issues, we propose a novel Deformable Motion Modulation (DMM) that utilizes geometric kernel offset with adaptive weight modulation to simultaneously perform feature alignment and style transfer. Different from normal style modulation used in style transfer, the proposed modulation mechanism adaptively reconstructs smoothed frames from style codes according to the object shape through an irregular receptive field of view. To enhance the spatio-temporal consistency, we leverage bidirectional propagation to extract the hidden motion information from a warped image sequence generated by noisy poses. The prop
    
[^29]: 学习神经网络中的表达性先验，提高推广和不确定性估计

    Learning Expressive Priors for Generalization and Uncertainty Estimation in Neural Networks. (arXiv:2307.07753v1 [cs.LG])

    [http://arxiv.org/abs/2307.07753](http://arxiv.org/abs/2307.07753)

    本文提出了一种用于神经网络的先验学习方法，通过利用可扩展和结构化的神经网络后验作为推广的信息先验，提高了神经网络的推广和不确定性估计能力。我们的方法在大规模上提供了表达性的概率表示，并产生了非空推广界限。我们的技术贡献是推导出可处理的目标函数，并提出了改进的推广界限计算方法。在经验上，我们证明了该方法在不确定性估计和推广方面的有效性。

    

    在这项工作中，我们提出了一种新的先验学习方法，用于提高深度神经网络中的推广和不确定性估计。关键思想是利用可扩展和结构化的神经网络后验作为具有推广保证的信息先验。我们学习到的先验在大规模上提供了表达性的概率表示，类似于在ImageNet上预训练模型的贝叶斯对应物，并进一步产生了非空推广界限。我们还将这个想法扩展到连续学习框架中，我们的先验的有利特性是可取的。主要的推动因素是我们的技术贡献：(1) Kronecker积求和的计算，(2) 推导和优化可处理的目标函数，从而导致改进的推广界限。在经验上，我们详尽地展示了该方法在不确定性估计和推广方面的有效性。

    In this work, we propose a novel prior learning method for advancing generalization and uncertainty estimation in deep neural networks. The key idea is to exploit scalable and structured posteriors of neural networks as informative priors with generalization guarantees. Our learned priors provide expressive probabilistic representations at large scale, like Bayesian counterparts of pre-trained models on ImageNet, and further produce non-vacuous generalization bounds. We also extend this idea to a continual learning framework, where the favorable properties of our priors are desirable. Major enablers are our technical contributions: (1) the sums-of-Kronecker-product computations, and (2) the derivations and optimizations of tractable objectives that lead to improved generalization bounds. Empirically, we exhaustively show the effectiveness of this method for uncertainty estimation and generalization.
    
[^30]: 结合模型预测控制和预测强化学习实现稳定的四足机器人行走

    Combining model-predictive control and predictive reinforcement learning for stable quadrupedal robot locomotion. (arXiv:2307.07752v1 [cs.RO])

    [http://arxiv.org/abs/2307.07752](http://arxiv.org/abs/2307.07752)

    本研究结合了模型预测控制和预测强化学习方法，旨在解决四足机器人稳定步态生成的问题。

    

    稳定的步态生成是四足机器人行走中的一个关键问题，因为这会影响到其他关键性能因素，比如在不平坦地形上的机动性和功耗。步态生成的稳定性来自于对四足机器人身体与运动环境之间相互作用的高效控制。在本研究中，我们研究了如何通过结合模型预测控制和预测强化学习控制器来实现这一目标。模型预测控制（MPC）是一种已经很成熟的方法，它不使用任何在线学习（除了一些自适应变化），因为它提供了方便的状态约束管理界面。相反，强化学习（RL）依靠基于纯经验的适应性调整。在其基本形式中，由于机器人的复杂性和昂贵的仿真/实验需求，RL并不总是适用于机器人。在本研究中，我们结合了这两种控制方法来解决四足机器人稳定步态生成的问题。

    Stable gait generation is a crucial problem for legged robot locomotion as this impacts other critical performance factors such as, e.g. mobility over an uneven terrain and power consumption. Gait generation stability results from the efficient control of the interaction between the legged robot's body and the environment where it moves. Here, we study how this can be achieved by a combination of model-predictive and predictive reinforcement learning controllers. Model-predictive control (MPC) is a well-established method that does not utilize any online learning (except for some adaptive variations) as it provides a convenient interface for state constraints management. Reinforcement learning (RL), in contrast, relies on adaptation based on pure experience. In its bare-bone variants, RL is not always suitable for robots due to their high complexity and expensive simulation/experimentation. In this work, we combine both control methods to address the quadrupedal robot stable gate gener
    
[^31]: SINC: 自主上下文学习用于视觉-语言任务

    SINC: Self-Supervised In-Context Learning for Vision-Language Tasks. (arXiv:2307.07742v1 [cs.CV])

    [http://arxiv.org/abs/2307.07742](http://arxiv.org/abs/2307.07742)

    提出了一种名为SINC的自主上下文学习框架，可以在不依赖于大型语言模型的情况下实现上下文学习，并避免了模板敏感性和幻觉等问题。

    

    大型预训练Transformers模型展示了在上下文学习中引人入胜的能力。这些模型可以在输入中呈现的演示中，迅速构建新的预测器，而无需梯度更新。最近的工作在视觉-语言领域中促进了这种能力，通过将视觉信息融入到已经能够进行上下文预测的大型语言模型中。然而，这些方法可能继承了语言领域的问题，如模板敏感性和产生幻觉。此外，这些语言模型的规模提高了计算需求，使得学习和操作这些模型资源密集。为此，我们提出了一个问题：“如何在不限制于大型语言模型的情况下，让通用模型能够进行上下文学习？”。为了回答这个问题，我们提出了一个简洁而通用的框架，自主上下文学习（SINC），它引入了一个元模型，以自我监督的提示为基础进行学习，这些提示包括量身定制的演示。

    Large Pre-trained Transformers exhibit an intriguing capacity for in-context learning. Without gradient updates, these models can rapidly construct new predictors from demonstrations presented in the inputs. Recent works promote this ability in the vision-language domain by incorporating visual information into large language models that can already make in-context predictions. However, these methods could inherit issues in the language domain, such as template sensitivity and hallucination. Also, the scale of these language models raises a significant demand for computations, making learning and operating these models resource-intensive. To this end, we raise a question: ``How can we enable in-context learning for general models without being constrained on large language models?". To answer it, we propose a succinct and general framework, Self-supervised IN-Context learning (SINC), that introduces a meta-model to learn on self-supervised prompts consisting of tailored demonstrations.
    
[^32]: 用于解决Raven的渐进矩阵问题的概念变化规则提取

    Abstracting Concept-Changing Rules for Solving Raven's Progressive Matrix Problems. (arXiv:2307.07734v1 [cs.AI])

    [http://arxiv.org/abs/2307.07734](http://arxiv.org/abs/2307.07734)

    本论文提出了一个用于提取概念变化规则的深度模型CRAB，通过学习可解释的概念和解析潜空间中的规则，实现了在Raven的渐进矩阵问题中无需辅助监督的全局规则发现和答案生成，实验证明了该模型优于无监督训练的基线模型。

    

    人类智能中的抽象视觉推理能力有助于在新环境中发现潜在规则。 Raven的渐进矩阵（RPM）是一种经典的测试方法，通过从候选项中选择来实现机器智能中的这种能力。最近的研究表明，以生成答案的方式解决RPM可以增进对规则的更深入理解。然而，现有的生成求解器在没有辅助监督（例如，规则注释和候选项中的干扰项）的情况下无法发现全局的概念变化规则。为此，我们提出了一种用于概念变化规则提取的深度潜变量模型（Concept-changing Rule ABstraction，CRAB），通过学习可解释的概念并解析潜空间中的概念变化规则。通过迭代学习过程，CRAB可以自动提取每个概念上在数据集上共享的全局规则，并形成可学习的全局规则的先验知识。与无辅助监督训练的基线相比，CRAB在任意位置的规则发现和答案生成方面表现优异。

    The abstract visual reasoning ability in human intelligence benefits discovering underlying rules in the novel environment. Raven's Progressive Matrix (RPM) is a classic test to realize such ability in machine intelligence by selecting from candidates. Recent studies suggest that solving RPM in an answer-generation way boosts a more in-depth understanding of rules. However, existing generative solvers cannot discover the global concept-changing rules without auxiliary supervision (e.g., rule annotations and distractors in candidate sets). To this end, we propose a deep latent variable model for Concept-changing Rule ABstraction (CRAB) by learning interpretable concepts and parsing concept-changing rules in the latent space. With the iterative learning process, CRAB can automatically abstract global rules shared on the dataset on each concept and form the learnable prior knowledge of global rules. CRAB outperforms the baselines trained without auxiliary supervision in the arbitrary-posi
    
[^33]: NeurASP：将神经网络融入到Answer Set Programming 中

    NeurASP: Embracing Neural Networks into Answer Set Programming. (arXiv:2307.07700v1 [cs.AI])

    [http://arxiv.org/abs/2307.07700](http://arxiv.org/abs/2307.07700)

    NeurASP是将神经网络集成到Answer Set Programming中的简单且有效的方法，通过以概率分布的形式处理神经网络输出，NeurASP能够将子符号和符号计算相结合，并通过应用符号推理改进神经网络的感知结果，并且可以通过使用ASP规则训练神经网络，使其从显式复杂语义约束中学习。

    

    我们提出了NeurASP，它是对Answer Set Programs的简单扩展，通过融合神经网络。通过将神经网络输出视为Answer Set Programs中原子事实的概率分布，NeurASP提供了一种简单有效的将子符号和符号计算相结合的方法。我们展示了NeurASP如何在符号计算中利用预训练的神经网络，并通过应用Answer Set Programming中的符号推理来改进神经网络的感知结果。此外，NeurASP可以通过使用ASP规则进行训练来更好地训练神经网络，使其不仅从数据中学习隐式相关性，还从规则所表示的显式复杂语义约束中学习。

    We present NeurASP, a simple extension of answer set programs by embracing neural networks. By treating the neural network output as the probability distribution over atomic facts in answer set programs, NeurASP provides a simple and effective way to integrate sub-symbolic and symbolic computation. We demonstrate how NeurASP can make use of a pre-trained neural network in symbolic computation and how it can improve the neural network's perception result by applying symbolic reasoning in answer set programming. Also, NeurASP can be used to train a neural network better by training with ASP rules so that a neural network not only learns from implicit correlations from the data but also from the explicit complex semantic constraints expressed by the rules.
    
[^34]: 利用大型语言模型生成答案集程序

    Leveraging Large Language Models to Generate Answer Set Programs. (arXiv:2307.07699v1 [cs.AI])

    [http://arxiv.org/abs/2307.07699](http://arxiv.org/abs/2307.07699)

    本文提出了一种神经符号方法，将大型语言模型和答案集编程的优势相结合，通过使用大型语言模型将自然语言描述转化为答案集程序，以实现处理复杂推理问题的能力。

    

    大型语言模型（LLMs），如GPT-3和GPT-4，在各种自然语言处理任务中展现了出色的性能，并显示出解决某些推理问题的能力。然而，尽管采用了各种提示技术，它们的推理能力有限且相对浅显。相反，形式逻辑擅长处理复杂推理，但将自然语言描述转化为形式逻辑是一个非专家难以应对的挑战。本文提出了一种神经符号方法，它结合了大型语言模型和答案集编程的优势。具体而言，我们使用一个LLM将逻辑谜题的自然语言描述转化为答案集程序。我们精心设计了LLM的提示，以逐步将自然语言描述转化为答案集程序。令人惊讶的是，仅仅通过几个上下文学习示例，LLMs就能生成相当复杂的答案集。

    Large language models (LLMs), such as GPT-3 and GPT-4, have demonstrated exceptional performance in various natural language processing tasks and have shown the ability to solve certain reasoning problems. However, their reasoning capabilities are limited and relatively shallow, despite the application of various prompting techniques. In contrast, formal logic is adept at handling complex reasoning, but translating natural language descriptions into formal logic is a challenging task that non-experts struggle with. This paper proposes a neuro-symbolic method that combines the strengths of large language models and answer set programming. Specifically, we employ an LLM to transform natural language descriptions of logic puzzles into answer set programs. We carefully design prompts for an LLM to convert natural language descriptions into answer set programs in a step by step manner. Surprisingly, with just a few in-context learning examples, LLMs can generate reasonably complex answer se
    
[^35]: 将大型语言模型与逻辑编程相结合，实现文本的强大和通用推理

    Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text. (arXiv:2307.07696v1 [cs.CL])

    [http://arxiv.org/abs/2307.07696](http://arxiv.org/abs/2307.07696)

    这项研究将大型语言模型与逻辑编程相结合，通过将自然语言句子转换为逻辑形式，使模型能够进行强大且通用的推理。该方法只需要少量的示例和可重用的知识模块，即可在多个问答任务中取得最先进的性能。

    

    尽管像GPT-3这样的大型语言模型在鲁棒性和通用性方面表现出色，但它们的推理能力还不能与针对特定自然语言推理问题训练的最佳模型相竞争。本研究观察到，大型语言模型可以作为一种高效的少示例语义解析器。它可以将自然语言句子转换为逻辑形式，作为答案集程序的输入，该程序是一种基于逻辑的声明性知识表示形式。这种组合结果形成了一个强大而通用的系统，可以处理多个问答任务，无需为每个新任务重新训练。它只需要少量示例来指导LLM适应特定任务，以及可应用于多个任务的可重用ASP知识模块。我们证明这种方法在几个NLP基准测试中取得了最先进的性能，包括bAbI、StepGame、CLUTRR和gSCAN。此外，它还成功解决了机器人规划问题。

    While large language models (LLMs), such as GPT-3, appear to be robust and general, their reasoning ability is not at a level to compete with the best models trained for specific natural language reasoning problems. In this study, we observe that a large language model can serve as a highly effective few-shot semantic parser. It can convert natural language sentences into a logical form that serves as input for answer set programs, a logic-based declarative knowledge representation formalism. The combination results in a robust and general system that can handle multiple question-answering tasks without requiring retraining for each new task. It only needs a few examples to guide the LLM's adaptation to a specific task, along with reusable ASP knowledge modules that can be applied to multiple tasks. We demonstrate that this method achieves state-of-the-art performance on several NLP benchmarks, including bAbI, StepGame, CLUTRR, and gSCAN. Additionally, it successfully tackles robot pla
    
[^36]: 在文档图像中的变化检测技术调查

    A Survey on Change Detection Techniques in Document Images. (arXiv:2307.07691v1 [cs.CV])

    [http://arxiv.org/abs/2307.07691](http://arxiv.org/abs/2307.07691)

    本文调查了文档图像中的变化检测技术，其中主要关注基于内容和基于布局的方法。介绍了现有数据集和评估指标，并报告了现有方法的不足和挑战。

    

    图像中的变化检测问题在医学领域的疾病诊断、通过遥感发现城市的增长模式以及检测法律文件和合同中的变化等不同领域中都有应用。本文介绍了在文档图像的不同版本中检测变化的核心技术和规则的调查。我们主要讨论了基于内容和基于布局的两种变化检测方法。基于内容的技术智能提取和分析图像内容（文本或非文本），以显示可能的差异，而基于布局的技术使用结构信息来预测文档的变化。我们还总结了在变化检测实验中使用的现有数据集和评估指标。报告了现有方法面临的不足和挑战，并提出了一些未来研究工作的指导。

    The problem of change detection in images finds application in different domains like diagnosis of diseases in the medical field, detecting growth patterns of cities through remote sensing, and finding changes in legal documents and contracts. However, this paper presents a survey on core techniques and rules to detect changes in different versions of a document image. Our discussions on change detection focus on two categories -content-based and layout-based. The content-based techniques intelligently extract and analyze the image contents (text or non-text) to show the possible differences, whereas the layout-based techniques use structural information to predict document changes. We also summarize the existing datasets and evaluation metrics used in change detection experiments. The shortcomings and challenges the existing methods face are reported, along with some pointers for future research work.
    
[^37]: 创建一个支持OpenMP Fortran和C++代码相互翻译的数据集

    Creating a Dataset Supporting Translation Between OpenMP Fortran and C++ Code. (arXiv:2307.07686v1 [cs.SE])

    [http://arxiv.org/abs/2307.07686](http://arxiv.org/abs/2307.07686)

    本研究创建了一个数据集，用于训练机器学习模型在OpenMP Fortran和C++代码之间进行翻译。这个数据集通过精细的代码相似性测试确保了可靠性和适用性，并且能够显著提升大规模语言模型的翻译能力。

    

    在本研究中，我们提出了一个新颖的数据集，用于训练在OpenMP Fortran和C++代码之间进行翻译的机器学习模型。通过精细的代码相似性测试，我们确保了数据集的可靠性和适用性。我们使用定量（CodeBLEU）和定性（人工评估）方法评估了我们数据集的有效性。我们展示了这个数据集如何显著提高大规模语言模型的翻译能力，对于没有先前编码知识的模型，提高了5.1倍，对于具有一定编码熟悉度的模型，提高了9.9倍。我们的工作突显了这个数据集在高性能计算的代码翻译领域的潜力。

    In this study, we present a novel dataset for training machine learning models translating between OpenMP Fortran and C++ code. To ensure reliability and applicability, the dataset is initially refined using a meticulous code similarity test. The effectiveness of our dataset is assessed using both quantitative (CodeBLEU) and qualitative (human evaluation) methods. We demonstrate how this dataset can significantly improve the translation capabilities of large-scale language models, with improvements of \times 5.1 for models with no prior coding knowledge and \times 9.9 for models with some coding familiarity. Our work highlights the potential of this dataset to advance the field of code translation for high-performance computing.
    
[^38]: 在线多智能体强化学习的高效对抗攻击

    Efficient Adversarial Attacks on Online Multi-agent Reinforcement Learning. (arXiv:2307.07670v1 [cs.LG])

    [http://arxiv.org/abs/2307.07670](http://arxiv.org/abs/2307.07670)

    本研究探讨了对在线多智能体强化学习（MARL）的对抗攻击的影响，首先展示了单独进行动作污染和奖励污染攻击的局限性，然后引入了一种混合攻击策略，该策略可以高效地攻击MARL智能体，即使攻击者没有先验信息。

    

    由于多智能体强化学习（MARL）具有广泛的应用范围，了解对MARL模型的对抗攻击的影响对于安全应用该模型至关重要。出于这个目的，我们研究了对MARL的对抗攻击的影响。在考虑的设置中，存在一个外部攻击者，他可以在智能体接收到奖励之前修改奖励，或在环境接收到动作之前操纵动作。攻击者的目标是将每个智能体引导到目标策略，或在攻击者选择的某个特定奖励函数下最大化累积奖励，同时最小化对反馈和动作的操纵量。我们首先展示了只进行动作污染攻击和只进行奖励污染攻击的局限性。然后，我们介绍了一种同时进行动作污染和奖励污染的混合攻击策略。我们展示了这种混合攻击策略可以高效地攻击MARL智能体，即使攻击者没有先验信息。

    Due to the broad range of applications of multi-agent reinforcement learning (MARL), understanding the effects of adversarial attacks against MARL model is essential for the safe applications of this model. Motivated by this, we investigate the impact of adversarial attacks on MARL. In the considered setup, there is an exogenous attacker who is able to modify the rewards before the agents receive them or manipulate the actions before the environment receives them. The attacker aims to guide each agent into a target policy or maximize the cumulative rewards under some specific reward function chosen by the attacker, while minimizing the amount of manipulation on feedback and action. We first show the limitations of the action poisoning only attacks and the reward poisoning only attacks. We then introduce a mixed attack strategy with both the action poisoning and the reward poisoning. We show that the mixed attack strategy can efficiently attack MARL agents even if the attacker has no pr
    
[^39]: 具有概率策略执行不确定性的高效鲁棒增强学习

    Efficient Action Robust Reinforcement Learning with Probabilistic Policy Execution Uncertainty. (arXiv:2307.07666v1 [cs.LG])

    [http://arxiv.org/abs/2307.07666](http://arxiv.org/abs/2307.07666)

    本文研究了具有概率策略执行不确定性的行动鲁棒增强学习问题，并提出了ARRLC算法，该算法在遗憾和样本复杂度上达到了极小极大最优，实验证明其优于非鲁棒算法并且收敛更快。

    

    鲁棒增强学习旨在在不确定性面前找到优化最坏情况下性能的策略。本文关注具有概率策略执行不确定性的行动鲁棒增强学习，其中代理机器不总是按照策略指定的动作进行，而是以概率$1-\rho$执行策略指定的动作，以概率$\rho$执行替代的对抗动作。我们证明了具有概率策略执行不确定性的行动鲁棒马尔可夫决策过程存在最优策略，并提供了解决其的行动鲁棒贝尔曼最优方程。此外，我们开发了具有证书的行动鲁棒增强学习(ARRLC)算法，该算法实现了极小极大遗憾和样本复杂度最优。此外，我们进行了数值实验来验证我们的方法的鲁棒性，结果表明ARRLC优于非鲁棒增强学习算法，并且比鲁棒TD算法收敛更快。

    Robust reinforcement learning (RL) aims to find a policy that optimizes the worst-case performance in the face of uncertainties. In this paper, we focus on action robust RL with the probabilistic policy execution uncertainty, in which, instead of always carrying out the action specified by the policy, the agent will take the action specified by the policy with probability $1-\rho$ and an alternative adversarial action with probability $\rho$. We establish the existence of an optimal policy on the action robust MDPs with probabilistic policy execution uncertainty and provide the action robust Bellman optimality equation for its solution. Furthermore, we develop Action Robust Reinforcement Learning with Certificates (ARRLC) algorithm that achieves minimax optimal regret and sample complexity. Furthermore, we conduct numerical experiments to validate our approach's robustness, demonstrating that ARRLC outperforms non-robust RL algorithms and converges faster than the robust TD algorithm i
    
[^40]: MPDIoU:一种用于高效准确的边界框回归的损失函数

    MPDIoU: A Loss for Efficient and Accurate Bounding Box Regression. (arXiv:2307.07662v1 [cs.CV])

    [http://arxiv.org/abs/2307.07662](http://arxiv.org/abs/2307.07662)

    提出了一种用于高效准确的边界框回归的损失函数MPDIoU，并通过包含多个相关因素的最小点距离来比较边界框的相似性。实验结果表明，该损失函数可以提高目标检测的准确性。

    

    边界框回归在目标检测和实例分割中被广泛使用，是目标定位的重要步骤。然而，大多数现有的边界框回归损失函数无法在预测的边界框与真实边界框具有相同宽高比但宽度和高度不同的情况下进行优化。为解决上述问题，我们充分探索了水平矩形的几何特征，并提出了一种基于最小点距离的边界框相似性比较指标MPDIoU，该指标包含了现有损失函数中考虑的所有相关因素，即重叠或非重叠区域、中心点距离和宽度高度的偏差，同时简化了计算过程。在此基础上，我们提出了一种基于MPDIoU的边界框回归损失函数，称为LMPDIoU。实验结果表明，将MPDIoU损失函数应用于现有的目标检测方法中可以获得更准确的结果。

    Bounding box regression (BBR) has been widely used in object detection and instance segmentation, which is an important step in object localization. However, most of the existing loss functions for bounding box regression cannot be optimized when the predicted box has the same aspect ratio as the groundtruth box, but the width and height values are exactly different. In order to tackle the issues mentioned above, we fully explore the geometric features of horizontal rectangle and propose a novel bounding box similarity comparison metric MPDIoU based on minimum point distance, which contains all of the relevant factors considered in the existing loss functions, namely overlapping or non-overlapping area, central points distance, and deviation of width and height, while simplifying the calculation process. On this basis, we propose a bounding box regression loss function based on MPDIoU, called LMPDIoU . Experimental results show that the MPDIoU loss function is applied to state-of-the-a
    
[^41]: SALC：基于骨架辅助的学习聚类用于时变室内定位

    SALC: Skeleton-Assisted Learning-Based Clustering for Time-Varying Indoor Localization. (arXiv:2307.07650v1 [cs.LG])

    [http://arxiv.org/abs/2307.07650](http://arxiv.org/abs/2307.07650)

    SALC是一种基于骨架辅助的学习聚类定位系统，可以适应时变室内环境，提高定位准确性。

    

    近年来，无线室内定位引起了相当大的关注。使用从WiFi访问点（AP）获取的接收信号强度（RSS）建立指纹数据库是室内定位中广泛使用的方法。然而，现有文献中对室内定位系统的时变问题研究不充分。与传统的静态指纹相比，动态重建的数据库可以适应高度变化的环境，从而实现定位准确性的可持续性。为了解决时变问题，我们提出了一种基于骨架辅助学习聚类定位（SALC）系统，包括基于RSS导向的地图辅助聚类（ROMAC）、基于聚类的在线数据库建立（CODE）和基于聚类的定位估计（CsLE）。SALC方案同时考虑了基于骨架最短路径（SSP）和参考点（RPs）之间的时变RSS测量的相似性。

    Wireless indoor localization has attracted significant amount of attention in recent years. Using received signal strength (RSS) obtained from WiFi access points (APs) for establishing fingerprinting database is a widely utilized method in indoor localization. However, the time-variant problem for indoor positioning systems is not well-investigated in existing literature. Compared to conventional static fingerprinting, the dynamicallyreconstructed database can adapt to a highly-changing environment, which achieves sustainability of localization accuracy. To deal with the time-varying issue, we propose a skeleton-assisted learning-based clustering localization (SALC) system, including RSS-oriented map-assisted clustering (ROMAC), cluster-based online database establishment (CODE), and cluster-scaled location estimation (CsLE). The SALC scheme jointly considers similarities from the skeleton-based shortest path (SSP) and the time-varying RSS measurements across the reference points (RPs)
    
[^42]: 美国餐厅评论和大型语言模型中的移民美食他者化和低声望构架

    Othering and low prestige framing of immigrant cuisines in US restaurant reviews and large language models. (arXiv:2307.07645v1 [cs.CL])

    [http://arxiv.org/abs/2307.07645](http://arxiv.org/abs/2307.07645)

    通过对2.1M英语Yelp评论的餐厅进行语言分析，研究发现移民美食更容易被构架为客观和他者化，而非西方移民美食受欢迎程度更高。

    

    识别和理解对食物的隐含态度有助于减轻因食物作为文化和种族身份的标志而导致的社会偏见。对食物的刻板印象是一种微侵略，它对有害的公共话语做出了贡献，这可能反过来加深对民族群体的偏见，并对餐馆的经济结果产生负面影响。通过仔细的语言分析，我们在一项大规模研究中评估了对移民美食态度的社会理论。该研究使用了2.1M英语Yelp评论的餐厅在14个美国州的框架差异。在控制了餐厅价格和邻里种族多样性等因素后，我们发现移民美食更有可能以客观和他者化的形式进行构架，如真实性（例如，真实，传统），异国情调（例如，异国，不同）和典型性（例如，典型，通常）。但非西方移民美食（例如，印度，墨西哥）更受欢迎。

    Identifying and understanding implicit attitudes toward food can help efforts to mitigate social prejudice due to food's pervasive role as a marker of cultural and ethnic identity. Stereotypes about food are a form of microaggression that contribute to harmful public discourse that may in turn perpetuate prejudice toward ethnic groups and negatively impact economic outcomes for restaurants. Through careful linguistic analyses, we evaluate social theories about attitudes toward immigrant cuisine in a large-scale study of framing differences in 2.1M English language Yelp reviews of restaurants in 14 US states. Controlling for factors such as restaurant price and neighborhood racial diversity, we find that immigrant cuisines are more likely to be framed in objectifying and othering terms of authenticity (e.g., authentic, traditional), exoticism (e.g., exotic, different), and prototypicality (e.g., typical, usual), but that non-Western immigrant cuisines (e.g., Indian, Mexican) receive mor
    
[^43]: 不同解释: 利用分歧减少模型过度依赖

    Dissenting Explanations: Leveraging Disagreement to Reduce Model Overreliance. (arXiv:2307.07636v1 [cs.AI])

    [http://arxiv.org/abs/2307.07636](http://arxiv.org/abs/2307.07636)

    这项研究介绍了不同解释的概念，旨在通过提供伴随冲突预测的解释来减少模型过度依赖。在模型多样性设置下，这种方法可以帮助人们从不同模型的解释中获得洞察力。

    

    尽管可解释性是日益复杂的黑盒模型的一个可取特征，但现代解释方法已被证明是不一致和矛盾的。解释的语义并不总是完全理解的 - 解释在多大程度上"解释"一个决策，在多大程度上只是支持一个决策？我们能否帮助人们从伴随正确预测的解释中获得洞察力，而不是过度依赖解释所提倡的错误预测？在这个角度上，我们引入了不同的解释概念: 伴随冲突预测的解释。我们首先探讨了在模型多样性设置下不同解释的优势，其中具有相似性能的多个模型可能有不同的预测。在这种情况下，提供不同的解释可以通过调用不同模型的解释实现。通过一项试点研究，我们证明了不同解释的价值。

    While explainability is a desirable characteristic of increasingly complex black-box models, modern explanation methods have been shown to be inconsistent and contradictory. The semantics of explanations is not always fully understood - to what extent do explanations "explain" a decision and to what extent do they merely advocate for a decision? Can we help humans gain insights from explanations accompanying correct predictions and not over-rely on incorrect predictions advocated for by explanations? With this perspective in mind, we introduce the notion of dissenting explanations: conflicting predictions with accompanying explanations. We first explore the advantage of dissenting explanations in the setting of model multiplicity, where multiple models with similar performance may have different predictions. In such cases, providing dissenting explanations could be done by invoking the explanations of disagreeing models. Through a pilot study, we demonstrate that dissenting explanation
    
[^44]: 基于价值的快慢AI引导

    Value-based Fast and Slow AI Nudging. (arXiv:2307.07628v1 [cs.AI])

    [http://arxiv.org/abs/2307.07628](http://arxiv.org/abs/2307.07628)

    本文提出了一种基于价值的AI-human协作框架，通过提供决策建议引导人类的思考和行动。通过不同的引导方式，刺激人类的快速思考、慢思考或元认知。具体选择使用哪种引导方式取决于特定决策场景中的价值观。

    

    引导是一种旨在影响人们思考和行动的行为策略。在我们的日常生活中，可以找到许多引导技术，这些引导技术可以针对人类快速和无意识的思维，例如使用图像产生恐惧，或更谨慎和费力的慢思维，例如释放让我们反思选择的信息。在本文中，我们提出并讨论了一个基于价值的AI人合作框架，在这个框架中，AI系统通过提供决策建议来引导人类。基于建议何时呈现给人类，我们提出了三种不同的引导方式，分别用于刺激人类的快速思考、慢思考或元认知。决定何时以及如何使用这些引导方式的是与特定决策场景相关的价值观。价值观包括决策质量、速度、人类技能提升和学习、人类主动性以及隐私等。在同一个决策场景中可以存在多个价值观。

    Nudging is a behavioral strategy aimed at influencing people's thoughts and actions. Nudging techniques can be found in many situations in our daily lives, and these nudging techniques can targeted at human fast and unconscious thinking, e.g., by using images to generate fear or the more careful and effortful slow thinking, e.g., by releasing information that makes us reflect on our choices. In this paper, we propose and discuss a value-based AI-human collaborative framework where AI systems nudge humans by proposing decision recommendations. Three different nudging modalities, based on when recommendations are presented to the human, are intended to stimulate human fast thinking, slow thinking, or meta-cognition. Values that are relevant to a specific decision scenario are used to decide when and how to use each of these nudging modalities. Examples of values are decision quality, speed, human upskilling and learning, human agency, and privacy. Several values can be present at the sam
    
[^45]: 一个用于评估日常生活活动的对话系统：通过扎根知识提高一致性

    A Dialogue System for Assessing Activities of Daily Living: Improving Consistency with Grounded Knowledge. (arXiv:2307.07544v1 [cs.CL])

    [http://arxiv.org/abs/2307.07544](http://arxiv.org/abs/2307.07544)

    这个论文介绍了一个用于评估日常生活活动的对话系统，通过模拟评估员和参与者之间的交互，提高了评估的一致性。

    

    在医疗保健中，自我照顾能力体现在“日常生活活动（ADL）”中，ADL作为功能能力（运作能力）的衡量。功能能力不足可能导致需要个人护理和协助的恶劣生活条件。为了准确识别需要支持的人，协助计划会持续评估参与者在各个领域的功能能力。然而，当涉及多个具有不同水平的专家评估员时，评估过程可能遇到一致性问题。尤其是初学者评估员可能缺乏与参与者进行实际互动所需的必要准备。为了解决这个问题，我们开发了一个对话系统，以自然且可重现的方式模拟评估员和具有不同功能能力的个体之间的交互。对话系统由两个主要模块组成，一个用于自然语言理解（NLU），一个用于自然语言生成（NLG）。

    In healthcare, the ability to care for oneself is reflected in the "Activities of Daily Living (ADL)," which serve as a measure of functional ability (functioning). A lack of functioning may lead to poor living conditions requiring personal care and assistance. To accurately identify those in need of support, assistance programs continuously evaluate participants' functioning across various domains. However, the assessment process may encounter consistency issues when multiple assessors with varying levels of expertise are involved. Novice assessors, in particular, may lack the necessary preparation for real-world interactions with participants. To address this issue, we developed a dialogue system that simulates interactions between assessors and individuals of varying functioning in a natural and reproducible way. The dialogue system consists of two major modules, one for natural language understanding (NLU) and one for natural language generation (NLG), respectively. In order to gen
    
[^46]: 无源领域适应与时间插补的时序数据

    Source-Free Domain Adaptation with Temporal Imputation for Time Series Data. (arXiv:2307.07542v1 [eess.SP])

    [http://arxiv.org/abs/2307.07542](http://arxiv.org/abs/2307.07542)

    本文提出了一种用于时序数据的无源领域适应方法MAPU，通过随机掩蔽和时间插补的方式，捕捉源领域的时间信息并引导目标模型产生目标结果。

    

    无源领域适应（SFDA）旨在在没有访问源领域数据的情况下从已标记的源领域自适应模型到未标记的目标领域，保持源领域的隐私。尽管在视觉应用中很常见，但是在时序应用中，SFDA还很少被研究。现有的主要设计用于视觉应用的SFDA方法可能无法处理时序数据中的时间动态，从而导致自适应性能受损。为了解决这个问题，本文提出了一种简单而有效的无源领域适应的时序数据方法，即MAsk and imPUte (MAPU)。首先，为了捕捉源领域的时间信息，我们的方法对时序信号进行随机掩蔽，同时利用一种新颖的时间插补器在嵌入空间中从掩蔽版本中恢复原始信号。其次，在适应步骤中，插补器网络被利用来引导目标模型产生目标结果。

    Source-free domain adaptation (SFDA) aims to adapt a pretrained model from a labeled source domain to an unlabeled target domain without access to the source domain data, preserving source domain privacy. Despite its prevalence in visual applications, SFDA is largely unexplored in time series applications. The existing SFDA methods that are mainly designed for visual applications may fail to handle the temporal dynamics in time series, leading to impaired adaptation performance. To address this challenge, this paper presents a simple yet effective approach for source-free domain adaptation on time series data, namely MAsk and imPUte (MAPU). First, to capture temporal information of the source domain, our method performs random masking on the time series signals while leveraging a novel temporal imputer to recover the original signal from a masked version in the embedding space. Second, in the adaptation step, the imputer network is leveraged to guide the target model to produce target 
    
[^47]: 在有向无环图约束下学习多个协调代理

    Learning Multiple Coordinated Agents under Directed Acyclic Graph Constraints. (arXiv:2307.07529v1 [cs.LG])

    [http://arxiv.org/abs/2307.07529](http://arxiv.org/abs/2307.07529)

    本文提出了一种在有向无环图约束下学习多个协调代理的新方法，通过利用DAG结构，提高了学习性能，并在实际环境中的多个任务上取得了优于其他非DAG方法的结果。

    

    本文提出了一种新颖的多智能体强化学习（MARL）方法，用于在有向无环图（DAG）约束下学习多个协调代理。与现有的MARL方法不同的是，我们的方法明确利用了代理之间的DAG结构，以达到更有效的学习性能。在理论上，我们提出了一种基于合成奖励的MARL模型的新型代理值函数，并证明它作为最优值函数的下界。在计算上，我们提出了一种实际的训练算法，利用领导者代理和奖励生成和分发代理的新概念，引导分解的从属代理在具有DAG约束的环境中更好地探索参数空间。在实证上，我们利用四个DAG环境，包括Intel高产量打包和测试工厂的实际调度，对我们的方法进行了基准测试，并证明它优于其他非DAG方法。

    This paper proposes a novel multi-agent reinforcement learning (MARL) method to learn multiple coordinated agents under directed acyclic graph (DAG) constraints. Unlike existing MARL approaches, our method explicitly exploits the DAG structure between agents to achieve more effective learning performance. Theoretically, we propose a novel surrogate value function based on a MARL model with synthetic rewards (MARLM-SR) and prove that it serves as a lower bound of the optimal value function. Computationally, we propose a practical training algorithm that exploits new notion of leader agent and reward generator and distributor agent to guide the decomposed follower agents to better explore the parameter space in environments with DAG constraints. Empirically, we exploit four DAG environments including a real-world scheduling for one of Intel's high volume packaging and test factory to benchmark our methods and show it outperforms the other non-DAG approaches.
    
[^48]: PatchSorter: 一种用于对象标注的高吞吐量深度学习数字病理学工具

    PatchSorter: A High Throughput Deep Learning Digital Pathology Tool for Object Labeling. (arXiv:2307.07528v1 [q-bio.QM])

    [http://arxiv.org/abs/2307.07528](http://arxiv.org/abs/2307.07528)

    PatchSorter是一个开源的标注工具，利用深度学习和直观的网络界面，能够实现对大型数据集的高吞吐量标注，相较于无辅助标注，每秒标签数提高超过7倍，对标注准确性的影响非常小。

    

    数字病理学图像中与诊断、预后和治疗反应相关的模式的发现通常需要标注大量组织学对象。本文介绍了一个开源标注工具 PatchSorter，它将深度学习与直观的网络界面相结合。通过使用超过100,000个对象，我们展示了相较于无辅助标注，每秒标签数提高超过7倍，对标注准确性的影响非常小，从而实现了对大型数据集的高吞吐量标注。

    The discovery of patterns associated with diagnosis, prognosis, and therapy response in digital pathology images often requires intractable labeling of large quantities of histological objects. Here we release an open-source labeling tool, PatchSorter, which integrates deep learning with an intuitive web interface. Using >100,000 objects, we demonstrate a >7x improvement in labels per second over unaided labeling, with minimal impact on labeling accuracy, thus enabling high-throughput labeling of large datasets.
    
[^49]: 自主车辆轨迹预测的机器学习: 一项综合研究、挑战和未来研究方向调查

    Machine Learning for Autonomous Vehicle's Trajectory Prediction: A comprehensive survey, Challenges, and Future Research Directions. (arXiv:2307.07527v1 [cs.LG])

    [http://arxiv.org/abs/2307.07527](http://arxiv.org/abs/2307.07527)

    这项综合研究调查了自主车辆的轨迹预测方法，通过借鉴现有文献并重点关注机器学习技术，特别是深度学习和强化学习。研究总结了目前的挑战，并提出了未来研究的方向。

    

    自主车辆 (AVs) 通过代替人工驾驶员而采用先进的计算机辅助决策系统，成为一种有前景的解决方案。然而，为了能够有效地驾驶道路，AVs 必须具备类似人类驾驶员的预测驾驶能力，即预测周围交通参与者的未来行为。在自动驾驶的背景下，借鉴现有文献对轨迹预测方法进行综合评估是推进该领域和发展全面理解的关键。为了满足这一需求，我们进行了一项综合调查，重点关注AVs的轨迹预测方法，特别是深度学习和强化学习为基础的机器学习技术。我们广泛研究了与AVs轨迹预测相关的两百余项研究。本文首先介绍了车辆轨迹预测的一般问题，并提供了一系列方法来解决这个问题。接着我们讨论了目前存在的挑战，并提出了未来研究的方向。

    Autonomous Vehicles (AVs) have emerged as a promising solution by replacing human drivers with advanced computer-aided decision-making systems. However, for AVs to effectively navigate the road, they must possess the capability to predict the future behavior of nearby traffic participants, similar to the predictive driving abilities of human drivers. Building upon existing literature is crucial to advance the field and develop a comprehensive understanding of trajectory prediction methods in the context of automated driving. To address this need, we have undertaken a comprehensive review that focuses on trajectory prediction methods for AVs, with a particular emphasis on machine learning techniques including deep learning and reinforcement learning-based approaches. We have extensively examined over two hundred studies related to trajectory prediction in the context of AVs. The paper begins with an introduction to the general problem of predicting vehicle trajectories and provides an o
    
[^50]: 现在可以说机器可以思考了吗？

    Can I say, now machines can think?. (arXiv:2307.07526v1 [cs.AI])

    [http://arxiv.org/abs/2307.07526](http://arxiv.org/abs/2307.07526)

    生成型人工智能技术使得机器具备了人类化的响应能力，这促使我们重新审视了图灵的思考机器概念，并对机器的认知能力进行了评估。我们发现，尽管图灵测试是评估机器能力的关键，但智能还有其他方面，而人工智能机器展示了其中大部分方面。

    

    生成型人工智能技术在不同领域为新一代机器带来了机会。这些机器具有各种能力，例如可以生成图像、生成答案或故事，并根据用户提供的"提示"编写代码。这些机器被认为是'思考的思想'，因为它们具有生成人类化回应的能力。在这项研究中，我们分析和探究了人工智能支持的机器的能力。我们重新审视了图灵的思考机器概念，并将其与最新的技术进展进行了比较。本研究还讨论了思考机器的异议和后果，以及评估机器认知能力的可用技术。我们得出结论，图灵测试是评估机器能力的关键方面。然而，智能还有其他方面，而人工智能机器展示了其中大部分方面。

    Generative AI techniques have opened the path for new generations of machines in diverse domains. These machines have various capabilities for example, they can produce images, generate answers or stories, and write codes based on the "prompts" only provided by users. These machines are considered 'thinking minds' because they have the ability to generate human-like responses. In this study, we have analyzed and explored the capabilities of artificial intelligence-enabled machines. We have revisited on Turing's concept of thinking machines and compared it with recent technological advancements. The objections and consequences of the thinking machines are also discussed in this study, along with available techniques to evaluate machines' cognitive capabilities. We have concluded that Turing Test is a critical aspect of evaluating machines' ability. However, there are other aspects of intelligence too, and AI machines exhibit most of these aspects.
    
[^51]: 将因果关系约简为结构模型的函数

    Reducing Causality to Functions with Structural Models. (arXiv:2307.07524v1 [cs.AI])

    [http://arxiv.org/abs/2307.07524](http://arxiv.org/abs/2307.07524)

    本文提出了一种基于结构功能模型的约简定义，将因果关系定义为将因果联系起来的函数。作者使用增量压缩和对比前向推理的方法，实现了产生符合直觉的因果表达，并将该模型应用于多个因果场景。这种模型与概率理论兼容但不可约，并且经过与其他因果理论的比较，还应用于自由意志、因果解释和心理因果等问题。

    

    目前，在哲学和统计学领域，关于因果关系的精确定义仍然是一个开放的问题。我们认为，因果关系应该被定义为将因果联系起来的函数（在数学中表示）。我们提出了基于结构功能模型（SFM）的因果关系的约简定义。通过使用增量压缩和对比前向推理，SFM可以产生符合我们的直觉的因果表达，如“X导致Y”和“X是Y的原因”。我们编译了一组因果场景的数据集，并在其中使用SFM。SFM与概率理论兼容但不可约，我们还将SFM与其他因果理论进行了比较，并将其应用于自由意志、因果解释和心理因果等下游问题。

    The precise definition of causality is currently an open problem in philosophy and statistics. We believe causality should be defined as functions (in mathematics) that map causes to effects. We propose a reductive definition of causality based on Structural Functional Model (SFM). Using delta compression and contrastive forward inference, SFM can produce causal utterances like "X causes Y" and "X is the cause of Y" that match our intuitions. We compile a dataset of causal scenarios and use SFM in all of them. SFM is compatible with but not reducible to probability theory. We also compare SFM with other theories of causation and apply SFM to downstream problems like free will, causal explanation, and mental causation.
    
[^52]: PapagAI：反思性文章的自动反馈

    PapagAI:Automated Feedback for Reflective Essays. (arXiv:2307.07523v1 [cs.AI])

    [http://arxiv.org/abs/2307.07523](http://arxiv.org/abs/2307.07523)

    PapagAI是第一个基于教学理论并实现为混合AI系统的开源自动反馈工具，旨在提高学生学习成果并补充讲师的教学活动。

    

    在高等教育期间，撰写反思性实践是预备教师进行的常规练习。通常情况下，他们的讲师需要提供个别反馈，这可能是一项常规任务。本文提出了第一个基于教学理论并实现为混合AI系统的开源自动反馈工具。我们描述了组件，并讨论了我们的系统与现有最先进的生成式大型语言模型相比的优势和劣势。我们的工作的主要目标是实现学生的更好学习结果，并补充讲师的教学活动。

    Written reflective practice is a regular exercise pre-service teachers perform during their higher education. Usually, their lecturers are expected to provide individual feedback, which can be a challenging task to perform on a regular basis. In this paper, we present the first open-source automated feedback tool based on didactic theory and implemented as a hybrid AI system. We describe the components and discuss the advantages and disadvantages of our system compared to the state-of-art generative large language models. The main objective of our work is to enable better learning outcomes for students and to complement the teaching activities of lecturers.
    
[^53]: 由生成闭环人工智能引领的基础科学的未来

    The Future of Fundamental Science Led by Generative Closed-Loop Artificial Intelligence. (arXiv:2307.07522v1 [cs.AI])

    [http://arxiv.org/abs/2307.07522](http://arxiv.org/abs/2307.07522)

    生成型人工智能和大型语言模型可能为基础科学的发现提供机会，通过其自主生成假设和探索假设空间的闭环方法，加速科学发现的进程。

    

    机器学习和人工智能的最新进展，包括生成型人工智能和大型语言模型，正在颠覆技术创新、产品开发和整个社会。人工智能对技术的贡献可以通过多种途径实现，需要大量训练数据集和明确的性能评估标准，范围从模式识别和分类到生成模型。然而，由于科学实践和模型发现需要访问高质量的大型数据集，人工智能对基础科学的贡献较少。生成型人工智能，特别是大型语言模型，可能代表了通过定量模型增强和加速基础深度科学的科学发现的机会。在这里，我们探索和研究了一种由人工智能驱动、自动化的闭环科学发现方法的各个方面，包括自主生成假设和开放式自主探索假设空间。

    Recent advances in machine learning and AI, including Generative AI and LLMs, are disrupting technological innovation, product development, and society as a whole. AI's contribution to technology can come from multiple approaches that require access to large training data sets and clear performance evaluation criteria, ranging from pattern recognition and classification to generative models. Yet, AI has contributed less to fundamental science in part because large data sets of high-quality data for scientific practice and model discovery are more difficult to access. Generative AI, in general, and Large Language Models in particular, may represent an opportunity to augment and accelerate the scientific discovery of fundamental deep science with quantitative models. Here we explore and investigate aspects of an AI-driven, automated, closed-loop approach to scientific discovery, including self-driven hypothesis generation and open-ended autonomous exploration of the hypothesis space. Int
    
[^54]: CephGPT-4:一种具有视觉大语言模型的交互式多模态颅颌测量与诊断系统

    CephGPT-4: An Interactive Multimodal Cephalometric Measurement and Diagnostic System with Visual Large Language Model. (arXiv:2307.07518v1 [cs.AI])

    [http://arxiv.org/abs/2307.07518](http://arxiv.org/abs/2307.07518)

    CephGPT-4是一个具有视觉大语言模型的交互式多模态颅颌测量与诊断系统，它能够通过自动分析颅颌标志点和生成诊断报告，实现出色的性能，为正畸测量和诊断应用带来革命性的潜力。

    

    大规模多模态语言模型在一般领域取得了显著的成功。然而，在基于多模态颅颌医学数据的诊断语言模型的探索仍然有限。本文提出了一种新颖的多模态颅颌分析和诊断对话模型。首先，构建了多模态正畸医学数据集，包括颅颌影像和医患对话数据，并使用U-net自动分析颅颌标志点和生成诊断报告。然后，将颅颌数据集和生成的诊断报告分别在Minigpt-4和VisualGLM上进行微调。结果表明，CephGPT-4模型表现出优异的性能，并具有颠覆正畸测量和诊断应用的潜力。这些创新在正畸学领域具有革命性的应用潜力。

    Large-scale multimodal language models (LMMs) have achieved remarkable success in general domains. However, the exploration of diagnostic language models based on multimodal cephalometric medical data remains limited. In this paper, we propose a novel multimodal cephalometric analysis and diagnostic dialogue model. Firstly, a multimodal orthodontic medical dataset is constructed, comprising cephalometric images and doctor-patient dialogue data, with automatic analysis of cephalometric landmarks using U-net and generation of diagnostic reports. Then, the cephalometric dataset and generated diagnostic reports are separately fine-tuned on Minigpt-4 and VisualGLM. Results demonstrate that the CephGPT-4 model exhibits excellent performance and has the potential to revolutionize orthodontic measurement and diagnostic applications. These innovations hold revolutionary application potential in the field of orthodontics.
    
[^55]: 引发即实现——因果问题的解决方案

    Causing is Achieving -- A solution to the problem of causation. (arXiv:2307.07517v1 [cs.AI])

    [http://arxiv.org/abs/2307.07517](http://arxiv.org/abs/2307.07517)

    从应用本体论的角度解决因果问题，通过系统功能概念理解因果关系，将任何原因分解为实现、防止、允许和不允许四个子功能，最后三个子功能可以仅用实现来定义。因果的本质在于实现功能。

    

    从应用本体论的角度来看，最近一个挑战因果理解和建模问题的前提是因果很真实。因而获得了以下三个结果：(1)通过系统功能的概念可以理解因果；(2)任何原因都可以仅用四个子功能进行分解，即实现、防止、允许和不允许；(3)最后三个子功能可以仅用实现来定义。据此可以得出，因果的本质在于一个单一的功能，即实现。现在需要阐明实现功能的性质，在先前的工作中只部分展开了该问题。本文首先讨论了上述因果论中的几个基本原则，因为这些原则在讨论中很有帮助，然后总结了先前的研究结果，并最终揭示了实现的性质，从而全面解决了因果是什么的问题。

    From the standpoint of applied ontology, the problem of understanding and modeling causation has been recently challenged on the premise that causation is real. As a consequence, the following three results were obtained: (1) causation can be understood via the notion of systemic function; (2) any cause can be decomposed using only four subfunctions, namely Achieves, Prevents, Allows, and Disallows; and (3) the last three subfunctions can be defined in terms of Achieves alone. It follows that the essence of causation lies in a single function, namely Achieves. It remains to elucidate the nature of the Achieves function, which has been elaborated only partially in the previous work. In this paper, we first discuss a couple of underlying policies in the above-mentioned causal theory since these are useful in the discussion, then summarize the results obtained in the former paper, and finally reveal the nature of Achieves giving a complete solution to the problem of what causation is.
    
[^56]: 人工智能是算法模仿：为什么人工“代理”不是（也不会成为）真正的代理

    Artificial intelligence is algorithmic mimicry: why artificial "agents" are not (and won't be) proper agents. (arXiv:2307.07515v1 [cs.AI])

    [http://arxiv.org/abs/2307.07515](http://arxiv.org/abs/2307.07515)

    本研究通过对比生物系统和算法系统，指出了生物系统具有自我制造自主能力、符号和物理方面没有区分以及体验到模糊问题的大世界等特点，而算法系统则与此相反。

    

    这篇论文通过对比生物系统和算法系统，重点探讨“代理”概念，来探讨人工通用智能（AGI）的发展前景。作者指出了三个基本的差异：（1）生物系统具有自我制造的自主能力，能够设定自身的内在目标，而算法系统存在于一个由外部代理提供目标函数的计算环境中。（2）生物系统是具体体现的，即其符号和物理方面没有区分，而算法运行在计算结构上，最大限度地将软件与硬件隔离。（3）生物系统体验到一个庞大的世界，其中大多数问题是模糊的（并非全部可定义），而算法系统存在于一个小世界中，其中所有问题都是明确的。这三个差异说明了生物和算法系统具有非常不同的能力。

    What is the prospect of developing artificial general intelligence (AGI)? I investigate this question by systematically comparing living and algorithmic systems, with a special focus on the notion of "agency." There are three fundamental differences to consider: (1) Living systems are autopoietic, that is, self-manufacturing, and therefore able to set their own intrinsic goals, while algorithms exist in a computational environment with target functions that are both provided by an external agent. (2) Living systems are embodied in the sense that there is no separation between their symbolic and physical aspects, while algorithms run on computational architectures that maximally isolate software from hardware. (3) Living systems experience a large world, in which most problems are ill-defined (and not all definable), while algorithms exist in a small world, in which all problems are well-defined. These three differences imply that living and algorithmic systems have very different capab
    
[^57]: 解释性不是游戏。(arXiv:2307.07514v1 [cs.AI])

    Explainability is NOT a Game. (arXiv:2307.07514v1 [cs.AI])

    [http://arxiv.org/abs/2307.07514](http://arxiv.org/abs/2307.07514)

    Shapley values may provide misleading measures of relative feature importance in XAI, challenging their proposed uses in high-stakes application domains.

    

    可解释性人工智能（XAI）旨在帮助人类决策者理解复杂的机器学习（ML）模型。XAI的一个重要特征是通过使用Shapley值来理论上证明相对特征重要性的度量。本文在最近的研究基础上，提出一个简单的论证，说明Shapley值可能会给相对特征重要性提供误导，使其为预测中无关的特征分配更高的重要性，而对与预测有关的特征分配较低的重要性。这些结果的意义在于它们有效地挑战了相对特征重要性的多种提议用法，这些用法正在高风险应用领域快速增长。

    Explainable artificial intelligence (XAI) aims to help human decision-makers in understanding complex machine learning (ML) models. One of the hallmarks of XAI are measures of relative feature importance, which are theoretically justified through the use of Shapley values. This paper builds on recent work and offers a simple argument for why Shapley values can provide misleading measures of relative feature importance, by assigning more importance to features that are irrelevant for a prediction, and assigning less importance to features that are relevant for a prediction. The significance of these results is that they effectively challenge the many proposed uses of measures of relative feature importance in a fast-growing range of high-stakes application domains.
    
[^58]: 使用放射学报告和图像改善ICU死亡率预测的实证研究

    An empirical study of using radiology reports and images to improve ICU mortality prediction. (arXiv:2307.07513v1 [cs.AI])

    [http://arxiv.org/abs/2307.07513](http://arxiv.org/abs/2307.07513)

    本研究利用放射学报告和图像构建了一个基于深度学习的多模态数据生存预测模型，用于预测重症监护病房（ICU）的死亡率，并在MIMIC-IV数据集上取得了0.7829的平均C-index。

    

    背景：预测重症监护病房（ICU）的评分系统在ICU管理中起着重要作用，因为它能预测重要的结果，尤其是死亡率。许多评分系统已经在ICU中开发和使用。这些评分系统主要基于电子健康记录（EHR）中的结构化临床数据，但可能会丧失叙述和图像中的重要临床信息。方法：在这项工作中，我们利用多模态数据建立了一个基于深度学习的生存预测模型来预测ICU死亡率。我们调查了四组特征：（1）简化急性生理学评分（SAPS）II的生理测量、（2）放射专家预定义的常见胸部疾病、（3）基于BERT的文本表示和（4）胸部X射线图像特征。我们使用Medical Information Mart for Intensive Care IV（MIMIC-IV）数据集评估了提出的模型。结果：我们的模型达到了0.7829的平均C-index（95%的置信区间）

    Background: The predictive Intensive Care Unit (ICU) scoring system plays an important role in ICU management because it predicts important outcomes, especially mortality. Many scoring systems have been developed and used in the ICU. These scoring systems are primarily based on the structured clinical data in the electronic health record (EHR), which may suffer the loss of important clinical information in the narratives and images. Methods: In this work, we build a deep learning based survival prediction model with multi-modality data to predict ICU mortality. Four sets of features are investigated: (1) physiological measurements of Simplified Acute Physiology Score (SAPS) II, (2) common thorax diseases pre-defined by radiologists, (3) BERT-based text representations, and (4) chest X-ray image features. We use the Medical Information Mart for Intensive Care IV (MIMIC-IV) dataset to evaluate the proposed model. Results: Our model achieves the average C-index of 0.7829 (95% confidence i
    
[^59]: RoPDA：用于低资源命名实体识别的鲁棒基于提示的数据增强

    RoPDA: Robust Prompt-based Data Augmentation for Low-Resource Named Entity Recognition. (arXiv:2307.07417v1 [cs.CL])

    [http://arxiv.org/abs/2307.07417](http://arxiv.org/abs/2307.07417)

    RoPDA是一种用于低资源NER的数据增强方法，通过基于预训练语言模型和连续提示进行实体和上下文增强，并提出了自一致性过滤和混合技术以优化增强样本的利用。

    

    数据增强在低资源NER任务中被广泛使用以解决数据稀缺的问题。然而，先前的数据增强方法存在破坏句法结构、标记-标签不匹配和对外部知识或手动工作的需求的缺点。为了解决这些问题，我们提出了RoPDA: 一种用于低资源NER的鲁棒基于提示的数据增强方法。基于预训练语言模型（PLMs）和连续提示，RoPDA通过五个基本的增强操作进行实体增强和上下文增强，生成标签翻转和保留标签的样本。为了优化增强样本的利用，我们提出了两种技术：自一致性过滤和混合。前者有效地消除低质量样本，后者防止直接利用标签翻转样本导致性能下降。在三个基准测试中进行了大量实验...

    Data augmentation has been widely used in low-resource NER tasks to tackle the problem of data sparsity. However, previous data augmentation methods have the disadvantages of disrupted syntactic structures, token-label mismatch, and requirement for external knowledge or manual effort. To address these issues, we propose \textbf{Ro}bust \textbf{P}rompt-based \textbf{D}ata \textbf{A}ugmentation (RoPDA) for low-resource NER. Based on pre-trained language models (PLMs) with continuous prompt, RoPDA performs entity augmentation and context augmentation through five fundamental augmentation operations to generate label-flipping and label-preserving examples. To optimize the utilization of the augmented samples, we present two techniques: Self-Consistency Filtering and mixup. The former effectively eliminates low-quality samples, while the latter prevents performance degradation arising from the direct utilization of label-flipping samples. Extensive experiments on three benchmarks from diffe
    
[^60]: DataAssist:一种用于数据清洗和准备的机器学习方法

    DataAssist: A Machine Learning Approach to Data Cleaning and Preparation. (arXiv:2307.07119v1 [cs.LG])

    [http://arxiv.org/abs/2307.07119](http://arxiv.org/abs/2307.07119)

    DataAssist是一种机器学习方法，用于提高数据集质量和节省数据清洗和准备时间。

    

    目前的自动化机器学习工具主要关注于模型选择和参数优化，忽略了数据清洗和整理所占据的大部分时间。本文介绍了一种名为DataAssist的自动化数据准备和清洗平台，利用机器学习方法提高数据集质量。我们展示了DataAssist提供了一个用于探索性数据分析和数据清洗的管道，包括为用户选择的变量生成可视化，统一数据注释，提供异常值删除建议以及对数据进行预处理。导出的数据集可以轻松与其他自动化机器学习工具或用户指定的模型进行整合，以进行后续分析。我们的数据中心化工具适用于多个领域，包括经济学、商业和预测应用，可节省超过50\%的数据清理和准备时间。

    Current automated machine learning (ML) tools are model-centric, focusing on model selection and parameter optimization. However, the majority of the time in data analysis is devoted to data cleaning and wrangling, for which limited tools are available. Here we present DataAssist, an automated data preparation and cleaning platform that enhances dataset quality using ML-informed methods. We show that DataAssist provides a pipeline for exploratory data analysis and data cleaning, including generating visualization for user-selected variables, unifying data annotation, suggesting anomaly removal, and preprocessing data. The exported dataset can be readily integrated with other autoML tools or user-specified model for downstream analysis. Our data-centric tool is applicable to a variety of fields, including economics, business, and forecasting applications saving over 50\% time of the time spent on data cleansing and preparation.
    
[^61]: 视频焦点网络：用于视频动作识别的时空焦点调制

    Video-FocalNets: Spatio-Temporal Focal Modulation for Video Action Recognition. (arXiv:2307.06947v1 [cs.CV])

    [http://arxiv.org/abs/2307.06947](http://arxiv.org/abs/2307.06947)

    本论文提出了一种名为视频焦点网络的视频识别架构，通过时空焦点调制来模拟局部和全局上下文，结合了Transformer和卷积设计的优点，既有效又高效。

    

    最近的视频识别模型利用Transformer模型进行长距离时空上下文建模。视频Transformer设计基于自注意力，可以以高计算成本模拟全局上下文。相比之下，用于视频的卷积设计提供了一种高效的替代方法，但缺乏长距离依赖建模。为了实现这两种设计的最佳效果，本研究提出了视频焦点网络（Video-FocalNet），这是一种既有效又高效的视频识别架构，可以模拟局部和全局上下文。视频焦点网络基于时空焦点调制架构，对自注意力的交互和聚合步骤进行了颠倒，以提高效率。此外，聚合步骤和交互步骤都使用了高效的卷积和逐元素乘法操作来实现，其计算成本比视频表达中的自注意力对应部分要低得多。我们广泛探索了焦点调制的设计空间。

    Recent video recognition models utilize Transformer models for long-range spatio-temporal context modeling. Video transformer designs are based on self-attention that can model global context at a high computational cost. In comparison, convolutional designs for videos offer an efficient alternative but lack long-range dependency modeling. Towards achieving the best of both designs, this work proposes Video-FocalNet, an effective and efficient architecture for video recognition that models both local and global contexts. Video-FocalNet is based on a spatio-temporal focal modulation architecture that reverses the interaction and aggregation steps of self-attention for better efficiency. Further, the aggregation step and the interaction step are both implemented using efficient convolution and element-wise multiplication operations that are computationally less expensive than their self-attention counterparts on video representations. We extensively explore the design space of focal modu
    
[^62]: Rad-ReStruct: 一种新颖的结构化放射学报告的VQA基准和方法

    Rad-ReStruct: A Novel VQA Benchmark and Method for Structured Radiology Reporting. (arXiv:2307.05766v1 [cs.CV])

    [http://arxiv.org/abs/2307.05766](http://arxiv.org/abs/2307.05766)

    本文提出了Rad-ReStruct，一个用于评估和比较不同方法的新型基准数据集，以X光图像的结构化报告形式提供了细粒度、按层次排序的注释。我们提出了一种新方法hi-VQA，将结构化报告任务建模为分层视觉问答(VQA)，并考虑先前提问和回答的上下文来填充结构化放射学报告。实验证明hi-VQA取得了与最先进方法相竞争的性能。

    

    放射学报告是放射科医生与其他医务人员之间沟通的重要部分，但其可能耗时且容易出错。其中一种减轻这种情况的方法是结构化报告，它比自由文本报告更节约时间并且能够实现更精确的评估。然而，关于自动化结构化报告的研究有限，并且目前没有公开的基准用于评估和比较不同方法。为了弥补这一空白，我们介绍了Rad-ReStruct，这是一个新的基准数据集，提供了细粒度的、按层次排序的X光图像的结构化报告形式的注释。我们将结构化报告任务建模为分层视觉问答(VQA)，并提出了hi-VQA，一种考虑先前提问和回答的上下文以填充结构化放射学报告的新方法。我们的实验证明hi-VQA在医学VQA基准测试中取得了与最先进方法相竞争的性能。

    Radiology reporting is a crucial part of the communication between radiologists and other medical professionals, but it can be time-consuming and error-prone. One approach to alleviate this is structured reporting, which saves time and enables a more accurate evaluation than free-text reports. However, there is limited research on automating structured reporting, and no public benchmark is available for evaluating and comparing different methods. To close this gap, we introduce Rad-ReStruct, a new benchmark dataset that provides fine-grained, hierarchically ordered annotations in the form of structured reports for X-Ray images. We model the structured reporting task as hierarchical visual question answering (VQA) and propose hi-VQA, a novel method that considers prior context in the form of previously asked questions and answers for populating a structured radiology report. Our experiments show that hi-VQA achieves competitive performance to the state-of-the-art on the medical VQA benc
    
[^63]: 通过xAI和主动学习的人在AI循环中进行视觉检查

    Human in the AI loop via xAI and Active Learning for Visual Inspection. (arXiv:2307.05508v1 [cs.HC])

    [http://arxiv.org/abs/2307.05508](http://arxiv.org/abs/2307.05508)

    通过xAI和主动学习的人在AI循环中进行视觉检查的论文探讨了工业 5.0 中人机协作的新机会，并分享了关于视觉检查中的人工智能、人类数字孪生和网络安全的最新研究成果。

    

    工业革命通过引入自动化来改变制造业，增加的自动化改变了人工工人的角色。机器人和人工智能的进步开辟了人机协作的新领域。本章首先描述了工业5.0，人机协作以及关于质量检查的最新技术，重点是视觉检查。然后，我们提供了关于如何在视觉检查中实现和增强人机协作的观点。最后，我们分享了在欧盟H2020 STAR项目中关于视觉检查的一些结果，考虑了人工智能，人类数字孪生和网络安全。

    Industrial revolutions have historically disrupted manufacturing by introducing automation into production. Increasing automation reshapes the role of the human worker. Advances in robotics and artificial intelligence open new frontiers of human-machine collaboration. In this chapter, we first describe Industry 5.0, human-machine collaboration, and state-of-the-art regarding quality inspection, emphasizing visual inspection. We then provide our perspective on how human-machine collaboration could be realized and enhanced in visual inspection. Finally, we share some of the results obtained in the EU H2020 STAR project regarding visual inspection, considering artificial intelligence, human digital twins, and cybersecurity.
    
[^64]: 揭开巨人的真面目：对ChatGPT在编码算法和数据结构方面的熟练程度进行全面评估

    Unmasking the giant: A comprehensive evaluation of ChatGPT's proficiency in coding algorithms and data structures. (arXiv:2307.05360v1 [cs.SE])

    [http://arxiv.org/abs/2307.05360](http://arxiv.org/abs/2307.05360)

    本文全面评估了ChatGPT在编码算法和数据结构方面的能力，基于最大的编码挑战目录，重点关注Python编程语言和数据结构算法两个基础主题。总结测试中ChatGPT的代码解决问题的准确性、代码质量和运行时错误的性质。

    

    大型语言模型(LLMs)的转变性影响深刻地重塑了人工智能(AI)技术领域。值得注意的是，ChatGPT在这些模型中有着独特之处，展示出卓越的多轮对话性能，并在多种语言中展示出对编码的熟练程度。在本文中，我们根据迄今为止最大的编码挑战目录对ChatGPT的编码能力进行了全面评估。我们的重点是Python编程语言，以及集中在数据结构和算法上的问题，这两个主题是计算机科学的基础。我们评估ChatGPT解决所提交问题的能力，评估其代码质量以及代码引发的运行时错误的性质。当ChatGPT的代码成功执行但未能解决手头问题时，我们会研究通过的测试案例中的模式，以了解ChatGPT代码中的错误之处。

    The transformative influence of Large Language Models (LLMs) is profoundly reshaping the Artificial Intelligence (AI) technology domain. Notably, ChatGPT distinguishes itself within these models, demonstrating remarkable performance in multi-turn conversations and exhibiting code proficiency across an array of languages. In this paper, we carry out a comprehensive evaluation of ChatGPT's coding capabilities based on what is to date the largest catalog of coding challenges. Our focus is on the python programming language and problems centered on data structures and algorithms, two topics at the very foundations of Computer Science. We evaluate ChatGPT for its ability to generate correct solutions to the problems fed to it, its code quality, and nature of run-time errors thrown by its code. Where ChatGPT code successfully executes, but fails to solve the problem at hand, we look into patterns in the test cases passed in order to gain some insights into how wrong ChatGPT code is in these 
    
[^65]: 使用双调节器解决联邦半监督学习中的数据不平衡问题

    Combating Data Imbalances in Federated Semi-supervised Learning with Dual Regulators. (arXiv:2307.05358v1 [cs.LG])

    [http://arxiv.org/abs/2307.05358](http://arxiv.org/abs/2307.05358)

    本文提出了一种带有双调节器的新型联邦半监督学习框架FedDure，解决了数据分布不平衡的问题。通过粗调节器和细调节器对本地模型的更新进行规范，以及学习适应性加权方案，适应不同的数据分布。

    

    联邦学习已经成为一种从分散异构数据中学习的流行方法。由于分散客户端上标签稀缺，联邦半监督学习（FSSL）出现以从少量标记数据中训练模型。现有的FSSL方法假设客户端之间的标签数据独立且具有相同分布，并且在客户端内部标记和未标记数据之间具有一致的类别分布。本文研究了FSSL的更实际和具有挑战性的情况，即数据分布不仅在客户端之间不同，在客户端内部标记和未标记数据之间也不同。为了解决这个挑战，本文提出了一种带有双调节器的新型FSSL框架，FedDure。FedDure通过粗调节器（C-reg）和细调节器（F-reg）解除了以前的假设：C-reg通过跟踪标记数据分布的学习效果来规范本地模型的更新；F-reg学习一个适应性加权方案，以适应客户端内不同的数据分布。

    Federated learning has become a popular method to learn from decentralized heterogeneous data. Federated semi-supervised learning (FSSL) emerges to train models from a small fraction of labeled data due to label scarcity on decentralized clients. Existing FSSL methods assume independent and identically distributed (IID) labeled data across clients and consistent class distribution between labeled and unlabeled data within a client. This work studies a more practical and challenging scenario of FSSL, where data distribution is different not only across clients but also within a client between labeled and unlabeled data. To address this challenge, we propose a novel FSSL framework with dual regulators, FedDure.} FedDure lifts the previous assumption with a coarse-grained regulator (C-reg) and a fine-grained regulator (F-reg): C-reg regularizes the updating of the local model by tracking the learning effect on labeled data distribution; F-reg learns an adaptive weighting scheme tailored f
    
[^66]: ECS -- 用于数据质量保证的交互工具

    ECS -- an Interactive Tool for Data Quality Assurance. (arXiv:2307.04368v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.04368](http://arxiv.org/abs/2307.04368)

    本文提出了一种交互工具ECS，用于保证数据质量。该工具能够检测出在安全关键系统中具有潜在危害属性的数据点。

    

    随着机器学习系统的能力不断增强及其在安全关键系统中的潜在应用，确保高质量的数据变得越来越重要。本文提出了一种新颖的数据质量保证方法。首先讨论了数学基础，然后通过多个示例介绍了这种方法。该方法能够检测出在安全关键系统中具有潜在危害属性的数据点。

    With the increasing capabilities of machine learning systems and their potential use in safety-critical systems, ensuring high-quality data is becoming increasingly important. In this paper we present a novel approach for the assurance of data quality. For this purpose, the mathematical basics are first discussed and the approach is presented using multiple examples. This results in the detection of data points with potentially harmful properties for the use in safety-critical systems.
    
[^67]: ChatGPT在生成式AI和大语言模型时代的应用：一份简洁的调查报告

    ChatGPT in the Age of Generative AI and Large Language Models: A Concise Survey. (arXiv:2307.04251v1 [cs.CL])

    [http://arxiv.org/abs/2307.04251](http://arxiv.org/abs/2307.04251)

    ChatGPT是由OpenAI创建的一种大型语言模型（LLM），它在自然语言处理（NLP）领域引起了革命性的变革。它是第一个实现公众大规模与生成式人工智能（GAI）互动的关键技术，也引发了类似技术的研究兴趣和应用探索。

    

    ChatGPT是由OpenAI创建的一种大型语言模型（LLM），经过精心训练并使用了大量数据。它在自然语言处理（NLP）领域引起了革命性的变革，并推动了LLM能力的边界。ChatGPT在大规模范围内实现了普遍公众与生成式人工智能（GAI）的互动，起到了关键作用。它还引发了开发类似技术和研究其应用和影响的兴趣。本文的主要目标是对ChatGPT及其演化的当前研究方向进行简明调查。我们同时考虑了ChatGPT的玻璃盒和黑盒视角，包括技术的组成部分和基本要素，以及其应用、影响和影响。玻璃盒方法着重于理解技术的内部运作，而黑盒方法将其视为一个复杂系统，因此研究其输入，

    ChatGPT is a large language model (LLM) created by OpenAI that has been carefully trained on a large amount of data. It has revolutionized the field of natural language processing (NLP) and has pushed the boundaries of LLM capabilities. ChatGPT has played a pivotal role in enabling widespread public interaction with generative artificial intelligence (GAI) on a large scale. It has also sparked research interest in developing similar technologies and investigating their applications and implications. In this paper, our primary goal is to provide a concise survey on the current lines of research on ChatGPT and its evolution. We considered both the glass box and black box views of ChatGPT, encompassing the components and foundational elements of the technology, as well as its applications, impacts, and implications. The glass box approach focuses on understanding the inner workings of the technology, and the black box approach embraces it as a complex system, and thus examines its inputs,
    
[^68]: 在发展有效的人工智能与人类团队协作中应用以人为中心的人工智能：以人工智能-人类共同认知系统的视角

    Applying human-centered AI in developing effective human-AI teaming: A perspective of human-AI joint cognitive systems. (arXiv:2307.03913v1 [cs.AI])

    [http://arxiv.org/abs/2307.03913](http://arxiv.org/abs/2307.03913)

    本研究介绍了将人工智能与人类团队协作作为一种新的发展范式的方法，强调有效的人工智能与人类团队需要充分利用双方的独特能力，同时克服挑战和限制，提高联合表现。同时，该研究指出现有研究往往未考虑到动态、适应性和协作团队环境中人工智能的功能，呼吁加强关于人工智能与人类团队协作的研究。

    

    研究和应用已将人工智能与人类团队协作作为一种新的范式来发展人工智能系统。人工智能与人类团队协作认识到人工智能将作为一名队友而不仅仅是工具与人类协作。有效的人工智能与人类团队需要能够充分利用人类和人工智能的独特能力，同时克服每个成员的已知挑战和限制，增强人类能力，并将联合性能提高到任何实体之上。2023年全国人工智能研究和战略计划更新认识到，主要关注人工智能系统独立性能的研究计划往往未考虑到人工智能在动态、适应性和协作团队环境中必须提供的功能，并呼吁进一步研究人工智能与人类团队协作。然而，人们对于人工智能是否能作为人类的队友存在争议。主要的关注点在于采用"协作"范式是否与人类的认知过程相矛盾。

    Research and application have used human-AI teaming (HAT) as a new paradigm to develop AI systems. HAT recognizes that AI will function as a teammate instead of simply a tool in collaboration with humans. Effective human-AI teams need to be capable of taking advantage of the unique abilities of both humans and AI while overcoming the known challenges and limitations of each member, augmenting human capabilities, and raising joint performance beyond that of either entity. The National AI Research and Strategic Plan 2023 update has recognized that research programs focusing primarily on the independent performance of AI systems generally fail to consider the functionality that AI must provide within the context of dynamic, adaptive, and collaborative teams and calls for further research on human-AI teaming and collaboration. However, there has been debate about whether AI can work as a teammate with humans. The primary concern is that adopting the "teaming" paradigm contradicts the human
    
[^69]: 一种可解释的模型以支持AML治疗方案的决策

    An explainable model to support the decision about the therapy protocol for AML. (arXiv:2307.02631v1 [cs.LG])

    [http://arxiv.org/abs/2307.02631](http://arxiv.org/abs/2307.02631)

    本文提出了一种可解释的机器学习模型，用于支持AML患者治疗方案的决策，解决了当前风险分类存在的问题和专家需求额外测试和分析的困扰。

    

    急性髓细胞白血病（AML）是一种最具侵略性的血液肿瘤。为了支持专家关于合适治疗的决策，AML患者根据其细胞遗传和分子特征获得预后信息，通常分为有利、中等和不利三个风险类别。然而，当前的风险分类存在已知问题，如同一风险组中患者之间的异质性和中风险类别的清晰定义缺失。此外，由于大多数AML患者被归为中风险分类，专家常需进行其他测试和分析，导致治疗延迟和患者临床状况恶化。本文提出了数据分析和一种可解释的机器学习模型，以支持根据患者生存预测确定最合适的治疗方案的决策。

    Acute Myeloid Leukemia (AML) is one of the most aggressive types of hematological neoplasm. To support the specialists' decision about the appropriate therapy, patients with AML receive a prognostic of outcomes according to their cytogenetic and molecular characteristics, often divided into three risk categories: favorable, intermediate, and adverse. However, the current risk classification has known problems, such as the heterogeneity between patients of the same risk group and no clear definition of the intermediate risk category. Moreover, as most patients with AML receive an intermediate-risk classification, specialists often demand other tests and analyses, leading to delayed treatment and worsening of the patient's clinical condition. This paper presents the data analysis and an explainable machine-learning model to support the decision about the most appropriate therapy protocol according to the patient's survival prediction. In addition to the prediction model being explainable
    
[^70]: 使用Transformer模型预测表情符号

    Emoji Prediction using Transformer Models. (arXiv:2307.02054v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.02054](http://arxiv.org/abs/2307.02054)

    使用基于Transformer的方法，在大型语料库上微调BERT模型以预测给定文本的表情符号。实验结果显示，该方法在预测准确率上优于其他最先进的模型，具有潜在的自然语言处理和社交媒体营销应用价值。

    

    近年来，社交媒体中使用表情符号的频率大幅增加，使得它们成为了理解在线沟通的重要元素。然而，由于其含糊的特性，预测给定文本中表情符号的含义是一项具有挑战性的任务。在本研究中，我们提出了一种基于Transformer的方法来使用BERT进行表情符号预测，BERT是一种广泛使用的预训练语言模型。我们在一个包含文本和表情符号的大型语料库上对BERT进行微调，以预测给定文本的最合适的表情符号。我们的实验结果表明，我们的方法在预测表情符号方面的准确率超过了75％，优于几种最先进的模型。该研究在自然语言处理、情感分析和社交媒体营销方面具有潜在的应用前景。

    In recent years, the use of emojis in social media has increased dramatically, making them an important element in understanding online communication. However, predicting the meaning of emojis in a given text is a challenging task due to their ambiguous nature. In this study, we propose a transformer-based approach for emoji prediction using BERT, a widely-used pre-trained language model. We fine-tuned BERT on a large corpus of text containing both text and emojis to predict the most appropriate emoji for a given text. Our experimental results demonstrate that our approach outperforms several state-of-the-art models in predicting emojis with an accuracy of over 75 percent. This work has potential applications in natural language processing, sentiment analysis, and social media marketing.
    
[^71]: InstructEval: 系统评估指令选择方法

    InstructEval: Systematic Evaluation of Instruction Selection Methods. (arXiv:2307.00259v1 [cs.CL])

    [http://arxiv.org/abs/2307.00259](http://arxiv.org/abs/2307.00259)

    InstructEval开发了一个评估套件，用于对指令选择方法进行全面评估。通过使用策划的手动编写的指令，可以显著提高性能。

    

    上下文学习 (ICL) 通过使用指令和一小组注释示例来提示一个大型语言模型 (LLM) 来执行任务。最近的工作表明，提示中使用的输入的细节对 ICL 有着重要影响，这激励了指令选择算法的发展。然而，指令选择的影响尚未得到深入探索，现有的分析仅限于模型和任务的浅层子集，这限制了洞察力的普适性。我们开发了一个 ICL 评估套件，以对这些技术进行全面评估。该套件包括来自4个不同模型家族的13个开源LLM，涵盖9个不同的任务，代表了3个分类中各种类型的任务。在本研究中，我们使用我们的基准测试评估了7种受欢迎的指令选择方法相对于ICL相关的五项期望性能。我们发现使用策划的手动编写的指令可以显著地提高性能。

    In-context learning (ICL) performs tasks by prompting a large language model (LLM) using an instruction and a small set of annotated examples called demonstrations. Recent work has shown that the precise details of the inputs used in the prompt significantly impacts ICL, which has incentivized instruction selection algorithms. The effect of instruction-choice however is severely underexplored, with existing analyses being restricted to shallow subsets of models and tasks, which limits the generalizability of their insights. We develop an ICL evaluation suite to conduct a thorough assessment of these techniques. The suite includes 13 open-sourced LLMs of varying scales from 4 distinct model families and covers 9 different tasks, representing a range of task types across 3 categories. In this work, we evaluate the relative performance of 7 popular instruction selection methods using our benchmark over five desiderata relevant to ICL. We discover that using curated manually-written instru
    
[^72]: 从合成的人类团队活动中学习

    Learning from Synthetic Human Group Activities. (arXiv:2306.16772v1 [cs.CV])

    [http://arxiv.org/abs/2306.16772](http://arxiv.org/abs/2306.16772)

    提出了M3Act，一个多视图多团队多人的人类原子动作和团队活动数据生成器，通过Unity引擎驱动实现。该生成器具有大规模数据生成、多模态和高质量注释等特点，能够用于研究复杂的人类互动和团队活动。

    

    在以人为中心的计算机视觉中，对复杂的人类互动和团队活动的理解引起了人们的关注。然而，相关任务的进展受到了获取大规模标记的真实世界数据集的困难的限制。为了缓解这个问题，我们提出了M3Act，一个多视图多团队多人的人类原子动作和团队活动数据生成器。M3Act采用Unity引擎驱动，包含可供仿真使用的三维场景和人物资源，可配置的照明和摄像系统，高度参数化的模块化团队活动，以及在数据生成过程中具有大量领域随机化的特点。我们的数据生成器能够生成具有多个视图、模态（RGB图像、2D姿势、3D动作）和高质量注释的大规模人类活动数据集（2D边界框、实例分割掩模、个体动作和团队活动类别）。利用M3Act，我们可以生成大规模的人类活动数据集，用于研究人类互动和团队活动。

    The understanding of complex human interactions and group activities has garnered attention in human-centric computer vision. However, the advancement of the related tasks is hindered due to the difficulty of obtaining large-scale labeled real-world datasets. To mitigate the issue, we propose M3Act, a multi-view multi-group multi-person human atomic action and group activity data generator. Powered by the Unity engine, M3Act contains simulation-ready 3D scenes and human assets, configurable lighting and camera systems, highly parameterized modular group activities, and a large degree of domain randomization during the data generation process. Our data generator is capable of generating large-scale datasets of human activities with multiple viewpoints, modalities (RGB images, 2D poses, 3D motions), and high-quality annotations for individual persons and multi-person groups (2D bounding boxes, instance segmentation masks, individual actions and group activity categories). Using M3Act, we
    
[^73]: 良好的解释者暗地里是人类-主动学习者吗？

    Are Good Explainers Secretly Human-in-the-Loop Active Learners?. (arXiv:2306.13935v1 [cs.AI])

    [http://arxiv.org/abs/2306.13935](http://arxiv.org/abs/2306.13935)

    本文提出了一种可解释的AI技术，用于获取额外的训练数据，同时考虑到人类的介入，这可以通过模拟来评估其效用，同时具有与标准主动学习算法的可比性。

    

    可解释的人工智能（XAI）技术近年来在多个用例中变得流行。在这里，我们考虑了它在研究模型预测以收集额外训练数据方面的应用。我们认为这相当于主动学习，其中查询策略涉及人类的介入。我们提供了一个人类角色的数学近似，并提出了一个端到端工作流的通用形式化。这使我们能够严格比较此用法与标准主动学习算法，同时允许扩展工作流。一个额外的好处是，它们的效用可以通过模拟来评估，而不是进行昂贵的用户研究。我们还提出了一些初步的有前途的结果。

    Explainable AI (XAI) techniques have become popular for multiple use-cases in the past few years. Here we consider its use in studying model predictions to gather additional training data. We argue that this is equivalent to Active Learning, where the query strategy involves a human-in-the-loop. We provide a mathematical approximation for the role of the human, and present a general formalization of the end-to-end workflow. This enables us to rigorously compare this use with standard Active Learning algorithms, while allowing for extensions to the workflow. An added benefit is that their utility can be assessed via simulation instead of conducting expensive user-studies. We also present some initial promising results.
    
[^74]: DoubleAdapt：一种用于股票趋势预测的增量学习元学习方法

    DoubleAdapt: A Meta-learning Approach to Incremental Learning for Stock Trend Forecasting. (arXiv:2306.09862v1 [q-fin.ST])

    [http://arxiv.org/abs/2306.09862](http://arxiv.org/abs/2306.09862)

    DoubleAdapt是一个增量学习的方法，用于股票趋势预测。它利用元学习技术自动学习如何将股票数据适应到本地平稳分布空间中，从而有效地适应数据和模型，减轻分布漂移的影响。

    

    股票趋势预测是量化投资的基本任务之一，准确预测价格趋势是不可或缺的。作为一项在线服务，股票数据随时随地持续到达。使用最新数据对预测模型进行增量更新是实用而高效的，因为这些新数据可能揭示了未来股票市场中会重复出现的一些新模式。然而，由于分布漂移（即概念漂移）的挑战，股票趋势预测的增量学习仍然没有得到充分探索。随着股票市场动态演变，未来数据的分布可能会与增量数据稍微或显着地不同，从而阻碍增量更新的有效性。为了解决这一挑战，我们提出了一个利用两个适配器的端到端框架——DoubleAdapt，可以有效地适应数据和模型，以减轻分布漂移的影响。我们的关键洞察力是利用元学习技术自动学习如何将股票数据适应到本地平稳分布空间中。

    Stock trend forecasting is a fundamental task of quantitative investment where precise predictions of price trends are indispensable. As an online service, stock data continuously arrive over time. It is practical and efficient to incrementally update the forecast model with the latest data which may reveal some new patterns recurring in the future stock market. However, incremental learning for stock trend forecasting still remains under-explored due to the challenge of distribution shifts (a.k.a. concept drifts). With the stock market dynamically evolving, the distribution of future data can slightly or significantly differ from incremental data, hindering the effectiveness of incremental updates. To address this challenge, we propose DoubleAdapt, an end-to-end framework with two adapters, which can effectively adapt the data and the model to mitigate the effects of distribution shifts. Our key insight is to automatically learn how to adapt stock data into a locally stationary distri
    
[^75]: 剪枝方式提高可靠策略：一种多目标深度Q学习方法应用于重症护理

    Pruning the Way to Reliable Policies: A Multi-Objective Deep Q-Learning Approach to Critical Care. (arXiv:2306.08044v1 [cs.LG])

    [http://arxiv.org/abs/2306.08044](http://arxiv.org/abs/2306.08044)

    该论文介绍了一种深度Q学习方法，通过剪枝动作集来实现将中间生物标志物信号整合到奖励规范中，提高了重症护理策略的可靠性。

    

    大多数医疗决策具有连续性，因此，强化学习可能有望制定精确的数据驱动治疗计划。然而，该领域的主要挑战之一是主要基于死亡率的奖励函数的稀疏性，导致离线估计的稳定性降低。本研究引入了一种深度Q学习方法，能够获得更可靠的重症护理策略。该方法将相关但嘈杂的中间生物标志物信号整合到奖励规范中，同时不会损害感兴趣的主要结果（例如患者生存率）的优化。通过根据所有可用奖励对动作集进行剪枝，然后基于稀疏主要奖励，使用受限动作集进行最终模型训练，通过解离准确和近似奖励来最小化主要目标的潜在扭曲，实现了上述目标。

    Most medical treatment decisions are sequential in nature. Hence, there is substantial hope that reinforcement learning may make it possible to formulate precise data-driven treatment plans. However, a key challenge for most applications in this field is the sparse nature of primarily mortality-based reward functions, leading to decreased stability of offline estimates. In this work, we introduce a deep Q-learning approach able to obtain more reliable critical care policies. This method integrates relevant but noisy intermediate biomarker signals into the reward specification, without compromising the optimization of the main outcome of interest (e.g. patient survival). We achieve this by first pruning the action set based on all available rewards, and second training a final model based on the sparse main reward but with a restricted action set. By disentangling accurate and approximated rewards through action pruning, potential distortions of the main objective are minimized, all whi
    
[^76]: 用贝叶斯推理模拟人类类人概念学习

    Modeling Human-like Concept Learning with Bayesian Inference over Natural Language. (arXiv:2306.02797v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02797](http://arxiv.org/abs/2306.02797)

    该论文通过在自然语言中进行贝叶斯推理来模拟人类类人概念学习，使用大型语言模型作为提议分布并拟合先验以更好地模拟人类学习者，并在生成性和逻辑性概念上进行实验评估。

    

    我们通过在自然语言中进行贝叶斯推理来模拟对抽象符号概念的学习。为了高效推理，我们使用一个大型语言模型作为提议分布。我们根据人类数据拟合先验以更好地模拟人类学习者，并在生成性和逻辑性概念上进行评估。

    We model learning of abstract symbolic concepts by performing Bayesian inference over utterances in natural language. For efficient inference, we use a large language model as a proposal distribution. We fit a prior to human data to better model human learners, and evaluate on both generative and logical concepts.
    
[^77]: 通过反事实路径几何导航解释性多元宇宙

    Navigating Explanatory Multiverse Through Counterfactual Path Geometry. (arXiv:2306.02786v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.02786](http://arxiv.org/abs/2306.02786)

    该论文提出了解释性多元宇宙的概念，用于导航和比较所有可能的反事实路径的几何关系。

    

    反事实解释是解释（不透明的）预测模型决策的事实标准。其生成往往受到算法和特定领域约束的影响，如基于密度的可行性和属性的（不）可变性或变化的方向性，旨在最大化其在现实生活中的实用性。除了对反事实实例本身的要求之外，已知算法可行性路径与事实数据点之间的连接，即算法可诉求，已成为重要的技术考虑因素。尽管这两个要求确保了旅程的步骤和目的地的合理性，但目前的文献忽略了这种反事实路径的多样性。为了解决这个缺点，我们引入了一种新颖的解释性多元宇宙概念，涵盖了所有可能的反事实旅程；然后展示了如何导航、推理和比较这些轨迹的几何关系。

    Counterfactual explanations are the de facto standard when tasked with interpreting decisions of (opaque) predictive models. Their generation is often subject to algorithmic and domain-specific constraints -- such as density-based feasibility and attribute (im)mutability or directionality of change -- that aim to maximise their real-life utility. In addition to desiderata with respect to the counterfactual instance itself, existence of a viable path connecting it with the factual data point, known as algorithmic recourse, has become an important technical consideration. While both of these requirements ensure that the steps of the journey as well as its destination are admissible, current literature neglects the multiplicity of such counterfactual paths. To address this shortcoming we introduce the novel concept of explanatory multiverse that encompasses all the possible counterfactual journeys; we then show how to navigate, reason about and compare the geometry of these trajectories -
    
[^78]: 交通理解的情境推理研究

    A Study of Situational Reasoning for Traffic Understanding. (arXiv:2306.02520v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2306.02520](http://arxiv.org/abs/2306.02520)

    本研究提出了三个新的基于文本的交通领域情境推理任务，旨在评估语言模型在情境决策、事件因果关系推理和解决人类驾驶考试方面的能力。研究采用了四种知识增强方法，具有潜力在不同语言推理任务中实现模型的泛化能力。

    

    智能交通监控(ITMo)技术有潜力改善道路安全/安全性，实现智能城市基础设施。了解交通情况需要将感知信息与领域特定和因果常识知识复杂融合。尽管之前的工作已经为交通监控提供了基准和方法，但模型能否有效地对齐这些信息来源并在新场景中推理仍不清楚。为了解决这种评估差距，我们设计了三个用于交通领域情境推理的新型文本任务：i) BDD-QA，评估语言模型(LMs)执行情境决策的能力，ii) TV-QA，评估LMs推理复杂事件因果关系的能力，iii) HDT-QA，评估模型解决人类驾驶考试的能力。我们采用了之前工作中已经显示出语言推理任务通用性的四种知识增强方法。

    Intelligent Traffic Monitoring (ITMo) technologies hold the potential for improving road safety/security and for enabling smart city infrastructure. Understanding traffic situations requires a complex fusion of perceptual information with domain-specific and causal commonsense knowledge. Whereas prior work has provided benchmarks and methods for traffic monitoring, it remains unclear whether models can effectively align these information sources and reason in novel scenarios. To address this assessment gap, we devise three novel text-based tasks for situational reasoning in the traffic domain: i) BDD-QA, which evaluates the ability of Language Models (LMs) to perform situational decision-making, ii) TV-QA, which assesses LMs' abilities to reason about complex event causality, and iii) HDT-QA, which evaluates the ability of models to solve human driving exams. We adopt four knowledge-enhanced methods that have shown generalization capability across language reasoning tasks in prior work
    
[^79]: 不容易出错的快速矩阵乘法:基于约束编程的解法

    Fast Matrix Multiplication Without Tears: A Constraint Programming Approach. (arXiv:2306.01097v1 [cs.AI])

    [http://arxiv.org/abs/2306.01097](http://arxiv.org/abs/2306.01097)

    本文提出了一种基于约束编程的方法，以寻找快速矩阵乘法的非交换算法或提供不可行性证明。我们通过打破对称性的约束条件和有效的不等式约束来修剪搜索空间，可以在合理的时间内找到已知的最佳算法或改进的算法。

    

    已知将一个 $N \times M$ 矩阵与一个 $M \times P$ 的矩阵相乘时，可以使用少于朴素 $NMP$ 方法建议的乘法次数。其中最著名的是 Strassen 算法，可将两个 $2\times 2$ 的矩阵相乘，只需 7 次而非 8 次乘法。这引出了快速矩阵乘法的约束满足问题，其中必须选择一组 $R <NMP$ 乘法项，并将它们组合以满足输出矩阵的正确性约束。本文提出了一种简单而新颖的基于约束编程的方法，以寻找快速矩阵乘法的非交换算法或提供不可行性证明。我们提出了一组打破对称性的约束条件和有效的不等式约束来修剪搜索空间，并减少要检查的解决方案数量。我们的实验表明，在合理的时间内，我们的方法可以找到已知的最佳算法或改进的算法，适用于测试的所有矩阵大小，最大为 $768 \times 768$。

    It is known that the multiplication of an $N \times M$ matrix with an $M \times P$ matrix can be performed using fewer multiplications than what the naive $NMP$ approach suggests. The most famous instance of this is Strassen's algorithm for multiplying two $2\times 2$ matrices in 7 instead of 8 multiplications. This gives rise to the constraint satisfaction problem of fast matrix multiplication, where a set of $R < NMP$ multiplication terms must be chosen and combined such that they satisfy correctness constraints on the output matrix. Despite its highly combinatorial nature, this problem has not been exhaustively examined from that perspective, as evidenced for example by the recent deep reinforcement learning approach of AlphaTensor. In this work, we propose a simple yet novel Constraint Programming approach to find non-commutative algorithms for fast matrix multiplication or provide proof of infeasibility otherwise. We propose a set of symmetry-breaking constraints and valid inequal
    
[^80]: 面向变化环境的公平解缠在线学习

    Towards Fair Disentangled Online Learning for Changing Environments. (arXiv:2306.01007v1 [cs.LG])

    [http://arxiv.org/abs/2306.01007](http://arxiv.org/abs/2306.01007)

    本论文提出了一种面向变化环境的在线学习算法，该算法通过将模型参数划分为环境不变部分和环境特定部分，从而实现了数据公平性。通过大量的实验，证明了该算法的有效性。

    

    在面对变化环境的在线学习问题中，数据按时间顺序一个接一个地接收，并且它们的分布假设可能经常变化。虽然现有方法通过提供对动态遗憾或自适应遗憾的严格界限来展示其学习算法的有效性，但它们大多完全忽略了带有模型公平性的学习，其定义为跨不同子族群（例如，种族和性别）的统计平等。另一个缺点是，在适应新环境时，在线学习者需要使用全局更改更新模型参数，这是昂贵和低效的。受到稀疏机制转移假设的启发，我们声称在线学习中的变化环境可以归因于特定于环境的部分学习参数的部分变化，其余部分保持不变。为此，本文在假设从不同子人群收集的数据具有公平的模型表示的前提下，提出了一种新算法，将模型参数分为环境不变部分和环境特定部分。我们推导了每个子人群模型表示公正性的统计保证，并证明了我们提出的算法的收敛速率。此外，我们通过对合成和真实世界数据集的广泛实验证明了我们方法的有效性。

    In the problem of online learning for changing environments, data are sequentially received one after another over time, and their distribution assumptions may vary frequently. Although existing methods demonstrate the effectiveness of their learning algorithms by providing a tight bound on either dynamic regret or adaptive regret, most of them completely ignore learning with model fairness, defined as the statistical parity across different sub-population (e.g., race and gender). Another drawback is that when adapting to a new environment, an online learner needs to update model parameters with a global change, which is costly and inefficient. Inspired by the sparse mechanism shift hypothesis, we claim that changing environments in online learning can be attributed to partial changes in learned parameters that are specific to environments and the rest remain invariant to changing environments. To this end, in this paper, we propose a novel algorithm under the assumption that data coll
    
[^81]: 在模拟人类社会中训练社会对齐的语言模型

    Training Socially Aligned Language Models in Simulated Human Society. (arXiv:2305.16960v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2305.16960](http://arxiv.org/abs/2305.16960)

    本研究提出了一种在模拟人类社会中训练语言模型的新方法，相比于现有方法，该方法具有更大的可扩展性和高效性，并在对齐基准和人类评估中展示出更优异的性能。

    

    AI系统中的社会对齐旨在确保这些模型按照既定的社会价值行事。然而，与人类不同，人们通过社交互动得出对价值判断的共识，当前的语言模型（LMs）则在孤立地复制其训练语料库时被训练出来，导致在陌生场景中表现不佳，并易受到对抗攻击。本研究提出了一种新的训练范式，允许LMs从模拟的社交互动中学习。与现有方法相比，我们的方法具有更大的可扩展性和高效性，在对齐基准和人类评估中展示出更优异的性能。这种LMs训练中的范式转变使我们离开发能够强有力且准确反映社会规范和价值的AI系统更近了一步。

    Social alignment in AI systems aims to ensure that these models behave according to established societal values. However, unlike humans, who derive consensus on value judgments through social interaction, current language models (LMs) are trained to rigidly replicate their training corpus in isolation, leading to subpar generalization in unfamiliar scenarios and vulnerability to adversarial attacks. This work presents a novel training paradigm that permits LMs to learn from simulated social interactions. In comparison to existing methodologies, our approach is considerably more scalable and efficient, demonstrating superior performance in alignment benchmarks and human evaluations. This paradigm shift in the training of LMs brings us a step closer to developing AI systems that can robustly and accurately reflect societal norms and values.
    
[^82]: 通过能量感知的早期退出实现可持续的边缘智能

    Sustainable Edge Intelligence Through Energy-Aware Early Exiting. (arXiv:2305.14094v1 [eess.SY])

    [http://arxiv.org/abs/2305.14094](http://arxiv.org/abs/2305.14094)

    本文提出了能量自适应动态早期退出机制，通过能量感知的策略，在EH边缘设备中实现了高效准确推理。

    

    深度学习模型已成为物联网应用的一种有前途的解决方案。然而，由于其计算复杂性，深度学习模型消耗大量能量，这可能会快速耗尽电池并影响物联网设备的性能。为了实现可持续运行，本文考虑一个带有可充电电池和能量收获能力的边缘设备。除了环境能源的随机性外，收获速率通常不足以满足推理能源需求，在能源不可知的设备中会导致严重的性能降低。为了解决这个问题，我们提出了能量自适应动态早期退出机制，以实现在充满环境能源情况下的高效准确推理。

    Deep learning (DL) models have emerged as a promising solution for Internet of Things (IoT) applications. However, due to their computational complexity, DL models consume significant amounts of energy, which can rapidly drain the battery and compromise the performance of IoT devices. For sustainable operation, we consider an edge device with a rechargeable battery and energy harvesting (EH) capabilities. In addition to the stochastic nature of the ambient energy source, the harvesting rate is often insufficient to meet the inference energy requirements, leading to drastic performance degradation in energy-agnostic devices. To mitigate this problem, we propose energy-adaptive dynamic early exiting (EE) to enable efficient and accurate inference in an EH edge intelligence system. Our approach derives an energy-aware EE policy that determines the optimal amount of computational processing on a per-sample basis. The proposed policy balances the energy consumption to match the limited inco
    
[^83]: GPT用于半自动化数据科学：引入CAAFE实现上下文感知自动特征工程

    GPT for Semi-Automated Data Science: Introducing CAAFE for Context-Aware Automated Feature Engineering. (arXiv:2305.03403v1 [cs.AI])

    [http://arxiv.org/abs/2305.03403](http://arxiv.org/abs/2305.03403)

    介绍了一种名为CAAFE的上下文感知自动特征工程方法，它利用大型语言模型根据数据集描述生成更多具有语义意义的特征，能够提高大多数数据集的性能，平均ROC AUC表现提高至0.822。

    

    随着自动化机器学习（AutoML）领域的发展，将领域知识纳入这些系统中变得越来越重要。我们利用大型语言模型（LLMs）的强大功能提出了一种方法来实现这一目标。具体地，我们介绍了一种用于表格数据的特征工程方法，名为上下文感知自动特征工程（CAAFE），它利用LLM根据数据集的描述生成更多具有语义意义的特征。该方法产生用于创建新特征的Python代码，并提供生成特征的效用说明。尽管方法论上很简单，但CAAFE提高了14个数据集中11个数据集的性能，与2个数据集并列，只有1个数据集性能下降，从而使所有数据集的平均ROC AUC表现从0.798提升至0.822。对于所评估的数据集，这一改进与使用随机森林（AUC 0.782）代替逻辑回归（AUC 0.754）所获得的平均改进相似。此外，

    As the field of automated machine learning (AutoML) advances, it becomes increasingly important to include domain knowledge within these systems. We present an approach for doing so by harnessing the power of large language models (LLMs). Specifically, we introduce Context-Aware Automated Feature Engineering (CAAFE), a feature engineering method for tabular datasets that utilizes an LLM to generate additional semantically meaningful features for tabular datasets based on their descriptions. The method produces both Python code for creating new features and explanations for the utility of the generated features.  Despite being methodologically simple, CAAFE enhances performance on 11 out of 14 datasets, ties on 2 and looses on 1 - boosting mean ROC AUC performance from 0.798 to 0.822 across all datasets. On the evaluated datasets, this improvement is similar to the average improvement achieved by using a random forest (AUC 0.782) instead of logistic regression (AUC 0.754).  Furthermore,
    
[^84]: 基于Transformer的机器人学习中的空间-语言注意力策略

    Spatial-Language Attention Policies for Efficient Robot Learning. (arXiv:2304.11235v1 [cs.RO])

    [http://arxiv.org/abs/2304.11235](http://arxiv.org/abs/2304.11235)

    本文提出了一种空间-语言注意力策略(SLAP)，使用三维标记作为输入表示，以训练单一多任务和语言条件化的动作预测策略，能够在引入未见过的干扰物和物体配置时达到47.5%的成功率。

    

    本文研究了如何使用Transformer建立和训练机器人决策制定的空间表示。具体来说，为了使机器人能够在各种环境中运行，我们必须能够快速训练或微调机器人感知和动作策略，以适应不同的情况并具有数据效率和鲁棒性。作为解决方案，我们提出了一种空间-语言注意力策略（SLAP）。SLAP使用三维标记作为输入表示，以训练单一多任务、语言条件化的动作预测策略。我们的方法在真实世界中展示了80%的成功率，跨越了8项任务并仅使用单一模型，在引入未见过的干扰物和物体配置时仍保持了47.5%的成功率，即使每个任务仅使用少数示例。相对于先前的工作（仅使用未见干扰物和配置的情况下，成功率为20%），这表示了30%的提高。

    We investigate how to build and train spatial representations for robot decision making with Transformers. In particular, for robots to operate in a range of environments, we must be able to quickly train or fine-tune robot sensorimotor policies that are robust to clutter, data efficient, and generalize well to different circumstances. As a solution, we propose Spatial Language Attention Policies (SLAP). SLAP uses three-dimensional tokens as the input representation to train a single multi-task, language-conditioned action prediction policy. Our method shows 80% success rate in the real world across eight tasks with a single model, and a 47.5% success rate when unseen clutter and unseen object configurations are introduced, even with only a handful of examples per task. This represents an improvement of 30% over prior work (20% given unseen distractors and configurations).
    
[^85]: CAFIN: 基于节点中心性的公平性增强进程的无监督图表示学习方法

    CAFIN: Centrality Aware Fairness inducing IN-processing for Unsupervised Representation Learning on Graphs. (arXiv:2304.04391v1 [cs.LG])

    [http://arxiv.org/abs/2304.04391](http://arxiv.org/abs/2304.04391)

    CAFIN是一种基于节点中心性的公平性增强进程技术，用于无监督学习的图表示学习方法中。实验结果表明，CAFIN在提供最优公平结果的同时，具有竞争力或更好的下游任务性能。

    

    由于所学嵌入的紧凑性和丰富性以及未标记图数据的丰富性，无监督学习的图表示在(大型)图上已经受到研究界的重视。当这些节点表示被部署时，必须使用适当的公平性约束条件生成以减少它们对下游任务造成的偏差。因此，对于特定的下游任务，已经调查了图学习算法的群体和个体公平性概念。这些公平性概念的主要局限性是没有考虑连接模式在图中导致的不同节点影响(或中心性能量)。在本文中，我们为归纳图表示学习算法设计了一个基于中心性的公平框架。我们提出了CAFIN（Centrality Aware Fairness inducing IN-processing），一种利用图结构改进GraphSAGE表示的进程技术——无监督图学习文献中的一种流行框架。对真实世界数据集的广泛实验表明，CAFIN在提供具有竞争力或更好的下游任务性能的同时，实现了最先进的公平结果。

    Unsupervised representation learning on (large) graphs has received significant attention in the research community due to the compactness and richness of the learned embeddings and the abundance of unlabelled graph data. When deployed, these node representations must be generated with appropriate fairness constraints to minimize bias induced by them on downstream tasks. Consequently, group and individual fairness notions for graph learning algorithms have been investigated for specific downstream tasks. One major limitation of these fairness notions is that they do not consider the connectivity patterns in the graph leading to varied node influence (or centrality power). In this paper, we design a centrality-aware fairness framework for inductive graph representation learning algorithms. We propose CAFIN (Centrality Aware Fairness inducing IN-processing), an in-processing technique that leverages graph structure to improve GraphSAGE's representations - a popular framework in the unsup
    
[^86]: 如何选择最佳的盟友进行可转移攻击？

    How to choose your best allies for a transferable attack?. (arXiv:2304.02312v1 [cs.CR])

    [http://arxiv.org/abs/2304.02312](http://arxiv.org/abs/2304.02312)

    本文提出了一种新方法来评估可转移性，通过将畸变放置于中心位置并提出了一种新的选择机制FiT，该机制旨在通过只进行几个初步查询即可选择最佳的源模型。

    

    对抗样本的可转移性是深度神经网络安全中的一个关键问题。一个为源模型而制造的对抗样本可以欺骗另一个目标模型，使对抗攻击的威胁更加真实。衡量可转移性是一个关键问题，但攻击成功率本身并不能提供坚实的评估。本文提出了一种评估可转移性的新方法，将畸变放置于中心位置。这个新工具显示，如果攻击者随机选择源模型，那么可转移攻击的表现可能远远不及黑盒攻击。为了解决这个问题，我们提出了一种新的选择机制，称为FiT，该机制旨在通过只进行几个初步查询即可选择最佳的源模型。我们的实验结果表明，FiT在选择多个攻击情境下的最佳源模型方面非常有效，例如单一模型攻击、集成模型攻击和多攻击（代码可在https://github.com/weny1choi/FiT中找到）。

    The transferability of adversarial examples is a key issue in the security of deep neural networks. The possibility of an adversarial example crafted for a source model fooling another targeted model makes the threat of adversarial attacks more realistic. Measuring transferability is a crucial problem, but the Attack Success Rate alone does not provide a sound evaluation. This paper proposes a new methodology for evaluating transferability by putting distortion in a central position. This new tool shows that transferable attacks may perform far worse than a black box attack if the attacker randomly picks the source model. To address this issue, we propose a new selection mechanism, called FiT, which aims at choosing the best source model with only a few preliminary queries to the target. Our experimental results show that FiT is highly effective at selecting the best source model for multiple scenarios such as single-model attacks, ensemble-model attacks and multiple attacks (Code avai
    
[^87]: 《桥接模仿学习和在线强化学习：一个乐观的故事》

    Bridging Imitation and Online Reinforcement Learning: An Optimistic Tale. (arXiv:2303.11369v1 [cs.LG])

    [http://arxiv.org/abs/2303.11369](http://arxiv.org/abs/2303.11369)

    本文提出了两种算法，iPSRL和iRLSVI，旨在解决给定离线演示数据集的问题，可以显著减少强化学习中的遗憾，桥接了在线 RL 和模仿学习。

    

    本文研究以下问题：给定一个来自不完美专家的离线演示数据集，最好的方式是什么来利用它来引导 MDP 中的在线学习表现。我们首先提出了一种基于知情后验采样的 RL（iPSRL）算法，它使用离线数据集和专家的行为策略信息来生成离线数据集。如果专家足够能干，则其累积贝叶斯遗憾在离线数据集大小 N 下会指数快速下降到零。由于该算法计算时间复杂度过高，我们随后提出了 iRLSVI 算法，可看作是在线 RL 和模仿学习的 RLSVI 算法的组合。我们的实验结果表明，与两个基准（没有离线数据，或使用离线数据集但不利用生成策略信息）相比，所提出的 iRLSVI 算法能够显著减少遗憾。我们的算法桥接了在线 RL 和模仿学习。

    In this paper, we address the following problem: Given an offline demonstration dataset from an imperfect expert, what is the best way to leverage it to bootstrap online learning performance in MDPs. We first propose an Informed Posterior Sampling-based RL (iPSRL) algorithm that uses the offline dataset, and information about the expert's behavioral policy used to generate the offline dataset. Its cumulative Bayesian regret goes down to zero exponentially fast in N, the offline dataset size if the expert is competent enough. Since this algorithm is computationally impractical, we then propose the iRLSVI algorithm that can be seen as a combination of the RLSVI algorithm for online RL, and imitation learning. Our empirical results show that the proposed iRLSVI algorithm is able to achieve significant reduction in regret as compared to two baselines: no offline data, and offline dataset but used without information about the generative policy. Our algorithm bridges online RL and imitation
    
[^88]: 无梯度结构化剪枝方法与无标签数据

    Gradient-Free Structured Pruning with Unlabeled Data. (arXiv:2303.04185v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.04185](http://arxiv.org/abs/2303.04185)

    本文提出了一种使用无标签数据的无梯度结构化剪枝方法，在GLUE和SQuAD基准测试上的实验证明了其有效性，仅需几分钟就能将原始FLOP计数的最高40%减少而准确度仅下降不超过4%。

    

    大型语言模型在许多领域中解决困难任务方面取得了巨大成功，但这种成功伴随着高计算成本和推理延迟。随着开发人员和第三方对这些模型进行个性化定制，提供高效的推理需求也越来越大。许多努力尝试通过剪枝和蒸馏等模型压缩技术来减少推理成本。然而，这些技术要么需要有标签的数据，要么因为需要重新训练压缩模型以恢复准确性而耗时。本文提出了一种仅使用无标签数据的无梯度结构化剪枝框架。使用BERT$_{BASE}$和DistilBERT在GLUE和SQuAD基准测试上的评估结果表明了该方法的有效性。仅使用预训练模型的权重和无标签数据，在单个GPU上仅需几分钟，即可将原始FLOP计数的最高40%减少，准确度下降不超过4%。

    Large Language Models (LLMs) have achieved great success in solving difficult tasks across many domains, but such success comes with a high computation cost, and inference latency. As developers and third parties customize these models, the need to provide efficient inference has increased. Many efforts have attempted to reduce inference cost through model compression techniques such as pruning and distillation. However, these techniques either require labeled data, or are time-consuming as they require the compressed model to be retrained to regain accuracy. In this paper, we propose a gradient-free structured pruning framework that uses only unlabeled data. An evaluation on the GLUE and SQuAD benchmarks using BERT$_{BASE}$ and DistilBERT illustrates the effectiveness of the proposed approach. By only using the weights of the pre-trained model and unlabeled data, in a matter of a few minutes on a single GPU, up to 40% of the original FLOP count can be reduced with less than a 4% accur
    
[^89]: 清洁CLIP: 缓解多模态对比学习中的数据污染攻击

    CleanCLIP: Mitigating Data Poisoning Attacks in Multimodal Contrastive Learning. (arXiv:2303.03323v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2303.03323](http://arxiv.org/abs/2303.03323)

    CleanCLIP是一个通过独立重新对齐个别模态的表示来削弱后门攻击引入的虚假关联的微调框架。

    

    多模态对比预训练已被用于在大量配对的图文数据上训练多模态表示模型，如CLIP。然而，先前的研究揭示了这类模型容易受到后门攻击的影响。具体而言，当在含有后门的示例上进行训练时，CLIP学习到了嵌入式后门触发器与目标标签之间的虚假相关性，并将它们在联合嵌入空间中进行了对齐。即使注入了少量的毒化示例，例如在3000000个预训练数据中注入了75个示例，也能显著操纵模型的行为，使其难以检测或忘记这种相关性。为了解决这个问题，我们提出了CleanCLIP，一种通过独立重新对齐个别模态的表示来削弱后门攻击引入的学习到的虚假关联的微调框架。我们通过使用多模态对比和单模态自监督的组合进行无监督微调来证明这一点。

    Multimodal contrastive pretraining has been used to train multimodal representation models, such as CLIP, on large amounts of paired image-text data. However, previous studies have revealed that such models are vulnerable to backdoor attacks. Specifically, when trained on backdoored examples, CLIP learns spurious correlations between the embedded backdoor trigger and the target label, aligning their representations in the joint embedding space. Injecting even a small number of poisoned examples, such as 75 examples in 3 million pretraining data, can significantly manipulate the model's behavior, making it difficult to detect or unlearn such correlations. To address this issue, we propose CleanCLIP, a finetuning framework that weakens the learned spurious associations introduced by backdoor attacks by independently re-aligning the representations for individual modalities. We demonstrate that unsupervised finetuning using a combination of multimodal contrastive and unimodal self-supervi
    
[^90]: 一种基于神经网络的跨时期命名实体识别模型

    A Neural Span-Based Continual Named Entity Recognition Model. (arXiv:2302.12200v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.12200](http://arxiv.org/abs/2302.12200)

    本文提出了一种基于神经网络的跨时期命名实体识别模型SpanKL，通过知识蒸馏和多标签预测来实现记忆保留和冲突防止，该模型在跨时期NER任务中表现出色，显示出高实际价值。

    

    在实体类型不断增加的领域（例如个人助手）中，具备持续学习能力的命名实体识别模型（NER）具有现实价值。与此同时，NER的学习范式逐渐发展出了新的模式，如基于跨度的方法。然而，跨时期学习在这方面的潜力尚未被充分探索。本文提出了SpanKL，一种简单而有效的基于跨度的模型，利用知识蒸馏（KD）来保留记忆，并采用多标签预测来防止跨时期NER中的冲突。与之前的序列标记方法不同，在SpanKL中，跨度和实体级别的独立建模以及设计的一致优化促进了每个增量步骤的学习，并减轻了遗忘。在从OntoNotes和Few-NERD衍生的合成CL数据集上的实验表明，SpanKL在许多方面显著优于先前的最优结果，并且从CL到上限的差距最小，显示了其高实际价值。

    Named Entity Recognition (NER) models capable of Continual Learning (CL) are realistically valuable in areas where entity types continuously increase (e.g., personal assistants). Meanwhile the learning paradigm of NER advances to new patterns such as the span-based methods. However, its potential to CL has not been fully explored. In this paper, we propose SpanKL, a simple yet effective Span-based model with Knowledge distillation (KD) to preserve memories and multi-Label prediction to prevent conflicts in CL-NER. Unlike prior sequence labeling approaches, the inherently independent modeling in span and entity level with the designed coherent optimization on SpanKL promotes its learning at each incremental step and mitigates the forgetting. Experiments on synthetic CL datasets derived from OntoNotes and Few-NERD show that SpanKL significantly outperforms previous SoTA in many aspects, and obtains the smallest gap from CL to the upper bound revealing its high practiced value. The code i
    
[^91]: 正则化神经网络模拟人类洞察力

    Regularised neural networks mimic human insight. (arXiv:2302.11351v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.11351](http://arxiv.org/abs/2302.11351)

    本文研究了正则化神经网络是否具有类似于人类洞察力的行为。研究发现，正则化神经网络在学习动态和行为特征上密切模仿了人类的洞察力，表现出洞察力的延迟、突然性和选择性发生。

    

    人类有时会展现出突然提高任务表现的情况，这与洞察力时刻相关。这种洞察力相关的性能提升似乎很特殊，因为它们前面有一个较长时间的僵局，变化异常突然，并且只发生在一部分学习者身上。本文探讨了使用梯度下降算法训练的人工神经网络中是否也存在类似洞察力行为。我们通过一项感知决策任务比较了人类和正则化神经网络的学习动态，该任务提供了一个隐藏的机会，可以更有效地解决任务。我们发现人类倾向于通过洞察力发现这种规律，而不是逐渐发现。值得注意的是，带有正则化门控调节的神经网络紧密模仿了人类洞察力的行为特征，表现出洞察力的延迟、突然性和选择性发生。网络学习动态的分析揭示了洞察力行为关键地取决于噪声添加。

    Humans sometimes show sudden improvements in task performance that have been linked to moments of insight. Such insight-related performance improvements appear special because they are preceded by an extended period of impasse, are unusually abrupt, and occur only in some, but not all, learners. Here, we ask whether insight-like behaviour also occurs in artificial neural networks trained with gradient descent algorithms. We compared learning dynamics in humans and regularised neural networks in a perceptual decision task that provided a hidden opportunity which allowed to solve the task more efficiently. We show that humans tend to discover this regularity through insight, rather than gradually. Notably, neural networks with regularised gate modulation closely mimicked behavioural characteristics of human insights, exhibiting delay of insight, suddenness and selective occurrence. Analyses of network learning dynamics revealed that insight-like behaviour crucially depended on noise adde
    
[^92]: 公平扩散：训练文本到图像生成模型实现公平性

    Fair Diffusion: Instructing Text-to-Image Generation Models on Fairness. (arXiv:2302.10893v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.10893](http://arxiv.org/abs/2302.10893)

    这篇论文提出了一种名为“公平扩散”的新策略，可以在生成文本到图像模型部署后减轻偏见并使模型接受公平性指导。

    

    最近，生成式AI模型在质量方面取得了惊人的成果，并因此被广泛应用于越来越多的应用中。但由于它们高度依赖于从互联网上随机抽取的十亿级数据集，因此它们也会受到退化和偏见的人类行为的影响，正如我们所展示的那样。事实上，它们甚至可能加剧这些偏见。为了不仅揭示而且对抗这些不良影响，我们提出了一种新的策略，称为公平扩散，以在生成文本到图像模型部署后减轻偏见。具体而言，我们展示了基于人类指导的偏差转移，可在任何方向上产生任意新的比例，例如，身份组。正如我们的实证评估所示，这种控制使生成图像模型在公平性方面能够接受指导，无需数据过滤和额外的训练。

    Generative AI models have recently achieved astonishing results in quality and are consequently employed in a fast-growing number of applications. However, since they are highly data-driven, relying on billion-sized datasets randomly scraped from the internet, they also suffer from degenerated and biased human behavior, as we demonstrate. In fact, they may even reinforce such biases. To not only uncover but also combat these undesired effects, we present a novel strategy, called Fair Diffusion, to attenuate biases after the deployment of generative text-to-image models. Specifically, we demonstrate shifting a bias, based on human instructions, in any direction yielding arbitrarily new proportions for, e.g., identity groups. As our empirical evaluation demonstrates, this introduced control enables instructing generative image models on fairness, with no data filtering and additional training required.
    
[^93]: 面向对抗生成模型的PAC-Bayesian泛化界

    PAC-Bayesian Generalization Bounds for Adversarial Generative Models. (arXiv:2302.08942v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2302.08942](http://arxiv.org/abs/2302.08942)

    将PAC-Bayesian理论扩展到生成模型，为基于Wasserstein距离和总变差距离的模型提供了泛化界，为Wasserstein GAN和Energy-Based GAN提供了新的训练目标，并在合成数据集上展示出非虚空泛化界。

    

    我们将PAC-Bayesian理论扩展到生成模型，并为基于Wasserstein距离和总变差距离的模型开发了泛化界。我们第一个关于Wasserstein距离的结果假设实例空间是有界的，而我们的第二个结果利用了降维的优势。我们的结果自然适用于Wasserstein GAN和Energy-Based GAN，而我们的界限为这两种GAN提供了新的训练目标。尽管我们的工作主要是理论性的，但我们进行了数值实验，展示了Wasserstein GAN在合成数据集上的非虚空泛化界。

    We extend PAC-Bayesian theory to generative models and develop generalization bounds for models based on the Wasserstein distance and the total variation distance. Our first result on the Wasserstein distance assumes the instance space is bounded, while our second result takes advantage of dimensionality reduction. Our results naturally apply to Wasserstein GANs and Energy-Based GANs, and our bounds provide new training objectives for these two. Although our work is mainly theoretical, we perform numerical experiments showing non-vacuous generalization bounds for Wasserstein GANs on synthetic datasets.
    
[^94]: HumanMAC：用于人体运动预测的掩码动作修复

    HumanMAC: Masked Motion Completion for Human Motion Prediction. (arXiv:2302.03665v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2302.03665](http://arxiv.org/abs/2302.03665)

    HumanMAC是一个掩码动作修复框架，通过训练阶段的运动扩散模型和推断阶段的去噪过程，在观察到的运动数据的控制下进行运动预测，并在多个基准数据集上展示了显著的改进。

    

    人体运动预测是计算机视觉和计算机图形学中的一个经典问题，具有广泛的实际应用。以编码-解码风格为基础的先前方法在经验性能方面取得了巨大的成功，但实际上仍存在一些问题，包括复杂的损失约束、繁琐的培训过程以及预测中不同类别运动的稀缺切换。本文从新的角度提出了一个新颖的框架，采用掩蔽完成方式解决了以上问题。具体来说，在训练阶段，我们学习了一个运动扩散模型来从随机噪声中生成运动。在推断阶段，通过去噪过程，我们进行了运动预测并在观察到的运动数据的控制下进行了预测。我们提出的框架名为HumanMAC，在几个基准数据集上显示出明显的改进。

    Human motion prediction is a classical problem in computer vision and computer graphics, which has a wide range of practical applications. Previous effects achieve great empirical performance based on an encoding-decoding style. The methods of this style work by first encoding previous motions to latent representations and then decoding the latent representations into predicted motions. However, in practice, they are still unsatisfactory due to several issues, including complicated loss constraints, cumbersome training processes, and scarce switch of different categories of motions in prediction. In this paper, to address the above issues, we jump out of the foregoing style and propose a novel framework from a new perspective. Specifically, our framework works in a masked completion fashion. In the training stage, we learn a motion diffusion model that generates motions from random noise. In the inference stage, with a denoising procedure, we make motion prediction conditioning on obse
    
[^95]: 路径学家式诊断: 基于Transformer的层次注意力引导多实例学习用于全切片图像分类

    Diagnose Like a Pathologist: Transformer-Enabled Hierarchical Attention-Guided Multiple Instance Learning for Whole Slide Image Classification. (arXiv:2301.08125v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2301.08125](http://arxiv.org/abs/2301.08125)

    这项研究提出了一种基于Transformer的层次注意力引导多实例学习框架，用于组织病理学全切片图像分类。该框架可以动态和关注地发现并利用WSI的多个分辨率的区分性区域，提高了分类性能。

    

    多实例学习（MIL）和transformers在组织病理学全切片图像（WSI）分类中越来越受欢迎。然而，与人类病理学家在不同放大倍率下选择性观察组织病理学组织的特定区域不同，大多数方法不会层次化和注重地结合WSI的多分辨率，导致对WSI和其他分辨率信息的关注丧失。为了解决这个问题，我们提出了一个层次注意力引导的多实例学习框架，充分利用WSI。该框架可以动态地和关注地发现跨WSI的多个分辨率的区分性区域。在该框架内，提出了一个集成注意力转换器来进一步提高transformer的性能，并获得更全面的WSI（bag）表示。该transformer由多个集成注意力模块组成，其中包括一个transformer层。

    Multiple Instance Learning (MIL) and transformers are increasingly popular in histopathology Whole Slide Image (WSI) classification. However, unlike human pathologists who selectively observe specific regions of histopathology tissues under different magnifications, most methods do not incorporate multiple resolutions of the WSIs, hierarchically and attentively, thereby leading to a loss of focus on the WSIs and information from other resolutions. To resolve this issue, we propose a Hierarchical Attention-Guided Multiple Instance Learning framework to fully exploit the WSIs. This framework can dynamically and attentively discover the discriminative regions across multiple resolutions of the WSIs. Within this framework, an Integrated Attention Transformer is proposed to further enhance the performance of the transformer and obtain a more holistic WSI (bag) representation. This transformer consists of multiple Integrated Attention Modules, which is the combination of a transformer layer 
    
[^96]: StitchNet: 从预训练片段组合神经网络

    StitchNet: Composing Neural Networks from Pre-Trained Fragments. (arXiv:2301.01947v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.01947](http://arxiv.org/abs/2301.01947)

    StitchNet提出了一种新的神经网络创建方式，它通过组合预训练神经网络的片段来创建高性能的网络，无需传统训练的大量计算资源和数据要求。通过居中核对齐（CKA），可以有效指导片段的选择，以满足特定准确性需求和计算资源限制。此外，StitchNet还可以实现即时个性化模型创建和推断。

    

    我们提出了一种新颖的神经网络创建范式StitchNet，它将来自多个预训练神经网络的片段（一个或多个连续的网络层）拼接在一起。StitchNet允许创建高性能的神经网络，而无需传统的基于反向传播训练的大量计算和数据要求。我们利用居中核对齐（CKA）作为一种兼容性度量，以有效地指导选择这些片段，以组合适合特定准确性需求和计算资源限制的任务网络。然后，我们展示了这些片段可以被拼接在一起，以在计算资源和数据要求的一小部分下创建与传统训练网络相媲美准确度的神经网络。最后，我们探索了这种新范式所能实现的一种新颖的即时个性化模型创建和推断应用。

    We propose StitchNet, a novel neural network creation paradigm that stitches together fragments (one or more consecutive network layers) from multiple pre-trained neural networks. StitchNet allows the creation of high-performing neural networks without the large compute and data requirements needed under traditional model creation processes via backpropagation training. We leverage Centered Kernel Alignment (CKA) as a compatibility measure to efficiently guide the selection of these fragments in composing a network for a given task tailored to specific accuracy needs and computing resource constraints. We then show that these fragments can be stitched together to create neural networks with comparable accuracy to traditionally trained networks at a fraction of computing resource and data requirements. Finally, we explore a novel on-the-fly personalized model creation and inference application enabled by this new paradigm.
    
[^97]: 带有脉冲编码网络的闭式控制

    Closed-form control with spike coding networks. (arXiv:2212.12887v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2212.12887](http://arxiv.org/abs/2212.12887)

    本文扩展了脉冲编码网络理论，通过引入闭式最优估计和控制，实现了对循环脉冲神经网络中动态系统的控制。

    

    使用脉冲神经网络(SNNs)进行高效和鲁棒的控制仍然是一个待解决的问题。虽然生物系统的行为是通过稀疏和不规则的脉冲模式产生的，这提供了鲁棒和高效的控制，但用于控制的大部分人工脉冲神经网络的活动模式是密集和规则的，可能导致代码效率较低。此外，对于大多数现有的控制解决方案，即使对于完全识别的系统，也需要网络训练或优化，使得它们在芯片低功耗解决方案中的实施变得复杂。脉冲编码网络(SCNs)的神经科学理论提供了在循环脉冲神经网络中实现动态系统的完全分析解决方案，同时保持不规则、稀疏和鲁棒的脉冲活动，但如何直接应用于控制问题还不清楚。在这里，我们通过引入闭式最优估计和控制来扩展SCN理论。

    Efficient and robust control using spiking neural networks (SNNs) is still an open problem. Whilst behaviour of biological agents is produced through sparse and irregular spiking patterns, which provide both robust and efficient control, the activity patterns in most artificial spiking neural networks used for control are dense and regular -- resulting in potentially less efficient codes. Additionally, for most existing control solutions network training or optimization is necessary, even for fully identified systems, complicating their implementation in on-chip low-power solutions. The neuroscience theory of Spike Coding Networks (SCNs) offers a fully analytical solution for implementing dynamical systems in recurrent spiking neural networks -- while maintaining irregular, sparse, and robust spiking activity -- but it's not clear how to directly apply it to control problems. Here, we extend SCN theory by incorporating closed-form optimal estimation and control. The resulting networks 
    
[^98]: 好奇心在策略搜索中促进多样性

    Curiosity creates Diversity in Policy Search. (arXiv:2212.03530v2 [cs.NE] UPDATED)

    [http://arxiv.org/abs/2212.03530](http://arxiv.org/abs/2212.03530)

    本研究使用好奇心作为内在动机，并将其应用于进化策略搜索方法中。与常用的多样性度量指标相比，好奇心能够在没有明确的多样性标准的情况下生成更高的多样性，并找到多种能够获得奖励的策略。

    

    在搜索策略时，奖励稀疏的环境通常缺乏足够的信息来确定应该改进或避免的行为。在这种环境中，策略搜索过程往往会盲目地搜索产生奖励的转换，没有早期奖励可以偏向于某个方向。克服这个问题的一种方式是使用内在动机来探索新的转换，直到找到奖励。在这项工作中，我们使用了最近提出的内在动机定义——好奇心，结合进化策略搜索方法。我们提出了Curiosity-ES，一种适应于使用好奇心作为适应度度量的进化策略。我们将好奇心与常用的多样性度量指标——新颖性进行比较，并发现好奇心能够在完整的回合中生成更高的多样性，而无需明确的多样性标准，并且能够找到多种能够获得奖励的策略。

    When searching for policies, reward-sparse environments often lack sufficient information about which behaviors to improve upon or avoid. In such environments, the policy search process is bound to blindly search for reward-yielding transitions and no early reward can bias this search in one direction or another. A way to overcome this is to use intrinsic motivation in order to explore new transitions until a reward is found. In this work, we use a recently proposed definition of intrinsic motivation, Curiosity, in an evolutionary policy search method. We propose Curiosity-ES, an evolutionary strategy adapted to use Curiosity as a fitness metric. We compare Curiosity with Novelty, a commonly used diversity metric, and find that Curiosity can generate higher diversity over full episodes without the need for an explicit diversity criterion and lead to multiple policies which find reward.
    
[^99]: \{kappa}HGCN: 通过连续和离散曲率学习实现树状结构建模

    \{kappa}HGCN: Tree-likeness Modeling via Continuous and Discrete Curvature Learning. (arXiv:2212.01793v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2212.01793](http://arxiv.org/abs/2212.01793)

    本文提出了一种新的\{kappa}HGCN模型，在双曲空间内实现树状结构建模，通过结合连续和离散曲率来学习输入图的基础几何结构，并在多个基准测试和数据集上取得了最先进的性能。

    

    树状结构在现实世界中广泛存在，包括层次结构和幂律分布。最近，利用双曲空间进行树状结构建模受到了广泛关注，由于其呈指数增长，相比于平坦的欧几里得空间，曲面双曲空间提供了更易处理和嵌入的空间，特别适用于展现隐含树状结构的数据集。然而，真实世界树状数据的复杂性提出了一个重要挑战，因为它经常展示出树状、平坦和圆形区域的异质组成。将这样异质的结构直接嵌入一个同质化的嵌入空间（即双曲空间）必然导致重大失真。为了缓解上述缺点，本研究致力于探索双曲空间的曲率，以实现灵活准确地建模树状结构。具体而言，我们提出了一种新的\{kappa}HGCN模型，将连续和离散曲率相结合，学习输入图的基础几何结构。我们的模型在不同的基准测试和数据集上均取得了最先进的性能，证明了其在捕捉输入数据的树状结构方面的有效性。

    The prevalence of tree-like structures, encompassing hierarchical structures and power law distributions, exists extensively in real-world applications, including recommendation systems, ecosystems, financial networks, social networks, etc. Recently, the exploitation of hyperbolic space for tree-likeness modeling has garnered considerable attention owing to its exponential growth volume. Compared to the flat Euclidean space, the curved hyperbolic space provides a more amenable and embeddable room, especially for datasets exhibiting implicit tree-like architectures. However, the intricate nature of real-world tree-like data presents a considerable challenge, as it frequently displays a heterogeneous composition of tree-like, flat, and circular regions. The direct embedding of such heterogeneous structures into a homogeneous embedding space (i.e., hyperbolic space) inevitably leads to heavy distortions. To mitigate the aforementioned shortage, this study endeavors to explore the curvatur
    
[^100]: CLIP: 用更少的数据更快地训练模型

    CLIP: Train Faster with Less Data. (arXiv:2212.01452v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.01452](http://arxiv.org/abs/2212.01452)

    本文提出了CLIP，通过结合课程学习和数据集修剪的方法，在深度学习模型的训练中使用更少的数据，实现更快的收敛速度和更好的泛化能力。

    

    深度学习模型需要大量的数据进行训练，但近年来机器学习正从以模型为中心转向以数据为中心的方法。在数据为中心的方法中，重点是通过改进和提高数据质量来提高模型的学习性能，而不是重新设计模型架构。在本文中，我们提出了CLIP，即使用迭代数据修剪的课程学习。CLIP结合了课程学习和数据集修剪这两种数据为中心的方法，以提高模型的学习准确性和收敛速度。所提出的方案采用了有损数据集修剪的方法，迭代地去除最不重要的样本，并逐渐减小在课程学习训练中的有效数据集的大小。在众筹密度估计模型上进行的大量实验验证了结合这两种方法的理念，通过减小收敛时间和改进泛化能力。据我们所知，这是第一次将课程学习和数据集修剪结合应用于深度学习的训练中。

    Deep learning models require an enormous amount of data for training. However, recently there is a shift in machine learning from model-centric to data-centric approaches. In data-centric approaches, the focus is to refine and improve the quality of the data to improve the learning performance of the models rather than redesigning model architectures. In this paper, we propose CLIP i.e., Curriculum Learning with Iterative data Pruning. CLIP combines two data-centric approaches i.e., curriculum learning and dataset pruning to improve the model learning accuracy and convergence speed. The proposed scheme applies loss-aware dataset pruning to iteratively remove the least significant samples and progressively reduces the size of the effective dataset in the curriculum learning training. Extensive experiments performed on crowd density estimation models validate the notion behind combining the two approaches by reducing the convergence time and improving generalization. To our knowledge, th
    
[^101]: 使用不完整标签进行人群密度估计

    Crowd Density Estimation using Imperfect Labels. (arXiv:2212.01450v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2212.01450](http://arxiv.org/abs/2212.01450)

    本文研究了不完整标签对人群计数准确性的影响，并提出了一种系统，利用深度学习模型自动生成不完整标签，并将其用于训练新的人群计数模型。实验证明，所提出的方案的准确性接近于完美标签数据集的准确性。

    

    密度估计是人群计数中最常用的方法之一，深度学习模型通过学习头部标注的人群图像来估计未见图像中的人群密度。通常，模型的学习性能很大程度上受到标注准确性的影响，不准确的标注可能导致预测过程中的定位和计数错误。已有大量的研究关注使用完美标签数据集进行人群计数，但没有人探索注释错误对模型准确性的影响。本文研究了不完整标签（包括噪声和缺失标签）对人群计数准确性的影响。我们提出了一种系统，利用深度学习模型（称为标注器）自动生成不完整标签，然后用于训练新的人群计数模型（目标模型）。我们在两个人群计数模型和两个基准数据集上的分析结果表明，所提出的方案的准确性接近于完美标签数据集的准确性。

    Density estimation is one of the most widely used methods for crowd counting in which a deep learning model learns from head-annotated crowd images to estimate crowd density in unseen images. Typically, the learning performance of the model is highly impacted by the accuracy of the annotations and inaccurate annotations may lead to localization and counting errors during prediction. A significant amount of works exist on crowd counting using perfectly labelled datasets but none of these explore the impact of annotation errors on the model accuracy. In this paper, we investigate the impact of imperfect labels (both noisy and missing labels) on crowd counting accuracy. We propose a system that automatically generates imperfect labels using a deep learning model (called annotator) which are then used to train a new crowd counting model (target model). Our analysis on two crowd counting models and two benchmark datasets shows that the proposed scheme achieves accuracy closer to that of the
    
[^102]: 可扩展的分层无线联邦学习算法

    Scalable Hierarchical Over-the-Air Federated Learning. (arXiv:2211.16162v2 [cs.IT] UPDATED)

    [http://arxiv.org/abs/2211.16162](http://arxiv.org/abs/2211.16162)

    本研究提出了一种针对分布式环境的通信高效的分层联邦学习算法，通过使用可扩展的无线聚合方案和带宽有限的广播方案，解决了设备干扰和边缘服务器干扰的问题。

    

    本研究提出了一种针对包含核心服务器和多个边缘服务器及设备集群的分布式环境的通信高效的分层联邦学习算法。假设不同的学习任务，具有相同任务的集群进行协作。为了在无线链路上实现算法，我们提出了一种可扩展的分簇无线聚合方案，用于上行链路，同时采用带宽有限的广播方案用于下行链路，每个算法迭代只需要一个资源块，不受边缘服务器和设备数量的影响。这种设置面临着上行链路设备干扰和下行链路边缘服务器干扰的问题，需要进行严格的建模。我们首先通过将设备建模为一个泊松集群过程，在设置中建立了一个空间模型，并对由干扰引起的上行链路和下行链路的误差进行量化。然后，我们提出了一种全面的数学方法来推导收敛性。

    In this work, we propose a communication-efficient hierarchical federated learning algorithm for distributed setups including core servers and multiple edge servers with clusters of devices. Assuming different learning tasks, clusters with a same task collaborate. To implement the algorithm over wireless links, we propose a scalable clustered over-the-air aggregation scheme for the uplink with a bandwidth-limited broadcast scheme for the downlink that requires only a single resource block for each algorithm iteration, independent of the number of edge servers and devices. This setup is faced with interference of devices in the uplink and interference of edge servers in the downlink that are to be modeled rigorously. We first develop a spatial model for the setup by modeling devices as a Poisson cluster process over the edge servers and quantify uplink and downlink error terms due to the interference. Accordingly, we present a comprehensive mathematical approach to derive the convergenc
    
[^103]: 改进卷积神经网络的输入遮罩方法研究

    Towards Improved Input Masking for Convolutional Neural Networks. (arXiv:2211.14646v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.14646](http://arxiv.org/abs/2211.14646)

    本论文提出了一种改进的卷积神经网络的输入遮罩方法，通过层遮罩能够有效减少遮罩引起的缺失偏差，并消除或最小化了遮罩对模型预测的影响。

    

    对于理解和解释模型预测结果来说，从机器学习模型的输入中移除特征非常重要。然而，对于视觉模型来说，这是非常困难的，因为遮罩图像的一部分通常会引起很大的分布偏移。这是因为用于遮罩的基准颜色（通常是灰色或黑色）是处于分布之外的。此外，遮罩本身的形状可以包含不需要的信号，模型可能会利用这些信号进行预测。最近，在视觉变换器中对图像遮罩的缺失偏差问题方面已经取得了一些进展。在本研究中，我们提出了一种新的CNN遮罩方法，称之为层遮罩，可以在很大程度上减少遮罩引起的缺失偏差。直观上，层遮罩将一个遮罩应用于中间激活图，使得模型只处理没有遮罩的输入。我们展示了我们的方法（i）能够消除或最小化遮罩的影响。

    The ability to remove features from the input of machine learning models is very important to understand and interpret model predictions. However, this is non-trivial for vision models since masking out parts of the input image typically causes large distribution shifts. This is because the baseline color used for masking (typically grey or black) is out of distribution. Furthermore, the shape of the mask itself can contain unwanted signals which can be used by the model for its predictions. Recently, there has been some progress in mitigating this issue (called missingness bias) in image masking for vision transformers. In this work, we propose a new masking method for CNNs we call layer masking in which the missingness bias caused by masking is reduced to a large extent. Intuitively, layer masking applies a mask to intermediate activation maps so that the model only processes the unmasked input. We show that our method (i) is able to eliminate or minimize the influence of the mask sh
    
[^104]: NLP中的不良偏见：避免衡量危机

    Undesirable biases in NLP: Averting a crisis of measurement. (arXiv:2211.13709v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.13709](http://arxiv.org/abs/2211.13709)

    这项研究提供了一个跨学科的方法来探讨NLP模型偏见的问题，通过采用心理测量学的视角，特别关注构念效度和测量工具的信度，在衡量模型偏见的情境中如何应用。

    

    随着大型语言模型和自然语言处理（NLP）技术的快速发展和普及，预测其使用可能对人们造成伤害变得至关重要。近年来，一个受到关注的问题是这一技术在行为中显示出有害偏见。尽管已经投入了大量的努力来评估和减轻这些偏见，但我们衡量NLP模型偏见的方法存在严重问题（例如，通常不清楚它们到底衡量了什么）。在本文中，我们采用心理测量学的视角，提供了一个跨学科的方法来讨论NLP模型偏见的问题，心理测量学专注于衡量不直接可观察到的概念，如偏见。具体而言，我们将探讨心理测量学的两个核心概念，即构念效度和测量工具的信度，并讨论它们在衡量模型偏见的情境中如何应用。我们的目标是提供一个全面的视角来解决这个问题。

    As Large Language Models and Natural Language Processing (NLP) technology rapidly develops and spreads into daily life, it becomes crucial to anticipate how its use could harm people. One problem that has received a lot of attention in recent years is that this technology has displayed harmful biases in its behavior. Although a lot of effort has been invested in assessing and mitigating these biases, our methods of measuring the biases of NLP models have serious problems (e.g., it is often unclear what they actually measure). In this paper, we provide an interdisciplinary approach to discussing the issue of NLP model bias by adopting the lens of psychometrics -- a field specialized in the measurement of concepts like bias that are not directly observable. In particular, we will explore two central notions from psychometrics, the construct validity and the reliability of measurement tools, and discuss how they can be applied in the context of measuring model bias. Our goal is to provide
    
[^105]: 一种带有嘈杂标签的长尾实例分割基准测试

    A Benchmark of Long-tailed Instance Segmentation with Noisy Labels. (arXiv:2211.13435v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.13435](http://arxiv.org/abs/2211.13435)

    本文提出了一个带有噪声标签的大词汇量的长尾数据集，用于实例分割任务的基准测试，并在该数据集上评估了先前的实例分割算法。结果表明，训练数据集中的噪声会影响模型学习稀有类别并降低整体性能，为解决这一实际挑战提供了启示。

    

    本文考虑了在长尾数据集上进行实例分割任务，该数据集包含噪声标签，即一些注释是不正确的。这种情况具有现实意义的原因有两个。首先，从真实世界中收集的数据集通常遵循长尾分布。其次，对于实例分割数据集来说，由于一幅图像中有许多实例，其中一些实例很小，因此更容易引入注释误差。具体来说，我们提出了一个新的数据集，该数据集是一个包含噪声标签的大词汇量的长尾数据集，用于实例分割。此外，我们在该数据集上评估了先前提出的实例分割算法。结果表明，训练数据集中的噪声将阻碍模型学习稀有类别并降低整体性能，这启发我们探索更有效的方法来解决这个实际挑战。代码和数据集可以在https://github.com/GuanlinLee/Noi上找到。

    In this paper, we consider the instance segmentation task on a long-tailed dataset, which contains label noise, i.e., some of the annotations are incorrect. There are two main reasons making this case realistic. First, datasets collected from real world usually obey a long-tailed distribution. Second, for instance segmentation datasets, as there are many instances in one image and some of them are tiny, it is easier to introduce noise into the annotations. Specifically, we propose a new dataset, which is a large vocabulary long-tailed dataset containing label noise for instance segmentation. Furthermore, we evaluate previous proposed instance segmentation algorithms on this dataset. The results indicate that the noise in the training dataset will hamper the model in learning rare categories and decrease the overall performance, and inspire us to explore more effective approaches to address this practical challenge. The code and dataset are available in https://github.com/GuanlinLee/Noi
    
[^106]: DroneNet: 使用自组织神经网络的无人机进行人群密度估计

    DroneNet: Crowd Density Estimation using Self-ONNs for Drones. (arXiv:2211.07137v4 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2211.07137](http://arxiv.org/abs/2211.07137)

    使用自组织神经网络的无人机进行人群密度估计的模型（DroneNet），相比于使用CNN的模型具有更高的计算效率，能够在保持准确性的前提下降低推断时间。

    

    使用无人机进行视频监控既方便又高效，由于无人机在许多场景下部署和移动没有障碍。无人机视频监控的一个有趣应用是估计公共场所的人群密度（包括行人和车辆）。使用卷积神经网络（CNN）进行深度学习，利用图像和视频进行自动人群计数和密度估计。然而，这类模型的性能和准确性通常取决于模型架构，即更深的CNN模型在增加推断时间的代价下提高了准确性。在本文中，我们提出了一种新颖的无人机人群密度估计模型（DroneNet），使用自组织操作神经网络（Self-ONN）。相比于基于CNN的模型，Self-ONN在计算复杂度更低的情况下提供了高效的学习能力。我们将算法在两个无人机视角的公开数据集上进行了测试。评估结果显示，所提出的DroneNet在人群密度估计上表现出

    Video surveillance using drones is both convenient and efficient due to the ease of deployment and unobstructed movement of drones in many scenarios. An interesting application of drone-based video surveillance is to estimate crowd densities (both pedestrians and vehicles) in public places. Deep learning using convolution neural networks (CNNs) is employed for automatic crowd counting and density estimation using images and videos. However, the performance and accuracy of such models typically depend upon the model architecture i.e., deeper CNN models improve accuracy at the cost of increased inference time. In this paper, we propose a novel crowd density estimation model for drones (DroneNet) using Self-organized Operational Neural Networks (Self-ONN). Self-ONN provides efficient learning capabilities with lower computational complexity as compared to CNN-based models. We tested our algorithm on two drone-view public datasets. Our evaluation shows that the proposed DroneNet shows supe
    
[^107]: 基于SPD流形的图神经网络用于运动想象分类：来自时频分析的视角

    Graph Neural Networks on SPD Manifolds for Motor Imagery Classification: A Perspective from the Time-Frequency Analysis. (arXiv:2211.02641v2 [eess.SP] UPDATED)

    [http://arxiv.org/abs/2211.02641](http://arxiv.org/abs/2211.02641)

    本文介绍了一种基于SPD流形的图神经网络用于运动想象分类，利用EEG的二阶统计量，相比传统方法具有更好的性能。

    This paper introduces a graph neural network based on SPD manifolds for motor imagery classification, which utilizes second-order statistics of EEG signals and outperforms traditional methods.

    运动想象（MI）的分类是脑电图（EEG）基础脑机接口（BCI）领域中备受追捧的研究课题，具有巨大的商业价值。过去二十年，MI-EEG分类器的趋势发生了根本性的转变，其性能逐渐提高。 Tensor-CSPNet的出现是BCI研究中第一个几何深度学习（GDL）框架的必要性，其归因于信号的非欧几里德性质的特征化。从根本上讲，Tensor-CSPNet是一种基于深度学习的分类器，利用EEG的二阶统计量。与利用EEG信号的一阶统计量的传统方法相比，利用这些二阶统计量代表了经典的处理方法。这些统计量提供了足够的区分信息，使它们适用于MI-EEG分类。在本研究中，我们介绍了另一种GDL分类器，

    The classification of motor imagery (MI) is a highly sought-after research topic in the field of Electroencephalography (EEG)-based brain-computer interfaces (BCIs), with immense commercial value. Over the past two decades, there has been a fundamental shift in the trend of MI-EEG classifiers, resulting in a gradual increase in their performance. The emergence of Tensor-CSPNet, the first geometric deep learning (GDL) framework in BCI research, is attributed to the imperative of characterizing the non-Euclidean nature of signals. Fundamentally, Tensor-CSPNet is a deep learning-based classifier that capitalizes on the second-order statistics of EEGs. In contrast to the conventional approach of utilizing first-order statistics for EEG signals, the utilization of these second-order statistics represents the classical treatment. These statistics provide adequate discriminative information, rendering them suitable for MI-EEG classification. In this study, we introduce another GDL classifier,
    
[^108]: 基于联邦生成对抗网络的医学图像合成中的后门攻击与防御

    Backdoor Attack and Defense in Federated Generative Adversarial Network-based Medical Image Synthesis. (arXiv:2210.10886v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.10886](http://arxiv.org/abs/2210.10886)

    本研究调查了联邦生成对抗网络中后门攻击的被忽视问题，并发现成功攻击是由于部分本地判别器对毒素过度拟合所致。

    

    深度学习基于图像合成的技术已经应用于医疗保健研究中，用于生成医学图像以支持开放研究并增加医学数据集。训练生成对抗神经网络（GANs）通常需要大量的训练数据。联邦学习（FL）提供了一种使用分布式数据训练中央模型并保持本地原始数据的方法。然而，考虑到FL服务器无法访问原始数据，它容易受到后门攻击的影响，后门攻击是一种通过污染训练数据的对抗性攻击。大多数后门攻击策略集中在分类模型和中心化领域。现有的后门攻击能否影响GAN训练仍然是一个开放问题，如果可以影响，如何在FL环境中进行防御也是一个问题。在这项研究中，我们调查了联邦GANs（FedGANs）中后门攻击这个被忽视的问题。攻击的成功随后被确定为部分本地判别器对毒素过度拟合的结果。

    Deep Learning-based image synthesis techniques have been applied in healthcare research for generating medical images to support open research and augment medical datasets. Training generative adversarial neural networks (GANs) usually require large amounts of training data. Federated learning (FL) provides a way of training a central model using distributed data while keeping raw data locally. However, given that the FL server cannot access the raw data, it is vulnerable to backdoor attacks, an adversarial by poisoning training data. Most backdoor attack strategies focus on classification models and centralized domains. It is still an open question if the existing backdoor attacks can affect GAN training and, if so, how to defend against the attack in the FL setting. In this work, we investigate the overlooked issue of backdoor attacks in federated GANs (FedGANs). The success of this attack is subsequently determined to be the result of some local discriminators overfitting the poison
    
[^109]: 语言建模任务中的不充分规范化：一个以因果关系为基础的性别代词消解研究

    Underspecification in Language Modeling Tasks: A Causality-Informed Study of Gendered Pronoun Resolution. (arXiv:2210.00131v3 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2210.00131](http://arxiv.org/abs/2210.00131)

    本研究通过提供一个因果模型，在语言建模任务中探讨了不充分规范化的作用，提出了两种轻量级黑盒评估方法来帮助检测任务的不充分规范化，并在性别代词消解任务中应用这些方法，同时发现了性别与时间、性别与位置之间的虚假相关性。

    

    现代语言建模任务常常存在不充分规范化的问题：对于给定的标记预测，在推断时可能有多个单词符合用户产生自然语言的意图，然而在训练时只有一个单词能够最小化任务的损失函数。我们提供了一个简单而合理的因果机制，描述了不充分规范化在生成虚假相关性方面的作用。尽管其简洁性，我们的因果模型直接指导了两种轻量级黑盒评估方法的开发，我们将其应用于广泛的语言模型任务中的性别代词消解上，以帮助 1) 检测推断时任务的不充分规范化，利用了 2）之前未报道的性别与时间、性别与位置的虚假相关性，涵盖了 A）不同规模的语言模型，从BERT-base到GPT 3.5，B）不同的预训练目标，从遮蔽和自回归语言建模到这些目标的混合，以及C）不同的训练阶段，从仅预训练到增强训练。

    Modern language modeling tasks are often underspecified: for a given token prediction, many words may satisfy the user's intent of producing natural language at inference time, however only one word would minimize the task's loss function at training time. We provide a simple yet plausible causal mechanism describing the role underspecification plays in the generation of spurious correlations. Despite its simplicity, our causal model directly informs the development of two lightweight black-box evaluation methods, that we apply to gendered pronoun resolution tasks on a wide range of LLMs to 1) aid in the detection of inference-time task underspecification by exploiting 2) previously unreported gender vs. time and gender vs. location spurious correlations on LLMs with a range of A) sizes: from BERT-base to GPT 3.5, B) pre-training objectives: from masked & autoregressive language modeling to a mixture of these objectives, and C) training stages: from pre-training only to reinforcement l
    
[^110]: 在稀疏奖励强化学习中利用Transformer进行可解释的时序逻辑运动规划

    Exploiting Transformer in Sparse Reward Reinforcement Learning for Interpretable Temporal Logic Motion Planning. (arXiv:2209.13220v2 [cs.RO] UPDATED)

    [http://arxiv.org/abs/2209.13220](http://arxiv.org/abs/2209.13220)

    该论文提出了一个通过将Transformer应用于稀疏奖励强化学习的方法，开发了一个双Transformer引导的时序逻辑框架(T2TL)，该框架通过两次利用Transformer的结构特性，使得机器人在训练过程中能够高效理解任务指令，并改进任务的性能。

    

    基于自动机的方法使得机器人能够执行各种复杂任务。然而，大多数现有的基于自动机的算法在考虑的任务中高度依赖于手动定制的状态表示，限制了其在深度强化学习算法中的适用性。为了解决这个问题，我们通过将Transformer引入强化学习，开发了一个双Transformer引导的时序逻辑框架(T2TL)，它两次利用Transformer的结构特性，即首先通过Transformer模块对LTL指令进行编码，以在训练过程中高效理解任务指令，然后再次通过Transformer对上下文变量进行编码，以改进任务的性能。特别地，LTL指令由限守法LTL指定。作为一种语义保持的重写操作，利用LTL进展将复杂任务分解为可学习的子目标，从而将非马尔可夫奖励决策过程转换为马尔可夫奖励决策过程，从而实现了更好的任务性能。

    Automaton based approaches have enabled robots to perform various complex tasks. However, most existing automaton based algorithms highly rely on the manually customized representation of states for the considered task, limiting its applicability in deep reinforcement learning algorithms. To address this issue, by incorporating Transformer into reinforcement learning, we develop a Double-Transformer-guided Temporal Logic framework (T2TL) that exploits the structural feature of Transformer twice, i.e., first encoding the LTL instruction via the Transformer module for efficient understanding of task instructions during the training and then encoding the context variable via the Transformer again for improved task performance. Particularly, the LTL instruction is specified by co-safe LTL. As a semantics-preserving rewriting operation, LTL progression is exploited to decompose the complex task into learnable sub-goals, which not only converts non-Markovian reward decision processes to Mark
    
[^111]: 基于幂法和反幂法的神经网络求解线性特征值问题

    Neural Networks Based on Power Method and Inverse Power Method for Solving Linear Eigenvalue Problems. (arXiv:2209.11134v5 [math.NA] UPDATED)

    [http://arxiv.org/abs/2209.11134](http://arxiv.org/abs/2209.11134)

    本文提出了两种神经网络方法，分别基于幂法和反幂法，用于求解线性特征值问题。通过自动微分实现微分算子，通过优化损失函数实施迭代算法，可以高效地求解最大正特征值、最小特征值和内部特征值，并在实验中证明了方法的准确性。

    

    本文提出了两种受幂法和反幂法启发的神经网络，用于求解线性特征值问题。这些神经网络与传统方法类似，其中微分算子通过自动微分实现。特征值问题的特征函数通过神经网络学习，并通过优化特定定义的损失函数实施迭代算法。在给定先验知识的情况下，可以高效地求解最大正特征值、最小特征值和内部特征值。我们在一维、二维和高维数值实验中考察了我们方法的适用性和精确性。数值结果表明，我们的方法可以得到准确的特征值和特征函数近似值。

    In this article, we propose two kinds of neural networks inspired by power method and inverse power method to solve linear eigenvalue problems. These neural networks share similar ideas with traditional methods, in which the differential operator is realized by automatic differentiation. The eigenfunction of the eigenvalue problem is learned by the neural network and the iterative algorithms are implemented by optimizing the specially defined loss function. The largest positive eigenvalue, smallest eigenvalue and interior eigenvalues with the given prior knowledge can be solved efficiently. We examine the applicability and accuracy of our methods in the numerical experiments in one dimension, two dimensions and higher dimensions. Numerical results show that accurate eigenvalue and eigenfunction approximations can be obtained by our methods.
    
[^112]: 基于记忆增强的图神经网络：一个受启发于大脑的综述

    Memory-Augmented Graph Neural Networks: A Brain-Inspired Review. (arXiv:2209.10818v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2209.10818](http://arxiv.org/abs/2209.10818)

    本文提供了一个关于记忆增强型图神经网络的全面回顾，通过心理学和神经科学的视角，提出了分类法和比较标准，并讨论了其局限性和未来发展方向。

    

    我们通过心理学和神经科学的视角对现有的记忆增强型图神经网络文献进行了全面回顾。我们提出了一个记忆增强型图神经网络的分类法和一组用于比较它们记忆机制的标准。我们还对这些研究的局限性进行了深入讨论。最后，我们讨论了这个领域的挑战和未来发展方向。

    We provide a comprehensive review of the existing literature on memory-augmented GNNs. We review these works through the lens of psychology and neuroscience, which has several established theories on how multiple memory systems and mechanisms operate in biological brains. We propose a taxonomy of memory-augmented GNNs and a set of criteria for comparing their memory mechanisms. We also provide critical discussions on the limitations of these works. Finally, we discuss the challenges and future directions for this area.
    
[^113]: SAFARI：鲁棒性可解释性评估的多功能高效方法

    SAFARI: Versatile and Efficient Evaluations for Robustness of Interpretability. (arXiv:2208.09418v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2208.09418](http://arxiv.org/abs/2208.09418)

    本文提出了一种名为SAFARI的方法，用于评估深度学习的解释可靠性。该方法针对现有技术无法解决的几个挑战，通过引入两种黑盒评估方法，即最坏情况解释差异和一般情况下的鲁棒性的概率概念，来解决现有度量不全面、XAI技术异质性和误解罕见性等问题。使用遗传算法和子集模拟进行评估。

    

    深度学习的可解释性是建立可信赖的人工智能的一道障碍。尽管可解释人工智能（XAI）社区做出了巨大的努力，但解释缺乏鲁棒性——无法区分的输入扰动可能会导致不同的解释结果。因此，针对给定的XAI方法评估深度学习可解释性的鲁棒性至关重要。本文识别了现有技术无法共同应对的几个挑战：i)现有指标不全面；ii)XAI技术高度异质；iii)误解通常是罕见事件。为了解决这些挑战，我们引入了两种黑盒评估方法，分别涉及最坏情况解释差异和一般情况下的鲁棒性的概率概念。使用具有定制适应度函数的遗传算法（GA）来解决约束优化，以实现高效的最坏情况评估。使用专门用于估计罕见事件概率的子集模拟（SS）来进行整体评估。

    Interpretability of Deep Learning (DL) is a barrier to trustworthy AI. Despite great efforts made by the Explainable AI (XAI) community, explanations lack robustness -- indistinguishable input perturbations may lead to different XAI results. Thus, it is vital to assess how robust DL interpretability is, given an XAI method. In this paper, we identify several challenges that the state-of-the-art is unable to cope with collectively: i) existing metrics are not comprehensive; ii) XAI techniques are highly heterogeneous; iii) misinterpretations are normally rare events. To tackle these challenges, we introduce two black-box evaluation methods, concerning the worst-case interpretation discrepancy and a probabilistic notion of how robust in general, respectively. Genetic Algorithm (GA) with bespoke fitness function is used to solve constrained optimisation for efficient worst-case evaluation. Subset Simulation (SS), dedicated to estimate rare event probabilities, is used for evaluating overa
    
[^114]: 半监督的跨语言语音情绪识别

    Semi-supervised cross-lingual speech emotion recognition. (arXiv:2207.06767v2 [cs.SD] UPDATED)

    [http://arxiv.org/abs/2207.06767](http://arxiv.org/abs/2207.06767)

    通过半监督学习方法，我们提出了一种基于Transformer的半监督跨语言情绪识别方法，通过在未标注的语句上应用伪标签策略来适应新领域，有效解决了跨语言情绪识别中标注数据不足和领域差异大的问题。

    

    过去几年来，由于深度学习技术的使用，单语种语音情绪识别（SER）的性能大幅提升。然而，由于源语种和目标语种之间存在较大差异以及目标语种中缺乏标注数据，跨语言SER在实际应用中仍然是一个挑战。考虑到这些因素，本文提出了一种半监督学习方法，用于当目标语种（即新语言）中只有少量标注样本可用时的跨语言情绪识别。我们的方法基于Transformer，并通过在未标注的语句上利用伪标签策略来适应新领域。具体而言，我们研究了硬伪标签和软伪标签两种方法。我们对提出的方法在独立说话人的设定下进行了全面评估，同时涵盖了两个目标语种。

    Performance in Speech Emotion Recognition (SER) on a single language has increased greatly in the last few years thanks to the use of deep learning techniques. However, cross-lingual SER remains a challenge in real-world applications due to two main factors: the first is the big gap among the source and the target domain distributions; the second factor is the major availability of unlabeled utterances in contrast to the labeled ones for the new language. Taking into account previous aspects, we propose a Semi-Supervised Learning (SSL) method for cross-lingual emotion recognition when only few labeled examples in the target domain (i.e. the new language) are available. Our method is based on a Transformer and it adapts to the new domain by exploiting a pseudo-labeling strategy on the unlabeled utterances. In particular, the use of a hard and soft pseudo-labels approach is investigated. We thoroughly evaluate the performance of the proposed method in a speaker-independent setup on both 
    
[^115]: 基于分类的二值化：软函数真的必要吗？

    Binarizing by Classification: Is soft function really necessary?. (arXiv:2205.07433v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2205.07433](http://arxiv.org/abs/2205.07433)

    本文提出将网络二值化视为一个二值分类问题，使用多层感知器作为分类器和梯度估计器，以解决二值神经网络的梯度估计问题，从而实现更好的性能。

    

    二值神经网络利用"Sign"函数对权重和激活进行二值化，这需要梯度估计器来克服其不可微性，并且在反向传播过程中不可避免地带来梯度误差。虽然许多手动设计的软函数被提出作为梯度估计器以更好地逼近梯度，但它们的机制尚不清楚，并且二值模型与完全精度模型之间仍存在巨大的性能差距。为了解决这些问题并减少梯度误差，我们提出将网络二值化视为一个二值分类问题，并在前向传递中使用多层感知器（MLP）作为分类器以及在反向传递中作为梯度估计器。由于MLP具有适应任何连续函数的理论能力，它可以自适应地学习二值化网络并在没有任何先验知识的情况下反向传播梯度。从这个角度来看，我们进一步通过实验证明了即使在没有任何软函数的情况下，MLP也具有进行网络二值化和反向传播梯度的能力。

    Binary neural networks leverage $\mathrm{Sign}$ function to binarize weights and activations, which require gradient estimators to overcome its non-differentiability and will inevitably bring gradient errors during backpropagation. Although many hand-designed soft functions have been proposed as gradient estimators to better approximate gradients, their mechanism is not clear and there are still huge performance gaps between binary models and their full-precision counterparts. To address these issues and reduce gradient error, we propose to tackle network binarization as a binary classification problem and use a multi-layer perceptron (MLP) as the classifier in the forward pass and gradient estimator in the backward pass. Benefiting from the MLP's theoretical capability to fit any continuous function, it can be adaptively learned to binarize networks and backpropagate gradients without any prior knowledge of soft functions. From this perspective, we further empirically justify that eve
    
[^116]: 无监督发现和合成物体光场

    Unsupervised Discovery and Composition of Object Light Fields. (arXiv:2205.03923v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2205.03923](http://arxiv.org/abs/2205.03923)

    本文提出了一种无监督发现和合成物体光场的方法，通过将物体表示为以物体为中心的光场来提高渲染质量和操作效率。

    

    近期，神经场景表示法，包括连续和离散表示，已经成为三维场景理解的强大新范式。最近的研究致力于无监督发现以物体为中心的神经场景表示法。然而，射线行进的高成本，加上每个物体表示法都必须单独进行射线行进的事实，导致采样不足的亮度场，从而产生噪点渲染、低帧率、高内存和时间复杂度的训练和渲染。在这里，我们提出将物体以物体为中心的光场表示法来表示。我们提出了一种新颖的光场复合模块，可以从一组以物体为中心的光场重建全局光场。我们的方法被称为组合性物体光场（COLF），可以实现无监督学习以物体为中心的神经场景表示法，在标准数据集上实现最先进的重建和新视角合成性能。

    Neural scene representations, both continuous and discrete, have recently emerged as a powerful new paradigm for 3D scene understanding. Recent efforts have tackled unsupervised discovery of object-centric neural scene representations. However, the high cost of ray-marching, exacerbated by the fact that each object representation has to be ray-marched separately, leads to insufficiently sampled radiance fields and thus, noisy renderings, poor framerates, and high memory and time complexity during training and rendering. Here, we propose to represent objects in an object-centric, compositional scene representation as light fields. We propose a novel light field compositor module that enables reconstructing the global light field from a set of object-centric light fields. Dubbed Compositional Object Light Fields (COLF), our method enables unsupervised learning of object-centric neural scene representations, state-of-the-art reconstruction and novel view synthesis performance on standard 
    
[^117]: 探索无代理数据的分布式知识一致性在联邦蒸馏中的应用

    Exploring the Distributed Knowledge Congruence in Proxy-data-free Federated Distillation. (arXiv:2204.07028v4 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2204.07028](http://arxiv.org/abs/2204.07028)

    本文提出了一种基于分布式知识一致性的无代理数据联邦蒸馏算法，解决了客户端模型异质性引起的知识差异问题，从而提高了模型表示的准确性。

    

    联邦学习 (FL) 是一种保护隐私的机器学习范 paradigm, 在此服务器周期性地收集客户端的本地模型参数, 而不组装其私有数据. 有限的通讯和个性化需求对FL提出了严峻挑战. 联邦蒸馏 (FD) 被提出同时解决上述两个问题, 与此服务器和客户端之间交换知识, 支持异构本地模型同时显著减少通讯开销. 然而，大多数现有的FD方法需要一个代理数据集，而这在现实中通常是不可用的. 一些最近的无代理数据的FD方法可以消除额外的公共数据的需求, 但由于客户端模型的异质性而产生了明显的差异, 导致服务器上的模型表示不明确，并且不可避免地降低了准确性.

    Federated learning (FL) is a privacy-preserving machine learning paradigm in which the server periodically aggregates local model parameters from clients without assembling their private data.  Constrained communication and personalization requirements pose severe challenges to FL. Federated distillation (FD) is proposed to simultaneously address the above two problems, which exchanges knowledge between the server and clients, supporting heterogeneous local models while significantly reducing communication overhead. However, most existing FD methods require a proxy dataset, which is often unavailable in reality.  A few recent proxy-data-free FD approaches can eliminate the need for additional public data, but suffer from remarkable discrepancy among local knowledge due to client-side model heterogeneity, leading to ambiguous representation on the server and inevitable accuracy degradation.  To tackle this issue, we propose a proxy-data-free FD algorithm based on distributed knowledge c
    
[^118]: 视觉Transformer的参数高效模型适应

    Parameter-efficient Model Adaptation for Vision Transformers. (arXiv:2203.16329v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2203.16329](http://arxiv.org/abs/2203.16329)

    本文研究了针对图像分类任务的视觉Transformer的参数高效模型适应策略，通过将模型子模块投影到子空间进行分解，实现了性能与参数成本的平衡。

    

    在计算机视觉领域，通过将大规模预训练的视觉模型（例如，视觉Transformer）适应到下游任务中，实现了很好的迁移学习性能。常见的模型适应方法要么更新所有模型参数，要么利用线性探测器。本文旨在研究针对图像分类任务的视觉Transformer的参数高效模型适应策略。我们将高效模型适应形式化为一个子空间训练问题，并对不同的高效适应方法进行全面的基准测试。我们对每种高效模型适应方法进行了实证研究，重点关注其性能与参数成本的关系。此外，我们提出了一个参数高效模型适应框架，首先通过度量局部内在维度来选择子模块，然后通过一种新颖的Kronecker适应方法将它们投影到子空间进行进一步分解。我们对我们的方法与一个相似的方法进行了分析和比较。

    In computer vision, it has achieved great transfer learning performance via adapting large-scale pretrained vision models (e.g., vision transformers) to downstream tasks. Common approaches for model adaptation either update all model parameters or leverage linear probes. In this paper, we aim to study parameter-efficient model adaptation strategies for vision transformers on the image classification task. We formulate efficient model adaptation as a subspace training problem and perform a comprehensive benchmarking over different efficient adaptation methods. We conduct an empirical study on each efficient model adaptation method focusing on its performance alongside parameter cost. Furthermore, we propose a parameter-efficient model adaptation framework, which first selects submodules by measuring local intrinsic dimensions and then projects them into subspace for further decomposition via a novel Kronecker Adaptation (KAdaptation) method. We analyze and compare our method with a dive
    
[^119]: 自动学术论文审稿：概念、技术与挑战。

    Automated scholarly paper review: Concepts, technologies, and challenges. (arXiv:2111.07533v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2111.07533](http://arxiv.org/abs/2111.07533)

    提出自动学术论文审稿（ASPR）的概念和流程，综述了实现全面计算机化审稿流程的相关文献和技术，同时指出实现中存在的挑战，如文档解析和表达不完美、数据不足、人机交互缺陷和发现低质量文章的难度。

    

    同行评审是研究评价的广泛接受机制，在学术出版中扮演着重要的角色。然而，由于其效率低下和可重复性差，这一机制长期以来备受批评。近年来，人工智能应用于辅助同行评审。尽管如此，在涉及人员的情况下，这些限制仍是不可避免的。本文提出了自动学术论文审稿（ASPR）的概念和流程，并综述了实现全面计算机化审稿流程的相关文献和技术。在审查和讨论的基础上，我们得出结论：ASPR 的每个阶段已经有相应的研究和初步实施。我们还进一步探讨了ASPR存在的挑战。主要困难在于文档解析和表达不完美、数据不足、人机交互缺陷和发现低质量文章的难度。

    Peer review is a widely accepted mechanism for research evaluation, playing a pivotal role in academic publishing. However, criticisms have long been leveled on this mechanism, mostly because of its poor efficiency and low reproducibility. Recent years have seen the application of artificial intelligence (AI) in assisting the peer review process. Nonetheless, with the involvement of humans, such limitations remain inevitable. In this paper, we propose the concept and pipeline of automated scholarly paper review (ASPR) and review the relevant literature and technologies of achieving a full-scale computerized review process. On the basis of the review and discussion, we conclude that there is already corresponding research and preliminary implementation at each stage of ASPR. We further look into the challenges in ASPR with the existing technologies. The major difficulties lie in imperfect document parsing and representation, inadequate data, defective human-computer interaction, and fla
    
[^120]: 剪枝三值量化

    Pruning Ternary Quantization. (arXiv:2107.10998v5 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2107.10998](http://arxiv.org/abs/2107.10998)

    本文提出了一种剪枝三值量化方法（PTQ），通过集成L2归一化、剪枝和权重衰减项，实现同时优化比特宽度、模型大小和准确性，将模型大小大大减小且保持较高的测试准确性。

    

    推理时间、模型大小和准确性是深度模型压缩中的三个关键因素。现有的大部分工作将这三个关键因素分开处理，因为同时优化它们非常困难。例如，低比特量化旨在获得更快的模型；权重共享量化旨在提高压缩比和准确性；混合精度量化旨在平衡准确性和推理时间。为了同时优化比特宽度、模型大小和准确性，我们提出了剪枝三值量化（PTQ）：一种简单、有效、对称的三值量化方法。我们将L2归一化、剪枝和权重衰减项结合在一起，以减小量化过程中梯度估计器的权重差异，从而产生高度压缩的三值权重。我们的方法带来了最高的测试准确性和最高的压缩比。例如，它可以产生一个仅为939kb（49倍）的2位三值ResNet-18模型，仅准确性下降4％。

    Inference time, model size, and accuracy are three key factors in deep model compression. Most of the existing work addresses these three key factors separately as it is difficult to optimize them all at the same time. For example, low-bit quantization aims at obtaining a faster model; weight sharing quantization aims at improving compression ratio and accuracy; and mixed-precision quantization aims at balancing accuracy and inference time. To simultaneously optimize bit-width, model size, and accuracy, we propose pruning ternary quantization (PTQ): a simple, effective, symmetric ternary quantization method. We integrate L2 normalization, pruning, and the weight decay term to reduce the weight discrepancy in the gradient estimator during quantization, thus producing highly compressed ternary weights. Our method brings the highest test accuracy and the highest compression ratio. For example, it produces a 939kb (49$\times$) 2bit ternary ResNet-18 model with only 4\% accuracy drop on the
    
[^121]: 在流图中基于草图的异常检测

    Sketch-Based Anomaly Detection in Streaming Graphs. (arXiv:2106.04486v3 [cs.DS] UPDATED)

    [http://arxiv.org/abs/2106.04486](http://arxiv.org/abs/2106.04486)

    本文提出了在动态图中以在线的方式为边和子图分配异常分数的方法，其利用了扩展的草图数据结构，并且在真实数据集上表现优于现有的方法。

    

    在动态图的图边流中，如何以在线的方式为边和子图分配异常分数，以检测异常行为，并在常数时间和内存下进行？本文首先将计数最小化草图数据结构扩展为高阶草图，该高阶草图具有保留稠密子图结构的有用属性（输入中的稠密子图转化为数据结构中的密集子矩阵）。然后，我们提出了4个利用这个增强数据结构的在线算法，这些算法（a）同时检测边和图的异常；（b）以常数内存和常数更新时间处理每个新到达的边的边和图；（c）在4个真实数据集上优于现有的基线方法。我们的方法是第一个将稠密子图搜索纳入流式方法以检测图形异常的方法。

    Given a stream of graph edges from a dynamic graph, how can we assign anomaly scores to edges and subgraphs in an online manner, for the purpose of detecting unusual behavior, using constant time and memory? For example, in intrusion detection, existing work seeks to detect either anomalous edges or anomalous subgraphs, but not both. In this paper, we first extend the count-min sketch data structure to a higher-order sketch. This higher-order sketch has the useful property of preserving the dense subgraph structure (dense subgraphs in the input turn into dense submatrices in the data structure). We then propose 4 online algorithms that utilize this enhanced data structure, which (a) detect both edge and graph anomalies; (b) process each edge and graph in constant memory and constant update time per newly arriving edge, and; (c) outperform state-of-the-art baselines on 4 real-world datasets. Our method is the first streaming approach that incorporates dense subgraph search to detect gra
    
[^122]: 元素越笨，整体越聪明。或者，可能并非如此？

    The Less Intelligent the Elements, the More Intelligent the Whole. Or, Possibly Not?. (arXiv:2012.12689v2 [eess.SY] UPDATED)

    [http://arxiv.org/abs/2012.12689](http://arxiv.org/abs/2012.12689)

    我们探讨了个体智能是否对于集体智能的产生是必要的，以及怎样的个体智能有利于更大的集体智能。在Lotka-Volterra模型中，我们发现了一些个体行为，特别是掠食者的行为，有利于与其他种群共存，但如果猎物和掠食者都足够智能以推断彼此的行为，共存将伴随着两个种群的无限增长。

    

    我们探讨了大脑中的神经元与社会中的人类之间的利维坦类比，问自己是否个体智能对于集体智能的产生是必要的，更重要的是，怎样的个体智能有利于更大的集体智能。首先，我们回顾了连接主义认知科学、基于代理的建模、群体心理学、经济学和物理学的不同洞见。随后，我们将这些洞见应用于Lotka-Volterra模型中导致掠食者和猎物要么共存要么全球灭绝的智能类型和程度。我们发现几个个体行为 - 尤其是掠食者的行为 - 有利于共存，最终在一个平衡点周围产生震荡。然而，我们也发现，如果猎物和掠食者都足够智能以推断彼此的行为，共存就会伴随着两个种群的无限增长。由于Lotka-Volterra模型是不稳定的，我们提出了一些未来的研究方向来解决这个问题。

    We explore a Leviathan analogy between neurons in a brain and human beings in society, asking ourselves whether individual intelligence is necessary for collective intelligence to emerge and, most importantly, what sort of individual intelligence is conducive of greater collective intelligence. We first review disparate insights from connectionist cognitive science, agent-based modeling, group psychology, economics and physics. Subsequently, we apply these insights to the sort and degrees of intelligence that in the Lotka-Volterra model lead to either co-existence or global extinction of predators and preys.  We find several individual behaviors -- particularly of predators -- that are conducive to co-existence, eventually with oscillations around an equilibrium. However, we also find that if both preys and predators are sufficiently intelligent to extrapolate one other's behavior, co-existence comes along with indefinite growth of both populations. Since the Lotka-Volterra model is al
    
[^123]: MDP Playground: 一种用于强化学习的分析和调试测试平台

    MDP Playground: An Analysis and Debug Testbed for Reinforcement Learning. (arXiv:1909.07750v5 [cs.LG] UPDATED)

    [http://arxiv.org/abs/1909.07750](http://arxiv.org/abs/1909.07750)

    MDP Playground是一个用于强化学习的测试平台，可以根据不同维度的难度控制方式，挑战代理在各种环境中的表现。它提供了参数化的玩具环境集合，并通过实验揭示了这些环境对代理的影响。

    

    我们提出了MDP Playground，一个用于强化学习代理的测试平台，可以根据难度的不同维度进行控制，以挑战代理并在玩具和复杂的强化学习环境中获得不同程度的难度。我们考虑并允许对各种维度进行控制，包括延迟奖励、序列长度、奖励密度、随机性、图像表示、无关特征、时间单位、动作范围等。我们通过在OpenAI Gym中变化这些维度来定义一个参数化的快速运行的玩具环境集合，并建议使用这些环境来更好地了解代理。然后，我们展示了如何使用MDP Playground设计实验，以深入了解玩具环境。我们还提供了可以将许多这些维度注入到任何Gym环境中的包装器。我们在Atari和Mujoco上使用这些包装器进行实验，以了解这些维度对比玩具环境更复杂的环境的影响。

    We present MDP Playground, a testbed for Reinforcement Learning (RL) agents with dimensions of hardness that can be controlled independently to challenge agents in different ways and obtain varying degrees of hardness in toy and complex RL environments. We consider and allow control over a wide variety of dimensions, including delayed rewards, sequence lengths, reward density, stochasticity, image representations, irrelevant features, time unit, action range and more. We define a parameterised collection of fast-to-run toy environments in OpenAI Gym by varying these dimensions and propose to use these to understand agents better. We then show how to design experiments using MDP Playground to gain insights on the toy environments. We also provide wrappers that can inject many of these dimensions into any Gym environment. We experiment with these wrappers on Atari and Mujoco to allow for understanding the effects of these dimensions on environments that are more complex than the toy envi
    

