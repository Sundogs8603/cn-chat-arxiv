# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Push Past Green: Learning to Look Behind Plant Foliage by Moving It.](http://arxiv.org/abs/2307.03175) | 本文提出了一种通过移动植物来查看叶片背后内容的方法，通过使用自我监督训练了一个神经网络SRPNet，可以预测有效的显露出植物叶片下空间的动作，进一步可以通过执行一系列动作逐步显露出更多空间，实验结果表明该方法在合成和真实植物上都取得了良好的效果。 |
| [^2] | [LEO: Learning Efficient Orderings for Multiobjective Binary Decision Diagrams.](http://arxiv.org/abs/2307.03171) | 本论文研究了多目标BDD方法中变量排序的问题。通过推导出基于变量评分函数的参数配置空间，提高了多目标BDD方法的可扩展性，并使用黑箱优化技术高效地寻找解。 |
| [^3] | [Focused Transformer: Contrastive Training for Context Scaling.](http://arxiv.org/abs/2307.03170) | Focused Transformer通过反差训练优化了上下文缩放问题，允许语言模型处理更长的上下文信息。 |
| [^4] | [BrickPal: Augmented Reality-based Assembly Instructions for Brick Models.](http://arxiv.org/abs/2307.03162) | BrickPal是一种基于增强现实的积木模型装配指导系统，可通过自然语言处理技术生成装配顺序，并在增强现实头盔中提供实时指导。与传统方法相比，BrickPal能有效帮助用户进行积木装配，而且生成的装配顺序与手动调整的顺序具有相同的可用性。 |
| [^5] | [Distilling Large Vision-Language Model with Out-of-Distribution Generalizability.](http://arxiv.org/abs/2307.03135) | 本文研究了针对大型视觉语言模型的模型压缩方法，将教师模型的视觉表示压缩到学生模型中。研究重点在于超出分布可泛化的问题，并提出了两个原则来增强学生模型的性能。 |
| [^6] | [Learning Multi-Agent Intention-Aware Communication for Optimal Multi-Order Execution in Finance.](http://arxiv.org/abs/2307.03119) | 本文提出了一种多智能体强化学习方法，考虑实际约束下的多订单执行问题。通过智能体之间的通信与协作，最大化整体利润。现有的方法忽视了同时执行多个订单的情况，导致次优性和偏差。 |
| [^7] | [A Survey on Evaluation of Large Language Models.](http://arxiv.org/abs/2307.03109) | 本文综述了大型语言模型（LLMs）的评估方法，关注三个关键维度：评估什么、在哪里评估以及如何评估。评估任务包括自然语言处理、推理、医学应用、伦理学、教育、自然和社会科学、代理应用等多个领域。本文为社会层面对LLMs潜在风险的理解提供了重要参考。 |
| [^8] | [Efficient Domain Adaptation of Sentence Embeddings using Adapters.](http://arxiv.org/abs/2307.03104) | 本论文提出了一种通过训练轻量级适配器来高效域自适应句子嵌入的方法，避免了微调整个句子嵌入模型的资源消耗。通过训练特定领域的适配器，可以在不同领域中使用同一模型获得良好的性能。 |
| [^9] | [OpenDelta: A Plug-and-play Library for Parameter-efficient Adaptation of Pre-trained Models.](http://arxiv.org/abs/2307.03084) | OpenDelta是一个开源库，提供了各种delta调整方法的即插即用实现。它能够以高效的方式调整大型预训练模型的参数，而无需修改模型的代码，具有实用性和灵活性。 |
| [^10] | [DeepOnto: A Python Package for Ontology Engineering with Deep Learning.](http://arxiv.org/abs/2307.03067) | DeepOnto是一个Python包，用于深度学习本体工程。它通过集成深度学习框架和本体API，提供了丰富的工具和算法，支持本体工程任务，如本体对齐和完成。 |
| [^11] | [Generalizing Backpropagation for Gradient-Based Interpretability.](http://arxiv.org/abs/2307.03056) | 本论文在深度神经网络的特征解释中，泛化了反向传播算法，以便更好地理解梯度图的可解释统计数据，如最高加权路径和熵。作者通过在合成数据集上的评估和应用于BERT的实验中验证了该方法的有效性。 |
| [^12] | [Art Authentication with Vision Transformers.](http://arxiv.org/abs/2307.03039) | 本文研究使用视觉Transformer进行艺术认证，通过对比实验证明EfficientNet在该任务中表现最佳，提高了计算机辅助艺术品认证的可靠性。 |
| [^13] | [Sequential Neural Barriers for Scalable Dynamic Obstacle Avoidance.](http://arxiv.org/abs/2307.03015) | 我们提出了一种顺序神经控制屏障模型（SNCBFs）的组合学习方法，通过分解和预测障碍物的空间交互模式，实现可扩展的动态障碍物避障。 |
| [^14] | [Self-supervised Optimization of Hand Pose Estimation using Anatomical Features and Iterative Learning.](http://arxiv.org/abs/2307.03007) | 本文提出了一个自监督流程用于优化手势姿势估计，通过使用解剖特征和迭代学习，最终实现了基于姿势的活动识别的便宜且稳健的方法。 |
| [^15] | [A Privacy-Preserving Walk in the Latent Space of Generative Models for Medical Applications.](http://arxiv.org/abs/2307.02984) | 这项工作提出了一种潜在空间导航策略，通过使用辅助身份分类器作为导向，在潜在空间中生成多样化的合成样本，以支持深度模型的训练，并解决了由于使用生成对抗网络而导致的隐私问题。 |
| [^16] | [On the Cultural Gap in Text-to-Image Generation.](http://arxiv.org/abs/2307.02971) | 该论文研究文本到图像生成中的文化差异，并提出了一个具有挑战性的跨文化基准，通过分析已有模型在该基准上生成的有缺陷的图像，提出了使用对象-文本对齐的多模态度量来优化跨文化模型的微调数据。 |
| [^17] | [A Neuromorphic Architecture for Reinforcement Learning from Real-Valued Observations.](http://arxiv.org/abs/2307.02947) | 本文提出了一种新颖的神经网络架构，用于从实值观测中进行强化学习。该模型采用了多层事件驱动聚类、时间差分误差调制和资格痕迹等方法，并在经典RL环境中取得了优于表格方法的性能表现。 |
| [^18] | [In Time and Space: Towards Usable Adaptive Control for Assistive Robotic Arms.](http://arxiv.org/abs/2307.02933) | 本论文提出了一种利用前馈多模态反馈的自适应控制方法，通过更新的建议来实时比较映射，显著减少了用户在控制机器人臂时的认知负荷。 |
| [^19] | [LEA: Improving Sentence Similarity Robustness to Typos Using Lexical Attention Bias.](http://arxiv.org/abs/2307.02912) | 本论文提出了LEA模块，用于提高对打字错误的句子相似性鲁棒性。该模块通过引入词汇相似性来解决文本噪音问题，并避免了打字错误导致的标记分布偏移。 |
| [^20] | [Audio-visual End-to-end Multi-channel Speech Separation, Dereverberation and Recognition.](http://arxiv.org/abs/2307.02909) | 本文提出了一种视听端到端多通道语音分离、去混响和识别方法，该方法充分利用视觉信息，通过减小前后端组件之间的误差成本不匹配来提高语音识别的准确性。 |
| [^21] | [BaBE: Enhancing Fairness via Estimation of Latent Explaining Variables.](http://arxiv.org/abs/2307.02891) | 本文提出了一种名为BaBE的方法，通过估计潜在解释变量来提高公平性。该方法通过结合贝叶斯推断和期望最大化方法，估计给定Z的每个群体E的最可能值。 |
| [^22] | [Contrast Is All You Need.](http://arxiv.org/abs/2307.02882) | 对比学习方法在数据稀缺的法律分类场景中表现更好，使用SetFit微调的模型比普通微调使用更少的训练样本。LIME的结果显示，对比学习方法有助于提升对正面和负面特征的认知，这些特征在法律上具有信息量，并对分类结果有贡献。 |
| [^23] | [Towards a safe MLOps Process for the Continuous Development and Safety Assurance of ML-based Systems in the Railway Domain.](http://arxiv.org/abs/2307.02867) | 本文提出了一个安全的MLOps流程，用于在铁路领域中持续开发和安全保证基于机器学习系统的系统。该流程整合了系统工程、安全保证和机器学习生命周期，解决了再现性、可追溯性、协作性和持续适应性的问题。 |
| [^24] | [Enhancing LLM with Evolutionary Fine Tuning for News Summary Generation.](http://arxiv.org/abs/2307.02839) | 本论文提出一种新的方法使用LLM进行新闻摘要生成，通过进化调优事件模式群体，提高生成结果的准确性和可靠性。 |
| [^25] | [Evaluating raw waveforms with deep learning frameworks for speech emotion recognition.](http://arxiv.org/abs/2307.02820) | 本论文提出了一种直接将原始音频文件输入深度神经网络进行情感识别的模型，而无需进行特征提取阶段。通过在六个不同数据集上进行实验，作者展示了该模型的贡献，并将传统特征提取技术和多种机器学习算法、集成学习方法、深度学习技术相结合用于对比实验。 |
| [^26] | [Semi-supervised Domain Adaptive Medical Image Segmentation through Consistency Regularized Disentangled Contrastive Learning.](http://arxiv.org/abs/2307.02798) | 本文提出了一种半监督领域自适应医学图像分割方法，通过一致性规则解联对比学习实现了编码器的预训练，并结合解码器进行了进一步的微调。 |
| [^27] | [BHEISR: Nudging from Bias to Balance -- Promoting Belief Harmony by Eliminating Ideological Segregation in Knowledge-based Recommendations.](http://arxiv.org/abs/2307.02797) | BHEISR模型通过消除过滤泡沫效应，促进信念和谐，通过利用个性化的类别信息激发用户的好奇心和兴趣，鼓励用户拓宽信念视野和探索新的信息。 |
| [^28] | [What Should Data Science Education Do with Large Language Models?.](http://arxiv.org/abs/2307.02792) | 大型语言模型（LLM）正在改变数据科学家的责任和数据科学教育模式，从动手编码和标准分析转变为评估和管理自动化AI执行的分析。这种转变要求数据科学教育注重培养学生的多样化技能，如创造力、批判性思维和AI引导的编程。 |
| [^29] | [The Role of Subgroup Separability in Group-Fair Medical Image Classification.](http://arxiv.org/abs/2307.02791) | 本研究研究了深度分类器中的表现差异，发现分类器将个体分为子群的能力在医学成像模态和受保护特征方面存在显著差异，并证明了这个属性对算法偏见具有预测能力。通过理论分析和实证评估，我们发现子群可分性、子群差异和模型在存在系统偏见数据时的性能降级之间存在关系，这为公平医学成像人工智能的发展提供了重要的见解。 |
| [^30] | [Censored Sampling of Diffusion Models Using 3 Minutes of Human Feedback.](http://arxiv.org/abs/2307.02770) | 该论文研究了通过3分钟的人类反馈来扩散模型的有限采样，并表明仅几分钟的人类反馈生成的标签就足够实现图像的审查任务。 |
| [^31] | [PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations.](http://arxiv.org/abs/2307.02762) | 本研究提出了PRD算法，利用同行评级和讨论改善了基于大型语言模型的评估方法，解决了自我提升和位置偏见等问题。 |
| [^32] | [Knowledge Graph Self-Supervised Rationalization for Recommendation.](http://arxiv.org/abs/2307.02759) | 这项研究提出了一种新的自监督合理化方法KGRec，用于知识感知的推荐系统。通过关注知识合理化机制和生成对比度自监督任务，KGRec能够有效地识别有信息量的知识连接，并利用这些连接进行推荐。 |
| [^33] | [Offline Reinforcement Learning with Imbalanced Datasets.](http://arxiv.org/abs/2307.02752) | 本文提出了一种在不平衡数据集中的新型离线强化学习方法，通过将CQL与回溯过程相结合来提取策略，从而有效地解决了不平衡数据集带来的挑战。 |
| [^34] | [RecallM: An Architecture for Temporal Context Understanding and Question Answering.](http://arxiv.org/abs/2307.02738) | 本文介绍了一种名为RecallM的架构，用于创建可适应和可更新的长期记忆，以提升大型语言模型聊天机器人的时间理解能力。 |
| [^35] | [Fine-grained Action Analysis: A Multi-modality and Multi-task Dataset of Figure Skating.](http://arxiv.org/abs/2307.02730) | 这篇论文提出了一种多模态和多任务的花样滑冰数据集（MMFS），包含了256个类别的动作得分和空间和时间标签。该数据集的关键贡献是首次引入了独立的空间和时间分类，并首次使用骨骼模态进行精细动作质量评估。 |
| [^36] | [Hierarchical Empowerment: Towards Tractable Empowerment-Based Skill-Learning.](http://arxiv.org/abs/2307.02728) | 分层授权提出了一种可以计算授权的新框架，通过引入变分下界和分层架构，实现了在短期和长期时间尺度上的授权计算，并在模拟机器人任务中得到了验证。 |
| [^37] | [TL-nvSRAM-CIM: Ultra-High-Density Three-Level ReRAM-Assisted Computing-in-nvSRAM with DC-Power Free Restore and Ternary MAC Operations.](http://arxiv.org/abs/2307.02717) | TL-nvSRAM-CIM是一种新颖的存储器内计算方案，利用超高密度的三级ReRAM辅助计算来解决大规模神经网络模型中权重容量不足的问题，并采用了零直流功耗恢复和三态MAC操作来提高能效和保持准确性。 |
| [^38] | [Validation of the Practicability of Logical Assessment Formula for Evaluations with Inaccurate Ground-Truth Labels.](http://arxiv.org/abs/2307.02709) | 本文验证了逻辑评估公式在具有不准确的真实标签的评估中的实用性，通过将其应用于乳腺癌肿瘤分割在医学组织病理学全切片图像分析中的情况进行实验，结果表明LAF在这种情况下具有有效性，并展示了LAF在MHWSIA中的潜力。 |
| [^39] | [Loss Functions and Metrics in Deep Learning. A Review.](http://arxiv.org/abs/2307.02694) | 本文回顾了深度学习中最常见的损失函数和性能测量方法，旨在帮助从业者选择最适合其特定任务的方法。 |
| [^40] | [SACHA: Soft Actor-Critic with Heuristic-Based Attention for Partially Observable Multi-Agent Path Finding.](http://arxiv.org/abs/2307.02691) | 这篇论文提出了一种名为SACHA的基于启发式注意力的软演员批判器方法，用于解决部分可观察多智能体路径规划问题。通过引入新颖的启发式注意力机制，SACHA促进了智能体之间的合作，提高了复杂多智能体环境下的路径规划效果。 |
| [^41] | [Scaling In-Context Demonstrations with Structured Attention.](http://arxiv.org/abs/2307.02690) | 本研究提出了一种用于上下文学习的结构化注意力机制，解决了大规模语言模型在使用演示进行上下文学习时遇到的限制与挑战。 |
| [^42] | [AI4OPT: AI Institute for Advances in Optimization.](http://arxiv.org/abs/2307.02671) | AI4OPT是一个融合人工智能和优化的研究所，致力于解决供应链、能源系统、芯片设计与制造以及可持续食品系统等领域的问题，并提供工程教育中的人工智能教育路径。 |
| [^43] | [Convergence of Communications, Control, and Machine Learning for Secure and Autonomous Vehicle Navigation.](http://arxiv.org/abs/2307.02663) | 连接和自主驾驶车辆（CAVs）可以通过融合通信、控制和学习系统实现自主导航，但这带来了一些挑战，包括稳定路径跟踪、抗击网络物理攻击的强大控制和自适应导航控制器设计。 |
| [^44] | [Many-objective Optimization via Voting for Elites.](http://arxiv.org/abs/2307.02661) | 创新点：提出了多目标优化通过对精英进行投票（MOVE）的方法，结合多目标进化算法和质量多样性算法的元素，在解决多目标优化问题时具有较好的性能表现。 |
| [^45] | [Surge Routing: Event-informed Multiagent Reinforcement Learning for Autonomous Rideshare.](http://arxiv.org/abs/2307.02637) | 这项研究提出了一种基于事件信息的多智能体强化学习框架，用于自动拼车，通过预测和适应需求激增，并生成协同的路由和接乘策略来服务更多请求。 |
| [^46] | [An explainable model to support the decision about the therapy protocol for AML.](http://arxiv.org/abs/2307.02631) | 本文提出了一种可解释的机器学习模型，用于支持AML患者治疗方案的决策，解决了当前风险分类存在的问题和专家需求额外测试和分析的困扰。 |
| [^47] | [Real-time Workload Pattern Analysis for Large-scale Cloud Databases.](http://arxiv.org/abs/2307.02626) | 该论文提出了阿里巴巴工作负载矿工(AWM)，一个实时系统，用于在复杂的大规模工作负载中发现工作负载模式。通过对用户请求的SQL查询模式进行编码和发现，并基于发现的模式优化查询处理。该系统适用于大规模云数据库，可以更好地理解数据库系统的趋势和特征。 |
| [^48] | [Dynamic Observation Policies in Observation Cost-Sensitive Reinforcement Learning.](http://arxiv.org/abs/2307.02620) | 本文研究了在观测代价敏感强化学习中，强化学习代理在每个时间步不需要昂贵的测量，提出了一种新的方法DMSOA，并在多个环境中进行了评估，结果表明DMSOA能够以更少的决策步骤和测量次数学到更好的策略。 |
| [^49] | [Federated Epidemic Surveillance.](http://arxiv.org/abs/2307.02616) | 本研究旨在探索联邦方法在流行病监测中的应用。我们提出了一个假设检验框架，通过推送到保管人的防火墙并进行元分析，来解决数据分布和共享限制的问题。通过实验验证了我们的方法的有效性，并提出了适合的$p$-值合并方法。这些发现为联邦流行病监测提供了有价值的见解。 |
| [^50] | [Human Inspired Progressive Alignment and Comparative Learning for Grounded Word Acquisition.](http://arxiv.org/abs/2307.02615) | 本研究通过比较学习和渐进对齐的方式，借鉴人类语言习得的过程，探索了一种用于基于经验的词汇获取的计算过程。该方法不涉及固定的词汇量大小，也不涉及有区分性的目标，能够高效地持续学习更多的概念。 |
| [^51] | [Evade ChatGPT Detectors via A Single Space.](http://arxiv.org/abs/2307.02599) | 本研究发现，当前的ChatGPT检测器不能有效区分人类生成和AI生成内容之间的差异，而一个额外的空格成为了规避检测的关键因素。 |
| [^52] | [ODD: A Benchmark Dataset for the NLP-based Opioid Related Aberrant Behavior Detection.](http://arxiv.org/abs/2307.02591) | 这个研究介绍了一份名为ODD的新型基准数据集，用于通过分析患者的电子健康记录笔记，检测和分类药物滥用异常行为。这个数据集在药物相关病例的自然语言处理研究中具有重要的创新和贡献。 |
| [^53] | [TransformerG2G: Adaptive time-stepping for learning temporal graph embeddings using transformers.](http://arxiv.org/abs/2307.02588) | TransformerG2G是一种使用Transformer进行自适应时间步长的图嵌入模型，通过学习历史上的长程依赖关系，准确地捕捉时态图的动态特征。 |
| [^54] | [Exploring new ways: Enforcing representational dissimilarity to learn new features and reduce error consistency.](http://arxiv.org/abs/2307.02516) | 本文提出了一种新方法，利用表征差异性来降低模型的相关性和常见失败模式。通过使架构之间不同深度的中间表示具有差异性，以学习具有不同失败模式的强大集合，结果表明，这种方法可以提高集合的准确性。 |
| [^55] | [Exploring Multimodal Approaches for Alzheimer's Disease Detection Using Patient Speech Transcript and Audio Data.](http://arxiv.org/abs/2307.02514) | 本研究使用患者语音和转录数据，探索了多种方法来进行阿尔茨海默病（AD）的检测，包括使用预训练语言模型和图神经网络（GNN）来提取特征，并采用数据增强和音频数据的融合。最后尝试了一种对比学习方法。 |
| [^56] | [Diffusion Models for Computational Design at the Example of Floor Plans.](http://arxiv.org/abs/2307.02511) | 该论文探索了基于扩散模型的AI生成器在计算设计中的能力，并提出了具有改进的语义编码的新扩散模型。利用这些模型，可以提高生成楼层平面的有效性，并改进不同示例的查询性能。该研究还探讨了将扩散模型与建筑信息模型相结合的方法。 |
| [^57] | [STS-CCL: Spatial-Temporal Synchronous Contextual Contrastive Learning for Urban Traffic Forecasting.](http://arxiv.org/abs/2307.02507) | 本研究通过引入先进的对比学习方法，提出了一种新颖的时空同步上下文对比学习（STS-CCL）模型，用于高效地捕捉大规模无标签交通数据的复杂时空表示。该模型通过使用动态图视图生成器和语义上下文对比方法，实现了节点级和图级的对比学习。 |
| [^58] | [Natural Language Generation and Understanding of Big Code for AI-Assisted Programming: A Review.](http://arxiv.org/abs/2307.02503) | 这项综述回顾了大型代码训练的transformer-based大语言模型（LLMs）在AI辅助编程方面的应用，包括代码生成、代码摘要、缺陷检测等。同时讨论了将NLP技术与软件自然化相结合的挑战和机会。 |
| [^59] | [Math Agents: Computational Infrastructure, Mathematical Embedding, and Genomics.](http://arxiv.org/abs/2307.02502) | 本文提出了数学智能体和数学嵌入作为解决生成式人工智能在基因组学应用方面的局限性的新方法，通过使用基于GPT的工作流将文献中的方程转换为LaTeX和Python格式，以实现自动化的大规模评估和交互式计算。 |
| [^60] | [mPLUG-DocOwl: Modularized Multimodal Large Language Model for Document Understanding.](http://arxiv.org/abs/2307.02499) | mPLUG-DocOwl是一种模块化多模态大型语言模型，用于无OCR文档理解。它通过联合训练语言、通用视觉-语言和文档指令调优数据集，提升了无OCR文档理解能力。 |
| [^61] | [Anomaly detection in image or latent space of patch-based auto-encoders for industrial image analysis.](http://arxiv.org/abs/2307.02495) | 该论文研究了使用基于补丁自编码器构建的图像或潜在空间的多种方法来检测工业图像中的异常，并与其他两种方法进行了比较和评估。 |
| [^62] | [FREEDOM: Target Label & Source Data & Domain Information-Free Multi-Source Domain Adaptation for Unsupervised Personalization.](http://arxiv.org/abs/2307.02493) | 本文提出了一种新的问题场景TFDA，即三无领域自适应，解决了多源领域自适应中目标标签、源数据和领域信息不可用的问题。这种方法更加实用，避免了对先前领域信息的依赖和数据隐私问题。 |
| [^63] | [TablEye: Seeing small Tables through the Lens of Images.](http://arxiv.org/abs/2307.02491) | 本文提出了一种创新的框架TablEye，通过生成表格图像来实现领域转换，克服了形成表格数据先验知识的限制，从而实现了少样本表格学习。 |
| [^64] | [Visual Question Answering (VQA) on Images with Superimposed Text.](http://arxiv.org/abs/2307.02489) | 本研究探讨了在医学图像上叠加文本对VQA的影响，并发现这种做法不会严重降低VQA性能。这一发现对于验证在图像上叠加文本的实践方式具有重要意义，特别是在医学领域的VQA任务中使用AI技术。 |
| [^65] | [Deductive Additivity for Planning of Natural Language Proofs.](http://arxiv.org/abs/2307.02472) | 本论文研究了自然语言证明规划中的演绎可加性，探讨了是否能够通过嵌入空间实现高效的规划启发式方法。研究结果表明，嵌入空间的前提陈述总和接近于基于这些前提的结论嵌入。从而证明了演绎可加性的存在。 |
| [^66] | [Embodied Task Planning with Large Language Models.](http://arxiv.org/abs/2307.01848) | 本文提出了一个带有巨型语言模型的具身任务规划代理（TaPA），通过将LLM与视觉感知模型对齐，根据场景中已存在的对象生成可执行的计划。通过构建多模态数据集和利用GPT-3.5生成的数据对预训练模型进行具身计划的调优。 |
| [^67] | [Reliable AI: Does the Next Generation Require Quantum Computing?.](http://arxiv.org/abs/2307.01301) | 这项调查研究了下一代人工智能是否需要量子计算，发现数字硬件无法完全解决可靠性问题。 |
| [^68] | [REAL: A Representative Error-Driven Approach for Active Learning.](http://arxiv.org/abs/2307.00968) | 本研究提出了一种名为REAL的新方法，该方法通过选择具有代表性错误的数据实例来改进主动学习。通过考虑错误实例及其邻域中的错误密度，REAL在准确率和F1-macro得分方面优于其他算法。 |
| [^69] | [Image Matters: A New Dataset and Empirical Study for Multimodal Hyperbole Detection.](http://arxiv.org/abs/2307.00209) | 本研究提出了一个新的多模态夸张检测数据集，并使用文本和图像作为两种模态进行研究。同时，评估了不同预训练的多模态编码器在此任务中的表现。该研究探索了夸张检测的跨领域性能。 |
| [^70] | [Towards Open Vocabulary Learning: A Survey.](http://arxiv.org/abs/2306.15880) | 该论文调研了在视觉场景理解领域的开放词汇学习，在与零样本学习和开放集识别等相关概念的比较中，总结和分析了该领域的最新发展。 |
| [^71] | [UTRNet: High-Resolution Urdu Text Recognition In Printed Documents.](http://arxiv.org/abs/2306.15782) | 本文提出了一种解决印刷乌尔都文本识别挑战的新方法，并引入了大规模实际标记数据集和合成数据集，提供了乌尔都文本行检测的基准数据集，同时开发了一个在线工具，实现了印刷文档中乌尔都OCR的端到端识别。 |
| [^72] | [Chinese Fine-Grained Financial Sentiment Analysis with Large Language Models.](http://arxiv.org/abs/2306.14096) | 本文提出了一个用于企业预警的新型、广泛的中文细粒度金融情感分析数据集FinChina SA，并使用现有开源大语言模型对其进行评估和实验。该数据集将成为推进真实金融情感分析任务探索的宝贵资源。 |
| [^73] | [Active Policy Improvement from Multiple Black-box Oracles.](http://arxiv.org/abs/2306.10259) | 本研究提出了MAPS和MAPS-SE两个算法，可在多黑盒预言情况下，采用模仿学习并主动选择和改进最优预言，显著提升了性能。 |
| [^74] | [Stacking of Hyperparameter Tuned Models for Tagging Coding Problems.](http://arxiv.org/abs/2306.10077) | 这项工作使用超参数调优的增强模型堆叠方法，在Codeforces和Leetcode的数据集上取得了77.8%的准确率和0.815的PR-AUC分数。 |
| [^75] | [Look Beneath the Surface: Exploiting Fundamental Symmetry for Sample-Efficient Offline RL.](http://arxiv.org/abs/2306.04220) | 本文提出了一个新的离线强化学习算法TDM，利用系统动力学的基本对称性实现高效学习小数据集。 |
| [^76] | [Efficient automatic design of robots.](http://arxiv.org/abs/2306.03263) | 本论文首次使用进化计算和人工神经网络，能够在单个消费者级计算机上数秒内优化机器人结构以达到所需行为，为自动化设计复杂系统开辟了新的可能性。 |
| [^77] | [A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets.](http://arxiv.org/abs/2305.18486) | 本文对基准数据集上 ChatGPT 的性能进行了全面的评估，包括问答、文本摘要、代码生成、常识推理、数学问题求解、机器翻译、偏见检测和伦理考虑等任务。研究旨在验证 ChatGPT 的优势和弱点，并为使用语言模型的未来研究提供见解。 |
| [^78] | [Capturing Emerging Complexity in Lenia.](http://arxiv.org/abs/2305.09378) | 研究人工生命平台Lenia，通过识别复杂新兴行为的度量标准和使用遗传算法产生不同行为的结果，以进化出更好的Lenia行为。 |
| [^79] | [Fast and Multi-aspect Mining of Complex Time-stamped Event Streams.](http://arxiv.org/abs/2303.03789) | 这篇论文提出了一种名为CubeScope的方法，用于快速、多方面地挖掘复杂的时间戳事件流。该方法能够识别突然的不连续性和不同的动态模式，并对所有属性进行多方面摘要，并发现隐藏的群体和其关系。CubeScope还能检测到异常的突然出现。 |
| [^80] | [Denoise Pretraining on Nonequilibrium Molecules for Accurate and Transferable Neural Potentials.](http://arxiv.org/abs/2303.02216) | 该论文提出了一种用于准确和可迁移神经势的非平衡分子去噪预训练方法，并通过实验证明了该方法能显著提高势能模型的准确性和可迁移性。 |
| [^81] | [FederatedTrust: A Solution for Trustworthy Federated Learning.](http://arxiv.org/abs/2302.09844) | 本研究关注解决分布式数据隐私问题，提出了一个名为FederatedTrust的解决方案，旨在处理联邦学习模型的可信任性问题，包括健壮性、公平性、可解释性和问责制。 |
| [^82] | [Generation of Highlights from Research Papers Using Pointer-Generator Networks and SciBERT Embeddings.](http://arxiv.org/abs/2302.07729) | 该论文提出了一种使用指针生成网络和SciBERT嵌入来自动生成研究论文亮点的方法。在多个基准数据集上的实验证明，该模型在研究亮点生成方面具有最佳性能。 |
| [^83] | [Heckerthoughts.](http://arxiv.org/abs/2302.05449) | 这本论文是作者在斯坦福大学和微软研究院工作经验的技术回忆录，涉及了机器学习和人工智能的基本概念、应用以及创造过程中的故事。 |
| [^84] | [ESC: Exploration with Soft Commonsense Constraints for Zero-shot Object Navigation.](http://arxiv.org/abs/2301.13166) | 本文提出了一种新颖的零样本物体导航方法 ESC，它从预先训练的视觉和自然语言处理模型中转移常识知识，可在未知环境中进行导航，具有广阔的应用前景。 |
| [^85] | [Adapting Neural Link Predictors for Complex Query Answering.](http://arxiv.org/abs/2301.12313) | 本文提出通过训练一个参数高效的分数适应模型来重新校准神经链接预测分数以解决神经链接预测器在复杂查询回答中的问题。 |
| [^86] | [Memory-efficient NLLB-200: Language-specific Expert Pruning of a Massively Multilingual Machine Translation Model.](http://arxiv.org/abs/2212.09811) | 本研究提出了一种节约内存的NLLB-200模型修剪方法，可在保持翻译质量的同时移除多达80％的专家，使得在单个32GB的GPU上运行模型成为可能。这对于大规模多语言机器翻译具有重要的意义。 |
| [^87] | [Unbiased Heterogeneous Scene Graph Generation with Relation-aware Message Passing Neural Network.](http://arxiv.org/abs/2212.00443) | 本文提出了一种无偏见的异构场景图生成框架，使用关系感知消息传递神经网络捕获对象之间的上下文感知性，并设计了一种新的消息传递层来汇总图像的上下文信息。 |
| [^88] | [A Weakly-Supervised Streaming Multilingual Speech Model with Truly Zero-Shot Capability.](http://arxiv.org/abs/2211.02499) | 本文介绍了一个弱监督流式多语言语音模型，利用机器翻译服务将语音识别转录转化为弱监督数据来训练模型。该模型具有真正的零-shot能力，可以在扩展到新的目标语言时产生高质量的语音翻译结果。 |
| [^89] | [DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models.](http://arxiv.org/abs/2210.14896) | 介绍了DiffusionDB数据集，这是一个规模庞大的文本到图像提示数据集，总计包含1400万张图像和180万个唯一提示。该数据集被用来帮助研究人员解决文本提示生成图像时所需的适当提示的问题，并指出了一些特定的提示样式和超参数值可能导致模型错误，甚至生成误导信息。 |
| [^90] | [Spotting Virus from Satellites: Modeling the Circulation of West Nile Virus Through Graph Neural Networks.](http://arxiv.org/abs/2209.05251) | 本论文通过使用卫星图像来预测西尼罗河病毒的循环，提出了一种空间感知的方法，利用图神经网络(GNN)来聚合邻居的特征。 |
| [^91] | [Challenges and Opportunities in Offline Reinforcement Learning from Visual Observations.](http://arxiv.org/abs/2206.04779) | 该论文研究了离线强化学习从视觉观察中的挑战和机遇，针对这一复杂领域建立了视觉领域中连续控制的简单基准，并设计了一系列基准任务，以更好地表示现实世界离线RL问题中的数据分布，并通过对两种基于视觉的在线强化学习算法的简单修改进行评估。 |
| [^92] | [Machine Learning-Friendly Biomedical Datasets for Equivalence and Subsumption Ontology Matching.](http://arxiv.org/abs/2205.03447) | 本文介绍了五个新的生物医学本体匹配任务，通过引入机器学习技术并解决现有评估方法的限制，提供了综合评估框架来衡量本体匹配系统的性能。 |
| [^93] | [Potential sources of dataset bias complicate investigation of underdiagnosis by machine learning algorithms.](http://arxiv.org/abs/2201.07856) | 这项研究发现，机器学习算法在胸部X射线数据集上训练时会在未得到足够服务的人群中产生高虚报率，可能放大了系统的未诊断问题。然而，研究的实验设置不足以全面研究算法的未诊断问题，而且使用与训练数据相同偏倚的测试数据进一步加剧了结果的解释难度。 |
| [^94] | [AGM Belief Revision, Semantically.](http://arxiv.org/abs/2112.13557) | 本论文建立了关于实现最小变化范式的信念修正运算符的通用模型论刻画，适用于所有具有经典模型论语义的逻辑，包括以前缺乏刻画的形式主义。该研究通过推广Katsuno和Mendelzon的方法，为任意塔斯基逻辑的AGM风格修正提供了刻画方法。 |
| [^95] | [Balancing Biases and Preserving Privacy on Balanced Faces in the Wild.](http://arxiv.org/abs/2103.09118) | 本研究引入了平衡野外面孔数据集（BFW），通过该数据集我们发现人脸识别模型存在人口统计偏见。为了解决这个问题，我们提出了一种新颖的域自适应学习方案，该方案可以提高平均性能并保护隐私。 |
| [^96] | [Differentiable Logic Machines.](http://arxiv.org/abs/2102.11529) | 可微分逻辑机器 (DLM) 是一种新颖的神经逻辑架构，可以解决归纳逻辑编程 (ILP) 和强化学习 (RL) 问题，其创新之处在于定义了一种受限但富有表现力的一阶逻辑程序的连续松弛，并提供了可解释的解决方案。通过梯度下降进行训练，同时设计了一种新颖的评论家架构用于加速强化学习训练。 |
| [^97] | [A Time Leap Challenge for SAT Solving.](http://arxiv.org/abs/2008.02215) | SAT求解中，算法进步对硬件进步的影响至少同样重要。 |

# 详细

[^1]: 推开绿色：通过移动植物来查看植物叶片背后的内容的学习

    Push Past Green: Learning to Look Behind Plant Foliage by Moving It. (arXiv:2307.03175v1 [cs.RO])

    [http://arxiv.org/abs/2307.03175](http://arxiv.org/abs/2307.03175)

    本文提出了一种通过移动植物来查看叶片背后内容的方法，通过使用自我监督训练了一个神经网络SRPNet，可以预测有效的显露出植物叶片下空间的动作，进一步可以通过执行一系列动作逐步显露出更多空间，实验结果表明该方法在合成和真实植物上都取得了良好的效果。

    

    自主农业应用（例如检查、表型分析、采摘水果）需要操作植物叶片以查看叶子和枝干的背后。部分可见性、极端杂乱、薄结构以及植物的未知几何和动力学都使得这种操作具有挑战性。我们通过数据驱动的方法解决了这些挑战。我们使用自我监督来训练SRPNet，一个神经网络，该网络预测在给定植物上执行候选动作时会显露出多少空间。我们使用带有交叉熵方法的SRPNet来预测有效地显露出植物叶片下的空间的动作。此外，由于SRPNet不仅预测显露出多少空间，还预测显露出空间的位置，因此我们可以执行一系列动作，逐步显露出更多的植物叶片下的空间。在物理测试平台上，我们对合成的藤蔓和真实植物（龙血树）进行了实验，涵盖了5个设置，包括2个测试泛化性能的设置。

    Autonomous agriculture applications (e.g., inspection, phenotyping, plucking fruits) require manipulating the plant foliage to look behind the leaves and the branches. Partial visibility, extreme clutter, thin structures, and unknown geometry and dynamics for plants make such manipulation challenging. We tackle these challenges through data-driven methods. We use self-supervision to train SRPNet, a neural network that predicts what space is revealed on execution of a candidate action on a given plant. We use SRPNet with the cross-entropy method to predict actions that are effective at revealing space beneath plant foliage. Furthermore, as SRPNet does not just predict how much space is revealed but also where it is revealed, we can execute a sequence of actions that incrementally reveal more and more space beneath the plant foliage. We experiment with a synthetic (vines) and a real plant (Dracaena) on a physical test-bed across 5 settings including 2 settings that test generalization to
    
[^2]: LEO：学习高效有序的多目标二进制决策图

    LEO: Learning Efficient Orderings for Multiobjective Binary Decision Diagrams. (arXiv:2307.03171v1 [cs.AI])

    [http://arxiv.org/abs/2307.03171](http://arxiv.org/abs/2307.03171)

    本论文研究了多目标BDD方法中变量排序的问题。通过推导出基于变量评分函数的参数配置空间，提高了多目标BDD方法的可扩展性，并使用黑箱优化技术高效地寻找解。

    

    基于二进制决策图（BDD）的方法近年来在多目标整数规划问题中取得了最先进的结果。构建BDD时使用的变量排序对其大小以及由放松或限制的BDD导出的界限质量有重要影响，本文首先展示了变量排序对多目标背包问题的帕累托前沿（PF）枚举时间的类似影响，表明有必要推导出可提高多目标BDD方法可扩展性的变量排序方法。为此，我们推导出一个基于变量评分函数的新的参数配置空间，该评分函数在一小组可解释且易于计算的变量特征上是线性的。我们展示了如何使用黑箱优化高效地探索配置空间，避免了维度的诅咒（变量和目标的数量），并找到了良好的解。

    Approaches based on Binary decision diagrams (BDDs) have recently achieved state-of-the-art results for multiobjective integer programming problems. The variable ordering used in constructing BDDs can have a significant impact on their size and on the quality of bounds derived from relaxed or restricted BDDs for single-objective optimization problems. We first showcase a similar impact of variable ordering on the Pareto frontier (PF) enumeration time for the multiobjective knapsack problem, suggesting the need for deriving variable ordering methods that improve the scalability of the multiobjective BDD approach. To that end, we derive a novel parameter configuration space based on variable scoring functions which are linear in a small set of interpretable and easy-to-compute variable features. We show how the configuration space can be efficiently explored using black-box optimization, circumventing the curse of dimensionality (in the number of variables and objectives), and finding go
    
[^3]: Focused Transformer: 反差训练对上下文缩放进行优化

    Focused Transformer: Contrastive Training for Context Scaling. (arXiv:2307.03170v1 [cs.CL])

    [http://arxiv.org/abs/2307.03170](http://arxiv.org/abs/2307.03170)

    Focused Transformer通过反差训练优化了上下文缩放问题，允许语言模型处理更长的上下文信息。

    

    大规模语言模型能够以上下文化的方式吸纳新的信息，但由于有效上下文长度的限制，这种方法的潜力通常受到限制。解决这个问题的一种方法是为注意力层提供访问外部存储器的能力，该存储器由（键，值）对组成。然而，随着文档数量的增加，相关键与无关键的比例减少，使模型更加关注无关键。我们发现了一个名为分心问题的重要挑战，即与不同语义值相关联的键可能重叠，使它们难以区分。为了解决这个问题，我们引入了Focused Transformer（FoT），一种受对比学习启发的训练方法。这种新颖的方法增强了（键，值）空间的结构，使上下文长度得以扩展。我们的方法允许对现有大型模型进行微调，以更好地处理长上下文。

    Large language models have an exceptional capability to incorporate new information in a contextual manner. However, the full potential of such an approach is often restrained due to a limitation in the effective context length. One solution to this issue is to endow an attention layer with access to an external memory, which comprises of (key, value) pairs. Yet, as the number of documents increases, the proportion of relevant keys to irrelevant ones decreases, leading the model to focus more on the irrelevant keys. We identify a significant challenge, dubbed the distraction issue, where keys linked to different semantic values might overlap, making them hard to distinguish. To tackle this problem, we introduce the Focused Transformer (FoT), a technique that employs a training process inspired by contrastive learning. This novel approach enhances the structure of the (key, value) space, enabling an extension of the context length. Our method allows for fine-tuning pre-existing, large-s
    
[^4]: BrickPal:基于增强现实的积木模型装配指导书

    BrickPal: Augmented Reality-based Assembly Instructions for Brick Models. (arXiv:2307.03162v1 [cs.HC])

    [http://arxiv.org/abs/2307.03162](http://arxiv.org/abs/2307.03162)

    BrickPal是一种基于增强现实的积木模型装配指导系统，可通过自然语言处理技术生成装配顺序，并在增强现实头盔中提供实时指导。与传统方法相比，BrickPal能有效帮助用户进行积木装配，而且生成的装配顺序与手动调整的顺序具有相同的可用性。

    

    装配指导书是类似乐高积木套装的强制性组成部分。传统的装配指导书制作需要大量的手动调整，这对于休闲用户和定制积木套装来说是棘手的。此外，传统的纸质指导书缺乏表现力和互动性。为了解决以上两个问题，我们提出了BrickPal，一种基于增强现实的系统，该系统通过增强现实头戴显示器可视化装配指导书。它利用自然语言处理（NLP）技术生成合理的装配顺序，并在增强现实头盔中提供实时指导。我们的用户研究证明，与传统的装配方法相比，BrickPal在帮助用户进行积木装配方面是有效的。此外，NLP算法生成的装配顺序与手动调整的顺序具有相同的可用性。

    The assembly instruction is a mandatory component of Lego-like brick sets.The conventional production of assembly instructions requires a considerable amount of manual fine-tuning, which is intractable for casual users and customized brick sets.Moreover, the traditional paper-based instructions lack expressiveness and interactivity.To tackle the two problems above, we present BrickPal, an augmented reality-based system, which visualizes assembly instructions in an augmented reality head-mounted display. It utilizes Natural Language Processing (NLP) techniques to generate plausible assembly sequences, and provide real-time guidance in the AR headset.Our user study demonstrates BrickPal's effectiveness at assisting users in brick assembly compared to traditional assembly methods. Additionally, the NLP algorithm-generated assembly sequences achieve the same usability with manually adapted sequences.
    
[^5]: 用于超出分布可泛化性的大型视觉语言模型压缩

    Distilling Large Vision-Language Model with Out-of-Distribution Generalizability. (arXiv:2307.03135v1 [cs.CV])

    [http://arxiv.org/abs/2307.03135](http://arxiv.org/abs/2307.03135)

    本文研究了针对大型视觉语言模型的模型压缩方法，将教师模型的视觉表示压缩到学生模型中。研究重点在于超出分布可泛化的问题，并提出了两个原则来增强学生模型的性能。

    

    大型视觉语言模型取得了出色的性能，但其规模和计算要求使它们在资源受限设备和时间敏感任务上的部署变得不切实际。模型压缩是创建更小、更快的模型以保持较大模型性能的有希望的方法。本文研究了将大型视觉语言模型中的视觉表示压缩到轻量级学生模型中的过程，使用小型或中型数据集。值得注意的是，本研究关注的是超出分布（OOD）可泛化的开放词汇问题，这在以往的模型压缩研究中被忽视了。我们从视觉和语言的角度提出了两个原则来增强学生模型的OOD可泛化性：（1）更好地模仿教师的视觉表示空间，并在视觉语言对齐方面谨慎地促进更好的一致性；（2）通过丰富学生模型的自举学习和数据扩充来提高OOD可泛化性。

    Large vision-language models have achieved outstanding performance, but their size and computational requirements make their deployment on resource-constrained devices and time-sensitive tasks impractical. Model distillation, the process of creating smaller, faster models that maintain the performance of larger models, is a promising direction towards the solution. This paper investigates the distillation of visual representations in large teacher vision-language models into lightweight student models using a smallor mid-scale dataset. Notably, this study focuses on open-vocabulary out-of-distribution (OOD) generalization, a challenging problem that has been overlooked in previous model distillation literature. We propose two principles from vision and language modality perspectives to enhance student's OOD generalization: (1) by better imitating teacher's visual representation space, and carefully promoting better coherence in vision-language alignment with the teacher; (2) by enric
    
[^6]: 学习多智能体意图感知通信以实现金融中的最优多订单执行

    Learning Multi-Agent Intention-Aware Communication for Optimal Multi-Order Execution in Finance. (arXiv:2307.03119v1 [cs.AI])

    [http://arxiv.org/abs/2307.03119](http://arxiv.org/abs/2307.03119)

    本文提出了一种多智能体强化学习方法，考虑实际约束下的多订单执行问题。通过智能体之间的通信与协作，最大化整体利润。现有的方法忽视了同时执行多个订单的情况，导致次优性和偏差。

    

    订单执行是量化金融中的一个基本任务，旨在完成特定资产的一系列交易订单的收购或清算。最近无模型强化学习（RL）的进展为订单执行问题提供了一种数据驱动的解决方案。然而，现有的工作总是针对单个订单进行优化，忽视了同时执行多个订单的实践，导致次优性和偏差。在本文中，我们首先提出了一种考虑实际约束的多智能体强化学习（MARL）方法来执行多订单。具体而言，我们将每个智能体视为一个独立的操作员来交易一个特定的订单，同时保持彼此通信并协作以最大化总体利润。然而，现有的MARL算法通常通过仅交换部分观测信息来在智能体之间进行通信，这在复杂的金融环境中是低效的。

    Order execution is a fundamental task in quantitative finance, aiming at finishing acquisition or liquidation for a number of trading orders of the specific assets. Recent advance in model-free reinforcement learning (RL) provides a data-driven solution to the order execution problem. However, the existing works always optimize execution for an individual order, overlooking the practice that multiple orders are specified to execute simultaneously, resulting in suboptimality and bias. In this paper, we first present a multi-agent RL (MARL) method for multi-order execution considering practical constraints. Specifically, we treat every agent as an individual operator to trade one specific order, while keeping communicating with each other and collaborating for maximizing the overall profits. Nevertheless, the existing MARL algorithms often incorporate communication among agents by exchanging only the information of their partial observations, which is inefficient in complicated financial
    
[^7]: 对大型语言模型评估的调查

    A Survey on Evaluation of Large Language Models. (arXiv:2307.03109v1 [cs.CL])

    [http://arxiv.org/abs/2307.03109](http://arxiv.org/abs/2307.03109)

    本文综述了大型语言模型（LLMs）的评估方法，关注三个关键维度：评估什么、在哪里评估以及如何评估。评估任务包括自然语言处理、推理、医学应用、伦理学、教育、自然和社会科学、代理应用等多个领域。本文为社会层面对LLMs潜在风险的理解提供了重要参考。

    

    大型语言模型（LLMs）由于在各种应用中表现出的前所未有的性能而在学术界和工业界越来越受欢迎。随着LLMs在研究和日常使用中继续发挥着重要作用，它们的评估变得越来越关键，不仅在任务水平上，而且在社会层面上，以更好地了解它们的潜在风险。在过去的几年里，已经做出了相当大的努力来从不同的角度来研究LLMs。本文综述了LLMs的这些评估方法，重点关注三个关键维度：评估什么、在哪里评估以及如何评估。首先，我们从评估任务的角度提供了一个概述，涵盖了一般的自然语言处理任务、推理、医学应用、伦理学、教育、自然科学和社会科学、代理应用和其他领域。其次，我们通过深入探讨评估方法和基准答案来回答“在哪里”和“如何”这两个问题。

    Large language models (LLMs) are gaining increasing popularity in both academia and industry, owing to their unprecedented performance in various applications. As LLMs continue to play a vital role in both research and daily use, their evaluation becomes increasingly critical, not only at the task level, but also at the society level for better understanding of their potential risks. Over the past years, significant efforts have been made to examine LLMs from various perspectives. This paper presents a comprehensive review of these evaluation methods for LLMs, focusing on three key dimensions: what to evaluate, where to evaluate, and how to evaluate. Firstly, we provide an overview from the perspective of evaluation tasks, encompassing general natural language processing tasks, reasoning, medical usage, ethics, educations, natural and social sciences, agent applications, and other areas. Secondly, we answer the `where' and `how' questions by diving into the evaluation methods and bench
    
[^8]: 使用适配器高效域自适应句子嵌入

    Efficient Domain Adaptation of Sentence Embeddings using Adapters. (arXiv:2307.03104v1 [cs.CL])

    [http://arxiv.org/abs/2307.03104](http://arxiv.org/abs/2307.03104)

    本论文提出了一种通过训练轻量级适配器来高效域自适应句子嵌入的方法，避免了微调整个句子嵌入模型的资源消耗。通过训练特定领域的适配器，可以在不同领域中使用同一模型获得良好的性能。

    

    句子嵌入使我们能够捕捉短文本的语义相似性。大多数句子嵌入模型是针对一般语义文本相似性（STS）任务进行训练的。因此，要在特定领域中使用句子嵌入，必须将模型适应于该领域以获得良好的结果。通常，这是通过对感兴趣的域对整个句子嵌入模型进行微调来实现的。虽然这种方法能够产生最先进的结果，但在微调过程中更新了所有模型的权重，使该方法在资源上要求较高。因此，我们提出了训练轻量级适配器的方法，而不是单独为每个目标领域微调整个句子嵌入模型。这些特定领域的适配器不需要微调所有底层句子嵌入模型的参数。相反，我们只训练少量的额外参数，同时保持底层句子嵌入模型的权重不变。训练特定领域的适配器可以始终使用同一模型并在不同领域中获得良好的性能。

    Sentence embeddings enable us to capture the semantic similarity of short texts. Most sentence embedding models are trained for general semantic textual similarity (STS) tasks. Therefore, to use sentence embeddings in a particular domain, the model must be adapted to it in order to achieve good results. Usually, this is done by fine-tuning the entire sentence embedding model for the domain of interest. While this approach yields state-of-the-art results, all of the model's weights are updated during fine-tuning, making this method resource-intensive. Therefore, instead of fine-tuning entire sentence embedding models for each target domain individually, we propose to train lightweight adapters. These domain-specific adapters do not require fine-tuning all underlying sentence embedding model parameters. Instead, we only train a small number of additional parameters while keeping the weights of the underlying sentence embedding model fixed. Training domain-specific adapters allows always 
    
[^9]: OpenDelta: 一种用于参数高效调整预训练模型的即插即用库

    OpenDelta: A Plug-and-play Library for Parameter-efficient Adaptation of Pre-trained Models. (arXiv:2307.03084v1 [cs.LG])

    [http://arxiv.org/abs/2307.03084](http://arxiv.org/abs/2307.03084)

    OpenDelta是一个开源库，提供了各种delta调整方法的即插即用实现。它能够以高效的方式调整大型预训练模型的参数，而无需修改模型的代码，具有实用性和灵活性。

    

    大型预训练模型 (PTMs) 的规模给调整下游任务带来了重大挑战，原因是全参数微调涉及高昂的优化开销和存储成本。为了解决这个问题，许多研究探索了参数高效调整方法，也称为 "delta 调整"，即仅更新一小部分参数，称为 "delta 模块"，同时保持主干模型的参数固定。然而，由于现有实现直接修改主干 PTMs 的代码，并为每个 PTM 硬编码特定的 delta 调整方法，delta 调整的实用性和灵活性受到了限制。在本文中，我们提出了 OpenDelta，这是一个开源库，通过提供各种 delta 调整方法的即插即用实现来克服这些限制。我们的新技术消除了修改主干 PTMs 代码的需求，使 OpenDelta 可以与不同的、甚至是新的 PTMs 兼容。OpenDelta 的设计简单、可扩展，并且易于使用。

    The scale of large pre-trained models (PTMs) poses significant challenges in adapting to downstream tasks due to the high optimization overhead and storage costs associated with full-parameter fine-tuning. To address this, many studies explore parameter-efficient tuning methods, also framed as "delta tuning", which updates only a small subset of parameters, known as "delta modules", while keeping the backbone model's parameters fixed. However, the practicality and flexibility of delta tuning have been limited due to existing implementations that directly modify the code of the backbone PTMs and hard-code specific delta tuning methods for each PTM. In this paper, we present OpenDelta, an open-source library that overcomes these limitations by providing a plug-and-play implementation of various delta tuning methods. Our novel techniques eliminate the need to modify the backbone PTMs' code, making OpenDelta compatible with different, even novel PTMs. OpenDelta is designed to be simple, mo
    
[^10]: DeepOnto: 一个用于深度学习本体工程的Python包

    DeepOnto: A Python Package for Ontology Engineering with Deep Learning. (arXiv:2307.03067v1 [cs.AI])

    [http://arxiv.org/abs/2307.03067](http://arxiv.org/abs/2307.03067)

    DeepOnto是一个Python包，用于深度学习本体工程。它通过集成深度学习框架和本体API，提供了丰富的工具和算法，支持本体工程任务，如本体对齐和完成。

    

    应用深度学习技术，特别是语言模型（LMs），在本体工程中已经引起了广泛关注。然而，深度学习框架如PyTorch和Tensorflow主要是为Python开发的，而广泛使用的本体API（如OWL API和Jena）主要是基于Java的。为了方便无缝集成这些框架和API，我们提出了Deeponto，一个专为本体工程设计的Python包。该包包括一个基于广泛认可和可靠的OWL API的核心本体处理模块，以更“Pythonic”的方式封装其基本特性，并扩展其功能以包括其他重要组成部分，包括推理、语言化、规范化、投影等。基于这个模块，Deeponto提供了一套工具、资源和算法，支持各种本体工程任务，例如本体对齐和完成，利用深度学习方法实现。

    Applying deep learning techniques, particularly language models (LMs), in ontology engineering has raised widespread attention. However, deep learning frameworks like PyTorch and Tensorflow are predominantly developed for Python programming, while widely-used ontology APIs, such as the OWL API and Jena, are primarily Java-based. To facilitate seamless integration of these frameworks and APIs, we present Deeponto, a Python package designed for ontology engineering. The package encompasses a core ontology processing module founded on the widely-recognised and reliable OWL API, encapsulating its fundamental features in a more "Pythonic" manner and extending its capabilities to include other essential components including reasoning, verbalisation, normalisation, projection, and more. Building on this module, Deeponto offers a suite of tools, resources, and algorithms that support various ontology engineering tasks, such as ontology alignment and completion, by harnessing deep learning meth
    
[^11]: 泛化反向传播用于基于梯度的可解释性

    Generalizing Backpropagation for Gradient-Based Interpretability. (arXiv:2307.03056v1 [cs.LG])

    [http://arxiv.org/abs/2307.03056](http://arxiv.org/abs/2307.03056)

    本论文在深度神经网络的特征解释中，泛化了反向传播算法，以便更好地理解梯度图的可解释统计数据，如最高加权路径和熵。作者通过在合成数据集上的评估和应用于BERT的实验中验证了该方法的有效性。

    

    许多用于解释深度神经网络的流行特征归因方法依赖于计算模型输出对输入的梯度。虽然这些方法可以指示哪些输入特征可能对模型的预测很重要，但它们对模型本身的内部工作了解甚少。在本文中，我们观察到模型的梯度计算是使用半环的更一般形式的特例。这种观察使我们能够将反向传播算法泛化，以高效地计算关于神经网络梯度图的其他可解释统计数据，例如最高加权路径和熵。我们实现了这个泛化算法，在合成数据集上进行评估以更好地理解它计算的统计数据，并将其应用于研究BERT在主谓数一致性任务（SVA）上的行为。使用这种方法，我们验证了模型组件上通过的梯度流量反映了其重要性。

    Many popular feature-attribution methods for interpreting deep neural networks rely on computing the gradients of a model's output with respect to its inputs. While these methods can indicate which input features may be important for the model's prediction, they reveal little about the inner workings of the model itself. In this paper, we observe that the gradient computation of a model is a special case of a more general formulation using semirings. This observation allows us to generalize the backpropagation algorithm to efficiently compute other interpretable statistics about the gradient graph of a neural network, such as the highest-weighted path and entropy. We implement this generalized algorithm, evaluate it on synthetic datasets to better understand the statistics it computes, and apply it to study BERT's behavior on the subject-verb number agreement task (SVA). With this method, we (a) validate that the amount of gradient flow through a component of a model reflects its impor
    
[^12]: 使用视觉Transformer进行艺术认证

    Art Authentication with Vision Transformers. (arXiv:2307.03039v1 [cs.CV])

    [http://arxiv.org/abs/2307.03039](http://arxiv.org/abs/2307.03039)

    本文研究使用视觉Transformer进行艺术认证，通过对比实验证明EfficientNet在该任务中表现最佳，提高了计算机辅助艺术品认证的可靠性。

    

    近年来，Transformer模型在语言领域取得成功后，已成功应用于视觉任务。视觉Transformer已在包括图像分类、目标检测和语义分割等任务中推动了最新技术进展。尽管大量研究已证明使用卷积神经网络进行艺术归属和艺术认证任务取得了有希望的结果，本文重点研究了视觉Transformer在艺术认证方面的优势，并从而提高了计算机辅助艺术品认证的可靠性。使用由Vincent van Gogh真迹和两个对比数据集组成的精心编制的数据集，我们将Swin Transformer的艺术认证性能与EfficientNet进行了比较。通过使用包含模仿品和类似van Gogh风格画家作品的标准对比集，我们发现EfficientNet在整体上取得了最佳性能。

    In recent years, Transformers, initially developed for language, have been successfully applied to visual tasks. Vision Transformers have been shown to push the state-of-the-art in a wide range of tasks, including image classification, object detection, and semantic segmentation. While ample research has shown promising results in art attribution and art authentication tasks using Convolutional Neural Networks, this paper examines if the superiority of Vision Transformers extends to art authentication, improving, thus, the reliability of computer-based authentication of artworks. Using a carefully compiled dataset of authentic paintings by Vincent van Gogh and two contrast datasets, we compare the art authentication performances of Swin Transformers with those of EfficientNet. Using a standard contrast set containing imitations and proxies (works by painters with styles closely related to van Gogh), we find that EfficientNet achieves the best performance overall. With a contrast set th
    
[^13]: 可扩展动态障碍物避障的顺序神经屏障方法

    Sequential Neural Barriers for Scalable Dynamic Obstacle Avoidance. (arXiv:2307.03015v1 [cs.RO])

    [http://arxiv.org/abs/2307.03015](http://arxiv.org/abs/2307.03015)

    我们提出了一种顺序神经控制屏障模型（SNCBFs）的组合学习方法，通过分解和预测障碍物的空间交互模式，实现可扩展的动态障碍物避障。

    

    在扩大机器人围绕动态障碍物的导航时，存在两个主要挑战：障碍物的复杂交互动力学很难通过分析建模，而规划和控制的复杂性随障碍物数量的增加呈指数级增长。因此，在这种情况下，数据驱动和基于学习的方法尤为有价值。然而，数据驱动方法对分布漂移敏感，使得在不同障碍物密度下训练和推广学习模型变得困难。我们提出了一种新颖的顺序神经控制屏障模型（SNCBFs）的组合学习方法，以实现可扩展性。我们的方法利用了一个重要观察：多个动态障碍物的空间交互模式可以通过每个障碍物的状态的时间序列进行分解和预测。通过分解，我们可以将仅针对少量障碍物训练的控制策略推广到障碍物密度可以是100倍的环境中。

    There are two major challenges for scaling up robot navigation around dynamic obstacles: the complex interaction dynamics of the obstacles can be hard to model analytically, and the complexity of planning and control grows exponentially in the number of obstacles. Data-driven and learning-based methods are thus particularly valuable in this context. However, data-driven methods are sensitive to distribution drift, making it hard to train and generalize learned models across different obstacle densities. We propose a novel method for compositional learning of Sequential Neural Control Barrier models (SNCBFs) to achieve scalability. Our approach exploits an important observation: the spatial interaction patterns of multiple dynamic obstacles can be decomposed and predicted through temporal sequences of states for each obstacle. Through decomposition, we can generalize control policies trained only with a small number of obstacles, to environments where the obstacle density can be 100x hi
    
[^14]: 使用解剖特征和迭代学习的自监督手势姿势估计优化

    Self-supervised Optimization of Hand Pose Estimation using Anatomical Features and Iterative Learning. (arXiv:2307.03007v1 [cs.CV])

    [http://arxiv.org/abs/2307.03007](http://arxiv.org/abs/2307.03007)

    本文提出了一个自监督流程用于优化手势姿势估计，通过使用解剖特征和迭代学习，最终实现了基于姿势的活动识别的便宜且稳健的方法。

    

    手动装配工人在工作中面临着越来越复杂的情况。人性化辅助系统可以帮助解决问题，但作为实现技术的物体识别却阻碍了这些系统的复杂的人性化设计。同时，基于手势姿势的活动识别在复杂使用情景下（如佩戴手套）中存在姿势估计不准确的问题。本文提出了一个自监督的流程，用于将手势姿势估计适应特定的使用场景，并尽量减少人为干预。这使得基于手势姿势的活动识别更加廉价和稳健。该流程包括一个通用的机器学习模型，用于在广义数据集上训练手势姿势估计，空间和时间滤波以考虑手部解剖约束，以及一个重新训练的步骤来改进模型。在一个公开可用和注释的数据集上评估了不同的参数组合。然后将最佳参数和模型组合应用到未标记视频样本上，来验证效果。

    Manual assembly workers face increasing complexity in their work. Human-centered assistance systems could help, but object recognition as an enabling technology hinders sophisticated human-centered design of these systems. At the same time, activity recognition based on hand poses suffers from poor pose estimation in complex usage scenarios, such as wearing gloves. This paper presents a self-supervised pipeline for adapting hand pose estimation to specific use cases with minimal human interaction. This enables cheap and robust hand posebased activity recognition. The pipeline consists of a general machine learning model for hand pose estimation trained on a generalized dataset, spatial and temporal filtering to account for anatomical constraints of the hand, and a retraining step to improve the model. Different parameter combinations are evaluated on a publicly available and annotated dataset. The best parameter and model combination is then applied to unlabelled videos from a manual a
    
[^15]: 生成模型潜在空间中的隐私保护行走在医学应用中

    A Privacy-Preserving Walk in the Latent Space of Generative Models for Medical Applications. (arXiv:2307.02984v1 [cs.LG])

    [http://arxiv.org/abs/2307.02984](http://arxiv.org/abs/2307.02984)

    这项工作提出了一种潜在空间导航策略，通过使用辅助身份分类器作为导向，在潜在空间中生成多样化的合成样本，以支持深度模型的训练，并解决了由于使用生成对抗网络而导致的隐私问题。

    

    生成对抗网络（GANs）展示了它们生成与目标分布匹配的合成样本的能力。然而，从隐私角度来看，使用GAN作为数据共享的代理不是一个安全的解决方案，因为它们往往在潜在空间中嵌入接近真实样本的副本。最近的研究受k-匿名原则的启发，通过在潜在空间中对样本进行聚合来解决这个问题，但会减少数据集的大小。我们的工作旨在通过提出一种潜在空间导航策略来减轻这个问题，该策略能够生成多样化的合成样本，以支持深度模型的有效训练，并以原则性的方式解决隐私问题。我们的方法利用辅助身份分类器作为导向，在潜在空间中非线性地在点之间移动，最小化与接近真实样本的副本发生冲突的风险。我们通过实验证明，对于潜在空间中的任意随机点对，我们的方法能够生成多样化的合成样本，达到了同时解决隐私问题和有效训练的目的。

    Generative Adversarial Networks (GANs) have demonstrated their ability to generate synthetic samples that match a target distribution. However, from a privacy perspective, using GANs as a proxy for data sharing is not a safe solution, as they tend to embed near-duplicates of real samples in the latent space. Recent works, inspired by k-anonymity principles, address this issue through sample aggregation in the latent space, with the drawback of reducing the dataset by a factor of k. Our work aims to mitigate this problem by proposing a latent space navigation strategy able to generate diverse synthetic samples that may support effective training of deep models, while addressing privacy concerns in a principled way. Our approach leverages an auxiliary identity classifier as a guide to non-linearly walk between points in the latent space, minimizing the risk of collision with near-duplicates of real samples. We empirically demonstrate that, given any random pair of points in the latent sp
    
[^16]: 关于文本到图像生成中的文化差异

    On the Cultural Gap in Text-to-Image Generation. (arXiv:2307.02971v1 [cs.CV])

    [http://arxiv.org/abs/2307.02971](http://arxiv.org/abs/2307.02971)

    该论文研究文本到图像生成中的文化差异，并提出了一个具有挑战性的跨文化基准，通过分析已有模型在该基准上生成的有缺陷的图像，提出了使用对象-文本对齐的多模态度量来优化跨文化模型的微调数据。

    

    文本到图像（T2I）生成中的一个挑战是在训练数据中意外反映了文化差距，当输入文本的文化元素很少出现在训练集中时，这表明生成图像的质量差异。尽管各种T2I模型展示了令人印象深刻但是随意的例子，但是目前没有一个基准来系统评估T2I模型生成跨文化图像的能力。为了弥补这一差距，我们提出了一个具有综合评估标准的具有挑战性的跨文化（C3）基准，该基准可以评估模型对目标文化的适应性。通过分析在C3基准上由稳定扩散模型生成的有缺陷的图像，我们发现该模型经常无法生成特定的文化对象。因此，我们提出了一种考虑对象与文本对齐的新型多模态度量，用于过滤目标文化中的微调数据，用于优化跨文化能力的T2I模型。

    One challenge in text-to-image (T2I) generation is the inadvertent reflection of culture gaps present in the training data, which signifies the disparity in generated image quality when the cultural elements of the input text are rarely collected in the training set. Although various T2I models have shown impressive but arbitrary examples, there is no benchmark to systematically evaluate a T2I model's ability to generate cross-cultural images. To bridge the gap, we propose a Challenging Cross-Cultural (C3) benchmark with comprehensive evaluation criteria, which can assess how well-suited a model is to a target culture. By analyzing the flawed images generated by the Stable Diffusion model on the C3 benchmark, we find that the model often fails to generate certain cultural objects. Accordingly, we propose a novel multi-modal metric that considers object-text alignment to filter the fine-tuning data in the target culture, which is used to fine-tune a T2I model to improve cross-cultural g
    
[^17]: 一种从实值观测中进行强化学习的神经形态架构

    A Neuromorphic Architecture for Reinforcement Learning from Real-Valued Observations. (arXiv:2307.02947v1 [cs.NE])

    [http://arxiv.org/abs/2307.02947](http://arxiv.org/abs/2307.02947)

    本文提出了一种新颖的神经网络架构，用于从实值观测中进行强化学习。该模型采用了多层事件驱动聚类、时间差分误差调制和资格痕迹等方法，并在经典RL环境中取得了优于表格方法的性能表现。

    

    强化学习（RL）为复杂环境下的决策提供了一个强大的框架。然而，以高效且生物启发的方式实现RL仍然是一个挑战。本文提出了一种新颖的脉冲神经网络（SNN）架构，用于解决具有实值观测的RL问题。所提出的模型结合了多层事件驱动聚类，增加了时间差分（TD）误差调制和资格痕迹, 并基于之前的工作进行改进。消融研究证实了这些组成部分对所提出的模型性能的重要影响。在经典RL环境中，我们的网络不断优于表格方法，并成功发现了稳定的控制策略：山车、倒立摆和摆臂。所提出的模型在计算效率上具有吸引力的折中方案。

    Reinforcement Learning (RL) provides a powerful framework for decision-making in complex environments. However, implementing RL in hardware-efficient and bio-inspired ways remains a challenge. This paper presents a novel Spiking Neural Network (SNN) architecture for solving RL problems with real-valued observations. The proposed model incorporates multi-layered event-based clustering, with the addition of Temporal Difference (TD)-error modulation and eligibility traces, building upon prior work. An ablation study confirms the significant impact of these components on the proposed model's performance. A tabular actor-critic algorithm with eligibility traces and a state-of-the-art Proximal Policy Optimization (PPO) algorithm are used as benchmarks. Our network consistently outperforms the tabular approach and successfully discovers stable control policies on classic RL environments: mountain car, cart-pole, and acrobot. The proposed model offers an appealing trade-off in terms of computa
    
[^18]: 时间和空间：可用的辅助机器人臂自适应控制方向

    In Time and Space: Towards Usable Adaptive Control for Assistive Robotic Arms. (arXiv:2307.02933v1 [cs.HC])

    [http://arxiv.org/abs/2307.02933](http://arxiv.org/abs/2307.02933)

    本论文提出了一种利用前馈多模态反馈的自适应控制方法，通过更新的建议来实时比较映射，显著减少了用户在控制机器人臂时的认知负荷。

    

    机器人解决方案，特别是机器人臂，在与人类进行密切合作的情况下越来越频繁地部署，例如在制造或家庭护理环境中。这些机器人臂需要用户控制多个自由度（DoFs）来执行任务，主要涉及抓取和操作物体。标准输入设备主要具有两个DoFs，需要耗时且认知负荷大的模式切换来选择单个DoFs。现代自适应DoF映射控制（ADMCs）已经显示可以减少必要的模式切换次数，但尚未能显著降低感知工作负荷。用户仍然承担将抽象模式切换纳入工作流程的心理负担。我们通过提供前馈多模态反馈，使用ADMC的更新建议，使用户能够实时视觉比较当前和建议的映射，从而解决了这个问题。

    Robotic solutions, in particular robotic arms, are becoming more frequently deployed for close collaboration with humans, for example in manufacturing or domestic care environments. These robotic arms require the user to control several Degrees-of-Freedom (DoFs) to perform tasks, primarily involving grasping and manipulating objects. Standard input devices predominantly have two DoFs, requiring time-consuming and cognitively demanding mode switches to select individual DoFs. Contemporary Adaptive DoF Mapping Controls (ADMCs) have shown to decrease the necessary number of mode switches but were up to now not able to significantly reduce the perceived workload. Users still bear the mental workload of incorporating abstract mode switching into their workflow. We address this by providing feed-forward multimodal feedback using updated recommendations of ADMC, allowing users to visually compare the current and the suggested mapping in real-time. We contrast the effectiveness of two new appr
    
[^19]: LEA: 使用词汇注意偏差提高对打字错误的句子相似性鲁棒性

    LEA: Improving Sentence Similarity Robustness to Typos Using Lexical Attention Bias. (arXiv:2307.02912v1 [cs.CL])

    [http://arxiv.org/abs/2307.02912](http://arxiv.org/abs/2307.02912)

    本论文提出了LEA模块，用于提高对打字错误的句子相似性鲁棒性。该模块通过引入词汇相似性来解决文本噪音问题，并避免了打字错误导致的标记分布偏移。

    

    文本噪音，如打字错误或缩写，是一个众所周知的问题，会对大多数下游任务中的纯变压器模型造成惩罚。我们展示了这也适用于句子相似性，这是多个领域中的一个基本任务，比如匹配、检索或释义。可以使用交叉编码器来处理句子相似性，其中两个句子在输入中连接，使模型能够利用它们之间的相互关系。之前解决噪音问题的工作主要依赖于数据增强策略，展示了在处理与训练样本相似的损坏样本时性能有所提升。然而，所有这些方法仍然受到打字错误引起的标记分布偏移的影响。在这项工作中，我们提出使用一种新颖的词汇感知注意模块（LEA）来解决文本噪音问题，该模块在两个句子中的词之间引入了词汇相似性。通过使用原始文本相似性，我们的方法避免了token分布偏移的问题。

    Textual noise, such as typos or abbreviations, is a well-known issue that penalizes vanilla Transformers for most downstream tasks. We show that this is also the case for sentence similarity, a fundamental task in multiple domains, e.g. matching, retrieval or paraphrasing. Sentence similarity can be approached using cross-encoders, where the two sentences are concatenated in the input allowing the model to exploit the inter-relations between them. Previous works addressing the noise issue mainly rely on data augmentation strategies, showing improved robustness when dealing with corrupted samples that are similar to the ones used for training. However, all these methods still suffer from the token distribution shift induced by typos. In this work, we propose to tackle textual noise by equipping cross-encoders with a novel LExical-aware Attention module (LEA) that incorporates lexical similarities between words in both sentences. By using raw text similarities, our approach avoids the to
    
[^20]: 视听端到端多通道语音分离、去混响和识别

    Audio-visual End-to-end Multi-channel Speech Separation, Dereverberation and Recognition. (arXiv:2307.02909v1 [eess.AS])

    [http://arxiv.org/abs/2307.02909](http://arxiv.org/abs/2307.02909)

    本文提出了一种视听端到端多通道语音分离、去混响和识别方法，该方法充分利用视觉信息，通过减小前后端组件之间的误差成本不匹配来提高语音识别的准确性。

    

    准确识别包含重叠发言者、噪声和混响的混音语音仍然是一项具有挑战性的任务。本文提出了一种视听多通道语音分离、去混响和识别方法，该方法充分将视觉信息融入到所有系统组件中，基于视觉模态与声学信号失真之间的不变性。视频输入在基于掩蔽的MVDR语音分离、基于DNN-WPE或光谱映射（SpecM）的语音去混响前端和Conformer ASR后端中的有效性得到了持续的证明。研究了执行语音分离和去混响的视听一体化前端架构，通过基于掩蔽的WPD以流水线或联合方式进行。通过端到端联合微调，使用ASR成本函数单独或与其线性插值，最小化语音增强前端和ASR后端组件之间的误差成本不匹配。

    Accurate recognition of cocktail party speech containing overlapping speakers, noise and reverberation remains a highly challenging task to date. Motivated by the invariance of visual modality to acoustic signal corruption, an audio-visual multi-channel speech separation, dereverberation and recognition approach featuring a full incorporation of visual information into all system components is proposed in this paper. The efficacy of the video input is consistently demonstrated in mask-based MVDR speech separation, DNN-WPE or spectral mapping (SpecM) based speech dereverberation front-end and Conformer ASR back-end. Audio-visual integrated front-end architectures performing speech separation and dereverberation in a pipelined or joint fashion via mask-based WPD are investigated. The error cost mismatch between the speech enhancement front-end and ASR back-end components is minimized by end-to-end jointly fine-tuning using either the ASR cost function alone, or its interpolation with the
    
[^21]: BaBE:通过估计潜在解释变量增强公平性

    BaBE: Enhancing Fairness via Estimation of Latent Explaining Variables. (arXiv:2307.02891v1 [cs.LG])

    [http://arxiv.org/abs/2307.02891](http://arxiv.org/abs/2307.02891)

    本文提出了一种名为BaBE的方法，通过估计潜在解释变量来提高公平性。该方法通过结合贝叶斯推断和期望最大化方法，估计给定Z的每个群体E的最可能值。

    

    本文考虑了两个群体之间不公平歧视的问题，并提出了一种预处理方法来实现公平性。我们提出了一种基于贝叶斯推断和期望最大化方法的BaBE (Bayesian Bias Elimination)方法，用于估计给定Z的每个群体的E的最可能值。

    We consider the problem of unfair discrimination between two groups and propose a pre-processing method to achieve fairness. Corrective methods like statistical parity usually lead to bad accuracy and do not really achieve fairness in situations where there is a correlation between the sensitive attribute S and the legitimate attribute E (explanatory variable) that should determine the decision. To overcome these drawbacks, other notions of fairness have been proposed, in particular, conditional statistical parity and equal opportunity. However, E is often not directly observable in the data, i.e., it is a latent variable. We may observe some other variable Z representing E, but the problem is that Z may also be affected by S, hence Z itself can be biased. To deal with this problem, we propose BaBE (Bayesian Bias Elimination), an approach based on a combination of Bayes inference and the Expectation-Maximization method, to estimate the most likely value of E for a given Z for each grou
    
[^22]: 对比就是你所需的一切

    Contrast Is All You Need. (arXiv:2307.02882v1 [cs.CL])

    [http://arxiv.org/abs/2307.02882](http://arxiv.org/abs/2307.02882)

    对比学习方法在数据稀缺的法律分类场景中表现更好，使用SetFit微调的模型比普通微调使用更少的训练样本。LIME的结果显示，对比学习方法有助于提升对正面和负面特征的认知，这些特征在法律上具有信息量，并对分类结果有贡献。

    

    在这项研究中，我们分析了数据稀缺的分类场景，其中可用的标记法律数据很少且不平衡，可能会影响结果的质量。我们重点关注了两个微调目标：SetFit（句子转换器微调），一种对比学习设置，以及在法律条款分类任务上的普通微调设置。此外，我们使用LIME（局部可解释模型无关解释）比较了提取的特征，以查看哪些特定特征对模型的分类决策有贡献。结果显示，与使用相同数量的训练样本的普通微调相比，使用SetFit的对比设置表现更好。LIME的结果显示，对比学习方法有助于提升对正面和负面特征的认知，这些特征在法律上具有信息量，并对分类结果有贡献。因此，使用对比目标进行微调的模型似乎更自信地基于法律信息进行决策。

    In this study, we analyze data-scarce classification scenarios, where available labeled legal data is small and imbalanced, potentially hurting the quality of the results. We focused on two finetuning objectives; SetFit (Sentence Transformer Finetuning), a contrastive learning setup, and a vanilla finetuning setup on a legal provision classification task. Additionally, we compare the features that are extracted with LIME (Local Interpretable Model-agnostic Explanations) to see which particular features contributed to the model's classification decisions. The results show that a contrastive setup with SetFit performed better than vanilla finetuning while using a fraction of the training samples. LIME results show that the contrastive learning approach helps boost both positive and negative features which are legally informative and contribute to the classification results. Thus a model finetuned with a contrastive objective seems to base its decisions more confidently on legally informa
    
[^23]: 在铁路领域中持续开发和安全保证基于机器学习系统的安全MLOps流程

    Towards a safe MLOps Process for the Continuous Development and Safety Assurance of ML-based Systems in the Railway Domain. (arXiv:2307.02867v1 [cs.SE])

    [http://arxiv.org/abs/2307.02867](http://arxiv.org/abs/2307.02867)

    本文提出了一个安全的MLOps流程，用于在铁路领域中持续开发和安全保证基于机器学习系统的系统。该流程整合了系统工程、安全保证和机器学习生命周期，解决了再现性、可追溯性、协作性和持续适应性的问题。

    

    传统的自动化技术单独并不足以实现非受限基础设施上的无人驾驶列车运行（称为GoA 4）。现今，所需的感知任务通过机器学习（ML）实现，因此需要可靠高效地开发和部署。达到这个目标的一个重要方面是使用一个安全的MLOps流程，用于解决改进再现性、可追溯性、协作性和无人驾驶运营对不断变化的条件的持续适应性。MLOps结合了机器学习应用开发和操作（Ops），基于运营反馈实现高频软件发布和持续创新。本文概述了在铁路领域中持续开发和安全保证基于机器学习系统的安全MLOps流程。它将系统工程、安全保证和机器学习生命周期融入一个全面的工作流程中。我们介绍了流程的各个阶段和它们之间的相互关系。

    Traditional automation technologies alone are not sufficient to enable driverless operation of trains (called Grade of Automation (GoA) 4) on non-restricted infrastructure. The required perception tasks are nowadays realized using Machine Learning (ML) and thus need to be developed and deployed reliably and efficiently. One important aspect to achieve this is to use an MLOps process for tackling improved reproducibility, traceability, collaboration, and continuous adaptation of a driverless operation to changing conditions. MLOps mixes ML application development and operation (Ops) and enables high frequency software releases and continuous innovation based on the feedback from operations. In this paper, we outline a safe MLOps process for the continuous development and safety assurance of ML-based systems in the railway domain. It integrates system engineering, safety assurance, and the ML life-cycle in a comprehensive workflow. We present the individual stages of the process and thei
    
[^24]: 使用进化调优增强LLM进行新闻摘要生成

    Enhancing LLM with Evolutionary Fine Tuning for News Summary Generation. (arXiv:2307.02839v1 [cs.CL])

    [http://arxiv.org/abs/2307.02839](http://arxiv.org/abs/2307.02839)

    本论文提出一种新的方法使用LLM进行新闻摘要生成，通过进化调优事件模式群体，提高生成结果的准确性和可靠性。

    

    新闻摘要生成是情报分析领域中的重要任务，可以提供准确全面的信息，帮助人们更好地理解和应对复杂的现实事件。然而，传统的新闻摘要生成方法面临一些挑战，包括模型本身和训练数据量的限制，以及文本噪声的影响，使得准确生成可靠信息变得困难。本文提出了一种使用具有强大自然语言理解和生成能力的LLM进行新闻摘要生成的新范式。我们利用LLM从新闻段落中提取多个结构化事件模式，通过遗传算法进化事件模式群体，并选择最适应的事件模式输入LLM生成新闻摘要。设计了一个新闻摘要生成器(NSG)来选择和进化事件模式群体，并生成新闻摘要。

    News summary generation is an important task in the field of intelligence analysis, which can provide accurate and comprehensive information to help people better understand and respond to complex real-world events. However, traditional news summary generation methods face some challenges, which are limited by the model itself and the amount of training data, as well as the influence of text noise, making it difficult to generate reliable information accurately. In this paper, we propose a new paradigm for news summary generation using LLM with powerful natural language understanding and generative capabilities. We use LLM to extract multiple structured event patterns from the events contained in news paragraphs, evolve the event pattern population with genetic algorithm, and select the most adaptive event pattern to input into the LLM to generate news summaries. A News Summary Generator (NSG) is designed to select and evolve the event pattern populations and generate news summaries. T
    
[^25]: 用深度学习框架评估原始波形进行语音情感识别

    Evaluating raw waveforms with deep learning frameworks for speech emotion recognition. (arXiv:2307.02820v1 [cs.SD])

    [http://arxiv.org/abs/2307.02820](http://arxiv.org/abs/2307.02820)

    本论文提出了一种直接将原始音频文件输入深度神经网络进行情感识别的模型，而无需进行特征提取阶段。通过在六个不同数据集上进行实验，作者展示了该模型的贡献，并将传统特征提取技术和多种机器学习算法、集成学习方法、深度学习技术相结合用于对比实验。

    

    语音情感识别是语音处理领域中的一个具有挑战性的任务。为了展示和处理语音信号，特征提取过程具有重要意义。在这项工作中，我们提出了一个模型，将原始音频文件直接输入深度神经网络进行情感识别，而无需进行任何特征提取阶段，利用了六个不同的数据集：EMO-DB、RAVDESS、TESS、CREMA、SAVEE和TESS+RAVDESS。为了展示所提出模型的贡献，我们将传统的特征提取技术（如梅尔频谱图、梅尔频率倒谱系数）与机器学习算法、集成学习方法、深度学习和混合深度学习技术相结合。我们评估了支持向量机、决策树、朴素贝叶斯、随机森林模型作为机器学习算法，以及多数投票和堆叠方法作为集成学习技术。此外，我们还评估了卷积神经网络、遗传算法和深度卷积神经网络作为深度学习技术。

    Speech emotion recognition is a challenging task in speech processing field. For this reason, feature extraction process has a crucial importance to demonstrate and process the speech signals. In this work, we represent a model, which feeds raw audio files directly into the deep neural networks without any feature extraction stage for the recognition of emotions utilizing six different data sets, EMO-DB, RAVDESS, TESS, CREMA, SAVEE, and TESS+RAVDESS. To demonstrate the contribution of proposed model, the performance of traditional feature extraction techniques namely, mel-scale spectogram, mel-frequency cepstral coefficients, are blended with machine learning algorithms, ensemble learning methods, deep and hybrid deep learning techniques. Support vector machine, decision tree, naive Bayes, random forests models are evaluated as machine learning algorithms while majority voting and stacking methods are assessed as ensemble learning techniques. Moreover, convolutional neural networks, lo
    
[^26]: 通过一致性规则解联对比学习进行半监督领域自适应医学图像分割

    Semi-supervised Domain Adaptive Medical Image Segmentation through Consistency Regularized Disentangled Contrastive Learning. (arXiv:2307.02798v1 [cs.CV])

    [http://arxiv.org/abs/2307.02798](http://arxiv.org/abs/2307.02798)

    本文提出了一种半监督领域自适应医学图像分割方法，通过一致性规则解联对比学习实现了编码器的预训练，并结合解码器进行了进一步的微调。

    

    尽管无监督领域自适应（UDA）是缓解领域偏移的一种有前途的方法，但它们的表现不及其监督对应方法。在这项工作中，我们研究了相对较少探索的半监督领域自适应（SSDA）用于医学图像分割，其中对一些标记的目标样本的访问可以大大改善适应性能。具体地，我们提出了一个两阶段的训练过程。首先，我们使用一种新颖的领域内容解联对比学习（CL）和像素级特征一致性约束，在自学习范式中预训练编码器。所提出的CL从源图像和目标图像中强制编码器学习区分性内容特定但领域不变的语义，而一致性规则通过保持空间敏感性来强制挖掘局部像素级信息。然后，对这个预训练的编码器和解码器进行进一步的下游任务微调。

    Although unsupervised domain adaptation (UDA) is a promising direction to alleviate domain shift, they fall short of their supervised counterparts. In this work, we investigate relatively less explored semi-supervised domain adaptation (SSDA) for medical image segmentation, where access to a few labeled target samples can improve the adaptation performance substantially. Specifically, we propose a two-stage training process. First, an encoder is pre-trained in a self-learning paradigm using a novel domain-content disentangled contrastive learning (CL) along with a pixel-level feature consistency constraint. The proposed CL enforces the encoder to learn discriminative content-specific but domain-invariant semantics on a global scale from the source and target images, whereas consistency regularization enforces the mining of local pixel-level information by maintaining spatial sensitivity. This pre-trained encoder, along with a decoder, is further fine-tuned for the downstream task, (i.e
    
[^27]: BHEISR: 从偏见到平衡 - 消除基于知识的推荐中的意识形态隔离，促进信念和谐

    BHEISR: Nudging from Bias to Balance -- Promoting Belief Harmony by Eliminating Ideological Segregation in Knowledge-based Recommendations. (arXiv:2307.02797v1 [cs.IR])

    [http://arxiv.org/abs/2307.02797](http://arxiv.org/abs/2307.02797)

    BHEISR模型通过消除过滤泡沫效应，促进信念和谐，通过利用个性化的类别信息激发用户的好奇心和兴趣，鼓励用户拓宽信念视野和探索新的信息。

    

    在个性化推荐系统领域，人们越来越关注的是信念失衡和用户偏见的加剧现象，这一现象主要归因于过滤泡沫。针对这一关键问题，我们引入了一种创新的中介机构（BHEISR），将其置于用户和现有推荐系统之间，以减轻过滤泡沫效应在现有推荐系统中产生的负面影响。主要目标是为用户创造信念平衡，同时最小化过滤泡沫带来的不利影响。BHEISR模型融合了“推动理论”的原则，同时秉持民主和透明的原则。它利用用户特定的类别信息来激发好奇心，即使在用户可能最初认为不感兴趣的领域。通过逐步激发对新领域的兴趣，该模型鼓励用户拓宽信念视野并探索他们通常忽视的信息。我们的模型具有时间敏感性。

    In the realm of personalized recommendation systems, the increasing concern is the amplification of belief imbalance and user biases, a phenomenon primarily attributed to the filter bubble. Addressing this critical issue, we introduce an innovative intermediate agency (BHEISR) between users and existing recommendation systems to attenuate the negative repercussions of the filter bubble effect in extant recommendation systems. The main objective is to strike a belief balance for users while minimizing the detrimental influence caused by filter bubbles. The BHEISR model amalgamates principles from nudge theory while upholding democratic and transparent principles. It harnesses user-specific category information to stimulate curiosity, even in areas users might initially deem uninteresting. By progressively stimulating interest in novel categories, the model encourages users to broaden their belief horizons and explore the information they typically overlook. Our model is time-sensitive a
    
[^28]: 大规模语言模型对数据科学教育应该做什么？

    What Should Data Science Education Do with Large Language Models?. (arXiv:2307.02792v1 [cs.CY])

    [http://arxiv.org/abs/2307.02792](http://arxiv.org/abs/2307.02792)

    大型语言模型（LLM）正在改变数据科学家的责任和数据科学教育模式，从动手编码和标准分析转变为评估和管理自动化AI执行的分析。这种转变要求数据科学教育注重培养学生的多样化技能，如创造力、批判性思维和AI引导的编程。

    

    大型语言模型（LLM），如ChatGPT等的快速发展正在改变数据科学和统计学。这些最先进的工具可以简化复杂的流程，从而重塑了数据科学家的角色。我们认为LLM正在转变数据科学家的责任，将他们的重点从动手编码、数据整理和进行标准分析转变为评估和管理这些自动化AI执行的分析。这种角色的演变类似于从软件工程师转变为产品经理。我们在本文中使用LLM在数据科学案例研究中说明了这种转变。这些发展要求数据科学教育有意义地发展。教育方法现在必须更加注重培养学生的多样化技能，如LLM启发的创造力、批判性思维、AI引导的编程。LLM还可以在课堂上起到重要的作用，作为互动式教学和...

    The rapid advances of large language models (LLMs), such as ChatGPT, are revolutionizing data science and statistics. These state-of-the-art tools can streamline complex processes. As a result, it reshapes the role of data scientists. We argue that LLMs are transforming the responsibilities of data scientists, shifting their focus from hands-on coding, data-wrangling and conducting standard analyses to assessing and managing analyses performed by these automated AIs. This evolution of roles is reminiscent of the transition from a software engineer to a product manager. We illustrate this transition with concrete data science case studies using LLMs in this paper. These developments necessitate a meaningful evolution in data science education. Pedagogy must now place greater emphasis on cultivating diverse skillsets among students, such as LLM-informed creativity, critical thinking, AI-guided programming. LLMs can also play a significant role in the classroom as interactive teaching and
    
[^29]: 子群可分性在组公平医学图像分类中的作用

    The Role of Subgroup Separability in Group-Fair Medical Image Classification. (arXiv:2307.02791v1 [cs.CV])

    [http://arxiv.org/abs/2307.02791](http://arxiv.org/abs/2307.02791)

    本研究研究了深度分类器中的表现差异，发现分类器将个体分为子群的能力在医学成像模态和受保护特征方面存在显著差异，并证明了这个属性对算法偏见具有预测能力。通过理论分析和实证评估，我们发现子群可分性、子群差异和模型在存在系统偏见数据时的性能降级之间存在关系，这为公平医学成像人工智能的发展提供了重要的见解。

    

    我们研究了深度分类器中的表现差异。我们发现分类器将个体分为子群的能力在医学成像模态和受保护特征方面存在显著差异；关键是，我们证明了这个属性对算法偏见具有预测能力。通过理论分析和大量实证评估，我们发现子群可分性、子群差异和模型在存在系统偏见数据（如欠诊断）时的性能降级之间存在关系。我们的发现为模型如何产生偏见提供了新的视角，为公平医学成像人工智能的发展提供了重要的见解。

    We investigate performance disparities in deep classifiers. We find that the ability of classifiers to separate individuals into subgroups varies substantially across medical imaging modalities and protected characteristics; crucially, we show that this property is predictive of algorithmic bias. Through theoretical analysis and extensive empirical evaluation, we find a relationship between subgroup separability, subgroup disparities, and performance degradation when models are trained on data with systematic bias such as underdiagnosis. Our findings shed new light on the question of how models become biased, providing important insights for the development of fair medical imaging AI.
    
[^30]: 通过3分钟的人类反馈进行扩散模型的有限采样

    Censored Sampling of Diffusion Models Using 3 Minutes of Human Feedback. (arXiv:2307.02770v1 [cs.CV])

    [http://arxiv.org/abs/2307.02770](http://arxiv.org/abs/2307.02770)

    该论文研究了通过3分钟的人类反馈来扩散模型的有限采样，并表明仅几分钟的人类反馈生成的标签就足够实现图像的审查任务。

    

    近期，扩散模型在高质量图像生成方面取得了显著成果。然而，有时预训练的扩散模型在某种程度上存在错误对齐的问题，即模型可以生成好的图像，但有时会生成不理想的图像。如果是这样，我们只需要阻止生成糟糕的图像，我们称之为审查任务。在这项工作中，我们提出了使用经过最小人类反馈训练的奖励模型对预训练扩散模型进行审查生成。我们展示了通过极高的人类反馈效率可以实现审查，并且仅几分钟的人类反馈生成的标签就足够了。

    Diffusion models have recently shown remarkable success in high-quality image generation. Sometimes, however, a pre-trained diffusion model exhibits partial misalignment in the sense that the model can generate good images, but it sometimes outputs undesirable images. If so, we simply need to prevent the generation of the bad images, and we call this task censoring. In this work, we present censored generation with a pre-trained diffusion model using a reward model trained on minimal human feedback. We show that censoring can be accomplished with extreme human feedback efficiency and that labels generated with a mere few minutes of human feedback are sufficient. Code available at: https://github.com/tetrzim/diffusion-human-feedback.
    
[^31]: PRD: 同行评级和讨论改善基于大型语言模型的评估

    PRD: Peer Rank and Discussion Improve Large Language Model based Evaluations. (arXiv:2307.02762v1 [cs.CL])

    [http://arxiv.org/abs/2307.02762](http://arxiv.org/abs/2307.02762)

    本研究提出了PRD算法，利用同行评级和讨论改善了基于大型语言模型的评估方法，解决了自我提升和位置偏见等问题。

    

    如今，评估和比较不同现代大型语言模型（LLMs）生成的回答质量在自动化方面很难。最近的研究建议并主要使用LLMs作为无参考度量衡开放式问题回答的参考指标。更具体地说，他们以被认为是“最强”的LLM作为评估器，对候选模型的答案进行两两比较并提供排名分数。然而，这种直观的方法存在多个问题，例如带来自我提升（青睐自己的答案）和位置偏见。我们从教育领域（Cho and MacArthur, 2011；Walsh, 2014）中汲取见解和教训，改进了基于LLM的评估。具体而言，我们提出了（1）同行评级（PR）算法，该算法考虑每个同行LLM对所有答案对的两两偏好，并输出模型的最终排名；以及（2）同行讨论（PD），在其中我们促使两个LLMs进行讨论并尝试就两个偏好达成共识。

    Nowadays, the quality of responses generated by different modern large language models (LLMs) are hard to evaluate and compare automatically. Recent studies suggest and predominantly use LLMs as a reference-free metric for open-ended question answering. More specifically, they use the recognized "strongest" LLM as the evaluator, which conducts pairwise comparisons of candidate models' answers and provides a ranking score. However, this intuitive method has multiple problems, such as bringing in self-enhancement (favoring its own answers) and positional bias. We draw insights and lessons from the educational domain (Cho and MacArthur, 2011; Walsh, 2014) to improve LLM-based evaluations. Specifically, we propose the (1) peer rank (PR) algorithm that takes into account each peer LLM's pairwise preferences of all answer pairs, and outputs a final ranking of models; and (2) peer discussion (PD), where we prompt two LLMs to discuss and try to reach a mutual agreement on preferences of two an
    
[^32]: 知识图谱自监督合理化方法用于推荐系统的研究

    Knowledge Graph Self-Supervised Rationalization for Recommendation. (arXiv:2307.02759v1 [cs.IR])

    [http://arxiv.org/abs/2307.02759](http://arxiv.org/abs/2307.02759)

    这项研究提出了一种新的自监督合理化方法KGRec，用于知识感知的推荐系统。通过关注知识合理化机制和生成对比度自监督任务，KGRec能够有效地识别有信息量的知识连接，并利用这些连接进行推荐。

    

    本文介绍了一种新的自监督合理化方法，称为KGRec，用于知识感知的推荐系统。为了有效地识别有信息量的知识连接，我们提出了一种关注知识合理化机制，为知识三元组生成合理化得分。通过这些得分，KGRec通过合理化掩码集成生成和对比度自监督任务进行推荐。为了突出知识图谱中的合理性，我们设计了一种以掩码重建形式的新型生成任务。通过使用高合理化得分对重要知识进行掩码，KGRec被训练来重建并突出有用的知识连接，作为合理的依据。为了进一步合理化协同交互对知识图谱学习的影响，我们引入了一种对比度学习任务，对齐来自知识和用户-物品交互视图的信号。为了确保对比度的抗噪声性，通过判断两个图中的潜在噪声边缘，

    In this paper, we introduce a new self-supervised rationalization method, called KGRec, for knowledge-aware recommender systems. To effectively identify informative knowledge connections, we propose an attentive knowledge rationalization mechanism that generates rational scores for knowledge triplets. With these scores, KGRec integrates generative and contrastive self-supervised tasks for recommendation through rational masking. To highlight rationales in the knowledge graph, we design a novel generative task in the form of masking-reconstructing. By masking important knowledge with high rational scores, KGRec is trained to rebuild and highlight useful knowledge connections that serve as rationales. To further rationalize the effect of collaborative interactions on knowledge graph learning, we introduce a contrastive learning task that aligns signals from knowledge and user-item interaction views. To ensure noise-resistant contrasting, potential noisy edges in both graphs judged by the
    
[^33]: 在不平衡数据集中的离线强化学习

    Offline Reinforcement Learning with Imbalanced Datasets. (arXiv:2307.02752v1 [cs.LG])

    [http://arxiv.org/abs/2307.02752](http://arxiv.org/abs/2307.02752)

    本文提出了一种在不平衡数据集中的新型离线强化学习方法，通过将CQL与回溯过程相结合来提取策略，从而有效地解决了不平衡数据集带来的挑战。

    

    当前离线强化学习（RL）研究中对基准的普遍使用导致了对实际数据集分布不平衡的忽视。由于探索或安全考虑的挑战，实际离线RL数据集在状态空间上通常是不平衡的。我们在本文中具体说明了离线RL中不平衡数据集的特性，其中状态覆盖率遵循一个由偏态策略所特征化的幂律分布。理论上和实证上，我们证明了基于分布约束的典型离线RL方法，如保守Q学习（CQL），在不平衡数据集下提取策略是无效的。受自然智能的启发，我们提出了一种新的离线RL方法，该方法利用CQL的增强与回溯过程相结合，以回忆以往相关经验，有效地缓解不平衡数据集带来的挑战。我们在多个任务上评估了我们的方法。

    The prevalent use of benchmarks in current offline reinforcement learning (RL) research has led to a neglect of the imbalance of real-world dataset distributions in the development of models. The real-world offline RL dataset is often imbalanced over the state space due to the challenge of exploration or safety considerations. In this paper, we specify properties of imbalanced datasets in offline RL, where the state coverage follows a power law distribution characterized by skewed policies. Theoretically and empirically, we show that typically offline RL methods based on distributional constraints, such as conservative Q-learning (CQL), are ineffective in extracting policies under the imbalanced dataset. Inspired by natural intelligence, we propose a novel offline RL method that utilizes the augmentation of CQL with a retrieval process to recall past related experiences, effectively alleviating the challenges posed by imbalanced datasets. We evaluate our method on several tasks in the 
    
[^34]: RecallM:一种用于时间上下文理解和问题回答的架构

    RecallM: An Architecture for Temporal Context Understanding and Question Answering. (arXiv:2307.02738v1 [cs.AI])

    [http://arxiv.org/abs/2307.02738](http://arxiv.org/abs/2307.02738)

    本文介绍了一种名为RecallM的架构，用于创建可适应和可更新的长期记忆，以提升大型语言模型聊天机器人的时间理解能力。

    

    用于大型语言模型（LLM）聊天机器人的理想长期记忆机制将为连续学习、复杂推理和学习序列和时间依赖关系打下基础。创建这种类型的记忆机制是一个极具挑战性的问题。在本文中，我们探索了不同方法实现长期记忆的效果。我们提出了一种新的架构，专注于为AGI系统创建可适应和可更新的长期记忆。我们通过各种实验展示了RecallM架构的好处，特别是它提供的改进的时间理解能力。

    The ideal long-term memory mechanism for Large Language Model (LLM) based chatbots, would lay the foundation for continual learning, complex reasoning and allow sequential and temporal dependencies to be learnt. Creating this type of memory mechanism is an extremely challenging problem. In this paper we explore different methods of achieving the effect of long-term memory. We propose a new architecture focused on creating adaptable and updatable long-term memory for AGI systems. We demonstrate through various experiments the benefits of the RecallM architecture, particularly the improved temporal understanding it provides.
    
[^35]: 精细动作分析：一种多模态和多任务的花样滑冰数据集

    Fine-grained Action Analysis: A Multi-modality and Multi-task Dataset of Figure Skating. (arXiv:2307.02730v1 [cs.CV])

    [http://arxiv.org/abs/2307.02730](http://arxiv.org/abs/2307.02730)

    这篇论文提出了一种多模态和多任务的花样滑冰数据集（MMFS），包含了256个类别的动作得分和空间和时间标签。该数据集的关键贡献是首次引入了独立的空间和时间分类，并首次使用骨骼模态进行精细动作质量评估。

    

    现有的动作数据集的精细动作分析面临着动作类别不足、细粒度低、模态和任务有限的挑战。本文提出了一种多模态多任务的花样滑冰数据集（MMFS），该数据集是从世界花样滑冰锦标赛中收集而来的。MMFS包括动作识别和动作质量评估，使用RGB、骨骼和11671个视频片段采集了256个类别的动作得分，并包含了空间和时间标签。我们的数据集的关键贡献包括以下三个方面：（1）首次提出了独立的空间和时间分类，以进一步探索精细动作识别和质量评估。(2)MMFS首次引入了骨骼模态用于复杂的精细动作质量评估。(3)我们的多模态和多任务数据集鼓励更多的动作分析模型。为了评估我们的数据集，我们采用了基于RGB和基于骨骼的方法。

    The fine-grained action analysis of the existing action datasets is challenged by insufficient action categories, low fine granularities, limited modalities, and tasks. In this paper, we propose a Multi-modality and Multi-task dataset of Figure Skating (MMFS) which was collected from the World Figure Skating Championships. MMFS, which possesses action recognition and action quality assessment, captures RGB, skeleton, and is collected the score of actions from 11671 clips with 256 categories including spatial and temporal labels. The key contributions of our dataset fall into three aspects as follows. (1) Independently spatial and temporal categories are first proposed to further explore fine-grained action recognition and quality assessment. (2) MMFS first introduces the skeleton modality for complex fine-grained action quality assessment. (3) Our multi-modality and multi-task dataset encourage more action analysis models. To benchmark our dataset, we adopt RGB-based and skeleton-based
    
[^36]: 分层授权：朝着可行的基于授权的技能学习迈进

    Hierarchical Empowerment: Towards Tractable Empowerment-Based Skill-Learning. (arXiv:2307.02728v1 [cs.LG])

    [http://arxiv.org/abs/2307.02728](http://arxiv.org/abs/2307.02728)

    分层授权提出了一种可以计算授权的新框架，通过引入变分下界和分层架构，实现了在短期和长期时间尺度上的授权计算，并在模拟机器人任务中得到了验证。

    

    通用智能体需要大量的技能。 授权 - 技能和状态之间的最大互信息 - 为学习大量不同技能提供了一条路径，但互信息很难优化。我们介绍了一种新的框架，分层授权，通过集成目标条件层次强化学习的概念，使得计算授权更加可行。我们的框架提供了两个具体的贡献。首先，我们介绍了一种新的变分下界，可用于计算短期视角下的授权。其次，我们引入了一个分层架构，用于计算指数时间尺度下的授权。我们在一系列模拟机器人任务中验证了该框架的贡献。在一个流行的蚂蚁导航领域，我们的四级智能体能够学习覆盖面积比之前的工作大两个数量级的技能。

    General purpose agents will require large repertoires of skills. Empowerment -- the maximum mutual information between skills and the states -- provides a pathway for learning large collections of distinct skills, but mutual information is difficult to optimize. We introduce a new framework, Hierarchical Empowerment, that makes computing empowerment more tractable by integrating concepts from Goal-Conditioned Hierarchical Reinforcement Learning. Our framework makes two specific contributions. First, we introduce a new variational lower bound on mutual information that can be used to compute empowerment over short horizons. Second, we introduce a hierarchical architecture for computing empowerment over exponentially longer time scales. We verify the contributions of the framework in a series of simulated robotics tasks. In a popular ant navigation domain, our four level agents are able to learn skills that cover a surface area over two orders of magnitude larger than prior work.
    
[^37]: TL-nvSRAM-CIM：具有零直流功耗恢复和三态MAC操作的超高密度三级ReRAM辅助计算存储器内计算

    TL-nvSRAM-CIM: Ultra-High-Density Three-Level ReRAM-Assisted Computing-in-nvSRAM with DC-Power Free Restore and Ternary MAC Operations. (arXiv:2307.02717v1 [cs.AR])

    [http://arxiv.org/abs/2307.02717](http://arxiv.org/abs/2307.02717)

    TL-nvSRAM-CIM是一种新颖的存储器内计算方案，利用超高密度的三级ReRAM辅助计算来解决大规模神经网络模型中权重容量不足的问题，并采用了零直流功耗恢复和三态MAC操作来提高能效和保持准确性。

    

    随着规模庞大的神经网络，将所有权重放在芯片上仍然是SRAM-CIM的一大挑战，因为其存储容量有限。之前的非易失性SRAM-CIM（nvSRAM-CIM）通过在高效SRAM-CIM上集成高密度单级ReRAM来解决这个问题，在芯片上储存权重以消除芯片外的内存访问。然而，之前的SL-nvSRAM-CIM在增加SL-ReRAM数量和计算效率受限方面存在问题。为了克服这些挑战，本文提出了一种超高密度三级ReRAM辅助的非易失性SRAM计算存储器内计算方案（TL-nvSRAM-CIM）用于大型神经网络模型。采用了集群式选择器-n-ReRAM（cluster-nSnRs）来可靠地恢复权重，并消除了直流功耗。此外，提出了一种带有差分计算方案的三态SRAM-CIM机制，用于能量高效的三态MAC操作，并保持高NN准确性。提出的TL-nvSRAM-CIM实现了7.

    Accommodating all the weights on-chip for large-scale NNs remains a great challenge for SRAM based computing-in-memory (SRAM-CIM) with limited on-chip capacity. Previous non-volatile SRAM-CIM (nvSRAM-CIM) addresses this issue by integrating high-density single-level ReRAMs on the top of high-efficiency SRAM-CIM for weight storage to eliminate the off-chip memory access. However, previous SL-nvSRAM-CIM suffers from poor scalability for an increased number of SL-ReRAMs and limited computing efficiency. To overcome these challenges, this work proposes an ultra-high-density three-level ReRAMs-assisted computing-in-nonvolatile-SRAM (TL-nvSRAM-CIM) scheme for large NN models. The clustered n-selector-n-ReRAM (cluster-nSnRs) is employed for reliable weight-restore with eliminated DC power. Furthermore, a ternary SRAM-CIM mechanism with differential computing scheme is proposed for energy-efficient ternary MAC operations while preserving high NN accuracy. The proposed TL-nvSRAM-CIM achieves 7.
    
[^38]: 通过逻辑评估公式验证对不准确地真实标签的评估的实用性

    Validation of the Practicability of Logical Assessment Formula for Evaluations with Inaccurate Ground-Truth Labels. (arXiv:2307.02709v1 [cs.AI])

    [http://arxiv.org/abs/2307.02709](http://arxiv.org/abs/2307.02709)

    本文验证了逻辑评估公式在具有不准确的真实标签的评估中的实用性，通过将其应用于乳腺癌肿瘤分割在医学组织病理学全切片图像分析中的情况进行实验，结果表明LAF在这种情况下具有有效性，并展示了LAF在MHWSIA中的潜力。

    

    逻辑评估公式（LAF）是一种用于评估具有不准确地真实标签（IAGTLs）的预测模型的新理论，用于各种人工智能应用。然而，LAF在实际应用中对于具有IAGTLs的评估的实用性尚未得到验证。在本文中，为了解决这个问题，我们将LAF应用于医学组织病理学全切片图像分析中的乳腺癌肿瘤分割（TSfBC）。实验结果和分析显示LAF在TSfBC中对于具有IAGTLs的评估的有效性，并反映了将LAF应用于MHWSIA的潜力。

    Logical assessment formula (LAF) is a new theory proposed for evaluations with inaccurate ground-truth labels (IAGTLs) to assess the predictive models for various artificial intelligence applications. However, the practicability of LAF for evaluations with IAGTLs has not yet been validated in real-world practice. In this paper, to address this issue, we applied LAF to tumour segmentation for breast cancer (TSfBC) in medical histopathology whole slide image analysis (MHWSIA). Experimental results and analysis show the validity of LAF for evaluations with IAGTLs in the case of TSfBC and reflect the potentials of LAF applied to MHWSIA.
    
[^39]: 深度学习中的损失函数和度量方法：一项评论

    Loss Functions and Metrics in Deep Learning. A Review. (arXiv:2307.02694v1 [cs.LG])

    [http://arxiv.org/abs/2307.02694](http://arxiv.org/abs/2307.02694)

    本文回顾了深度学习中最常见的损失函数和性能测量方法，旨在帮助从业者选择最适合其特定任务的方法。

    

    深度学习的一个重要组成部分是选择用于训练和评估模型的损失函数和性能度量。本文回顾了深度学习中最常见的损失函数和性能测量方法。我们探讨了每种技术的优势和局限性，并举例说明它们在各种深度学习问题上的应用。我们的评论旨在全面了解最常见的深度学习任务中使用的不同损失函数和性能指标，并帮助从业者选择最适合其特定任务的方法。

    One of the essential components of deep learning is the choice of the loss function and performance metrics used to train and evaluate models. This paper reviews the most prevalent loss functions and performance measurements in deep learning. We examine the benefits and limits of each technique and illustrate their application to various deep-learning problems. Our review aims to give a comprehensive picture of the different loss functions and performance indicators used in the most common deep learning tasks and help practitioners choose the best method for their specific task.
    
[^40]: SACHA：基于启发式注意力的软演员批判器用于部分可观察多智能体路径规划

    SACHA: Soft Actor-Critic with Heuristic-Based Attention for Partially Observable Multi-Agent Path Finding. (arXiv:2307.02691v1 [cs.RO])

    [http://arxiv.org/abs/2307.02691](http://arxiv.org/abs/2307.02691)

    这篇论文提出了一种名为SACHA的基于启发式注意力的软演员批判器方法，用于解决部分可观察多智能体路径规划问题。通过引入新颖的启发式注意力机制，SACHA促进了智能体之间的合作，提高了复杂多智能体环境下的路径规划效果。

    

    多智能体路径规划（MAPF）是许多大规模机器人系统的关键组成部分，智能体必须规划其到达给定目标位置的无碰撞路径。最近，多智能体强化学习已被引入以解决部分可观察MAPF的变体，通过在集中方式下基于每个智能体的部分观察来学习分散的单智能体策略。然而，由于这种设定的非平稳性，现有的基于学习的方法在实现复杂的多智能体合作，特别是在拥堵环境中效果不佳。为了解决这一挑战，我们提出了一种名为基于启发式注意力的软演员批判器（SACHA）的多智能体演员-批判器方法，它采用新颖的启发式注意力机制来促进智能体之间的合作。SACHA为每个智能体学习一个神经网络，以选择性地关注多个智能体之间的最短路径启发指导。

    Multi-Agent Path Finding (MAPF) is a crucial component for many large-scale robotic systems, where agents must plan their collision-free paths to their given goal positions. Recently, multi-agent reinforcement learning has been introduced to solve the partially observable variant of MAPF by learning a decentralized single-agent policy in a centralized fashion based on each agent's partial observation. However, existing learning-based methods are ineffective in achieving complex multi-agent cooperation, especially in congested environments, due to the non-stationarity of this setting. To tackle this challenge, we propose a multi-agent actor-critic method called Soft Actor-Critic with Heuristic-Based Attention (SACHA), which employs novel heuristic-based attention mechanisms for both the actors and critics to encourage cooperation among agents. SACHA learns a neural network for each agent to selectively pay attention to the shortest path heuristic guidance from multiple agents within its
    
[^41]: 使用结构化注意力扩展上下文演示

    Scaling In-Context Demonstrations with Structured Attention. (arXiv:2307.02690v1 [cs.CL])

    [http://arxiv.org/abs/2307.02690](http://arxiv.org/abs/2307.02690)

    本研究提出了一种用于上下文学习的结构化注意力机制，解决了大规模语言模型在使用演示进行上下文学习时遇到的限制与挑战。

    

    最近大规模语言模型的兴起突出了它们在上下文学习方面的能力，即在上下文中从少数演示中“学习”执行任务而无需进行参数更新。然而，它们在上下文学习方面的能力受到模型架构的限制：1）由于位置嵌入，演示的使用受到最大句子长度的限制；2）注意力的二次复杂度阻碍用户有效使用更多的演示；3）研究表明，LLM对演示的顺序敏感。在这项工作中，我们通过提出更好的架构设计来解决这些挑战。我们提出了SAICL（用于上下文学习的结构化注意力），它通过为上下文学习设计了一种结构化注意力机制来替换全注意力，并消除了个别演示之间不必要的依赖关系，同时使模型对演示的排列不变。

    The recent surge of large language models (LLMs) highlights their ability to perform in-context learning, i.e., "learning" to perform a task from a few demonstrations in the context without any parameter updates. However, their capabilities of in-context learning are limited by the model architecture: 1) the use of demonstrations is constrained by a maximum sentence length due to positional embeddings; 2) the quadratic complexity of attention hinders users from using more demonstrations efficiently; 3) LLMs are shown to be sensitive to the order of the demonstrations. In this work, we tackle these challenges by proposing a better architectural design for in-context learning. We propose SAICL (Structured Attention for In-Context Learning), which replaces the full-attention by a structured attention mechanism designed for in-context learning, and removes unnecessary dependencies between individual demonstrations, while making the model invariant to the permutation of demonstrations. We e
    
[^42]: AI4OPT: 优化进展的人工智能研究所

    AI4OPT: AI Institute for Advances in Optimization. (arXiv:2307.02671v1 [math.OC])

    [http://arxiv.org/abs/2307.02671](http://arxiv.org/abs/2307.02671)

    AI4OPT是一个融合人工智能和优化的研究所，致力于解决供应链、能源系统、芯片设计与制造以及可持续食品系统等领域的问题，并提供工程教育中的人工智能教育路径。

    

    本文是对AI4OPT的简要介绍，AI4OPT是美国国家科学基金会（NSF）关于优化进展的人工智能研究所。AI4OPT将人工智能与优化相结合，受到供应链、能源系统、芯片设计与制造以及可持续食品系统等终端应用案例的启发。AI4OPT还将其“教师教学”理念运用于为工程领域提供人工智能的长期教育路径。

    This article is a short introduction to AI4OPT, the NSF AI Institute for Advances in Optimization. AI4OPT fuses AI and Optimization, inspired by end-use cases in supply chains, energy systems, chip design and manufacturing, and sustainable food systems. AI4OPT also applies its "teaching the teachers" philosophy to provide longitudinal educational pathways in AI for engineering.
    
[^43]: 通信、控制和机器学习在安全和自主驾驶车辆导航中的融合

    Convergence of Communications, Control, and Machine Learning for Secure and Autonomous Vehicle Navigation. (arXiv:2307.02663v1 [cs.IT])

    [http://arxiv.org/abs/2307.02663](http://arxiv.org/abs/2307.02663)

    连接和自主驾驶车辆（CAVs）可以通过融合通信、控制和学习系统实现自主导航，但这带来了一些挑战，包括稳定路径跟踪、抗击网络物理攻击的强大控制和自适应导航控制器设计。

    

    连接和自主驾驶车辆（CAVs）可以减少交通事故中的人为错误，提高道路效率，并执行从交货到智能城市监视等各种任务。实现这些好处需要CAVs能够自主导航到目标位置。为此，每个CAV的导航控制器必须利用传感器和无线系统收集的信息，进行纵向和横向移动的决策。然而，实现CAVs的自主导航需要将通信、控制和学习系统进行融合。本文的目标是明确揭示与这种融合相关的挑战，并提出解决方案来应对两个主要用例：非协调和协调CAVs。特别是，与非协调CAVs的导航相关的挑战包括稳定路径跟踪、抗击网络物理攻击的强大控制和自适应导航控制器设计。同时，当多个CAVs同时存在时...

    Connected and autonomous vehicles (CAVs) can reduce human errors in traffic accidents, increase road efficiency, and execute various tasks ranging from delivery to smart city surveillance. Reaping these benefits requires CAVs to autonomously navigate to target destinations. To this end, each CAV's navigation controller must leverage the information collected by sensors and wireless systems for decision-making on longitudinal and lateral movements. However, enabling autonomous navigation for CAVs requires a convergent integration of communication, control, and learning systems. The goal of this article is to explicitly expose the challenges related to this convergence and propose solutions to address them in two major use cases: Uncoordinated and coordinated CAVs. In particular, challenges related to the navigation of uncoordinated CAVs include stable path tracking, robust control against cyber-physical attacks, and adaptive navigation controller design. Meanwhile, when multiple CAVs co
    
[^44]: 多目标优化通过对精英进行投票

    Many-objective Optimization via Voting for Elites. (arXiv:2307.02661v1 [cs.NE])

    [http://arxiv.org/abs/2307.02661](http://arxiv.org/abs/2307.02661)

    创新点：提出了多目标优化通过对精英进行投票（MOVE）的方法，结合多目标进化算法和质量多样性算法的元素，在解决多目标优化问题时具有较好的性能表现。

    

    实际问题通常由多个目标组成，并且需要在这些目标之间进行权衡的解决方案。目前的多目标优化方法通常需要具备挑战性的假设，如对目标的重要性/难度在加权求和的单目标范式中进行了解，或通过庞大的种群来克服多目标帕累托优化中的维度灾难。结合多目标进化算法和MAP-Elites等质量多样性算法的元素，我们提出了多目标优化通过对精英进行投票（MOVE）的方法。MOVE通过维护在不同目标函数子集上表现良好的精英映射来解决问题。在一个包含14个目标的图像神经演化问题上，我们证明MOVE在只具有50个精英的种群情况下是可行的，并且优于一个简单的单目标基线。我们发现算法的性能依赖于解决方案在不同桶之间跳转（以使一个父代产生一个属于精英集合的子代）。

    Real-world problems are often comprised of many objectives and require solutions that carefully trade-off between them. Current approaches to many-objective optimization often require challenging assumptions, like knowledge of the importance/difficulty of objectives in a weighted-sum single-objective paradigm, or enormous populations to overcome the curse of dimensionality in multi-objective Pareto optimization. Combining elements from Many-Objective Evolutionary Algorithms and Quality Diversity algorithms like MAP-Elites, we propose Many-objective Optimization via Voting for Elites (MOVE). MOVE maintains a map of elites that perform well on different subsets of the objective functions. On a 14-objective image-neuroevolution problem, we demonstrate that MOVE is viable with a population of as few as 50 elites and outperforms a naive single-objective baseline. We find that the algorithm's performance relies on solutions jumping across bins (for a parent to produce a child that is elite f
    
[^45]: Surge Routing：基于事件信息的多智能体强化学习用于自动拼车

    Surge Routing: Event-informed Multiagent Reinforcement Learning for Autonomous Rideshare. (arXiv:2307.02637v1 [cs.AI])

    [http://arxiv.org/abs/2307.02637](http://arxiv.org/abs/2307.02637)

    这项研究提出了一种基于事件信息的多智能体强化学习框架，用于自动拼车，通过预测和适应需求激增，并生成协同的路由和接乘策略来服务更多请求。

    

    大型事件通常会引发拼车服务需求的激增，而这些需求不会被平均需求模式所捕捉到，给路由算法带来了独特的挑战。我们提出了一个学习框架，用于自动化出租车车队，从互联网上获取事件数据以预测和适应需求激增，并生成协同的路由和接乘策略，以服务更多的请求比其他路由协议。我们通过以下方式实现这一目标：(i)一个事件处理框架，用于从互联网上抓取事件信息并生成密集的向量表示，作为神经网络的输入特征来预测需求；(ii)一个双神经网络系统，使用这些密集的向量表示来预测整个地图上的每小时需求；(iii)一种基于概率的方法，利用区域占用时间表将公开的需求数据映射到离散化的街道交叉口上。

    Large events such as conferences, concerts and sports games, often cause surges in demand for ride services that are not captured in average demand patterns, posing unique challenges for routing algorithms. We propose a learning framework for an autonomous fleet of taxis that scrapes event data from the internet to predict and adapt to surges in demand and generates cooperative routing and pickup policies that service a higher number of requests than other routing protocols. We achieve this through a combination of (i) an event processing framework that scrapes the internet for event information and generates dense vector representations that can be used as input features for a neural network that predicts demand; (ii) a two neural network system that predicts hourly demand over the entire map, using these dense vector representations; (iii) a probabilistic approach that leverages locale occupancy schedules to map publicly available demand data over sectors to discretized street inters
    
[^46]: 一种可解释的模型以支持AML治疗方案的决策

    An explainable model to support the decision about the therapy protocol for AML. (arXiv:2307.02631v1 [cs.LG])

    [http://arxiv.org/abs/2307.02631](http://arxiv.org/abs/2307.02631)

    本文提出了一种可解释的机器学习模型，用于支持AML患者治疗方案的决策，解决了当前风险分类存在的问题和专家需求额外测试和分析的困扰。

    

    急性髓细胞白血病（AML）是一种最具侵略性的血液肿瘤。为了支持专家关于合适治疗的决策，AML患者根据其细胞遗传和分子特征获得预后信息，通常分为有利、中等和不利三个风险类别。然而，当前的风险分类存在已知问题，如同一风险组中患者之间的异质性和中风险类别的清晰定义缺失。此外，由于大多数AML患者被归为中风险分类，专家常需进行其他测试和分析，导致治疗延迟和患者临床状况恶化。本文提出了数据分析和一种可解释的机器学习模型，以支持根据患者生存预测确定最合适的治疗方案的决策。

    Acute Myeloid Leukemia (AML) is one of the most aggressive types of hematological neoplasm. To support the specialists' decision about the appropriate therapy, patients with AML receive a prognostic of outcomes according to their cytogenetic and molecular characteristics, often divided into three risk categories: favorable, intermediate, and adverse. However, the current risk classification has known problems, such as the heterogeneity between patients of the same risk group and no clear definition of the intermediate risk category. Moreover, as most patients with AML receive an intermediate-risk classification, specialists often demand other tests and analyses, leading to delayed treatment and worsening of the patient's clinical condition. This paper presents the data analysis and an explainable machine-learning model to support the decision about the most appropriate therapy protocol according to the patient's survival prediction. In addition to the prediction model being explainable
    
[^47]: 大规模云数据库的实时工作负载模式分析

    Real-time Workload Pattern Analysis for Large-scale Cloud Databases. (arXiv:2307.02626v1 [cs.DB])

    [http://arxiv.org/abs/2307.02626](http://arxiv.org/abs/2307.02626)

    该论文提出了阿里巴巴工作负载矿工(AWM)，一个实时系统，用于在复杂的大规模工作负载中发现工作负载模式。通过对用户请求的SQL查询模式进行编码和发现，并基于发现的模式优化查询处理。该系统适用于大规模云数据库，可以更好地理解数据库系统的趋势和特征。

    

    在云系统上托管数据库服务已成为常见做法，这导致数据库工作负载的增加，为模式分析提供了机会。从商业逻辑的角度发现工作负载模式有助于更好地了解数据库系统的趋势和特征。然而，现有的工作负载模式发现系统不适用于通常由行业使用的大规模云数据库。这是因为大规模云数据库的工作负载模式通常比普通数据库复杂得多。在本文中，我们提出了阿里巴巴工作负载矿工(AWM)，这是一个用于在复杂大规模工作负载中发现工作负载模式的实时系统。AWM对用户请求的日志记录的SQL查询模式进行编码和发现，并基于发现的模式优化查询处理。首先，数据收集和预处理模块收集流式查询日志，并对日志数据进

    Hosting database services on cloud systems has become a common practice. This has led to the increasing volume of database workloads, which provides the opportunity for pattern analysis. Discovering workload patterns from a business logic perspective is conducive to better understanding the trends and characteristics of the database system. However, existing workload pattern discovery systems are not suitable for large-scale cloud databases which are commonly employed by the industry. This is because the workload patterns of large-scale cloud databases are generally far more complicated than those of ordinary databases. In this paper, we propose Alibaba Workload Miner (AWM), a real-time system for discovering workload patterns in complicated large-scale workloads. AWM encodes and discovers the SQL query patterns logged from user requests and optimizes the querying processing based on the discovered patterns. First, Data Collection & Preprocessing Module collects streaming query logs an
    
[^48]: 在观测代价敏感强化学习中的动态观测策略

    Dynamic Observation Policies in Observation Cost-Sensitive Reinforcement Learning. (arXiv:2307.02620v1 [cs.LG])

    [http://arxiv.org/abs/2307.02620](http://arxiv.org/abs/2307.02620)

    本文研究了在观测代价敏感强化学习中，强化学习代理在每个时间步不需要昂贵的测量，提出了一种新的方法DMSOA，并在多个环境中进行了评估，结果表明DMSOA能够以更少的决策步骤和测量次数学到更好的策略。

    

    强化学习已被证明可以学习复杂任务的高级控制策略，包括游戏、机器人、供暖与制冷系统和文本生成。然而，强化学习中的动作-感知循环通常假设在每个时间步都可以获得对环境状态的测量，且不产生成本。然而，在深海和行星机器人探索、材料设计和医学等应用中，测量或者近似环境状态可能会产生高昂的成本。本文调查了近来不断增长的文献，采取了RL代理可能不需要或者不想在每个时间步进行昂贵测量的观点。在这个背景下，我们提出了Deep Dynamic Multi-Step Observationless Agent (DMSOA)，并将其与文献进行对比，并在OpenAI gym和Atari Pong环境中进行了实证评估。我们的结果显示，DMSOA能够以更少的决策步骤和测量次数学到更好的策略。

    Reinforcement learning (RL) has been shown to learn sophisticated control policies for complex tasks including games, robotics, heating and cooling systems and text generation. The action-perception cycle in RL, however, generally assumes that a measurement of the state of the environment is available at each time step without a cost. In applications such as deep-sea and planetary robot exploration, materials design and medicine, however, there can be a high cost associated with measuring, or even approximating, the state of the environment. In this paper, we survey the recently growing literature that adopts the perspective that an RL agent might not need, or even want, a costly measurement at each time step. Within this context, we propose the Deep Dynamic Multi-Step Observationless Agent (DMSOA), contrast it with the literature and empirically evaluate it on OpenAI gym and Atari Pong environments. Our results, show that DMSOA learns a better policy with fewer decision steps and meas
    
[^49]: 联邦流行病监测

    Federated Epidemic Surveillance. (arXiv:2307.02616v1 [stat.AP])

    [http://arxiv.org/abs/2307.02616](http://arxiv.org/abs/2307.02616)

    本研究旨在探索联邦方法在流行病监测中的应用。我们提出了一个假设检验框架，通过推送到保管人的防火墙并进行元分析，来解决数据分布和共享限制的问题。通过实验验证了我们的方法的有效性，并提出了适合的$p$-值合并方法。这些发现为联邦流行病监测提供了有价值的见解。

    

    流行病的监测是一项具有挑战性的任务，特别是当关键数据分散且利益相关方无法或不愿共享时。为了克服这一障碍，应开发联邦方法来整合实体愿意提供的较不敏感的证据。本研究旨在探索将假设检验推送到每个保管人的防火墙后，再通过元分析来合并结果的可行性，并确定重建假设检验和优化推理的最佳方法。我们提出了一个假设检验框架来识别指标的激增，并对真实数据和半合成数据进行功效分析和实验，以展示我们所提出的假设检验的性质，并提出合适的$p$-值合并方法。我们的研究结果凸显了使用$p$-值合并作为流行病监测的联邦方法的潜力，并为整合可用信息提供了宝贵的见解。

    The surveillance of a pandemic is a challenging task, especially when crucial data is distributed and stakeholders cannot or are unwilling to share. To overcome this obstacle, federated methodologies should be developed to incorporate less sensitive evidence that entities are willing to provide. This study aims to explore the feasibility of pushing hypothesis tests behind each custodian's firewall and then meta-analysis to combine the results, and to determine the optimal approach for reconstructing the hypothesis test and optimizing the inference. We propose a hypothesis testing framework to identify a surge in the indicators and conduct power analyses and experiments on real and semi-synthetic data to showcase the properties of our proposed hypothesis test and suggest suitable methods for combining $p$-values. Our findings highlight the potential of using $p$-value combination as a federated methodology for pandemic surveillance and provide valuable insights into integrating availabl
    
[^50]: 基于人类启发的渐进对齐和比较学习用于基于经验的词汇获取

    Human Inspired Progressive Alignment and Comparative Learning for Grounded Word Acquisition. (arXiv:2307.02615v1 [cs.CL])

    [http://arxiv.org/abs/2307.02615](http://arxiv.org/abs/2307.02615)

    本研究通过比较学习和渐进对齐的方式，借鉴人类语言习得的过程，探索了一种用于基于经验的词汇获取的计算过程。该方法不涉及固定的词汇量大小，也不涉及有区分性的目标，能够高效地持续学习更多的概念。

    

    人类语言习得是一种高效、受监督和持续的过程。本研究借鉴了人类婴儿习得第一门语言的方式，通过比较学习开发了一种用于词汇获取的计算过程。受认知发现的启发，我们生成了一个小型数据集，使计算模型能够比较各种属性的相似性和差异性，学习过滤出并提取共同的信息用于每个共享的语言标签。我们将词汇获取框架定义为既包括信息过滤过程，也包括表征-符号映射过程。该过程不涉及固定的词汇量大小，也不涉及有区分性的目标，使模型能够持续高效地学习更多的概念。我们在控制实验中的结果显示了这种方法在高效地持续学习基于经验的词汇方面的潜力。

    Human language acquisition is an efficient, supervised, and continual process. In this work, we took inspiration from how human babies acquire their first language, and developed a computational process for word acquisition through comparative learning. Motivated by cognitive findings, we generated a small dataset that enables the computation models to compare the similarities and differences of various attributes, learn to filter out and extract the common information for each shared linguistic label. We frame the acquisition of words as not only the information filtration process, but also as representation-symbol mapping. This procedure does not involve a fixed vocabulary size, nor a discriminative objective, and allows the models to continually learn more concepts efficiently. Our results in controlled experiments have shown the potential of this approach for efficient continual learning of grounded words.
    
[^51]: 通过一个空格绕过ChatGPT检测器

    Evade ChatGPT Detectors via A Single Space. (arXiv:2307.02599v1 [cs.CL])

    [http://arxiv.org/abs/2307.02599](http://arxiv.org/abs/2307.02599)

    本研究发现，当前的ChatGPT检测器不能有效区分人类生成和AI生成内容之间的差异，而一个额外的空格成为了规避检测的关键因素。

    

    ChatGPT带来了革命性的社会价值，但也引发了人们对于AI生成内容滥用的担忧。因此，一个重要问题是如何检测出内容是由ChatGPT生成还是人类生成的。现有的检测器是建立在人类生成和AI生成内容之间存在分布差距的假设上的。这些差距通常是通过统计信息或分类器来识别的。我们的研究质疑了检测器中的分布差距假设。我们发现检测器不能有效地区分人类生成和AI生成内容之间的语义和风格差距。相反，"微小的差异"，如额外的一个空格，在检测中变得至关重要。基于这一发现，我们提出了SpaceInfi策略来规避检测。实验证明了这种策略在多个基准和检测器上的有效性。我们还对为什么SpaceInfi能成功规避检测提供了理论解释。

    ChatGPT brings revolutionary social value but also raises concerns about the misuse of AI-generated content. Consequently, an important question is how to detect whether content is generated by ChatGPT or by human. Existing detectors are built upon the assumption that there are distributional gaps between human-generated and AI-generated content. These gaps are typically identified using statistical information or classifiers. Our research challenges the distributional gap assumption in detectors. We find that detectors do not effectively discriminate the semantic and stylistic gaps between human-generated and AI-generated content. Instead, the "subtle differences", such as an extra space, become crucial for detection. Based on this discovery, we propose the SpaceInfi strategy to evade detection. Experiments demonstrate the effectiveness of this strategy across multiple benchmarks and detectors. We also provide a theoretical explanation for why SpaceInfi is successful in evading perple
    
[^52]: ODD: 一份基于自然语言处理的药物滥用异常行为检测的基准数据集

    ODD: A Benchmark Dataset for the NLP-based Opioid Related Aberrant Behavior Detection. (arXiv:2307.02591v1 [cs.CL])

    [http://arxiv.org/abs/2307.02591](http://arxiv.org/abs/2307.02591)

    这个研究介绍了一份名为ODD的新型基准数据集，用于通过分析患者的电子健康记录笔记，检测和分类药物滥用异常行为。这个数据集在药物相关病例的自然语言处理研究中具有重要的创新和贡献。

    

    药物滥用异常行为（ORAB）是防止药物过量的新风险因素。以往，ORAB主要通过调查结果和药物给予监测进行评估。然而，这些方法无法扩展，并不能涵盖所有异常行为的范围。然而，ORAB在电子健康记录笔记中广泛有记录。本文介绍了一个名为ODD的新型生物医学自然语言处理基准数据集，用于ORAB检测。ODD是一个专家注释的数据集，包括750多个公开可用的电子健康记录笔记。ODD旨在从患者的电子健康记录笔记中识别ORAB，并将其分类为九个类别：1）已确认异常行为，2）暗示的异常行为，3）阿片类药物，4）适应症，5）已诊断的阿片制剂依赖，6）苯二氮平类药物，7）药物变化，8）与中枢神经系统相关，9）社会健康决定因素。

    Opioid related aberrant behaviors (ORAB) present novel risk factors for opioid overdose. Previously, ORAB have been mainly assessed by survey results and by monitoring drug administrations. Such methods however, cannot scale up and do not cover the entire spectrum of aberrant behaviors. On the other hand, ORAB are widely documented in electronic health record notes. This paper introduces a novel biomedical natural language processing benchmark dataset named ODD, for ORAB Detection Dataset. ODD is an expert-annotated dataset comprising of more than 750 publicly available EHR notes. ODD has been designed to identify ORAB from patients' EHR notes and classify them into nine categories; 1) Confirmed Aberrant Behavior, 2) Suggested Aberrant Behavior, 3) Opioids, 4) Indication, 5) Diagnosed opioid dependency, 6) Benzodiapines, 7) Medication Changes, 8) Central Nervous System-related, and 9) Social Determinants of Health. We explored two state-of-the-art natural language processing (NLP) mode
    
[^53]: TransformerG2G：使用Transformer进行自适应时间步长的学习时态图嵌入

    TransformerG2G: Adaptive time-stepping for learning temporal graph embeddings using transformers. (arXiv:2307.02588v1 [cs.LG])

    [http://arxiv.org/abs/2307.02588](http://arxiv.org/abs/2307.02588)

    TransformerG2G是一种使用Transformer进行自适应时间步长的图嵌入模型，通过学习历史上的长程依赖关系，准确地捕捉时态图的动态特征。

    

    动态图嵌入已成为处理不同时间图分析任务（如链路预测、节点分类、推荐系统、异常检测和图生成）的一种非常有效的技术，广泛应用于各种应用领域。这些时态图展现了异质的瞬时动态、不同的时间间隔以及在演化过程中高度变化的节点特征。因此，将历史图上的长程依赖融入到学习时态动态的过程中至关重要。本文提出了一个带有不确定性量化的图嵌入模型TransformerG2G，通过利用先进的Transformer编码器从当前状态（$t$）和之前的上下文（时间戳[$t-1, t-l$]，$l$是上下文的长度）中首先学习中间节点表示。此外，我们采用两个投影层来生成每个节点的低维多元高斯分布，作为其潜在嵌入。

    Dynamic graph embedding has emerged as a very effective technique for addressing diverse temporal graph analytic tasks (i.e., link prediction, node classification, recommender systems, anomaly detection, and graph generation) in various applications. Such temporal graphs exhibit heterogeneous transient dynamics, varying time intervals, and highly evolving node features throughout their evolution. Hence, incorporating long-range dependencies from the historical graph context plays a crucial role in accurately learning their temporal dynamics. In this paper, we develop a graph embedding model with uncertainty quantification, TransformerG2G, by exploiting the advanced transformer encoder to first learn intermediate node representations from its current state ($t$) and previous context (over timestamps [$t-1, t-l$], $l$ is the length of context). Moreover, we employ two projection layers to generate lower-dimensional multivariate Gaussian distributions as each node's latent embedding at ti
    
[^54]: 探索新的方法：强化表征差异以学习新特征并降低错误一致性

    Exploring new ways: Enforcing representational dissimilarity to learn new features and reduce error consistency. (arXiv:2307.02516v1 [cs.LG])

    [http://arxiv.org/abs/2307.02516](http://arxiv.org/abs/2307.02516)

    本文提出了一种新方法，利用表征差异性来降低模型的相关性和常见失败模式。通过使架构之间不同深度的中间表示具有差异性，以学习具有不同失败模式的强大集合，结果表明，这种方法可以提高集合的准确性。

    

    独立训练的机器学习模型往往学习相似的特征。在一组独立训练的模型中，这导致预测相关性和常见的失败模式。以往的尝试着重于减小输出预测或logits的相关性，结果产生了不一致的优化目标，从而降低了模型准确性。在本文中，我们提出了一种新颖的思想，即利用表征相似性领域的方法，在训练过程中促进差异性，而不是衡量训练模型的相似性。为此，我们促进了架构之间不同深度的中间表示的差异性，并旨在学习具有不同失败模式的强大集合。我们表明，高度差异的中间表示导致更少相关的输出预测和稍微较低的错误一致性，从而提高了整体准确性。通过这样做，我们首次揭示了连接的新可能性。

    Independently trained machine learning models tend to learn similar features. Given an ensemble of independently trained models, this results in correlated predictions and common failure modes. Previous attempts focusing on decorrelation of output predictions or logits yielded mixed results, particularly due to their reduction in model accuracy caused by conflicting optimization objectives. In this paper, we propose the novel idea of utilizing methods of the representational similarity field to promote dissimilarity during training instead of measuring similarity of trained models. To this end, we promote intermediate representations to be dissimilar at different depths between architectures, with the goal of learning robust ensembles with disjoint failure modes. We show that highly dissimilar intermediate representations result in less correlated output predictions and slightly lower error consistency, resulting in higher ensemble accuracy. With this, we shine first light on the conne
    
[^55]: 使用患者语音转录和音频数据探索多模态方法进行阿尔茨海默病检测

    Exploring Multimodal Approaches for Alzheimer's Disease Detection Using Patient Speech Transcript and Audio Data. (arXiv:2307.02514v1 [eess.AS])

    [http://arxiv.org/abs/2307.02514](http://arxiv.org/abs/2307.02514)

    本研究使用患者语音和转录数据，探索了多种方法来进行阿尔茨海默病（AD）的检测，包括使用预训练语言模型和图神经网络（GNN）来提取特征，并采用数据增强和音频数据的融合。最后尝试了一种对比学习方法。

    

    阿尔茨海默病（AD）是一种常见的严重影响患者健康的痴呆症。由于AD会影响患者的语言理解和表达能力，患者的语音可以作为指示该疾病的指标。本研究使用来自DementiaBank Pitt数据库的患者语音和转录数据，探索了各种方法来检测AD。所提出的方法包括使用预训练语言模型和图神经网络（GNN）从语音转录构建图，并使用GNN提取特征用于AD检测。采用了数据增强技术，包括同义词替换、基于GPT的增强器等，以解决数据集大小较小的问题。还引入了音频数据，并使用WavLM模型提取音频特征。然后使用各种方法将这些特征与文本特征融合。最后，尝试了一种对比学习方法，通过将语音转录回音频并将其用于对比学习。

    Alzheimer's disease (AD) is a common form of dementia that severely impacts patient health. As AD impairs the patient's language understanding and expression ability, the speech of AD patients can serve as an indicator of this disease. This study investigates various methods for detecting AD using patients' speech and transcripts data from the DementiaBank Pitt database. The proposed approach involves pre-trained language models and Graph Neural Network (GNN) that constructs a graph from the speech transcript, and extracts features using GNN for AD detection. Data augmentation techniques, including synonym replacement, GPT-based augmenter, and so on, were used to address the small dataset size. Audio data was also introduced, and WavLM model was used to extract audio features. These features were then fused with text features using various methods. Finally, a contrastive learning approach was attempted by converting speech transcripts back to audio and using it for contrastive learning
    
[^56]: 用于计算设计的扩散模型在楼层平面示例中的应用

    Diffusion Models for Computational Design at the Example of Floor Plans. (arXiv:2307.02511v1 [cs.LG])

    [http://arxiv.org/abs/2307.02511](http://arxiv.org/abs/2307.02511)

    该论文探索了基于扩散模型的AI生成器在计算设计中的能力，并提出了具有改进的语义编码的新扩散模型。利用这些模型，可以提高生成楼层平面的有效性，并改进不同示例的查询性能。该研究还探讨了将扩散模型与建筑信息模型相结合的方法。

    

    最近，基于扩散模型的AI图像生成器因其能够根据简单的文本提示创建图像而受到广泛讨论。但是，在土木工程的实际应用中，它们需要能够根据给定的约束条件创建特定的建筑设计方案。在本文中，我们以楼层平面作为示例，探索基于扩散的AI生成器在计算设计中的能力，并确定它们目前的限制。我们解释了扩散模型的工作原理，并提出了具有改进的语义编码的新扩散模型。通过多次实验，我们展示了我们可以将生成的楼层平面的有效性从6%提高到90%，并改进了不同示例的查询性能。我们发现了一些问题，并针对这些模型提出了未来的研究挑战，并讨论了将扩散模型与建筑信息模型相结合的需要。通过这些，我们为土木工程中扩散模型的当前状态和未来方向提供了关键见解。

    AI Image generators based on diffusion models are widely discussed recently for their capability to create images from simple text prompts. But, for practical use in civil engineering they need to be able to create specific construction plans for given constraints. Within this paper we explore the capabilities of those diffusion-based AI generators for computational design at the example of floor plans and identify their current limitation. We explain how the diffusion-models work and propose new diffusion models with improved semantic encoding. In several experiments we show that we can improve validity of generated floor plans from 6% to 90% and query performance for different examples. We identify short comings and derive future research challenges of those models and discuss the need to combine diffusion models with building information modelling. With this we provide key insights into the current state and future directions for diffusion models in civil engineering.
    
[^57]: STS-CCL：用于城市交通预测的时空同步上下文对比学习

    STS-CCL: Spatial-Temporal Synchronous Contextual Contrastive Learning for Urban Traffic Forecasting. (arXiv:2307.02507v1 [cs.LG])

    [http://arxiv.org/abs/2307.02507](http://arxiv.org/abs/2307.02507)

    本研究通过引入先进的对比学习方法，提出了一种新颖的时空同步上下文对比学习（STS-CCL）模型，用于高效地捕捉大规模无标签交通数据的复杂时空表示。该模型通过使用动态图视图生成器和语义上下文对比方法，实现了节点级和图级的对比学习。

    

    高效地捕捉大规模无标签交通数据中复杂的时空表示仍然是一个具有挑战性的任务。鉴于这个困境，本文采用先进的对比学习方法，并提出了一种新颖的时空同步上下文对比学习（STS-CCL）模型。首先，我们详细阐述了用于时空图数据的基本和强大的增强方法，这些方法不仅扰动了图结构和时间特征的数据，而且还利用了基于学习的动态图视图生成器进行自适应增强。其次，我们引入了一种时空同步对比模块（STS-CM），以同时捕捉良好的时空依赖关系并实现图级对比。为了进一步区分负筛选中的节点个体，设计了一种基于语义特征和空间异质性的语义上下文对比方法，实现了节点级的对比学习以及…

    Efficiently capturing the complex spatiotemporal representations from large-scale unlabeled traffic data remains to be a challenging task. In considering of the dilemma, this work employs the advanced contrastive learning and proposes a novel Spatial-Temporal Synchronous Contextual Contrastive Learning (STS-CCL) model. First, we elaborate the basic and strong augmentation methods for spatiotemporal graph data, which not only perturb the data in terms of graph structure and temporal characteristics, but also employ a learning-based dynamic graph view generator for adaptive augmentation. Second, we introduce a Spatial-Temporal Synchronous Contrastive Module (STS-CM) to simultaneously capture the decent spatial-temporal dependencies and realize graph-level contrasting. To further discriminate node individuals in negative filtering, a Semantic Contextual Contrastive method is designed based on semantic features and spatial heterogeneity, achieving node-level contrastive learning along with
    
[^58]: 自然语言生成和理解大型代码用于AI辅助编程：一项综述

    Natural Language Generation and Understanding of Big Code for AI-Assisted Programming: A Review. (arXiv:2307.02503v1 [cs.SE])

    [http://arxiv.org/abs/2307.02503](http://arxiv.org/abs/2307.02503)

    这项综述回顾了大型代码训练的transformer-based大语言模型（LLMs）在AI辅助编程方面的应用，包括代码生成、代码摘要、缺陷检测等。同时讨论了将NLP技术与软件自然化相结合的挑战和机会。

    

    本文全面回顾了自然语言处理（NLP）技术的文献，特别关注使用大型代码进行训练的基于transformer的大型语言模型（LLMs）在AI辅助编程任务领域中的应用。经过软件自然化增强的LLMs在促进AI辅助编程应用方面起到了至关重要的作用，包括代码生成、代码补全、代码翻译、代码优化、代码摘要、缺陷检测和克隆检测。其中著名的应用包括由OpenAI的Codex和DeepMind AlphaCode驱动的GitHub Copilot。本文概述了主要的LLMs及其在与AI辅助编程相关的下游任务中的应用。此外，本文探讨了在这些应用中将NLP技术与软件自然化相结合所面临的挑战和机会，并讨论了扩展AI辅助编程的可能性。

    This paper provides a comprehensive review of the literature concerning the utilization of Natural Language Processing (NLP) techniques, with a particular focus on transformer-based large language models (LLMs) trained using Big Code, within the domain of AI-assisted programming tasks. LLMs, augmented with software naturalness, have played a crucial role in facilitating AI-assisted programming applications, including code generation, code completion, code translation, code refinement, code summarization, defect detection, and clone detection. Notable examples of such applications include the GitHub Copilot powered by OpenAI's Codex and DeepMind AlphaCode. This paper presents an overview of the major LLMs and their applications in downstream tasks related to AI-assisted programming. Furthermore, it explores the challenges and opportunities associated with incorporating NLP techniques with software naturalness in these applications, with a discussion on extending AI-assisted programming 
    
[^59]: 数学智能体：计算基础设施、数学嵌入和基因组学

    Math Agents: Computational Infrastructure, Mathematical Embedding, and Genomics. (arXiv:2307.02502v1 [q-bio.OT])

    [http://arxiv.org/abs/2307.02502](http://arxiv.org/abs/2307.02502)

    本文提出了数学智能体和数学嵌入作为解决生成式人工智能在基因组学应用方面的局限性的新方法，通过使用基于GPT的工作流将文献中的方程转换为LaTeX和Python格式，以实现自动化的大规模评估和交互式计算。

    

    生成式人工智能的发展可以通过更易于理解的数学知识来提升。除了人工智能聊天以外，大型语言模型（LLM）也在编程、算法发现和定理证明方面得到应用，但它们在基因组学应用方面的局限性较大。本项目引入了数学智能体和数学嵌入作为“数学摩尔定律”的新进展，使用基于GPT的工作流将文献中的方程转换为LaTeX和Python格式。虽然存在许多数字方程表示方法，但缺乏自动化的大规模评估工具。LLM对于人工智能聊天提供了语言用户界面，并为大规模的AI辅助计算基础设施提供了形式化语言。鉴于无限的形式可能空间，与数学互动的数学智能体有可能使我们从“大数据”转向“大数学”。数学与自然语言不同，具有可以通过证明来验证的特性，使其在应用范围上更加广泛。

    The advancement in generative AI could be boosted with more accessible mathematics. Beyond human-AI chat, large language models (LLMs) are emerging in programming, algorithm discovery, and theorem proving, yet their genomics application is limited. This project introduces Math Agents and mathematical embedding as fresh entries to the "Moore's Law of Mathematics", using a GPT-based workflow to convert equations from literature into LaTeX and Python formats. While many digital equation representations exist, there's a lack of automated large-scale evaluation tools. LLMs are pivotal as linguistic user interfaces, providing natural language access for human-AI chat and formal languages for large-scale AI-assisted computational infrastructure. Given the infinite formal possibility spaces, Math Agents, which interact with math, could potentially shift us from "big data" to "big math". Math, unlike the more flexible natural language, has properties subject to proof, enabling its use beyond tr
    
[^60]: mPLUG-DocOwl: 模块化多模态大型语言模型用于文档理解

    mPLUG-DocOwl: Modularized Multimodal Large Language Model for Document Understanding. (arXiv:2307.02499v1 [cs.CL])

    [http://arxiv.org/abs/2307.02499](http://arxiv.org/abs/2307.02499)

    mPLUG-DocOwl是一种模块化多模态大型语言模型，用于无OCR文档理解。它通过联合训练语言、通用视觉-语言和文档指令调优数据集，提升了无OCR文档理解能力。

    

    文档理解是指从各种类型的数字文档中自动提取、分析和理解信息，例如网页。现有的多模态大型语言模型（MLLMs），包括mPLUG-Owl，已经展示了有希望的零-shot能力，可以实现无OCR的文本识别，表明它们在无OCR文档理解方面具有潜力。然而，这些模型在没有领域内训练的情况下，往往忽视OCR细粒度特征，如复杂的表格或大块文本，这些特征对于无OCR文档理解是必要的。在本文中，我们基于mPLUG-Owl提出了mPLUG-DocOwl，用于无OCR文档理解。具体而言，我们首先构建了一个包含多种视觉-文本理解任务的指令调优数据集。然后，我们通过针对语言、通用视觉-语言和文档指令调优数据集进行联合训练来增强无OCR文档理解能力。

    Document understanding refers to automatically extract, analyze and comprehend information from various types of digital documents, such as a web page. Existing Multi-model Large Language Models (MLLMs), including mPLUG-Owl, have demonstrated promising zero-shot capabilities in shallow OCR-free text recognition, indicating their potential for OCR-free document understanding. Nevertheless, without in-domain training, these models tend to ignore fine-grained OCR features, such as sophisticated tables or large blocks of text, which are essential for OCR-free document understanding. In this paper, we propose mPLUG-DocOwl based on mPLUG-Owl for OCR-free document understanding. Specifically, we first construct a instruction tuning dataset featuring a wide range of visual-text understanding tasks. Then, we strengthen the OCR-free document understanding ability by jointly train the model on language-only, general vision-and-language, and document instruction tuning dataset with our unified ins
    
[^61]: 基于基于补丁自编码器的图像或潜在空间的异常检测在工业图像分析中的应用

    Anomaly detection in image or latent space of patch-based auto-encoders for industrial image analysis. (arXiv:2307.02495v1 [cs.CV])

    [http://arxiv.org/abs/2307.02495](http://arxiv.org/abs/2307.02495)

    该论文研究了使用基于补丁自编码器构建的图像或潜在空间的多种方法来检测工业图像中的异常，并与其他两种方法进行了比较和评估。

    

    我们研究了基于补丁自编码器构建的颜色图像中检测异常的几种方法。我们比较了基于原始图像和其重构之间的误差、基于潜在空间中正常图像分布的支持估计以及基于原始图像与重建图像的恢复版本之间的误差这三种方法的性能。这些方法在工业图像数据库MVTecAD上进行评估，并与两种具有竞争力的现有方法进行了比较。

    We study several methods for detecting anomalies in color images, constructed on patch-based auto-encoders. Wecompare the performance of three types of methods based, first, on the error between the original image and its reconstruction,second, on the support estimation of the normal image distribution in the latent space, and third, on the error between the originalimage and a restored version of the reconstructed image. These methods are evaluated on the industrial image database MVTecADand compared to two competitive state-of-the-art methods.
    
[^62]: FREEDOM: 无目标标签、无源数据和无领域信息的多源领域自适应无监督个性化方法

    FREEDOM: Target Label & Source Data & Domain Information-Free Multi-Source Domain Adaptation for Unsupervised Personalization. (arXiv:2307.02493v1 [cs.LG])

    [http://arxiv.org/abs/2307.02493](http://arxiv.org/abs/2307.02493)

    本文提出了一种新的问题场景TFDA，即三无领域自适应，解决了多源领域自适应中目标标签、源数据和领域信息不可用的问题。这种方法更加实用，避免了对先前领域信息的依赖和数据隐私问题。

    

    从服务角度来看，多源领域自适应（MSDA）是一种适应部署模型到客户数据集的有希望的场景。它可以在没有目标标签的情况下提供适应，并支持多个领域构建的源数据集的情况。然而，这种方法依赖于先前的多源数据集的领域信息，即有多少个领域存在以及每个数据样本的领域标签。此外，MSDA需要同时拥有源数据集和目标数据集（物理上），这会导致客户设备存储限制或通过将客户数据传输到服务器引起数据隐私问题。为了更实际的模型自适应场景，我们放宽了这些限制，提出了一种新的问题场景，即三无领域自适应（TFDA），其中1）目标标签，2）源数据集，以及大部分3）源领域信息（领域标签+领域数量）都不可用。

    From a service perspective, Multi-Source Domain Adaptation (MSDA) is a promising scenario to adapt a deployed model to a client's dataset. It can provide adaptation without a target label and support the case where a source dataset is constructed from multiple domains. However, it is impractical, wherein its training heavily relies on prior domain information of the multi-source dataset -- how many domains exist and the domain label of each data sample. Moreover, MSDA requires both source and target datasets simultaneously (physically), causing storage limitations on the client device or data privacy issues by transferring client data to a server. For a more practical scenario of model adaptation from a service provider's point of view, we relax these constraints and present a novel problem scenario of Three-Free Domain Adaptation, namely TFDA, where 1) target labels, 2) source dataset, and mostly 3) source domain information (domain labels + the number of domains) are unavailable. Und
    
[^63]: TablEye: 通过图像视角看小表格

    TablEye: Seeing small Tables through the Lens of Images. (arXiv:2307.02491v1 [cs.LG])

    [http://arxiv.org/abs/2307.02491](http://arxiv.org/abs/2307.02491)

    本文提出了一种创新的框架TablEye，通过生成表格图像来实现领域转换，克服了形成表格数据先验知识的限制，从而实现了少样本表格学习。

    

    少样本表格学习的探索变得迫切。表格数据是一种多功能的表示形式，可以捕捉多样的信息，但也存在数据和模型大小的限制。标记大量的表格数据可能具有挑战性，并且可能不可行捕捉每一个重要特征。然而，少样本表格学习相对未被充分探索，主要是由于独立数据集中共享信息的稀缺性以及定义表格数据边界的内在模糊性。据我们所知，目前尚未开发出无限制条件的有意义且可行的少样本表格学习技术。在本文中，我们提出了一种创新的框架TablEye，通过采用领域转换来克服形成表格数据先验知识的限制。它通过生成表格图像来实现领域转换，从而有效地保留了内在的语义。

    The exploration of few-shot tabular learning becomes imperative. Tabular data is a versatile representation that captures diverse information, yet it is not exempt from limitations, property of data and model size. Labeling extensive tabular data can be challenging, and it may not be feasible to capture every important feature. Few-shot tabular learning, however, remains relatively unexplored, primarily due to scarcity of shared information among independent datasets and the inherent ambiguity in defining boundaries within tabular data. To the best of our knowledge, no meaningful and unrestricted few-shot tabular learning techniques have been developed without imposing constraints on the dataset. In this paper, we propose an innovative framework called TablEye, which aims to overcome the limit of forming prior knowledge for tabular data by adopting domain transformation. It facilitates domain transformation by generating tabular images, which effectively conserve the intrinsic semantic
    
[^64]: 图像中带有叠加文本的视觉问答（VQA）。

    Visual Question Answering (VQA) on Images with Superimposed Text. (arXiv:2307.02489v1 [cs.CV])

    [http://arxiv.org/abs/2307.02489](http://arxiv.org/abs/2307.02489)

    本研究探讨了在医学图像上叠加文本对VQA的影响，并发现这种做法不会严重降低VQA性能。这一发现对于验证在图像上叠加文本的实践方式具有重要意义，特别是在医学领域的VQA任务中使用AI技术。

    

    叠加的文本注释一直是研究不足的，但在医学图像中普遍存在且非常重要。医学图像还突出了低分辨率、噪声和叠加的文本元信息所带来的挑战。因此，我们研究了在医学图像上叠加文本对VQA的影响。我们的研究结果表明，即使在使用AI技术进行VQA任务的医学图像中，添加这些文本元信息也不会严重降低VQA性能的关键指标。我们的发现具有重要意义，因为它们验证了在图像上叠加文本的做法，甚至适用于医学图像领域的VQA任务。该研究有助于推进对VQA的理解，特别是在医疗保健和医学领域。

    Superimposed text annotations have been under-investigated, yet are ubiquitous, useful and important, especially in medical images. Medical images also highlight the challenges posed by low resolution, noise and superimposed textual meta-information. Therefor we probed the impact of superimposing text onto medical images on VQA. Our results revealed that this textual meta-information can be added without severely degrading key measures of VQA performance. Our findings are significant because they validate the practice of superimposing text on images, even for medical images subjected to the VQA task using AI techniques. The work helps advance understanding of VQA in general and, in particular, in the domain of healthcare and medicine.
    
[^65]: 自然语言证明规划的演绎可加性研究

    Deductive Additivity for Planning of Natural Language Proofs. (arXiv:2307.02472v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2307.02472](http://arxiv.org/abs/2307.02472)

    本论文研究了自然语言证明规划中的演绎可加性，探讨了是否能够通过嵌入空间实现高效的规划启发式方法。研究结果表明，嵌入空间的前提陈述总和接近于基于这些前提的结论嵌入。从而证明了演绎可加性的存在。

    

    当前设计用于多步骤命题验证的自然语言系统通常分为两个阶段：使用启发式方法检索一组相关的前提陈述（规划），然后使用大型语言模型从这些陈述中生成新的结论（演绎）。规划阶段通常需要昂贵的Transformer操作，并且无法扩展到任意数量的前提陈述。本文研究了是否可以通过与演绎推理兼容的嵌入空间实现高效的规划启发式方法。具体地，我们评估了嵌入空间是否具有我们称之为演绎可加性的特性：前提陈述嵌入的总和应该接近基于这些前提的结论的嵌入。除了来自GPT3的微调嵌入和来自BM25的稀疏嵌入之外，我们还探索了多种现成的密集嵌入源。我们在内在上研究了嵌入模型，评估了演绎可加性的属性是否存在。

    Current natural language systems designed for multi-step claim validation typically operate in two phases: retrieve a set of relevant premise statements using heuristics (planning), then generate novel conclusions from those statements using a large language model (deduction). The planning step often requires expensive Transformer operations and does not scale to arbitrary numbers of premise statements. In this paper, we investigate whether an efficient planning heuristic is possible via embedding spaces compatible with deductive reasoning. Specifically, we evaluate whether embedding spaces exhibit a property we call deductive additivity: the sum of premise statement embeddings should be close to embeddings of conclusions based on those premises. We explore multiple sources of off-the-shelf dense embeddings in addition to fine-tuned embeddings from GPT3 and sparse embeddings from BM25. We study embedding models both intrinsically, evaluating whether the property of deductive additivity
    
[^66]: 带有巨型语言模型的具身任务规划

    Embodied Task Planning with Large Language Models. (arXiv:2307.01848v1 [cs.CV] CROSS LISTED)

    [http://arxiv.org/abs/2307.01848](http://arxiv.org/abs/2307.01848)

    本文提出了一个带有巨型语言模型的具身任务规划代理（TaPA），通过将LLM与视觉感知模型对齐，根据场景中已存在的对象生成可执行的计划。通过构建多模态数据集和利用GPT-3.5生成的数据对预训练模型进行具身计划的调优。

    

    为了使机器人能够在通用环境中成功完成复杂的人类指令，为具身智能体提供常识是非常重要的。最近的巨型语言模型（LLM）可以在复杂任务的计划生成中嵌入丰富的语义知识，然而它们缺乏关于真实世界的信息，通常会产生不可行的动作序列。在本文中，我们提出了一个具身任务规划代理（TaPA），用于基于物理场景约束的具身任务规划，其中代理根据场景中已存在的对象通过将LLM与视觉感知模型对齐来生成可执行的计划。具体而言，我们首先构建了一个包含室内场景、指令和行动计划三元组的多模态数据集，其中我们为GPT-3.5提供了设计的提示信息和场景中已存在的对象列表，以生成大量的指令和相应的计划行动。生成的数据用于预训练的基础上进行具身计划的调优。

    Equipping embodied agents with commonsense is important for robots to successfully complete complex human instructions in general environments. Recent large language models (LLM) can embed rich semantic knowledge for agents in plan generation of complex tasks, while they lack the information about the realistic world and usually yield infeasible action sequences. In this paper, we propose a TAsk Planing Agent (TaPA) in embodied tasks for grounded planning with physical scene constraint, where the agent generates executable plans according to the existed objects in the scene by aligning LLMs with the visual perception models. Specifically, we first construct a multimodal dataset containing triplets of indoor scenes, instructions and action plans, where we provide the designed prompts and the list of existing objects in the scene for GPT-3.5 to generate a large number of instructions and corresponding planned actions. The generated data is leveraged for grounded plan tuning of pre-traine
    
[^67]: 可靠的人工智能：下一代是否需要量子计算？

    Reliable AI: Does the Next Generation Require Quantum Computing?. (arXiv:2307.01301v1 [cs.AI])

    [http://arxiv.org/abs/2307.01301](http://arxiv.org/abs/2307.01301)

    这项调查研究了下一代人工智能是否需要量子计算，发现数字硬件无法完全解决可靠性问题。

    

    在这项调查中，我们旨在探讨一个基本问题，即下一代人工智能是否需要量子计算。人工智能在我们日常生活的许多方面都起着重要作用，并且是第四次工业革命的核心。因此，人工智能的可靠性和值得信赖性是至关重要的。然而，人工智能的可靠性仍然存在许多问题，例如隐私、责任、安全等，在自动驾驶、医疗保健、机器人等领域都存在着。这些问题可能有各种原因，包括数据不足、偏见、鲁棒性问题，以及基本的计算问题，如数字硬件上的可计算性问题。这些可计算性问题的根源在于数字硬件基于图灵机的计算模型，该模型本质上是离散的。值得注意的是，我们的研究结果表明，数字硬件无法完全解决这些问题。

    In this survey, we aim to explore the fundamental question of whether the next generation of artificial intelligence requires quantum computing. Artificial intelligence is increasingly playing a crucial role in many aspects of our daily lives and is central to the fourth industrial revolution. It is therefore imperative that artificial intelligence is reliable and trustworthy. However, there are still many issues with reliability of artificial intelligence, such as privacy, responsibility, safety, and security, in areas such as autonomous driving, healthcare, robotics, and others. These problems can have various causes, including insufficient data, biases, and robustness problems, as well as fundamental issues such as computability problems on digital hardware. The cause of these computability problems is rooted in the fact that digital hardware is based on the computing model of the Turing machine, which is inherently discrete. Notably, our findings demonstrate that digital hardware i
    
[^68]: REAL:一种基于代表性错误驱动的主动学习方法

    REAL: A Representative Error-Driven Approach for Active Learning. (arXiv:2307.00968v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2307.00968](http://arxiv.org/abs/2307.00968)

    本研究提出了一种名为REAL的新方法，该方法通过选择具有代表性错误的数据实例来改进主动学习。通过考虑错误实例及其邻域中的错误密度，REAL在准确率和F1-macro得分方面优于其他算法。

    

    在拥有有限标记预算的情况下，主动学习旨在从未标记的样本中选择最具信息量的实例，以获取标签用于模型训练。为了实现这一目标，主动学习通常根据不确定性和多样性来衡量未标记实例的信息量。然而，它并不考虑具有邻域错误密度的错误实例，这些实例在提高模型性能方面具有巨大潜力。为了解决这个局限性，我们提出了一种名为REAL的新方法，该方法选择具有代表性错误的数据实例用于主动学习。它将少数预测作为聚类中的“伪错误”进行识别，并根据估计的错误密度为该聚类分配自适应的采样预算。在五个文本分类数据集上进行的大量实验证明，REAL在准确率和F1-macro得分方面始终优于所有表现最佳的基准算法。

    Given a limited labeling budget, active learning (AL) aims to sample the most informative instances from an unlabeled pool to acquire labels for subsequent model training. To achieve this, AL typically measures the informativeness of unlabeled instances based on uncertainty and diversity. However, it does not consider erroneous instances with their neighborhood error density, which have great potential to improve the model performance. To address this limitation, we propose $REAL$, a novel approach to select data instances with $\underline{R}$epresentative $\underline{E}$rrors for $\underline{A}$ctive $\underline{L}$earning. It identifies minority predictions as \emph{pseudo errors} within a cluster and allocates an adaptive sampling budget for the cluster based on estimated error density. Extensive experiments on five text classification datasets demonstrate that $REAL$ consistently outperforms all best-performing baselines regarding accuracy and F1-macro scores across a wide range of
    
[^69]: 图像的重要性：多模态夸张检测的新数据集和实证研究

    Image Matters: A New Dataset and Empirical Study for Multimodal Hyperbole Detection. (arXiv:2307.00209v1 [cs.CV])

    [http://arxiv.org/abs/2307.00209](http://arxiv.org/abs/2307.00209)

    本研究提出了一个新的多模态夸张检测数据集，并使用文本和图像作为两种模态进行研究。同时，评估了不同预训练的多模态编码器在此任务中的表现。该研究探索了夸张检测的跨领域性能。

    

    夸张，即夸大其词，是一种常见的语言现象。夸张检测是理解人类表达的重要部分。已经有几项关于夸张检测的研究，但大多数的研究只关注文本模态。然而，随着社交媒体的发展，人们可以使用各种模态（包括文本、图像、视频等）来表达夸张。在本文中，我们专注于多模态夸张检测。我们从微博（中国的一种社交媒体）创建了一个多模态检测数据集，并对其进行了一些研究。我们将微博的文本和图像视为两种模态，探索了文本和图像在夸张检测中的作用。此外，我们还评估了不同预训练的多模态编码器在这个下游任务上的性能。由于这个数据集是从五个不同的主题构建的，我们还评估了不同领域之间的性能。

    Hyperbole, or exaggeration, is a common linguistic phenomenon. The detection of hyperbole is an important part of understanding human expression. There have been several studies on hyperbole detection, but most of which focus on text modality only. However, with the development of social media, people can create hyperbolic expressions with various modalities, including text, images, videos, etc. In this paper, we focus on multimodal hyperbole detection. We create a multimodal detection dataset\footnote{The dataset will be released to the community.} from Weibo (a Chinese social media) and carry out some studies on it. We treat the text and image from a piece of weibo as two modalities and explore the role of text and image for hyperbole detection. Different pre-trained multimodal encoders are also evaluated on this downstream task to show their performance. Besides, since this dataset is constructed from five different topics, we also evaluate the cross-domain performance of different 
    
[^70]: 面向开放词汇学习的调研

    Towards Open Vocabulary Learning: A Survey. (arXiv:2306.15880v1 [cs.CV])

    [http://arxiv.org/abs/2306.15880](http://arxiv.org/abs/2306.15880)

    该论文调研了在视觉场景理解领域的开放词汇学习，在与零样本学习和开放集识别等相关概念的比较中，总结和分析了该领域的最新发展。

    

    在视觉场景理解领域，深度神经网络在分割、跟踪和检测等各种核心任务上取得了令人瞩目的进展。然而，大多数方法基于封闭集的假设，即模型只能识别训练集中已定义的类别。最近，由于视觉语言预训练的快速进展，提出了开放词汇设置。这些新方法旨在定位和识别超出注释标签空间的类别。与弱监督和零样本设置相比，开放词汇方法更加通用、实用和有效。本文对开放词汇学习进行了全面的回顾，总结和分析了近期在该领域的发展。特别是，我们首先将其与零样本学习、开放集识别和超出分布检测等相关概念进行了比较。然后，在分割任务的几个紧密相关的任务中进行了回顾。

    In the field of visual scene understanding, deep neural networks have made impressive advancements in various core tasks like segmentation, tracking, and detection. However, most approaches operate on the close-set assumption, meaning that the model can only identify pre-defined categories that are present in the training set. Recently, open vocabulary settings were proposed due to the rapid progress of vision language pre-training. These new approaches seek to locate and recognize categories beyond the annotated label space. The open vocabulary approach is more general, practical, and effective compared to weakly supervised and zero-shot settings. This paper provides a thorough review of open vocabulary learning, summarizing and analyzing recent developments in the field. In particular, we begin by comparing it to related concepts such as zero-shot learning, open-set recognition, and out-of-distribution detection. Then, we review several closely related tasks in the case of segmentati
    
[^71]: UTRNet: 印刷文档中高分辨率乌尔都文本识别

    UTRNet: High-Resolution Urdu Text Recognition In Printed Documents. (arXiv:2306.15782v1 [cs.CV])

    [http://arxiv.org/abs/2306.15782](http://arxiv.org/abs/2306.15782)

    本文提出了一种解决印刷乌尔都文本识别挑战的新方法，并引入了大规模实际标记数据集和合成数据集，提供了乌尔都文本行检测的基准数据集，同时开发了一个在线工具，实现了印刷文档中乌尔都OCR的端到端识别。

    

    本文提出了一种新颖方法来解决印刷乌尔都文本识别的挑战，使用高分辨率、多尺度的语义特征提取。我们提出的UTRNet架构，一个混合CNN-RNN模型，在基准数据集上展示了最先进的性能。为了解决以前工作的局限性，这些工作很难推广到乌尔都文本的复杂性和缺乏足够的实际标记数据，我们引入了UTRSet-Real，一个包含超过11,000行的大规模实际标记数据集和UTRSet-Synth，一个与实际世界非常相似的含有20,000行的合成数据集，并对现有的IIITH数据集的基准真实性进行了修正，使其成为未来研究的更可靠的资源。我们还提供了UrduDoc，一种用于扫描文档中乌尔都文本行检测的基准数据集。此外，我们还开发了一种在线工具，通过将UTRNet与文本的端到端乌尔都OCR集成在印刷文档中。

    In this paper, we propose a novel approach to address the challenges of printed Urdu text recognition using high-resolution, multi-scale semantic feature extraction. Our proposed UTRNet architecture, a hybrid CNN-RNN model, demonstrates state-of-the-art performance on benchmark datasets. To address the limitations of previous works, which struggle to generalize to the intricacies of the Urdu script and the lack of sufficient annotated real-world data, we have introduced the UTRSet-Real, a large-scale annotated real-world dataset comprising over 11,000 lines and UTRSet-Synth, a synthetic dataset with 20,000 lines closely resembling real-world and made corrections to the ground truth of the existing IIITH dataset, making it a more reliable resource for future research. We also provide UrduDoc, a benchmark dataset for Urdu text line detection in scanned documents. Additionally, we have developed an online tool for end-to-end Urdu OCR from printed documents by integrating UTRNet with a tex
    
[^72]: 基于大语言模型的中文细粒度金融情感分析

    Chinese Fine-Grained Financial Sentiment Analysis with Large Language Models. (arXiv:2306.14096v1 [cs.CL])

    [http://arxiv.org/abs/2306.14096](http://arxiv.org/abs/2306.14096)

    本文提出了一个用于企业预警的新型、广泛的中文细粒度金融情感分析数据集FinChina SA，并使用现有开源大语言模型对其进行评估和实验。该数据集将成为推进真实金融情感分析任务探索的宝贵资源。

    

    金融领域实体级别的细粒度情感分析是情感分析的重要子任务，目前面临着众多挑战。其中主要挑战之一来自于缺乏专门设计用于金融文本情感分析的高质量大规模标注语料库，这限制了开发有效文本处理技术所需的数据的可用性。大语言模型（LLMs）的最新进展在自然语言处理任务中取得了显著的性能，主要集中在语言模式匹配方面。在本文中，我们提出了一个新颖的、广泛的中文细粒度金融情感分析数据集FinChina SA，用于企业预警。我们对流行的现有开源LLMs使用我们的数据集进行了全面的评估和实验。我们坚信，我们的数据集将成为推动真实世界金融情感分析任务探索的宝贵资源。

    Entity-level fine-grained sentiment analysis in the financial domain is a crucial subtask of sentiment analysis and currently faces numerous challenges. The primary challenge stems from the lack of high-quality and large-scale annotated corpora specifically designed for financial text sentiment analysis, which in turn limits the availability of data necessary for developing effective text processing techniques. Recent advancements in large language models (LLMs) have yielded remarkable performance in natural language processing tasks, primarily centered around language pattern matching. In this paper, we propose a novel and extensive Chinese fine-grained financial sentiment analysis dataset, FinChina SA, for enterprise early warning. We thoroughly evaluate and experiment with well-known existing open-source LLMs using our dataset. We firmly believe that our dataset will serve as a valuable resource to advance the exploration of real-world financial sentiment analysis tasks, which shoul
    
[^73]: 多黑盒预言下的主动策略改进

    Active Policy Improvement from Multiple Black-box Oracles. (arXiv:2306.10259v1 [cs.LG])

    [http://arxiv.org/abs/2306.10259](http://arxiv.org/abs/2306.10259)

    本研究提出了MAPS和MAPS-SE两个算法，可在多黑盒预言情况下，采用模仿学习并主动选择和改进最优预言，显著提升了性能。

    

    强化学习在各种复杂领域中取得了重大进展，但是通过强化学习确定有效策略往往需要进行广泛的探索，而模仿学习旨在通过使用专家演示来指导探索，缓解这个问题。在真实世界情境下，人们通常只能接触到多个次优的黑盒预言，而不是单个最优的预言，这些预言不能在所有状态下普遍优于彼此，这给主动决定在哪种状态下使用哪种预言以及如何改进各自估计值函数提出了挑战。本文介绍了一个可行的解决方案，即MAPS和MAPS-SE算法。

    Reinforcement learning (RL) has made significant strides in various complex domains. However, identifying an effective policy via RL often necessitates extensive exploration. Imitation learning aims to mitigate this issue by using expert demonstrations to guide exploration. In real-world scenarios, one often has access to multiple suboptimal black-box experts, rather than a single optimal oracle. These experts do not universally outperform each other across all states, presenting a challenge in actively deciding which oracle to use and in which state. We introduce MAPS and MAPS-SE, a class of policy improvement algorithms that perform imitation learning from multiple suboptimal oracles. In particular, MAPS actively selects which of the oracles to imitate and improve their value function estimates, and MAPS-SE additionally leverages an active state exploration criterion to determine which states one should explore. We provide a comprehensive theoretical analysis and demonstrate that MAP
    
[^74]: 使用超参数调优模型的堆叠方法解决编码问题的翻译

    Stacking of Hyperparameter Tuned Models for Tagging Coding Problems. (arXiv:2306.10077v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2306.10077](http://arxiv.org/abs/2306.10077)

    这项工作使用超参数调优的增强模型堆叠方法，在Codeforces和Leetcode的数据集上取得了77.8%的准确率和0.815的PR-AUC分数。

    

    编码问题是需要以计算机程序形式提供解决方案的问题。编码问题在学生和专业人士中非常受欢迎，因为它可以提升他们的技能和职业机会。一个能够帮助练习编码问题的AI系统将非常有用，并且存在巨大的潜力。在这项工作中，我们提出了一种采用超参数调优的增强模型堆叠方法，以在从Codeforces和Leetcode获取的数据集上达到77.8％的准确率和0.815的PR-AUC分数。我们开源了为这项工作开发的数据集和模型。

    Coding problems are problems that require a solution in the form of a computer program. Coding problems are popular among students and professionals as it enhances their skills and career opportunities. An AI system that would help those who practice coding problems would be highly useful and there is a huge potential for such a system. In this work, we propose a model which uses stacking of hyperparameter tuned boosting models to achieve impressive metric scores of 77.8% accuracy and 0.815 PR-AUC on the dataset that was scraped from Codeforces and Leetcode. We open source the dataset and the models developed for this work.
    
[^75]: 在表面之下寻找：利用基本对称性实现高效离线强化学习

    Look Beneath the Surface: Exploiting Fundamental Symmetry for Sample-Efficient Offline RL. (arXiv:2306.04220v1 [cs.LG])

    [http://arxiv.org/abs/2306.04220](http://arxiv.org/abs/2306.04220)

    本文提出了一个新的离线强化学习算法TDM，利用系统动力学的基本对称性实现高效学习小数据集。

    

    离线强化学习通过从预先收集的数据集中学习策略来解决与环境交互的实际问题。然而，现有的离线强化学习算法的性能严重依赖于数据集的规模和状态-动作空间覆盖范围。真实世界数据的收集通常是昂贵和难以控制的，导致数据集小且覆盖范围狭窄，从而对离线强化学习的实际部署提出了重大挑战。在本文中，我们提供了一个新的见解，即利用系统动力学的基本对称性可以在小数据集下显著提高离线强化学习的性能。具体来说，我们提出了一个时间反演对称(T-symmetry)强制的动力学模型(TDM)，建立了一对正向和反向潜在动力学之间的一致性。TDM为小数据集提供了良好的表示，并基于T-symmetry的符合性提供了一种新的OOD样本的可靠性度量。

    Offline reinforcement learning (RL) offers an appealing approach to real-world tasks by learning policies from pre-collected datasets without interacting with the environment. However, the performance of existing offline RL algorithms heavily depends on the scale and state-action space coverage of datasets. Real-world data collection is often expensive and uncontrollable, leading to small and narrowly covered datasets and posing significant challenges for practical deployments of offline RL. In this paper, we provide a new insight that leveraging the fundamental symmetry of system dynamics can substantially enhance offline RL performance under small datasets. Specifically, we propose a Time-reversal symmetry (T-symmetry) enforced Dynamics Model (TDM), which establishes consistency between a pair of forward and reverse latent dynamics. TDM provides both well-behaved representations for small datasets and a new reliability measure for OOD samples based on compliance with the T-symmetry. 
    
[^76]: 机器人的高效自动化设计

    Efficient automatic design of robots. (arXiv:2306.03263v1 [cs.RO])

    [http://arxiv.org/abs/2306.03263](http://arxiv.org/abs/2306.03263)

    本论文首次使用进化计算和人工神经网络，能够在单个消费者级计算机上数秒内优化机器人结构以达到所需行为，为自动化设计复杂系统开辟了新的可能性。

    

    由于机器人的物理结构、感官、马达布局和行为之间存在复杂的相互依赖关系，它们的设计通常非常困难。20年来，启发于自然界的进化设计，使用进化算法自动设计机器人已经尝试过无数次，但这也非常低效。本文展示了首次在单个消费者级计算机上的数秒内优化机器人结构以展现所需行为，并制造出具有该行为的机器人。与其他基于梯度的机器人设计方法不同的是，本算法不预设任何特定的解剖形式，而是从随机生成的软体机器人种群开始，使用进化计算和人工神经网络的技术来引导优化过程。我们的方法为自动化设计机器人和其他难以手动设计的复杂系统开辟了新的可能性。

    Robots are notoriously difficult to design because of complex interdependencies between their physical structure, sensory and motor layouts, and behavior. Despite this, almost every detail of every robot built to date has been manually determined by a human designer after several months or years of iterative ideation, prototyping, and testing. Inspired by evolutionary design in nature, the automated design of robots using evolutionary algorithms has been attempted for two decades, but it too remains inefficient: days of supercomputing are required to design robots in simulation that, when manufactured, exhibit desired behavior. Here we show for the first time de-novo optimization of a robot's structure to exhibit a desired behavior, within seconds on a single consumer-grade computer, and the manufactured robot's retention of that behavior. Unlike other gradient-based robot design methods, this algorithm does not presuppose any particular anatomical form; starting instead from a randoml
    
[^77]: 基准数据集上 ChatGPT 的系统研究和全面评估

    A Systematic Study and Comprehensive Evaluation of ChatGPT on Benchmark Datasets. (arXiv:2305.18486v1 [cs.CL])

    [http://arxiv.org/abs/2305.18486](http://arxiv.org/abs/2305.18486)

    本文对基准数据集上 ChatGPT 的性能进行了全面的评估，包括问答、文本摘要、代码生成、常识推理、数学问题求解、机器翻译、偏见检测和伦理考虑等任务。研究旨在验证 ChatGPT 的优势和弱点，并为使用语言模型的未来研究提供见解。

    

    最近，如 ChatGPT 这样的大型语言模型（LLM）的开发引起了很多关注。然而，由于难以将该模型生成的产出与基本事实进行比较，因此其在基准学术数据集上的评估仍未充分探索。本文旨在对 ChatGPT 在包括问答、文本摘要、代码生成、常识推理、数学问题求解、机器翻译、偏见检测和伦理考虑等任务中的表现进行彻底评估。具体而言，我们在 140 个任务中评估了 ChatGPT，并分析了其在这些数据集中生成的 255K 次响应，这使我们的工作成为了在 NLP 基准测试中对 ChatGPT 进行的最大评估。简而言之，我们的研究旨在验证 ChatGPT 在各种任务中的优势和弱点，并为使用 LLM 的未来研究提供见解。我们还报告了一种新的迸发能力，即遵循多个查询指令。

    The development of large language models (LLMs) such as ChatGPT has brought a lot of attention recently. However, their evaluation in the benchmark academic datasets remains under-explored due to the difficulty of evaluating the generative outputs produced by this model against the ground truth. In this paper, we aim to present a thorough evaluation of ChatGPT's performance on diverse academic datasets, covering tasks like question-answering, text summarization, code generation, commonsense reasoning, mathematical problem-solving, machine translation, bias detection, and ethical considerations. Specifically, we evaluate ChatGPT across 140 tasks and analyze 255K responses it generates in these datasets. This makes our work the largest evaluation of ChatGPT in NLP benchmarks. In short, our study aims to validate the strengths and weaknesses of ChatGPT in various tasks and provide insights for future research using LLMs. We also report a new emergent ability to follow multi-query instruct
    
[^78]: 在Lenia中捕获新兴复杂性

    Capturing Emerging Complexity in Lenia. (arXiv:2305.09378v1 [cs.NE])

    [http://arxiv.org/abs/2305.09378](http://arxiv.org/abs/2305.09378)

    研究人工生命平台Lenia，通过识别复杂新兴行为的度量标准和使用遗传算法产生不同行为的结果，以进化出更好的Lenia行为。

    

    本研究项目探讨了Lenia，这是一个模拟数字生物系统的人工生命平台。Lenia的生态系统由简单的人工生物组成，它们可以移动、消耗、生长和繁殖。该平台是一个研究人工生命和进化的重要工具，因为它提供了一个可扩展和灵活的环境，用于创建具有不同能力和行为的多样化生物。该研究的关键是在Lenia中测量复杂性，识别测量规则的长期复杂性新兴行为的度量标准，旨在进化出尚未发现的更好的Lenia行为。遗传算法使用相邻区域或核作为基因型，同时保持Lenia的其他参数（例如生长函数）不变，以产生不同人口行为的结果，然后测量适应度值以决定所得行为的复杂性。首先，我们使用时间变化作为适应度函数，

    This research project investigates Lenia, an artificial life platform that simulates ecosystems of digital creatures. Lenia's ecosystem consists of simple, artificial organisms that can move, consume, grow, and reproduce. The platform is important as a tool for studying artificial life and evolution, as it provides a scalable and flexible environment for creating a diverse range of organisms with varying abilities and behaviors. Measuring complexity in Lenia is a key aspect of the study, which identifies the metrics for measuring long-term complex emerging behavior of rules, with the aim of evolving better Lenia behaviors which are yet not discovered. The Genetic Algorithm uses neighborhoods or kernels as genotype while keeping the rest of the parameters of Lenia as fixed, for example growth function, to produce different behaviors respective to the population and then measures fitness value to decide the complexity of the resulting behavior. First, we use Variation over Time as a fitn
    
[^79]: 快速和多方面挖掘复杂的时间戳事件流

    Fast and Multi-aspect Mining of Complex Time-stamped Event Streams. (arXiv:2303.03789v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.03789](http://arxiv.org/abs/2303.03789)

    这篇论文提出了一种名为CubeScope的方法，用于快速、多方面地挖掘复杂的时间戳事件流。该方法能够识别突然的不连续性和不同的动态模式，并对所有属性进行多方面摘要，并发现隐藏的群体和其关系。CubeScope还能检测到异常的突然出现。

    

    针对具有多个属性的大规模在线时间演变事件流（如在线购物日志：项目、价格、品牌、时间和地理位置活动：上车和下车地点、时间），我们如何对大规模、动态、高阶张量流进行摘要？我们的回答是专注于两种类型的模式，即“制度”和“组件”，我们提出了一种高效有效的方法CubeScope来处理高阶张量流。具体而言，它识别任何突然的不连续性，并识别出不同的动态模式“制度”（例如工作日/周末/假期模式）。在每个制度中，它还对所有属性（例如项目、价格、品牌和时间）进行多方面摘要，并发现表示潜在群体（例如项目/品牌群）及其关系的隐藏的“组件”。由于其简洁而有效的摘要，CubeScope还能检测到异常的突然出现。

    Given a huge, online stream of time-evolving events with multiple attributes, such as online shopping logs: (item, price, brand, time), and local mobility activities: (pick-up and drop-off locations, time), how can we summarize large, dynamic high-order tensor streams? How can we see any hidden patterns, rules, and anomalies? Our answer is to focus on two types of patterns, i.e., ''regimes'' and ''components'', for which we present CubeScope, an efficient and effective method over high-order tensor streams. Specifically, it identifies any sudden discontinuity and recognizes distinct dynamical patterns, ''regimes'' (e.g., weekday/weekend/holiday patterns). In each regime, it also performs multi-way summarization for all attributes (e.g., item, price, brand, and time) and discovers hidden ''components'' representing latent groups (e.g., item/brand groups) and their relationship. Thanks to its concise but effective summarization, CubeScope can also detect the sudden appearance of anomalie
    
[^80]: 用于准确和可迁移神经势的非平衡分子去噪预训练

    Denoise Pretraining on Nonequilibrium Molecules for Accurate and Transferable Neural Potentials. (arXiv:2303.02216v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2303.02216](http://arxiv.org/abs/2303.02216)

    该论文提出了一种用于准确和可迁移神经势的非平衡分子去噪预训练方法，并通过实验证明了该方法能显著提高势能模型的准确性和可迁移性。

    

    最近等变图神经网络（GNN）的进展使深度学习能够开发快速的模型替代昂贵的从头计算量子力学（QM）方法，以用于分子势能的预测。然而，使用GNN建立准确和可迁移的势能模型仍然具有挑战性，因为数据受到昂贵的计算成本和QM方法的理论层次的限制，特别是对于大型和复杂的分子系统。在这项工作中，我们提出了对非平衡分子构型进行去噪预训练，以实现更准确和可迁移的GNN势能预测。具体地，对采样的非平衡构型的原子坐标进行随机噪声扰动，并预训练GNN对扰动的分子构型进行去噪，从而恢复原始坐标。对多个基准测试进行严格实验证明，预训练显著提高了神经势能的准确性。此外，我们还展示了预训练可以提高可迁移性，使模型在不同系统上表现良好。

    Recent advances in equivariant graph neural networks (GNNs) have made deep learning amenable to developing fast surrogate models to expensive ab initio quantum mechanics (QM) approaches for molecular potential predictions. However, building accurate and transferable potential models using GNNs remains challenging, as the data is greatly limited by the expensive computational costs and level of theory of QM methods, especially for large and complex molecular systems. In this work, we propose denoise pretraining on nonequilibrium molecular conformations to achieve more accurate and transferable GNN potential predictions. Specifically, atomic coordinates of sampled nonequilibrium conformations are perturbed by random noises and GNNs are pretrained to denoise the perturbed molecular conformations which recovers the original coordinates. Rigorous experiments on multiple benchmarks reveal that pretraining significantly improves the accuracy of neural potentials. Furthermore, we show that the
    
[^81]: FederatedTrust: 解决可信任的联邦学习问题

    FederatedTrust: A Solution for Trustworthy Federated Learning. (arXiv:2302.09844v2 [cs.CR] UPDATED)

    [http://arxiv.org/abs/2302.09844](http://arxiv.org/abs/2302.09844)

    本研究关注解决分布式数据隐私问题，提出了一个名为FederatedTrust的解决方案，旨在处理联邦学习模型的可信任性问题，包括健壮性、公平性、可解释性和问责制。

    

    随着物联网（IoT）和边缘计算的快速发展，集中式机器学习和深度学习方法面临着分布式数据孤立所带来的挑战，这些数据孤立中保存着敏感信息。为了解决数据隐私问题，出现了协作和隐私保护的机器学习和深度学习技术，如联邦学习（FL）。然而，仅仅确保数据隐私和性能是不够的，因为越来越需要建立对模型预测的信任。现有文献提出了各种关于可信任机器学习和深度学习方面的方法（不包括数据隐私），将健壮性、公平性、可解释性和问责制视为重要支柱。然而，进一步的研究需要确定与FL模型特别相关的可信任支柱和评估指标，并开发能够计算FL模型可信任水平的解决方案。本研究检查了评估可信任性的现有要求

    The rapid expansion of the Internet of Things (IoT) and Edge Computing has presented challenges for centralized Machine and Deep Learning (ML/DL) methods due to the presence of distributed data silos that hold sensitive information. To address concerns regarding data privacy, collaborative and privacy-preserving ML/DL techniques like Federated Learning (FL) have emerged. However, ensuring data privacy and performance alone is insufficient since there is a growing need to establish trust in model predictions. Existing literature has proposed various approaches on trustworthy ML/DL (excluding data privacy), identifying robustness, fairness, explainability, and accountability as important pillars. Nevertheless, further research is required to identify trustworthiness pillars and evaluation metrics specifically relevant to FL models, as well as to develop solutions that can compute the trustworthiness level of FL models. This work examines the existing requirements for evaluating trustwort
    
[^82]: 使用指针生成网络和SciBERT嵌入生成研究论文的摘要

    Generation of Highlights from Research Papers Using Pointer-Generator Networks and SciBERT Embeddings. (arXiv:2302.07729v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2302.07729](http://arxiv.org/abs/2302.07729)

    该论文提出了一种使用指针生成网络和SciBERT嵌入来自动生成研究论文亮点的方法。在多个基准数据集上的实验证明，该模型在研究亮点生成方面具有最佳性能。

    

    如今，许多研究文章都以研究亮点作为前言，以总结论文的主要发现。亮点不仅帮助研究人员准确快速地识别论文的贡献，还通过搜索引擎增加了文章的可发现性。我们的目标是在给定研究论文的特定段落的情况下自动构建研究亮点。我们使用了一个具有覆盖机制和上下文嵌入层的指针生成网络，将输入标记编码为SciBERT嵌入。我们在基准数据集CSPubSum上测试了我们的模型，并且还提出了MixSub，一个用于自动生成研究亮点的新的跨学科论文语料库。对于CSPubSum和MixSub，我们观察到所提出的模型相对于相关变体和文献中提出的其他模型来说具有最佳性能。在CSPubSum数据集上，我们的模型在只使用论文的摘要作为输入时表现最佳。

    Nowadays many research articles are prefaced with research highlights to summarize the main findings of the paper. Highlights not only help researchers precisely and quickly identify the contributions of a paper, they also enhance the discoverability of the article via search engines. We aim to automatically construct research highlights given certain segments of a research paper. We use a pointer-generator network with coverage mechanism and a contextual embedding layer at the input that encodes the input tokens into SciBERT embeddings. We test our model on a benchmark dataset, CSPubSum, and also present MixSub, a new multi-disciplinary corpus of papers for automatic research highlight generation. For both CSPubSum and MixSub, we have observed that the proposed model achieves the best performance compared to related variants and other models proposed in the literature. On the CSPubSum dataset, our model achieves the best performance when the input is only the abstract of a paper as op
    
[^83]: Heckerthoughts.（arXiv:2302.05449v4 [cs.AI] UPDATED）

    Heckerthoughts. (arXiv:2302.05449v4 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2302.05449](http://arxiv.org/abs/2302.05449)

    这本论文是作者在斯坦福大学和微软研究院工作经验的技术回忆录，涉及了机器学习和人工智能的基本概念、应用以及创造过程中的故事。

    

    本文是关于我在斯坦福大学和微软研究院工作的技术回忆录。包括了与机器学习和人工智能相关的基本概念，这些概念的应用以及其创造背后的故事。

    This manuscript is technical memoir about my work at Stanford and Microsoft Research. Included are fundamental concepts central to machine learning and artificial intelligence, applications of these concepts, and stories behind their creation.
    
[^84]: ESC：具备软件常识约束的零样本物体导航探索

    ESC: Exploration with Soft Commonsense Constraints for Zero-shot Object Navigation. (arXiv:2301.13166v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2301.13166](http://arxiv.org/abs/2301.13166)

    本文提出了一种新颖的零样本物体导航方法 ESC，它从预先训练的视觉和自然语言处理模型中转移常识知识，可在未知环境中进行导航，具有广阔的应用前景。

    

    准确地定位和导航到特定物体的能力对于在现实世界中操作并与物体交互以完成任务的实体代理来说至关重要。这种物体导航任务通常需要在具有标记物体的视觉环境中进行大规模训练，这种训练效果在未知环境中的新颖物体上泛化效果较差。本文提出了一种新颖的零样本物体导航方法——具备软件常识约束的探索（ESC），它将预先训练的模型中的常识知识转移到在视觉环境上进行开放世界物体导航时不需要进行导航或其他视觉环境训练。首先，ESC利用预先训练的视觉和语言模型进行开放世界基于提示的接地，利用预先训练的常识语言模型进行房间和物体推理。然后，ESC通过将常识知识建模为软逻辑谓词来使其转化为导航动作，从而进行有效的探索。在MP3D上进行了大量实验，......

    The ability to accurately locate and navigate to a specific object is a crucial capability for embodied agents that operate in the real world and interact with objects to complete tasks. Such object navigation tasks usually require large-scale training in visual environments with labeled objects, which generalizes poorly to novel objects in unknown environments. In this work, we present a novel zero-shot object navigation method, Exploration with Soft Commonsense constraints (ESC), that transfers commonsense knowledge in pre-trained models to open-world object navigation without any navigation experience nor any other training on the visual environments. First, ESC leverages a pre-trained vision and language model for open-world prompt-based grounding and a pre-trained commonsense language model for room and object reasoning. Then ESC converts commonsense knowledge into navigation actions by modeling it as soft logic predicates for efficient exploration. Extensive experiments on MP3D, 
    
[^85]: 用于复杂查询回答的神经链接预测器的调整

    Adapting Neural Link Predictors for Complex Query Answering. (arXiv:2301.12313v2 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2301.12313](http://arxiv.org/abs/2301.12313)

    本文提出通过训练一个参数高效的分数适应模型来重新校准神经链接预测分数以解决神经链接预测器在复杂查询回答中的问题。

    

    在不完整知识图谱上回答复杂查询是一项具有挑战性的任务，模型需要在缺失知识的情况下回答复杂逻辑查询。最近，Arakelyan等人（2021）；Minervini等人（2022）表明，神经链接预测器也可以用于回答复杂查询：他们的连续查询分解（CQD）方法通过将复杂查询分解为原子子查询，使用神经链接预测器回答并通过t-范数来聚合其分数，以对每个复杂查询的答案进行排序。然而，CQD不处理否定并且仅使用原子训练查询的训练信号：在回答复杂查询期间，神经链接预测分数没有通过模糊逻辑t-范数进行校准以相互作用。在这项工作中，我们提出通过训练一个参数高效的分数适应模型来重新校准神经链接预测分数以解决这个问题：这个新组件通过反向传播法在复杂查询上进行训练。

    Answering complex queries on incomplete knowledge graphs is a challenging task where a model needs to answer complex logical queries in the presence of missing knowledge. Recently, Arakelyan et al. (2021); Minervini et al. (2022) showed that neural link predictors could also be used for answering complex queries: their Continuous Query Decomposition (CQD) method works by decomposing complex queries into atomic sub-queries, answers them using neural link predictors and aggregates their scores via t-norms for ranking the answers to each complex query. However, CQD does not handle negations and only uses the training signal from atomic training queries: neural link prediction scores are not calibrated to interact together via fuzzy logic t-norms during complex query answering. In this work, we propose to address this problem by training a parameter-efficient score adaptation model to re-calibrate neural link prediction scores: this new component is trained on complex queries by back-propa
    
[^86]: 高效节约内存的NLLB-200：针对大规模多语言机器翻译模型的语言特定专家删减

    Memory-efficient NLLB-200: Language-specific Expert Pruning of a Massively Multilingual Machine Translation Model. (arXiv:2212.09811v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2212.09811](http://arxiv.org/abs/2212.09811)

    本研究提出了一种节约内存的NLLB-200模型修剪方法，可在保持翻译质量的同时移除多达80％的专家，使得在单个32GB的GPU上运行模型成为可能。这对于大规模多语言机器翻译具有重要的意义。

    

    与传统的双语翻译系统相比，大规模多语言机器翻译具有吸引力，因为一个单一模型可以翻译成多种语言，并从知识转移中获益，尤其是对于低资源语言。然而，大规模多语言模型受到多语言性的限制，除非进行大规模扩展，否则会增加训练和推理成本。稀疏的专家混合模型是一种在不需要大量计算的情况下大幅增加模型容量的方法。最近发布的NLLB-200是这样一个模型的例子。它涵盖了202种语言，但仅推理就需要至少四个32GB的GPU。在这项工作中，我们提出了一种修剪方法，允许删除多达80％的专家，但翻译质量几乎没有损失，这使得在单个32GB的GPU上运行该模型成为可能。进一步分析表明，我们的修剪度量指标可以识别出语言特定的专家

    Compared to conventional bilingual translation systems, massively multilingual machine translation is appealing because a single model can translate into multiple languages and benefit from knowledge transfer for low resource languages. On the other hand, massively multilingual models suffer from the curse of multilinguality, unless scaling their size massively, which increases their training and inference costs. Sparse Mixture-of-Experts models are a way to drastically increase model capacity without the need for a proportional amount of computing. The recently released NLLB-200 is an example of such a model. It covers 202 languages but requires at least four 32GB GPUs just for inference. In this work, we propose a pruning method that allows the removal of up to 80\% of experts with a negligible loss in translation quality, which makes it feasible to run the model on a single 32GB GPU. Further analysis suggests that our pruning metrics allow to identify language-specific experts and p
    
[^87]: 使用关系感知消息传递神经网络生成无偏见的异构场景图

    Unbiased Heterogeneous Scene Graph Generation with Relation-aware Message Passing Neural Network. (arXiv:2212.00443v3 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2212.00443](http://arxiv.org/abs/2212.00443)

    本文提出了一种无偏见的异构场景图生成框架，使用关系感知消息传递神经网络捕获对象之间的上下文感知性，并设计了一种新的消息传递层来汇总图像的上下文信息。

    

    近期的场景图生成（SGG）框架聚焦于学习图像中多个对象之间的复杂关系。由于消息传递神经网络（MPNN）能够模拟对象与邻近对象之间的高阶相互作用，因此它们是SGG的主导表示学习模块。然而，现有的基于MPNN的框架将场景图视为同质图，这限制了对象之间的上下文感知性，而忽视了关系往往高度依赖于与关系相关联的对象这一事实。本文提出了一种无偏见的异构场景图生成（HetSGG）框架，利用消息传递神经网络捕获关系感知上下文。我们设计了一种新的消息传递层，称为关系感知消息传递神经网络（RMP），它考虑了对象之间的谓词类型，汇总了图像的上下文信息。所提出的HetSGG框架在基准数据集上取得了最新的性能，证明了关系感知消息传递对于SGG的有效性。

    Recent scene graph generation (SGG) frameworks have focused on learning complex relationships among multiple objects in an image. Thanks to the nature of the message passing neural network (MPNN) that models high-order interactions between objects and their neighboring objects, they are dominant representation learning modules for SGG. However, existing MPNN-based frameworks assume the scene graph as a homogeneous graph, which restricts the context-awareness of visual relations between objects. That is, they overlook the fact that the relations tend to be highly dependent on the objects with which the relations are associated. In this paper, we propose an unbiased heterogeneous scene graph generation (HetSGG) framework that captures relation-aware context using message passing neural networks. We devise a novel message passing layer, called relation-aware message passing neural network (RMP), that aggregates the contextual information of an image considering the predicate type between 
    
[^88]: 具有真正零-shot能力的弱监督流式多语言语音模型

    A Weakly-Supervised Streaming Multilingual Speech Model with Truly Zero-Shot Capability. (arXiv:2211.02499v2 [cs.CL] UPDATED)

    [http://arxiv.org/abs/2211.02499](http://arxiv.org/abs/2211.02499)

    本文介绍了一个弱监督流式多语言语音模型，利用机器翻译服务将语音识别转录转化为弱监督数据来训练模型。该模型具有真正的零-shot能力，可以在扩展到新的目标语言时产生高质量的语音翻译结果。

    

    本文介绍了我们构建的流式多语言语音模型（SM2）的工作，该模型可以将多种口语语言转录或翻译为目标语言的文本。SM2的核心是Transformer Transducer，具有高度流式处理能力。我们使用通过机器翻译服务将语音识别语料库中的转录转化而成的弱监督数据来训练SM2模型，而非人工标记的语音翻译数据。利用来自25种语言的35.1万小时的匿名语音训练数据，SM2模型的语音翻译质量与某些最新的大规模非流式语音模型相当甚至更好。更重要的是，我们展示了当扩展到新的目标语言时，SM2具有真正的零-shot能力，可以为训练过程中未见过的{源语音，目标文本}对产生高质量的语音翻译结果。

    In this paper, we introduce our work of building a Streaming Multilingual Speech Model (SM2), which can transcribe or translate multiple spoken languages into texts of the target language. The backbone of SM2 is Transformer Transducer, which has high streaming capability. Instead of human labeled speech translation (ST) data, SM2 models are trained using weakly supervised data generated by converting the transcriptions in speech recognition corpora with a machine translation service. With 351 thousand hours of anonymized speech training data from 25 languages, SM2 models achieve comparable or even better ST quality than some recent popular large-scale non-streaming speech models. More importantly, we show that SM2 has the truly zero-shot capability when expanding to new target languages, yielding high quality ST results for {source-speech, target-text} pairs that are not seen during training.
    
[^89]: DiffusionDB: 文本到图像生成模型的大规模提示画廊数据集

    DiffusionDB: A Large-scale Prompt Gallery Dataset for Text-to-Image Generative Models. (arXiv:2210.14896v3 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2210.14896](http://arxiv.org/abs/2210.14896)

    介绍了DiffusionDB数据集，这是一个规模庞大的文本到图像提示数据集，总计包含1400万张图像和180万个唯一提示。该数据集被用来帮助研究人员解决文本提示生成图像时所需的适当提示的问题，并指出了一些特定的提示样式和超参数值可能导致模型错误，甚至生成误导信息。

    

    随着扩散模型的最新进展，用户可以通过编写自然语言提示生成高质量图像。然而，生成具有所需细节的图像需要适当的提示，而且往往不清楚模型对不同提示的反应或最佳提示是什么。为了帮助研究人员解决这些关键挑战，我们介绍了DiffusionDB，这是第一个大规模的文本到图像提示数据集，总计6.5TB，包含使用Stable Diffusion生成的1400万张图像，180万个唯一提示和由真实用户指定的超参数。我们分析了提示的语法和语义特征，并指出了可能导致模型错误的特定超参数值和提示样式，并提供了潜在有害模型使用的证据，如生成误导信息。这个人为驱动的数据集的空前规模和多样性为了解提示和生成图像之间相互作用提供了激动人心的研究机会。

    With recent advancements in diffusion models, users can generate high-quality images by writing text prompts in natural language. However, generating images with desired details requires proper prompts, and it is often unclear how a model reacts to different prompts or what the best prompts are. To help researchers tackle these critical challenges, we introduce DiffusionDB, the first large-scale text-to-image prompt dataset totaling 6.5TB, containing 14 million images generated by Stable Diffusion, 1.8 million unique prompts, and hyperparameters specified by real users. We analyze the syntactic and semantic characteristics of prompts. We pinpoint specific hyperparameter values and prompt styles that can lead to model errors and present evidence of potentially harmful model usage, such as the generation of misinformation. The unprecedented scale and diversity of this human-actuated dataset provide exciting research opportunities in understanding the interplay between prompts and generat
    
[^90]: 从卫星中发现病毒：通过图神经网络对西尼罗河病毒的循环建模

    Spotting Virus from Satellites: Modeling the Circulation of West Nile Virus Through Graph Neural Networks. (arXiv:2209.05251v2 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2209.05251](http://arxiv.org/abs/2209.05251)

    本论文通过使用卫星图像来预测西尼罗河病毒的循环，提出了一种空间感知的方法，利用图神经网络(GNN)来聚合邻居的特征。

    

    西尼罗河病毒(WNV)的发生代表了最常见的蚊媒性动物传播病毒感染之一。它的循环通常与适合于媒介蚊子繁殖和病毒复制的气候和环境条件相关。此外，已开发了几种统计模型来塑造和预测WNV的循环：特别是，地球观测(EO)数据的大规模可用性，加上人工智能领域的不断进步，提供了宝贵的机会。在本文中，我们试图通过将卫星图像输入深度神经网络(DNNs)来预测WNV的循环，这些卫星图像已经广泛显示具有环境和气候特征。值得注意的是，虽然之前的方法独立地分析每个地理点，但我们提出了一种空间感知的方法，考虑了附近点的特征。具体而言，我们依靠图神经网络(GNN)来聚合邻居的特征。

    The occurrence of West Nile Virus (WNV) represents one of the most common mosquito-borne zoonosis viral infections. Its circulation is usually associated with climatic and environmental conditions suitable for vector proliferation and virus replication. On top of that, several statistical models have been developed to shape and forecast WNV circulation: in particular, the recent massive availability of Earth Observation (EO) data, coupled with the continuous advances in the field of Artificial Intelligence, offer valuable opportunities.  In this paper, we seek to predict WNV circulation by feeding Deep Neural Networks (DNNs) with satellite images, which have been extensively shown to hold environmental and climatic features. Notably, while previous approaches analyze each geographical site independently, we propose a spatial-aware approach that considers also the characteristics of close sites. Specifically, we build upon Graph Neural Networks (GNN) to aggregate features from neighbour
    
[^91]: 离线强化学习从视觉观察中的挑战和机遇

    Challenges and Opportunities in Offline Reinforcement Learning from Visual Observations. (arXiv:2206.04779v3 [cs.LG] UPDATED)

    [http://arxiv.org/abs/2206.04779](http://arxiv.org/abs/2206.04779)

    该论文研究了离线强化学习从视觉观察中的挑战和机遇，针对这一复杂领域建立了视觉领域中连续控制的简单基准，并设计了一系列基准任务，以更好地表示现实世界离线RL问题中的数据分布，并通过对两种基于视觉的在线强化学习算法的简单修改进行评估。

    

    离线强化学习已经展现了在利用大规模预先收集的数据集进行策略学习方面的巨大潜力，使得Agent可以避免通常费时昂贵的在线数据收集。然而，在连续动作空间中，基于视觉观察的离线强化学习仍然未被充分探索，在这个复杂的领域中对关键挑战的理解有限。在本文中，我们为视觉领域中的连续控制建立简单的基准，并引入了一系列针对离线强化学习的基准任务，这些任务旨在更好地表示现实世界离线RL问题中存在的数据分布，并受离线RL从视觉观察中的一组期望所指导，包括对视觉干扰的稳健性和动力学中可视化变化的识别能力。通过使用这套基准任务，我们展示了对两种广泛使用的基于视觉的在线强化学习算法DreamerV2和DrQ-v2进行简单修改的可行性。

    Offline reinforcement learning has shown great promise in leveraging large pre-collected datasets for policy learning, allowing agents to forgo often-expensive online data collection. However, offline reinforcement learning from visual observations with continuous action spaces remains under-explored, with a limited understanding of the key challenges in this complex domain. In this paper, we establish simple baselines for continuous control in the visual domain and introduce a suite of benchmarking tasks for offline reinforcement learning from visual observations designed to better represent the data distributions present in real-world offline RL problems and guided by a set of desiderata for offline RL from visual observations, including robustness to visual distractions and visually identifiable changes in dynamics. Using this suite of benchmarking tasks, we show that simple modifications to two popular vision-based online reinforcement learning algorithms, DreamerV2 and DrQ-v2, suf
    
[^92]: 机器学习友好的生物医学数据集用于等价和包含关系本体匹配

    Machine Learning-Friendly Biomedical Datasets for Equivalence and Subsumption Ontology Matching. (arXiv:2205.03447v7 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2205.03447](http://arxiv.org/abs/2205.03447)

    本文介绍了五个新的生物医学本体匹配任务，通过引入机器学习技术并解决现有评估方法的限制，提供了综合评估框架来衡量本体匹配系统的性能。

    

    本体匹配在生物信息学和语义网等许多领域中扮演着重要角色，随着机器学习技术的应用，其研究越来越受到关注。然而，现有的本体匹配评估方法仍存在一些限制，包括对包含关系映射的有限评估、参考映射的亚优解以及对基于机器学习的系统评估的有限支持。为了解决这些限制，我们提出了五个新的生物医学本体匹配任务，涉及从Mondo和UMLS中提取的本体。每个任务包括等价和包含关系匹配，并通过人工筛选、本体修剪等方式确保参考映射的质量，并提出了一个综合评估框架，来从不同的角度评估基于机器学习和非机器学习的本体匹配系统性能。我们报告了评估结果。

    Ontology Matching (OM) plays an important role in many domains such as bioinformatics and the Semantic Web, and its research is becoming increasingly popular, especially with the application of machine learning (ML) techniques. Although the Ontology Alignment Evaluation Initiative (OAEI) represents an impressive effort for the systematic evaluation of OM systems, it still suffers from several limitations including limited evaluation of subsumption mappings, suboptimal reference mappings, and limited support for the evaluation of ML-based systems. To tackle these limitations, we introduce five new biomedical OM tasks involving ontologies extracted from Mondo and UMLS. Each task includes both equivalence and subsumption matching; the quality of reference mappings is ensured by human curation, ontology pruning, etc.; and a comprehensive evaluation framework is proposed to measure OM performance from various perspectives for both ML-based and non-ML-based OM systems. We report evaluation r
    
[^93]: 数据集偏倚的潜在来源使机器学习算法对未诊断问题的研究复杂化

    Potential sources of dataset bias complicate investigation of underdiagnosis by machine learning algorithms. (arXiv:2201.07856v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2201.07856](http://arxiv.org/abs/2201.07856)

    这项研究发现，机器学习算法在胸部X射线数据集上训练时会在未得到足够服务的人群中产生高虚报率，可能放大了系统的未诊断问题。然而，研究的实验设置不足以全面研究算法的未诊断问题，而且使用与训练数据相同偏倚的测试数据进一步加剧了结果的解释难度。

    

    越来越多的报告引起了对机器学习算法可能放大由训练数据中嵌入的偏见导致的健康差异的担忧。 Seyyed-Kalantari等人发现，在三个胸部X射线数据集上训练的模型在“未发现”标签（表示没有疾病）的亚组之间产生了虚报率（FPR）的差异。这些模型在已知历史上未得到足够服务的亚组中一直产生更高的FPR，并且该研究得出结论，这些模型显示并且可能会放大系统的未诊断问题。我们认为该研究中的实验设置不足以研究算法未诊断问题。在缺乏关于数据集偏倚程度和性质的具体知识（或假设）的情况下，很难调查模型偏倚问题。重要的是，他们使用的测试数据展示了与训练数据相同的偏倚（由于随机分割），严重复杂化了所报道的差异的解释。

    An increasing number of reports raise concerns about the risk that machine learning algorithms could amplify health disparities due to biases embedded in the training data. Seyyed-Kalantari et al. find that models trained on three chest X-ray datasets yield disparities in false-positive rates (FPR) across subgroups on the 'no-finding' label (indicating the absence of disease). The models consistently yield higher FPR on subgroups known to be historically underserved, and the study concludes that the models exhibit and potentially even amplify systematic underdiagnosis. We argue that the experimental setup in the study is insufficient to study algorithmic underdiagnosis. In the absence of specific knowledge (or assumptions) about the extent and nature of the dataset bias, it is difficult to investigate model bias. Importantly, their use of test data exhibiting the same bias as the training data (due to random splitting) severely complicates the interpretation of the reported disparities
    
[^94]: AGM信念修正的语义学通用特性

    AGM Belief Revision, Semantically. (arXiv:2112.13557v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2112.13557](http://arxiv.org/abs/2112.13557)

    本论文建立了关于实现最小变化范式的信念修正运算符的通用模型论刻画，适用于所有具有经典模型论语义的逻辑，包括以前缺乏刻画的形式主义。该研究通过推广Katsuno和Mendelzon的方法，为任意塔斯基逻辑的AGM风格修正提供了刻画方法。

    

    我们建立了对于实现最小变化范式的信念修正运算符的通用模型论刻画，参考了Alchourr\'{o}n, G\"{a}rdenfors, 和 Makinson (AGM)的开创性工作。我们的刻画适用于所有塔斯基逻辑，即所有具有经典模型论语义的逻辑，因此适用于知识表示等广泛领域中使用的各种形式主义，包括以前缺乏模型论刻画的许多形式主义。我们的出发点是Katsuno和Mendelzon(K&M)的方法，他们为有限符号上的命题逻辑提供了这样的刻画。我们将K&M的方法推广到任意塔斯基逻辑的AGM风格修正的基础上，其中基础可以指代代理人信念的各种表示方式（如信念集合、任意或有限句子集合或单个句子）。我们的第一个核心结果是一个表示定理，提供了一个双向的co表示方法

    We establish a generic, model-theoretic characterization of belief revision operators implementing the paradigm of minimal change according to the seminal work by Alchourr\'{o}n, G\"{a}rdenfors, and Makinson (AGM). Our characterization applies to all Tarskian logics, that is, all logics with a classical model-theoretic semantics, and hence a wide variety of formalisms used in knowledge representation and beyond, including many for which a model-theoretic characterization has hitherto been lacking. Our starting point is the approach by Katsuno and Mendelzon (K&M), who provided such a characterization for propositional logic over finite signatures. We generalize K&M's approach to the setting of AGM-style revision over bases in arbitrary Tarskian logics, where base may refer to one of the various ways of representing an agent's beliefs (such as belief sets, arbitrary or finite sets of sentences, or single sentences). Our first core result is a representation theorem providing a two-way co
    
[^95]: 在野外平衡面孔中平衡偏见并保护隐私

    Balancing Biases and Preserving Privacy on Balanced Faces in the Wild. (arXiv:2103.09118v5 [cs.CV] UPDATED)

    [http://arxiv.org/abs/2103.09118](http://arxiv.org/abs/2103.09118)

    本研究引入了平衡野外面孔数据集（BFW），通过该数据集我们发现人脸识别模型存在人口统计偏见。为了解决这个问题，我们提出了一种新颖的域自适应学习方案，该方案可以提高平均性能并保护隐私。

    

    当前的人脸识别模型存在人口统计偏见。为了衡量不同族群和性别子群之间的这些偏见，我们引入了我们的平衡野外面孔数据集（BFW）。该数据集允许对每个子群的人脸识别性能进行描述。我们发现，依赖单一分数阈值来区分真实和冒名顶替者样本对会导致次优结果。此外，子群内的性能往往与全局平均值有明显差异。因此，特定的错误率仅适用于与验证数据匹配的人群。为了减轻不平衡的性能，我们提出了一种新颖的域自适应学习方案，该方案利用从最先进的神经网络中提取的面部特征。该方案提高了平均性能，并在去除人口统计知识的同时保留了身份信息。去除人口统计知识可以防止潜在的偏见影响决策，并保护隐私。

    There are demographic biases present in current facial recognition (FR) models. To measure these biases across different ethnic and gender subgroups, we introduce our Balanced Faces in the Wild (BFW) dataset. This dataset allows for the characterization of FR performance per subgroup. We found that relying on a single score threshold to differentiate between genuine and imposters sample pairs leads to suboptimal results. Additionally, performance within subgroups often varies significantly from the global average. Therefore, specific error rates only hold for populations that match the validation data. To mitigate imbalanced performances, we propose a novel domain adaptation learning scheme that uses facial features extracted from state-of-the-art neural networks. This scheme boosts the average performance and preserves identity information while removing demographic knowledge. Removing demographic knowledge prevents potential biases from affecting decision-making and protects privacy 
    
[^96]: 可微分逻辑机器

    Differentiable Logic Machines. (arXiv:2102.11529v5 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2102.11529](http://arxiv.org/abs/2102.11529)

    可微分逻辑机器 (DLM) 是一种新颖的神经逻辑架构，可以解决归纳逻辑编程 (ILP) 和强化学习 (RL) 问题，其创新之处在于定义了一种受限但富有表现力的一阶逻辑程序的连续松弛，并提供了可解释的解决方案。通过梯度下降进行训练，同时设计了一种新颖的评论家架构用于加速强化学习训练。

    

    推理、学习和决策的集成是构建更通用人工智能系统的关键。为此，我们提出了一种新颖的神经逻辑架构，称为可微分逻辑机器（DLM），可以解决归纳逻辑编程（ILP）和强化学习（RL）问题，其中解决方案可以被解释为一阶逻辑程序。我们的提议包括几个创新点。首先，我们的架构通过为谓词分配权重而不是规则，定义了一种受限但富有表现力的一阶逻辑程序的连续松弛，与大多数先前的神经逻辑方法不同。其次，通过这种可微分的架构，我们提出了几种（监督和RL）训练过程，基于梯度下降，可以恢复一个完全可解释的解决方案（即逻辑公式）。第三，为了加速RL训练，我们还设计了一种新颖的评论家架构，可以实现演员评论家

    The integration of reasoning, learning, and decision-making is key to build more general artificial intelligence systems. As a step in this direction, we propose a novel neural-logic architecture, called differentiable logic machine (DLM), that can solve both inductive logic programming (ILP) and reinforcement learning (RL) problems, where the solution can be interpreted as a first-order logic program. Our proposition includes several innovations. Firstly, our architecture defines a restricted but expressive continuous relaxation of the space of first-order logic programs by assigning weights to predicates instead of rules, in contrast to most previous neural-logic approaches. Secondly, with this differentiable architecture, we propose several (supervised and RL) training procedures, based on gradient descent, which can recover a fully-interpretable solution (i.e., logic formula). Thirdly, to accelerate RL training, we also design a novel critic architecture that enables actor-critic a
    
[^97]: 《SAT求解中的时间跃迁挑战》

    A Time Leap Challenge for SAT Solving. (arXiv:2008.02215v2 [cs.AI] UPDATED)

    [http://arxiv.org/abs/2008.02215](http://arxiv.org/abs/2008.02215)

    SAT求解中，算法进步对硬件进步的影响至少同样重要。

    

    我们比较了过去两个十年中硬件进步和算法进步对SAT求解的影响。特别是，我们比较了使用新的计算机硬件进行的20年前的SAT求解器与使用20年前的旧硬件进行的现代SAT求解器。我们的发现表明，在算法方面的进展对硬件方面的进步至少同样重要。

    We compare the impact of hardware advancement and algorithm advancement for SAT solving over the last two decades. In particular, we compare 20-year-old SAT-solvers on new computer hardware with modern SAT-solvers on 20-year-old hardware. Our findings show that the progress on the algorithmic side has at least as much impact as the progress on the hardware side.
    

