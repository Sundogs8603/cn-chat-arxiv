<rss version="2.0"><channel><title>Chat Arxiv econ</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for econ</description><item><title>&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#21307;&#30103;&#20445;&#20581;&#25104;&#26412;&#25928;&#30410;&#20998;&#26512;&#30340;&#22810;&#20803;&#36125;&#21494;&#26031;&#21487;&#21152;&#22238;&#24402;&#26641;&#25193;&#23637;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#27169;&#22411;&#30340;&#23616;&#38480;&#24615;&#65292;&#21487;&#20197;&#22788;&#29702;&#22810;&#20010;&#30456;&#20851;&#32467;&#26524;&#21464;&#37327;&#30340;&#22238;&#24402;&#21644;&#20998;&#31867;&#20998;&#26512;</title><link>https://arxiv.org/abs/2404.02228</link><description>&lt;p&gt;
&#22522;&#20110;&#36125;&#21494;&#26031;&#21487;&#21152;&#22238;&#24402;&#26641;&#30340;&#21307;&#30103;&#20445;&#20581;&#25104;&#26412;&#25928;&#30410;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Seemingly unrelated Bayesian additive regression trees for cost-effectiveness analyses in healthcare
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02228
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#21307;&#30103;&#20445;&#20581;&#25104;&#26412;&#25928;&#30410;&#20998;&#26512;&#30340;&#22810;&#20803;&#36125;&#21494;&#26031;&#21487;&#21152;&#22238;&#24402;&#26641;&#25193;&#23637;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#27169;&#22411;&#30340;&#23616;&#38480;&#24615;&#65292;&#21487;&#20197;&#22788;&#29702;&#22810;&#20010;&#30456;&#20851;&#32467;&#26524;&#21464;&#37327;&#30340;&#22238;&#24402;&#21644;&#20998;&#31867;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#30340;&#29702;&#35770;&#32467;&#26524;&#21644;&#27169;&#25311;&#35777;&#25454;&#34920;&#26126;&#65292;&#36125;&#21494;&#26031;&#21487;&#21152;&#22238;&#24402;&#26641;&#26159;&#19968;&#31181;&#38750;&#24120;&#26377;&#25928;&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#26041;&#27861;&#12290;&#21463;&#21040;&#22312;&#21355;&#29983;&#32463;&#27982;&#23398;&#20013;&#30340;&#25104;&#26412;&#25928;&#30410;&#20998;&#26512;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#20855;&#26377;&#22810;&#20010;&#30456;&#20851;&#32467;&#26524;&#21464;&#37327;&#30340;&#22238;&#24402;&#21644;&#20998;&#31867;&#20998;&#26512;&#30340;BART&#30340;&#22810;&#20803;&#25193;&#23637;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#36890;&#36807;&#20801;&#35768;&#27599;&#20010;&#20010;&#20307;&#21709;&#24212;&#19982;&#19981;&#21516;&#26641;&#32452;&#30456;&#20851;&#32852;&#65292;&#21516;&#26102;&#22788;&#29702;&#32467;&#26524;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#22810;&#20803;BART&#27169;&#22411;&#30340;&#19968;&#20123;&#20027;&#35201;&#23616;&#38480;&#24615;&#12290;&#22312;&#36830;&#32493;&#32467;&#26524;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#26412;&#36136;&#19978;&#26159;&#34920;&#38754;&#26080;&#20851;&#22238;&#24402;&#30340;&#38750;&#21442;&#25968;&#29256;&#26412;&#12290;&#21516;&#26679;&#65292;&#25105;&#20204;&#38024;&#23545;&#20108;&#20803;&#32467;&#26524;&#30340;&#24314;&#35758;&#26159;&#38750;&#21442;&#25968;&#27010;&#25324;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02228v1 Announce Type: cross  Abstract: In recent years, theoretical results and simulation evidence have shown Bayesian additive regression trees to be a highly-effective method for nonparametric regression. Motivated by cost-effectiveness analyses in health economics, where interest lies in jointly modelling the costs of healthcare treatments and the associated health-related quality of life experienced by a patient, we propose a multivariate extension of BART applicable in regression and classification analyses with several correlated outcome variables. Our framework overcomes some key limitations of existing multivariate BART models by allowing each individual response to be associated with different ensembles of trees, while still handling dependencies between the outcomes. In the case of continuous outcomes, our model is essentially a nonparametric version of seemingly unrelated regression. Likewise, our proposal for binary outcomes is a nonparametric generalisation of
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;DML&#20272;&#35745;&#22120;&#25193;&#23637;&#65292;&#36890;&#36807;&#23545;&#27010;&#29575;&#24471;&#20998;&#24314;&#27169;&#36827;&#34892;&#27424;&#37319;&#26679;&#65292;&#24182;&#26657;&#20934;&#20998;&#25968;&#20197;&#21305;&#37197;&#21407;&#22987;&#20998;&#24067;&#65292;&#20197;&#35299;&#20915;&#22788;&#29702;&#20998;&#37197;&#19981;&#24179;&#34913;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.01585</link><description>&lt;p&gt;
&#20351;&#29992;&#19981;&#24179;&#34913;&#30340;&#22788;&#29702;&#20998;&#37197;&#26657;&#20934;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
Calibrating doubly-robust estimators with unbalanced treatment assignment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01585
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;DML&#20272;&#35745;&#22120;&#25193;&#23637;&#65292;&#36890;&#36807;&#23545;&#27010;&#29575;&#24471;&#20998;&#24314;&#27169;&#36827;&#34892;&#27424;&#37319;&#26679;&#65292;&#24182;&#26657;&#20934;&#20998;&#25968;&#20197;&#21305;&#37197;&#21407;&#22987;&#20998;&#24067;&#65292;&#20197;&#35299;&#20915;&#22788;&#29702;&#20998;&#37197;&#19981;&#24179;&#34913;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#23588;&#20854;&#26159;&#21452;&#26426;&#22120;&#23398;&#20064;&#65288;DML&#65289;&#20272;&#35745;&#22120;&#65288;Chernozhukov&#31561;&#65292;2018&#65289;&#65292;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#22320;&#29992;&#20110;&#20272;&#35745;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#12290;&#28982;&#32780;&#65292;&#25968;&#25454;&#38598;&#36890;&#24120;&#34920;&#29616;&#20986;&#22788;&#29702;&#20998;&#37197;&#19981;&#24179;&#34913;&#65292;&#21482;&#26377;&#23569;&#25968;&#35266;&#27979;&#20540;&#34987;&#22788;&#29702;&#65292;&#23548;&#33268;&#31283;&#20581;&#27010;&#29575;&#24471;&#20998;&#20272;&#35745;&#19981;&#31283;&#23450;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;DML&#20272;&#35745;&#22120;&#30340;&#31616;&#21333;&#25193;&#23637;&#65292;&#35813;&#25193;&#23637;&#23545;&#27010;&#29575;&#24471;&#20998;&#24314;&#27169;&#36827;&#34892;&#20102;&#27424;&#37319;&#26679;&#65292;&#24182;&#26657;&#20934;&#20998;&#25968;&#20197;&#21305;&#37197;&#21407;&#22987;&#20998;&#24067;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#29702;&#35770;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#20272;&#35745;&#22120;&#20445;&#30041;&#20102;DML&#20272;&#35745;&#22120;&#30340;&#28176;&#36817;&#29305;&#24615;&#12290;&#27169;&#25311;&#30740;&#31350;&#35828;&#26126;&#20102;&#20272;&#35745;&#22120;&#30340;&#26377;&#38480;&#26679;&#26412;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01585v1 Announce Type: new  Abstract: Machine learning methods, particularly the double machine learning (DML) estimator (Chernozhukov et al., 2018), are increasingly popular for the estimation of the average treatment effect (ATE). However, datasets often exhibit unbalanced treatment assignments where only a few observations are treated, leading to unstable propensity score estimations. We propose a simple extension of the DML estimator which undersamples data for propensity score modeling and calibrates scores to match the original distribution. The paper provides theoretical results showing that the estimator retains the DML estimator's asymptotic properties. A simulation study illustrates the finite sample performance of the estimator.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30740;&#31350;&#35758;&#31243;&#65292;&#20171;&#32461;&#20102;&#31038;&#20250;&#29615;&#22659;&#35774;&#35745;&#20316;&#20026;&#19968;&#31181;&#29992;&#20110;&#33258;&#21160;&#21270;&#25919;&#31574;&#21046;&#23450;&#30340;AI&#36890;&#29992;&#26694;&#26550;&#65292;&#26088;&#22312;&#25429;&#25417;&#19968;&#33324;&#32463;&#27982;&#29615;&#22659;&#65292;&#36890;&#36807;AI&#27169;&#25311;&#31995;&#32479;&#20998;&#26512;&#25919;&#24220;&#21644;&#32463;&#27982;&#25919;&#31574;&#65292;&#24182;&#24378;&#35843;&#26410;&#26469;&#22522;&#20110;AI&#30340;&#25919;&#31574;&#21046;&#23450;&#30740;&#31350;&#20013;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.14090</link><description>&lt;p&gt;
&#31038;&#20250;&#29615;&#22659;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Social Environment Design
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14090
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30740;&#31350;&#35758;&#31243;&#65292;&#20171;&#32461;&#20102;&#31038;&#20250;&#29615;&#22659;&#35774;&#35745;&#20316;&#20026;&#19968;&#31181;&#29992;&#20110;&#33258;&#21160;&#21270;&#25919;&#31574;&#21046;&#23450;&#30340;AI&#36890;&#29992;&#26694;&#26550;&#65292;&#26088;&#22312;&#25429;&#25417;&#19968;&#33324;&#32463;&#27982;&#29615;&#22659;&#65292;&#36890;&#36807;AI&#27169;&#25311;&#31995;&#32479;&#20998;&#26512;&#25919;&#24220;&#21644;&#32463;&#27982;&#25919;&#31574;&#65292;&#24182;&#24378;&#35843;&#26410;&#26469;&#22522;&#20110;AI&#30340;&#25919;&#31574;&#21046;&#23450;&#30740;&#31350;&#20013;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#20316;&#20026;&#19968;&#31181;&#29992;&#20110;&#25913;&#21892;&#25919;&#24220;&#21644;&#32463;&#27982;&#25919;&#31574;&#21046;&#23450;&#30340;&#25216;&#26415;&#20855;&#26377;&#28508;&#21147;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#30740;&#31350;&#35758;&#31243;&#65292;&#20171;&#32461;&#20102;&#31038;&#20250;&#29615;&#22659;&#35774;&#35745;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#33258;&#21160;&#21270;&#25919;&#31574;&#21046;&#23450;&#30340;AI&#36890;&#29992;&#26694;&#26550;&#65292;&#19982;&#24378;&#21270;&#23398;&#20064;&#12289;&#32463;&#27982;&#19982;&#35745;&#31639;&#31038;&#20250;&#36873;&#25321;&#31038;&#21306;&#30456;&#36830;&#25509;&#12290;&#35813;&#26694;&#26550;&#26088;&#22312;&#25429;&#25417;&#19968;&#33324;&#32463;&#27982;&#29615;&#22659;&#65292;&#21253;&#25324;&#23545;&#25919;&#31574;&#30446;&#26631;&#30340;&#25237;&#31080;&#65292;&#24182;&#20026;&#36890;&#36807;AI&#27169;&#25311;&#23545;&#25919;&#24220;&#21644;&#32463;&#27982;&#25919;&#31574;&#36827;&#34892;&#31995;&#32479;&#20998;&#26512;&#25552;&#20379;&#25351;&#23548;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;&#26410;&#26469;&#22522;&#20110;AI&#30340;&#25919;&#31574;&#21046;&#23450;&#30740;&#31350;&#20013;&#30340;&#20851;&#38190;&#24320;&#25918;&#38382;&#39064;&#12290;&#36890;&#36807;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24076;&#26395;&#23454;&#29616;&#21508;&#31181;&#31038;&#20250;&#31119;&#21033;&#30446;&#26631;&#65292;&#20174;&#32780;&#20419;&#36827;&#26356;&#20855;&#36947;&#24503;&#21644;&#36127;&#36131;&#20219;&#30340;&#20915;&#31574;&#21046;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14090v1 Announce Type: new  Abstract: Artificial Intelligence (AI) holds promise as a technology that can be used to improve government and economic policy-making. This paper proposes a new research agenda towards this end by introducing Social Environment Design, a general framework for the use of AI for automated policy-making that connects with the Reinforcement Learning, EconCS, and Computational Social Choice communities. The framework seeks to capture general economic environments, includes voting on policy objectives, and gives a direction for the systematic analysis of government and economic policy through AI simulation. We highlight key open problems for future research in AI-based policy-making. By solving these challenges, we hope to achieve various social welfare objectives, thereby promoting more ethical and responsible decision making.
&lt;/p&gt;</description></item><item><title>&#22312;&#19968;&#20010;&#37325;&#22797;&#30340;&#36125;&#21494;&#26031;&#35828;&#26381;&#38382;&#39064;&#20013;&#65292;&#21363;&#20351;&#27809;&#26377;&#25215;&#35834;&#33021;&#21147;&#65292;&#22996;&#25176;&#20154;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#19978;&#19979;&#25991;&#26080;&#36951;&#25022;&#23398;&#20064;&#31639;&#27861;&#26469;&#23454;&#29616;&#19982;&#32463;&#20856;&#26080;&#23398;&#20064;&#27169;&#22411;&#20013;&#20855;&#26377;&#25215;&#35834;&#30340;&#22996;&#25176;&#20154;&#30340;&#26368;&#20248;&#25928;&#29992;&#26080;&#38480;&#25509;&#36817;&#30340;&#25928;&#26524;&#65307;&#22312;&#20195;&#29702;&#20154;&#20351;&#29992;&#19978;&#19979;&#25991;&#26080;&#20132;&#25442;&#36951;&#25022;&#23398;&#20064;&#31639;&#27861;&#30340;&#24773;&#20917;&#19979;&#65292;&#22996;&#25176;&#20154;&#26080;&#27861;&#33719;&#24471;&#27604;&#20855;&#26377;&#25215;&#35834;&#30340;&#26080;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#25928;&#29992;&#26356;&#39640;&#30340;&#25928;&#29992;&#12290;</title><link>https://arxiv.org/abs/2402.09721</link><description>&lt;p&gt;
&#35828;&#26381;&#19968;&#20301;&#23398;&#20064;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
Persuading a Learning Agent
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09721
&lt;/p&gt;
&lt;p&gt;
&#22312;&#19968;&#20010;&#37325;&#22797;&#30340;&#36125;&#21494;&#26031;&#35828;&#26381;&#38382;&#39064;&#20013;&#65292;&#21363;&#20351;&#27809;&#26377;&#25215;&#35834;&#33021;&#21147;&#65292;&#22996;&#25176;&#20154;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#19978;&#19979;&#25991;&#26080;&#36951;&#25022;&#23398;&#20064;&#31639;&#27861;&#26469;&#23454;&#29616;&#19982;&#32463;&#20856;&#26080;&#23398;&#20064;&#27169;&#22411;&#20013;&#20855;&#26377;&#25215;&#35834;&#30340;&#22996;&#25176;&#20154;&#30340;&#26368;&#20248;&#25928;&#29992;&#26080;&#38480;&#25509;&#36817;&#30340;&#25928;&#26524;&#65307;&#22312;&#20195;&#29702;&#20154;&#20351;&#29992;&#19978;&#19979;&#25991;&#26080;&#20132;&#25442;&#36951;&#25022;&#23398;&#20064;&#31639;&#27861;&#30340;&#24773;&#20917;&#19979;&#65292;&#22996;&#25176;&#20154;&#26080;&#27861;&#33719;&#24471;&#27604;&#20855;&#26377;&#25215;&#35834;&#30340;&#26080;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#25928;&#29992;&#26356;&#39640;&#30340;&#25928;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#37325;&#22797;&#30340;&#36125;&#21494;&#26031;&#35828;&#26381;&#38382;&#39064;&#65288;&#26356;&#19968;&#33324;&#22320;&#65292;&#20219;&#20309;&#20855;&#26377;&#23436;&#20840;&#20449;&#24687;&#30340;&#24191;&#20041;&#22996;&#25176;-&#20195;&#29702;&#38382;&#39064;&#65289;&#65292;&#20854;&#20013;&#22996;&#25176;&#20154;&#27809;&#26377;&#25215;&#35834;&#33021;&#21147;&#65292;&#20195;&#29702;&#20154;&#20351;&#29992;&#31639;&#27861;&#26469;&#23398;&#20064;&#22914;&#20309;&#23545;&#22996;&#25176;&#20154;&#30340;&#20449;&#21495;&#20570;&#20986;&#21709;&#24212;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#38382;&#39064;&#31616;&#21270;&#20026;&#19968;&#20010;&#19968;&#27425;&#24615;&#30340;&#24191;&#20041;&#22996;&#25176;-&#20195;&#29702;&#38382;&#39064;&#65292;&#20195;&#29702;&#20154;&#36817;&#20284;&#22320;&#26368;&#20339;&#21709;&#24212;&#12290;&#36890;&#36807;&#36825;&#20010;&#31616;&#21270;&#65292;&#25105;&#20204;&#21487;&#20197;&#35777;&#26126;&#65306;&#22914;&#26524;&#20195;&#29702;&#20154;&#20351;&#29992;&#19978;&#19979;&#25991;&#26080;&#36951;&#25022;&#23398;&#20064;&#31639;&#27861;&#65292;&#21017;&#22996;&#25176;&#20154;&#21487;&#20197;&#20445;&#35777;&#20854;&#25928;&#29992;&#19982;&#32463;&#20856;&#26080;&#23398;&#20064;&#27169;&#22411;&#20013;&#20855;&#26377;&#25215;&#35834;&#30340;&#22996;&#25176;&#20154;&#30340;&#26368;&#20248;&#25928;&#29992;&#20043;&#38388;&#21487;&#20197;&#26080;&#38480;&#25509;&#36817;&#65307;&#22914;&#26524;&#20195;&#29702;&#20154;&#20351;&#29992;&#19978;&#19979;&#25991;&#26080;&#20132;&#25442;&#36951;&#25022;&#23398;&#20064;&#31639;&#27861;&#65292;&#21017;&#22996;&#25176;&#20154;&#26080;&#27861;&#33719;&#24471;&#27604;&#20855;&#26377;&#25215;&#35834;&#30340;&#26080;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#26368;&#20248;&#25928;&#29992;&#26356;&#39640;&#30340;&#25928;&#29992;&#12290;&#22996;&#25176;&#20154;&#22312;&#23398;&#20064;&#27169;&#22411;&#19982;&#38750;&#23398;&#20064;&#27169;&#22411;&#20013;&#21487;&#20197;&#33719;&#24471;&#30340;&#25928;&#29992;&#20043;&#38388;&#30340;&#24046;&#36317;&#26159;&#26377;&#30028;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09721v1 Announce Type: cross  Abstract: We study a repeated Bayesian persuasion problem (and more generally, any generalized principal-agent problem with complete information) where the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal's signals. We reduce this problem to a one-shot generalized principal-agent problem with an approximately-best-responding agent. This reduction allows us to show that: if the agent uses contextual no-regret learning algorithms, then the principal can guarantee a utility that is arbitrarily close to the principal's optimal utility in the classic non-learning model with commitment; if the agent uses contextual no-swap-regret learning algorithms, then the principal cannot obtain any utility significantly more than the optimal utility in the non-learning model with commitment. The difference between the principal's obtainable utility in the learning model and the non-learning model is bound
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#27169;&#25311;&#25509;&#25910;&#32773;&#34892;&#20026;&#30340;&#36125;&#21494;&#26031;&#21149;&#23548;&#38382;&#39064;&#20013;&#65292;&#21457;&#36865;&#32773;&#35774;&#35745;&#20102;&#19968;&#20010;&#26368;&#20248;&#28040;&#24687;&#31574;&#30053;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#26597;&#35810;&#31639;&#27861;&#65292;&#20197;&#20248;&#21270;&#20854;&#39044;&#26399;&#25928;&#29992;&#12290;</title><link>https://arxiv.org/abs/2311.18138</link><description>&lt;p&gt;
&#36890;&#36807;&#27169;&#25311;&#36827;&#34892;&#31639;&#27861;&#24615;&#21149;&#23548;
&lt;/p&gt;
&lt;p&gt;
Algorithmic Persuasion Through Simulation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.18138
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#27169;&#25311;&#25509;&#25910;&#32773;&#34892;&#20026;&#30340;&#36125;&#21494;&#26031;&#21149;&#23548;&#38382;&#39064;&#20013;&#65292;&#21457;&#36865;&#32773;&#35774;&#35745;&#20102;&#19968;&#20010;&#26368;&#20248;&#28040;&#24687;&#31574;&#30053;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#26597;&#35810;&#31639;&#27861;&#65292;&#20197;&#20248;&#21270;&#20854;&#39044;&#26399;&#25928;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#36125;&#21494;&#26031;&#21149;&#23548;&#38382;&#39064;&#65292;&#20854;&#20013;&#21457;&#36865;&#32773;&#24076;&#26395;&#35828;&#26381;&#25509;&#25910;&#32773;&#37319;&#21462;&#20108;&#20803;&#34892;&#20026;&#65292;&#20363;&#22914;&#36141;&#20080;&#20135;&#21697;&#12290;&#21457;&#36865;&#32773;&#20102;&#35299;&#19990;&#30028;&#30340;&#65288;&#20108;&#20803;&#65289;&#29366;&#24577;&#65292;&#27604;&#22914;&#20135;&#21697;&#36136;&#37327;&#26159;&#39640;&#36824;&#26159;&#20302;&#65292;&#20294;&#26159;&#23545;&#25509;&#25910;&#32773;&#30340;&#20449;&#24565;&#21644;&#25928;&#29992;&#21482;&#26377;&#26377;&#38480;&#30340;&#20449;&#24687;&#12290;&#21463;&#21040;&#23458;&#25143;&#35843;&#26597;&#12289;&#29992;&#25143;&#30740;&#31350;&#21644;&#29983;&#25104;&#24335;&#20154;&#24037;&#26234;&#33021;&#30340;&#26368;&#26032;&#36827;&#23637;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#20801;&#35768;&#21457;&#36865;&#32773;&#36890;&#36807;&#26597;&#35810;&#27169;&#25311;&#25509;&#25910;&#32773;&#30340;&#34892;&#20026;&#26469;&#20102;&#35299;&#26356;&#22810;&#20851;&#20110;&#25509;&#25910;&#32773;&#30340;&#20449;&#24687;&#12290;&#22312;&#22266;&#23450;&#25968;&#37327;&#30340;&#26597;&#35810;&#20043;&#21518;&#65292;&#21457;&#36865;&#32773;&#25215;&#35834;&#19968;&#20010;&#28040;&#24687;&#31574;&#30053;&#65292;&#25509;&#25910;&#32773;&#26681;&#25454;&#25910;&#21040;&#30340;&#28040;&#24687;&#26469;&#26368;&#22823;&#21270;&#22905;&#30340;&#39044;&#26399;&#25928;&#29992;&#26469;&#37319;&#21462;&#34892;&#21160;&#12290;&#25105;&#20204;&#23545;&#21457;&#36865;&#32773;&#22312;&#20219;&#20309;&#25509;&#25910;&#32773;&#31867;&#22411;&#20998;&#24067;&#19979;&#30340;&#26368;&#20248;&#28040;&#24687;&#31574;&#30053;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#26597;&#35810;&#31639;&#27861;&#65292;&#20248;&#21270;&#20102;&#36825;&#20010;&#36125;&#21494;&#26031;&#21149;&#23548;&#28216;&#25103;&#20013;&#21457;&#36865;&#32773;&#30340;&#39044;&#26399;&#25928;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.18138v2 Announce Type: replace-cross Abstract: We study a Bayesian persuasion problem where a sender wants to persuade a receiver to take a binary action, such as purchasing a product. The sender is informed about the (binary) state of the world, such as whether the quality of the product is high or low, but only has limited information about the receiver's beliefs and utilities. Motivated by customer surveys, user studies, and recent advances in generative AI, we allow the sender to learn more about the receiver by querying an oracle that simulates the receiver's behavior. After a fixed number of queries, the sender commits to a messaging policy and the receiver takes the action that maximizes her expected utility given the message she receives. We characterize the sender's optimal messaging policy given any distribution over receiver types. We then design a polynomial-time querying algorithm that optimizes the sender's expected utility in this Bayesian persuasion game. We 
&lt;/p&gt;</description></item></channel></rss>