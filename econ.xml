<rss version="2.0"><channel><title>Chat Arxiv econ</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for econ</description><item><title>&#26412;&#25991;&#36890;&#36807;&#25193;&#23637;&#20132;&#26131;&#25104;&#26412;&#32463;&#27982;&#23398;&#21644;&#26381;&#21153;&#20027;&#23548;&#36923;&#36753;&#65292;&#21457;&#23637;&#20102;&#19968;&#20010;&#27491;&#24335;&#30340;&#29702;&#35770;&#26694;&#26550;&#26469;&#20998;&#26512;&#25968;&#25454;&#31354;&#38388;&#21644;&#26381;&#21153;&#29983;&#24577;&#30340;&#32463;&#27982;&#21487;&#34892;&#24615;&#12290;&#20854;&#36129;&#29486;&#21253;&#25324;&#23545;&#29983;&#24577;&#31995;&#32479;&#20132;&#26131;&#32463;&#27982;&#21487;&#34892;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#12289;&#29983;&#24577;&#31995;&#32479;&#31283;&#23450;&#24615;&#30340;&#35268;&#27169;&#35201;&#27714;&#21644;&#20219;&#24847;&#25968;&#25454;&#25110;&#26381;&#21153;&#25552;&#20379;&#32773;-&#28040;&#36153;&#32773;&#29983;&#24577;&#31995;&#32479;&#30340;&#19968;&#33324;&#21487;&#34892;&#24615;&#26465;&#20214;&#30340;&#25512;&#23548;&#65292;&#24182;&#25552;&#20986;&#20102;&#19994;&#21153;&#29983;&#24577;&#31995;&#32479;&#30340;&#20195;&#25968;&#23450;&#20041;&#12290;</title><link>http://arxiv.org/abs/2310.03157</link><description>&lt;p&gt;
&#25968;&#25454;&#31354;&#38388;&#21644;&#26381;&#21153;&#29983;&#24577;&#30340;&#32463;&#27982;&#21487;&#34892;&#24615;&#30340;&#27491;&#24335;&#20132;&#26131;&#25104;&#26412;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Formal Transaction Cost-Based Analysis of the Economic Feasibility of Data Spaces and Service Ecosystems. (arXiv:2310.03157v1 [econ.TH])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03157
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25193;&#23637;&#20132;&#26131;&#25104;&#26412;&#32463;&#27982;&#23398;&#21644;&#26381;&#21153;&#20027;&#23548;&#36923;&#36753;&#65292;&#21457;&#23637;&#20102;&#19968;&#20010;&#27491;&#24335;&#30340;&#29702;&#35770;&#26694;&#26550;&#26469;&#20998;&#26512;&#25968;&#25454;&#31354;&#38388;&#21644;&#26381;&#21153;&#29983;&#24577;&#30340;&#32463;&#27982;&#21487;&#34892;&#24615;&#12290;&#20854;&#36129;&#29486;&#21253;&#25324;&#23545;&#29983;&#24577;&#31995;&#32479;&#20132;&#26131;&#32463;&#27982;&#21487;&#34892;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#12289;&#29983;&#24577;&#31995;&#32479;&#31283;&#23450;&#24615;&#30340;&#35268;&#27169;&#35201;&#27714;&#21644;&#20219;&#24847;&#25968;&#25454;&#25110;&#26381;&#21153;&#25552;&#20379;&#32773;-&#28040;&#36153;&#32773;&#29983;&#24577;&#31995;&#32479;&#30340;&#19968;&#33324;&#21487;&#34892;&#24615;&#26465;&#20214;&#30340;&#25512;&#23548;&#65292;&#24182;&#25552;&#20986;&#20102;&#19994;&#21153;&#29983;&#24577;&#31995;&#32479;&#30340;&#20195;&#25968;&#23450;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#31354;&#38388;&#21644;&#26381;&#21153;&#29983;&#24577;&#65288;&#22914;Gaia-X&#65289;&#34987;&#26399;&#26395;&#25512;&#21160;&#26032;&#20852;&#30340;&#25968;&#25454;&#32463;&#27982;&#12290;&#28982;&#32780;&#65292;&#20247;&#25152;&#21608;&#30693;&#65292;&#36825;&#31181;&#22522;&#20110;&#32593;&#32476;&#30340;&#32463;&#27982;&#27835;&#29702;&#32467;&#26500;&#22312;&#20004;&#20010;&#31283;&#23450;&#30340;&#65288;&#27835;&#29702;&#65289;&#31471;&#28857;&#20043;&#38388;&#21344;&#25454;&#20102;&#19968;&#20010;&#28508;&#22312;&#19981;&#31283;&#23450;&#30340;&#20301;&#32622;&#65292;&#21363;&#20844;&#21496;&#65288;&#21363;&#20998;&#23618;&#27835;&#29702;&#65289;&#21644;&#65288;&#24320;&#25918;&#30340;&#65289;&#24066;&#22330;&#65288;&#21363;&#36890;&#36807;&#36135;&#24065;&#31995;&#32479;&#21327;&#35843;&#65289;&#12290;&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#26381;&#21153;&#20027;&#23548;&#36923;&#36753;&#30340;&#26576;&#20123;&#20803;&#32032;&#65292;&#22522;&#20110;&#20132;&#26131;&#25104;&#26412;&#32463;&#27982;&#23398;&#65292;&#21457;&#23637;&#20102;&#19968;&#20010;&#20851;&#20110;&#65288;&#25968;&#25454;&#25110;&#26381;&#21153;&#65289;&#29983;&#24577;&#31995;&#32479;&#21442;&#19982;&#32773;&#32463;&#27982;&#20215;&#20540;&#30340;&#27491;&#24335;&#65288;&#25968;&#23398;&#65289;&#29702;&#35770;&#12290;&#22312;&#35813;&#29702;&#35770;&#26694;&#26550;&#20869;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20960;&#20010;&#20851;&#20110;&#29983;&#24577;&#31995;&#32479;&#20132;&#26131;&#32463;&#27982;&#21487;&#34892;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#12289;&#29983;&#24577;&#31995;&#32479;&#31283;&#23450;&#24615;&#30340;&#35268;&#27169;&#35201;&#27714;&#21644;&#20219;&#24847;&#25968;&#25454;&#25110;&#26381;&#21153;&#25552;&#20379;&#32773;-&#28040;&#36153;&#32773;&#29983;&#24577;&#31995;&#32479;&#30340;&#19968;&#33324;&#21487;&#34892;&#24615;&#26465;&#20214;&#30340;&#23450;&#29702;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19994;&#21153;&#29983;&#24577;&#31995;&#32479;&#30340;&#20195;&#25968;&#23450;&#20041;&#65292;&#24182;&#23558;&#20854;&#19982;&#29616;&#26377;&#30340;&#38750;&#27491;&#24335;&#27010;&#24565;&#36827;&#34892;&#20102;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data spaces and service ecosystems such as Gaia-X are expected to fuel the emerging data economy. It is well known, however, that this type of network-based economic governance structures occupies a potentially unstable position between the two stable (governance) endpoints, namely the firm (i.e., hierarchical governance) and the (open) market (i.e., coordination through the monetary system).  This paper develops a formal (mathematical) theory of the economic value for (data or service) ecosystem participants by extending transaction costs economics using certain elements from service-dominant logic. Within this theory, we derive several theorems on (i) necessary conditions for the economic feasibility of ecosystem-based transactions, (ii) scaling requirements for ecosystem stability, and (iii) a generic feasibility condition for arbitrary data or service provider-consumer ecosystems. Finally, we present an algebraic definition of business ecosystems and relate it to existing informal 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#28151;&#28102;&#37096;&#20998;&#21487;&#35266;&#27979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#26032;&#22411;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#31163;&#32447;&#35774;&#32622;&#19979;&#21487;&#21516;&#26102;&#22788;&#29702;&#36830;&#32493;&#29366;&#24577;&#21644;&#35266;&#23519;&#31354;&#38388;&#65292;&#20855;&#26377;&#39640;&#25928;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.17083</link><description>&lt;p&gt;
&#19968;&#31181;&#38024;&#23545;&#28151;&#28102;&#37096;&#20998;&#21487;&#35266;&#27979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Policy Gradient Method for Confounded POMDPs. (arXiv:2305.17083v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17083
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#28151;&#28102;&#37096;&#20998;&#21487;&#35266;&#27979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#26032;&#22411;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#31163;&#32447;&#35774;&#32622;&#19979;&#21487;&#21516;&#26102;&#22788;&#29702;&#36830;&#32493;&#29366;&#24577;&#21644;&#35266;&#23519;&#31354;&#38388;&#65292;&#20855;&#26377;&#39640;&#25928;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;&#36830;&#32493;&#29366;&#24577;&#21644;&#35266;&#23519;&#31354;&#38388;&#30340;&#28151;&#28102;&#37096;&#20998;&#21487;&#35266;&#27979;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDP&#65289;&#30340;&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#65292;&#22312;&#31163;&#32447;&#35774;&#32622;&#19979;&#20351;&#29992;&#12290;&#25105;&#20204;&#39318;&#20808;&#24314;&#31435;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#35782;&#21035;&#32467;&#26524;&#65292;&#20197;&#22312;&#31163;&#32447;&#25968;&#25454;&#19979;&#38750;&#21442;&#25968;&#22320;&#20272;&#35745;POMDP&#20013;&#30340;&#20219;&#20309;&#21382;&#21490;&#20381;&#36182;&#31574;&#30053;&#26799;&#24230;&#12290;&#35782;&#21035;&#32467;&#26524;&#20351;&#25105;&#20204;&#33021;&#22815;&#35299;&#20915;&#19968;&#31995;&#21015;&#26465;&#20214;&#30697;&#38480;&#21046;&#65292;&#24182;&#37319;&#29992;&#20855;&#26377;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#30340;&#26368;&#23567;&#26368;&#22823;&#23398;&#20064;&#36807;&#31243;&#26469;&#20272;&#35745;&#31574;&#30053;&#26799;&#24230;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#38024;&#23545;&#39044;&#20808;&#25351;&#23450;&#30340;&#31574;&#30053;&#31867;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#38480;&#26679;&#26412;&#30340;&#38750;&#28176;&#36817;&#20272;&#35745;&#30028;&#38480;&#65292;&#20197;&#20102;&#35299;&#26679;&#26412;&#22823;&#23567;&#12289;&#26102;&#38388;&#38271;&#24230;&#12289;&#38598;&#20013;&#24230;&#31995;&#25968;&#21644;&#27714;&#35299;&#26465;&#20214;&#30697;&#38480;&#21046;&#30340;&#20266;&#27491;&#21017;&#24230;&#37327;&#23545;&#20110;&#22343;&#21248;&#20272;&#35745;&#26799;&#24230;&#30340;&#24433;&#21709;&#12290;&#26368;&#21518;&#65292;&#36890;&#36807;&#22312;&#26799;&#24230;&#19978;&#21319;&#31639;&#27861;&#20013;&#20351;&#29992;&#25152;&#25552;&#20986;&#30340;&#26799;&#24230;&#20272;&#35745;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#25214;&#21040;&#21382;&#21490;&#20381;&#36182;&#24615;&#31574;&#30053;&#26799;&#24230;&#26041;&#38754;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a policy gradient method for confounded partially observable Markov decision processes (POMDPs) with continuous state and observation spaces in the offline setting. We first establish a novel identification result to non-parametrically estimate any history-dependent policy gradient under POMDPs using the offline data. The identification enables us to solve a sequence of conditional moment restrictions and adopt the min-max learning procedure with general function approximation for estimating the policy gradient. We then provide a finite-sample non-asymptotic bound for estimating the gradient uniformly over a pre-specified policy class in terms of the sample size, length of horizon, concentratability coefficient and the measure of ill-posedness in solving the conditional moment restrictions. Lastly, by deploying the proposed gradient estimation in the gradient ascent algorithm, we show the global convergence of the proposed algorithm in finding the history-depe
&lt;/p&gt;</description></item></channel></rss>